Spoken Dialogue Interpretation with the DOP ModelRens BodDepartment of Computational LinguisticsUniversity of AmsterdamSpuistraat 134, 1012 VB Amsterdamrens.bod@let.uva.nlAbstractWe show how the DOP model can be used for fast androbust processing of spoken input in a practical spokendialogue system called OVIS.
OVIS, OpenbaarVervoer Informatie Systeem ("Public Transport Infor-mation System"), is a Dutch spoken language infor-mation system which operates over ordinary telephonelines.
The prototype system is the immediate goal ofthe NWO 1 Priority Programme "Language and SpeechTechnology".
In this paper, we extend the originalDOP model to context-sensitive interpretation ofspoken input.
The system we describe uses the OVIScorpus (10,000 trees enriched with compositionalsemantics) to compute from an input word-graph thebest utterance together with its meaning.
Dialoguecontext is taken into account by dividing up the OVIScorpus into context-dependent subcorpora.
Eachsystem question triggers a subcorpus by which the useranswer is analyzed and interpreted.
Our experimentsindicate that the context-sensitive DOP model obtainsbetter accuracy than the original model, allowing forfast and robust processing of spoken input.1.
IntroductionThe Data-Oriented Parsing (DOP) model (cf.
Bod1992, 1995; Bod & Kaplan 1998; Scha 1992; Sima'an1995, 1997; Rajman 1995) is a probabilistic parsingmodel which does not single out a narrowly predefinedset of structures as the statistically significant ones.
Itaccomplishes this by maintaining a large corpus ofanalyses of previously occurring utterances.
Newutterances are analyzed by combining subtrees fromthe corpus.
The occurrence-frequencies of the subtreesare used to estimate the most probable analysis of anutterance.To date, DOP has mainly been applied tocorpora of trees labeled with syntactic annotations.Let us illustrate this with a very simple example.Suppose that a corpus consists of only two trees:(1)S SNP VP NP VPJohn V NP Peter V NPI J J Ilikes Mary hates SusanI Netherlands Organization for Scientific Research138To combine subtrees, a node-substitution operationindicated as o is used.
Node-substitution identifies theleftmost nonterminai frontier node of one tree with theroot node of a second tree (i.e., the second tree issubstituted on the leftmost nonterminal frontier nodeof the first tree).
A new input sentence such as Marylikes Susan can thus be parsed by combining subtreesfrom this corpus, as in (2):(2)S o NP o NP = SNP VP Mary Susan NP VPV NP Mary V NPI I Ilikes likes SusanOther derivations may yield the same parse tree; forinstance:(3)S o NP o V = SNP VP Mary likes NP VPV NP Mary V NPI I ISusan likes SusanDOP computes the probability of substituting a subtreet on a specific node as the probability of selecting tamong all subtrees in the corpus that could besubstituted on that node.
This probability is equal tothe number of occurrences of t, divided by the totalnumber of occurrences of subtrees t' with the sameroot label as t. Let rl(t) return the root label of t then:P(t) = #(t) / ~,t,:rl(t,)=rl(t)#(t').
The probability of aderivation is computed by the product of theprobabilities of the subtrees is consists of.
Theprobability of a parse tree is computed by the sum ofthe probabilities of all derivations that produce thatparse tree.Bod (1992) demonstrated that DOP can beimplemented using conventional context-free parsingtechniques.
However, the computation of the mostprobable parse of a sentence is NP-hard (Sima'an1996).
The most probable parse can be estimated byiterative Monte Carlo sampling (Bod 1995), butefficient algorithms exist only for sub-optimalsolutions such as the most likely derivation of asentence (Bod 1995, Sima'an 1995) or the "labelledrecall parse" of a sentence (Goodman 1996).
So far,the syntactic DOP model has been tested on the ATIScorpus and the Wall Street Journal corpus, obtainingsignificantly better test results than other stochasticparsers (Charniak 1996).
For example, Goodman(1998) compares the results of his DOP parser to areplication of Pereira & Schabes (1992) on the sametraining and test data.
While the Pereira & Schabesmethod achieves 79.2% zero-crossing bracketsaccuracy, DOP obtains 86.1% on the same data(Goodman 1998: p. 179, table 4.4).
Thus the DOPmethod outperforms the Pereira & Schabes methodwith an accuracy-increase of 6.9%, or an error-reduction of 33%.
Goodman also performs a statisticalanalysis using t-test, showing that the differences arestatistically significant beyond the 98th percentile.In Bod et al (1996), it was shown how DOPcan be generalized to semantic interpretation by usingcorpora annotated with compositional semantics.
Inthe current paper, we extend the DOP model tospoken dialogue understanding, and we show how itcan be used as an efficient and robust NLP componentin a practical spoken dialogue system called OVIS.OVIS, Openbaar Vervoer Informatie Systeem ("PublicTransport Information System"), is a Dutch spokenlanguage information system which operates overordinary telephone lines.
The prototype system is theimmediate goal of the NWO Priority Programme"Language and Speech Technology".The backbone of any DOP model is anannotated language corpus.
In the following section,we therefore start with a description of the corpus thatwas developed for the OVIS system, the "OVIScorpus".
We then show how this corpus can be used byDOP to compute the most likely meaning M of a wordstring W: argmax g P(M, W).
Next we demonstrate howthe dialogue context C can be integrated so as tocompute argmaxg P(M, W I C).
Finally, we interfaceDOP with speech and show how the most likelymeaning M of an acoustic utterance A given dialoguecontext C is computed: argmax g P(M, A I C).
The lastsection of this paper deals with the experimentalevaluation of the model.2.
The OVIS corpus: trees enriched withcompositional frame semanticsThe OVIS corpus currently consists of 10,000 syntac-tically and semantically annotated user utterancesthat were collected on the basis of a pilot version ofthe OVIS system 2.
The user utterances are answers tosystem questions uch as From where to where do youwant to travel?, At what time do you want to travel fromUtrecht to Leiden?, Could you please repeat yourdestination ?.For the syntactic annotation of the OVIS userutterances, a tag set of 40 lexical/syntactic categories2 The pilot version is based on a German system developedby Philips Dialogue Systems in Aachen (Aust et al 1995),adapted to Dutch.139was developed.
This tag set was deliberately keptsmall so as to improve the robustness of the DOPparser.
A correlate of this robustness i that the parserwill overgenerate, but as long as the probability modelcan accurately select the correct utterance-analysisfrom all possible analyses, this overgeneration is notproblematic.
Robustness is further achieved by aspecial category, called ERROR.
This category is usedfor stutters, false starts, and repairs.
No grammar isused to determine the correct syntactic annotation;there is a small set of guidelines, that has the degreeof detail necessary to avoid an "anything goes"attitude in the annotator, but leaves room for theannotator's perception of the structure of the utterance(see Bonnema et al 1997).The semantic annotations are based on theupdate language defined for the OVIS dialoguemanager by Veldhuijzen van Zanten (1996).
Thislanguage consists of a hierarchical frame structurewith slots and values for the origin and destination ofa train connection, for the time at which the userwants to arrive or depart, etc.
The distinction betweenslots and values can be regarded as a special case ofground and focus distinction (Vallduvi 1990).
Updatesspecify the ground and focus of the user utterances.For example, the utterance Ik wil niet vandaag maarmorgen naar Almere (literally: "I want not today buttomorrow to Almere") yields the following update:(4) user .wants .
( ( \[# today\ ]  ; \[ !
tomorrow\ ]  ) ;des t inat ion  .place.
town.
a lmere)An important property of this update language is thatit allows encoding of speech-act information (v. Noordet al 1997).
The "#" in the update means that theinformation between the square brackets (representingthe focus of the user-utterance) must be retracted,while the "!"
denotes the corrected information.This update language is used to semanticallyenrich the syntactic nodes of the OVIS trees by meansof the following annotation convention:?
Every meaningful lexical node is annotated with aslot and/or value from the update language whichrepresents the meaning of the lexical item.?
Every meaningful non-lexical node is annotatedwith a formula schema which indicates how itsmeaning representation can be put together out ofthe meaning representations a signed to its daughternodes.In the examples below, these schemata use thevariable dl  to indicate the meaning of the leftmostdaughter constituent, d2 to indicate the meaning ofthe second daughter node constituent, etc.
Forinstance, the full (syntactic and semantic) annotationfor the above sentence Ik wil niet vandaag maarmorgen naar Almere is given in figure (5).Note that the top-node meaning of (5) iscompositionally built up out of the meanings of itssub-constituents.
Substituting the meaning represen-tations into the corresponding variables yields theupdate expression (4).
The OVIS annotations are incontrast with other corpora and systems (e.g.
Miller etal.
1996), in that our annotation convention exploitsthe Principle of Compositionality of Meaning.
3(5)Sdl.d2~ V PPER d 1 .d2uir v / ~ ~ ~ M pik wantsfwil MP MPMP CON MP P NP/ ~  !
tomorrow destination,place town.almereI I I IADV MP maar rnorgen naar almere# todayI Iniet vaMaagFigure (6) gives an example of the ERROR categoryfor the annotation of the ill-formed sentence VanVoorburg naar van Venlo naar Voorburg ("FromVoorburg to from Venlo to Voorburg"):(6)MPERRORI(dl;d2) MPdl.d2MP(dl;d2)/ destinaiion.place P NP P NP ,aar ?rigin'place towlvenhorigi.place town.v0orburg\] van venlovan worburgMPP NP destinTon.place l w,.\]00rbur~naar tvorburgNote that the ERROR category has no semanticannotation; in the top-node semantics of Van Voorburg3 To maintain our annotation convention in the face ofphenomena such as non-standard quantifier scope ordiscontinuous constituents may create complications in thesyntactic or semantic analyses assigned to certainsentences and their constituents.
It is therefore not clear yetwhether our current treatment ought to be viewed ascompletely general, or whether a more sophisticatedtreatment in the vein of van den Berg et al (1994) should beworked out.140naar van Venlo naar Voorburg, the meaning of thefalse start Van Voorburg naar is thus absent:(7) (or ig in.place.town.venlo ;des tination, place, town.
voorburg )The manual annotation of 10,000 OVIS utterancesmay seem a laborious and error-prone process.
In orderto expedite this task, a flexible and powerfulannotation workbench (SEMTAGS) was developed byBonnema (1996).
SEMTAGS is a graphical interface,written in C using the XVIEW toolkit.
It offers allfunctionality needed for examining, evaluating, andediting syntactic and semantic analyses.
SEMTAGS ismainly used for correcting the output of the DOPparser.
After the first 100 OVIS utterances wereannotated and checked by hand, the parser used thesubtrees of these annotations to produce analyses forthe next 100 OVIS utterances.
These new analyseswere checked and corrected by the annotator usingSEMTAGS, and were added to the total set ofannotations.
This new set of 200 analyses was thenused by the DOP parser to predict the analyses for anext subset of OVIS utterances.
In this incremental,bootstrapping way, 10,000 OVIS utterances wereannotated in approximately 600 hours (supervisionincluded).
For further information on OVIS and how toobtain the corpus, see http://earth.let.uva.nl/-rens.3.
Using the OVIS corpus for data-orientedsemantic analysisAn important advantage of a corpus annotatedaccording to the Principle of Compositionality ofMeaning is that the subtrees can directly be used byDOP for computing syntactic/semantic representationsfor new utterances.
The only difference is that we nowhave composite labels which do not only containsyntactic but also semantic information.
By way ofillustration, we show how a representation for theinput utterance lk wil van Venlo naar Almere ("I wantfrom Venlo to Almere") can be constructed out ofsubtrees from the trees in figures (5) and (6):(8)S o MPdl.d2 (dl;d2)PER VP MPuser d I ,d2 d I .d2ik V MP p NPwants (dl;d2) origin.place town.venloI I Iwi!
van venloMPdl .d2MPdl.d2P NPdestination.place town.almereI Inaar almereSPd2PERuser p(d I ;d2)Vik wantsMP MPdl.d2P NP P NPorigin.place town.venlo destination.place town.almereI I I Ivan venlo near  almerewhich yields the following top-node update semantics:(9) user .wants .
( origin, place, town.
venlo ;destination, place, town.
almere)The probability calculations for the semantic DOPmodel are similar to the original DOP model.
That is,the probability of a subtree t is equal to the number ofoccurrences of t in the corpus divided by the numberof occurrences of all subtrees t' that can be substitutedon the same node as t. The probability of a derivationD = t 1 o ... o t n is the product of the probabilities of itssubtrees t i.
The probability of a parse tree T is the sumof the probabilities of all derivations D that produce T.And the probability of a meaning M and a word stringW is the sum of the probabilities of all parse trees T ofW whose top-node meaning is logically equivalent toM (see Bod et al 1996).As with the most probable parse, the mostprobable meaning M of a word string W cannot becomputed in deterministic polynomial time.
Althoughthe most probable meaning can be estimated byiterative Monte Carlo sampling (see Bod 1995), thecomputation of a sufficiently large number of randomderivations is currently not efficient enough for apractical application.
To date, only the most l ikelyderivation can be computed in near to real-time (by abest-first Viterbi optimization algorithm).
We there-fore assume that most of the probability mass for eachtop-node meaning is focussed on a single derivation.Under this assumption, the most likely meaning of astring is the top-node meaning generated by the mostlikely derivation of that string (see also section 5).4.
Extending DOP to dialogue context:context-dependent subcorporaWe now extend the semantic DOP model to computethe most likely meaning of a sentence given theprevious dialogue.
In general, the probability of a top-node meaning M and a particular word string W i givena dialogue-context Ci = Wi - l ,  Wi-2 ... WI is given byP(M, W i I Wi- l ,  Wi-2 ... WI).Since the OVIS user utterances are typically answersto previous system questions, we assume that themeaning of a word string W i does not depend on thefull dialogue context but only on the previous(system) question Wi.
l .
Under this assumption,P(M, W i l Ci) = P(M,W i I Wi_l)For DOP, this formula means that the updatesemantics of a user utterance W i is computed on thebasis of the subcorpus which contains all OVISutterances (with their annotations) that are answers tothe system question Wi_ 1.
This gives rise to thefollowing interesting model for dialogue processing:each system question triggers a context-dependentdomain (a subcorpus) by which the user answer isanalyzed and interpreted.
Since the number ofdifferent system questions is a small closed set (seeVeldhuijzen van Zanten 1996), we can create off-linefor each subcorpus the corresponding DOP parser.In OVIS, the following context-dependentsubcorpora can be distinguished:(1) place subcorous: utterances following questionslike From where to where do you want to travel?What is ),our destination ?, etc.
(2) date subcorpus: utterances following questionslike When do you want to travel?, When do you wantto leave from X?, When do you want to arrive in Y?,etc.
(3) time subcorpus: utterances following questionslike At what time do you want to travel?
At what timedo you want to leave f rom X?, At what time do youwant to arrive in Y?, etc.
(4) yes/no subcorpus: utterances following y/n-questions like Did you say that ... ?
Thus you want toarrive at... ?Note that a subcorpus can contain utterances whosetopic goes beyond the previous system question.
Forexample, if the system asks From where to where doyou want to travel?, and the user answers with: FromAmsterdam to Groningen tomorrow morning, then thedate-expression tomorrow morning ends up in theplace-subcorpus.It is interesting to note that this context-sensitive DOP model can easily be generalized todomain-dependent i terpretation: a corpus is clusteredinto subcorpora, where each subcorpus corresponds toa topic-dependent domain.
A new utterance isinterpreted by the domain in which it gets highestprobability.
Since small subcorpora tend to assignhigher probabilities to utterances than largesubcorpora (because relative frequencies of subtreesin small corpora tend to be higher), it follows that alanguage user strives for the smallest, most specificdomain in which the perceived utterance can beanalyzed, thus establishing a most specific commonground.1415.
Interfacing DOP with speechSo far, we have dealt with the estimation of theprobability P(M, W\[ C) of a meaning M and a wordstring W given a dialogue context C. However, inspoken dialogue processing, the word string W is notgiven.
The input for DOP in the OVIS system areword-graphs produced by the speech recognizer (theseword-graphs are generated by our project partners fromthe University of Nijmegen).A word-graph is a compact representation forall sequences of words that the speech recognizerhypothesizes for an acoustic utterance A (see e.g.figure 10).
The nodes of the graph represent points intime, and a transition between two nodes i and j,represents a word w that may have been utteredbetween the corresponding points in time.
Forconvenience we refer to transitions in the word-graphusing the notation <i, j, w>.
The word-graphs areoptimized to eliminate epsilon transitions.
Suchtransitions represent periods of time when the speechrecognizer hypothesizes that no words are uttered.Each transition is associated with an acoustic score.This is the negative logarithm (of base 10) of theacoustic probability P(a I w) for a hypothesized wordw normalized by the length of w. Reconverting theseacoustic scores into their corresponding probabilities,the acoustic probability P(A I W) for a hypothesizedword string W can be computed by the product of theprobabilities associated to each transition in thecorresponding word-graph path.
Figure (10) shows anexample of a simplified word-graph for the utteredsentence lk wil graag vanmorgen aar Leiden ("I'd liketo go this morning to Leiden"):(lO)ik wil graag van Maarn naar Leiden~46.31~ (64.86~ O5.421 196.97~ (121.33~ ~54.751 (11~65~vanmorgen(258.80~The probabilistic interface between DOP and speechword-graphs thus consists of the interface between theDOP probabilities P(M, W IC) and the word-graphprobabilities P(A I W) so as to compute the probabilityP(M, A I C) and argmaxM P(M, A I C).
We start byrewriting P(M, A I C) as:P(M,A IC) = ~"wP(M,W, A IC)= ~w P(M, W I C) ?
P(A I M, W, C)The probability P(M, W IC)  is computed by thedialogue-sensitive DOP model as explained in theprevious section.
To estimate the probabilityP(A IM,  W, C) on the basis of the informationavailable in the word-graphs, we must make thefollowing independence assumption: the acousticutterance A depends only on the word string W, and142not on its context C and meaning M (cf.
Bod & Scha1994).
Under this assumption:P(M,A IC) = ~wP(M,  WIC) '  P(A IW)To make fast computation feasible, we furthermoreassume that most of the probability mass for eachmeaning and acoustic utterance is focused on a singleword string W (this will allow for efficient Viterbi bestfirst search):P(M,A IC) = P(M, WIC) .
P(A IW)Thus, the probability of a meaning M for an acousticutterance A given a context C is computed by theproduct of the DOP probability P(M, W I C) and theword-graph probability P(A I W).As to the parsing of word-graphs, it is well-known that parsing algorithms for word strings caneasily be generalized to word-graphs (e.g.
van Noord1995).
For word strings, the initialization of the chartusually consists of entering each word w i into chartentry <i, i+1>.
For word-graphs, a transition <i,j, w>corresponds to a word w between positions i and jwhere j is not necessarily equal to i+1 as is the casefor word strings (see figure I0).
It is thus easy to seethat for word-graphs the initialization of the chartconsists of entering each word w from transition< i , j ,  w> into chart entry <i , j>.
Next, parsingproceeds with the subtrees that are triggered by thedialogue context C (provided that all subtrees areconverted into equivalent rewrite rules -- see Bod1992, Sima'an 1995).
The most likely derivation iscomputed by a bottom-up best-first CKY parseradapted to DOP (Sima'an 1995, 1997).
This parser hasa time complexity which is cubic in the number ofword-graph nodes and linear in the grammar size.
Thetop-node meaning of the tree resulting from the mostlikely derivation is taken as the best meaning M foran utterance A given context C.6.
Eva luat ionIn our experimental evaluation of DOP we wereinterested in the following questions:(1) Is DOP fast enough for practical spokendialogue understanding?
(2) Can we constrain the OVIS subtrees withoutloosing accuracy?
(3) What is the impact of dialogue context on theaccuracy?For all experiments, we used a random split of the10,000 OVIS trees into a 90% training set and a 10%test set.
The training set was divided up into the foursubcorpora described in section 4, which served tocreate the corresponding DOP parsers.
The 1000 word-graphs for the test set utterances were used as input.For each word-graph, the previous system questionwas known to determine the particular DOP parser.while the user utterances were kept apart.
As to thecomplexity of the word-graphs: the average number oftransitions per word is 4.2, and the average number ofwords per word-graph path is 4.6.
All experiments wererun on an SGI Indigo with a MIPS RI0000 processorand 640 Mbyte of core memory,To establish the semantic accuracy of thesystem, the best meanings produced by the DOPparser were compared with the meanings in the testset.
Besides an exact match metric, we also used amore fine-grained evaluation for the semanticaccuracy.
Following the proposals in Boros et al(1996) and van Noord et al (1997), we translatedeach update meaning into a set of semantic units,where a unit is triple <Communicat iveFunct ion ,Slot, Value>.
For instance, the next exampleuser.
wants, travel,  des t inat ion.
( \[# place, town.a lmere\]  ;\[ !
place, town.a lkmaar\ ]  )translates as:<denial,  des t inat ion  town, a lmere><correct ion,  dest inat ion_town,  a lkmaar>Both the updates in the OVIS test set and the updatesproduced by the DOP parser were translated intosemantic units of the form given above.
The semanticaccuracy was then evaluated in three different ways:(1) match, the percentage of updates which wereexactly correct (i.e.
which exactly matched theupdates in the test set); (2) precision, the number ofcorrect semantic units divided by the number ofsemantic units which were produced; (3) recall, thenumber of correct semantic units divided by thenumber of semantic units in the test set.As to question (1), we already suspect that it is notefficient to use all OVIS subtrees.
We thereforeperformed experiments with versions of DOP wherethe subtree collection is restricted to subtrees with acertain maximum depth.
The following table shows forfour different maximum depths (where the maximumnumber of frontier words is limited to 3), the numberof subtree types in the training set, the semanticaccuracy in terms of match, precision and recall (aspercentages), and the average CPU time per word-graph in seconds.subtree- semantic accuracy#subtrees CPU timedepth match precision recall1 3191 76.2 79.4 82.1 0.212 10545 78.5 83.0 84.3 0.863 32140 79.8 84.7 86.2 2.764 64486 80.6 85.8 86.9 6.03Table 1: Experimental results on OVIS word-graphsThe experiments how that at subtree-depth 4 thehighest accuracy is achieved, but that only forsubtree-depths I and 2 are the processing times fastenough for practical applications.
Thus there is atrade-off between efficiency and accuracy: theefficiency deteriorates if the accuracy improves.
Webelieve that a match of 78.5% and a correspondingprecision and recall of resp.
83.0% and 84.3% (for thefast processing times at depth 2) is promising enoughfor further esearch.
Moreover, by testing DOP directlyon the word strings (without the word-graphs), a matchof 97.8% was achieved.
This shows that linguisticambiguities do not play a significant role in thisdomain.
The actual problem are the ambiguities in theword-graphs (i.e.
the multiple paths).Secondly, we are concerned with the question as towhether we can impose constraints on the subtreesother than their depth, in such a way that the accuracydoes not deteriorate and perhaps even improves.
Toanswer this question, we kept the maximal subtree-depth constant at 3, and employed the followingconstraints:?
Eliminating once-occurring subtrees: this led to aconsiderable decrease for all metrics; e.g.
matchdecreased from 79.8% to 75.5%.?
Restricting subtree lexicalization: restricting themaximum number of words in the subtree frontiersto resp.
3, 2 and 1, showed a consistent decrease insemantic accuracy similar to the restriction of thesubtree depth in table 1.
The match dropped from79.8% to 76.9% if each subtree was lexicalizedwith only one word.?
Eliminating subtrees with only non-head words:this led also to a decrease in accuracy; the moststringent metric decreased from 79.8% to 77.1%.Evidently, there can be important relations in OVISthat involve non-head words.Finally, we are interested in the impact of dialoguecontext on semantic accuracy.
To test this, weneglected the previous system questions and createdone DOP parser for the whole training set.
Thesemantic accuracy metric match dropped from 79.8%to 77.4% (for depth 3).
Moreover, the CPU time persentence deteriorated by a factor of 4 (which ismainly due to the fact that larger training sets yieldslower DOP parsers).The following result nicely illustrates how thedialogue context can contribute to better predictionsfor the correct meaning of an utterance.
In parsing theword-graph corresponding to the acoustic utteranceDonderdag acht februari ("Thursday eight February"),the DOP model without dialogue context assignedhighest probability to a derivation yielding the wordstring Dordrecht acht februari and its meaning.
Theuttered word Donderdag was thus interpreted as thetown Dordrecht which was indeed among the otherhypothesized words in the word-graph.
If  the DOPmodel took into account the dialogue context, theprevious system question When do you want to leave?was known and thus triggered the subtrees from thedate-subcorpus only, which now correctly assigned the143highest probability to Donderdag acht februari and itsmeaning, rather than to Dordrecht acht februari.7.
ConclusionsWe showed how the DOP model can be used forefficient and robust processing of spoken input in theOVIS spoken dialogue system.
The system wedescribed uses syntactical ly and semantical lyanalyzed subtrees from the OVIS corpus to computefrom an input word-graph the best utterance togetherwith its meaning.
We showed how dialogue context isintegrated by dividing up the OVIS corpus intocontext-dependent subcorpora.
Each system questiontriggers a subcorpus by which the user utterance isanalyzed and interpreted.Efficiency was achieved by computing themost probable derivation rather than the most probableparse, and by restricting the depth and lexicalizationof the OVIS subtrees.
Robustness was achieved by theshallow syntactic/semantic annotations, including theuse of the productive ERROR label for repairs andfalse starts.
The experimental evaluation showed thatDOP's blending of lexical relations with syntactic-semantic structure yields promising results.
Theexperiments also indicated that elimination ofsubtrees diminishes the semantic accuracy, evenwhen intuitively unimportant subtrees with only non-head words are discarded.
Neglecting dialogue contextalso diminished the accuracy.As future research, we want to investigatefurther optimization techniques for DOP, includingfinite-state approximations.
We want to enrich theOVIS utterances with discourse annotations, such asco-reference links, in order to cope with anaphoraresolution.
We will also extend the annotations withfeature structures and/or functional structuresassociated with the surface structures o as to dealwith more complex linguistic phenomena (see Bod &Kaplan 1998).AcknowledgmentsWe are grateful to Khalii Sima'an for using his DOPparser, and to Remko Bonnema for using SEMTAGSand the relevant semantic interfaces.
We also thankRemko Bonnema, Ronald Kaplan, Remko Scha andKhalil Sima'an for helpful discussions and comments.The OVIS corpus was annotated by Mike de Kreekand Sascha SchLitz.
This research was supported byNWO, the Netherlands Organization for ScientificResearch (Priority Programme Language and SpeechTechnology).ReferencesH.
Aust, M. Oerder, F. Seide and V. Steinbiss.
1995.
"ThePhilips automatic train timetable information system",Speech Communication, 17 pp 249-262.M.
van den Berg, R. Bod and R. Scha, 1994.
"A Corpus-Based Approach to Semantic Interpretation", ProceedingsNinth Amsterdam Colloquium, Amsterdam, The Netherlands.R.
Bod, 1992.
"A Computational Model of LanguagePerformance: Data Oriented Parsing", Proceedings COLING-92, Nantes, France.R.
Bod, 1995.
Enriching Linguistics with Statistics:Performance Models of Natural Language, ILLC DissertationSeries 1995-14, University of Amsterdam.R.
Bod and R. Scha, 1994.
"Prediction and Disambiguationby means of Data-Oriented Parsing", Proceedings TwenteWorkshop on Language Technology (TWLT8), Twente, TheNetherlands.R.
Bod, R. Bonnema nd R. Scha, 1996.
"A Data-OrientedApproach to Semantic Interpretation", Proceedings Work-shop on Corpus-Oriented Semantic Analysis, ECA1-96,Budapest, Hungary.R.
Bod and R. Kaplan, 1998.
"A Probabilistic Corpus-DrivenModel for Lexical-Functional Analysis", this proceedings.R.
Bonnema, 1996.
Data-Oriented Semantics, Master'sThesis, Department of Computational Linguistics, Universityof Amsterdam, The Netherlands.R.
Bonnema, R. Bod and R. Scha, 1997.
"A DOP Model forSemantic Interpretation", Proceedings ACL/EACL-97,Madrid, Spain.M.
Boros et al 1996.
"Towards understanding spontaneousspeech: word accuracy vs. concept accuracy."
ProceedingsICSLP'96, Philadelphia (PA).E.
Charniak, 1996.
"Tree-bank Grammars", ProceedingsAAAI-96, Menlo Park (Ca).J.
Goodman, 1996.
"Efficient Algorithms for Parsing the DOPModel", Proceedings Empirical Methods in Natural LanguageProcessing, Philadelphia (PA),J. Goodman, 1998.
Parsing Inside-Out, Ph.D. thesis, HarvardUniversity, Massachusetts.S.
Miller et al 1996.
"A fully statistical approach to naturallanguage interfaces", Proceedings ACL'96, Santa Cruz (Ca.).G.
van Noord, 1995.
"The intersection of finite stateautomata and definite clause grammars", ProceedingsACL'95, Boston, Massachusetts.G.
van Noord, G. Bouma, R. Koeling and M. Nederhof, 1997.Robust Grammatical Analysis for Spoken Dialogue Systems,unpublished manuscript.F.
Pereira and Y. Schabes, 1992.
"Inside-Outside Reestima-tion from Partially Bracketed Corpora", Proceedings ACL'92,Newark, Delaware.M.
Rajman 1995.
"Approche Probabiliste de l'AnalyseSyntaxique", Traitement Automatique d s Langues, 36(1-2).R.
Scha 1992.
"Virtuele Grammatica's en Creatieve Algorit-men", Gramma/77"T 1(1).K.
Sima'an, 1995.
"An optimized algorithm for Data OrientedParsing", In: R. Mitkov and N. Nicolov (eds.
), RecentAdvances inNatural Language Processing 1995, volume 136of Current Issues in Linguistic Theory.
John Benjamins,Amsterdam.K.
Sima'an, 1996.
"Computational Complexity ofProbabilistic Disambiguation by means of Tree Grammars",Proceedings COLING-96, Copenhagen, Denmark.K.
Sima'an, 1997.
"Explanation-Based Learning of Data-Oriented Parsing", in T. Ellison (ed.)
CoNLL97:Computational Natural Language Learning, ACL'97, Madrid,Spain.E.
Vallduvi, 1990.
The Informational Component.
Ph.D.thesis, University of Pennsylvania, PA.G.
Veldhuijzen van Zanten, 1996.
Semantics of updateexpressions.
Technical Report 24.
NWO Priority ProgrammeLanguage and Speech Technology, The Hague.144
