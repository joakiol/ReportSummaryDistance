Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and ComputationalNatural Language Learning, pp.
1093?1102, Prague, June 2007. c?2007 Association for Computational LinguisticsMandarin Part-of-Speech Tagging and Discriminative RerankingZhongqiang Huang11Purdue UniversityWest Lafayette, IN 47907zqhuang@purdue.eduMary P. Harper1,22University of MarylandCollege Park, MD 20742mharper@casl.umd.eduWen WangSRI InternationalMenlo Park, CA 94025wwang@speech.sri.comAbstractWe present in this paper methods to improveHMM-based part-of-speech (POS) taggingof Mandarin.
We model the emission prob-ability of an unknown word using all thecharacters in the word, and enrich the stan-dard left-to-right trigram estimation of wordemission probabilities with a right-to-leftprediction of the word by making use of thecurrent and next tags.
In addition, we utilizethe RankBoost-based reranking algorithmto rerank the N-best outputs of the HMM-based tagger using various n-gram, mor-phological, and dependency features.
Twomethods are proposed to improve the gen-eralization performance of the reranking al-gorithm.
Our reranking model achieves anaccuracy of 94.68% using n-gram and mor-phological features on the Penn ChineseTreebank 5.2, and is able to further improvethe accuracy to 95.11% with the addition ofdependency features.1 IntroductionPart-of-speech (POS) tagging is potentially help-ful for many advanced natural language processingtasks, for example, named entity recognition, pars-ing, and sentence boundary detection.
Much re-search has been done to improve tagging perfor-mance for a variety of languages.
The state-of-the-art systems have achieved an accuracy of 97% forEnglish on the Wall Street Journal (WSJ) corpus(which contains 4.5M words) using various mod-els (Brants, 2000; Ratnaparkhi, 1996; Thede andHarper, 1999).
Lower accuracies have been reportedin the literature for Mandarin POS tagging (Tseng etal., 2005; Xue et al, 2002).
This is, in part, due tothe relatively small size and the different annotationguidelines (e.g., granularity of the tag set) for the an-notated corpus of Mandarin.
Xue at el.
(2002) andTseng at el.
(2005) reported accuracies of 93% and93.74% on CTB-I (Xue et al, 2002) (100K words)and CTB 5.0 (500K words), respectively, each us-ing a Maximum Entropy approach.
The character-istics of Mandarin make it harder to tag than En-glish.
Chinese words tend to have greater POS tagambiguity than English.
Tseng at el.
(2005) reportedthat 29.9% of the words in CTB have more than onePOS assignment compared to 19.8% of the Englishwords in WSJ.
Moreover, the morphological prop-erties of Chinese words complicate the prediction ofPOS type for unknown words.These challenges for Mandarin POS taggingsuggest the need to develop more sophisticatedmethods.
In this paper, we investigate the useof a discriminative reranking approach to in-crease Mandarin tagging accuracy.
Reranking ap-proaches (Charniak and Johnson, 2005; Chen et al,2002; Collins and Koo, 2005; Ji et al, 2006; Roarket al, 2006) have been successfully applied to manyNLP applications, including parsing, named entityrecognition, sentence boundary detection, etc.
Tothe best of our knowledge, reranking approacheshave not been used for POS tagging, possibly dueto the already high levels of accuracy for English,which leave little room for further improvement.However, the relatively poorer performance of ex-isting methods on Mandarin POS tagging makesreranking a much more compelling technique toevaluate.
In this paper, we use reranking to improvetagging performance of an HMM tagger adapted to1093Mandarin.
Hidden Markov models are simple andeffective, but unlike discriminative models, such asMaximum Entropy models (Ratnaparkhi, 1996) andConditional Random Fields (John Lafferty, 2001),they have more difficulty utilizing a rich set of con-ditionally dependent features.
This limitation can beovercome by utilizing reranking approaches, whichare able to make use of the features extracted fromthe tagging hypotheses produced by the HMM tag-ger.
Reranking also has advantages over MaxEntand CRF models.
It is able to use any featuresextracted from entire labeled sentences, includingthose that cannot be incorporated into MaxEnt andCRF models due to inference difficulties.
In addi-tion, reranking methods are able to utilize the infor-mation provided by N-best lists.
Finally, the decod-ing phase of reranking is much simpler.The rest of the paper is organized as follows.
Wedescribe the HMM tagger in Section 2.
We discussthe modifications to better handle unknown words inMandarin and to enrich the word emission probabil-ities through the combination of bi-directional esti-mations.
In Section 3, we first describe the rerankingalgorithm and then propose two methods to improveits performance.
We also describe the features thatwill be used for Mandarin POS reranking in Sec-tion 3.
Experimental results are given in Section 4.Conclusions and future work appear in Section 5.2 The HMM Model2.1 Porting English Tagger to MandarinThe HMM tagger used in this work is a second-order HMM tagger initially developed for Englishby Thede and Harper (1999).
This state-of-the-artsecond-order HMM tagger uses trigram transitionprobability estimations, P (ti|ti?2ti?1), and trigramemission probability estimations, P (wi|ti?1ti).
Letti1 denote the tag sequence t1, ?
?
?
, ti, and wi1 denotethe word sequencew1, ?
?
?
, wi.
The tagging problemcan be formally defined as finding the best tag se-quence ?
(wN1 ) for the word sequence wN1 of lengthN as follows1:?
(wN1 ) = arg maxtN1P (tN1 |wN1 ) = arg maxtN1P (tN1 wN1 )P (wN1 )= arg maxtN1P (tN1 wN1 ) (1)= arg maxtN1?iP (ti|ti?11 wi?11 )P (wi|ti1wi?11 )1We assume that symbols exist implicitly for boundary con-ditions.?
arg maxtN1?iP (ti|ti?2ti?1)P (wi|ti?1ti) (2)The best tag sequence ?
(wN1 ) can be determined ef-ficiently using the Viterbi algorithm.For estimating emission probabilities of unknownwords (i.e., words that do not appear in the train-ing data) in English (and similarly for other inflectedlanguages), a weighted sum of P (ski |ti?1ti) (withk up to four) was used as an approximation, whereski is the suffix of length k of word wi (e.g., s1i isthe last character of word wi).
The suffix informa-tion and three binary features (i.e., whether the wordis capitalized, whether the word is hyphenated, andwhether the word contains numbers) are combinedto estimate the emission probabilities of unknownwords.The interpolation weights for smoothing tran-sition, emission, and suffix probabilities wereestimated using the log-based Thede smoothingmethod (Thede and Harper, 1999) as follows:PThede(n-gram)= ?
(n-gram)PML(n-gram) +(1?
?
(n-gram))PThede((n-1)-gram)where:PML(n-gram) = the ML estimation?
(n-gram) = f(n-gram count)f(x) =loga(x+ 1) + bloga(x+ 1) + (b+ 1)While porting the HMM-based English POS tag-ger to Mandarin is fairly straightforward for wordsseen in the training data, some thought is required tohandle unknown words due to the morphology dif-ferences between the two languages.
First, in Man-darin, there is no capitalization and no hyphenation.Second, although Chinese has morphology, it is notthe same as in English; words tend to contain farfewer characters than inflected words in English, soword endings will tend to be short, say one or twocharacters long.
Hence, in our baseline model (de-noted HMM baseline), we simply utilize word end-ings of up to two characters in length along with abinary feature of whether the word contains num-bers or not.
In the next two subsections, we describetwo ways in which we enhance this simple HMMbaseline model.10942.2 Improving the Mandarin Unknown WordModelChinese words are quite different from Englishwords, and the word formation process for Chinesewords can be quite complex (Packard, 2000).
In-deed, the last characters in a Chinese word are, insome cases, most informative of the POS type, whilefor others, it is the characters at the beginning.
Fur-thermore, it is not uncommon for a character in themiddle of a word to provide some evidence for thePOS type of the word.
Hence, we chose to employa rather simple but effective method to estimate theemission probability, P (wi|ti?1, ti), of an unknownword, wi.
We use the geometric average2 of theemission probability of the characters in the word,i.e., P (ck|ti?1, ti) with ck being the k-th characterin the word.
Since some of the characters in wi maynot have appeared in any word tagged as ti in thatcontext in the training data, only characters that areobserved in this context are used in the computationof the geometric average, as shown below:P (wi|ti?1, ti) = n?
?ck?wi,P (ck|ti?1,ti)6=0P (ck|ti?1, ti) (3)wheren = |{ck ?
wi|P (ck|ti?1, ti) 6= 0}|2.3 Bi-directional Word Probability EstimationIn Equation 2, the word emission probabilityP (wi|ti?1ti) is a left-to-right prediction that de-pends on the current tag ti associated with wi, aswell as its previous tag ti?1.
Although the interac-tion between wi and the next tag ti+1 is captured tosome extent when ti+1 is generated by the model,this implicit interaction may not be as effective asadding the information more directly to the model.Hence, we chose to apply the constraint explicitly inour HMM framework by replacing P (wi|ti?1ti) inEquation 2 with P ?
(wi|ti?1ti)P 1??
(wi|titi+1) forboth known and unknown words, with ?
(wN1 ) deter-mined by:?
(wN1 ) = arg maxtN1?i(P (ti|ti?2ti?1)?P?(wi|ti?1ti)P1??
(wi|titi+1)) (4)2Based on preliminary testing, the geometric average pro-vided greater tag accuracy than the arithmetic average.This corresponds to a mixture model of two genera-tion paths, one from the left and one from the right,to approximate ?
(wN1 ) in Equation 1 in a differentway.?
(wN1 ) = arg maxtN1P (tN1 wN1 )= arg maxtN1P (tN1 )P (wN1 |tN1 )P (tN1 ) ?
?iP (ti|ti?1ti?2)P (wN1 |tN1 ) = P?
(wN1 |tN1 )P1??
(wN1 |tN1 )??iP?(wi|ti?1ti)P1??
(wi|titi+1)In this case, the decoding process involves thecomputation of three local probabilities, i.e.,P (ti|ti?2ti?1), P (wi|ti?1ti), and P (wi|titi+1).By using a simple manipulation that shifts thetime index of P (wi|titi+1) in Equation 4 by twotime slices3 (i.e., by replacing P (wi|titi+1) withP (wi?2|ti?2ti?1)), we are able to compute ?
(wN1 )in Equation 4 with the same asymptotic time com-plexity of decoding as in Equation 2.3 Discriminative RerankingIn this section, we describe our use of theRankBoost-based (Freund and Schapire, 1997; Fre-und et al, 1998) discriminative reranking approachthat was originally developed by Collins and Koo(2005) for parsing.
It provides an additional avenuefor improving tagging accuracy, and also allows usto investigate the impact of various features on Man-darin tagging performance.
The reranking algorithmtakes as input a list of candidates produced by someprobabilistic model, in our case the HMM tagger,and reranks these candidates based on a set of fea-tures.
We first introduce Collins?
reranking algo-rithm in Subsection 3.1, and then describe two mod-ifications in Subsections 3.2 and 3.3 that were de-signed to improve the generalization performance ofthe reranking algorithm for our POS tagging task.The reranking features that are used for POS taggingare then described in Subsection 3.4.3.1 Collins?
Reranking AlgorithmFor training the reranker for the POS tagging task,there are n sentences {si : i = 1, ?
?
?
, n} each withni candidates {xi,j : j = 1, ?
?
?
, ni} along with3Replacing P (wi|titi+1) with P (wi?1|ti?1ti) also givesthe same solution.1095the log-probability L(xi,j) produced by the HMMtagger.
Each tagging candidate xi,j in the trainingdata has a ?goodness?
score Score(xi,j) that mea-sures the similarity between the candidate and thegold reference.
For tagging, we use tag accuracyas the similarity measure.
Without loss of general-ity, we assume that xi,1 has the highest score, i.e.,Score(xi,1) ?
Score(xi,j) for j = 2, ?
?
?
, ni.
Tosummarize, the training data consists of a set of ex-amples {xi,j : i = 1, ?
?
?
, n; j = 1, ?
?
?
, ni}, eachalong with a ?goodness?
score Score(xi,j) and alog-probability L(xi,j).A set of indicator functions {hk : k = 1, ?
?
?
,m}are used to extract binary features {hk(xi,j) : k =1, ?
?
?
,m} on each example xi,j .
An example of anindicator function for POS tagging is given below:h2143(x) = 1 ifx contains n-gram ?go/VV to?0 otherwiseEach indicator function hk is associated with aweight parameter ?k which is real valued.
In ad-dition, a weight parameter ?0 is associated withthe log-probability L(xi,j).
The ranking func-tion of candidate xi,j is defined as ?0L(xi,j) +m?k=1?khk(xi,j).The objective of the training process is to set theparameters ??
= {?0, ?1, ?
?
?
, ?m} to minimize thefollowing loss function Loss(??)
(which is an upperbound on the training error):Loss(??)
=?ini?j=2Si,je?Mi,j(??
)where Si,j is the weight function that gives the im-portance of each example, and Mi,j(??)
is the mar-gin:Si,j = Score(xi,1)?
Score(xi,j)Mi,j(??)
= ?0(L(xi,1)?
L(xi,j)) +m?k=1?k(hk(xi,1)?
hk(xi,j))All of the ?i?s are initially set to zero.
The valueof ?0 is determined first to minimize the loss func-tion and is kept fixed afterwards.
Then a greedy se-quential 4 optimization method is used in each itera-tion (i.e., a boosting round) to select the feature that4Parallel optimization algorithms exist and have comparableperformance according to (Collins et al, 2002).has the most impact on reducing the loss functionand then update its weight parameter accordingly.For each k ?
{1, ?
?
?
,m}, (hk(xi,1)?
hk(xi,j)) canonly take one of the three values: +1, -1, or 0.
Thusthe training examples can be divided into three sub-sets with respect to k:A+k = {(i, j) : (hk(xi,1)?
hk(xi,j)) = +1}A?k = {(i, j) : (hk(xi,1)?
hk(xi,j)) = ?1}A0k = {(i, j) : (hk(xi,1)?
hk(xi,j)) = 0}The new loss after adding the update parameter ?to the parameter ?k is shown below:Loss(?
?, k, ?)
=?(i,j)?A+kSi,je?Mi,j(??)??
+?(i,j)?A?kSi,je?Mi,j(??)+?
+?(i,j)?A0kSi,je?Mi,j(??
)= e?
?W+k + e?W?k +W0kThe best feature/update pair (k?, ??)
that minimizesLoss(?
?, k, ?)
is determined using the following for-mulas:k?
= arg maxk????
?W+k ??W?k????
(5)??
=12logW+k?W?k?
(6)The update formula in Equation 6 is problematicwhen either W+k?
or W?k?
is zero.
W+k is zero if hknever takes on a value 1 for any xi,1 with value 0 ona corresponding xi,j for j = 2, ?
?
?
, ni (and similarlyfor W?k ).
Collins introduced a smoothing parameter to address this problem, resulting in a slight modi-fication to the update formula:??
=12logW+k?
+ ZW?k?
+ Z(7)The value of  plays an important role in this for-mula.
If  is set too small, the smoothing factor Zwould not prevent setting ??
to a potentially overlylarge absolute value, resulting in over-fitting.
If  isset too large, then the opposite condition of under-training could result.
The value of  is determinedbased on a development set.10963.2 Update OnceCollins?
method allows multiple updates to theweight of a feature based on Equations 5 and 7.
Wefound that for those features for which either W+k orW?k equals zero, the update formula in Equation 7can only increase their weight (in absolute value) inone direction.
Although these features are strongand useful, setting their weights too large can be un-desirable in that it limits the use of other features forreducing the loss.Based on this analysis, we have developed andevaluated an update-once method, in which we usethe update formula in Equation 7 but limit weightupdates so that once a feature is selected on a cer-tain iteration and its weight parameter is updated,it cannot be updated again.
Using this method, theweights of the strong features are not allowed to pre-vent additional features from being considered dur-ing the training phase.3.3 Regularized RerankingAlthough the update-once method may attenuateover-fitting to some extent, it also prevents adjust-ing the value of any weight parameter that is initiallyset too high or too low in an earlier boosting round.In order to design a more sophisticated weight up-date method that allows multiple updates in both di-rections while penalizing overly large weights, wehave also investigated the addition of a regulariza-tion term R(??
), an exponential function of ?
?, to theloss function:RegLoss(??)
=?ini?j=2Si,je?Mi,j(??)
+R(??)R(??)
=m?k=1pk ?
(e?
?k + e?k ?
2)where pk is the penalty weight of parameter ?k.
Thereason that we chose this form of regularization isthat (e?
?k +e?k?2) is a symmetric, monotonicallydecreasing function of |?k|, and more importantly itprovides a closed analytical expression of the weightupdate formula similar to Equations 5 and 6.
Hence,the best feature/update pair for the regularized lossfunction is defined as follows:k?
= arg maxk????
?W+k + pke?
?k ?
?W?k + pke+?k??????
=12logW+k?
+ pk?e??k?W?k?
+ pk?e+?k?There are many ways of choosing pk, the penaltyweight of ?k.
In this paper, we use the values of?
?
(W+k +W?k ) at the beginning of the first iteration(after ?0 is determined) for pk, where ?
is a weight-ing parameter to be tuned on the development set.The regularized weight update formula has many ad-vantages.
It is always well defined no matter whatvalue W+k and W?k take, in contrast to Equation 6.For all features, even in the case when either W+k orW?k equals zero, the regularized update formula al-lows weight updates in two directions.
If the weightis small, W+k and W?k have more impact on deter-mining the weight update direction, however, whenthe weight becomes large, the regularization factorspke??
and pke+?
favor reducing the weight.3.4 Reranking FeaturesA reranking model has the flexibility of incorporat-ing any type of feature extracted from N-best can-didates.
For the work presented in this paper, weexamine three types of features.
For each windowof three word/tag pairs, we extract all the n-grams,except those that are comprised of only one word/tagpair, or only tags, or only words, or do not includeeither the word or tag in the center word/tag pair.These constitute the n-gram feature set.In order to better handle unknown words, we alsoextract the two most important types of morpho-logical features5 that were utilized in (Tseng et al,2005) for those words that appear no more thanseven times (following their convention) in the train-ing set:Affixation features: we use character n-gram pre-fixes and suffixes for n up to 4.
For example,for word/tag pair D?
?/NN (Information-Bag, i.e., folder), we add the following fea-tures: (prefix1, D, NN), (prefix2, D?, NN),(prefix3, D?
?, NN), (suffix1, ?, NN), (suf-fix2,?
?, NN), (suffix3,D?
?, NN).AffixPOS features6: we used the training set tobuild a prefix/POS and suffix/POS dictionaryassociating possible tags with each prefix and5Tseng at el.
also used other morphological features thatrequire additional resources to which we do not have access.6AffixPOS features are somewhat different from the CTB-Morph features used in (Tseng et al, 2005), where a mor-pheme/POS dictionary with the possible tags for all morphemesin the training set was used instead of two separate dictionariesfor prefix and suffix.
AffixPOS features perform slightly betterin our task than the CTB-morph features.1097suffix in the training set.
The AffixPOS fea-tures indicate the set of tags a given affix couldhave.
For the same example D?
?/NN, Doccurred as prefix in both NN and VV words inthe training data.
So we add the following fea-tures based on the prefix D: (prefix, D, NN,1, NN), (prefix, D, VV, 1, NN), and (prefix,D, X, 0, NN) for every tag X not in {NN, VV},where 1 and 0 are indicator values.
Features areextracted in the similar way for the suffix?.The n-gram and morphological features are easyto compute, however, they have difficulty in captur-ing the long distance information related to syntac-tic relationships that might help POS tagging ac-curacy.
In order to examine the effectiveness ofutilizing syntactic information in tagging, we havealso experimented with dependency features that areextracted based on automatic parse trees.
First abracketing parser (the Charniak parser (Charniak,2000) in our case) is used to generate the parsetree of a sentence, then the const2dep tool devel-oped by Hwa was utilized to convert the bracket-ing tree to a dependency tree based on the headpercolation table developed by the second author.The dependency tree is comprised of a set of de-pendency relations among word pairs.
A depen-dency relation is a triple ?word-a, word-b, relation?,in which word-a is governed by word-b with gram-matical relation denoted as relation.
For example,in the sentence ??
(Tibet) ?N(economy) ??
(construction) ??
(achieves) >W(significant)?
(accomplishments)?, one example dependencyrelation is ??
?, ?, mod?.
Given these depen-dency relations, we then extract dependency features(in total 36 features for each relation) by examiningthe POS tags of the words for each tagging candi-date of a sentence.
The relative positions of the wordpairs are also taken into account for some features.For example, if??
and?
in the above sentenceare tagged as VV and NN respectively in one can-didate, then two example dependency features are(dep-1, ?
?, VV, ?, NN, mod), (dep-14, ?
?,VV, NN, right, mod), in which dep-1 and dep-14 arefeature types and right indicates that word-b (??
)is to the right of word-a (?
).4 Experiments4.1 DataThe most recently released Penn Chinese Treebank5.2 (denoted CTB, released by LDC) is used in ourexperiments.
It contains 500K words, 800K char-acters, 18K sentences, and 900 data files, includ-ing articles from the Xinhua news agency (China-Mainland), Information Services Department ofHKSAR (Hongkong), and Sinorama magazine (Tai-wan).
Its format is similar to the English WSJ PennTreebank, and it was carefully annotated.
There are33 POS tags used, to which we add tags to discrim-inate among punctuation types.
The original POStag for punctuation was PU; we created new POStags for each distinct punctuation type (e.g., PU-?
).The CTB corpus was collected during differenttime periods from different sources with a diversityof articles.
In order to obtain a representative splitof training, development, and test sets, we dividethe whole corpus into blocks of 10 files by sortedorder.
For each block, the first file is used for de-velopment, the second file is used for test, and theremaining 8 files are used for training.
Table 1 givesthe basic statistics on the data.
The developmentset is used to determine the parameter ?
in Equa-tion 4, the smoothing parameter  in Equation 7, theweight parameter ?
described in Section 3.3, and thenumber of boosting rounds in the reranking model.In order to train the reranking model, the methodin (Collins and Koo, 2005) is used to prepare theN-best training examples.
We divided the trainingset into 20 chunks, with each chunk N-best taggedby the HMM model trained on the combination ofthe other 19 chunks.
The development set is N-besttagged by the HMM model trained on the trainingset, and the test set is N-best tagged by the HMMmodel trained on the combination of the training setand the development set.Train Dev Test#Sentences 14925 1904 1975#Words 404844 51243 52900Table 1: The basic statistics on the data.In the following subsections, we will first exam-ine the HMM models alone to determine the bestHMM configuration to use to generate the N-bestcandidates, and then evaluate the reranking mod-els.
Finally, we compare our performance with pre-vious work.
In this paper, we use the sign testwith p ?
0.01 to evaluate the statistical significanceof the difference between the performances of twomodels.10984.2 Results of the HMM taggersThe baseline HMM model ported directly from theEnglish tagger, as described in Subsection 2.1, hasan overall tag accuracy of 93.12% on the test set,which is fairly low compared to the 97% accuracyof many state-of-the-art taggers on WSJ for English.By approximating the unknown word emissionprobability using the characters in the word as inEquation 3, the performance of the HMM tagger im-proves significantly to 93.43%, suggesting that char-acters in different positions of a Chinese word helpto disambiguate the word class of the entire word, incontrast to English for which suffixes are most help-ful.Figure 1 depicts the impact of combining the left-to-right and right-to-left word emission models us-ing different weighting values (i.e., ?)
on the devel-opment set.
Note that emission probabilities of un-known words are estimated based on characters us-ing the same ?
for combination.
When ?
= 1.0, themodel uses only the standard left-to-right predictionof words, while when ?
= 0 it uses only the right-to-left estimation.
It is interesting to note that the right-to-left estimation results in greater accuracy than theleft-to-right estimation.
This might be because thereis stronger interaction between a word and its nexttag.
Also as shown in Figure 1, the estimations inthe two directions are complementary to each other,with ?
= 0.5 performing best.
The performance ofthe HMM taggers on the test set is given in Table 2for the best operating point, as well as the two otherextreme operating points to compare the left-to-rightand right-to-left constraints.
Our best HMM taggerfurther improves the tag accuracy significantly from93.43% (?
= 1.0) to 94.01% (?
= 0.5).Figure 1: The accuracy of the HMM tagger on thedevelopment set with various ?
values for combin-ing the word emission probabilities.Overall Known UnknownHMM baseline 93.12% 94.65% 69.08%HMM, ?=1.0 93.43% 94.71% 73.41%HMM, ?=0.0 93.65% 94.88% 74.23%HMM, ?=0.5 94.01% 95.21% 75.15%Table 2: The performance of various HMM taggerson the test set.4.3 Results of the Reranking ModelsThe HMM tagger with the best accuracy (i.e., theone with ?
= 0.5 in Table 2) is used to generatethe N-Best tagging candidates, with a maximum of100 candidates.
As shown in Table 3, a maximum of100-Best provides a reasonable margin for improve-ment in the reranking task.We first test the performance of the rerankingmethods using only the n-gram feature set, whichcontains around 18 million features.
Later, wewill investigate the addition of morphological fea-tures and dependency features.
The smoothingparameter  (for Collins?
method and the update-once method) and the weight parameter ?
(forthe regularization method) both have great im-pact on reranking performance.
We trained vari-ous reranking models with  values of 0.0001 ?
{1, 2.5, 5, 7.5, 10, 25, 50, 75, 100}, and ?
values of{0.1, 0.25, 0.5, 0.75, 1}.
For all these parameter val-ues, 600,000 rounds of iterations were executed onthe training set.
The development set was used todetermine the early stopping point in training.
Ifnot mentioned explicitly, all the results reported arebased on the best parameters tuned on the develop-ment set.1-Best 50-Best 100-Besttrain 93.48% 96.96% 97.13%dev 93.75% 97.68% 97.84%test 93.19% 97.19% 97.35%Table 3: The oracle tag accuracies of the 1-Best, 50-Best, and 100-Best candidates in the training, devel-opment, and test sets for the reranking experiments.Note that the tagging candidates are prepared usingthe method described in Subsection 4.1.Table 4 reports the performance of the best HMMtagger and the three reranking taggers on the test set.All three reranking methods improve the HMM tag-ger significantly.
Also, the update-once and regu-larization methods both outperform Collins?
originaltraining method significantly.1099Overall Known UnknownHMM, ?=0.5 94.01% 95.21% 75.15%Collins 94.38% 95.56% 75.85%Update-once 94.50% 95.67% 76.13%Regularized 94.54% 95.70% 76.48%Table 4: The performance on the test set of theHMM tagger, and the reranking methods using then-gram features.We observed that no matter which value thesmoothing parameter  takes, there are only about10,000 non-zero features finally selected by Collins?original method.
In contrast, the two new methodsselect substantially more features, as shown in Ta-ble 5.
As mentioned before, there are some strongfeatures that only appear in positive or negative sam-ples, i.e., either W+k or W?k equals zero.
Althoughintroducing the smoothing parameter  in Equation 7prevents infinite weight values, the update to thefeature weights is no longer optimal (in terms ofminimizing the error function).
Since the updateis not optimal, subsequent iterations may still fo-cus on these features (and thus ignore other weakerbut informative features) and always increase theirweights in one direction, leading to biased training.The update-once method at each iteration selectsa new feature that has the most impact in reduc-ing the training loss function.
It has the advantageof preventing increasingly large weights from beingassigned to the strong features, enabling the updateof other features.
The regularization method allowsmultiple updates and also penalizes large weights.Once a feature is selected and has its weight updated,no matter how strong the feature is, the weight valueis optimal in terms of the current weights of otherfeatures, so that the training algorithm would chooseanother feature to update.
A previously selected fea-ture may be selected again if it becomes suboptimaldue to a change in the weights of other features.#iterations #features percentCollins 115400 10020 8.68%Update-once 545100 545100 100%Regularized 92500 70131 75.82%Table 5: The number of iterations (for the bestperformance), the number of selected features, andthe percentage of selected features, by Collins?method, the update-once method, and the regular-ization method on the development set.Overall Known UnknownHMM, ?=0.5 94.01% 95.21% 75.15%Collins 94.44% 95.55% 77.05%Update-once 94.68% 95.68% 78.91%Regularized 94.64% 95.71% 77.84%Table 6: The performance on the test set of theHMM tagger and the reranking methods using n-gram and morphological features.We next add morphological features to the n-gramfeatures selected by the reranking methods7.
Ascan be seen by comparing Table 6 to Table 4, mor-phological features improve the tagging accuracy ofunknown words.
It should be noted that the im-provement made by both update-one and regulariza-tion methods is statistically significant over using n-gram features alone; however, the improvement byCollins?
original method is not significant.
This sug-gests that the two new methods are able to utilize agreater variety of features than the original method.We trained several Charniak parsers using thesame method for the HMM taggers to generate auto-matic parse trees for training, development, and testdata.
The update-once method is used to evaluatethe effectiveness of dependency features for rerank-ing, as shown in Table 7.
The parser has an overalltagging accuracy that is greater than that of the bestHMM tagger, but worse than that of the rerankingmodels using n-gram and morphological features.
Itis interesting to note that reranking with the depen-dency features alone improves the tagging accuracysignificantly, outperforming reranking models usingn-gram and morphological features.
This suggeststhat the long distance features based on the syntacticstructure of the sentence are very beneficial for POStagging of Mandarin.
Moreover, n-gram and mor-phological features are complementary to the depen-dency features, with their combination performingthe best.
The n-gram features improve the accuracyon known words, while the morphological featuresimprove the accuracy on unknown words.
The bestaccuracy of 95.11% is an 18% relative reduction inerror compared to the best HMM tagger.7Because the size of the combined feature set of all n-gramfeatures and morphological features is too large to be handledby our server, we chose to add morphological features to then-gram features selected by the reranking methods, and thenretrain the reranking model.1100Overall Known UnknownParser 94.31% 95.57% 74.52%dep 94.93% 96.01% 77.87%dep+ngram 95.00% 96.11% 77.49%dep+morph 94.98% 96.01% 78.79%dep+ngram+morph 95.11% 96.12% 79.32%Table 7: The tagging performance of the parserand the update-once reranking models with depen-dency features and their combination with n-gramand morphological features.4.4 Comparison to Previous WorkSo how is our performance compared to previouswork?
When working on the same training/test data(CTB5.0 with the same pre-processing procedures)as in (Tseng et al, 2005), our HMM model ob-tained an accuracy of 93.72%, as compared to their93.74% accuracy.
Our reranking model8 using n-gram and morphological features improves the ac-curacy to 94.16%.
Note that we did not use all themorphological features as in (Tseng et al, 2005),which would probably provide additional improve-ment.
The dependency features are expected to fur-ther improve the performance, although they are notincluded here in order to provide a relatively faircomparison.5 Conclusions and Future WorkWe have shown that the characters in a word areinformative of the POS type of the entire word inMandarin, reflecting the fact that the individual Chi-nese characters carry POS information to some de-gree.
The syntactic relationship among charactersmay provide further information, which we leaveas future work.
We have also shown that the ad-ditional right-to-left estimation of word emissionprobabilities is useful for HMM tagging of Man-darin.
This suggests that explicit modeling of bi-directional interactions captures more sequential in-formation.
This could possibly help in other sequen-tial modeling tasks.We have also investigated using the reranking al-gorithm in (Collins and Koo, 2005) for the Man-darin POS tagging task, and found it quite effective8Tseng at el.
?s training/test split uses up the entire CTB cor-pus, leaving no development data for tuning parameters.
Inorder to roughly measure reranking performance, we use theupdate-once method to train the reranking model for 600,000rounds with the other parameters tuned in Section 4.
This sac-rifices performance to some extent.in improving tagging accuracy.
The original algo-rithm has a tendency to focus on a small subset ofstrong features and ignore some of the other usefulfeatures.
We were able to improve the performanceof the reranking algorithm by utilizing two differentmethods that make better use of more features.
Bothare simple and yet effective.
The effectiveness of de-pendency features suggests that syntax-based longdistance features are important for improving part-of-speech tagging performance in Mandarin.
Al-though parsing is computationally more demandingthan tagging, we hope to identify related featuresthat can be extracted more efficiently.In future efforts, we plan to extract additionalreranking features utilizing more explicitly the char-acteristics of Mandarin.
We also plan to extend ourwork to speech transcripts for Broadcast News andBroadcast Conversation corpora, and explore semi-supervised training methods for reranking.AcknowledgmentsThis material is based upon work supported bythe Defense Advanced Research Projects Agency(DARPA) under Contract No.
HR0011-06-C-0023.Any opinions, findings and conclusions or recom-mendations expressed in this material are those ofthe authors and do not necessarily reflect the viewsof DARPA.
We gratefully acknowledge the com-ments from the anonymous reviewers.ReferencesThorsten Brants.
2000.
TnT a statistical part-of-speechtagger.
In ANLP, pages 224?231.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminative rerank-ing.
In ACL.Eugene Charniak.
2000.
A maximum-entropy-inspiredparser.
In Proceedings of the first conference on NorthAmerican chapter of the Association for Computa-tional Linguistics, pages 132?139, San Francisco, CA,USA.
Morgan Kaufmann Publishers Inc.John Chen, Srinivas Bangalore, Michael Collins, andOwen Rambow.
2002.
Reranking an n-gram supertag-ger.
In the Sixth International Workshop on Tree Ad-joining Grammars and Related Frameworks.Michael Collins and Terry Koo.
2005.
Discrimina-tive reranking for natural language parsing.
Compu-tational Linguistics, 31(1):25?70.1101Michael Collins, Robert E. Schapire, and Yoram Singer.2002.
Logistic regression, adaboost and bregman dis-tances.
Machine Learning, 48(1):253?285.Yoav Freund and Robert E. Schapire.
1997.
A decision-theoretic generalization of on-line learning and an ap-plication to boosting.
Journal of Computer and SystemSciences, 1(55):119?139.Yoav Freund, Raj Iyer, Robert E. Schapire, and YoramSinger.
1998.
An efficient boosting algorithm forcombining preferences.
In the Fifteenth InternationalConference on Machine Learning.Heng Ji, Cynthia Rudin, and Ralph Grishman.
2006.
Re-ranking algorithms for name tagging.
In HLT/NAACL06 Workshop on Computationally Hard Problems andJoint Inference in Speech and Language Processing.Fernando Pereira John Lafferty, Andrew McCallum.2001.
Conditional random fields: Probabilistic modelsfor segmenting and labeling sequence data.
In ICML.Jerome Packard.
2000.
The Morphology of Chinese.Cambridge University Press.Adwait Ratnaparkhi.
1996.
A maximum entropy modelfor part-of-speech tagging.
In EMNLP.Brian Roark, Yang Liu, Mary Harper, Robin Stewart,Matthew Lease, Matthew Snover, Izhak Shafran, Bon-nie Dorr, John Hale, Anna Krasnyanskaya, and LisaYung.
2006.
Reranking for sentence boundary detec-tion in conversational speech.
In ICASSP.Scott M. Thede and Mary P. Harper.
1999.
A second-order hidden Markov model for part-of-speech tag-ging.
In ACL, pages 175?182.Huihsin Tseng, Daniel Jurafsky, and Christopher Man-ning.
2005.
Morphological features help pos taggingof unknown words across language varieties.
In theFourth SIGHAN Workshop on Chinese Language Pro-cessing.Nianwen Xue, Fu dong Chiou, and Martha Palmer.
2002.Building a large-scale annotated chinese corpus.
InCOLING.1102
