Proceedings of the 2011 Workshop on Biomedical Natural Language Processing, ACL-HLT 2011, pages 10?18,Portland, Oregon, USA, June 23-24, 2011. c?2011 Association for Computational LinguisticsUnsupervised Entailment Detection between Dependency Graph FragmentsMarek ReiComputer LaboratoryUniversity of CambridgeUnited KingdomMarek.Rei@cl.cam.ac.ukTed BriscoeComputer LaboratoryUniversity of CambridgeUnited KingdomTed.Briscoe@cl.cam.ac.ukAbstractEntailment detection systems are generallydesigned to work either on single words, re-lations or full sentences.
We propose a newtask ?
detecting entailment between depen-dency graph fragments of any type ?
whichrelaxes these restrictions and leads to muchwider entailment discovery.
An unsupervisedframework is described that uses intrinsic sim-ilarity, multi-level extrinsic similarity and thedetection of negation and hedged language toassign a confidence score to entailment rela-tions between two fragments.
The final systemachieves 84.1% average precision on a data setof entailment examples from the biomedicaldomain.1 IntroductionUnderstanding that two different texts are semanti-cally similar has benefits for nearly all NLP tasks,including IR, IE, QA and Summarisation.
Similar-ity detection is usually performed either on singlewords (synonymy) or full sentences and paragraphs(paraphrasing).
A symmetric similarity relation im-plies that both elements can be interchanged (syn-onymy and paraphrasing), while directional similar-ity suggests that one fragment can be substituted forthe other but not the opposite (hyponymy and entail-ment).All of these language phenomena can be ex-pressed using a single entailment relation.
For para-phrases and synonyms the relation holds in both di-rections (observe?
notice), whereas entailment andhyponymy are modelled as a unidirectional relation(overexpress ?
express).
Such relations, however,can be defined between text fragments of any sizeand shape, ranging from a single word to a completetext segment.
For example (argues against?
doesnot support; the protein has been implicated?
theprotein has been shown to be involved).We propose a new task ?
detecting entailmentrelations between any kinds of text fragments.
Aunified approach is not expected to perform betterwhen compared to systems optimised only for a spe-cific task (e.g.
recognising entailment between sen-tences), but constructing a common theory to coverall text fragments has important benefits.
A broaderapproach will allow for entailment discovery amonga much wider range of fragment types for which nospecialised systems exist.
In addition, entailment re-lations can be found between different types of frag-ments (e.g.
a predicate entailing an adjunct).
Finally,a common system is much easier to develop and in-tegrate with potential applications compared to hav-ing a separate system for each type of fragment.In this paper we present a unified framework thatcan be used to detect entailment relations betweenfragments of various types and sizes.
The systemis designed to work with anything that can be rep-resented as a dependency graph, including singlewords, constituents of various sizes, text adjuncts,predicates, relations and full sentences.
The ap-proach is completely unsupervised and requires onlya large plain text corpus to gather information forcalculating distributional similarity.
This makes itideal for the biomedical domain where the availabil-ity of annotated training data is limited.
We ap-ply these methods by using a background corpus10of biomedical papers and evaluate on a manuallyconstructed dataset of entailing fragment pairs, ex-tracted from biomedical texts.2 ApplicationsEntailment detection between fragments is a vitalstep towards entailment generation ?
given text T ,the system will have to generate all texts that ei-ther entail T or are entailed by T .
This is motivatedby applications in Relation Extraction, InformationRetrieval and Information Extraction.
For example,if we wish to find all genes that are synthesised inthe larval tissue, the following IE query can be con-structed (with x and y marking unknown variables):(1) x is synthesised in the larval tissueKnown entailment relations can be used to mod-ify the query: (overexpression?
synthesis), (larvalfat body ?
larval tissue) and (the synthesis of x iny ?
x is synthesised in y).
Pattern (2) entails pat-tern (1) and would also return results matching theinformation need.
(2) the overexpression of x in the larval fat bodyA system for entailment detection can automati-cally extract a database of entailing fragments froma large corpus and use them to modify any querygiven by the user.
Recent studies have also inves-tigated how complex sentence-level entailment re-lations can be broken down into smaller consecu-tive steps involving fragment-level entailment (Sam-mons et al, 2010; Bentivogli et al, 2010).
For ex-ample:(3) Text: The mitogenic effects of the B beta chain offibrinogen are mediated through cell surfacecalreticulin.Hypothesis: Fibrinogen beta chain interacts withCRP55.To recognise that the hypothesis is entailed by thetext, it can be decomposed into five separate stepsinvolving text fragments:1.
B beta chain of fibrinogen?
Fibrinogen beta chain2.
calreticulin?
CRP553.
the mitogenic effects of x are mediated through y?y mediates the mitogenic effects of x4.
y mediates the mitogenic effects of x ?
y interactswith x5.
y interacts with x?
x interacts with yThis illustrates how entailment detection betweenvarious smaller fragments can be used to constructan entailment decision between more complicatedsentences.
However, only the presence of these con-structions has been investigated and, to the best ofour knowledge, no models currently exist for auto-mated detection and composition of such entailmentrelations.3 Modelling entailment between graphfragmentsIn order to cover a wide variety of language phe-nomena, a fragment is defined in the following way:Definition 1.
A fragment is any connected subgraphof a directed dependency graph containing one ormore words and the grammatical relations betweenthem.This definition is intended to allow extraction ofa wide variety of fragments from a dependency treeor graph representation of sentences found using anyappropriate parser capable of returning such output(e.g.
Ku?bler et al, 2009).
The definition coverssingle- or multi-word constituents functioning as de-pendents (e.g.
sites, putative binding sites), text ad-juncts (in the cell wall), single- or multi-word pred-icates (* binds to receptors in the airways) and rela-tions (* binds and activates *) including ones with?internal?
dependent slots (* inhibits * at *), some ofwhich may be fixed in the fragment (* induces au-tophosphorylation of * in * cells), and also full sen-tences1.
An example dependency graph and someselected fragments can be seen in Figure 1.Our aim is to detect semantically similar frag-ments which can be substituted for each other in text,resulting in more general or more specific versionsof the same proposition.
This kind of similarity canbe thought of as an entailment relation and we defineentailment between two fragments as follows:1The asterisks (*) are used to indicate missing dependentsin order to increase the readability of the fragment when repre-sented textually.
The actual fragments are kept in graph formand have no need for them.11induce inB61recombinantautophosphorylation of ECKcell intactmod modsubj iobjiobjdobj dobjdobjFigure 1: Dependency graph for the sentence: Recombinant B61 induces autophosphorylation of ECK in intact cells.Some interesting fragments are marked by dotted lines.Definition 2.
Fragment A entails fragment B (A?B) if A can be replaced by B in sentence S and the re-sulting sentence S?
can be entailed from the originalone (S?
S?
).This also requires estimating entailment relationsbetween sentences, for which we use the definitionestablished by Bar-Haim et al (2006):Definition 3.
Text T entails hypothesis H (T ?
H)if, typically, a human reading T would infer that His most likely true.We model the semantic similarity of fragments asa combination of two separate directional similarityscores:1.
Intrinsic similarity: how similar are the com-ponents of the fragments.2.
Extrinsic similarity: how similar are the con-texts of the fragments.To find the overall score, these two similaritymeasures are combined linearly using a weightingparameter ?:Score(A?
B) = ??
IntSim(A?
B)+(1?
?)?
ExtSim(A?
B)In this paper f(A ?
B) designates an asym-metric function between A and B.
When referringonly to single words, lowercase letters (a,b) are used;when referring to fragments of any size, includingsingle words, then uppercase letters are used (A,B).Score(A?
B) is the confidence score that frag-ment A entails fragment B ?
higher score indi-cates higher confidence and 0 means no entailment.IntSim(A?
B) is the intrinsic similarity betweentwo fragments.
It can be any function that comparesthem, for example by matching the structure of onefragment to another, and outputs a similarity score inthe range of [0, 1].
ExtSim(A ?
B) is a measureof extrinsic similarity that compares the contexts ofthe two fragments.
?
is set to 0.5 for an unsuper-vised approach but the effects of tuning this param-eter are further analysed in Section 5.The directional similarity score is first found be-tween words in each fragment, which are then usedto calculate the score between the two fragments.3.1 Intrinsic similarityIntSim(A?
B) is the intrinsic similarity betweenthe two words or fragments.
In order to best captureentailment, the measure should be non-symmetrical.We use the following simple formula for word-levelscore calculation:IntSim(a?
b) =length(c)length(b)where c is the longest common substring for a andb.
This measure will show the ratio of b that is alsocontained in a.
For example:IntSim(overexpress?
expression) = 0.70IntSim(expression?
overexpress) = 0.64The intrinsic similarity function for fragments isdefined using an injective function between compo-nents of A and components of B:IntSim(A?
B) =Mapping(A?
B)|B|where Mapping(A ?
B) is a function that goesthrough all the possible word pairs {(a, b)|a ?A, b ?
B} and at each iteration connects the one12with the highest entailment score, returning the sumof those scores.
Figure 2 contains pseudocodefor the mapping process.
Dividing the value ofMapping(A ?
B) by the number of componentsin B gives an asymmetric score that indicates howwell B is covered by A.
It returns a lower scoreif B contains more elements than A as some wordscannot be matched to anything.
While there are ex-ceptions, it is common that if B is larger than A,then it cannot be entailed by A as it contains moreinformation.while unused elements in A and B dobestScore = 0for a ?
A, b ?
B, a and b are unused doif Score(a?
b) > bestScore thenbestScore = Score(a?
b)end ifend fortotal+ = bestScoreend whilereturn totalFigure 2: Pseudocode for mapping between two frag-mentsThe word-level entailment score Score(a ?
b)is directly used to estimate the entailment score be-tween fragments, Score(A ?
B).
In this case weare working with two levels ?
fragments which inturn consist of words.
However, this can be extendedto a truly recursive method where fragments consistof smaller fragments.3.2 Extrinsic similarityThe extrinsic similarity between two fragments orwords is modelled using measures of directional dis-tributional similarity.
We define a context relation asa tuple (a, d, r, a?)
where a is the main word, a?
is aword connected to it through a dependency relation,r is the label of that relation and d shows the direc-tion of the relation.
The tuple f : (d, r, a?)
is referredto as a feature of a.To calculate the distributional similarity betweentwo fragments, we adopt an approach similar toWeeds et al (2005).
Using the previous notation,(d, r, a?)
is a feature of fragment A if (d, r, a?)
is afeature for a word which is contained inA.
The gen-eral algorithm for feature collection is as follows:1.
Find the next instance of a fragment in thebackground corpus.2.
For each word in the fragment, find dependencyrelations which connect to words not containedin the fragment.3.
Count these dependency relations as distribu-tional features for the fragment.For example, in Figure 1 the fragment (* induces* in *) has three features: (1, subj, B61), (1, dobj,autophosphorylation) and (1, dobj, cell).The BioMed Central2 corpus of full papers wasused to collect distributional similarity features foreach fragment.
1000 papers were randomly selectedand separated for constructing the test set, leaving70821 biomedical full papers.
These were tokenisedand parsed using the RASP system (Briscoe et al,2006) in order to extract dependency relations.We experimented with various schemes for fea-ture weighting and found the best one to be a varia-tion of Dice?s coefficient (Dice, 1945), described byCurran (2003):wA(f) =2P (A, f)P (A, ?)
+ P (?, f)where wA(f) is the weight of feature f for fragmentA, P (?, f) is the probability of the feature appear-ing in the corpus with any fragment, P (A, ?)
is theprobability of the fragment appearing with any fea-ture, and P (A, f) is the probability of the fragmentand the feature appearing together.Different measures of distributional similarity,both symmetrical and directonal, were also testedand ClarkeDE (Clarke, 2009) was used for the fi-nal system as it achieved the highest performance ongraph fragments:ClarkeDE(A?
B) =?f?FA?FBmin(wA(f), wB(f))?f?FAwA(f)where FA is the set of features for fragmentA andwA(f) is the weight of feature f for fragment A. Itquantifies the weighted coverage of the features ofAby the features of B by finding the sum of minimumweights.2http://www.biomedcentral.com/info/about/datamining/13The ClarkeDE similarity measure is designed todetect whether the features of A are a proper subsetof the features of B.
This works well for findingmore general versions of fragments, but not whencomparing fragments which are roughly equal para-phrases.
As a solution we constructed a new mea-sure based on the symmetrical Lin measure (Lin,1998).LinD(A?
B) =?f?FA?FB[wA(f) + wB(f)]?f?FAwA(f) +?f?FA?FBwB(f)Compared to the original, the features ofB whichare not found in A are excluded from the scorecalculation, making the score non-symmetrical butmore balanced compared to ClarkeDE.
We ap-plied this for word-level distributional similarity andachieved better results than with other common sim-ilarity measures.The LinD similarity is also calculated betweenfragment levels to help detect possible paraphrases.If the similarity is very high (greater than 85%), thena symmetric relationship between the fragments isassumed and the value of LinD is used as ExtSim.Otherwise, the system reverts to the ClarkeDEmeasure for handling unidirectional relations.3.3 Hedging and negationLanguage constructions such as hedging and nega-tion typically invert the normal direction of an en-tailment relation.
For example, (biological discov-ery?
discovery) becomes (no biological discovery?
no discovery) and (is repressed by?
is affectedby) becomes (may be repressed by?
is affected by).Such cases are handled by inverting the directionof the score calculation if a fragment is found tocontain a special cue word that commonly indicateshedged language or negation.
In order to find thelist of indicative hedge cues, we analysed the train-ing corpus of CoNLL 2010 Shared Task (Farkas etal., 2010) which is annotated for speculation cuesand scopes.
Any cues that occurred less than 5 timesor occurred more often as normal text than as cuewords were filtered out, resulting in the followinglist:(4) suggest, may, might, indicate that, appear,likely, could, possible, whether, would, think,seem, probably, assume, putative, unclear,propose, imply, possiblyFor negation cues we used the list collected byMorante (2009):(5) absence, absent, cannot, could not, either,except, exclude, fail, failure, favor over,impossible, instead of, lack, loss, miss,negative, neither, nor, never, no, no longer,none, not, rather than, rule out, unable, withthe exception of, withoutThis is a fast and basic method for estimatingthe presence of hedging and negation in a fragment.When dealing with longer texts, the exact scope ofthe cue word should be detected, but for relativelyshort fragments the presence of a keyword acts as agood indication of hedging and negation.4 EvaluationA ?pilot?
dataset was created to evaluate differententailment detection methods between fragments3.In order to look for valid entailment examples, 1000biomedical papers from the BioMed Central full-textcorpus were randomly chosen and analysed.
Wehypothesised that two very similar sentences orig-inating from the same paper are likely to be moreand less general versions of the same proposition.First, the similarities between all sentences in a sin-gle paper were calculated using a bag-of-words ap-proach.
Then, ten of the most similar but non-identical sentence pairs from each paper were pre-sented for manual review and 150 fragment pairswere created based on these sentences, 100 of whichwere selected for the final set.When applied to sentence-level entailment extrac-tion, similar methods can suffer from high lexicaloverlap as sentences need to contain many match-ing words to pass the initial filter.
However, for theextraction of entailing fragments most of the match-ing words are discarded and only the non-identicalfragments are stored, greatly reducing the overlapproblem.
Experiments in Section 5 demonstratethat a simple bag-of-words approach performs ratherpoorly on the task, confirming that the extractionmethod produces a diverse selection of fragments.3http://www.cl.cam.ac.uk/~mr472/entailment/14Two annotators assigned a relation type to can-didate pairs based on how well one fragment canbe substituted for the other in text while preservingmeaning (A ?
B, A ?
B, A ?
B or A 6= B).Cohen?s Kappa between the annotators was 0.88, in-dicating very high agreement.
Instances with dis-agreement were then reviewed and replaced for thefinal dataset.Each fragment pair has two binary entailment de-cisions (one in either direction) and the set is evenlybalanced, containing 100 entailment and 100 non-entailment relations.
An example sentence with thefirst fragment is also included.
Fragment sizes rangefrom 1 to 20 words, with the average of 2.86 words.The system assigns a score to each entailment re-lation, with higher values indicating higher confi-dence in entailment.
All the relations are rankedbased on their score, and average precision (AP) isused to evaluate the performance:AP =1RN?i=1E(i)?
CorrectUpTo(i)iwhere R is the number of correct entailment re-lations, N is the number of possible relations inthe test set, E(i) is 1 if the i-th relation is en-tailment in the gold standard and 0 otherwise, andCorrectUpTo(i) is the number of correctly re-turned entailment relations up to rank i. Averageprecision assigns a higher score to systems whichrank correct entailment examples higher in the list.As a secondary measure we also report the Break-Even Point (BEP) which is defined as precision atthe rank where precision is equal to recall.
Usingthe previous annotation, this can also be calculatedas precision at rank R:BEP =CorrectUpTo(R)RBEP is a much more strict measure, treating the taskas binary classification and ignoring changes to theranks within the classes.5 ResultsThe test set is balanced, therefore random guessingwould be expected to achieve an AP and BEP of0.5 which can be regarded as the simplest (random)baseline.
Table 1 contains results for two more basicapproaches to the task.
For the bag-of-words (BOW)system, the score of A entailing B is the proportionof words in B that are also contained in A.Scorebow(A?
B) =|{b|b ?
A,B}||{b|b ?
B}|We also tested entailment detection when usingonly the directional distributional similarity betweenfragments as it is commonly done for words.
Whileboth of the systems perform better than random, theresults are much lower than those for more informedmethods.
This indicates that even though there issome lexical overlap between the fragments, it is notenough to make good decisions about the entailmentrelations.System type AP BEPRandom baseline 0.500 0.500BOW 0.657 0.610Distributional similarity 0.645 0.480Table 1: Results for basic approaches.Table 2 contains the results for the system de-scribed in Section 3.
We start with the most basicversion and gradually add components.
Using onlythe intrinsic similarity, the system performs betterthan any of the basic approaches, delivering 0.71 AP.System type AP BEPIntrinsic similarity only 0.710 0.680+ Word ExtSim 0.754 0.710+ Fragment ExtSim 0.801 0.710+ Negation & hedging 0.831 0.720+ Paraphrase check 0.841 0.720Table 2: Results for the system described in Section 3.Components are added incrementally.Next, the extrinsic similarity between words is in-cluded, raising the AP to 0.754.
When the string-level similarity fails, the added directional distri-butional similarity helps in mapping semanticallyequivalent words to each other.The inclusion of extrinsic similarity between frag-ments gives a further increase, with AP of 0.801.The 4.5% increase shows that while fragments are15larger and occur less often in a corpus, their distribu-tional similarity can still be used as a valuable com-ponent to detect semantic similarity and entailment.Checking for negation and hedge cues raises theAP to 0.831.
The performance is already high anda 3% improvement shows that hedging and negationaffect fragment-level entailment and other compo-nents do not manage to successfully capture this in-formation.Finally, applying the fragment-level check forparaphrases with a more appropriate distributionalsimilarity measure, as described in Section 3.2, re-turns an AP of 0.841.
The results of this final con-figuration are significantly different compared to theinitial system using only intrinsic similarity, accord-ing to the Wilcoxon signed rank test at the level of0.05.The formula in Section 3 contains parameter ?which can be tuned to adjust the balance of intrinsicand extrinsic similarity.
This can be done heuristi-cally or through machine learning methods and dif-ferent values can be used for fragments and words.In order to investigate the effects of tuning on thesystem, we tried all possible combinations of ?wordand ?fragment with values between 0 and 1 at incre-ments of 0.05.
Table 3 contains results for some ofthese experiments.
?word ?fragment AP BEP0.5 0.5 0.841 0.720* 0.0 0.656 0.4800.0 1.0 0.813 0.7201.0 1.0 0.765 0.6900.45 0.65 0.847 0.740Table 3: Results of tuning the weights for intrinsic anddistributional similarity.The best results were obtained with ?word = 0.45and ?fragment = 0.65, resulting in 0.847 AP and0.74 BEP.
This shows that parameter tuning can im-prove the results, but the 0.6% increase is modestand a completely unsupervised approach can givecompetitive results.
In addition, the optimal valuesof ?
are close to 0.5, indicating that all four com-ponents (intrinsic and distributional similarities be-tween words and fragments) are all contributing tothe performance of the final system.6 Previous workMost work on entailment has focused on compar-ing sentences or paragraphs.
For example, Haghighiet al (2005) represent sentences as directed depen-dency graphs and use graph matching to measure se-mantic overlap.
This method also compares the de-pendencies when calculating similarity, which sup-ports incorporation of extra syntactic information.Hickl et al (2006) combine lexico-syntactic featuresand automatically acquired paraphrases to classifyentailing sentences.
Lintean and Rus (2009) makeuse of weighted dependencies and word semanticsto detect paraphrases.
In addition to similarity theylook at dissimilarity between two sentences and usetheir ratio as the confidence score for paraphrasing.Lin and Pantel (2001) were one of the first toextend the distributional hypothesis to dependencypaths to detect entailment between relations.
Szpek-tor et al (2004) describe the TEASE method for ex-tracting entailing relation templates from the Web.Szpektor and Dagan (2008) use the distributionalsimilarity of arguments to detect unary template en-tailment, whilst Berant et al (2010) apply it to bi-nary relations in focused entailment graphs.Snow et al (2005) described a basic method ofsyntactic pattern matching to automatically discoverword-level hypernym relations from text.
The use ofdirectional distributional similarity measures to findinference relations between single words is exploredby Kotlerman et al (2010).
They propose new mea-sures based on feature ranks and compare them withexisting ones for the tasks of lexical expansion andtext categorisation.In contrast to current work, each of the ap-proaches described above only focuses on detectingentailment between specific subtypes of fragments(either sentences, relations or words) and optimis-ing the system for a single scenario.
This meansonly limited types of entailment relations are foundand they cannot be used for entailment generationor compositional entailment detection as describedin Section 2.MacCartney and Manning (2008) approachsentence-level entailment detection by breaking theproblem into a sequence of atomic edits linking thepremise to the hypothesis.
Entailment relations arethen predicted for each edit, propagated up through16a syntax tree and then used to compose the result-ing entailment decision.
However, their system fo-cuses more on natural logic and uses a predefined setof compositional rules to capture a subset of validinferences with high precision but low recall.
Italso relies on a supervised classifier and informationfrom WordNet to reach the final entailment decision.Androutsopoulos and Malakasiotis (2010) haveassembled a survey of different tasks and approachesrelated to paraphrasing and entailment.
They de-scribe three different goals (paraphrase recogni-tion, generation and extraction) and analyse variousmethods for solving them.7 ConclusionEntailment detection systems are generally devel-oped to work on specific text units ?
either singlewords, relations, or full sentences.
While this re-duces the complexity of the problem, it can alsolead to important information being disregarded.
Inthis paper we proposed a new task ?
detecting en-tailment relations between any kind of dependencygraph fragments.
The definition of a fragment cov-ers the language structures mentioned above andalso extends to others that have not been fully in-vestigated in the context of entailment recognition(such as multi-word constituents, predicates and ad-juncts).To perform entailment detection between varioustypes of dependency graph fragments, a new sys-tem was built that combines the directional intrin-sic and extrinsic similarities of two fragments toreach a final score.
Fragments which contain hedg-ing or negation are identified and their score cal-culation is inverted to better model the effect onentailment.
The extrinsic similarity is found withtwo different distributional similarity measures, firstchecking for symmetric similarity and then for di-rectional containment of distributional features.
Thesystem was evaluated on a manually constructeddataset of fragment-level entailment relations fromthe biomedical domain and each of the added meth-ods improved the results.Traditionally, the method for entailment recogni-tion is chosen based on what appears optimal forthe task ?
either structure matching or distributionalsimilarity.
Our experiments show that the combina-tion of both gives the best performance for all frag-ment types.
It is to be expected that single words willbenefit more from distributional measures while fullsentences get matched by their components.
How-ever, this separation is not strict and evidence fromboth methods can be used to strengthen the decision.The experiments confirmed that entailment be-tween dependency graph fragments of various typescan be detected in a completely unsupervised set-ting, without the need for specific resources or an-notated training data.
As our method can be appliedequally to any domain and requires only a large plaintext corpus, we believe it is a promising directionfor research in entailment detection.
This can leadto useful applications in biomedical information ex-traction where manually annotated datasets are inshort supply.We have shown that a unified approach can beused to detect entailment relations between depen-dency graph fragments.
This allows for entail-ment discovery among a wide range of fragmenttypes, including ones for which no specialised sys-tems currently exist.
The framework for fragment-level entailment detection can be integrated into var-ious applications that require identifying and rewrit-ing semantically equivalent phrases - for example,query expansion in IE and IR, text mining, sentence-level entailment composition, relation extraction andprotein-protein interaction extraction.ReferencesIon Androutsopoulos and Prodromos Malakasiotis.2010.
A survey of paraphrasing and textual entailmentmethods.
Journal of Artificial Intelligence Research,38(7):135?187.Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, DaniloGiampiccolo, Bernardo Magnini, and Idan Szpektor.2006.
The second pascal recognising textual entail-ment challenge.
In Proceedings of the Second PAS-CAL Challenges Workshop on Recognising TextualEntailment, pages 1?9.
Citeseer.Luisa Bentivogli, Elena Cabrio, Ido Dagan, Danilo Gi-ampiccolo, Medea Lo Leggio, and Bernardo Magnini.2010.
Building Textual Entailment Specialized DataSets: a Methodology for Isolating Linguistic Phenom-ena Relevant to Inference.
In Proceedings of the Sev-enth conference on International Language Resourcesand Evaluation (LREC?10).17Jonathan Berant, Ido Dagan, and Jacob Goldberger.2010.
Global learning of focused entailment graphs.In Proceedings of the 48th Annual Meeting of the Asso-ciation for Computational Linguistics, number Section6, pages 1220?1229.
Association for ComputationalLinguistics.Ted Briscoe, John Carroll, and Rebecca Watson.
2006.The second release of the RASP system.
In Proceed-ings of the COLING/ACL 2006 Interactive Presenta-tion Sessions, number July, pages 77?80, Sydney, Aus-tralia.
Association for Computational Linguistics.Daoud Clarke.
2009.
Context-theoretic semantics fornatural language: an overview.
In Proceedings ofthe Workshop on Geometrical Models of Natural Lan-guage Semantics, number March, pages 112?119.
As-sociation for Computational Linguistics.James Richard Curran.
2003.
From distributional to se-mantic similarity.
Ph.D. thesis, University of Edin-burgh.Lee R. Dice.
1945.
Measures of the amount of ecologicassociation between species.
Ecology, 26(3):297?302.Richa?rd Farkas, Veronika Vincze, Gyo?rgy Mo?ra, Ja`nosCsirik, and Gyo?rgy Szarvas.
2010.
The CoNLL-2010Shared Task: Learning to Detect Hedges and theirScope in Natural Language Text.
In Proceedings ofthe Fourteenth Conference on Computational NaturalLanguage Learning ?
Shared Task, pages 1?12.
As-sociation for Computational Linguistics.Aria D. Haghighi, Andrew Y. Ng, and Christopher D.Manning.
2005.
Robust textual inference via graphmatching.
In Proceedings of the conference on Hu-man Language Technology and Empirical Methods inNatural Language Processing, Morristown, NJ, USA.Association for Computational Linguistics.Andrew Hickl, Jeremy Bensley, John Williams, KirkRoberts, Bryan Rink, and Ying Shi.
2006.
Recog-nizing textual entailment with LCC?s GROUNDHOGsystem.
In Proceedings of the Second PASCAL Chal-lenges Workshop.Lili Kotlerman, Ido Dagan, Idan Szpektor, and MaayanZhitomirsky-Geffet.
2010.
Directional distributionalsimilarity for lexical inference.
Natural Language En-gineering, 16(04):359?389.Sandra Ku?bler, Ryan McDonald, and Joakim Nivre.2009.
Dependency Parsing.
Synthesis Lectures on Hu-man Language Technologies, 2:1?127.Dekang Lin and Patrick Pantel.
2001.
Discovery of infer-ence rules for question-answering.
Natural LanguageEngineering, 7(04):343?360.Dekang Lin.
1998.
Automatic retrieval and cluster-ing of similar words.
In Proceedings of the 17th in-ternational conference on Computational linguistics-Volume 2, pages 768?774.
Association for Computa-tional Linguistics.Mihain C. Lintean and Vasile Rus.
2009.
Para-phrase Identification Using Weighted Dependenciesand Word Semantics.
In Proceedings of the FLAIRS-22, volume 22, pages 19?28.Bill MacCartney and Christopher D. Manning.
2008.Modeling semantic containment and exclusion in natu-ral language inference.
In Proceedings of the 22nd In-ternational Conference on Computational Linguistics-Volume 1, pages 521?528.
Association for Computa-tional Linguistics.Roser Morante.
2009.
Descriptive analysis of negationcues in biomedical texts.
In Proceedings of the Sev-enth International Language Resources and Evalua-tion (LREC10), pages 1429?1436.Mark Sammons, V.G.
Vinod Vydiswaran, and Dan Roth.2010.
Ask not what textual entailment can do foryou...
In Proceedings of the Annual Meeting of the As-sociation of Computational Linguistics (ACL), pages1199?1208.
Association for Computational Linguis-tics.Rion Snow, Daniel Jurafsky, and Andrew Y. Ng.
2005.Learning syntactic patterns for automatic hypernymdiscovery.
In Advances in Neural Information Pro-cessing Systems.Idan Szpektor and Ido Dagan.
2008.
Learning entail-ment rules for unary templates.
In Proceedings of the22nd International Conference on Computational Lin-guistics - COLING ?08, pages 849?856, Morristown,NJ, USA.
Association for Computational Linguistics.Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-tura Coppola.
2004.
Scaling web-based acquisition ofentailment relations.
In Proceedings of EMNLP, vol-ume 4, pages 41?48.Julie Weeds, David Weir, and Bill Keller.
2005.
The dis-tributional similarity of sub-parses.
In Proceedings ofthe ACL Workshop on Empirical Modeling of SemanticEquivalence and Entailment, pages 7?12, Morristown,NJ, USA.
Association for Computational Linguistics.18
