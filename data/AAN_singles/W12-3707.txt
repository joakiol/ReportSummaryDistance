Proceedings of the 3rd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, pages 38?46,Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational LinguisticsSentimantics: Conceptual Spaces forLexical Sentiment Polarity Representation with ContextualityAmitava Das                           Bj?rn Gamb?ckDepartment of Computer and Information ScienceNorwegian University of Science and TechnologySem S?lands vei 7-9, NO-7094 Trondheim, Norwayamitava.santu@gmail.com    gamback@idi.ntnu.noAbstractCurrent sentiment analysis systems rely onstatic (context independent) sentimentlexica with proximity based fixed-pointprior polarities.
However, sentiment-orientation changes with context and theselexical resources give no indication ofwhich value to pick at what context.
Thegeneral trend is to pick the highest one, butwhich that is may vary at context.
Toovercome the problems of the presentproximity-based static sentiment lexicontechniques, the paper proposes a new wayto represent sentiment knowledge in aVector Space Model.
This model can storedynamic prior polarity with varyingcontextual information.
The representationof the sentiment knowledge in theConceptual Spaces of distributionalSemantics is termed Sentimantics.1  IntroductionPolarity classification is the classical problemfrom where the cultivation of Sentiment Analysis(SA) started.
It involves sentiment / opinionclassification into semantic classes such aspositive, negative or neutral and/or other fine-grained emotional classes like happy, sad, anger,disgust,surprise and similar.
However, for thepresent task we stick to the standard binaryclassification, i.e., positive and/or negative.The Concept of Prior Polarity: Sentimentpolarity classification (?The text is positive ornegative??)
started as a semantic orientationdetermination problem: by identifying the semanticorientation of adjectives, Hatzivassiloglou et al(1997) proved the effectiveness of empiricallybuilding a sentiment lexicon.
Turney (2002)suggested review classification by Thumbs Up andThumbs Down, while the concept of prior polaritylexica was firmly established with the introductionof SentiWordNet (Esuli et al, 2004).More or less all sentiment analysis researchersagree that prior polarity lexica are necessary forpolarity classification, and prior polarity lexicondevelopment has been attempted for otherlanguages than English as well, including forChinese (He et al, 2010), Japanese (Torii et al,2010), Thai (Haruechaiyasak et al, 2010), andIndian languages (Das and Bandyopadhyay, 2010).Polarity Classification Using the Lexicon: Highaccuracy for prior polarity identification is veryhard to achieve, as prior polarity values areapproximations only.
Therefore the prior polaritymethod may not excel alone; additional techniquesare required for contextual polaritydisambiguation.
The use of other NLP methods ormachine learning techniques over human producedprior polarity lexica was pioneered by Pang et al(2002).
Several researches then tried syntactic-statistical techniques for polarity classification,reporting good accuracy (Seeker et al, 2009;Moilanen et al, 2010), making the two-stepmethodology (sentiment lexicon followed byfurther NLP techniques) the standard method forpolarity classification.Incorporating Human Psychology: Theexisting reported solutions or available systems arestill far from perfect or fail to meet the satisfactionlevel of the end users.
The main issue may be thatthere are many conceptual rules that governsentiment and there are even more clues (possiblyunlimited) that can convey these concepts fromrealization to verbalization of a human being (Liu,382010).
The most recent trends in prior polarityadopt an approach to sentiment knowledgerepresentation which lets the mental lexicon modelhold the contextual polarity, as in human mentalknowledge representation.Cambria et al (2011) made an importantcontribution in this direction by introducing a newparadigm: Sentic Computing1, in which they use anemotion representation and a Common Sense-based approach to infer affective states from shorttexts over the web.
Grassi (2009) conceived theHuman Emotion Ontology as a high level ontologysupplying the most significant concepts andproperties constituting the centerpiece for thedescription of human emotions.The Proposed Sentimantics: The present paperintroduces the concept of Sentimantics which isrelated to the existing prior polarity concept, butdiffers from it philosophically in terms ofcontextual dynamicity.
It ideologically follows thepath of Minsky (2006), Cambria et al (2011) and(Grassi, 2009), but with a different notion.Sentiment analysis research started years ago,but still the question ?What is sentiment oropinion??
remains unanswered!
It is very hard todefine sentiment or opinion, and to identify theregulating or the controlling factors of sentiment;an analytic definition of opinion might even beimpossible (Kim and Hovy, 2004).
Moreover, noconcise set of psychological forces could bedefined that really affect the writers?
sentiments,i.e., broadly the human sentiment.Sentimantics tries to solve the problem with apractical necessity and to overcome the problemsof the present proximity-based static sentimentlexicon techniques.As discussed earlier, the two-step methodologyis the most common one in practice.
As describedin Section 3, a syntactic-polarity classifier wastherefore developed, to examine the impact ofproposed Sentimantics concept, by comparing it tothe standard polarity classification technique.
Thestrategy was tested on both English and Bengali.The intension behind choosing two distinctlanguage families is to establish the credibility ofthe proposed methods.1http://sentic.net/sentics/For English we choose the widely used MPQA3corpus, but for the Bengali we had to create ourown corpus as discussed in the following section.The remainder of the paper then concentrates onthe problems with using prior polarity values only,in Section 4, while the Sentimantics concept properis discussed in Section 5.
Finally, some initialconclusions are presented in Section 6.2 Bengali CorpusNews text can be divided into two main types: (1)news reports that aim to objectively present factualinformation, and (2) opinionated articles thatclearly present authors?
and readers?
views,evaluation or judgment about some specific eventsor persons (and appear in sections such as?Editorial?, ?Forum?
and ?Letters to the editor?).
ABengali news corpus has been acquired for thepresent task, based on 100 documents from the?Reader?s opinion?
section (?Letters to the Editor?
)from the web archive of a popular Bengalinewspaper.
4   In total, the corpus contains 2,235sentences (28,805 word forms, of which 3,435 aredistinct).
The corpus has been annotated withpositive and negative phrase polarities usingSanchay5, the standard annotation tool for Indianlanguages.
The annotation was done semi-automatically: a module marked the sentimentwords from SentiWordNet (Bengali)6 and then thecorpus was corrected manually.3 The Syntactic Polarity ClassifierAdhering to the standard two-step methodology(i.e., prior polarity lexicon followed by any NLPtechnique), a Syntactic-Statistical polarityclassifier based on Support Vector Machines(SVMs) has been quickly developed usingSVMTool.7 The intension behind the developmentof this syntactic polarity classifier was to examinethe effectiveness and the limitations of the standardtwo-step methodology at the same time.The selection of an appropriate feature set iscrucial when working with Machine Learningtechniques such as SVM.
We decided on a feature3http://www.cs.pitt.edu/mpqa/4http://www.anandabazar.com/5http://ltrc.iiit.ac.in/nlpai_contest07/Sanchay/6http://www.amitavadas.com/sentiwordnet.php7http://www.lsi.upc.edu/~nlp/SVMTool/39Polarity Precision RecallEng.
Bng.
Eng.
Bng.Total 76.03% 70.04% 65.8% 63.02%Positive 58.6% 56.59% 54.0% 52.89%Negative 76.3% 75.57% 69.4% 65.87%Table 1: Overall and class-wise results ofsyntactic polarity classificationset including Sentiment Lexicon, Negative Words,Stems, Function Words, Part of Speech andDependency Relations, as most previous researchagree that these are the prime features to detect thesentimental polarity from text (see, e.g., Pang andLee, 2005; Seeker et al, 2009; Moilanen et al,2010; Liu et.
al., 2005).Sentiment Lexicon: SentiWordNet 3.0 8  forEnglish and SentiWordNet (Bengali) for Bengali.Negative Words: Manually created.
Contains80 entries collected semi-automatically from boththe MPQA9 corpus and the Movie Review dataset10by Cornell for English.
50 negative words werecollected manually for Bengali.Stems: The Porter Stemmer11 for English.
TheBengali Shallow Parser12 was used to extract rootwords (from morphological analysis output).Function Words: Collected from the web.
13Only personal pronouns are dropped for thepresent task.
A list of 253 entries was collectedmanually from the Bengali corpus.POS, Chunking and DependencyRelations:The Stanford Dependency parser 14  forEnglish.
The Bengali Shallow Parser was used toextract POS, chunks and dependency relations.The results of SVM-based syntactic classificationfor English and Bengali are presented in Table 1,both in total and for each polarity class separately.To understand the effects of various features onthe performance of the system, we used the featureablation method.
The dictionary-based approachusing only SentiWordNet gave a 50.50% precision8http://sentiwordnet.isti.cnr.it/9http://www.cs.pitt.edu/mpqa/10http://www.cs.cornell.edu/People/pabo/movie-review-data/11http://tartarus.org/martin/PorterStemmer/java.txt12ltrc.iiit.ac.in/showfile.php?filename=downloads/shallow_parser.php13http://www.flesl.net/Vocabulary/Single-word_Lists/function_word_list.php14http://nlp.stanford.edu/software/lex-parser.shtmlFeatures Precision Eng.
Bng.Sentiment Lexicon 50.50% 47.60%+Negative Words 55.10% 50.40%+Stemming 59.30% 56.02%+ Function Words 63.10% 58.23%+ Part of Speech 66.56% 61.90%+Chunking 68.66% 66.80%+Dependency Relations 76.03% 70.04%Table 2: Performance of the syntactic polarityclassifier by feature ablation(Eng.)
and 47.60% (Bng.)
which can be consideredas baselines.
As seen in Table 2, incremental use ofother features like negative words, function words,part of speech, chunks and tools like stemmingimproved the precision of the system to 68.66%(Eng.)
and 66.80% (Bng.).
Further use of syntacticfeatures in terms of dependency relations improvedthe system precision to 76.03% (Eng.)
and 70.04%(Bng.).
The feature ablation proves theaccountability of the two-step polarityclassification technique.
The prior polarity lexicon(completely dictionary-based) approach givesabout 50% precision; the further improvements ofthe system are obtained by other NLP techniques.To support our argumentation for choosingSVM, we tested the same classification problemwith another machine learning technique,Conditional Random Fields (CRF)15 with the samedata and setup.
The performance of the CRF-basedmodel is much worse than the SVM, with aprecision of 70.04% and recall of 67.02% forEnglish, resp.
61.23% precision and 55.00% recallfor Bengali.
The feature ablation method was alsotested for the CRF model and the performance wasmore or less the same when the dictionary featuresand lexical features were used (i.e., SentiWordNet+ Negative Words + Stemming + Function Words+ Part of Speech).
But it was difficult to increasethe performance level for the CRF by usingsyntactic features like chunking and dependencyrelations.
SVMs work excellent to normalize thisdynamic situation.It has previously been noticed that multi-enginebased methods work well for this type ofheterogeneous tagging task, e.g., in Named Entity15http://crfpp.googlecode.com/svn/trunk/doc/index.html40Recognition (Ekbal and Bandyopadhyay, 2010)and POS tagging (Shulamit et al, 2010).
We havenot tested with that kind of setup, but rather lookedat the problem from a different perspective,questioning the basics: Is the two-step methodologyfor the classification task ideal or should we lookfor other alternatives?4 What Knowledge at What Level?In this section we address some limitationsregarding the usage of prior polarity values fromexisting of prior polarity lexical resources.
Dealingwith unknown/new words is a common problem.
Itbecomes more difficult for sentiment analysisbecause it is very hard to find out any contextualclue to predict the sentimental orientation of anyunknown/new word.
There is another problem:word sense disambiguation, which is indeed asignificant subtask when applying a resource likeSentiWordNet (Cem et al, 2011).A prior polarity lexicon is attached with twoprobabilistic values (positivity and negativity), butaccording to the best of our knowledge no previousresearch clarifies which value to pick in whatcontext?
?
and there is no information about this inSentiWordNet.
The general trend is to pick thehighest one, but which may vary by context.
Anexample may illustrate the problem better: Supposea word ?high?
(Positivity: 0.25, Negativity: 0.125from SentiWordNet) is attached with a positivepolarity (its positivity value is higher than itsnegativity value) in the sentiment lexicon, but thepolarity of the word may vary in any particular use.Sensex reaches high+.Prices go high-.Hence further processing is required todisambiguate these types of words.
Table 3 showshow many words in the SentiWordNet(s) areambiguous and need special care.
There are 6,619(Eng.)
and 7,654 (Bng.)
lexicon entries inSentiWordNet(s) where both the positivity and thenegativity values are greater than zero.
Thereforethese entries are ambiguous because there is noclue in the SentiWordNet which value to pick inwhat context.
Similarly, there are 3,187 (Eng.)
and2,677 (Bng.)
lexical entries in SentiWordNet(s)whose positivity and negativity value difference isless than 0.2.
These are also ambiguous words.TypesEng.
Bng.Numbers (%)English: n/28,430Bengali: n/30,000Total Token 115,424 30,000Positivity > 0 ?
Negativity > 0 28,430  30,000Positivity > 0 ?
Negativity > 0 6619 (23.28 %)7,654(25.51 %)Positivity > 0 ?
Negativity = 0 10,484 (36.87 %)8,934(29.78 %)Positivity = 0 ?
Negativity > 0 11,327 (39.84 %)11,780(39.26 %)Positivity > 0 ?
Negativity > 0 ?|Positivity-Negativity| ?
0.23,187(11.20 %)2,677(8.92 %)Table 3: SentiWordNet(s) statisticsThe main concern of the present task is theambiguous entries from SentiWordNet(s).
Thebasic hypothesis is that if we can add some sort ofcontextual information with the prior polarityscores in the sentiment lexicon, the updated richlexicon network will serve better than the existingone, and reduce or even remove the need forfurther processing to disambiguate the contextualpolarity.
How much contextual information wouldbe needed and how this knowledge should berepresented could be a perpetual debate.
To answerthese questions we introduce Sentimantics:Distributed Semantic Lexical Models to hold thesentiment knowledge with context.5 Technical Solutions for SentimanticsIn order to propose a model of Sentimantics westarted with existing resources such asConceptNet 16  (Havasi et al, 2007) andSentiWordNet for English, and SemanticNet (Dasand Bandyopadhyay, 2010) and SentiWordNet(Bengali) for Bengali.
The common sense lexicalike ConceptNet and SemanticNet are developedfor general purposes, and to formalizeSentimantics from these resources is problematicdue to lack of dimensionality.
Section 5.1 presentsa more rational explanation with empirical results.In the end we developed a Syntactic Co-Occurrence Based Vector Space Model to hold theSentimantics from scratch by a corpus driven semi-supervised method (Section 5.2).
This modelperforms better than the previous one and quitesatisfactory.
Generally extracting knowledge from16http://csc.media.mit.edu/conceptnet41this kind of VSM is very expensive algorithmicallybecause it is a very high dimensional network.Another important limitation of this type of modelis that it demands very well defined processedinput to extract knowledge, e.g., Input: (high)Context: (sensex, share market, point).Philosophically, the motivation of Sentimantics isto provide a rich lexicon network which will servebetter than the existing one and reduce therequirement of further language processingtechniques to disambiguate the contextual polarity.This model consists of relatively fewerdimensions.
The final model is the best performinglexicon network model, which could be describedas the acceptable solution for the Sentimanticsproblem.
The details of the proposed models aredescribed in the following.5.1 Semantic Network Overlap, SNOWe started experimentation with network overlaptechniques.
The network overlap technique findsoverlaps of nodes between two lexical networks:namely ConceptNet-SentiWordNet for English andSemanticNet-SentiWordNet (Bengali) for Bengali.The working principle of the network overlaptechnique is very simple.
The algorithm starts withany SentiWordNet node and finds its closestneighbours from the commonsense networks(ConceptNet or SemanticNet).
If, for example, anode chosen from SentiWordNet is ?long/?, theclosest neighbours of this concept extracted fromthe commonsense networks are: ?road (40%) /waiting (62%) / car (35%) / building (54%) / queue(70%) ??
The association scores (as the previousexample) are also extracted to understand thesemantic similarity association.
Hence the desiredSentimantics lexical network is developed by thisnetwork overlap technique.
The next primechallenge is to assign contextual polarity to eachassociation.
For this a corpus-based method wasused; based on the MPQA17 corpus for English andthe corpus developed by us for.
The corpora arepre-processed with dependency relations andstemming using the same parsers and stemmers asin Section 3.
The dependency relations arenecessary to understand the relations between theevaluative expression and other modifier-modifiedchunks in any subjective sentence.
Stemming is17http://www.cs.pitt.edu/mpqa/necessary to understand the root form of any wordand for dictionary comparison.
The corpus-drivenmethod assigns each sentiment word in thedeveloped lexical network a contextual priorpolarity, as shown in Figure 1.Semantic network-based polarity calculationOnce the desired lexical semantic network to holdthe Sentimantics has been developed, we lookfurther to leverage the developed knowledge forthe polarity classification task.
The methodologyof contextual polarity extraction from the networkis very simple, and only a dependency parser andstemmer are required.
For example, consider thefollowing sentence.We have been waiting in a long queue.To extract the contextual polarity from thissentence it must be known that waiting-long-queueare interconnected with dependency relations, andstemming is a necessary pre-processing step fordictionary matching.
To extract contextual polarityfrom the developed network the desired input is(long) with its context (waiting, queue).
Theaccumulated contextual polarity will be Neg:(0.50+0.35)=0.85.
For comparison if the score wasextracted from SentiWordNet (English) it would bePos: 0.25 as this is higher than the negative score(long: Pos: 0.25, Neg: 0.125 in SentiWordNet).SNO performance and limitationsAn evaluation proves that the present NetworkOverlap technique outperforms the previoussyntactic polarity classification technique.
Theprecision scores for this technique are 62.3% forEnglish and 59.7% for Bengali on the MPQA andFigure 1: The Sentimantics Network42Type NumberSolved BySemanticOverlapTechniquePositivity > 0 ?Negativity > 0Eng.
6,619 2,304 (34.80 %)Bng.
7,654 2,450 (32 %)|Positivity -Negativity| ?
0.2Eng.
3,187 957 (30 %)Bng.
2,677 830 (31.5 %)Table 4: Results of Semantic OverlapBengali corpora: clearly higher than the baselinesbased on SentiWordNet (50.5 and 47.6%; Table 2).Still, the overall goal to ?reduce/remove therequirement to use further NLP techniques todisambiguate the contextual polarity?
could not beestablished empirically.
To understand why, weperformed an analysis of the errors and missedcases of the semantic network overlap technique:most of the errors were caused by lack of coverage.ConceptNet and SemanticNet were both developedfrom the news domain and for a different task.
Thecomparative coverage of SentiWordNet (English)and MPQA is 74%, i.e., if we make a complete setof sentiment words from MPQA then altogether74% of that set is covered by SentiWordNet, whichis very good and an acceptable coverage.
ForBengali the comparative coverage is 72%, which isalso very good.
However, the comparativecoverage of SentiWordNet (English)-ConceptNetand SentiWordNet (Bengali)-SemanticNet is verylow: 54% and 50% respectively: only half of thesentiment words in the SentiWordNets are coveredby ConceptNet (Eng) resp.
SemanticNet (Bng).Now look at the evaluation in Table 4 which wereport to support our empirical reasoning behindthe question ?What knowledge to keep at whatlevel??
It shows how much fixed point-based staticprior polarity is being resolved by the SemanticNetwork Overlap technique.
The comparativeresults are noteworthy but not satisfactory: only34% (Eng.)
and 32% (Bng.)
of the cases of?Positivity > 0 ?
Negativity > 0?
resp.
30% (Eng.
)and 31.5 % (Bng.)
of the cases of ?|Positivity -Negativity| ?
0.2?
are resolved by this technique.The results are presented in Table 4.As a result of the error analysis, we insteaddecided to develop a Vector Space Model fromscratch in order to solve the Sentimantics problemand to reach a satisfactory level of coverage.
Theexperiments in this direction are reported below.5.2 Starting from Scratch: Syntactic Co-Occurrence Network ConstructionA syntactic word co-occurrence network wasconstructed for only the sentimental words fromthe corpora.
The syntactic network is defined in away similar to previous work such the Spin Model(Takamura et al, 2005) and Latent SemanticAnalysis to compute the association strength withseed words (Turney and Litman, 2003).
Thehypothesis is that all the words occurring in thesyntactic territory tend to have similar semanticorientation.
In order to reduce dimensionalitywhen constructing the network, only the open wordclasses noun, verb, adjective and adverb areincluded, as those classes tend to have maximizedsentiment properties.
Involving fewer featuresgenerates VSMs with fewer dimensions.For the network creation we again started withSentiWordNet 3.0 to mark the sentiment words inthe MPQA corpus.
As the MPQA corpus is markedat expression level, SentiWordNet was used tomark only the lexical entries of the subjectiveexpressions in the corpus.
As before, the StanfordPOS tagger and the Porter Stemmer were used toget POS classes and stems of the English terms,while SentiWordNet (Bengali), the Bengali corpusand the Bengali processors were used for Bengali.Features were extracted from a ?4 word windowaround the target terms.
To normalize the extractedwords from the corpus we used CF-IOF, conceptfrequency-inverse opinion frequency (Cambria etal., 2011), while a Spectral Clustering technique(Dasgupta and Ng, 2009) was used for the in-depthanalysis of word co-occurrence patterns and theirrelationships at discourse level.
The clusteringalgorithm partitions a set of lexica into a finitenumber of groups or clusters in terms of theirsyntactic co-occurrence relatedness.Numerical weights were assigned to the wordsand then the cosine similarity measure was used tocalculate vector similarity:s qk?,d j??????
?= qk?.d j?= wi ,ki=1N?
?
wi , j  -----(1)When the lexicon collection is relatively static, itmakes sense to normalize the vectors once andstore them, rather than include the normalization inthe similarity metric (as in Equation 2).s qk?,d j??????
?=wi ,k ?
wi , ji=1N?i ,k2wi=1N?
?
j ,k2wj=1N?-------(2)43ID Lexicon 1 2 31 Broker 0.63 0.12 0.041 NASDAQ 0.58 0.11 0.061 Sensex 0.58 0.12 0.031 High 0.55 0.14 0.082 India 0.11 0.59 0.022 Population 0.15 0.55 0.012 High 0.12 0.66 0.013 Market 0.13 0.05 0.583 Petroleum 0.05 0.01 0.863 UAE 0.12 0.04 0.653 High 0.03 0.01 0.93Table 5: Five example cluster centroidsAfter calculating the similarity measures and usinga predefined threshold value (experimentally set to0.5), the lexica are classified using a standardspectral clustering technique: Starting from a set ofinitial cluster centers, each document is assigned tothe cluster whose center is closest to the document.After all documents have been assigned, the centerof each cluster is recomputed as the centroid ormean j??
(where j?
?is the clustering coefficient)of its members:?
?= 1/ jc( ) ?xx?c j?Table 5 gives an example of cluster centroids byspectral clustering.
Bold words in the lexicon namecolumn are cluster centers.
Comparing twomembers of Cluster2, ?India?
and ?Population?, itcan be seen that ?India?
is strongly associated withCluster2 (p=0.59), but has some affinity with theother clusters as well (e.g., p=0.11 with Cluster1).These non-zero values are still useful forcalculating vertex weights during the contextualpolarity calculation.Polarity Calculation using the Syntactic Co-Occurrence NetworkThe relevance of the semantic lexicon nodes wascomputed by summing up the edge scores of thoseedges connecting a node with other nodes in thesame cluster.
As the cluster centers also areinterconnected with weighted vertices, inter-clusterrelations could be calculated in terms of weightednetwork distance between two nodes within twoseparate clusters.Figure 2: Semantic affinity graph for contextualprior polarityAs an example, the lexicon level semanticorientation from Figure 2 could be calculated asfollows:Sd (wi ,wj ) =vkk=0n?k*  wjp----(3) or=vkk=0n?kc=0m?
* lcc=0m?
*  w jp---(4)Where Sd(wi,wj) is the semantic orientation of wiwith wj given as context.
Equations (3) and (4) arefor intra-cluster and inter-cluster semantic distancemeasure respectively.
k is the number of weightedvertices between two lexica wi and wj.
vk theweighted vertex between two lexica, m the numberof cluster centers between them, lc the distancebetween their cluster centers, and wpj the polarityof the known word wj.This network was created and used in particularto handle unknown words.
For the prediction ofsemantic orientation of an unknown word, a bag-of-words method was adopted: the bag-of-wordschain was formed with most of the known words,syntactically co-located.A classifier based on Conditional RandomFields was then trained on the corpus with a smallset of features: co-occurrence distance, ConceptNetsimilarity scores, known or unknown based onSentiWordNet.
With the help of these very simplefeatures, the CRF classifier identifies the mostprobable bag-of-words to predict the semanticorientation of an unknown word.
As an example:Suppose X marks the unknown words and that theprobable bag-of-words are:9_11-X-Pentagon-USA-BushDiscuss-Terrorism-X-PresidentMiddle_East-X-Osama44Once the target bag-of-words has been identified,the following equation can be used to calculate thepolarity of the unknown word X.Discuss-0.012-Terrorism-0.0-X-0.23-PresidentThe scores are extracted from ConceptNet andthe equation is:wxp= eii=0n?
*  pij=1n?
-----(5)Where ei is the edge distances extracted fromConceptNet and Pi is the polarity information ofthe lexicon in the bag-of-words.The syntactic co-occurrence network givesreasonable performance increment over the normallinear sentiment lexicon and the Semantic NetworkOverlap technique, but it has some limitations: it isdifficult to formulate a good equation to calculatesemantic orientation within the network.
Theformulation we use produced a less distinguishingvalue for different bag of words.
As example inFigure 2:(High, Sensex)=0.3 0.3 0.32+=(Price, High)=0.22 0.35 0.292+=The main problem is that it is nearly impossibleto predict polarity for an unknown word.
Standardpolarity classifiers generally degrade inperformance in the presence of unknown words,but the Syntactic Co-Occurrence Network is verygood at handling unknown or new words.The performance of the syntactic co-occurrencemeasure on the corpora is shown in Table 6, with a70.0% performance for English and 68.0% forBengali; a good increment over the SemanticNetwork Overlap technique: about 45% (Eng.)
and41% (Bng.)
of the ?Positivity > 0 ?
Negativity > 0?cases and 43% (Eng.)
and 38% (Bng.)
of the?|Positivity ?
Negativity| ?
0.2?
cases were resolvedby the Syntactic co-occurrence based technique.To better aid our understanding of the developedlexical network to hold Sentimantics we visualizedthis network using the Fruchterman Reingold forcedirected graph layout algorithm (Fruchterman andReingold, 1991) and the NodeXL 18  networkanalysis tool (Smith et al, 2009).18http://www.codeplex.com/NodeXLType NumberSolved BySyntacticCo-OccurrenceNetworkPositivity>0 &&Negativity>0Eng.
6,619 2978  (45 %)Bng.
7,654 3138  (41 %)|Positivity-Negativity|>=0.2Eng.
3,187 1370 (43 %)Bng.
2,677 1017 (38 %)Table 6: Results of the syntactic co-occurrencebased technique6 ConclusionsThe paper has introduced Sentimantics, a new wayto represent sentiment knowledge in theConceptual Spaces of distributional Semantics byusing in a Vector Space Model.
This model canstore dynamic prior polarity with varyingcontextual information.
It is clear from theexperiments presented that developing the VectorSpace Model from scratch is the best solution tosolving the Sentimantics problem and to reach asatisfactory level of coverage.
Although it couldnot be claimed that the two issues ?Whatknowledge to keep at what level??
and?reduce/remove the requirement of using furtherNLP techniques to disambiguate the contextualpolarity?
were fully solved, our experiments showthat a proper treatment of Sentimantics canradically increase sentiment analysis performance.As we showed by the syntactic classificationtechnique the lexicon model only provides 50%accuracy and further NLP techniques increase it to70%, whereas by the VSM based technique itreaches 70% accuracy while utilizing fewerlanguage processing resources and techniques.To the best of our knowledge this is the firstresearch endeavor which enlightens the necessityof using the dynamic prior polarity with context.
Itis an ongoing task and presently we are exploringits possible applications to multiple domains andlanguages.
The term Sentimantics may or may notremain in spotlight with time, but we do believethat this is high time to move on for the dynamicprior polarity lexica.45ReferencesCambria Erik, Amir Hussain and Chris Eckl.
2011.Taking Refuge in Your Personal Sentic Corner.SAAIP, IJCNLP, pp.
35-43.Cem Akkaya, Janyce Wiebe, Conrad Alexander andMihalcea Rada.
2011.
Improving the Impact ofSubjectivity Word Sense Disambiguation onContextual Opinion Analysis.
CoNLL.Das Amitava and Bandyopadhyay S. 2010.SemanticNet-Perception of Human Pragmatics.COGALEX-II, COLING, pp 2-11.Das Amitava Bandyopadhyay S. 2010.
SentiWordNetfor Indian Languages.
ALR, COLING, pp 56-63.Dasgupta, Sajib and Vincent Ng.
2009.
Topic-wise,Sentiment-wise, or Otherwise?
Identifying theHidden Dimension for Unsupervised TextClassification.
EMNLP.Ekbal A. and Bandyopadhyay S. 2010.
Voted NERSystem using Appropriate Unlabeled Data.Lingvisticae Investigationes Journal.Esuli Andrea and Fabrizio Sebastiani.
2006.SentiWordNet: A Publicly Available LexicalResource for Opinion Mining.
LREC, pp.
417-422.Fruchterman Thomas M. J. and Edward M. Reingold.1991.
Graph drawing by force-directed placement.Software: Practice and Experience, 21(11):1129?1164.Grassi, Marco.
2009.
Developing HEO HumanEmotions Ontology.
Joint International Conferenceon Biometric ID management and MultimodalCommunication, vol.
5707 of LNCS, pp 244?251.Haruechaiyasak Choochart, Alisa Kongthon, PalingoonPornpimon and Sangkeettrakarn Chatchawal.
2010.Constructing Thai Opinion Mining Resource: A CaseStudy on Hotel Reviews.
ALR, pp 64?71.Hatzivassiloglou Vasileios and Kathleen R. McKeown.1997.
Predicting the Semantic Orientation ofAdjectives.
ACL, pp.
174?181.Havasi, C., Speer, R., Alonso, J.
2007.
ConceptNet 3: aFlexible, Multilingual Semantic Network forCommon Sense Knowledge.
RANLP.He Yulan, Alani Harith and Zhou Deyu.
2010.Exploring English Lexicon Knowledge for ChineseSentiment Analysis.
CIPS-SIGHAN, pp 28-29.Kim Soo-Min and Eduard Hovy.
2004.
Determining theSentiment of Opinions.
COLING, pp.
1367-1373.Liu Bing.
2010.
NLP Handbook.
Chapter: SentimentAnalysis and Subjectivity, 2nd Edition.Liu Hugo, Henry Lieberman and Ted Selker.
2003.
AModel of Textual Affect Sensing using Real-WorldKnowledge.
IUI, pp.
125-132.Minsky Marvin.
2006.
The Emotion Machine.
Simonand Schuster, New York.Moilanen Karo, Pulman Stephen and Zhang Yue.
2010.Packed Feelings and Ordered Sentiments: SentimentParsing with Quasi-compositional PolaritySequencing and Compression.
WASSA, pp.
36--43.Ohana Bruno and Brendan Tierney.
2009.
Sentimentclassification of reviews using SentiWordNet.
In the9th IT&T Conference.Pang Bo, Lillian Lee and Vaithyanathan Shivakumar.2002.
Thumbs up?
Sentiment Classification usingMachine Learning Techniques.
EMNLP, pp 79-86.Pang, Bo and Lillian Lee.
2005.
Seeing stars: Exploitingclass relationships for sentiment categorization withrespect to rating scales.
ACL, pp.
115-124.Seeker Wolfgang, Adam Bermingham, Jennifer Fosterand Deirdre Hogan.
2009.
Exploiting Syntax inSentiment Polarity Classification.
National Centre forLanguage Technology Dublin City University,Ireland.Shulamit Umansky-Pesin, Roi Reichart and AriRappoport.
2010.
A Multi-Domain Web-BasedAlgorithm for POS Tagging of Unknown Words.COLING.Smith Marc, Ben Shneiderman, Natasa Milic-Frayling,Eduarda Mendes Rodrigues, Vladimir  Barash, CodyDunne, Tony Capone, Adam Perer, and Eric Gleave.2009.
Analyzing (social media) networks withNodeXL.
4th International Conference onCommunities and Technologies, pp.
255-264.Takamura Hiroya, Inui Takashi and Okumura Manabu.2005.
Extracting Semantic Orientations of Wordsusing Spin Model.
ACL, pp.
133-140.Torii Yoshimitsu, Das Dipankar, Bandyopadhyay Sivajiand Okumura Manabu.
2011.
Developing JapaneseWordNet Affect for Analyzing Emotions.
WASSA,ACL, pp.
80-86Turney Peter and Michael Littman.
2003.
Measuringpraise and criticism: Inference of semanticorientation from association.
ACM Transactions onInformation Systems, 21(4):315?346.Turney Peter.
2002.
Thumbs up or thumbs down?Semantic orientation applied to unsupervisedclassification of reviews.
ACL, pp.
417?424.Turney Peter.
2006.
Similarity of Semantic Relations.Computational Linguistics, 32(3):379-416.46
