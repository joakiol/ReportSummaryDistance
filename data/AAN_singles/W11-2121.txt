Proceedings of the 6th Workshop on Statistical Machine Translation, pages 171?176,Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational LinguisticsDescription of the JHU System Combination Scheme for WMT 2011Daguang XuJohns Hopkins UniversityBaltimore, USAdxu5@jhu.eduYuan CaoJohns Hopkins UniversityBaltimore, USAyuan.cao@jhu.eduDamianos KarakosJohns Hopkins UniversityBaltimore, USAdamianos@jhu.eduAbstractThis paper describes the JHU system combi-nation scheme used in WMT-11.
The JHUsystem combination is based on confusionnetwork alignment, and inherited the frame-work developed by (Karakos et al, 2008).We improved our core system combination al-gorithm by making use of TER-plus, whichwas originally designed for string alignment,for alignment of confusion networks.
Exper-imental results on French-English, German-English, Czech-English and Spanish-Englishcombination tasks show significant improve-ments on BLEU and TER by up to 2 points onaverage, compared to the best individual sys-tem output, and improvements compared withthe results produced by ITG which we used inWMT-10.1 IntroductionSystem combination aims to improve the translationquality by combining the outputs from multiple in-dividual MT systems.
The state-of-the-art systemcombination methodologies can be roughly catego-rized as follows (Karakos et al, 2010):1.
Confusion network based: confusion networkis a form of lattice with the constraint that allpaths need to pass through all nodes.
An exam-ple of a confusion network is shown in Figure1.Here, the set of arcs between two consecutivenodes represents a bin, the number following aword is the count of this word in its bin, and0 1this/10 2is/7was/3 3a/8one/2 4dog/9cat/1 5/0./10Figure 1: Example confusion network.
The total count ineach bin is 10.each bin has the same size.
The basic method-ology of system combination based on confu-sion network includes the following steps: (a)Choose one system output as the ?skeleton?,which roughly decides the word order.
(b)Align further system outputs to the skeleton,thus forming a confusion network.
(c) Rescorethe final confusion network using a languagemodel, then pick the best path as the output ofcombination.A textual representation (where each line con-tains the words and counts of each bin) is usu-ally the most convenient for machine process-ing.2.
Joint optimization based: unlike building con-fusion network, this method considers all sys-tem outputs at once instead of incrementally.Then a log-linear model is used to derive costs,followed by a search algorithm to explore thecombination space (Jayaraman et al, 2005;Heafield et al, 2009; He et al, 2009).3.
Hypothesis selection based: this method onlyincludes algorithms that output one of the inputtranslations, and no word selection from mul-tiple systems is performed.
Typical algorithmscan be found in (Rosti et al, 2007).171This paper describes the JHU system com-bination submitted to the Sixth Workshopon Statistical Machine Translation (WMT-11)(http://statmt.org/wmt11/index.html ).
The JHUsystem combination is confusion network basedas described above, following the basic systemcombination framework described in (Karakos etal., 2008).
However, instead of ITG alignmentsthat were used in (Karakos et al, 2008), alignmentsbased on TER-plus (Snover et al, 2009) were usednow as the core system alignment algorithm.The rest of the paper is organized as follows:Section 2 introduces the application of TER-plus insystem combination.
Section 3 introduces the JHUsystem combination pipeline.
Section 4 presents thecombination results and concluding remarks appearin Section 5.2 Word Reordering for HypothesisAlignmentGiven the outputs of multiple MT systems, wewould like to reorder and align the words of differenthypothesis in a way such that an objective function isoptimized, thus reaching better translations by mak-ing use of more information.
In our system combi-nation scheme, the objective function was based onTranslation-Edit-Rate Plus (TER-plus).2.1 Introduction to TER-plusTER-plus is an extension of Translation Error Rate(TER) (Snover et al, 2006).
TER is an evaluationmetric for machine translation; it generalizes WordError Rate (WER) by allowing block shifts in addi-tion to the edit distance operations.
However, oneproblem with TER is that only exact match of wordblocks are allowed for shifting; this constraint mightbe too strict as it sometimes prevents reasonableshifts if two blocks have similar meanings.TER-plus remedies this problem by introducingnew flexible matches between words, thus allowingword substitutions and block shifts with costs muchlower than that of TER.
Specifically, substitutioncosts are now dependent on whether the words havethe same stem (stem matches) or are synonyms (syn-onym matches).
These operations relax the shift-ing constraints of TER; shifts are now allowed if thewords of one string are synonyms or share the samestem as the words of the string they are compared to(Snover et al, 2009).TER-plus identifies words with the same stem us-ing the Porter stemming algorithm (Porter et al,1980), and identifies synonyms using the WordNetdatabase (Miller et al, 1995).2.2 TER-plus for system combinationOriginally, TER-plus was designed for aligning to-gether word strings.
However, similar to the workof (Karakos et al, 2010), who extended ITG to al-low bilingual parsing of two confusion networks (bytreating each confusion network bin as a multi-wordentity), we converted the basic TER-plus code totake into account multiple words present in confu-sion network bins.
Specifically, we define the costof aligning two confusion network bins as (Karakoset al, 2010)cost(b1, b2) =1|b1||b2|?w1?b1?w2?b2C(w1, w2)in which b1,b2 are the confusion network bins whichare candidates for alignment, | ?
| is the size of abin, w1, w2 are words in b1 and b2 respectively, andC(w1, w2) is defined as follows:C(w1, w2) =??????????????
?0 w1 matches w20.5 w2 is deleted0.6 w2 is inserted0.2 w1 and w2 are synonyms0.2 w1 and w2 share stems1 none of the aboveFurthermore, the bin shift cost is set to 1.5.
Thesenumbers are empirically determined based on exper-imental results.Similar to (Karakos et al, 2010), when a bin gets?deleted?, it gets replaced with a NULL arc, whichsimply encodes the empty string, and is otherwisetreated as a regular token in the alignments.3 The JHU System Combination PipelineWe now describe the JHU system combinationpipeline in which TER-plus is used as the core con-fusion network alignment algorithm as introduced inthe previous section.1723.1 Combination procedure overviewThe JHU system combination scheme is based onconfusion network as introduced in section 1.
Theconfusion networks are built in two stages:1.
Within-system combination: (optional, onlyapplicable in the case where per-system n-bestlists are available.)
the within-system combi-nation generates system-specific confusion net-works based on the alignment of the n-besttranslations.2.
Between-system combination: incrementalalignment of the confusion networks of differ-ent systems generated in step 1, starting from2-system combination up to the combination ofall systems.
The order with which the systemsare selected is based on the individual BLEUscores (i.e., the best two systems are first com-bined, then the 3rd best is aligned to the result-ing confusion network, etc.
)For the between-system combination we madeuse of TER-plus as described in section 2.2.3.2 Language model Rescoring withFinite-State Transducer OperationsOnce the between-system confusion networks areready (one confusion network per sentence), a paththrough each of them has to be selected as the com-bination output.
In order to pick out the the most flu-ent word sequence as the final translation, we needto rescore the confusion networks using a languagemodel.
This task can be performed efficiently via fi-nite state transducer (FST) operations (Allauzen etal., 2002).
First, we build an FST for each confu-sion network, called CN-FST.
Since the confusionnetwork is just a sequence of bins and each bin is asuperposition of single words, the CN-FST can bebuilt as a linear FST in a straightforward way (seeFigure 1).A 5-gram language model FST (LM-FST) is thenbuilt for each sentence.
To build the LM-FST, werefer to the methodology described in (Allauzen etal., 2003).
In brief, the LM-FST is constructed inthe following way:1.
Extract the vocabulary of each segment.2.
Each state of the FST encodes an n-gram his-tory (n ?
1 words).
Each (non-null) arc thatoriginates from that state corresponds uniquelyto a word type (i.e., word that follows that his-tory in the training data).3.
The cost of each word arc is the corre-sponding language model score (negative log-probability, based on the modified Kneser-Neyformula (Kneser, 1995) for that n-gram).4.
Extra arcs are added for backing-off to lower-order histories, thus allowing all possible wordstrings to receive a non-zero probability.In order to deal with the situation where a wordin the confusion network is not in the vocabulary ofthe language model, we need to build another sim-ple transducer, namely, the ?unknown word?
FST(UNK-FST), to map this word to the symbol <unk>that encodes the out-of-vocabulary (OOV) words.Note that this is useful only if one builds open-vocabulary language models which always give anon-zero probability to OOV words; e.g., checkout the option -unk of the SRILM toolkit (Stolcke,2002).
(Obviously, the UNK-FST leaves all otherwords unmodified.
)After all these three transducers have been built,they are composed in the following manner (for eachsentence):CN-FST .o.
UNK-FST .o.
LM-FSTNote that a possible re-weighting of the arc costsof the CN-FST can be done in order to better accountfor the different dynamic ranges between the CNcosts and the LM-FST costs.
Furthermore, to avoidtoo many word deletions (especially in regions of theconfusion network where the words disagree most)an additive word deletion penalty can be added to allNULL arcs.
The best (minimum-cost) path from thisresulting FST is selected as the output translation ofthe system combination for that sentence.3.3 System combination pipeline summaryWe now summarize the JHU system combinationend-to-end pipeline as follows(since BLEU score isa key metric in the WMT11 translation evaluation,we use BLEU score as the system ranking criteria.The BLEU score we computed for the experimentsbelow are all case-insensitive):1731.
Process and re-format (lowercase, tokenize,romanize, etc.)
all individual system out-puts.
Note that we compute the case-insensitiveBLEU score in our experiments.2.
Build LM-FST and UNK-FST for each sen-tence.3.
Decide the between-system combination orderaccording to the 1-best output BLEU score ofindividual systems.4.
Do between-system combination based on theorder decided in step 3 using TER-plus.5.
Rescore the confusion network and start tuningon the parameters: convert the between-systemconfusion network into FST, compose it withthe UNK-FST and with the LM-FST.
Whencomposing with LM-FST, try different CN arccoefficients (we tried the range {5, .
.
.
, 21}),and unknown word insertion penalties (we triedthe values {0.3, 0.5, 0.7, 1}).6.
Compute the BLEU score for all m-syst x youtputs, where m is the number of systems forcombination, x is the weight and y is the inser-tion penalty.7.
Among all the scores computed in step 6, findthe best BLEU score, and keep the correspond-ing parameter setting(m, x, y).8.
Apply the best parameter setting to the testdataset for evaluation.Obviously, if n-best outputs from systems are avail-able, an extra step of producing within-system com-binations (and searching for the best n-best size) willalso be executed.4 ResultsIn WMT11, we participated in French-English,German-English, Czech-English and Spanish-English system combination tasks.
Although wefollowed the general system combination pipelineintroduced in 3.3, we did not do the within-systemcombination since we received only 1-best outputsfrom all systems.We built both primary and contrastive systems,and they differ in the way the 5-gram language mod-els were trained.
The language model for the pri-mary system was trained with the monolingual Eu-roparl, news commentary and news crawl corpusprovided by WMT11.
The language model for thecontrastive system was trained using only the 1-best outputs from all individual systems (sentence-specific language model).The number of systems used for combinationtuning in each language pair was: 24 for French-English, 26 for German-English, 12 for Czech-English, and 16 for Spanish-English.
The best re-sults for the combination in the primary systemmade use of 23 systems for French-English, 5 sys-tems for German-English, 10 systems for Czech-English, 10 systems for Spanish-English.
In the con-trastive system, the number of systems were 20, 5,6, 10 respectively.The TER and BLEU scores on the developmentset for the best individual system, the primary andcontrastive combinations are given in Table 1, andthe scores for test set are given in Table 2.
From theresults we see that, compared with the best individ-ual system outputs, system combination results insignificantly improved BLEU scores and remarkablereductions on TER, for all language pairs.
More-over, we observe that the primary system performsslightly better than the contrastive system in mostcases.We also did the experiment of xx-English whichmade combinations of all English outputs availableacross different source languages.
We used 35 sys-tems in this experiment for both primary and con-trastive combination, and best result made use of 15and 16 systems respectively.
The development andtest set results are shown in the ?xx-en?
column intable 1 and 2 respectively.
From the results we seethe improvements on TER and BLEU scores of bothdevelopment and test sets almost doubled comparedwith the best results of single language pairs.To make a comparison with the old techniquewe used in WMT10 system combination task, weran the WMT11 system combination task using ITGwith surface matching.
The detailed implementationis described in (Narsale, 2010).
Table 3 and 4 showthe WMT11 results using ITG for alignment respec-tively.
It can be seen that TER-plus outperforms ITG174Systemfr-en de-en cz-en es-en xx-enTER BLEU TER BLEU TER BLEU TER BLEU TER BLEUBest single system 56.2 28.1 60.1 23.6 54.9 27.9 51.8 30.2 51.8 30.2Primary combination 49.2 32.6 58.1 25.7 55.1 28.7 48.3 33.7 44.9 35.5Contrastive combination 49.8 32.3 58.2 25.6 54.9 28.9 49.1 33.3 45.0 37.2Table 1: Results for all language pairs on development set.
The best number in each column is shown in bold.Systemfr-en de-en cz-en es-en xx-enTER BLEU TER BLEU TER BLEU TER BLEU TER BLEUBest single system 58.2 30.5 65.1 23.5 59.7 29.1 60.0 28.9 58.2 30.5Primary combination 55.9 31.9 64.4 25.0 60.1 29.6 55.4 33.5 51.7 36.3Contrastive combination 56.5 31.6 65.7 24.4 59.9 29.8 56.5 33.4 52.5 36.5Table 2: Results for all language pairs on test set.
The best number in each column is shown in bold.Systemfr-en de-en cz-en es-en xx-enTER BLEU TER BLEU TER BLEU TER BLEU TER BLEUBest single system 56.2 28.1 60.1 23.6 54.9 27.9 51.8 30.2 51.8 30.2Primary combination 49.0 32.5 57.6 25.0 54.6 28.1 48.8 33.1 45.3 35.7Contrastive combination 56.1 31.7 58.0 24.9 55.0 28.0 49.4 33.0 45.6 35.9Table 3: Results for all language pairs on development set using ITG.
The best number in each column is shown inbold.Systemfr-en de-en cz-en es-en xx-enTER BLEU TER BLEU TER BLEU TER BLEU TER BLEUBest single system 58.2 30.5 65.1 23.5 59.7 29.1 60.0 28.9 58.2 30.5Primary combination 55.9 31.9 64.5 24.7 60.1 29.4 55.8 33.0 52.2 35.0Contrastive combination 56.6 31.4 64.7 24.4 60.7 29.6 56.6 33.0 52.9 35.3Table 4: Results for all language pairs on test set using ITG.
The best number in each column is shown in bold.175almost in all results.
We will experiment with ITGand flexible match costs and will report results in asubsequent publication.5 ConclusionWe described the JHU system combination schemethat was used in WMT-11.
The JHU system com-bination system is confusion network based, andwe demonstrated the successful application of TER-plus (which was originally designed for string align-ment) to confusion network alignment.
The WMT-11 submission results show that significant improve-ments on the TER and BLEU scores (over the bestindividual system) were achieved.AcknowledgmentsThis work was supported by the DARPA GALE pro-gram Grant No HR0022-06-2-0001.
We would alsolike to thank the IBM Rosetta team for their strongsupport in the system combination evaluation tasks.ReferencesD.
Karakos, J. Smith, and S. Khudanpur.
2010.
Hypoth-esis ranking and two-pass approaches for machinetranslation system combination.
Acoustics Speechand Signal Processing (ICASSP), IEEE InternationalConference on.S.
Jayaraman and A. Lavie.
2005.
Multi-engine machinetranslation guided by explicit word matching.
Proc.EAMT:143?152.K.
Heafield, G. Hanneman, and A. Lavie.
2009.Machinetranslation system combination with flexibleword ordering.
Proc.
EACL 2009, WSMT.X.
He and K. Toutanova.
2009.
Joint optimizationfor machine translation system combination.
Proc.EMNLP.A.-V.I.
Rosti, S. Matsoukas, and R. Schwartz.
2007.Improved word-level system combination for machinetranslation.
Proceedings of Association for Computa-tional Linguistics(ACL)D. Karakos, J. Eisner, S. Khudanpur, M. Dreyer.
2008.Machine translation system combination using ITG-based alignments.
Proceedings of Association forComputational Linguistics(ACL) HLT, Short Papers(Companion Volume):81-84.M.
Snover, B. Dorr, R. Schwartz, L. Micciulla, J.Makhoul.
2006 A Study of Translation Edit Rate withTargeted Human Annotation.
Proceedings of Associa-tion for Machine Translation in the Americas.G.Miller.
1995 WordNet: A Lexical Database for En-glish.
.
Communications of the ACM Vol.
38, No.
11.M.
Snover, N. Madnani, B. Dorr, R. Schwartz.
2009Fluency, adequacy, or HTER?
Exploring different hu-man judgments with a tunable MT metric.
Proceed-ings of the Fourth Workshop on Statistical MachineTranslation at the 12th Meeting of the European Chap-ter of the Association for Computational Linguistics(EACL-2009), Athens, Greece.M.F.Porter.
1980 An algorithm for suffix stripping.
Pro-gram 14(3):130-137C.
Allauzen, M. Mohri, B. Roark 1980 Generalized Al-gorithms for Constructing Statistical Language Mod-els.
Proceedings of the 41st Annual Meeting of theAssociation for Computational Linguistics, July 2003,pp.
40-47.Sushant Narsale.
2010 JHU system combination schemefor WMT 2010.
Proceedings of Fifth Workshop onMachine Translation, ACL.R.
Kneser, Ney.
H. 2010 Improved backing-off for m-gram language modeling.
Proceedings of the IEEE In-ternational Conference on Acoustics, Speech, and Sig-nal Processing, ICASSP.A.
Stolcke 2002 SRILM - An Extensible Language Mod-eling Toolkit.
Proceedings of International Conferenceon Spoken Language Processing.C.
Allauzen, M. Riley, J. Schalkwyk, W. Skut, MehryarMohri.
2002 OpenFst: A General and EfficientWeighted Finite-State Transducer Library Proceed-ings of the Ninth International Conference on Im-plementation and Application of Automata, (CIAA2007), vol.
4783, Lecture Notes in Computer Science,pages 11-23, 2007WMT11 official webpage.
http://statmt.org/wmt11 /in-dex.html176
