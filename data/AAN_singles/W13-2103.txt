Proceedings of the 14th European Workshop on Natural Language Generation, pages 20?29,Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational LinguisticsUser-Controlled, Robust Natural Language Generation from an EvolvingKnowledge BaseEva BanikComputationalLinguistics LtdLondon, UKebanik@comp-ling.comEric KowComputationalLinguistics LtdLondon, UKkowey@comp-ling.comVinay Chaudhri?SRI InternationalMenlo Park, CAchaudhri@ai.sri.comAbstractIn this paper we describe a natural lan-guage generation system which producescomplex sentences from a biology knowl-edge base.
The NLG system allows do-main experts to discover errors in theknowledge base and generates certainparts of answers in response to users?questions in an e-textbook application.The system allows domain experts to cus-tomise its lexical resources and to set pa-rameters which influence syntactic con-structions in generated sentences.
Thesystem is capable of dealing with certaintypes of incomplete inputs arising from aknowledge base which is constantly editedand includes a referring expression gen-eration module which keeps track of dis-course history.
Our referring expressionmodule is available for download as theopen source Antfarm tool1.1 IntroductionIn this paper we describe a natural language gen-eration system we have developed to interfacewith a biology knowledge base.
The knowledgebase (KB) encodes sentences from a biology text-book, and the ultimate goal of our project is todevelop an intelligent textbook application whichcan eventually answer students?
questions aboutbiology2 (Spaulding et al 2011).
?The work reported in this paper was supported by fund-ing from Vulcan, Inc. We would also like to thank the mem-bers of the Inquire Biology development team: Roger Cor-man, Nikhil Dinesh, Debbie Frazier, Stijn Heymans, Sue Hi-nojoza, David Margolies, Adam Overholtzer, Aaron Spauld-ing, Ethan Stone, William Webb, Michael Wessel and NeilYorke-Smith.1https://github.com/kowey/antfarm2http://www.aaaivideos.org/2012/inquire_intelligent_textbook/The natural language generation module is partof a larger system, which includes a question un-derstanding module, question answering and rea-soning algorithms, as well as an answer presenta-tion module which produces pages with informa-tion from the KB.
We measure the progress andconsistency of encoding by asking ?what is an X?
?type questions of the application and evaluate thequality of answers.
In response to these questions,the system generates ?glossary pages?
of concepts,which display all information about concept X inthe KB that are deemed relevant.
The NLG mod-ule is used for two purposes in our system: tocheck the completeness and consistency of the KB(instead of looking at complex graphs of the en-coded knowledge, it is easier to detect errors innatural language sentences), and to present partsof answers in response to questions.One goal of our project was to develop a toolwhich empowers biology teachers to encode do-main knowledge with little training in formalknowledge representation.
In the same spirit, weaimed to develop an NLG system which alloweddomain experts to easily and intuitively customizethe generated sentences as much as possible, with-out any training on the grammar or internal work-ings of the system.
This was necessary becausemany domain-specific concepts in the KB are bestexpressed by biology terminology and linguisticconstructions specific to the domain.
We devel-oped a utility which allows encoders to not onlyassociate lexical items with concepts in the KB butalso customise certain lexical parameters whichinfluence the structure of sentences generated todescribe events.Another requirement was robustness: since theknowledge base is constantly edited, the NLG sys-tem had to be able to deal with missing lexical in-formation, incomplete inputs, changing encodingguidelines, and bugs in the KB as much as possi-ble.
The system also had to be flexible in the sense20Figure 1: Architecture of the AURA NLG systemthat it had to be able to generate different versionsof the same output to suit specific contexts or typesof concepts in its input.
Our system therefore gen-erates all possible realizations for a given input,and allows the answer presentation module to sendparameters to determine which output is returnedin a specific context.After describing the architecture of the NLGmodule in detail we explain how the system is ableto deal with unseen combination of event-to-entityrelations when describing events.
We illustrate theutility we developed to allow domain experts tocustomize the system?s output by adding parame-ters to lexical entries associated with concepts.2 Related WorkWork on natural language generation from ontolo-gies and knowledge bases tends to fall into twogroups.
On the one hand, there are tools for ontol-ogy verbalization which tend to handle a limitednumber of relations, and where the goal of the sys-tem is to help the work of knowledge engineers.These systems produce template based outputs,and the texts closely follow the structure of theontology (Wilcock, 2003; Galanis and Androut-sopoulos, 2007).
Some of these systems attemptto minimize reliance on domain-specific linguisticresources and attempt to detect words in the labelsof the ontology to use as lexical items (Mellish andSun, 2005).
On the other hand there are NLG sys-tems which take their input from complex knowl-edge bases (Reiter et al 2003; Paris, 1988) andproduce fluent texts geared towards users otherthan knowledge engineers.
These systems pro-duce outputs tailored to the user or the contextand they are difficult for non-NLG-experts to cus-tomize or port to a different domain.
Our systemfalls halfway between these two groups: like on-tology verbalizers, we wanted to produce outputfor all inputs, using ontology labels if necessary inthe absence of lexical entries.
However, like so-phisticated NLG systems, we also wanted to gen-erate good quality output for inputs for which thesystem had lexical resources, and we also wantedto be able to tailor the generated output to the con-text in which it is displayed.
Our input was alsomore expressive than the input of ontology verbal-izers, because of the presence of cardinality con-straints and co-references in our KB.
Our work isperhaps most closely related to the MIAKT sys-tem which also allows domain experts to edit lex-ical knowledge and schemas (Bontcheva, 2004;Bontcheva and Wilks, 2004).
Like MIAKT, wealso aimed to develop an NLG system which canbe easily maintained as the KB changes.3 Architecture of the AURA NLG systemOur NLG system generates complex sentencesfrom the AURA knowledge base (Gunning et al2010), which contains information from a college-level biology textbook.
AURA is a frame-basedKB which encodes events, the entities that partici-pate in events, properties, and roles that the entitiesplay in an event (e.g., catalyst, reactant, messen-ger, parent).
The KB specifies relations betweenthese types, including event-to-entity, event-to-event, event-to-property, entity-to-property.
TheAURA KB is built on top of the CLIB ontology ofgeneral concepts (Barker et al 2001), which wasextended with biology-specific information.
TheKB consists of a set of concept maps, which de-scribe all the statements that are true about a con-cept in our KB.
The input to our NLG system isa set of relations extracted from the KB either inresponse to users?
questions or when generatingglossary pages that describe specific concepts in21detail.
The generation pipeline consists of fourmain stages: content selection, input conversion,realisation and referring expression generation, asillustrated in Fig1.3.1 Content SelectionQuestion answering and reasoning algorithms thatreturn answers or other content in AURA are notengineered to satisfy the purposes of natural lan-guage generation.
The output of these algorithmscan be best thought of as pointers to concepts inthe KB, which need to be described to provide ananswer to the user.
In order for the answer to becomplete in a given context, the output of reason-ing algorithms have to be extended with additionalrelations, depending on the specific question thatwas asked, and the context in which the answerwas found in the KB.
The relations selected fromthe KB also vary depending on the type of con-cept that is being described (event, entity, role,property).
For example, a user might ask ?Whatis a catalyst??.
To answer this question, AURAwill retrieve entities from the KB (?role players?
)which play the role of catalyst in various events.For example, it will find ?adenylyl cyclase?, whichis defined in the KB as a universal catalyst, i.e.,this information is encoded on the concept map ofAdenylyl cyclase and is regarded as a ?universaltruth?.
In this case, our content selection algorithmwill return a single plays triple, and the NLG sys-tem will produce ?Adenylyl cyclase is a catalyst?.
?Another entity that will be returned in response tothe question is ?ribosomal RNA?.
However, ribo-somal RNA is a catalyst only in specific situations,and therefore we need to give more detail on thecontexts in which it can play the role of a catalyst.This includes the event in which ribosomal RNAis a catalyst, and perhaps the larger process dur-ing which this event occurs.
Accordingly, contentselection here will return a number of relations (in-cluding agent, object, subevent), and our NLGsystem will produce:?In translation elongation, ribosomal RNA is acatalyst in the formation of a peptide bond by theribosomal RNA and a ribosome.
?Similarly, for ?triose phosphate dehydrogenase?we will produce?In energy payoff phase of glycolysis, NAD plus isconverted by a triose phosphate dehydrogenase toa hydrogen ion, an NADH and a PGAP.
Here, thetriose phosphate dehydrogenase is a catalyst.
?For ?cellulose synthase?
the situation is slightlydifferent, because the event in which this entityplays the role of catalyst is not part of a larger pro-cess but the function of the entity.
So we needslightly different information to produce the cor-rect sentence: ?The function of cellulose synthaseis conversion of a chemical in a cell to cellulose.Here, a cellulose synthase is a catalyst.
?The task of the AURA content selection module isto determine what information to include for eachentity or event that was returned as the answer tothe question.
We do this by retrieving sets of rela-tions from the KB that match contextual patterns.We also filter out relations which contain overlygeneric classes (e.g., Tangible-Entity), and any du-plication arising from the presence of inverse rela-tions or inferences in the KB.
The output of con-tent selection is a structured bundle (Fig.
2), whichcontains(1) the relations that form the input to NLG(2) information about concepts in the input: whatclass(es) they belong to, cardinality constraints(3) parameters influencing the style of output texts.3.2 Input ConversionThe realisation phase in our system is carried outby the GenI surface realizer (Kow, 2007), usinga Tree-Adjoining Grammar (Joshi and Schabes,1997).
The task of the input conversion moduleis to interpret the structured bundles returned bycontent selection, and to convert the informationto GenI?s input format.
We parse the structuredbundles, perform semantic aggregation, interpretparameters in bundles which influence the style ofthe generated text, and convert triples to semanticliterals as required by GenI.4 Handling Unseen Combinations ofRelationsAs Fig 3 shows, a combination of event-to-entityrelations are associated with elementary trees inthe grammar to produce a full sentence.
The do-main of the relations associated with the sametree is the event which specifies the main pred-icate of the sentence and the range of the rela-tions are entities that fill in the individual argu-ment and modifier positions.
Depending on theevent, different relations can be used to fill in thesubject and object positions, and verbs might de-termine the prepositions needed to realize some ofthe arguments.
Ideally the mapping between sets22(TRIPLES-DATA:TRIPLES((|_Cell56531| |has-part| |_Ribosome56523|)(|_Ribosome56523| |has-part| |_Active-Site56548|)(|Enzyme-Synthesis17634| |base| |_Cell56531|)(|Enzyme-Synthesis17634| |raw-material| |_Free-Energy56632|)(|Enzyme-Synthesis17634| |raw-material| |_Monomer56578|)(|Enzyme-Synthesis17634| |raw-material| |_Activation-Energy56580|)(|Enzyme-Synthesis17634| |raw-material| |_Monomer56581|)(|Enzyme-Synthesis17634| |raw-material| |_Amino-Acid56516|)(|Enzyme-Synthesis17634| |result| |_Free-Energy56575|)(|Enzyme-Synthesis17634| |result| |Protein-Enzyme17635|)):CONSTRAINTS((|Enzyme-Synthesis17634| |raw-material| (|at-least| 3 |Amino-Acid|))):INSTANCE-TYPES((|_Ribosome56523| |instance-of| |Ribosome|)(|_Active-Site56548| |instance-of| |Active-Site|)(|_Cell56531| |instance-of| |Cell|)(|_Free-Energy56632| |instance-of| |Free-Energy|)(|_Monomer56578| |instance-of| |Monomer|)(|_Activation-Energy56580| |instance-of| |Activation-Energy|)(|_Monomer56581| |instance-of| |Monomer|)(|_Amino-Acid56516| |instance-of| |Amino-Acid|)(|_Free-Energy56575| |instance-of| |Free-Energy|)(|Enzyme-Synthesis17634| |instance-of| |Enzyme-Synthesis|)(|Protein-Enzyme17635| |instance-of| |Protein-Enzyme|)(|Free-Energy| |subclasses| |Energy|)(|Activation-Energy| |subclasses| |Energy|)(|Free-Energy| |subclasses| |Energy|)):CONTEXT NIL:OUTPUT-PARAMETERS NIL)A protein enzyme is synthesized in an active site of a ribosome of a cell using at least 3 amino acids and 2 monomers.This process transforms activation energy and free-energy to another free-energy.Enzyme synthesis ?
a protein enzyme is synthesized in an active site of a ribosome of a cell using at least 3 amino acidsand 2 monomers.
This process transforms activation energy and free-energy to another free-energy.Synthesis of a protein enzyme in an active site of a ribosome of a cell using at least 3 amino acids and 2 monomers.
Thisprocess transforms activation energy and free-energy to another free-energy.Figure 2: An example input bundle and the three outputs generated by our system for this inputSNP ?
SRX[1]agentVPV RX[2]objectPP PP PP PPP RX[3]destinationP RX[4]instrumentP RX[5]originP RX[6]pathSS?
S PunctPunct N VPthisprocessV RX[7]requireraw-materialRXRX?
P RX[8]ofhas-partFigure 3: Tree selectionof event-to-entity relations and sentences would begiven based on encoding guidelines used to cre-ate the knowledge base.
However, the goal ofour project is to continuously expand the knowl-edge base with more information, encoding newtypes of events, and enriching existing events withmore detail as we go along (e.g., by specifying en-ergy consumption and regulation mechanisms forprocesses), therefore our encoding guidelines arecontinuously revised.
In order to produce output,our realizer requires a generation lexicon, whichmaps sets of relations onto elementary trees in thegrammar.
Determining this mapping would re-quire knowing the number of entities that can be23associated with each event type, and the relationsthat can be used to express them.
However, be-cause our knowledge base is continuously chang-ing, neither the number of entities linked to spe-cific events, nor the types of relations used arestable and therefore it was impossible to buildsuch a generation lexicon from the KB.
Instead,we adopted an approach where we detect ?eventframes?
in the input of the system, and automat-ically create entries for them in the generationlexicon, guessing sentence structure and orderingbased on the event participants.
An event frameis a set of event-to-entity relations which have thesame event in the domain of the relations, and par-ticipating entities in the range.
We currently dis-tinguish between two types of event frames, de-pending on the type of the entities in the range ofrelations: participant frames (ranges are of typeTangible-Entity) and energy frames (ranges aretype Energy).
An example of a participant frameand an energy frame extracted from the input il-lustrated in section 4.2 is illustrated below:Participant frame:(Uptake07 path Plasma-membrane78)(Uptake07 origin Extracellular-Side52)(Uptake07 destination Cytoplasm39)(Uptake07 agent Cell-Surface-Receptor79)(Uptake07 instrument Coated-Vesicle49)(Uptake07 object Cholesterol08)Energy frame:(Uptake07 raw-material Chemical-Energy70)(Uptake07 raw-material Free-Energy89)Our input conversion module detects eventframes and automatically creates an entry inGenI?s generation lexicon for each frame, an-chored on a noun or verb associated with the eventin our concept-to-word mapping lexicon.
The en-tries link the sets of relations in the frame to a treewith the same number of arguments, attemptingto place entities that play agent and object par-ticipants into subject/object positions in the tree ifthey exist.
Our algorithm also attempts to deter-mine the best syntactic construction for the spe-cific combination of participant relations, and de-cides between selecting an active sentential tree,a passive sentential tree, a complex noun phrase,or a combination of these.
This process also in-volves deciding based on the event participantswhether the tree will be anchored on a transitiveverb, an intransitive verb, or a verb with a prepo-sitional object, and assigning default prepositionsto event participants (unless we have more detailspecified in the lexicon, as described in the nextsection).
The elementary trees in the grammarare named after the number of referring expres-sions and prepositional phrases in the tree, and weuse this naming convention to automatically gen-erate tree names (or tree family names) for lexi-cal entries, thereby linking trees in the grammar toGenI?s generation lexicon.
The two S-rooted treesin Fig 3 were selected based on automatically gen-erated lexical entries for the two frames above.4.1 RealisationThe GenI surface realizer selects elementary TAGtrees for (sets of) relations in its input and com-bines them using the standard operations of sub-stitution and adjunction to produce a single de-rived tree.
We have developed a feature-based lex-icalized Tree Adjoining Grammar to generate sen-tences from relations in the KB.
Our grammar hastwo important properties, following the approachin (Banik, 2010):(1) our grammar includes discourse-level elemen-tary trees for relations that are generated in sepa-rate sentences, and(2) instead of the standard treatment of entities asnouns or NPs substituted into elementary trees,our grammar treats entities as underspecified re-ferring expressions, leaving the generation of nounphrases to the next stage.
The underspecified re-ferring expressions replace elementary trees in thegrammar, which the generator would otherwisehave to combine with substitution.
This under-specification saves us computational complexityin surface realisation, and at the same time allowsus to make decisions on word choice at a laterstage when we have more information on the syn-tax of the sentence and discourse history.The output of the realizer is an underspecifiedtext in the form of a sequence of lemma - featurestructure pairs.
Lemmas here can be underspeci-fied ?
instead of an actual word, they can be an in-dex or a sequence of indices pointing to conceptsin the KB.
The syntax and sentence boundariesare fully specified, and the output can be one ormore sentences long.
The feature structures asso-ciated with lemmas include all information neces-sary for referring expression generation and mor-phological realisation, which is performed in thenext phase.
To give an example, the set of rela-tions below would produce an output with 8 un-derspecified referring expressions (shown as RX),distributed over two sentences:(Uptake07 path Plasma-membrane78)(Uptake07 origin Extracellular-Side52)24(Uptake07 destination Cytoplasm39)(Uptake07 agent Cell-Surface-Receptor79)(Uptake07 instrument Coated-Vesicle49)(Uptake07 object Cholesterol08)(Uptake07 raw-material Chemical-Energy70)(Uptake07 raw-material Free-Energy89)NP(Uptake07) ?
RX[1] absorb RX[2] to RX[3] of RX[8]with RX[4] from RX[5] through RX[6].
This process re-quires RX[7].The elementary trees selected by the realizer forthis output, and the correspondences between re-lations and referring expressions are illustrated inFig.3.4.2 Referring Expression GenerationThe final stage in the NLG pipeline is performingmorphological realisation and spelling out the re-ferring expressions left underspecified by the real-isation module.
The input to referring expressiongeneration is a list of lemma - feature structurepairs, where lemmas are words on leaf nodes inthe derived tree produced by syntactic realisation.In our system, some of the lemmas can be unspec-ified, i.e., there is no word associated with the leafnode, only a feature structure.
For these cases, weperform lexicon lookup and referring expressiongeneration based on the feature structure, as wellas morphological realisation.
To give an example,the input illustrated in the previous section will begenerated as?Uptake of cholesterol by human cell?
a cellsurface receptor absorbs cholesterol to the cyto-plasm of a human cell with a coated vesicle froman extracellular side through a plasma membrane.This process requires chemical energy and free-energy.
?Many concept labels in our ontology are verycomplex, often giving a description of the conceptor the corresponding biology terminology, andtherefore these labels can only be used for NLGunder specific circumstances.
To overcome thisproblem, we have created a lexicon that maps con-cept names to words, and the grammar has controlover which form is used in a particular construc-tion.
Accordingly, we distinguish between twotypes of underspecified nodes:?
NP nodes where the lexical item for thenode is derived by normalizing the conceptclass associated with the node (Uptake-Of-Cholesterol-By-Human-Cell ?
?uptake ofcholesterol by human cell?)?
RX (referring expression) nodes where lex-ical items are obtained by looking up classnames in the concept-to-word mapping lexi-con (Uptake-Of-Cholesterol-By-Human-Cell?
?absorb?
)The feature structures on RX nodes in the out-put of GenI describe properties of entities in the in-put, which were associated with that specific nodeduring realisation.
The feature structures specifythree kinds of information:?
the identifier (or a list of identifiers) for thespecific instances of entities the RX noderefers to?
the KB class for each entity?
any cardinality constraints that were asso-ciated with each entity for the relation ex-pressed by the tree in which the RX node ap-pearsWe define cardinality constraints as a triple (Do-main, Slot, Constraint) where the Constraint itselfis another triple of the form (ConstraintExpres-sion, Number, ConstraintClass).
ConstraintEx-pression is one of at least, at most, or exactlyand ConstraintClass is a KB class over which theconstraint holds.
There is usually (but not neces-sarily) one or more relations associated with ev-ery cardinality constraint.
We say a triple (Do-main Slot Range) is associated with a cardinalityconstraint (Domain, Slot, (ConstraintExpression,Number, ConstraintClass)) if?
the Domain and Slot of the associated tripleis equal to the Domain and Slot of the cardi-nality constraint and?
one of the following holds:?
either (Range instance-of Constraint-Class) holds for the range of the triple?
or Range is taxonomically related toConstraintClass (via a chain of subclassrelations)We define a referring expression language(Fig.
4) which describes groups of instance names(variables) that belong to the same KB class, andthe associated cardinality constraints.
Groupsthemselves can be embedded within a larger group(an umbrella), resulting in a complex expressionwhich gives examples of a concept (e.g., ?threeatoms (a carbon and two oxygens)?).
Expressions25<refex> = <umbrella> SPACE <refex> | <umbrella><umbrella> = <group> ( <refex> )| <group><group> = <class> <instances> <constraints><instances> = :: <instance> <instances> | <instance><constraints> = : <constraint> <constraints> | <constraint><constraint> = <op> : <num> | unk : <dash-delimited-string><op> = ge | le | eqFigure 4: Syntax of the referring expression languagein this language are constructed from triples dur-ing the input conversion stage, when we performsemantic aggregation.
The groups are then passedthrough elementary trees by the realisation module(GenI) to appear in the output as complex featurestructures on leaf nodes of the derived tree.
The re-ferring expression generation module parses thesecomplex feature values, and constructs (possiblycomplex) noun phrases as appropriate.To illustrate some examples, the following fea-ture value shows a simple referring expressiongroup which encodes two entities (Monomer14and Monomer7) and two cardinality constraints (atleast 2 and at most 5).
This expression will be gen-erated as ?between 2 and 5 monomers?
:Monomer::Monomer14::Monomer7:ge:2:le:5We also allow more complex cardinality con-straints which give the general type of an entityand specify examples of the general type, as in ?atleast 3 organic molecules (2 ATPs and an ethyl al-cohol)?
:Organic-Molecule:ge:3(ATP:: ATP80938:eq:2Ethyl-Alcohol:: Ethyl-Alcohol80922)The referring expression generation modulemakes three main decisions based on the refer-ring expression, additional feature structures onthe node, and discourse history: it chooses lem-mas, constructs discriminators, and decides be-tween singular/plural form.
The algorithm for dis-criminator choice in the referring expression gen-eration module is illustrated in Fig 5.
Our refer-ring expression generation module, including dis-course history tracking and determiner choice, ismade available in the Antfarm3 open source tool.5 Giving Domain Experts Control overSentence StructureBy automatically associating event frames with el-ementary trees we are able to generate a sentencefor all combinations of event-to-entity relations3https://github.com/kowey/antfarmFigure 6: Parameters in the concept-to-word map-ping lexiconwithout having to maintain the grammar and gen-eration lexicon of the realizer as the knowledgebase evolves.
However sentences generated thisway are not always well-formed.
Events in theKB can be realized with a wide range of verbs andnouns, which require different prepositions or syn-tactic constructions, and different types of eventsmay require different participants to be their gram-matical subject or object.
To give an example, forevents that have an agent, in the majority of thecases we get a grammatical sentence if we placethe agent in subject position.
If the frame lacksan agent but has an object, we can usually gener-ate a grammatical passive sentence, with the ob-ject participant as the subject.
However, it is oftenthe case that events do not have an agent, and weget a grammatical (active) sentence by placing an-other relation in the subject position e.g., base forthe event Store or instrument for Block.
Which26for each group in the referring expression doif all members of the group are first mentions and there are no distractors in the history: thenif the group has cardinality constraints: thenupper bound M ?
at most Mlower bound N ?
at least N (multiple group members in this case are also interpreted as lower bound)both bounds?
between N and M or exactly Nelseone group member?
generate an indefinite determiner (a/an)more than one member?
generate a cardinalend ifend ifif the group is a first mention but there are distractors in the discourse history thenif the group has only one member thenif the group exactly matches one previous mention?
anotherif the group exactly matches N > 1 previous mentions?
the Nthif there is a 2-member group in the history, and one of the members was mentioned by itself?
the otherif the discourse history has more than one distractor?
a(n) Nthend ifif there are multiple group members thenif the group is a subset of a previously mentioned group which has no distractors?
N of theend ifend ifif the group is not a first mention thenif the group has upper and/or lower bounds?
the sameif the group has one member only?
theif the group has multiple members?
the Nend ifend forFigure 5: Algorithm for discriminator choice in our referring expression moduleevent participant can appear in subject and ob-ject positions depends not only on the type of theevent, but also on the encoding guidelines whichare continuously evolving.In order to improve the quality of the gener-ated output, and to give domain experts controlover customizing the system without having to un-derstand details of the grammar, we extended theconcept-to-word mapping lexicon with parameterswhich control preposition choice, and allow cus-tomization of the position of participating entities.We developed a graphical user interface which al-lows encoders (biology domain experts) to addand edit these lexical parameters as they encodeconcepts in the KB.To give an example, in the absence of a lexicalitem and any parameters for the event Glycogen-Storage, our system would produce the followingdefault output, attempting to use the concept labelas the main verb of the sentence in an automati-cally produced generation lexicon entry:?Glycogen storage ?
glycogen is glycogenedstorage in a vertebrate in a liver cell and a musclecell.
?In order to improve the quality of the output, oneof our biology teachers has customized the param-eters in the lexicon to yield:?Glycogen storage ?
glycogen is stored by aFigure 7: Concept map for the event ?Reduction?vertebrate within a liver cell and a muscle cell.
?This was achieved through a graphical user inter-face which is part of the tool used for knowledgeencoding, and is illustrated in Fig 6.
Our sys-tem allows encoders to re-generate sentences af-ter editing the parameters to see the effect of thechanges on the output.
The top half of the win-dow in in Fig 6 allows encoders to associate wordsor phrases with concepts, where they can add asmany synonyms as they see fit.
One of the syn-onyms has to be marked as the primary form, tobe used for generation by default.4 For events,4The concept-to-word mapping lexicon is shared betweenthe question interpretation and the NLG module, and the ad-ditional synonyms are currently only used for mapping ques-27(a) ?Plastocyanin reduces P700+?
(b) ?P700+ receives an electron from plastocyanin.
?Figure 8: Concept-to-word mapping parameters for the two synonyms of Reductionthe primary form is a verb and its nominalization,and for entities it is a noun.
The bottom half ofthe window shows the parameter settings for eachsynonym associated with the concept.
Here theencoders can specify relations which link the sub-ject and object of a verb to the event (grammaticalsubject/object), and assign prepositions to otherevent-to-entity relations for the verb, when it isused to realize the specified event.
There is alsoan option to tell the NLG system to ignore someof the event participants when using a specific verbfor the event.
This functionality is used for verbsthat already imply one of the participants.
For ex-ample, the word polymerization already impliesthat the result of the event is a polymer.
In thesecases there is no need for the NLG system to gen-erate the implied participant (here, result).
An-other example is the verb reduce, which impliesthat the object of the event is an electron.
The ed-itor allows the users to enter different parametervalues for the synonyms of the same event.
Forexample, the graph in Fig 7 could be described inat least three different ways:1.
P700+ is reduced by plastocyanin2.
Plastocyanin reduces P700+3.
P700+ receives an electron from plastocyanin.Here sentences 1 and 2 make no mention of theelectron involved in the process, but sentence 3 ex-plicitly includes it.
In order for the system to cor-rectly generate sentences 1 and 2, the concept-to-word mapping parameters for ?reduce?
(as a syn-onym for Reduction) have to include an impliedparticipant.
Otherwise the system will assume thatall participants should be mentioned in the sen-tence, and it will generate ?P700+ is reduced bya plastocyanin of an electron?.
Fig 8. illustratesthe different concept-to-word mapping parametersneeded for the two synonyms for Reduction in or-der to generate the above sentences correctly.tions onto concepts in the KB.6 ConclusionsWe have presented an NLG system which gen-erates complex sentences from a biology KB.Our system includes a content selection module,which tailors the selected relations to the contextin which the output is displayed, and allows thepresentation module to send parameters to influ-ence properties of generated outputs.
We have de-veloped a referring expression generation modulewhich generates complex noun phrases from ag-gregated cardinality constraints and entities in theinput, and keeps track of discourse history to dis-tinguish mentions of different groups of concepts.Our system allows biology teachers to detect in-consistencies and incompleteness in the KB, suchas missing cardinality constraints, errors wheretwo instances of the concept were added unnec-essarily (unification errors on entities), and miss-ing or incorrect relations.
To make the systemrobust, we have developed an algorithm to pro-duce sentences and complex noun phrases for un-seen combinations of event-to-entity relations inthe KB by automatically generating entries in thelexicon of the GenI surface realizer.
Our algorithmmakes default decisions on sentence structure andordering based on relations sent to the NLG sys-tem, expressing the event?s participants.
To allowdomain experts to easily improve the default out-puts generated by our algorithm, we have defineda framework for adding lexical parameters to con-cepts, which allow non-NLG-experts to customizethe structure of generated sentences for events inthe KB as they are encoded.
Although our systemcurrently only produces one or two possibly com-plex sentences, it was designed to ultimately gen-erate paragraph-length texts.
This can be achievedsimply by adding more discourse-level elementarytrees to the grammar of the realizer, since our sys-tem is already able to handle referring expressionsacross sentence boundaries.28ReferencesE.
Banik.
2010.
A Minimalist Architecture for Gener-ating Coherent Text.
Ph.D. thesis, The Open Univer-sity, UK.K.
Barker, B. Porter, and P. Clark.
2001.
A library ofgeneric concepts for composing knowledgebases.
InProceedings K-CAP 2001, pages 14?21.K.
Bontcheva and Y. Wilks.
2004.
Automatic reportgeneration from ontologies: the MIAKT approach.In 9th Int.
Conf.
on Applications of Natural Lan-guage to Information Systems, page 324335, Manch-ester, UK.K.
Bontcheva.
2004.
Open-source tools for creation,maintenance, and storage of lexical resources forlanguage generation from ontologies.
In 4th Conf.on Language Resources and Evaluation, Lisbon,Portugal.D.
Galanis and I. Androutsopoulos.
2007.
Generat-ing multilingual descriptions from linguistically an-notated owl ontologies: the NaturalOWL system.
InINLG07, Schloss Dagstuhl, Germany, page 143146.D.
Gunning, V. K. Chaudhri, P. Clark, K. Barker, Shaw-Yi Chaw, M. Greaves, B. Grosof, A. Leung, D. Mc-Donald, S. Mishra, J. Pacheco, B. Porter, A. Spauld-ing, D. Tecuci, and J. Tien.
2010.
Project halo up-date - progress toward digital aristotle.
AI Magazine,Fall:33?58.A.
K. Joshi and Y. Schabes.
1997.
Tree-AdjoiningGrammars.
In Grzegorz Rosenberg and Arto Sa-lomaa, editors, Handbook of Formal Languagesand Automata, volume 3, pages 69?124.
Springer-Verlag, Heidelberg.E.
Kow.
2007.
Surface realisation: ambiguity anddeterminism.
Ph.D. thesis, Universite de HenriPoincare, Nancy.C.
Mellish and X.
Sun.
2005.
The semantic web asa linguistic resource: Opportunities for natural lan-guage generation.
In Knowledge-Based Systems.C.L.
Paris.
1988.
Tailoring object descriptions to theusers level of expertise.
Computational Linguistics,14(3):6478.
Special Issue on User Modelling.E.
Reiter, R. Robertson, and L. M. Osman.
2003.Lessons from a failure: generating tailored smok-ing cessation letters.
Artificial Intelligence, 144(1-2):41?58.A.
Spaulding, A. Overholtzer, J. Pacheco, J. Tien, V. K.Chaudhri, D. Gunning, and P. Clark.
2011.
Inquirefor ipad: Bringing question-answering ai into theclassroom.
In International Conference on AI in Ed-ucation (AIED).G.
Wilcock.
2003.
Talking owls: Towards an ontologyverbalizer.
In Human Lan- guage Technology forthe Semantic Web and Web Services, ISWC03, page109112, Sanibel Island, Florida.29
