KNOWLEDGE MANAGEMENT FOR TERMINOLOGY-INTENSIVEAPPLICATIONS: NEEDS AND TOOLSlngrid MeyerArtificial Intelligence Laboratory, Dept.
of Computer ScienceUniversity of Ottawa, Ottawa, Canada K 1N 6N5IXMAI.
@acadvm 1.uottawa.CAABSTRACTThis paper addresses the problem of how to provide support for the acquisition,formalization, refinement, retrieval - in other words, for the management - of theknowledge required for producing high-quality terminology.
This problem will becomeincreasingly significant as term banks evolve into knowledge bases.
Knowledgemanagement for terminology-intensive activities is complicated by two factors: 1) theimportance of encyclopedic as well as lexical-semantic knowledge, and 2) the widespectrum of working environments in which terminological ctivities can be carried out,from terminology as a distinct specialization atone end of the spectrum, to terminology aspractised in document-production at the other.
In the first two sections of the paper, webriefly analyze ach of the two complicating factors.
In the third section, we describe theterminological support hat is currently available and under development in a knowledgemanagement tool called CODE, which is being used to build a prototype, knowledge-based term bank called COGNITERM, designed to be useful across a spectrum ofterminology-intensive environments.. LEXICAL-SEMANTIC AND ENCYCLOPEDIC KNOWLEDGE INTERMINOLOGYTerminology is the practical discipline concerned with describing and namingconcepts in specialized domains.
The data produced by this process is, increasingly, storedin data bases known as term banks.
Since concepts are the starting point for all practicalterminology work, and since concepts are the building-blocks of knowledge, it follows thatterminology is a very knowledge-intensive activity: describing concepts involves acquiringknowledge about heir characteristics, and naming concepts involves matching conceptualcharacteristics with linguistic forms (i.e.
terms).
In fact, terminology is somewhat of amisnomer: most fundamentally, it is not the study of "terms", but rather of the knowledgeconveyed by the terms.Given the crucial role of knowledge in terminology, one needs to address thequestion of what kind of knowledge to include in term banks.
In the related iscipline oflexicography, the same question, formulated in relation to dictionaries and lexicons, hasresulted in the long-standing debate about differences between lexical-semantic (i.e.linguistic) and encyclopedic (i.e.
world, extra-linguistic) knowledge (1).
One viewpointhas been that dictionaries and encyclopedias should be conceived as distinct entities - hencethe apothegm "dictionaries are about words, encyclopedias re about hings".
Meaning-Text (MT) Lexicography (Mel'cuk 1988a/b), for example, makes a strict distinctionbetween lexical-semantic and encyclopedic knowledge on the basis of semantic features:those which are necessary and sufficient (in the mathematical sense) to a definition arelexical-semantic, while those that are superfluous are encylopedic, and banned from20definitions.
A contrasting point of view, expressed for example by McArthur (1986:pp.102-109) is that for certain purposes, it may be useful to produce ahybrid of dictionary andencyclopedia - in other words, an encyclopedic dictionary.
McArthur proposes that thedictionary-encyclopedia rel tionship be seen as a continuum rather than a dichotomy, andproposes the term micro-lexicography to designate the activity dealing with "the world ofwords...", and the term macro-lexicography to designate the activity which "shades outinto the world of things and subjects, and centres on compendia of knowledge...".Depending on the lexicographic framework and the intended user of the dictionary,a strict differentiation between lexical-semantic and encyclopedic knowledge can be notonly theoretically interesting, but also practically relevant: in the MT framework, forexample, it underlies virtually all aspects of lexicographic methodology.
Learners'dictionaries, on the other hand, whether they are aimed at learners of the mother tongue(i.e.
children's dictionaries) or learners of a foreign language, typically featureencyclopedic characteristics, such as pictures and a rich supply of examples, that areintended to supplement definitions.
Furthermore, the definitions themselves may includeinformation that exceeds the bounds of "necessary and sufficient".The lexical-semantic vs. encyclopedic debate is pertinent to terminology since thisdiscipline is closely linked to lexicography in purpose and method.
In our view,terminology is clearly macro-lexicographic (to use McArthur's term) in orientation: termbanks must include not only necessary and sufficient information about concepts, but also acertain amount of encyclopedic nformation as well.
The following are just some of thereasons for our view:Relationship to specialized omains.
Terminology is closely related to thespecialized omains of activity whose lexica it describes.
This is reflected in the basicorganization of term banks according to specialized omains (i.e.
subject fields).
Untilrecently, most terminology work was done by domain experts, and the increasing numbersof terminologists who are not domain experts till consider consultation with experts to becrucial to their work.
One of the goals of terminology is to provide assistance in theordering and use of terms within specialized omains.
Because of its relationship tolanguages for special purposes (LSPs), terminology has a need for subject classificationand thesaural structure.
In other words, it is closely linked to information science, withwhich it shares tools such as keywords, indexes and thesauri.The role of term banks as learning tools.
Although term banks can be consulted byusers with a wide range of domain expertise, by far the bulk of users are not domainexperts.
The largest user group has always been translators, who consult erm banks notonly for strictly linguistic information (e.g.
part-of-speech, morphology, target-languageequivalent), but also for conceptual information (e.g.
conceptual characteristics, relations toother concepts), since it is well known that a certain depth of understanding of the domainis necessary to use its terminology correctly.
Term banks can be seen as learning tools forthe terminologists themselves, for example, when they are assigned a new field in whichthey have little knowledge, or when they are working in a field that is highly influenced byneighboufing fields with which they are not very familiar.
Because of the teaching role ofterm banks, definitions are often complemented byexamples of terms in context, much inthe same way that learners' dictionaries are.
Like encyclopedias, terminologicalpublications often include pictures and diagrams.The multilingual spect of terminology.
All the large term banks that currently existare multilingual, and this tendency will most likely remain in the face of the increasingimportance of international communication for trade and knowledge communication.
It iswell known that establishing lexical equivalence between different languages i  oftenimpossible on the basis of lexical-semantic information alone.
To take a well-knownexample from general anguage, the word river is defined in Webster's Ninth NewCollegiate Dictionary as "a natural stream of water of considerable volume".
French,however, distinguishes between flowing bodies of water that empty into the ocean (fleuve)21and those that empty into a lake or another flowing body of water (rividre) - informationthat would be considered encyclopedic f one applied the necessary-and-sufficient rule.The need for multifun~tional term banks.
In keeping with the increasing emphasison the shareability of lexical resources in general, term banks will have to aim at meetingthe needs of more and more user types, including machines (Freibott and Heid 1990,McNaught 1990, Meyer 1991).
Machine uses (e.g.
machine translation, expert systems,NL interfaces to databases) will require very large quantities of explicitly representedconceptual information, since they do not possess much of the world knowledge thathumans know implicitly.Because of the important encyclopedic dimension of terminology, we feel that aterm bank can be conceived as a kind of knowledge base, and we are currently in theprocess of designing aprototype knowledge-based term bank, called COGNITERM, in theArtificial Intelligence Laboratory of the University of Ottawa, Canada.
COGN1TERM willbe constructed using a knowledge ngineering tool called CODE (Conceptually OrientedDesign Environment, Skuce et al 1989), that has already been tested in two terminology-intensive environments, where a number of small knowledge bases (several hundredconcepts) were constructed.
Before discussing the research in progress for theCOGNITERM project (Section 3), we will briefly describe some of the knowledgemanagement needs that our research isaiming to fill..
KNOWLEDGE MANAGEMENT NEEDS ACROSS THETERMINOLOGY SPECTRUMAs explained above, the knowledge management problem in terminology isheightened by the fact that persons doing terminology need to manage both lexical-semanticand encyclopedic knowledge.
This problem is further complicated by the fact thatterminology is a very heterogeneous discipline, since the naming and description ofspecialized concepts can be carried out in a wide spectrum of working environments,dictating various types of knowledge management support.
At one end of this spectrum iswhat we might call the most "pure" form of terminology, namely terminology practised asa distinct specialization.
In this type of environment, we find persons officially designatedas terminologists, often with professional training and/or certification in terminology (2),following a controlled methodology (3).
At the other end of the spectrum we find a muchmore "casual" form of terminology as it is practised as a component of document-production.
Here, the naming and description of concepts i  carried out at various "links"in a "chain" of activities, which can include product design specification, technical writing(e.g.
user manuals), revision, proofreading, translation, management information, etc.Normally, many of the persons involved in these activities have no specialized training interminology, their methodology can be highly informal, and there may be no centralizedrepository for the terminological data.The technology and methodology we are developing for terminology-orientedknowledge management support are intended to be generic enough to be useful across thespectrum of terminology environments.
The various knowledge management (KM) needsthat characterize the two ends of the spectrum are examined in turn below.2.1 Termino logy  as a Dist inct Special izat ionThis type of environment is typified by organizations such as the Department of the?
Secretary of State of Canada, which has had an official terminology service since 1953,22employing up to 80 staff terminologists preparing up to 4,000 terminology records a week(4).
The mission of these terminologists i to facilitate the proper use of terms, in Englishand French, throughout the Public Service of Canada.
To this end, terminologists maintainwhat is now the largest erm bank in the world (about one million database records).
Theyalso prepare bilingual glossaries (which are often published) on subject areas requested byclients, and respond to inquiries from clients on specific problems.
The terminological datathat is collected can be conceptual or linguistic (5): conceptual data includes informationsuch as subject-field labels, synonyms and antonyms, definitions, and equivalents in thesecond language; linguistic data includes information such as part-of-speech,morphological anomalies, usage labels, and idiomatic expressions.
Terminologists inenvironments such as this one most often work thematically (6): in other words, theycollect and describe (as exhaustively as practical constraints allow) the specialized termsused in a given field.The major challenge of terminology is conceptual, not linguistic: terminologists aretrained in linguistics and thus are properly prepared for the linguistic dimension of theirtask; in contrast, they are not normally domain experts, yet they require a substantialamount of expert knowledge in order to do their work.
In other words, the major difficultyis pinning down the meanings of terms.
Compounding their problem is the fact thatterminologists can be required to work in several fields simultaneously, or to change fieldsfrequently depending on clients' needs.In the following paragraphs, we summarize (7) the four components of aterminologist's work in terms of the KM tasks on the one hand, and the roles of thisknowledge in the production of terminology records on the other.2.1.1 Selection of documentationKM tasks.
Before any collection or analysis of terms can occur, terminologistsmust select he knowledge sources for the project.
Given their linguistic orientation, theyhave traditionally preferred texts as knowledge sources, although the collaboration ofexperts is also highly valued.
Before collecting the documentary corpus, terminologistsacquire some general knowledge about the field by doing introductory reading intextbooks, encyclopedia rticles, popularizing journals, etc.
They begin to familiarizethemselves with the general knowledge structures of the field, trying to determine itsboundaries, subdivisions, and areas of overlap with other fields (for multidisciplinaryfields).
Often, at this stage, terminologists will sketch out these "skeletal" knowledgestructures in the form of a concept network.
They will also make mental or written noteson a number of individual concepts which emerge as being particularly important.Roles of knowledge.
These preliminary KM activities are crucial to the selection ofthe documentary corpus since they help to clarify the project's cope: a clear idea of theconceptual boundaries of the field helps delimit the range of documentation to be sought.Determining areas of overlap with other fields also helps terminologists establish links withrelated documentation.
When the terminologists are ready to begin the search for thedocumentary corpus, a clear idea of the major subfields helps them orient their work alonga number of documentary "paths", which may be priontized according to users' needs.The names of subfields, of key concepts, and of the characteristics of these concepts helpprovide specific points of entry into the documentation.
Having a general idea of thehierarchical structure of the field also helps orient the process of documentation selectionsince terminologists end to proceed from general to more specific literature.Once a preliminary corpus is obtained, their general knowledge of the domainprovides terminologists with a yardstick for judging its quality.
It also helps them classifydocumentation according to subfield.
In multilingual terminology, classification accordingto subfield is particularly important: to "manage" the large amounts of documentation tobescanned (see 2.1.2 below), terminologists very often work on one subfield at a time, inone language and then in the other, before proceeding to another subfield.23Finally, these preliminary conceptual activities provide terminologists with theconceptual framework and basic terminology needed for communicating with librarians andother documentation resource persons, as well as with experts.
Communication isparticularly important in the case of experts (8), who tend to be very busy: ifterminologists have done their "homework", they will be able to direct he conversation iorder to elicit the maximum information i  a minimum amount of time.
"Starting out onthe right foot" in this way boosts terminologists' credibility with experts, and increasestheir chances of convincing experts to remain involved as the project advances.2.1.2 Establishment of a nomenclatureKM tasks.
Once the documentation has been selected, it undergoes a process calledscanning, i.e.
careful reading, with the extraction (9) of potential terms along with theircontexts (10).
Additional research may be needed for specific problems (e.g.
terms notfound for concepts identified, terms with inadequate contexts), after which the data isorganized by grouping the various instances of a term, noting obvious cases of synonymy,abbreviations, usage labels, etc.
Through the scanning process, terminologists begin toanalyze (11) the general knowledge structures of the field, fleshing out (whether on paperor in the mind) the skeletal concept network drafted uring their background reading.
Theyalso begin to analyze the conceptual characteristics of individual terms (i.e.
the terms foundin the documentation), based on the contexts in which the terms appear.Roles of knowledge.
Drawing on their general understanding of the domain,terminologists begin identifying the lexical items that are specific to their field.
Thisprocess involves eliminating terms that would constitute "noise" in the terminology, i.e.lexical items that belong to general rather than specialized vocabulary, or terms that do notfall within the established boundaries of the field.
As well, terminologists must identifywhat are known as "silences," i.e.
lacunae in the preliminary terminology.
Asterminologists prepare to finalize the nomenclature (i.e.
to determine the terms for whichrecords will be prepared) and decide which contexts will be retained for analysis (2.1.3),the conceptual framework acquired so far will help them continue to communicate aboutproblem areas with documentation resource persons and domain experts.2.1.3 Preparation of term recordsKM tasks.
Using the established terminology and associated contexts,terminologists can begin a systematic analysis of terms-in-context.
The primary function ofthis analysis is to determine the meanings of the terms, although it also serves to identifyother linguistic characteristics such as part-of-speech, gender, frequency, geographicorigin, etc.
The conceptual goal at this stage is to achieve the depth of understandingneeded to complete the term records.
Terminologists carefully analyze the various contextsin which the terms have been found in order to identify a certain number of conceptualcharacteristics for all concepts.
These characteristics will then be compared with those ofpotentially related concepts (e.g.
synonyms, equivalents in the other language) in order todetermine those which are necessary for establishing a conceptual match.Roles of knowledge.
The most important application of conceptual analysis isdefinition construction.
If they are attempting the classic intensional (i.e.
genus-differentia)definition, terminologists will need to compare the characteristics of a given concept withthose of concepts at the same hierarchical level (i.e.
with the characteristics of the co-ordinate concepts (12)) in order to determine the distinguishing characteristics (i.e.
thedifferentia in an intensional definition).
Relations other than the generic-specific (e.g.whole-part, cause-effect, tool-function) may also be analyzed and reflected in definitions.Conceptual nalysis is also essential to identifying synonyms and equivalents in thesecond language.
Identifying synonyms requires a careful comparison of conceptualcharacteristics n order to determine that these are indeed identical for the terms in question.24When two concepts differ in only a very few (and not very significant) characteristics, theymay be designated as pseudosynonyms (e.g.
one concept may have one more characteristicthan another, and thus be more specific).
Establishing a conceptual match is also crucial tomultilingual terminology work, which is complicated by the fact that conceptual structuresoften do not correspond perfectly from one language to another, resulting in cases ofincomplete equivalence.
Sometimes there may be no equivalent in the other language at all,resulting in the need to create a neologism (13).
In this case, conceptual analysis isessential for determining whether the concept already exists within the current knowledgestructures of the target language, and when it does, what its characteristics are (since theconcept is so new, its characteristics, and consequently itslocation within the knowledgestructures, may still be fluctuating).
In many cases, an existing term will be adopted todesignate the new concept, and conceptual nalysis of the candidate terms is essential fordetermining which one possesses the greatest emantic compatibility with the new concept.2.1.4 Quality controlKM tasks.
Quality control can be achieved by two types of activity: revision andupdating.
On the one hand, before the project is completed, the various types ofinformation collected by the terminologist are revised by domain experts and otherterminologists (e.g.
terminologists with experience in neighbouring or related fields, ormore experienced terminologists).
On the other hand, after the project is completed, aperiodic updating of terminology records can occur whenever this is justified by changesand expansion in the domain.
Revising the results of a terminology project involvesanalyzing and discussing specific conceptual problems identified by the experts and/orother terminologists.
Periodic updating implies a monitonng of changes in knowledgestructures and conceptual characteristics.Roles of knowledge.
To facilitate revision, terminologists need a soundunderstanding of the domain in order to interpret feedback from experts, and to elicitinformation on this feedback (e.g.
when terminologists do not understand feedback, whenthe feedback contradicts what the terminologists found, or when experts give conflictingfeedback).
Regarding updating, a clear understanding of the current state of the knowledgewill give the terminologist a basis for comparison when new structures and conceptualcharacteristics emerge.
Conceptual problems increase when a field is particularly large orhas complex knowledge structures, or when the field is changing rapidly.2.2 Terminology as a Component of Document-ProductionBy document-production, we mean a "chain" of writing activities that are carriedout from the inception of a product (14) to the production of public (or widely available)written information about his product.
The "links" in a document-production chain can bedistributed throughout an organization, and the actual "documents" in various states ofcompletion.
These documents can include anything from product designers' roughpersonal notes, to intermediate "current state" documents used to coordinate members of ateam, to "official" publications (e.g.
technical manuals produced by technical writers), totranslations of these official publications.Although there are usually no officially designated terminologists in this type ofenvironment, terminology-intensive activities are pervasive nonetheless: concepts aredescribed and named by persons such as product designers, technical writers,proofreaders, revisers, abstracters, management information specialists, public relationsofficers, and translators (15).
Given the heterogeneity of this type of environment, theterminology-related KM problems are much more complex than they are in the "purer"form of terminology work described above.
The following are just some of the issues thatcontribute to this complexity.252.2.1 MethodologyGiven the variety of people involved in document-production, this kind ofenvironment typically exhibits a lack of consistent methodology for terminology work.This problem is particularly crucial at the early stages of document-production.
Forexample, product designers carry a heavy burden of defining and naming concepts, buthave no formal training (and very often, no interest!)
in terminology.
Terms that arechosen "on the fly" easily become ntrenched, even though they may be inappropriate.Normally, this type of environment does not stress a methodology for assuring that termsare clearly described and logically named, nor that the consistent use of approvedterminology is enforced.2.2.2 Coordination between links in the document-production chainGiven the number of people that can be involved in document-production,coordinating the various links in the chain is a fundamental problem.
Writers in a givenlink in the chain may, for example, have trouble understanding what the originator ofcertain terms actually meant by them.
If it is impossible to contact he originators ofknowledge personally, the meanings of terms may have to be reconstructed from scantresources.
Knowing that a given document will soon be passed on to another link in thechain, documentors are easily tempted not to resolve terminological problems that they haveinherited, leading to a "pass-my-confusion-onto-the-next-person" phe omenon.Complicating things is that documents do not flow in a one-way direction from inception tofinalization; documentors, consequently, can be sent in loops.
Common terminologicalproblems resulting from this situation are inconsistency (terms being used to mean differentthings by different people), and overloading.
(terms used in too many different senses).Coordination is also complicated by the fact that concepts exist at different levels of"clarity" at the various links in the chain: at the initial design stage, they may still be quitefuzzy; by the time they are documented in some kind of "official" text, their conceptualcharacteristics should be (in pnnciple, at least!)
much clearer.
From a terminological pointof view, this conceptual fluidity means a continuous evolution of concept definitions andnames from one link in the document-production chain to the next.2.2.3 Centralization of terminological dataMost organizations do not maintain centralized repositories (e.g.
term banks) ofterminological data.
When such repositories do exist, they often take the form of informalglossaries that may be out of date, not validated by experts and/or professional writers,and not used consistently throughout the organization.
This state of affairs places a heavyonus on the documentor to find out who originated certain terms, what the terms mean,how they should be used in context, how they should be translated, and so on.
The lack ofcentralization f terminological data (particularly conceptual data) is particularly problematicfor people who are at the end Of the document-production chain - for example, the editors,proofreaders, and translators (16): they are the furthest away from the originators ofconcepts (and have the hardest time accessing these originators); the documents passed onto them are likely to have the greatest number of terminological problems (due to the "pass-my-confusion-onto-the-next-person" phe omenon mentioned above); and finally, thesepeople usually have the least amount of domain expertise (editors, proofreaders andtranslators are typically language xperts, not domain experts).
A lack of centralizedinformation about erms is also a drawback for newcomers to a project, since it forces themto acquire knowledge about erms almost from scratch.263.
A GENERIC TOOL FOR TERMINOLOGY-ORIENTEDKNOWLEDGE MANAGEMENTAs has been argued elsewhere (e.g.
Ahmad et al 1989, Czap and Nedobity 1990,Meyer and Paradis 1991, Parent 1989, Skuce and Meyer 1990a/b, Wijnands 1989), theknowledge management problems of terminology are not unique to this field.
Rather, theyare general problems of knowledge ngineenng that are now receiving extensive attentionin the literature of AI.
The AI research group at the University of Ottawa, Canada, hasover the past few years developed a generic knowledge ngineering tool called CODE(Conceptually Oriented Design Environment, Skuce et al 1989), which is written inSmalltalk and runs on a Macintosh, 386 or UNIX platform.
CODE can be described as ageneric knowledge manager, designed to assist any person (including the non-expert) facedwith the task of acquinng, formalizing, refining and accessing the knowledge structures ofa specialized omain.
CODE allows the user to construct a knowledge base whichdescribes concepts in frame-like units called CDs (concept descriptors) that are normally,though not necessarily, arranged in inheritance hierarchies.CODE has been tested in two terminology applications: a bilingual vocabularyproject at the Department of the Secretary of State of Canada (Meyer and Paradis 1991,Skuce and Meyer 1990a/b) and a software documentation project at Bell NorthernResearch, the Canadian counterpart of Bell Labs (Skuce 1991).
These two environmentscorrespond to the two ends of the terminology spectrum described above.
Based on whatwe learned uring these experiences, we are now enhancing the system's terminologicalsupport in a new version of CODE (Version 4), expected to be operational in late 1991.Concurrently with system development, we are using CODE to build a prototype bilingualterm bank, called COGNITERM, with a rich, highly structured and easily accessibleknowledge component.
In a nutshell, this term bank can be described as a hybrid betweena traditional term bank (17) and a knowledge base.Since a general technical description of the current and forthcoming versions ofCODE are found elsewhere (Skuce et al 1989, Skuce and Meyer 1991), we shall justoutline below some of the features that are receiving particular attention i  light of the factthat we intend COGNITERM to facilitate the management of both lexical-semantic andencyclopedic information, and to be usable across the spectrum of terminologyenvironments.User interface.
Given the many different ypes of users that can be engaged interminology-intensive activities, and the fact that we see a knowledge-based term bank asboth a communication tool (e.g.
between terminologists, between terminologists andexperts, between the various "links" in a document-production "chain") and a teaching tool,the user interface has been a top priority in system development from the start.
Hence, thecurrent version of CODE is already user-tailorable, i.e., the same knowledge base isaccessible in different manners for different purposes.
For example, adomain expert or aterminologist who is highly experienced in a domain will have a different set of optionsthan a learner.
In the current version of CODE, we have also placed a strong emphasis ongraphical representation.
The system can easily produce various types of semantic netdiagrams, for both hierarchical and non-hierarchical relations.
The graphical displayupdates automatically when changes are made to the knowledge base, and offersmechanisms for focussing on certain parts of the knowledge base, highlighting specialconcepts (e.g.
concepts that are uncertain, unconfirmed, etc.
), and comparing andcontrasting knowledge substructures.
In CODE Version 4, Hypercard-like bit map imageswill be available, so that one can ask of a term "show me one", or of an image "what is thiscalled?
"Access to, and navigation through, the knowledge base.
Since a knowledge baseincorporates large amounts of encyclopedic nformation, and since different users will27require different information, it is important that the knowledge be easily accessible andnavigable.
A CODE knowledge base is essentially a hierarchically organized hypertext-likesystem, incorporating the notion of property inheritance.
One may navigate in whatevermanner is appropriate, with typical retracing abilities of hypertext systems.
Unliketraditional term banks, in which access is strictly terminological (i.e.
one must know a termin order to get conceptual information about it), CODE allows conceptual charactersfics tobe entry-points into the knowledge, so that one can ask questions like "what is the term forthe machine with function X", "what is the term for the material with physical properties X,Y, Z?"
Access to, and navigation through, the knowledge is facilitated by the graphicalcomponent described above, and also through a browsing capability.
In Version 4, thebrowser will use a basic window whose behaviour is modelled after an outline processor,with the ability to dynamically expand and contract ree-structures.
The user can easilytailor-make the browser to suit a given need.
To facilitate the use of terms as entry-pointsinto the knowledge, the current version of CODE has a search/rename browser that permitsscanning of the entire knowledge base for every occurrence of a term, and can be restrictedto certain contexts (e.g.
concept names, names of conceptual characteristics, descriptions ofconceptual characteristics) to speed up the search.
Version 4 will include a clearly definedset of terminological "status levels", by which we mean attributes of a term such as how itis used (e.g.
as a concept name or the name of a conceptual characteristic), whether it isdefined or not, whether it is used in definitions but is not a knowledge base concept orproperty, etc.Informal, trial-and-error knowledge xperimentation.
The system containsfeatures, which we are still developing, for managing knowledge that is in different statesof "clarity" (for want of a better term).
Lack of clarity may be due to several causes: forexample, a terminologist may be unclear about a concept because he/she does not have thedomain expertise to understand it properly; a technical writer, translator, etc.
in thedocument-production chain may be unclear about a concept because people at variouspreceding links in the chain have used a term inconsistently; a concept may be very new(e.g.
in the case of neologisms) and thus intrinsically unclear; and so on.
In all thesesituations, we find problems uch as what to call a concept, what the superconcept is,whatsubconcepts it has, what characteristics it has, what the similar concepts are.
CODEpermits rapid entry of hunches, guesses, trials, etc., followed by experimentation with theconsequences of entering new knowledge.
For example, superconcept links may bechanged on the graph just by dragging, and the consequences can be seen immediately intextual or graphical form.
One may ask for "similar" concepts, or potential terminologicalconflicts.
Previously made changes (up to three) can be discarded in one click.Multidimensionality.
It is well known that concepts and entire knowledgestructures can be "seen" from various "viewpoints" (18), which correspond roughly to theneeds or interests of the knowledge base user.
CODE offers a "masking" facility thatallows one to restrict what is visible in the knowledge base by Boolean conditions onconcepts and characteristics.
For example, different users might require different ypes ofknowledge about a certain laboratory procedure.
CODE allows one user to say "show meonly things about this laboratory procedure related to the tools that are required", andanother to say "show me only things related to the types of organisms that the procedurecan identify".
The masking facility also allows the notion of viewpoint o be extended toinclude a notion of depth of domain expertise.
For example, the user may requestinformation about the laboratory procedure that would be of interest (and understandable)to a beginning biology student, or to a seasoned researcher.Ranking of conceptual characteristics.
We are currently investigating theusefulness of ranking characteristics according to where they fall in the lexical-semantic/encyclopedic continuum.
For certain purposes (e.g.
users with different levels ofdomain expertise), it may be useful to at least distinguish between characteristics that arenecessary and sufficient, those that are encyclopedic but useful to establishing interlingual28equivalence, and finally, all other encyclopedic characteristics.
We are also investigating analgorithm proposed by Maybury (1990) for ranking characteristics according to conceptsimilarity on the one hand (e.g.
similarity of characteristics of co-ordinate concepts), andprototypicality on the other (e.g.
the degree to which a concept's characteristics arereflected in its subordinate concepts), which offers the possibility of generating definitionsof the genus-differentia type automatically.Multiple knowledge bases.
Facilities for managing multiple knowledge bases(under development for Version 4) are required in order to work in multidisciplinary fields,and in order to work multilingually (since knowledge structures rarely correspond perfectlyfrom one language to another).
Both situations require support for isolating areas ofcorrespondence and non-correspondence, and for comparing and contrasting.
Multilingualwork will require support for automatically generating some knowledge substructures (i.e.those that do correspond for the most part); eventually, this would involve a machinetranslation component.
CODE already includes a general high-level ontology, which isbeing regularly refined; it will eventually serve as a basis for integrating knowledge bases.Quality control.
The envisaged use of the system by various persons in aterminology environment ecessitates a ophisticated capacity for quality control.
CODEoffers a capacity for detecting conceptual inconsistencies of various types, carrying out typechecking, flagging entries as to source, entry person, date, state of correctness, etc.Database-like r trieval facilities permit queries uch as "show me all entries about laserprinters made by X since last month and not yet approved".
In order to ensureterminological consistency, CODE offers a number of features for assisting users innaming a conceptual characteristic (acommon terminological problem in knowledge basebuilding).
The system can display all currently used names of similar properties (e.g.
allproperties belonging to the same category of property), and will prompt if this propertyname has already been used elsewhere.SUMMARYWe have described two issues that must be considered in the development oftechnology for managing knowledge in terminology-intensive environments: 1) theimportance of encyclopedic as well as lexical-semantic knowledge, and 2) the widespectrum of working environments in which terminological ctivities can be carried out.We have also described a number of features currently available and under development ina generic knowledge management tool called CODE.
Many of the ideas describedrepresent work in progress related to the design of a prototype knowledge-based term bankusing the CODE system.
The problems are difficult, and our ideas constantly evolving:any comments on this work would therefore be warmly welcomed.ACKNOWLEDGEMENTSWe gratefully acknowledge the many useful suggestions of Douglas Skuce aboutthis paper specifically, and also about he general research framework (both technical andmethodological) for the COGNITERM project.
Roda Roberts provided some useful ideasfor Section 1 of this paper.
Karen Eck and Lynne Bowker helped with proofreading andtext preparation.The COGNITERM project (1991-1994) is supported by the Social Sciences andHumanities Research Council of Canada (SSHRC) and Research Services of theUniversity of Ottawa.
Testing of the CODE system in terminology-intensive environmentshas been supported by the Terminology and Linguistic Services Directorate of the29Department of the Secretary of State of Canada, and by Bell Northern Research.Development of the CODE system and associated methodology is being supported by theNatural Sciences and Engineering Research Council of Canada (NSERC), the UniversityResearch Incentives Fund (URIF) of the Government ofOntario, Bell Northern Research,and Research Services of the University of Ottawa.NOTES1.
Discussions of this debate as it has been articulated within a lexicographic frameworkcan be found, for example, in Bierwisch and Kiefer 1970, Haiman 1980, Frawley 1981.More references can be found in Haiman 1980.2.
In Canada, most erminologists have university-level training in Translation, since mostof them do bilingual (French-English) terminology.
Some universities ven offer an M.A.in Terminology.
Canada's largest professional organization of translators, the Socidtd estraducteurs du Qudbec, offers a standardized xam for certification i terminology.3.
For example, at the Terminology and Linguistics Services Directorate ofthe Departmentof the Secretary of State of Canada, an 85-page handbook prescribes the methodology.Questions of methodology are also outlined in some well-known textbooks onterminology, e.g.
Rondeau 1984, Wiister 1974, Sager 1990.4.
A general overview of the Terminology and Linguistic Services Directorate can befound in Gawn 1990.5.
We use the term linguistic (in opposition to conceptual) in the very general sense of'related to the terms, as opposed to the concepts designated by the terms'.
Of course, anyattempt to separate terms from concepts, while useful for analysis, is fundamentallyartificial: terms and concepts are intimately inked.6.
Thematic is opposed to term-oriented.
In the latter type of terminology, work is doneon isolated terms, normally in response to specific requests from clients.7.
A more detailed analysis can be found in Meyer 1991.8.
In effect, terminologists experience most of the problems of expertise licitationsummarized, for example, in Gaines 1990.9.
Semi-automation of the scanning process in terminology is the object of considerableresearch interest at the moment.
For an overview, cf.
Auger 1989.
Eventually, theknowledge management tool we envision would be integrated with technology for semi-automated scanning.10.
Noting a variety of contexts for the terms is extremely important in terminology, sincecontextual nalysis is the principal way in which terminologists determine the meanings ofterms, and also how they are used in context.
Most term banks include some contexts inthe terminology records.11.
We say begin to analyze because analysis is still not very deep at this stage, given thatscanning involves rather fast reading.
The cognitive processes that occur at this stage are30not yet very well understood, but we are assuming that some level of analysis, even if it ispartly unconscious, does happen.12.
According to the ISO International Standard 1087, a co-ordinate concept is a "conceptin a hierarchical system which ranks at the same level as one or more other concepts."13.
A neologism is a term that is used in a new sense.
Sometimes existing terms can beused (and just given an additional sense), and sometimes a totally new term is coined.14.
For terminological simplicity, we use the term product o include things like services,regulations, committee decisions, etc.
(and not just products in the strictest sense of theterm).15.
A more detailed overview of the various types of writing activities in a document-production chain can be found in Language Technology (April 1989, Special Issue onDocumentation).16.
Terminological problems are such an impediment to translation, and particularly tomachine translation, that many organizations are starting to impose an in-house "controlledlanguage" on their technical writers.
An interesting overview of this phenomenon can befound in Pogson 1988.17.
The traditional term bank we are using as a model is TERMIUM III, the Secretary ofState's bilingual (French-English) term bank.
COGNITERM will include all theinformation categories currently available in TERMIUM.18.
This idea is very similar to "view" in Murray and Porter 1989.REFERENCESAhmad et al 1989.
"Terminology and Knowledge Engineering: A SymbioticRelationship Explained".
Technical Report, KITES Project, University of Surrey,Guildford, Surrey.Auger, Pierre.
1989.
"lnformatique t terminologie: revue des technologiesnouvelles".
META 34, 3.Bierwish, M. and Kiefer, F. 1970.
"Remarks on Definitions in Natural Language".In: F. Kiefer (ed.
), Studies in Syntax and Semantics.
Dordrecht, Reidel, 55-79.Czap, Hans and Nedobity, Wolfgang (eds).
1990.
TKE '90: Terminology andKnowledge Engineering (2 vols).
Frankfurt: INDEKS Verlag.
(Proceedings of the 2ndInternational Congress on Terminology and Knowledge Engineering, Trier, Oct. 1990).Frawley, W. 1981.
"In Defense of the Dictionary: A response to Haiman."
Lingua55:1, pp.
375-383.Freibott, Gerhard, and Heid, Ulrich.
1990.
"Terminological nd Lexical Knowledgefor Computer-Aided Translation and Technical Writing".
Proceedings of the SecondInternational Conference on Terminology and Knowledge Engineering.
Frankfurt:INDEKS Verlag.Gaines, Brian.
1990.
"Knowledge Acquisition Systems," Knowledge Engineering(Vol.
1: Fundamentals), Hojjat Adeli, Ed.
New York: McGraw-Hill.31Gawn, Peter.
1990.
"Tools for Terminology".
META 33, 2, pp.
452-455.Haiman, J.
1980.
"Dictionaries and Encyclopedias".
Lingua 50:4, 329-357.Knowles, Francis.
1988.
"Lexicography and Terminography: A rapprochement?
"Zurilex '86 Proceedings.
Ed.
Mary Snell-Hornby.
Tubingen: Francke Publishers.Maybury, Mark T. 1990.
"Generating Natural Language Definitions fromClassification Hierarchies", Proceedings of the 1st ASIS SIG/CR Classification ResearchWorkshop, Toronto, pp.
101-108.McArthur, Tom.
1986.
Worlds of Reference: Lexicography, Learning and Languagefrom the Clay Tablet o the Computer.
Cambridge University Press.McNaught, John.
1990.
"Reusability of Lexical and Terminological Resources: StepsTowards Independence".
Proceedings of the International Workshop on ElectronicDictionaries (Oiso, Kanagawa, Japan, Nov. 1990).
Japan Electronic Dictionary ResearchInstitute Technical Report TR-031.Mel'cuk, Igor.
1988a.
"Principes et crit~res de description s6manfique dans le DEC".In: Dictionnaire xplicatif et combinatoire du fran#ais contemporain: recherches lexico-sdmantiques H. Mel'cuk et al Montreal: Presses de l'Universit6 de Montr6al.Mel'cuk, Igor.
1988b.
"Semantic Description of Lexical Units in an ExplanatoryCombinatorial Dictionary: Basic Principles and Heuristic Criteria".
International Journalof Lexicography, Vol.
1, 3.Meyer, Ingrid.
1991.
"Concept Management for Terminology: A KnowledgeEngineering Approach".
Paper presented at the ASTM Symposium on StandardizingTerminology for Better Communication: Practice, Applied Theory, and Results(Cleveland, Ohio, June 1991).Meyer, Ingrid and Paradis, Line.
1991 (in press).
"Applying Knowledge-EngineeringTechnology to Terminology: A Pilot Project".
Terminology Update.
Ottawa: Departmentof the Secretary of State of Canada.Meyer, Ingrid and Skuce, Douglas.
1990.
"Computer-Assisted Concept Analysis forTerminology: A Framework for Technological nd Methodological Research".
Paperpresented at the Fourth International Congress of the European Association forLexicography (EURALEX 90).
Malaga, Spain, Aug. 28 - Sept. 1, 1990.Meyer, Ingrid, Miller, David and Michaud, Diane.
1991 (in press).
"Terminologie etanalyse notionnelle assist6e par ordinateur".
Actes du colloque international sur lesindustries de la langue (Montreal, Nov. 1990).Murray, Kenneth and Porter, Bruce.
1989.
"Controlling Search for the Consequencesof New Information During Knowledge Integration".
Proceedings of the 6th InternationalWorkshop on Machine Learning.Parent, Richard.
1989.
"Recherche d'une synergie ntre d6veloppement li guistiqueinformafis6 et syst~mes xperts : importance d  la terminologie".
META, 34, 3.Pogson, Geoff.
1988.
"Controlled English: Enlightenment Through Constraint".Language Technology, Vol.
6, pp.
22-25.Rondeau, Guy.
1984.
Introduction d la terminologie.
Chicoufimi: G. Monn.Sager, Juan.
1990.
A Practical Course in Terminology Processing.Amsterdam/Philadelphia: John Benjamins.Skuce, Douglas.
1991 (in preparation).
"Experiences in Acquiring Knowledge AboutIndustrial Software" (working title).Skuce, Douglas.
1989.
"A Generic Knowledge Acquisition Environment IntegratingNatural Language and Logic".
Proceedings IJCAI Workshop on Knowledge Acquisition(Detroit, Aug. 1989).Skuce, Douglas and Meyer, Ingrid.
1990a.
"Concept Analysis and Terminology: AKnowledge-Based Approach to Documentation".
Proceedings of the ThirteenthInternational Conference on Computational Linguistics (COLING 90).32Skuce, Douglas and Meyer, Ingrid.
1990b.
"Computer-Assisted Concept Analysis:An Essential Component of a Terminologist's Workstation".
Proceedings of the SecondInternational Congress on Terminology and Knowledge Engineering Applications (TKE90), Frankfurt: INDEKS Verlag.Skuce, Douglas and Meyer, Ingrid.
1991.
"Terminology and Knowledge Acquisition:Exploring a Symbiotic Relationship".
Paper submitted to the 6th Banff KnowledgeAcquisition for Knowledge-Based Systems Workshop, to be held in Banff, Canada,October 1991.Skuce, Douglas and Monarch, Ira.
1990.
"Ontological Issues in Knowledge BaseDesign: Some Problems and Suggestions".
Proceedings of the 5th Workshop onKnowledge Acquisition for Knowledge-Based Systems (Banff, Canada, Oct. 1990).
Alsoavailable as Technical Report CMU-CMT-90-119, Centre for Machine Translation,Carnegie Mellon University, Pittsburgh.Skuce, Douglas, Wang, S., and Beauvill6, Y.
1989.
"A Generic KnowledgeAcquisition Environment for Conceptual and Ontological Analysis".
ProceedingsKnowledge Acquisition for Knowledge-Based Systems Workshop (Banff, Canada, Oct.1989).Vinay, J.-P. and Darbelnet, J.
1976.
Stylistique compar~e du fran~ais et de l' anglais:mdthode de traduction.
Paris: Didier.Wijnands, Paul.
1989.
"Syst~mes xperts et terminologie".
META, 34, 3.Wiister, Eugen.
1974.
"Die allgemeine Terminologielehre - in Grenzgebiet zwischenSprachwissenschaft, Logik, Ontologie, Informatik und den Sachwissenschaften".Linguistics 119 (1974), pp.
61-106.33
