The Generative LexiconJ ames  Puste jovsky"Computer Science DepartmentBrandeis UniversityIn this paper, I will discuss four major topics relating to current research in lexical seman-tics: methodology, descriptive coverage, adequacy of the representation, and the computationalusefulness of representations.
In addressing these issues, I will discuss what I think are someof the central problems facing the lexical semantics community, and suggest ways of best ap-proaching these issues.
Then, I will provide a method for the decomposition oflexical categoriesand outline a theory of lexical semantics embodying a notion of cocompositionality and typecoercion, as well as several evels of semantic description, where the semantic load is spreadmore evenly throughout the lexicon.
I argue that lexical decomposition is possible if it is per-formed generatively.
Rather than assuming a fixed set of primitives, I will assume a fixednumber of generative devices that can be seen as constructing semantic expressions.
I developa theory of Qualia Structure, a representation language for lexical items, which renders muchlexical ambiguity in the lexicon unnecessary, while still explaining the systematic polysemythat words carry.
Finally, I discuss how individual lexical structures can be integrated into thelarger lexical knowledge base through a theory of lexical inheritance.
This provides us withthe necessary principles of global organization for the lexicon, enabling us to fully integrateour natural anguage lexicon into a conceptual whole.1.
IntroductionI believe we have reached an interesting turning point in research, where linguisticstudies can be informed by computational tools for lexicology as well as an appre-ciation of the computational complexity of large lexical databases.
Likewise, com-putational research can profit from an awareness of the grammatical and syntacticdistinctions of lexical items; natural language processing systems must account forthese differences in their lexicons and grammars.
The wedding of these disciplines isso important, in fact, that I believe it will soon be difficult to carry out serious com-putational research in the fields of linguistics and NLP without the help of electronicdictionaries and computational lexicographic resources (cf.
Walker et al \[forthcoming\]and Boguraev and Briscoe \[1988\]).
Positioned at the center of this synthesis i  the studyof word meaning, lexical semantics, which is currently witnessing a revival.In order to achieve a synthesis of lexical semantics and NLP, I believe that thelexical semantics community should address the following questions:1.
Has recent work in lexical semantics been methodologically sounderthan the previous work in the field?2.
Do theories being developed today have broader coverage than theearlier descriptive work?Waltham, MA 02254Q 1991 Association for Computational LinguisticsComputational Linguistics Volume 17, Number 43.
Do current heories provide any new insights into the representation fknowledge for the global structure of the lexicon?4.
Finally, has recent work provided the computational community withuseful resources for parsing, generation, and translation research?Before addressing these questions, I would like to establish two basic assumptionsthat will figure prominently in my suggestions for a lexical semantics framework.The first is that, without an appreciation of the syntactic structure of a language,the study of lexical semantics i bound to fail.
There is no way in which meaningcan be completely divorced from the structure that carries it.
This is an importantmethodological point, since grammatical distinctions are a useful metric in evaluatingcompeting semantic theories.The second point is that the meanings of words should somehow reflect he deeper,conceptual structures in the system and the domain it operates in.
This is tantamountto stating that the semantics of natural language should be the image of nonlinguisticconceptual organizing principles (whatever their structure).Computational lexical semantics hould be guided by the following principles.First, a clear notion of semantic well-formedness will be necessary to characterize atheory of possible word meaning.
This may entail abstracting the notion of lexicalmeaning away from other semantic influences.
For instance, this might suggest hatdiscourse and pragmatic factors hould be handled ifferently or separately from thesemantic contributions oflexical items in composition.
1 Although this is not a necessaryassumption and may in fact be wrong, it may help narrow our focus on what isimportant for lexical semantic descriptions.Secondly, lexical semantics must look for representations that are richer than the-matic role descriptions (Gruber 1965; Fillmore 1968).
As argued in Levin and Rap-paport (1986), named roles are useful at best for establishing fairly general mappingstrategies to the syntactic structures in language.
The distinctions possible with theta-roles are much too coarse-grained to provide a useful semantic interpretation of asentence.
What is needed, I will argue, is a principled method of lexical decomposi-tion.
This presupposes, if it is to work at all, (1) a rich, recursive theory of semanticcomposition, (2) the notion of semantic well-formedness mentioned above, and (3) anappeal to several levels of interpretation in the semantics (Scha 1983).Thirdly, and related to the point above, the lexicon is not just verbs.
Recent workhas done much to clarify the nature of verb classes and the syntactic onstructionsthat each allows (Levin 1985, 1989).
Yet it is not clear whether we are any closer tounderstanding the underlying nature of verb meaning, why the classes develop asthey do, and what consequences these distinctions have for the rest of the lexiconand grammar.
The curious thing is that there has been little attention paid to the otherlexical categories (but see Miller and Johnson-Laird \[1976\], Miller and Fellbaum \[1991\],and Fass \[1988\]).
That is, we have little insight into the semantic nature of adjectivalpredication, and even less into the semantics of nominals.
Not until all major categorieshave been studied can we hope to arrive at a balanced understanding of the lexiconand the methods of composition.Stepping back from the lexicon for a moment, let me say briefly what I think the1 This is still a contentious point and is an issue that is not at all resolved inthe community.
Hobbs(1987) and Wilensky (1990), for example, argue that here should be no distinction betweencommonsense knowledge and lexical knowledge.
Nevertheless, I will suggest below that here aregood reasons, both methodological and empirical, for establishing just such a division.
Pustejovsky andBergler (1991) contains a good survey on how this issue is addressed bythe community.410James Pustejovsky The Generative Lexiconposition of lexical research should be within the larger semantic picture.
Ever sincethe earliest attempts at real text understanding, a major problem has been that of con-trolling the inferences associated with the interpretation process.
In other words, howdeep or shallow is the understanding of a text?
What is the unit of well-formednesswhen doing natural anguage understanding; the sentence, utterance, paragraph, ordiscourse?
There is no easy answer to this question because, except for the sentence,these terms are not even formalizable in a way that most researchers would agree on.It is my opinion that the representation f the context of an utterance should beviewed as involving many different generative factors that account for the way thatlanguage users create and manipulate the context under constraints, in order to beunderstood.
Within such a theory, where many separate semantic levels (e.g.
lexicalsemantics, compositional semantics, discourse structure, temporal structure) have in-dependent interpretations, the global interpretation f a "discourse" isa highly flexibleand malleable structure that has no single interpretation.
The individual sources of se-mantic knowledge compute local inferences with a high degree of certainty (cf.
Hobbset al 1988; Charniak and Goldman 1988).
When integrated together, these inferencesmust be globally coherent, a state that is accomplished by processes of cooperationamong separate semantic modules.
The basic result of such a view is that semanticinterpretation proceeds in a principled fashion, always aware of what the source of aparticular inference is, and what the certainty of its value is.
Such an approach allowsthe reasoning process to be both tractable and computationally efficient.
The repre-sentation of lexical semantics, therefore, should be seen as just one of many levels ina richer characterization f contextual structure.2.
Methods in Lexical SemanticsGiven what I have said, let us examine the questions presented above in more detail.First, let us turn to the issue of methodology.
How can we determine the soundnessof our method?
Are new techniques available now that have not been adequatelyexplored?
Very briefly, one can summarize the most essential techniques assumed bythe field, in some way, as follows (see, for example Cruse \[1986\]):?
On the basis of categorial distinctions, establish the fundamentaldifferences between the grammatical classes; the typical semanticbehavior of a word of category X.
For example, verbs typically behave aspredicators, nouns as arguments.?
Find distinctions between elements of the same word class on the basisof collocation and cooccurrence t sts.
For example, the nouns dog andbook partition into different selectional c asses because of contextsinvolving animacy, while the nouns book and literature partition intodifferent selectional c asses because of a mass/count distinction.?
Test for distinctions of a grammatical nature on the basis of diathesis; i.e.alternations that are realized in the syntax.
For example, break vs. cut in(1) and (2) below (Fillmore 1968; Lakoff 1970; Hale and Keyser 1986):Example 1a.
The glass broke.b.
John broke the glass.411Computational Linguistics Volume 17, Number 4Example 2a.
*The bread cut.b.
John cut the bread.Such alternations reveal subtle distinctions in the semantic and syntacticbehavior of such verbs.
The lexical semantic representations of theseverbs are distinguishable on the basis of such tests.Test for entailments in the word senses of a lexical item, in differentgrammatical contexts.
One can distinguish, for example, betweencontext-free and context-sensitive entailments.
When the use of a wordalways entails a certain proposition, we say that the resulting entailmentis not dependent on the syntactic ontext (cf.
Katz and Fodor 1963;Karttunen 1971, 1974; Seuren 1985).
This is illustrated in Example 3,where a killing always entails a dying.Example 3a.
John killed Bill.b.
Bill died.When the same lexical item may carry different entailments in differentcontexts, we say that the entailments are sensitive to the syntacticcontexts; for example, forget in Example 4,Example 4a.
John forgot that he locked the door.b.
John forgot to lock the door.Example 4a has a factive interpretation f forget that 4b does not carry: infact, 4b is counterfactive.
Other cases of contextual specification i volveaspectual verbs such as begin and finish as shown in Example 5.Example 5a.
Mary finished the cigarette.b.
Mary finished her beer.The exact meaning of the verb finish varies depending on the object itselects, assuming for these examples the meanings finish smoking or finishdrinking.Test for the ambiguity of a word.
Distinguish between homonymy andpolysemy, (cf.
Hirst 1987; Wilks 1975b); that is, from the accidental ndlogical aspects of ambiguity.
For example, the homonymy between thetwo senses of bank in Example 6 is accidental.
2Example 6a.
the bank of the riverb.
the richest bank in the city2 Cf.
Weinreich (1972) distinguishes between contrastive and complementary polysemy, essentiallycovering this same distinction.
See Section 4for discussion.412James Pustejovsky The Generative LexiconIn contrast, he senses in Example 7 exhibit a polysemy (cf.
Weinreich1972; Lakoff 1987).Example 7a.
The bank raised its interest rates yesterday (i.e.
the institution).b.
The store is next to the new bank (i.e.
the building).?
Establish what the compositional nature of a lexical item is when appliedto other words.
For example, alleged vs. female in Example 8.Example 8a.
the alleged suspectb.
the female suspectWhile female behaves as a simple intersective modifier in 8b, certainmodifiers uch as alleged in 8a cannot be treated as simple attributes;rather, they create an intensional context for the head they modify.
Aneven more difficult problem for compositionality arises from phrasescontaining frequency adjectives (cf.
Stump 1981), as shown in 8c and 8d.Example 8c.
An occasional sailor walks by on the weekend.d.
Caution: may contain an occasional pit (notice on a box of prunes).The challenge here is that the adjective doesn't modify the nominal head,but the entire proposition containing it (cf.
Partee \[1985\] for discussion).A similar difficulty arises with the interpretation f scalar predicatessuch as fast in Example 9.
Both the scale and the relative interpretationbeing selected for depends on the noun that the predicate is modifying.Example 9a.
a fast typist: one who types quicklyb.
a fast car: one which can move quicklyc.
a fast waltz: one with a fast tempoSuch data raise serious questions about he principles of compositionalityand how ambiguity should be accounted for by a theory of semantics.This just briefly characterizes some of the techniques that have been useful forarriving at pre-theoretic notions of word meaning.
What has changed over the yearsare not so much the methods themselves as the descriptive details provided by eachtest.
One thing that has changed, however - -  and this is significant - -  is the waycomputational lexicography has provided stronger techniques and even new tools forlexical semantics research: see Atkins (1987) for sense discrimination tasks; Amsler(1985), Atkins et al (forthcoming) for constructing concept axonomies; Wilks et al(1988) for establishing semantic relatedness among word senses; and Boguraev andPustejovsky (forthcoming) for testing new ideas about semantic representations.3.
Descriptive Adequacy of Existing RepresentationsTurning now to the question of how current heories compare with the coverage oflexical semantic data, there are two generalizations that should be made.
First, the413Computational Linguistics Volume 17, Number 4taxonomic descriptions that have recently been made of verb classes are far superiorto the classifications available twenty years ago (see Levin \[1985\] for review).
Usingmainly the descriptive vocabulary of Talmy (1975, 1985) and Jackendoff (1983), fine andsubtle distinctions are drawn that were not captured in the earlier, primitives-basedapproach of Schank (1972, 1975) or the frame semantics of Fillmore (1968).As an example of the verb classifications developed by various researchers (andcompiled by the MIT Lexicon Project; see Levin \[1985, 1989\]), consider the grammaticalalternations in the example sentences below (cf.
Dow .ty 1991).Example 10a.
John met Mary.b.
John and Mary met.Example 11a.
A car ran into a truck.b.
A car and a truck ran into each other.Example 12a.
A car ran into a tree.b.
*A car and a tree ran into each other.These three pairs show how the semantics of transitive motion verbs (e.g.
run into)is similar in some respects to reciprocal verbs such as meet.
The important difference,however, is that the reciprocal interpretation requires that both subject and object beanimate or moving; hence 12b is ill-formed.
(cf.
Levin 1989; Dowty 1991).Another example of how diathesis reveals the underlying semantic differencesbetween verbs is illustrated in Examples 13 and 14 below.
A construction called theconative (see Hale and Keyser \[1986\] and Levin \[1985\]) involves adding the prepositionat to the verb, changing the verb meaning to an action directed toward an object.Example 13a.
Mary cut the bread.b.
Mary cut at the bread.Example 14a.
Mary broke the bread.b.
*Mary broke at the bread.What these data indicate is that the conative is possible only with verbs of a particularsemantic lass; namely, verbs that specify the manner of an action that results in a changeof state of an object.As useful and informative as the research on verb classification is, there is a majorshortcoming with this approach.
Unlike the theories of Katz and Fodor (1963), Wilks(1975a), and Quillian (1968), there is no general coherent view on what the entire lexi-con will look like when semantic structures for other major categories are studied.
Thiscan be essential for establishing a globally coherent theory of semantic representation.On the other hand, the semantic distinctions captured by these older theories wereoften too coarse-grained.
It is clear, therefore, that the classifications made by Levinand her colleagues are an important starting point for a serious theory of knowledgerepresentation.
I claim that lexical semantics must build upon this research toward414James Pustejovsky The Generative Lexiconconstructing a theory of word meaning that is integrated into a linguistic theory, aswell as interpreted in a real knowledge representation system.4.
Explanatory Adequacy of Existing RepresentationsIn this section I turn to the question of whether current theories have changed theway we look at representation a d lexicon design.
The question here is whether therepresentations a sumed by current heories are adequate to account for the richnessof natural anguage semantics.
It should be pointed out here that a theory of lexicalmeaning will affect the general design of our semantic theory in several ways.
Ifwe view the goal of a semantic theory as being able to recursively assign meaningsto expressions, accounting for phenomena such as synonymy, antonymy, polysemy,metonymy, etc., then our view of compositionality depends ultimately on what thebasic lexical categories of the language denote.
Conventional wisdom on this pointpaints a picture of words behaving as either active functors or passive arguments(Montague 1974).
But we will see that if we change the way in which categories candenote, then the form of compositionality itself changes.
Therefore, if done correctly,lexical semantics can be a means to reevaluate the very nature of semantic ompositionin language.In what ways could lexical semantics affect the larger methods of composition insemantics?
I mentioned above that most of the careful representation work has beendone on verb classes.
In fact, the semantic weight in both lexical and compositionalterms usually falls on the verb.
This has obvious consequences for how to treat lexicalambiguity.
For example, consider the verb bake in the two sentences below.Example 15a.
John baked the potato.b.
John baked the cake.Atkins, Kegl, and Levin (1988) demonstrate hat verbs such as bake are systematicallyambiguous, with both a change-of-state s nse (15a) and a create sense (15b).A similar ambiguity exists with verbs that allow the resulative construction, shownin Examples 16 and 17, and discussed in Dowty (1979), Jackendoff (1983), and Levinand Rapoport (1988).Example 16a.
Mary hammered the metal.b.
Mary hammered the metal flat.Example 17a.
John wiped the table.b.
John wiped the table clean.On many views, the verbs in Examples 16 and 17 are ambiguous, related by eithera lexical transformation (Levin and Rapoport 1988), or a meaning postulate (Dowty1979).
In fact, given strict requirements on the way that a verb can project its lexicalinformation, the verb run in Example 18 will also have two lexical entries, dependingon the syntactic environment i  selects (Talmy 1985; Levin and Rappaport 1988).415Computational Linguistics Volume 17, Number 4Example 18a.
Mary ran to the store yesterday.b.
Mary ran yesterday.These two verbs differ in their semantic representations, where run in 18a means go-to-by-means-of-running, while in 18b it means simply move-by-running (cf.
Jackendoff1983).The methodology described above for distinguishing word senses is also assumedby those working in more formal frameworks.
For example, Dowty (1985) proposesmultiple entries for control and raising verbs, and establishes their semantic equiva-lence with the use of meaning postulates.
That is, the verbs in Examples 19 and 20 arelexically distinct but semantically related by rules.
3Example 19a.
It seems that John likes Mary.b.
John seems to like Mary.Example 20a.
Mary prefers that she come.b.
Mary prefers to come.Given the conventional notions of function application and composition, there islittle choice but to treat all of the above cases as polysemous verbs.
Yet, somethingabout the systematicity of such ambiguity suggests that a more general and simplerexplanation should be possible.
By relaxing the conditions on how the meaning of acomplex expression is derived from its parts, I will, in fact, propose a very straight-forward explanation for these cases of logical polysemy.5.
A Framework for Computational SemanticsIn this section, I will outline what I think are the basic requirements for a theory ofcomputational semantics.
I will present a conservative approach to decomposition,where lexical items are minimally decomposed into structured forms (or templates)rather than sets of features.
This will provide us with a generative framework for thecomposition of lexical meanings, thereby defining the well-formedness conditions forsemantic expressions in a language.We can distinguish between two distinct approaches to the study of word mean-ing: primitive-based theories and relation-based theories.
Those advocating primitivesassume that word meaning can be exhaustively defined in terms of a fixed set ofprimitive lements (e.g.
Wilks 1975a; Katz 1972; Lakoff 1971; Schank 1975).
Inferencesare made through the primitives into which a word is decomposed.
In contrast othis view, a relation-based theory of word meaning claims that there is no need fordecomposition i to primitives if words (and their concepts) are associated through anetwork of explicitly defined links (e.g.
Quillian 1968; Collins and Quillian 1969; Fodor1975; Carnap 1956; Brachman 1979).
Sometimes referred to as meaning postulates, theselinks establish any inference between words as an explicit part of a network of word3 Both Klein and Sag (1985) and Chomsky (1981) assume, however, that here are reasons for relatingthese two forms tructurally.
See below and Pustejovsky (1989a) for details.416James Pustejovsky The Generative Lexiconconcepts.
4 What I would like to do is to propose a new way of viewing primitives,looking more at the generative or compositional spects of lexical semantics, rather thanthe decomposition i to a specified number of primitives.Most approaches to lexical semantics making use of primitives can be character-ized as using some form of feature-based semantics, since the meaning of a word isessentially decomposable into a set of features (e.g.
Katz and Fodor 1963; Katz 1972;Wilks 1975; Schank 1975).
Even those theories that rely on some internal structure forword meaning (e.g.
Dowty 1979; Fillmore 1985) do not provide a complete characteri-zation for all of the well-formed expressions in the language.
Jackendoff (1983) comesclosest, but falls short of a comprehensive s mantics for all categories in language.No existing framework, in my view, provides a method for the decomposition of lexicalcategories.What exactly would a method for lexical decomposition give us?
Instead of ataxonomy of the concepts in a language, categorized by sets of features, such a methodwould tell us the minimal semantic onfiguration of a lexical item.
Furthermore, itshould tell us the compositional properties of a word, just as a grammar informs usof the specific syntactic behavior of a certain category.
What we are led to, therefore,is a generative theory of word meaning, but one very different from the generativesemantics of the 1970s.To explain why I am suggesting that lexical decomposition proceed in a generativefashion rather than the traditional exhaustive approach, let me take as a classic example,the word closed as used in Example 21 (see Lakoff 1970).Example 21a.
The door is closed.b.
The door closed.c.
John closed the door.Lakoff (1970), Jackendoff (1972), and others have suggested that the sense in 21c mustincorporate something like cause-to-become-not-open for its meaning.
Similarly, a verbsuch as give specifies a transfer from one person to another, e.g., cause-to-have.
Mostdecomposition theories assume a set of primitives and then operate within this setto capture the meanings of all the words in the language.
These approaches can becalled exhaustive since they assume that with a fixed number of primitives, completedefinitions of lexical meaning can be given.
In the sentences in 21, for example, closeis defined in terms of the negation of a primitive, open.
Any method assuming a fixednumber of primitives, however, runs into some well-known problems with being ableto capture the full expressiveness of natural anguage.These problems are not, however, endemic to all decomposition approaches.
Iwould like to suggest that lexical (and conceptual) decomposition is possible if itis performed generatively.
Rather than assuming a fixed set of primitives, let us as-sume a fixed number of generative devices that can be seen as constructing semanticexpressions.
5 Just as a formal language is described more in terms of the productionsin the grammar than its accompanying vocabulary, a semantic language is definableby the rules generating the structures for expressions rather than the vocabulary ofprimitives itself.
64 For further discussion on the advantages and disadvantages to both approaches, see Jackendoff (1983).5 See Goodman (1951) and Chomsky (1955) for explanations of the method assumed here.6 This approach isalso better suited to the way people write systems in computational linguistics.Different people have distinct primitives for their own domains, and rather than committing a designer417Computational Linguistics Volume 17, Number 4How might this be done?
Consider the sentences in.
Example 21 again.
A minimaldecomposition on the word closed is that it introduces an opposition of terms: closedand not-closed.
For the verbal forms in 21b and 21c, both terms in this opposition arepredicated of different subevents denoted by the sentences.
In 21a, this opposition isleft implicit, since the sentence refers to a single state.
Any minimal analysis of thesemantics of a lexical item can be termed agenerative operation, since it operates on thepredicate(s) already literally provided by the word.
This type of analysis is essentiallyAristotle's principle of opposition (cf.
Lloyd 1968), and it will form the basis of one levelof representation for a lexical item.
The essential opposition denoted by a predicateforms part of what I will call the qualia structure of that lexical item.
Briefly, the qualiastructure of a word specifies four aspects of its meaning:?
the relation between it and its constituent parts;?
that which distinguishes it within a larger domain (its physicalcharacteristics);?
its purpose and function;?
whatever brings it about.I will call these aspects of a word's meaning its Constitutive Role, Formal Role, Telic Role,and its Agentive Role, respectively.
7This minimal semantic distinction is given expressive force when combined witha theory of event ypes.
For example, the predicate in 21a denotes the state of the doorbeing closed.
No opposition is expressed by this predicate.
In 21b and 21c, however,the opposition is explicitly part of the meaning of the predicate.
Both these predicatesdenote what I will call transitions.
The intransitive use of close in 21b makes no mentionof the causer, yet the transition from not-closed to closed is still entailed.
In 21c, the eventthat brings about the closed state of the door is made more explicit by specifying theactor involved.
These differences constitute what I call the event structure of a lexicalitem.
Both the opposition of predicates and the specification of causation are part of averb's semantics, and are structurally associated with slots in the event template forthe word.
As we will see in the next section, there are different inferences associatedwith each event ype, as well as different syntactic behaviors (cf.
Grimshaw 1990 andPustejovsky 1991).Because the lexical semantic representation f a word is not an isolated expression,but is in fact linked to the rest of the lexicon, in Section 7, I suggest how the globalintegration of the semantics for a lexical item is achieved by structured inheritancethrough the different qualia associated with a word.
I call this the lexical inheritancestructure for the word.Finally, we must realize that part of the meaning of a word is how it translates theunderlying semantic representations i to expressions that are utilized by the syntax.This is what many have called the argument structure for a lexical item.
I will build onGrimshaw's recent proposals (Grimshaw 1990) for how to define the mapping fromthe lexicon to syntax.to a particular vocabulary of primitives, a lexical semantics should provide a method for thedecomposition and composition of lexical items.7 Some of these roles are reminiscent of descriptors used by various computational researchers, uch asWilks (1975b), Hayes (1979), and Hobbs et al (1987).
Within the theory outlined here, these rolesdetermine a minimal semantic description of a word that has both semantic and grammaticalconsequences.418James Pustejovsky The Generative LexiconThis provides us with an answer to the question of what levels of semantic rep-resentation are necessary for a computational lexical semantics.
In sum, I will arguethat lexical meaning can best be captured by assuming the following levels of repre-sentation.1.
Argument Structure: The behavior of a word as a function, with its arityspecified.
This is the predicate argument structure for a word, whichindicates how it maps to syntactic expressions.2.
Event Structure: Identification of the particular event ype (in the senseof Vendler \[1967\]) for a word or phrase: e.g.
as state, process, ortransition.3.
Qualia Structure: The essential attributes of an object as defined by thelexical item.4.
Inheritance Structure: How the word is globally related to otherconcepts in the lexicon.These four structures essentially constitute the different levels of semantic expressive-ness and representation that are needed for a computational theory of lexical semantics.Each level contributes a different kind of information to the meaning of a word.
Theimportant difference between this highly configurational approach to lexical semanticsand feature-based approaches i that the recursive calculus defined for word mean-ing here also provides the foundation for a fully compositional semantics for naturallanguage and its interpretation i to a knowledge representation model.5.1 Argument StructureA logical starting point for our investigations into the meaning of words is what hasbeen called the functional structure or argument structure associated with verbs.
Whatoriginally began as the simple listing of the parameters or arguments associated witha predicate has developed into a sophisticated view of the way arguments are mappedonto syntactic expressions (for example, the f-structure in Lexical Functional Grammar\[Bresnan 1982\] and the Projection Principle in Government-Binding Theory \[Chomsky1981\]).One of the most important contributions has been the view that argument s ructureis highly structured independent of the syntax.
Williams's (1981) distinction betweenexternal and internal arguments and Grimshaw's proposal for a hierarchically struc-tured representation (Grimshaw 1990) provide us with the basic syntax for one aspectof a word's meaning.The argument structure for a word can be seen as a minimal specification ofits lexical semantics.
By itself, it is certainly inadequate for capturing the semanticcharacterization f a lexical item, but it is a necessary component.5.2 Event StructureAs mentioned above, the theory of decomposition being outlined here is based on thecentral idea that word meaning is highly structured, and not simply a set of semanticfeatures.
Let us assume this is the case.
Then the lexical items in a language willessentially be generated by the recursive principles of our semantic theory.
One levelof semantic description involves an event-based interpretation of a word or phrase.I will call this level the event structure of a word (cf.
Pustejovsky 1991; Moens andSteedman 1988).
The event structure of a word is one level of the semantic specification419Computational Linguistics Volume 17, Number 4for a lexical item, along with its argument structure, qualia structure, and inheritancestructure.
Because it is recursively defined on the syntax, it is also a property of phrasesand sentences.
8I will assume a sortal distinction between three classes of events: states (eS), pro-cesses (8), and transitions (eT).
Unlike most previous ,;ortal classifications for events,I will adopt a subeventual analysis or predicates, as argued in Pustejovsky (1991) andindependently proposed in Croft (1991).
In this view, an event sort such as e T maybe decomposed into two sequentially structured subevents, (ee,sS).
Aspects of theproposal will be introduced as needed in the following discussion.6.
A Theory of QualiaIn Section 5, I demonstrated how most of the lexical semantics research has con-centrated on verbal semantics.
This bias influences our analyses of how to handleambiguity and certain noncompositional structures.
Therefore, the only way to relatethe different senses for the verbs in the examples below was to posit separate ntries.Example 22a.
John baked the potato.
(bake1 = change(x, State(y)))b. John baked the cake.
(bake2 = create(x,y))Example 23a.
Mary hammered the metal.
(hammer1 = change(x, State(y)))b. Mary hammered the metal fiat.
(hammer2 = cause(x, Become(fiat(y))))Example 24a.
John wiped the table.
(wipe1 = change (x, State (y) ))b. John wiped the table clean.
(wipe2 = cause(x, Become(clean(y))))Example 25a.
Mary ran yesterday.
(run1 = move(x))b. Mary ran to the store yesterday.
(run2 = go-to(x, y))?
Although the complement types selected by bake in 22, for example, are semanticallyrelated, the two word senses are clearly distinct and therefore must be lexically distin-guished.
According to the sense enumeration view, the same argument holds for theverbs in 23-25 as well.8 This proposal is an extension ofideas explored by Bach (1986), Higginbotham (1985), and Allen (1984).For a full discussion, see Pustejovsky (1988, 1991).
See Tenny (1987) for a proposal on how aspectualdistinctions are mapped to the syntax.420James Pustejovsky The Generative LexiconA similar philosophy has lead linguists to multiply word senses in constructionsinvolving Control and Equi-verbs, where different syntactic ontexts necessitate dif-ferent semantic types?Example 26a.
It seems that John likes Mary.b.
John seems to like Mary.Example 27a.
Mary prefers that she come.b.
Mary prefers to come.Normally, compositionality in such structures simply refers to the application of thefunctional element, the verb, to its arguments.
Yet, such examples indicate that inorder to capture the systematicity of such ambiguity, something else is at play, wherea richer notion of composition is operative.
What then accounts for the polysemy ofthe verbs in the examples above?The basic idea I will pursue is the following.
Rather than treating the expressionsthat behave as arguments to a function as simple, passive objects, imagine that theyare as active in the semantics as the verb itself.
The product of function applicationwould be sensitive to both the function and its active argument.
Something like thisis suggested in Keenan and Faltz (1985), as the Meaning-Form Correlation Principle.
Iwill refer to such behavior as cocompositionality (see below).
What I have in mind canbest be illustrated by returning to the examples in 28.Example 28a.
John baked the potato.b.
John baked the cake.Rather than having two separate word senses for a verb such as bake, suppose thereis simply one, a change-of-state reading.
Without going into the details of the analysis,let us assume that bake can be lexically specified as denoting a process verb, and isminimally represented asExample 29. l?Example 29Lexical Semantics for bake: n)~y)~x)~eP\[bake(e P) A agent(e P,x) A object(e P,y)\]In order to explain the shift in meaning of the verb, we need to specify more clearlywhat the lexical semantics of a noun is.
I have argued above that lexical semantic theorymust make a logical distinction between the following qualia roles: the constitutive,formal, telic, and agentive roles.
Now let us examine these roles in more detail.
Onecan distinguish between potato and cake in terms of how they come about; the former9 For example, Dowty (1985) proposes multiple entries for verbs taking different subcategorizations.Gazdar et al (1985), adopting the analysis in Klein and Sag (1985), propose a set of lexical type-shiftingoperations to capture sense relatedness.
We return to this topic below.10 I will be assuming a Davidsonian-style r presentation for the discussion below.
Predicates in thelanguage are typed for a particular event-sort, and thematic roles are treated as partial functions overthe event (cf.
Dowty 1989 and Chierchia 1989).11 More precisely, the process e p should reflect hat it is the substance contained in the object x that isaffected.
See footnote 20 for explanation.421Computational Linguistics Volume 17, Number 4is a natural kind, while the latter is an artifact.
Knowledge of an object includes notjust being able to identify or refer, but more specifically, being able to explain how anartifact comes into being, as well as what it is used for; the denotation of an objectmust identify these roles.
Thus, any artifact can be identified with the state of beingthat object, relative to certain predicates.As is well known from work on event semantics and Aktionsarten, it is a generalproperty of processes that they can shift their event type to become a transition event(cf.
Hinrichs 1985; Moens and Steedman 1987; and Krifka 1987).
This particular factabout event structures, together with the semantic distinction made above betweenthe two object types, provides us with an explanation for what I will refer to as thelogical polysemy of verbs such as bake.As illustrated in Example 30a, when the verb takes as its complement a naturalkind such as potato, the resulting semantic interpretation is unchanged; i.e., a processreading of a state-change.
This is because the noun does not "project" an event struc-ture of its own.
That is, relative to the process of baking, potato does not denote anevent-type.
12Example 30a.
bake as Process:3eP\[bake(e P) A agent(~,j) A object(e P,a-potato)\]b.PJohn bakedVVPa potatoNPWhat is it, then, about the semantics of cake that shifts this core meaning of bakefrom a state-change predicate to its creation sense?
As just suggested, this additionalmeaning is contributed by specific lexical knowledge we have about artifacts, andcake in particular; namely, there is an event associated with that object's "cominginto being," in this case the process of baking.
Thus, just as a verb can select for anargument-type, we can imagine that an argument is itself able to select he predicatesthat govern it.
I will refer to such constructions as cospecifications.
Informally, relativeto the process bake, the noun cake carries the selectional information that it is a processof "baking" that brings it about.
1312 However, elative to the process of growing, the noun potato does denote an event:1.
Mary grew the potato.13 Other examples of cospecifications are: a. read a book, b. smoke acigarette, c. mail a letter, d. deliver alecture, and e. take a bath.422James Pustejovsky The Generative LexiconWe can illustrate this schematically in Example 31, where the complement effec-tively acts like a "stage-level" event predicate (cf.
Carlson 1977) relative to the processevent-type of the verb (i.e.
a function from processes to transitions, <P,T>).
14 Thechange in meaning in 31 comes not from the semantics of bake, but rather in com-position with the complement of the verb, at the level of the entire verb phrase.
The"creation" sense arises from the semantic role of cake that specifies it is an artifact (seebelow for discussion).Example 31a.
bake as a derived Transition: 153e P, eS\[create(e P, s) A bake(e P ) A agent(eP,j) A object(e P,x)A cake(e s) A object(e s,x)\]b.TPJohn bakedV<P,T>a cakeNPVPThus, we can derive both word senses of verbs like bake by putting some of thesemantic weight on the NP.
This view suggests that, in such cases, the verb itself isnot polysemous.
Rather, the sense of "create" is part of the meaning of cake by virtueof it being an artifact.
The verb appears polysemous because certain complements addto the basic meaning by virtue of what they denote.
We return to this topic below,There are several interesting things about such collocations.
First, because the complement "selects"the verb that governs it (by virtue of knowledge of what is done to the object), the semantics of thephrase is changed.
The semantic "connectedness," as it were, is tighter when cospecification btains.
Insuch cases, the verb is able to successfully drop the dative PP argument, as shown below in (1).
Whenthe complement does not select he verb governing it, dative-drop is ungrammatical asseen in (2)(although there are predicates selected by these nouns; e.g.
keep a secret, read a book, and play a record).la.
Romeo gave the lecture.b.Hamlet mailed a letter.c.
Cordelia told a story.d.Gertrude showed a movie.e.Mary asked a question.2a.
*Bill told the secret.b.
*Mary gave a book.c.
*Cordelia showed the record.For discussion see Pustejovsky (in press).14 cf.
Pustejovsky (forthcoming) for details.15 As mentioned in footnote 11, this representation is incomplete.
See footnote 20 for semantics of bake.423Computational Linguistics Volume 17, Number 4and provide a formal treatment for how the nominal semantics i expressed in theseexamples.Similar principles eem to be operating in tile resultative constructions in Exam-ples 23 and 24; namely, a systematic ambiguity is the result of principles of semanticcomposition rather than lexical ambiguity of the verbs.
For example, the resultativeinterpretations for the verbs hammer in 23(b) and wipe in 24(b) arise from a similaroperation, where both verbs are underlyingly specified with an event type of pro-cess.
The adjectival phrases fiat and clean, although clearly stative in nature, can alsobe interpreted as stage-level event predicates (cf.
Dowty 1979).
Notice, then, howthe resultative construction requires no additional word sense for the verb, nor anyspecial semantic machinery for the resultative interpretation to be available.
Schemat-ically, this is shown in Example 32.Example 32TP <P,T>IJohn hammer the metal flatV NP APVPIn fact, this analysis explains why it is that only process verbs participate in the re-sultative construction, and why the resultant phrase (the adjectival phrase) must be asubset of the states, namely, stage-level vent predicates.
Because the meaning of thesentence in 32 is determined by both function application of hammer to its argumentsand function application of fiat to the event-type of the verb, this is an example ofcocompositionality (cf.
Pustejovsky \[forthcoming\] for discussion).Having discussed some of the behavior of logical polysemy in verbs; let us con-tinue our discussion of lexical ambiguity with the issue of metonymy.
Metonymy, wherea subpart or related part of an object "stands for" the object itself, also poses a prob-lem for standard enotational theories of semantics.
To see why, imagine how oursemantics could account for the "reference shifts" of the complements shown in Ex-ample 33.16Example 33a.
Mary enjoyed the book.b.
Thatcher vetoed the channel tunnel.
(Cf.
Hobbs 1987)c. John began a novel.16 See Nunberg (1978) and Fauconnier (1985) for very clear discussions of the semantics of metonymyand the nature of reference shifts.
See Wilks (1975) and Fass (1988) for computational models ofmetonymic resolution.424James Pustejovsky The Generative LexiconThe complements ofenjoy in 33(a) and begin in 33(c) are not what these verbs normallyselect for semantically, namely a property or action.
Similarly, the verb veto normallyselects for an object that is a legislative bill or a suggestion.
Syntactically, these maysimply be additional subcategorizations, but how are these examples related semanti-cally to the normal interpretations?I suggest hat these are cases of semantic type coercion (cf.
Pustejovsky 1989a),where the verb has coerced the meaning of a term phrase into a different semantictype.
Briefly, type coercion can be defined as follows: 17DefinitionType Coercion: A semantic operation that converts an argument to the type that isexpected by a function, where it would otherwise result in a type error.In the case of 33(b), it is obvious that what is vetoed is some proposal relating tothe object denoted by the tunnel.
In 33(a), the book is enjoyed only by virtue of someevent or process that involves the book, performed by Mary.
It might furthermore bereasonable to assume that the semantic structure of book specifies what the artifact isused for; i.e.
reading.
Such a coercion results in a word sense for the NP that I willcall logical metonymy.
Roughly, logical metonymy occurs when a logical argument (i.e.subpart) of a semantic type that is selected by some function denotes the semantictype itself.Another interesting set of examples involves the possible subjects of causativeverbs.
TM Consider the sentences in Examples 34 and 35.Example 34a.
Driving a car in Boston frightens me.b.
To drive a car in Boston frightens me.c.
Driving frightens me.d.
John's driving frightens me.e.
Cars frighten me.f.
Listening to this music upsets me.g.
This music upsets me.h.
To listen to this music would upset me.Example 35a.
John killed Mary.b.
The gun killed Mary.c.
John's stupidity killed Mary.d.
The war killed Mary.e.
John's pulling the trigger killed Mary.As these examples illustrate, the syntactic argument to a verb is not always the samelogical argument in the semantic relation.
Although superficially similar to cases ofgeneral metonymy (cf.
Lakoff and Johnson 1982; Nunberg 1978), there is an interestingsystematicity o such shifts in meaning that we will try to characterize below as logicalmetonymy.171 am following Cardelli and Wegener (1985) and their characterization of polyrnorphismic behavior.18 See Verma nd Mohanan (1991) for an extensive survey of experiencer subject constructions i  differentlanguages.425Computational Linguistics Volume 17, Number 4The sentences in 34 illustrate the various syntactic onsequences of metonymy andcoercion involving experiencer verbs, while those in 35 show the different metonymicextensions possible from the causing event in a killing.
The generalization here is thatwhen a verb selects an event as one of its arguments, type coercion to an event will per-mit a limited range of logical metonymies.
For example, in sentences 34(a,b,c,d,f,h), the' entire event is directly referred to, while in 34(e,g) only a participant from the coercedevent reading is directly expressed.
Other examples of coercion include "concealedquestions" 36 and "concealed exclamations" 37 (cf.
Grimshaw 1979; Elliott 1974).Example 36a.
John knows the plane's arrival time.
(= what time the plane will arrive)b.
Bill figured out the answer.
(= what the answer is)Example 37a.
John shocked me with his bad behavior.
(= how bad his behavior is)b.
You'd be surprised at the big cars he buys.
(= how big the cars he buys are)That is, although the italicized phrases yntactically appear as NPs, their semantics isthe same as if the verbs had selected an overt question or exclamation.In explaining the behavior of the systematic ambiguity above, I made referenceto properties of the noun phrase that are not typical semantic properties for nounsin linguistics; e.g., artifact, natural kind.
In Pustejovsky (1989b) and Pustejovsky andAnick (1988), I suggest hat there is a system of relations that characterizes the seman-tics of nominals, very much like the argument structure of a verb.
I called this theQualia Structure, inspired by Aristotle's theory of explanation and ideas from Moravc-sik (1975).
Essentially, the qualia structure of a noun determines its meaning as muchas the list of arguments determines a verb's meaning.
The elements that make up aqualia structure include notions such as container, space, surface, figure, artifact, andso on.
19As stated earlier, there are four basic roles that constitute the qualia structure fora lexical item.
Here I will elaborate on what these roles are and why they are useful.They are given in Example 38, where each role is defined, along with the possiblevalues that these roles may assume.Example 38The Structure of Qualia:1.
Constitutive Role: the relation between an object and its constituents, orproper parts.?
Material?
Weight?
Parts and component elements19 These components of an object's denotation have long been considered crucial for our commonsenseunderstanding of how things interact in the world.
Cf.
Hayes (1979), Hobbs et al (1987), and Croft(1991) for discussion of these qualitative aspects of meaning.426James Pustejovsky The Generative Lexicon2.
Formal Role: that which distinguishes the object within a larger domain.?
Orientation?
Magnitude?
Shape?
Dimensionality?
Color?
Position3.
Telic Role: purpose and function of the object..Purpose that an agent has in performing an actBuilt-in function or aim that specifies certain activitiesAgentive Role: factors involved in the origin or "bringing about" of anobject.?
Creator?
Artifact?
Natural Kind?
Causal ChainWhen we combine the qualia structure of a NP with the argument structure of a verb,we begin to see a richer notion of compositionality emerging, one that looks very muchlike object-oriented approaches to programming (cf.
Ingria and Pustejovsky 1990).To illustrate these structures at play, let us consider a few examples.
Assumethat the decompositional semantics of a nominal includes a specification of its qualiastructure:Example 39Object( Const, Form, Telic, Agent)For example, a minimal semantic description for the noun novel will include values foreach of these roles, as shown in Example 40, where *x* can be seen as a distinguishedvariable, representing the object itself.Example 40novel(*x*)Const: narrative(*x*)Form: book(*x*), disk(*x*)Telic: read(T,y,*x*)Agentive: artifact(*x*), write(T,z,*x*)This structures our basic knowledge about the object: it is a narrative; typically inthe form of a book; for the purpose of reading (whose event type is a transition);and is an artifact created by a transition event of writing.
Observe how this structurediffers minimally, but significantly, from the qualia structure for the noun dictionary inExample 41.427Computational Linguistics Volume 17, Number 4Example 41dictionary(*x*)Const: alphabetized-listing(*x*)Form: book(*x*), disk(*x*)Telic: reference(P,y,*x*)Agentive: artifact(*x*), compile(T,z,*x~)Notice the differences in the values for the constitutive and telic roles.
The purpose ofa dictionary is an activity of referencing, which has an event structure of a process.I will now demonstrate that such structured information is not only useful fornouns, but necessary to account for their semantic behavior.
I suggested earlier, thatfor cases such as 33, repeated below, there was no need to posit a separate lexical entryfor each verb, where the syntactic and semantic types had to be represented explicitly.Example 42a.
Mary enjoyed the book.b.
Thatcher vetoed the channel tunnel.c.
John began a novel.Rather, the verb was analyzed as coercing its complement to the semantic type it ex-pected.
To illustrate this, consider 42(c).
The type for begin within a standard typedintensional logic is <VP, <NP, S>>, and its lexical semantics is similar to that of othersubject control verbs (cf.
Klein and Sag \[1985\] for discussion).Example 43APAT~7 ~Ax\[begin'(P(x*))(x*)\]Assuming an event structure such as that of Krifka (1987) or Pustejovsky (1991),we can convert his lexical entry into a representation consistent with a logic makinguse of event-types (or sorts) by means of the following meaning postulate.
2?Example 44VPVxl .. .
Xn \[\] \[P?
(xl)  .
.. (Xn) ~ 3e ~ \[P (xl)  .
.. (x , )  (e ~ )\]\]This allows us to type the verb begin as taking a transition event as its first argument,represented in Example 45.Example 45APT A 7979 Ax\[begin ' (PT (X*)) (X*)\]Because the verb requires that its first argument be of type transition the complementin 33(c) will not match without some sort of shift.
It is just this kind of context wherethe complement (in this case a novel) is coerced to another type.
The coercion dictates tothe complement that it must conform to its type specification and the qualia roles may20 It should be pointed out that the lexical structure for the verb bake given above in 30 and 31 can moreproperly be characterized as a process acting on various qualia of the arguments.1.
AyAxAee S\[bake(e ) A agent(d, x) A object(d, Const(y)  A cake(e s) A object(e s, Formal(x))\]428James Pustejovsky The Generative Lexiconin fact have values matching the correct type.
For purposes of il lustration, the qualiastructure for novel f rom 41 can be represented as the logical expression in Example 46.Example 46novel translates into:)~x\[novel(x) A Const(x)= narrative'(x) AForm(x) = book'(x) ATelic(x) = ,~y, eT\[read' (x)(y)(er)\] AAgent(x) = ,~y, er\[write'(x)(y)(eT)\]\]The coercion operat ion on the complement  in the above examples can be seen as arequest to find any transition event associated with the noun.
As we saw above, thequalia structure contains just this kind of information.We can imagine the qualia roles as partial functions f rom a noun denotat ion into itssubconst ituent denotations.
For our  present purposes,  we abbreviate these functionsas Q~, Qo  QT, QA.
When applied, they return the value of a particular qualia role.
Forexample, the purpose of a novel is for reading it, shown in 47(a), while the mode ofcreating a novel is by writ ing it, represented in 47(b).Example 47a.
QT(novel) = &y~ eT\[read(x)(y)(er)\]b. QA (novel) = )~y, eT\[write(x) (y) (eT)\]As the expressions in 47 suggest, there are, in fact, two obvious interpretations for thissentence in 42(c).Example 48a.
John began to read a novel.b.
John began to write a novel.One of these is selected by the coercing verb, result ing in a complement  that has aevent-predicate interpretation, wi thout  any syntactic transformations (cf.
Pustejovsky\[1989a\] for details), al The derivation in 49(a) and the structure in 49(b) show the effectsof this coercion on the verb's complement,  using the telic value of novel.
2221 There are, of course, an indefinite number of interpretations, depending on pragmatic factors andvarious contextual influences.
But I maintain that there are only a finite number of defaultinterpretations available in such constructions.
These form part of the lexical semantics of the noun.Additional evidence for this distinction is given in Pustejovsky and Anick (1988) and Briscoe et al(1990).22 Partee and Rooth (1983) suggest that all expressions in the language can be assigned abase type, whilealso being associated with a type ladder.
Pustejovsky (1989a) extends this proposal, and argues thateach expression c~ may have available to it, a set of shifting operators, which we call Ga, which operateover an expression, changing its type and denotation.
By making reference to these operators directlyin the rule of function application, we can treat the functor polymorphically, as illustrated below.1.
Function Application with Coercion (FAc):If c~ is of type (b, a}, and fl is of type c, then(a) if type c = b, then c~(fl) is of type a.
(b) if there is a ?
C ~,~ such that cr(fl) results in an expression of type b, thenc~(a(fl)) is of type a.
(c) otherwise a type error is produced.429Computational Linguistics Volume 17, Number 4Example 49a.
John began a novel.b.
begin'(QT(a novel))(John)c. begin'(Ax, eT \[read(a novel)(x)(eT)\]) (John)d. John{Ax\[begin'(Ax~ eT\[read(a novel)(x)(eT)\](x*))(x*)\]}e. John{ Ax\[begin'( AeT\[read(a novel)(x" )(eT)\])(x* )\]}f. begin'(Ae T \[read(a novel) (John) (eT)\]) (John)g.Mary begin a novelNP' < VP, < NP, S >> NP'< NP, S >SThe fact that this is not a unique interpretation of the elliptical event predicate is insome ways irrelevant to the notion of type coercion.
That there is some event involvingthe complement is required by the lexical semantics of the governing verb and the rulesof type well-formedness, and although there are many ways to act on a novel, I arguethat certain relations are "privileged" in the lexical semantics of the noun.
It is not therole of a lexical semantic theory to say what readings are preferred, but rather whichare available.
23Assuming the semantic selection given above for begin is correct, we would predictthat, because of the process event-type associated with the telic role for dictionary, thereis only one default interpretation for the sentence in 50; namely, the agentive vent of"compiling.
"23 There are interesting differences in complement types between finish and complete.
The former takesboth NP and a gerundive VP, while the latter takes only an NP (cf.
for example, Freed \[1979\] fordiscussion).la.
John finished the book.b.
John finished writing the book.2a.
John completed the book.b.
*John completed writing the book.The difference would indicate that, contrary to some views (e.g.
Wierzbicka \[1988\] and Dixon \[1991\]),lexical items need to carry both syntactic and semantic selectional information to determine the rangeof complements they may take.
Notice here also that complete nds to select the agentive role value forits complement and not the telic role.
The scope of semantic selection isexplored at length inPustejovsky (forthcoming).430James Pustejovsky The Generative LexiconExample 50a.
Mary began a dictionary.
(Agentive)b.
??
Mary began a dictionary.
(Telic)Not surprisingly, when the noun in complement position has no default interpretationwithin an event predicate - -  as given by its qualia structure - -  the resulting sentenceis extremely odd.Example 51a.
*Mary began a rock.b.
?
?John finished the flower.The semantic distinctions that are possible once we give semantic weight to lexicalitems other than verbs are quite wide-ranging.
The next example I will consider con-cerns scalar modifiers, such as fast, that modify different predicates depending on thehead they modify.
If we think of certain modifiers as modifying only a subset of thequalia for a noun, then we can view fast as modifying only the telic role of an object.This allows us to go beyond treating adjectives uch as fast as intersective modifiersfor example, as Ax\[car'(x) Afast'(x)\].
Let us assume that an adjective such as fast is amember of the general type (N, N), but can be subtyped as applying to the Telic roleof the noun being modified.
That is, it has as its type, (IN Telic\],N}.
This gives risedirectly to the different interpretations in Example 52.Example 52a.
a fast car: drivingQT (car) = AxAyAeP\[ drive(x)(y)(e v) \]b. a fast typist: typingQr(typist) = AxAeP\[ type(x)(e P) \]c. a fast motorway: travelingQv(motorway) = AxAeV\[ travel(cars)(e P) A on(x)(cars)(e v) \]These interpretations are all derived from a single word sense for fast.
Because thelexical semantics for this adjective indicates that it modifies the telic role of the noun,it effectively acts as an event predicate rather than an attribute over the entire noundenotation, as illustrated in Example 53 for fast motorway (cf.
Pustejovsky and Boguraev\[1991\] for discussion).Example 53Ax \[mot orway (x ) .
.
.
\[Tel ic ( x ) = AeV \[ travel (cars )( e P)A on(x)(cars)(e p) A fast(e P) \]\]\]As our final example of how the qualia structure contributes to the semantic in-terpretation of a sentence, observe how the nominals window and door in Examples 54and 55 carry two interpretations (cf.
Lakoff \[1987\] and Pustejovsky and Anick \[1988\]):Example 54a.
John crawled through the window.b.
The window is closed.431Computational Linguistics Volume 17, Number 4Example 55a.
Mary painted the door.b.
Mary walked through the door.Each noun appears to have two word senses: a physical object denotation and anaperture denotation.
Pustejovsky and Anick (1988) characterize the meaning of such"Double Figure-Ground" nominals as inherently relational, where both parameters arelogically part of the meaning of the noun.
In terms of the qualia structure for this classof nouns, the formal role takes as its value the Figure of a physical object, while theconstitutive role assumes the Invert-Figure value of an aperture.
24Example 56Lexical Semantics for door:door(*x* ,*y*)Const: aper ture(*y* )Form: phys-obj (*x*)Te l i c :  pass - through(T ,z , *y* )Agentive: artifact(*x*)The foregrounding or backgrounding of a nominal's qualia is very similar to argumentstructure-changing operations for verbs.
That is, in 55(a), paint applies to the formalrole of the door, while in 55(b), through will apply to the constitutive interpretation ofthe same NP.
The ambiguity with such nouns is a logical one, one that is intimatelylinked to the semantic representation f the object itself.
The qualia structure, then, isa way of capturing this logical polysemy.In conclusion, it should be pointed out that the entire lexicon is organized aroundsuch logical ambiguities, which Pustejovsky and Anick (1988) call Lexical ConceptualParadigms.
Pustejovsky (forthcoming) distinguishes tlhe following systems and theparadigms that lexical items fall into:Example 57a.
Count/Mass Alternationsb.
Container/Containee Alternationsc.
F igure/Ground Reversalsd.
Product/Producer Diathesise.
Plant/Fruit  Alternationsf.
Process/Result Diathesisg.
Object/Place Reversalsh.
State/Thing Alternationsi.
Place/PeopleSuch paradigms provide a means for accounting for the systematic ambiguity that mayexist for a lexical item.
For example, a noun behaving according to paradigm 57(a)24 There are many such classes of nominals, both two-dimensional such as those mentioned in the text,and three-dimensional, such as "room," fireplace," and "pipe."
They are interesting semantically,because they are logically ambiguous, referring to either the object or the aperture, but not both.Boguraev and Pustejovsky (forthcoming) show how these logical polysemies are in fact encoded indictionary definitions for these words.432James Pustejovsky The Generative Lexiconexhibits a logical polysemy involving packaging or grinding operators; e.g., haddockor lamb (cf.
Copestake and Briscoe \[1991\] for details).7.
Lexical Inheritance TheoryIn previous ections, I discussed lexical ambiguity and showed how a richer view oflexical semantics allows us to view a word's meaning as being flexible, where wordsenses could arise generatively by composition with other words.
The final aspect ofthis flexibility deals with the logical associations a word has in a given context; that is,how this semantic information is organized as a global knowledge base.
This involvescapturing both the inheritance relations between concepts and, just as importantly,how the concepts are integrated into a coherent expression i  a given sentence.I will assume that there are two inheritance mechanisms atwork for representingthe conceptual relations in the lexicon: fixed inheritance and projective inheritance.
Thefirst includes the methods of inheritance traditionally assumed in AI and lexical re-search (e.g.
Roberts and Goldstein 1977; Brachman and Schmolze 1985; Bobrow andWinograd 1977); that is, a fixed network of relations, which is traversed to discoverexisting related and associated concepts (e.g.
hyponyms and hypernyms).
In order toarrive at a comprehensive theory of the lexicon, we need to address the issue of globalorganization, and this involves looking at the various modes of inheritance that existin language and conceptualization.
Some of the best work addressing the issue of howthe lexical semantics of a word ties into its deeper conceptual structure includes thatof Hobbs et al (1987) and Wilks (1975), while interesting work on shared informationstructures in NLP domains is that of Flickinger et al (1985) and Evans and Gazdar(1989, 1990).In addition to this static representation, I will introduce another mechanism forstructuring lexical knowledge, the projective inheritance, which operates generativelyfrom the qualia structure of a lexical item to create a relational structure for ad hoccategories.
Both are necessary for projecting the semantic representations of individuallexical items onto a sentence level interpretation.
The discussion here, however, willbe limited to a description of projective inheritance and the notion of "degrees ofprototypicality" of predication.
I will argue that such degrees of salience or coherencerelations can be explained in structural terms by examining a network of related lexicalitems.
25I will illustrate the distinction between these mechanisms by considering the twosentences in Example 58, and their relative prototypicality.Example 58a.
The prisoner escaped last night.b.
The prisoner ate dinner last night.Both of these sentences are obviously well-formed syntactically, but there is a definitesense that the predication i  58(a) is "tighter" or more prototypical than that in 58(b).What would account for such a difference?
Intuitively, we associate prisoner with anescaping event more strongly than an eating event.
Yet this is not information thatcomes from a fixed inheritance structure, but is rather usually assumed to be com-monsense knowledge.
In what follows, however, I will show that such distinctions25 Anick and Pustejovsky (1990) explore how metrics such as association ratios can be used to statisticallymeasure the notions of prototypicality mentioned here.433Computational Linguistics Volume 17, Number 4can be captured within a theory of lexical semantics by means of generating ad hoccategories.First, we give a definition for the fixed inheritance structure of a lexical item (cf.Touretzky 1986).
Let Q and P be concepts in our model of lexical organization.
Then:DefinitionA sequence (Q1, P1,..., Pn) is an inheritance path, which can be read as the conjunctionof ordered pairs {(xl,yi) \[ 1 < i < n}.Furthermore, following Touretsky, from this we can define the set of concepts that lieon an inheritance path, the conclusion space.DefinitionThe conclusion space of a set of sequences ?
is the set of all pairs (Q, P) such that asequence (Q,.
.
.
,  P) appears in q~.From these two definitions we can define the traditional i s -a  relation, relating theabove pairs by a generalization operator, ~G, 26 as  well as other relations that I will notdiscuss.
27Let us suppose that, in addition to these fixed relational structures, our semanticsallows us to dynamically create arbitrary concepts through the application of certaintransformations to lexical meanings.
For example, for any predicate, Q - -  e.g.
thevalue of a qualia role - -  we can generate its opposition, ~Q (cf.
Pustejovsky 1991).By relating these two predicates temporally we can generate the arbitrary transitionevents for this opposition (cf.
Wright 1963):Example 59a.
~Q(x) <_ Q(x)b. Q(x) < -~Q(x)c. Q(x) < Q(x)d. ~Q(x) < -~Q(x)Similarly, by operating over other qualia role values we can generate semanticallyrelated concepts.
I will call any operator that performs uch an operation a projectivetransformation, and define them below:DefinitionA projective transformation, Tr, on a predicate Q1 generates a predicate, Q2, such that7r(Q1) = Q2, where Q2 ~ ~.
The set of transformations includes: 7, negation, _<,temporal precedence, >_, temporal succession, =, temporal equivalence, and act,an operator adding agency to an argument.Intuitively, the space of concepts traversed by the application of such operatorswill be related expressions in the neighborhood of the original exical item.
This spacecan be characterized by the following two definitions:26 See, for example, Michalski (1983) and Smolka (1988) for a treatment making use of subsorts.27 Such relations include not only hypernymy and hopyonymy, but also troponymy, which relates verbsby manner relations (cf.
Miller 1985; Beckwith et al 1989; Miller and Fellbaum 1991.434James Pustejovsky The Generative LexiconDefinitionA series of applications of transformations, ~rl,..., 7rn, generates a sequence of predi-cates, (Q1,..., Qnl, called the projective xpansion of Q1, P(Q1).DefinitionThe projective conclusion space, P(@R), is the set of projective xpansions generatedfrom all elements of the conclusion space, ~, on role R of predicate Q: as: P(~R) ={(P(Q1),P(Qn)> \[ (QI,... ,Qn) E ~R}.From this resulting representation, we can generate a relational structure that canbe considered the set of ad hoc categories and relations associated with a lexical item(cf.
Barselou 1983).Using these definitions, let us return to the sentences in Example 58.
I will assumethat the noun prisoner has a qualia structure such as that shown in 60.Example 60Qualia Structure of prisoner(x):prisoner(*x*)Form: human(*x*)Telic: \[confine(y,*x*) location(*x*,prison)\]Furthermore, I assume the following lexical structure for escape.Example 61Lexical Semantics for escape:AxAeT3e p, eS\[escape(e T) A act(e P) A confined(d) A agent(e p, x)A -~confined(e s) A object(e s, x)\]Using the representation in 60 above, I now trace part of the derivation of theprojective conclusion space for prisoner.
Inheritance structures are defined for eachqualia role of an element.
In the case above, values are specified for only two roles.For each role, R, we apply a projective transformation 7r onto the predicate Q that isthe value of that role.
For example, from the telic role of prisoner we can generalize (e.g.drop the conjunct) to the concept of being confined.
From this concept, we can apply thenegation operator, generating the predicate opposition of not-confined and confined.
Tothis, we apply the two temporal operators, < and >, generating two states: free beforecapture and free after capture.
Finally, to these concepts, if we apply the operator act,varying who is responsible for the resulting transition event, we generate the concepts:turn in, capture, escape, and release.Example 62Projecting on Telic Role of prisoner:a.
~c: \[confine(y, x) A loc(x, prison)\] ~ confine(y, x)b.
7:BE1 \[-~confine(E1, y, x)\]c. 3E2 \[confine(E2, y x)\]d. ~: E1 _< E2 = T1e.
<_: E2 <_ E1 = T2f.
act: act(x, T1) = "turn in"435Computational Linguistics Volume 17, Number 4g.
act: act(y, T1) = "capture"h. act: act(x, T2) = "escape"i. act: act(y, T2) = "release"These relations constitute the projective conclusion space for the telic role of prisonerrelative to the application of the transformations mentioned above.
Similar operationson the formal role will generate concepts uch as die and kill.
Generating such structuresfor all items in a sentence during analysis, we can take those graphs that result in nocontradictions to be the legitimate semantic interpretations of the entire sentence.Let us now return to the sentences in Example 58.
It is now clear why these twosentences differ in their prototypicality (or the relevance conditions on their predi-cation).
The predicate at is not within the space of related concepts generated fromthe semantics of the NP the prisoner; escape, however, did fall within the projectiveconclusion space for the Telic role of prisoner, as shown in Example 63.Example 63Conclusion Space for (58):escape c P(~T(prisoner))eat ~ P( ~T(prisoner) )This is illustrated in Example 64 below.Example 64release(T, y, *x*) escape(T, *x*) capture(T, y, *x*) turn-in(T, *x*)81 ~ S2 82 _~ $1-~confined(S2, y *x*)Iconfined(S1, y, *x*)Formal Telic escape(T, *x*)the prisoner escapedI IDet N VNP VP ~ j fSWe can therefore use such a procedure as one metric for evaluating the "proximity"of a predication (Quillian 1968; Hobbs 1982).
In the examples above, the difference436James Pustejovsky The Generative Lexiconin semanticality can now be seen as a structural distinction between the semanticrepresentations for the elements in the sentence.In this section, I have shown how the lexical inheritance structure of an itemrelates, in a generative fashion, the decompositional structure of a word to a muchlarger set of concepts that are related in obvious ways.
What we have not addressed,however, is how the fixed inheritance information of a lexical item is formally derivableduring composition.
This issue is explicitly addressed in Briscoe et al (1990) as wellas Pustejovsky and Briscoe (1991).8.
ConclusionIn this paper I have outlined a framework for lexical semantic research that I believecan be useful for both computational linguists and theoretical linguists alike.
I arguedagainst he view that word meanings are fixed and inflexible, where lexical ambigu-ity must be treated by multiple word entries in the lexicon.
Rather, the lexicon canbe seen as a generative system, where word senses are related by logical operationsdefined by the well-formedness rules of the semantics.
In this view, much of the lex-ical ambiguity of verbs and prepositions i eliminated because the semantic load isspread more evenly throughout the lexicon to the other lexical categories.
I describeda language for structuring the semantic information carried by nouns and adjectives,termed Qualia structure, as well as the rules of composition that allow this informationto be incorporated into the semantic interpretation of larger expressions, includingexplicit methods for type coercion.
Finally, I discussed how these richer lexical repre-sentations can be used to generate projective inheritance structures that connect heconceptual information associated with lexical items to the global conceptual lexicon.This suggests a way of accounting for relations uch as coherence and the prototyp-icality of a predication.
Although much of what I have presented here is incompleteand perhaps omewhat programmatic, I firmly believe this approach can help clarifythe nature of word meaning and compositionality n natural language, and at the sametime bring us closer to understanding the creative use of word senses.AcknowledgmentsI would like to thank the following forcomments on earlier drafts of this paper:Peter Anick, Sabine Bergler, Bran Boguraev,Ted Briscoe, Noam Chomsky, Bob Ingria,George Miller, Sergei Nirenburg, and RichThomason.ReferencesAnick, P., and Pustejovsky, J.
(1990).
"Anapplication of lexical semantics toknowledge acquisition from corpora."
InProceedings, 13th International Conference onComputational Linguistics, Helsinki,Finland.Atkins, Beryl T. (1987).
"Semantic ID tags:corpus evidence for dictionary senses."
InProceedings, 3rd Annual Conference atUniversity of Waterloo, Center for the NewOED.Atkins, Beryl; Kegl, Judy; and Levin, Beth(1988).
"Anatomy of a verb entry.
"International Journal of Lexicography,1:84-126.Atkins, Beryl; Klavans, Judith; andBoguraev, Bran.
"Semantic verb clustersfrom MRDs."
Forthcoming.Bach, Emmon (1986).
"The algebra ofevents.
Linguistics and Philosophy, 9: 5-16.Barselou, Lawrence W. (1983) "Ad hoccategories."
Memory and Cognition,11:211-227.Beckwith, Richard; FeUbaum, C.; Gross, D.;and Miller, G. (1989).
"WordNet: A lexicaldatabase organized on psycholinguisticprinciples."
Proceedings, First InternationalWorkshop on Lexical Acquisition, IJCAI,Detroit.Bobrow, D. G., and Winograd, T.
(1977).
"An overview of KRL, a knowledgerepresentation language."
CognitiveScience, 1:3-46.Boguraev, Bran, and Briscoe, Ted (eds.)(1988).
Computational Lexicography forNatural Language Processing.
Harlow,437Computational Linguistics Volume 17, Number 4Essex: Longman.Boguraev, Bran, and Pustejovsky, James.Lexical Knowledge: Representation a dAcquisition.
Forthcoming.
Cambridge,MA: The MIT Press.Brachman, Ronald J.
(1979).
"On theepistemelogical status of semanticnetworks."
In Associative Networks:Representation a d Use of Knowledge byComputers, edited by N. Findler.
NewYork: Academic Press.Brachman, R. J., and Schmolze, J.
(1985).
"An overview of the KL-ONE knowledgerepresentation system."
Cognitive Science,9:171-216.Bresnan, Joan (ed.)
(1982).
The MentalRepresentation f Grammatical Relations.Cambridge, MA: The MIT Press.Briscoe, E., Copestake, A., and Boguraev, B.(1990).
"Enjoy the paper: lexical semanticsvia lexicology."
In Proceedings, 13thInternational Conference on ComputationalLinguistics, Helsinki, Finland.Cardelli, L., and Wegner, P. (1985).
"Onunderstanding types, data abstraction,and polymorphism."
ACM ComputingSurveys, 17(4): 471-522.Carlson, Gregory (1977).
"Reference tokinds in English."
Doctoral dissertation,University of Massachusetts.Carnap, Rudolf (1956).
Meaning andNecessity.
Chicago: University of ChicagoPress.Charniak, Eugene, and Goldman, Robert(1988).
"A logic for semanticinterpretation."
In Proceedings, 26thAnnual Meeting of the Association forComputational Linguistics, Buffalo, NY.Chierchia, G. (1989).
"Structured meanings,thematic roles, and control."
In Properties,Types, and Meaning, Volume 2, edited byG.
Chierchia, B. Partee, and R. Turner.Dordrect: Kluwer Academic Publishers.Chomsky, Noam (1975).
The Logical Structureof Linguistic Theory.
Chicago: University ofChicago Press.Chomsky, Noam (1981).
Lectures onGovernment and Binding.
Dordrect: ForisPublications.Collins, A., and Quillian, M.
(1969).
"Retrieval time from semantic memory.
"Journal of Verbal Learning and VerbalBehavior, 9: 240-247.Copestake, A., and Briscoe, T.
(1991).
"Lexical operations in a unification-basedframework."
In Proceedings, SIGLEXWorkshop on Lexical Semantics andKnowledge Representation, edited byJ.
Pustejovsky and S. Bergler, Berkeley,CA.Croft, William (1991).
Categories andRelations in Syntax: The Clause-LevelOrganization of Information.
Chicago:University of Chicago Press.Cruse, D. A.
(1986).
Lexical Semantics.Cambridge, U.K.: Cambridge UniversityPress.Dixon, R. M. W. (1991).
A New Approach toEnglish Grammar, on Semantic Principles,Oxford, U.K., Oxford University Press.Dowty, David R. (1979).
Word Meaning andMontague Grammar.
Dordrecht: D. Reidel.Dowty, David R. (1985).
"On some recentanalyses of control."
Linguistics andPhilosophy, 8: 1--41.Dowty, David R. (1989).
"On the semanticcontent of the notion 'thematic role'."
InProperties, Types, and Meaning Volume II,edited by G. Chierchia, B. Partee, andR.
Turner.
Dordrect: Kluwer AcademicPublishers.Elliott, D. E. (1974).
"Towards a grammar ofexclamations."
Foundations of Language,11:231-246.Evans, Roger, and Gazdar, Gerald (1989).
"Inference in DATR."
In Proceedings,Fourth European ACL Conference.Manchester, England.Evans, Roger, and Gazdar, Gerald (1990).
"The DATR papers: February 1990,"Cognitive Science Research Paper CSRP139, School of Cognitive and ComputingScience, University of Sussex, Brighton,England.Fass, Dan (1988).
"Collative semantics: Asemantics for natural anguageprocessing."
MCCS-99-118, ComputingResearch Laboratory, New Mexico StateUniversity.Fauconnier, G. (1985).
Mental Spaces.Cambridge, MA: The MIT Press.Fillmore, Charles (1968).
"The case forcase."
In Universals in Linguistic Theory,edited by E. Bach and R. Harms.
NewYork: Holt, Rinehart, and Winston.Fillmore, Charles (1985).
"Constructiongrammar."
Ms.Flickinger, D.; Pollard, C.; and Wasow, T.(1985).
"Structure-sharing i  lexicalrepresentation."
In Proceedings, 23rdAnnual Meeting of the ACL.
Chicago, IL.Fodor, Jerry (1975).
The Language of Thought.Cambridge, MA: Harvard UniversityPress.Freed, A. F. (1979).
The Semantics of EnglishAspectual Complementation.
Dordrecht:Reidel.Gazdar, G.; Klein, E.; Pullum, G; and Sag, I.(1985).
Generalized Phrase StructureGrammar.
Cambridge, MA: HarvardUniversity Press.438James Pustejovsky The Generative LexiconGoodman, Nelson (1951).
The Structure ofAppearance.
Dordrecht: Reidel.Grice, H. P. (1971).
"Meaning."
In Semantics:An Interdisciplinary Reader in Philosophy,Linguistics, and Psychology, edited byD.
Steinberg and L. Jacobovits.Cambridge: Cambridge University Press.Grimshaw, Jane (1979).
"Complementselection and the lexicon."
LinguisticInquiry, 10:279-326.Grimshaw, Jane (1990).
Argument Structure.Cambridge, MA: The MIT Press, in press.Gruber, Jeffrey (1965).
"Studies in lexicalrelations."
Doctoral dissertation,Massachusetts Institute of Technology.Hale, Ken, and Keyser, S. J.
(1986).
"Sometransitivity alternations in English.
"Lexicon Project Working Papers 7, Centerfor Cognitive Science, MIT.Hale, Ken, and Keyser, S. J.
(1987).
"A viewfrom the middle."
Lexicon ProjectWorking Papers 10, Center for CognitiveScience, MIT.Hayes, Patrick (1979).
"Naive physicsmanifesto."
In Expert Systems in theMicro~Electronic Age, edited by DonaldMitchie.
Edinburgh: EdinburghUniversity Press.Higginbotham, James (1985).
"Onsemantics."
Linguistic Inquiry, 16:547-593.Hinrichs, Erhard W. (1985).
"Acompositional semantics for aktionartenand NP reference in English."
Doctoraldissertation, Ohio State University.Hirst, Graeme (1987).
Semantic Interpretationand the Resolution of Ambiguity.Cambridge: Cambridge University Press.Hobbs, Jerry (1982).
"Towards anunderstanding of coherence in discourse.
"In Strategies for Natural LanguageProcessing, edited by W. Lehnert andM.
Ringle.
Hillsdale, NJ: LawrenceErlbaum Associates.Hobbs, Jerry (1987).
"World knowledge andword meaning."
In Proceedings, TINLAP-3.Las Cruces, NM.Hobbs, Jerry; Croft, William; Davies, Todd;Edwards, Douglas; and Laws, Kenneth.(1987).
"Commonsense metaphysics andlexical semantics."
ComputationalLinguistics, 13:241-250.Hobbs, Jerry; Croft, William; Davies, Todd;Edwards, Douglas; and Laws, Kenneth,"The TACITUS commonsense knowledgebase."
Artificial Intelligence Center, SRIInternational.Hobbs, Jerry; Stickel, Mark; Martin, Paul;and Edwards, Douglas (1988).
"Interpretation asabduction."
InProceedings, 26th Annual Meeting of theAssociation for Computational Linguistics.Buffalo, NY.Ingria, Robert, and Pustejovsk~; James(1990).
"Active objects in syntax,semantics, and parsing."
In The MITParsing Volume, 1989-1990, edited byCarol Tenny.
Center for Cognitive Science,MIT.Jackendoff, Ray (1972).
SemanticInterpretation i Generative Grammar.Cambridge, MA: The MIT Press.Jackendoff, Ray (1983).
Semantics andCognition.
Cambridge, MA: The MITPress.Katz, Jerrold J.
(1972).
Semantic Theory.
NewYork: Harper and Row.Katz, Jerrold J., and Fodor, Jerry (1963).
"The structure of a semantic theory.
"Language, 39(2): 170-210.Karttunen, Lauri (1971).
"Implicativeverbs."
Language, 47: 340-58.Karttunen, Lauri (1974).
"Presuppositionand linguistic context."
TheoreticalLinguistics 1: 181-93.Katz, Jerrold, and Fodor, Jerry (1963).
"Thestructure of a semantic theory."
Language,39: 170-210.Keenan, Edward, and Faltz, Leonard (1985).Boolean Semantics for Natural Language.Dordrect: Reidel.Klein, E., and Sag, I.
(1985).
"Type-driventranslation."
Linguistics and Philosophy, 8:163-202.Krifka, Manfred (1987).
"Nominal referenceand temporal constitution: Towards asemantics of quantity."
FNS-Bericht 17.Forschungsstelle ffir natfirlich-sparchlicheSystem, Universit~it Tfbingen.Lakoff, George (1970).
Irregularity in Syntax.Holt, Rinehart, and Winston.Lakoff, George (1971).
"On generativesemantics."
In Semantics: AnInterdisciplinary Reader, edited byD.
Steinberg and L. Jakobovits.Cambridge University Press.Lakoff, George (1987).
Women, Fire, andDangerous Objects.
Chicago: University ofChicago Press.Levin, Beth (ed.)
(1985).
"Lexical semanticsin review," Lexicon Project WorkingPapers Number 1, MIT.Levin, B.
Towards a Lexical Organization ofEnglish Verbs.
Chicago: University ofChicago Press.
Forthcoming.Levin, Beth, and Rapoport, T. R.
(1988).
"Lexical subordination."
Proceedings ofCLS 24, 275-289.Levin, Beth, and Rappaport, Malka (1986).
"The formation of adjectival passives.
"Linguistic Inquiry, 17:623-663.Levin, Beth, and Rappaport, Malka (1988).
"On the nature of unaccusativity."
In439Computational Linguistics Volume 17, Number 4Proceedings, NELS 1988.Levin, Beth, and Rappaport, Malka.Unaccusatives.
The MIT Press,forthcoming.Lloyd, G. E. R. (1968).
Aristotle: The Growthand Structure of his Thought.
CambridgeUniversity Press.McKeon, Richard (1941).
The Basic Works ofAristotle.
Random House.Mel'~uk, I.
(1988).
Dependency Syntax.Albany, NY: SUNY Press.Michalski, R. S. (1983).
"A theory andmethodology of inductive learning."
InMachine Learning L R. S. Michalski,J.
Carbonelli, and T. Mitchell, eds.
PaloAlto, CA: Tioga Publishing.Miller, George (1985).
"Dictionaries of themind."
In Proceedings, 23rd AnnualMeeting of the Association for ComputationalLinguistics, Chicago, IL.Miller, G. A., and Fellbaum, C.
(1991).
"Semantic networks of English.
"Cognition, October 1991.Miller, George, and Johnson-Laird, Phillip(1976).
Language and Perception.Cambridge, MA: Belknap, HarvardUniversity Press.Moens, M., and Steedman, M.
(1988).
"Temporal ontology and temporalreference."
Computational Linguistics, 14(2):15-28.Montague, Richard (1974).
FormalPhilosophy: The Collected Papers of RichardMontague, edited by Richard Thomason.New Haven: Yale University Press.Moravcsik, J. M. (1975).
"Aitia as generativefactor in Aristotle's philosophy."
Dialogue,14:622-636.Mourelatos, Alexander (1981).
"Events,processes, and states."
In Syntax andSemantics: Tense and Aspect, edited byP.
Tedeschi and A. Zaenen.
New York:Academic Press.Nunberg, G. (1978).
The Pragmatics ofReference.
Bloomington, Indiana: IndianaUniversity Linguistics Club.Quillian, M. Ross (1968).
"Semanticmemory," In Semantic InformationProcessing, edited by M. Minsky.Cambridge, MA: The MIT Press.Partee, Barbara, and Rooth, Mats (1983).
"Generalized conjunction and typeambiguity."
In Meaning, Use, andInterpretation ofLanguage, edited byB~iuerle, Schwarze, and von Stechow.Walter de Gruyter.Passonneau, Rebecca J.
(1988).
"Acomputational model of the semantics oftense and aspect."
ComputationalLinguistics, 14(2).Pustejovsky, James (1988).
"The geometry ofevents."
In Studies in Generative Approachesto Aspect, edited by Carol Tenny.
LexiconProject Working Papers 24, MIT.Pustejovsky, James (1989a).
"Type coercionand selection."
Paper presented at WestCoast Conference on Formal Linguistics.Vancouver.Pustejovsky, James (1989b).
"Issues incomputational lexical semantics."
InProceedings, Fourth European ACLConference, Manchester, England.Pustejovsky, James (1991).
"The syntax ofevent structure."
Cognition, 41.Pustejovsky, James (in press a).
"Principlesversus criteria: On Randall's catapulthypothesis."
In Theoretical Issues inLanguage Acquisition, edited byJ.
Weissenborn, H. Goodluck, andT.
Roeper.
Dordrecht: Kluwer AcademicPublishers.Pustejovsky, James (in press b).
"Typecoercion and lexical selection."
InSemantics and the Lexicon, edited byJ.
Pustejovsky.
Dordrecht: KluwerAcademic Publishers.Pustejovsky, James (forthcoming).
TheGenerative Lexicon: A Theory ofComputational Lexical Semantics.Cambridge, MA: The MIT Press.Pustejovsky, James, and Anick, Peter (1988).
"On the semantic interpretation fnominals."
In Proceedings, COLING-1988,Budapest.Pustejovsky, James, and Bergler, Sapine, eds.
(in press).
Lexical Semantics andCommonsense R asoning.
Berlin: SpringerVerlag.Pustejovsky, James, and Boguraev, Bran(1991).
"Lexical knowledge representationand natural language processing."
In IBMJournal of Research and Development, 45:4.Roberts, R. B., and Goldstein, (1977).
TheFRL Manual, Technical Report AI Memo409, MIT Artificial Intelligence Laboratory.Scha, Remko J. H. (1983).
"Logicalfoundations for question answering.
"MS 12.331 Philips Research Laboratories,Eindhoven, the Netherlands.Schank, Roger (1975).
Conceptual InformationProcessing.
Amsterdam: North-Holland.Sueren, Pieter (1985).
Discourse Semantics.Oxford: Blackwell Publishers.Smolka, G. (1988).
"A feature logic withsubsorts."
Wissenschaftliches Zentrumder IBM Deutschland, LILOG-Report 33.Stump, G. (1981).
"Frequency adjectives.
"Linguistics and Philosophy, 4:221-258.Talmy, Len (1975).
"Semantics and syntax ofmotion."
In Syntax and Semantics 4, edited440James Pustejovsky The Generative Lexiconby J. P. Kimball.
New York: AcademicPress.Talmy, Len (1985).
"Lexicalization patterns.
"In Language Typology and SyntacticDescription, edited by Timothy Shopen.Cambridge.Tenny, Carol (1987).
"Grammaticalizingaspect and affectedness."
Doctoraldissertation, MIT.Tenny, Carol (1989).
"The aspectual interfacehypothesis," Lexicon Project WorkingPapers 31, MIT.Touretzky, David S. (1986).
The Mathematicsof Inheritance Systems.
Los Altos, CA:Morgan Kaufmann.Vendler, Zeno (1967).
Linguistics andPhilosophy.
Ithaca, NY: Cornell UniversityPress.Verma, Manindra, and Mohanan, K. P.(1991).
Experiencer Subjects in South AsianLanguages, CSLI.
Distributed byUniversity of Chicago Press.Walker, Donald; Zampolli, Antonio, andCalzolari, Nicoletta, (eds.)
(forthcoming).Automating the Lexicon.
Oxford UniversityPress.Weinreich, Uriel (1972).
Explorations inSemantic Theory.
The Hague: Mouton.Wierzbicka, Anna (1988).
The Semantics ofGrammar.
Amsterdam: John Benjamins.Wilks, Yorick (1975a).
"A preferentialpattern seeking semantics for naturallanguage inference."
Artificial Intelligence,6: 53-74.Wilks, Yorick (1975b).
"An intelligentanalyser and understander for English.
"Communications of the ACM, 18: 264-274.Wilks, Yorick; Fass, Dan; Guo, Cheng-Ming;McDonald, James; Plate, Tony; and Slator,Brian (1988).
"A tractable machinedictionary as a resource for computationalsemantics."
In Computational Lexicographyfor Natural Language Processing, edited byBran Boguraev and Ted Briscoe.
Harlow,Essex: Longman.Williams, Edwin (1981).
"Argumentstructure and morphology."
LinguisticReview, 1:81-114.von Wright, Georg H. (1963).
Norm andAction: A Logical Inquiry.
London:Routledge and Kegan Paul.441
