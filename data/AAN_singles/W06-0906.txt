Proceedings of the Workshop on Annotating and Reasoning about Time and Events, pages 38?45,Sydney, July 2006. c?2006 Association for Computational LinguisticsExtending TimeML with Typical Durations of EventsFeng Pan, Rutu Mulkar, and Jerry R. HobbsInformation Sciences Institute (ISI), University of Southern California4676 Admiralty Way, Marina del Rey, CA 90292, USA{pan, rutu, hobbs}@isi.eduAbstractIn this paper, we demonstrate how to ex-tend TimeML, a rich specification lan-guage for event and temporal expressionsin text, with the implicit typical durationsof events, temporal information in textthat has hitherto been largely unexploited.Event duration information can be veryimportant in applications in which thetime course of events is to be extractedfrom text.
For example, whether twoevents overlap or are in sequence oftendepends very much on their durations.1 IntroductionTemporal information processing has becomemore and more important in many natural lan-guage processing (NLP) applications, such asquestion answering (Harabagiu and Bejan, 2005;Moldovan et.
al., 2005; Saur?
et.
al., 2005),summarization (Mani and Schiffman, 2005), andinformation extraction (Surdeanu et.
al., 2003).Temporal anchoring and event ordering areamong the most important kinds of temporal in-formation needed for NLP applications.
Al-though there has been much work on extractingand inferring such information from texts(Hitzeman et al, 1995; Mani and Wilson, 2000;Filatova and Hovy, 2001; Boguraev and Ando,2005), none of this work has exploited the im-plicit event duration information from the text.Consider the sentence from a news article:George W. Bush met with Vladimir Putin inMoscow.How long was the meeting?
Our first reactionto this question might be that we have no idea.But in fact we do have an idea.
We know themeeting was longer than 10 seconds and lessthan a year.
How much tighter can we get thebounds to be?
Most people would say the meet-ing lasted between an hour and three days.There is much temporal information in textthat has hitherto been largely unexploited, en-coded in the descriptions of events and relyingon our knowledge of the range of usual durationsof types of events, which can be very importantin applications in which the time course of eventsis to be extracted from news.
For example,whether two events overlap or are in sequenceoften depends very much on their durations.
If awar started yesterday, we can be pretty sure it isstill going on today.
If a hurricane started lastyear, we can be sure it is over by now.To extract such implicit event duration infor-mation from texts automatically, we developed acorpus annotated with typical durations of events(Pan et al, 2006a) which currently contains allthe 48 non-Wall-Street-Journal (non-WSJ) newsarticles (a total of 2132 event instances), as wellas 10 WSJ articles (156 event instances), fromthe TimeBank corpus annotated in TimeML(Pustejovky et al, 2003).Because the annotated corpus is still fairlysmall, we cannot hope to learn to make fine-grained judgments of event durations that arecurrently annotated in the corpus, but as we showin greater detail in (Pan et al, 2006b), it is possi-ble to learn useful coarse-grained judgments thatconsiderably outperform a baseline and approachhuman performance.This paper describes our work on extendingTimeML with annotations of typical durations ofevents, which can enrich the expressiveness ofTimeML, and provides NLP applications thatexploit TimeML with this additional implicitevent duration information for their temporalinformation processing tasks.In Section 2 we first describe the corpus oftypical durations of events, including the annota-tion guidelines, the representative event classeswith examples, the inter-annotator agreement38study, and the machine learning results.
TimeMLand its event classes will be described in Section3, and we will discuss how to integrate event du-ration annotations into TimeML in Section 4.2 Annotating and Learning Typical Du-ration of EventsIn the corpus of typical durations of events, everyevent to be annotated was already identified inthe TimeBank corpus.
Annotators are asked toprovide lower and upper bounds on the durationof the event, and a judgment of level of confi-dence in those estimates on a scale from one toten.
An interface was built to facilitate the anno-tation.
Graphical output is displayed to enable usto visualize quickly the level of agreementamong different annotators for each event.
Forexample, here is the output of the annotations (3annotators) for the ?finished?
event (in bold) inthe sentenceAfter the victim, Linda Sanders, 35, had fin-ished her cleaning and was waiting for herclothes to dry,...This graph shows that the first annotator believesthat the event lasts for minutes whereas the sec-ond annotator believes it could only last for sev-eral seconds.
The third annotates the event torange from a few seconds to a few minutes.
Alogarithmic scale is used for the output.2.1 Annotation InstructionsAnnotators are asked to identify upper and lowerbounds that would include 80% of the possiblecases, excluding anomalous cases.The judgments are to be made in context.First of all, information in the syntactic environ-ment needs to be considered before annotating,and the events need to be annotated in light ofthe information provided by the entire article.Annotation is made easier and more consistent ifcoreferential and near-coreferential descriptionsof events are identified initially.When the articles were completely annotatedby the three annotators, the results were analyzedand the differences were reconciled.
Differencesin annotation could be due to the differences ininterpretations of the event; however, we foundthat the vast majority of radically different judg-ments can be categorized into a relatively smallnumber of classes.
Some of these correspond toaspectual features of events, which have beenintensively investigated (e.g., Vendler, 1967;Dowty, 1979; Moens and Steedman, 1988; Pas-sonneau, 1988).
We then developed guidelines tocover those cases (see the next section).2.2 Event ClassesAction vs. State: Actions involve change, suchas those described by words like "speaking","gave", and "skyrocketed".
States involve thingsstaying the same, such as being dead, being dry,and being at peace.
When we have an event inthe passive tense, sometimes there is an ambigu-ity about whether the event is a state or an action.For example,Three people were injured in the attack.Is the ?injured?
event an action or a state?
Thismatters because they will have different dura-tions.
The state begins with the action and lastsuntil the victim is healed.
Besides the generaldiagnostic tests to distinguish them (Vendler,1967; Dowty, 1979), another test can be appliedto this specific case: Imagine someone says thesentence after the action had ended but the statewas still persisting.
Would they use the past orpresent tense?
In the ?injured?
example, it isclear we would say ?Three people were injuredin the attack?, whereas we would say ?Threepeople are injured from the attack.?
Our annota-tion interface handles events of this type by al-lowing the annotator to specify which interpreta-tion he is giving.
If the annotator feels it?s tooambiguous to distinguish, annotations can begiven for both interpretations.Aspectual Events:  Some events are aspects oflarger events, such as their start or finish.
Al-though they may seem instantaneous, we believethey should be considered to happen across someinterval, i.e., the first or last sub-event of the lar-ger event.
For example,After the victim, Linda Sanders, 35, had fin-ished her cleaning and was waiting for herclothes to dry,?The ?finished?
event should be considered as thelast sub-event of the larger event (the ?cleaning?event), since it actually involves opening thedoor of the washer, taking out the clothes, clos-ing the door, and so on.
All this takes time.
This39interpretation will also give us more informationon typical durations than simply assuming suchevents are instantaneous.Reporting Events: These are everywhere in thenews.
They can be direct quotes, taking exactlyas long as the sentence takes to read, or they canbe summarizations of long press conferences.
Weneed to distinguish different cases:Quoted Report: This is when the reportedcontent is quoted.
The duration of the eventshould be the actual duration of the utterance ofthe quoted content.
The time duration can be eas-ily verified by saying the sentence out loud andtiming it.
For example,"It looks as though they panicked," a detectivesaid of the robbers.This probably took between 1 and 3 seconds; it?svery unlikely it took more than 10 seconds.Unquoted Report: This is when the reportingdescription occurs without quotes that could beas short as just the duration of the actual utter-ance of the reported content (lower bound), andas long as the duration of a briefing or press con-ference (upper bound).If the sentence is very short, then it's likelythat it is one complete sentence from thespeaker's remarks, and a short duration should begiven; if it is a long, complex sentence, then it'smore likely to be a summary of a long discussionor press conference, and a longer duration shouldbe given.
For example,The police said it did not appear that anyoneelse was injured.A Brooklyn woman who was watching herclothes dry in a laundromat was killed Thursdayevening when two would-be robbers emptiedtheir pistols into the store, the police said.If the first sentence were quoted text, it would bevery much the same.
Hence the duration of the?said?
event should be short.
In the second sen-tence everything that the spokesperson (here thepolice) has said is compiled into a single sen-tence by the reporter, and it is unlikely that thespokesperson said only a single sentence with allthis information.
Thus, it is reasonable to givelonger duration to this ?said?
event.Multiple Events: Many occurrences of verbsand other event descriptors refer to multipleevents, especially, but not exclusively, if the sub-ject or object of the verb is plural.
For example,Iraq has destroyed its long-range missiles.Both single (i.e., destroyed one missile) and ag-gregate (i.e., destroyed all missiles) events hap-pened.
This was a significant source in dis-agreements in our first round of annotation.Since both judgments provide useful informa-tion, our current annotation interface allows theannotator to specify the event as multiple, andgive durations for both the single and aggregateevents.Events Involving Negation: Negated eventsdidn't happen, so it may seem strange to specifytheir duration.
But whenever negation is used,there is a certain class of events whose occur-rence is being denied.
Annotators should con-sider this class, and make a judgment about thelikely duration of the events in it.
In addition,there is the interval during which the nonoccur-rence of the events holds.
For example,He was willing to withdraw troops in ex-change for guarantees that Israel would not beattacked.There is the typical amount of time of ?beingattacked?, i.e., the duration of a single attack, anda longer period of time of ?not being attacked?.Similarly to multiple events, annotators are askedto give durations for both the event negated andthe negation of that event.Positive Infinite Durations: These are stateswhich continue essentially forever once they be-gin.
For example,He is dead.Here the time continues for an infinite amountof time, and we allow this as an annotation.2.3 Inter-Annotator AgreementAlthough the graphical output of the annotationsenables us to visualize quickly the level of agree-ment among different annotators for each event,a quantitative measurement of the agreement isneeded.
The kappa statistic (Krippendorff, 1980;Carletta, 1996) has become the de facto standardto assess inter-annotator agreement.
It is com-puted as:)(1)()(EPEPAP?
?=?P(A) is the observed agreement among the an-notators, and P(E) is the expected agreement,40Figure 1: Overlap of Judgments of [10 minutes,30 minutes] and [10 minutes, 2 hours].which is the probability that the annotators agreeby chance.2.3.1  What Should Count as Agreement?Determining what should count as agreement isnot only important for assessing inter-annotatoragreement, but is also crucial for later evaluationof machine learning experiments.We first need to decide what scale is most ap-propriate.
One possibility is just to convert all thetemporal units to seconds.
However, this wouldnot correctly capture our intuitions about therelative relations between duration ranges.
Forexample, the difference between 1 second and 20seconds is significant; while the difference be-tween 1 year 1 second and 1 year 20 seconds isnegligible.
In order to handle this problem, weuse a logarithmic scale for our data.
After firstconverting from temporal units to seconds, wethen take the natural logarithms of these values.This logarithmic scale also conforms to the halforders of magnitude (HOM) (Hobbs and Kreino-vich, 2001) which was shown to have utility inseveral very different linguistic contexts.In the literature on the kappa statistic, most au-thors address only category data; some can han-dle more general data, such as data in intervalscales or ratio scales (Krippendorff, 1980; Car-letta, 1996).
However, none of the techniquesdirectly apply to our data, which are ranges ofdurations from a lower bound to an upper bound.In fact, what coders were instructed to anno-tate for a given event is not just a range, but aduration distribution for the event, where thearea between the lower bound and the upperbound covers about 80% of the entire distributionarea.
Since it?s natural to assume the most likelyduration for such distribution is its mean (aver-age) duration, and the distribution flattens outtoward the upper and lower bounds, we use the-5 0 5 10 15 20 25 30020406080100120140160180Means of Annotated DurationsNumber of AnnotatedDurationsFigure 2: Distribution of Means of AnnotatedDurations.normal or Gaussian distribution to model ourduration distributions.In order to determine a normal distribution, weneed to know two parameters: the mean and thestandard deviation.
For our duration distributionswith given lower and upper bounds, the mean isthe average of the bounds.
Under the assumptionthat the area between lower and upper boundscovers 80% of the entire distribution area, thelower and upper bounds are each 1.28 standarddeviations from the mean.With this data model, the agreement betweentwo annotations can be defined as the overlap-ping area between two normal distributions.
Theagreement among many annotations is the aver-age overlap of all the pairwise overlapping areas.For example, the overlap of judgments of [10minutes, 30 minutes] and [10 minutes, 2 hours]are as in Figure 1.
The overlap or agreement is0.508706.2.3.2  Expected AgreementAs in (Krippendorff, 1980), we assume there ex-ists one global distribution for our task (i.e., theduration ranges for all the events), and ?chance?annotations would be consistent with this distri-bution.
Thus, the baseline will be an annotatorwho knows the global distribution and annotatesin accordance with it, but does not read the spe-cific article being annotated.
Therefore, we mustcompute the global distribution of the durations,in particular, of their means and their widths.This will be of interest not only in determiningexpected agreement, but also in terms of what itsays about the genre of news articles and aboutfuzzy judgments in general.We first compute the distribution of the meansof all the annotated durations.
Its histogram isshown in Figure 2, where the horizontal axis41-5 0 5 10 15 20 25050100150200250300350400Widths of Annotated DurationsNumber of AnnotatedDurationsFigure 3: Distribution of Widths of AnnotatedDurations.represents the mean values in the natural loga-rithmic scale and the vertical axis represents thenumber of annotated durations with that mean.We also compute the distribution of the widths(i.e., upper bound ?
lower bound) of all the anno-tated durations, and its histogram is shown inFigure 3, where the horizontal axis represents thewidth in the natural logarithmic scale and thevertical axis represents the number of annotateddurations with that width.Two different methods were used to computethe expected agreement (baseline), both yieldingnearly equal results.
These are described in detailin (Pan et al, 2006a).
For both, P(E) is about0.15.Experimental results show that the use of theannotation guidelines resulted in about 10% im-provement in inter-annotator agreement, meas-ured as described in this section, see (Pan et al,2006a) for details.2.4 Machine Learning Experiments2.4.1  FeaturesLocal Context.
For a given event, the local con-text features include a window of n tokens to itsleft and n tokens to its right, as well as the eventitself.
The best n was determined via cross vali-dation.
A token can be a word or a punctuationmark.
For each token in the local context, includ-ing the event itself, three features are included:the original form of the token, its lemma (or rootform), and its part-of-speech (POS) tag.Syntactic Relations.
The information in theevent?s syntactic environment is very importantin deciding the durations of events.
For a givenevent, both the head of its subject and the head ofits object are extracted from the parse trees gen-erated by the CONTEX parser (Hermjakob andMooney, 1997).
Similarly to the local contextfeatures, for both the subject head and the objecthead, their original form, lemma, and POS tagsare extracted as features.WordNet Hypernyms.
Events with the samehypernyms may have similar durations.
Butclosely related events don?t always have thesame direct hypernyms.
We extract the hy-pernyms not only for the event itself, but also forthe subject and object of the event, since eventsrelated to a group of people or an organizationusually last longer than those involving individu-als, and the hypernyms can help distinguish suchconcepts.
For our learning experiments, we ex-tract the first 3 levels of hypernyms from Word-Net (Miller, 1990).2.4.2  Learning Coarse-grained BinaryEvent DurationsThe distribution of the means of the annotateddurations in Figure 2 is bimodal, dividing theevents into those that take less than a day andthose that take more than a day.
Thus, in our firstmachine learning experiment, we have tried tolearn this coarse-grained event duration informa-tion as a binary classification task.Data.
The original annotated data can bestraightforwardly transformed for this binaryclassification task.
For each event annotation, themost likely (mean) duration is calculated first byaveraging (the logs of) its lower and upper bounddurations.
If its most likely (mean) duration isless than a day (about 11.4 in the natural loga-rithmic scale), it is assigned to the ?short?
eventclass, otherwise it is assigned to the ?long?
eventclass.
(Note that these labels are strictly a con-venience and not an analysis of the meanings of?short?
and ?long?.
)We divide the total annotated non-WSJ data(2132 event instances) into two data sets: a train-ing data set with 1705 event instances (about80% of the total non-WSJ data) and a held-outtest data set with 427 event instances (about 20%of the total non-WSJ data).
The WSJ data (156event instances) is kept for further test purposes.Results.
The learning results in Figure 4 showthat among all three learning algorithms explored(Na?ve Bayes (NB), Decision Trees C4.5, andSupport Vector Machines (SVM)), SVM withlinear kernel achieves the best overall precision(76.6%).
Compared with the baseline (59.0%)and human agreement (87.7%), this level of per-formance is very encouraging, especially as thelearning is from such limited training data.42Figure 4: Overall Test Precision on non-WSJData.Feature evaluation in (Pan et al, 2006b) showsthat most of the performance comes from eventword or phrase itself.
A significant improvementabove that is due to the addition of informationabout the subject and object.
Local context doesnot help and in fact may hurt, and hypernym in-formation also does not seem to help.
It is grati-fying to see that the most important informationis that from the predicate and arguments describ-ing the event, as our linguistic intuitions wouldlead us to expect.In order to evaluate whether the learned modelcan perform well on data from different newsgenres, we tested it on the unseen WSJ data (156event instances).
A precision of 75.0%, which isvery close to the test performance on the non-WSJ data, proves the great generalization capac-ity of the learned model.Some preliminary experimental results oflearning the more fine-grained event durationinformation, i.e., the most likely temporal unit(cf.
(Rieger 1974)?s ORDERHOURS, ORDERDAYS),are shown in (Pan et al, 2006b).
SVM againachieves the best performance with 67.9% testprecision (baseline 51.5% and human agreement79.8%) in ?approximate agreement?
where tem-poral units are considered to match if they are thesame temporal unit or an adjacent one.3 TimeML and Its Event ClassesTimeML (Pustejovsky et al, 2003) is a richspecification language for event and temporalexpressions in natural language text.
Unlike mostprevious attempts at event and temporal specifi-cation, TimeML separates the representation ofevent and temporal expressions from the anchor-ing or ordering dependencies that may exist in agiven text.TimeML includes four major data structures:EVENT, TIMEX3, SIGNAL, AND LINK.EVENT is a cover term for situations that happenor occur, and also those predicates describingstates or circumstances in which something ob-tains or holds true.
TIMEX3, which extendsTIMEX2 (Ferro, 2001), is used to mark up ex-plicit temporal expressions, such as time, dates,and durations.
SIGNAL is used to annotate sec-tions of text, typically function words that indi-cate how temporal objects are related to eachother (e.g., ?when?, ?during?, ?before?).
The setof LINK tags encode various relations that existbetween the temporal elements of a document,including three subtypes: TLINK (temporallinks), SLINK (subordination links), and ALINK(aspectual links).Our event duration annotations can be inte-grated into the EVENT tag.
In TimeML eachevent belongs to one of the seven event classes,i.e., reporting, perception, aspectual, I-action, I-state, state, occurrence.
TimeML annotationguidelines1 give detailed description for each ofthe classes:Reporting.
This class describes the action of aperson or an organization declaring something,narrating an event, informing about an event, etc(e.g., say, report, tell, explain, state).Perception.
This class includes events involv-ing the physical perception of another event (e.g.,see, watch, view, hear).Aspectual.
In languages such as English andFrench, there is a grammatical device of aspec-tual predication, which focuses on different fac-ets of event history, i.e., initiation, reinitiation,termination, culmination, continuation (e.g., be-gin, stop, finish, continue).I-Action.
An I-Action is an Intensional Action.It introduces an event argument (which must bein the text explicitly) describing an action orsituation from which we can infer somethinggiven its relation with the I-Action (e.g., attempt,try, promise).I-State.
This class of events are similar to theprevious class.
This class includes states that re-fer to alternative or possible worlds (e.g., believe,intend, want).State.
This class describes circumstances inwhich something obtains or holds true (e.g., onboard, kidnapped, peace).Occurrence.
This class includes all the manyother kinds of events describing something thathappens or occurs in the world (e.g., die, crash,build, sell).1http://www.cs.brandeis.edu/~jamesp/arda/time/timeMLdocs/annguide12wp.pdf434 Integrating Event Duration Annota-tions into TimeMLOur event duration annotations can be integratedinto TimeML by adding two more attributes tothe EVENT tag for the lower bound and upperbound duration annotations (e.g., ?lowerBound-Duration?
and ?upperBoundDuration?
attributes).To minimize changes of the existing TimeMLspecifications caused by the integration, we cantry to share as much as possible our event classesas described in Section 2.2 with the existing onesin TimeML as described in Section 3.We can see that four event classes are sharedwith very similar definitions, i.e., reporting, as-pectual, state, and action/occurrence.
For theother three event classes that only belong to Ti-meML (i.e., perception, I-action, I-state), the I-action and perception classes can be treated asspecial subclasses of the action/occurrence class,and the I-state class as a special subclass of thestate class.However, there are still three classes that onlybelong to the event duration annotations (i.e.,multiple, negation, and positive infinite).
Thepositive infinite class can be treated as a specialsubclass of the state class with a special durationannotation for positive infinity.Each multiple event has two annotations.
Forexample, forIraq has destroyed its long-range missiles.there is the time it takes to destroy one missileand the duration of the interval in which all theindividual events are situated ?
the time it takesto destroy all its missiles.Since the single event is usually more likely tobe encountered in multiple documents, and thusthe duration of the single event is usually morelikely to be shared and re-used, to simplify thespecification, we can take only the duration an-notation of the single events for the multipleevent class, and the single event can be assignedwith one of the seven TimeML event classes.
Forexample, the ?destroyed?
event in the above ex-ample is assigned with the occurrence class inTimeBank.The events involving negation can be simpli-fied similarly.
Since the event negated is usuallymore likely to be encountered in multiple docu-ments, we can take only the duration annotationof the negated event for this class.
For example,inHe was willing to withdraw troops in ex-change for guarantees that Israel would not beattacked.the event negated is the ?being attacked?
eventand it is assigned with the occurrence class inTimeBank.
Alternatively, TimeML could beextended to treat negations of events as states.The format used for annotated durations isconsistent with that for the value of the DURA-TION type in TimeML.
For example, the sen-tenceThe official said these sites could only be vis-ited by a special team of U.N. monitors and dip-lomats.can be marked up in TimeML as:The official <EVENT eid="e63"class="REPORTING"> said </EVENT>these sites <SIGNAL sid="s65">could</SIGNAL> only be <EVENTeid="e64" class="OCCURRENCE">visited </EVENT> by a special teamof <ENAMEX TYPE="ORGANIZATION"> U.N.</ENAMEX> monitors and diplomats.If we annotate the ?said?
event with the dura-tion annotation of [5 seconds, 5 minutes], and the?visited?
event with [10 minutes, 1 day], the ex-tended mark-up becomes:The official <EVENT eid="e63"class="REPORTING" lowerBoundDura-tion="PT5S" upperBoundDura-tion="PT5M"> said </EVENT> thesesites <SIGNAL sid="s65">could</SIGNAL> only be <EVENTeid="e64" class="OCCURRENCE" lower-BoundDuration="PT10M" upperBoundDu-ration="P1D"> visited </EVENT> by aspecial team of <ENAMEXTYPE="ORGANIZATION"> U.N. </ENAMEX>monitors and diplomats.5 ConclusionIn this paper we have demonstrated how to ex-tend TimeML with typical durations of events.We can see that the extension is very straight-forward.
Other interesting temporal informationcan be extracted or learned.
For example, foreach event class, we can generate its own meanand widths graphs, and learn their durationsseparately from other classes, which may capturedifferent duration characteristics associated witheach event class.44AcknowledgmentsThis work was supported by the Advanced Re-search and Development Activity (ARDA), nowthe Disruptive Technology Office (DTO), underDOD/DOI/ARDA Contract No.
NBCHC040027.The authors have profited from discussions withHoa Trang Dang, Donghui Feng, Kevin Knight,Daniel Marcu, James Pustejovsky, Deepak Ravi-chandran, and Nathan Sobo.ReferencesB.
Boguraev and R. K. Ando.
2005.
TimeML-Compliant Text Analysis for Temporal Reasoning.In Proceedings of the International Joint Confer-enceon Artificial Intelligence (IJCAI).J.
Carletta.
1996.
Assessing agreement on classifica-tion tasks: the kappa statistic.
Computational Lin-gustics, 22(2):249?254.D.
R. Dowty.
1979.
Word Meaning and MontagueGrammar, Dordrecht, Reidel.L.
Ferro.
2001.
Instruction Manual for the Annotationof Temporal Expressions.
Mitre Technical ReportMTR 01W0000046, the MITRE Corporation,McLean, Virginia.E.
Filatova and E. Hovy.
2001.
Assigning Time-Stamps to Event-Clauses.
Proceedings of ACLWorkshop on Temporal and Spatial Reasoning.S.
Harabagiu and C. Bejan.
2005.
Question Answer-ing Based on Temporal Inference.
In Proceedingsof the AAAI-2005 Workshop on Inference for Tex-tual Question Answering, Pittsburgh, PA.U.
Hermjakob and R. J. Mooney.
1997.
LearningParse and Translation Decisions from Exampleswith Rich Context.
In Proceedings of the 35th An-nual Meeting of the Association for ComputationalLinguistics (ACL).J.
Hitzeman, M. Moens, and C. Grover.
1995.
Algo-rithms for Analyzing the Temporal Structure ofDiscourse.
In Proceedings of EACL.
Dublin, Ire-land.J.
R. Hobbs and V. Kreinovich.
2001.
Optimal Choiceof Granularity in Commonsense Estimation: WhyHalf Orders of Magnitude, In Proceedings of Joint9th IFSA World Congress and 20th NAFIPS Inter-national Conference, Vacouver, British Columbia.K.
Krippendorf.
1980.
Content Analysis: An introduc-tion to its methodology.
Sage Publications.I.
Mani and G. Wilson.
2000.
Robust Temporal Proc-essing of News.
In Proceedings of Annual Confer-ence of the Association for Computational Linguis-tics (ACL).I.
Mani and B. Schiffman.
2005.
Temporally Anchor-ing and Ordering Events in News.
In J. Pustejovskyand R. Gaizauskas ed.
Time and Event Recognitionin Natural Language.
John Benjamins.G.
A. Miller.
1990.
WordNet: an On-line Lexical Da-tabase.
International Journal of Lexicography 3(4).M.
Moens and M. Steedman.
1988.
Temporal Ontol-ogy and Temporal Reference.
Computational Lin-guistics 14(2): 15-28.D.
Moldovan, C. Clark, and S. Harabagiu.
2005.Temporal Context Representation and Reasoning.In Proceedings of the International Joint Confer-enceon Artificial Intelligence (IJCAI).F.
Pan, R. Mulkar, and J. R. Hobbs.
2006a.
An Anno-tated Corpus of Typical Durations of Events.
Toappear in Proceedings of the Fifth InternationalConference on Language Resources and Evalua-tion (LREC), Genoa, Italy.F.
Pan, R. Mulkar, and J. R. Hobbs.
2006b.
LearningEvent Durations from Event Descriptions.
To ap-pear in Proceedings of the 44th Conference of theAssociation for Computational Linguistics (COL-ING-ACL), Sydney, Australia.R.
J. Passonneau.
1988.
A Computational Model ofthe Semantics of Tense and Aspect.
ComputationalLinguistics 14:2.44-60.J.
Pustejovsky, J. Castano, R. Ingria, R.
Saur?, R. Gai-zauskas, A. Setzer, and G. Katz.
2003.
TimeML:Robust specification of event and temporal expres-sions in text.
In Proceedings of the AAAI SpringSymposium on New Directions in Question-Answering.C.
J. Rieger.
1974.
Conceptual memory: A theory andcomputer program for processing and meaningcontent of natural language utterances.
StanfordAIM-233.R.
Saur?, R. Knippen, M. Verhagen and J. Puste-jovsky.
2005.
Evita: A Robust Event Recognizerfor QA Systems.
In Proceedings of HLT/EMNLP.M.
Surdeanu, S. Harabagiu, J. Williams, and P.Aarseth.
2003.
Using predicate-argument structuresfor information extraction.
In Proceedings of the41th Annual Conference of the Association forComputational Linguistics (ACL-03), pages 8?15.Z.
Vendler.
1967.
Linguistics in Philosophy, Ithaca,Cornell University Press.45
