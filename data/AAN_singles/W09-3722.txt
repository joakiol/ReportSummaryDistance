Proceedings of the 8th International Conference on Computational Semantics, pages 248?259,Tilburg, January 2009. c?2009 International Conference on Computational SemanticsA Multiclassifier based Approach for Word SenseDisambiguation using Singular ValueDecompositionAna Zelaia, Olatz Arregi and Basilio SierraComputer Science FacultyUniversity of the Basque Countryana.zelaia@ehu.esAbstractIn this paper a multiclassifier based approach is presented for aword sense disambiguation (WSD) problem.
A vector representationis used for training and testing cases and the Singular Value Decom-position (SVD) technique is applied to reduce the dimension of therepresentation.
The approach we present consists in creating a set ofk-NN classifiers and combining the predictions generated in order togive a final word sense prediction for each case to be classified.
Thecombination is done by applying a Bayesian voting scheme.
The ap-proach has been applied to a database of 100 words made available bythe lexical sample WSD subtask of SemEval-2007 (task 17) organizers.Each of the words was considered an independent classification prob-lem.
A methodological parameter tuning phase was applied in order tooptimize parameter setting for each word.
Results achieved are amongthe best and make the approach encouraging to apply to other WSDtasks.1 IntroductionWord sense disambiguation (WSD) is the problem of determining whichsense of a word is used when a word appears in a particular context.
Infact, WSD is an important component in many information organizationtasks, and fundamentally consists in a classification problem: given someword-contexts corresponding to some possible senses, the WSD system hasto classify an occurrence of the word into one of its possible senses.248In the approach presented in this paper, a vector representation is usedfor training and testing word cases and the Singular Value Decompositionof matrices is applied in order to reduce the dimension of the representa-tion.
In particular, Latent Semantic Indexing (LSI) [2] is used to make thedimension reduction.
This technique compresses vectors representing wordrelated contexts into vectors of a lower-dimensional space and has shown tohave the ability to extract the relations among features representing wordsby means of their context of use.We present a multiclassifier [8] based approach which uses different train-ing databases.
These databases are obtained from the original trainingdataset by random subsampling.
The implementation of this approach ismade by a model inspired in bagging [3], and the k-NN classification algo-rithm [4] is used to make sense predictions for testing words.For experimentation, a previous tuning phase was performed to trainingdata in order to automatically set some system parameters to their optimalvalues.
Four are the parameters to be optimized, and the combination of allof them gives the possibility to perform the complete disambiguation processby 1440 different ways for each of the 100 words to be disambiguated.
Thetuning phase has been performed in a sound manner with the aim to improveour previous work [10].
Although the computational payload is high, it is asystematic way to fix the optimal values for parameters.The aim of this article is to give a brief description of our approach todeal with the WSD task and to show the results achieved.
In Section 2,our approach is presented.
In Section 3, the experimental setup is intro-duced.
The experimental results are presented and discussed in Section 4,and finally, Section 5 contains some conclusions and future work.2 Proposed ApproachIn this section, our approach is presented and the techniques used are brieflyreviewed.
First the dataset used in our experiments is described and previ-ous results are presented.
Next, the data preparation is explained in moredetail.
A short introduction to the SVD theory and to the k-NN classifica-tion algorithm is given afterwards.
Finally, the multiclassifier constructionis shown.2492.1 Dataset and previous resultsThe dataset we use in the experiments was obtained from the 4th Interna-tional Workshop on Semantic Evaluations (SemEval-2007) web page1, task17, subtask 1: Coarse-grained English Lexical Sample WSD.
This task con-sists of lexical sample style training and testing data for 100 lemmas (35nouns and 65 verbs) of different degree of polysemy (ranging from 1 to 13)and number of instances annotated (ranging from 19 instances in trainingfor the word grant to 2536 instances at share).The average inter-annotator agreement for these lemmas is over 90%.
In[9] task organizers describe the results achieved by the participating systems.They define a baseline for the task based on giving the most frequent sensein training (F-score: 78.0%).
The best system performance (89.1%) wasclosely approaching the inter-annotator agreement but still below it.2.2 Data PreparationOnce we downloaded the training and testing datasets, some features wereextracted and vector representations were constructed for each training andtesting case.
The features were extracted by [1] and are local collocations(bigrams and trigrams formed with lemmas, word-forms or PoS tags aroundthe target), syntactic dependencies (using relations like object, subject, nounmodifier, preposition and sibling) and Bag-of-words features.
This way, theoriginal training and testing databases were converted to feature databases.2.3 The SVD technique using LSIThe SVD technique consists in factoring term-document matrix M into theproduct of three matrices, M = U?VTwhere ?
is a diagonal matrix ofsingular values, and U and V are orthogonal matrices of singular vectors(term and document vectors, respectively).
Being k the number of singularvalues in matrix ?
and selecting the p highest singular values p < k, avector representation for the training and testing cases can be calculated inthe reduced dimensional vector space Rp.In our experiments we construct one feature-case matrix for each of the100 words using the corresponding feature training dataset.
Each of thecolumns in this matrix gives a vector representation to each of the trainingcases.
As the number of training cases varies among different words, thenumber of columns present in the matrices is different; consequently, the1http://nlp.cs.swarthmore.edu/semeval/tasks/task17/data.shtml250number of singular values changes as well.
Taking this in consideration,we calculate the SVD of each matrix and obtain the reduced vector repre-sentations for training and testing cases for different p values.
In order tocalculate the SVD of the matrices, we use Latent Semantic Indexing (LSI)2[5], which has been successfully used for classification purposes [7],2.4 The k-NN classification algorithmk-NN is a distance based classification approach.
According to this ap-proach, given an arbitrary testing case, the k-NN classifier ranks its nearestneighbors among the training cases [4].In the approach presented in this article, the training and testing casesfor each word are represented by vectors in each reduced dimensional vectorspace.
The nearest to a testing case are considered to be the vectors whichhave the smallest angle with respect to it, and thus the highest cosine.
Thatis why the cosine is usually calculated to measure the similarity betweenvectors.
The word senses associated with the k top-ranking neighbors areused to make a prediction for the testing case.
Parameter k was optimizedfor each word during tuning phase.2.5 The multiclassifier constructionThe combination of multiple classifiers has been intensively studied with theaim of improving the accuracy of individual components [8].
A widely usedtechnique to implement this approach is bagging [3], where a set of trainingdatabases TDiis generated by selecting n training cases drawn randomlywith replacement from the original training database TD of n cases.
Whena set of n1< n training cases is chosen from the original training collection,the bagging is said to be applied by random subsampling.In our work, we construct a multiclassifier by applying random sub-sampling for each word.
As the number n of training cases is different foreach word, we optimize via tuning the parameter n1for each multiclassifierconstructed.
This way, we work with training databases TDiof differentsizes.
Moreover, the number of training databases TDito create for eachmulticlassifier, is also optimized via tuning.Once the multiclassifiers are constructed, and given a testing case q for aword, the corresponding multiclassifier will make a word-sense label predic-tion cibased on each one of the training databases TDi.
In order to calculatethese confidence values, word-sense predictions are made for training cases2http://lsi.research.telcordia.com, http://www.cs.utk.edu/?lsi251and the accuracies obtained give the confidence values which indicate theaccuracy level that may be expected when a prediction is made for a testingcase based on each training database TDiand word-sense cjto be predicted.The way we combine such predictions is by applying Bayesian voting [6],where a confidence value cvicjis calculated for each training database TDiand word-sense cjto be predicted.
In testing phase, confidence values ob-tained for the testing cases are summed by sense; the sense cjthat gets thehighest value is finally proposed as a prediction for the testing case q. Thisprocess is repeated for every testing case.In Fig.
1 an illustration of the experiment performed for each one of the100 words can be seen.
First, vectors in the original Vector Space are pro-jected to the reduced space using SVD; next, random subsampling is appliedto the training database TD to obtain different training databases TDi; af-terwards, the k-NN classifier is applied for each TDito make sense labelpredictions; finally, Bayesian voting scheme is used to combine predictions,and c will be the final sense label prediction for testing case q.3 Experimental Setup.
The tuning phaseThe experiments were carried out in two phases.
First, a parameter tuningphase was performed in order to set the following parameters to their optimalvalues:?
The dimension p of the reduced dimensional vector space Rpto whichword-case vectors are projected for each word.?
The number of classifiers, training databases TDi, to create for eachword.?
The number k of nearest neighbors to be considered by the k-NNclassifier for each word.?
The number n1of cases to select from the TD of each word in orderto create each one of the TDi, that is, the size of each TDi.All the four parameters were adjusted independently for each word, be-cause of the different characteristics of words with respect to the number oftraining and testing cases present in the dataset and the number of word-senses associated to each of them.Validation and testing data subsets used in the tuning phase were ex-tracted form the original training database TD for each word.
Both subsets252100 words for WSDaffect.v allow.vwork.vOriginal  training andtesting databases.
.
..   .
.Features:local collocations,syntactic dependenciesand Bag of WordsOriginal Vector Space: Rmm: Number of featuresTrainingTesting.
.
..   .
..   .
.d2dnq1d1d2dnq1d1q2qn'qn'q2Reduced Space: Rpp: Singular Values, p mRandom Subsamplingk-NNk-NNk-NNc1,cvc11c2,cvc22ci,cvciiSingular Value Decomposition (SVD)by Latent Semantic Indexing (LSI) (*)SVDRmRmRpRpRpRpi training databases (TDi)generated by selecting n1cases (n1<n) randomlyTD1TD2TDid1d2dnd3d1d2d3dnqqd21d11d12......dn11dn12d22dn1id1id2iqqBayesian Votingc: word sense proposedfor testing case qCosine Similarity Measure(*) http://lsi.research.telcordia.comhttp://www.cs.utk.edu/~lsi.
.
.mfeaturesmfeaturesmfeaturesmfeaturesmfeaturesmfeaturesci: Sense given byclassifier i to case qcvcii: Confidence Valuecalculated by classifieri for sense cic...Testingcase qTDProjection oftesting case qFigure 1: Proposed multiclassifier approach for WSD taskwere constructed by random selection of cases, where 75% of the cases wereselected for the validation subset and the rest for the tuning purposed madetesting subset.In the following the optimization of parameters is explained.
Parameterswere optimized in the same order as presented in this subsection, that is,the dimension reduction first, the number of classifiers second, the number kof nearest neighbors third and the size of each TDilast.
When the first pa-rameter was being optimized, all possibilities for the other three parameters253were taken into account, and the optimization of the parameter was madebased on the average of the 10% best results.
Once a parameter was fixed,the same method was applied in order to optimize the rest of the parame-ters.
This optimization method implies that the experiment was performedfor all the combinations of the four parameters.
This implies a high compu-tational cost during the tuning phase.
For testing phase, the experimentsare performed using the optimal values for parameters.3.1 The dimension p of RpThis is the first parameter we tuned.
As it was previously mentioned inSection 2.3, the dimension p of the reduced dimensional vector space Rptowhich training and testing cases are projected varies for different words.
Thereason for that is the difference in the number of cases present in the datasetfor each word.
For words with a high number of cases, the dimension waspreviously reduced to 500 (see [2]).
Then, for every word we experimentedby keeping the number of dimensions in a proportion.
This proportion isgiven by parameter ?.
We analyze four proportions by setting parameter?
to: ?
= 0 keep all dimensions, ?
= 1 keep 2/3 of the dimensions, ?
= 2keep half of the dimensions and ?
= 3 keep a third of the dimensions.We calculated four different values for p. Training and testing cases wererepresented in the four Rpspaces and word-sense label predictions calculatedfor all of them.
All the possibilities were tried for the rest of the parameters(detailed in the following subsections).
For each value of ?, we selected the10% best results from the 1440 we have, calculated the average of them andset parameter ?
to its optimal value for each word.
The optimization of ?gives a final optimal value for parameter p for each word.3.2 The number of classifiers, TDiThe number of classifiers, or TDito create for each word is also a parameterthat needs to be tuned.
This is because the number of cases present for eachword is quite variable, and this fact may have some influence in the numberof TDito construct.
In our work, we experimented with 6 different val-ues for parameter i = 3, 5, 10, 20, 30, 40.
We performed the disambiguationprocess for each of them by considering the results for the optimal valueof parameter ?, already optimized, and all the possible values for the restof the parameters for each word.
We then selected the best 10% averageresults achieved for each value of i, calculated the average, and based onthese average results set the optimal value for parameter i for each word.2543.3 The number k of nearest neighbors for k-NNAt this stage of the tuning phase, and having already optimized the dimen-sionality reduction and the number of classifiers to create for each word,we take both optimal values and experiment with all possible values for therest of the parameters.
We calculate the average for six different values ofk, k = 3, 5, 7, 9, 11, 13.
We set the optimal value of k for each word basedon the maximum average obtained.3.4 The size of training databases TDi: parameter n1As it was mentioned in Section 2.5, the parameter n1will be optimized foreach word in order to create training databases TDiof different sizes.
Theselection of different values for n1was experimented for each word accordingto the following equation:n1=s?i=1(2 + ?tij?
), j = 1, .
.
.
, 10where tiis the total number of training cases in the sense ciand s is thetotal number of senses for the given word.
By dividing tiby j, the numberof training-cases selected from each word-sense preserves the proportion ofcases per sense in the original one.
However, it has to be taken into accountthat some of the word-senses have a very low number of training-cases as-signed to them.
By summing 2, at least 2 training-cases will be selectedfrom each word-sense.
In order to decide the optimal value for j, the clas-sification experiment was carried out varying j from 1 to 10 for each word.Given that parameters p, i and k are already set to their optimal values foreach word, we calculate results for the 10 possible values of j, and set it toits optimal value.4 Experimental ResultsThe experiment was conducted by considering the optimal values for param-eters tuned.
Original training and testing datasets were used for the finalexperiment, and results achieved were compared to the ones made availableby task organizers [9].Our system achieved an F-score of 85.65%, which compared to the base-line defined (78.0%) is a very good result, although still below the bestpublished by task organizers (89.1%).255In [9] the performance of the top-8 systems on individual verbs and nounsis shown; 73 of the 100 lemmas are included in a table in two separatedgroups.
Lemmas that have perfect or almost perfect accuracies have beenremoved.
In TABLE 1 the average results achieved by our system for the twogroups of lemmas are compared to the ones published in the cited paper.
Wecan observe that our system performs better than the average of the top-8systems disambiguating nouns, but slightly worse for verbs.
In the overall,our system is very near to the average performance of the top-8 systems.Top-8 Our systemVerbs 70.44 67.78Nouns 79.86 82.96Overall 74.32 74.02Table 1: Average performance compared to the top-8 in [9]We want to remark that our system uses only the official training andtesting data, without including background knowledge of any type.
Some ofthe top-8 systems used background knowledge in order to assist in resolvingambiguities.0.70.720.740.760.780.80.820.840  0.5  1  1.5  2  2.5  3?AccuracyFigure 2: Average accuracy related to parameter ?
= 0, 1, 2, 3An analysis of the parameter optimization performed in the tuning phaselead us to observe that there is a relation between the dimensionality reduc-tion level applied by SVD and the accuracy achieved for a word disambigua-tion (see Fig.
2).
Words with more than 500 cases in the training datasetwere not depicted in the figure because an additional dimension reductionwas applied to them (see section 3.1).
The graphic in Fig.
2 suggests that2560 1 2 350100150200?nsensesFigure 3: Complexity related to parameter ?
= 0, 1, 2, 3a dimensionality reduction of half of the features, ?
= 2, is appropriate forwords where a high level of accuracy is reached.In order to analyze the adequacy of the parameter tuning performed, wecreated a new variable dividing the case number n of the training databaseby the number of senses for each word.
This calculus is meant to representthe complexity of each word.
In Fig.
3 the interquartile relationships foundamong the parameter ?
and the complexity of the words is presented.
Foreach value of ?
the segments represent the minimum and the maximum valueof the complexity, while the bold line shows the median and the rectangulararea represents the density of the second and third quartiles.
As it can beseen, the evolution of the median value, as well as the minimum values, aresimilar to the observed in the accuracies.
This allows to say that the ?
valuewas properly selected by the automatic selection used, and also that highervalues of ?
would not ensure better solutions for the most complex words.5 Conclusions and Future WorkThe good results achieved by our system show that the construction ofmulticlassifiers, together with the use of Bayesian voting to combine word-257sense label predictions, plays an important role in disambiguation tasks.The use of the SVD technique in order to reduce the vector representationof cases has been proved to behave appropriately.We also want to remark that, our disambiguation system has been adaptedto the task of disambiguating each one of the 100 words by applying amethodological parameter tuning directed to find the optimal values foreach word.
This makes possible to have a unique disambiguation systemapplicable to words with very different characteristics.Moreover, in our experiments we used only the training data supplied forsense disambiguation in test set, with no inclusion of background knowledgeat all, while most of the top-8 systems participating in the task do use somekind of background knowledge.
As future work, we intend to make use ofsuch knowledge and hope that results will increase.
We also intend to applythis approach to other disambiguation tasks.References[1] E. Agirre and O. Lopez de Lacalle.
Ubc-alm: Combining k-nn with svdfor wsd.
In Proceedings of the 4th International Workshop on SemanticEvaluations, SemEval-2007, pages 342?345, 2007.
[2] M. Berry and M. Browne.
Understanding Search Engines: Mathemati-cal Modeling and Text Retrieval.
SIAM Society for Industrial and Ap-plied Mathematics, ISBN: 0-89871-437-0, Philadelphia, 1999.
[3] L. Breiman.
Bagging predictors.
Machine Learning, 24(2):123?140,1996.
[4] B. Dasarathy.
Nearest Neighbor (NN) Norms: NN Pattern RecognitionClassification Techniques.
IEEE Computer Society Press, 1991.
[5] S. Deerwester, S. Dumais, G. Furnas, T. Landauer, and R. Harshman.Indexing by latent semantic analysis.
Journal of the American Societyfor Information Science, 41:391?407, 1990.
[6] T. Dietterich.
Machine learning research: Four current directions.
TheAI Magazine, 18(4):97?136, 1998.
[7] S. Dumais.
Latent semantic analysis.
In ARIST (Annual Review ofInformation Science Technology), volume 38, pages 189?230, 2004.258[8] T. Ho, J.
Hull, and S. Srihari.
Decision combination in multiple clas-sifier systems.
IEEE Transactions on Pattern Analysis and MachineIntelligence, 16(1):66?75, 1994.
[9] S. Pradhan, E. Loper, D. Dligach, and M. Palmer.
Semeval-2007 task17: English lexical sample, srl and all words.
In A. for Computa-tional Linguistics, editor, Proceedings of the 4th International Work-shop on Semantic Evaluations, SemEval-2007, pages 87?92, 2007.
[10] A. Zelaia, O. Arregi, and B. Sierra.
Ubc-zas: A k-nn based multiclas-sifier system to perform wsd in a reduced dimensional vector space.In Proceedings of the 4th International Workshop on Semantic Evalua-tions, SemEval-2007, pages 358?361, 2007.259
