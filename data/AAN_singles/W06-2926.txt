Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X),pages 186?190, New York City, June 2006. c?2006 Association for Computational LinguisticsA Pipeline Model for Bottom-Up Dependency ParsingMing-Wei Chang Quang Do Dan RothDepartment of Computer ScienceUniversity of Illinois at Urbana-ChampaignUrbana, IL 61801{mchang21, quangdo2, danr}@uiuc.eduAbstractWe present a new machine learning frame-work for multi-lingual dependency pars-ing.
The framework uses a linear, pipelinebased, bottom-up parsing algorithm, witha look ahead local search that serves tomake the local predictions more robust.As shown, the performance of the firstgeneration of this algorithm is promising.1 System Description1.1 Parsing as a PipelinePipeline computation is a common computationalstrategy in natural language processing, where a taskis decomposed into several stages that are solved se-quentially.
For example, a semantic role labelingprogram may start by using a part-of-speech tagger,than apply a shallow parser to chunk the sentenceinto phrases, and continue by identifying predicatesand arguments and then classifying them.
(Yamada and Matsumoto, 2003) proposed abottom-up dependency parsing algorithm, where thelocal actions, chosen from among Shift, Left, Right,are used to generate a dependency tree using ashift-reduce parsing approach.
Moreover, they usedSVMs to learn the parsing decisions between pairsof consecutive words in the sentences 1.
This isa true pipeline approach in that the classifiers aretrained on individual decisions rather than on theoverall quality of the parser, and chained to yield the1A pair of words may become consecutive after the wordsbetween them become the children of these two wordsglobal structure.
It suffers from the limitations ofpipeline processing, such as accumulation of errors,but nevertheless, yields very competitive parsing re-sults.We devise two natural principles for enhancingpipeline models.
First, inference procedures shouldbe incorporated to make robust prediction for eachstage.
Second, the number of predictions shouldbe minimized to prevent error accumulation.
Ac-cording to these two principles, we propose an im-proved pipeline framework for multi-lingual depen-dency parsing that aims at addressing the limitationsof the pipeline processing.
Specifically, (1) we uselocal search, a look ahead policy, to improve the ac-curacy of the predicted actions, and (2) we argue thatthe parsing algorithm we used minimizes the num-ber of actions (Chang et al, 2006).We use the set of actions: Shift, Left, Right, Wait-Left, WaitRight for the parsing algorithm.
The pureWait action was suggested in (Yamada and Mat-sumoto, 2003).
However, here we come up withthese five actions by separating actions Left into(real) Left and WaitLeft, and Right into (real) Rightand WaitRight.
Predicting these turns out to be eas-ier due to finer granularity.
We then use local searchover consecutive actions and better exploit the de-pendencies among them.The parsing algorithm is a modified shift-reduceparser (Aho et al, 1986) that makes use of the ac-tions described above and applies them in a leftto right manner on consecutive word pairs (a, b)(a < b) in the word list T .
T is initialized as the fullsentence.
Latter, the actions will change the contentsof T .
The actions are used as follows:186Shift: there is no relation between a and b.Right: b is the parent of a,Left: a is the parent of bWaitLeft: a is the parent of b, but it?s possible thatb is a parent of other nodes.
Action is deferred.The actions control the procedure of buildingtrees.
When Left or Right is performed, the algo-rithm has found a parent and a child.
Then, the func-tion deleteWord will be called to eliminate the childword, and the procedure will be repeated until thetree is built.
In projective languages, we discoveredthat action WaitRight is not needed.
Therefore, forprojective languages, we just need 4 actions.In order to complete the description of the algo-rithm we need to describe which pair of consecu-tive words to consider once an action is taken.
Wedescribe it via the notion of the focus point, whichrepresents the index of the current word in T .
Infact, determining the focus point does not affect thecorrectness of the algorithm.
It is easy to show thatany pair of consecutive words in the sentence canbe considered next.
If the correct action is chosenfor the corresponding pair, this will eventually yieldthe correct tree (but may necessitate multiple cyclesthrough the sentence).In practice, however, the actions chosen will benoisy, and a wasteful focus point policy will resultin a large number of actions, and thus in error accu-mulation.
To minimize the number of actions taken,we want to find a good focus point placement policy.There are many natural placement policies that wecan consider (Chang et al, 2006).
In this paper, ac-cording to the policy we used, after S and WL, thefocus point moves one word to the right.
After L orR, we adopt the policy Step Back: the focus movesback one word to the left.
Although the focus place-ment policy here is similar to (Yamada and Mat-sumoto, 2003), they did not explain why they madethis choice.
In (Chang et al, 2006), we show thatthe policy movement used here minimized the num-ber of actions during the parsing procedure.
We canalso show that the algorithm can parse a sentencewith projective relationships in only one round.Once the parsing algorithm, along with the focuspoint policy, is determined, we can train the actionclassifiers.
Given an annotated corpus, the parsingalgorithm is used to determine the action taken foreach consecutive pair; this is used to train a classifierAlgorithm 1 Pseudo Code of the dependency pars-ing algorithm.
getFeatures extracts the featuresdescribing the currently considered pair of words;getAction determines the appropriate action for thepair; assignParent assigns the parent for the childword based on the action; and deleteWord deletes theword which become child once the action is taken.Let t represents for a word and its part of speechFor sentence T = {t1, t2, .
.
.
, tn}focus= 1while focus< |T | do~v = getFeatures(tfocus, tfocus+1)?
= getAction(tfocus, tfocus+1, ~v)if ?
= L or ?
= R thenassignParent(tfocus, tfocus+1, ?
)deleteWord(T, focus, ?
)// performing Step Back herefocus = focus ?
1elsefocus = focus + 1end ifend whileto predict one of the four actions.
The details of theclassifier and the features are given in Section 3.When we apply the trained model on new data,the sentence is processed from left to right to pro-duce the predicted dependency tree.
The evaluationprocess is somewhat more involved, since the actionclassifier is not used as it is, but rather via a localsearch inference step.
This is described in Section 2.Algorithm 1 depicts the pseudo code of our parsingalgorithm.Our algorithm is designed for projective lan-guages.
For non-projective relationships in somelanguages, we convert them into near projectiveones.
Then, we directly apply the algorithm on mod-ified data in training stage.
Because the sentences insome language, such as Czech, etc.
, may have multiroots, in our experiment, we ran multiple rounds ofAlgorithm 1 to build the tree.1.2 Labeling the Type of DependenciesIn our work, labeling the type of dependencies isa post-task after the phase of predicting the headfor the tokens in the sentences.
This is a multi-class classification task.
The number of the de-187pendency types for each language can be found inthe organizer?s introduction paper of the shared taskof CoNLL-X.
In the phase of learning dependencytypes, the parent of the tokens, which was labeledin the first phase, will be used as features.
The pre-dicted actions can help us to make accurate predic-tions for dependency types.1.3 Dealing with Crossing EdgesThe algorithm described in previous section is pri-marily designed for projective languages.
To dealwith non-projective languages, we use a similar ap-proach of (Nivre and Nilsson, 2005) to map non-projective trees to projective trees.
Any singlerooted projective dependency tree can be mappedinto a projective tree by the Lift operation.
Thedefinition of Lift is as follows: Lift(wj ?
wk) =parent(wj) ?
wk, where a ?
b means that a is theparent of b, and parent is a function which returnsthe parent word of the given word.
The procedure isas follows.
First, the mapping algorithm examines ifthere is a crossing edge in the current tree.
If there isa crossing edge, it will perform Lift and replace theedge until the tree becomes projective.2 Local SearchThe advantage of a pipeline model is that it can usemore information that is taken from the outcomesof previous prediction.
However, this may result inaccumulating error.
Therefore, it is essential for ouralgorithm to use a reliable action predictor.
This mo-tivates the following approach for making the localprediction in a pipeline model more reliable.
Infor-mally, we devise a local search algorithm and use itas a look ahead policy, when determining the pre-dicted action.In order to improve the accuracy, we might wantto examine all the combinations of actions proposedand choose the one that maximizes the score.
It isclearly intractable to find the global optimal predic-tion sequence in a pipeline model of the depth weconsider.
The size of the possible action sequenceincreases exponentially so that we can not examineevery possibility.
Therefore, a local search frame-work which uses additional information, however, issuitable and tractable.The local search algorithm is presented in Al-Algorithm 2 Pseudo code for the local search al-gorithm.
In the algorithm, y represents the a actionsequence.
The function search considers all possibleaction sequences with |depth| actions and returnsthe sequence with highest score.Algo predictAction(model, depth, State)x = getNextFeature(State)y = search(x, depth, model, State)lab = y[1]State = update(State, lab)return labAlgo search(x, depth, model, State)maxScore = ?
?F = {y | ?y?
= depth}for y in F dos = 0, TmpState = Statefor i = 1 .
.
.
depth dox = getNextFeature(TmpState)s = s + log(score(y[i], x))TmpState = update(TmpState, y[i])end forif s > maxScore theny?
= ymaxScore = send ifend forreturn y?gorithm 2.
The algorithm accepts two parameters,model and depth.
We assume a classifier that cangive a confidence in its prediction.
This is repre-sented here by model.
depth is the parameter de-termining the depth of the local search.
State en-codes the configuration of the environment (in thecontext of the dependency parsing this includes thesentence, the focus point and the current parent andchildren for each node).
Note that the features ex-tracted for the action classifier depends on State, andState changes by the update function when a predic-tion is made.
In this paper, the update function caresabout the child word elimination, relationship addi-tion and focus point movement.The search algorithm will perform a search oflength depth.
Additive scoring is used to score thesequence, and the first action in this sequence is per-formed.
Then, the State is updated, determining the188next features for the action classifiers and search iscalled again.One interesting property of this framework is thatwe use future information in addition to past infor-mation.
The pipeline model naturally allows accessto all the past information.
But, since our algorithmuses the search as a look ahead policy, it can producemore robust results.3 Experiments and ResultsIn this work we used as our learning algorithm aregularized variation of the perceptron update ruleas incorporated in SNoW (Roth, 1998; Carlson etal., 1999), a multi-class classifier that is specificallytailored for large scale learning tasks.
SNoW usessoftmax over the raw activation values as its confi-dence measure, which can be shown to be a reliableapproximation of the labels?
probabilities.
This isused both for labeling the actions and types of de-pendencies.
There is no special language enhance-ment required for each language.
The resources pro-vided for 12 languages are described in: (Hajic?
etal., 2004; Chen et al, 2003; Bo?hmova?
et al, 2003;Kromann, 2003; van der Beek et al, 2002; Brantset al, 2002; Kawata and Bartels, 2000; Afonso etal., 2002; Dz?eroski et al, 2006; Civit Torruella andMart??
Anton?
?n, 2002; Nilsson et al, 2005; Oflazer etal., 2003; Atalay et al, 2003).3.1 Experimental SettingThe feature set plays an important role in the qual-ity of the classifier.
Basically, we used the samefeature set for the action selection classifiers andfor the label classifiers.
In our work, each exam-ple has average fifty active features.
For each wordpair (w1, w2), we used their LEMMA, the POSTAGand also the POSTAG of the children of w1 andw2.
We also included the LEMMA and POSTAGof surrounding words in a window of size (2, 4).We considered 2 words before w1 and 4 words af-ter w2 (we agree with the window size in (Yamadaand Matsumoto, 2003)).
The major difference ofour feature set compared with the one in (Yamadaand Matsumoto, 2003) is that we included the pre-vious predicted action.
We also added some con-junctions of the above features to ensure expressive-ness of the model.
(Yamada and Matsumoto, 2003)made use of the polynomial kernel of degree 2 sothey in fact use more conjunctive features.
Besidethese features, we incorporated the information ofFEATS for the languages when it is available.
Thecolumns in the data files we used for our work arethe LEMMA, POSTAG, and the FEATS, which istreated as atomic.
Due to time limitation, we did notapply the local search algorithm for the languageshaving the FEATS features.3.2 ResultsTable 1 shows our results on Unlabeled AttachmentScores (UAS), Labeled Attachment Scores (LAS),and Label Accuracy score (LAC) for 12 languages.Our results are compared with the average scores(AV) and the standard deviations (SD), of all the sys-tems participating in the shared task of CoNLL-X.Our average UAS for 12 languages is 83.54%with the standard deviation 6.01; and 76.80% withthe standard deviation 9.43 for average LAS.4 Analysis and DiscussionWe observed that our UAS for Arabic is generallylower than for other languages.
The reason for thelow accuracy of Arabic is that the sentence is verylong.
In the training data for Arabic, there are 25%sentences which have more than 50 words.
Sincewe use a pipeline model in our algorithm, it requiredmore predictions to complete a long sentence.
Morepredictions in pipeline models may result in moremistakes.
We think that this explains our relativelylow Arabic result.
Moreover, in our current system,we use the same window size (2,4) for feature ex-traction in all languages.
Changing the windows sizeseems to be a reasonable step when the sentences arelonger.For Czech, one reason for our relatively low resultis that we did not use the whole training corpus dueto time limitation 2 .
Actually, in our experimenton the development set, when we increase the sizeof training data in the training phase we got signif-icantly higher result than the system trained on thesmaller data.
The other problem for Czech is thatCzech is one of the languages with many types ofpart of speech and dependency types, and also the2Training our system for most languages takes 30 minutesor 1 hour for both phases of labeling HEAD and DEPREL.
Ittakes 6-7 hours for Czech with 50% training data.189Language UAS LAS LACOurs AV SD Ours AV SD Ours AV SDArabic 76.09 73.48 4.94 60.92 59.94 6.53 75.69 75.12 5.49Chinese 89.60 84.85 5.99 85.05 78.32 8.82 87.28 81.66 7.92Czech 81.78 77.01 6.70 72.88 67.17 8.93 80.42 76.59 7.69Danish 86.85 84.52 8.97 80.60 78.31 11.34 86.51 84.50 4.35Dutch 76.25 75.07 5.78 72.91 70.73 6.66 80.15 77.57 5.92German 86.90 82.60 6.73 84.17 78.58 7.51 91.03 86.26 6.01Japanese 90.77 89.05 5.20 89.07 85.86 7.09 92.18 89.90 5.36Portuguese 88.60 86.46 4.17 83.99 80.63 5.83 88.84 85.35 5.45Slovene 80.32 76.53 4.67 69.52 65.16 6.78 79.26 76.31 6.40Spanish 83.09 77.76 7.81 79.72 73.52 8.41 89.26 85.71 4.56Swedish 89.05 84.21 5.45 82.31 76.44 6.46 84.82 80.00 6.24Turkish 73.15 69.35 5.51 60.51 55.95 7.71 73.75 69.59 7.94Table 1: Our results are compared with the average scores.
UAS=Unlabeled Attachment Score,LAS=Labeled Attachment Score, LAC=Label Accuracy, AV=Average score, and SD=standard deviation.length of the sentences in Czech is relatively long.These facts make recognizing the HEAD and thetypes of dependencies more difficult.Another interesting aspect is that we have notused the information about the syntactic and/or mor-phological features (FEATS) properly.
For the lan-guages for which FEATS is available, we have alarger gap, compared with the top system.5 Further Work and ConclusionIn the shared task of CoNLL-X, we have shown thatour dependency parsing system can do well on mul-tiple languages without requiring special knowledgefor each of the languages.From a technical perspective, we have addressedthe problem of using learned classifiers in a pipelinefashion, where a task is decomposed into severalstages and classifiers are used sequentially to solveeach stage.
This is a common computational strat-egy in natural language processing and is known tosuffer from error accumulation and an inability tocorrect mistakes in previous stages.
We abstractedtwo natural principles, one which calls for makingthe local classifiers used in the computation morereliable and a second, which suggests to devise thepipeline algorithm in such a way that it minimizesthe number of actions taken.However, since we tried to build a single approachfor all languages, we have not fully utilized the capa-bilities of our algorithms.
In future work we will tryto specify both features and local search parametersto the target language.Acknowledgement This research is supported byNSF ITR IIS-0428472, a DOI grant under the Reflexprogram and ARDA?s Advanced Question Answer-ing for Intelligence (AQUAINT) program.ReferencesA.
V. Aho, R. Sethi, and J. D. Ullman.
1986.
Compilers:Principles, techniques, and tools.
In Addison-WesleyPublishing Company, Reading, MA.A.
Carlson, C. Cumby, J. Rosen, and D. Roth.
1999.The SNoW learning architecture.
Technical ReportUIUCDCS-R-99-2101, UIUC Computer Science De-partment, May.M.
Chang, Q.
Do, and D. Roth.
2006.
Local searchfor bottom-up dependency parsing.
Technical report,UIUC Computer Science Department.Joakim Nivre and Jens Nilsson.
2005.
Pseudo-projectivedependency parsing.
In Proceedings of the 43rd An-nual Meeting of the Association for ComputationalLinguistics (ACL?05).D.
Roth.
1998.
Learning to resolve natural language am-biguities: A unified approach.
In Proceedings of theNational Conference on Artificial Intelligence (AAAI),pages 806?813.H.
Yamada and Y. Matsumoto.
2003.
Statistical de-pendency analysis with support vector machines.
InIWPT2003.190
