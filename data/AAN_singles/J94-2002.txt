Tree-Adjoining Grammar Parsing andBoolean Matrix MultiplicationGiorg io  Satta *tUniversita di VeneziaThe computational problem of parsing a sentence ina tree-adjoining language is investigated.
Aninteresting relation is studied between this problem and the well-known computational problem ofBoolean matrix multiplication: it is shown that any algorithm for the solution of the former problemcan easily be converted into an algorithm for the solution of the latter problem.
This result bearson at least wo important computational issues.
First, we realize that a straightforward methodthat improves the known upper bound for tree-adjoining grammar parsing is hard to find.
Second,we understand which features of the tree-adjoining grammar parsing problem are responsible forthe claimed ifficulty.1.
IntroductionAmong formalisms for the computation of syntactic description of natural anguagesentences, Tree-Adjoining Grammars (TAG) play a major role.
The class of TAG's wasfirst introduced in Joshi, Levy, and Takahashi (1975) and Joshi (1985); since then, formaland computational properties of this class have been extensively investigated, and thelinguistic relevance of TAGs has been discussed in the literature as well.
The readerwho is interested in these topics is referred to some of the most recent works, forexample Schabes (1990) and Frank (1992), and to the references therein.Both in a theoretical vein and in view of possible natural anguage processingapplications, the recognition and parsing problems for TAGs have been extensivelystudied and many algorithms have been proposed for their solution.
On the basis oftabular techniques, the least ime upper bound that has been attested is O(I G II w I 6) forthe random-access model of computation, I GI being the size of the input grammar andI wl the length of the input string.
In recent years, improvement of such a worst-caserunning time has been a common goal for many researchers, but up to the presenttime the TAG parsing problem has strongly resisted all such attempts.
Because of therecord of all these efforts, the task of improving the above upper bound is actuallyregarded as a difficult one by many researchers.In support of such a common feeling, in this paper we restate the TAG parsingproblem as a search problem and relate it to the well-known computational prob-lem of Boolean matrix multiplication.
This is done in such a way that time upperbounds for TAG parsing can be transferred to time upper bounds for the latter prob-lem.
More precisely, we show that any algorithm for TAG parsing that improves theO(IGIJwl 6) time upper bound can be converted into an algorithm for Boolean ma-trix multiplication running in less than O(m 3) time, m being the order of the input?
Universita diVenezia, Scienze dell'Informazione, via Torino, 155, 30172 Mestre-Venezia, It ly.
E-mail:satta@moo.dsi.unive.it.t This research was done while the author was a post-doctoral fe low at the Institute for Research inCognitive Science, University ofPennsylvania, 3401 Walnut Street, Philadelphia, PA19104~228, USA.
(~) 1994 Association for Computational LinguisticsComputational Linguistics Volume 20, Number 2matrices.
Crucially, Boolean matrix multiplication has been the object of ~nvestigationfor many Years: methods that are asymptotically faster than O(m 3) are known, butthe more considerable the improvement turned out to be, the more complex the in-volved computation was found to be.
At the present ime, the asymptotically fastestalgorithms for Boolean matrix multiplication are considered to be only of theoreticalinterest, because the huge constants involved in the running time of these methodsrender prohibitive any practical application, given current computer hardware.As a matter of fact, the design of practical algorithms for Boolean matrix multi-plication that considerably improve the cubic time upper bound is regarded as a verydifficult enterprise.
A consequence of the results presented in this paper is that TAGparsing should also be considered as having the status of a problem that is "hard toimprove," and there is enough evidence to think that methods for TAG parsing thatare asymptotically faster than O(\] G I\[w \]6) are unlikely to be of any practical interest,i.e., will involve very complex computations.The remaining part of this paper is organized as follows.
The next section presentsthe definition of tree-adjoining grammar and introduces the two computational prob-lems that are to be related.
Section 3 establishes the main result.
Section 4 draws onthe computational consequences of such a result and reports ome discussion.
Finally,Section 5 concludes by indicating how similar results can be found for variants of theTAG parsing problem that have been recently discussed in the literature.2.
PreliminariesThis section introduces the Boolean matrix multiplication problem and the tree-adjoin-ing grammar parsing problem, along with the definition of tree-adjoining grammar.The notation presented here will be used throughout the paper.2.1 Boolean Matrix MultiplicationLet/3 -- {0, 1} be the set of truth values.
The logical symbols V,/x are defined as usual.The set of Boolean square matrices Bin, m _> 1, is defined as the set of all m x m squarematrices whose elements belong to/3.
Given a matrix A c Bm, we say that A has orderm; the element in the ith row and jth column of A is denoted by aij.
In Bin, the productof A and B, written A x B, is a Boolean matrix C such that:mCiJ ~- V aik /~ bkj, 1 <_ i,j <_ m. (1)k~lAn instance of the Boolean matrix multiplication problem is therefore a pair (A, B)and the solution to such an instance consists of the matrix C such that C = A x B. Inwhat follows BMM will denote the set of all possible instances of the Boolean matrixmultiplication problem.2.2 Tree-Adjoining GrammarsThe definition of TAG and the associated notion of derivation are briefly introducedin the following; the reader is also referred to the standard literature (see, for instance,Vijay-Shanker and Joshi \[1985\] or Joshi, Vijay-Shanker, and Weir \[1991\]).A tree-adjoining grammar is a tree rewriting system denoted by a tuple G =(VN, VT, S, I, A), where VN and VT are finite, disjoint sets of nonterminal and terminalsymbols respectively, S E VN is a distinguished symbol, and I and A are finite sets ofelementary trees.
Trees in !
and A are called initial and auxiliary trees respectivelyand meet the following specifications.
Internal (nonleaf) nodes in an elementary tree174Giorgio Satta Tree-Adjoining Grammar Parsinginitial treeS<.auxiliary tro~A,4 d dterminal nodes(a)adjunction,4>(b)Figure 1Definitions of (a) initial and auxiliary trees and (b) adjunction operation.are labeled by symbols in VN.
An initial tree has a root labeled by S and leaf nodeslabeled by symbols in VT U {?}.
An auxiliary tree has leaf nodes labeled by symbolsin VT U {C} with the addition of one node, called the foot node, having the samenonterminal label as the root node (see Figure la).
We define the size of G, writtenI G \], to be the total number of nodes in all the trees in the set I U A.
In what followswe will also denote by TAG the class of all tree-adjoining grammars.In TAG, the notion of derivation is based on a composition operation called ad-junction, defined in the following way.
Let 3' be an auxiliary tree having its root (andfoot node) labeled by A E VN.
Let alo 3'' be any tree containing a node ~?
labeled byA, and let ~- be the subtree of 3'' rooted in 7.
The adjunction of 3' into 3'' at node ~?results in a tree specified as follows (see Figure lb):(i) the subtree ~- is excised from 3`';(ii) the auxiliary tree 3' replaces T in 3'', with the root of 3" replacing theexcised node ~?
;(iii) the subtree ~- is attached to the resulting tree, with the foot node of 3"replacing ~/in T.In TAG a derivation is the process of recursive composition of elementary trees usingthe adjunction operation; the resulting trees are called derived trees.
Since adjunctionsat different nodes can be performed in any order, we can adjoin derived trees intoderived trees without affecting our arguments.175Computational Linguistics Volume 20, Number 2Sz2Figure 2Parse tree 3'' is included in a parse tree of string w = ZlXZ2yz3 in L(G).
We say that thederivation of string pair Ix, Y/is a subderivation of a sentential derivation of w.2.3 Tree-Adjoining Grammar ParsingIn order to introduce the definition of the TAG parsing problem on which our resultsare based, we define in the following the string language derived from a TAG anddiscuss the notion of parse forest along with the important issue of its representation.Given an alphabet V, we denote by V* the set of all finite strings over V (null stringc included).Although TAG is a class of tree rewriting systems, a derivation relation can bedefined on strings in the following way.
Let 3' be an elementary tree and let "7' bea tree obtained from "7 by means of zero or more adjunction operations.
If the yieldof "7' is a string x E V~, that is -y E /, we say that "7 derives x in G. If the yield of3, / is a string xAy E V,~VNV,~, that is "y E A, we say that 3, derives the pair (x,y) inG.
In particular, the set of all strings in V~ that can be derived in G is denoted byL(G).
In this perspective then, an elementary or a derived tree is seen as a structuraldescription of a string (a pair of strings) derived by the grammar;  such a descriptionis called a parse tree.
The space of all parse trees associated with a given string by thegrammar  is called a parse forest.We introduce now the notion of subderivation.
Let w be a sentence in L(G) andlet ~, E A derive the pair (xt Y/ in  G, x, y E V~, with an associated parse tree -y'.
If 7' isincluded in a parse tree of w, we have that w = ZlXZ2yz3 for some zl, z2~ z3 E V~ (seeFigure 2).
Parse tree "7' represents the contribution of auxiliary tree 3' to a derivationof w; we say therefore that the derivation of /x~ Y/ from "7 is a subder ivat ion of asentential derivation of w. As a consequence of the definition of parse forest, we havethat all subderivations of the sentential derivations of w can be read off from the parseforest of w. Part of this information will be used to establish our result, as preciselystated in the next definition.
We need some additional notation.
Let w =- dld2""dn,n > 0, be a string over some alphabet; symbol pWq denotes the substring dpdp+l ... dqfor 1 _< p < q < n and is undefined otherwise.Definition 1Let G = (VN, VTt St It A) be a tree-adjoining rammar  and w E V~ be an input string,I wI = n, n > 0.
A parse relation Rp C A x {1..n} 4 associated with the pair /G, w / isspecified as follows.
For every auxiliary tree "y in G and for natural numbers p, q~ r and176Giorgio Satta Tree-Adjoining Grammar Parsings, 1 < p < q < r < s < n, Rp(7,p,q,r,s) holds if and only if:(i)(ii)the pair (pWq~ rWs) can be derived by 7 in G, andthe derivation in (i) is a subderivation of a sentential derivation of w in G.The goal of a parsing algorithm for TAG is one of constructing a "suitable" rep-resentation for the parse forest of a given string, with respect o a given grammar.However, there is no common agreement in the literature on the requirements hatsuch a representation should meet; therefore the issue of the representation f a parseforest deserves ome discussion here.There seems to be a trade-off between computational t imeand space in choosingamong different representations of a parse forest.
Note that, from an extreme perspec-tive, the input itself can be considered as a highly compressed representation f theparse forest--one that needs a time-expensive process for parse tree retrieval.
1 Moreexplicit representations offer the advantage of time-efficient retrieval of parse trees,at the cost of an increase in storage resources.
In practice, most commonly used al-gorithms olve the parsing problem for TAGs by computing a superset of a parserelation (defined as above) and by representing it in such a way that its instancescan be tested in constant time; such a condition is satisfied by the methods reportedin Vijay-Shanker and Joshi (1985), Schabes and Joshi (1988), Palis, Schende, and Wei(1990), Schabes (1991), Lavelli and Satta (1991), Lang (1992), and Vijay-Shanker andWeir (1993).
From such a representation, time-efficient computations can be used laterto retrieve parse structures of the input string.On the basis of the previous observation, we assume in the following that thesolution of the parsing problem involves (at least) the computation of a representationfor Rp such that its instances can be tested in constant time: we base our results onsuch an assumption.
More precisely, an input instance of the tree-adjoining grammarparsing problem is defined to be any pair (G, w), and the unique solution of such aninstance is provided by an explicit representation f relation (set) Rp associated with(G, w) as in Definition 1.
In what follows, TGP will represent the set of all instancesof the tree-adjoining grammar parsing problem.3.
Technical PartIn this section the Boolean matrix multiplication problem is related to the tree-adjoininggrammar parsing problem, establishing the major result of this paper.
A precise spec-ification of the studied reduction is preceded by an informal discussion of the generalidea underlying the construction.3.1 The Basic ApproachTwo maps ~ and ~ will be studied in this section.
Map ~c establishes a correspondencebetween the set BMM and a proper subset of TGP containing, in some sense, its mostdifficult instances.
Conversely, map ~ is defined on the set of solutions of all TGPproblems in the image of Y', and gives values in the set of Boolean square matrices.Maps ~ and G are defined in such a way that, given any algorithm for the solutionof the TGP problem, we can effectively construct an algorithm for the solution of theBMM problem using the commutative diagram shown in Figure 3.1 I owe this observation to Bernard Lang (personal communication).177Computational Linguistics Volume 20, Number 2multiplication<,4, B> in BMM " C = A ?
Bparsing<G, w> in TGP , RpFigure 3Maps ~- and ~ define a commutative diagram with respect to any algorithm for Booleanmatrix multiplication and any parsing algorithm for tree-adjoining grammars.Both the BMM and the TGP problems are viewed here as search problems whosesolutions are obtained by exploring a search space of elementary combinations.
Inthe case of the BMM problem, the elementary combinations are the combinationsof elements of the input matrices.
If m is the order of these matrices, the solutionof the problem requires the specification of O(m 2) elements of the product matrix,where each element depends upon O(m) elementary combinations ( ee relation (1)).Therefore the problem involves a search in a space of O(m 3) different combinations.On the other hand, in the TGP problem the elementary combinations are taken tobe single applications of the adjunction operation.
In parsing a string w of length naccording to a tree-adjoining grammar G, we have to construct a parse relation ofsize O(I G In 4) (see Definition 1), and there are O(n 2) distinguishable combinations inwhich each element of the relation can be obtained.
In the general case then, a numberO(I G In 6) of distinguishable combinations are involved in the parsing problem, andwe have to perform a search within an abstract space of this size.In order to achieve our result, we then establish a size preserving correspondencebetween the two search spaces above.
There is no way of representing matrices Aand B within string w without blowing up the search space associated with the targetparsing problem.
Our choice will then be to represent the input matrices by meansof grammar G, which fixes I GI to a quantity O(m2).
This forces the choice of n to aquantity O(m~), obtaining therefore the desired relation IG In 6 = O(1/'/3).The general idea underlying the construction is the following one.
Observe thatnon-null elements aik and bk,j in the input matrices force element cij to value 1 in theproduct matrix if and only if k = k t. The check of such a condition can be transferredto the computation of an adjunction operation in the target parsing problem using thefollowing encoding method.
We fix a positive integer b to a (rounded) quantity m~.Then we encode each index i of the input matrices by means of positive integers il,/2, and i3, such that il is O(b 4) and i2, is are O(b).
Condition k = k t above is thereforereduced to the three tests kh = k~, 1 < h < 3, which can be performed independently.The test kl = k~ is precompiled into some auxiliary tree of G; the tests k2 = k~ andk3 = k~ are performed by the parser using the input string, as explained below.Map ~- constructs a string w of distinguishable symbols by concatenating six"slices" w (h), 1 < h < 6, each slice of length O(b).
Map ~- also encodes the inputmatrices A and B within the target grammar G; it does so by transforming each non-null element in the input matrices into an auxiliary tree of G in the following way.Non-null element aik is mapped into an auxiliary tree "~1 having its root (and foot node)178Giorgio Satta Tree-Adjoining Grammar Parsing!
i, , X 2 !
Ik; /k3+lJ31Y2 ,\J2F igure  4String w is composed of six slices, and auxiliary trees corresponding tonon-null elements aikand bk'j derive string pairs (xl, yl} and (x2, y2} matching the slices of w as shown above;integers are used to indicate the position within a single slice of the boundary symbols instrings xl, yl, x2, and y2.
The figure depicts the case k = k', resulting in the exact nesting of thetwo derived trees.labeled by a symbol including integers i1 and kl.
Moreover, 3'1 will eventually derivea string pair (xl, yl) with the following property.
String xl is the smallest substring ofw including the symbol in the /3th position within slice w (1) and the symbol in thek3th position within slice w (2).
Furthermore, string yl is the smallest substring of wincluding the symbol in the (k2 + 1)-th position within slice w (5) and the symbol in the/2th position within slice w (6).
This is schematically shown in Figure 4.At the same time 5 r maps non-null element bk,j into an auxiliary tree 3'2 havingits root labeled by a symbol including integers k~ and jl.
Crucial to our construction,3` 2 will derive a pair of strings (x2~y2> with the following property.
String x2 is thesmallest substring of w including the symbol in the (k~ + 1)-th position within slicew (2) and the symbol in the j3th position within slice w (3).
Furthermore, string y2 is thesmallest substring of w including the symbol in the j2th position within slice w (4) andthe symbol in the k~th position within slice w (s).
Let us call 3'~ and 3,~ the derived treesobtained from 3,1 and 3"2 as above.
Observe that k2 = k~ and k3 = k~ if and only if theyields of 3"~ and 3` ~ are exactly nested within w; see again Figure 4.To complete the construction of G, map 5 v provides an auxiliary tree 3,3 with thefollowing property.
Tree 3,3 can contribute to a sentential derivation of w in G if andonly if 3"~ and 3"~ can be adjoined to it.
This is in turn possible just in case integer kl inthe root of 3"1 and integer k~ in the root of 3` 2 coincide, as specified by the adjunctionsites in 3'3, and the yields of 3` ~ and 3"~ are exactly nested within w. It follows that, bydeciding whether 3'3 contributes to a sentential derivation of w, the parser is able toperform the required test k = k'.
Finally, index k in its coded form is discarded in thederivation process above, while indices i and j are preserved in such a way that mapcan eventually recover non-null element Cq by reading off the parse relation.179Computational Linguistics Volume 20, Number 2Table 1Values of f  (b) (i) for b = 3 and 1 < i < 15.i 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15f(b)(i) 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2f(2b)(i) 1 1 1 2 2 2 3 3 3 1 1 1 2 2 2f(b)(i) 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3The next section presents a detailed specification of maps ~" and G and provesthe above claimed properties.
As we will see, the search space defined by the result-ing instance of the TAG parsing problem includes the solution of the source matrixmultiplication problem.3.2 The Two MapsThe goal of this subsection is to establish a mapping between comparisons of matrixindices in Boolean matrix multiplication and instances of the adjunction operation intree-adjoining rammar parsing.
As already mentioned in the previous subsection,this result is achieved by encoding natural numbers using three positive integers.
Theencoding is then used to chop off matrix indices into smaller numbers that will beprocessed independently.
This is explained in detail in the following.For pairs of integers i and b, let qn(i, b) and rm(i, b) be the quotient and theremainder respectively of the integer division of i by b.
We define qn+(i, b) = qn(i, b)+lwhenever m(i, b)  0 and qn+(i, b) = qn(i, b) otherwise; we also define rm+(i, b) =rm(i,b) whenever m(i,b) ~ 0, and rm+(i,b) = b otherwise.
Note that, for i > 1,qn+ (i, b) > 1 and 1 < rm+ (i, b) G b.Definit ion 2Let b > I be an integer.
We associate with b a funct ionf  (b) defined on the set of positivenatural numbers, specified as follows:wheref(b)(i) = (f~b)(i),f(2b)(i),f(3b)(i)} ,f(lb)(i) = qn+(i, b2),f(2 b)(i) = qn+(rm+(i, b2),b),f(3 b) (i) = rm+ (i, b).Table 1 shows some values o f f  (b) for the case b = 3.Observe that, for i > 1, f(3 b) and f(2 b) give values in the range {1..b}, while f(1 b)can give any positive integer.
It is not difficult to see that function fib) establishes aone-to-one correspondence b tween the set N of positive natural numbers and theset N x {1..b} x {1..b}.
In an informal way, we will often refer to value f(1 b) (i) as themost significant digit corresponding to i, and to values f(2 b) (i) and f(3 b) (i) as the leastsignificant digits corresponding to i.
In the following, the superscript in fib) will beomitted whenever b can be understood from the context.We are now in a position to define in detail the maps F and G involved in thediagram of Figure 3 discussed in Section 3.1.
As a first step, we study map ~- thattakes as input an instance of BMM and returns an instance of TGP.180Giorgio Satta Tree-Adjoining Grammar ParsingFI(n)<A,u, v>dq dr<A,u, v>F2(n)<B, U, V>d ~  ~ D  dsdq dr<B, u, v>F3(n).
_(n) ?
~?n) IS : D<C, u, v> t4 :I c<A, u, t> \[ dla D<B, t, v> I D<C, u, v> D dpFigure 5Definition of families of auxiliary trees F~ n), n > 1 and 1 < h < 6.
Each tree in some class isspecified by the values of the integer parameters corresponding to that class.Let n > 1 be an integer.
In the following we will refer to sets of terminal symbolsVT (")={dp I' 1Gp_<6(n+1)} ,and to sets of nonterminal symbolsV(N n)= {(A,u,v),(B,u,v),(C,u,v) \] l <u<v<n4}U{C,D,S} .Based on these sets, Figure 5 defines families of auxiliary trees F~ n), 1 ( h _ 6.
Forexample, an auxiliary tree 7(P, q, r, s, u, v) C 1~ ") will be specified by providing actualvalues for the integer parameters p, q, r, s, u, and v, consistently with the definitionsof sets V(T n) and V(N n).
In the following we will also use the initial tree % depicted inFigure 6.The next definition introduces map ~, which is the core component of the pro-posed reduction.
The definition is rather technical: it will be followed by a moreintuitive example.Definit ion 3Let (A, B) be an instance of BMM, m the order of matrices A and B.
Let alo n = Lm~/+1and ~r -- n + 1.
A map ~c is specified in such a way that YZ((A, B)) = (G, w), whereG =- (w(n)~ V(Tn)~ S~ I1 a (n)) and w = dld2 ... d6~.
Set I contains the only initial tree %; set181Computational Linguistics Volume 20, Number 2Ys: SIDICIDIEFigure 6Definition of initial tree %.A (n) contains all and only the following elementary trees (f(h n) =fh, 1 < h < 3):(i) for every aq = 1 in A, the auxiliary tree7(p,q,r,s,u,v) E P~ n)belongs to A (n), where; ---- f3(/), q ---- cr +f3(J),r = 4or +f2(j) + 1, s = 5cr +f2(i),U= A(i), V= A(J);(ii) for every bq -- 1 in B, the auxiliary tree7(p,q,y,s,u,v) E F~ n)belongs to A (n), wherep= a+f3( i )+ l ,  q= 2cr+f3(j),r = 3a+f2(j) ,  s = 4or +f2(i),u= A(i), v= A(J);(iii) for every pair (A, u, t), (B, t, v) E V(N n), the auxiliary trees7(u,t,v) E C~ "),7(u, v) E r~ ")belong to A(nJ;(iv) for every 1 < p < 6a, the auxiliary trees n),7(p) E r (n) 6belong to A(").In order to have a better understanding of map 9 r and of the idea underlying rammarG and string w, we discuss in the following a simple example, adding more details tothe informal discussion presented in Section 3.1.Let us define a Boolean matrix by specifying only its non-null elements.
Assumethen that an input instance (A, B / of the BMM problem consists of two matrices of182Giorgio Satta Tree-Adjoining Grammar Parsinga2,151B:C:ib 153I multiplicationc23mappingY I :  Y3: <C,l,l><A,1,2> \[d 2 ~ d 2 0 + 1  <,4,1,2>1d d 4+3 <A,1,2> 16+2+1 <B,2,1>I<C,1,1> Y2:<8,2,1>d4+3+1"~/~ d16+ 2ds+t <B2,I> d12+3Y4" CI<C,I,I>IcCI<C,I,I>d 2 d8+ 1 C d12+3 d20+ 1(a) (b)Figure 7Part (a) shows how non-null elements a2,15 and b15,7 in matrices A and B combine together,forcing element c2,7 in matrix C to value 1; each array element is represented asan arc in adirected graph.
Correspondingly, trees 3`1, 3`2, 3'3 and 3'4 in (b) are introduced in G by map ~-.These trees can be composed, using adjunction, with trees in p~3) and r~ 3), in such a way thata derived tree is obtained that matches tring w and encodes the indices of c2,7.order m = 64, specified asA = {a2,15}~ B :- {b15,7}.The multiplication of matrices A and B results in matrix C consisting of the only non-null element Ca, 7.
As already mentioned in Section 3.1, the multiplication process canbe seen as a test for equality performed on the second index of a2~ls and the first indexof b15,7; in the following these indices will be called "intermediate" indices.
Elementc2,7 in the product matrix is forced to value I if this test succeeds, and the intermediateindices are discarded in the process.
See Figure 7a for a schematic representation fsuch an operation.In performing an adjunction operation, two requirements must be satisfied.
First,the nonterminal label at the adjunction site must match the nonterminal label at theroot (and foot node) of the adjoined tree; and second, adjunction must compose treesin such a way that the derived string is compatible with w. In the proposed reduc-tion, each test for equality performed on some pair of intermediate indices by matrixmultiplication is transferred to an adjunction operation by map ~, using as targets thetwo requirements just described.
This is exemplified in the following.183Computational Linguistics Volume 20, Number 2According to Definition 3, we find n = 3 and cr = 4.
Map J: then constructsa string w = dld2...d24, which can be thought of as composed of six slices w (h) =4(h-1)+lW4h, 1 _< h _< 6.
Each element in a single slice will be used as a placeholderto record information about matrix indices.
Furthermore, map jv exploits funct ionf  (3)(see Table 1) in order to map each non-null element of the input matrices to an auxiliarytree in I~ 3) or F~ 3) (steps (i) and (ii) in Definition 3).
More specifically, each index of anon-null element is converted into three digits: the most significative one is encodedas part of the nonterminal symbols, and the two least significative digits are encodedby the terminal symbols in the target ree.
Trees ")'1 and "/2 obtained in this way fromnon-null elements a2,15 and b15,7 respectively have been depicted in Figure 7b.
Twoadditional trees "Y3 E F~ 3) and "Y4 E 1~ 3) have been reported in the figure, that are alsoadded to G by J: (step (iii) in Definition 3).Crucial to our construction, the test on the intermediate indices of elements a2,15and b15,7 has been reduced to three independent tests involving smaller integers.
Moreprecisely, the equality test on the most significative digits obtained from the intermedi-ate indices has been transferred to the requirement on the matching of the nonterminallabels of the nodes involved in the adjunction.
In fact, "Yl and "Y2 can be adjoined into")/3 just in case such a test is satisfied.
At the same time, the equality test on theleast significative digits obtained from the intermediate indices has been transferredto the requirement on the matching of the derived string with w. In fact, after theadjunction of "/1 and "/2 into ")'3 takes place, no terminal symbol can intervene betweenthe internal boundaries of the yield of "Y1 and the external boundaries of the yieldof "Y2 in slices w (2) and w (s) (see again Figure 7b).
Then "Y3 can participate in a sen-tential derivation of w just in case all three equality tests above are simultaneouslysatisfied.The choice of the order of I wl has been dictated by general considerations onthe size of the search spaces associated with the two problems at hand, as alreadydiscussed in Section 3.1.
As a note, we observe that slices w (2) and w (s) are used in theabove construction to pair together least significative digits obtained from intermediateindices.
The fact that these indices have range in {1..n} forces the choice of the lengthof these slices to ~r = n + 1; the example in Figure 7 actually uses the (n + 1)-th symbolof w (2).
For uniformity, this value has then been extended to all other slices, fixing I wlto 6or.In Lemma 1 below we will state in a more precise way the above arguments, andwe will also show how derivations of the kind outlined above are the only derivationsin G than can match string w, proving therefore the correctness of the reduction.
Tocomplete the diagram of Figure 3, we now turn to the specification of map ~.Definition 4Let/G,  w) be an instance of TGP in the image of map ~-, and let m, n, and cr be as inDefinition 3.
Let alo Rp be the parse relation that solves instance /G, w).
A map G isspecified in such a way that G(Rp) = C, C a Boolean matrix of order m, and element cijis non-null if and only if Rp('y, p, q, r, s) holds for an auxiliary tree ~/(u, v) E E~ n), where(f(h n) =fh,  1 < h < 3)p = f3( i ) ,  q = 2?+f3( j ) ,r = 3 r+f2(j), s = 5cr+f2( i ) ,u = f l ( i ) ,  v = A( J ) .In the above definition, funct ionf (n) is used to retrieve the indices of non-null elements184Giorgio Satta Tree-Adjoining Grammar Parsingil ,kl  kl ,Yl )2i i i i.wl2) .
w 5).k3/  / \ ~ k2+lJ3 hFigure 8Non-null elements aik and bkj are mapped into auxiliary trees 3'1 and 3"2 in G, and trees 3"~ and3'~ can successively be obtained compatibly with string w. As a convention, symbols 6h,6 E {i, k,j} and 1 < h < 3, denote integersfh(6), which indicate ither positions within eachsingle slice or components of nonterminal symbols labeling tree nodes.of matrix C. In this case also, the most significative digits associated with the retrievedindices are encoded within the nonterminal symbols of the auxiliary tree -y(u, v), whilethe two least significative digits are encoded by the position of the yield boundariesof the string derived from ~/(u, v) consistently with the input string w. To conclude ourprevious example, we see that if we apply the relations in Definition 4 to the derivedtree at the bottom of Figure 7b, we get indices 2 and 7 of the only non-null elementinC.The following result shows that any algorithm for the solution of a generic instanceof TGP can be converted into an algorithm for the solution of the BMM problem, viathe computation of maps 3 v and G. This concludes the present section.Lemma 1Let /A,  B / be an instance of BMM and let /G,  w / = ~-(/A, B/).
Let alo Rp be the parserelation that solves/G~ w/.
Then we haveA x B = G(Rp).ProofAssume that m is the order of the matrices A and B, n is the natural number associatedwith m as in Definition 3, and ?
= n + 1.
Let C = A x B and C / = G(Rp).To prove cij = 1 implies clj = 1, we go through a sentential derivation of w in Gand then apply the definition of G. If Cq = 1, then there exists k, 1 < k < m, such thataik = bkj = 1.
Let "Yl and "y2 be the unique auxiliary trees in G associated by map 3 v185Computational Linguistics Volume 20, Number 2il ,kl  kl  ,jl il ,Jlh hFigure 9Tree 7~ is derived from trees "/~, 7~ and auxiliary trees in G. We use the same conventions as inFigure 8.with aik and bkj respectively (steps (i) and (ii) in Definition 3).
Tree "71 has root (andfoot node) labeled by nonterminal (A,fl(i),fl(k)); furthermore, the terminal symbolsin the yield of "Yl are (from left to right) d/B(i ), d?+/B(k ), d4,+/a(k)+l and d5c,+f2(i).
The onlypair of substrings of w that ~'1 can derive, by means of zero or more adjunctions oftrees in F~ n) and P(')6 , is(f3(i)Wo-+f3(k)~ 4a+f2(k)+1W5o-+f2(i)) ?Call ~ a parse tree associated with such a derivation (see Figure 8).
In a similar way,auxiliary tree "Y2 has root labeled by nonterminal (B,fl(k);fl(j)) and derives pair{o- +f3(k )+ l W2o" +f3(j) ~ 3cr +f2(j) W4cr +f2(k )}of substrings of w. Call 3~ a parse tree associated with the derivation (see again Fig-ure 8).According to step (iii) in Definition 3, grammar G also includes auxiliary trees"y3 = 7(f1(i)~fl (k),fl(j)) E p~n) and "/4 = 70Cl ( / ) ;Aq) )  C r~n).
Note that the yields of trees7~ and 7 / 2 are exactly nested within w; moreover, the root (and the foot) nodes of 71and 72 have been preserved in the derivation.
Therefore 3'I and V~ can be adjoined into73 and the resulting tree 7~ can in turn be adjoined into 74.
In this way, 74 derives thepair of substrings of w(f3 (i)W2cr +f3 (j), 3?
q-f2 (j) W5~r q-f2 (i) } "Call 7~ the resulting derived tree (see Figure 9).
Since derived tree 71 can be adjoinedinto % in G and a tree can be eventually derived for the input string w, we haveRe(v4,f3(i), 2e +f3(j), 3or +f2(j), 5~ +f2(i)),and from the definition of ~ we get c;j = 1.186Giorgio Satta Tree-Adjoining Grammar ParsingAssuming clj = 1, we now prove cij = 1; this is done by arguing that the onlysentential derivations for w that are allowed by G are those of the kind outlinedabove.
From the definition of G we have thatRp(%,f3(i) ,  20 +f3 (j), 30 +f2(j), 50 +f2(i))holds for the auxiliary tree 3'4 = 3'0cl (i),fl(j)) E F~ n).
Equivalently, there exists at leastone derivation from '/4 of strings(x,y) = <f3(i)w2o-+f3(j)~3o.+f2~)w5o.+f2(i)) (2)that participates in a sentential derivation of w. Fix such a derivation.We first observe that, in order to derive any terminal symbol from '/4, auxiliarytrees in F~ n), F~ n) and F~ n) must be used.
Any tree in F~ n) can only derive symbolsin slices w (h), h E {1,2, 5, 6}, and any tree i n  F~ n) can only derive symbols in slicesw (h), h E {2, 3, 4, 5}.
Therefore at least one tree in F~ n) and at least one tree in F~ n)must be used in the derivation of (x, y), since (x, y) includes terminal symbols fromevery slice of w. Furthermore, if more than one tree in F~ ") is used in a derivation inG, the resulting string cannot match w. The same argument applies to trees in F~ n).We must then conclude that exactly one tree in F~ "), one tree in F~ "), and one treein F~ n) have been used in the derivation of (x, y) from 74.
Call the above trees 71 =q'(p, k3, k2+1, s, u, kl) E F~ n), "/2 ~--" 7(k~+1, q, r, k~, k~, v) E F~ n), and "/3 = "/( u/, t, V') E F~ n).As a second step, we observe that 73 can be adjoined into 74 only if u' =f l ( i )  andv' = A q) and 3'3 can host 71 and "/2 just in case u' = u, v' = v, and k I = k~ = t .
Wealso observe that, after these adjunctions take place, the leftmost terminal symbol inthe yield of 3'4 will be the leftmost erminal symbol in the yield of 71, that is dp.
Fromrelation (2) we then conclude that p =f3(i).
Similarly, we can argue that q = 20 +f3(j),r = 3o +f2(j) and s = 50 +f2(i).
Finally, adjunction of '/1 and "/2 into "/3 can match wjust in case  k 3 = k~ and k2 = k~.From the relations inferred above, we conclude that we can rewrite 71 as 70c3(i), k3,k2 + 1,5o +f2 (i),fl (i), kl) C F~ n) and '/2 as '/(k3 + 1, 20 +f3 (/'), 3o +f2(j), k2, kl,fl (j)) E F~ n) .Sincef is one-to-one and k2, k3 c {1..n}, there exists k such thatf(k) = (kl, k2, k3).
Fromsteps (i) and (ii) in Definition 3, we then have that aik and bkj are non-null and thencq = l. \[\]4.
Computational ConsequencesThe results presented in the previous section are developed here under a computa-tional perspective.
Some interesting computational consequences will then be drawnfor the tree-adjoining rammar parsing problem.
The following analysis assumes therandom-access machine as the model of computation.4.1 Transferring of Time Upper BoundsWe show in the following how time upper bounds for the TGP problem can be trans-ferred to time upper bounds for the BMM problem using the commutative diagramstudied in the previous section.Let (A, B) be an instance of BMM and let (G, w} = .T((A, B)); m and n are specifiedas in Definition 3.
Observe that, since n 6 > m, funct ionf (n) maps set {1..m} into productset {1..n 4} x {1..n} x {1..n}, in other words we have i <_fl(i) <_ n 4 and i <f2(i) , f3(i)  < n187Computational Linguistics Volume 20, Number 2for 1 < i < m. From the definition of ~', we see that G contains O(m 2) auxiliary treesp(n) F~n) and p~n).
This determines the size of G and we have from each of the classes -1 ,I(G,w)\] = O(/t/2), since \]w\] = O(n).
Each auxiliary tree introduced in G at steps (i)and (ii) of Definition 3 requires the computation of a constant number of instances offunctionf (n) on some integer i, 1 ( i ( m. Such a computation can be carried out in anamount of time O(log2(m)) using standard algorithms for integer division.
Summingup, the entire computation of ~" on an instance (A, B) takes time O(m 2 log2(m)).Let Rp be the parse relation that solves (G, w) = ~'((A, B)).
From Definition 1 andthe above observations we have that \]Rp\] = O(m2n4), that is \]Re\] = O(m2+~).
We cancompute C = G(Rp) in the following way.
For every element cij we compute f(n)(i)and f(n)(j) and then check Rp according to Definition 4.
(Recall also our assumptionthat an instance of Rp can be tested in constant time.)
Again we find that the entirecomputation takes an amount of time O (m 2 log 2 (m)).
We observe that the computationof ~r and G takes an amount of time (asymptotically) very close to the one needed tostore (A,B) or C.As a consequence of the above discussion and of Lemma 1, we have that any timeupper bound for the TGP problem can be transferred toan upper bound for the BMMproblem, down to the time needed for the computation of transformations ~- and ~.The following statement gives an example.Theorem 1Let Ap be an algorithm for the solution of the TGP problem having running timeO(\[GlPlwlq).
Then any instance of BMM can be solved in time O(max{m 2p+q,m 2 log2(m)}), where m is the order of the input matrices.ProofFrom Lemma 1 and from the previous discussion we have that two Boolean matricesof order m can be multiplied in time O(I G IPl w I q + m 2 log2(m)), where \]G I = O(m 2)and Iwl = O(m~).
\[\]Observe that, according to our definition, the TGP problem has a trivial time lowerbound O(IR p I), since this is the amount of time needed in the worst case to store arepresentation forRp that can be accessed in constant time.
In practice this means thatthe upper bound transfer stated by the above result is effective down to O(m 2+2 ).4.2 Time Upper Bounds for TGPIn previous ections we have related the complexity of tree-adjoining grammar pars-ing to the complexity of Boolean matrix multiplication.
Here we speculate on theconsequences of the presented result.As a computational problem, Boolean matrix multiplication has been an object ofinvestigation for many years.
Researchers have tried to improve the well-known O(m 3)time upper bound, m the order of the input matrices, and methods were found thatwork asymptotically faster than the standard cubic time algorithm.
Strassen's divideand conquer algorithm that runs in time O(m 2sl) (see for instance Cormen, Leiserson,and Rivest \[1990\]) has been the first one in the series, and the best time upper boundknown to date is approximately 0(m2"376), as  reported in Coppersmith and Winograd(1990).
It is worth noting here that the closer esearchers have come to the O(m 2) trivialtime lower bound, the more complex the computation i volved in these methods hasbecome.
In fact, if Strassen's algorithm outperforms the O(m 3) standard algorithm only188Giorgio Satta Tree-Adjoining Grammar Parsingfor input matrices of order greater than 45 or so (see again Cormen, Leiserson, andRivest \[1990\]), recently discovered methods that are asymptotically faster are definitelyprohibitive, given current computer hardware.
At present, no straightforward methodis known for Boolean matrix multiplication that considerably improves the cubic upperbound and that can be used in practical cases.
Also, there is enough evidence that, ifsuch a method exists, its discovery should be a very difficult enterprise.Let us now turn to the TAG parsing problem.
Many algorithms have been pro-posed for its solution and an O(I G III U A I\] w 16) time upper bound has been givenin the literature; see for instance Schabes (1990).
We remark here that the depen-dency on the grammar size can be further improved using techniques imilar to theone proposed in Graham, Harrison, and Ruzzo (1980) for the context-free grammarrecognition/parsing problem: this results in an O(I G II w 16) time upper bound for thegeneral case.
Theorem 1 can be used to transfer this upper bound to an upper boundfor Boolean matrix multiplication, finding the already mentioned O(m 3) result.More interestingly, Theorem 1 implies that any method for the solution of thetree-adjoining grammar parsing problem having running time O(I G II w I s) will give usa method for Boolean matrix multiplication having running time O(m2"83).
Likewise,any O(I G I\]wl 4) time method for the former problem will result in an O(m 2'~) timemethod for Boolean matrix multiplication.
Even if the involved constants hidden inthe studied construction are large, the resulting methods will still be competitive withknown methods for Boolean matrix multiplication that improve the cubic time upperbound.
We conclude then that the TAG parsing problem should also be consideredas having the status of a problem that is "difficult" to improve, and we have enoughevidence to think that methods for TAG parsing that are asymptotically faster thanO(I G II w I 6) are unlikely to be practical, i.e., will involve rather complex computations.5.
Remarks and ConclusionPolynomial time reductions between decision/search problems are commonly usedin providing hardness results for complexity classes not known to be included in P(P is the class of all languages decidable in deterministic polynomial time).
We havestudied here a polynomial time reduction between Boolean matrix multiplication andTAG parsing, two problems already known to be in P. However, the choice of themapping allows one to transfer upper bounds from the first problem to the other.
Inthis way TAG parsing inherits from Boolean matrix multiplication the reputation ofbeing a problem tough to improve.
We comment in the following on the significanceof this result.As already discussed, the notion of the parse forest is an informal one, and thereis no common agreement on which specifications such a structure should meet.
Theobtained results are based on the assumption that a parsing algorithm for TAG shouldbe able to provide a representation for a parse forest such that instances of the parserelation Rp in Definition I can be retrieved in constant time.
Whatever the specificationsof the output parse forest structure will be, it seems quite reasonable to require that anexplicit representation f relation Rp can be extracted from the output in linear timewith respect o the size of the output itself, therefore without affecting the overallrunning time of the method.
This requirement is satisfied by all TAG parsers thathave been presented to date in the literature.As a second point, the studied construction provides an interesting insight intothe structure of the TAG parsing problem.
We see for instance that the major source of189Computational Linguistics Volume 20, Number 2complexity derives from cases of properly nested adjunction operations.
Such cases areresponsible for a bounded amount of nondeterminism in the computation: to detecthow a string divides into subparts according to the adjunction of a derived tree intoanother, we have to consider many possibilities in general, as much as we do to detecta non-null element within a product Boolean matrix.
A closer look at the studiedconstruction reveals also that the parsing problem for linear TAG does not seem easierthan the general case, since ~ maps instances of BMM to instances of TGP restrictedto such a class (a linear TAG is a TAG whose elementary trees allow adjunction onlyinto nodes along a single spine).
This contrasts with the related case of context-freegrammar parsing, where the restriction of the problem to linear grammars can besolved in time O(I G II w 12) but no method is known for the general case working withthis bound.
As expected from our result, the techniques that are used for linear context-free grammar parsing cannot be easily generalized to improve the parsing problemfor linear TAGs with respect o the general case.Finally, we want to discuss here an interesting extension of the studied result.The TAG parsing problem can be generalized to cases in which the input is a latticerepresentation f a string of terminal symbols along with a partially specified parserelation associated with it.
This has many applications for ill-formed input and error-correcting parsing.
The TAG lattice parsing problem can still be solved in O(I G\[I w I 6)time: the general parsing method provided in Lang (1992) can be used to this purpose,and already known tabular methods for TAG parsing can be easily adapted as well.Without giving the technical details of the argument, we sketch here how Booleanmatrix multiplication can be related to TAG lattice parsing.
For order m matrices, onecan use an encoding function f/(n), where n = \[ml/2j + 1, mapping set {1..m} intoproduct set {1..n} x {1..n}.
This allows a direct encoding of any instance (A, B) ofthe BMM problem into a word lattice wl consisting of 6(n + 1) nodes and O(m 2) arcs,where some arcs involve four nodes and represent a derived tree corresponding toa non-null element in either A or B.
Then we can use a grammar G in the targetinstance of the TAG lattice problem that is defined independently of (A, B) and there-fore has constant size.
(Such a grammar can be obtained from families F~ n) and F~ n)defined in Section 3 by deleting the integer components in each nonterminal sym-bol.)
The construction obtained in this way relates therefore the BMM problem to thefixed grammar parsing problem, and provides a result even stronger than the onepresented in Theorem 1.
We have in fact that any algorithm for TAG lattice parsinghaving running time O(IG IP\[w I q) can be converted into an algorithm for Boolean ma-trix multiplication running in time O(max{m~, malog2(m)}), independently of p. Asan example, O(I G IPl w 14) for TAG lattice parsing becomes O(m 2 log2(m)) for matrixmultiplication, for any p. Since many tabular methods for TAG parsing can be easilyextended to TAG lattice parsing, this means that the chances of getting an 0(I G IPlw 14)time upper bound for the TAG parsing problem itself by means of these techniquesare really small.AcknowledgmentsI am indebted to Yves Schabes whosuggested to me the original idea of relatinga standard computational problem to thetree-adjoining grammar parsing problem.
Iwant to thank Bernard Lang, OwenRambow, and Yves Schabes, who haveprovided, directly or indirectly, importantsuggestions for the development of theideas in this paper.
Comments from twoanonymous referees have also been veryhelpful in improving the exposition of theresults reported in this paper.
Finally, I amgrateful to Aravind Joshi for his support inthis research.
None of these people isresponsible for any error in this work.
Thisresearch was partially funded by thefollowing grants: ARO grant DAAL190Giorgio Satta Tree-Adjoining Grammar Parsing03-89-C-0031, DARPA grantN00014-90-J-1863, NSF grant IRI 90-16592,and Ben Franklin grant 91S.3078C-1.ReferencesCoppersmith, D., and Winograd, S.
(1990).
"Matrix multiplication via arithmeticprogression."
Journal of SymbolicComputation, 9(3), 251-280.
Special Issueon Computational Algebraic Complexity.Cormen, T. H.; Leiserson, C. E.; and Rivest,R.
L. (1990).
Introduction to Algorithms.
TheMIT Press.Frank, R. (1992).
Syntactic locality and treeadjoining rammar: grammatical, acquisitionand processing perspectives.
Doctoraldissertation, University of Pennsylvania.Graham, S. L.; Harrison, M. A.; and Ruzzo,W.
L. (1980).
"An improved context-freerecognizer."
ACM Transactions onProgramming Languages and Systems, 2(3),415-462.Joshi, A. K. (1985).
"How muchcontext-sensitivity is necessary forcharacterizing structuraldescriptions--tree adjoining rammars.
InNatural Language Processing--Theoretical,Computational nd Psychological Perspectives,edited by D. Dowty, L. Karttunen, andA.
Zwicky, 206-250.
CambridgeUniversity Press.
Originally presented ina Workshop on Natural Language Parsingat Ohio State University, Columbus, Ohio,May 1983.Joshi, A. K.; Levy, L. S.; and Takahashi, M.(1975).
"Tree adjunct grammars."
Journalof Computer System and Science, 10(1),136-163.Joshi, A.; Vijay-Shanker, K.; and Weir, D.(1991).
"The convergence of mildlycontext-sensitive grammaticalformalisms."
In Foundational Issues inNatural Language Processing, edited byS.
Shieber and T. Wasow, 31-82.
MITPress.Lang, B.
(1992).
"Recognition can be harderthan parsing."
Abstract submitted to theSecond TAG Workshop, June 1992.Lavelli, A., and Satta, G.
(1991).
"Bidirectional parsing of lexicalized treeadjoining rammars."
In Proceedings, FifthConference ofthe European Chapter of theAssociation for Computational Linguistics,Berlin, 1991, 27-32.Palis, M. A.; Shende, S.; and Wei, D. S. L.(1990).
"An optimal linear-time parallelparser for tree-adjoining languages.
"SIAM Journal on Computing, 19(1), 1-31.Schabes, Y.
(1990).
Mathematical ndcomputational spects of lexicalized grammars.Doctoral dissertation, University ofPennsylvania.
Available as technicalreport (MS-CIS-9048, LINC LAB179) fromthe Department of Computer Science.Schabes, Y.
(1991).
"The valid prefixproperty and left to right parsing oftree-adjoining grammar."
In Proceedings,Second International Workshop on ParsingTechnologies, Cancun, Mexico, February1991, 21-30.Schabes, Y., and Joshi, A. K. (1988).
"AnEarley-type parsing algorithm for treeadjoining rammars."
In Proceedings, 26thMeeting of the Association for ComputationalLinguistics, Buffalo, June 1988, 258-269.Vijay-Shanker, K., and Joshi, A. K.
(1985).
"Some computational properties of treeadjoining rammars."
In Proceedings, 23rdMeeting of the Association for ComputationalLinguistics, Chicago, July 1985, 82-93.Vijay-Shanker, K., and Weir, D. J.
(1993).
"The use of shared forests in TAGparsing."
In Proceedings, Sixth Conference ofthe European Chapter of the Association forComputational Linguistics, Utrecht, 1993,384-393.191
