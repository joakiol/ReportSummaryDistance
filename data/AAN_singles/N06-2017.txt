Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 65?68,New York, June 2006. c?2006 Association for Computational LinguisticsEvaluating Centering for Sentence Ordering in Two New DomainsNikiforos KaramanisNatural Language and Information Processing GroupComputer LaboratoryUniversity of CambridgeNikiforos.Karamanis@cl.cam.ac.ukAbstractThis paper builds on recent research investigatingsentence ordering in text production by evaluatingthe Centering-based metrics of coherenceemployed by Karamanis et al (2004) using thedata of Barzilay and Lapata (2005).
This is the firsttime that Centering is evaluated empirically as asentence ordering constraint in several domains,verifying the results reported in Karamanis et al1 IntroductionAs most literature in text linguistics argues, afelicitous text should be coherent which meansthat the content has to be organised in a waythat makes the text easy to read and comprehend.The easiest way to demonstrate this claim isby arbitrarily reordering the sentences that anunderstandable text consists of.
This process veryoften gives rise to documents that do not make sensealthough the information content remains the same.Hence, deciding in which sequence to present aset of preselected information-bearing items is animportant problem in automatic text production.Entity coherence, which arises from the wayNP referents relate subsequent sentences in thetext, is an important aspect of textual felicity.Centering Theory (Grosz et al, 1995) has beenan influential framework for modelling entitycoherence in computational linguistics in the lasttwo decades.
Karamanis et al (2004) were the firstto evaluate Centering-based metrics of coherencefor ordering clauses in a subset of the GNOMEcorpus (Poesio et al, 2004) consisting of 20 artefactdescriptions.
They introduced a novel experimentalmethodology that treats the observed ordering ofclauses in a text as the gold standard, which isscored by each metric.
Then, the metric is penalisedproportionally to the amount of alternative orderingsof the same material that score equally to or betterthan the gold standard.This methodology is very similar to the wayBarzilay and Lapata (2005) evaluate automaticallyanother model of coherence called the entity gridusing a larger collection of 200 articles from theNorth American News Corpus (NEWS) and 200accident narratives from the National TransportationSafety Board database (ACCS).
The same data andsimilar methods were used by Barzilay and Lee(2004) to compare their probabilistic approach forordering sentences with that of Lapata (2003).This paper discusses how the Centering-basedmetrics of coherence employed by Karamanis et alcan be evaluated on the data prepared by Barzilayand Lapata.
This is the first time that Centeringis evaluated empirically as a sentence orderingconstraint in more than one domain, verifying theresults reported in Karamanis et alThe paper also contributes by emphasising thefollowing methodological point: To conduct ourexperiments, we need to produce several alternativeorderings of sentences and compare them with thegold standard.
As the number of possible orderingsgrows factorially, enumerating them exhaustively(as Barzilay and Lee do) becomes impractical.In this paper, we make use of the methods ofKaramanis (2003) which allow us to explore a65Table 1A NP referentsSentences department trial microsoft ... products brands ...(a) S O S ... ?
?
...(b) ?
?
O ... S O ...Table 1B CF list: CHEAPNESSSentences {CP, next two referents} CB Transition CBn=CPn?1(a) {department, microsoft, trial, ...} n.a.
n.a.
n.a.
(b) {products, microsoft, brands, ...} microsoft RETAIN ?Table 1: (A) Fragment of the entity grid for example (1); (B) CP (i.e.
first member of the CF list), next tworeferents, CB, transition and violations of CHEAPNESS (denoted with a ?)
for the same example.sufficient number of alternative orderings and returnmore reliable results than Barzilay and Lapata,who used a sample of just 20 randomly producedorderings (often out of several millions).2 Materials and methods2.1 Centering data structuresExample (1) presents the first two sentences of a textin NEWS (Barzilay and Lapata, Table 2):(1) (a) [The Justice Department]S is conducting [an anti-trust trial]O against [Microsoft Corp.]X with [evidence]Xthat [the company]S is increasingly attempting to crush[competitors]O .
(b) [Microsoft]O is accused of trying toforcefully buy into [markets]X where [its own products]Sare not competitive enough to unseat [establishedbrands]O .
(...)Barzilay and Lapata automatically annotated theircorpora for the grammatical role of the NPs ineach sentence (denoted in the example by thesubscripts S, O and X for subject, object andother respectively)1 as well as their coreferentialrelations.
This information is used as the basisfor the computation of the entity grid: a two-dimensional array that captures the distribution ofNP referents across sentences in the text using theaforementioned symbols for their grammatical roleand ???
for a referent that does not occur in asentence.
Table 1A illustrates a fragment of the gridfor the sentences in example (1).2Our data transformation script computes the basicstructure of Centering (known as CF list) for eachrow of the grid using the referents with the symbols1Subjects in passive constructions such as ?Microsoft?in (1b) are marked with O.2If a referent such as microsoft is attested by severalNPs, e.g.
?Microsoft Corp.?
and ?the company?
in (1a), therole with the highest priority (in this case S) is used.S, O and X (Table 1B).
The members of the CFlist are ranked according to their grammatical role(Brennan et al, 1987) and their position in the grid.3The derived sequence of CF lists can then be used tocompute other important Centering concepts:?
The CB, i.e.
the referent that links the current CF list withthe previous one such as microsoft in (b).?
Transitions (Brennan et al, 1987) and NOCBs, that is,cases in which two subsequent CF lists do not have anyreferent in common.?
Violations of CHEAPNESS (Strube and Hahn, 1999),COHERENCE and SALIENCE (Kibble and Power, 2000).2.2 Metrics of coherenceKaramanis (2003) assumes a system which receivesan unordered set of CF lists as its input and uses ametric to output the highest scoring ordering.
Hediscusses how Centering can be used to define manydifferent metrics of coherence which might be usefulfor this task.
In our experiments we made use of thefour metrics employed in Karamanis et al (2004):?
The baseline metric M.NOCB which simply prefers theordering with the fewest NOCBs.?
M.CHEAP which selects the ordering with the fewestviolations of CHEAPNESS.?
M.KP, introduced by Kibble and Power, which sumsup the NOCBs as well as the violations of CHEAPNESS,COHERENCE and SALIENCE, preferring the ordering withthe lowest total cost.?
M.BFP which employs the transition preferences ofBrennan et al3The referent department appears in an earlier gridcolumn than microsoft because ?the Justice Department?is mentioned before ?Microsoft Corp.?
in the text.
Sincegrid position corresponds to order of mention, the formercan be used to resolve ties between referents with the samegrammatical role in the CF list similarly to the use of the lattere.g.
by Strube and Hahn.66NEWS M.NOCB pcorpus lower greater tiesM.CHEAP 155 44 1 <0.000M.KP 131 68 1 <0.000M.BFP 121 71 8 <0.000N of texts 200Table 2: Comparing M.NOCB with M.CHEAP,M.KP and M.BFP in the NEWS corpus.2.3 Experimental methodologyAs already mentioned, previous work assumes thatthe gold standard ordering (GSO) observed in a textis more coherent than any other ordering of thesentences (or the corresponding CF lists) it consistsof.
If a metric takes a randomly produced orderingto be more coherent than the GSO, it has to bepenalised.Karamanis et al (2004) introduce a measurecalled the classication rate which estimates thispenalty as the weighted sum of the percentageof alternative orderings that score equally to orbetter than the GSO.4 When comparing severalmetrics with each other, the one with the lowestclassification rate is the most appropriate forsentence ordering.Karamanis (2003) argues that computing theclassification rate using a random sample of onemillion orderings provides reliable results for theentire population of orderings.
In our experiments,we used a random sample of that size for GSOswhich consisted of more than 10 sentences.
Thisallows us to explore a sufficient portion of possibleorderings (without having to exhaustively enumerateevery ordering as Barzilay and Lee do).
Arguably,our experiments also return more reliable resultsthan those of Barzilay and Lapata who used a sampleof just a few randomly produced orderings.Since the Centering-based metrics can be directlydeployed on unseen texts without any training, wetreated all texts in NEWS and ACCS as testing data.54The classification rate is computed according to theformula Better(M,GSO) + Equal(M,GSO)/2.
Better(M,GSO)stands for the percentage of orderings that score better thanthe GSO according to a metric M, whilst Equal(M,GSO) is thepercentage of orderings that score equal to the GSO.5By contrast, Barzilay and Lapata used 100 texts in eachdomain to train their probabilistic model and 100 to test it.
Notethat although they experiment with quite large corpora theirreported results are not verified by statistical tests.ACCS M.NOCB pcorpus lower greater tiesM.CHEAP 183 17 0 <0.000M.KP 167 33 0 <0.000M.BFP 100 100 0 1.000N of texts 200Table 3: Comparing M.NOCB with M.CHEAP,M.KP and M.BFP in the ACCS corpus.3 ResultsThe experimental results of the comparisons of themetrics from section 2.2 are reported in Table 2for the NEWS corpus and in Table 3 for ACCS.Following Karamanis et al, the tables compare thebaseline metric M.NOCB with each of M.CHEAP,M.KP and M.BFP.
The exact number of GSOsfor which the classification rate of M.NOCB islower than its competitor for each comparison isreported in the second column of the Table.
Forexample, M.NOCB has a lower classification ratethan M.CHEAP for 155 (out of 200) GSOs fromNEWS.
M.CHEAP achieves a lower classificationrate for just 44 GSOs, while there is a single tie inwhich the classification rate of the two metrics isthe same.
The p value returned by the two-tailedsign test for the difference in the number of GSOs,rounded to the third decimal place, is reported in thefifth column of Table 2.6Overall, the Table shows that M.NOCB doessignificantly better in NEWS than the otherthree metrics which employ additional Centeringconcepts.
Similarly, M.CHEAP and M.KP areoverwhelmingly beaten by the baseline in ACCS.Also note that since M.BFP fails to significantlyovertake M.NOCB in ACCS, the baseline can beconsidered the most promising solution in that casetoo by applying Occam?s razor.Table 4 shows the results of the evaluation of themetrics in GNOME from Karamanis et al Theseresults are strikingly similar to ours despite the muchsmaller size of their sample.
Hence, M.NOCB isthe most suitable among the investigated metrics forordering the CF lists in both NEWS and ACCS inaddition to GNOME.6The sign test was chosen by Karamanis et al to testsignificance because it does not carry specific assumptionsabout population distributions and variance.67GNOME M.NOCB pcorpus lower greater tiesM.CHEAP 18 2 0 <0.000M.KP 16 2 2 0.002M.BFP 12 3 5 0.036N of texts 20Table 4: Comparing M.NOCB with M.CHEAP,M.KP and M.BFP in the GNOME corpus.4 DiscussionOur experiments have shown that the baselineM.NOCB performs better than its competitors.This in turn indicates that simply avoiding NOCBtransitions is more relevant to sentence ordering thanthe additional Centering concepts employed by theother metrics.But how likely is M.NOCB to come up with theGSO if it is actually used to guide an algorithmwhich orders the CF lists in our corpora?
Theaverage classication rate of M.NOCB is anestimate of exactly this variable.The average classification rate for M.NOCBis 30.90% in NEWS and 15.51% in ACCS.The previously reported value for GNOME is19.95%.7 This means that on average M.NOCBtakes approximately 1 out of 3 alternative orderingsin NEWS and 1 out of 6 in ACCS to be morecoherent that the GSO.
As already observed byKaramanis et al, there results suggest that M.NOCBcannot be put in practical use.However, the fact that M.NOCB is shown toovertake its Centering-based competitors acrossseveral corpora means that it is a simple, yet robust,baseline against which other similar metrics can betested.
For instance, Barzilay and Lapata report aranking accuracy of around 90% for their best grid-based sentence ordering method, which we take tocorrespond to a classification rate of approximately10% (assuming that there do not exist any equallyscoring alternative orderings).
This amounts to animprovement over M.NOCB of almost 5% in ACCSand 20% in NEWS.Given the deficiencies of the evaluation inBarzilay and Lapata, this comparison can only be7The variability is presumably due to the differentcharacteristics of each corpus (which do not prevent M.NOCBfrom always beating its competitors).provisional.
In our future work, we intend to directlyevaluate their method using a substantially largenumber of alternative orderings and M.NOCB as thebaseline.
We will also try to supplement M.NOCBwith other features of coherence to improve itsperformance.AcknowledgmentsMany thanks to Regina Barzilay and Mirella Lapata for theirdata, to Le An Ha for the data transformation script and to ChrisMellish, Massimo Poesio and three anonymous reviewers forcomments.
Support from the Rapid Item Generation project(Wolverhampton University) and the BBSRC-funded Flyslipgrant (No 16291) is also acknowledged.ReferencesRegina Barzilay and Mirella Lapata.
2005.
Modeling localcoherence: An entity-based approach.
In Proceedings ofACL 2005, pages 141?148.Regina Barzilay and Lillian Lee.
2004.
Catching the drift:Probabilistic content models with applications to generationand summarization.
In Proceedings of HLT-NAACL 2004,pages 113?120.Susan E. Brennan, Marilyn A. Friedman [Walker], and Carl J.Pollard.
1987.
A centering approach to pronouns.In Proceedings of ACL 1987, pages 155?162, Stanford,California.Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein.
1995.Centering: A framework for modeling the local coherence ofdiscourse.
Computational Linguistics, 21(2):203?225.Nikiforos Karamanis, Massimo Poesio, Chris Mellish, and JonOberlander.
2004.
Evaluating centering-based metrics ofcoherence using a reliably annotated corpus.
In Proceedingsof ACL 2004, pages 391?398, Barcelona, Spain.Nikiforos Karamanis.
2003.
Entity Coherence for DescriptiveText Structuring.
Ph.D. thesis, Division of Informatics,University of Edinburgh.Rodger Kibble and Richard Power.
2000.
An integratedframework for text planning and pronominalisation.
InProceedings of INLG 2000, pages 77?84, Israel.Mirella Lapata.
2003.
Probabilistic text structuring:Experiments with sentence ordering.
In Proceedings of ACL2003, pages 545?552, Saporo, Japan, July.Massimo Poesio, Rosemary Stevenson, Barbara Di Eugenio,and Janet Hitzeman.
2004.
Centering: a parametrictheory and its instantiations.
Computational Linguistics,30(3):309?363.Michael Strube and Udo Hahn.
1999.
Functional centering:Grounding referential coherence in information structure.Computational Linguistics, 25(3):309?344.68
