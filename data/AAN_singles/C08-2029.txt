Coling 2008: Companion volume ?
Posters and Demonstrations, pages 115?118Manchester, August 2008On ?redundancy?
in selecting attributes for generating referringexpressionsPhilipp Spanger Kurosawa TakehiroDepartment of Computer ScienceTokyo Institute of TechnologyTokyo Meguro?Ookayama 2-12-1, 152-8550 Japan{philipp, kurosawa, take}@cl.cs.titech.ac.jpTokunaga TakenobuAbstractWe seek to develop an efficient algorithmselecting attributes that approximates hu-man selection.
In contrast to previous workwe sought to combine the strengths of cog-nitive theories and simple learning algo-rithms.
We then developed a new algo-rithm for attribute selection based on ob-servations from a corpus, which outper-formed a simple base algorithm by a sig-nificant margin.
We then carried out a de-tailed comparison between our algorithmand Reiter & Dale?s ?Incremental Algo-rithm?.
In terms of achieving a human-likeattribute selection, the overall performanceof both algorithms is fundamentally equiv-alent, while differing in the handling of re-dundancy in selected attributes.
We furtherinvestigated this phenomenon and drawsome conclusions for further improvementof attribute-selection algorithms.1 IntroductionReferring expressions are a key research area inhuman-agent communication.
In the generation ofreferring expressions humans do not necessarilyproduce the most effective (i.e.
minimal) expres-sions in a computational sense.
Given evolution-ary development of human linguistic capabilities,we can assume that human-produced expressionsare generally optimal to identify a target for otherhuman subjects.
Thus the generation of human-like referring expressions is an important task asc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.the generation of those expressions that are mosteasily understandable for humans.The seminal work in this field is the ?Incremen-tal algorithm?
(IA) (Dale and Reiter, 1995).
Theirwork is based on an analysis of the overall cog-nitive tendencies of humans in the selection of at-tributes.
In recent years, there have been a numberof important extensions to this algorithm, dealingwith very specific problems.
This need for a sys-tematic approach and unified evaluation of thosevastly differing algorithms provided the motiva-tion for the creation of the TUNA-corpus1that wasdeveloped at Aberdeen University as part of theTUNA project (van Deemter, 2007).
Work has be-gun to use this corpus for evaluating different al-gorithms for attribute selection.Our research is carried out within this generaltrend, seeking to take advantage of common re-sources (e.g.
TUNA-corpus).
A critical question ishow to combine the generic human cognitive ten-dencies and the dependency of attribute selectionon a specific distribution of attributes in a specificcase.
In this research we tackle this question ina corpus-based approach.
Specifically, in a givenenvironment, we seek to develop an efficient algo-rithm for selection of attributes that approximateshuman selection.2 The corpusWe utilized a simplified version of the TUNA-corpus, which was also the basis for the GRE-challenge held as part of the UCNLG+MT work-shop in 2007 (Belz and Gatt, 2007).
The corpusconsists of a collection of paired pictures of objectsand human-produced referring expressions anno-tated with attribute sets.
Figure 1 shows an image1TUNA-corpus: www.csd.abdn.ac.uk/research/tuna115greengreengreengreenredred bluetargetFigure 1: Image of a TUNA-corpus pictureof such a case2.
This corpus provides informationon the attribute-value pairs of the target and thedistractors as well as of the referring expressionshumans produced.
Every item in our corpus con-sists of an input part (?case?)
and an output part(?description?).
Each individual case consists ofseven case entities: one target referent and six dis-tractors.
Every entity consists of a set of attribute-value pairs and all descriptions consist of a subsetof the attribute-value pairs of the target referent inthe same format as any entity.
This corpus com-prises two domains: a ?Furniture?
and a ?Person?- domain.
We note that within the corpus therewere some cases that we judged as inappropriatefor this study and thus excluded from the overallevaluation.
This included cases where attribute-values were unspecified and/or inconsistent.3 The base algorithmWe developed a base algorithm as a baseline forevaluation.
We define ?discriminative power?
of aspecific attribute as the number of entities in thecase that have a different value from the target forthis attribute.We add attributes in descending order of dis-criminative power until the target can be identifieduniquely.
The generated attribute set is the output.Every time an attribute is selected, we recalcu-late the discriminative power of the attributes ofexclusively those distractors that could not be ex-cluded by this stage.4 Analysis of human-produced referringexpressionsOur hypothesis is that in human generation of re-ferring expressions, a combination of generic cog-2Actual pictures in the TUNA-corpus do neither showcolour labels nor a target-marker.nitive factors as well as case-dependent factorshave to be dealt with.
In order to account for thecognitive factor, we define a ?selection probabil-ity?
over a whole domain (i.e.
independent from aspecific case) and calculate the differences of thisselection probability over the different attributes.We define the selection probability of a specific at-tribute a in a specific domain as equation (1).SP (a) =C(a)?x?XC(x)(1)where C(x) denotes the number of occurrences ofattribute x in the corpus.We observe that in the Furniture-domain the at-tributes colour and type have extraordinarily highselection probabilities and in particular the at-tribute type is selected virtually unconditionally.We observe the same tendency of a very high selec-tion probability for the attribute type in the Person-domain, even though all distractors as well as thetarget are of same type ?person?.
Since the at-tribute type becomes the head of the noun phrasein the linguistic realisation of a referring expres-sion, it is natural to mention the type.
Overall, wecan conclude that the different values for the selec-tion probabilities reflect the cognitive load humansassign different attributes in a given domain.4.1 Co-occurrence of attributesWe hypothesize that the selection of attributes islimited by co-occurence - dependencies betweenattributes.In order to measure this degree of co-occurrence, we defined a ?degree of dependency?between attributes as in equation (2).
If the degreeof dependency approaches 1, there is practically nodependency in the occurrence of attributes a and b.If this factor grows above 1, the two attributes eas-ily occur jointly in the referring expression, on theother hand, the further it decreases below 1, theless likely are the two attributes to occur jointly.In the equation P(a, b) is the probability that thetwo attributes will be selected together, P(x) isthe probability that the attribute x will be selected.D(a, b) is the degree of dependency between at-tributesD(a, b) =P(a, b)P(a)?
P(b)(2)We observed that in the Furniture-domain, sizeor orientation and dimension are less likely to oc-116cur together in a referring expression.
Further-more, in the Person - domain, hairColour andhasHair or hasBeard have a high degree of depen-dency, i.e.
they likely occur together.4.2 Redundancy of attributesEven though in many referring expressions uniqueidentification with few attributes is possible, hu-mans show a tendency to add ?redundant?
at-tributes, i.e.
that are in a strict sense not necessaryfor identification.
By adding redundancy, humansadd robustness to the expression as well as pos-sibly reducing the cognitive load for humans in aspecific context.
Within the corpus, we counted thenumber of expressions containing redundancy.
Inthe Furniture-domain there were 220 out of all 278expressions and in the Person-domain there were213 out of 230.Table 1: Number of selected redundant attributesFurniture (278 cases) Person (230 cases)attribute occurrences attribute occurrencescolour 110 type 201orientation 15 x-dimension 4size 10 hasBeard 42type 210 hasGlasses 41x-dimension 18 hasHair 32This level of redundancy indicates that in or-der to produce human-like sets of attributes for thegeneration of referring expressions, it is not neces-sary to aim for a minimal set.5 Our proposed algorithm for effectiveattribute selectionBased on our analysis of co-occurrence and redun-dancy of attributes, we centrally implemented thefollowing improvements of the base algorithm.Co-occurrence Based on the results from sec-tion 4.1, when a certain attribute is selected, weraise the selection probabilities of those attributesthat have a tendency to co-occur with it, on theother hand we lower the selection probabilities ofthose attributes that have a tendency not to co-occur with this attribute.Redundancy Based on the results in section 4.2,having selected the attributes to uniquely deter-mine the target, we add the next candidate in thelist of attributes as a redundant attribute .Combination We combine both individual im-provements.
First of all, we add the type-attributeand then score the result based on the selec-tion probability.
With each selection of a spe-cific attribute, we change the scores based on co-occurrence, and at the end we add a redundant at-tribute.6 Evaluation of proposed algorithmWe measured the proximity of the sets of attributesby our system to the human-produced set of at-tributes.
We utilize the Dice-coefficient (DC) ?a measure of proximity for sets.
For purposes ofTable 2: Average DC for key improvementsFurniture PersonBase algorithm 0.305 0.314Base+selection probability 0.784 0.669Base+co-occurrence 0.254 0.314Base+redundancy 0.401 0.341Combination 0.811 0.703Incremental algorithm 0.811 0.705comparison, we implemented a version of the In-cremental algorithm, where we calculated the or-der of selection of attributes according to the se-lection probabilities of attributes in the overall do-main (Furniture or Person).
It is of note that ouralgorithm (combination of all individual improve-ments) performs almost equivalent to the IA.6.1 Comparison with Incremental AlgorithmWe carried out a detailed analysis of the results ofour algorithm and those of the IA.
We found thatthe results of both algorithms in the Furniture - do-main are exactly the same; however the results ofthe Person - domain show significant differences.Thus we concentrate on further analysis of the re-sults in the Person - domain.We divided all cases from the Person - domaininto three sets; a set of cases where our algorithmperforms better than the IA (sys-superior cases: 27cases), a set of cases where the opposite is true (IA-superior cases: 24 cases) and a set of tie cases.
Wethen compared the first two sets.Investigating these sets, we observed that thekey difference between these two algorithms layin the treatment of redundancy.
The IA often failsin the case where humans use fewer attributes andadd only type as redundant attribute.
On the otherhand, our algorithm fails in the case where humansuse more complex expressions, that is, more at-tributes including several redundant ones.We investigated the redundant attributes whichare selected by humans but not by the algorithms.117In the IA-superior cases, our system fails to se-lect the hasBeard attribute compared with the IAin 20 out of 24 cases, while in the sys-superiorcases both algorithms fail to select almost the sameredundant attributes.
We investigated for both al-gorithms, which attributes the algorithms wronglyselect; i.e.
which are not selected by humans.
Inthe sys-superior cases, the IA wrongly selects at-tributes in all 27 cases, with 23 out of those in-cluding the wrongly-selected hasBeard attribute.In the IA-superior cases, the number of caseswith wrongly selected attributes is much smaller(9 cases for each) and they are largely equiavalent.Thus, our detailed analysis showed an over-all opposite tendency in one attribute; hasBeard.While in sys-superior cases about 85% of the casesin which the IA output wrong attributes includedhasBeard, in IA-superior cases our system failedto select exactly hasBeard at a largely equivalentrate (about 83%).
At this moment, we do not haveany reasonable explanation for this peculiarity ofhasBeard, but suspect it might possibly be relatedto the characteristics of the corpus.However, from the overall observation that ouralgorithm achieved an equivalent level of human-likeness to the IA while being weaker in cases ofmore complex redundancy, we conclude that fur-ther improvement in selecting redundant attributesis crucial to outperform the IA.7 Concluding RemarksBased on observations from the TUNA-corpus,we developed an algorithm for attribute-selectionmodeling human referring expressions.
Ourcorpus-based algorithm sought to combine humangeneric tendencies of attribute selection in a cer-tain domain with case-dependent variation of thesalience of specific attributes.
Our improved algo-rithm outperformed the base algorithm by a signif-icant margin.
However, we got qualitatively equiv-alent results to our implementation of the IA.A detailed analysis of the characteristics of ouralgorithm in comparison to the IA pointed to theimportance of the phenomenon of redundancy aspossibly a central aspect that needs to be furtherinvestigated to achieve a qualitative improvementover the IA.Our investigations into redundancy show that inthose cases where our algorithm outperformed theIA, our algorithm almost exclusively added solelythe type-attribute.
In contrast in more complexcases of redundancy in referring expressions, theIA has shown to be superior.
Since we achievedoverall parity to the IA even though generally per-forming worse than the IA in cases of more com-plex redundancy, we can conclude that outside ofthis phenomenon our algorithm performs betterthan the IA in terms of human-likeness.In previous research there has been some discus-sion on ?redundancy?
vs. ?minimality?
in refer-ring expressions (e.g.
(Viethen and Dale, 2006)).Through our research we have identified the phe-nomenon of redundancy as a critical topic for fur-ther research and for achieving further progressin the generation of human-like referring expres-sions.Our algorithm includes some strong simplifica-tions, e.g.
our treatment of attributes did not takeaccount of the fact that attribute-values are also ofdifferent type and did not explore what implica-tions this has for the process of producing refer-ring expressions; binary (hasHair), discrete (hair-Colour) or graded (x-dim).
In future these factorsshould be integrated into attribute selection algo-rithms.In future work, we will seek to provide a moredetailed investigation of the phenomenon of re-dundancy, including its variation over different do-mains.
Such an analysis should also contribute tofurther our understanding of the human cognitiveprocess in the selection of attributes for the gener-ation of referring expressions.ReferencesBelz, Anja and Albert Gatt.
2007.
The attribute se-lection for GRE challenge: Overview and evaluationresults.
In Proceedings of the MT Summit XI Work-shop Using Corpora for Natural Language Gener-ation: Language Generation and Machine Transla-tion (UCNLG+MT), pages 75?83.Dale, Robert.
and Ehud Reiter.
1995.
Computationalinterpretation of the gricean maxims in the gener-ation of referring expressions.
Cognitive Science,19(2):233?263.van Deemter, Kees.
2007.
TUNA: To-wards a unified algorithm for the genera-tion of referring expressions - Final Report -.http://www.csd.abdn.ac.uk/research/tuna/pubs/TUNA-final-report.pdf.Viethen, Jette and Robert Dale.
2006.
Algorithms forgenerating referring expressions: Do they do whatpeople do?
In Proceedings of the Fourth Inter-national Natural Language Generation Conference,pages 63?70.118
