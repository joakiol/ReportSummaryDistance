Proceedings of the First Workshop on Multilingual Modeling, pages 18?24,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsThe Study of Effect of Length in Morphological Segmentation ofAgglutinative LanguagesLoganathan Ramasamy and Zdene?k Z?abokrtsky?Institute of Formal and Applied LinguisticsFaculty of Mathematics and Physics, Charles University in Prague{ramasamy, zabokrtsky}@ufal.mff.cuni.czSowmya VajjalaSeminar fu?r SprachwissenschaftUniversita?t Tu?bingensowmya@sfs.uni-tuebingen.deAbstractMorph length is one of the indicative featurethat helps learning the morphology of lan-guages, in particular agglutinative languages.In this paper, we introduce a simple unsu-pervised model for morphological segmenta-tion and study how the knowledge of morphlength affect the performance of the seg-mentation task under the Bayesian frame-work.
The model is based on (Goldwater etal., 2006) unigram word segmentation modeland assumes a simple prior distribution overmorph length.
We experiment this modelon two highly related and agglutinative lan-guages namely Tamil and Telugu, and com-pare our results with the state of the art Mor-fessor system.
We show that, knowledge ofmorph length has a positive impact and pro-vides competitive results in terms of overallperformance.1 IntroductionMost of the NLP tasks require one way or an-other the handling of morphology.
The task be-comes very crucial when the language in ques-tion is morphologically rich as is the case in manyIndo-European languages.
The application of mor-phology is evident in applications such as Statis-tical Machine Translation (SMT) (Lee, 2004), de-pendency parsing, information retrieval and so on.Apart from the morphological analysis as in the tra-ditional linguistic sense, morphological segmenta-tion is also widely used as an easy alternative tofull fledged morphological analysis.
In this paperwe mainly focus on the task of morphological seg-mentation.The main task in morphological segmentation isto segment the given token or wordform into setof morphs or identifying the location of each mor-pheme boundary within the token.
Morphologicalsegmentation is most suitable for agglutinative lan-guages (such as Finnish or Turkish) than fusionallanguages (such as Semitic languages).Though both supervised (Koskenniemi, 1983)and unsupervised methods (Goldsmith, 2001;Creutz and Lagus, 2005) are extensively studied formorphological segmentation, unsupervised tech-niques have the appeal of application to multilin-gual data with cost effective manner.
Within un-supervised paradigm, various methods have beenexplored.
Minimum Description Length (MDL)(Goldsmith, 2001; Creutz and Lagus, 2005) basedapproaches are most popular in which the best seg-mentation corresponds to the compact represen-tation of morphology and the resulting lexicon.
(Goldwater et al, 2009; Snyder and Barzilay, 2008)attempted word segmentation and joint segmenta-tion of related languages using Bayesian approach.
(Demberg, 2007; Dasgupta and Ng, 2007) appliedvarious probabilistic measures to discover affixesof wordforms.
(Naradowsky and Goldwater, 2009;Yarowsky and Wicentowski, 2000) explored waysto model orthographic rules of wordforms.In this work, we are mainly going to focus onBayesian approach.
Bayesian approaches providenatural way of modeling subjective knowledge aswell as separating problem specific aspects fromgeneral aspects.
In the case of agglutinative lan-18guages, the number of morphemes in a word as wellas morph length play a major role in morpholog-ical process.
The main rationale for this work isto study linguistic factors (mainly morph length),so that language specific priors can be applied overdifferent languages.
This will especially be use-ful when modeling resource poor languages (RPL)with little or no data, as well as building resourcesfor RPL from resource rich languages (RRL).Towards that objective, our main contribution inthis work is, we introduce a simple unsupervisedsegmentation model based on Bayesian approachand we study the effect of morph length prior fortwo agglutinative languages.2 Previous WorkIn this section, we briefly survey earlier works thatutilized the morph length information, then we pro-vide basis for our unsupervised morphological seg-mentation model and finally we list some priorworks on morphological analysis/segmentation ofTelugu and Tamil.Snover (2001) used an exponential like distri-bution for morph length that decreased over wordlength, thus favoring shorter morph lengths.
Ourwork is directly related to (Creutz, 2003) as itmade use of prior distributions on morph length andfrequency of morphs under maximum a posteriori(MAP) framework.
Gamma distribution was usedas a prior distribution for morph length.
The maindifference between (Creutz, 2003) and our work isthat, we are going to experiment different morphlengths under Bayesian framework.Naradowsky (2011) introduced an exponentiallength penalty to prevent the model from under seg-mentation results.
It also emphasized that avoidinglength penalty seriously affected the model.
(Poonet al , 2009) indirectly specified about the morphlength by restricting the number of morphemes perword.In this work, we mainly rely on Goldwater (2009;2006) which conducted an extensive study on theapplication of Bayesian approach to word segmen-tation in child-directed speech utterances.
It in-cluded both unigram and bigram models (based onHierarchical Dirichlet Processes) for word segmen-tation.
Gibbs sampling was used to extract sam-ples (utterances with word boundaries) from pos-terior distribution.
We apply the unigram model(Goldwater et al, 2009) to morphological segmen-tation where the word boundaries in speech utter-ances correspond to morpheme boundaries in word-forms.Before we describe unsupervised morphologicalsegmentation model, we briefly survey the existingwork on Telugu and Tamil morphological segmen-tation/analysis.Rao et al (2011) described in detail, the prepara-tion of a linguistic database for Telugu morpholog-ical analysis, compiling 2800 morphological cate-gories and reported a coverage of 95-97%.
Theyfollowed a word and paradigm model, which wasconsidered to be better suited for agglutinative lan-guages.
The issue of out-of-vocabulary words washandled better in the rule based approach by (Gana-pathiraju and Levin, 2006).
They describe a rule-based morphological analyzer TelMore for Telugunouns and verbs.Aksharbharathi et al (2004) describes the devel-opment of a generic morphological analysis shellthat uses dictionaries along with Finite State Trans-ducers based feature structures, to perform the mor-phological analysis of a word.
The feature struc-tures were derived from the standard rules of thegrammar in respective languages.
This was testedwith Hindi, Telugu, Tamil and Russian.Kiranmai et al (2010) describe a supervisedmorphological analyzer with support vector ma-chines.For Tamil, morphological segmentation is rarelystudied.
Most of the work is done for morpholog-ical analysis of wordforms.
Most of the analyz-ers use rule based approaches.
Dhanalakshmi et al(2009) used sequence labeling approach to morpho-logical analysis of wordforms.3 Unsupervised MorphologicalSegmentationConsider a wordform (w) of length n composed ofcharacters from alphabet LA,w = c1c2c3...cnThe main objective is to identify the character po-sitions where morpheme boundaries occur.
The19model we describe here is similar to the cachemodel described in (Goldwater et al, 2006) forword segmentation.
We apply the same model toidentify morpheme boundaries.
The model makesdecision at every character position in the wordformfor the entire corpus.
The hypothesis probabilitythat no morpheme boundary at position i in word-form w is calculated as follows,P (w?i |h) =nma + ?P0(ma)Nm + ?
(1)ma is a substring or a morph in the wordformw which contains the character position position i.nma refers to number of times the morph ma oc-curs in the history of morph counts Nm.
In the caseof having a boundary at position i, we will havetwo morphs to consider, one morph (ma) to the leftof position i (including i), and another morph (mb)starting after i.
The probability of having a mor-pheme boundary at position i is calculated in thesame way as Equation 1, but this time with twomorphs,P (w+i |h) =nma + ?P0(ma)Nm + ?.nmb + I(ma == mb) + ?P0(mb)(Nm + 1) + ?
(2)I(ma == mb) takes the value 1 if both morphsare same, otherwise the value is 0.
Also note thatthe additional 1 (due to previous factor) in the de-nominator of the second part of the equation.
Inboth the equations, P0 is a base distribution whichcan be utilized to put a bias over certain hypothe-ses.
In our case, the base distribution (P0) mainlyassigns probability distribution over morph length.Additional linguistic factors can also be modeledthis way.
?
is a concentration parameter which canbe used to control P0.
Overall, the model (in equa-tion 1 and 2) uses only unigram morph counts.Every character position (except the last posi-tion) in a given word is a potential candidate thatcan have a morpheme boundary.
To determinewhether they really have morpheme boundary ornot, for every character position i inw, we calculatehypothesis probabilities b+i (i.e.
has a morphemeboundary) and b?i (has no morpheme boundary).Having calculated the hypothesis probabilities, wechoose the hypothesis by using a weighted coin flip.In our problem, we have only two hypotheses: (i) amorpheme boundary and (ii) no morpheme bound-ary.
If the new hypothesis is different from the char-acter?s previous status, then appropriate data struc-tures are updated.
This procedure is repeated formany number of iterations.3.1 Modeling morpheme lengthWe encode our beliefs about morph length viabase distribution P0.
We chose Poisson distribu-tion for modeling the length of the morphs.
Pois-son distribution utilizing morph length is defined asP (l, k) = lke?lk!
, where l is an expected length ofthe morph and when supplied k, it returns the prob-ability density of a morph having length k. We de-fine two base distributions based on morph lengthprior,PA0 (m) = p(l, k)=lke?lk!
(3)PB0 (m) = p(m)p(l, k)=nm| lm |lke?lk!
(4)p(m) is probability of the morph itself.
| lm | -total number of substrings of length equal to thelength of morph m. Morfessor (Creutz and Lagus,2005) uses Zipfian distribution for frequencies andgamma length prior for modeling the length of themorphs.
Setting a particular expected morph lengtheffectively puts a bias towards that particular morphlength (l).
We experiment both our base distribu-tions over different morph lengths.3.2 InferencingGibbs sampling (Gilks et al, 1996) uses iterativeprocedure to repeatedly draw value of a variablegiven the current state of all other variables in themodel.
In our case, drawing a value is equal todetermining whether there is a boundary at thecharacter position, thus obtaining individual mor-phemes.
We iteratively segment the given corpus orlist of words into morphological segments.
The in-tuitive idea is that, when we sample enough numberof times i.e.
drawing morphological segments ofwords given history of segments of all other words,20the sampler converges to the posterior distributionof the morphological segments of the entire corpus.The Algorithm 1 gives a general outline of how theGibbs sampling procedure is applied to morpholog-ical segmentation.Algorithm 1: Basic Sampling ProcedureData: words, modelResult: Segmented wordsbeginRandSeg ??
InitializeSegments(words)Baseline??
Evaluate(RandSeg)CurrSeg ??
RandSegMorphCounts??
GetCounts(CurrSeg)for i ?
iterations dofor j ?
size(words) dofor k ?
length(words[j]) dob?k ??
Calculate(P (words[j]?k ))b+k ??
Calculate(P (words[j]+k ))if HasNoBoundaryAt(k) thenadd boundary at k withprobabilityb+kb?k +b+kno change at k with probabilityb?kb?k +b+kif HasBoundaryAt(k) thenremove boundary at k withprobabilityb?kb?k +b+kno change at k with probabilityb+kb?k +b+kUpdateCurrSeg(CurrSeg)AdjustMorphCounts(MorphCounts)We use temperature (T) settings (not shown inthe algorithm) to make the sampling procedure con-verge faster.
We use 10 values (from 0.1 to 1.0) forT and raise the probability values of hypotheses to( 1T ).
Also, we make the collection rate very small,so that only few and substantially different samples(or morphological segmentation of the entire cor-pus) are collected.4 Experimental SetupThe experiments are carried out for the unigramsegmentation model (unsup-uni) as described inSection 3 and Morfessor system (Creutz and Lagus,2005).
For both Tamil and Telugu, we perform thefollowing experiments: (i) baseline (ii) unsup-uniwith base distribution PA0 (unsup-uni-p0-len) (iii)unsup-uni with base distribution PB0 (unsup-uni-p0-lex-len) and (iv) with Morfessor.
For each sys-tem, we add some knowledge about morph length(l) and report the accuracy.The experiments (ii), (iii) and (iv) use additionaldataset known as extra-data.
Extra-data is an unan-notated/unsegmented data which augments the testdata while training the systems.
As test data withgold segmentation is very small, we feel this step isnecessary to make the evaluation credible.
The fol-lowing subsection describes the datasets in detail.Baseline system corresponds to random segmen-tation.
We evaluate baseline system for morphlengths 1 to 10.
For each morph length (l) experi-ment, we change the probability of adding a bound-ary at each character position to be (1l ) except atl = 1 where the probability is 0.75.Unsup-uni-p0-len experiment uses base distribu-tion PA0 (see Section 3.1).
We conduct this experi-ment in 2 steps: (i) running the Gibbs sampler withthe extra-data and (ii) use the parameters (includ-ing morph counts) from step (i) and run the Gibbssampler on test data.
We set the expected morphlength (l) in the base distribution PA0 every time werun the experiment for different morph length.
Forthe step (i), the Gibbs sampler is run for 10000 iter-ations with different concentration parameter (?
).We collect samples every 1000 iterations and westore the last sample as our model along with otherparameters.
For step (ii), we use the model fromstep (i) and run the Gibbs sampler on test data.
Wecollect the final sample as our predicted segmen-tation of the test data and perform evaluation onthe predicted segmentation.
In unsup-uni-p0-lex-len experiment, we use the base distribution PB0(see Section 3.1).
PB0 includes morpheme proba-bility apart from the length prior.
Experiments forunsup-uni-p0-lex-len is carried out in the same wayas that of unsup-uni-p0-len.We use gamma distribution length prior for ex-periments with Morfessor.
We train Morfessor onextra-data for morph lengths 1 to 10.
We changethe expected length in the gamma prior for eachmorph length experiment.
Then we run the Mor-fessor on test data with same parameters createdduring the training.We use Precision (P), Recall (R) and F-score (F)21Lang.
Words Chars Morphs Avg.
m.(l)Tamil 1500 12642 3280 3.85Telugu 998 10303 1733 5.95Table 1: Gold segmentation: statisticsfor evaluating our predicted segmentation with goldsegmentation.
Our evaluation is same as (Creutzand Linde?n, 2004).4.1 DataWe use EMILLE corpus (Xiao et al , 2004) forour experiments.
The EMILLE corpus containsmonolingual, parallel and annotated data for var-ious Indian languages.
We randomly selected ar-ticles from monolingual section of Tamil and Tel-ugu data.
The original data were in utf-8 andwe transliterated the data into latin format.
Thetransliteration step is an important step as it avoidsconfusion in specifying morph length (l).
As wealready mentioned earlier, we use two sets (extra-data and test data) of data for each language.
Fortraining of extra-data, we use 30000 unique wordslist for each language.
For test data, we make wordslist from real sentences thus it can contain multi-ple occurrences of a same wordform.
The Table 1provides the statistics of the test data for which wehave manually performed gold segmentations.
Atpresent, our gold segmentation does not take intoaccount multiple possible segmentations.The Figure 1 shows morph counts distributionof both Tamil and Telugu (derived from gold seg-ments) according to their morph lengths.
Tamil hasmore morphs that are shorter in length than Telugu.5 ResultsThe Table 2 shows evaluation results for the exper-imental setup described in the previous section.For Tamil, most of the morphs have the length 1-4.
The models unsup-uni-p0-len and unsup-uni-p0-lex-len perform quite well near to that length range.For the same range (l = 1 to 4), both the modelstogether perform better than Morfessor in terms ofF-score.
The performance of unsup-uni-p0-len andunsup-uni-p0-lex-len are constantly decreasing andstart to perform worse than Morfessor after length5.
This is somewhat expected that unsup-uni mod-1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 18Tamilmorph length (l)morph count02004006001 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16Telugumorph length (l)morph count0100200300Figure 1: Morph counts according to morph length (l)els are quite sensitive to length priors and may per-form poorly if we assume morph lengths far fromthe true range.
Whereas, Morfessor has a consis-tent performance over the entire length range (l = 1to 10).
This implies that, Morfessor is less sensitiveto length priors even if we drastically change theexpected morph length.
Unsup-uni-p0-len gave thebest overall performance (F-score - 48.83%) com-pared to other models in this task.Telugu?s common morph length ranges from 2-8.
Except at l = 1 & 2, Morfessor beats bothunsup-uni-p0-len and unsup-uni-p0-lex-len in allother remaining length ranges.
Unsup-uni modelsperform quite poorly over different length rangeswhen comparing with Tamil for the same range.
Inthis task, Morfessor?s overall performance (F-score43.63%) is better than unsup-uni models.
Mor-fessor also performs better near the most frequentmorph length range (5-8).6 Some Observations on (l)?
The results (Table 2) suggest that unsup-unimodel is quite sensitive to morph length pa-rameter in the prior distributions.?
For Tamil, unsup-uni model performs wellnear to the true morph length range.
But theperformance deteriorates when the expectedmorph length parameter is too different from22Language System P/R/FMorph length (l)1 2 3 4 5 6 7 8 9 10TamilbaselineP 15.79 15.86 17.04 17.11 15.33 16.33 15.98 14.75 17.63 16.65R 73.98 50.08 34.92 26.25 19.64 15.50 13.82 11.47 12.31 10.24F 26.02 24.09 22.91 20.72 17.22 15.91 14.82 12.91 14.50 12.68unsup-uni-p0-lenP 63.61 62.17 67.99 69.68 69.22 72.77 72.29 68.70 66.73 64.08R 39.62 40.01 36.49 33.18 28.82 26.47 24.23 22.10 20.65 20.76F 48.83 48.69 47.49 44.96 40.7 38.82 36.30 33.45 31.54 31.36unsup-uni-p0-lex-lenP 46.51 59.48 63.79 63.69 56.10 54.58 50.29 48.18 45.99 50.39R 41.35 41.07 39.34 38.28 36.04 33.69 34.25 34.08 33.02 28.65F 43.78 48.59 48.67 47.82 43.88 41.66 40.75 39.92 38.44 36.53MorfessorP 48.54 48.32 48.61 49.01 50.24 49.07 49.93 49.21 49.42 48.93R 41.75 40.18 40.07 40.24 40.46 39.84 40.35 39.84 40.40 39.62F 44.89 43.87 43.93 44.19 44.82 43.98 44.63 44.03 44.64 43.78TelugubaselineP 07.88 08.05 07.91 07.38 07.70 07.54 07.62 08.52 08.96 07.91R 75.69 51.59 32.97 23.86 20.00 16.00 13.66 13.38 12.97 10.07F 14.28 13.93 12.76 11.27 11.12 10.25 09.78 10.41 10.60 10.07unsup-uni-p0-lenP 36.67 37.29 36.2 39.71 41.87 40.58 41.34 39.15 38.10 33.65R 53.10 51.17 48.14 38.07 29.1 19.31 16.14 11.45 11.03 9.66F 43.38 43.14 41.33 38.87 34.34 26.17 23.21 17.72 17.11 15.01unsup-uni-p0-lex-lenP 22.27 26.55 32.46 35.76 28.29 19.31 19.83 18.3 18.17 17.26R 66.9 58.34 44.41 35.17 35.31 55.17 42.21 49.79 55.45 52.28F 33.41 36.5 37.51 35.47 31.41 28.6 26.98 26.76 27.37 25.95MorfessorP 29.32 29.59 30.48 30.72 30.88 30.85 31.31 30.34 29.88 30.40R 70.30 69.48 69.48 69.75 70.17 70.30 71.96 70.99 70.58 71.96F 41.38 41.50 42.38 42.65 42.89 42.88 43.63 42.51 41.99 42.74Table 2: Results for Tamil and Teluguthe true frequent morph length range.?
However for Telugu, morph length parameterdid not improve the results at the most frequentmorph length range (5-8).?
Concentration parameter (?)
too influencesthe effect of base distribution as a whole, butat present, our study does not take into account?.
For small ?
values, the base distributionwill not have much effect.7 ConclusionIn this paper, we mainly studied the effect of knowl-edge of morph length that could have on the ac-curacy of morphological segmentation of aggluti-native languages.
Towards that goal, we intro-duced a simple unsupervised morphological seg-mentation model based on Bayesian approach thatutilized prior distribution over morph length.
Theresults showed that the knowledge of length cer-tainly has a positive impact on the accuracy.
Also,the model provided competitive results in generaland achieved best overall performance (F-score:48.83%) for Tamil against Morfessor.
As a futurework, it would be interesting to see the model andpriors that handle sandhi changes.AcknowledgementsThe research leading to these results has re-ceived funding from the European Commission?s7th Framework Program (FP7) under grant agree-ment n?
238405 (CLARA).
We would like to thankDavid Marec?ek for useful suggestions about theoryand implementation of the system.
We also wouldlike to thank anonymous reviewers for their usefulcomments.ReferencesAkshar Bharathi, Rajeev Sangal, Dipti M Sharma andRadhika Mamidi.
2004.
Generic MorphologicalAnalysis Shell.
In Proceedings of LREC 2004.Benjamin Snyder and Regina Barzilay.
2008.
Unsuper-vised Multilingual Learning for Morphological Seg-mentation.
In Proceedings of the 46th Annual Meet-ing of the Association for Computational Linguistics(ACL), pages 737?745.
2008.David Yarowsky and Richard Wicentowski.
MinimallySupervised Morphological Analysis by MultimodalAlignment.
In Proceedings of the 38th Annual Meet-ing on Association for Computational Linguistics(ACL), 2000.Dhanalakshmi V, AnandKumar M, Rekha RU and Ra-jendran S. 2009.
Morphological Analyzer for Ag-23glutinative Languages Using Machine Learning Ap-proaches.
In Advances in Recent Technologies inCommunication and Computing, 2009, ARTCom?09,2009.Hoifung Poon, Colin Cherry and Kristina Toutanova.2009.
Unsupervised Morphological Segmentationwith Log-Linear Models.
In Proceedings of Hu-man Language Technologies: The 2009 Annual Con-ference of the North American Chapter of the ACL(NAACL-HLT), pages 209?217, Boulder, Colorado,June 2009.Jason Naradowsky and Sharon Goldwater.
2009.
Im-proving Morphology Induction by Learning SpellingRules.
In Proceedings of 21st International JointConference on Artificial Intelligence (IJCAI), 2009.Jason Naradowsky and Kristina Toutanova.
2011.
Un-supervised Bilingual Morpheme Segmentation andAlignment with Context-rich Hidden Semi-MarkovModels.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguis-tics: Human Language Technologies, pages 895?904,June, 2011.John Goldsmith.
2001.
Unsupervised Learning of theMorphology of a Natural Language.
ComputationalLinguistics, 27(2): pages 153?198, 2001.Kimmo Koskenniemi.
1983.
Two-level morphol-ogy: A general computational model for word-formrecognition and production.
Publication 11, Univer-sity of Helsinki, Department of General Linguistics,Helsinki.
1983.Madhavi Ganapathiraju and Lori Levin.
2006.
Tel-More: Morphological Generator for Telugu Nounsand Verbs.
In Proceedings of the Second Interna-tional Conference on Digital Libraries.
2006.Mathias Creutz.
2003.
Unsupervised Segmentation ofWords Using Prior Distributions of Morph Lengthand Frequency.
In Proceedings of the 41st AnnualMeeting of the Association for Computational Lin-guistics (ACL), pages 280?287, July 2003.Mathias Creutz and Krista Lagus.
2005.
UnsupervisedMorpheme Segmentation and Morphology Inductionfrom Text Corpora Using Morfessor 1.0.
In Publica-tions in Computer and Information Science, ReportA81, Helsinki University of Technology, 2005.Mathias Creutz and Krister Linde?n.
2004.
MorphemeSegmentation Gold Standards for Finnish and En-glish.
Publications in Computer and Information Sci-ence, Report A77, Helsinki University of Technology,October, 2004.Matthew G. Snover and Michael R. Brent.
2001.
ABayesian model for morpheme and paradigm identi-fication.
In Proceedings of the 39th Annual Meetingon Association for Computational Linguistics (ACL),pages 490?498, 2001.Sai Kiranmai G., K. Mallika, M. Anand Kumar, V.Dhanalakshmi and K. P. Soman.
2010.
Morpho-logical Analyzer for Telugu using support vector ma-chines.
In Proceedings of ICT 2010.Sajib Dasgupta and Vincent Ng.
2007.
High-Performance, Language-Independent MorphologicalSegmentation.
In Proceedings of NAACL HLT 2007,pages 155?163, 2007.Sharon Goldwater, Thomas L. Griffiths and Mark John-son.
2006.
Contextual dependencies in unsupervisedword segmentation.
In In Proceedings of the 21st In-ternational Conference on Computational Linguisticsand 44th Annual Meeting of the Association for Com-putational Linguistics (ACL), 2006.Sharon Goldwater, Thomas L. Griffiths and Mark John-son.
2009.
A Bayesian framework for word segmen-tation: Exploring the effects of context.
Cognition,112 (1), pp.
21?54, 2009.Uma Maheshwar Rao G., Amba Kulkarni P. and Christo-pher Mala.
2011.
A Telugu Morphological Analyzer.International Telugu Internet Conference Proceed-ings, Milpitas, California, USA, 28th - 30th Septem-ber, 2011Vera Demberg.
2007.
A Language-Independent Unsu-pervised Model for Morphological Segmentation.
InProceedings of the 45th Annual Meeting of the As-sociation of Computational Linguistics (ACL), pages920?927, Prague, Czech Republic, June 2007.Walter R. Gilks, Sylvia Richardson and David Spiegel-halter.
1996.
Markov Chain Monte Carlo in Practice.Chapman and Hall.
1996.Xiao Z., McEnery A., Baker P. and Hardie A.
2004.Developing Asian language corpora: standards andpractice.
In Proceedings of the Fourth Workshop onAsian Language Resources, pp.
1?8, 2004.Young-Suk Lee.
2004.
Morphological Analysis for Sta-tistical Machine Translation.
In Proceedings of theHLT-NAACL 2004, pp.
57?60, Boston, USA, 2004.24
