Chinese Base-Phrases ChunkingYuqi Zhang and Qiang ZhouState Key Laboratory of Intelligent Technology and SystemsDepartment of Computer Science and TechnologyTsinghua University, Beijing, 100084, P.R.China{zyq, zhouq}@s1000e.cs.Tsinghua.edu.cnAbstractThis paper introduces new definitions of Chinesebase phrases and presents a hybrid model tocombine Memory-Based Learning method anddisambiguation proposal based on lexicalinformation and grammar rules populated from alarge corpus for 9 types of Chinese base phraseschunking.
Our experiment achieves an accuracy(F-measure) of 93.4%.
The significance of theresearch lies in the fact that it provides a solidfoundation for the Chinese parser.1 IntroductionRecognizing simple and non-recursive base phrasesis an important subtask for many natural languageprocessing applications, such as informationretrieval.
Gee and Grosjean (Gee and Grosjean,1983) showed psychological evidence that chunkslike base phrases play an important role in humanlanguage understanding.
CoNLL-2000?s sharedtask identified many kinds of English base phrases,which are syntactically related non-overlappinggroups of words (Tjong and Buchholz, 2000).
Theshared task has significantly heightened theprogress in the techniques of English partialparsing.
For Chinese processing, Zhao (1998) putforward a definition of Chinese baseNP that is acombination of determinative modifier and headnoun (Zhao, 1998).
Based on that research, Zhao etal.
(2000) extended the concept of baseNP to seventypes of Chinese base phrases.
These base phrasesmay consist of words or other base phrases, but itsconstituents, in turn, should not contain any basephrases.In this paper, we put forward the new definitionof Chinese base phrases, which are simple andnon-recursive, similar to the CoNLL-2000?s sharedtask.
The definition enables us to resolve most localambiguities and is very useful for NLP tasks such asname entity recognition and information extraction.We construct a hybrid model to recognize ninetypes of Chinese base phrases.
Many researches inChinese partial parsing (Zhou, 1996; Zhao, 1998;Sun, 2001) have shown that statistical learning is ofgreat use for Chinese chunking, especially for largecorpus.
However, the lack of morphological hints inChinese makes it necessary to use semantic andsyntactic information such as context free grammarrules in Chinese processing.
In our approach,viewing chunking as a tagging problem byencoding the chunk structure in new tags attachedto each word, we use Memory-Based Learning(MBL) method to set a tag indicating type andposition in a base phrase on each word.
After whichgrammar rules are used to disambiguate the tags.Our test with a corpus of about 2 MB showed thatthe experiment achieves 94.4% in precision and92.5% in recall.2 Definitions of Chinese BasePhrasesThe idea of parsing by chunks goes back to Abney(1991).
In his definition of chunks in English, heassumed that a chunk has syntactic structure and hedefined chunks in terms of major heads, which areall content words except those that appear betweena function word and the content word whichselects.
A major head is the ?semantic?
head (s-head)for the root of the chunk headed by it.
However,s-heads can be defined in terms of syntactic heads.If the syntactic head h  of a phrase P is a contentword,  is also the s-head of P. If h  is a functionword, the s-head of P is the s-head of the phraseselected by .f fhhThe research enlightens us about the definition ofChinese base phrases.
In this paper, a Chinese basephrase consists of a single content word surroundedby a cluster of function words.
The single contentword is the semantic head of the base phrase.
Theforms of base phrases can be expressed as follows.
{Modifier} * + head + {complement}* orCoordinate structureThe components of ?modifier?
and ?complement?are optional.
A head could be a simple word as wellas the structure of ?modifier + head?
or ?head +complement?, but not ?modifier + head +complement?.
Coordinate structure could notconsist of coordinate symbols such as comma andco-ordinating conjunction.
The type of base phrasesis congruent with its head?s semantic information.In most cases, the type accords with the head?ssyntactical information, for example, when the headis a noun, the phrase is a noun phrase.
However,when a head is a noun that denotes a place, the basephrase including that head is not a noun phrase, buta location phrase.We consider 9 types of Chinese base phrases inour research: namely adjective phrase (ap),distinguisher phrase (bp), adverbial phrase (dp),noun phrase (np), temporal phrase (tp), locationphrase (sp), verb phrase (vp), quantity phrase (mp),quasi quantity phrase (mbar).
The inner grammarstructures of every base phrase are very importanttoo, but we will discuss that in another paper.3 OverviewThe frame of Chinese base phrase parsing iscomposed of two parts: one is the ?Type andbracket tagging model?, the other is the ?Basephrases acquisition model?
which consists of twomodules which are ?brackets matching ?and?correct the types of base phrases?.
(See figure 1.
)The input to the system is a sequence of POS.
In the?Predict the phrase boundary?
module, we predictthe type, which each word belongs to, and theposition of each word in a base phrase withMemory-Based Learning (MBL)(Using thesoftware package provided by Tilburg University.
).And the result is expressed as a pair formed by basephrase type and position information.
Because ourChinese base phrases are non-recursive andnon-overlapping, the left and right boundaries ofbase phrases must match with each other whichmeans they should be a pair and alternative.However, the errors involving in the first part willlead to incorrect base phrases because theboundaries do not match, for example ?[?[?]?.
Inthe second part, grammar rules that indicate theinner structures of base phrases are used to resolvethe boundary ambiguities.
Furthermore, it alsotakes lexical information into account to correct thetype mistakes.The corpus used in the experiment includes 7606sentences.
It comes from the Chinese BalanceCorpus including about 2000 thousand words withfour types: literature (44%), news (30%), academicarticle (20%) and spoken Chinese (6%).
These 7606sentences are split into 6846 training sentences and760 held out for testing.Input Type and bracket taggingmodelObtain feature vectorsPredict the phrase boundaryBrackets matching Grammar rulesCorrect the types of basephrases  LexicalinformationOutput Base phrases acquisition modelFigure 1: system overview4 Predicting the phrase boundarieswith MBLMemory-Based Learning (MBL) is a classificationbased, supervised learning approach: amemory-based learning algorithm constructs aclassifier for a task by storing a set of examples.Each example associates a finite number of classes.Given a new feature vector, the classifierextrapolates its class from those of the most similarfeature vectors in memory (Daelemans et, al., 1999).The input to the ?Predict the phrase boundary?module is some feature vectors, which compose of asequence of POS.
The solution of the module is tofind >< ii cr ,iic,,,{(Wojciech and Thorsten, 1998), aduple formed by a type tag and a boundary tag foreach word t .
Here r  indicates the boundary tag,while  denotes the type tag.i,, },,,, ??
mbarmpbpspdpc j, LRritp}apvpnp,,,{ OIRL(?-?
denotesthe word is not in any type of base phrases.)?
The  indicates the positionof the word in a base phrase as shown below:ir?L?
: the left boundary,     ?R?
: the right boundary,?I?
: the middle position, ?O?
: outside any basephrases, ?LR?
: the left and right boundary.What information is used to represent data infeature vectors is an important aspect in MBLalgorithms.
We tried many feature vectors withvarious lengths.
And it is interesting to note that thefeature window is not the bigger the better.
Whenthe feature window is (-2, +2) in the context, theresult is the best.
So the feature vector in theexperiment is: (POS-2, POS-1, POS0, POS+1,POS+2).
The pattern describes the combination offeature vector and result duple >< mncr: 90,40 ????
mn(POS-2, POS-1, POS0, POS+1, POS+2, ).
>< mncrFor the experiment in the first step, we use1TiMBL , an MBL software package developed inthe ILK-group (Daelemans et, al., 2001).
Theresults of phrase boundary prediction with MBLshows in table 1.Table1?The result of word boundary predictionTable 1 shows that there is much differencebetween the results of various types of base phrases.The precisions and recalls of np, vp, mp, ap and dpare all almost over 90%.
Comparatively, the resultsof sp, tp, bp and mbar are much lower, especiallytheir recalls.
This is due to some resemblancesbetween sp, tp and np in Chinese syntacticalgrammars.
Sp and tp may be considered as belongto NP, however, in the definition of Chinese basephrases, sp, tp and np are defined separately for thesemantic difference.
And the separation can alsohelp in other tasks such as proper nounidentification, information retrieval etc.TiMBL1  is a software bag about many MBLalgorithms.
It can be download free fromhttp://ilk.kub.nl/5 Obtaining Chinese base phrases5.1 The errors in phrase boundarypredictionThere are three types of errors in the results of firstprocessing model.
(1) Boundary ambiguity: the r  ?s mistakeswill cause the multiple choices regarding theboundaries.
For example:  ?i{np ?/rN  } ?/m  ?
?/n  } ?/?
?/p  {np ?
?/t  {np ?
?/n  } ?/u  {np ?
?/vN  ?
?/vN  } {ap ?/dD  ?/a  } ?/??.
(Please pay attention to the?__?
part.)
There are altogether three modalities:?
{ ?
{ ?
}?, ?
{ ?}?}?
and?
{ ?
{ ?}?}?.
These are caused by theredundancy and absence of boundaries.mcmcmc mcmc(2) The type mistake of base phrases: Forexample: in the sentence of ?
{np ?
?/n  } {dp ??
?/d  } {vp ?/vC  } {np ???
?/nS  } ?/f  {tp ?
?/nR  ?
?/n  } ?/p?
?, the parser mistakes the type of ?
{ ?
?/nR  ?
?/n  }?
,which is np, for tp.
This error typecommonly appears between sp, tp and np, as well asmbar and mp.Precisionfor<  >mncrRecallFor >< mncrnpvpsptpapbpdpmpmbar92.27%90.40%75.15%82.87%93.52%92.60%97.56%93.90%74.15%93.61%89.65%48.41%71.62%91.89%76.38%97.63%92.38%72.26%Total1 91.90% 91.65%- 97.85% 98.41%Total2 93.83% 93.83%(3)   Boundaries absence: For example, in thesentence of ?
{vp ?
?/v  } {np ?
?/n  } ?/?
{np ?
?/n  ?
?/n  } ?
?/c  {vp ?
?/v  }?,  ?
{np ?
?/n  ?
?/n  }?should be ?
{np ?
?/n  } {np ?
?/n  }?.
It is verydifficult to correct this type of errors because theboundary distribution accords with the definition ofChinese base phrases.
The left and right boundariesalternate with each other.
Therefore, it is verydifficult to find the errors in the sequence from themodalities.5.2 Obtaining the whole base phraseswith Grammar rulesWith the bracket (boundary) representation,incorrect bracket will be generated but these will beeliminated in the bracket combination process.
Inthe experiment, we attempt to apply grammar rulesthat represent the inner structures of Chinese basephrases to get rid of the boundary ambiguities.These grammar rules are derived from the corpus.On the other hand, boundary predictions can findmany base phrases that do not accord with thelimited grammar rules.Figure 2 shows the main strategy of how to usethe grammar rules.
When if ()>1, there are morethan one pair of combined brackets in which thesequences accord with the grammar rules.
We areapt to choose the longest possible because theshorter sequences appear more in the corpus.
Thelonger the sequence, the more weight it should carry.When there is only the shorter sequence accordingwith grammar rules, it is more possible to be thecorrect one.
In this case, one or more boundarieswill be left.
They often need some other boundariesto match, so we try to retrieve some missingboundaries through the partitions in the sentencesthat should not belong to any base phrases.
Thesepartitions are the marks of base phrase boundaries.If we find these partitions between two ambiguousboundaries, we will know where to place the newboundary.5.3 Correct the type mistake withlexical informationIn the Chinese language, some POS sequences maybelong to different types.
For example, ?
{vN n}?could be np, sp or tp.
These sequences often appearin np, sp, tp, mp and mbar.
It is difficult to know itsright type even with the grammar rules, as we havedone in section 5.2.
In order to resolve this problem,we attempt to use lexical information because itimplies semantic information to some extent.The lexical information is distinctive between mpand mbar.
mbar is often composed of numbers suchas ?1200?
and numbers in Chinese such as ??
?.The lexical information between tp and np is alsoobvious, such as ???
?, ????
and ????
etc.
Forsp and np, the words are ???
?, ????
etc.5.4 Experimental resultsStep 1:  Finding the sequence where the errors appear.
The sequences are three types:?{?{?
}?, ?{?}?
}?, ?{?{?}?
}?.Step 2:  if  (the number of sequences of POS in a pair of matched boundaries according with the grammarrules) >1then {Select the boundaries that make the sequence longest}Step 3:  if (the number of sequences of POS in a pair of combined boundaries according with the grammarrules) =1if (Only the sequence with the shortest length accords with the grammar rules).then { Find partitions such as conjunctions, localizers, punctuations and someprepositions between the ambiguous boundaries in sequences;if (The partitions exist)then {Add boundaries to generate whole base phrases according to thepartitions}}Figure 2:  The Algorithm of Matching BoundariesThe simplest bracket combination algorithm is verystrict: it only uses adjacent brackets if they appearnext to each other in the correct order (first openand then close) without any intervening brackets.The result of the algorithm is shown in table 2, asthe baseline of the boundary combinationexperiment.Table 2: The base-line resultPrecision Recall F_MNp 93.9% 86.1% 89.8%Vp 90.6% 86.2% 88.4%Sp 75.5% 47.7% 58.4%Tp 85.4% 70.2% 77.0%Ap 93.4% 83.4% 88.1%Bp 93.4% 71.3% 80.9%dp 97.7% 94.0% 95.8%mp 92.0% 85.3% 88.5%mbar ------- 0 -------Total 92.9% 85.7% 89.2%Table 3: The result of disambiguation withgrammar rulesPrecision Recall F_Mnp 94.3% 91.9% 93.1%vp 95.0% 94.2% 94.6%sp 73.6% 50.9% 60.2%tp 84.9% 73.8% 79.0%ap 93.5% 89.7% 91.5%bp 91.6% 79.4% 85.0%dp 97.6% 98.1% 97.8%mp 86.7% 90.9% 88.7%mbar 63.6% 12.6% 21.1%Total 93.9% 92.0% 92.9%From the table 2, we could see the recalls arecommonly low.
We change another strategy toobtain the whole base phrases as described insection 5.2.
The result of using the grammar rules isshown in table 3.With the help of grammar rules, all kinds of basephrases improved their f-measures though theprecisions or recalls of some types decrease slightly.Comparing with the baseline results in table 2, allthe recalls increase significantly.
However, therecalls of sp, tp and mp still do not satisfy us.
Thereare more than twenty structures of np which alsobelong to tp or sp.
Except in the case where mp andmbar have the same structure {m}, they are easilydistinguished in other structures.
(Mbar is alwayscomposed of numerals and mp always ends with aquantifier.)
In order to distinguish tp from np, spfrom np and mbar from mp, we use lexicalinformation for the type disambiguation.
Theresults are shown in table 4.Table 4: The result after using lexicalinformationPrecision Recall F_Mnp 95.0% 91.9% 93.5%vp 95.0% 94.3% 94.6%sp 69.2% 71.3% 70.2%tp 79.8% 84.1% 81.9%ap 93.1% 90.0% 91.5%bp 91.6% 79.4% 85.0%dp 97.6% 98.1% 97.8%mp 93.4% 90.9% 92.1%mbar 67.6% 54.1% 60.1%Total 94.4% 92.5% 93.4%From the table 4, we could see improvement inall the results (precisions and recalls) of mp andmbar.
It shows that the lexical information iseffective for distinguishing between them.
On thecontrary, although the f-measures of np and spincrease, their precisions decline.
Thus, those wordsmarking tp and sp are not appropriate fordisambiguation.
We could see the effect of lexicalinformation is limited because it is difficult to findthe words that could distinguish different types ofbase phrases.6 ConclusionsThe experiment on identifying Chinese basephrases shows that the definition of Chinese basephrases is suitable for parsing.
It shows good resultsand the efficiency of the proposed approach insimplifying sentence structures.
Many tasks such aschunking on high level could benefit from this.With the system described here, we get 9 types ofChinese base phrases, and acquire high precisionsand recalls on most types of base phrases.
Theresults of the experiment also show that the use ofgrammar rules is necessary.
Grammar rules haveeffects on boundary disambiguation particularly.The lexical information is effective indistinguishing between mbar and mp.AcknowledgementsThis work was supported by the National ScienceFoundation of China (Grant No.
69903007),National 973 Foundation (Grant No.
1998030507)and National 863 Plan (Grant No.
2001AA114040).ReferencesAbney, Steven.
(1991) Parsing by chunks.
InBerwick, Abney, and Tenny, editors,Principle-Based Parsing.
Kluwer AcademicPublishers.Erik F. Tjong Kim Sang and Sabine Buchholz.(2000).
?Introduction to CoNLL-200 SharedTask: Chunking?.
Proceedings of CoNLL-2000and LLL-2000.
Lisbon, Portugal.
127-132.J.
P. Gee and F. Grosjean (1983) Performancestructures: A psycholinguistic and linguisticappraisal.
Cognitive Psychology, 15:411-458Sun Honglin (2001) A Content Chunk Parser forUnrestricted Chinese Text, Dissertation for thedegree of Doctor of Science, Peking University.Walter Daelemans, Jakub Zavrel, Ko van der Sloot(2001) TiMBL:Tilburg Memory-Based Learnerversion 4.0 Reference Guide.http://ilk.kub.nl/downloads/pub/papers/ilk0104.ps.pz.Wojciech Skut and Thorsten Brants (1998) ChunkTagger, Statistical Recognition of Noun Phrase,In ESSLLI-98 Workshop on AutomatedAcquisition of Syntax and Parsing, Saarbrvcken.Zhao Jun (1998) The research on Chinese BaseNPRecognition and Structure Analysis, Dissertationfor the degree of Doctor of Engineering,Tsinghua University.Zhao et al, (2000) Tie-jun ZHAO, et al ?StatisticsBased Hybrid Approach to Chinese Base PhraseIdentification?, In Proceedings of the SecondChinese Language Processing Workshop, ACL2000, 73-77.Zhou, Qiang (1996).
Phrase Bracketing andAnnotating on Chinese Language Corpus, Ph.D.dissertation, Peking University.
