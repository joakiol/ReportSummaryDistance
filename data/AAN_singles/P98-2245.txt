Bridging the Gap between Dictionary and ThesaurusOi Yee KwongComputer  Laboratory ,  Un ivers i ty  of  Cambr idgeNew Museums Site, Cambr idge  CB2 3QG,  U.K.oyk20@cl .cam.ac .ukAbst ractThis paper presents an algorithm to integrate dif-ferent lexical resources, through which we hope toovercome the individual inadequacy of the resources,and thus obtain some enriched lexical semantic in-formation for applications such as word sense disam-biguation.
We used WordNet as a mediator betweena conventional dictionary and a thesaurus.
Prelimi-nary results support our hypothesised structural re-lationship, which enables the integration, of the re-sources.
These results also suggest that we can com-bine the resources to achieve an overall balanced e-gree of sense discrimination.1 In t roduct ionIt is generally accepted that applications uch asword sense disambiguation (WSD), machine trans-lation (MT) and information retrieval (IR), requirea wide range of resources to supply the necessarylexical semantic information.
For instance, Cal-zolari (1988) proposed a lexical database in Italianwhich has the features of both a dictionary and athesaurus; and Klavans and Tzoukermann (1995)tried to build a fuller bilingual exicon by enhancingmachine-readable dictionaries with large corpora.Among the attempts to enrich lexical information,many have been directed to the analysis of dictio-nary definitions and the transformation of the im-plicit information to explicit knowledge bases forcomputational purposes (Amsler, 1981; Calzolari,1984; Chodorow et al, 1985; Markowitz et al,1986; Klavans et al, 1990; Vossen and Copestake,1993).
Nonetheless, dictionaries are also infamousof their non-standardised sense granularity, and thetaxonomies obtained from definitions are inevitablyad hoc.
It would therefore be a good idea if we canunify our lexical semantic knowledge by some exist-ing, and widely exploited, classifications such as thesystem in Roget's Thesaurus (Roget, 1852), whichhas remained intact for years and has been used inWSD (Yarowsky, 1992).While the objective is to integrate different lex-ical resources, the problem is: how do we recon-cile the rich but variable information in dictionary1487senses with the cruder but more stable taxonomieslike those in thesauri?This work is intended to fill this gap.
We useWordNet as a mediator in the process.
In the fol-lowing, we will outline an algorithm to map wordsenses in a dictionary to semantic lasses in someestablished classification scheme.2 In ter - re la tedness  o f  the  ResourcesThe three lexical resources used in this work are the1987 revision of Roget's Thesaurus (ROGET) (Kirk-patrick, 1987), the Longman Dictionary of Contem-porary English (LDOCE) (Procter, 1978) and Word-Net 1.5 (WN) (Miller et al, 1993).
Figure 1 showshow word senses are organised in them.
As we havementioned, instead of directly mapping an LDOCEdefinition to a ROGET class, we bridge the gap withWN, as indicated by the arrows in the figure.
Sucha route is made feasible by linking the structures incommon among the resources.Words are organised in alphabetical order inLDOCE, as in other conventional dictionaries.
Thesenses are listed after each entry, in the form of textdefinitions.
WN groups words into sets of synonyms("synsets"), with an optional textual gloss.
Thesesynsets form the nodes of a taxonomic hierarchy.In ROGET, each semantic lass comes with a num-ber, under which words are first assorted by part ofspeech and then grouped into paragraphs accordingto the conveyed idea.Let us refer to Figure 1 and start from word x2 inWN synset X.
Since words expressing every aspectof an idea are grouped together in ROGET, we cantherefore xpect o find not only words in synset X,but also those in the coordinate WN synsets (i.e.
Mand P, with words ml,  m2, pl, P2, etc.)
and the su-perordinate WN synsets (i.e.
C and A, with wordscl, c2, etc.)
in the same ROGET paragraph.
Inother words, the thesaurus class to which x2 belongsshould include roughly X U M U P U C U A. Mean-while, the LDOCE definition corresponding to thesense of synset X (denoted by D~) is expected to besimilar to the textual gloss of synset X (denoted byGI(X)).
In addition, given that it is not unusual forA120.
N. c l ,  c2, ... (in C); / ~ ' " - - ~ml,  m2, ... (in M); p l ,  p2, B C{el ,  c2, ... }.
GIfC)... (in P); x l ,  x2, ... (in X) I\[V .... Adj .... E F M P X\ [ml .
m2.... }.GI(M) {pl, p2, ...I, GI(P} {x l ,  x2, ... }, GI(X)121.N .... /~R Tx2I.... definition (Dx) similiar t,) GI(X)or defined in terms of words inX t)r C, etc.2 ....3 ....x3I ....2 ....(ROGEr) 0~VN) (LDOCE)Figure 1: Organisation of word senses in different resourcesdictionary definitions to be phrased with synonymsor superordinate rms, we would also expect o findwords from X and C, or even A, in the LDOCE def-inition.
That means we believe Dx ~ GI(X) andD~N(XUCUA)  5?
.3 The  A lgor i thmThe possibility of using statistical methods to assignROGET category labels to dictionary definitions hasbeen suggested by Yarowsky (1992).
Our algorithmoffers a systematic way of linking existing resourcesby defining a mapping chain from LDOCE to RO-GET through WN.
It is based on shallow process-ing within the resources themselves, exploiting theirinter-relatedness, and does not rely on extensive sta-tistical data.
It therefore has an advantage of beingimmune to any change of sense discrimination withtime, since it only depends on the organisation butnot the individual entries of the resources.
Given aword with part of speech, W(p), the core steps areas follows:S tep  1: From LDOCE, get the sense definitionsDz, ..., Dt under the entry W(p).Step  2: From WN, find all the synsetsSn{wl,w2,...} such that W(p) e Sn.
Alsocollect the corresponding loss definitions,Gl(Sn), if any, the hypernym synsets Hyp(Sn),and the coordinate synsets Co(Sn).Step  3: Compute a similarity score matrix .4 forthe LDOCE senses and the WN synsets.
Asimilarity score .4(i,j) is computed for the i thLDOCE sense and the jth WN synset usinga weighted sum of the overlaps between theLDOCE sense and the WN synset, hypernyms,and gloss respectively, that is.4(i,j) = al\[D, M Sj\[ + a2IDi M gyp(Sj)\[+ asIni N GI(Sj) IFor our tests, we tried setting az = 3, a2 = 5and as = 2 to reveal the relative significance offinding a synonym, a hypernym, and any wordin the textual gloss respectively in the dictio-nary definition.S tep  4: From ROGET, find all paragraphsPm{wi,w2, ...} such that W(p) E pro.Step 5: Compute a similarity score matrix B for theWN synsets and the ROGET classes.
A simi-larity score B(j, k) is computed for the jth WNsynset (taking the synset itself, the hypernyms,and the coordinate terms) and the k th ROGETclass, according to the following:B(j, k) = bllSj N Pkl + b2IHyp(Sj) M Pkl+ bHCo(Sj) n PklWe have set bz = b2 = ba = 1.
Since a ROGETclass contains words expressing every aspect ofthe same idea, it should be equally likely to findsynonyms, hypernyms and coordinate terms incommon.Step 6: For i = I to t (i.e.
each LDOCE sense), findmax(A(i,j.))
from matrix A.
Then trace frommatrix B the jth row and find rnax(B(j,k)).The i th LDOCE sense should finally be mappedto the ROGET class to which Pk belongs.We have made an operational assumption aboutthe analysis of definitions.
We did not attempt oparse definitions to identify genus terms but simplyapproximated this by using the weights az, a2 and asin Step 3.
Considering that words are often definedin terms of superordinates and slightly less often bysynonyms, we assign numerical weights in the ordera2 > az > as.
We are also aware that definitions cantake other forms which may involve part-of relations,membership, and so on, though we did not deal withthem in this study.4 Test ing  and  Resu l tsThe algorithm was tested on 12 nouns, listed in Ta-ble 1 with the number of senses in the various lexicalresources.The various types of possible mapping errors aresummarised in Table 2.
Incorrectly Mapped andUnmapped-a re both "misses", whereas Forced Er-ror and Unmapped-b are both "false alarms".The performance of the three parts of mappingis shown in Table 3.
The "carry-over error" is only1488Word R W L Word R W LCountry 3 4 5 Matter 8 5 7Water 9 8 8 System 6 8 5School 3 6 7 Interest 14 8 6Room 3 4 5 Voice 4 8 9Money 1 3 2 State 7 5 6Girl 4 5 5 Company 10 8 9Table 1: The 12 nouns used in testingTarget ExistsYesNoMapping OutcomeWrong Match No MatchIncorrectly Mapped Unmapped-aForced Error Unmapped-bTable 2: Different ypes of errorsapplicable to the last stage, L -+R, and it refers tocases where the final answer is wrong as a result ofa faulty outcome from the first stage (L --+W).L--~W W--~R L -~RAccurately Mapped 68.9% 75.0% 55.4%Incorrectly Mapped 12.2% 1.4% 4.1%Unmapped-a 2.7% 6.9% 13.5%Unmapped-b 13.5% 5.6% 16.2%Forced Error 2.7% 11.1% -Carry-over Error - - 10.8%Table 3: Performance of the algorithm5 Discuss ionOverall, the Accurately Mapped figures support ourhypothesis that conventional dictionaries and the-sauri can be related through WordNet.
Looking atthe unsuccessful cases, we see that there are rela-tively more "false alarms" than "misses", showingthat errors mostly arise from the inadequacy of indi-vidual resources because there are no targets ratherthan from partial failures of the process.
Moreover,the number of "misses" can possibly be reduced ifmore definition patterns are considered.Clearly the successful mappings are influenced bythe fineness of the sense discrimination in the re-sources.
How finely they are distinguished can beinferred from the similarity score matrices.
Readingthe matrices row-wise shows how vaguely a certainsense is defined, whereas reading them column-wisereveals how polysemous a word is.While the links resulting from the algorithm canbe right or wrong, there were some senses of thetest words which appeared in one resource but hadno counterpart in the others, i.e.
they were not at-tached to any links.
Thus 18.9% of the LDOCEsenses, 11.1% of the WN synsets and 58.1% ofthe ROGET classes were among these unattachedsenses.
Though this implies the insufficiency of us-ing only one single resource in any application, it alsosuggests there is additional information we can useto overcome the inadequacy of individual resources.For example, we may take the senses from one re-source and complement them with the unattachedsenses from the other two, thus resulting in a morecomplete but not redundant sense discrimination.6 Future  WorkThis study can be extended in at least two paths.One is to focus on the generality of the algorithm bytesting it on a bigger variety of words, and the otheron its practical value by applying the resultant lexi-cal information in some real applications and check-ing the effect of using multiple resources.
It is alsodesirable to explore definition parsing to see if map-ping results will be improved.Re ferencesR.
Amsler.
1981.
A taxonomy for English nouns andverbs.
In Proceedings of ACL '81, pages 133-138.N.
Calzolari.
1984.
Detecting patterns in a lexical database.
In Proceedings of COLING-8~, pages 170-173.N.
Calzolari.
1988.
The dictionary and the thesauruscan be combined.
In M.W.
Evens, editor, RelationalModels of the Lexicon: Representing Knowledge in Se-mantic Networks.
Cambridge University Press.M.S.
Chodorow, R.J. Byrd, and G.E.
Heidorn.
1985.Extracting semantic hierarchies from a large on-linedictionary.
In Proceedings of ACL '85, pages 299-304.B.
Kirkpatrick.
1987.
Roger's Thesaurus of EnglishWords and Phrases.
Penguin Books.J.
Klavans and E. Tzoukermann.
1995.
Combining cor-pus and machine-readable dictionary data for buildingbilingual lexicons.
Machine Translation, 10:185-218.J.
Klavans, M. Chodorow, and N. Wacholder.
1990.From dictionary to knowledge base via taxonomy.
InProceedings of the Sixth Conference of the Universityof Waterloo, Canada.
Centre for the New Oxford En-glish dictionary and Text Research: Electronic TextResearch.J.
Markowitz, T. Ahlswede, and M. Evens.
1986.
Se-mantically significant patterns in dictionary defini-tions.
In Proceedings of ACL '86, pages 112-119.G.A.
Miller, R. Beckwith, C. Fellbaum, D. Gross, andK.
Miller.
1993.
Introduction to ~,VordNet: An on-line lexical database.
Five Papers on WordNet.P.
Procter.
1978.
Longman Dictionary of ContemporaryEnglish.
Longman Group Ltd.P.M.
Roget.
1852.
Roger's Thesaurus of English Wordsand Phrases.
Penguin Books.P.
Vossen and A. Copestake.
1993.
Untangling def-inition structure into knowledge representation.
InT.
Briscoe, A. Copestake, and V. de Paiva, editors, In-heritance, Defaults and the Lexicon.
Cambridge Uni-versity Press.D.
Yarowsky.
1992.
Word-sense disambiguation usingstatistical models of Roget's categories trained onlarge corpora.
In Proceedings of COLING-92, pages454-460, Nantes, France.1489
