Dynamic User Level and Utility Measurement for AdaptiveDialog in a Help-Desk SystemPreetam MaloorDepartment ofComputer Science,Texas A & M University,College Station, TX 77843, USApreetam@csdl.tamu.eduJoyee ChaiConversational MachinesIBM T. J. Watson Research Center,Hawthorne, NY 10532, USAjchai@us.ibm.comAbstractThe learning and self-adaptive capability indialog systems has become increasinglyimportant with the advances in a wide range ofapplications.
For any application, particularlythe one dealing with a technical domain, thesystem should pay attention to not only the userexperience level and dialog goals, but moreimportantly, the mechanism to adapt he systembehavior to the evolving state of the user.
Thispaper describes a methodology that firstidentifies the user experience level and utilitymetrics of the goal and sub-goals, thenautomatically adjusts those parameters based ondiscourse history and thus directs adaptivedialog management.IntroductionA new generation of dialog systems hould beviewed as learning systems rather than staticmodels (Jokinen, 2000).
Close-world andstatic approaches have tremendous limitationsand often fail when the task becomes complexand the application environment andknowledge changes.
Thus, the learningcapability of a dialog system has become animportant issue.
It has been addressed in manydifferent aspects including dynamicconstruction of mutual knowledge (Andersenet al 1999), learning of speech acts (Stolckeret al 1998), learning optimal strategies(Litman et al 1998; Litman et al 1999;Walker et al 1998), collaborative agent in planrecognition (Lesh et al 1999), etc.
This paperaddresses the dynamic user modeling anddialog-goal utility measurement to facilitateadaptive dialog behavior.For any dialog system dealing with a technicaldomain, such as repair support (Weis, 1997),help-desk support, etc, it is crucial for thesystem not only to pay attention to the userknowledge and experience level and dialoggoals, but more important, to have certainmechanisms that adapt he system behavior interms of action planning, content selection,and content realization to user cognitivelimitations.
Dialog strategies and managementshould be adjusted to the evolving state of theuser.
Thus a better understanding andmodeling of user cognitive process and humanperception is desirable.In this paper, we propose a methodology thatautomatically learns user experience levelsbased on sub-goal utilities and characteristicsobserved during the interaction.
Those userlevels will further feedback to update utilitymetrics and direct different dialog strategies ateach level of dialog management: actionplanning, content selection and contentrealization.
The Help-Desk is our applicationdomain.
This is a work in progress.
We havebuilt a prototype system and are currently inthe process of evaluation of our methodologyand hypotheses.1 System OverviewThe system components, hown in figure 1,consist of a problem space representation a da set of modules and agents that utilize thisrepresentation.
The architecture supports adynamic updating process for user level andsub-goal utility measurement, and thus allowsthe system to adapt its dialog behavior to theupdated environment.94~(~o r~nt ,~decdoll I oa Lq4 -1 1r Ii iFigure 1.
System ComponentsThe problem space is modeled by an AcyclicProblem Graph structure, which represents hedialog goal (i.e., final goal) and different paths(solutions) to the final goal.
The LevelAdjusting Agent controls the initial detectionand dynamic shifting of user expertise levelbased on the interactions with the user.
TheAction Planner identifies the problem node(i.e., dialog goal) in the Acyclic ProblemGraph and locates the optimal path to it.
TheContent Selection component uses the LevelAdjusting Agent and the Action Planner toselect he content for the dialog.
The ContentRealization module deals with the finalpresentation of the dialog content o the user.The Utility Updating Agent automaticallyupdates the utility metrics of the sub-goals inthe Acyclic Problem Graph based on the singleand group user models that are created uringinteractions.
Different strategies are applied indifferent modules, which will be describedlater.2 Problem Space ModelingThe problem space is modeled by an aeyclicgraph named Acyclic Problem Graph.
It canalso be considered as a forest containing jointtrees that have overlapped root nodes andinternal nodes.
Internal nodes correspond tosub-goals.
A path traversed from a root to aparticular node contains a potential solution toa goal or sub-goal related to that node.
Given aroot node, the ffurffier away from the root, thegreater is the complexity of the goal (or sub-goal) represented by a node.
Since multiplepaths can lead to a node, there could bemultiple solutions to a goal.Figure 2 is a fragment of an acyclic graph forsolving problems pertaining to a Windowsbased PC.
In this example, three pathscorrespond to three potential solutions to theproblem about how to set the displayresolution of a monitor.A CConcept:.
Desklop SettingsRemedy: (set of remedies forgeneration purpose)Reward: +15Plmishment: -45Timeout:Best.case: 10 sees (reward: +10)Worst-ease: 30 sees (puais lma~t:-2O)Figure 2.
Acyclie Problem GraphEach node in the graph has the followingfields: Concept Name, Remedy, and UtilityMetrics that include Reward, Punishment,Best-case timeout and Worst-case firneout.Concept Name represents an instructioncorresponding to a particular goal or sub-goalduring the problem solving.
For example, theconcept of "Display Properties" node dealswith manipulating the display of the monitor.Remedy is the template that is used to generatenatural language responses and explanationscorresponding to a particular goal.
It alsocontains phrases and key terms used forlanguage generation.Reward and Punishment are the utility metricscorresponding to each sub-goal (Winlder,951972) depending upon the \]hypothesis ofuncertainty of understanding and the level ofimportance.
Uncertainty of understandingimplies the difficulty in following certaininstructions or understanding certain concepts.For example, some technical terms requireusers to possess greater expertise in order tocomprehend them.
Some potential ways ofinitializing uncertainty ofunders.tanding are byobservation, analysis of previously loggeddata, or surveys.
The level of importanceindicates the importance of the sub-goal forunderstanding an instruction or a concepttowards the realization of the overall goal ofsolving the problem.
One good indication ofsuch importance, for example, in the AcyclicProblem Graph, is the branch factor of eachnode.
A more difficult concept has a greaterlevel of uncertainty and hence would lead toless punishment if the user does notunderstand it.
On the other hand, if a usercorrectly understands a concept that has a highdegree of uncertainty, he would be rewardedhighly.
Reward and punishment can be pre-determined and then re-adjusted later when theuser and the group modeling progresses.Timeout metrics are used to indicate whetherthe user understands the instruction or theconcept associated With the sub-goal withinthe expected period of time.
The hypothesisthat when a user has no problem ofunderstanding a system instruction, the user isvery likely to respond to the system rapidly.However, when the user has difficulties,he/she tends to spend more time on thinkingand asking for help.
There are two timeouts:best-case and worst-case.
Each timeout has areward and a punishment.
Best-case time is thetime expected by the system, in the best ease,that a user would take to understaud theinstruction.
The user is rewarded when actualtime spent is less than the best-case time.Similarly, the worst-case time is the systemexpectation for the worst ease.
If the user stilldoesn't get the instruction after the worst-easetime period, he is punished for it.
Again, thesevalues are pre-set and will be dynamically ree-adjusted.3 Dialog ManagementThe Dialog Manager can be broadly classifiedinto two main modules: Content Selection andContent Realization.3.1 Content Selection ModuleThe Content Selection Module consists of fourcomponents: Level-Adjusting Agent, Utility-Updating Agent, Action Planner and ContentSelector.& L1 The Level-Adjusting A entThere are three levels of user expertise that hedialog manager takes into consideration:Expert, Moderate and Novice.
The agentcontrols the initial detection and dynamicshifting of user expertise level based oninteractions with the user.If a user is using the system for the first time, agood indication of the initial user expertiselevel is the level of detail and technicalcomplexity of the initial query.
As user'sinteraction with the system continues, a profileof the user is constructed gradually.
Thisprofile could be re-used to set the initial userexpertise when the user uses the system again.The dynamic shifting of user expertise l vel isof two kinds: local (i.e., temporary) shiftingbetween local expertise levels andaccumulated (i.e., long term) shifting betweenaccumulated expertise levels.
Local shiftingadjusts the expertise level temporarily - byobserving the user confirmation (currently anexplicit user confirmation is expected) whichindicates whether he/she understands a certaininstruction.
The reason for temporaryadjustment is because we assume that the useris having trouble understanding only thisparticular instruction and not the overallsolution.The accumulated shifting permauently adjuststhe user expertise level depending upon twothreshold values: EXPERTLEVEL andNOVICELEVEL.
The user is considered anexpert when his accumulated expertise l vel isabove the EXPERTLEVEL and is considered96novice when that is below theNOVICE_LEVEL.
The user is assumed tohave moderate xpertise if he lies betweenthese two thresholds.
An accumulated value(ACCUM_VALUE) is calculated based on thewhole dialog history.
If the ACCUiVLVALUEof a user crosses a threshold, the accumulateduser expertise level changes long term as it isassumed that there is a change in the user'soverall understanding of the solution.At any point of the interaction, the systemmaintains ACCUM VALUE for the user.
Thisvalue is used to adjust he user expertise level.The ACCUM VALUE is calculated based onthe following set of features associated withutility metrics in each node in the discoursehistory (Wies, 1997; Jameson et al 1999):Sub-goal Complexity: More complex sub-goals have a greater level of importance anduncertainty of understanding, and thus have ahigh reward and a low punishment.
Similarly,comparably simple sub-goals have a lowreward and a high punishment.Accomplishing Time: this is perhaps thetrickiest parameter as the chance of making anincorrect assumption is much higher.
The userresponse time could be a good indication ofuser understanding.
The longer the resolvingof the user's problems lasts, the moreunfavorable the evaluation is.
Also if the userresponds quickly, he is rewarded for it.
Todetect whether the user is distracted or not, if aseries of timeouts occur continuously, the useris not paying attention to the system.Response Complexity: There is a reward and apunishment associated with each systemresponse that reflects the complexity of thecontent and realization of the systemresponses.
First of all, the content for responsegeneration varies with different expertiselevels.
For novice users, all the content on thesolution path will be generated as several turnsof responses based on the number of sub-goalsin the path.
For expert users, only 40% contenton the solution path (toward the final goal) isused for the generation as one response.Furthermore, for users with different expertiselevel, the Content Realization Module willgenerate system responses (in the prototypesystem, the system responses are mainlyinstructions that guide users to solve a help-desk problem) with different levels ofsyntactic omplexity and technical details.
Forexample, for novice users, the system tends togenerate responses with single instructioncorresponding to one sub-goal, while forexpert users, the system tends to generateresponses with single instructioncorresponding to multiple sub-goals on thesolution path.
The response with multipleinstructions will have higher eward and lowerpunishment than those are associated withsingle instruction.
Thus the user who gives apositive confirmation to a more complexsystem response will be rewarded higher thanthose who understand a simple systemresponse.Based on the above factors, theACCUM VALUE can be calculateddepending upon the conditions using thefollowing formulae:ACCUM VALUE = ACCUlvLVALUE +f/response -complexity (reward, punishment), sub-goal(reward,punishmen0, timeout(reward, punishment)\]In the prototype system, we have used thefollowing:If a goal is accomplished by the user(indicatedby positive user confirmation),ACCUM_VALUE = ACCUM...VALUE + \[response-complexity(reward) * sub-goal(reward)\]If a goal is not accomplished(indicated bynegative user confirmation),ACCUM_VALUE = ACCUM.
VALUE \[response-complexity(punishment) * sub-goal(punishment)\]If a goal is accomplished before best-timetimeout value,ACCUM_VALUE = ACCUM_VALUE + \ [ response-complexity(reward) * sub-goal(best-case timeout reward)\].If a goal is not accomplished before worst-timetimeout value,ACCUMVALUE = ACCUM.VALUE - \[response-complexity(punishment) * sub-goal(worst-ease timeout punis-lament)\].Other variations of the formula re expected tobe explored in the future.973.L 2 Action Planner and Content SelectorThe Action Planner identifies the finalgoal node in the Acyclic Problem Graphand finds the optimal path to it.
Theoptimal path is selected based on the pathutility function.
The utility of a path in thegraph is the summation of thereward/punishment ra io of all the nodes (sub-goals) in that path.Path utility (start-node, goal) = E (r i / Pi)nwhere i is a concept node in the path from thestart node to the goal node, ri is the reward andpl is the punishment of the corresponding odei.
The number of nodes n in the path acts asthe normalizing factor.Thusfor a given path, higher its path utility,greater is the difficulty to understand theconcepts it contains and thus higher is thelevel of expertise required.The following co-operative strategies are used:for an expert user, select he path that has themaximum path utility.
For a novice, select heone with the minimum path utility since this isthe one containing concepts easiest tounderstand and with more steps ofinstructions.
For a moderate-experience us r,select a path in between.
(We are currentlymore focused on the experienced and noviceusers.)
Content Selector is applied to select heappropriate nodes on the path to form thecontent of dialog.3.L3 Utility Updating AgentA set of users having very similar expertiselevels can be classified as a group.
A UtilityUpdating Agent dynamically updates utilitymetrics of sub-goals in the Acyclic ProblemGraph based on the group interactions with thesystem.
For example, Group A has a reward of+50 and a punishment o f -10  assigned to thesub-goal with associated concept of DisplayProperties.
However the agent notices that themajority of the group understand thecorresponding instruction very quickly withoutgoing into the sub-goal resolution, then theagent decreases the reward to +35 andincreases the punishment to -25.
Thisdynamic re-training of utility metrics in sub-goals would reflect the evolving userexperience level as a whole and wouldimprove the robustness of the dialog manager.3.2 Content Realization ModuleThis module deals with the final presentationof the dialog content o the user.
The dialogmanager adopts different response strategiesfor each of the three expertise levels.
It hasbeen observed that an expert user appreciates aresponse, which is precise, to the point, andshort.
For a novice user, it has been observedthat such a user likes system instructions thatare step-wise, higher level of detail andminimum technical jargon.
For a moderate-experience user, the strategy lies somewhere inbetween which we haven't given a fullconsideration.
The response strategy followedfor each type of user is given in the table 1.Response \[ I.~ve~ ofd~l  of system Teclmical t~'ms in system SyntacTic Conccisencss of the\[ inKa'uctions and e:(planation in.~ru~ows and ~planation explanation Expertise iExpert / Low High HighModerate I Moderate Moderate ModerateNovice High Low LowTable 1.
User expertise level and corresponding dialog strategies983.3 AlgorithmThe proposed algorithm for action planning,content selection and content realization isgiven in Figure 3.
This algorithm recursivelyapplies a divide and conquer mechanism toaccomplish the final goal by resolving sub-goals.
Two variables (i,e., local expertise l veland accumulated expertise level) aremaintained by the Level-Adjusting Agent forthe automated level updating.
The ActionPlanner identifies the goal node and thesolution path to it depending on the expertiselevel of the user.
Based on this level, theContent Realization Module will first selectthe content on the path to be presented andthen use various response strategies togenerate and display system instructions to theuser.
For novice users, all the content onsolution path will be used; for moderate andexpert users, only partial content on the path(toward the goal) will be used.
In terms ofgeneration, for novice and moderate xpertiseusers, the system generates responses withsingle instruction corresponding to one sub-goal, while for expert users, the system tendsto generate responses with single instructioncorresponding to multiple sub-goals on thesolution path.
The syntax of the responsebecomes more complex as the expertise levelincreases.
Depending on the response of theuser, the Level-Adjusting Agent updates theuser expertise level and adapts the responsestrategies accordingly.1) Level-Adjnsting Agent detects the initial expertise level and assigns it to both local expertise level and accumulatedexpertise l vel.2) Action Planner identifies the start node and goal node in the Acyclic Problem Graph and locates the appropriate pathbetween the start node and the goal node.a~ For novice user, the path with minimum path utility is selectedb.
For expert user, the path with maximum path utility is selectedc.
For moderate user, a path in between is selected3) Content Realization Module generates system instructions based on the selected path by using the following responseSU'~tegles"a.
For an expert, the instruction is generated by using the nodes that fall within a distance of X% from the goalnode to the root node.b.
For a moderate-experienced user, nodes within a distance of Y% (where Y > X) are used,e.
For a novice, all nodes from the root to the goal are used to generate the instruction(X and Y could be experimentally determined later)4) Content Realization Module displays generated insmactions tothe user.5) Level-Adjusting Agent receives the user confirmation and updates user expertise l vel.a.
If the confirmation ispositive, the Level Adjusting Agent does the following:i. Update ACCUM_VALUE=ACCUM VALUE + \[response--complexity(reward) * sub-goal(reward)\]i i .
If ACCUM VALUE crosses above an expertise level threshold, upgrade accumulated expertiseleveliii.
If the goal node is the final node, exit.
Otherwise, continue to the next node.b.
If the confirmation isnegativei.
If current local expertise l vel is greater than novice, temporarily reduce local expertise level; elsesuspend system at current state (so that the user can take his own time in understand/rig theinstruction or seek outside help).i i .
Update ACCUM_VALUE= ACCUM VALUE - \[response.complexity(punishment) * sub-goal(punishmen0\].iii.
If ACCCUIvLVALUE crosses below a level threshold, reduce accumulated experience l vel.iv.
Record the current node and the current pathv.
Make current node as the goal node; Go to step 2.
Repeat until all sub-goal nodes of this goal nodeare understood.6) Re-initialize local expertise level to current value of accumulated expertise level.
Restore path to value stored in step5.b.iv.
Go to step 2.
Reset he start node.
Continue till the final goal is reached.
(A timer that is running on a separate hread also modifies the ACCUM_VALUE variable.
On occurrence ofa tirneout, hefollowing steps are followed:If the time spent is less than the best-case timeACCUM._VALUE=ACCUM_.VALUE + \[response-complexity(reward) * sub-goal(best-case timeout reward)\].Go to step 5.a.ii.If the time spent is more than the worst-case timeACCUM_VALUE=ACCUM_VALUE - \[response-complexity(punishment) * sub-goal(worst.ease timeoutpunishrnent)l.Go to step 5.b.iii.
)Figure 3.
Algorithm994 An example  of  interactionA scenario appl icat ion for the system using theprob lem tree o f  F igure 2 is g iven in F igure 4.This set o f  interactions is between the systemand a user  who is trying to adjust the displaysettings o f  his monitor.1.
System: Hi, how may I help you?2.
User: I need to adjust the desktop resolution of my monitor> Initial accumulated expertise l vel detected - ExpertGoal node-Desktop Setting (as it deals with adjusting the resolution)Shortest part is nodes 1-2-6.7 (assuming that it has the maximum path utility value).Nodes 6,7 (40% rounded to nearest whole number) are selected to generate r sponse.> Response generated with instruction corresponding to multiple sub-goals on the solution path.3.
System: Yon can do that by adjusting the desktop area in the desktop settings section of the displayproperties window.4.
User: Where is desktop setting window?Temporarily decreasing local expertise l vel to Moderate.ACCUM VALUE=ACCUlVLVALUE- \[response-complexity (punishment) * Desktop-Setting(punishment)\]} Shortest path to Desktop Setting recalculated as 8-5-6-7 (assuming that it has the average pathutility value).Nodes 5,6,7 (70% rounded to nearest whole number) are selected to generate r sponse.Response generated with single instruction corresponding to one sub-goal.5.
System: First, go to the Control Panel window....worst-case timeout occurred ....> Temporarily decrease local expertise level to Novice.> ACCUIVLVALUE=AC CU/VLVALUE \[response-complexity(punishment) * control-panel(worst-case timeout punishment)\]> ACCUM_VALUE falls below EXPERTLEVEL Make accumulated experience l vel moderate.> Shortest path to Control Panel recalculated as nodes 3-.4-5 (assuming it has the minimum pathutility value).> All nodes used to generate r sponse.Response generated with single instruction corresponding to one sub-goal.6.
System: 1.
Click on "Start" icon on lower left corner of your screen.7.
User: Ok> ACCUM VALUE = ACCUM LEVEL + \[response-eomplexity (reward), Start(reward)\]8.
System: 2.
Click on "Settings" label.9.
User: Ok> ACCUM_VALUE=ACCUM_LEVEL + \[response-complexity(reward), Settings(reward)\]10.
System: 3.
Click on "Control Panel" label.> No change in ACCUM VALUE as user has been punished earlier at this step.local experience l vel goes back to moderate.
Path reset o 8-5-6-7 selected in step 4.11.
System: Now click on the DLsplay Properties window.12.
User: OKNo change in ACCUlVLVALUE as user has been punished earlier at this step.13.
System: Select "Desktop settings" in this window.14.
User: OkNo change in ACCUM_VALUE as user has been punished earlier at this step.15.
System: Finally, adjust "display area" by moving the slide-bar.16.
User: Ok.
Thank yonNo change in ACC"UM_VALUE as user has been punished earlier at this step.Profile of user stored.Figure 4.
An example100Notice that after step 9, the user level remainsat moderate and does not return to expert.This is because adecrease in accumulated userexpertise level has taken place in step 5.
Also,the style of the dialog is different at each levelaccording to the expertise level of the user atthat time.ConclusionThis paper describes hypotheses, strategiesand a methodology in building a dialog systemthat adapts itself to the evolving level of userexpertise.
Furthermore, the system allowsautomated sub-goal utility adjusmaent basedon history of interactions with groups of users.We have implemented the algorithm describedin this paper on a prototype system where theutility metrics have been initialized manuallyby a help-desk expert, based on hisexperiences of interaction with users.
We arecurrently working on evaluation of hypothesesand the system.This work is still in its early stage.
Our futurework includes conducting evaluation of thehypotheses and the system and investigatingmachine learning techniques for improvingutility adjustments.AcknowledgementThis work was a summer project while thefirst author was doing his summer internship atthe Conversational Machines Group at IBM T.J. Watson Research Center.
We would like tothank all members in Conversational MachinesGroup for their discussions and support.ReferencesCarl Andersen, David Traum, K. Purang DarsanaPurushothaman, Don Perlis (1999) MixedInitiative Dialogue and Intelligence via ActiveLogic.
In proceedings of the AAAI99 Workshopon Mixed-Initiative Intelligence, pp.
60-67.Anthony Jameson, Ralph Sch~fer, Thomas Weis,Andr6 Berthold and Thomas Weyrath (1999)MaMng Systems Sensitive to the User ~ Time andWorking Memory Constraints, Intelligent UserInterfaces.Kristiina Jokinen (2000) Learning Dialog System.LREC 2000 Second International Conference onLanguage Resources and Evaluation, Athens,Greece.Neal Lesh, Charles Rich, Candace Sidner (1997)Using plan recognition in human-computercollaboration.
In 7tn International Conf.
On UserModeling, Banff, Canada.Diane J. Litman, Shirnei Pan, Marilyn A Walker,(1998) Evaluating Response Strategies in aWeb-Based Spoken Dialogue Agent.
InProceedings of the 36 th Annual Meeting of theAssociation for Computational Linguistics andthe 17th International Conference onComputational Linguistics (COLING-ACL'98),Montreal, Canada, pp.
780-786.Diane J. Litrnan, Shimei Pan (1999) EmpiricallyEvaluating an Adaptable Spoken DialogueSystem.
In Proceedings of the 7th InternationalConference on User Modeling (UM), Banff,Canada, pp.
55-64.Andros Stolcke, Elizabeth Shriberg, Rebecca Bates,Noah Coccaro, Daniel Jurafsky, RachelMartin, Marie Meteer, Klaus Ries, Paul Taylor,Carol Van Ess-Dykerna (1998) Dialog actmodeling for conversational speech.
In Chu-Carroll J., and Green N., (Eds), ApplyingMachine Learning to Discourse Processing.Papers fi'om the 1998 AAAI Spring Symposium.Stanford, CA.Marilyn Walker, Jeanne Fromer, ShrikanthNarayanan (1998) Learning Optimal DialogStrategies: A Case Study of a Spoken DialogAgent for EmaiL In Proceedings of COLING-ACL'98, University of Montreal, Canada.Thomas Weis (1997) Resource-Adaptive ActionPlanning in a Dialogue System for RepairSupport, KI.Robert L Winlder (1972) Introduction to BayesianInference and Decision.
Holt, Rinehart andWinston Inc.101
