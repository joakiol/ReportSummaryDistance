A Case Study of Natural Language Customisation:The Practical Effects of World KnowledgeMaxilyn A. Walker Andrew L. Nelson Phil Stentonl yn@l inc .c i s .upenn.edu a ln@hplb .hp l .hp .eom sps@hplb .hp l .hp .comUn ivers i ty  of Pennsy lvan iaComputer  Sc ience Dept .200 S. 33rd  St.Ph i lade lph ia ,  PA  19104Hewlet t  Packard  Laborator iesPersona l  Sys tems LabF i l ton  Rd .
,  S toke  Gi f fordBr isto l ,  BS12 6QZ,  U .K .AbstractThis paper proposes a methodology for the eustomisa-tion of natural language interfaces to information re-trieval applications.
We report a field study in whichwe tested this methodology by customising a com-mercially available natural anguage system to a largedatabase of sales and marketing information.
We notethat it was difficult to tailor the common sense reason-ing capabilities of the particular system we used to ourapplication.
This study validates aspects of the sug-gested methodology as well as providing insights thatshould inform the design of natural auguage systemsfor this class of applications.1 Introduct ionIt is commonly accepted that we unders tand discourseso wel l  because we know so rauch\[5\].
Hobbs identifiestwo central research problems in understanding howpeople interpret discourse.
We must characterise: (1)the knowledge that people have, and (2) the processesthey use to deploy that knowledge.
This includes peci-fying and constraining the inferential and retrieval pro-cesses that operate on what is known\[7\].
This problemis of practical interest for the design of various typesof natural anguage interfaces (NLI's) that make use ofdifferent knowledge sources.The knowledge used by an NLI is often split intotwo types.
DOMAIN-INDEPENDENT knowledge consistsof grammatical rules and lexical definitions.
It also in-cludes knowledge used for common-sense r asoning\[6\].DOMAIN-DEPENDENT knowledge centres on modelingprocesses unique to the application task, or the partic-ular relations in the application database.
The processof customising an NLI consists in adding the domain-dependent knowledge abont a particular application tothe domain-independent k owledge that comes withthe NLI\[4\].
Very little has been written about howthis eustomisation is done.This paper results from a particular customisationeffort in which we took a commercially available NLIand attempted to customise it to a large sales and mar-keting information database installed at a customersite.
The application wa.s information retrieval for de-cision support.
We suggest a particular method tobe used in the customisation process and evaluate thesuccess of this method.
We note a number of prob-lems with using the domain independent knowledgeprovided with the NLI for our particular application.We a l~ note eases where the inferential processes sup-ported by the NLI do not appear to be appropriatelyconstrained.
The application of this method leads tosome general results about the process of customisa-tion, as well as .some specific insights regarding thistype of application and the evaluation of an NLI.
Sec-tion 2 describes the particular NLI and the application.Sections 3, 4, 5, 6 and 7 describe the methodology thatwe applied in our customisation effort.
Section 8 de-scribes the results of testing the customisation.
Fi-nally, Section 9 provides uggestions for customisers ordesigners of NLI's.2 NLI and Sales Appl icat ionThe database was a large and complex on-line salesdatabase, containing information about orders, deliv-eries, brands, customer preferences, ales territories,promotions and competitors.
There were 20-30 differ-ent types of records with over 200 views ranging overdata summaries of 2-3 years.Our user group consisted of 50 managers, composedof accounts, brands, commercial and marketing man-agers, each with different data requirements.
Theyfit the user profile recommended for NLI's\[8\].
Theywere relatively infrequent computer users, who wereexperts in the domain with at least one year's experi-ence.
None knew anything about database languages.Some of them had used a previously installed NLI, In-tellect, as well as a menu-based interface that accessedAcrEs DE COLING-92, NANTES, 23-28 AOt~n" 1992 8 2 0 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992tile name set of data 1.
They required ad hoe access toinformation that was difficult to support with standardreports.The NLI we worked with was considered state of theart.
It appeared to use a pipeline architecture con-sisting of morphological nalysis, parser, semantic ill-terpretation, and database query translator.
The se-mantic representation language was a hybrid of a se-mantic network and first order predicate logic, whichsupported time dependent facts, qnantified statements,tense information and general sets\[3\].
In addition, thisNLI included a Generator that produced English fromttle semantic representation language, a Deductive Systern that reasoned about statements in the represen-tation language using forward and backward chain-ing, and which handled quantification, time dependentfacts and truth maintenance.
Aruoug the knowledgesources that came with the NLI was a Dictionary of10000 initial English words, and a set of Concepts thatprovided internal notions of predicates, and set andmembership hierarchies.The semantic representation, concepts, and dictio-nary modules upported both intensional and exten-sional representation f data.
In addition, users couldadd both new concepts and inference rules to tile systern with simple declarative sentences.3 MethodInformation sources for the customisation inchlded:the customisation manual, database scheina, NL tran-scripts of users accessing tile data in the database usingthe previous NLI, Intellect, and a test.
suite of Englishsentences\[2\].Our customisation metltod had four parts:1.
NL transcript analysis2.
Mapping NL terms onto all l';ntity-lLelation (FLR)diagram3.
Constructing the customisation files4.
Gencrating a test suite and testing the eustomisa-tionWe restricted our efforts to implementing and testingcoverage of a sub-part of the domain identified as im-portant hrough analysis of the NL transcripts, namelythe deliveries subdomain 2.
The important concepts arelisted below and highlighted iu Figure 1.?
'Fhe Product Hierarchy : Markets, Sectors,Brands, etc.?
The Customer IIierarchy : Corporations, TradingCompanies, ConcernsI In \[9\] we colnpalre tile menu system to Intellect.2T|te customislng team comprised two computational fin-gulsts, a computer scientiat aald two psychologists.o The Time llierarchy: Years, Book Months, BookWeeks?
l)eliveric~: of Products to Cnstomers over TimePRODUCTHIERARC~dYIIIERARCIIY I IIILRARf21Y ?I I f -1I ....... 1 I 3 \ [  ...... \] IIOOK MOral 1 COMPANY UNIT TYPIT.~__L  .
.
.
.
_A  L___CONI'IARN BOOKWIZEK UN\]DELIVERY yFigure 1: Simplified model of tile Sales domainThe following sections will discuss each aspect of theeustomisation procedure and the issues raised by eachstep of the method.4 Analysing the transcriptsThe N b transcripts consisted of every interaction withtile previuus NLI, Intellect, over a period of a year,by our user group, ascessing our target databasc.
Adetailed accotm t of the transcrillt analysis can be foumlill \[9\].
llerc we focus on how the results atfected tilerest of the procedure.The transcripts showed that tile most important setof user queries were those about deliveries of the differ-ent levels of the t)roduct hierarchy to the different levelsof the customer hierarchy.
The transcripts also showedthat over 30% of user errors were synouym errors orresulted from the use of term:~ to refer to concepts thatwere calculable from in~brmation i the database.
Wecollected a list of all the unknown word errors fromthe Intellect installation.
For example using the termwholesalers resulted ill an Intellect error, but it refersto a subset of trading companies with trade category ofWSL.
We didn't feel that the syntax of the transcriptswas important since it reflected a degree of accommo-dation to Intellect, but the Intellect lexicon and theunknown word errors gave us a good basis for the re-quired lexical and conceptual coverage.
In the absenceof such information, a method to acqnire it, such asWizard of Oz studies, would be necessary\[10, \].ACRES DE COLING-92, NANTES, 23-28 AO(rl 1992 8 2 1 I)ROC.
OF COLING-92, NANI'ES, AUO.
23-28, 19925 Mapp ing  NL terms onto  anE -R  diagramThe steps we applied in this part of the proposedmethod are: (1) take the E-R d iagram provided by thedatabase designer at tim customer site as a conceptualrepresentation of the domain, (2) associate ach lexicali tem from the transcript analysis with either an entityor a relation, (3) Refine and expand the E-R d iagrama~s neee.qsary.We started with a list of lexical i tems e.g.
mar-kets, sectors, brands, deliver, pack size, date, corporate,trading concern, customer location, that were part ofthe Intellect lexicon or had appeared in the transcriptsas unknown words.
By placing these lexical i tems onthe 1~1~.
d iagram we were able to sketch out tim map-ping between user terms and database concepts beforccormnitt ing anyth ing to the customisation files s. How-ew;r, we found mapping vocabnlary onto the E-R dia-gram to be rnore difficult than we had anticipated.First, a nmnber  of words were ambiguous in thatthey could go in two different places on the E-R dia-gram, atul thus apparently refer to mult iple concepts inthe domain.
Th is  was most clearly demonstrated withcertain generic terms such as customer.
Customer canbe used to refer to a relation at any level of the cuS-tomer hierarchy, the conceru, the trading company orthe corporation.
It can also be associated with the at-tr ibute of the customer reference number which is a keyvalue in the 'Concern'  database relation.Second, some words were based on relationships be-tween two entities, so they could have gone in twoplaces.
For instance market share is calculated frona in-formation associated with both the market entity andwith the trade sector entity.
Similarly, the term deity.cry refers to a relation between any level of the producthierarchy and any level of the customer hierarchy.
Yetthere was no entity that corresponded to a delivery,even though it was one of the main concepts in thedomain.In both of these cases we created new entities to referto concepts uch as delivery and market share.
We werethen able to indicate links between these concepts andother related concepts ill the domain and could anno-tate these concepts with the relevant vocabulary items.In some cases it was difficult to determine whether aterm should be a new entity.
For instance the termwholesalers refers to members  of the trading companyentity with a part icular value in the trade category at-tribute.
However since trade category is not used inany other relation, it doesn't  have a separate entityof its own.
In this case we left wholesaler as a termassociated with trading company.Third,  in our lexicon there were operators or predi-3 In a perfect world, the NLI would target an ,E~R diagram andthe snapping front the E~R diagram to the database would be aaindependent aspect of the semantic modelling of the domain.cators such as less than, greater than, equal to, at least,change, decrease, latest estimate, over time, chart,graph, pie, during, without, across, display, earliest,available.
These operators were domain independentoperators; some of them were synonyms for functionsthat the system did support.
Since these seem to beconcepts perhaps related to the task, but not specificto the domain, for convenience we created a pseudo en-t i ty on the E-R d iagram having to do with output  anddisplay concepts such as graphing,  ranking, displayinginformation as a percentage tc.Finally, there were also terms for which there was nodatabase information such as ingredients and journey,ambiguous terms such as take, get, accept, use, as wellas terms that were about the database itself, such asdatabase, information.
For other terms such as earliestor available it was difficult to determine what  domainconcepts they should be associated with.t iowever, the benefits of this method were that oncewe had made the extensions to the E-R d iagram, thenall synonyms were clearly associated with the entitiesthey referred to, words that could ambiguously refer tomultiple concepts were obvious, and words for which acalculation had to be specified were apparent.
We werealso able to identify which concepts users had tried toaccess whiclt were not present in the domain.
Oncethis was done the cnstomisat ion files were built incre-mental ly over the restricted domain.6 Const ruct ing  the customisa-t ion filesThe input to this part of the process was the annotatedF~R d iagram as well as the test suite.
We chose not touse the menu system customisat ion tool that  was partof the NLI 4.
We preferred to use an interface in whichdeclarative forms are specified in a file.As we developed the customisat ion file incremental lyover the domain,  we ensured that all the synonyms fora concept were specific(I, and thoroughly tested thesystem with each addition.
Th is  section discusses con-struct ing the customisat ion file.
In section 7, we dis-cuss the test suite itself.
The results are discussed insection 8.6 .1  Grammat ica l  and  Conceptua l  In -fo rmat ionThe custvmiser 's  job is to link domain dependentknowledge about the application to domain indepen-dent knowledge about language and the world.
Con-s t rut t ing a customisation file consisted of specifyinga number of forms that  would allow the NL1 to pro-tThe menu system was very large mad unwieldy with manylevels, too many choices at each level, and a lack of clarity ~boutthe ramifications of the choices.AcrEs D~ COLING-92, NArrrES, 23-28 ^ o~t' 1992 8 2 2 Paoc.
OF COL1NG-92, NANTES.
AUG. 23-28.
1992ducea  mapping between English words, database re-lations, attr ibutes and values, and concepts used illcommon sense reasoning by tile deductive conrponentof the NIA.A database relation, such as 'Deliveries', could \[lavenouns or verbs a~sociated with it, e.g.
delivery or de-liver.
In tile case of verbs, mappings are specified toindicate which attr ibutes correspond to each argumentslot of the verb.In either case, both relation and attr ibute mappings,give one an opportunity to state that the relation orthe attr ibute is a particular type of entity.
This typeinformation means that each concept ha_q type pref-erences associated with its arguments.
Tile NLI pro~vided types such as person,  o rga l l i sa t ion ,  locat ion ,manu:factured object~ category, transact ion,  dateor t ime durat ion .
The specification of these typessupplies background information to support various in-ferential processes.
There are three types of inferencethat will conccrn us here:?
Coercion?
Generalisation and Specification?
Ambiguity rezolutionCOERCIONS depend on tile type information a.?soci-ated with the arguments  to verbs.
For cxanlple, con-sider a verb like supply with arguments upplier andsuppliee.
Let's say that  suppliers are specified to heof type concern,  and suppliees are of type pro jec t .Then the query Who supplied London?
violates a typeprefcrence specified in the customisation file, namelythat suppliee is a project.
A coercion inference cancoerce London, a c i ty ,  to proj ,~ct ,  by using the infer-ence path \ [p ro j sc t  located locat ion  in c i ty \ ] .
Thenthe question can be understood to mean who suppliesprojects which are in London?f3\].GENERAI,ISATION inferences can suppnrt the.
infer-cute that Life is a kind of Cheese given other factssuch as Life is in sector Full feat Soft and Full 1:at Softis a kind of Cheese.
A similar inference is supportedby tile type organ iuat ion  ; if X works for organisationY, and Y is a suborganisation of organisation Z, thenthe NLI is supposed to be able to infer that X worksfor Z.AMBIGUITY resolution consists of iiliing ill under-specified relations.
A cerumen case of unspecified rela-tions are those, that hold between the nouns of nounnoun compounds (n-n-relations).
For example a mo-torola processor is a processor with motorola as tit(:manufacturer.
A deparlmenf monster is a nranager ofdcpartment.
The specification of conceptual types inSimilarly from tile knowledge that an attr ibute is alocat ion ,  the NLI can infer that it can be used as mlanswer to a question about where Something is.6 .2  D i f f i cu l t iesA minor difficulty in developing tile customisation filewas that we identified lexical itenls for which there wasno information in tile databa.se, hi this case we used afacility of tile NLI by which we could associate hdpfitlerror messages with tile use of particnlar lexical items.In eases where the concept could be calculated fromother database informatioir, we were able to use tileNLI to extend the database sehcma and specify tilecalculations that were necdcd in order to support uscr'saccess to these concepts.The more major  difficulty was to determine which ofthe concepts that the NLI knew about, was the typeto use tbr a specific donlain lexical item.
For exam-pie m specifying the 'Marke.ts' database relation, tar-get phrases nrigllt be the chocolate market, the mar-ket chocolate, sales of chocolates, how much chocolateor kinds of chocolate.
One of the types available wascategox'y which seems to be the way tile key market-name is used ill the phrase the chocolate market 5. llow-ever, another el)lion was to create an attr ibute map-ping far marketname.
Attr ibute nlappings can specifythat all attr ibnte type is onc of a different set of typessuch ass  un ique ident i f ie~,  a n~o,  a pay ,  theemployer,  or a ~uperorgan isat ion .
And some ofthese have subtypes, e.g.
name Call he of type proper,classifier, coulmon, lnndel or patternnumber.
So per-haps if one wants to say sales of chocolates then mar-ketname shouhl he a e(unuloti IlaUle.
A sohttion wouldhe to say ntarketname belongs to a number of thesetypes, possibly at tile expense of overgencrating.
Inthe case of this l)articular NLI, a t tempt ing to do thisgellerated warnings.7 Generat ing the test suiteThe tt~t suite of sentenccs w~ constructed by selectingselltene~:s that cover the requircnlcnts identified by ourtranscript analysis from tile published test suite \[2\].We then substituted concepts to reflect our subdomainof sales.
Sentences wcre generalised across hieraretliesin the donm.i~ and with respect to various words tbrrelations in : hierarchy (e.g.
ore in, belong to, contain,have, ore part of, are kind oil.As ~',oon as we I)egan testing our first eustomisationtile mappings, it was immediately obvious that this testsuite r:~:~ inappropriate tor use ill early custnrnisation.This was because it was partit ioned with respect to tile custmrtisation file is intended to support the infer- _ .
.
.
.
.
.
.
.
.
.
.enge of these unspecified n-n-relations.
For example, SThe documentation  a category says that objects "fallthe NIA first interprets these with a generic hove re- iltto" categories.
If C i~ ~ c~.tegory you call ask, "who #ll intoC f" It is uot clear aa tt~ witether thi~ Ilte$1lt that 'i~trketa' wan lation and then at tempts  to use tile conceptual types a category.to infer what relation the user UlUSt have intended.AcrEs DE COLING-92, NANIF.S, 23 28 Ao~r 1992 8 2 3 Ih~oc.
OF COLIN(;-92, NAN1 F.S, AUG. 23-28, 1992syntactic form and not with respect o the boundariesof customisation sub-domains.
This is a common fea-ture of most test suites.
It also contained some querieswhich had too much syntactic omplexity to be of usein identifying separable problems in the customisationfile.We therefore created a smaller set of deliveries testqueries that used only the more simple syntactic formsand which was organised with incremental domain cov-erage.
This was ideal for iterative development of theeustomisation, and enabled us to concentrate on get-ting the basic coverage working first.
Later in the cus-tomisation we used the more complete syntax-basedtest suite to get a more complete picture of the lim-itations of the resulting system with respect to userrequirements.
We will discuss a possible remedy tothe situation of having two distinct test suites in theconclnsion.8 Test ing the customisat ionSome of tile coverage limitations were specific to thisNLI, but there are some general lessons to be learned.Many of the pernicious problems had to do with theNLI's ambitious use of common-sense knowledge.
Thissection briefly discusses some of the limitations in syn-tactic coverage that we detected.
The remainder of thediscussion focusses on the NLI's nse of common sensereasoning.8.1 Testing syntactic overageWhile the syntactic overage of the NLI appeared tobe better tban the Intellect systenr, we were able toidentify some coverage limitations of tire system.NUMERIC QUANTITIES like the number of 'cases ~ de-livered and number of tonnes delivered were difficnltto handle.
We managed to engineer coverage for Howmany queries concerning the nnmber of eases of prod-ucts, hut were unable to get any coverage for How muchqueries concerning number of tonnes.COORDINATION worked for some cases arid not forotbers with no clear dividing line.
Switching the orderof noun conjuncts, e.g~ in List the market and scclor ofLile, could change whetber or not the system was ableto provide a reasonable answer.
Similarly NEGATIONworked in some cases and not in otbers that were min-imally different.
It appeared that the verb and someof its arguments could be negated What was not deliv-ered to Lee's?, while others emdd not, What was notdeliver~ed in Janus771.DISCOURSE related functionality, such ms interpret-ing pronouns arrd the use of ellipsis was also variable atbest, with furtber refinements o previous queries uchms and their sales not properly interpreted.8.2 The effects of world knowledgeA number of problems concerned tile set of predefinedconcepts that came with the NLI, and that that wereused in tile customisation file as types for each lexicalitem and its arguments.
These seemed to be domainindependent concepts, but to our surprise we discov-ered that this representation f common-sense knowl-edge incorporated a particular model of the world.
Forinstance, a lot of support was provided for the conceptsof t ime and time durat?onu, but time was fixed to tirecalendar year.
Our domain had its own notion of timein terms of bookweeks and bookmonths in which weeksdid not run from Sunday to Sunday and months couldconsist of either 4 or 5 weeks.
The English expressionweekly deliveries was based on this and manager's com-missions were calculated over these time durations.\]'here were a number of cases where domain depen-dent knowledge was embedded in the presumably do-main independent conceptual and dictionary structureof the NLI.
For instance how much was hard-wired toreturu an answer in dollars.
The point is not that itdidn't respond in pounds sterling, but rather that ourusers wanted amounts uch as eases, tonnes~ and easeequivalents in response to questions uch as How muchcaviar was delivered to TinyGourmet?Another feature of world knowledge which made cus-tomisation difficult was tbe fact that predefined con-cepts comprise a set of built-in definitions for certainwords.
These definitions were part of tile core lex-icon of 10,000 words provided with the system, butthe custouriser is not given a list of what these wordsare 6.
This causes mysterious conflicts to arise withdomain-specific definitions.
For instance, we had tofirst discover by carefid sleuthing that the system hadits own definitions of consumer, customer, warehouse,sale, and configuralion, and then purge these defini-tions.
It was not pos.sible to determine the effects ofthese purges in terms of other concepts in tile system.hi particular, there were concepts that were not easyto renmve by pnrging lexical definitions uch ms theconcept of TIME mentioned shove.
The ambiguity ofpredefined concepts also arose for certain verbs.
Forexample, the verb to have was pre-defined with specialproperties, but no explicit definition was made avail-able to the customiser.
It was impossible to determinethe effects of nsing it, and yet it seemed unwise to purgeit.Our application had a great need for GENERALISA-TION type inferences due to the product, customer andtime hierarchies ( ee figure 1).
Tbe most common verbwas deliver and this could refer to deliveries of anylevel in the product hierarchy to any level in the cus-tomer hierarchy.
We spent a great deal of time tryingto get this to work properly and were not able to.
Inthe examples below (Q) is the original query, (P) isthe paraphrase provided by the system and (R) is the~Presumably ecause thln in consider proprietary knowledge.ACi-ES oE COL1NG-92, NAN'rI!s, 23-28 AOt~'r 1992 8 2 4 P~oc.
Ot: COLING-92, NANTES, AUG. 23-28, 1992system's response.
In example l the enstomer Lee isat the level of corporation and the query is properlyinterpreted, resulting in a table of product, customer,delivery date, etc.
(1) Q: What are tile sales of Krunehy in Lee?P: List Lee's Krunchy sales.lIowever, in 2 the customer Foodmart is at tile lcvelof trading company and a query with the identical syn-tactic form is interpreted completely differently.
(2) Q: What arc the sales of Kruuchy in Foodmart?P: List the Krunehy in \]?oodmart sales.R: "\[qmrc aren't any brands namell Foodmart.Other problems were not so clearly problems withcommon sense knowledge but rather with inappropri-ately constrained inferential powers.
Some of thesewcrc best identified by examining the paraphrases thatthe generator produced of the semantic interpretationof a user query or statement.
By tile paraphrase pro-vided in (3)P, it appears that the u-n-relation ill reportgroups has I)een interpreted ms have.
(3) Q: What do you know about report groups?t': What do you know about groups that have RF~POR.T?1/o: The database contains no information aboutwhich groups haw~ cnstomers.Then another default inference is made, which con-sists of assuming that an unknown proper noun is oftype customer.
This results in the response given in(3)lL Of course to the user, this response seems to ill-dieate that tile system has not at all understood hisquery.Another example of a non-.fruitful assumption of ahaw: relation for a non-speciticd n-n-relation call beseen in (4)1{.
below.
The NLI lirst expands the properaamc BSL to traded unit type BSI,, thcn apparentlytreats this a~s a noun noun Colupound with all unspec-ified n-n-relation.
This relation is then lilled m withtim have relation which appears ill (4)R.(4) Q: Show the total salem of bsl, bsj and bsr to Lee'sI)LC.1': List tile total sale of traded unit type BSL, thetotal sale of traded unit type BSJ and the totalsales of traded unit type BSR to Lee's PLC.R: Traded unit types don't have traded unit typt~s.Consumer unit types have traded unit types.In exanrple (5), the NLI appears to make au unwar-ranted inference that the number 17 must refer to 17dollars.
It also tills in a null noun, taking the sentenceto actually mean how much N was krunehy sold .... Itreplaces this null noun with tile type traded unit typewhich is given ms a default for how much queries.
(5) Q: how much was kruuchy sold between week 17in 1988 and week 52 in 19887P: ilow much traded unit type that wan sohl tokruuehy costs between 17 and 52 dollars?R: The datab~.se contains no information abouthow expensive traded unit types are.It seems that the semantic information that the sys-tem has, such ,xu knowing that krunchy is a brand andthat sales are of a product to a customer, should letit overcome the slightly nonstandard syntax how muchwas krunchy sold.
Ilowever it apparently pays moreattention to that aspect of the syntax here, while ig-noring the fact that 17 is speeilied to be a designatorof a book week.9 Conc lus ionsThe NI, transcript analysis proved useful to identifythe target cow,rage and to tocns our experiment on apriority part of tile domain.
Ill most cases transcriptinformation will not t)e available and so interview dataor experimental Wizard-of-Oz data\[10\] will have to begenerate d to make explicit the users' models of the do-main.The I'~R model of the domldn was very useful forcarrying out an incremental dcvelopruent of tile cus-tomisation file.
It lets the customiscr know where thereasonable domain boundaries lie, in order that subparts of the customisation call sensibly bc developedand tested in isolation.
In addition the eustomisationwa.u simplified by having the entities and attributes oftile E-I~ model labelled with the domain vocabularyin advance.
Thus the process of associating synonymswith appropriate ustomisation tile relations and at-tributes wa.u straighttbrward.The main linfitation of tile approach seem to be thatE-I~ diagrams are too limited to capture the use of thevocabulary ill the domain.
Wc used an E-R diagrambecause it was the conceptual representation availablefor the domain and because it is the most prevalentsemantic modeling tool used ill databa.sc design.
How-ever, it does not in fact allow one to represent theinformation that one would like to represent for thepurl)oses of linking NL concepts and lexical items tothe domain.
The only semantic information associatedwith relations that is represented in all E-It diagramare whether they are many-to-one or one-to-one.
Theattributes of the entity that participate in the rela-tion arc not indicated specifically.
The representationAcrEs DF, COLINGO2, NANTES.
23-28 AOt~r 1992 8 2 5 Pl~oc:.
OF COL1NG-92, NANTES, AUG. 23-28, 1992should be much richer, possibly incorporating seman-tic concepts uch as whether a relation is transitive, orother concepts uch as that an attribute represents apart of a wtmle.
Of course this is part of what the NLIwas attempting to provide with its concept hierarchyand dictionary of 10000 initial words.But it seemed that one of the main difficulties withthe NLI was in fact exactly in attempting to provide aricher semantic model with common sense informationto support inference.
This is commonly believed to behelpful for the portabil ity of a NL system across a num-ber of domains.
We found it a hindrance mnre than ahelp.
Some predefined concepts had to be purged fromthe lexicon.
Some definitions were difficult to delete orwork around e.g.
time definitions.
The problems weencountered made us wonder whether there is any gen-eral world knowledge or whether it is always flavouredby thc perspective of the knowledge base designers andthe domains they had in mind.The process was not helped by the black box natureof the NL system.
The general problem with black boxsystems is that it is difficult for a cnstomiser to get aninternal model of system.
It would help a great dealif the world model was made available directly to thecustomiser, the semantics of each concept was clearlydefined, and a way to modify rather than purge certainparts of the conceptual structure was made available.The customiser sitould not be left to learn by example.During customisation of the NL system we found ouruser requirements est suite ditficult to use for debug-ging purposes.
The test suite had to be modified to re-flect concepts in the database rather than syntax.
Thisis because customisations must be done incrementallyand tested at each phase.
A solution to this problem isfirst to ensure that the test suite has a number of sen-tences which test only a single syntactic onstruction.Second, store the test suite components in a database.Each component would be retrievable through the se-mantic class it belonged to (i.e Temporal Expression orComplex NP).
In addition each component would beretrievable through the concepts of the E-R diagramthat it accessed.
Then it should be possible to gen-erate test suites that are usable by developers for thepurpose of testing customisation files.
Simple querie~sof the test suite database about a particular conceptwould generate appropriate test sentences whose se-taantic categories and category fillers were limited tothat concept.References\[1\] Ntis Dahlback and Arne Jonsson.
Empirical stud-ies of discourse representations for natural lan-guage interfaces.
In Proc.
4th Conference of theEuropean Chapter of the ACL, Association ofComputational Linguistics, pages 291-298, 1989.\[2\] Daniel Fliekinger, John Nerbonne, Ivan Sag, andThomas Wasow.
Towards evaluation of nip sy~terns, 1987.
Presented to the 25th Annual Meetingof tile Association for Computational Linguistics.\[3\] Jerrold M. Ginsparg.
A robust portable naturalhmguagc data base interface.
In Proc.
1st AppliedAG'L, Association of Computational Linguistics,Santa Monics, Ca., pages 25-30, 1983.\[4\] Barbara J. Grosz.
Team: A transportable naturallanguage interface system.
In Proc.
1st AppliedACL, Association of Computational Linguistics,Santa Monica, Ca., 1983.\[5\] Jerry R. Hobbs.
The logical notation: Ontolog-ical promiscuity, chapter 2 of discourse and in-ference.
Technical report, SRI International, 333Ravenswood Ave., Menlo Park, Ca 94025, 1985.\[6\] Jerry IL Hobbs, Wiltiam Croft, Todd Davies, Dou-glas Edwards, and Kenneth Laws.
The tacituscommonsense knowledge base.
Technical report,SRI International, 333 Ravenswood Ave., MenloPark, Ca 94025, 1987.\[7\] Aravind K. Joshi and Scott Weinstein.
Control ofinference: Role of some aspects of diseourse struc-ture - centering.
In Proc.
International Joint Con-ference on Artificial Intelligence, pages pp.
385-387, 1981.\[8\] S.R.
Petrick.
On natural language based computersystems.
IBM Journal of Research and Develop-ment, pages 314-325, July, 1976.\[9\] Marilyn Walker and Steve Whittaker.
When nat-ural langnage is better than menus: A field study.Technical Report HPL-BRC-TR-89-020, l ip  Lab-oratories, Bristol, England, 1989.\[10\] Steve Whittaker and Phil Stenton.
User stndiesand the design of natural language systems.
InProc.
gth Conference of the European Chapter ofthe A CL, Association of Computational Linguis-tics, pages 116-123, 1989.Acll~S DE COLING-92, NANTES, 23-28 AOt'rf 1992 8 2 6 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992
