Practical Bootstrapping of Morphological AnalyzersKemal Oflazer 1,~1Department ofComputer EngineeringBilkent UniversityBilkent, Ankara, 06533,Turkeyko@cr l ,  nmsu.
eduSergei Nirenburg ~2Computing Research'LaboratoryNew Mexico State UniversityLas Cruces, NM, 88003serge i@cr l ,  nmsu.
eduAbstractThis paper presents a semi-automatic technique fordeveloping broad-coverage finite-state morphologicalanalyzers for any language.
It consists of threecomponents-elicitation of linguistic information fromhumans, a machine learning bootstrapping scheme anda testing environment.
The three components are ap-plied iteratively until a threshold of output quality isattained.
The initial application of this technique isfor morphology of low-density languages in the contextof the Expedition project at NMSU CRL.
This elicit-build-test echnique compiles lexical and inflectionalinformation elicited from a human into a finite statetransducer lexicon and combines this with a sequenceof morphographemic rewrite rules that is induced us-ing transformation-based learning from the elicited ex-amples.
The resulting morphological nalyzer is thentested against a test suite, and any corrections are fedback into the learning procedure that builds an im-proved analyzer.IntroductionThe Expedition project is devoted to fast "ramp-up"of machine translation systems from less studied,so-called "low-density" languages into English.
Oneof the components that must be acquired and builtduring this process is a morphological nalyzer forthe source low-density language.
Since we expectthat the source language informant will not bewell-versed in computational linguistics in generalor in recent approaches to building morphologicalanalyzers (e.g., \[Koskenniemi, 1983\], \[Antworth.
1990\],\[Karttunen et al, 1992\], \[Karttunen, 1994\]) and theoperation of state-of-the-art finite state tools (e.g.,\[Karttunen.
1993\], \[Karttunen a d Beesley, 1992\],\[Karttunen et al, 1996\]) in particular, the generationof the morphological nalyzer component has to beaccomplished almost semi-automatically.
The usermust be guided through a knowledge licitation proce-dure for the knowledge required for the morphologicalanalyzer.
This is accomplished using the elicitationcomponent of Expedition, the Boas system.
As thistask is not easy, we expect that the development ofthe morphological nalyzer will be an iterative process,whereby the human informant will revise and/orrefine the information previously elicited based on thefeedback from a test runs of the nascent analyzer.The work reported in this paper describes the useof machine learning in the process of building and re-fining morphological nalyzers.
The main use of ma-chine learning in our current approach is in the au-tomatic learning of formal rewrite or replace rules formorphographemic changes from the examples, providedby the informant.
This subtask of accounting for suchphenomena is perhaps one of the more complicated as-pects of building an analyzer and by automating it weexpect o gain a certain improvement in productivity.There have been a number of studies on induc-ing morphographemic rules from a list of inflectedwords and a root word list.
Johnson \[1984\] presentsa scheme for inducing phonological rules from surfacedata, mainly in the context of studying certain aspectsof language acquisition.
The premise is that languageshave a finite number of alternations to be handled bymorphographemic rules and a fixed number of contextsin which they appear; so if there is enough data, phono-logical rewrite rules can be generated to account forthe data.
Rules are ordered by some notion of "'surfaci-ness", and at each stage the nmst surfacy rule -- the rulewith the most transparent context is selected.
Goldingand Thompson\[1985\] describe an approach for inducingrules of English word formation from a given corpusof root forms and the corresponding inflected forms.The procedure described there generates a sequence oftransformation rules, l each specifying how to performa particular inflection.More recently, Theron and Cloete \[1997\] have pre-1Not in the sense it is used in transformation-based learn-ing \[Brill, 1995\].14sented a scheme for obtaining two-level morphologyrules from a set of aligned segmented and surface pairs.They use the notion of string edit sequences assum-ing that only insertions and deletions are applied to aroot form to get the inflected form.
They determinethe root form associated with an inflected form (andconsequently the suffixes and prefixes) by exhaustivelymatching against all root words.
The motivation is that"real" suffixes and prefixes will appear often enough inthe corpus of inflected forms, so that, once frequentlyoccurring suffixes and prefixes are identified, one canthen determine the segmentation for a given inflectedword by choosing the segmentation with the most fre-quently occurring affix segments and considering theremainder to be the root.
While this procedure seemsto be reasonable for a small root word list, the potentialfor "noisy" or incorrect alignments i quite high whenthe corpus of inflected forms is large and the proce-dure is not given any prior knowledge of possible seg-mentations.
As a result, selecting the "correct" seg-mentation automatically becomes quite nontrivial.
Anadditional complication is that allomorphs show up asdistinct affixes and their counts in segmentations arenot accumulated, which might lead to actual segmen-tations being missed due to fragmentation.
The ruleinduction is not via a learning scheme: aligned pairsare compressed into a special data structure and traver-sals over this data structure generate morphographemicrules.
Theron and Cloete have experimented with plu-ralization in Afrikaans, and the resulting system hasshown about 94% accuracy on unseen words.Goldsmith \[1998\] has used an unsupervised learningmethod based on the minimum description length prin-ciple to learn the "morphology" of a number of lan-guages.
What is learned is a set of "root" words andaffixes, and common inflectional pattern classes.
Thesystem requires just a corpus of words in a language.
Inthe absence of any root word list to use as a scaffolding,the shortest forms that appear frequently are assumedto be roots, and observed surface forms are then eithergenerated by concatenative affixation of suffixes or byrewrite rules.
2 Since the system has no notion of whatthe roots and their part of speech values really are, andwhat morphological information is encoded by the af-fixes, these need to be retrofitted manually by a human(if one is building a morphological nalyzer) who wouldhave to weed through a large number of noisy rules.
Wefeel that this approach, while quite novel, can be usedto build real-world morphological nalyzers only aftersubstantial modifications are made.ZSome of which may" not make sense, but are necessary-to account for the data: for instance arule like insert a wordfinal y after the root "eas".
is used to generate asy.15This paper is organized as follows: The next sectionvery briefly describes the Boas project of which thiswork is a part.
The subsequent sections describe thedetails of the approach, the morphological nalyzer ar-chitecture, and the induction of morphographemic rulesalong with explanatory examples.
Finally, we providesome conclusions and ideas for future work.The  BOAS Pro jec tBoas \[Nirenburg, 1998, Nirenburg and Raskin, 1998\] isa semi-automatic knowledge licitation system thatguides a team of two people through tile process of de~veloping the static knowledge sources for a moderate-quality, broad-coverage MT system from any "low-density" language into English.
Boas contains knowl-edge about human language and means of realization ofits phenomena in a number of specific languages and is,thus, a kind of a "linguist in the box" that helps non-professional cquirers with the task.
In the spirit of tilegoal-driven, "demand-side" approach to computationalapplications of language processing \[Nirenburg, 1996\],the process of acquiring this knowledge has been splitinto two steps: (i) acquiring the descriptive, declarativeknowledge about a language and, (ii) deriving opera-tional knowledge (content for the processing engines)from this descriptive knowledge.
A typical elicitationinteraction screen of Boas is shown in Figure 1.An important aspect hat we strive to achieve regard-ing these descriptive and operational pieces of informa-tion, be it elicited from human informants or acquiredvia machine learning is that they should be transpar-ent and human readable, and where necessary humanmaintainable and extendable, contrary to opaque anduninterpretable representations acquired by various ta-tistical earning paradigms.Before proceeding any further we would also like tostate the aims and limitations of our approach.
Ourmain goal is to significantly expedite the deveIopmentof a morphological nalyzer.
It is clear that for inflec-tional anguages where ach root word can be associatedwith a finite number of word forms, one can, with a lotof work, generate a list of word forms with associatedmorphological features encoded, and use this as a look-up table to analyze word forms in input texts.
This is,however, something we would like to avoid, as it is timeconsuming, expensive and error-prone.
We would preferattempting tocapture general morphophonological andmorphographemic phenomena, nd lexicon abstractions(say as inflectional paradigms) using an example driventechnique, and essentially reduce the acquisition pro-cess to one of just assigning root or citation forms toone of these lexicon abstractions, with the automaticgeneration process to be described, doing the rest of,.
~ I~; \ [ \ ]  l l lm l  r ~"ii ' ? "
I I II I I'1 II I" I, I ~ ?
~'i-:" ~:I~T~': ,~-~,,~.. ~ ,,,~1~.. ~ .,.~, . "
-n  i r~ "~, ~ .-.- ~ .- : "~ 4-- \],~i!
i~i!
~ ~ ,.
* ,- ,...--i~,"~ i~-": .~;.~ -' " : '~  ,.,,..,.
.
.  "
"  ' .
"~ : . "
,,,?. '
" .'
!i ~= ' ~   :~*, ""?
?
I .t.
",'l" "'" " - ~.'"
"-: .
.
.
.
!..L~ ~ .!
.... ~ .',.~4._~..
: ~:-,'.
'~- I i i .
"."
-.....'..
~-..~.,'~r.
"....,:_ .~'.~.~W**.'~.
';~, '.d.\[..: !
"~'7..
"'.
* ,."
.
.
.
??
i ~.~i; ~~ ~?4~I ?
~- .
.
.
.
.
.
.
.
.
.~  .:,.
.... ,.~.
:.--.
.
.
!
.~~ ?
.
I, -.
,!..~:.-:~," s.-~.I'- -..I: .
:~.~ ,-.:-,~.>-.~.'.
,';,~,,,-,,,F,.~.
';*':3 :" " '" -i ,;'; ..!.lj-.j.~'~.~...,:"?
- i -'~, s i,,.~ .,.i'i : , ,~ : : , : .
.
, '~ '  .~ : " -~  .
,~ ."
,  ".. " , "  .
.
.
.
.
.
.
.
.
.  ""
.~ .
, r ,  ?
.
'~ ~,--I.
'~.~,, ,."
" .'
:" ~ "" ~~i- i "-',-",--, *~-~..- x ,,~..~I ~-.~ ?
, I :lj .~...!
r-, d,~.
'L~,, .~|~ ,"?
?
..... I~,.I~I~!-, ' .
.~,...~I," :~  ,~.~J ,.~ , ~, ~.
.
.
.
.
.
:..:..
!
:.,.~ .
.
.
.
."
j.
.. ::~.d,, .. ....
,,., ("" i "",,i ;~B','.
; ;,',"?
i."
;: .>~ ",'~ ":"::: ".7'I """!""
"~:~:":"" /~\]~, - r "~ i "~ : '~.i~ ~ _ ~ .I ?
.IIIIIFigure 1: .~ sample Boas elicitation screen16the work.
This process will still be imperfect, as we ex-pect human informants to err in making their paradigmabstractions, and overlook details or exceptions.
So, thewhole process will be an iterative one, with convergenceto a wide-coverage analyzer coming slowly at the be-ginning (where morphological phenomena and lexiconabstractions are being defined and tested), but signifi-cantly speeding up once wholesale root form acquisitionstarts.
Since the generation of the operation content(data files to be used by the morphological nalyzer en-gine) from the elicited descriptions, is expected to takea few minutes, feedback on operational performance anbe provided very fast.
There are also ways to utilize apartially acquired morphological nalyzer to aid in theacquisition of open class root or citation forms.Human languages have many diverse morphologicalphenomena and it is not our intent at this point to havea universal architecture that can accommodate any andall phenomena.
Rather, we propose a modular and ex-tensible architecture that can accommodate additionalfunctionality in future incarnations of Boas.
We alsointend to limit the morphological processing to process-ing single tokens and deal with multi-token phenomenasuch as partial or full word reduplications with addi-tional machinery that we do not discuss here.The Elicit-Build-Test ParadigmIn this paper we concentrate on operational content inthe context of building a morphological nalyzer.
Todetermine this content, we integrate the informationprovided by the informant with automatically derivedinformation.
The whole process is an iterative one as il-lustrated in Figure 2, whereby the information elicitedis transformed into operational data required by thegeneric morphological nalyzer engine s and the result-ing analyzer is tested on a test corpus.
4 Any discrep-ancies between the output of the analyzer and the testcorpus are then analyzed and potential sources of er-rors are given as feedback to the elicitation process.Currently, this feedback is limited to morphographemicprocesses.The box in Figure 2 labeled Morphological Ana-lyzer Generation is the main component which takesin the information elicited and generates a seriesof regular expressions for describing the morpholog-ical lexicon and morphographemic rules.
The mor-phographemic rules describing changes in spelling as aresult of affixation operations, are induced from the ex-3We currently use XRCE finite state tools as our targetenvironment \[Karttunen etal., 1996\].4Also independently elicited from either the human in-formant or compiled from any on-line resources for the lan-guage in question.amples provided, by using transformation-based learn-ing \[Brill, 1995, Satta and Henderson, 1997\].
The re-sult is an ordered set of contextual replace oz" rewriterules, much like those used in phonology.
We then useerror-tolerant finite state recognition \[Oflazer, 1996\] toperform "reverse spelling correction" for identifying theerroneous words the finite state analyzer accepts thatare (very) close to the correct words in the test corpusthat it rejects.
The resulting pairs are then aligned, andthe resulting mismatches are identified and logged forfeedback purposes.Morpho log ica l  Ana lyzer  Arch i tec tureWe adopt the general approach advocated by Kart-tunen \[1994\] and build the morphological nalyzer asthe combination of several finite state transducers someof which are constructed directly from the elicited in-formation while others are constructed from the outputof the machine learning stage.
Since the combination ofthe transducers is computed at compile time, there areno run time overheads.
The basic architecture of themorphological nalyzer is depicted in Figure 3.
Thecomponents of this generic architecture are as follows:The analyzer consists of the union of transducers eachof which implements he morphological ealalysis processfor one paradigm.
Each such transducer is the compo-sition of a number of components.
These componentsare (from bottom to top) described below:1.
The bottom component is an ordered sequenceof morphographemic rules that are learned viatransformation-based learning from the examples forthe inflectional paradigm provided by the human in-formant.
The rules are then composed into one finitestate transducer \[Kaplan and Kay, 1994\].2.
The root and morpheme lexicon contains the rootwords and the affixes.
We currently assume thatall affixation is concatenative and that the lexi-con is described by a regular expression of the sort\[ Affixes \]* \[ Roots  \] \[ Suffixes \]*.53.
The morpheme to surfacy \]eature mapping essentiallymaps morphemes to feature names but retains someencoding of the surface morpheme.
Thus, allomorphsthat encode the same feature would be mapped todifferent "surfacy" features.4.
The lexical and surfacy constraints pecify any con-ditions to constrain the possibly overgenerating mor-photactics of the root and morpheme l xicon.
These5%Ve currently assume that we have at most one prefixand at most one suffix, but this is not a fundamental limita-tion.
On the other hand, elicitation of complex morphotac-tics for an agglutinative language like Turkish or Finnish,requires a more sophisticated elicitation machinery.17!..I CorpusCompilationJTestCorpusStart1Human Elicitation Process /../Description f Morphology(paradigms, examples, exceptions, etc.
)1I Morphological Analyzer Generation1I Content for Morphological Analyzer Engine(lexicons, morphographemic rules)1Lrco_o.w.
c.    Erroo J " l (MA Engine, TestEngine) OmissionsFigure 2: The Elicit-Build-Test Paradigm for Bootstrapping a Morphological Analyzerconstraints can be encoded using the root morphemesand the surfacy features generated by the previousmapping.
The use of surfacy features enables refer-ence to zero morphemes which otherwise could nothave been used.
For instance, if in some paradigm acertain prefix does not co-occur with a certain suffix,or always occurs with some other suffix, or if a certainroot/lemma of that paradigm has exceptional behav-ior with respect to one or more of the affixes, or if theallomorph that goes with a certain root depends onthe properties of the root, these are encoded at thislevel as a finite state constraint.The surfacy feature to feature mapping module mapsthe surfacy representation f the affixes to symbolicfeature names; as a result, no surface informationremains except for the lemma or the root word.
Thus,for instance, allomorphs that encode the same featureand map to different surfacy features, now map to thesame feature symbol.The feature constraints specify ant' constraintsamong the symbolic features.
This is an alternativefunctionality to that provided by lexical and surfacyconstraints to constrain morphotactics, but at thislevel one refers to and constrains features as opposedto surfacy features.
This may provide a more natu-ral or convenient abstraction, especially for languageswith long distance morphotactic constraints.These six finite state transducers are composed to yieldthe transducer for the paradigm, and the union ofthe resulting transducers produces one (possibly large)transducer for morphological analysis where surfacestrings applied at the lower side produce all possibleanalyses at the upper side.In fo rmat ion  E l i c i ted  f rom HumanIn formantsThe Boas environment elicits morphological informa-tion by asking the informant a series of questions aboutthe paradigms of inflection.
A paradigm abstracts to-gether lemmas (or root words) that essentially behavethe same with respect to inflection, and captures infor-mation about the morphological features encoded andforms realizing these features, from which additional in-formation can be extracted.
It is assumed that all lem-mas that belong to the same paradigm take the sameset of inflectional affixes.
It is expected that the rootsand/or the affixes may undergo systematic or idiosyn-cratic morphographemic changes.
It is also assumedthat certain lemmas in a given paradigm mat" behavein some exceptional way (for instance, contrary to allother lemmas, a given lemma may not have one of theinflected forms\]) A paradigm description also providesthe full inflectional patterns for one characteristic ordistinguished lemma belonging to the paradigm, andadditional examples for any other lemmas whose inflec-tional forms undergo nonstandard morphographemic18Lemma+.Morpholo~al Fe tmes (e.g,, hapl~+Adj+Super ).
.
-~  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
..i\[ Ftssm~C~s iio t.o .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
~ .
.
- .
.IS~ric?-ti-FeitureMIplPinl \ ] iooIMl~lMmme- ,o -S I Id .
.
l~  F ..... li U ' ' *  U : o t, - - - - - - , - l )  )\[; -; , o , (i .
.
.
.
.
,)J li i .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
?
.. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
-" .,o !TSurface Form (e.g.
bappiest)Figure 3: General Architecture of the Morphological Analyzerchanges.
If necessary, any lexical and feature con-straints can be encoded.
Currently the provisions wehave for such constraints are limited to writing regularexpressions (albeit at a much higher level), but captur-ing such constraints using a more natural anguage (e.g.,\[Ranta, 1998\]) can be stipulated for future versions.Preprocess ing ~'The information elicited from the human informant iscaptured as a text file.
The root word and the in-flection examples for the distinguished lemma are pro-cessed with an alignment algorithm to determine howthe given root word aligns with each inflected form sothat the edit distance is minimum.
Once such align-ments are performed, the segments in the inflected formthat are before and after the root alignment pointsare considered to be the prefixes and suffixes of theparadigm.
These are then associated with the featuresgiven with the inflected form.Let us provide a simple example from a Russian verbinflection paradigm.
The following information aboutthe distinguished lemma in the paradigm is provided: 6ROOT rez Verb LEMMA rezat'FORM rezat' Inf FORM reZ' ImpsgFORM.
reZ'te Imppl FORM reZu PreslsgFORM feZeS Pres2sg FORM reZet Pres3sgFORM reZem Preslpl FORM reZete Pres2p1FORM reZut Pres3pl FORM.
rezali PastPlFORM rezalo PastNsg FORM rezala PastFsgFORM rezal PastMsgThe alignment produces the following suffix feature6Upper case characters and the single quote symbol en-code specific Russian characters.
The transliteration is notconventional.pairs for the suffix lexicon and morpheme to featuremapping transduction:+at'-> +Inf+u -> +Preslsg+em -> +Preslpl+all -> +PastPl+al -> +PastMs E+' -> +Impsg+eS -> +Pres2sg+ete -> +Pres2pl+alo -> +PastNsg+'te -> +Imppl+'et -> +Pres3sg+ut -> +Pres3pl+ala -> +PastFsgWe then produce the following segmentations to beused by the learning stage discussed in the next section.It should be noted we (can) use the lemma form as themorphological stem, so that the analysis we generatewill have the lemma.
Thus, some of the rules learnedlater will need to deal with this.
(rezat'+at', rezat')(rezat'+'te, reZ'te)(rezat'+et, reZet)(rezat'+ete, reZete)(rezat'+ali, rezali)(rezat'+ala, rezala)(rezat '?t, reZ')(rezat'+eS, reZeS)(rezat'+em, reZem)(rezat'+ut, reZut)(rezat'+alo, rezalo)(rezat'+al, rezal)Learn ing  Segmentat ion  andMorphographemic  Ru lesThe lemma and suffix information elicited and ex-tracted as summarized above are used to c~mstructregular expressions for the lexicon component of eachparadigm.
7 The example segmentations like thoseabove are fed into the learning module to induce mor-phographemic rules.~The result of this process is a script for the XRCE finitestate tool xfst.
Large scale lexicons can be more efficientlycompiled ~, the XRCE tool lexc.
We currently do not gen-erate lerc scripts, but it is trivial to do so.19Fiwms 1":o-:" I I " "  !~Transr .
r  .,.d,m ~Figure 4: Transformation-based learning of mor-phographemic rulesGenerat ing  Cand idate  Ru les  f rom ExamplesThe preprocessing stage yields a list of pairs of seg-mented lexical forms, and surface \]orms.
The seg-mented forms have the roots/lemmas and affixes, andthe affix boundaries are marked by the + symbol.
Thislist is then processed by a transformation-based l arn-ing paradigm\[Brill, 1995, Satta and Henderson, 1997\]as illustrated in Figure 4.
The basic idea is that we con-sider the list of segmented words as our input and findtransformation rules (expressed as contextual rewriterules) to incrementally transform it into the list of sur-face forms.
The transformation we choose at every iter-ation is the one that makes the list of segmented formsclosest o the list of surface forms.The first step in the learning process is an initialalignment of pairs using a standard ynamic program-ming scheme.
The only constraints in the alignment arethat a + in the segmented lexical form is always alignedwith an empty string on the surface side (notated by a0), and that a consonant (vowel) on one side is alignedwith a consonant (vowel) or 0 on the other side.
Thealignment is also constrained by the fact that it shouldcorrespond to the minimum edit distance between theoriginal exical and surface forms, s ~,From this point on,we will use a simple example from English to clarify ourpoints.We assume that we have the pairs (un+happy+est,unhappiest) and (shop+ed, shopped) in our examplebase.
We align these and determine the total number of"errors" in the segmented forms that we have to fix tomake all match the corresponding surface forms.
Theinitial alignment produces the aligned pairs:un+happy+es*c shop0+edun0happi0est shopp0edwith a total of 5 errors.
From each segmented pair wegenerate rewrite rules of the sort 9SWe choose one if there are multiple legitimate align-ments.9V~re use  the XRCE Finite State Tools regular expressionsyntax \[Karttunen et al, 1996\].
For the sake of readability.we will ignore the escape symbol (Z) that should precedeany special characters (e.g., +) used in these rules.20u -> 1 \[\] LeftContext _ RightContext ;where u(pper) is a symbol in the segmented form,l(ower) is a symbol in the surface form.
Rules aregenerated only from those aligned symbol pairs whichare different.
LeftContext and RightContext are sim-ple regular expressions describing contexts in the seg-mented side (up to some small length) taking into ac-count also the word boundaries.
For instance, from thefirst aligned-pair example, this procedure would gener-ate rules such as (depending on the amount of left andright context allowed)y -> i \]1 p _ y -> i II p _ ?
ey-> i l l  p_+es  y -> i l l  p_+esty->i l l  p _ + e s t #  y -> i l l  p p_+e? "
i +->01 # u n  _ +->011 #un _ h a p+->011 _ es t?
,+ -> 0 l i  _ e s t # .
.
.+-> 0 I I  ppy  _ e s t #The # symbol denotes a word boundary, to captureany word initial and final phenomena.
The segmenta-tion rules (+ -> 0) require at least some minimal leftor right context (usually longer than the minimal con-text for other rules for more accurate segmentation de-cisions).
We also disallow contexts that consist onlyof a morpheme boundary, as such contexts are usu-ally not informative.
It should also be noted that theseare rules that transform a segmented form into a sur-face form (contrary to what may be expected for anal-ysis.)
This lets us capture situations where multiplesegmented forms may map to the same surface form,which would be the case when the language has mor-phological ambiguity.
Thus, in a reverse look-up a givensurface form may be interpreted in multiple wa~'s if ap-plicable.10Since we have many examples of aligned pairs, it islikely that a given rule will be generated from manypairs.
For instance, if the pairs (stop+ed, stopped)and ( t r ip+ed,  t r ipped)  were also in the list.
the gem-ination rule0 -> p \]l p _ + e d, (along with certainothers) will also be generated from these examples.
Wecount how many times a rule is generated and associatethis number with the rule as its promzse, meaning thatit promises to fix this many "errors" if it is selected toapply to the current list of segmented forms.Genera l i z ing  Rules  If information regardingphoneme/grapheme classes in addition to consonantand vowel classes, such as SIBILANTS = {s,x.z}, LABIAL= {b,m, .
.
.}
HIfiHWOVELS = { u, i .
.
. )
.
etc., it isl?However, the learning procedure may fail to fix all er-rors, if among the examples there are cases where the samesegmented form maps to two different surface forms (gener-ation ambiguity).possible to generate more general rules.
Such rules cancover more cases and the number of rules induced willtypically be smaller and cover more unseen cases.
Forinstance, in addition to arule like 0 -> p II p _ +e, the ruleso -> p II0 -> p I I0 -> p I I0 -> p I ICONSONANTS _ ep _ VOWELSLABIALS  _ eCONSONANTS _ VOWELScan be generated where symbols such as CONSONANTSor LABIALS stand for regular expressions denoting theunion of relevant symbols in the alphabet.
The promisescores of the generalized rules are found by adding thepromise scores of the original rules generating them.
Itshould also be noted that generalization will increasesubstantially the number of candidate rules to be con-sidered during each iteration, but this is hardly a seriousissue, as the number of examples one would have perparadigm would be quite small.
The rules learned inthe process would be the most general set of rules thatdo not conflict with the evidence in the examples.Selecting Rules At each iteration all the rules alongwith their promise scores are generated from the cur-rent state of the example pairs.
The rules generatedare then ranked based on their promise scores with thetop rule having the highest promise.
Among rules withthe same promise score, we rank more general ruleshigher with generality being based on context subsump-tion.
However, all the segmentation rules go to thebottom of the list, though within this group rules arestill ranked based on decreasing promise and contextgenerality.
The reasoning for treating the segmenta-tion rules separately and later in the process, is thataffixation boundaries constitute contexts for any mor-phographemic changes and they should not be elimi-nated if there are any (more) morphographemic phe-nomena to process.Starting with the top ranked rule we test each rule onthe segmented component of the pairs using the finitestate engine, to see how much the segmented forms are?
'fixed".
The first rule that fixes as many "errors" as itpromises to fix, gets selected and is added to the list ofrules generated, in order.
HThe complete procedure for rule learning can now begiven as follows:- Al ign surface and segmented forms;- Compute total Error;- uhile(Error > O) {-Generate all possible revrite rulesi l Note that a rule may actually clobber other places, sincecontext checking is done only on the segmented form sideand what it delivers ma.v be different han what it promises.as promise scores are also dependent on the surface side.21(subject to context size limits);-Rank Rules ;-while (there are more rules anda rule has not yet been selected) {- Select the next rule;- Tentatively apply rule toall the segmented forms;Re-align the resulting segmentedforms with the correspondingsurface forms to seehow many ''errors'' havebeen f~xed;- If the number fixed is equal towhat the rules promised to fixselect this rule;)-Commit the changes with the changesperformed by the rule andsave alignments;-Reduce Error by the promisescore of the selected rule;)This procedure eventually generates all ordered se-quence of two groups of rewrite rules.
The first group ofrules are for any morphographemic phenomena in thegiven set of examples, and the second group of ruleshandle segmentation.
All these rules are composed inthe order generated to construct he MorphographemicRules transducer at the bottom of each paradigm (seeFigure 3).Ident i fy ing  Er rors  and  Prov id ing  FeedbackOnce the MoTThographemic Rules transducers are com-piled and composed with the lexicon transducer that isgenerated automatically fl'om the elicited information,we obtain the analyzer as the union of the individualtransducers for each paradigm.
It is now possible totest this transducer against a test corpus and to see ifthere are any surface forms in the test corpus that arenot recognized by the generated analyzer.
Our inten-tion is to identify and provide feedback about any minorproblems that are due to a lack of examples that covercertain morphographemic phenomena, or to an error inassociating a given lemma with a paradigm.Our approach ere is as follows: we use the result-ing morphological nalyzer with an error-tolerant finitestate recognizer engine \[Oflazer.
1996\].
For any (cor-rect) word in the test corpus that is not recognizedwe try to find words recognized by the analyzer thatare (very) close to the rejected word.
by error-tolerantrecognition, performing essentially a reverse spellingcorrection.
If the rejection is due a snmll number (1or 2) of errors, the erroneous words recognized by therecognizer are aligned with the corresponding correctwords from the test corpus.
These aligned pairs canthen be analyzed to see what the problems may be.An  ExampleThe examples generated from the above Russianparadigm will induce the following rules coded usingXRCE notation and composed with .
o. operator.
(\[..\]indicates empty string.
): 12\[t -> \ [ .
.1  II _ ' + \] .o.Ca-> C .
.
\ ]  I I  _ " + \] .o .\ [ z -> \ [ .
.
\ ]  I I  _ ' + \] .o .\ [ '  ->  z I I  _+a\ ]  .o .\ [ '  -> Z I I  _ + e \] .o .\[' -> Z II + u \] .o.\[' -> \ [ .
.
\ ]  ~1 _ + ' \] .o.\ [ .
.
\ ]  -> Z 11 + ' \] .o .\[' -> \[..\] II 7- + _ e \] .o.\ [+-> \ [ .
.
\ ]  I I  _ ' # \] .o .\[+ -> \ [ .
.
\ ]  I I  _ u # \] .o .\[+ -> \ [ .
.
\ ]  I I  _ e S # \] .o .\ [+ -> \ [ .
.
\ ]  I I  _ a 1 # \] .o .\ [+-> \ [ .
.
\ ]  I I  _ e ra# \] .o .\[+ -> \ [ .
.
\ ]  I I  _ e t # \] .o .\ [+ -> \ [ .
.3  I I  _ u t # \] .o .C+ -> \ [ .
.
\ ]  I I  _ a t ' # \] .
o .\[+ -> \ [ .
.
\ ]  I I  _ ' t e # \] .o .\[+ -> \ [ .
.
\ ]  I I  _ a 1 a # \] .o .\[+ -> \ [ .
.
\ ]  I I  _ a 1 i # \] .o .\[+ -> \ [ .
.
\ ]  I I  _ a 1 o # \] .o .\ [+-> \ [ .
?
\] I I  _ e t e # \]Note that since we require that the analyses containthe verbal lemmas, a number of rules deal with thelemma marker +at ' .
These rules when composed withtile lexicon, will.
for example, outputrezat'+Verb Par2 +Impsgin response to input reZu.
Now, pisat' is a verbthat was included in this paradigm, and running thecorpus containing inflected forms of pisat' throughthe error-tolerant analyzer and subsequent alignmentwould raise the following flags (among others):Morp.-> pisZut pisZete pisZte piszali piszaloFile -> piSOut piSOete piSOte pisOali pisOalowhich indicate a consistent problem due either to awrong paradigm selection for this verb or the lack ofexamples that would describe the s --~ S alternation.Since only examples from one verb were given, some ofthe rules were specialized to fixing the phenomena inthose examples, which explains the spurious z/Z in theinflected forms of p i sa t ' .
Adding such examples forthe verb to the example base or defining anew paradigmfor this other verb in the next round solves these prob-lems.t~This example does not involve rule generalization.22Performance Issues The process of generating amorphological nalyzer once the descriptive data isgiven, is very fast.
Each paradigm can be processedwithin seconds on a fast workstation, including the fewdozens of iterations of rule learning from the examples.A new version of the analyzer ca,, be generated withinminutes and tested very rapidly on any test data.
Thus,none of the processes described in this paper constitutesa bottleneck in the elicitation process.Summary  and  Conc lus ionsWe have presented the highlights of our approach forautomatically generating finite state morphological n-alyzers from information elicited from human infor-mants.
Our approach uses transformation-based learn-ing to induce morphographemic rules from examplesand combines these rules with the lexicon informationelicited to compile the morphological nalyzer.
Thereare other opportunities for using machine learning inthis process.
For instance, one of the important issuesin wholesale acquisition of open class items is that of de-termining which paradigm a given lemma or root wordbelongs to.
From the examples given during the acqui-sition phase it is possible to induce a classifier that canperform this selection to aid the informant.We believe that this approach to machine learning ofa natural language processor that involves a 1/uman in-formant in an elicit-generate-test loop and uses scaffold-ing provided by the human informant in machine learn-ing, is a very viable approach that avoids the noise andopaqueness of other induction schemes.
Our currentwork involves using similar principles to induce (light)syntactic parsers in the Boas framework.AcknowledgementsThis research was supported ill part by ContractMDA904-97-C-3976 from the US Department of De-fense.
We also thank XRCE for providing the finitestate tools.Re ferences\[Antworth, 1990\] Evan L. Antworth.
PC-KIMMO: Atwo-level processor for Morphological Analysis.
Sum-mer Institute of Linguistics, Dallas, Texas, 1990.\[Brill, 1995\] Eric Brill.
Transformation-based error-driven learning and natural anguage processing: Acase study in part-of-speech tagging.
ComputationalLinguistics, 21(4):543-566, December 1995.\[Golding and Thompson, 1985\] Andrew Golding andHenry S. Thompson.
A morphology component forlanguage programs.
Linguistics.
23.
1985.\[Goldsmith.
1998\] John Goldsnfith.
Unsupervisedlearning of the morphology of a natural lan-guage.
Unpublished Manuscript, available atht tp : / /humani t ies  .uchicago.
edu\] facu l ty /gold-~mith/index, html, 1998.\[Johnson, 1984\] Mark Johnson.
A discovery proce-dure for certain phonological rules.
In Proceedingso\[ lOth International Conference on ComputationalLinguistics-COLING'84, 1984.\[Kaplan and Kay, 1994\] Ronald M. Kaplan and MartinKay.
Regular models of phonological rule systems.Computational Linguistics, 20(3):331-378, Septem-ber 1994.\[Karttunen and Beesley, 1992\] Lauri Karttunen andKenneth.
R. Beesley.
Two-level rule compiler.
Tech-nical Report, XEROX Palo Alto Research Center,1992.\[Karttunen etal., 1992\] Lauri Karttunen, Ronald M.Kaptan, and Annie Zaenen.
Two-level morphologywith composition.
In Proceedings of the 15 th Interna-tional ConJerence on Computational Linguistics, vol-ume 1, pages 141-148, Nantes, France, 1992.
Inter-national Committee on Computational Linguistics.\[Karttunen eta/., 1996\] Lauri Karttunen, Jean-PierreChanod, Gregory Grefenstette, and Anne Schiller.Regular expressions for language ngineering.
Nat-ural Language Engineering, 2(4):305-328, 1996.\[Karttunen, 1993\] Lauri Karttunen.
Finite-state lexi-con compiler.
XEROX, Palo Alto Research Center-Technical Report, April 1993.\[Karttunen, 1994\] Lauri Karttunen.
Constructing lex-ical transducers.
In Proceedings of the 16 th Inter-national Conference on Computational Linguistics,volume 1, pages 406-411, Kyoto, Japan, 1994.
Inter-national Committee on Computational Linguistics.\[Koskenniemi, 1983\] Kimmo Koskenniemi.
Two-levelmorphology: A general computational model forword form recognition and production.
PublicationNo: 11.
Department of General Linguistics, Univer-sity of Helsinki, 1983.\[Nirenburg and Raskin, 1998\] Sergei Nirenburg andVictor Raskin.
Universal grammar and lexis for quickramp-up of MT systems.
In Proceedings of First In-ternational Con\[erence on Language Resources andEvaluation, 1998.\[Nirenburg, 1996\] Sergei Nirenburg.
Supply-side anddemand-side lexical semantics.
In Proceedings of the23Workshop on Breadth and Depth of Semantic Lexi-cons at the 34th Annual Meeting of the Associationfor Computational Linguistics, 1996.\[Nirenburg, 1998\] Sergei Nirenburg.
Project Boas: "ALinguist in a Box" as a multi-purpose language re-source.
In Proceedings of COLING'98, 1998.\[Oflazer, 1996\] Kemal Oflazer.
Error-tolerant finite-state recognition with applications to morphologicalanalysis and spelling correction.
Computational Lin-guistics, 22(1):73-90, March 1996.\[Ranta, 1998\] Aarne Ranta.
A multilingual natural lan-guage interface to regular expressions.
In Lauri Kart-tunen and Kemal Oflazer, editors, Proceedings ofInternational Workshop on Finite State Methods inNatural Language Processing, FSMNLP'98, 1998.\[Satta nd Henderson, 1997\] Giorgio Satta andJolm C. Henderson.
String transformation learning.In Proceedings of ACL/EACL 'gz 1997.\[Theron and Cloete, 1997\] Pieter Theron and IanCloete.
Automatic acquisition of two-level morpho-logical rules.
In Proceedings of 5th Conference onApplied Natural Language Processing, 1997.
