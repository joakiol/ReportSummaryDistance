Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 574?578,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsRefinements to Interactive Translation PredictionBased on Search GraphsPhilipp Koehn?, Chara Tsoukala?and Herve Saint-Amand?Center for Speech and Language Processing, The Johns Hopkins University?School of Informatics, University of Edinburghphi@jhu.edu, ctsoukal@inf.ed.ac.uk, hsamand@inf.ed.ac.ukAbstractWe propose a number of refinements to thecanonical approach to interactive trans-lation prediction.
By more permissivematching criteria, placing emphasis onmatching the last word of the user prefix,and dealing with predictions to partiallytyped words, we observe gains in bothword prediction accuracy (+5.4%) and let-ter prediction accuracy (+9.3%).1 IntroductionAs machine translation enters the workflow ofprofessional translators, the exact nature of thishuman-computer interaction is currently an openchallenge.
Instead of tasking translators to post-edit the output of machine translation systems, amore interactive approach may be more fruitful.One such idea is interactive translation predic-tion (Langlais et al, 2000b): While the user writesthe translation for a sentence, the system makessuggestions for sequent words.
If the user di-verges from the suggestions, the system recalcu-lates its prediction, and offers new suggestions.This input modality is familiar to anybody whohas used auto-complete functions in text editors,cell phones, or web applications.The technical challenge is to come up with amethod that predicts words that the user will ac-cept.
The standard approach to this problem usesthe search graph of the machine translation sys-tem.
Such search graphs may be recomputed in aconstraint decoding process restricted to the par-tial user input (called the prefix), but this is oftentoo slow with big models and limited computingresources, so we use static word graphs.The user prefix is matched against the searchgraph.
If the user prefix cannot be found in thesearch graph, approximate string matching is usedby finding a path with minimal string edit distance,i.e., a path in the graph with the minimal numberof insertions, deletions and substitutions to matchthe user prefix.This paper presents a number of refinementsto extend this approach, by allowing more per-missive matching criterion, placing emphasis onmatching the last word of the user prefix, and deal-ing with predictions to partially typed words.
Weshow improvements in word prediction accuracyfrom 56.1% to 60.5% and letter prediction accu-racy from 75.2% to 84.5% on a publicly availablebenchmark (English-Spanish news translation).2 Related WorkThe interactive machine translation paradigm wasfirst explored in the TransType and TransType2projects (Langlais et al, 2000a; Foster et al,2002; Bender et al, 2005; Barrachina et al, 2009).Given the computational cost and need for quickresponse time, most current word operates onsearch graphs (Och et al, 2003).
Such searchgraphs can be efficiently represented and pro-cessed with finite state tools (Civera et al, 2004).More recently, the approach has been extended toSCFG-based translation models (Gonz?alez-Rubioet al, 2013).There are several ways the sentence completionpredictions can be presented to the user: show-ing the complete sentence prediction, only a fewwords, or multiple choices.
User actions may bealso extended to mouse actions to pinpoint the di-vergence from an acceptable translation (Sanchis-Trilles et al, 2008), or hand-writing (Alabau et al,2011) and speech modalities (Cubel et al, 2009).3 Properties of Core AlgorithmOur implementation of the core algorithm followsclosely Koehn (2009).
It is a dynamic program-ming solution that computes the minimal cost toreach each node in the search graph by matchingparts of the user prefix.
Cost is measured primar-ily in terms of string edit distance (number of dele-tions, insertions and substitutions), and secondaryin terms of translation model score for the matchedpath in the graph.
Search is done iteratively, withan increasing number of allowable edits.574prefixtime5 10 15 20 25 30 35 400ms8ms16ms24ms32ms40ms48ms56ms64ms72ms80ms0 edits1 edit2 edits3 edits4 edits5 edits6 edits7 edits8 editsFigure 1: Average response time of baselinemethod based on length of the prefix and numberof edits: The main bottleneck is the string edit dis-tance between prefix and path.3.1 Experimental SetupGiven the large number of proposed variations ofthe algorithm, we do not carry out user studies, butrather use a simulated setting.
We predict transla-tions that were crafted by manual post-editing ofmachine translation output.
We also use the searchgraphs of the system that produced the originalmachine translation output.Such data has been made available by the CAS-MACAT project1.
In the project?s first field trial2,professional translators corrected machine transla-tions of news stories from a competitive English?Spanish machine translation system (Koehn andHaddow, 2012).
This test set consists of 24,444word predictions and 141,662 letter predictions.3.2 Prediction SpeedSince the interactive translation prediction processis used in an interactive setting where each keystroke of the user may trigger a new request, veryfast response time is needed.
According to stan-dards in usability engineering0.1 second is about the limit for havingthe user feel that the system is reactinginstantaneously (Nielsen, 1993).So, this is the time limit we have to set ourselvesto predict the next words of a translator.What are the main factors that influence pro-cessing time in our core algorithm?
See Figure 1for an illustration.
We plot processing time against1http://www.casmacat.eu/2http://www.casmacat.eu/uploads/Deliverables/d6.1.pdfprefixfailure rate5 10 15 20 25 30 35 400%10%20%30%40%50%60%70%80%90%100%6 edits7 edits9 edits11 edits12 edits13 edits14 edits15 editsFigure 2: Ratio of prefix matching processes aban-doned due to exceeding the 100ms time limit(showing only curves with a minimum of 5 edits).the length of the user prefix and the string edit dis-tance between the user prefix and the search graph.The graph clearly shows that the main slowdownin processing time occurs when the edit rate in-creases.To guarantee a response in 100ms, the algo-rithms aborts when this time is exceeded and re-lies on a prediction based on string edit distanceagainst the best path in the graph.
The larger thenumber of edits, the more often this occurs, as Fig-ure 2 shows.3.3 AccuracyWe are mainly interested in the accuracy of themethod: How often does it predict a word that theuser accepts?
There is a trade-off between speedand accuracy.One way we can balance this trade-off is by re-moving nodes from the search graph.
By thresh-old pruning (Sanchis-Trilles and Ortiz-Mart?
?nez,2014), we remove nodes from the search graphthat are only part of paths that are worse than thebest path by a specified score difference.See Table 1 how the choice of the score differ-ence threshold impacts failure rate and accuracy.A wider threshold has the potential to achieve bet-ter results (if we allows for up to 1 second of pro-cessing time), but with the constraint of 100ms re-sponse time, the optimum is with a threshold of0.4.
Wider thresholds lead to a higher failure rate,causing overall lower accuracy.575Threshold 100ms Max 1000ms MaxAcc.
Fail Acc.
Fail0.3 55.8% 4.5% 56.9% 0.0%0.4 56.1% 6.5% 58.0% 0.0%0.5 55.9% 9.0% 58.8% 0.0%0.6 55.5% 11.6% 59.4% 0.0%0.8 54.4% 17.1% 59.4% 0.0%1.0 52.7% 21.7% 58.6% 6.5%Table 1: Impact of threshold pruning on search ac-curacy and failure rate (i.e., failure to completesearch in given time and resorting to matchingagainst best translation).4 RefinementsWe now introduce a number of refinements overthe core method.
Given the constraints establishedin the previous section (maximum response timeof 100ms, pruning threshold 0.4), we set out toimprove accuracy.4.1 Matching Last WordThe first idea is that it is more important to matchthe last word of the user prefix than having mis-matches in earlier words.
We attempt to find thelast word in the predicted path either before orafter the optimal matching position according tostring edit distance.We combine the matched path in the prefix withthe optimal suffix, and search for the last user pre-fix word within a window.
This means that weeither move words from the suffix to the prefix orthe other way around, without changing the over-all string along the path.Table 2 shows the impact on accuracy for differ-ent window sizes.
While we expected some gainsby checking for the word somewhere around theoptimal position in the predicted path, we do seesignificant gains by not placing any restrictions towhere the word can be found, except for a biasto less distant positions.
For instance, examininga window of up to 3 words gives us a word pre-diction accuracy of 57.2% versus the 56.1% base-line.
Finding the last word anywhere boosts per-formance to 59.1%.The table also reports accuracy numbers whenwe allow the process to run up to 1 second ?which is basically an exhaustive search but notpractically useful.
These numbers shed some lighton why an unlimited window size in matching thelast word helps: the gains come partially from thecases where the initial search fails.
Finding thelast user word anywhere in the machine transla-Window 100ms Max 1000ms Maxbaseline 56.1% 58.0%1 word 56.6% 58.4%2 words 56.9% 58.6%3 words 57.2% 58.9%5 words 57.8% 59.3%anywhere 59.1% 59.5%Table 2: Search for the last prefix word in a win-dow around the predicted position in the matchedpath.Word Matching 100ms Max 1000ms Maxbaseline 59.1% 59.5%case-insensitive 58.7% 59.4%Table 3: Search with case-insensitive word match-ing (say, University and university).tion output is a better fallback than computing op-timal string edit distance.
Analysis of the datasuggests that gains mainly come from large lengthmismatches between user translation and machinetranslation, even in the case of first pass searches.4.2 Case-Insensitive MatchingSome mismatches between words matter less thanothers.
For instance, if the user prefix differs onlyin casing from the machine translation (say, Uni-versity instead of university), then we may stillwant to treat that as a word match in our al-gorithm.
However, as Table 3 shows, allowingcase-insensitive matching leads to lower accuracy(58.7% vs. 59.1%).A major reason is computational cost.
The mostinner loop in the algorithm compares words.
Thisis optimized by representing words as integers.However, if we allow case-insensitive matching,this simple method does not work anymore.
We doprecompute approximate word matches and storematching words identifiers in a hash map, but stillthe ratio of searches that do not complete in 100msincreases from 6.5% to 9.7%.
By extending the al-lowable time to 1 second, the accuracy gap is re-duced to 0.1%.4.3 Approximate Word MatchingWhen a word in the user translation differs froma word in the decoder search graph only by a fewletters, then it should be considered a lesser errorthan substitutions of completely different words.Such word differences may be due to casing, mor-phological variants, or spelling inconsistencies.We compute word dissimilarity by computing576Max.
Dissimilarity 100ms Max.
1000ms Max.baseline 59.1% 59.5%30% 60.2% 61.0%20% 60.4% 61.3%10% 60.6% 61.5%Table 4: Counting substitutions between similarwords as half an error.
Dissimilarity is measuredas letter edit distanceMin Stem / Max Suffix 100ms 1000msbaseline 59.1% 59.5%4 / 3 59.4% 60.1%3 / 3 59.5% 60.2%2 / 3 59.5% 60.3%Table 5: Counting substitutions between morpho-logical variants as half an error.
Morphologicalvariance is approximated by requiring a minimumnumber of initial letters to match and a maximumof final letters to differ.the ratio of letter edit operations to the length ofthe shorter word.3We now set a threshold formaximum dissimilarity, under which mismatchedwords are considered only half the edit cost ofother edit operations.Table 4 shows that we get significantly higherword prediction accuracy than with the baselineapproach (up to 60.6% vs. 59.1%), and the bestperformance with a 10% threshold.
We observethe same computational problem as in the previoussection (about 9.2% first pass failures, vs. 6.5%),reflected in a higher accuracy gap for 100ms and1000ms time limits.4.4 Stemmed MatchingWe suspected that the main benefit of approximateword matching is the better handling of morpho-logical variants.
In Spanish, this mainly consti-tutes itself as different word endings.
Thus, we re-define our word dissimilarity measure by considerwords similar, if they agree in at least a numberof leading letters (presumably the stem), and maydiffer in at most a number of trailing letters (pre-sumably the morpheme).Table 5 shows that this is successful in increas-ing the word prediction rate (59.5% vs. 59.1%)but not as much as with the more general approx-imate word matching in the previous section (re-call: 60.6%).3For instance, if a 6 letter word and a 4 letter word canbe matched with two deletions and one substitution, then thedissimilarity score is34= .75.# Method Word Acc.
Letter Acc.1 baseline 56.0% 75.2%2 1+matching last word 59.0% 80.6%3 2+case insensitive 58.7% 80.4%4 2+dissimilarity 10% 60.5% 80.6%5 2+stem 2/3 59.4% 80.5%6 4+desperate 60.5% 84.5%Table 6: Extending the approach to word com-pletion.
Impact of refinements of letter predictionaccuracy with additional desperate word matchingagainst the entire vocabulary.5 Word CompletionBesides word prediction, word completion is alsoa useful feature in an interactive translation tool.When the machine translation system decides forcollege over university, but the user types the letteru, it should change its prediction.To enable word completion in the canonical al-gorithm, we allow matching of the final user word(if not followed by a space character) as a prefix ofany word as a zero cost operation.
The predictedsuffix that is returned to the user then starts withthe remaining letters of the word in the path.Table 6 shows that the refinements that helpedsentence completion also benefit word comple-tion.
From a baseline accuracy of 75.2% correctlypredicted letters, we reach up to 80.6%.
Note thatthe baseline word prediction accuracy is slightlylower (56.0% vs. 56.1%) than in the previous ex-periments, since the previously correctly matchedlast word may be mistaken as the prefix of anotherword.We add an additional refinement to this task: Ifthe potentially incomplete final word of the userprefix cannot be found in the predicted path, thenwe explore the entire vocabulary from the un-pruned search graph for completions.
If multiplewords match, the one with the highest path scoreis used.
This desperate word completion methodgives significant gains (84.5% over 80.6%).6 Conclusion and Future WorkWe observe most improvements by a focus onthe last word of the user prefix and approximateword matching.
This suggests that there may beadditional gains by a stronger focus on the tailof the user prefix.
Also, the findings from thetime/productivity tradeoffs indicate that more timeefficient algorithms and implementations shouldbe explored.577AcknowledgementsThis work was supported under the CASMACATproject (grant agreement No287576) by theEuropean Union 7thFramework Programme(FP7/2007-2013).ReferencesAlabau, V., Sanchis, A., and Casacuberta, F. (2011).Improving on-line handwritten recognition usingtranslation models in multimodal interactive ma-chine translation.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Lin-guistics: Human Language Techologies, pages 389?394, Portland, Oregon, USA.
Association for Com-putational Linguistics.Barrachina, S., Bender, O., Casacuberta, F., Civera, J.,Cubel, E., Khadivi, S., Lagarda, A., Ney, H., Tom?as,J., Vidal, E., and Vilar, J.-M. (2009).
Statistical ap-proaches to computer-assisted translation.
Compu-tational Linguistics, 35(1).Bender, O., Hasan, S., Vilar, D., Zens, R., and Ney,H.
(2005).
Comparison of generation strategies forinteractive machine translation.
In Proceedings ofthe 10th Conference of the European Association forMachine Translation (EAMT), Budapest.Civera, J., Cubel, E., Lagarda, A. L., Pic?o, D.,Gonz?alez, J., Vidal, E., Casacuberta, F., Vilar, J. M.,and Barrachina, S. (2004).
From machine translationto computer assisted translation using finite-statemodels.
In Lin, D. and Wu, D., editors, Proceedingsof EMNLP 2004, pages 349?356, Barcelona, Spain.Association for Computational Linguistics.Cubel, E., Khadivi, S., Lagarda, A., Ney, H., Toms,J., Vidal, E., and Vilar, J.-M. (2009).
Statistical ap-proaches to computer-assisted translation.
Compu-tational Linguistics, 35(1).Foster, G., Langlais, P., and Lapalme, G. (2002).
User-friendly text prediction for translators.
In Proceed-ings of the Conference on Empirical Methods in Nat-ural Language Processing (EMNLP), pages 148?155, Philadelphia.
Association for ComputationalLinguistics.Gonz?alez-Rubio, J., Ort?
?z-Martinez, D., Bened?
?, J.-M., and Casacuberta, F. (2013).
Interactive ma-chine translation using hierarchical translation mod-els.
In Proceedings of the 2013 Conference on Em-pirical Methods in Natural Language Processing,pages 244?254, Seattle, Washington, USA.
Associ-ation for Computational Linguistics.Koehn, P. (2009).
A process study of computer-aidedtranslation.
Machine Translation, 23(4):241?263.Koehn, P. and Haddow, B.
(2012).
Towards effectiveuse of training data in statistical machine translation.In Proceedings of the Seventh Workshop on Statisti-cal Machine Translation, pages 363?367, Montreal,Canada.
Association for Computational Linguistics.Langlais, P., Foster, G., and Lapalme, G. (2000a).Transtype: a computer-aided translation typing sys-tem.
In Proceedings of the ANLP-NAACL 2000Workshop on Embedded Machine Translation Sys-tems.Langlais, P., Foster, G., and Lapalme, G. (2000b).
Unitcompletion for a computer-aided translation typingsystem.
In Proceedings of Annual Meeting of theNorth American Chapter of the Association of Com-putational Linguistics (NAACL).Nielsen, J.
(1993).
Usability Engineering.
MorganKaufmann.Och, F. J., Zens, R., and Ney, H. (2003).
Efficientsearch for interactive statistical machine translation.In Proceedings of Meeting of the European Chap-ter of the Association of Computational Linguistics(EACL).Sanchis-Trilles, G. and Ortiz-Mart?
?nez, D. (2014).
Ef-ficient wordgraph pruning for interactive translationprediction.
In Annual Conference of the EuropeanAssociation for Machine Translation (EAMT).Sanchis-Trilles, G., Ortiz-Mart?
?nez, D., Civera, J.,Casacuberta, F., Vidal, E., and Hoang, H. (2008).Improving interactive machine translation via mouseactions.
In Proceedings of the 2008 Conference onEmpirical Methods in Natural Language Process-ing, pages 485?494, Honolulu, Hawaii.
Associationfor Computational Linguistics.578
