Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 529?536Manchester, August 2008Linguistically-based sub-sentential alignment for terminology extractionfrom a bilingual automotive corpusLieve Macken and Els Lefever and Veronique HosteLanguage and Translation Technology TeamGhent University CollegeBelgium{Lieve.Macken, Els.Lefever, Veronique.Hoste}@hogent.beAbstractWe present a sub-sentential alignmentsystem that links linguistically motivatedphrases in parallel texts based on lexicalcorrespondences and syntactic similarity.We compare the performance of our sub-sentential alignment system with differentsymmetrization heuristics that combine theGIZA++ alignments of both translation di-rections.
We demonstrate that the alignedlinguistically motivated phrases are a use-ful means to extract bilingual terminologyand more specifically complex multiwordterms.1 IntroductionThis research has been carried out in the frame-work of a customer project for PSA PeugeotCitro?en.
The final goal of the project is a re-duction and terminological unification process ofPSA?s database, which contains all text strings thatare used for compiling user manuals.
French beingthe source language, all French entries have beentranslated to some extent into the twenty differentlanguages that are part of the customer?s portfolio.Two sub-projects have been defined:1. automatic terminology extraction for all lan-guages taking French as the pivot language2.
improved consistency of the database entries,e.g.
through the automatic replacement ofsynonyms by the preferred term (decided in(1))c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.This paper presents a novel terminology extrac-tion method applied to the French-English part ofthe database.There is a long tradition of research intobilingual terminology extraction (Kupiec, 1993),(Gaussier, 1998).
In most systems, candidate termsare first identified in the source language based onpredefined PoS patterns ?
for French, N N, N PrepN, and N Adj are typical patterns.
In a second step,the translation candidates are extracted from thebilingual corpus based on word alignments.
In re-cent work, Itagaki et al (2007) use the phrase tablederived from the GIZA++ alignments to identifythe translations.We use a different and more flexible approach.We developed a sub-sentential alignment systemthat links linguistically motivated phrases in paral-lel texts based on lexical correspondences and syn-tactic similarity.
Rather than predefining terms assequences of PoS patterns, we first generate candi-date terms starting from the aligned phrases.
In asecond step, we use a general purpose corpus andthe n-gram frequency of the automotive corpus todetermine the specificity of the terms.The remainder of this paper is organized as fol-lows: Section 2 describes the corpus.
In Section 3,we present our linguistically-based sub-sententialalignment system and in Section 4 we describehow we use the aligned phrases for terminologyextraction.2 Automotive corpusFor developing our terminology extraction mod-ule, we have used the French-English sentence-aligned database that contains 363,651 entries.These entries can be full sentences, parts of sen-tences, as well as isolated words and are alignedacross languages by means of a unique ID.
The529PoS tagging Lemmatisation PoS after Lemmaserror rate error rate update after updateFrench 4.50 % 2.29 % 1.92 % 1.22 %English 5.16 % 3.13 % 2.66 % 3.03 %Table 1: Part-of-Speech tagging and lemmatisationerror rate on the test sentencesaverage sentence length of a database entry is 9words.2.1 Linguistic annotationIn order to ensure consistent processing of the lan-guages in the corpus (e.g.
Italian, Spanish, Ger-man), we have used the freely availabe TreeTag-ger tool (Schmid, 1994) for performing tokeni-sation, part-of-speech tagging and lemmatisationof the corpus.
In order to evaluate the domain-adaptability of the tagger, we have manually val-idated the quality of the TreeTagger output for atraining set of 12,200 tokens (about 1,200 sen-tences).
We have used this validated set to derivea list of hard coded PoS tags (e.g.
the French wordvis can be a noun or verb, but is always a nounin our corpus) as well as post-processing rulesfor remediating erroneous PoS tags.
We addition-ally annotated 350 test sentences (about 3,500 to-kens).
Table 1 shows the error rate figures for PoS-tagging and lemmatisation before and after updat-ing the default output of the TreeTagger tool.We further enriched the corpora with chunk in-formation.
During text chunking, syntactically re-lated words are combined into non-overlappingchunks based on PoS information.
We devel-oped rule-based chunkers for English and French.The rule-based chunkers contain distituency rules,i.e.
the rules add a chunk boundary when two part-of-speech codes cannot occur in the same con-stituent.
The following example shows a French-English sentence pair divided in non-overlappingchunks:Fr: valable | uniquement | pour la ceinture | des?ecurit?e avant lat?erale | du c?ot?e passagerEn: applies | only | to the outer seat belt | on thepassenger sideWe manually indicated chunk boundaries in the350-sentences test corpus and evaluated the rule-based chunkers by running the CoNLL-evalscript(Tjong Kim Sang and Buchholz, 2000).
We ob-tained precision scores of 89% and 87% and recallscores of 91% and 91% for French and English re-spectively.# Words # Sentence pairsShort (< 8 words) 4,496 404Medium (8-19 words) 4,493 212Long (> 19 words) 4,498 97Total 13,487 713Development corpus 4,423 231Table 2: Number of words and sentence pairs inthe three test corpora and the development corpus2.2 Test corporaAs we expect that sentence length has an impacton the alignment performance, we created threetest corpora with varying sentence length.
We dis-tinguished short sentences (2-7 words), medium-length sentences (8-19 words) and long sentences(> 19 words).
Each test corpus contains approxi-mately 4,500 words.We also compiled a development corpus con-taining sentences of varying sentence length to de-bug the system and to determine the value of thethresholds used in the system.
The formal charac-teristics of the test corpora and the training corpusare given in Table 2.3 Sub-sentential alignmentSub-sentential alignments ?
and the underlyingword alignments ?
are used in the context ofMachine Translation to create phrase tables forphrase-based statistical machine translation sys-tems (Koehn et al, 2007).
A stand-alone sub-sentential alignment module however, is also use-ful for human translators if incorporated in CAT-tools, e.g.
sophisticated bilingual concordance sys-tems, or in sub-sentential translation memory sys-tems (Gotti et al, 2005).
A quite obvious applica-tion of a sub-sentential alignment system is the cre-ation of bilingual dictionaries and terminology ex-traction from bilingual corpora (Melamed, 2000),(Itagaki et al, 2007).In the context of statistical machine translation,GIZA++ is one of the most widely used wordalignment toolkits.
GIZA++ implements the IBMmodels and is used in Moses (Koehn et al, 2007)to generate the initial source-to-target and target-to-source word alignments after which some sym-metrization heuristics combine the alignments ofboth translation directions.We present an alternative ?
linguistically-based?
approach, that starts from a lexical probabilisticbilingual dictionary generated by IBM Model One.5303.1 ArchitectureThe basic idea behind our approach is that ?
at leastfor European languages ?
translations conveyingthe same meaning use to a certain extent the samebuilding blocks from which this meaning is com-posed: i.e.
we assume that to a large extent nounand prepositional phrases, verb phrases and adver-bial phrases in one language directly map to simi-lar constituents in the other language1.
The extentto which our basic assumption holds depends onthe translation strategy that was used.
Text typesthat are typically translated in a more literal way(e.g.
user manuals) will contain more direct corre-spondences.We conceive our sub-sentential aligner as a cas-cade model consisting of two phases.
The objec-tive of the first phase is to link anchor chunks,i.e.
chunks that can be linked with a very high pre-cision.
Those anchor chunks are linked based onlexical clues and syntactic similarity.
In the sec-ond phase, we will try to model the more complextranslational correspondences based on observedtranslation shift patterns.
The anchor chunks of thefirst phase will be used to limit the search space inthe second phase.As the application at hand is terminology ex-traction, we are interested in alignments with veryhigh precision.
As the automotive corpus containsrather literal translations, we expect that a high per-centage of anchor chunks can be retrieved usingonly the first phase of our approach.The sub-sentential alignment system takes asinput sentence-aligned texts, together with addi-tional linguistic annotations (part-of-speech codesand lemmas) for the source and the target text.In the first step of the process, the source andtarget sentences are divided into chunks based onPoS information, and lexical correspondences areretrieved from a bilingual dictionary.
During an-chor chunk alignment, the sub-sentential alignerlinks chunks based on lexical correspondences andchunk similarity.3.2 Bilingual DictionaryWe used the Perl implementation of IBM ModelOne that is part of the Microsoft Bilingual Sen-tence Aligner (Moore, 2002) to derive a bilingualdictionary from a parallel corpus.
IBM Model One1The more syntax-aware SMT systems assume that to acertain extent syntactic relationships in one language directlymap to syntactic relationships in the other, which Hwa (2002)calls the Direct Correspondence Assumption.is a purely lexical model: it only takes into accountword frequencies of source and target sentences2.The IBMmodels allow only 1:n word mappings,and are therefore asymmetric.
To overcome thisproblem, we ran the model in two directions: fromFrench to English and from English to French.
Toget high-accuracy links, only the words pairs oc-curring in both the French-English and English-French word lists were retained, and the probabil-ities were averaged.
To get rid of the noise pro-duced by the translation model, only the entrieswith an averaged value of at least 0.1 were re-tained.
This value was set experimentally3.The resulting bilingual dictionary contains28,990 English-French word pairs.
The bilingualdictionary is used to create the lexical link matrixfor each sentence pair.3.3 Lexical Link MatrixFor each source and target word in each sentencepair, all translations for the word form and thelemma are retrieved from the bilingual dictionary.In the process of building the lexical link ma-trix, function words are neglected.
Given the fre-quency of function words in a sentence, linkingfunction words based on lexical information alone,often results in erroneous alignments.
For thatreason no lexical links are created for the follow-ing word classes: determiners, prepositions, co-ordinating conjunctions, possessive pronouns andpunctuation symbols.For all content words, if a source word occurs inthe set of possible translations of a target word, orif a target word occurs in the set of possible transla-tions of the source words, a lexical link is created.Identical strings in source and target language arealso linked.3.4 Anchor chunksAnchor chunk alignment comprises two steps.
Ina first step, we select candidate anchor chunks; ina second step we test the syntactic similarity of thecandidate anchor chunks.3.4.1 Selecting candidate anchor chunksThe candidate anchor chunks are selected based onthe information available in the lexical link matrix.2The higher numbered IBM Models build on IBM ModelOne and take into account word order (distortion) and modelthe probability that a source word aligns to n target words(fertility).3Lowering this threshold significantly decreased precisionscores of the sub-sentential alignment system.531For each source chunk a candidate target chunk isconstructed.
The candidate target chunk is built byconcatenating all target chunks from a begin indexuntil an end index.
The begin index points to thefirst target chunk with a lexical link to the sourcechunk under consideration.
The end index pointsto the last target chunk with a lexical link to thesource chunk under consideration.
In this way, 1:1and 1:n candidate target chunks are built.The process of selecting candidate chunks as de-scribed above, is performed a second time startingfrom the target sentence.
In this way additional n:1candidates are constructed.3.4.2 Testing chunk similarityFor each selected candidate pair, a similarity testis performed.
Chunks are considered to be similarif at least a certain percentage of words of sourceand target chunk(s) are either linked by means ofa lexical link or can be linked on the basis of cor-responding part-of-speech codes.
All word classescan be linked based on PoS codes.In addition to linking words based on PoS codes,a small set of predefined language-dependent ruleswere implemented to handle function words.
Forexample:?
Extra function words (determiners and prepo-sitions) in source or target language are linkedtogether with their noun to the noun?s transla-tion.?
In French, the preposition de is contractedwith the definitive articles le and les to du anddes respectively.
The contracted determinersare linked to an English preposition and de-terminer.The percentage of words that have to be linked wasempirically set at 85%.3.5 Remaining chunksIn a second step, chunks consisting of one functionword ?
mostly punctuation marks and conjunctions?
are linked based on corresponding part-of-speechcodes if its left or right neighbour on the diagonalis an anchor chunk.
Corresponding final punctua-tion marks are also linked.In a final step, additional candidates are con-structed by selecting non-anchor chunks in thesource and target sentence that have correspond-ing left and right anchor chunks as neigbours.
Theanchor chunks of the first step are used as contex-tual information to link n:m chunks or chunks forwhich no lexical link was found in the lexical linkmatrix.In Figure 1, the chunks [Fr: gradient] ?
[En: gra-dient] and the final punctuation mark have beenretrieved in the first step as anchor chunk.
In thelast step, the n:m chunk [Fr: de remont?ee p?edaled?
embrayage] ?
[En: of rising of the clutch pedal]is selected as candidate anchor chunk because it isenclosed within anchor chunks.Figure 1: n:m candidate chunk: ?A?
stands for an-chor chunks, ?L?
for lexical links, ?P?
for wordslinked on the basis of corresponding PoS codes and?R?
for words linked by language-dependent rules.As the contextual clues (the left and right neig-bours of the additional candidate chunks are an-chor chunks) provide some extra indication that thechunks can be linked, the similarity test for the fi-nal candidates was somewhat relaxed: the percent-age of words that have to be linked was loweredto 0.80 and a more relaxed PoS matching functionwas used:?
Verbs and nouns can be linkedFr: pour permettre de vidanger proprement le circuitEn: to permit clean draining of the system?
Adjectives and nouns can be linkedFr: l?
entr?ee d?
airEn: incoming air?
Past participles can be linked to past tense43.6 EvaluationAll translational correspondences were manuallyindicated in the three test corpora (see section 2.2).4The English PoS tagger often tags a past participle erro-neously as a past tense.532We adapted the annotation guidelines of Macken(2007) to the French-English language pair, andused three different types of links: regular linksfor straightforward correspondences, fuzzy linksfor translation-specific shifts of various kinds, andnull links for words for which no correspondencecould be indicated.
Figure 2 shows an example.Figure 2: Manual reference: regular links are indi-cated by x?s, fuzzy links and null links by 0?sTo evaluate the system?s performance, we used theevaluation methodology of Och and Ney (2003).Och and Ney distinguished sure alignments (S)and possible alignments (P) and introduced the fol-lowing redefined precision and recall measures:precision =|A ?
P ||A|, recall =|A ?
S||S|(1)and the alignment error rate (AER):AER(S, P ;A) = 1 ?|A ?
P | + |A ?
S||A| + |S|(2)We consider all regular links of the manual ref-erence as sure alignments and all fuzzy and nulllinks as possible alignments to compare the outputof our system with the manual reference.We trained statistical translation models usingMoses.
Moses uses the GIZA++ toolkit (IBMModel 1-4) in both translation directions (sourceto target, target to source) and allows for differentsymmetrization heuristics to combine the align-ments of both translation directions.
We used threedifferent heuristics: grow-diag-final (default), in-tersection and union.SHORT MEDIUM LONGp r e p r e p r e?
.99 .83 .10 .98 .73 .16 .99 .77 .13?
.95 .92 .07 .91 .86 .11 .91 .89 .10Gdf .95 .91 .07 .93 .85 .11 .94 .88 .09Ling.
.96 .93 .06 .94 .88 .09 .92 .87 .10Table 3: Precision (p), recall (r) and align-ment error rate (e) for three symmetrizationheuristics based on the GIZA++ alignments(intersection(?
), union (?
), Grow-diag-final(Gdf)) vs the linguistically-based system (Ling.
)for the three test corporaTable 3 compares the alignment quality of ourlinguistically-based system with the purely statisti-cal approaches.
Overall, the results confirm our as-sumption that shorter sentences are easier to alignthan longer sentences.
As expected, the intersec-tion heuristic aligns words with a very high preci-sion (98-99%).
We further observe that the align-ment error rate of the linguistically-based systemis the lowest for the short and medium-length sen-tences, but that on the long sentences the defaultsymmetrization heuristic yields the best results.Manual inspection of the alignments revealed thatin some long sentences, the linguistically-basedsystem misaligns repeated terms in long sentences,a phenomenon that occured frequently in the longsentence corpus.
As expected, the linguistically-based system scores better on function words.Overall, on this data set, the linguistically-basedsystem yields results that are comparable to the re-sults obtained by the complex and computationallyexpensive chain of IBM models.4 Terminology extractionAs described in Section 1, we generate candidateterms starting from the aligned anchor chunks.
Ina second step, we use a general purpose corpus andthe n-gram frequency of the automotive corpus todetermine the specificity of the terms.4.1 Generating candidate termsEnglish and French use a different compoundingstrategy.
In English, the most frequently used com-pounding strategy is the concatenation of nouns,while in French prepositional phrases are concate-nated.
The following example illustrates the dif-ferent compounding strategy:Fr: une proc?edure d?
initialisation du calculateurde bo?
?te de vitesses automatique533En: an automatic gearbox ECU initialisation pro-cedureWe start from the anchor chunks as they are theminimal chunks that could be linked together.
Weimplemented two heuristics to generate additionalFrench candidate terms: a first heuristic strips offadjectives and a second heuristic considers each N+ PP pattern as candidate term.For each French candidate term, the Englishtranslation is constructed on the basis of the wordalignments.
The following candidate terms aregenerated for our example:1 proc?edure d?
initialisationdu calculateur de bo?
?te devitesses automatiqueautomatic gearbox ECUinitialisation procedure2 proc?edure d?
initialisationdu calculateur de bo?
?te devitessesgearbox ECU initialisa-tion procedure3 proc?edure d?
initialisation initialisation procedure4 initialisation du calcula-teurECU initialisation5 calculateur de bo?
?te devitessesgearbox ECU6 bo?
?te de vitesses automa-tiqueautomatic gearbox7 bo?
?te de vitesses gearbox8 proc?edure procedure9 initialisation initialisation10 calculateur ECU11 automatique automatic4.2 Filtering of candidate termsAs our terminology extraction module is meant togenerate a bilingual automotive lexicon, every en-try in our lexicon should refer to a concept or ac-tion that is relevant in an automotive context.
Thisalso means we want to include the minimal se-mantical units (e.g.
seat belt) as well as the largersemantical units (e.g.
outer front seat belt) of aparent-child term relationship.
In order to decideon which terms should be kept in our lexicon, wehave combined two algorithms: Log-Likelihoodfor single word entries and Mutual ExpectationMeasure for multiword entries.4.2.1 Log-Likelihood MeasureIn order to detect single word terms that are dis-tinctive enough to be kept in our bilingual lexi-con, we have applied the Log-Likelihood measure(LL).
This metric considers frequencies of wordsweighted over two different corpora (in our casea technical automotive corpus and the more gen-eral purpose corpus ?Le Monde?
), in order to as-sign high LL-values to words having much higheror lower frequencies than expected.
Daille (1995)has determined empirically that LL is an accuratemeasure for finding the most surprisingly frequentwords in a corpus.
Low LL values on the otherhand allow to retrieve common vocabulary withhigh frequencies in both corpora.
We have cre-ated a frequency list for both corpora and calcu-lated the Log-Likelihood values for each word inthis frequency list.
In the formula below, N cor-responds to the number of words in the corpus,whereas the observed values O correspond to thereal frequencies of a word in the corpus.
The for-mula for calculating both the expected values (E)and the Log-Likelihood have been described in de-tail by (Rayson and Garside, 2000).Ei=Ni?iOi?iNi(3)We used the resulting Expected values for calcu-lating the Log-Likelihood:?2ln?
= 2?iOiln(OiEi) (4)Manual inspection of the Log-Likelihood fig-ures confirmed our hypothesis that more domain-specific terms in our corpus got high LL-values.As we are mainly interested in finding distinc-tive terms in the automotive corpus, we have onlykept those terms showing positive Expected Val-ues in our domain-specific corpus combined withuser-defined Log-Likelihood values.
Examples ofFrench-English translation pairs that are filteredout using the LL values are:Fr: tout ?
En: entireFr: propre ?
En: cleanFr: interdits ?
En: prohibitedFr: nombre ?
En: number4.2.2 Mutual Expectation MeasureDias and Kaalep (2003) have developed the Mu-tual Expectation measure for evaluating the degreeof cohesiveness between words in a text.
We haveapplied this metric on our list of multiword terms,to exclude multiword terms which components donot occur together more often than expected bychance.
In a first step, we have calculated all n-gram frequencies (up to 8-grams) for our Englishand French sentences.
We use these frequencies toderive the Normalised Expectation (NE) values forall multiword entries, as specified by the formulaof Dias and Kaalep:534NE =prob(n?
gram)1n?prob(n?
1 ?
grams)(5)The Normalised Expectation value expresses thecost, in terms of cohesiveness, of the possibleloss of one word in an n-gram.
The higher thefrequency of the n-1-grams, the smaller the NE,and the smaller the chance that it is a valid mul-tiword expression.
As simple n-gram frequencyalso seems to be a valid criterion for multiwordterm identification (Daille, 1995), the NE valuesare multiplied by the n-gram frequency to obtainthe final Mutual Expectation (ME) value.We have calculated Mutual Expectation valuesfor all French and English multiword terms andfiltered out incomplete or erroneous terms havingvery low ME values.
The following example hasbeen filtered out:Fr: permettant d?alimenter le circuit d?eau arri`ereEn: to supply the rear water circuitIncomplete term:eau arri`ere - rear water (should be Fr: circuitd?eau arri`ere - En: rear water circuit)4.3 Evaluation of the Terminology ExtractionModuleTo evaluate the terminology extraction module,we used all sentences of the three test corpora(see Section 2.2).
We compared the performanceof our algorithm with the output of a commer-cial state-of-the-art terminology extraction pro-gram SDL MultiTerm Extract5.
MultiTerm firstextracts source language terms and identifies ina separate step the term translations.
MultiTermmakes use of basic vocubulary lists to exclude gen-eral vocabulary words from the candidate term list.We ran MultiTerm Extract with the default settingson 70,000 aligned sentences6of the automotivecorpus.
The extracted terms of our system havebeen filtered by applying Log-Likelihood thresh-olds (for single word terms) and Mutual Expec-tation thresholds (for multiword terms).
Tabel 4shows the number of terms after each reductionphase.The output of both systems has been manuallylabeled taking into account the following guide-lines:5www.translationzone.com/en/products/sdlmultitermextract670,000 sentences was the maximum size of the corpusthat could be processed within MultiTerm Extract.# extracted # entries # entriesentries after afterME filtering LL filteringAnchor chunk approach 2778 2688 2549Multiterm Extract 1337 N/A N/ATable 4: Figures after Log-Likelihood and MutualExpectation reductionAnchor chunk approach Correct Not correct Maybe correctMultiwords 78.5% 19% 2.5%Single words 89.5% 9.5% 1%All terms 83% 15% 2%Multiterm Extract Correct Not correct Maybe correctMultiwords 51% 48.5% 0.5%Single words 83% 16% 1%All terms 66% 33.5% 0.5%Table 5: Results Term Extraction Module?
judge the quality of the bilingual entry as awhole, meaning that the French and Englishterms should express the same concept?
each entry should form a semantic unit andrefer to an existing concept or action in theautomotive contextDuring manual validation, the following threelabels have been used: OK (valid entry), NOK (nota valid entry) and MAYBE (when the annotatorwas not sure about the correct label).
Table 5lists the results of both our system and MultiTermExtract and illustrates that our linguisticallybased alignment approach works particularly wellfor the extraction of more complex multiwordexpressions.Error analysis on the errors made by the anchorchunk approach revealed the following error types:1. compounds that are only partially retrievedin one of the two languages:ceinture outer seat belt(valable uniquement pourla ceinture de s?ecurit?eavant lat?erale)(applies only to the outerseat belt)2. fuzzy word links (different grammaticaland syntactical structures, paraphrases etc)that result in bad lexicon entries:fusibles no fuse(montage avec vide-poches inf?erieur fixe sansrangement des fusibles)(fitting with fixed lowerstorage compartment withno fuse storage)3. translation errors in the parallel corpus:automatique additional(tableau de commandeclimatisation automa-tique)(additional air condition-ing unit control panel)5354. ambiguous words that cause PoS andchunking errors (in the corpus avant is usu-ally used as an adjective, but in the example ithas a prepositional function as avant de):c?ables avant cables(rep?erer la position desc?ables avant de lesd?eclipper)(mark the position of thecables before unclippingthem)5 Conclusions and future workWe presented a sub-sentential alignment systemthat links linguistically motivated phrases in paral-lel texts based on lexical correspondences and syn-tactic similarity.
Overall, the obtained alignmentscores are comparable to the scores of the state-of-the-art statistical approach that is used in Moses.The results show that the aligned linguisticallymotivated phrases are a useful means to extractbilingual terminology for French-English.
In theshort term, we will test our methodology on otherlanguage pairs, i.e.
French-Dutch, French-Spanishand French-Swedish.
We will also compare ourwork with other bilingual term extraction pro-grams.6 AcknowledgementWe would like to thank PSA Peugeot Citro?en forfunding this project.ReferencesDaille, B.
1995.
Study and implementation of com-bined techniques for automatic extraction of termi-nology.
In Klavans, J. and P. Resnik, editors, TheBalancing Act: Combining Symbolic and StatisticalApproaches to Language, pages 49?66.
MIT Press,Cambridge, Massachusetts; London, England.Dias, G. and H. Kaalep.
2003.
Automatic Extraction ofMultiword Units for Estonian: Phrasal Verbs.
Lan-guages in Development, 41:81?91.Gaussier, E. 1998.
Flow Network Models for WordAlignment and Terminology Extraction from Bilin-gual Corpora .
In 36th Annual Meeting of the Associ-ation for Computational Linguistics and 17th Inter-national Conference on Computational Linguistics(Proceedings of COLING-ACL ?98), pages 444?450,Universit?e de Montr?eal, Montreal, Quebec, Canada.Gotti, F., P. Langlais, E. Macklovitch, D. Bourigault,B.
Robichaud, and C. Coulombe.
2005.
3GTM: athird-generation translation memory.
In Proceedingsof the 3rd Computational Linguistics in the North-East (CLiNE) Workshop, Gatineau, Qu?ebec.Hwa, R., P. Resnik, A. Weinberg, and O. Kolak.
2002.Evaluating translational correspondence using anno-tation projection.
In Proceedings of the 40th An-nual Meeting of the Association for ComputationalLinguistics (ACL), pages 392?399, Philadelphia, PA,USA.Itagaki, M., T. Aikawa, and X.
He.
2007.
Auto-matic Validation of Terminology Consistency withStatistical Method.
In Maegaard, Bente, editor,Machine Translation Summit XI, pages 269?274,Copenhagen, Denmark.
European Associaton forMachine Translation.Koehn, P., H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open Source Toolkitfor Statistical Machine Translation.
In Proceedingsof the ACL 2007 Demo and Poster Sessions, pages177?180, Prague, Czech Republic.Kupiec, J.
1993.
An algorithm for finding noun phrasecorrespondences in bilingual corpora.
In Proceed-ings of the 31st Annual Meeting of the Associationfor Computational Linguistics.Macken, L. 2007.
Analysis of translational corre-spondence in view of sub-sentential alignment.
InProceedings of the METIS-II Workshop on New Ap-proaches to Machine Translation, pages 97?105,Leuven, Belgium.Melamed, I. Dan.
2000.
Models of translational equiv-alence among words.
Computational Linguistics,26(2):221?249.Moore, R. C. 2002.
Fast and accurate sentence align-ment of bilingual corpora.
In Proceedings of the 5thConference of the Association for Machine Transla-tion in the Americas, Machine Translation: from re-search to real users, pages 135?244, Tiburon, Cali-fornia.Och, F. J. and H. Ney.
2003.
A systematic comparisonof various statistical alignment models.
Computa-tional Linguistics, 29(1):19?51.Rayson, P. and R. Garside.
2000.
Comparing cor-pora using frequency profiling.
In Proceedings ofthe workshop on Comparing Corpora, 38th annualmeeting of the Association for Computational Lin-guistics (ACL 2000), pages 1?6.Schmid, H. 1994.
Probabilistic part-of-speech taggingusing decision trees.
In International Conference onNew Methods in Language Processing, Manchester,UK.Tjong Kim Sang, Erik F. and Sabine Buchholz.2000.
Introduction to the CoNLL-2000 Shared Task:Chunking.
In CoNLL-2000 and LLL-2000, pages127?132, Lisbon, Portugal.536
