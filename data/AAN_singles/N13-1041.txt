Proceedings of NAACL-HLT 2013, pages 401?410,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsMining User Relations from Online Discussions using Sentiment Analysisand Probabilistic Matrix FactorizationMinghui Qiu?, Liu Yang?,?, Jing Jiang??
School of Information Systems, Singapore Management University, Singapore?
School of Software and Microelectronics, Peking University, China{minghui.qiu.2010,jingjiang}@smu.edu.sg, yang.liu@pku.edu.cnAbstractAdvances in sentiment analysis have enabledextraction of user relations implied in onlinetextual exchanges such as forum posts.
How-ever, recent studies in this direction only con-sider direct relation extraction from text.
Asuser interactions can be sparse in online dis-cussions, we propose to apply collaborativefiltering through probabilistic matrix factor-ization to generalize and improve the opinionmatrices extracted from forum posts.
Exper-iments with two tasks show that the learnedlatent factor representation can give good per-formance on a relation polarity prediction taskand improve the performance of a subgroupdetection task.1 IntroductionThe fast growth of the social Web has led to a largeamount of interest in online social network analysis.Most existing work on social network analysis re-lies on explicit links among users such as undirectedfriendship relations (Liben-Nowell and Kleinberg,2003), directed following relations (Hopcroft et al2011) and trust/distrust relations (Leskovec et al2010).
However, besides these explicit social rela-tions, the various kinds of interactions between on-line users often suggest other implicit relations.
Inparticular, in online discussion forums, users inter-act through textual posts and these exchanged textsoften reveal whether two users are friends or foes, orwhether two users share the same viewpoint towardsa given issue.To uncover such implicit relations requires textanalysis and particularly sentiment analysis.
Re-cently, Hassan et al(2012) studied predicting thepolarity of user interactions in online discussionsbased on textual exchanges.
They found that the au-tomatically predicted signed relations had an accu-racy above 80%.
The extracted signed network wasfurther used to detect ideological subgroups.
This isa piece of pioneering work that extracts online socialrelations based on text analysis.In this paper, we further extend the idea of miningsocial relations from online forum posts by incorpo-rating collaborative filtering.
Our work is motivatedby the observation that direct textual exchanges be-tween users are sparse.
For example, in the data setwe use, only around 13% of user-user pairs have di-rect interactions.
Collaborative filtering is a com-monly used technique in recommender systems topredict missing ratings.
The key assumption is thatif two people have the same opinion on an item A,they are likely to also have the same opinion on adifferent item B.
In online discussion forums, usersexpress their opinions about each other as well asthe various aspects of the topic under discussion, butnot every user comments on every aspect or everyother user.
Collaborative filtering allows us to iden-tify users with the same opinion even if they have notdirectly interacted with each other or commented onany common aspect.Our method starts with extracting opinions onusers and topic aspects from online posts using sen-timent analysis.
The results are two matrices indi-cating the sentiment polarity scores between pairsof users and pairs of a user and an aspect.
To in-corporate collaborative filtering, we choose proba-bilistic matrix factorization (PMF) (Salakhutdinov401and Mnih, 2008), a technique that has been success-fully applied for collaborative filtering-based recom-mendation problems.
PMF automatically discoversa low-rank representation for both users and itemsbased on observed rating data.
In our problem, thepredicted sentiment polarity scores are treated as rat-ing data, and the results of PMF are low-rank vectorsrepresenting each user in online discussions.We evaluate our method on two tasks.
The firstis to predict the polarity of interactions between twousers not from their own textual exchanges but fromtheir interactions with other users or comments ontopic aspects.
The second is to use the latent vectorsto group users based on viewpoints.
We find that thelatent factor representation can produce good predic-tion results for the first task and improve the cluster-ing results of the second task compared with a num-ber of baselines, showing the effectiveness of col-laborative filtering for mining social relations fromonline discussions.2 Related WorkOur work is closely related to recent studies ondetecting subgroups from online discussions (Abu-Jbara et al 2012; Dasigi et al 2012; Hassan etal., 2012).
Abu-Jbara et al(2012) proposed tobuild discussant attitude profiles (DAP) from on-line posts and use these profiles to cluster users intosubgroups.
A DAP is a vector that contains theattitudes of a discussant towards other discussantsand a set of opinion targets.
We also extract opin-ions of users towards other users and opinion tar-gets from posts, which are similar to DAPs.
Thedifference is that we further apply probabilistic ma-trix factorization to derive a low-rank representationfrom the raw opinion scores.
Our comparison withDAP-based clustering shows that probabilistic ma-trix factorization can improve subgroup detection.Hassan et al(2012) proposed to predict the polar-ity of interactions between users based on their tex-tual exchanges.
They defined a set of interactionfeatures using sentiment analysis and applied super-vised learning for polarity prediction.
In compari-son, our work is unsupervised, that is, we do not useany ground truth of interaction polarity for training.Probabilistic matrix factorization was proposedby Salakhutdinov and Mnih (2008) as a collabo-rative filtering method for recommender systems.It has attracted much attention and been extendedby Ma et al(2008) and Wang and Blei (2011).In particular, Ma et al(2008) proposed a SocRecmodel that combines social network informationwith rating data using the PMF framework to per-form social recommendation.
Our model bears sim-ilarity to SocRec in that we also consider two typesof interactions, i.e.
user-user interactions and user-aspect interactions.
However, different from Ma etal.
(2008), we predict both the user-user and user-aspect scores from textual posts using sentimentanalysis, and the user-user opinion polarity scoresare symmetric.Part of our method uses sentiment analysis to ex-tract opinions from text.
This is built on top of alarge body of existing work on opinion extraction,e.g.
Choi et al(2006) and Wu et al(2009).
As thesentiment analysis component is not our main con-tribution, we do not review existing work along thisdirection in detail here.
Interested readers can referto Pang and Lee (2008).The idea of incorporating sentiment analysis intocollaborative filtering algorithms has been exploredby Kawamae (2011), Moshfeghi et al(2011) andLeung et al(2011).
While their work also com-bines sentiment analysis with collaborative filtering,the purpose is to improve the accuracy of item rec-ommendation.
In contrast, we borrow the idea andtechnique of collaborative filtering to improve userrelation mining from online text.3 Method OverviewIn this section, we provide an overview of ourmethod.
We first introduce some concepts.User: We use user to refer to a discussant in an on-line discussion.
Each user has an online ID, whichcan be used by other users to refer to him/her in apost.
Users are both opinion holders and opiniontargets.
For example, User 1 below expresses a neg-ative opinion towards another user in the followingsnippet.User 1: Actually, I have to disagree with you.Aspect: We use topic aspect or aspect to refer to anopinion target that is related to the topic under dis-cussion.
For example, when debating about whetherone should vote for Obama, people may express402opinions on targets such as ?President Obama?
and?Republican party,?
as shown in the following snip-pets.
These aspects are all related to Obama?s pres-idential campaign.
As we will explain later, the as-pects we consider are named entities and frequentnoun phrases.User 2: Americans should vote for President Obama be-cause he picks good corporations as winners.User 3: I simply point out how absolutely terrible the Re-publican party is.Polarity Score: A sentiment polarity score is areal number between 0 and 1, where 0 indicates acompletely negative opinion and 1 indicates a com-pletely positive opinion.User-User Opinion Matrix: The opinions ex-tracted from posts between users are represented bya user-user opinion matrix S, where entry si,j is apolarity score between the i-th user and the j-th user.We assume that the polarity scores are symmetric.User-Aspect Opinion Matrix: The opinions heldby different users on the various topic aspects arerepresented by a user-aspect opinion matrix R,where entry ri,k is a polarity score indicating the i-thuser?s opinion towards the k-th aspect.Given the matrices S and R, we perform proba-bilistic matrix factorization to derive a low-rank vec-tor representation for users and aspects such that ifthe polarity score between two users or a user andan aspect is high, the dot product between the corre-sponding two vectors is also high.In Section 4, we will explain in detail how weidentify topic aspects from a discussion thread andhow we obtain polarity scores from posts.
In Sec-tion 5, we will present the details of our probabilisticmatrix factorization model.4 Construction of Opinion MatricesThe opinion matrices are constructed from a singleforum thread discussing some controversial topic.4.1 Aspect IdentificationAs we have pointed out, there are two kinds of opin-ion targets, namely users and aspects.
Users areclearly defined and can often be identified in postsby their IDs or second person pronouns.
For aspects,however, there is not a pre-defined set.
We observethat these topic aspects are usually named entitiesor noun phrases frequently mentioned.
We thereforeuse the OpenNLP toolkit1 to perform chunking andobtain noun phrases and the Standford NER tagger2to identify named entities from the posts.Some of the candidate aspect phrases identifiedabove actually refer to the same actual aspect, e.g.
?Obama voter,?
?Obama voters?
and ?the Obamavoter.?
We remove stop words from each candidatephrase and use the WordNet by Miller (1995) to ob-tain the lemma of each word such that we can nor-malize the candidate aspect phases to some extent.Finally, to select salient aspects for a given discus-sion topic, we count the number of times each candi-date aspect has been expressed a positive or negativeopinion on by all users, and select those candidateaspects which have opinion expressions from at leastM users.
We set M to 2 in our experiments.
Fig-ure 1 shows the top salient aspects for the thread on?Will you vote for Obama??
We acknowledge thereare still duplicate aspects in the results like ?Repub-lican Party?
and ?GOP?.
To normalize these aspects,some additional information such as Wikipedia en-tries and Google snippets may be considered.
Wewill study this problem in our future work.4.2 Opinion Expression IdentificationOur next step is to identify candidate opinion expres-sions.
This problem has been studied in Hu and Liu(2004), Popescu and Etzioni (2005), and Hassanand Radev (2010).
Based on previous work, we dothe following.
We first combine three popular sen-timent lexicons to form a single sentiment lexicon:the lexicon used in Hu and Liu (2004), MPQA Sub-jectivity Lexicon by Wilson et al(2005) and Senti-WordNet by Baccianella et al(2010).
Our final sen-timent lexicon contains 15,322 negative expressionsand 10,144 positive expressions.
We then identifycandidate opinion expressions by searching for oc-currences of words in this lexicon in the posts.4.3 Opinion Relation ExtractionGiven a post that contains an aspect and an opin-ion expression, we still need to determine whetherthe opinion expression is used to describe the as-pect.
This is a relation extraction problem.
We use asupervised learning approach based on dependency1http://opennlp.apache.org/2http://nlp.stanford.edu/ner/index.shtml403020406080100OBAMA BUSHAMERICA PALINREPUBLICANCONGRESSTAX_CUTAMERICANCLINTONMCCAINTEA_PARTY IRAQSARAH_PALINPRESIDENT_OBAMAREAGANRON_PAULECONOMIC_POLICYAFGHANISTANCARTER FOXHEALTH_CARENATIONAL_DEBTDEMOCRAT GOPMIDDLE_CLASSOBAMA_ADMINISTRATIONREPUBLICAN_PARTYTAX_BREAKWASHINGTONFEDERAL_GOVERNMENTHEALTH_CARE_REFORMHITLERIRAQ_WARWALL_STREETFigure 1: Salient aspects and number of users who express opinions on them in the thread ?Will you vote for Obama?
?ID Dependency path rule ExampleR1 ADJOP ?
amod?
NTR I simply point out how terrible REPUBLICAN PARTY is.R2 ADJOP ?
nsubj ?
NTR BUSH is even more reasonable for tax hike than Obama.R3 VOP ?
dobj ?
NTR I would never support OBAMA.R4 VOP ?
prep ?
?
NTR I?ll vote for OBAMA.R5 VOP ?
nsubjpass?
NTR DEMOCRATIC PARTY are ultimately corrupted by love of money.R6 NOP ?
dobj ?
V ?
nsubj ?
NTR PAKISTAN is increasing terrorist threat.R7 ADJOP ?
amod?
N ?
nsubj ?
NTR OBAMA was a top scorer for occidental college.R8 ADVOP ?
advmod?
V ?
nsubj ?
NTR OBAMA is smarter than people.Table 1: Examples of frequent dependency path rules in our training data.
OP and TR refer to the opinion and thetarget.
The opinion words are in italic and the aspect words are in uppercase.paths.
Previous work by Mintz et al(2009), and Qiuet al(2009) has shown that the shortest path be-tween a candidate opinion aspect and a candidateopinion expression in the dependency parse tree canbe effective in extracting opinion relations.
We usethe Stanford Parser from Klein and Manning (2003)to obtain the dependency parse trees for each sen-tence in the posts and then get the dependency pathsbetween each pair of candidate aspect and opinionexpression.
We use dependency relations and POStags of nodes along the path to represent a depen-dency path.
Given a set of training sentences (weuse the one from Wu et al(2009)), we can get a setof dependency path rules based on their frequenciesin the training data.
Table 1 shows the frequent de-pendency path rules in our training data.When a pair of aspect and opinion expression isidentified to be related, we use the polarity of theopinion expression to label the relation.
Finally,given a pair of users, we use the percentage of pos-itive interactions between them over all subjectiveinteractions (i.e.
interactions with either positive ornegative opinions) as extracted from their exchangedposts as the sentiment polarity score between thetwo users, regardless of the reply-to direction ofthe posts.
Similarly, given a user and an aspect,we also use the percentage of positive opinion re-lations extracted as the sentiment polarity score be-tween them.
Thus the user-user opinion matrix andthe user-aspect opinion matrix are constructed.
Ifthere is no subjective interaction detected betweentwo users or between a user and an aspect, the cor-responding entry in the matrix is left empty.
We willsee later that empty entries in the matrices are notused in the probabilistic matrix factorization step.5 Probabilistic Matrix FactorizationAs we have pointed out earlier, a problem with thematrices extracted as described in Section 4 is thatthe matrices are sparse, i.e.
many entries are empty.For the data set we use, we find that around 87% ofentries in the user-user opinion matrix and around90% of entries in the user-aspect opinion matrix areempty.
In this section, we describe how we useProbabilistic Matrix Factorization (PMF) to repre-sent users and aspects in a latent factor space andthus generalize the user preferences.Our model is almost a direct application of proba-404bilistic matrix factorization from Salakhutdinov andMnih (2008), originally proposed for recommendersystems.
The main difference is that the user-useropinion polarity scores are symmetric.
Our model isalso similar to the one used by Ma et al(2008).
Wedescribe our model as follows.We assume that there are K latent factors withwhich both users and aspects can be represented.
Letui ?
RK denote the vector in the latent factor spacefor the i-th user, and ak the vector for the k-th aspect.Recall that the opinions extracted from posts be-tween users are represented by a user-user opinionmatrix S, and the opinions held by different users onthe various topic aspects are represented by a user-aspect opinion matrix R. We assume that the polar-ity scores si,j between the i-th and the j-th users andri,k between the i-th user and the k-th aspect in thetwo matrices S and R are generated in the followingway:p(si,j |ui, uj , ?21) = N (si,j |g(uTi uj), ?21),p(ri,k|ui, ak, ?22) = N (ri,k|g(uTi ak), ?22),where ?21 and ?22 are variance parameters, g(?)
thelogistic function, and N (?|?, ?2) is the normal dis-tribution with mean ?
and variance ?2.We can see that with this generative assumption,if two users are similar in terms of their dot productin the latent factor space, then they are more likelyto have positive interactions as extracted from theirtextual exchanges.
Similarly, if a user and an aspectare similar, then the user is more likely to express apositive opinion on the aspect in his/her posts.
Thelatent factors can therefore encode user preferencesand similarity between two users in the latent factorspace reflects whether they share similar viewpoints.We also place the following prior over ui and ak:p(ui|?2U ) = N (ui|~0, ?2UI),p(ak|?2A) = N (ak|~0, ?2AI),where ?2U and ?2A are two variance parameters forusers and aspects, respectively, and I is the identifymatrix.Figure 2 shows the plate notation for the genera-tive model.Let U be aK?U matrix containing the vectors uifor allU users, andA be anK?Amatrix containingFigure 2: Probabilistic matrix factorization model onopinion matrices.the vectors ak for all A aspects.
To automaticallylearn U andA, we minimize the following objectivefunction:L(U ,A,S,R)=12U?i=1A?k=1I(ri,k)(ri,k ?
g(uTi ak))2+?12U?i=1U?j=1I(si,j)(si,j ?
g(uTi uj))2+?U2||U||2F +?A2||A||2F , (1)where ?
= ?21?22, ?U =?21?2U, and ?A =?21?2A, I(s) isan indicator function which equals 1 when s is notempty and otherwise 0.To optimize the objective function above, we canperform gradient descent on U and A to find a localoptimum point.
The derivation is similar to Ma et al(2008).Degenerate Versions of the ModelWe refer to the complete model described aboveas PMF-UOM (PMF model based on User OpinionMatrices).
PMF-UOM has the following two degen-erate versions by considering either only the user-user opinion matrix or only the user-aspect opinionmatrix.PMF-UU: In this degenerate version of the model,we use only the user-user opinion matrix to learn thelatent factor representation.
Specifically, the objec-tive function is modified such that we drop the sum405of the square errors involving R and the regularizeron A.PMF-UA: In this degenerate version of the model,we use only the user-aspect opinion matrix to learnthe latent factor representation.
Specifically, the ob-jective function is modified such that we drop thesum of the square errors involving S.6 ExperimentsIn this section, we present our experiments that eval-uate our model.6.1 Data Set and Experiment SettingsThe data set we use comes from Abu-Jbara et al(2012) and Hassan et al(2012).
The data setcontains a set of discussion threads collected fromtwo political forums (Createdebate3 and Politicalfo-rum4) and one Wikipedia discussion session.
Werandomly select 6 threads from the original data setto evaluate our model.
Some details of the data weuse are listed in Table 2.ID topic #sides #sentences #usersDS1 Vote for Obama 2 12492 197DS2 Abortion Banned 6 3844 70DS3 Profile Muslims 4 2167 69DS4 England and USA 6 2030 62DS5 Tax Cuts 2 1193 26DS6 Political Spectrum 7 1130 50Table 2: Some statistics of the data sets.In our experiments, for the PMF-based methods,we set the number of latent factors to be 10 as wedo not observe big difference when vary the latentfactor size from 10 to 50.
For the other parame-ters, we select the optimal setting for each threadbased on the average of 50 runs.
?U is chosenfrom {0.1, 0.01}, ?A from {0.01, 0.001} and ?
from{1, 0.1}.6.2 Relation Polarity PredictionThe first task we use to evaluate our model is to pre-dict the polarity of interactions between two users.Different from Hassan et al(2012), however, weare not using this task to evaluate the accuracy ofsentiment analysis from text.
Our experimental set-ting is completely different in that we do not make3www.createdebate.com4www.politicalforum.comuse of the text exchanges between the two users butinstead use their interactions with other users or as-pects.
The purpose is to test the effectiveness of col-laborative filtering.Experimental Setting: The experiments are set upin the following way.
Given a pair of users i and jwho have directly exchanged posts, i.e.
si,j is notempty, we first hide the value of si,j in the matrix S.Let the altered matrix be S?(i,j).
We then use S?
(i,j)instead of S in the learning process as described inSection 5 to learn the latent factor representation.Let u?i and u?j denote the learned latent vectors foruser i and user j.
We predict the polarity of relationbetween i and j as follows:s?i,j ={1 if g(u?Ti u?j) > 0.5,0 otherwise,where g(?)
is the logistic function to convert the dotproduct into a value between 0 and 1.To judge the quality of the predicted polarity s?i,j ,we could compare it with si,j .
But since si,j itself ispredicted from the textual exchanges between i andj, it is not the ground truth.
Instead, we ask two hu-man annotators to assign the true polarity label foruser i and user j by reading the textual exchangesbetween them and judging whether they are friendsor foes in the discussion thread.
The annotators areasked to assign a score of 0 (indicating a negativerelation), 0.5 (indicating a neutral relation) or 1 (in-dicating a positive relation).
The lowest agreementscore based on Cohen?s kappa coefficient among the6 threads we use is 0.56, showing fair to good agree-ment.
As ground truth, we set the final polarity scoreto 1 if the average score of the two annotators islarger than 0.5 and 0 otherwise.We compare the PMF-based methods with twomajority baselines: MBL-0 always predicts negativerelations for all the user pairs (assuming most rela-tions are negative) and MBL-1 always predicts posi-tive relations (assuming most relations are positive).We use MAE (mean absolute error) and RMSE(root mean square error) as defined below as perfor-mance metrics:MAE =?i,j |s?i,j ?
li,j |N,RMSE =?
?i,j(s?i,j ?
li,j)2N,4060.20.40.60.81.0DS1 DS2 DS3 DS4 DS5 DS6MAEMB-1MB-0PMF-UUPMF-UAPMF-UOMFigure 3: Comparing all the methods in terms of MAE.0.20.40.60.81.0DS1 DS2 DS3 DS4 DS5 DS6RMSEMB-1MB-0PMF-UUPMF-UAPMF-UOMFigure 4: Comparing all the methods in terms of RMSE.where N is the total number of user pairs we test,and li,j is the ground truth polarity score betweenuser i and user j.Results: We show the results of our model and ofPMF-UU and PMF-UA in terms of MAE in Figure 3and RMSE in Figure 4.
The MAE values range be-tween 0.31 and 0.44 except for DS5, which has ahigher error rate of 0.53.
The results show that evenwithout knowing the textual exchanges between twousers, from their interactions with other users and/orwith topic aspects, we can still infer the polarity oftheir relation with decent accuracy most of the time.The results also show the comparison between ourmodel and the competing methods.
We can see thatoverall the complete model (PMF-UOM) performsbetter than the two degenerate models (PMF-UUand PMF-UA).
The differences are statistically sig-nificant at the 5% level without considering DS5, asindicated by a 2-tailed paired t-test.
Comparing tothe majority baselines, our model significantly out-performs MBL-1 at 1% significance level while out-performs MBL-0 on all the data sets except DS5.
Aclose examinations shows DS5 has very unbalancedrelations (around 83% of relations are negative).
Ex-cept for the unbalanced data set, our model has rea-sonably good performance.6.3 Subgroup DetectionThe second task we study is the problem of detectingideological subgroups from discussion threads.
Theoriginal data set has been labeled with the groundtruth for this problem, that is, for each thread thenumber of viewpoints is known and the viewpointheld by each user is labeled.
A subgroup is definedas a set of users holding the same viewpoint.Experimental Setting: Through this second exper-iment, we would like to verify the hypothesis thatusing the learned latent factor representation U forusers, we can better detect subgroups than directlyusing the opinion matrices S and R. For all themethods we compare, we first construct a featurevector representation for each user.
We then applyK-means clustering to group users.
The number ofclusters is set to be the true number of viewpointsfor each thread.
The different methods are describedbelow:?
PMF-based methods: We simply use thelearned latent vectors u?i after optimizing theobjective function as the feature vectors to rep-resent each user.?
BL-1: This is our own implementation to sim-ulate the method by Abu-Jbara et al(2012).Here each user is represented by a (3 ?
(U +A))-dimensional vector, where U is the num-ber of users and A is the number of aspects,i.e.
(U +A) is the total number of opinion tar-gets.
For each opinion target, there are 3 di-mensions in the feature vector, correspondingto the number of positive, neutral and negativeopinion expressions towards the target from theonline posts.?
BL-2: BL-2 is similar to BL-1 except that weonly use a (U+A)-dimensional vector to repre-407sent each user.
Here for each opinion target, wedirectly use the corresponding sentiment polar-ity score si,j or ri,j from the matrix S orR.
Forempty entries in S andR, we use a score of 0.5.We use Purity (the higher the better), Entropy (thelower the better) and Rand Index (the higher the bet-ter) to evaluate the performance of subgroup detec-tion (Manning et al 2008).
We further use Accuracyobtained by choosing the best alignment of clusterswith the ground truth class labels and computing thepercentage of users that are ?classified?
correctly.Results: We first give an overview of the perfor-mance of all the methods on the task.
We show theaverage performance of the methods on all the datasets in Figure 5.
Overall, our model has a better per-formance than all the competing methods.0.40.60.81.0Purity Entropy Accuracy RandIndexBL-1BL-2PMF-UUPMF-UAPMF-UOMFigure 5: An overview of the average performance of allthe methods on the 6 threads.We present all the results in Table 3.
We per-form 2-tailed paired t-test on the results.
We findthat PMF-UOM outperforms all the other methodsin terms of RandIndex at 5% significance level andoutperforms other methods in terms of Purity andEntropy at 10% significance level.
Furthermore,the PMF-UOM model outperforms its degenerativemodels PMF-UU and PMF-UA at 10% significancelevel in terms of all the measures.We observe that PMF-UOM achieves the best per-formance in terms of all the measures for almostall threads.
In particular, comparison with BL-1and BL-2 shows that collaborative filtering can gen-eralize the user preferences and help better groupthe users based on their viewpoints.
The fact thatPMF-UOM outperforms both PMF-UU and PMF-UA shows that it is important to consider both user-user interactions and user-aspect interactions.The Effects of Cluster Size: To test the effect of thenumber of clusters on the experiment result, we varythe number of clusters from 2 to 10 in all methods.We find that all methods tend to achieve better re-sults when the number of clusters equals the groundtruth cluster size.
Overall, our method PMF-UOMshows a better performance than the other four meth-ods when the number of clusters changes, which in-dicates the robustness of our method.BL-1 BL-2 PMF-UU PMF-UA PMF-UOMDS1P 0.61 0.61 0.61 0.61 0.62E 0.96 0.96 0.94 0.95 0.94A 0.59 0.59 0.55 0.57 0.60R 0.51 0.51 0.50 0.51 0.52DS2P 0.53 0.63 0.64 0.61 0.68E 1.17 1.22 1.14 1.09 0.99A 0.47 0.53 0.48 0.47 0.50R 0.50 0.50 0.56 0.56 0.58DS3P 0.66 0.68 0.62 0.60 0.68E 1.05 1.01 1.06 1.07 0.94A 0.61 0.63 0.48 0.47 0.58R 0.50 0.52 0.53 0.53 0.57DS4P 0.64 0.64 0.66 0.65 0.70E 0.92 0.94 0.90 0.91 0.85A 0.59 0.64 0.62 0.62 0.68R 0.49 0.52 0.52 0.51 0.56DS5P 0.86 0.86 0.86 0.86 0.86E 0.56 0.56 0.49 0.48 0.38A 0.70 0.70 0.57 0.60 0.71R 0.52 0.52 0.43 0.45 0.56DS6P 0.50 0.50 0.60 0.60 0.68E 1.35 1.35 1.03 1.04 0.79A 0.40 0.30 0.53 0.54 0.64R 0.53 0.53 0.68 0.68 0.74Table 3: Results on subgroup detection on all the 6threads.
P, E, A and R refer to Purity, Entropy, Accuracyand RandIndex, respectively.7 ConclusionsIn this paper, we studied how to use probabilisticmatrix factorization, a common technique for col-laborative filtering, to improve relation mining fromonline discussion forums.
We first applied senti-ment analysis to extract user-user opinions and user-aspect opinions from forum posts.
The extractedopinions form two opinion matrices.
We then ap-plied probabilistic matrix factorization using these408two matrices to discover a low-rank latent factorspace which aims to better generalize the users?
un-derlying preferences and indicate user similaritiesbased on their viewpoints.
Using a data set with 6discussion threads, we showed that the learned la-tent vectors can be used to predict the polarity ofuser relations well without using the users?
directinteraction data, demonstrating the effectiveness ofcollaborative filtering.
We further found that for thetask of subgroup detection, the latent vectors gavebetter performance than using the directly extractedopinion data, again showing that collaborative fil-tering through probabilistic matrix factorization canhelp address the sparseness problem in the extractedopinion matrices and help improve relation mining.Our current work mainly focuses on the user opin-ion matrices.
As future work, we would like to ex-plore how to incorporate textual contents withoutopinionated expressions.
One possible way is toconsider the combination of matrix factorization andtopic modeling as studied by Wang and Blei (2011)where we can use topic modeling to study textualcontents.AcknowledgmentsWe thank the reviewers for their valuable commentson this work.ReferencesAmjad Abu-Jbara, Pradeep Dasigi, Mona Diab, andDragomir R. Radev.
2012.
Subgroup detection inideological discussions.
In Proceedings of the 50thAnnual Meeting of the Association for ComputationalLinguistics, pages 399?409.Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-tiani.
2010.
Sentiwordnet 3.0: An enhanced lexicalresource for sentiment analysis and opinion mining.
InLREC.Yejin Choi, Eric Breck, and Claire Cardie.
2006.
Jointextraction of entities and relations for opinion recog-nition.
In Proceedings of the 2006 Conference onEmpirical Methods in Natural Language Processing,EMNLP ?06, pages 431?439, Stroudsburg, PA, USA.Association for Computational Linguistics.Pradeep Dasigi, Weiwei Guo, and Mona T. Diab.
2012.Genre independent subgroup detection in online dis-cussion threads: A study of implicit attitude usingtextual latent semantics.
In Proceedings of the 50thAnnual Meeting of the Association for ComputationalLinguistics, pages 65?69.Ahmed Hassan and Dragomir Radev.
2010.
Identify-ing text polarity using random walks.
In Proceed-ings of the 48th Annual Meeting of the Association forComputational Linguistics, ACL ?10, pages 395?403,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Ahmed Hassan, Amjad Abu-Jbara, and Dragomir Radev.2012.
Detecting subgroups in online discussions bymodeling positive and negative relations among par-ticipants.
In Proceedings of the 2012 EMNLP, pages59?70.John Hopcroft, Tiancheng Lou, and Jie Tang.
2011.
Whowill follow you back?
: reciprocal relationship predic-tion.
In Proceedings of the 20th ACM internationalconference on Information and knowledge manage-ment, pages 1137?1146.Minqing Hu and Bing Liu.
2004.
Mining and summariz-ing customer reviews.
In Proceedings of the 10th ACMSIGKDD international conference on Knowledge dis-covery and data mining, pages 168?177.Noriaki Kawamae.
2011.
Predicting future reviews: sen-timent analysis models for collaborative filtering.
InProceedings of the fourth ACM international confer-ence on Web search and data mining, WSDM ?11,pages 605?614.Dan Klein and Christopher D. Manning.
2003.
Accurateunlexicalized parsing.
In Proceedings of the 41st An-nual Meeting on Association for Computational Lin-guistics - Volume 1, ACL ?03, pages 423?430, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Jure Leskovec, Daniel Huttenlocher, and Jon Kleinberg.2010.
Predicting positive and negative links in onlinesocial networks.
In Proceedings of the 19th interna-tional conference on World wide web, pages 641?650.Cane Wing-Ki Leung, Stephen Chi-Fai Chan, Fu-LaiChung, and Grace Ngai.
2011.
A probabilistic rat-ing inference framework for mining user preferencesfrom reviews.
World Wide Web, 14(2):187?215.David Liben-Nowell and Jon Kleinberg.
2003.
The linkprediction problem for social networks.
In Proceed-ings of the twelfth international conference on Infor-mation and knowledge management.Hao Ma, Haixuan Yang, Michael R. Lyu, and Irwin King.2008.
Sorec: Social recommendation using proba-bilistic matrix factorization.
In Proc.
of ACM interna-tional conference on Information and knowledge man-agement.Christopher D. Manning, Prabhakar Raghavan, and Hin-rich Schtze.
2008.
Introduction to Information Re-trieval.
Cambridge University Press, July.409George A. Miller.
1995.
Wordnet: A lexical databasefor english.
Communications of the ACM, Vol.
38, No.11:39?41.Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.2009.
Distant supervision for relation extraction with-out labeled data.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL and the 4thInternational Joint Conference on Natural LanguageProcessing of the AFNLP: Volume 2 - Volume 2, ACL?09, pages 1003?1011, Stroudsburg, PA, USA.
Asso-ciation for Computational Linguistics.Yashar Moshfeghi, Benjamin Piwowarski, and Joe-mon M. Jose.
2011.
Handling data sparsity in collabo-rative filtering using emotion and semantic based fea-tures.
In Proceedings of the 34th international ACMSIGIR conference on Research and development in In-formation Retrieval, SIGIR ?11, pages 625?634.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Found.
Trends Inf.
Retr., 2(1-2):1?135, January.Ana-Maria Popescu and Oren Etzioni.
2005.
Extract-ing product features and opinions from reviews.
InProceedings of the conference on Human LanguageTechnology and Empirical Methods in Natural Lan-guage Processing, HLT ?05, pages 339?346, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2009.Expanding domain sentiment lexicon through doublepropagation.
In Proceedings of the 21st internationaljont conference on Artifical intelligence, IJCAI?09,pages 1199?1204, San Francisco, CA, USA.
MorganKaufmann Publishers Inc.Ruslan Salakhutdinov and Andriy Mnih.
2008.
Prob-abilistic matrix factorization.
In Advances in NeuralInformation Processing Systems, volume 20.Chong Wang and David M. Blei.
2011.
Collaborativetopic modeling for recommending scientific articles.In Proceedings of the 17th ACM SIGKDD interna-tional conference on Knowledge discovery and datamining, pages 448?456.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-levelsentiment analysis.
In HLT/EMNLP.Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.2009.
Phrase dependency parsing for opinion mining.In Proceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing: Volume 3- Volume 3, EMNLP ?09, pages 1533?1541, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.410
