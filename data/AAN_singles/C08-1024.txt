Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 185?192Manchester, August 2008Looking for TroubleStijn De Saeger Kentaro TorisawaLanguage Infrastructure GroupNational Institute of Informationand Communications Technology{stijn,torisawa}@nict.go.jpJun?ichi KazamaSchool of Information ScienceJapan Advanced Instituteof Science and Technologykazama@jaist.ac.jpAbstractThis paper presents a method for miningpotential troubles or obstacles related tothe use of a given object.
Some exam-ple instances of this relation are ?medicine,side effect?
and ?amusement park, heightrestriction?.
Our acquisition method con-sists of three steps.
First, we use an un-supervised method to collect training sam-ples from Web documents.
Second, a setof expressions generally referring to trou-bles is acquired by a supervised learningmethod.
Finally, the acquired troublesare associated with objects so that eachof the resulting pairs consists of an ob-ject and a trouble or obstacle in using thatobject.
To show the effectiveness of ourmethod we conducted experiments usinga large collection of Japanese Web doc-uments for acquisition.
Experimental re-sults show an 85.5% precision for the top10,000 acquired troubles, and a 74% pre-cision for the top 10% of over 60,000 ac-quired object-trouble pairs.1 IntroductionThe Stanford Encyclopedia of Philosophy definesan artifact as ?.
.
.
an object that has been inten-tionally made or produced for a certain purpose?.Because of this purpose-orientedness, most humanactions relating to an object or artifact fall intotwo broad categories ?
actions relating to its in-tended use (e.g.
reading a book), and the prepa-rations necessary therefore (like buying the book).Information concerning potential obstacles, harm-ful effects or troubles that interfere with this in-tended use is therefore highly relevant to the user.c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.While some such troubles are self-evident, othersrepresent a genuine obstacle whose existence wasthusfar unknown to the user.
For example, in early2008 a food poisoning case caused a big media stirin Japan when dozens of people fell ill after eatingChinese-imported frozen food products containingresidual traces of toxic pesticides.
While suppos-edly the presence of toxic chemicals in importedfrozen foods had already been established on sev-eral occasions before, until the recent incidentspublic awareness of these facts remained low.
Inretrospect, a publicly available system suggesting?residual agrichemicals?
as a potential danger withthe consumption of ?frozen foods?
based on in-formation mined from a large collection of Webdocuments might have led to earlier detection ofthis crisis.
From the viewpoint of manufacturersas well, regularly monitoring the Internet for prod-uct names and associated troubles may allow themto find out about perceived flaws in their productssooner and avoid large scale recalls and damage totheir brand.For a less dramatic example, searching for?Tokyo Disneyland?
on the Internet typicallyyields many commercial sites offering travel deals,but little or no information about potential ob-stacles such as ?height restrictions?
(constraintson who can enjoy a given attraction1) and ?traf-fic jams?
(a necessary preparation for enjoying atheme park is actually getting there in time).
Ofterusers have no way of finding out about this untilthey actually go there.These examples demonstrate the importance ofa highly accurate automatic method for acquir-ing what we will call ?object-trouble?
relations ?pairs ?eo, et?
in which the thing referred to by etconstitutes an (actual or potential) trouble, obsta-cle or risk in the context of use of an object eo.1For example, one has to be over 3 ft. tall to get on theSplash Mountain.185Large scale acquisition of this type of contextualknowledge has not been thoroughly studied so far.In this paper, we propose a method for automati-cally acquiring Japanese noun phrases referring totroubles, (henceforth referred to as trouble expres-sions), and associating them with expressions de-noting artifacts, objects or facilities.Our acquisition method consists of three steps.As a first step, we use an unsupervised method forefficiently collecting training data from a Web cor-pus.
Then, a set of expressions denoting troubles isacquired by a supervised learning method ?
Sup-port Vector Machines (Vapnik, 1998) ?
trained onthis data.
Finally, the acquired trouble expressionsare paired with noun phrases referring to objects,using a combination of pairwise mutual informa-tion and a verb-noun dependency filter based onstatistics in a Web corpus.A broad focus on noun-verb dependencies ?and in particular the distinction between depen-dency relations with negated versus non-negatedverbs ?
is the main characteristic of our method.While this distinction did not prove useful for im-proving the supervised classifier?s performance instep 2, it forms the basis underlying the unsuper-vised method for training sample selection in thefirst step, and the final filtering mechanism in thethird step.The rest of this paper is organized as follows.Section 2 points out related work.
Section 3 ex-amines the notion of trouble expressions and theirevidences.
Section 4 describes our method, whoseexperimental results are discussed in Section 5.2 Related WorkOur goal of automatically acquiring object-troublepairs from Web documents is perhaps best viewedas a problem of semantic relation extraction.
Re-cently the Automatic Content Extraction (ACE)program (Doddington et al, 2004) is a well-known benchmark task concerned with the au-tomatic recognition of semantic relations fromunstructured text.
Typical target relations in-clude ?Reaction?
and ?Production?
(Pantel andPennacchiootti, 2006), ?person-affiliation?
and?organization-location?
(Zelenko et al, 2002),?part-whole?
(Berland and Charniak, 1999; Girjuet al, 2006) and temporal precedence relations be-tween events (Chklovski and Pantel, 2004; Tori-sawa, 2006).
Our current task of acquiring ?object-trouble?
relations is new and object-trouble rela-tions are inherently more abstract and indirect thanrelations like ?person-affiliation?
?
they cruciallydepend on additional knowledge about whetherand how a given object?s use might be hamperedby a specific trouble.Another line of research closely related to ourwork is the recognition of semantic orientation andsentiment analysis (Turney, 2002; Takamura et al,2006; Kaji and Kitsuregawa, 2006).
Clearly trou-bles should be associated with a negative orien-tation of an expression, but studies on the acqui-sition of semantic orientation traditionally do notbother with the context of evaluation.
While re-cent work on sentiment analysis has started to as-sociate sentiment-related attribute-evaluation pairsto objects (Kobayashi et al, 2007), these attributesusually concern intrinsic properties of the objects,such as a digital camera?s colors ?
they do notextend to sentiment-related factors external to theobject like ?traffic jams?
for theme parks.
The ac-quisition method proposed in this work addressesboth these matters.Finally, our task of acquiring trouble expres-sions can be regarded as hyponymy acquisition,where target expressions are hyponyms of theword ?trouble?.
Although we used the classicallexico-syntactic patterns for hyponymy acquisition(Hearst, 1992; Imasumi, 2001; Ando et al, 2003)to reflect this intuition, our experiments show wewere unable to attain satisfactory performance us-ing lexico-syntactic patterns alone.
Thus, we alsouse verb-noun dependencies as evidence in learn-ing (Pantel and Ravichandran, 2004; Shinzato andTorisawa, 2004).
We treat the evidences uniformlyas elements in a feature vector given to a super-vised learning method, which allowed us to ex-tract a considerably larger number of trouble ex-pressions than could be acquired by sparse lexico-syntactic patterns alone, while still keeping decentprecision.
What kind of hyponymy relations canbe acquired by noun-verb dependencies is still anopen question in NLP.
In this work we show thatat least trouble expressions can successfully be ac-quired based on noun-verb dependency informa-tion alone.3 Trouble Expressions and Features forTheir AcquisitionIn section 1 we have characterized trouble expres-sions as a kind of ?trouble?
that occurs in the spe-cific context of using some object, in other words:1861. hyponym ni nita hypernym(hyponym similar to hypernym)2. hyponym to yobareru hypernym(hypernym called hyponym)3. hyponym igai no hypernym(hypernym other than hyponym)4. hyponym no youna hypernym(hypernym like hyponym)5. hyponym to iu hypernym(hypernym called hyponym)6. hyponym nado(no|,) hypernym(hypernym such as hyponym)Table 1: Japanese lexico-syntactic patterns for hy-ponymy relationsas hyponyms of ?trouble?.
Hence one source of ev-idence for acquisition are hyponymy relations with?trouble?
or its synonyms.
Another characteriza-tion of trouble expressions is to think of them asobstacles in a broad sense: things that prevent cer-tain actions from being undertaken properly.
Inthis sense traffic jams and sickness are troublessince they prevent people from going places anddoing things.
This assumption underlies a secondimportant class of evidences for learning.More precisely, the evidence used for learning isclassified into three categories: (i) lexico-syntacticpatterns for hyponymy relations, (ii) dependencyrelations between expressions and negated verbs,and (iii) dependency relations between expres-sions and non-negated verbs.
The first two cat-egories are assumed to contain positive evidenceof trouble expressions, while we assumed the thirdto function mostly as negative evidence.
Our ex-periments show that (i) turns out to be less usefulthan expected, while the combination of (ii) and(iii) alone already gave quite reasonable precisionin acquiring trouble expressions.
Each category ofevidence is described further below.3.1 Lexico-syntactic patterns for hyponymySince trouble expressions are hyponyms of ?trou-ble?, one obvious way of acquiring trouble expres-sions is to use classical lexico-syntactic patternsfor hyponymy acquisition (Hearst, 1992).
Table1 lists some of the patterns proposed in studieson hyponymy acquisition for Japanese (Ando etal., 2003; Imasumi, 2001) that are utilized in thiswork.In actual acquisition, we instantiated the hy-pernym positions in the patterns by Japanesetranslations of ?trouble?
and its synonyms,namely toraburu (troubles), sainan (acci-dents), saigai (disasters) and shougai (obsta-cles or handicaps), and used the instantiated pat-terns as evidence.
Hereafter, we call these pat-terns LSPHs (Lexico-Syntactic Patterns for Hy-ponymy).3.2 Dependency relations with VerbsWe expect expressions that frequently refer totroubles to have a distinct dependency profile, bywhich we mean a specific set of dependency rela-tions with verbs (i.e.
occurrences in specific argu-ment positions).
If T is a trouble expression, thengiven a sufficiently large corpus one would expectto find a reasonable number of instantiations ofpatterns like the following:?
T kept X from doing Y .?
X didn?t enjoy Y because of T .Similarly, ?X enjoyed T ?
would present neg-ative evidence for T being a trouble expression.Rather than single out a set of particular depen-dency relations suspected to be indicative of trou-ble expressions, we let a supervised classifier learnan appropriate weight for each feature in a largevector of dependency relations.
Two classes of de-pendency relations proved to be especially benefi-cial in determining trouble candidates in an unsu-pervised manner, so we discuss them in more detailbelow.Dependency relations with negated verbs Fol-lowing our characterization of troubles as thingsthat prevent specific actions from taking place, weexpect a good deal of trouble expressions to appearin patterns like the following.?
X cannot go to Y because of T .?
X did not enjoy Y because of T .The important points in the above are (i) thenegated verbs and (ii) the mention of T as the rea-son for not verb-ing.
The following are Japanesetranslations of the above patterns.
Here P denotespostpositions (Japanese case markers), V standsfor verbs and the phrase ?because of?
is translatedas the postposition de.
?T de Y ni ikenai.P P V (cannot go)?T de X ga tanoshikunakatta.P P V (did not enjoy)187We refer to the following dependency relationsbetween expressions marked with the postpositionde and negated verbs in these patterns as DNVs(Dependencies to Negated Verbs).T de ?
negated verb (1)We allow any verb to be the negated verb, expect-ing that inappropriate verbs will be less weightedby machine learning techniques.
For instance,the dependency relations to negated verbs with anoriginally negative orientation such as ?suffer?
and?die?
will not work as positive examples for trou-ble expressions.Unfortunately, these patterns still present onlyweak evidence for trouble expressions.
The pre-cision of the trouble expressions collected usingDNV patterns is extremely low ?
around 6.5%.This is due to the postposition de?s ambiguity ?besides ?because of?
relations it also functions as amarker for location, time and instrument relations,among others.
As a result, non-trouble expressionssuch as ?by car?
(instrument) and ?in Tokyo?
(lo-cation) are marked by the postposition de as well.We consider a second class of dependency rela-tions, acting mostly as a counter to the noisy ex-pressions introduced by the ambiguity of the post-position de.Dependency relations with non-negated verbsThe final type of evidence is formulated as the fol-lowing dependency relation.T de ?
non-negated verbWe call this type of relation DAVs (Dependen-cies to Affirmative Verbs).
The use of these pat-terns is motivated by the intuition that noisy ex-pressions found with DNVs, such as expressionsabout locations or instruments, will also frequentlyappear with non-negated verbs.
That is, if you ob-serve ?cannot go to Y (by / because of) X?
and Xis not a trouble expression, then you can expect tofind ?can go to Y (by / because of) X?
as well.Our initial expectation was that the DNV andDAV evidences observed with the postposition dealone would contain sufficient information to ob-tain an accurate classifier, but this expectation wasnot borne out by our early experiments.
As itturns out, using dependency relations to verbs inall argument positions as features to the SVM re-sulted roughly in a 10?15% increase in precision.Therefore in our final experiments we let the DNVand DAV evidence consist of dependencies withfour additional postpositions (ha, ga, wo and ni),which are used to indicate topicalization, subject,object and indirect object.
We found that the SVMwas quite successful in learning a dependency pro-file for trouble expressions based on this informa-tion.Nonetheless, the DNV/DAV patterns proved tobe useful besides as evidence for supervised learn-ing, for instance in gathering sufficient trouble can-didates and sample selection when preparing train-ing data2.4 MethodAs mentioned, our method for finding troublesin using some objects consists of three steps, de-scribed in more detail below.Step 1 Gather training data with a sufficientamount of positive samples using an unsuper-vised method to reduce the workload of man-ual annotation.Step 2 Collect expressions commonly perceivedas troubles by using the evidences describedin the previous section.Step 3 Identify pairs of trouble expressions andobjects such that the trouble expressions rep-resent an obstacle in using the objects.4.1 Step 1: Gathering Training DataWe considered noun phrases observed with theLSPH and DNV evidences as candidate trouble ex-pressions.
However, we still found only 7% ofthe samples observed with these evidences to bereal troubles.
Because of the diversity of our ev-idences (dependencies with verbs) we need a rea-sonable amount of positive samples in order to ob-tain an accurate classifier.
Without some sampleselection scheme, we would have to manually an-notate about 8000 samples in order to obtain only560 positive samples in the training data.
For thisreason we used the following scoring function asan unsupervised method for sample selection.Score(e) =fLSPH(e) + fDNV(e)fLSPH(e) + fDNV(e) + fDAV(e)(2)Here, fLSPH(e), fDNV(e) and fDAV(e) are the fre-quencies that expression e appears with the re-spective evidences.
Intuitively, this function gives2We will discuss yet another use of the DNV evidence instep 2 of our acquisition method.188a large score to expressions that occur frequentlywith the positive evidences for trouble expressions(LSPHs and DNVs), or those that appear rarelywith the negative evidences (DAVs).
In prepar-ing training data we ranked all candidates accord-ing to the above score, and annotated N elementsfrom the top and bottom of the ranking as train-ing data.
In our experiments, the top elements in-cluded a reasonable number of positive samples(25.8%) while there were almost none in the worstelements.4.2 Step 2: Finding Trouble ExpressionsIn this step our aim is to acquire expressions of-ten associated with troubles.
We use a super-vised classifier, namely Support Vector Machines(SVMs) (Vapnik, 1998) for distinguishing trou-bles from non-troubles, based on the evidences de-scribed above.
Each dimension of the feature vec-tor presented to the SVM corresponds to the obser-vation of a particular evidence (i.e., these are bi-nary features).
We tried using frequencies insteadof binary feature values but could not find any sig-nificant improvement in performance.
After learn-ing we sort the candidate trouble expressions ac-cording to their distance to the hyperplane learnedby the SVM, and consider the top N expressionsin the sorted list as true trouble expressions.4.3 Step 2: Identifying Object-Trouble PairsIn this third stage we rank possible combinationsof objects and trouble expressions acquired in theprevious step according to their degree of associ-ation and apply a filter using negated verbs to thetop pairs in the ranking.
The final output of ourmethod is the top N pairs that survived the filter-ing.
We describe each step below.Generating Object-Trouble Pairs To generateand rank object-trouble pairs we use a variant ofpairwise mutual information that scores an object-trouble pair ?eo, et?
based on the observed fre-quency of the following pattern.eono etP(3)The postposition no is a genitive case marker, andthe whole pattern can be translated as ?etof / ineo?.
We assume that appearance of expression etin this pattern refers to a trouble in using the objecteo.More precisely, we generate all possible combi-nations of trouble expression and objects and rankthem according to the following score.I(eo, et) =f(?eono et?)f(?eo?)f(?et?
)(4)where f(e) denotes an expression e?s frequency.This score is large when the pattern ?eono et?is observed more frequently than can be expectedfrom eoand et?s individual frequencies.
Frequencydata for all noun phrases was precomputed for thewhole Web corpus.Filtering Object-Trouble Pairs The filtering inthe second step is based on the following assump-tion.Assumption If a trouble expression etrefers to atrouble in using an object eo, there is a verb vsuch that v frequently co-occurs with eoandv has the following dependency relation withet.etde ?
negated vThe intuition behind this assumption can be ex-plained as follows.
First, if eodenotes an object orartifact then its frequently co-occurring verbs arelikely to be related to a use of eo.
Second, if etis atrouble in using eo, there is some action associatedwith eothat etprevents or hinders, implying that etshould be observed with its negation.
For instance,if ?traffic jam?
is a trouble in using an amusementpark, then we can expect the following pattern toappear also in a corpus.
?juutai de yuuenchi ni ikenai.traffic jam P theme park P V (cannot go)cannot go to a theme park because of a traffic jamThe verb ?to go?
co-occurs often with the noun?theme park?
and the above pattern contains thedependency relation ?traffic jam de?
cannot go?.Substituting v in the hypothesis for ?to go?, the as-sumption becomes valid.
Because of data sparse-ness the above pattern may not actually appear inthe corpus, but even so the dependency relation?traffic jam de ?
cannot go?
may be observedwith other facilities, and thus making the assump-tion hold anyway.As a final filtering procedure, we gathered Kverbs most frequently co-occurring with each ob-ject and checked if the trouble expression in thepair has dependency relations with the K verbs in189negated form and the postposition de.
If none ofthe K verbs has such a dependency with the trou-ble expression, the pair is discarded.
Otherwise, itis produced as the final output of our method.5 Experimental Results5.1 Finding Trouble ExpressionsWe extracted noun phrases observed in LSPH,DNV and DAV patterns from 6?
109sentences inabout 108crawled Japanese Web documents, andused the LSPH and DNV data3as candidate trou-ble expressions.
After restricting the noun phrasesto those observed more than 10 times in the evi-dences, we had 136,212 noun phrases.
We denotethis set asD.
Extracting 200 random samples fromD we found the ratio of troubles to non-troubleswas around 7% and thus expected to find about10, 000 real trouble expressions in D.4Using the sample selection method described inSection 4.2 we prepared 6,500 annotated samplestaken from D as training data.
The top 3,500 sam-ples included 912 positive samples and the worst3,000 had just 9 positives, thereby confirming theeffectiveness of the scoring function for selectinga reasonable amount of positive samples.
Our finaltraining data thus contained 14% positives.For the feature vectors we included dependen-cies with all verbs occurring more than 30 timesin our Web corpus.
Besides the LSPH, DNV andDAV evidences discussed previously, we also in-cluded 10 additional binary features indicating foreach of the five postpositions whether the expres-sion was observed with DNV or DAV evidence atall, and found that including this information im-proved performance.We trained a classifier with a polynomial kernelof degree 1 on these evidences using the softwareTinySVM5, and evaluated the results obtained bythe supervised acquisition method by asking threehuman raters whether a randomly selected sampleexpression denotes a kind of ?trouble?
in generalsituations.
More specifically, we asked whetherthe expression is a kind of toraburu (trou-ble), sainan (accident), saigai (disaster) orshougai (obstacle or handicap).6For various3We restricted noun phrases from the DNV data to thosefound with the postposition de, as these are most likely torefer to troubles.4Thus, in the experiments we evaluated the top 10,000samples output by our method.5http://chasen.org/?taku/software/TinySVM/6Actually one of the raters is a co-author of this paper, but0204060801000  20  40  60  80  100Precision (%)Number of Samples (%)randomLSPHScorefullw/o LSPHw/o DAVw/o DNVw/o sum DAV/DNVFigure 1: Performance of trouble expression ac-quisition (all 3 raters)combinations of evidences (described below), wepresented 200 randomly sampled expressions fromthe top 10,000 expressions ranked according to thedistance to the hyperplane learned by the SVM.Samples of all the compared methods are mergedand shuffled before evaluation.
The kappa statisticfor assessing the inter-rater agreement was 0.78,indicating substantial agreement according to Lan-dis and Koch, 1977.7We made no effort to removesamples used in training from the experiment, andfound that the samples scored by the raters (1281in total, after removal of duplicates) contained 67training samples.
The 200 samples from the ?full?classifier contained 12 of these.Fig.
1 shows the precision of the acquired trou-ble expressions compared to the samples labeledas troubles by all three raters.
We sorted the sam-ples according to their distance to the SVM hyper-plane and plotted the precision of the top N sam-ples.
The best overall precision (85.5%) was ob-tained by a classifier trained on the full combina-tion of evidences (labeled ?full?
in Fig.
1), main-taining over 90% precision for the top 70% of the200 samples.The remaining results show the relative con-tributions of the evidences.
They were obtainedby retraining the ?full?
classifier with a particu-lar set of evidences removed, respectively LSPHevidences (labeled ?w/o LSPH?
), DNV evidences(?w/o DNV?
), DAV evidences (?w/o DAV?)
andthe 10 features indicating the observation ofhe had no knowledge of the experimental setting nor had seenthe acquired data prior to the experiment.7This kappa value was calculated over the sum total ofsamples presented to the raters for scoring (duplicates re-moved).19020304050607080901000  20  40  60  80  100Precision (%)Number of Samples (%)randomtop 10% MItop 50% MItop 10% proposedtop 50% proposedFigure 2: Performance of object-trouble pair ac-quisition (3 raters)DAV/DNV evidence per postposition (?w/o sumDAV/DNV?
).As Fig.
1 shows, leaving out DNV and evenLSPH evidences did not affect performance asmuch as we expected, while leaving out the DAVdependencies gave more than 20% worse results.Of further interest is the importance of the binaryfeatures for DAV/DNV presence per postposition(?w/o sum DAV/DNV?).
The absence of these 10binary features accounts for a 10% precision losscompared to the full feature set (75%).We also compared it with a baseline method us-ing only lexico-syntactic patterns.
We extracted100 random noun phrases from the LSPH evidencein D for evaluation (?LSPH?
in Fig.
1).
The pre-cision for this method was 31%, confirming thatlexico-syntactic patterns for hyponymy constitutefairly weak evidence for predicting trouble expres-sions when used alone.
?Score?
shows the preci-sion of the top 100 samples output by our Scorefunction from section 4.
Finally, ?random?
(drawnas a straight line) denotes 100 random samplesfrom D and roughly corresponds to our estimateof 7% true positives.5.2 Identifying Object-Trouble PairsFor the second step, we assumed the top 10,000 ex-pressions obtained by our best-scoring supervisedlearning method (?full?
in the previous experi-ments) to be trouble expressions, and proceededto combine them with terms denoting artifacts orfacilities.We randomly picked 2,500 words that ap-peared as direct objects of the verbs kau (?tobuy?
), tsukau (?to use?
), tsukuru (?to make?
),taberu (?to eat?)
and tanoshimu (?to enjoy?
)rank/raters object trouble expressions1/3 kousoku douro sakeyoi unten(highway) (drunk driving)7/3 kouseibushitsu ranyou(antibiotics) (abuse)8/3 suidousui suiatsu teika(tap water) (drop in water pressure)21/3 nouyaku zanryuubushitsu(agrichemicals) (residue)98/2 kikai gohandan(machine) (judgement error)136/3 zaisan souzoku funsou(estate) (succession dispute)Figure 3: Examples of acquired object-troublepairsmore than 500 times in our Web corpus, assumingthat this would yield a representative set of nounphrases denoting objects or artifacts.8Combiningthis set of objects with the acquired trouble expres-sions gave a list of 61,873 object-trouble pairs (allpairs ?eo, et?
with at least one occurrence of thepattern ?eono et?).
Of this list, 58,570 pairs sur-vived the DNV filtering step and form the final out-put of our method.
For the DNV filtering, we usedthe top 30 verbs most frequently co-occurring withthe object.We again evaluated the resulting object-troublepairs by asking three human raters whether the pre-sented pairs consist of an object and an expressionreferring to an actual or potential trouble in usingthe object.
The kappa statistic was 0.60, indicatingmoderate inter-rater agreement.Fig.
2 shows the precision of the acquired pairswhen comparing with what are considered trueobject-trouble relations by all three raters.
Someexamples of the pairs obtained by our method arelisted in table 3 along with their ranking and thenumber of raters who judged the pair to be correct.The precision for our proposed method whenconsidering the top 10% of pairs ranked by the Iscore and filtered by the method described in sec-tion 4.3 is 71.5% (?top 10% proposed?
in Fig.
2),which is actually worse than the results obtainedwithout the final DNV filtering (?top 10% MI?,74%).
For the first half of all samples however, wedo observe some performance increase by the fil-tering, though both methods appear to converge inthe second half of the graph.
This tendency is mir-rored closely when considering the results for thetop 50% of all pairs (respectively ?top 50% pro-posed?
and ?top 50% MI?
in Fig.
2).
The 15%decrease in precision compared to top 10% results8We manually removed pronouns from this set.191indicates that performance drops gradually whenmoving to the lower ranked pairs.6 Concluding Remarks and Future WorkWe have presented an automatic method for find-ing potential troubles in using objects, mainly ar-tifacts and facilities.
Our method acquired 10,000trouble expressions with 85.5% precision, and over6000 pairs of objects and trouble expressions with74% precision.Currently, we are developing an Internet searchengine frontend that issues warnings about poten-tial troubles related to search keywords.
Althoughwe were able to acquire object-trouble pairs withreasonable precision, we plan to make a large-scalehighly precise list of troubles by manually check-ing the output of our method.
We expect such a listto lead to even more acurate object-trouble pair ac-quisition.ReferencesAndo, M., S. Sekine, and S. Ishizaki.
2003.
Automaticextraction of hyponyms from newspaper using lexi-cosyntactic patterns.
In IPSJ SIG Technical Report2003-NL-157, pages 77?82.
in Japanese.Berland, M. and E. Charniak.
1999.
Finding parts invery large corpora.
In Proc.
of ACL-1999, pages 57?64.Chklovski, T. and P. Pantel.
2004.
Verbocean: Miningthe web for fine-grained semantic verb relations.
InProc.
of EMNLP-04.Doddington, G., A. Mitchell, M. Przybocki,L.
Ramshaw, S. Strassel, and R. Weischedel.2004.
The Automatic Content Extraction (ACE)Program?Tasks, Data, and Evaluation.
Proceedingsof LREC 2004, pages 837?840.Girju, R., A. Badulescu, and D. Moldvan.
2006.
Au-tomatic discovery of part-whole relations.
Computa-tional Linguistics, 32(1):83?135.Hearst, M. 1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Proc.
of COLING?92,pages 539?545.Imasumi, K. 2001.
Automatic acqusition of hyponymyrelations from coordinated noun phrases and apposi-tions.
Master?s thesis, Kyushu Institute of Technol-ogy.Kaji, N. and M. Kitsuregawa.
2006.
Automatic con-struction of polarity-tagged corpus from html docu-ments.
In Proc.
of COLING/ACL 2006, pages 452?459.
(poster session).Kobayashi, N., K. Inui, and Y. Matsumoto.
2007.
Ex-tracting aspect-evaluation and aspect-of relations inopinion mining.
In Proc.
of EMNLP-CoNLL 2007,pages 1065?1074.Pantel, P. and M. Pennacchiootti.
2006.
Espresso:Leveranging generic patterns for automaticallyharvesting semantic relations.
In Proc.
ofCOLING/ACL-06, pages 113?120.Pantel, P. and D. Ravichandran.
2004.
Automaticallylabelling semantic classes.
In Proc.
of HLT/NAACL-04, pages 321?328.Shinzato, K. and K. Torisawa.
2004.
Acquir-ing hyponymy relations from web documents.
InHLT/NAACL-04, pages 73?80.Takamura, H., T. Inui, and M. Okumura.
2006.
Latentvariable models for semantic orientation of phrases.In Proc.
of EACL 2006, pages 201?208.Torisawa, K. 2006.
Acquiring inference rules withtemporal constraints by using japanese coordinatedsentences and noun-verb co-occurrences.
In Moore,R.C., J.A.
Bilmes, J. Chu-Carroll, and M. Sanderson,editors, HLT-NAACL.
The Association for Computa-tional Linguistics.Turney, P. 2002.
Thumbs up or thumbs down?
seman-tic orientation applied to unsupervised classificationof reviews.
In Proc.
of ACL?02, pages 417?424.Vapnik, Vladimir N. 1998.
Statistical Learning The-ory.
Wiley-Interscience.Zelenko, D., C. Aone, and A. Richardella.
2002.
Ker-nel methods for relation extraction.
In EMNLP ?02:Proceedings of the ACL-02 conference on Empiricalmethods in natural language processing, pages 71?78, Morristown, NJ, USA.
Association for Compu-tational Linguistics.192
