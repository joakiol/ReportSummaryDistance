Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages, pages 43?53,Baltimore, Maryland, USA, 26 June 2014.c?2014 Association for Computational LinguisticsLearning Grammar Specifications from IGT: A Case Study of ChintangEmily M. Bender Joshua Crowgey Michael Wayne Goodman Fei XiaDepartment of LinguisticsUniversity of WashingtonSeattle, WA 98195-4340 USA{ebender,jcrowgey,goodmami,fxia}@uw.eduAbstractWe present a case study of the methodol-ogy of using information extracted frominterlinear glossed text (IGT) to create ofactual working HPSG grammar fragmentsusing the Grammar Matrix focusing onone language: Chintang.
Though the re-sults are barely measurable in terms ofcoverage over running text, they nonethe-less provide a proof of concept.
Our expe-rience report reflects on the ways in whichthis task is non-trivial and on mismatchesbetween the assumptions of the methodol-ogy and the realities of IGT as produced ina large-scale field project.1 IntroductionWe explore the possibility of learning precisiongrammar fragments from existing products of doc-umentary linguistic work.
A precision grammar isa grammar which encodes a sharp notion of gram-maticality and furthermore relates strings to elabo-rate semantic representations.
Such objects are ofinterest in the context of documentary linguisticsbecause: (1) they are valuable tools in the explo-ration of linguistic hypotheses (especially regard-ing the interaction of various phenomena); (2) theyfacilitate the search for examples in corpora whichare not yet understood; and (3) they can supportthe development of treebanks (see Bender et al.,2012a).
However, they are expensive to build.The present work is carried out in the context ofthe AGGREGATION project,1which is exploringwhether such grammars can be learned on the ba-sis of data already collected and enriched throughthe work of descriptive linguists, specifically, col-lections of IGT (interlinear glossed text).The grammars themselves are not likely targetsfor machine learning, especially in the absence of1http://depts.washington.edu/uwcl/aggregation/treebanks, which are not generally available forlanguages that are the focus of descriptive anddocumentary linguistics.
Instead, we take advan-tage of the LinGO Grammar Matrix customiza-tion system (Bender et al., 2002; Bender et al.,2010) which maps from collections of statementsof linguistic properties (encoded in choices files)to HPSG (Pollard and Sag, 1994) grammar frag-ments which in turn can be used to parse stringsinto semantic representations in the format of Min-imal Recursion Semantics (MRS; Copestake et al.,2005) and conversely, to generate strings fromMRS representations.
The choices files are amuch simpler representation than the grammarsderived from them and therefore a more approach-able learning target.
Furthermore, using the Gram-mar Matrix customization system to produce thegrammars results in much less noise in the auto-matically derived grammar code than would arisein a system learning grammars directly.Here, we focus on a case study of Chintang, aKiranti language of Nepal, described by the Chin-tang Language Research Project (CLRP) (Bickelet al., 2009).
Where Lewis and Xia (2008) andBender et al.
(2013) apply similar methodologiesto extract large scale properties for many lan-guages, we focus on a case study of a single lan-guage, looking at both the large scale propertiesand the lexical details.
This is important for tworeasons: First, it gives us a chance to look in-depth at the possible sources of difficulty in ex-tracting the large scale properties.
Second, whilelarge-scale properties are undoubtedly important,the bulk of the information specified in a preci-sion grammar is far more fine-grained.
In thiscase study we apply the methodology of Bender etal.
(2013) to extract general word order and caseproperties and examine the sources of error affect-ing those results.
We also explore extensions ofthose methodologies and that of Wax (2014) to ex-tract lexical entries and specifications for morpho-43logical rules.
Together with a few default spec-ifications, this information is enough to allow usto define grammars through the Grammar Matrixcustomization system and thus evaluate the resultsin terms of parsing coverage, accuracy and am-biguity over running text.
Chintang is particu-larly well-suited for this case study because it isan actual endangered language subject to activedescriptive research, making the evaluation of ourtechniques realistic.
Furthermore, the descriptiveresearch on Chintang is fairly advanced, havingproduced both large corpora of high-quality IGTand sophisticated linguistic descriptions, makingthe evaluation and error analysis possible.2 Related WorkThis work can be understood as a task related toboth grammar induction and grammar extraction,though it is distinct from both.
It also connectswith and extends previous work using interlinearglossed text to extract grammatical properties.Grammar induction (Clark, 2001; Klein andManning, 2002; Klein and Manning, 2004;Haghighi and Klein, 2006; Smith and Eisner,2006; Snyder et al., 2009, inter alios) involves thelearning of grammars from unlabeled sentences.Here, unlabeled means that the sentences are of-ten POS tagged, but no syntactic structures forthe sentences are available.
Most of those stud-ies choose probabilistic context-free grammars(PCFGs) or dependency grammars as the gram-mar framework, and estimate the probability ofthe context-free rules or dependency arcs from thedata.
These studies improve parsing performancesignificantly over some baselines such as the EMalgorithm, but the induced grammars are very dif-ferent from precision grammars with respect tocontent, quality, and grammar framework.Grammar extraction, on the other hand, learnsgrammars (sets of rules) from treebanks.
Here theidea is to use heuristics to convert the syntacticstructures in a treebank into derivation trees con-forming to a particular framework, and then ex-tract grammars from those trees.
This has beendone in a wide range of grammar frameworks, in-cluding PCFG (e.g.
Krotov et al., 1998), LTAG(e.g.
Xia, 1999; Chen and Vijay-Shanker, 2000),LFG (e.g.
Cahill et al., 2004), CCG (e.g.
Hock-enmaier and Steedman, 2002, 2007), and HPSG(e.g.
Miyao et al., 2004; Cramer and Zhang, 2009).However, this approach is not applicable to workword-order=v-finalhas-dets=yesnoun-det-order=det-noun...case-marking=erg-abserg-abs-erg-case-name=ergerg-abs-abs-case-name=abs...verb4_valence=erg-absverb4_stem1_orth=sams-i-neverb4_stem1_pred=_sams-i-ne_v_re...verb-pc3_inputs=verb-pc2verb-pc3_lrt1_name=2nd-person-subjverb-pc3_lrt1_feat1_name=pernumverb-pc3_lrt1_feat1_value=2ndverb-pc3_lrt1_feat1_head=subjverb-pc3_lrt1_lri1_inflecting=yesverb-pc3_lrt1_lri1_orth=a-Figure 1: Excerpts from a choices fileon endangered language documentation, as tree-banks are not available for such languages.A third line of research attempts to bootstrapNLP tools for resource-poor languages by takingadvantage of IGT data and resources for resource-rich languages.
The canonical form of an IGT in-stance includes a language line, a word-to-wordor morpheme-to-morpheme gloss line, and a trans-lation line (typically in a resource-rich language).The bootstrapping process starts with word align-ment of the language line and translation line withthe help of the gloss line.
Then the translation lineis parsed and the parse tree is projected to the lan-guage line using the alignments (Xia and Lewis,2007).
The projected trees can be used to answerlinguistic questions such as word order (Lewisand Xia, 2008) or bootstrap parsers (Georgi et al.,2013).
Our work extends this methodology to theconstruction of precision grammars.3 MethodologyOur goal in this work is to automatically createchoices files on the basis of IGT data.
The choicesfiles encode both general properties about the lan-guage we are trying to model as well as more spe-cific information including lexical classes, lexicalitems within lexical classes and definitions of lexi-cal rules.
Lexical rule definitions can include bothmorphotactic information (ordering of affixes) aswell as morphosyntactic information, though hereour focus is on the former.
Sample excerpts froma choices file are given in Fig 1.
These choicesfiles are then input into the Grammar Matrix cus-tomization system2which produces HPSG gram-2SVN revision (for reproducibility): 27678.44mar fragments that meet the specifications in thechoices files.
The Grammar Matrix customizationsystem provides analyses of a range of linguisticphenomena.
Here, we focus on a few that we con-sider the most basic: major constituent word or-der, the general case system, case frames for spe-cific verbs, case marking on nouns, and morpho-tactics for verbs.
In ?3.1 we describe the datasetwe are working with.
?3.2 describes the differentapproaches we take to building choices files on thebasis of this dataset.
?3.3 explains the metrics wewill use to evaluate the resulting grammars in ?4.3.1 The Chintang DatasetChintang (ISO639-3: ctn) is a language spoken byabout 5000 people in Nepal and believed to be-long to the Eastern subgroup of the Kiranti lan-guages, which in turn are argued to belong to thelarger Tibeto-Burman family (Bickel et al., 2007;Schikowski et al., in press).
Here we briefly sum-marize properties of the language that relate tothe information we are attempting to automaticallydetect in the IGT, and in many cases make theproblem interestingly difficult.Schikowski et al.
(in press) describe Chintangas exhibiting information-structurally constrainedword order: All permutations of the major senten-tial constituents are expected to be valid, with thedifferent orders subject to different felicity condi-tions.
They state, however, that no detailed analy-sis of word order has yet been carried out, and sothis description should be taken as preliminary.In contrast, much detailed work has been doneon the marking of arguments, both via agree-ment on the verb and via case marking of depen-dents (Bickel et al., 2010; Stoll and Bickel, 2012;Schikowski et al., in press).
The case marking sys-tem can be understood as following an ergative-absolutive pattern, but with several variations fromthat theme.
In an ergative-absolutive pattern, thesole argument of an intransitive verb (here calledS) is marked the same as the most patient-like ar-gument of a transitive verb (here called O) anddifferentiated from the most agent-like argumentof a transitive verb (here called A).
Most A ar-guments are marked with an overt case markercalled ergative, while S and O arguments appearwithout a case marker.
In most writing about thelanguage, this unmarked case is called nomina-tive; here we will use the term absolutive.
Simi-larly, verbs agree with up to two arguments, andthe agreement markers for S and O are generallyshared and distinguished from those for A.Divergences from the ergative-absolutive pat-tern include variable marking of ergative case onfirst and second person pronouns as well as va-lence alternations such as one that licenses oc-currences of transitive verbs with two absolutivearguments (and S-style agreement with the A ar-gument) when the O argument is of an indefinitequantity (Schikowski et al., in press).
Further-more, the language allows dropping of arguments(A, S, and O).
Finally, there are of course valencesbeyond simple intransitive and transitive, as wellas case frames even for two-argument verbs otherthan { ERG, ABS }.
As a result of the combination ofthese facts, the actual occurrence of ergative-case-marked arguments in speech is relatively low: Ex-amining a corpus of speech spoken to and aroundchildren, Stoll and Bickel (2012) find that only11% of (semantically) transitive verb tokens havean overt, ergative-marked NP A argument.
As dis-cussed below, these properties make it difficult forautomated methods to detect both the overall casesystem of the language and accurate informationregarding the case frames of individual verbs.The dataset we are using contains 9793 (8863train, 930 test) IGT instances which come fromthe corpus of narratives and other speech col-lected, transcribed, translated and glossed by theCLRP.3An example is shown in Fig.
2.
As canbe seen in Fig.
2, the glossing in this dataset is ex-tremely thorough.
It is also supported by a detailedToolbox lexicon that encodes not only alternativeforms for each lemma as well as glosses in Englishand Nepali, but also valence frames for most verbentries which list the expected case marking onthe arguments.
Finally, note that morphosyntacticproperties without a morphological reflex are sys-tematically unglossed in the data, so that ABS neverappears (nor does SG for singular nouns, etc.
).In our experiments, we abstract away from theproblem of morphophonological analysis in orderto focus on morphosyntax and lexical acquisition.Accordingly, our grammars target the second lineof the IGT, which represents each form as a se-quence of phonologically regularized morphemes.3.2 GrammarsIn this section, we describe the different means weuse for extracting the different kinds of informa-3http://www.spw.uzh.ch/clrp45unisaNau-nisa-Na3sPOSS-younger.brother-ERG.Akhattekhatt-etake-IND.PSTmomoDEM.DOWNkosikosi-iriver-LOCmobamo-peDEM.DOWN-LOC?The younger brother took it to the river.?
[ctn] (Bickel et al., 2013c)Figure 2: Sample IGTtion required to build the choices files (see Fig 1above).
We first describe our points of comparison(oracle, ?3.2.1 and baseline, ?3.2.2), and then con-sider different ways of detecting the large-scaleproperties (word order, ?3.2.3; overall case sys-tem, ?3.2.4).
Next we turn to different ways of ex-tracting two kinds of lexical information: the con-straints on case (i.e.
case frames of verbs and thecase marking on nouns, ?3.2.5) and verbal mor-photactics (?3.2.6).
Finally, we describe a smallset of hand-coded ?choices?
which are added to allchoices files (except the oracle one) in order to cre-ate working grammars (?3.2.7).The alternative approaches to extracting the var-ious kinds of information can be cross-classifiedwith each other, giving the set of choices files de-scribed in Table 1.
The first column gives iden-tifiers for the choices files.
The second specifieshow the lexicon was created, the third how thevalue for major constituent word order was deter-mined, and the fourth how the values for case weredetermined, including the overall case system, thecase frames, and the case values for nouns.
Theseoptions are all described in more detail below.3.2.1 Oracle choices fileAs an upper-bound, we use the choices file de-veloped in Bender et al., 2012b.
This file in-cludes hand-specified definitions of lexical rulesfor nouns and verbs as well as lexical entries cre-ated by importing lexical entries from the Tool-box lexicon developed by the CLRP.
This lex-icon, as noted above, lists valence frames formost verbal entries.
As the Grammar Matrixcustomization system currently only provides forsimple transitive and intransitive verbs, only twoverb classes were defined: intransitives with thecase frame { ABS } and transitives with the caseframe { ERG, ABS }.
In addition, there is one classof nouns.
Finally, the choices file includes hand-coded lexical entries for pronouns.
As an upper-bound, this choices file can be expected to repre-sent high precision and moderate recall: verbs thatdon?t fit the two classes defined aren?t imported.Note that the Grammar Matrix customizationsystem does not currently support the definition ofadjectives, adverbs, or other parts of speech out-side of verb, noun, determiner, (certain) adposi-tions, conjunctions and auxiliaries.
Thus while weexpect each grammar to be able to parse at leastsome sentences in the corpus, to the extent thatsentences tend to include words outside the classesnoun, verb and determiner, we expect relativelylow coverage, even from our upper-bound.3.2.2 Baseline choices fileOur baseline choices file is designed to create aworking grammar, without particular high-levelinformation about Chintang, that focuses on cov-erage at the expense of precision.
We hand-specified the (counter-factual) assertion that thereis no case marking in Chintang, and in addi-tion that Chintang allows free word order (on thegrounds that this is the least constrained word or-der possibility).
It also defines bare-bones classesof nouns, determiners and transitive verbs, andthen populates the lexicon by using a variant of themethodology in Xia and Lewis 2007.
In particu-lar, we parse the translation line using the Char-niak parser (Charniak, 1997) and then use the cor-respondences inherent in IGT to create a projectedtree structure for the language line, following Xiaand Lewis.
An example of the result for Chintangis shown in Fig 3.
The projected trees include partof speech tags for each word that can be aligned.For each such word tagged as noun, verb, or deter-miner, we create an instance in the correspondinglexical type.
In this baseline grammar, all verbsare assumed to be transitive, but since all argu-ments can (optionally) be dropped, the grammar isexpected to be able to cover intransitive sentences,even if the semantic representation is wrong.Since this baseline choices file models Chintangas if it had no case marking, we expect it the re-sulting grammar to have relatively high recall interms of the combination of nominal and verbalconstituents.
On the other hand, since it is build-ing a full-form lexicon and Chintang is a morpho-logically complex language, we expect it to haverelatively low lexical coverage on held-out data.46Choices file Lexicon Word order CaseORACLE Manual Manual ManualBASELINE Fullform Default NoneFF-AUTO-NONE Fullform Auto NoneFF-DEFAULT-GRAM Fullform Default Auto (GRAM)FF-AUTO-GRAM Fullform Auto Auto (GRAM)FF-DEFAULT-SAO* Fullform Default Auto (SAO)FF-AUTO-SAO* Fullform Auto Auto (SAO)MOM-DEFAULT-NONE MOM Default NoneMOM-AUTO-NONE MOM Auto NoneMOM-DEFAULT-GRAM* MOM Default Auto (GRAM)MOM-AUTO-GRAM* MOM Auto Auto (GRAM)MOM-DEFAULT-SAO* MOM Default Auto (SAO)MOM-AUTO-SAO* MOM Auto Auto (SAO)Table 1: Choices files generatedsvpnp-objppnpnn vbdjutta khet-a-N-eshoe buy-PST-1sS/P-IND.PSTI bought a pair of shoe .prp vbd dt nn in nnnp-subj-prp np nppp .np-objvpsFigure 3: Projected tree structure (ex.
from (Bickelet al., 2013d))3.2.3 Word orderWe applied the methodology of Bender et al.
(2013) for determining major constituent order.For our dataset, the algorithm chose ?v-final?,which matches what is in the ORACLE choices file,but is not necessarily correct.
We created two ver-sions of each of the other choices files, one withthe default (baseline) answer of ?free word order?and one with this automatically supplied answer.3.2.4 Case systemSimilarly, we applied extended versions of the twomethods for automatically discovering case sys-tems from Bender et al.
2013: GRAM which looksfor known case grams in glosses (not using pro-jected trees) and SAO which extends the structure-projection methodology of Xia and Lewis (2007)to detect S, A and O arguments and then looksfor the most frequent gram associated with eachof these.4The GRAM method determines thecase system of Chintang to be ergative-absolutive,while the SAO method indicates ?none?
(no case).Specifying a case system in a choices file has noeffect on the coverage or precision of the resultinggrammar if the lexical items don?t constrain case.Thus the case system choices only make sense incombination with the case frames choices (?3.2.5).3.2.5 Case frames and case valuesThe HPSG analysis of case involves a feature CASEwhich is constrained by both verbs and nouns:Nouns constrain their own CASE value, while verbsconstrain the CASE value of the arguments they se-lect for.5In order to constrain verbs and nounsappropriately, we first need a range of possiblecase values.
For choices files built based on theGRAM system, we consider case markers to be anyof those included in the set of grams defined bythe Leipzig Glossing Rules (Bickel et al., 2008):ABL, ABS, ACC, ALL, COM, DAT, ERG, GEN, INS, LOC,and OBL.
For choices files built based on the SAOsystem, we consider as case markers only thosegrams (automatically) identified as marking S, A,or O.
In the present study, that should only be erga-tive; as there is no marked case for absolutive, allother nouns were treated as absolutive (regardlessof their actual case marking, since the SAO systemhas no way to detect other case grams).4Our extensions involved making the system able to han-dle the situation where one or more of S, A and O are morpho-logically unmarked and therefore unreflected in the glosses.5For the details of the analyses of case systems providedby the Grammar Matrix, see Drellishak 2009.47In choices files which specify case systems, weconstrain the case value for nouns by creating onenoun class for every case value, and then assigningthe lexical entries for nouns to those lexical classesbased on the grams in the gloss of the noun.6Similarly, we create lexical classes for eachcase frame identified for transitive and intransitiveverbs: We look for case grams on each argumentof the verb, as determined by the function tags inthe projected tree (e.g.
NP-SUBJ-PRP in Fig 3).7Foreach case frame we identify, we create a lexicalclass, and we create lexical entries for verbs basedon the case frames we extract for them.
Whenthe system identifies both an overt subject and anovert object, it considers the verb to be transitiveand constrains the case of its two arguments basedon the observed case values.
If either argumentis overt but not marked for case, the verb is con-strained to select for the default case on that argu-ment, according to the detected case marking sys-tem (i.e.
ergative for transitive subjects and absolu-tive for transitive objects, in this instance).
Whenthere is an overt subject but no overt object, theverb is treated as intransitive and is constrained toselect for a subject of the observed case (or thedefault case, here absolutive, if the overt subjectbears no case marker).
When there is an overt ob-ject but no subject, the verb is assumed to be tran-sitive and the object?s case assigned as with othertransitives but the subject?s case is constrained tothe default (i.e.
ergative, in this instance).
Verbswith no overt arguments are not matched.3.2.6 MOM choices file: Automaticallyextracted lemmas and lexical rulesThe final refinement we try on our baseline isto apply the ?Matrix-ODIN Morphology?
(MOM)methodology of Wax 2014.
This methodology at-tempts to automatically identify affixes and cre-ate appropriate descriptions of lexical rules in achoices file to model those affixes.
As a result,it also identifies stems.
Thus we use the same ba-sic choices as in the baseline choices file, but nowpopulate the lexicon with stems rather than full-forms.
Compared to BASELINE, this one should re-sult in a grammar with better lexical coverage onheld-out data, to the extent that the MOM system6In future work, we plan to extend the MOM approach(?3.2.6) from verbs to nouns, but for now, the nouns aretreated as full-form lexical entries across all choices files.7While the GRAM method doesn?t require the projectedtrees to determine the overall case system, we do need themhere to find case frames for particular verbs.is able to correctly extract both stems and inflec-tional rules.
We note that while the MOM systemuses the same conceptual approach to alignment asthat in the BASELINE, GRAM and SAO approaches, theimplementation is separate, and so does not findexactly the same set of verbs.3.2.7 Shared choicesThe ORACLE choices file ran as-is.
For the re-maining choices files, we also needed to answerthe questions about determiners (whether there areany, position with respect to the noun).
Based oninitial experiments, we chose ?yes?
for the pres-ence of determiners and ?det-noun?
order.
In anattempt to boost coverage generally, we also codedthe choices that allow any argument to be dropped.While the determiner-related choices are specificto Chintang, the latter set of choices could be ex-pected to boost coverage (at the cost of some pre-cision) for any language.3.2.8 SummaryTable 1 shows the 10 logical possibilities that arisefrom combining the methods discussed in this sec-tion, in addition to the ORACLE grammar and theBASELINE grammar.
However, we test only a subsetof these possibilities for the following reasons:8The SAO system chose no case as the case systemfor Chintang.
As a result, this makes FF-DEFAULT-SAO and FF-AUTO-SAO the same as BASELINE and FF-AUTO-NONE, respectively.
In future work, we aimto improve the SAO system but until it is effec-tive enough to pick some case system for Chin-tang, these options do not require further testing.Secondly, while it is possible in principle to com-bine the output of the MOM system (which classi-fies verbs based on their morphological combina-toric potential) with the output of the system be-hind the GRAM choices files (which classifies verbsbased on their case frames), doing so is non-trivialbecause these classifications are orthogonal, yeteach verb must inherit from each dimension.
Wethus leave the exploration of MOM-DEFAULT-GRAMand MOM-AUTO-GRAM (and likewise MOM-DEFAULT-SAO and MOM-AUTO-SAO) for future work.3.3 EvaluationWe evaluate the grammars generated by thechoices files over both the data used to developthem (?training?
; 8863 items) as well as data notincluded in the development process (held-out8Untested choices files are marked with an * in the table.48?test?
data; 930 items).
We run both of these eval-uations because we are actually testing two sepa-rate questions.
The first is whether the grammarsgenerated in this way can provide useful analyti-cal tools to linguists.
In this primary use-case, weexpect a linguist to provide the system with all oftheir IGT and then use the generated grammars inorder to gain insights into that same data.
Thisdoes not amount to a case of testing on the train-ing data because the annotations provided to thesystem (IGT) are not the same as those producedby the system (full parses, including semantic rep-resentations).
However, we are still interested inalso testing on held-out data in order to answer thesecond question: whether grammars generated inthis way can also generalize to further texts.We evaluate the grammars generated by thechoices files we create in terms of lexical cov-erage, parse coverage, parse accuracy and am-biguity.
Lexical coverage measures how manyitems consist only of word forms recognized bythe grammar.
Any item with unknown lexicalitems won?t parse.9Parse coverage is the num-ber of items that receive any analysis at all, whereambiguity is the number of different analyses eachitem receives.
To measure parse accuracy, weexamined the items that parse and determinedwhich parses had semantic representations whosepredicate-argument structures plausibly matchedwhat was indicated in the gloss.4 ResultsTable 2 compares the lexical information encodedin each of the choices files in a quantitative fash-ion.
The first thing to note is that the grammarsvary widely in the size of their lexicons.
The BASE-LINE/FF lexicons are expected to be larger than theothers because they take each fully inflected formencountered as a separate lexical entry.
On theother hand, the ORACLE choices file was built on thebasis of the Toolbox lexicon (dictionary) from theCLRP and thus is effectively created on the basisof a much larger dataset.
The GRAM choices filesonly contain verbs for which a case frame couldbe identified.
If the projected tree was not inter-pretable by our extraction heuristics or if the ex-ample had no overt arguments, then the verb willnot be extracted.
The MOM choices files, on the9There are methods for handling unknown lexical items(e.g.
Adolphs et al., 2008) in more mature grammars of thistype, but these are not applicable at this stage.other hand, only need to identify verbs in the stringto be able to extract them, and should be able togeneralize across different inflected forms of thesame verb.
This gives a number of verb entriesintermediate between that for BASELINE/FF and theGRAM files.
For nouns, there is less variation: theMOM files use the same data as the BASELINE, whilethe GRAM method faces as simpler problem thanfor verbs: it only needs to identify the case gram(if any) in a noun?s gloss.
The slightly larger num-bers of nouns in the GRAM files v. the others can beexplained by the same form being glossed in twodifferent ways in the training data.The remaining differences can be briefly ex-plained as follows: The ORACLE choices file doesnot contain any entries for determiners.
The oth-ers all contain the same 240 entries; one for anyword aligned by the algorithm to a determiner inthe English translation.
Only the ORACLE and MOMchoices files attempt to handle morphology, and sofar MOM only does verbal morphology.Table 3 presents the results of parsing trainingand test data with the various grammars, in abso-lute numbers and in percentages of the entire dataset.
The ?lexical coverage?
columns indicate forhow many items the grammars were able to rec-ognize each constituent word form.
The ?itemsparsed?
columns show the number of items thatreceived any analysis at all, while ?items correct?show the number of items that were judged (byone of the authors) to have a predicate-argumentstructure that plausibly reflects the gloss given inthe IGT.
The final column shows the average num-ber of distinct analyses the grammars find for theitems they parse at all.The results are in fact barely measurable withthese metrics (especially on the test data), butnonetheless speak to the differences between thegrammars.
Regarding lexical coverage, the ORA-CLE grammar does best on the test data set.
Thisis because it is the only choices file not derivedfrom the training data.
Not surprisingly, the BASE-LINE grammar has the highest number of readingsper item parsed, followed closely by FF-AUTO-NONEwhich adds only a minor constraint on word or-der.10On the other hand, comparing the numberof items parsed to the number judged correct, ex-cept for the MOM choices files, the ?survival rate?was over 50% for all other tests.11This suggests10It is in this relative lack of constraint that BASELINEmostly clearly forms a baseline to improve upon.11The vast majority of the incorrect parses for the MOM49Choices file # verb entries # noun entries # det entries # verb affixes # noun affixesORACLE 900 4751 0 160 24BASELINE 3005 1719 240 0 0FF-AUTO-NONE 3005 1719 240 0 0FF-DEFAULT-GRAM 739 1724 240 0 0FF-AUTO-GRAM 739 1724 240 0 0MOM-DEFAULT-NONE 1177 1719 240 262 0MOM-AUTO-NONE 1177 1719 240 262 0Table 2: Amount of lexical information in each choices fileTraining Data (N = 8863) Test Data (N = 930)lexical items items average lexical items items averagechoices file coverage (%) parsed (%) correct (%) readings coverage (%) parsed (%) correct (%) readingsORACLE 1165 (13) 174 (3.5) 132 (1.5) 2.17 116 (12.5) 20 (2.2) 10 (1.1) 1.35BASELINE 1276 (14) 398 (7.9) 216 (2.4) 8.30 41 (4.4) 15 (1.6) 8 (0.9) 28.87FF-AUTO-NONE 1276 (14) 354 (4.0) 196 (2.2) 7.12 41 (4.4) 13 (1.4) 7 (0.8) 13.92FF-DEFAULT-GRAM 911 (10) 126 (1.4) 84 (0.9) 4.08 18 (1.9) 4 (0.4) 2 (0.2) 5.00FF-AUTO-GRAM 911 (10) 120 (1.4) 82 (0.9) 3.84 18 (1.9) 4 (0.4) 2 (0.2) 5.00MOM-DEFAULT-NONE 1102 (12) 814 (9.2) 52 (0.6) 6.04 39 (4.2) 16 (1.7) 3 (0.3) 10.81MOM-AUTO-NONE 1102 (12) 753 (8.5) 49 (0.6) 4.20 39 (4.2) 10 (1.1) 3 (0.3) 9.20Table 3: Resultsthat, despite the noise introduced by the automaticmethods of lexical extraction, the precision gram-mar backbone provided by the Grammar Matrixcan still provide high-quality parses.For example, the BASELINE grammar producessix parses of the string in (1):(1) dindindaykhiptukumkhipt-u-kV-mcount-3P-IND.NPST-1/2nsA?
(We) count days.?
[ctn] (Bickel et al., 2013b)Among these six is one which produces the se-mantic representation in (2).
While this grammardoes not yet capture any of the agreement mor-phology that indicates that the subject is first per-son plural, it does correctly link the ?day?
to thesemantic ARG2 of ?count?.(2)?
h1,h3: din n day(x4),h5: exist q rel(x4, h6, h7),h6: khipt-u-kv-m v count(e2, x9, x4){ h6=qh3} ?Finally, we note that the longest items we areable to parse consist of one verb and two NPs, eachof which can have only up to two words (a deter-miner and a noun).
Most of the examples that doparse consist of only one or two words, while thefull data set ranges from items of length 1 to itemsof length 25 (average 4.5 words/item in training,choices files involved analyses of words for ?yes?, ?well?,?what?
and the like as verbs.
Note that one form of ?yes?
is thecopula, and such examples were accepted.
Another source ofincorrect parses for many grammars involves homophony be-tween the focus particle and a verb meaning ?come?.5 words/item in test).
The Grammar Matrix al-ready supports some longer sentences in the formof coordination, so one avenue for future work isto explore the automatic detection of coordinationstrategies.
Otherwise, branching out to longer sen-tences will require additions to the Grammar Ma-trix allowing the specification of modifiers and awider range of valence types for verbs.5 Error AnalysisThe opportunity to work closely with one lan-guage has allowed us to observe several waysin which the assumptions of the systems we arebuilding on do not match what we find in the data.Here we briefly review some of those mismatchesand reflects on what could be done to handle them.The first observation concerns the non-glossingof zero-marked morphosyntactic features, such asabsolutive case in Chintang.
From the point ofview of a consumer of IGT it is certainly desirableto have as much information as possible made ex-plicit in the glossing.
From the point of view ofa project creating IGT in the context of on-goingfieldwork, however, it is likely often difficult toreliably gloss zero morphemes and thus the de-cision to leave them systematically unglossed isquite sensible.
Both the GRAM method and espe-cially the SAO method for detecting case systems,which we extended to extracting case frames forparticular verbs, are not yet fully robust to thepossibility that certain case values are unmarkedmorphologically and thus not glossed in the data.50While we extended them to a certain extent in thiswork, there is still more to be done on this front.A second observation concerns the glossing ofproper names, as in (3):(3) pailegopaile-kofirst-GENubhiyautiu-bhiya3A-marriagepaphumapaphu-maa.clan.of.Rai.people-F?His first marriage was with a Phuphu woman.?
[ctn] (Bickel et al., 2013a)We use statistical alignment between the trans-lation line and the gloss line and between thegloss line and the language line in order to projectinformation from the analysis of the translationline onto the language line.
Glosses such as?a.clan.of.Rai.people?
tend to confuse this align-ment process, though they are very informative toa human reader of the IGT.
Error analysis of sen-tences for which we were unable to extract subjectand object arguments at all suggested that manyof the errors were caused by misalignments likelydue to the aligner not being able to cope with thiskind of glossing.
Future work will explore how totrain the aligner to function better in such cases.In addition to properties of the glossing conven-tions, there are also properties of the language thatproved challenging for our system.
The first is theintricate nature of the case-marking system as dis-cussed in ?3.1.
In particular, our system does notmodel any distinction between 1st and 2nd per-son pronouns and other nouns, such that when thepronouns appear without a case marker, they aretaken to be in the unmarked case (i.e.
absolutive),though this is not necessarily so.
The second prop-erty of the language that our system found diffi-cult is the optionality of arguments.
We were ableto adapt our case frame extraction strategy to han-dle dropped subjects, but dropped objects are moreconfounding: our system is unable so far to distin-guish such verbs from intransitives.
One possibleway forward in this case is to draw more informa-tion from the English translation in the IGT: En-glish tends not to drop arguments, and so when wefind an object (especially a pronominal object) inthe English translation that is not aligned to any-thing in the language line, we would have evidencethat the verb in question may be transitive.Finally, we looked closely at the items in the testdata for which we had complete lexical analysis,but which still failed to parse.
We did this both forthe fullform and MOM-based lexicons.
The goalhere was to evaluate whether (a) our assignment ofitems to lexical categories was correct (and therewas some other issue standing in the way of an-alyzing the item) or (b) we should have parsed agiven item, but our system had misidentified thewords in question in such a way that no syntacticanalysis could be found.
For the baseline system,we found that although some items had misidenti-fied categories (specifically, pronouns and adverbswere sometimes misidentified as determiners), thetwo major obstacles to parsing came from multi-verb constructions or sentential fragments.
Of the26 unparsed items with lexical coverage, 10 con-tained multiple verbs and 12 were NP or interjec-tory fragments (eg: ?Yes, yes, yes.?).
We observeda similar pattern among 23 unparsed items fromthe MOM-based lexicon.
We can take two lessonsfrom this assessment: (1) since much of our datacomes from naturally occurring speech, it may beuseful to rerun our tests with an NP fragment asa valid root symbol in our grammars; (2) properidentification of auxiliary verbs is an importantnext step for improving our system.6 ConclusionIn this paper we have taken the first steps towardscreating actual precision grammars by creatingGrammar Matrix customization system choicesfiles on the basis of automated analysis of IGT.Measured in terms of coverage over held-out data,the results are hardly impressive and might seemdiscouraging.
However, we see in these initial for-ays rather a proof-of-concept.
Moreover, the pro-cess of digging into the details of getting an IGT-to-grammar system working for one particular lan-guage has been a very rich source of informationon the mismatches between the assumptions ofsystems built to handle high-level properties andthe linguistic facts and glossing conventions of thekind of data they are meant to handle.7 AcknowledgmentsThis material is based upon work supported bythe National Science Foundation under Grant No.BCS-1160274.
Any opinions, findings, and con-clusions or recommendations expressed in thismaterial are those of the author(s) and do not nec-essarily reflect the views of the NSF.We would like to thank David Wax for his as-sistance in setting up the MOM system, Olga Za-maraeva for general discussion, and especially theCRLP for providing access to the Chintang data.51ReferencesPeter Adolphs, Stephan Oepen, Ulrich Callmeier,Berthold Crysmann, Dan Flickinger, and BerndKiefer.
2008.
Some fine points of hybrid naturallanguage parsing.
Marrakech, Morocco, May.Emily M. Bender, Dan Flickinger, and Stephan Oepen.2002.
The grammar matrix: An open-source starter-kit for the rapid development of cross-linguisticallyconsistent broad-coverage precision grammars.
InJohn Carroll, Nelleke Oostdijk, and Richard Sut-cliffe, editors, Proceedings of the Workshop onGrammar Engineering and Evaluation at the 19thInternational Conference on Computational Lin-guistics, pages 8?14, Taipei, Taiwan.Emily M. Bender, Scott Drellishak, Antske Fokkens,Laurie Poulson, and Safiyyah Saleem.
2010.
Gram-mar customization.
Research on Language & Com-putation, pages 1?50.
10.1007/s11168-010-9070-1.Emily M. Bender, Sumukh Ghodke, Timothy Baldwin,and Rebecca Dridan.
2012a.
From database to tree-bank: Enhancing hypertext grammars with grammarengineering and treebank search.
In Sebastian Nord-hoff and Karl-Ludwig G. Poggeman, editors, Elec-tronic Grammaticography, pages 179?206.
Univer-sity of Hawaii Press, Honolulu.Emily M. Bender, Robert Schikowski, and BalthasarBickel.
2012b.
Deriving a lexicon for a precisiongrammar from language documentation resources:A case study of Chintang.
In Proceedings of COL-ING 2012, pages 247?262, Mumbai, India, Decem-ber.
The COLING 2012 Organizing Committee.Emily M. Bender, Michael Wayne Goodman, JoshuaCrowgey, and Fei Xia.
2013.
Towards creating pre-cision grammars from interlinear glossed text: Infer-ring large-scale typological properties.
In Proceed-ings of the 7th Workshop on Language Technologyfor Cultural Heritage, Social Sciences, and Human-ities, pages 74?83, Sofia, Bulgaria, August.
Associ-ation for Computational Linguistics.Balthasar Bickel, Goma Banjade, Martin Gaenszle,Elena Lieven, Netra Paudyal, Ichchha Rai, ManojRai, Novel Kishor Rai, and Sabine Stoll.
2007.
Freeprefix ordering in Chintang.
Language, 83(1):43?73.Balthasar Bickel, Bernard Comrie, and Martin Haspel-math.
2008.
The Leipzig glossing rules: Con-ventions for interlinear morpheme-by-morphemeglosses.
Max Planck Institute for Evolutionary An-thropology and Department of Linguistics, Univer-sity of Leipzig.Balthasar Bickel, Martin Gaenszle, Novel Kishore Rai,Elena Lieven, Goma Banjade, Toya Nath Bhatta,Netra Paudyal, Judith Pettigrew, Ichchha P. Rai,Manoj Rai, Robert Schikowski, and Sabine Stoll.2009.
Audiovisual corpus of the chintang lan-guage, including a longitudinal corpus of languageacquisition by six children, plus a trilingual dic-tionary, paradigm sets, grammar sketches, ethno-graphic descriptions, and photographs.
DOBESArchive, http://www.mpi.nl/DOBES.Balthasar Bickel, Manoj Rai, Netra P. Paudyal, GomaBanjade, Toya N. Bhatta, Martin Gaenszle, ElenaLieven, Ichchha Purna Rai, Novel Kishore Rai, andSabine Stoll.
2010.
The syntax of three-argumentverbs in Chintang and Belhare (Southeastern Ki-ranti).
In Studies in Ditransitive Constructions: AComparative Handbook, pages 382?408.
Mouton deGruyter, Berlin.Balthasar Bickel, Martin Gaenszle, Novel KishoreRai, Vishnu Singh Rai, Elena Lieven, Sabine Stoll,G.
Banjade, T. N. Bhatta, N Paudyal, J Pettigrew,and M Rai, I. P.and Rai.
2013a.
Hatuwa.
Accessed:15 January 2013.Balthasar Bickel, Martin Gaenszle, Novel KishoreRai, Vishnu Singh Rai, Elena Lieven, Sabine Stoll,G.
Banjade, T. N. Bhatta, N Paudyal, J Pettigrew,and M Rai, I. P.and Rai.
2013b.
Khadak?s daily life.Accessed: 15 January 2013.Balthasar Bickel, Martin Gaenszle, Novel KishoreRai, Vishnu Singh Rai, Elena Lieven, Sabine Stoll,G.
Banjade, T. N. Bhatta, N Paudyal, J Pettigrew,and M Rai, I. P.and Rai.
2013c.
Tale of a poor guy.Accessed: 15 January 2013.Balthasar Bickel, Martin Gaenszle, Novel KishoreRai, Vishnu Singh Rai, Elena Lieven, Sabine Stoll,G.
Banjade, T. N. Bhatta, N Paudyal, J Pettigrew,and M Rai, I. P.and Rai.
2013d.
Talk of kazi?s trip.Accessed: 15 January 2013.Aoife Cahill, Michael Burke, Ruth O?Donovan, JosefVan Genabith, and Andy Way.
2004.
Long-distancedependency resolution in automatically acquiredwide-coverage pcfg-based lfg approximations.
InProceedings of the 42nd Meeting of the Associationfor Computational Linguistics (ACL?04), Main Vol-ume, pages 319?326, Barcelona, Spain, July.Eugene Charniak.
1997.
Statistical parsing with acontext-free grammar and word statistics.
In Pro-ceedings of AAAI-1997.John Chen and K. Vijay-Shanker.
2000.
AutomatedExtraction of TAGs from the Penn Treebank.
InProc.
of the 6th International Workshop on ParsingTechnologies (IWPT-2000), Italy.Alexander Clark.
2001.
Unsupervised inductionof stochastic context-free grammars using distri-butional clustering.
In Proc.
of the 5th Confer-ence on Computational Natural Language Learning(CoNLL-2001).Ann Copestake, Dan Flickinger, Carl Pollard, andIvan A.
Sag.
2005.
Minimal recursion semantics:An introduction.
Research on Language & Compu-tation, 3(4):281?332.52Bart Cramer and Yi Zhang.
2009.
Construction of agerman hpsg grammar from a detailed treebank.
InProceedings of the 2009 Workshop on Grammar En-gineering Across Frameworks (GEAF 2009), pages37?45, Suntec, Singapore.Scott Drellishak.
2009.
Widespread But Not Uni-versal: Improving the Typological Coverage of theGrammar Matrix.
Ph.D. thesis, University of Wash-ington.Ryan Georgi, Fei Xia, and William D. Lewis.
2013.Enhanced and portable dependency projection algo-rithms using interlinear glossed text.
In Proceedingsof ACL 2013 (Volume 2: Short Papers), pages 306?311, Sofia, Bulgaria, August.Aria Haghighi and Dan Klein.
2006.
Prototype-driven grammar induction.
In Proceedings of the21st International Conference on ComputationalLinguistics and 44th Annual Meeting of the Associ-ation for Computational Linguistics (COLING/ACL2006), pages 881?888, Sydney, Australia, July.
As-sociation for Computational Linguistics.Julia Hockenmaier and Mark Steedman.
2002.Acquiring compact lexicalized grammars from acleaner treebank.
In Proc.
of LREC-2002, pages1974?1981.Julia Hockenmaier and Mark Steedman.
2007.
Ccg-bank: A corpus of ccg derivations and dependencystructures extracted from the penn treebank.
Com-putational Linguistics, 33(3):355?396.Dan Klein and Christopher Manning.
2002.
A gen-eral constituent context model for improved gram-mar induction.
In Proceedings of the 40th AnnualMeeting of the Association for Computational Lin-guistics (ACL-2002), Philadelphia, PA.Dan Klein and Christopher Manning.
2004.
Corpus-based induction of syntactic structure: models of de-pendency and constituency.
In Proceedings of the42nd Annual Meeting of the Association for Compu-tational Linguistics (ACL-2004), Barcelona, Spain.Alexander Krotov, Mark Hepple, Robert Gaizauskas,and Yorick Wilks.
1998.
Compacting the PennTreebank Grammar.
In Proc.
of the 36th AnnualMeeting of the Association for Computational Lin-guistics (ACL-1998), Montreal, Quebec, Canada.William D. Lewis and Fei Xia.
2008.
Automati-cally identifying computationally relevant typolog-ical features.
In Proceedings of the Third Interna-tional Joint Conference on Natural Language Pro-cessing, pages 685?690, Hyderabad, India.Yusuke Miyao, Takashi Ninomiya, and Junichi Tsu-jii.
2004.
Corpus-oriented grammar developmentfor acquiring a head-driven phrase structure gram-mar from the penn treebank.
In Proc.
of the First In-ternational Joint Conference on Natural LanguageProcessing (IJCNLP-2004), Hainan, China.Carl Pollard and Ivan A.
Sag.
1994.
Head-DrivenPhrase Structure Grammar.
Studies in Contempo-rary Linguistics.
The University of Chicago Pressand CSLI Publications, Chicago, IL and Stanford,CA.Robert Schikowski, Balthasar Bickel, and NetraPaudyal.
in press.
Flexible valency in Chintang.In B. Comrie and A. Malchukov, editors, ValencyClasses: A Comparative Handbook.
Mouton deGruyter, Berlin.Noah A. Smith and Jason Eisner.
2006.
Annealingstructural bias in multilingual weighted grammar in-duction.
In Proceedings of the 21st InternationalConference on Computational Linguistics and 44thAnnual Meeting of the Association for Computa-tional Linguistics (ACL/COLING 2006), pages 569?576, Sydney, Australia, July.
Association for Com-putational Linguistics.Benjamin Snyder, Tahira Naseem, and Regina Barzi-lay.
2009.
Unsupervised multilingual grammar in-duction.
In Proceedings of the Joint Conference ofthe 47th Annual Meeting of the ACL and the 4th In-ternational Joint Conference on Natural LanguageProcessing of the AFNLP, pages 73?81, August.Sabine Stoll and Balthasar Bickel.
2012.
How tomeasure frequency?
Different ways of countingergatives in Chintang (Tibeto-Burman, Nepal) andtheir implications.
In Frank Seifart, Geoffrey Haig,Nikolaus P. Himmelmann, Dagmar Jung, Anna Mar-getts, and Paul Trilsbeek, editors, Potentials of Lan-guage Documentation: Methods, Analyses, and Uti-lization, pages 83?89.
University of Hawai?i Press,Manoa.David Wax.
2014.
Automated grammar engineeringfor verbal morphology.
Master?s thesis, Universityof Washington.Fei Xia and William D. Lewis.
2007.
Multilin-gual structural projection across interlinear text.In Proc.
of the Conference on Human LanguageTechnologies (HLT/NAACL 2007), pages 452?459,Rochester, New York.Fei Xia.
1999.
Extracting Tree Adjoining Gram-mars from Bracketed Corpora.
In Proc.
of 5th Nat-ural Language Processing Pacific Rim Symposium(NLPRS-1999), Beijing, China.53
