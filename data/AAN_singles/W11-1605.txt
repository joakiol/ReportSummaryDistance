Workshop on Monolingual Text-To-Text Generation, pages 34?42,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 34?42,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsText specificity and impact on quality of news summariesAnnie LouisUniversity of PennsylvaniaPhiladelphia, PA 19104lannie@seas.upenn.eduAni NenkovaUniversity of PennsylvaniaPhiladelphia, PA 19104nenkova@seas.upenn.eduAbstractIn our work we use an existing classifier toquantify and analyze the level of specific andgeneral content in news documents and theirhuman and automatic summaries.
We dis-cover that while human abstracts contain amore balanced mix of general and specificcontent, automatic summaries are overwhelm-ingly specific.
We also provide an analysis ofsummary specificity and the summary qual-ity scores assigned by people.
We find thattoo much specificity could adversely affect thequality of content in the summary.
Our find-ings give strong evidence for the need for anew task in abstractive summarization: identi-fication and generation of general sentences.1 IntroductionTraditional summarization systems are primarilyconcerned with the identification of important andunimportant content in the text to be summarized.Placing the focus on this distinction naturally leadsthe summarizers to completely avoid the task of text-to-text generation and instead just select sentencesfor inclusion in the summary.
In this work, we arguethat the general and specific nature of the content isalso taken into account by human summarizers; weshow that this distinction is directly related to thequality of the summary and it also calls for the useand refinement of text-to-text generation techniques.General sentences are overview statements.
Spe-cific sentences supply details.
An example generaland specific sentence from different parts of a newsarticle are shown in Table 1.
[1] The first shock let up as the eye of the storm movedacross the city.
[2] The National Hurricane Center in Miami reported itsposition at 2 a.m. Sunday at latitude 16.1 north, longitude67.5 west, about 140 miles south of Ponce, Puerto Rico,and 200 miles southeast of Santo Domingo.Table 1: General (in italics) and specific sentencesPrior studies have advocated that the distinctionbetween general and specific content is relevant fortext summarization.
Jing and McKeown (2000)studied what edits people use to create summariesfrom sentences in the source text.
Two of the op-erations they identify are generalization and specifi-cation where the source content gets changed in thesummary with respect to specificity.
In more recentwork, Haghighi and Vanderwende (2009) built asummarization system based on topic models, whereboth topics at general document level as well asthose at specific subtopic levels were learnt.
Theunderlying idea here is that summaries are gener-ated by a combination of content from both theselevels.
But since the preference for these two typesof content is not known, Haghighi and Vanderwende(2009) use some heuristic proportions.Many systems that deal with sentence compres-sion (Knight and Marcu, 2002; McDonald, 2006;Galley and McKeown, 2007; Clarke and Lapata,2008) and fusion (Barzilay and McKeown, 2005;Filippova and Strube, 2008), do not take into ac-count the specificity of the original or desired sen-tence.
However, Wan et al (2008) introduce a gen-eration task where a summary sentence is createdby combining content from a key (general) sentenceand its supporting sentences in the source.
More34recently, Marsi et al (2010) manually annotatedthe transformations between source and compressedphrases and observe that generalization is a frequenttransformation.But it is not known what distribution of generaland specific content is natural for summaries.
In ad-dition, an analysis of whether this aspect is relatedto quality of the summary has also not been done sofar.
We address this issue in our work, making useof an accurate classifier to identify general and spe-cific sentences that we have developed (Louis andNenkova, 2011).We present the first quantitative analysis of gen-eral and specific content in a large corpus of newsdocuments and human and automatic summariesproduced for them.
Our findings reveal that human-written abstracts have much more general contentcompared to human and system produced extractivesummaries.
We also provide an analysis of how thisdifference in specificity is related to aspects of sum-mary quality.
We show that too much specificitycould adversely affect the quality of summary con-tent.
So we propose the task of creating generalsentences for use in summaries.
As a starting pointin this direction, we discuss some insights into theidentification and generation of general sentences.2 DataWe obtained news documents and their sum-maries from the Document Understanding Confer-ence (DUC) evaluations.
We use the data from2002 because they contain the three different typesof summaries we wish to analyze?abstracts andextracts produced by people, and automatic sum-maries.
For extracts, the person could only selectcomplete sentences, without any modification, fromthe input articles.
When writing abstracts peoplewere free to write the summary in their own words.We use data from the generic multi-documentsummarization task.
There were 59 input sets, eachcontaining 5 to 15 news documents on a topic.
Thetask is to provide a 200 word summary.
Two human-written abstracts and two extracts were produced foreach input by trained assessors at NIST.
Nine au-tomatic systems participated in the conference thatyear and we have 524 automatic summaries overall.3 General and specific sentences in newsBefore we present our analysis of general and spe-cific content in news summaries, we provide a briefdescription of our classifier and some example pre-dictions.
Our classifier is designed to predict for agiven sentence, its class as general or specific.As in our example in Table 1, a general sentencehints at a topic the writer wishes to convey but doesnot provide details.
So a reader expects to see moreexplanation and specific sentences satisfy this role.We observed that certain properties are prominentin general sentences.
They either express a strongsentiment, are vague or contain surprising content.Accordingly our features were based on word speci-ficity, language models, length of syntactic phrasesand the presence of polarity words.
Just the words inthe sentences were also a strong indicator of generalor specific nature.
But we found the combination ofall non-lexical features to provide the best accuracyand is the setup we use in this work.We trained our classifier on general and specificsentences from news texts.
Initially, we utilized ex-isting annotations of discourse relations as trainingdata.
This choice was based on our hypotheses thatdiscourse relations such as exemplification relate ageneral with a specific sentence.
Later, we verifiedthe performance of the classifier on human anno-tated general and specific sentences, also from twogenre of news articles, and obtained similar and ac-curate predictions.
Detailed description of the fea-tures and training data can be found in Louis andNenkova (2011).Our classifier uses logistic regression and so apartfrom hard prediction into general/specific classes,we can also obtain a confidence (probability) mea-sure for membership in a particular class.
In ourtests, we found that for sentences where there is highannotator agreement for placing in a particular class,the classifier also produces a high confidence predic-tion on the correct class.
When the agreement wasnot high, the classifier confidence was lower.
In thisway, the confidence score indicates the level of gen-eral or specific content.
So for our experiments inthis paper, we choose to use the confidence score fora sentence belonging to a class rather than the clas-sification decision.The overall accuracy of the classifier in binary35[G1] ?The crisis is not over?.
[G2] No casualties have been reported, but experts are concerned that a major eruption could occur soon.
[G3] Seismologists said the volcano had plenty of built-up magma and even more severe eruptions could come later.
[G4] Their predictions might be a false alarm ?
the volcano may have done its worst already.
[S1] (These volcanoes ?
including Mount Lassen in Shasta County, and Mount Rainier and Mount St. Helens in Washington, allin the Cascade Range ?
arise where one of the earth?s immense crust plates is slowly diving beneath another.
); Pinatubo?slast eruption, 600 years ago, is thought to have yielded at least as much molten rock ?
half a cubic kilometer ?
as MountSt.
Helens did when it erupted in 1980.
[S2] The initial explosions on Mount Pinatubo at 8:51 a.m. Wednesday sent a 10-mile-high mushroom cloud of swirling ash androck fragments into the skies over Clark Air Base, forcing the Air Force to evacuate hundreds of American volunteers who hadstayed behind to guard it and to tend sensitive communications equipment.
[S3] Raymundo Punongbayan, director of the Philippine Institute of Vulcanology and Seismology, said Friday?s blasts were partof a single eruption, the largest since Mount Pinatubo awoke Sunday from its 600-year slumber.Table 2: General (G) and specific (S) sentences from input d073bclassification is 75%.
More accurate predictions aremade on the examples with high annotator agree-ment reaching over 90% accuracy on sentenceswhere there was complete agreement between fiveannotators.
So we expect the predictions from theclassifier to be reliable for analysis in a task setting.In Table 2, we show the top general and specificsentences (ranked by the classifier confidence) forone of the inputs, d073b, from DUC 2002.
This in-put contains articles about the volcanic eruption atMount Pinatubo.
Here, the specific sentences pro-vide a lot of details such as the time and impact ofthe eruption, information about previous volcanoesand about the people and organizations involved.In the next section, we analyze the actual distri-bution of specific and general content in articles andtheir summaries for the entire DUC 2002 dataset.4 Specificity analysisFor each text?input, human abstract, human extractand automatic summary?we compute a measure ofspecificity as follows.
We use the classifier to markfor each sentence the confidence for belonging to thespecific class.
Each token in the text is assigned theconfidence level of the sentence it belongs to.
Theaverage specificity of words is computed as the meanvalue of the confidence score over all the tokens.The histogram of this measure for each type oftext is shown in Figure 1.For inputs, the average specificity of words rangesbetween 50 to 80% with a mean value of 65%.
So,news articles tend to have more specific content thangeneric but the distribution is not highly skewed to-wards either of the extreme ends.The remaining three graphs in Figure 1 representthe amount of specific content in summaries for thesame inputs.
Human abstracts, in contrast to the in-puts, are spread over a wider range of specificity lev-els.
Some abstracts have as low as 40% specificityand a few actually score over 80%.
However, thesharper contrast with inputs comes from the largenumber of abstracts that have 40 to 60% specificity.This trend indicates that abstracts contain more gen-eral content compared to inputs.
An unpaired two-sided t-test between the specificity values of inputsand abstracts confirmed that abstracts have signif-icantly lower specificity.
The mean value for ab-stracts is 62% while for inputs it is 65%.The results of the analysis are opposite for hu-man extracts and system summaries.
The meanspecificity value for human extracts is 72%, 10%higher compared to abstractive summaries for thesame inputs.
This difference is also statistically sig-nificant.
System-produced summaries also show asimilar trend as extracts but are even more heavilybiased towards specific content.
There are even ex-amples of automatic summaries where the averagespecificity level reaches 100%.
The mean specificityvalue is 74% which turned out significantly higherthan all other types of texts, inputs and both types ofhuman summaries.
So system summaries appear tobe overwhelmingly specific.The first surprising result is the opposite charac-teristics of human abstracts and extracts.
While ab-stracts tend to be more general compared to the in-put texts, extracts are more specific.
Even though36Figure 1: Specific content in inputs and summariesboth types of summaries were produced by people,we see that the summarization method deeply influ-ences the nature of the summary content.
The task ofcreating extractive summaries biases towards morespecific content.
So it is obvious that systems whichmainly use extractive techniques would also createvery specific summaries.
Further, since high speci-ficity arises as a result of the limitations associatedwith extractive techniques, perhaps, overly specificcontent would be detrimental to summary quality.We investigate this aspect in the next section.5 Specificity and summary qualityIn this section, we examine if the difference in speci-ficity that we have observed is related to the per-ceived quality of the summary.
Haghighi and Van-derwende (2009) report that their topic model basedsystem was designed to use both a general contentdistribution and distributions of content for specificsubtopics.
However, using the general distributionyielded summaries with better content than using thespecific topics.
Here we directly study the relation-ship between specificity of system summaries andtheir content and linguistic quality scores.
We alsoexamine how the specificity measure is related tothe quality of specialized summaries where peoplewere explicitly told to include only general contentor only specific details in their summaries.
For thisanalysis, we focus on system produced summaries.5.1 Content qualityAt DUC, each summary is evaluated by humanjudges for content and linguistic quality.
The qual-ity of content was assessed in 2002 by means of acoverage score.
The coverage score reflects the sim-ilarity between content chosen in a system summaryand that which is present in a human-written sum-mary for the same input.
A human abstract is cho-sen as the reference.
It is divided into clauses andfor each of these clauses, judges decide how well itis expressed by the system produced summary (as apercentage value).
The average extent to which thesystem summary expresses the clauses of the humansummary is considered as the coverage score.
Sothese scores range between 0 and 1.We computed the Pearson correlation between thespecificity of a summary and its coverage score, andobtained a value of -0.16.
The correlation is not veryhigh but it is significant (pvalue 0.0006).
So speci-ficity does impact content quality and more specificcontent indicates decreased quality.We have seen from our analysis in the previoussection that when people produce abstracts, theykeep a mix of general and specific content but theabstracts are neither too general nor too specific.
Soit is not surprising that the correlation value is notvery high.
Further, it should be remembered that thenotion of general and specific is more or less inde-pendent of the importance of the content itself.
Twosummaries can have the same level of generality butvary greatly in terms of the importance of the con-tent present.
So we performed an analysis to checkthe contribution of generality to the content scoresin addition to the importance factor.We combine a measure of content importance37Predictor Mean ?
Stdev.
?
t value p-value(Intercept) 0.212 0.03 6.87 2.3e-11 *rouge2 1.299 0.11 11.74 < 2e-16 *avgspec -0.166 0.04 -4.21 3.1e-05 *Table 3: Results from regression testfrom the ROUGE automatic evaluation (Lin andHovy, 2003; Lin, 2004) with generality to predictthe coverage scores.
We use the same reference asused for the official coverage score evaluation andcompute ROUGE-2 which is the recall of bigrams ofthe human summary by the system summary.
Nextwe train a regression model on our data using theROUGE-2 score and specificity as predictors of thecoverage score.
We then inspected the weights learntin the regression model to identify the influence ofthe predictors.
Table 3 shows the mean values andstandard deviation of the beta coefficients.
We alsoreport the results from a test to determine if the betacoefficient for a particular predictor could be set tozero.
The p-value for rejection of this hypothesisis shown in the last column and the test statistic isshown as the ?t value?.
We used the lm function inthe R toolkit1 to perform the regression.From the table, we see that both ROUGE-2 andaverage specificity of words (avgspec) turn out assignificant predictors of summary quality.
Relevantcontent is highly important as shown by the positivebeta coefficient for ROUGE-2.
At the same time, itis preferable to maintain low specificity, a negativevalue is assigned to the coefficient for this predictor.So too much specificity should be avoided by sys-tems and we must find ways to increase the general-ity of summaries.
We discuss this aspect in Sections6 and 7.5.2 Linguistic qualityWe have seen from the above results that maintain-ing a good level of generality improves content qual-ity.
A related question is the influence of specificityon the linguistic quality of a summary.
Does theamount of general and specific content have any re-lationship with how clear a summary is to read?
Webriefly examine this aspect here.In DUC 2002 linguistic quality scores were onlymentioned as the number of errors in a summary,not a holistic score.
Moreover, it was specified as1http://www.r-project.org/ling score sums.
avg specificity1, 2 202 0.715 400 0.729, 10 79 0.77Table 4: Number of summaries at extreme levels of lin-guistic quality scores and their average specificity valuesa range?errors between 1 and 5 receive the samescore.
So we use another dataset for this analy-sis only.
We use the system summaries and theirlinguistic quality scores from the TAC ?09 queryfocused summarization task2.
Each summary wasmanually judged by NIST assessors and assigned ascore between 1 to 10 to reflect how clear it is toread.
The score combines multiple aspects of lin-guistic quality such as clarity of references, amountof redundancy, grammaticality and coherence.Since these scores are on an integer scale, we donot compute correlations.
Rather we study the speci-ficity, computed in the same manner as describedpreviously, of summaries at different score levels.Here there were 44 inputs and 55 systems.
In Table4, we show the number of summaries and their av-erage specificity for 3 representative score levels?best quality (9 or 10), worst (1 or 2) and mediocre(5).
We only used summaries with more than 2 sen-tences as it may not be reasonable to compare thelinguistic quality of summaries of very short lengths.From this table, we see that the summaries withgreater score have a higher level of specificity.
Thespecificity of the best summaries (9, 10) are signifi-cantly higher than that with medium and low scores(two-sided t-test).
This result is opposite to our find-ing with content quality and calls attention to an im-portant point.
General sentences cannot stand aloneand need adequate support and details.
But cur-rently, very few systems even make an attempt toorganize their summaries.
So overly general con-tent and general content without proper context canbe detrimental to the linguistic quality.
Such sum-maries can appear uncontentful and difficult to readas the example in Table 5 demonstrates.
This sum-mary has an average specificity of 0.45 and its lin-guistic quality score is 1.So we see an effect of specificity on both content2http://www.nist.gov/tac/2009/Summarization/update.summ.09.guidelines.html38?We are quite a ways from that, actually.
?As ice and snow at the poles melt, the loss of their reflective surfaces leads to exposed land and water absorbing more heat.It is in the middle of an area whose population?and electricity demands?are growing.It was from that municipal utility framework, city and school officials say, that the dormitory project took root.
?We could offer such a plan in Houston next year if we find customer demand, but we have n?t gone to the expense of marketing the plan.?
?We get no answers.
?Table 5: Example general summary with poor linguistic qualityand linguistic quality though in opposite directions.5.3 Quality of general and specific summariesSo far, we examined the effect of specificity on thequality of generic summaries.
Now, we examinewhether this aspect is related to the quality of sum-maries when they are optimized to be either gen-eral or specific content.
We perform this analysison DUC 20053 data where the task was to create ageneral summary for certain inputs.
For others, aspecific summary giving details should be produced.The definitions of a general and specific summaryare given in the task guidelines.4We tested whether the degree of specificity is re-lated to the content scores5 of system summaries ofthese two types?general and specific.
The Pearsoncorrelation values are shown in Table 6.
Here wefind that for specific summaries, the level of speci-ficity is significantly positively correlated with con-tent scores.
For the general summaries there is norelationship between specificity and content quality.These results show that specificity scores arenot consistently predictive of distinctions within thesame class of summaries.
Within general sum-maries, the level of generality does not influence thescores obtained by them.
This finding again high-lights the disparity between content relevance andspecific nature.
When all summaries are specific orgeneral, their levels of specificity are no longer in-dicative of quality.
We also computed the regres-sion models for these two sets of summaries withROUGE scores and specificity, and specificity levelwas not a significant predictor of content scores.Our findings in this section confirm that generalsentences are useful content for summaries.
So we3http://duc.nist.gov/duc2005/4http://duc.nist.gov/duc2005/assessor.summarization.instructions.pdf5We use the official scores computed using the Pyramidevaluation method (Nenkova et al, 2007)Summaries correlation p-valueDUC 2005 general -0.03 0.53DUC 2005 specific 0.18* 0.004Table 6: Correlations between content scores and speci-ficity for general and specific summaries in DUC 2005face the issue of creating general sentences whichare summary-worthy.
We concentrate on this aspectfor the rest of this paper.
In Section 6, we pro-vide an analysis of the types of general sentencesextracted from the source text and used in humanextracts.
We move from this limited view and exam-ine in Section 7, the possibility of generating generalsentences from specific sentences in the source text.Our analysis is preliminary but we hope that it willinitiate this new task of using general sentences forsummary creation.6 Extraction of general sentencesWe examine general sentences that were chosen inhuman extracts to understand what properties sys-tems could use to identify such sentences from thesource text.
We show in Table 7, the ten extract sen-tences that were predicted to be general with highestconfidence.
The first sentence has a 0.96 confidencelevel, the last sentence has 0.81.These statements definitely create expectation andneed further details to be included.
Taken out of con-text, these sentences do not appear very contentful.However despite the length restriction while creat-ing summaries, humans tend to include these gen-eral sentences.
Table 8 shows the full extract whichcontains one of the general sentences ([9] ?Instead itsank like the Bismarck.?
).When considered in the context of the extract, wesee clearly the role of this general sentence.
It intro-duces the topic of opposition to Bush?s nominationfor a defense secretary.
Moreover, it provides a com-parison between the ease with which such a propo-sition could have been accepted and the strikingly39opposite situation that arose?the overwhelming re-jection of the candidate by the senate.
So sentence[9] plays the role of a topic sentence.
It conveys themain point the author wishes to make in the sum-mary and further details follow this sentence.But given current content selection methods, suchsentences would rank very low for inclusion intosummaries.
So the prediction of general sentencescould prove a valuable task enabling systems to se-lect good topic sentences for their summaries.
How-ever, proper ordering of sentences will be necessaryto convey the right impact but this approach couldbe a first step towards creating summaries that havean overall theme rather than just the selection of sen-tences with important content.We also noticed some other patterns in the generalsentences chosen for extracts.
A crude categoriza-tion was performed on the 75 sentences predictedwith confidence above 0.65 and are shown below:first sentence : 6 (0.08)last sentence : 13 (0.17)comparisons : 4 (0.05)attributions : 14 (0.18)A significant fraction of these general sentences(25%) were used in the extracts to start and endthe summary, likely positions for topic sentences.Some of these (5%) involve comparisons.
We de-tected these sentences by looking for the presenceof connectives such as ?but?, ?however?
and ?al-though?.
The most overwhelming pattern is pres-ence of quotations, covering 18% of the sentenceswe examined.
These quotations were identified us-ing the words ?say?, ?says?, ?said?
and the presenceof quotes.
We can also see that three of the top 10general sentences in Table 7 are quotes.So far we have analyzed sentences chosen bysummary authors directly from the input articles.In the next section, we analyze the edit operationsmade by people while creating abstractive sum-maries.
Our focus is on the generalization operationwhere specific sentences are made general.
Sucha transformation would be the generation-based ap-proach to obtain general sentences.7 Generation of general sentencesWe perform our analysis on data created for sen-tence compression.
In this line of work (Knight and[1] Folksy was an understatement.
[2] ?Long live democracy?!
[3] The dogs are frequent winners in best of breed andbest of show categories.
[4] Go to court.
[5] Tajikistan was hit most hard.
[6] Some critics have said the 16-inch guns are outmodedand dangerous.
[7] Details of Maxwell?s death are sketchy.
[8] ?Several thousands of people who were in the sheltersand the tens of thousands of people who evacuated inlandwere potential victims of injury and death?.
[9] Instead it sank like the Bismarck.
[10] ?The buildings that collapsed did so because of acombination of two things: very poor soil and very poorstructural design,?
said Peter I. Yanev, chairman of EQEInc., a structural engineering firm in San Francisco.Table 7: Example general sentences in humans extractsMarcu, 2002; McDonald, 2006; Galley and McKe-own, 2007), compressions are learnt by analyzingpairs of sentences, one from the source text, theother from human-written abstracts such that theyboth have the same content.
We use the sentencepairs available in the Ziff-Davis Tree Alignmentcorpus (Galley and McKeown, 2007).
These sen-tences come from the Ziff-Davis Corpus (Harmanand Liberman, 1993) which contains articles abouttechnology products.
Each article is also associatedwith an abstract.
The alignment pairs are producedby allowing a limited number of edit operations tomatch a source sentence to one in the abstract.
Inthis corpus, alignments are kept between pairs thathave any number of deletions and upto 7 substitu-tions.
There are 15964 such pairs in this data.
It isworth noting that these limited alignments only map25% of the abstract sentences, so they do not coverall the cases.
Still, an analysis on this data could bebeneficial to observe the trends.We ran the classifier individually on each sourcesentence and abstract sentence in this corpus.
Thenwe counted the number of pairs which undergo eachtransformation such as general-general, general-specific from the source to an abstract sentence.These results are reported in Table 9.
The table alsoprovides the average number of deletion and substi-tution operations associated with sentence pairs inthat category as well as the length of the uncom-pressed sentence and the compression rate.
Com-pression rate is defined as the ratio between the40Summary d118i-f:- President-elect Bush designated Tower as his defense secretary on Dec. 16.
[Specific]- Tower?s qualifications for the job ?intelligence, patriotism and past chairmanship of the Armed Services Committee ?the nominationshould have sailed through with flying colors.
[Specific]- Instead it sank like the Bismarck.
[General]- In written testimony to the Senate panel on Jan. 26, Tower said he could ?recall no actions in connection with any defense activities?in connection with his work for the U.S. subsidiary.
[Specific]- Tower has acknowledged that he drank excessively in the 1970s, but says he has reduced his intake to wine with dinner.
[General]- The Democratic-controlled Senate today rejected the nomination of former Texas Sen. John Tower as defense secretary, deliveringa major rebuke to President Bush just 49 days into his term.
[Specific]- The Senate?s 53-47 vote came after a bitter and divisive debate focused on Tower?s drinking habits, behavior toward women and hisbusiness dealings with defense contractors.
[General]Table 8: Example extract with classifier predictions and a general sentence from Table 7Type Total % total Avg deletions Avg subs.
Orig length Compr.
rateSS 6371 39.9 16.3 3.9 33.4 56.6SG 5679 35.6 21.4 3.7 33.5 40.8GG 3562 22.3 9.3 3.3 21.5 60.8GS 352 2.2 8.4 4.0 22.7 66.0Table 9: Types of transformation of source into abstract sentenceslength in words of the compressed sentence and thelength of the uncompressed sentence.
So lower com-pression rates indicate greater compression.We find that the most frequent transformations arespecific-specific (SS) and specific-general (SG).
To-gether they constitute 75% of all transformations.But for our analysis, the SG transformation is mostinteresting.
One third of the sentences in this dataare converted from originally specific content to be-ing general in the abstracts.
So abstracts do tend toinvolve a lot of generalization.Studying the SG transition in more detail, we cansee that the original sentences are much longer com-pared to other transitions.
This situation arises fromthe fact that specific sentences in this corpus arelonger.
In terms of the number of deletions, we seethat both SS and SG involve more than 15 deletions,much higher than that performed on the general sen-tences.
However, we do not know if these operationsare proportional to the original length of the sen-tences.
But looking at the compression rates, we geta clearer picture, the SG sentences after compres-sion are only 40% their original length, the maxi-mum compression seen for the transformation types.For GG and GS, about 60% of the original sentencewords are kept.
For the SG transition, long sentencesare chosen and are compressed aggressively.
In Ta-ble 10, we show some example sentence pairs un-dergoing the SG transition.Currently, compression systems do not achievethe level of compression in human abstracts.
Sen-tences that humans create are shorter than what sys-tems produce.
Our results predict that these could bethe cases where specific sentences get converted intogeneral.
One reason why systems do not attain thiscompression level could be because they only con-sider a limited set of factors while compressing, suchas importance and grammaticality.
We believe thatgenerality can be an additional objective which canbe used to produce even shorter sentences which wehave seen in our work, will also lead to summarieswith better content.8 ConclusionIn this work, we have provided the first quantitativeanalysis of general and specific content as relevantto the task of automatic summarization.
We findthat general content is useful for summaries how-ever, current content selection methods appear to notinclude much general content.
So we have proposedthe task of identifying general content which couldbe used in summaries.
There are two ways of achiev-ing this?by identifying relevant general sentencesfrom the input and by conversion from specific to41[1] American Mitac offers free technical support for one year at a toll-free number from 7:30 to 5:30 P.S.T.American Mitac offers toll-free technical support for one year.
[2] In addition to Yurman, several other government officials have served on the steering committee that formed the group.Several government officials also served on the steering committee.
[3] All version of the new tape drives, which, according to Goldbach, offer the lowest cost per megabyte for HSC-based 8mm tapestorage, are available within 30 days of order.The products are available within 30 days of order.
[4] In a different vein is Edward Tufte ?s ?The Visual Display of Quantitative Information?
(Graphics Press, 1983), a book coveringthe theory and practice of designing statistical charts, maps, tables and graphics.Tufte ?s book covers the theory and practice of designing statistical charts, maps, tables and graphics.
[5] In addition, Anderson said two Ada 9X competitive procurements?a mapping and revision contract and an implementation anddemonstration contract?will be awarded in fiscal 1990.Two competitive procurements will be awarded in fiscal 1989.Table 10: Example specific to general (in italics) compressionsgeneral content.
We have provided a brief overviewof these two approaches.Our work underscores the importance of com-pression and other post-processing approaches overextractive summaries.
Otherwise system contentcould contain too much extraneous details whichtake up space where other useful content could havebeen discussed.Our study also highlights a semantic view of sum-mary creation.
Summaries are not just a bag of im-portant sentences as viewed by most methods today.Rather a text should have a balance between sen-tences which introduce a topic and those which dis-cuss them in detail.
So another approach to contentselection could be the joint selection of a generalsentence with its substantiation.
In future work, itwould be interesting to observe if such summariesare judged more responsive and of better linguisticquality than summaries which do not have such astructure.ReferencesR.
Barzilay and K. McKeown.
2005.
Sentence fusion formultidocument news summarization.
ComputationalLinguistics, 31(3).J.
Clarke and M. Lapata.
2008.
Global inference forsentence compression: An integer linear programmingapproach.
Journal of Artificial Intelligence Research,31(1):399?429.K.
Filippova and M. Strube.
2008.
Sentence fusionvia dependency graph compression.
In Proceedingsof EMNLP, pages 177?185.M.
Galley and K. McKeown.
2007.
Lexicalized markovgrammars for sentence compression.
In ProceedingsNAACL-HLT.A.
Haghighi and L. Vanderwende.
2009.
Exploring con-tent models for multi-document summarization.
InProceedings of NAACL-HLT, pages 362?370.D.
Harman and M. Liberman.
1993.
Tipster complete.Corpus number LDC93T3A, Linguistic Data Consor-tium, Philadelphia.H.
Jing and K. McKeown.
2000.
Cut and paste basedtext summarization.
In Proceedings of NAACL.K.
Knight and D. Marcu.
2002.
Summarization beyondsentence extraction: A probabilistic approach to sen-tence compression.
Artificial Intelligence, 139(1).C.
Lin and E. Hovy.
2003.
Automatic evaluation of sum-maries using n-gram co-occurrence statistics.
In Pro-ceedings of HLT-NAACL.C.
Lin.
2004.
ROUGE: a package for automatic evalua-tion of summaries.
In ACL Text Summarization Work-shop.A.
Louis and A. Nenkova.
2011.
General versus spe-cific sentences: automatic identification and applica-tion to analysis of news summaries.
Technical Re-port No.
MS-CIS-11-07, University of PennsylvaniaDepartment of Computer and Information Science.E.
Marsi, E. Krahmer, I. Hendrickx, and W. Daelemans.2010.
On the limits of sentence compression by dele-tion.
In E. Krahmer and M. Theune, editors, Empiricalmethods in natural language generation, pages 45?66.Springer-Verlag, Berlin, Heidelberg.R.
McDonald.
2006.
Discriminative sentence compres-sion with soft syntactic evidence.
In EACL?06.A.
Nenkova, R. Passonneau, and K. McKeown.
2007.The pyramid method: Incorporating human content se-lection variation in summarization evaluation.
ACMTrans.
Speech Lang.
Process., 4(2):4.S.
Wan, R. Dale, M. Dras, and C. Paris.
2008.
Seedand grow: augmenting statistically generated sum-mary sentences using schematic word patterns.
In Pro-ceedings of EMNLP, pages 543?552.42
