Proceedings of the Third Workshop on Statistical Machine Translation, pages 119?122,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsFirst Steps towards a general purpose French/EnglishStatistical Machine Translation SystemHolger SchwenkLIUM, University of Le Mans72085 Le Mans cedex 9FRANCEschwenk@lium.univ-lemans.frJean-Baptiste Fouet Jean SenellartSYSTRAN SA92044 Paris La De?fense cedexFRANCEfouet,senellart@systran.frAbstractThis paper describes an initial version of ageneral purpose French/English statistical ma-chine translation system.
The main featuresof this system are the open-source Moses de-coder, the integration of a bilingual dictionaryand a continuous space target language model.We analyze the performance of this system onthe test data of the WMT?08 evaluation.1 IntroductionStatistical machine translation (SMT) is today con-sidered as a serious alternative to rule-based ma-chine translation (RBMT).
While RBMT systemsrely on rules and linguistic resources built for thatpurpose, SMT systems can be developed withoutthe need of any language knowledge and are onlybased on bilingual sentence-aligned and large mono-lingual data.
However, while the monolingual datais usually available in large amounts, bilingual textsare a sparse resource for most of the language pairs.The largest SMT systems are currently build for thetranslation of Mandarin and Arabic to English, us-ing more than 170M words of bitexts that are eas-ily available from the LDC.
Recent human evalua-tions of these systems seem to indicate that they havereached a level of performance allowing a human be-ing to understand the automatic translations and toanswer complicated questions on its content (Jones,2008).In a joint project between the University of LeMans and the company SYSTRAN, we try to buildsimilar general purpose SMT systems for Euro-pean languages.
In the final version, these systemswill not only be trained on all available mono- andbilingual data, but also will include additional re-sources from SYSTRAN like high quality dictio-naries, named entity transliteration and rule-basedtranslation of expressions like numbers and dates.Our ultimate goal is to combine the power of data-driven approaches and the concentrated knowledgepresent in RBMT resources.
In this paper, we de-scribe an initial version of an French/English sys-tem and analyze its performance on the test corporaof the WMT?08 workshop.2 Architecture of the systemThe goal of statistical machine translation (SMT) isto produce a target sentence e from a source sen-tence f .
It is today common practice to use phrasesas translation units (Koehn et al, 2003; Och andNey, 2003) and a log linear framework in order tointroduce several models explaining the translationprocess:e?
= arg max p(e|f)= arg maxe{exp(?i?ihi(e, f))} (1)The feature functions hi are the system models andthe ?i weights are typically optimized to maximizea scoring function on a development set (Och andNey, 2002).
In our system fourteen features func-tions were used, namely phrase and lexical transla-tion probabilities in both directions, seven featuresfor the lexicalized distortion model, a word and aphrase penalty and a target language model (LM).The system is based on the Moses SMT toolkit(Koehn et al, 2007) and constructed as follows.119First, Giza++ is used to perform word alignmentsin both directions.
Second, phrases and lexical re-orderings are extracted using the default settings ofthe Moses SMT toolkit.
A 4-gram target LM isthen constructed as detailed in section 2.2.
Thetranslation itself is performed in two passes: first,Moses is run and a 1000-best list is generatedfor each sentence.
The parameters of Moses aretuned on devtest2006 for the Europarl task andnc-devtest2007 for the news task, using the cmerttool.
These 1000-best lists are then rescored with acontinuous space 5-gram LM and the weights of thefeature functions are optimized again using the nu-merical optimization toolkit Condor (Berghen andBersini, 2005).
Note that this step operates onlyon the 1000-best lists, no re-decoding is performed.This basic architecture of the system is identical tothe one used in the 2007 WMT evaluation(Schwenk,2007a).2.1 Translation modelIn the frame work of the 2008 WMT sharedtask, two parallel corpora were provided: the Eu-roparl corpus (about 33M words) and the news-commentary corpus (about 1.2M words).
It is knownthat the minutes of the debates of the Europeanparliament use a particular jargon and these textsalone do not seem to be the appropriate to build aFrench/English SMT system for other texts.
Themore general news-commentary corpus is unfortu-nately rather small in size.
Therefore, with thegoal to build a general purpose system, we inves-tigated whether more bilingual resources are avail-able.
Two corpora were identified: the proceedingsof the Canadian parliament, also known as Hansardcorpus (about 61M words), and data from the Unitednations (105M French and 89M English words).
Inthe current version of our system only the Hansardbitexts are used.In addition to these human generated bitexts, weinvestigated whether the translations of a high qual-ity bilingual dictionary could be integrated into aSMT system.
SYSTRAN provided this resourcewith more than 200 thousand entries, different formsof a verb or genres of an noun or adjective beingcounted as one entry.
It is still an open researchquestion how to best integrate a bilingual dictionaryinto a SMT system.
At least two possibilities cometo mind: add the entries directly to the phrase ta-ble or add the words and their translations to the bi-texts.
With the first solution one can be sure that theentries are added like there are and that they won?tsuffer any deformation due to imperfect alignmentof multi-word expressions.
However, it is not obvi-ous how to obtain the phrase translation and lexicalprobabilities for each new phrase.
The second solu-tion has the potential advantage that the dictionarywords could improve the alignments of these wordswhen they also appear in the other bitexts.
The cal-culation of the various scores of the phrase table issimplified too, since we can use the standard phraseextraction procedure.
However, one has to be awarethat all the translations that appear only in the dictio-nary will be equally likely which certainly does notcorrespond to the reality.
In future work will try toimprove these estimates using monolingual data.For now, we used about ten thousand verbs andhundred thousand nouns from the dictionary.
Foreach verb, we generated all the conjugations in thepast, present, future and conditional tense; and foreach noun the singular and plural form were gener-ated.
In total this resulted in 512k ?new sentences?in the bitexts.2.2 Language modelIn comparison to bilingual texts which are neededfor the translation model, it is much easier to findlarge quantities of monolingual data, in English aswell as in French.
In this work, the following re-sources were used for the language model:?
the monolingual parts of the Europarl, Hansard,UN and the news commentary corpus,?
the Gigaword corpus in French and English asprovided by LDC (770M and 3261M words re-spectively),?
about 33M words of newspaper texts crawledfrom the WEB (French only)Separate LMs were build on each data source withthe SRI LM toolkit (Stolcke, 2002) and then linearlyinterpolated, optimizing the coefficients with an EMprocedure.
Note that we build two sets of LMs: afirst set tuned on devtest2006, and a second one onnc-devtest2007.
The perplexities of these LMs are120French EnglishData Eparl News Eparl NewsBack-off 4-gram LM:Eparl+news 52.6 184.0 42.0 105.8All 50.0 136.1 39.7 85.4Continuous space 5-gram LM:All 42.0 118.9 34.1 75.0Table 1: Perplexities on devtest2006 (Europarl) andnc-devtest2007 (news commentary) for various LMs.given in Table 1.
We were not able to obtain signifi-cantly better results with 5-gram back-off LMs.It can be clearly seen that the additional LM data,despite its considerable size, achieves only a smalldecrease in perplexity for the Europarl data.
Thistask is so particular that other out-of-domain datadoes not seem to be very useful.
The system opti-mized on the more general news-commentary task,however, seems to benefit from the additional mono-lingual resources.
Note however, that the test datanewstest2008 is not of the same type and we mayhave a mismatch between development and test data.We also used a so-called continuous space lan-guage model (CSLM).
The basic idea of this ap-proach is to project the word indices onto a contin-uous space and to use a probability estimator oper-ating on this space (Bengio et al, 2003).
Since theresulting probability functions are smooth functionsof the word representation, better generalization tounknown n-grams can be expected.
A neural net-work can be used to simultaneously learn the pro-jection of the words onto the continuous space andto estimate the n-gram probabilities.
This is still an-gram approach, but the LM probabilities are ?in-terpolated?
for any possible context of length n-1instead of backing-off to shorter contexts.
This ap-proach was successfully used in large vocabularycontinuous speech recognition (Schwenk, 2007b)and in a phrase-based SMT systems (Schwenk et al,2006; De?chelotte et al, 2007).
Here, it is the firsttime trained on large amounts of data, more than 3Gwords for the English LM.
This approach achievesan average perplexity reduction of almost 14% rela-tive (see Table 1).3 Experimental EvaluationThe shared evaluation task of the third workshopon statistical machine translation features two dif-ferent test sets: test2008 and newstest2008.
Thefirst one contains data from the European parlia-ment of the same type than the provided training anddevelopment data.
Therefore good generalizationperformance can be expected.
The second test set,however, is news type data from unknown sources.Scanning some of the sentences after the evaluationseems to indicate that this data is more general thanthe provided news-commentary training and devel-opment data ?
it contains for instance financial andpublic health news.Given the particular jargon of the European par-liament, we decided to build two different systems,one rather general system tuned in nc-devtest2007and an Europarl system tuned on devtest2006.
Bothsystems use the tokenization proposed by the MosesSMT toolkit and the case was preserved in the trans-lation and language model.
Therefore, in contrast tothe official BLEU scores, we report here case sensi-tive BLEU scores as calculated by the NIST tool.3.1 Europarl systemThe results of the Europarl system are summarizedin Table 2.
The translation model was trained onthe Europarl and the news-commentary data, aug-mented by parts of the dictionary.
The LM wastrained on all the data, but the additional out-of-domain data has probably little impact given thesmall improvements in perplexity (see Table 1).French/English English/FrenchModel 2007 2008 2007 2008baseline 32.64 32.61 31.15 31.80base+CSLM 32.98 33.08 31.63 32.37base+dict 32.69 32.75 30.97 31.59+CSLM 33.11 33.13 31.54 32.34Table 2: Case sensitive BLEU scores for the Europarlsystem (test data)When translating from French to English theCSLM achieves a improvement of about 0.4 pointsBLEU.
Adding the dictionary had no significant im-pact, probably due to the jargon of the parliamentproceedings.
For the opposite translation direction,121the dictionary even seems to worsen the perfor-mance.
One reason for this observation could be thefact that the dictionary adds many French transla-tions for one English word.
These translation arenot correctly weighted and we have to rely com-pletely on the target LM to select the correct one.This may explain the large improvement achievedby the CSLM in this case (+0.75 BLEU).3.2 News systemThe results of the more generic news system aresummarized in Table 3.
The translation modelwas trained on the news-commentary, Europarl andHansard bitexts as well as parts of the dictionary.The LM was again trained on all data.French/English English/FrenchModel/bitexts 2007 2008 2007 2008news 29.31 17.98 28.60 17.51news+dict 30.09 18.78 28.92 18.01news+eparl 30.53 20.39 28.55 19.70+dict 30.94 20.63 28.46 19.96+Hansard 31.48 21.10 28.97 20.21+CSLM 31.98 21.02 29.64 20.51Table 3: Case sensitive BLEU scores of the news system(nc-test2007 and newstest2008)First of all, we realize that the BLEU scores onthe out-of-domain generic 2008 news data are muchlower than on the nc-test2007 data.
Adding morethan 60M words of the Hansard bitexts gives an im-provement of the BLEU score of about 0.5 for mostof the test sets and translation directions.
The dictio-nary is very interesting when only a limited amountof resources is available ?
a gain of up to 0.8 BLEUwhen only the news-commentary bitexts are used ?but still useful when more data is available.
As faras we know, this is the first time that adding a dic-tionary improved the translation quality of a verystrong baseline.
In previous works, results were onlyreported in a setting with limited resources (Vogel etal., 2003; Popovic?
and Ney, 2006).
However, we be-lieve that he integration of the dictionary is not yetoptimal, in particular with respect to the estimationof the translation probabilities.
The only surprisingresult is the bad performance of the CSLM on thenewstest2008 data for the translation from French toEnglish.
We are currently investigating this.This work has been partially funded by theFrench Government under the project INSTAR (ANRJCJC06 143038).ReferencesYoshua Bengio, Rejean Ducharme, Pascal Vincent, andChristian Jauvin.
2003.
A neural probabilistic lan-guage model.
JMLR, 3(2):1137?1155.Frank Vanden Berghen and Hugues Bersini.
2005.
CON-DOR, a new parallel, constrained extension of powell?sUOBYQA algorithm: Experimental results and com-parison with the DFO algorithm.
Journal of Computa-tional and Applied Mathematics, 181:157?175.Daniel De?chelotte, Holger Schwenk, He?le`ne Bonneau-Maynard, Alexandre Allauzen, and Gilles Adda.2007.
A state-of-the-art statistical machine translationsystem based on moses.
In MT Summit, pages 127?133.D.
Jones.
2008.
DLPT* MT comprehension test re-sults, Oral presentation at the 2008 Nist MT Evalua-tion workshop, March 27.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrased-based machine translation.In HLT/NACL, pages 127?133.Philipp Koehn et al 2007.
Moses: Open source toolkitfor statistical machine translation.
In ACL, demonstra-tion session.Franz Josef Och and Hermann Ney.
2002.
Discrimina-tive training and maximum entropy models for statis-tical machine translation.
In ACL, pages 295?302.Franz Josef Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignement models.Computational Linguistics, 29(1):19?51.Maja Popovic?
and Hermann Ney.
2006.
Statisticalmachine translation with a small amount of bilingualtraining data.
In LREC workshop on Minority Lan-guage, pages 25?29.Holger Schwenk, Marta R. Costa-jussa`, and Jose?
A. R.Fonollosa.
2006.
Continuous space language modelsfor the IWSLT 2006 task.
In IWSLT, pages 166?173,November.Holger Schwenk.
2007a.
Building a statistical machinetranslation system for French using the Europarl cor-pus.
In Second Workshop on SMT, pages 189?192.Holger Schwenk.
2007b.
Continuous space languagemodels.
Computer Speech and Language, 21:492?518.Andreas Stolcke.
2002.
SRILM - an extensible languagemodeling toolkit.
In ICSLP, pages II: 901?904.Stephan Vogel, Ying Zhang, Fei Huang, Alicia Trib-ble, Ashish Venugopal, Bing Zhao, and Alex Waibel.2003.
The CMU statistical machine translation sys-tem.
In MT Summit, pages 402?409.122
