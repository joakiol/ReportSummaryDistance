Multi-label Text Categorization with Model Combinationbased on F1-score MaximizationAkinori Fujino, Hideki Isozaki, and Jun SuzukiNTT Communication Science LaboratoriesNTT Corporation2-4, Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan 619-0237{a.fujino,isozaki,jun}@cslab.kecl.ntt.co.jpAbstractText categorization is a fundamental task innatural language processing, and is gener-ally defined as a multi-label categorizationproblem, where each text document is as-signed to one or more categories.
We fo-cus on providing good statistical classifierswith a generalization ability for multi-labelcategorization and present a classifier de-sign method based on model combinationand F1-score maximization.
In our formu-lation, we first design multiple models forbinary classification per category.
Then,we combine these models to maximize theF1-score of a training dataset.
Our experi-mental results confirmed that our proposedmethod was useful especially for datasetswhere there were many combinations of cat-egory labels.1 IntroductionText categorization is a fundamental task in suchaspects of natural language processing as informa-tion retrieval, information extraction, and text min-ing.
Since a text document often belongs to multiplecategories in real tasks such as web pages and in-ternational patent categorization, text categorizationis generally defined as assigning one or more pre-defined category labels to each data sample.
There-fore, developing better classifiers with a generaliza-tion ability for such multi-label categorization tasksis an important issue in the field of machine learning.A major and conventional machine learning ap-proach to multi-label categorization is based on bi-nary classification.
With this approach, we assumethe independence of categories and design a binaryclassifier for each category that determines whetheror not to assign a category label to data samples.Statistical classifiers such as the logistic regressionmodel (LRM), the support vector machine (SVM),and naive Bayes are employed as binary classi-fiers (Joachims, 1998).In text categorization, the F1-score is often usedto evaluate classifier performance.
Recently, meth-ods for training binary classifiers to maximize theF1-score have been proposed for SVM (Joachims,2005) and LRM (Jansche, 2005).
It was con-firmed experimentally that these training methodswere more effective for obtaining binary classifierswith better F1-score performance than the minimumerror rate and maximum likelihood used for train-ing conventional classifiers, especially when therewas a large imbalance between positive and nega-tive samples.
In multi-label categorization, macro-and micro-averaged F1-scores are often used to eval-uate classification performance.
Therefore, we canexpect to improve multi-label classification perfor-mance by using binary classifiers trained to maxi-mize the F1-score.On the other hand, classification frameworksbased on classifier combination have also been stud-ied in many previous works such as (Wolpert, 1992;Larkey and Croft, 1996; Ting and Witten, 1999;Ghahramani and Kim, 2003; Bell et al, 2005;Fumera and Roli, 2005), to provide better classi-fier systems.
In the classifier combination researchfield, it is known that weighted linear combinationsof multiple classifiers often provide better classifica-tion performance than individual classifiers.823We present a classifier design method based onthe combination of multiple binary classifiers to im-prove multi-label classification performance.
In ourframework, we first train multiple binary classifiersfor each category.
Then, we combine these bi-nary classifiers with weights estimated to maximizemicro- or macro-averaged F1-scores, which are of-ten used for evaluating multi-label classifiers.
To es-timate combination weights, we extend the F1-scoremaximization training algorithm for LRM describedin (Jansche, 2005).
Using three real text datasets,we show experimentally that our classifier designmethod is more effective than the conventional bi-nary classification approaches to multi-label catego-rization.Our method is based on a binary classification ap-proach.
However, Kazawa et al (2005) proposeda method for modeling a map directly from datasamples to the combination of assigned category la-bels, and confirmed experimentally that the methodoutperformed conventional binary classification ap-proaches.
Therefore, we also compare our methodwith the direct mapping method experimentally.2 F1-score Maximization Training of LRMWe first review the F1-score maximization trainingmethod for linear models using a logistic functiondescribed in (Jansche, 2005).
The method was pro-posed in binary classification settings, where classi-fiers determine a class label assignment y ?
{1, 0}for a data sample represented by a feature vector x.Here, y(n) = 1 (= 0) indicates that the class label isassigned (unassigned) to the nth feature vector x(n).The discriminative function of a binary classifierbased on a linear model is often defined asf(x;?)
= ?t1x + ?0, (1)where ?
= (?0,?t1)t is a model parameter vector,and ?t1x implies the inner product of ?1and x. Abinary classifier using f(x;?)
outputs a predictedclass label assignment y?
for x as y?
(n) = 1 (= 0)when f(x(n);?)
?
0 (< 0).An LRM is a binary classifier that uses the dis-criminative function f(x;?).
In this model, theclass posterior probability distribution is defined byusing a logistic function:g(z) = {1 + exp(?z)}?1.
(2)That is, P (y = 1|x;?)
= g(f(x;?))
and P (y =0|x;?)
= 1 ?
P (y = 1|x;?)
= g(?f(x;?
)).The LRM determines that y(n) = 1 (= 0) whenP (y = 1|x(n);?)
?
0.5 (< 0.5), since g(0) = 0.5.The model parameter vector ?
is usually estimatedto maximize the likelihood of P (y|x;?)
for trainingdataset D = {x(m), y(m)}Mm=1 and the prior proba-bility density of ?:JR(?)
=M?m=1log P (y(m)|x(m);?)
+ log p(?).
(3)In this paper, the classifier design approach that em-ploys this training method is called LRM-L.By contrast, in the training method proposedby (Jansche, 2005), the discriminative functionf(x;w) is estimated to maximize the F1-score oftraining dataset D. This training method employs anapproximate form of the F1-score obtained by usinga logistic function.The F1-score is defined as F1= 2(1/PR +1/RE)?1, where PR and RE represent precisionand recall defined as PR = C/A and RE = C/B,respectively.
Here, C represents the number of datasamples whose true and predicted class label assign-ments, y(n) and y?
(n), respectively, correspond to 1.A represents the number of data samples for whichy?
(n) = 1.
B represents the number of data samplesfor which y(n) = 1.
C , A, and B are computedfor training dataset D as C =?Mm=1 y(m)y?
(m),A =?Mm=1 y?
(m), and B =?Mm=1 y(m).In (Jansche, 2005), y?
(m) was approximated by us-ing the discriminative and logistic functions shownin Eqs.
(1) and (2) asy?(m)?
g(?f(x(m);?
)), ?
> 0, (4)because lim???
g(?f(x(m);?))
= y?(m).
Then, anapproximate distribution of the F1-score for trainingdataset D was provided asF?1(?)
=2?Mm=1 g(?f(x;?
))y(m)?Mm=1 y(m) +?Mm=1 g(?f(x;?)).
(5)The ?
estimate for the discriminative functionf(x;?)
can be computed to maximize JF (?)
=log F?1(?)
+ log p(?)
around the initial ?
value byusing a gradient method.
In this paper, the classi-fier design approach that uses this training methodis called LRM-F.8243 Proposed MethodWe propose a framework for designing a multi-labelclassifier based on the combination of multiple mod-els.
In our formulation, multiple models are com-bined with weights estimated to maximize the F1-scores of the training dataset.
In this section, weshow our formulation for model combination andtraining methods for combination weights.3.1 Combination of Multiple Models forMulti-label CategorizationMulti-label categorization is the task of selectingmultiple category labels from K pre-defined cat-egory labels for each data sample.
Multi-labelclassifiers provide a map from a feature vectorx to a category label assignment vector y =(y1, .
.
.
, yk, .
.
.
, yK)t, where y(n)k = 1 (= 0) indi-cates that the kth category label is assigned (unas-signed) to x(n).In our formulation, we first design multiple mod-els for binary classification per category and ob-tain J ?
K discriminative functions, where J is thenumber of models.
The discriminative function ofthe jth model for the kth category is denoted byfjk(x;?jk), where ?jk represents the model param-eter vector.
Let ?
= {?jk}j,k be a model parameterset.
We train model parameter vectors individuallywith each model training algorithm and obtain theestimate ??
= {??jk}jk.
Then, we define the dis-criminative function of our multi-label classifier bycombining multiple models such asfk(x; ?
?,w) =J?j=1wjfjk(x; ?
?jk) + w0, ?k, (6)where w = (w0, w1, .
.
.
, wj , .
.
.
, wJ)t is a weightparameter vector and is independent of k. wj pro-vides the combination weight of the jth model, andw0is the bias factor for adjusting the threshold ofthe category label assignment.We estimate the w value to maximize themicro-averaged F1-score (F?
), which is often usedfor evaluating multi-label categorization perfor-mance.
The F?-score of training dataset D ={x(m),y(m)}Mm=1 is calculated asF?
=2?Mm=1?Kk=1 y(m)k y?
(m)k?Mm=1?Kk=1 y(m)k +?Mm=1?Kk=1 y?
(m)k, (7)We provide an approximate form of the F?-score ofthe training dataset, F??(?
?,w), by using the approx-imation:y?
(m)k ?
g(?fk(x(m); ?
?,w)), ?
> 0, (8)as shown in Eq.
(4).
In our proposed method, w isestimated to maximize F??(?
?,w).However, training dataset D is also used to es-timate ?.
Using the same training data samplesfor both ?
and w may lead to a bias estimation ofw.
Thus, we used an n-fold cross-validation of thetraining data samples to estimate w as in (Wolpert,1992).
Let ??
(?m) be the model parameter set esti-mated by using n ?
1 training data subsets not con-taining {x(m),y(m)}.
Then, usingF??
=2?m,k y(m)k g(?fk(x; ??
(?m),w))?m,k y(m)k +?m,k g(?fk(x; ??
(?m),w)), (9)we provide the objective function of w such thatJ?
(w) = log F??
+ log p(w), (10)where p(w) is a prior probability density of w.We use a Gaussian prior (Chen and Rosenfeld,1999) with the form as p(w) ?
?Jj=0 exp{?
(wj ?
?j)2/2?2j }, where ?j , and ?j are hyperparameters inthe Gaussian prior.
We compute an estimate of w tomaximize J?
(w) around the initial w value by usinga quasi-Newton method.
In this paper, this formula-tion is called model combination by micro-averagedF1-score maximization (MC-F?
).3.2 Other Training MethodsIn multi-label categorization problems, the macro-averaged F1-score (FM ) is also used to evaluateclassifiers.
Moreover, the average labeling F1-score(FL) has been used to evaluate the average labelingperformance of classifiers for data samples (Kazawaet al, 2005).
These F1-scores are computed fortraining dataset D asFM =1KK?k=12?Mm=1 y(m)k y?
(m)k?Mm=1 y(m)k +?Mm=1 y?
(m)k, (11)FL =1MM?m=12?Kk=1 y(m)k y?
(m)k?Kk=1 y(m)k +?Kk=1 y?(m)k.
(12)Using Eq.
(8), we can also obtain the approxi-mate forms, F?M (?
?,w) and F?L(?
?,w), of the FM -825and FL-scores, and then present similar objectivefunctions to that for the F?-score.
Therefore, inthe next section, we examine experimentally the per-formance of classifiers obtained by estimating w tomaximize F?M (?
?,w) and F?L(??,w).
In this paper,these model combination methods based on FM -and FL-scores are called MC-FM and MC-FL, re-spectively.4 Experiments4.1 Test CollectionsTo evaluate our proposed method empirically, weused three test collections: Reuters-21578 (Reuters),WIPO-alpha (WIPO), and Japanese Patent (JPAT)datasets.
Reuters and WIPO are English documentdatasets and have often been employed for bench-mark tests of multi-label classifiers.The Reuters dataset contains news articles fromthe Reuters newswire and consists of 135 topic cate-gories.
Following the setup in (Yang and Liu, 1999),we extracted 7770 and 3019 articles as training andtest samples, respectively.
A subset consisting of thetraining and test samples contained 90 topic cate-gories.
We removed vocabulary words included ei-ther in the stoplist or in only one article.
There were16365 vocabulary words in the dataset.The WIPO dataset consists of patent documentscategorized using the International Patent Classifica-tion (IPC) taxonomy (Fall et al, 2003).
The IPC tax-onomy has four hierarchical layers: Section, Class,Subclass, and Group.
Using patent documents be-longing to Section D (textiles; paper), we evalu-ated classifiers in a task that consisted of selectingassigned category labels from 160 groups for eachpatent document.
Following the setting provided inthe dataset, we extracted 1352 and 358 patent docu-ments as training and test samples, respectively.
Weremoved vocabulary words in the same way as forReuters.
There were 45895 vocabulary words in thedataset.The JPAT dataset (Iwayama et al, 2007) con-sists of Japanese patent documents published be-tween 1993 and 1999 by the Japanese Patent Office.These documents are categorized using a taxonomyconsisting of Themes and F-terms.
The themes aretop-label categories, and the patent documents be-longing to each theme are categorized by using F-Reuters WIPO JPATNav 1.17 1.28 10.5Nmax 15 6 40K 90 160 268Nds 10789 1710 2464NLC 468 378 2430Nds/NLC 23.1 4.52 1.01Table 1: Statistical information of three datasets:Nav and Nmax are the average and maximum num-ber of assigned category labels per data sample, re-spectively.
K and Nds are the number of categorylabels and data samples, respectively.
NLC is thenumber of category label combinations appearing ineach dataset.terms.
Using patent documents belonging to Theme5J104, we evaluated classifiers in a task that con-sisted of selecting assigned category labels from 268F-terms for each patent document.
1920 patent doc-uments published between 1993 and 1997 were usedas training samples, and 544 patent documents pub-lished between 1998 and 1999 were used test sam-ples.
We extracted Japanese nouns, verbs, and adjec-tives from patent documents by using a morpholog-ical analyzer named MeCab 1, and removed vocab-ulary words included in only one patent document.There were 21135 vocabulary words in the dataset.Table 1 shows statistical information about thecategory label assignment of the data samples for thethree datasets.
The average numbers of assigned cat-egory labels per data sample, Nav , for Reuters andWIPO were close to 1 and much smaller than thatfor JPAT.
The number of category label combina-tions, NLC , included in JPAT was larger than thosefor Reuters and WIPO.
These statistical informationresults show that JPAT is a more complex multi-labeldataset than Reuters or WIPO.4.2 Experimental SettingsFor text categorization tasks, we employed word-frequency vectors of documents as feature vectorsinput into classifiers, using the independent word-based representation, known as the Bag-of-Words(BOW) representation.
We normalized the L1-norms of the word-frequency vectors to 1, to miti-gate the effect of vector size on computation.
Wedid not employ any word weighting methods suchas inverse document frequency (IDF).1http://mecab.sourceforge.net/826We constructed three multi-label text classifiersbased on our proposed model combination methods,MC-F?, MC-FM , and MC-FL, where LRM andSVM (J = 2) were employed as binary classifica-tion models combined with each method.
We trainedthe LRM by using LRM-L described in Section 2,where a Gaussian prior was used as the prior proba-bility density of the parameter vectors.
We providedthe SVM by using SVMlight 2 (SVM-L), where weemployed a linear kernel function and tuned the C(penalty cost) parameter as a hyperparameter.To evaluate our proposed method, we examinedthe micro- and macro-averaged, and average label-ing F1-scores (F?, FM , and FL), of test samples ob-tained with the three classifiers based on MC-F?,MC-FM , and MC-FL.
We compared the perfor-mance of the three classifiers with that of two binaryclassification approaches, where LRM-L or SVM-Lwas used for binary classification.We also examined two binary classification ap-proaches using LRM-F and SVM-F. For LRM-F, weused a Gaussian prior and provided the initial pa-rameter vector with a parameter estimate obtainedwith LRM-L. SVM-F is a binary classifier designapproach that employs SVMperf 3.
For SVM-F, weused a linear kernel function, set the L (loss parame-ter) parameter to maximize the F1-score, and tunedthe C (penalty cost) parameter as a hyperparameter.Moreover, we examined the performance of theMaximal Margin Labeling (MML) method (Kazawaet al, 2005), which models the map from featurevectors to category label assignment vectors, be-cause it was reported that MML provides better per-formance than binary classification approaches.We tuned the hyperparameter of SVM-F for JPATto provide good performance for test samples, be-cause the computational cost for training was high.We tuned the other hyperparameters by using a 10-fold cross-validation of training samples.4.3 Results and DiscussionIn Table 2, we show the classification performanceobtained for three datasets with our proposed andother methods described in Section 4.2.
We ex-amined nine evaluation scores: the micro-averagedF1-score (F?
), precision (P?
), and recall (R?
), the2http://svmlight.joachims.org/3http://svmlight.joachims.org/svm perf.htmlMethod F?
(P?/R?)
FM (PM /RM ) FL (PL/RM )MC-F?
87.0 (87.4/86.7) 51.3 (60.0/48.4) 90.0 (90.1/92.3)MC-FM 85.0 (80.8/89.5) 53.9 (54.9/58.4) 89.7 (88.5/94.1)MC-FL 86.3 (84.3/88.3) 53.4 (59.6/52.6) 90.0 (89.3/93.6)LRM-L 85.2 (87.3/83.2) 46.1 (55.0/43.1) 86.9 (87.6/88.6)LRM-F 85.2 (87.2/83.2) 47.4 (58.5/42.7) 87.0 (87.6/88.7)SVM-L 87.1 (92.9/82.0) 48.9 (58.9/45.8) 88.1 (89.3/88.8)SVM-F 82.4 (78.9/86.2) 51.4 (49.4/60.1) 87.4 (86.9/91.4)MML 87.8 (92.6/83.4) 59.3 (62.6/60.0) 91.2 (91.7/93.2)(a) ReutersMethod F?
(P?/R?)
FM (PM /RM ) FL (PL/RM )MC-F?
51.4 (57.3/46.6) 30.4 (35.8/30.3) 46.9 (48.3/51.5)MC-FM 48.1 (46.1/50.4) 32.2 (33.8/36.0) 46.8 (46.3/56.0)MC-FL 48.6 (45.8/51.9) 32.5 (33.4/36.5) 47.1 (46.4/56.8)LRM-L 40.5 (68.0/28.9) 22.1 (33.7/17.9) 32.7 (36.5/32.0)LRM-F 41.0 (68.6/29.2) 22.3 (34.0/18.1) 33.2 (37.0/32.4)SVM-L 41.8 (61.9/31.5) 24.4 (34.2/21.0) 35.1 (38.8/35.3)SVM-F 48.3 (53.8/43.8) 32.3 (37.4/31.8) 45.6 (47.9/49.6)MML 48.6 (54.9/43.6) 30.8 (36.5/29.7) 49.4 (56.2/48.4)(b) WIPOMethod F?
(P?/R?)
FM (PM /RM ) FL (PL/RM )MC-F?
41.8 (42.6/41.1) 17.5 (21.4/17.4) 40.2 (43.5/44.4)MC-FM 40.6 (35.8/46.7) 20.2 (20.4/23.1) 39.4 (37.7/50.6)MC-FL 42.1 (42.3/41.9) 17.6 (21.1/17.8) 40.5 (43.2/45.2)LRM-L 33.9 (44.4/27.4) 15.8 (20.9/14.0) 32.2 (46.5/29.9)LRM-F 36.9 (44.6/31.5) 16.9 (22.9/14.7) 35.1 (47.3/34.1)SVM-L 33.3 (39.6/28.7) 16.3 (20.9/14.6) 31.9 (42.4/31.6)SVM-F 32.2 (28.6/36.8) 19.7 (15.0/38.4) 31.0 (30.7/40.0)MML 32.7 (42.1/26.8) 14.7 (19.4/12.9) 32.2 (51.8/30.5)(c) JPATTable 2: Micro- and macro-averaged, and averagelabeling F1-scores (%) with our proposed and con-ventional methods.macro-averaged F1-score (FM ), precision (PM ),and recall (RM ), and the average labeling F1-score(FL), precision (PL), and recall (RL) of the test sam-ples.
FM and PM were calculated by regarding boththe F1-score and precision as zero for the categorieswhere there were no data samples predicted as posi-tive samples.LRM-F and SVM-F outperformed LRM-L andSVM-L in terms of FM -score for the three datasets,respectively.
The training methods of LRM-F andSVM-F were useful to improve the FM -scores ofLRM and SVM, as reported in (Jansche, 2005;Joachims, 2005).
The F?- and FL-scores of LRM-Fwere similar or better than those of LRM-L. LRM-F was effective in improving not only the FM -scorebut also the F?- and FL-scores obtained with LRM.Let us evaluate our model combination methods.827MC-F?
provided better F?-scores than LRM-F andSVM-F.
The FM -scores of MC-FM were similar orbetter than those of LRM-F and SVM-F. Moreover,MC-FL outperformed LRM-F and SVM-F in termsof FL-scores.
The binary classifiers designed by us-ing LRM-F and SVM-F were trained to maximizethe F1-score for each category.
On the other hand,MC-F?, MC-FM , and MC-FL classifiers were con-structed by combining LRM and SVM with weightsestimated to maximize the F?-, FM -, and FL-scores,respectively.
The experimental results show that ourtraining methods for combination weights were use-ful for obtaining better multi-label classifiers.MC-F?, MC-FM , and MC-FL outperformedMML as regards the three F1-scores for JPAT.
How-ever, MML performed better for Reuters than MC-F?, MC-FM , and MC-FL, and provided a better FL-score for WIPO.
As shown in Table 1, there weremore category label combinations for JPAT than forReuters or WIPO.
As a result, there were fewer datasamples for the same category label assignment forJPAT.
Therefore, MML, which learns the map di-rectly from the feature vectors to the category labelassignment vectors, would have been overfitted tothe training dataset for JPAT.
By contrast, our modelcombination methods employ binary classifiers foreach category, which mitigates such an overfittingproblem.
Our model combination methods will beuseful for complex datasets where there are manycategory label combinations.5 ConclusionWe proposed a multi-label classifier design methodbased on model combination.
The main idea be-hind our proposed method is to combine multiplemodels with weights estimated to maximize evalua-tion scores such as the micro- and macro-averaged,and average labeling F1-scores.
Using three realtext datasets, we confirmed experimentally that ourproposed method provided similar or better perfor-mance than conventional binary classification ap-proaches to multi-label categorization.
We also con-firmed that our proposed method was useful fordatasets where there were many combinations ofcategory labels.
Future work will involve trainingour multi-label classifier by using labeled and un-labeled samples, which are data samples with andwithout category label assignment.ReferencesDavid A.
Bell, J. W. Guan, and Yaxin Bi.
2005.
Oncombining classifier mass functions for text categorization.IEEE Transactions on Knowledge and Data Engineering,17(10):1307?1319.Stanley F. Chen and Ronald Rosenfeld.
1999.
A Gaussian priorfor smoothing maximum entropy models.
Technical report,Carnegie Mellon University.C.
J.
Fall, A.
To?rcsva?ri, K. Benzineb, and G. Karetka.
2003.Automated categorization in the international patent classifi-cation.
ACM SIGIR Forum, 37(1):10?25.Giorgio Fumera and Fabio Roli.
2005.
A theoretical and exper-imental analysis of linear combiners for multiple classifiersystems.
IEEE Transactions on Pattern Analysis and Ma-chine Intelligence, 27(6):942?956.Zoubin Ghahramani and Hyun-Chul Kim.
2003.
Bayesianclassifier combination.
Technical report, Gatsby Computa-tional Neuroscience Unit, University College London.Makoto Iwayama, Atsushi Fujii, and Noriko Kando.
2007.Overview of classification subtask at NTCIR-6 patent re-trieval task.
In Proceedings of the 6th NTCIR WorkshopMeeting on Evaluation of Information Access Technologies(NTCIR-6), pages 366?372.Martin Jansche.
2005.
Maximum expected F-measure train-ing of logistic regression models.
In Proceedings ofHuman Language Technology Conference and Conferenceon Empirical Methods in Natural Language Processing(HLT/EMNLP2005), pages 692?699.Thorsten Joachims.
1998.
Text categorization with supportvector machines: Learning with many relevant features.
InProceedings of the 10th European Conference on MachineLearning (ECML ?98), pages 137?142.Thorsten Joachims.
2005.
A support vector method for multi-variate performance measures.
In Proceedings of the 22ndInternational Conference on Machine Learning (ICML?05),pages 377?384.Hideto Kazawa, Tomonori Izumitani, Hirotoshi Taira, andEisaku Maeda.
2005.
Maximal margin labeling for multi-topic text categorization.
In Advances in Neural InformationProcessing Systems 17, pages 649?656.
MIT Press, Cam-bridge, MA.Leah S. Larkey and W. Bruce Croft.
1996.
Combining classi-fiers in text categorization.
In Proceedings of the 19th ACMInternational Conference on Research and Development inInformation Retrieval (SIGIR-96), pages 289?297.Kai Ming Ting and Ian H. Witten.
1999.
Issues in stackedgeneralization.
Journal of Artificial Intelligence Research,10:271?289.David H. Wolpert.
1992.
Stacked generalization.
Newral Net-works, 5(2):241?259.Yiming Yang and Xin Liu.
1999.
A re-examination of textcategorization methods.
In Proceedings of the 22nd ACMInternational Conference on Research and Development inInformation Retrieval (SIGIR-99), pages 42?49.828
