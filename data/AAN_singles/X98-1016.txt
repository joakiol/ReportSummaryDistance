Transforming Examples into Patterns for Information ExtractionRoman Yangarber and Ralph GrishmanDept .
of  Computer  Sc ienceNew York  Un ivers i ty715 Broadway,  7 th  F loorNew York ,  NY  10003, USAroman,  g r i shman~cs .nyu .eduAbstractInformation Extraction (IE) systems today are com-monly based on pattern matching.
The patterns areregular expressions tored in a customizable knowl-edge base.
Adapting an IE system to a new subjectdomain entails the construction of a new pattern base- -  a time-consuming and expensive task.
We describea strategy for building patterns from examples.
Toadapt the IE system to a new domain quickly, theuser chooses a set of examples in a training text, andfor each example gives the logical form entries whichthe example induces.
The system transforms theseexamples into patterns and then applies meta-rulesto generalize these patterns.1 IntroductionThe task of Information Extraction (IE) as under-stood in this paper is the selective xtraction of mean-ing from free natural language text.
1 This kind oftext analysis is distinguished from others in Natu-ral Language Processing in that "meaning" is under-stood in a narrow sense - in terms of a fixed set of se-mantic objects, namely, entities, relationships amongthese entities, and events in which these entities par-ticipate.
These objects belong to a small number oftypes, all having fixed regular structure, within a fixedand closely circumscribed subject domain, which per-mits the objects to be stored in a database (e.g., arelational data base).
These characteristics make theIE task both simpler and more tractable than themore ambitious problem of general text understand-ing.
They allow us to define the notion of a "correctanswer", and, therefore, to conduct quantitative val-uation of performance ofan IE system.
A series of for-mal evaluations - -  the Message Understanding Con-1For a review of a range of extraction systems, the readeris referred to \[9\].ferences (MUCs), 2 conducted over the last decade - -are described in \[8, 6\].The MUCs have yielded some widely (if not uni-versally) accepted wisdom regarding IE:?
Customization and portability is an importantproblem: to be considered a useful tool, an IEsystem must be able to perform in a variety ofdomains.?
Systems have modular design: Control is encap-sulated in immutable core engines, which drawupon domain- or scenario-specific nformationstored in knowledge bases (KB) which are cus-tomized for each new domain and scenario.?
Text analysis is based on pattern matching: regu-lar expression pattern matching is a widely usedstrategy in the IE community.
Pattern match-ing is a form of deterministic bottom-up par-tial parsing.
This approach has gained consid-erable popularity due to limitations on the accu-racy of full syntactic parsers, and the adequacyof partial, semantically-constrained, parsing forthis task \[2, 1, 5\].?
Building effective patterns for a new domain isthe most complex and time-consuming part ofthe customization process; it is highly error-prone, and requires detailed knowledge of systeminternals.In view of these findings, it becomes evident hat hav-ing a disciplined method of customizing the pattern2In this paper we will use IE terminology accepted in theMUC literature.
A subject domain will denote the class oftextual documents to be processed, such as "business news,"while scenario will refer to the set of facts to be extracted,i.e., the specific extraction task that is applied to documentswithin the domain.
One example of a scenario is "executivesuccession", the task tested in MUC-6, where the system seeksto identify events in which corporate managers left their postsor assumed new ones.97J,)Name RecognitionT  Noun,Vor  rou   ' !.
<>Noun PhrasesEventsPattern Base :Ref6rence::Res01:Ution?
.
.
.
.
.
.
.
.
.
- , .
.
.
.
.
-  ,Semantic ConceptHierarchyInferenceRules?
Disc0urSe!
I!nfei~ence?
- .
.
.
.
.
, .
.
.
.
.
.
.
.
, .
.
:!0utpUt: Ge:nerati0n: :!Figure 1: IEsystemarchitecturebase is essential.
It is particularly valuable if themethod allows naive users (i.e., non-developers, un-familiar with system internals) to customize the sys-tem.
The current work describes uch a method.2 Structure of the IE SystemAn outline of our IE system \[5, 11, 12\] is shown infigure 1.
The system is a pipeline of modules: eachmodule draws on attendant KBs to process its input,and passes its output to the next module.The lexical analysis module is responsible forbreaking up the document into sentences, and sen-tences into tokens.
This module draws on a set ofon-line dictionaries.
Lexical analysis attaches to eachtoken a reading, or a list of alternative readings, incase the token is syntactically ambiguous.
A read-ing contains a list of features and their values (e.g.,"syntactic ategory = Noun").
The lexical analyzerincorporates a statistical part-of-speech tagger, whicheliminates unlikely readings for each token, aThe name recognition module identifies propernames in the text by using local textual cues, suchSWe wish to thank BBN for providing us with their tagger.as capitalization, personal titles ("Mr.", "Esq.
"), andcompany suffixes ("Inc.", "C0.
").4 The next moduleidentifies small syntactic units, such as basic noungroups (nouns with their left modifiers) and verbgroups.
When it identifies a phrase, the system marksthe text segment with a semantic description, whichincludes the semantic lass of the head of the phrase.
5The next module (incrementally building on infor-mation gathered by the earlier modules) finds largernoun phrases, involving (for example) conjunction,apposition, and prepositional phrase modifiers, us-ing local semantic information.
The following mod-ule identifies cenario-specific clauses and nominaliza-tions.These four modules operate by matching patternsof successively increasing complexity against the in-put.
The patterns are regular expressions which trig-ger associated actions.
The actions perform opera-tions on the logical \]orm representation (LF) of theprocessed segments of the discourse.
The discourse is4Name recognition is a well-researched topic, with the bestavailable systems today reaching 96% accuracy in narrow do-mains.5These marks  are pointers to the corresponding entit ieswhich are created and added to the logical form.98Slot  Va lueclass C-Companyname Coca-Cola, Inc.location ...Figure 2: LF for the text: "Coca-Cola, Inc."thus represented as a sequence of LFs correspondingto the entities, relationships, and events encounteredso far in the analysis.A LF is an object with named slots (see examplein figure 2).
One slot in each LF, named "class", hasdistinguished status, and determines the number andtype of other slots that the object may contain.
E.g.,an entity of class "company" has a slot called "name".It also contains a slot "location" which points to an-other entity, thereby establishing a relation betweenthe location entity and the matrix entity.
Eventsare specific kinds of relations, usually having severaloperands (example in figure 3).The subsequent modules operate on the logicalforms built by the pattern matching modules.
Re/er-ence resolution merges co-referring expressions, e.g.,it links anaphoric pronouns to their antecedents.
Dis-course in/erence uses inference rules to build morecomplex event structures, where the informationneeded to extract a single complex fact is spreadacross several clauses.
Lastly, the output-generationphase formats the resultant LF into the output struc-ture specified by the user, e.g., into a database table.3 General  and Specific Pat-ternsBefore we describe our example-based strategy forbuilding patterns, we examine the organization of thepattern base in more detail.
We can group the pat-terns into "layers" according to their range of appli-cability:1.
Domain-independent: this layer contains themost generally applicable patterns.
Included inthis layer are many of the patterns for namerecognition (for people, organizations, and loca-tions, as well as temporal and numeric expres-sions, currencies, etc.
), and the purely syntacticpatterns for noun groups and verb groups.
Thesepatterns are useful in a wide range of tasks.2.
Domain-specific: the next layer contains domain-specific patterns, which are useful across a nar-rower range of scenarios, but still have consid-erable generality.
These include domain-specificname patterns, such as those for certain typesof artifacts, as well as patterns for noun phraseswhich express relationships among entities, suchas those between persons and organizations.. Scenario-specific: the last layer containsscenario-specific patterns, having the narrowestapplicability, such as the clausal patterns thatcapture relevant events.This stratification reflects the relative "persis-tence" of the patterns.
The patterns at the lowestlevel, having the widest applicability, are built in asa core component of the system.
These change littlewhen the system is ported to a new domain.
Themid-range patterns, applicable in certain commonlyencountered omains, can be organized as domain-specific pattern libraries, which can be plugged in asrequired by the extraction task.
6 For example, for the"business/economic news" domain, we have patternsthat capture:?
entities - organization, company, person, loca-tion;?
relations - person/organization, organiza-tion/location, parent/subsidiary organization.The scenario-specific patterns must be built on a per-scenario basis.
This is accomplished through a set ofgraphical tools, which engage the user only at thelevel of surface representations, hiding the internaloperation of the patterns.
The user's input is reducedto?
providing textual examples of events of interest,?
describing the corresponding output structures(LFs) which the example text should induce.In the remaining sections we discuss how the systemcan use this information to* automatically build patterns to map the user-specified text into the user-specified LF,?
generalize the newly created patterns to boostcoverage.6To a limited degree, the system is able to adapt o a newdomain automatically: given training data in the domain, wecan train a statistical proper name recognizer \[3\], in effect,obviating the need for building domain-specific name patterns.99...Information Resources Inc.'s London-based European Information Services opera-tion has appointed George Garrick, .40 yearsold, president .
.
.Field ValuePositionCompanyLocationPersonStatuspresidentEuropean Information ServicesLondonGeorge GarrickInFigure 3: Succession text and extracted record4 Example-based Acquisition4.1 Ob ject iveConsider a situation where the developer has founda salient text segment and proceeds to extend theIE system to extract he proper information from it.Figure 3 shows a (paraphrased) text segment from theMUC-6 development corpus, with the correspondingextracted event, in the form of a database record.
Wewill use this example to illustrate our methodology.In our earlier system (as in most other IE systems),upon finding a candidate xample, the developer hadto construct a pattern capable of capturing the ex-ample.
Such a pattern consists of two parts:?
the precondition, which seeks to match an activeclause beginning with a np of type "company",followed by a verb group (vg) of class "appoint",followed by a np of class "person", etc.;?
the action which fires when the pattern matches,and prescribes the operations to be performed onthe sentence fragments and the logical form.Figure 4 shows an excerpt from the pattern code; itis written in Common Lisp, with the preconditionspecified using a special "pattern language".
Clearly,this method of development is quite time-consumingand error-prone.Instead, we now employ a kind of a "bootstrap-ping" procedure: the system allows the user to intro-duce a new example and apply to it the patterns thatthe system has acquired so far.
This produces a par-tial analysis, and builds LFs for the analyzable con-stituents of the example text.
The user then specifieshow these LFs, or their sub-parts, combine to yieldthe LF for the entire example.
;;; For <company> appoints <person> <position>(definePattern Appoint"np(C-company)?
vg(C-appoint) np(C-person)to-be?
np(C-position):company=l.attributes, person=3.attributes,position=5.attributes I(definehction Appoint (phrase-type)( le t  ( (person-at  (binding 'person))(company-entity (entity-bound 'company))(person-entity (entity-bound 'person))(pos i t ion -ent i ty  (ent i ty-bound 'pos i t ion) )new-event);; if no company slot in position, use agentFigure 4: A manually coded scenario pattern4 .2  Acqu i r ing  Precond i t ionsTo illustrate this method, we first show how the sys-tem acquires the pattern for analyzing the portion ofour example shown in figure 6.
This is a complexNP made up of a series of nouns, names, and otherlexical items.
The crucial point is that a basic sys-tem, which has not been specialized for any domain,will analyze this reduced example as in figure 5 bydint of its built-in patterns for named entities.
7 Theanalysis also produces the LF entities for each boxedsegment.
This information is sufficient for the systemto propose a precondition for a candidate pattern: sn(C-company)  's  n(C-city)  -based  n(C-company) n(operation)The system then initiates an interaction with the userin which s/he can operate on the components, mod-ifying them or labeling them as optional (indicatedbelow by a following question mark), to complete theprecondition of the pattern:\[n(C-company) 's\]?
\[n(C-city)-based\]?
n(C-company) n(operation)?4 .3  Acqu i r ing  Act ionsNow the user specifies, again by example, what actionis to be performed when the precondition of the pat-tern matches.
S/he can select the new type of event7The customization tool supports two methods for analyz-ing specific noun group structures.
The approach describedhere involves the creation of a semantically-specific noun grouppattern.
Alternatively, the phrase can first be analyzed by thegeneral, syntactic noun group pattern, with the resulting LFthen restructured by a semantically-specific pattern.SFor purposes of presentation, we have simplified the formof these patterns to emphasize the parallel with the clausepatterns.
In the current implementation, each pattern elementwould involve a conjunction of tests for the syntactic type (n)and the semantic lass (C-company, etc.
).100company location companyI Information Resources Inc.
I ' s  ~ -based I Earopea n Information Services I operationFigure 5: Initial analysis.
.
.
Information Resources Inc. 's London-based European Information Services oper-ation .
..Slot Valueclass C-Companyname European Information Services~ocation entity ~ <London>parent  entity ~ <I.R.Inc.>Figure 6: A complex NP and corresponding entityLFor entity to be created, and indicate how the matchedconstituents (LFs) discovered in the example are tofunction in the new event.
Alternatively, s/he maydesignate one of the generated entities as the "head"entity (or the matrix entity) for the complex phrase,and designate the remaining entities as subordinate tothe matrix entity, i.e., as standing in some semanticrelation to it.
To accomplish this, the user can drag-and-drop a subordinate ntity into the appropriateslot in the matrix entity (in a simple GUI environ-ment); the slot serves to indicate the relationship ofthe subordinate ntity to the matrix; (see figure 6).The precondition and the action together now con-stitute a complete pattern which matches a complexNP and produces a LF with relations.4 .4  Semant ic  Genera l i za t ionConsider the final, optional constituent in the pre-condition of the preceding pattern, n(operation).
Wewould like to broaden the coverage of the pattern,so that it could match any semantically similar nounin that position; in particular, it should also match"concern", "outfit", etc.
To this end, our system al-lows the user to gather semantic oncepts in an in-heritance hierarchy.
For example, s/he can gatherall these and more lexemes under the same semanticclass, called, e.g., C-co-descrip.
Similarly, the classesC-city for city names and C-state for state nameswould be gathered under a concept C-location.
TheGUI tools then allow the user to perform semanticgeneralization on the individual constituents of thepattern's precondition; its final form becomes:Slot i Valuec~ass Pred icate -Star t - Jobcompany ent i ty  ~ <E.
I .S .>person entity ~ <Garrick>pos i t ion  entity ~ <president>Figure 7: Event LF corresponding to a clauseIn(C-company) 's\]?
\[n(C-location)-based\]?n(C-company) n(C-co-descrip)?The semantic hierarchy is scenario-specific.
It isbuilt up dynamically through tools that draw onpre-existing domain-independent hierarchies, uch asWordNet, as well as domain-specific word similaritymeasures and co-occurrence statistics \[4\].By a similar process, we can now acquire a clausalpattern from the example in figure 3 at the beginningof this ?section.
The system proposes the precondi-tion:np(C-company) vg(C-appoint) np(C-person)np(president)Applying semantic generalization to the last con-stituent yields:np(C-company) vg(C-appoint) np(C-person)np(C-title)where C-title is a semantic lass that gathers all cor-porate titles.
The user can now fill the slots in theLF for the event as in figure 7.5 Meta - ru lesConsider the following variant of the original exam-ple:... George Garrick, an avowed anti-capitalist, was appointed yesterday presi-dent of Information Resources Inc., ...The basic pattern for an active clause, which we ac-quired in the preceding section, will not match thisparaphrase.
There are two essential kinds of varia-tions here:101?
syntactic transformations; the system needs sev-eral related patterns, which capture the cor-responding passive clause, relative clause, andother syntactic variants of the example.?
optional, semantically irrelevant modifiers, e.g.,sentence adjuncts, appositions, etc., as exempli-fied by the italicized segments above.The user could, of course, provide transformed exam-ples, build patterns individually for each transforma-tion of the original, and insert the optional modifiersto make the patterns as general as possible.
How-ever, it is clear that this naive approach quickly leadsto a proliferation of patterns with which the user isdirectly concerned.
Instead, we have introduced ameta-rule mechanism: after a pattern is accepted,the system generates all related generalizations of thepattern automatically.
9 For example, from the activeclause pattern above, a passivizing meta-rule will pro-duce the precondition:np(C-person) rn?
sa?
pass-vg(C-appoint) sa?np(C-title) \[by np(C-company)\]?
lOThe resulting pattern will match the variant exam-ple, and produce the correct event LF.
To maximizecoverage, the system should contain meta-rules forall clausal variants, including nominalizations; imilarmeta-rules can be provided to generalize noun-phrasepatterns, as discussed in section 4.2.6 D iscuss ionWe have described a comprehensive methodology foracquiring patterns from examples and automaticallyexpanding their coverage.
Other IE systems employvariants of example-based pattern acquisition.
Onesystem, developed at University of Massachusetts atAmherst, \[10\], used unsupervised training to learnpatterns from the MUC training corpus.
However,unsupervised learning can degrade in the face of \[1\]sparse data; the UMass system seemed to require onemore order of magnitude of training data than wasavailable in MUC-6.
The HASTEN system, devel-oped by SRA \[7\], used a somewhat different example-based approach: they seek to broaden coverage byallowing statistically approximate matches, a strat-egy that lacks a syntactic basis, and may result inovergeneration.
\[2\]9A meta-rule mechanism is also included in the SRI FAS-TUS system\[2\].1?where rn is a pre-defined sub-pattern that matches variousright noun-phrase modifiers, a is a sentence adjunct, and pass-vg is a passive verb group.The presented methodology has been fully imple-mented as a set of tools that complement our coreinformation extraction engine, and has been testedon three different scenarios.
One of the scenarios wassuccessfully implemented by a computational linguistwho interacted with the system exclusively by meansof the tools, and had no familiarity with the systeminternals.Our experience also suggests areas of improvement,which we are currently pursuing.
One importantquestion is: where do examples come from?
We seekto shift the burden of inventing the examples fromthe developer to the system.
In response to theseproblems we are building tools that will help the usersurf the corpus to help discover patterns.7 Conc lus ionPorting an existing system to a new domain presentsan important problem in IE.
Effective techniques areneeded to minimize the time and complexity of theprocess, and to extricate the porting process fromlow-level system details, so that it can be undertakenby non-expert users.
In this report, we have describedour approach to the problem, based on:?
example-based acquisition of scenario-specificpatterns,?
system-aided generalization of acquired pat-terns, at the semantic and syntactic level.The experience we have gained from implementingthis strategy leads us to believe in its overall useful-ness.ReferencesDouglas Appelt, Jerry Hobbs, John Bear, DavidIsrael, Megumi Kameyama, Andy Kehler, DavidMartin, Karen Meyers, and Mabry Tyson.
SRIInternational FASTUS system: MUC-6 test re-sults and analysis.
In Proc.
Sixth Message Un-derstanding Conf.
(MUC-6), Columbia, MD,November 1995.
Morgan Kaufmann.Douglas Appelt, Jerry Hobbs, John Bear, DavidIsrael, and Mabry Tyson.
FASTUS: A finite-state processor for information extraction fromreal-world text.
In Proc.
13th Int'l Joint Conf.Artificial Intelligence (IJCAI-93), pages 1172-1178, August 1993.102[3] Andrew Borthwick, John Sterling, EugeneAgichtein, and Ralph Grishman.
Exploiting di-verse knowledge sources via maximum entropy innamed entity recognition.
In Proceedings of theSixth Workshop on Very Large Corpora, Mon-treal, Canada, August 1998.
[4] Ido Dagan, Shaul Marcus, and ShaulMarkovitch.
Contextual word similarityand estimation from sparse data.
In Proceed-ings of the 31st Annual Meeting of the Assn.for Computational Linguistics, pages 31-37,Columbus, OH, June 1993.
[5] Ralph Grishman.
The NYU system for MUC-6,or where's the syntax.
In Proc.
Sixth MessageUnderstanding Conf., pages 167-176, Columbia,MD, November 1995.
Morgan Kaufmann.
[6] Ralph Grishman and Beth Sundheim.
Mes-sage understanding conference - 6: A brief his-tory.
In Proc.
16th Int'l Conf.
on ComputationalLinguistics (COLING 96), Copenhagen, August1996.
[7] George Krupka.
SRA: Description of the SRAsystem as used for MUC-6.
In Proc.
Sixth Mes-sage Understanding Conf.
(MUC-6), Columbia,MD, November 1995.
Morgan Kaufmann.
[8] Proceedings of the Sixth Message UnderstandingConference (MUC-6), Columbia, MD, November1995.
Morgan Kaufmann.
[9] Maria Teresa Pazienza, editor.
Information Ex-traction.
Springer-Verlag, Lecture Notes in Ar-tificial Intelligence, Rome, 1997.
[10] W. Soderland, D. Fisher, J. Aseltine, andW.
Lenhert.
CRYSTAL: Inducing a conceptualdictionary.
In Proc.
Int'l Joint Conf.
ArtificialIntelligence (IJCAI-95), pages 1314-1319, Mon-treal, Canada, 1995.
[11] Roman Yangarber and Ralph Grishman.
Cus-tomization of information extraction systems.In Paola Velardi, editor, International Work-shop on Lexically Driven Information Extrac-tion, pages 1-11, Frascati, Italy, July 1997.
Uni-versitg di Roma.
[12] Roman Yangarber and Ralph Grishman.
NYU:Description of the Proteus/PET system as usedfor MUC-7 ST.
In MUC-7: Seventh Message Un-derstanding Conference, Columbia, MD, April1998.
Avaliable through the SAIC MUC website, http ://www.muc.
saic.
com/.103
