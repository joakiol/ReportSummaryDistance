Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 92?95,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPSubstring-based Transliteration with Conditional Random FieldsSravana Reddy and Sonjia WaxmonskyDepartment of Computer ScienceThe University of ChicagoChicago, IL 60637{sravana, wax}@cs.uchicago.eduAbstractMotivated by phrase-based translation research,we present a transliteration system where char-acters are grouped into substrings to be mappedatomically into the target language.
We show howthis substring representation can be incorporatedinto a Conditional Random Field model that useslocal context and phonemic information.1 IntroductionWe present a transliteration system that is moti-vated by research in phrase-based machine trans-lation.
In particular, we borrow the concept ofphrases, which are groups of words that are trans-lated as a unit.
These phrases correspond to multi-character substrings in our transliteration task.That is, source and target language strings aretreated not as sequences of characters but as se-quences of non-overlapping substrings.We model transliteration as a sequential label-ing task where substring tokens in the source lan-guage are labeled with tokens in the target lan-guage.
This is done using Conditional RandomFields (CRFs), which are undirected graphicalmodels that maximize the posterior probabilitiesof the label sequence given the input sequence.
Weuse as features both local contexts and phonemicinformation acquired from an English pronuncia-tion dictionary.2 The Transliteration ProcessOur transliteration system has the following steps:1.
Pre-processing of the target language.2.
Substring alphabet generation for both thesource and target.
This step also generatestraining data for the CRFs in Step 3 and 4.3.
CRF training on aligned data from Step 2.4.
Substring segmentation and translitera-tion of source language input.Our training and test data consists of three sets ?English to Hindi, English to Kannada, and Englishto Tamil (Kumaran and Kellner, 2007) ?
from theNEWS 2009 Machine Transliteration Shared Task(Li et al, 2009).2.1 Step 1: Pre-ProcessingThe written words of Hindi, Tamil, and Kannadacorrespond almost perfectly to their phonologicalforms, with each character mapping to a phoneme.The only exception to this arises from the implicitvowel (which may be a schwa /@/ or a centralvowel /5/) that is inserted after consonants thatare not followed by the halanta or ?killer stroke?.Hence, any mappings of an English vowel to atarget language schwa will not be reflected in thealignment of the named entity pair.To minimize misalignments of target languagestrings with the English strings during training,we convert the Indic abugida strings to an in-ternal phonemic representation.
The conversionmaps each unicode character to its correspond-ing phonemic character and inserts a single sym-bol (representing the schwa/central vowel) after allconsonants that are not followed by the halanta.These phoneme sequences are used as the in-ternal representation of Indic character strings forall later steps in our system.
Once transliterationis complete, the phonemic symbols are convertedback to unicode by reversing the above process.2.2 Step 2: Substring alphabet generationOur decision to use substrings in the transliterationtask is motivated by the differences in orthographyand phonology between the target and source lan-guages, which prevent trivial one-to-one characterlevel alignment.
We first discuss the cause of thepoor character alignment between English and the92Indic languages, and then describe how we trans-form the input into substring representation.English uses several digraphs for phonemesthat are represented by single characters in Indicscripts, which are either part of standard ortho-graphic convention (oo, ch, etc.
), or necessitatedby the lack of a single phoneme that approximatesan Indic one (as in the case of aspirated conso-nants).
Conversely, English sometimes uses a sin-gle character for a biphone (such as x for /ks/, oru for /ju/ as in museum), which is represented bytwo characters in the target languages.
In certaincases, a digraph in English is transliterated to a di-graph in the target, as a result of metathesis (le ?/@l/, in words like temple).
Further, all three tar-get languages often insert vowels between Englishconsonant clusters; for instance, Hindi inserts aschwa between s and p in ?transport?, transliter-ated as ?rAns@por?
(V~ A\spoV).To handle these cases, we borrow the concept ofphrases from machine translation (Och and Ney,2004), where groups of words are translated as aunit.
In the case of transliteration, the ?phrases?are commonly occurring substrings ?
sequencesof characters ?
in one language that map to acharacter or a substring in the other.
We use theterm ?substrings?
after a previous work (Sherif andKondrak, 2007) that employs it in a noisy channeltransliteration system.
Zhao et al (2007) also usesubstrings (which they call ?blocks?)
in a bi-streamHMM.We bootstrap the induction of substrings byaligning all named entity pairs in the training data,using the GIZA++ toolkit (Och and Ney, 2003).The toolkit performs unidirectional one-to-manyalignments, meaning that a single symbol in itssource string can be aligned to at most one sym-bol in its target.
In order to induce many-to-manyalignments, GIZA++ is run on the data in both di-rections (source language to target language andtarget language to source), and the bidirectionalalignment of a named entity pair is taken to be theunion of the alignments in each direction.
Anyinserted characters (maps within the alignmentwhere the source or target character is null) arecombined with the preceding character within thestring.
For example, the initial bidirectional align-ment of shivlal ?
Siv@lAl (E?vlAl) containsthe maps [sh ?
S, i ?
i, v ?
v, null ?
@, l ?
l,a ?
A, and l ?
l].
The null ?
@ map is combinedwith the preceding map to give v ?
v@, and hencea one-to-one alignment.Multicharacter units formed by bidirectionalalignments are added to source and target alha-bets.
The above example would add the substrings?sh?
to the source alphabet, and v@ to the target.Very low frequency substrings in both languagesare removed, giving the final substring alphabetsof single and multicharacter tokens.
These alpha-bets (summarized in Table 1) are used as the tokenset for the CRF in Step 3.We now transform our training data into asubstring-based representation.
The originalnamed entity pairs are replaced by their bidirec-tional one-to-one alignments described earlier.
Forexample, the ?s h i v l a l?
?
?S i v @ lA l?
training pair is replaced by ?sh i v l a l?
?
?S i v@ l A l?.
A few (less than 3%) of thepairs are not aligned one-to-one, since their bidi-rectional alignments contain low-frequency sub-strings that have not been included in the alpha-bet.1 These pairs are removed from the trainingdata, since only one-to-one alignments can be han-dled by the CRF.2.3 Step 3: CRF transliterationWith the transformed training data in hand, we cannow train a CRF sequential model that uses sub-strings rather than characters as the basic tokenunit.
The CRF algorithm is chosen for its abilityto handle non-independent features of the sourcelanguage input sequence.
We use the open-sourceCRF++ software package (Kudo, 2005).Ganesh et al (2008) also apply a CRF to thetransliteration task (Hindi to English) but withdifferent alignment methods than those presentedhere.
In particular, multicharacter substrings areonly used as tokens on the target (English) side,and a null token is used to account for deletion.We train our CRF using unigram, bigram, andtrigram features over the source substrings, as wellas pronunciation information described in ?2.3.1.Table 2 describes these feature sets.2.3.1 Phonetic informationSince the CRF model allows us to incorporate non-independent features, we add pronunciation dataas a token-level feature.
Doing so allows the CRFto use phonetic information for local decision-making.
Word pronunciations were obtained from1Note that if we did not filter out any of the substrings,every pair would be aligned one-to-one.93Target Language Source Target# of Tokens Longest Token # of Tokens Longest TokenHindi 196 augh, ough 141 Aj@ (aAy), ks@ (?s)Kannada 197 aine 137 Aj@, mjATamil 179 cque 117 mij, Aj@Table 1: Overview of the substring alphabets generated in Step 2.Feature Set DescriptionU Unigram: s?1, s0, and s1B Bigram: s?1+s0T Trigram: s?2+s?1+s0,s?1+s0+s1 and s0+s1+s2P Phoneme assigned to s0from dictionary lookupTable 2: Feature sets used for CRF in Step 3. si isthe substring relative to the current substring s0.the CMU Pronouncing Dictionary2.
Just over athird of the English named entities have pronun-ciation information available for some or all theconstituent words.The CMU dictionary provides a sequence ofphoneme symbols for an English word.
We in-clude these phonemes as CRF features if andonly if a one-to-one correspondence exists be-tween phonemes and substring tokens.
For exam-ple, the English word simon has the segmentation?s i m o n?
and pronunciation ?S AY M AH N?,both of length five.
Additionally, a check is doneto ensure that vowel phonemes do not align withconsonant characters and vice-versa.2.4 Step 4: Substring segmentationIn order to apply our trained model to unseendata, we must segment named entities into non-overlapping substrings that correspond to tokensin the source alphabet generated in Step 2.
For in-stance, we need to convert the four character deshto the three token sequence ?d e sh?.This is a non-trivial task.
We must allow forthe fact that substrings are not inserted every timethe component character sequence appears.
Forinstance, in our English/Hindi training set, the bi-gram ti always reduces to a single substring tokenwhen it occurs in the -tion suffix, but does not re-duce in any other contexts (like martini).
Thereare also cases where more than one non-trivial seg-mentation is possible.
For example, two possible2The CMU Pronouncing Dictionary (v0.7a).
Available athttp://www.speech.cs.cmu.edu/cgi-bin/cmudictsegmentations of desh are ?d es h?
and ?d e sh?,with the latter being the one that best correspondsto the three-character Hindi d?eS (d?
).One solution is to greedily choose the mostlikely multi-character substring ?
in the examplecited, we can choose ?d e sh?
because sh reducesmore frequently than es.
However, this creates theproblem in cases where no reduction should occur,as with the ti in martini.
Since contextual informa-tion is necessary to determine the correct substringsegmentation, we model segmentation with a CRF,using a combination of character unigram, bigram,and trigram features.We use an approach motivated by the In-side/Outside representation of NP-chunkingwhich treats segmentation as a tagging processover words (Ramshaw and Marcus, 1995).
Asin NP-chunking, our goal is to identify non-overlapping, non-recursive segments in our inputsequence.
Our tagset is {I, O, B} where Iindicates that a character is inside a substring, Oindicates a character is outside a substring, and Bmarks a right boundary.After the test data has been segmented into itssubstring representation, it can be passed as inputto the CRF model trained in Step 3 to produce ourfinal transliteration output.3 ResultsWe first report our results on the development dataprovided by the NEWS task, for different featuresets and segmentation methods.
We then presentthe performance of our system on the test data.33.1 Development DataTable 3 shows the results across feature sets.Noting that the trigram feature T provides asizable improvement, we compare results fromU+B+T+P and U+B+P feature sets.
Of the im-proved cases, 75-84% are a single vowel-to-vowel3For the development runs, we use the training set fortraining, and the development for testing.
For the final testruns, we use both the training and development sets for train-ing, and the test set for evaluation.94Language Feature Set ACC F-ScoreU+P 24.6 86.2Hindi U+B+P 26.2 86.5U+B+T+P 34.5 88.6U+B+T 34.2 88.3U+P 26.7 87.8Tamil U+B+P 27.6 88.0U+B+T+P 34.9 89.8U+B+T 33.1 89.7U+P 22.5 86.0Kannada U+B+P 22.6 86.2U+B+T+P 28.7 88.0U+B+T 27.5 87.9Table 3: Accuracy (ACC) and F-score results (in%) for CRF model on the development data.Language Feature Set ACC F-ScoreHindi U+B+T+P 34.4 90.2U+B+T 33.6 89.5Tamil U+B+T+P 29.1 91.1U+B+T 25.5 90.6Kannada U+B+T+P 27.2 89.8U+B+T 23.4 89.2Table 4: Results on development data, restricted toNEs where P is included as a feature.change, with the majority of the changes involvinga schwa/central vowel.We see small gains from using the phonetic fea-ture in both accuracy and F-Score.
We further ex-amine only those named entities where dictionaryinformation is applied, and as expected, this subsetshows greater improvement (Table 4).Table 5 compares our the Inside/Outside tag-ging approach with a greedy approach describedearlier.
The greedy approach only inserts a multi-character substring when that substring reducesmore than 50% of the time in the overall train-ing corpus.
Since the Greedy method uses nolocal contextual information, results are signifi-cantly lower given the same feature set.Language Segmentation ACC F-ScoreHindi I-O-B 34.5 88.6Greedy 30.3 86.7Tamil I-O-B 34.9 89.8Greedy 28.2 87.5Kannada I-O-B 28.7 88.0Greedy 25.0 86.7Table 5: Comparison of segmentation methodson development data, using the U+B+T+P featureset.3.2 Test DataOur model produces 10 candidates for each namedentity in the test data, ranked by the probabilitythat the model assigns the candidate.
We filter outcandidates below the rank of 5 whose scores areless than 0.5 lower than that of the highest rank-ing candidate.
Table 6 shows our results on thetest data, using a CRF trained on the training anddevelopment data, with the feature set U+B+T+P.Hindi Kannada TamilAccuracy 41.8 36.3 43.5F-Score 87.9 87.0 90.2MRR 54.6 48.2 57.2MAPref 41.2 35.5 43.0MAP10 18.3 16.4 19.5MAPsys 24.0 21.8 26.5Table 6: Final results on the test data (in %).ReferencesSurya Ganesh, Sree Harsh, Prasad Pingali, and Va-sudeva Varma.
2008.
Statistical transliteration forcross language information retrieval using HMMalignment model and CRF.
In Proceedings of the2nd Workshop on Cross Lingual Information Access.Taku Kudo.
2005.
CRF++: Yet another CRF toolkit.Available at http://chasen.org/ taku/software/crf++/.A.
Kumaran and Tobias Kellner.
2007.
A genericframework for machine transliteration.
In Proceed-ings of SIGIR-07.Haizhou Li, A Kumaran, Min Zhang, and VladimirPervouchine.
2009.
Whitepaper of NEWS 2009machine transliteration shared task.
In Proceed-ings of ACL-IJCNLP 2009 Named Entities Work-shop (NEWS 2009).Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Franz Josef Och and Hermann Ney.
2004.
The align-ment template approach to statistical machine trans-lation.
Computational Linguistics, 30(4):417?449.Lance Ramshaw and Mitch Marcus.
1995.
Textchunking using transformation-based learning.
InProceedings of WVLC-3.Tarek Sherif and Grzegorz Kondrak.
2007.
Substring-based transliteration.
In Proceedings of ACL-07.Bing Zhao, Nguyen Bach, Ian Lane, and Stephan Vo-gel.
2007.
A log-linear block transliteration modelbased on bi-stream HMMs.
In Proceedings ofNAACL HLT 2007.95
