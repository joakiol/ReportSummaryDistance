Spoken-Language Trans la t ion  Method Us ing  ExamplesHitoshi IIDA, Eiichiro SUMITA and Osamu FURUSEATR Interpreting Telecommunications Research Laboratories2-2 HikaridaiSeika-cho, Kyoto 619-02, JAPAN{iida, sumita, furuse}@itl.atr.co.jp1 In t roduct ionConventional approaches to machine translationare mostly concerned with written text, such astechnical documents.
This paper addresses theproblem of spoken-language translation and ex-plains the method and its capability to handlespoken language.2 Seven requ i rements  fo rspoken- language t rans la t ionThe following new design features are critical forsuccess in spoken-language translation:1.
Incremental processingIncremental processing is required so as tohandle fragmental phrases or incomplete ut-terances and to realize a real-time response.This has a very close relation with item 5 be-low.2.
Handling spoken languageFragmental phrases, isolated phrases, a gra-dient of case role changing, complex topical-ization, metonymical phrases, idiomatic ex-pressions for etiquette, and inconsistent ex-pressions in one utterance are main charac-teristics of spoken language.
They stronglydepend on dialogue situations.3.
Handling euphemistic expressionsUnder the influence of social position or situ-ation, euphemistic expressions appear in var-ious scenes in various forms.4.
Deterministic processingNeither pre-editing nor post-editing can berelied on in a speech translation system.
In-teractive disambiguation by speakers doesnot necessarily converge a correct interpre-tation.5.
Suff icient speed to avoid to break  com-mun icat ionAs an interpreter intervenes between speak-ers, real-time response is required to keepsmooth turn taking...High-quality translationThis is necessary in order to ensure correctinformation exchange between speakers.Recovering from speech recognition er-rorsThere are various aspects to recovering fromspeech recognition errors, for example incorrecting phoneme sequences, syllable se-quences, word sequences (including com-pound words and collocations).3 Meeting the seven requirements3.1 Incremental processingThis is an essential technology if one is to buildan incremental translation system like a simulta-neous interpreter, and the proper way to graspa chunk of a translation unit corresponding tosome chunk in a target language is to extend'constituent boundary parsing' to bottom-up-typeparsing \[Furuse96\].3.2 Recovering from er rorsA certain recovery method is now under consid-eration: a re-entrizing model for phoneme candi-dates by means of searching the correct phonemesusing modification depending on recognition er-ror characteristics in an example-based framewbrk\[Wakita95\].
This approach provides a recovery ef-fect in handling phoneme or syllable sequences,and the effect depends on the particular speakersbecause of individual error characteristics.3.3 Requirements covered byEBMT/TDMTThe remaining requirements are handled effec-tively by an example-based approach as explainedhere.In NLP systems, especially for spoken language,many possibile syntactic structures are produced.It is an important and difficult process to choosethe most plausibile structure.
Conventional ap-proachs, such as knowledge-based one, cannot eas-ily handle continuous phenomena: gradation ofcase role changing; derivation of a metonymical1074relation; and relationship between a topicalizedword and the main predicate.We have proposed Example-BasedMachine 3?anslation (EBMT) to deal with thesedifliculties\[Sumita92-a\].
The EBMT method pre-pares a large number of translation examples; thetranslation example that most closely matches theinput expression is retrieved; and tile example isnfimicked.When applying F, BM'F to sentence transla-tion, the sentence must be analyzed by matchingtransaltion patterns of phrases \[Furuse94\].
Thismodel is in a sense "driven by transfer", andwe call it Transfer-Driven Machine %anslation(TDMT).3.3.1 Hand l ing  spoken languageSpoken language includes many phenomena;here, howew'.r, we concentrate on the followingones:(1) "wa" is a Japanese topic marker and, in gen-eral, this marker can t)e replaced by othercase particles.
But some usages cannot beidentified as to case role because of grada-tion of case role changing.
Moreover, if thereare double topic markers in a sentence, theycannot I)e replaced by other particles 1.
Thefirst sentence in our Japanese-to-English (JE)translation "snapshot" (Figure 1), for exam-.ple, is properly translated in our TI)MT pro-totype system.
(i) "Chikatetsu-wa ichiban-chikai eki-wadoko desu-ka.
"('subway-topiealized,' 'the near-est,' 'station-topicalized,' 'where,' 'be-question')(2) Two sentences are mixed in one utterance.The tirst is pended, then inunedaitely the sec-ond sentence starts without conjunction.
(ii) "Shiharai-wa ginkou-fllrikomi-o o-machi-shite-oriInasu.
"('payment-topicalized,' 'bank-transfer-objective,' 'wait-for-polite-modest')a.a.= Hand l ing  euphemis t i c  express ions(1) There are various types of expressions forpoliteness, modesty, and euphemism.
Suchexpressions are used depending on socialroles.
The fourth sentence in our Japanese-to-Korean (JK) translation snapshot (Figure2) is a sample of this type, which is properlydealt with by TI)MT.
(iii) "Yoyaku-wokakunin-sasete-itadaki-masu.
"1In this paper, sample Japanese sentences are writ-ten alphabetically and surrounded by double quotes,and the corresponding English words with usage mod-ifiers follow in parenthesis.
('reservation-objective,''confirm-modest')(iv) "Go-dengon-woo-t ut ae-moushiage-masu .
"('message-polite-objective,''inform-honorific')3.3.3 Deterministic processingConventionM MT methods provide multipletranslation candidates but no information to usein selecting among them, or else just the first pos-sible sentence that is generated.On the contrary, EBMT generates all the possi-ble candidates combining suitable phrases.
It alsoprovides proper scores to each candidate using asimilarity calculation.
The scores realize "deter-ministic" translation.3.3 .4  Speed\[Furuse96\] has improved a matching mechanismover translation patterns.
By accepting inputin left-to-right order and dealing with best-onlysubstructures, the explosion of structural ambi-guity is restrained and an efficient ranslation ofa lengthy input sentence can be achieved, l)re -liminary experimentation has shown that averagetranslation times are reduced from 1.15 secondsto 0.55 seconds for input of 10 words in lengthand from 10.87 seconds to 2.04 seconds for in-put of 20 words in length.
The incorporationof incremental morphological analysis and gener-ation \[Akamine95\] into the new-version TDMT,is promising for achieving incremental (simulta-neous) translation for a practical spoken-languagetranslation system.If instantaneous response is required, the restdominant process is retrieval of the closest ransla-tion patterns from bulk collection.
It is effectivelysolved by using a massively parallel algorithmsand machines \[Sumita95-a, Snmita95-b, Oi93\].3.3.5 QualityFirst, a well-known difficult problem inJapanese to English translation was selected asa test.
The Japanese noun phrase of the form"noun + NO + noun" using the Japanese adnom-inM particle "NO" is an expression whose meaningis continuous.
A translation success rate of about80% has been demonstrated in a Jacknife test\[Sumita92-a\].
Also, for other Japanese and En-glish phrases, similar effectiveness in target wordselection and structural dsiambiguation has beendemonstrated\[Sumita92-b\].We have evaluated a experimental TDMT sys-tem, with 825 model sentences about conferenceregistration.
These sentences cover basic expres-sions in an inquiry dialogue.
The success rate is71% for a test data set consisting of 1,050 unseensentences in the same domain.1075target : "T would like to arrive at Las Vegas by nine o' clock at night"target : "If you get on the bus at nine fifteen, you ~l l  arrive by e~ht o' clock at night"source : "AB~-CT~ "target : "At eight 0' clock 2"source : "L; ~ ~f~, ~?
: ~ ~d--~r.
'\]ff~;0~7~ AT~-n"target : "Well, i t  takes eleven hours approximately, r~ht ?
"source : % ~ ~,~'~ U ~-~'6-i--~l%"ffl\[;b ~ U~-"target : "No .
there is the time difference and i t  wil l  take t~elve hours"Figure 1: JE translation snapshot by TDMTsource : "C -~%T'~Pe~,gtCZSf~'8~9-~ ~''(Hi is it possible to make hotel reservation from here?
)target : "~1~ ~ ~ ~ + ~@~1~?
"source : "C~fr(~-C'~ /~-c~'C-~, ,~a)Z Ia t~*~Z~X-c ' I~  bT~  ~:~i~ ~"(OK, what we do is to give you all the ~nformation you need and then~e ask you to go ahead and make the call yourself.
)target : ~ ,~  7~ul \ ]  o~o~ ~ ~o~ ~ ~ ~x\]~?~.\]~h"source : "b+~ U~d~69~JU~/~U~< tZ~"(OL l'm looking for a central locatioi~ i f  possible.
)target : "~L~ ~ ~\]~ ~J~ ~ ~xj~\]~ ..(Not too expensive, and it shouldn ~ t take too long to get to the major sights from there.
)target : "e~H17~ ~ HI~I ~ ~ ~l~ ~17~ ~gJL"Figure 2: JK translation snapshot by TDMT4 JE  8?
JK  pro to type  sys temsThe TDMT system is being expanded so as tohandle travel arrangement dialogues including thetopics of hotel reservation, room services, trou-bleshooting during hotel stays, various informa-tion queries, and various travel arrangements.
Atpresent the JE system has about a 5,000-wordvocabulary and a transfer knowledge from 2,000training sentences.
The JK system is half thissize.
While some modules, such as morphologi-cal analysis and generation, are language-specific,the transfer module is a common part of every lan-guage pair.
Through JE and JK implementation,we believe that the translation of every languagepair can be achieved in the same framework usingTDMT.
On the other hand, it has turned out thatthe linguistic distance between source and targetlanguages reflects the variety of target expressionpatterns in the transfer knowledge.
Table 1 showsthe number of target expression patterns corre-sponding a Japanese particles in JE and JK.
Thesenumbers are counted from the current TDMT sys-tem's transfer knowledge, and the numbers of ex-amples are token numbers (i.e., not including du-plications).5 Discuss ion5.1 In tegrat ion  of  Speech and LanguageA mechanism for spontaneous speech translationmust be consistent with a mechanism for handlingassociative knowledge, such as translation usageexamples and word co-occurrence information forrnemory-b~ed processing, and with a mechanismfor logical structure analysis according to detailedrules for each processing phase in the Transfer-Driven MT processing.
Under the process, a studyshould be carried out on building a stochastic lan-guage model using both syntactic and semanticinformation for speech understanding.5.2 Re la ted  ResearchOn the other hand, some studies hope to buildspoken language translation systems using a cer-tain interlingua method.
A semantic parseris a typical example of this method.
In par-ticular, "semantic pattern based parsing" inJANUS, CMU's speech to speech translation sys-tem \[Woszczyna93, Levin95\] uses frame based se-mantics with a semantic phrase grammar andthe operation of the parser is viewed as "phrasespotting."
Another one is MIT's multilingual1076'Fable 1: Japanese particle translation in JE and ,IK translationJapanesePatternX w(J YXga YXno YXoYXn i  YXde YJPExample Target patterns224 30140 15226 36147 15154 22120 25Example Target patterns66 140 188 241 155 533 5GALAXY: a human-language interface to on-line travel information \[Goddean94\].
The systemmakes use of 'semantic frame representation' soas to paraphrase a recognized speech input utter-ance into a concrete and simple expression thatcontbrms with one of the system's internal repre-sentations and makes the utterance meaning easyto handle.
Itowever, in extracting the meaningof an inlmt sentence, many default values are re-quired so as to execute heuristic inferences.
Theinference is too powerful in explaining a speaker'sintention and the propositional content of the ut-terance by one key word or phrase.
Such a methodmay work well in a certain domain, but less scala-bility may be revealed when making a larger pro-totype system.VERBMOBIL is a typical translation systemfor face-to:face dialogue \[Wahlster93\].
This sys-tem adopts English as a dialogue language forhuman-machine interface and makes use of DRT-based semantic representation u its.6 Conc lus ion'\['DMT has been proposed as a general techniquefor spoken-language translation.
We have ap-plied TDMT to two language pairs, i.e., Japanese-English, and Japanese-Korean, as a first step to-ward multi-lingual translation.
Also, we are plan-ning to integrate speech recognition with TI)M'Ffor achieving effective and efficient speech trans-lation.References\[Akamine95\] Akamine, S. and l!
'uruse, O.:Einiehi-taiwabun-hon'yaku niokeru zenshinteki-nihongobml-seisei (incremental generation ofJapanese Sentence in English to Japanese Dia-logue Translation), in ProF. of 1 st NLP convetion,pp.281-284 (1995), (in Japanese).\[Furuse94\] Furuse, O. and Iida, H. : ConstituentBoundary Parsing for EBMT, in ProF. of COL-ING'94, pp.
105-111 (1994).\[Furuse96\] Furnse, O. and Iida, H. : IncrementalTranslation Utilizing Constituent Boundary Pat-tern, in ProF. of COLING'96 (1996).\[Goddeau94\] Goddeau, D., et al : GALAXY:A IIUMAN-LANGUAGE INTERFACE TO ON-LINE 'I'RAVI!3; INFORMATION, in Poc.
of IC:SLP94, pp.707-710 (1994).\[lida93\] 1ida, H. : Prospects for Adwmced Spo-ken Dialogue Processing, \[EICE TRANS.
INF.and SYST., VOL.
E-76-D, No.l, pp.
2-8 (1993).\[Levin95\] Levin, L. , et al : Using Contextin Machine Translation of Spoken Language, inProF.
of TMI-95, pp.
173-187 (1995).\[Nagao84\] Nagao, M. : A Framework of a Ma-chine Translation between Japanese and Englishby Analogy Principle, in Artitieial and Human In-telligence, eds.
A. Elithorn and R. Banerji, North-llolhmd, pp.
173-180 (1984) .\[Oi93\] Oi, K. et al : Toward Massively Paral-lel Spoken Language Translation, in Proe.
of theWorkshop on Parallel Processing for AI, IJCAI'93,pp.
36-39 (1993).\[Sumita92-a\] Surnita, E. and Iida, II.
:Example-Based Transfer of Japanese AdnominalParticles into English, IEICE TRANS.
INF.
andSYST., VOL.
E-75-1), No.4, pp.
585-594 (1992).\[Smnita92-b\] Sumita, E. and Iida, 11. :Example-Based NLP Techniques- A Case Studyof Machine Translation - , Statistically-BasedNLP Techniques- Papers from the 1992 Work-shop, Technical Report W'92-01, AAAI Press(1992).\[Sumita95-a\] Sumita, E. and Iida, tt.
: Itetero-geneous Computing for Example-Based Transla-tion of Spoken Language, in Proe.
of TMI-95, pp.273-286 (1995).\[Sumita95-b\] Sumita, g. and Iida, H. : Hetero~geneous Computing for Example-Based Transla-tion of Spoken Language, in ProF. of TMI-95, pp.273-286 (1995).\[Wahlster93\] Wahlster, W. : Verbmobil: Trans-lation of Face-To-Face Dialogs, in ProF. of MT--Sumnfit IV, pp.
127-135(1993).\[Wakita95\] Wakita, Y. et al : Phoneme Can-didate Re-entry Modeling Using Recognition Er-ror Characteristics over Multiple HMM States, inProF.
of ESCA Workshop on Spoken DialogueSystems, pp.
73-76 (1995).\[Woszczyna93\] Woszczyna, M., et al : REC-CENT ADVANCES IN JANUS: A SPEECHTRANSLATION SYSTEM, in ProF. of EU-ROSPEECH'93, pp.
1295-1298 (1993).1077
