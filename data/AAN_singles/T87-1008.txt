Information, Unification and LocalityFernando C. N. PereiraArtificial Intelligence CenterSRI InternationalOctober 14, 19861 Unification TechnologyIn this discussion, I am wearing the humble hat of a "symbolic systems engi-neer" who  has been involved in building artifacts, unification-based grammarformalisms, that might be used to describe certain aspects of some naturallanguages.
In the same way a physicist might see the calculus as one ofmany technologies she needs in her scientific pursuits, and mathematiciansas excessively glorified engineers, so it may well be reasonable for a linguistto look upon computational linguists of my formal persuasion as engineersbuilding generic language-description tools.One needs to be clear about the role of mathematical tools in scien-tific pursuits.
Most differential equations one might write correspond to nophysically-realizable system.
The calculus imposes only very broad, weakconstraints on the class of systems it can describe, eg.
differentiability ofstate functions and trajectories.
Similarly, there is no reason to believegrammar formalisms can impose strong lingustically-motivated constraintson the classes of languages they can describe.Unification-based grammar formalisms are thus a subject of inquiry re-lated to but independent from linguistic theory.
The kinds of questionsone asks about a formalism are then those from formal language theory(generative power, recognition complexity) and programming language de-sign (semantics, expressive capabilities, implementation algorithms and datastructures).342 Un i f i ca t ion  in Abst rac tIn a unification framework we deal with a domain of descriptions P that areused to classify objects from some class under analysis 0,  utterances andtheir fragments in the case that concerns us here.
Classification is given bya description relation ~ between objects in 0 and elements of P. If d is a\[partial\] description of e, we write e ~ d, e satisfies (or is described by) d.The set of all objects that satisfy a description d is written \[dl.Descriptions are in general partial, that is, a description d may in generalbe extended to a more specific (more informative) description dI.
With suit-able technical assumptions, this gives a partial order d ~ d' on descriptions.In terms of the description relation ~,  d E d' iff for every object e, e ~ dwhenever e ~ d ~.Two descriptions d and d' are compatible if there is a description d" suchthat d _C d" and d ~ _C d", that is if d and d' can both be extended to a singledescription more informative than both.If two descriptions d and d ~ are compatible, it is reasonable to assumethat there is a least specific description dU d' more specific that both d andd'.
In other words, d U d' contains all the information in d and d', but nomore.
For historical reasons, d t.J d' is called the unification of d and d'.
Inmore standard mathematical terminology, d u d' is the join of d and d'.In terms of the description relation, if e ~d it d', e ~ d and e~ d'.Furthermore, we want unification to behave like logical conjunction: if e ~ dand e ~ d', e ~ d U d'.
Thus lid U d'~ = \[\[d\] n \[d'~ holds for any compatibledescriptions d and d'.The domains of objects, descriptions and the description relation areusually infinite, even though there may be some way of finitely characterizingthe description relation.
Such a characterization is a grammar.To write grammars, we need to be able to constrain entities to satisfyarbitrarily complex descriptions without giving the descriptions in full.
Ourmain instruments for this are parameterized descriptions and rules.A parameterized description d(pl,...,pk) is not a description itself, butrather an encoding of a function from k-tuples of descriptions to descrip-tions.
An object e satisfies such a parameterized description iff there aredescriptions f l , .
.
.
,  fk such that e satisfies d(f l , .
.
.
,  f~).
Given a family ofparameterized descriptions (di)iel with parameters (Pi)i~s and a set C ofconstraints involving the parameters, a family of objects (ei)ie I satisfies theparameterized descriptions relative to the constraints iff there are descrip-tions (fi)ieJ that can be uniformly replaced for the parameters in such a35way that e~ ~ di((f j) jeJ) and all the constraints in C are  satisfied.In current unification-based formalisms, a grammar is a set of inductiverules with the general formEl : d l ' "E , ,  : dn/ (E l , .
.
.
,  E,)  : d if Cwhere the El are object variables, d and the d~ are parameterized descrip-tions, C is a set of conditions on the parameters, and f is a structuralcomposition function on objects.
Given an appropriate notion of allowedderivation - -  a tree with nodes labelled by object-description pairs e : d inwhich each node satisfies a rule - -  the grammar is sound with respect o adescription relation ~ iff the root e : d of every derivation allowed by thegrammar obeys the condition e ~ d.The main technical question at this level is whether a given vocabu-lary of constraints and rules really define the description relation, that is,whether the rules are well-founded with respect o the structural decom-position of elements of C) given by the structural composition functions fand whether there is a least description relation compatible with the deriva-tions allowed by the grammar.
This question has been answered in detailfor definite-clause-based grammar formalisms (in which descriptions are justlogical terms), but the situation is much less clear for more complicated do-mains (eg.
those with disjunctive constraints) and classes of constraints (eg.LFG's constraint equations).The preceding discussion may be summarized as follows.
Descriptionsclassify objects (strings, utterance fragments).
Rules give the descriptionof a compound object in terms of descriptions of its parts.
Grammaticalanalysis is the derivation of a description for an object according to therules of a grammar that axiomatizes the description relation.3 Computat ionThe discussion of the previous ection concerned the denotational seman-tics of a grammar formalism.
The denotational semantics gives a rigorousspecification of what a grammar does.
However, from a computational pointof view we are also interested in how a grammar does what it does.
Thisquestion can be posed at two levels: at the more abstract level of oper-ational semantics, the problem is how to give abstract procedures (proofprocedures) that construct derivation trees yielding classifications ofobjects36(utterances); at the more concrete level, what data structures and algorithmsare required for efficient analysis (classification, proof generation).In some cases, for example in DCGs or PATR-II, the formalism itselfis only semi-decidable, so the procedure given by the operational semanticsmay not terminate when it is asked to classify an object with a descriptionit does not satisfy.
However, for reasonable classes of grammars in thoseformalisms, as well as for all grammars in LFG, the classification (analysis)problem is decidable.Even though LFG as well as all offiine parsable DCGs and PATR-IIgrammars are decidable, it has been shown that they are intractable (NP-complete).
The sources of this intractability are rather interesting, and leadto the question of locality which I will discuss in the next section.We should not take the undecidability or intractability of unification-based formalisms as fatal flaw any more than we take the same propertiesas fatal flaws in a programming language.
From an engineering point of view,grammar formalisms are just programming languages for grammar writingin which it is of course possible to write intractable or even nonterminatingprograms.Finally, at the most concrete level, we have the question Of whatdata structures and algorithms are in practice most useful for analysis inunification-based formalisms.
The problem here is rather more difficult thanthat for simpler formalisms uch as CFGs.At an abstract operational level, derivations classifying a given s~ringcan be build very much in the same way as derivations in a context-freegrammar.
However, in contrast with CFGs, we have to satisfy not only lo-cal identity conditions between onterminals but also rule constraints, whichmay have global consequences for the choice of descriptions in the deriva-tion.
In the typical incremental derivation procedures currently in use, ruleapplications assign to objects parameterized descriptions whose parametersmay then be filled in by by unifications as specified by constraints and otherrule applications.
Alternative derivation paths assign different values to pa-rameters, requiring some mechanism to segregate the assignments.
It is easyto construct grammars that require space exponential on input length forstoring alternative descriptions of the parts of the input even though therecognition problem for the grammars in question is clearly linear time witha specialized algorithm.
This problem may well be related to the questionof locality which I discuss below.374 LocalityThe intractability of existing unification-based formalisms eems to havesomething to do with lack o/locality: constraints on description parametersare weak enough to allow the construction of (exponentially many) partialderivations for a string, but strong enough to conspire in rejecting almost allof those derivations.
Basically, constraints chain together to constrain pa-rameters arbitrarily far apart in a derivation.
Lack of locality impinges alsoon the implementation data structures, as it allows rule applications to givealternative values to parameters arbitrarily deep inside a derivation, thusrequiring a costly copying or structure-sharing mechanism to keep separatethe alternative derivations.Most grammars written in practice do not seem to suffer from lack oflocality.
However, it is not very clear why this is so and it is not easy torecognize lack of locality in a grammar.
Even from an engineering point ofview, it would be useful to have precise criteria for locality in a grammar,with suitable consequences in the complexity department.
If locality criteriacould be embodied in formal constraints on allowable grammars, we wouldbe able to design restricted formalisms with good complexity properties.The locality question has a more philosophical angle.
Nonlocal gram-mars lead to nondeterministic recognizers.
The description of a part of anutterance is supposed to represent the information contributed by that partto the utterance interpretation i~rocess.
Lack of locality means that theprocessor is unable to identify the exact informational contribution of anutterance lement without considering the whole utterance.
This is ratherunsatisfactory, as one might expect hat the informational contribution ofan object is precisely what can be learned from the presence of the objectwithout regard to context.
Lack of locality in a grammar thus suggeststhat we have not been successful in our classification of objects as to theirinformation-carrying properties.
Somehow, correct classification and de-terminism seem to go together.
Current unification-based formalisms areexpressive nough to describe a great variety of languages, but they do notseem to make all the classificatory distinctions that are needed to pin downthe informational contributions of objects.
Alternatively, there may well bea negative result lurking here that shows the impossibility of exact classifica-tion of informational content; in this case we should be able to find naturalsituations in which nonlocality emerges.38
