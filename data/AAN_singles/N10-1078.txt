Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 537?545,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsEnabling Monolingual Translators: Post-Editing vs. OptionsPhilipp KoehnUniversity of Edinburgh10 Crichton StreetEdinburgh, EH8 9ABScotland, United Kingdompkoehn@inf.ed.ac.ukAbstractWe carried out a study on monolingual trans-lators with no knowledge of the source lan-guage, but aided by post-editing and the dis-play of translation options.
On Arabic-Englishand Chinese-English, using standard test dataand current statistical machine translation sys-tems, 10 monolingual translators were able totranslate 35% of Arabic and 28% of Chinesesentences correctly on average, with some ofthe participants coming close to professionalbilingual performance on some of the docu-ments.While machine translation systems have advancedgreatly over the last decade, nobody seriously ex-pects human-level performance any time soon, ex-cept for very constraint settings.
But are todayssystems good enough to enable monolingual speak-ers of the target language without knowledge ofthe source language to generate correct translations?And what type of assistance from machine transla-tion is most helpful for such translators?We carried out a study that involved monolin-gual translators who had no knowledge of Chineseand Arabic to translate documents from the NIST20081 test sets, being assisted by statistical machinetranslation systems trained on data created under theGALE2 research program.Our study shows that monolingual translatorswere able to translate 35% of Arabic and 28% ofChinese sentences, under a strict standard of correct-ness that scored professional bilingual translationsas 61% and 66% correct for Arabic and Chinese, re-spectively.
We found also large variability amongthe participants and between the documents in the1http://www.itl.nist.gov/iad/mig/tests/mt/2http://www.darpa.mil/ipto/programs/gale/gale.aspstudy, indicating the importance of general languageskills and domain knowledge.
The results suggestthat a skilled monolingual translator can competewith a bilingual translator, when using todays ma-chine translation systems.1 Related WorkThe use of human translators in combination withmachine translation is as old as the emergence ofthe first effective machine translation systems.
Typi-cally, this takes the form of a human translator post-editing machine translation output, and rarely of ahuman translator guiding the decisions of a machinetranslation system.
Recent examples of using post-editing of machine translation in tools for transla-tion tools are the Google Translator Toolkit (Galvezand Bhansali, 2009) and the WikiBabel project (Ku-maran et al, 2008).A recent seminal effort on building interactivemachine translation systems (Langlais et al, 2000;Barrachina et al, 2009) looked at a tighter integra-tion of machine translation and human translationby developing a prediction model that interactivelysuggests translations to the human translator, takingher prior translation decisions into account.
This ap-proach was recently re-implemented and extendedby Koehn (2009).Our study uses both post-editing and the extendedinteractive machine translation approach as types ofassistance for translations.
In our case, however, welook at monolingual translators, while prior workhas focused on bilingual translators.Another effort to enable monolingual translatorslooked at a more linguistically motivated tool usingsyntactic analysis to inform their translation deci-sions (Albrecht et al, 2009).The quality of the translations produced by537monolingual translators was previously explored byCallison-Burch (2005) in a submission to the NIST2005 evaluation campaign, but not properly evalu-ated.
The idea of using post-editing by monolingualspeakers without access to the source as a metric toevaluate machine translation quality of different sys-tems was explored by Callison-Burch et al (2009) inthe WMT 2009 shared task.2 Human TranslationExcept for constraint settings with a very limiteddomain, translation quality by trained humans ismuch higher than automatic translation methods.Especially for the commercially most relevant fieldof publication-quality translation of official reports,product manuals, promotion material, web sites, andso on, machine translation currently plays at most asupportive role.2.1 Translation ToolsThe main draw-back of relying on professional hu-man translators is their high cost.
A number of tech-nological advances in the industry have increasedthe productivity of translators, and thus loweredtheir cost, over the last two decades.
The pervasiveuse of computers and the Internet has reduced thecost of management, and helped a industry wheretranslation is outsources many times over: fromthe original customer to a translation agency, froma translation agency to freelance translators, andmaybe some additional levels in between.The use of computers has also led to the adoptionof tools such as translation memories3 (databasesof translated material that are queried for fuzzymatches, i.e.
translated sentences similar to the oneto be processed), monolingual and bilingual concor-dances (showing words used in context, and theirtranslations), terminology databases, online dictio-naries and thesauri, and basic editing tools such asword processors and spell checkers (Desilets, 2009).The use of machine translation has not yet madegreat inroads into the toolbox of professional trans-lators.
Being reduced to mere post-editors ofbadly machine translated texts is not an appealingprospect, and machine translation is generally con-sidered (rightly or wrongly) not yet good enough to3for instance: Trados, http://www.trados.com/increase productivity.
More innovative use of ma-chine translations such as interactive machine trans-lation (Langlais et al, 2000) has not advanced muchbeyond the research stage.
There is rich potential forimprovements and entirely new tools.2.2 Translation SkillsA fully qualified professional translator has to havetwo sets of skills when translating a text.
On the onehand the language skills to generally understand thesource language and to write well in the target lan-guage, and on the other hand the domain knowledgeto understand the content of a possibly very special-ized technical document.
Both skill sets may be hardto find, especially in combination.In fact, it is common practice in the translationindustry to differentiate translators according to theirqualifications.
For instance, junior translators mayproduce the first draft, and senior translators edit it?
which they will be able to do much faster than atranslation from scratch by themselves.Human translation is also performed in a non-professional environment by generally less quali-fied volunteer translators.
To give just a few ex-ample: there are vibrant communities that concernthemselves with the translation of Wikipedia arti-cles4 (Kumaran et al, 2008), open source softwaredocumentation,5 movie subtitles,6 and even materialsuch as the TED conference talks.7Research has shown that less qualified transla-tors are able to increase their productivity and qual-ity disproportionally when given automatic assis-tance (Koehn and Haddow, 2009).
Assistance maybe as limited as offering machine translation in apost-editing environment, as for instance providedby Google Translator Toolkit8 (Galvez and Bhansali,2009) which provides a special function to translateWikipedia articles.In this context, our work looks at one extreme ofthe skill range: translators that have no knowledgeof the source language.
While we would not expectthem to compete with professional translators thathave this knowledge, their inferior performance may4http://en.wikipedia.org/wiki/Wikipedia:Translation5http://l10n.kde.org/6http://www.opensubtitles.org/7http://www.ted.com/translate/8http://translate.google.com/toolkit/538Figure 1: Translation Options shown to the monolingual translator.
The machine translation of the Arabic inputsentence is: The us house of representatives adopted thursday a law calls for the withdrawal of us combat troops fromiraq by the first of april 2008, defying once again president george bush who opposed to setting any date.be remedied as suggested above: their texts may beedited by a more qualified translator, or their do-main knowledge may augment the language skillsof a collaborating translator.From the view of human translation, the mainquestion that this paper is trying to answer is: howwell can monolingual translators perform, given thecurrent quality of machine translation, and whattypes of assistance offered by a machine translationsystem is most helpful?3 Machine TranslationStatistical machine translation has made greatprogress over the last two decades, with chang-ing models, learning methods, decoding algorithms,decision rules, etc.
While there is increasing ef-fort to build grammar-based translation models thattake into account the recursive nature of language,currently the most popular models are still phrase-based.3.1 Phrase-Based ModelsIn phrase based models, the input is segmented intotext chunks (that do not have to correspond to lin-guistic phrases), each is translated and may be re-ordered, and the output is assembled with the helpof a language model.
The translations for individualphrases are called translation options.
Typically, upto 20 translation options for each input phrase areconsidered during decoding.The large number of translation options and theireven larger combinatorial arrangement creates asearch space that is too large to exhaustively explore,creating the need for a heuristic search algorithm.During the heuristic search a search graph is con-structed.
This search graph can be converted into aword lattice, which is useful for n-best list genera-tion, or in our case interactive machine translation.3.2 Interactive Machine TranslationThe by-products of phrase-based models have beenused in a type of computer aided translation toolcalled interactive machine translation.
In these se-tups, the human translator is creating the translation,but receives suggestions how to complete the sen-tence or is offered alternative translation options forthe input words and phrases.The translation options that the decoder is us-ing are ranked based on their probability and pre-sented to the human translator, as done by Koehn(2009).
Sentence completion prediction is based onthe search graph (Barrachina et al, 2009).
If thehuman translator starts a translation that divergesfrom the suggestion, the interactive translation toolquickly computes a approximate match in the searchgraph and uses this as a starting point for further pre-dictions.In our experiments, we offer both translation op-tions and interactive sentence completion predic-tions to the user.
See Figure 1 for an example.5393.3 Arabic and ChineseThis paper is using machine translation systems forArabic?English and Chinese?English that were de-veloped in the context of the recent GALE researchprogram funded by DARPA.The choice of these two languages pairs has twomotivations: first, a lot of resources have goneinto improving translation quality for these languagepairs.
An important question is how the improve-ments in translation quality can be utilized.The second motivation for choosing Arabic?English and Chinese?English is that they are undeci-pherably foreign for a typical European or Americanspeaker of English.
The fact that both languages arewritten in a different script already makes it impossi-ble to spot cognates, except for the occasional num-ber.
In our study, the test subjects had to practicallyexclusively rely on the given sentence translations orphrase translations options.3.4 Evaluation of Machine TranslationChinese?English is considered significantly harderthan Arabic?English, as measured by automaticmetrics (which measure similarity to a human refer-ence translation), human evaluation metrics such asHTER (which measures the number of editing stepsnecessary to correct the output into an acceptabletranslation), or human judgment on the correctnessof the translation, its fluency or adequacy (which istypically measured on a scale from 1 to 5).All these metrics have been criticized in the pastas too simple, biased towards statistical systems,non-repeatable, having low intra and inter-annotatoragreement, or plainly too expensive to use.
How toproperly evaluate machine translation quality is stillan open problem.From the view of machine translation evaluation,this paper explores the question if current machinetranslation systems have reached the goal to bringacross the meaning of a foreign text.
The ability ofa monolingual target language speaker to producecorrect translations (based on her understanding ofthe machine translation output) is a test for this goal.It sets aside the problems of clumsy wordings andgrammatical errors.
To relate this to traditional er-ror metrics in machine translation: we focus on theadequacy opposed to the fluency of translation.Language Sentences WordsArabic 9,320,356 228,712,189Chinese 2,039,399 49,564,193Table 1: Training data: number of sentences and Englishwords in the parallel training data4 ExperimentWe trained translation models using Moses (Koehnet al, 2007) on the bilingual data provided by theLDC, with additional monolingual data from the En-glish Gigaword corpus for an interpolated 5-gramlanguage model.
Basic statistics about the corpusare given in Table 1.
The systems are close to thestate of the art.We used four news stories for each of the two lan-guages for the monolingual translators.
The newsstories were selected from the evaluation sets of the2008 machine translation evaluation campaign orga-nized by NIST.
See Table 2 for details.
The newsstories are rather short (around 10 sentences each),since we opted for a variety of stories rather thanlong stories.The evaluation set comes with four referencetranslations.
This allowed us to use one of the refer-ence translation as gold standard for the evaluation,and the other three reference translations as competi-tors for the monolingual translations.We recruited 10 monolingual translators, studentsat the University of Edinburgh for the study.
Noneof the students had knowledge of either Chinese orArabic.
Each translator was given all eight storiesto translate, half of the stories with only the ma-chine translation output (Post-editing task) and halfof the stories with interactive assistance as describedin Section 3.2: prediction of sentence completionand translation options (Options).In both cases, we also displayed the Arabic orChinese source sentence to the translator, which mayshow some clues regarding punctuation, numbers, orthe length of source words.
The translators had noknowledge of the source script.After all the translations were completed, we as-sessed the translation quality.
Since we did not haveaccess to bilingual speakers for this, we resorted tothe standard manual setup, where human judges areasked to assess the quality of each sentence transla-540Story Headline Sent.
Words1: Chinese White House Pushes for Nuclear Inspectors to Be Sent as Soon as Possible to Mon-itor North Korea?s Closure of Its Nuclear Reactors6 2072: Chinese Torrential Rains Hit Western India, 43 People Dead 10 2043: Chinese Research Shows a Link between Arrhythmia and Two Forms of Genetic Variation 7 2474: Chinese Veteran US Goalkeeper Keller May Retire after America?s Cup 10 3675: Arabic Britain: Arrests in Several Cities and Explosion of Suspicious Car 7 2246: Arabic Ban Ki-Moon Withdraws His Report on the Sahara after Controversy SurroundingIts Content8 3107: Arabic Pakistani Opposition Leaders Call on Musharraf to Resign.
11 3128: Arabic Al-Maliki: Iraqi Forces Are Capable of Taking Over the Security Dossier Any TimeThey Want8 255Table 2: News stories used in the experiment with headlines from the reference translationAssistance Arabic ChineseBilingual 61?6% 66?6%Postediting 35?4% 26?4%Options 34?4% 30?4%Table 3: Correctness of translations (with 95% confi-dence interval) under the two types of assistance, com-pared against professional reference translationstion compared to a reference translation in context?
the first reference translation in the NIST evalua-tion set which was produced by a professional trans-lation agency.We used a strict evaluation metric: a binary judg-ment, if the translation is correct.
Correct was de-fined as a fluent translation that contains the samemeaning in the document context.
The referencetranslation was shown with its document context(two sentences before and after).
We used a variantof the web-based evaluation tool of the 2009 Work-shop on Statistical Machine Translation.5 ResultsThe headline results are displayed in Table 3.
Thebilingual translations which were taken from theother three reference sets score surprisingly low:only about two thirds of the sentences were deemedto be correct by our judges.
This is a better resultthan the monolingual translators performance, whotranslate around one third of the sentences correctly,except for a statistically significant worse showingfor post-editing Chinese?English.Translator Arabic Chinesebi1 67?10% 65?11%bi2 49?10% 67?10%bi3 67?10% 67?9%mono1 48?11% 31?11%mono2 29?10% 21?8%mono3 26?10% 12?7%mono4 50?11% 26?11%mono5 25?10% 25?10%mono6 26?9% 18?9%mono7 23?10% 29?10%mono8 50?11% 50?10%mono9 42?10% 37?11%mono10 25?9% 32?10%Table 4: Correctness by translator (note: different bilin-gual translators for Arabic and Chinese)Translation speed of the monolingual translatorsvaried, but it was mostly around 500 words per hour(7 seconds per word), which is roughly comparableto the lower end of professional translation speed.Table 4 shows the performance of the individualtranslators.
The 95% confidence intervals are verywide, due to the few sentences that were translatedby each translator, but some monolingual transla-tors are significantly better than others.
Some ofthe monolingual translators seem to compete head-to-head with the professional bilingual translators:three monolingual translators perform as well as oneof the bilingual translators for Arabic?English, al-beit one has to be cautioned by the wide confidenceintervals.
See also Figure 2 for a graphical display.541Story BLEU Bilingual Post-ed.
Options1: Chinese 42.8 76?16% 32?13% 40?13%2: Chinese 24.8 70?10% 39?8% 33?9%3: Chinese 35.1 61?12% 19?8% 17?7%4: Chinese 26.7 64?11% 12?6% 36?9%5: Arabic 43.6 60?14% 10?6% 13?7%6: Arabic 48.5 57?13% 34?9% 43?9%7: Arabic 60.5 72?10% 45?8% 36?9%8: Arabic 55.7 50?13% 45?10% 39?10%Table 5: Correctness by story and BLEU score of MTLength Bilingual Post-ed.
OptionsArabic ?15 words 81?16% 56?15% 48?16%Arabic 16?30 words 54?10% 41?8% 37?7%Arabic >30 words 62?8% 27?6% 29?6%Chinese ?15 words 60?12% 48?10% 21?9%Chinese 16?30 words 73?13% 25?9% 32?10%Chinese >30 words 68?8% 17?5% 33?6%Table 6: Correctness by sentence lengthSimilarly, performance on the different storiesvaries (Table 5, Figure 3): For instance, the monolin-gual translators struggled with the Chinese medicaland sports stories (no.
3 and 4) and the Arabic carexplosion story (no.
5), while even on average, theyare close to bilingual translation quality on the Ara-bic stories 6 and 8.
Note that correctness correlatesmildly with BLEU.Surprisingly, we did not find a consistent effectof sentence length on the quality of the translations(see Table 6).
We expected to find worse translationsamong the longer sentences, but this is not the casefor the all conditions.6 AnalysisOur results have shown that monolingual translatorsare often able to produce correct translation whenpost-editing output from current Arabic?English andChinese?English machine translation systems.
ForChinese?English, they are better when given addi-tional assistance in form of translation options andinteractive machine translation.We give in Figure 4 examples for translationsby machine translation, as well as monolingual andbilingual translators.One puzzle is the low score for the professionalhuman translators, as only two thirds of their trans-(a) Critical judgesREF: Torrential Rains Hit Western India, 43 People DeadBI: Heavy Rains Plague Western India Leaving 43 Dead(b) Mistakes by the professional translatorsREF: Over just two days on the 29th and 30th, rainfall inMumbai reached 243 mm.BI: The rainfall in Mumbai had reached 243 cm over thetwo days of the 29th and 30th alone.
(c) Bad English by monolingual translatorsMONO: The western region of india heavy rain killed 43people.
(d) Mistranslated / untranslated nameREF: Johndroe said that the two leaders ...MT: Strong zhuo, pointing out that the two presidents ...MONO: Qiang Zhuo pointed out that the two presidents ...(e) Wrong relationship between entitiesREF: The next match against Colombia will probablybe the US team?s and Keller?s last performance in thisAmerica?s Cup competition.MT: The colombian team for the match, and it is verylikely that the united states and kai in the americas cupfinal performance.MONO6: The Colombian team and the United States arevery likely to end up in the Americas Cup as the finalperformance.MONO8: The next match against Colombia is likely tobe the United States?
and Keller?s final performance inthe current Copa America.
(f) Badly muddled machine translationREF: In the current America?s cup, he has, just as before,been given an important job to do by head coach Bradley,but he clearly cannot win the match singlehanded.
TheUS team, made up of ?young guards,?...MT: He is still being head coach bradley appointed toimportant, it?s even a fist ?, four young guards at the be-ginning of the ?, the united states is...MONO: He is still being considered important by headcoach Bradley who appointed him.
It is a fight with ?fouryoung guards at the beginning of their careers?, but theUnited States...Figure 4: Examples of translations542bi1 bi2 bi3 mono1 mono2 mono3 mono4 mono5 mono6 mono7 mono8 mono9 mono1001020304050607080 ArabicChineseFigure 2: Quality of different bilingual and monolingual translators: For Arabic, three monolingual translators are asgood as the worst bilingual translator (around 50% of sentences judged as correct).
For detailed numbers, see Table 4.bi123m3on451617mbi123m3o8396i30bi123m3oA713273bi123m3oAr406ma09c17oC30040a09c17oh1r54e97sa09c17on451617ma09c17on451617m??
??
??
??
??
??
??
??
?
?1512?95?24on4m6?
?6?24o?r6142mFigure 3: Translation quality of monolingual translators differs significantly between stories: For the last Ararbicpolitics stories average performance is close to bilingual quality, while it is bad for the Chinese science and sports aswell as the Arabic terror story.
For detailed numbers, please see Table 5.543lations were deemed to be correct.
The example (a)shows such a translation, and it is hard to tell why itwas deemed wrong by all three judges who looked atit.
There are real mistakes in the professional trans-lations, as example (b) shows, which mistakes therain fall amount as 243cm instead of 243mm.Some monolingual translators, by the way, alsohad problems with that number.
The machine trans-lation system is not very well in translating numbers,which could be relatively easily addressed.Sometimes monolingual translators are just notthorough enough in their efforts, as example (c)shows, where the output does have the correct mean-ing elements, but it is just not correct English.
Thesetype of examples explain the big difference betweenthe different monolingual translators.A severe problem for monolingual translators areuntranslated or mistranslated names.
In example (d)Johndroe was referred to by monolingual transla-tors as Qiang Zhuo or Strong Zhuo.
The statisticalmachine translation system we used has no specialname transliteration component, so often a name re-mains untranslated.
Without given the right transla-tion as a choice, the monolingual is in no position ofcompleting a correct translation.The monolingual translators?
world and domainknowledge helps them a great deal to piece togethertranslations, but sometimes it is not enough, as ex-ample (e) shows.
There is some connection betweenfinal performance, United States and Columbia, butit is not the final performance for both teams asMONO6 renders it.
Translator MONO8 got it right,but other translators made different mistakes.Finally, there are some cases, as example (f)shows, where the machine translation is just so bad,that monolingual translators have no chance to ren-der a proper translation of the sentence, especiallywhen only post-editing.7 ConclusionWe approached this study from two directions: themotivation to enable monolingual translators and theneed for a way to assess the quality of todays ma-chine translation systems.Coming from a human translator?s perspective,we asked what type of assistance machine trans-lation can provide for a human translator.
Wecompared the use of interactive machine translationagainst post-editing, and found no significant differ-ence for Arabic (34% vs. 35%), but better perfor-mance with richer assistance for Chinese (30% vs.26%).
We believe that there is ample opportunityto provide additional assistance and we will explorethis in future work.Coming from a machine translation perspective,we asked if current systems are good enough tobring across the meaning of documents, even if gen-erating output language with grammatical and id-iomatic mistakes.
Given the harsh metric we use toassess translation quality (complete correctness of asentence), we showed that monolingual translatorswere able to produce translations that were on aver-age 35% (Arabic) and 28% (Chinese) correct, com-pared to 61% (Arabic) and 66% (Chinese) correct-ness for professional bilingual translations.Arguable, the method we use to assess the preser-vation of meaning in machine translation is superiorto subjective adequacy judgments: it separates thetask of defining the meaning of a machine transla-tion from the assessment of its correctness.We identified name and number translation as im-portant aspects to improve performance on this task.We also learned that there are significant differ-ence between human translators, which indicatesthat general language skills and effort are very im-portant.
We also learned that the performance variessignificantly for different documents in a way thathints at the importance of domain knowledge.
Inconclusion, a good monolingual translator has goodlanguage skills in the target language and under-stands the domain.
In this case, this study suggests,she may be as good as a professional bilingual trans-lator.AcknowledgementThis work was supported in part by the GALE pro-gram of the Defense Advanced Research ProjectsAgency, Contract No.
HR0011-06-C-0022, andin part by the EuroMatrixPlus project funded bythe European Commission (7th Framework Pro-gramme).
This study was made possible by the workof the monolingual translators.544ReferencesAlbrecht, J., Hwa, R., and Marai, G. E. (2009).Correcting automatic translations through collab-orations between MT and monolingual target-lan-guage users.
In Proceedings of the 12th Confer-ence of the European Chapter of the ACL (EACL2009), pages 60?68, Athens, Greece.
Associationfor Computational Linguistics.Barrachina, S., Bender, O., Casacuberta, F., Civera,J., Cubel, E., Khadivi, S., Lagarda, A., Ney, H.,Toma?s, J., Vidal, E., and Vilar, J.-M. (2009).
Sta-tistical approaches to computer-assisted transla-tion.
Computational Linguistics, 35(1):3?28.Callison-Burch, C. (2005).
Linear B system descrip-tion for the 2005 NIST MT evaluation exercise.
InProceedings of Machine Translation EvaluationWorkshop.Callison-Burch, C., Koehn, P., Monz, C., andSchroeder, J.
(2009).
Findings of the 2009Workshop on Statistical Machine Translation.
InProceedings of the Fourth Workshop on Statis-tical Machine Translation, pages 1?28, Athens,Greece.
Association for Computational Linguis-tics.Desilets, A.
(2009).
Up close and personal with atranslator - how translators really work.
In Ma-chine Translation Summit XII.
Tutorial.Galvez, M. and Bhansali, S. (2009).
Translatingthe world?s information with google translatortoolkit.Koehn, P. (2009).
A web-based interactive computeraided translation tool.
In Proceedings of the ACLInteractive Poster and Demonstration Sessions.Koehn, P. and Haddow, B.
(2009).
Interactive as-sistance to human translators using statistical ma-chine translation methods.
In Machine Transla-tion Summit XII.Koehn, P., Hoang, H., Birch, A., Callison-Burch,C., Federico, M., Bertoldi, N., Cowan, B., Shen,W., Moran, C., Zens, R., Dyer, C. J., Bojar, O.,Constantin, A., and Herbst, E. (2007).
Moses:Open source toolkit for statistical machine trans-lation.
In Proceedings of the 45th Annual Meet-ing of the Association for Computational Linguis-tics Companion Volume Proceedings of the Demoand Poster Sessions, pages 177?180, Prague,Czech Republic.
Association for ComputationalLinguistics.Kumaran, A., Saravanan, K., and Maurice, S.(2008).
wikiBABEL; community creation of mul-tilingual data.
In Babel Wiki Workshop 2008:Cross-Language Communication.Langlais, P., Foster, G., and Lapalme, G. (2000).Transtype: a computer-aided translation typingsystem.
In Proceedings of the ANLP-NAACL2000 Workshop on Embedded Machine Transla-tion Systems.545
