UNDERSTANDING SCENE DESCRIPTIONSAS EVg~NT SIMULATIONS IDavid L. WaltzUniversity of Illinois at Urbana-ChampaignThe language of scene descriptions 2 must allow ahearer to build structures of schemas similar (to somelevel of detail) to those the speaker has built viaperceptual processes.
The understanding process ingeneral requires a hearer to create and run "event~ "  to check the consistency and plausibilityof a "picture" constructed from a speaker's description.A speaker must also run similar event simulations on hisown descriptions in order to be able to judge when thehearer has been given sufficient information toconstruct an appropriate "picture", and to be able torespond appropriately to the heater's questions about orresponses to the scene description.In this paper I explore some simple scene,description examples in which a hearer must makejudgements involving reasoning about scenes, space,common-sense physics, cause-effect relationships, etc.While I propose some mechanisms for dealing with suchscene descriptions, my primary concern at this time istO flesh out our understanding of just what themechanisms must accomplish: what information will beavailable to them and what information must be found orgenerated to account for the inferences we know areactually made.1.
THE PROBLEM AREAAn entity (human or computer) that could be said tofully understand scene descriptions would have to have abroad range of abilities.
For example, it would have tobe able to make predictions about likely futures; tojudge certain scene descriptions to be implausible orimpossible; to point to items in a scene, given adescription of the scene; and to say whether or not ascene description corresponded to a given sceneexperienced through other sensory modes.
3 In general,then, the entity would have to have a sensory systemthat it could use to generate scene representations tobe compared with scene representations it had generatedon the basis of natural language input.In this paper I concentrate on I) the problems ofmaking appropriate predictions and inferences aboutdescribed scenes, and 2) the problem of judging whenscene descriptions are physically implausible orimpossible.I do not consider directly problems that  wouldrequire a vision system, problems such as decidingwhether a linguistic scene description is appropriatefor a perceived scene, or generating lingulstic scenedescriptions from visual input, or learning scenedescription lar4uage through experience.I also do not consider speech act aspects of scenedescriptions in much detail here.
I believe that theprinciples of speech acts transcend topics of language;I am not convinced that the study of scene descriptionswould lead to major insights into speech acts thatcouldn't be as well gained through the study of languagein other domains.IThis work was supported Ln part oy the Office of NavalResearch under Contract  ONR-NO0014-75-C-0612 with  theUniversity of Illinois, and was supported in part by theAdvanced Research Projects Agency of the Department ofDefense and monitored by ONR under Contract No.N0001~-77-C-O378 with Bolt Beranek and Newman Inc.2The term "scene" is intended to coyer both staticscenes and dynamic scenes (or events) that are boundedin space and time.3In general !
believe that many of the event simulationprocedures ought to involve kinesthetic and tactileinformation.
I by no means intend the simulations to beonly visual, although we have explored the A1 aspects ofvision far more than those of any other senses.I do believe, however, that the study of scenedescriptions has a considerable bearing on other areasof language analysis, including syntax, semantics, andpragmatics.
For example, consider the followingsentences:($I) I saw the man on the hill with my own eyes.
(32) I saw the man on the hill with a telescope.
($3) I saw the man on the hill with a red ski mask.The well-known sentence $2 is truly ambiguous, but $Iand $3, while likely to be treated as syntacticallysimilar to $2 by current parsers, are each relativelyunambiguous; I would like to be able to explain how asystem can choose the appropriate parsings in thesecases, as well as how a sequence of sentences can addconstraints to a single scene-centered representation,and aid in disamDiguation.
For example, if given thepair of sentences:($2) I saw the man on the hill with a telescope.
($4) I cleaned the lens to get a better view of him.a language understanding system should be able to selectthe appropr ia te  read ing  of  $2.I would also like to explore mechanisms that wouldbe appropriate for judging that($5) My dachshund bit our mailman on the ear.requires an explanation (dachshunds could not jump highenough to reach a mailman's ear, and there is no way tochoose between possible scenarios which would get thedachsund high enough or the mailman low enough for thebiting to take place).
The mechanisms must also be ableto judge that the sentences:($6) My doberman bit our mailman on the ear.
($7) My dachshund bit our gardener on the ear.
($8) My dachshund bit our mailman on the leg.do not require explanations.A few words about the importance of explanation arein order  here.
If a program could judge correctly whichscene descriptions were plausible and wnich were no5,but could not explain why it made the judgements it did,I think I would feel profoundly dissatisfied with andsuspicious of the program as a model of languagecomprehension.
A program ought to consider the "rightoptions" and decide among them for the "right reasons"aif it is to be taken seriously as a model of cognition.!
will argue that scene descriptions are often mostnaturally represented by structures which are, at leastin part, only awkwardly viewed as propositional; suchrepresentations include coordinate systems,trajectories, and event-simulating mechanisms, i.e.procedures w~ich set up models of objects, interactions,and constraints, "set them in motion", and "watch whathappens".
I suggest that event simulations aresupported by mechanisms that model common-sense physicsand human behaviorI will also argue that there is no way to put limitson the degree of detail which may have to be consideredin constructing event simulations; virtually any featureof an object can in the right circumstances becomecentrally important.4An explanation need not be in natural language; forexample, I probably could be convinced via traces of aprogram's operation that it had been concerned with theright issues in judging scene plausibility.2.
THE NATURE OF SCENE DESCRIPTIONSI have found it useful to distinguish between staticand dynamic scene descriptions.
Static scenedescriptions express spatial relations or actions inprogress, as in:($9) The pencil is on the desk.
($I0) A helicopter is flying overhead.
($11) My dachshund was biting the mailman.Sequences of sentences can also be used to specify asingle static scene description, a process I will referto as "detail addition".
As an example of detailaddition, consider the following sequence of sentences(taken from Waltz & Bog~ess \[I\]):($12) A goldfish is in a fish bowl.
(313) The fish bowl is on a stand.
(S14)'The stand is on a desk.
($15) The desk is in a room.A program written by BoKEess \[2\] is able to build arepresentation of these sentences by assigning to eachobject mentioned a size, position, and orientation in acoordinate system, as i l lustrated in figure I. I willrefer to such representations as "spatial analog models"(in \[I\] they were called "visual analog models").Objects in BogEesa's program are defined by givingvalues for their typical values of size, weight,orientation, surfaces capable of supporting otherobjects, as well as other properties such as "hollow" or"solid", and SO on.F i~e  I A "visual analog model" of $12-$15.Dynamic scene descriptions can use detail additionalso, but more co-,-only they use either the mechanismsof "successive refinement" \[3\] or "temporal addition".
"Temporal addition" refers to the process of describin 6events through a series of tlme-ordered static scenedescriptions, as in:($16) Our mailman fell while running from ourdachshund.
($17) The dachshund bit the mailman on the ear.
"Successive refinement" refers to a process where anintroductory sentence sets up a more or lessprototyplcal event which is then modified by succeedingsentences, e.g.
by listing exceptions to one's ordinaryexpectations of the prototype, or by providing specificvalues for optional items in he prototype, or bysimilar means.
The following sentences provide anexample of "successive refinement":($18) A car hit a boy near cur house.
($19) The car was speeding east~ard on Main Street ~tthe time.
($20) The boy, ~ was riding a bicycle, was knockedto th~ ~round.3.
THE GOALS OF A SCENE UNDERSTANDING SYSTEMWhat should a scene description understanding systemto do with a linguistic scene description?
Basically I)verify plausIDillty, 2) make inferences and predictions,3) act if action is called for, and a) remember whateveris important.
For the time being, I am only consideringI) and 2) in detail.
In order to carry out I) and 2), Iwould llke my system to turn scene descriptions (statiuor dynamic) into a time sequence of "expanded spatialanalog models", where each expanded spatial analog modelrepresents either I) a set of spatial relationships (asin $12-$15), or 2) spatial relationships plus models ofactions in progress, chosen from a fairly large set ofprimitive actions (see below), or 3) prototypicalactions that can stand for sequences of primitiveactions.
These prototypical actions would have to befitted into the current context, and modified accordingto the dictates of the objects and modifiers that weresupplied in the scene description.The action prototype would have associated selectionrestrictions for objects; if the objects in the scenedescription matched the selection restrictions, thenthere would be no need to expand the prototype intoprimitives, and the "before" and "after" scenes (similarto pro- and post-condltions) of the action prototypecould be used safely.If the selection restrictions were violated byobjects in the scene, or if modif iers were present, orif the context did not match the preconditions, then itwould have to be possible to adapt the action prototype"appropriately".
It would also have to be possible toreason abOut the action without actually running theevent simulation sequence underlying it in its entirety;sections that would have to be modified, plus before andafter models, might be the only portions of thesimulation actually run.
The rest of the prototype couldbe treated as a kind of "black box" with knowninput-output characteristics.I have not yet fotmd a principled way to enumeratethe primitives mentioned above, but I believe that thereshould be many of them, and that they should notnecessarily be non-overlapplng; what is most importantis that they should have precise representations inspatial analog models, and be capable of being used togenerate plausible candidates for succeding spatialanalog models.
Some examples of primitives I have lookedat and expect to include are: brea~-object-lnto-parta,mechanlcally- join-parts, hit, tough, support, translate,fall.As an example of the expansion of a non-primitiveaction into primitive actions, consider "bite x y"; itssteps are: 1)\[set-up\] instantlate x ~ as a "biting-thing"- -  defaults = mouth, teeth, jaws of an animate entity;2) instantiate y as "thlng-bitten"; 3)\[before\] x is openand does not touch y and x partially surrounds y (i.e.
yis not totally Inside x); ~) x is closing on y;5)\[actlon\] x is touching y, preferably in two places onopposite sides of y and x continues to close; 6) xdeforms y; 7)falter\] x is moving away from y, and nolonger touches y.Finally, lest it should not ~e clear from thesketchiness of the comaents above, I am by no meanssatisfied yet with these ideas as an explanation ofscene description understanding, a l though I am confidentthat this research is headed in  the right generaldirection.4.
PLAUSIBILITY JUDGEMENTThe basic argument I am advancing in this paper isthis: it is essential in understandlng scenedescriptions to set up and run event simulations for thescenes; we judge the plausibil ity (or possiDility),meaningfulness, and completeness of a description on thebasis of our experience in attempting to set up and runthe simulation.
By studying cases where we judgedescriptions to be implausible we can gain insight intoJust what is done routinely dm'ing the understanding ofscene descriptions, since these cases correspond tofailures in setting up or running event simulations.5By "instantiate an X" I mean assign X a physical place,posture ,  o r ientat ion ,  e tc .
or  re t r ieve  a po in ter  to  sv~han ins tant ia t ion ,  i f  i t  i s  a fami l ia r  one .
Th 3" ins tant ia te  a ~aby" would re t r ieve  a po in ter ,  w~ereaa" ins tant ia te  a two-neaded dog" would proPaP ly  have  toa t tempt  to  generate  one on the  spot .
Note that  th i sp rocess  may i t se l f  fa i l ,  i .
e .
that  an ent i ty  may not  beab le  to  " imag ine"  such  an ob jec t .As the examples below illustrate, sometimes an eventsimulation simply cannot be set up because informationis missing, or several possible "pictures" are equallyplausible, or the objects and actions being describedcannot be fitted together for a variety of reasons, orthe results of running the simulation do not match ourknowledge of the world or the following portions of thescene description, and so on.
It is also important toempbaclze that our ultimate interest is in being able tosucceed in setting up and running event simulations;therefore I have for the most part chosen ambiguousexamples where at least one event slmuiation succeeds.4.1 TRANSLATING AN OLD EXAMPLE INTO NEW MECHANISMSConsider Bar-Hillel's famous sentence \[4\]: 6($I0) The box is in the pen.Plausibility Judgement is necessary to choose theappropriate reading, i.e.
that "pen" = playpen.
Minorextensions to Boggess's program could allow it to choose?
the appropriate referent for pen.
Penl (the writingimplement) would be defined as having a relatively fixedsize (subject to being overridden by modifiers, as in"tiny pen" or "twelve inch pen"), but the size of cen2(the enclosure) would be allowed to vary over a range ofvalues (as would the size of box).
The program couldattempt to model the sentence by instantlatlng standard(default-sized) models of box, penl, and pen2, andattempting to assign the objects to positions in acoordinate system such that the box would be in peril orpen2.
Pen; could not take part in such a spatial analogmodel both because of pen1's rigid size, and the extremeshrinkage that would be required of box (outside box'sallowed range) to make it smaller than the pen;, andalso because pen; is not a container (i.e.
hollowobject).
Pen2 and box prototypes could be fittedtogether without problems, and could thus be chosen asthe most appropriate interpretation.4.2 A SIMPLE EVENT SIMULATIONExtending Boggess's program to deal with most of theother examples given in this paper so far would beharder, although I believe that $I-$4 could be handledwithout too much difficulty.
Let us look at $2 and S~ inmore detail:($2) I saw the man on the hill with a telescope.
($4) I cleaned the lens to get a better view of him.After being told $2, a system would either pick oneof the possible interpretations as most plausible, or itmight be unable to choose between competinginterpretations, and keep them both.
When it is told$4, the system must first discover that "the lens" ispart of the telescope.
Having done this, $4unambiguously forces the placement of the speaker to beclose enough to the telescope to touch it.
This isbecause all common interpretations of clean require theagent to be close to the object.
At least two possibleinterpretations still remain: I) the speaker is distantfrom the man on the hill, and is using the telescope toview the man; or 2) the speaker, telescope, and man onthe hill are all close together.
The phrase "to get abetter view of him" refers to the actions of the speakerin viewing the man, and thus makes interpretation I)much more likely, but 2) is still conceivable.
Thereasoning necessary to choose I) as most plausible israther subtle, involving the idea that telescopes areusually used to look at distant objects.In any case, the proposed mechanisms should allow asystem to discard an interpretatllon of $2 and S~ wherethe man on the hill had a telescope and was distant fromthe speaker.6A central figure in the machine translation effort ofthe late 5O's and early 6O's, Bar-Hillel cited thissentence in explaining why machine translation wasimpossible.
He subsequently quit the field.4.3 SIMULATING AN IMPLAUSIBLE EVENTLet us also look again at $5:($5) My dachshund bit our mailman on the ear.and be more specific about what an event simulationshould involve in this rather complex case.
The eventsimulation set up procedures I envision would.executethe following steps:I) instantiate a standard mailman and dachshund indefault positions (e.g.
both standing on level groundoutdoors on a residential street with no special propsother than the mailman's uniform and mailbag);2) analyze the preconditions for "bite" to find thatthey require the dog's mouth to surround the mailman'sear;3) see whether the dachshund's mouth can reach themailman's ear directly (no);~) see whether the dog can stretch high enough to reach(no; this test would require an articulated model ofthe dog's skeleton or a prototypical representation of adog on its hind legs.
);5) see whether a dachshund could jump high enough (no;tbls step is decidedly non-trivial to implement!"
);6) see whether the mailman ordinarily gets into anypositions w~ere the dog could reach his ear (no);7) conclude that the mailman could not be bitten asstated unless default sizes or movement ranges arerelaxed in some way.
Since there is no clearly preferredway to relax the defaults, more information is necessaryto make this an "unambiguous" description.I have quoted "unambiguous" because the sentence $5is not ambiguous in any ordinary sense, lexically orstructurally.
What is ambiguous are the conditions andactions whlch could have led up to $5.
Strangelyenough, the ordinary actions of mailmen (checked in step6) seem relevant to the judgement of plausibility inthis sentence.
As evidence for this analysis, note thatthe substitution of "gardener" for "mailman" turns ($5)into a sentence that can be simulated without problems.I think that it is significant that such peripheralfactors can be influential in Judging the plausibilityof an event.
At the same time, I am aware that theeffect in this case is rather weak, that people canaccept this sentence without noting any strangeness, soI do not want to draw conclusions that are too strong.~.4 MAKING INFERENCES ABOUT SCENESConsider the following passage:(91) YOU are at one end of a vast hall stretchingforward out of sight to the west.
There are openingsto either side.
Nearby, a wide stone staircase leadsdownward.
The hall is filled with wisps of white mistswaying to and fro almost as if alive.
A cold windblows up the staircase.
There is a passage at the topof the dome behind you.
Rough stone steps lead up thed~e.Given this passage (taken from the computer game"Adventure") one can infer that it is possible to moveto the west, north, south, or east (up the rough stonesteps).
Note that  this information is buried in thedescription; in order to infer this information, itwould be useful to construct a spatial analog model,TAltbough one could do it by simply including in thedef init ion of a dog information about how high a dog canJump, e.g.
no higher than twice the dog's length.However I consider tbls something of a "hack", becauseit iKnores some other problems, for example the timingproblem a dog would face in biting a small target like aperson's ear at the apex of its highest jump.
I wouldprefer a solution that could, if necessary, perform anevent simulation for step 5), rather than trust canneddata.with "you" facing west, and the scene features placedappropriately.
In playing Adventure, it is alsonecessary to remember salient features of the scenesdescribed so that one can reoo@~Lize the same room later,given a passage such as:(P2) You're in hall of mists.
Rough stone steps leadup the dome.
There is a threatening little dwarf inthe room with you.Adventure can only accept a very limited class ofco-v, ands from a player at any given point in the game.It is only possible to play  the game because one canmake reasonable inferences about what actions arepossible at a given point, i.e.
take an object, move ins~e direction, throw a knife, open a door, etc.
WhileI am not quite sure what make of my observations aboutthis example, I think that games such as Adventure arepotentially valuable tools for gathering informationabout the kinds of spatial and other inferences peoplemake about scene descriptions.4.5 MIRACLES AND WORLD RECORDSWith some sentences there may be no plausibleinterpretation at all.
In many of the examples whichfollow, it seems unlikely that we actually generate (atleast consciously) an event simulation.
Rather it seemsthat we have some shortcuts for recognizing that certainevents would have to be termed "miraculous" or difficultto believe.
(32..2,) My car goes 2000 miles on a tank of  gas.
(323) Mary caught the bullet between her teeth.
($24) The child fell from the 10th story window to thestreet below, but wasn't hurt.
(325) We took the refrigerator home in the trunk ofour VW Beetle.
($26) She ~md given b i r th  to 25 ch i ld ren  by the age o f30.
(527) The robin picked up the hook and flew away withit.
(328) The child chewed up and swallowed the pair ofscissors.The Gulnness Book of World Records is full ofexamples that defy event simulation.
How one is able toJudge the plausibility of tsese (and how we ml~ht get asystem to do so) remains s~methl~ of a mystery to me.The problem of recognizing obviously implausibleevents rapidly is an important one to consider fordealing with pronouns.
Often we choose the appropriatereferent for a pronoun because only one of the possiblereferents could be part of a plausible event ifsubstituted for the pronoun.
For example, "it" mustrefer to "milk", not "baby", in 329:($29) I didn't want the baby to get sick from drinkingthe milk, so I boiled it.5.
T~ ROLK OF EVKNT SIMULATION IN A FULu T~ORY OFLA.CUAC~I suggested in section 3 that a scene descriptionunderstanding system would have to 1) verify theplausibility of a described scene, 2) make inferences orpredlction~ about the scene, 3) act if action is calledfor, and ~) remember whatever is important.
As pointedout in section ~.5, event simulations may not even beneed for all cases of plausibility judgement.Furthermore, scene descriptions constitute only  one ofmany possible topics of language.
Nonetheless, I feelthat the study of event simulation is extremelyimportant.5.1 WHY ARE SIMPLE PHYSICAL SCENES WORTH CONSIDERING?For a number of reasons, methodological as well astheoretical, I believe that it is not only worthwhile,but also important to begin the study of scenedescriptions with the world of simple physleai objects,events, and physical behaviors with simple goals.I) Methodologically it is necessary to pick an area ofconcentration which is restricted in some way.
The worldof simple physical objects and events is one of thesimplest worlds that links language and sensorydescriptions.2) As argued in the work of Piaget \[5\], it seems likelythat we come to comprehend the world by first masteringthe sensory/motor world, and then by adapting andbuilding on our schemata from the sensory/motor world tounderstand progressively more abstract worlds.
In thearea of language Jackendoff \[6\] offers parallelarg,~eents.
Thus the world of simple physical objects andbehaviors has a privileged positions in the developmentof cognition and language.3) Few words in English are reserved for describing theabstract world only.
Most abstract words also have aphysical meaning.
In some cases the physical meaningsmay provide important metaphors for understanding theabstract world, w~ile in other cases the same mechanismsthat are used in the interpretation of the physicalworld may be shared with mechanisms that interpret theabstract world.4) I would llke the representations I develop forlinguistic scene descriptions to be compatible withrepresentations I can imagine generating with a visionsystem.
Thus this work does have an indirect bearing onvision research: my representations characterize and putconstraints on the types and forms of information Ithink a vision system o~nt  to be able to supp ly .5) Even in the physical domain, we must come to gripswith some processes that resemble those involved in thegeneration and understanding of metaphor: matching,adaptation of schemata, ~di f lcat ion of stereotypicalitems to match actual items, and the interpretation ofitems from different perspectives.5.2 SCENE D~SCRIPTIONS AND A THEORY OF ACTIONI take it as evident that every scene description,indeed every utterance, is associated with some purposeor goal o f  a speaker.
The speaker 's  purpose a f fec ts  theorgan izat ion  and order  of  the speaker 's  p resentat ion ,the items included and the items omitted, as well asword choice and stress.
Any two witnesses of the sameevent will in general give accounts of it that differ onevery level, especially if one or both witnesses wereparticipants or ~as some special interest in the causeor outcome of the event .For now I have ignored all these factOrS of scenedescription understanding; I have not attempted anaccount of the deciphering of a speaker's goals orbiases from a given scene description.
I have insteadconsidered only the propositional content of scenedescription utterances, in particular the issue' ofwhether or not a given scene description could plausiblycorrespond to a real scene.
Until we can give an accountof the Judgement of plausibility of descriptionmeanings, we cannot even say now we recognize blatantlles; from this perspective, understanding ~ someonemight lle or mislead, i.e.
understanding the intendedeffect of an utterance, is a secondary issue.There seems to me to be a clear need for a "theoryof human action", both for purposes of event simulationand, more importantly, to provide a better overallframework for AI research than we currently nave.
Whileno one to my knowledge still accepts as plausible the"big switch" theory of intelligent action \[7\], mos~ AIwork seems to proceed on the "big switch" ass,,mptionsthat it is valid to study intelligent behavior inisolated domains, and that there is no compelling reasonat this point to worry a~out whether (let alne how) thepieces developed in isolation will ultimately fittogether.5.3 ARE THERE MANY WAYS TO SKIN % CAT?Spatial analog models are certainly not the onlypossible representation for scene descriptions, hut theyare convenient and natural in many ways.
Among theiradvantages are: I) computational adequacy for10representing the locations and motions of objects; 2)the ability to implicitly represent relationshipsbetween objects, and to allow easy derivation of theserelationships; 3) ease of interaction with a visionsystem, and ultimately appropriateness for allowing amobile entity to navlgate and locate objects.
The mainproblem with these representations is that scenedescriptions are usually underspeclfled, so that thereis a range of possible locations for each object.
Itthus becomes risky to trust implicit relationshipsbetween objects.
Event stereotypes are probablyimportant because they specify compactly all theimportant relationships between objects.5.~ RELATED WORKA number of papers related the the topics treatedhere have appeared in recent years.
Many are listed in\[8\] which also provides some ideas on the generation ofscene descriptions.
This work has been pervasivelyinfluenced by the ideas of Bill Woods on "proceduralsemantics", especially as presented in \[9\].Representations for large-scale space (paths, maps,etc.)
were treated in Kuipers' thesis \[I0\].
Novak \[11\]wrote a program that generated and used diagrams forunderstanding physics problems.
Simmons \[12\] wroteprograms that understood simple scene descriptionsinvolving several known objects.
Inferences about thecauses and effects of actions and events have beenconsidered by Schank and Abelson\[13\] and Rieger\[14\].Johnson-Laird\[15\] has investigated problems inunderstanding scenes with spatial locative prepositions,as has Herskovits\[16\].
Recent work by Forbus\[17\] hasdeveloped a very interesting paradigm for qualitativereasoning in physics, built on work by deKleer\[18,19\],and related to work by Hayes\[20,21\].
My comments onpronoun resolution are in the same spirit as Hobbs\[22\],although Hobbs's "predicate interpretation" is quitedifferent from my "analog spatial models".
Ideas on theadaptation of prototypes for the representation of 3-Dshape were explored in Waltz \[23\].
A effort towardqualitative mechanics is described in Bundy \[24\].
Alsorelevant is the work on mental imagery of Kosslyn &Shwartz\[25\] and Hinton\[26\].I would like to acknowledge especially the helpfulcomments of Ken Forbus, and also the help I havereceived from Bill Woods, Candy Sidner, Jeff Gibbons,Rusty Bobrow, David Israel, and Brad Goodman.6.
REFERENCES\[I\] Waltz, D.L.
and Boggess, L.C.
Visual Analogrepresentations for natural language understanding.Prec.
of IJCAI-79.
Tokyo, Japan, Aug. 1979.\[2\] Boggess, L.C.
Computational interpretation of~nglish spatial prepositions.
Unpublished Ph.D.dissertation, Computer Science Dept., University ofIllinois, Urbana, 1978.\[3\] Chafe, W.L.
The flow of thought and the flow oflanguage.
In T.Glvon (ed.)
Discourse and Syntax.Academic Press, New York, 1979.\[~\] Bar-Hillel, Y. Lsun~ua~e and Information.Addison-Wesley, New York, 1964.\[5\] Piaget, J.
Six Psvcholo~ieal ~udies .
Vintage Books,New York, 1967.\[6\] Jackendoff, R. Toward an explanatory semanticrepresentation. "
" L 1, 89-150, 1975.\[7\] Minsky, M. and Papert, S. Artificial Intelli=ence,Project MAC report, 1971.\[8\] Waltz, D.L.
Generating and understanding scenedescriptions.
In Josbi, Sag, and Webber (e de.)
Elementsof Discourse Understanding, Cambridege University Press,to appear.
Also Working paper 24, Coordinated ScienceLab, Univ.
of Illinois, Urbana Feb. 1980.\[9\] Woods, W.A.
Procedural semantics as a theory ofmeaning In Joshl, Sag, and Webber (eds.
)Discourse Understsndln~.
Cambridge University Press, toappear .\[I0\] Kulpers, B.J.
Representing knowledge of large-scalespace.
Tech.
Rpt.
AI-TR-418, MIT AI Lab, Cambridge, MA,1977.\[11\] Novak, G.S.
Computer understanding of physicsproblems stated in natural language.
Tech.
Rpt.
NL-30,Dept.
of Computer Science, University of Texas, Austin,1976.\[12\] Simmons, R.F.
The CLOWNS microworld.
In Schank andNash-Webber (eds.)
Theoretical Issues in NaturalLangtu~=e Processing, ACL, Arlington, VA, 1975.\[13\] Scbank, B.C.
and Abelson, R. ScriPts.
Plans.Goals.
and Understandin=.
Lawrence Erlbaum Associates,Hillsdale, NJ, 1977.\[14\] Rieger, C. The commonsense algorithm as a basis forcomputer models of human memory, inference, belief andcontextual language comprehension.
In Scbank andNash-Webber (eds.)
Theoretical Issues in NaturalLanguage Processing.
ACL, Arlington, VA, ~975.\[15\] Johnson-Laird, P.N.
Mental models in cognitivescience.
CQ~nitive Science ~ I, 71-115, Jan.-Mar.1980.\[16\] Herskovitz, A.
On the spatial uses of prepositions.In this proceedings.\[17\] Forbua, K.D.
A study of qualitative and geometricknowledge in reasoning about motion.
MS thesis, MIT AILab, Cambridge, MA, Feb. 1980.\[18\] de Kleer, J.
Multiple representations of knowledgein a mechanlcs problem-solver.
Prec.
5tb Intl.
Joint~onf.
on Artificial Intelli~ence~ MIT, Cambridge, MA,1977, 299-304.\[19\] de Kleer, J.
The origin and resolution ofambiguities in causal arguments.
Prec.
IJCAI-79, Tokyo,Japan, 1979, 197-203.\[20 \] Hayes, P.J.
The naive physics manifesto.Unpublished paper, May 1978.\[21\] Hayes, P.J.
Naive physics I: Ontology for liquids.Unpublished paper, Aug. 1978.\[22\] Hobbs, J.R. Pronoun resolution.
Research report,Dept.
of Computer Sciences, City College, CityUniversity of New York, c.1976.\[23\] Waltz, D.L.
Relating images, concepts, and words.Prec.
of the NSF WorMshoo on the RePresentation of ~-OOblects, University of Pennsylvania, Philadelphia, 1979.Also available as Working Paper 23, Coordinated ScienceLab, University of Illinois, Urbana, Feb. 1980.\[24\] Bundy, A.
Will it reach the top?
Prediction in themechanics world.
Artificial Intelli~ence 10.
2, April1978.\[25\] Kossly~, S.H.
& Shwartz, S.P.
A simulation ofvisual imagery.
CQ~nitive Science I, 3, July 1977.\[26\] Hinton, G. Some demonstrations of the effects ofstructural descriptions in mental imagery.
Co=nitiveScience ~, 3, July-Sept. 1979.
