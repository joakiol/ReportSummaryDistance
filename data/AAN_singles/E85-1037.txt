A PROBLEM SOLVING APPROACH TO GENERATING TEXT FROM SYSTEMIC GRAMMARS*Terry PattenDept.
of Artificial Intelligence, University of EdinburghHope Park Square, Meadow Lane, EH8 9NW.ABSTRACTSystemic grammar has been used for AI textgeneration work in the past, but the Implementa-tions have tended be ad hoc or inefficient.
Thispaper presents an approach to systemic text genera-tion where AI problem solving techniques areapplied directly to an unadulterated systemic gram-mar.
This approach is made possible by a specialrelationship between systemic grammar and problemsolving: both are organized primarily as choosingfrom alternatives.
The result is simple, efficienttext generation firmly based in a linguistictheory.INTRODUCTIONThis paper will describe an approach to textgeneration where AI problem solving techniques areused to generate text from systemic grammars.
**Problem solving is a general term used here torefer to areas of AI research such as 'expert sys-tems', 'planning', 'design' and so on \[Hayes-Rothet al, 1983).
Techniques developed in thesefields are applied directly to an unadulteratedsystemic grammar, resulting in a simple, efficienttext generator firmly based in an establishedlinguistic theory.This approach is only possible because of afundamental relationship that exists between sys-temic grammar and AI problem solving.
Thisrelationship is described in the next section.
Thethird section will be concerned with one of themost important manifestations of this special rela-tionship: a common representation.
The followingsection will show how this common representationallows goal directed problem solving techniques tobe aPPlied directly to the grammar.
One of themost novel and important aspects of this approachis that it is compatible with the semantic stratumdescribed in the systemic theory: a system networkorganized around the idea of 'register' {Halliday,1978).
The semantic stratum and its relationshipto the grammar will be discussed next.
Some advan-tages of the approach will then be put forward.
* Many thanks to my supervisors Graeme Ritchieand Austin Tare.
This work was supported in partby an ORS award.
** For an overview of systemic grammar, see\[Winograd, 1983\] Chapter 6.Finally, the current status of the project will bedescribed, including sample output generated from alarge grammar.THE FUNDAMENTAL RELATIONSHIPI.
"The central nature of intelligentProblem solving is that a system mustconstruct its solution selectively andefficiently from a space of aiterna-tlves."
\[Hayes-Roth et al, 1983)2.
"We shall define language as 'meaningpotential': that is as sets of options oralternatives, in meaning, that are avail-able to the speaker-hearer."
\[Halliday indeJoia et al, 1980, I~72)Compare these two quotations.
Notice that bothAI problem solving and systemic grammar have attheir very core the idea of choosing from alterna-tives.
Systemic grammar is probably unique in hav-ing such emphasis on the idea of choice; or in dif-ferent terminology, systemic grammar is dis-tinguished in allowing the paradigmatic mode ofdescription to dominate over the syntagmatic \[seeHalliday et al, 1981, p. 19).
Thus, this is aspecial relationship between systemic grammar andAI problem solving.This fundamental relationship can be exploitedbecause systemic grammar provides knowledge \[in theAI sense) about the various linguistic alterna-tives, and AI problem solving provides computa-tional techniques for choosing between the alterna-tives, given the appropriate knowledge.
The textgeneration approach described here is simply thestandard AI knowledge-based problem solving metho-dology, with a systemic grammar acting as Dart ofthe knowledge base.KNOWLEDGE REPRESENTATIONOne of the manifestations of this fundamentalrelationship between AI problem solving and sys-temic grammar is a common representation ofknowledge.
Both of these fields represent theinterdependencies between the various alternativesas "condltion/effect" relationships.251problem solvingThe last decade has produced problem solvingtechniques which use domain-specific knowledge toguide the problem solving process.
Problem solvingknowledge is often expressed as condition/effectrules.
For instance, a medical problem solver mayhave the rule:i fthena patient has symptoms X, and Ydrug A should be administered.Here if the conditions Ithe symptomsJ are satis-fied, the problem solver can infer that drug Ashould be given.
At this point other rules may beinvolved:ifa drug should be administered andnot in stockthen...it isThe problem solver is forming a chain of inferenceswhich leads toward the solution.
This is called"forward chaining".Condition/effect rules can also be used toreason from the effects back to the conditions.SUDDOSe we have a rule:ifthena surface is hot and compound B isappliedthe surface will be made Permanentlynon-reflective.If a problem solver has a goal to make a surfacenon-reflectlve, it can see from the effects thatthis rule will achieve the goal.
The conditions ofthe rule are set as subgoals, and the problemsolver will try to find rules to achieve these.Rules must then be found that have the effects ofheating the surface and applying the compound.Here the problem solver is working backward fromthe solution.
This is called "goal-directed back-ward chaining".s~stemic grammarSystemic linguistics was developed in theearly sixties by M.A.K.
Halliday, although itsroots in sociology and anthropology extend backmuch further.
The emphasis of systemic linguisticshas not been on the structure of language, but onits function; systemicists are not so muchinterested in what language 'looks llke', as in howit is used.
They are interested in how language isused to ask questions and make statements, howlanguage can be used to relate 'who did what towhom', and how language ties itself to previousdiscourse.The relationship between this functional viewof language and the structural tradition is analo-gous to the relationshi~ between Physiology andanatomy*, and is equally complementary.
This func-tional perspective has led to a different conceptu-alization of what language is, and how it should bedescribed.The most important knowledge structure in sys-temic grammar is the 'system' ~ this is where thetheory gets its name.
A system is simply a mutu-ally exclusive choice between a set of alternativefeatures.
Figure I shows a system that represents achoice between a marked- and unmarked-wh-theme.unmarked-wh-themewh- I IWh / T?picallo i II~ " Flnltel' imarked-wh-themeI-r77-.. 1Figure I.
A system ~Mann/Halliday I .Systems also have 'entry conditions': a logicalcombination of features that must be chosen beforethe particular choice is appropriate.
In this casethe entry condition is simply the feature wh-.
Sothe clause must be a wh- clause before the choicebetween a marked- or unmarked-wh-theme is relevant.The boxes contain what are called 'realizationrules'.
These specify the syntactic consequences ofchoosing the associated feature.
"Wh / Topical" isread: "the Wh element is conflated with the Topi-cal", meaning that the Wh and Topical are realizedby the same item.
"Wh " Finite" is read: "the Whelement is adjacent to the Finite element", meaningthat the Wh element immediately precedes the Finiteelement in the clause.As well as systems, systemic grammars may con-tain what Mann \[19831 calls "gates'.
A gate alsohas some logical combination of features acting asentry conditions....
Present __~do-finltedoesmass-subject jFinite : does Is ingu lar -sub jec t  IFigure 2.
A gate (Mann/Halllday).In Figure 2 the curly bracket means AND, and thesquare bracket means OR.
A gate also may have real-ization rules.
Here the Finite element is con-strained to be some form of 'does': "does", "doesnot" or "doesn't".
The significant differencebetween systems and gates is that gates do notinvolve a choice.
* This analogy was probably first made by Firth(1957) and has been used several times since -- see\[Winograd, 1983, p.287J252interrogativeindicative I/ f in i te_  I --J mar ked-decl-themei - I  I deelaratlve__lJ I imDerative J unmarked-decl-themeJ non-finlte I Subject/Theme Jclause-J middle operativeI--I I A~ent/Sub4ect \]I effective, receptivetheme \[-I #^Theme J/ : conflatlon: adjacency # : boundaryFigure 3.
A grammar excerpt.Now consider these two constructs from a prob-lem solving point of view.
A feature that is partof a system can be " interpreted as acondltion/effect rule.
The conditions are simplythe entry conditions of the system; the effects arechoosing the feature, and doing whatever the reali-zation rules say.
This means that these featurescan be interpreted as problem solving rules and putat the disposal of the problem solver.
Again itmust be stressed that a system involves choice.From a problem solving point of view choices shouldbe avoided whenever possible, in case the wrongchoice is made.
Notice if a system feature is usedfor backward chaining the choice is not explicitlyconsidered.
Suppose there is a goal to chooseunmarked-wh-theme.
Since the problem solver caninterpret the system features as condition/effectrules, it sees that there is a rule calledunmarked-wh-theme that achieves this goal as one ofits effects.
The problem solver begins to backwardchain by invoking this rule and setting its condi-tion, wh-, as a subgoal.
The feature marked-wh-theme was never explicitly considered.Similarly, features that are gates can beinterpreted as forward chaining condition/effectrules.
In Figure 2, if the entry conditions aresatisfied, the does rule fires, choosing does andconstraining the Finite element.THE METHODThe last section showed that features fromsystemic grammars can be interpreted as acondition/effect rule of the type used by AI Prob-lem solvers, regardless of whether they are part ofa system or a gate.
An AI problem solver can thususe a systemic grammar as part of its knowledgebase, and solve grammatical problems in exactly thesame way as it solves medical problems using medi-cal knowledge, or chemistry problems using chemis-try knowledge.an examDleFigure 3 is a simplified excerpt from a sys-temic grammar.
Suppose, for the moment, that thesemantics wants to choose unmarked-declarative-theme and operative.
The grammar provides rulesthat achieve these goals as Dart of their effects.The feature unmarked-declarative-theme can bethought of as a rule that chooses that feature andconflates the Subject with the Theme.
This rulehas, however, the condition declarative.
This isset as a subgoal which can be achieved by anotherrule tl~at in turn has the condition indicative.
Inthis way the problem solver backward cha lnsf romunmarked-declaratlve-theme through declarative,through indicative, through finite, to clause.
Atthis point the backward chaining stops becauseclause has no conditions.
The problem solver alsobackward chains from operative through effective toclause.
Once clause is chosen, the gate themefires \[the only instance of forward chaining inthis example).Every time a rule is used the 'realizationrules' in the effects are accumulated, graduallyconstraining the structure of the clause.
In theexample, the Agent has been constrained to be theleftmost constituent in the clause.
The semanticswill choose other features of course, from parts ofthe grammar not shown here, and after further for-ward and backward chaining, the clause will be com-pletely determined.253The careful reader may have noticed that it ispossible for the semantics to start the same pro-cess with the goal "move the agent into the themePosition" \[conflate Agent and ThemeJ, assumingthere is a rule expressing the transitivity ofconflation.
The transitivity rule would set assubgoais: "conflate Agent with X" and "conflateTheme with X", where X could be instantiated toSubject.
From there the problem solving wouldproceed as before.
However, this would require fartoo much inference for such a simple goal.
First,the transitivity would have to be worked outcorrectly.
Second, there are likely to be otherrules with the same realization rules, but whichwould lead to conflicts, and backtracking.In problem solving, if a simple goal requirestoo much inference, its solution can be 'compiled'\[Brachman, 1983J.
Here, the semantics may have arule that says:ifthenthere is a goal to make a statement and agoal to move the agent into the themePositionchoose unmarked-declarative-theme andoperative.This use of compiled knowledge to actuallychoose features from the grammar corresponds to thesystemic idea of 'preselection'.
Preselection isan important part of systemic theory, being thevehicle of realization across network boundaries.Systemic grammar:adopts... the general perspective on thelinguistic system you find in Hjelmslev,in the Prague school, with Firth in theLondon school, with Lamb and to a certainextent with Pike - language as a basi-cally tristratai system: semantics, gram-mar, phonology.
\[Halliday, 1978, P.39JEach level must Pass down information to thelevel below.
Realization rules at the higher levelDreselect features from the next level below.
Thesemantic stratum \[described in the next sectionJpreselects features from the grammatical stratum\[e.g.
unmarked-declarative-theme and operative inthe example aboveJ.
Simliarly, the grammatlcaistratum preselects phonologlcal/graphologlcalfeatures.Preselection is also used to interface thedifferent ranks at the grammatical level \[clause,group and wordj.
The colon in Figure 2 is the sym-bol for preseleetlon.
Thus the feature does at theclause rank preselects the feature does from theauxiliary network at the word rank.
If, forinstance, the features reduced and negative arealso preseleoted, the Finite element will be real-ized as "doesn't".Returning to Figure 3, compare this backwardchaining approach to Mann's \[1983) NIGEL system.NIGEL begins at the left hand side of the networkand works its way towards the right.
It starts bychoosing the feature clause.
Then it sees that itmust choose between finite and non-finite.
Thereis a semantic 'choice-expert' associated with thissystem which cannot make the choice withoutspecific information about the context and the com-municative goals, The choice expert gains thisinformation by passing messages to the 'environ-ment'.
In this case the answer returned from theenvironment will indicate that finite should bechosen.
Another choice expert will now choosebetween indicative and imperative and so on.Whether or not this is a valid or interestingway to do text generation is not at issue here.From a computational point of view NIGEL has somedrawbacks.
Most importantly, an explicit choicemust be made for every system encountered duringthe process.
For large grammars, this will numberin the hundreds, and will result in a large over-head.
In contrast, the preselection - backwardchaining approach outlined in this paper greatlyreduces the number of explicit choices,The reason these choices are avoided here isthat the problem solving process is ~oal-directed.The semantic stratum chooses some features from theright hand side of the network, which greatlyreduces the number of Possible paths through thenetwork from the very start.It could be argued that this kind of goal-directed search is non-deterministlc because sys-tems may have disjunctive entry condit ions,  Thereis, however, an AI problem solving technique whichhas been developed for this purpose: least commit-ment \[Stefik et al, 1983~.
Least commitment issimply the principle o f  not making any choicesuntil absolutely necessary.
Whenever a disjunctiveentry condition is encountered, a decision must bemade about which subgoal to set.
There is norequirement that the decision be made at that par-ticular instant, so it is suspended until one ofthe subgoals is set as part of another chain ininference \[gratuitously solving the original prob-lemJ.
Of course there will be cases where none ofthe subgoals \[entry conditions) are part of anotherinference.
In these cases, it must be assumed thatthe semantics will preselect a feature correspond-ing to one of the subgoals.Clearly this whole text generation methodrelies on the semantic level to preselect theappropriate grammatical features.
The next sectionwill briefly look at this semantic level.254control __Jstrategythreat of deprivation...J loss of --IJprivilege J commandimperative-- l rej ect i?n--I obligat ionthreat ofpunishment.,.appeal...Figure 4.
Some semantic choicesSEMANTICSNo motivation for the stratified approachadopted by systemic grammar will be given here,except pointing out that the role of the semanticstratum is to interface the extra-linguistic withthe grammatical \[Halliday, 1978).
In order topreselect the correct features from the grammar,this level must contain a considerable amount ofknowledge \[in the AI sense) relating grammaticalfeatures to extra-lingulstic factors.In this section we will look at one particularorganization of the semantic stratum, as presentedin \[Halliday, 1978).
Halliday organized his seman-tic stratum around the idea of 'register':It refers to the fact that the languagewe speak or write varies according to thetype of situation ... What the theory ofregister does isattempt to uncover thegeneral principles which govern thisvariation, so that we can begin to under-stand what situational factors determinewhat linguistic features.
\[Halliday indeJoia st al., 1980, #764)Halliday uses the same system network notationto describe the semantics.
Figure 4 \[adapted from\[Halliday, 1978)) describes the control strategiesthat a mother can use on her child.The features of a semantic system network,llke those of the grammatical networks, have reali-zation rules ~ including preselection.
Forinstance the semantic feature re4ection Dreselectsthe features which will make the hearer the Medium\[Affected), and realize it with the pronoun 'you'\[by preselecting from the nominal group and nounnetworks).
The semantic feature decisionpreselects, for instance, the clause featuredeclarative.
The semantic feature resolutionPreselect3 the features present-in and present togive this type of threat its tense construction --e.g.
"you're going upstairs", "I'm taking youupstairs".
Similarly, obligation preselects neces-sary passive modulation \[Halliday, 1970) -- e.g.
"I'll have to take you upstairs", "you'll have togo upstairs" \[Halliday, 1978).Unfortunately, very little work has been donein the area of register, even by Halliday and hiscolleagues, so no large portions of a semanticstratum have been built.
However, this exampleillustrates the idea.ADVANTAGESThe backward chaining approach outlined herehas several advantages.
First, this method doesnot involve any linguistic sacrifices, since anestablished linguistic formalism is utilized.
Sys-temic grammar was developed by l inguists forlinguistic purposes, and is used here in a totallyunadulterated form.
Nothing llnguisticaily ad hochas been introduced for computational reasons.Second, no computational sacrifices have beenmade to accommodate the linguistic formalism.State-of-the-art computational techniques are beingexploited at all stages of the problem solving pro-cess.Third, the approach is parsimonious.
There isno need for a sPecial-purpose text generation com-ponent.
Other methods involve an AI problem solverthat does the extra-linguistic work and perhaps thehigh- leve l  'text-plannlng', then passes a specifi-cation off to a special-purpose mechanism thatprocesses the grammar.
Here the AI problem solvercan directly process the grammar; eliminating thespecial purpose component, and avoiding the kind ofmessage passing that NIGEL, for example, must do.PROJECT STATUSAt present, this approach to text generationis being tested on a large systemic grammar.
Thegrammar has been collected from a variety ofsources \[Mann/Halliday) \[Kress, 1976J \[Halliday &Hasan, 1976) \[Winograd, 1983J, and  contains aboutsix hundred grammatical features.
Fragments ofgrammar usually appear in the linguistic literatureas 'system networks'.
These are entered as LISPdata structures, and translated by a three pageLISP program into OPS5 production rules, lOPS5 is awidely used production system that was used toimplement, for example, RI \[Gaschnig et al,1983JJ.once the grammar is  in the form of OPS5 rules,OPS5 can perform forward and backward chainingdirectly.
The rest of the system consists mostly ofOPS5 rules to act on the realization rules of thegrammar, and to output the text as it is being gen-erated.The interface between the grammar and the255semantics has been implemented, namely preselec-tion.
Since preselectlon is done via realizationrules, it is implemented by a small group of OPS5rules as just mentioned.Although the interface between the grammar andthe semantics has been implemented, the semanticstratum itself has not.
This means that to test theapproach, those features that would have beenpreselected by the semantics must be preselected byhand.Another limitation at the moment is that thereis no graphological level.
This means that theoutput does not contain punctuation, capitals, theword "an", and so on.To put all this in perspective, recall thatsystemic linguistics stratifies language into thesemantic, the grammatical, and the graphological\[or if working with speech, phonologicalJ strata.Currently only the middle stratum, the grammatical;has been implemented.
Again it should be Pointedout that the interfacebetween the different strata\[preselectlon in each caseJ has been implemented aswell.sample outputConsider the context of a medical expert sys-tem that is trying to diagnose a patient's illness.Suppose there is a patient named Mary who has beenhaving headaches and stiff neck muscles.
The expertsystem hypothesizes that Mary has a fever, andtests this hypothesis by asking "Does Mary have afever ?- At this point, the user, who we willassume is neither a medical or computing expert,can ask "WHY" \[did you ask me that question?J*.The test system at this stage can generate the fol"lowing response \[bars have been added to indicateclause boundaries).il well mary has been having headaches IIon this basis perhaps she has a infectionII this DOSSlbility would be SUPDorted bya fever II so we ask I does she have oneilRemember that at present, the features thatwould be preselected by the semantics must bepreselected by hand for each individual clause.However, this example illustrates the grammar weare working with, and demonstrates that thisapproach works very well with large grammars.CONCLUSIONThis paper has described a new approach togenerating text from systemic grammars.
State-of-the-art AI problem solving techniques are applieddirectly to an unadulterated systemic grammar.
Wehave seen how this approach is made possible by aspecial relationship between systemic linguisticsand AI problem solving.
A semantic stratum, con-sisting of a large knowledge base relating dif-ferent 'registers' to grammatical features,preselects some features from the grammaticallevel.
The large number of features which are notpreselected are inferred efficiently by goal-directed backward chaining and forward chaining.This approach has the advantage of being ableto combine an established linguistic formalism withpowerful AI methods.
It also has the advantage ofsimplicity resulting from the application of thesesame methods throughout the generation process.This approach has been applied successfully toa large grammatical stratum.
Of course it will nothave been tested properly until a substantialsemantic stratum is developed.In conclusion, although there are still manyunresolved linguistic matters in systemic text gen-eration, we hope this approach has moved towardsolving the computational problems involved.
* Following an example from \[Hasling et al,1984).256REFERENCESBraohman,R., Amarel,S., Engelman,C.,Engelmore,R., Feigenbaum,E., Wilkins,D.
"What areExpert Systems ?"
In \[Hayes-Roth et al; 1983).Firth,J.R., "A synopsis of linguistic theory1930-1955J."
Studies in Linguistic Analysis.Blackwell, Oxford, 1957, PP.
1-32.
Reprinted inPalmer, F.R.,\[ed.)
Selected Papers of J.R.Firth1952-1959.
Longman, London, 1968, PP.
~'8:2~5.Forgey,C.L.
"OPS5 User's Manual".
CMU-CS-81-135 Carnegie Mellon University, Pittsburgh, 1981.Gaschnig,J., Klahr,P., Pople,H.,Shortllffe,E., Terry,A., "Evaluation of ExpertSystems: Issues and Case Studies."
In \[Hayes-Rothet al, 1983J.Halliday, M.A.K., Explorations in the Func-tions of Language.
Edward Arnold, London, 1973.- - ,  Language as a Social Semiotic.
EdwardArnold, London, 197~.- - ,  "Modality and modulation in English."
In\[Kress, 1976, Ch.
13), 1970.Halliday, M.A.K.
& Martln,J.R.
\[eds.
J Readingsin Systemic Linguistics.
Batsford Academic, Lon-don, 19"~.Hasling,D., Clancey,W., Rennels,G., "Strategicexplanation for a diagnostic consultation system.
"In Coombs,M.\[ed.)
Developments in Expert Systems.Academic Press, London, 1984, pp.
117-133.Hayes-Roth,F., Waterman,D., Lenat,D., \[eds.
)Building Expert Systems.
Addlson-Wesley, London,; 983.deJoia,A.
& Stenton,A.
Terms in SystemicLinguistics.
Batsford Academic, London, 1980.Kress,G.
led.)
Halliday: S~m and Functionin Language.
Oxford, London, 1976.Mann,W./Halliday,M.A.K.
"Systemic Grammar ofEnglish, S.G.
Clause Systems".
From the PENMANsystem, InfOrmation Sciences Institute, USC.Mann,W.
& Matthlessen,C.
"Nigel: A SystemicGrammar for Text Generation".
RR-83-I05, Informa-tion Sciences Institute, USC.
1983.Monaghan,J.
The Neo-Firthian Tradition andits Contribution to General Linguistics.
MaxNiemeyer Veriag, Tublngen, ;979.Stefik,M., Aikins,J., Balzer,R., Benoit,J.,Birnbaum,L., Hayes-Roth~F., Sacerdoti,E., "Thearchitecture of expert systems."
In \[Hayes-Roth etal., 1983), 1983.WinoErad,T.
Language as ~ Cognitive Process.Addison-Wesley, London, 1983.2~
