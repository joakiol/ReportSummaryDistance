Proceedings of the ACL 2014 Student Research Workshop, pages 78?85,Baltimore, Maryland USA, June 22-27 2014.c?2014 Association for Computational LinguisticsOpen Information Extraction for Spanish Languagebased on Syntactic ConstraintsAlisa ZhilaCentro de Investigaci?onen Computaci?on,Instituto Polit?ecnico Nacional,07738, Mexico City, Mexicoalisa.zhila@gmail.comAlexander GelbukhCentro de Investigaci?onen Computaci?on,Instituto Polit?ecnico Nacional,07738, Mexico City, Mexicogelbukh@gelbukh.comAbstractOpen Information Extraction (Open IE)serves for the analysis of vast amounts oftexts by extraction of assertions, or rela-tions, in the form of tuples ?argument 1;relation; argument 2?.
Various approachesto Open IE have been designed to per-form in a fast, unsupervised manner.
Allof them require language specific infor-mation for their implementation.
In thiswork, we introduce an approach to OpenIE based on syntactic constraints over POStag sequences targeted at Spanish lan-guage.
We describe the rules specific forSpanish language constructions and theirimplementation in EXTRHECH, an OpenIE system for Spanish.
We also discusslanguage-specific issues of implementa-tion.
We compare EXTRHECH?s perfor-mance with that of REVERB, a similarOpen IE system for English, on a paral-lel dataset and show that these systemsperform at a very similar level.
We alsocompare EXTRHECH?s performance on adataset of grammatically correct sentencesagainst its performance on a dataset of ran-dom texts extracted from the Web, drasti-cally different in their quality from the firstdataset.
The latter experiment shows ro-bustness of EXTRHECH on texts from theWeb.1 IntroductionOpen IE is a rapidly developing area in text pro-cessing, with its own applications and approachesthat are different from traditional IE (Etzioni etal., 2008; Banko and Etzioni, 2008; Etzioni,2011).
Unlike traditional IE, where systems aretargeted at extraction of instances of particular re-lations with arguments restricted to certain seman-tic classes, e.g., to be born in(HUMAN; LOCA-TION), Open IE serves for extraction of all pos-sible relations with arbitrary arguments.
For ex-ample, in ?Woman who drove van full of kids ischarged with attempted murder?
two relations canbe identified: ?Woman; drove; van full of kids?
and?Woman; is charged with; attempted murder?.The ability to extract arbitrary relations fromtext allows applications of Open IE that are notpossible in the frame of traditional IE.
Amongthem are fact extraction at sentence level (e.g.,?Mozart; was born in; Salzburg?
), new perspectiveon search as question answering (e.g., Where wasMozart born?)
(Etzioni, 2011), or assessment ofthe quality of text documents at Web scale (Hornet al., 2013).
Additionally, the output of Open IEsystems can serve for ontology population (Soder-land et al., 2010) and acquisition of common senseknowledge (Lin et al., 2010).Although all Open IE systems are targeted at theextraction of arbitrary relations, the approaches tothis task vary significantly.
The pilot approachsuggested by Banko et al.
(2007) is based onsemi-supervised learning of general relation pat-terns that then serve for extraction of arbitraryrelations.
However, the output of such systemscontains many incoherent and inconsistent extrac-tions, and the training stage is quite computation-ally complex.
Fader et al.
(2011) suggested an-other approach where syntactic and lexical con-straints were applied over POS-tagged input.
Thisapproach has proven to be robust and fast enoughfor relation extraction at Web scale.Although Open IE is targeted at extraction ofarbitrary relations without any semantic restric-tions, all approaches have strong language de-pendent restrictions and require language spe-cific information to be introduced in the corre-sponding systems.
For Spanish language, theapporach based on rules over dependency treeshas been implemented both using full parsing78(Aguilar-Galicia, 2012) and using shallow depen-dency parsing (Gamallo et al., 2012).
The for-mer work shows that this approach is too com-putationally costly and is not always robust evenon grammatically correct texts.
The latter workdoes not report any results for Spanish language ordiscusses any details specific to implementationsfor languages other than English.
Further, we arenot aware of any existing research on whether theapproach based on syntactic constraints over POStags can be generalized to other languages.
Ad-ditionally, although Open IE is claimed to be use-ful for information extraction from the Web, weare not aware of any research on its applicabilityto texts randomly extracted from the Internet, i.e.,those that have not been verified for grammaticalcorrectness by peers or editors.In this paper we discuss Open IE based on syn-tactic constraints over POS tag sequences, aimedat Spanish language.
We describe its implemen-tation and introduce EXTRHECH, an Open IE sys-tem for Spanish.
We also compare its performancewith that of REVERB (Fader et al., 2011) on aparallel dataset.
Additionally, we evaluate perfor-mance of our system over a dataset of texts ran-domly extracted from the Internet and discuss theissues that arise when processing random Internettexts.
We also give a brief analysis of errors.The paper is organized as follows.
Related workis reviewed in Section 2.
Section 3 presents ourapproach to Open IE for Spanish and describesthe EXTRHECH system.
Section 4 describes theexperiments for a parallel English-Spanish datasetand for a Spanish dataset of texts randomly ex-tracted from the Internet.
In Section 5, a briefanalysis of errors is presented.
Section 6 drawsthe conclusions and outlines future work.2 Related WorkThere exist several approaches to Open IE.Chronologically the first one was introducedin the pilot works on Open IE by Banko et al.
(2007) and Etzioni et al.
(2008).
Their approach isbased on semi-supervised machine learning prin-ciples and includes three main steps: (1) man-ual labeling of a training corpus for seed relationphrases and features; (2) further semi-supervisedlearning of relations; (3) automatic extractions ofrelations and their arguments.
This approach isimplemented in TEXTRUNNER (Banko and Et-zioni, 2008), WOEpos, and WOEparse, both (Wuand Weld, 2010).
In these systems, the detectionof a relation triple starts from the potential argu-ments expressed as noun phrases, i.e., before theconnecting relation phrase is detected.
Once de-tected, neither the argument phrases nor the rela-tion phrase can be backtracked, which makes theapproach prone to incoherent and uninformativeextractions.
For example, in ?to make a deal with?,deal can be erroneously extracted as an argument,although it is a part of the relation phrase.The group of rule-based approaches includessystems based on rules applied over linguisti-cally annotated texts.
FES-2012 system (Aguilar-Galicia, 2012) applies rules to the fully parsed sen-tences.
However, in the same work the authorsshow that this approach is too slow to be scaled toa Web-sized corpus and that it is not robust.
An-other system implementing rule-based approach isDEPOE (Gamallo et al., 2012).
In this system, therules are applied to the output of shallow depen-dency parsing.
In REVERB system (Fader et al.,2011), syntactic constraints are applied over POStags and syntactic chunks.
The last two systemsshow better results in terms of precision/recall andspeed, and, consequently, scalability to a Web-sized corpus.Finally, the approach based on the deep au-tomatic linguistic analysis is implemented inOLLIE (Mausam et al., 2012).
This system com-bines various approaches: it uses output of a rule-based Open IE system to bootstrap learning of therelation patterns and then additionally applies lex-ical and semantic patterns to extract relations thatare not expessed through verb phrases.
Such acomplex approach leads to high-precision resultswith a high yield.
However, there is a tradeoff be-tween accuracy of the output and cost of imple-mentation and computation and complexity of thetraining stage.All these approaches require language-dependent information for their implementation.The third approach directly uses lexical infor-mation for the context analysis.
The other twoapproaches employ language-specific morpholog-ical and syntactic information.
Of the describedsystems, only two have been implemented forlanguages other than English.
FES-2012 systemis implemented for Spanish language; however,its use of the full syntactic parsing does not scaleto a Web-sized corpus.
DEPOE system, based onrules over shallow dependency parsing, is claimed79to have its variants for Spanish, Portuguese, andGalician languages (Gamallo et al., 2012).
How-ever, the authors do not report any experimentalresults on languages other than English or anylanguage-specific details.The approach based on syntactic constraintsover POS tags has not been applied to languagesother than English, in spite of that this methodcan be easily adapted to other languages because itonly requires a reliable POS tagger.
The basic al-gorithm for relation extraction, according to Faderet al.
(2011), is as follows:?
First, search for a verb-containing relationphrase in a sentence;?
If detected, search for a noun phrase to theleft of the relation phrase;?
If a noun phrase detected, search for anothernoun phrase to the right of the relation phrase.Additionally, the experiments for Open IE sys-tems have been conducted only on texts that camefrom verified sources, i.e., Wikipedia, news, ortextbooks (Banko and Etzioni, 2008; Fader et al.,2011; Mausam et al., 2012).
However, Open IE ismeant to work with Web text data that may comefrom any source including those that have not beenedited or verified for grammar errors.3 System DescriptionIn this section we introduce EXTRHECH,1a sys-tem for Open IE in Spanish.
It takes a POS-taggedtext as input, applies syntactic constraints over se-quences of POS-tags, and returns a list of extractedrelations as triples ?argument 1; relation; argu-ment 2?
that correspond to each sentence.3.1 Basic ProcessingThe system takes as input a POS-tagged text.
Inour experiemnts, we used a morphological ana-lyzer from Freeling-2.2 (Padr?o et al., 2010).
ForSpanish language, it returns POS tags accoridng toEAGLES POS tag set (Leech and Wilson, 1999).Consequently, our system is designed to work withthis POS tag set.Spanish uses a number of non-ASCII charac-ters, such as ?a, ?e, ?n, etc.
These characters cancome in different encodings.
To be able to cor-rectly analyze text with these characters, Freeling1All materials are available on the pagehttp://www.gelbukh.com/resources/spanish-open-fact-extraction.analyzer should receive the input in ISO encod-ing.
Thus, the input text needs an additional pre-processing stage to be converted into this encod-ing.
Though this might look as a minor technicalissue, guessing the original encoding becomes asignificant problem when working with texts fromarbitrary sources on the Web.
We discuss encodingrelated issues in Section 4.2.After the text has been properly POS-tagged,we feed it into EXTRHECH system, which ap-plies the fact extraction algorithm described inSection 2 to each sentence, one sentence at a time.We use the same basic algorithm as in (Fader etal., 2011) but with different triple matching rulesas appropriate for Spanish grammar.The original POS-tag sequences for Englishwould produce nonsense results on Spanish inputdue to substantial difference in grammars: infini-tives are not preceded by ?to?, adjectives usuallyfollow nouns, and oblique case pronouns precedeverbs instead of following them, just to name a fewpeculiarities of Spanish.First, the system looks for a verb-containingphrase in a sentence by matching it against the fol-lowing expression:VREL?
(V W* P) | (V),where V stands either for a single verb optionallypreceded by a reflexive pronoun (se realizaron,?were carried out?
), or a participle (calificado,?qualified?).
V W* P matches a verb with depen-dent words, where W stands for either a noun, anadjective, an adverb, a pronoun, or an article, andP stands either for a preposition optionally imme-diately followed by an infinitive, or for a gerund(sigue siendo, ?continues to be?).
The symbol* denotes zero or more matches.
Here and fur-ther, the whole match is referred to as verb phrase(though it is not a verb phrase in linguistic sense).After detecting a verb phrase, EXTRHECHlooks for a noun phrase to the left from the be-ginning of the verb phrase.
This noun phrase is apotential first argument of the relation.
If a matchis found, then the system looks for another nounphrase to the right from the end of the verb phrase.The noun on the right side is treated as the secondargument.Noun phrases are searched for with the follow-ing regular expression:NP?
Np (PREP Np)?,where Np matches a noun optionally preceded byeither an article (la din?amica, ?the dynamics?
),80an adjective, an ordinal number (los primerosganadores, ?the first winners?
), a number (3 casas,?3 houses?
), or their combination, and optionallyfollowed by either a single adjective (un esfuerzocriminal, ?a criminal effort?
), a single participle,or both (los documentos escritos antiguos, ?theancient written documents?).
The whole expres-sion matched by Np can be preceded by an indef-inite determinant construction, e.g., uno de, ?oneof ?.
PREP matches a single preposition.
Hence,an entire noun phrase is either a single noun withoptional modifiers or a noun with optional modi-fiers followed by a prepositional phrase that is apreposition and another noun with its correspond-ing optional modifiers (una larga lista de proble-mas actuales, ?a long list of current problems?
).The symbol ?
denotes 0 or 1 matches.If noun phrases are matched on both sides of theverb phrase, all three components are consideredto represent a relation and are extracted in the formof a triple.As an output unit, EXTRHECH returns a tripleconsisting of ?argument 1; relation; argument 2?,where argument 1 semantically is, e.g., an agentor experiencer of the relation and argument 2 is ageneral object or circumstance of the relation.3.2 Additional ProcessingAbove we described the core rules and the basicsequence for relation extraction.
In addition tothem, we also implemented several optional rulesfor processing of certain language constructionsthat can be turned on and off with the input pa-rameters.First, participle clauses that follow a noun canbe searched for a relational triple if they terminatewith a noun.
For example, from a phrasePrecios del caf?e suministrados por la OIC(?Coffee prices provided by International CoffeeOrganization?
)EXTRHECH returns the relation:?Precios del caf?e; suministrados por; la OIC?.Second, EXTRHECH also approaches resolu-tion of coordinating conjunctions between verbphrases and between noun phrases into corre-sponding separate relations.
Here follows the ex-ample of a sentence with a coordinating conjunc-tion between verb phrases:El cerebro almacena enormes cantidades de informaci?on yrealiza millones de actividades todos los d?
?as(?The brain stores vast amounts of information and performsmillions of activities every day?).
Two facts are detected:?El cerebro; almacena enormes cantidades de; informaci?on?and?El cerebro; realiza millones de; actividades todos los d?
?as?.Third, relative clauses introduced by single rel-ative pronouns (e.g., que (?that?, ?who?
), cual(?which?))
as in las partes que conforman untrabajo de investigaci?on (?parts that make up aresearch work?)
are also searched for relations.However, relative pronoun phrases with preposi-tions, e.g.
en el cual (?in which?)
are not taken intoconsideration for relation extraction due to theircoreferential complexity.3.3 LimitationsThe implementation of basic processing per-formed by EXTRHECH system follows the algo-rithm introduced in (Fader et al., 2011).
Thismeans that extracted facts are limited to the rela-tions expressed through a verb phrase.
This limi-tation is discussed in the cited paper.In our apporach to Open IE in Spanish, we donot allow pronouns to be potential arguments ofa relation.
It was mainly done because of a wideuse of a neutral pronoun lo (?this?, ?which?, or nodirect translation) as a head of relative clauses inSpanish language, e.g., lo que dio valor al poderjudicial (?
that gave value to the judiciary?).
In-cluding pronouns for potential argument matcheswould return a lot of uninformative relations as?lo; dio valor a; el poder judicial?.
This issue canbe solved only by introducing anaphora resolutiontechniques which involves processing on a super-sentence level.
Although seemingly feasible, thismodification will necessarily slow down the ex-traction speed which is critical while working withlarge scale corpora.
As mentioned in Section 2,high speed performance is one of the main advan-tages of the approach to Open IE based on syntac-tis constraints compared to the others.
Hence, anymodifications that would affect its speed should beconsidered with caution.Another language dependent limitation is re-lated to the order of the processing.
Asearlier described in Section 3.1, an extractedtriple is expected to correspond semanticallyto ?agent/experiencer; relation; general ob-ject/circumstance?.
This is expected to be cor-rect for a direct word order, i.e., Subject ?
Verb?
(Indirect) Object, which is a dominant word or-der for Spanish.
Yet the inverted word order, i.e.81(Indirect) Object ?
Verb ?
Subject (e.g., De lam?edula espinal nacen los nervios perif?ericos, i.e.,literally *?From the spinal cord arise peripheralnerves?
), also occasionally takes place in gram-matically correct and stylistically neutral Spanishtexts.
However, the occurence of this constructionis less then 10% according to (Clements, 2006).4 Experiments and EvaluationIn this section we describe the experiments con-ducted with EXTRHECH system.4.1 Experiment on parallel news datasetWe compare EXTRHECH?s performance with thatof REVERB, an Open IE system for English basedon the same algorithm (Fader et al., 2011).
Sincethese systems are designed for different languages,we ran our experiment on a parallel dataset.1We took 300 parallel sentences from theEnglish-Spanish part of News Commentary Cor-pus (Callison-Burch et al., 2011).
Then, we ranthe extractors over the corresponding languages.After that, two human annotators labeled each ex-traction as correct or incorrect.
For the Spanishpart of the dataset, the annotators agreed on 80%of extractions (Cohen?s kappa ?
= 0.60), whereasfor the English part they agreed on 85% of extrac-tions with ?
= 0.68.
For both datasets their respec-tive ?
coefficients indicate substantial agreementbetween the annotators.Precision was calculated as a fraction of correctextractions among all returned extractions.
Wecalculated Recall as a fraction of all returned cor-rect extractions among all possible (i.e., expected)correct extractions.
By manual revision of the sen-tences in the datasets, we made a list of all ex-pected correct extractions.
Their number was usedto estimate the recall.In contrast to REVERB, our system does nothave a confidence score mechnaism at this point.To make the comparison between the systems ap-propriate, we ran REVERB extractor with the con-fidence score level set to 0 that means that the sys-tem returns all relations that match the rules, i.e.,in the same way as EXTRHECH does.
Hence, thesystems were in equivalent conditions.
The resultsof the experiment are shown in Table 1.As we see, on a parallel dataset of texts fromNews Commentary Corpus, both systems show avery similar performance.
Based on this observa-tion, we can conclude that the algorithm suggestedSystem Precision RecallCorrect ReturnedExtractions ExtractionsEXTRHECH 0.59 0.48 218 368REVERB 0.56 0.44 201 358Table 1: Performance comparison of REVERB andEXTRHECH systems over a parallel dataset.in (Fader et al., 2011) can be easily adopted forother languages with dominating SVO word orderand an available POS-tagger.4.2 Experiment on Raw Web datasetOne of the most important goals of Open IE sys-tems is to be able to process large amounts of textsdirectly from the Web.
This requires high per-formance speed and robustness on texts that of-ten lack grammatical and orthographical correct-ness or coherence.
The study showing the ap-proach?s advantage in speed was already presentedin (Fader et al., 2011).
In this work we focused onrobustness.
We evaluated the performance of oursystem on a dataset of sentences extracted fromthe Internet ?as is?.
For this dataset, we took200 random data chunks detected by a sentencesplitter from CommonCrawl 2012 corpus (Kirk-patrick, 2011), which is a collection of web textscrawled from over 5 billion web pages.
However,41 from those 200 chunks were not samples oftextual information in human language but ratherpieces of programming codes or numbers.
Wetook out these chunks because they are not rele-vant for our research.
In a real life scenario theycould be easily detected and eliminated from theWeb data stream.
After this, our dataset consistedof 159 sentences written in human language.
Wewill refer to this dataset as Raw Web text dataset.1Of 159 sentences of the dataset, 36 sentences (22%of the dataset) were grammatically incorrect or in-coherent, as evaluated by a professional linguist.We ran EXTRHECH system over this datasetand asked two human judges to label extractionsas correct or incorrect.
The annotators agreed on70% of extractions with Cohen?s ?
= 0.40, whichindicates the lower bound of moderate agreementbetween judges.Precision and Recall were calculated in thesame manner as described in Section 4.1.
We com-pare these numbers to the results obtained for thedataset of grammatically correct sentences fromNews Commentary Corpus in Table 2.We can observe that system?s performence has82Dataset Precision RecallNews Commentary 0.59 0.48Raw Web 0.55 0.49Table 2: Performance of EXTRHECH on the gram-matically correct dataset and the dataset of noisysentences extracted from the Webnot lowered significantly when processing ?noisy?texts compared to edited newspaper texts.
An in-teresting observation is that texts from the Internetare poorer in facts than the news texts.
The num-ber of expected extractions was manually evalu-ated by a human expert for both datasets.
The ra-tio of extractions to sentences for the news datasetwas 1.5:1, while for the Raw Web dataset it wasonly 1.03:1.Now we will briefly discuss the issue arisingdue to various encoding standards used for non-ASCII characters, e.g., of ?a, ?e, ?n, etc.
While apply-ing Freeling morphological analyzer to the dataset,we encountered an issue that the sentences camein various encodings.
As we mentioned in Sec-tion 3, Freeling-2.2 analyzer works properly onlywith ISO encoded input.
Therefore, we had toconvert each sentence from the dataset into ISOencoding.
While most of the sentences were inUTF-8 encoding and were converted in a singlepass, the encoding of about 3% of the sentenceswas initially corrupted, therefore, they were notprocessed correctly by the POS-tagger.
Althoughthe issue is manageable at the scale of a smalldataset, it might affect the speed and quality of factextraction when working at Web scale.5 Error AnalysisAfter running EXTRHECH on the datasets, we an-alyzied the errors in the output.
We followedthe classifications of the types of errors and theircauses suggested in (Zhila and Gelbukh, 2014).The distribution of the errors in EXTRHECH?s out-put over the types of errors is shown in Table 3.The data about error types was gathered over ex-tractions from Raw Web dataset.
When errors arepresent both in the arguments and in the relationphrase, they are likely to have the same cause.Based on the analysis of the outputs over RawWeb dataset, the following causes for errors havebeen observed:?
Underspecified noun phrase?
Overspecified verb phrase?
Non-contiguous verb phraseType of errors PercentageIncorrect relation phrase 21%Incorrect argument(s) 45%of them, with also incorrect relation 19%Incorrect argument order 6%Table 3: Distribution of errors in output bythe basic error types in relation extraction forEXTRHECH system run over Raw Web dataset?
N-ary relation or preposition (e.g., entre, ?be-tween?)?
Conditional subordinate clause?
Incorrectly resolved relative clause?
Incorrectly resolved conjunction?
Inverse word order?
Incorrect POS-tagging?
Grammatical errors in original sentencesInverse word order is one of the main causes forthe incorrect order of arguments in extracted rela-tions.
However, as it can be seen in Table 3, thisis the least common type of errors, which is in ac-cordance to the low frecuency of the inverse wordorder (Clements, 2006).
A more detailed analysisof the issues that cause the errors can be found in(Zhila and Gelbukh, 2014).6 ConclusionsWe have introduced an approach to Open IE basedon syntactic constraints over POS tag sequencestargeted at Spanish language.
We described therules for relation phrases and their arguments inSpanish and their implementation in EXTRHECHsystem.
Further, we presented a series of ex-periments with EXTRHECH and showed (1) thatthe performance of this approach to Open IEis similar for English and Spanish, and (2) thatEXTRHECH?s performance is robust on texts ofvarying quality.
We also gave a brief classificationof errors by their types and causes.Our future plans include implementation ofshallow parsing and syntactic n-grams (Sidorovet al., 2012; Sidorov et al., 2013; Sidorov et al.,2014; Sidorov, 2013a; Sidorov, 2013b), as well aslearning techniques, and analysis of their influenceon the system?s performance.AcknowledgmentsThe work was partially supported by the Gov-ernment of Mexico: SIP-IPN 20144534 and20144274, PIFI-IPN, and SNI.
We thank Yahoo!for travel and conference support for this paper.83ReferencesHonorato Aguilar-Galicia.
2012.
Extracci?on au-tom?atica de informaci?on sem?antica basada en estruc-turas sint?acticas.
Master?s thesis, Center for Com-puting Research, Instituto Polit?ecnico Nacional,Mexico City, D.F., Mexico.Michele Banko and Oren Etzioni.
2008.
The tradeoffsbetween open and traditional relation extraction.
InProceedings of ACL-08: HLT, pages 28?36.
Associ-ation for Computational Linguistics, June.Michele Banko, Michael J. Cafarella, Stephen Soder-land, Matt Broadhead, and Oren Etzioni.
2007.Open information extraction from the web.
In IJ-CAI, pages 2670?2676.Chris Callison-Burch, Philipp Koehn, Christof Monz,and Omar Zaidan.
2011.
Findings of the 2011workshop on statistical machine translation.
In Pro-ceedings of the Sixth Workshop on Statistical Ma-chine Translation, pages 22?64, Edinburgh, Scot-land, July.
Association for Computational Linguis-tics.Joseph Clancy Clements.
2006.
Primary and sec-ondary object marking in Spanish.
In J. ClancyClements and Jiyoung Yoon, editors, Functional ap-proaches to Spanish syntax: Lexical semantics, dis-course, and trasitivity, pages 115?133.
London: Pal-grave MacMillan.Oren Etzioni, Michele Banko, Stephen Soderland, andDaniel S. Weld.
2008.
Open information extractionfrom the web.
Commun.
ACM, 51(12):68?74, De-cember.Oren Etzioni.
2011.
Search Needs a Shake-Up.
Na-ture, 476(7358):25?26, August.Anthony Fader, Stephen Soderland, and Oren Etzioni.2011.
Identifying relations for open information ex-traction.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,EMNLP ?11, pages 1535?1545, Stroudsburg, PA,USA.
Association for Computational Linguistics.Pablo Gamallo, Marcos Garcia, and SantiagoFern?andez-Lanza.
2012.
Dependency-basedopen information extraction.
In Proceedings ofthe Joint Workshop on Unsupervised and Semi-Supervised Learning in NLP, ROBUS-UNSUP ?12,pages 10?18, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Christopher Horn, Alisa Zhila, Alexander Gelbukh,Roman Kern, and Elisabeth Lex.
2013.
Using fac-tual density to measure informativeness of web doc-uments.
In Proceedings of the 19th Nordic Confer-ence on Computational Linguistics, NoDaLiDa.Marshall Kirkpatrick.
2011.
New 5 billionpage web index with page rank now avail-able for free from common crawl foundation.http://readwrite.com/2011/11/07/common_crawl_foundation_announces_5_billion_page_w, November.
[last visited on25/01/2013].Geoffrey Leech and Andrew Wilson.
1999.
Standardsfor tagsets.
In Syntactic Wordclass Tagging, pages55?80.
Springer Netherlands.Thomas Lin, Mausam, and Oren Etzioni.
2010.
Iden-tifying functional relations in web text.
In Proceed-ings of the 2010 Conference on Empirical Methodsin Natural Language Processing, pages 1266?1276.Association for Computational Linguistics, October.Mausam, Michael Schmitz, Stephen Soderland, RobertBart, and Oren Etzioni.
2012.
Open language learn-ing for information extraction.
In EMNLP-CoNLL,pages 523?534.
ACL.Llu?
?s Padr?o, Samuel Reese, Eneko Agirre, and AitorSoroa.
2010.
Semantic services in freeling 2.1:Wordnet and ukb.
In Pushpak Bhattacharyya, Chris-tiane Fellbaum, and Piek Vossen, editors, Princi-ples, Construction, and Application of MultilingualWordnets, pages 99?105, Mumbai, India, February.Global Wordnet Conference 2010, Narosa Publish-ing House.Grigori Sidorov, Francisco Velasquez, Efstathios Sta-matatos, Alexander Gelbukh, and Liliana Chanona-Hern?andez.
2012.
Syntactic dependency-based n-grams as classification features.
In M. Gonz?alez-Mendoza and I. Batyrshin, editors, Advances inComputational Intelligence.
Proceedings of MICAI2012, volume 7630 of Lecture Notes in Artificial In-telligence, pages 1?11.
Springer.Grigori Sidorov, Francisco Velasquez, Efstathios Sta-matatos, Alexander Gelbukh, and Liliana Chanona-Hern?andez.
2013.
Syntactic dependency-based n-grams: More evidence of usefulness in classifica-tion.
In Alexander Gelbukh, editor, ComputationalLinguistics and Intelligent Text Processing.
Proceed-ings of International Conference on Intelligent TextProcessing and Computational Linguistics, CICLing2013, volume 7816 of Lecture Notes in Artificial In-telligence, pages 13?24.
Springer.Grigori Sidorov, Francisco Velasquez, Efstathios Sta-matatos, Alexander Gelbukh, and Liliana Chanona-Hern?andez.
2014.
Syntactic n-grams as machinelearning features for natural language processing.Expert Systems with Applications, 41(3):853?860.Grigori Sidorov.
2013a.
Non-continuous syntactic n-grams.
Polibits, 48:67?75.Grigori Sidorov.
2013b.
Syntactic dependency basedn-grams in rule based automatic english as secondlanguage grammar correction.
International Jour-nal of Computational Linguistics and Applications,4(2):169?188.Stephen Soderland, Brendan Roof, Bo Qin, Shi Xu,Mausam, and Oren Etzioni.
2010.
Adapting openinformation extraction to domain-specific relations.AI Magazine, 31(3):93?102.84Fei Wu and Daniel S. Weld.
2010.
Open informationextraction using wikipedia.
In Proceedings of the48th Annual Meeting of the Association for Com-putational Linguistics, ACL ?10, pages 118?127,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Alisa Zhila and Alexander Gelbukh.
2014.
Automaticidentification of facts in real internet texts in Spanishusing lightweight syntactic constraints: Problems,their causes, and ways for improvement.
Submitted.85
