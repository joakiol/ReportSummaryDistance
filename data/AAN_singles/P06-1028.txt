Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 217?224,Sydney, July 2006. c?2006 Association for Computational LinguisticsTraining Conditional Random Fields with Multivariate EvaluationMeasuresJun Suzuki, Erik McDermott and Hideki IsozakiNTT Communication Science Laboratories, NTT Corp.2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237 Japan{jun, mcd, isozaki}@cslab.kecl.ntt.co.jpAbstractThis paper proposes a framework for train-ing Conditional Random Fields (CRFs)to optimize multivariate evaluation mea-sures, including non-linear measures suchas F-score.
Our proposed framework isderived from an error minimization ap-proach that provides a simple solution fordirectly optimizing any evaluation mea-sure.
Specifically focusing on sequentialsegmentation tasks, i.e.
text chunking andnamed entity recognition, we introduce aloss function that closely reflects the tar-get evaluation measure for these tasks,namely, segmentation F-score.
Our ex-periments show that our method performsbetter than standard CRF training.1 IntroductionConditional random fields (CRFs) are a recentlyintroduced formalism (Lafferty et al, 2001) forrepresenting a conditional model p(y|x), whereboth a set of inputs, x, and a set of outputs,y, display non-trivial interdependency.
CRFs arebasically defined as a discriminative model ofMarkov random fields conditioned on inputs (ob-servations) x.
Unlike generative models, CRFsmodel only the output y?s distribution over x. Thisallows CRFs to use flexible features such as com-plicated functions of multiple observations.
Themodeling power of CRFs has been of great ben-efit in several applications, such as shallow pars-ing (Sha and Pereira, 2003) and information ex-traction (McCallum and Li, 2003).Since the introduction of CRFs, intensive re-search has been undertaken to boost their effec-tiveness.
The first approach to estimating CRF pa-rameters is the maximum likelihood (ML) criterionover conditional probability p(y|x) itself (Laf-ferty et al, 2001).
The ML criterion, however,is prone to over-fitting the training data, espe-cially since CRFs are often trained with a verylarge number of correlated features.
The maximuma posteriori (MAP) criterion over parameters, ?,given x and y is the natural choice for reducingover-fitting (Sha and Pereira, 2003).
Moreover,the Bayes approach, which optimizes both MAPand the prior distribution of the parameters, hasalso been proposed (Qi et al, 2005).
Furthermore,large margin criteria have been employed to op-timize the model parameters (Taskar et al, 2004;Tsochantaridis et al, 2005).These training criteria have yielded excellent re-sults for various tasks.
However, real world tasksare evaluated by task-specific evaluation mea-sures, including non-linear measures such as F-score, while all of the above criteria achieve op-timization based on the linear combination of av-erage accuracies, or error rates, rather than a giventask-specific evaluation measure.
For example, se-quential segmentation tasks (SSTs), such as textchunking and named entity recognition, are gener-ally evaluated with the segmentation F-score.
Thisinconsistency between the objective function dur-ing training and the task evaluation measure mightproduce a suboptimal result.In fact, to overcome this inconsistency, anSVM-based multivariate optimization method hasrecently been proposed (Joachims, 2005).
More-over, an F-score optimization method for logis-tic regression has also been proposed (Jansche,2005).
In the same spirit as the above studies, wefirst propose a generalization framework for CRFtraining that allows us to optimize directly notonly the error rate, but also any evaluation mea-sure.
In other words, our framework can incor-porate any evaluation measure of interest into theloss function and then optimize this loss functionas the training objective function.
Our proposedframework is fundamentally derived from an ap-proach to (smoothed) error rate minimization well217known in the speech and pattern recognition com-munity, namely the Minimum Classification Er-ror (MCE) framework (Juang and Katagiri, 1992).The framework of MCE criterion training supportsthe theoretical background of our method.
The ap-proach proposed here subsumes the conventionalML/MAP criteria training of CRFs, as describedin the following.After describing the new framework, as an ex-ample of optimizing multivariate evaluation mea-sures, we focus on SSTs and introduce a segmen-tation F-score loss function for CRFs.2 CRFs and Training CriteriaGiven an input (observation) x?X and parametervector ?
= {?1, .
.
.
, ?M}, CRFs define the con-ditional probability p(y|x) of a particular outputy ?
Y as being proportional to a product of po-tential functions on the cliques of a graph, whichrepresents the interdependency of y and x. Thatis:p(y|x; ?)
= 1Z?
(x)?c?C(y,x)?c(y,x; ?
)where ?c(y,x; ?)
is a non-negative real value po-tential function on a clique c ?
C(y,x).
Z?(x)=?y?
?Y?c?C(y?,x) ?c(y?,x; ?)
is a normalizationfactor over all output values, Y .Following the definitions of (Sha and Pereira,2003), a log-linear combination of weighted fea-tures, ?c(y,x; ?)
= exp(?
?
f c(y,x)), is usedas individual potential functions, where f c rep-resents a feature vector obtained from the corre-sponding clique c. That is, ?c?C(y,x) ?c(y,x) =exp(?
?F (y,x)), where F (y,x)=?c f c(y,x) isthe CRF?s global feature vector for x and y.The most probable output y?
is given by y?
=arg maxy?Y p(y|x; ?).
However Z?
(x) never af-fects the decision of y?
since Z?
(x) does not de-pend on y.
Thus, we can obtain the following dis-criminant function for CRFs:y?
= arg maxy?Y?
?
F (y,x).
(1)The maximum (log-)likelihood (ML) of theconditional probability p(y|x; ?)
of trainingdata {(xk,y?k)}Nk=1 w.r.t.
parameters ?
isthe most basic CRF training criterion, that is,arg max?
?k log p(y?k|xk; ?
), where y?k is thecorrect output for the given xk.
Maximizingthe conditional log-likelihood given by CRFs isequivalent to minimizing the log-loss function,?k?
log p(y?k|xk; ?).
We minimize the follow-ing loss function for the ML criterion training ofCRFs:LML?
=?k[??
?
F (y?k,xk) + logZ?
(xk)].To reduce over-fitting, the Maximum aPosteriori (MAP) criterion of parameters?, that is, arg max?
?k log p(?|y?k,xk) ?
?k log p(y?k|xk; ?)p(?
), is now the most widelyused CRF training criterion.
Therefore, weminimize the following loss function for the MAPcriterion training of CRFs:LMAP?
= LML?
?
log p(?).
(2)There are several possible choices when selectinga prior distribution p(?).
This paper only con-siders L?-norm prior, p(?)?
exp(?||?||?/?C),which becomes a Gaussian prior when ?=2.
Theessential difference between ML and MAP is sim-ply that MAP has this prior term in the objectivefunction.
This paper sometimes refers to the MLand MAP criterion training of CRFs as ML/MAP.In order to estimate the parameters ?, we seek azero of the gradient over the parameters ?:?LMAP?
= ??
log p(?)
+?k[?F (y?k,xk)+?y?Ykexp(?
?F (y,xk))Z?
(xk)?F (y,xk)].
(3)The gradient of ML is Eq.
3 without the gradientterm of the prior, ??
log p(?
).The details of actual optimization proceduresfor linear chain CRFs, which are typical CRF ap-plications, have already been reported (Sha andPereira, 2003).3 MCE Criterion Training for CRFsThe Minimum Classification Error (MCE) frame-work first arose out of a broader family of ap-proaches to pattern classifier design known asGeneralized Probabilistic Descent (GPD) (Kata-giri et al, 1991).
The MCE criterion minimizesan empirical loss corresponding to a smooth ap-proximation of the classification error.
This MCEloss is itself defined in terms of a misclassifica-tion measure derived from the discriminant func-tions of a given task.
Via the smoothing parame-ters, the MCE loss function can be made arbitrarilyclose to the binary classification error.
An impor-tant property of this framework is that it makes it218possible in principle to achieve the optimal Bayeserror even under incorrect modeling assumptions.It is easy to extend the MCE framework to useevaluation measures other than the classificationerror, namely the linear combination of error rates.Thus, it is possible to optimize directly a variety of(smoothed) evaluation measures.
This is the ap-proach proposed in this article.We first introduce a framework for MCE crite-rion training, focusing only on error rate optimiza-tion.
Sec.
4 then describes an example of mini-mizing a different multivariate evaluation measureusing MCE criterion training.3.1 Brief Overview of MCELet x ?
X be an input, and y ?
Y be an output.The Bayes decision rule decides the most probableoutput y?
for x, by using the maximum a posterioriprobability, y?
= arg maxy?Y p(y|x; ?).
In gen-eral, p(y|x; ?)
can be replaced by a more generaldiscriminant function, that is,y?
= arg maxy?Yg(y,x,?).
(4)Using the discriminant functions for the possi-ble output of the task, the misclassification mea-sure d() is defined as follows:d(y?,x,?)=?g(y?,x,?)
+ maxy?Y\y?g(y,x,?).
(5)where y?
is the correct output for x.
Here it canbe noted that, for a given x, d()?0 indicates mis-classification.
By using d(), the minimization ofthe error rate can be rewritten as the minimizationof the sum of 0-1 (step) losses of the given trainingdata.
That is, arg min?
L?
whereL?=?k?(d(y?k,xk,?)).
(6)?
(r) is a step function returning 0 if r<0 and 1 oth-erwise.
That is, ?
is 0 if the value of the discrimi-nant function of the correct output g(y?k,xk,?)
isgreater than that of the maximum incorrect outputg(yk,xk,?
), and ?
is 1 otherwise.Eq.
5 is not an appropriate function for op-timization since it is a discontinuous functionw.r.t.
the parameters ?.
One choice of contin-uous misclassification measure consists of sub-stituting ?max?
with ?soft-max?, maxk rk ?log ?k exp(rk).
As a resultd(y?,x,?
)=?g?+log[A?y?Y\y?exp(?g)]1?, (7)where g?
= g(y?,x,?
), g= g(y,x,?
), and A=1|Y|?1 .
?
is a positive constant that represents L?-norm.
When ?
approaches ?, Eq.
7 converges toEq.
5.
Note that we can design any misclassifi-cation measure, including non-linear measures ford().
Some examples are shown in the Appendices.Of even greater concern is the fact that the stepfunction ?
is discontinuous; minimization of Eq.6 is therefore NP-complete.
In the MCE formal-ism, ?
() is replaced with an approximated 0-1 lossfunction, l(), which we refer to as a smoothingfunction.
A typical choice for l() is the sigmoidfunction, lsig(), which is differentiable and pro-vides a good approximation of the 0-1 loss whenthe hyper-parameter ?
is large (see Eq.
8).
An-other choice is the (regularized) logistic function,llog(), that gives the upper bound of the 0-1 loss.Logistic loss is used as a conventional CRF lossfunction and provides convexity while the sigmoidfunction does not.
These two smoothing functionscan be written as follows:lsig = (1 + exp(??
?
d(y?,x,?)
?
?
))?1llog = ?
?1 ?
log(1 + exp(?
?
d(y?,x,?)
+ ?
)), (8)where ?
and ?
are the hyper-parameters of thetraining.We can introduce a regularization term to re-duce over-fitting, which is derived using the samesense as in MAP, Eq.
2.
Finally, the objective func-tion of the MCE criterion with the regularizationterm can be rewritten in the following form:LMCE?
= Fl,d,g,?
[{(xk,y?k)}Nk=1]+ ||?||?
?C .
(9)Then, the objective function of the MCE criterionthat minimizes the error rate is Eq.
9 andFMCEl,d,g,?
=1NN?k=1l(d(y?k,xk,?))
(10)is substituted for Fl,d,g,?.
Since N is constant, wecan eliminate the term 1/N in actual use.3.2 FormalizationWe simply substitute the discriminant function ofthe CRFs into that of the MCE criterion:g(y,x,?)
= log p(y|x; ?)
?
?
?
F (y,x) (11)Basically, CRF training with the MCE criterionoptimizes Eq.
9 with Eq.
11 after the selection ofan appropriate misclassification measure, d(), and219smoothing function, l().
Although there is no re-striction on the choice of d() and l(), in this workwe select sigmoid or logistic functions for l() andEq.
7 for d().The gradient of the loss function Eq.
9 can bedecomposed by the following chain rule:?LMCE?
=?F()?l() ?
?l()?d() ??d()??
+||?||?
?1C .The derivatives of l() w.r.t.
d() given in Eq.8 are written as: ?lsig/?d = ?
?
lsig ?
(1?
lsig) and?llog/?d= lsig.The derivative of d() of Eq.
7 w.r.t.
parameters?
is written in this form:?d()??
= ?Z?
(x, ?)Z?
(x, ?)?exp(?g?
)?F (y?,x)+?y?Y[exp(?g)Z?
(x, ?)?exp(?g?
)?F (y,x)] (12)where g = ?
?F (y,x), g?
= ?
?F (y?,x), andZ?
(x, ?
)=?y?Y exp(?g).Note that we can obtain exactly the same lossfunction as ML/MAP with appropriate choices ofF(), l() and d().
The details are provided in theAppendices.
Therefore, ML/MAP can be seen asone special case of the framework proposed here.In other words, our method provides a generalizedframework of CRF training.3.3 Optimization ProcedureWith linear chain CRFs, we can calculate the ob-jective function, Eq.
9 combined with Eq.
10,and the gradient, Eq.
12, by using the variant ofthe forward-backward and Viterbi algorithm de-scribed in (Sha and Pereira, 2003).
Moreover, forthe parameter optimization process, we can simplyexploit gradient descent or quasi-Newton methodssuch as L-BFGS (Liu and Nocedal, 1989) as wellas ML/MAP optimization.If we select ?
= ?
for Eq.
7, we only needto evaluate the correct and the maximum incor-rect output.
As we know, the maximum outputcan be efficiently calculated with the Viterbi al-gorithm, which is the same as calculating Eq.
1.Therefore, we can find the maximum incorrectoutput by using the A* algorithm (Hart et al,1968), if the maximum output is the correct out-put, and by using the Viterbi algorithm otherwise.It may be feared that since the objective func-tion is not differentiable everywhere for ?=?,problems for optimization would occur.
How-ever, it has been shown (Le Roux and McDer-mott, 2005) that even simple gradient-based (first-order) optimization methods such as GPD and (ap-proximated) second-order methods such as Quick-Prop (Fahlman, 1988) and BFGS-based methodshave yielded good experimental optimization re-sults.4 Multivariate Evaluation MeasuresThus far, we have discussed the error rate ver-sion of MCE.
Unlike ML/MAP, the framework ofMCE criterion training allows the embedding ofnot only a linear combination of error rates, butalso any evaluation measure, including non-linearmeasures.Several non-linear objective functions, such asF-score for text classification (Gao et al, 2003),and BLEU-score and some other evaluation mea-sures for statistical machine translation (Och,2003), have been introduced with reference to theframework of MCE criterion training.4.1 Sequential Segmentation Tasks (SSTs)Hereafter, we focus solely on CRFs in sequences,namely the linear chain CRF.
We assume that xand y have the same length: x=(x1, .
.
.
, xn) andy=(y1, .
.
.
, yn).
In a linear chain CRF, yi dependsonly on yi?1.Sequential segmentation tasks (SSTs), such astext chunking (Chunking) and named entity recog-nition (NER), which constitute the shared tasksof the Conference of Natural Language Learn-ing (CoNLL) 2000, 2002 and 2003, are typicalCRF applications.
These tasks require the extrac-tion of pre-defined segments, referred to as tar-get segments, from given texts.
Fig.
1 shows typ-ical examples of SSTs.
These tasks are gener-ally treated as sequential labeling problems incor-porating the IOB tagging scheme (Ramshaw andMarcus, 1995).
The IOB tagging scheme, wherewe only consider the IOB2 scheme, is also shownin Fig.
1.
B-X, I-X and O indicate that the wordin question is the beginning of the tag ?X?, insidethe tag ?X?, and outside any target segment, re-spectively.
Therefore, a segment is defined as asequence of a few outputs.4.2 Segmentation F-score Loss for SSTsThe standard evaluation measure of SSTs is thesegmentation F-score (Sang and Buchholz, 2000):F?
=(?2 + 1) ?
TP?2 ?
FN + FP + (?2 + 1) ?
TP (13)220He   reckons   the  current  account  deficit   will   narrow   to    only   #   1.8   billion  .NP VP NP VP PP NPB-NP B-VP B-NP I-NP I-NP I-NP B-VP I-VP B-PP B-NP I-NP I-NP I-NP Ox:y:Seg.
:United  Nation   official   Ekeus Smith   heads   for   Baghdad  .B-ORG I-ORG O OOB-PER I-PER B-LOC Ox:y:Seg.
: ORG PER LOCText Chunking Named Entity Recognitiony1 y2 y3 y4 y5 y6 y7 y8 y9 y10 y11 y12 y13 y14Dep.
: y1 y2 y3 y4 y5 y6 y7 y8 y9Dep.
:Figure 1: Examples of sequential segmentation tasks (SSTs): text chunking (Chunking) and named entityrecognition (NER).where TP , FP and FN represent true positive,false positive and false negative counts, respec-tively.The individual evaluation units used to calcu-late TP , FN and PN , are not individual outputsyi or output sequences y, but rather segments.
Weneed to define a segment-wise loss, in contrast tothe standard CRF loss, which is sometimes re-ferred to as an (entire) sequential loss (Kakadeet al, 2002; Altun et al, 2003).
First, we con-sider the point-wise decision w.r.t.
Eq.
1, that is,y?i = arg maxyi?Y1 g(y,x, i,?).
The point-wisediscriminant function can be written as follows:g(y,x, i,?)
= maxy??Y|y|[yi]?
?
F (y?,x) (14)where Yj represents a set of all y whose lengthis j, and Y[yi] represents a set of all y that con-tain yi in the i?th position.
Note that the sameoutput y?
can be obtained with Eqs.
1 and 14,that is, y?
= (y?1, .
.
.
, y?n).
This point-wise dis-criminant function is different from that describedin (Kakade et al, 2002; Altun et al, 2003), whichis calculated based on marginals.Let ysj be an output sequence correspond-ing to the j-th segment of y, where sj repre-sents a sequence of indices of y, that is, sj =(sj,1, .
.
.
, sj,|sj |).
An example of the Chunk-ing data shown in Fig.
1, ys4 is (B-VP, I-VP)where s4 = (7, 8).
Let Y[ysj ] be a set of alloutputs whose positions from sj,1 to sj,|sj | areysj = (ysj,1 , .
.
.
, ysj,|sj |).
Then, we can define asegment-wise discriminant function w.r.t.
Eq.
1.That is,g(y,x, sj ,?)
= maxy?
?Y|y|[ysj ]?
?
F (y?,x).
(15)Note again that the same output y?
can be obtainedusing Eqs.
1 and 15, as with the piece-wise dis-criminant function described above.
This propertyis needed for evaluating segments since we do notknow the correct segments of the test data; we canmaintain consistency even if we use Eq.
1 for test-ing and Eq.
15 for training.
Moreover, Eq.
15 ob-viously reduces to Eq.
14 if the length of all seg-ments is 1.
Then, the segment-wise misclassifica-tion measure d(y?,x, sj ,?)
can be obtained sim-ply by replacing the discriminant function of theentire sequence g(y,x,?)
with that of segment-wise g(y,x, sj ,?)
in Eq.
7.Let s?k be a segment sequence corresponding tothe correct output y?k for a given xk, and S(xk)be all possible segments for a given xk.
Then, ap-proximated evaluation functions of TP , FP andFN can be defined as follows:TPl =?k?s?j?s?k[1?l(d(y?k,xk, s?j ,?))]??
(s?j )FPl =?k?s?j?S(xk)\s?kl(d(y?k,xk, s?j ,?))??
(s?j)FNl =?k?s?j?s?kl(d(y?k,xk, s?j ,?))??
(s?j )where ?
(sj) returns 1 if segment sj is a target seg-ment, and returns 0 otherwise.
For the NER datashown in Fig.
1, ?ORG?, ?PER?
and ?LOC?
are thetarget segments, while segments that are labeled?O?
in y are not.
Since TPl should not have avalue of less than zero, we select sigmoid loss asthe smoothing function l().The second summation of TPl and FNl per-forms a summation over correct segments s?.
Incontrast, the second summation in FPl takes allpossible segments into account, but excludes thecorrect segments s?.
Although an efficient way toevaluate all possible segments has been proposedin the context of semi-Markov CRFs (Sarawagiand Cohen, 2004), we introduce a simple alter-native method.
If we select ?
= ?
for d() inEq.
7, we only need to evaluate the segments cor-responding to the maximum incorrect output y?
tocalculate FPl.
That is, s?j ?
S(xk)\s?k can bereduced to s?j ?
s?k, where s?k represents segmentscorresponding to the maximum incorrect output y?.In practice, this reduces the calculation cost and sowe used this method for our experiments describedin the next section.Maximizing the segmentation F?-score, Eq.
13,221is equivalent to minimizing ?2?FN+FP(?2+1)?TP , since Eq.13 can also be written as F?
= 11+ ?2?FN+FP(?2+1)?TP.
Thus,an objective function closely reflecting the seg-mentation F?-score based on the MCE criterioncan be written as Eq.
9 while replacing Fl,d,g,?with:FMCE-Fl,d,g,?
=?2 ?
FNl + FPl(?2 + 1) ?
TPl.
(16)The derivative of Eq.
16 w.r.t.
l() is given by thefollowing equation:?FMCE-Fl,d,g,?
?l() ={?2ZD+ (?2+1)?ZNZ2D, if ?
(s?j ) = 11ZD, otherwisewhereZN andZD represent the numerator and de-nominator of Eq.
16, respectively.In the optimization process of the segmentationF-score objective function, we can efficiently cal-culate Eq.
15 by using the forward and backwardViterbi algorithm, which is almost the same ascalculating Eq.
3 with a variant of the forward-backward algorithm (Sha and Pereira, 2003).
Thesame numerical optimization methods describedin Sec.
3.3 can be employed for this optimization.5 ExperimentsWe used the same Chunking and ?English?
NERtask data used for the shared tasks of CoNLL-2000 (Sang and Buchholz, 2000) and CoNLL-2003 (Sang and De Meulder, 2003), respectively.Chunking data was obtained from the WallStreet Journal (WSJ) corpus: sections 15-18 astraining data (8,936 sentences and 211,727 to-kens), and section 20 as test data (2,012 sentencesand 47,377 tokens), with 11 different chunk-tags,such as NP and VP plus the ?O?
tag, which repre-sents the outside of any target chunk (segment).The English NER data was taken from theReuters Corpus21.
The data consists of 203,621,51,362 and 46,435 tokens from 14,987, 3,466and 3,684 sentences in training, development andtest data, respectively, with four named entitytags, PERSON, LOCATION, ORGANIZATIONand MISC, plus the ?O?
tag.5.1 Comparison Methods and ParametersFor ML and MAP, we performed exactly the sametraining procedure described in (Sha and Pereira,2003) with L-BFGS optimization.
For MCE, we1http://trec.nist.gov/data/reuters/reuters.htmlonly considered d() with ?
= ?
as described inSec.
4.2, and used QuickProp optimization2.For MAP, MCE and MCE-F, we used the L2-norm regularization.
We selected a value of Cfrom 1.0?
10n where n takes a value from -5 to 5in intervals 1 by development data3.
The tuning ofsmoothing function hyper-parameters is not con-sidered in this paper; that is, ?=1 and ?=0 wereused for all the experiments.We evaluated the performance by Eq.
13 with?
= 1, which is the evaluation measure used inCoNLL-2000 and 2003.
Moreover, we evaluatedthe performance by using the average sentence ac-curacy, since the conventional ML/MAP objectivefunction reflects this sequential accuracy.5.2 FeaturesAs regards the basic feature set for Chunking, wefollowed (Kudo and Matsumoto, 2001), which isthe same feature set that provided the best resultin CoNLL-2000.
We expanded the basic featuresby using bigram combinations of the same typesof features, such as words and part-of-speech tags,within window size 5.In contrast to the above, we used the originalfeature set for NER.
We used features derived onlyfrom the data provided by CoNLL-2003 with theaddition of character-level regular expressions ofuppercases [A-Z], lowercases [a-z], digits [0-9] orothers, and prefixes and suffixes of one to four let-ters.
We also expanded the above basic features byusing bigram combinations within window size 5.Note that we never used features derived from ex-ternal information such as the Web, or a dictionary,which have been used in many previous studies butwhich are difficult to employ for validating the ex-periments.5.3 Results and DiscussionOur experiments were designed to investigate theimpact of eliminating the inconsistency betweenobjective functions and evaluation measures, thatis, to compare ML/MAP and MCE-F.Table 1 shows the results of Chunking and NER.The F?=1 and ?Sent?
columns show the perfor-mance evaluated using segmentation F-score and2In order to realize faster convergence, we applied onlineGPD optimization for the first ten iterations.3Chunking has no common development set.
We firsttrain the systems with all but the last 2000 sentences in thetraining data as a development set to obtain C, and then re-train them with all the training data.222Table 1: Performance of text chunking and namedentity recognition data (CoNLL-2000 and 2003)Chunking NERl() n F?=1 Sent n F?=1 SentMCE-F (sig) 5 93.96 60.44 4 84.72 78.72MCE (log) 3 93.92 60.19 3 84.30 78.02MCE (sig) 3 93.85 60.14 3 83.82 77.52MAP 0 93.71 59.15 0 83.79 77.39ML - 93.19 56.26 - 82.39 75.71sentence accuracy, respectively.
MCE-F refers tothe results obtained from optimizing Eq.
9 basedon Eq.
16.
In addition, we evaluated the errorrate version of MCE.
MCE(log) and MCE(sig)indicate that logistic and sigmoid functions areselected for l(), respectively, when optimizingEq.
9 based on Eq.
10.
Moreover, MCE(log) andMCE(sig) used d() based on ?=?, and were op-timized using QuickProp; these are the same con-ditions as used for MCE-F. We found that MCE-Fexhibited the best results for both Chunking andNER.
There is a significant difference (p<0.01)between MCE-F and ML/MAP with the McNemartest, in terms of the correctness of both individualoutputs, yki , and sentences, yk.NER data has 83.3% (170524/204567) and82.6% (38554/46666) of ?O?
tags in the trainingand test data, respectively while the correspond-ing values of the Chunking data are only 13.1%(27902/211727) and 13.0% (6180/47377).
In gen-eral, such an imbalanced data set is unsuitable foraccuracy-based evaluation.
This may be one rea-son why MCE-F improved the NER results muchmore than the Chunking results.The only difference between MCE(sig) andMCE-F is the objective function.
The correspond-ing results reveal the effectiveness of using an ob-jective function that is consistent as the evalua-tion measure for the target task.
These resultsshow that minimizing the error rate is not opti-mal for improving the segmentation F-score eval-uation measure.
Eliminating the inconsistency be-tween the task evaluation measure and the objec-tive function during the training can improve theoverall performance.5.3.1 Influence of Initial ParametersWhile ML/MAP and MCE(log) is convex w.r.t.the parameters, neither the objective function ofMCE-F, nor that of MCE(sig), is convex.
There-fore, initial parameters can affect the optimizationTable 2: Performance when initial parameters arederived from MAPChunking NERl() n F?=1 Sent n F?=1 SentMCE-F (sig) 5 94.03 60.74 4 85.29 79.26MCE (sig) 3 93.97 60.59 3 84.57 77.71results, since QuickProp as well as L-BFGS canonly find local optima.The previous experiments were only performedwith all parameters initialized at zero.
In this ex-periment, the parameters obtained by the MAP-trained model were used as the initial values ofMCE-F and MCE(sig).
This evaluation setting ap-pears to be similar to reranking, although we usedexactly the same model and feature set.Table 2 shows the results of Chunking and NERobtained with this parameter initialization setting.When we compare Tables 1 and 2, we find thatthe initialization with the MAP parameter valuesfurther improves performance.6 Related WorkVarious loss functions have been proposed for de-signing CRFs (Kakade et al, 2002; Altun et al,2003).
This work also takes the design of the lossfunctions for CRFs into consideration.
However,we proposed a general framework for designingthese loss function that included non-linear lossfunctions, which has not been considered in pre-vious work.With Chunking, (Kudo and Matsumoto, 2001)reported the best F-score of 93.91 with the vot-ing of several models trained by Support Vec-tor Machine in the same experimental settingsand with the same feature set.
MCE-F with theMAP parameter initialization achieved an F-scoreof 94.03, which surpasses the above result withoutmanual parameter tuning.With NER, we cannot make a direct compari-son with previous work in the same experimentalsettings because of the different feature set, as de-scribed in Sec.
5.2.
However, MCE-F showed thebetter performance of 85.29 compared with (Mc-Callum and Li, 2003) of 84.04, which used theMAP training of CRFs with a feature selection ar-chitecture, yielding similar results to the MAP re-sults described here.2237 ConclusionsWe proposed a framework for training CRFs basedon optimization criteria directly related to targetmultivariate evaluation measures.
We first pro-vided a general framework of CRF training basedon MCE criterion.
Then, specifically focusingon SSTs, we introduced an approximate segmen-tation F-score objective function.
Experimentalresults showed that eliminating the inconsistencybetween the task evaluation measure and the ob-jective function used during training improves theoverall performance in the target task without anychange in feature set or model.AppendicesMisclassification measuresAnother type of misclassification measure usingsoft-max is (Katagiri et al, 1991):d(y,x,?)
= ?g?
+[A?y?Y\y?g?
]1?.Another d(), for g in the range [0,?):d(y,x,?)
=[A?y?Y\y?
g?]
1?
/g?.Comparison of ML/MAP and MCEIf we select llog() with ?=1 and ?=0, and use Eq.7 with ?= 1 and without the term A for d().
Wecan obtain the same loss function as ML/MAP:log (1 + exp(?g?
+ log(Z?
?
exp(g?
))))= log(exp(g?)
+ (Z?
?
exp(g?))exp(g?
))= ?g?
+ log(Z?).ReferencesY.
Altun, M. Johnson, and T. Hofmann.
2003.
InvestigatingLoss Functions and Optimization Methods for Discrimi-native Learning of Label Sequences.
In Proc.
of EMNLP-2003, pages 145?152.S.
E. Fahlman.
1988.
An Empirical Study of LearningSpeech in Backpropagation Networks.
In Technical Re-port CMU-CS-88-162, Carnegie Mellon University.S.
Gao, W. Wu, C.-H. Lee, and T.-S. Chua.
2003.
A Maxi-mal Figure-of-Merit Approach to Text Categorization.
InProc.
of SIGIR?03, pages 174?181.P.
E. Hart, N. J. Nilsson, and B. Raphael.
1968.
A FormalBasis for the Heuristic Determination of Minimum CostPaths.
IEEE Trans.
on Systems Science and Cybernetics,SSC-4(2):100?107.M.
Jansche.
2005.
Maximum Expected F-Measure Trainingof Logistic Regression Models.
In Proc.
of HLT/EMNLP-2005, pages 692?699.T.
Joachims.
2005.
A Support Vector Method for Multivari-ate Performance Measures.
In Proc.
of ICML-2005, pages377?384.B.
H. Juang and S. Katagiri.
1992.
Discriminative Learningfor Minimum Error Classification.
IEEE Trans.
on SignalProcessing, 40(12):3043?3053.S.
Kakade, Y. W. Teh, and S. Roweis.
2002.
An Alterna-tive Objective Function for Markovian Fields.
In Proc.
ofICML-2002, pages 275?282.S.
Katagiri, C. H. Lee, and B.-H. Juang.
1991.
New Dis-criminative Training Algorithms based on the GeneralizedDescent Method.
In Proc.
of IEEE Workshop on NeuralNetworks for Signal Processing, pages 299?308.T.
Kudo and Y. Matsumoto.
2001.
Chunking with SupportVector Machines.
In Proc.
of NAACL-2001, pages 192?199.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
ConditionalRandom Fields: Probabilistic Models for Segmenting andLabeling Sequence Data.
In Proc.
of ICML-2001, pages282?289.D.
C. Liu and J. Nocedal.
1989.
On the Limited MemoryBFGS Method for Large-scale Optimization.
MathematicProgramming, (45):503?528.A.
McCallum and W. Li.
2003.
Early Results for NamedEntity Recognition with Conditional Random Fields Fea-ture Induction and Web-Enhanced Lexicons.
In Proc.
ofCoNLL-2003, pages 188?191.F.
J. Och.
2003.
Minimum Error Rate Training in StatisticalMachine Translation.
In Proc.
of ACL-2003, pages 160?167.Y.
Qi, M. Szummer, and T. P. Minka.
2005.
Bayesian Con-ditional Random Fields.
In Proc.
of AI & Statistics 2005.L.
A. Ramshaw and M. P. Marcus.
1995.
Text Chunkingusing Transformation-based Learning.
In Proc.
of VLC-1995, pages 88?94.J.
Le Roux and E. McDermott.
2005.
Optimization Methodsfor Discriminative Training.
In Proc.
of Eurospeech 2005,pages 3341?3344.E.
F. Tjong Kim Sang and S. Buchholz.
2000.
Introductionto the CoNLL-2000 Shared Task: Chunking.
In Proc.
ofCoNLL/LLL-2000, pages 127?132.E.
F. Tjong Kim Sang and F. De Meulder.
2003.
Introductionto the CoNLL-2003 Shared Task: Language-IndependentNamed Entity Recognition.
In Proc.
of CoNLL-2003,pages 142?147.S.
Sarawagi and W. W. Cohen.
2004.
Semi-Markov Condi-tional Random Fields for Information Extraction.
In Procof NIPS-2004.F.
Sha and F. Pereira.
2003.
Shallow Parsing with Con-ditional Random Fields.
In Proc.
of HLT/NAACL-2003,pages 213?220.B.
Taskar, C. Guestrin, and D. Koller.
2004.
Max-MarginMarkov Networks.
In Proc.
of NIPS-2004.I.
Tsochantaridis, T. Joachims and T. Hofmann, and Y. Altun.2005.
Large Margin Methods for Structured and Interde-pendent Output Variables.
JMLR, 6:1453?1484.224
