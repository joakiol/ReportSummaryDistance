A News Story Categorization SystemPhilip J. Hayes, Laura E. Knecht, and Monica J. CellioCarnegie Group Inc650 Commerce Court at Station SquarePittsburgh, PA 15219AbstractThis paper describes a pilot version of acommercial application of natural languageprocessing techniques to the problem of categorizingnews stories into broad topic categories.
The systemdoes not perform a complete semantic or syntacticanalyses of the input stories.
Its categorizations aredependent on fragmentary ecognition using pattern-matching techniques.
The fragments it looks for aredetermined by a set of knowledge-based rules.
Theaccuracy of the system is only slightly lower than thatof human categorizers.1.
IntroductionThe large economic potential of automatic textprocessing is leading to an increasing interest in itscommercial pplications.
This paper describes a pilotversion of a commercial application of naturallanguage processing techniques to the problem ofcategorizing news stories into broad topic categories.The conventional way to process natural languagetexts is to have people read them and perform someaction based on what they have read.
People, forinstance, currently categorize news stories for routingpurposes and extract information from bankingpayment telexes o that transactions can be executed.Unfortunately, using people tends to be:?
slow - people read text slowly;?
expens ive  - if the volume of text is high,processing it requires the efforts of manypeople;?
i ncons is tent  - it is very hard to get a group ofpeople to make consistent decisions about ext.In many cases, the proper processing of text is centralto a company's revenue stream, so that improvementsin the processing can provide major leverage andjustify major contract system expenditures.Automatic text processing offers the possibility ofsuch improvements in all three areas.
A single textprocessing machine can potentially do the job ofseveral people faster, cheaper, and more consistently.This paper describes an implementation of asystem to do text categorization.
The texts it operateson are news stories, but similar techniques could beemployed on electronic mail messages, telex traffic,technical abstracts, etc.. Once categorization hasbeen accomplished, the results can be used to routethe texts involved to interested parties or to facilitatelater etrieval of the texts from an archival database.The system described here uses the well-established natural language processing technique ofpattern-matching \[1,5\].
Since the input to the systemis an arbitrary news story on any topic whatsoever,no attempt is made to perform acomplete syntactic orsemantic analysis.
Instead, categorization is based onthe presence of particular words and phrases inparticular lexical contexts.
As the more detaileddescription i  Section 3 will make clear, however, theapproach used goes well beyond the keywordapproaches used in information retrieval (e.g.
\[6\]).
Inparticular, the words and phrases the system looks forand the context in which i t  looks for them arespecified through a modified version of the powerfulpattern matching language used in Carnegie Group'sLanguage Craft TM product I \[3\].
Moreover, thesystem determines which words and phrases to searchfor in a given story and how to interpret the presenceof these words and phrases according to knowledge-based rules.As simple as these techniques are by currentnatural anguage processing standards, the accuracyof the system is high.
As described in more detail inSection 4, the system had an average accuracy of1Language Craft also uses caseframe parsing techniques forcomplete linguistic analyses.93% 2 on a sample of 500 random stories that had notbeen previously processed by the system or seen byits developers.
Moreover, this accuracy was obtainedwithout sacrificing computational efficiency.
Theaverage processing time was 15 seconds per story 3ona Symbolics 3640, a figure which we believe couldbe considerably improved through a detailedperformance optimization which we have notperformed.The remaining sections of the paper describe inmore detail: the problem tackled by the system, theapproach used, and the results obtained.2.
The ProblemThe primary goal in developing the systemdescribed in this paper was to demonstrate thefeasibility of categorizing news stories by computerin small amounts of time (a few seconds) usingnatural language processing techniques.
The specifictask chosen to do this was emulation of theperformance of a group of human categorizers.
Ourraw material was a data base containing manythousands of news stories that had beenhand-categorized 4 for any of 72 categories.
Oursystem was required to assign 6 of the 72 categories:acquisitions/mergers, metals, shipping, bonds, war,and disorders.
A story could be assigned one or moreof these codes, or no code at all if none of the chosensix was appropriate.
The restriction to six codes wasimposed to keep the effort required to build thesystem within certain budgetary limits.
As Section 3will show, the approach taken is equally applicable tothe larger set of categories.Modelling the categorizations produced by humanbeings presented some difficulties.
To summarize:?
The text processing techniques used in thesystem were oriented to identifying conceptsexplicitly mentioned in a story.
They were not2More pmdsely, its average recall was 93% (i.e.
it made 93% ofthe topic assignments it should have made) and its averageprecision was also 93% (i.e.
93% of the topics it did assign werecorrect).~The average story length was 250 words; stories varied fromabout a 100 to about 3000 words.4The hand-categorizations were done by a group of people whohad no involvement with or knowledge of the system wedeveloped.well suited to identifying the class of peoplethat a story might be of interest to.
The humancategorizers of the stories in our data base usedboth these kinds of considerations when theyassigned topic codes to stories.e Some topic codes had relatively vague,subjective definitions.o The human categorizers were not alwaysconsistent in the way they made their topicassignments.The news stories themselves posed anotherchallenge.
Though the set of topics to be assigned bythe system was narrowed from 72 to 6, there was noparallel narrowing of the stream of stories that wouldserve as input to the system.
The full range of storytypes found in a newspaper occurred in the data baseof news stories.
As a consequence, our task was notthe relatively simple one of, for instance,distinguishing a story about war from one aboutbonds.
War stories also had to be distinguished frommilitary, disaster, crime, diplomacy, politics, andsports stories, to name just a few.It was often the case that we could characterize thekind of stories that might mislead the system.
Wewere prepared for sports stories that looked likemetals stories ("...captured the gold medal at thesummer Olympics...") or like war/disorders tories("...the battle on center court at Wimbledon...'3.
Amore difficult challenge was posed by words andphrases that were good predictors of a particular topicbut occurred randomly across all story types,sometimes with the same meaning, sometimes not.For instance, the noun note, in the sense of financialinstrument, was useful for finding stories aboutbonds; however, numerous, random stories used thatword in a different sense.
Metaphorical languagewas also a problem -- not use of fixed phrases (wehad no trouble failing to assign the category metalsto a story that contained the phrase like a leadballoon) -- but rather creative metaphorical language.So, a story about a series of battles in the continuingdisposable diaper war between Proctor and Gambleand its competitors was assigned to the disorderscategory.103.
Approach3.1.
OverviewThe system tackles story categorization i twodistinct phases:?
hypothesization: an attempt o pick out allcategories into which the story might fall onthe basis of the words and phrases it contains;if particular words and phrases uggest morethan one category, they will contribute to thehypothesization f each of these categories;?
conf'wmation: an attempt o find additionalevidence in support of a hypothesized topic orto determine whether or not the language thatled to the topic's being hypothesized was usedin a way that misled the system; it is this phase,for instance, that would detect that conflictvocabulary was being used in the context of asports story and disconf'trm the war anddisorders categories for that story.
This phasethus has an expert system flavor to it.Both phases use the same basic kind of processing: acontextually limited search for words and phrasesusing pattern-matching techniques.
They are alsoboth organized (conceptually) as a collection ofknowledge-based rules.
The phases differ only in thedirectedness with which the search is conducted.Hypothesization always looks for the same words andphrases.
Confirmation looks for different words andphrases using specific knowledge-based rulesassociated with each of the topics that have beenhypothesized.The search for words and phrases in both phases isorganized around patternsets.
A patternset representsa collection of words and phrases that are associatedwith a given concept, such as conflict.
The conceptsassociated with patternsets sometimes correspond tothe topics we are trying to categorize stories into, butthey may also be more specific or may span severaltopics.The basic operation on a patternset is to determinehow many of the words and phrases it representsappear in a story.
System actions are taken when thenumber of matches crosses a threshold, at whichpoint we say that the patternset has matched.
Thethresholds are empirically determined and differ frompatternset to patternset and even from use to use ofthe patternset.Hypothesization is typically performed on thebasis of matches of single patternsets.
Confirmationrules typically involve branching conditionsdepending on the results of multiple patternsetmatches.
Individual patternsets may be involved inboth hypothesization a d confirmation phases.The remainder of this section describes theoperation of the system in greater technical detail.3.2.
Patterns and PatternsetsPatternsets are collections of patterns.
A pattern isan expression in a pattern-matching language thatcorresponds to one or more words and phrases thatmight appear in a story.
A pattern is said to matchthe story if any of the words or phrases that itspecifies appear in the story.
Each pattern has aweight, either probable or possible, with matches ofprobables counting more than matches of possibles,according to a scheme xplained below.
Patterns alsohave names.The following pattern, called "titanium", willmatch the word titanium and assign the match aweight of "probable".
(titanium) -> probable= titaniumEight operators are available to allow individualpatterns to specify several words and phrases.
Theyare:?
?
: specifies an optional subpattern;?
!
and,,!!
:,, specify alternatives (i.e.
they bothmean or ) ;~?
~ and &not: specify a subpattern that shouldnot be matched; ~?
&skip: specifies the maximum number ofwords to skip over,?
+N: specifies that a word is a noun and cantherefore be pluralized;?
+V: specifies that a word is a verb and cantherefore occur with the full range of verbalinflections.The following examples illustrate how theseoperators are used.5The operator !!
is more efficient than !, but there are somesituations where it cannot be used.~hc  operator &not filters out a subpaRcrn to the left of thesubpattem to be matched; ~Fdters out a subpattem to the right.11?
(par (pricing !!
?issue price))-> probable= parprice\[This rule matches the phrases par pricing, parissue price, and par price.\]?
((&not ratings) war +N) -> possible= war\[This rule matches war or wars preceded byanything except he word ratings.\]?
(sell +V (&skip 6 (company !!
business i!unit))) -> possible= sell-co\[This rule matches any form of the verb sellfollowed by company, business, or unit, with asmany as 6 words intervening.\]The pattern operator &skip deserves specialcomment.
It allows us to find key expressions evenwhen it is impossible to predict exactly whatextraneous words they will contain.
Consider, forexample, the phrases ell the business and sell theunit; these phrases must be matched if the system isto detect stories about acquisitions.
The problem isthat expressions like sell the business are rare.Examples of the sorts of phrases that we actually findin acquisitions stories are given below:sell the Seven-Up businesssell the ailing Seven-Up unitsell its Seven-Up soft drink businesssell 51 pct of the common stock of its unitsell the worldwide franchise beverage businesssell about 5 mln dlrs worth of shares in the companyWith &skip, we can look for the verb sell followedby company, unit, or business without havingspecify what the intervening words might be.In addition to pattern operators, a set of wildeardsis also available to rule-writers for matching wordsthat cannot be specified in advance.
$ is the generalwildcard: it matches any single word or othersymbol.
$d matches any determiner (a, the, this,etc.
); Sn matches any number; $q matches anyquantifier (much, many, some, etc.
); and $p matchesany punctuation mark.3.3.
Hypothesizat ion and Conf i rmat ionAfter a story has been read in, the system beginsthe process of topic determination by applying itshypothesization rules.
A hypothesization rule tellsthe system to hypothesize one or more specifiedtopics if a given pattemset matches the story with astrength greater than a given threshold.For example, one of the system's hypothesizationrules specifies that the topics war and d isordersshould be hypothesized if the score for matches in the"conflict" patternset is 4 or greater; another rulespecifies that the metals topic be hypothesized if the"metals" patternset matches with a score greater than2.
The thresholds for each rule are determinedempirically based on the rule developer's observationof the performance of the system when differentthresholds are used.
Note also that there is notnecessarily a direct correlation between topics andpatternsets; ome patternsets could provide evidencefor more than one topic, and some topics could makeuse of more than one patternset.The scores for patternset matches are calculatedaccording to the formula:(2 x probables) + possib lesi.e.
a match with a "probable" pattern has a weight of2 while a match with a "possible" pattern has aweight of 1.
In the course of establishing thisweighting system, we experimented with severalmore complex and finely-grained schemes, but foundthat they provided no significant advantage inpractice.After the hypothesization phase comesconfirmation.
This involves more detailed topic-specific processing to determine whether or not thevocabulary used in hypothesizing the topic was usedin a misleading way.
The confirmation phase usestopic-specific knowledge-based rules which may tryto match additional patterns or pattemsets.The most complex confirmation rules in the systemare those for the war and disorders topics.
Thesetopics were difficult to tell apart, so considerableadditional processing was involved.
The rules useadditional specialized patternsets: one patternsetlooked specifically for words (including propernames) that occur in war but not disorders tories andanother looked for vocabulary that occurs in storiesthat are both war and disorders tories.
There arealso patternsets for sports, crime, and disastervocabulary.
The confirmation rules associated withwar and disorders attempt o match these rulesaccording to a branching set of conditions.Consider the following story, for example.
The12words and phrases in boldface match patterns in the"conflict" patternset; he total value of matches isgreat enough to get the story hypothesized as warand disorders.
In the confirmation phase, additionalpatternsets are run against he story.
As soon as Iranand lraq are matched, the topic war is confirmed andthe topic disorders is disconfirmed.\[RAN ANNOUNCES END OF MAJOROFFENSIVE IN GULF WARLONDON, Feb 26 - Iran announced tonightthat its major offensive against Iraq in the Gulfwar had ended after dealing savage blowsagainst he Baghdad government.\[..3The statement by the Iranian HighCommand appeared to herald the close of anassault on the port city of Basra in southernIraq.\[..3It said 81 Iraqi brigades and battalionswere totally destroyed, along with 700 tanksand 1,500 other vehicles.
The victory list alsoincluded 80 warplanes downed, 250anti.aircraft guns and 400 pieces of militaryhardware destroyed and the seizure of 220tanks and armored personnel carriers.For the story that follows, the topics war anddisorders are also originally hypothesized.
In theconfirmation phase, two things are discovered: thestory mentions no wars by name nor contains anyreferences to countries or organizations involved inconflicts that are classified as wars; and there isnothing in the story that suggests that the topicdisorders should be disconfirrned.
Hence war isdisconf'm-ned and disorders is confirmed.RIOT REPORTED IN SOUTH KOREANPRISONSeoul, July 5 - Twelve South Korean womendetainees refused food for the fifth consecutiveday today after a riot against theirmaltreatment i  a Seoul prison was put down,dissident sources aid.The 12, detained for anti-governmentprotests and awaiting trial, pushed away prisonofficials, smashed windows and occupied aprison building on Tuesday as a protest againstwhat they called "suppression of prisoners'human rights".After two hours, about 40 riot police, firingtear gas, stormed the building andoverpowered the protesters, the sources aid.Some protesters were injured, they added.For the story below, both war and disorders arehypothesized and then disconfirmed because tennis ismatched uring the disconf'u'mation phase.LENDL DEMONSTRATES GRASSCOURT MATURITYLONDON, July 2 - Czechoslovak top seedIvan Lendl served warning that he may finallyhave come of age on grass when he emergedvictorious from a pitched battle with one of thefinest exponents of the fast court game atWimbledon today.The U.S. and French Open tennis championhas never won a title on grass but he outlastedAmerican 10th seed Tim Mayotte 6-4 4-6 6-43-6 9-7 over three and a half hours to joinBoris Becker, Henri Leconte and SlobodanZivojinovic in Friday's emifinals.The titanic struggle on court one upstagedthe centre court clash between seventh seedLeconte and the remarkable Australian PatCash, which had been billed as the day's mainattraction \[...\]The story below is the rare sports story which isalso a disorders tory.
Even though the name of asporting event, Asian Games, occurs in the text, thetopic disorders is not disconfirmed.
The reason isthat the confirmation patternsets match words andphrases in the story (e.g.
radicals and violentprotests) that very strongly suggest that real disordersare being described.POLICE SEEK 160 SOUTH KOREANRADICALSSEOUL, July 2 - Police said today theywanted to detain 160 South Koreans to stopsabotage attempts during September's AsianGames in Seoul.The 160, mostly students and workers,masterminded various violent protests againstthe government and the United States in thepast months but managed to escape arrest,police said.They had been tipped that the radicals weretrying to organise big demonstrations againstthe government during the Asiad, which is torun from September 20 to October 5.
"It is highly probable that they will formradical underground groups to step up theiranti-government and anti-U.S, protests andmay disrupt he Asian Games in an attempt todefame the government," a senior police officertold reporters.\[...\]3.4.
Flow of ControlRather than being expressed in a formal rulelanguage, topic hypothesization and confirmationrules are specified through a lisp program.
Having a13program allows for fine-grained control by the ruledeveloper.
Rather than having a set ofhypothesization and conf'u'mation rules which areprocessed in a fixed order, we allow the ruledeveloper to specify the order and manner ofprocessing in a topic-dependent manner.
The majorkinds of activities available to rule developers forincorporation i to the control code are the following:running one or more patternsets, applying evaluationfunctions to the resulting matches, and confirming ordisconfirming topics.In developing the system, we observed manyregularities in the lisp code which controls the flowof processing and we believe it would be possible andprofitable to provide rule developers with a morerestricted control anguage which embodies many ofthese regularities in its primitives.3.5.
Rulebase DevelopmentThe process of formulating the rulebase of thesystem, i.e.
the collection of patterns, patternsets, andhypothesization a d confirmation rules it uses, is anempirical one.
It requires human rule developers toexamine many stories, create rulebase componentsaccording to their intuitions, run stories through thesystem, observe the results, and modify the system toavoid any miscategorizations that have occurredwithout introducing new miscategorizations.
Thistask is time-consuming and sometimes tedious.Nevertheless, our experience with the systemsuggests that it does tend to converge without undueoscillation at an accuracy level that while far fromperfect is adequate for many tasks of practicalimportance (see Section 4).
The rule developmenteffort on this system took approximately six personmonths.An important factor in the success of the rulebasedevelopment effort was the separation of thevocabulary the system looks for into a collection ofabstract concepts represented by patternsets.
Thepatternsets provide rule developers with a way ofthinking about the themes they are looking for in astory when they write the hypothesization andconfh'mation rules without becoming mired inquestions about which specific words and phrasesindicate those themes.In designing the system, we also considered adifferent approach in which the selection of wordsand phrases to look for would be determinedautomatically by a statistical method.
Since we didnot adopt this approach, we have no direct evidencethat it would not have worked as well as the labor-intensive method chosen.
However, our choice wasinfluenced by a belief that a statistical method wouldnot provide us with a choice of words and phrasesthat could be used to make distinctions as precisely asthe patterns of the kind described above that werechosen by humans.As shown in \[2\], accuracy is particularlyproblematic with a traditional keyword approachregardless of whether the keywords are selected byhumans or statistically.
And if we had adopted astatistical approach, it would have beencomputationally expensive to vary the length of thephrases chosen as much as human rule developers do.It would also have been difficult to establish thecontextual restrictions that human rule developersestablish (e.g.
this word, so long as it is not followedby one of these four others).
Rules of the complexityof the confirmation rule for war and disordersdescribed in Section 3.3 are of course essentiallyimpossible to establish by statistical means.Some interesting possibilities for a statisticalapproach to defining keywords have appearedrecently in conjunction with semantic informationabout potential keywords \[7\] and in conjunction withvery powerful parallel hardware devices \[4\].However, given the current state of the art, wecontinue to believe that our decision to use rulesformulated and refined by human developers was asound one from the point of view of the accuracy ofthe resulting system.4.
Performance4.1.
Measur ing Per formanceThe accuracy of the system for topic assignmentswas measured through two percentages for each ofthe six topics:?
recall: the percentage of stories assigned thetopic code by human categorizers that werealso assigned that code by the system;?
precision: the percentage of stories assignedthe topic code by the system that actuallycarried the topic code assigned by the humancategorizers.14The recall rate serves as a measure of the numberof stories for which the system misses an appropriatetopic code; a high recall percentage will thereforemean few such false negatives.
The precision rate,on the other hand, measures the number of stories forwhich the system chooses an incorrect topic.
A highprecision percentage means few such false positives.We emphasized high recall over high precision.4.2.
ResultsThe results obtained from the system were verypromising.
After certain necessary adjustments(described below) to the raw results, the system hadan average recall rate of 93% (i.e.
it made 93% of thetopic assignments it should have made and missedonly 7%) and an average precision rate also of 93%(i.e.
93% of the topics it did assign were correct).Another way of expressing this is that it had onaverage only 7% false negatives and 7% falsepositives in its topic assignments.
This level ofaccuracy was achieved in an average of around 15seconds per story on a Symbolics 3640 in CommonLisp.
Little effort was spent to optimize theexecution time and we believe that a substantialimprovement in speed is possible.Adjustments o the raw recall and precision figuresproduced by the system were necessary because, asdescribed in Section 2, we discovered threeproblematic features of the hand-categorizationsagainst which the system was being evaluated: theywere not always content-based; they were not alwaysconsistent; and some topic definitions were vague.Given this, it was clear that raw performance scoreswould not give a meaningful picture of how well thesystem worked, so we devised a score-adjustmentprocedure to provide results that would reflect systemperformance more accurately.
The remainder of thissection describes that procedure and presents the rawand adjusted results we obtained.We used an adjustment procedure that was basedon the assumption that there are three explanationsfor disagreements between the system and the humancategorizers about the assignment of a topic to astory:?
The human categorizer is clearly wrong.?
The system is clearly wrong.?
The topic assignment is debatable.
This casecan typically be attributed to one of the threesources of difficulty described above.A set of 500 stories was run through the system.These stories had never before been processed, andno hypothesization r conf'trmation rules had everbeen based on them.
A Carnegie Group employeewho was not involved with the system producedscore adjustments for each topic disagreementbetween the system and the human categorizers.
Theemployee was presented with a story and told thatthere was a disgreement on a specific named topic;she was not told which choice the system or thehuman categorizers had made.
The employee wasasked to decide whether the topic was appropriate forthe story, inappropriate, or debatable.
Debatablecases counted in favor of the system.The results of this experiment before and afteradjustment of the system's cores were as follows(where acq is acquisitions/mergers, mtl is metals,shp is shipping, bnd is bonds, and dis is disorders).Raw Raw Adj.
Adj.Rec.
Prec.
Rec.
Prec.acq 85% 82% 92% 92%bnd 91% 89% 97% 100%dis 90% 58% 93% 84%mtl 80% 70% 95% 90%shp 72% 49% 88% 92%war 88% 82% 92% 100%Recall is 92% or higher, except in the case of theshipping code.
This is not surprising because itturned out that shipping was a strongly interest-basedcategory, as far as the human categorizers wereconcerned.
So, stories about rough weather in the St.Lawrence seaway (but not the Rhine) and thedevaluation of the rupee (but not the Turkish lira)were classified as shipping stories because humancategorizers possessed the expert knowledge thatshippers are interested in that particular waterwayand that particular currency.The precision scores are actually higher than thecorresponding recall scores in the case of war andbonds.
Since we have found that precision can betraded off against recall by appropriate manipulationof thresholds associated with our rulebase, thissuggests that the recall rate for those two topics couldbe further improved while still maintaining anacceptable precision rate.The adjustment procedure also allowed us to15measure the performance of the hand-categorizers.While adjusted precision scores were perfect for allsix topics, adjusted recall scores ranged from 81% to100%, with an average of 94%.Adj.
Rec.
Adj.
Prec.acq  100% 100%bnd 97% 100%dis 81% 100%mtl  95% 100%shp 100% 100%war  90% 100%While human performance on precision is clearlysuperior to that of the system, the average recall ratesof human categorizers and of the system are verysimilar (94% v. 93%).
Closer examination of theresults, however, shows that the kind of errors madeare quite different.
Human errors stem mainly frominconsistent application of categories, especially thecategories with the vaguest definitions, and fromfailing to specify all the categories when severalshould have been assigned to a story.
System errorson the other hand stem largely from misinterpretationof the way in which language is being used.
Thissometimes results in ridiculous categorizations of akind that humans never produce.Out of 500 stories, the system produced a total of28 "lemons" (stories that were clearly assigned thewrong categories).
We analyzed these stories anddiscovered six sources of errors:?
The system did not match useful words orphrases, or the disconfirmation rules were toopowerful.?
The topic vocabulary was not much used in thestory.?
The system used the story background toderive the topic.?
The topic vocabulary came too late in the story.?
The topic vocabulary was used with differentmeanings.?
The topic vocabulary was used with the samemeaning, but different focus.Examples and further discussion follow.4.2.1.
Topic Vocabulary Not Much Used In StorySome stories did not use the topic vocabulary morethan one or two times.
Setting thresholds very lowwould catch these stories, but generate many falsepositives as well.
Most stories that had this problemwere also very short, so we added length-dependentthresholds to address the problem.
This techniqueworked for metals stories, where the vocabulary issomewhat distinctive, but would not work foracquisitions tories, where the vocabulary consists ofvery common words like buy and sell.4.2.2.
Story Background Used To Derive TopicNews stories sometimes have backgroundinformation included which does not have much todo with the main point of the story.
For example, thefollowing story, about the Pope's visit to Colombia,was miscategorized asa metals story because of thebackground information about the country.
Solvingthis problem requires a deep understanding of thestructure of the story.SECURITY FOR POPE TIGHTENSChiquinquira, Colombia, July 3 - Securityprecautions for Pope John Paul II weretightened today, with hundreds of troopsmaking thorough body searches of visitors tothis colonial town high in the Andesmountains.\[...\]Chiquinquira has been spared the guerillawarfare which has torn much of Colombia overthe past three decades.
But the nearby Muzoemerald mines, the country's biggest, haveattracted adventurers who often feud violentlyin the town.Some Muzo miners have moved on to themore lucrative drug traffic \[...\].4.2.3.
Topic Vocabulary Used With DifferentMeaningSometimes tories are miscategorized because ofthe metaphorical language they use.
For example, inone story the word revolution appeared numeroustimes: the British government was calling for arevolution in broadcasting.
Another contained thephrases ready to go to war, make peace, make war,target, and heavy losses; the subject of the story waslabor negotiations in the automobile industry.
Sincethe system does not really understand the texts itprocesses, it is inevitable that it will be fooled fromtime to time by such usage.164.2.4.
Topic Vocabulary Used with Same MeaningBut Different FocusThe following story illustrates another problem forwhich there is no obvious solution.
The word armyoccurs four times (not all shown), and the sense ofthe word in this military story is exactly the sense itmight have in an actual war or disorders tory.CHINESE ARMY TO HAVE NCOS FORFIRST TIMEPeking, July 4 - The Chinese army willallow non-commissioned officer ranks for thefirst time as part of its reform program, theNew China News Agency said today.It said soldiers who have been in the armyfor one year and had a good record would, aftertraining at two special schools, serve as NCOS.\[...\]5.
Conc lus ionThis paper has shown that high accuracy automatictext categorization is feasible for texts covering adiverse set of topics, using the well-establishednatural language processing technique of patternmatching applied according to knowledge-basedrules, but without requiring a complete syntactic orsemantic analysis of the texts.
Automatic textprocessing of this kind has many potentialapplications with high economic paybacks in therouting and archiving of news stories, electronicmessages, or other forms of on-line text.
We expectthat many such systems will be in commercial usewithin the next few years.3.
Hayes, P. J., Andersen, P., Safier, S. SemanticCase Frame Parsing and Syntactic Generality.
Proc.of 23rd Annual Meeting of the Assoc.
for Comput.Ling., Chicago, June, 1985.4.
Hillis, W. D..
The Connection Machine.
MITPress, Cambridge, Mass., 1985.5.
Parkison, R. C., Colby, K. M., and Faught, W. S."Conversational Language Comprehension UsingIntegrated Pattern-Matching and Parsing".
ArtificialIntelligence 9 (1977), 111-134.6.
Salton, G. and McGill, M. J.. Introduction toModern Information Retrieval.
McGraw-Hill, NewYork, 1983.7.
Walker, D. E. and Amsler, RI A.
The Use ofMachine-Readable Dictionaries in SublanguageAnalysis.
In Analyzing Language in RestrictedDomains: Sublanguage Description and Processing,R.
Grishman and R. Kittredge, Ed., LawrenceErlbaum Associates, Hillsdale, New Jersey, 1986, pp.69-83.AcknowledgementsPeter Neuss and Scott Sailer contributedsubstantially tothe design and implementation f thesystem described in this paper.References1.
Carbonell, J. G., Boggs, W. M., Mauldin, M. L.,and Anick, P. G. The XCALIBUR Project: ANatural Language Interface to Expert Systems.
Proc.Eighth Int.
JL Conf.
on Artificial Intelligence,Karlsruhe, August, 1983.2.
Furnas, G. W., Landauer, T. K., Dumais, S. T.,and Gomez, L. M. "Statistical semantics: Analysis ofthe potential performance ofkeyword informationsystems".
Bell System Technical Journal 62, 6(1983), 1753-1806.17
