Building Accurate Semantic Taxonomies fromMonolingual MRDsGerman Rigau and Horacio RodrlguezDepartament de LSI.Universitat Polit~cnica de Catalunya.Barcelona.
Catalonia.
{g.rigau, horacio}@lsi.upc.esEneko AgirreLengoia eta Informatikoak saila.Euskal Erriko Universitatea.Donostia, Basque Country.jibagbee@si.ehu.esAbstractThis paper presents a method thatconbines aset of unsupervised algorithms inorder to accurately build large taxonomiesfrom any machine-readable dictionary(MRD).
Our aim is to profit fromconventional MRDs, with no explicitsemantic oding.
We propose a system that1) performs fully automatic extraction oftaxonomic links from MRD entries and 2)ranks the extracted relations in a way thatselective manual refinement is allowed.Tested accuracy can reach around 100%depending on the degree of coverageselected, showing that taxonomy buildingis not limited to structured ictionariessuch as LDOCE.1 IntroductionThere is no doubt about the increasing need ofowning accurate and broad coverage generallexical/semantic resources for developing NLapplications.
These resources include Lexicons,Lexical Databases, Lexical Knowledge Bases(LKBs), Ontologies, etc.
Many researchers believethat for effective NLP it is necessary to build aLKB which contain class/subclass relations andmechanisms for the inheritance of properties aswell as other inferences.
The work presented hereattempts to lay out some solutions to overcome oralleviate the "lexical bottleneck" problem(Briscoe 91) providing a methodology to buildlarge scale LKBs from conventional dictionaries,in any language.
Starting with the seminal workof (Amsler 81) many systems have followed thisapproach (e.g., Bruce et al 92; Richardson 97).Why should we propose another one?Regarding the resources used, we must point outthat most of the systems built until now refer toEnglish only and use rather rich, well structured,controlled and explicitly semantically codeddictionaries (e.g.
LDOCE 87).
This is not the casefor most of the available sources for languagesother than English.
Our aim is to use conventionalMRDs, with no explicit semantic oding, to obtaina comparable accuracy.The system we propose is capable of 1)performing fully automatic extraction (with acounterpart in terms of both recall and precisionfall) of taxonomic links of dictionary senses and 2)ranking the extracted relations in a way thatselective manual refinement is allowed.Section 2 shows that applying a conventionalpure descr ipt ive approach the result ingtaxonomies are not useful for NLP.
Our approachis presented in the rest of the paper.
Section 3deals with the automatic selection of the mainsemantic primitives present in DiccionarioGeneral Ilustrado de la Lengua Espafiola (DGILE87), and for each of these, section 4 shows themethod for the selection of its mostrepresentative g nus terms.
Section 5 is devoted tothe automatic acquisition of large and accuratetaxonomies from DGILE.
Finally, some conclusionsare drawn.2 Acquiring taxonomies from MRDsA straightforward way to obtain a LKBacquiring taxonomic relations from dictionarydefinitions can be done following a purely bottomup strategy with the following steps: 1) parsingeach definition for obtaining the genus, 2)performing a genus disambiguafion procedure, and3) building a natural classification of the conceptsas a concept taxonomy with several tops.Following this purely descriptive methodology,the semantic primitives of the LKB could beobtained by collecting those dictionary sensesappearing at the top of the complete taxonomiesderived from the dictionary.
By characterizingeach of these tops, the complete LKB could beproduced.
For DGILE, the complete noun taxonomywas derived following the automatic methoddescribed by (Rigau et al 97) 1.1This taxonomy contains 111,624 dictionary senses andhas only 832 dictionary senses which are tops of thetaxonomy (these top dictionary senses have no1103However, several problems arise a) due to thesource (i.e, circularity, errors, inconsistencies,omitted genus, etc.)
and b) the limitation of thegenus sense disambiguation techniques applied:i.e, (Bruce et al 92) report 80% accuracy usingautomatic techniques, while (Rigau et al 97)report 83%.
Furthermore, the top dictionarysenses do not usually represent he semanticsubsets that the LKB needs to characterize inorder to represent useful knowledge for NLPsystems.
In other words, there is a mismatchbetween the knowledge directly derived from anMRD and the knowledge needed by a LKB.To illustrate the problem we are facing, let ussuppose we plan to place the FOOD concepts inthe LKB.
Neither collecting the taxonomiesderived from a top dictionary sense (or selecting asubset of the top dictionary senses of DGILE)closest to FOOD concepts (e.g., substancia-substance-), nor collecting those subtaxonomiesstarting from closely related senses (e.g., bebida-drinkable liquids- and alimento -food-) we areable to collect exactly the FOOD concepts presentin the MRD.
The first are too general (they wouldcover non-FOOD concepts) and the second are toospecific (they would  not cover all FOODdictionary senses because FOODs are described inmany ways).All these problems can be solved using a mixedmethodology.
That is, by attaching selected topconcepts (and its der ived taxonomies) toprescribed semantic primitives represented in theLKB.
Thus, first, we prescribe a minimal ontology(represented by the semantic primitives of theLKB) capable of representing the whole lexiconderived from the MRD, and second, following adescriptive approach, we collect, for everysemantic primit ive placed in the LKB, itssubtaxonomies.
Finally, those subtaxonomiesselected for a semantic primitive are attached tothe corresponding LKB semantic ategory.Several prescribed sets of semantic primitiveshave been created as Ontological KnowledgeBases: e.g.
Penman Upper Model (Bateman 90),CYC (Lenat & Guha 90), WordNet (Miller 90).Depending on the application and theoreticaltendency of the LKB different sets of semanticprimitives can be of interest.
For instance,WordNet noun top unique beginners are 24semantic ategories.
(Yarowsky 92) uses the 1,042major categories of Roget's thesaurus, (Liddy &Paik 92) use the 124 major subject areas of LDOCE,hypernyms), and 89,458 leaves (which have nohyponyms).
That is, 21,334 definitions are placedbetween the top nodes and the leaves.1104(Hearst & Schfitze, 95) convert the hierarchicalstructure of WordNet into a fiat system of 726semantic ategories.In the work presented in this paper we used assemantic primitives the 24 lexicographer's files(or semantic files) into which the 60,557 nounsynsets (87,641 nouns) of WordNet 1.5 (WN1.5)are classified 2.
Thus, we considered the 24semantic tags of WordNet as the main LKBsemantic primitives to which all dictionarysenses must be attached.
In order to overcome thelanguage gap we also used a bi l ingualSpanish/English dictionary.3 At tach ing  DGILE  dict ionary senses  tosemant ic  pr imi t ivesIn order to classify all nominal DGILE senseswith respect o WordNet semantic files, we useda similar approach to that suggested by(Yarowsky 92).
Rather than collect evidence froma blurred corpus (words belonging to a Roget'scategory are used as seeds to collect a subcorpus forthat category; that is, a window context producedby a seed can be placed in several subcorpora), wecollected evidence from dictionary senses labelledby a conceptual distance method (that is, adefinition is placed in one semantic file only).This task is divided into three fully automaticconsecutive subtasks.
First, we tag a subset (due tothe difference in size between the monolingualand the bi l ingual dictionaries) of DGILEdictionary senses by means of a process that usesthe conceptual distance formula; second, wecollect salient words for each semantic file; andthird, we enrich each DGILE dictionary sensewith a semantic tag collecting evidence from thesalient words previously computed.3.1 Attach WordNet  synsets  to DGILEheadwords.For each DGILE definition, the conceptualdistance between headword and genus has beencomputed using WN1.5 as a semantic net.
Weobtained results only for those definitions havingEnglish translations for both headword andgenus.
By computing the conceptual distancebetween two words (Wl,W2) we are also selectingthose concepts (Cli,C2j) which represent them andseem to be closer with respect o the semantic net2One could use other semantic lassifications becauseusing this methodology a minimal set of informed seedsare needed.
These seeds can be collected from MRDs,thesauri or even by introspection, see (Yarowsky 95).used.
Conceptual distance is computed usingformula (1).min 1 (1) dist(w I,w2) = c~,a ~ )depth(ck)c2~ ~ w2 q e patl~c~ ,c2iThat is, the conceptual distance between twoconcepts depends on the length of the shortestpath 3 that connects them and the specificity ofthe concepts in the path.Noun definitionsNoun definitions with genusGenus termsGenus terms with bilin~ual translationGenus terms with WN1.5 translationHeadwordsHeadwords with bilingual translationHeadwords with WN1.5 translationDefinitions with bilin~ual translationDefinitions with WN1.5 translationTable 1, data of first attachment usingdistance.93,39492,69314,1317,6107,31953,45511,40710,66730,446conceptuaAs the b i l ingua l  d ic t ionary  is notdisambiguated with respect o WordNet synsets(every Spanish word has been assigned to allpossible connections to WordNet synsets), thedegree of polysemy has increased from 1.22(WN1.5) to 5.02, and obviously, many of theseconnections are not correct.
This is one of thereasons why  after processing the wholedictionary we obtained only an accuracy of 61% ata sense (synset) level (that is, correct synsetsattached to Spanish headwords and genus terms)and 64% at a file level (that is, correct WN1.5lexicogra, pher's file assigned to DGILE dictionarysenses) 'L  We processed 32,2085 dict ionarydefinitions, obtaining 29,205 with a synsetassigned to the genus (for the rest we did notobtain a bilingual-WordNet relation between theheadword and the genus, see Table 1).In this way, we obtained a preliminaryvers ion of 29,205 d ict ionary def init ionssemantically labelled (that is, with Wordnetlexicographer's files) with an accuracy of 64%.That is, a corpus (collection of dictionary senses)3We only consider hypo/hypermym relations.4To evaluate this process, we select at random a test setwith 391 noun senses that give a confidence rate of 95%.5The difference with 30,446 is accounted for by repeatedheadword and genus for an entry.1105classified in 24 partitions (each one correspondingto a semantic category).
Table 2 compares thedistribution of these DGILE dictionary senses (seecolumn a) with respect to WordNet semanticcategories.
The greatest differences appear withthe classes ANIMAL and PLANT, whichcorrespond to large taxonomic scientif icclassifications occurring in WN1.5 but which donot usually appear in a bilingual dictionary.3.2 Collect the salient words for every semanticprimitive.Once we have obtained the first DGILEversion with semantically labelled definitions,we can collect the salient words (that is, thoserepresentative words for a particular category)using a Mutual Information-like formula (2),where w means word and SC semantic lass.
(2) AR(w, SC) = Pr(wlSC)log 2 Pr(wlSC)Pr(w)Intuit ively,  a sal ient word  6 appearssignificantly more often in the context of asemantic category than at other points in thewhole corpus, and hence is a better than averageindicator for that semantic category.
The wordsselected are those most relevant o the semanticcategory, where relevance is defined as theproduct of salience and local frequency.
That is tosay, important words should be distinctive andfrequent.We performed the training process consideringonly the content word forms from dictionarydefinitions and we discarded those salient wordswith a negative score.
Thus, we derived a lexiconof 23,418 salient words (one word can be a salientword for many semantic ategories, see Table 2,columns b and c).3.3 Enrich DGILE definitions with WordNetsemantic primitives.Using the salient words per category (orsemantic lass) gathered in the previous step welabelled the DGILE dictionary definitions again.When any of the salient words appears in adefinition, there is evidence that the wordbelongs to the category indicated.
If several ofthese words appear, the evidence grows.6Instead of word lemmas, this study has been carried outusing word forms because word forms rather thanlemmas are representative of typical usages of thesublanguage used in dictionaries.Semantic file03 tops04 act05 animal#DGILEsenses (a)77 (0.2%)3,138 (10.7%)712 (2.4%)6,915 (23.7%) 06 artifact07attribute 2,078 (7.1%)O8 body09 co~ition10 communication621 (2.1%)1,556 (5.3%)4,076 (13.9%)11 event 541 (1.8%)12 feelin13 food14 group15 place16 motive17 obiect18 person306 (1.0%)749 (2.5%)661 (2.2%)416 (1.4%)15 (0.0%)#Contentwords(b)3,279 (11.2%)I54016,9636,191~5,98811,069#Salientwords(c)2,5938494,5151,571#DGILEsenses (d)4,188 (4.8%)4,544 (5.2%)12,958 (14.9%)4,146 (4.8%)#WordNetsynsets35 (0.0%)4895 (8.0%)7,112 (11.7%)24,633 6,012 (6.9%)3,071 477 1,544 (1.7%)1,623 2639,101 (15.0%o)2,526 (4.2%)1,376 (2.3%) 4,285 665 3,208 (3.6%)9,699 1,362 3,672 (4.2%) 2,007 (3.3%)3,3017176474021,016 (1.2%)2,614 (3.0%)3,074 (3.5%)2,073 (2.4%)4,67913,901 (16.0%)4,3382,5874,115 (6.8%)752 (1.2%)397 (0.6%)2,290 (3.8%)1,661 (2.7%)1,755 (2.9%)87 9 22 (0.0%) 28 (0.0%)437 (1.5%) 2,733 412 1,645 (1.9%) 839 (1.4%)19,273 2,304 5,563 (9.1%)119 phenomenon20 plant21 possession22 process23 quantity24 relation25 shape26 state27 substance28 timeTotal147 (0.5%)581 (2.0%)287 (1.0%)211 (0.7%)344 (1.2%)102 (0.3%)165 (0.6%)805 (2.7%)642 (2.2%)344 (1.2%)32,2087844,9651,7129872,1796001,0404,4695,0022,172181,6691147002781773177617271273432123,418425 (0.4%)4,234 (4.9%)1,033 (1.2%)6948 (8.0%)1,502 (1.7%)288 (0.3%)677 (0.8%)1,973 (2.3%)3,518 (4.0%)1,544 (1.8%)Table 2, comparison fthe two labelling process (and82,759salient words ~er context) with to res452 (0.7%)7,971 (13.2%)829 (1.4%)445 (0.7%)1,050 (1.7%)343 (0.6%)284 (0.4%)1,870 (3.0%)2,068 (3.4%)799 (1.3%)60,557~ect WN1.5 semantic tags.We add together their weights, over all wordsin the definition, and determine the category forwhich the sum is greatest, using formula (3).
(3) W(SC) = EAR(w,SC)wedefinitionThus, we obtained a second semanticallylabelled version of DGILE (see table 2, column d).This version has 86,759 labelled definitions(covering more than 93% of all noun definitions)with an accuracy rate of 80% (we have gained,since the previous labelled version, 62% coverageand 16% accuracy).The main differences appear (apart from theclasses ANIMAL and PLANT) in the classes ACTand PROCESS.
This is because during the firstautomatic labelling many dictionary definitionswith genus acci6n (act or action) or efecto (effect)were classified erroneously as ACT or PROCESS.These results are difficult to compare withthose of \[Yarowsky 92\].
We are using a smallercontext window (the noun dictionary definitionshave 9.68 words on average) and a microcorpus(181,669 words).
By training salient words from alabelled dictionary (only 64% correct) rather thana raw corpus we expected to obtain less noise.Although we used the 24 lexicographer's filesof WordNet as semantic primitives, a more fine-grained classification could be made.
For example,all FOOD synsets are classified under <food,nutrient> synset in file 13.
However, FOODconcepts are themselves classified into 11subclasses (i.e., <yolk>,  <gastronomy>,<comestible, edible, eatable .
.
.
.
>, etc.).
Thus, ifthe LKB we are planning to build needs torepresent <beverage, drink, potable> separatelyfrom the concepts <comestible, edible, eatable,...> a finer set of semantic primitives hould bechosen, for instance, considering each directhyponym of a synset belonging to a semantic filealso as a new semantic primitive or even selecting1106for each semantic file the level of abstraction weneed.A further experiment could be to iterate theprocess by collecting from the second labelleddictionary (a bigger corpus) a new set of salientwords and reestimating again the semantic tagsfor all dictionary senses (a similar approach isused in Riloff & Shepherd 97).4 Selecting the main top beginners for asemantic primitiveThis section is devoted to the location of themain top dictionary sense taxonomies for a givensemantic primitive in order to correctly attach allthese taxonomies to the correct semantic primitivein the LKB.In order to illustrate this process we will locatethe main top beginners for the FOOD dictionarysenses.
However, we must consider that many ofthese top beginners are structured.
That is, some ofthem belong to taxonomies derived from otherones, and then cannot be directly placed withinthe FOOD type.
This is the case of vino (wine),which is a zumo (juice).
Both are top beginners forFOOD and one is a hyponym of the other.First, we collect all genus terms from the wholeset of DGILE dictionary senses labelled in theprevious section with the FOOD tag (2,614senses), producing a lexicon of 958 different genusterms (only 309, 32%, appear more than once in theFOOD subset of dictionary sensesT).As the automatic dictionary sense labelling isnot free of errors (around 80% accuracy) 8 we candiscard some senses by using filtering criteria.?
Filter 1 (F1) removes all FOOD genus termsnot assigned to the FOOD semantic file during themapping process between the bilingual dictionaryand WordNet.
* Filter 2 (F2) selects only those genus termswhich appear more times as genus terms in theFOOD category.
That is, those genus terms whichappear more frequently in dictionary definitionsbelonging to other semantic tags are discarded.?
Filter 3 (F3) discards those genus termswhich appear with a low frequency as genus termsin the FOOD semantic category.
That is,infrequent genus terms (given a certain threshold)are removed.
Thus, F3>1 means that the filteringcriteria have discarded those genus terms7We select his group of genus for the test set.8Most of them are not really errors.
For instance, allfishes must be ANIMALs, but some of them are edible(that is, FOODs).
Nevertheless, all fishes labelled asFOOD have been considered mistakes.ii07appearing in the FOOD subset of dictionarydefinitions less than twice.Table 4 shows the first 10 top beginners forFOOD.
Bold face is used for those genus termsremoved by filter 2.
Thus, pez -fish- is anANIMAL.90 bebida (drink) !48 pasta (pasta, etc.
)86 v ino(w ine)~09 pan(bread )78 pez (fish) plato (dish)56 comida (food) 33 guisado (casserole)55 came (meat) 3-2 salsa (souce)?
Table 4, frequency of m girmers for FOODTable 5 shows the performance of the secondlabelling with respect o filter 3 (genus frequency)varying the threshold.
From left to right, filter,number of genus terms selected (#GT), accuracy(A), number of definitions (#D) and theirrespective accuracy.LABEL2+F3 I #GT I A I#D I AF3>9 32 89% 9081 88%F3>8 37 90% 953 88%F3>7 39 88% 969 87%F3>6 45 88% 1,011 87%F3>5 51 87% 1,047 82%F3>4 62 85% 1,102 86%F3>3 73 78% 1,146 84%F3>2 99 69% 1,224 80%F3>1 151 62% 1,328 77%LABEL2 + F1 I #GT \[ A I#D I AFl+F3>9 31 94% 895 90%Fl+F3>8 35 95% 931 90%F1+F3>7 37 91% 947 89%Fl+F3>6 43 92% 989 90%Fl+F3>5 49 92% 1,025 90%Fl+F3>4 55 91% 1,055 90%Fl+F3>3 64 85% 1,091 88%Fl+F3>2 85 82% 1,152 87%Fl+F3>1 125 78% 1,234 86%variying 3.Tables 6 and 7 show that at the same level ofgenus frequency, filter 2 (removing genus termswhich are more frequent in other semanticcategories) is more accurate that filter 1(removing all genus terms the translation ofwhich cannot be FOOD).
For instance, no errorappears when selecting those genus terms whichappear 10 or more times (F3) and are more frequentin that category than in any other (F2).Table 8 shows the coverage of correct genusterms selected by criteria F1 and F2 to respectcriteria F3.
Thus, for genus terms appearing 10 ormore times, by using either of the two criteria weare collecting 97% of the correct ones.
That is, inboth cases the criteria discards less than 3% ofcorrect genus terms.LABEL2 + F2 \[ #GT \[ A \ [#D \[ AF2+F3>9 31 100% 893 100%F2+F3>8 35 100% 929 100%F2+F3>7 37 95% 945 98%F2+F3>6 41 94% 973 98%F2+F3>5 47 92% 1,009 97%?F2+F3>4 56 91% 1,054 96%F2+F3>3 65 87% 1,090 95%F2+F3>2 82 83% 1,141 93%F2+F3>1 123 82% 1,223 92%filter 2 varying filter 3.ICovera~e vs F1 \[Coverage vs F2F3>9 97%0 97%F3>8 95% 95%F3>7 95% 95%F3>6 96% 91%F3>5 96% 92%F3>4 89% 90%F3>3 90% 89%F3>2 86% 83%F3>1 83% 81%Table 8, coverage of second labelling with respect to filtel1 and 2 varying filter 3.5 Bu i ld ing  automat ica l ly  la rge  sca letaxonomies  f rom DGILEThe automatic Genus Sense Disambiguationtask in DGILE has been performed following(Rigau et al 97).
This method reports 83%accuracy when selecting the correct hypernym bycombining eight different heuristics using severalmethods and types of knowledge.
Using thiscombined technique the selection of the correcthypernym from DGILE had better performancethan those reported by (Bruce et al 92) usingLDOCE.Once the main top beginners (relevant genusterms) of a semantic category are selected andevery  d ic t ionary  def in i t ion  has beendisambiguated, we collect all those pairs labelledwith the semantic category we are working on1108having one of the genus terms selected.
Usingthese pairs we finally build up the completetaxonomy for a given semantic primitive.
That is,in order to build the complete taxonomy for asemantic primitive we fit the lower senses usingthe second labelled lexicon and the genus selectedfrom this labelled lexicon.Table 9 summarizes the sizes of the FOODtaxonomies acquired from DGILE with respect ofi ltering criteria and the results manual lyobtained by (Castell6n 93) 9 where 1) is (Castell6n93), (2) F2 + F3 > 9 and (3) F2 + F3 > 4.FOODGenus termsDicfi0narysensesLevelsSenses in ,ve i lSenses in level2Sensesinlevel3Senses in level 4Senses in level 5Senses in level 6(1) (2) (3)62 33 68392 952 1,2426 5 62 18 4867 490 60488 379 45267 44 6587 21 606 0 13Table 9, comparison ofFOOD taxonomies.Using the first set of criteria (F2+F3>9), weacquire a FOOD taxonomy with 952 senses (morethan two times larger than if it is done manually).Using the second one (F2+F3>4), we obtainanother taxonomy with 1,242 (more than threetimes larger).
While using the first set of criteria,the 33 genus terms selected produce a taxonomicstructure with only 18 top beginners, the secondset, with 68 possible genus terms, produces anothertaxonomy with 48 top beginners.
However, bothfinal taxonomic structures produce more flattaxonomies than if the task is done manually.This is because we are restricting the innertaxonomic genus terms to those selected by thecriteria (33 and 68 respectively).
Consider thefol lowing taxonomic chain, obtained in asemiautomatic way by (Castell6n 93):beb ida_13 <- l lqu ido  16  <- zumo 1 1 <-vino 1_1 <- rueda 1_1As liquido -liquid- was not selected as apossible genus (by the criteria described above),the taxonomic hain for that sense is:zumo_l_l  <-vino 1 1 <-rueda 1 19We used the results reported by (CasteIl6n 93) as abaseline because her work was done using the sameSpanish dictionary.Thus, a few arrangements (18 or 48 dependingon the criteria selected) must be done at the toplevel of the automatic taxonomies.
Studying themain top beginners we can easily discover aninternal structure between them.
For instance,placing all zumo (juice) senses within bebida(drink).Performing the same process for the wholedictionary we obtained for F2+F3>9 a taxonomicstructure of 35,099 definitions and for F2+F3>4 thesize grows to 40,754.6 ConclusionsWe proposed a novel methodology whichcombines several structured lexical knowledgeresources for acquiring the most important genusterms of a monolingual dictionary for a givensemantic primitive.
Our approach for buildingLKBs is mainly descriptive (the main source ofknowledge is MRDs), but a minimal prescribedstructure is provided (the semantic primitives ofthe LKB).
Using the most relevant genus terms fora particular semantic primitive and applying afiltering process, we presented a method toconstruct fully automatically taxonomies from anyconventional dictionary.
This approach differsfrom previous ones because we are consideringsenses as lexical units of the LKB (e.g., in contrastto Richardson 97 who links words) and the mixedmethodo logy appl ied (e.g, the completedescriptive approach of Bruce et al 92).The results show that the construction oftaxonomies using lexical resources i not limited tohighly structured MRDs.
Applying appropriatetechniques, conventional dictionaries uch asDGILE could be useful resources for buildingautomatically substantial pieces of an LKB.AcknowledgmentsThis research as been partially funded by theSpanish Research Department (ITEM ProjectTIC96-1243-C03-03), the Catalan ResearchDepartment (CREL project), and the UE Comision(EuroWordNet LE4003).ReferencesAmsler R. (1981)A Taxonomy for Enghish Nounsand Verbs, in proceedings of the 19th AnnualMeeting of the ACL, (ACL'81), Stanford, CA.Bateman J.
(1990)Upper modeling: Organizingknowledge for Natural Language Processing.
inproccedings of Fifth International workshop onNatural Language Generation, Pittsburg, PA.Briscoe E., (1991) Lexical Issues in NaturalLanguage Processing.
In E. Klein and F..Veltman (eds.
), Natural Lan~ma~e and Sveech.Springer-Verlag.Bruce R. and Guthrie L. (1992) Genusdisambiguation: A study in weigthedpreference, in proceedings of COLING'92.Nantes, France.Castell6n I.
(1993) Lexicografia Computacional:Adquisici6n Autom~tica de ConocimientoL~xico, Ph.D. Thesis, UB, Barcelona.DGILE (1987) Diccionario General Ilustrado de laLengua E~pafiola VOX.
Alvar M.
(ed.
).Biblograf S.A. Barcelona, Spain.Hearst M. and Schiitze H. (1995) Customizing aLexicon to Better Suit a Computational Task, inBoguraev B. and Pustejovsky J.
(eds.)
CorvusProcessin~ for Lexical Acauisition.
The MITvPress, Cambridge, Massachusetts.LDOCE (1987) Longman Dict ionary ofContemporary English.
Procter, P. et al (eds).Longman, Harlow and London.Lenat D. and Guha R., (1990)Knowledge-based Svstems: Revresentation a dInference in the Cvc Proiect.
Addison Wesley.Liddy E. And Paik W. (1992) Statistically-GuidedWord Sense Disambiguation, i  proceedings ofthe AAAI Fall Symposium on Statistically-Based NLP Techniques.Miller G. (1990) Five papers on WordNet,International Journal of Lexicography 3(4).Richardson S. (1997) Determining Similaritv andInferring Relations in a Lexical KnowledgeBase., Ph.D. Thesis, The City University of NY.Rigau G., Atserias J. and Agirre E. (1997)Combining Unsupervised Lexical KnowledgeMethods for Word Sense Disambiguation inproceedings of the 34th Annual Meeting of theACL (ACL'97).
Madrid, Spain.Riloff E. and Shepherd J.
(1997) A Corpus-BasedApproach for Building Semantic Lexicons, inproceedings of the Second Conference onEmpirical Methods in NLP.Yarowsky D. (1992) Word-Sense DisambiguationUsing Statistical Models of Rogetis CategoriesTraiend on Large Corpora, in proceedings ofCOLING'92, Nantes, France.Yarowsky D. (1995) Unsupervised Word SenseDisambiguation Rivaling Supervised Methods,in proceedings of the 33th Annual Meeting oftha Association for Computational Linguistics,(ACL'95).1109
