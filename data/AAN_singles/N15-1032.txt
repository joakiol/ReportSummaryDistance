Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 283?292,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsDigital Leafleting: Extracting Structured Data fromMultimedia Online FlyersEmilia ApostolovaBrokerSavant Inc.2506 N. Clark St, 415Chicago, IL 60614, USAemilia@brokersavant.comPayam PourashrafDePaul University243 S Wabash AveChicago, IL 60604, USAppourash@cdm.depaul.eduJeffrey SackBrokerSavant Inc.2506 N. Clark St, 415Chicago, IL 60614, USAjeff@brokersavant.comAbstractMarketing materials such as flyers and otherinfographics are a vast online resource.
Ina number of industries, such as the com-mercial real estate industry, they are in factthe only authoritative source of information.Companies attempting to organize commer-cial real estate inventories spend a significantamount of resources on manual data entry ofthis information.
In this work, we proposea method for extracting structured data fromfree-form commercial real estate flyers in PDFand HTML formats.
We modeled the prob-lem as text categorization and Named EntityRecognition (NER) tasks and applied a su-pervised machine learning approach (SupportVector Machines).
Our dataset consists ofmore than 2,200 commercial real estate fly-ers and associated manually entered structureddata, which was used to automatically cre-ate training datasets.
Traditionally, text cate-gorization and NER approaches are based ontextual information only.
However, informa-tion in visually rich formats such as PDF andHTML is often conveyed by a combinationof textual and visual features.
Large fonts,visually salient colors, and positioning oftenindicate the most relevant pieces of informa-tion.
We applied novel features based on vi-sual characteristics in addition to traditionaltext features and show that performance im-proved significantly for both the text catego-rization and NER tasks.1 IntroductionDigital flyers are the preferred and sometimes onlymethod of conveying offerings information in anumber of broker-based industries.
Such industriestypically lack a centralized database or an estab-lished source of information.
Organizing such con-tent typically involves manual data entry, an expen-sive and labour intensive effort.
Further challenge isthat available offerings constantly change and man-ually entered data often results in out-dated invento-ries.In particular, the commercial real estate industryin the US (unlike residential real estate1) does nothave a centralized database or an established sourceof information.
A number of commercial real estateinventories collect commercial real estate data usinginformation from flyers, contacting brokers, or vis-iting physical sites2.
The data is manually enteredin structured form.
At the same time, inventorieschange on a daily basis.
As a result, the collectedinformation is typically sparse and often outdated.In fact, commercial real estate brokers often need torely on networking and chance in preference to con-sulting third party listing databases.While brokers do not often update third party in-ventory databases, they do create marketing mate-rials (usually PDF flyers and/or HTML emails/webpages) that contain all relevant listing information.Virtually all commercial real estate offerings comewith a publicly available marketing material thatcontains all relevant listing information.
Figures 1and 2 show two typical commercial real estate flyers.1The US Multiple Listing Services (MLS), governed by theNational Association of Realtors, represents the US residentialreal estate.2LoopNet, subsidiary of CoStar Group Inc., is the mostheavily trafficked online commercial real estate inventory.283Figure 1: An example of a commercial real estate flyerc?
Kudan Group Real Estate.Our goal is to utilize this publicly available informa-tion and extract structured data that can be continu-ously updated for a reliable centralized database ofofferings.Commercial listing information is typically sum-marized in a structured form suitable for targetedproperty searches.
The most important informationconsists of the various categories of the offering.
Forexample, the transaction type (sale, lease, and/or in-vestment), the property type (industrial, retail, of-fice, etc.
), the location of the property (its full geo-coded address), the size of the property, the contactinformation of the brokers representing the property,etc.This information is typically present in text formwithin the flyer.
However, flyers and similar mar-keting materials are essentially multi-media docu-ments.
In addition to text, information is also con-veyed by attributes such as font size, color, position-ing, and images.
For example, the listing addressof the flyer on Figure 1 can be easily identified byits prominent color, size, and positioning (2834 N.Southport Ave, upper left corner).
While the ad-dress of the broker firm shown in the same flyer isconsidered non-essential information and lacks suchvisual prominence (156 North Jefferson St., upperright corner).
In fact, it is very difficult and some-times impossible to distinguish between the two ad-dress types when considering a text-only version ofthe flyer.
Similarly, the transaction type (For Sale)of the property on Figure 2 is prominently shownin a large font and distinctive color.
To account forthe multi-media nature of the dataset, we attempt tocombine textual and visual features for the task ofautomatic extraction of structured information fromfree-form commercial real estate flyers.The problem of extracting structured data fromflyers was modeled as text categorization andNamed Entity Recognition (NER) tasks as describedin Section Problem Definition below.
Typically,both text categorization and NER approaches are ap-plied to genres with exclusively text-based content(newswires, scientific publications, blogs and othersocial media texts).
As a result, the feature space ofNER and text categorization involves purely textualfeatures: word attributes and characteristics, theircontexts and frequencies.
However, textual infor-mation in visually rich formats, such as PDF andHTML, is interlaced with typographic and other vi-sually salient characteristics.
In this study, we pro-pose several novel features that take visual charac-teristics into account and show that performance im-proves significantly on both the text categorizationand NER tasks.2 Problem DefinitionGiven a commercial real estate flyer, our task is toextract structured information that can be used as in-put to a commercial real estate listing service.
Thisinformation includes categories associated with theproperty (property type and transaction type) and alist of property attributes (address, space informa-tion, and broker information).The task of identifying a list of categories wasmodeled as a text categorization task.
The cate-gories and associated types are summarized in Ta-ble 1.
Both text categorization tasks (identifyingthe Transaction and Property Types) are multi-labelclassification tasks, i.e.
multiple category labels canbe assigned to each listing.
For example, propertiesare often offered for both sale and lease and belongto both transaction types.
Similarly, a retail buildingcould offer an associated office unit and belongs toproperty types retail and office.The task of identifying values of specific listingattributes was modeled as a Named Entity Recog-nition (NER) task.
The various NER types and de-284Transaction Type A listing can have one or more of thefollowing transaction types: sale,lease, investment.Property Type A listing can have one or more of thefollowing property types: retail,office, industrial, land, multi-family.Table 1: Types and descriptions of flyer categories.scriptions are summarized in Table 2.
The namedentities represent a typical set of attributes collectedby commercial real estate listing services.
They are1) one or more brokers representing the property andtheir contact information; 2) the full address of theproperty broken down into individual address fields;3) one or more spaces including their sizes and types(e.g.
sizes of available units in a shopping mall, thesizes of a warehouse building and associated officebuilding, etc.
).Broker Name The contact information of allBroker Email listing brokers, including full name,Broker Phone email address, phone number.Company Name The brokerage company name.Street The address information of theCity listing address including street orNeighborhood intersection, city, state, and,State zip code.ZipSpace Size Size and attributes of relevant spacesand Type (e.g.
27,042 SF building, 4.44 acressite, etc.
); Includes the numeric value,unit of measure, whether the value isa part of a range (min or max) or exactvalue, as well as the space type (unit,building,lot); Excludes size informationof non-essential listing attributes(e.g.
basement size or parking lot size).Table 2: Types and descriptions of named entities rel-evant to extracting listing information from commercialreal estate flyers.The problem of automatically extracting struc-tured information from real estate flyers was thenimplemented as a combination of the text catego-rization and NER tasks.3 Method3.1 DatasetThe dataset consists of 2,269 commercial real estateflyers submitted to a listing service3over a periodof one year.
It represents over 450 US locations,over 90 commercial real estate companies and over800 commercial real estate brokers.
The flyers weregenerated using different tools and formats and rep-resent a wide variety of styles.
Typically, the samebroker can represent properties of various categoriesand transaction types.
The text categorization wasevaluated using the full dataset of 2,269 flyers with5-fold cross validation.
For the NER task, we used60 percent of the flyers for training (a total of 1,361flyers), and the remaining 40 percent for testing (atotal of 908 flyers).All flyers (PDF and HTML) were converted toa common format (HTML)4.
The flyers were con-verted to text using an HTML parser and extract-ing DOM5text elements while preserving some ofthe white space formatting.
In some cases, text waspresented inside embedded images within the flyer.Since the majority of flyers, however, were mostly intext format, OCR6was not used and text within im-ages was discarded.
The median number of charac-ters, tokens, and sentences for flyers are 2106, 424,and 72 respectively.3.2 Training Data TransformationIn previous work, we have created a tool used toannotate HTML flyers and evaluated the NER taskon a subset of 800 manually annotated flyers.
How-ever, the manual annotation proved a laborious task(the same listing attribute typically appears multi-ple times in the document) and resulted in moder-ate inter-annotator agreement.
In this work, insteadof manually annotating the full set of 2,269 flyers,we used listing data entered by professional data en-3c?
BrokerSavant Inc.4PDFs were converted to HTML using the PDFTO-HTML conversion program http://pdftohtml.sourceforge.net/.
While the open-source tool oc-casionally misaligned text, performance was satisfactoryand the use of more accurate commercial PDF-to-HTML5conversion tool was deemed unnecessary.5Document Object Model.6Optical Character Recognition.285Figure 2: An example of a commercial real estate flyerand manually entered listing informationc?
ProMakerCommercial Real Estate LLC,c?
BrokerSavant Inc.try staff employed by the listing service7.
Figure 2shows an example of a real estate flyer and the cor-responding manually entered listing data.To generate a dataset for the text categorizationtasks we assigned the list of manually entered la-bels for transaction and property types to each flyer.For example, the flyer from Figure 2 was assignedto transaction type sale and property type industrial.To generate annotated data for the NER task, wehad to convert the stand-alone listing informationto annotated text in which each occurrence of thefield values was marked with the corresponding en-tity type via string matching.
The manually enteredlisting data, however, introduced some text varia-tions and did not always match the text in the cor-responding flyer.
For example, the same street andintersection address could be expressed in a varietyof ways (e.g.
?Westpark Drive and Main Street?
vs?Westpark Dr & Main St?
; ?123 North Main Road?vs ?123 N Main?, etc.).
Similarly, broker names,phones, and company names could have a variety ofalternative representations (e.g.
?Michael R. Smith?vs ?Mike Smith CCIM?
; ?Lee and Associates?
vs ?Lee& Associates of IL LLC?
; ?773-777-0000 ext 102?
vs?773.777.0000x102?, etc.).
Lastly, space size infor-mation was always entered in square feet, while atthe same time it could be expressed as both squarefeet and acres (with various precision points) in thecorresponding flyer (e.g.
53796 sf, 1.235 acres, 1.23acres, etc.
).To account for the various ways in which an at-tribute value can be expressed in the text we hand-7c?
BrokerSavant Inc.crafted a small set of rules and regular expressionsthat allowed us to find most of its alternative repre-sentations.
In some cases, however, the listing valuewas not found in the corresponding flyer text.
Inthe case of such a discrepancy, the flyer was sim-ply discarded from the training set used for the cor-responding named entity type.
Such discrepanciescould occur for several reasons.
In some cases, themanually hand-crafted rules and regular expressionsdid not cover all possible variants in which the valuecould be expressed.
On occasion, the text contain-ing the attribute value was in image format (insideembedded images).
We also noted a few instancesof incorrectly entered manual data.
As a result, onlya portion of the training data (a total of 1,361 fly-ers) was used for the training of individual namedentity types.
We were able to automatically annotate878 flyers used for training the address named en-tity recognizer (street or intersection, city, state, zip),1145 flyers used for training the broker informa-tion named entity recognizer (broker name, phone,email, company) and 1242 flyers for training thespace named entity recognizer (size and space type).3.3 Data Pre-processingAs mentioned earlier, all flyers (PDF and HTML)were converted to a common format (HTML).
AnHTML parser was then used to create a text repre-sentation of the flyer.
The text was tokenized and to-kens were normalized (all tokens were converted tolower case and digits were converted to a commonformat).As noted previously, data entry staff were able toquickly spot listing attributes of interest solely be-cause of their visual characteristics.
To account forsuch visual characteristics we included typographicand other visual features associated with tokens ortext chunks for both the text categorization and NERtasks.
Typographic and visual features were basedon the computed HTML style attributes for eachDOM element containing text.Computing the HTML style attributes is a com-plex task since they are typically defined by a combi-nation of CSS8files, in-lined HTML style attributes,and browser defaults.
The complexities of style def-inition, inheritance, and overwriting are handled by8Cascading Style Sheets.286browsers9.
We used the Chrome browser to dynam-ically compute the style of each DOM element andoutput it as inline style attributes.
To achieve this weprogrammatically inserted a javascript snippet thatinlines the computed style and saves the new ver-sion of the HTML on the local file system utilizingthe HTML5 saveAs interface10.
We then normalizedthe style attribute values for font size, RGB color,and Y coordinate as described in the following sec-tions.3.4 Text CategorizationThe text categorization task involves labeling all fly-ers with appropriate transaction types and propertytypes as shown in Table 1.
This is a multi-label clas-sification task as in all cases a flyer can have morethan one label (e.g.
Transaction Type: sale, lease;Property Type: retail, office).We applied a supervised Machine Learning ap-proach to the task utilizing Support Vector Machines(SVM) (Vapnik, 2000) using the LibSVM library(Chang and Lin, 2011).
SVM was a sensible choiceas it has been shown to be one of the top performerson a number of text categorization tasks (Joachims,1998; Yang and Liu, 1999; Sebastiani, 2002).Category information such as the transaction typeand property type are one of the key pieces of infor-mation in a flyer.
However, they are not always ex-plicitly mentioned in the flyer and in some cases thedata entry person needs to read the full content of theflyer to infer the property type.
For example, an in-dustrial property might be inferred by a mention ofa particular zoning category and description of load-ing docks; a retail property type might be inferred bymentions of retail neighbors (e.g.
Staples, Bed Bathand Beyond, etc) and traffic counts; an investmentproperty type can be inferred by description of NOI(net operating income) and Cap Rates (the ratio be-tween the NOI and capital cost of a property), etc.At the same time, when present, terms indicatingthe transaction and property types typically appearprominently in large fonts.
For example, the prop-9We attempted to use an HTML renderer from the Cobrajava toolkit http://lobobrowser.org/cobra.jsp tocompute HTML style attributes.
However, this renderer pro-duced poor results on our dataset and failed to accurately com-pute the pixel location of text elements.10https://github.com/eligrey/FileSaver.jserty type of the flyer shown on Figure 1 is promi-nently shown in large font (Restaurant indicates re-tail property type).
Similarly, the transaction typeof the flyer shown on Figure 2 is again prominentlydisplayed in a large font (For Sale).
The classifierscould then benefit from both the full text of the fly-ers, combined with some information of the visualprominence of individual words.We used ?bag-of-words?
representation (token un-igrams) and modeled the task as a binary classifica-tion for each category label.
As a term weightingscheme, we first used TF-IDF as one of the mostcommon weighting schemes used for term catego-rization (Lan et al, 2005; Soucy and Mineau, 2005).This served as a performance baseline.
To accountfor visually prominent characteristics of importantdocument terms we also introduced a term weightthat takes into account the relative font size of theterm.
As a measure of the relative font size, we usedthe percentile rank of the term font size, comparedto all term font sizes in the document.
For example,a weight of 0.9 is assigned to terms whose font sizeis greater than 90% of all tokens within the currentdocument.
The font size percentile was then used asa term weighting scheme (instead of TF-IDF).
Table3 summarizes the results of 5-fold cross validationusing the full dataset of 2,269 flyers.
We used a lin-ear kernel model with the default parameters.TF-IDF Font Size PctlProperty type P 79.57 85.04R 85.27 84.16F 82.32 84.6Transaction type P 87.56 89.64R 92.87 94.60F 90.14 92.05Table 3: Results from applying SVM on the task ofidentifying flyer Property Types (retail, office, industrial,land, multi-family) and Transaction Types (sale, lease, in-vestment).
We used ?bag-of-words?
representation (uni-grams) applying two different term weight schemes: TF-IDF and the relative percentile rank of the term font size.P=precision, R=recall, F=f1 score.In both text categorization tasks the Font Size Per-centile term weight significantly outperformed theTF-IDF term weight scheme11.11The difference is statistically significant with p value <0.05% using Z-test on two proportions.2873.5 Named Entity RecognitionA supervised machine learning approach was thenapplied to the task of identifying the named entitiesshown in Table 2.
The task was modeled as a BIOclassification task, classifiers identify the Beginning,the Inside, and Outside of the text segments.
Wefirst used a traditional set of text-based features forthe classification task.
Table 4 lists the various text-based features used.
In all cases, a sliding windowincluding the 6 preceding and 6 following tokenswas used as features.Feature Name DescriptionToken A normalized string representation ofthe token.
All tokens were convertedto lower case and all digits wereconverted to a common format.Token Orth The token orthography.
Possible valuesare lowercase (all token characters arelower case), all capitals (all tokencharacters are upper case), upper initial(the first token character is upper case,the rest are lower case), mixed (anymixture of upper and lower case lettersnot included in the previous categories).Token Kind Possible values are word, number,symbol, punctuation.Regex type Regex-based rules were used to markchunks as one of 3 regex types:email, phone number, zip code.Gazetteer Text chunks were marked as possibleUS cities or states based on US CensusBureau city and state data.www.census.gov/geo/maps-data/data/gazetteer2013.html.Table 4: List of text-based features used for the NER task.A sliding window of the 6 preceding and 6 following to-kens was used for all features.As noted previously, data entry staff were ableto quickly spot named entities of interest solely be-cause of their visual characteristics.
To account forsuch visual characteristics, we also included visualfeatures associated with text chunks.
We used thecomputed HTML style attributes for each DOM el-ement containing text.
Table 5 lists the computedvisual features and shows details on how we nor-malized the style attribute values for font size, RGBcolor, and Y coordinate.We then applied SVM on the NER task using theLibSVM library.
We again chose SVMs as theyhave been shown to perform well on a variety ofFeature Name DescriptionFont Size The computed font-size attribute ofthe surrounding HTML DOM element,normalized to 7 basic sizes (xx-small,x-small, small, medium, large, x-large,xx-large).Color The computed color attribute of thesurrounding HTML DOM element.The RGB values were normalizedto a set of 100 basic colors.
Weconverted the RGB values to theYUV color space, and then usedEuclidian distance to find themost similar basic colorapproximating human perception.Y Coordinate The computed top attribute of thesurrounding HTML DOM element, i.e.the y-coordinate in pixels.
The pixellocations was normalized to 150 pixelincrements (roughly 1/5th of thevisible screen for the most commonscreen resolution.
)Table 5: List of visual features used for the NER task.A sliding window of 6 preceding and 6 following DOMelements were used for all features.NER tasks, for example (Isozaki and Kazawa, 2002;Takeuchi and Collier, 2002; Mayfield et al, 2003;Ekbal and Bandyopadhyay, 2008).
We used a lin-ear kernel model with the default parameters.
Themulti-class problem was converted to binary prob-lems using the one-vs-others scheme.As described earlier, we used a portion of thetotal training data (a total of 1,361 flyers) for theNER tasks.
We were able to automatically annotateand use as training data 878 flyers used for addressnamed entities, 1,145 flyers used for broker infor-mation named entities, and 1,242 flyers for spacenamed entities.
Results were evaluated against themanually entered data for the full test set of 908flyers.
We first used the trained classifiers to findnamed entities, including their boundaries and types.The predicted named entities were then used to gen-erate listing data as follows.
For attributes that havea single value per flyer, we used the predicted namedentity of the corresponding type with the highestprobability estimate12.
Single value listing attributesare the fields of the listing address (street or inter-section, city, state, zip).
Flyers contain a single list-12We used the LibSVM probability estimates for each pre-dicted named entity.288ing, which in turn has a single address.
In contrast,broker information and space information are multi-value attributes.
A listing is typically representedby multiple brokers and can contain multiple spaces.To construct listing information in the case of multi-value attributes, we used all predicted named entitiesof the corresponding types.
The predicted listing in-formation was then compared to the gold standardof manually entered listing data.The construction of listing data (for comparisonwith manually entered data) resulted in a strict per-formance measure.
We consider an answer to becorrect only if both the entity boundaries and entitytype are accurately predicted.
In addition, in the caseof single value attributes, only the highest rankingnamed entity (based on estimated probabilities) wasretained.Results are shown in Table 6.
We compared per-formance of classifiers using only textual features(first 3 columns), versus performance using both tex-tual and visual features (next 3 columns).Named Entity Pt Rt Ft Pv+t Rv+t Fv+tBroker Name 93.3 81.2 86.9 95.9 85.5 90.4Broker Email 95.6 83.6 89.2 95.8 86.5 90.9Broker Phone 95.4 82.6 88.6 95.7 83.3 89.1Company Name 97.6 93.9 95.7 98.2 94.9 96.5Street 77.0 83.4 80.1 81.4 88.6 84.9City 88.1 96.1 91.9 92.0 98.3 95.0State 93.1 98.6 95.8 95.4 99.4 97.3Zip 92.0 86.7 89.3 96.3 86.4 91.1Space Size 76.8 57.9 66.0 80.1 65.7 72.2Space Type 66.7 62.6 64.6 68.8 66.7 67.8OVERALL 87.7 80.3 83.8 89.7 83.5 86.5Table 6: Results from applying SVM using the textualfeatures described in Table 4, as well as both the textualand visual features described in Tables 4 and 5. t=textualfeatures only, v+t=visual + textual features, P=Precision,R=Recall, F=F1-scoreThe addition of visual features significantly13in-creased the overall F1-score from 83.8 to 86.5%.Performance gains are more significant for namedentities that are typically visually salient and are oth-erwise difficult (or impossible) to identify in a text-only version of the flyers.
In particular, improve-ments were most significant for named entities refer-ring to space information.
A flyer typically describesmultiple spaces, however, only a few of these are13The difference is statistically significant with p value <0.05% using Z-test on two proportions.considered relevant for the purposes of listing ser-vices.
For example, the size of an office space is typ-ically entered, while the size of an office associatedwith a retail or industrial space is typically omitted.Similarly, lot size is included in building and landlistings, but excluded when the listing refers to a unit(or multiple units) within a building.
Essential spaceinformation is usually prominently displayed and asa result easy to identify.
Similarly, named entitiesreferring to address information also showed over-all significant improvement.
As noted earlier, theproperty address (vs other addresses in the flyer) istypically visually prominent.
In both cases, visualfeatures proved useful predictors.4 DiscussionIn both the text categorization and NER tasks per-formance improved significantly over the baselinewith the addition of typographic and visual features.However, in both cases, improvements were some-what moderate (around 3% on average).
Furtherimprovement could be achieved by including fea-tures that account for additional visual characteris-tics, such as a measure of how eye-catching or strik-ing the relative font color differences are, the per-ceived contrast between foreground and backgroundcolors, etc.In future work, we could also add to the overallsystem an image classification component.
It hasbeen noted that occasionally the only indicator ofthe property type of a flyer is present in embeddedflyer images and not present in the flyer text.
Forexample, a number of flyers display images of theinside and outside of restaurants, gas stations, shop-ping malls and thus specify the property type as re-tail without giving additional textual clues.
Simi-larly, an image of a warehouse, a land parcel, or anareal photo of a shopping center explicitly identifythe listing property type.Lastly, it should be noted that an overall systemperformance baseline is one that measures the aver-age performance of data entry staff in commercialreal estate listing services.
However, the terms andconditions of most listing services prohibit gather-ing and using data for such purposes.
We were ableto collect a very small set of listings (100 listings)289from several listing services14and evaluate the pre-cision of a limited set of listing fields.
We comparedthe values of manually entered listing fields againstthe associated flyer (considered to be the gold stan-dard).
The precision of property type, transactiontype, space type, and space size was measured as97%, 79%, 72%, and 73% respectively.
While re-sults are not conclusive, this preliminary evaluationsuggests that machine learning could achieve perfor-mance on par with the performance of manual dataentry.5 Related WorkA number of studies survey and compare termweighting schemes and feature selection methodsfor text categorization, for example (Salton andBuckley, 1988; Yang and Pedersen, 1997; Deboleand Sebastiani, 2004; Soucy and Mineau, 2005; Lanet al, 2005; Lan et al, 2009).
They describe super-vised and traditional term weighting schemes.
All,however, are only considering the textual informa-tion in documents such as the term frequency, thecollection frequency, combined with normalizationfactors, various information theory functions andstatistics metrics.A number of term weighting schemes have beensuggested for web retrieval and classification thatrely on the HTML DOM structure.
(Cutler et al,1997; Cutler et al, 1999; Riboni, 2002; Kwon andLee, 2000).
The idea is that terms appearing in dif-ferent HTML elements of a document may have dif-ferent significance in identifying the document (e.g.terms in HTML titles and headings vs HTML body).In our dataset, however, visually salient informa-tion does not fall into any distinctive HTML elementtype.
Instead all text is typically presented in div el-ements whose style characteristics are defined by anumber of css descriptors complicated by externalcss files, css inlining, style inheritance, and browserdefaults.Nadeau and Satoshi (2007) present a survey ofNER and describe the feature space of NER re-search.
While they mention multi-media NER in thecontext of video/text processing, all described fea-tures/approaches focus only on textual representa-14Due to data usage restrictions we were unable to collect alarger dataset or reveal the identity of the source listing services.tion.The literature on Information Extraction fromHTML resources is dominated by various ap-proaches based on wrapper induction (Kushmerick,1997; Kushmerick, 2000).
Wrapper inductions relyon common HTML structure (based on the HTMLDOM) and formatting features to extract structuredinformation from similarly formatted HTML pages.This approach, however, is not applicable to the gen-res of marketing materials (PDF and HTML) sincethey typically do not share any common structurethat can be used to identify relevant named entities.Laender et al (2002) present a survey of data extrac-tion techniques and tools from structured or semi-structured web resources.Cai et al (2003) present a vision-based segmenta-tion algorithm of web pages that uses HTML layoutfeatures and attempts to partition the page at the se-mantic level.
In (Burget and Rudolfova, 2009) au-thors propose web-page block classification basedon visual features.
Yang and Zhang (2001) build acontent tree of HTML documents based on visualconsistency inferred semantics.
Burget (2007) pro-poses a layout based information extraction fromHTML documents and states that this visual ap-proach is more robust than traditional DOM-basedmethods.Changuel et al(2009a) describe a system for au-tomatically extracting author information from web-pages.
They use spatial information based on thedepth of the text node in the HTML DOM tree.
In(Changuel et al, 2009b) and (Hu et al, 2006), theauthors proposed a machine learning method for ti-tle extraction and utilize format information such asfont size, position, and font weight.
In (Zhu et al,2007) authors use layout information based on fontsize and weight for NER for automated expense re-imbursement.None of the above studies, however, include com-puted HTML style attributes (as seen in browsers),and as a result are not applicable to the vast major-ity of web pages which do not rely on HTML layouttags or DOM-structure to describe style.6 ConclusionIn this study, we generated dataset and features fromavailable commercial real estate flyers and associ-290ated manually entered listing data.
This approachprecludes the need for manual linguistic annotationand instead relies on existing data available fromcommercial real estate listing services.
We modeledthe structured data extraction task as text catego-rization and NER tasks and applied machine learn-ing (SVM) on the automatically generated trainingdatasets.
The learned models were then applied onour test set and the predicted values were used toreconstruct listing data matching the manually en-tered fields.
Results suggest that this completelyautomated approach could substitute or enhance theexisting manual data entry workflows.In addition, we have shown that ubiquitous onlineformats such as PDF and HTML often exploit theinteraction of textual and visual elements.
Specifi-cally, in the marketing domain, information is oftenaugmented or conveyed by non-textual features suchas positioning, font size, color, and images.
We ex-plored the use of novel features capturing the visualcharacteristics of marketing flyers.
Results showthat the addition of visual features improved over-all performance significantly in the context of textcategorization and NER.ReferencesRadek Burget and Ivana Rudolfova.
2009.
Web page ele-ment classification based on visual features.
In Intelli-gent Information and Database Systems, 2009.
ACI-IDS 2009.
First Asian Conference on, pages 67?72.IEEE.Radek Burget.
2007.
Layout based information extrac-tion from html documents.
In Document Analysis andRecognition, 2007.
ICDAR 2007.
Ninth InternationalConference on, volume 2, pages 624?628.
IEEE.Deng Cai, Shipeng Yu, Ji-Rong Wen, and Wei-Ying Ma.2003.
Extracting content structure for web pagesbased on visual representation.
In Web Technologiesand Applications, pages 406?417.
Springer.Chih-Chung Chang and Chih-Jen Lin.
2011.
LIBSVM:A library for support vector machines.
ACM Transac-tions on Intelligent Systems and Technology, 2:27:1?27:27.
Software available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Sahar Changuel, Nicolas Labroche, and BernadetteBouchon-Meunier.
2009a.
Automatic web pages au-thor extraction.
In Flexible Query Answering Systems,pages 300?311.
Springer.Sahar Changuel, Nicolas Labroche, and BernadetteBouchon-Meunier.
2009b.
A general learning methodfor automatic title extraction from html pages.
In Ma-chine Learning and Data Mining in Pattern Recogni-tion, pages 704?718.
Springer.Michal Cutler, Yungming Shih, and Weiyi Meng.
1997.Using the structure of html documents to improve re-trieval.
In USENIX Symposium on Internet Technolo-gies and Systems, pages 241?252.Michal Cutler, Hongou Deng, SS Maniccam, and WeiyiMeng.
1999.
A new study on using html structures toimprove retrieval.
In Tools with Artificial Intelligence,1999.
Proceedings.
11th IEEE International Confer-ence on, pages 406?409.
IEEE.Franca Debole and Fabrizio Sebastiani.
2004.
Super-vised term weighting for automated text categoriza-tion.
In Text mining and its applications, pages 81?97.Springer.Asif Ekbal and Sivaji Bandyopadhyay.
2008.
Named en-tity recognition using support vector machine: A lan-guage independent approach.
International Journal ofComputer Systems Science & Engineering, 4(2).Yunhua Hu, Hang Li, Yunbo Cao, Li Teng, Dmitriy Mey-erzon, and Qinghua Zheng.
2006.
Automatic ex-traction of titles from general documents using ma-chine learning.
Information processing & manage-ment, 42(5):1276?1293.Hideki Isozaki and Hideto Kazawa.
2002.
Efficient sup-port vector classifiers for named entity recognition.
InProceedings of the 19th international conference onComputational linguistics-Volume 1, pages 1?7.
Asso-ciation for Computational Linguistics.Thorsten Joachims.
1998.
Text categorization with sup-port vector machines: Learning with many relevantfeatures.
Springer.Nicholas Kushmerick.
1997.
Wrapper induction forinformation extraction.
Ph.D. thesis, University ofWashington.Nicholas Kushmerick.
2000.
Wrapper induction: Ef-ficiency and expressiveness.
Artificial Intelligence,118(1):15?68.Oh-Woog Kwon and Jong-Hyeok Lee.
2000.
Web pageclassification based on k-nearest neighbor approach.In Proceedings of the fifth international workshop onon Information retrieval with Asian languages, pages9?15.
ACM.Alberto HF Laender, Berthier A Ribeiro-Neto, Altigran Sda Silva, and Juliana S Teixeira.
2002.
A brief surveyof web data extraction tools.
ACM Sigmod Record,31(2):84?93.Man Lan, Chew-Lim Tan, Hwee-Boon Low, and Sam-Yuan Sung.
2005.
A comprehensive comparativestudy on term weighting schemes for text categoriza-tion with support vector machines.
In Special interest291tracks and posters of the 14th international conferenceon World Wide Web, pages 1032?1033.
ACM.Man Lan, Chew Lim Tan, Jian Su, and Yue Lu.
2009.Supervised and traditional term weighting methodsfor automatic text categorization.
Pattern Analy-sis and Machine Intelligence, IEEE Transactions on,31(4):721?735.James Mayfield, Paul McNamee, and Christine Piatko.2003.
Named entity recognition using hundreds ofthousands of features.
In Proceedings of the sev-enth conference on Natural language learning at HLT-NAACL 2003-Volume 4, pages 184?187.
Associationfor Computational Linguistics.David Nadeau and Satoshi Sekine.
2007.
A survey ofnamed entity recognition and classification.
Lingvisti-cae Investigationes, 30(1):3?26.Daniele Riboni.
2002.
Feature selection for web pageclassification.
na.Gerard Salton and Christopher Buckley.
1988.
Term-weighting approaches in automatic text retrieval.
In-formation processing & management, 24(5):513?523.Fabrizio Sebastiani.
2002.
Machine learning in auto-mated text categorization.
ACM computing surveys(CSUR), 34(1):1?47.Pascal Soucy and Guy W Mineau.
2005.
Beyond tfidfweighting for text categorization in the vector spacemodel.
In IJCAI, volume 5, pages 1130?1135.Koichi Takeuchi and Nigel Collier.
2002.
Use of supportvector machines in extended named entity recognition.In proceedings of the 6th conference on Natural lan-guage learning-Volume 20, pages 1?7.
Association forComputational Linguistics.Vladimir Vapnik.
2000.
The nature of statistical learningtheory.
springer.Yiming Yang and Xin Liu.
1999.
A re-examination oftext categorization methods.
In Proceedings of the22nd annual international ACM SIGIR conference onResearch and development in information retrieval,pages 42?49.
ACM.Yiming Yang and Jan O Pedersen.
1997.
A comparativestudy on feature selection in text categorization.
InICML, volume 97, pages 412?420.Yudong Yang and HongJiang Zhang.
2001.
Html pageanalysis based on visual cues.
In Document Analy-sis and Recognition, 2001.
Proceedings.
Sixth Inter-national Conference on, pages 859?864.
IEEE.Guangyu Zhu, Timothy J Bethea, and Vikas Krishna.2007.
Extracting relevant named entities for auto-mated expense reimbursement.
In Proceedings ofthe 13th ACM SIGKDD international conference onKnowledge discovery and data mining, pages 1004?1012.
ACM.292
