Connective-based LocalCoherence Analysis: A Lexiconfor Recognizing CausalRelationshipsManfred StedeUniversity of Potsdam (Germany)email: stede@ling.uni-potsdam.deAbstractLocal coherence analysis is the task of deriving the (most likely) coher-ence relation holding between two elementary discourse units or, recur-sively, larger spans of text.
The primary source of information for thisstep is the connectives provided by a language for, more or less explic-itly, signaling the relations.
Focusing here on causal coherence relations,we propose a lexical resource that holds both lexicographic and corpus-statistic information on German connectives.
It can serve as the cen-tral repository of information needed for identifying and disambiguatingconnectives in text, including determining the coherence relations beingsignaled.
We sketch a procedure performing this task, and describe amanually-annotated corpus of causal relations (also in German), whichserves as reference data.221222 Stede1 Introduction?Text parsing?
aims at deriving a structural description of a text, often a tree in thespirit of Rhetorical Structure Theory (Mann and Thompson, 1988).
For automatingthis task (see, e.g., Sumita et al (1992); Corston-Oliver (1998); Marcu (2000)), thecentral source of information are the connectives that the author employed to moreor less specifically signal the type of coherence relation between adjacent spans.
Forillustration, consider this short text:1.Because well-formed XML does not permit raw less-than signs and ampersands, if you use a characterreference such as &#60; or the entity reference &lt; to insert the < character, the formatter willoutput &lt; or perhaps &#60;.Supposing that we are able to identify the connectives and punctuation symbols cor-rectly (here in particular: note that to is not a spatial preposition; distinguish betweencommas in enumerations and those finishing clauses), we can identify the ?scaffold?of this short text as the following:Because A, if B or C to D, E or Fwith A to F representing the minimal units of analysis.
Next, fairly simple rules willbe sufficient to guess the most likely overall bracketing of this string:(Because A, (if ((B or C) to D)), (E or F))And finally, it happens that the connectives because, if, to and or are quite reliable sig-nals of the coherence relations Reason, Condition, Purpose and Disjunction, respec-tively.
Combining this information with the bracketing, we can obtain a tree structurein spirit of RST.Texts of this level of complexity could be handled by early text parsers (see Sec-tion 2).
But, obviously, not too many texts behave as nicely as our example does.
Ingeneral, constructing a discourse tree is highly complicated even without trying to findsemantic/pragmatic labels for the relationships; the discussion by Polanyi et al (2004)demonstrates that just the structural decisions are often very difficult to make.
Takinga different viewpoint, this author argues in Stede (2008) that constructing ?the?
treestructure for a text should not be regarded as such an important goal and that coher-ence should rather be explained as the interplay of different levels of (possibly partial)description, such as referential and thematic structure, intentional structure, and a levelof local coherence analysis that records the clearly recognizable relationships betweenadjacent text spans but does not aim at constructing a complete and well-formed tree.In the present paper, this viewpoint is taken to the task of automatic analysis, whichaims at identifying individual coherence relations and the spans related.
We restrictourselves here to causal relationships and moreover to those that are explicitly sig-naled by a connective.
The central resource used in our approach is a lexicon thatcollects the information associated with individual connectives and makes it availableto applications such as a coherence analysis or text generation.The paper is organized as follows.
After reviewing some earlier research on textparsing in Section 2, we turn to connectives in Section 3 and point out a number ofproblems that sophisticated coherence analyzers have to reckon with.
Then, Section 4explains the connective lexicon we developed, and Section 5 describes a corpus wecollected and annotated manually for causal connectives and the relations they signal.1Source: http://www.cafeconleche.org/books/bible2/chapters/ch17.htmlConnective-based Local Coherence Analysis 223It serves as a reference for designing the analysis procedure, which is finally sketchedin Section 6.
Our analysis and implementation target German text, but most of thephenomena apply equally to English.2 Related WorkIn the late 1990s.
the best-known work on ?text parsing?
was that of Marcu, whichis collected in Marcu (2000).
He had used surface-based and statistical methods toidentify elementary discourse units, hypothesize coherence relations between adjacentsegments, and finally compute the most likely overall ?rhetorical tree?
for the text.Surface-based methods were highly popular at the time, but with the recent advancesin robust and wide-coverage sentence parsing, it seems sensible to cast local coherenceanalysis as a problem of linguistic analysis, drawing on the results of syntactic parsing(or even, on top of that, semantic analysis).An early approach in this spirit was implemented in the RASTA analyzer (Corston-Oliver, 1998).
It perused the output of the ?Microsoft English Grammar?
to guess thepresence of coherence relations on the basis of accumulated evidence from a varietyof more or less deep linguistic features.
For instance, a hypotactic clause would al-ways figure as the satellite of some nucleus-satellite relation in RST terms.
For somerelations (e.g., Elaboration), the type of referring expressions, especially in subjectposition, was considered a predictive feature.
In general, RASTA employed a set ofnecessary criteria for each relation to hold in a particular context, and for those rela-tions passing the filter, a voting scheme accumulated evidence to decide on the mostlikely relation.
The system worked on Encarta articles, hence on expository text; 13relations were being used.While RASTA employed a relation-centric approach, the recent work by L?ngenet al (2006) places the connectives at the center of the analysis, recording informationabout them in a specific lexicon (similar to our own earlier work (Stede, 2002)).
In thelexicon used by L?ngen et al, an entry consists of three zones: the identification zonegives the textual representation of the connective, its lemma and part-of-speech tag;the filter zone encodes necessary conditions for particular discourse relations, in theform of context descriptions; the allocation zone then specifies a default relation to beassumed if no other relation can be derived on the basis of further (soft) conditions.
Italso encodes constraints on the size of units to be related, the nuclearity assignment,and the information whether the segment including the connective attaches to the leftor to the right in the text.
Each entry gives rise to a rule used by a shift-reduce parserthat tries to build a complete rhetorical tree.
This parser works in close cooperationwith a module identifying logical document structure, and the context conditions spec-ified in lexicon entries often refer to this level of structure, or to a syntactic dependencyanalysis provided by the Connexor parser2.We share with these approaches (and with that of Polanyi et al (2004)) the desire toderive as much information about discourse relations as possible without resorting tonon-linguistic knowledge, so that the role of local coherence analysis in effect can beseen as extending the realm of robust sentence parsing.
Our approach is to representas much of the necessary information as possible in a declarative resource: a lexicon2http://www.connexor.com224 Stedeof connectives.3 Complications with ConnectivesConnectives are closed-class lexical items that can belong to four different syntacticcategories: coordinating and subordinating conjunction, adverbial, and preposition(such as despite or due to).
They have in common that semantically they denote two-place relations, and the text spans they relate can at least potentially be expressed asfull clauses (Pasch et al, 2003).
As mentioned in the beginning, they are not alwaysas easy to interpret as in our ?well-formed XML?
example.
In this section, we suggestan inventory of the complications that a thorough local coherence analysis procedureneeds to deal with.
We group them into four categories.Ambiguity.
Here we need to distinguish two kinds: (i) ambiguity as to whether aword is used as a connective or not, and (ii) ambiguity as to the semantic reading of aconnective.
Certain cases of (i) correspond to the distinction between ?sentential use?and ?discourse use?
that Hirschberg and Litman (1994) had proposed not for connec-tives but more generally for ?cue phrases?
in spoken language.
For example, Germandenn can be a coordinating conjunction (sentential use) or a particle often used inquestions without a recognizable semantic effect (discourse use).
Other cases of (i)reflect ambiguity between different ?sentential?
uses.
Sometimes this coincides with asyntactic difference (e.g., English as is a connective only when used as subordinator),but with many adverbials it does not (e.g., German daher can be a locative adver-bial ?from there?
or a causal adverbial ?therefore?).
Also, sometimes the distinctioncoincides with semantic scope, as with the focus particle / connective nur (?only?
):(1) Es war ein sch?ner Sommertag.
Nur die V?gel sangen nicht.
(?It was a nice summer day.
Only the birds weren?t singing.?
)In a narrow-scope reading of ?only?, the message is that everybody was singing exceptfor the birds; in a wide-scope reading, ?only?
connects the two sentences and signalsa restrictive elaboration.
Ambiguity of type (i) is more widespread than one mightthink; in Dipper and Stede (2006), we report that 42 out of 135 frequent Germanconnectives also have a non-connective reading, and we point out that many of theproblems cannot be handled with off-the-shelf part-of-speech taggers.Concerning ambiguity (ii), some connectives can have more than one semanticreading, which we regard as a difference in the coherence relation being signaled.Sometimes, the relation can be established on different levels of linguistic description(see, e.g., Sweetser (1990)).
For example, finally can be used to report the last onein a sequence of events, or it can be used by the author as a device for structuringthe discourse (?and my last point is...?).
Interestingly, the very similar German wordschlie?lich in addition has a third reading: It can also be an argumentative markerconveying that a presented reason is definitive or self-evident, which in English maybe signaled with ?after all?
: Vertraue ihr.
Sie ist schlie?lich die Chefin.
(?Trust her.She is the boss, after all.?
)Pragmatic features.
In addition to the relational differences, connectives can some-times be distinguished by more fine-grained pragmatic features, which are usually notmodeled as a difference in coherence relation.
A well-known case in point is the dif-ference between because and since (corresponding to German weil / da), where onlyConnective-based Local Coherence Analysis 225the latter has a tendency to mark the following information as hearer-old (not neces-sarily discourse-old).
The same pair of connectives serves to illustrate the feature ofnon-/occurrence within the scope of focus particles:(2) Nur weil/?da es regnet, nehme ich das Auto(?Only because/?since it?s raining, I take the car.?
)While in German, the da variant is hardly acceptable at all, in English there is a ten-dency for since to be interpreted in its temporal reading when used within the scopeof only.Also, connectives can convey largely the same information yet differ in terms ofstylistic nuances, for instance in degree of formality.
Thus a concessive relation inEnglish may be signaled in a standard way with although, or with a rather formal, andin that sense ?marked?
notwithstanding construction.Form.
While the majority of connectives consist of a single word, some of them havetwo parts.
Well-known instances are either .. or and if .. then.
For the German versionof the latter (wenn .. dann), a coherence analyzer must account for the possibilityof its occurring in reverse order: Dann nehme ich eben das Auto, wenn Du so bet-telst.
(?Then I?ll take the car, if you?re begging so much?.)
Further, looking at highlyfrequent collocations such as even though or even if, it is difficult to decide whetherwe are dealing with a single-word connective and a focus particle, or with a complexconnective; one solution is to check in such cases whether the meaning is in fact de-rived compositionally and then to prefer the focus particle analysis.
From ?regular?two-word connectives it is only a small step to the shady area of phrasal connectives,which can allow for almost open-ended variation and modification: for this reason /for these reasons / for all these very good reasons / ....For German, we have dealt with the issue of differentiating between types of multi-token connectives in a separate paper Stede and Irsig (2008).Discourse structure.
As is well-known, the structural description of a text can alsobemore complicated than in our ?well-formedXML?
example shown at the beginning.For one thing, discourse units can be embedded into one another, using parentheticalmaterial or appositions.
Further, connectives can occasionally link text segments thatare non-adjacent ?
a phenomenon that has been studied intensively by Webber et al(2003) and also by Wolf and Gibson (2005).
An example from Webber et al: Johnloves Barolo.
So he ordered three cases of the ?97.
But he had to cancel the orderbecause then he discovered he was broke.
Here, the then is to be understood as linkingthe discovery event back to the ordering event rather than to the (adjacent) canceling.In German, many adverbial connectives have an overt anaphoric affix (e.g., deswegen,daher, trotzdem), and the ability to link non-adjacent segments appears to be restrictedto these.
Non-adjacency also leads to the issue of crossing dependencies, which is alsodiscussed by the two teams of authors mentioned above.
It correlates with the problemof two connectives occurring in the same clause, as it happens in the Barolo example(because then), which renders the parsing task significantly more complex than in the?well-formed XML?
example.A different problem is to be found in situations where a single coherence relationis signaled twice, by two different connectives, where one typically is to be read cat-aphorically:226 Stede(3) Ich nehme deshalbi das Auto, weili Du so bettelst.
(?I take the car (for that reason)i becausei you?re begging so much.?
)This phenomenon is difficult to reproduce in English; again, in German it is alsolimited to a certain class of connectives that can serve as cataphoric ?correlates?.
Ob-viously, in such examples, a coherence analyzer will have to be very careful not tohypothesize two separate causal relationships.
The same danger applies when multi-ple causes are enumerated for the same consequence, or multiple consequences arisingfrom the same cause.
The mere insertion of the focus particle auch (?also?)
in example3 can fundamentally change the discourse structure to stating two reasons for takingthe car:(4) Es regnet sehr stark.
Ich nehme deshalb das Auto, auch weil Du so bettelst.
(?It?s raining heavily.
I therefore take the car, also because you?re begging somuch.?
)Finally, it is to be noted that certain connectives convey information about the dis-course structure beyond the local relation between two segments.
A case in point isthe first word of this paragraph, which not only makes a ?List?
or ?Enumeration?
rela-tion explicit, but also provides the information that this very list is now coming to anend.
A smart coherence analyzer could thus reduce the search space for linking thesubsequent text segment ?
it will definitely not be part of the same ?List?
configura-tion.4 A Rich Lexical Resource for ConnectivesFor building programs to perform local coherence analysis on texts that display thecomplexities discussed above, our approach is to clearly divide the labor betweena declarative connective lexicon on the one hand, and a flexible analysis procedureon the other.
In this section, we describe our Discourse Marker Lexicon (DIMLEX),whose first version was described in Stede (2002).
At the time, it was used for rela-tively simple text parsing as outlined at the beginning of the paper, and also for a lan-guage generation application.
The multi-functionality results from using a rather ab-stract XML encoding for the ?master?
lexicon, which is transformed by XSLT scriptsto the format needed by a specific application ?
both in terms of technical format(e.g., programming language) and the amount and granularity of information neededfor the application.
With our current focus on causal relations, we extended the DIM-LEX entries of the causal connectives to a richer scheme, which will gradually betransferred to the remaining connectives as well.It is not trivial to define an inventory of causal connectives, due to the grey areaof words marking a semantic relationship that readers can also interpret causally ?after all, causality is very often not explicitly signaled but being left for the reader toreconstruct.
For example, in The wind shook the shed for a few seconds, and thenit collapsed there certainly is causality involved in the relationship between the sen-tences, but we would not want to treat and or then as causal connectives.
With thehelp of the ?Handbook of German Connectives?
(Pasch et al, 2003), we determined aset of 66 German connectives that primarily convey causality.Connective-based Local Coherence Analysis 227The DIMLEX entries for these connectives consist of the following zones of infor-mation: (1) orthography, syntax, and structural features; (2) non-/connective disam-biguation rules; (3) semantic and pragmatic features, including information on dis-ambiguating different readings, and on role linking.
As for the type of information,entries contain both binary features and probabilities derived from corpus analyses.Orthography and syntax.
Orthographic variants that we store in the lexicon resultfrom the recent official German spelling reform and from frequent mistakes madeby speakers/authors (as found in corpora).
Also, we list both upper and lower casespellings because this difference plays a role in many disambiguation rules (see be-low).
Each variant has a unique identifier that is being used in those rules.
Also, oneof the variants is marked as ?canonical?
for co-reference purposes.
Here is a sampleexcerpt from the entry for aufgrund, corresponding to the English due to:<orth type="simple" canon="1" onr="k2v1"><part type="cont">aufgrund</part> </orth><orth type="complex" canon="0" onr="k2v2"><part type="cont">auf Grund</part> </orth><orth type="simple" canon="0" onr="k2v3"><part type="cont">Aufgrund</part> </orth><orth type="complex" canon="0" onr="k2v4"><part type="cont">Auf Grund</part> </orth>Each orth is of type ?simple?
or ?complex?, depending on the number of tokensinvolved.
For simple connectives (single tokens), the part type is always ?cont?
(continuous), whereas for complex connectives it may also be ?discontinuous?
if lin-guistic material can intervene between the parts (which is not the case for the twocomplex variants above).Syntactically, connectives can be subordinating conjunctions; Postponierer; pre-, post- and circumpositions; and adverbials, some of which can occur only in spe-cific positions (characterized in accordance with the Feldermodell that is often usedto describe German sentence structure in terms of Vorfeld, Mittelfeld, Nachfeld).
Weencode this information following the classification by Pasch et al (2003)), whoseprimary criterion is whether the connective can be integrated into the clause, and ifso, at what positions it can occur.
Here is the information for the prepositional adverb(?padv?)
dadurch (?by means of this?
):<padv><vorfeld>1</vorfeld><mittelfeld>1</mittelfeld><nacherst>0</nacherst><nachfeld>1</nachfeld><nullstelle>0</nullstelle><nachnachfeld>0</nachnachfeld><satzklammer>0</satzklammer></padv>The binary features say that the connective can be in the Vorfeld (preceding thefinite verb or auxiliary: Dadurch ist es geschehen), Mittelfeld (between auxiliary and228 Stedeverb: Es ist dadurch geschehen), and Nachfeld (following the verb phrase: Es istgeschehen dadurch).As a representation more directly usable for computational purposes, we also spec-ify patterns of the connective being situated in a syntax tree in TIGER format (Brantset al, 2004).
This format is used both in large hand-annotatedGerman corpora as wellas in an automatic parser3.
The idea of the patterns in the lexical entry thus is to findinstances of the word in a TIGER-tree, whether coming from a treebank or from aparser.
For illustration, here is the pattern for the complex connective so .. dass (?so ..that?
):(#avp:[cat="AVP"] > [lemma="so"])&((#avp > #s:[cat="S"])|((#avp > #cs:[cat="CS"]) &(#cs > #s:[cat="S"])))&(#s > [lemma=("dass")])This expression looks for an adverbial phrase (AVP) that dominates both so and a sen-tence (S), or a coordination of sentences (CS) that in turn dominate dass.
Between theso and dass, any material can intervene.
An examples matched by this expression inthe TIGER corpus is: Der Kanzler hat China so gern , da?
er ihm sogar die h?chstenBerge der Welt zu schenken verm?chte.
(?The chancellor likes China so much, that heeven wants to give the world?s highest mountains as a present to the country.?
)Besides the syntactic structure of individual conjuncts, we also need to representthe possibilities on linear order of the conjuncts.
This is also based on the terminologyof Pasch et al (2003), who distinguish between the internal conjunct (the clause orphrase that the connective syntactically belongs to) and the external one.
Sometimes,this a hard constraint: With the conjunction denn (causal ?for?
), the internal conjunctcan only follow the external one.
With other connectives, e.g., weil (?because?
), bothorderings are possible, i.e., the because-clause giving a reason can precede or followthe clause giving the effect.
In these cases we include probabilities derived from acorpus analysis, which the coherence analysis module can use for disambiguatingscope when it has no other information available.The syntactic representations become somewhat more complicated in case of com-plex connectives.
For instance, there is a variant of dadurch that co-occurs with a sub-sequent (but not necessarily adjacent!)
complement clause headed by dass (?that?
).Similarly, as shown in the previous section, certain causal conjunctions and adverbialscan co-occur and redundantly mark the same relation.
Our lexicon entries contain fea-tures representing those possible pairings.
For a more general discussion on Germancomplex connectives, see Stede and Irsig (2008).Finally, we include a feature stating whether the connective can be in the scope of afocus particle.
This information can sometimes support non-/connective disambigua-tion.3http://www.ims.uni-stuttgart.de/tcl/SOFTWARE/BitPar.htmlConnective-based Local Coherence Analysis 229Non-/connective disambiguation.
In Dipper and Stede (2006), we reported on anapproach to disambiguating non-/connective use for nine connectives by incremen-tally training a Brill tagger, which lead to F-measures of 81% (+connective) and 95%(?connective) in the best of four training scenarios.
During this work it became clearthat the part-of-speech context of the word often indeed provides enough informationfor making the decision.
The main reason why off-the-shelf taggers, however, do notperform very well is that tagsets do not reflect the distinction ?
recall the syntacticheterogeneity of the ?class?
of connectives.
From our findings we thus constructed foreach connective a set of patterns over part-of-speech and lemma information, leadingto regular expressions associated with probabilites (again gathered from corpus stud-ies).
These expressions become part of the DiMLex entries and can be used by the co-herence analyzer.
Starting from the Dipper/Stede results, we manually created classesof connectives with apparently-equivalent behavior, rather than studying each of the66 connectives in detail.
For illustration, here is the pattern set for daher, which canbe a causal connective (?therefore?)
or a locative adverb (?from there?
):<conn-disambi><pros><pro value="90" ref="k5v2"> $.
$$/PROAV </pro><pro value="90" ref="k5v1"> VVFIN $$/PROAV </pro></pros><cons><con value="99" ref="k5v1 k5v2">$$/PROAV $, {?dass?
}/KOUS</con><con value="95" ref="k5v2">$.
$$/PROAV .
* {?kommen?
?ruehren?}
.+ $, {?dass?
}/KOUS</con><con value="99" ref="k5v1"> $$/PROAV $.
</con></cons></conn-disambi>Weights range from 0 to 100, so 99 represents basically a strict rule.
Notice the refattribute, which restricts the rules to orthographic variants (in this case to upper andlower case ones).
The first two rules support a +connective reading: daher tagged aspronominal adverb (PROAV) following a full stop or a finite verb, respectively.
Thefollowing three rules support a ?connective reading: daher followed by the subordi-nating conjunction (KOUS) dass; occurring in a collocation like kommt daher, dass(?stems from?
); occurring before a full stop, i.e., sentence-final.Semantics and Pragmatics.
As stated earlier, we identify a difference in readingswith a difference in coherence relation signaled by the connective.
As for the in-ventory of relations, we take inspiration from Mann and Thompson (1988), Asherand Lascarides (2003), and especially for the causal relations, from the taxonomicapproach of Sanders et al (1992).
Not every distinction made in the literature canbe traced to connectives; so we do for instance not follow RST?s distinction between?Volitional Cause?
and ?Non-volitional Cause?
in DIMLEX.
But we find differences inconnective use for semantic versus pragmatic causal relations (Sanders et al, 1992).230 StedeFor instance, the denn used in (4) below is quite typical for pragmatic relations (see,e.g.
Pasch, 1989).
(5) Er wird bestimmt p?nktlich kommen, denn er ist doch immer so gewissenhaft.
(?Surely he will arrive on time, for he is always so assiduous.?
)Thus, in the realm of causality we use coherence relations labeled ?Argument-Claim?
(pragmatic) and ?Reason-Consequence?
(semantic).
Further, if the consequence is ayet-unrealized intended effect, we assign the relation ?Purpose?
as it has been sug-gested by Mann and Thompson (1988).
The connectives associated with Purpose aremostly quite specific (e.g., English in order to; German um .. zu), but there can alsobe ambiguity between Purpose and ?other?
causality (e.g., English so that; Germandamit).Disambiguation between the semantic and the pragmatic relation is usually verydifficult and thus a matter of heuristically weighing the evidence.
Similar to our han-dling non-/connective disambiguation (see above), we use a scheme of weight ac-cumulation for features indicating the presence of a relation.
For example, for theconnective schlie?lich we found that with the main verb of the clause elided, the prag-matic reading is very unlikely; on the other hand, if the verb is in present tense and theAktionsart is ?state?, it very likely signals the pragmatic ?Claim-Argument?
relation.Other evidence for this relation includes modal particles signaling the epistemic statusof the proposition(s), often in conjunction with present or future tense.
This is illus-trated in example 4 above, where the speaker expresses her confidence that the eventwill materialize with bestimmt (?surely?
), while doch a?in the second clause marks theinformation has hearer-old, so that the difference between claim and argument in thiscase is quite transparent.
Other features we modeled are inspired by the empiricalwork of Frohning (2007).
They include position, tense and aspect of the clause, moodand modality, and lexical collocations; Frohning derived their weights from corpusanalyses.Often, however, no compelling evidence for either of the three relations can befound, and for these cases we use a neutral relation called ?Cause-Caused?, which isthus meant to subsume the two others.In addition to relation(s), a lexicon entry specifies the role linking for connectives:the mapping from the syntactically internal or external conjunct (see above) to itsfunction in the relation.
We label these functions in accordance with the relations:?Argument?, ?Claim?, ?Reason?, and so forth.
Since causal relations are directed, andthe mapping cannot be predicted from syntactic features, it is crucial to represent thisinformation explictly.Besides, we use a number of more idosyncratic features to represent informationthat is relevant only for certain connectives, in particular to distinguish very similarones.
An example mentioned in the previous section is the information-structural dif-ference between weil (?because?)
and da (?since?).
For other families of connectives,this ?miscelleneous features?
section is more important; with temporal connectives,for instance, we specify in addition to the coarse-grained coherence relation morefine-grained distinctions such as whether the time spans of the related events meet ornot, etc.Connective-based Local Coherence Analysis 231Having discussed our treatment of syntax and semantics separately, we now haveto attend to the relationship between the two, i.e., to the issues of ambiguity and pol-ysemy.
The majority of connectives has one syntactic description and can conveyone or two similar coherence relations (the typical ambiguity between semantic andpragmatic reading).
We do, however, also find other configurations:?
Two syntactic descriptions: weil used to be a subordinating conjunction, but inspoken German is now widely accepted as a coordinating conjunction as well.Since the meaning is the same, it suffices to simply list both syntactic variantsin DIMLEX.?
One syntactic description, many coherence relations: When used as an adverb,the connective damit can signal Purpose (?so that?)
or Reason-Consequence(?thus?).
This situation is similar to the previous one: We provide a disjunctionof semantic readings (including the disambiguation information) and a singlesyntactic description.4?
Two syntactic descriptions, several coherence relations: These cases are theonly serious complications, as a difference in syntax can correlate with one insemantics, so that we cannot simply specify disjunctions for the syntactic andsemantic descriptions.
Instead, we use multiple lexical entries, in accordancewith the intuition that we are dealing with fairly unrelated items (polysemy).An example is dann (?then?
), which on the one hand is a temporal adverbial,and on the other hand can express a Condition relation (optionally with a corre-sponding wenn (?if?)
in the other clause).
In the latter case, it does not behaveas an adverb, though, but it governs a verb-second clause.
So, distributing theinformation across two separate lexicon entries seems to be appropriate.Finally, to enhance the maintainability of DIMLEX, we inlcude with the entriesa range of linguistic examples that illustrate the relevant distinctions, and we alsocitee information that is provided by standard dictionaries ?
especially in those caseswhere our formalization is not yet complete.
One of the XSLT scripts for convertingDIMLEX maps the base lexicon to an HTML format that allows for inspecting theentries, including the information just mentioned, which is intended for the humaneye rather than for automatic parsers or generators.5 A Corpus Annotated with Causal RelationsAs a preparatory step for implementing a local coherence analyzer that aims specifi-cally at identifying causal relations, we built a corpus with causal connectives anno-tated manually.
We selected 200 short texts from a product review web site5, wheretravelers comment on various tourist destinations.
Since they often give reasons forthe opinions they express, this genre offers more instances of causal connectives than,say, newspaper text.
On the other hand, there is the undeniable drawback of frequent4As a matter of fact, the situation is more difficult: Damit is one of the most complicated words inour lexicon, as it also has a reading as subordinator where it signals Purpose, as well as a non-connectiveadverbial reading (?with it/that?
).5http://www.dooyoo.de232 Stedemistakes in grammar and orthography, which makes any automatic analyis quite hard,and also sometimes poses challenges to the human annotator.Creating the corpus involved several steps.
First, potential causal connectives weresearched automatically (using the list from DIMLEX) and manually filtered.
Subse-quently, identifying causal connectives was not an issue for the annotation process, asthey were already presented to annotators as ?anchors?
for their task.
We then de-signed annotation guidelines with instructions for identifying causes and effects.
Asfor the length of spans, annotators were encouraged to prefer a shorter span in caseswhere the boundary of a cause or effect is not quite clear.
At the same time, they wereasked to mark two discontinuous spans in cases where a cause/effect was interruptedby extraneous material such as authors?
remarks on their own text production.
Thus,in the following example, the C1 and C2 indices mark the intended cause, and E theintended effect.
(6) [The beach was not very pleasant]E , as [it was,]C1 I just have to say this here,[utterly littered with remains of picnics.
]C2When multiple reasons are given for the same effect (or vice versa), annotators had tomark them separately, so that each cause-effect pair can be derived individually fromthe annotated data.
Sometimes this multiplicity can involve separate connectives, asin the following example.
In such cases, annotators had to choose a central connective(the one linking the adjacent cause and effect) and then add additional ones as sec-ondary connectives, possibly forming a chain.
This ensures easy retrievability of allpairs from the data.
(7) [We reached the hotel late]E [due to]Co1 [the flight?s delay]Ca and also[because]Co2 [it took so long to find a cab.
]CbFurther, annotators had to identify possible redundant markings of the same cause-effect pair (as with the cataphoric correlates discussed above) as well as focus particlesthat modify connectives.
Thus, in example (7), they would mark also and link it to themodified because.Our first version of the annotation guidelines was subject to an informal evalua-tion with annotators who had not been involved in the project.
On the basis of theresults we clarified several aspects in the guidelines and thus wrote the final version.Furthermore, we prepared two instructional videos: one for using the annotation toolMMAX26, and one for our specific annotation scenario, illustrating the handling of afairly complicated text passage.
In the formal evaluation with two annotators, they re-ceived no training other than by the guidelines and the two videos.
Of 78 connectives,34 were analyzed identically.
The vast majority of the mismatches (36 of 44) re-sulted from different span length: There was overlap between the spans chosen by theannotators, but the boundaries were not exactly identical.
Other mismatches, whichoccurred only a few times, included different decisions on secondary connectives andthe resulting chains of causes/effects.Finally, with the guidelines having become stable, experienced annotators createdthe ?official?
annotation of the entire corpus of 200 texts (containing some 1,2006http://mmax2.sourceforge.netConnective-based Local Coherence Analysis 233causal connectives).
It is now is available as a resource for training and evaluationof automatic procedures.
We also developed a web-based viewer (essentially translat-ing the MMAX2 format to HTML and Javascript) that allows for manually browsingthe corpus comfortably.76 Towards recognizing causal relations automaticallyHaving described DIMLEX as the central resource for local coherence analysis, andthe corpus as reference and evaluation tool, we now briefly sketch a procedure forrecognizing causal relations, whose implementation is currently under way in our textanalysis workbench (Chiarcos et al, 2008), a standoff XML architecture for fusinglinguistic annotations coming from different manual or automatic annotation tools.
Inthis highly modular approach, the output of each individual analysis module is storedin a separate layer, using our standoff XML format PAULA (Dipper, 2005).
Analysistools can use previously computed layers for their own task, which usually involvescreating one or more new layers.In this setting, the task of local coherence analysis involves the following layers.The first four are to be built in the pre-processing phase, and the last two are the resultof the coherence analyzer:1.
Token layer (including sentence boundaries)2.
Part-of-Speech3.
Logical document structure (headlines, paragraph breaks, etc.)4.
Dependency syntax analysis5.
Elementary discourse units6.
Connectives and (sets of) EDUs they relateThe procedure of coherence analysis consists of the following three sequentialsteps, which at various points make use of information from DIMLEX:Connective identification.
All the words listed in DIMLEX as some orthographicvariant of a causal connective are identified in the text.
This includes a check forcomplex connectives as listed in the lexicon, i.e., two correspondingwords in adjacentclauses (amongst others, the if .. then type).
It also includes a check for correlates,i.e., a connective that according to DIMLEX can be a correlate occurring in a clauseimmediately preceding a subordinate clause governed by a connective that accordingto DIMLEX can have a correlate (the deshalb .. weil type.
For these checks, the syntaxlayer (4) is used to identify adjacent clauses.Next, the single-word connective candidates are run through the disambiguationfilters, i.e., the PoS/token regular expressions specified in their lexical entries arematched against the text?s PoS representation on the corresponding layer (2).
Thoseitems that appear to be words in non-connective use are removed from the connectivelist.
Finally, a new layer (6) is created, for now holding only the words that wererecognized as connectives.7All material can be found at http://www.ling.uni-potsdam.de/~stede/kausalkorpus.html.234 StedeSegmentation.
The basic idea of our approach follows that of the module imple-mented by L?ngen et al (2006) for German.
We first overgenerate, guessing segmentboundaries at every possible position, according to the dependency parse result; then,contextual rules remove those boundaries that appear to be wrong (e.g., commas inenumerations).
We are, however, using somewhat different definitions of segments,namely a variant of Jasinskaja et al (2007), and the corpus annotated according tothose segmentation guidelines will be used to evaluate our module.
One issue wherewe diverge from both L?ngen et al and from Jasinskaja et al is in our handling ofprepositions: We do admit certain prepositional phrases as elementary discourse units,but only those that are headed by a preposition listed in DIMLEX, e.g., the causalmarkers wegen (?due to?)
or durch (?through?).
The resulting sequence of segments isrepresented on a new layer of analysis (5).Relation and scope identification.
Next, the connective layer (6) is extended withinformation on relations and scopes: Every connective is associated with one or moreattribute-value structures listing possible coherence relations along with probabilities.To this end, all relations stored with the connective in DIMLEX are recorded as hy-potheses, and weights are accumulated as the result of evaluating the associated dis-ambiguation rules, which largely operate on the syntax layer, as explained in Section 4.Finally, for each relation we also hypothesize its scope: the thematic roles are as-sociated with sequences of minimal units from layer (5).
Given a reliable syntacticanalysis, scope determination is usually straightforward for coordinating and subordi-nating conjunctions.
For adverbials, we hypothesize different solutions and rank themaccording to size: The most narrow interpretation is taken as most likely.
In this step,we also consider the layer of logical document structure in order to avoid segmentsthat would stretch across paragraphs or other kinds of boundaries.
Similarly, a layerwith the results of ?text tiling?
(breakdown of the text in terms of thematic units, in thetradition of Hearst (1994)) could be used for this purpose, as well as as an ?attribution?layer that identifies those modal contexts that attribute a span of text to a particularsource (as in indirect speech).In this way, the module will generate hypotheses of coherence relations and relatedspans, for the time being solely on the basis of connectives occurring in the text.
Asexplained, this information is represented in two additional analysis layers.
Modulesfollowing in the processing chain may combine the various hypotheses into the mostlikely overall relational tree structure for the paragraph (or a set of such tree struc-tures, see Reitter and Stede (2003)), or they may use the hypotheses directly for someapplication that does not rely on a spanning tree.7 DiscussionThe central idea behind the separation of the declarative DIMLEX resource and the (on-going) implementation of an analysis procedure is to facilitate a smooth extensibilityof the overall approach towards further kinds of connectives and coherence relations.When the lexicon is extended ?
while the underlying scheme remains unchanged?
coverage of the analyzer grows without adaptations to the analysis procedure.
Animportant benefit of the XML-based organization of the lexicon is its suitability for avariety of applications (parsing, generation, lexicography), which can each select fromConnective-based Local Coherence Analysis 235the master lexicon exactly those types of information that are relevant for them.
Onthe other hand, an obvious drawback of the present ?flat?
XML format is a relativelyhigh degree of redundancy.
The good reasons for introducing inheritance-based rep-resentation formalisms in ?standard?
computational lexicons of content words largelyapply to the realm of connectives (and possibly to other function words) as well.
Forthe time being, however, the more mundane task of lexical description still offers agreat many open questions for individual connectives and families thereof; the issueof more intelligent storage should become prominent later, when the groundwork hasstabilized.As with the vast majority of coherence relations, causal ones often need not beexplicitly signaled at the linguistic surface by a connective.
Thus the approach pro-posed in this paper will of course only partially solve the problem of local coherenceanalysis.
An important challenge for future work is to identify linguistic features ofdiscourse units other than connectives that can also serve to at least constrain the rangeof admissible coherence relations (see, e.g.
Asher and Lascarides, 2003).
Investigatingthese with empirical methods is an important next step in the overall program of par-tially deriving coherence relations in authentic text without resorting to non-linguisticknowledge.AcknowledgmentsThe following people from the Potsdam Applied Computational Linguistics Groupcontributed to the work described in this paper (in alphabetical order): Andr?
Herzog(causality corpus); Kristin Irsig (DiMLex entries for causal connectives); AndreasPeldszus (causality corpus and annotation guidelines); Uwe K?ssner (implementationof LCA module).ReferencesAsher, N. and A. Lascarides (2003).
Logics of Conversation.
Cambridge: CambridgeUniversity Press.Brants, S., S. Dipper, P. Eisenberg, S. Hansen, E. K?nig, W. Lezius, C. Rohrer,G.
Smith, and H. Uszkoreit (2004).
Tiger: Linguistic interpretation of a germancorpus.
Research on Language and Computation 2(4), 597?620.Chiarcos, C., S. Dipper, M. G?tze, J. Ritz, and M. Stede (2008).
A flexible frame-work for integrating annotations from different tools and tagsets.
In Proc.
of theFirst International Conference on Global Interoperability for Language Resources,Hongkong.Corston-Oliver, S. (1998).
Computing of Representations of the Structure of WrittenDiscourse.
Ph.
D. thesis, University of California at Santa Barbara.Dipper, S. (2005).
XML-based stand-off representation and exploitation of multi-level linguistic annotation.
In R. Eckstein and R. Tolksdorf (Eds.
), Proceedings ofBerliner XML Tage, pp.
39?50.236 StedeDipper, S. and M. Stede (2006).
Disambiguating potential connectives.
In M.
Butt(Ed.
), Proceedings of KONVENS ?06, Konstanz, pp.
167?173.Frohning, D. (2007).
Kausalmarker zwischen Pragmatik und Kognition.
Korpus-basierte Analysen zur Variation im Deutschen.
T?bingen: Niemeyer.
(Im Er-scheinen).Hearst, M. A.
(1994).
Multi-paragraph segmentation of expository text.
In Proceed-ings of the 32nd Meeting of the Association for Computational Linguistics, LasCruces/NM.Hirschberg, J. and D. J. Litman (1994).
Empirical studies on the disambiguation ofcue phrases.
Computational Linguistics 19(3), 501?530.Jasinskaja, K., J. Mayer, J. Boethke, A. Neumann, A. Peldszus, and K. J. Rodr?guez(2007).
Discourse tagging guidelines for German radio news and newspaper com-mentaries.
Ms., Universit?t Potsdam.L?ngen, H., H. Lobin,M.
B?renf?nger,M.
Hilbert, and C. Puskas (2006).
Text parsingof a complex genre.
In B. Martens and M. Dobreva (Eds.
), Proc.
of the Conferenceon Electronic Publishing (ELPUB 2006), Bansko, Bulgaria.L?ngen, H., C. Puskas, M. B?renf?nger, M. Hilbert, and H. Lobin (2006).
Discoursesegmentation of German written text.
In T. Salakoski, F. Ginter, S. Pyysalo, andT.
Phikkala (Eds.
), Proceedings of the 5th International Conference on NaturalLanguage Processing (FinTAL 2006), Berlin/Heidelberg/New York.
Springer.Mann, W. and S. Thompson (1988).
Rhetorical structure theory: Towards a functionaltheory of text organization.
TEXT 8, 243?281.Marcu, D. (2000).
The theory and practice of discourse parsing and summarization.Cambridge/MA: MIT Press.Pasch, R. (1989).
Adverbials?tze ?
kommentars?tze ?
adjungierte s?tze.
eine hy-pothese zu den typen der bedeutungen von ?weil?, ?da?
und ?denn?.
In W.
Motsch(Ed.
), Wortstruktur und Satzstruktur, Linguistische Studien des ZISW: Reihe A ?Arbeitsberichte 194, pp.
141?158.
Berlin: Akademie der Wissenschaften der DDR.Pasch, R., U. Brau?e, E. Breindl, and U. H. Wa?ner (2003).
Handbuch der deutschenKonnektoren.
Berlin/New York: Walter de Gruyter.Polanyi, L., C. Culy, M. van den Berg, G. L. Thione, and D. Ahn (2004).
A rulebased approach to discourse parsing.
In Proceedings of the SIGDIAL ?04 Work-shop, Cambridge/MA.
Assoc.
for Computational Linguistics.Reitter, D. and M. Stede (2003).
Step by step: underspecified markup in incrementalrhetorical analysis.
In Proceedings of the 4th International Workshop on Linguisti-cally Interpreted Corpora (LINC), Budapest.Sanders, T., W. Spooren, and L. Noordman (1992).
Toward a taxonomy of coherencerelations.
Discourse Processes 15, 1?35.Connective-based Local Coherence Analysis 237Stede, M. (2002).
DiMLex: A lexical approach to discourse markers.
In Exploringthe Lexicon - Theory and Computation.
Alessandria: Edizioni dell?Orso.Stede, M. (2008).
RST revisited: Disentangling nuclearity.
In C. Fabricius-Hansenand W. Ramm (Eds.
), ?Subordination?
versus ?coordination?
in sentence and text.Amsterdam: John Benjamins.Stede, M. and K. Irsig (2008).
Identifying complex connectives: Complications forlocal coherence analysis.
In A. Benz, P. K?hnlein, and M. Stede (Eds.
), Proceed-ings of the Workshop on Constraints in Discourse, Potsdam, pp.
77?84.Sumita, K., K. Ono, T. Chino, T. Ukita, and S. Amano (1992).
A discourse structureanalyzer for Japanese text.
In Proceedings of the International Conference on FifthGeneration Computer Systems, pp.
1133?1140.Sweetser, E. (1990).
From etymology to pragmatics.
Cambridge: Cambridge Univer-sity Press.Webber, B., M. Stone, A. Joshi, and A. Knott (2003).
Anaphora and discourse struc-ture.
Computational Linguistics 29(4), 545?587.Wolf, F. and E. Gibson (2005).
Representing discourse coherence: a corpus-basedstudy.
Computational Linguistics 31(2), 249?287.
