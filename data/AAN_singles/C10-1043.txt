Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 376?384,Beijing, August 2010Automatically Learning Source-side Reordering Rules for Large ScaleMachine TranslationDmitriy GenzelGoogle, Inc.dmitriy@google.comAbstractWe describe an approach to automaticallylearn reordering rules to be applied as apreprocessing step in phrase-based ma-chine translation.
We learn rules for 8 dif-ferent language pairs, showing BLEU im-provements for all of them, and demon-strate that many important order trans-formations (SVO to SOV or VSO, head-modifier, verb movement) can be capturedby this approach.1 IntroductionOne of the major problems of modern statisti-cal machine translation relates to its difficultiesin producing the correct word order on the targetside of the translation where the source side or-der is not the same as the target side.
In manycases where the translation is spectacularly bad, ifone only enters the source sentence in the word or-der of the target language the translation becomesnear-perfect (largely because the language modelcan now make sense of it).
The word order prob-lems are especially extensive for languages thathave major differences, such as SOV vs. SVOlanguages, but also cause insidious, but entirelyavoidable errors for the language pairs where theword order is almost right, but not quite1.
Forpractical reasons all phrase-based decoders limitthe amount of reordering allowed and thus arecompletely unable to produce correct translationswhen the necessary movement is over a large dis-tance.
Furthermore, where the actual systematicreordering for the two languages is within the de-coder?s search space, it is penalized just as any1For example of the latter kind, verb movement forEnglish-German and similar language pairs often causesverbs to be aligned to nothing and to be altogether droppedin translation.other kind of reordering, whereas doing anythingother than this systematic reordering should in factbe penalized.It has been argued that this is a fundamentalflaw in phrase-based decoding systems and hier-archical and syntax-based systems have been pro-posed to solve this problem.
These systems canin principle resolve a part of this problem, but ata significant time cost during training, and evenworse, during translation, making it less practicalfor realtime systems.
Instead we propose a systemfor learning pre-ordering rules automatically fromdata and demonstrate that it can capture many dif-ferent kinds of reordering phenomena and do so atno additional online cost.2 Related WorkMany solutions to the reordering problem havebeen proposed, e.g.
syntax-based models (Chi-ang, 2005), lexicalized reordering (Och et al,2004), and tree-to-string methods (Zhang et al,2006).
All these methods try to solve the reorder-ing problem in different ways, but have the fol-lowing problems in common: word alignment isnot affected by them and they tend to introducesignificant additional work to be done at transla-tion time.
Most state of the art systems use HMMor IBM Model 4 word alignment, both of whichhave a penalty term associated with long distancejumps, and tend to misalign words which move farfrom their expected positions.We are going to focus on the approaches wherereordering is done as a preprocessing step (some-times called pre-ordering).
These approacheshave the advantage that they are independent ofthe actual MT system used, are often fast to ap-ply, and tend to decrease (due to improved qualityof heuristic estimates) rather than dramatically in-crease the time spent in actual decoding, unlike376some of the previously mentioned approaches.The downside of these methods is that the reorder-ing is fixed, and if it is wrong it can hurt the qualityof translations.
We will discuss solutions for thisproblem later.Even in the relatively limited space ofpreprocessing-based reordering solutions, therehas been a large amount of previous work, as farback as Brown et al (1992).
Most approachesfocus on utilizing manually written rules for dif-ferent languages.
A common language pair forwhich rules were proposed is German-English(Nie?en and Ney, 2001; Collins et al, 2005).There is similar work for Chinese-English (Wanget al, 2007) and quite a few other languages.Clearly, such methods work quite well, but requirelinguistic expertise to produce.
Our goal, how-ever, is to learn reordering from parallel data thatis already available to an MT system in an entirelyunsupervised manner.We are not the first to attempt this task.
Inparticular, Xia and McCord (2004) proposed away to automatically learn reordering patterns forFrench-English.
Their system parses parallel databoth on the source and target side and then usesa variety of heuristics to extract reordering ruleswhich are then applied during training.
Morerecently, Li et al (2007) use a maximum en-tropy system to learn reordering rules for binarytrees (i.e., whether to keep or reorder for eachnode).
An approach most similar to ours is thatof Rottmann and Vogel (2007) where they learnreordering rules based on sequences of part-of-speech tags (but do not use parse trees).
All ofthese approaches show improvements in transla-tion quality, but are applied on a single languagepair.
Our goal is to find a method that workswell for many language pairs, regardless of theword order transformations needed, and withoutlanguage-specific tuning.
Unlike our predeces-sors, we use a systematic search through the spaceof possible permutation rules to minimize a spe-cific metric, related to the monotonicity of result-ing alignments.3 Our ApproachWe limit ourselves to reorderings of the sourceside of training and test data.
To constrain ourreorderings, we first produce a parse tree, usinga dependency parser similar to that of Nivre andScholz (2004).
The above parser is much fasterthan the time spent in translating the same sen-tence and thus creates almost no overhead.
Inour experiments where the source language is En-glish the training data for the parser is the PennTreebank (Marcus et al, 1993).
For German, weuse TIGER treebank (Brants et al, 2002).
Wethen convert the dependency tree to a shallow con-stituent tree.
The trees are annotated by bothPenn Treebank part of speech tags and by Stan-ford dependency types (de Marneffe et al, 2006;de Marneffe and Manning, 2008).
For an exam-ple, see Figure 1a.Our reorderings are constrained by reorderingof nodes in a parse tree of the source sentence.Thus, the full space of reorderings we considerconsists of all reorderings that would produce aparse tree with the same set of child-parent rela-tionships.
For an example of a valid reordering,see Figure 1b.Each reordering is described by a series ofrules and we learn one such series for each lan-guage pair automatically.
Each source sentence isparsed, and the tree is transformed sequentially,one rule at a time applying to the entire tree, topdown.
The reordered sentence is read off theleaves of the tree and training and evaluation pro-ceeds as normal.
We are using a state-of-the-artphrase-based statistical machine translation sys-tem to perform the actual translation.
The systemis itself capable of further local reordering duringtranslation limited by the maximum distance of 4words.3.1 Rule SpaceEach rule consists of two parts: conditioningcontext and action.
For every internal node inthe parse tree, traversed top-down, the node ismatched against the conditioning context, and if amatch is found, the associated action applies.
Allactions are limited to reordering children of thematching node.
Furthermore, if a rule applies at anode, its descendants are not traversed for the pur-pose of matching to avoid modifying the same partof the sentence twice by the same rule.
A differ-ent rule may apply on this node or its descendants377_VBDPRPInsubjVBDsawhead_NNdobjDTadetNNmanheadRBeasilyadvmod(a) A sample parse tree_VBDPRPInsubjVBDsawheadRBeasNoTadtmid_lldibjDyadevllmanhead(b) After reordering (moving RB over NN)Figure 1: Parse tree of a sentence and its reorderingFeature DescriptionnT POS tag of this nodenL Syntactic label of this nodepT POS tag of the parent of this nodepL Syntactic label of the parent1T POS tag of the first child1L Label of the first child2T POS tag of the second child2L Label of the second child... ...Table 1: Set of features used as conditioning vari-ableslater in the sequence.A conditioning context is a conjunction of con-ditions.
Each condition is a (feature, value) pair.List of features is given in table 1.
In practice,we limit ourselves to no more than 4 conditions ina given context to avoid combinatorial explosionand sparsity as well as contexts that fail to gen-eralize.
However, we may exhaustively generateevery possible conjunction of up to 5 conditionsfrom this list that covers up to 4 children that weactually observe in training.For example, the following contexts would bevalid for transformation in Fig.
1:?
nT = VBD?
1T = PRP?
1L = nsubj?
3T = dobj?
etc.or any conjunction of these.
The action performedin this example is swapping children 3 and 4 ofthe VBD node, and can be denoted as the permu-tation (1,2,4,3).When processing a rule sequence, once a ruleapplies, the action is performed, and that rule isno longer applied on the same node or its descen-dants (but can be further applied elsewhere in thetree).
Another rule (even an identical one) startsfrom the top and can apply to nodes modified byprevious rules.3.2 Reordering metricsTo evaluate the quality of a given reordering rule,we need to have reliable metrics that, for each sen-tence pair, can evaluate whether an improvementin monotonicity has been made.The easiest metric to use is the number of cross-ing alignment links for a given aligned sentencepair.
For instance, in Figure 2, there are 2 cross-ing links.
This metric is trivial to compute and hassome nice properties.
For instance, moving a sin-gle word one position out of place causes one link378I have a doghave?
dog?
I?Figure 2: Counting crossing alignment linksto cross, moving it farther away from its correctposition would cause more links to cross.
We willrefer to this metric as crossing score.An ideal metric would be the actual BLEUscore that the system would obtain under this re-ordering rule on the development set.
However,since each rule affects word alignment, phraseextraction, optimal feature weights, and the ac-tual translation, it would be necessary to retrainthe entire phrase-based system for each possiblerule, which is impractical.
It is, however, practi-cal, to retranslate the development set, keeping thephrase table and feature weights constant.
Nor-mally, however, phrase tables contain multi-wordphrases, such as ?a b?
which may no longer matchafter the reordering, and this biases the system to-ward the original word order.
To avoid this, forthis computation only, we use a phrase table thatonly contains single words and is therefore inde-pendent of the source sentence word order.
Thislets us test whether a given reordering improvesthe search space for the phrase-based decoder atthe relatively small computational cost of trans-lating the development set.
We obtain a differ-ence of the BLEU scores with and without a givenrule, which we hope to be a reasonable estimateof the true gain in BLEU score that one would ob-tain, by retraining the full system, including wordalignment, full-length phrase extraction, and tun-ing the feature weights.
We refer to this score asestimated BLEU gain.Note that these two scores are used to obtain anestimate of utility of any given rule, and are notused for evaluation of the entire system.
Thosemetrics are discussed in detail in the evaluationsection.3.3 AlgorithmWe propose a straightforward algorithm to au-tomatically learn reordering rules.
The inputdata for all algorithms is word-aligned sentencepairs.
We have found that sophisticated align-ment models introduce a bias toward alignmentbetween certain kinds of nodes (usually ones thatare close), and this has undesirable effects.
Inpractical terms this means that neither HMM norModel 4 alignments are useful (even though theyare better as alignments), but Model 1 alignmentsare.
However, to compensate for poor quality ofthe alignments, we simply delete those alignmentlinks that have posterior probabilities under 0.52and remove sentence pairs which have very fewalignments left.
The crossing score works quitewell even when only a portion of the words in asentence are aligned.The algorithm?s outline is given as Alg.
1.The algorithm proceeds by considering all rulesafter the best sequence of rules so far, and ap-pends the best new rule (according to the metric)to the sequence.
In practice, some changes areneeded, and we describe some variations.
Eachof these variations produces a different sequenceof rules, but they are interchangeable, and we cansimply pick one that performs best on the devel-opment set, or to combine them through multi-source translation or consensus.In all variations, we are unable to generate allpossible rules for every sentence, as the numbercan easily be 104-106 per sentence.
It is sufficient,however, to take a random sample of the input,extract top candidates, and reevaluate those on theentire set.We also limit the kinds of rules we are allowedto generate.
The number of possible actions on anode with n children is n!
?
1 and our trees arequite shallow, often containing 5, 6, or even morechildren per node.
To avoid dealing with explo-sion of rules and the resulting sparsity of the rulespace, we modify the process slightly, so that in-stead of matching a node, we match a node and aconsecutive subsequence of its children of a givensize, as a sliding window.
For example, in Figure1a, node VBD has 4 children.
If we limit our-2This guarantees only one alignment per word379Algorithm 1 Optimizing alignment linksinput: A set of aligned sentence pairsbase = <empty sequence>;for several iterations docandidate rules = GenerateAllCandidateRules(input, base);base.append(MinCost(candidate rules))end forselves to 3 children at a time we would attempt tomatch this node twice: with its children 1,2,3 and2,3,4.
In other words, we pretend to consider twonodes, one with the first set of children, and onewith the second, proceeding left to right.
If eitherone matches, we apply the action to the subset ofchildren in the window and stop processing thenode further.It is also useful to produce more than one ruleper iteration, although this can be problematic,since the rules may interfere with each other.3.3.1 Variant 1: Optimizing crossing scoreWe start with the initially empty base sequence.As described above, we generate every possiblerule from a subset of sentences, and evaluate themon the entire input, with the base sequence alwaysapplied first.
We use crossing score as a met-ric.
However, instead of extracting only one best-scoring rule, we extract K best.
Now we need toobtain a decorrelated set: for every pair of rules,we count the number of sentences where they bothapply.
For every rule we consider all rules that areranked higher, and if the percentage of matchesbetween these two rules is high, the rules mayinterfere with each other, and the current rule isdropped.
We thus obtain a small ordered set ofrules that tend to apply on different sentences, andshould not interfere with each other.
From thisordered set we produce all candidate rule subse-quences and evaluate them, to ensure there reallyis no interference.
The one with the best score isthen appended to the base sequence.
The processis then repeated with a new base sequence.3.3.2 Variant 2: Optimizing EstimatedBLEU gainWe proceed as in the previous variant, but finalevaluation of potential sequences to be appendedis done differently.
Instead of using a crossingscore, we reorder the development set with eachcandidate rule sequence and score it using a trans-lation system with a fixed phrase table with sin-gle word phrases only (to avoid bias for a spe-cific word order).
The sequence with the highestBLEU is then appended to base sequence, and theprocess is repeated.3.3.3 Variant 3: Optimizing EstimatedBLEU gain in sequenceIn this variant, once we obtain a set ofdecorrelated candidate rules {a1, a2, .
.
.
an} or-dered by crossing score, we evaluate the fol-lowing rule sequences (where b is base se-quence): (b), (b, a1), (b, a1, a2) .
.
.
(b, a1, .
.
.
an)using estimated BLEU gain, as above.
If wefind that for some k, score(b, a1, .
.
.
ak?1) >score(b, a1, .
.
.
ak?1, ak), that means that ak in-terferes with preceding rules.
We remove allsuch ak, and retranslate/rescore until the score se-quence is monotonically non-decreasing.
At thispoint, we append all surviving rules to the basesequence, and repeat the process.4 EvaluationAs described above, our base system is a phrase-based statistical MT system, similar to that ofOch and Ney (2004).
The baseline decoder iscapable of local reordering of up to 4 words.Our training data is extracted by mining from theWeb, as well as from other published sources.We train systems from English to 7 other lan-guages, as well as German-English.
We chosethem as follows: SOV languages (Japanese, Ko-rean, Hindi), VSO language (Welsh), long dis-tance verb movement (German), noun-modifierissues (Russian and Czech).
The amount of train-ing data varies from 28 million words (for Hindi)to 260 million (for German).
The baseline sys-380tem is a production-quality system used by a largenumber of users.For the first set of experiments for German-English and English-German we use WMT-09data sets for development and testing (Callison-Burch et al, 2009).
We report BLEU scores foreach of the algorithms along with the best scorefrom the WMT-09 workshop for reference in Ta-ble 2.Unfortunately, there is no standard data set formost of the languages we would like to experi-ment with.
For the second set of experiments, weuse an unpublished data set, containing data in En-glish and 7 languages mentioned above.
Our testdata comes from two sources: news articles fromWikiNews3 (996 sentences) and a set of randomsentences from the web (9000 sentences).
Fromthese, we create 3 sets: dev1: 3000 sentences fromweb and 486 sentences from wiki; dev2: 1000 sen-tences from web; and test: the remainder of web(5000 sentences) and wiki (510 sentences).
Thedev1 set is used for tuning the system, both dev1and dev2 for tuning consensus, and the test set forevaluation.
These sets are the same for all 7 lan-guages.Discriminative minimum error rate training(Macherey et al, 2008) was applied to optimizethe feature weights for each system.We evaluate the three variants of the algorithmmentioned above.
Each algorithm outputs a re-ordering rule sequence (40-50 rules long) whichis applied to all the training and test data, and acomplete system is trained from scratch.There is no need for us to pick a single al-gorithm for all language pairs, since each algo-rithm produces rules that are compatible with eachother.
We are able to pick the algorithm that worksbest on the development set for each languagepair.In addition, we can use a decoder that is capa-ble of performing a multi-input translation whichis given the unreordered input as well as the threereordered inputs produced by the above algorithm.This decoder is able to learn separate featureweights for each feature/algorithm combination.Finally, we can use consensus translation3http://en.wikinews.orgTable 4: Manual vs. automatic reordering.
Auto-matic score is the combined score from Table 3.Language Base Manual Auto-maticDiffHindi 16.85 19.25 19.36 0.11Japanese 25.91 28.78 29.12 0.34Korean 23.61 27.99 27.91 -0.08(Macherey and Och, 2007) to produce the bestpossible translation for each sentence.Results using BLEU score (character-level forJapanese and Korean, word-level for other lan-guages) for English to X systems are given in Ta-ble 3, along with the score of Google Translate asof Feb 15, 2010, for expected quality reference.All gains in the combined and consensus columnsare statistically significant using a bootstrap re-sampling test (Noreen, 1989).We should also note that the parsing and re-ordering overhead was an average of 10msec persentence, and had no appreciable impact on thespeed of the system.4.1 Comparison with manual reorderingWe also compared our automatic method with amanually written reordering rule set for SOV lan-guages (Xu et al, 2009) (rules initially written forKorean) for comparison with our approach.
Theresults are given in Table 4.
The results are mostlycomparable, with automatic rules being better fortwo of the three languages.4.2 Turning off decoder reorderingAll of the above experiments allowed the decoderto further reorder the sentence as needed.
Re-ordering in the decoder creates an exponential in-crease in the search space, and for a typical de-coding strategy can lead to increase in decodingtime, search errors, or both.
Since we already pre-order the sentence, it should be possible to avoidreordering in the decoder altogether.Results for the combined decoder are given inTable 5.
It contains the gain of the combined de-coder against the baseline from Table 3, and thegain when decoder reordering is turned off againstthe same baseline (which has decoder reorderingon).
For many languages it is indeed now possi-381Table 2: Results for 3 algorithms on WMT-09 data with best individual system score from the workshop:for EN to DE, Edinburgh, for DE to EN, GoogleLanguage Base Var.
1 Var.
2 Var.
3 Best workshopEN to DE 16.09 16.30 16.35 16.40 14.76DE to EN 21.00 22.45 22.13 22.05 20.23Table 3: Results on internal test set for 3 systems (Variant 1,2,3), the variant which performed best onthe development set, the combined system, and the consensus run, along with Google Translate scores(Feb 15, 2010) for referenceLanguage Google Base Var.
1 Var.
2 Var.
3 Best on dev Combined Consensus%BLEU %BLEU gain gain gain gain gain gainCzech 16.68 15.35 -0.08 0.13 0.19 0.19 0.21 0.21German 20.34 18.65 0.47 0.30 0.39 0.39 0.72 0.73Hindi 19.15 16.85 2.25 2.08 0.15 2.08 2.51 2.47Japanese 30.74 25.91 3.05 2.60 3.05 3.05 3.21 3.03Korean 27.99 23.61 3.34 3.77 4.16 4.16 4.30 4.30Russian 16.80 15.33 0.08 0.10 0.10 0.08 0.14 0.23Welsh 27.38 25.48 1.25 0.77 1.43 1.43 1.34 1.63Table 5: Disallowing decoder reordering: differ-ence against baseline in %BLEU gainLanguage DecoderreorderingNo decoderreorderingCzech 0.21 0.08German 0.72 0.55Hindi 2.51 2.27Japanese 3.21 3.21Korean 4.30 4.15Russian 0.14 -0.10Welsh 1.34 0.98ble to avoid decoder reordering altogether whichleads to a significant speedup.5 AnalysisWe looked at the rules being learned as well as atthe differences in the output to see if the gains inBLEU are in fact due to the reordering phenomenabeing resolved.
The top rules for each languageare given in Table 6.One can observe that the top rules for Germanand Slavic languages are as expected: verb move-ment and noun modifier reordering.
Other toprules for German cover other specific cases of verbmovement, other rules for Czech include, for ex-ample, movement of the subject of the passivesentence to the right and movement of the pos-sessive (which is similar to the noun compoundcase).The rules for Welsh include movement of theadjective modifier over its head (given in the ta-ble above) and other rules moving noun modifiers,moving a modal verb left over its subject, movingdeterminers to the right of nouns, etc.For Japanese and Korean, there are many ruleswith dramatic impact, such as a rule moving allheads to the right, reversing a sequence of threenodes starting with a modal (e.g.
can do some-thing to something do can), moving numericalmodifiers to the right of their heads, and many oth-ers.Hindi is also an SOV language, but its gram-mar is not as similar to Japanese or Korean as theyare to each other.
Still, Hindi also has some simi-lar rules, but there are many more involving verbmovement, such as a rule directly moving the verbto the final position.By looking at the sentences produced by thesystem we can see that the differences are dra-matic for SOV and VSO languages, as expected,382Table 6: Examples of top rules and their applicationLanguages Context Order ExampleHindi 1L:head 3L:none 2,1,3 I see him?
I him seeJapanese, Korean 2L:prep 2,1 eat with a spoon?
eat a spoon withGerman 1T:VBN 2L:prep 2,1 struck with a ball?
with a ball struckRussian, Czech 1L:nn 2L:head 2,1 a building entrance?
a entrance buildingWelsh 1L:amod 2L:head 2,1 blue ball?
ball bluebut more interestingly, most German sentencesnow have a verb where the baseline had none.
An-other profound effect can be observed for Rus-sian: the baseline almost invariably translatednoun compounds incorrectly: e.g.
group leadersmay be translated as group of-leaders since thisrequires no reordering and no preposition inser-tion.
This is especially problematic, since the userof the translation system often cannot detect this:the resulting sentence is not ungrammatical andcan even make sense.
Our algorithm learns a rulethat prevents this from happening.
Now the de-coder must pay a cost to keep the order the sameas in English.6 Discussion and Future WorkWe have demonstrated a general technique whichrequires only access to a parser for the source lan-guage (in addition to parallel data which alreadyexists for an MT system) and is capable of re-ducing reordering problems endemic in a phrase-based system.
No linguists or even native speakersof any of these languages were needed to write therules.
The algorithm is quite robust and performswell on noisy web data, much of it being ungram-matical.All variants turned out to perform well, al-though variants 1 and 3 were better most of thetime.
We consider all variants to be useful, sincethey find different local maxima under differentobjective functions, and in practice use all of themand pick a rule sequence that performs best on thedevelopment set for any specific language pair.We plan to explore this research area further inseveral ways.
First, it would be interesting to ex-periment with applying rules learned for one lan-guage to a related language, e.g.
Portuguese forSpanish or German for Dutch.
This would let ususe rules learned from a major language for a mi-nor one with less available training data.We have only used English and German assource languages.
There is training data forparsers in other languages, and this approachshould work well for most source languages.Where a source language parser is not available,we can still improve quality, by learning rulesfrom the target side and applying them only for thepurpose of improving word alignment.
Improv-ing word alignment alone would not help as muchas also using the reordering in the decoder, but itwill probably help in extracting better phrases.
Wealso plan to use parser projection to induce a rea-sonable quality parser for other languages.ReferencesSabine Brants, Stefanie Dipper, Silvia Hansen, Wolf-gang Lezius, and George Smith.
2002.
The tigertreebank.
In In Proceedings of the Workshop onTreebanks and Linguistic Theories, pages 24?41.Peter F. Brown, Stephen A. Della, Pietra Vincent,J.
Della Pietra, John D. Lafferty Robert, and L. Mer-cer.
1992.
Analysis, statistical transfer, and syn-thesis in machine translation.
In Proceedings ofthe Fourth International Conference on Theoreticaland Methodological Issues in Machine Translation,pages 83?100.Chris Callison-Burch, Philipp Koehn, Christof Monz,and Josh Schroeder.
2009.
Findings of the 2009Workshop on Statistical Machine Translation.
InProceedings of the Fourth Workshop on StatisticalMachine Translation, pages 1?28, Athens, Greece,March.
Association for Computational Linguistics.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of the ACL?05, pages 263?270, Ann Arbor,Michigan, June.Michael Collins, Philipp Koehn, and Ivona Kucerova.2005.
Clause restructuring for statistical machine383translation.
In Proceedings of the ACL?05, pages531?540, Ann Arbor, Michigan, June.Marie-Catherine de Marneffe and Christopher D. Man-ning.
2008.
The Stanford typed dependencies rep-resentations.
In COLING?08 Workshop on Cross-framework and Cross-domain Parser Evaluation,Manchester, England, August.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure trees.
InLREC.Chi-Ho Li, Minghui Li, Dongdong Zhang, Mu Li,Ming Zhou, and Yi Guan.
2007.
A probabilisticapproach to syntax-based reordering for statisticalmachine translation.
In Proceedings of the ACL-07,pages 720?727, Prague, Czech Republic, June.Wolfgang Macherey and Franz J. Och.
2007.
An em-pirical study on computing consensus translationsfrom multiple machine translation systems.
In Pro-ceedings of the EMNLP-CoNLL?07, pages 986?995,Prague, Czech Republic, June.Wolfgang Macherey, Franz Och, Ignacio Thayer, andJakob Uszkoreit.
2008.
Lattice-based minimum er-ror rate training for statistical machine translation.In Proceedings of the EMNLP-2008, pages 725?734, Honolulu, Hawaii, October.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of english: The Penn Treebank.
Computa-tional Linguistics, 19(2):313?330.Sonja Nie?en and Hermann Ney.
2001.
Morpho-syntactic analysis for reordering in statistical ma-chine translation.
In Machine Translation Summit,pages 247?252, Santiago de Compostela, Spain,September.Joakim Nivre and Mario Scholz.
2004.
Deterministicdependency parsing of English text.
In Proceedingsof Coling 2004, pages 64?70, Geneva, Switzerland,Aug 23?Aug 27.
COLING.Eric W. Noreen.
1989.
Computer-Intensive Meth-ods for Testing Hypotheses.
John Wiley & Sons,Canada.Franz Josef Och and Hermann Ney.
2004.
The align-ment template approach to statistical machine trans-lation.
Computational Linguistics, 30(4):417?449.Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,Anoop Sarkar, Kenji Yamada, Alex Fraser, ShankarKumar, Libin Shen, David Smith, Katherine Eng,Viren Jain, Zhen Jin, and Dragomir Radev.
2004.A smorgasbord of features for statistical machinetranslation.
In HLT-NAACL 2004: Main Proceed-ings, pages 161?168, Boston, Massachusetts, USA,May 2 - May 7.Kay Rottmann and Stephan Vogel.
2007.
Word re-ordering in statistical machine translation with apos-based distortion model.
In Proceedings of TMI,Skovde, Sweden.Chao Wang, Michael Collins, and Philipp Koehn.2007.
Chinese syntactic reordering for statisticalmachine translation.
In Proceedings of the EMNLP-CoNLL?2007, pages 737?745, Prague, Czech Re-public, June.Fei Xia and Michael McCord.
2004.
Improving astatistical MT system with automatically learnedrewrite patterns.
In Proceedings of Coling 2004,pages 508?514, Geneva, Switzerland, Aug 23?Aug27.
COLING.Peng Xu, Jaeho Kang, Michael Ringgaard, and FranzOch.
2009.
Using a dependency parser to improveSMT for subject-object-verb languages.
In Pro-ceedings of NAACL-HLT?09, Boulder, Colorado.Hao Zhang, Liang Huang, Daniel Gildea, and KevinKnight.
2006.
Synchronous binarization for ma-chine translation.
In Proceedings of the HumanLanguage Technology Conference of the NAACL,Main Conference, pages 256?263, New York City,USA, June.
Association for Computational Linguis-tics.384
