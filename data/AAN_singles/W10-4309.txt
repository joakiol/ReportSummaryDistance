Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 55?58,The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational LinguisticsTowards Semi-Supervised Classification of Discourse Relations usingFeature CorrelationsHugo Hernault and Danushka Bollegala and Mitsuru IshizukaGraduate School of Information Science & TechnologyThe University of Tokyo7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japanhugo@mi.ci.i.u-tokyo.ac.jpdanushka@iba.t.u-tokyo.ac.jpishizuka@i.u-tokyo.ac.jpAbstractTwo of the main corpora available fortraining discourse relation classifiers arethe RST Discourse Treebank (RST-DT)and the Penn Discourse Treebank (PDTB),which are both based on the Wall StreetJournal corpus.
Most recent work us-ing discourse relation classifiers have em-ployed fully-supervised methods on thesecorpora.
However, certain discourse rela-tions have little labeled data, causing lowclassification performance for their asso-ciated classes.
In this paper, we attemptto tackle this problem by employing asemi-supervised method for discourse re-lation classification.
The proposed methodis based on the analysis of feature co-occurrences in unlabeled data.
This in-formation is then used as a basis to ex-tend the feature vectors during training.The proposed method is evaluated on bothRST-DT and PDTB, where it significantlyoutperformed baseline classifiers.
We be-lieve that the proposed method is a firststep towards improving classification per-formance, particularly for discourse rela-tions lacking annotated data.1 IntroductionThe RST Discourse Treebank (RST-DT) (Carl-son et al, 2001), based on the Rhetorical Struc-ture Theory (RST) (Mann and Thompson, 1988)framework, and the Penn Discourse Treebank(PDTB) (Prasad et al, 2008), are two of the mostwidely-used corpora for training discourse rela-tion classifiers.
They are both based on the WallStreet Journal (WSJ) corpus, although there aresubstantial differences in the relation taxonomyused to annotate the corpus.
These corpora havebeen used in most of the recent work employ-ing discourse relation classifiers, which are basedon fully-supervised machine learning approaches(duVerle and Prendinger, 2009; Pitler et al, 2009;Lin et al, 2009).Still, when building a discourse relation clas-sifier on either corpus, one is faced with thesame practical issue: Certain relations are veryprevalent, such as ELABORATION[N][S] (RST-DT), with more than 4000 instances, whereasother occur rarely, such as EVALUATION[N][N]1(RST-DT), with three instances, or COMPARI-SON.PRAGMATIC CONCESSION (PDTB), with 12instances.
This lack of training data causes poorclassification performance on the classes associ-ated to these relations.In this paper, we try to tackle this problem byusing feature co-occurrence information, extractedfrom unlabeled data, as a way to inform the classi-fier when unseen features are found in test vectors.The advantage of the method is that it relies solelyon unlabeled data, which is abundant, and cheapto collect.The contributions of this paper are the follow-ing: First, we propose a semi-supervised methodthat exploits the abundant, freely-available un-labeled data, which is harvested for feature co-occurrence information, and used as a basis to ex-tend feature vectors to help classification for caseswhere unknown features are found in test vec-tors.
Second, the proposed method is evaluatedon the RST-DT and PDTB corpus, where it signif-icantly improves F-score when trained on moder-ately small datasets.
For instance, when trained ona dataset with around 1000 instances, the proposedmethod increases the macro-average F-score up to30%, compared to a baseline classifier.2 Related WorkSince the release in 2002 of the RST-DT corpus,several fully-supervised discourse parsers have1We use the notation [N] and [S] respectively to denotethe nucleus and satellite in a RST discourse relation.55been built in the RST framework.
In duVerle andPrendinger (2009), a discourse parser based onSupport Vector Machines (SVM) (Vapnik, 1995)is proposed.
Shallow lexical, syntactic and struc-tural features, including ?dominance sets?
(Soricutand Marcu, 2003) are used.The unsupervised method of Marcu and Echi-habi (2002) was the first to try to detect ?implicit?relations (i.e.
relations not accompanied by a cuephrase, such as ?however?, ?but?
), using word pairsextracted from two spans of text.
Their methodattempts to capture the difference of polarity inwords.Discourse relation classifiers have also beentrained using PDTB.
Pitler et al (2008) performeda corpus study of the PDTB, and found that ?ex-plicit?
relations can be most of the times distin-guished by their discourse connectives.Lin et al (2009) studied the problem of detect-ing implicit relations in PDTB.
Their relationalclassifier is trained using features extracted fromdependency paths, contextual information, wordpairs and production rules in parse trees.
For thesame task, Pitler et al (2009) also use word pairs,as well as several other types of features such asverb classes, modality, context, and lexical fea-tures.In this paper, we are not aiming at definingnovel features for improving performance in RSTor PDTB relation classification.
Instead we incor-porate features that have already shown to be use-ful for discourse relation learning and explore thepossibilities of using unlabeled data for this task.3 MethodIn this section, we describe a semi-supervisedmethod for relation classification, based on featurevector extension.
The extension process employsfeature co-occurrence information.
Co-occurrenceinformation is useful in this context as, for in-stance, we might know that the word pair (for,when) is a good indicator of a TEMPORAL rela-tion.
Or, after analyzing a large body of unlabeleddata, we might also notice that this word pair co-occurs often with the word ?run-up?
placed at theend of a span of text.
Suppose now that we have toclassify a test instance containing the feature ?run-up?, but not the word pair (for, when).
In this case,by using the co-occurrence information, we knowthat the instance has a chance of being a TEM-PORAL relation.
We first explain how to computea feature correlation matrix, using unlabeled data.In a second section, we show how to extend fea-ture vectors in order to include co-occurrence in-formation.
Finally, we describe the features usedin the discourse relation classifiers.3.1 Feature Correlation MatrixA training/test instance is represented using a d-dimensional feature vector f = [f1, .
.
.
, fd]T,where fi ?
{0, 1}.
We define a feature correla-tion matrix, C such that the (i, j)-th element ofC, C(i,j) ?
{0, 1} denotes the correlation betweenthe two features fi and fj .
If both fi and fj appearin a feature vector then we define them to be co-occurring.
The number of different feature vectorsin which fi and fj co-occur is used as a basis tocompute C(i,j).
Importantly, feature correlationscan be calculated using only unlabeled data.It is noteworthy that feature correlation matri-ces can be computed using any correlation mea-sure.
For the current task we use the ?2-measure(Plackett, 1983) as the preferred correlation mea-sure because of its simplicity.
We create the fea-ture correlation matrix C, such that, for all pairs offeatures (fi, fj),C(i,j) ={1 if ?2i,j > c0 otherwise.
(1)Here c is the critical value, which, for a confi-dence level of 0.05 and one degree of freedom, canbe set to 3.84.3.2 Feature Vector ExtensionOnce the feature correlation matrix is computedusing unlabeled data as described in Section 3.1,we can use it to extend a feature vector duringtesting.
One of the reasons explaining why a clas-sifier might perform poorly on a test instance, isthat there are features in the test instance that werenot observed during training.
Let us represent thefeature vector corresponding to a test instance xby fx.
Then, we use the feature correlation ma-trix to find the set of correlated features Fc(fi) ofa particular feature fi that occur in fx.Specifically, for a feature fi ?
fx, F ?
(fi) con-sists of features fj , where C(i,j) = 1.
We definethe extended feature vector f ?x of fx as the union ofall the features that appear in fx and Fc(fx).
Sincea discourse relation is defined between two spansof short texts (elementary discourse units), whichare typically two clauses or sentences, a particu-lar feature does not usually occur more than once56in a feature vector.
Therefore, we introduced theproposed method in the context of binary valuedfeatures.
However, the above mentioned discus-sion can be naturally extended to cover real-valuedfeatures.3.3 FeaturesFigure 1 shows the parse tree for a sentence com-posed of two discourse units, which serve as argu-ments of a discourse relation we want to generatea feature vector from.
Lexical heads have beencalculated using the projection rules of Magerman(1995), and indicated between brackets.
For eachargument, surrounded by dots, is the minimal setof sub-parse trees containing strictly all the wordsof the argument.We extract all possible lemmatized word pairsfrom the two arguments.
Next, we extract fromleft and right argument separately, all productionrules from the sub-parse trees.
Finally, we encodein our features three nodes of the parse tree, whichcapture the local context at the connection pointbetween the two arguments (Soricut and Marcu,2003): The first node, which we call Nw, is thehighest ancestor of the first argument?s last wordw, and is such that Nw?s right-sibling is the an-cestor of the second argument?s first word.
Nw?sright-sibling node is calledNr.
Finally, we callNpthe parent of Nw and Nr.
For each node, we en-code in the feature vector its part-of-speech (POS)and lexical head.
For instance, in Figure 1, wehave Nw = S(comment), Nr = SBAR(when), andNp = VP(declined).4 ExperimentsIt is worth noting that the proposed method is inde-pendent of any particular classification algorithm.As our goal is strictly to evaluate the relative ben-efit of employing the proposed method, we se-lect a logistic regression classifier, for its simplic-ity.
We used the multi-class logistic regression(maximum entropy model) implemented in Clas-sias (Okazaki, 2009).
Regularization parametersare set to their default value of one.Unlabeled instances are created by selectingtexts of the WSJ, and segmenting them into ele-mentary discourse units (EDUs) using our sequen-tial discourse segmenter (Hernault et al, 2010).As there is no segmentation tool for the PDTBframework, we assumed that feature correlationinformation taken from EDUs created using a RSTsegmenter is also useful for extending feature vec-tors of PDTB relations.Since we are interested in measuring the over-all performance of a discourse relation classifieracross all relation types, we use macro-averagedF-score as the preferred evaluation metric for thistask.
We train a multi-class logistic regressionmodel without extending the feature vectors asa baseline method.
This baseline is expected toshow the effect of using the proposed feature ex-tension approach for the task of discourse relationlearning.Experimental results on RST-DT and PDTBdatasets are depicted in Figures 2 and 3.
We ob-serve that the proposed feature extension methodoutperforms the baseline for both RST-DT andPDTB datasets for the full range of training datasetsizes.
However, the difference between the twomethods decreases as we increase the amount oftraining data.
Specifically, with 200 training in-stances, for RST-DT, the baseline method has amacro-averaged F-score of 0.079, whereas the theproposed method has a macro-averaged F-scoreof 0.159 (around 101% increase in F-score).
For1000 training instances, the F-score for RST-DTincreases by 29.2%, from 0.143 to 0.185, whilethe F-score for PDTB increases by 27.9%, from0.109 to 0.139.
However, the difference betweenthe two methods diminishes beyond 10000 train-ing instances.0 5000 10000 15000 20000Number of training instances0.050.100.150.200.250.30Macro-average F-scoreProposed methodBaseline RST-DTFigure 2: Macro-average F-score (RST-DT) as afunction of the number of training instances used.5 ConclusionWe presented a semi-supervised method for im-proving the performance of discourse relationclassifiers.
The proposed method is based onthe analysis of co-occurrence information har-vested from unlabeled data only.
We evaluated57NP (Sherry)S (declined)VP (declined)NNP NNPdeclinedVBD (declined)Mr. Sherry toVP (comment)comment when asked about the salesTO VPSBAR (when)WHADVP (when)WRBS (asked)VP (asked)VBNPP (about)IN NP (sales)DT NNS..
(.
)Argument 1 Argument 2VBS (comment)Figure 1: Two arguments of a discourse relation, and the minimum set of subtrees that contain them?lexical heads are indicated between brackets.0 2000 4000 6000 8000 10000Number of training instances0.000.050.100.150.200.250.300.35Macro-average F-scoreProposed methodBaseline PDTBFigure 3: Macro-average F-score (PDTB) as afunction of the number of training instances used.the method on two of the most widely-used dis-course corpora, RST-DT and PDTB.
The methodperforms significantly better than a baseline classi-fier trained on the same features, especially whenthe number of labeled instances used for training issmall.
For instance, using 1000 training instances,we observed an increase of nearly 30% in macro-average F-score.
This is an interesting perspectivefor improving classification performance of rela-tions with little training data.
In the future, weplan to improve the method by employing rankedco-occurrences.
This way, only the most relevantcorrelated features can be selected during featurevector extension.
Finally, we plan to investigateusing larger amounts of unlabeled training data.ReferencesL.
Carlson, D. Marcu, and M. E. Okurowski.
2001.Building a discourse-tagged corpus in the frame-work of Rhetorical Structure Theory.
Proc.
of Sec-ond SIGdial Workshop on Discourse and Dialogue-Volume 16, pages 1?10.D.
A. duVerle and H. Prendinger.
2009.
A noveldiscourse parser based on Support Vector Machineclassification.
In Proc.
of ACL?09, pages 665?673.H.
Hernault, D. Bollegala, and M. Ishizuka.
2010.A sequential model for discourse segmentation.
InProc.
of CICLing?10, pages 315?326.Z.
Lin, M-Y.
Kan, and H. T. Ng.
2009.
Recognizingimplicit discourse relations in the Penn DiscourseTreebank.
In Proc.
of EMNLP?09, pages 343?351.D.
M. Magerman.
1995.
Statistical decision-tree mod-els for parsing.
Proc.
of ACL?95, pages 276?283.W.
C. Mann and S. A. Thompson.
1988.
RhetoricalStructure Theory: Toward a functional theory of textorganization.
Text, 8(3):243?281.D.
Marcu and A. Echihabi.
2002.
An unsupervised ap-proach to recognizing discourse relations.
In Proc.of ACL?02, pages 368?375.N.
Okazaki.
2009.
Classias: A collection of machine-learning algorithms for classification.E.
Pitler, M. Raghupathy, H. Mehta, A. Nenkova,A.
Lee, and A. Joshi.
2008.
Easily identifiable dis-course relations.
In Proc.
of COLING?08 (Posters),pages 87?90.E.
Pitler, A. Louis, and A. Nenkova.
2009.
Automaticsense prediction for implicit discourse relations intext.
In Proc.
of ACL?09, pages 683?691.R.
L. Plackett.
1983.
Karl Pearson and the chi-squaredtest.
International Statistical Review, 51(1):59?72.R.
Prasad, N. Dinesh, A. Lee, E. Miltsakaki,L.
Robaldo, A. Joshi, and B. Webber.
2008.
ThePenn Discourse Treebank 2.0.
In Proc.
of LREC?08.R.
Soricut and D. Marcu.
2003.
Sentence level dis-course parsing using syntactic and lexical informa-tion.
Proc.
of NA-ACL?03, 1:149?156.V.
N. Vapnik.
1995.
The Nature of Statistical LearningTheory.
Springer-Verlag New York, Inc.58
