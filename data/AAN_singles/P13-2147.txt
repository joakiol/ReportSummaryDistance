Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 848?854,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsBidirectional Inter-dependencies of Subjective Expressions andTargets and their Value for a Joint ModelRoman Klinger and Philipp CimianoSemantic Computing GroupCognitive Interaction Technology ?
Center of Excellence (CIT-EC)Bielefeld University33615 Bielefeld, Germany{rklinger,cimiano}@cit-ec.uni-bielefeld.deAbstractOpinion mining is often regarded as a clas-sification or segmentation task, involvingthe prediction of i) subjective expressions,ii) their target and iii) their polarity.
In-tuitively, these three variables are bidirec-tionally interdependent, but most work haseither attempted to predict them in isolationor proposing pipeline-based approachesthat cannot model the bidirectional interac-tion between these variables.
Towards bet-ter understanding the interaction betweenthese variables, we propose a model thatallows for analyzing the relation of targetand subjective phrases in both directions,thus providing an upper bound for the im-pact of a joint model in comparison to apipeline model.
We report results on twopublic datasets (cameras and cars), show-ing that our model outperforms state-of-the-art models, as well as on a new datasetconsisting of Twitter posts.1 IntroductionSentiment analysis or opinion mining is the task ofidentifying subjective statements about products,their polarity (e. g. positive, negative or neutral)in addition to the particular aspect or feature ofthe entity that is under discussion, i. e., the so-called target.
Opinion analysis is thus typicallyapproached as a classification (Ta?ckstro?m and Mc-Donald, 2011; Sayeed et al 2012; Pang and Lee,2004) or segmentation (Choi et al 2010; Johans-son and Moschitti, 2011; Yang and Cardie, 2012)task by which fragments of the input are classi-fied or labelled as representing a subjective phrase(Yang and Cardie, 2012), a polarity or a target (Huand Liu, 2004; Li et al 2010; Popescu and Etzioni,2005; Jakob and Gurevych, 2010).
As an example,the sentence ?I like the low weight of the camera.
?contains a subjective term ?like?, and the target?low weight?, which can be classified as a positivestatement.While the three key variables (subjective phrase,polarity and target) intuitively influence each otherbidirectionally, most work in the area of opinionmining has concentrated on either predicting oneof these variables in isolation (e. g. subjective ex-pressions by Yang and Cardie (2012)) or modelingthe dependencies uni-directionally in a pipeline ar-chitecture, e. g. predicting targets on the basis ofperfect and complete knowledge about subjectiveterms (Jakob and Gurevych, 2010).
However, suchpipeline models do not allow for inclusion of bidi-rectional interactions between the key variables.
Inthis paper, we propose a model that can includebidirectional dependencies, attempting to answerthe following questions which so far have not beenaddressed but provide the basis for a joint model:?
What is the impact of the performance lossof a non-perfect subjective term extraction incomparison to perfect knowledge??
Further, how does perfect knowledge abouttargets influence the prediction of subjectiveterms??
How is the latter affected if the knowledgeabout targets is imperfect, i. e. predicted by alearned model?We study these questions using imperatively de-fined factor graphs (IDFs, McCallum et al(2008),McCallum et al(2009)) to show how these bi-directional dependencies can be modeled in an ar-chitecture which allows for further steps towardsjoint inference.
IDFs are a convenient way to defineprobabilistic graphical models that make structuredpredictions based on complex dependencies.8482 A Model for the Extraction of TargetPhrases and Subjective ExpressionsThis section gives a brief introduction to impera-tively defined factor graphs and then introduces ourmodel.2.1 Imperatively Defined Factor GraphsA factor graph (Kschischang et al 2001) is a bi-partite graph over factors and variables.
Let factorgraph G define a probability distribution over aset of output variables y conditioned on input vari-ables x.
A factor ?i computes a scalar value overthe subset of variables xi and yi that are neighborsof ?i in the graph.
Often this real-valued functionis defined as the exponential of an inner productover sufficient statistics {fik(xi,yi)} and parame-ters {?ik}, where k ?
[1,Ki] and Ki is the numberof parameters for factor ?i.A factor template Tj consists of parameters{?jk}, sufficient statistic functions {fjk}, and adescription of an arbitrary relationship betweenvariables, yielding a set of tuples {(xj ,yj)}.
Foreach of these tuples, the factor template instan-tiates a factor that shares {?jk} and {fjk} withall other instantiations of Tj .
Let T be the set offactor templates and Z(x) be the partition func-tion for normalization.
The probability distri-bution can then be written as p(y|x) = 1Z(x)?Tj?T?
(xi,yi)?Tj exp(?Kjk=1 ?jkfjk(xi,yi)).FACTORIE1 (McCallum et al 2008; McCallumet al 2009) is an implementation of imperativelydefined factor graphs in the context of Markov1http://factorie.cs.umass.edubetter than CCD shift systemsPOS=JJRW=betterPOS-W=better JJRONE-EDGE-POS=JJRONE-EDGE-W=betterONE-EDGE-POS-W=better JJRONE-EDGE-POS-SEQ=JJRBOTH-POS=JJRBOTH-W=betterBOTH-POS-W=better JJRBOTH-POS-POS-SEQ=JJRPOS=NNW=shiftW=systemsPOS-W=shift NNPOS-W=systems NNSPOS-SEQ=NN-NNSNO-CLOSE-NOUNONE-EDGE-POS=NNONE-EDGE-POS=NNSONE-EDGE-W=shiftONE-EDGE-W=sensorsBOTH-POS=NNBOTH-POS=NNS.
.
.subjective targetsinglespaninterspanFigure 1: Example for features extracted for targetand subjective expressions (text snippet taken fromthe camera data set (Kessler et al 2010)).
IOB-likefeatures are merged for simplicity in this depiction.chain Monte Carlo (MCMC) inference, a commonapproach for inference in very large graph struc-tures (Culotta and McCallum, 2006; Richardsonand Domingos, 2006; Milch et al 2006).
Theterm imperative is used to denote that actual codein an imperative programming language is writ-ten to describe templates and the relationship oftuples they yield.
This flexibility is beneficial formodeling inter-dependencies as well as designinginformation flow in joint models.2.2 ModelOur model is similar to a semi-Markov conditionalrandom field (Sarawagi and Cohen, 2004).
It pre-dicts the offsets for target mentions and subjectivephrases and can use the information of each otherduring inference.
In contrast to a linear chain con-ditional random field (Lafferty et al 2001), this al-lows for taking distant dependencies of unobservedvariables into account and simplifies the design offeatures measuring characteristics of multi-tokenphrases.
The relevant variables, i. e. target and sub-jective phrase, are modelled via complex span vari-ables of the form s = (l, r, c) with a left and rightoffset l and r, and a class c ?
{target, subjective}.These offsets denote the span on a token sequencet = (t1, .
.
.
, tn).We use two different templates to define factorsbetween variables: a single span template and aninter-span template.
The single span template de-fines factors with scores based on features of thetokens in the span and its vicinity.
In our model,all features are boolean.
As token-based featureswe use the POS tag, the lower-case representationof the token as well as both in combination.
Theactual span representation consists of these featuresprefixed with ?I?
for all tokens in the span, with ?B?for the token at the beginning of the span, and with?E?
for the token at the end of the span.
In addition,the sequence of POS tags of all tokens in the spanis included as a feature.The inter-span template takes three characteris-tics of spans into account: Firstly, we measure ifa potential target span contains a noun which isthe closest noun to a subjective expression.
Sec-ondly, we measure for each span if a span of theother class is in the same sentence.
A third fea-ture indicates whether there is only one edge in thedependency graph between the tokens containedin spans of a different class.
These features areto a great extent inspired by Jakob and Gurevych849(2010).
For parsing, we use the Stanford parser(Klein and Manning, 2003).The features described so far, however, cannotdifferentiate between a possible aspect mentionwhich is a target of a subjective expression andone which is not.
Therefore, the features of theinter-span template are actually built by taking thecross-product of the three described characteristicswith all single-span features.
Spans which are notin the context of a span of a different class are rep-resented by a ?negated?
feature (namely No-Close-Noun, No-Single-Edge, and Not-Both-In-Sentence).The example in Figure 1 shows features for twospans which are in context of each other.
All ofthese features representing the text are taken intoaccount for each class, i. e., target and subjectiveexpression.Inference is performed via Markov Chain MonteCarlo (MCMC) sampling.
In each sampling step,only the variables which actually change need tobe evaluated, and therefore the sampler directs theprocess of unrolling the templates to factors.
Theseworld changes are necessary to find the maximuma posteriori (MAP) configuration as well as learn-ing the parameters of the model.
For each tokenin the sequence, a span of length one of each classis proposed if no span containing the token exists.For each existing span, it is proposed to changeits label, shorten or extend it by one token if pos-sible (all at the beginning and at the end of thespan, respectively).
Finally, a span can be removedcompletely.In order to learn the parameters of our model, weapply SampleRank (Wick et al 2011).
A crucialcomponent in the framework is the objective func-tion which gives feedback about the quality of asample proposal during training.
We use the follow-ing objective function f(t) to evaluate a proposedspan t:f(t) = maxg?so(t,g)|g| ?
?
?
p(t,g) ,where s is the set of all spans in the gold standard.Further, the function o calculates the overlap interms of tokens of two spans and the function preturns the number of tokens in t that are not con-tained in g, i. e., those which are outside the overlap(both functions taking into account the class of thespan).
Thus, the first part of the objective functionrepresents the fraction of correctly proposed con-tiguous tokens, while the second part penalizes aspan for containing too many tokens that are out-side the best span.
Here, ?
is a parameter whichcontrols the penalty.3 Results and Discussion3.1 Experimental SettingWe report results on the J.D.
Power and AssociatesSentiment Corpora2, an annotated data set of blogposts in the car and in the camera domain (Kessleret al 2010).
From the rich annotation set, weuse subjective terms and entity mentions whichare in relation to them as targets.
We do not con-sider comitter, negator, neutralizer,comparison, opo, or descriptor annota-tions to be subjective expressions.
Results on thesedata sets are compared to Jakob and Gurevych(2010).In addition, we report results on a Twitter dataset3 for the first time (Spina et al 2012).
Here,we use a Twitter-specific tokenizer and POS tag-ger4 (Owoputi et al 2013) instead of the Stanfordparser.
Hence, the single-edge-based feature de-scribed in Section 2.2 is not used for this dataset.
Ashort summary of the datasets is given in Table 1.As evaluation metric we use the F1 measure, theharmonic mean between precision and recall.
Truepositive spans are evaluated in a perfect match andapproximate match mode, where the latter regardsa span as positive if one token within it is includedin a corresponding span in the gold standard.
In thiscase, other predicted spans matching the same goldspan do not count as false positives.
In the objectivefunction, ?
is set to 0.01 to prefer spans which arelonger than the gold phrase over predicting no span.Four different experiments are performed (allvia 10-fold cross validation): First, predicting sub-jectivity expressions followed by predicting targetswhile making use of the previous prediction.
Sec-2http://verbs.colorado.edu/jdpacorpus/3http://nlp.uned.es/?damiano/datasets/entityProfiling_ORM_Twitter.html4In version 0.3, http://www.ark.cs.cmu.edu/TweetNLP/Car Camera TwitterTexts 457 178 9238Targets 11966 4516 1418Subjectives 15056 5128 1519Table 1: Statistics of the data sets.85000.20.40.60.81pred.
S. ?
T. pred.
T. ?
S. Gold S. ?
T. Gold T. ?
S. Jakob 2010F 1Target-F1 PartialSubjective-F1 PartialTarget-F1Subjective-F10.530.440.65 0.61  0.650.710.480.320.581.000.50 0.540.601.000.651.00Figure 2: Results for the workflow of first predicting subjective phrases, then targets (pred.
S.?
T.), andvice versa (pred.
T.?
S.), as well as in comparison to having perfect information for the first step for thecamera data set.00.20.40.60.81pred.
S. ?
T. pred.
T. ?
S. Gold S. ?
T. Gold T. ?
S. Jakob 2010F 1Target-F1 PartialSubjective-F1 PartialTarget-F1Subjective-F10.510.430.62 0.64  0.690.740.430.330.551.000.50 0.560.661.000.701.00Figure 3: Results for the car data set.ond, predicting targets followed by predicting sub-jective expressions.
Third, assuming perfect knowl-edge of subjective expressions when predicting tar-gets, and fourth, assuming perfect knowledge oftargets in predicting subjective expressions.
Thisprovides us with the information how good a pre-diction can be with perfect knowledge of the othervariable as well as an estimate of how good theprediction can be without any previous knowledge.3.2 ResultsFigures 2, 3 and 4 show the results for the fourdifferent settings compared to the results by Jakoband Gurevych (2010) for cars and cameras.
Thedarker bars correspond to perfect match, the lighterones to the increase when taking partial matchesinto account.
In the following we only discuss theperfect match.Comparing the results (for the car and cameradata sets, Figure 2 and 3) for subjectivity predic-tion, one can observe a limited performance whentargets are not known (0.54F1 for the camera set,0.56F1 for the car set), an upper bound with per-fect target information is much higher (0.65F1,0.7F1).
When first predicting targets followed bysubjective term prediction, we obtain results of0.6F1 and 0.66F1.
The results for target predic-tion are much lower when not knowing subjec-tive expressions in advance (0.32F1, 0.33F1), andclearly increase with predicted subjective expres-sions (0.48F1, 0.43F1) and outperform previousresults when compared to Jakob and Gurevych(2010) (0.58F1, 0.55F1 in comparison to their0.5F1 on both sets).The results for the Twitter data set show the samecharacteristics (in Figure 4).
However, they aregenerally much lower.
In addition, the differencebetween exact and partial match evaluation modes85100.20.40.60.81pred.
S. ?
T. pred.
T. ?
S. Gold S. ?
T. Gold T. ?
S.F 1Target-F1 PartialSubjective-F1 PartialTarget-F1Subjective-F10.420.320.670.40  0.410.600.260.130.401.000.22  0.281.000.35Figure 4: Results for the Twitter data set.00.20.40.60.81Sentence Edge Noun AllF 1  0.480.57  0.520.650.410.48  0.420.58(a) Camera Data Set, given subjective terms.00.20.40.60.81Sentence Edge Noun AllF 10.680.550.170.710.620.510.170.65(b) Camera Data Set, given target terms.Figure 5: Evaluation of the impact of different features.is higher.
This is due to the existence of many morephrases spanning multiple tokens.Exemplarily, the impact of the three features inthe inter-span templates for the camera data set isdepicted in Figure 5 for (a) given subjective terms(b) given targets, respectively.
Detecting the clos-est noun is mainly of importance for target iden-tification and only to a minor extent for detectingsubjective phrases.
A short path in the dependencygraph and detecting if both phrases are in the samesentence have a high positive impact for both sub-jective and target phrases.3.3 Conclusion and DiscussionThe experiments in this paper show that targetphrases and subjective terms are clearly interde-pendent.
However, the impact of knowledge aboutone type of entity for the prediction of the othertype of entity has been shown to be asymmetric.The results clearly suggest that the impact of sub-jective terms on target terms is higher than the otherway round.
Therefore, if a pipeline architecture ischosen, this order is to be preferred.
However, theresults with perfect knowledge of the counterpartentity show (in both directions) that the entitiesinfluence each other positively.
Therefore, the chal-lenge of extracting subjective expressions and theirtargets is a great candidate for applying supervised,joint inference.AcknowledgmentsRoman Klinger has been funded by the ?It?sOWL?
project (?Intelligent Technical SystemsOstwestfalen-Lippe?, http://www.its-owl.de/), a leading-edge cluster of the German Min-istry of Education and Research.
We thank theinformation extraction and synthesis laboratory(IESL) at the University of Massachusetts Amherstfor their support.852ReferencesYoonjung Choi, Seongchan Kim, and Sung-HyonMyaeng.
2010.
Detecting Opinions and their Opin-ion Targets in NTCIR-8.
Proceedings of NTCIR8Workshop Meeting, pages 249?254.A.
Culotta and A. McCallum.
2006.
Tractable Learn-ing and Inference with High-Order Representations.In ICML Workshop on Open Problems in StatisticalRelational Learning.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the tenthACM SIGKDD international conference on Knowl-edge discovery and data mining, pages 168?177,New York, NY, USA.
ACM.Niklas Jakob and Iryna Gurevych.
2010.
Extractingopinion targets in a single- and cross-domain set-ting with conditional random fields.
In Proceed-ings of the 2010 Conference on Empirical Methodsin Natural Language Processing, pages 1035?1045,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Richard Johansson and Alessandro Moschitti.
2011.Extracting opinion expressions and their polarities:exploration of pipelines and joint models.
In Pro-ceedings of the 49th Annual Meeting of the Associ-ation for Computational Linguistics: Human Lan-guage Technologies: short papers ?
Volume 2, pages101?106, Stroudsburg, PA, USA.
Association forComputational Linguistics.Jason S. Kessler, Miriam Eckert, Lyndsie Clark, andNicolas Nicolov.
2010.
The 2010 ICWSM JDPASentment Corpus for the Automotive Domain.
In4th International AAAI Conference on Weblogs andSocial Media Data Workshop Challenge (ICWSM-DWC 2010).D.
Klein and Ch.
D. Manning.
2003.
Fast exact in-ference with a factored model for natural languageparsing.
In Advances in Neural Information Process-ing Systems 16 [Neural Information Processing Sys-tems.F.R.
Kschischang, B.J.
Frey, and H.-A.
Loeliger.
2001.Factor graphs and the sum-product algorithm.
Infor-mation Theory, IEEE Trans on Information Theory,47(2):498?519.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.
In International Conference on Ma-chine Learning, pages 282?289.Fangtao Li, Minlie Huang, and Xiaoyan Zhu.
2010.Sentiment analysis with global topics and local de-pendency.
In Proceedings of the Twenty-FourthAAAI Conference on Artificial Intelligence, pages1371?1376, Atlanta, Georgia, USA.A.
McCallum, K. Rohanimanesh, M. Wick, K. Schultz,and Sameer Singh.
2008.
FACTORIE: EfficientProbabilistic Programming via Imperative Declara-tions of Structure, Inference and Learning.
In NIPSWorkshop on Probabilistic Programming.Andrew McCallum, Karl Schultz, and Sameer Singh.2009.
FACTORIE: Probabilistic programming viaimperatively defined factor graphs.
In Neural Infor-mation Processing Systems (NIPS).B.
Milch, B. Marthi, and S. Russell.
2006.
BLOG:Relational Modeling with Unknown Objects.
Ph.D.thesis, University of California, Berkeley.O.
Owoputi, B. OConnor, Ch.
Dyer, K. Gimpely,N.
Schneider, and N. A. Smith.
2013.
Improvedpart-of-speech tagging for online conversational textwith word clusters.
In The 2010 Annual Conferenceof the North American Chapter of the Associationfor Computational Linguistics.Bo Pang and Lillian Lee.
2004.
A sentimental edu-cation: Sentiment analysis using subjectivity sum-marization based on minimum cuts.
In Proceedingsof the 42nd Meeting of the Association for Compu-tational Linguistics, Main Volume, pages 271?278,Barcelona, Spain, July.Ana-Maria Popescu and Oren Etzioni.
2005.
Extract-ing product features and opinions from reviews.
InProceedings of Human Language Technology Con-ference and Conference on Empirical Methods inNatural Language Processing, pages 339?346, Van-couver, British Columbia, Canada, October.
Associ-ation for Computational Linguistics.M.
Richardson and P. Domingos.
2006.
Markov logicnetworks.
Machine Learning, 62(1-2):107?136.Sunita Sarawagi and William W. Cohen.
2004.
Semi-markov conditional random fields for informationextraction.
In Advances in Neural Information Pro-cessing Systems 17 [Neural Information ProcessingSystems.Asad Sayeed, Jordan Boyd-Graber, Bryan Rusk, andAmy Weinberg.
2012.
Grammatical structures forword-level sentiment detection.
In Proceedings ofthe 2012 Conference of the North American Chap-ter of the Association for Computational Linguis-tics: Human Language Technologies, pages 667?676, Montre?al, Canada, June.
Association for Com-putational Linguistics.D.
Spina, E. Meij, A. Oghina, M. T. Bui, M. Breuss,and M. de Rijke.
2012.
A Corpus for Entity Pro-filing in Microblog Posts.
In LREC Workshop onInformation Access Technologies for Online Reputa-tion Management.Oscar Ta?ckstro?m and Ryan McDonald.
2011.
Semi-supervised latent variable models for sentence-levelsentiment analysis.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies, pages853569?574, Portland, Oregon, USA, June.
Associationfor Computational Linguistics.M.
Wick, K. Rohanimanesh, K. Bellare, A. Culotta,and A. McCallum.
2011.
SampleRank: Trainingfactor graphs with atomic gradients.
In Interna-tional Conference on Machine Learning.Bishan Yang and Claire Cardie.
2012.
Extracting opin-ion expressions with semi-markov conditional ran-dom fields.
In Proceedings of the 2012 Joint Con-ference on Empirical Methods in Natural LanguageProcessing and Computational Natural LanguageLearning, pages 1335?1345, Stroudsburg, PA, USA.Association for Computational Linguistics.854
