Proceedings of the Workshop on Frontiers in Corpus Annotation II: Pie in the Sky, pages 1?4,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsIntroduction toFrontiers in Corpus Annotation IIPie in the SkyAdam MeyersNew York Universitymeyers@cs.nyu.edu1 IntroductionThe Frontiers in Corpus Annotation workshops are op-portunities to discuss the state of the art of corpus annota-tion in computational linguistics.
Corpus annotation haspushed the enitre field in new directions by providing newtask definitions and new standards of analysis.
At the firstFrontiers in Corpus Annotation workshop at HLT-NAACL2004 we compared assumptions underlying different an-notation projects in light of both multilingual applicationsand the pursuit of merged representations that incorporatethe result of various annotation projects.Beginning September, 2004, several researchers havebeen collaborating to produce detailed semantic anno-tation of two difficult sentences.
The effort aimed toproduce a single unified representation that goes beyondwhat may currently be feasible to annotate consistentlyor to generate automatically.
Rather this ?pie in the sky?annotation effort was an attempt at defining a future goalfor semantic analysis.
We decided to use the ?Pie in theSky?
annotation effort (http://nlp.cs.nyu.edu/meyers/pie-in-the-sky.html) as a theme for this year?s workshop.Consequently this theme has been brought out in manyof the papers contained in this volume.The first 4 papers (Pustejovsky et al, 2005; E. W.Hinrichs and S. Ku?bler and K. Naumann, 2005; Bieset al, 2005; Dinesh et al, 2005) all discuss some as-pect of merging annotation.
(Pustejovsky et al, 2005)describes issues that arise for merging argument struc-tures for verbs, nouns and discourse connectives, as wellas time and anaphora representations.
(E. W. Hinrichsand S. Ku?bler and K. Naumann, 2005) focuses on themerging of syntactic, morphological, semantic and ref-erential annotation.
(E. W. Hinrichs and S. Ku?bler andK.
Naumann, 2005) also points out that the ?Pie in theSky?representation lacks syntactic features.
This bringsto light an important point of discussion: should linguis-tic analyses be divided out into separate ?levels?
cor-responding to syntax, morphology, discourse, etc.
orshould/can a single representation represent all such ?lev-els??
As currently conceived, ?Pie in the Sky?
is in-tended to be as ?language neutral?
as possible ?
this maymake adding a real syntactic level difficult.
However, ar-guably, surface relations can be added on as features toPie in the Sky, even if we delete or ignore those featuresfor some (e.g., language neutral) purposes.
Still, otherpapers present further difficulties for maintaining a sin-gle representation that covers multiple modes of analysis.
(Bies et al, 2005) discusses possible conflicts betweennamed entity analyses and syntactic structure and (Di-nesh et al, 2005) discusses a conflict between discoursestructure and syntactic structure.
I think it is reasonable toassume that some such conflicts will be resolvable, e.g.,I believe that the named entity conflicts point to short-comings of the original Penn Treebank analysis.
How-ever, the discourse structure/syntactic structure conflictsmay be harder to solve.
In fact, some annotation projects,e.g., the Prague Dependency Treebank (Hajic?ova?
and Ce-plova?, 2000), assume that multiple analyses or ?levels?are necessary to describe the full range of phenomena.The 5th through 7th papers (Inui and Okumura, 2005;Calhoun et al, 2005; Wilson and Wiebe, 2005) investi-gate some additional types of annotation that were notpart of the distributed version of Pie in the Sky, but whichcould be added in principle.
In fact, with help fromthe authors of (Calhoun et al, 2005), I did incorporatetheir analysis into the latest version (number 6) of the?Piein the Sky?
annotation.
Furthermore, it turns out thatsome units of Information Structure cross the boundariesof the syntactic/semantic constituents, thus raising thesort of difficulties discussed in the previous paragraph.Specifically, information structure divides sentences intothemes and rhemes.
For the sample two sentences, therheme boundaries do correspond to syntactic units, butthe theme boundaries cross syntactic boundaries, formingunits made up of parts of multiple syntactic constituents.
(Palmer et al, 2005; Xue, 2005) (the eighth and1eleventh papers) make comparisons of annotated phe-nomena across English and Chinese.
It should be pointedout that seven of the papers at this workshop are pre-dominantly about the annotation of English, one is aboutGerman annotation and one is about Japanese annotation.These two are the only papers at the workshop that explic-itly discuss attempts to apply the same annotation schemeacross two languages.
(McShane et al, 2005; Poesio and Artstein, 2005) (theninth and tenth papers) both pertain to issues about im-proving the annotation process.
(Poesio and Artstein,2005) discusses some better ways of assessing inter-annotator agreement, particularly when there is a grayarea between correct and incorrect annotation.
(McShaneet al, 2005) discusses the issue of human-aided annota-tion (human correction of a machine-generated analysis)as it pertains to a single-integrated annotation scheme,similar in many ways to ?Pie in the Sky?, although it hasbeen in existence for a lot longer.2 Issues for DiscussionThese papers raise a number of important issues for dis-cussion, some of which I have already touched on.Question 1: Should the community annotate lots ofindividual phenomena independently of one another orshould we assume an underlying framework and per-form all annotation tasks so they are compatible with thatframework?Some of the work presented describes the annotationof fairly narrow linguistic phenomena.
Pie in the Sky canbe viewed as a framework for unifying these annotationschemata into a single representation (a Unified Linguis-tic Annotation framework in the sense of (Pustejovsky etal., 2005)).
Other work presented assumes that the in-tegrated framework is the object of the annotation ratherthan the result of merging annotations (E. W. Hinrichsand S. Ku?bler and K. Naumann, 2005; McShane et al,2005).
There are pros and cons to both approaches.When researchers decide to annotate one small pieceof linguistic analysis (verb argument structure, noun ar-gument structure, coreference, discourse structure, etc.
),this has the following potential advantages: (1) explor-ing one phenomenon in depth may provide a better char-acterization of that phenomenon.
If individual phenom-ena are examined with this level of care, perhaps we willend up with a better overall analysis; (2) a very focusedtask definition for the annotator may improve interanno-tator agreement; and (3) it is sometimes easier to ana-lyze a phenomenon in isolation, especially if there is nota large literature of previous work about it ?
indeed, try-ing to integrate this new phenomenon before adequatelyunderstanding it may unduly bias one?s research.
How-ever, by ignoring a more complete theory, these anno-tation projects run the risk of task-based biases, e.g.,classifying predication as coreference or coreference asargument-hood.
While an underlying all-inclusive the-ory could be a useful roadmap, unifying the results ofseveral annotation efforts (and resolving inconsistencies)may yield the same result (as suggested in (Pustejovskyet al, 2005)) while maintaining the advantages of inves-tigating the phenomena separately.
On the other hand, asthis merging process has not come to completion yet, thejury is still out.Let?s say that, for the sake of argument, the reader ac-cepts the research program where individual annotationefforts are slowly merged into one ?Pie in the Sky?
typesystem.
There is still another obvious question that arises:Question 2: Why make up a brand new system like?Pie in the Sky?
when there are so many existing frame-works around?
For example, Head-Driven Phrase Struc-ture Grammar (Pollard and Sag, 1994) assumes a fairlylarge feature structure that would seem to accommodateevery possible level of linguistic analysis (although inpractice most authors in that framework only work on thesyntactic and semantic portion of that feature structure).Our initial motivation for starting fresh is that wewanted the framework to use the minimal features nec-essary to represent the input annotation systems and toextend them as much as possible.
In addition, part of theexperiment was an aim to keep features in a somewhatlanguage-neutral form and it is not clear that there are ex-isting frameworks that both share this bias and are suffi-ciently expressive for our purposes.
However, ultimatelyit might be beneficial to convert ?Pie in the Sky?
to oneor more pre-existing frameworks.So far, we have limited the scope of ?Pie in the Sky?to semantic and (recently) some discourse information aswell.
However, there are some cases where we found itnecessary to include syntactic information, e.g., althoughheads are semantic arguments of adjective modifiers, thesurface relation between the head of the noun phrase andits constituents is important for determining other partsof meaning.
For example, although explosive would bearthe same argument relation to powerful in both (a) Theexplosive is powerful and (b) the powerful explosive, theinterpretation of (b) requires that powerful be part of thesame unit as explosive, e.g., for the proper interpretationof He bought a powerful explosive.
Thus it may seemlike a good idea to ultimately fill out ?Pie in the Sky?
intoa larger framework.
However, we would still want to beable to pick out the language-neutral components of theanalysis from the language-specific ones.Question 3: D. Farwell, a member of the workshopcommittee, has pointed out that there are levels within se-mantics.
The question is how should these multiple levelsbe handled?
The annotated examples did not include phe-nomena such as metaphor, metonymy or idiomaticity thatmay have multiple interpretations: literal and intended.2For example, an adequate interpretation of I love listen-ing to Mozart would require Mozart to be decomposedinto music by Mozart (although arguably the representa-tion of some of the complex discourse references were ofthis flavor).3 What?s in the Latest Pie in the SkyAnalysisAs of this writing, the latest ?Pie in the Sky?
analysisincludes: (1) argument structure of all parts of speech(verbs, nouns, adjectives, determiners, conjunctions, etc.
)using the PropBank/NomBank/Discourse Treebank argu-ment labels (ARG0, ARG1, ARG2,     ), reminiscent ofRelational Grammar of the 1970s and 1980s (Perlmut-ter, 1984), (2) some more specifically labeled FrameNet(Baker et al, 1998) roles for these same constituents;(3) morphological and part of speech features; (4) point-ers to gazetteers, both real and hypothetical (thanks toB.
Sundheim); (5) Veracity/According-To features basedon NYU?s proposed FactBank annotation scheme; (6)various coreference features including some based on aproposed extension to NomBank; (7) temporal featuresbased on Timex2 (Ferro et al, 2002) and TimeML (Puste-jovsky et al, 2004); and (8) Information Structure fea-tures based on (Calhoun et al, 2005).
For more de-tail, please see: http://nlp.cs.nyu.edu/meyers/pie-in-the-sky.html4 The Future of ?Pie in the Sky?After this workshop, we plan to retire the current two?Pie in the Sky?
sentences and start again with some newtext.
I observed the following obstacles during this ex-periment: (1) annotation projects were somewhat hesi-tant to volunteer their time (so we are extremely gratefulto all projects that did so.
); (2) the target material was notlong enough for some annotation approaches to be ableto really make their mark, e.g., two sentences are not sointeresting for discourse purposes.
; and (3) partially dueto its length, some interesting phenomena were not well-represented (idioms, metonymy, etc.
)The lack of volunteers may, in part, be related to thescale of the project.
We built the project up slowly andinvited people to join in, rather than posting a request forannotations to an international list.
Initially, this was nec-essary just to make the project possible to manage.
Addi-tionally, inadequacies of the data were probably barriersfor projects that focused on discourse phenomena or phe-nomena that was not well-represented by our data.
Nev-ertheless, using more data may place too heavy a burdenon annotation projects and this could make projects hesi-tant to participate.With these issues in mind, I note that several sites an-notated two longer documents for the recent U.S. Govern-ment sponsored Semantic Annotation Planning Meetingat the University of Maryland.
This success was, in part,due to the chance for annotation sites to attract govern-ment interest in funding their projects.
While we will notattempt to duplicate this workshop, I believe that thereis an underlying issue that is very important.
The fieldreally needs a single test corpus for all new annotationprojects.This test corpus would meet a number of importantneeds of the annotation community: (1) it would pro-vide a testbed for new annotation schemata; (2) it wouldprovide a large corpus that is annotated in a fairly com-plete framework ?
this way focused annotation projectsmay be able to more easily write specifications in lightof where their particular set of phenomena fit into somelarger framework; and (3) it would provide a steady flowof input annotation in order to produce a single unifiedannotation framework.To make this idea a reality, we need to obtain a con-sensus on what people would like to annotate.
Addi-tionally, we need volunteers to translate this same cor-pus into other languages, as we would inevitably choosean English corpus.
Of course, if we could find a suitabletext that was already translated in multiple languages, thiswould save time.
The perfect text would be article length(loosely defined); include difficult to handle phenomena(idioms, metonymy, etc.
); include a wide range of an-notatable linguistic phenomena and not have copyrightrestrictions which would hamper the project.
It would,of course, be helpful if the annotation community wouldprovide input on which text to choose ?
this would avoida situation where one could not annotate the test text be-cause the target phenomenon is not represented there.In summary, I have used this introduction to both sum-marize how the papers of this workshop fit together, topropose some unifying themes for discussion, and to pro-pose an agenda for how to proceed after the workshop isover.
We hope to see some of these ideas come to fruitionbefore ?Frontiers in Corpus Annotation III.
?ReferencesCollin F. Baker, Charles J. Fillmore, and John B. Lowe.1998.
The Berkeley FrameNet Project.
In Proceedingsof Coling-ACL98: The 17th International Conferenceon Computational Linguistics and the 36th Meeting ofthe Association for Computational Linguistics, pages86?90.A.
Bies, S. Kulick, and M. Mandel.
2005.
Parallel En-tity and Treebank Annotation.
In ACL 2005 Workshop:Frontiers in Corpus Annotation II: Pie in the Sky.S.
Calhoun, M. Nissim, M. Steedman, and J. Brenier.2005.
A Framework for Annotating Information Struc-3ture in Discourse.
In ACL 2005 Workshop: Frontiersin Corpus Annotation II: Pie in the Sky.N.
Dinesh, A. Lee, E. Miltsakaki, R. Prasad, A. Joshi,and B. Webber.
2005.
Attribution and the (Non-)Alignment of Syntactic and Discourse Arguments ofConnectives.
In ACL 2005 Workshop: Frontiers inCorpus Annotation II: Pie in the Sky.E.
W. Hinrichs and S. Ku?bler and K. Naumann.
2005.
AUnified Reprewsentation for Morphological, Syntac-tic, Semantic, and Referential Annotations.
In ACL2005 Workshop: Frontiers in Corpus Annotation II:Pie in the Sky.L.
Ferro, L. Gerber, I. Mani, B. Sundheim, and G. Wil-son.
2002.
Instruction Manual for the Annotation ofTemporal Expressions.
MITRE Washington C3 Cen-ter, McLean, Virginia.Eva Hajic?ova?
and Mark?eta Ceplova?.
2000.
Deletionsand Their Reconstruction in Tectogrammatical Syntac-tic Tagging of Very Large Corpora.
In Proceedings ofColing 2000: The 18th International Conference onComputational Linguistics, pages 278?284.T.
Inui and M. Okumura.
2005.
Investigating the Char-acteristics of Causal Relations in Japanese Text.
InACL 2005 Workshop: Frontiers in Corpus AnnotationII: Pie in the Sky.M.
McShane, S. Nirenburg, S. Beale, and T. O?Hara.2005.
Semantically Rich Human-Aided Machine An-notation.
In ACL 2005 Workshop: Frontiers in CorpusAnnotation II: Pie in the Sky.M.
Palmer, N. Xue, O. Babko-Malaya, J. Chen, andB.
Snyder.
2005.
A Parallel Proposition Bank II forChinese and English.
In ACL 2005 Workshop: Fron-tiers in Corpus Annotation II: Pie in the Sky.David.
M. Perlmutter.
1984.
Studies in Relational Gram-mar 1.
The University of Chicago Press, Chicago.M.
Poesio and R. Artstein.
2005.
The Reliability ofAnaphoric Annotation, Reconsidered: Taking Ambi-guity into Account.
In ACL 2005 Workshop: Frontiersin Corpus Annotation II: Pie in the Sky.Carl Pollard and Ivan A.
Sag.
1994.
Head-Driven PhraseStructure Grammar.
University of Chicago Press andCSLI Publications, Chicago and Stanford.J.
Pustejovsky, B. Ingria, R. Sauri, J. Castano, J. Littman,R.
Gaizauskas, A. Setzer, G. Katz, and I. Mani.
2004.The Specification Language TimeML.
In I. Mani,J.
Pustejovsky, and R. Gaizauskas, editors, The Lan-guage of Time: A Reader.
Oxford University Press,Oxford.J.
Pustejovsky, A. Meyers, M. Palmer, and M. Poe-sio.
2005.
Merging PropBank, NomBank, TimeBank,Penn Discourse Treebank and Coreference.
In ACL2005 Workshop: Frontiers in Corpus Annotation II:Pie in the Sky.T.
Wilson and J. Wiebe.
2005.
Annotating Attributionsand Private States.
In ACL 2005 Workshop: Frontiersin Corpus Annotation II: Pie in the Sky.N.
Xue.
2005.
Annotating Discourse Connectives in theChinese Treebank.
In ACL 2005 Workshop: Frontiersin Corpus Annotation II: Pie in the Sky.4
