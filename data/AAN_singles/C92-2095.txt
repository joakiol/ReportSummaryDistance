Isolating Cross-linguistic Parsing Complexity with aPrinciples-and-Parameters Parser:A Case Study of Japanese and English *Sand iway  Fong & Robert C. BerwickNEC Research  Ins t i tu te ,  4 Independence  W~y,  P r inceton ,  N J ,  08540 USA,  szLnd iway@research .nec .comRm 838, M IT  At  L~bortLtory,  545 Techno logy  Sq.,  Ca inbr ldgc ,  MA 02139,  berwick~ai .mi t .edu1 In t roduct ionAs parsing models and linguistic theories have broadened to encorapass a wider range of non-English lan-guages, a particularly uscfifl "stress test" is to buikl asingle theory/parser pair that can work for multiple lan-guages, in the best case with minor variation, perhapsrestricted to the lexicon.
This paper reports on the re-suits of just such a test applied to a fully operational(Prolog) implementation f a so-called principles-and-parameters model of syntax, for the case of Japaneseand English.
This paper has two basic aims: (1) to showhow an implemented model tbr an entire principles-and-parameters model (essentially all of the linguistic theoryin Lasnik & Uriagereka (1988)), see figure 2 for a com-puter snapshot, leads directly to both a parser for nml-tiple languages and a useful "computational linguisticsworkbench" in which one can easily experiment withalternative linguistic theoretical tormulations of gram-marital  principles as well as alternative computationalstrategies; (2) to use this system to uncover sourcesof parsing complexity in Japanese as opposed to En-glish.
In particular, we examine the "null hypothesis"that a single parsing design suffices for efficient pro-cessing of both/ lead-f irst and Ilead-final anguages, incontrast o approaches that posit, e.g., a right-corneror other mirror-image strategy for parsing Japanese ascompared to English (e.g., BUP; Mazuka (1990)).
Inthis case we can confirm computationally and precisely,in accordance with nmch current psychollnguisitic work(l'~razier and Raynert (1988); lnoue and J.1).
Fodor(1991); Nagai (1991)) that it is not the lien&finalcharacter of Japanese that results in processing diffi-culty so mudl as the possibility of scrambling and freedeletion of NPs (so-called "super Pro Drol)" ).
We dothis by empirically investigating the effects of 3 t)ossi-ble "optimizations" of the parsing system for Japanese:(1) the use of right-context information via automaticsource transformations, using a l,rogramming languagecompiler technique to introduce dummy nonterminalsand corresponding semantic actions; (2) modificationof the Japanese grammar to put the specitier of CP*Tiffs research ltas been supported by NSF (~ralttDCR85552543 under a Presidential Young fnvestiglttorAward to Professor Robert C. Berwiek, and a grant front theKapor Family Foundation.
We would like to thank linwardLasnik, Alec Marantz, Shigeru Miyagawa, David Pesetsky,and Mamoro Saito for valuable discussions and valiant at-tempts to tell us about Japanese.
(= S) on tile right and so eliminate unnecessary center-embedding; and (3) eliminating of scrambling and NPdrop to isolate tile separate ffects of llead-final (e.g.,Verb-final) l)hrase structure in Japanese.By explicit construction, the implementation demomstratcs that it is possible to build an efficient principle-and-parameters parser lbr multiple languages, using 25principles titat are expressed in a language quite closein form to that of the original linguistic theory.
'\].
'heEnglish-Japanese dilt~rences handled include the ba-sic Suhjeet-Objcct-.Verb (SOV) order of Japanese; free"scrambling" of Japancsc noun phrases; topic-commentstructurc; ,mnappearauee of noun phrases that are dis-course recoverable; and lack of wh-word movemcnt inJapanese questions.
No rule reprogrammingis requiredto accommodate hese differences, but changes to only4 binary switches and a ininimally distinct lexicon withdifferent thematic grids in some cases.
The parsercouples everal already-known parsing design strategiesto ol)tain efficient parsing times, e.g., type-checking;nmltitdc~entry canonical LR(1) parsing; and automatic(source-to-source) grammar transformations.
12 P r inc lp lc -based  pars ingIn a t)rinciple-based parser, construction- and language~speeitic rules arc rcplaeed with broader principles thatremain invariant aside from parametric variation (seebelow).
The parser works by a (partially interleaved)generate-and-test tedmique that uses a canonical LR(1)covering rammar (derived from X theory plus the the-ory of movement) to lirst buibl an initial set of treestructures; these structures are then run through a se-1'1'o the best of our knowledge, this system is the first andbroa(lest-coveragc of it~ type to be able to parse Japaneseaml English by setting jnt;t a few parameter switches.
Dorr(1987), uoder the supervlsi:)n of tim second author, devel-oped a c(mc"i:tually similar scheme to fiandle L'nglish, Span-ish, and (~crman.
lit,wryer, l)orr's system did not have thesame bro~td coverage of English; did not handle Japanese;used hand rather than automatic ompiling; and was ap-proximately 15 times slowek.
Gunji's (1987) Japanese unifi-ceti(m grammar comes closest o the principle-ba~ed model,but requires hand-modification from a set of core principles~utd oes not really accommodate he important Japanesephenomenon of scrambling; see below.
Otficr such systemswork only on nmch smatlcr parts of English, e.g., Sharp(1985); Wehrli (1987); Crocker (1989); Cortes (1988); Johnoson, (1989); or are not in fact parsers, but proof-cfieckers,e.g., Stabler, (1991, forthcoming).Ac~\].
;s DE COLING-92, NANTES, 23-28 Ao(rr 1992 6 3 1 l'l~o(:, oi: COI,ING-92, N^NTES, AUO.
23-28, 1992ries of predicates whese conjunction defines the remain-der of the constraints the (sentence, I)hra.ue structurc,LF) triple must satisfy.
This is done using familiar ma-chinery from Prolog to output LFs that satisfy all thedeclarative constraints of the linguistic theory.
In prac-tice, a straightforward generate-and-test mechanism isgrossly inefficient, since the principles that apply toat the level of surface structure (S-structure) are buta fraction of those that apply in the overall system.The usual problems of lexical and structural ambiguitythe the underconstrained nature of the initial X systemmeans that the number of possible S-structures to hy-pothesize may be buge.
qb obtain an efficient parserwe use a full multiple-entry table with backtracking (asin 2bruits, 198fi), extending it to a canonical LR(1)parser.
The LIt.
machine uses an atttomatically-builtS-structure grammar tbat folds together enough of timconstraints from other principles, parameters, lexicalsubcategory information oflline to produce a 25-foldimprovement over tile online phrase structure recov-ery procedure originally proposed by Fong and Berwick(1989).
Optimizations include extra conditions in ac-tion classes to permit interleaving of other principles(like movement) with structure-building (the 'intcrleawing' noted by principles marked ' l '  in the snapshot infigure 2 below); control structure flexibility in principleordering; precomputation f the LK transition function;elimination of infinite recursion of empty elements by anadditional stack mechanism, and so forth.
We exploitthe explicit modularity of the principle-ba.qcd system inway that is impossible in an ordinary rule-based sys-tem: we can build a grammar for phrase strneture thatis small enough to make full, canonical LI~.
(1) parsingusable, unlike large CFGs.
The earlier error detectionof full Lll(1) parsing over LALtt methods means thatfail as early as possible, to avoid expensive trcc con-structions that can sever participate in final solutions.
23 The  Japanese  parserWe begin with a very simple parameterization fJapanese that will nonetheless be able to cover allthe Lasnik and Salts w/l-questions, crambling, and soforth; sec tile table on the next page that follows the ex-ample sentences.
The important point is that very littleadditional must bc said in order to parse a wide vari-ety of distinctive Japancsc sentences; the principles asshown on tbe ri~hthand side of the computer snapshotdo no~ change.
~Consider first the example wh-movement sentencesfound in the linguistics paper On the Nature of ProperGovcramenl by Lasnik & Salts (1984).
4 These seu-:qb providca rough measure of the machine size for thephrase structurc grammar of S-structure for both Englishand Japanese, the augmented CFC, consists of about 74 pro-ductions derived fronl a schema of 30-34 rules.
The resultingcharacteristic tisitc state automaton (CFSM) consists of 123states with 550 traalsitions between the various states.
Theaction table consists of a totM of 984 individual (nonerror)entries.3We will scramble only from direct object positions here,even though it is straightforward to scramble front indirectobject positions.
Informally, we have noted that scrambhngfrom IO greatly increases computation time.
A tighter setof constraints oil scrambling seems called for.4Average best parsing time for the Japanese sentencesshown is 0.37sees/word on a Symbolies 3650 (64K LIPS) (eltence.q (listed below) display nlany familiar typologi-cal Japanese-English differences, and cover a rathersoplfiaticated sct of differences between English andJapanese: for instance, why (6) is fine in Japanese butnot in English; frec omissiol) of NPs; "scrambling" ofsubjects and objects; Verb-final (more generally, IIead-final) constituent structure, and no overt movement ofwh-phras~.
We also consider a different set of Japanesesentences (also listed below) designed to illustrate arange of the same phenomena, taken from ttosokawa(1990).
We stress that these sentences are designed toillustrate a range of sentence distinctions in Japanese,as well a.q our investigative method, rat|mr than serveas any complete list of syntactic differences between thetwo languages ( ince they aro obviously not).
s\[Lasnik & Salts (1984)\](2) Watashi-wa Taro-ga nani-o katta ka shitte iru'I know what Johll bought'{6) Kimi-wa dare-ni Taro~ga naze kubi-ni natta tteitta no'qb whom did you say that John was fired why'(32) *Meari-wa Taro-g~ nani-o katta ka do ka sltiranai'Mary does not know whether or sot John boughtwhat'(37a) Taro-wa haze kubi-ni natta no'Why was John fired'(37b) Iliru-wa Taro-ga haze kubi-ni nntta tte itta no'Why did Bill say that John was fired'(39a) Taro-ga nani-o te-ni ireta koto-o sonnani okotteruno~What arc you so angry about the fact that "Faroobtained'(39b) ~l'aro-ga naze sore-o te-ni ireta koto-o sonnaniokotterll no'Why are you so angry about the fact that Taroobtained it'(41a) ltanoko-ga Taro-ga nani-o te-ni frets tte itta koto-0 sonn&lll okottcru )to~What arc you so angry about the fact thatI\[anoko said that Taro obtained'(4lb) *Hanoko-ga Taro-ga naze sore-o re-hi frets tte ittakoto-o Solinalli okottern no'Why are you so angry about he fact that Ilanokosaid that Taro obtained it'(60) Kimi-wa nani-o doko-de katta no~Where did you buy what'(63) Kimi-wa nani-o sagashiteru no'Why are you looking for what'Complement /noneomplement  asymmetry ,scrambl ing and uneXl)eeted parsesTo see bow the parser handles one Japanese xam-plc (see the actual computer output in figure 1 or fig-ure 2), consider (39a) (and thc corresponding illicit(39b)), where a complement wh but not a noncom-plement wh can be extracted from a complex NP: (a)Taro-ga nani~o te-ni frets koto-o sonnani okotterun o; (b)*Taro-ga haze sorc-o re-hi frets koto-o 'What/*Wlly are youso angry about the fact that 'Faro obtained'Tbis example illustrates everal Japanese typologi-cal differences with Englisb.
The subject of the ma-trix clause (= you) has been omitted.
Nani ('what')and te ('hand') have been scrambled; the direct object= 1.52see, n= 100).
Parsing time on a Sun Sparestation 2is approximately an order of magnitude faster.SE.g., the doublc-o constraint; cast-overwriting, passiveand causative constructions, etc.
all remain to be fullyimplmoented.ACYEs DE COLING~92, NANTI~S, 23-28 AOt)r 1992 6 3 2 PROC.
OF COLING-92, NANfI!S, AUG. 23-28, 1992(marked -o) now al>pcaring in front of tim indirect ob-ject re, Phr~ule structure is l lead final.
Our relaxationof the Caac Adjacency paranteter and the rule that al-lows adjunctiou of NP to VP, plus transmission of Caseto the scrambled NP will let this analysis through.
'\]?heLF for this nentence should be something along the linesof: for what x, pro is so angry about \[tiLe fact that "Faroobtained x\]IlL this example ply denotes the understood subjectof okottern ("be angry").
The Ll:s actually returned bythe parser are shown in tile siLapshot in tigure l.S\[llosokaw~t (1990)\](tb)' Gengogaku-no gakuseioga tiizu~o tabetalinguistics-sen student-nora cheese-ace eat-pmst'A student of linguistics ate cheese'(2by Nagai karat-no gakusei-ga tiizu-o tabetalong hair-gcn student-,nom cheese-ace eat-p~lt'A hmg haired student ate cheese'(3b) Taro-ga hoit-o kattaJohn-nora book-ace buy-pa~t'.lohn bought a book'(4b) Taro-ga Hanoko-ni hon-o agetaJohn-nora Mary-dat book-ace give-past'John bought Mary a book'(5b) Taro-ga hon-o table-no ue-ni sitsJohn book:ace ta.ble-gen top-dat (top of table)put-p~t'John put the book on the table'(6b) 'Faro-wa gakkoo-ni ttaJohn-top uchool-dat gO-l)~t' John went to school'(151)) Watashi-wa tattvga nani-o katta ka shiranaiI-top John-nora what-ace bought Q know-not<1 don~t know what John bought'(lTb) q_'mo wa Chomsky-no Barriers-o yontimashita kaJohn-top Cln)msky-gen tlarriers-acc rcad-1)mut Q'I)id John read Chonmky's Barriers'(18b) llanoko-waBiru-ga Chomsky-no Barriers-o yonda ka do kashiranaiMary-top llill-noin Chomsky-gen Barriers-aceread Q know-not'Mary does not know whether or not Bill readChomsky's, .. 'Tile parametr ic differences that we need to accomodateall these differences between English and Japanese arcquite few:OWe will not have room to tlescribe in detail thederivation of these LFs.
But, it uhouhl be notedtbat the derivation sequence is quite complex.
Note,for example, that .ant ('what') undergoes movententat two levels of phrase structure in order to get tothe specilier position of the matrix Complementizer:lOP nani\[IP *l~aro\[NP\[CP pro\[ VP~t'&\[ V I~ iretal\]\] huts\],..\]\]Furthermore, the LF trace t' violates the so-called emptycategory principle unless it is deleted (as indicated by \[\] inthe snapshot), under the present heory.
Tile lack of wh-ntovement at S-structure in Japanese, and its presence inEngbsh, interacts with these constraints to bar example8like (6) in English; see Lasnik ~ Salts.AcrEs DE COLING-92, NANTES, 2.3-28 AO(rl" 1992 6 3 3~ h: *ltca<l orderAgreement|lounding~Casc AdjacettcysWh in SyntaxaPro-Dropmd Japanese parameter settjn6snpecPinal :-\+  Bpeclnitial,het~d|nitial.hcadFinal :-\+ headhfitial.u~r(weak /bouudingNode(i2),boundingNode(np).caseAdj acency.wh\] n,qyntlax:- fig proDrop,mpecFinal :-\+ apeelnitial.headFm~l.headlnitial :-\+ hendFinal.agr(weak).boundingNode(i2 ).boundingNode(np).
;- no caneAdjacency,:-no whlnSynmxi)roDrop.
_ _  _As one can see from the figure, the system does cor-rectly rccover the right l,F, a.s the lmut one in snap-shot.
llowever, it also (surprisingly) discovers threeadditional LFs, i l lustrating the power of the system touncover alternative interpretations that a proper theoryof context would have the job of ruling out.
Ignoringin(liccs~ they all have tile sanlc t~)rn|: for what x, 'Farois so angry about \[the f~tct that pro obtained z\]llere the embedded subject 7hro h~ been inter-changed with the matr ix  subject pro.
It turns out thatthe sentence happens to bc ambiguous with respect tothe two basic interl)rc~atiotts, z l,br complcteness, hereate the three variants of that correspond to the firstthree LFs reported l)y the parser.
S. Miyagawa (i).c.
)informs us that the last two, given proper context, are infact possible.
These include.
: (1) pro is eoreferent withkoto ("fact"): s, i.e., for what x, Taro is so attgry about\[the fact that tim fact obtained x\]; (2) pry is corefcrentwith taro: for what z, Taro is so angry about \[the fact thatTaro obtained ~:\]; and (3) pry is free in the sentence: forwhat x, Taro is so &ngry al)out \[thc fact that (someone lse)t)btained x\].
~4 Pars ing  Japanese :  the  computat iona le f fec ts  o f  sc rantb l lng~ pro -drop ,  andphrase  s t ruc tureNext we turn to the investigation of the computalioaaldiffercnee,~ between the two languages that we haveexplored, and show how to use the system in mJ ex-ploratory mode I~o discover complexity differences be-tween English and Japanese.
Ia the discussion that foplows, we shall need to draw on comparisons between thecomplexity of different parses.
While this is a dclicatematter,  there arc two obvious metrics to use in compar-ing this parser's comt)lexity.
The tirst is the total num-ber of principle operations used to analyze a sentence -the munber of S-structures, chain forlnations, indcx-ings, tile case filter and otitcr constraint applications,etc.
We can treat these individually and tm a whole togive all account of the entire "search space" the parsermoves thr(mgh to discow~r analyses, llowever, this isrThis was pointed out by D, PesetHky, and conlirmed byM.
Salts.
llowever, t)resumably the nse of wa rather than9a and intonational pauses could be exploited as a surfacecue to rate out more gcnerally ambiguity in this examptcand others like it.
See l'bng and llerwick (1989) for a discuu-sion of how to integrate mtrfax:e cues into the principled~ased~ystem.tThis interpretation c~n be eliminated by itoposing sclcc-tional restriction, on the possible "agents" of okotteru (letuu say tbat they muut be animate).~Itaving a parsing system that can recover all such lin-guistic alternatives i of interest in its own rigltt, both toverify and correct the linguiutie theory, as well a8 enmlrethat no possibilities are overlooked by human interpreters.PRoc, OF COLING-92, N^I~rEs, AUG, 23-28, 1992Pr inc ip le -and-Parameters  Par~Build LR Graph Language Op Status Option~ Parsers Run Screen Sentences Time Traein0 IRun Sentence~ (ExaMples) e39a .
.
.
.ie39a 7-~ro-~ r Jant -o  tr-nl Irmta koto-o  ~oona,~t  okotteru noLFt \[C2CNP r~niJ-aoc \[01\[~2CNP taroJ-no~ \[liCvPCveCNvEs2Ct2 pro CllEVp\[\] CvPCsP teJ-dat CvICuet-B-P\] \[v /(BGR)t 2 0 1 4 1 3\[V ireta\]s j 5\] I \ ]  \[Itfl\]\] \[C\]\]\[N koto\]\]-acc3\[q\[Aov so?~il \[v (~(otte\]6\]fi\] \[VtT\] \[I I(HOR)2\[v Iro\]7\]2\]\] \[C no\]\]\]LF: \[CZ\[NP nanl\]-acc \[CI\[IZ\[NP taro\]-rloB \[II\[VP\[VPtNP\[C2\[12 P~'O \[n\[vP\[\] \[VP\[SP tel-dot \[VI\[NPC-FFP\] [v l(fl~R)1 2 2 1 ~ 1 2\[V lreta\]4\]4\]\]\] \[It2\]\] \[C\]\] \[N kOto\]\]-~W~5\[V\[ADV ~w~\[\] \[Vokotte\] \] 6\] \[Vt 7\] \[I I(~RI2tv ~rt/\] ?\] 2\]\] [c r~\]\]\]LF: Cc2\[sP t~an|\]-a(~ \[CI\[12\[NP taro\]-t~ \[II\[VP\[VP\[NPEC2\[12 pro \[II\[VP\[\] \[VP\[NP te\]-daL \[VI\[NPt-~-P\] \[V I(P~R)1 2 0 t 4 1Cv Ireta\]5\]5\]\]\] \[It3\]\] Ccl\] Cs koto\] -ace6 \[vCAov ~ot~i\] Cv okotte\] 7 \] 7 \] Creel Cl ,(mR)2 Cv Iru\]o\]2\]\] Cc ~\ ] \ ] \ ]LF : \[c2 \[NP aanl\] -ac?i \[el It2 ~ro 2 ell \[vP \[vP \[NP \[ c2 \[12 the taro\] ~8 \[11 \[vP \[\] I \[VP CsP t~\] -dat 4 \[ v1 \[NPt-~-P\] I Cv l(fl~R) 3\[v Ireta\] \] \]\]\] tit \]\]\[C\]\]\[N koto\]\]-a~c \[vtAov ~ i \ ] \ [v  ~o~te\] \] \] \[vt \]\[I I(~R) \[v it'u\] \] \]\]re n~\]\]\]55 3 6 77 8 2 82Ro (.ore) par'~e~~hFigure 1: Computer snapshot from Lasnik & Saito.often not a good measure of the total time speut inanalysis.
The second measure we use is more particularand precisely tailored to the specific backtracking-Litdesign we have built to recover structural descriptions:we can count the total number of Lit finite-state controlsteps taken in recovering the S-structure(s) for a givensentence; indeed, this accmmts for tile bulk of pars-lug time for those cases, as in Japanese and many En-glish sentences, where multiple quasi-S-structures arereturned.
Taken together, these two measures provideboth a coarse and a more fine-grained way of seeingwhat is hard or easy to compute)  ?5 Complex i ty  o f  Japanese  pars ingGiven this initial set of analyses, let us now examinethe complexity of Japanese sentence processing as com-pared to English.
To do this, we initially examinedsentences that we thought would highlight he ease ofJapanese relative to English, namely, the "classic" En-glish center-embedded vs. Japanese left-branching con-structs from Kuno (1973), e.g., The cheese the rat thecat John keeps killed, :Taro-ga kaHe-iru ncko-ga ko-rosila nezumi-gaOn the conventional Chomsky-Miller account, theEnglish construction is very difficult to parse, while theleft-branching Japanese form is completely understand-able.
Interestingly, as shown in figure 2 the nmnber ofoperations required to complete this parse correctly isenormous, as one can see from the righthand columnnumbers that show the structures that are passed intoand out of each principle module.It at first appears that left-branching structures aredefinitely not simpler than the corresponding center-embedded examples.
Why should this be?
On a mod-ern analysis uch as the one adopted here, recall thatrestrictive relative clauses, e.g.
the rat the cat killed,are open sentences, and so contain an operator-variablestructure coindexed with the rat, roughly:(l) \[NP\[NP the rat\]l \ [ep  Op .
.
.
.
the cat killed h\]\]l?Note that these two are metrics that are stable acrosscompile-cycles and different platforms.
This would be nottrue, of course, for simple parse times - -  the obviousalternative.where the empty operator (Op) is base-generatedin an A-position and subsequently fronted by Move-c~(Chomsky, 1986:86).Thus, the Japanese structures are center-embeddedafter aU--thc parser places a potcntially arbitrary stringof empty Operators at tile front of tile sentence.
Per-haps, then, the formal accounts of wily this sentenceshould be easy are incorrect; it is formally difficult buteasy oil other grounds.
Of course, alternatively, the the-pry or parsing model could be incorrect, or perhaps itis scrambling, or pro-drop, or the tlead-final characterof the language makes such sentences difficult.
In therest of this paper we focus on 3 attempts to discoverthe source of the cmnplcxity.To investigate these questions, wc embarked on a se-ries of optimization efforts that focused on the Specpositions of CP and the Ilead-final character of tile lan-guage, with the goal of making the Japanese as easy,or easier than, the corresponding English sentences ordetermining why we could not make it easier.
In all,we conducted three empirical tests: (1) using dummynonterminals to "lift" information from the verb to theVP node, to test the lIead-first/final hypothesis; (2)placing Spec of CP on the left rather than the right, totest the center-embedding hypothesis; and (3) buildinga "restricted" pseudo-Japanese that eliminated scram-bling and frec pro-drop, while nol lifting the informa-tion up aml to the left, leaving the llead-final characterintact.
We will next cover cash computer expcrimeut inturn.
Figure 3 gives a bar-graph summary of tim threeexperimental results in the form of times improvemcnt(reduction) ill LR state creation.Opt imizat ion  1: Head- f ina l  in fo rmat ionOur first optimization centers on the IIead-fiualphrase structure of Japanese.
With Heads at the end,valuable information (subcategorization, etc.)
may bcunavailable at the time the parser is to make a partic-ular decision, tIowever, for our Lit machine, there isa well-known programming language optimization: in-troduce dummy nonterminals on the left of a real non-terminal, e.g., VP--* X V NP, which, when reduced,call semantic action routines that can check the inputstream for a particular property (say, tile presence of anoun arbitrarily far to the right).
Specifically, if verbACRES DE COLING-92, NANTES, 23-28 ^ 0~' 1992 6 3 4 PRec.
OF COLING-92, NANTES, AUG. 23-28.
1992Princ, iple-e~nd-F%r'ome~er~ P a r s e r S _Build L~ firuph Languag= Oo Stalu~ Ootlon?
Par==r,?
~tm 5c~=o S=nt, anc??
lithe l~cino~ n t e ~ eSelect nnd R~ Stn~a,~a flgR~ ' ra ro -~ )?
.??.
=eu n*ko-#a koroetca  nez~#-g= e=b.e= ?~=*u-~-FI \[CZEllCN.\[C= Op \[Cl\[l?\[X~\[?/ ORafC\]\[II\[Np\[C?
O~3\[Ci\[~\[~ ~\]4\[H\[YP\[VP\[B~e~\]a\[V ~\ ]S \ ]  \[qt 6\] \[I IS,&o~w~- :Z. J '" 7 f~'t~ s~;T'~l~an~tte ~lt~\[11iz c,.
* ~U- - -~- - -~-  n t~,\ [ -~,  ~p\]k.tt.?
I\]hu 81 Oct, 9=4;1140J GflhIIIIJRY H i l l  13137 CL PL-U~ER= ~ LllpKld, l~F lUef~~7 .
.
.
.
.
.
.
.IOenerator~4aa0ct~Figure 2: Tile parse of tile Japanese counterpart of the English center-embedded question.
'I~'acing out the left-hand fringe of the tree, note the string of empty operators, ms well as, on the right-hand column, the large numberof parser operations required to build this single correct LF as COml)arcd to English (in the text).
Still, a singleparse is correctly returned.information occurs on the right we can oflline "lift" thatinformation up to the VP node, where it can then in-fluence the Lit state transitions that are made whenexamining material to the left of the head.
For exam-ple, for each V subcategory, the LK machine will con-tain in effect a a new Lit state; the system will add acommand to look ms far into the input as needed to de-termine whether to branch to this new state or anotherV subcategory state.
This is precisely tile mechanismwe used to determine whether to insert an empty cat-egory or not in a flead-first language.
For instance,in Japanese relative clauses this is of importance be-cause tile parser may get valuable information from theverb to determine whether a preceding NP belongs tothat relative clause or not.
tile action and transitiontables of the resulting Japanese machine, which we willcall "optimized," will be far larger than its base casecounterpart (more precisely: the action table is 3 timeslarger, or about 380K to 980K, while tile transition ta-ble is about twice as large, 72K to 142K).The advantages accrued by this optimization are sub-stantial, 2-10 times better; see the table below.
(Thisalso holds across other sentences; ee the bar graph sum-mary at the end of the paper.)
The unoptimized num-ber of LR state transitions grows astonishingly rapidly.For example, the transitions needed to parse ce4 is ex-actly mu shown--over 20 million of them, compared to1 million for the optimized version) 1Sentences:eel.
The cheese was rotten;ee2.
The cheese tile rat ate was rotten;ce3.
The che~e the rat tile cat killed ate was rotten.ce4.
The cheese the rat the cat John keeps killed ate wasrotten.
(=l~a on snapshot)(See figure 2 for computer output of the correspondingJapanese sentence.
)Tota l  number of Lit state t rans i t ionsSe,,t .
.
.
.
.
I JP,'~n?pt" I Jl', O,,t.
I Ti .... E .~,~I \[ I better(E') J el \[ 232 ~1~- -  \[ 1,9(6.1) 74ff~ 1e2 I 7122 I 1518 14.7(1.6) 2431 /~ I 257,042 125/246 \[ 10.18(.19) 4979 120,360,664966,114 ~A~( .03)  32101 _jThe same basic trend also holds, though not asstrongly, when we look at these and other sentencesin terms of the total number of principle operations re-quired; while we do not have space to review all of thesehere, as an example, sentence (15b) takes 4126 opera-tions in the base case, and 455 when optimized in thisfashion; while ce3 takes 1280 operations and 667 whenoptimized, respectively.a iWe should point out that in all cases, about a two-thirdsof these transitions occur before the LR machine reaches apoint in the search space where the solutions are "clustered"enough that the remaining solutions do not take go mucheffort.AcrEs DE COLING-92, NANTES, 23-28 Aour 1992 6 3 5 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992Opt imizat ion  2: Spec of  CP  on the  r ightA second obvious strategy is to remove the center-embedding itself, llere there is a grammatical move wecan make.
Evidently, in Japanese the only elementsthat appear in Spec of CP are put there by LF move-ment.
Thus, these elements can never be visible in thisposition on the surface.
If this is so, then there is reallynothing to prevent us from placing just the Spec of CPon the right, rather titan the left.
This is an exampleof the "testbed" property of the system; this changetakes two lines of code.
Given this change, the result-ing structures will have their Operators on the right,rather than the left, and will not be center-embedded.In addition, in this test the parser will not take advan-tage of right-hand information, thus eliminating this a.sa possible source of speedup.Parsing complexity is reduced by this move, by a fac-tor of just about one-half, if one considers either LRstate transitions or principle operations; not.
as good asthe first optimization; see below for some representativeresults.
Also, with the most deeply center-embeddedsentence the total number of principle operations ac-tually is worse titan in the base case.
Evidently wehave not located the source of the parser's problems incenter-embedding alone.Complexlty for Spee on the r ightSentence LR trans.
Total opseel 122 32ce2 4930 97ce3 209,980 721ce4 16,290,667 12605Opt imizat ion  3: Factor ing  out  t im effects ofsc rambl ing  arid pr0-dropWhile it appears that tlead~final information helpsthe most, we nmst also remember that part of the com-plexity of Japanese is the result of frce scrambling andpr0-drop.
To factor apart these effects, we ran a seriesof computer experimeuts on a quasi-J apanese grammar,J*, ttlat was just like Japanese except scrambling andpro-drop were barred.
The changes were again simpleto make: one change was automatic, just turning off aparameter value, while the second involved 3 lines ofhand-coding in the X" schemas to force the system tolook for a lexical NP in DO (and IO) positions l"urther,we did not optimize for right-hand information (so thatthe tlead-final character was left intact).
Of course,we now can rio longer parse sentences with scrambleddirect objects.The table below shows the results.
This was the bestoptimization of all.
Without scrambling, and henceno movement at all compared to English, the Ilead-final quasi-Japanese was for the most part parsed 5-10 times more efficiently than English, and at worst(for the triply-embedded sentence) with three timesfewer LR transitions and only about 30% more prin-ciple operations than English.
Thus, this was evenmore efficient han the righthand information optimizedJapanese parser.
(The first column gives the number ofLK transitions and the second gives the total munberof principle operations for this "no scramble/drop" ver-sion, while the last two columns give the same informa-tion for English.
)No scrambl ing/drop vs. Engllsh~ e ~ , R  t ...... No.
ops Eng.
LR Eng.
opseel \].03.
32 745 109ce2 \[274 88 2431 168ce3 11241 445 4979 558ce4 ~ 3719 21,074 2874As before, with a short sentence, there is little differ-ence between optimization mcthods, but over a rangeof sentences and with longer sentences, the no-scrambleor pro-drop optimization works better than any other.Evidently, given the framework of assumptions we havemade, the IleFtd-fnal character of Japanese does nothurt the most; rather, it is scrambling and pro-dropthat does, since if we remove these latter two effects weget the biggest improvement in parsing efficiency.
Wecan confirm this by looking at the Lt~ transitions for theother sentences (lb)-(18b) across methods, summariz-ing our tests.
We can summarize the three experimentsacro~q sentences in figure 3.Summary  of colnplexity across teatsuSentence ,opt.
Opt.
Spcc-Final No Scra-mble/drop~ - -  ~6"  730 602 2162b ~4 790 957 298311 3 289 185 1034b I 422 307* 1495b t2 1051 878* 370fib ~ 377 267 1381511 955 19,998 11,205 168117b ~7 1789 685 27218b i,036 84,727 43,745 53066 Conc lus ionsGiven our limited set of test sentences, our results mustbe correspondingly tentative.
Nonetheless, we can drawseveral initial conclusions:* One can parse Japanese by parametrically varying agrammar, nmch as expected.
Tile limits of the methodare theory-bound: we can accommodate just as muchas we understand about Japanese syntax.
* Attempting to parse more than one language withthe same grammar and parser carl quickly reveal whatis wrong with one's theory for either language.
In ourcase, we discovered omissions in the implementationrelating to Case transmission, the Wh-Comp Require-ment, and trace deletion, among other items.
* A single parser suffices for very distinct languages.The grammar is parameterized, but not the parser, con-firming nmch recent other research in Japanese sentenceprocessing cited in the introduction.
Japanese at firstappears much more complex to parse titan correspond-ing English sentences.
We suggest, tentatively, thatcomplexity is introduced by scrambling and omission ofNPs, rather than Ilead-final properties.
Unoptimized,the system is too slow.
Some efficiency is obtained if onecan "lift" information from the right for use in parsingwith an Llt machine.
Frmn a heuristic standpoint, hissuggests that strategies limiting what may appear in ascrambled position or dropped in a certain context willaid such art LR-based device more titan switching to aparser based presumably geared for a different branch-ing direction.?
The prineiple-bmsed system affords a new and gen-erally straightforward way to precisely explore differ-ent grammatical theories, structural assumptions, andparsing methods and their computational consequencesAcrEs DE COLING-92, NANTES, 23-28 AOt'rr 1992 6 3 6 I'ROC.
OF COLING-92, NAI~rES, AUG. 23-28, 19924035-i 30 -~ 25-i 20- 15-'LO-02470LOlb 2b ab 4b 5b 7b 15b 17b t 8b col co2 co3 e~,4.%tt~,m, .
;\[\] Right-lured iafiwmttion\[\]  Spoe CP tm fight * = complete partm not ob(ain~d\[\] No itcrtmbllng orprorhopFigure 3: A bar graph showing the improvemeat in total LI1.
transitions when parsing Japanese xamples lb -18b,and cel-ee4, compared against im original base case unoptimized parser, across tile 3 experiments described here.The horizontal line drawn at 1.0 indicates improvement over the base cause.in a precise way, without extensive hand coding.
All ofthe experiments we tried took no more than a few linesof modification.
Of course, the difficult part is to comeup with a universal set of principles in the first p lacc~so that in fact, English looks just about like Japanese,and vice-versa.7 ReferencesBaltin, M.R., aml A.S. Kroch (eds.
), 1989.
AlternativeConceptions of Phrase Structure, The Univemity ofChicago Press.Chomsky, N.A., 1986.
Knotoledge o\] Language: Its Nature,Origin, and Use.
Prager.Correa, N., 1988.
Syntactic Analysis of English with respectto Government-binding Grammax, Ph.D. dissertation,Syracuse University.Crocker, M.W., 1989.
A Principle-Based System .for Syn-tactic Analysis, (m.s.
).Dorr, B.J., 1987.
UNITRAN: A Principle-Based Appro~tchto Machine Translation.
S.M.
thesis.
MIT Departmentof Electrical Engineering and Computer Science.Fong, S. & R.C.
Berwick, 1989.
The computational in|-plementa~tion of principle-based parsers, blternationalWorkshop on Parsing Technologies., Carnegie MellonUniversity, in M. Tomita (ed) Current lssues in Pars-ing Technologies, Kluwer.Fong, S., 1991.
Computational Properties of Principle-baaed Grammatical Theories.
Ph.D., dissertation, M\[TDepartment ofComputer Science and Electrical Engi-neering.Frazier, L., and K. Rayner, 1988.
Parameterizing the lan-guage processing system: Left- vs. right-branchingwithin and across languages.
In J. tiawkias (ed.)
Ex-pluming Language Universals, llasi\[ Blackwell, Oxford,pp.
247 279.Hosokawa, I1.
1991.
Syntactic difl:erences betwemt Englishand Japanese.
Georgetown Journal of Languages andLinguistics, 1:4,401-414.lnoue, N. and Fodor, J.D., 1991.
Information-paced process-ing of Japanese sentences.
Paper presented at the In-ternationM Workshop on Japanese Syntactic Process-ing, Duke University.Johnson, M., 1989.
Use of tile Knowledge of Language,Journal of Psyeholingulstic Research.
18(1).Knno, S., 1973.
\]'he Slruclure of the Japanese Language,Cambridge, MA: MIT Press.Lamdk, H. & M. Saito, 1984.
On the nature of proper gov-ernment.
Lir~guistic h~quiry, 15:2.Lasnik, II.
& J. Uriagereka, 1988.
A C'ourse in GB Syn-tax: Lectmves on Binding and Empty Categories, Cam-bridge, MA: M1T Press.Mazuka, It., 19911.
Processing of empty categories inJapanese.
Manuscript, Duke University.Nagai, N., 1991.
Paper presented at the International Con-ference on Japanese Sylttactic Processing, l)uke Uni-versity.Sharp, ILM., 1985.
A Model of Gramntar Based on Princi-ples of (~overnment a td l\]inding Theory.
M.S.
thesis.Department of Computer Science.
University of BritishColumbia.Stabler, E.P., Jr., 1991 forthcoming.
The Logical Approachto Syntax: Foundations, Specifications and Implemen-tations o\] Theories of Government and Binding., Cam-bridge, MA: MIT Press.Tomita, M., 1986.
E~icient Parsing \]or Natural Language:A Fast Algorithm for Practical Stlstems.
Kluwer.Wehrli, E., 1986.
A Government-Binding Parser `for l')~neh.Working Paper No.
48.
University of Geneva.ACTES DE COLING-92, NAm.Es.
23-28 ^ o(rr 1992 6 3 7 I)ROC.
OF COLING-92, NANTES, AUo.
23-28.
1992
