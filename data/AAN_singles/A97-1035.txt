Software Infrastructure for Natural Language ProcessingHamish CunninghamDept.
Computer ScienceUniversity of Sheffield211 Portobello St.Sheffield S10 4DPhamish~dcs,  she f .
ac.
ukKevin HumphreysDept.
Computer ScienceUniversity of Sheffield211 Portobello St.Sheffield S10 4DPkvhOdcs, she f .
ac.
ukRobert GaizauskasDept.
Computer ScienceUniversity of Sheffield211 Portobello St.Sheffield S10 4DProbertg@dcs, shef.
ac.
ukYorick WilksDept.
Computer ScienceUniversity of Sheffield211 Portobello St.Sheffield S10 4DPyorick~dcs, shef.
ac.
ukAbst ractWe classify and review current approachesto software infrastructure for research, de-velopment and delivery of NLP systems.The task is motivated by a discussion ofcurrent rends in the field of NLP and Lan-guage Engineering.
We describe a sys-tem called GATE (a General Architecturefor Text Engineering) that provides a soft-ware infrastructure on top of which het-erogeneous NLP processing modules maybe evaluated and refined individually, ormay be combined into larger applicationsystems.
GATE aims to support both re-searchers and developers working on com-ponent technologies (e.g.
parsing, tagging,morphological analysis) and those work-ing on developing end-user applications(e.g.
information extraction, text sum-marisation, document generation, machinetranslation, and second language learning).GATE promotes reuse of component tech-nology, permits specialisation and collab-oration in large-scale projects, and allowsfor the comparison and evaluation of al-ternative technologies.
The first release ofGATE is now available.1 In t roduct ionThis paper reviews the currently available designstrategies for software infrastructure for NLP andpresents an implementation of a system calledGATE - a General Architecture for Text Engineer-ing.
By software infrastructure we mean what hasbeen variously referred to in the literature as: soft-ware architecture; software support tools; languageengineering platforms; development enviromnents.Our gloss on these terms is: common models for therepresentation, storage and exchange of data in andbetween processing modules in NLP systems, alongwith graphical interface tools for the management ofdata and processing and the visualisation of data.NLP systems produce information about texts 1, andexisting systems that aim to provide software in-frastructure for NLP can be classified as belongingto one of three types according to the way in whichthey treat this information:add i t ive ,  o r  markup-based:information produced is added to the text inthe form of markup, e.g.
in SGML (Thompsonand McKelvie, 1996);referent ia l ,  or  annotat ion -based:  informationis stored separately with references back to theoriginal text, e.g.
in the T IPSTER architecture(Grishman, 1996);abst ract ion -based:  the original text is preservedin processing only as parts of an integrated atastructure that represents information aboutthe text in a uniform theoretically-motivatedmodel, e.g.
attribute-value structures in theALEP system (Simkins, 1994).A fourth category might be added to cater for thosesystems that provide communication and controlinfrastructure without addressing the text-specificneeds of NLP (e.g.
Verbmobil's ICE architecture(Amtrup, 1995)).We begin by reviewing examples of the three ap-proaches we sketched above (and a system that fallsinto the fourth category).
Next we discuss currenttrends in the field and motivate a set of requirementsthat have formed the design brief for GATE, whichis then described.
The initial distribution of thesystem includes a MUC-6 (Message UnderstandingConference 6 (Grishman and Sundheim, 1996)) styleinformation extraction (IE) system and an overview1These texts may sometimes be the results of auto-matic speech recognition - see section 2.6.237of these modules is given.
GATE is now availablefor research purposes - seehttp ://ul;w. dcs.
shef.
ac.
u_k/research/groups/nlp/gate/ for details of how to obtain the system.It is written in C++ and Tc l /Tk  and currently runson UNIX (SunOS, Solaris, Irix, Linux and AIX areknown to work); a Windows NT version is in prepa-ration.2 Manag ing  In fo rmat ion  about  Text2.1 Abst rac t ion  ApproachesThe abstraction-based approach to managing in-formation about texts is primarily motivated bytheories of the nature of the information to berepresented.
One such position is that declara-tive, constraint-based representations u ing feature-structure matrices manipulated under unificationare an appropriate vehicle by which "many techni-cal problems in language description and computermanipulation of language can be solved" (Shieber,1992).
Information in these models may be charac-terised as abstract in our present context as thereis no requirement to tie data elements back to theoriginal text - these models represent abstractionsfrom the text.One recent example of an infrastructure projectbased on abstraction is ALEP - the Advanced Lan-guage Engineering Platform (Simkins, 1994).
ALEPaims to provide "the NLP research and engineeringcommunity in Europe with an open, versatile, andgeneral-purpose d velopment environment".
ALEP,while in principle open, is primarily an advanced sys-tem for developing and manipulating feature struc-ture knowledge-bases under unification.
Also pro-vided are several parsing algorithms, algorithms fortransfer, synthesis and generation (Schlitz, 1994).As such, it is a system for developing particulartypes of data resource (e.g.
grammars, lexicons) andfor doing a particular set of tasks in LE in a particu-lar way.
ALEP does not aim for complete gener-icity (or it would need also to supply algorithmsfor Baum-Welch estimation, fast regular expressionmatching, etc.).
Supplying a generic system to doevery LE task is clearly impossible, and prone toinstant obsolescence in a rapidly changing field.In our view ALEP, despite claiming to use atheory-neutral formalism (an HPSG-like formalism),is still too committed to a particular approach to lin-guistic analysis and representation.
It is clearly ofhigh utility to those in the LE community to whomthese theories and formalisms are relevant; but itexcludes, or at least does not actively support, allthose who are not, including an increasing numberof researchers committed to statistical, corpus-basedapproaches.
GATE, as will be seen below, is morelike a shell, a backplane into which the whole spec-trum of LE modules and databases can be plugged.Components used within GATE will typically existalready - our emphasis is reuse, not reimplementa-tion.
Our project is to provide a flexible and efficientway to combine LE components to make LE systems(whether experimental or for delivered applications)- not to provide 'the one true system', or even 'theone true development environment'.
Indeed, ALEP-based systems might well provide components oper-ating within GATE.
Seen this way, the ALEP enter-prise is orthogonal to ours - there is no significantoverlap or conflict.In our view the level at which we can assume com-monality of information, or of representation of in-formation, between LE modules is very low, if weare to build an environment which is broad enoughto support the full range of LE tools and acceptthat we cannot impose standards on a research com-munity in flux.
What does seem to be a highestcommon denominator is this: modules that processtext, or process the output of other modules thatprocess text, produce further information about thetext or portions of it.
For example, part-of-speechtags, phrase structure trees, logical forms, discoursemodels can all be seen in this light.
It would seem,therefore, that we are on safe common ground if westart only by committing to provide a mechanismwhich manages arbitrary information about text.There are two methods by which this may be done.First, one may embed the information in the text atthe relevant points - the additive approach.
Second,one may associate the information with the text bybuilding a separate database which stores this in-formation and relates it to the text using pointersinto the text - the re\]erential pproach.
The nexttwo subsections discuss systems that have adoptedthese two approaches respectively, then we comparethe two and indicate why we have chosen a hybridapproached based mainly on the second.
Finally welook at a system that falls outside our three cate-gories.2.2 Add i t ive  ApproachesAdditive architectures for managing informationabout text add markup to the original text at eachsuccessive phase of processing.
This model has beenadopted by a number of projects including parts ofthe MULTEXT EC project.
The MULTEXT work 2has led to the development of an architecture based2Note that other partners in theproject adopted a different architectural solution - seehttp ://www.
ipl.
univ-aix, fr/proj ect s/multext/.238on SGML at the University of Edinburgh called LT-NSL (Thompson and McKelvie, 1996).The architecture is based on a commitment toTEI-style (the Text Encoding Initiative (Sperberg-McQueen and Burnard, 1994)) SGML encoding ofinformation about text.
The TEI defines standardtag sets for a range of purposes including many rel-evant to LE systems.
Tools in a LT-NSL systemcommunicate via interfaces pecified as SGML doc-ument type definitions (DTDs - essentially tag setdescriptions), using character streams on pipes - anarrangement modelled after UNIX-style shell pro-gramming.
To obviate the need to deal with somedifficult types of SGML (e.g.
minimised markup)texts are converted to a normal form before process-ing.
A tool selects what information it requiresfrom its input SGML stream and adds informationas new SGML markup.
An advantage here is adegree of data-structure independence: so long asthe necessary information is present in its input, atool can ignore changes to other markup that in-habits the same stream - unknown SGML is simplypassed through unchanged (so, for example, a se-mantic interpretation module might examine phrasestructure markup, but ignore POS tags).
A disad-vantage is that although graph-structured data maybe expressed in SGML, doing so is complex (eithervia concurrent markup, the specification of multi-ple legal markup trees in the DTD, or by ratherugly nesting tricks to cope with overlapping - so-called "milestone tags").
Graph-structured informa-tion might be present in the output of a parser, forexample, representing competing analyses of areasof text.2.3 Referent ia l  ApproachesThe ARPA-sponsored T IPSTER programme in theUS, now entering its third phase, has also produceda data-driven architecture for NLP systems (Grish-man, 1996).
Whereas in LT-NSL all informationabout a text is encoded in SGML, which is added bythe modules, in T IPSTER a text remains unchangedwhile information is stored in a separate database- the referential approach.
Information is storedin the database in the form of annotations.
Anno-tations associate arbitrary information (attributes),with portions of documents (identified by sets ofstart/end byte offsets or spans).
Attributes may bethe result of linguistic analysis, e.g.
POS tags or tex-tual unit type.
In this way the information built upabout a text by NLP modules is kept separate fromthe texts themselves.
In place of an SGML DTD,an annotation type declaration defines the informa-tion present in annotation sets.
Figure 1 shows anexample from (Grishman, 1996).TeztSarah savored the soup.0...15...110..115..120AnnotationsId TypetokentokentokentokentokennamesentenceSpanStart End0 56 1314 1718 2222 230 50 23Attributespos=NPpos----VBDpos----DTpos----NNname_type=personFigure 1: T IPSTER annotations exampleThe definition of annotations in T IPSTER formspart of an object-oriented model that deals withinter-textual information as well as single texts.Documents are grouped into collections, each witha database storing annotations and document at-tributes uch as identifiers, headlines etc.
The modelalso describes elements of information extraction(IE) and information retrieval (IR) systems relatingto their use, with classes representing queries andinformation eeds.The T IPSTER architecture is designed to beportable to a range of operating environments, oit does not define implementation technologies.
Par-ticular implementations make their own decisions re-garding issues such as parallelism, user interface, ordelivery platform.
Various implementations of TIP-STER systems are available, including one in GATE.2.4 Compar i son  o f  LT -NSL  and  T IPSTERBoth architectures are appropriate for NLP, butthere are a number of significant differences.
Wediscuss five here, then note the possibility of compli-mentary inter-operation of the two.1.
T IPSTER can support documents on read-onlymedia (e.g.
Internet material, or CD-ROMs,which may be used for bulk storage by organisa-tions with large archiving needs) without copy-ing each document.2.
From the point of view of efficiency, the originalLT-NSL model of interposing SGML betweenall modules implies a generation and parsingoverhead in each module.
Later versions havereplaced this model with a pre-parsed represen-tation of SGML to reduce this overhead.
Thisrepresentation will presumably be stored in in-termediate files, which implies an overhead fromthe I /O involved in continually reading and239writing all the data associated with a documentto file.
There would seem no reason why thesefiles should not be replaced by a database im-plementation, however, with potential perfor-mance benefits from the ability to do I /O onsubsets of information about documents (andfrom the high level of optimisation present inmodern database technology).3.
A related issue is storage overhead.
T IPSTERis minimal in this respect, as there is no inher-ent need to duplicate the source text and all itsmarkup during the nromalisation process.4.
At first thought texts may appear to be one-dimensional, consisting of a sequence of charac-ters.
This view breaks down when structureslike tables appear - these are inherently two-dimensional and their representation and ma-nipulation is much easier in a referential modellike T IPSTER than in an additive model likeSGML because a markup-based representationis based on the one-dimensional view.
In TIP-STER, the column of a table can be repre-sented as a single object with multiple refer-ences to parts of the text (an annotation withmultiple spans).
Marking columns in SGML re-quires a tag for each row of the column.
Relatedpoints are that: T IPSTER avoids the difficul-ties referred to earlier of representing raph-structured information in SGML; LT NSL isinefficient where processing algorithms requirenon-sequential ccess to data (McKelvie, Brew,and Thompson, 1997).5.
T IPSTER can easily support multi-level accesscontrol via a database's protection mechanisms- this is again not straightforward in SGML.6.
Distributed control is easy to implement in adatabase-centred system like T IPSTER - theDB can act as a blackboard, and implemen-tations can take advantage of well-understoodaccess control (locking) technology.
How todo distributed control in LT-NSL is not obvi-ous.
We plan to provide this type of control inGATE via collaboration with the Corelli projectat CRL, New Mexico - see (Zajac, 1997) formore details.2.5 Combin ing  Add i t ion  and ReferenceWe believe the above comparison demonstrates thatthere are significant advantages to the T IPSTERmodel and it is this model that we have chosen forGATE.We also believe that SGML and the TEI must re-main central to any serious text processing strategy.The points above do not contradict his view, butindicate that SGML should not form the central rep-resentation format of every text processing system.Input from SGML text and TEI  conformant outputare becoming increasingly necessary for LE appli-cations as more and more publishers adopts thesestandards.
This does not mean, however, that flat-file SGML is an appropriate format for an architec-ture for LE systems.
This observation is born outby the facts that T IPSTER started with an SGMLarchitecture but rejected it in favour of the currentdatabase model, and that LT-NSL has gone partlytowards this style by passing pre-parsed SGML be-tween components.Interestingly, a T IPSTER referential system couldfunction as a module in an LT-NSL additive system,or vice-versa.
A T IPSTER storage system couldwrite data in SGML for processing by LT-NSL tools,and convert he SGML results back into native for-mat.
Work is underway to integrate the LT-NSLAPI with GATE and provide SGML I /O for TIP-STER (and we acknowledge valuable assistance fromcolleagues at Edinburgh in this task).2.6  ICEICE, the Intarc Communication Environment(Amtrup, 1995), is an 'environment for the develop-ment of distributed AI systems'.
As part of the Verb-mobil real-time speech-to-speech translation projectICE has addressed two key problems for this typeof system, viz.
distributed processing and incremen-tal interpretation (Gorz et al, 1996): distributionto contribute to processing speed in what is a verycompute-intensive application area; incremental in-terpretation both for speed reasons and to facili-tate feedback of results from downstream odulesto upstream ones (e.g.
to inform the selection ofword interpretations from phone lattices using part-of-speech information).ICE provides a distribution and communicationlayer based on PVM (Parallel Virtual Machine).The infrastructure that ICE delivers doesn't fit intoour tripartite classification because the communica-tion channels do not use data structures pecific toNLP needs, and because data storage and text col-lection management is left to the individual modules.ICE might well form a useful backbone for an NLPinfrastructure, and could operate in any of the threeparadigms.3 NLP  Trends  and  GATEFor a variety of reasons NLP has recently spawneda related engineering discipline called language ngi-neering (LE), whose orientation is towards the appli-240cation of NLP techniques to solving large-scale, real-world language processing problems in a robust andpredictable way.
These problems include informa-tion extraction, text summarisation, document gen-eration, machine translation, second language learn-ing, amongst others.
In many cases, the technologiesbeing developed are assistive, rather than fully auto-matic, aiming to enhance or supplement a human'sexpertise rather than attempting to replace it.The reasons for the growth of language ngineer-ing include:?
computer hardware advances which have in-creased processor speeds and memory capacity,while reducing prices;?
increasing availability of large-scale, language-related, on-line resources, such as dictionaries,thesauri, and 'designer' corpora - corpora se-lected for representativeness and perhaps anno-tated with descriptive information;?
the demand for applications in a world whereelectronic text has grown exponentially in vol-ume and availability, and where electronic om-munications and mobility have increased theimportance of multi-lingual communication;?
maturing NLP technology which is now able, forsome tasks, to achieve high levels of accuracyrepeatedly on real data.Aside from the host of fundamental theoreticalproblems that remain to be answered in NLP, lan-guage engineering faces a variety of problems of itsown.
Two features of the current situation are ofprime importance; they constrain how the field candevelop and must be acknowledged and addressed.First, there is no theory of language which is uni-versally accepted, and no computational model ofeven a part of the process of language understandingwhich stands uncontested.
Second, building intelli-gent application systems, systems which model orreproduce nough human language processing capa-bility to be useful, is a large-scale ngineering ef-fort which, given political and economic realities,must rely on the efforts of many small groups of re-searchers, patially and temporally distributed, withno collaborative master plan.The first point means that any attempt o pushresearchers into a theoretical or representationalstraight-jacket is premature, unhealthy and doomedto failure.
The second means that no research teamalone is likely to have the resources to build fromscratch an entire state-of-the-art LE application sys-tem.
Note the tension here: the first point identi-fies a centrifugal tendency, pushing researchers intoever greater theoretical diversity; the second, a cen-tripetal tendency forcing them together.Given this state of affairs, what is the best prac-tical support hat can be given to advance the field?Clearly, the pressure to build on the efforts of othersdemands that LE tools or component technologies -parsers, taggers, morphological nalysers, discourseplanning modules, etc, - be readily available for ex-perimentation and reuse.
But the pressure towardstheoretical diversity means that there is no point at-tempting to gain agreement, in the short term, onwhat set of component technologies should be de-veloped or on the informational content or syntaxof representations that these components should re-quire or produce.Our response to these considerations has beento design and implement a software environmentcalled GATE - a General Architecture for Text Engi-neering (Cunningham, Gaizauskas, and Wilks, 1995;Cunningham, Wilks, and Gaizauskas, 1996) - whichattempts to meet the following objectives:1. support information interchange between LEmodules at the highest common level possi-ble without prescribing theoretical approach(though it allows modules which share theoret-ical presuppositions to pass data in a mutuallyaccepted common form);2. support the integration of modules written inany source language, available either in sourceor binary form, and be available on any commonplatform;3. support the evaluation and refinement of LEcomponent modules, and of systems built fromthem, via a uniform, easy-to-use graphical in-terface which in addition offers facilities for vi-sualising data and managing corpora.The remainder of this paper describes the design ofGATE.
In section 4 we detail the design of GATE.Section 5 illustrates how GATE can be used by de-scribing how we have taken a pre-existing informa-tion extraction system and embedded it in GATE.Section 6 makes some concluding remarks.4 GATE Des ignCorresponding to the three key objectives identifiedat the end of section 3, GATE comprises three prin-cipal elements: GDM, the GATE Document Man-ager, based on the T IPSTER document manager;CREOLE, a Collection of REusable Objects for Lan-guage Engineering: a set of LE modules integratedwith the system; and GGI, the GATE Graphical In-terface, a development tool for LE R&:D, providing241integrated access to the services of the other compo-nents and adding visualisation and debugging tools.Working with GATE, the researcher will from theoutset reuse existing components, and the commonAPIs of GDM and CREOLE mean only one inte-gration mechanism must be learnt.
As CREOLEexpands, more and more modules will be availablefrom external sources (including users of other TIP-STER systems).4.1 GDMThe GDM provides a central repository or serverthat stores all information an LE system generatesabout the texts it processes.
All communication be-tween the components of an LE system goes throughGDM, which insulates these components from directcontact with each other and provides them with auniform API for manipulating the data they pro-duce and consume.The basic concepts of the data model underlyingthe GDM have been explained in the discussion ofthe Tipster model in section 2.3 above.
The TIP-STER architecture has been fully specified (Grish-man, 1996) and its specification should be consultedfor further details, in particular for definitions of theAPI.
The GDM is fully conformant with the coredocument management subset of this specification.4.2 CREOLEAll the real work of analysing texts in a GATE-basedLE system is done by CREOLE modules or objects(we use the terms module and object rather looselyto mean interfaces to resources which may be pre-dominantly algorithmic or predominantly data, or amixture of both).
Typically, a CREOLE object willbe a wrapper around a pre-existing LE module ordatabase - a tagger or parser, a lexicon or ngramindex, for example.
Alternatively, objects may bedeveloped from scratch for the architecture - in ei-ther case the object provides a standardised API tothe underlying resources which allows access via GGIand I /O via GDM.
The CREOLE APIs may also beused for programming new objects.When the user initiates a particular CREOLE ob-ject via GGI (or when a programmer does the samevia the GATE API when building an LE applica-tion) the object is run, obtaining the information itneeds (document source, annotations from other ob-jects) via calls to the GDM API.
Its results are thenstored in the GDM database and become availablefor examination via GGI or to be the input to otherCREOLE objects.GDM imposes constraints on the I /O tbrmat ofCREOLE objects, namely that all information mustbe associated with byte offsets and conform to theannotations model of the T IPSTER architecture.The principal overhead in integrating a module withGATE is making the components use byte offsets, ifthey do not already do so.4.3 GGIThe GGI is a graphical tool that encapsulates theGDM and CREOLE resources in a fashion suitablefor interactive building and testing of LE compo-nents and systems.
The GGI has functions for creat-ing, viewing and editing the collections of documentswhich are managed by the GDM and that form thecorpora which LE modules and systems in GATEuse as input data.
The GGI also has facilities todisplay the results of module or system execution -new or changed annotations associated with the doc-ument.
These annotations can be viewed either inraw form, using a generic annotation viewer, or in anannotation-specific way, if special annotation view-ers are available.
For example, named entity annota-tions which identify and classify proper names (e.g.organization ames, person names, location names)are shown by colour-coded highlighting of relevantwords; phrase structure annotations are shown bygraphical presentation of parse trees.
Note that theviewers are general for particular types of annota-tion, so, for example, the same procedure is used forany POS tag set, Named-Entity markup etc.
(seesection 4.4 below).
Thus CREOLE developers reuseGATE data visualisation code with negligible over-head.4.4 Plug and PlayThe process of integrating existing modules intoGATE (CREOLEising) has been automated to alarge degree and can be driven from the interface.The developer is required to produce some C orTcl code that uses the GDM T IPSTER API to getinformation from the database and write back re-sults.
When the module pre-dates integration, thisis called a wrapper as it encapsulates the module ina standard form that GATE expects.
When mod-ules are developed specifically for GATE they canembed T IPSTER calls throughout heir code anddispense with the wrapper intermediary.
The under-lying module can be an external executable writtenin any language (the current CREOLE set includesProlog, Lisp and Perl programs, for example).There are three ways to provide the CREOLEwrapper functions.
Packages written in C, or inlanguages which obey C linkage conventions, canbe compiled into GATE directly as a Tcl pack-age.
This is tight coupling and is maximally efficientbut necessitates recompilation of GATE when mod-ules change.
On platforms which support shared242libraries C-based wrappers can be loaded at run-time - dynamic oupling.
This is also efficient (witha small penalty at load time) and allows devel-opers to change CREOLE objects and run themwithin GATE without recompiling the GATE sys-tem.
Wrappers written in Tcl can also be loaded atrun-time - loose coupling.
There is a performancepenalty in comparison with using the C APIs, butfor simple cases this is the easiest integration route.In each case the implementation of CREOLE ser-vices is completely transparent to GATE.CREOLE wrappers encapsulate informa-tion about the preconditions for a module to run(data that must be present in the GDM database)and post-conditions (data that will result).
This in-formation is needed by GGI, and is provided by thedeveloper in a configuration file, which also detailswhat sort of viewer to use for the module's resultsand any parameters that need passing to the module.These parameters can be changed from the interfaceat run-time, e.g.
to tell a parser to use a differentlexicon.
Aside from the information eeded for GGIto provide access to a module, GATE compatibilityequals T IPSTER compatibility - i.e.
there will bevery little overhead in making any T IPSTER mod-ule run in GATE.Given an integrated module, all other interfacefunctions happen automatically.
For example, themodule will appear in a graph of all modules avail-able, with permissible links to other modules auto-matically displayed, having been derived from themodule pre- and post-conditions.At any point the developer can create a new graphfrom a subset of available CREOLE modules to per-form a task of specific interest.5 V IE :  An  App l i ca t ion  In  GATETo illustrate the process of converting pre-existingLE systems into GATE-compatible CREOLE setswe use as an example the creation of VIE (VanillaInformation Extraction system) from LaSIE (Large-Scale Information Extraction system) (Gaizauskaset al, 1995), Sheffield's entry in the MUC-6 sys-tem evaluations.
LaSIE module interfaces were notstandardised when originally produced and its CRE-OLEization gives a good indication of the ease of in-tegrating other LE tools into GATE.
The resultingsystem, VIE, is distributed with GATE.5.1 LaSIELaSIE was designed as a research system for inves-tigating approaches to information extraction andto be entered into the MUC-6 conference (Grish-man and Sundheim, 1996).
As such it was a stand-alone system that was aimed at specific tasks and,while based on a modular design, none of its mod-ules were specifically designed with reuse in mind,nor was there any attempt o standardise data for-mats passed between modules.
Modules were writ-ten in a variety of programming languages, includ-ing C, C++,  Flex, Perl and Prolog.
In this regardLaSIE was probably typical of existing LE systemsand modules.
The high-level tasks which LaSIEperformed include the four MUC-6 tasks (carriedout on Wall Street Journal articles) - named entityrecognition, coreference r solution and two templatefilling tasks.
The system was a pipelined architec-ture which processes a text sentence-at-a-time andconsists of three principal processing stages: lexicalpreprocessing, parsing plus semantic interpretation,and discourse interpretation.5.2 The CREOLEisation of LaSIEAs described in section 4.2, CREOLEisation of ex-isting LE modules involves providing them with awrapper so that the modules communicate via theGDM, by accessing TIPSTER-compl iant documentannotations and updating them with new informa-tion.
The major work in converting LaSIE to VIEinvolved defining useful module boundaries, unpick-ing the connections between them, and then writingwrappers to convert module output into annotationsrelating to text spans and to convert GDM inputfrom annotations relating to text spans back intothe module's native input format.The complete VIE system comprises ten modules,each of which is a CREOLE object integrated intoGATE.
The CREOLEisation took approximatelytwo person months.
The resulting system has all thefunctionality of the original LaSIE system.
However,the interface makes it much easier to use.
And, ofcourse, it is now possible to swap in modules, such asa different parser, with significantly less effort thanwould have been the case before.
For more detailsof this process ee (Cunningham et al, 1996).VIE and its components are being deployed fora number of purposes including IE in French, Ger-man and Spanish.
Experience so far indicates thatGATE is a productive nvironment for distributedcollaborative reuse-based software development.6 Conc lud ing  RemarksOf course, GATE does not solve all the problemsinvolved in plugging diverse LE modules together.There are three barriers to such integration:?
managing storage and exchange of informationabout texts;243?
incompatibility of representation f informationabout texts;?
incompatibility of type of information used andproduced by different modules.GATE provides a solution to the first two of these,based on the work of the TIPSTER architecturegroup.
Because GATE places no constraints on thelinguistic formalisms or information content usedby CREOLE modules, the latter problem mustbe solved by dedicated translation functions - e.g.tagset-to-tagset mapping - and, in some cases, byextra processing - e.g.
adding a semantic processorto complement a bracketing parser.The recent completion of this work means a fullassessment of the strengths and weaknesses ofGATEis not yet possible.
The implementation f VIE inGATE, however, provides an existence proof thatthe original conception is workable.
We believe thatthe environment provided by GATE will now allowus to make significant strides in assessing alterna-tive LE technologies and in rapidly assembling LEprototype systems.
Thus, to return to the themes ofsection 3, GATE will not commit us to a particularlinguistic theory or formalism, but it will enable us,and anyone who wishes to make use of it, to build,in a pragmatic way, on the diverse fforts of others.7 AcknowledgementsThis work was supported by the UK Engineering andPhysical Sciences Research Council, grant numberGR/K25267, and the EC DG XIII Language Engi-neering programme, grant number LE1-2238.ReferencesAmtrup, J.W.
1995.
ICE - INTARC Communica-tion Environment User Guide and Reference Man-ual Version 1.4.
Technical report, University ofHamburg.Cunningham, H., R.G.
Gaizauskas, and Y. Wilks.1995.
A General Architecture for Text En-gineering (GATE) - a new approach to Lan-gnage Engineering R&D.
Technical ReportCS - 95 - 21, Department of Computer Sci-ence, University of Sheffield.
Also available ashttp ://xxx.
lanl.
gov/ps/cmp-lg/9601009.Cunningham, H., K. Humphreys, R. Gaizauskas,and M. Stower, 1996.
CREOLE Devel-oper's Manual.
Department of Computer Sci-ence, University of Sheffield.
Available athttp ://www.
dcs.
shef.
ac.
uk/resear ch/groups/nip/gate.Cunningham, H., Y. Wilks, and R. Gaizauskas.1996.
GATE - a General Architecture for TextEngineering.
In Proceedings of the 16th Con-ference on Computational Linguistics (COLING-96), Copenhagen, August.Gaizanskas, R., T. Wakao, K Humphreys, H. Cun-ningham, and Y. Wilks.
1995.
Description of theLaSIE system as used for MUC-6.
In Proceedingsof the Sixth Message Understanding Conference(MUC-6).
Morgan Kaufmann.Gorz, G., M. Kessler, J. Spilker, and H. Weber.1996.
Research on Architectures for IntegratedSpeech/Language Systems in Verbmobil.
In Pro-ceedings of COLING-96, Copenhagen.Grishman, R. 1996.
TIPSTER Architecture DesignDocument Version 2.2.
Technical report, DARPA.Available at h t tp  ://www.
t ips ter ,  org/.Grishman, R. and B. Sundheim.
1996.
Messageunderstanding conference - 6: A brief history.
InProceedings of the 16th International Conferenceon Computational Linguistics, Copenhagen, June.McKelvie, D., C. Brew, and H. Thompson.
1997.Using SGML as a Basis for Data-Intensive NLP.In Proceedings of the fifth Conference on AppliedNatural Language Processing (ANLP-97).Schiitz, J.
1994.
Developing Lingware in ALEP.ALEP User Group News, CEC Luxemburg, 1(1),October.Shieber, S. 1992.
Constraint-Based Grammar For-malisms.
MIT Press.Simkins, N. K. 1994.
An Open Architecture forLanguage Engineering.
In First Language Engi-neering Convention, Paris.Sperberg-McQueen, C.M.and L. Burnard.
1994.Guidelines for Electronic Text Encoding and In-terchange (TEl P3).
ACH, ACL, ALLC.Thompson, H.S.
and D. McKelvie.
1996.
A SoftwareArchitecture for Simple, Efficient SGML Applica-tions.
In Proceedings of SGML Europe '96, Mu-nich.Zajac, R. 1997.
An Open Distributed Architecturefor Reuse and Integration of Heterogenous NLPComponents.
In Proceedings of the 5th conferenceon Applied Natural Language Processing (ANLP-97).244
