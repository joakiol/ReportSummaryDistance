Proceedings of the ACL 2010 Conference Short Papers, pages 258?262,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsCross Lingual Adaptation: An Experiment on Sentiment ClassificationsBin WeiUniversity of RochesterRochester, NY, USA.bwei@cs.rochester.eduChristopher PalE?cole Polytechnique de Montre?alMontre?al, QC, Canada.christopher.pal@polymtl.caAbstractIn this paper, we study the problem ofusing an annotated corpus in English forthe same natural language processing taskin another language.
While various ma-chine translation systems are available, au-tomated translation is still far from per-fect.
To minimize the noise introducedby translations, we propose to use onlykey ?reliable?
parts from the translationsand apply structural correspondence learn-ing (SCL) to find a low dimensional rep-resentation shared by the two languages.We perform experiments on an English-Chinese sentiment classification task andcompare our results with a previous co-training approach.
To alleviate the prob-lem of data sparseness, we create ex-tra pseudo-examples for SCL by makingqueries to a search engine.
Experimentson real-world on-line review data demon-strate the two techniques can effectivelyimprove the performance compared to pre-vious work.1 IntroductionIn this paper we are interested in the problem oftransferring knowledge gained from data gatheredin one language to another language.
A simple andstraightforward solution for this problem mightbe to use automatic machine translations.
How-ever, while machine translation has been the sub-ject of a great deal of development in recent years,many of the recent gains in performance manifestas syntactically as opposed to semantically cor-rect sentences.
For example, ?PIANYI?
is a wordmainly used in positive comments in Chinese butits translation from the online Google translator isalways ?cheap?, a word typically used in a neg-ative context in English.
To reduce this kind oferror introduced by the translator, Wan in (Wan,2009) applied a co-training scheme.
In this settingclassifiers are trained in both languages and thetwo classifiers teach each other for the unlabeledexamples.
The co-training approach manages toboost the performance as it allows the text simi-larity in the target language to compete with the?fake?
similarity from the translated texts.
How-ever, the translated texts are still used as trainingdata and thus can potentially mislead the classifier.As we are not really interested in predicting some-thing on the language created by the translator,but rather on the real one, it may be better to fur-ther diminish the role of the translated texts in thelearning process.
Motivated by this observation,we suggest here to view this problem as a specialcase of domain adaptation, in the source domain,we mainly observe English features, while in theother domain mostly features from Chinese.
Theproblem we address is how to associate the fea-tures under a unified setting.There has been a lot of work in domain adaptionfor NLP (Dai et al, 2007)(Jiang and Zhai, 2007)and one suitable choice for our problem is the ap-proach based on structural correspondence learn-ing (SCL) as in (Blitzer et al, 2006) and (Blitzeret al, 2007b).
The key idea of SCL is to identify alow-dimensional representations that capture cor-respondence between features from both domains(xs and xt in our case) by modeling their correla-tions with some special pivot features.
The SCLapproach is a good fit for our problem as it per-forms knowledge transfer through identifying im-portant features.
In the cross-lingual setting, wecan restrict the translated texts by using them onlythrough the pivot features.
We believe this form ismore robust to errors in the language produced bythe translator.Adapting language resources and knowledge toa new language was first studied for general textcategorization and information retrieval as in (Bel258et al, 2003), where the authors translate a key-word lexicon to perform cross-lingual text cate-gorization.
In (Mihalcea et al, 2007), differentshortcomings of lexicon-based translation schemewas discussed for the more semantic-oriented tasksubjective analysis, instead the authors proposedto use a parallel-corpus, apply the classifier in thesource language and use the corresponding sen-tences in the target language to train a new clas-sifier.
With the rapid development of automaticmachine translations, translating the whole corpusbecomes a plausible option.
One can either chooseto translate a corpus in the target language and ap-ply the classifier in the source language to obtainlabeled data, or directly translated the existing dataset to the new language.
Various experiments ofthe first strategy are performed in (Banea et al,2008) for the subjective analysis task and an aver-age 65 F1 score was reported.
In (Wan, 2008), theauthors propose to combine both strategies withensemble learning and train a bi-lingual classifier.In this paper, we are also interested in explor-ing whether a search engine can be used to im-prove the performance of NLP systems through re-ducing the effect of data sparseness.
As the SCLalgorithm we use here is based on co-occurrencestatistics, we adopt a simple approach of creatingpseudo-examples from the query counts returnedby Google.2 Our ApproachTo begin, we give a formal definition of the prob-lem we are considering.
Assume we have two lan-guages ls and lt and denote features in these twolanguages as xs and xt respectively.
We also havetext-level translations and we use xt?
for featuresin the translations from ls to lt and xs?
for theother direction.
Let y be the output variable wewant to predict, we have labeled examples (y, xs)and some unlabeled examples (xt).
Our task is totrain a classifier for (y, xt).
In this paper, we con-sider the binary sentiment classification (positiveor negative) problem where ls and lt correspond toEnglish and Chinese (for general sentiment analy-sis, we refer the readers to the various previousstudies as in (Turney, 2002),(Pang et al, 2002),and(McDonald et al, 2007)).
With these definitionsin place, we now describe our approach in furtherdetail.2.1 Structural CorrespondenceLearning(SCL)Due to space limitations, we give a very briefoverview of the SCL framework here.
For adetailed illustration, please refer to (Ando andZhang, 2005).
When SCL is used in a domainadaptation problem, one first needs to find a setof pivot features xp.
These pivot features shouldbehave in a similar manner in both domains, andcan be used as ?references?
to estimate how muchother features may contribute when used in a clas-sifier to predict a target variable.
These featurescan either be identified with heuristics (Blitzeret al, 2006) or by automatic selection (Blitzeret al, 2007b).
Take sentiment classification asan example, ?very good?
and ?awful?
are goodpivot features, if a certain feature in the target do-main co-occurs often with ?very good?
but infre-quently with ?awful?, we could expect this fea-ture will play a similar role as ?very good?
inthe final classifier but a different role from ?aw-ful?.
We can make this observation purely basedon the co-occurrence between these features.
Nohand-labeling is required and this specific featuredoesn?t need to be present in our labeled trainingdata of the source domain.The SCL approach of (Ando and Zhang, 2005)formulates the above idea by constructing a setof linear predictors for each of the pivot fea-tures.
Each of these linear predictor is binary likewhether ?very good?
occurs in the text and wehave a set of training instances (1|0, {xi}).
Theweight matrix of these linear predictors will en-code the co-occurrence statistics between an or-dinary feature and the pivot features.
As the co-occurrence data are generally very sparse for a typ-ical NLP task, we usually compress the weightmatrix using the singular vector decompositionand only selects the top k eigenvectors vk.
Thismatrix w of the k vectors {vk} gives a mappingfrom the original feature space to a lower dimen-sional representation and is shown in (Ando andZhang, 2005) to be the optimal choice of dimen-sion k under common loss functions.
In the nextstep we can then train a classifier on the extendedfeature (x,w ?
x) in the source domain.
As wgroups the features from different domains withsimilar behavior relative to the pivot features to-gether, if such a classifier has good performanceon the source domain, it will likely do well on thetarget domain as well.2592.2 SCL for the Cross-lingual AdaptationViewing our task as a domain adaptation prob-lem.
The source domain correspond to Englishreviews and the target domain for Chinese ones.The full feature vector is (xs, xt).
The difficultywe are facing is, due to noise in the translations,the conditional probabilities p(y|xs) and the onein the translated texts p(y|xs?)
may be quite differ-ent.
Consider the following two straightforwardstrategies of using automatic machine translations:one can translate the original English labeled data(y, xs) into (y, xt?)
in Chinese and train a clas-sifier, or one can train a classifier on (y, xs) andtranslate xt in Chinese into xs?
in English so as touse the classifier.
But as the conditional distribu-tion can be quite different for the original languageand the pseudo language produced by the machinetranslators, these two strategies give poor perfor-mance as reported in (Wan, 2009).Our solution to this problem is simple: insteadof using all the features as (xs, xt?)
and (xs?
, xt),we only preserves the pivot features in the trans-lated texts xs?
and xt?
respectively and discard theother features produced by the translator.
So, nowwe will have (xs, xtp) and (xsp, xt) where x(s|t)pare pivot features in the source and the target lan-guages.
In other words, when we use the SCL onour problem, the translations are only used to de-cide if a certain pivot feature occurs or not in thetraining of the linear predictors.
All the other non-pivot features in the translators are blocked to re-duce the noise.In the original SCL as we mentioned earlier,the final classifier is trained on the extended fea-tures (x,w ?
x).
However, as mentioned abovewe will only use the pivot features.
To representthis constraint, we can modify the vector to be(wp ?
x,w ?
x) where wp is a constant matrix thatonly selects the pivot features.
This modificationwill not affect the deduction procedure and resultsin (Ando and Zhang, 2005).
Experiments showthat using only pivot features actually outperformsthe full feature setting.For the selection of the pivot features, we fol-low the automatic selection method proposed in(Blitzer et al, 2007a).
We first select some candi-dates that occur at least some constant number oftimes in reviews of the two languages.
Then, werank these features according to their conditionalentropy to the labels on the training set.
In table1, we give some of the pivot features with EnglishEnglish Pivot Features?poor quality?, ?not buy?, ?easy use?, ?very easy?
?excellent?, ?perfect?, ?still very?, ?garbage?,?poor?, ?not work?, ?not to?, ?very comfortable?Chinese Pivot Featureswanmei(perfect), xiaoguo hen(effect is very...)tisheng(improve),feichang hao(very good),cha(poor), shushi(comfortable), chuse(excellent)Table 1: Some pivot features.translations associated with the Chinese pivot fea-tures.
As we can see from the table, althoughwe only have text-level translations we still getsome features with similar meaning from differ-ent languages, just like performing an alignmentof words.2.3 Utilizing the Search EngineData sparseness is a common problem in NLPtasks.
On the other hand, search engines nowadaysusually index a huge amount of web pages.
Wenow show how they can also be used as a valuabledata source in a less obvious way.
Previous studieslike (Bollegala, 2007) have shown that search en-gine results can be comparable to language statis-tics from a large scale corpus for some NLP taskslike word sense disambiguation.
For our problem,we use the query counts returned by a search en-gine to compute the correlations between a normalfeature and the pivot features.Consider the word ?PIANYI?
which is mostlyused in positive comments, the query ?CHAN-PIN(product) PING(comment) CHA(bad) PI-ANYI?
has 2,900,000 results, while ?CHAN-PIN(product) PING(comment) HAO(good) PI-ANYI?
returns 57,400,000 pages.
The results im-ply the word ?PIANYI?
is closer to the pivot fea-ture ?good?
and it behaves less similar with thepivot feature ?bad?.To add the query counts into the SCL scheme,we create pseudo examples when training lin-ear predictors for pivot features.
To construct apseudo-positive example between a certain featurexi and a certain pivot feature xp, we simply querythe term xixp and get a count c1.
We also queryxp alone and get another count c2.Then we cancreate an example (1, {0, ..., 0, xi = c1c2 , 0, ..., 0}).The pseudo-negative examples are created simi-larly.
These pseudo examples are equivalent totexts with a single word and the count is used to260approximate the empirical expectation.
As an ini-tial experiment, we select 10,000 Chinese featuresthat occur more than once in the Chinese unla-beled data set but not frequent enough to be cap-tured by the original SCL.
And we also select thetop 20 most informative Chinese pivot features toperform the queries.3 Experiment3.1 Data SetFor comparsion, we use the same data set in (Wan,2009):Test Set(Labeled Chinese Reviews): The dataset contains a total of 886 labeled product reviewsin Chinese (451 positive reviews and 435 negativeones).
These reviews are extracted from a popularChinese IT product website IT168 1.
The reviewsare mainly about electronic devices like mp3 play-ers, mobile phones, digital cameras and comput-ers.Training Set(Labeled English Reviews): Thisis the data set used in the domain adaption exper-iment of (Blitzer et al, 2007b).
It contains fourmajor categories: books, DVDs, electronics andkitchen appliances.
The data set consists of 8000reviews with 4000 positive and 4000 negative, It isa public data set available on the web 2.Unlabeled Set (Unlabeled Chinese Reviews):1000 Chinese reviews downloaded from the samewebsite as the Chinese training set.
They are ofthe same domain as the test set.We translate each English review into Chineseand vice versus through the public Google Trans-lation service.
Also following the setting in (Wan,2009), we only use the Chinese unlabeled data andEnglish training sets for our SCL training proce-dures.
The test set is blind to the training stage.The features we used are bigrams and unigramsin the two languages as in (Wan, 2009).
In Chi-nese, we first apply the stanford Chinese word seg-menter 3 to segment the reviews.
Bigrams refersto a single Chinese word and a bigram refers totwo adjacent Chinese words.
The features are alsopre-processed and normalized as in (Blitzer et al,2007b).1http://www.it168.com2http://www.cis.upenn.edu/ mdredze/datasets/sentiment/3http://nlp.stanford.edu/software/segmenter.shtmlModels Precision Recall F-ScoreCoTrain 0.768 0.905 0.831SCL-B 0.772 0.914 0.837SCL-C 0.764 0.896 0.825SCL-O 0.760 0.909 0.828SCL-E 0.801 0.909 0.851Table 2: Results on the Positive ReviewsModels Precision Recall F-ScoreCoTrain 0.879 0.717 0.790SCL-B 0.931 0.752 0.833SCL-C 0.908 0.743 0.817SCL-O 0.928 0.739 0.823SCL-E 0.928 0.796 0.857Table 3: Results on the Negative Reviews3.2 ComparisonsWe compare our procedure with the co-trainingscheme reported in (Wan, 2009):CoTrain: The method with the best perfor-mance in (Wan, 2009).
Two standard SVMs aretrained using the co-training scheme for the Chi-nese views and the English views.
And the resultsof the two SVMs are combined to give the finaloutput.SCL-B: The basic SCL procedure as explained.SCL-O: The basic SCL except that we use allfeatures from the translated texts instead of onlythe pivot features.SCL-C: The training procedure is still the sameas SCL-B except in the test time we only usethe Chinese pivot features and neglect the Englishpivot features from translations.SCL-E: The same as SCL-B except that in thetraining of linear pivot predictors, we also use thepseudo examples constructed from queries of thesearch engine.Table 2 and 3 give results measured on the pos-itive labeled reviews and negative reviews sep-arately.
Table 4 gives the overall accuracy onthe whole 886 reviews.
Our basic SCL approachSCL-B outperforms the original Co-Training ap-proach by 2.2% in the overall accuracy.
We canCoTrain SCL-B SCL-O SCL-C SCL-E0.813 0.835 0.826 0.822 0.854Table 4: Overall Accuracy of Different Methods261also notice that using all the features including theones from translations actually deteriorate the per-formance from 0.835 to 0.826.The model incorporating the co-occurrencecount information from the search engine has thebest overall performance of 0.857.
It is interestingto note that the simple scheme we have adopted in-creased the recall performance on the negative re-views significantly.
After examining the reviews,we find the negative part contains some idioms andwords mainly used on the internet and the querycount seems to be able to capture their usage.Finally, as our final goal is to train a Chinesesentiment classifier, it will be best if our modelcan only rely on the Chinese features.
The SCL-C model improves the performance from the Co-Training method a little but not as much as theSCL ?
B and the SCL ?
O approaches.
Thisobservation suggests that the translations are stillhelpful for the cross-lingual adaptation problemas the translators perform some implicit semanticmapping.4 ConclusionIn this paper, we are interested in adapting ex-isting knowledge to a new language.
We showthat instead of fully relying on automatic trans-lation, which may be misleading for a highly se-mantic task like the sentiment analysis, using tech-niques like SCL to connect the two languagesthrough feature-level mapping seems a more suit-able choice.
We also perform an initial experimentusing the co-occurrence statistics from a searchengine to handle the data sparseness problem inthe adaptation process, and the result is encourag-ing.As future research we believe a promising av-enue of exploration is to construct a probabilisticversion of the SCL approach which could offer amore explicit model of the relations between thetwo domains and the relations between the searchengine results and the model parameters.
Also,in the current work, we select the pivot featuresby simple ranking with mutual information, whichonly considers the distribution information.
Incor-porating the confidence from the translator mayfurther improve the performance.ReferencesRie Kubota Ando and Tong Zhang.
2005.
A frame-work for learning predictive structures from multi-ple tasks and unlabeled data.
Journal of MachineLearning Research.Carmen Banea, Rada Mihalcea, Janyce Wiebe, andSamer Hassan.
2008.
Multilingual subjectivityanalysis using machine translation.
In Proceedingsof EMNLP.Nuria Bel, Cornelis H. A. Koster, and Marta Ville-gas.
2003.
Cross-lingual text categorization.
InResearch and AdvancedTechnology for Digital Li-braries.John Blitzer, Ryan McDonald, and Fernando Pereira.2006.
Domain adaptation with structural correspon-dence learning.
In Proceedings of EMNLP.John Blitzer, Koby Crammer, Alex Kulesza, FernandoPereira, and Jennifer Wortman.
2007a.
Learningbounds for domain adaptation.
In Proceedings ofNIPS.John Blitzer, Mark Dredze, and Fernando Pereira.2007b.
Biographies, bollywood, boom-boxes andblenders: Domain adaptation for sentiment classi-fication.
In Proceedings of ACL.Danushka Bollegala.
2007.
Measuring semantic sim-ilarity between words using web search engines.
InProceedings of WWW 07.Wenyuan Dai, Gui-Rong Xue, Qiang Yang, and YongYu.
2007.
Co-clustering based classification forout-of-domain documents.
In Proceedings of KDD.Jing Jiang and ChengXiang Zhai.
2007.
A two-stageapproach to domain adaptation for statistical classi-fiers.
In Proceedings of CIKM.Ryan T. McDonald, Kerry Hannan, Tyler Neylon, MikeWells, and Jeffrey C. Reynar.
2007.
Structuredmodels for fine-to-coarse sentiment analysis.
InProceedings of ACL.Rada Mihalcea, Carmen Banea, and Janyce Wiebe.2007.
Learning multilingual subjective language viacross-lingual projections.
In Proceedings of ACL.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
sentiment classification us-ing machine learning techniques.
In Proceedings ofEMNLP.Peter D. Turney.
2002.
Thumbs up or thumbs down?semantic orientation applied to unsupervised classi-fication of reviews.
In Proceedings of ACL.Xiaojun Wan.
2008.
Using bilingual knowledge andensemble techniques for unsupervised chinese sen-timent analysis.
In Proceedings of EMNLP.Xiaojun Wan.
2009.
Co-training for cross-lingual sen-timent classification.
In Proceedings of ACL.262
