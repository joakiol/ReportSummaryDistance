Rhetorical structure in dialog*Amanda StentComputer  Science Depar tmentUn ivers i ty  of  RochesterRochester ; :N 'Y  14~27 ......s tent~cs ,  rochester ,  eduAbst rac tIn this paper we report on several issues arisingout of a first attempt o annotate task-oriented spo-ken dialog for rhetorical structure using RhetoricalStructure Theory.
We discuss an annotation schemewe are developing to resolve the difficulties we haveencountered.1 In t roduct ionIn this paper we report on several issues arising outof a first attempt o annotate complex task-orientedspoken dialog for rhetorical structure using Rhetor-ical Structure Theory (RST):o Relations needed (section 3.1)o Identification of minimal units for annotation(section 3.2.2)?
Dialog coverage (section 3.2.3)?
Overlap due to the subject-matter/presenta-tional relation distinction (section 3.3)We discuss how we are dealing with these issues in anannotation scheme for argumentation acts in dialogthat we are developing.2 P rev ious  workWe are engaged in tim construction and inlplemen-ration of a theory of content-planning for complex,mixed-initiative task-oriented ialogs based on cor-pus analysis, for use in dialog systems uch as theTRIPS system (Allen et al, 2000) 1 .
Our basicpremise is that a conversational gent should be ableto produce whatever a human can produce in simi-lar discourse situations, and that if we can explainwhy a human produced a particular contribution," This work w~ supported by ONR research grant N00014-95-l-1088, U.S. Air Force/Rome Labs research contract no.F30602-95-1-0025, NSF research grant no.
IRI-9623665 andColumbia University/NSF research grant no.
OPG: 1307.
Wewould like to thank the armuymous reviewers and l)r. JasonEisner for their helpful comments on earlier drafts of thispaper.IWe are using the Monroe corpus (Stent, 2000), with ref-erence t.o the TRAINS corpus (Heeman and Allen, 1995) andthe HCRC Mapta~sk corpus (Anderson et al, 1991).247we can program a conversational gent to producesomething similar.
Therefore, in examining our di-alogs the question we must answer is "Why did thisspeaker produce this?
".RST is a descriptive theory of hierarchical struc-ture in discourse that identifies functional relation-ships between discourse parts based on the inten-tions behind their production (Mann and Thomp-son, 1987).
It has been used in content plan-ning systems for text (effectively text monolog) (e.g.
(Cawsey, 1993), (How, 1993), (Moore and Paris,1993)).
It has not yet been used much in contentplanning for spoken dialog.Because the dialogs we are examining are task-oriented, they are hierarchically structured and soprovide a natural place to use RST.
In fact, in or-der to uncover the full structure behind discoursecontributions, it is necessary for us to use a modelof rhetorical structure.
Certain dialog contribu-tions are explained by the speaker's rhetorical goals,rather than by task goals.
In example 1, utterance 3is justification for utterance 1 but does not directlycontribute to completing the task.Example  1A 1 They can't fix that power line at fiveninety and EastB 2 \Veil itA 3 Because you got to fix the tree firstThe details of how to apply RST to spoken dialogare unclear.
If we mark rhetorical structure onlywithin individual turns (as has generally been thecase  in annotations of text dialog, e.g.
(Moser etal., 1996),(Cawsey, 1993)), we miss the structure incontributions like example 1 or example 2.
Thereis also tile question of how to handle dialog-specificbehaviors: grounding utterances and back-channels(utterances that maintain the comnmnication), andal)andoned or interrupted utterances.Example  2 (simpli f ied)A 1 Bus C at irondequoit broke down.B 2 Before it.
even got started?A 3 ~'eah, but we convinced some people toloan US sonic vans.Initial annotationDialog-specific Subtypes of Elaboration OtherComment Particularize, Generalize ComparisonCorrection Instantiate Counter-expectationCue i Exemplify Agent, RoleArgumentation acts?
Question~response.
::Proposal-acceptGreeting-ack.New manualSubtypes of Elaboration Schemas~Set~member .
.
.
.
.
.
.
.
.
Joke, ListProcess-step Make-planObject-attribute Describe-situationFigure 1: Examples of other relationsIn our first attempt to annotate, we removedabandoned utterances, back-channels, and simpleacknowledgments such as "Okay".
We used utter-ances as minimal units; utterances were segmentedusing prosodic and syntactic cues and speakerchanges (see 3.2.2).
We did occasionally split an ut-terance into two units if it consisted of two phrases orclauses eparated by a cue word such as "because".Two annotators, working separately, marked onecomplete dialog using Michael O'Donnell's RST an-notation tool (1997).
They used the set of relationsin (Mann and Thompson, 1987), and some addi-tional relations pecific to dialog or to our domain.Examples of the additional relations are given in fig-ure 1.
When we compared the results, the tree struc-tures obtained were similar, but the relation labelswere very different, and in neither case was the entiredialog covered.
Also, the annotators found structurenot covered by the relations given.
As a result, westopped the annotation project and started evelop-ing an annotation scheme that would retain rhetor-ical relations while dealing with the difficulties wehad encountered.
The rest of this paper describesthis new annotation scheme.
An example of the typeof analysis we are looking for appears in figure 3.3 I ssues  and  proposa lsThe issues we encountered fall into three areas,which we will examine in turn: issues related to in-dividual relations, dialog-specific issues, and issuesrelated to the well-known presentational/subject-matter distinction in RST.3.1 Relat ionsThe key in any annotation project is to have a setof tags that are mutually exclusive, descriptive, andgive a useful distinction between different behaviors.The set of relations we used failed this test withrespect o our corpus.As in earlier work (Moore and Paris.
1992).
ourannotators found some of the relations ambiguous.In particular, the differences between the motivateand justify relations and between the elaboration andmotivation relations were unclear (partly because248we did not distinguish between presentational ndsubject-matter relations).Some of the relations we used overlapped.
Theelaboration relation is too broad; in some sectionsof our dialogs almost every utterance is an elabora-tion of the first one, but the utterances cover a widevariety of different ypes of elaborations.
Anticipat-ing this, we had given the annotators several morespecific relations (see figure 1), but we also allowedthem to use the elaboration tag in case a type of elab-oration arose for which there was no subtype.
As aresult of the overlap, use of the elaboration tag wasinconsistent.
The joint relation is also too broad.Other relations were never used, although one an-notator went on to look at several more dialogs.
Inshort, the set of relation-tags we used did not effec-tively partition the set of relations we saw.In our annotation scheme, we are taking severalsteps to define relations more clearly, reduce over-lap, and eliminate too-broad relations.
Instead ofgiving annotators an semi-ordered set of relationswith their definitions, we are giving them decisiontrees, with questions they can use to clarify the dis-tinctions between relations at each point (figure 2).The annotators did not find the relation definitionsin (Mann and Thompson, 1987) particularly help-ful, but we are including simplified definitions, andannotators are instructed to test against he defini-tions before labeling any relation.
We are includingseveral examples with each definition, so that anno-tators can obtain an intuitive understanding of howthe relations appear.
Finally, we are providing anyuseful discourse cues that signal the existence of arelation.We are eliminating relations that overlap withothers.
Where a relation appears to cover a varietyof different phenomena, s in the case of elaboration,we are using more specific relations instead.
We areeliminating the joint relation, as it gives no help-ful information from a content-planning perspectiveand annotators are tempted to over-use it.One of the criticisms of RST is that there is aninfinite set of relations (Grosz and Sidner, 1986).The goal is to arrive at a mutually-exclusive, clearly-defined set of relations with" discr iminatory power ineach domain, so we expect that  for each new do-main, it may be necessary to start  with an initialset of high-level relations elected from different cat-egories, examine a small  set of texts or dialogs in thatdomain, and then revise the set of relations by mak-?
ing relevant high-leve!
.relations more.specific.._We..used this process to develop our annotat ion scheme.In the manual  we include instructions for moving tonew domains.
Our examples come from a variety ofdomains and types of discourse, to add generality.3.2 D ia log -spec i f i c  i ssues3.2.1 Dia log-spec i f i c  re la t ions ,  schemas  andconversat iona l  gamesTask-oriented ialog is a complex behavior, involv-ing two part ic ipants,  each with their own beliefsand intentions, in a col laborative ffort to inter-act to solve some problem.
There is a whole setof behaviors related to maintaining the col labora-tion and synchronizing beliefs that does not arisein monolog \[(Clark, 1996), (Traum and Hinkelman,1992)\].
These include answering questions, agree-ing to proposals, and simply acknowledging that  theothe r part ic ipant has spoken.In example 3, ut terance 3 provides motivation forutterance 1.
However, A would not have producedutterance 3 without B's question.
If we simply marka motivation relation between utterances 1 and 3 wewill be losing dialog coverage, the spans involvedin the relation will not be adjacent, and we will beignoring the important  relationship between utter-ances 2 and 3.
A better  analysis would be to marka question-answer relation between utterances 2 and3, and a motivation relation between utterance 1andthe unit consisting of utterances 2 and 3.Example  3A 1 Then they're going to have tobasically waitB 2 Why?A 3 Because the roads have to be fixed beforeelectrical lines can be fixedThe question-answer relation is not in Mann andThompson's  original list of relations 2.
It is an "ad-jacency pair  ''a, and is a type of conversational game(ClarM 1996).
Adjacency pairs, like other relations,are functional relat ionships between parts of dis-course, but.
they are specific to mult i -party discourse.In our annotat ion scheme, we include relations fordifferent kinds of adjacency pairs (figure 1).
We have2They do.
however, include requests for information in thesolutionhood relationaAn adjacency pair is a pair of utterances, the first of whichimposes a cognitive preference for the second, e.g.
question-answer, proposabaeeept.2491.
In this set of spans, is the speaker attempting toaffect the hearer's:o be l ie f -  go to question 2?
a t t i tude  - go to question 3o abi l i ty  to perform an action - enablemen~...... .2.. Is:t:he_speaker..tryi.ug..to.inccrease.the.hearer'.s be l ie fin some fact, or enable the hearer to better under -s tand  some fact??
Bel ief -  evidence?
Understanding- background3 .
.
.
.Figure 2: Par t ia l  decision tree for presentational re-lations, expressed as a list of questionstentat ively categorized adjacency pairs with subject-matter  relations, although they may eventual ly be-come a third category of relation.Some of these relations are bi-nuclear.
For in-stance, a l though usually the answer is the only par trequired for discourse coherence, at times both ques-tion and answer may be needed, as in example 4.Example  4A 1 And the last one was at the whereon the loop?B 2 Four ninety.It would seem that these relations can only applyat the lowest levels of an RST analysis, with a dif-ferent speaker for each span.
However, example 5,in which turns 2-7 are the answer to the question inutterance 1, shows that this is not the case.Example  5 ( s l ight ly  s impl i f ied)A 1 What's "close"?B 2 "Close".
Um I don't know.
I I'm prettysure thatA 3 So Mount Hope and Highland would be.B 4 Yeah.A 5 Well what about like 252 and 383'?B 6 It says "next".A 7 Oka~v.
So I guess it has to be adjacent.It might seem that .the simplest approach wouldbe to annotate  adjacency pairs between turns, andmark other rhetorical relations only within turns.However, we have found many instances of rhetori-cal relations, or even units (section 3.2.2), spanningturns.
The two examples below i l lustrate a cross-speaker elaboration and a cross-speaker sequence re-lation.Example  6A i So that.takes care of the ill guyand the handicapped guy.B 2 " OkayB 3 And that takes two hours.A 1A 2B 3A 4B 5B 6SummaryMake-fla~ \ (6)...... Object-attribute, Enablement, /  \$olutionhood, Quesffon-answer (nun~er),Motivation , / ,~, / \ (3) Assert-ack.
(~) (2) , / \(4} (5}We have to send buses to the Lake.There are people there to evacuate.How many are we sending?Two.Okay.So 1 ambulance to Pittsford and 2buses to the Lake.Figure 3: Sample analysis of part  of a constructeddialog.
Nuclei are marked with *; non-RST relationsare in italics.Example  7A 1 So they can ta- to- take out the power.B 2 And then we have to wait ...Wi th  a model of adjacency pairs,_we can-now han-dle grounding acts such as acknowledgments.
If anutterance is clearly a back-channel or abandoned,annotators  are instructed to so mark it and leave itout of further annotat ion.RST in its original formulat ion does not cover en-veloping or parallel structures or conventional forms.However, even in task-or iented ialogs speakers oc-casionally tell jokes.
Furthermore,  there are fixed,structural  patterns in dialog, such as form-fill ingbehaviors.
These are frequently domain-specif ic,and resemble schemas \[(McKeown, 1985), (Cawsey,1993)\].
While it may be possible to give an RSTanalysis for some of these, it is more accurate toidentify, what is actual ly going on.
Our annotat ionscheme includes four of these, make-plan, describe-situation, list and joke.
It also includes an adjacencypair for greetings, a conventional form.An annotated ialog extract  i l lustrat ing most ofthese issues is shownin  figure 3.3.2.2 Ident i fy ing  and  order ing  un i tsIn spoken dialog, both part ic ipants often speak atonce, or one speaker may complete what anotherspeaker says, as in examples 8 and 9.Example  8 (+ 's  mark  over lapp ing  speech):\ 1 And + he's done + with that at one thirtyB 2 + Okay +Example  9A 1 So it'll take themB 2 Two nmre hours250Our  original use of utterances as minimal  unitsspl its a cross-turn completion from the utterance itcompletes (example 9) ,  and says nothing about  howto order  units when one overlaps with another.
Wehave altered our segmentat ion rules to take care ofthese difficulties.
Our definition is that  a minimal~unit .must .be one~.~f tthe following,~.with:eadier pos-sibi l it ies taking precedence over later ones:1.
A syntact ic phrase separated from the immedi-ate ly  prior phrase by a cue word such as "be-cause" or "since"2.
A syntact ical ly  complete clause3.
A stretch of continuous speech ended by apause, a prosodic boundary  or a change ofspeakerOne unit  will be considered to succeed another ifit s tar ts  after the other.This  means that  the standard segmentat ion of adialog into utterances may have to be modified forthe purposes of an RST analysis, although a segmen-tat ion into utterances and one into minimal unitswill be very similar.
Annotators  will start  with adialog segmented into turns and utterances, and areencouraged to re-segment as needed.3 .2.3 D ia log  coverageWhen one gets higher in the tree resulting from anRST annotat ion,  the spans typical ly begin to fol-low the task structure or the exper imental  structure.In the Monroe corpus, usually one partner tells theother about  the task, then the two col laborate tosolve it, and finally one partner  summarizes the so-lution (following the experimental  structure).
In theTRAINS corpus usually one subtask in the plan isdiscussed at a t ime (following the task structure).Given the length and complexity of a typical dia-log, it may not be possible to achieve complete cov-erage, even with our expanded relation set and theuse of schemas.
If we can identify useful sub-dialogsor can associate parts  of a dialog with parts of thetask, f inding annotat ions for each part may suffice.For our domain,  we have establ ished heuristics aboutwhen an annotator  can stop trying to achieve cover-age.
An annotator  can stop when:o The top level of the annotat ion tree has onere lat ion label covering the whole dialog.o The structure between the spans at the top levelis identical to the task structure.
* Tim structure between the spans at the toplevel is identical to a domain-dependent orexpe.r iment-dependent schema.o There is consensus between annotators  that nomore relations can be marked.3.3 The sub jec t -mat ter /p resentat iona lrelation d ist inct ionThe relations in RST fall into two classes.
Subject-matter relations uch as summary are intended tobe recognized by the hearer.
Presentational rela-tions such as motivation are supposed to "increasesome inclination" in the hearex~ LtCh .as.
the.
inclina-tion to act (Mann and Thompson, 1987).
As Mooreand associates have explained in (1992) and (1993),while the intentions of the speaker are adequatelyrepresented in the case of presentational relationsby the relations themselves, in the case of subject-matter relations the intentions of the speaker mayvary.
Furthermore, these two types of relations ac-tually come from different levels of relationship be-tween discourse elements: the informational level(subject-matter relations), and the intentional level(presentational relations).
RST conflates these twolevels.Mann and Thompson said that, in the case wherea presentational relation and a subject-matter re-lation were both applicable, the subject-matter re-lation should take precedence.
However, we wouldlike to have information about both levels when pos-sible.
In our annotation scheme the presentationalrelations are split from the subject-matter relationsand annotators are instructed to consider for eachset of spans whether there is a subject-matter rela-tion, and also whether there is a presentational rela-tion.
If there are two relations, both are marked.
Ifone covers a slightly different span than the other,at the next level of annotation the span that seemsmore appropriate is used.In the following example, utterance 3 is justifica-tion (presentational) for utterance 1, but it is alsoin a non-volitional cause (subject-matter) relation-ship with utterance 1.
The annotator would be in-structed to label both relations.Example  10 (s l ight ly s impl i f ied)A 1 I can't find the Rochester airportB 2 + I- it's +A 3 + I think I have + a disability with mapsWe would also like more information, at times,about the subject matter in the spans of a relation.The relation between a "When" question and an-swer is question-answer, as is that between a "Why"question and answer; but the first question-answerforms part of an elaboration and the second formspart of a justification or motivation.
In our ammta-tion scheme, we supply a list of content types, suchas time.
location and number.
The annotator addsthe content ype in I)arentheses after the relation tagwhen required.
This means that the annotator mayhave to mark three items for a given set of spans: 'thepresentational relation (if any), the subject-matterrelation, and the content ype (if required).
We find25tthis approach preferable to expanding the set of re-lations to include, for instance, temporal-question-answer and spatial-question, answer.
Cawsey used asimilar method in (1993).4 Cur rent  and  fu ture  work?
-"-We-:havean :amaotation ~manuat"that weare"refming "using TRAINS-93 dialogs 4.
Shortly, we will beginannotating the Monroe corpus with the new manualand different annotators.
We will also annotate afew dialogs from a different corpus (e.g.
Maptask)to ensure generality.
We plan to use the results ofour annotation in the construction (ongoing) of newgeneration components for the TRIPS system at theUniversity of Rochester (Allen et al, 2000).5 Re la ted  WorkIn recent years there has been much research onannotation schemes for dialog.
Traum and Hinkel-man outline four levels of "conversational cts" in(1992).
"Argumentation acts", including rhetoricalrelations, form the top level, but this level is not de-scribed in detail.
DAMSL (Core and Allen, 1997) in-cludes speech acts and some grounding acts, but notrhetorical relations.
The HCRC Maptask project an-notation scheme includes adjacency pairs, but notrhetorical relations (Carletta et al, 1996).The COCONUT project annotation manual al-lows the annotator to mark individual utter-ances as elaboration, and segments as summary,act:condition, act:consequence or otherinfo (DiEu-genio et al, 1998).
This annotation scheme doesnot treat rhetorical structure separately from othertypes of dialog behavior.
We have observed enoughstructure in the corpora we have looked at to jus-tify treating rhetorical structure as a separate, im-portant phenomenon.
For instance, in a DAMSL-tagged set of 8 dialogs in our corpus, 40% of theutterances were statements, and many of these ap-peared in sequences of statements.
The relationshipsbetween many of these statements are unclear with-out a model of rhetorical structure.In (1999), Nakatani and Traum describe a hierar-chical annotation of dialog for I-units, based on the.. domination and satisfaction-precedence relations of(Grosz and Sidner, 1986).
Other researchers haveshown that Grosz and Sidner's model of discoursestructure (GST) and RST are similar in many re-spects \[(Moser and Moore, 1996), (Marcu, 1999)\].However, RST provides more specific relations thanGST, and this is useful for content planning.
Aswell as helping to specify generation goals, contentand ordering constraints, the rhetorical informationis needed in case the system has to explain what it.has said.4A rough draft is available from the author.RDA is an annotation scheme for identifyingrhetorical structure in explanatory texts in theSHERLOCK domain (Moser et al, 1996).
We followRDA in requiring annotators to consider both in-tentional and informational relations.
However, be-cause of the dialog issues previously described, RDAis not sufficient for dialog.Marcu uses discourse-cuesto"automa~ically un-cover rhetorical relations in text (1997).
Much ofthis work is applicable to the problem of uncoveringrhetorical relations in dialog; however, many cuesin dialog are prosodic and it is not yet possible toobtain accurate information about prosodic ues au-tomatically.6 ConclusionsWe have examined several issues arising from a firstattempt o annotate spoken dialog for rhetoricalstructure.
We have proposed ways of dealing witheach of these issues in an annotation scheme we aredeveloping.
Much future work is certainly neededin this area; we hope that the results of our annota-tion may form a quantitative baseline for comparisonwith future work.ReferencesJ.
Allen, D. Byron, M. Dzikovska, G. Ferguson,L.
Galescu, and A. Stent.
2000.
An architecturefor a generic dialogue shell, upcoming in the Nat-ural Language Engineering Journal special issueon Best Practices in Spoken Language DialogueSystems Engineering.A.
Anderson, M. Bader, E. Bard, E. Boyle, G. Do-herty, S. Garrod, S. Isard, J. Kowtko, J. MeAl-lister, J. Miller, C. Sotillo, H. Thompson, andR.
Weinert.
1991.
The HCRC Maptask corpus.Language and Speech, 34:351-366.J.
Carletta, A. Isard, S. Isard, J. Kowtko,and G. Doherty-Sneddon.
1996.
HCRC dia-log structure coding manual.
Technical ReportHCRC/TR-82, HCRC, Edinburgh University.A.
Cawsey.
1993.
Planning interactive explanations.International Journal of Man-Machine Studies,38:169-199.H.
Clark.
1996.
Using Language.
Cambridge Uni-versity Press.M.
Core and J. Allen.
1997.
Coding dialogs with theDAMSL annotation scheme.
In AAAI Fall Sym-posium on Communicative Action in Humans andMachines, pages 28-35, November.B.
DiEugenio, P. Jordan.
and L. Pylkkiinen.
1998.The COCONUT project: Dialogue annotationmanual.
Technical Report 98-I, ISP, Universityof Pittsburgh.B.
Gross- and C. Sidner.
1986.
Attention, inten-tions, and the structure of discourse.
Computa-tional Linguistics, 12(3).252P.
Heeman and J. Allen.
1995.
The TRAINS-93dialogs.
Technical Report Trains TN 94-2, Com-puter Science Dept., U. Rochester, March.E.
Hovy.
1993.
Automated iscourse generation us-ing discourse structure relations.
Artificial Intel-ligence, 63(1-2):341-385.W.. Mann_and S. Thompsom 19877.
Rhetorical struc-ture theow: a theory of  text organisation.
InL.
Polanyi, editor, The Structure of Discourse.Ablex, Norwood, NJ.D.
Marcu.
1997.
The rhetorical parsing, sum-marization, and generation of natural anguagetexts.
Technical Report CSRG-371, Departmentof Computer Science, University of Toronto.D.
Marcu.
1999.
A formal and computationalsynthesis of Grosz and Sidner's and Mann andThompson's theories.
In The Workshop on Levelsof Representation i  Discourse, Edinburgh, Scot-land.K.
McKeown.
1985.
Text Generation: Using Dis-course Strategies and Focus Constraints to Gener-ate Natural Language Text.
Cambridge UniversityPress, Cambridge.J.
Moore and C. Paris.
1992.
Exploiting user feed-back to compensate for the unreliability of usermodels.
UMUAI, 2(4):331-365.J.
D. Moore and C. L. Paris.
1993.
Planning textfor advisory dialogues: Capturing intentional ndrhetorical information.
Computational Linguis-tics, 19(4):651-695.J.
Moore and M. Pollack.
1992.
A problem for RST:The need for multi-level discourse analysis.
Com-putational Linguistics, 18(4):537-544.M.
G. Moser and J. D. Moore.
1996.
Toward asynthesis of two accounts of discourse structure.Computational Linguistics, 22(3):409-420.M.
Moser, J. Moore, and E. Glendening.
1996.Instructions for coding explanations: Identifyingsegments, relations and minimal units.
TechnicalReport 96-17, University of Pittsburgh.
Depart-ment of Computer Science.C.
Nakatani and D. Traum.
1999.
Coding discoursestructure in dialogue (version 1.0).
Technical Re-port UMIACS-TR-99-03, University, of Maryland.Michael O'Donnell.
1997.
RST-Tool: An RSTanalysis tool.
In Proceedings of the 6th Eu-ropean Workshop on Natural Language Gener-ation, Gerhard-Mercator University, Duisburg,Germany.A.
Stent.
2000.
The Monroe corpus.
Technical Re-port TR728/TN99-2, University of Rochester.D.
Traum and E. Hinkehnan.
1992.
Conversationacts in task-oriented spoken dialogue.
Computa-tional Intelli.qenee, 8(3):575--599.
