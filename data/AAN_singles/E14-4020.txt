Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 100?105,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsUnsupervised Parsing for Generating Surface-BasedRelation Extraction PatternsJens IlligUniversity of KasselWilhelmsh?oher Allee 73D-34121 Kassel, Germanyillig@cs.uni-kassel.deBenjamin Roth and Dietrich KlakowSaarland UniversityD-66123 Saarbr?ucken, Germany{benjamin.roth, dietrich.klakow}@lsv.uni-saarland.deAbstractFinding the right features and patterns foridentifying relations in natural language isone of the most pressing research ques-tions for relation extraction.
In this pa-per, we compare patterns based on super-vised and unsupervised syntactic parsingand present a simple method for extract-ing surface patterns from a parsed trainingset.
Results show that the use of surface-based patterns not only increases extrac-tion speed, but also improves the qualityof the extracted relations.
We find that, inthis setting, unsupervised parsing, besidesrequiring less resources, compares favor-ably in terms of extraction quality.1 IntroductionRelation extraction is the task of automatically de-tecting occurrences of expressed relations betweenentities in a text and structuring the detected in-formation in a tabularized form.
In natural lan-guage, there are infinitely many ways to creativelyexpress a set of semantic relations in accordance tothe syntax of the language.
Languages vary acrossdomains and change over time.
It is therefore im-possible to statically capture all ways of express-ing a relation.Most relation extraction systems (Bunescu andMooney, 2005; Snow et al., 2005; Zhang et al.,2006; Mintz et al., 2009; Alfonseca et al., 2012;Min et al., 2012) generalize semantic relationsby taking into account statistics about the syntac-tic construction of sentences.
Usually supervisedparsers are applied for parsing sentences.Statistics are then utilized to machine-learn howtextual mentions of relations can be identified.Many researchers avoid the need for expensivecorpora with manually labeled relations by apply-ing a scheme called distant supervision (Mintz etal., 2009; Roth et al., 2013) which hypothesizesthat all text fragments containing argument co-occurrences of known semantic relation facts in-deed express these relations.
Still, systems rely-ing on supervised parsers require training from an-notated treebanks, which are expensive to create,and highly domain- and language dependent whenavailable.An alternative is unsupervised parsing, whichautomatically induces grammars by structurallyanalyzing unlabeled corpora.
Applying unsuper-vised parsing thus avoids the limitation to lan-guages and domains for which annotated data isavailable.
However, induced grammars do notmatch traditional linguistic grammars.
In most ofthe research on parsing, unsupervised parsers arestill evaluated based on their level of correspon-dence to treebanks.
This is known to be prob-lematic because there are several different ways oflinguistically analyzing text, and treebank anno-tations also contain questionable analyses (Klein,2005).
Moreover, it is not guaranteed that the syn-tactic analysis which is most conforming to a gen-eral linguistic theory is also best suited in an ex-trinsic evaluation, such as for relation extraction.In this work, we apply a supervised and an un-supervised parser to the relation extraction task byextracting statistically counted patterns from theresulting parses.
By utilizing the performance ofthe overall relation extraction system as an indirectmeasure of a parser?s practical qualities, we get atask-driven evaluation comparing supervised andunsupervised parsers.
To the best of our knowl-edge, this is the first work to compare general-purpose unsupervised and supervised parsing onthe application of relation extraction.
Moreover,we introduce a simple method to obtain shallowpatterns from syntactic analyses and show that, be-sides eliminating the need to parse text during sys-tem application, such patterns also increase extrac-tion quality.
We discover that, for this method, un-100supervised parsing achieves better extraction qual-ity than the more expensive supervised parsing.1.1 Related WorkUnsupervised and weakly supervised trainingmethods have been applied to relation extraction(Mintz et al., 2009; Banko et al., 2007; Yatesand Etzioni, 2009) and similar applications suchas semantic parsing (Poon and Domingos, 2009)and paraphrase acquisition (Lin and Pantel, 2001).However, in such systems, parsing is commonlyapplied as a separately trained subtask1for whichsupervision is used.H?anig and Schierle (2009) have applied unsu-pervised parsing to a relation extraction task buttheir task-specific data prohibits supervised pars-ing for comparison.Unsupervised parsing is traditionally only eval-uated intrinsically by comparison to gold-standardparses.
In contrast, Reichart and Rappoport (2009)count POS token sequences inside sub-phrases formeasuring parsing consistency.
But this count isnot clearly related to application qualities.2 MethodologyA complete relation extraction system consists ofmultiple components.
Our system follows the ar-chitecture described by Roth et al.
(2012).
Inshort, the system retrieves queries in the formof entity names for which all relations capturedby the system are to be returned.
The en-tity names are expanded by alias-names extractedfrom Wikipedia link anchor texts.
An informationretrieval component retrieves documents contain-ing either the name or one of the aliases.
Furtherfiltering retains only sentences where a named en-tity tagger labeled an occurrence of the queriedentity as being of a suitable type and furthermorefound a possible entity for the relation?s second ar-gument.
For each candidate sentence, a classifiercomponent then identifies whether one of the cap-tured relation types is expressed and, if so, whichone it is.
Postprocessing then outputs the classi-fied relation according to task-specific format re-quirements.
Here, we focus on the relation typeclassifier.1An exception is the joint syntactic and semantic (super-vised) parsing model inference by Henderson et al.
(2013)2.1 Pattern ExtractionFor our relation extraction system, we use a simplepattern matching framework.
Whenever at leastone candidate sentence containing two entities Aand B matches one of the patterns extracted for acertain relation type R, the classifier states that Rholds between A and B.We experimented with two types of patterns.First, we simply parsed the training set and ex-tracted shortest dependency path patterns.
Thesepatterns search for matches on the parse tree.Following Lin and Pantel (2001), the shortestpath connecting two arguments in a dependencygraph has been widely used as a representationof relation instance mentions.
The general ideais that shortest paths skip over irrelevant op-tional parts of a sentence such as in $1, who... founded $2 where the shortest path pattern$1?founded?$2 matches although an irrel-evant relative clause appears between the argu-ments $1 and $2.
Similar representations havebeen used by Mintz et al.
(2009), Alfonseca et al.
(2012) and Snow et al.
(2005).In a second set of experiments, we used theshortest dependency paths in parsed training sen-tences to generate surface-based patterns.
Thesepatterns search for matches directly on plain textand therefore do no longer rely on parsing at appli-cation time.
The patterns are obtained by turningthe shortest paths between relational arguments inthe parsed training data into token sequences withgaps.
The token sequences consist of all wordsin the sentence that appear on the shortest depen-dency path.
Argument positions in the surface pat-terns are specified by special tokens $1 and $2.At all places, where there are one or more tokenswhich are not on the shortest dependency path butwhich are surrounded either by tokens on the de-pendency path or by arguments, an asterisk repre-sents up to four unspecified tokens.
For the short-est path $1?,?who?$2 connecting Friedmanand economist in the DMV parse depicted in Fig-ure 1, this method generates the pattern $1,*$2 who.
As can be seen, such patterns can cap-ture a conjunction of token presence conditions tothe left, between, and to the right of the arguments.In cases where argument entities are not parsed asa single complete phrase, we generate patterns foreach possible combination of outgoing edges fromthe two arguments.
We dismiss patterns generatedfor less than four distinct argument entity pairs of101Milton Friedman , a conservative economist who died in 2006 at age 94 , received the Nobel Prize for economics in 1976 .nnnsubjpunctdetamodapposnsubjrcmodpreppobjpreppobjnumpunctMALT rootdetnndobjpreppobjpreppobjpunctDMV rootFigure 1: Comparison of a DMV (above text) and a MALT parse (below text) of the same sentence.the same relation type.
For each pattern, we cal-culate the precision on the training set and retainonly patterns above a certain precision threshold.2.2 Supervised and Unsupervised ParsingTypical applications which require syntactic anal-yses make use of a parser that has been trained un-der supervision of a labeled corpus conforming toa linguistically engineered grammar.
In contrast,unsupervised parsing induces a grammar from fre-quency structures in plain text.Various algorithms for unsupervised parsinghave been developed in the past decades.
Head-den (2012) gives a rather recent and extensiveoverview of unsupervised parsing models.
For ourwork, we use the Dependency Model with Valence(DMV) by Klein and Manning (2004).
Most ofthe more recent unsupervised dependency pars-ing research is based on this model.
DMV is agenerative head-outward parsing model which istrained by expectation maximization on part-of-speech (POS) sequences of the input sentences.Starting from a single root token, head tokens gen-erate dependants by a probability conditioned onthe direction (left/right) from the head and thehead?s token type.
Each head node generates to-kens until a stop event is generated with a prob-ability dependent on the same criteria plus a flagwhether some dependant token has already beengenerated in the same direction.For comparison of unsupervised and supervisedparsing, we apply the (Nivre, 2003) determinis-tic incremental parsing algorithm Nivre arc-eager,the default algorithm of the MALT framework2(Nivre et al., 2007).
In this model, for each wordtoken, an SVM classifier decides for a parser statetransition, which, in conjunction with other deci-sions, determines where phrases begin and end.2http://www.maltparser.org as of Nov. 20133 ExperimentsWe used the plain text documents of the EnglishNewswire and Web Text Documents provided forTAC KBP challenge 2011 (Ji et al., 2011).
Weautomatically annotated relation type mentions inthese documents by distant supervision using theonline database Freebase3, i.e.
for all relationtypes of TAC KBP 2011, we took relation triplesfrom Freebase and, applying preprocessing as de-scribed in Section 2, we retrieved sentences men-tioning both arguments of some Freebase relationwith matching predicted entity types.
We hypothe-size that all sentences express the respective Free-base relation.
This way we retrieved a distantlysupervised training set of 480 622 English sen-tences containing 92468 distinct relation instancesinstantiating 41 TAC KBP relation types.3.1 Training and EvaluationFrom our retrieved set of sentences, we took thosewith a maximum length of 10 tokens and trans-formed them to POS sequences.
We trained DMVonly on this dataset of short POS sequences, whichwe expect to form mentions of a modeled relation.Therefore, we suspect that DMV training assignsan increased amount of probability mass to depen-dency paths along structures which are truly re-lated to these relations.
We used the DMV imple-mentation from Cohen and Smith (2009)4.For the supervised Nivre arc-eager parser weused MALT (Nivre et al., 2007) with a pre-trainedPenn Treebank (Marcus et al., 1993) model5.
Asa baseline, we tested left branching parses i.e.3http://www.freebase.com as of Nov. 20134publicly available at http://www.ark.cs.cmu.edu/DAGEEM/ as of Nov. 2013 (parser version 1.0).5http://www.maltparser.org/mco/english_parser/engmalt.linear-1.7.mcoas of Nov. 201310200.020.040.060.080.10.120.140.160.180.20  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1micro-average KBPF 1threshold on pattern-precisionlbranchdmv surfacedmv dep-graphmalt surfacemalt dep-graph00.10.20.30.40.50  0.05  0.1  0.15  0.2  0.25  0.3  0.35  0.4precisionrecalllbranchdmv surfacedmv dep-graphmalt surfacemalt dep-graphFigure 2: micro-averaged F1and precision&recall results for varied training precision thresholdspattern set (+additional DMV pattern) precision recall F1MALT generated patterns only .1769 .2010 .1882+p:title $1 * $2 of +0.73% +8.40% +4.14%+p:title $1 , * $2 of +0.90% +4.22% +2.39%+o:state of hqs $1 * in * , $2 +1.35% +1.59% +1.43%+p:title $1 , * $2 who +0.90% +1.35% +1.22%+o:parents $1 , * by $2 +0.62% +1.35% +1.06%+o:city of hqs $1 , * in $2 , +1.01% +1.04% +1.00%+p:origin $2 ?s $1 won the +0.84% +1.04% +0.95%+p:employee of $1 * $2 ?s chief +0.28% +1.04% +0.79%+o:website $1 : $2 +0.28% +1.04% +0.79%Table 1: DMV patterns improving MALT resultsthe most, when added to the MALT patternsetdependency trees solely consisting of head-to-dependent edges from the right to the left6.All the extracted sentences were parsed and pat-terns were extracted from the parses.
The patternswere then applied to the corpus and their precisionwas determined according to Freebase.
With dif-ferent cut-off values on training precision, the fullrelation extraction pipeline described in Section 2was evaluated with respect to the Slot Filling testqueries of TAC KBP 2011.3.2 ResultsFigure 2 (left) depicts F1-measured testset resultsfor pattern sets with varying training precisionthresholds.
Figure 2 (right) shows a precision re-call plot of the same data points.As can be seen in Figure 2 (left), flatteninggraph patterns to surface-based patterns increasedthe overall F1score.
The curve for MALT gen-erated surface patterns in Figure 2 (right) showsno increase in precision towards low recall levelswhere only the highest-training-precision patternsare retained.
This indicates a lack of precision6Since for such parses the shortest path is the completeobserved word sequence between the two relation arguments,surface and parse-tree patterns become equal.in MALT-based surface patterns.
In contrast, thecorresponding DMV-based graph increases mono-tonically towards lower recall levels, which is re-flected by the highest F1score (Figure 2, left).Table 1 shows the increases in evaluation scoreof those DMV-generated patterns which help mostto more precisely identify relations when added tothe set of all MALT-generated patterns (sorted byF1score).
Figure 1 compares the syntactic analy-ses of MALT and DMV for an example sentencewhere DMV generates one of the listed patterns.The numbers of Table 1 indicate that such patternsare missing without alternatives in the pattern setgained from supervised parsing.4 ConclusionWe have presented a simple method for generat-ing surface-based patterns from parse trees which,besides avoiding the need for parsing test data,also increases extraction quality.
By comparingsupervised and unsupervised parsing, we further-more found that unsupervised parsing not onlyeliminates the dependency on expensive domain-specific training data, but also produce surface-based extraction patterns of increased quality.
Ourresults emphasize the need for task-driven evalu-ation of unsupervised parsing methods and showthat there exist indicative structures for relation ex-traction beyond widely agreed-on linguistic syntaxanalyses.5 AcknowledgementsBenjamin Roth is a recipient of the Google EuropeFellowship in Natural Language Processing, andthis research is supported in part by this GoogleFellowship.103ReferencesEnrique Alfonseca, Katja Filippova, Jean-Yves Delort,and Guillermo Garrido.
2012.
Pattern learning forrelation extraction with a hierarchical topic model.In Proceedings of the 50th Annual Meeting of the As-sociation for Computational Linguistics: Short Pa-pers - Volume 2, ACL ?12, pages 54?59, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Michele Banko, Michael J. Cafarella, Stephen Soder-land, Matt Broadhead, and Oren Etzioni.
2007.Open information extraction from the web.
In Pro-ceedings of the 20th International Joint Conferenceon Artifical Intelligence, IJCAI?07, pages 2670?2676, San Francisco, CA, USA.
Morgan KaufmannPublishers Inc.Razvan C. Bunescu and Raymond J. Mooney.
2005.A shortest path dependency kernel for relation ex-traction.
In Proceedings of the conference on Hu-man Language Technology and Empirical Methodsin Natural Language Processing, HLT ?05, pages724?731, Stroudsburg, PA, USA.
Association forComputational Linguistics.Shay B. Cohen and Noah A. Smith.
2009.
Shared lo-gistic normal distributions for soft parameter tying inunsupervised grammar induction.
In Proceedings ofHuman Language Technologies: The 2009 AnnualConference of the North American Chapter of theAssociation for Computational Linguistics, NAACL?09, pages 74?82, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Christian H?anig and Martin Schierle.
2009.
Rela-tion extraction based on unsupervised syntactic pars-ing.
In Gerhard Heyer, editor, Text Mining Ser-vices, Leipziger Beitr?age zur Informatik, pages 65?70, Leipzig, Germany.
Leipzig University.William Headden.
2012.
Unsupervised Bayesian Lexi-calized Dependency Grammar Induction.
Ph.D. the-sis, Brown University.James Henderson, Paola Merlo, Ivan Titov, andGabriele Musillo.
2013.
Multi-lingual joint parsingof syntactic and semantic dependencies with a latentvariable model.
Computational Linguistics, 39(4).Heng Ji, Ralph Grishman, and Hoa Dang.
2011.Overview of the TAC2011 knowledge base popula-tion track.
In TAC 2011 Proceedings Papers.Dan Klein and Christopher D. Manning.
2004.Corpus-based induction of syntactic structure: mod-els of dependency and constituency.
In ACL, ACL?04, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Dan Klein.
2005.
The Unsupervised Learning of Natu-ral Language Structure.
Ph.D. thesis, Stanford Uni-versity.Dekang Lin and Patrick Pantel.
2001.
DIRT: Discov-ery of Inference Rules from Text.
In Proceedingsof the Seventh ACM SIGKDD International Con-ference on Knowledge Discovery and Data Mining(KDD?01), pages 323?328, New York, NY, USA.ACM Press.Mitchell P. Marcus, Mary Ann Marcinkiewicz, andBeatrice Santorini.
1993.
Building a large anno-tated corpus of english: the penn treebank.
Comput.Linguist., 19(2):313?330, June.Bonan Min, Xiang Li, Ralph Grishman, and Sun Ang.2012.
New york university 2012 system for kbpslot filling.
In Proceedings of the Fifth Text AnalysisConference (TAC 2012).
National Institute of Stan-dards and Technology (NIST), November.M.
Mintz, S. Bills, R. Snow, and D. Jurafsky.
2009.Distant supervision for relation extraction withoutlabeled data.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL and the4th International Joint Conference on Natural Lan-guage Processing of the AFNLP: Volume 2-Volume2, pages 1003?1011.
Association for ComputationalLinguistics.Joakim Nivre, Johan Hall, Jens Nilsson, AtanasChanev, G?ulsen Eryigit, Sandra K?ubler, SvetoslavMarinov, and Erwin Marsi.
2007.
Maltparser:A language-independent system for data-driven de-pendency parsing.
Natural Language Engineering,13(2):95?135.Joakim Nivre.
2003.
An efficient algorithm for pro-jective dependency parsing.
In Proceedings of the8th International Workshop on Parsing Technologies(IWPT), pages 149?160.Hoifung Poon and Pedro Domingos.
2009.
Unsuper-vised semantic parsing.
In Proceedings of the 2009Conference on Empirical Methods in Natural Lan-guage Processing: Volume 1 - Volume 1, EMNLP?09, pages 1?10, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Roi Reichart and Ari Rappoport.
2009.
Automatic se-lection of high quality parses created by a fully un-supervised parser.
In Proceedings of the ThirteenthConference on Computational Natural LanguageLearning, CoNLL ?09, pages 156?164, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.Benjamin Roth, Grzegorz Chrupala, Michael Wiegand,Singh Mittul, and Klakow Dietrich.
2012.
General-izing from freebase and patterns using cluster-baseddistant supervision for tac kbp slotfilling 2012.
InProceedings of the Fifth Text Analysis Conference(TAC 2012), Gaithersburg, Maryland, USA, Novem-ber.
National Institute of Standards and Technology(NIST).Benjamin Roth, Tassilo Barth, Michael Wiegand, andDietrich Klakow.
2013.
A survey of noise reduction104methods for distant supervision.
In Proceedings ofthe 2013 workshop on Automated knowledge baseconstruction, pages 73?78.
ACM.Rion Snow, Daniel Jurafsky, and Andrew Y. Ng.
2005.Learning syntactic patterns for automatic hypernymdiscovery.
In Lawrence K. Saul, Yair Weiss, andL?eon Bottou, editors, Advances in Neural Informa-tion Processing Systems 17, pages 1297?1304.
MITPress, Cambridge, MA.Alexander Yates and Oren Etzioni.
2009.
Unsuper-vised methods for determining object and relationsynonyms on the web.
J. Artif.
Int.
Res., 34(1):255?296, March.Min Zhang, Jie Zhang, Jian Su, and Guodong Zhou.2006.
A composite kernel to extract relations be-tween entities with both flat and structured features.In Proceedings of the 21st International Conferenceon Computational Linguistics and the 44th annualmeeting of the Association for Computational Lin-guistics, ACL-44, pages 825?832, Stroudsburg, PA,USA.
Association for Computational Linguistics.105
