Feature Structures and NonmonotonicityGosse Bouma*Rijksuniversiteit GroningenUnification-based grammar formalisms use feature structures to represent linguistic knowledge.The only operation defined on feature structures, unification, is information-combining andmonotonic.
Several authors have proposed nonmonotonic extensions of this formalism, as fora linguistically adequate description of certain natural anguage phenomena some kind of defaultreasoning seems essential.
We argue that the effect of these proposals can be captured by meansof one general, nonmonotonic, operation on feature structures, called default unification.
Weprovide a formal semantics of the operation and demonstrate how some of the phenomena used tomotivate nonmonotonic extensions of unification-based formalisms can be handled.1.
IntroductionWhile monotonicity is often desirable from a formal and computational perspective, itis at odds with a considerable body of linguistic work.
Default principles, default rules,and default feature-values can be found in many linguistic formalisms and are usedprominently in work on phonology, morphology, and syntax.
In spite of their greatexpressive power and flexibility, unification-based grammar formalisms (see Shieber1986a, for an introduction) are in general not very successful in modeling such de-vices.
Unification is an information-combining, monotonic, operation on feature struc-tures, whereas the implementation f default devices typically requires ome form ofnonmonotonicity.
In this paper, we present anonmonotonic operation on feature struc-tures, which enables us to implement the effects of a number of default devices usedin linguistics.
As the operation is defined in terms of feature structures only, an impor-tant characteristic of unification-based formalisms, namely that linguistic knowledgeis encoded in the form of feature structures, is preserved.In the next section, we present an overview of linguistic phenomena that are bestdescribed using defaults.
We also argue that previous proposals for handling thesephenomena in a unification-based setting are unsatisfactory.
Section 3 provides theformal background for the central part of the paper, Section 4, in which a definitionof default unification is presented.
Section 5 briefly presents ome applications of thisoperation and the final section draws some conclusions concerning the role of non-monotonicity in unification-based formalisms.2.
Previous WorkThere are a number of phenomena that suggest hat unification-based grammar for-malisms might profit from the addition of some form of nonmonotonicity, and severalauthors have in fact suggested such extensions.
In this section, we argue that theseproposals uffer from a number of shortcomings.
Most importantly, previous propos-als have either been highly restricted in scope or have been presented in very informal* Computational Linguistics Department, Postbus 716, 9700 AS Groningen, The Netherlands(~) 1992 Association for Computational LinguisticsComputational Linguistics Volume 18, Number 2terms, thus leaving a number of questions concerning the exact behavior of the pro-posed extensions unanswered.An overview of the issues that call for the addition of non-monotonic reasoningand of some of the proposals in that direction is presented below.?
Exceptional Rules.
Consider a language in which the vast majority ofverbs cannot precede its subject, whereas a small number of exceptionalverbs can.
The rule accounting for inverted structures would probablyrequire that verbs occurring in it be marked as +INV (i.e.
(INV) : +).
As aconsequence, all regular verbs must be marked explicitly as --INV (toprevent hem from occurring in the inversion rule).
Note that, in aunification-based grammar, there is no need to mark the exceptionalverbs as +INV, which leads to the rather counterintuitive situation thatregular verbs need to be marked extra, whereas the exceptional ones canremain underspecified.
A more natural solution would be to assign allverbs the specification qNV by default (either by means of templateinheritance or by means of lexical feature specification defaults as usedin Generalized Phrase Structure Grammar \[GPSG; Gazdar et al 1985\])and to overwrite or block this specification i  the exceptional cases.
Thepossibility of incorporating an overwrite operation in a unification-basedformalism is mentioned in Shieber (1986a, p.
60).?
Feature Percolation Principles.
Both GPSG and Head-driven PhraseStructure Grammar (HPSG; Pollard and Sag 1987) adopt the so-calledHead Feature Convention (HFC).
In GPSG, the HFC is a default principle:head features will normally have identical values on mother and head,but specific rules may assign incompatible values to specific headfeatures.
In unification-based formalisms, it is impossible to express thisprinciple directly.
Adding the constraint (Xo head) = (Xi head) to everyrule of the form Xo --~ X1... Xn (with Xi (1 K i < n) the head of the ruleand assuming all head features to be collected under head) will not do, asit rules out the possibility of exceptions altogether.
Shieber (1986b)therefore proposes to add this constraint conservatively, which means that,if the rule already contains conflicting information for some head featuref, the constraint is replaced by a set of constraints (Xo head f') =(Xi head f'), for all head features f' # f.?
Structuring the Lexicon.
Flickinger, Pollard, and Wasow (1985),Flickinger (1987), De Smedt (1990), Daelemans (1988), and others, haveargued that the encoding and maintenance of the detailed lexicaldescriptions typical for lexicalist grammar formalisms benefits greatlyfrom the use of (nonmonotonic) inheritance.
In Flickinger, Pollard, andWasow (1985), for instance, lexical information is organized in the formof frames, which are comparable to the templates (i.e., feature structuresthat may be used as part of the definition of other feature structures) ofPATR-II (Shieber 1986a).
A frame or specific lexical entry may inheritfrom more general frames.
Frames can be used to encode informationeconomically and, perhaps more importantly, as a means to expresslinguistic generalizations.
For instance, all properties typical of verbs aredefined in the VERB-frame, and properties typical of auxiliaries aredefined in the AUX-frame.
The AUX-frame may inherit from theVERB-frame, thus capturing the fact that an auxiliary is a kind of verb.184Gosse Bourna Feature Structures and NonmonotonicityIn this approach, a mechanism that allows inheritance of information bydefault (i.e., a mechanism in which local information may exclude theinheritance of more general information) is of great importance.
Withoutsuch a mechanism, a frame may contain only properties that holdwithout exception for all items that inherit from this frame.
In practice,however, one often wants to define the properties that are typical for agiven class in the form of a frame, without ruling out the possibility thatexceptions might exist.
In unification-based formalisms, templates canplay the role of frames, but as unification is used to implementinheritance, nonmonotonic inheritance is impossible.?
Inflectional Morphology.
In PATR-II the lexicon is a list of inflectedword forms associated with feature structures.
The only tools availablefor capturing lexical generalizations are templates ( ee above) and lexicalrules.
Lexical rules may transform the feature structure of a lexical entry.An example is the rule for agentless passive (Shieber 1986a, p. 62), whichtransforms the feature structure for transitive past participles into a featurestructure for participles occurring in agentless passive constructions.Lexical rules can only change the feature structure of a lexical entry, notits word form, and thus, the scope of these rules is rather estricted.While the examples in Flickinger, Pollard, and Wasow (1985) and Evansand Gazdar (1989a,b) suggest that the latter restriction can be easilyremoved, it is not so obvious how a unification-based grammarformalism can cope with the combination of rules and exceptions typicalfor (inflectional) morphology.
For instance, it is possible to formulate arule that describes past tense formation in English, but it is not so easyto exclude the application of this rule to irregular verbs and to describe(nonredundantly) past tense formation of these irregular verbs.
Evansand Gazdar (1989a,b) present he DATR-formalism, which, among otherthings, contains a nonmonotonic inference system that enables an elegantaccount of the blocking-phenomenon just described.
The examples usedthroughout their presentation are all drawn from inflectionalmorphology and illustrate once more the importance of defaultreasoning in this area of linguistics.?
Gapping.
In Kaplan (1987) it is observed that gapping constructions andother forms of nonconstituent conjunction can be analyzed in LexicalFunctional Grammar (Bresnan and Kaplan, 1982) as the conjunction oftwo functional-structures (f- tructures), one of which may be incomplete.The missing information i  the incomplete f-structure can be filled in if itis merged with the complete f-structure, using an operation calledpriority union.
Priority union of two f-structures A and B is defined as anoperation that extends A with information from B that is not included(or filled in) in A.
As not all information i  B is present in the priorityunion of A and B, this operation introduces nonmonotonicity.The proposals for incorporating the kind of default reasoning that is required foreach of the phenomena above are both rather diverse and idiosyncratic and, further-more, suffer from a number of shortcomings.The Head Feature Convention and Feature Specification Defaults of GPSG, for instance,appear to be motivated with a very particular set of linguistic phenomena in mindand also are rather intimately connected to peculiarities of the GPSG-formalism.
What185Computational Linguistics Volume 18, Number 2is particularly striking is the fact that two different conceptions of default appear toplay a role: a head feature is exempt from the HFC only if this would otherwise leadto an inconsistency, whereas a feature is exempt from having the value specified insome feature specification default (among others) if this feature covaries with anotherfeature.Overwrite and add conservatively are also highly restricted operations.
From theexamples given in Shieber (1986a) it seems as if overwriting can only be used toadd or substitute (nonmonotonically) one atomic feature value in a given (possiblycomplex) feature structure (which acts as default).
Add conservatively, on the otherhand, is only used to add one reentrancy (as far as possible) to a given feature structure(which acts as nondefault).
An additional restriction is that add conservatively is wellbehaved only for the kind of feature structures used in GPSG (that is, feature structuresin which limited use is made of covariation or reentrancy).
Consider for instance theexample in (1).
1 Adding the constraint (Xo head) = (X1 head) to (1) conservativelycould result in either la or lb.Example 1GoX1headheada.XoX1headheadb.X0X1headheadAs add conservatively and overwriting are, in a sense, mirror images of eachother, it is tempting to generalize the definitions of these operations and to think ofthem as operations on arbitrary feature structures, whose effect is equivalent to thatof priority union.
Thus, given two feature structures FSD (the default) and FSND (thenondefault), adding FSp to FSND conservatively would be equivalent to overwritingFSD with FSND, and to the priority union of FSND and FSD (i.e.
FSND/FSD in thenotation of Kaplan \[1987\]).
However, in light of the example above, it should be clearthat such a generalization is highly problematic.
Other examples worth consideringare 2 and 3.1 Whether this kind of situation can occur in GPSG probably depends on whether one is willing toconclude from examples such as:S\[COMPo~\] ---*{\[SUBCATa\]}, H\[COMP NIL\] (Gazdar et al 1985, p. 248)that covariation ofarbitrary categories is in principle not excluded in this formalism.186Gosse Bouma Feature Structures and NonmonotonicityExample 2Example 3g:r~a FSND= \[ g:b \]Again, if we try to combine the two feature structures along the lines of any one ofthe operations mentioned above, there are at least two possible results (note that inExample 3, we could either preserve the information that features f and g are reentrant,or preserve the information that f : a), and there is no telling which one is correct.Two conclusions can be drawn at this point.
First of all, on the basis of the ex-amples just given, it can be concluded that a nonmonotonic operation on featurestructures that relies (only) on the fact that the result should be consistent must bevery restricted indeed, as more generic versions will always run into the problem thatthere can be several mutually exclusive solutions to solving a given unification conflict.Second, claims that the operations add conservatively, overwriting, and priority union areequivalent are unwarranted, asno definitions of these operations are available that aresufficiently explicit to determine what their result would be in moderately complexexamples uch as 1-3.The approach exemplified by Flickinger (1987) and others is to use a general-purpose knowledge representation formalism to represent linguistic information andmodel default inheritance.
Feature structures are defined as classes of some sort, whichmay inherit from other, more generic, classes.
The inheritance strategy used says thatinformation in the generic class is to be included in the specific class as well, aslong as the specific class does not contain local information that is in conflict withthe information to be inherited.
Such an inheritance strategy will run into problems,however, if reentrancies are generally allowed.
For instance, think of the examplespresented above as involving a generic class FSD from which a specific class FSNDinherits.
The inheritance procedure in, for instance, Flickinger (1987, p. 59ff) does notsay anything about which one of the possible results will be chosen.The work of Evans and Gazdar (1989a,b), finally, is not easily incorporated in aunification-based formalism, as they use semantic nets instead of feature structures torepresent linguistic information.
That is, although the syntax of DATR is suggestivelysimilar to that of, for instance, PATR-II, DATR descriptions do in fact denote graphsthat differ rather substantially from the graphs used to represent feature structures ( eeEvans and Gazdar 1989b).
The nonmonotonic reasoning facilities of DATR thereforeare not directly applicable in a unification-based formalism either.We conclude that a formally explicit definition of a nonmonotonic operation onfeature structures i still missing.
In particular, the interaction of reentrancy and non-monotonicity is a subtle issue, which has not been given the attention it deserves.
Thatthere is a need for nonmonotonic devices is obvious from the fact that several authorshave found it necessary to introduce partial solutions for dealing with nonmonotonic-ity in a unification-based setting.
The intuitions underlying these proposals appear tobe compatible, if not identical, and thus it seems attractive to consider an operationthat subsumes the effects of the proposals o far.
Default Unification, as defined below,is an attempt to provide such an operation.187Computational Linguistics Volume 18, Number 23.
Feature Structures and UnificationFeature structures are often depicted as matrices of attribute-value pairs where valuesare either atoms or feature structures themselves and, furthermore, values may beshared by different attributes in the feature structure.
Feature structures can be definedusing a description language, such as the one found in PATR-II (Shieber 1986a) or inKasper and Rounds (1986; 1990).
For instance, 4a is a description of 4b.Example 4a.
( (f) = a(g f)  = a(g f)  = Igg)f ' aFollowing the approach of Kasper and Rounds (1986; 1990), and others, we representfeature structures formally as finite (acyclic) automata (the definition below is takenfrom Dawar and Vijay-Shanker 1990):Definit ionA finite acyclic automaton A is a 7-tuple(Q, ~, P, 6, q0, F, "~/where:1.
Q is a nonempty finite set of states,2.
G is a countable set (the alphabet),3.
1 ~ is a countable set (the output alphabet),4.
~ : Q x G --* Q is a finite partial function (the transition function),5. q0EQ,6.
FC_Q,7.
)~ : F --* P is a total function (the output function),8. the directed graph (Q, E) is acyclic, where pEq iff for somel E Y~,6(p,I) = q,9.
for every q E Q, there exists a directed path from q0 to q in (Q, E), and10.
for every q E F, 6(q, I) is not defined for any l.We will frequently write QA, GA, etc.
for the set of states of automaton A, the alphabetof A, etc.The relationship between the matrix notation and the automaton concept shouldbe obvious.
The following automaton M is, for instance, equivalent to the matrix in 4b.188Gosse Bourna Feature Structures and NonmonotonicityExample 5QM = {q0,ql,q2,q3} ~SM(q2,g) = q3~M = {f,g} ~M(q2,f) = q3FM = {a} FM = {ql,q3}6M(qo,f) = q l  /~M(ql) = a~M(qo~g) "~" 92 AM(93 ) = aNote that ~M(qo,gf) = ~M(qo,gg) = 93,  2 which represents the fact that the two paths(gf) and (gg) are reentrant.
Unification is defined in terms of subsumption, a relationthat imposes a partial ordering on automata:DefinitionAn automaton A subsumes an automaton B (A _ B) iff there is a homomorphism hfrom A to B such that:1. h(6A(q,l) = ~s(h(q),l),2.
&B(h(q)) = &A(q) for all q E FA, and3.
h(qoA) = qoB-Intuitively, A u B if B extends the information in A.
A = B if A _ B and B U A.Unification of two automata A and B (A U B) is the least upper bound of these automataunder subsumption.
If no upper bound exists, unification fails.The semantics of descriptions (sets of formulae of the description language) isgiven in terms of satisfaction:DefinitionAn automaton A = (Q, G, F, 6, q0, F, ;~) satisfies a description D (A ~ D) or a formula(A ~ q~) in the following cases:A~DA~aA ~ (p) -- DA ~ (pl) = (p2)iff for all q~ E D :A ~ q~,iff Q = F = {q0} and &(q0) = a,iff 6(qo, p) is defined and qo/P ~ D,iff 6(qo, pl) = ~(q0, p2).qo/P is the automaton obtained from A by making ~(q0, P) the initial state andremoving all inaccessible states.
There is always a unique minimal element in thesubsumption hierarchy that satisfies a description D. This element is the denotationof D. 32 rS(q, pl) is defined for pl ff ~* as 6(6(q, p), 1).3 Much of the formal work on feature structures is concerned with the semantics of feature structuredescriptions involving disjunction and negation.
Such descriptions do not denote a unique featurestructure, but denote sets of feature structures.
Such extensions are not taken into consideration here.189Computational Linguistics Volume 18, Number 24.
Default UnificationDefault reasoning with feature structures requires the ability to modify feature struc-tures nonmonotonically.
Unification does not have this ability, as it can only replace afeature structure by more specific instances of that structure.
Below, we define defaultunification as an operation that merges parts of one feature structure (the default ar-gument) with another feature structure (the nondefault argument).
We write AU!B forthe default unification of the default feature structure A and the nondefault featurestructure B.
The operation has the following characteristics:1.
It has a declarative semantics and is procedurally neutral.
That is, ifA -- A' and B = B', then (AU!B) = (A'U!B').2.
It is monotonic only with respect o the nondefault argument.
That is,B U (AU!B) is always true, but in general A U (AU!B) will not hold.3.
It never fails.
If A is fully incompatible with B, (AU!B) = B.4.
It gives a unique result.5.
Reentrancies in the nondefault argument may be replaced by a weaker setof reentrancies if necessary (this is the add conservatively operation ofShieber (1986b)).Intuitions about default unification appear to be more clear in those cases wherefeature structures do not contain any reentrancies.
Therefore, we will first define de-fault unification for this case, moving to the general case in Section 4.2.
Section 4.3.deals with the incorporation of add conservatively.4.1 Default Unification without ReentranciesSubsumption suggests a straightforward definition of an operation that has properties1-4 above.DefinitionDefault Unification (first version) AU!B = A ~ U B, where A ~ is the maximal (i.e.
mostspecific) element in the subsumption ordering such that A' r- A and A ~ U B is defined.From this definition of U!, it follows immediately that properties 1-3 hold.
Thefact that default unification has a unique result follows from the fact that A' is unique(up to isomorphism).
4 Note furthermore that from tile requirement that A ~ must be themaximal it follows that no information contained in A is left out in AU!B unnecessarily.4 Unicity of A p is proved as follows: Assume that there is an A" such that (1) A" ~ X ,  (2) A t E A andA" U A, (3) A t U B and A" U B are defined, and (4) both A t and A" are maximal.
We show that theseassumpt ions are inconsistent.
From (2) it follows that A t U A" is defined and (X  U A ' )  D A.
From (3) itfollows that (X  U A ' )  U B is defined (since, if there are no reentrancies, it holds in general that if X U Y,Y U Z, and X u Z are defined, X u Y U Z is defined).
But then, if (A t U A' )  = A t or (A t U A ' )  = A ' ,either condition (1) or (4) is not met, or, if A t U A" ~ A t ~ A ' ,  condition (4) is not met.
D190Gosse Bouma Feature Structures and NonmonotonicityAn example of default unification is presented below (where nil is used to representthe empty feature structure):Example 6A =f :aii!
g: g: aB =f:a \]g.  :b\] \]a !f ;a  \[ nii g: g : naA 'UB=f :af: f:ag: g: g :bThe definition of default unification above relies crucially on the fact that thereis a unique maximal element A' unifiable with B.
In Section 2, we argued that suchan approach is only feasible for a limited domain.
In particular, once reentranciesare introduced, A' is no longer guaranteed to be unique, and the definition above istherefore not easily generalized.
Fortunately, it is also possible to define AU!B withoutrequiring unifiability of some element A t with B explicitly.
This definition, which willbe extended below, defines AU!B in terms of the difference of the two arguments Aand B.DefinitionDifference (first version) The difference of two automata A and B is the maximalelement A - B that meets the following conditions:1.
A -BU_A,2.
if 8a-B(q0,p) is defined, then there is no prefix p' of p such that6B(qO,P') E FB,3.
if ~a-B(q0,p) E FA-B then ~8(q0,P) is undefined.DefinitionDefault Unification (second version)Atd!B = (A - B) U B.It should be obvious that characteristics 1-3 continue to hold.
Uniqueness followsin this case from the fact that the difference operation will give a unique result.
(A - Bcan be constructed from A by checking for each state in A whether it must be removed191Computational Linguistics Volume 18, Number 2or not and ensuring that the resulting automaton is connected.)
For instance, assumingA and B to be defined as in Example 6, we find that A - B is:Example 7Note that in A - B all parts that are identical in A and 13 are removed, whereas this wasnot the case for A', as defined in Definition 3.1.
The outcome of default unification,however, is identical in both cases.
The reason for this restriction on A - B will becomeapparent below.While default unification monotonically extends the nondefault argument (i.e.
B EAU!B) and nonmonotonical ly extends the default argument, the operation itself ismonotonic in its default argument and nonmonotonic n its nondefault argument.
Thetheorem below proves monotonicity for the default argument; that is, a more specificdefault argument will lead to a more specific outcome of default unification:Theorem 1For all feature structures A, B, and C, not containing reentrancies, if A F- B then(ALl!C) _ (BU!C).ProofIt suffices to show that (A - C) G (B - C), or in other words:1. if ,X(6A-C(qo~p) ) = a then ,X(6B-c(qo~P)) = a, and2.
if 6A-C(qo,P) is defined then 6B-c(q0,p) is defined.If these two conditions are met, there is a homomorphism from A - C to B - C asrequired by the definition of subsumption.
(Remember that there are no reentrancies.
)Case (1): If .X(6A-C(qO, p)) = a, then (i))~(6B(qo, p)) = a (since A - C _G_ A U B) andfrom the definition of A - C it follows that (ii) there is no prefix p' of p such that6c(qo, p') c Fc nor is ~c(q0,p) defined.
From (i) and (ii) it follows that ~B-c(q0,p) isdefined and that ~(6~-c(q0, p)) = a.Case (2): If ~A-C(q0, p) is defined and 6A-C(qO, p) (~ FA-C (otherwise this case re-duces to case (1)), it follows that (i) 6B(q0, p) is defined, and (ii) there is no prefix p~ ofp such that ~c(q0, p') E Fc.
From (i) and (ii) it follows that ~B-C(q0, p) is defined.
?Note, however, that addition of nondefault information does not necessarily leadto a more specific result.
That is, the dual of Theorem 1. does not hold:Example 8if B E_ C then (ALl!B) G (ALl!C)The reason is that addition of nondefault information may lead to a larger amountof default information being removed, and thus, the resulting feature-structures AU!Band AU!C can be incompatible.
An example that falsifies 8 is presented below.192Gosse Bouma Feature Structures and NonmonotonicityExample 9A= ~:a\ ]B= L~:b\] Au!B=: b AU!C =bbFinally, for feature structures without reentrancies, the following distribution lawholds:Theorem 2For all feature structures A, B, and C, not containing any reentrancies and such thatA U B is defined, (A U B)U!C -- (AU!C) td (BU!C)ProofSince (AUB)U!C = ((AUB)-C)WC and (AU!C)U(BU!C)= ( (A -C)UC)W((B-C)UC)=(A - C) U (B - C) U C, it suffices to prove that (A U B) - C = (A - C) U (B - C).
LetD=(AOB) -CandE=(A-C)u(B-C) .
I tmustbeshownthat (1 )DEEand(2)EGD.Case (1): If A(6o(qo,p)) = a, then (i) A(~AuB(qo,p)) = a and thus A(6A(qo,p)) = aor A(~B(q0,p)) = a (since there are no reentrancies) and (ii) there is no prefix p' ofp such that 6c(qo,p') c Fc, nor is 8c(qo,p) defined.
From (i) and (ii) it follows thatA(6A-c(qo,p)) = a or A(SB-C(qo,P)) = a, and thus that A(6E(qo, p)) = a.
Similarly, if8D(qo, p) is defined (but not an end state), it follows that 6,~(qo, p) or 8B(qO, p) is definedand that there is no prefix p' of p such that 6c(qo, p) EFc.
Therefore, either 8A-C(qO, p)or 6B-C(qo,p) is defined, and thus 8E(qO,P) is defined.
It follows that D _u E.Case (2): If A(SE(qo,p)) = a, then )~(SA-c(qo,p)) = a or A(SB-c(qo,p)) = a (sincethere are no reentrancies).
Therefore, A(SAuB(qo,P)) = a and also, there is no prefix p'of p such that 6c(qo,p') E Fc, nor is ~c(qo,P) defined.
It follows that A(6D(qo,p)) = a.Similarly if ~E(qO, p) is defined but not an end state, 6D(qO, p) is defined.
It follows thatEUD.
?As long as Theorem 2. holds, it is possible to define default unification by de-composing the default argument into simpler feature structures and adding these(nonmonotonically) to the nondefault argument.
This approach appears to underliesome of the previous proposals, but is inadequate once reentrancies enter the picture.4.2 Default Unification with ReentranciesTaking reentrancies into account requires an extension of the difference operation.If we allow either default or nondefault information to refer to an extension of anondefault or default reentrancy, respectively, there is in general no unique maximalelement subsuming A and unifiable with B.
A slight modification of Examples 2 and 3will illustrate this.Example 10193Computational Linguistics Volume 18, Number 2Example 11A= \[ f : \[T\]~ : a\] \] B : \ [~  :  \[ g : \[f : b\] \]In Example 10, there is default information that refers to an extension of a non-default reentrancy.
A - B could be constructed from .4 by removing either the fact that(if) : a or (gf) : b.
In 11, nondefault information refers to an extension of a defaultreentrancy.
In this case, we could either remove the reentrancy (and the fact that(gf) : a) or remove the fact that (if) : a and (gf) : a and preserve the reentrancy.
Neithersolution subsumes the other.
To avoid such problems, it is best to avoid interactionbetween reentrancies and other information altogether and to treat reentrant nodesin a similar fashion as atomic nodes.
That is, we remove default reentrancies if theyrefer to defined parts of the nondefault automaton, and default information in generalis removed if it refers to extensions of nondefault reentrancies.
Thus, the differenceoperation can be extended as follows:DefinitionDifference (final version) The difference of A and B is the maximal element A - B inthe subsumption ordering that meets the following conditions:1.
A -BU_A,2.
if 6A-B(qO,P) is defined, then there is no prefix pt of p such that6B(qo,p') E FB or 6B(qo,P') = 6B(qo,P")(p'  p"),3. if 6A-~(qO,P) C FA-B then 6B(qo,p) is undefined,4.
(4) if 6A-B(qO,P) --- 6A-B(qO,P')(p ~ p') then 6B(qo,p) and 6B(qO,P') areundefined.The definition of default unification remains as before:DefinitionDefault Unification (= second version)AU!B --- (A - B) t3 B.Again, characteristics 1-4 of default unification mentioned in the introduction ofthis section hold.
Uniqueness of the result follows from the fact that A - B is unique.
(A - B can be constructed in this case as follows: for all paths p, if 6A(q0, p) = 6A(q0, P'),and p is defined in B, introduce a new value for ~A(q0, p) such that the automata thathave ~A(q0, p) and 6A(qo, p') as initial state are isomorphic.
Next, check for all states inthe modified automaton whether they must be removed and ensure that the resultingautomaton is connected.
)The monotonicity properties of default unification also remain as before.
The the-orem below is the relevant generalization of Theorem 1.Theorem 3For all feature structures A, B, and C, if A G B then (AU!C) U (BU!C)ProofIt suffices to show that A - C ___ B - C, or in other words:1. if ~(6A-C(qo, p)) = a, then ,~(6B-C(qO, p)) = a,194Gosse Bouma Feature Structures and Nonmonotonicity2.
if 6A-c(qo,p) = 6A-C(qo,p') then 6B-c(qo,p) = ~B-C(qo,P'), and3.
if ~x-c(q0, p) is defined, then ~B-C(q0~p) is defined.If these three conditions are met, there is a homomorphism from A - C to B - C asrequired by the definition of subsumption.Case (1): If /~(6A-c(qo,p)) = a, then (i) ~(~B(qO,P)) = a ( since A - C E A _G B)and (ii) from the definition of A - C, it follows that there is no prefix p' of p suchthat 6c(q0, p') EFc or 6c(qo, p') = 6c(q0~ p"), nor is ~c(q0, p) defined.
From (i) and (ii) itfollows that ~B-C(q0~ p) is defined and that A(~B-c(q0, p)) = a.Case (2): Similarly, if 6A-C(qO,p) = ~A-C(q0,p'), then (i) 6B(qo,p) = ~B(qo~P'), and(ii) there is no prefix p' of p such that ~c(q0,p') E Fc or 6c(qo,p') = 6c(qo,p') nor is6c(q0, p) defined.
From (i) and (ii) it follows that 6B-c(q0, p) = 6B-c(q0, p').Case (3): If 6A-c(qo,p) is defined and ~A-C(q0,p) ~ FA-C (otherwise this case re-duces to case (1)) and 6A-C(qO,P) not reentrant (otherwise this case reduces to case(2)), it follows that (i) ~B(qo,P) is defined, and (ii) there is no prefix p' of p such that6c(qo,p') E Fc or 6c(qo,p') = ~c(q0,p").
From (i) and (ii) it follows that ~B-C(qO, P) isdefined.
?The distribution law, however, continues to hold only in one direction:Theorem 4For all feature structures A, B, and C, such that A U B is defined, (AU!C) U (BU!C) ?-(A u B)u!cProofAs in the previous section, it suffices to prove that (A - C) U (B - C) __U (A U B) - C.From the fact that X E X' and Y G Y' implies (X u Y) G (X' u Y'), it follows that((A - C) U (B - C)) ?- (A U B).
Now, as in the previous proof, if some path p is atomic,reentrant, or merely defined in (A -  C) U (B - C), it follows that (i) p is atomic, reentrant,or defined in A U B and (ii) there is no atomic or reentrant path p' in C that is a prefixof p, nor is p defined in C if p is atomic or reentrant in (A - C) u (B - C).
It followsthat p is atomic, reentrant, or defined in (A U B) - C. ?An illustration of this result is given below.
Note that 12 also illustrates that theconverse of Theorem 4. no longer holds.Example 12A =B= \[g:a\]c= \[g:b\]195Computational Linguistics Volume 18, Number 24.3 Add ConservativelyDefining default unification as (A - B) U B will fail to capture the idea of Shieber's(1986b) add conservatively, as the difference operation completely removes a defaultreentrancy if one of the paths leading to it is also defined in the nondefault argument.However, linguistic applications, uch as an encoding of the Head Feature Convention,indicate that a more subtle approach should be taken.
In particular, if a default struc-ture contains the information that (P /= (P'), whereas in the nondefault structure (pl)is defined for some feature l, we want to treat only I as an exception to the generalrule that (P /= (P'/, and preserve the information that Ipl') = (p'l' I (for l' # I).We implement this idea using the following operation:DefinitionLet A and B be automata.
The extension of A relative to B (Ext(A, B)) is the minimal(i.e.
most general) element Ext(A, B) such that1.
A G Ext(A~B),2. if ~A(qO,P) = ~A(qO,p') and ~B(qo,pql) is defined (for some pql E ~*), then~Ext(A,B) (qo, pql') = ~Ext(A,B) (qo, p'ql') (wherever possible) for all 1 / E G.The automaton A is extended, sometimes somewhat redundantly, with reentrantpaths that are extensions of paths already reentrant in A. Ext(A, B) is neverthelessusually more informative than A itself, as the addition of a path pl blocks unificationwith feature structures in which p receives an atomic value.
Note furthermore that pathextensions are not always possible; that is, if 6A(qO,p) E FA and 6B(qo, pl) is defined,there is no extension of A in which pl is defined.
(This explains the wherever possible).In order to get al relevant path-extensions, G will in general be the set of all featuresdefined in the grammar, although in particular cases G can be restricted to a smallerset (the set of head-features, for instance).We are now ready to give a definition of default unification that incorporatesthe effects of add conservatively.
To avoid confusion, we use the operator t3ac!
for thisextended version of default unification.DefinitionDefault Unification (final version)AOac!B = (Ext(A, B) - B) 0 B.An example of default unification involving reentrancies i  presented below.
Weassume that the set of features G = {f,g}.Example 13A =B =Ext(A, B) =I i \ [ r :a  \]\]I f ' \ [ \ ]  f:F1 X: \ [  f : \ [  X : \ [196Gosse Bouma Feature Structures and Nonmonotonicity\] Ext (A ,B)  - B = g fg n~ \[ : \](Ext(A, B) - B) U B =The example shows that default unification is slightly more restrictive than add con-servatively, since the original reentrancy is removed even though A and B would havebeen unifiable.
The reason is of course that this will guarantee uniqueness of the resultof default unification, whereas this is not the case for add conservatively.5.
Linguistic Applications of Default UnificationIn this section, we sketch how default unification can be incorporated in a grammarformalism and argue briefly that this can be an alternative for some of the extensionsmentioned in Section 2.5.1 Nonmonotonic Template InheritanceIn grammar formalisms uch as PATR-II, feature structures are defined as sets ofequations and templates.
Each equation or template denotes a feature structure (i.e.the minimal feature structure that satisfies the equation or the equations that makeup the template definition), and the denotation of a set of such elements i simply theunification of all their denotations.
Incorporation of default unification requires that adistinction is made between default and nondefault information.
In the notation usedhere, nondefault information is prefixed by a "!'.
The feature structure denoted by adefinition that contains both default and nondefault information is arrived at by firstunifying all default information and unifying all nondefault information.
Next, thetwo feature structures are combined by means of default unification (tAac!
).If templates are incorporated as default information, the feature structure denotedby the template is inherited nonmonontonically.
(Monotonic inheritance is possible aswell of course: this is achieved by prefixing a template with "!'.)
As an illustration,consider the following fragment, in which an attempt is made to encode some of thepeculiarities of the English auxiliary system in a lexicalist grammar:Example 14 NPVERBVPAUX: ( (cat) = n(nform) = norm ).
: ( ( ca t )  = v(aux)  - -  -(inv) = - ).
:( VERB(subcat first) = NP(subcat rest) = empty ).
: ( VERB!
(aux)  = +!
(inv) = +(subcat first) = VP(subcat rest first) = NP(subcat rest rest I -- empty!
(subcat first subcat first nform I =(subcat rest first nform I ).197Computational Linguistics Volume 18, Number 2Adding the equations !
(aux} : + and !
(inv} : +5 to the definition of AUX has an ef-fect comparable to that of the overwrite-operation f (C;hieber 1986a, p. 60).
The AUXtemplate inherits from VERB by default, but the equations just mentioned block in-heritance of the values for (inv} and (aux}.
However, default unification allows us todo more.
An auxiliary does not subcategorize for an ordinary NP subject, nor doesit subcategorize for a complement VP that subcategorizes for an ordinary NP subject.Rather, the restrictions to be placed on the nform of the subject are inherited from theembedded VP:Example 15a.
it will annoy Kim that she lostb.
*Sue will annoy Kim that she lostThis dependency between elements of the subcat list is encoded in the final equation,which also suppresses (or overwrites) the default value for (nform}.
The denotation ofAUX is thus:Example 16cat : vaux : +inv : +subcat :first :res t  :ca t  : vaRx  : - -inv : -\[ \ [cat:np 1 \ ] f i r s t :  subcat : nform : \ [ \ ]rest : emptyf l r s t : \ [n fo rm:~\ ]  \].
\[ cat : nprest : emptyThe nonmonotonic inheritance regime is flexible enough to allow for exceptionsto exceptions.
Gazdar et al (1985, p. 65) observe that at least in some dialects ofEnglish, the auxiliary might cannot occur in inverted structures.
This is expressed inthe following lexical entry, in which might inherits nonmonotonically from AUX, whichitself inherits nonmonotonically from VERB:Example 17might :( AUX!
( inv}=- ).There is an important difference between the approach to nonmonotonic inheri-tance sketched here and the majority of inheritance-based formalisms used for Knowl-edge Representation, which has to do with the way in which templates are evaluated.If a template is used as part of the definition of another feature structure, all we needto know to determine the denotation of this feature structure is the denotation of this5 Note that the feature INV as used here indicates only whether  a (lexical) i tem may occur in an invertedstructure.
It does not dist inguish between inverted and noninverted clauses.198Gosse Bouma Feature Structures and Nonmonotonicitytemplate (which is a feature structure).
How this template was defined (as a set ofequations or as a combination of (more general) templates, as a combination of de-fault and nondefault information or not) is completely irrelevant to its meaning.
Thus,the denotation of AUX would remain as before, if we defined it as:Example 18AUX : ( (cat) = v(aux) = +(inv) = +.Consequently, the denotation of might is not affected by this change in definition either.The role of classes (or frames) in inheritance-based systems, however, as describedin, for instance, Touretzky (1986), is rather different.
To determine the denotation of aclass might that inherits from a class AUX,  we not only need to know the contents ofAUX,  but also the classes from which AUX inherits.
The latter is important for resolv-ing multiple-inheritance conflicts.
If the class might inherits from both AUX and VERB,for instance, and AUX in its turn inherits from VERB as well, information inheritedfrom AUX must take precedence over information from VERB, as the former is morespecific than the latter.
In our nonmonotonic inheritance mechanism for templates,such reasoning is impossible.
Adding the template VERB as default information to thedefinition of the template (or lexical entry) might would lead to a unification failureof the default information, and thus the definition as a whole would be considered asillegal.
6 This is as it should be, we believe, given the fact that the inheritance hierarchyas such should not play a role in determining the meaning of templates.
The denota-tion of the template AUX is the feature structure in 16 (i.e., whether it is defined asin 14 or as in 18 is irrelevant), and from that it is impossible to conclude that AUXinherits from VERB, and thus the kind of reasoning used to justify the resolution offeature conflicts used in Touretzky (1986) is not applicable in our case.5.2 Lexical DefaultsThe definition of auxiliaries above is still unsatisfactory in that it predicts that auxil-iaries subcategorize for verbal complements that are specified as (aux) = - .
Clearly,this requirement is too strong (although it is correct for the auxiliary do).
One way tosolve this problem is to redefine the AUX-template as:Example 19AUX : .
?
.
(subcat first cat) = v(subcat first subcat first) = NP(subcat first subcat rest) = empty6 Of course, it is possible to combine incompatible d fault information if we impose the correct orderingexplicitly.
This can be done by using definitions (i.e.
a set of equations inbrackets) indefinitions:might : ( (VERB !AUX)!
(inv) -= -- ).This is equivalent to the definition of might given in 17, albeit more complex and possibly misleading.199Computational Linguistics Volume 18, Number 2This solution seems inelegant, however, as it reconstructs part of the VP-template inorder to express the correct subcategorization requirements.
Thus, the obvious gen-eralization that an auxiliary subcategorizes for a VP is missed by this redefinition.The source of this inelegance is the fact that VP inherits from VERB, and that VERBcontains default information about properties typical for verbs.
However, while theseproperties hold for the vast majority of verbs, it is not the case that if an elementsubcategorizes for a verbal complement, the default properties need to hold for thecomplement aswell.
What is needed here is a distinction between properties that holdby default for all members of a class and default properties that can be assumed tohold if a lexical item subcategorizes for members of this class.
While the latter can beexpressed safely by means of templates, the former are more adequately expressed inthe form of lexical defaults.The extension of unification-based formalisms witlh lexical defaults can be imple-mented using default unification.
The effect of lexical defaults is comparable to thatof lexical Feature Specification Defaults in GPSG.
A lexical default is a statement of theform Name: Ant ~ Cons, where Ant and Cons are feature structure descriptions.
Theinterpretation f lexical defaults is that the feature structure of each lexical entry thatis subsumed by the antecedent of a lexical default is extended, by means of defaultunification, with the contents of the consequent.
Lexical entries are thus compiled intwo stages: first, the denotation of the feature structure description is computed andnext, the lexical defaults are applied to this feature structure.Consider for example the following lexical defaults:Example 20FSD1 :FSD2 :VERB ) ~ ( (aux)=- ) .
(aux)=-  ) ~ ( ( inv )=-  ).The fragment in 14 and 17 is assumed to be redefined as follows:Example 21VERB:VP:AUX :might:(cat)  = v ).VERB(subcat first) = NP(subcat rest) = empty ).VERB(aux)  = +(subcat first) = VP?
.
.  )
.AUX(inv) = - ).Each verbal lexical item will be extended with the information (aux) = - ,  unless itis an auxiliary of course, since in that case, the lexical entry is already specified as(aux) = +.
Only nonauxiliary verbs are extended with the information (inv) = -(FSD2).
7 Auxiliaries remain unspecified for this feature, thus capturing the fact that7 The evaluation of these two lexical defaults is thus order-sensitive, The same situation can in principlearise in GPSG as well, although the particular example given here is avoided in GKPS by200Gosse Bouma Feature Structures and Nonmonotonicityauxiliaries can, but not necessarily do, occur in inverted structures.
8 The exceptionalcharacter of might is expressed in this case by adding explicitly the information that itcannot invert.The problem sketched at the beginning of this section is now resolved.
An auxiliarysubcategorizes for a VP, which in its turn inherits from the template VERB.
However,since the latter template no longer contains default information that should hold forlexical entries only, an auxiliary no longer subcategorizes for verbal complements thatare (aux) : - .
Auxiliaries that subcategorize for a restricted set of verbal complements,such as do, which requires a (aux) : - complement, can be encoded by adding therelevant constraint to their lexical entries.5.3 Specialization of ReentranciesAnother important property of default unification is that it enables us to define ex-ceptions to a reentrancy.
Consider for instance the following GPSG rule (where Hindicates the head of the rule):Example 22s x 2  \[-subj\]The symbol S can be analyzed as the feature structure in 23.
Applying the Head FeatureConvention to the rule in 22 amounts to adding to H all head features compatible withhead features in S. Using default unification, this is implemented in 24 as a defaultreentrancy that equates the head features of S and H.Example 23S :( (head n) = -(head v) = +(head bar) = 2(head subj) = + .Example 24S-rule X0 ~ X1 X2;(Xo)  = s(Xl head bar) = 2!
(X2 head subj) = -(Xo head) = (X2 head)The final equation in 24 both implements he HFC and defines X2 as the head daughter.An exception to the reentrancy is the fact that IX2 head subj) = - ,  which is thereforerepresented asnondefault information.
In this approach, the HFC is part of the rulesitself and thus, the effect of Shieber's (1986b) special-purpose compilations step, whichadds the HFC conservatively, is achieved irectly.implementing the effect of FSD2 above as a feature coocurrence r striction.8 Note that, as in GPSG, the feature INV plays a double role by indicating both an item's potential tooccur in inverted structures as well as indicating whether a given structure is inverted or not.201Computational Linguistics Volume 18, Number 26.
ConclusionsWe have shown in the preceding sections that it is possible to incorporate nonmono-tonicity in a unification-based formalism, while at the same time preserving the ideathat linguistic knowledge is represented in the form of feature structures.In spite of their great flexibility, unification-based formalisms are in general notvery well equipped to deal with linguistic rules or generalizations that have a defaultcharacter and for which exceptions exist.
In Sections 4 and 5 we hope to have demon-strated that a nonmonotonic operation on feature structures combined with straight-forward extensions of the description languages used in unification-based formalismsenables a satisfactory account of the phenomena mentioned in the introduction.
Theapplications illustrate that default unification can be used to give linguistically ap-pealing implementations of certain natural language phenomena, not that it would beimpossible to account for these facts using unification only.
Thus, default unificationserves to extend the expressive power of unification-based formalisms, but leaves therepresentation method of unification-based formalisms, in which linguistic objects arerepresented asfeature structures, unchanged.
Comparing default unification to earlierproposals, we believe that an advantage of our approach is that it is general, in thesense that one operation is used to achieve the effects of overwriting, add conservatively,nonmonotonic template inheritance, and priority union.
Also, whereas previous proposalsdo not seem to be well behaved for feature structures containing reentrancies, defaultunification is defined for feature structures of arbitrary complexity.D6rre et al (1990) suggest hat the use of nonmonotonic devices in unification-based formalisms will, for the time being, be limited to off-line extensions of theseformalisms; that is, extensions whose effect can be computed at compile time and re-sult in ordinary feature structures.
They also note that while there may be linguisticarguments in favor of more dynamic notions of default reasoning, from a computa-tional point of view the off-line approach is clearly preferred.
Default unification, asused in the previous ection, is an example of an off-line extension, as the effects ofnonmonotonic template inheritance, lexical defaults, and the meaning of rule defini-tions in which default and non-default information is combined, can be computed atcompile time.
Again, this emphasizes the point that incorporation ofdefault unificationin principle only extends the expressive power of unification-based formalisms.AcknowledgmentsA syntactic approach to default unificationis presented in Bouma (1990).
The reactionson that paper made it clear to me thatdefault unification should be defined notonly for feature structure descriptions, butalso for feature structures themselves.
Forhelpful questions, uggestions, andcomments on the material presented here, Iwould like to thank Bob Carpenter, JohnNerbonne, audiences in Tilburg, Groningen,Tiibingen, and Dhsseldorf, and threeanonymous CL reviewers.ReferencesBouma, Gosse (1990).
"Defaults inunification grammar."
In Proceedings, 28thAnnual Meeting of the Association forComputational Linguistics, Pittsburgh, PA,165-172.Bresnan, Joan, and Kaplan, Ronald (1982).
"Lexical functional grammar: A formalsystem for grammatical representation.
"In The Mental Representation f GrammaticalRelations, edited by J. Bresnan, 173-281.Cambridge, MA: The MIT Press.Dawar, Anuj, and Vijay-Shanker, K.
(1990).
"An interpretation ofnegation in featurestructure descriptions."
ComputationalLinguistics, 16(1), 11-21.Daelemans, Walter (1988).
"A model ofDutch morphophonology and itsapplications."
A/Communications, 1(2),18-25.D6rre, Jochen; Eisele, Andreas; Wedekind,Jiirgen; Calder, Jo; and Reape, Mike(1990).
A Survey of Linguistically MotivatedExtensions to Unification-Based Formalisms.DYANA Deliverable R3.1.A., Centre for202Gosse Bouma Feature Structures and NonmonotonicityCognitive Science, University ofEdinburgh.Evans, Roger, and Gazdar, Gerald (1989a).
"Inference in DATR."
In Proceedings,Fourth Conference ofthe European Chapter ofthe ACL," University of Manchester, 66-71.Evans, Roger, and Gazdar, Gerald (1989b).
"The semantics of DATR."
In Proceedings,Seventh Conference ofthe Society for the Studyof Artificial Intelligence and the Simulation ofBehaviour, edited by A. Cohn, 79-87.London: Pitman Publ.Flickinger, Daniel (1987).
Lexical Rules in theHierarchical Lexicon.
Doctoral dissertation,Stanford University, Stanford, CA.Hickinger, Daniel; Pollard, Carl; and Wasow,Thomas (1985).
"Structure-sharing ilexical representation."
In Proceedings, 23rdAnnual Meeting of the Association forComputational Linguistics.
Chicago, Illinois,262-267.Gazdar, Gerald; Klein, Ewan; Pullum,Geoffrey; and Sag, Ivan (1985).
GeneralizedPhrase Structure Grammar.
London:Blackwell.Kaplan, Ronald (1987).
"Three seductions ofcomputational psycholinguistics."
InLinguistic Theory and Computer Applications,edited by P. Whitelock, H. Somers,P.
Bennett, R. Johnson, and M. McGeeWood, 149-188.
London: Academic Press.Kasper, Robert, and Rounds, William (1986).
"A logical semantics for featurestructures."
In Proceedings, 26th AnnualMeeting of the Association for ComputationalLinguistics.
New York, NY, 257-266.Kasper, Robert, and Rounds, William (1990).
"The logic of unification in grammar.
"Linguistics and Philosophy, 13(1), 35-58.Pollard, Carl, and Sag, Ivan (1987).Information-Based Syntax and Semantics,Volume 1: Fundamentals.
CSLI LectureNotes 13.
Chicago: University of ChicagoPress.Shieber, Stuart (1986a).
An Introduction toUnification-Based Approaches toGrammar.CSLI Lecture Notes 4.
Chicago: Universityof Chicago Press.Shieber, Stuart (1986b).
"A simplereconstruction f GPSG."
In Proceedings,COLING 1986.
Bonn, Germany, 211-215.De Smedt, Koenraad (1990).
IncrementalSentence Generation.
Doctoral dissertation,Katholieke Universiteit Nijmegen,Nijmegen, The Netherlands.Touretzky, David (1986).
The Mathematics ofInheritance Systems.
Los Altos, CA:Morgan Kaufmann.203
