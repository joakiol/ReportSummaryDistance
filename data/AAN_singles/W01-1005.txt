Identification of relevant terms to support the construction of DomainOntologiesPaola Velardi?
and Michele Missikoff?
and Roberto Basili+?
Universit?
di Roma ?La Sapienza?Velardi@dsi.uniroma1.it?IASI-CNR, Romamissikoff@iasi.rm.cnr.it+ Roberto BasiliUniversit?
di Roma, Tor Vergatabasili@info.uniroma2.itAbstractThough the utility of domainOntologies is now widelyacknowledged in the IT (InformationTechnology) community, severalbarriers must be overcome beforeOntologies become practical anduseful tools.
One importantachievement would be to reduce thecost of identifying and manuallyentering several thousand-conceptdescriptions.
This paper describes atext mining technique to aid anOntology Engineer to identify theimportant concepts in a DomainOntology.1 IntroductionIn cooperating to work together (or even ininteracting in social settings), people andorganizations must communicate amongthemselves.
However, due to different contextsand backgrounds, there can be differentviewpoints, assumptions and needs regardingthe same domain or the same problem.
Theymay use different jargon and terminology,sometimes even confused, overlapping, andthey may use concepts and evaluation methodsthat are mismatched or poorly defined.The consequence is the lack of a sharedunderstanding that leads to a poorcommunication between people andorganizations.
In particular, when IT solutionsare involved, this lack of a sharedunderstanding impacts on:?
Effectiveness of people?s cooperation?
Flaws in enterprise organization?
The identification of the requirements forthe system specification?
The inter-operability among systems and?
The possibility of re-using and sharing ofsystems components.The goals of an Ontology is to reduce (oreliminate) conceptual and terminologicalconfusion.
This is achieved by identifying andproperly defining a set of relevant conceptsthat characterize a given application domain.With respect to a Thesaurus:An Ontology aims at describing concepts,whereas a Thesaurus aims at describing terms;An Ontology can be seen as an enrichedThesaurus where, besides the definitions andrelationships among terms of a given domain,more conceptual knowledge, by means ofricher semantic relationships, is represented.With respect to a Knowledge Base (KB):An Ontology can be seen as a KB whose goalis the description of the concepts necessary fortalking about domains;A KB, in addition, includes the knowledgeneeded to model and elaborate a problem,derive new knowledge, prove theorems, oranswer to intentional queries about a domain.Though the utility of domain Ontologies isnow widely acknowledged in the ITcommunity, several barriers must be overcomebefore Ontologies become practical and usefultools for shared knowledge management.We envisage three main areas whereinnovative computational solutions couldsignificantly reduce the cost and effort ofOntology construction:?
provide effective support for collaborativedevelopment of consensus Ontologies,since consensus is the first condition  to bemet in order to obtain the desired benefitsfrom an Ontology?
enable distributed development and accessto Ontologies, since wide-spread usage ofa resource outweighs the cost ofdevelopment?
develop tools to identify the relevantconcepts and (semi-)automatically  enrichwith semantic information the nodes of theOntology, thus reducing the cost andcomplexity of manually defining severalthousand conceptsIn this paper, we describe SymOntos, anOntology management system underdevelopment at our institution since the lastseveral years.
In designing SymOntos, wehave been working to define innovativesolutions concerning the three critical issueslisted above.
These solutions are currentlybeing experimented in the context of theEuropean project FETISH1, aimed at thedefinition of an interoperability platform forSmall Medium Enterprises in the tourismsector.Though we will (very) briefly presentSymOntos, this paper is concerned with thethird issue, that is, the description of textmining methods and tools to automaticallyenrich the concept Ontology.In the FETISH Project, we decided to explorethe possibility to support the extraction ofinitial shared/able knowledge from on-linetextual documentation accessible from theWeb.2 SymOntos: a symbolic Ontologymanagement  systemSymOntos (SymOntos 2000) is an Ontologymanagement system under development atIASI_CNR.
It supports the construction of anOntology  following the OPAL (Object,Process, and Actor modeling Language)methodology.
OPAL is a methodology for themodeling and management of the EnterpriseKnowledge Base and, in particular, it allowsthe representation of the semi-formalknowledge of an enterprise.
As alreadymentioned, an Ontology gathers a set ofconcepts that are considered relevant to a givendomain.
Therefore, in SymOntos theconstruction of an Ontology is performed bydefining a set of concepts.
In essence, inSymOntos a concept is characterized by:a term, that denotes the concept,a definition, explaining the meaning of theconcept, generally in natural language,a set of relationships with other concepts.1 The interested reader may access the Web sitereported in the bibliographyFigure 1 shows an example of  filled conceptform in the Tourism domain.
The DomainOntology is called OntoTour.
Conceptrelationships play a key role since they allowconcepts to be inter-linked according to theirsemantics.
The set of concepts, together withtheir links, forms a semantic network(Brachman 1979).In a semantically rich Ontology, both conceptsand semantic relationships are categorized.Semantic relationships are distinguishedaccording to three main categories2 namely,Broader Terms, Similar Terms, Related Terms,that are described below.The Broader Terms relationship allows a set ofconcepts to be organized according to ageneralization hierarchy (corresponding in theliterature to the well-known ISA hierarchy).With the Similar Terms relationship, a set ofconcepts that are similar to the concept beingdefined are given, each of which annotatedwith a similarity degree.
For instance, theconcept Hotel can have as similar conceptsBed&Breackfast, , with similarity degree 0.6,and camping, with similarity degree 0.4.Finally, the Related Terms relationship allowsthe definition of a set of concepts that aresemantically related to the concept beingdefined.
Related concepts may be of differentkinds, but they must be defined in theOntology.For instance, TravelAgency, Customer, orCreditCard, are concepts that are semanticallyrelated to the Hotel concept.In SymOntos, Broader relations are alsoreferred to as  ?vertical?
, while Related andSimilar are called ?horizontal?
relations.SymOntos is equipped with functions to ensureconcept management, verification and2 The represented information is in fact quite morerich, but we omit a detailed description for sake ofspaceOntology closure, and a web interface to helpdeveloping consensus definitions in a givenuser community (Missikoff and Wang, 2000).These functions are not described here sincethey are outside the purpose of the paper.HotelDef: A place where atourist can stayXML tag: <htl>Gen: AccommodationSpec: Country_ Guest_house, motelPart-of:receptivity _systemHas-part:fitness_facilities,restaurant, garageRelated-objects: Reservation,payment, depositRelated-actors: Htl-manager,cashier, room_serviceRelated-processes: reserving,paying, billing,airport_transferSimilar-concepts: B&B[0.6],camping[0.4],holiday_apartment[0.7]Figure 1 ?
the Hotel concept in OntoTour3 Text Mining tools to construct aDomain OntologyIn Section 2 we illustrated the main features ofthe SymOntos system, and provided anexample of  concept definition in the Tourismdomain.The techniques described in this Section areintended to significantly improve humanproductivity in the process that a group ofdomain experts accomplish in order to find anagreement on:?
the identification of the key concepts andrelationships in the domain of interest?
providing an explicit representation of theconceptualization captured in the previousstageTo reduce time, cost (and, sometimes, harshdiscussions) it is highly advisable to refer tothe documents available in the field.
In thispaper we show that text-mining tools may beof great help in this task.At the present state of the project, naturallanguage processing tools have been used forthe following tasks:1.
Identification of  thesauric information, i.e.discovery of terms that are good candidatenames for the concepts in the Ontology.2.
Identification of taxonomic relationsamong these terms.3.
Identification of related termsFor sake of space, only the first method isdescribed in this paper.
Details of the othermethods may be found in (Missikoff et al2001).To mine texts, we used  a corpus processornamed ARIOSTO (Basili et al 1996) whoseperformance has been improved with theaddition of a Named Entity recognizer(Cucchiarelli et al 1998) (Paliouras et al2000) and a chunk parser CHAOS (Basili et al1998).
In the following, we will refer to thisenhanced release of the system as ARIOSTO+.Figure 2 provides an example of final output(simplified for sake of readability) produced byARIOSTO+  on a Tourism text.
Interpretingthe output predicates of Figure 2 is ratherstraightforward.The main principles underlying the CHAOSparsing technology are decomposition andlexicalization.
Parsing is carried out in foursteps: (1) POS tagging, (2) Chunking, (3) Verbargument structure matching and (4) Shallowgrammatical analysis.
.Chunks are defined via prototypes.
These aresequences of morphosyntactical labels mappedto specific grammatical functions, called chunktypes.
Examples of labels for the innercomponents are Det, N, Adj, and Prepwhile types are related to traditionalconstituents, like NP, PP, etc.The definition of chunk prototypes in CHAOSis implemented through regular expressions.Chunks are the first types of output shown inFigure 2.
The link(..) predicates represent theresult of shallow parsing.
Whenever theargument structure information cannot be usedto link chunks, a plausibility measure iscomputed, which is inversely proportional  tothe number of colliding syntactic attachments(see the referred papers for details).
The firstphase of the Ontology building processconsists in the identification of the keyconcepts of the application domain.______________________________________The  Colorado River Trail   follows the  Colorado Riveracross 600 miles of beautiful  Texas Country  - from thepecan orchards   of  San Saba   to the  Gulf of Mexico  .
[ 1 , Nom , [The,Colorado_River_Trail] ][ 2 , VerFin , [follows] ][ 3 , Nom , [the,Colorado_River] ][ 4 , Prep , [across,600_miles] ][ 5 , Prep , [of,beautiful,Texas_Country] ](more follows..)link(0,2,'Sentence').link(2,1,'V_Sog', plaus(1.0)).link(2,3,'V_Obj', plaus(1.0)).link(3,4,'NP_PP',plaus(0.5)).link(2,4,'V_PP',plaus(0.5)).link(4,5,'PP_PP',plaus(0.3333333333333333)).link(3,5,'NP_PP',plaus(0.3333333333333333)).link(2,5,'V_PP',plaus(0.3333333333333333)).(?morefollows?
)______________________________________________Figure 2.
An example of parsed TourismtextThough concept names do not always have alexical correspondent in natural language,especially at the most general levels of theOntology, one such correspondence may benaturally drawn among the more specificconcept names and  domain-specific words andcomplex nominals, like:?
Domain Named Entities (e.g., gulf ofMexico, Texas Country, Texas WildlifeAssociation)?
Domain-specific complex nominals   (e.g.,travel agent, reservation list, historic site,preservation area)?
Domain-specific singleton words (e.g.,hotel, reservation, trail, campground)We denote these singleton and complex wordsas Terminology.Terminology is the set of words or wordstrings , which convey a single, possiblycomplex, meaning within a given community.In a sense, Terminology  is the surfaceappearance, in texts, of  the domain knowledgein a given domain.
Because of their lowambiguity and high specificity, these words arealso particularly useful to conceptualize aknowledge domain, but on the other side, thesewords are often not found in Dictionaries.
Wenow describe how the different types ofTerminology are captured  using NLPtechniques.3.1 Detection of Named EntitiesProper names are the instances of domainconcepts, therefore they populate the leaves ofthe Ontology.Proper names are pervasive in texts.
In theTourism domain, as in most domains, NamedEntities (NE) represent more than 20% of  thetotal occurring words.To detect NE, we used a module alreadyavailable in ARIOSTO+.
A detaileddescription of the method summarizedhereafter may be found in (Cucchiarelli et al1998) (Paliouras et al 2000).
In ARIOSTO+,NE are detected and semantically taggedaccording to three main conceptual categories:locations (objects in OPAL), organizations andpersons (actors in OPAL) .
When contextualcues are sufficiently strong (e.g.
"lake Tahoe islocated.".
), names of locations are further sub-categorized (city, bank, hotel, geographiclocation, ..), therefore the Ontology Engineer isprovided with semantic cues to correctly placethe instance under  the appropriate conceptnode of the Ontology.Named Entity recognition is based on a set ofcontextual rules (e.g.
"a complex or simpleproper name followed by the trigger wordauthority is a organization named entity").Rules are manually entered or machine learnedusing decision lists.
If a complex nominal doesnot match  any  contextual  rule in the NE rulebase, the decision is delayed until syntacticparsing.
A classification based on syntacticallyaugmented context similarity is laterttempted.The NE tagger is also used to automaticallyenrich the Proper Names dictionary, thusleading to increasingly better coverage as longas new texts are analyzed.As reported in the referred papers, the F-measure (combined recall and precision with aweight factor w=0,5) of this method isconsistently (i.e.
with different experimentalsettings) around  89%, a performance thatcompares very well with other NE recognizersdescribed in the literature3.3.2 Detection of domain-specific wordsand complex nominalsNEs are word strings in part or totallycapitalized, and they often appear in well-characterized contexts.
Therefore, the task ofNE recognition is relatively well assessed inliterature.
Other not-named terminologicalpatterns (that we will refer hereafter again withthe word "terminology" though in principlet rminology includes also NEs) are rather moredifficult to capture since the notion of erm ismostly underspecified.In the literature (see Bourigault et al (1998)for an overview of recent research) thefollowing steps are in general adopted:?
Detecting terminological candidates fromtexts?
Selecting the specific entries that can bemembers of a terminological glossary inthe target domain of knowledge.Candidates terminological expressions are3 ftp.muc.saic.com/proceedings/score_reports_index.htmlusually captured with more or less shallowtechniques, ranging from stochastic methods(Church, 1988) to more sophisticated syntacticapproaches (e.g.
Jacquemin, 1997).Obviously, richer syntactic informationpositively influences the quality of the result tobe input to the statistical filtering.
In ourresearch, we used the CHAOS parser to selectcandidate terminological patterns.
Nominalexpressions usually denoting terminologicalitems are very similar to chunk instances.Specific chunk prototypes have been used tomatch  terminological structures.A traditional problem of purely syntacticapproaches to term extraction isovergeneration.
The available candidates thatsatisfy grammatical constraints are far morethan the true terminological entries.
Extensivestudies suggest that statistical filters be alwaysfaced with 50-80% of non-terminologicalcandidates.Filtering of true terms can be done byestimating the strength of an associationamong words in a candidate terminologicalexpression.
Commonly used associationmeasures are the Mutual Information (Fano,1961) and the Dice factor (Smadja et al 1996).In both formulas, the denominator combinesthe marginal probability of each wordappearing in the candidate term.
If one of thesewords is particularly frequent, both measurestend to be low.
This is indeed not desirable,because certain very prominent domain wordsappear in many terminological patterns.
Forexample, in the Tourism domain, the term visaappears both in isolation and in manymultiword patterns, e.g.
: business visa,extended visa, multiple entry business visa,transit visa, student visa, etc.
?Such patternsare usually not captured by standardassociation measures, because of the highmarginal probability of visa.Another widely used measure is the inversedocument frequency, idf.idfi =log2NdfiWhere dfi is the number of documents in adomain Di that include a term t, and N is thetotal number of documents in a collection of ndomains (D1, ?, Dn).
The idea underlying thismeasure is to capture words that are frequent ina subset of documents representing a givendomain, but are relatively rare in a collectionof  generic documents.
This measure capturesalso words that appear just one time in adomain, which is in principle correct, but isalso a major source of noise.Other corpus-driven studies suggested thatpure frequency as a ranking score (i.e.
ameasure of the plausibility of any candidate tobe a term) is a good metrics (Daille 1994).However, frequency alone cannot be taken as agood indicator: several very frequentexpressions (e.g.
last week) are perfectcandidates from a grammatical point of viewbut they are totally irrelevant as terminologicalexpressions.
It is worth noticing that this is truefor two independent reasons.
First, they are notrelated to specific knowledge, pertinent to thetarget domain, but are language specific:different languages express with differentsyntactic structures  (adverbial vs. nominalphrases) similar temporal or spatialexpressions.
As a result such expressions havesimilar distributions in different domaincorpora.
True terminology is tightly related tospecific concepts so that their use in the targetcorpus is highly different wrt other corpora.Second, common sense expressions are onlyoccasionally used, their meaning depending onfactual rather than on conceptual information.They occur often once in a document and tendnot to repeat throughout the discourse.
Theirappearance is thus evenly spread throughoutdocuments of any corpus.
Conversely, trueterms are central elements in discourses andthey tend to recur in the documents where theyappear.
They are thus expected to show moreskewed (i.e.
low entropy) distributions.The above issues suggest the application oftwo different evaluation (utility) functions.Although both are related to the widelyemployed notion of term probability, theycapture more specific aspects and provide amore effective ranking.3.2.1 Modeling Relevance in domainsAs observed above, high frequency in a corpusis a property observable for terminological aswell as non-terminological expressions (e.g.
"last week" or "real time").
The specificity of aterminological candidate with respect to thetarget domain (Tourism in our case) ismeasured via comparative analysis acrossdifferent domains.
A specific score, calledDomain Relevance (DR), has been defined.More precisely, given a set of n d mains4 (D1,?, Dn)  the domain relevance of a term t iscomputed as:(1)D R ( t , D i )= P ( t | D i )P(t | D i )i=1..n?where the conditional probabilities (P(t|Di))are estimated as:E ( P ( t| D i ) )=freq(t in Di)freq(t in Di)i=1..n?3.2.2 Modeling Consensus about a termTerms are concepts whose meaning is agreedupon large user communities in a givendomain.
A more selective analysis should takeinto account not only the overall occurrence inthe target corpus but also its appearance in4 ?
domains ?
are (pragmatically) represented bytexts collections in different areas, e.g.
medicine,finance, tourism, etc.single documents.
Domain concepts (e.g.ravel agent) are referred frequentlythroughout the documents of a domain, whilethere are certain specific terms with a highfrequency within single documents butcompletely absent in others (e.g.
petrol station,foreign income).Distributed usage expresses a form ofconsensus tied to the consolidated semantics ofa term (within the target domain) as well as toits centrality in communicating domainknowledge.
A second indicator to be assignedto candidate terms can thus be defined.Domain consensus measures the distributeduse of a term in a domain Di..
The distributionof a term t in documents dj can be taken as astochastic variable estimated throughout all dj?
Di.
The entropy H of this distributionexpresses the degree of consensus of t in Di.More precisely, the domain consensus isexpressed as follows(2)DC(t,Di) =H(P(t,dj)=P(t,dj)dj?
Di?
log2 1P(t,dj)???
???
?Where:E(P(t ,dj))=freq(t in dj)f req( t in dj)dj?
Di?Pruning of not terminological (or not-domain)candidate terms is performed using acombination of the measures (1) and (2).
Weexperimented several combinations of thesetwo measures, with similar results.
The results,discussed in the next Section, have beenobtained applying a threshold a to the set ofterms ranked according to (1) and theneliminating the candidates with a rank (2)lower than b.4 ExperimentsAn obvious problem of any automatic methodfor concept extraction is to provide objectiveperformance evaluation.?
Firstly, a "golden standard" tourismterminology would be necessary toformally measure the accuracy of themethod.
One such standard is notavailable, and determining this standard isone of the objectives of FETISH.Moreover, the notion of "term" is toovague to consider available terminologicaldatabases as "closed" sets, unless thedomain is extremely specific.?
Secondly, no formal methods to evaluate aterminology are available in literature.
Thebest way to evaluate a "basic" linguisticcomponent (i.e.
a module that performssome basic task, such as POS tagging,terminology extraction, etc.)
within alarger NLP application (informationextraction, document classification, etc.)
isto compute the difference in performancewith and without the basic component.
Inour case, since Ontology does not performany measurable task, adopting a similarapproach is not straightforward.
As amatter of facts, an Ontology is a basiccomponent itself, therefore it can beformally evaluated only in the context ofsome specific usage of the Ontology itself.Having in mind all these inherent difficulties,we performed two sets of experiments.
In thefirst, we extracted the terminology from acollection of texts in the Tourism domain, andwe manually evaluated the results, with thehelp of other participants in the FETISHproject (see the FETISH web site).
In thesecond, we attempted to assess the generalityof our approach.
We hence extracted theterminology from a financial corpus (the WallStreet journal) and then we both manuallyevaluated the result, and compared theextracted terminology with an availablethesaurus in a (approximately) similar domain.As a reference set of terms we used theWashington Post5 (WP) dictionary ofeconomic and financial terms.To compute the Domain Relevance, we firstcollected corpora in several domains: tourismannouncements and hotel descriptions,economic prose (Wall Street Journal), medicalnews (Reuters), sport news (Reuters), abalanced corpus (Brown Corpus) and fournovels by Wells.
Overall, about 3,2 millionwords were collected.In the first experiment, we used the Tourismcorpus as a ?target?
domain for termextraction.The Tourism corpus was manually built usingthe WWW and currently has only about200,000 words, but it is rapidly growing.Table 1 is a summary of the experiment.
It isseen that only 2% terms are extracted from theinitial list of candidates.
This extremely highfiltering rate is due to the small corpus: manycandidates are found just one time in thecorpus.
However, candidates are extracted withhigh precision (over 85%).N.
of candidate multiword terms (afterparsing)14.383N.
of extracted terms (with a=0.35 andb=0.50)288% correct (3 human judges) 85.20%Number of subtrees (of which withdepth>0)177(54)Table 1.
Summary results for the termextraction task in the Tourism domainTable 2 shows the 15 most highly ratedmultiword terms, ordered by Consensus(Relevance is 1 for all the terms in the list).Table 3 illustrates the effectiveness of DomainConsensus at pruning irrelevant terms: all the5http://www.washingtonpost.com/wp-srv/business/longterm/glossary/indexag.htmcandidate terms in the list have DR>a, butDC<b.Terms Domain Consensuscredit cardtourist informationtravel agentswimming poolservice chargecar rentalcredit card numbercard numberroom rateinformation centrebeach hoteltourist areatour operatorstandard roomvideo camera0.8469130.6967010.6866680.6640410.6409510.6355800.6166710.6166710.5967640.5796620.5718980.5654620.5434190.5394500.523142Table 2: The 15 most highly rankedmultiword Tourism termsDomainRelevanceDomainConsensusenglish cyclistmanual workpetrol stationschool diplomawestern moviewhite cloudfalse statementbest pricecouncil decisionforeign incomegay communitymortgage interestsubstantial discounttypical day1.0000001.0000001.0000001.0000001.0000001.0000000.6213690.6129480.6129480.4419070.4419070.4419070.4419070.4419070.0000000.0000000.0000000.0000000.0000000.0000000.0000000.2242440.0000000.0000000.2242440.0000000.2242440.224244Table 3.
Terms with high Domain Relevanceand low Domain ConsensusIn the second experiment, we used the one-million-word Wall Street journal (WSJ) andthe Washington Post (WP) referenceterminology.The WP  includes 1270 terms, but only 214occur at least once in the WSJ.
We used these214 as the "golden standard" (Test1), but weperformed different experiments eliminatingterms with a frequency lower than 2 (Test2), 5(Test5) and 10 (Test10).
This latter set includesonly 73 terms.During syntactic processing, 41,609 chunkprototypes have been extracted as eligibleterminology.The Tables 4 and 5 compare our method with twith Mutual Information, Dice factor, and purefrequency.
Clearly, these measures are appliedon the same set of eligible candidates extractedby the CHAOS chunker.
The results reportedin each line are those obtained using the bestthreshold for each adopted measure6.
For ourmethod (DR+DC), the threshold is given bythe values a and b.
As remarked in theintroduction, a comparison against a goldenstandard may be unfair, since, on one side,many terms may be present in the observeddocuments, and not present in the terminology.On the other side, low frequency terms in thereference terminology are difficult to captureusing statistical filters.
Due to these problems,the F-measure is in general quite low, thoughour method outperforms Mutual Informationand Dice factor.
As remarked by Daille(1994), the frequency emerges as a reasonableindicator, especially as for the Recall value,which is a rather obvious result.However pure frequency implies the problemsoutlined in the previous section.
Upon manualinspection, we found that, as obvious,undesired terms increase rapidly in thefrequency ranked term list, as the frequencydecreases.
Manually inspecting the first 100highly ranked terms produced a score of 87,5precision for our method, and 77,5 for thefrequency measure.
For the subsequent 100terms, the discrepancy gets much higher(18%).Note that the precision score is in line with thatobtained for the Tourism corpus.
Notice also6 as a matter of fact, for our method we are notquite using the best value for b, as emarked later.that the values of a and b are the same in thetwo experiments.
In practice, we found thatthe threshold a=0,35  for the DomainRelevance is a generally ?good?
value, while alittle tuning may be necessary for the DomainConsensus.
In the Tourism domain, wherestatistical evidence is lower, a lower value forb produces higher precision (+1, 2%).Method ThresholdPrec Recall FDR+DC 0.35 0.49 17.18 17.61 17.39MI 0.00009 6.68 32.08 11.05Dice 0.034 7.48 23.90 11.39Freq 22 14.19 25.79 18.30Table 4 WSJ/WP experiment on Test1Method ThresholdPrec Recall FDR+DC 0.35 0.57 23.80 19.42 21.39MI 0.00009 6.42 47.57 11.30Dice 0.057 8.22 23.30 12.15Freq 22 14.19 39.81 20.92Table 5 WSJ/WP experiment on Test55 Conclusion and Future WorkThe text mining techniques  proposed in thispaper are meant to increase the productivity ofan Ontology Engineer during the timeconsuming task of populating a DomainOntology.
The work presented in this paper isin part well assessed, in part still underdevelopment.
We are designing newalgorithms and techniques to widen thespectrum of information that can be extractedfrom texts and from other on-line resources,such as dictionaries and lexical taxonomies(like EuroWordnet, a multilingual version ofWordnet).
An on-going extension of thisresearch is to detect similarity relations amongconcepts on the basis of contextual similarity.Similarity is one of the fields (see Figure 1) ina concept definition form that are currentlyfilled by humans.One admittedly weak part of the researchpresented in this paper is evaluation: we couldproduce a numerical evaluation of certainspecific subtasks (extraction of Named Entitiesand extraction of thesauric information), butwe did not evaluate the overall effect that ourtext mining tools produce on the Ontology.However, we are not aware of any  assessedOntology evaluation methodology in theliterature, besides (Farquhar et al 1996) wherean analysis of Ontology Server userdistribution and requests is presented.
A betterperformance indicator would have been thenumber of users that access Ontology Serveron a regular basis, but the authors mention thatregular users are only a small percentage7.
Asremarked in Subsection 3.1.2, an objectiveevaluation of an Ontology as a stand-aloneartifact is not feasible: the only  possiblesuccess indicator is the (subjective)acceptance/rejection rate of the OntologyEngineer when inspecting the automaticallyextracted information.
An Ontology  can onlybe evaluated in a context in which many usersof a community (e.g.
Tourism operators in ourapplication) access the Ontology  on a regularbasis and use this shared knowledge toincrease their ability to communicate, accessprominent information and documents,improve collaboration.
Though  a fieldevaluation of OntoTour is foreseen during thelast months of the project, we believe that wideaccessibility and  a long-lasting monitoring ofuser behaviors would provide the basis for asound evaluation of  the OntoTour system.7 The system described by Farquhar and his colleagues,however, is not a specific Ontology, but a tool, OntologyServer, to help publishing, editing and browsing anOntology.6 ReferencesE.
Agirre, O. Ausa, E. Havy and D. Martinez"Enriching very large ontologies using the WWW"ECAI2000 workshop on Ontology Learning,http://ol2000.aifb.uni-karlsruhe.de/, Berlin, August 2000R.J.
Brachman ?On the epistemological status ofsemantic networks?
; in "Associative Networks -Representation and use of Knowledge by Computers",N.V.Findler (Ed.
); Academic Press, New York, 1979.Basili R., M.T.
Pazienza, F.M.
Zanzotto (1998), ARobust Parser for Information Extraction, Proceedings ofthe European Conference on Artificial Intelligence (ECAI'98), Brighton (UK), August 1998.Bourigault, D. , C. Jacquemin and M.C.
L'Homme(1998), Eds.
Proceedings of the first Workshop onComputational Terminology, jointly held with COLING-98, Montreal, 1998A.
Cucchiarelli, D. Luzi and P. Velardi "Semantictagging of Unknown Proper Noun"s in Natural LanguageEngineering, December 1998.V.
Paliouras Cucchiarelli A., Karkaletsis G.Spyropolous C. Velardi P. "Automatic adaptation ofProper Noun Dictionaries through cooperation ofmachine learning and probabilistic methods" 23rd annualSIGIR, Athens, June 2000Basili, R., M.T.
Pazienza, P. Velardi,  An EmpyricalSymbolic Approach to Natural Language Processing,Artificial Intelligence, 85, 59-99,  August 1996R.
Basili, G. De Rossi, M.T.
Pazienza "InducingTerminology for Lexical Acquisition" Proc.
of theSecond Conference on Empirical Methods in NaturalLanaguge Processing, Providence, USA, August 1997R.
Basili, M.T.
Pazienza F. Zanzotto, "CustomizableModular Lexicalized Parsing Extraction" proc.
of  Int.Workshop on  Parsing Technology, Povo (Trento)February 2000B.
Daille "Study and Implementation of CombinedTechniques for Automatic Extraction of Terminology"Proc.
of  ACL94 Workshop "The Balancing Act:combining Symbolic and Statistical Approaches toLanguage" , New Mexico State University, July 1994.R.
Fano "Trasmission of Information, MIT press, 1961Farquhar, R. Fikes, W. Pratt, J.
Rice "CollaborativeOntology Construction for Information Integration"http://www-ksl-svc.stanford.edu:5915/doc/project-papers.htmlFETISH Groupware (2001)http://liss.uni.net/QuickPlace/trial/Main.nsf?OpenDatabaseJacquemin, C. (1997).
Variation terminologique.Memoire d'Habilitation Diriger des Recherces andInformatique Fondamentale.
Universit?
de Nantes,Nantes, France.Justenson J.S.
and S.M.
Katz (1995) Technicalterminology: some linguistic properties and an algorithmfor identification in text.
Natural language engineering,Vol.
1, Part 1, March 1995Klavans, J (2001).
Text Mining Techniques for FullyAutomatic Glossary Construction, Proceedings of theHTL2001 Conference, San Diego (CA), March, 2001.Miller A.
"WordNet: An on-line lexical resource"Special issue of the Journal of Lexicography, 3(4) 1990M.Missikoff, XF.
Wang, ?Consys ?
A Web System forCollaborative Ontology Building?, submitted, Dic.
2000.Missikoff M., Velardi P. and Fabriani P. (2001) ?TextMining Techniques to Automatically Enrich a DomainOntology?
to appear on Applied Intelligence, SpecialIssue on Text and Web Mining.A.
Maedche and S. Staab "Learning Ontologies for theSemantic Web" http://www.aifb.uni-karlsruhe.de/WBS/ama/publications.htmlPustejovsky  "The generative lexicon : a theory ofcomputational lexical semantics" MIT press 1993Smadja, F, K. McKeown and V. Hatzivassiloglou(1996) Translating Collocations for Bilingual Lexicons: astatistical approach, Computational Linguistics, 22:1SymOntos (2001), a Symbolic Ontology ManagementSystem.
http://www.symontos.orgA.
Wagner "Enriching a Lexical Semantic Net withSelectional Prefernces by means of Statistical CorpusAnalysis" ECAI2000 workshop on Ontology Learning,ibidemY.
Wilks, B. Slator and L. Guthrie "Electric Words:Dictionaries, Computers, and Meaning", MIT Press,Cambridge, MA, 1999
