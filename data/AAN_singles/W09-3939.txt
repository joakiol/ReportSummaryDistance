Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 276?285,Queen Mary University of London, September 2009. c?2009 Association for Computational LinguisticsComparison of Classification and Ranking Approachesto Pronominal Anaphora Resolution in Czech?Ngu.
y Giang Linh, Va?clav Nova?k, Zdene?k Z?abokrtsky?Charles University in PragueInstitute of Formal and Applied LinguisticsMalostranske?
na?me?st??
25, CZ-11800{linh,novak,zabokrtsky}.ufal.mff.cuni.czAbstractIn this paper we compare two Ma-chine Learning approaches to the taskof pronominal anaphora resolution: aconventional classification system basedon C5.0 decision trees, and a novelperceptron-based ranker.
We use coref-erence links annotated in the Prague De-pendency Treebank 2.0 for training andevaluation purposes.
The perceptron sys-tem achieves f-score 79.43% on recogniz-ing coreference of personal and possessivepronouns, which clearly outperforms theclassifier and which is the best result re-ported on this data set so far.1 IntroductionAnaphora Resolution (AR) is a well establishedtask in Natural Language Processing (Mitkov,2002).
Classification techniques (e.g., single can-didate model aimed at answering: ?Is there acoreference link between the anaphor and thisantecedent candidate, or not??)
are very oftenused for the task, e.g.
in Mccarthy and Lehnert(1995) and Soon et al (2001).
However, as ar-gued already in Yang et al (2003), better resultsare achieved when the candidates can compete ina pairwise fashion.
It can be explained by thefact that in this approach (called twin-candidatemodel), more information is available for the de-cision making.
If we proceed further along thisdirection, we come to the ranking approach de-scribed in Denis and Baldridge (2007), in whichthe entire candidate set is considered at once and?The work on this project was supported by thegrants MSM 0021620838, GAAV C?R 1ET101120503 and1ET201120505, MS?MT C?R LC536, and GAUK 4383/2009which leads to further significant shift in perfor-mance, more recently documented in Denis andBaldridge (2008).In this paper we deal with supervised ap-proaches to pronominal anaphora in Czech.1 Fortraining and evaluation purposes, we use corefer-ences links annotated in the Prague DependencyTreebank, (Jan Hajic?, et al, 2006).
We limit our-selves only to textual coreference (see Section 2)and to personal and possessive pronouns.
Wemake use of a rich set of features available thanksto the complex annotation scenario of the tree-bank.We experiment with two of the above men-tioned techniques for AR: a classifier and a ranker.The former is based on a top-down induction ofdecision trees (Quinlan, 1993).
The latter usesa simple scoring function whose optimal weightvector is estimated using perceptron learning in-spired by Collins (2002).
We try to provide bothimplementations with as similar input informationas possible in order to be able to compare theirperformance for the given task.Performance of the presented systems can becompared with several already published works,namely with a rule-based system described inKuc?ova?
and Z?abokrtsky?
(2005), some of the ?clas-sical?
algorithms implemented in Ne?mc??
?k (2006),a system based on decision trees (Ngu.
y, 2006),and a rule-based system evaluated in Ngu.
y andZ?abokrtsky?
(2007).
To illustrate the real complex-ity of the task, we also provide performance eval-uation of a baseline solution.1Currently one can see a growing interest in unsupervisedtechniques, e.g.
Charniak and Elsner (2009) and Ng (2008).However, we make only a very tiny step in this direction:we use a probabilistic feature based on collocation counts inlarge unannotated data (namely in the Czech National Cor-pus).276The most important result claimed in this pa-per is that, to the best of our knowledge, the pre-sented ranker system outperforms all the previ-ously published systems evaluated on the PDTdata.
Moreover, the performance of our ranker (f-score 79.43%) for Czech data is not far from theperformance of the state-of-the-art system for En-glish described in Denis and Baldridge (2008) (f-score for 3rd person pronouns 82.2 %).2A side product of this work lies in bringingempirical evidence ?
for a different language anddifferent data set ?
for the claim of Denis andBaldridge (2007) that the ranking approach ismore appropriate for the task of AR than the clas-sification approach.The paper is structured as follows.
The datawith manually annotated links we use are de-scribed in Section 2.
Section 3 outlines prepro-cessing the data for training and evaluation pur-poses.
The classifier-based and ranker-based sys-tems are described in Section 4 and Section 5 re-spectively.
Section 6 summarizes the achieved re-sults by evaluating both approaches using the testdata.
Conclusions and final remarks follow in Sec-tion 7.2 Coreference links in the PragueDependency Treebank 2.0The Prague Dependency Treebank 2.03 (PDT 2.0,Jan Hajic?, et al (2006)) is a large collection oflinguistically annotated data and documentation,based on the theoretical framework of FunctionalGenerative Description (FGD; introduced by Sgall(1967) and later elaborated, e.g.
in by Sgall et al(1986)).
The PDT 2.0 data are Czech newspapertexts selected from the Czech National Corpus4(CNC).The PDT 2.0 has a three-level structure.
On thelowest morphological level, a lemma and a posi-tional morphological tag are added to each token.The middle analytical level represents each sen-tence as a surface-syntactic dependency tree.
Onthe highest tectogrammatical level, each sentenceis represented as a complex deep-syntactic depen-2However, it should be noted that exact comparison is notpossible here, since the tasks are slightly different for thetwo languages, especially because of typological differencesbetween Czech and English (frequent pro-drop in Czech)and different information available in the underlying data re-source on the other hand (manually annotated morphologicaland syntactical information available for Czech).3http://ufal.mff.cuni.cz/pdt2.0/4http://ucnk.ff.cuni.cz/dency tree, see Mikulova?
and others (2005) for de-tails.
This level includes also annotation of coref-erential links.The PDT 2.0 contains 3,168 newspaper texts(49,431 sentences) annotated on the tectogram-matical level.
Coreference has been annotatedmanually in all this data.
Following the FGD,there are two types of coreference distinguished:grammatical coreference and textual coreference(Panevova?, 1991).
The main difference betweenthe two coreference types is that the antecedent ingrammatical coreference can be identified usinggrammatical rules and sentence syntactic struc-ture, whereas the antecedent in textual coreferencecan not.The further division of grammatical and textualcoreference is based on types of anaphors:Grammatical anaphors: relative pronouns, re-flexive pronouns, reciprocity pronouns, re-stored (surface-unexpressed) ?subjects?
ofinfinitive verbs below verbs of control,Textual anaphors: personal and possessive pro-nouns, demonstrative pronouns.The data in the PDT 2.0 are divided into threegroups: training set (80%), development test set(10%), and evaluation test set (10%).
The trainingand development test set can be freely exploited,while the evaluation test data should serve only forthe very final evaluation of developed tools.Table 1 shows the distribution of each anaphortype.
The total number of coreference links in thePDT 2.0 data is 45,174.5 Personal pronouns in-cluding those zero ones and possessive pronounsform 37.4% of all anaphors in the entire corpus(16,888 links).An example tectogrammatical tree with de-picted coreference links (arrows) is presented inFigure 1.
For the sake of simplicity, only threenode attributes are displayed below the nodes: tec-togrammatical lemma, functor, and semantic partof speech (tectogrammatical nodes themselves arecomplex data structures and around twenty at-tributes might be stored with them).Tectogrammatical lemma is a canonical wordform or an artificial value of a newly created node5In terms of the number of coreference links, PDT 2.0is one of the largest existing manually annotated resources.Another comparably large resource is BBN Pronoun Coref-erence and Entity Type Corpus (Weischedel and Brunstein,2005), which contains a stand-off annotation of coreferencelinks in the Penn Treebank texts.277Type/Count train dtest etestPersonal pron.
12,913 1,945 2,030Relative pron.
6,957 948 1,034Under-control pron.
6,598 874 907Reflexive pron.
3,381 452 571Demonstrative pron.
2,582 332 344Reciprocity pron.
882 110 122Other 320 35 42Total 34,983 4,909 5,282Table 1: Distribution of the different anaphortypes in the PDT 2.0.on the tectogrammatical level.
E.g.
the (artifi-cial) tectogrammatical lemma #PersPron standsfor personal (and possessive) pronouns, be theyexpressed on the surface (i.e., present in the orig-inal sentence) or restored during the annotationof the tectogrammatical tree structure (zero pro-nouns).Functor captures the deep-syntactic dependencyrelation between a node and its governor in thetectogrammatical tree.
According to FGD, func-tors are divided into actants (ACT ?
actor, PAT ?patient, ADDR ?
addressee, etc.)
and free modi-fiers (LOC ?
location, BEN ?
benefactor, RHEM?
rhematizer, TWHEN ?
temporal modifier, APP?
appurtenance, etc.
).Semantic parts of speech correspond to ba-sic onomasiological categories (substance, fea-ture, factor, event).
The main semantic POS dis-tinguished in PDT 2.0 are: semantic nouns, se-mantic adjectives, semantic adverbs and semanticverbs (for example, personal and possessive pro-nouns belong to semantic nouns).3 Training data preparationThe training phase of both presented AR systemscan be outlined as follows:1. detect nodes which are anaphors (Sec-tion 3.1),2. for each anaphor ai, collect the set of an-tecedent candidates Cand(ai) (Section 3.2),3. for each anaphor ai, divide the set ofcandidates into positive instances (true an-tecedents) and negative instances (Sec-tion 3.3),4. for each pair of an anaphor ai and an an-tecedent candidate cj ?
Cand(ai), computethe feature vector ?
(c, ai) (Section 3.4),5. given the anaphors, their sets of antecedentcandidates (with related feature vectors), andthe division into positive and negative candi-dates, train the system for identifying the trueantecedents among the candidates.Steps 1-4 can be seen as training data prepro-cessing, and are very similar for both systems.System-specific details are described in Section 4and Section 5 respectively.3.1 Anaphor selectionIn the presented work, only third person per-sonal (and possessive) pronouns are considered,6be they expressed on the surface or reconstructed.We treat as anaphors all tectogrammatical nodeswith lemma #PersPron and third person stored inthe gram/person grammateme.
More than 98 %of such nodes have their antecedents (in the senseof textual coreference) marked in the training data.Therefore we decided to rely only on this highlyprecise rule when detecting anaphors.7In our example tree, the node #PersPron rep-resenting his on the surface and the node #Per-sPron representing the zero personal pronoun hewill be recognized as anaphors.3.2 Candidate selectionIn both systems, the predicted antecedent of agiven anaphor ai is selected from an easy-to-compute set of antecedent candidates denoted asCand(ai).
We limit the set of candidates to se-mantic nouns which are located either in the samesentence before the anaphor, or in the preced-ing sentence.
Table 2 shows that if we disregardcataphoric and longer anaphoric links, we loosea chance for correct answer with only 6 % ofanaphors.6The reason is that antecedents of most other types ofanaphors annotated in PDT 2.0 can be detected ?
giventhe tree topology and basic node attributes ?
with precisionhigher than 90 %, as it was shown already in Kuc?ova?
andZ?abokrtsky?
(2005).
For instance, antecedents of reflexivepronouns are tree-nearest clause subjects in most cases, whileantecedents of relative pronouns are typically parents of therelative clause heads.7It is not surprising that no discourse status model (as usede.g.
in Denis and Baldridge (2008)) is practically neededhere, since we limit ourselves to personal pronouns, whichare almost always ?discourse-old?.278Antecedent location Percnt.Previous sentence 37 %Same sentence, preceding the anaphor 57 %Same sentence, following the anaphor 5 %Other 1 %Table 2: Location of antecedents with respect toanaphors in the training section of PDT 2.0.3.3 Generating positive and negativeinstancesIf the true antecedent of ai is not present inCand(ai), no training instance is generated.
If it ispresent, the sets of negative and positive instancesare generated based on the anaphor.
This prepro-cessing step differs for the two systems, becausethe classifier can be easily provided with morethan one positive instance per anaphor, whereasthe ranker can not.In the classification-based system, all candi-dates belonging to the coreferential chain aremarked as positive instances in the training data.The remaining candidates are marked as negativeinstances.In the ranking-based system, the coreferentialchain is followed from the anaphor to the nearestantecedent which itself is not an anaphor in gram-matical coreference.8 The first such node is put onthe top of the training rank list, as it should be pre-dicted as the winner (E.g., the nearest antecedentof the zero personal pronoun he in the exampletree is the relative pronoun who, however, it is agrammatical anaphor, so its antecedent Brien ischosen as the winner instead).
All remaining (neg-ative) candidates are added to the list, without anyspecial ordering.3.4 Feature extractionOur model makes use of a wide range of featuresthat are obtained not only from all three levels ofthe PDT 2.0 but also from the Czech National Cor-pus and the EuroWordNet.
Each training or test-ing instance is represented by a feature vector.
Thefeatures describe the anaphor, its antecedent can-didate and their relationship, as well as their con-8Grammatical anaphors are skipped because they usuallydo not provide sufficient information (e.g., reflexive pronounsprovide almost no cues at all).
The classification approachdoes not require such adaptation ?
it is more robust againstsuch lack of information as it treats the whole chain as posi-tive instances.texts.
All features are listed in Table 4 in the Ap-pendix.When designing the feature set on personal pro-nouns, we take into account the fact that Czechpersonal pronouns stand for persons, animals andthings, therefore they agree with their antecedentsin many attributes and functions.
Further we usethe knowledge from the Lappin and Leass?s al-gorithm (Lappin and Leass, 1994), the Mitkov?srobust, knowledge-poor approach (Mitkov, 2002),and the theory of topic-focus articulation (Kuc?ova?et al, 2005).
We want to take utmost advantage ofinformation from the antecedent?s and anaphor?snode on all three levels as well.Distance: Numeric features capturing the dis-tance between the anaphor and the candidate, mea-sured by the number of sentences, clauses, treenodes and candidates between them.Morphological agreement: Categorial featurescreated from the values of tectogrammatical gen-der and number9 and from selected morphologicalcategories from the positional tag10 of the anaphorand of the candidate.
In addition, there are featuresindicating the strict agreement between these pairsand features formed by concatenating the pair ofvalues of the given attribute in the two nodes (e.g.,masc neut).Agreement in dependency functions: Catego-rial features created from the values of tec-togrammatical functor and analytical functor (withsurface-syntactic values such as Sb, Pred, Obj) ofthe anaphor and of the candidate, their agreementand joint feature.
There are two more features in-dicating whether the candidate/anaphor is an ac-tant and whether the candidate/anaphor is a sub-ject on the tectogrammatical level.11Context: Categorial features describing the con-text of the anaphor and of the candidate:?
parent ?
tectogrammatical functor and the se-mantic POS of the effective parent12 of the9Sometimes gender and number are unknown, but we canidentify the gender and number of e.g.
relative or reflexivepronouns on the tectogrammatical level thanks to their an-tecedent.10A positional tag from the morphological level is a stringof 15 characters.
Every positions encodes one morphologicalcategory using one character.11A subject on the tectogrammatical level can be a nodewith the analytical functor Sb or with the tectogrammaticalfunctor Actor in a clause without a subject.12The ?true governor?
in terms of dependency relations.279anaphor and the candidate, their agreementand joint feature; a feature indicating theagreement of both parents?
tectogrammaticallemma and their joint feature; a joint featureof the pair of the tectogrammatical lemmaof the candidate and the effective parent?slemma of the anaphor; and a feature indicat-ing whether the candidate and the anaphor aresiblings.13?
coordination ?
a feature that indicateswhether the candidate is a member of a coor-dination and a feature indicating whether theanaphor is a possessive pronoun and is in thecoordination with the candidate?
collocation ?
a feature indicating whether thecandidate has appeared in the same colloca-tion as the anaphor within the text14 and afeature that indicates the collocation assumedfrom the Czech National Corpus.15?
boundness ?
features assigned on the ba-sis of contextual boundness (available in thetectogrammatical trees) {contextually bound,contrastively contextually bound, or contex-tually non-bound}16 for the anaphor and thecandidate; their agreement and joint feature.?
frequency ?
1 if the candidate is a denotativesemantic noun and occurs more than oncewithin the text; otherwise 0.Semantics: Semantically oriented feature thatindicates whether the candidate is a person namefor the present and a set of 63 binary ontologi-cal attributes obtained from the EuroWordNet.17These attributes determine the positive or negative13Both have the same effective parent.14If the anaphor?s effective parent is a verb and the can-didate is a denotative semantic noun and has appeared as achild of the same verb and has had the same functor as theanaphor.15The probability of the candidate being a subject preced-ing the verb, which is the effective parent of the anaphor.16Contextual boundness is a property of an expression (beit expressed or absent in the surface structure of the sentence)which determines whether the speaker (author) uses the ex-pression as given (for the recipient), i.e.
uniquely determinedby the context.17The Top Ontology used in EuroWordNet (EWN) con-tains the (structured) set of 63 basic semantic concepts likePlace, Time, Human, Group, Living, etc.
For the majority ofEnglish synsets (set of synonyms, the basic unit of EWN), theappropriate subset of these concepts are listed.
Using the In-ter Lingual Index that links the synsets of different languages,the set of relevant concepts can be found also for Czech lem-mas.relation between the candidate?s lemma and the se-mantic concepts.4 Classifier-based systemOur classification approach uses C5.0, a succes-sor of C4.5 (Quinlan, 1993), which is probably themost widely used program for inducing decisiontrees.
Decision trees are used in many AR sys-tems such as Aone and Bennett (1995), Mccarthyand Lehnert (1995), Soon et al (2001), and Ngand Cardie (2002).18Our classifier-based system takes as input a setof feature vectors as described in Section 3.4 andtheir classifications (1 ?
true antecedent, 0 ?
non-antecedent) and produces a decision tree that isfurther used for classifying new pairs of candidateand anaphor.The classifier antecedent selection algorithmworks as follows.
For each anaphor ai, featurevectors ?
(c, ai) are computed for all candidatesc ?
Cand(ai) and passed to the trained decisiontree.
The candidate classified as positive is re-turned as the predicted antecedent.
If there aremore candidates classified as positive, the nearestone is chosen.If no candidate is classified as positive, a sys-tem of handwritten fallback rules can be used.
Thefallback rules are the same rules as those used inthe baseline system in Section 6.2.5 Ranker-based systemIn the ranker-based AR system, every training ex-ample is a pair (ai, yi), where ai is the anaphoricexpression and yi is the true antecedent.
Usingthe candidate extraction function Cand, we aimto rank the candidates so that the true antecedentwould always be the first candidate on the list.
Theranking is modeled by a linear model of the fea-tures described in Section 3.4.
According to themodel, the antecedent y?i for an anaphoric expres-sion ai is found as:y?i = argmaxc?Cand(ai)?
(c, ai) ??
?wThe weights ?
?w of the linear model are trainedusing a modification of the averaged perceptron al-18Besides C5.0, we plan to use also other classifiers in thefuture (especially Support Vector Machine, which is oftenemployed in AR experiments, e.g.
by Ng (2005) and Yanget al (2006)) in order to study how the classifier choice in-fluences the AR system performance on our data and featuresets.280gorithm (Collins, 2002).
This is averaged percep-tron learning with a modified loss function adaptedto the ranking scenario.
The loss function is tai-lored to the task of correctly ranking the true an-tecedent, the ranking of other candidates is irrel-evant.
The algorithm (without averaging the pa-rameters) is listed as Algorithm 1.
Note that thetraining instances where yi /?
Cand(ai) were ex-cluded from the training.input : N training examples (ai, yi),number of iterations Tinit : ?
?w ??
?0 ;for t?
1 to T , i?
1 to N doy?i ?
argmaxc?Cand(ai) ?
(c, ai) ??
?w ;if y?i 6= yi then?
?w = ?
?w + ?
(yi, ai)?
?
(y?i, ai);endendoutput: weights ?
?wAlgorithm 1: Modified perceptron algorithmfor ranking.
?
is the feature extraction func-tion, ai is the anaphoric expression, yi is thetrue antecedent.Antecedent selection algorithm using a ranker:For each third person pronoun create a feature vec-tor from the pronoun and the semantic noun pre-ceding the pronoun and is in the same sentence orin the previous sentence.
Use the trained rankingfeatures weight model to get out the candidate?stotal weight.
The candidate with the highest fea-tures weight is identified as the antecedent.6 Experiments and evaluation6.1 Evaluation metricsFor the evaluation we use the standard metrics:19Precision = number of correctly predicted anaphoric third person pronounsnumber of all predicted third person pronounsRecall = number of correctly predicted anaphoric third person pronounsnumber of all anaphoric third person pronounsF-measure = 2?Precision?RecallPrecision+RecallWe consider an anaphoric third person pronounto be correctly predicted when we can success-19Using simple accuracy would not be adequate, as therecan be no link (or more than one) leading from an anaphorin the annotated data.
In other words, finding whether a pro-noun has an antecedent or not is a part of the task.
A deeperdiscussion about coreference resolution metrics can be foundin Luo (2005).fully indicate its antecedent, which can be any an-tecedent from the same coreferential chain as theanaphor.Both the AR systems were developed and testedon PDT 2.0 training and development test data.
Fi-nally they were tested on evaluation test data forthe final scoring, summarized in Section 6.3.6.2 Baseline systemWe have made some baseline rules for the task ofAR and tested them on the PDT 2.0 evaluation testdata.
Their results are reported in Table 3.
Base-line rules are following: For each third person pro-noun, consider all semantic nouns which precedethe pronoun and are not further than the previoussentence, and:?
select the nearest one as its antecedent(BASE 1),?
select the nearest one which is a clause sub-ject (BASE 2),?
select the nearest one which agrees in genderand number (BASE 3),?
select the nearest one which agrees in gen-der and number; if there is no such noun,choose the nearest clause subject; if no clausesubject was found, choose the nearest noun(BASE 3+2+1).6.3 Experimental results and discussionScores for all three systems (baseline, clasifierwith and without fallback, ranker) are given in Ta-ble 3.
Our baseline system based on the combina-tion of three rules (BASE 3+2+1) reports resultssuperior to the ones of the rule-based system de-scribed in Kuc?ova?
and Z?abokrtsky?
(2005).
Kuc?ova?and Z?abokrtsky?
proposed a set of filters for per-sonal pronominal anaphora resolution.
The list ofcandidates was built from the preceding and thesame sentence as the personal pronoun.
After ap-plying each filter, improbable candidates were cutoff.
If there was more than one candidate left atthe end, the nearest one to the anaphor was cho-sen as its antecedent.
The reported final successrate was 60.4 % (counted simply as the number ofcorrectly predicted links divided by the number ofpronoun anaphors in the test data section).An interesting point of the classifier-based sys-tem lies in the comparison with the rule-based281Rule P R FBASE 1 17.82% 18.00% 17.90%BASE 2 41.69% 42.06% 41.88%BASE 3 59.00% 59.50% 59.24%BASE 3+2+1 62.55% 63.03% 62.79%CLASS 69.9% 70.44% 70.17%CLASS+3+2+1 76.02% 76.60% 76.30%RANK 79.13% 79.74% 79.43%Table 3: Precision (P), Recall (R) and F-measure(F) results for the presented AR systems.system of Ngu.
y and Z?abokrtsky?
(2007).
With-out the rule-based fallback (CLASS), the clas-sifier falls behind the Ngu.
y and Z?abokrtsky?
?ssystem (74.2%), while including the fallback(CLASS+3+2+1) it gives better results.Overall, the ranker-based system (RANK) sig-nificantly outperforms all other AR systems forCzech with the f-score of 79.43%.
Comparingwith the model for third person pronouns of Denisand Baldridge (2008), which reports the f-score of82.2%, our ranker is not so far behind.
It is im-portant to say that our system relies on manuallyannotated information20 and we solve the task ofanaphora resolution for third person pronouns onthe tectogrammatical level of the PDT 2.0.
Thatmeans these pronouns are not only those expressedon the surface, but also artificially added (recon-structed) into the structure according to the princi-ples of FGD.7 ConclusionsIn this paper we report two systems for AR inCzech: the classifier-based system and the ranker-based system.
The latter system reaches f-score79.43% on the Prague Dependency Treebank testdata and significantly outperforms all previouslypublished results.
Our results support the hypoth-esis that ranking approaches are more appropriatefor the AR task than classification approaches.ReferencesChinatsu Aone and Scott William Bennett.
1995.Evaluating automated and manual acquisition of20In the near future, we plan to re-run the experiments us-ing sentence analyses created by automatic tools (all neededtools are available in the TectoMT software framework(Z?abokrtsky?
et al, 2008)) instead of manually created analy-ses, in order to examine the sensitivity of the AR system toannotation quality.anaphora resolution strategies.
In Proceedings of the33rd annual meeting on Association for Computa-tional Linguistics, pages 122?129, Morristown, NJ,USA.
Association for Computational Linguistics.Anto?nio Branco, Tony McEnery, Ruslan Mitkov, andFa?tima Silva, editors.
2007.
Proceedings of the 6thDiscourse Anaphora and Anaphor Resolution Col-loquium (DAARC 2007), Lagos (Algarve), Portugal.CLUP-Center for Linguistics of the University ofOporto.Eugene Charniak and Micha Elsner.
2009.
EM worksfor pronoun anaphora resolution.
In Proceedings ofthe 12th Conference of the European Chapter of theACL (EACL 2009), pages 148?156, Athens, Greece,March.
Association for Computational Linguistics.Michael Collins.
2002.
Discriminative Training Meth-ods for Hidden Markov Models: Theory and Exper-iments with Perceptron Algorithms.
In Proceedingsof EMNLP, volume 10, pages 1?8.Pascal Denis and Jason Baldridge.
2007.
A rankingapproach to pronoun resolution.
In Proceedings ofthe 20th International Joint Conference on ArtificialIntelligence (IJCAI2007), pages 1588?1593, Hyder-abad, India, January 6?12.Pascal Denis and Jason Baldridge.
2008.
Special-ized models and ranking for coreference resolu-tion.
In Proceedings of the 2008 Conference onEmpirical Methods in Natural Language Processing(EMNLP2008), pages 660?669, Honolulu, Hawaii,USA, October 25?27.Jan Hajic?, et al 2006.
Prague Dependency Treebank2.0.
CD-ROM, Linguistic Data Consortium, LDCCatalog No.
: LDC2006T01, Philadelphia.Lucie Kuc?ova?
and Zdene?k Z?abokrtsky?.
2005.Anaphora in Czech: Large Data and Experimentswith Automatic Anaphora.
LNCS/Lecture Notes inArtificial Intelligence/Proceedings of Text, Speechand Dialogue, 3658:93?98.Lucie Kuc?ova?, Kater?ina Vesela?, Eva Hajic?ova?, andJir???
Havelka.
2005.
Topic-focus articulation andanaphoric relations: A corpus based probe.
In KlausHeusinger and Carla Umbach, editors, Proceedingsof Discourse Domains and Information Structureworkshop, pages 37?46, Edinburgh, Scotland, UK,Aug.
8-12.Shalom Lappin and Herbert J. Leass.
1994.
?an algo-rithm for pronominal anaphora resolution?.
Compu-tational Linguistics, 20(4):535?561.Xiaoqiang Luo.
2005.
On coreference resolution per-formance metrics.
In HLT ?05: Proceedings ofthe conference on Human Language Technology andEmpirical Methods in Natural Language Process-ing, pages 25?32, Morristown, NJ, USA.
Associa-tion for Computational Linguistics.282J Mccarthy and Wendy G. Lehnert.
1995.
Using de-cision trees for coreference resolution.
In In Pro-ceedings of the Fourteenth International Joint Con-ference on Artificial Intelligence, pages 1050?1055.Marie Mikulova?
et al 2005.
Anotace na tektogra-maticke?
rovine?
Praz?ske?ho za?vislostn?
?ho korpusu.Anota?torska?
pr??
?ruc?ka (t-layer annotation guide-lines).
Technical Report TR-2005-28, U?FAL MFFUK, Prague, Prague.Ruslan Mitkov.
2002.
Anaphora Resolution.
Long-man, London.Va?clav Ne?mc???k.
2006.
Anaphora Resolution.
Mas-ter?s thesis, Faculty of Informatics, Masaryk Univer-sity.Vincent Ng and Claire Cardie.
2002.
Improving ma-chine learning approaches to coreference resolution.In ACL ?02: Proceedings of the 40th Annual Meet-ing on Association for Computational Linguistics,pages 104?111, Morristown, NJ, USA.
Associationfor Computational Linguistics.Vincent Ng.
2005.
Supervised ranking for pro-noun resolution: Some recent improvements.
InManuela M. Veloso and Subbarao Kambhampati,editors, AAAI, pages 1081?1086.
AAAI Press / TheMIT Press.Vincent Ng.
2008.
Unsupervised models for corefer-ence resolution.
In Proceedings of the 2008 Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP2008), pages 640?649, Hon-olulu, Hawaii, USA.Giang Linh Ngu.
y and Zdene?k Z?abokrtsky?.
2007.Rule-based approach to pronominal anaphora reso-lution applied on the prague dependency treebank2.0 data.
In Branco et al (Branco et al, 2007), pages77?81.Giang Linh Ngu.
y.
2006.
Proposal of a Set of Rulesfor Anaphora Resolution in Czech.
Master?s thesis,Faculty of Mathematics and Physics, Charles Uni-versity.Jarmila Panevova?.
1991.
Koreference gramaticka?
nebotextova??
In Etudes de linguistique romane et slave.Krakow.J.
Ross Quinlan.
1993.
C4.5: programs for machinelearning.
Morgan Kaufmann Publishers Inc., SanFrancisco, CA, USA.Petr Sgall, Eva Hajic?ova?, and Jarmila Panevova?.
1986.The Meaning of the Sentence in Its Semantic andPragmatic Aspects.
D. Reidel Publishing Company,Dordrecht.Petr Sgall.
1967.
Generativn??
popis jazyka a c?eska?deklinace.
Academia, Prague, Czech Republic.Wee Meng Soon, Hwee Tou Ng, and DanielChung Yong Lim.
2001.
A machine learning ap-proach to coreference resolution of noun phrases.Comput.
Linguist., 27(4):521?544.Zdene?k Z?abokrtsky?, Jan Pta?c?ek, and Petr Pajas.
2008.TectoMT: Highly Modular MT System with Tec-togrammatics Used as Transfer Layer.
In Proceed-ings of the 3rd Workshop on Statistical MachineTranslation, ACL.Ralph Weischedel and Ada Brunstein.
2005.
BBNPronoun Coreference and Entity Type Corpus.
CD-ROM, Linguistic Data Consortium, LDC CatalogNo.
: LDC2005T33, Philadelphia.Xiaofeng Yang, Guodong Zhou, Jian Su, andChew Lim Tan.
2003.
Coreference resolution us-ing competition learning approach.
In ACL ?03:Proceedings of the 41st Annual Meeting on Asso-ciation for Computational Linguistics, pages 176?183, Morristown, NJ, USA.
Association for Compu-tational Linguistics.Xiaofeng Yang, Jian Su, and Chew Lim Tan.
2006.Kernel-based pronoun resolution with structuredsyntactic knowledge.
In Proceedings of the 21stInternational Conference on Computational Lin-guistics and 44th Annual Meeting of the Asso-ciation for Computational Linguistics (COLING-ACL2006), pages 41?48, Sydney, Australia, July17?21.283A Appendixt-ln95049-047-p3s1rootO - ORSTRn.denotBrien - BRIENACTn.denotkter?
- WHOACTn.pron.indefLouganis - LOUGANISPATn.denottr novat - TO TRAINRSTRvrok - YEARTHLn.denotdeset - TENRSTRadj.quant.def#PersPron - HISACTn.pron.def.personemocn?n - INJURYPATn.denot.negvdt - TO KNOWPREDvale - BUT enuncADVScoapzavzat_se - TO TIE SOMEONE'S SELFPREDv#PersPron - (HE)ACTn.pron.def.persml?en - SECRECYPATn.denot.neg.Figure 1: Simplified tectogrammatical tree representing the sentence O?Brien, ktery?
Louganise tre?novaldeset let, o jeho onemocne?n??
ve?de?l, ale zava?zal se mlc?en??m.
(Lit.
: O?Brien, who Louganis trained forten years, about his injury knew, but (he) tied himself to secrecy.)
Note two coreferential chains {Brien,who, (he)} and {Louganis, his}.284Distancesent dist sentence distance between c and aiclause dist clause distance between c and ainode dist tree node distance between c and aicand ord mention distance between c and aiMorphological Agreementgender t-gender of c and ai, agreement, jointnumber t-number of c and ai, agreement, jointapos m-POS of c and ai, agreement, jointasubpos detailed POS of c and ai, agreement, jointagen m-gender of c and ai, agreement, jointanum m-number of c and ai, agreement, jointacase m-case of c and ai, agreement, jointapossgen m-possessor?s gender of c and ai, agreement, jointapossnum m-possessor?s number of c and ai, agreement, jointapers m-person of c and ai, agreement, jointFunctional Agreementafun a-functor of c and ai, agreement, jointfun t-functor of c and ai, agreement, jointact c/ai is an actant, agreementsubj c/ai is a subject, agreementContextpar fun t-functor of the parent of c and ai, agreement, jointpar pos t-POS of the parent of c and ai, agreement, jointpar lemma agreement between the parent?s lemma of c and ai, jointclem aparlem joint between the lemma of c and the parent?s lemma of aic coord c is a member of a coordinationapp coord c and ai are in coordination & ai is a possessive pronounsibl c and ai are siblingscoll c and ai have the same collocationcnk coll c and ai have the same CNC collocationtfa contextual boundness of c and ai, agreement, jointc freq c is a frequent wordSemanticscand pers c is a person namecand ewn semantic position of c?s lemma within the EuroWordNet Top OntologyTable 4: Features used by the perceptron-based model285
