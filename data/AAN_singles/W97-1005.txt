A Statistical Decision Making Method: A Case Study onPrepositional Phrase Attachment*Mehmet  Kayaalp, Ted Pedersen and Rebecca BruceDepartment of Computer Science & EngineeringSouthern Methodist UniversityDallas, TX 75275-0122{kayaalp, pedersen, rbruce}@seas, smu.
eduAbstractStatistical classification methods usuallyrely on a single best model to make ac-curate predictions.
Such a model aims tomaximize accuracy by balancing precisionand recall.
The Model Switching methodas presented in this paper performs withhigher predictive accuracy and 100% recallby using a set of decomposable models in-stead of a single one.The implemented system, MS1, is testedon a case study, predicting PrepositionalPhrase Attachment (PPA).
The resultsshow that iV is more accurate than otherstatistical techniques that select singlemodels for classification and competitivewith other successful NLP approaches inPPA disambiguation.
The Model Switch-ing method may be preferable to othermethods because of its generality (i.e., widerange of applicability), and its competitiveaccuracy in prediction.
It may also be usedas an analytical tool to investigate the na-ture of the domain and the characteristicsof the data with the help of generated mod-els.1 IntroductionDecision problems are classically defined as problemswhose answers fall in either of two classes: Yes andNo (Garey and Johnson, 1979).
Optimization prob-lems are another class of problems that maximizeor minimize some value; however, they can be castas decision problems as well (Cormen et al, 1990).Classification problems incorporate the characteris-tics of both: A classification problem is a decision*This research was supported inpart by the Office ofNaval Research under grant number N00014-95-1-0776problem, in which a decision is made (a class is se-lected) that maximizes a utility function (yon Neu-mann and Morgenstern, 1953).
The Model Switch-ing method as proposed in this paper can be usedwith any utility function (decision criterion) for anydecision problem with categorical data that can berepresented as a tuple (C, F1, F2, ..., Fn) of a classvariable C and some feature variables F{1 .... }.In the following sections, we will describe thePrepositional Phrase Attachment (PPA) problemand various approaches to solving it.
After dis-cussing the statistical concepts used in this work, wewill introduce the concept of Model Switching, whyit is needed, how it works, and our experience on thePPA problem with Model Switching.
Comparisonswith earlier works on corpus-based PPA predictionand conclusions will follow.2 PPA ProblemResolving the PPA problem is a common problem inany NLP system that deals with syntactic parsingor text understanding.
The Naive Bayes classifierand leading machine learning systems, such as C4.5(Quinlan, 1993), CN2 (Clark and Niblett, 1989) andPEBLS (Cost and Sahberg, 1993), fail to provide pre-diction with competitive accuracy rates on this prob-lem (see Table 4 on page 40).
A sentence can be soambiguous that it may not be possible to determinethe correct attachment without extra contextual in-formation.
(Ratnaparkhi et al, 1994) reported thathuman experts could reach an accuracy of 93%, ifcases were given as whole sentences out of context.The PPA problem is illustrated by the followingexample:I described the problem on the paper.
(1)This is an ambiguous sentence, which can be inter-preted two different ways, depending on the site ofPPA.
The prepositional phrase (PP) in the abovesentence is "on the paper."
If it is attached toKayaalp, Pedersen ~ Bruce 33 Statistical PP AttachmentMehmet Kayaalp, Ted Pedersen and Rebecca Bruce (1997) A Statistical Decis ion Making Method: A CaseStudy on Prepositional Phrase Attachment.
In T.M.
Ellison (ed.)
CoNLL97: Computational Natural LanguageLearning, ACL pp 33-42.
(~) 1997 Association for Computational Linguisticsthe (object) noun "problem," then the interpreta-tion would be equal to (2); on the other hand, if itis attached to the verb "describe," then it would beinterpreted as (3).I described the problem that was on the paper(2)On the paper, I described the problem.
(3)In this paper, we address only the type of PPA prob-lem illustrated above and don't consider other lessfrequent PPA problems.
For the linguistic details ofthe problem, the reader can refer to (Hirst, 1987).We use the PPA data created by (Brill and Resnik,1994) and (Ratnaparkhi et al, 1994) to objectivelycompare the performances of the systems.
Both datawere extracted from the Penn Treebank Wall StreetJournal (WSJ) Corpus (Marcus et al, 1993).
In or-der to distinguish these data from each other, wecall the former one BSzR data and the latter oneIBM data.
Both PPA data were formatted in tu-ples with five variables (4), which denote the class(i.e., the PPA attachment site) and the features (i.e.,verb, object noun, preposition and PP noun) in therespective order?
Values of these variables for theabove example (1) are illustrated in (5), where(A, B, C, D, E) (4)(verb lnoun , "describe", problem", "on", "paper"X5)For representation convenience, we can map the val-ues of these variables to positive integers as in Ta-ble 1.
Then, the examples, (2) and (3) can be con-\[ Leve ls  I\[ A \[ B \] C \[ D \[ E \]noun  descr ibeverb  jo inbeimprovesh ipp ingdev?1ops1238182384538465162516366"25prob lem on  paperboard  as  d i rec tordean  o f  N .V .Hatch  p lus  endsuccess  theychunks  shotsKoch  bar:opt ion  pot(A t i corprebateTable 1: Substitution of variable values for associ-ated integer labels at the Levels column.
The num-ber of levels of five variables are 2, 3845, 5162, 81and 6625.verted to tuples (6) and (7), respectively.
(A=I ,B=I ,C=I ,D=I ,E=I )  (6)(A=2, B=I ,C=I ,D=I ,E=I )  (7)Kayaalp, Pedersen ~ Bruce 34Using this convention, the PPA data can be rep-resented in a contingency table (Table 2) with fivedimensions, where each dimension is dedicated toa variable.
The size of a contingency table is de-termined by the cardinality of values (a.k.a.
levels)of these variables (8); for the IBM data, there are2.13 ?
1013 cells in the table (9).
Each cell in thetable corresponds to a unique combination of thevariable values and all combinations are representedin the table.CBAE DI I22 i211 21 2 1 2L,10100 0 0 00\]010102 .
.
.
5162. .
.
1 .
- .
3845?
.
.
1 .
.
.
1 2? '
'  0 .
.
.?
.
?
0 .
.
?.
- -  0 .
.
.
1 \] 0I0\ [00 00\[0Table 2: The PPA data can be represented in a 2 ?3845 x 5162 x 81 ?
6625 contingency table, where eachcell contains frequency with which the corresponding5-tuple (i.e., a unique PPA instance) occurs in thedata.
(IAI =2, \]BI =3845, ICI =5162, IDI--81, IEI =6625)(8)2 ?
3845 ?
5162 ?
81 ?
6625 = 2.13 x 1013 (9)Considering that there are 27,937 PPA observationsin the training and test data together, a search spaceof more than 21 trillion possible distinct cases (rep-resented in the cells of contingency table) indicatesthat the data is extremely sparse.To solve PPA problem, NLP researchers designeddomain specific classifier systems.
Those systemscan be categorized in two classes:1.
Rule based systems (Boggess et al, 1991), (Brilland Resnik, 1994)2.
Statistical and information theoretic ap-proaches (Hindle and Rooth, 1993), (Ratna-parkhi et al, 1994),(Collins and Brooks, 1995),(Franz, 1996)Using lexical collocations to determine PPA withstatistical techniques was first proposed by (Hindleand Rooth, 1993).
They suggested a score calledLexical Association to predict PPA.
It is a log likeli-hood ratio of probability estimates of two PPA sites.The probability of attachment was based on thefrequencies of the 2-tuples (B, D), and (C, D), whereB, C, D stand for the variables: verb, object nounStatistical PP Attachmentand preposition, respectively.
While (Hindle andRooth, 1993) stated that this approach was not suc-cessful in estimating PPA using small 2-tuple fre-quencies, which comprised a major portion of thePPA data, the accuracy reported was 79.7%, whichis a substantial improvement over the lower boundof 65% (10):tions used in the function).
If all fail, the assign-ment is noun attachment, since 52% of the time theattachment site on the training data was noun.I~(A\]B, C, D, E) =I (A ,B ,C ,D)+ I (A ,B ,D ,E)+ \ ] (A ,C ,D,E)\](B, C, D) + I(B, D, E) + \](C, D, E) (12)f(A = 1) f (A = 2) "1max f(A=~)+~=2)' f(A--'~)~-?~--2)(10)The lower bound for the B&R data is 63% (Brill andResnik, 1994) and for the IBM data is 52% (Ratna-parkhi et al, 1994).
(Ratnaparkhi et al, 1994) was the first to con-sidered the full four feature set defined in (4).
Theapproach made use of a maximum entropy model(Berger et al, 1996) formulated from frequency in-formation for various combinations of the observedfeatures.
The combinations that reduced the en-tropy most, were chosen.
The accuracy of PPA clas-sification using this approach was 77.7% on the IBMdata.
(For performance comparison of various ap-proaches on available data, please refer to Table 4on page 40.
)(Brill and Resnik, 1994) suggested a rule basedapproach where the antecedent ofeach rule specifiesvalues for the feature variables in (4).
A typical rulemight be as follows:features(B =12, C, D = 3, E) -+ ppa(A = 1) (11)471 such inference rules are found useful and orderedto reduce the error-rate to a minimum.
They re-ported an accuracy of 80.8% on the data that wealso use.
They also duplicated the experiment of(Hindle and Rooth, 1993), which scored around 5%less than the rule-based approach.
(Collins and Brooks, 1995) proposed a specificheuristic computation to predict PPAs.
The ideaoriginated from the back-off model (Katz, 1987).
Ifthe combination of feature values observed for a testinstance is also observed in the training set, thenthat test instance is classified with the most fre-quent PPA site for those feature values in the train-ing set.
Otherwise, probability estimates for the twoPPA sites are obtained from functions(12)-(14), viaa process similar to model switching.
If the high-est complexity formulation, (12), cannot be usedto classify a test instance (i.e., the required featurevalue combinations are not observed in the trainingdata), then the decision process is switched to thenext function, where functions are ranked based oncomplexity (i.e., the arity of the frequency distribu-ff(A\]B,C,D,E) = \ ] (A,B,D)  T I (A ,C,D)  T J (A,D,E)f l3 ~I (B,D)  + f(O,D) + f(D, E) " "I~(AID) -- \](A,D) (14)f(D)If a higher order function cannot classify a test in-stance, then the decision process is switched to thenext function.
If all fail, the guess is the noun at-tachment, since 52% of the time the attachment siteon the training data was noun.While the probability estimates in (14) are maxi-mum likelihood estimates (MLEs), the estimates in(12) and (13) are heuristic formulations (i.e., notMLEs).
The rationale behind these formulae are:1. a decision made by utilizing more feature vari-ables should be favorable over the others,2.
the preposition feature D is essential; thus, it isbetter to keep it in all n-grams of the decisionfunctions.They used IBM data, which we also use, and re-ported an accuracy of 84.1%.
(Franz, 1996) proposed a new feature set, whichprovided a more compact representation f the PPAdata.
Using a hierarchical log-linear model con-taining only second order interactions, he achieveda classification performance comparable to that of(Hindle and Rooth, 1993).
He also designed anotherexperiment with a less common PPA problem withthree attachment sites.3 Decomposab le  Mode lsIn this paper, PPA is cast as a problem in supervisedlearning, where a probabilistic lassifier is inducedfrom tagged training data in the form of 5-tuples(6) and (7).
The task is to predict the value of thetag A given the values of the feature variables Bthrough E.Probabilistic models (e.g., decomposable models)specify joint distribution functions that assign prob-ability values to every unique combination of themodel variables, where the sum of those values isequal to 1.
We adopt a Maximum Likelihood Es-timation (MLE) approach.
Given a decomposablemodel, MLE yields the most probable tag to eachKayaalp, Pedersen ~ Bruce 35 Statistical PP Attachmenttest data instance represented by a 4-tuple of fea-ture values.Decomposable models belong to the class of graph-ical models, 1where variables are either interdepen-dent or conditionally independent of one another.
2All graphical models have a graphical representationsuch that each variable in the model is mapped to avertex in the graph, and there is an undirected edgebetween each pair of vertices corresponding to a pairof interdependent variables.
While edges representinteractions between pairs of variables, i.e., secondorder interactions, cliques 3 with n vertices representn th order interactions.
Any two vertices that arenot directly connected by an edge are conditionallyindependent given the values of the vertices on thepath that connects them.Decomposable models are graphical models thatare isomorphic to chordal graphs.
In chordal graphs,there is no cycle of four or more without a chord,where a cord is an edge joining two non-consecutivevertices on the cycle.
The elementary components ofa chordal graph are its cliques; therefore, a chordalgraph can be represented as a set of its cliques.The chordM graph in Figure 1 represents a decom-E BAFigure 1: The decomposable modelABD.ABE.ACE.
Edges of the separators,AB and AE (corresponding to ABD N ABE andABE N ACE), are drawn thicker.
A separator is aset of vertices whose removal disconnects the graph.posable model, which we can mnemonically denoteas (15).ABD.ABE.ACE (15)In this model, variables A, B, and D are stochas-tically dependent since they form a clique.
Simi-lar statements can be made for the other cliques inthe model.
The interactions between AB and AE,1 Graphical models are a subset of log-linear models.2B and C are conditionally independent given A ifP(BIC, A ) = P(BIA ).3A clique is a complete (sub)graph, where every ver-tex pair is connected with an edge.denoted by the corresponding edges AB, AE areobserved in two out of the three cliques which in-dicates their relative importance in describing thisdistribution.
The variable A is observed in all threecliques of the model because we consider only thosecliques that contain the class variable A in definingthe model.
There are three edges missing, BC, CD,and DE, which distinguish this model from the sat-urated model ABCDE.
These missing edges denotethree conditional independence r lations:1.
The variables D and E are conditionally inde-pendent given AB (intersection of two cliques,ABD N ABE).2.
The variables B and C are conditionally inde-pendent given AE (ABE n ACE).3.
The variables C and D are conditionally inde-pendent given A (ABD N ACE).This approach to classifying PPA is the first to makeuse of conditional independence in modeling the dis-tribution of feature variables.A well known example of a decomposable modelis the Naive Bayes model in which all feature vari-ables are conditionally independent given the valueof classification variable.
For the PPA problem, theNaive Bayes model is AB.AC.AD.AE.Decomposable models are important because theyare those graphical models that express the jointprobability distributions of the variables in terms ofthe product of their marginal distributions, whereeach factor of the product corresponds to a cliqueor a separator in the graphical representation f themodel.
Because the joint distribution functions ofdecomposable models have such closed-form expres-sions, the parameters as Maximum Likelihood Esti-mates (MLEs) can be calculated irectly from thetraining data without the need for an iterative fit-ting procedure; hence, those MLEs are also calleddirect estimates (Bishop et al, i975).3.1 Max imum L ike l ihood Es t imat ionLet the PPA variables, IAI = I, IBI = J , .
.
.
,  IEI = Mresulting in an I ?
J x K x L x M contingency table(e.g., Table 2).
Let the count in each cell (i.e., thefrequency with which the corresponding 5-tuple isobserved in the training data) be denotes as nijktrn.When all variables are considered to be interdepen-dent (i.e., the saturated ecomposable model) themaximum likelihood estimate of the probability ofany 5-tuple is equal to the count in the correspond-ing cell noklm divided by the total count N, which isequal to 24,840 for the IBM training data (Table 2).15(A= i ,B= I ,C= i ,D= I ,E= i) =Kayaalp, Pedersen ~4 Bruce 36 Statistical PP Attachment911111 --  r t l l l l l  2N - 24840 (16)Estimates of the marginal probability distribu-tions can be calculated in a similar fashion.
If weare interested in the probability of observing a verbattachment when "describe" is the noun, and "on"is the preposition (i.e., A = 1,B = 1, D = 1), re-gardless of the values of the other variables, it canbe calculated as in (17) and (18).K Mni l+i+ = E E nnkl,~ (17)k=l  m=lnn+l+ (18) 9(A=I,B=i,D=I) = p l l+ l+ - NLet c denote the specific cell coordinates (e.g.,11111 in (16)), and let the model .A4 = {C: U C2 U?
.
.
CO }, where Cd denotes a clique in the graph rep-resentation of A//, then the direct estimates (MLEs)are computed as in (19).D ^ ~n(c) Hd=l p(cc,,)- -  D ^ Hd=2 p(es )(19)where the factors in the numerator are the marginalprobabilities for c in the cliques {Cd}, whose unionrepresents the model.
The intersections of cliques{Cd} yield separators {Sa} and the marginal prob-abilities for c in {Sd} are factors in the denomi-nator (Lauritzen, 1996).
For the saturated model,{,.~} = {}, and the MLE is most straightforward:= 9c (20)mllln = 911111 (21)MLEs of the model (15) can be computed as in(22), and using this model, MLEs of the examples(2) and (3) can be calculated as in (23) and (24),respectively.=~2tl: l l  I =m211119(A, B, D) 9(A, B, E) 9(A, C, Et22)9(A, B) 9(A, E)91:+1+ 9n++l  P:+l+l (23)911+++91+++1921+I+ 921++1 P2+i+i (24)92i+++ 92+++lAs seen in this example, decomposable modelsprovide us not only a very powerful representationmedium but also computational efficiency in esti-mating parameters.4 Model SwitchingLet E1 and E2 be equal to MLEs in (23) and (24).There are four cases in determining the class basedon these equations.E i=0AE2=0 -4 A=nu l l  (25)El >0AE i=E2 -4 A=nu l l  (26)El > $2 -+ A = 1 (27)E1 < E2 "-')" A = 2 (28)In cases (25) and (26), there is no classification andno recall for this test instance with this model.
In(27) and (28), the classifications are noun and verbattachments, respectively.For the PPA data with five variables, there areonly 110 decomposable models, corresponding to allchordal graphs of order five or less, where everyclique of the order two and higher contains the vertexthat represents the class variable.
Since this num-ber is not large, we considered all of these models forclassification.
4 Let al test instances be composed inthe set T and letT= % u%u.
.
.uT~ (29)where 7~ is a set of test instances that can be classi-fied with model A,4i for (1 < i < m = 110); i.e., theoutcomes of ?n(AI7~, .h4~) is either in (27) or in (28).These estimates may not always be correct, un-less the information in features are sufficient and theclassification model is perfect; therefore, each set ofestimates associated with ~ and A//i has a precisionvalue:precision(M lT) - I clT = Tc  u Tw(30)(31)where 7~c and "/~w are sets of correctly and wronglyclassified test instances in set 7~.
If we have an or-dered list of models (.A41, A42,.
.
.
,  .A4m) as a certifi-cate, whereprecision(.MilT~ ) > precision(A4~+: l'/~+l) (32)we could use the certificate to maximize the overallclassification accuracy.Since the first model .N'/1 is associated with thehighest precision value, the probability that a test in-stance is correctly classified with .A41 is higher than4 For problems with larger variable set additional tech-niques (Edwards and HavrAnek, 1987) or (Madigan andRaftery, 1994) are necessary to reduce the model space.Kayaalp, Pedersen ~4 Bruce 37 Statistical PP Attachmentthat probability for any other model; therefore, .M1should be used to classify all possible test instances.T = 7 -0 = "\]~ t.9 7 -1 , where ~ VI T 1 = {} (33)After ~ is classified, the process is repeated forthe remaining test instances 7-1 with M2 that is themost "precise" model remaining in the model set.This cycle can be generalized as7-/- 1 = 7~ t3 7 -i, where "/~ N 7 --/= { }, and T = T O(34)and will be iterated k times, where T k = {}.
Theoverall classification accuracy then be calculated askaccuracy(.A41,.M2,.. .Mk lT - ) -  i=1 (35)' 17-1The question remains now, how we can find thelist of models (.M1, .M2, .
.
.
,  .Mk , .
.
.
,  .Mm) orderedby precision.
Since precision is a measure that can beacquired after classifying all test instances, how canwe order models based on precision before testing?One approach is to use the error rates of the mod-els acquired through cross-validation.
The techniquewe use here is called leave-one-out cross-validation(Lachenbruch and Mickey, 1968).
Let the trainingdata set be TO, where every data instance Pi E T~,i = 1 ,2 , .
.
.
, r  and r = I~ I.
When amode lA / / j  isapplied to a data instance Pi, in this technique, alltraining instances except Pi (i.e., T?
- pi) are usedto compute the direct estimate for pi.
This processis repeated for every data instance (i.e., r times).This technique is applied to all training instancesfor every model.
The precision score of each modelis collected, and based on those scores, the modelsare ordered.If k (the number of models used to classify allPPA instances) is small, then it is expected thatafter each iteration the test instances remaining tobe classified would be decreased significantly; hence,the characteristics of T i-1 and T i might differ sub-stantially and ordering the remaining models basedon T i, rather than "T 0, might increase the overallaccuracy.A second experiment is designed to apply this re-cursive strategy to order the models via the samecross-validation process.
First, the most precisemodel for the entire (training) data is identified.Then, the data instances that are classified with thefirst model are excluded from the original data set,as in (33).
Within the remaining data instances, allmodels in {.A42, M3, .
.
.
,  Adrn} are searched for thecurrent most precise model.
This model selectionModels \[\[ Cor Inc Prc Acc RTCABCDEABDE.ACDACDE.ABDABDEACDE.ABEABCDABD.ACD.ADEACDEABD.ACDABE.ACD.ACEABDACDABE.ACE.ADEACE.ADE.ABADEADAD.AEABC.AEAC.ADA150 17 90 89.8 2930145 16 90 89.9 2769192 10 95 91.9 256746 11 81 90.8 25105 0 100 90.9 2505293 42 87 89.6 2170441 73 86 88.3 165651 11 82 88.0 1594263 50 84 87.3 12813 0 100 87.4 1278401 107 79 85.5 770296 63 82 85.1 4110 0 0 85.1 4116 1 86 85.1 404156 47 77 84.5 201141 56 72 83.7 40 0 0 83.7 41 1 50 83.7 20 0 0 83.7 22 0 100 83.7 0Table 3: Classification with Multiple Models.
Cor(Inc): Number of correct (incorrect) classifications.Prc: Precision xl00.
Acc: Accuracy xl00.
RTC:Remaining Test Cases.cycle is iterated exhaustively (34) until all data in-stances are classified.
The models selected for theIBM data are shown in Table 3.The MLE algorithm is a table look up, whereeach table contains marginal values for a clique ofvariables as defined in the graph representation.
Ifthose values could be stored in a memory array, thetime complexity of MLE could be O(1); however, thenumber of values is huge, thus we have to store eachset of clique marginals on disk, and currently the ac-cess to the data is through sequential file access witha t ime complexity O(n), where n is the number oftraining instances.
MLEs need to be computed form models and for n training instances.
During eachrecursive step a considerable part of the training in-stances are classified (around 5%); thus we may rep-resent the process asg = rnn ~ (36)19T(N)  : T (~N)  + g (37)O(N log N) (38)Therefore, the average time complexity for thecurrent program is O(mn 2 log(mn2)), but throughmemoization, 5 the overhead of the recursion will bedrastically reduced in newer versions of the program.5A standard dynamic programming technique thatstores computed information in a table, which is lookedup when that information is needed next time.Kayaalp, Pedersen 8/Bruce 38 Statistical PP AttachmentThe software of MS1 is developed in Perl and isfreely available for research purposes only.
Inter-ested parties may contact he first author.5 DiscussionIn some of the earlier works on PPA there are as-pects of the model switching framework.
For exam-ple, (Brill and Resnik, 1994) ordered rules to min-imize the error-rate in PPA classification.
Each ofthese inference rules may be considered a decisionfunction in a decision list.
Whenever a higher or-der rule fails, the control switches to the next ruleto classify that test instance.
(Collins and Brooks,1995) ordered heuristic decision functions by com-plexity (arity) and classified test instances with themost complex applicable function.Non-recursive Model Switching consists of twophases:1.
Ordering available models (e.g., via leave-one-out cross-validation),2.
Applying the model on top of the list to the testdata; whenever that model does not yield anyestimate, the system switches to the next modelon the list.The first phase corresponds to the learning phaseof learning systems; whereas, the.
last phase can beconceptualized as a decision list (Rivest, 1987) and(Kohavi and Benson, 1993), where the control is con-ditioned by the availability of a direct estimate givena model with a test instance.
6In the recursive version of the Model Switching,however, the model list is dynamically changed sincethe above phases are within a loop, where in each it-eration all instances of the available data are consid-ered for classification and those which are classifiedare excluded from the data for the next iteration.The base case of recursion is reached when all in-stances are classified.Although in this work we suggest a precision-driven model ordering scheme, the Model Switchingmethod enables one to use any other utility func-tion such as accuracy or F-measure.
There are otherutility functions that need not be acquired throughcross-validation, but rather can be collected by an-alyzing the entire training set as in statistical sig-nificance analysis (e.g., G 2, Pearson's X2), or infor-mation criteria (e,g., Akaike or Bayes InformationCriteria etc.
), which can be used as well.An advantage of this method is that we make useof a complex and powerful set of models.
Much of6This relevance of decision lists was indicated by MikeCollins in our personal discussions.the earlier PPA research was confined to singlecliquemodels, such as ABCD or AB, which are a smallsubset of decomposable models.5.1 Quant i ta t ive  Ana lys i sStatistical (decomposable) model selection tech-niques were first applied to NLP problems by (Bruceand Wiebe, 1994).
Those model selection techniquesaim to find a single best model but they alone do notperform as well as Model Switching, since even themost accurate decomposable model, AB.AD, had aclassification accuracy of 77%.Unlike Model Switching, the methods uggested inearlier PPA works are usually tailored to the PPAproblem, thus it is hard to transfer them to anotherdomain.
On the other hand, neither Naive Bayesnor the conventional machine learning tools, such asCN2, C4.5 and PEBLS, perform as well.
These foursymbolic classifiers are well known and are diverseto some extent: Naive Bayes is a simple Bayesianapproach, CN2 is based on rule induction, C4.5 isbased on decision trees, and PEBLS is based on near-est neighbor method.
A performance comparison ofvarious classifiers with MS1 is given on Table 4.
Thecomparison between the proposed systems solvingPPA ambiguity and general machine learning sys-tems was always neglected in earlier articles on PPAproblem .7The results of the first five classifiers presentedin Table 4 and the performance of B&R classifieron IBM data were determined as part of this study,while the other four results are benchmarks quotedfrom the authors cited above.
Those benchmarkswere produced via single trials, hence we performedsingle trial tests as well.
CN2, C4.5 and PEBLSperformances were based on their default settings.The only exception involved CN2 where an ordered-induced-rule-list is used instead of an unordered one,since the ordered rules yield 99.7% accuracy ver-sus 90.8% accuracy of unordered rules on the IBMtraining data.
After the test, we checked the ac-curacy rates of unordered induced rules, which areunexpectedly better than the ordered ones: 78% onB~R data and 76.2% on IBM data.
Naive Bayes'recall values are very low: 74% for IBM data and78% for B&R data; therefore, the remaining testinstances are classified as the most frequent class.Notice that this is also a type of model switch-ing, where the forms of the models and the modellist M = (AB.AC.AD.AE, A) are predetermined asdone by (Collins.and Brooks, 1995).7(Ratnaparkhi et al, 1994) reported a decision treeexperiment using mutual information with 77.7% accu-racy.Kayaalp, Pedersen ~ Bruce 39 Statistical PP AttachmentI Classifiers \]Data Bayes CN2 C4.5 PEBLS MS1 I B~R IBM C&BIB&R 74.6 77.4 78.4 76.4 81.2 I 80.8 n.a.
81.9 IIBM 73.0 70.7 79.6 76.9 83.7 81.4 77.7 84.1Table 4: Performances of various classifiers on available data.
CK:B:(Collins and Brooks, 1995); B~R:(data/classifier) by (Srill and Resnik, 1994); IBM: (data/classifier) by (Ratnaparkhi et al, 1994); Bayes:Naive Bayes with defaults, i.e., A/\[ = (AB.AC.AD.AE, A).The performance differences between MS1 andC&B, the Back-off Model by (Collins and Brooks,1995), are 0.4% for IBM data and 0.7% for B~Rdata.
With only two test trials and without anydeviation measure these differences cannot be con-sidered significant, especially in this case, where theperformances of the classifiers fluctuate 2-3% (e.g.,C~B accuracy deviates 2.2%) within two very sim-ilar data sets, B~R and IBM data.
As one anony-mous reviewer indicated, the 0.7% accuracy differ-ence on B&R data needs to be evaluated cautiouslydue to the size of the B~R test data, which con-tains only 500 test instances; whereas the IBM datacontains 3097 test instances.5.2 Qualitative AnalysisThe approach of (Collins and Brooks, 1995) is sim-pler than MS1, since it doesn't consist of any learn-ing part; the models were selected and grouped byits designers and ordered heuristically, which meansclassification requires prior knowledge specific to thedomain.
With the human expertise involved, the listof models is simpler and shorter than the list foundby MS1 and it is heuristically grouped and weighted(forming a kind of mixture model), which is not thecase in MS1 at this point in time; nevertheless, MS1reached to a performance l vel that is competitive tothe other system supported with human expertise.MS1 uses neither any lexical information or heuris-tics with respect o the PPA problem; hence, it canbe adopted and applied to any other classificationproblem involving categorical data.
MS1 is a ma-chine learning alternative to the system developedby (Collins and Brooks, 1995), and the ordering ofthe models that it produces may provide insight intothe data that could aid in developing a custom mix-ture model.Unlike the other techniques, MS1 generates anordered list of models where each model providesa graphical representation of the interdependenciesamong variables.
The user can identify relevant rela-tions and see which features play the most significantroles; thus, one can not only predict he outcome ofa classification problem with high accuracy but alsoKayaalp, Pedersen ~ Bruce 40gain insight into the nature of the domain and thedata under investigation.
For example, MS1 iden-tified the fact that the preposition feature (variableD) is so important hat all test instances (exceptthe last four) were predicted by models that havethis variable.
This was one of the most importantheuristic steps in formulating the approach used by(Collins and Brooks, 1995).
Further analysis of themodel ist by linguists may yield other observations,such as, in the first 75% of the predictions, 97% ofthe test instances were identified using models con-taining the interaction ABD with a precision of 86%,and in the rest of the predictions this interaction wasnot useful.
Similar model lists can be generated onvarious corpora and their comparisons may revealdifferences in those corpora.MS1 and the systems by (Ratnaparkhi et al,1994) and (Brill and Resnik, 1994) consist of atraining phase, where they form certain structures(such as rules, models, etc.)
that are used with theavailable statistics to classify test instances; there-fore, these systems can be considered true learningsystems.
On the other hand in systems designedby (Hindle and Rooth, 1993), (Collins and Brooks,1995), and (Franz, 1996), the forms of models werepredetermined by their designers, as in the NaiveBayes approach.5.3 ScalabilityThe structure of the underlying PPA data (4) castsa difficult problem to learning system.
When thenumber of observations grows, the levels of features(except that of the preposition, which is limitedby grammar) grow proportionally.
This effect wasfirst identified by (Zipf, 1935).
Due to this effectthe number of cells in contingency table representa-tions explodes, which corresponds to an exponentialgrowth in the search space.Three general machine learning systems citedabove require very large main memory capacity torun the PPA data, which brings the scalability intoquestion.
MSi's implementation is based on largedata and limited main memory assumptions, hencecomputation time has been traded with memory re-Statistical PP Attachmentquirement.
The Model Switching approach is scal-able in computation time and memory: While thedata size grows, the leave-one-out cross-validationtechnique may be switched to a simpler v-fold cross-validation technique, which is "stable" and prefer-able for larger data size (Breiman et al, 1984).There is always, a much simpler choice: Rankingmodels through statistical significance analysis orthrough information criteria, whose cost is O(I.M I).One problem encountered in applying ModelSwitching to other domains is that the numberof decomposable models grows exponentially withthe number of possible variables.
The method of(Edwards and Havr?nek, 1987) or (Madigan andRaftery, 1994) for selecting a good subset of modelsfor the data resolves this last concern regarding scal-ability.
Using these techniques, the Model Switch-ing method may be applied to other NLP problemswith much larger size of feature variables.
ModelSwitching method is currently being applied to wordsense disambiguation which is cast with eight fea-tures.
The preliminary results are very encourag-ing, and provide evidence for the robustness of themethodology.6 .A .cknowledgmentsWe gratefully acknowledge the support provided forthis research by the Office of Naval Research undergrant number N00014-95-1-0776.
We would also liketo thank Mike Collins for his constructive comments.Re ferencesAdam L. Berger, Vincent J. Della Pietra, andStephen A. Della Pietra.
1996.
A maximumentropy approach to natural anguage process-ing.
Computational Linguistics, 22(1):39-68.Yvonee M. M. Bishop, Stephen E. Fienberg, andPaul W. Holland.
1975.
Discrete Multivari-ate Analysis: Theory and Practice.
The MITPress, Cambridge, MA.Lois Boggess, Rajeev Agarwal, and Ron Davis.
1991.Disambiguation ofprepositional phrases in au-tomatically labeled technical text.
In Proceed-ing of the Ninth National Conference on Arti-ficial Intelligence, pages 155-159, Cambridge,MA.
AAAI, MIT Press.Leo Breiman, Jerome H. Friedman, Richard A. O1-shen, and Charles J.
Stone.
1984.
Classifica-tion and Regression Trees.
Wadsworth, Bel-mont, CA.Eric Brill and Philip Resnik.
1994.
A rule, basedapproach to prepositional phrase attachmentdisambiguation.
In Proceedings of the Fif-teenth International Conference on Computa-tional Linguistics (COLING-9.t).Rebecca Bruce and Janyce Wiebe.
1994.
Word-sensedisambiguation using decomposable models.In Proceedings of the 32nd Annual Meeting ofthe Association for Computational Linguistics(ACL-9~).Peter Clark and Tim Niblett.
1989.
The CN2 induc-tion algorithm.
Machine Learning, 3:261-283.Michael Collins and James Brooks.
1995.
Preposi-tional phrase attachment through a backed-offmodel.
In Proceedings of the Third Workshopon Very Large Corpora.Thomas H. Cormen, Charles E. Leiserson, andRonald L. Rivest.
1990.
Introduction to Al-gorithms.
MIT Press, Cambridge, MA.Scott Cost and Steven Salzberg.
1993.
A weightednearest neighbor algorithm for learning withsymbolic features.
Machine Learning, 10:57-78.David Edwards and Thom~ Havr?nek.
1987.
Afast model selection procedure for large fami-lies of models.
Journal of American StatisticalAssociation, 82(397):205-213.Alexander Franz.
1996.
Learning PP attach-ment from corpus statistics.
In StefanWermter, Ellen Riloff, and Gabriele Scheler,editors, Connectionist, Statistical, and Sym-bolic Approaches to Learning for Natural Lan-guage Processing, volume 1040 of LectureNotes in Artificial Intelligence, pages 188-202.Springer-Verlag, New York, NY.Michael R. Garey and David S. Johnson.
1979.
Com-puters and Intractability.
W. H. Freeman andCompany, New York, NY.Donald Hindle and Mats Rooth.
1993.
Structuralambiguity and lexical relations.
ComputationalLinguistics, 19(1):103-120.Graeme Hirst.
1987.
Semantic interpretation and theresolution of ambiguity.
Cambridge UniversityPress, New York, NY.Slava M. Katz.
1987.
Estimation of probabili-ties from data for the language model com-ponent of a speech recognizer.
In TransactionsKayaalp, Pedersen 8J Bruce 41 Statistical PP Attachmenton Acoustics, Speech, and Signal Processing,pages 400-401.
IEEE.Ron Kohavi and Scott Benson.
1993.
Research ondecision lists.
Machine Learning, 13:131-134.Peter A. Lachenbruch and M. Ray Mickey.
1968.Estimation of error rates in discriminant anal-ysis.
Technometrics, 10(1):1-11, February.Steffen L. Lauritzen.
1996.
Graphical Models.
Ox-ford University Press, New York, NY.David Madigan and Adrian E. Raftery.
1994.
Modelselection and accounting for model uncertaintyin graphical models using Occam's window.Journal of American Statistical Association,89(428):1535-1546.Mitchell P. Marcus, Beatrice Santorini, andMary Ann Marcinkiewicz.
1993.
Buildinga large annotated corpus of English: ThePenn Treebank.
Computational Linguistics,19(2):313-330.John Ross Quinlan.
1993.
C~.5: Programs for Ma-chine Learning.
Morgan Kaufman Publishers,San Mateo, CA.Adwait Ratnaparkhi, Jeff Reynar, and S~dimRoukos.
1994.
A maximum entropy model forprepositional phrase attachment.
In Proceed-ings of Human Language Technology Work-shop, pages 250-255, Plainsboro, NJ.
ARPA.Ronald L. Rivest.
1987.
Learning decision lists.
Ma-chine Learning, 2:229-246.John von Neumann and Oskar Morgenstern.
1953.Theory of Games and Economic Behavior.Princeton University Press, Princeton, NJ.George Kingsley Zipf.
1935.
The Psycho-biologyof Language.
Houghton Mifflin Company,Boston, MA.Kayaalp, Pedersen 8J Bruce 42 Statistical PP Attachment
