NAACL-HLT Workshop on the Induction of Linguistic Structure, pages 81?83,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsTwo baselines for unsupervised dependency parsing?Anders S?gaardCenter for Language TechnologyUniversity of CopenhagenDK-2300 Copenhagen Ssoegaard@hum.ku.dkAbstractResults in unsupervised dependency parsingare typically compared to branching baselinesand the DMV-EM parser of Klein and Man-ning (2004).
State-of-the-art results are nowwell beyond these baselines.
This paper de-scribes two simple, heuristic baselines that aremuch harder to beat: a simple, heuristic al-gorithm recently presented in S?gaard (2012)and a heuristic application of the universalrules presented in Naseem et al (2010).
Ourfirst baseline (RANK) outperforms existingbaselines, including PR-DVM (Gillenwater etal., 2010), while relying only on raw text, butall submitted systems in the Pascal GrammarInduction Challenge score better.
Our secondbaseline (RULES), however, outperforms sev-eral submitted systems.1 RANK: a simple heuristic baselineOur first baseline RANK is a simple heuristic base-line that does not rely on part of speech.
It only as-sumes raw text.
The intuition behind it is that a de-pendency structure encodes something related to therelatively salience of words in a sentence (S?gaard,2012).
It constructs a word graph of the words ina sentence and applies a random walk algorithm torank the words by salience.
The word ranking isthen converted into a dependency tree using a simpleheuristic algorithm.The graph over the words in the input sentenceis constructed by adding directed edges between the?word nodes.
The edges are not weighted, but mul-tiple edges between nodes will make transitions be-tween them more likely.The edge template was validated on developmentdata from the English Penn-III treebank (Marcus etal., 1993) and first presented in S?gaard (2012):?
Short edges.
To favor short dependencies, we addlinks between all words and their neighbors.
Thismakes probability mass flow from central words to theirneighboring words.?
Function words.
We use a keyword extraction algorithmwithout stop word lists to extract function or non-contentwords.
The algorithm is a crude simplification ofTextRank (Mihalcea and Tarau, 2004) that does not relyon linguistic resources, so that we can easily apply itto low-resource languages.
Since we do not use stopword lists, highly ranked words will typically be functionwords.
For the 50-most highly ranked words, we addadditional links from their neighboring words.
This willadd additional probability mass to the function words.This is relevant to capture structures such as prepositionalphrases where the function words take content words ascomplements.?
Morphological inequality.
If two words wi, wj havedifferent prefixes or suffixes, i.e.
the first two or last threeletters, we add an edge between them.Given the constructed graph we rank the nodesusing the algorithm in Page and Brin (1998), alsoknown as PageRank.
The input to the PageRank al-gorithm is any directed graph G = ?E,V ?
and theoutput is an assignment PR : V ?
R of a score,also referred to as PageRank, to each node in thegraph, reflecting the probability of ending up in thatnode in a random walk.81from/to The finger-pointing has already begun .The 0 3 2 2 3 2finger-pointing 3 0 5 2 3 2has 2 4 0 3 3 2already 2 2 5 0 3 2begun 2 3 3 3 0 3.
2 2 3 2 4 0PR(%) 13.4 17.4 21.2 15.1 19.3 13.6Figure 1: Graph, pagerank (PR) and predicted depen-dency structure for sentence 7 in PTB-III Sect.
23.The words are now ranked by their PageRank(Figure 1), and from the word ranking we derivea dependency tree.
The derivation is very simple:We introduce a store of potential heads, initializedas a singleton containing the word with the high-est PageRank (which is attached to the artificial rootnote).
Each word is now assigned a syntactic headtaken from all the words that were already assignedheads.
Of these words, we simply select the clos-est possible head.
In case of ties, we select the headwith the highest PageRank.2 RULES: a simple rule-based baselineOur second baseline is even simpler than our firstone, but makes use of input part of speech.
In par-ticular it builds on the idea that unsupervised pars-ing can be informed by universal dependency rules(Naseem et al, 2010).
We reformulate the univer-sal dependency rules used in Naseem et al (2010)in terms of the universal tags provided in the sharedtask (Figure 2), but unlike them, we do not engagein grammar induction.
Instead we simply present astraight-forward heuristic application of the univer-sal dependency rules:RULES finds the head of each word w by findingthe nearest word w?
such that POS(w?
)?POS(w) isa universal dependency rule.
In case of ties, we se-lect the left-most head in the candidate set.
The headof the sentence is said to be the left-most verb.
Notethat we are not guaranteed to find a head satisfyinga universal dependency rule.
In fact when the de-pendent has part of speech AUX or ?.?
we will neverfind such a head.
If no head is found, we attach thedependent to the artificial root node.Note that like RANK, RULES would give usVERB?
?VERB NOUN??ADJVERB?
?NOUN NOUN??DETVERB?
?ADV NOUN??NOUNVERB?
?ADP NOUN??NUMVERB??CONJVERB??DETVERB??NUMVERB??ADJVERB??XADP?
?NOUN ADJ??ADVADP?
?ADVFigure 2: Universal dependency rules (Naseem et al,2010) wrt.
universal tags.RANK RULES DMV win bestArabic 0.340 0.465 0.274 0.541 0.573Basque 0.255 0.137 0.321 0.440 0.459Czech 0.329 0.409 0.276 0.488 0.491Danish 0.424 0.451 0.395 0.502 0.502Dutch 0.313 0.405 0.284 0.437 0.492En-Childes 0.481 0.519 0.498 0.538 0.594En-WSJ 0.328 0.425 0.335 0.555 0.560Portuguese 0.371 0.546 0.240 0.418 0.652Slovene 0.284 0.377 0.242 0.580 0.580Swedish 0.375 0.551 0.290 0.573 0.573the correct analysis of the sentence in Figure 1(excl.
punctuation).
Surprisingly, RULES turns outto be a very competitive baseline.3 ResultsShared task results were evaluated by the organiz-ers in terms of directed accuracy (DA), also knownas unlabeled attachment score, undirected accuracy(UA) and NED (Schwartz et al, 2011), both forshort and full length sentences.
We will focus onDA for full length sentences here, arguable the mostwidely accepted metric.
Table 1 presents results forall 10 datasets, with DMV based on fine-grained na-tive POS (which performs best on average comparedto DMV-CPOS and DMV-UPOS),1 and Tu, stan-dard as the winning system (?win?).
The ?best?
resultcherry-picks the best system for each dataset.The first thing we note is that our two baselines1In a way it would be fairer to exclude native POS and CPOSinformation, since native tag sets reflect language-specific syn-tax.
Moreover, the validity of relying on manually labeled inputis questionable.82are much better than the usual structural baselines.The macro-averages for the branching baselines are0.252 (left) and 0.295 (right), but if we allow our-selves to cherry-pick the best branching baseline foreach language the macro-average of that baselineis 0.352.
This corresponds to the macro-averageof RANK which is 0.350.
The macro-average ofRULES is 0.429.Interestingly, RANK achieves better full lengthsentence DA than at least one of the submitted sys-tems for each language, except English.
The sameholds for full length sentence NED.
RULES is aneven stronger baseline.Most interestingly the two baselines are signifi-cantly better on average than all the baselines pro-posed by the organizers, including DMV-EM andDMV-PR.
This is surprising in itself, since our twobaselines are completely heuristic and require notraining.
It seems none of the baseline systems nec-essarily learn anything apart from simple, univer-sal properties of linguistic trees that we could easilyhave spelled out in the first place.More than half of the submitted systems are worsethan RULES in terms of DA, but three systems alsooutperform our baselines by some margin (Bisk,Blunsom and Tu).
Since our baselines are better thanharmonic initialization, the obvious next step wouldbe to try to initialize EM-based unsupervised parsersby the structures predicted by our baselines.ReferencesJennifer Gillenwater, Kuzman Ganchev, Joao Graca, Fer-nando Pereira, and Ben Taskar.
2010.
Sparsity in de-pendency grammar induction.
In ACL.Mitchell Marcus, Mary Marcinkiewicz, and BeatriceSantorini.
1993.
Building a large annotated corpusof English: the Penn Treebank.
Computational Lin-guistics, 19(2):313?330.Rada Mihalcea and Paul Tarau.
2004.
Textrank: bringingorder into texts.
In EMNLP.Tahira Naseem, Harr Chen, Regina Barzilay, and MarkJohnson.
2010.
Using universal linguistic knowledgeto guide grammar induction.
In EMNLP.Larry Page and Sergey Brin.
1998.
The anatomy of alarge-scale hypertextual web search engine.
In Inter-national Web Conference.Roy Schwartz, , Omri Abend, Roi Reichart, and Ari Rap-poport.
2011.
Neutralizing linguistically problematicannotations in unsupervised dependency parsing eval-uation.
In ACL.Anders S?gaard.
2012.
Unsupervised dependency pars-ing without training.
Natural Language Engineering,18(1):187?203.83
