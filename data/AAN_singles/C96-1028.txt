Cross-Serial  Dependenc ies  Are Not  Hard to ProcessCarl Vogel Ulrike Hahn Holly BraniganInstitute for Computational Department of Experimental Centre for Cognitive ScienceLinguisticsUniversity of StuttgartAzenbergstr.
12D-70174 StuttgartGermanyPsychologyUniversity of OxfordSouth Parks RoadOxford OX1 3UDEnglandUniversity of Edinburgh2 Buccleuch PlaceEdinburgh EH8 9LWScotland{vogel,holly,ueh}~cogsci.ed.ac.ukAbstractCross-serial dependencies in Dutdl  andSwiss-German are the only known extra-context fi'ee natural language syntacticphenonmna.
Psycholinguistie videncesuggests cross-serial orderings tend to beeasier to process t, lmn nested cons\[ ,ruc-|iions.
We, argue thai; |;tie expressivity re-quirements of the corresponding formallanguages do not actually entail |;hat pro-cessing reduplication languages requirethe worst-ease time complexity for lmi-guages of the same expressive class.
Wedist;inguish between context-free repre-sentability and contc, xt-free processing.We show that for any language with upto context fl'ee expressive power, pro-cessing cross-scriM dependencies can beaccommodated without atfect;ing tmrsingcomplexil,y.
This is relal,ed to other workon reduplication phenonmna in formalmodels of computation.1 In t roduct ionThe cross-serial dependencies in Dutch and Swiss-German are the only known constituent-h;vel syn-tacl;ic phenomena whMl make natural languagesnot representable in con|,ext fi'ee languages (Gaz-dar, 198,5; Gazdar mid Pullum, 1985).
Psycholin-guistic s~,udy of the cross-scriM dependencies re-veals thai; tim cross-serial orderings tend to bepreferred over nested constructions (Bach eL al.,1986)} Bach et al argue Dora this dmt tim push-down stack cannot be the universal basis of thehuman parsing mechanism (since the pushdownautomaton is essentially a context free recognil, iondevice whidt cannot represent cross-serial depen-dencies).
Stabler (1994), on the other hand, con-siders t;tm findings of Bach el; al.
(1986) as evi-dence for finite hunian sentence processing capac-ity.
In l, his paper, we dist, inguish between conl,ext-fi'ee representability and context-fl'ee processing.1Nested constructions are a quintessentially con-text free phenomenon.We show that for any language with up to con-text fi'ee expressive power, processin9 cross-serialdependencies can be accommodated without af-fecting parsing complexity.
While this does essen-tially inflme the language with indexed expressiv-ity, it does so while allowing us to rc~ain eollt,extfree (or even regular) parsing eonqJexity.
Ess~'n-tially, il; is possible t,o carve oul; a cross-sectionof l,he expressivity hierarchy with dm dcaircd pro-cessing complexity.
The result is based oil the sim-ple observation that t,he cross-serial dependenciesm'e idealized by the string duplication language(whereas the nested dependencies m'e idealized bythe palindrome language), and that it is t, rivial toprovide a context-free (or regular) language parsefor half of the st;ring, followed by a Lest: of equal-il,y for the remaining half of the string.
This isconsis(,ent; with tindings that cross-serial depen-dencies are not; hard to process, but qualilies theinterpret;ation that Bach el; al.
give to their re-suits and l,he implications on the human parsingniechanism, hi parl;icular, this suggests thai, withml addil, ional operation |tie pushdown stack canbe adequate for processing human lasiguages.
It,also suggests an explanation for die finding thatDutch cross-serial dependencies arc easier to pro-cess than Gernlan nested dependencies.
We out-line fllrliher consequences of our proposal in termsof patterns of disfhiencies that are likely to occurin languages that admit cross-serial dependenciesand propose a strate.gy R~r emtfirical investigation.2 Prel iminariesTo calibrate our discussion, we quickly review t,h~,salient terminology from formal langm~ge theoryand the current undersl,anding of dm import; tornatural anguage.s.2.1 Termino logyLet 12i denote the hierarchy of languages gener-ated by the corresponding hierarchy of gramnmrs(according to dm usuN hierarchy (Hopcroft andUlhnan, 1979)).
Thus,/20 denot;es the (:lass of lan-guages general,ed by type 0 grammars.
They areehm'aeterized by unrestricted grammar produc-157tion rules.
?1 is the class of languages generatedby context sensitive granlmars--the sole restric-tion on production rules in this type of grammaris that the right hand side (RHS) of each rule is atleast as long as the left hand side (LHS).
?1.5 de-notes the class of languages generated by indexedgrammars.
Gazdar (1985) provides the most per-spicuous notation for the restricted forms thatproduction rules may take in such grammars: 21.
A\[...\] --+ W\[...\]2.
A\[...\] ---+ B\[i, ...\]3.
A\[i,...\] ----+ W\[...\]Indexed grammars incorporate a notion of stack-ing; rules of the form in (2) describe push opera-tions, and those of the form in (3) involve pops.Rules of the form (1) are copy operations.
Theelipses indicate that the remainder of the stackis passed on from the LHS to each nonterminal(and only the nonterminals) on the RHS.
?2 is theclass of context free languages generated by gram-mars whose productions are restricted such thatthe LHS of each is a single nonterminal symbol,and each RHS is a sequence of terminals and non-terminals.
Finally, the regular languages, ?3 arethose produced by regular grammars, character-ized by rules that have a single nonterminal sym-bol on the LHS and on the RHS, either a terminalsymbol or a terminal and a single nonterminal.These classes of languages can be arranged intoa hierarchy based on proper containment rela-tions among them: ?3 C ?2 C ?1.5 C ?1 C?0 (?0 is the least restrictive, the most expres-sive).
Aho (1968) shows the existence of lan-guages that are a proper subset of the indexedlanguages and a proper superset of the contextfree.
Joshi et al (1989) conjecture that thereis actually a convergence in expressive poweramong the 'mildly context sensitive' (MCS) lan-guages, but other work points out exceptions (Sav-itch, 1989; Vogel and Erjavec, 1994).
Since thereduplication languages (Savitch, 1989) are cen-tral to the point of this paper we define them--the languages homomorphic to the set of strings{ww\[w 6 {a,b}*}.
The string duplication lan-guages are not context free, although they areclosely related to the string reversal anguages({wwR\[w 6 {a, b}*}, where the R indicates the re-versal operator) which are context free.
The twolanguages induce different dependency relation-ships which is best described as nesting in the con-text free case and cross-serial in the indexed case:a b b a  a b a b. I - - - -?4- .
.
.
.
.
?
I. I - - - -?2The bracketed material indicates a stack of in-dices; W denotes a sequence of elements of terminalsand nonterminals; A, B denote nonterminals.An important property of the each of the lan-guage classes is that it is closed under bottl in-tersection with regular languages (e.g., the inter-section of a context free language and a regularlanguage is no more expressive than a contextfree language) and homomorphism (e.g., an or-der preserving map of each symbol in a languageto a single element (possibly a string) of a contextfree language implies that the first language is alsocontext free).
It is convenient to refer to languageswith homomorphismSwwR{WWRIwto E {a, b}*} ai~d{wwIw 6 {a,b}*} as and ww, respectively.Corresponding to expressivity class and the as-sociated model of computation is the complex-ity of recognition for each class.
Table 1 givesan informal ranking of the language classes withtheir corresponding worst case recognition com-plexity on the standard model of computation.Thus, given a context free grammar for ww R anda string of length n, then in the worst case it willtake an amount of time proportional to the cubeof the length of the string to determine whetherthe string is in ww R (and identify its structure).While the expressivity hierarchy is useful for dif-ferentiating classes of lmlguages in precise termslike worst-case recognition complexity, it is easyto use the hierarchy incorrectly.
For instance,it is not valid to conclude that because a lan-guage is in a particular language class all subsetsof that language are also included that languageclass (e.g.
ww;i is a proper subset of w, yet w 6?3ww R 6?2).
Also, in most cases the structural de-scriptions that underlie strings of a language areof more interest han the string sets themselves.For this reason it is useful to distinguish weak andstrong containment of a grammar in a languageclass: e.g., a grammar is weakly context free ifits stringset is context free; a grammar is stronglycontext free if its treeset is also context free.2.2 Applicability to Natural LanguagePullum and Gazdar (1982) survey the argumentsup to the time they wrote for the non-coritext-freeness of natural anguage.
The most interestingwere those that considered i ealizations of linguis-tic phenomena in terms of the string duplicatinglanguage, ww.
In each case they found the m'-gument flawed: the phenomena in question didnot yield languages whose stringsets were homo-morphic to tile duplication language.
Bresnan etal.
(1982) argue that Dutch is not strongly con-text free.
Shieber (1985) provides a stringset ar-gument about a dialect of Swiss-German, whichhas a class of verb phrases with cross-serial depen-dencies (through case marking) between NPs andtheir Vs, which establishes even the weak-non-context-freeness of natural language because ofhomomorphism to ww.
Manaster-Ramer (1987)re-analyzes an argument considered by Pullumand Gazdar (1982) about Dutch and produces a158Hierarchy Level \]\] Language Type .
Model of Computation Complexity?
.
, , ,0 unrestricted phrase structure undecidablegrammar (=.r.e.)
..1 context sensitive (C recursive) PSPACE1.5 indexed1.75 mildly context sensitive2 context free3 regularTuring Machine (TM)Linear Bounded AutomataLBA)ested Stack AutomataNSA)mbeded PushdownAutomata (EPDA)Pushdown Automata (PDA)Finite State Machines (FSM)NP-Completen 7n a' linear " 'Table 1: Models of Grammar and Computationcorrected stringset argument that Dutch licencesa"b'*c '~ constructions, which are MCS.
No knownsyntactic phenomenon requires greater than in-dexed language xpressivity.The point of this paper is to emphasize that al-though a particular Swiss-German dialect rendersnatural anguage syntax non-context free, it doesnot entail that natural languages, induding theones that license cross-serial dependencies, incurthe worst case recognition complexity costs for in-dexed languages.
In fact, we argue in the nextsection that ww is fairly straightforward to pro-cess.
Essentially, we consider languages xx  homo-morphic to ww, where x can be either ?3 or ?2,and argue that the recognition for xx is no worsethan worst case recognition for ?3 if x E?3 andno worse than the worst case for ?2 i fx E?2, eventhough xx  is itself indexed.3 Cross-Serial Dependencies AreNot Hard to ProcessIt is always possible to compile less restrictivegrammar formalisms into more restrictive coveringformalisms, allowing different constituent analy-ses and potential stringset overgeneration.
Meta-grammatical techniques give an alternative thatpreserve coverage, but use special purpose pro-cessing.
We suggest a parsing method for lan-guages that rely on ww which does not cost agreater complexity fec than the worst case forparsing context fi'ee grammars.
The method ismetagrammatical and therefore akin to propos-als put forward previously for handling coordina-tion (Dahl and McCord, 1983) with logic gram-mars and TAGs (Shieber, 1995) or for extraposi-tion (Milward, 1994).
The method is constrainedenough not to augment overall processing com-plexity, implying that ww does not require theworst case recognition complexity for its charac-teristic class, the MCS languages.3.1 Why not?Trivially, the string duplication languages can berecognized with time complexity proportional tothe length of the string - -  if the string is of evenlength, and its first half is identical to the sec-ond half, then this can be established in just lin-ear time.
Though trivial in the sense of beingabout mere recognition, this is nonetheless inter-esting.
In particular, under the reasonable hy-pothesis that humans are not in general reverse-wired a it is easier to process serial orders thmltheir reverse.
In this trivial recognition model wecould take tile serial ordering as primitive, but touse the same model as a recognizer for the con-text free string reversal anguages would requirean additional step of reversing the second tlalfof the string before checking equivalence, whichmeans the recognition complexity is nlogn.
Thus,for trivial recognition tim string duplication lan-guages are easier to process than the string rever-sal lazlguagcs.
This is a concrete illustration thatnot every language costs the worst case recogni-tion complexity for its expressivity class.However, in the case of natural anguages, pars-ing is of greater interest than mere recognition.A generalization of the recognizer method can beused inside a parsing approach as well.
Supposesome i such that i > 2; suppose we want a rec-ognizer for {ww\]w E {a,b}*} where w E ?i ,  thenwe can use a parser that is no worse than cubic(if i : 2) and which can be linear (if i = 3) todetermine if w EEl.
Thus, if we parse exactlyhalf of the string using a processor designed forlanguages in ?i,  and then ascertain whether theremaining half is identical, then we remain in theaWhile there actually is structural reverse wiring,psychological effects, like child learning of the dis-tinction between left and right hands on themselvesand on a person facing them, suggest hat there is adifference in processing time required between recog-nizing a copy and an inverse copy.
Another examplecomes from the recognition of rotated objects.
Thereis a robust effect for which given a reference objectand a rotated object-in-question it takes time linearin the amount of rotation to recognize the objects ascopies.
Mirror-image objects are isomorphic, yet ittakes strictly more time to recognize reflected copiesthan to recognize nonreflected copies (Cooper, 1975).159same processing complexity class, since the iden-tity check occurs after tile parse and only requireslinear time, but we also have structural informa-tion about the sentence as a whole.
We know thestructure of the first half of the string, and the sec-ond half of tile string but not the structure of tilesecond half (the grammar for w could be ambigu-ous), although we can assume that the second wwas licensed by exactly the same tree structure asthe first.
This method also preserves a relative dif-ference between parsing ww and ww n,  at least for?3.
Since ww ~ can be represented directly within?2 it can be argued that we should not be requiredto use the metagrammatical  method of parsing it,just to keep symmetry with the duplication lan-guages.
Interestingly, if w is in ?2 and we use themetagrammatical  parsing method, then ww ~?
alsorequires more processing time than ww for thesame reason as the trivial case.
Suppose insteadthat we allow ww n to be parsed without usingtile metagrammatical  method.
In that case ww isrelatively even easier t.o process since it costs \[wl 3to parse with the metagrammatical approach butww I~ will cost (2\[wl) 3 in tile direct approach.
It,might be claimed that just as we argue ww not torequire the worst case complexity for its languageclass (?1.5), neither need ww n for ?2; but, thereversal language is a canonical example of a lan-guage that makes maximal use of the stack in thePDA.
In any case, the metagrammatical methodfor parsing ww costs no more than just parsingstrings in the characteristic language class of w.If this were the complete story then we couldonly recognize languages homomorphic to the du-plication languages.
Clearly even the Ziirich di-alect of Swiss-German allows other constructions,all of which we can assume are context free (Pul-lure and Gazdar, 1982).
Essentially we want tobe able to write arbitrary ?3 or ?2 grammars andalso be able to parse the string duplication lan-guage for whichever ?i  we choose.
The languagedefined by such a union is no longer ?
i ,  but willnot contain arbitrary ?1.5 strings, and if i = 3then the union will not even contain arbitrary con-text fi'ee strings.
However, the situation is moreinvolved than tile basic approach since there needsto be a way to indicate where the metagrammat-teal approach is to be invoked.
Add a single fea-ture to the grammar interpreted by tile processoras 'expect a copy'.
41.
A ---+ WBMYWe allow context free productions of the formshown in (1), where A and B are nonterminals andW, Y are (possibly empty) sequences of terminalsand nonterminals, B possibly occurring among4Ol lce  we admit 'interpretability b  the processor'we in principle have TM power.
Itowever we makequite restricted use of such interpretation.
The ruleformat makes clear that it is less expressive than in-dexed grammars when interpreted irectly.the nonterminals of Y.
For an ambiguous CFG,there is no guarantee that multiple instances ofa nontcrminal will rewrite to through the samesequence of productions to yield the same string.There are any number of ways that this basicnotation can be used in a metagrammatical  ap-proach.
In the first instance, we take c to be asignal to the processor to generate an expectationfor a duplicate of the terminal sequence that thenonterminal it is attached to gets rewritten to,and that this expectation must be satisfied by thenext nonterminal of the same name and in thesame local domain.
5 This approach will requirethat the sequence of terminals rewritten from thefirst B in (1) will be duplicated by the terminalsequence rewritten from the first instance of B (ifany) that occurs in Y.
The restriction will nothold of subsequent instances of the nonterminalmarked for copying in the same local domain norat ditferent levels in the analysis.
A stronger in-terpretation could require an expectation for thesame constituent analysis of the nonterminal aswell.
Since we do not allow the feature to stack,tile string-based method does not yield the fullexpressive power of indexed languages.
The pointis just that it's possible to keep a CF (or regular)grammar, and supplement the processor with astring-duplication operator which can be; invokedat the subsentence l vel.
This is sufficient o yieldlanguages thai; more closely resemhle the Ziirichdialect in having other constructions besides theduplication construction, yet remaining efficientlyprocessable.
~We have implemented tile interpreter in a chartparser that can be used in either top-down orbottom-up fashion.
Edges in the chart are markedwith a category (some nonterminal or preter-minal symbol from the grammar),  constituents,subs|ring span and expectations (along with aunique identifier for each edge).
This is modi-fied to include a list of constraints, which for thepresent purposes is presumed to be just duplica-tion checks.
An edge with no expectations i in-active (saturated) and one with expectations iactive.
In the completer step, when active edgescombine with adjacent inactive edges whose cate-gory satisfies the current expectation of the ac-tive, the usual process of creating a new edgewith one less expectation is augmented with an-other: if the current expectation has an associ-ated copy feature, then the new edge is markedwith a constraint interpreted by the parser as in-dicated above - -  the nonterminal symbol and tilestring spanned by the inactive edge are noted so5We take a local domain, in tree terms, as a nodeand tile set of nodes that it immediately dominates.~To get closer still to the Zfirich dialect, we requirethat the duplication operator be applied at the level ofpreterminals, with complementation, to get the pair-ings of case-marked NPs and Vs.160that the next inaetive edge of the same category(if one is expected) will have to span an |dent|-eL1 string.
Constraints of this form are not passedon after satisfied once, and are not passed out ofthe local domain.
Within the same set of restric-tions the implemented constraint could have been'expect a reversed copy'.
This would require con>putating the string's reverse before annotating theconstraint list.4 D iscuss ionTile context; free languages have alre.ady beenstudied from the perspective of minimal additionto incorporate copy languages.
Savitch (1989)does exactly that by prese, nting the model of con>put;at|on required for the class of languages de-lined by augment;ing the CFLs with redut)lication:a Reduplicat;ion PDA (RPDA).
An I~PDA is justa PDA which has a special type of symbol thai,can tie put onto the stack to nlake the machinetreat the part of the stack above it ms if it werea queue.
Essentially, t,his obtains the reversM be-havior nee, ded of a st.ack to process copy languagesas well as rew',rsals.
Mull,|pie instances of thespecial sylnbol can be placed on |.he stack.
Say-itch present,s a chara.ct,erization f the languagesill te, rms of stxingsets and the requisil;e compu-Lal;ional structures.
The family that we charac-terized above in terms of graInntars arc tn'operlya sullset of the languages recognized by R.PDA,a restrk:tion of RPDA languages which Savitch(1989) terlns simple R, PDA lanqu,.qes.
The modelof comput~ttion here is an RPDA in which only(me spe, cial symbol is allowed on the stack atany one, time.
We have not In'oven the equiva-lence we conje(:tllre bel, we(,'tl our Inetagranunaticalmethod and the reduplication contex&free gram-mars (RCFC, s) that Savi|,ch introduces as genera-tive of simple RPDA languages.
Saviteh's (1989)grammars are stated in terms of rule schemata (atin|re set) that general,e potentially infinite sets ofrewril;e rules.
This is the tradeoff lletwe, en doingthings metagraInmatieally and directly.Josh| and Rainbow (Josh|, 1990; Rainbow andJosh|, 1994) have also considered the perforntan('edata associated with processing crossed vs. nesteddependencies and present an alternative com-putal, ion model, |;tie bottom-up embedded PDA(BEPDA), designed for a wit|an|; of tree-adjoininggralnmar (it uses a stack of slacks and a morecomplex operation for eml)tying the stack).
II,am-bow an(1 Josh| (1994) use the processing model todemonstrate that it can account for the dilDrencebetween crossed and nested dependencies in terlnsof the amount of time associated objects spend inthe pushdown store of the BEPDA using a mildlycontext free language model that captures depen-dencies directly, rather t;han metagrammatically.
7r Josh| (1990) gives a similar analysis fi)r EDPAs.Essentially, their analysis (:oncludes (;tie satne:when judging string isomorphisnls, it; is easier tomake the judgment of identic~flly ordered pairsthan it is to reversely ordered pairs.
Thus, thecross-serial dependencies needn't cost the worstease complexity for parsing indexed or mildly ecru-text sensitive languages.
Parsing ww languagesrequires, at worst, (;lie worst ease complexity ofparsing w in whichever language class w is re-stricted to.
Shieber (1985) pointed out withoutproof that (;tie nonCl,' data associated ZiMch di-Nee(; is linearly parsable; our task has been toclarify how this follows from the language (;heory.4.1 A CaveatFor eilicicnt processing of ww to entail correspond~ing eomplexity fin" natural lmlguages that licensecross-serial dependencies hinges crucially on therebeing eflMently (:(mlputable hoinonmrphisms tm-tween the natural language, and the string dupli-eati<m languages.
This is aIl open question, tIow-ever, given that empirical work that COlnpares pro-cessing of crossed atld nested dependencies alldconcludes that the m'oss-serial dependencies arepreferred to nested ones (Bach el; al., 1986), andgiw~,n (}tit' arl{un!.ent thai, cross-serial dependenciesare in theory easier to process, we feel it.
teas(m-able to enterta.in the asSUml)tion that somel;hingsuch exists.
This does n(~t require us l.(~ assunlothai; ileol)le a(:Lually use conl,exl;-fl'ee grammarsand COlllp/lte holllolnort)hisills ill order 1,o itnder-stand natural languages, just thai; l:he c(mlt)ul;a-tional model should lm at least approximat.ely aseflicient as t)eoph~,.4.2 ImI ) l i cat ions()tit' inetagralnmatical pproach to dealing withcross serial dependencies involves the ~uSSUlnpl,ionof an operation for testing string duplication.
Wehinl;ed earlier that we h;el there to lm sutlicientreason to believe that copy-checldng is a basic cog-nitive flmction, and although we don't supposethat, people have built in production systems andprocessors i olnorphic to ollr chart parser aim baselanguage, we do think that t,his copy-dmeking isinvoked in the processing of crossed depe.Ildencies.Our approach to accounting for the processingcomplexity that the string duplication languagesshould take does make empMcal predictions andthese can lie teste, d. For instance, if it is t;he casethat such a nmchanisin exists, then patterns ofstring-copy disthtency should ocellr with (lifferenl.frequency in languages that lk:ense cross-serial ( e-pendencies than in those tha, t (t(I iI.ot.
A stxing-copy dislhleney is just one that involves a repeatof part of the sentence, ul, t;ered so far:1.
We went to the to lhe store to buy some Jlo'.a'.The idea ix that speakers of bmguages with wwhomomorphisms have a different pattenl  of in-voking copy-checking than those who speak lan-161guages that do not admit cross serial dependen-cies.
These differences should be manifest inspeech corpora like those that are currently beingaccumulated (Anderson et al, 1992; Miller, 1995),but which n~d augmentation by a corpus derivedfrom copy-language dialects.
Verifying this would,for example, establish whether the copied stringsneed to be constituents, and this has a bearing onwhether processing models designed for incremen-tal interpretation (Milward, 1992) are the best de-scriptors of human performance."
We do not offerarguments that our metagrammatical approach isthe best description of human processing of cross-serial dependencies, just that it is another theo-retical justification for the difference in process-ing nested dependencies and efficient processingof crossed dependencies.AcknowledgementsVogel is grateful to the SFB 340 for fundinghis stay Stuttgart; Hahn acknowledges the sup-port of ESRC grant No.
R004293341442; Brani-tan, EPSI~C research studentship No.
92315069.All would like to thank Catherine Collin, Toma~Erjavec, Tsutomu Fujinami:, Merce Prat, FredP0powich, Mark Steedman, and the anonymousreviewers.ReferencesAlfred V. Aho.
1968.
Indexed grammars--an exten-tion to context-free grammars.
Journal of the As-sociation/or Computing Machinery, 15(4):647-671.Anne H. Anderson, Miles Bader, Ellen Gurman Bard,Elizabeth H. Boyle, Gwyneth M. Doherty, Simon C.Garrod, Stephen D. Isard, Jacqueline C. Kowtko,Jan M. McAllister, Jim Miller, Catherine F. Sotillo,Henry S. Thompson, and Regina Weinert.
1992.The IICRC Map Task corpus.
Language andSpeech, 34(4):351-366.Emmon Bach, Colin Brown, and William Marslen-Wilson.
1986.
Cross and nested dependencies ingerman and dutch: A psycholinguistic study.
Lan-guage and Cognitive Processes, 1(4):249-262.Joan Bresnan, Ron Kaplan, Stanley Peters, and AnnieZaenen.
1982.
Cross-serial dependencies in dutch.Linguistic Inquiry, 13(4):613-35.Lynn Cooper.
1975.
Mental rotation of random two-dimensional shapes.
Cognitive Psychology, 7:23-43.Veronica Dahl and Michael McCord.
1983.
T~eatingcoordination in logic grammars.
American Journalo/Computational Linguistics, 9(2):69-91.SNore that the English 'respectively' constructionsrequire a special intonational behavior in the sing-song litany-voice that is required for a speaker tomake an extended 'respectively' construction inter-pretable, thus arguments for specifically metagram-matical treatment do exist (where intonational factsaxe considered evidence for a signa\] to the processorto do something unusual).Gerald Gazdar and Geoffrey Pullum.
1985.
Compu-tationally relevant properties of natural anguagesand their grammars.
Technical Report CSLI-85-24,Stanford: Center for the Study of Language andInformation.Gerald Gazdar.
1985.
Applicability of indexed gram-mars to natural anguage.
Technical Report CSLI-85-34, Stanford: Center for the Study of Languageand Information.John E. Hopcroft and Jeffrey D. Ullman.
1979.
Intro-duction to Automata Theory, Languages, and Com-putation.
Addison-Wesley Publishing Co., ReadingMA.Aravind K. Joshi, K. Vijay-Shanker, and David Weir.1989.
The convergence of mildly context-sensitivegrammar formalisms.
Technical Report MS-CIS-89-14; LINC LAB 144, Department of Computerand Information Science University of Pennsylva-nia, Philadelphia, PA.Aravind Joshi.
1990.
Processing crossed and nesteddependencies: An automaton perspective on thepsycholingnistic results.
Language and CognitiveProcesses, 5(1):1-27.Alexis Manaster-Ramer.
1987.
Dutch as a formallanguage.
Linguistics and Philosophy, 10(2):221-46.Jim Miller.
1995.
Focus in the languages of europe.To appear in G. Bernini (ed.)
Pragmatic organiza-tion in the languages (Volume I. of Typology of thelanguages of Europe).
Mouton-de Gruyter.David Milward.
1992.
Dynamics, dependency gram-mar and incremental interpretation.
In COL-ING92, pages 1095-9.David Milward.
1994.
Dynamic dependency gram-mar.
Linguistics and Philosophy, 17:561-605.Geoffrey Pullum and Gerald Ga~dar.
1982.
Naturallanguages and context-free languages.
Linguisticsand Philosophy, 4:471-504.Owen Rambow and Aravind Joshi.
1994.
A process-ing model for free word order languages.
In L. Fra-zier C. Clifton, Jr. and K. Rayner, editors, Perspec-tives on Sentence Processing.
Lawrence Erlbaum.Walter Savitch.
1989.
A formal model for context-freelanguages augmented with reduplication.
Compu-tational Linguistics, 15(4):250-61.Stuart Shieber.
1985.
Evidence against he context-freeness of natural anguage.
Linguistics and Phi-losophy, 8(3):333-43.Stuart Shieber.
1995.
What is wrong with tags.
In-vited talk at the Seventh Conference of the Euro-pean Chapter of the Association for ComputationalLinguistics.
Belfield, Dublin, Ireland.Edward P. Stabler.
1994.
The finite connectivity oflinguistic structure.
In Lyn Frazier Charles Clifton,Jr.
and Keith Rayner, editors, Perspectives on Sen-tence Processing.
HiUsdale, N J: Lawrence Erlbaum.Carl Vogel and Toma~ Erjavec.
1994.
Restricted is-continuous phrase structure grammar and its rami-fications.
In Carlos Martin-Vide, editor, Current Is-sues in Mathematical Linguistics.
The Netherlands:Elsevier Science Publishers.162
