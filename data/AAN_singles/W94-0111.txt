Exploring the Statistical Derivationof Transformational Rule Sequencesfor Part-of-Speech TaggingLance A. RamshawInst.
for Research in Cognitive ScienceUniversity of Pennsylvania3401 Walnut Street #412-CPhiladelphia, PA 19104-6228 USAramshaw@linc, cis.
upenn, eduandDept.
of Computer ScienceBowdoin CollegeBrunswick, ME 04011 USAMitchell P. MarcusComputer and Information Science Dept.University of Pennsylvania558 Moore BuildingPhiladelphia, PA 19104-6389 USAmit oh@line, c is.
upenn, eduIntroductionEric Brill in his recent thesis (1993b) proposed an ap-proach called "transformation-based error-driven learn-ing" that can statistically derive linguistic models fromcorpora, and he has applied the approach in variousdomains including part-of-speech tagging (Brill, 1992;Brill, 1994) and building phrase structure trees (Brill,1993a).
The method learns a sequence of symbolic rulesthat characterize important contextual factors and usethem to predict a most likely value.
The search for suchfactors only requires counting various ets of events thatactually occur in a training corpus, and the method isthus able to survey a larger space of possible contextualfactors than could be practically captured by a statis-tical model that required explicit probability estimatesfor every possible combination of factors.
Brill's resultson part-of-speech tagging show that the method canoutperform the HMM techniques widely used for thattask, while also providing more compact and perspicu-o.s models.Decision trees are an established learning techniquethat is also based on surveying a wide space of possiblefactors and repeatedly selecting a most significant fac-tor or combination of factors.
After briefly describingBrill's approach and noting a fast implementation f it,this paper analyzes it in relation to decision trees.
Thecontrast highlights the kinds of applications to whichrule sequence l arning is especially suited.
We point outhow it, ma.ages to largely avoid difficulties with over-training, and show a way of recording the dependenciesbt.tween rules in the learned sequence.
The analysisthroughout is based on part-of-speech tagging exper-iments using the tagged Brown Corpus (Francis andK.eera, 1979) and a tagged Septuagint Greek versionof the first five books of the Bible (CATSS, 1991).Brill 's ApproachThis learning approach starts with a supervised train-ing corpus and a baseline heuristic for assigning initialvalues.
In the part-of-speech tagging application, forexample, the baseline heuristic might be to assign eachknown but ambiguous word whatever tag is most oftencorrect for it in the training corpus, and to assign allunknown words an initial tag as nouns.
(Brill's resultspoint out that performance on unknown words is a cru-cial factor for part-of-speech tagging systems.
His sys-tem is organized in two separate rule sequence trainingpasses, with an important purpose of the first pass beingexactly to predict he part-of-speech of unknown words.However, because the focus in these experiments i onunderstanding the mechanism, rather than on compara-tive performance, the simple but unrealistic assumptionof a closed vocabulary is made.
)The learner then works from those baseline tag as-signments using a set of templates that define classes oftransformational rules, where each rule changes omeassigned values based on characteristics of the neighbor-hood.
Again, for tagging, the rule templates typicallyinvolve either the actual words or the tags currently as-signed to words within a few positions on each side ofthe value to be changed.
The rule templates used inthese experiments involve up to two of the currently-assigned tags on each side of the tag being changed;they include \[ - -  C A/B \] (change tag A totag B if the previous tag is C) and \[ - -  - -  A/B C D \](change A to B if the following two tags are C and D).During training, instantiated rules like \[ - -  DET V/N- -  - -  \] are built by matching these templates againstthe training corpus.A set of such templates combined with the given part-of-speech tagset (and vocabulary, if the rule patterns86also refer directly to the words) defines a large space ofpossible rules, and the training process operates by us.ing some ranking function to select at each step a rulejudged likely to improve the current tag assignment.Brill suggests the simple ranking function of choosing(one of) the rule(s) that makes the largest net improve-ment in the current raining set tag assignments.
Notethat applying a rule at a location can have a positiveeffect (changing the current ag assignment from incor-rect to correct), a negative one (from correct to someincorrect value), or can he a neutral move (from oneincorrect ag to another).
Rules with the largest posi-tive minus negative score cause the largest net benefit.In each training cycle, one such rule is selected and ap-plied to the training corpus and then the scoring andselection process is repeated on the newly-transformedcorpus.
This process is continued either until no bene-ficial rule can be found, or until the degree of improve-ment becomes less than some threshold.
The scoringprocess is tractable in spite of the huge space of possi-ble rules because rules that never apply positively canbe ignored.The final model is thus an ordered sequence ofpattern-action rules.
It is used for prediction on a testcorpus by beginning with the predictions of the baselineheuristic and then applying the transformational rulesin order.
In our test runs, seven templates were used,three templates testing the tags of the immediate, next,and both neighbors to the left, three similar templateslooking to the right, and a seventh template that teststhe tags of the immediate l ft and right neighbors.
Thefirst ten rules learned from a training run across a 50K-word sample of the Brown Corpus are listed in Fig.
1;they closely replicate Brill's results (1993b, page 96), al-lowing for the fact that his tests used more templates,including templates like "if one of the three previoustags is A".Brill's results demonstrate that this approach canoutperform the Hidden Markov Model approaches thatare frequently used for part-of-speech tagging (Jelinek,1985; Church, 1988; DeRose, 1988; Cutting et al, 1992;Weischedel t al., 1993), as well as showing promise forother applications.
The resulting model, encoded asa list of rules, is also typically more compact and forsome purposes more easily interpretable than a table ofHMM probabilities.An Incremental AlgorithmIt is worthwhile noting first that it is possible in somecircumstances to significantly speed up the straight-forward algorithm described above.
An improvementin our experiments of almost two orders of magnitude(from four days to under an hour) was achieved by usingan incremental approach that maintains lists of point-ers to link rules with the sites in the training corpuswhere they apply, rather than scanning the corpus fromscratch each time.
The improvement is particularly no-ticeable in the later stages of training, when the rulesbeing learned typically affect only one or two sites isl thetraining corpus.
Note, however, that the linked lists illthis incremental pproach require a significant amountof storage space.
Depending on the number of possi-ble rules generated by a particular combination of rul,.templates and training corpus, space constraints maynot permit this optimization.Incrementalizing the algorithm requires maintaininga list for each rule generated of those sites in the corpuswhere it applies, and a list for each site of the rulesthat apply there.
Once one of the highest-scoring rulesis selected, its list of site pointers is first used to makethe appropriate changes in the current tag values inthe corpus.
After making the changes, that list is usedagain in order to update other rule pointers that mayhave been affected by them.
It suffices to check eachsite within the span of the largest defined rule templatefrom each changed site, testing to see whether all ofits old rule links are still active, and whether any newrules now apply at that site.
Our current algorithm isshown in Fig.
2.
Note that, after the initial setup, itis necessary to rescan the corpus only when updatinguncovers a rule that has not previously had any positiveeffect.Rule Sequences and Decision TreesTo understand the success of Brill's new method, it isuseful to compare it with the decision tree approach(Breiman et al, 1984; Quinlan, 1993), which is anestablished method for inducing compact and inter-pretable models.
The key difference is that decisiontrees are applied to a population of non-interactingproblems that are solved independently, while rule se-quence learning is applied to a sequence of interrelatedproblems that are solved in parallel, by applying rulesto the entire corpus.
The following sections discuss howthis parallel approach allows leveraging of partial solu-tions between eighboring instances, but also requiresthat the rules themselves be largely independent.
Whiledecision trees can synthesize complex rules from simpletests, rule sequence learning requires those combina-tions to be built into the templates.Leveraged LearningDecision trees are traditionally applied to independentproblem instances encoded as vectors of measurementsfor the various possibly-relevant factors.
In predict-ing the part of speech of a word in a corpus, such .factors would include the identities of the neighboringwords within some window.
However, it would also beuseful to know the currently predicted tags for thosewords, since the tag-assignment problems for neighbor-ing words in a corpus are not independent.
The rule se-quence learning technique is particularly well adaptedto a corpus that is inherently a sequence of such inter-related problem instances.
Because the rule patterns ina part-of-speech system do depend in part on tile un-known part-of-speech values at neighboring locations,87Pass1.2.3.4.5.6.7.8.9.10.Rule Pos.
Ne 9.
Neu|.m __ TO/ IN AT u 227 0 0TO NN/VB - -  u 113 13 0- -  TO/ IN NN - -  49 0 0- -  IN PPS/PPO - -  51 4 0- -  - -  TO/ IN NP ~ 46 0 0~ TO/ IN PP$ - -  46 1 0m CS/DT NN - -  52 I i  lHVD VBD/VBN ~ - -  38 0 0~ CS/QL  ~ CS 41 7 0MD NN/VB m ~ 32 0 0Figure 1: First 10 Rules Learned on Brown Corpus Sample/ /Records  for locations in the corpus, called "sites",/ / inc lude  a linked list of the rules that apply at that site./ /Records  for rules include score components (positive, negative, and neutral)/ /and  a linked list of the sites at which the rule applies./ /A  hash table stores all rules that apply positively anywhere in the training.scan corpus using templates, making hash table entries for positive rulesscan corpus again to identify negative and neutral sites for those rulesloophigh_rule := some rule with maximum scoreif high_rule.score <= 0then exit loopoutput rule tracefor each change_site on high.xule.site_list doapply high_rule at change_site by changing current agunseen_rules := 0for each change_site on high_rule.site.list dofor each test_site in the neighborhood of change_site donew_rules_list := NILfor each template doif template applies at test_sitethen add resulting rule to new_rules.listfor each rule in test_site.rules.list - new_rules_list doremove connection between rule and test_sitefor each rule in new_rules_list - test_site.rules_list doif rule in hash tablethen make new connection between rule and test_siteelse unseen_rules := unseen.rules O {rule}if unseen_rules # 0 thenadd unseen_rules to hash tablefor each site in corpus dofor each rule in unseen_rules doif rule applies at site thenmake connection between rule and siteadjust appropriate rule score (positive, negative, or neutral)end loopFigure 2: Incremental Version of Rule Sequence Learning Algorithm88it seems useful to allow those patterns to be based ateach point on the system's best current guess for thosevalues.
It is difficult to take account of that kind ofdependence in a traditional decision tree, since changesin neighboring tag predictions can force the recompu-tation of predicate splits higher in the tree.
Breakingthe tag prediction process up into a series of rules that?
can each be applied immediately to the entire corpus isa simple scheme that allows for that kind of leverage.Much as when a bank compounds interest, this allowsthe system to base its future learning on the improvedestimates of neighborhood tags resulting from the op-eration of earlier rules.A non-leveraged learner would have to build rulesor trees based only on the unchanging features of theneighboring words and perhaps the baseline guesses oftheir tags.
In effect, such a learner would be forced totry to resolve the ambiguity at the neighboring loca-tion as part of the rule for the primary site, using asevidence only cases where the two occur together.
Theleveraging approach allows the system to factor the bestcurrent guess for the neighboring site in terms of all theevidence into the choice for the primary site.
It is toallow for leveraging that the model is formulated as asequence of individual rules.Largely Independent RulesThis breaking up of the rule sequence model into largelyindependent rules also results in another important dif-ference between rule sequence learning and decisiontrees.
In the building of a decision tree, an elemen-tary predicate is selected at each step to split a singleleaf node, meaning that it is applied only to those train-ing instances associated with that particular branch ofthe tree.
The two new leaves thus created effectivelyrepresent two new classification rules, each one select-ing exactly the instances that classify to it, and thuseach including all of the predicates inherited down thatbranch of the tree.
In the rule sequence method, on theother hand, the rules are generated from the templatesas they are applied to the whole corpus in a largely inde-pendent manner; there is no corresponding inheritanceof earlier predicates down the branches of a tree.Note that one could simulate the decision tree stylein a sequence learner by adding to the pattern for eachrule template a variable-length field that records thecomplete history of rules which have affected that lo-cation.
Then, as in a decision tree, a rule generated atone site in the training set would be scored only againstsites whose previous rule history exactly matched itsown.
But rule sequence learning as defined here is notsensitive in that way to the previous rule history.The "largely independent" rules in the sequencewould be fully independent if the system were not do-ing leveraging; if all rule patterns were tested each timeagainst he original baseline tag predictions, then therewould be no way for earlier rules to affect later ones inthe sequence.
Leveraging does make later rules depen-dent on the results of earlier ones, but it does so to astrictly limited degree, which is generally much weakerthan the direct inheritance of rules down decision treebranches.To see the limitation, suppose that templates couldtest the current tag of the word to be changed, butcould only consult the baseline tags for the rest of thepattern.
Earlier rule firings could then affect what rulesmight later apply at a particular location only by chang-ing the current tag assignment for that location itselfto one of the other possible tag values.
Each rule fir-ing would make potentially applicable at the locationsaffected all rules whose central pattern element specifythat new tag value, while disabling those rules whosepatterns pecify the old value.
The training set at anytime during training would thus in effect be partitionedfor purposes of rule application into at most as manyclasses as there are tags.
Such a system can be picturedas a lattice with one column for each tag assignment andwith a single slanting arc at each generation that movessome corpus locations from one column to another.While a decision tree path can encode an arbitraryamount of information in its branching, this system isforced to merge as often as it branches, which requiresthe rules to be more independent.
Furthermore, thesystem's ability to use even the available partitioning inorder to construct dependent rule sequences i  furtherlimited, since tag changes are only made when somesubset of the data is identified for which the new tag ismore representative of the training corpus; tile learneris not free to use tag assignments o encode arbitraryrule dependencies.
Even in the actual system, wherethe leveraging can include changes in the neighborhoodas well as at the location itself, the rule sequence mech-anism still appears to have much less power to createcomplex combined rules than do decision trees.Because rule sequence learners are more limited interms of the connections between rules that they canconstruct during training, they must begin with morecomplex predicates built into their rule templates.
Ifthe templates in a rule sequence run are not strongenough to distinguish the important patterns in tiledata, performance will naturally suffer.
But if the ruletemplates that are likely to be useful can be predicted illadvance, the rule sequence approach can benefit bothfrom leveraging and, as shown later, from decreasedfragmentation f the training set.Scoring MetricsThis difference in organization between rule sequencelearning and decision trees carries through naturally tothe scoring methods used to select the next rule to ap-ply.
Decision trees often select the split which mostreduces either a diversity index or some measure basedon the conditional entropy of the truth given the tree'spredictions (Breiman et al, 1984; Quinlan and Rivest,1989; Quinlan, 1993).
Note that these metrics may se-lect a split that does not change the score of the current89predictions against he truth, for instance by splittinga node in such a way that both children still have thesame plurality class as the parent.
Such a split maystill make sense in entropy terms if the distributions ofthe other tags in the two new nodes are substantiallydifferent, thus suggesting that later rules will have aneasier time isolating particular tag values.
In a rule se-quence learner, however, there is less likely to be anyadvantage to such a split, since the instances whose tagsare changed by that rule will then be mixed with othersthat were already assigned the new tag for other rea-sons.
The net benefit metric that is actually used in rulesequence learning is equivalent in decision tree terms tousing the resubstitution estimate of the misclassifica-tiou rate.
While that metric is not ideal for decisiontrees, it appears to work well for rule sequence learn-ing, where the mechanism is strictly limited in terms ofthe connections between rules that it can construct.Over t ra in ingIt is particularly interesting to compare rule sequenceswith decision trees in terms of the risk of overtrain-ing (or "overfitting").
One of the intriguing features ofrule sequence learning is its apparent resistance to over-trai,ing.
For example, Fig.
3 shows the graph of per-cent correct on both training set (solid line) and test set(dotted line) as a function of the number of rules appliedfor a typical part-of-speech training run on 120K wordsof Greek text.
The training set performance naturallyimproves monotonically, given the nature of the algo-riti~m, but the surprising feature of that graph is thatthe test set performance also improves monotonically,except for minor noise, and this seems to be true forthe great majority of our rule sequence training runs.This is in marked contrast o similar graphs for deci-sion trees or neural net classifiers or for the iterative EMtraining of HMM tuggers on unsupervised data, whereperformance on the test set initially improves, but latersignificantly degrades.Experiments suggest hat part of the difference is dueto knowledge mbodied in the templates.
When a part-of-speech training run is supplied with relevant em-plates, as in Fig.
3, one gets an "improve to plateau"test-set curve.
Irrelevant emplates, however, can leadto overtraining.
Fig.
4 shows that noticeable overtrain-ing results from using just a single irrelevant emplate,in this case, one that tested the tags of the words fivepositions to the left and right, which seem likely to belargely uncorrelated with the tag at the central ocation.l"ig.
5, where the single irrelevant emplate is com-bia,ed with the seven normal templates, shows that insuch cases, most of the overtraining happens late inthe training process, when most of the useful relevanttemplates have already been applied.
At that stage,as always, the templates are applied to each remain-i ,g incorrectly-tagged site, generating candidate rules.I,~ach r,h, imturally succeeds at the site that proposedit, h , t  most are now effectively random changes, whichare thus likely to do more harm than good when triedelsewhere, especially since most of the assigned tagsat this stage are correct.
Thus if the rule's patternmatches elsewhere in the training set, it is quite likelythat the change there will be negative, so that the un-helpful rule will not be learned.
Thus the presence ofrelevant templates supplies an important degree of pro-tection against overtraining from any irrelevant em-plates, both by reducing the number of incorrect sitesthat are left late in training and by raising the percent-age already correct, which makes it more likely that badrules will be filtered out.
The same applies, of course,to relevant and irrelevant instances of mixed templates,which is the usual case.Most of the overtraining will thus come from patternsthat match only once in the training set (to their gen-erating instance).
Under these assumptions, note thatapplying a score threshold > 1 can significantly reducethe overtraining risk, just as decision trees sometimescontrol that risk by applying a threshold to the entropygain required before splitting a node.
Brill's systemuses a score threshold of 2 as the default, thus gainingadditional protection against overtraining, while our ex-perimental runs have been exhaustive, in order to betterunderstand the mechanism.Using test runs like those plotted above for irrele-vant templates of various degrees of complexity, we alsofound a connection in terms of overtraining risk betweenthe inherent matching probability of the templates usedand the size of the training set.
A large training setmeans a larger number of incorrect sites that might en-gender overtrained rules, but also a better chance offinding other instances of those rule patterns and thusfiltering them out.
The combination of those factorsappears to cause the risk of overtraining for a partic-ular irrelevant emplate to first rise and then fall withincreasing training set size, as the initial effect of in-creased exposure is later overcome by that of increasedfiltering from further occurrences of the patterns.In comparing this with decision trees, the key con-trust is that the filtering effect there decreases as train-ing proceeds.
The splitting predicates there are appliedto increasingly small fragments of the training set, sothat the chance of filtering counterexamples also de-creases.
(To put it in decision tree terms, with fewpoints left in the rectangle being split, it becomes morelikely that an irrelevant predicate will incorrectly ap-pear to provide a useful split.)
But since rule sequencelearning continues to score its essentially independentrules against the entire training set, the protection offiltering against overtraining remains tronger.
Givingup the power to synthesize new rules thus provides anovertraining payoff as well as a leverage one.Rule I n te rdependenceWhile the connections between rules in a rule sequenceare more limited than the inheritance of rule ancestorsfound in decision trees, it is still interesting to be able90oo030303r,,,0303 i !
!
!
!0 200 400 600 800 1000Figure 3: Training Set (solid line) and Test Set (dotted line) Performance on Greek Corpus00' q l " "03030303?.003 !
!
!
!
i0 200 400 600 800 1000Figure 4: Training with 1 Irrelevant Template on Greek Corpus91oo0303?003r,,..0303I; i i !
; i i0 200 400 600 800 1000 1200Figure 5: Training with 7 Relevant and 1 Irrelevant Templatesto characterize and quantify the rule dependencies thatare present.
We have therefore added code that keepstrack, whenever a rule is applied at a site, of a depen-dency tree showing the earlier rule applications thatthat rule depends on.
For example, the dependencytree from the Brown Corpus data in Fig.
6 shows a casewhere the last rule that applied at this particular site(the bottom line in the figure, representing the root ofthe tree), which changed JJ to RB, depended on earlierrules that changed the previous site (relative position-1)  to VBN and the following one (position +1) toDT.
(The final number on each line tells during whatpass that rule was learned.
While recorded internallyas trees, these structures actually represent dependencyDAGs, since one rule application may be an ancestor ofanother along more than one path.)
All sites start out~qsigned a null dependency tree representing the base-line heuristic choice.
The application of a rule causes;t new tree to be built, with a new root node, whosechildren are the dependency trees for those neighboringlocations referenced by the rule pattern.
At the end ofthe training run, the final dependency trees are sorted,sl.ructurally similar trees are grouped together, and thecla.~s~.s are then sorted by frequency and output alongwith the list of rules learned.
(','rtain common classes of dependency can be notediu t.ht, r,'sulting trees.
('.orrectiou rules result when onernh, inak~,s an; overly gem~ral change, which affects not- , ly  apl~rol~riate sites, but also inappropriate ones, sothat a later rule in the sequence undoes part of theearlier effect.
One dependency of this type from ourBrown Corpus run can be seen in Fig.
7.
Here thefirst rule was the more general one that changed PP$to PPO whenever it follows VBD.
While that rule wasgenerally useful, it overshot in some cases, causing thelater learning of a correction rule that changed PPOback to PP$ after RB VBD.Chaining rules occur in cases where a change ripplesacross a context, as in Fig.
8.
The first rule to applyhere (21) changed QL to AP in relative position +2.That change enabled the RB to QL rule (181) at po-sition +1, and together those two changes enabled theroot rule (781).
Note that this two-step rule chain hasallowed this rule to depend indirectly on a current tagvalue that is further away than could be sensed in a sin-gle rule, given the current maximum template width.The dependency tree output also shows something ofthe overall degree and nature of rule interdependence.The trees for a run on 50K words of the Brown Corpusbear out that rule dependencies, at least in the part-of-speech tagging application, are limited.
Of a totalof 3395 sites changed uring training, only 396 had de-pendency trees with more than one node, with the mostfrequent such tree appearing only 4 times.
Thus thegreat majority of the learning in this case came fromtemplates that applied in one step directly to the base-line tags, with leveraging being involved in only about12% of the changes.The relatively small amount of interaction found be-tween the rules also suggests that the order in which92(7)(8)(649)oFigure 6: Sample Dependency Tree from Brown Corpus Data0: - -  VBD PP$/PPO (30)0: RB VBD PPO/PP$ (174)Figure 7: Sample Correction Class Dependency Tree from Brown Corpus Data+2: - -  - -  QL/AP CS - -  (21)+I :  RB/QL AP CS (181)0: NNS/VBZ QL AP (781)Figure 8: Sample Chaining Class Dependency Tree from Brown Corpus Datao03030o03r,..03?,D03 i i !
!0 500 1000 1500+1: ~ - -  CD/DT NN - --1 :  - -  HVD VBD/VBN - -0: , - -  VBN J J /RB DT - -Figure 9: Training and Test Set Performance on Greek, Random Rule Choice93the rules are applied is not likely to be a major factorin the success of the method for this particular appli-cation, and initial experiments tend to bear this out.\["ig.
3 earlier showed a training run on Greek text usingthe largest net benefit choice rule that Brill proposes.Note that, on this Greek corpus, the initial baselinelevel of choosing the most frequent raining set tag foreach word is already quite good; performance on bothsets further improves during training, with most of theimprovement occurring in the first few passes.
In com-parison, Fig.
9 gives the results for a training run wherethe next rule at each step was randomly selected fromamoug all rules that had a net positive ffect of any size.While tim progress is more gradual, both the trainingand test curves reach very close to the same maximaunder these conditions as they do when the largest netI)enefit rule is chosen at each step.
Note that it doestake more rules to reach those levels, since the ran-dora training frequently chooses more specific rules thatwould have been subsumed by more general ones cho-sen later.
Thus the largest net benefit ranking criterionis a useful one, particularly if one wants to find a shortinitial subsequence of rules which achieves the bulk ofthe good effect.
But at least for this task, where thereis little interdependence, choice of search order does notnm('h affect the final performance achieved.Future WorkThe general analysis of rule sequences in relation todecision trees presented here is based on experimentsprimarily in the part-of-speech tagging domain.
Withinthat domain, it would be useful to quantify more clearlywhether or not rule sequence learning is more effectivethan tiaditional decision tree methods when applied tothe same corpora and making use of the same factors.Such experiments would better illuminate the trade-oils between the ability to combine predicates into morecomplex rules on the one hand and the ability to lever-age partial results and resist overtraining on the other.It would also be usefu\[to test the data presented here onovertraining risk and on rule interdependence in otherdomains, particularly ones where the degree of rule in-terdependence ould be expected to be greater.
Furtherexploration of the connections between rule sequencesand decision trees may also suggest other approaches,perhaps blends of the two, that would work better insolne circumstances.Within rule sequence learning itself, other rankingschemes for selecting the next rule to apply might beahh.
to improve on the simple maximum net benefitheuristic.
We are currently exploring the use of likeli-hood ratios for this purpose.
It may also be possibleto control for the remaining risk of overtraining in amore sensitive way than with a simple threshold.
De-cision trees often use selective pruning to control over-training, and deleted estimation (Jelinek and Mercer,19~()) or other cross-validation techniques arc also nat-ural .~u14gi,'sti~ms for this purpose, but if, is difficult tosee how to apply any of these techniques to bare rule se-quences because they contain hidden dependencies be-tween rules, so that there is no obvious way to deleteselected rules or to interpolate between two differentrule sequences.
One goal for collecting the dependencytree data is to make it possible to prune or restruc-ture rule sequences, using the recorded ependencies tomaintain consistency among the remaining rules.ConclusionsTransformational rule sequence learning is a simple andpowerful mechanism for capturing the patterns in lin-guistic data, which makes it an attractive alternativewell worth further exploration.
Brill has showed that itsperformance for part-of-speech tagging can surpass thatof the HMM models most frequently used, while pro-ducing a more compact and perhaps more interpretablemodel.While its results can be compared with those of HMMmodels, the rule sequence technique itself seems to havemore in common with decision trees, especially in itsability to automatically select at each stage from a largespace of possible factors the predicate or rule that ap-pears to be most useful.
Decision trees synthesize com-plex rules from elementary predicates by inheritance;rule sequence learning, on the other hand, prespeci-ties in the templates essentially the full space of pos-sible rules, with each rule acting largely independently.This restriction in power turns out not to be cripplingas long the template set can be made rich enough tocover the patterns likely to be found in the data, and itbrings two important benefits in return: first, breakingthe learning process into independent rules means thatthey can be applied to the whole corpus as they arelearned, so that where neighboring patterns in the dataare interrelated, the rules can leverage off the best esti-mates regarding their surroundings; and second, sincethe independent rules continue to be scored against hewhole training corpus, a substantial measure of protec-tion against overtraining compared to decision trees isgained.ReferencesBreiman, Leo, Jerome H. Friedman, Richard A. Olshen,and Charles J.
Stone.
1984.
Classification and Re-gression Trees.
Pacific Grove, California: Wadsworth& Brooks/Cole.Brill, Eric.
1992.
A simple rule-based part of speechtagger.
In Proceedings off the DARPA Speech andNatural Language Workshop, 199~.Brill, Eric.
1993a.
Automatic grammar induction andparsing free text: A transformation-based approach.In Proceedings of the DARPA Speech and NaturalLanguage Workshop, 1993.Brill, Eric.
1993b.
A Corpus-Based Approach to Lan-guage Learning.
Ph.D. thesis, University of Pennsyl-vania.94Brill, Eric.
1994.
A report of recent progress intransformation-based error-driven learning.
In Pro-ceedings of the ARPA Workshop on Human LanguageTechnology, March, 1994.CATSS.
1991.
Produced by Computer-Assisted Toolsfor Septuagint Studies, available through the Univer-sity of Pennsylvania's Center for Computer Analysisof Texts.Church, Kenneth.
1988.
A stochastic parts programand noun phrase parser for unrestricted text.
In Sec-ond Conference on Applied Natural Language Pro-cessing.
ACL.Cutting, D.,'J.
Kupiec, J. Pederson, and P. Sibun.
1992.A practical part-of-speech tagger.
In Proceedings ofthe Third Conference on Applied Natural LanguageProcessing.
ACL.DeRose, Steven J.
1988.
Grammatical category disam-biguation by statistical optimization.
ComputationalLinguistics, 14(1):31-39.Francis, W. Nelson and Henry Kucera.
1979.
Manualof information to accompany a standard corpus ofpresent-day edited American English, for use withdigital computers.
Technical report, Department ofLinguistics, Brown University.Jelinek, F. 1985.
Markov source modeling of text gener-ation.
In ed.
J.K. Skwirzinski, editor, Impact of Pro-cessing Techniques of Communication.
Nijhoff, Dor-drecht.Jelinek, F. and R. L. Mercer.
1980.
Interpolated es-timation of Markov source parameters from sparsedata.
In E.S.
Gelsema nd L. N. Kanal, editors, Pat.tern Recognition i  Practice.
North-Holland, Amster-dam, pages 381-397.Quinlan, J. Ross.
1993.
C~.5: Programs for MachineLearning.
Morgan Kaufmann.Quinlan, J. Ross and Ronald L. Rivest.
1989.
Inferringdecision trees using the minimum description lengthprinciple.
Information and Computation, 80:227-248.Weischedel, Ralph, Marie Meteerl Richard Schwartz,Lance Ramshaw, and Jeff Palmucci.
1993.
Cop-ing with ambiguity and unknown words throughprobabilistic methods.
Computational Linguistics,19(2):359-382.95
