Discourse Cues for Broadcast News SegmentationMark T. MayburyThe MITRE Corporation202 Burlington RoadBedford, MA 01730, USAmaybury@mitre.orgAbstractThis paper describes the design and application oftime-enhanced, finite state models of discoursecues to the automated segmentation of broadcastnews.
We describe our analysis of a broadcastnews corpus, the design of a discourse cue basedstory segmentor that builds upon informationextraction techniques, and finally its computationalimplementation a d evaluation in the BroadcastNews Navigator (BNN) to support video newsbrowsing, retrieval, and summarization.1.
IntroductionLarge video collections require content-basedinformation browsing, retrieval, extraction, andsummarization to ensure their value for tasks suchas real-time profiling and retrospective search.Whereas image processing for video indexingcurrently provides low level indec~s uch as visualtransitions and shot classification (Zhang et al1994), some research has investigated the use oflinguistic streams (e.g., closed captions, transcripts)to provide keyword-based indexes to video.
Story-based segmentation remains illusive.
For example,traditional text tiling approaches oftenundersegment broadcast news because of rapidtopic shifts (Mani et al 1997).
This paper takes acorpus-based approach to this problem, buildinglinguistic models based on an analysis of a digitalcollection of broadcast news, exploiting theregularity utilized by humans in signaling topicshifts to detect story segments.2.
Broadcast News AnalysisHuman communication is characterized by distinctdiscourse structure (Grosz and Sidner 1986) whichis used for a variety of purposes includingmanaging interaction between participants,mitigating limited attention, and signaling topicshifts.
In processing enre such as technical orjournalistic texts, programs can take advantage ofexplicit discourse cues (e.g., "the first", "the mostimportant") to perform tasks such as summarization(Paice 1981).
Our initial inability to segment topicsin closed caption news text using thesaurus basedsubject assessments (Liddy and Myaeng 1992)motivated an investigation of explicit turn takingsignals (e.g., anchor to reporter handoff).
Weanalyzed programs (e.g., CNN PrimeNews) from anover one year corpus of closed caption texts with theintention of creating models of discourse and othercues for segmentation.I~  .
.
.
.
.
.
Discourse Cuesc~ ~-- , .
.
-~,~,+: ,  __...--- Insert ions OV~IIIVHEAnl:h~r .>> TALKS BETWEEN RE S~.NTAT W~S gn,.~ T TEAMSTERS UN~N ~ ~ UPS ARE/ HAS M C*.'
E {C~E'V ~N CLOSER TO A DEAL UPS I~_L_O ~_N .lJl D U R IN G THE STRII< E 300MILLION DCt.
ARS A WEB~, AS TH~ TFA~qqT?~ cT?
'~ " ~ .
.
.
.
.
.
.
.
Fc "~'n I'~ ~TS TO>> STRIKES I VOLVhG THE TRANSPORTATION O~ PEOF%E ARE RULED B ~ CNEF~DERAL LA WALKOLrT S IN THE PACKAGE SHIPPING INDUSTRY BY ANOTHER LET'S'~?'
Om ion n.l~-- E j ro(s>> PRESIOENT CL~TON SAY THAT ALONE EXPLAINS HIS REPU 4T VEN( ANOSTOP THE UPS STRKE AS HE DID SO( MOST HS AGO WHEN IRL I~ PILOTS>~ THE AIRL~4E COMPANIES ~ECAUSE THg?
T A K E - - R EBY A FEDERAL LAW WHK~H GNES TH E SIO~14/T ~J??
~ H ~ ~.)
IN I ERV ~N E 1"~-'I=~I~?
"~ ISS LIBSTANTIAL EC.~f~C~vI?
0ANGER OP ~ TO THE COUNTRY THE UP~ ?GTRIKEWITH THE TEAMSTERS IS NOT COVERED BY THUpcaseFigure 1.
Closed Caption Challenges(CNN Prime News, August 17, 1997)While human captioners employ standard cues tosignal discourse shifts in the closed caption stream(e.g., ">>" is used to signal a speaker shift whereas">>>" signals a subject change), these can beerroneous, incomplete, or inconsistent.
Figure 1illustrates a typical excerpt from our corpus.
Ourcreation of a gold standard corpus of a variety ofbroadcast sources indicates that transcription worderror rates range from 2% for pre-recorded programssuch as 60 Minutes news magazine to 20% for livetranscriptions (including errors of insertion,deletion, and transposition).
This noisy datacomplicates robust story segmentation.8192.1 News Story Discourse StructureBroadcast news has a prevalent structure with oftenexplicit cues to signal story shifts.
For example,analysis of the structure of ABC World NewsTonight indicates:?
broadcasts start and end with the anchor?
reporter segments are preceded by an introductoryanchor segment and together they form a single story?
commercials serve as story boundariesSimilar but unique structure is also prevalent inmany other news programs uch as CNN PrimeNews (See Figure 1) or MS-NBC.
For example,the structure for the Jim Lehrer News Hourprovides not only segmentation i formation butalso content information for each segment.
Thus,the order of stories is consistently:?
preview of major stories of the day or in the broadcastprogram?
sponsor messages?
summary of the day's news(including some major stories)?
four to six major stories?
recap summary of the day's news?
sponsor messagesRecovering this structure would enable a user toview the four minute opening summary, retrievedaily news summaries, preview and retrieve majorstories, or browse a video table of contents, with orwithout commercials.2.2 Discourse Cues and Named EntitiesManual and semi-automated analysis of our newscorpora reveals that regular cues are used to signalthese shifts in discourse, although this structurevaries dramatically from source to source.
Forexample, CNN discourse cues can be classified intothe following categories (examples from 8/18/97):?
Start of Broadcast"GOOD EVENING, I 'M KATHLEEN KENNEDY, S ITT INGIN FOR JOIE CHEN.
"?
Anchor-to-Reporter Handoff"WE'RE JO INED BY CNN'S CHARLES ZEWE IN NEWORLEANS.
CHARLES??
Reporter-to-Anchor Handoff"CHARLES ZEWE, CNN, NEW ORLEANS"?
Cataphoric Segment"STILL  AHEAD ON PRIMENEWS"?
Broadcast End"THAT WRAPS UP THIS MONDAY EDIT ION OF"PRIMENEWS""The regularity o f  these discourse cues frombroadcast to broadcast provides an effectivefoundat ion for discourse-based segmentat ionroutines.
We have similarly d iscovered regulardiscourse cues in other news programs.
Forexample,  anchor/reporter and reporter/anchorhandoffs  in CNN Pr ime News or ABC News andother network programs are identif ied throughpattern matching o f  strings such as:?
(word) (word) ", ABC NEWS"?
"ABC'S CORRESPONDENT'' (word) (word)The pairs of words in parentheses correspond to thereporter's first and last names.
Combining thehandoffs with structural cues, such as knowing thatthe first and last speaker in the program will be theanchor, allow us differentiate anchor segments fromreporter segments.
By preprocessing the closedcaption text with a part of speech tagger and namedentity detector (Aberdeen et al 1995) retrained onclosed captions, we generalize search of text stringsto the following class of patterns:* (proper name) ", ABC NEWS"?
"ABC'S CORRESPONDENT'" (proper name)3.
Computational ImplementationOur discourse cue story segmentor has beenimplemented in the context of a multimedia (closedcaptioned text, audio, video) analysis system forweb based broadcast news navigation.
We employ afinite state machine to represent discourse statessuch as an anchor, reporter, or advertisting segment(See Figure 2).
We further enhance these withmultimedia cues (e.g.
detected Silence, black or logokeyframes) and temporal knowledge (indicated astime in Figure 2).
For example, from statisticalanalysis of CNN Prime News Programs, we knowthat weather segments appear on average 18 minutesafter the start of the news.820Figure 2.
Partial Time-Enhanced FSMAfter segmentation, the user is presented with ahierarchical navigation space of the news whichenables earch and retrieval of segmented stories orbrowsing stories by date, topic, named entity orkeyword (see Figure 3).
This is MITRE'sBroadcast News Navigator(http://www.mitre.org/resources/centers/advanced_info/g04f/bnn/mmhomeext.html).Named Ent~t~es byType Captions Story SummaryFigure 3.
Broadcast News NavigatorWe leverage the story segments and extractednamed entities to select he sentence with the mostnamed entities to serve as a single sentencesummary of a given segment.
Story structure isalso useful for multimedia summarization.
Forexample, we can select key frames or key wordsfrom the substructure which will likely contain themost meaningful content (e.g., an reporter segmentwithin an anchor segment).4.
EvaluationWe evaluated segmentor performance by measuringboth the precision and recall of segment boundariescompared to manual annotation of story boundarieswhere:1.
Precision - # of correct segment tags# of total segment tags2.
Recall = # of correct segment tags# of hand tags94C ~ -  T "~ 75Jim Lehrer News Hour I 77 52Table 1.
Segmentation PerformanceTable 1 presents average precision and recall resultsfor multiple programs after applying eneralized cuepatterns developed first for ABC as described inSection 2.2.
Recall degrades when porting thesesame algorithms to different news programs (e.g.,CNN, Jim Lehrer) given the genre differences asdescribed in Section 2.1.Errors in story boundary detection includeerroneously splitting a single story segment into twostory segments, and merging two contiguous torysegments into a single story segment.
Furthermore,given our error-driven transformation based propername taggers operate at approximately 80%precision and recall, this can adversely impactdiscourse cue detections.
Also, our preliminaryevaluation of speech transcription results in worderror rates of approximately 50%, which suggestnon captioned text is not yet feasible for this class ofsegmentation.We have just completed an empirical study (Merlinoand Maybury, forthcoming) with BNN users thatexplores the optimal mixture of media elementsshow in Figure 3 (e.g., keyframes, named entities,topics) in terms of speed and accuracy of storyidentification and comprehension tasks.
Keyfindings include that users perform better and prefermixed media presentations over just one media (e.g.,named entities or topic lists), and they are quickerand more accurate working from extracts andsummaries than from the source transcript or video.8216.
Conclusion and Future WorkWe have described and evaluated a news storysegmentation algorithm that detects news discoursestructure using discourse cue, s that exploit fixedexpressions and transformational-based, part ofspeech and named entity taggers created usingerror-driven learning.
The implementation utilizesa time-enhanced finite state automata thatrepresents discourse states and their expectedtemporal occurance in a news broadcast based onstatistical analysis of the corpus.
This provides animportant mechanism to enable topic tracking,indeed we take the text from each segment an runthis through a commercial topic identificationrouUne an provide the user with a list of the topclasses associated with each story (See Figure 3).The segmentor has been integrated into a system(BNN) for content-based news access and has beendeployed in a corporate intranet and is currentlybeing evaluated for deployment in the USgovernment and a national broadcastingcorporation.We have improved segmentation performance byexploiting cues in audio and visual streams (e.g.,speaker shifts, scene changes) (Maybury et al1997).
To obtain a better indication of annotatorreliability and for comparative evaluation, we needto measure interannotator agreement.
Futureresearch includes investigating the relationship ofother linguistic properties, such as co-reference,intonation contours, and lexical semanticscoherence to serve as a measure of cohesion thatmight further support story segmentation.
Finally,we are currently evaluating in user studies whichmix of media elements (e.g., key frame, namedentities, key sentence) are most effective inpresenting story segments for different informationseeking tasks (e.g., story identification,comprehension, correlation).AcknowledgementsAndy Merlino is the principal system developer ofBNN.
The Alembic sub-system is the result ofefforts by MITRE's Language Processing Groupincluding Marc Vilaln and John Aberdeen for part ofspeech proper name taggers, and David Day fortraining these on closed caption text.ReferencesAberdeen, J.; Burger, J.; Day, D.; Hirschman, L.;Robinson, P. and Vilain, M. (1995) "Description of tileAlembic System Used for MUC-6", Proceedings of theSixth Message Understanding Conference, Columbia,MD, 6-8 November, 1995.Brill, E. (1995) Transformation-based Error-DrivenLearning and Natural Language Processing: A CaseStudy in Part of Speech Tagging.
ComputationalLinguistics, 21(4).Grosz, B. J. and Sidner, C. July-September, (1986)"Attention, Intentions, and the Structure of Discourse.
"Computational Linguistics 12(3): 175-204.Liddy, E. and Myaeng, S. (1992) "DR-LINK'sLinguistic-Conceptual Approach to DocumentDetection", Proceedings of the First Text RetrievalConference, 1992, NIST.Mani, I., House, D., Maybury, M. and Green, M. (1997)Towards Content-based Browsing of Broadcast NewsVideo.
In Maybury, M.
(ed.)
Intelligent MultimediaInformation Retrieval, AAAI/MIT Press, 241-258.Merlino, A. and Maybury, M. forthcoming.
AnEmpirical Study of the Optimal Presentation ofMultimedia Summaries of Broadcast News.
In Mani, I.and Maybury, M.
(eds.)
Automated TextSummarizationMerlino, A., Morey, D. and Maybury, M. (1997)"Broadcast News Navigation using Story Segments",Proceedings of the ACM International MultimediaConference, Seattle, WA, November 8-14, 381-391.Paice, C. D. (1981) The Automatic Generation ofLiterature Abstracts: An Approach Based on theIdentification of Self-Indicating Phrases.
In Oddy, R.N., Robertson, S. E., van Rijsbergen, C. J., Williams,P.W.
(eds.)
Information Retrieval Research.
London:Butterworths, 172-191.Zhang, H. J.; Low, C. Y.; Smoliar, S. W. and Zhong, D.(1995) Video Parsing, Retrieval, and Browsing: AnIntegrated and Content-Based Solution.
proceedings ofACM Multimedia 95.
San Francisco, CA, p. 15-24.822
