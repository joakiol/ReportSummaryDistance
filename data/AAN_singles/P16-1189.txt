Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 2009?2018,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsSet-Theoretic Alignment for Comparable CorporaThierry Etchegoyhen and Andoni AzpeitiaVicomtech-IK4Mikeletegi Pasalekua, 57Donostia / San Sebasti?an, Gipuzkoa, Spain{tetchegoyhen, aazpeitia}@vicomtech.orgAbstractWe describe and evaluate a simple methodto extract parallel sentences from com-parable corpora.
The approach, termedSTACC, is based on expanded lexical setsand the Jaccard similarity coefficient.
Weevaluate our system against state-of-the-art methods on a large range of datasets indifferent domains, for ten language pairs,showing that it either matches or outper-forms current methods across the boardand gives significantly better results onthe noisiest datasets.
STACC is a portablemethod, requiring no particular adaptationfor new domains or language pairs, thusenabling the efficient mining of parallelsentences in comparable corpora.1 IntroductionWith the rise of data-driven machine translation,be it statistical (Brown et al, 1990), example-based (Nagao, 1984), or rooted in neural networks(Bahdanau et al, 2014), the need for large paral-lel corpora has increased accordingly.
Althoughquality bitexts have been made available over theyears (Tiedemann, 2012), creating parallel corporais a resource-consuming effort involving profes-sional human translation of large volumes of textsin multiple languages.
As a consequence, there isstill a lack of parallel data to properly model trans-lation across languages and domains.To overcome this limitation, special emphasishas been placed in the last two decades on theexploitation of comparable corpora, with the de-velopment of a range of methods to mine paral-lel sentences from texts addressing similar topicsin different languages.
The work we present fol-lows this line of research, describing and evaluat-ing a simple method that allows parallel sentencesto be efficiently mined in different languages anddomains with minimal adaptation effort.The method we describe, termed STACC, isbased on expanded lexical sets and the Jaccardsimilarity coefficient (Jaccard, 1901), which iscomputed as the ratio of set intersection overunion.
We evaluate this simple approach againststate-of-the-art methods for comparable sentencealignment on a variety of datasets for ten dif-ferent language pairs, showing that STACC eithermatches or outperforms competing approaches.The paper is organised as follows: Section 2 de-scribes related work on parallel sentence mining incomparable corpora; Section 3 presents the STACCmethod; Section 4 describes the experiments incomparable sentence alignment, including the de-scription of test corpora and systems, and an anal-ysis of the results; Section 5 presents results ob-tained with an optimised version of the alignmentprocess, beyond system comparison; finally, Sec-tion 6 draws conclusions from the work describedin the paper.2 Related workA large variety of techniques have been proposedto mine parallel sentences in comparable cor-pora.
One of the first approaches was proposedby (Zhao and Vogel, 2002), who combined sen-tence length and bilingual lexicon models undera maximum likelihood criterion.
(Munteanu andMarcu, 2002) explored the use of suffix trees, lateropting for maximum entropy-based binary classi-fication using a modified version of IBM Model 1word translation probabilities (Brown et al, 1993)2009and both general and alignment-specific features(Munteanu and Marcu, 2005).
(Fung and Cheung,2004) describe the first approach to tackle paral-lel sentence mining in very non-parallel corpora,using cosine similarity as their sentence selectioncriterion.Several approaches have employed full statisti-cal machine translation models instead of relyingonly on lexical tables.
(Abdul-Rauf and Schwenk,2009), for instance, apply the TER metric (Snoveret al, 2006) on fully machine translated output toidentify parallel sentences; (Sarikaya et al, 2009)use a similar approach but with BLEU (Papineniet al, 2002) as their similarity metric.
One of thenoted advantages of including full machine trans-lation is the ability to better model the complexfactors found in translation, e.g.
fertility and con-textual information, as compared to lexicon-basedapproaches.
The latter enable, in principle, thecapture of a larger set of lexical translation vari-ants, and do not require the training of completetranslation models.Sophisticated feature-based approaches havebeen developed in recent years in order to providea method that may apply to larger sets of languagepairs and domains.
(Stef?anescu et al, 2012) re-port improvements over previous methods with afeature-based sentence similarity measure, an ap-proach which is described in more detail in Sec-tion 4.2.1.
Another feature-rich approach is de-scribed in (Smith et al, 2010), showing improve-ments over standard and improved binary classi-fiers; we describe their model in more details inSection 4.2.2.Jaccard similarity, a core component of the ap-proach we describe, has been standardly used asa text similarity measure in information retrievaland text summarisation tasks, or to compute se-mantic similarity (Pilehvar et al, 2013).
For com-parable corpora, it has been notably employed by(Paramita et al, 2013), who estimate documentcomparability by computing the coefficient on asubset of translated source sentences, discardingthose containing large amounts of named enti-ties or numbers, and taking the average of thesesentence-level scores.
The method we present inthe next section builds on a related similarity mea-sure as a direct indicator of comparable sentencesimilarity.3 STACCSTACC is an approach to sentence similarity basedon expanded lexical sets, whose main goal is toprovide a simple yet effective procedure that canbe applied across domains and corpora with mini-mal adaptation and deployment costs.We start with the minimal set of bilingual infor-mation that can be automatically extracted froma seed parallel corpus, using lexical translationsdetermined and ranked according to IBM models;word translations are computed in both directionsusing the GIZA++ toolkit (Och and Ney, 2003).STACC relies on the Jaccard index, which de-fines set similarity as the ratio of set intersectionover union.
We base our comparable sentencesimilarity measure strictly on this index, applyingit to expanded lexical sets as described below.Let siand sjbe two tokenised and truecasedsentences in languages l1and l2, respectively, Sithe set of tokens in si, Sjthe set of tokens in sj,Tijthe set of expanded translations into l2for alltokens in Si, and Tjithe set of expanded transla-tions into l1for all tokens in Sj.
The STACC simi-larity score is then computed as in Equation 1:simstacc=|Tij?Sj||Tij?Sj|+|Tji?Si||Tji?Si|2(1)That is, the score is defined as the average of theJaccard similarity coefficients obtained betweensentence token sets and expanded lexical transla-tions in both directions.The translation sets Tijand Tjiare initiallycomputed from sentences siand sjby retain-ing the k-best lexical translations found in GIZAtables, if any.
Lexical translations are selectedaccording to the ranking provided by the pre-computed lexical probabilities but the specificprobability values are not used any further tocompute similarity:1all potential translations aremembers of the translation set as tokens.
Discard-ing this source of potentially exploitable informa-tion is mostly motivated by the relative reliabil-ity of lexical translation probabilities across do-mains.
Lexical translations are usually extractedfrom a different domain than that of the compa-rable corpora at hand, typically using profession-ally created institutional corpora such as Europarl(Koehn, 2005), and lexical distributions across1This differs from (Skadin?a et al, 2012), who include alexical translation feature where actual probabilities are usedto compute the final score.2010domains can be expected to be quite different.This casts doubt on the usefulness of using pre-computed translation probabilities and simple setmembership was favoured in our approach.The initial lexical translation sets undergo a firstexpansion step to capture morphological variation,using longest common prefix matching (hereafter,LCP).
To apply prefix matching to the minimal setof elements necessary, we compute the followingtwo set differences:?
Set of elements in the source to target trans-lation set that are not members of the targettoken set: T?ij= Tij?
Sj?
Set of elements in the target to source trans-lation set that are not members of the sourcetoken set: T?ji= Tji?
SiFor each element in T?ij(respectively T?ji) andeach element in Sj(respectively Si), if a commonprefix is found with a minimal length of more thann characters, the prefix is added to both translationsets.2This simplified approach to stemming removesthe need to rely on manually constructed endingslists to compute similarity or on a complete mor-phological analyser, which might not be avail-able at all for under-resourced languages.
It isalso computationally more efficient as it exploitsthe nature of the alignment problem to reduce thesearch space: instead of matching each source andtarget word against every potential ending, withhundreds of possible endings in some languages,only the prefixes of word pairs within the sub-sets created through set difference need to be com-pared using LCP.Another set expansion operation is defined tohandle named entities, which are strong indicatorsof potential alignment, given their low relative fre-quency, and are likely to be missing from transla-tion tables trained on a different domain.
Whilecreating the previously defined lexical translationsets from truecased sentences, capitalised tokensthat are not found in the translation tables areadded to the translation sets.
Numbers are simi-larly handled and added to the expanded sets, asthey can also act as alignment indicators, in par-ticular when they denote dates.These two expansions steps are essential to asuccessful use of Jaccard similarity for compara-ble sentence alignment.
For instance, LCP gives2Throughout the experiments we describe, n was set to 3.a 2.9 points improvement in F1 measure on theinitial Basque-Spanish test set described in Sec-tion 4.1, whereas the NE/Number expansion re-sulted in a 1.3 points gain; the two expansionscombined gave a 4.3 points increase in terms ofF1 measure.
For the English-Bulgarian pair on theinitial Wikipedia test set, the gains were 3.7, 2.6and 5.5, respectively.
Combining the two oper-ations thus contributed to the improvements overthe state of the art described in Section 4.3.No additional operations are performed on thecreated sets, and in particular no filtering is ap-plied, with punctuation and functional words keptalongside content words in the final sets.
This no-tably eliminates the use of stop word lists from thecomputation of similarity.Although it builds on fairly standard ideas, suchas the use of GIZA tables or the Jaccard index, theapproach is original in its conjoined use of theseelements with surface-based information and sim-ple set-theoretic operations to form a similarity as-sessment mechanism that proved efficient on com-parable corpora, as shown in the next section.4 Comparable sentence alignmentWe performed a systematic comparison be-tween different approaches to comparable sen-tence alignment on a variety of comparable cor-pora and language pairs.
This section describesthe components of the experimental setup.4.1 CorporaThree core sets of corpora were used in the evalu-ation, which we describe in turn.
The selected testsets, all manually aligned, were used in differentsettings with gradual amounts of alignment noiseadded to the original sets.
The goal of noisificationis to assess the behavior of each approach in differ-ent scenarios and evaluate their ability to properlyalign data from ideal conditions to gradually nois-ier environments, the latter being a more realisticcase when dealing with comparable corpora.The first corpus consists in the public datasetscreated within the Accurat project.3The corpuscovers 7 language pairs, each one composed ofEnglish and an under-resourced language.
Thedatasets contain manually verified alignments thatwere created from news articles.
We noisi-fied these datasets by adding sentences from the3http://www.accurat-project.eu/.
The corpus is availablefrom: http://metashare.elda.org/repository/search/?q=accurat2011TEST SETS EN-DE EN-EL EN-ET EN-LT EN-LV EN-RO EN-SL1:1 ATS: 512 ATS: 512 ATS: 512 ATS: 512 ATS: 512 ATS: 512 ATS: 5122:1ATS: 512AOC: 512ATS: 512AOC: 512ATS: 512AOC: 512ATS: 512AOC: 512ATS: 512AOC: 512ATS: 512AOC: 512ATS: 512AOC: 512100:1ATS: 512AOC: 6891EUP: 43797ATS: 512AOC: 24276EUP: 26412ATS: 512AOC: 50688ATS: 512AOC: 50688ATS: 512AOC: 50688ATS: 512AOC: 50688ATS: 512AOC: 15857EUP: 34831Table 1: Accurat evaluation setsTEST SETS BG-EN DE-EN ES-EN1:1 WTS: 516 WTS: 314 WTS: 500100:1WTS: 516EUP: 51084WTS: 314NC: 31086WTS: 500NC: 49500Table 2: Wikipedia evaluation setsTEST SETS ES-EU1:1 500-500EITB NOISE1 1000-1000EITB NOISE2 1000-1500Table 3: EITB evaluation setsoriginal comparable corpora collected within theproject, creating the following additional variants:(i) a 2:1 noisified version, where for each sentencein the original sets, 2 additional sentences withoutcorresponding alignments were added; and (ii) a100:1 noisified version with 100 sentences addedfor each sentence in the test sets.
For each lan-guage pair, the additional sentences were takenfrom the initial portion of the selected additionalcorpora in one language and the final portion inthe other language.
For the 2:1 datasets, and the100:1 variants in some language pairs, the originalcomparable corpora were used as additional data.For other language pairs, creating the 100:1 vari-ant required adding sentences from different cor-pora to reach the required amount of data.
Table 1describes the final datasets used in the evaluation.4As a second corpus, we used the data describedin (Smith et al, 2010).5The texts were ex-tracted from Wikipedia articles in 3 language pairs(English-German, English-Spanish and English-Bulgarian) and manually annotated for paral-lelism.
We used the provided test sets (here-after, WTS) and added a 100:1 noisified variant us-ing sentences from the News Crawl corpus6forEnglish-German and English-Spanish, and fromEuroparl for the English-Bulgarian pair.
Table 24In the table, ATS refers to the Accurat test sets, AOC tothe Accurat original corpora, and EUP to the Europarl corpus.5Available at: http://research.microsoft.com/en-us/people/chrisq/wikidownload.aspx.6Refered to as NC here and available from:http://www.statmt.org/wmt13/translation-task.html.describes these datasets, to which we will refercollectively as the Wikipedia corpus.Finally, we used the EITB corpus, composed ofnews generated by the Basque Country?s publicbroadcasting service.7The news are written in-dependently in Basque and Spanish but refer tothe same specific events and the corpus can thusbe categorized as strongly comparable.
We de-fined initial test sets of 500 manually aligned sen-tences in each language, and created two noisifiedvariants: (i) a test set with 500 additional sen-tences in both languages, and (ii) a test set with500 additional sentences in Spanish and 1000 inBasque.
All additional sentences were taken fromunaligned portions of the same EITB corpus.
Ta-ble 3 summarises the EITB test sets.The selected corpora thus cover 10 different lan-guage pairs and different domains, with varyingdegrees of noisification, and provide for a largeand diverse comparison set.4.2 SystemsThree approaches were evaluated against the pre-viously described corpora: LEXACC (Stef?anescuet al, 2012), the STACC method described in Sec-tion 3, and the approach based on ConditionalRandom Fields described in (Smith et al, 2010),to which we will refer as CRF.
The latter was onlyevaluated on the Wikipedia corpus, using the re-7Euskal Irrati Telebista (EITB): http://www.eitb.eus.
Thecorpus was provided courtesy of EITB and will be made avail-able to the research community.2012sults reported in the aforementioned article, as thetools to apply this method were not available tous; both LEXACC and STACC were evaluated onall test sets.LEXACC was selected given its reported perfor-mance and its aim at portability across domainsand language pairs; the system is also available aspart of the Accurat toolkit,8which allowed for adirect comparison with STACC on all datasets.The CRF approach has proven more effec-tive than standard classifier-based methods on theWikipedia datasets, with published results on pub-lically available test sets, and was thus selectedas an alternative approach to comparable sentencealignment.Both approaches are based on sophisticatedmethods with demonstrated improvements overthe state-of-the-art, thus providing strong base-lines for system comparison.4.2.1 LEXACCLEXACC is a fast parallel sentence mining systembased on a cross-linguistic information retrieval(CLIR) approach.
It uses the Lucene search en-gine9in two major steps: target sentences are firstindexed by the search engine, and a search queryis built from a translation of content words in thesource sentence to retrieve alignment candidates.The query is constructed using IBM Model 1 lexi-cal translation tables, extracted from seed parallelcorporaThe alignment metric in LEXACC is a transla-tion similarity measure based on 5 feature func-tions briefly described here (see (Stef?anescu et al,2012) for a detailed description):?
f1measures source-target candidate pairsstrength in terms of content word translationand string similarity;?
f2is similar to f1but applies to functionalwords, as identified in manually created stopword lists;?
f3measures content word alignment oblique-ness defined as a discounted correlation mea-sure;?
f4is a binary feature that compares the num-ber of initial/final aligned word translationsover a pre-defined threshold;8http://www.accurat-project.eu/index.php?p=accurat-toolkit9http://lucenenet.apache.org/?
f5is a second binary feature which evaluatesif the source and target sentences end with thesame punctuation.The similarity measure is then computed ac-cording to the sum of weighted feature functions,with optimal weights determined by means of lo-gistic regression.
We used the optimal featureweights described in (Stef?anescu et al, 2012) forthe language pairs in the Accurat corpus and theprovided default weights for English-Spanish andEnglish-Bulgarian; for Basque-Spanish, optimalweights were estimated through logistic regressionon a training set formed with 9500 positive paral-lel examples from the IVAP corpus10and an equalamount of non-parallel negative examples.For the experiments, all lexical translation ta-bles were created with GIZA++ on the JRC-AcquisCommunautaire corpus.11Lucene searches wereset to return a maximum of 100 candidates foreach source sentence.
We used the default setupfor LEXACC, except for two minor changes.
First,we removed the initial Lucene search constraintwhich was set to discard identical source and tar-get sentences, a setting which prevented the re-trieval of valid news candidates such as sports re-sults.
Secondly, we increased the length ratio filterfrom 1.5 to 7.5, as the initial value was too restric-tive for the Basque-Spanish corpus.
Both changeswere thus meant to retrieve the most accurate setof alignment candidates, in order to get meaning-ful results on the test sets with both methods.4.2.2 Conditional Random FieldsThe model we refer to as CRF (Smith et al, 2010)is a first order linear chain Conditional RandomField (Lafferty et al, 2001), where for each sourcesentence a hidden variable indicates the corre-sponding target sentence to which it is aligned, ornull if there is no such target sentence.
This sys-tem was compared to the standard binary classifierof (Munteanu and Marcu, 2005) and to a rankingvariant designed by the authors to avoid class im-balance issues that arise with binary classification.On the Wikipedia test sets, the CRF approach gave10Extracted from the translation memories re-leased by the Basque Public Administration Institute(http://opendata.euskadi.eus/catalogo/-/memorias-de-traduccion-del-servicio-oficial-de-traductores-del-ivap/),which consist of professional translations of public adminis-tration texts.11We used the latest available version of the cor-pus, as of November 2015, in the OPUS repository:http://opus.lingfil.uu.se/JRC-Acquis.php.2013the best results overall and was thus selected forour system comparison.The sequence model comprises the followingfeatures:?
A word alignment feature set, based on IBMModel 1 and HMM alignments, which in-cludes: log probability of the alignment;number of aligned/unaligned words; longestaligned/unaligned sequence of words; andnumber of words for different degrees of fer-tility.?
Two sentence-related features: source andtarget length ratio modeled through a Pois-son distribution (Moore, 2002), and relativeposition of source and target sentences in thedocument.?
A set of distortion features measuring the dif-ference in position between the previous andcurrent aligned sentences.?
A set of features based on Wikipedia markup,including matching and non-matching linksfor alignment candidates.?
A set of lexicon features based on a prob-abilistic model of word pair alignments,trained on a set of annotated Wikipedia ar-ticles.
The lexicon-based feature set includesthe HMM translation probability, word-basedpositional differences, orthographic similar-ity, context translation similarity and distri-butional similarity.The seed parallel data were based on the Eu-roparl corpus for Spanish and German and theJRC-Aquis corpus for Bulgarian.
The authors alsoincluded article titles of parallel Wikipedia doc-uments and Wiktionary translations as additionalseed data.4.2.3 STACCIn order to establish a fair comparison betweenLEXACC and STACC, all shared settings were iden-tical.
Thus, lexical translations were based on thesame previously described GIZA tables extractedfrom the JRC corpus, and STACC alignment wasperformed on the same sets of candidates retrievedfrom the Lucene searches by LEXACC for eachlanguage pair.As described in Section 3, STACC is based onthe k-best translations provided by lexical transla-tion tables.
For the experiments, k was set to 5, avalue arbitrarily determined to be an optimal com-promise between overcrowding the sets with un-likely translations and limiting translation candi-dates to minimal translation variants.
Experiment-ing with different values on the test sets showedthat this value for k was not actually the optimalone for some language pairs, with e.g.
a 2.9 pointgain in F1 measure when setting k to 2 for English-Greek on the initial Accurat test set.12The results we present in the next section arethus not the best achievable ones using the STACCapproach.
Nonetheless, we maintained the use ofa default value because of the lack of in-domaindevelopment sets on which an optimal value couldbe fairly computed.4.3 ResultsTo evaluate the accuracy of the tested methods,precision was taken as the ratio of correct align-ments over predicted alignments, and recall as theratio of correct alignments over true alignments.We present results in terms of F1 measure, as weseek an optimal balance between alignment preci-sion and recall.Table 4 presents the results on the Accurat testsets for LEXACC and STACC using their respec-tive optimal similarity thresholds.13On the 21test sets, the two systems were tied on two oc-casions, with STACC obtaining better results in89.5% of the remaining cases.
On the noisiestdatasets, STACC was consistently and markedlybetter across language pairs.The results on the Wikipedia test sets are shownin Table 5.
For English-Spanish and English-German, both approaches performed quite simi-larily on the initial test sets, with STACC obtainingthe best results on the noisier sets.The results for English-Bulgarian are interest-ing, as this is the only case where LEXACC outper-forms STACC on both the clean and noisy datasets.The data used for noisification in this case mayhave had an effect on the results.
Data extractedfrom Europarl, which compose the entire noisifi-12Note that similar issues would arise if the selected trans-lations were determined based on thresholds over translationprobabilities, as the thresholds would need to be empiricallyset as well.13The optimal thresholds were determined as the valuesproviding the best results on the test sets.
This would obvi-ously not be an available threshold selection method whenmining comparable corpora, where a default value wouldhave to be used instead.
Such a default value would howevernot allow for a fair comparison of the systems.2014SYSTEM TEST SETS EN-DE EN-EL EN-ET EN-LT EN-LV EN-RO EN-SLLEXACC 1:1 96.0 89.5 88.9 93.1 95.0 99.4 88.5STACC 1:1 96.7 88.0 92.0 96.1 96.6 98.8 89.5LEXACC 2:1 83.4 83.2 73.9 81.2 83.8 95.3 81.6STACC 2:1 89.2 83.2 79.9 86.9 88.2 95.3 82.3LEXACC 100:1 16.6 22.7 34.2 45.1 45.1 70.4 24.9STACC 100:1 33.7 37.3 42.5 56.0 56.2 75.7 35.3Table 4: Best F1 measures on the Accurat evaluation setsSYSTEM TEST SETS EN-BG EN-DE EN-ESLEXACC 1:1 87.1 82.7 98.2STACC 1:1 84.9 82.0 99.7LEXACC 100:1 27.6 31.0 66.2STACC 100:1 16.6 35.8 73.3Table 5: Best F1 measures on the Wikipedia evaluation setsCRF LEXACC STACCLANGUAGE PAIR R@90 R@80 R@90 R@80 R@90 R@80EN-BG 72.0 81.8 80.4?
80.4?
80.2 81.6?EN-DE 58.7 68.8 75.2 78.7 68.8 81.8?EN-ES 90.4 93.7 97.0?
97.0?
99.6?
99.6?Table 6: Targeted recall on the Wikipedia evaluation setsSYSTEM TEST SETS ES-EULEXACC 1:1 77.2LEXACC DF 1:1 80.2STACC 1:1 90.9LEXACC EITB NOISE1 59.2LEXACC DF EITB NOISE1 62.2STACC EITB NOISE1 82.8LEXACC EITB NOISE2 54.5LEXACC DF EITB NOISE2 57.4STACC EITB NOISE2 79.5Table 7: Best F1 measures on the EITB evaluation sets33.7 37.342.556.0 56.275.735.3 38.542.2 43.659.2 57.978.337.8en-de en-el en-et en-lt en-lv en-ro en-slF1stacc stacc_optFigure 1: STACC optimisation results on the Accurat 100:1 test sets2015cation set for this language pair, is closer to theJRC vocabulary than the original comparable dataon which the alignment process would take placein real-world conditions.
Although we have notthoroughly tested the impact of this variable, it ispossible that those datasets are more confusing foran approach such as STACC, which is based mostlyon lexical information extracted from seed paral-lel data, than for a feature-based approach wheresome features, like the boolean punctuation-basedones in LEXACC, may compensate for erroneousalignments due to artificial domain vocabularyoverlap.
Determining if this hypothesis is indeedcorrect would require further experiments beyondthe scope of this paperTo include the CRF approach in the comparison,we used two of the provided measures, namely re-call obtained at precisions of 80 and 90 percent onthe 1:1 test sets.14We report results obtained withthe best variant of CRF, namely the model whichincludes Wikipedia and lexicon features, with in-tersected results from both directions.
Results arereported in Table 6.
Although the comparison waslimited in this case, results were in favour of LEX-ACC and STACC on targeted recall measures for theWikipedia datasets.Finally, both LEXACC and STACC were com-pared against the EITB test sets, with results shownin Table 7.
For this language pair, STACC per-formed markedly better with differences of up to25 points.
A likely explanation for these results isthe nature of the features that compose the LEX-ACC model.
In particular the features related toalignment obliqueness and number of initial/finalaligned words might be detrimental in the case ofBasque, which exhibits free word order.
Giventhe poor results obtained with feature weights op-timised on the IVAP corpus, we also checked theresults using the provided default weights.
Thisresulted in slightly better performance, as shownin the rows named LEXACC DF in Table 7, thoughstill far from the results achieved with STACC.4.4 DiscussionOverall, STACC provided the best results acrossdomains and language pairs, in particular for nois-ier datasets.
Additionally, the approach has several14Note that, for both LEXACC and STACC, in some sce-narios even the lowest thresholds gave precisions higher than90, rendering the comparison moot.
We indicate these caseswith a ?
sign next to the highest recall obtained at the closestprecision to the arbitrary 80 and 90 precision points.advantages over existing methods and systems forcomparable segment alignment.First, it is undoubtedly simpler, as it requiresbut minimal information to reach optimal results.Lexical tables and simple set expansion operationsbased on surface properties of the tokens are theonly components of the approach, as compared tothe more sophisticated feature-based approacheswhich rely on larger sets of components for whichoptimal weights need to be computed prior to ap-plying the models.Secondly, because of its simplicity, STACC is amore portable method, as is it is not necessary toperform any type of adaptation for new domainsand language pairs, nor to rely on domain-specificinformation such as link structure in Wikipedia.
Inactual practice, portability is an important issuewhich hinders on the exploitation of comparablecorpora.
An efficient yet easily deployable methodis therefore a welcome addition to the toolset forparallel data extraction.Finally, STACC results in fewer computationalsteps when compared to more complex feature-based methods.
First, it involves simple binaryset intersection and union operations for the com-putation of similarity, instead of conjoined fea-ture computation on larger component sets.
Sec-ondly, the approach relies on tractable set differ-ences for its most computationally expensive op-eration of longest common prefix matching, com-pared to matching all tokens against lists of wordendings which can be quite large, notably in thecase of agglutinative languages.Although promising, the approach could be fur-ther evaluated, and potentially improved, alongtwo main lines.It might be worth exploring for instance the im-pact of filtering alignment candidates accordingto the relative position of sentence pairs in theoriginal source and target documents, a document-level property notably exploited by (Smith et al,2010).
As the STACC approach is featureless,and meant to remain as such in order to main-tain its portability and ease of deployment, filter-ing distant sentence pairs would need to take placeprior to the computation of alignment scores.
Asimple approach compatible with STACC wouldconsist in constraining candidate sets by includ-ing sentence position information when perform-ing indexing and candidate querying in a CLIR ap-proach.
This would provide an additional evalua-2016tion of the accuracy of the approach in scenarioswhere document-level information is exploitable.Additionally, given the importance of k-bestlexical translations in computing STACC similarity,variations in lexical coverage obtained with dif-ferent translation tables can be expected to impactalignment accuracy.
Although mining comparablecorpora usually requires the use of seed translationknowledge extracted from a domain that differsfrom the one being mined, default tables with widelexical coverage can be built from existing parallelcorpora in different domains.
Thus, improvementsmight be obtained with larger and more diverse ta-bles than the ones used in the experiments reportedhere, which were based on translations extractedfrom a single domain.
A precise assessment of theevolution of alignment accuracy given variationsin lexical translation coverage is left for future re-search.5 Alignment optimisationAs previously mentioned, for both LEXACC andSTACC, alignments were computed for everysource sentence against candidate translations re-trieved by Lucene and all cases where a given tar-get sentence has more than one source alignmentwere left as is.Although this methodology enabled a fair com-parison between the two systems, it evidently im-pacts alignment accuracy.
One simple optimisa-tion is to retain only the best overall source-targetalignments, discarding all alignments establishedbetween a given source sentence and a target sen-tence if the latter is linked to better scoring sourcesentences.The net effect of this procedure is the promotionof better alignments, as some correct alignmentswould not be hidden anymore by other better scor-ing shared alignments.
This is most likely to occurwith source-target pairs that are close variants ofeach other, with close similarity scores.We applied this simple optimisation to the Ac-curat test sets and observed improvements acrossthe board, as shown in Figure 1.
Depending on ac-tual usage, this optimised version of STACC align-ment can constitute the best alternative for theextraction of parallel sentences from comparablecorpora.6 ConclusionsWe described a simple approach to comparablesentence alignment, termed STACC, which is basedon automatically extracted seed lexical transla-tions, the Jaccard similarity coefficient, and sim-ple set expansion operations that target named en-tities, numbers, and morphological variation usinglongest common prefixes.
Building on fairly stan-dard components for the computation of similar-ity, this method is shown to perform better thancurrent alternatives.The approach was evaluated on a large rangeof datasets from various domains for ten languagepairs, giving the best results overall when com-pared to sophisticated state-of-the-art methods.STACC also performed better than competing ap-proaches on noisier corpora, showing promises forthe exploitation of the typically noisy data foundwhen mining comparable corpora.STACC is a highly portable method which re-quires no adaptation for its application to new do-mains and language pairs.
It thus allows for thefast deployment of a crucial component in compa-rable corpora alignment, which opens the path foran increase in the amount of such corpora that canbe exploited in the future.AcknowledgmentsThis work was partially funded by the SpanishMinistry of Economy and Competitiveness and theDepartment of Economic Development and Com-petitiveness of the Basque Government throughthe AdapTA (RTC-2015-3627-7), PLATA (IG-2014/00037) and TRADIN (IG-2015/0000347)projects.
We would like to thank MondragonLin-gua Translation & Communication as coordinatorof these projects and the three anonymous review-ers for their helpful feedback and suggestions.ReferencesSadaf Abdul-Rauf and Holger Schwenk.
2009.
On theuse of comparable corpora to improve SMT perfor-mance.
In Proceedings of the 12th Conference of theEuropean Chapter of the Association for Computa-tional Linguistics, EACL ?09, pages 16?23, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-gio.
2014.
Neural machine translation by jointlylearning to align and translate.
arXiv:1409.0473.2017Peter F Brown, John Cocke, Stephen A Della Pietra,Vincent J Della Pietra, Fredrick Jelinek, John D Laf-ferty, Robert L Mercer, and Paul S Roossin.
1990.A statistical approach to machine translation.
Com-putational linguistics, 16(2):79?85.Peter F Brown, Vincent J Della Pietra, Stephen A DellaPietra, and Robert L Mercer.
1993.
The mathemat-ics of statistical machine translation: Parameter esti-mation.
Computational linguistics, 19(2):263?311.Pascale Fung and Percy Cheung.
2004.
Mining VeryNon-Parallel Corpora: Parallel Sentence and Lexi-con Extraction via Bootstrapping and E.M.
In Pro-ceedings of Empirical Methods in Natural LanguageProcessing, pages 57?63.Paul Jaccard.
1901.
Distribution de la flore alpinedans le bassin des Dranses et dans quelques r?egionsvoisines.
Bulletin de la Soci?et?e Vaudoise des Sci-ences Naturelles, 37:241 ?
272.Philipp Koehn.
2005.
Europarl: A Parallel Corpus forStatistical Machine Translation.
In Proceedings ofthe 10th Machine Translation Summit, pages 79?86.John D. Lafferty, Andrew McCallum, and FernandoC.
N. Pereira.
2001.
Conditional random fields:Probabilistic models for segmenting and labeling se-quence data.
In Proceedings of the Eighteenth Inter-national Conference on Machine Learning, ICML?01, pages 282?289, San Francisco, CA, USA.
Mor-gan Kaufmann Publishers Inc.Robert C. Moore.
2002.
Fast and accurate sentencealignment of bilingual corpora.
In Proceedings ofthe 5th Conference of the Association for MachineTranslation in the Americas on Machine Transla-tion: From Research to Real Users, AMTA ?02,pages 135?144, London, UK, UK.
Springer-Verlag.Dragos Stefan Munteanu and Daniel Marcu.
2002.Processing Comparable Corpora With BilingualSuffix Trees.
In Proceedings of the Conference onEmpirical Methods in Natural Language Process-ing, pages 289?295.
Association for ComputationalLinguistics.Dragos Stefan Munteanu and Daniel Marcu.
2005.
Im-proving machine translation performance by exploit-ing non-parallel corpora.
Computational Linguis-tics, 31(4):477?504.Makoto Nagao.
1984.
A Framework for a MechanicalTranslation Between Japanese and English by Anal-ogy Principle.
In Proceedings of the InternationalNATO Symposium on Artificial and Human Intelli-gence, pages 173?180, New York, NY, USA.
Else-vier North-Holland, Inc.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational linguistics, 29(1):19?51.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: A Method for AutomaticEvaluation of Machine Translation.
In Proceedingsof the 40th Annual Meeting on Association for Com-putational Linguistics, pages 311?318.
Associationfor Computational Linguistics.Monica Lestari Paramita, David Guthrie, EvangelosKanoulas, Rob Gaizauskas, Paul Clough, and MarkSanderson.
2013.
Methods for collection and evalu-ation of comparable documents.
In Building and Us-ing Comparable Corpora, pages 93?112.
Springer.Mohammad Taher Pilehvar, David Jurgens, andRoberto Navigli.
2013.
Align, disambiguate andwalk: A unified approach for measuring semanticsimilarity.
In Proceedings of the 51st meeting of theAssociation for Computational Linguistics, pages1341?1351.
The Association for Computational Lin-guistics.Ruhi Sarikaya, Sameer Maskey, R Zhang, Ea-EeJan, D Wang, Bhuvana Ramabhadran, and SalimRoukos.
2009.
Iterative sentence-pair extractionfrom quasi-parallel corpora for machine translation.In Proceedings of InterSpeech, pages 432?435.Inguna Skadin?a, Ahmet Aker, Nikos Mastropavlos,Fangzhong Su, Dan Tufis, Mateja Verlic, AndrejsVasil?jevs, Bogdan Babych, Paul Clough, RobertGaizauskas, et al 2012.
Collecting and using com-parable corpora for statistical machine translation.In Proceedings of the 8th International Conferenceon Language Resources and Evaluation.Jason R. Smith, Chris Quirk, and Kristina Toutanova.2010.
Extracting parallel sentences from com-parable corpora using document level alignment.In Human Language Technologies: The 2010 An-nual Conference of the North American Chapter ofthe Association for Computational Linguistics, HLT?10, pages 403?411, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A study oftranslation edit rate with targeted human annotation.In Proceedings of Association for Machine Transla-tion in the Americas, pages 223?231.Dan Stef?anescu, Radu Ion, and Sabine Hunsicker.2012.
Hybrid parallel sentence mining from com-parable corpora.
In Proceedings of the 16th Con-ference of the European Association for MachineTranslation, pages 137?144.J?org Tiedemann.
2012.
Parallel data, tools and inter-faces in OPUS.
In Proceedings of the 8th LanguageResources and Evaluation Conference, pages 2214?2218.Bing Zhao and Stephan Vogel.
2002.
Adaptive parallelsentences mining from web bilingual news collec-tion.
In Proceedings of the 2002 IEEE InternationalConference on Data Mining, pages 745?748.
IEEE.2018
