Semantic and Discourse Informationfor Text-to-Speech IntonationLaur ie  H iyakumoto ,  Scot t  P revost  &: Jus t ine  Casse l lThe Media LaboratoryMassachusetts Institute of Technology20 Ames Street, Cambridge, MA USA 02139{hyaku, p revost ,  jus t  ?ne}?media.
fair.
eduAbst rac tConcept-to-Speech (CTS) systems,which aim to synthesize speech fromsemantic information and discoursecontext, have succeeded in produc-ing more appropriate and natural-sounding prosody than text-to-speech(TTS) systems, which rely mostly onsyntactic and orthographic informa-tion.
In this paper, we show howrecent advances in CTS systems canbe used to improve intonation in textreading systems for English.
Specif-ically, following (Prevost, 1995; Pre-vost, 1996), we show how informa-tion structure is used by our programto produce intonational patterns withcontext-appropriate variation in pitchaccent type and prominence.
Follow-ing (Cahn, 1994; Cahn, 1997), we alsoshow how some of the semantic infor-mation used by such CTS systems canbe drawn from WordNet (Miller et al,1993), a large-scale semantic lexicon.1 In t roduct ionAlthough theories relating intonational patternswith discourse phenomena have been proposed(Pierrehumbert and Hirschberg, 1990), existingTTS systems, and even CTS systems, often failto exploit them.
The most advanced intonationsystems (Hirschberg, 1990; Hirschberg, 1993)have relied on elements of discourse contextwhich are relatively easy to extract from text,such as lexical givenness.
Our system augmentsthis approach by analyzing information struc-ture and drawing semantic information from alarge-scale semantic database.Information structure is identified by firstdividing utterances into semantic propositionsrather than syntactic constituents (cf.
(Mon-aghan, 1994)), in accordance with our beliefthat intonational domains are often orthogonalto traditional syntactic onstituents.
1 These se-mantic propositions are then sub-divided intotheme (or topic) and theme (or comment).The theme of the proposition represents a linkto prior utterances, whereas the rheme pro-vides the core contribution--roughly, the newor interesting part--of the proposition.
Basedon previous intonation generation work (Pre-vost and Steedman, 1994), thematic and rhe-matic items requiring accentuation are assignedLq-H* and H* pitch accents respectively.The notion that large databases in TTSsystems can substitute for application-specificknowledge bases has been suggested by (Horneet al, 1993) and (Cahn, 1994).
FollowingCahn's proposal (Cahn, 1994) and implemen-tation (Cahn, 1997), we employ WordNet toidentify lexical items related by synonymy, hy-pernymy or hyponymy, and also to identify con-trastive lexical items.
However, our use of infor-mation structure situates our work in a differenttheoretical framework from Cahn's.1 (Steedman, 1991) and (Prevost and Steedman, I994)show how the correspondence b tween intonationalphrasing and semantic onstituency an be modeled byCombinatory Categorial Grammar (CCG), a formalismallowing amore flexible notion of syntactic onstituency.,17In the remainder of this paper we describehow our present TTS research builds on thegrowing body of CTS research.
First we presentthe motivation for our approach and the under-lying theoretical model of intonation.
Then webriefly introduce WordNet.
Next, we describethe phases of computation and discuss the roleof WordNet in making accentability decisions.Finally, we present sample output of the system,explore areas for improvement, and summarizeour results.2 Semant ic  and  D iscourse  E f fects  onIn tonat ionThe effects of "givenness" on the accentabil-ity of lexical items has been examined insome detail and has led to the development ofintonation algorithms for both text-to-speech(Hirschberg, 1990; Hirschberg, 1993; Mon-aghan, 1991; Terken and Hirschberg, 1994) andconcept-to-speech systems (Monaghan, 1994).While the strategy of accenting open-class itemson first mention often produces appropriateand natural-sounding intonation in synthesizedspeech, such algorithms fail to account for cer-tain accentual patterns that occur with someregularity in natural speech, such as items ac-cented to mark an explicit contrast amongthe salient discourse ntities.
In addition, thegiven/new distinction alone does not seem toaccount for the variation among accent ypesfound in natural speech.
2 Unfortunately, suchissues have been difficult to resolve for text-to-speech because of the paucity of semantica.nd discourse-level information readily availablewithout sophisticated text understanding algo-rithms and robust knowledge representations.Previous CTS work (Prevost, 1995; Prevost,1996; Prevost and Steedman, 1994) showed thatboth contrastive accentual patterns and lim-ited pitch accent variation could be modeledin a spoken language generation system.
Thepresent work incorporates these results in a2Of course, the granularity of the given/new distinc-|.ion may be at issue here.
The relationship of accenttypes to the given/new taxonomy proposed by (Prince,\[981) may warrant more xploration i  a computationalfl'amework.text-to-speech system, using a similar represen-tation for discourse context (i.e.
informationstructure), and replacing the domain-specificknowledge base with WordNet.We represent local discourse context using atwo-tiered information structure framework.
Inthe higher tier, propositions are divided intotheme and rheme.
The theme represents whatthe proposition is about and provides the con-textual link to prior utterances.
The rhemeprovides the core contribution of the proposi-tion to the discourse--the material the listeneris unlikely to predict from context.
In the sim-plest case, where an utterance conveys a singleproposition, the division into theme and rhemeis often straightforward, as shown in the ques-tion/answer pair in Figure 1.
(Steedman, 1991) and (Prevost and Steed-man, 1994) argue that for the class of utter-ances exemplified by these examples, the rhemeof the utterance often occurs with an intona-tional (intermediate) phrase carrying the H* L-L% (H* L-) tune, while the theme, when itbears any marked intonational features, oftencarries the L-t-H* L-L?~ (L-I-H* L-) tune.While this mapping of thematic constituentsonto intonational tunes is certainly an oversim-plification, it has been quite useful in previ-ous concept-to-speech work.
We are currentlyusing the Boston University radio news cor-pus (Ostendorf, Price, and Shattuck-Hufnagel,1995) to compile statistics to support our use ofthis mapping.
3 Preliminary results show thatthe H* accent is most prevalent, occurringmore than fifty percent of the time.
!H* andL--t-H* occur less frequently than H*, but morethan any of the other possible accents.
We takethe prevalence ofH* and L-t-H* in the corpusto support our decision to focus on these accenttypes.Given the mapping of tunes onto thematicand rhematic phrases, one must still determinewhich items within those phrases are to be ac-cented.
We consider such items to be in theme-or rheme-focus, the secondary tier of our in-3This corpus is partially annotated with ToBI-style(Pitrelli, Beckman, and Hirschberg, 1994) intonationmarkings.48Q: I know the SMART programmer w ote the SPEEDY algorithm,A:(But WHICH algorithm) (did the STUPIDL+H* L-H% H*(The STUPID programmerL+H*theme-focusThemewrote)L-H%programmer write?
)L-L%(the SLOW \]H*rheme-focusRhemealgorithm.
)L-L%Figure 1: An Example of Information Structureformation structure representation, as shown inFigure 1.
The determination of focused itemsis based on both givenness and contrastiveness.For the current TTS task, we consider items tobe in focus on first mention and whenever Word-Net finds a contrasting item in the current dis-course segment.
The algorithm for determiningthe contrast sets is described in Section 4 below.The adaptation of an information structureapproach to the TTS task highlights a num-ber of important issues.
First, while it may beconvenient to think of the division into themeand theme in terms of utterances, it may bemore appropriate to consider the division interms of propositions.
Complex utterances maycontain a number of clauses conveying sev-eral propositions and consequently more thanone theme/rheme s gmentation.
Our programannotates thematic and rhematic stretches oftext by first trying to locate propositional con-stituents, as described in Section 4.Another information structure issue broughtto fight by the TTS task is that themes maynot consist solely of background material, butmay also include inferable items, as shown inexample (1).
In this example, "name" is cer-tainly not part of the shared background be-tween the speaker and the listener.
However,since it is common knowledge that pets havenames, it serves as a coherent thematic rink tothe previous utterance.
4(1) Miss Smith has a Colfie.The dog's NAME is LASSIE.LWH* L- H* L-L%4WordNet can capture some inferences, but is unableto account for a complex relationship like this one.3 The  WordNet  Lex ica l  DatabaseWordNet is a large on-fine Engfish lexicaldatabase, based on theories of human lexicalmemory and comprised of four part-of-speechcategories: nouns, verbs, adjectives, and ad-verbs (Miller et al, 1993).
Within each cate-gory, lexical meaning is represented by synonymsets (synsets) organized around semantic rela-tionships.
Polysemous words are represented bymultiple synsets, one for each word sense.
Therelease used in this work, WordNet 1.5, con-tains a total of 91,591 synsets and 168,135 wordsenses (Miller, 1995).Types of semantic relationships betweensynsets vary by category.
The basic structureof each is discussed briefly below.3.0 .1  NounsThe nouns category is the largest and se-mantically richest of the four.
It contains60,557 synsets, grouped into 25 different op-ical hierarchies.
Synsets in each hierar-chy are organized using hypernymy/hyponymy(IS-A) relationships.
The noun hierarchiesalso include antonymy and three types ofmeronymy/holonymy relationships (PART-OF,MEMBER-OF, MADE-OF).
Meronyms aretypically defined at the level of basic conceptsin the hierarchies.3.0 .2  VerbsVerbs currently comprise 11,363 synsets inWordNet, divided into 15 categories based onsemantic riteria.
The primary semantic rela-tionships for verbs in WordNet are lexical entail-ment (e.g.
snoring ENTAILS sleeping) and hy-pernomy/hyponymy.
Verb hierarchies also in-49clude troponymy (MANNER-OF) relationships,and to a. lesser extent, antonymy and causMrelationships.
Generally, verb hierarchies aremuch shallower with higher branching factorsthan noun hierarchies, but like nouns, verbs ex-hibit basic concept levels at which most tro-ponyms are defined.3.0.3 Ad ject ivesWordNet contains 16,428 synsets of adjectivesdivided into descriptive and relational types,and a small closed-class of reference-modifyingadjectives.
Descriptive adjectives are organizedaround antonymy, and relational adjectives ac-cording to the nouns to which they pertain.WordNet alo encodes limitations on syntacticpositions that specific adjectives can occupy.3.0.4 AdverbsAdverbs make up the smallest of the four cat-egories, with a total of 3243 synsets.
Adverbsare organized by antonymy and similarity rela-tionships.4 Imp lementat ionAn overview of the system architecture isshown in Figure 2.
Following (Cahn, 1994;Cahn, 1997), text files are first parsed by theNPtool noun phrase parser, which identifiesnoun phrases and tags each word with morpho-logical, syntactic, and part-of-speech informa-tion (Voutilainen, 1993).
The preliminary pro-cessing module then adds gender informationfor proper names, resolves ambiguous tags, andreformats the text for further processing.
~ Next,the previous mention, contrast, and theme mod-ules assign pitch accents, phrase accents, andboundary tones, using WordNet to identify setsof synonyms and contrastive words.
Finally, theannotated text is re-formatted for the TrueTalkspeech synthesizer (Entropic Research Labora-tory, 1995).
Additional implementation detailsfor the accent assignment modules are providedbelow.SGender resohition is performed via simple lookupusing the CMU Artificial Intelligence Repository NameCorpus (l(antrowitz, 1994).
Ambiguous parses are re-solved using a set of heuristics derived from analysis ofNPtool output.4.1 G ivenness  Ident i f icat ionThe first of the three accent assignment mod-ules assigns .pitch accents to words using thefollowing given/new strategy:For each word W,1.
If W is a noun, verb, adjective, or adverb,and W ?
history(),  and W ?
equiv(x), forany x E history( ):(a) tag W as a focused item(b) add W to history( )(c) create equiv(W)2.
If W is a noun, verb, adjective, or adverb,and W E equiv(x), tag W as inferable.
6The history and equivalence lists are reset ateach paragraph boundary.
Matches are limitedto words belonging to the same part-of-speechcategory, relying only on word roots.Equivalence (synonym) sets are created fromsemantic relationships for each WordNet cate-gory as follows:1.
Nouns: equiv(W) = union of hypernymsand synonyms for all synsets of W. Thenumber of hypernym levels used for eachsense is determined by searching for the ex-istence of meronyms on the current level,climbing the hypernym tree until a levelcontaining meronyms is found, or the rootis reached.
If no meronyms are found, then(1/4 ?
depth of W synset) levels are used.
72.
Verbs: equiv(W) = union of hypernyms,synonyms, and entailments for all synsetsof W. Only one level of hypernyms iincluded.S3.
Adjectives and adverbs: equiv(W) = syn-onyms for all synsets of W.6Items tagged as inferable by this step are realizedby less prominent pitch accents than items tagged asfocused, reflecting their status as not explicitly given.~The present approach to identifying a "basic" con-cept level for nouns using meronymic relations is not theoptimal solution.
Many noun categories in WordNet donot include meronyms, and meronyms may exist at sev:eral levels within a hierarchy.8 Because verb hierarchies have a much higher branch-ing factor, considering more than one level is generallyimpractical.50TEXTNPtoolTaggert /PreliminaryProcessingGivennessIdentificationWordNet I\_ ContrastiveStressAssignmentTheme/RhemeSegmentationTrueTatkFormatterNames DatabaseVTTSFigure 2: ArchitectureEquivalence lists are ordered and searchedfrom most common to least common sense of aword.
The current implementation is limited tosingle word matches; no WordNet entries con-sisting of multi-word descriptions are includedin the equivalence list.4.2 Cont ras t ive  Stress  Ass ignmentThe second accent assignment module compareseach open-class word (nouns, verbs, adjectives,and adverbs) with other words previously real-ized in the text to identify possible contrastiverelationships.
The top-level algorithm for as-signing contrastive stress is shown in pseudo-code in Figure 3.Sets of possible contrastive words for nounsand verbs are determined by the hyper-nym/hyponym relationships in WordNet as fol-lows:...Identify the set of immediate hypernyms,hyper(W), corresponding to each sense ofW (synsets containing W).For each h: h E hyper(W), identify theset of immediate hyponyms, hypo(h), suchthat W e hypo(h).The set of possible contrastive words is theunion of hyponyms for each sense of W.The contrastive sets for adjectives and ad-verbs are simply the union of antonyms for allforeach word W1 {for each word W2 on the history list(from most to least recent) {for each A: A E contrast(W2) {if W1 equals A then {tag W1 for contrastive stress;end search;}}}if no contrast is found {add W1 to the history list;generate &: store {x:  x E contrast(W1)};}}Figure 3: Contrastive Stress Assignmentword senses, as hypernym/hyponym relation-ships are not used in WordNet for either class.All contrastive sets generated are ordered andsearched from the most common to least com-mon sense of a word.
The present implementa-tion is limited to single word searches.There are a number of shortcomings in thepresent implementation of contrastive stress as-signment.
The first is its failure to use tex-tual information to facilitate identification ofcontrastive relationships.
To rectify this sit-uation, a search for keywords commonly usedto indicate contrast (e.g.
however, unlike, on-51the-other-hand), as well as explicit negation(not) must be incorporated.
Identifying parallelphrasing may also be useful in identifying con-trastive relationships not encoded in WordNet(namely for non-antonymic ontrasts betweenadjectives and adverbs).4.3 Theme ~ Rheme Ident i f i cat ionThe modules described above determine the sec-ond tier of the information structure--that is,which items are eligible for focus based on theirnew or contrastive status.
The theme/rhemeidentification module is responsible for deter-mining the primary information structure de-lineation of theme and rheme.
Based on an au-tomatic segmentation of utterances or parts ofutterances into theme and rheme, we can applythe mapping of tunes described in Section 2 todecide which pitch accents to assign and whereto place phrasal and boundary tones.The automatic segmentation of utterancesinto theme and rheme is a difficult problem.Our preliminary approach is based on a num-ber of heuristics, and generally performs quitewell.
Nonetheless, we expect this module tobe substantially refined once we have concludedour empirical analysis of the Boston Univer-sity radio news corpus (Ostendorf, Price, andShattuck-Hufnagel, 1995).The theme/rheme identification algorithmbegins by trying to identify propositional con-stituents within utterances.
As noted in Sec-tion 2, a single utterance may contain sev-eral clauses corresponding to several seman-tic propositions.
Propositional constituents arecentered around verb occurrences.
The al-gorithm looks for verb complexes--contiguousstretches of text containing verbs, adverbs andsome prepositions.
Utterances are then dividedinto propositional constituents uch that eachcontains a single verb complex.
The algorithmalso considers multi-word clauses that are setapart by punctuation, such as utterance-initialprepositional phrases, as separate propositionalconstituents.
9 This segmentation scheme is sim-9Note that we work with the part-of-speech outputof NPtool rather than a complete parse tree.
While thispresents a number of diffictflties for dividing utterancesilar to Gussenhoven's division of utterances intofocus domains (Gussenhoven, 1983).Once propositional constituents have beendetermined, the algorithm applies a number ofheuristics to sub-divide each into theme andrheme.
We consider two possible segmentationpoints: before the verb-complex and after theverb-complex.
The heuristics are as follows,where PreV, V and PostV correspond to thepre-verbal material, the verb-complex materialand the post-verbal material respectively.1.
In the case where neither PreV, V norPostV contains focused items:theme = \[PreV\]rheme = \[V PostV\]Accent V material.2.
If PreV and V contain focused items, butPostV does not:theme = \[PreV\]rheme = \[V PostV\]3.
If PreV and PostV contain focused items,but V does not:theme = \[PreV V\]rheme = \[PostV\]4.
If V and PostV contain focused items, butPreV does not:theme = \[PreV V\]rheme = \[PostV\]5.
If PreV, V and PostV all contain focuseditems:theme = \[PreV V\]rheme = \[PostV\]6.
If PreV contains focused items, but V andPostV do not:rheme = \[PreV\]theme = \[V PostV\]7.
If V contains focused items, but PreV andPostV do not:theme = \[PreV\]rheme = \[V PostV\]into propositional constituents, it allows us more free-dom in sub-dividing those propositional constituents intotheme and rheme.
That is, our program can produceprosodic phrases, such as those shown in Figure 1, thatare orthogonal to traditional syntactic structures.528.
If PostV contains focused items, but PreVand V do not:theme = \[PreV V\]rheme = \[PostV\]Note that these heuristics encode a prefer-ence tbr thematic phrases to precede rhematicphrases, but do not always dictate such an or-dering.
Also, note that the heuristics allowthematic phrases to sometimes contain focuseditems.
This is in accordance with our observa-tion in Section 2 that themes need not containonly background material.Based on the theme/rheme identificationheuristics, we map L-t-H* accents onto focuseditems in themes and H* accents onto focuseditems in rhemes.
L- phrasal tones are placedat theme and rheme boundaries.
When themeor rheme phrases are also marked by punctu-ation, appropriate boundary tones and pausesare also inserted (e.g.
H% for comma delim-ited phrases).5 Resu l ts  and  Conc lus ionsThe system was designed and debugged usinga set of five single-paragraph texts.
It was thentested using several new single-paragraph texts,excerpted from news articles and encyclopediaentries.
Sample output is shown in Figures 4and 5, where prominence, defined as a multiplierof the default nuclear accent, is shown directlybelow the associated pitch accent.These preliminary test results indicate us-ing information structure in conjunction withWordNet can produce intonational patternswith context-appropriate variation in pitchaccent type and prominence.
In general,LWH* accents occur on items deemed to bethematic, and H* accents occur on rhematicitems.
WordNet proved to be fairly success-\[ul at identifying words which were "given" viainference, thus allowing the program to cor-rectly reduce the pitch accent prominence as-signed to these words.
For example, in Figure 4,the prominence of the pitch accent on "achieve-ment" is lowered because of its relationship to"feat."
In Figure 5, the prominence of the ac-cent on "soil" is lowered because of its relation-ship to "ground."
To a lesser extent, Word-Net was also able to identify appropriate con-trastive relationships, uch as the relationshipbetween "difficult" and "easy" in Figure 5.
Con-sequently, our program places a slightly moreprominent accent on "difficult" than it wouldhave if "easy" had not occurred within the samesegment.While quite encouraging, these preliminaryresults have also identified many opportunitiesfor improvement.
The current implementationis limited by the absence of a full parse tree.It is also limited by the current heuristic ap-proach to phrase segmentation, and thereforeoften produces L- phrasal tones in improperplaces.
Substituting better tools for both pars-ing and phrase segmentation would improve theoverall performance.The system's accuracy level for WordNet syn-onym and contrast identification can be im-proved in two ways: by incorporating wordsense disambiguation, and by using a more so-phisticated approach for generating a "match.
"Presently, WordNet results are searched in orderof most common to least common word senses,thus biasing matches towards common wordsenses, rather than determining the most likelycontext.
Incorporating a sense disambiguationalgorithm, such as that discussed in (R.esnik,1995), is a logical next step.
Word matches arealso limited to comparisons between individualwords within a single l~art-of-speech ategory.Extending consideration to adjacent words andsemantic roles would greatly reduce the numberof spurious matches generated by the system.Another area for improvement concerns theprominence of pitch accents.
Based on our pre-liminary results, we believe that the L-t-H* ac-cents should be somewhat lower than thoseshown in Figures 4 and 5.
Once we havecompleted our analysis of the Boston Univer-sity radio news corpus (Ostendorf, Price, andShattuck-Hufnagel, 1995), we expect o modifythe accent prominences based on our findings.Our assessment of system performance isbased on human listeners qualitative measure-ments of the "comprehensibility" of output fromour system in comparison with the standard53The cloning of ~ adult sheep in Scot l~d seems likely to sparkL+H* L+H* L+H* L+H* L+H* L- H* H*1.1 1.1 1.1 1.1 1.1 1.1 1.1intense debate about the ethics of genetic engineering research inH* H* H* H* H* H*1.1 1.1 1.1 1.1 1.1 1.1hum~s.
But experts agree that, however the debate is resolved, theH* L-LZ L+H* L- H* L-HZ H* L- L+H* L-HZ0.7 1.3 1.1 1.1 1.1genie is irretrievably out of the bottle.
The unprecedented feat wasL+H* L+H* L+H* L- H* L-LZ L+H* L+H*1.1 1.1 1.1 1.1 1.1 1.1considered by m~y scientists to be impossible because of theL+H* L- H* H* H* H*1.1 1.1 1.1 1.1 1.1technical difficulties involved in nurturing genetic material ~dH* H* H* H* H* H* L-1.1  1,1 1.1 1.1 1,1 1.1proof ing  it to grow into ~ intact org~ism.
M~y more scientistsL+H* L- H* H* H* L-LZ L+H* L+H*1.1 1.1 1.1 1.1 1.1 1.1have considered it ~ ethically dubious goal because the achievementL- H* H* H* L- L+H*1.1 1.1 1.1 0 .7theoretically opens the door to cloning hum~s,  a possibility fraughtL+H* L+H* L- H* H* L-LZ H* H*1.1 1.1 1.1 0 .7  1.1 1.1with moral ~biguit ies.H* H* L-LZ1.1 1.1Figure 4: Results for an excerpt from the Los Angeles Times, February 24, 1997TrueTalk output.
Although adequate for pre-liminary tests, better performance measure-ments are needed for future work.
Possibilitiesinclude testing listener comprehension a d re-call of speech content, and comparing the sys-tem's output with that of several human speak-ers reading the same text.AcknowledgmentsThe authors would like to thank Janet Cahn formany helpful suggestions, and particularly forher advice on selecting V~rordNet, NPtool andthe Boston University radio news corpus.
Wewould also like to thank Ken Haase for facili-tating many helpful discussions, and the MauiHigh Performace Computing Center (MHPCC)for use of computing facilities.
This researchwas funded by the generous sponsors of the MITMedia Laboratory.Re ferencesCahn, Janet.
1994.
Context-sensitive prosody fortext-to-speech synthesis.
Technical Report 94-02,MIT Media Laboratory.Cahn, Janet.
1997.
Prosody as a Consequence of theCapacity and Contents of Memory.
Ph.D. thesis,Massachusetts Institute of Technology.
Forthcom-ing.54Termites are frequently classed as pests.L+H* L+H* L+H* L- H* L-LZI .
I  I .
I  i .
I  I .
Iof the known species have destructive habits,L+H* L+H* L+H* L- H* H* L-LZi .
I  I .
I  i .
i  I .
I  i .
IAlthough only 10 percentL+H* L+H* L+H*1.1 1.1 1.1these  spec ies  may doL+H* L+H*1.1 1.1great d~age.
Subter r~e~ termites, which enter wooden structuresH* H* L-LZ H* L-HE L+H* L- H* H*1.1 1.1 1.1 1.1 1.1 1.1through the ground, as they need to maintain contact with the soil'sH* L-HZ L+H* L+H* L- H* H*1.1 0.9 1.1 1.1 0.7moisture, are fairly easy to control.
Insecticides c~ be placed inH* L-HZ L+H* L- H* H* L-LZ L+H* L+H* L-1.1 1.1 1.1 1.1 1.1 1.3trenches dug aro~d the structure to be protected.
Materials such asH* H* H* L-LZ L+H* L+H*i.I i.l i.l 0.9 I.Ipressure treated wood ~d reinforced concrete are impervious toL+H* L+H* L- H* L- L+H* L- H* L- H*1.1 1.3 1.1 1.1 1.1 1.1termites and make safe fo~dations.
Dry wood termites, however, nestL- L+H* L- H* H* L-LZ L+H* L-HZ L+H* L-HZ L+HZO.7 1.1 0.7 1.1 1.1 1.1within the wood they feed on ~d are much more difficult to control;L- H* L- L+H* L- H* L-L%i .
I  I .
I  1 .3f~ igat ion  has proved to be the best tec~ique.L+H* L+H* L- H* H* L-LZ1.1 1.3 0.7 1.1Figure 5: Results for an excerpt from the Britannica online serviceEntropic R.esearch Laboratory, 1995.
TrueTalk Ref-erence Manual.Gussenhoven, Carlos.
1983.
On the Grammar andSemantics of Sentence Accent.
Foris, Dodrecht.Hirschberg, Julia.
1990.
Accent and discourse con-text: Assigning pitch accent in synthetic speech.In Proceedings of the Eighth National Conferenceon Artificial Intelligence, pages 952-957.Hirschberg, Julia.
1993.
Pitch accent in con-text: Predicting intonational prominence fromtext.
Artificial Intelligence, 63:305-340.Horne, M., M. Filipsson, M. Ljungqvist, andA.
Lindstrom.
1993.
Referent racking in re-stricted texts using a lemmatized lexicon: Impli-cations for generation of prosody.
In Proceedingsof Eurospeech '93, volume 3, pages 2011-2014,Berlin.Kantrowitz, Mark.
1994.
CMU artificial in-telligence repository name corpus, http://  al-mond.srv.cs.cmu.edu/afs/cs.cmu.edu/project/ai-repository/ai/html/air.html.Miller, G.A.
1995.
WordNet version 1.5, Unix re-lease notes.
Technical report, Cognitive ScienceLaboratory, Princeton University.Miller, G.A., R. Beckwith, C. Fellbaum, D. Gross,and C. Miller.
1993.
Introduction to WordNet:an on-line lexical database, five papers on Word-Net.
Technical report, Cognitive Science Labora-tory, Princeton University.55Monaghan, Alex.
1991.
Intonation in a Text-to-Speech Conversion System.
Ph.D. thesis, Univer-sity of Edinburgh.Monaghan, Alex.
1994.
Intonation accent place-ment in a concept-to-dialogue system.
In Pro-ceedings of the Second ESCA/IEEE Workshop on,5))eech Synthesis, pages 171-174, New Paltz, NY,September.Ostendorf, M., P.J.
Price, and S. Shattuck-Hufnagel.1995.
The Boston University radio news corpus.Technical Report ECS-95-001, Boston University.Pierrehumbert, Janet and Julia Hirschberg.
1990.The meaning of intonational contours in the in-terpretation of discourse.
In Philip Cohen, JerryMorgan, and Martha Pollock, editors, Intentionsin Communication.
MIT Press, Cambridge, MA,pages 271-312.Pitrelli, John, Mary Beckman, and Julia Hirschberg.1994.
Evaluation of prosodic transcription label-ing reliability in the ToBI framework.
In Pro-ceedings of the International Conference on Spo-ken Language Processing (ICSLP), Yokohama,September.Prevost, Scott.
1995.
A Semantics of Contrast andInformation Structure for Specifying Intonationin Spoken Language Generation.
Ph.D. thesis,University of Pennsylvania.
IRCS Report 96-01.Prevost, Scott.
1996.
An information structural ap-proach to monologue generation.
In Proceedingsof the 34th Annual Meeting of the Association forComputational Linguistics, pages 294-301, SantaCruz.Prevost, Scott and Mark Steedman.
1994.
Specify-ing intonation from context for speech synthesis.Speech Communication, 15:139-153.Prince, Ellen F. 1981.
Towards a taxonomy of thegiven/new distinction.
In P. Cole, editor, RadicalPragmatics.
Academic Press, London, pages 223-255.Resnik, Philip.
1995.
Disambiguating noun group-ings with respect to wordnet senses.
In ThirdWorkshop on Very Large Corpora, Cambridge,MA.Steedrnan, Mark.
1991.
Structure and intonation.Language, pages 260-296.Terken, Jacques and Julia Hirschberg.
1994.
Deac-cent.uation of words representing ' iven' informa-tion: Effects of persistence of grammatical func-tion and surface position.
Language and Speech,37(2):125-145.Voutilainen, Atro.
1993.
NPtool: a detector of En-glish noun phrases.
In Proceedings of the Work-shop on Very Large Corpora.56
