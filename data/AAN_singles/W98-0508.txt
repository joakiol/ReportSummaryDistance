IIlIIiIIiIIIIIIIIII!On Parsing Binary Dependency Structures Deterministically inLinear TimeHard ARNOLA IKielikone OyP.O.
Box 126, 00211 Helsinki, Finlandharfi@kielikone.fiandHelsinld University of TechnologyComputer Science LaboratoryEspoo, FinlandAbstractIn this paper we demonstrate that it ispossible to parse dependency structuresdeterministically in linear time usingsyntactic heuristic choices.
We in'st provetheoretically that deterministic, linearparsing of dependency structures i possibleunder certain conditions.
We then discuss afully implemented parser and argue thatthose conditions hold for at least one naturallanguage.
Empirical data demonstrates thatthe parsing time is indeed linear.
The presentquality of the parser in terms of finding theright dependency structure for sentences iabout 85%.IntroductionNatural language sentences have ambiguities atmany levels of abstraction.
Since presentcomputational lgorithms can handle only partialstructures, one after another, these ambiguitiescause problems for parsing.
A common solutionis to create ahemative structures in parallel, andexplore a forest of possible trees in hope that theright parse tree will appear among them.
Thissolution for processing ambiguities in parsingcreates two new problems.
Which tree is theright one among many in a forest.'?
Furthermore,in the process of creating alternative structures,the number of partial trees tends to growexponentially or at least polynomially with thenumber of words of a sentence.
That in turnimplies similar growth in the processing time.If a parsing algorithm were able to makeconfidently only the right local structuralchoices for a sentence, it would deterministicallyproduce only a single, correct ree.
The benefitswould be obvious: there would be no search forthe right tree in a forest, and the processing timecould be benign.
However, to our bestknowledge, no one has yet been able to producea deterministic parser for a constituent analysisof sentences.A dependency theory of syntactic structureindicates yntactic relations directly between thewords of a sentence (e.g., Hays, 1964; Hudson,1976, Hellwig, 1986; Mel'chuk, 1988; Robinson,1970; Schubert, 1986; Starosta, 1988).
We havestudied the parsing of dependency structuresover several years (Nelimarkka et al 1984,Jiippinen et al 1986, Valkonen et al, 1987).
Inthis paper we discuss the final version of ourfully implementod dependency parser and showthat h is possible to design a heuristicdeterministic dependency parser that parsessentences in linear time.
The parser choosesheuristically only one direct governor amongalternatives for each word in a sentence.
Such adeterministic parser runs a great potential riskthat at some point a wrong choice is made andthe right parse tree is missed.
We demonslrateempirically that the quality of the deterministicl Formerly Hard JfippinenCurrent address: Ganesa Oy, It.
Teatterik.
1 D 22, 00100 Helsinki, Finland.
E-mail: harri@kielikone.fi68parser can be maintained on a satisfactory level.We first discuss deterministic parsingtheoretically and then proceed to discuss theimplemented parser.1 Strings and GovernmentsI.I Direct governments and governedstringsLet x be a node that has certain formalproperties.
Let S = {xl.
x2, x3 .
.
.
.  }
be a well-ordered set or a string of such nodes.
(We donot discuss the formal properties of nodes here.Later on, when nodes are interpreted as wordforms, their formal properties will be morpho-syntactic attributes.)
Let R be a binary,asymmetric, and antireflexive relation betweenthe nodes of S:(0 R = { <xi, xi> \]xi, x i ~ S, xi Rxi, and i# j }We say that xi directly governs xj or is a directgovernor or a regent of xj.
Correspondingly, xjis directly governed by or a dependant of xi.Graphic representation indicates directgovermnents byarrows (Figure 1).Rather than using just one direct governmentrelation we admit several annotated binaryrelations, distinguished with integer subscripts.Let R = {Rb R2, R3, ...} be a set of such binaryrelations.We stipulate the following tree constraint forthe direct government: a directly governed nodehas a unique direct governor.R2R, I R3 R3X2 X3 X4 X5Figure 1: A governed stringWe say that a node xi governs xj (i#j) iff either xidirectly governs xj, or xi governs Xk (k#i,j) and xkgoverns or directly governs xj.
If  all nodes of  astring except one are governed by the samegovernor, we say that the string is totallygoverned (by that common governor).
Figure 1shows a totally governed string that is governedby node xl.Due to the tree constraint, governed strings aretopologically trees.
We distinguish differentkinds of  ambiguities in strings.
A string S isunambiguous with respect o a set of  relationsR if each node has only one possible directgovernor and governing relation.
S is locallyambiguous but globally unambiguous, if S hasonly one unique totally governed string but atleast one node has more than one possible directgovernor or governing relation.
S is (globally)ambiguous, if there are more than onetopologically different (or differently annotated)totally governed strings for it.We stipulate another topological constraint.
Theprojectivity constraint states that ifxi Rk xj, forany i, j, k and i>j, there exists no Rp such that XmRp x, for any m and n such that m>j and i<n<j orm<i and i<n<j.
(The projectivity constraintprohibits "crossing" direct governments.
)1.2 Government  MapsIt is convenient to study governed strings usingtwo-dimensional government maps (GM).
AGM(S,R) is a matrix whose rows represent thenodes of a string S and the columns represent therelations of R. The ordering of the rowscorresponds to the ordering of the nodes in S,while the ordering of the columns (relations) isarbitrary.
The direct governor of a node ismarked at the intersection of the governingrelation and the governed node.
For example, ifR = {Rb R2, R3, R4} and S = {XL X2, X3, X4, XS}Table 1 shows the GM(S,R) of  the governedstring in Figure 1.
Formally, GM(S,R) c S x R xS.
(Henceforth we often simply write GM ratherthan GM(S,R).
)Node/Relation RI R2 R3 R4XIX2X4X5X3XIx3X4Table I: The GM of Figure 269Two GM's are called equidimensional if theyrepresent identical strings and identical sets ofrelations and the relations occupy the samecolumns in both maps.We borrow a few operations from the set theory.A direct government xi R~- x i belongs to a GM(marked ~) iffxi and xj are nodes in the GM andxi Rk x i is marked in GM.
A government mapGMI includes another equidimensional mapGM2 (GM2 c_ GM1) if  all direct governors inGM2 are also in GMI, GMI properly includesan equidimensional map GM2 (GM2 c GMI) ifGM2 c_ GM1 and GMI ?
: GM2.
Any given twoequidimensional maps are identical, if theyinclude one another.
We also admit unions (u)and intersections (c~) of two equidimensionalGM's in the obvious manner.A GM may exhibit just those direct governerswhich constitute a totally governed string, it mayshow any subset of the direct governors of thenodes, or it may exhibit all possible directgovernors of the nodes.
We say that a resolvedGM (GM') is a map that shows only the directgovernors of  a totally governed string.
Acomplete and unresolved GM (GM c~) is a mapthat indicates all possible direct governors of thenodes.
A (partially) unresolved GM (GM u)indicates some but not necessarily all directgovernors of the nodes.
For each GM, GM' _cGM cu and GM" c GM cu.Let GMr(S,R) and GM~"(S,R) represent aresolved and the complete and unresolvedequidimensional maps, respectively.
If S isunambiguous, GM r = GM% If S is locallyambiguous but globally unambiguous, thereexists only one GM ' and the GM r c GM ~'~.
IfS isglobally ambiguous, there exists more than onedifferent GM r and for each GM' c GM ~.Finally, if there exists no GM ' such that GM ~ _cGM ?
'', we say that the string is ungrammatical(with respect to R).Table 2 shows the GM ~ of  a locally ambiguousbut globally unambiguous string.
Node x4 cannotbe directly governed by both x3 and xs, hence thestring is locally ambiguous.
Only the formerchoice results in a totally governed string(Figure 1 and Table 1).70Node/Relation Ri R2 R3 R4Xlx~x3x4x5x3XIX3 X5X4Table 2: Locally ambiguous butglobally unambiguous GM ~''Table 3 shows the GM c?
of a both locally andglobally ambiguous tring.
Figure 1 shows oneand Figure 2 shows another governed stringcorresponding to this GM ?~.
If a string isambiguous, at least one row has multiple entriesin the GM%Node.Relation Ri 17,2 R3 R4XiX2X5X3 X!X1X3X4Table 3: Locally and globally ambiguous GM ?
"R2X3 X4 XSFigure 2: Another governed string1.3 Deterministic parsingAn GM r carries all necessary information aboutthe structure of  a governed string.
If the processof  uncovering the structure of  a string is calledparsing, a parsing process equals to the findingof  the GM r for a given string (or all resolvedmaps if the string is globally ambiguous), andthe found GM ) represents he parse tree of thestring.The nodes and relations in a GM generate anabstract search space for governed strings.Therefore, parsing can be viewed as a search forthe GM ~ in the space genereted by the string ofnodes and the set of available relations.
Theprocess begins with an empty map and makesprogresssively more and more direct governorsknown.
The process hould end with a GM u suchthat GM' c_ GM ~.
If G1Vf c GM ~ there remains aresidual problem of  finding GM ", GM" c GM",such that GM'" = GM ~.Let us assume that for each globally ambiguousstring there is single fight parse tree, called thepreferred tree.
We call a parsing processdeterministic, if it begins with an empty mapand marks direct governors in the map in suchan order that when the process ends GM u = GM r,where GM" is the explored map and GM rrepresents he parse tree or the preferred parsetree if the string is globally ambiguous.Theorem 1: Unambiguous strings can be parseddeterministically.A proof is trivial.
Any algorithm which finds allpossible direct governors of the nodes byiterating through all the relations and all thenodes creates the GM c'' by definition.
And withunambiguous strings, GM r = GM ~u.The following OS algorithm (for Open Search),among others, parses unambiguous stringsdeterministically.Let nR denote the number ofavailable relations and ns stand for the numberof  nodes in an input string.OS algorithm:1.
Assign the available relations as columns ina GM in random order.2.
Assign the nodes of an input string as rowsin the GM in their precedence order.3.
Mark each cell in the GM empty and eachrow open.4.
For each column k (k=l .... , nR) test each xi(i=l ..... n~) and each open xj (j--i-l, i-2 .....1, i+ 1, i+2 ..... n~) for xi R xj, where R is therelation assigned in the column k. Mark eachfound direct governor xi in the GMJj,k\] andmark the rowj closed.Let us call the number of open nodes (plus 1)between a direct governor and the governednode at the moment of a test the distance of  therelation test.Distance lt.vpothesis: It is possible to orderlinguistic dependency relations as columns in aGM in such a way that the maximum distanceremains within a fixed boundary when the OSalgorithm parses natural language sentences.
(We return to this hypothesis later on in thispaper.
)Theorem 2: If the distance hypothesis holds,unambiguous strings can be parsed in lineartime.Let us assume that the distance hypothesis holdsand let d stand for the maximum distance.
Theiteration statement in the OS algorithm is thenlimited as follows:.
, ,(j=i-l, j-2, ..., i-d, i+l, i+2, ..., i+d);Let C denote the most expensive relation test.The OS algorithm consumes in the worst case atmost C * nR * nN * 2 * d = O(nN).Next we show that even ambiguous naturallanguage sentences can be parseddeterministically in linear time if a certainadditional condition holds.Best-First Conjecture: It is possible to order thelinguistic relations as columns in a GM in such away that (without violating the DistanceHypothesis) the OS algorithm produces fornatural language sentences the right or thepreferred GM r most of the time.Due to its heuristic flavor, we call the thusmodified OS algorithm the BF algorithm.B F algorithm:1.
Assign the available linguistic relations ascolumns in a GM in such an order that boththe Best-First Conjecture and the DistanceHypothesis hold.2.
(steps 2.-4. are as in the OS-algorithm)The enforcement of  the Best-First Conjecturebrings a heuristic omponent in the algorithm,and the algorithm does not explore the searchspace fully anymore.
Once the algorithmchooses a local governor over the alternative71IIIIiI!
!IiIIIIIIones for a word, the alternative local governorswill be rejected forever.
Therefore, there is noguarantee that the right parse trees will bealways produced, hence the phrase "most of thetime".Claim: The BF algorithm parses naturallanguage sentences detenninistically in linearcomputational cost of the most expensiverelation test).2.2 DecompositionThe theoretical model assumes that sentencesare parsed in one pass.
The DCParser dividessentences into segments, using conjunctions anddelimiters as separators.
The BF-algorithm istime so that the right or the preferred parse trees ,.
applied to each segment separately, and the finalare producedmostofthetime, phase unites the structures built in thosesegments applying the algorithm again.This claim is an unprecise mpirical statement Decomposition greatly strengthens the Distancethat can be supported only by empirical means.
Hypothesis, but it does not alter the linearityThat will be done next.
proof, since the sum of linear elements i linear:2 The Practical ParserFrom now on we assume that strings of  nodesare natural language sentences and discuss afully implemented parser (DCParser) that parsesFinnish sentences.
The DCParser differs fromthe simple theoretical model described above,but, as v~ll be shown below, the differences donot alter the theory.2.1 ContextsThe formal part introduced binary relations ascontext-free ordered pairs (1).
Dependencyrelations in the implemented parser use contexts.Formally, they could be expressed as context-sensitive ordered pairs as in (2), but theDCParser uses different rule syntax as discussedin 2.5.
(2) Ri = { <\[cx l \ ]x \ [cxr \ ] , i cy~\ ]y \ [cy , \ ]> lx, y are morphosyntactic representationsof the direct governor and the governedword form,cx~, cxr, cyi, cy, are morpho-syntaetierepresentations of  the left and the rightcontexts o fx  and y, respectively,and x Riy }.The use of contexts in relations adds anotherheuristic component to the BF-algorithm, andone dependency relation may require quite a fewbut fixed number of  such context sensitivedefinitions.
Contexts do not alter, however, thelinear time behavior of  Theorem 2.
They onlyincrease the value of the constant C (the(3) O(ni) + O(nj) + ... + O(nk) = O(nl~),ni, nj, ..., m. <__nswhere n~ is the number of the words in asentence.2.3 Homographic disambiguationThe theoretical model did not discuss ambiguousnodes.
In practice a word form can have severalalternative morphotactic interpretations.
TheDCParser has a separate morphological nalysisphase which produces all possible morphotacticinterpretations for the word forms of inputsentences.
A separate preprosessing phaseexplicitly disambiguates most of the lexical andhomographic ambiguities of Finnish word formsusing context sensitive rules designed for thepurpose (Nyl~nen, 1986).
The remainingambiguities are resolved implicitly by theDCParser as follows.
When an interpretation ofan ambiguous word form qualifies as a governednode the alternative interpretations will berejected.
This strategy implements yet anotherheuristic component for the parser, but thestrategy does not alter the linearity argumentpresented earfier.2.4 The  dependency  relationsThe parser uses 32 different binary dependencyrelations for Finnish.
The coordinating relationsare discussed in 2.5.
The most important otherrelations are listed in Table 4.
The typicalsyntactic ategories for the regents and for thedependants are also shown.
Space does notallow a discussion of  the individual relations.They are visualized in examples below.
By72stipulation, the finite verb of  the main clause isthe head of a grammatical sentence.Relation ame Dependant ResentIntensAttr Adverb Adverb/Adj.ModAttr Adverb Noun/Adj.AdjAttr Adjective NounGenAttr Noun NounQuantAttr Num/Adv./Pron.
NounNomAttr Noun NounMaterAttr Noun NounInfAttr Verb NounRelAttr Verb NounClauseAttr Verb NounPostpComp Noun PostpositionPrepComp Noun PrepositionNegComp Verb NegVerbAuxComp Verb CopulaSubject Noun VerbObject Noun VerbAdverbial Noun/Adverb VerbComplement Noun/Adjective CopulaConnector Delimiter Verb/NounSeparator Delimiter VerbHead Verb noneTable 4: Common relations2.5 Coord inat ionsConjPreComp ConjPreComp SubjectJohn v, Bill a~nd hfdry laughedSubject Object ConjPostComp ConjPostCompI s~v John ; Bill and MaryFigure 3: CoordinationsCoordinations are one of the main sources ofsyntactic ambiguity in natural languagesentences.
For us they cause also a notationalproblem, since coordinations do not seem to beprima facie binary relations.
The DCParser treatsa coordination as two coexisting binaryrelations.
One word governs the coordinatorwhich governs the other word.
By stipulation,that word among coordinated words which isclosest to the regent becomes the head of thecoordination.
For example, the coordinatedsubject in the sentence John, Bill and Marylaughed is ascending, while the coordinatedobject in the sentence I sin,, John, Bill and Maryis descending as Figure 3 illustrates.2.6 Subord inate  clausesThe DCParser treats finite subordinate clausesso that the subordinating conjunction serves as alinking word between the heads of the main andthe subordinate clauses.
The conjunction is inthe relation in question, and the head of thesubordinate clause is in the ConjPostComp-relation with the conjunction.
Below there is aFinnish example sentence from the corpus, itsrough word-for-word translation and the parsetree produced by the DCParser (4).
Thissentence xemplifies both subordinate clausesand coordinations.
In this output mode theDCParser displays word forms as triplets:surface form, Relation, base form.
Hierarchy isindicated using indentation: the regent of a givendependant is the first word below that isindented one step less.Riittda, kmt puolueetja niidenj~rjesti~t\[It is enough\], [when\] \[the parties and their organiz.\]velvoitetacai : lainsaadt~mtn m'ullajulkaisemaan\[are compelled\] \[using legislation\] \[to publish\]tarkasti tililq~aattkset, budjettinsaja\[accurately\] \[financial statements, heir budgets andlahjoituksensa.their donations\].
(4)-,, Connector, _COMMAI-puolueet, ConjPreComp, uolue\[-ja, CoordPreDep, jaI-niiden, GenAttr, neI-ji~rjesltt, Object, jarjestOI-lains~l~mOn, GenAttr, lainsaadant6-m~//a, Adverbial, apuI-/ahjoituksensa, ConjPostComp, lab...I-ja, CoordPostDep, ja~-budjettinsa, ConjPostComp, budjettiI-,, CoordPostDep, _COMMA~.tifinpadtOkset, Object, tilinp~ttsI-tarkasti, Adverbial, tarkasti{-julkaisemctan, Adverbial, julkaistaI-veivoitetacm, ConjPostComp, velvoittaa./am, Adverbial, kunI--, Separator, _PERIODRiittliii, Head, RiittM73Another sentence from the corpus and its parsetree are as follows:Kysymys askarntttaa koko maaJlmaa tlyt,\[The question\]\[puzzles\] \[the whole wodd\]\[now,\]hm Yhdysvalta#!
retmblikacmit\[when\] \[the republicans ofthe U.S.\]mat pit/nleet /molnekokmtkSensa\[have held\] \[their party congress\]ja nimomeet presidentti Bushin\[and\] \[nominated\] \[president Bush\]ja varapresidemti Da71Quaylen\[and\] \[vice-president Dan Quayle\]taisteluparikseen,\[as their fighting couple,\]/mten eljd aruotta sittetL\[like\] \[four years ago.\](5)I-Kys)vnys, Subject, Kysymysl-koko, AdjAttr, koko.maailmaa, Object, maailma1-,, Connector, _COMMA\]-Yhdysvaltam, GenAttr, YhdysvallatI-republikawlit, Subject, republikaaniI-puoluekokouksensa, Object, puoluekokous\]-presidentti, NomPreAttr, presidentti\[ \[-varapresidentti, NomPreAttr, ..I \[-Dan, NomPreAttr, DanI I'Quay len, ConjPostComp, Quayle\]-ja, CoordPostDep,  ja\[oBnshin, Object, BushI I-,, Connector, _COMMA\]?mistehtparikseen, Adverbial, taistelu...I \]-neljd, QuantAttr, nelj~iI \[-vuotta, PostpComp, vuosi\[ \[-sitten, ConjPostComp, sit, ten\[-kuten, Apposition, kuten\[-nimemwet, ConjPostComp, nimetaI-ja, CoordPostDep, ja\[-pitaneet, AuxComp, pit~I-ovat, ConjPostComp, olla-/ran, ClauseAttr, kunI-nyt, Adverbial, nytI--, Separator, PERIODI-askarruttaa, Head, askarruttaa2.7 The  grammarIn the DCParser word forms are represented asobjects of morpho-syntactie attributes.
Forexample, the word form jdrjest~t (organizations)appears as \[Form="jarjestOt", Lex="jiirjest6",Cat=Noun, Case=Nom, Number=PL\]For efficiency reasons binary relations areexpressed as active rules.
The testing of arelation, then, corresponds to the activation ofthe respective rule or a set of alternative rules.For example, a simplified rule for AdjAttr(adjectival attribute of  nouns) reads as:(6)- Rule for adjectival attributesRedo AdjAttrNode Focus \[ Cat=Noun, Cs:=Case, Nm:=Number \]DI := DepCand Left(l) \[ Cat=Adjective,Case--Cs, Number=Nm \]-> MakeDep D1 \[ Rel:=AdjAttr \]A rule has two main parts: the condition part andthe action part.
The condition part searches andtests qualifying dependants and possiblecontextual words.
A word qualifies in a test if itsattribute object satisfies the description given inthe rule.
Variables can be used for passingattribute values.
C: =" assings a value; "=" tests avalue) The action part binds and namesdependants and assigns values to attributes.
Therule above iteratively (Redo) binds immediatelypreceeding adjectives as attributes if they agreein the case and number with the head noun.Rules are classified into generic rules (grammarproper) and lexical rules.
Their expressivepower is identical.
The former are activated bysyntactic categories.
(6) visualizes a simplegeneric rule.
Lexical rules are activated byspecific lexemes.
For example, (7) describes apart of  a complex rule for Finnish verb pitdd.
(7)LexBlock "pitaa"-- pitim tehditOnce pitaa !DI "= DepCand Right(4) \[ Modal=Iinf \]-> MakeDep D1 \[ Rel:=Subject \]Focus \[ SubCat'--InfSubj \]- pitM jostakinOnce pitaa I 0D1 := DepCand Right(4) \[ Cat=Noun+Proper+Pronoun,Case=El \]Not Node From DI Right(l) \[ Modal=IpartiO-llpartic \]-> MakeDep D1 \[ Rel:=Adverbial \]Focus \[ SubCat:=Intr \]74Pit#ti has several senses and subcatagories inFinnish.
(7) shows two of them.
The firstalternative treats the verb as a modal verb as inMinun p i t~ menn~ saunaan (I must go to thesauna).
(In our linguistic analysis we treat theinfinitive menna (to go) as the subject of themodal verb pitOO and the genitive minun (?I) asthe subject of  the infinitive.)
The secondalternative handles the idiomatic usage MindpidOn hanest~ (I like her) where a surface elativeadverbial represents a deep semantic object ofpitaO.
The rule binds an elative as adverbial, butdoes not bind it if the elative is followed by aparticiple as in Min~ piclOn hOnestO l~htev~stdtuoksusta (?1 like the ~agrance coming fromher).The grmnmar (Arnola, 1998) consists of about950 generic rules and of about 12 500 lexicalrules.
An algorithm, which implements the Best-First strategy, controls the activation of the rules.3.
Empirical Results3.1 Benchmark test suiteThe parser has been under development foryears.
It is an integral part of  a commercialmachine translation system called TranSmart?.A benchmark test suite of  correctly parsedsentences (source sentences and their correctparse trees) has been accumulated during thisperiod.
Only sentences that have revealedgrammatical errors in the parser have beenadded to the test suite after the errors werecorrected.
Otherwise the test suite sentence havebeen randomly selected.
The test suite sentencesare periodically parsed to guarantee monotonousimprovement of  the grammar.200 T =_ "?I,50,,o+ / 1e?
T ~60 zO 10 20 30 40 50 60Figure 4: Distribution of  the sentence lengths ofthe benchmark test suiteAs of this writing, the benchmark test suitecomprises over 3000 sentences.
The distributionof the sentence lengths (including delimiters) isshown in Figure 4.
The average sentence lengthis 12.1 words.3.2 Linearity argumentWe used the benchmark test suite sentences totest the linearity claim.
Figure 5 shows thedistribution of the parsing times in seconds.
Theprocessor is an old Intel 486, 66 MHz.
A 150MHz Pentium processor parses about 400sentence/minute of  running text.1.91.6 i ~ 00.6 ~ C:0.20 -~:::~:~ , ?D0 10 20 30 40 SO 60Figure 5: Distribution of the parsing times ofthe test suite sentences1.8 7;.6 ,~1.4L2 ,~t0.8 ~-0.6 J0.4 10.2 i0 t ~~0---"2t2_=.-~--I 0 2O 30G 7-  7-40 50 60Figure 6: Average parsing times for diffe~er, tsentence lengthsFigure 6 plots the average parsing times for eachsentence length.
Sentences whose length isbetween 5 and 20 words form statisticallymeaningful sets.
Their average parsing timesform a clear linear function.
Longer sentencesdo not support a contrary view.3.3 QualityIt remains to discuss the quality o f  the parser.Weuse  the following strict criterion for thecorreemess of  a parse tree.
A sentence is parsed75IIIIIIIIIIIcorrectly if the sentence is grammatical nd theproduced dependency structure completelycomplies with the structure a competent humanjudge would assign to it.
Otherwise the parsetree is judged incorrect.
Hence, a single, localstructural error in an otherwise  cor rect  parse trc?disqualifies the st~cture.
If a sentence isglobally ambiguous but it is clear for a humanreader which structure is meant, the structure isjudged correct only if it is in agreement with thehuman decision.
If a human reader cannot makethe right choice for an ambiguous sentencewithout extual context, the structure is deemedcorrect if it is one of the possible corrects t ructures .4567891011121314181 148/82% 19/10?/0 6/3% 8/4%253 207/82% 26/10?/o 11/4% 9/4%380 331187?/0 38110?/0 4/1% 7/2%216 174/81% 27/13% 8/4% 7/3%297 249/84% 33/11% 8/3% 7/2%387 334/86% 34/90/0 11/3% 8/2%196 166/85% 16/8% 8/4% 6/3%267 224/84% 25/9% 8/3% 10/4%118 97/82% 16/14% 2/2% 3/3%2680 2271/85% 252/90/0 83/3% 74/3%391 337/86% 36/9*/0 1 i/3% 7/2%Table 5: Parsing quality of  the test samplesFigure 7 shows the percentage numbers of eachcolumn in a graphic form.
Lines are fitted to thedata  to  indicate possible tendencies of the series.Presently the DQParser is fully developed in thesense that it is in practical use in commercialmachine translation systems.
However, thetuning of the parser still continues.
The parserhas been subjected to tens of thousands ofgenuine unedited sentences from differentsources over the years.
Each parse tree has beencarefully studied and all indicated errors or gapsthat could be systematically corrected werecorrected in the grammar and in the lexicons.About once a week the benchmark test suite wasprocessed and possible errors found in the testsuite were  cor rected .Occasionally (about oncein a month or  two)  afresh piece of text was randomly selected.
Thetotal number of sentences in the text and theI number of sentences parsed correctly right awaywere recorded.
The incorrectly parsed sentenceswere classified into three classes: the onesI parsed correctly after (only) lexical corrections,the ones parsed correctly after grammaticalcorrections (and possible lexical corrections),and the ones whose parsing errors could not beI corrected in systematic fashion.
These a errorsexhibit a fundamental drawback of the Best-Firststrategy.
Table 5 shows the data of these testI samples.
Each column presents both absoluteand relative numbers: absolute/percentage%.IIText No.
Parsed Rcq.
Req.
Fatallyo f  correctly Icxical gramm, in...................... ,,s~_t._ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
c~r?ct= concc:t. _coF_.cct .1 375 294178% 50/13% 19/5% 12/3%2 196 148/76% 34/17% 8/4% 8/4%3 196 162/83% 18/90/0 10/5% 613%1009080706050403020100~ i ~ ~ " " " ~1' i i i..; '.~ i .b \ [ :~  :.~-!
d - i -~-!
-ddd-~' t ' ti i i !
i i:!
!.!
!
.~.-.!
......
~-.
: --T-..;--T~ : --.~:F..T-T-_~_.
?_~._4 ~ ~.~_~.~..~_-~_i i i .
i i  !.
i:i !i i1 3 5 7 9 11 13correct iiil!-.--,oxen, i!corre ons !
!II= Jl.
Gra,~',mr I1corrections i iiiX Fatally =;incorrect i!ilI!Un.
('n~a=y I!correct) I!Ii!
tiFigure 7: Parsing quality of the 14 last samplesTable 5 and Figure 7 show that the parser seemsto embody a stable 2-4% error ratio due tofundamental problems in the Best-First strategy.Approximately the same number of sentences(2-5%) have revealed grammatical deficienciesin the parser.
This figure may have a slow,although not clear declining trend.
9-17% of thesentences have revealed lexical deficiencies, andthis figure seems to have a slow declining trend.76-87% of the sentences were parsed correctlyright away, and this figure seems to show a clearI 761if slow upward trend.
(The test samples coveralmost wo years of rather intense tuning.
)ConclusionIn this paper we have argued that it is possible toparse binary dependency structures of naturallanguage sentences deterministically and inlinear time, and to keep parsing quality withinacceptable limits, if syntactic heuristics isapplied appropriately.
A possibility for linearparsing has been proved theoretically anddemonstrated mpirically.
The quality issue wasdiscussed using empirical data.
Determinismwas accomplished with a Best-First searchalgorithm which implements syntactic heuristicsin three ways: 1) in a permanent ordering of thetesting of dependency relations, 2) in theimplicit disambiguation of homographic wordform interpretations, and 3) in the contexts ofdependency relation rules.Linear behavior is strongly supported by theempirical data.
It is difficult to be precise aboutthe quality issue.
Empirical data shows that theupper limit of the quality of this deterministicstrategy is96-98%.
The inherent error ate is dueto the use of heuristics.
Nondeterministie parsersdo not have such theoretical barriers.
But thisinherent error ratio should be contrasted with thefact that a deterministic parser produces the fightparse tree, while a nondeterministic parserproduces usually only a forest of candidate parsetrees accurately.At the moment of this writing this deterministicparser seems to have reached about 85%correctness rate (the average of the last fivesamples).
Current errors are mainly lexicalerrors or gaps (about 9%) which usually can beeasily corrected but the corrections improve thequality only slightly.
Some 3% of the currenterrors are errors and gaps in the grammar.
Oneshould be cautious, however, of giving anyprecise numbers for parsing quality, since ourexprerience shows that quality numbers varymarkedly from one text to another.An interactive demonstration f the parser isavailable to the public for testing purposes athttp://www'kielik?ne'fddcparser'fi'dem?"
andthe machine translation system (from Finnishinto English) at http://www.kielikone.fi/fealcee.AcknowledgementsMy thanks go to the whole personnel ofKielikone Ltd. and, in particular, to KaarinaHyvtnen, Jukka-Pekka Jnntunen, the late TimLinnanvirta, and Asko Nyk~inen, who havecontributed tothe paper.
I also want to thank theanonymous referees of this article.
The SirraFoundation and The Technology DevelopmentCentre have tinancially supported the workreported in this article.ReferencesAreola, H. (1998) The functional dependencystructure of Finnish.
(manuscript)Hays, D. (1964) Dependeno' theory: a formalism andsome observations.
Language, 40, pp.
511-525.Hellwig, P. (1986) Dependency md.fication grammar.Prof.
COLING-86, Bonn.Hudson, R. (1976) Arguments for a Non-transformational Grammar.
The University ofChicago Press.Jappinen, H., Lehtola, A., and Valkonen, K. (1986)Fzmctional structures for parsing dependencyconstraints.
Prof. COLING-86, Bonn, pp.
461-463.Mel'chuk, I.
(1988) Dependeno' Sj ~ltar : Theory cmdPractice.
State University of New York Press.Nelimarkka, E., Jappinen, H., and Lehtola, A.
(1984)Two-we 9, automata cmd dependeno, grammar: aparsing method for #lflectional free word-orderiwtguages.
Prec.
COLING-84 and 22th ACLMeeting, Stanford, pp.
389-392.Nykanen, A (1996).
Design and Implementation fms Em, ironment for Parsing Finnish.
M.Se.
(Eng.
)Thesis, Helsinki University of Technology,Department ofComputer Science (in Finnish)Robinson, J.
(1970) Dependency structure andtrmlsformational ndes.
Language, 2/46.Schubert, K. (1986) Linguistic cmd extra-linguisticlmow/edge.
Computers and Translation, 1,pp.
125-152.Starosta, S. (1986) The Case for Lexicase.
PinterPublisher.Valkonen, K., Jappinen, H., and Lehtola, A.
(1987)Blackboard-based ependency parsing.
Prec.IJCAI-87,Milan, pp.
700-702.77
