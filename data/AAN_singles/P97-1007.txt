Combining Unsupervised Lexical Knowledge Methods for WordSense Disambiguation *German Rigau, Jordi Atserias Eneko AgirreDept .
de L lenguatges  i Sist.
In fo rmkt ics  Lengoa ia  eta  Sist.
In fo rmat ikoak  sai laUn ivers i ta t  Po l i t~cnica de Cata lunya  Euska l  Herr iko  Un iber ts i ta teaBarce lona ,  Cata lon ia  Donost ia ,  Basque  Count ry{g. rigau, bat alla}@is i. upc.
es j ibagbee~s i. ehu.
esAbstractThis paper presents a method to combinea set of unsupervised algorithms that canaccurately disambiguate word senses in alarge, completely untagged corpus.
Al-though most of the techniques for wordsense resolution have been presented asstand-alone, it is our belief that full-fledgedlexical ambiguity resolution should com-bine several information sources and tech-niques.
The set of techniques have beenapplied in a combined way to disambiguatethe genus terms of two machine-readabledictionaries (MRD), enabling us to con-struct complete taxonomies for Spanishand French.
Tested accuracy is above 80%overall and 95% for two-way ambiguousgenus terms, showing that taxonomy build-ing is not limited to structured ictionariessuch as LDOCE.1 IntroductionWhile in English the "lexical bottleneck" problem(Briscoe, 1991) seems to be softened (e.g.
WordNet(Miller, 1990), Alvey Lexicon (Grover et al, 1993),COMLEX (Grishman et al, 1994), etc.)
there areno available wide range lexicons for natural anguageprocessing (NLP) for other languages.
Manual con-struction of lexicons is the most reliable techniquefor obtaining structured lexicons but is costly andhighly time-consuming.
This is the reason for manyresearchers having focused on the massive acquisi-tion of lexical knowledge and semantic informationfrom pre-existing structured lexical resources as au-tomatically as possible.
*This research as been partially funded by CICYTTIC96-1243-C03-02 (ITEM project) and the EuropeanComission LE-4003 (EuroWordNet project).As dictionaries are special texts whose subjectmatter is a language (or a pair of languages in thecase of bilingual dictionaries) they provide a widerange of information about words by giving defini-tions of senses of words, and, doing that, supplyingknowledge not just about language, but about theworld itself.One of the most important relation to be ex-tracted from machine-readable dictionaries (MRD)is the hyponym/hypernym relation among dictio-nary senses (e.g.
(Amsler, 1981), (Vossen and Serail,1990) ) not only because of its own importance as thebackbone of taxonomies, but also because this rela-tion acts as the support of main inheritance mecha-nisms helping, thus, the acquisition of other relationsand semantic features (Cohen and Loiselle, 1988),providing formal structure and avoiding redundancyin the lexicon (Briscoe et al, 1990).
For instance,following the natural chain of dictionary senses de-scribed in the Diccionario General Ilustrado de laLengua Espadola (DGILE, 1987) we can discoverthat a bonsai is a cultivated plant or bush.bonsai_l_2 planta y arbusto asi cultivado.
(bonsai, plant and bush cultivated in that way)The hyponym/hypernym relation appears be-tween the entry word (e.g.
bonsai) and the genusterm, or the core of the phrase (e.g.
planta andarbusto).
Thus, usually a dictionary definition iswritten to employ a genus term combined with dif-ferentia which distinguishes the word being definedfrom other words with the same genus term 1.As lexical ambiguity pervades language in texts,the words used in dictionary are themselves lexicallyambiguous.
Thus, when constructing complete dis-ambiguated taxonomies, the correct dictionary senseof the genus term must be selected in each dictionary:For other kind of definition patterns not based ongenus, a genus-like term was added after studying thosepatterns.48DGILEoverallheadwords 93,484senses 168,779total numberof wordsaverage lengthof definition1,227,3807.26nouns53,79993,275903,1639.68LPPLoverall nouns15,953 10,50622,899 13,74097,778 66,3233.27 3.82Table 1: Dictionary Datadefinition, performing what is usually called WordSense Disambiguation (WSD) 2.
In the previous ex-ample planta has thirteen senses and arbusto onlyone.Although a large set of dictionaries have been ex-ploited as lexicM resources, the most widely usedmonolingual MRD for NLP is LDOCE which wasdesigned for learners of English.
It is clear that dif-ferent dictionaries do not contain the same explicitinformation.
The information placed in LDOCE hasallowed to extract other implicit information easily,e.g.
taxonomies (Bruce et al, 1992).
Does it meanthat only highly structured ictionaries like LDOCEare suitable to be exploited to provide lexical re-sources for NLP systems?We explored this question probing two disparatedictionaries: Diccionario General Ilustrado de laLengua Espa~ola (DGILE, 1987) for Spanish, andLe Plus Petit Larousse (LPPL, 1980) for French.Both are substantially poorer in coded informationthan LDOCE (LDOCE, 1987) 3.
These dictionariesare very different in number of headwords, polysemydegree, size and length of definitions (c.f.
table 1).While DGILE is a good example of a large sizeddictionary, LPPL shows to what extent he smallestdictionary is useful.Even if most of the techniques for WSD are pre-sented as stand-alone, it is our belief, following theideas of (McRoy, 1992), that full-fledged lexical am-biguity resolution should combine several informa-tion sources and techniques.
This work does not ad-dress all the heuristics cited in her paper, but prof-its from techniques that were at hand, without anyclaim of them being complete.
In fact we use unsu-pervised techniques, i.e.
those that do not requirehand-coding of any kind, that draw knowledge froma variety of sources - the source dictionaries, bilin-gual dictionaries and WordNet - in diverse ways.2Called also Lexical Ambiguity Resolution, WordSense Discrimination, Word Sense Selection or WordSense Identification.3In LDOCE, dictionary senses are explicitly orderedby frequency, 86% dictionary senses have semantic odesand 44% of dictionary senses have pragmatic codes.This paper tries to proof that using an appropriatemethod to combine those heuristics we can disam-biguate the genus terms with reasonable precision,and thus construct complete taxonomies from anyconventional dictionary in any language.This paper is organized as follows.
After this shortintroduction, section 2 shows the methods we haveapplied.
Section 3 describes the test sets and showsthe results.
Section 4 explains the construction ofthe lexical knowledge resources used.
Section 5 dis-cusses previous work, and finally, section 6 facessome conclusions and comments on future work.2 Heur i s t i cs  fo r  Genus  SenseD isambiguat ionAs the methods described in this paper have beendeveloped for being applied in a combined way, eachone must be seen as a container of some part of theknowledge (or heuristic) needed to disambiguate hecorrect hypernym sense.
Not all the heuristics aresuitable to be applied to all definitions.
For combin-ing the heuristics, each heuristic assigns each candi-date hypernym sense a normalized weight, i.e.
a realnumber anging from 0 to 1 (after a scaling process,where maximum score is assigned 1, c.f.
section 2.9).The heuristics applied range from the simplest (e.g.heuristic 1, 2, 3 and 4) to the most informed ones(e.g.
heuristics 5, 6, 7 and 8), and use informationpresent in the entries under study (e.g.
heuristics 1,2, 3 and 4) or extracted from the whole dictionary asa unique lexical knowledge resource (e.g.
heuristics5 and 6) or combining lexical knowledge from sev-eral heterogeneous lexical resources (e.g.
heuristic 7and 8).2.1 Heurist ic  1: Monosemous  Genus TermThis heuristic is applied when the genus term ismonosemous.
As there is only one hypernym sensecandidate, the hyponym sense is attached to it.
Only12% of noun dictionary senses have monosemousgenus terms in DGILE, whereas the smaller LPPLreaches 40%.2.2 Heurist ic  2: Ent ry  Sense Order ingThis heuristic assumes that senses are ordered in anentry by frequency of usage.
That is, the most usedand important senses are placed in the entry beforeless frequent or less important ones.
This heuristicprovides the maximum score to the first sense of thehypernym candidates and decreasing scores to theothers.492.3 Heur is t ic  3: Expl ic i t  Semant ic  DomainThis heuristic assigns the maximum score to the hy-pernym sense which has the same semantic domaintag as the hyponym.
This heuristic is of limited ap-plication: LPPL lacks semantic tags, and less than10% of the definitions in DGILE are marked withone of the 96 different semantic domain tags (e.g.med.
for medicine, or def.
for law, etc.
).2.4 Heur is t ic  4: Word  Match ingThis heuristic trusts that related concepts will beexpressed using the same content words.
Giventwo definitions - that of the hyponym and that ofone candidate hypernym - this heuristic computesthe total amount of content words shared (includingheadwords).
Due to the morphological productivityof Spanish and French, we have considered iffer-ent variants of this heuristic.
For LPPL the matchamong lemmas proved most useful, while DGILEyielded better results when matching the first fourcharacters of words.2.5 Heur is t ic  5: S imple  Cooccur renceThis heuristic uses cooccurrence data collected fromthe whole dictionary (see section 4.1 for more de-tails).
Thus, given a hyponym definition (O) and aset of candidate hypernym definitions, this methodselects the candidate hypernym definition (E) whichreturns the maximum score given by formula (1):SC(O, E) : E cw(wi, wj) (I)'wIEOAwj6EThe cooccurrence weight (cw) between two wordscan be given by Cooccurrence Frequency, MutualInformation (Church and Hanks, 1990) or Associ-ation Ratio (Resnik, 1992).
We tested them us-ing different context window sizes.
Best results wereobtained in both dictionaries using the AssociationRatio.
In DGILE window size 7 proved the mostsuitable, whereas in LPPL whole definitions wereused.2.6 Heur ist ic  6: Cooccur rence  VectorsThis heuristic is based on the method presented in(Wilks et al, 1993) which also uses cooccurrencedata collected from the whole dictionary (c.f.
sec-tion 4.1).
Given a hyponym definition (O) and a setof candidate hypernym definitions, this method se-lects the candidate hypernym (E) which returns themaximum score following formula (2):CV(O, E) = sim(Vo, VE) (2)The similarity (sim) between two definitions canbe measured by the dot product, the cosine functionor the Euclidean distance between two vectors (Voand VE) which represent the contexts of the wordspresented in the respective definitions following for-mula (3):t%el = eiv(wd (3)wi6De,fThe vector for a definition (VDel) is computedadding the cooccurrence information vectors of thewords in the definition (civ(wi)).
The cooccur-rence information vector for a word is collected fromthe whole dictionary using Cooccurrence Frequency,Mutual Information or Association Ratio.
The bestcombination for each dictionary vary: whereas thedot product, Association Ratio, and window size 7proved best for DGILE, the cosine, Mutual Informa-tion and whole definitions were preferred for LPPL.2.7 Heur is t i c  7: Semant ic  VectorsBecause both LPPL and DGILE are poorly seman-tically coded we decided to enrich the dictionary as-signing automatically a semantic tag to each dictio-nary sense (see section 4.2 for more details).
Insteadof assigning only one tag we can attach to each dic-tionary sense a vector with weights for each of the25 semantic tags we considered (which correspondto the 25 lexicographer files of WordNet (Miller,1990)).
In this case, given an hyponym (O) and aset of possible hypernyms we select he candidate hzy-pernym (E) which yields maximum similarity amongsemantic vectors:sv(o ,  E) = sim(Vo, (4)where sim can be the dot product, cosine or Eu-clidean Distance, as before.
Each dictionary sense.has been semantically tagged with a vector of se-mantic weights following formula (5).Yogi = sw (w,) (5)wiEDefThe salient word vector (swv) for a word containsa saliency weight (Yarowsky, 1992) for each of the 25semantic tags of WordNet.
Again, the best methoddiffers from one dictionary to the other: each oneprefers the method used in the previous ection.2.8 Heur is t ic  8" Conceptua l  D is tanceConceptual distance provides a basis for determiningcloseness in meaning among words, taking as refer-ence a structured hierarchical net.
Conceptual dis-tance between two concepts is essentially the length50of the shortest path that connects the concepts inthe hierarchy.
In order to apply conceptual distance,WordNet was chosen as the hierarchical knowledgebase, and bilingual dictionaries were used to linkSpanish and French words to the English concepts.Given a hyponym definition (O) and a set of candi-date hypernym definitions, this heuristic hooses thehypernym definition (E) which is closest accordingto the following formula:CD(O, E) = dist(headwordo, genusE) (6)That is, Conceptual Distance is measured betweenthe headword of the hyponym definition and thegenus of the candidate hypernym definitions usingformula (7), c.f.
(Agirre et al, 1994).
To computethe distance between any two words (wl,w2), all thecorresponding concepts in WordNet (el,, e2j) aresearched via a bilingual dictionary, and the mini-mum of the summatory for each concept in the pathbetween each possible combination of c1~ and c2~ isreturned, as shown below:1 dist(wl, w2) = rain E depth(ck) Cl i EWlC2j EW2 CkEpath(c l~ ,c2.i )(7)Formulas (6) and (7) proved the most suitableof several other possibilities for this task, includ-ing those which included full definitions in (6) orthose using other Conceptual Distance formulas, c.f.
(Agirre and Rigau, 1996).2.9 Combining the heuristics: SummingAs outlined in the beginning of this section, the wayto combine all the heuristics in one single decisionis simple.
The weights each heuristic assigns to therivaling senses of one genus are normalized to theinterval between 1 (best weight) and 0.
Formula (8)shows the normalized value a given heuristic will giveto sense E of the genus, according to the weight as-signed to the heuristic to sense E and the maximumweight of all the sense of the genus Ei.vote(O, E) = weight(O, E)max E, ( weigth( O , Ei ) ) (s)The values thus collected from each heuristic, areadded up for each competing sense.
The order inwhich the heuristics are applied has no relevance atall.Correct Genus SelectedMonosemousSenses per genusidem (polysemous only)Correct senses per genusidem (polysemous only)DGILE LPPL391382 (98%)61 (16%)115111 (97%)40 (36%)2.75 2.293.64 3.021.381.511.05\ [ \ ]Table 2: Test Sets3 Eva luat ion3.1 Test SetIn order to test the performance ofeach heuristic andtheir combination, we selected two test sets at ran-dom (one per dictionary): 391 noun senses for DG-ILE and 115 noun senses for LPPL, which give confi-dence rates of 95% and 91% respectively.
From thesesamples, we retained only those for which the au-tomatic selection process elected the correct genus(more than 97% in both dictionaries).
Both test setswere disambiguated by hand.
Where necessary mul-tiple correct senses were allowed in both dictionaries.Table 2 shows the data for the test sets.3.2 Resu l tsTable 3 summarizes the results for polysemousgenus.In general, the results obtained for each heuristicseem to be poor, but always over the random choicebaseline (also shown in tables 3 and 4).
The bestheuristics according to the recall in both dictionariesis the sense ordering heuristic (2).
For the rest, thedifference in size of the dictionaries could explain thereason why cooccurrence-based heuristics (5 and 6)are the best for DGILE, and the worst for LPPL.Semantic distance gives the best precision for LPPL,but chooses an average of 1.25 senses for each genus.With the combination of the heuristics (Sum)we obtained an improvement over sense ordering(heuristic 2) of 9% (from 70% to 79%) in DGILE,and of 7% (from 66% to 73%) in LPPL, maintainingin both cases a coverage of 100%.
Including monose-mous genus in the results (c.f.
table 4), the sumis able to correctly disambiguate 83% of the genusin DGILE (8% improvement over sense ordering)and 82% of the genus in LPPL (4% improvement).Note that we are adding the results of eight differentheuristics with eight different performances, improv-ing the individual performance of each one.In order to test the contribution of each heuris-tic to the total knowledge, we tested the sum of allthe heuristics, eliminating one of them in turn.
Theresults are provided in table 5.51LPPLrecallprecisioncoverageDGILErecallprecisioncoverageLPPLrecallprecisioncoverageDGILErecallprecisionrandom (1) (2) (3) (4) (5) (6)36% 66% 8% 11% 22%36% - 66% 66% 44% 61%100% 100% 12% 25% 36%(7)11%57%19%(8)50%76%66%Sum73%73%100%30% 70% 1% 44% 57% 60% 57% 47% 79%30% 70% 100% 72% 57% 60% 58% 49% 79%100% 100% 1% 61% 100% 100% 99% 95% 100%Table 3: Results for polysemous genus.coveragerandom (1) (2) (3) (4) (5) (6)59% 35% 78% - 40% 42% 50%59% 100% 78% 93% 82% 84%100% 35% 100% 43% 51% 59%(7)42%88%48%(s)68%87%78%Sum82%82%100%41% 16% 75% 2% 41% 59% 63% 59% 48% 83%41% 100% 75% 100% 79% 65% 66% 63% 57% 83%100% 16% 100% 2% 56% 95% 97% 94% 89% 100%Table 4: Overall results.LPPL Sum -(1) -(2) -(3) -(4) -(5) -(6)recall 82% 73% 74% - 73% 76% 77%precision 82% 73% 75% - 73% 76% 77%coverage 100% 100% 99% - 100% 100% 100%DGILErecall 83% 79% 72% 81% 81% 81% 81%precision 83% 79% 72% 82% 81% 81% 81%coverage 100% 100% 100% 98% 100% 100% 100%-(7) -(8)77% 78%77% 78%lOO% lOO%81% 77%81% 77%100% 100%Table 5: Knowledge provided by each heuristic (overall results).
(Gale et al, 1993) estimate that any sense-identification system that does not give the cor-rect sense of polysemous words more than 75% ofthe time would not be worth serious consideration.As table 5 shows this is not the case in our sys-tem.
For instance, in DGILE heuristic 8 has theworst performance (see table 4, precision 57%), butit has the second larger contribution (see table 5,precision decreases from 83% to 77%).
That is,even those heuristics with poor performance an con-tribute with knowledge that other heuristics do notprovide.3.3 Evaluat ionThe difference in performance between the two dic-tionaries how that quality and size of resources ia key issue.
Apparently the task of disambiguatingLPPL seems easier: less polysemy, more monose-mous genus and high precision of the sense order-ing heuristic.
However, the heuristics that dependonly on the size of the data (5, 6) perform poorly onLPPL, while they are powerful methods for DGILE.The results show that the combination of heuris-tics is useful, even if the performance of some of theheuristics is low.
The combination performs betterthan isolated heuristics, and allows to disambiguateall the genus of the test set with a success rate of83% in DGILE and 82% in LPPL.All the heuristics except heuristic 3 can readily beapplied to any other dictionary.
Minimal parameteradjustment (window size, cooccurrence weigth for-mula and vector similarity function) should be doneto fit the characteristics of the dictionary, but ac-cording to our results it does not alter significantlythe results after combining the heuristics.4 Der ived  Lex ica l  KnowledgeResources4.1 Cooccur rence  DataFollowing (Wilks et al, 1993) two words cooccurif they appear in the same definition (word order indefinitions are not taken into account).
For instance,for DGILE, a lexicon of 300,062 cooccurrence pairsamong 40,193 word forms was derived (stop wordswere not taken into account).
Table 6 shows the firsteleven words out of the 360 which cooccur with vino(wine) ordered by Association Ratio.
From left toright, Association Ratio and number of occurrences.The lexicon (or machine-tractable dictionary,52AR #oc.11.1655 15 tinto (red)10.0162 23 beber (to drink)9.6627 14 mos?o (must)8.6633 9 jerez (sherry)8.1051 9 cubas (cask, barrel)8.0551 16 licor (liquor)7.2127 17 bebida (drink)6.9338 12 uva (grape)6.8436 9 trago (drink, swig)6.6221 12 sabot (taste)6.4506 15 pan (bread)Table 6: Example of(wine).association ratio for vinoMTD) thus produced from the dictionary is usedby heuristics 5 and 6.4.2 Mult i l ingual  DataHeuristics 7 and 8 need external knowledge, notpresent in the dictionaries themselves.
This knowl-edge is composed of semantic field tags and hier-archical structures, and both were extracted fromWordNet.
In order to do this, the gap between ourworking languages and English was filled with twobilingual dictionaries.
For this purpose, we deriveda list of links for each word in Spanish and Frenchas follows.Firstly, each Spanish or French word was lookedup in the bilingual dictionary, and its English trans-lation was found.
For each translation WordNetyielded its senses, in the form of WordNet concepts(synsets).
The pair made of the original word andeach of the concepts linked to it, was included in afile, thus producing a MTD with links between Span-ish or French words and WordNet concepts.
Obvi-ously some of this links are not correct, as the trans-lation in the bilingual dictionary may not necessarilybe understood in its senses (as listed in WordNet).The heuristics using these MTDs are aware of this.For instance when accessing the semantic fieldsfor vin (French) we get a unique translation, wine,which has two senses in WordNet: <wine,vino>as a beverage, and <wine, wine-coloured> asa kind of color.
In this example two linkswould be produced (vin, <wine,vino>) and(vin, <wine, wine-coloured>).
This link allowsus to get two possible semantic fields for vin(noun.food, file 13, and noun.attribute, file 7)and the whole structure of the hierarchy in Word-Net for each of the concepts.5 Compar i son  w i th  P rev ious  WorkSeveral approaches have been proposed for attachingthe correct sense (from a set of prescribed ones) of aword in context.
Some of them have been fully testedin real size texts (e.g.
statistical methods (Yarowsky,1992), (Yarowsky, 1994), (Miller and Teibel, 1991),knowledge based methods (Sussna, 1993), (Agirreand Rigau, 1996), or mixed methods (Richardsonet al, 1994), (Resnik, 1995)).
The performanceof WSD is reaching a high stance, although usuallyonly small sets of words with clear sense distinctionsare selected for disambiguation (e.g.
(Yarowsky,1995) reports a success rate of 96% disambiguatingtwelve words with two clear sense distinctions eachone).This paper has presented a general techniquefor WSD which is a combination of statistical andknowledge based methods, and which has been ap-plied to disambiguate all the genus terms in two dic-tionaries.Although this latter task could be seen easier thangeneral WSD 4, genus are usually frequent and gen-eral words with high ambiguity ~.
While the averageof senses per noun in DGILE is 1.8 the average ofsenses per noun genus is 2.75 (1.30 and 2.29 respec-tively for LPPL).
Furthermore, it is not possible toapply the powerful "one sense per discourse" prop-erty (Yarowsky, 1995) because there is no discoursein dictionaries.WSD is a very difficult task even for humans 6,but semiautomatic echniques to disambiguate g nushave been broadly used (Amsler, 1981) (Vossen andSerail, 1990) (Ageno et ah, 1992) (Artola, 1993)and some attempts to do automatic genus disam-biguation have been performed using the semanticcodes of the dictionary (Bruce et al, 1992) or us-ing cooccurrence data extracted from the dictionaryitself (Wilks et al, 1993).Selecting the correct sense for LDOCE genusterms, (Bruce et al, 1992)) report a success rateof 80% (90% after hand coding of ten genus).
Thisimpressive rate is achieved using the intrinsic char-4In contrast o other sense distinctions Dictionaryword senses frequently differ in subtle distinctions (onlysome of which have to do with meaning (Gale et ah,1993)) producing a large set of closely related ictionarysenses (Jacobs, 1991).5However, in dictionary definitions the headword andthe genus term have to be the same part of speech.6(Wilks et al, 1993) disambiguating 197 occurrencesof the word bank in LDOCE say "was not an easy task,as some of the usages of bank did not seem to fit anyof the definitions very well".
Also (Miller et al, 1994)tagging semantically SemCor by hand, measure an errorrate around 10% for polysemous words.53acteristics of LDOCE.
Yhrthermore, using only theimplicit information contained into the dictionarydefinitions of LDOCE (Cowie et al, 1992) reporta success rate of 47% at a sense level.
(Wilks etal., 1993) reports a success rate of 45% disambiguat-ing the word bank (thirteen senses LDOCE) using atechnique similar to heuristic 6.
In our case, combin-ing informed heuristics and without explicit seman-tic tags, the success rates are 83% and 82% over-all, and 95% and 75% for two-way ambiguous genus(DGILE and LPPL data, respectively).
Moreover,93% and 92% of times the real solution is betweenthe first and second proposed solution.6 Conc lus ion and Future WorkThe results show that computer aided constructionof taxonomies using lexical resources is not limitedto highly-structured dictionaries as LDOCE, but hasbeen succesfully achieved with two very different dic-tionaries.
All the heuristics used are unsupervised,in the sense that they do not need hand-codding ofany kind, and the proposed method can be adaptedto any dictionary with minimal parameter setting.Nevertheless, quality and size of the lexical knowl-edge resources are important.
As the results forLPPL show, small dictionaries with short definitionscan not profit from raw corpus techniques (heuristics5, 6), and consequently the improvement of preci-sion over the random baseline or first-sense heuristicis lower than in DGILE.We have also shown that such a simple techniqueas just summing is a useful way to combine knowl-edge from several unsupervised WSD methods, al-lowing to raise the performance of each one in isola-tion (coverage and/or precision).
Furthermore, venthose heuristics with apparently poor results provideknowledge to the final result not provided by the restof heuristics.
Thus, adding new heuristics with dif-ferent methodologies and different knowledge (e.g.from corpora) as they become available will certainlyimprove the results.Needless to say, several improvements can bedone both in individual heuristic and also in themethod to combine them.
For instance, the cooccur-fence heuristics have been applied quite indiscrim-inately, even in low frequency conditions.
Signifi-cance tests or association coefficients could be usedin order to discard low confidence decisions.
Also,instead of just summing, more clever combinationscan be tried, such as training classifiers which usethe heuristics as predictor variables.Although we used these techniques for genus dis-ambiguation we expect similar results (or even bet-ter taken the "one sense per discourse" propertyand lexical knowledge acquired from corpora) for theWSD problem.7 AcknowledgmentsThis work would not be possible without the col-laboration of our colleagues, pecially Jose Mari Ar-riola, Xabier Artola, Arantza Diaz de Ilarraza, KepaSarasola nd Aitor Soroa in the Basque Country andHoracio Rodr~guez in Catalonia.ReferencesAlicia Ageno, Irene CastellSn, Maria AntoniaMarti, Francesc Ribas, German Rigau, HoracioRodriguez, Mariona Taul@ and Felisa Verdejo.1992.
SEISD: An environment for extraction ofSemantic information from on-line dictionaries.In Proceedings of the 3th Conference on AppliedNatural Language Processing (ANLP'92), Trento,Italy.Eneko Agirre, Xabier Arregi, Xabier Artola, ArantzaDiaz de Ilarraza and Kepa Sarasola.
1994.
Con-ceptual Distance and Automatic Spelling Correc-tion.
In Proceedings of the workshop on Compu-tational Linguistics /or Speech and HandwritingRecognition, Leeds, United Kingdom.Eneko Agirre and German Rigau.
1996.
WordSense Disambiguation using Conceptual Density.In Proceedings of the 16th International Confer-ence on Computational Linguistics (Coling'96),pages 16-22.
Copenhagen, Denmark.Robert Amsler.
1981.
A Taxonomy for EnglishNouns and Verbs.
In Proceedings of the 19thAnnual Meeting of the Association for Computa-tional Linguistics, pages 133-138.
Stanford, Cali-fornia.Xabier Artola.
1993.
Conception et construc-cion d'un systeme intelligent d'aide diccionariale(SIAL)).
PhD.
Thesis, Euskal Herriko Unibertsi-tatea, Donostia, Basque Country.Eduard Briscoe, Ann Copestake and Branimir Bogu-raev.
1990.
Enjoy the paper: Lexical Semanticsvia lexicology.
In Proceedings of the 13th Inter'na-tional Conference on Computational Linguistics(Coling'90), pages 42-47.Eduard Briscoe.
1991.
Lexical Issues in NaturalLanguage Processing.
In Klein E. and Veltman F.eds.
Natural Language and Speech.
pages 39-68,Springer-Verlag.Rebecca Bruce, Yorick Wilks, Louise Guthrie, BrianSlator and Ted Dunning.
1992.
NounSense - ADisambiguated Noun Taxonomy with a Sense of54Humour.
Research Report MCCS-92-2~6.
Com-puting Research Laboratory, New Mexico StateUniversity.
Las Cruces.Kenneth Church and Patrick Hanks.
1990.
WordAssociation Norms, Mutual Information, and Lex-icography.
Computational Linguistics, vol.
16, ns.1, 22-29.P.
Cohen and C. Loiselle.
1988.
Beyond ISA: Struc-tures for Plausible Inference in Semantic Data.
InProceedings of 7th Natural Language ConferenceAAAI'88.Jim Cowie, Joe Guthrie and Louise Guthrie.
1992.Lexical Disambiguation using Simulated Anneal-ing.
In Proceedings of DARPA WorkShop onSpeech and Natural Language, pages 238-242, NewYork.DGILE 1987.
Diccionario General Ilustrado de laLengua Espa~ola VOX.
Alvar M.ed.
BiblografS.A.
Barcelona, Spain.William Gale, Kenneth Church and DavidYarowsky.
1993.
A Method for DisambiguatingWord Senses in a Large Corpus.
Computers andthe Humanities 26, pages 415-439.Ralph Grishman, Catherine Macleod and AdamMeyers.
1994.. Comlex syntax: building a com-putational lexicon.
In Proceedings of the 15thAnnual Meeting of the Association for Compu-tational Linguistics, (Coling'9~).
268-272.
Kyoto,Japan.Claire Grover, John Carroll and John Reckers.
1993.The Alvey Natural Language Tools grammar (4threalese).
Technical Report 284.
Computer Labo-ratory, Cambridge University, UK.Paul Jacobs.
1991.
Making Sense of Lexical Ac-quisition.
In Zernik U.
ed., Lexical Acquisition:Exploiting On-line Resources to Build a Lexicon,Lawrence Erlbaum Associates, publishers.
Hills-dale, New Jersey.LDOCE 1987.
Longman Dictionary of Contempo-rary English.
Procter, P. ed.
Longman, Harlowand London.LPPL 1980.
Le Plus Petit Larousse.
Gougenheim,G.
ed.
Librairie Larousse.Sussan McRoy.
1992.
Using Multiple KnowledgeSources for Word Sense Discrimination.
Compu-tational Linguistics 18(1).George Miller.
1990.
Five papers on WordNet.
Spe-cial Issue of International Journal of Lexicography3(4).George Miller and David Teibel.
1991.
A pro-posal for Lexical Disambiguation.
In Proceedingsof DARPA Speech and Natural Language Work-shop, 395-399, Pacific Grave, California.George Miller, Martin Chodorow, Shari Landes,Claudia Leacock and Robert Thomas.
1994.
Us-ing a Semantic Concordance for sense Identifica-tion.
In Proceedings of ARPA Workshop on Hu-man Language Technology.Philip Resnik.
1992.
WordNet and Distributionalanalysis: A class-based approach to lexical dis-covery.
In Proceedings of AAAI Symposyum onProbabilistic Approaches to NL, San Jose, Califor-nia.Philip Resnik.
1995.
Disambiguating Noun Group-ings with Respect to WordNet Senses.
In Proceed-ings of the Third Workshop on Very Large Cor-pora, MIT.R.
Richardson, A.F.
Smeaton and J. Murphy.
1994.Using WordNet as a Knowledge Base for Measur-ing Semantic Similarity between Words.
Work-ing Paper CA-129~, School of Computer Applica-tions, Dublin City University.
Dublin, Ireland.Michael Sussna.
1993.
Word Sense Disambiguationfor Free-text Indexing Using a Massive SemanticNetwork.
In Proceedings of the Second Interna-tional Conference on Information and knowledgeManagement.
Arlington, Virginia.Piek Vossen and Iskander Serail.
1992.
Word-Devil,a Taxonomy-Browser fo Lexical Decompositionvia the Lexicon.
Esprit BRA-3030 Acquilex Work-ing Paper n. 009.Yorick Wilks, Dam Fass, Cheng-Ming Guo, JamesMcDonald, Tony Plate and Brian Slator.
1993.Providing Machine Tractable Dictionary Tools.
InPustejowsky J. ed.
Semantics and the Lexicon,pages 341-401.David Yarowsky.
1992.
Word-Sense Disambigua-tion Using Statistical Models of Rogets CategoriesTrained on Large Corpora.
In Proceedings of thel~th International Conference on ComputationalLinguistics (Coling'92), pages 454-460.
Nantes,France.David Yarowsky.
1994.
Decision Lists for LexicalAmbiguity Resolution.
In Proceedings of the 32thAnnual Meeting of the Association for Compu-tational Linguistics, (ACL'9~).
Las Cruces, NewMexico.David Yarowsky.
1995.
Unsupervised WordSense Disambiguation Rivaling Supervised Meth-ods.
In Proceedings of the 33th Annual Meetingof the Association for Computational Linguistics,(ACL'95).
Cambridge, Massachussets.55
