Using Subcategorization toResolve Verb Class AmbiguityMaria LapataSchool of Cognitive ScienceDivision of InformaticsUniversity of Edinburgh2 Buccleuch PlaceEdinburgh EH8 9LW, UKmlap@cogsci.ed.ac.ukChris BrewHCRC Language Technology GroupDivision of InformaticsUniversity of Edinburgh2 Buccleuch PlaceEdinburgh EH8 9LW, UKchrisbr@cogsci.ed.ac.ukAbstractLevin's (1993) taxonomy of verbs and their classesis a widely used resource for lexical semantics.
Inher framework, some verbs, such as give exhibit noclass ambiguity.
But other verbs, such as write, caninhabit more than one class.
In some of these am-biguous cases the appropriate class for a particulartoken of a verb is immediately obvious from inspec-tion of the surrounding context.
In others it is not,and an application which wants to recover this infor-mation will be forced to rely on some more or lesselaborate process of inference.
We present a simplestatistical model of verb class ambiguity and showhow it can be used to carry out such inference.1 IntroductionThe relation between the syntactic realization of averb's arguments and its meaning has been exten-sively studied in Levin (1993).
Levin's work re-lies on the hypothesis that "the behavior of a verb,particularly with respect o the expression and in-terpretation of its arguments, is to a large extentdetermined by its meaning" (Levin, 1993, p. 1).Verbs which display the same diathesis alterna-tions-alternations in the realization of their argu-ment structure-are assumed to share certain mean-ing components and are organized into a semanti-cally coherent class.As an example consider sentences (1)-(3)taken from Levin.
Example (1) illustrates thecausative/inchoative alternation.
Verbs undergoingthis alternation can be manifested either as transi-tive with a causative reading (cf.
(la)) or as intransi-tive with an inchoative reading (cf.
(lb)).
Examples(2) and (3) illustrate the dative and benefactive al-ternations respectively.
Verbs which license the for-mer alternate between the prepositional frame NP-V-NP-PPto (cf.
(2a)) and the double object frameV-NP-NP (cf.
(2b)), whereas verbs which undergothe latter alternate between the double object frame(cf.
(3a)) and the prepositional frame NP-V-NP-PPJ~r (cf.
(3b)).
(1) a. Janet broke the cup.b.
The cup broke.
(2) a.
Bill sold a car to Tom.b.
Bill sold Tom a car.
(3) a. Martha carved the baby a toy.b.
Martha carved a toy for the baby.Verbs like crack and chip pattern with break in li-censing the causative/inchoative alternation and areassociated with the semantic lass of BREAK verbs.Verbs make and build behave similar to carve inlicensing the benefactive alternation and are mem-bers of the class of BUILD verbs, whereas ell andgive undergo the dative alternation and participatein the GIVE class.
By grouping together verbs whichpattern together with respect o diathesis alterna-tions Levin defines approximately 200 verb classes,which she argues reflect important semantic regu-larities.2 MotivationLevin provides an index of 3,024 verbs for whichshe lists the semantic lasses and diathesis alterna-tions.
The mapping between verbs and classes isnot one-to-one.
Of the 3,024 verbs which she cov-ers, 784 are listed as having more than one class.Even though Levin's monosemous verbs outnumberher polysemous verbs by a factor of nearly four toone, the total frequency of the former (4,252,715)is comparable to the total frequency of the latter(3,986,014).
This means that close to half of thecases processed by a hypothetical semantic taggerwould manifest some degree of ambiguity.
The fre-quencies are detailed in table 1 and were compiledfrom a lemmatized version of the British NationalCorpus (BNC), a widely distributed 100 millionword collection of samples of written and spokenEnglish (Burnard, 1995).266Classes \[ Verbs I BNCfrequency1 2,239 4,252,7152 536 2,325,9823 173 738,8544 43 395,2125 23 222,7476 7 272,6697 2 26,12310 1 4,427Table 1: Polysemous verbs according to LevinI O09080706o~ so3020I001 2 ,3 4 5 6 7 8 9 10 11 12Number of alternationsClasses1234567Figure 1: Relation between umber of classes andalternationsFurthermore, as shown in figure 1, the numberof alternations licensed by a given verb increaseswith the number of classes it inhabits.
Considerfor example verbs participating in one alternationonly: of these, 90.4% have one semantic class, 8.6%have two classes, 0.7% have three classes and 0.3%have four classes.
In contrast, of the verbs licensingsix different alternations, 14% have one class, 17%have two classes, 12.4% have three classes, 53.6%have four classes, 2% have six classes and 1% hasseven classes.Palmer (1999) and Dang et al (1998) argue thatthe use of syntactic frames and verb classes can sim-plify the definition of different verb senses.
Beyondthis, we claim that information about he argumentstructure of a polysemous verb can often help dis-ambiguating it.Consider for instance the verb serve which is amember of four classes: GIVE, FIT, MASQUERADEand FULFILLING.
Each of these classes can in turnlicense four distinct syntactic frames.
As shown inthe examples I below, in (4a) serve appears ditran-sitively and belongs to the semantic lass of GIVEverbs, in (4b) it occurs transitively and is a mem-ber of the class of FIT verbs, in (4c) it takes thepredicative complement as minister of the interiorand is a member of MASQUERADE verbs.
Finally,in sentence (4d) serve is a FULFILLING verb andtakes two complements, a noun phrase (an appren-ticeship) and a prepositional phrase headed by to.In the case of verbs like serve we can guess theirsemantic lass solely on the basis of the frame withwhich they appear.
(4) a. I'm desperately trying to find a venue forthe reception which can serve our guestsan authentic Italian meal.b.
The airline serves 164 destinations in over75 countries.c.
Jean-Antoine Chaptal was a brilliantchemist and technocrat who servedNapoleon as minister of the interior from1800 to 1805.d.
Before her brief exposure to pop stardom,she served an apprenticeship to a still-lifephotographer.But sometimes we do not have the syntactic infor-mation that would provide cues for semantic disarn-biguation.
Consider sentence (5a).
The verb writeis a member of three Levin classes, two of which(MESSAGE TRANSFER, PERFORMANCE) take theditransitive flame NP-V-NP-NP.
In this case wehave the choice between the "message transfer"reading (cf.
(5a)) and the "performance" reading(cf.
(Sb)).
This is an instance of the common prob-lem of inferring the value of a hidden variable (inthis case the "true class" of a particular instanceof write).
The same situation arises with the verbphone which is listed as a GET verb and an INSTRU-MENT OF COMMUNICATION verb and in both casescan take the frame NP-V-NP-NP.
In sentence (5c)the preferred reading is that of "get" instead of "in-strument of communication" (cf.
sentence (5d)).
(5) a.
A solicitor wrote him a letter at the air-port.b.
I want you to write me a screenplay called"The Trip".1 Unless tated otherwise the example sentences were takenfrom the BNC and simplified for clarification purposes.267c.
I'll phone you a taxi.d.
As I entered the room I wished I'd thoughtof phoning a desperate SOS to James.The objective of this paper is to address theverb class disambiguation problem by developinga probabilistic framework which combines linguis-tic knowledge (i.e., Levin's classification) and framefrequencies acquired from the BNC.
Our initial ex-periments focus on the syntactic frames characteris-tic for the dative and benefactive alternations (cf.
ex-amples (2) and (3)).
These frames are licensed bya fairly large number of classes: 19 classes licensethe double object frame, 22 license the NP-V-NP-PPto frame and 14 classes license the NP-V-NPPPfi~r frame.
The semantic and syntactic propertiesof these alternations have been extensively studiedand are well understood (see Levin (1993) and thereferences therein).
Furthermore, they are fairly pro-ductive and one would expect hem to be well rep-resented in a large corpus.In section 3 we describe the statistical model andthe estimation of the various model parameters, ec-tion 4 presents ome preliminary results and sec-tion 5 contains ome discussion and concluding re-marks.3 The ModelWe view the choice of a class for a polysemousverb in a given frame as the joint probabilityP(verb,frame, class) which we rewrite using thechain rule in (6).
(6) P(verb,frame, class) = P(verb)e (frame lverb) P (class I verb, frame)We also make the following independence assump-tion:(7) P(classlverb,frame) ~ P(class\[frame)The independence assumption reflects Levin's hy-pothesis that the argument structure of a given verbis a direct reflection of its meaning.
Accordingly weassume that the semantic lass determines the argu-ment structure of its members without making ref-erence to the individual verbs.
By applying BayesLaw we write P(classlframe) as:(8) P(class\[frame)= P (frame lclass) P (class)P (frame )By substituting (7) and (8) into (6),P(verb, class,frame) can be written as:(9) P(verb,frame, class)P (verb) P (frame l verb) P (frame lclass) P (class)P ~rame )We estimate the probabilities P(verb),P(framelverb), P(framelclass) and P(class)as follows:(10) P(verb) f(verb)f (verbi)i(11) P(framelverb)(12) P(framelclass)(13) P(class) .~f (verb,frame)f (verb, framei)if (class,frame)f (class, framei)if (class)Y~.
f (classi)i(14) P(frame) ,~ f (frame)f {framei)iIt is easy to obtain f(verb) from the lemmatizedBNC.
For the experiments reported here, syntacticframes for the dative and benefactive alternationswere automatically extracted from the BNC usingGsearch (Keller et al, 1999), a tool which facilitatessearch of arbitrary POS-tagged corpora for shallowsyntactic patterns based on a user-specified context-free grammar and a syntactic query.
The acquisitionand filtering process is detailed in Lapata (1999).We rely on Gsearch to provide moderately accu-rate information about verb frames in the same waythat Hindle and Rooth (1993) relied on Fidditch toprovide moderately accurate information about syn-tactic structure, and Ratnaparkhi (1998) relied onsimple heuristics defined over part-of-speech tagsto deliver information early as useful as that pro-vided by Fidditch.
We estimated f(verb,frame) asthe number of times a verb co-occurred with a par-ticular frame in the corpus.We cannot read off P(frame\[class) from the cor-pus, because it is not annotated with verb classes.Nevertheless we can use the information listed inLevin with respect o the syntactic frames exhib-ited by the verbs of a given class.
For each class268Class FramesMAN NER NP-V-NP-PP#om, NP-V-NP,NP-V-PPat, NP-V-NP-PREDACCOMPANY NP-V-NP, NP-V-NP-PPt,,THROW NP-V-NP-NP, NP-V-NP-PPtoc,NP-V-NP-PP#om-PPto, NP-V-NP,NP-V-NP-PPto, NP-V-NP-PPar,PERFORMANCE NP-V, NP-V-NP, NP-V-NP-NP,NP-V-NP-PPto, NP-V-NP-PP?~r,NP-V-NPG I v E NP-V-NP-PPto, NP-V-NP-NPCONTRIBUTE NP-V-NP-PPtoTable 2: Sample of verb classes and their syntacticframeswe recorded the syntactic frames it licenses (cf.
ta-ble 2).
Levin's description of the argument struc-ture of various verbs goes beyond the simple list-ing of their subcategofization.
Useful informationis provided about the thematic roles of verbal argu-ments and their interpretation.
Consider the exam-ples in (15): in (15a) the verb present is a member ofthe FULFILLING class and its theme is expressed bythe prepositional phrase with an award, in (15b) thePP headed by with receives a locative interpretationand the verb load inhabits the SPRAY/LOAD class,whereas in (15c) the prepositional phrase is instru-mental and hit inhabits the HIT class.
None of theinformation concerning thematic roles was retained.All three classes (FULFILLING, SPRAY/LOAD andHIT) were assigned the frame NP-V-NP-PPwith'.
(15) a.b.C.John presented the student with an award.John loaded the truck with bricks.John hit the wall with a hammer.Because we didn't have corpus counts for thequantity f(class,frame) we simply assumed thatall frames for a given class are equally likely.This means, for instance, that the estimate forP(NP-V-NP-NPtolGIvE) is ?
and similarly the es-timate for P(NP-VIPERFORMANCE ) is ~ (cf.
ta-ble 2).
This is clearly a simplification, since onewould expect f(class,frame) tobe different for dif-ferent corpora, and to vary with respect to class sizeand the frequency of class members.In order to estimate P(class) we first estimatef(class) which we rewrite as follows:(16) f (class) = E f (verbi, class)iClass size(class) p(class\[amb_class) f (verb, class)THROW 27 0.40 7783.6SEND 20 0.27 5253.9GIVE 15 0.20 3891.8MARRY 10 0.13 2529.6Table 3: Estimation of f(verb, class) for the verbpassThe estimate of f(verb, class) for monosemousverbs reduces to the count of the verb in the cor-pus.
Once again we cannot estimate f(verb, class)for polysemous verbs directly.
All we have is theoverall frequency of a given verb in the BNC andthe number of classes it is a member of according toLevin.
We rewrite f(verb, class) as:(17) f (verb, class) = f (verb)p(classlverb)We approximate p(classlverb) by collapsing acrossall verbs that have the appropriate pattern of ambi-guity:(18) f (verb, class) ~ f (verb)p(classlamb_class)Here amb_class, the ambiguity class of a verb, isthe set of classes that it might inhabit.
2We collapseverbs into ambiguity classes in order to reduce thenumber of parameters which must be estimated: wecertainly lose information, but the approximationmakes it easier to get reliable estimates from limiteddata.
In future work we plan to use the EM algo-rithm (Dempster et al, 1977) to uncover the hiddenclass, but for the present study, we simply approxi-mate p(classlamb_class) using a heuristic based onclass size:size(class)(19) p(classlamb_class)size(c)c ~ amb~' lassFor each class we recorded the number of its mem-bers after discarding verbs whose frequency wasless than 1 per 1M in the BNC.
This gave us a firstapproximation of the size of each class.
We thencomputed, for each polysemous verb, the total sizeof the classes of which it was a member.
We calcu-lated p(classlamb_class) bydividing the former bythe latter (cf.
equation (19)).
We obtained an esti-mate for the class frequency f(class) by multiply-ing p(classlamb_class) by the observed frequencyof the verb in the BNC (cf.
equation (18)).2Our use of ambiguity classes is inspired by a similar use inHMM based part-of-speech tagging (Kupiec, 1992).269~e.+05 -4e+05 -u~2e.H)5 -??
?I !
: ..... ~: :;No N N"?
E "Figure 2: The ten most frequent classes1201oo~ so~ 60E~ 4077-20 ~ ,;.ItFigure 3:0.Z IgZmTen most frequent frames in LevinAs an example consider the verb pass which hasthe classes THROW, SEND, GIVE and MARRY.
Therespective p(classlamb_class) for these classes are27 20 15 and l0 By multiplying these by the fre-72 '  72 '  72 ~"quency of pass in the BNC (19,559) we obtainthe estimates for f(verb, class) given in table 3.Note that simply relying on class size, without re-gard to frequency, would give quite different results.For example the class of MANNER OF SPEAKINGverbs has 76 members, of which 30 have frequen-cies which are less than 1 per 1M, and is the sev-enth largest class in Levin's classification.
Accord-ing to our estimation scheme MANNER OF SPEAK-ING verbs are the 116th largest class.
The estimatesfor the ten most frequent classes are shown in fig-ure 2.The estimation process described above in-volves at least one gross simplification, sincep(classlamb_class) i  calculated without referenceto the identity of the verb in question.
For anytwo verbs which fall into the same set of classesp(classlamb_class) will be the same, even thoughone or both may be atypical in its distribution acrossthe classes.
Furthermore, the estimation tends tofavour large classes, again irrespectively of the iden-tity of the verb in question.
For example the verbcarry has three classes, CARRY, FIT and COST.
In-tuitively speaking, the CARRY class is the most fre-quent (e.g., Smoking can impair the blood whichcarries oxygen to the brain, I carry sugar lumpsaround with me).
However, since the FIT class(e.g., Thameslink presently carr/es 20,000 passen-gers daily) is larger than the CARRY class, it will begiven a higher probability (0.45 versus 0.4).
This isclearly wrong, but it is an empirical question howmuch it matters.Finally, we wanted to estimate the probabilityof a given frame, P(frame).
We could have donethis by acquiring Levin compatible subcategoriza-tion frames from the BNC.
Techniques for the auto-matic acquisition of subcategofization dictionarieshave been developed by Manning (1993), Bfiscoeand Carroll (1997) and Carroll and Rooth (1998).But the present study was less ambitious, and nar-rowly focused on the frames representing the da-tive and the benefactive alternation.
In default of themore ambitious tudy, which we plan for the future,the estimation of P(frame) was carried out on typesand not on tokens.
The mapping of Levin's linguis-tic specifications into surface syntactic informationresulted in 79 different frame types.
By counting thenumber of times a given frame is licensed by severalsemantic lasses we get a distribution of frames, asample of which is shown in figure 3.The probabilities P(frmnelclass) andP(framelverb) will be unreliable when thefrequency estimates for f(verb,frame) andf(class,frame) are small, and ill-defined whenthe frequency estimates are zero.
FollowingHindle and Rooth (1993) we smooth the ob-served frequencies in the following way, wheref(V,frame) = ~i.f(verbi,frame), f (V )  =270~i  f (verbi), f (C,frame) : ~ i  f (classi,ft~me)and f(C) = ~ i  f(classi).
We redefine theprobability estimates as follows:(20) P (framel verb)f(V,Jmme) f (verb,frame) + f(v)f (verb,framei) + 1i(21 ) P (framelclass)f(C,/~ame) f (class,frame) + f(c)f (class,framei) + 1iWhen f(verb,frame) is zero, the estimate usedis proportional to the average f(V.frame) f(v) across allverbs.
Similarly, when f(class,frame) is zero, ourestimate is proportional to the average f(c.l'~ame) f(C)across all classes.
We don't claim that this scheme isperfect, but any deficiencies it may have are almostcertainly masked by the effects of approximationsand simplifications elsewhere in the system.4 ResultsWe evaluated the performance of the model on allverbs listed in Levin which are polysemous and takeframes characteristic for the dative and benefactivealternations.
This resulted in 154 verbs which takethe NP-V-NP-NP frame, 135 verbs which take theNP-V-NP-PPw frame and 84 verbs which take theNP-V-NP-PPj~,r frame.
The verbs were all polyse-mous and had an average of 3.8 classes.
Each classhad an average of 3.4 frames.
Furthermore, we di-vided these verbs in two categories: verbs which canbe disambiguated solely on the basis of their frame(e.g., serve; category A) and verbs which are gen-uinely ambiguous, i.e., they inhabit a single frameand yet can be members of more than one semanticclass (e.g., write; category B).The task was the following: given that we knowthe frame of a given verb can we predict its se-mantic class?
In other words by varying the classin the term P(verb,frame, class) we are trying tosee whether the class which maximizes it is the onepredicted by the lexical semantics and the argumentstructure of the verb in question.For the verbs belonging to category A (306 intotal) we used Levin's own classification in eval-uation.
The model's performance was consideredcorrect if it agreed with Levin in assigning a verbthe appropriate class given a particular frame.
Forclass ambiguous verbs (category B) we comparedthe model's predictions against manually annotateddata.
Given the restriction that these verbs are se-mantically ambiguous in a specific syntactic framewe could not simply sample from the entire BNC,since this would decrease the chances of finding theverb in the frame we are interested in.
Instead, for31 class ambiguous verbs we randomly selected ap-proximately 100 tokens from the data used for theacquisition of frame frequencies for the dative andbenefactive alternation.
Verbs with frame frequencyless than 100 were not used in the evaluation.The selected tokens were annotated with class in-formation by two judges.
The judges were given an-notation guidelines but no prior training.
We mea-sured the judges' agreement on the annotation taskusing the Kappa coefficient (Siegel and Castellan,1988) which is the ratio of the proportion of times,P(A), that k raters agree to the proportion of times,P(E), that we would expect he raters to agree bychance (cf.
(22)).
If there is a complete agreementamong the raters, then K = 1, whereas if there is noagreement among the raters (other than the agree-ment which would be expected to occur by chance),then K = 0.P(A) - P(E)(22) K -1 - P (E )We counted the performance of our model as cor-rect if it agreed with the "most preferred", i.e., mostfrequent verb class as determined in the manuallyannotated corpus sample by taking the average ofthe responses of both judges.We also compared the results for both categoriesto a naive baseline which relies only on class in-formation and does not take subcategorization intoaccount.
For a given polysemous verb, the baselinewas computed by defaulting to its most frequentclass, where class frequency was determined by theestimation procedure described in the previous ec-tion.As shown in table 4, in all cases our model out-performs the baseline.
It achieves a combined pre-cision of 91.8% for category A verbs.
One mightexpect a precision of 100% since these verbs canbe disambiguated solely on the basis of the frame.However, the performance of our model is less,mainly because of the way we estimated the termsP(class) and P(frame\[class): we overemphasizethe importance of frequent classes without takinginto account how individual verbs distribute acrossclasses.The model achieves a combined precision of83.9% for category B verbs (cf.
table 4).
Further-271II Category AFrame \[Verbs BaselineNP-V-NP-NP 123 61.8%NP-V-NP-PPto 113 67.2%NP'V-NP-PPfor 70 70%combinedCategory BModel Verbs Baseline Model87.8% 14 42.8% 85.7%92% 15 73.4% 86.6%98.5% 2 0% 50%II 306 165.7% 191.8% \[31 161.3% 183.9%Table 4: Model accuracy against baselineVerb Frame Preferencessave NP-V-NP-NPcall NP-V-NP-NPwrite NP-V-NP-NPmake NP-V-NP-NPextend NP-V-NP-PPtopresent NP-V-NP-PPtotake NP-V-NP-PPj~,~produce NP-V-NP-PPfbrGET, BILLGET, DUBMESSAGE TRANSFER, PERFORMANCEDUB, BUILDFUTURE HAVING, CONTRIBUTEFULFILLING, REFLEXIVE APPEARANCESTEAL, PERFORMANCEPERFORMANCE, CREATETable 5: Random sample of eight verbs and their semantic preferences as ranked by the modelmore, our model makes interesting predictions withrespect o the semantic preferences of a given verb.In table 5 we show the class preferences the modelcame up with for eight randomly selected verbs(class preferences are ranked from left to right, withthe leftmost class being the most preferred one).
Ta-ble 6 summarizes the average class frequencies forthe same eight verbs as assigned to corpus tokensby the two judges together with inter-judge agree-ment (K).
The category OTHER is reserved for cor-pus tokens which either have the wrong frame orfor which the classes in question are not applicable.In general agreement on the class annotation taskwas good with Kappa values ranging from 0.68 to1.
As shown in table 6, with the exceptions of calland produce the model's predictions are borne outin corpus data.5 DiscussionVerbsavecallGET64GET2ClassBILL25DUB94write M. TRANS.
PERF.54 19make DUB BUILD59 20extend FUT.
HAV.
CONTR.50 37present FULFIL.
R. APP.79 18take PERF.
CREATE52 13produce PERF.
CREATE8 91 1I KOTHER 0.74 11OTHER 0.82 4OTHER 0.85 18OTHER 0.78 21OTHER 0.71 13OTHER 0.94 3OTHER 0.77 33OTHER i 0.73iTable 6: Random sample of eight verbs and theirsemantic preferences as ranked by two judgesThis paper explores the degree to which syntacticframe information can be used to disambiguate verbsemantic lasses.
In doing so, we cast the task ofverb class disambiguation i a probabilistic frame-work which exploits Levin's semantic lassificationand frame frequencies acquired from the BNC.
Theapproach is promising in that it achieves high preci-sion witha simple model and can be easily extendedto incorporate other sources of information whichcan influence the class selection process (i.e., selec-tional restrictions).The semantic preferences which we generate canbe thought of as default semantic knowledge, to beused in the absence of any explicit contextual orlexico-semantic nformation to the contrary (cf.
ta-ble 5).
Consider the verb write for example.
The272model comes up with an intuitively reasonable rank-ing: we more often write things to people ("messagetransfer" reading) than for them ("performance"reading).
However, faced with a sentence like Maxwrote Elisabeth a book pragmatic knowledge forcesus to prefer the "performance" reading versus thethe "message transfer" reading.
In other cases themodel comes up with a counterintuitive ranking.
Forthe verb call, for instance, the "get" reading (e.g., Iwill call you a cab) is preferred over the more natu-ral "dub" reading (e.g., John called me a fool).We still rely heavily on the verb class informa-tion provided by Levin.
But part of original aimwas to infer class information for verbs not listedby Levin.
For such a verb, P(class), and henceP(verb,frame, class) will be zero, which is notwhat we want.
Recent work in computational lin-guistics (e.g., Schfitze (1993)) and cognitive psy-chology (e.g., Landauer and Dumais (1997)) hasshown that large corpora implicitly contain seman-tic information, which can be extracted and manipu-lated in the form of co-occurrence vectors.
The ideawould be to compute the centroid (geometric mean)of the vectors of all members of a semantic lass.Given an unknown verb (i.e., a verb not listed inLevin) we can decide its semantic lass by compar-ing its semantic vector to the centroids of all seman-tic classes.
We could (for example) determine classmembership on the basis of the closest distance tothe centroid representing a semantic lass (cf.
Patelet al (1998) for a proposal similar in spirit).
Oncewe have chosen a class for an unknown verb, we areentitled to assume that it will share the broad syn-tactic and semantic properties of that class.We also intend to experiment with a full scalesubcategorization dictionary acquired from theBNC.
We believe this will address issues such as:(a) relations between frames and classes (what arethe frames for which the semantic lass is predictedmost accurately) and (b) relations between verbsand classes (what are the verbs for which the seman-tic class is predicted most accurately).
We also planto experiment with different classification schemesfor verb semantics uch as WordNet (Miller et al,1990) and intersective Levin classes (Dang et al,1998).ReferencesTed Briscoe and John Carroll.
1997.
Automaticextraction of subcategofization from corpora.
InProceedings of the 5th ACL Conference on Ap-plied Natural Language Processing, pages 356-363, Washinton, DC.Lou Bumard, 1995.
Users Guide for the British Na-tional Corpus.
British National Corpus Consor-tium, Oxford University Computing Service.Glenn Carroll and Mats Rooth.
1998.
Valenceinduction with a head-lexicalized PCFG.
InProceedings of the 3rd Conference on Empir-ical Methods in Natural Language Processing,Granada.Hoa Trang Dang, Karin Kipper, Martha Palmer, andJoseph Rosenzweig.
1998.
Investigating regu-lar sense extensions based on intersective Levinclasses.
In Proceedings of the 17th InternationalConference on Computational Linguistics and36th Annual Meeting of the Association for Com-putational Linguistics, pages 293-299, Montrral.A.
E Dempster, N. M. Laird, and D. B. Rubin.1977.
Maximum likelihood for incomplete datavia the EM algorithm.
Journal of the Royal Sta-tistical Socie~, 39(2):1-38.Donald Hindle and Mats Rooth.
1993.
Structuralambiguity and lexical relations.
ComputationalLinguistics, 19(1): 103-120.Frank Keller, Martin Corley, Steffan Corley,Matthew W. Crocker, and Shaft Trewin.
1999.Gsearch: A tool for syntactic investigation ofunparsed corpora.
In Proceedings of the EACLWorkshop on Linguistically Interpreted Corpora,Bergen.Julian Kupiec.
1992.
Robust oart-of-speech tag-ging using a hidden Markov model.
ComputerSpeech and Language, 6(3):225-242.Thomas K. Landauer and Susan T. Dumais.
1997.A solution to Plato's problem: The latent seman-tic analysis theory of acquisition, induction andrepresentation f knowledge.
Psychological Re-view, 104(2):211-240.Mafia Lapata.
1999.
Acquiring lexical generaliza-tions from corpora: A case study for diathesisalternations.
In Proceedings of the 37th AnnualMeeting of the Association for ComputationalLinguistics, College Park, MA.Beth Levin.
1993.
English Verb Classes and Alter-nations: A Preliminary.
Investigation.
Universityof Chicago Press, Chicago.Christopher D. Manning.
1993.
Automatic acquisi-tion of a large subcategorization dictionary fromcorpora.
In Proceedings of the 31st Annual Meet-ing of the Association for Computational Linguis-tics, pages 235-242, Columbus, OH.273George A. Miller, Richard Beckwith, ChristianeFellbaum, Derek Gross, and Katherine J. Miller.1990.
Introduction to WordNet: An on-line lexi-cal database.
International Journal of Lexicogra-phy, 3(4):235-244.Martha Palmer.
1999.
Consistent criteria for sensedistinctions.
Computers and the Humanities, toappear.Malti Patel, John A. Bullinaria, and Joseph E Levy.1998.
Extracting semantic representations fromlarge text corpora.
In John A. Bullinaria, D. W.Glasspool, and G. Houghton, editors, In Proceed-ings of the 4th Workshop on Neural Computa-tion and Psychology, pages 199-212.
Springer,Berlin.Adwait Ratnaparkhi.
1998.
Unsupervised statisti-cal models for prepositional phrase attachment.In Proceedings of the 7th International Confer-ence on Computational Linguistics, pages 1079-1085.Hinrich Schtitze.
1993.
Word space.
InStephen.
Jos6 Hanson, Jack D. Cowan, andC.
Lee Giles, editors, Advances in Neural In-formation Processing Systems, pages 895-902.Morgan'Kaufmann, San Mateo, CA.Sidney Siegel and N. John Castellan.
1988.
NonParametric Statistics for the Behavioral Sciences.McGraw.-Hill, New York.274
