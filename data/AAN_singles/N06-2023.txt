Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 89?92,New York, June 2006. c?2006 Association for Computational LinguisticsSummarizing Speech Without Text Using Hidden Markov ModelsSameer Maskey, Julia HirschbergDept.
of Computer ScienceColumbia UniversityNew York, NY{smaskey, julia}@cs.columbia.eduAbstractWe present a method for summarizingspeech documents without using any typeof transcript/text in a Hidden MarkovModel framework.
The hidden variablesor states in the model represent whethera sentence is to be included in a sum-mary or not, and the acoustic/prosodic fea-tures are the observation vectors.
Themodel predicts the optimal sequence ofsegments that best summarize the docu-ment.
We evaluate our method by compar-ing the predicted summary with one gen-erated by a human summarizer.
Our re-sults indicate that we can generate ?good?summaries even when using only acous-tic/prosodic information, which points to-ward the possibility of text-independentsummarization for spoken documents.1 IntroductionThe goal of single document text or speech sum-marization is to identify information from a textor spoken document that summarizes, or conveysthe essence of a document.
EXTRACTIVE SUM-MARIZATION identifies portions of the original doc-ument and concatenates these segments to form asummary.
How these segments are selected is thuscritical to the summarization adequacy.Many classifier-based methods have been exam-ined for extractive summarization of text and ofspeech (Maskey and Hirschberg, 2005; Christensenet.
al., 2004; Kupiec et.
al., 1995).
These ap-proaches attempt to classify segments as to whetherthey should or should not be included in a summary.However, the classifiers used in these methods im-plicitly assume that the posterior probability for theinclusion of a sentence in the summary is only de-pendent on the observations for that sentence, andis not affected by previous decisions.
Some of these(Kupiec et.
al., 1995; Maskey and Hirschberg, 2005)also assume that the features themselves are inde-pendent.
Such an independence assumption simpli-fies the training procedure of the models, but it doesnot appear to model the factors human beings appearto use in generating summaries.
In particular, humansummarizers seem to take previous decisions intoaccount when deciding if a sentence in the sourcedocument should be in the document?s summary.In this paper, we examine a Hidden MarkovModel (HMM) approach to the selection of seg-ments to be included in a summary that we believebetter models the interaction between extracted seg-ments and their features, for the domain of Broad-cast News (BN).
In Section 2 we describe relatedwork on the use of HMMs in summarization.
Wepresent our own approach in Section 3 and discussour results in Section 3.1.
We conclude in Section 5and discuss future research.2 Related WorkMost speech summarization systems (Christensenet.
al., 2004; Hori et.
al., 2002; Zechner, 2001) uselexical features derived from human or AutomaticSpeech Recognition (ASR) transcripts as features toselect words or sentences to be included in a sum-mary.
However, human transcripts are not gener-ally available for spoken documents, and ASR tran-scripts are errorful.
So, lexical features have prac-tical limits as a means of choosing important seg-ments for summarization.
Other research effortshave focussed on text-independent approaches to ex-tractive summarization (Ohtake et.
al., 2003), whichrely upon acoustic/prosodic cues.
However, noneof these efforts allow for the context-dependence ofextractive summarization, such that the inclusion of89one word or sentence in a summary depends uponprior selection decisions.
While HMMs are used inmany language processing tasks, they have not beenemployed frequently in summarization.
A signifi-cant exception is the work of Conroy and O?Leary(2001), which employs an HMM model with pivotedQR decomposition for text summarization.
How-ever, the structure of their model is constrained byidentifying a fixed number of ?lead?
sentences to beextracted for a summary.
In the work we presentbelow, we introduce a new HMM approach to ex-tractive summarization which addresses some of thedeficiencies of work done to date.3 Using Continuous HMM for SpeechSummarizationWe define our HMM by the following parameters:?
= 1..N : The state space, representing a set ofstates where N is the total number of states in themodel; O = o1k, o2k, o3k, ...oMk : The set of obser-vation vectors, where each vector is of size k; A ={aij} : The transition probability matrix, where aijis the probability of transition from state i to state j;bj(ojk) : The observation probability density func-tion, estimated by ?Mk=1cjkN(ojk, ?jk,?jk), whereojk denotes the feature vector; N(ojk, ?jk,?jk) de-notes a single Gaussian density function with meanof ?jk and covariance matrix ?jk for the state j,with M the number of mixture components and cjkthe weight of the kth mixture component; ?
= pii :The initial state probability distribution.
For conve-nience, we define the parameters for our HMM bya set ?
that represents A, B and ?.
We can use theparameter set ?
to evaluate P (O|?
), i.e.
to measurethe maximum likelihood performance of the outputobservables O.
In order to evaluate P (O|?
), how-ever, we first need to compute the probabilities inthe matrices in the parameter set ?The Markov assumption that state durations havea geometric distribution defined by the probabilityof self transitions makes it difficult to model dura-tions in an HMM.
If we introduce an explicit du-ration probability to replace self transition proba-bilities, the Markov assumption no longer holds.Yet, HMMs have been extended by defining stateduration distributions called Hidden Semi-MarkovModel (HSMM) that has been succesfully used(Tweed et.
al., 2005).
Similar to (Tweed et.
al.,1234L-1LFigure 1: L state position-sensitive HMM2005)?s use of HSMMs, we want to model the po-sition of a sentence in the source document explic-itly.
But instead of building an HSMM, we modelthis positional information by building our position-sensitive HMM in the following way:We first discretize the position feature into L num-ber of bins, where the number of sentences in eachbin is proportional to the length of the document.We build 2 states for each bin where the secondstate models the probability of the sentence beingincluded in the document?s summary and the othermodels the exclusion probability.
Hence, for L binswe have 2L states.
For any bin lth where 2l and2l ?
1 are the corresponding states, we remove alltransitions from these states to other states except2(l+1) and 2(l+1)?1.
This converts our ergodic Lstate HMM to an almost Left-to-Right HMM thoughl states can go back to l ?
1.
This models sentenceposition in that decisions at the lth state can be ar-rived at only after decisions at the (l ?
1)th statehave been made.
For example, if we discretize sen-tence position in document into 10 bins, such that10% of sentences in the document fall into each bin,then states 13 and 14, corresponding to the seventhbin (.i.e.
all positions between 0.6 to 0.7 of the text)can be reached only from states 11, 12, 13 and 14.The topology of our HMM is shown in Figure 1.3.1 Features and TrainingWe trained and tested our model on a portion ofthe TDT-2 corpus previously used in (Maskey andHirschberg, 2005).
This subset includes 216 storiesfrom 20 CNN shows, comprising 10 hours of audiodata and corresponding manual transcript.
An an-notator generated a summary for each story by ex-tracting sentences.
While we thus rely upon human-90identified sentence boundaries, automatic sentencedetection procedures have been found to performwith reasonable accuracy compared to human per-formance (Shriberg et.
al., 2000).For these experiments, we extracted only acous-tic/prosodic features from the corpus.
The intu-ition behind using acoustic/prosodic features forspeech summarization is based on research in speechprosody (Hirschberg, 2002) that humans use acous-tic/prosodic variation ?
expanded pitch range,greater intensity, and timing variation ?
to indi-cate the importance of particular segments of theirspeech.
In BN, we note that a change in pitch, am-plitude or speaking rate may signal differences inthe relative importance of the speech segments pro-duced by anchors and reporters ?
the professionalspeakers in our corpus.
There is also considerableevidence that topic shift is marked by changes inpitch, intensity, speaking rate and duration of pause(Shriberg et.
al., 2000), and new topics or storiesin BN are often introduced with content-laden sen-tences which, in turn, often are included in storysummaries.Our acoustic feature-set consists of 12 features,similar to those used in (Inoue et.
al., 2004; Chris-tensen et.
al., 2004; Maskey and Hirschberg, 2005).It includes speaking rate (the ratio of voiced/totalframes); F0 minimum, maximum, and mean; F0range and slope; minimum, maximum, and meanRMS energy (minDB, maxDB, meanDB); RMSslope (slopeDB); sentence duration (timeLen =endtime - starttime).
We extract these features byautomatically aligning the annotated manual tran-scripts with the audio source.
We then employ Praat(Boersma, 2001) to extract the features from theaudio and produce normalized and raw versions ofeach.
Normalized features were produced by divid-ing each feature by the average of the feature valuesfor each speaker, where speaker identify was deter-mined from the Dragon speaker segmentation of theTDT-2 corpus.
In general, the normalized acousticfeatures performed better than the raw values.We used 197 stories from this labeled corpus totrain our HMM.
We computed the transition proba-bilities for the matrix ANXN by computing the rel-ative frequency of the transitions made from eachstate to the other valid states.
We had to computefour transition probabilities for each state, i.e.
aijwhere j = i, i + 1, i + 2, i + 3 if i is odd andj = i ?
1, i, i + 1, i + 2 if i is even.
Odd statessignify that the sentence should not be included inthe summary, while even states signify sentence in-clusion.
Observation probabilities were estimatedusing a mixture of Gaussians where the number ofmixtures was 12.
We computed a 12X1 matrix forthe mean ?
and 12X12 matrices for the covariancematrix ?
for each state.
We then computed the max-imum likelihood estimates and found the optimalsequence of states to predict the selection of docu-ment summaries using the Viterbi algorithm.
Thisapproach maximizes the probability of inclusion ofsentences at each stage incrementally.4 Results and EvaluationWe tested our resulting model on a held-out test setof 19 stories.
For each sentence in the test set we ex-tracted the 12 acoustic/prosodic features.
We built a12XN matrix using these features for N sentencesin the story where N was the total length of thestory.
We then computed the optimal sequence ofsentences to include in the summary by decodingour sentence state lattice using the Viterbi algorithm.For all the even states in this sequence we extractedthe corresponding segments and concatenated themto produce the summary.Evaluating summarizers is a difficult problem,since there is great disagreement between humansover what should be included in a summary.
Speechsummaries are even harder to evaluate because mostobjective evaluation metrics are based on word over-lap.
The metric we will use here is the standardinformation retrieval measure of Precision, Recalland F-measure on sentences.
This is a strict met-ric, since it requires exact matching with sentencesin the human summary; we are penalized if we iden-tify sentences similar in meaning but not identical tothe gold standard.We first computed the F-measure of a baselinesystem which randomly extracts sentences for thesummary; this method produces an F-measure of0.24.
To determine whether the positional informa-tion captured in our position-sensitive HMM modelwas useful, we first built a 2-state HMM that modelsonly inclusion/exclusion of sentences from a sum-mary, without modeling sentence position in thedocument.
We trained this HMM on the train-91ing corpus described above.
We then trained aposition-sensitive HMM by first discretizing posi-tion into 4 bins, such that each bin includes one-quarter of the sentences in the story.
We built an8-state HMM that captures this positional informa-tion.
We tested both on our held-out test set.
Re-sults are shown in Table 1.
Note that recall forthe 8-state position-sensitive HMM is 16% betterthan recall for the 2-state HMM, although precisionfor the 2-state model is slightly (1%) better thanfor the 8-state model.
The F-measure for the 8-state position-sensitive model represents a slight im-provement over the 2-state model, of 1%.
These re-sults are encouraging, since, in skewed datasets likedocuments with their summaries, only a few sen-tences from a document are usually included in thesummary; thus, recall is generally more importantthan precision in extractive summarization.
And,compared to the baseline, the position-sensitive 8-state HMM obtains an F-measure of 0.41, which is17% higher than the baseline.ModelType Precision Recall F-MeasHMM-8state 0.26 0.95 0.41HMM-2state 0.27 0.79 0.40Baseline 0.23 0.24 0.24Table 1: Speech Summarization Results5 ConclusionWe have shown a novel way of using continuousHMMs for summarizing speech documents withoutusing any lexical information.
Our model generatesan optimal summary by decoding the state lattice,where states represent whether a sentence shouldbe included in the summary or not.
This model isable to take the context and the previous decisionsinto account generating better summaries.
Our re-sults also show that speech can be summarized fairlywell using acoustic/prosodic features alone, withoutlexical features, suggesting that the effect of ASRtranscription errors on summarization may be mini-mized by techniques such as ours.6 AcknowledgementWe would like to thank Yang Liu, Michel Galley andFadi Biadsy for helpful comments.
This work wasfunded in part by the DARPA GALE program undera subcontract to SRI International.ReferencesBoersma P. Praat, a system for doing phonetics by com-puter Glot International 5:9/10, 341-345.
2001.Christensen H., Kolluru B., Gotoh Y., Renals S. Fromtext summarisation to style-specific summarisation forbroadcast news Proc.
ECIR-2004, 2004Conroy J. and Leary D.O Text Summarization via HiddenMarkov Models and Pivoted QR Matrix Decomposi-tion Technical report, University of Maryland, March2001Hirschberg J Communication and Prosody: FunctionalAspects of Prosody Speech Communication, Vol 36,pp 31-43, 2002.Hori C., Furui S., Malkin R., Yu H., Waibel A.. Au-tomatic Speech Summarization Applied to EnglishBroadcast News Speech Proc.
of ICASSP 2002, pp.9-12 .Inoue A., Mikami T., Yamashita Y.
Improvement ofSpeech Summarization Using Prosodic InformationProc.
of Speech Prosody 2004, JapanKupiec J., Pedersen J.O., Chen F. A Trainable DocumentSummarizer Proc.
of SIGIR 1995Language Data Consortium ?TDT-2 Corpus Univ.
ofPennsylvania.Maskey S. and Hirschberg J.
2005.
Comparing Lexical,Acoustic/Prosodic, Structural and Discourse FeaturesProc.
of ICSLP, Lisbon, Portugal.Ohtake K., Yamamoto K., Toma y., Sado S., Ma-suyama S. Newscast Speech Summarization via Sen-tence Shortening Based on Prosodic Features Proc.
ofSSPR pp.167-170.
2003Shriberg E., Stolcke A., Hakkani-Tur D., Tur G. ProsodyBased Automatic Segmentation of Speech into Sen-tences and Topics?
Speech Communication 32(1-2)September 2000Tweed D., Fisher R., Bins J., List T, Efficient HiddenSemi-Markov Model Inference for Structured VideoSequences Proc.
of (VS-PETS), pp 247-254, Beijing,Oct 2005.Witbrock M.J. and Mittal V.O.
Ultra-Summarization: AStatistical Approach to Generating Highly CondensedNon-Extractive Summaries Proc.
of SIGIR 1999Zechner K. Automatic Generation of Concise Sum-maries of Spoken Dialogues in Unrestricted DomainsResearch and Development in Information Retrieval,199-207, 2001.92
