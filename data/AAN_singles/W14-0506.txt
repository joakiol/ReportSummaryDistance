Proc.
of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, page 29,Gothenburg, Sweden, April 26 2014.c?2014 Association for Computational LinguisticsDistributional Learning as a Theory of Language Acquisition(Extended Abstract)Alexander ClarkDepartment of PhilosophyKing?s College, LondonStrand, Londonalexander.clark@kcl.ac.uk1 AbstractIn recent years, a theory of distributional learningof phrase structure grammars has been developedstarting with the simple algorithm presented in(Clark and Eyraud, 2007).
These ideas are basedon the classic ideas of American structuralist lin-guistics (Wells, 1947; Harris, 1954).
Since thatinitial paper, the algorithms have been extended tolarge classes of grammars, notably to the class ofMultiple Context-Free grammars by (Yoshinaka,2011).In this talk we will sketch a theory of languageacquisition based on these techniques, and con-trast it with other proposals, such as the semanticbootstrapping and parameter setting models.
Thisproposal is based on three recent results: first, aweak learning result for a class of languages thatplausibly includes all natural languages (Clark andYoshinaka, 2013), secondly, a strong learning re-sult for some context-free grammars, that includesa general strategy for converting weak learners tostrong learners (Clark, 2013a), and finally a theo-retical result that all minimal grammars for a lan-guage will have distributionally definable syntac-tic categories (Clark, 2013b).
We argue that wenow have all of the pieces for a complete and ex-planatory theory of language acquisition based ondistributional learning and sketch some of the non-trivial predictions of this theory about the syntaxand syntax-semantics interface.2 BiographyAlexander Clark is a Lecturer in Logic and Lin-guistics in the Department of Philosophy at King?sCollege London; before that he taught for sev-eral years in the Computer Science department ofRoyal Holloway, University of London.
His firstdegree was in Mathematics from the Universityof Cambridge, and his Ph.D. is from the Univer-sity of Sussex.
He did postdoctoral research at theUniversity of Geneva.
He is currently Presidentof SIGNLL and chair of the steering committee ofthe International Conference on Grammatical In-ference.
His research is on unsupervised learn-ing in computational linguistics, grammatical in-ference, and theoretical and mathematical linguis-tics.ReferencesAlexander Clark and R?emi Eyraud.
2007.
Polynomialidentification in the limit of substitutable context-free languages.
Journal of Machine Learning Re-search, 8:1725?1745, August.Alexander Clark and Ryo Yoshinaka.
2013.
Distri-butional learning of parallel multiple context-freegrammars.
Machine Learning, pages 1?27.Alexander Clark.
2013a.
Learning trees from strings:A strong learning algorithm for some context-freegrammars.
Journal of Machine Learning Research,14:3537?3559.Alexander Clark.
2013b.
The syntactic concept lat-tice: Another algebraic theory of the context-freelanguages?
Journal of Logic and Computation.Zellig Harris.
1954.
Distributional structure.
Word,10(2-3):146?62.R.
S. Wells.
1947.
Immediate constituents.
Language,23(2):81?117.R.
Yoshinaka.
2011.
Efficient learning of multiplecontext-free languages with multidimensional sub-stitutability from positive data.
Theoretical Com-puter Science, 412(19):1821 ?
1831.29
