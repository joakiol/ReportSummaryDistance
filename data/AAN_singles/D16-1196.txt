Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1912?1917,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsOrthographic Syllable as basic unit for SMT between Related LanguagesAnoop Kunchukuttan, Pushpak BhattacharyyaCenter For Indian Language Technology,Department of Computer Science & EngineeringIndian Institute of Technology Bombay{anoopk,pb}@cse.iitb.ac.inAbstractWe explore the use of the orthographic syl-lable, a variable-length consonant-vowel se-quence, as a basic unit of translation betweenrelated languages which use abugida or alpha-betic scripts.
We show that orthographic sylla-ble level translation significantly outperformsmodels trained over other basic units (word,morpheme and character) when training oversmall parallel corpora.1 IntroductionRelated languages exhibit lexical and structural sim-ilarities on account of sharing a common ances-try (Indo-Aryan, Slavic languages) or being in pro-longed contact for a long period of time (Indian sub-continent, Standard Average European linguistic ar-eas) (Bhattacharyya et al, 2016).
Translation be-tween related languages is an important requirementdue to substantial government, business and socialcommunication among people speaking these lan-guages.
However, most of these languages have fewparallel corpora resources, an important requirementfor building good quality SMT systems.Modelling the lexical similarity among relatedlanguages is the key to building good-quality SMTsystems with limited parallel corpora.
Lexical sim-ilarity implies that the languages share many wordswith the similar form (spelling/pronunciation) andmeaning e.g.
blindness is andhapana in Hindi,aandhaLepaNaa in Marathi.
These words couldbe cognates, lateral borrowings or loan words fromother languages.
Translation for such words can beachieved by sub-word level transformations.
For in-stance, lexical similarity can be modelled in the stan-dard SMT pipeline by transliteration of words whiledecoding (Durrani et al, 2010) or post-processing(Nakov and Tiedemann, 2012; Kunchukuttan et al,2014).A different paradigm is to drop the notion ofword boundary and consider the character n-gramas the basic unit of translation (Vilar et al, 2007;Tiedemann, 2009a).
Such character-level SMTbas been explored for closely related languageslikeBulgarian-Macedonian, Indonesian-Malaywithmodest success, with the short context of unigramsbeing a limiting factor (Tiedemann, 2012).
Theuse of character n-gram units to address this limi-tation leads to data sparsity for higher order n-gramsand provides little benefit (Tiedemann and Nakov,2013).In this work, we present a linguistically moti-vated, variable length unit of translation ?
ortho-graphic syllable (OS)?which provides more con-text for translation while limiting the number of ba-sic units.
The OS consists of one or more conso-nants followed by a vowel and is inspired from theakshara, a consonant-vowel unit, which is the funda-mental organizing principle of Indic scripts (Sproat,2003; Singh, 2006).
It can be thought of as an ap-proximate syllable with the onset and nucleus, butno coda.
While true syllabification is hard, ortho-graphic syllabification can be easily done.
Atreya etal.
(2016) and Ekbal et al (2006) have shown thatthe OS is a useful unit for transliteration involvingIndian languages.We show that orthographic syllable-level trans-1912lation significantly outperforms character-level andstrong word-level and morpheme-level baselinesover multiple related language pairs (Indian as wellas others).
Character-level approaches have beenpreviously shown to work well for language pairswith high lexical similarity.
Ourmajor finding is thatOS-level translation outperforms other approacheseven when the language pairs have relatively lesslexical similarity or belong to different languagefamilies (but have sufficient contact relation).2 Orthographic SyllabificationThe orthographic syllable is a sequence of one ormore consonants followed by a vowel, i.e a C+Vunit.
We describe briefly procedures for ortho-graphic syllabification of Indian scripts and non-Indic alphabetic scripts.
Orthographic syllabifica-tion cannot be done for languages using logographicand abjad scripts as these scripts do not have vowels.Indic Scripts: Indic scripts are abugida scripts,consisting of consonant-vowel sequences, with aconsonant core (C+) and a dependent vowel (ma-tra).
If no vowel follows a consonant, an implicitschwa vowel [IPA: ?]
is assumed.
Suppression ofschwa is indicated by the halanta character follow-ing a consonant.
This script design makes for astraightforward syllabification process as shown inthe following example.
e.g.
??????
( lakShamICV CCV CV)issegmented as ?
???
??
( la kSha mICV CCV CV).
There are twoexceptions to this scheme: (i) Indic scripts distin-guish between dependent vowels (vowel diacritics)and independent vowels, and the latter will consti-tute an OS on its own.
e.g.
??????
(mumbaI) ???
???
?
(mu mba I) (ii) The characters anusvaaraand chandrabindu are part of the OS to the left ifthey represents nasalization of the vowel/consonantor start a new OS if they represent a nasal consonant.Their exact role is determined by the character fol-lowing the anusvaara.Non-Indic Alphabetic Scripts: We use a simplermethod for the alphabetic scripts used in our experi-ments (Latin and Cyrillic).
The OS is identified by aC+V+ sequence.
e.g.
lakshami?la ksha mi, mum-bai?mu mbai.
The OS could contains multiple ter-minal vowel characters representing long vowels (ooin cool) or diphthongs (ai inmumbai).
A vowel start-Basic Unit Example TransliterationWord ?????????
gharAsamoracAMorph Segment ???
????
??
gharA samora cAOrthographic Syllable ?
??
?
??
?
??
gha rA sa mo racACharacter unigram ?
?
??
?
?
??
?
?
??
gha r A sa m o ra c ACharacter 3-gram ???
???
???
gharA samo rcAsomething that is in front of home: ghara=home, samora=front, cA=ofTable 1: Various translation units for aMarathi wording a word is considered to be an OS.3 Translation ModelsWe compared the orthographic syllable level model(O) with models based on other translation units thathave been reported in previous work: word (W),morpheme (M), unigram (C) and trigram characters.Table 1 shows examples of these representations.The first step to build these translation systems isto transform sentences to the correct representation.Each word is segmented as the per the unit of rep-resentation, punctuations are retained and a specialword boundary marker character (_) is introducedto indicate word boundaries as shown here:W: ????
, ????????
???
???
.O: ??
??
_ , _ ?
??
??
??
?
_ ??
?
_ ?
??
_ .For all units of representation, we trained phrase-based SMT (PBSMT) systems.
Since related lan-guages have similar word order, we used distancebased distortionmodel andmonotonic decoding.
Forcharacter and orthographic syllable level models, weuse higher order (10-gram) languages models sincedata sparsity is a lesser concern due to small vocabu-lary size (Vilar et al, 2007).
As suggested by Nakovand Tiedemann (2012), we used word-level tuningfor character and orthographic syllable level modelsby post-processing n-best lists in each tuning step tocalculate the usual word-based BLEU score.While decoding, the word and morpheme levelsystems will not be able to translate OOV words.Since the languages involved share vocabulary, wetransliterate the untranslated words resulting in thepost-edited systems WX and MX corresponding tothe systems W and M respectively.
Following de-coding, we used a simple method to regeneratewords from sub-word level units: Since we representword boundaries using a word boundary marker, we1913IA?IA DR?DR IA?DRben-hin 52.30 mal-tam 39.04 hin-mal 33.24pan-hin 67.99 tel-mal 39.18 DR?IAkok-mar 54.51 mal-hin 33.24IA: Indo-Aryan, DR: DravidianTable 2: Language pairs used in experiments alongwith Lexical Similarity between them, in terms ofLCSR between training corpus sentencessimply concat the output units between consecutiveoccurrences of the marker character.4 Experimental SetupLanguages: Our experiments primarily concen-trated on multiple language pairs from the two ma-jor language families of the Indian sub-continent(Indo-Aryan branch of Indo-European and Dravid-ian).
These languages have been in contact for along time, hence there are many lexical and gram-matical similarities among them, leading to the sub-continent being considered a linguistic area (Eme-neau, 1956).
Specifically, there is overlap betweenthe vocabulary of these languages to varying de-grees due to cognates, language contact and loan-words from Sanskrit (throughout history) and En-glish (in recent times).
Table 2 lists the languagesinvolved in the experiments and provides an indica-tion of the lexical similarity between them in termsof the Longest Common Subsequence Ratio (LCSR)(Melamed, 1995) between the parallel training sen-tences at character level.
All these language havea rich inflectional morphology with Dravidian lan-guages, and Marathi and Konkani to some degree,being agglutinative.
kok-mar and pan-hin have ahigh degree of lexical similarity.Dataset: We used the multilingual ILCI corpus forour experiments (Jha, 2012), consisting of a mod-est number of sentences from tourism and healthdomains.
The data split is as follows ?
training:44,777, tuning 1K, test: 2K sentences.
Languagemodels for word-level systems were trained on thetarget side of training corpora plus monolingual cor-pora from various sources [hin: 10M (Bojar et al,2014), tam: 1M (Ramasamy et al, 2012), mar: 1.8M(news websites), mal: 200K (Quasthoff et al, 2006)sentences].
We used the target language side of theparallel corpora for character, morpheme and OSlevel LMs.System details: PBSMT systems were trained us-ing the Moses system (Koehn et al, 2007), with thegrow-diag-final-and heuristic for extracting phrases,and Batch MIRA (Cherry and Foster, 2012) for tun-ing (default parameters).
We trained 5-gram LMswithKneser-Ney smoothing for word andmorphemelevel models and 10-gram LMs for character andOS level models.
We used the BrahmiNet translit-eration system (Kunchukuttan et al, 2015) for post-editing, which is based on the transliteration Mod-ule in Moses (Durrani et al, 2014).
We used un-supervised morphological segmenters trained withMorfessor (Virpioja et al, 2013) for obtaining mor-pheme representations.
The unsupervised morpho-logical segmenters were trained on the ILCI corpusand the Leipzig corpus (Quasthoff et al, 2006).Themorph-segmenters and our implementation of ortho-graphic syllabification are made available as part ofthe Indic NLP Library1.Evaluation: We use BLEU (Papineni et al, 2002)and Le-BLEU (Virpioja and Gr?nroos, 2015) forevaluation.
Le-BLEU does fuzzy matches of wordsand hence is suitable for evaluating SMT systemsthat perform transformation at the sub-word level.5 Results and DiscussionThis section discusses the results on Indian and non-Indian languages and cross-domain translation.Comparison of Translation Units: Table 3 com-pares the BLEU scores for various translation sys-tems.
The orthographic syllable level system isclearly better than all other systems.
It signifi-cantly outperforms the character-level system (by46% on an average).
The character-based systemis competitive only for highly lexically similar lan-guage pairs like pan-hin and kok-mar.
The sys-tem also outperforms two strong baselines which ad-dress data sparsity: (a) a word-level system withtransliteration of OOV words (10% improvement),(b) amorph-level systemwith transliteration of OOVwords (5% improvement).
The OS-level representa-tion is more beneficial when morphologically rich1http://anoopkunchukuttan.github.io/indic_nlp_library1914W WX M MX C Oben-hin 31.23 32.79 32.17 32.32 27.95 33.46pan-hin 68.96 71.71 71.29 71.42 71.26 72.51kok-mar 21.39 21.90 22.81 22.82 19.83 23.53mal-tam 6.52 7.01 7.61 7.65 4.50 7.86tel-mal 6.62 6.94 7.86 7.89 6.00 8.51hin-mal 8.49 8.77 9.23 9.26 6.28 10.45mal-hin 15.23 16.26 17.08 17.30 12.33 18.50Table 3: Results - ILCI corpus (% BLEU).
Thereported scores are:- W: word-level, WX : word-level fol-lowed by transliteration of OOV words, M: morph-level, MX :morph-level followed by transliteration of OOVmorphemes,C:character-level,O: orthographic syllable.
The values marked inbold indicate the best scores for the language pair.C O M Wben-hin 0.71 0.63 0.58 0.40pan-hin 0.72 0.70 0.64 0.50kok-mar 0.74 0.68 0.63 0.64mal-tam 0.77 0.71 0.56 0.46tel-mal 0.78 0.65 0.52 0.45hin-mal 0.79 0.59 0.46 -0.02mal-hin 0.71 0.61 0.45 0.37Table 4: Pearson?s correlation coefficient between lex-ical similarity and translation accuracy (both in terms ofLCSR at character level).
This was computed over thetest set between: (ii) sentence level lexical similarity be-tween source and target sentences and (ii) sentence leveltranslation match between hypothesis and reference.languages are involved in translation.
Significantly,OS-level translation is also the best system for trans-lation between languages of different language fam-ilies.
The Le-BLEU scores also show the same trendas BLEU scores, but we have not reported it due tospace limits.
There are a very small number of un-translated OSes, which we handled by simple map-ping of untranslated characters from source to tar-get script.
This barely increased translation accuracy(0.02% increase in BLEU score).Why is OS better than other units?
: The im-proved performance of OS level representation canbe attributed to the following factors:One, the number of basic translation units islimited and small compared to word-level andWX MX C Oben-hin Corpus not availablepan-hin 61.56 59.75 58.07 58.48kok-mar 19.32 18.32 17.97 19.65mal-tam 5.88 6.02 4.12 5.88tel-mal 3.19 4.07 3.11 3.77hin-mal 5.20 6.00 3.85 6.26mal-hin 9.68 11.44 8.42 13.32Table 5: Results: Agricuture Domain (% BLEU)morpheme-level representations.
For word-levelrepresentation, the number of translation units canincrease with corpus size, especially for morpholog-ically rich languages which leads to many OOVs.Thus, OS-level units address data sparsity.Two, while character level representation toodoes not suffer from data sparsity, we observethat the translation accuracy is highly correlatedto lexical similarity (Table 4).
The high corre-lation of character-level system and lexical simi-larity explains why character-level translation per-forms nearly as well other methods for languagepairs which have high lexical similarity, but per-forms badly otherwise.
On the other hand, the OS-level representation has lesser correlation with lexi-cal similarity and sits somewhere between character-level and word/morpheme level systems.
Hence it isable to make generalizations beyond simple char-acter level mappings.
We observed that OS-levelrepresentation was able to correctly generate wordswhose translations are not cognate with the sourcelanguage.
This is an important property since func-tion words and suffixes tend to be less similar lexi-cally across languages.Can improved translation performance be ex-plained by longer basic translation units?
To ver-ify this, we trained translation systemswith charactertrigrams as basic units.
We chose trigrams since theaverage length of the OS was 3-5 characters for thelanguages we tested with.
The translation accuracieswere far less than even unigram representation.
Thenumber of unique basic units was about 8-10 timeslarger than orthographic syllables, thus making datasparsity an issue again.
So, improved translation per-formance cannot be attributed to longer n-gramunits alone.191510 15 20 25 30 35 40 4525262728293031323334%BLEU(a) Language Pair: ben-hinCM OW10 15 20 25 30 35 40 45Training set size (in thousands of sentences)1012141618%BLEU(b) Language Pair: mal-hinCM OWFigure 1: Effect of training data size on translationaccuracy for different basic unitsCorpus Stats Lex-Sim W C Obul-mac (150k,1k,2k) 62.85 21.20 20.61 21.38dan-swe (150k,1k,2k) 63.39 35.13 35.36 35.46may-ind (137k,1k,2k) 73.54 61.33 60.50 61.24Table 6: Translation among non-Indic languages(%BLEU).
Corpus Stats show (train,tune,test) splitRobustness to Domain Change: We also testedthe translation models trained on tourism & healthdomains on an agriculture domain test set of 1000sentences.
In this cross-domain translation scenariotoo, the OS level model outperforms most units ofrepresentation.
The only exceptions are the pan-hinand tel-mal language pairs for the systemMX (accu-racies of the OS-level system are within 10% of theMX system).
Since the word level model depends oncoverage of the lexicon, it is highly domain depen-dent, whereas the sub-word units are not.
So, evenunigram-level models outperform word-level mod-els in a cross-domain setting.Experiments with non-Indian languages: Ta-ble 6 shows the corpus statistics and our re-sults for translation between some related non-Indiclanguage pairs (Bulgarian-Macedonian, Danish-Swedish, Malay-Indonesian).
OS level representa-tion outperforms character and word level represen-tation, though the gains are not as significant as In-dic language pairs.
This could be due to short lengthof sentences in training corpus [OPUS movie sub-titles (Tiedemann, 2009b)] and high lexical similar-ity between the language pairs.
Further experimentsbetween less lexically related languages on generalparallel corpora will be useful.Effect of training data size: For different train-ing set sizes, we trained SMT systems with vari-ous representation units (Figure 1 shows the learningcurves for two language pairs).
BPE levelmodels areconsistently better than word as well as morph-levelmodels, and are competitive or better than OS levelmodels.
Note that bn-hi is a relatively morpholog-ically simpler language where BPE is just compet-itive with OS over the complete dataset too as dis-cussed earlier.6 Conclusion & Future WorkWe focus on the task of translation between re-lated languages.
This aspect of MT research is im-portant to make available translation technologiesto language pairs with limited parallel corpus, buthuge potential translation requirements.
We pro-pose the use of the orthographic syllable, a variable-length, linguistically motivated, approximate sylla-ble, as a basic unit for translation between relatedlanguages.
We show that it significantly outper-forms other units of representation, over multiplelanguage pairs, spanning different language families,with varying degrees of lexical similarity and is ro-bust to domain changes too.
This opens up the possi-bility of further exploration of sub-word level trans-lation units e.g.
segments learnt using byte pair en-coding (Sennrich et al, 2016).AcknowledgmentsWe thank Arjun Atreya for inputs regarding ortho-graphic syllables.
We thank the Technology De-velopment for Indian Languages (TDIL) Programmeand the Department of Electronics & InformationTechnology, Govt.
of India for their support.1916ReferencesArjun Atreya, Swapnil Chaudhari, Pushpak Bhat-tacharyya, and Ganesh Ramakrishnan.
2016.
Valuethe vowels: Optimal transliteration unit selection formachine.
InUnpublished, private communication withauthors.Pushpak Bhattacharyya, Mitesh Khapra, and AnoopKunchukuttan.
2016.
Statistical machine translationbetween related languages.
In NAACL Tutorials.Ond?ej Bojar, Vojt?ch Diatka, Pavel Rychl?, PavelStra?
?k, V?t Suchomel, Ale?
Tamchyna, and DanielZeman.
2014.
HindEnCorp ?
Hindi-English andHindi-only Corpus for Machine Translation.
In Pro-ceedings of the 9th International Conference on Lan-guage Resources and Evaluation.Colin Cherry and George Foster.
2012.
Batch tuningstrategies for statistical machine translation.
In Pro-ceedings of the 2012Conference of the North AmericanChapter of the Association for Computational Linguis-tics: Human Language Technologies.Nadir Durrani, Hassan Sajjad, Alexander Fraser, and Hel-mut Schmid.
2010.
Hindi-to-Urdu machine transla-tion through transliteration.
In Proceedings of the 48thAnnual Meeting of the Association for ComputationalLinguistics.Nadir Durrani, Hieu Hoang, Philipp Koehn, and HassanSajjad.
2014.
Integrating an unsupervised translitera-tion model into Statistical Machine Translation.
EACL2014.Asif Ekbal, Sudip Kumar Naskar, and Sivaji Bandy-opadhyay.
2006.
A modified joint source-channelmodel for transliteration.
In Proceedings of the COL-ING/ACL on Main conference poster sessions.Murray B Emeneau.
1956.
India as a lingustic area.
Lan-guage.Girish Nath Jha.
2012.
The TDIL program and the IndianLanguage Corpora Initiative.
In Language Resourcesand Evaluation Conference.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, et al 2007.
Moses: Open source toolkit forStatistical Machine Translation.
In Proceedings of the45th Annual Meeting of the ACL on Interactive Posterand Demonstration Sessions.Anoop Kunchukuttan, Ratish Pudupully, Rajen Chatter-jee, AbhijitMishra, and PushpakBhattacharyya.
2014.The IIT Bombay SMT System for ICON 2014 Toolscontest.
In NLP Tools Contest at ICON 2014.Anoop Kunchukuttan, Ratish Puduppully, and PushpakBhattacharyya.
2015.
Brahmi-Net: A transliterationand script conversion system for languages of the In-dian subcontinent.I Dan Melamed.
1995.
Automatic evaluation and uni-form filter cascades for inducing n-best translation lex-icons.
In Third Workshop on Very Large Corpora.Preslav Nakov and J?rg Tiedemann.
2012.
Combin-ing word-level and character-level models for machinetranslation between closely-related languages.
In Pro-ceedings of the 50th Annual Meeting of the Associationfor Computational Linguistics: Short Papers-Volume2.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automatic evalu-ation of machine translation.
In Association for Com-putational Linguistics.Uwe Quasthoff, Matthias Richter, and Christian Bie-mann.
2006.
Corpus portal for search in monolingualcorpora.
In Proceedings of the fifth international con-ference on language resources and evaluation.Loganathan Ramasamy, Ond?ej Bojar, and Zden?k?abokrtsk?.
2012.
Morphological Processing forEnglish-Tamil Statistical Machine Translation.
InProceedings of the Workshop on Machine Translationand Parsing in Indian Languages.Rico Sennrich, Barry Haddow, and Alexandra Birch.2016.
Automatic evaluation and uniform filter cas-cades for inducing n-best translation lexicons.
In ACL.Anil Kumar Singh.
2006.
A computational phoneticmodel for Indian language scripts.
In Constraints onSpelling Changes: Fifth International Workshop onWriting Systems.Richard Sproat.
2003.
A formal computational analysisof Indic scripts.
In International symposium on indicscripts: past and future, Tokyo.J?rg Tiedemann and Preslav Nakov.
2013.
Analyzing theuse of character-level translation with sparse and noisydatasets.
In RANLP.J?rg Tiedemann.
2009a.
Character-based PBSMT forclosely related languages.
In Proceedings of the 13thConference of the European Association for MachineTranslation.J?rg Tiedemann.
2009b.
News from opus-a collection ofmultilingual parallel corpora with tools and interfaces.In Recent advances in natural language processing.J?rg Tiedemann.
2012.
Character-based pivot translationfor under-resourced languages and domains.
In EACL.David Vilar, Jan-T Peter, and Hermann Ney.
2007.
Canwe translate letters?
In Proceedings of the SecondWorkshop on Statistical Machine Translation.Sami Virpioja and Stig-Arne Gr?nroos.
2015.
Lebleu:N-gram-based translation evaluation score formorpho-logically complex languages.
InWMT 2015.Sami Virpioja, Peter Smit, Stig-Arne Gr?nroos, MikkoKurimo, et al 2013.
Morfessor 2.0: Python imple-mentation and extensions for morfessor baseline.1917
