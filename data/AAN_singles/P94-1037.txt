Optimality Theory: Universal Grammar, Learning andParsing Algorithms, and Connectionist Foundations(Abstract)Pau l  Smolensky  and  Bruce  TesarDepartment  of Computer  Science and Inst i tute of Cognit ive ScienceUniversity of Colorado, Boulder USAWe present a recently proposed theory of grammar,Optimality Theory (OT; Prince & Smolensky 1991,1993).
The principles of OT derive in large part fromthe high-level principles governing computation i  con-nectionist networks.
The talk proceeds as follows: (1)we summarize OT and its applications to UG.
The wepresent (2) learning and (3) parsing algorithms for OT.Finally, (4) we show how crucial elements of OT emergefrom connectionism, and discuss the one central featureof OT which so far eludes connectionist explanation.
(1) In OT, UG provides a set of highly general univer-sal constraints which apply in parallel to assess the well-formedness ofpossible structural descriptions oflinguis-tic inputs.
The constraints may conflict, and for mostinputs no structural description meets them all.
Thegrammatical structure is the one that optimally meetsthe conflicting constraint sets.
Optimality is defined ona language-particular b sis: each language's grammarranks the universal constraints in a dominance hierar-chy such that each constraint has absolute priority overall lower-ranked constraints.
Given knowledge of UG,the job of the learner is to determine the constraintranking which is particular to his or her language.
\[Theexplanatory power of OT as a theory of UG has nowbeen attested for phonology in over two dozen papersand books (e.g., McCarthy ~: Prince 1993; Rutgers Op-timality Workshop, 1993); applications ofOT to syntaxare now being explored (e.g.
Legendre, Raymond,$molensky 1993; Grimshaw 1993).\](2) Learnability ofOT (Tesar ~ Smolensky, 1993).
The-ories of UG can be used to address questions of learn-ability via the formal universal principles they provide,or via their substantive universals.
We will show thatOT endows UG with sufficiently tight formal struc-ture to yield a number of strong learnability results atthe formal level.
We will present a family of closelyrelated algorithms for learning, from positive exam-ples only, language-particular grammars on the basisof prior knowledge of the universal principles.
We willsketch our proof of the correctness of these algorithmsand demonstrate heir low computational complexity.
(More precisely, the learning time in the worst case,measured in terms of 'informative examples', grows onlyas n 2, where n is the number of constraints in UG, eventhough the number of possible grammars grows as n!,i.e., faster than exponentially.)
Because these resultsdepend only on the formal universals of OT, and not onthe content of the universal constraints which providethe substantive universals of the theory, the conclusionthat OT grammars are highly learnable applies equallyto OT grammars in phonology, syntax, or any othergrammar component.
(3) Parsing in OT is assumed by many to be problem-atic.
For OT is often described as follows: take aninput form, generate all possible parses of it (generally,infinite in number), evaluate all the constraints againstall the parses, filter the parses by descending the con-straints in the dominance hierarchy.
While this cor-rectly characterizes the input/output function which isan OT grammar, it hardly provides an efficient pars-ing procedure.
We will show, however, that efficient,provably correct parsing by dynamic programming ispossible, at least when the set of candidate parses issufficiently simple (Tesar, 1994).
(4) OT is built from a set of principles, most of whichderive from high-level principles of connectionist com-putation.
The most central of these assert hat, givenan input representation, connectionist networks tend tocompute an output representation which best satisfiesa set of conflicting soft constraints, with constraint con-flicts handled via a notion of differential strength.
For-malized through Harmony Theory (Smolensky, 1986)and Harmonic Grammar (Legendre, Miyata, & Smolen-sky 1990), this conception of computation yields a the-ory of grammar based on optimization.
OptimalityTheory introduces to a non-numerical form of optimiza-tion, made possible by a property as yet unexplainedfrom the connectionist perspective: in grammars, con-straints fall into strict domination hierarchies.271
