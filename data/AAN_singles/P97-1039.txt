A Portable Algorithm for Mapping Bitext CorrespondenceI .
Dan  Me lamedDept .
of Computer  and In format ion  ScienceUnivers i ty  of Pennsy lvan iaPh i lade lph ia ,  PA, 19104, U.S.A.melamed@unagi, cis.
upenn, eduAbst ractThe first step in most empirical work inmultilingual NLP is to construct maps ofthe correspondence b tween texts and theirtranslations (bitext maps).
The SmoothInjective Map Recognizer (SIMR) algo-rithm presented here is a generic patternrecognition algorithm that is particularlywell-suited to mapping bitext correspon-dence.
SIMR is faster and significantlymore accurate than other algorithms in theliterature.
The algorithm is robust enoughto use on noisy texts, such as those result-ing from OCR input, and on translationsthat are not very literal.
SIMR encap-sulates its language-specific heuristics, sothat it can be ported to any language pairwith a minimal effort.1 In t roduct ionTexts that are available in two languages (bitexts)are immensely valuable for many natural languageprocessing applications z. Bitexts are the raw ma-terial from which translation models are built.
Inaddition to their use in machine translation (Sato& Nagao, 1990; Brown et al, 1993; Melamed,1997), translation models can be applied to machine-assisted translation (Sato, 1992; Foster et al, 1996),cross-lingual information retrieval (SIGIR, 1996),and gisting of World Wide Web pages (Resnik,1997).
Bitexts also play a role in less auto-mated applications such as concordancing for bilin-gual lexicography (Catizone et al, 1993; Gale &Church, 1991b), computer-assisted language learn-ing, and tools for translators (e.g.
(Macklovitch,1 "Multitexts" in more than two languages are evenmore valuable, but they are much more rare.1995; Melamed, 1996b).
However, bitexts are of lit-tle use without an automatic method for construct-ing bitext maps.Bitext maps identify corresponding text units be-tween the two halves of a bitext.
The ideal bitextmapping algorithm should be fast and accurate, uselittle memory and degrade gracefully when facedwith translation irregularities like omissions and in.versions.
It should be applicable to any text genrein any pair of languages.The Smooth Injective Map Recognizer (SIMR) al-gorithm presented in this paper is a bitext mappingalgorithm that advances the state of the art on thesecriteria.
The evaluation in Section 5 shows thatSIMR's error rates are lower than those of otherbitext mapping algorithms by an order of magni-tude.
At the same time, its expected running timeand memory requirements are linear in the size of theinput, better than any other published algorithm.The paper begins by laying down SIMR's geomet-ric foundations and describing the algorithm.
Then,Section 4 explains how to port SIMR to arbitrarylanguage pairs with minimal effort, without rely-ing on genre-specific nformation such as sentenceboundaries.
The last section offers some insightsabout the optimal evel of text analysis for mappingbitext correspondence.2 B i text  GeometryA b i text  (Harris, 1988) comprises two versions ofa text, such as a text in two different languages.Translators create a bitext each time they trans-late a text.
Each bitext defines a rectangularb i text  space, as illustrated in Figure 1.
The widthand height of the rectangle are the lengths of thetwo component texts, in characters.
The lower leftcorner of the rectangle is the origin of the bitextspace and represents he two texts' beginnings.
Theupper right corner is the terminus  and representsthe texts' ends.
The line between the origin and the305IIoriginterminusdiagonalx = character position in text 1Figure 1: a bitext spaceterminus is the main  diagonal.
The slope of themain diagonal is the b i text  slope.Each bitext space contains a number of t ruepo ints  of  cor respondence  (TPCs) ,  other thanthe origin and the terminus.
For example, if a tokenat position p on the x-axis and a token at positionq on the y-axis are translations of each other, thenthe coordinate (p, q) in the bitext space is a TPC 2.TPCs also exist at corresponding boundaries of textunits such as sentences, paragraphs, and chapters.Groups of TPCs with a roughly linear arrangementin the bitext space are called chains.B i text  maps  are 1-to-1 functions in bitextspaces.
A complete set of TPCs for a particularbitext is called a t rue b i text  map (TBM) .
Thepurpose of a b i text  mapp ing  a lgor i thm is to pro-duce bitext maps that are the best possible approx-imations of each bitext's TBM.3 S IMRSIMR builds bitext maps one chain at a time.
Thesearch for each chain alternates between a genera-tion phase and a recognition phase.
The genera-tion phase begins in a small rectangular region ofthe bitext space, whose diagonal is parallel to themain diagonal.
Within this search rectangle, SIMRgenerates all the points of correspondence that sat-isfy the supplied matching predicate, as explainedin Section 3.1.
In the recognition phase, SIMRcalls the chain recognition heuristic to find suitablechains among the generated points.
If no suitablechains are found, the search rectangle is proportion-ally expanded and the generation-recognition cycle2Since distances in the bitext space are measured incharacters, the position of a token is defined as the meanposition of its characters.is repeated.
The rectangle keeps expanding until atleast one acceptable chain is found.
If more thanone chain is found in the same cycle, SIMR acceptsthe one whose points are least dispersed around itsleast-squares line.
Each time SIMR accepts a chain,it selects another egion of the bitext space to searchfor the next chain.SIMR employs a simple heuristic to select regionsof the bitext space to search.
To a first approxima-tion, TBMs are monotonically increasing functions.This means that if SIMR finds one chain, it shouldlook for others either above and to the right or belowand to the left of the one it has just found.
All SIMRneeds is a place to start the trace.
A good place tostart is at the beginning: Since the origin of thebitext space is always a TPC, the first search rect-angle is anchored at the origin.
Subsequent searchrectangles are anchored at the top right corner ofthe previously found chain, as shown in Figure 2.I e discovered TPC 1 next ~ oo undiscovered TPC T P C ~ J?
?
previous chain ?Figure 2: S\[MR's "expanding rectangle" searchstrategy.
The search rectangle is anchored at the topright corner of the previously found chain.
Its diag-onal remains parallel to the main diagonal.The expanding-rectangle search strategy makesSIMR robust in the face of TBM discontinuities.Figure 2 shows a segment of the TBM that containsa vertical gap (an omission in the text on the x-axis).As the search rectangle grows, it will eventually in-tersect with the TBM, even if the discontinuity isquite large (Melamed, 1996b).
The noise filter de-scribed in Section 3.3 prevents SIMR from being ledastray by false points of correspondence.3.1 Po int  Generat ionSIMR generates candidate points of correspondencein the search rectangle using one of its matchingpredicates.
A match ing  pred icate  is a heuristicfor deciding whether a given pair of tokens are likelyto be'mutual translations.
Two kinds of information306that a matching predicate can rely on most often arecognates and translation lexicons.Two tokens in a bitext are cognates if they havethe same meaning and similar spellings.
In the non-technical Canadian Hansards (parliamentary debatetranscripts available in English and in French), cog-nates can be found for roughly one quarter of alltext tokens (Melamed, 1995).
Even distantly relatedlanguages like English and Czech will share a largenumber of cognates in the form of proper nouns.Cognates are more common in bitexts from moresimilar language pairs, and from text genres wheremore word borrowing occurs, such as technical texts.When dealing with language pairs that have dissim-ilar alphabets, the matching predicate can employphonetic cognates (Melamed, 1996a).
When oneor both of the languages involved is written in pic-tographs, cognates can still be found among punc-tuation and digit strings.
However, cognates of thislast kind are usually too sparse to suffice by them-selves.When the matching predicate cannot generateenough candidate correspondence points based oncognates, its signal can be strengthened by a trans-lation lexicon.
Translation lexicons can be ex-tracted from machine-readable ilingual dictionaries(MRBDs), in the rare cases where MRBDs are avail-able.
In other cases, they can be constructed auto-matically or semi-automatically using any of severalmethods (Fung, 1995; Melamed, 1996c; Resnik &Melamed, 1997).
Since the matching predicate neednot be perfectly accurate, the translation lexiconsneed not be either.Matching predicates can take advantage of otherinformation, besides cognates and translation lexi-cons can also be used.
For example, a list of fauxamis is a useful complement to a cognate matchingstrategy (Macklovitch, 1995).
A stop list of functionwords is also helpful.
Function words are translatedinconsistently and make unreliable points of corre-spondence (Melamed, 1996a).3.2 Po int  Select ionAs illustrated in Figure 2, even short sequences ofTPCs form characteristic patterns.
Most chains ofTPCs have the following properties:?
L inear i ty:  TPCs tend to line up straight.?
Low Var iance of Slope: The slope of a TPCchain is rarely much different from the bitextslope.?
In ject iv i ty :  No two points in a chain of TPCscan have the same x- or y-co-ordinates.SIMR's chain recognition heuristic exploits theseproperties to decide which chains in the search rect-angle might be TPC chains.The heuristic involves three parameters: chainsize, max imum point  d ispersal  and max imumangle deviat ion.
A chain's size is simply the num-ber of points it contains.
The heuristic considersonly chains of exactly the specified size whose pointsare injective.
The linearity of the these chains istested by measuring the root mean squared istanceof the chain's points from the chain's least-squaresline.
If this distance exceeds the maximum pointdispersal threshold, the chain is rejected.
Next, theangle of each chain's least-squares line is comparedto the arctangent of the bitext slope.
If the differ-ence exceeds the maximum angle deviation thresh-old, the chain is rejected.
These filters can be effi-ciently combined so that SIMR's expected runningtime and memory requirements are linear in the sizeof the input bitext (Melamed, 1996a).The chain recognition heuristic pays no attentionto whether chains are monotonic.
Non-monotonicTPC chains are quite common, because even lan-guages with similar syntax like French and Englishhave well-known differences in word order.
For ex-ample, English (adjective, noun) pairs usually corre-spond to French (noun, adjective) pairs.
Such inver-sions result in TPCs arranged like the middle twopoints in the "previous chain" of Figure 2.
SIMRhas no problem accepting the inverted points.If the order of words in a certain text passage isradically altered during translation, SIMR will sim-ply ignore the words that "move too much" and con-struct chains out of those that remain more station-ary.
The maximum point dispersal parameter lim-its the width of accepted chains, but nothing lim-its their length.
In practice, the chain recognitionheuristic often accepts chains that span several sen-tences.
The ability to analyze non-monotonic pointsof correspondence over variable-size areas of bitextspace makes SIMR robust enough to use on transla-tions that are not very literal.3.3 Noise F i l terPoints of correspondence among frequent tokentypes often line up in rows and columns, as illus-trated in Figure 3.
Token types like the Englisharticle "a" can produce one or more correspondencepoints for almost every sentence in the opposite text.Only one point of correspondence in each row andcolumn can be correct; the rest are noise.
A noise fil-ter can make it easier for SIMR to find TPC chains.Other bitext mapping algorithms mitigate thissource of noise either by assigning lower weights to307aaaa" "  ac-.ca ac-.I.Uql i i  ?
qD?
?
q,Q ?qD~ 'aFrench textFigure 3: Frequent okens cause false points of cor-respondence that line up in rows and columns.correspondence points associated with frequent o-ken types (Church, 1993) or by deleting frequent o-ken types from the bitext altogether (Dagan et al,1993).
However, a token type that is relatively fre-quent overall can be rare in some parts of the text.In those parts, the token type can provide valuableclues to correspondence.
On the other hand, manytokens of a relatively rare type can be concentratedin a short segment of the text, resulting in manyfalse correspondence points.
The varying concentra-tion of identical tokens suggests that more localizednoise filters would be more effective.
SIMR's local-ized search strategy provides a vehicle for a localizednoise filter.The filter is based on the max imum point  am-b igu i ty  level parameter.
For each point p = (x, y),lct X be the number of points in column x withinthe search rectangle, and let Y be the number ofpoints in row y within the search rectangle.
Thenthe ambiguity level of p is X + Y - 2.
In partic-ular, if p is the only point in its row and column,then its ambiguity level is zero.
The chain recogni-tion heuristic ignores points whose ambiguity level istoo high.
What makes this a localized filter is thatonly points within the search rectangle count towardeach other's ambiguity level.
The ambiguity level ofa given point can change when the search rectangleexpands or moves.The noise filter ensures that false points of corre-spondence are very sparse, as illustrated in Figure 4.Even if one chain of false points of correspondenceslips by the chain recognition heuristic, the expand-ing rectangle will find its way back to the TBM be-fore the chain recognition heuristic accepts anotherfalse "".,Z??
:~ '~ anchoroff track "Figure 4: SIMR's noise filter ensures that TPCsare much more dense than false points of correspon-dence A good signal-to-noise ratio prevents SIMRfrom getting lost.chain.
If the matching predicate generates a reason-ably strong signal then the signal-to-noise ratio willbe high and SIMR will not get lost, even though itis a greedy algorithm with no ability to look ahead.4 Por t ing  to  New Language Pa i rsSIMR can be ported to a new language pair in threesteps.4.1 Step 1: Const ruct  Match ing  Pred icateThe original SIMR implementation forFrench/English included matching predicates thatcould use cognates and/or translation lexicons.
Forlanguage pairs in which lexical cognates are frequent,a cognate-based matching predicate should suffice.In other cases, a "seed" translation lexicon may beused to boost the number of candidate points pro-duced in the generation phase of the search.
TheSIMR implementation for Spanish/English uses onlycognates.
For Korean/English, SIMR takes advan-tage of punctuation and number cognates but sup-plements them with a small translation lexicon.4.2 Step 2: Const ruct  Axis GeneratorsIn order for SIMR to generate candidate points ofcorrespondence, it needs to know what token pairscorrespond to co-ordinates in the search rectangle.It is the axis generator's job to map the two halvesof the bitext to positions on the x- and y-axes ofthe bitext space, before SIMR starts searching forchains.
This mapping should be done with thematching predicate in mind.If the matching predicate uses cognates, then ev-ery word that might have a cognate in the otherhalf of the bitext should be assigned its own axis308position.
This rule applies to punctuation and num-bers as well as to "lexical" cognates.
In the case of-lexical cognates, the axis generator typically needsto invoke a language-specific tokenization programto identify words in the text.
Writing such a pro-gram may constitute a significant part of the port-ing effort, if no such program is available in advance.The effort may be lessened, however, by the realiza-tion that it is acceptable for the tokenization pro-gram to overgenerate just as it is acceptable for thematching predicate.
For example, when tokenizingGerman text, it is not necessary for the tokenizerto know which words are compounds.
A word thathas another word as a substring should result in oneaxis position for the substring and one for the su-perstring.When lexical cognates are not being used, the axisgenerator only needs to identify punctuation, num-bers, and those character strings in the text whichalso appear on the relevant side of the translationlexicon 3.
It would be pointless to plot other wordson the axes because the matching predicate couldnever match them anyway.
Therefore, for languageslike Chinese and Japanese, which are written with-out spaces between words, tokenization boils downto string matching.
In this manner, SIMR circum-vents the difficult problem of word identification inthese languages.4.3 Step 3: Re-optimize ParametersThe last step in the porting process is to re-optimizeSIMR's numerical parameters.
The four parametersdescribed in Section 3 interact in complicated ways,and it is impossible to find a good parameter setanalytically.
It is easier to optimize these parametersempirically, using simulated annealing (Vidal, 1993).Simulated annealing requires an objective func-tion to optimize.
The objective function for bitextmapping should measure the difference between theTBM and maps produced with the current parame-ter set.
In geometric terms, the difference is a dis-tance.
The TBM consists of a set of TPCs.
Theerror between a bitext map and each TPC can bedefined as the horizontal distance, the vertical dis-tance, or the distance perpendicular to the main di-agonal.
The first two alternatives would minimizethe error with respect o only one language or theother.
The perpendicular distance is a more robustaverage.
In order to penalize large errors more heav-ily, root mean squared (RMS) distance is minimizedinstead of mean distance.3Multi-word expressions in the translation lexicon aretreated just like any other character string.The most tedious part of the porting process is theconstruction of TBMs against which SIMR's param-eters can be optimized and tested.
The easiest wayto construct hese gold standards is to extract hemfrom pairs of hand-aligned text segments: The finalcharacter positions of each segment in an alignedpair are the co-ordinates of a TPC.
Over the courseof two porting efforts, I have develol~ed and refinedtools and methods that allow a bilingual annota-tor to construct he required TBMs very efficientlyfrom a raw bitext.
For example, a tool originally de-signed for automatic detection of omissions in trans-lations (Melamed, 1996b) was adopted to detect mis-alignments.4.4 Por t ing  Exper ience  SummaryTable 1 summarizes the amount of time investedin each new language pair.
The estimated timesfor building axis generators do not include the timespent to build the English axis generator, which waspart of the original implementation.
Axis generatorsneed to be built only once per language, rather thanonce per language pair.5 Evaluat ionSIMR was evaluated on hand-aligned bitexts of vari-ous genres in three language pairs.
None of these testbitexts were used anywhere in the training or port-ing procedures.
Each test bitext was converted to aset of TPCs by noting the pair of character positionsat the end of each aligned pair of text segments.
Thetest metric was the root mean squared distance, incharacters, between each TPC and the interpolatedbitext map produced by SIMR, where the distancewas measured perpendicular to the main diagonal.The results are presented in Table 2.The French/English part of the evaluation wasperformed on bitexts from the publicly availableBAF corpus created at CITI (Simard & Plamon-don, 1996).
SIMR's error distribution on the "parlia-mentary debates" bitext in this collection is given inTable 3.
This distribution can be compared to errordistributions reported in (Church, 1993) and in (Da-gan et al, 1993).
SIMR's RMS error on this bitextwas 5.7 characters.
Church's char_align algorithm(Church, 1993) is the only algorithm that does notuse sentence boundary information for which com-parable results have been reported, char_al ign'sRMS error on this bitext was 57 characters, exactlyten times higher.Two teams of researchers have reported resultson the same "parliamentary debates" bitext for al-gorithms that map correspondence at the sentencelevel (Gale & Church, 1991a; Simard et al, 1992).309Table 1: Time spent in constructing two "gold standard" TBMs.estimated time estimated timemain informant for spent to build spent onlanguage pair matching predicate new axis generator hand-alignmentSpanish/English lexical cognates 8 h 5 hKorean/English translation lexicon 6 h 12 hnumber ofsegmentsaligned13381224Table 2: SIMR accuracy on different ext genres in three language pairs.language number of number of RMS Errorpair training TPCs genre test TPCs in charactersFrench / English 598 parliamentary debatesCITI technical reportsother technical reportscourt transcriptsU.N.
annual reportI.L.O.
report7123365,305, 176561, 13931377204971295.74.4, 2.6, 9.920.6, 14.23.912.366.42.... Spanish / English 562 software manuals 376, 151,100, 349 4.7, 1.3, 6.6, 4.9Korean / English 615 military manuals 40, 88, 186, 299 2.6, 7.1, 25, 7.8military messages 192 0.53Table 3: SIMR 's error distribution on theFrench/English "parliamentary debates" bitext.number of error range fraction oftest points in characters test points1215469293057390243281758111111-101-80 to -70-70 to -60-60 to -50-50 to -40-40 to -30-30 to -20-20 to -10-10 to 00 to 1010 to 2020 to 3030 to 4040 to 5050 to 6060 to 7070 to 8080 to 9090 to 100110 to 120185.0001.0003.0001.0007.0006.0008.0013.0041.4292.5478.0060.0039.0024.0007.0011.0001.0001.0001.0001.0001.00017123 1.000Both of these algorithms use sentence boundaryinformation.
Melamed (1996a) showed that sen-tence boundary information can be used to convertSIMR's output into sentence alignments that aremore accurate than those obtained by either of theother two approaches.The test bitexts in the other two language pairswere created when SIMR was being ported to thoselanguages.
The Spanish/English bitexts were drawnfrom the on-line Sun MicroSystems Solaris An-swerBooks.
The Korean/English bitexts were pro-vided and hand-aligned by Young-Suk Lee of MIT'sLincoln Laboratories.
Although it is not possibleto compare SIMR's performance on these languagepairs to the performance ofother algorithms, Table 2shows that the performance on other language pairsis no worse than performance on French/English.6 Which  Text  Un i ts  to  Map?Early bitext mapping algorithms focused on sen-tences (Kay & RSscheisen, 1993; Debili & Sam-mouda, 1992).
Although sentence maps do not havesufficient resolution for some important bitext appli-cations (Melamed, 1996b; Macklovitch, 1995), sen-tences were an easy starting point, because theirorder rarely changes during translation.
Therefore,sentence mapping algorithms need not worry aboutcrossing correspondences.
In 1991, two teams of re-searchers independently discovered that sentencescan be accurately aligned by matching sequences310with similar lengths (Gale & Church, 1991a; Brownet al, 1991).Soon thereafter, Church (1993) found that bitextmapping at the sentence level is not an option fornoisy bitexts found in the real world.
Sentencesare often difficult to detect, especially where punc-tuation is missing due to OCR errors.
More im-portantly, bitexts often contain lists, tables, titles,footnotes, citations and/or mark-up codes that foilsentence alignment methods.
Church's olution wasto look at the smallest of text units - -  characters- -  and to use digital signal processing techniquesto grapple with the much larger number of textunits that might match between the two halves ofa bitext.
Characters match across languages only tothe extent hat they participate in cognates.
Thus,Church's method is only applicable to language pairswith similar alphabets.The main insight of the present work is that wordsare a happy medium-sized text unit at which to mapbitext correspondence.
By situating word positionsin a bitext space, the geometric heuristics of sen-tence alignment algorithms can be exploited equallywell at the word level.
The cognate heuristic ofthe character-based algorithms works better at theword level, because cognateness can be defined moreprecisely in terms of words, e.g.
using the LongestCommon Subsequence Ratio (Melamed, 1995).
Sev-eral other matching heuristics can only be appliedat the word level, including the localized noise filterin Section 3.3, lists of stop words and lists of /auxamis (Macklovitch, 1995).
Most importantly, trans-lation lexicons can only be used at the word level.SIMR can employ a small hand-constructed transla-tion lexicon to map bitexts in any pair of languages,even when the cognate heuristic is not applicable andsentences cannot be found.
The particular combina-tion of heuristics described in Section 3 can certainlybe improved on, but research into better bitext map-ping algorithms is likely to be most fruitfull at theword level.7 Conc lus ionThe Smooth Injective Map Recognizer (SIMR)bitext mapping algorithm advances the state of theart on several frontiers.
It is significantly more ac-curate than other algorithms in the literature.
Itsexpected running time and memory requirementsare linear in the size of the input, which makesit the algorithm of choice for very large bitexts.It is not fazed by word order differences.
It doesnot rely on pre-segmented input and is portable toany pair of languages with a minimal effort.
Thesefeatures make SIMR the mostly widely applicablebitext mapping algorithm to date.SIMR opens up several new avenues of research.One important application of bitext maps is the con-struction of translation lexicons (Dagan et al, 1993)and, as discussed, translation lexicons are an impor-tant information source for bitext mapping.
It islikely that the accuracy of both kinds of algorithmscan be improved by alternating between the two onthe same bitext.
There are also plans to build anautomatic bitext locating spider for the World WideWeb, so that SIMR can be applied to more new lan-guage pairs and bitext genres.AcknowledgementsSIMR was ported to Spanish/English while I wasvisiting Sun MicroSystems Laboratories.
Thanksto Gary Adams, Cookie Callahan, Bob Kuhns andPhilip Resnik for their help with that project.Thanks also to Philip Resnik for writing the Spanishtokenizer, and hand-aligning the Spanish/Englishtraining bitexts.
Porting SIMR to Korean/Englishwould not have been possible without Young-SukLee of MIT's Lincoln Laboratories, who provided theseed translation lexicon, and aligned all the trainingand test bitexts.
This paper was much improvedby helpful comments from Mitch Marcus, AdwaitRatnaparkhi, Bonnie Webber and three anonymousreviewers.
This research was supported by an equip-ment grant from Sun MicroSystems and by ARPAContract #N66001-94C-6043.ReferencesP.
F. Brown, J. C. Lai & R. L. Mercer, "AligningSentences in Parallel Corpora," Proceedings of the29th Annual Meeting of the AsSociation for Com-putational Linguistics, Berkeley, CA, 1991.P.
F. Brown, S. Della Pietra, V. Della Pietra, &R. Mercer, "The Mathematics of Statistical Ma-chine Translation: Parameter Estimation", Com-putational Lin9uistics 19:2, 1993.R.
Catizone, G. Russell & S. Warwick "DerivingTranslation Data from Bilingual Texts," Proceed-ings of the First International Lexical AcquisitionWorkshop, Detroit, MI, 1993.S.
Chen, "Aligning Sentences in Bilingual CorporaUsing Lexical Information," Proceedings of the31st Annual Meeting of the Association for Com-putational Linguistics, Columbus, OH, 1993.K.
W. Church, "Char_align: A Program for Align-ing Parallel Texts at the Character Level," Pro-311ceedings of the 31st Annual Meeting of the Asso-ciation for Computational Linguistics, Columbus,OH, 1993.I.
Dagan, K. Church, & W. Gale, "Robust WordAlignment for Machine Aided Translation," Pro-ceedings of the Workshop on Very Large Corpora:Academic and Industrial Perspectives, Columbus,OH, 1993.F.
Debili & E. Sammouda "Appariement des Phrasesde Textes Bilingues," Proceedings of the 14thInternational Conference on Computational Lin-guistics, Nantes, France, 1992.G.
Foster, P. Isabelle & P. Plamondon, "Word Com-pletion: A First Step Toward Target-Text Medi-ated IMT," Proceedings of the 16th InternationalConference on Computational Linguistics, Copen-hagen, Denmark, 1996.P.
Fung, "Compiling Bilingual Lexicon Entries froma Non-Parallel English-Chinese Corpus," Proceed-ings of the Third Workshop on Very Large Cor-pora, Boston, MA, 1995.W.
Gale & K. W. Church, "A Program for AligningSentences in Bilingual Corpora," Proceedings ofthe 29th Annual Meeting o-f the Association forComputational Linguistics, Berkeley, CA, 1991a.W.
Gale & K. W. Church, "Identifying Word Corre-spondences in Parallel Texts," Proceedings of theDARPA SNL Workshop, 1991b.B.
Harris, "Bi-Text, a New Concept in TranslationTheory," Language Monthly #54, 1988.M.
Kay & M. Rbscheisen "Text-Translation Align-ment," Computational Linguistics 19:1, 1993.E.
Macklovitch, "Peut-on verifier automatiquementla coherence terminologique?"
Proceedings of theIV es Journdes scientifiques, Lexicommatique tDictionnairiques, organized by AUPELF-UREF,Lyon, France, 1995.I.
D. Melamed "Automatic Evaluation and UniformFilter Cascades for Inducing N-best TranslationLexicons," Proceedings of the Third Workshop onVery Large Corpora, Boston, MA, 1995.I.
D. Melamed, "A Geometric Approach to MappingBitext Correspondence," Proceedings of the FirstConference on Empirical Methods in Natural Lan-guage Processing (EMNLP'96), Philadelphia, PA,1996a.I.
D. Melamed "Automatic Detection of Omissionsin Translations," Proceedings of the 16th Interna-tional Conference on Computational Linguistics,Copenhagen, Denmark, 1996b.I.
D. Metamed, "Automatic Construction of CleanBroad-Coverage Translation Lexicons," Proceed-ings of the Conference of the Association forMachine Translation in the Americas, Montreal,Canada, 1996c.I.
D. Melamed, "A Word-to-Word Model of Transla-tional Equivalence," Proceedings of the 35th Con-ference of the Association/or Computational Lin-guistics, Madrid, Spain, 1997.
(in this volume)P. Resnik & I. D. Melamed, "Semi-Automatic Acqui-sition of Domain-Specific Translation Lexicons,"Proceedings of the 7th A CL Conference on Ap-plied Natural Language Processing, Washington,DC, 1997.P.
Resnik, "Evaluating Multilingual Gisting of WebPages," UMIACS-TR-97-39, University of Mary-land, 1997.S.
Sato & M. Nagao, "Toward Memory-Based Trans-lation," Proceedings of the 13th InternationalConference on Computational Linguistics, 1990.S.
Sato, "CTM: An Example-Based TranslationAid System," Proceedings of the 14th Interna-tional Conference on Computational Linguistics,Nantes, France, 1992.SIGIR Workshop on Cross-linguistic MultilingualInformation Retrieval, Zurich, 1996.M.
Simard, G. F. Foster & P. Isabelle, "Using Cog-nates to Align Sentences in Bilingual Corpora,"in Proceedings of the Fourth International Con-ference on Theoretical and Methodological Issuesin Machine Translation, Montreal, Canada, 1992.M.
Simard &: P. Plamondon, "Bilingual SentenceAlignment: Balancing Robustness and Accuracy,"Proceedings of the Conference of the Associationfor Machine Translation in the Americas, Mon-treal, Canada, 1996.R.
V. V. Vidal, Applied simulated Annealing,Springer-Verlag, Heidelberg, Germany, 1993.312
