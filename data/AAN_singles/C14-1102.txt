Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 1081?1090, Dublin, Ireland, August 23-29 2014.Active Learning in Noisy Conditions for Spoken LanguageUnderstandingAbstractActive learning has proved effective in many fields of natural language processing.
However,in the field of spoken language understanding which is always dealing with noise, no completecomparison between different active learning methods has been done.
This paper compares thebest known active learning methods in noisy conditions for spoken language understanding.Additionally a new method based on Fisher information named as Weighted GradientUncertainty (WGU) is proposed.
Furthermore, Strict Local Density (SLD) method is proposedbased on a new concept of local density and a new technique of utilizing information densitymeasures.
Results demonstrate that both proposed methods outperform the best performanceof the previous methods in noisy and noise-free conditions with SLD being superior to WGUslightly.1 Introduction?Spoken language understanding (SLU) is currently an emerging field in the intersection of speechprocessing and natural language processing (Tur and De Mori, 2011).
The task of an SLU system is toextract meaning from speech utterances.
Example real-world applications are AT&T's How May I HelpYou?
and BBN's Call Director.
In the field of SLU, as well as other fields of natural language processing,gathering data is fairly cheap but labeling is quite expensive and time-consuming.
Thus, active learningmethods apply very well and can greatly reduce costs.
This article evaluates different techniques ofactive learning in the context of statistical SLU to reduce the labeling effort as much as possible.
Also,SLU deals with the most amount of noise, in comparison with other fields of NLP, making robustnessone of its most important issues (Tur and De Mori, 2011).
Therefore, in this article noisy conditions ofSLU are explored too.
In this paper, we concentrate on statistical approaches for modeling the SLUsystem.
Specifically conditional random fields (Lafferty et al., 2001) are used with a flat semantic frameto represent meaning and to model the SLU system.While there have been a couple of studies on active learning in the context of SLU, they have mostlyused only methods in the frameworks of uncertainty sampling (Tur et al., 2003; Jars and Panaget, 2008)and query-by-committee (Gotab et al., 2009).
In addition, noisy conditions which are an important aspectof SLU have not been addressed thoroughly.In this paper, performance of various known active learning methods namely uncertainty sampling,query-by-committee, Fisher information ratio (Settles and Craven, 2008) and instability sampling (Zhu?This work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/.Hossein HadianDepartment of ComputerEngineering, SharifUniversity of Technology,Tehran, Iranhadian@ce.sharif.eduHossein SametiDepartment of ComputerEngineering, SharifUniversity of Technology,Tehran, Iransameti@sharif.edu1081and Ma, 2012) are examined and analyzed in noise-free and noisy conditions of SLU.
Also a new methodfor measuring informativeness of instances based on the Fisher information framework is developed andevaluated along with other methods.
Besides, to deal with noisy conditions, the new concept of localdensity and a new technique to utilize density measures are introduced and described.The rest of this paper is organized as follows: Section 2 briefly describes CRFs, pool-based activelearning framework, and selected active learning methods applicable to CRFs.
Section 3 describes thefirst proposed method: Weighted Gradient Uncertainty.
Section 4 introduces the local density concept,describes its motives and the proposed method of SLD is described.
In Section 5, the noise model isdescribed and experiments are performed in both noisy and noise-free conditions.
Finally in Section 6conclusions are derived.2 Active Learning and CRFsCRFs (Lafferty et al., 2001) are statistical graphical models which have demonstrated state-of-the-artaccuracy in many fields as well as in SLU.
A linear-chain CRF with parameter vector ?, defines theprobability of ???
being the true label sequence for observation sequence ???
(with length T) as:?
(???|???
; ???)
=1?????(???)?
exp (??????(??
?1, ??
, ??
?, ?)??=1??=1).
(1)?????(???)
is the normalization factor and ensures that sum of ?
(???|???
; ?)
over all possible labelings equals1.
There are K feature functions ??(??
?1, ?
?, ??
?, ?)
in a linear-chain CRF along with their weights ?
?.Each feature ?
?, is a function of the whole observation sequence, the position of current observation andthe current and previous labels.
Training is the process of finding the optimum weight vector ?
tomaximize the conditional log-likelihood of training instances in the labeled data set ?:?(?
; ?)
=  ?
log?(???|???
; ?)(?,????)??????2?2??=1.
(2)The second term is a regularization penalty to prevent over-fitting.
After training, the labels can bepredicted using the Viterbi algorithm.Figure 1.
Pool-based active learning (Settles and Craven, 2008).The focus of this paper is on pool-based active learning in which a learner should select mostinformative instances for labeling from a pool of unlabeled ones.
We adopt the same notation used bySettles and Craven (2008) for the generic pool-based algorithm, sketched in Figure 1.
Query strategyGiven:   Labeled set ?, unlabeled pool ?, querystartegy ?(?
), query batch size ?repeat// learn a model using the current ??
= ?????(?
);for b = 1 to ?
do// query the most informative instance???
= argmax????(?)
;// move the labeled query from ?
to ??
= ?
?
????
, ?????(???
)?
;?
=  ?
?
???
;enduntil some stopping criterion;1082?(?)
is a function which evaluates how informative an unlabeled instance is.
Most methods of activelearning are a definition for this function.
In the following subsections the best known active learningmethods are briefly described.2.1 Uncertainty SamplingIn this very common framework the learner queries the instance that it is most uncertain how to label.Two methods in this framework proved effective according to Settles and Craven (2008) which arepresented here.
First is the least confident (LC) method:???(???)
=  1 ?
?(????|???
; ?
), (3)where ????
is the most likely label sequence.
Second query strategy is the sequence entropy (SE) methodwhich measures informativeness of an instance based on entropy in different labelings:???(???)
=  ??
?(???|???
; ?)??????
log?(???|???
; ?
),  (4)where ?
is the set of all possible labelings for ??
?.2.2 Query-By-CommitteeQuery-by-committee (QBC) is another well-studied and common framework for active learning.
Thereare many approaches in this framework, but we use the approach suggested by Settles and Craven (2008)which has performed best with CRFs: in each round of active learning, ?
is sampled |?| times (withreplacement) to create a unique modified labeled set ?(?).
This is done C times to create C unique labeledsets.
Then a committee of C models is trained: Each model ?(?)
is trained using its corresponding labeledset ?(?).
Then the disagreement among the committee members about labeling an instance is measuredas its informativeness:????(???)
=  ?
?
?(???|???
; ?)??????????
?(???|???
; ?).
(5)In this equation, ??
is the union of N-best labelings of all models in the committee, and ?(???|???
; ?)
=1??
?(???|???
; ?)?
?=1  is the consensus posterior probability for some label sequence ??
?.2.3 RepresentativenessIt is suggested that considering representativeness of instances can reduce the chance of selecting outliersin the process of active learning (Roy and McCallum, 2001).
Representativeness can be measured bydensity of each instance, defined as the average similarity of an instance to other instances.
Because thecomputation of density can be quite time-consuming in large-scale data sets, it is suggested to computedensity in clusters (Tang et al., 2002; Shen et al., 2004) or in a k-Nearest-Neighbor manner (Zhu et al.,2008).
Representativeness is applied by multiplying density to any arbitrary uncertainty measure toprevent outliers.
Settles and Craven (2008) define a query strategy based on density:???(???)
= ???(???)
?
[??(???)]?
, (6)??(???)
=1??
???(???
, ???(?))?
?=1  .
(7)Parameter ?
controls the relative effect of density ??(???).
This density uses a similarity measure ???(?,?)
to compute the average similarity of an instance with all other unlabeled instances.
The similaritymeasure used by Settles and Craven (2008) is a cosine similarity between two instances after beingtransformed to a vector of fixed length using this relation:???
= [?
?1(??)?
?=1 , ?
, ?
??(??)?
?=1  ],  (8)where ??(??)
is the value of feature ??
for token ??
, and J is the number of features in inputrepresentation.
These features can be generated using CRF feature templates.
Please refer to Settles andCraven (2008) for more details.10832.4 Fisher InformationWe also evaluate the FIR (Fisher Information Ratio) method proposed by Settles and Craven (2008).Two vectors based on Fisher information are defined:??(?)
= ?
?(???|???
; ?)
[(?
log?(???|???
; ?)?
?1)2+ ?,?
, (?
log?(???|???
; ?)???
)2+ ?
]?????
,  (9)??(?)
=1|?|?
??(?)(?
)|?|?=1 ,  (10)where ??(?)
and ??(?)
are the Fisher information matrices for sequence ???
and unlabeled pool ?respectively.
These matrices are estimated using their diagonal due to performance issues.
Also K is thetotal number of CRF features, ?
is the set of N-best label sequences for input ???
and constant ?<<1 isadded to prevent division by zero.
Finally, FIR measures the informativeness of instances using:????(???)
= ??????(??(?)?1??(?)).
(11)2.5 Instability Sampling(Zhu and Ma, 2012) suggest selecting instances which are most unstable.
They propose two new methodsto select most unstable instances based on recent active learning cycles: label-insensitive instabilitysampling (LIIS) and label-sensitive instability sampling (LSIS).
Given an unlabeled instance ???
at ithlearning cycle, its instability value in LIIS is estimated by:?????(???)
= ????(???)
+ ?
(????(???)
?
???1??
(???))???<???
,  (12)where ????(???)
is ???(???)
at ith learning cycle and ?
is the number of cycles considered for instabilityestimation.
Likewise, the instability value of ???
in LSIS is estimated by:?????(???)
= ????(???)
+ ?
?(???(?
), ???(?
?1)) (????(???)
?
???1??
(???))???<???
,  (13)where ?(???(?
), ???(?
?1)) is 0 if the predicted label sequences ???(?)
and ???(?
?1) are the same and 1 otherwise.It?s worthwhile to point that none of the instability sampling methods have been evaluated in the contextof sequence labeling and they have only been evaluated in the context of classification.3 The First Proposed Method: Weighted Gradient Uncertainty (WGU)The new method to be introduced in this article is an improvement over the FIR method (subsection2.4).
According to evaluations by Settles and Craven (2008), the FIR method didn?t perform well inpractice despite its sound theory.
In this section, first we investigate the essence of each component of??(?):??(?)?
= ?
?(???|???
; ?)
(?
???
?(???|???
; ?)???)2?????.
(14)According to this relation, the kth component of Fisher vector ??(?)
is the weighted sum of squaredgradients of log-probabilities for the N best labelings for instance ???
in kth dimension of CRF features.
Itcan be seen intuitively that each component of the Fisher vector increases when there is a kind of entropybetween the N-best probabilities.
That?s because when for example the best label sequence hasprobability 1 then its gradient will be zero in all dimensions (complete fit) and hence all the componentswill be zero.
On the other hand, if N best label sequences have equal probabilities, none of them willhave a zero gradient since none is a complete fit and  ??(?)
will be maximized.To show this fact more rigidly, assume the N best label sequences as ?
= { ???
(1) , ???
(2) , ?
, ???(?)
}, andalso for simplicity, define: ??
= ?(???(?)|???
; ?)
.
Then we will have:?????
=??????
(???1(?
), ??(?
), ??
?, ?)??=1??=1?
????????(???
), (15)and so, its partial derivative in kth dimension will be (assuming ?
contains all possible label sequences):1084?????????=???
(???1(?
), ??(?
), ??
?, ?)??=1???(?)?1?????(???)??????(???)??
?= ??(?)
?
?
????(?)?
?=1,(16)where ??(?
)is the result of applying feature function ??
(from CRF model) on nth best label sequence.Now using (16) we can rewrite (14) as:??(?)?
= ???
(??(?)
?
?
????(?)??=1)2??=1.
(17)To fully understand each component, we further factorized the above relation and proved it to be equalto (the proof is omitted here for brevity):??(?)?
=?
?
????
(??(?)
?
??(?))2??=?+1??=1.
(18)This relation explains the meaning of components of the Fisher vector completely.
Each component is asummation over N best label sequences.
The expression under summation consists of two parts: ???
?and (??(?)
?
??(?))2.
It can be shown using Lagrange multipliers that the first part is maximized(independently) when ??
=1?, ??
; which means this part is maximized when maximum entropybetween N best probabilities occurs.
The second part is the squared difference of kth feature functionapplied to two label sequences.
So this part is maximized when the dissimilarities between every twolabel sequences in N-best list are maximum, which in turn means the model has maximum uncertaintyin choosing the N-best label sequences for the input.
Notice that in this interpretation we have assumedthe two parts to be independent while they are not actually.
However since the number of features ofCRF (i.e.
K) is too large, the dependency is negligible and can be ignored.
So we conclude that eachcomponent of the Fisher vector ??(?)
is a measure of uncertainty of the model about the sequence ???
inthe corresponding dimension.
Accordingly, each component of the total Fisher information vector ??(?
)is the average uncertainty of the model in the corresponding dimension.Knowing the precise identity of Fisher vector ??(?
), we propose a natural measure which we callWeighted Gradient Uncertainty (WGU) based on the facts explained in the previous paragraph:????(???)
= ????(?)?(??(?)?
)2?.
(19)This measure is the weighted norm of ??(?)
with the total Fisher information vector ??(?)
as theweight vector.
This query strategy favors instances with high uncertainty in each dimension of CRFfeature space, especially the dimensions where the average uncertainty is higher.
In other terms, theWGU measure maximizes the components of the Fisher vector, while the FIR method minimizes theinversed components of the Fisher vector; and since many components of the Fisher vector are zero ornear-zero, their inversed values are very large and block out the other larger components (with verysmall inverse values) leading to a measure which effectively just counts the number of zero componentsand chooses the instance with the maximum number of zero components.4 Using Local Density for Noisy ConditionsAs described in Introduction, a great issue in SLU systems is the presence of noise in utterances.
Toaddress this problem, all the ATIS instances were converted to vectors according to (8) and werereduced to 2 dimensions using Principle Component Analysis (PCA).
Then the global density ??(???)
for ATIS is the dataset used in this article for evaluation; please read subsection 5.1.1085each instance was computed using (7).
Figure 2 shows the plot of all instances with darker pointsindicating instances with higher densities and lighter points showing the ones with lower densities.As seen in Figure 2(a), the center of the distribution in terms of density is the darkest part.
Also, thedistribution of instances is not uniform at all, and excluding any part of the distribution especially partsfurther from the density center can lead to great decrease in performance of the model.
The query strategy???
(6) uses this density to reduce the chance of querying outliers.
However, outliers as well as manyother instances which are far from the density center are almost deprived of the chance of being selected.To address this problem and yet avoid outliers we choose to compute information density for eachinstance locally, i.e.
using k nearest instances and not all instances.
Thus, we define the local informationdensity measure as follows:??(???
, ?)
=1??
Sim(???
, ????).?????(???
)(20)In which, ??(???)
is the set of k most similar instances to ???
, and k is the degree of locality.
(a)                                                                                  (b)Figure 2.
Plot of all ATIS instances.
Darker points show higher densities and lighter ones show lowerdensities.
(a) Using global density measure (b) Using local density measure (k=5).The same procedure to plot Figure 2(a) is repeated again but with ??(???
, ?)
computed as the densityof each instance and the result is shown in Figure 2(b).
The degree of locality is set to k=5.
As seen inthis plot, outliers are still completely grey which means they are avoided.
Also, any small neighborhoodwith sufficient density is biased to black, which means the instances in the center of that neighborhoodhave almost the same chance of being queried as the instances in the center of global density (??)
inFigure 2(a).Another advantage of local density is that it avoids noisy instances.
Noisy instances in the SLUcontext are the utterances in which one or more words are erroneous due to ASR or user errors.
Becauseof such errors, noisy instances take a small distance from their similar instances and reside alone in smallneighborhoods.Based on the LD measure (20), two active learning methods are considered: the first method applieslocal density measure to query strategy by multiplication (same as ???):???(???)
= ???(???)
?
[??(??
?, ?)]?
.
(21)The second method which is proposed in this paper, strictly applies the local density measure by firstfiltering out instances with local densities lower than a threshold T, and then queries the most informativeinstance according to a certain query strategy (here we use ???).
This method is called Strict LD (SLD).We believe that this method of utilizing density measures is more effective than the traditional method(i.e.
multiplying density measure by uncertainty measure (6)), since it does not affect all instances but1086only very low-density ones.
The threshold T is assumed to be in the form of ?
?
??????
, where ??????
is theaverage of local density over all unlabeled instances, and parameter ?
sets the intensity of filtering.It is necessary to note that the k-Nearest-Neighbor density measure (Zhu et al., 2008) is identical tolocal density in definition but the motivation is different and in this article we look at the k-nearest-neighbor density from a completely different perspective: to avoid a shortcoming in the global densitywhich is ignoring great parts of the input distribution and also to detect noisy instances.5 ExperimentsExperiments are all performed on the ATIS data set (Hemphil et.
al, 1990), both in noise-free and noisyconditions.
In this section, the noise model used to generate noise is briefly described and then theevaluations are presented.5.1 ATIS and Noise ModelATIS is a relatively simple corpus which contains air travel information data.
This corpus is the mostcommonly used data set for SLU research (Tur et.
al, 2010).
The data set contains questions (utterances)about flight, airport, and airline information.
We specifically use the class-A (context independent)utterances from ATIS-3 corpus (Dahl et.
al, 2004).
These utterances are not semantically labelled,instead for each utterance there is an SQL command which queries the answer to the utterance fromdatabase.
Thus a flat sematic representation was designed and semantic label sequences were generatedsemi-automatically from the SQL queries (as explained by He and Young (2006)).
The flat semanticrepresentation is listed in Table 1(a).
A flat semantic representation is in fact a set of attributes (semanticlabels) which are used to label an input utterance.
Table 1(c) shows a typical utterance with sematiclabels; note that IOB labeling scheme is used.
Totally there are 1630 class-A instances (test + train) inATIS-3 which are used in the experiments.
(a)Attribute Description Attribute DescriptionDCity depart.
city ACity arrival citySCity stop city DAir depart.
airportDDate depart.
date ADate arrival dateRDate return date AAir arrival airportOrigin PairASR via ?
fly atHuman to Chicago ?
chica toChicagoASR phoenix ?
t x(b)Show flights from Denver to Washington on Sunday arriving before noonO O O DCity O ACity O DDate O ADate-IADate-I(c)Table 1: (a) The flat semantic representation used to label utterances in the data set.
(b) Some examplepairs in noise model.
Each pair is extracted from actual errors in ATIS-3 utterances.
(c) A typicalexample from ATIS utterances.Utterances in ATIS are de-noised by wizards.
There are two origins of noise: human (end-user) errorsand ASR recognition errors.
We design a simple noise-model based on actual errors and regeneratehuman and ASR errors.
In ATIS-3, human errors are marked in SRO files and ASR errors are in N-bestlists in log files.
The noise model is a list of pairs of the form [correct-expression] ?
[erroneous-expression] which are applied to ATIS instances to add arbitrary percentage of noise.
A few examplepairs in the noise model are listed in Table 1(b).
Each pair is extracted from an actual error; for example[phoenix] ?
[t x] is a result of an ASR error in ATIS-3 logs where ?phoenix?
in ?Show me flights fromphoenix ??
was recognized as ?t x?
mistakenly.
Obviously this pair is only applicable to an utterancewhich contains the word ?phoenix?. Air Travel Information System A wizard is a human expert who transcribes utterances or answers them (Hemphil et.
al, 1990).10875.2 Parameter SettingsUsing the noise model described, 3 levels of noise were generated: 7% of instances in level 1, 15% inlevel 2, and 25% in level 3 are noisy.
In noisy conditions, when a noisy instance is selected by an activelearning method, we assume that the instance is correctly detected as noisy by the annotator and isrejected (i.e.
not added to ?
); but the determination of an instance as noisy incurs a cost which we assumeto be a quarter of cost of labeling one instance.
In all experiments, ?
is initialized with 5 random traininginstances.
Batch size in all experiments is set to B=2 and new instances are added to ?
until the totallabeling cost reaches 100.
For query-by-committee method, we set C=4 and N=20 to balance betweenspeed and accuracy.
For LD and SLD, we set k=1 because it achieved best performance.
For LIIS andLSIS, we set ?=2 which achieved better results.
Each method is evaluated as the average of 5 trials andeach trial is performed using 5-fold cross validation.
The reported performance for each method is thearea under F1 learning curve (F1 score in SLU is computed as described by Tur and De Mori (2011)).5.3 Effect of LocalityBy initial evaluations, ?=1 and ?=0.6 were chosen for the LD and SLD method respectively.
In Figure3, the performances of LD and SLD for different degrees of locality (for k=1 to 1000) are shown.
Theperformance of the LC method is also shown for comparison.As seen in Figure 3, local density improves uncertainty measure (i.e.
??
?, which is the base methodin LD and SLD) and performs better than global density (i.e.
local density with k=1000+).
Note that LDhas led to better performances than LC only for very local densities (i.e.
k<5) while SLD has improvedthe performance of LC almost for all degrees of locality.
It can also be seen that applying density strictlyis more effective than the traditional way for all degrees of locality especially in noisy conditions.
(a) Noise-free condition                                    (b) Noisy condition (average of all levels)Figure 3.
Effect of locality degree (in computation of information density) on performance of activelearning methods.
Plots (a) and (b) show the area under F1 learning curve for different values of k inLD and SLD methods, for noise-free and noisy conditions respectively.
The area under F1 learningcurve for LC is also shown for comparison.5.4 EvaluationsThe detailed results of the discussed active learning methods on different levels of noise are presentedin Table 2.
In each row, best performance is bolded and underlined, and second best performance is justbolded.
Random refers to the random sampling of instances (passive learning).
In noise-free condition,LD and SLD have improved a little over LC, but in average, SLD has performed remarkably better thanLC, which shows the effectiveness of using local density to avoid noisy instances (note that LC is thebase method used in LD and SLD).
The instability sampling methods have improved over uncertainty The cost of labelling one instance is equal to 1 for any instance.
In this paper, learning curves are depicted in terms ofannotation cost which is equivalent to annotation time (please refer to Tomanek and Hahn (2010)).0 200 400 600 800 10009090.59191.59292.5locality degree (k)AreaunderF1learningcurveSLDLDLC0 200 400 600 800 100088.58989.59090.59191.5locality degree (k)AreaunderF1learningcurveSLDLDLC1088sampling (i.e.
SE) but not significantly.
In the last row of Table 2 the running time of one cycle of activelearning for each method is presented in seconds.
QBC is the slowest method and LC is the fastest one.WGU is the second best in average performance but is rather slow in comparison to LC and this is adisadvantage of WGU.
In fact all methods that iterate over best labelings are considerably slower thatLC.Learning curves cannot be shown for all active learning methods due to lack of space.
Instead, learningcurves are shown for selected methods.
In Figure 4, learning curves for five methods of SLD, WGU,LIIS, FIR, and random are shown.
It can be seen that the new WGU method has the best performancein early stages of active learning but soon declines and stays above the curve of LIIS.
Also, the differenceof SLD with other methods is more remarkable in the noisy conditions.Random LC SE QBC ID FIR LIIS LSIS WGU LD SLDNoise-free 84.5 91.8 91.9 90.5 90.2 89.5 91.7 91.8 92.1 92.1 92.4Noise level 1 84.1 91.5 90.7 90 89.6 89.1 91.1 90.8 91.7 91.2 91.7Noise level 2 83.2 88.9 89 88.2 88.1 89.2 89.4 88.9 90.4 89.4 91.1Noise level 3 83 88.4 88.4 87.5 87.7 88.9 88.7 87.8 90 89.3 91Average 83.7 90.1 90 89 88.9 89.2 90.2 89.8 91.1 90.5 91.6Runtime 5 5 8 20 5.5 8 8 8 8 5.5 5.5Table 2.
Area under F1 learning curves (max possible score is 100) and runtimes ofvarious active learning methods on different levels of noise.Figure 4.
Learning curves for five selected methods: SLD, WGU, LIIS, FIR, and random for noise-freeand noisy conditions (averaged across noise levels 1-3).
Each learning curve shows the F1 measuresachieved by the corresponding method for different labelling costs up to 100.6 ConclusionIn this paper, best known active learning methods applicable to sequence labeling tasks were evaluatedin the field of SLU (Spoken Language Understanding) in real conditions of noise.
The new method ofWGU (Weighted Gradient Uncertainty) with theoretical justification was proposed and performed wellin the evaluations.
Also, to deal directly with noisy instances, two methods of LD (Local Density) andSLD (Strict LD) were proposed based on the local density concept.
It is possible to apply local densityto WGU or other methods to achieve even better results but this could be the subject of future work.0 20 40 60 80 100 1200.840.860.80.90.920.940.96Labeling costF1measureNoise-free conditionSLDWGULIISFIRRandom0 20 40 60 80 100 1200.840.850.860.80.880.890.90.910.920.930.94Labeling costF1measureNoisy conditions (average)SLDWGULIISFIRRandom1089ReferencesBurr Settles and Mark Craven.
2008.
An Analysis of Active Learning Strategies for Sequence Labeling Tasks, InEMNLP '08 Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp.
1070-1079.Charles T. Hemphill, John J. Godfrey, and George R. Doddington.
1990.
The ATIS spoken language systems pilotcorpus.
In Proceedings of the workshop on Speech and Natural Language.
Association for ComputationalLinguistics, Stroudsburg, PA, USA, pp.
96-101.Deborah A. Dahl, Madeleine Bates, Michael Brown, William Fisher, Kate Hunicke-Smith, David Pallett, ChristinePao, Alexander Rudnicky, and Elizabeth Shriberg.
1994.
Expanding the scope of the ATIS task: the ATIS-3 corpus.In Proceedings of the workshop on Human Language Technology (HLT '94).
Association for ComputationalLinguistics, Stroudsburg, PA, USA, pp.
43-48.Gokhan Tur, Dilek Hakkani-T?r, and Larry P. Heck.
2010.
What is left to be understood in ATIS?
IEEE SpokenLanguage Technology Workshop (SLT), Berkeley, California, USA, December 12-15, pp.
19-24.Gokhan Tur and Renato De Mori.
2011.
Spoken Language Understanding: Systems for Extracting SemanticInformation from Speech, First Edition, John Wiley & Sons.Gokhan Tur, Marzin Rahim, and Dilek Hakkani-T?r.
2003.
Active Learning for Spoken Language Understanding,In Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing, vol.
1, pp.
276-279.Isabelle Jars and Franck Panaget.
2008.
Improving Spoken Language Understanding with information retrievaland active learning methods, In Proceedings of IEEE International Conference on Acoustics, Speech, and SignalProcessing, pp.
5001-5004.John Lafferty, Andrew McCallum, and Fernando Pereira.
2001.
Conditional random fields: Probabilistic modelsfor segmenting and labeling sequence data, In Proceedings of the International Conference on Machine Learning(ICML), pp.
282?289.Jingbo Zhu and Matthew Ma.
2012.
Uncertainty-based active learning with instability estimation for textclassification.
ACM Transactions on Speech and Language Processing (TSLP), vol.
8(4) - 01/2012.Jingbo Zhu, Huizhen Wang, Tianshun Yao, and Benjamin K. Tsou.
2008.
Active learning with sampling byuncertainty and density for word sense disambiguation and text classification.
In Proceedings of the 22ndInternational Conference on Computational Linguistics (COLING '08), Vol.
1, pp.
1137-1144.Katrin Tomanek and Udo Hahn.
2010.
A comparison of models for cost-sensitive active learning.
In Proceedingsof the 23rd International Conference on Computational Linguistics (COLING '10), pp.
1247-1255.Lynette Hirschman.
1992.
Multi-Site Data Collection for a Spoken Language Corpus, In Proceedings ofInternational Conference on Spoken Language Processing, Banff, Canada.Min Tang, Xiaoqiang Luo, and Salim Roukos.
2002.
Active learning for statistical natural language parsing, InProceedings of the Association for Computational Linguistics 40th Anniversary Meeting, pp.120?127.Nicholas Roy and Andrew McCallum.
2001.
Toward optimal active learning through sampling estimation of errorreduction, In Proceedings of the International Conference on Machine Learning (ICML), pp.
441?448.Pierre Gotab, Fr?d?ric B?chet, and G?raldine Damnati.
2009.
Active learning for rule-based and corpus-basedSpoken Language Understanding models, In Proceedings of IEEE Conference on Automatic Speech Recognitionand Understanding, pp.
444-449.Yulan He and Steve Young.
2005.
Semantic processing using the hidden vector state model, Computer Speech &Language, vol.
19, no.
1, pp.
85?106.1090
