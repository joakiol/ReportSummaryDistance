Toward Asian Speech Translation System:  Developing Speech Recog-nition and Machine Translation for Indonesian LanguageHammam RizaIPTEKNETAgency for the Assessment andApplication of TechnologyJakarta, Indonesiahammam@iptek.net.idOskar RiandiICT CenterAgency for the Assessment andApplication of TechnologyJakarta, Indonesiaoskar@inn.bppt.go.idAbstractIn this paper, we present a report on the re-search and development of speech tospeech translation system for Asian lan-guages, primarily on the design and im-plementation of speech recognition andmachine translation systems for Indonesialanguage.
As part of the A-STAR project,each participating country will need to de-velop each component of the full systemfor the corresponding language.
We willspecifically discuss our method on buildingspeech recognition and stochastic languagemodel for statistically translating Indone-sian into other Asian languages.
The sys-tem is equipped with a capability to handlevariation of speech input, a more naturalmode of communication between the sys-tem and the users.1 IntroductionIndonesia is one of the ten most populous nationsin the world with the population of about 235 mil-lion people as of 2004 and is located strategicallywithin the Asia region.
The exchange of people,goods and services as well as information increasesand should not be hindered by language barrier.Even though, English language may be used as themain global communication language, the moredirect and more natural way of communication ispreferred by local and native people to ensure thesmooth exchange of information among people ofdifferent languages.It would be beneficial for Indonesia people, ifthere were a system that is able, to some extent in acertain domain, to capture either a speech or digitaltext based on Indonesian language and process it inorder to output into meaningful text into other lan-guages such as English, Japanese and other worldlanguages.
In addition to above mentioned benefit,large numbers of Indonesian people, statistically,have problem in using and comprehending anyinformation presented in English language, Thelanguage barrier problem is compounded by theproblem of the explosion of digital informationwhose majority uses English language via eitherInternet or any digital / printed form which mayoverwhelms potential users and  pose a threat ofinequality of access of information due to the lan-guage barrier (digital divide) especially for thecommon Indonesian people.
We are now part of amulti national project to develop speech to speechtranslation system for Asian languages facilitatedby ATR-Japan.Our most recent work is focusing on developingIndonesian speech recognition engine and a statis-tical language model for machine translation.
Ourapproach to MT is based on the integration of sto-chastic and symbolic approaches to be used foranalyzing Indonesian.
For creating the stochasticlanguage model, it is worthwhile to utilize anno-tated data when it is available and use supervisedlearning mechanism to estimate model?s parame-ter.
In this case, an annotated corpus is created formultiple genres of documents.
Of course, the costsof annotation are prohibitively labor intensive, andthe resulting corpora sometimes are susceptible toa particular genre.
Due to this limitation of anno-tated corpora, it is necessary that we use unsuper-vised and weakly supervised learning techniques,which do not require large, annotated data sets.Unsupervised learning utilizes raw, un-annotated corpora to discover underlying languagestructure such as lexical and contextual relation-ships.
This gives rise to emergent patterns andprinciples found in symbolic systems.
In this sys-tem, the language model is trained using weaklysupervised learning on small annotated corpus toseed unsupervised learning using much larger, un-annotated corpora.
Unsupervised and weakly su-pervised methods have been used successfully inseveral areas of NLP, including acquiring verbsub-categorization frames, part-of-speech tagging,word-sense disambiguation and prepositionalphrase attachment.The significant contribution of this preliminaryresearch is the development of ASR using speakeradaptation technique and a statistical languagemodel for translating from/to Indonesian languageas well as Indo-Malay language in some extent.The major language found in Indonesia, Malaysia,Brunei, Singapore, Southern Thailand and Philip-pines can be categorized into a single root Indo-Malay language spoken in different dialects.
Creat-ing an ideal language model for Indo-Malay lan-guage is expected to be used by more than 260 mil-lion people in the region.Figure 1.
Scope of Indonesian-Asian Languages2 Recognizing Indonesian SpeechAchievement of a high performance is often themost dominating design criterion when implement-ing speech recognition system.
The current state ofthe art speech recognition technology is able toproduce speaker independent recognizers whichhave extremely high recognition rates forsmall/medium vocabularies.Although the average recognition rates are high,some speakers have recognition rates considerablyworse than others.
It is generally agreed thatspeaker dependent system will give the best per-formance in applications involving a specificspeaker.
This requires, however, that enough train-ing data is available for training the system fromscratch.
An often used solution is to train speakerindependent system using data from many speak-ers.
But other experiments have shown that usingsuch systems, in general, involves obtaining alower performance than what is achievable with aspeaker dependent system.
This problem can beovercome, at least partially, by using speaker adap-tation techniques, the aim of which is to take aninitial model system which is already trained, anduse a sample of a new speaker data to attempt toimprove the modeling of the speaker with the cur-rent set of the model.By collecting data from a speaker and training amodel set on this speaker's data alone, the speaker'scharacteristics can be modeled more accurately.Such systems are commonly known as speakerdependent systems, and on a typical word recogni-tion task, may have half the errors of a speaker in-dependent system.
The drawback of speaker de-pendent systems is that a large amount of data(typically hours) must be collected in order to ob-tain sufficient model accuracy.
Rather than trainingspeaker dependent models, adaptation techniquescan be applied.
In this case, by using only a smallamount of data from a new speaker, a good speakerindependent system model set can be adapted tobetter fit the characteristics of this new speaker.Speaker adaptation techniques can be used invarious different modes.
If the true transcription ofthe adaptation data is known then it is termed su-pervised adaptation, whereas if the adaptation datais unlabelled then it is termed unsupervised adap-tation.
In the case where all the adaptation data isavailable in one block, e.g.
from a speaker enroll-ment session, then this termed static adaptation.Alternatively adaptation can proceed incrementallyas adaptation data becomes available, and this istermed incremental adaptation.One of the researches on speaker adaptationtechniques based on HMM is Maximum Likeli-hood Linear Regression (MLLR).
This methodtransforms the mean of continuous HMM.
MLLRASRSMTSSIndonesiaLanguageAsianLanguageswill generate a global adaptation transform when asmall amount of data is available.
While more ad-aptation data becomes available, improved adapta-tion is possible by increasing the number of trans-formation using the regression class.
The problemthen occurred when the number of regression classincreased while the adaptation data is static.
Thetransformation matrices are difficult to estimatewell enough when the amount of adaptation data isreduced too much due to a fine regression classdivision.To overcome this problem the use of VectorField Smoothing (VFS) incorporated with MLLRis a one technique.
VFS is used to deal with theproblem of retraining with insufficient trainingdata.
The transformation matrices produced byMLLR is then be used to calculate the transformvector of VFS continued by smoothing process.2.1 Maximum Likelihood Linear RegressionMLLR uses a set of regression based transformto tune the HMM mean parameter to new speaker.The aim of MLL is to estimate an appropriatetransformation for the mean vectors of each mix-ture component so that original system is tuned tothe new speaker.
For mixture component s withmean ?s, the adapted mean estimate s?)
is given bythe following equation.sss W ??
?=)where sW is an )1( +?
nn  transformation matrixand s?
is the extended mean vector,[ ]???
?= snss ????
,,,where the value of ?
indicated whether an offsetterm is to be included: 1=?
for an offset, 0=?for no offset.
The transformation matrix is deter-mined with a re-estimation algorithm based uponthe principle of maximum likelihood estimation.
Inthis way, the re-estimated transformation matrix isthe one that maximizes the probability of havinggenerated the observed adaptation data using themodel.2.2 Vector Field SmoothingThe vector field smoothing technique assumesthat the correspondence between feature vectorsfrom different speaker is viewed as a smooth vec-tor field.
Based on this assumption, the correspon-dence obtained from adaptation data is consideredto be an incomplete set of observation from thecontinuous vector filed, containing observationerrors.
To achieve both better correspondence andreduction errors, both interpolation and smoothingare introduce into adaptation process.VFS has three steps, as follows:?
Concatenation training: In this step, themean vector of the Gaussian distribution istrained by concatenation training.?
Interpolation: In this step, the untrainedmean vector is transferred to the newspeaker's voice space by using an interpo-lated transfer vector.?
Smoothing of transfer vector: In thisstep, each transfer vector is modified in ac-cordance with the other transfer vector.2.3 MLLR-VFSThe technique of MLLR-VFS can be separatelyperformed in three steps.
The first step is an exten-sion of the MLLR to multiple regression matrixes.The second step is calculating the transfer vector ofVFS using the regression matrix produced byMLLR.
The third step is the smoothing of transfervector as VFS usual manner.?
Extension to multiple regression classIf R states { }Rsss ,,, 21 ???
are shared in a given re-gression class, then the regression matrix sW)canbe written:??
?
??
?= =?= =?
?=?TtRr sTtRr srsrsrssrsrtsrr rWtot1 111 11)()( ?????
)?
Calculation of transfer vectorThe transfer vector i???
is calculated from the dif-ference between the mean vector of the initial con-tinuous density HMM and the initial continuousdensity HMM multiplied by the regression matrix.isii W ???
?)??
?=??
Smoothing of transfer vectorIn this step, each transfer vector is modified in ac-cordance with the other transfer vector as an usualVFS manner.We conduct these steps to develop the Indonesiaspeech recognition system with favorable result.Using the speech data provided by ATR-Japan, weobtain a promising result with accuracy rate around90%.
The signal processing model takes 12 kHzsampled data and transform it into 39-dimensionalMFCC vectors every 10 ms (see Table 1, A:speaker independent, B: speaker dependent, Data isnumber of words for adaptation).
This experimentalso used Left-to-Right HMM model with singleGaussian Mixture.Table 1.
Result of  Indonesian ASRBased on this result, we are now in collaborationwith Telkom RDC to develop speech data to en-hance the accuracy.
We will also improve thespeed of the system.3 Machine Translation for IndonesianLanguageA large number of Indonesian people, statistically,have problem in using and comprehending anyinformation presented in other cross-border lan-guages.
The language barrier problem is com-pounded by the problem of the explosion of digitalinformation whose majority uses English languagevia either Internet or any digital printed formwhich may overwhelms potential users and pose athreat of inequality of access of information due tothe language barrier (digital divide) especially forthe common Indonesian people.
This is one of themotivations for us to propose a collaborative pro-ject to develop speech to Asian speech translationsystem, between BPPT-Indonesia, ATR-Japan,ETRI-Korea, NECTEC-Thailand, CCNOIDA-India, NTU-Taiwan and CAS-China.In line with the research objectives, our most re-cent experiment is focusing on developing Indone-sian statistical language model - based on the inte-gration of stochastic and symbolic approaches - tobe used for analysis stage in the machine transla-tion engine.
For creating the stochastic languagemodel, it is worthwhile to utilize annotated datawhen it is available and use supervised learningmechanism to estimate model?s parameter.
In thiscase, an annotated corpus is created for multiplegenres of documents.
Of course, the costs of anno-tation are prohibitively labor intensive, and the re-sulting corpora sometimes are susceptible to a par-ticular genre.Due to this limitation of annotated corpora, it isnecessary that we use unsupervised and weaklysupervised learning techniques, which do not re-quire large, annotated data sets.
Unsupervisedlearning utilizes raw, un-annotated corpora to dis-cover underlying language structure such as lexicaland contextual relationships.
This gives rise toemergent patterns and principles found in symbolicsystems.
In this system, the language model istrained using weakly supervised learning on smallannotated corpus to seed unsupervised learningusing much larger, un-annotated corpora.Unsupervised and weakly supervised methodshave been used successfully in several areas ofNLP, including acquiring verb sub-categorizationframes, part-of-speech tagging, word-sense disam-biguation and prepositional phrase attachment.The Internet has proven to be a huge stimulusfor statistical MT, with hundreds of millions ofpages of text being used as corpus resources.
Overthe last few years, there has been an increasingawareness of the importance of corpus resources inMT research.
As researchers begin to consider theimplications of developing their systems beyondthe level of proof-of-concept research prototypeswith very restricted coverage, considerable atten-tion is being paid to the role that existing bilingualand monolingual corpus and lexical resources canplay.
Such collections are a rich repository of in-formation about actual language usage.A Data  MAP VFS MLLR MLLR-VFSB10 85.19 81.96 85.34 86.5120 86.50 84.28 87.91 89.2240 87.75 86.50 89.80 89.3480 90.23 90.26 90.57 91.3979.7100 90.11 90.76 90.29 91.9792.7In developing monolingual corpus, we checkedexisting Indonesian news articles available on web(Purwarianti, 2007).
We found that there are threecandidates for the article collection.
But in the arti-cle downloading, we were only able to retrieve onearticle collection, sourced from Tempointerakif.We downloaded about 56,471 articles which arenoisy with many incorrect characters and some ofthem are English.
We cleaned the articles semi-automatically by deleting articles with certainwords as sub title.
We joined our downloaded arti-cles with the available Kompas corpus (Tala, 2003)at http://ilps.science.uva.nl/Resources/BI/ and re-sulted 71,109 articles.In Indonesia, many research groups have beendeveloping a large-scale annotated corpus to fur-ther the NLP and Speech research in trainable sys-tem.
It should be clear that in statistical approach,there is no role whatsoever for the explicit encod-ing of linguistic information, and thus the knowl-edge acquisition problem is solved.
On the otherhand, the general applicability of the method mightbe doubted; it is heavily dependent on the avail-ability of good quality of data in very large propor-tions, something that is currently lacking for Indo-nesian languages.In order to experiment the feasibility of statisti-cal MT for Indonesian, we build a prototype Indo-nesian-English MT.
For that purpose, we need par-allel corpus of Indonesian-English sentences, andthere are none publicly available.
Therefore, wehave develop a collection of training and test sen-tences collected from a number of informationsources mainly from Indonesia national newsagency ANTARA, totaling 250.000 parallel sen-tences.
We then use SRILM to build the n-gramlanguage model and translation model, subse-quently use PHARAOH (Koehn 2006) as a beamsearch decoder.4 Discussion and Future WorkWe are working forward to improve the quality ofspeech recognition and MT.
Our collaboration withTelkom RDC and ATR-Japan will provide us withnew speakers?
data (40 speakers, 1000 words)which is expected to improve the accuracy of ASRto a better 90% level.In other speech processing work, University ofIndonesia (UI) and Bandung Institute of Technol-ogy (ITB) are also developing ASR and speechsynthesis (SS) which will be integrated in the finalspeech translation system.We are also building a new corpus in broadcast-ing news, to train the translation system, so as toenable automatic ?tagline?
in bilingual TV pro-gram.
The experts in translation have two differ-ing approaches toward the translation concept: uni-versalism and monadic.
We understood there is apossibility of ?un-translation?
which is ?translationfails ?
or un-translability occurs when it is impos-sible to build functionally relevant features of thesituation into contextual meaning of target lan-guage (TL) text.
Broadly speaking, the cases wherethis happens fail into two categories.
Those wherethe difficulty is linguistic, and those where it iscultural.We examine further the translability concept bytaking into account that most Asian language sharevery similar ?culture?
but different in languagestructure.
We can not enforce the system and struc-ture to target language without ?knowing?
the lan-guage itself.
In this case, a rule-based systemshould be used as a preprocessing to enable thestructure of source language to approximate thestructure of target language.
For example, in trans-lating Indonesian-English, we need a rule-basedsystem to transform the DM-MD rule.
This ruleapproximates the order of noun and adjectivephrase of Indonesian according to English noun oradjective phrase.
For example:MD                                     DMsebuah rumah besar -> a big house(a)        (house)  (big)gunung  biru itu -> the blue mountain(mountain)  (blue)  (the)In our future work, by implementing severalsymbolic modules as pre-processor, it is expectedthat statistical MT will perform better in translatingby having a ?similar?
language structure.5 ConclusionAn updated report on speech to speech translationsystem is given together with a brief overview ofsome of the issues and techniques in speech recog-nition and statistical machine translation (SMT),which are being actively researched today in Indo-nesia.It is particularly important for Indonesian lan-guage to have research on speech-to-speech trans-lation systems, which is an ideal solution to thefield of language technology.
Such work is clearlyimportant but difficult because it certainly willbring up many interesting differences of emphasis,for example in speech-to-speech work, there is anemphasis on speed, and on dealing with sentencefragments, since we would like to be able to trans-late each utterance as it is spoken, without waitingfor the end.
This gives importance to bottom upmethods of language analysis, and severe restric-tions on the input in terms of the type of text.ReferencesAyu Purwarianti, Masatoshi Tsuchiya and Seiichi Na-kagawa.
2007.
Developing a Question AnsweringSystem for Limited Resource Language - IndonesianQA, submitted to Journal of Language Resourcesand Evaluation.C.H.
Lee, J.L.
Gauvain.
1993.
?Speaker AdaptationBased on MAP Estimation of HMM Parameters?,Proc.ICASSP, Minneapolis, USA, pp.II-558-561.C.J.
Leggetter, P.C.
Woodland.
1995.
?Maximum Like-lihood Linear Regression for Speaker Adaptation ofContinuous Density Hidden Markov Models?, Com-puter Speech and Language, 9(2):171-185.F.Z.
Tala.
2003.
A Study of Stemming Effects on Infor-mation Retrieval in Bahasa Indonesia, M.Sc.
Thesis,University of Amsterdam.H.
Riza.
1999.
The Indonesia National Corpus and In-formation Extraction Project (INC-IX), TechnicalReport, BPP Teknologi, Jakarta, Indonesia.H.
Riza.
2001.
BIAS-II: Bahasa Indonesia AnalyserSystem Using Stochastic-Symbolic Techniques, In-ternational Conference on Multimedia Annotation(MMA), Tokyo, Japan.Heidi Christensen.
1996.
?Speaker Adaptation of Hid-den Markov Models using Maximum LikelihoodLinear Regression?, Project Report, Aalborg Univer-sity, Denmark.J.C.
Junqua, J.P Haton.
1996.
Robustness in AutomaticSpeech Recognition ?
Fundamental and Application,Kluwer Academic Publiser, Netherland.Kazumi Ohkura, Masahide Sugiyama, Shigeki Sa-gayama.
1992.
?Speaker Adaptation Based on Trans-fer Vertor Field Smoothing with Continuous MixtureDensity HMMS, Proc of ICSLP 92, pp.
369-372.M.J.F.
Gales.
1997.
?Maximum Likelihood LinearTransformations for HMM-Based SpeechRecognition?, TR 291, Tech.
Report, CambridgeUniversity Engineering Department.Oskar Riandi.
2001.
?A Study on the Combination ofMaximum Likelihood Linear Regression and VectorField Smoothing for Speaker adaptation?, M.Sc The-sis, Japan Advanced Institute of Science and Tech-nology (JAIST), Japan.S.Young, G. Evermann, M.J.F.
Gales, T. Hain, Dan Ker-shaw, G. Moore, J. Odell, D. Ollason, D. Povey, V.Valtchev, P.C.
Woodland.
2005.
?The HTK Book (forHTK Version 3.3)?, Revised for HTK Version 3.3April 2005, Cambridge University Engineering De-partmentPhilipp Koehn.
2006.
Statistical Machine Translation:the Basic, the Novel and the Speculative, SMT Tuto-rial, University of Edinburgh.Sakriani Sakti, Konstantin Markov, Satoshi Nakamura.2005.
?Rapid Development of initial Indonesian Pho-neme-Based Speech Recognition Using The Cross-Language Approach?, Proceeding of O-COCOSDA,Jakarta.
