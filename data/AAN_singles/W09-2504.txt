Proceedings of the 2009 Workshop on Applied Textual Inference, ACL-IJCNLP 2009, pages 27?35,Suntec, Singapore, 6 August 2009.c?2009 ACL and AFNLPAugmenting WordNet-based Inference with Argument MappingIdan SzpektorDepartment of Computer ScienceBar-Ilan UniversityRamat Gan, Israelszpekti@cs.biu.ac.ilIdo DaganDepartment of Computer ScienceBar-Ilan UniversityRamat Gan, Israeldagan@cs.biu.ac.ilAbstractWordNet is a useful resource for lexi-cal inference in applications.
Inferenceover predicates, however, often requiresa change in argument positions, whichis not specified in WordNet.
We pro-pose a novel framework for augmentingWordNet-based inferences over predicateswith corresponding argument mappings.We further present a concrete implementa-tion of this framework, which yields sub-stantial improvement to WordNet-basedinference.1 IntroductionWordNet (Miller, 1995), a manually constructedlexical database, is probably the mostly used re-source for lexical inference in NLP tasks, suchas Question Answering (QA), Information Extrac-tion (IE), Information Retrieval and Textual En-tailment (RTE) (Moldovan and Mihalcea, 2000;Pasca and Harabagiu, 2001; Bar-Haim et al, 2006;Giampiccolo et al, 2007).Inference using WordNet typically involves lex-ical substitutions for words in text based onWordNet relations, a process known as lexicalchains (Barzilay and Elhadad, 1997; Moldovanand Novischi, 2002).
For example, the an-swer to ?From which country was Louisiana ac-quired??
can be inferred from ?The UnitedStates bought up Louisiana from France?
using thechains ?France ?
European country ?
country?and ?buy up?
buy?
acquire?.When performing inference between predicatesthere is an additional complexity on top of lex-ical substitution: the syntactic relationship be-tween the predicate and its arguments may changeas well.
For example, ?X buy Y for Z ?X pay Z for Y ?.Currently, argument mappings are not specifiedfor WordNet?s relations.
Therefore, correct Word-Net inference chains over predicates can be per-formed only for substitution relations (mainly syn-onyms and hypernyms, e.g.
?buy?
acquire?
), forwhich argument positions do not change.
Otherrelation types that may be used for inference can-not be utilized when the predicate arguments needto be traced as well.
Examples include the Word-Net ?entailment?
relation (e.g.
?buy ?
pay?)
andrelations between morphologically derived words(e.g.
?acquire?
acquisition?
).Our goal is to obtain argument mappings forWordNet relations that are often used for infer-ence.
In this paper we address several prominentWordNet relations, including verb-noun deriva-tions and the verb-verb ?entailment?
and ?cause?relations, referred henceforth as inferential rela-tions.
Under the Textual Entailment paradigm,all these relations can be viewed as express-ing entailment.
Accordingly, we propose anovel framework, called Argument-mapped Word-Net (AmWN), that represents argument map-pings for inferential relations as entailment rules.These rules are augmented with subcategorizationframes and functional roles, which are proposedas a generally-needed extension for predicative en-tailment rules.Following our new representation scheme, wepresent a concrete implementation of AmWN fora large number of WordNet?s relations.
The map-pings for these relations are populated by com-bining information from manual and corpus-basedresources, which provides broader coverage com-pared to prior work and more accurate mappings.Table 1 shows typical inference chains obtained27Rule Chainsshopping:n ofXobj?
buying:n ofXobj?
buy:vXobj?
pay:v forXmodvote:v onXmod?
decide:v onXmod?
debate:vXobjXobj?s sentence:n ?
condemn:vXobj?
convict:vXobj?Xobj?s conviction:nXind?obj?s teacher:n ?
teach:v toXind?obj?Xsubjlearn:vTable 1: Examples for inference chains obtained using AmWN.
Arguments are subscripted with func-tional roles, e.g.
subject (subj) and indirect-object (ind-obj).
For brevity, predicate frames are omitted.using our implementation.To further improve WordNet-based inferencefor NLP applications, we address the phenom-ena of rare WordNet senses.
Rules generated forsuch senses might hurt inference accuracy sincethey are often applied incorrectly to texts whenmatched against inappropriate, but more frequentsenses of the rule words.
Since word sense disam-biguation (WSD) solutions are typically not suf-ficiently robust yet, most applications do not cur-rently apply WSD methods.
Hence, we proposeto optionally filter out such rules using a novelcorpus-based validation algorithm.We tested both WordNet and AmWN on a testset derived from a standard IE benchmark.
Theresults show that AmWN substantially improvesWordNet-based inference in terms of both recalland precision1.2 Argument-Mapping Entailment RulesIn our framework we represent argument map-pings for inferential relations between predicatesthrough an extension of entailment rules over syn-tactic representations.
As defined in earlier works,an entailment rule specifies an inference rela-tion between an entailing template and an en-tailed template, where templates are parse sub-trees with argument variables (Szpektor and Da-gan, 2008).
For example, ?Xsubj???
buyobj???
Y?
?Xsubj???
payprep?for???????
Y ?.When a rule is applied to a text, a new conse-quent is inferred by instantiating the entailed tem-plate variables with the argument instantiations ofthe entailing template in the text.
In our example,?IBM paid for Cognos?
can be inferred from ?IBMbought Cognos?.
This way, the syntactic structureof the rule templates specifies the required argu-ment positions for correct argument mapping.However, representing entailment rule structureonly by syntactic argument positions is insufficientfor predicative rules.
Correct argument mapping1We plan to make our AmWN publicly available.depends also on the specific syntactic functionalroles of the arguments (subject, object etc.)
and onthe suitable subcategorization frame (frame) forthe predicate mention - a set of functional rolesthat a predicate may occur with.
For example,?X?s buyout ?
buy X?
is incorrectly applied to?IBM?s buyout of Cognos?
if roles are ignored,since ?IBM?
plays the subject role while X needsto be an object.Seeking to address this issue, we were inspiredby the Nomlex database (Macleod et al, 1998)(see Section 3.2.1) and explicitly specify argu-ment mapping for each frame and functional role.As in Nomlex, we avoid the use of semanticroles and stick to the syntactic level, augment-ing the representation of templates with: (a) asyntactic functional role for each argument; (b)the valid predicate frame for this template men-tions.
We note that such functional roles typicallycoincide with dependency relations of the verbalform.
A rule example is ?Xsubjbreak{intrans}?damage{trans}Xobj?2.
More examples are shownin Table 1.Unlike Nomlex records, our templates can bepartial: they may contain only some of the possi-ble predicate arguments, e.g.
?buy{trans}Xobj?,where the subject, included in the frame, is omit-ted.
Partial templates are necessary for matchingpredicate occurrences that include only some ofthe possible arguments, as in ?Cognos was boughtyesterday?.
Additionally, some resources, such asautomatic rule learning methods (Lin and Pantel,2001; Sekine, 2005), can provide only partial ar-gument information, and we would want to repre-sent such knowledge as well.In our framework we follow (Szpektor and Da-gan, 2008) and use only rules between unary tem-plates, containing a single argument.
Such tem-plates can describe any argument mapping by de-2Functional roles are denoted by subscripts of the argu-ments and frames by subscripts of the predicate.
We short-hand trans for transitive frame {subject, object} and intransfor intransitive {subject}.
For brevity, we will not show alltemplate information when examples are self explanatory.28composing templates with several arguments intounary ones, while preserving the specification ofthe subcategorization frame.To apply a rule, the entailing template must befirst matched in the text, which includes match-ing the template?s syntactic dependency structure,functional roles, and frame.
Such procedure re-quires texts to be annotated with these types of in-formation.
This can be reasonably performed withexisting tools and resources, as described for ourown text processing in Section 4.Explicitly matching frames and functional rolesin rules avoids incorrect rule applications.
For ex-ample, ?Xobj?s buyout?
buy Xobj?
would be ap-plied only to ?Cognos?s buyout by IBM?
follow-ing proper role annotation of the text, but not to?IBM?s buyout of Cognos?.
As another example,?Xsubjbreak{intrans}?
damage{trans}Xobj?would be applied only to the intransitive occur-rence of ?break?, e.g.
?The vase broke?, but notto ?John broke the vase?.Ambiguous cases may occur during annotation.For example, the role of ?John?
in ?John?s invita-tion was well intended?
could be either subject orobject.
Such recognized ambiguities should be leftunannotated, blocking incorrect rule application.3 Argument Mapping for WordNetFollowing our extension of entailment rules, wepresent Argument-mapped WordNet (AmWN), aframework for extendingWordNet?s inferential re-lations with argument mapping at the syntacticrepresentation level.3.1 Argument Mapping RepresentationThe AmWN structure follows that of WordNet: adirected graph whose nodes are WordNet synsetsand edges are relations between synsets.
Sincewe focus on entailment between predicates, weinclude only predicative synsets: all verb synsetsand noun synsets identified as predicates (see Sec-tion 3.2).
In addition, only WordNet relations thatcorrespond to some type of entailment are consid-ered, as detailed in Section 3.2.In our framework, different subcategorizationframes are treated as having different ?meanings?,since different frames may correspond to differ-ent entailment rules.
Each WordNet synset is splitinto several nodes, one for each of its frames.
Wetake frame descriptions for verbs from WordNet3.3We also tried using VerbNet (Kipper et al, 2000), with-Figure 1: A description of ?buy/purchase X ?pay for X?
as a mapping edge in AmWN.Since WordNet does not provide frames for nounpredicates, these are taken from Nomlex-plus (seeSection 3.2).There are two types of graph edges that rep-resent entailment rules between nodes: mappingedges and substitution edges.
Mapping edgesspecify entailment rules that require argumentmapping, where the entailing and entailed tem-plate predicates are replaced by synsets.
Thus, anedge represents all rules between entailing and en-tailed synset members, as in Figure 1.Substitution edges connect pairs of predicates,of the same part-of-speech, which preserve argu-ment positions in inference.
This is analogous tohow WordNet may be currently used for inferencevia the synonym and hypernym relations.
UnlikeWordNet, substitution edges in AmWN may con-nect only nodes that have the same subcategoriza-tion frame.AmWN is utilized by generating rule chains fora given input unary template.
First, starting nodesthat match the input predicate are selected.
Then,rules are generated by traversing either incomingor outgoing graph edges transitively, dependingon the entailment direction requested.
Specificsynset-ids, if known, may also be added to the in-put to constrain the relevant starting nodes for theinput predicate.
Table 1 shows examples of rulechains from AmWN.3.2 Argument Mapping PopulationAfter defining the AmWN representation, we nextdescribe our implementation of AmWN.
We firstpopulate the AmWN graph with substitution edgesfor WordNet?s hypernyms and synonyms (as selfedges), e.g.
?buy ?
purchase?
and ?buy ?
ac-quire?.
The following subsections describe howmapping edges are created based on various man-ual and corpus-based information resources.3.2.1 Nominalization RelationsThe relation between a verb and its nominaliza-tions, e.g.
between ?employ?
and ?employment?,out any current performance improvement.29:ORTH "employment":VERB "employ":VERB-SUBC ((NOM-NP:SUBJECT ((DET-POSS)(N-N-MOD)(PP :PVAL ("by"))):OBJECT ((DET-POSS)(PP :PVAL ("of")))Figure 2: Part of the employment Nomlex entry,describing the possible syntactic dependency posi-tions for each role of the transitive frame.
It states,for example, that the verbal ?object?
role can bemapped to employment either as a possessive or asthe complement of the preposition ?of?.is described in WordNet by the derivationally re-lated relation.
To add argument mappings forthese relations we utilize Nomlex-plus (Meyerset al, 2004), a database of around 5000 Englishnominalizations.
Nomlex specifies for each ver-bal subcategorization frame of each nominaliza-tion how its argument positions are mapped tofunctional roles of related verbs.For each Nomlex entry, we extract all possibleargument mappings between the verbal and nom-inal forms, as well as between different argumentrealizations of the noun.
For example, the map-pings ?Xobj?s employment ?
employ Xobj?
and?Xobj?s employment?
employment of Xobj?
arederived from the entry in Figure 2.The major challenge in integrating Nomlex andWordNet is to identify for each Nomlex nounwhich WordNet synsets describe its predicativemeanings.
For example, one synset of ?acquisi-tion?
that is derivationally related to ?acquire?
isnot predicative: ?an ability that has been acquiredby training?.
We mark noun synsets as predicativeif they are (transitive) hyponyms of the act high-level synset.Once predicative synsets are identified, we cre-ate, for each synset, a node for each subcate-gorization frame of its noun members, as foundin Nomlex-plus.
In some nodes not all originalsynset members are retained, since not all mem-bers share all their frames.
Mapping edges arethen added between nodes that have the sameframe.
We add both noun-verb edges and nounself-edges that map different realizations of thesame functional role (e.g.
?Xobj?s employment?employment of Xobj?
).As rich as Nomlex-plus is, it still does not in-clude all nominalizations.
For example, the nounsLexical Relation Extracted Mappingsbuy ?
paybuy forX ?
payXX buy ?X paydivorce ?
marrydivorce fromX ?
marryXdivorce fromX ?X marrykill ?
diekillX ?X diekill amongX ?X diebreathe ?
inhalebreatheX ?
inhaleXbreathe inX ?
inhaleXremind ?
rememberremindX ?X rememberremind ofX ?
rememberXteach ?
learnteachX ?
learnXteach toX ?X learngive ?
havegiveX ?
haveXgive toX ?X haveTable 2: Some argument mappings for WordNetverb-verb relations discovered by unary-DIRT.?divorce?
(related to the verb ?divorce?)
and ?strik-ing?
are missing.
WordNet has a much richer setof nominalizations that we would like to use.
Todo so, we inherit associated frames and argumentrealizations for each nominalization synset fromits closest hypernym that does appear in Nomlex.Thus, ?divorce?
inherits its information from ?sep-aration?
and ?striking?
inherits from ?hit?.
A by-product of this process is the automatic extensionof Nomlex-plus with 5100 new nominalization en-tries, based on the inherited information4.3.2.2 Verb-Verb RelationsThere are two inferential relations between verbsin WordNet that do not preserve argument posi-tions: cause and entailment.
Unlike for nomi-nalizations, there is no broad-coverage manual re-source of argument mapping for these relations.Hence, we turn to unsupervised approaches thatlearn entailment rules from corpus statistics.Many algorithms were proposed for learningentailment rules between templates from corpora(Lin and Pantel, 2001; Szpektor et al, 2004;Sekine, 2005), but typically with mediocre accu-racy.
However, we only search for rules betweenverbs for which WordNet aleady indicates the ex-istence of an entailment relation and are thus notaffected by rules that wrongly relate non-entailingverbs.
We acquired a rule-set containing the top300 rules for every unary template in the ReutersRCV1 corpus5by implementing the unary-DIRTalgorithm (Szpektor and Dagan, 2008), which wasshown to have relatively high recall compared toother algorithms.4We plan making this extension publicly available as well.5http://about.reuters.com/researchandstandards/corpus/30To extract argument mappings, we identify allAmWN node pairs whose synsets are related inWordNet by a cause or an entailment relation.For each pair, we look for unary-DIRT rules be-tween any pair of members in the entailing andentailed synsets.
For example, the synset {buy,purchase} entails {pay}, so we look for rules map-ping either ?buy?
pay?
or ?purchase?
pay?.
Ta-ble 2 presents examples for discovered mappings.While unary-DIRT rules are not annotated withfunctional roles, they can be derived straightfor-wardly from the verbal dependency relations avail-able in the rule?s templates.
The obtained rules arethen added to AmWN as mapping edges.We only search for rules that map a functionalrole in the frame of one verb to any role for theother verb.
Focusing on frame elements avoids ex-tracting mapping rules learned for adjuncts, whichtend to be of low precision.3.3 Rule FilteringIn preliminary analysis we found two phenomena,sense drifting and rare senses, which may reducethe effectiveness of AmWN-based inference evenif each graph edge by itself, taken out of context, iscorrect.
To address these phenomena within prac-tical inference we propose the following optionalmethods for rule filtering.Sense Drifting WordNet verbs typically havea more fine-grained set of synsets than their re-lated nominalizations.
There are cases where sev-eral verb synsets are related to the same nomi-nal synset.
Since entailment between a verb andits nominalization is bidirectional, all such verbsynsets would end up entailing each other via thenominal node.Alas, some of these connected verb synsets rep-resent quite different meanings, which results inincorrect inferences.
This problem, which we callsense drifting, is demonstrated in Figure 3.
To ad-dress it, we constrain each rule generation chainto include at most one verb-noun edge, which stillconnects the noun and verb hierarchies.Rare Senses Some word senses in WordNet arerare.
Thus, applying rules that correspond to suchsenses yields many incorrect inferences, sincethey are typically matched against other frequentsenses of the word.
Such a rule is ?have X ?
Xis born?, corresponding to a rare sense of ?have?.WSD is a possible solution for this problem.
How-ever, most state-of-the-art IE, QA and RTE sys-tems do not rely on WSD methods, which are cur-rently not sufficiently robust.To circumvent the rare sense problem, we in-stead filter out such rules.
Each AmWN rule isvalidated against our unary-DIRT rule-set, which,being corpus-based, contains mostly rules for fre-quent senses.
A rule is directly-validated if it isin the corpus-based rule-set, or if it is a nominal-verb rule which describes a reliable morpholog-ical change for a predicate.
The AmWN graph-path that generated each rule is automatically ex-amined.
A rule is considered valid if there is asequence of directly-validated intermediate rulesalong the path whose transitive chaining generatesthe rule.
Invalid rules are filtered out.To illustrate, suppose the rule ?a?
d?
was gen-erated by the chain ?a ?
b ?
c ?
d?.
It is validif there is a rule chain along the path that yields ?a?
d?, e.g.
{?a?
b?,?b?
c?,?c?
d?}
or {?a?
b?,?b?
d?
}, whose rules are all directly-validated.4 Experimental SetupWe follow here the experimental setup presentedin (Szpektor and Dagan, 2008), testing the gener-ated rules on the ACE 2005 event dataset6.
Thisstandard IE benchmark includes 33 types of eventpredicates such as Injure, Sue and Divorce7.
TheACE guidelines specify for each event its possi-ble arguments.
For example, some of the Injureevent arguments are Agent and Victim.
All eventmentions, including their instantiated arguments,are annotated in a corpus collected from varioussources (newswire articles, blogs, etc.
).To utilize the ACE dataset for evaluating ruleapplications, each ACE event predicate was rep-resented by a set of unary seed templates, one foreach event argument.
Example seed templates forInjure are ?A injure?
and ?injure V ?.
Each event ar-gument is mapped to the corresponding seed tem-plate variable, e.g.
?Agent?
to A and ?Victim?
to Vin the above example.We manually annotated each seed template witha subcategorization frame and an argument func-tional role, e.g.
?injure{trans}Vobj?.
We also in-cluded relevant WordNet synset-ids, so only rulesfitting the target meaning of the event will be ex-tracted.
In this experiment, we focused only onthe core semantic arguments.
Adjuncts (time and6http://projects.ldc.upenn.edu/ace/7Only 26 frequent event types that correspond to a uniquepredicate were tested, following (Szpektor and Dagan, 2008).31Synset Members WordNet Gloss(verb) collar, nail, apprehend, arrest, pick up, nab, cop take into custodym(noun) apprehension, arrest, catch, collar, pinch, the act of apprehending (especially apprehendingtaking into custody a criminal)m(verb) get, catch, capture succeed in catching or seizing, especially after a chasem(noun) capture, seizure the act of taking of a person by forcem(verb) seize take or capture by force?
(hypernym)(verb) kidnap, nobble, abduct, snatch take away to an undisclosed location against their willand usually in order to extract a ransomFigure 3: A WordNet sense-drifting traversal, generating the incorrect inference ?kidnap?
arrest?.place) were ignored since they typically don?t re-quire argument mapping, the main target for ourassessment.The ACE corpus was dependency-parsed withMinipar (Lin, 1998) and annotated with functionalroles and frames for each predicate mention.
Thefunctional roles for a verb mention were taken di-rectly from the corresponding dependency tree re-lations.
Its frame was chosen to be the largestWordNet frame of that verb that matched the men-tion?s roles.Nominalization frames and functional rolesin the text were annotated using our extendedNomlex-plus database.
For each nominal mention,we found the largest Nomlex frame whose syntac-tic argument positions matched those of the men-tion?s arguments.
The arguments were then anno-tated with the specified roles of the chosen frame.Ambiguous cases, where the same argument posi-tion could match multiple roles, were left unanno-tated, as discussed in Section 2.Argument mentions for events were found inthe annotated corpus by matching either the seedtemplates or the templates entailing them in somerules.
The matching procedure follows the one de-scribed in Section 2.
Templates are matched us-ing a syntactic matcher that handles simple syn-tactic variations such as passive-form and con-junctions.
For example, ?wound{trans}Vobj?
injure{trans}Vobj?
was matched in the text?Hagelobjwas woundedtransin Vietnam?.
A ruleapplication is considered correct if the matched ar-gument is annotated in the corpus with the corre-sponding ACE role.We note that our system performance on theACE task as such is limited.
First, WordNet doesnot provide all types of needed rules.
Second, thesystem of our experimental setting is rather basic,with limited matching capabilities and without aWSD module.
However, this test-set is still veryuseful for relative comparison of WordNet and ourproposed AmWN.5 Results and AnalysisWe tested four different rule-set configurations:a) only the seed templates, without any rules; b)rules generated based on WordNet 3.0 without ar-gument mapping, using only synonym and hyper-nym relations; c) WordNet rules from (b), filteredusing our corpus-based validation method for raresenses; d) rules generated from our AmWN.Out of the 8953 non-substitutable inferential re-lations that we identified in WordNet, our AmWNimplementation created mapping edges for 75% of8325 Noun-Verb relations and 70% of 628 Verb-Verb relations.
Altogether 41549 mapping edgesbetween synset nodes were added.
A manual er-ror analysis of these mappings is provided in Sec-tion 5.2.Each configuration was evaluated for each ACEevent.
We measured the percentage of correct ar-gument mentions extracted out of all correct argu-ment mentions annotated for the event (recall) andout of all argument mentions extracted (precision),and F1, their harmonic average.
We report macroaverages over the 26 event types.5.1 ResultsTable 3 summarizes the results for the differentconfigurations.
As expected, matching only theseed templates yields the highest precision butlowest recall.
Using the standard WordNet config-uration actually decreases overall F1 performance.Though recall increases relatively by 30%, thanksto WordNet expansions, F1 is penalized by a sharp32Configuration R (%) P (%) F1No Rules 13.5 63.0 20.7WordNet 17.5 35.3 18.5WordNet with rule validation 16.5 46.9 20.4AmWN 20.8 43.9 24.2Table 3: Recall (R), Precision (P) and F1 resultsfor the different tested configurations.relative drop in precision (by 56%).
The main rea-son for this decline is the application of rules in-volving infrequent word senses, as elaborated inSection 3.3.When our rule validation approach is appliedto standard WordNet expansions, a much higherprecision is achieved with only a small decline inrecall.
This shows that our corpus-based filteringmethod manages to avoid many of the noisy rulesfor rare senses, while maintaining those that arefrequently involved in inference.Finally, our main result shows that adding ar-gument mapping improves performance substan-tially.
AmWN achieves a much higher recallthan WordNet.
Recall increases relatively by 26%over validated WordNet, and by 54% over theno-rules baseline.
Furthermore, precision dropsonly slightly, by 6%, compared to validated Word-Net.
This shows that argument mapping increasesWordNet?s graph connectivity, while our rule-validation method maintains almost the same pre-cision for many more generated rules.
The im-provement in overall F1 performance is statisti-cally significant compared to all other configura-tions, according to the two-sided Wilcoxon signedrank test at the level of 0.01 (Wilcoxon, 1945).5.2 Error AnalysisWe manually analyzed the reasons for false pos-itives (incorrect extractions) and false negatives(missed extractions) of AmWN by sampling 300extractions of each type.From the false positives analysis (Table 4) wesee that practically all generated rules are correct(99.4%), that is, they would be valid in some con-texts.
Almost all errors come frommatching errors(including parse errors) and context mismatches,due to our limited IE implementation.
The onlytwo incorrect rules sampled were due to an in-correct Nomlex entry and a WordNet synset thatshould have been split into two separate senses.Considering that correct extractions resulted, perour analysis, from correct rules, the analysis of thisReason % mentionsContext mismatch 57.2Match error 33.6Errors in gold-standard annotation 8.6Incorrect Rule learned 0.6Table 4: Distribution of reasons for false positives(incorrect argument extractions).Reason % mentionsRule not learned 67.7Match error 18.0Discourse analysis needed 12.0Argument is predicative 1.3Errors in gold-standard annotation 1.0Table 5: Distribution of reasons for false negatives(missed argument mentions).sample indicates that virtually all AmWN edgesthat get utilized in practice are correct.Context mismatches, which constitute the ma-jority of errors (57.2%), occur when the entail-ing template of a rule is matched in inappropriatecontexts.
This occurs typically when the match isagainst another sense of the predicate, or when anargument is not of the requested type (e.g.
?TheEnron sentence?
vs. ?A one month sentence?).
Infuture work, we plan to address this problem byutilizing context-sensitive application of rules inthe spirit of (Szpektor et al, 2008).Table 5 presents the false negatives analysis.Most missed extractions are due to rules that werenot learned (67.7%).
These mainly involve com-plex templates (?file a lawsuit ?
sue?)
and infer-ence rules that are not synonyms/hypernyms (?ex-ecute ?
sentence?
), which are not widely anno-tated inWordNet.
From further analysis, we foundthat 10% of these misses are due to rules that aregenerated from AmWN but filtered out by one ofour filtering methods (Section 3.3).12% of the arguments cannot be extracted byrules alone, due to required discourse analysis,while 18% of the mentions were missed due to in-correct syntactic matching.
By assuming correctmatches in these cases and avoiding rule filtering,we can estimate the upper bound recall of the rule-set for the ACE dataset to be 40%.In conclusion, for better performance the sys-tem should be augmented with context modelingand better template matching.
Additionally, otherrule-bases, e.g.
DIRT (Lin and Pantel, 2001),should be added to increase rule coverage.33Configuration R (%) P (%) F1AmWN 20.8 43.9 24.2No nominalization mappings 18.1 45.5 21.8No verb-verb mappings 19.3 43.8 22.8No rule validation 22.0 30.4 20.9No sense drift blocking 22.5 37.4 21.7Table 6: The Recall (R), Precision (P) and F1 re-sults for ablation tests.5.3 Component AnalysisTable 6 presents ablations tests that assess themarginal contribution of each AmWN component.Nominal-verb and verb-verb mappings contributeto the graph connectivity, hence the recall reduc-tion when they are removed.Complementary to recall components, rule fil-tering improves precision.
When removing thecorpus-based rule-validation, recall increases rel-atively by 6% but precision drops relatively by30%, showing the benefit of noisy-rule filtering.Allowing sense drifting hurts precision, a rela-tive drop of 22%.
Yet, recall increases relativelyby 8%, indicating that some verb synsets, con-nected via a shared nominal, entail each other eventhough they are not connected directly.
For exam-ple, ?foundX?
createX?
was generated only viathe shared nominal ?founding?.
In future work, weplan to apply AmWN to a coarse-grained set ofWordNet synsets (Palmer et al, 2007) as a possi-ble solution to sense drifting.6 Related WorkSeveral works attempt to extend WordNet with ad-ditional lexical semantic information (Moldovanand Rus, 2001; Snow et al, 2006; Suchanek et al,2007; Clark et al, 2008).
However, the only pre-vious work we are aware of that enriches Word-Net with argument mappings is (Novischi andMoldovan, 2006).
This work utilizes VerbNet?ssubcategorization frames to identify possible verbarguments.
Argument mapping is provided onlybetween verbs, ignoring relations between verbsand nouns.
Arguments are mapped based on the-matic role names shared between frames of dif-ferent verbs.
However, the semantic interpretationof thematic roles is generally inconsistent acrossverbs (Lowe et al, 1997; Kaisser and Webber,2007).
Instead, we discover these mappings fromcorpus statistics, offering an accurate approach (asanalyzed in Section 5.2).A frame semantics approach for argumentmapping between predicates is proposed by theFrameNet project (Baker et al, 1998).
Currently,FrameNet is the only resource for frame-semanticargument mappings.
However, it is manually con-structed and currently covers much less predi-cates and relations than WordNet.
Furthermore,frame-semantic parsers are less robust than syntac-tic parsers, presently hindering the utilization ofthis approach in applications (Burchardt and Pen-nacchiotti, 2008).Nomlex argument mapping patterns similar toours were derived for IE in (Meyers et al, 1998),but they were not integrated with any additionalinformation, such as WordNet.7 ConclusionsWe presented Argument-mapped WordNet(AmWN), a novel framework for augment-ing WordNet with argument mappings at thesyntactic representation level.
With AmWN,non-substitutable WordNet relations can alsobe utilized correctly, increasing the coverage ofWordNet-based inference.
The standard entail-ment rule representation is augmented in ourwork with functional roles and subcategorizationframes, shown to be a feasible extension neededfor correct rule application in general.Our implementation of AmWN populatesWordNet with mappings based on combiningmanual and corpus-based resources.
It covers abroader range of relations compared to prior workand yields more accurate mappings.
We also in-troduced a novel corpus-based validation mecha-nism, avoiding rules for infrequent senses.
Ourexperiments show that AmWN substantially im-proves standard WordNet-based inference.In future work we plan to add mappings be-tween verbs and adjectives and between differentframes of a verb.
We also want to incorporateresources for additional subcategorization frames,such as VerbNet.
Finally, we plan to enhance ourtext annotation based on noun-compound disam-biguation (Lapata and Lascarides, 2003).AcknowledgementsThis work was partially supported by the NEGEVproject (www.negev-initiative.org), the PASCAL-2 Network of Excellence of the European Commu-nity FP7-ICT-2007-1-216886, the FBK-irst/Bar-Ilan University collaboration and the Israel Sci-ence Foundation grant 1112/08.34ReferencesCollin F. Baker, Charles J. Fillmore, and John B. Lowe.1998.
The berkeley framenet project.
In Proceed-ings of ACL.Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro,Danilo Giampiccolo, Bernardo Magnini, and IdanSzpektor.
2006.
The second pascal recognising tex-tual entailment challenge.
In Second PASCAL Chal-lenge Workshop for Recognizing Textual Entailment.Regina Barzilay and Michael Elhadad.
1997.
Usinglexical chains for text summarization.
In Proceed-ings of ACL.Aljoscha Burchardt and Marco Pennacchiotti.
2008.Fate: a framenet-annotated corpus for textual entail-ment.
In Proceedings of LREC.Peter Clark, Christiane Fellbaum, Jerry R. Hobbs, PhilHarrison, William R. Murray, and John Thompson.2008.
Augmenting WordNet for Deep Understand-ing of Text.
In Proceedings of STEP 2008.Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,and Bill Dolan.
2007.
The third pascal recogniz-ing textual entailment challenge.
In Proceedings ofthe ACL-PASCAL Workshop on Textual Entailmentand Paraphrasing.Michael Kaisser and Bonnie Webber.
2007.
Questionanswering based on semantic roles.
In ACL 2007Workshop on Deep Linguistic Processing.Karin Kipper, Hoa Trang Dang, and Martha Palmer.2000.
Class-based construction of a verb lexicon.In Proceedings of AAAI.Mirella Lapata and Alex Lascarides.
2003.
Detect-ing novel compounds: The role of distributional ev-idence.
In Proceedings of EACL.Dekang Lin and Patrick Pantel.
2001.
Discovery of in-ference rules for question answering.
Natural Lan-guage Engineering, 7(4):343?360.Dekang Lin.
1998.
Dependency-based evaluation ofminipar.
In Proceedings of the Workshop on Eval-uation of Parsing Systems at LREC 1998, Granada,Spain.John B. Lowe, Collin F. Baker, and Charles J. Fillmore.1997.
A frame-semantic approach to semantic an-notation.
In Proceedings of the SIGLEX Workshopon Tagging Text with Lexical Semantics: Why, What,and How?Catherine Macleod, Ralph Grishman, Adam Meyers,Leslie Barrett, and Ruth Reeves.
1998.
NOMLEX:A Lexicon of Nominalizations.
In Proceedings ofEURALEX.AdamsMeyers, CatherineMacleod, Roman Yangarber,Ralph Grishman, Leslie Barrett, and Ruth Reeves.1998.
Using nomlex to produce nominalization pat-terns for information extraction.
In Proceedings ofCOLING.Adam Meyers, Ruth Reeves, Catherine Macleod,Rachel Szekeley, Veronkia Zielinska, and BrianYoung.
2004.
The Cross-Breeding of Dictionaries.In Proceedings of LREC.George A. Miller.
1995.
Wordnet: A lexical databasefor english.
In Communications of the ACM.Dan Moldovan and Rada Mihalcea.
2000.
Usingwordnet and lexical operators to improve internetsearches.
IEEE Internet Computing, 4(1):34?43.Dan Moldovan and Adrian Novischi.
2002.
Lexicalchains for question answering.
In Proceedings ofCOLING.Dan Moldovan and Vasile Rus.
2001.
Logic formtransformation of wordnet and its applicability toquestion answering.
In Proceedings of ACL.Adrian Novischi and Dan Moldovan.
2006.
Questionanswering with lexical chains propagating verb ar-guments.
In Proceedings of ACL.Martha Palmer, Hoa Trang Dang, and ChristianeFellbaum.
2007.
Making fine-grained andcoarse-grained sense distinctions, both manuallyand automatically.
Natural Language Engineering,13(2):137?163.Marius Pasca and Sanda Harabagiu.
2001.
The in-formative role of wordnet in open-domain questionanswering.
In Proceedings of Workshop on WordNetand Other Lexical Resources: Applications, Exten-sions and Customizations.Satoshi Sekine.
2005.
Automatic paraphrase discoverybased on context and keywords between ne pairs.
InProceedings of IWP.Rion Snow, Daniel Jurafsky, and Andrew Y. Ng.
2006.Semantic taxonomy induction from heterogenousevidence.
In Proceedings of ACL.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
Yago: A core of semantic knowl-edge - unifying wordnet and wikipedia.
In Proceed-ings of WWW2007.Idan Szpektor and Ido Dagan.
2008.
Learning entail-ment rules for unary templates.
In Proceedings ofCOLING.Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-ture Coppola.
2004.
Scaling web based acquisitionof entailment patterns.
In Proceedings of EMNLP2004.Idan Szpektor, Ido Dagan, Roy Bar-Haim, and JacobGoldberger.
2008.
Contextual preferences.
In Pro-ceedings of ACL.Frank Wilcoxon.
1945.
Individual comparisons byranking methods.
Biometrics Bulletin, 1:80?83.35
