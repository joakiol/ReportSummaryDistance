Inheritance in Natural LanguageProcessingWalter DaelemansTilburg UniversityGerald GazdarUniversity of SussexKoenraad De Smedt*University of NijmegenIn this introduction to the special issues, we begin by outlining a concrete xample that indicatessome of the motivations leading to the widespread use of inheritance networks in computationallinguistics.
This example allows us to illustrate some of the formal choices that have to be madeby those who seek network solutions to natural anguage processing (NLP) problems.
We providesome pointers into the extensive body of Al knowledge r presentation publications that have beenconcerned with the theory of inheritance over the last dozen years or so.
We go on to identify thethree rather separate traditions that have led to the current work in NLP.
We then provide afairlycomprehensive lit rature survey of the use that computational linguists have made of inheritancenetworks over the last two decades, organized by reference tolevels of linguistic description.
Inthe course of this survey, we draw the reader's attention to each of the papers in these issues ofComputational Linguistics and set them in the context of related work.1.
IntroductionImagine that you are a linguistic innocent setting out on the job of building a computerlexicon for English.
You begin by encoding everything you know about the verb loveand then turn your attention to the verb hate.
Although they are antonyms, the majorityof properties that you have listed for love will show up again in your list for hate.
Yourfirst thought is to put this list of common properties into an editor macro to save youthe laborious task of typing them all in each time that you add another verb.
Butit soon becomes clear to you that adopting this strategy is going to lead to a hugerepresentation for your lexicon, and one that keeps saying the same thing again andagain.
Your second thought is to put the common property list in just one place and callit, say, TRANSITIVE VERB.
Then you amend what you have entered for love and hateso that all the common material is replaced by a notation that indicates that each is atransitive verb.
This works well and you add a couple of thousand more English verbswithout difficulty.
It is only when you reach elapse and expire that you find yourselflanded with the tedious task of again typing full lists of properties, since these twoverbs cannot be accurately represented by including a reference to the TRANSITIVEVERB property list.
Looking at the entries for these two anomalous verbs induces afeeling of d6ja vu.
They too have many properties in common, but just not exactlythe same set of common properties as hate and love and their siblings.
Following thestrategy that worked well before, you gather their common properties together andgive them the name INTRANSITIVE VERB, then you strip the duplicated material* University of Leiden, Psychology Department, P.O.
Box 9555, 2300 RB Leiden, The Netherlands.
(~) 1992 Association for Computational LinguisticsComputational Linguistics Volume 18, Number 2VERB<category> = verb<past par t i c ip le> ~ /e d/I <trans i t ive> : yes <trans i t |ve> = no<form = /1 o v e l  <form> = /h  a t e/ <ferm> = /e  t a p s e/  <form = /e  x p i r e/Figure 1Monotonic single inheritance.from the entries for elapse and expire and replace it with a notation that points to yourlist of intransitive verb properties.
As you inspect your handiwork, you notice that thelists of properties associated with TRANSITIVE VERB and INTRANSITIVE VERB nowexhibit exactly the kind of duplication that you first saw when you wrote down yourentries for love and hate.
Indeed, the number of their commonalities exceeds the numberof their differences.
Once again you decide to invoke the style of solution that you haveused before: you collect the common properties together, give the collection the nameVERB and then rework your formulation of TRANSITIVE VERB and INTRANSITIVEVERB so as to strip the shared material and replace it with a notation indicating thateach is an instance of VERB.Although you may not realize it, what you have done is build an inheritancenetwork to represent the information that you are including in your lexicon--see Fig-ure 1.
The root node of this network is VERB and it has two daughters, TRANSITIVEVERB and INTRANSITIVE VERB, which inherit all the properties associated with theroot.
Each of these two nodes has further daughters (Love, Elapse, etc.).
The latterinherit all the properties of VERB together with all the properties of their immediateparent.
These inherited properties are added to the properties listed as idiosyncraticto the lexical item itself (e.g., the property of being orthographically represented as/1 o v e/).
This very simple lexical network has a couple of characteristics that it isworth drawing attention to.
Firstly, each node has a single parent, and there is thusonly one path through which properties may be inherited.
A network of this kind ei-ther consists of a single tree of nodes, or of a set of (unconnected) trees of nodes, andwe will call such a network a single inheritance network.
1 Secondly, in describing ourexample, we have been assuming that each node inherits all the properties associated1 Two trees are unconnected if and only if they have no nodes in common.
For present purposes, a set ofunconnected trees can always be trivially converted into an equivalent single tree by adding a newroot for all the trees, but one that has no properties associated with it.206Walter Daelemans et al Inheritance in Natural Language Processingwith its parent node which, in logician's parlance, means that property inheritance ismonotonic.Neither single inheritance nor monotonicity is a necessary characteristic of inheri-tance networks.
Suppose you try to add Beat to the network we have been describing.The obvious thing to do is to insert it as a daughter of TRANSITIVE VERB.
But thisis likely to entail that your network will claim that the past participle is *beated.
Onepotential solution to this problem would be to define a node called EN TRANSITIVEVERB and attach Beat as a daughter to this.
However, this strategy simply pushes theproblem further up the inheritance tree: EN TRANSITIVE VERB cannot be a daugh-ter of the TRANSITIVE VERB node since it contains a property (past participle =/e n/) that is inconsistent with a property associated with the latter (past participle= /e d/).
Nor can our new node be attached as a daughter of VERB, for exactly thesame reason.
It seems, therefore, as if the new node may have to be defined whollyfrom scratch, duplicating all but one of the properties of TRANSITIVE VERB.
To avoidthis disagreeable conclusion, we might consider another potential solution in whichwe remove any reference to the past participle suffix at the level of the VERB node,and specify it instead at the level of that node's daughters.
At first sight, this appearsto be a most attractive option.
In fact, by adopting it, we have embarked on a slipperyslope that will result in our stripping VERB of almost all the properties canonicallyassociated with verbs.
For each property ou might expect it to have, if there is a sin-gle verb in English that is exceptional with respect to that property, then the propertycannot appear at the VERB node.
In the case of morphological properties, this is likelyto mean that "present participle =/ i  n g/"  is the only property that can be associatedwith the VERB node.
And, in the case of syntactic properties, it is likely to mean thatbanalities uch as "category =verb" will be all we are able to list.How are we to avoid these rather dismal alternatives?
There are (at least) twopossibilities.
One is to abandon single inheritance.
Suppose we reorganize our net-work so that TRANSITIVE VERB and INTRANSITIVE VERB only encode syntacticproperties of verbs.
We then introduce two further nodes, ED VERB and EN VERB,which only encode morphological properties.
Then we allow Beat to have both TRAN-SITIVE VERB and EN VERB as its parents.
A network of this kind can no longer berepresented as a tree (or set of unconnected trees) and is said to employ multiple in-heritance-see Figure 2.
Another possibility is to abandon monotonicity.
We leave Beatwhere we first attached it, under TRANSITIVE VERB in our original network, and weassociate the property "past participle =/e  n /"  with it.
If inheritance continues to beconstrued monotonically, then the network will make contradictory claims about thepast participle of Beat.
But if we adopt a nonmonotonic interpretation f inheritance,in which properties that are attached to a node take precedence over those that are in-herited from a parent, then no contradiction will arise.
Such nonmonotonic inheritanceis known as "default inheritance'--see Figure 3.Monotonic single inheritance networks are easy to build and easy to understand.
Ifone designs a notation for defining them, then it is straightforward to say what the se-mantics of that notation is: translation i to first order logic, for example, is quite trivial.Unfortunately, for the reasons hinted at in the example considered above, monotonicsingle inheritance networks are not really very well suited to the description of naturallanguages.
As a result, as we shall see below, most researchers who have employed in-heritance techniques in NLP have chosen to use either default inheritance or multipleinheritance or, very commonly, both.
Networks that employ default and/or multipleinheritance are also quite easy to build, but they are much less easy to understand.The combination of default and multiple inheritance is especially problematic: "de-spite a decade of study, with increasingly subtle examples and counterexamples being207Computational Linguistics Volume 18, Number 2j ER VERB<past participte> = /e n/.o,VERB J <category> = verb<transitive> = yes <past participte> = /e d/Hate<form> = /h e t eli lmmlmmmml l lmBeat<form> = /b ?
e t /1INTRANSITIVE VERB J<transitive> = noEtapse I<form> = /e t a ps  el iFigure 2Monotonic multiple inheritance.lBeat I <form> = /b e a t /<past participte> = /e n/,k,TRANSITIVE VERB<transitive> = yesHate<forl~ = /h a t e/I VERB I <category> = verb<past participle> = /e d/.o,1ELapse<form> = /e t e p e ellINTRANSITIVE VERB<transitive> = no1Figure 3Nonmonotonic single inheritance.Expi re<forr0> = /e x p i r el208Walter Daelemans et al Inheritance in Natural Language Processingconsidered, consensus has yet to emerge regarding the proper treatment of multipleinheritance with cancellations" (Selman and Levesque 1989, pp.
1140).
Unsurprisingly,the problem has given rise to a large, and growing, list of publications in the knowl-edge representation literature (see, e.g., Horty, Thomason, and Touretzky 1990, andreferences therein).
Almost all of this theoretical work has concerned itself with verysimple networks that are only able to say whether or not a monadic property holds of anode in the network.
Recently, however, Thomason and Touretzky (1991) have turnedtheir attention to the properties of more expressive networks, potentially capable ofencoding what would need to be encoded in any real NLP application.
Nonmonotonicinference more generally (i.e.
not just in networks) has been, arguably, the dominanttheoretical concern in the AI literature of the late 1980s (as measured, for example, bythe proportion of papers that have appeared on the topic in Artificial Intelligence overthe period).One of the key issues in the knowledge representation literature has been how todeal with the default inheritance of mutually contradictory information from two ormore parent nodes.
Most NLP researchers who have embraced multiple inheritancetechniques have chosen to avoid this issue by adopting one of two strategies.
On onestrategy, information is partitioned between parental nodes.
You can, for example,inherit morphological properties from node A and syntactic properties from node B,but no single property can be inherited from more than one parent node.
This is knownas "orthogonal inheritance."
One way of thinking of it is in terms of a set of disjointsingle inheritance networks layered on top of each other.
On another strategy, a givenproperty, or set of properties, may potentially be inherited from more than one parentnode, but the parents are ordered: the first parent in the ordering that is able to supplythe property wins, and contradiction is thus avoided.
We will refer to this strategy as"prioritized inheritance.
"The use of inheritance networks in current NLP comes from three rather separatetraditions.
The first is that of "semantic nets" in AI, which goes back to Quillian (1968)through Fahlman's (1979) NETL to the late 1980s monographs by Touretzky (1986) andEtherington (1988).
The second is that of data abstraction i  programming languages,which has led to (a) object-orientation in computer science with its notions of classesand inheritance as embodied in such languages as Smalltalk, Simula, Flavors, CLOSand C++, and (b) the use of type hierarchies, which have become widely seen inunification-oriented NLP since the appearance of Ait-Kaci (1984) and Cardelli (1984).Of necessity, the type hierarchy work in NLP has remained strictly monotonic.
Thethird is the notion of "markedness" in linguistics, which originates in the Prague Schoolphonology of the 1930s, reappears in the "generative phonology" of Chomsky andHalle (1968) and Hetzron's (1975) and Jackendoff's (1975) models of the lexicon, andshows up in syntax in the "feature specification defaults" of Gazdar, Klein, Pullum,and Sag (1985).
2 Unlike the other three traditions, the linguistic tradition does notembody a notion of inheritance per se.
But the issue of how to decide which operationstake precedence over others has been a continuing concern in the literature (see, e.g.,Pullum 1979, especially Section 1.4.1, and references therein).The consensus view, though largely unspoken, among computational linguists cur-rently working with default inheritance networks appears to be that nodes that areclose (or identical) to the root(s) of the network should be used to encode that whichis regular, "unmarked," and productive, and that distance from the root(s) shouldcorrelate with increasing irregularity, "markedness," and lack of productivity.
At the2 See Evans (1987), Gazdar (1987), and Shieber (1986a) on the various defaulty characteristics of GPSG.209Computational Linguistics Volume 18, Number 2very least, this is what emerges from their practice.
The differences between the cur-rent strands of NLP work in this area are partly philosophical (e.g., as to whetherpsycholinguistic data could or should be relevant o the structure of the network),partly methodological (e.g., as to whether networks hould be built in a formal lan-guage designed for the purpose or implemented in an existing computer language),partly technical (e.g., whether a negation operator is useful, or whether orthogonalnetworks are to be preferred to those using prioritized inheritance), and partly the-oretical (e.g., the trade-off between the semantic perspicuity of monotonic networksversus the expressiveness and concision of their nonmonotonic competitors).In the subsequent sections of this paper we will survey the use computationallinguists have made of inheritance networks over the last dozen years.
To organizethis chronologically (e.g.
by date of publication) would be to impose a wholly spurioussense of historical continuity on what has, in fact, been a fairly haphazard set of paralleldevelopments.
It is tempting to try to organize the discussion that follows by referenceto technical and formal parameters, but the area is just too young for that to be possiblewithout a great deal of rather arbitrary taxonomy.
So we have chosen to play safe andorganize the material by reference to levels of linguistic description.
This is not whollysatisfactory, since a significant number of the approaches we discuss have been appliedto several different levels of description, which means that we have to refer to themin more than one section.
But we hope that readers will bear with us.2.
Syntax and MorphologyOne of the earliest applications of inheritance to syntax was Bobrow and Webber's(1980a,b) use of PSI-KLONE (a variant of KL-ONE) to encode ATNs.
In the contextof RUS, a system for natural language parsing and interpretation, inheritance wasused to organize linguistic knowledge fficiently in terms of grammatical categories.This frame-based representation was used by a process called incremental descriptionrefinement, which first determined which descriptions were compatible with an objectknown to have a set of properties, and then refined this set of descriptions as moreproperties become known.
Subsequent work by Brachman and Schmolze (1985) usedPSI-KLONE to translate the ouput of the RUS parser into KL-ONE representations ofliteral meaning.
An inheritance network that the authors refer to as a "syntaxonomy"is used to encode information about syntactic ategories.A rather similar view of language processing is to be found in the ConceptualGrammar of Steels (1978) and Steels and De Smedt (1983).
This approach adopteda single frame-based grammar epresentation for a variety of language processingtasks and for all types of linguistic knowledge.
General inference mechanisms basedon constraint propagation used the frames, organized in inheritance hierarchies, ingeneration and parsing.
De Smedt (1984) went on to use generic function application toprovide one of the earliest illustrations of the descriptive power of default inheritancenetworks for morphology in a treatment of Dutch verbs, an analysis that is extendedto adjectival and nominal forms in De Smedt and de Graaf (1990).
In the same paper,the authors indicate how inheritance techniques can be applied to a unification-basedformalism called Segment Grammar (Kempen 1987), which is intended to facilitateincremental syntactic processing.Attempts to reconcile inheritance with unification grammars began in the mid-1980s.
Shieber (1986b, p. 57ff) noted that the provision of lexical "templates" in PATRamounted to a language for defining monotonic multiple inheritance networks.
Hedrew attention to the possibility of adding a nonmonotonic "overwriting" operation toPATR and commented that "the cost of such a move is great, however, because the use210Walter Daelemans et al Inheritance in Natural Language Processingof overwriting eliminates the order independence that is so advantageous a propertyin a formalism" (1986, p. 60).
In a subsequent implementation of PATR, Karttunen(1986) makes all D-PATR templates ubject o overwriting.
The very similar notion of"priority union" is introduced in the context of LFG by Kaplan (1987, p. 180).
Theseideas are developed by Bouma (this issue) who gives a definition of default unificationon the basis of a logic for features.Kameyama (1988) uses PATR-style templates to build a multiple inheritance mul-tilingual lexicon to support Categorial Unification Grammar descriptions of Arabic,English, French, German, and Japanese nominals.
Although the system described ismonotonic, there is a footnote suggesting a move toward a default inheritance systemto deal with marked constituent orders (p. 202, nl0).Of all the unification-based grammar formalisms, it is HPSG which has thus far ledto the greatest use of inheritance networks, both default and monotonic.
Flickinger, Pol-lard, and Wasow (1985) proposed a treatment of lexical organization in which Englishsubcategorization frames and inflectional morphology were handled within a defaultmultiple inheritance network implemented in HPRL.
They pointed out that such anapproach took care of morphological "blocking" phenomena "largely for free" (1985,p.
267).
3 In his 1987 Ph.D. dissertation, Flickinger goes on to provide a monographlength inheritance treatment of the syntactic and morphological information embod-ied in the English lexicon.
His analysis crucially presupposes machinery for multipledefault inheritance.
Like Shieber (1986b, pp.
60-61), he notes the problem that contra-dictory attribute values pose for such machinery and entertains the hypothesis thatthe relevant links "should be disjoint in the set of attributes for which they supportinheritance" (1987, p. 61).
Flickinger's thesis is probably the most detailed discursiveapplication of a default inheritance framework to the lexicon.
In their paper in thepresent issue, Flickinger and Nerbonne (in press) extend the analysis further still soas to encompass some of the trickiest and most-debated data in the syntax of English.Pollard and Sag (1987), in the first book-length presentation of HPSG, treat thelexicon as a monotonic multiple-inheritance type hierarchy.
They implicitly reject theuse of an "overriding mechanism" (p. 194, n4) in favor of a variety of restrictionsdesigned to prevent overgeneration, together with a nonmonotonic formulation oflexical rules (pp.
212-213).
A concern to preserve monotonic inheritance in HPSG islikewise evident in more recent work, such as Carpenter and Pollard (1991) and Zajac(this issue).Monotonic multiple inheritance type hierarchies figure in a good deal of recentwork in unification-based grammars.
Examples include papers by Porter (1987), Emeleand Zajac (1990), and Emele et al (1990), who all use a semantics based on Ait-Kaci(1984); the use of sorts in Unification Categorial Grammar (Moens et al 1989); the CLEproject (Alshawi et al 1989) and theoretical work by Smolka (1988).Default multiple inheritance also figures centrally in a couple of grammaticalframeworks.
One is Hudson's (1984, 1990) Word Grammar, and a detailed expositionis provided by Fraser and Hudson in this issue.
Word Grammar is a feature-basedvariant of dependency grammar, one that makes pervasive use of a (multiple) inheri-tance relation.
The latter is unusual in that stipulated exceptions do not automaticallyoverride an inherited default: the latter has to be explicitly negated if the grammarrequires its suppression (compare Flickinger, Pollard, and Wasow's (1985) approach to"blocking," noted above).3 The existence ofan irregular form typically means that he corresponding regular form is not apermissible option.
This is known as "blocking.
"211Computational Linguistics Volume 18, Number 2The other is ELU (Russell et al in press), which extends a PATR-like grammarformalism with a language for defining default multiple inheritance networks forthe lexicon.
Inspired by CLOS, an object-oriented extension of Common LISP, theyadopt prioritized inheritance to escape the problem caused by conflicting inheritedinformation.
Russell et al (in press) illustrate their approach with ELU analyses ofEnglish and German verbal morphology.Evans and Gazdar (1989a) outline the syntax and theory of inference for DATR, alanguage for lexical knowledge representation, and (1989b) they provide a semanticsfor the language that is loosely based on the approach taken by Moore (1985) inhis semantics for autoepistemic logic.
DATR allows multiple default inheritance butenforces orthogonality.
Evans et al (in press) show how DATR can also be used toencode certain kinds of prioritized inheritance.
Unlike ELU and the Word Grammarnotation, DATR is not intended to be a full grammar formalism.
Rather, it is intendedto be a lexical formalism that can be used with any grammar that can be encoded interms of attributes and values.
Kilbury et al (1991) show how a DATR lexicon can belinked to a PATR syntax, while Andry et al (in press) employ a DATR lexicon in thecontext of a Unification Categorial Grammar.
The use of DATR to describe morphologyis illustrated, for Latin, by Gazdar (in press) and in the fragments of Arabic, English,German, and Japanese included in Evans and Gazdar (1990).All of our discussion thus far has presupposed the use of inheritance networksto store essentially static information.
But, following the precedent set by Brachmanand Schmolze (1985), a number of researchers have begun to explore their utility inlanguage processing itself.
Thus, for example, van der Linden (this issue) exploits thestructure of the network in order to avoid premature lexical disambiguation and toidentify lexical preferences during incremental parsing with a Lambek categorial gram-mar.
And Vogel and Popowich (1990) add a new twist to the now familiar "parsingas deduction" strategy: instead of construing parsing as, for example, inference in aHorn clause logic, they describe an HPSG parser that operates by means of path-basedinference over an inheritance network.3.
Phonology, Orthography, and MorphophonologyComputational phonology is perhaps the youngest and least studied branch of NLP.But notions of default have played such a prominent role in linguistic discussion ofthe area that it is not surprising that default inheritance networks have found a placein this subfield right from the start.Thus Gibbon and Reinhard have made extensive use of DATR networks to de-scribe lexical morphophonological phenomena such as German umlaut, Kikuyu tone,and Arabic vowel intercalation (Gibbon 1990b, in press; Reinhard 1990; Reinhard andGibbon 1991).
And Daelemans (1987a,b, 1988) uses the object-oriented knowledge rep-resentation language KRS to implement default orthogonal inheritance networks forthe lexical representation f phonological, orthographic, and morphological knowledgeof Dutch and shows how such a lexicon architecture can be used for both languagegeneration and automatic dictionary construction.
The work of Calder (1989) and hisassociates at Edinburgh and Stuttgart on "paradigmatic morphology" also fits withinthis tradition in that it invokes a restricted kind of default orthogonal inheritance formorphophonological description.
However, the emphasis in this work is on the use ofstring unification to define morphological operations rather than on the default struc-ture of the lexicon per se.
In subsequent work, Calder and Bird (1991) use a general212Walter Daelernans et al Inheritance in Natural Language Processingnonmonotonic logic to give a formal reconstruction of "underspecification phonology"(Archangeli 1988).
44.
Semantics and PragmaticsGiven that knowledge representation was principally driven by nat-ural language concerns right up to the beginning of the decade, onewould have expected substantial progress to have been made in the1980s on knowledge representation support for natural anguage se-mantics.
This seems not to have been the case (Brachman 1990; p. 1088).If one compares the progress made in morphology and syntax in NLP in the 1980s,then Brachman's judgment is surely correct.
And yet there has been a steady traditionof using semantic networks in the service of natural language understanding thatgoes back at least as far as Simmons (1973).
Much of the work in this tradition hasconcerned itself with domain and world knowledge relevant o disambiguation andto drawing inferences from what is said, but not to the semantic representations ofwords, phrases and utterances per se.
Exceptions to this generalization are not hardto find, however.For example, Barnett et al (1990) use the same language (CycL) for linguisticsemantic representation as is used in the encyclopedic nheritance network for whichthey are providing a natural language interface.
And Jacobs (1986, 1987) proposes auniform hierarchical encoding of both linguistic and conceptual knowledge in a frame-based formalism called ACE.
Jacobs then uses the resulting inheritance network togive an account of metaphor, inter alia.
By contrast, Allgayer et al (1989) employ twoseparate inheritance networks, one for linguistic semantic knowledge and the otherfor conceptual knowledge, both being implemented in a KL-ONE derivative calledSB-ONE.Several of the inheritance-based linguistic knowledge representation formalismsthat we have introduced in earlier sections are being used for semantic purposes.
ThusFraser and Hudson (this issue) make crucial use of the Word Grammar inheritancenetwork to reconstruct the meanings of various types of constituent (e.g.
verb phrases)that cannot be syntactically reconstructed in a dependency grammar.
Weischedel (1989)uses the taxonomic language NKL (based on KL-ONE) to express electional restric-tions, while Andry et al (in press) use DATR for the same purpose.
Cahill and Evans(1990) use DATR to build up complex lambda calculus representations in the lexi-con of a message understanding system.
Briscoe et al (1990) use a version of PATRaugmented with defeasible templates to implement a default orthogonal inheritancenetwork for a Pustejovskian analysis of metonymic sense extension in lexical seman-tics (e.g.
interpreting the film in Enjoy the film!
as watching the film).
5 Their approach isfurther elaborated in Briscoe and Copestake (1991) and Copestake and Briscoe (1991).A semantic analog of the monotonic type hierarchies discussed above in connectionwith syntax is manifested in the situation theoretic "infon lattices" introduced byKameyama et al (1991) to deal with meaning mismatches in machine translation.The use of inheritance networks for specifically linguistic pragmatic purposes (asopposed to general reasoning) is notable largely for its absence.
The only example weknow of is Etherington et al's (1989) proposal to represent the consequences of Gricean4 Compare Gibbon's (1990a) use of DATR to the same end.5 See Pustejovsky (1989, 1991).213Computational Linguistics Volume 18, Number 2maxims in a default inheritance network designed for fast (though not necessarilycorrect) reasoning.Most recent computational linguistic work on pragmatics has tended to turn togeneral nonstandard logics as tools for the job, rather than their less expressive networkrelations.
Thus Joshi et al (1984) and Lascarides and Asher (1991) have made the casefor nonmonotonic logics in formalizing Gricean maxims, while Schubert and Hwang(1989) show how a probabilistic logic might be Used in story understanding.
Mercerand Reiter (1982) and Mercer (1988) have employed Reiter's default logic to capturethe behavior of natural anguage presuppositions.
Perrault (1990) uses default logic toexpress a theory of speech acts, while Appelt and Konolige (1988) have deployed anextension to Moore's (1985) autoepistemic logic for the same purpose.5.
Concluding RemarksWithin computational linguistics, it is possible to see three distinct trends emerging.The first is the increasing employment of monotonic type lattices in unification~basedgrammars to constrain the space of permissible descriptions.
The second is the useof a variety of general nonmonotonic logics for formalizing pragmatic omponentsof NLP systems.
And the third is the development of a variety of restricted efaultinheritance languages designed for the representation f phonological, morphological,syntactic, and compositional semantic properties of lexemes.This last trend is partly driven by descriptive linguistic considerations (e.g.
captur-ing linguistically significant generalizations) and partly by considerations of softwareengineering.
The latter are somewhat analogous to the considerations that have encour-aged the spread of object-orientation in computer science and include (i) parsimony--inheritance lexicons can be made one or two orders of magnitude smaller than theirfull-entry counterparts; (ii) ease of maintenance changes or corrections will typicallyonly need to be made in one or two nodes, not in thousands of individual entries; (iii)uniformity--several levels of linguistic description can be encoded in the same wayand be made subject o the same rules of inference; (iv) modularity--multiple inheri-tance allows different axonomies to apply for different levels of description; and (v)interaction--where a lexical property at one level of description (e.g.
syntactic gender)depends on a lexical property at another level of description (e.g.
the phonology of aword-final vowel), then this can be stated.The work that has been done to date suggests that while default inheritance isessential for lexical networks, full unrestricted multiple inheritance is probably moreof a hindrance than a help.
It looks as if some version of orthogonal or prioritizedinheritance will be sufficient for lexical knowledge representation.
Moore and Kaplan(in Whitelock et al 1987, pp.
62-63) have noted that lexical defaults amount to de-fault specification (as opposed to the conjectural defaults of standard AI knowledgerepresentation) and that they often substitute for (large) finite specifications.
Likewise,Thomason (1991) has referred to lexical defaults as "a priori in a sense" or "at leaststipulative or conventional" and he goes on to point out that any nonmonotonic lexicalapplication can be converted to a monotonic one, albeit at the cost of scale.
These con-siderations provide some limited grounds for optimism with regard to the tractabilityand mathematical probity of (future) languages for lexical representation.
However,two cautionary notes are in order: firstly, the inheritance relation itself is not the solesource of intractability, and, secondly, existing work on inheritance lexicons has beenalmost wholly based on familiar European languages.214Walter Daelemans et al Inheritance in Natural Language ProcessingAcknowledgmentsWe are grateful to Rich Thomason forrelevant conversation and comments.ReferencesAit-Kaci, Hassan (1984).
A Lattice-TheoreticApproach to Computation Based on a Calculusof Partially Ordered Types.
Doctoraldissertation, University of Pennsylvania,Philadelphia, PA.Allgayer, J6rgen; Jansen-Winkeln, Roman;Reddig, Carola; and Reithinger, Norbert(1989).
"Bidirectional use of knowledge inthe multi-modal NL access ystemXTRA," IJCAI-89, 1492-1497.Alshawi, Hiyan; Carter, David; van Eijck,Johan; Moore, Robert; Moran, Douglas;Pereira, Fernando; Pulman, Stephen; andSmith, Arnold (1989).
"Final Report: CoreLanguage Engine," Technical Report,Project No.
2989, SRI, Cambridge.Andry, Francois; Fraser, Norman M.;McGlashan, Scott; Thornton, Simon; andYoud, Nick (1991).
"Making DATR workfor speech: Lexicon compilation iSUNDIAL," Computational Linguistics,18, 3.Appelt, Douglas, and Konolige, Kurt (1988).
"A practical nonmonotonic theory ofspeech acts."
In ACL Proceedings, 26thAnnual Meeting, 170-178.Archangeli, D. (1988).
"Aspects ofunderspecification theory," Phonology, 5,183-207.Barnett, Jim; Knight, Kevin; Mani, Inderjeet;and Rich, Elaine (1990).
"Knowledge andnatural language processing,"Communications of the ACM, 33, 8, 50-71.Bobrow, Robert J., and Webber, Bonnie Lynn(1980a).
"PSI-KLONE," Third BiennialConference ofthe CSCSI/SCEIO, 131-142.Bobrow, Robert J., and Webber, Bonnie Lynn(1980b).
"Knowledge representation forsyntactic/semantic processing," AAAI-80,316-323.Bouma, Gosse (1992).
"Feature structuresand nonmonotonicity," ComputationalLinguistics, 18(2), 183-203.Brachman, Ronald J.
(1990).
"The future ofknowledge representation," AAAI-90,1082-1092.Brachman, Ronald J., and Schmolze, JamesG.
(1985).
"An overview of the KL-ONEknowledge representation system,"Cognitive Science, 9, 191-216.Briscoe, Ted; Copestake, Ann; andBoguraev, Bran (1990).
"Enjoy the paper:Lexical semantics via lexicology."
InCOLING-90, 42-47.Briscoe, Ted, and Copestake, Ann (1991).
"Sense xtensions as lexical rules."
InProceedings ofthe IJCAI Workshop onComputational Approaches toNon-LiteralLanguage.
Sydney.Cahill, Lynne, and Evans, Roger (1990).
"Anapplication of DATR: the TIC lexicon,"ECAI-90, 120-125.Calder, Jo (1989).
"Paradigmaticmorphology."
In ACL Proceedings, FourthEuropean Conference, 58-65.Calder, Jo, and Bird, Steven (1991).
"Defaultsin underspecification phonology."
InDefault Logics for Linguistic Analysis, editedby Hans Kamp, 129-139, DYANA,ESPRIT deliverable R2.5.B, Edinburgh.Cardelli, Luca (1984).
"A semantics ofmultiple inheritance."
In Semantics of DataTypes, edited by G. Kahn, D. B. McQueen,and G. Plotkin, 51-67.
New York:Springer.Carpenter, Bob, and Pollard, Carl (1991)"Inclusion, disjointness, and choice: Thelogic of linguistic lassification."
In ACLProceedings, 29th Annual Meeting, 9-16.Chomsky, Noam, and Halle, Morris (1968).The Sound Pattern of English.
New York:Harper and Row.Copestake, Ann, and Briscoe, Ted (1991).
"Lexical operations in a unification-basedframework."
In Proceedings, ACL-SIGLEXWorkshop on Lexical Semantics andKnowledge Representation, Berkeley,188-197.Daelemans, Walter M. P. (1987a).
"A tool forthe automatic creation, extension andupdating of lexical knowledge bases."
InACL Proceedings, 3rd European Conference,70-74.Daelemans, Walter M. P. (1987b).
Studies inlanguage technology: An object-orientedcomputer model of morphophonological aspectsof Dutch.
University of Leuven.
Doctoraldissertation.Daelemans, Walter M. P. (1988).
"A modelof Dutch morphophonology and itsapplications," A/Communications, 1(2),18--25.De Smedt, Koenraad (1984).
"Usingobject-oriented knowledge-representationtechniques in morphology and syntaxprogramming," ECAI-84, 181-184.De Smedt, Koenraad, and de Graaf, Josje(1990).
"Structured inheritance inframe-based representation f linguisticcategories."
In Proceedings ofthe Workshopon Inheritance in Natural LanguageProcessing, edited by Walter Daelemansand Gerald Gazdar, 39-47.
Tilburg, The215Computational Linguistics Volume 18, Number 2Netherlands: ITK.Emele, Martin C., and Zajac, R6mi (1990).
"Typed unification grammars."
InCOLING-90, 293--298.Emele, Martin C.; Heid, Ulrich; Momma,Stefan; and Zajac, R6mi (1990).
"Organizing linguistic knowledge formultilingual generation."
In COLING-90,102-107.Etherington, David W. (1988).
Reasoning withIncomplete Information.
London/Los Altos:Pitman/Morgan Kaufmann.Etherington, David W.; Borgida, Alex;Brachman, Ronald J.; and Kautz, Henry(1989).
"Vivid knowledge and tractablereasoning: preliminary report," I\]CAI-89,1146-1152.Evans, Roger (1987).
"Towards a formalspecification for defaults in GPSG."
InProceedings, Workshop on Natural LanguageProcessing, Unification, and GrammarFormalisms, University of Stirling, 3-8.Evans, Roger, and Gazdar, Gerald (1989a).
"Inference in DATR."
In ACL Proceedings,4th European Conference, 66-71.Evans, Roger, and Gazdar, Gerald (1989b).
"The semantics of DATR."
In Proceedings,Seventh Conference ofthe Society for the Studyof Artificial Intelligence and Simulation ofBehaviour, edited by Anthony G. Cohn,79-87.Evans, Roger, and Gazdar, Gerald (1990).
"The DATR Papers, Volume 1," CognitiveScience Research Paper CSRP 139,University of Sussex, Brighton.Evans, Roger; Gazdar, Gerald; and Moser,Lionel (In press).
"Prioritised multipleinheritance in DATR."
In DefaultInheritance in the Lexicon, edited by TedBriscoe, Ann Copestake, and Valeriade Paiva.
Cambridge: CambridgeUniversity Press.Fahlman, Scott (1979).
NETL: A System forRepresenting and Using Real-WorldKnowledge.
Cambridge, MA: The MITPress.Flickinger, Daniel P.; Pollard, Carl J.; andWasow, Thomas (1985).
"Structure-sharingin lexical representation."
In ACLProceedings, 23rd Annual Meeting, 262-267.Flickinger, Daniel P. (1987).
Lexical Rules inthe Hierarchical Lexicon.
Doctoraldissertation, Stanford University.Flickinger, Daniel P., and Nerbonne, John(In press).
"Inheritance andcomplementation: A case study of easyadjectives and related nouns,"Computational Linguistics, 18(3).Fraser, Norman M., and Hudson, Richard A.(1992).
"Inheritance in word grammar,"Computational Linguistics, 18(2), 133-158.Gazdar, Gerald (1987).
"Linguisticapplications of default inheritancemechanisms."
In Linguistic Theory andComputer Applications, edited by PeterWhitelock, Mary McGee Wood, HaroldL.
Somers, Rod L. Johnson, and PaulBennett, 37-67.
London: Academic Press.Gazdar, Gerald (In press).
"Ceteris paribus.
"In Aspects of Computational Linguistics:Syntax, Semantics, Phonetics, edited byChristian Rohrer and Hans Kamp.
Berlin:Springer-Verlag.Gazdar, Gerald; Klein, Ewan; Pullum,Geoffrey K.; and Sag, Ivan A.
(1985).Generalized Phrase Structure Grammar,Oxford/Cambridge: Blackwell/Harvard.Gibbon, Dafydd (1990a).
"Underspecification in phonology."
In TheDATR Papers, Volume 1, edited by RogerEvans and Gerald Gazdar, 99-100.University of Sussex, Brighton: COGS.Gibbon, Dafydd (1990b).
"Prosodicassociation by template inheritance."
InProceedings, Workshop on Inheritance inNatural Language Processing, WalterDaelemans and Gerald Gazdar, 65-81.Tilburg, The Netherlands: ITK (Institutefor Language Technology and AI).Gibbon, Dafydd (1991).
"fLEX: a linguisticapproach to computational lexica."
InUrsula Klenk, ed.
Computatio Linguae:Aufsft ze Zur algorithmischen u dquantitativen Analyse der Sprache.Zeitschrift fiir Dialektologie undLinguistik, Beiheft 7, 32-53.Hetzron, Robert (1975).
"Where thegrammar fails," Language, 51,859-872.Horty, John E; Thomason, Richmond H.;and Touretzky, David S. (1990).
"Askeptical theory of inheritance innonmonotonic semantic networks,"Artificial Intelligence, 42(2-3), 311-348.Hudson, Richard A.
(1984).
Word Grammar.Oxford: Blackwell.Hudson, Richard A.
(1990).
English WordGrammar.
Oxford: Blackwell.Jackendoff, Ray (1975).
"Morphological ndsemantic regularities in the lexicon,"Language, 51, 639-671.Jacobs, Paul S. (1986).
"Knowledgestructures for natural anguagegeneration."
In COLING-86, 554-559.Jacobs, Paul S. (1987).
"A knowledgeframework for natural languageanalysis."
In IJCAI-87, 2, 675-678.Joshi, Aravind; Webber, Bonnie L.; andWeischedel, Ralph (1984).
"Defaultreasoning in interaction."
In Proceedings,AAAI Non-Monotonic Reasoning Workshop,New York, 144-150.Kameyama, Megumi (1988).
"Atomization216Walter Daelemans et al Inheritance in Natural Language Processingin grammar sharing."
In ACL Proceedings,26th Annual Meeting, 194-203.Kameyama, Megumi; Ochitani, Ryo; andPeters, Stanley (1991).
"Resolvingtranslation mismatches with informationflow."
In ACL Proceedings, 29th AnnualMeeting, 193-200.Kaplan, Ronald M. (1987).
"Three seductionsof computational psycholinguistics."
InLinguistic Theory and Computer Applications,edited by Peter Whitelock, Mary McGeeWood, Harold L. Somers, Rod L. Johnson,and Paul Bennett, 149-188.
London:Academic Press.Karttunen, Lauri (1986).
"D-PATR: Adevelopment environment forunification-based grammars."
InCOLING-86, 74-80.Kempen, Gerard (1987).
"A framework forincremental syntactic tree formation."
InI\]CA1-87, 2, 655-660.Kilbury, James; Naerger, Petra; and Renz,Ingrid (1991).
"DATR as a lexicalcomponent for PATR."
In ACL Proceedings,5th European Conference, 137-142.Lascarides, Alex, and Asher, Nicholas(1991).
"Discourse relations anddefeasible knowledge."
In ACLProceedings, 29th Annual Meeting, 55-62.Mercer, Robert E. (1988).
"Using defaultlogic to derive natural languagepresuppositions."
In Proceedings, SeventhBiennial Conference ofthe CSCSI/SCEIO,14-21.Mercer, Robert E., and Reiter, Raymond(1982).
"The representation fpresuppositions u ing defaults."
InProceedings, Fourth Biennial Conference oftheCSCSI/SCEIO, 103-107.Moens, Marc; Calder, Jo; Klein, Ewan;Reape, Mike; and Zeevat, Henk (1989).
"Expressing eneralizations inunification-based grammar formalisms.
"In ACL Proceedings, 4th EuropeanConference, 174-181.Moore, Robert C. (1985).
"Semanticalconsiderations on nonmonotonic logic,"Artificial Intelligence, 25(1), 75-94.Perrault, C. Raymond (1990).
"Anapplication of default logic to speech acttheory."
In Intentions in Communication,edited by Philip Cohen, Jerry Morgan,and Martha Pollack, 161-185.
Cambridge,MA: The MIT Press.Pollard, Carl, and Sag, Ivan A.
(1987).Information-Based Syntax and Semantics,Volume 1.
Stanford/Chicago:CSLI/Chicago University Press.Porter, Harry H. (1987).
"Incorporatinginheritance and feature structures into alogic grammar formalism."
In ACLProceedings, 25th Annual Meeting,228-234.Pullum, Geoffrey K. (1979).
Rule Interactionand the Organization of a Grammar.
NewYork: Garland.Pustejovsky, James (1989).
"Current issuesin computational lexical semantics."
InACL Proceedings, Fourth EuropeanConference, xvii-xxv.Pustejovsky, James (1991).
"The generativelexicon," Computational Linguistics, 17(4),409-441.Quillian, M. (1968).
"Semantic memory."
InSemantic Information Processing, edited byMarvin Minsky, 227-270.
Cambridge, MA:The MIT Press.Reinhard, Sabine (1990).
"Verarbeitungsprobleme nichtlinearerMorphologien: Umlautbeschreibung ieinem hierarchischen Lexikon."
In Lexikonund Lexicographie, dited by B. Rieger andB.
Schaeder, 45-61.
Hildesheim: OlmsVerlag.Reinhard, Sabine, and Gibbon, Dafydd(1991).
"Prosodic inheritance andmorphological generalisations."
InProceedings, Fifth Conference ofthe EuropeanChapter of the Association for ComputationalLinguistics, 131-136.Russell, Graham; Ballim, Afzal; Carroll,John; and Warwick-Armstrong, Susan (Inpress).
"A practical approach to multipledefault inheritance for unification-basedlexicons," Computational Linguistics, 18(3).Schubert, Lenhart K., and Hwang, ChungHee (1989).
"An episodic knowledgerepresentation for narrative texts."
InProceedings, First International Conference onPrinciples of Knowledge Representation andReasoning, 444--458.Selman, Bart, and Levesque, Hector J.(1989).
"The tractability of path-basedinheritance," IJCAI-89, 1140-1145.Shieber, Stuart M. (1986a).
"A simplereconstruction f GPSG."
In COLING-86,211-215.Shieber, Stuart M. (1986b).
An Introduction toUnification-Based Approaches toGrammar.Chicago: University of Chicago Press.Simmons, Robert F. (1973).
"Semanticnetworks: Their computation and use forunderstanding English sentences."
InComputer Models of Thought and Language,edited by Roger C. Schank and KennethM.
Colby, 63-113.
San Francisco: Freeman.Smolka, G. (1988).
"A feature logic withsubsorts," LILOG Report 33, IBMDeutschland, Stuttgart.Steels, Luc (1978).
"Introducing conceptualgrammar," Working Paper 176, MIT AILaboratory, Cambridge, MA.217Computational Linguistics Volume 18, Number 2Steels, Luc, and De Smedt, Koenraad (1983).
"Some examples of frame-based syntacticprocessing."
In Een Spyeghel voor G. JoSteenbergen, edited by Fr.
Daems andL.
Goossens, 293-305.
Leuven: Acco.Thomason, Richmond H.
(1991).
"Inheritance in natural language,"Unpublished manuscript, IntelligentSystems Programme, Pittsburgh.Thomason, Richmond H., and Touretzky,David S. (1992).
"Inheritance theory andnetworks with roles."
In Principles ofSemantic Networks: Explorations in theRepresentation f Knowledge, dited by JohnSowa, 231-266.
San Mateo: MorganKaufmann.Touretzky, David S. (1986).
The Mathematicsof Inheritance Systems.
London/Los Altos:Pitman/Morgan Kaufmann.Vogel, Carl, and Popowich, Fred (1990).
"Head-driven phrase structure grammaras an inheritance hierarchy."
InProceedings, Workshop on Inheritance inNatural Language Processing, edited byWalter Daelemans and Gerald Gazdar,104-113.
ITK, Tilburg.van der Linden, Erik-Jan (1992).
"Incremental processing and thehierarchical lexicon," ComputationalLinguistics, 18(2), 219-235.Weischedel, Ralph M. (1989).
"A hybridapproach to representation in the Janusnatural anguage processor."
In ACLProceedings, 27th Annual Meeting, 193-202.Whitelock, Peter; McGee Wood, Mary;Somers, Harold L.; Johnson, Rod L.; andBennett, Paul (1987).
Linguistic Theory andComputer Applications.
London: AcademicPress.Zajac, R6mi (1992).
"Inheritance andconstraint-based grammar formalisms,"Computational Linguistics, 18(2), 159-182.218
