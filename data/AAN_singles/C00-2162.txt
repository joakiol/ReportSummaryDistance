Improving SMT quality with morpho-syntactic analysisSonja Nief lcn and Hcrmann NeyLehrstuhl  fiir hf lbr lnatik VIComputer  Science DepartmentRWTH University of Technology AachenD-52056 Aachen, GermanyEmail: n iessen@in?ormat ik ,  rwth -aachen,  deAbst ractIn the framework of statistical machine transla-tion (SMT), correspondences between the wordsin the source and the target language arelearned from bilingual corpora on the basis ofso-called alignment mode, Is.
Many of the sta-tistical systems use little or no linguistic know-ledge to structure the underlying models.
Inthis paper we argue that training data is typical-ly not large enough to sutficiently represent therange of different phenomena in natural angua-ges and that SMT can take advantage of the ex-plicit introduction of some knowledge about thelmlgnages under consideration.
The improve-ment of the translation results is demonstratedon two ditferent German-English corpora.1 I n t roduct ionIn this pal)er, we address the question of howmorl)hological and syntactic analysis can helpstatistical machine translation (SMT).
In ourapl)roach, we introduce several transtbrmationsto the source string (in our experiments thesource language is German) to demonstrate howlinguistic knowledge can improve translation re-suits especially in the cases where, the token-type ratio (nmnber of training words versusnmnber of vocabulary entries) is unthvorable.After reviewing the statistical approach tomachine translation, we first explain our mo-tivation for examining additional knowledgesources.
We then present our approach in detail.Ext)erimental results on two bilingual German-English tasks are reported, namely the VERB-MOBIL  and the EUTRANS task.
Finally, we givean outlook on our fllture work.2 Stat i s t i ca l  Mach ine  Trans la t ionThe goal of the translation process in statisticalmachine translation can l)e fornmlated as tbl-lows: A source language string .f~ = f l .
.
.
f.!is to be translated into a target language stringc\[ =- e l .
.
.
el.
In the experiments reported inthis paper, the source language is German andthe target language is English.
Every Englishstring is considered as a possible translation forthe intmt.
If we assign a probability P'r(e\[lfi/)to each pair of strings (el, fi/), then according toBayes' decision rule, we have to choose the En-glish string that maximizes the I)roduct of theEnglish language model Pr(c{) and the stringtranslation model r'r(fff\[e{).Many existing systems tbr SMT (Wang andWaibel, 1997; Niefien et al, 1.
(/98; Och and We-ber, 1998) make use of a special way of structur-ing the string translation model (Brown et al,1993): 'l?he correspondence b tween the wordsin the source and the target string is describedby aligmuents that assign one target word posi-tion to each source word position.
The prob-ability of a certain English word to occur inthe target string is assumed to depend basicallyonly on the source word aligned to it.
It is clearthat this assumption is not always valid tbr thetranslation of naturM languages.
It turns outthat even those approaches that relax the word-by-word assumption like (Och et al, 1999) haveproblems with lnany phenomena typical of nat-ural languages in general and German in par-titular like?
idiomatic expressions;?
colnpound words that have to be translatedby more than one word;?
long range dependencies like prefixes ofverbs placed at the end of the sentence;?
ambiguous words with different meaningsdependent on the context.1081Tile parameters of the statistical knowledgesources nlentioned above are trained on bi-lingual corpora.
Bearing ill mind that morethan 40% of the word tbrms have only been seenonce in training (see q~,bles 1 and 4), it is obvi-ous that the phenomena listed above can hardlybe learned adequately from the data and thatthe explicit introduction of linguistic knowledgeis expected to improve translation quality.The overall architecture of the statisticaltranslation approach is depicted in Figure 1. hithis figure we already anticipate the t'aet thatwe will transtbrm the source strings in a certainmanner.
If necessary we can also apply the in-verse of these transfbrmations on the producedoutput strings.
Ill Section 3 we explain in detailwhich kinds of transtbrmations we apply.Source Language Text1QTransformation )1' flGlobal Search:maximize Pr(el).
Pr(f~ lel)over e I1 IlTarget Language Textl J I ~ Lexicon Model Pr(l 1 \]e,) \[Alignment Model \]Language ModelFigure 1.: Architecture of the translation 31)-preach based on Bwes' decision rule.3 Ana lys is  and  Trans format ion  ofthe InputAs already pointed ouL we used the inethodof transforming the inl)ut string in our experi-ments.
The advantage of this approach is thatexisting training and search procedures did nothave to be adapted to new nlodels incorporat-ing the information under consideration.
On theother hand, it would be more elegant to leavethe decision between different readings, tbr in-stance, to the overall decision process in search.Tile transtbrmation method however is nlore 3(t-equate tbr the preliminary identification of thosephenonmna relevant br improving the transla-tion results.3.1 AnalysisWe used GERTWOL,  a German Morphologi-cal Analyser (Haapalainen and M~@)rin, 1995)and the Constraint Grammar Parser Ibr Ger-man GERCG tbr lexical analysis and inorpho-logical and syntactic dismnbiguation.
For a de-scription of the Constraint Grammar approachwe refer the reader to (Karlsson, 1990).
Someprel)rocessing was necessary to meet the inputformat requirements of the tools, hi the caseswhere the tools returned lnore thalt one reading,either simple heuristics based on domain spe-cific pretbrence ruh;s where at)plied or a nloregeneral, non-mnbiguous analysis was used.In the following subsections we list sometranstbrmations we have tested.3.2 Separated German VerbprefixesSortie verbs in German consist of a main partand a detachable prefix which can be shiftedto the end of the clause, e.g.
"losfahren" ("toleave") in the sentence "Ich fahre morgen los.
".We extr~cted all word forms of separable verbsfl:om th.e training corl)us.
The resulting list con-tains entries of the tbrm prefixlmain.
The en-try "los\[t:'ahre" indicates, fi)r exalnple, that theprefix "los" (:an l)e detached flom the word tbrm"fahre".
In all clauses containing a word match-ing a main part and a word matching the corre-sponding prefix part occuring at the end of theclause, the prefix is prepended to the beginningof the main part, as in "Ich losfahre morgen.
"a.a German Compound WordsGerman comt)(mnd words pose special 1)roblemsto the robustness of a translation method, be-cause the word itself must be represented in thetraining data: the occurence of each of the coin-t)onents is not enough.
The word "I~'iichtetee"tbr example can not be translated although itscoml)onents "Friichte" and "Tee" appear in thetraining set of EUTRANS.
Besides, even if thecoml)ound occurs in training, tile training algo-r ithm may not be capable of translating it prop-erly as two words (in the nlentioned case thewords "fl'uit" and "tea") due to the word align-ment assumption mentioned in Section 2.
We1082therefore split the COml)ound words into their(:Oml)onents.3,,4 Annotat ion  w i th  POS Tags()he way of hell)|rig the disanfl)iguation of gill-t)Jguous words is to annotate them with theirt)m:l; of Sl)eech (POS) inl'()rmation.
We (:hose l;hetbllowing very ti'equent short words that often(:;rased errors in translation fi)r VERBMO\]3IL:"aber"  can 1)e adverb or (:onjun('tion.
"zu"  can l)e adverb, pret)osition , sepnratedverb prefix or infinitive marker.%ler' ,  "die" and "das" cnn 17e definite m:ti-CIos el' \])1"Ol1Ol111S.
'.\['he difficulties due to l;hese aml)iguities m:ei l lustrated by the fi)lh)wing exmnt)les: The sen-tence "Das wiird(' mir sehr gut 1)~ssen. ''
is oftentrnnslnted 1)y "Th, e would suit me very well.
"iltsl;e;~(l ()\[ "5l'h,at would suit me very well."
and"Das win: zu s(:lmcll."
is trnnsl;~ted by "Th~Ltwas to t'~lsl;."
instea,(t of "Theft; was too f;~st;.
".We alTpended the POS l;~g in training a,mtt(;st corpus fiTr the VERBMOBII, task (see 4.\]).3.5 Merg ing  PhrasesSome multi-word phrases as ~ whole rel)r(;senta distine(; synta.7"tie rob; in (;he s(mtenT:e. The17hra.se "irgend ('.t;w;ls" (%nything")  for exa,m-t)1(; m~y form ('it, l,('a: a.n in(h'tinit;('.
(h'.t;('.rmino.r():c an in(lelinil;e pronoun.
Like 2\] other mull;i-word tThrases "irg(:nd-et;wa.s" is merged in ordert;o form one single voca,bulary ('nl;ry.3.6 Treatment  o f  Unseen Wordsl"or sl;atist;i(::fl ma(:hin(; tr;mslation it is difficult1;() handle woi'ds not seen in training.
\]~br m>kllOWll i)l;O1)el; ll&llIeS~ i\[; is normally ('(TrreT't tot)bme the word un(;h~mge(t into th(; transl~fl;ion.We have t)(;(;n working on the l;17ea~l;nlenI; of 1111-kll()Wll words of other types.
As ~flr(;~dy men-l;ioned in Se(:l;ion 3.3, the st)litting of eomt)oundwords cml reduce |;he nmnber of unknown Cl(:r-man words.In addit ion, we have examined methods of r(>pl~('ing a word \['ullform l)y ~ more ;O)stra('l; wordform nnd (-heek whether this fi)rm is kn()wn and(:;~m l)e I;ranslnted.
Th(' l;rmlslat, ioll of the sin>|)lifted word tbrm is generally not the precis('trmlslai;ion of the original on(', 17ul; sometimesthe intended semantics is conveyed, e.g.
:"ka l tes"  is ~m adjective in the singular neuterfOl;lll &lid.
c3~11 be  t,l'a, nst:'ornled to the lessspecilic form "kalt" ("cold").
"Jahre" ("years") (:~m be replaced by the sin-gulm: form "J~fln:".
"bene idest "  (%o envy" in tirst person singu-lar): if the infinitive tbnn "beneiden" is notknown, it might hell).just, to remove timleading t)artiele "be".4 Trans la t ion  Resu l tsWe use the SSER (sul)jectivc sentence errorrat(') (Ni('fien et al, 2000) as evaluation cri-t('rion: E~wh translated senten(:e is judged by~ tmmmi exmniner according 1;(7 nn error scaleti'om 0.0 (semantical ly and syntaeti(:~flly co lreef) to 1.0 ((:onlt)h;l;ely wrong).4.1 Trans la t ion  Resu l ts  for VEm~MOmLTh(, VEI{BM()BII, corpus consists of st)onttme-ously spoken dialogs in t;he al)t)oint;ment sch(>(hfling domain (Wtflflster, 1993).
German sen-t;ences ;~re l;ra.nsl;~lx;d inl;o English.
The outputof the st)ee('h re(:ognizer (Ibr example th(; single-best hyl)othesis ) is used as int)ut to the tr;ms-lation moduh',s.
For resem:eh tmri/oses the orig-inal l;(;xt st)oken 1)y th(, users can t)7, t)r(;sentedt() the translal;ion system t;(7 ev~flm~te the MT(:omponent set)er~ti;ely from l;hc, re(:ognizT~r.'l'h('.
tra.ining set (:onsist;s (Tf d5 680 s(;nl;o.n(:epairs.
Testing was carried out on ~t seper~teset of 14:7 senl;enees l;h~fl; (to not contain anymlseen words, hi Table 1 l;he ehara('teristics ofthe training sets are summarized for l;he originaleort)ns and after l;he ai)plication of the des(:rit)edtr~Lnsfornlat;ion.s on t;he Gerlll}~tll part of l;he co lpus.
\[l.'he tM)le shows that  on t;his cou)us Ill(',splitting of (:Oml)OUll(ts iinl)roves l;hc l;oken-tyl)erntio t iom 59.7 t(7 65.2, lint th(', mmfl)er of singh;-tons (words s(;en only on('e in tt'nhfing) does notgo down by more than 2.8%.
'.l'he oth.er trans-fi)rm~tions (i)r(;1)ending separated verb 1)refixe,~"t)ref"; mineral;ion wi|;h 1)OS t~gs "i)os"; merg-ing of phrases "merge") do not at\[bet hese co>pus st;,l;isl;ies much.The translntion l)erformmme results are givenin rl2~fi)le 2 tbr tra.nslat;ion of text and in 'l~fi)le3 for translation of t;he single-best hyl)oth(!sisgiven t)y a sl)eech recognizer (a('(:m:a.
('y 69%).For t)oth cases, l;r;mslation on text ml(t onst)ee(:h int)ut , st)litting (:oml)oml(t words does1083Table 1: Corpus statistics: VERBMOBIL train-ing ( "baseline" =no preprocessing).preprocessingEnglish 465 143Gerlnanbaselineverb prefixessplit compoundspospos+mergepos+merge+prefno.
of no.
of single-tokens types tons4382 37.6%437968 7335 44.8%435 686 7370 44.3%442938 6794 42.0%437972 7 344 44.8%437330 7363 44.7%435055 7397 44.2%not iml)rove translation quality, but it is notharmful either.
The treatment of separable pre-fixes helps as does annotating some words withpart of speech inibrmation.
Merging of 1)hrasesdoes not improve the quality much further.
Thebest translations were adfieved with the combi-nation of POS-annotation, phrase merging andprepending separated verb prefixes.
This holdstbr t)oth translation of text and of speech input.Table 2: Results on VERBMOBIL text intmt.preprocessing SSER \[%\]baselineverb prefixessplit compoundspospos+mergepos+merge+pref20.319.420.319.719.518.0The fact that these hard-coded transtbrma-tions are not only hclpflfl on text input, butalso on speech input is quite encouraging.
Asan example makes clear this cannot be takenfor granted: The test sentence "Dann fahrenwir dann los."
is recognized as "Dam1 fahren wirdann uns."
and the tact that separable verbs donot occur in their separated form in the train-ing data is mffavorable in this case.
The fig-ures show that in generM the speech recognizeroutput contains enough information for helpflflpreprocessing.Table 3: Results on VERBMOBIL speech inlmt.preprocessingbaselineverb prefixessplit compoundssplit+prefpos+merge+prefssEa \[%143.441.843.142.341.14.2 Translat ion Results for EUTRANSThe EUTRANS corpus consists of differenttypes of German-English texts belonging to thetourism domain: web pages of hotels, touris-tic brochures and business correspondence.
Thestring translation and language model parame-ters were trained on 27 028 sentence pairs.
The200 test sentences contain 150 words never seenin training.Table 4 summarizes the corpus statistics ofthe training set for the original corpus, af-ter splitting of compound words and after ad-ditional prepending of seperated verb prefixes("split+prefixes").
The splitting of compoundsimproves the token-type ratio flom 8.6 to 12.3and the nmnber of words seen only once in train-ing reduces by 8.9%.Table 4: Corpus statistics: EUTRANS.preprocessing no.
oftokensEnglish 562 264Germanbaselinesplit compoundssplit+prefixes499 217535 505534 676no.
of single-types tons33 823 47.1%58317 58.9%43 405 50.0%43 407 49.8%Tile mlmber of words in the test sentencesnever seen in training reduces from 150 to 81 bycompound splitting and can further be reducedto 69 by replacing the unknown word forms bymore general forms.
80 unknown words are en-countered when verb prefixes are treated in ad-dition to compound splitting.Experiments for POS-annotation have notbeen pertbrmed on this corpus because no smallset of ambiguous words causing many of the1084translation errors on this |;ask can be identified:Comt)ared to |;it(', VERBMOBIL task, this tort)usis less homogeneous.
Merging of 1)hrases did nothelp much on VEI/,BMOBIL and is theretbre nottested here.Tal)le 5 shows that the splitting of comt)oundwords yields an improvement in the subjectivesentence rror rate of 4.5% and the treatmentof unknown words ("unk") improves the trans-lation quality by an additional 1%.
TreatingSOl)arable verb 1)refixes in addition to splittingcompounds gives the be, st result so far with animprovement of 7.1% absolute COml)ared to thel)aseline.Table 5: Results on EUTRANS.1)ret)rocessing SSER \[%\]1)aseline 57.4split comi)ounds 52.9sl) l it+lmk 51.8split+prefixes 50.35 Conclusion and Future WorkIn this paper, we have presented some methodsof providing morphological im syntactic intbr-mat|on tbr improving the 1)ertbrmance of sta-tistical machine trallslation.
First ext)erimentsprove their general aplflicalfility to reMistic andcomI)lex tasks such as spontaneously spoken di-alogs.We are.
1)lamfing to integrate the al)t)roachinto the search process.
We are also workingon language models and translation models thatuse mort)hological categories for smoothing inthe case  of unseen events.Acknowledgement.
This work was partlysupported by the German FederM Ministry ofEducation, Science, Research and Technologyunder the Contract Number 01 IV 701 q_'4(VERBMOBIL) and as part of the EUTRANSproject by the European Comnmnity (ESPRITproject number 30268).The authors would like to thank GregorLeusch tbr his support in implementation.ReferencesP.F.
Brown, S.A. Della Pietra, V.J.Della Pietra, and ILL. Mercer.
1993.Mathematics of Statistical Machine %'ansla-tion: Parameter Estimation.
ComputationalLinguistics, 19(2):263 311.Mariikka Haapalainen and Ari Majorin.
1995.GERTWOL und Morphologische Disambi-guierung fiir das Deutsche.
URL:www.lingsoft.fi/doc/gercg/NODALIDA-poster.html.Fred Karlsson.
1990.
Constraint Grmnmar asa Frainework tbr Parsing Running Text.
InPTvecedings of th, e 13th, hzternational Confer-cnce on Computational Linguistics, volume 3,pages 168-173, Helsinki, Finland.Sonja Niefien, Stephan Vogel, Hermann Ney,and Christoph Tilhnann.
1998.
A DP basedSearch Algorithm tbr Statistical MachineTranslation.
In Proceedings of the 36th An-nual Con:ferencc of the Association for Com-putational Linguistics and the 17th Interna-tional Conference on Computational Linguis-ties, pages 960 967, Montrdal, P.Q., Canada,August.Sonja Niefien, Franz loser Oeh, Gregor Leusch,and Hermaml Ney.
2000.
An Ewfluation Tooltbr Machine %'anslation: Fast Evaluationfor MT Research.
In Proceedings of the 2ndInternational Conference on Language Rc-so'arccs and Evaluation, pages 39 45, Athens,Greece, May.Franz .losef Och and Hans Weber.
1998. hn-t)roving Statistical Natural Language ~:ans-lation with Categories and Rules.
In Pro-eccdings of the 36th Annual Con.fcrcncc ofth, e Association for Computational Linguis-tics and the 17th international Conference onComputational Linguistics, pages 985-989,Montrdal, P.Q., Canada, August.Iq:anz ,loser Och, Christol)h Tillmmm, aim Her-maml Ney.
1999. hnproved Alignment Mod-els tbr Statistical Machine Translation.
InProceedings of the Co~:ference on EmpiricalMethods in Natu~nl Language Processing andVery Large Corpora, pages 20-28, Universityof Maryland, College Park, Maryland, June.Wolfgang Wahlster.
1993.
Verl)mobih Transla-lion of Face-to-Face Dialogs.
In Proceedingsof the MT Summit IV, pages 127-135, Kobe,Japan.Ye-Yi Wang and Alex Waibel.
1997.
Decod-ing Algorithm in Statistical %'anslation.
InProceedings of the A CL/EA CL '97, Madrid,Spain, pages 366 372, July.1085
