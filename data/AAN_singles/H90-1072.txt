Machine Translation Again?Yorick Wilks, Jaime Carbonen, David Farwell, Eduard Hovy andSergei NirenburgDepartment of Computer ScienceNew Mexico State UniversityLas Cruces, NM 88001Machine translation (MT) remains the paradigm task fornatural anguage processing (NLP) since its inception inthe 1950s.
Unless NIP can succeed with the central taskof machine translation, it cannot be considered successfulas a field.
We maintain that the most profitable approachto MT at the present ime is an interlingual and modularone.
MT is one the precious few computational tasks fal-ling broadly within artificial intelligence (AI) that combinea fundamental intellectual research challenge with enor-mous proven need.
To establish the latter, one only has tonote that in Japan alone the current MT requirement is for20 billion pages a year (a market of some $66 billion ayear).The vulgarized version of the history of MT is as fol-lows: In the 1950s and 1960s large funds were made avail-able to US MT which proved to be an umitigated failure.The ALPAC report (1966) said MT was impossible anddoomed all further US funding.
MT work then moved toCanada and Europe where it partly succeed, which wasthen followed by highly successful exploitation in Japan.The truth, of course, is not at all like that.MT work did not stop in the US after ALPAC: theAFOSR continued to fund it in the US and there were andare enormous commercial developments (the best knownsystems being SYS'rRAN, ALPS, LOGOS, METAL andSMART).ALPAC did not say MT was impossible nor that thework done was no good: only that at that point history,with the cost and power of 1960s computers, human trans-lation was arguably cheaper.MT work did not really move to Europe, since itstopped there also in response to the ALPAC report.
TheUK believed the ALPAC report, and only in France didserious work continue, and the GETA system in Grenoblebecame the foundation for a range of others, including themajor Japanese university system (Mu) and aspects of theEurotra system, which was designed to be a multilingualsystem between the languages of the EEC.The GETA system, like SYSTRAN, date their originsfrom the very earliest period of pre-ALPAC MT.
Thelongevity of such systems is proof of the need of staminaand persistence in MT to achieve serious results, but alsothe need for periodic redesign, pretty much from scratch,since old formalisms and software reach a point where theycannot be further optimized, a point reached long ago withSYSTRAN itself.
One way in which all MT work is inSYSTRAN's debt is that it is the main existence proof: itconvinces doubters that there that machine translation owexists, albeit in primitive form, and can be purchased on alarge scale and at a quality that many users find acceptablefor their needs.
A key defect in the ALPAC report was thatit underestimated how large a market here was for par-tially accurate, low quality MT, and SYS'rRAN filled thatmarket.
The point now, of course, is to move on to thehuge market for higher-quality MT.
But even now the pro-portion of internal EEC documentation translation forwhich a preliminary draft version is done by machine israpidly growing using a modified version of the SYSTRANsystem.It is certainly not the case that most major MT installa-tions in the world are now Japanese.
In the list given in theJEIDA report only one Japanese system occurs among thelist of major installed systems in the world outside Japan.All the rest are American.
However, that list is becomingquickly dated, as Japanese system are being researched,developed and deployed at a much faster ate, reflecting alopsided ten-to-one total R funding skew in favor of Japanover America.
Moreover, some commercial American MTefforts are being purchased by the Japanese; witnessBRAVIS's purchase of WEIDNER COMMUNICATIONS,and a (partial) purchase of SYSTRAN.
A crucial differ-ence between US and foreign strategies to date has beenthat the Japanese government made machine translationcentral to the Fifth Generation effort, and the EuropeanCommunity began ten years ago a $45 million investmentin the Eurotra project as part of their overall informationtechnology drive.Why this is a good time to get back into MT.There is a growing need for translation in intelligence,commerce, science, government, and international organi-zations.
This is due to factors uch as the following:?
Increases in international cooperation and competition,which involve an ever-growing volume of text to becommunicated.?
World-wide lectronic networks have made internationalcommunication much easier.?
Reports, documentation, legal papers, and manuals areincreasingly produced in one culture and exported tovarious other cultures, often in multiple languages.?
More emphasis i being placed on the use of nationallanguages in documents and systems.?
The economic rise of South-East Asia and the openingof the European market in 1992 add significantly tothese factors.371Strategic Reasons for an MT Effort:MT systems live and decay like natural organisms: theyhave natural life spans that cannot be indefinitelyprolonged.
The SYSTRAN system has lived long anddone well but it is 30 years old and cannot be optimizedabove the 75% level.
Later systems from the early 1970s(GETA, LOGOS, ALPS, WEIDNER, MU, etc) were betterconstructed but cannot rise above their current levels---theevidence for this being that the two research systems inthat list (GETA & MU) have now effectively collapsed andtheir teams dispersed.
The right thing is now to promote anew design using the enormous and transferable advancesthat have been made in interfaces, hardware, linguistics,AI, machine lexicons etc.The most recent new large-scale efforts have either beenbadly managed and proved impractical (like EUROTRA)or set very mow commercial goals (usually involvingonly Japanese and English or Asian languages) like themajor Japanese systems.The need has never been greater, not only for MT itselfbut all the associated technologies that can be integratedinto a well-designed MT system.
The rapid integration ofthe world is not leading to a common language (English)nearly as fast as it is leading to the absolute need to readmasses of documentation produced in foreign languages.
Itis also necessary to choose a system to which NEWlanguages can be rapidly added, i.e.
a modular, interlingualone.Much of the MT-related research performed in the US isbeing applied elsewhere.
No nationwide project utilizingthe best research talents in NLP has been attempted in theU.S.
in over two decades.
Today, Darpa is probably theonly institution with the resources and scope to mount alarge-scale MT effort successfully.
Such an effort wouldharness and coordinate NLP work of various kinds andwould create a setting in which new innovations could beused within this country first.A second strategic reason pertains to interprojectcollaborations.
Currently, there is relatively littlecollaboration and sharing of resources and expertise amongNLP research groups in this country.
A new nationalagenda with a set of clearly focused goals could serve as anintegrating agent.
The development of a standardinterlingua representation, a set of standardized lexicons,one or more grammars, support ools and interfaces, andadditional software, can shape much future NLP researchin this country by enabling researchers to make use ofexisting work and tools with much less effort than iscurrently the case.Technical Reasons for an MT Effort:Steady developments in various aspects of NLP makeavailable large portions of an MT system more or less offthe shelf, which greatly facilitates the construction of newMT systems.
These developments are the following:1.
Clearer understanding of semantics: Recentrefinements of taxonomical ontologies ofrepresentation provide an interlingua-like basis for anew, more powerful, MT.
Making maximal use ofthe high-level linguistic and semantic generalizationsshared among languages, one can minimizelanguage-to-language lexical or structural transferrules and so increase the portability of the systemacross domains.2.
More complete grammars: Development ofgrammars is an ongoing process.
There exist todaygrammars that cover English (and other languagessuch as German, Chinese, Japanese, and French) farmore extensively than the most comprehensivegrammars of 20 years ago did.3.
Better existing generation and parsing technology:Single-sentence parsing and generation has beenstudied to the point where a number of well-established paradigms and algorithms exist, eachwith known strengths and weaknesses, a situationwhich greatly facilitates the construction of a newMT system (in fact, in the last 5 years a number ofgeneral-purpose generators have been distributed:Penman, mumble, frege, etc.).4.
In addition, the number of existing MT systems andthe amount of MT experience is also much largerthan it was in the early days, especially in Europeand Japan.An Interlingual Approach Versus Transfer Or MassiveStatistics.A fundamental technical notion in our proposal isinterlinguality: it is one of the three basic structuralmethods for MT, contrasted with direct and transferapproaches.
The direct method was used for early systemslike SYSTRAN as well as large recent ones like SHALTfrom IBM Japan.
If one is only every going to be interestedin one language couple in one direction, as SYSTRANoriginally was, there is no reason not to use it.
We assume,however, that that is not our situation and muldlinguality isessential.
It should also be noted that some form ofintedinguality is now becoming the standard position inAI-knowledge representation a d our approach meshes bestwith that.
The interlingua approach overcomes theproblem of building thousands of transfer ules by using acentral representation i to which and from which all thelanguages are parsed and generated.Of major concern is to design an intedingua which isboth specific enough to allow simple and unambiguousprocessing and general enough to enable differentapproaches with different theoretical strengths to representthe information they can extract from the text.
Fortunately,none of the parties involved have ever been committed tothe highly formalized representation languages and systemswhich have been (and still are) popular in various areas ofNLP, formalisms whose logical properties have beenstudied extensively but whose practical utility is low.372Consider now the following example:"Mary was in a severe accident.
She lost a foot."vs.
"Mary was buying cloth, but measured it incorrectly byaccident.
She lost a foot.
"There is no statistical measure (e.g., no low-order n-grams) that will disambiguate r liably.
Yet, if a sentencesimilar to the above concerned the Lybian Colonel or AbuNidal it might be useful to have accurate intelligence.Language other than English have different ambiguitiesthat must be resolved to translate to English or to fill adatabase for an analyst.The interlingua pproach is far better able to exploitdomain knowledge in order to produce reliable translationsthan the other two approaches.
The massive statisticalapproach is inimical to any infusion of domain knowledgeor any comprehension of the language.
Pure statisticaltranslation had been rejected in the early years, but hasbeen brought back to life in the recent IBM re~arch effort.Experience has consistently shown that unaided statisticalmethods perform only at a low level which cannot beraised much, and only on a carefully selected materials (inthe IBM project based on the copious high-quality parallelFrench-English Hansard texts from Canada -- data notfound for other language pair.
Even the 50 successclaimed may depend crucially on order similarities betweenEnglish and French.
The paper claims that for 63 oftested sentences under 10 words, the most probable wordorder, based on trigram probabilities, was the correct one80 of the time, which together produce the figure above.The transfer approach is indeed capable of using domainknowledge, but the software engineering is much worsethan an interlingual approach.
If one must translate amongN languages, there are N(N-1)/2 language pairs.
A transferapproach would require on the order of N**2 transfergrammars (2 per language pair, one for each direction), ifthese must be augmented with domain semantics, a taskthat was gargantuan to start becomes totally intractable tohardiest of souls.
In contrast, the interlingua pproachrequires 2N grammars (1 for analysis and 1 for generationfor each language, into and out of the standardizedcommon interlingual knowledge representation).
Domainknowledge, though potentially complex, need be addedonly once per domain and retained in modular, reusabledeclarative data structures that serve as input to a unifyingcompiler.
This compiler combines modular domainknowledge and grammar files dynamically to produce a runtime translator among two languages for a given domain(or set of domains).Statistics, although not the preferred translationparadigm, plays several important roles in MT, including:Once the meaning of a text is analyzed, selecting the mostnormative (frequent) rendition into words in each targetlanguage.
Statistics can select collocations from large textcorpora (such as the preferred use of "pitch black" ratherthan "asphalt black").
Given a large potential exicon,simple frequency analysis can direct the dictionary-buildingwork towards the most frequent words first, so as to obtainmaximal utility of a system during development phases.All evaluation metrics of fluency, accuracy and cost oftranslation are statsfically based.Machine translation systems must be concerned with theknowledge ncoding, with modular software architectures,with good engineering, with scalable and evaluable systemsdevelopment, much more so than with specific finguisfictheories prevalent in modern transfer approaches.
Inpractice, MT approaches motivated by theoretical-linguisticconcerns, like EUROTRA, tend to be too driven byfinguistic fashion (since their chief motivation is to betheoretically interesting rather than effective).
This opinionis shared by the Japanese researchers.
Thus, the 1989JEIDA report concluded that linguistic theory had made nodiscernible contribution to the advance of MT.
Keyfeatures of the cooperative approach we advocate are:1.
The use of an interfingua instead of transfer rules orstatistical cooccurrences;2.
Modularity : both programs and data will beproduced in a modular fashion allowing them to beassembled into a number of prototype MT systems;3.
Commitment to gradual increase in the levels ofautomation of the systems we create;4.
The central role of world knowledge in addition toknowledge about language;5.
The use of a representation based on commonsensesemantics and pragmatics ;6.
Emphasis on the large scale of the systems underconstruction;7.
Ensuring portability across domains by buildingreusable tools and information repositories uch aslexicons;8.Developing a translator's workstation environmenta) to facilitate the integration of the above modulesand b) to support the creation of useful machine-aided translation systems at the earlier stages of theproject, while the various automatic processingmodules are being developed.
Included here will be aseparate, but compatible, lexicology workstation, toassist the incorporation of large-scale semantic,syntactic and collocational information from machine-readable dictionaries and text corpora.The Modularity AssumptionModularity is independent of interlinguality thoughopting for the latter requires the former.
Strong modularityof language components would now be supported by mostresearchers and developers in MT, largely because it allowsthe addition of new languages with minimum dislocation.It is also essential if it is to be possible to treat differentlanguages by different methods and to combine work at arange of sites.
Agreeing on suitable interfaces i a practicalnot a theoretical matter, and the experience of EUROTRAhas shown it is perfectly feasible (this is the main scientificcontribution of EUROTRA).373In order to harness the NLP research potential in thiscountry, a modular approach to the construction ofprototype MT systsems i proposed.
Under this approach,various sites will build various modules which can beassembled in various ways to construct various prototypesystems.Two advantages of the modular approach are: newlanguages and additional functionalities such as gisting canbe added with minimal disruption to the existing system,and the system can support various theoretical pproaches(which may be required by various languages, or whichmay be the best way to foster collaborations among roupswith different research methodologies).MT system modules are either theory-neutral or theory-based.
Theory-neutral modules are typically receptacles ofbasic information, such as core lexicons, morphologicalinformation, models of the application domain, domainlexicons, etc.
Theory-based modules are modules whoseconstruction and performance depends on a particulartheoretical approach (of Linguistics, semantics, etc.
);typical instances are parsers, generators, and theory-basedgrammars.In order to limit redundancy, this proposal calls for thestraightforward incorporation of existing theory-neutralmodules from any available source.
Various lexicons andsome theory-neutral grammars of several languages exist inthe public domain.
Only when such information isunavailable, or when the available information is notstructured in a useful way, should a new module beconstructed.
In such cases, the proposal calls for theconstruction of a single module, to be shared by allparticipants in the MT program.Some modules, however, must be structured to conformto the requirements of a particular theoretical pproach.
Inorder to allow various approaches to participate (and betested) in the MT program, the proposal calls for theparallel construction of various theory-based modules thatperform the same function.
Different modules will beconstructed at different sites, but the enforcement of anintermodule communication protocol will ensure that themodules are mutually replaceable.To summarize the modularity issue, we propose toenforce standard interfaces, modular development andmaintenance in the following dimensions:?
Modular knowledge bases?
Common "top" of ontology across all domainsCombinable "subworld" ontologies for specific domainsNo language-specific info in knowledge bases, onlydomain info.?
Modular unification-grammar files?
High-level well-structured grammars for each languageNo domain-specific info in any language specification?
Unifying grammar compiler (or interpreter)374?
Takes language, domain and dictionary to produce run-time working MT system No human eeds to cope withthe output object code of unifying compiler, in the sameway that no one needs to look at output of ADAcompiler once verified.The advantages of this modular approach include thefollowing:1.Various projects and various theoretical approacheswill be able to participate.2.Projects need not have experience in all aspects ofMT to participate.3.Redundant development of modules will beeliminated.4.Interproject collaboration will be stimulatedthroughout the U.S.5.The common goal of translation will provide a morecoherent focus for the various research endeavors andwill facilitate the comparison of various approachesto tease out their slrengths and weaknesses.6.As new and promising projects are found, they canbe included into the program.7.The theory-neutral modules, all in a standard form,will be made available to the whole NLP communityas a basic resource.8.Large-scale l xicons, automatically constructed fromtext, can be used in parsing and generation and ininteractive help.9.Existing work on collocation, cooccurrence, andclustering of words and phrases can be put to use(for example, to guide lexicon construction).The attached "mountain" figure shows a possiblecooperation being established between the Center forMachine Translation (Carnegie Mellon University), theComputing Research Laboratory (New Mexico StateUniversity) and the Information Sciences Institute(University of Southern California), whose groups shareboth experience of MT and the above assumptions.Figure- mountain shows the anticipated modules, startingfrom the bottom left-hand comer upward (parsing) goingup, and then down again to the bottom right (generation).The approximate number of modules and the sites withexpertise in them are indicated, with the sites responsiblefor the module in larger font.
Boxes in the middle representthe tasks of knowledge acquisition and system integration,also annotated with ressponsible sites.Gradual ImprovementIt is important o note that not all modules will berequired for the MAT system to run.
A number of themore experimental aspects can be "short-circuited",resulting in a leaner representation f the input text (andweaker output, or correspondingly more work for theaugmentor or post-editor).
We plan to adopt he policy offirst creating a machine-aided translation system and thengradually enhance the levels of automation in thesubsequent versions by implementing new descriptiveIn order to harness the NLP research potential in thiscountry, a modular approach to the construction ofprototype MT systems is proposed.
Under this approach,various sites will build various modules which can beassembled in various ways to construct various prototypesystems.Two advantages of the modular approach are: newlanguages and additional functionalities such as gisting canbe added with minimal disruption to the existing system,and the system can support various theoretical pproaches(which may be required by various languages, or whichmay be the best way to foster collaborations among roupswith different research methodologies).MT system modules are either theory-neutral or theory-based.
Theory-neutral modules are typically receptacles ofbasic information, such as core lexicons, morphologicalinformation, models of the application domain, domainlexicons, etc.
Theory-based modules are modules whoseconstruction and performance depends on a particulartheoretical approach (of Linguistics, semantics, etc.
);typical instances are parsers, generators, and theory-basedgrammars.In order to limit redundancy, this proposal calls for thestraightforward incorporation of existing theory-neutralmodules from any available source.
Various lexicons andsome theory-neutral grammars of several languages exist inthe public domain.
Only when such information isunavailable, or when the available information is notstructured in a useful way, should a new module beconstructed.
In such cases, the proposal calls for theconstruction of a single module, to be shared by allparticipants in the MT program.Some modules, however, must be structured to conformto the requirements of a particular theoretical pproach.
Inorder to allow various approaches to participate (and betested) in the MT program, the proposal calls for theparallel construction of various theory-based modules thatperform the same function.
Different modules will beconstructed at different sites, but the enforcement of anintermodule communication protocol will ensure that themodules are mutually replaceable.To summarize the modularity issue, we propose toenforce standard interfaces, modular development andmaintenance in the following dimensions:*Modular knowledge bases*Common "top" of ontology across all domainsCombinable "subworld" ontologies for specific domainsNo language-specific info in knowledge bases, onlydomain info.
*Modular unification-grammar files*High-level well-structured grammars for each languageNo domain-specific info in any language specification*Unifying grammar compiler (or interpreter)375*Takes language, domain and dictionary to produce run-time working MT system No human eeds to cope withthe output object code of unifying compiler, in the sameway that no one needs to look at output of ADAcompiler once verified.The advantages of this modular approach include thefollowing:1.Various projects and various theoretical approacheswill be able to participate.2.Projects need not have experience in all aspects ofMT to participate.3.Redundant development of modules will beeliminated.4.Interproject collaboration will be stimulatedthroughout the U.S.5.The common goal of translation will provide a morecoherent focus for the various research endeavors andwill facilitate the comparison of various approachesto tease out their strengths and weaknesses.6.As new and promising projects are found, they canbe included into the program.7.The theory-neutral modules, all in a standard form,will be made available to the whole NLP communityas a basic resource.8.I.arge-scale xicons, automatically constructed fromtext, can be used in parsing and generation and ininteractive help.9.Existing work on collocation, cooccurrence, andclustering of words and phrases can be put to use(for example, to guide lexicon construction).The attached "mountain" figure shows a possiblecooperation being established between the Center forMachine Translation (Carnegie Mellon University), theComputing Research Laboratory (New Mexico StateUniversity) and the Information Sciences Institute(University of Southern California), whose groups shareboth experience of MT and the above assumptions.Figure-.
mountain shows the anticipated modules, startingfrom the bottom left-hand comer upward (parsing) goingup, and then down again to the bottom right (generation).The approximate number of modules and the sites withexpertise in them are indicated, with the sites responsiblefor the module in larger font.
Boxes in the middle representthe tasks of knowledge acquisition and system integration,also annotated with responsible sites.Gradual ImprovementIt is important o note that not all modules will berequired for the MAT system to run.
A number of themore experimental aspects can be "short-circuited",resulting in a leaner representation f the input text (andweaker output, or correspondingly more work for theaugmentor or post.editor).
We plan to adopt he policy offirst creating a machine-aided translation system and thengradually enhance the levels of automation in thesubsequent versions by implementing new descriptiveWorld KnowledgeOurs is an AI approach in that we shall, in processingexpressions so as to select a particular interpretation, applycomputationally expressed knowledge of the world, as wellas our knowledge of language.
We thus select the mostsensible interpretation of ambiguous expressions,recovering the most sensible referents for pronouns andinferring information which is implicit.
This knowledge ofthe world is general in the sense that we know a great dealabout objects, actions, states, events and situations, uch asthe classes to which they belong and the attributes theypossess.
Through the application of such knowledge, weweed out incoherent interpretations a they develop andselect the most appropriate interpretation from those thatsurvive.Commonsense Semantics and PragmaticsA crucial component is a realistic pragmatics, bringingin the best of AI work on speech act, belief etc.phenomena.
These are now tractable and usable notions inMT systems.
We shall commit ourselves to commonsensesemantic approaches rather than formal ones since thesehave not proved fruitful in MT in any language.
This willalso involve a commitment to algorithmic elements of AI-based semantics (such as Preference Semantics) that havealready proved useful in message-understanding work, andhave an intimate connection with understanding of ill-formed, metaphor-laden text that is the normal form ofactual documents.In order to build working, portable prototype systems,the most practical and useful notations must be.
used.
Asmentioned above, the selection of notations whoseproperties are desirable on formal grounds but whosepractical utility is low will be avoided.In order to produce MT of superior quality that existingsystems, one of the most powerful key ideas is the use ofdiscourse-related and pragmatic terms.
Most MT systemsoperate on a sentence-by-sentence basis only; they take noaccount of the discourse structure.
Given recent work ondiscourse structure at various centers in the U.S., structuralinformation should be taken into account and can be usedto improve the quality of the translation.
Similarly,pragmatic information, such as Speech Acts, referencetreatment, and perhaps even some stylistic notions (to theextent that notations have been developed to representthem) will be used to improve the quality of the translation.ScaleWe emphasize scale phenomena, both in the sense ofbringing large-scale lexical material automatically viaexisting work on machine readable dictionaries, but alsomaking use where possible of statistically-based work oncorpora to guide lexical entry selection, corrigibility ofsentences toparticular syntax rules etc.Portability?
Construct reusable tools, general informationrepositories (e.g., lexicons, grammars)* Establish nationwide resources in standard form?
Ensure future reusability?
Construct reusable tools, general informationrepositories (e.g., lexicons, grammars)?
Establish nationwide resources in standard form?
Ensure future reusabilityOne of the well-known weaknesses of current MTsystems is their limited applicability.
In order to achieve anacceptable level of translation quality, the current brute-force approaches require large collections of translationrules which invariably contain increasingly domain-specificinformation.
Porting these systems to a new domainbecomes a major undertaking.By using the newest NLP technology while focusing onthe development and use of a number of very generalinformation resources (such as a high-level conceptontology under which domain-specific ontologies aresubordinated, and a general lexicon for closed-class words),this proposal is aimed at overcoming the problem ofdomain-dependence without compromising on translationquality.A major factor supporting the domain-independence isthe ability to acquire information --- conceptual, exical,phrasal, translational - - interactively during the translationprocess.
When the system encounters input it cannothandle, it queries the human assistant, who decides whattype of information the input is and then inserts appropriatedefinitions into the system's information banks for futureuse, using the interfaces and acquisition tools provided.The proposed MT program devotes a ~arge amount ofeffort on the development of interactive acquisitionsoftware and interfaces, via the notions of the Translator'sand Lexicologist's workstations.The strengths and weaknesses of this interlinguai approachThe strengths of the interlingua pproach have beenbriefly discussed above.The central weakness is the necessity to build aknowledge base, and therefore the initial development cost,though it can be amortized over other languages, and manytranslations in the context of a well-engineered modularsystem.We would like now to defend the interlingua pproachagainst three most commonly held negative opinions.OPINION 1: An interlingual approach forces unneededprocessingIf a source language has, say, an expression which is three waysambiguous and some target language has an expression which hasprecisely the same three-way ambiguity, unanalyzed why not simplycarry the ambiguity from the source to the target and let the reader376figure it out?
Why disarnbiguate needlessly?The response is, on the one hand, that a third languageprobably has different expression for each of the possibleinterpretations, so that if the same representationalapparatus is to be applied to translations between thesource language and a third language or from the targetlanguage and a third language, such processing is necessaryin any case.
On the other hand, a quick inspection ofbilingual dictionaries shows that cases of completecorrespondence of ambiguity across languages i  extremelyrare, even in closely related languages uch as German andDutch.The issue of "since we sometimes can get away withless processing, why risk doing unnecessary work?"
can becompared with intelligence-gathering work, where much ofthe effort is routine; information often confirmsexpectations; and therefore much of the work is"unnecessary."
With such an attitude, all unexpected,important intelligence would often be ignored, much to thedetriment of the analysts and policymakers.
Ignoringmeaning in translation because it need not always beinterpreted, is an equally flawed philosophy.
The timeswhen deeper analysis is required can be absolutely crucialto produce meaningful, rather than misleading, translations.language particular bias would simply be defect of theapproach, rather than wholly invalidating it.A standard example here would be the case of the verb"wear" in English and the problem of expressing thenotion in Japanese or Chinese.
It so happens that inJapanese the corresponding verb depends entirely on whatis worn e.g.
shoes (verb= hateiru ), coat (verb= kiteiru ),spectacles (verb= kaketeiru ) and so on (and similarly forChinese).
It is thus reasonable to say that Japanese does nothave a concept of "wear" in the way English does.However, that observation is no kind of argument at allagainst an interlingual approach, merely one for intelligentgeneration.
In an interlingual environment there will be atleast one interlingual node (which may or may notcorrespond to "wear") that links the relevant senserepresentations.
The crucial point is that it would be theintelligent Japanese generator (since no problem arises inthe Japanese to English direction) that makes the choice ofoutput verb based simply on selection semantics (e.g.
if theworn object is "koutoo" the verb is "kiteiru" and so on).ConclusionThere are several aspects of the knowledge-basedinterlingua MT project that incur a measure of risk.Foremost among these is the distributed management riskOPINION 2: Interlingual approaches are heavily knowledgeamong the three centers.dependent and the task of working out appropriaterepresentations i too demanding to be practical.It has been our experience that some, even ifincomplete, level of knowledge representation is crucial tomachine translation.
The need for such knowledge isespecially obvious in the translation of technical text,where translations based on a general knowledge of theworld are markedly inferior to translations based on aspecific knowledge of the subject domain of the translation.Large-scale know.ledge bases are being actively developedin the field, and domain models have come to beconsidered a standard component of many AI-relatedapplication systems.
In our system, acquisition of worldknowledge will be an ongoing task, and we fully intend toprove the feasibility of working with large knowledgebases in practical terms.
To wit, EDR laboratories, andFujitsu in Japan have come to the same conclusion and areactively building large knowledge-bases for interlingua-based machine translation, with initial success.Although it is clearly in thenational interest o establish several sites developing MTtechnology in mutual cooperation, special effort must bemade to address communication, establishment ofstandards, mutual responsibility relationships, fall-backpositions and so on.
We think this is an eminentlymanageable risk, but nonetheless a omnipresent one.
Weare fully cognizant of this risk, and are prepared tominimize it by establishing common procedures, open linesof communication, and accommodation where necessary.OPINION 3: interlingual approaches are based on aparticular language, thus creating unnatural analysesfor other languages.This is the "cultural imperialism" argument.
If,however, there exists such a thing as a universal descriptivelinguistic framework, then there is no reason to assume thatlanguage imperialism must be a side-effect of theinterlingual approach.
Our experience in the developmentof an interlingual representation based on a cross-linguisticcomparison of parallel texts has indicated, at least, thatsuch a language independent framework is possible.
Buteven if no such framework exists, then at worst, such377\r - ' -'9..- -~.o  ,nF~gm'e 1:MAT Sys~m ModuMs.378
