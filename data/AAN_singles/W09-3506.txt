Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 36?39,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPMachine Transliteration using Target-Language Grapheme andPhoneme: Multi-engine Transliteration ApproachJong-Hoon Oh, Kiyotaka Uchimoto, and Kentaro TorisawaLanguage Infrastructure Group, MASTAR Project,National Institute of Information and Communications Technology (NICT)3-5 Hikaridai Seika-cho, Soraku-gun, Kyoto 619-0289 Japan{rovellia,uchimoto,torisawa}@nict.go.jpAbstractThis paper describes our approach to?NEWS 2009 Machine TransliterationShared Task.?
We built multiple translit-eration engines based on different combi-nations of two transliteration models andthree machine learning algorithms.
Then,the outputs from these transliteration en-gines were combined using re-rankingfunctions.
Our method was applied to alllanguage pairs in ?NEWS 2009 MachineTransliteration Shared Task.?
The officialresults of our standard runs were rankedthe best for four language pairs and thesecond best for three language pairs.1 OutlineThis paper describes our approach to ?NEWS2009 Machine Transliteration Shared Task.
?Our approach was based on two transliterationmodels ?
TM-G (Transliteration model basedon target-language Graphemes) and TM-GP(Transliteration model based on target-languageGraphemes and Phonemes).
The differencebetween the two models lies in whether ornot a machine transliteration process dependson target-language phonemes.
TM-G directlyconverts source-language graphemes into target-language graphemes, while TM-GP first trans-forms source language graphemes into target-language phonemes and then target-languagephonemes coupled with their correspondingsource-language graphemes are converted intotarget-language graphemes.
We used three dif-ferent machine learning algorithms (conditionalrandom fields (CRFs), margin infused relaxed al-gorithm (MIRA), and maximum entropy model(MEM)) (Berger et al, 1996; Crammer andSinger, 2003; Lafferty et al, 2001) for build-ing multiple machine transliteration engines.
Weattempted to improve the transliteration qualityby combining the outputs of different machinetransliteration engines operating on the same in-put.
Our approach was applied to all languagepairs in ?NEWS 2009 Machine TransliterationShared Task.?
The official results of our approachwere ranked as the best for four language pairs andthe second best for three language pairs (Li et al,2009a).2 Transliteration ModelLet S be a source-language word and T be a target-language transliteration of S. T is represented intwo ways ?
TG, a sequence of target-languagegraphemes, and TP , a sequence of target-languagephonemes.
Here, a target-language grapheme isdefined as a target-language character.
We regardconsonant and vowel parts in the romanized formof a target language grapheme as a target-languagephoneme.
Then TM-G and TM-GP are formu-lated as Eq (1) and (2), respectively.PTM?G(T |S) = P (TG|S) (1)PTM?GP (T |S) (2)=?
?TPP (TP |S) ?
P (TG|TP , S)JaChEn?:I?:I?:B?:I?:I?:B?
:B TGNUDNILKETP?
:B ?:I?
:B ?
:B ?:I?
:B ?
:B TGNOTNIRKUTPnotnilCSClintonKELINDUN KURINTON???
?????ClintonClinton???
????
?ClintonTM-G TM-GPFigure 1: Illustration of the two transliterationmodels36Figure 1 illustrates the two transliteration mod-els with examples, Clinton and its Chineseand Japanese transliterations.
Target languagegraphemes are represented in terms of the BIO no-tation.
This makes it easier to represent many-to-one correspondence between target languagephoneme and grapheme.3 Machine Learning AlgorithmsA machine transliteration problem can be con-verted into a sequential labeling problem, whereeach source-language grapheme is tagged with itscorresponding target-language grapheme.
Thissection briefly describes the machine learning al-gorithms used for building multiple transliterationengines.3.1 Maximum Entropy ModelMachine transliteration based on the maximumentropy model was described in detail in Oh et al(2006) along with comprehensive evaluation of itsperformance.
We used the same way as that pro-posed by Oh et al (2006), thus its full descriptionis not presented here.3.2 Conditional Random Fields (CRFs)CRFs, a statistical sequence modeling framework,was first introduced by Lafferty et al (2001).CRFs has been used for sequential labeling prob-lems such as text chunking and named entityrecognition (McCallum and Li, 2003).
CRF++1was used in our experiment.3.3 Margin Infused Relaxed AlgorithmThe Margin Infused Relaxed Algorithm (MIRA)has been introduced by Crammer and Singer(2003) for large-margin multi-class classification.Kruengkrai et al (2008) proposed a discriminativemodel for joint Chinese segmentation and POStagging, where MIRA was used as their machinelearning algorithm.
We used the same model forour machine transliteration, exactly joint syllabi-cation2 and transliteration.3.4 FeaturesWe used the following features within the ?3 con-text window3 for the above mentioned three ma-1Available at http://crfpp.sourceforge.net/2A syllable in English is defined as a sequence of Englishgrapheme corresponding to one target-language grapheme.3The unit of context window is source-languagegrapheme or syllable.chine learning algorithms.?
Left-three and right-three source-languagegraphemes (or syllables)?
Left-three and right-three target-languagephonemes?
Target-language graphemes assigned to theprevious three source-language graphemes(or syllables)4 Multi-engine Transliteration4.1 Individual Transliteration EngineThe main aim of the multi-engine transliterationapproach is to combine the outputs of multiple en-gines so that the final output is better in qualitythan the output of each individual engine.
Wedesigned four transliteration engines using dif-ferent combinations of source-language translit-eration units, transliteration models, and machinelearning algorithms as listed in Table 1.
We namedfour transliteration engines as CRF-G, MEM-G,MEM-GP, and MIRA-G.
Here, the prefixes rep-resent applied machine learning algorithms (max-imum entropy model (MEM), CRFs, and MIRA),while G and GP in the suffix represent the translit-eration models, TM-G and TM-GP, respectively.Each individual engine produces 30-best translit-erations for a given source-language word.Source-language transliteration unitGrapheme SyllableTM-G ME-G, CRF-G MIRA-GTM-GP ME-GP N/ATable 1: Design strategy for multiple translitera-tion engines4.2 Combining MethodologyWe combined the outputs of multiple translitera-tion engines by means of a re-ranking function,g(x).
Let X be a set of transliterations gener-ated by multiple transliteration engines for source-language word s and ref be a reference translit-eration of s. A re-ranking function is defined asEq.
(3), where it ranks ref in X higher and theothers lower (Oh and Isahara, 2007).g(x) : X ?
{r : r is ordering of x ?
X} (3)We designed two types of re-ranking functions byusing the rank of each individual engine and ma-chine learning algorithm.374.2.1 Re-ranking Based on the Rank ofIndividual EnginesTwo re-ranking functions based on the rank ofeach individual engine, grank and gFscore(x),are used for combining the outputs of multipletransliteration engines.
Let X be a set of outputsof N transliteration engines for the same input.grank(x) re-ranks x ?
X in the manner shownin Eq.
(4), where Ranki(x) is the position of x inthe n-best list generated by the ith transliterationengine.
grank(x) can be interpreted as the averagerank of x over outputs of each individual engine.If x is not in the n-best list of the ith transliterationengine, 1Ranki(x) = 0.grank(x) =1NN?i=11Ranki(x)(4)gFscore(x) is based on grank(x) and the F-score measure, which is one of the evaluation met-rics in the ?NEWS 2009 Machine TransliterationShared Task?
(Li et al, 2009b).
We consideredthe top three outputs of each individual engineas reference transliterations and defined them asvirtual reference transliterations.
We calculatedthe F-score measure between the virtual referencetransliteration and each output of multiple translit-eration engines.
gFscore(x) is defined by Eq.
(5),where VRef is a set of virtual reference transliter-ations, and Fscore(vr, x) is a function that restoresthe F-score measure between vr and x.gFscore(x) = grank(x) ?MF (x) (5)MF (x) =1|V Ref |?vr?V RefFscore(vr, x)Since the F-score measure is calculated in terms ofstring similarity, x gets a high score from gMF (x)when it is orthographically similar to virtual refer-ence transliterations.4.2.2 Re-ranking based on Machine LearningAlgorithmWe used the maximum entropy model for learn-ing re-ranking function gME(x).
Let ref be a ref-erence transliteration of source-language word s,feature(x) be a feature vector of x ?
X , andy ?
{ref, wrong} be the training label for x.gME(x) assigns a probability to x ?
X as shownin Eq.
(6).gME(x) = P (ref |feature(x)) (6)A feature vector of x is composed of?
?grank(x), gFscore(x), 1Ranki(x) , P (T |S)?where 1Ranki(x) and P (T |S) of each individual en-gine are used as a feature.We estimated P (ref |feature(x)) by using thedevelopment data.5 Our Results5.1 Individual EngineCRF-G MEM-G MEM-GP MIRA-GEnCh 0.628 0.686 0.715 0.684EnHi 0.455 0.469 0.469 0.412EnJa 0.514 0.517 0.519 0.490EnKa 0.386 0.380 0.380 0.338EnKo 0.460 0.438 0.447 0.367EnRu 0.600 0.561 0.566 0.568EnTa 0.453 0.459 0.459 0.412JnJk N/A 0.532 N/A 0.571Table 2: ACC of individual engines on the test dataTable 2 presents ACC4 of individual translit-eration engines, which was applied to all lan-guage pairs in ?NEWS 2009 Machine Translit-eration Shared Task?
(Li et al, 2004; Kumaranand Kellner, 2007; The CJK Dictionary Institute,2009).
CRF-G was the best transliteration enginein EnKa, EnKo, and EnRu.
Owing to the hightraining costs of CRFs, we trained CRF-G in EnChwith a very small number of iterations5.
Hence,the performance of CRF-G was poorer than thatof the other engines in EnCh.
MEM-GP was thebest transliteration engine in EnCh, EnHi, EnJa,and EnTa.
These results indicate that joint useof source language graphemes and target languagephonemes were very useful for improving perfor-mance.
MIRA-G was sensitive to the training datasize, because it was based on joint syllabicationand transliteration.
Therefore, the performance ofMIRA-G was relatively better in EnCh and EnJa,whose training data size is bigger than other lan-guage pairs.
CRF-G could not be applied to JnJk,mainly due to too long training time.
Further,MEM-GP could not be applied to JnJk, becausetransliteration in JnJk can be regarded as conver-sion of target language phonemes to target lan-guage graphemes.
MEM-G and MIRA-G were4Word accuracy in Top-1 (Li et al, 2009b)5We applied over 100 iterations to other language pairsbut only 30 iterations to EnCh.38applied to JnJk and MIRA-G showed the best per-formance in JnJK.65.2 Combining Multiple Enginesgrank gFscore gME I-BESTEnCh 0.730 0.731 0.731 0.715EnHi 0.481 0.475 0.483 0.469EnJa 0.535 0.535 0.537 0.519EnKa 0.393 0.399 0.398 0.386EnKo 0.461 0.444 0.473 0.460EnRu 0.602 0.605 0.600 0.600EnTa 0.470 0.478 0.474 0.459JnJk 0.597 0.593 0.590 0.571Table 3: Multi-engine transliteration results on thetest data: the underlined figures are our official re-sultTable 3 presents the ACC of our multi-enginetransliteration approach and that of the best in-dividual engine (I-BEST) in each language pair.gME gave the best performance in EnCh, EnHi,EnJa, and EnKo, while gFscore did in EnCh, EnKa,EnRu, and EnTa.
Comparison between the bestindividual transliteration engine and our multi-engine transliteration showed that grank and gMEconsistently showed better performance except inEnRu, while gFscore showed the poorer perfor-mance in EnKo.
The results to be submitted as?the standard run?
were selected among the re-sults listed in Table 3 by using cross-validation onthe development data.
We submitted the results ofgME as the standard run to ?NEWS 2009 MachineTransliteration Shared Task?
for the six languagepairs in Table 3, while the result of gFscore is sub-mitted as the standard run for EnRu.
The officialresults of our standard runs were ranked the bestfor EnCh, EnJa, EnKa, and EnTa, and the secondbest for EnHi, EnKo, and EnRu (Li et al, 2009a).6 ConclusionIn conclusion, we have applied multi-enginetransliteration approach to ?NEWS 2009 MachineTransliteration Shared Task.?
We built multipletransliteration engines based on different com-binations of transliteration models and machinelearning algorithms.
We showed that the translit-eration model, which is based on target language6We submitted the results of MEM-G as a standard run forJnJk because we had only one transliteration engine for JnJKbefore the submission deadline of the NEWS 2009 machinetransliteration shared task.graphemes and phonemes, and our multi-enginetransliteration approach are effective, regardless ofthe nature of the language pairs.ReferencesA.
L. Berger, S. D. Pietra, and V. J. D. Pietra.
1996.
Amaximum entropy approach to natural language pro-cessing.
Computational Linguistics, 22(1):39?71.Koby Crammer and Yoram Singer.
2003.
Ultracon-servative online algorithms for multiclass problems.Journal of Machine Learning Research, 3:951?991.Canasai Kruengkrai, Jun?ichi Kazama, Kiyotaka Uchi-moto, Kentaro Torisawa, and Hitoshi Isahara.
2008.A discriminative hybrid model for joint Chineseword segmentation and pos tagging.
In Proc.
of The11th Oriental COCOSDA Workshop.A.
Kumaran and Tobias Kellner.
2007.
A genericframework for machine transliteration.
In Proc.
ofSIGIR ?07, pages 721?722.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.
In Proc.
of ICML01, pages 282?289.Haizhou Li, Min Zhang, and Su Jian.
2004.
A jointsource-channel model for machine transliteration.In Proc.
of ACL ?04, pages 160?167.Haizhou Li, A Kumaran, Vladimir Pervouchine, andMin Zhang.
2009a.
Report on NEWS 2009 machinetransliteration shared task.
In Proc.
of ACL-IJCNLP2009 Named Entities Workshop.Haizhou Li, A Kumaran, Min Zhang, and VladimirPervouchine.
2009b.
Whitepaper of NEWS 2009machine transliteration shared task.
In Proc.
ofACL-IJCNLP 2009 Named Entities Workshop.Andrew McCallum and Wei Li.
2003.
Early results fornamed entity recognition with conditional randomfields, feature induction and web-enhanced lexicons.In Proc.
of CoNLL ?03, pages 188?191.Jong-Hoon Oh and Hitoshi Isahara.
2007.
Machinetransliteration using multiple transliteration enginesand hypothesis re-ranking.
In Proc.
of the 11th Ma-chine Translation Summit, pages 353?360.Jong-Hoon Oh, Key-Sun Choi, and Hitoshi Isahara.2006.
A comparison of different machine transliter-ation models.
Journal of Artificial Intelligence Re-search (JAIR), 27:119?151.The CJK Dictionary Institute.
2009. http://www.cjk.org.39
