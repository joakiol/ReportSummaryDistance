Proceedings of the ACL 2010 Conference Short Papers, pages 68?73,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsThe Manually Annotated Sub-Corpus:A Community Resource For and By the PeopleNancy IdeDepartment of Computer ScienceVassar CollegePoughkeepsie, NY, USAide@cs.vassar.eduCollin BakerInternational Computer Science InstituteBerkeley, California USAcollinb@icsi.berkeley.eduChristiane FellbaumPrinceton UniversityPrinceton, New Jersey USAfellbaum@princeton.eduRebecca PassonneauColumbia UniversityNew York, New York USAbecky@cs.columbia.eduAbstractThe Manually Annotated Sub-Corpus(MASC) project provides data and annota-tions to serve as the base for a community-wide annotation effort of a subset of theAmerican National Corpus.
The MASCinfrastructure enables the incorporation ofcontributed annotations into a single, us-able format that can then be analyzed asit is or ported to any of a variety of otherformats.
MASC includes data from amuch wider variety of genres than exist-ing multiply-annotated corpora of English,and the project is committed to a fullyopen model of distribution, without re-striction, for all data and annotations pro-duced or contributed.
As such, MASCis the first large-scale, open, community-based effort to create much needed lan-guage resources for NLP.
This paper de-scribes the MASC project, its corpus andannotations, and serves as a call for con-tributions of data and annotations from thelanguage processing community.1 IntroductionThe need for corpora annotated for multiple phe-nomena across a variety of linguistic layers iskeenly recognized in the computational linguisticscommunity.
Several multiply-annotated corporaexist, especially for Western European languagesand for spoken data, but, interestingly, broad-based English language corpora with robust anno-tation for diverse linguistic phenomena are rela-tively rare.
The most widely-used corpus of En-glish, the British National Corpus, contains onlypart-of-speech annotation; and although it con-tains a wider range of annotation types, the fif-teen million word Open American National Cor-pus annotations are largely unvalidated.
The mostwell-known multiply-annotated and validated cor-pus of English is the one million word Wall StreetJournal corpus known as the Penn Treebank (Mar-cus et al, 1993), which over the years has beenfully or partially annotated for several phenomenaover and above the original part-of-speech taggingand phrase structure annotation.
The usability ofthese annotations is limited, however, by the factthat many of them were produced by independentprojects using their own tools and formats, mak-ing it difficult to combine them in order to studytheir inter-relations.
More recently, the OntoNotesproject (Pradhan et al, 2007) released a one mil-lion word English corpus of newswire, broadcastnews, and broadcast conversation that is annotatedfor Penn Treebank syntax, PropBank predicate ar-gument structures, coreference, and named enti-ties.
OntoNotes comes closest to providing a cor-pus with multiple layers of annotation that can beanalyzed as a unit via its representation of the an-notations in a ?normal form?.
However, like theWall Street Journal corpus, OntoNotes is limitedin the range of genres it includes.
It is also limitedto only those annotations that may be produced bymembers of the OntoNotes project.
In addition,use of the data and annotations with software otherthan the OntoNotes database API is not necessar-ily straightforward.The sparseness of reliable multiply-annotatedcorpora can be attributed to several factors.
Thegreatest obstacle is the high cost of manual pro-duction and validation of linguistic annotations.Furthermore, the production and annotation ofcorpora, even when they involve significant scien-tific research, often do not, per se, lead to publish-able research results.
It is therefore understand-68able that many research groups are unwilling toget involved in such a massive undertaking for rel-atively little reward.The Manually Annotated Sub-Corpus(MASC) (Ide et al, 2008) project has beenestablished to address many of these obstaclesto the creation of large-scale, robust, multiply-annotated corpora.
The project is providingappropriate data and annotations to serve as thebase for a community-wide annotation effort,together with an infrastructure that enables therepresentation of internally-produced and con-tributed annotations in a single, usable formatthat can then be analyzed as it is or ported to anyof a variety of other formats, thus enabling itsimmediate use with many common annotationplatforms as well as off-the-shelf concordanceand analysis software.
The MASC project?s aim isto offset some of the high costs of producing highquality linguistic annotations via a distribution ofeffort, and to solve some of the usability problemsfor annotations produced at different sites byharmonizing their representation formats.The MASC project provides a resource that issignificantly different from OntoNotes and simi-lar corpora.
It provides data from a much widervariety of genres than existing multiply-annotatedcorpora of English, and all of the data in the cor-pus are drawn from current American English soas to be most useful for NLP applications.
Per-haps most importantly, the MASC project is com-mitted to a fully open model of distribution, with-out restriction, for all data and annotations.
It isalso committed to incorporating diverse annota-tions contributed by the community, regardless offormat, into the corpus.
As such, MASC is thefirst large-scale, open, community-based effort tocreate a much-needed language resource for NLP.This paper describes the MASC project, its corpusand annotations, and serves as a call for contribu-tions of data and annotations from the languageprocessing community.2 MASC: The CorpusMASC is a balanced subset of 500K words ofwritten texts and transcribed speech drawn pri-marily from the Open American National Corpus(OANC)1.
The OANC is a 15 million word (andgrowing) corpus of American English producedsince 1990, all of which is in the public domain1http://www.anc.orgGenre No.
texts Total wordsEmail 2 468Essay 4 17516Fiction 4 20413Gov?t documents 1 6064Journal 10 25635Letters 31 10518Newspaper/newswire 41 17951Non-fiction 4 17118Spoken 11 25783Debate transcript 2 32325Court transcript 1 20817Technical 3 15417Travel guides 4 12463Total 118 222488Table 1: MASC Composition (first 220K)or otherwise free of usage and redistribution re-strictions.Where licensing permits, data for inclusion inMASC is drawn from sources that have alreadybeen heavily annotated by others.
So far, thefirst 80K increment of MASC data includes a40K subset consisting of OANC data that hasbeen previously annotated for PropBank predi-cate argument structures, Pittsburgh Opinion an-notation (opinions, evaluations, sentiments, etc.
),TimeML time and events2, and several other lin-guistic phenomena.
It also includes a handful ofsmall texts from the so-called Language Under-standing (LU) Corpus3 that has been annotated bymultiple groups for a wide variety of phenomena,including events and committed belief.
All of thefirst 80K increment is annotated for Penn Tree-bank syntax.
The second 120K increment includes5.5K words of Wall Street Journal texts that havebeen annotated by several projects, including PennTreebank, PropBank, Penn Discourse Treebank,TimeML, and the Pittsburgh Opinion project.
Thecomposition of the 220K portion of the corpus an-notated so far is shown in Table 1.
The remain-ing 280K of the corpus fills out the genres that areunder-represented in the first portion and includesa few additional genres such as blogs and tweets.3 MASC AnnotationsAnnotations for a variety of linguistic phenomena,either manually produced or corrected from outputof automatic annotation systems, are being added2The TimeML annotations of the data are not yet com-pleted.3MASC contains about 2K words of the 10K LU corpus,eliminating non-English and translated LU texts as well astexts that are not free of usage and redistribution restrictions.69Annotation type Method No.
texts No.
wordsToken Validated 118 222472Sentence Validated 118 222472POS/lemma Validated 118 222472Noun chunks Validated 118 222472Verb chunks Validated 118 222472Named entities Validated 118 222472FrameNet frames Manual 21 17829HSPG Validated 40* 30106Discourse Manual 40* 30106Penn Treebank Validated 97 87383PropBank Validated 92 50165Opinion Manual 97 47583TimeBank Validated 34 5434Committed belief Manual 13 4614Event Manual 13 4614Coreference Manual 2 1877Table 2: Current MASC Annotations (* projected)to MASC data in increments of roughly 100Kwords.
To date, validated or manually producedannotations for 222K words have been made avail-able.The MASC project is itself producing annota-tions for portions of the corpus forWordNet sensesand FrameNet frames and frame elements.
To de-rive maximal benefit from the semantic informa-tion provided by these resources, the entire cor-pus is also annotated and manually validated forshallow parses (noun and verb chunks) and namedentities (person, location, organization, date andtime).
Several additional types of annotation haveeither been contracted by the MASC project orcontributed from other sources.
The 220K wordsofMASC I and II include seventeen different typesof linguistic annotation4, shown in Table 2.All MASC annotations, whether contributed orproduced in-house, are transduced to the GraphAnnotation Framework (GrAF) (Ide and Suder-man, 2007) defined by ISO TC37 SC4?s LinguisticAnnotation Framework (LAF) (Ide and Romary,2004).
GrAF is an XML serialization of the LAFabstract model of annotations, which consists ofa directed graph decorated with feature structuresproviding the annotation content.
GrAF?s primaryrole is to serve as a ?pivot?
format for transducingamong annotations represented in different for-mats.
However, because the underlying data struc-ture is a graph, the GrAF representation itself canserve as the basis for analysis via application of4This includes WordNet sense annotations, which are notlisted in Table 2 because they are not applied to full texts; seeSection 3.1 for a description of the WordNet sense annota-tions in MASC.graph-analytic algorithms such as common sub-tree detection.The layering of annotations over MASC textsdictates the use of a stand-off annotation repre-sentation format, in which each annotation is con-tained in a separate document linked to the pri-mary data.
Each text in the corpus is provided inUTF-8 character encoding in a separate file, whichincludes no annotation or markup of any kind.Each file is associated with a set of GrAF standofffiles, one for each annotation type, containing theannotations for that text.
In addition to the anno-tation types listed in Table 2, a document contain-ing annotation for logical structure (titles, head-ings, sections, etc.
down to the level of paragraph)is included.
Each text is also associated with(1) a header document that provides appropriatemetadata together with machine-processable in-formation about associated annotations and inter-relations among the annotation layers; and (2) asegmentation of the primary data into minimal re-gions, which enables the definition of different to-kenizations over the text.
Contributed annotationsare also included in their original format, whereavailable.3.1 WordNet Sense AnnotationsA focus of the MASC project is to provide corpusevidence to support an effort to harmonize sensedistinctions in WordNet and FrameNet (Baker andFellbaum, 2009), (Fellbaum and Baker, to appear).The WordNet and FrameNet teams have selectedfor this purpose 100 common polysemous wordswhose senses they will study in detail, and theMASC team is annotating occurrences of thesewords in the MASC.
As a first step, fifty oc-currences of each word are annotated using theWordNet 3.0 inventory and analyzed for prob-lems in sense assignment, after which the Word-Net team may make modifications to the inven-tory if needed.
The revised inventory (which willbe released as part of WordNet 3.1) is then used toannotate 1000 occurrences.
Because of its smallsize, MASC typically contains less than 1000 oc-currences of a given word; the remaining occur-rences are therefore drawn from the 15 millionwords of the OANC.
Furthermore, the FrameNetteam is also annotating one hundred of the 1000sentences for each word with FrameNet framesand frame elements, providing direct comparisonsof WordNet and FrameNet sense assignments in70attested sentences.5For convenience, the annotated sentences areprovided as a stand-alone corpus, with the Word-Net and FrameNet annotations represented instandoff files.
Each sentence in this corpus islinked to its occurrence in the original text, so thatthe context and other annotations associated withthe sentence may be retrieved.3.2 ValidationAutomatically-produced annotations for sentence,token, part of speech, shallow parses (noun andverb chunks), and named entities (person, lo-cation, organization, date and time) are hand-validated by a team of students.
Each annotationset is first corrected by one student, after which itis checked (and corrected where necessary) by asecond student, and finally checked by both auto-matic extraction of the annotated data and a thirdpass over the annotations by a graduate studentor senior researcher.
We have performed inter-annotator agreement studies for shallow parses inorder to establish the number of passes required toachieve near-100% accuracy.Annotations produced by other projects andthe FrameNet and Penn Treebank annotationsproduced specifically for MASC are semi-automatically and/or manually produced by thoseprojects and subjected to their internal quality con-trols.
No additional validation is performed by theANC project.The WordNet sense annotations are being usedas a base for an extensive inter-annotator agree-ment study, which is described in detail in (Pas-sonneau et al, 2009), (Passonneau et al, 2010).All inter-annotator agreement data and statisticsare published along with the sense tags.
The re-lease also includes documentation on the wordsannotated in each round, the sense labels for eachword, the sentences for each word, and the anno-tator or annotators for each sense assignment toeach word in context.
For the multiply annotateddata in rounds 2-4, we include raw tables for eachword in the form expected by Ron Artstein?s cal-culate alpha.pl perl script6, so that the agreementnumbers can be regenerated.5Note that several MASC texts have been fully annotatedfor FrameNet frames and frame elements, in addition to theWordNet-tagged sentences.6http://ron.artstein.org/resources/calculate-alpha.perl4 MASC Availability and DistributionLike the OANC, MASC is distributed withoutlicense or other restrictions from the AmericanNational Corpus website7.
It is also availablefrom the Linguistic Data Consortium (LDC)8 fora nominal processing fee.In addition to enabling download of the entireMASC, we provide a web application that allowsusers to select some or all parts of the corpus andchoose among the available annotations via a webinterface (Ide et al, 2010).
Once generated, thecorpus and annotation bundle is made available tothe user for download.
Thus, the MASC user neednever deal directly with or see the underlying rep-resentation of the stand-off annotations, but gainsall the advantages that representation offers.
Thefollowing output formats are currently available:1. in-line XML (XCES9), suitable for use withthe BNCs XAIRA search and access inter-face and other XML-aware software;2. token / part of speech, a common input for-mat for general-purpose concordance soft-ware such as MonoConc10, as well as theNatural Language Toolkit (NLTK) (Bird etal., 2009);3.
CONLL IOB format, used in the Confer-ence on Natural Language Learning sharedtasks.115 ToolsThe ANC project provides an API for GrAF an-notations that can be used to access and manip-ulate GrAF annotations directly from Java pro-grams and render GrAF annotations in a formatsuitable for input to the open source GraphViz12graph visualization application.13 Beyond this, theANC project does not provide specific tools foruse of the corpus, but rather provides the data informats suitable for use with a variety of availableapplications, as described in section 4, togetherwith means to import GrAF annotations into ma-jor annotation software platforms.
In particular,the ANC project provides plugins for the General7http://www.anc.org8http://www.ldc.upenn.edu9XML Corpus Encoding Standard, http://www.xces.org10http://www.athel.com/mono.html11http://ifarm.nl/signll/conll12http://www.graphviz.org/13http://www.anc.org/graf-api71Architecture for Text Engineering (GATE) (Cun-ningham et al, 2002) to input and/or output an-notations in GrAF format; a ?CAS Consumer?to enable using GrAF annotations in the Un-structured Information Management Architecture(UIMA) (Ferrucci and Lally, 2004); and a corpusreader for importing MASC data and annotationsinto NLTK14.Because the GrAF format is isomorphic to in-put to many graph-analytic tools, existing graph-analytic software can also be exploited to searchand manipulate MASC annotations.
Trivial merg-ing of GrAF-based annotations involves simplycombining the graphs for each annotation, afterwhich graph minimization algorithms15 can be ap-plied to collapse nodes with edges to commonsubgraphs to identify commonly annotated com-ponents.
Graph-traversal and graph-coloring al-gorithms can also be applied in order to iden-tify and generate statistics that could reveal in-teractions among linguistic phenomena that mayhave previously been difficult to observe.
Othergraph-analytic algorithms ?
including commonsub-graph analysis, shortest paths, minimum span-ning trees, connectedness, identification of artic-ulation vertices, topological sort, graph partition-ing, etc.
?
may also prove to be useful for mininginformation from a graph of annotations at multi-ple linguistic levels.6 Community ContributionsThe ANC project solicits contributions of anno-tations of any kind, applied to any part or all ofthe MASC data.
Annotations may be contributedin any format, either inline or standoff.
All con-tributed annotations are ported to GrAF standoffformat so that they may be used with other MASCannotations and rendered in the various formatsthe ANC tools generate.
To accomplish this, theANC project has developed a suite of internal toolsand methods for automatically transducing otherannotation formats to GrAF and for rapid adapta-tion of previously unseen formats.Contributions may be emailed toanc@cs.vassar.edu or uploaded via theANC website16.
The validity of annotationsand supplemental documentation (if appropriate)are the responsibility of the contributor.
MASC14Available in September, 2010.15Efficient algorithms for graph merging exist; see,e.g., (Habib et al, 2000).16http://www.anc.org/contributions.htmlusers may contribute evaluations and error reportsfor the various annotations on the ANC/MASCwiki17.Contributions of unvalidated annotations forMASC and OANC data are also welcomed and aredistributed separately.
Contributions of unencum-bered texts in any genre, including stories, papers,student essays, poetry, blogs, and email, are alsosolicited via the ANC web site and the ANC Face-Book page18, and may be uploaded at the contri-bution page cited above.7 ConclusionMASC is already the most richly annotated corpusof English available for widespread use.
Becausethe MASC is an open resource that the commu-nity can continually enhance with additional an-notations and modifications, the project serves as amodel for community-wide resource developmentin the future.
Past experience with corpora suchas the Wall Street Journal shows that the commu-nity is eager to annotate available language data,and we anticipate even greater interest in MASC,which includes language data covering a range ofgenres that no existing resource provides.
There-fore, we expect that as MASC evolves, more andmore annotations will be contributed, thus creat-ing a massive, inter-linked linguistic infrastructurefor the study and processing of current AmericanEnglish in its many genres and varieties.
In addi-tion, by virtue of its WordNet and FrameNet anno-tations, MASC will be linked to parallel WordNetsand FrameNets in languages other than English,thus creating a global resource for multi-lingualtechnologies, including machine translation.AcknowledgmentsThe MASC project is supported by NationalScience Foundation grant CRI-0708952.
TheWordNet-FrameNet algnment work is supportedby NSF grant IIS 0705155.ReferencesCollin F. Baker and Christiane Fellbaum.
2009.
Word-Net and FrameNet as complementary resources forannotation.
In Proceedings of the Third Linguistic17http://www.anc.org/masc-wiki18http://www.facebook.com/pages/American-National-Corpus/4247422667172Annotation Workshop, pages 125?129, Suntec, Sin-gapore, August.
Association for Computational Lin-guistics.Steven Bird, Ewan Klein, and Edward Loper.2009.
Natural Language Processing with Python.O?Reilly Media, 1st edition.Hamish Cunningham, Diana Maynard, KalinaBontcheva, and Valentin Tablan.
2002.
GATE: Aframework and graphical development environmentfor robust nlp tools and applications.
In Proceedingsof ACL?02.Christiane Fellbaum and Collin Baker.
to appear.Aligning verbs in WordNet and FrameNet.
Linguis-tics.David Ferrucci and Adam Lally.
2004.
UIMA: Anarchitectural approach to unstructured informationprocessing in the corporate research environment.Natural Language Engineering, 10(3-4):327?348.Michel Habib, Christophe Paul, and Laurent Viennot.2000.
Partition refinement techniques: an interest-ing algorithmic tool kit.
International Journal ofFoundations of Computer Science, 175.Nancy Ide and Laurent Romary.
2004.
Internationalstandard for a linguistic annotation framework.
Nat-ural Language Engineering, 10(3-4):211?225.Nancy Ide and Keith Suderman.
2007.
GrAF: A graph-based format for linguistic annotations.
In Proceed-ings of the Linguistic Annotation Workshop, pages1?8, Prague, Czech Republic, June.
Association forComputational Linguistics.Nancy Ide, Collin Baker, Christiane Fellbaum, CharlesFillmore, and Rebecca Passonneau.
2008.
MASC:The Manually Annotated Sub-Corpus of AmericanEnglish.
In Proceedings of the Sixth InternationalConference on Language Resources and Evaluation(LREC), Marrakech, Morocco.Nancy Ide, Keith Suderman, and Brian Simms.
2010.ANC2Go: A web application for customized cor-pus creation.
In Proceedings of the Seventh Interna-tional Conference on Language Resources and Eval-uation (LREC), Valletta, Malta, May.
European Lan-guage Resources Association.Mitchell P. Marcus, Mary Ann Marcinkiewicz, andBeatrice Santorini.
1993.
Building a large anno-tated corpus of English: the Penn Treebank.
Com-putational Linguistics, 19(2):313?330.Rebecca J. Passonneau, Ansaf Salleb-Aouissi, andNancy Ide.
2009.
Making sense of word sensevariation.
In SEW ?09: Proceedings of the Work-shop on Semantic Evaluations: Recent Achieve-ments and Future Directions, pages 2?9, Morris-town, NJ, USA.
Association for Computational Lin-guistics.Rebecca Passonneau, Ansaf Salleb-Aouissi, VikasBhardwaj, and Nancy Ide.
2010.
Word sense an-notation of polysemous words by multiple annota-tors.
In Proceedings of the Seventh InternationalConference on Language Resources and Evaluation(LREC), Valletta, Malta.Sameer S. Pradhan, Eduard Hovy, Mitch Mar-cus, Martha Palmer, Lance Ramshaw, and RalphWeischedel.
2007.
OntoNotes: A unified relationalsemantic representation.
In ICSC ?07: Proceed-ings of the International Conference on SemanticComputing, pages 517?526, Washington, DC, USA.IEEE Computer Society.73
