Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 157?165,October 25, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsHow Synchronous are Adjuncts in Translation Data?Sophie ArnoultILLCUniversity of Amsterdams.i.arnoult@uva.nlKhalil Sima?anILLCUniversity of Amsterdamk.simaan@uva.nlAbstractThe argument-adjunct distinction is cen-tral to most syntactic and semantic the-ories.
As optional elements that refine(the meaning of) a phrase, adjuncts areimportant for recursive, compositional ac-counts of syntax, semantics and transla-tion.
In formal accounts of machine trans-lation, adjuncts are often treated as modi-fiers applying synchronously in source andtarget derivations.
But how well can theassumption of synchronous adjunction ex-plain translation equivalence in actual par-allel data?
In this paper we present thefirst empirical study of translation equiva-lence of adjuncts on a variety of French-English parallel corpora, while varyingword alignments so we can gauge the ef-fect of errors in them.
We show that forproper measurement of the types of trans-lation equivalence of adjuncts, we mustwork with non-contiguous, many-to-manyrelations, thereby amending the traditionalDirect Correspondence Assumption.
Ourempirical results show that 70% of manu-ally identified adjuncts have adjunct trans-lation equivalents in training data, againstroughly 50% for automatically identifiedadjuncts.1 IntroductionMost syntactic and semantic theories agree on theargument-adjunct distinction, although they varyon the specifics of this distinction.
Common tothese theories is that adjunction is a central de-vice for language recursion, as adjunction modi-fies initial but complete sentences by adding op-tional phrases; adjunction also contributes to se-mantic compositionality, albeit in various ways,as syntactic adjuncts may take different seman-tic roles.
Shieber and Schabes (1990) transfer therole of adjuncts from monolingual syntax (Joshiet al., 1975) to the realm of translation equiva-lence using a Synchronous Tree Adjoining Gram-mars (STAG), and propose to view adjunction asa synchronous operation for recursive, composi-tional translation.
STAG therefore relies substan-tially on what Hwa (2002) calls the Direct Corre-spondence Assumption, the notion that semanticor syntactic relations correspond across a bitext.We know from various works?notably by Hwa etal.
(2002) for dependency relations, Arnoult andSima?an (2012) for adjuncts, and Pad?o and Lap-ata (2009) and Wu and Fung (2009) for semanticroles?that the Direct Correspondence Assumptiondoes not always hold.A question that has not received much atten-tion is the degree to which the assumption ofsynchronous adjunction is supported in humantranslation data.
This is crucial for the succes-ful application of linguistically-motivated STAG,but attempts at answering this question empiricallyare hampered by a variety of difficulties.
Lin-guistic structures may diverge between languages(Dorr, 1994), translations may be more or less lit-eral, and annotation resources may be inaccurate,when they are available at all.
Besides, automaticword alignments are known to be noisy and man-ual alignments are rather scarse.
The work ofArnoult and Sima?an (2012) reports lower and up-per bounds of one-to-one adjunct correspondence,using rather limited resources to identify Frenchadjuncts making their results not directly applica-ble for measuring the stability of the synchronousadjunction assumption.In this paper we aim at redefining the transla-tion equivalence of adjuncts in ways that allow usto report far more accurate bounds on their cross-linguistic correspondence.
In particular, we are in-terested in measuring adjunct correspondence ro-bustly, in training data.Consider for example the sentence pair of Fig-157ure 1.
Most adjuncts in each sentence translateas adjuncts in the other sentence, but one of thesetranslation equivalences appears to be many-to-many, because of parsing mismatches across thebitext; both parses and adjunct labellers on bothsides of the bitext must be on par for adjunct trans-lation equivalences to be established.
Besides, onegenerally establishes translation equivalence usingword alignments, which may be noisy.
Anotherfactor is that of the degree of translation equiva-lence in the data in general; while parallel bitextsexpress the same meaning, meaning may divergelocally.I think that the time Ae1Ae6has been Ae7longtaken Ae2, for example , tooin handling Ae3applications Ae4routine for changes of facilities Ae5along a pipelineje crois qu?il a pris Af1de temps Af2trop`a ?etudier des demandes Af3de changements d?installations Af4, Af5courantes le long d?un pipe-line par exempleFigure 1: Example sentence pairThis paper contributes the first study to mea-sure the degree of adjunction synchronicity: wederive many-to-many pairings between adjunctsacross a bitext, thus supporting a generic viewof translation equivalence, where meaning canbe expressed by distinct entities and redistributedfreely in translation; practically, this also allowsus to capture equivalence in spite of mismatchedparses.
We abstract away from word alignmentsto a certain degree, as we directly pair adjunctsacross a bitext, but we still use word alignments?namely the overlap of adjunct projections with tar-get adjuncts?to decide on these pairings.
We fur-ther distinguish between adjunct pairings that arebijective through the word alignment, and otherpairings, where the translation equivalence doesnot exactly agree with the word alignment; wequalify these pairings as weakly equivalent.Under this new view of adjunct translationequivalence, we perform measures in French-English data.
We show that adjunction is pre-served in 40% to 50% of the cases with automati-cally labelled adjuncts, with differences betweendata sets, word aligners and sentence length;about 25% more adjuncts form weakly translation-equivalent pairings.
With gold adjunct annota-tions, the proportion of translation-equivalent ad-juncts increases to 70%.These results show that adjunct labelling accu-racy on both sides of the data is crucial for adjunctalignment, while suggesting that applications thatexploit adjunction can gain from decreasing theirdependence on word alignments and idealized ex-perimental conditions , and identifying favorablecontexts for adjunct preservation.2 Alignment-based role pairingHow can one find translation-equivalent adjunctsusing word alignments, without being too con-strained by the latter?
Obviously, adjunct pairsthat are consistent with the word alignments aretranslation equivalent, but we also want to be ableto identify translation-equivalent adjuncts that arenot exactly aligned to each other, and also to ac-cept many-to-many pairings; not only to get lin-guistically justified discontinuous pairs, as withthe French double negation particle, but also forrobustness with regard to dissimilar attachmentsin the French and English parses.2.1 Translation equivalence under thealignment-consistency constraintConsider for instance Figure 2, which representsa word alignment for part of the sentence pair ofFigure 1.
We would like to match?f2to e?2and e?6,?f3to e?3,?f4to e?5, and?f5to e?6.
If one only pairsadjuncts that are consistent with the word align-ment, one obtains only half of these adjunct pairs:?
?f3, e?3?
and ?
?f4, e?5?
; one cannot pair up?f5ande?6because the latter is also aligned outside of theformer; and one can also not find the equivalencebetween?f2on one hand and e?2and e?6on the otherhand if one assumes one-to-one correspondencebetween adjuncts.2.2 Translation equivalence throughprojectionWe align adjuncts across the bitext by projectingthem through the word alignment and finding, foreach adjunct, the shortest adjunct or sequence ofadjuncts that overlaps the most with that adjunct?s158`a?etudierdelesdemandescourantesdechangementsdeinstallationslelongdeunpipe-line,parexempleinhandlingroutineapplicationsforchangesoffacilitiesalonga pipeline, forexample,?f2?f3?f4?f5e?2e?3e?4e?5e?6Figure 2: Example with word alignmentprojection.
To prevent source adjuncts from be-ing aligned to the first target adjunct that sub-sumes their projection, we also enforce that onlynon-overlapping source adjuncts may be alignedto a same target sequence, as explained in sec-tion 2.2.1.This procedure results in a many-to-many align-ment between adjuncts on either side.
We distin-guish several types of adjunct pairings through thisalignment, which we interpret as divergent, equiv-alent or weakly equivalent, as described in sec-tion 2.2.2.We perform this alignment in both source-targetand target-source directions to measure the pro-portion of source, respectively target, adjuncts thatfall in each category.2.2.1 Adjunct pairing procedureWe define the projection of an adjunct ?
as theunique tuple of maximal, non-overlapping phrases?n1that are aligned to ?
through the word align-ment.
Each phrase ?iin this tuple is understoodas being extended with possible surrounding un-aligned positions?phrases are primarily identifiedby the aligned positions they cover.
And each ?iis maximal as any larger phrase distinct from ?iwould also include (aligned) positions not alignedto ?.
Let I(?i) be the set of aligned positionsin each ?i, and I(?n1) the set of aligned positionscovered by ?n1.We align ?
to the non-overlapping sequenceof target adjuncts ?m1that has the smallest set ofaligned positions while having the largest over-lap with ?n1; the overlap of a projection and a tar-get sequence is the intersection of their respectivesets of aligned positions.
For instance in Figure 2,the projection of?f4is maximally covered by e?2,e?4, and e?5; we align the latter to?f4as it coversthe least aligned positions.
In practice, we searchthrough the tree of target adjuncts for adjuncts thatoverlap with ?n1, and for each such adjunct ?
wecompare its overlap with ?n1to that of the sequenceof its children ?k1to determine which (of ?
or ?k1)should be part of the final target sequence.We perform a similar selection on overlappingsource adjuncts that point to the same target se-quence.
For each source adjunct ?, we determineif its target sequence ?m1is also aligned to adjunctsdominated by ?, in which case we compare theoverlap of ?
?s projection with ?n1to that of its chil-dren in the source adjunct tree to determine whichshould be aligned to ?m1.
For instance in Figure 2,e?4is aligned to?f2(when projecting from Englishto French), but so is e?2; as e?2?s projection overlapsmore with?f2, we discard the alignment betweene?4and?f2.The final alignments for our example are repre-sented in Table 1.Table 1: Adjunct pairings for the alignment ofFigure 2f ?
e e?
f?f2e?2, e?6e?2?f2?f3e?3e?3?f3?f4e?5e?4-?f5e?6e?5?f4e?6?f22.2.2 Types of adjunct pairingsWe distinguish three main classes of adjuncttranslation equivalence: divergent, equivalent andweakly equivalent.
We further subdivide eachclass into two types, as shown in Table 2.
Ad-junct pairings fall into one of these types depend-ing on their configuration (unaligned, one-to-oneor many-to-many) and their agreement with theword alignments.
Equivalent types notably differfrom weakly equivalent ones by being bijectively159aligned; With the notations of section 2.2.1, twoadjunct sequences ?n1and ?m1with respective pro-jections ?n?1and ?m?1are translation equivalent iffI(?n?1) = I(?m1) and I(?m?1) = I(?n1).Table 2: Adjunct pairing typesdivergentnull empty projectiondiv no aligned target adjunctsweakly equivalentwe-nm many-to-many non-bijectivewe-11 one-to-one non-bijectiveequivalenteq-nm many-to-many bijectiveeq-11 one-to-one bijectiveIn Table 1, e?4?s translation is divergent as it isnot aligned to any adjunct;?f5and e?6are weaklyequivalent as the projection of?f5does not coverall the aligned positions of e?6.
The pairing from?f2to e?2, e?6is many-to-many equivalent, and so arethe pairings from e?2and e?6to?f2; the remainingpairings are one-to-one equivalent.As Table 3 shows, the divergent types null anddiv regroup untranslated adjuncts (Example 1)and divergent adjuncts: Examples (2) and (3) showcases of conflational divergence (Dorr, 1994), thatappear in different types because of the underly-ing word alignments; in Example (4), the prepo-sitional phrase with this task has been wronglylabelled as an adjunct, leading to a falsely diver-gent pairing.
The weakly-equivalent types we-nmand we-11 regroup both divergent and equiva-lent pairings: the adjuncts of Examples (5) and (8)are aligned by our method to adjuncts that are nottheir translation equivalent, the adjunct in Exam-ple (6) cannot be aligned to its equivalent becauseof a parsing error, and the equivalences in Exam-ples (7) and (9) cannot be identified because of aword-alignment error.
Finally, we show a numberof equivalent pairings (eq-nm and eq-11): inExample (10), an attachment error in the Frenchparse induces a many-to-one equivalence wherethere should be two one-to-one equivalences; Ex-amples (11) to (13) show a number of true many-to-many equivalences, while Examples (14) and(15) show that adjuncts may be equivalent across abitext while belonging to a different syntactic cate-gory and modifying a different type of phrase (15).3 Adjunct identificationWe identify adjuncts in dependency trees obtainedby conversion from phrase-structure trees: we mapmodifier labels to adjuncts, except when the de-pendent is a closed-class word.
For English, weuse the Berkeley parser and convert its output withthe pennconverter (Johansson and Nugues, 2007;Surdeanu et al., 2008); for French, we use theBerkeley parser and the functional role labeller ofCandito et al.
(2010).
The pennconverter with de-fault options and the French converter make sim-ilar structural choices concerning the representa-tion of coordination and the choice of heads.3.1 English adjunctsWe first identify closed-class words by their POStag: CC, DT, EX, IN, POS, PRP, PRP$, RP, SYM,TO, WDT, WP, WP$, WRB.
Punctuation marks,identified by the P dependency relation, and namedependencies, identified by NAME, POSTHON, orTITLE, are also treated as closed-class words.Adjuncts are identified by the dependency rela-tion: ADV, APPO, NMOD (except determiners, pos-sessives and ?of?
complements), PRN, AMOD (ex-cept when the head is labeled with ADV) and PMODleft of its head.
Cardinals, identified by the CDPOS tag, and remaining dependents are classifiedas arguments.3.2 French adjunctsClosed-class words are identified by the (coarse)POS tags: C, D, CL, P, PONCT, P+D, PRO.
Aux-iliary verbs, identified by the dependency relationsaux tps and aux pass, are also included.Adjuncts are identified by the dependency re-lations mod rel and mod (except if the depen-dent?s head is a cardinal number, identified by thes=card label).3.3 EvaluationWe evaluate adjunct identification accuracy usinga set of 100 English and French sentences, drawnrandomly from the Europarl corpus.
A single an-notator marked adjuncts in both sets, identifyingslightly more than 500 adjuncts in both sets.
Wefind F scores of 71.3 and 72.2 for English andFrench respectively, as summarized in Table 4.
Wefind that about a quarter of errors are related toparse attachment, yielding scores of 77.7 and 78.6if one corrects them.160Table 3: Examples of adjunct pairing typesnull(1) it is indeed a great honour vous me faites un grand honneur(2) the polling booths les isoloirsdiv(3) the voting stations les isoloirs(4) to be entrusted with this task en me confiant cette t?achewe-nm(5) reforms to the Canadian military r?eformes des forces [arm?ees] [canadiennes](6) an even greater country un pays [encore] [plus] magnifique(7) in safe communities [en s?ecurit?e] [dans nos communaut?es]we-11(8) across the land de tout le pays(9) strong opinions des opinions bien arr?et?eeseq-nm(10) a proud moment for Canada un moment heureux pour le Canada(11) we have used the wrong process nous ne suivons pas le bon processus(12) our common space and our common means un espace et des moyens communs(13) the [personal] [protected] files les dossiers confidentiels et prot?eg?eseq-11(14) the names just announced les noms que je viens de mentionner(15) one in three Canadian jobs au Canada , un emploi sur troisTable 4: Adjunct identification F scoresprec.
recall FEnauto.
66.2 77.2 71.3corr.
72.3 84.0 77.7Frauto.
68.1 76.7 72.2corr.
74.7 83.0 78.64 Experiments4.1 Experimental set-upWe measure adjunct translation equivalence infour data sets: the manually-aligned CanadianHansards corpus (Och and Ney, 2003), contain-ing 447 sentence pairs, the house and senate train-ing data of the Canadian Hansards (1.13M sen-tence pairs), the French-English Europarl trainingset (1.97M sentence pairs) and the Moses news-commentaries corpus (156k sentence pairs).
Be-sides, we randomly selected 100 sentence pairsfrom the Europarl set to measure adjunct identi-fication accuracy as reported in section 3 and ad-junct correspondence with gold adjunct annota-tions.All four corpora except the manual Hansardsare preprocessed to keep sentences with up to80 words, and all four data sets are used jointlyto train unsupervised alignments, both with theBerkeley aligner (Liang et al., 2006) and GIZA++(Brown et al., 1993; Och and Ney, 2003) throughmgiza (Gao and Vogel, 2008), using 5 iterations ofModel 1 and 5 iterations of HMM for the Berkeleyaligner, and 5 iterations of Model 1 and HMM and3 iterations of Model 3 and Model 4 for GIZA++.The GIZA++ alignments are symmetrized usingthe grow-diag-final heuristics.
Besides, the man-ual Hansards corpus is aligned with Sure Only(SO) and Sure and Possible (SP) manual align-ments.4.2 Measurements with gold adjunctannotationsWe compared adjunct translation equivalence ofautomatically identified adjuncts and gold anno-tations using 100 manually annotated sentencepairs from the Europarl corpus; adjuncts werealigned automatically, using the Berkeley wordalignments.
We also measured adjunct equiv-alence using automatic adjunct annotations cor-rected for parse attachment errors, as introduced161in section 3.3.
Table 5 reports harmonic mean fig-ures (mh) for each adjunct projection type.
Forinformation, we also report their decomposition inthe case of gold annotations, showing some depen-dence on the projection direction.Table 5: Translation equivalence of auto-matic, rebracketed and gold adjunctsauto.
corr.
goldmhmhef fe mhnull 7.6 7.7 8.1 7.3 7.7div 22.3 22.5 14.7 12.0 13.2we-nm 10.8 9.6 2.7 4.6 3.4we-11 12.5 10.8 7.4 8.5 7.9eq-nm 3.5 2.2 2.5 3.3 2.9eq-11 41.8 45.8 64.5 64.3 64.4About two thirds of manually identified ad-juncts form equivalent pairs, representing a gainof 20 points with regard to automatically identi-fied adjuncts.
This is accompanied by a halving ofdivergent pairings and of weakly equivalent ones.Further, we find that about half of the remainingweak equivalences can be interpreted as transla-tion equivalent (to compare to an estimated thirdfor automatically identified adjuncts), allowing usto estimate to 70% the degree of translation equiv-alence given Berkeley word alignments in the Eu-roparl corpus.4.3 Measurements with manual andautomatic alignmentsWe aligned adjuncts in the manual Hansards cor-pus using all four word alignments.
Table 6presents the mean proportions for each categoryof adjunct projection.Table 6: Translation-equivalence of adjunctsin the manual HansardsSO SP bky gizanull 32.1 2.8 8.7 3.3div 19.7 29.3 27.1 30.3we-nm 3.4 14.6 8.5 11.4we-11 5.7 13.8 13.5 15.3eq-nm 4.1 7.3 4.1 4.2eq-11 33.7 31.8 37.6 35.3Comparing the mean proportions per type be-tween the four alignments, we see that a third ofadjuncts on either side are not aligned at all withthe sure-only manual alignments.
In the exampleof Figure 2 for instance, these alignments do notlink?f3to e?3.
On the other hand, the sure andpossible manual alignments lead to many diver-gent or weakly equivalent pairings, a result of theirdense phrasal alignments.
In comparison, the au-tomatic alignments connect more words than thesure-only alignments, leading to a mixed result forthe adjunct pairings: one gains more translation-equivalent, but also more divergent and weaklyequivalent pairs.
In this, the Berkeley aligner ap-pears less noisy than GIZA++, as it captures moretranslation equivalent pairs and less weakly equiv-alent ones.
This is confirmed in the other data setstoo, as Table 7 shows.Table 7: Mean proportions of adjunct-pairingtypes in automatically aligned datahans-hst europarl newsbky giza bky giza bky gizanull 7.5 2.7 6.3 2.3 8.3 3.3div 28.1 30.8 21.8 24.2 21.0 23.9we-nm 10.4 12.2 11.0 12.7 10.6 12.6we-11 13.4 15.5 12.4 14.6 11.7 14.2eq-nm 3.2 4.0 3.2 4.0 3.1 3.8eq-11 37.1 34.6 45.0 42.0 44.9 41.8Comparing figures between the different datasets, we see that the Europarl and the Newsdata have more translation-equivalent and less di-vergent adjuncts than the Hansards training data(hans-hst).
Taking the harmonic mean for bothequivalent types (eq-nm and eq-11), we findthat 48.2% of adjuncts have an adjunct translationequivalent in the Europarl data (with the Berke-ley aligner) and 48.0% in the News corpus, against40.3% the Hansards training set and 41.6% in themanual Hansards set.
This suggests that transla-tions in the Hansards data are less literal than inthe Europarl or the News corpus.4.4 Effect of sentence lengthWe explore the relation between sentence lengthand translation equivalence by performing mea-surements in bucketed data.
We bucket the datausing the length of the English sentences.
Mea-surements are reported in Table 8 for the Hansards162Table 8: Adjunct translation equivalence with the Berkeley aligner in bucketeddatahans-man hansard-hst europarl1-15 16-30 1-15 16-30 31-50 51-80 1-15 16-30 31-50 51-80null 9.3 8.5 6.5 7.6 7.8 8.0 6.4 6.0 6.2 6.6div 28.1 25.9 39.5 25.3 23.5 22.6 25.3 22.2 21.2 20.6we-nm 6.1 9.4 5.3 10.1 13.6 16.7 5.0 9.3 12.5 14.9we-11 11.8 14.1 12.2 13.4 14.2 14.8 10.0 11.7 13.0 13.9eq-nm 3.1 4.5 2.8 3.4 3.3 3.1 3.4 3.3 3.1 2.9eq-11 40.6 36.3 32.5 39.6 37.3 34.4 49.1 47.1 43.7 40.7and the Europarl sets (the News set yields similarresults to the Europarl data).All data sets show a dramatic increase of theproportion of adjuncts involved in many-to-many,and to a lesser extent one-to-one weakly equiva-lent translations.
This increase is accompanied bya decrease of all other adjunct-pairing types (un-aligned adjuncts excepted), and is likely to resultfrom increased word-alignment and parsing errorswith sentence length.A rather surprising result is the high proportionof divergent adjunct translations in the shorter sen-tences of the Hansards training set; we find thesame phenomenon with the GIZA++ alignment.We attribute this effect to the Hansards set havingless literal translations than the other sets.
Thatwe see this effect mostly in shorter sentences mayresult from translation mismatches being mostlylocal.
As sentence length increases however, wordand adjunct alignment errors are also likely to linkmore unrelated adjuncts, resulting in a drop of di-vergent adjuncts.4.5 Simplifying alignmentsWe perform a simple experiment to test the effectof word-alignment simplification of adjunct trans-lation equivalence.
For this we remove alignmentlinks between function words (as defined in sec-tion 3) on both sides of the data, and we realignadjuncts using these simplified alignments.
Ta-ble 9 shows that this simplification (column ?-fw?
)slightly decreases the proportion of weakly equiv-alent pairings with regard to the standard align-ment (?std?
), mostly to the benefit of translation-equivalent pairings.
This suggests that furthergains may be obtained with better alignments.Table 9: Effect of alignment simplificationon adjunct translation equivalence in the Eu-roparl databky gizastd -fw std -fwnull 6.3 7.5 2.3 3.1div 21.8 21.5 24.2 24.0we-nm 11.0 9.1 12.7 10.8we-11 12.4 10.0 14.6 13.2eq-nm 3.2 4.0 4.0 4.8eq-11 45.0 47.5 42.0 43.75 Related workWhile adjunction is a formal operation that may beapplied to non-linguistic adjuncts in STAG, De-Neefe and Knight (2009) restrict it to syntacticadjuncts in a Synchronous Tree Insertion Gram-mar.
They identify complements using (Collins,2003)?s rules, and regard all other non-head con-stituents as adjuncts.
Their model is able to gen-eralize to unseen adjunction patterns, and to beat astring-to-tree baseline in an Arabic-English trans-lation task.Arnoult and Sima?an (2012) exploit adjunct op-tionality to generate new training data for a phrase-based model, by removing phrase pairs with anEnglish adjunct from the training data.
They iden-tify adjuncts using syntactic heuristics in phrase-structure parses.
They found that few of the gener-ated phrase pairs were actually used at decoding,leading to marginal improvement over the base-line in a French-English task.
They also report163figures of role preservation for different categoriesof adjuncts, with lower bounds between 29% and65% and upper bounds between 61% and 78%, inautomatically aligned Europarl data.
The upperbounds are limited by discontinuous adjunct pro-jections, while the estimation of lower bounds islimited by the lack of adjunct-identification meansfor French.There has been a growing body of work on ex-ploiting semantic annotations for SMT.
In manycases, predicate-argument structures are used toprovide source-side contextual information forlexical selection and/or reordering (Xiong et al.,2012; Li et al., 2013), without requiring cross-linguistic correspondence.
When correspondencebetween semantic roles is required, predicates arecommonly aligned first.
For instance, Lo et al.
(2012) use a maximum-weighted bipartite match-ing algorithm to align predicates with a lexical-similarity measure to evaluate semantic-role corre-spondence.
Pad?o and Lapata (2009) use the samealgorithm with a similarity measure based on con-stituent overlap to project semantic roles from En-glish to German.6 ConclusionIn this paper we presented the first study of trans-lation equivalence of adjuncts on a variety ofFrench-English parallel corpora and word align-ments.
We use a method based on overlap to de-rive many-to-many adjunct pairings, that are inter-pretable in terms of translation equivalence.We found through measurements in French-English data sets that 40% to 50% of adjuncts?depending on the data?are bijectively alignedacross a bitext, whereas about 25% more adjunctsalign to adjuncts, albeit not bijectively.
We esti-mate that a third of these weakly equivalent linksrepresent true, adjunct translation equivalences.With manually identified adjuncts, we foundthat about 70% have adjunct translation-equivalents in automatically aligned data.These are fairly low results if one considers thatFrench and English are relatively close syntacti-cally.
So while they show that adjunct labellingaccuracy on both sides of the data is crucial foradjunct alignment, and that applications thatexploit adjunction can gain from decreasing theirdependence on word alignments and idealizedexperimental conditions, they call for betterunderstanding of the factors behind translationdivergence.In fact, as a remaining quarter of adjuncts havedivergent translations, it would be interesting todetermine, for instance, the degree to which diver-gence is caused by lexical conflation, or reflectsnon-literal translations.AcknowledgmentsWe thank the anonymous reviewers for their perti-nent comments.
This research is part of the project?Statistical Translation of Novel Constructions?,which is supported by NWO VC EW grant fromthe Netherlands Organisation for Scientific Re-search (NWO).ReferencesSophie Arnoult and Khalil Sima?an.
2012.
AdjunctAlignment in Translation Data with an Applica-tion to Phrase-Based Statistical Machine Transla-tion.
In Proceedings of the 16th Annual Conferenceof the European Association for Machine Transla-tion, pages 287?294.Peter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1993.
TheMathematics of Statistical Machine Translation: Pa-rameter Estimation.
Computational Linguistics,19(2):263?311.M.-H. Candito, B. Crabb?e, and P. Denis.
2010.
Statisti-cal French dependency parsing: treebank conversionand first results.
In Proceedings of The seventh in-ternational conference on Language Resources andEvaluation (LREC).Michael Collins.
2003.
Head-driven statistical modelsfor natural language parsing.
Computational Lin-guistics, 29(4):589?637.Steve DeNeefe and Kevin Knight.
2009.
SynchronousTree Adjoining Machine Translation.
In Proceed-ings of the 2009 Conference on Empirical Methodsin Natural Language Processing, pages 727?736.Bonnie J. Dorr.
1994.
Machine Translation Diver-gences: A Formal Description and Proposed Solu-tion.
Computational Linguistics, 20(4):597?633.Qin Gao and Stephan Vogel.
2008.
Parallel Implemen-tations of Word Alignment Tool.
In Software En-gineering, Testing, and Quality Assurance for Natu-ral Language Processing, pages 49?57, Columbus,Ohio, June.
Association for Computational Linguis-tics.Rebecca Hwa, Philip Resnik, Amy Weinberg, andOkan Kolak.
2002.
Evaluating Translational Cor-respondence Using Annotation Projection.
In Pro-ceedings of the 40th Annual Meeting on Associationfor Computational Linguistics, ACL ?02, pages 392?399.164Richard Johansson and Pierre Nugues.
2007.
Ex-tended Constituent-to-dependency Conversion forEnglish.
In Proceedings of NODALIDA 2007, pages105?112, Tartu, Estonia, May 25-26.Aravind K. Joshi, Leon S. Levy, and Masako Taka-hashi.
1975.
Tree adjunct grammars.
Journal ofComputer and System Sciences, 10(1):136?163.Junhui Li, Philip Resnik, and Hal Daum?e III.
2013.Modeling Syntactic and Semantic Structures in Hi-erarchical Phrase-based Translation.
In Proceed-ings of the 2013 Conference of the North Ameri-can Chapter of the Association for ComputationalLinguistics: Human Language Technologies, pages540?549, Atlanta, Georgia.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by Agreement.
In Proceedings of the MainConference on Human Language Technology Con-ference of the North American Chapter of the Asso-ciation of Computational Linguistics, HLT-NAACL?06, pages 104?111.Chi-kiu Lo, Anand Karthik Tumuluru, and Dekai Wu.2012.
Fully Automatic Semantic MT Evaluation.
InProceedings of the Seventh Workshop on StatisticalMachine Translation, WMT ?12, pages 243?252.Franz Josef Och and Hermann Ney.
2003.
A System-atic Comparison of Various Statistical AlignmentModels.
Computational Linguistics, 29:19?51.Sebastian Pad?o and Mirella Lapata.
2009.
Cross-lingual Annotation Projection for Semantic Roles.Journal of Artificial Intelligence Research, 36:307?340.Stuart Shieber and Yves Schabes.
1990.
Synchronoustree-adjoining grammars.
In Handbook of FormalLanguages, pages 69?123.
Springer.Mihai Surdeanu, Richard Johansson, Adam Meyers,Llu?
?s M`arquez, and Joakim Nivre.
2008.
TheCoNLL-2008 Shared Task on Joint Parsing of Syn-tactic and Semantic Dependencies.
In CoNLL 2008:Proceedings of the Twelfth Conference on NaturalLanguage Learning, pages 159?177, Manchester,United Kingdom.Dekai Wu and Pascale Fung.
2009.
Can Semantic RoleLabeling Improve SMT?
In Proceedings of the 13thAnnual Conference of the European Association forMachine Translation, pages 218?225.Deyi Xiong, Min Zhang, and Haizhou Li.
2012.
Mod-eling the Translation of Predicate-Argument Struc-ture for SMT.
In Proceedings of the 50th AnnualMeeting of the Association for Computational Lin-guistics, pages 902?911.165
