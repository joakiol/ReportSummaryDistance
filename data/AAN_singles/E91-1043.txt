A LANGUAGEiBIDIRECTIONAL MODEL FOR NATURALPROCESSINGGtinter NeumannLehrstuhl fur ComputerlinguistikUniversit~it des SaarlandesIm Stadtwald 15, Bau 17.26600 Saarbriicken 11, FRGneumann@coli.uni-sb.deABSTRACTIn this paper* I will argue for a model ofgrammatical processing that is based onuniform processing and knowledge sources.The main feature of this model is to viewparsing and generation as two stronglyinterleaved tasks performed by a singleparametrized eduction process.
It will beshown that this view supports flexible andefficient natural language processing.1 INTRODUCTIONThe aspect of bidirectionality has beengaining importance since the growing rate ofresearch on natural anguage generation overthe last years offers us deeper insights intothis cognitive ability of humans.
There aretheoretical as well as practical reasons foradopting bidirectionality.
Theoretically, theassumption of common knowledge sourcesfor both generation and analysis is essentialfor the view of language as "an interpersonalmedium and an interface to thought"(McDonald 1987).
From a psychologicalpoint of view, there is a certain amount ofempirical evidence for shared processors orfacilities (Jackendoff 1987): From a systemengineering view, a bidirectional systemproduces utterances only from that subset oflanguage that it is capable to understand.Therefore, inconsistencies of the languagebehaviour of the system can be avoided(Jacobs 1988).A fundamental requirement of abidirectional knowledge base is that it berepresented declaratively (Appelt 1987).
Fromthis viewpoint one can distinguish twodifferent types of bidirectional naturalhmguage systems:?
systems that use uniform knowledgesources, but different processes?
systems that use uniform knowledgesources as well as uniform processes 1Up to now, systems that are capable ofanalysing and producing language fall into thefirst class, i.e.
they use different operationsfor both directions (cf.
Hoeppner et al 1983;Busemann and Hauenschild 1988; Allgayer etal.
1989) Currently, it is an open questionwhat degree of bidirectionality should orcould be desired (cf.
Appelt 1987; Mann1987; McDonald 1987; Shieber 1988; Jacobs1988).
One of the reasons could be that theformal specification of some tasks (e.g., thedetermination of content in generation) iscurrently not well understood in order todecide whether they could be bidirectional inprinciple.But in some research areas uniformprocessing models have been developed thatare based on formalisms which are well suitedfor uniform irepresentation and processing,e.g., Koskenniemi's (1984) two-level modelof morphology.
Recently, there are firstapproaches to uniform architectures forgrammaticallprocessing (e.
., Shieber 1988;Dymetman and Isabelle 1988; Dymetman etal.
1990).
These architectures are based onPereira and lWarren's (1983) paradigm ofparsing as deduction.
In principle, parsingand generation are viewed as a singleparametrizeddeduction process.PROBLEMS OF BIDIRECTIONALGRAMMATICAL  PROCESSING* Thanks to Klaus Netter, Karel Oliva, NorbertReithinger, Harald Trost and Hans Uszkoreit forfruitful discussions about he aspects of the paper'scontents.1Besides these two classes there are also systems thatuse different knowledge sources that are compiled fromthe same source (e.g., Horacek and Pyka 1988) andsystems that use common basic representation devices?
(e.g., Lancel et,al.
1988; Neumann and Finkler 1990).- 245 -Currently developed approaches thatconsider parsing as well as generation (e.g.,Shieber 1988; Shieber et al 1990; Dymetmanet al 1990; van Noord 1990; Zajac and Emele1990) assume:?
that both tasks take place independentlyfrom each other, i.e.
an utterance is eithergenerated orparsed and?
that grammatical processing can beperformed without considerations ofdiscourse.A great problem with this view is that it offersno solution of the problem of choice betweenparaphrases in generation: The proposedapproaches assume - more or less explicitly -modularity between the conceptual ndgrammatical component of a natural languagesystem.
2 A great advantage of a modulardesign especially for uniform architectures isthat it is possible to view the grammaticalcomponent as relatively autonomous and self-contained (cf.
Appelt 87).But then the following problems emerge:The conceptual component will be unable toexactly specify the logical form as input to thegrammatical component that will preciselylead to the utterance that reflects the intendedmeaning unless the conceptual module hasdetailed information about the grammar andknows when to use a specific construction(which renders the modular designmeaningless).On the other hand, when parsing andgeneration are performed within thegrammatical component by a single processonly then the opposite view of computing allpossible parses of an utterance is thecomputation of all possible paraphrases of alogical form.
When gramm~ttical processingshould be modelled by means of abidirectional grammar, the declarativestructure of the grammar must not containpragmatical or stylistical information becauseof the modular design.
But then the processcan only choose randomly betweenparaphrases during generation and this meansthat the intended meaning will possibly not beconveyed.Ideally, a logical language would behelpful which necessarily and sufficientlyrepresents all meaning distinctions of natural2By a conceptual component I mean either the what-to-say component of a generation system or thecomponent that performs inference, plan recognitionor anaphora esolution ofan understanding system.language.
But as Shieber (1988) states "this... is just the central problem of knowledgerepresentation for natural language 10general".
Currently, there exist onlyapproximate solutions to this problem forexample the use of canonical logical forms(cf.
Shieber 88).
3 But this still offers nosolution of the problem of choice betweenparaphrases.In this paper it will be argued that thefollowing two points will contribute to anapproximate solution:?
interleaved parsing and generation?
using the language use of interlocutors asan additional access criterion to linguisticknowledgeInterleaved parsing and generation means thatboth tasks take place in parallel (see section2).
In principle this results in a bidirectionaland incremental flow of information duringnatural language processing (see section 4.1).An important point during the use of languageis that the Choice of linguistic material isinfluenced by the language use of others (seesection 3).
This leads to more flexibility: notall necessary parameters (e.g., pragmaticalvalues) need to be specified in the input of agenerator because decision points can also beset dynamically during run-time.A promising approach to realize these twofeatures will be to base grammaticalprocessing on a uniform process that isparametrized by means of a declarativelyspecified preference structure of knowledgesources.
But, it is necessary to be aware thatthe grammatical component must be assumedto be an integrated part of a whole naturallanguage system (in particular in models forperforming dialogs) in order to realize thissolution.
;Before the architecture of the model will bedescribed in section 4 the two issues areexplained in more detail in the next sections.2 INTERLEAVING GENERATIONAND ANALYSISThe strategy of viewing natural anguageprocessing as based on a uniform deductionprocess has a formal elegance and results inmore compact systems.
There is one furtheradvantage that is of both theoretical andpractical relevance: uniform architectures offerthe possibility to view generation and parsingas strongly interleaved tasks.
By this I mean3It is questionable whether there xists a full solution.- 246  -that during performing one task (e.g.,generation) the other one (e.g., analysis) isused for monitoring the former.
In principlethis results in a bidirectional and incrementalflow of information:?
During the parse of an utterance theaddressee of the utterance cansimultaneously start to construct hisanswer.
In doing so, partial results of theparsing process can be used directly duringgeneration (e.g., if a paraphrase will begenerated).
In such flow of control it willbe possible that generation can be used forcompleting the resulting structure ofelliptic, underspecified or ill-formed inputduring the process of  understanding or forgenerating paraphrases in due time.?
During generation i terleaved parsing couldhelp to avoid the construction ofambiguous utterances.
E g., it is necessaryfor a natural language help system togenerate utterances that reflect exactly theintended meaning (if possible at all) to besure that the dialog partner will perform thecorrect operations.
For instance, producingthe utterance "Remove the folder by meansof the system tools" is better than "Removethe folder with the system tools" becausefor the latter utterance there exists thereading "Remove the folder that containsthe system tools", too.Of course, it is also possible to analyse agenerated utterance if processes areperforming their tasks in an isolated way.
4 Insuch flow of control the complete istructurehas to be generated again if ambiguities aredetected that have to be avoided.
BeCause thesource of an ambiguous utterance is not useddirectly to guide the generation process it ispossible that the newly generated structure isstill ambiguous (and it may happen that thesame ambiguous tructure is generated again).This results in inefficient systems because ingeneral the loop between the i isolatedprocesses must be performed several' times.The advantage of a uniform architecture isthat intermediate r sults of one direction can4For example, the complete structure of a producedutte~mce is analysed during \[he 'anticipation-feedback-loop' of the HAM-ANS system (see Hoeppner t al.1983) to determine whether itcan be actually utteredelliptic or not.immediately be used in the opposite directionto determine the ambiguous information indue time.3 B IDIRECTIONALITY SUPPORTSFLEXIBLE AND EFF IC IENTGENERATIONOne of the disadvantages of currentlydeveloped generation systems is that theyview the structure of linguistic knowledgeonly statically.
If alternatives exist for aparticular linguistic expression, decisionpoints are evaluated to determine theappropriate actual utterance.
It is necessary tospecify corresponding decision points for allpossible utterances otherwise the choice mustbe performed randomly (the determination fthe appropriate set of decision points is one ofthe sources of complexity in existinggeneration systems).
The flexibility of suchsystems depends directly on the flexibility thatis brought into the system via the decisionpoints that are specified by hand during thedevelopment of a generation system (i.e.
theflexibility is restricted).On the other side, in a bidirectional systemthe resulting structures of the parsing task canbe used directly during generation.
E.g., ingeneral aset :of alternative l xemes is specifiedduring the process of lexical choice which aresynonymous in the actual situation or whenthe semantic input cannot be sufficientlyspecified (e!g., in German, some drinking-devices can be denoted either 'Tasse' (cup) or'Becher' (mtip) because their shape cannot beinterpreted Unequivocally).
An appropriatechoice would be to use the same lexeme thatwas previously used by the hearer (if no otherinformation is available).
In principle this isalso possible for the choice betweenalternative syntactic structures.This means that uniform architectures offerthe possibility to model the assumption thatduring communication the use of language ofone interlocutor is influenced by means of thelanguage use of the others.
This adaptabilityto the use of language of partners incommunication is one of the sources for thefact that the global generation process ofhumans is flexible and efficient.
Of course,adaptability is also a kind of co-operativebehaviour.
This is necessary if new ideashave to be expressed for which no mutuallyknown linguistic terms exist (e.g., duringcommunication between experts and novices).In this case adaptability to the use of language247 -of the hearer is necessary in order to makepossible that the hearer will be able tounderstand the new information.I do not want to argue that all choices aredetermined by means of language use ofothers.
But, when structures that aredetermined uring analysis are consideredduring generation, the number of decisionpoints or parameters which have to bespecified during the development of ageneration system is reduced.
This leads tomore flexibility: not all necessary parametersneed to be specified in the input of agenerator because decision points can also beset dynamically during run-time.This dynamic behaviour of a generationsystem will increase efficiency, too.
AsMcDonald et al (1987) define, one generatordesign is more efficient han another, if it isable to solve the same problem with fewersteps.
They argue that "the key elementgoverning the difficulty of utteranceproduction is the degree of familiarity with thesituation".
The efficiency of the generationprocess depends on the competence andexperience one has acquired for a particularsituation.
In such situations the generationprocess performs its task by using compiledknowledge and preferences.Currently, it is a great problem howcompiled knowledge is acquired ynamicallyand how it is activated in particular situations.But a uniform architecture asproposed in thispaper seems to be a promising basis fordesigning such a system, because thestructures determined during analysislcould beused for restricting the potential search space.4 AN OUTLINE OF ABIDIRECTIONAL ARCHITECTUREIf both aspects - interleaving parsing andgeneration and using the language use ofinterlocutors as additional criterion for thestructure of linguistic knowledge - are realizedwithin a uniform architecture thenthis willincrease flexibility and efficiency in naturallanguage processing.
E.g., when starting thegeneration from a :logical form, thegrammatical process is able to ::call theconceptual module's attention if a subphrasecauses ambiguity.
Thus it is not necessary thatthe conceptual module has detailedinformation about he grammar.The flow of control within a system basedon an interleaved approach is bidirectional.E.g., during the generation of an utterancepartial structures are analysed to avoidunnecessary ambiguities.
The bidirectionalflow of control supports incrementalprocessing: it is possible to start processing ofpartial structures before the whole structure isknown.
In Finkler and Neumann (1989) andNeumann and Finkler (1990) we have alreadydescribed an implemented generation system(named POPEL-HOW) that realizes anincremental nd bidirectional flow of controlbased on a uniform parallel processing model.The incremental and bidirectional f ow ofcontrol has two main advantages duringgeneration.
Firstly, the determination ofcontents can be done on the basis ofconceptual considerations only, becausePOPEL-HOW is flexible enough to handleunderspecif ied input.
Secondly, theconceptualizer has to regard feedback fromPOPEL-HOW during the computation of thefurther selection process.
This means, anincremental system like POPEL can model theinfluence of linguistic restrictions on theprocess that determines what to say next.Underspecified structures are analysed inPOPEL-HOW at each level of description bymeans of declarative described mapping rules.The analysis of such structures i performedwith generation specific operations.
If thesystem would be based on a uniformarchitecture then such specific operations areno more necessary.4.1  B iLD - A MODEL FORBIDRECTIONAL LINGUISTICDEDUCTIONAt the University of Saarbriicken a projectcalled BiLD is now being started where it willbe investigated how interleaving of parsingand generation can be efficiently performedand how such a model can be used forincreasing flexibility and efficiency duringnatural language processing.
Fig.
1 (nextpage) shows the schematic structure of itsarchitecture.The core of the system is a uniformparametrized deduction process.
The maintask for the process in both directions is thedetermination f the corresponding syntacticinformationi'that functions as an interfacebetween graphematic and semanticinformation (a formalism based on Head-driven Phrase Structure Grammar (Pollardand Sag 1987) will be used).- 248  -l eml ln t loexpre ls iOnI TlinguisticdeductionprocessI?'n::.
:r: ' -I and I I ox looncompl iedi l ruo lure lLI I I l i t  I r lO l lFig.
1 : Schematic structure of BiLDThe task of the deduction process duringgeneration is to construct he graphematicform of a specified semantical featuredescript ion.
5 For example, to yield theutterance "A man sings" the deduction processgets as input the semantic feature structureI \[rel : sing'sem" | \[quant : exist'"/ /vat:El , -|agenS:|restr \[pred : man|L t :tvar: l \]and deduces the graphematic structure\[graph : (A_man_sings.)
\]by means of successive application of lexicaland grammatical information.
In the same waythe deduction process computes from thegraphematic structure an appropriate :semanticstructure in parsing direction.The author has now started to develop andimplement a first version of a prototype of auniform algorithm for HPSG.
The main idea 6is that the approach is head-driven in bothdirections.
In the first phase of the algorithmthe maximal projection for all head elementsare computed (or predicted) bottom-up.Phrases are then combined top-down.
Thecompletion step is controlled by syntactic andsemantic information inherited from lexicalheads and by the principles of HPSG.5The resulting structure of the generation :process aswell as the input structure of the parsing process iswritten language, therefore we use the feature 'graph'instead of 'phon' which is preferably used in Pollardand Sag (1987).6Basic ideas of the approach are influenced by thehead-driven parser of Proudian and Pollard (1985).Because heads are processed first thecompletion of structures must be performed inleft as well as in right direction.The approach supports the ID/LP formatof rules.
But it is an open question whetherlinear precendence can be processed in thesame way for generation and parsing.
Theproblem is that during parsing the task of LPrules is to filter out ungrammatical structures.During generation the task of LP rules can beseen as an ordering criterion.
But in this casethe problem of choice between paraphrasesemerges.
In POPEL-HOW it is assumed thatthe order of activation of concepts (which isdetermined using pragmatical knowledge)should be maintained if it is syntacticallywellformed; otherwise the segments arereordered.
Whether such viewpoint isacceptable for generation in general is stillopen.4.2 ASPECTS OF CONTROLSTRUCTUREA major aspect of the BiLD project is thatspecific parametrization of the deductionprocess is represented in the lexicon as wellas in the grammar to obtain efficient structuresof control (Uszkoreit 1991).
The main idea isthat preference values are assigned to theelements (disjuncts or conjuncts) of featuredescriptions.
For example, in HPSG alllexical entries are put together into one largedisjunctive form.
From a purely declarativepoint of view these elements are unordered.But a preference structure is usrd duringprocessing in order to guide the process oflexical choice efficiently which itselfinfluences the grammatical process.To support flexibility and efficiency (in theway described in section 3) the language useof interlocutors will be considered to influencethe preference values.
For example, thefrequency of access of a lexeme will increaseits preference value.
In a uniform lexicon it isno matter whether the lexeme was accessedduring parsing or generation.
But this meansthat the use of particular linguistic elements ofthe interlocutor influences the choice of lexicalmaterial during generation.5 CONCLUSIONIn this paper it is argued that generationand parsing should be best viewed as twointerleaved tasks based on a singleparametrized deduction process and that thisview supports flexible and efficient natural- 249,language processing.
A major point of  view isthat the language use of  interlocutors houldbe cons idered  dur ing generat ion as anadditional access criterion.REFERENCESAllgayer J.; Jansen-Winkeln R.; Reddig C. andReithinger N. 1989 "Bidirectional use of knowledgein the multi-modal NL access system XTRA",Proceedings of the l l th International Joint Conferenceon Artificial Intelligence, 1492-1497.Appelt, D. E. 1987 "Bidirectional Grammars andthe Design of Natural Language GenerationSystems," In Y. Wilks (ed.)
Theoretical Issues inNatural Processing-3, New Mexico State University,Las Cruces, New Mexico, 185-191.Busemann, S. and Hauenschild, C. i988 "AConstructive View of GPSG or How to Make ItWork," Proceedings of the 12th InternationalConference on Computational Linguistics, 77-82.Dymetman, M. and Isabelle, P. 1988 "ReversibleLogic Grammars for Machine Translation,"Proceedings of the 2nd International Conference onTheoretical and Methodological Issues in MachineTranslation of Natural Language.Dymetman, M.; Isabelle P. and Perrauit, F. 1990"A Symmetrical Approach to Parsing and Generation,"Proceedings of the 13th International Conference onComputational Linguistics, 90-96.Finkler, W. and Neumann, G. 1989 "POPEL-HOW: A Distributed Parallel Model for IncrementalNatural Language Production with Feedback,"Proceedings of the Eleventh International JointConference on Artificial Intelligence, 1518-t523.Hoeppner, W.; Christaller, T.; Marburger, H.;Morik, K.; Nebel, B.; O'Leary, M. and Wahlster, W.1983 "Beyond Domain-Independence: Experience withthe Development of a Gel'man Language AccessSystem To Higly Diverse Background Systems,"Proceedings of the 8th International Joint Conferenceon Artificial Intelligence, 643-646.Horacek, H. and Pyka, C. 1988 "Anweiadbarkeitvon Unifikationsgrammatiken ftir effizientesGenerieren," In H. Trost (ed.)
4.0sterreichischeArtificial-lntelligence-Tagung, Springer, Berlin, 171-177.Jackendoff, R. 1987 "Consciousness and theComputational Mind," Cambridge Massachussetts:MIT Press.Jacobs, P. S. 1988 "Ach!eving Bidirectionality,"Proceedings of the 12th International Conference onComputational Linguistics, 267-274.Koskenniemi, K. 1984 "A General ComputationalModel for Word-Form Recognition and Production,"Proceedings of the lOth International Conference onComputational Linguistics, 178-181.Lancel, J.M.
; Otani, M.; Simonin, N. andDanlos, L. 1988 "SAGE: a Sentence Parsing andGeneration System," Proceedings of the 12thInternational Conference on ComputationalLinguistics, 359-364.Mann, W. C. 1987 "What is Special AboutNatural Language Generation Research?," In Y.Wilks (ed.)
Theoretical Issues in Natural Processing-3, New Mexico State University, Las Cruces, NewMexico, 206-211.McDonald D. D. 1987 "No Better, but no Worse,than People," In Y. Wiiks (ed.)
Theoretical Issues inNatural Processing-3, New Mexico State University,Las Cruces, New Mexico, 200-205.McDonald, D. D.; Meteer, M. W. andPustejovsky, J. D. 1987 "Factors Contributing toEfficiency in Natural Language Generation," In G.Kempen (ed.)
Natural Language Generation: NewResults in Artificial Intelligence, Psychology andLinguistics, Dordrecht: Martinus Nijhoff, 159-182.Neumann, G. and Finkler, W. 1990 "A Head,Driven Approach to Incremental and ParallelGeneration of Syntactic Structures," Proceedings ofthe 13th International Conference on ComputationalLinguistics, 288-293.van Noord, G. 1990 "Reversible Unification BasedMachine Translation," Proceedings of the 13thInternational Conference on ComputationalLinguistics, 299-304.Pereira, F. C. N. and Warren, D. H. D. 1983"Parsing as Deduction, " Proceedings of the 21thAnnual Meeting of the Association forComputationaL Linguistics, 137-144.Proudian, D. and Pollard, C. 1985 "Parsing Head,Driven Phrase iStructure Grammar, " Proceedings ofthe 23rd Annual Meeting of the Association forComputational Linguistics, 167-171.Pollard, C.!
and Sag, I.
1987 "Information-basedsyntax and semantics," CLSI Lecture Notes 13, Centerfor the Study of Language and Information, Standford,CA.Shieber, S. M. 1988 "A Uniform Architecture forParsing and Generation," Proceedings of the 12thInternational Conference on ComputationalLinguistics, 61,4-619.Shieber, S.iM.
; van Noord, G.; Moore, R. M. andPereira, F. C. P. 1989 "A Semantic Head-DrivenGeneration Algorithm for Unification-BasedFormalisms," Proceedings of the 27th AnnualMeeting of the Association for ComputationalLinguistics, 7-17.Uszkoreit, H. 1991 "Strategies for Adding ControlInformation to Declarative Grammars," TechnicalReport, Institute for Computational Linguistics,University of Saarbriicken, FRG.Zajac, R. and Emele, M. 1990 "Typed UnificationGrammars," Proceedings of the 13th InternationalConference onComputational Linguistics, 293-298.- 250 -
