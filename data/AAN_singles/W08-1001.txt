Proceedings of the ACL-08: HLT Workshop on Parsing German (PaGe-08), pages 1?8,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsLexcalised Parsing of German V2Yo SatoDepartment of Computer ScienceQueen Mary, University of LondonMile End Road, London E1 4NS, U.K.AbstractThis paper presents a method and implemen-tation of parsing German V2 word order bymeans of constraints that reside in lexicalheads.
It first describes the design of theunderlying parsing engine: the head-cornerchart parsing that incorporates a procedurethat dynamically enforces word order con-straints.
While the parser could potentiallygenerate all the permutations of terminal sym-bols, constraint checking is conducted locallyin an efficient manner.
The paper then showshow this parser can adequately cover a varietyof V2 word order patterns with sets of lexi-cally encoded constraints, including non-localpreposing of an embedded argument or an ad-verbial.1 IntroductionThis paper presents a method of parsing V2 wordorder manifested in a variety of German matrix sen-tences in a lexicalised and locality-respecting man-ner: lexicalised, as the V2 pattern is licensed ulti-mately encoded in verbs, in the form of constraintsthat hold amongst its arguments and itself; locality-respecting, because (a) no constraint that operates onconstituents from different subcategorisation framesis invoked and (b) the matrix verb and the prever-bal constituent, however ?distant?
its origin is, areordered in the same projection via the slash-basedmechanism.The underlying grammar is loosely linearisation-based, in the sense that word order is dissoci-ated from the syntactic structure in a discontinuity-allowing manner, as presented in Sato (2008).
Themain benefit of a linearisation approach is that syn-tactic constituency becomes independent (to a de-gree) of its surface realisation and hence discour-ages constituency manipulation for the sake of wordorder.
In line of this spirit I will largely adopt thesimple constituency construal that faithfully corre-spond to its semantics.
However, I distance myselffrom the more or less standard version of linearisa-tion grammar where potentially non-local LP con-ditions are permitted (Reape, 1993) or word orderpatterns are imposed at the clause level (as in ?topo-logical field?
model of Kathol (2000)).The crux of the proposal consists in employinga head-corner parsing in which the set of word or-der constraints are incorporated into a VP?s lexicalhead (i.e.
common or auxiliary verb).
For a V2 pro-jection, its head verb contains the constraints to theeffect that only one of its arguments can be frontedimmediately before the verb itself.
To enable this,potential discontinuity and obligatory adjacency inpart of a phrase is included in the repertoire of wordorder constraints in addition to the standard LP (lin-ear precedence) constraints.2 The dataThe V2 constructions to be dealt with in this paperare as follows (I will use as an example the tertiaryverb gebengive or its past participle gegebengiventhroughout):1.
The ?basic?
case where dependency betweenthe preverbal constituent and the matrix verb isstrictly local, e.g:1Ein Buch geben die Eltern dem Sohn.a book give the parents the son?A book the parents give the son?2.
The case where an argument of the lower verbis fronted across the higher auxiliary verb:Ein Buch haben die Eltern dem Sohn gegeben.a book have the parents the son given?A book the parents have given the son?3.
The long-distance dependency case:Ein Buch, sagt ein Freund, dass er glaubt, dass dieEltern dem Sohn geben.
?A book, a friend says that he thinks that the parentsgive the son?4.
Adjunct frontingHeimlich haben die Eltern dem Sohn ein Buch gegeben.secretly have the parents the son a book given?Secretly the parents have given the son a book.?5.
Partial VP frontingEin Buch dem Sohn gegeben haben die Eltern.Ein Buch gegeben haben die Eltern dem Sohn.As stated, our approach adopts a linearisation ap-proach in which constituency does not determine thesurface realisation, which is handled instead by wordorder conditions encoded in lexical heads.
My con-tention here is not so much plausibility as a grammaras neutrality to particular phrase structures, whichlinearisation promotes.
Therefore I take a rathersimplified position to use an entirely uniform phrasestructure for the verb-argument structure for com-mon verbs, namely the flat construal where all thearguments as well as the head project onto a clause(?VP?)
as mutual sisters, although I hasten to addour constraint enforcement could equally apply toconfigurational analyses.
In fact we take an auxil-iary verb to subcategorise for a clause rather thanthe complex verb analysis, and adopt the traditionalbinary iteration analysis for adjunct-head phrases, tosee how our parser fares with configurational analy-ses.I sum up the assumed constituency of the aboveexamples graphically as trees (though this has littleimpact on word order):(1) Clause(=VP)VgebenNPdie ElternDDNPdem SohnaaaNPein Buch(2)&(5)AuxhabenPPPClause(((( hhhh-e E. -em S. ein Buch gegeben(3) ((((((NPein FreundVsagtbbCP!
!CdassHHClauseNPerVglaubtaaCP""Cdass```C`lause    ````-e E. -em S. ein Buch geben(4) AuxhabenPPPClauseAdvheimlichPPPClause(((( hhhh-e E. -em S. ein Buch gegeben3 The parser3.1 Core designThe design of the parser employed here can becalled constrained free word order parsing.
First,it allows for completely free word order at default.The core algorithm for the parse engine is whatReape (1991) presents as a generalised permutation-complete parser, which in turn is based on the pre-ceding proposal of Johnson (1985).
Details apart,while using context-free production rules (no multi-ple left-hand side non-terminal symbols), this algo-rithm only checks for the presence of all the right-hand side constituents, wherever in the string theyoccur, potentially discontinuously,1 effectively li-censing all the permutations of the given terminalsymbols (e.g.
3!
= 6 permutations for the stringconsisting of ring, up and John including up Johnring etc.).
This ?directionless?
parsing is renderedpossible by Johnson?s ?bitvector?
representation ofpartial string coverage.
In the above up John ringstring, the coverage of the ring and up combina-1More precisely, it searches for non-overlapping combina-tions, excluding the same word being counted more than onceor more than one word counting towards the same rule in thesame search path.2tion, which materially constitutes a complex verb,is represented as [1,0,1].
This is then then mergedwith the bitvector of John, [0,1,0] into [1,1,1].
Sec-ond, however, this rather promiscuous (and expen-sive) parsing is dynamically restricted by word or-der constraints that obtain in individual languages.With sufficient constraints applied during the parse,the above combinations with ring, up and John arerestricted to ring up John and ring John up.I do not claim for originality in this basic design.Daniels (2005) for example describes an implemen-tation of an algorithm that falls precisely in suchstyle of parsing.2 The main points of the proposallie in lexicalisation and localisation, which contrastwith the general trend to introduce phrasal and non-local constraint processing for German processing,of which Daniels?
work is an example.
All the wordorder constraints are stored in lexicon, more specifi-cally in lexical heads.To adapt this design to a practical lexically drivenparsing, the author implemented a rendering ofhead-corner chart parsing.
It is head-corner in thesense described e.g.
in van Noord (1991), wherethe parsing of a production rule always starts fromits head.
This is necessary for our design becausethe parser first retrieves the word order informationfrom the head.
Furthermore, it requires the wordsto be processed first by preterminal rules since with-out processing lexical heads the whole recognitionprocess does not come off the ground.
Therefore, achart parsing algorithm that invokes lexical initiali-sation is utilised (as described in Gazdar & Mellish(1989) rather than the classical top-down parsing ofEarley (1970)).3.2 Constraint checking and propagationSince no non-local word order constraints are intro-duced in our parsing, they can be fully enforced ateach application of a production rule.
More specif-ically, the checking of constraint compliance is car-ried out at the completer operation of chart pars-ing.3 The data structure of an edge is suitably mod-ified.
In addition to the dotted production rule, itneeds to carry the constraint set relevant to the corre-2A foregoing implementation by Mu?ller (2004) also em-ploys bitvector-based linearisation approach.3The equivalent operation is called the ?fundamental rule?
inGazdar & Mellish (1989).sponding production rule, retrievable from the head,which is always processed first in our head-corneralgorithm.4 Also, as we are adopting the bitvectorrepresentation of coverage, an edge contains its cor-responding bitvector.
The completer operation in-volves merger of two bitvectors, so the check can beconducted at this stage:Completer in constrained parsingLet A and B be symbols, ?, ?
and ?
be arbi-trary strings, V1 and V2 be bitvectors and V mbe their merge, then:If the chart contains an active edge ?V1, A?
??
B ??
and a passive edge ?V2, B?
?
?
?, runthe CHECK-ORDER procedure.
If it succeeds,add edge ?V m, A?
?B ?
??
to the chart if V1and V2 are mergeable.
If it fails, do nothing.The CHECK-ORDER procedure consists in a bit-wise comparison of bitvectors.
It picks out thebitvectors of the categories in question and checksthe compliance of the newly found category with re-spect to the relevant constraints.
If for example A, Band C had been found at [0,1,0,0,0], [0,0,1,0,1] and[1,0,0,1,0] respectively, this would validate A ?
Bbut not A ?
C. Thus the edges for string combina-tions that violate the word order constraints wouldnot be created, eliminating wasteful search paths.As we will shortly see, the constraint type thatchecks continuity of a phrase is also introduced.Therefore the phrase (dis)continuity can also be as-certained locally, which is a major advantage over aparsing that relies largely on concatenation.
Thus,the cost of constraint checking remains very smalldespite the capability of processing discontinuity.5Note however that by locality is meant subcat-egorisation locality (or ?selection?
locality as de-scribed in Sag (2007)): whatever is in the samesubcategorisation frame of a lexical head is consid-ered local.
Depending on the adopted analysis, con-stituents ?local?
in this sense may of course occurin different trees.
Constraints on such ?non-local?
?in the tree sense but not in the subcategorisationsense?
constituents are still enforceable in the im-plemented parser.
The unused constraints at a node,4This retrieval of word order information is carried out at thepredictor stage of chart parsing.5It is worth mentioning that the bitvector checking is con-ducted over the whole string, the effect of applied constraintswill be never lost.3for example some constraint applicable to the verband its subject at the VP node in the configurational(subjectless-VP) analysis, is made to propagate upto the upper node.
Thus it is no problem to enforcea constraint over ?different trees?, as long as it is ap-plied to ?local?
constituents in our sense.64 Possible constraints and subtypingIt is crucial, if the computational properties of theparser is to be transparent in constrained free wordorder parsing, to identify the kind of word order con-straints admitted into lexical heads.
We will remainrelatively conservative, in introducing only two op-erators for constraint encoding.
We first invoke thebinary LP operator (?)
in a conventional sense: thewhole (or, equivalently, right-periphery) of a stringfor category A needs to precede the whole (or left-periphery) of a string for category B to satisfy A ?B (I will use the shorthand A ?
(B,C) to express(A ?
B) ?
(A ?
C).
Crucially, the contiguity op-erator () is added.
It takes a set of constituents as itsoperand and requires the constituents in it to be con-tiguous, regardless of their order.
Thus, {A,B,C}encodes the requirement for A, B and C as a wholeforming a contiguous string.
For example, the stringI ring John up does not satisfy {ring, up} but doessatisfy {ring, John, up}.Also important is how to succinctly generaliseon the word order patterns now encoded in lexicalitems, as one would certainly want to avoid a te-dious task of writing them all individually, if theyallow for broader classification.
For example the En-glish transitive verb generally follows its subject ar-gument and precedes its object argument, and onewould naturally want to lump these verbs under oneumbrella.
For such a cluster of lexical heads, we willintroduce a word order (sub)type.
More pertinently,the German verbs may be classified into v1-verb, v2-verb and vf-verb according to the positions of theirarguments in their projection.
We will also allowmultiple inheritance that becomes standard in thetyped feature system (cf.
Pollard and Sag (1987)).6See Sato (2006) for details.5 Constraints for V25.1 General setupTo enforce the V2 word order pattern lexically, I pro-pose to use a combination of two word order sub-types: dislocating-verb (disl-v) and matrix-v2-verb(mtrx-v2-v).
The former type represents a verb oneof whose arguments is to be ?dislocated?.
A verb ofthis type can thus be characterised as ?contributing?the dislocated (preverbal) element.
The latter, on theother hand, is the type that is projected onto a ma-trix sentence.
This type should be constrained suchthat one dislocated constituent must ?and only onemay?
precede and be adjacent to the verb itself.
Itmay be characterised as a verb that provides a locus?immediately before itself?
of, or ?receives?
thedislocated element.Dislocation is handled by a constraint percola-tion mechanism.
I assume the dislocated constituentis pushed into a storage that then participates in aslash style percolation, although the storage contentwould still need to be ordered by lexicalised con-straints rather than by the percolation mechanism it-self, as they are the sole resource for word order.7Thus the checking as regards the dislocated con-stituent is conducted at each projection in the per-colation path, hence locally, while the percolationmechanism gives some ?global?
control over disloca-tion.
Not just the positioning of the dislocated con-stituent at the left-periphery of the whole sentence,but the assurance of a global singularity restrictionof dislocation ?not just one constituent per clausein multiple embeddings?
becomes thus possible.Let args be the set of the arguments of a disl-v,disl be that of the dislocated one and situ be that ofthe remaining arguments, i.e.
disl ?
args where|disl| = 1 and situ = {x|x ?
args ?
x /?
disl}.Then the type disl-v can be characterised as havingthe following constraint:disl-v: disl ?
situ (disl ?
dislst)Simply put, this says that the arguments are dividedinto two parts, the dislocated and in-situ parts, theformer of which precedes the latter.
We assume, as7The adopted mechanism is close to Penn (1999), thoughhe invokes potentially non-local topology-based constraints andremoves the filler and gapped head entirely.4in the standard treatment, there is only one dislo-cated constituent, until we consider the VP fronting.The notation with an arrow on the right indicates thissingleton set is pushed into the storage that is prop-agated upwards.The mtrx-v2-v type is then characterised as fol-lows:mtrx-v2-v: dislst ?
verb, {dislst, verb}This simply says the dislocated constituent (storedin a lower node and percolated) immediately pre-cedes the matrix verb.
(For the following presen-tation, the storage-related notations will be omittedand implicitly assumed unless necessary.
Also, theset variables disl and args will be used with the samemeaning.
)Thus the combination of the two types gives, forexample where args = {A,B,C}, disl = {A} andthe matrix verb is V , the following constraint set:{A ?
(B,C), A ?
V, {A, V }}which essentially says that the dislocated A immedi-ately precedes the matrix verb V and precedes (notnecessarily immediately) the in-situ B and C.5.2 Local caseTo begin with, let us see a case where dependencybetween the preverbal constituent and the matrixverb is strictly local, taking (1) as an example.
Notefirst that there are six possible variants:(1)a.
Die Eltern geben dem Sohn ein Buch.b.
Die Eltern geben ein Buch dem Sohn.c.
Dem Sohn geben die Eltern ein Buch.d.
Dem Sohn geben ein Buch die Eltern.e.
Ein Buch geben die Eltern dem Sohn.f.
Ein Buch geben dem Sohn die Eltern.In this case, geben is both a matrix (argument-receiving) and dislocating (argument-contributing)verb.
This means that the two subtypes should beoverloaded.
Let us call this overloaded sub-speciesdisl-mtrx-v2-v: which is given the following specifi-cation:disl-mtrx-v2-v:disl ?
situ, disl ?
verb, {disl, verb}To adapt this type to our verb, geben, where we rep-resent its arguments as sNP (subject NP), ioNP (in-direct object NP) and doNP (direct object NP), weobtain, for the case where sNP is preposed:{sNP ?
(ioNP, doNP),sNP ?
geben, (sNP, geben)}where the constraints on the first line is inher-ited from disloc-v while those on the second frommatrix-v2-v.
This corresponds to the sentences (a)and (b) above.
The followings are the cases whereioNP and doNP are preposed, corresponding to (c,d)and (e,f), respectively.
{ioNP ?
(sNP, doNP), ioNP ?
geben, (ioNP, geben)}{doNP ?
(sNP, ioNP), doNP ?
geben, (doNP, geben)}These possible sets are enforced in the manner ofexclusive disjunction, that is, only one of the abovethree sets actually obtains.
This does not mean, how-ever, each set must be explicitly stated in the verband processed blindly.
Only the abstract form ofthe constraint, as described under the type specifi-cation above, is written in the lexicon.
During pars-ing, then, one of the sets, as dynamically found tomatch the input string, is computed and applied.
Inthe subsequent discussion, therefore, only the direct-object fronting case is considered as a representativeexample for each construction.5.3 Argument fronting across auxiliaryWe now consider the cases where the dependency isnot local, starting with an auxiliary-involving case.The dependency between an auxiliary and an ar-gument of its lower verb is, according to the Aux-Clause construal adopted here, is not local.
We canhowever succinctly specify such non-local V2 ren-derings as a case where the above two types are in-stantiated separately in two verbs.
The example isreproduced below:(2) Ein Buch haben die Eltern dem Sohn gegeben.The argument-contributing gegebengiven is, asbefore, assigned the disl-v type, but is further sub-typed and inherits the constraints also from vf-v (v-final verb), reflecting the fact that it occurs head-finally.gegeben (type disl-vf-v):{doNP ?
(sNP, ioNP),5(sNP, doNP, ioNP) ?
gegeben}The dislocated doNP climbs up the tree ((2) inSection 2) in the storage, which is then subject tothe constraints of matrix haben at the top node.
Thisargument-receiving auxiliary haben is, as before,given the mtrx-v2-v status.8.haben (type mtrx-v2-v):{doNPst ?
haben, (doNPst, haben)}Thus the dislocated ein Buch is duly placed at theleft-periphery in a manner that forbids interventionbetween itself and the matrix verb.5.4 Long-Distance DependencyHaving dealt with an argument fronting of the auxil-iary construction as a non-local case, we could nowextend the same treatment to long-distance depen-dency.
Our example is:(3) Ein Buch, sagt ein Freund, dass er glaubt, dassdie Eltern dem Sohn geben.
(?A book, a friend says that he thinks that theparents give the son?
)In fact, it suffices to endow exactly the same typeas gegeben, i.e.
disl-vf-v, to the occurrence of gebenin a subordinate clause.9geben (in subord.
clause, type disl-vf-v):{doNP ?
(sNP, ioNP),(sNP, doNP, ioNP) ?
geben}This ensures that the dislocated argument goesprogressively up towards the top node.
To preventthis argument from being ?dropped?
the half waythrough, however, the non-matrix CP-taking verbs?in the middle?
that should be bypassed, in our caseglaubt, needs to possess the constraint that pushesthe dislocated element to the left of itself:glaubt (in subord.
clause, type ?middle-v?
):10{doNPst ?
glaubt}8More precisely this also involves haben?
VP(gapped)9This means that, given the identical morphological form,gegeben is type-ambiguous between the matrix and subordinateoccurrences.
This does not add too much to parsing complexity,however, as this ?ambiguity?
is quickly resolved when one of itsargument is encountered.10The constraints applicable to the usual finite verb is omit-ted, i.e.
sNP ?
glaubt and glaubt ?
CP(gapped).Finally, a mtrx-v2-v, in our case sagt, takes care ofplacing the dislocated constituent immediately be-fore itself.sagt (type mtrx-v2-v):11{doNPst ?
sagt, (doNPst, sagt)}5.5 Adjunct frontingI declared at the beginning to use the traditional bi-nary adjunction analysis for adjunct-head phrases.12In order to achieve this, I first propose a fundamentalconceptual shift, given the iterability and optionalityof adjuncts.
In the traditional concept of adjunct-head phrases, it is the adjunct that selects for thehead it modifies rather than the other way round.Also semantically, the adjunct is considered the ?se-mantic head?
that works as a functor.
In light ofthis background, it is not implausible to take theadjunct as the ?parsing head?
equipped with wordorder constraints.
In fact, the opposite option ?equipping the syntactic head with its relative wordorder with adjuncts?
is not as feasible in our lexi-cal head-corner parsing.
The iterability of adjunctsmeans that the head would have to be equipped withan infinite number of adjuncts as its ?arguments?,which would lead to various uninstantiation prob-lems.
Therefore, I swap the statuses and treat, interms of parsing, the adjunct as a functor with wordorder constraints incorporated relative to its modi-fiee.Thus, the word order constraints are now givento the lexical adjuncts also.
I will take as an ex-ample adverbs.13 Adverbs are now the potential lo-cus of word order patterns relative to its modifiee(clause/VP), but are not given any specific constraintin German generally, because one can appear eitherafter or inside a clause.
Our focus is solely on thepossibility of putting one before the clause it modi-fies, when it is subject to the V2 constraint.
This ishandled simply by saying, for such a type, which wecall disl-adverb, it dislocates itself, in the manner of11Likewise: sagt ?
CP(gapped) omitted.12That is against the temptation for a constituency changethat renders adjuncts sisters on par with arguments (cf.
Boumaet al(2001)), in which case V2 would simply fall out from theforegoing word order types.13The same treatment can be extended to prepositional ad-juncts (remember the unused constraints will percolate up tothe maximal projection).6?head movement?
which is widely used in Germansyntax (Kiss and Wesche, 1991; Netter, 1992).disl-adverb: adv (adv?
dislst)This specification ensures the adverb itself goesonto the extraction path, to be placed at the left-periphery, triggered by the mtrx-v2-v type.
The sin-gularity of the adverbials at the prerverbal positionis ensured by means of percolation storage control.6 Verbal FrontingOur last challenge concerns fronting of verb or ver-bal projections.
From the preceding discussion, anoption that suggests itself is to treat the verb frontingas the case of verb dislocating itself.
I will in-deed propose a strategy along this line, but this av-enue proves more difficult due to complications spe-cific to verb-related fronting.
Firstly, generally suchfronting is limited to the environment of a lower VPgoverned by a higher verb such as an auxiliary, ascan be seen from the following contrast:(4)a. Gegeben haben die Eltern dem Sohn ein Buch.b.
*Geben, sagt ein Freund, dass die Eltern dem Sohn einBuch.Second, the type we used for gegeben in Section5.3, namely disl-vf-v, clearly does not work, as theverb does not occur phrase-finally (but in fact ini-tially) relative to its sisters in (4a).
Some relaxationof LP constraints seem to be in order.Thirdly, German displays a variety of ways tofront part of a VP:(5)Gegeben haben die Eltern dem Sohn ein Buch.Dem Sohn gegeben haben die Eltern ein Buch.Ein Buch gegeben haben die Eltern dem Sohn.Dem Sohn ein Buch gegeben haben die Eltern.This raises the question of whether this fits in the V2pattern at all, coupled with the ongoing debate on thestatus of the preverbal string.
Quite apart from thetheoretical debate, however, how best to adequatelygenerate these patterns is an acute parsing issue.
Weare assuming the flat clause=VP anaylsis, so relax-ing the singularity condition seems unavoidable.Fourthly, to make the matter worse, allowing mul-tiple frontings and dropping LP requirements doesnot solve the problem, as ordering of the preverbalconstituents is constrained, as shown in the follow-ing data:(6)*Gegeben dem Sohn haben die Eltern ein Buch.
*Dem Sohn gegeben ein Buch haben die Eltern.It is a great challenge for any syntactician to pro-vide a unified account for such complex behaviour,and I confine myself here to offering the ?solution?sets of constraints that adequately generate the de-sired string.
What I offer is this: allowing multipledislocations only for the verbal fronting cases via anew word order subtype, while retaining the verb-final LP conditions for these dislocated constituents.For this new type we first relax the singularitycondition for dislocation.
To allow multiple dislo-cations, it would suffice to drop the |disl| = 1 condi-tion, but an unrestricted application of disl ?
argswould lead to overgeneration, due to two furtherconstraints applicable: (1) not all arguments can and(2) the subject argument cannot be fronted alongwith the verb (as in (a) and (b) below, respectively):(7)a.
*Die Eltern dem Sohn ein Buch gegeben haben.b.
*Die Eltern gegeben haben dem Sohn ein Buch.
*Die Eltern ein Buch gegeben haben dem Sohn.Therefore we add the conditions to exlude the above,along with the the verb-final constraint applicablethe dislocated constituents to exclude (6).
Let us callthis type frontable-v.
The constraint specification isas follows:gegeben (frontable-v):disl = {gegeben} ?
ptargs, ptargs ?
gegebenwhere ptargs ?
args and sNP /?
ptargsThe proposed constraint set might strike as ratherad hoc.
It would clearly be better to treat both thefronted and non-fronted occurrences of gegeben assharing some common word order type, and what ismeant by ?applying the constraints amongst the dis-located constituents?
needs to be fleshed out.
Thusthis may not be an elegant solution, but neverthelessis an generatively adequate solution.
More impor-tantly it serves as a good example for the flexibility7and adaptability of constrained free word order pars-ing, because it handles a rather complex word orderpattern in a way neutral to grammatical construal,i.e.
without invoking constituency manipulation.7 Concluding RemarksI conclude this paper by responding to a natural ob-jection: why would one have to go through this con-voluted route of lexical word order control, whenthe ?natural?
way to constrain V2 ?or V1 and VF,for that matter?
would be to have some ?global?patterns pertinent to clause types?
My responsesare primarily engineering-oriented.
First, lexicalisedencoding gives the parser, through locality restric-tion, a certain control over computational complex-ity, as the search space for constraint enforcement isrestricted.14 However this not an entirely unique, ifmore amenable, feature to lexicalised parsing, as onecould impose such a control in non-lexicalised pars-ing.
The advantage truly unique to lexicalising wordorder lies in rendering the parser and grammar in-dependent of surface realisation and hence re-usableacross languages.
In short, it promotes modularity.As we have seen, though the parser needs to con-form to a certain strategy, the word order componentis fairly independent, as a separate procedure whichcan be modified if for example more types of wordorder operators are needed.
The grammar could alsobe kept more compact and cross-linguistically appli-cable, because word order is abstracted away fromconstituency.
Therefore, paradoxically, an advan-tage of lexicalising German parsing is to enable thesame parser/grammar to be used in other languagestoo, even if it is not naturally suited to the language.ReferencesGosse Bouma, Robert Malouf, and Ivan Sag.
2001.
Sat-isfying constraints on extraction and adjunction.
Nat-ural Language and Linguistic Theory, 19(1).Mike Daniels.
2005.
Generalized ID/LP Grammar.Ph.D.
thesis, Ohio State University.Jay Earley.
1970.
An efficient context free parsing algo-rithm.
Communications of ACM, 13:94?102.Gerald Gazdar and Chris Mellish.
1989.
Natural Lan-guage Processing in Prolog.
Addison Wesley.14For a complexity analysis of such grammar, see Sato (2008)and Suhre (1999).Mark Johnson.
1985.
Parsing with discontinuous con-stituents.
In Proceedings of the 23rd Annual Meetingof the ACL, pages 127?132.Andreas Kathol.
2000.
Linear Syntax.
OUP.Tibor Kiss and B Wesche.
1991.
Verb order and headmovement.
In O Herzog, editor, Text Understandingin LILOG, pages 216?40.
Springer.Stefan Mu?ller.
2004.
Continuous or discontinuous con-stituents?
a comparison between syntactic analyses forconstituent order and their processing systems.
Re-search on Language and Computation 2(2).Klaus Netter.
1992.
On non-head non-movement.
AnHPSG treatment of finite verb position in German.In G. Go?rz, editor, Proceedings of KONVENS 92.Springer.Gerald Penn.
1999.
Linearization and Wh-extraction inHPSG: Evidence from Serbo-Croatian.
In R. Borselyand A. Przepiorkowski, editors, Slavic in HPSG.CSLI.Carl Pollard and Ivan Sag.
1987.
Information-BasedSyntax and Semantics.
CSLI.Mike Reape.
1991.
Parsing bounded discontinuous con-stituents: Generalisation of some common algorithms.DIANA Report, Edinburgh University.Mike Reape.
1993.
A Formal Theory of Word Order.Ph.D.
thesis, Edinburgh University.Ivan Sag.
2007.
Remarks on locality.
In Stefan Mu?ller,editor, Proceedings of HPSG07.
CSLI.Yo Sato.
2006.
A proposed lexicalised linearisationgrammar: a monostratal alternative.
In Stefan Mu?ller,editor, Proceedings of HPSG06.
CSLI.Yo Sato.
2008.
Implementing Head-Driven Linearisa-tion Grammar.
Ph.D. thesis, King?s College London.Oliver Suhre.
1999.
Computational Aspects of a Gram-mar Formalism for Languages with Freer Word Order.Diplomarbeit, Eberhard-Karls-Universita?t Tu?bingen.Gertjan van Noord.
1991.
Head corner parsing for dis-continuous constituency.
In Proceedings of the 29thannual meeting on ACL, pages 114?121.8
