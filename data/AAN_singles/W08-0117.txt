Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 100?103,Columbus, June 2008. c?2008 Association for Computational LinguisticsImplicit Proposal Filteringin Multi-Party Consensus-Building ConversationsYasuhiro KatagiriFuture University ?
Hakodatekatagiri@fun.ac.jpYosuke MatsusakaNational Institute of AdvancedIndustrial Science and Technologyyosuke.matsusaka@aist.go.jpYasuharu DenChiba Universityden@cogsci.l.chiba-u.ac.jpMika EnomotoTokyo University of Technologymenomoto@media.teu.ac.jpMasato IshizakiThe University of Tokyoishizaki@iii.u-tokyo.ac.jpKatsuya TakanashiKyoto Universitytakanasi@ar.media.kyoto-u.ac.jpAbstractAn attempt was made to statistically estimateproposals which survived the discussion tobe incorporated in the final agreement in aninstance of a Japanese design conversation.Low level speech and vision features of hearerbehaviors corresponding to aiduti, noddingsand gaze were found to be a positive pre-dictor of survival.
The result suggests thatnon-linguistic hearer responses work as im-plicit proposal filters in consensus building,and could provide promising candidate fea-tures for the purpose of recognition and sum-marization of meeting events.1 IntroductionNon-verbal signals, such as gaze, head nods, fa-cial expressions and bodily gestures, play signif-icant roles in the conversation organization func-tions.
Several projects have been collecting multi-modal conversation data (Carletta et al, 2006) formulti-party dialogues in order to develop techniquesfor meeting event recognitions from non-verbal aswell as verbal signals.
We investigate, in this paper,hearer response functions in multi-party consensus-building conversations.
We focus particularly on theevaluative aspect of verbal and non-verbal hearer re-sponses.
During the course of a consensus-buildingdiscussion meeting, a series of proposals are puton the table, examined, evaluated and accepted orrejected.
The examinations of proposals can takethe form of explicit verbal exchanges, but they canalso be implicit through accumulations of hearerresponses.
Hearers would express, mostly uncon-sciously for non-verbal signals, their interest andpositive appraisals toward a proposal when it isintroduced and is being discussed, and that thesehearer responses would collectively contribute to thedetermination of final consensus making.
The ques-tion we address is whether and in what degree it ispossible and effective to filter proposals and estimateagreement by using verbal and non-verbal hearer re-sponses in consensus-building discussion meetings.2 Multi-Party Design Conversation Data2.1 Data collectionWe chose multi-party design conversations for thedomain of our investigation.
Different from a fixedproblem solving task with a ?correct?
solution, par-ticipants are given partially specified design goalsand engage in a discussion to come up with an agree-ment on the final design plan.
The condition of ourdata collection was as follows:Number of participants: six for each sessionArrangement: face-to-face conversationTask: Proposal for a new mobile phone businessRole: No pre-determined role was imposedA compact meeting archiver equipment, AIST-MARC (Asano and Ogata, 2006), which can cap-ture panoramic video and speaker-separated speechstreams, was used to record conversations (Fig.
1).The data we examined consist of one 30 minutesconversation conducted by 5 males and 1 female.Even though we did not assign any roles, a chairper-son and a clerk were spontaneously elected by theparticipants at the beginning of the session.100Figure 1: AIST-MARC and a recording scene2.2 Data Annotation2.2.1 Clause unitsIn order to provide a clause level segmentationof a multi-channel speech stream, we extended thenotion of ?clause units (CUs)?, originally developedfor analyzing spoken monologues in the Corpus ofSpontaneous Japanese (Takanashi et al, 2003), toinclude reactive tokens (Clancy et al, 1996) andother responses in spoken conversations.
Two of theauthors who worked on the Corpus of SpontaneousJapanese independently worked on the data and re-solved the differences, which created 1403 CUs con-sisting of 469 complete utterances, 857 reactive to-kens, and 77 incomplete or fragmental utterances.2.2.2 Proposal unitsWe developed a simple classification scheme ofdiscourse segments for multi-party consensus build-ing conversations based on the idea of ?interactionprocess analysis?
(Bales, 1950).Proposal: Presentation of new ideas and their eval-uation.
Substructure are often realized throughelaboration and clarification.Summary: Sum up multiple proposals possiblywith their assessmentOrientation: Lay out a topic to be discussed andsignal a transition of conversation phases, initi-ated mostly by the facilitator of the discussionMiscellaneous: Other categories including openingand closing segmentsThe connectivity between clause units, the contentof the discussion, interactional roles, relationshipwith adjacent segments and discourse markers wereconsidered in the identification of proposal units.Two of the authors, one worked on the Corpus ofSpontaneous Japanese and the other worked for theFigure 2: Image processing algorithmproject of standardization of discourse tagging, in-dependently worked on the data and resolved thedifferences, which resulted in 19 proposals, 8 sum-maries, 19 orientations and 2 miscellaneouses.2.3 Core clause units and survived proposalunitsCore clause units (CUs) were selected, out of all theclause units, based on whether the CUs have sub-stantial content as a proposal.
A CU was judgedas a core CU, when the annotator would find it ap-propriate to express, upon hearing the CU, either anapproval or a disapproval to its content if she werein the position of a participant of the conversation.Three of the authors worked on the text data exclud-ing the reactive tokens, and the final selection wassettled by majority decision.
35 core CUs were se-lected from 235 CUs in the total of 19 proposal PUs.Cohen?s kappa agreement rate was 0.894.Survived proposal units (PUs) were similarly se-lected, out of all the proposal units, based onwhether the PUs were incorporated in the finalagreement among all the participants.
9 survivedPUs were selected from 19 proposal PUs.3 Feature Extraction of Hearer?s BehaviorFor each clause unit (CU), verbal and non-verbalfeatures concerning hearer?s behavior were ex-tracted from the audio and the video data.3.1 Non-Verbal FeaturesWe focused on nodding and gaze, which were ap-proximated by vertical and horizontal head move-ments of participants.An image processing algorithm (Figure 2) was ap-plied to estimate head directions and motions (Mat-susaka, 2005).
Figure 3 shows a sample scene andthe results of applying head direction estimation al-gorithm.101Figure 3: Sample scene with image processing results.The circles represent detected face areas, and the lines inthe circles represent head directions.For each CU, the vertical and horizontal compo-nents of head movements of 5 hearers were calcu-lated for two regions, the region inside the CU andthe 1-sec region immediately after the CU.
For eachof the two regions, the mean and the peak values andthe relative location, in the region, of the peak werecomputed.
These 12 non-verbal features were usedfor the statistical modeling.3.2 Verbal FeaturesVerbal features were extracted from the audio data.For each CU, power values of 5 hearers were ex-tracted for two regions, ?within?
and ?after?
CU, andfor each of the two regions, the mean and the peakvalues and the relative location, in the region, ofthe peak were computed.
In addition to these ver-bal features, we also used aiduti features of reactivetokens (RTs).
The percentage of the total durationof RTs, the total number of RTs, and the number ofparticipants who produced an RT were computed in?within?
and ?after?
regions for each of the CUs.
Atotal of 12 CU verbal features were used for the sta-tistical modeling.4 Experiments4.1 Overview of the AlgorithmStatistical modeling was employed to see if it is pos-sible to identify the proposal units (PUs) that are sur-vived in the participants?
final consensus.
To thisend, we, first, find the dominant clause unit (CU) ineach PU, and, then, based on the verbal and non-verbal features of these CUs, we classify PUs into?survived?
and ?non-survived.
?Table 1: The optimal model for finding core-CUsEstimate(Intercept) ?1.72within/speech power/mean ?11.54after/vertical motion/peak loc.
?4.25after/speech power/mean 3.91after/aiduti/percent 3.02Table 2: Confusion matrix of core-CU prediction experi-ment (precision = 0.50, recall = 0.086)PredictedObserved Non-core CoreNon-core 431 3Core 32 34.2 Finding Dominant CUsA logistic regression model was used to model thecoreness of CUs.
A total of 24 verbal and non-verbalfeatures were used as explanatory variables.
Sincethe number of non-core CUs was much larger thanthat of core CUs, down-sampling of negative in-stances was performed.
To obtain a reliable estima-tion, a sort of Monte Carlo simulation was adopted.A model selection by using AIC was applied forthe 35 core CUs and another 35 non-core CUs thatwere re-sampled from among the set of 434 com-plete and non-core CUs.
This process was repeated100 times, and the features frequently selected inthis simulation were used to construct the optimalmodel.
Table 1 shows the estimated coefficient forthe optimal model, and Table 2 shows the accu-racy based on a leave-1-out cross validation.
Thedominant CU in each PU was identified as the CU600 700 800 900 1000 1100 12000.00.20.40.60.81.0time[sec]core?CUlikelihoodO P S S O O P S S S P P O S P OO0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0(0) (0) (1) (0) (0)(0)(0) (0) (0) (0) (0) (0) (1) (0) (0) (0) (0)(0)Figure 4: The predicted coreness of CUs.
Dominant CUswere defined to be CUs with the highest coreness in eachof the PUs.
Black and white dots are CUs labeled as coreand non-core.102Table 3: The optimal model for finding survived-PUsEstimatewithin/vertical motion/peak val.
3.96within/speech power/mean ?27.76after/speech power/peak val.
1.49Table 4: Result of the survived-PU prediction (precision= 0.83, recall = 0.44)PredictedObserved Non-survived SurvivedNon-survived 37 1Survived 4 5with the highest predicted value in that PU.
Figure 4shows the predicted values for coreness.4.3 Finding Survived PUsThe verbal and non-verbal features of the dominantCUs of each of the PUs were used for the modelingof the survived-PU prediction.
Discriminant analy-sis was utilized and a model selection was appliedfor the 47 PUs.
Table 3 shows the estimated coeffi-cient for the optimal model, and Table 4 shows theaccuracy based on a leave-1-out cross validation.5 DiscussionsThe results of our estimation experiments indicatethat the final agreement outcome of the discus-sion can be approximately estimated at the proposallevel.
Though it may not be easy to identify actualutterances contributing to the agreement (core-CUs),the dominant CUs in PUs were found to be effectivein the identification of survived-PUs.
The predictionaccuracy of survived-PUs was about 89%, with thechance level of 69%, whereas that of core-CUs wasabout 92%, with the chance level of 86%.In terms of hearer response features, intensityof verbal responses (within/speech power/mean, af-ter/speech power/mean), and immediate nodding re-sponses (after/vertical motion/peak loc.)
were themost common contributing features in core-CU es-timation.
In contrast, occurrence of a strong aidutiimmediately after, rather than within, the core-CU (after/speech power/peak val.
), and a strongnodding within the core-CU (within/vertical mo-tion/peak val.)
appear to be signaling support fromhearers to the proposal.
It should be noted that iden-tification of target hearer behaviors must be vali-dated against manual annotations before these gen-eralizations are established.
Nevertheless, the re-sults are mostly coherent with our intuitions on theworkings of hearer responses in conversations.6 ConclusionsWe have shown that approximate identification ofthe proposal units incorporated into the final agree-ment can be obtained through the use of statisticalpattern recognition techniques on low level speechand vision features of hearer behaviors.
The resultprovides a support for the idea that hearer responsesconvey information on hearers?
affective and evalu-ative attitudes toward conversation topics, which ef-fectively functions as implicit filters for the propos-als in the consensus building process.AcknowledgmentsThe work reported in this paper was supported by JapanSociety for the Promotion of Science Grants-in-aid forScientific Research (B) 18300052.ReferencesF.
Asano and J. Ogata.
2006.
Detection and separationof speech events in meeting recordings.
In Proc.
Inter-speech, pages 2586?2589.R.
F. Bales.
1950.
A set of categories for the analysisof small group interaction.
American Sociological Re-view, 15:257?263.J.
Carletta, S. Ashby, S. Bourban, M. Flynn, M. Guille-mot, T. Hain, J. Kadlec, V. Karaiskos, W. Kraaij, M.Kronenthal, G. Lathoud, M. Lincoln, A. Lisowska, I.McCowan, W. Post, D. Reidsma, and P.Wellner.
2006.The AMI meeting corpus: A pre-announcement.
InMachine Learning for Multimodal Interaction, pages28?39.P.
M. Clancy, S. A. Thompson, R. Suzuki, and H. Tao.1996.
The conversational use of reactive tokens in En-glish, Japanese and Mandarin.
Journal of Pragmatics,26:355?387.Y.
Matsusaka.
2005.
Recognition of 3 party conversationusing prosody and gaze.
In Proc.
Interspeech, pages1205?1208.K.
Takanashi, T. Maruyama, K. Uchimoto, and H.Isahara.
2003.
Identification of ?sentence?
in.spontaneous Japanese: detection and modification ofclause boundaries.
In Proc.
ISCA & IEEE Workshopon Spontaneous Speech Processing and Recognition,pages 183?186.103
