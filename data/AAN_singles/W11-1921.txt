Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 127?130,Portland, Oregon, 23-24 June 2011. c?2011 Association for Computational Linguistics1Coreference Resolution System using Maximum Entropy ClassifierWeipeng Chen,Muyu Zhang,Bing QinCenter for Information RetrievalHarbin Institute of Technology{wpchen,myzhang,bing.qin}@ir.hit.edu.cnAbstractIn this paper, we present our supervisedlearning approach to coreference resolutionin ConLL corpus.
The system relies on amaximum entropy-based classifier for pairsof mentions, and adopts a rich linguisitical-ly motivated feature set, which mostly hasbeen introduced by Soon et al(2001), andexperiment with alternaive resolution proc-ess, preprocessing tools,and classifiers.
Weoptimize the system?s performance for M-UC (Vilain et al 1995), BCUB (Bagga andBaldwin, 1998) and CEAF (Luo, 2005) .1.
IntroductionThe coreference resolution is the task in which allexpressions refer to the same entity in a discoursewill be identified.
As the core of natural languageprocessing, coreference resolution is significant tomessage understanding, information extraction,text summarization, information retrieval, informa-tion filtration, and machine translation.A considerable engineering efforts is needed forthe full coreference resolution task, and a signifi-cant part of this effort concerns feature engineering.The backbone of our system can be split into twosubproblems: mention detection and creation ofentitly.
We train a mention detector on the trainingtexts.
Once the mentions are identified, coreferenceresolution involves partitioning them into subsetscorresponding to the same entity.
This problem iscast into the binary classification problem of decid-ing whether two given mentions are coreferent.Our system relies on maximum entropy-basedclassifier for pairs of mentions.
Our system relieson a rich linguistically motivated feature set.
Oursystem architecture makes it possible to defineother kinds of features: atmoic word and markablefeatures.
This approach to feature engineering issuitable not only for knowledge-rich but also forknowledge-poor datasets.
Finally, we use the best-first clustering to create the coreference chains.2.
System DescriptionThis section briefly describes our system.
First themention detection is presented.
Next, the featureswhich we import are described.
Finally, we de-scribled the learning and encoding methods.2.1 Mention DetectorThe first stage of the coreference resolutionprocess try to identify the occurrence of mentionsin document.
To detect system mention from a testtext, we train a mention detector on the trainingdata.
We formulate the mention problem as a clas-sification, by assigning to each token in the text alabel, indicating whether it is a mention or not.Hence, to learn the detector, we create one trainingtext and derive its class value (one of b, i, o) fromthe annotated data.
Each instance represents the  ,the token under consideration, and consists of 19linguistic features, many of which are modeled af-ter the systems of Bikel et al (1999) and Florian etal.
(2004) , as describled below.
(1) Lexical: Tokens in the windows of  threewords before and after the target word:{     ,?,    }.
(2) Capitalization: Determine whether    isIsAllCaP (all the characters of word are ca-pitalized, such as ?BBN?
), IsInitCap (theword starts with a capitalized character,1272such as ?Sally?
), IsCapPeriod (more thanone characters of word are capitalized butnot all, and the first character is not capita-lized too, such ?M.?
), and IsAllLower (allthe character of word aren?t capitalized,such as ?can? )
(see Bikel et al  (1999)).
(3) Grammatical: The single POS tags of thetokens in the window of three words beforeand after the target word{    ,?,    }.
(4) Semantic: The  named entity (NE) tag andthe Noun Phrase tag of  .We employ maximum entropy-based classifier, fortraining the mention detector.
These detectedmentions are to be used as system mentions in ourcoreference experiment.2.2 FeaturesTo determine which mentions belong to same en-titly, we need to devise a set of features that is use-ful in determining whether two mentions corefer ornot.
All the feature value are computed automati-cally, without any manual intervention.
(1) Distance Feature: A non-negative integerfeature capture the distance between anap-hor and antecedent.
If anaphor and antece-dent are in the same sentence, the value is0; If their sentence distance is 1, the valueis 1, and so on.
(2) Antecedent-pronoun Feature: A Booleanfeature capture whether the antecedent is p-ronoun or not.
True if the antecedent is a p-ronoun.
Pronouns include reflexive prono-uns, personal pronouns, and possessive pr-onouns.
(3) Anaphor-pronoun Feature: A Boolean f-eature capture whether  the anaphor is pro-noun or not.
True if the anaphor is a pron-oun.
(4) String Match Feature: A non-negative in-teger feature.
If one candidate is a substrin-g of another, its value is 0, else the value is0 plus the edit distance.
(5) Anaphor Definite Noun Phrase Feature:A Boolean feature capture whether the ana-phor is a definite noun phrase or not.
Trueif the anaphor is a pronoun.
In our definiti-on, a definite noun phrase is someone thatstart with the word ?the?.
(6) Anaphor Demonstrative Noun Phrase F-eature:  A Boolean feature capture wheth-er the anaphor is a demonstractive  noun ornot.
True if the anaphor is a demonstractivenoun.
In our definition, a demonstractive  noun is someone that start with the word, su-ch as this, that, those, these.
(7) ProperName Feature: A Boolean feature.True if  anphor and antecedent both are pr-oper name.
(8) Gender Feature: Its value are true, falseor  unknow.
If gender of pair of  instancematches, its value is true,else if  the valueis umatches, the value is false; If one of thepair instance?s gender is unknown, the val-ue is uknown.
(9) Number Feature: A Boolean feature.
Trueif the  number of pair of instance is match-es;(10) Alias Feature: A Boolean feature.
True iftwo markables refer to the same entity usi-ng different notation(acronyms, shorthands,etc), its value is true.
(11) Semantic Feature: Its value are true, fals-e, or unknown.
If semantic class relatenessof a pair instance is the same, or one is theparent of other, its value is true; Else if the-y are unmatch,the value is false; If one of t-he the pair instance?s semantic class is unk-nown, the value is unknown.2.3 LearningWe did not make any effort to optimize the nu-mber of training instances for the pair-wise learne-r: a positive instance for each adjacent coreferentmarkable pair and negative training instances for amarkable m and all markables disreferent with mthat occur before m (Soon et al,2001).
For decod-ing it generates all the possible links inside a win-dow of 100 markables.Our system integrate many machine learning methods, such as maximum entropy (Tsuruoka,  200-6) , Descision Tree,Support Vector Machine  (Joa-chims, 2002) .
We compare the result using differ-ent method in our system, and decide to rely on m-aximum entropy-based classifier, and it led to thebest results.2.4 DecodingIn the decoding step, the coreference chains arecreated by the best-first clustering.
Each mention is1283compared with all of its previous mentions withprobability greater than a fixed threshold, and isclustered with the one hightest probability.
If nonehas probability greater than the threshold, the men-tion becomes a new cluster.3.
Setting and data3.1 SettingOur system has participated in the closed settingsfor English.
Which means all the knowledge re-quired by the mention detector and feature detectoris obtained from the annotation of the corpus(seePradhan et al  (2007)), with the exception of Wor-dNet.3.2 DataWe selecte all ConLL training data and develop-ment data, contain ?gold?
files and ?auto?
file, totrain our final system.
The "gold" indicates thatthe annotation is that file is hand-annotated andadjudicated quality, whereas the second means itwas produced using a combination of automatictools.
The training data distribution is shown inTable 1.Category bc bn mz nw wbQuantity 40 1708 142 1666 190Table 1: Final system?s training data distributionIn this paper, we report the results from our dev-elopment system, which were trained on the traini-ng data and tested on the development set.
The de-tail is shown in Table 2,3.Category bc bn mz nw wbQuantity 32 1526 128 1490 166Table 2: Experiment system?s training data distributionCategory bc bn mz nw wbQuantity 8 182 14 176 24Table 3: Experiment system?s test set distribution4.
EvaluationFirst, we have evaluated our mention detector mo-dule, which is train by the ConLL training data.
Itregards all the token as the candidate, and cast it i-nto the mention detector, and the detector decidesit is  mention or not.
The mention detector?s resultis shown in Table4.Metric R P FValue 63.6 55.26 59.14Table 4: Performance of  mention detector on the de-velopment setSecond, we have evaluated our system with thesystem mention, and we use the previous mentiondetector to determine the mention boundary.
As fo-llow, we list the system perfomance  of using MUC,B-CUB,CEAF (E) , CEAF (M) , BLANC (Recasens a-nd Hovy, in prep)  in Table 5 .Metric R P FMUC 45.53 47.00 46.25BCUB 61.29 68.07 64.50CEAF(M) 47.47 47.47 47.47CEAF(E) 39.23 37.91 38.55BLANC 64.00 68.31 65.81Table 5 :Result using  system mentionsFinally, we  have evaluated our system with thegold mentions, which mention?s boundary is corect.The system performance is shown in Table 6:Metric R P FMUC 50.15 80.49 61.78BCUB 48.87 85.75 62.62CEAF(M) 54.50 54.50 54.50CEAF(E) 67.38 32.72 44.05BLANC 66.03 78.41 70.02Table6:Result using  gold mentionsResult of system shows a big difference  betwee-n using gold mentions and using system mentions.In comparison to the system using system mention-s, we see that the F-score rises significantly by4.21- 15.53 for the system using gold mentions.
Itis worth noting that the F-scorer when using the B-CUB metric, the system using system mention rise-1294s 2.12 for system using gold mention.
Although t-his is surprising, in my opinion this correlation isbecause the mention detection recall more candid-ate mention, and the BCUB metric is benefit for t-he mention which is merge into the erroneouschain.5.
ConclusionIn this paper, we have presented a new modularsystem for coreference in English.
We train a men-tion detector to find the mention?s boundary basedon maximum entropy classifier to decide pairs ofmention refer to or not.Due to the flexible architecture, it allows us ex-tend the system to multi-language.
And if it is ne-cessary, we can obtain other modules to supportthe system.
The results obtained confirm the feasi-bility of our system.ReferencesWee Meng Soon,Hwee You Ng,and Daniel ChungYong Lim.2001.A machine learing approach to core-ference resolution of noun phrases.ComputationalLinguistic(special Issue on Computational AnaphoraResolution),27(4):521-544Marc Vilain,John Burger,John Aberdeen,Dennis Con-nolly,and Lynette Hirschman.1995.A modeltheoreticcoreference scoring scheme.In Proceedings of the 6thMessage Understanding Conference,pages 45-52.Amit Bagga and Breck baldwin.1998.Algorithms forscoring coreference chains.In Proceedings of the lin-guistic Coreference Workshoop at the InternationalConference on Language Resources and Evalua-tion(LREC-1998),pages 563-566.Xiaoqiang Luo.2005.On coreference resoluton perfor-mance metrics.In Proceeddings of the Annual Meet-ing of the North American Chapter of the Associationfor Computational Linguistics-Human LanguageTechnology Conference(NAACL/HLY-2005),pages25-32Josef Steinberger,Massimo Poesio,Mijail A.kabadjov-b,and Karel jezek.2007.Two uses of anaphora resolu-tion in summarization.In Information Processing andmanagement,Special issue on Summarization,pages1663-1680Bikel,R.Schwartz,and R.Weischedel.1999.An algorithmthat learns what's in a name.Machine Learning,34(1-3):pages211-231Florian,H.Hassan,A.Ittycheriah,H.Jing,N.Kambhatla, X.Luo,N.Nicolov,and I.Zitouni.2004.A statistical modelfor multilingual entity detection and tracking.InProc.of HLA/NAACL.Sameer Pradhan and Lance Ramshaw and Ralph Wei-schedel and Jessica MacBride and Linnea Micciulla.2007.Unrestricted Coreference: Identifying Entitiesand Events in OntoNotes.
In Proceedings of the IEEEInternational Conference on Semantic Computing(ICSC), Irvine, CAMarta Recasens and Eduard Hovy.in prep.BLAN-C:Implementing the rand index for coreference eval-uation.Yoshimasa Tsuruoka.2006.A simple c++ library formaxium entropy classifiction.Ysujii laboratory,Dep-artment of Computer Science,University of Tokyo.Throsten Joachims.1999.Making large-scale SVMlearning practical.In B.Scholkopf,C.Burges,and A.S-mola,editors,Advances in Kernel Methods-SupportVector Learning.MIT-Press.130
