SquibsDoes GIZA++ Make Search Errors?Sujith Ravi?University of Southern CaliforniaKevin Knight?
?University of Southern CaliforniaWord alignment is a critical procedure within statistical machine translation (SMT).
Brownet al (1993) have provided the most popular word alignment algorithm to date, one that hasbeen implemented in the GIZA (Al-Onaizan et al 1999) and GIZA++ (Och and Ney 2003)software and adopted by nearly every SMT project.
In this article, we investigate whether thisalgorithm makes search errors when it computes Viterbi alignments, that is, whether it returnsalignments that are sub-optimal according to a trained model.1.
BackgroundWord alignment is the problem of annotating a bilingual text with links connectingwords that have the same meanings.
Brown et al (1993) align an English/French sen-tence pair by positing a probabilistic model by which an English sentence is translatedinto French.1 The model provides a set of non-deterministic choices.
When a particularsequence of choices is applied to an English input sentence e1...el, the result is a partic-ular French output sentence f1...fm.
In the Brown et al models, a decision sequence alsoimplies a specific word alignment vector a1...am.
We say aj = i when French word fj wasproduced by English word ei during the translation.
Here is a sample sentence pair (e, f)and word alignment a:e: NULL0 Mary1 did2 not3 slap4 the5 green6 witch7f : Mary1 no2 dio?3 una4 bofetada5 a6 la7 bruja8 verde9a: [ 1 3 4 5 5 0 5 7 6 ]Notice that the English sentence contains a special NULL word (e0) that generates?spurious?
target words (in this case, a6).
The Brown et al (1993) models are many-to-one, meaning that each English word can produce several French children, but each?
Information Sciences Institute, University of Southern California, 4676 Admiralty Way, Marina del Rey,CA 90292.
E-mail: sravi@isi.edu.??
Information Sciences Institute, University of Southern California, 4676 Admiralty Way, Marina del Rey,CA 90292.
E-mail: knight@isi.edu.1 We follow standard convention in using ?English?
and ?French?
simply as shorthand for ?source?
and?target?.
In fact, we use English/Spanish examples in this article.Submission received: 16 December 2009; accepted for publication: 7 April 2010.?
2010 Association for Computational LinguisticsComputational Linguistics Volume 36, Number 3French word has only one English parent.
This is why we can represent an alignment asa vector a1...am.
There are (l + 1)m ways to align (e, f).
For Brown et al the goal of wordalignment is to find the alignment a that is most likely, given a sentence pair (e, f):argmaxa P(a|e, f) = argmaxaP(a, f|e) (1)2.
IBM Model 3Supplied with a formula for P(a|e, f), we can search through the (l + 1)m alignmentsfor the highest-scoring one.
Brown et al (1993) come up with such a formula by firstpositing this generative story (IBM Model 3):Given an English sentence e1...el:1.
Choose a fertility ?i for each English word ei, according to the distributionn(?i|ei).2.
Let m?
=?i=1...l ?i.3.
Choose a number ?0 of ?spurious?
French words, by doing the followingm?
times: with probability p1, increment ?0 by one.4.
Let m = m?
+ ?0.5.
Choose a French translation ?ik for each English word (including e0) andfertility value, according to the distribution t(?ik|ei).6.
Choose a French position j for each ?ik (i > 0), according to d(j|i, l,m).
If thesame j is chosen twice, fail the procedure.7.
Place each of the ?0 spuriously generated words, one by one, into vacantpositions in the English string, according to uniform probability.8.
Output the French string f1...fm, where fj is the French word ?ik that wasplaced into position j in Step 6 or 7.9.
Output alignment a1...am, where aj is the English position i from thatsame ?ik.Different decision sequences can result in the same outputs f and a.
With this inmind, Brown et al provide the following formula:P(a, f|e) =m?j=1t( fj|eaj ) ?l?i=1n(?i|ei) ?m?aj =0,j=1d( j|aj, l,m)?l?i=0?i!
?
1?0!?
(m ?
?0?0)?
p?01 ?
pm?2?00 (2)Note that terms ?0...?l are only shorthand, as their values are completely deter-mined by the alignment a1...am.296Ravi and Knight Does GIZA++ Make Search Errors?3.
Finding the Viterbi AlignmentWe assume that probability tables n, t, d, and p have already been learned from data,using the EM method described by Brown et al (1993).
We are concerned solely with theproblem of then finding the best alignment for a given sentence pair (e, f) as describedin Equation 1.
Brown et al were unable to discover a polynomial time algorithm forthis problem, which was in fact subsequently shown to be NP-complete (Udupa andMaji 2006).
Brown et al therefore devise a hill-climbing algorithm.
This algorithm startswith a reasonably good alignment (Viterbi IBM Model 2, computable in quadratic time),after which it greedily executes small changes to the alignment structure, graduallyincreasing P(a, f|e).
The small changes consist of moves, in which the value of someaj is changed, and swaps, in which a pair aj and ak exchange values.
At each step inthe greedy search, all possible moves and swaps are considered, and the one whichincreases P(a, f|e) the most is executed.
When P(a, f|e) can no longer be improved, thesearch halts.2Our question is whether this hill-climbing algorithm, as implemented in GIZA++,makes search errors when it tries to locate IBM Model 3 Viterbi alignments.
To answerthis, we built a slow but optimal IBM Model 3 aligner, by casting the problem in theinteger linear programming (ILP) framework.
Given a sentence pair (e1...el, f1...fm), weset up the following variables: Binary link variables linkij.
We have one such variable for each pair ofEnglish and French tokens.
If linkij = 1, then there is an alignment linkbetween ei and fj.
The English NULL word is represented by i = 0. Binary fertility variables fertik.
We have one variable for each English tokenpaired with an integer fertility value 0..9.
If fertik = 1, then token ei hasfertility k.To ensure that values we assign to variables are legal and self-consistent, we in-troduce several constraints.
First, we require that for each j, all linkxj values sum toone.
This means each French token has exactly one alignment link, as required by IBMModel 3.
Second, we require that for each i, all fertix values sum to one, so that eachEnglish token has a unique fertility.
Third, we require that link and fertility variableassignments be consistent with one another: for each i, the sum of linkix variables equals1 ?
ferti1 + 2 ?
ferti2 + .
.
.
+ 9 ?
ferti9.3We then define an objective function whose minimization corresponds to findingthe Viterbi IBM Model 3 alignment.
Figure 1 presents the components of the objectivefunction, alongside counterparts from the P(a, f|e) formula previously given.
Note thatthe coefficients for the objective function are derived from the already-learned probabil-ity tables n, d, t, and p.For each sentence pair in our test set, we create and solve an ILP problem.
Figure 2demonstrates this for a simple example.
The reader can extract the optimal alignmentfrom the alignment variables chosen in the ILP solution.2 Brown et al (1993) describe a variation called pegging, which carries out multiple additional greedyhill-climbs, each with a different IBM Model 2 Viterbi link fixed (pegged) for the duration of thehill-climb.
In practice, pegging is slow, and the vast majority of GIZA++ users do not employ it.3 The default configuration of GIZA++ includes this same fertility cap of 9, though the Brown et al (1993)description does not.297Computational Linguistics Volume 36, Number 3Figure 1Objective function and constraints (left) for the ILP formulation that encodes the problem ofselecting the Viterbi alignment for a sentence pair under IBM Model 3.
Components of the ILPobjective function are paired with counterparts (right) from the Model 3?s P(a, f|e) formula.4.
ExperimentsFor Chinese/English experiments, we run GIZA++ training on 101,880 sentence pairs.We evaluate Viterbi alignments on a smaller test set of 1,880 sentence pairs with manualalignments.
For Arabic/English, we train on 300,000 sentence pairs and test on 2,000.In tests, we compare GIZA++ Viterbi alignments (based on greedy hill-climbing) withoptimal ILP alignments.
We use CPLEX to solve our ILP problems.298Ravi and Knight Does GIZA++ Make Search Errors?Figure 2Illustration of ILP-based optimal alignment of a single sentence pair.
Already-trained logprobabilities are shown at the top of the figure.
In the middle is a schematic of variablesintroduced for the English/Spanish sentence pair seatbelts / los cinturones de seguridad.At the bottom is the ILP formulation and its solution.Figure 3 compares the results from GIZA++ alignment with optimal ILP alignmentfor different language pairs and alignment directions, and for unions of uni-directionalalignments.
We measure the rate at which GIZA++ makes search errors, and we com-pute alignment F-scores for the various testing conditions.
We conclude that although299Computational Linguistics Volume 36, Number 3Figure 3Comparison of GIZA++ Viterbi alignments (based on greedy hill-climbing) with optimal ILPalignments for different language pairs and alignment directions in terms of alignment quality(F-score).
The figure also shows the alignment F-scores for UNION alignments that combinealignment links from both directions.
The fourth column shows the percentage of sentences onwhich GIZA++ makes search errors in comparison to optimal ILP alignments.GIZA++ makes search errors on 5?15% of sentence pairs, these errors do not contributeto an overall loss in alignment task accuracy, as measured by F-score.Focusing on sentence pairs where GIZA++ makes a search error, we plot the av-erage difference in log model scores between GIZA++ and ILP Viterbi alignments inFigure 4.
We notice a positive correlation between sentence length and the search errorFigure 4Average difference in log model scores between GIZA++ and ILP alignments at different Englishsentence lengths for English/Chinese alignment.
Points in the plot that appear to be on thex-axis actually lie just above it.300Ravi and Knight Does GIZA++ Make Search Errors?Figure 5Average time (msec) taken by the ILP aligner at different English sentence lengths forEnglish/Chinese alignment.
The experiments were run on a single machine with a 64-bit,2.4 GHz AMD Opteron 850 processor.gap between GIZA++ and ILP scores.
As we move to longer sentences, the alignmentprocedure becomes harder and GIZA++ makes more errors.
Finally, Figure 5 plots thetime taken for ILP alignment at different sentence lengths showing a positive correlationas well.5.
DiscussionWe have determined that GIZA++ makes few search errors, despite the heuristic natureof the algorithm.
These search errors do not materially affect overall alignment accuracy.In practice, this means that researchers should not spend time optimizing this particularaspect of SMT systems.Search errors can occur in many areas of SMT.
The area that has received the mostattention is runtime decoding/translation.
For example, Germann et al (2001) devise anoptimal ILP decoder to identify types of search errors made by other decoders.
A secondarea (this article) is finding Viterbi alignments, given a set of alignment parametervalues.
A third area is actually learning those parameter values.
Brown et al?s (1993)EM learning algorithm aims to optimize the probability of the French side of the parallelcorpus given the English side.
For Model 3 and above, Brown et al collect parametercounts over subsets of alignments, instead of over all alignments.
These subsets, likeViterbi alignments, are generated heuristically, and it may be that true n-best lists of301Computational Linguistics Volume 36, Number 3alignments would yield better counts and better overall parameter values.
Of course,even if we were able to collect accurate counts, EM is not guaranteed to find a globaloptimum, which provides further opportunity for search errors.
We leave the problemof search errors in alignment training to future study.AcknowledgmentsThis work was supported by NSF grant0904684 and DARPA GALE ContractNumber HR0011-06-C-0022.ReferencesAl-Onaizan, Yaser, Jan Curin, Michael Jahr,Kevin Knight, John Lafferty, FranzJosef Och Dan Melamed, David Purdy,Noah Smith, and David Yarowsky.
1999.Statistical machine translation.
Technicalreport, Johns Hopkins University.Brown, Peter, Vincent Della Pietra,Stephen Della Pietra, and Robert Mercer.1993.
The mathematics of statisticalmachine translation: Parameter estimation.Computational Linguistics, 19(2):263?311.Germann, Ulrich, Michael Jahr, KevinKnight, Daniel Marcu, and Kenji Yamada.2001.
Fast decoding and optimal decodingfor machine translation.
In Proceedings ofthe 39th Annual Meeting of the Associationfor Computational Linguistics (ACL),pages 228?235, Toulouse.Och, Franz Josef and Hermann Ney.
2003.A systematic comparison of variousstatistical alignment models.
ComputationalLinguistics, 29(1):19?51.Udupa, Raghavendra and Hemanta K. Maji.2006.
Computational complexity ofstatistical machine translation.
InProceedings of the Conference of theEuropean Chapter of the Association ofComputational Linguistics (EACL), pages25?32, Trento.302
