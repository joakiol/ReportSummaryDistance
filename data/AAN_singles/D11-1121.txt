Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1310?1319,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsIdentifying and Following Expert Investors in Stock Microblogs1Roy Bar-Haim, 1Elad Dinur, 1,2Ronen Feldman, 1Moshe Fresko and 1Guy Goldstein1Digital Trowel, Airport City, Israel2School of Business Administration, The Hebrew University of Jerusalem, Jerusalem, Israel{roy, moshe}@digitaltrowel.com, ronen.feldman@huji.ac.ilAbstractInformation published in online stock invest-ment message boards, and more recently instock microblogs, is considered highly valu-able by many investors.
Previous work fo-cused on aggregation of sentiment from allusers.
However, in this work we show that itis beneficial to distinguish expert users fromnon-experts.
We propose a general frameworkfor identifying expert investors, and use it as abasis for several models that predict stock risefrom stock microblogging messages (stocktweets).
In particular, we present two methodsthat combine expert identification and per-userunsupervised learning.
These methods wereshown to achieve relatively high precision inpredicting stock rise, and significantly outper-form our baseline.
In addition, our work pro-vides an in-depth analysis of the content andpotential usefulness of stock tweets.1 IntroductionOnline investment message boards such as Yahoo!Finance and Raging Bull allow investors to sharetrading ideas, advice and opinions on public com-panies.
Recently, stock microblogging services suchas StockTwits (which started as a filtering serviceover the Twitter platform) have become very popu-lar.
These forums are considered by many investorsas highly valuable sources for making their tradingdecisions.This work aims to mine useful investment in-formation from messages published in stock mi-croblogs.
We shall henceforth refer to these mes-sages as stock tweets.
Ultimately, we would like totransform those tweets into buy and sell decisions.Given a set of stock-related messages, this processtypically comprises two steps:1.
Classify each message as ?bullish?
(having apositive outlook on the stock), ?bearish?
(hav-ing a negative outlook on the stock), or neutral.2.
Make trading decisions based on these messageclassifications.Previous work on stock investment forums andmicroblogs usually regarded the first step (messageclassification) as a sentiment analysis problem, andaligned bullish with positive sentiment and bearishwith negative sentiment.
Messages were classifiedby matching positive and negative terms from sen-timent lexicons, learning from a hand-labeled set ofmessages, or some combination of the two (Das andChen, 2007; Antweiler and Frank, 2004; Chua et al,2009; Zhang and Skiena, 2010; Sprenger andWelpe,2010).
Trading decisions were made by aggregatingthe sentiment for a given stock over all the tweets,and picking stocks with strongest sentiment signal(buying the most bullish stocks and short-selling themost bearish ones).Sentiment aggregation reflects the opinion of theinvestors community as a whole, but overlooks thevariability in user expertise.
Clearly, not all investorsare born equal, and if we could tell experts from non-experts, we would reduce the noise in these forumsand obtain high-quality signals to follow.
This pa-per presents a framework for identifying experts instock microblogs by monitoring their performancein a training period.
We show that following the ex-perts results in more precise predictions.1310Based on the expert identification framework, weexperiment with different methods for deriving pre-dictions from stock tweets.
While previous worklargely aligned bullishness with message sentiment,our in-depth content analysis of stock tweets (to bepresented in section 2.2) suggests that this view istoo simplistic.
To start with, one important dif-ference between bullishness/bearishness and posi-tive/negative sentiment is that while the former rep-resents belief about the future, the latter may alsorefer to the past or present.
For example, a user re-porting on making profit from a buying stock yester-day and selling it today is clearly positive about thestock, but does not express any prediction about itsfuture performance.
Furthermore, messages that dorefer to the future differ considerably in their signif-icance.
A tweet reporting on buying a stock by theuser conveys a much stronger bullishness signal thana tweet that merely expresses an opinion.
Overall, itwould seem that judging bullishness is far more elu-sive than judging sentiment.We therefore propose and compare two alterna-tive approaches that sidestep the complexities of as-sessing tweets bullishness.
These two approachescan be viewed as representing two extremes.
Thefirst approach restricts our attention to the most ex-plicit signals of bullishness and bearishness, namely,tweets that report actual buy and sell transactionsperformed by the user.
In the second approach welearn directly the relation between tweets contentand stock prices, following previous work on pre-dicting stock price movement from factual sourcessuch as news articles (Lavrenko et al, 2000; Koppeland Shtrimberg, 2004; Schumaker and Chen, 2010).This approach poses no restrictions on the tweetscontent and avoids any stipulated tweet classifica-tion.
However, user-generated messages are largelysubjective, and their correlation with the stock pricesdepends on user?s expertise.
This introduces muchnoise into the learning process.
We show that bymaking the learning user-sensitive we can improvethe results substantially.
Overall, our work illus-trates the feasibility of finding expert investors, andthe utility of following them.2 Stock Tweets2.1 Stock Tweets LanguageStock tweets, as Twitter messages in general, areshort textual messages of up to 140 characters.
Theyare distinguished by having one or more referencesto stock symbols (tickers), prefixed by a dollar sign.For instance, the stock of Apple, Inc. is referencedas $AAPL.
Two other noteworthy Twitter conven-tions that are also found in stock tweets are hashtags,user-defined labels starting with ?#?, and referencesto other users, starting with ?@?.
Table 1 lists someexamples of stock tweets.As common with Twitter messages, stock tweetsare typically abbreviated and ungrammatical utter-ances.
The language is informal and includes manyslang expressions, many of which are unique to thestock tweets community.
Thus, many positive andnegative expressions common to stock tweets are notfound in standard sentiment lexicons.
Their uniquelanguage and terminology often make stock tweetshard to understand for an outsider.
Many wordsare abbreviated and appear in several non-standardforms.
For example, the word bought may also ap-pear as bot or bght, and today may appear as 2day.Stock tweets also contain many sentiment expres-sions which may appear in many variations, e.g.wow, woooow, woooooooow and so on.
These char-acteristics make the analysis of stock tweets a par-ticularly challenging task.2.2 Content AnalysisA preliminary step of this research was an exten-sive data analysis, aimed to gain better understand-ing of the major types of content conveyed in stocktweets.
First, we developed a taxonomy of tweetcategories while reading a few thousands of tweets.Based on this taxonomy we then tagged a sampleof 350 tweets to obtain statistics on the frequencyof each category.
The sample contained only tweetsthat mention exactly one ticker.
The following typesof tweets were considered irrelevant:?
Tweets that express question.
These tweetswere labeled as Question.?
Obscure tweets, e.g.
?$AAPL fat?, tweetsthat contain insufficient information (e.g.
?http://url.com $AAPL?)
and tweets that seem1311Example %FactNews $KFRC: Deutsche Bank starts at Buy 14.3%Chart Pattern $C (Citigroup Inc) $3.81 crossed its 2nd Pivot Point Supporthttp://empirasign.com/s/x4c10.9%Trade bot back some $AXP this morning 12.9%Trade Outcome Sold $CELG at 55.80 for day-trade, +0.90 (+1.6%)X 2.9%OpinionSpeculation thinking of hedging my shorts by buying some oil.
thinking ofbuying as much $goog as i can in my IRA.
but i need more doing,less thinking.4.0%Chart Prediction http://chart.ly/wsy5ny $GS - not looking good for this one -breaks this support line on volume will nibble a few short12.9%Recommendation $WFC if you have to own financials, WFC would be my choice.http://fsc.bz/448 #WORDEN1.7%Sentiment $ivn is rocking 8.6%Question $aapl breaking out but in this mkt should wait till close?
7.1%Irrelevant $CLNE follow Mr. Clean $$ 24.9%Table 1: Tweets categories and their relative frequenciesto contain no useful information (e.g ?EvenSteve Jobs is wrong sometimes...
$AAPLhttp://ow.ly/1Tw0Z?).
These tweets were la-beled Irrelevant.The rest of the tweets were classified into two majorcategories: Facts and Opinions.Facts can be divided into four main subcategories:1.
News: such tweets are generally in the form ofa tweeted headline describing news or a currentevent generally drawn from mass media.
Assuch they are reliable but, since the informationis available in far greater detail elsewhere, theiradded value is limited.2.
Chart Pattern: technical analysis aims to pro-vide insight into trends and emerging patternsin a stock?s price.
These tweets describe pat-terns in the stock?s chart without the inclusionof any predicted or projected movement, an im-portant contrast to Chart Prediction, which isan opinion tweet described below.
Chart pat-tern tweets, like news, are a condensed form ofinformation already available through more in-depth sources and as such their added value islimited.3.
Trade: reports an actual purchase or sale of astock by the user.
We consider this as the mostvaluable form of tweet.4.
Trade Outcome: provides details of an ?inversetrade?, the secondary trade to exit the initialposition along with the outcome of the over-all trade (profit/loss).
The value of these tweetsis debatable since although they provide detailsof a trade, they generally describe the ?exit?transaction.
This creates a dilemma for ana-lysts since traders will often exit not becauseof a perceived change in the stock?s potentialbut as a result of many short-term trading ac-tivities.
For this reason trade outcome providesa moderate insight into a user?s position whichshould be viewed with some degree of caution.Opinions can also be divided into four main subcat-egories:1.
Speculation: provides individual predictions offuture events relating to a company or actionsof the company.
These are amongst the leastreliable categories, as the individual user is typ-ically unable to justify his or her insight into thepredicted action.2.
Chart Prediction: describes a user?s predictionof a future chart movement based on technicalanalysis of the stock?s chart.3.
Recommendation: As with analyst recommen-dations, this category represents users whosummarize their understanding and insight into1312a stock with a simple and effective recommen-dation to take a certain course of action withregard to a particular share.
Recommendationis the less determinate counterpart to Trade.4.
Sentiment: These tweets express pure senti-ment toward the stock, rather than any factualcontent.Table 1 shows examples for each of the tweet cate-gories, as well as their relative frequency in the ana-lyzed sample.3 An Expert Finding FrameworkIn this section we present a general procedure forfinding experts in stock microblogs.
Based on thisprocedure, we will develop in the next sections sev-eral models for extracting reliable trading signalsfrom tweets.We assume that a stock tweet refers to exactly onestock, and therefore there is a one-to-one mappingbetween tweets and stocks.
Other tweets are dis-carded.
We define expertise as the ability to pre-dict stock rise with high precision.
Thus, a user isan expert if a high percentage of his or her bullishtweets is followed by a stock rise.
In principle, wecould analogously follow bearish tweets, and see ifthey are followed by a stock fall.
However, bearishtweets are somewhat more difficult to interpret: forexample, selling a share may indicate a negative out-look on the stock, but it may also result from otherconsiderations, e.g.
following a trading strategy thatholds the stock for a fixed period (cf.
the discussionon Trade Outcome tweets in the previous section).We now describe a procedure that determineswhether a user u is an expert.
The procedure re-ceives a training set T of tweets posted by u, whereeach tweet is annotated with its posting time.
It isalso given a classifier C, which classifies each tweetas bullish or not bullish (either bearish or neutral).The procedure first applies the classifier C to iden-tify the bullish tweets in T .
It then determines thecorrectness of each bullish tweet.
Given a tweet t,we observe the price change of the stock referencedby t over a one day period starting at the next tradingday.
The exact definition of mapping tweets to stockprices is given in section 5.1.
A one-day holdingperiod was chosen as it was found to perform wellin previous works on tweet-based trading (Zhangand Skiena, 2010; Sprenger and Welpe, 2010), inparticular for long positions (buy transactions).
Abullish tweet is considered correct if it is followedby a stock rise, and as incorrect otherwise1.
Given aset of tweets, we define its precision as the percent-age of correct tweets in the set.
Let Cu, Iu denotethe number of correct and incorrect bullish tweetsof user u, respectively.
The precision of u?s bullishtweets is therefore:Pu =CuCu + IuLet Pbl be the baseline precision.
In this work wechose the baseline precision to be the proportion oftweets that are followed by a stock rise in the wholetraining set (including all the users).
This representsthe expected precision when picking tweets at ran-dom.
Clearly, if Pu ?
Pbl then u is not an expert.If Pu > Pbl, we apply the following statistical testto assess whether the difference is statistically sig-nificant.
First, we compute the expected number ofcorrect and incorrect transactions Cbl, Ibl accordingto the baseline:Cbl = Pbl ?
(Cu + Iu)Ibl = (1?
Pbl)?
(Cu + Iu)We then compare the observed counts (Cu, Iu) tothe expected counts (Cbl, Ibl), using Pearson?s Chi-square test.
Since it is required for this test thatCbl and Ibl are at least 5, cases that do not meetthis requirement are discarded.
If the resulting p-value satisfies the required significance level ?, thenu is considered an expert.
In this work we take?
= 0.05.
Note that since the statistical test takesinto account the number of observations, it will re-ject cases where the number of the observations isvery small, even if the precision is very high.
Theoutput of the procedure is a classification of u asexpert/non-expert, as well as the p-value (for ex-perts).
The expert finding procedure is summarizedin Algorithm 1.In the next two sections we propose several alter-natives for the classifier C.1For about 1% of the tweets the stock price did not changein the next trading day.
These tweets are also considered correctthroughout this work.1313Algorithm 1 Determine if a user u is an expertInput: set of tweets T posted by u, bullishnessclassifier C, baseline probability Pbl, significancelevel ?Output: NON-EXPERT/(EXPERT, p-value)Tbullish ?
tweets in T classified by C as bullishCu ?
0 ; Iu ?
0for each t ?
Tbullish doif t is followed by a stock rise thenCu++elseIu++end ifend forPu = CuCu+Iuif Pu ?
Pbl thenreturn NON-EXPERTelseCbl ?
Pbl ?
(Cu + Iu)Ibl ?
(1?
Pbl)?
(Cu + Iu)p?
ChiSquareTest(Cu, Iu, Cbl, Ibl)if p > ?
thenreturn NON-EXPERTelsereturn (EXPERT, p)end ifend if4 Following Explicit TransactionsThe first approach we attempt for classifying bullish(and bearish) tweets aims to identify only tweets thatreport buy and sell transactions (that is, tweets inthe Trade category).
According to our data analysis(reported in section 2.2), about 13% of the tweetsbelong to this category.
There are two reasons tofocus on these tweets.
First, as we already noted,actual transactions are clearly the strongest signalof bulishness/bearishness.
Second, the buy and sellactions are usually reported using a closed set ofexpressions, making these tweets relatively easy toidentify.
A few examples for buy and sell tweets areshown in Table 2.While buy and sell transactions can be capturedreasonably well by a relatively small set of patterns,the examples in Table 2 show that stock tweets havesell sold sum $OMNI 2.14 +12%buy bot $MSPD for earnings testingnew indicator as well.sell Out 1/2 $RIMM calls @ 1.84(+0.81)buy added to $joez 2.56buy I picked up some $X JUL 50 Puts@3.20 for gap fill play about an hourago.buy long $BIDU 74.01buy $$ Anxiously sitting at the bid on$CWCO @ 11.85 It seems the askand I are at an impasse.
20 min ofthis so far.
Who will budge?
(notme)buy In 300 $GOOG @ 471.15.sell sold $THOR 41.84 for $400 theFreeFactory is rockingsell That was quick stopped out $ICEsell Initiated a short position in $NEM.Table 2: Buy and sell tweetstheir unique language for reporting these transac-tions, which must be investigated in order to comeby these patterns.
Thus, in order to develop a clas-sifier for these tweets, we created a training and testcorpora as follows.
Based on our preliminary anal-ysis of several thousand tweets, we composed a vo-cabulary of keywords which trade tweets must in-clude2.
This vocabulary contained words such as in,out, bot, bght, sld and so on.
Filtering out tweets thatmatch none of the keywords removed two thirds ofthe tweets.
Out of the remaining tweets, about 5700tweets were tagged.
The training set contains about3700 tweets, 700 of which are transactions.
The testset contains about 2000 tweets, 350 of which aretransactions.Since the transaction tweets can be characterizedby a closed set of recurring patterns, we developeda classifier that is based on a few dozens of man-ually composed pattern matching rules, formulatedas regular expressions.
The classifier works in threestages:1.
Normalization: The tweet is transformed intoa canonical form.
For example, user name2That is, we did not come across any trade tweet that doesnot include at least one of the keywords in the large sample weanalyzed, so we assume that such tweets are negligible.1314Dataset Transaction P R F1Train Buy 94.0% 84.0% 0.89Sell 96.0% 83.0% 0.89Test Buy 85.0% 70.0% 0.77Sell 88.5% 79.0% 0.84Table 3: Results for buy/sell transactition classifier.
Pre-cision (P), Recall (R), and F-measure (F1) are reported.is transformed into USERNAME; ticker nameis transformed into TICKER; buy, buying,bought, bot, bght are transformed into BUY,and so on.2.
Matching: Trying to match one of the buy/sellpatterns in the normalized tweet.3.
Filtering: Filtering out tweets that match ?dis-qualifying?
patterns.
The simplest examplesare a tweet starting with an ?if?
or a tweet con-taining a question mark.The results of the classifier on the train and test setare summarized in Table 3.
The results show thatour classifier identifies buy/sell transactions with agood precision and a reasonable recall.5 Unsupervised Learning from StockPricesThe drawback of the method presented in the pre-vious section is that it only considers a small partof the available tweets.
In this section we proposean alternative method, which considers all the avail-able tweets, and does not require any tagged corpusof tweets.
Instead, we use actual stock price move-ments as our labels.5.1 Associating Tweets with Stock PricesWe used stock prices to label tweets as follows.
Eachtweet message has a time stamp (eastern time), indi-cating when it was published.
Our policy is to buyin the opening price of the next trading day (PB),and sell on the opening price of the following trad-ing day (PS).
Tweets that are posted until 9:25 in themorning (market hours begin at 9:30) are associatedwith the same day, while those are posted after thattime are associated with the next trading date.5.2 TrainingGiven the buy and sell prices associated with eachtweet, we construct positive and negative trainingexamples as follows: positive examples are tweetswhere PS?PBPB ?
3%, and negative examples aretweets where PS?PBPB ?
?3%.We used the SVM-light package (Joachims,1999), with the following features:?
The existence of the following elements in themessage text:?
Reference to a ticker?
Reference to a user?
URL?
Number?
Hashtag?
Question mark?
The case-insensitive words in the message afterdropping the above elements.?
The 3, 4, 5 letter prefixes of each word.?
The name of the user who authored the tweet,if it is a frequent user (at least 50 messages inthe training data).
Otherwise, the user name istaken to be ?anonymous?.?
Whether the stock price was up or down 1% ormore in the previous trading day.?
2, 3, 4-word expressions which are typical totweets (that is, their relative frequency in tweetsis much higher than in general news text).6 Empirical EvaluationIn this section we focus on the empirical task oftweet ranking: ordering the tweets in the test set ac-cording to their likelihood to be followed by a stockrise.
This is similar to the common IR task of rank-ing documents according to their relevance.
A per-fect ranking would place all the correct tweets beforeall the incorrect ones.We present several ranking models that use theexpert finding framework and the bullishness classi-fication methods discussed in the previous sectionsas building blocks.
The performance of these mod-els is evaluated on the test set.
By considering the1315precision at various points along the list of rankedtweets, we can compare the precision-recall trade-offs achieved by each model.Before we discuss the ranking models and the em-pirical results, we describe the datasets used to trainand test these models.6.1 DatasetsStock tweets were downloaded from the StockTwitswebsite3, during two periods: from April 25, 2010to November 1, 2011, and from December 14, 2010to February 3, 2011.
A total of 700K tweets mes-sages were downloaded.
Tweets that do not containexactly one stock ticker (traded in NYSE or NAS-DAQ) were filtered out.
The remaining 340K tweetswere divided as follows:?
Development set: April 25, 2010 to August 31,2010: 124K messages?
Held out set: September 1, 2010 to November1, 2010: 110K messages?
Test set: December 14, 2010 to February 3,2011: 106K messagesWe consider the union of the development and heldout sets as our training set.6.2 Ranking Models6.2.1 Joint-All ModelThis is our baseline model, as it does not attemptto identify experts.
It learns a single SVM modelas described in Section 5 from all the tweets in thetraining set.
It then applies the SVM model to eachtweet in the test set, and ranks them according to theSVM classification score.6.2.2 Transaction ModelThis model finds expert users in the training set(Algorithm 1), using the buy/sell classifier describedin Section 4.
Tweets classified as buy are consideredbullish, and the rest are considered non-bullish.
Ex-pert users are ranked according to their p value (inascending order).
The same classifier is then appliedto the tweets of the expert users in the test set.
Thetweets classified as bullish are ordered according tothe ranking of their author (first all the bullish tweets3stocktwits.comof the highest-ranked expert user, then all the bullishtweets of the expert ranked second, and so on).6.2.3 Per-User ModelThe joint all model suffers from the tweets ofnon-experts twice: at training time, these tweets in-troduce much noise into the training of the SVMmodel.
At test time, we follow these unreliabletweets along with the more reliable tweets of the ex-perts.
The per-user model addresses both problems.This model learns from the development set a sep-arate SVM model Cu for each user u, based solelyon the user?s tweets.
We then optimize the clas-sification threshold of the learnt SVM model Cuas follows.
Setting the threshold to ?
results in anew classifier Cu,?.
Algorithm 1 is applied to u?stweets in the held-out set (denoted Hu), using theclassifier Cu,?.
For the ease of presentation, we de-fine ExpertPValue(Hu, Cu,?,Pbl,?)
as a function thatcalls Algorithm 1 with the given parameters, and re-turns the obtained p-value if u is an expert and 1otherwise.
We search exhaustively for the thresh-old ??
for which this function is minimized (in otherwords, the threshold that results in the best p-value).The threshold of Cu is then set to ?
?, and the user?sp-value is set to the best p-value found.
If u is anon-expert for all of the attempted ?
values then u isdiscarded.
Otherwise, u is identified as an expert.The rest of the process is similar to the transac-tion model: the tweets of each expert u in the testset are classified using the optimized per-user clas-sifier Cu.
The final ranking is obtained by sortingthe tweets that were classified as bullish accordingto the p-value of their author.
The per-user rankingprocedure is summarized in Algorithm 2.6.2.4 Joint-Experts ModelThe joint experts model makes use of the expertsidentified by the per-user model, and builds a sin-gle joint SVM model from the tweets of these users.This results in a model that is trained on more exam-ples than in the previous per-user method, but unlikethe joint all method, it learns only from high-qualityusers.
As with the joint all model, test tweets areranked according to the SVM?s score.
However, themodel considers only the tweets of expert users inthe test set.1316        Figure 1: Empirical model comparisonAlgorithm 2 Per-user ranking modelInput: dev.
set D, held-out set H, test set S , base-line probability Pbl, significance level ?Output: A ranked listR of tweets in S// Learning from the training setE ?
?
// set of expert usersfor each user u doDu ?
u?s tweets in DCu ?
SVM classifier learnt from DuHu ?
u?s tweets inH??
= argmin?
ExpertPValue(Hu, Cu,?,Pbl,?
)Cu ?
Cu,?
?pu ?ExpertPValue(Hu, Cu,??,Pbl,?
)if pu ?
?
thenadd u to Eend ifend for// Classifying and ranking the test setfor each user u ?
E doSbullish,u ?
u?s tweets in S that were classifiedas bullish by Cuend forR ?
tweets in ?u Sbullish,u sorted by pureturn R6.3 ResultsFigure 1 summarizes the results obtained for thevarious models.
Each model was used to rank thetweets according to the confidence that they predicta positive stock price movement.
Each data pointcorresponds to the precision obtained for the first ktweets ranked by the model, and the results for vary-ing k values illustrate the precision/recall tradeoff ofthe model.
These data points were obtained as fol-lows:?
For methods that learn a single SVM model(joint all and joint experts), the graph was ob-tained by decreasing the threshold of the SVMclassifier, at fixed intervals of 0.05.
For eachthreshold value, k is the number of tweets clas-sified as bullish by the model.?
For methods that rank the users by their p valueand order the tweets accordingly (transactionand per user), the i-th data point correspondsto the cumulative precision for the tweets clas-sified as bullish by the first i users.
For the peruser method we show the cumulative results forthe first 20 users.
For the transaction methodwe show all the users that were identified as ex-perts.The random line is our baseline.
It shows the ex-pected results for randomly ordering the tweets inthe test set.
The expected precision at any point isequal to the percentage of tweets in the test set thatwere followed by a stock rise, which was found tobe 51.4%.We first consider the joint all method, whichlearns a single model from all the tweets.
The only1317Correct Incorrect P p87 46 65.4 0.001142 86 62.3 0.001162 103 61.1 0.002220 158 58.2 0.008232 168 58.0 0.008244 176 58.1 0.006299 229 56.6 0.016335 255 56.8 0.009338 268 55.8 0.031344 269 56.1 0.019419 346 54.8 0.062452 387 53.9 0.152455 389 53.9 0.145479 428 52.8 0.395481 430 52.8 0.398487 435 52.8 0.388675 564 54.5 0.030683 569 54.6 0.026690 573 54.6 0.022720 591 54.9 0.011Table 4: Per user model: cumulative results for first 20users.
The table lists the number of correct and incorrecttweets, the precision P and the significance level p.per-user information available to this model is a fea-ture fed to the SVM classifier, which, as we found,does not contribute to the results.
Except for thefirst 58 tweets, which achieved precision of 55%,the precision quickly dropped to a level of around52%, which is just a little better than the randombaseline.
Next, we consider the transaction configu-ration, which is based on detecting buy transactions.Only 10 users were found to be experts according tothis method, and in the test period these users had atotal of 173 tweets.
These 173 tweets achieve goodprecision (57.1% for the first 161 tweets, and 54.9%for the first 173 tweets).
However this method re-sulted in a low number of transactions.
This happensbecause it is able to utilize only a small fraction ofthe tweets (explicit buy transactions).Remarkably, per user and joint experts, the twomethods which rely on identifying the experts viaunsupervised learning are by far the best methods.Both models seem to have comparable performance,where the results of the join experts model are some-what smoother, as expected.
Table 4 shows cumu-lative results for the first 20 users in the per-usermodel.
The results show that this model achievesgood precision for a relatively large number oftweets, and for most of the data points reported in thetable the results significantly outperform the base-line (as indicated by the p value).
Overall, these re-sults show the effectiveness of our methods for find-ing experts through unsupervised learning.7 Related WorkA growing body of work aims at extracting senti-ment and opinions from tweets, and exploit this in-formation in a variety of application domains.
Davi-dov et al (2010) propose utilizing twitter hash-tag and smileys to learn enhanced sentiment types.O?Connor et al (2010) propose a sentiment detec-tor based on Twitter data that may be used as a re-placement for public opinion polls.
Bollen et al(2011) measure six different dimensions of publicmood from a very large tweet collection, and showthat some of these dimensions improve the predica-tion of changes in the Dow Jones Industrial Average(DJIA).Sentiment analysis of news articles and financialblogs and their application for stock prediction werethe subject of several studies in recent years.
Someof these works focus on document-level sentimentclassification (Devitt and Ahmad, 2007; O?Hare etal., 2009).
Other works also aimed at predictingstock movement (Lavrenko et al, 2000; Koppeland Shtrimberg, 2004; Schumaker and Chen, 2010).All these methods rely on predefined sentiment lex-icons, manually classified training texts, or theircombination.
Lavrenko et al (2000), Koppel andShtrimberg (2004), and Schumaker and Chen (2010)exploit stock prices for training, and thus save theneed in supervised learning.Previous work on stock message boards include(Das and Chen, 2007; Antweiler and Frank, 2004;Chua et al, 2009).
(Sprenger andWelpe, 2010) is, tothe best of our knowledge, the first work to addressspecifically stock microblogs.
All these works takea similar approach for classifying message bullish-ness: they train a classifier (Na?
?ve Bayes, which Dasand Chen combined with additional classifiers anda sentiment lexicon, and Chua et al presented im-provement for) on a collection of manually labeledmessages (classified into Buy, Sell, Hold).
Interest-ingly, Chua et al made use of an Australian mes-1318sage board (HotCopper), where, unlike most of thestock message boards, these labels are added by themessage author.
Another related work is (Zhang andSkiena, 2010), who apply lexicon-based sentimentanalysis to several sources of news and blogs, in-cluding tweets.
However, their data set does not in-clude stock microblogs, but tweets mentioning theofficial company name.Our work differs from previous work on stockmessages in two vital aspects.
Firstly, these worksdid not attempt to distinguish between experts andnon-expert users, but aggregated the sentiment overall the users when studying the relation between sen-timent and the stock market.
Secondly, unlike theseworks, our best-performing methods are completelyunsupervised, and require no manually tagged train-ing data or sentiment lexicons.8 ConclusionThis paper investigated the novel task of finding ex-pert investors in online stock forums.
In particular,we focused on stock microblogs.
We proposed aframework for finding expert investors, and exper-imented with several methods for tweet classifica-tion using this framework.
We found that combin-ing our framework with user-specific unsupervisedlearning allows us to predict stock price movementwith high precision, and the results were shown to bestatistically significant.
Our results illustrate the im-portance of distinguishing experts from non-experts.An additional contribution of this work is an in-depth analysis of stock tweets, which sheds light ontheir content and its potential utility.In future work we plan to improve the features ofthe SVM classifier, and further investigate the use-fulness of our approach for trading.ReferencesWerner Antweiler and Murray Z. Frank.
2004.
Is allthat talk just noise?
the information content of in-ternet stock message boards.
Journal of Finance,59(3):1259?1294.Johan Bollen, Huina Mao, and Xiaojun Zeng.
2011.Twitter mood predicts the stock market.
Journal ofComputational Science, 2(1):1 ?
8.Christopher Chua, Maria Milosavljevic, and James R.Curran.
2009.
A sentiment detection engine for in-ternet stock message boards.
In Proceedings of theAustralasian Language Technology Association Work-shop 2009.Sanjiv R. Das and Mike Y. Chen.
2007.
Yahoo!
forAmazon: Sentiment extraction from small talk on theWeb.
Management Science, 53(9):1375?1388.Dmitry Davidov, Oren Tsur, and Ari Rappoport.
2010.Enhanced sentiment learning using twitter hashtagsand smileys.
In Proceedings of the 23rd InternationalConference on Computational Linguistics: Posters,COLING ?10.
Association for Computational Linguis-tics.Ann Devitt and Khurshid Ahmad.
2007.
Sentimentpolarity identification in financial news: A cohesion-based approach.
In Proceedings of the 45th AnnualMeeting of the Association of Computational Linguis-tics, pages 984?991.T.
Joachims.
1999.
Making large-scale SVM learningpractical.
In B. Scholkopf, C. Burges, and A. Smola,editors, Advances in Kernel Methods - Support VectorLearning.
MIT-Press.Moshe Koppel and Itai Shtrimberg.
2004.
Good newsor bad news?
Let the market decide.
In Proceedingsof the AAAI Spring Symposium on Exploring Attitudeand Affect in Text: Theories and Applications.Victor Lavrenko, Matt Schmill, Dawn Lawrie, PaulOgilvie, David Jensen, and James Allan.
2000.
Min-ing of concurrent text and time series.
In Proceedingsof the 6th ACM SIGKDD Int?l Conference on Knowl-edge Discovery and Data Mining Workshop on TextMining.Brendan O?Connor, Ramnath Balasubramanyan,Bryan R. Routledge, and Noah A. Smith.
2010.
Fromtweets to polls: Linking text sentiment to public opin-ion time series.
In Proceedings of the InternationalAAAI Conference on Weblogs and Social Media.Neil O?Hare, Michael Davy, Adam Bermingham, PaulFerguson, Pvraic Sheridan, Cathal Gurrin, and Alan FSmeaton.
2009.
Topic-dependent sentiment analysisof financial blogs.
In TSA?09 - 1st International CIKMWorkshop on Topic-Sentiment Analysis for Mass Opin-ion Measurement.Robert P. Schumaker and Hsinchun Chen.
2010.
A dis-crete stock price prediction engine based on financialnews.
Computer, 43:51?56.Timm O. Sprenger and Isabell M. Welpe.
2010.
Tweetsand trades: The information content of stock mi-croblogs.
Technical report, TUM School of Manage-ment, December.
working paper.Wenbin Zhang and Steven Skiena.
2010.
Tradingstrategies to exploit blog and news sentiment.
InICWSM?10.1319
