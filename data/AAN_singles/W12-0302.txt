Proceedings of the EACL 2012 Workshop on Computational Linguistics and Writing, pages 9?18,Avignon, France, April 23, 2012. c?2012 Association for Computational LinguisticsFrom Drafting Guideline to Error Detection:Automating Style Checking for Legislative TextsStefan H?flerUniversity of Zurich, Instituteof Computational LinguisticsBinzm?hlestrasse 148050 Z?rich, Switzerlandhoefler@cl.uzh.chKyoko SugisakiUniversity of Zurich, Instituteof Computational LinguisticsBinzm?hlestrasse 148050 Z?rich, Switzerlandsugisaki@cl.uzh.chAbstractThis paper reports on the development ofmethods for the automated detection of vi-olations of style guidelines for legislativetexts, and their implementation in a pro-totypical tool.
To this aim, the approachof error modelling employed in automatedstyle checkers for technical writing is en-hanced to meet the requirements of legisla-tive editing.
The paper identifies and dis-cusses the two main sets of challenges thathave to be tackled in this process: (i) theprovision of domain-specific NLP methodsfor legislative drafts, and (ii) the concretisa-tion of guidelines for legislative drafting sothat they can be assessed by machine.
Theproject focuses on German-language legisla-tive drafting in Switzerland.1 IntroductionThis paper reports on work in progress that isaimed at providing domain-specific automatedstyle checking to support German-language legisla-tive editing in the Swiss federal administration.
Inthe federal administration of the Swiss Confedera-tion, drafts of new acts and ordinances go throughseveral editorial cycles.
In a majority of cases, theyare originally written by civil servants in one ofthe federal offices concerned, and then reviewedand edited both by legal experts (at the FederalOffice of Justice) and language experts (at the Fed-eral Chancellery).
While the former ensure thatthe drafts meet al relevant legal requirements, thelatter are concerned with the formal and linguisticquality of the texts.
To help this task, the author-ities have drawn up style guidelines specificallygeared towards Swiss legislative texts (Bundeskan-zlei, 2003; Bundesamt f?r Justiz, 2007).Style guidelines for laws (and other types oflegal texts) may serve three main purposes: (i) im-proving the understandability of the texts (Lerch,2004; Wydick, 2005; Mindlin, 2005; Butt andCastle, 2006; Eichhoff-Cyrus and Antos, 2008),(ii) enforcing their consistency with related texts,and (iii) facilitating their translatability into otherlanguages.
These aims are shared with writingguidelines developed for controlled languages inthe domain of technical documentation (Lehrndor-fer, 1996; Reuther, 2003; Muegge, 2007).The problem is that the manual assessment ofdraft laws for their compliance with all relevantstyle guidelines is time-consuming and easily in-consistent due to the number of authors and editorsinvolved in the drafting process.
The aim of thework presented in this paper is to facilitate thisprocess by providing methods for a consistent au-tomatic identification of some specific guidelineviolations.The remainder of the paper is organised as fol-lows.
We first delineate the aim and scope of theproject presented in the paper (section 2) and theapproach we are pursuing (section 3).
In the mainpart of the paper, we then identify and discussthe two main challenges that have to be tackled:the technical challenge of providing NLP methodsfor legislative drafts (section 4) and the linguis-tic challenge of concretising the existing draftingguidelines for legislative texts (section 5).2 Aim and ScopeThe aim of the project to be presented in this paperis to develop methods of automated style checkingspecifically geared towards legislative editing, andto implement these methods in a prototypical tool(cf.
sections 3 and 4).
We work towards automat-9XML<...><...><...><...><...><...><...>DetectionRulesPre-processingErrorDetectionLegislativeDraftEnriched DraftError ReportPredefinedHelptextsID 203Help TextID  span80  [...]135  [...]203  [...]OutputGeneration2)1)3)HighlightedDraft1)2)3)Documentation/Help Text+Error IDToken IDsFigure 1: Architecture of the style checking system.ically detecting violations of existing guidelines,and where these guidelines are very abstract, weconcretise them so that they become detectable bymachine (cf.
section 5).
However, it is explicitlynot the goal of our project to propose novel stylerules.We have adopted a broad conception of ?stylechecking?
that is roughly equivalent to how theterm, and its variant ?controlled language check-ing,?
have been used in the context of technicalwriting (Geldbach, 2009).
It comprises the assess-ment of various aspects of text composition con-trolled by specific writing guidelines (typographi-cal conventions, lexical preferences, syntax-relatedrecommendations, constraints on discourse anddocument structure), but it does not include theevaluation of spelling and grammar.While our project focuses on style checking forGerman-language Swiss federal laws (the federalconstitution, acts of parliament, ordinances, fed-eral decrees, cantonal constitutions), we believethat the challenges arising from the task are in-dependent of the chosen language and legislativesystem but pertain to the domain in general.3 ApproachThe most important innovative contribution of ourproject is the enhancement of the method of er-ror modelling to meet the requirements of legisla-tive editing.
Error modelling means that texts aresearched for specific features that indicate a styleguideline violation: the forms of specific ?errors?are thus anticipated and modelled.The method of error modelling has mainly beendeveloped for automated style checking in the do-main of technical writing.
Companies often con-trol the language used in their technical documen-tation in order to improve the understandability,readability and translatability of these texts.
Con-trolled language checkers are tools that evaluateinput texts for compliance with such style guide-lines set up by a company.1State-of-the-art controlled language checkerswork along the following lines.
In a pre-processingstep, they first perform an automatic analysis of theinput text (tokenisation, text segmentation, mor-phological analysis, part-of-speech tagging, pars-ing) and enrich it with the respective structuraland linguistic information.
They then apply anumber of pre-defined rules that model potential?errors?
(i.e.
violations of individual style guide-lines) and aim at detecting them in the analysedtext.
Most checkers give their users the option tochoose which rules the input text is to be checkedfor.
Once a violation of the company?s style guide-lines has been detected, the respective passage ishighlighted and an appropriate help text is madeavailable to the user (e.g.
as a comment in the orig-inal document or in an extra document generatedby the system).
The system we are working on isconstructed along the same lines; its architectureis outlined in Fig.
1.Transferring the described method to the do-main of legislative editing has posed challengesto both pre-processing and error modelling.
Thepeculiarities of legal language and legislative textshave necessitated a range of adaptations in the NLPprocedures devised, and the guidelines for legisla-tive drafting have required highly domain-specific1Examples of well-developed commercial tools that offersuch style checking for technical texts are acrolinx IQ byAcrolinx and CLAT by IAI.10error modelling, which needed to be backed upby substantial linguistic research.
We will detailthese two sets of challenges in the following twosections.4 Pre-Processing4.1 TokenisationThe legislative drafters and editors we are target-ing exclusively work with MS Word documents.Drafters compose the texts in Word, and legisla-tive editors use the commenting function of Wordto add their suggestions and corrections to thetexts they receive.
We make use of the XMLrepresentation (WordML) underlying these doc-uments.
In a first step, we tokenise the text con-tained therein and assign each token an ID directlyin the WordML structure.
We then extract thetext material (including the token IDs and someformatting information that proves useful in theprocessing steps to follow) for further processing.The token IDs are used again at the end of thestyle checking process when discovered styleguideviolations are highlighted by inserting a Word com-ment at the respective position in the WordML rep-resentation of the original document.
The outputof our style checker is thus equivalent to how leg-islative editors make their annotations to the drafts?
a fact that proves essential with regard to the toolbeing accepted by its target users.4.2 Text SegmentationAfter tokenisation, the input text is then segmentedinto its structural units.
Legislative texts exhibit asophisticated domain-specific structure.
Our textsegmentation tool detects the boundaries of chap-ters, sections, articles, paragraphs, sentences andenumeration elements, and marks them by addingcorresponding XML tags to the text.There are three reasons why text segmentationis crucial to our endeavour:1.
Proper text segmentation ensures that onlyrelevant token spans are passed on to furtherprocessing routines (e.g.
sentences containedin articles must to be passed on to the parser,whereas article numbers or section headingsmust not).2.
Most structural units are themselves the ob-ject of style rules (e.g.
?sections should notcontain more than twelve articles, articlesshould not contain more than three para-graphs and paragraphs should not containmore than one sentence?).
The successfuldetection of violations of such rules dependson the correct delimitation of the respectivestructural units in the text.3.
Certain structural units constitute the contextfor other style rules (e.g.
?the sentence rightbefore the first element of an enumeration hasto end in a colon?
; ?the antecedent of a pro-noun must be within the same article?).
Heretoo, correct text segmentation constitutes theprerequisite for an automated assessment ofthe respective style rules.We have devised a line-based pattern-matching al-gorithm with look-around to detect the boundariesof the structural units of legislative drafts (H?flerand Piotrowski, 2011).
The algorithm also exploitsformatting information extracted together with thetext from the Word documents.
However, not allformatting information has proven equally reliable:as the Word documents in which the drafts are com-posed do only make use of style environments toa very limited extent, formatting errors are rela-tively frequent.
Font properties such as italics orbold face, or the use of list environments are fre-quently erroneous and can thus not be exploited forthe purpose of delimiting text segments; headersand newline information, on the other hand, haveproven relatively reliable.Figure 2 illustrates the annotation that our toolyields for the excerpt shown in the following ex-ample:(1) Art.
14 Amtsenthebung 2Die Wahlbeh?rde kann eine Richterin odereinen Richter vor Ablauf der Amtsdauer desAmtes entheben, wenn diese oder dieser:a. vors?tzlich oder grobfahrl?ssigAmtspflichten schwer verletzt hat; oderb.
die F?higkeit, das Amt auszu?ben, aufDauer verloren hat.Art.
14 Removal from officeThe electoral authorities may remove a judgefrom office before he or she has completedhis or her term where he or she:2Patentgerichtsgesetz (Patent Court Act), SR 173.41; forthe convenience of readers, examples are also rendered in the(non-authoritative) English version published athttp://www.admin.ch/ch/e/rs/rs.html.11<article><article_head><article_type>Art.</article_type><article_nr>14</article_nr><article_header>Amtsenthebung</article_header></article_head><article_body><paragraph><sentence>Die Wahlbeh?rde kann eine Richterin oder einen Richter vor Ablauf der Amtsdauerdes Amtes entheben, wenn diese oder dieser:<enumeration><enumeration_element><element_nr type="letter">a.</element_nr><element_text>vors?tzlich oder grobfahrl?ssig Amtspflichten schwer verletzt hat;oder</element_text></enumeration_element><enumeration_element><element_nr type="letter">b.</element_nr><element_text>die F?higkeit, das Amt auszu?ben, auf Dauer verloren hat.</element_text></enumeration_element></enumeration></sentence></paragraph></article_body></article>Figure 2: Illustration of the text segmentation provided by the tool.
Excerpt: Article 14 of the Patent Court Act.
(Token delimiters and any other tags not related to text segmentation have been omitted in the example.)a.
wilfully or through gross negligencecommits serious breaches of his or herofficial duties; orb.
has permanently lost the ability toperform his or her official duties.As our methods must be robust in the face of inputtexts that are potentially erroneous, the text seg-mentation provided by our tool does not amount toa complete document parsing; our text segmenta-tion routine rather performs a document chunkingby trying to detect as many structural units as pos-sible.Another challenge that arises from the fact thatthe input texts may be erroneous is that featureswhose absence we later need to mark as an errorcannot be exploited for the purpose of detectingthe boundaries of the respective contextual unit.
Acolon, for instance, cannot be used as an indicatorfor the beginning of an enumeration since we mustlater be able to search for enumerations that are notpreceded by a sentence ending in a colon as thisconstitutes a violation of the respective style rule.Had the colon been used as an indicator for the de-tection of enumeration boundaries, only enumera-tions preceded by a colon would have been markedas such in the first place.
The development of ad-equate pre-processing methods constantly facessuch dilemmas.
It is thus necessary to always an-ticipate the specific guideline violations that onelater wants to detect on the basis of the informationadded by any individual pre-processing routine.Special challenges also arise with regard to thetask of sentence boundary detection.
Legislativetexts contain special syntactic structures that off-the-shelf tools cannot process and that thereforeneed special treatment.
Example (1) showed a sen-tence that runs throughout a whole enumeration;colon and semicolons do not mark sentence bound-aries in this case.
To complicate matters evenfurther, parenthetical sentences may be insertedbehind individual enumeration items, as shown inexample (2).
(2) Art.
59 Abschirmung 31 Der Raum oder Bereich, in dem station?reAnlagen oder radioaktive Strahlenquellenbetrieben oder gelagert werden, ist so zu3Strahlenschutzverordnung (Radiological Protection Or-dinance), SR 814.50; emphasis added.12konzipieren oder abzuschirmen, dass unterBer?cksichtigung der Betriebsfrequenz:a. an Orten, die zwar innerhalb desBetriebsareals, aber ausserhalb vonkontrollierten Zonen liegen und andenen sich nichtberuflichstrahlenexponierte Personen aufhaltenk?nnen, die Ortsdosis 0,02 mSv proWoche nicht ?bersteigt.
Dieser Wertkann an Orten, wo sich Personennicht dauernd aufhalten, bis zumF?nffachen ?berschritten werden;b. an Orten ausserhalb des Betriebsarealsdie Immissionsgrenzwerte nachArtikel 102 nicht ?berschritten werden.2 [...]Art.
59 Shielding1 The room or area in which stationaryradiation generators or radioactive sourcesare operated or stored shall be designed andshielded in such a way that, taking intoaccount the frequency of use:a. in places situated within the premisesbut outside controlled areas, wherenon-occupationally exposed personsmay be present, the local dose does notexceed 0.02 mSv per week.
In placeswhere people are not continuouslypresent, this value may be exceededby up to a factor of five;b. in places outside the premises, theoff-site limits specified in Article102are not exceeded.2 [...]In this example, a parenthetical sentence (markedin bold face) has been inserted at the end of thefirst enumeration item.
A full stop has been putwhere the main sentence is interrupted, whereasthe inserted sentence is ended with a semicolonto indicate that after it, the main sentence is con-tinued.
The recognition of sentential insertions asthe one shown in (2) is important for two reasons:(i) sentential parentheses are themselves the objectof style rules (in general, they are to be avoided)and should thus be marked by a style checker, and(ii) a successful parsing of the texts depends on aproper recognition of the sentence boundaries.
Asoff-the-shelf tools cannot cope with such domain-specific structures, we have had to devise highlyspecialised algorithms for sentence boundary de-tection in our texts.4.3 Linguistic AnalysisFollowing text segmentation, we perform a lin-guistic analysis of the input text which consists ofthree components: part-of-speech tagging, lemma-tisation and chunking/parsing.
The informationadded by these pre-processing steps is later usedin the detection of violations of style rules thatpertain to the use of specific terms (e.g.
?the modalsollen ?should?
is to be avoided?
), syntactic con-structions (e.g.
?complex participial constructionspreceding a noun should be avoided?)
or combina-tions thereof (e.g.
?obligations where the subjectis an authority must be put as assertions and notcontain a modal verb?
).For the tasks of part-of-speech tagging and lem-matisation, we employ TreeTagger (Schmid, 1994).We have adapted TreeTagger to the peculiaritiesof Swiss legislative language.
Domain-specifictoken types are pre-tagged in a special routine toavoid erroneous part-of-speech analyses.
An ex-ample of a type of tokens that needs pre-taggingare domain-specific cardinal numbers: i.e.
cardi-nal numbers augmented with letters (Article 2a)or with Latin ordinals (Paragraph 4bis) as well asranges of such cardinal numbers (Articles 3c?6).Furthermore, TreeTagger?s recognition of sentenceboundaries is overwritten by the output of our textsegmentation routine.
We have also augmentedTreeTagger?s domain-general list of abbreviationswith a list of domain-specific abbreviations andacronyms provided by the Swiss Federal Chan-cellery.
The lemmatisation provided by TreeTag-ger usually does not recognise complex compoundnouns (e.g.
G?terverkehrsverlagerung ?freight traf-fic transfer?
); such compound nouns are frequentin legislative texts (Nussbaumer, 2009).
To solvethe problem, we combine the output of TreeTag-ger?s part-of-speech tagging with the lemma infor-mation delivered by the morphology analysis toolGERTWOL (Haapalainen and Majorin, 1995).Some detection tasks (e.g.
the detection of legaldefinitions discussed in section 4.4 below) addi-tionally require chunking or even parsing.
Forchunking, we also employ TreeTagger; for pars-ing, we have begun to adapt ParZu to legislativelanguage, a robust state-of-art dependency parser13(Sennrich et al, 2009).
Like most off-the-shelfparsers, ParZu was trained on a corpus of newspa-per articles.
As a consequence, it struggles withanalysing constructions that are rare in that do-main but frequent in legislative texts, such as com-plex coordinations of prepositional phrases andPP-attachment chains (Venturi, 2008), parenthe-ses (as illustrated in example 2 above) or subjectclauses (as shown in example 3 below).
(3) Art.
17 Rechtfertigender Notstand 4Wer eine mit Strafe bedrohte Tat begeht,um ein eigenes oder das Rechtsgut eineranderen Person aus einer unmittelbaren,nicht anders abwendbaren Gefahr zuretten, handelt rechtm?ssig, wenn erdadurch h?herwertige Interessen wahrt.Art.
17 Legitimate act in a situation ofnecessityWhoever carries out an act that carries acriminal penalty in order to save a legalinterest of his own or of another fromimmediate and not otherwise avertabledanger, acts lawfully if by doing so hesafeguards interests of higher value.As the adaptation of ParZu to legislative texts isstill in its early stages, we cannot yet provide anassessment of how useful the output of the parser,once properly modified, will be to our task.4.4 Context RecognitionThe annotations that the pre-processing routinesdiscussed so far add to the text serve as the basisfor the automatic recognition of domain-specificcontexts.
Style rules for legislative drafting oftenonly apply to special contexts within a law.
Anexample is the rule pertaining to the use of themodal sollen (?should?).
The drafting guidelinesforbid the use of this modal except in statementsof purpose.
Statements of purpose thus consti-tute a special context inside which the detectionof an instance of sollen is not to trigger an errormessage.
Other examples of contexts in whichspecial style rules apply are transitional provisions(?bergangsbestimmungen), repeals and amend-ments of current legislation (Aufhebungen und ?n-derungen bisherigen Rechts), definitions of the4Strafgesetzbuch (Criminal Code), SR 311.0; emphasisadded.subject of a law (Gegenstandsbestimmungen), def-initions of the scope of a law (Geltungsbereichsbe-stimmungen), definitions of terms (Begriffsbestim-mungen), as well as preambles (Pr?ambeln) andcommencement clauses (Ingresse).A number of these contexts can be identifiedautomatically by assessing an article?s positionin the text and certain keywords contained in itsheader.
A statements of purpose, for instance, isusually the first article of a law, and its header usu-ally contains the words Zweck (?purpose?)
or Ziel(?aim?).
Similar rules can be applied to recognisetransitional provisions, repeals and amendments ofcurrent legislation, and definitions of the subjectand the scope of a law.Other contexts have to be detected at the senten-tial level.
Definitions of terms, for instance, do notonly occur as separate articles at the beginning of alaw; they can also appear in the form of individualsentences throughout the text.
As there is a wholerange of style rules pertaining to legal definitions(e.g.
?a term must only be defined if it occurs atleast three times in the text?
; ?a term must only bedefined once within the same text?
; ?a term mustnot be defined by itself?
), the detection of this par-ticular context (and its components: the term andthe actual definition) is crucial to a style checkerfor legislative texts.5To identify legal definitions in the text, we havebegun to adopt strategies developed in the con-text of legal information retrieval: Walter andPinkal (2009) and de Maat and Winkels (2010),for instance, show that definitions in German courtdecisions and in Dutch laws respectively can bedetected by searching for combinations of keywords and sentence patterns typically used in thesedomain-specific contexts.
In H?fler et al (2011)we have argued that this approach is also feasiblewith regard to Swiss legislative texts: our pilotstudy has shown that a substantial number of legaldefinitions can be detected even without resort-ing to syntactic analyses, merely by searching fortypical string patterns such as ?X im Sinne dieserVerordnung ist/sind Y?
(?X in the sense of this ordi-nance is/are Y?).
We are currently working towardsrefining and extending the detection of legal defini-tions by including additional syntactic informationyielded by the processes of chunking and parsinginto the search patterns.5Further rules for the use of legal definitions in Swiss lawtexts are provided by Bratschi (2009).14Once the legal definitions occurring in a drafthave been marked, the aforementioned style rulescan be checked automatically (e.g.
by searchingthe text for terms that are defined in a definitionbut occur less than three times in the remainderof the text; by checking if there are any two legaldefinitions that define the same term; by assessingif there are definitions where the defined term alsooccurs in the actual definition).After having outlined some of the main chal-lenges that the peculiarities of legal language andlegislative texts pose to the various pre-processingtasks, we now turn to the process of error mod-elling, i.e.
the effort of transferring the guidelinesfor legislative drafting into concrete error detectionmechanisms operating on the pre-processed texts.5 Error Modelling5.1 SourcesThe first step towards error modelling consists incollecting the set of style rules that shall be ap-plied to the input texts.
The main source that weuse for this purpose are the compilations of draft-ing guidelines published by the Swiss Federal Ad-ministration (Bundeskanzlei, 2003; Bundesamt f?rJustiz, 2007).
However, especially when it comesto linguistic issues, these two documents do notclaim to provide an exhaustive set of writing rules.Much more so than the writing rules that are putin place in the domain of technical documenta-tion, the rules used in legislative drafting are basedon historically grown conventions, and there maywell be conventions beyond what is explicitly writ-ten down in the Federal Administration?s officialdrafting guidelines.Consequently, we have also been collect-ing rule material from three additional sources.A first complementary source are the variousdrafting guidelines issued by cantonal govern-ments (Regierungsrat des Kantons Z?rich, 2005;Regierungsrat des Kantons Bern, 2000) and, to alesser extent, the drafting guidelines of the otherGerman-speaking countries (Bundesministeriumf?r Justiz, 2008; Bundeskanzleramt, 1990; Rechts-dienst der Regierung, 1990) and the EuropeanUnion (Europ?ische Kommission, 2003).
A sec-ond source are academic papers dealing with spe-cific issues of legislative drafting, such as Eisen-berg (2007), Bratschi (2009).Finally, legislative editors themselves constitutean invaluable source of expert knowledge.
In or-der to learn of their unwritten codes of practice,we have established a regular exchange with theCentral Language Services of the Swiss FederalChancellery.
Including the editors in the processis likely to prove essential for the acceptability ofthe methods that we develop.5.2 Concretisation and FormalisationThe next error modelling step consists in concretis-ing and formalising the collected rules so that spe-cific algorithms can be developed to search forviolations of the rules in the pre-processed texts.Depending on the level of abstraction of a rule,this task is relatively straight-forward or it requiresmore extensive preliminary research:Concrete Rules A number of rules for legisla-tive drafting define concrete constraints and canthus be directly translated into detection rules.
Ex-amples of such concrete rules are rules that pro-hibit the use of specific abbreviations (e.g.
bzw.?respectively?
; z.B.
?e.g.?
; d.h.
?i.e.?)
and of certainterms and phrases (e.g.
grunds?tzlich ?in princi-ple?
; in der Regel ?as a general rule?).
In suchcases, error detection simply consists in searchingfor the respective items in the input text.Some rules first need to be spelled out but canthen also be formalised more or less directly: therule stating that units of measurement must alwaysbe written out rather than abbreviated, for instance,requires that a list of such abbreviations of mea-suring units (e.g.
m for meter, kg for kilogram, %for percent) is compiled whose entries can then besearched for in the text.The formalisation of some other rules is some-what more complicated but can still be derivedmore or less directly.
The error detection strate-gies for these rules include accessing tags thatwere added during pre-processing or evaluatingthe environment of a potential error.
For exam-ple, the rule stating that sentences introducing anenumeration must end in a colon can be checkedby searching the text for <enumeration> tags thatare not preceded by a colon; violations of the rulestating that an article must not contain more thanthree paragraphs can be detected by counting foreach <article_body> environment, the number of<paragraph> elements it contains.15Abstract Rules However, guidelines for legisla-tive drafting frequently contain rules that definerelatively abstract constraints.
In order to be ableto detect violations of such constraints, a linguisticconcretisation of the rules is required.An example is the oft-cited rule that a sentenceshould only convey one statement or proposition(Bundesamt f?r Justiz, 2007, p. 358).
The er-ror modelling for this rule is not straightforward:it is neither clear what counts as a statement inthe context of a legislative text, nor is it obviouswhat forms sentences violating this rule exhibit.Linguistic indicators for the presence of a multi-propositional sentence first need to be determinedin in-depth analyses of legislative language.
InH?fler (2011), we name a number of such indica-tors: among other things, sentence coordination,relative clauses introduced by the adverb wobei(?whereby?
), and certain prepositions (e.g.
vorbe-h?ltlich ?subject to?
or mit Ausnahme von ?with theexception of?)
can be signs that a sentence containsmore than one statement.Even drafting rules that look fairly specific atfirst glance may turn out to be in need of further lin-guistic concretisation.
An example is the rule thatstates that in an enumeration, words that are sharedbetween all enumeration elements should be brack-eted out into the introductory sentence of the enu-meration.
If, for instance, each element of anenumeration starts with the preposition f?r (?for?
),then that preposition belongs in the introductorysentence.
The rule seems straight enough, but inreality, the situation is somewhat more compli-cated.
Example (4) shows a case where a wordthat occurs at the beginning of all elements of anenumeration (the definite article die ?the?)
cannotbe bracketed out into the introductory sentence:(4) Art.
140 Obligatorisches Referendum 6[...]2 Dem Volk werden zur Abstimmungunterbreitet:a. die Volksinitiativen auf Totalrevisionder Bundesverfassung;b. die Volksinitiativen auf Teilrevision derBundesverfassung in der Form derallgemeinen Anregung, die von derBundesversammlung abgelehnt wordensind;6Bundesverfassung (Federal Constitution), SR 101; em-phasis added.c.
die Frage, ob eine Totalrevision derBundesverfassung durchzuf?hren ist,bei Uneinigkeit der beiden R?te.Art.
140 Mandatory referendum[...]2 The following shall be submitted to a voteof the People:a. the popular initiatives for a completerevision of the Federal Constitution;b. the popular initiatives for a partialrevision of the Federal Constitution inthe form of a general proposal that havebeen rejected by the Federal Assembly;c. the question of whether a completerevision of the Federal Constitutionshould be carried out, in the event thatthere is disagreement between the twoCouncils.Even if one ignores the fact that the definite articlein letters a and b is in fact not the same as theone in letter c (the former being plural, the lattersingular), it is quite apparent that articles cannotbe extracted from the elements of an enumerationwithout the nouns they specify.
Even the seem-ingly simple rule in question is thus in need of amore linguistically informed concretisation beforeit can be effectively checked by machine.The examples illustrate that style guidelines forlegislative writing are often kept at a level of ab-straction that necessitates concretisations if oneis to detect violations of the respective rules au-tomatically.
Besides the development of domain-specific pre-processing algorithms, the extensiveand highly specialised linguistic research requiredfor such concretisations constitutes the main taskbeing tackled in this project.Conflicting Rules A further challenge to errormodelling arises from the fact that a large propor-tion of drafting guidelines for legislative texts donot constitute absolute constraints but rather havethe status of general writing principles and rulesof thumb.
This fact has to be reflected in the feed-back messages that the system gives to its users:what the tool detects are often not ?errors?
in theproper sense of the word but merely passages thatthe author or editor may want to reconsider.The fact that many style rules only define softconstraints also means that there may be conflict-ing rules.
Consider, for instance, sentence (5):16(5) Art.
36 Ersatzfreiheitsstrafe 7[...]5 Soweit der Verurteilte die Geldstrafe trotzverl?ngerter Zahlungsfrist oderherabgesetztem Tagessatz nicht bezahlt oderdie gemeinn?tzige Arbeit trotz Mahnungnicht leistet, wird die Ersatzfreiheitsstrafevollzogen.Art.
36 Alternative custodial sentence[...]5 As far as the offender fails to pay themonetary penalty despite being granted anextended deadline for payment or a reduceddaily penalty unit or fails to perform thecommunity service despite being warned ofthe consequences, the alternative custodialsentence is executed.On the one hand, this sentence must be consid-ered a violation of the style rule that states thatthe main verb of a sentence (here execute) shouldbe introduced as early as possible (Regierungsratdes Kantons Z?rich, 2005, p. 73).
On the otherhand, if the sentence was re-arranged in compli-ance with this rule ?
by switching the order of themain clause and the subsidiary clause ?
it wouldviolate the rule stating that information is to be pre-sented in temporal and causal order (Bundesamtf?r Justiz, 2007, p. 354).
This latter rule entailsthat the condition precedes its consequence.To be able to deal with such conflicting con-straints, error detection strategies have to be as-signed weights.
However, one and the same rulemay have different weights under different cir-cumstances.
In conditional sentences like the oneshown above, the causality principle obviouslyweighs more than the rule that the main verb mustbe introduced early in the sentence.
Such context-dependent rankings for individual style rules haveto be inferred and corroborated by tailor-madecorpus-linguistic studies.5.3 Testing and EvaluationThe number of drafts available to us is very lim-ited ?
too limited to be used to test and refine theerror models we develop.
However, due to thecomplexity of the drafting process (multiple au-thors and editors, political intervention), laws that7Strafgesetzbuch (Criminal Code), SR 311.0have already come into force still exhibit viola-tions of specific style rules.
We therefore resortto such already published laws to test and refinethe error models we develop.
To this aim, we havebuilt a large corpus of legislative texts automati-cally annotated by the pre-processing routines wehave described earlier in the paper (H?fler andPiotrowski, 2011).
The corpus contains the entirecurrent federal legislation of Switzerland, i.e.
thefederal constitution, all cantonal constitutions, allfederal acts and ordinances, federal decrees andtreaties between the Confederation and individualcantons and municipalities.
It allows us to try outand evaluate novel error detection strategies byassessing the number and types of true and falsepositives returned.6 ConclusionIn this paper, we have discussed the developmentof methods for the automated detection of viola-tions of domain-specific style guidelines for leg-islative texts, and their implementation in a proto-typical tool.
We have illustrated how the approachof error modelling employed in automated stylecheckers for technical writing can be enhanced tomeet the requirements of legislative editing.
Twomain sets of challenges are tackled in this process.First, domain-specific NLP methods for legisla-tive drafts have to be provided.
Without extensiveadaptations, off-the-shelf NLP tools that have beentrained on corpora of newspaper articles are notadequately equipped to deal with the peculiaritiesof legal language and legislative texts.
Second,the error modelling for a large number of draft-ing guidelines requires a concretisation step beforeautomated error detection strategies can be put inplace.
The substantial linguistic research that suchconcretisations require constitutes a core task to becarried out in the development of a style checkerfor legislative texts.AcknowledgmentsThe project is funded under SNSF grant 134701.The authors wish to thank the Central LanguageServices of the Swiss Federal Chancellery for theircontinued advice and support.ReferencesRebekka Bratschi.
2009.
?Frau im Sinne dieser Bade-ordnung ist auch der Bademeister.?
Legaldefinitio-17nen aus redaktioneller Sicht.
LeGes, 20(2):191?213.Bundesamt f?r Justiz, editor.
2007.
Gesetzgebungs-leitfaden: Leitfaden f?r die Ausarbeitung von Er-lassen des Bundes.
Bern, 3. edition.Bundeskanzlei, editor.
2003.
GesetzestechnischeRichtlinien.
Bern.Bundeskanzleramt, editor.
1990.
Handbuch der Recht-setzungstechnik, Teil 1: Legistische Leitlinien.
Wien.Bundesministerium f?r Justiz, editor.
2008.
Handbuchder Rechtsf?rmlichkeit, Empfehlungen zur Gestal-tung von Gesetzen und Rechtsverordnungen.
Bunde-sanzeiger Verlag, K?ln.Peter Butt and Richard Castle.
2006.
Modern LegalDrafting.
Cambridge University Press, Cambridge,UK, 2nd edition.Emile de Maat and Radboud Winkels.
2010.
Auto-mated classification of norms in sources of law.
InSemantic Processing of Legal Texts.
Springer, Berlin.Karin M. Eichhoff-Cyrus and Gerd Antos, editors.2008.
Verst?ndlichkeit als B?rgerrecht?
Die Rechts-und Verwaltungssprache in der ?ffentlichen Diskus-sion.
Duden, Mannheim, Germany.Peter Eisenberg.
2007.
Die Grammatik der Gesetzes-sprache: Was ist eine Verbesserung?
In AndreasL?tscher and Markus Nussbaumer, editors, Denkenwie ein Philosoph und schreiben wie ein Bauer,pages 105?122.
Schulthess, Z?rich.Europ?ische Kommission, editor.
2003.
Gemein-samer Leitfaden des Europ?ischen Parlaments, desRates und der Kommission f?r Personen, die in denGemeinschaftsorganen an der Abfassung von Rechts-texten mitwirken.
Amt f?r Ver?ffentlichungen derEurop?ischen Gemeinschaften, Luxemburg.Stephanie Geldbach.
2009.
Neue Werkzeuge zur Au-torenunterst?tzung.
MD?, 4:10?19.Mariikka Haapalainen and Ari Majorin.
1995.
GER-TWOL und morphologische Desambiguierung f?rdas Deutsche.
In Proceedings of the 10th NordicConference of Computational Linguistics.
Universityof Helsinki, Department of General Linguistics.Stefan H?fler and Michael Piotrowski.
2011.
Build-ing corpora for the philological study of Swiss legaltexts.
Journal for Language Technology and Com-putational Linguistics (JLCL), 26(2):77?90.Stefan H?fler, Alexandra B?nzli, and Kyoko Sugisaki.2011.
Detecting legal definitions for automatedstyle checking in draft laws.
Technical Report CL-2011.01, University of Zurich, Institute of Computa-tional Linguistics, Z?rich.Stefan H?fler.
2011.
?Ein Satz ?
eine Aussage.?
Multi-propositionale Rechtss?tze an der Sprache erkennen.LeGes, 22(2):259?279.Anne Lehrndorfer.
1996.
Kontrolliertes Deutsch: Lin-guistische und sprachpsychologische Leitlinien f?reine (maschinell) kontrollierte Sprache in der Tech-nischen Dokumentation.
G?nter Narr, T?bingen.Kent D. Lerch, editor.
2004.
Recht verstehen.Verst?ndlichkeit, Missverst?ndlichkeit und Unver-st?ndlichkeit von Recht.
de Gruyter, Berlin.Maria Mindlin.
2005.
Is plain language better?
A com-parative readability study of plain language courtforms.
Scribes Journal of Legal Writing, 10.Uwe Muegge.
2007.
Controlled language: The nextbig thing in translation?
ClientSide News Magazine,7(7):21?24.Markus Nussbaumer.
2009.
Rhetorisch-stilistischeEigenschaften der Sprache des Rechtswesens.
InUlla Fix, Andreas Gardt, and Joachim Knape, ed-itors, Rhetorik und Stilistik/Rhetoric and Stylis-tics, Handbooks of Linguistics and Communica-tion Science, pages 2132?2150.
de Gruyter, NewYork/Berlin.Rechtsdienst der Regierung, editor.
1990.
Richtli-nien der Regierung des F?rstentums Liechtenstein?ber die Grunds?tze der Rechtsetzung (LegistischeRichtlinien).
Vaduz.Regierungsrat des Kantons Bern, editor.
2000.
Recht-setzungsrichtlinien des Kantons Bern.
Bern.Regierungsrat des Kantons Z?rich, editor.
2005.Richtlinien der Rechtsetzung.
Z?rich.Ursula Reuther.
2003.
Two in one ?
can it work?
Read-ability and translatability by means of controlledlanguage.
In Proceedings of EAMT-CLAW 2003.Helmut Schmid.
1994.
Probabilistic part-of-speechtagging using decision trees.
In Proceedings of theInternational Conference on New Methods in Lan-guage Processing, pages 44?49.Rico Sennrich, Gerold Schneider, Martin Volk, andMartin Warin.
2009.
A new hybrid dependencyparser for German.
In Proceedings of the GSCLConference 2009, pages 115?124, T?bingen.Giulia Venturi.
2008.
Parsing legal texts: A contrastivestudy with a view to knowledge managment applica-tions.
In Proceedings of the LREC 2008 Workshopon Semantic Processing of Legal Texts, pages 1?10,Marakesh.Stephan Walter and Manfred Pinkal.
2009.
Defini-tions in court decisions: Automatic extraction andontology acquisition.
In Joost Breuker, PompeuCasanovas, Michel Klein, and Enrico Francesconi,editors, Law, Ontologies and the Semantic Web.
IOSPress, Amsterdam.Richard C. Wydick.
2005.
Plain English for Lawyers.Carolina Academic Press, 5th edition.18
