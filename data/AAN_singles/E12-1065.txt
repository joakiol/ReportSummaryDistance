Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 634?644,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsCharacter-based Kernels for Novelistic Plot StructureMicha ElsnerInstitute for Language, Cognition and Computation (ILCC)School of InformaticsUniversity of Edinburghmelsner0@gmail.comAbstractBetter representations of plot structurecould greatly improve computational meth-ods for summarizing and generating sto-ries.
Current representations lack abstrac-tion, focusing too closely on events.
Wepresent a kernel for comparing novelisticplots at a higher level, in terms of thecast of characters they depict and the so-cial relationships between them.
Our kernelcompares the characters of different nov-els to one another by measuring their fre-quency of occurrence over time and thedescriptive and emotional language associ-ated with them.
Given a corpus of 19th-century novels as training data, our methodcan accurately distinguish held-out novelsin their original form from artificially dis-ordered or reversed surrogates, demonstrat-ing its ability to robustly represent impor-tant aspects of plot structure.1 IntroductionEvery culture has stories, and storytelling is oneof the key functions of human language.
Yet whilewe have robust, flexible models for the structureof informative documents (for instance (Chen etal., 2009; Abu Jbara and Radev, 2011)), currentapproaches have difficulty representing the nar-rative structure of fictional stories.
This causesproblems for any task requiring us to modelfiction, including summarization and generationof stories; Kazantseva and Szpakowicz (2010)show that state-of-the-art summarizers performextremely poorly on short fictional texts1.
A ma-jor problem with applying models for informative1Apart from Kazantseva, we know of one other at-tempt to apply a modern summarizer to fiction, by theartist Jason Huff, using Microsoft Word 2008?s extrac-tive summary feature: http://jason-huff.com/text to fiction is that the most important struc-ture underlying the narrative?its plot?occurs ata high level of abstraction, while the actual narra-tion is of a series of lower-level events.A short synopsis of Jane Austen?s novel Prideand Prejudice, for example, is that Elizabeth Ben-net first thinks Mr. Darcy is arrogant, but latergrows to love him.
But this is not stated straight-forwardly in the text; the reader must infer it fromthe behavior of the characters as they participatein various everyday scenes.In this paper, we present the plot kernel, acoarse-grained, but robust representation of nov-elistic plot structure.
The kernel evaluates thesimilarity between two novels in terms of thecharacters and their relationships, constructingfunctional analogies between them.
These are in-tended to correspond to the labelings produced byhuman literary critics when they write, for exam-ple, that Elizabeth Bennet and Emma Woodhouseare protagonists of their respective novels.
By fo-cusing on which characters and relationships areimportant, rather than specifically how they inter-act, our system can abstract away from events andfocus on more easily-captured notions of whatmakes a good story.The ability to find correspondences betweencharacters is key to eventually summarizing oreven generating interesting stories.
Once we caneffectively model the kinds of people a romanceor an adventure story is usually about, and whatkind of relationships should exist between them,we can begin trying to analyze new texts by com-parison with familiar ones.
In this work, we eval-uate our system on the comparatively easy taskprojects/autosummarize.
Although this cannot betreated as a scientific experiment, the results are unusablybad; they consist mostly of short exclamations containingthe names of major characters.634of recognizing acceptable novels (section 6), butrecognition is usually a good first step towardgeneration?a recognition model can always beused as part of a generate-and-rank pipeline, andpotentially its underlying representation can beused in more sophisticated ways.
We show a de-tailed analysis of the character correspondencesdiscovered by our system, and discuss their po-tential relevance to summarization, in section 9.2 Related workSome recent work on story understanding has fo-cused on directly modeling the series of eventsthat occur in the narrative.
McIntyre and Lapata(2010) create a story generation system that drawson earlier work on narrative schemas (Chambersand Jurafsky, 2009).
Their system ensures thatgenerated stories contain plausible event-to-eventtransitions and are coherent.
Since it focuses onlyon events, however, it cannot enforce a global no-tion of what the characters want or how they relateto one another.Our own work draws on representations thatexplicitly model emotions rather than events.
Almand Sproat (2005) were the first to describe sto-ries in terms of an emotional trajectory.
They an-notate emotional states in 22 Grimms?
fairy talesand discover an increase in emotion (mostly posi-tive) toward the ends of stories.
They later use thiscorpus to construct a reasonably accurate clas-sifier for emotional states of sentences (Alm etal., 2005).
Volkova et al(2010) extend the hu-man annotation approach using a larger number ofemotion categories and applying them to freely-defined chunks instead of sentences.
The largest-scale emotional analysis is performed by Moham-mad (2011), using crowd-sourcing to construct alarge emotional lexicon with which he analyzesadult texts such as plays and novels.
In this work,we adopt the concept of emotional trajectory, butapply it to particular characters rather than worksas a whole.In focusing on characters, we follow Elson etal.
(2010), who analyze narratives by examiningtheir social network relationships.
They use anautomatic method based on quoted speech to findsocial links between characters in 19th centurynovels.
Their work, designed for computationalliterary criticism, does not extract any temporalor emotional structure.A few projects attempt to represent story struc-ture in terms of both characters and their emo-tional states.
However, they operate at a very de-tailed level and so can be applied only to shorttexts.
Scheherazade (Elson and McKeown, 2010)allows human annotators to mark character goalsand emotional states in a narrative, and indicatethe causal links between them.
AESOP (Goyal etal., 2010) attempts to learn a similar structure au-tomatically.
AESOP?s accuracy, however, is rel-atively poor even on short fables, indicating thatthis fine-grained approach is unlikely to be scal-able to novel-length texts; our system relies on amuch coarser analysis.Kazantseva and Szpakowicz (2010) summarizeshort stories, although unlike the other projectswe discuss here, they explicitly try to avoid givingaway plot details?their goal is to create ?spoiler-free?
summaries focusing on characters, settingsand themes, in order to attract potential readers.They do find it useful to detect character men-tions, and also use features based on verb aspect toautomatically exclude plot events while retainingdescriptive passages.
They compare their genre-specific system with a few state-of-the-art meth-ods for summarizing news, and find it outper-forms them substantially.We evaluate our system by comparing real nov-els to artificially produced surrogates, a procedurepreviously used to evaluate models of discoursecoherence (Karamanis et al 2004; Barzilay andLapata, 2005) and models of syntax (Post, 2011).As in these settings, we anticipate that perfor-mance on this kind of task will be correlated withperformance in applied settings, so we use it as aneasier preliminary test of our capabilities.3 DatasetWe focus on the 19th century novel, partly fol-lowing Elson et al(2010) and partly becausethese texts are freely available via Project Guten-berg.
Our main dataset is composed of romances(which we loosely define as novels focusing on acourtship or love affair).
We select 41 texts, tak-ing 11 as a development set and the remaining30 as a test set; a complete list is given in Ap-pendix A.
We focus on the novels used in Elsonet al(2010), but in some cases add additional ro-mances by an already-included author.
We alsoselected 10 of the least romantic works as an out-of-domain set; experiments on these are in section8.6354 PreprocessingIn order to compare two texts, we must first ex-tract the characters in each and some features oftheir relationships with one another.
Our first stepis to split the text into chapters, and each chapterinto paragraphs; if the text contains a running di-alogue where each line begins with a quotationmark, we append it to the previous paragraph.We segment each paragraph with MXTerminator(Reynar and Ratnaparkhi, 1997) and parse it withthe self-trained Charniak parser (McClosky et al2006).
Next, we extract a list of characters, com-pute dependency tree-based unigram features foreach character, and record character frequenciesand relationships over time.4.1 Identifying charactersWe create a list of possible character referencesfor each work by extracting all strings of propernouns (as detected by the parser), then discardingthose which occur less than 5 times.
Groupingthese into a useful character list is a problem ofcross-document coreference.Although cross-document coreference has beenextensively studied (Bhattacharya and Getoor,2005) and modern systems can achieve quite highaccuracy on the TAC-KBP task, where the listof available entities is given in advance (Dredzeet al 2010), novelistic text poses a significantchallenge for the methods normally used.
Thetypical 19th-century novel contains many relatedcharacters, often named after one another.
Thereare complicated social conventions determiningwhich titles are used for whom?for instance,the eldest unmarried daughter of a family can becalled ?Miss Bennet?, while her younger sistermust be ?Miss Elizabeth Bennet?.
And charactersoften use nicknames, such as ?Lizzie?.Our system uses the multi-stage clusteringapproach outlined in Bhattacharya and Getoor(2005), but with some features specific to 19thcentury European names.
To begin, we merge allidentical mentions which contain more than twowords (leaving bare first or last names unmerged).Next, we heuristically assign each mention a gen-der (masculine, feminine or neuter) using a list ofgendered titles, then a list of male and female firstnames2.
We then merge mentions where each islonger than one word, the genders do not clash,2The most frequent names from the 1990 US census.reply left-of-[name] 17right-of-[name] feel 14right-of-[name] look 10right-of-[name] mind 7right-of-[name] make 7Table 1: Top five stemmed unigram dependency fea-tures for ?Miss Elizabeth Bennet?, protagonist ofPride and Prejudice, and their frequencies.and the first and last names are consistent (Char-niak, 2001).
We then merge single-word mentionswith matching multiword mentions if they appearin the same paragraph, or if not, with the multi-word mention that occurs in the most paragraphs.When this process ends, we have resolved eachmention in the novel to some specific character.As in previous work, we discard very infrequentcharacters and their mentions.For the reasons stated, this method is error-prone.
Our intuition is that the simpler methoddescribed in Elson et al(2010), which mergeseach mention to the most recent possible coref-erent, must be even more so.
However, due tothe expense of annotation, we make no attempt tocompare these methods directly.4.2 Unigram character featuresOnce we have obtained the character list, we usethe dependency relationships extracted from ourparse trees to compute features for each charac-ter.
Similar feature sets are used in previous workin word classification, such as (Lin and Pantel,2001).
A few example features are shown in Table1.To find the features, we take each mention inthe corpus and count up all the words outside themention which depend on the mention head, ex-cept proper nouns and stop words.
We also countthe mention?s own head word, and mark whetherit appears to the right or the left (in general, thisword is a verb and the direction reflects the men-tion?s role as subject or object).
We lemmatizeall feature words with the WordNet (Miller et al1990) stemmer.
The resulting distribution overwords is our set of unigram features for the char-acter.
(We do not prune rare features, althoughthey have proportionally little influence on ourmeasurement of similarity.
)6360 10 20 30 40 500.00.20.40.60.81.01.21.41.6Freq of Miss Elizabeth BennetEmotions of Miss Elizabeth BennetCross freq x Mr. DarcyFigure 1: Normalized frequency and emotions associated with ?Miss Elizabeth Bennet?, protagonist of Prideand Prejudice, and frequency of paragraphs about her and ?Mr.
Darcy?, smoothed and projected onto 50 basispoints.4.3 Temporal relationshipsWe record two time-varying features for eachcharacter, each taking one value per chapter.
Thefirst is the character?s frequency as a proportionof all character mentions in the chapter.
The sec-ond is the frequency with which the character isassociated with emotional language?their emo-tional trajectory (Alm et al 2005).
We use thestrong subjectivity cues from the lexicon of Wil-son et al(2005) as a measurement of emotion.If, in a particular paragraph, only one characteris mentioned, we count all emotional words inthat paragraph and add them to the character?stotal.
To render the numbers comparable acrossworks, each paragraph subtotal is normalized bythe amount of emotional language in the novel asa whole.
Then the chapter score is the averageover paragraphs.For pairwise character relationships, we countthe number of paragraphs in which only two char-acters are mentioned, and treat this number (as aproportion of the total) as a measurement of thestrength of the relationship between that pair3.
El-son et al(2010) show that their method of find-ing conversations between characters is more pre-cise in showing whether a relationship exists, butthe co-occurrence technique is simpler, and we3We tried also counting emotional language in these para-graphs, but this did not seem to help in development experi-ments.care mostly about the strength of key relationshipsrather than the existence of infrequent ones.Finally, we perform some smoothing, by takinga weighted moving average of each feature valuewith a window of the three values on either side.Then, in order to make it easy to compare bookswith different numbers of chapters, we linearly in-terpolate each series of points into a curve andproject it onto a fixed basis of 50 evenly spacedpoints.
An example of the final output is shown inFigure 1.5 KernelsOur plot kernel k(x, y) measures the similaritybetween two novels x and y in terms of the fea-tures computed above.
It takes the form of aconvolution kernel (Haussler, 1999) where the?parts?
of each novel are its characters u ?
x,v ?
y and c is a kernel over characters:k(x, y) =?u?x?v?yc(u, v) (1)We begin by constructing a first-order ker-nel over characters, c1(u, v), which is defined interms of a kernel d over the unigram features anda kernel e over the single-character temporal fea-tures.
We represent the unigram feature counts asdistributions pu(w) and pv(w), and compute theirsimilarity as the amount of shared mass, times asmall penalty of .1 for mismatched genders:637d(pu, pv) = exp(??(1?
?wmin(pu(w), pv(w))))?.1 I{genu = genv}We compute similarity between a pair of time-varying curves (which are projected onto 50evenly spaced points) using standard cosine dis-tance, which approximates the normalized inte-gral of their product.e(u, v) =(u ?
v??u??v?)?
(2)The weights ?
and ?
are parameters of the sys-tem, which scale d and e so that they are compa-rable to one another, and also determine how fastthe similarity scales up as the feature sets growcloser; we set them to 5 and 10 respectively.We sum together the similarities of the char-acter frequency and emotion curves to measureoverall temporal similarity between the charac-ters.
Thus our first-order character kernel c1 is:c1(u, v) = d(pu, pv)(e(ufreq, vfreq)+e(uemo, vemo))We use c1 and equation 1 to construct a first-order plot kernel (which we call k1), and also asan ingredient in a second-order character kernelc2 which takes into account the curve of pairwisefrequencies u?, u?
between two characters u and u?in the same novel.c2(u, v) = c1(u, v)?u??x?v?
?ye(u?, u?, v?, v?
)c1(u?, v?
)In other words, u is similar to v if, for somerelationships of u with other characters u?, thereare similar characters v?
who serves the same rolefor v. We use c2 and equation 1 to construct ourfull plot kernel k2.5.1 Sentiment-only baselineIn addition to our plot kernel systems, we imple-ment a simple baseline intended to test the effec-tiveness of tracking the emotional trajectory ofthe novel without using character identities.
Wegive our baseline access to the same subjectiv-ity lexicon used for our temporal features.
Wecompute the number of emotional words used ineach chapter (regardless of which characters theyco-occur with), smoothed and normalized as de-scribed in subsection 4.3.
This produces a singletime-varying curve for each novel, representingthe average emotional intensity of each chapter.We use our curve kernel e (equation 2) to mea-sure similarity between novels.6 ExperimentsWe evaluate our kernels on their ability to distin-guish between real novels from our dataset andartificial surrogate novels of three types.
First, wealter the order of a real novel by permuting itschapters before computing features.
We constructone uniformally-random permutation for each testnovel.
Second, we change the identities of thecharacters by reassigning the temporal featuresfor the different characters uniformally at randomwhile leaving the unigram features unaltered.
(Forexample, we might assign the frequency, emotionand relationship curves for ?Mr.
Collins?
to ?MissElizabeth Bennet?
instead.)
Again, we produceone test instance of this type for each test novel.Third, we experiment with a more difficult order-ing task by taking the chapters in reverse.In each case, we use our kernel to performa ranking task, deciding whether k(x, y) >k(x, yperm).
Since this is a binary forced-choiceclassification, a random baseline would score50%.
We evaluate performance in the case wherewe are given only a single training document x,and for a whole training set X , in which case wecombine the decisions using a weighted nearestneighbor (WNN) strategy:?x?Xk(x, y) >?x?Xk(x, yperm)In each case, we perform the experiment ina leave-one-out fashion; we include the 11 de-velopment documents in X , but not in the testset.
Thus there are 1200 single-document compar-isons and 30 with WNN.
The results of our threesystems (the baseline, the first-order kernel k1 andthe second-order kernel k2) are shown in Table2.
(The sentiment-only baseline has no character-specific features, and so cannot perform the char-acter task.
)Using the full dataset and second-order kernelk2, our system?s performance on these tasks isquite good; we are correct 90% of the time fororder and character examples, and 67% for the638order character reversesentiment only 46.2 - 51.5single doc k1 59.5 63.7 50.7single doc k2 61.8 67.7 51.6WNN sentiment 50 - 53WNN k1 77 90 63WNN k2 90 90 67Table 2: Accuracy of kernels ranking 30 real novelsagainst artificial surrogates (chance accuracy 50%).more difficult reverse cases.
Results of this qual-ity rely heavily on the WNN strategy, which trustsclose neighbors more than distant ones.In the single training point setup, the systemis much less accurate.
In this setting, the sys-tem is forced to make decisions for all pairs oftexts independently, including pairs it considersvery dissimilar because it has failed to find anyuseful correspondences.
Performance for thesepairs is close to chance, dragging down overallscores (52% for reverse) even if the system per-forms well on pairs where it finds good correspon-dences, enabling a higher WNN score (67%).The reverse case is significantly harder thanorder.
This is because randomly permuting anovel actually breaks up the temporal continuityof the text?for instance, a minor character whoappeared in three adjacent chapters might now ap-pear in three separate places.
Reversing the textdoes not cause this kind of disruption, so correctlydetecting a reversal requires the system to repre-sent patterns with a distinct temporal orientation,for instance an intensification in the main char-acter?s emotions, or in the number of paragraphsfocusing on pairwise relationships, toward the endof the text.The baseline system is ineffective at detectingeither ordering or reversals4.
The first-order ker-nel k1 is as good as k2 in detecting character per-mutations, but less effective on reorderings andreversals.
As we will show in section 9, k1 placesmore emphasis on correspondences between mi-nor characters and between places, while k2 ismore sensitive to protagonists and their relation-ships, which carry the richest temporal informa-4The baseline detects reversals as well as the plot kernelsgiven only a single point of comparison, but these results donot transfer to the WNN strategy.
This suggests that unlikethe plot kernels, the baseline is no more accurate for docu-ments it considers similar than for those it judges are distant.tion.7 Significance testingIn addition to using our kernel as a classifier, wecan directly test its ability to distinguish real fromaltered novels via a non-parametric two-samplesignificance test, the Maximum Mean Discrep-ancy (MMD) test (Gretton et al 2007).
Givensamples from a pair of distributions p and q anda kernel k, this test determines whether the nullhypothesis that p and q are identically distributedin the kernel?s feature space can be rejected.
Theadvantage of this test is that, since it takes allpairwise comparisons (except self-comparisons)within and across the classes into account, it usesmore information than our classification experi-ments, and can therefore be more sensitive.As in Gretton et al(2007), we find an unbiasedestimate of the test statistic MMD2 for samplesets x ?
p, y ?
q, each with m samples, by pair-ing the two as z = (xi, yi) and computing:MMD2(x, y) =1(m)(m?
1)m?i 6=jh(zi, zj)h(zi, zj) = k(xi, xj)+k(yi, yj)?k(xi, yj)?k(xj , yi)Intuitively, MMD2 approaches 0 if the ker-nel cannot distinguish x from y and is positiveotherwise.
The null distribution is computed bythe bootstrap method; we create null-distributedsamples by randomly swapping xi and yi in ele-ments of z and computing the test statistic.
Weuse 10000 test permutations.
Using both k1 andk2, we can reject the null hypothesis that the dis-tribution of novels is equal to order or characterswith p < .001; for reversals, we cannot reject thenull hypothesis.8 Out-of-domain dataIn our main experiments, we tested our kernelonly on romances; here we investigate its abilityto generalize across genres.
We take as our train-ing set X the same romances as above, but as ourtest set Y a disjoint set of novels focusing mainlyon crime, children and the supernatural.Our results (Table 3) are not appreciably differ-ent from those of the in-domain experiments (Ta-ble 2) considering the small size of the dataset.This shows our system to be robust, but shallow;639order character reversesentiment only 33.0 - 53.4single doc k1 59.5 61.7 52.7single doc k2 63.7 62.0 57.3WNN sentiment 20 - 70WNN k1 80 90 80WNN k2 100 80 70Table 3: Accuracy of kernels ranking 10 non-romancenovels against artificial surrogates, with 41 romancesused for comparison.the patterns it can represent generalize acceptablyacross domains, but this suggests it is describingbroad concepts like ?main character?
rather thangenre-specific ones like ?female romantic lead?.9 Character-level analysisTo gain some insight into exactly what kinds ofsimilarities the system picks up on when compar-ing two works, we sorted the characters detectedby our system into categories and measured theircontribution to the kernel?s overall scores.
Weselected four Jane Austen works from the devel-opment set5 and hand-categorized each characterdetected by our system.
(We performed the cate-gorization based on the most common full namemention in each cluster.
This name is usually agood identifier for all the mentions in the cluster,but if our coreference system has made an error, itmay not be.
)Our categorization for characters is intended tocapture the stereotypical plot dynamics of liter-ary romance, sorting the characters according totheir gender and a simple notion of their plot func-tion.
The genders are female, male, plural (?theCrawfords?)
or not a character (?London?).
Thefunctional classes are protagonist (used for thefemale viewpoint character and her eventual hus-band), marriageable (single men and womenwho are seeking to marry within the story) andother (older characters, children, and charactersmarried before the story begins).We evaluate the pairwise kernel similaritiesamong our four works, and add up the propor-tional contribution made by character pairs ofeach type to the eventual score.
(For instance,the similarity between ?Elizabeth Bennet?
and5Pride and Prejudice, Emma, Mansfield Park and Per-suasion.
?Emma Woodhouse?, both labeled ?female pro-tagonist?, contributes 26% of the kernel similaritybetween the works in which they appear.)
We plotthese as Hinton-style diagrams in Figure 2.
Thesize of each black rectangle indicates the magni-tude of the contribution.
(Since kernel functionsare symmetric, we show only the lower diagonal.
)Under the kernel for unigram features, d(top), the most common character types?non-characters (almost always places) and non-marriageable women?contribute most to the ker-nel scores; this is especially true for places, sincethey often occur with similar descriptive terms.The diagram also shows the effect of the kernel?spenalty for gender mismatches, since females pairmore strongly with females and males with males.Character roles have relatively little impact.The first-order kernel c1 (middle), which takesinto account frequency and emotion as well as un-igrams, is much better than d at distinguishingplaces from real characters, and assigns somewhatmore weight to protagonists.Finally, c2 (bottom), which takes into accountsecond-order relationships, places much moreemphasis on female protagonists and much lesson places.
This is presumably because the femaleprotagonists of Jane Austen?s novels are the view-point characters, and the novels focus on their re-lationships, while characters do not tend to havestrong relationships with places.
An increasedtendency to match male marriageable characterswith marriageable females, and ?other?
maleswith ?other?
females, suggests that c2 relies moreon character function and less on unigrams thanc1 when finding correspondences between char-acters.As we concluded in the previous section, thefrequent confusion between categories suggeststhat the analogies we construct are relatively non-specific.
We might hope to create role-based sum-mary of novels by finding their nearest neighborsand then propagating the character categories (forexample, ?
is the protagonist of this novel.
Shelives at .
She eventually marries , her othersuitors are and her older guardian is .?
)but the present system is probably not adequatefor the purpose.
We expect that detecting a fine-grained set of emotions will help to separate char-acter functions more clearly.640F ProtM ProtF Marr.M Marr.Pl Marr.F OtherM OtherPl OtherNon-char Character frequency by categoryTypesTokensF Prot M Prot F Marr.M Marr.Pl Marr.F OtherM OtherPl OtherNon-char Unigram features (d)Non-char Pl OtherM OtherF OtherPl Marr.M Marr.F Marr.M ProtF ProtF Prot M Prot F Marr.M Marr.Pl Marr.F OtherM OtherPl OtherNon-char First-order (c1)Non-char Pl OtherM OtherF OtherPl Marr.M Marr.F Marr.M ProtF ProtF Prot M Prot F Marr.M Marr.Pl Marr.F OtherM OtherPl OtherNon-char Second-order (c2)Non-char Pl OtherM OtherF OtherPl Marr.M Marr.F Marr.M ProtF ProtFigure 2: Affinity diagrams showing character typescontributing to the kernel similarity between fourworks by Jane Austen.10 ConclusionsThis work presents a method for describing nov-elistic plots at an abstract level.
It has three maincontributions: the description of a plot in termsof analogies between characters, the use of emo-tional and frequency trajectories for individualcharacters rather than whole works, and evalua-tion using artificially disordered surrogate novels.In future work, we hope to sharpen the analogieswe construct so that they are useful for summa-rization, perhaps by finding an external standardby which we can make the notion of ?analogous?characters precise.
We would also like to investi-gate what gains are possible with a finer-grainedemotional vocabulary.AcknowledgementsThanks to Sharon Goldwater, Mirella Lapata, Vic-toria Adams and the ProbModels group for theircomments on preliminary versions of this work,Kira Moura?o for suggesting graph kernels, andthree reviewers for their comments.ReferencesAmjad Abu Jbara and Dragomir Radev.
2011.
Coher-ent citation-based summarization of scientific pa-pers.
In Proceedings of ACL 2011, Portland, Ore-gon.Cecilia Ovesdotter Alm and Richard Sproat.
2005.Emotional sequencing and development in fairytales.
In ACII, pages 668?674.Cecilia Ovesdotter Alm, Dan Roth, and RichardSproat.
2005.
Emotions from text: Machine learn-ing for text-based emotion prediction.
In Proceed-ings of Human Language Technology Conferenceand Conference on Empirical Methods in NaturalLanguage Processing, pages 579?586, Vancouver,British Columbia, Canada, October.
Association forComputational Linguistics.Regina Barzilay and Mirella Lapata.
2005.
Model-ing local coherence: an entity-based approach.
InProceedings of the 43rd Annual Meeting of the As-sociation for Computational Linguistics (ACL?05).Indrajit Bhattacharya and Lise Getoor.
2005.
Rela-tional clustering for multi-type entity resolution.
InProceedings of the 4th international workshop onMulti-relational mining, MRDM ?05, pages 3?12,New York, NY, USA.
ACM.Nathanael Chambers and Dan Jurafsky.
2009.
Un-supervised learning of narrative schemas and theirparticipants.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL and the6414th International Joint Conference on Natural Lan-guage Processing of the AFNLP, pages 602?610,Suntec, Singapore, August.
Association for Com-putational Linguistics.Eugene Charniak.
2001.
Unsupervised learning ofname structure from coreference data.
In SecondMeeting of the North American Chapter of the Asso-ciation for Computational Linguistics (NACL-01).Harr Chen, S.R.K.
Branavan, Regina Barzilay, andDavid R. Karger.
2009.
Global models of docu-ment structure using latent permutations.
In Pro-ceedings of Human Language Technologies: The2009 Annual Conference of the North AmericanChapter of the Association for Computational Lin-guistics, pages 371?379, Boulder, Colorado, June.Association for Computational Linguistics.Mark Dredze, Paul McNamee, Delip Rao, Adam Ger-ber, and Tim Finin.
2010.
Entity disambigua-tion for knowledge base population.
In Proceed-ings of the 23rd International Conference on Com-putational Linguistics (Coling 2010), pages 277?285, Beijing, China, August.
Coling 2010 Organiz-ing Committee.David K. Elson and Kathleen R. McKeown.
2010.Building a bank of semantically encoded narratives.In Nicoletta Calzolari (Conference Chair), KhalidChoukri, Bente Maegaard, Joseph Mariani, JanOdijk, Stelios Piperidis, Mike Rosner, and DanielTapias, editors, Proceedings of the Seventh con-ference on International Language Resources andEvaluation (LREC?10), Valletta, Malta, May.
Euro-pean Language Resources Association (ELRA).David Elson, Nicholas Dames, and Kathleen McKe-own.
2010.
Extracting social networks from liter-ary fiction.
In Proceedings of the 48th Annual Meet-ing of the Association for Computational Linguis-tics, pages 138?147, Uppsala, Sweden, July.
Asso-ciation for Computational Linguistics.Amit Goyal, Ellen Riloff, and Hal Daume III.
2010.Automatically producing plot unit representationsfor narrative text.
In Proceedings of the 2010 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 77?86, Cambridge, MA, Octo-ber.
Association for Computational Linguistics.Arthur Gretton, Karsten M. Borgwardt, Malte Rasch,Bernhard Schlkopf, and Alexander J. Smola.
2007.A kernel method for the two-sample-problem.
InB.
Scho?lkopf, J. Platt, and T. Hoffman, editors, Ad-vances in Neural Information Processing Systems19, pages 513?520.
MIT Press, Cambridge, MA.David Haussler.
1999.
Convolution kernels on dis-crete structures.
Technical Report UCSC-CRL-99-10, Computer Science Department, UC Santa Cruz.Nikiforos Karamanis, Massimo Poesio, Chris Mellish,and Jon Oberlander.
2004.
Evaluating centering-based metrics of coherence.
In ACL, pages 391?398.Anna Kazantseva and Stan Szpakowicz.
2010.
Sum-marizing short stories.
Computational Linguistics,pages 71?109.Dekang Lin and Patrick Pantel.
2001.
Induction ofsemantic classes from natural language text.
InProceedings of the seventh ACM SIGKDD interna-tional conference on Knowledge discovery and datamining, KDD ?01, pages 317?322, New York, NY,USA.
ACM.David McClosky, Eugene Charniak, and Mark John-son.
2006.
Effective self-training for parsing.
InProceedings of the Human Language TechnologyConference of the NAACL, Main Conference, pages152?159.Neil McIntyre and Mirella Lapata.
2010.
Plot induc-tion and evolutionary search for story generation.In Proceedings of the 48th Annual Meeting of theAssociation for Computational Linguistics, pages1562?1572, Uppsala, Sweden, July.
Association forComputational Linguistics.G.
Miller, A.R.
Beckwith, C. Fellbaum, D. Gross, andK.
Miller.
1990.
Introduction to WordNet: an on-line lexical database.
International Journal of Lexi-cography, 3(4).Saif Mohammad.
2011.
From once upon a timeto happily ever after: Tracking emotions in novelsand fairy tales.
In Proceedings of the 5th ACL-HLT Workshop on Language Technology for Cul-tural Heritage, Social Sciences, and Humanities,pages 105?114, Portland, OR, USA, June.
Associa-tion for Computational Linguistics.Matt Post.
2011.
Judging grammaticality with treesubstitution grammar derivations.
In Proceedingsof the 49th Annual Meeting of the Associationfor Computational Linguistics: Human LanguageTechnologies, pages 217?222, Portland, Oregon,USA, June.
Association for Computational Linguis-tics.Jeffrey C. Reynar and Adwait Ratnaparkhi.
1997.A maximum entropy approach to identifying sen-tence boundaries.
In Proceedings of the Fifth Con-ference on Applied Natural Language Processing,pages 16?19, Washington D.C.Ekaterina P. Volkova, Betty Mohler, Detmar Meur-ers, Dale Gerdemann, and Heinrich H. Bu?lthoff.2010.
Emotional perception of fairy tales: Achiev-ing agreement in emotion annotation of text.
InProceedings of the NAACL HLT 2010 Workshop onComputational Approaches to Analysis and Gener-ation of Emotion in Text, pages 98?106, Los Ange-les, CA, June.
Association for Computational Lin-guistics.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-level sentiment analysis.
In Proceedings of Hu-man Language Technology Conference and Confer-ence on Empirical Methods in Natural Language642Processing, pages 347?354, Vancouver, BritishColumbia, Canada, October.
Association for Com-putational Linguistics.643A List of textsDev set (11 works)Austen Emma, Mansfield Park, NorthangerAbbey, Persuasion, Pride and Prej-udice, Sense and SensibilityBronte?, Emily Wuthering HeightsBurney Cecilia (1782) Hardy Tess of the D?UrbervillesJames The Ambassadors Scott IvanhoeTest set (30 works)Braddon Aurora Floyd Bronte?, Anne The Tenant of Wildfell HallBronte?, Charlotte Jane Eyre, Villette Bulwer-Lytton ZanoniDisraeli Coningsby, Tancred Edgeworth The Absentee, Belinda, HelenEliot Adam Bede, Daniel Deronda, Mid-dlemarchGaskell Mary Barton, North and SouthGissing In the Year of Jubilee, New GrubStreetHardy Far From the Madding Crowd, Judethe Obscure, Return of the Native,Under the Greenwood TreeJames The Wings of the Dove Meredith The Egoist, The Ordeal of RichardFeverelScott The Bride of Lammermoor Thackeray History of Henry Esmond, Historyof Pendennis, Vanity FairTrollope Doctor ThorneOut-of-domain set (10 works)Ainsworth The Lancashire Witches Bulwer-Lytton Paul CliffordDickens Oliver Twist, The Pickwick Papers Collins The MoonstoneConan-Doyle A Study in Scarlet, The Sign of theFourHughes Tom Brown?s SchooldaysStevenson Treasure Island Stoker DraculaTable 4: 19th century novels used in our study.644
