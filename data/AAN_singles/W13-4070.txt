Proceedings of the SIGDIAL 2013 Conference, pages 452?456,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsComparison of Bayesian Discriminative and Generative Models forDialogue State TrackingLuka?s?
Z?ilka, David Marek, Mate?j Korvas, Filip Jurc??
?c?ekCharles University in PragueFaculty of Mathematics and PhysicsMalostranske?
na?me?st??
25118 00 Praha, Czech Republiclukas@zilka.me, david@marek.me,korvas@ufal.mff.cuni.cz, jurcicek@ufal.mff.cuni.czAbstractIn this paper, we describe two dialoguestate tracking models competing in the2012 Dialogue State Tracking Challenge(DSTC).
First, we detail a novel discrim-inative dialogue state tracker which di-rectly estimates slot-level beliefs using de-terministic state transition probability dis-tribution.
Second, we present a gener-ative model employing a simple depen-dency structure to achieve fast inference.The models are evaluated on the DSTCdata, and both significantly outperform thebaseline DSTC tracker.1 IntroductionThe core component of virtually any dialogue sys-tem is a dialogue state tracker.
Its purpose is tomonitor dialogue progress and provide compactrepresentation of the past user input and systemoutput in the form of a dialogue state.
In previ-ous works on this topics, Williams (2007) usedparticle filters to perform inference in a complexBayesian network modelling the dialogue state,Williams (2008) presented a generative trackerand showed how to train an observation modelfrom transcribed data, Young et al(2010) groupedindistinguishable dialogue states into partitionsand consequently performed dialogue state track-ing on these partitions instead of the individualstates, Thomson and Young (2010) used a dy-namic Bayesian network to represent the dialoguemodel in an approximate form, and Mehta et al(2010) used probabilistic ontology trees.In this paper, we describe two probabilistic di-alogue state trackers: (1) a discriminative dia-logue state tracker (DT) ?
a model using a sim-ple deterministic state transition probability, re-sulting in significant computational savings, and(2), a generative dialogue state tracker (GT) ?
amodel using simple conditional dependency struc-ture with tied and handcrafted model parameters.Both trackers were evaluated in the DSTC.
Theaim of the DSTC was to provide a common testbedfor different dialogue state tracking methods andto evaluate these methods in a unified way.
Be-cause of limited space, the interested reader is re-ferred to Williams et al(2013) for informationabout the data and evaluation metrics used in thechallenge.This paper is structured as follows.
The de-terministic and generative trackers are detailed inSection 2 and the presented models are evaluatedon the DSTC data in Section 3.
Section 4 discussesthe obtained results, and Section 5 concludes thepaper.2 Bayesian Dialogue State TrackingThe goal of dialogue state tracking is to moni-tor progress in the dialogue and provide a com-pact representation of the dialogue history in theform of a dialogue state.
Because of the uncer-tainty in the user input, statistical dialogue sys-tems maintain a probability distribution over all di-alogue states called the belief state and every turn,as the dialogue progresses, updates this distribu-tion in the light of the new observations in a pro-cess called belief monitoring.Since the true observations are hidden, thebelief state depends on the past and currentobservation probabilities, p(o1), .
.
.
, p(ot), andsystem actions, a0, .
.
.
, at?1, which are re-ferred to as the observed history: ht ={a0, p(o1), .
.
.
, at?1, p(ot)}.
If the system isMarkovian, the belief state bt depends only on theprevious belief state bt?1, the observation distribu-tion p(ot), and the last system action at?1.
Thereare two ways to derive the belief state update usingthe Bayes theorem, resulting either in discrimina-tive or generative probabilistic models.The discriminative update can be represented as452follows:bt = b(st|ht)=?st?1,otp(st|at?1, st?1,ot)b(st?1|ht?1)p(ot) (1)where the probability p(st|at?1, st?1,ot) repre-sents the discriminative dialogue model.
By fur-ther factorisation of (1), we can derive the genera-tive update formula:bt ?
?st?1,otp(st|at?1, st?1)p(ot|st)??
b(st?1|ht?1)p(ot) (2)where the transition probability p(st|at?1, st?1)and the observation probability p(ot|st) representthe generative dialogue model.In our approach, we define the dialogue stateas a vector s = [s1, .
.
.
, sN ] where si are val-ues for slots in the dialogue domain, e.g.
to.descor from.monument.
The observations are factoredsimilarly to o = [o1, .
.
.
, oN ], where oi are indi-vidual slot-level observations, e. g. inform(to.desc= downtown)?
oto.desc = downtown.
The prob-ability of the slot-level observations p(oi) can beeasily obtained by marginalising the observationprobability p(o).
Because of limited space, onlythe processing of the inform dialogue acts is de-scribed in detail.In the next two sections, we present the discrim-inative and generative models of belief update em-ployed in the DSTC challenge by using the factori-sation of the full belief state into independent fac-tors to obtain computationally efficient updates.2.1 Discriminative Belief UpdateIn this work, the belief state bt is defined as aproduct of marginal probabilities of the individualslots, b(st) = ?i b(sit), where sit is the i-th slot atthe turn t and the slot belief b(sit) is a probabilitydistribution over all values for the slot i.
To keepthe notation uncluttered, the slot index, i, will beomitted in the following text.
To further simplifythe belief updates, similarly to the full belief mon-itoring represented by (1), the slot belief dependsonly on the previous slot belief bt?1, the observa-tion distribution p(ot), and the last system actionat?1.
This results in update rules for individualslots s as follows:b(st) =?st?1,otp(st|at?1, st?1, ot)b(st?1)p(ot) (3)where the conditional probability distributionp(st|at?1, st?1, ot) represents the slot-level dia-logue model.There are two aspects which have to be takeninto account when we consider the presented be-lief update: (1) the computational complexity and(2) the parameters of the dialogue model.
First,the complexity of the belief update is given by thenumber of slot values and observations becausethe sum must be evaluated for all their combina-tions.
This suggests that even this update may becomputationally too expensive for slots where ob-servations have a large number of values.
Second,the slot-level dialogue model describes probabilis-tically how the value of a slot changes accordingto the context and the observations.
Parametersof this conditional distribution would ideally beestimated from annotated data.
Because of datasparsity, however, such estimates tend to be ratherpoor and either they must be smoothed or the pa-rameters must be tied.
To overcome this problem,we decided to set the parameters manually on thebasis of two simple assumptions leading to verycomputationally efficient updates.
First, we as-sume that our dialogue model should completelytrust what the user says.
Second, we assume thatthe user goal does not change when the user issilent.
For example, if the user says: ?I want togo downtown?, oto.desct = downtown, then thestate should be sto.desct = downtown; and whenthe user says nothing in the next turn, oto.desct+1 =(where the symbol  is a special slot value repre-senting that the user was silent), the state remainssto.desct+1 = downtown.
This is captured by the fol-lowing definition of the slot-level dialogue model:p(st|at?1, st?1, ot) =??
?1 (st = ot ?
ot 6= )?
(st = st?1 ?
ot = )0 otherwise(4)When (4) is substituted into (3), the belief up-date greatly simplifies and appears into the follow-ing form:b(st) =????
?st =  : p(st?1 = )p(ot = )st 6=  : p(ot = st)+ p(ot = )p(st?1 = st)(5)Note that this model effectively accumulatesprobability from multiple hypotheses and frommultiple turns.
For example, its ability to ?remem-ber?
the belief from the previous turn is propor-tional to the probability mass assigned to the SLU453hypothesis that the user was silent about the slot inquestion.
In the special case when the user is silentwith probability 1.0, the current belief is equal tothe previous belief.This belief update is very computationally effi-cient.
First, instead of summing over all combi-nations of the slot and observation values (3), thebelief can be computed by means of a simple for-mula (5).
Second, if the user does not mention aparticular slot value during the dialogue, this valuewill always have a probability of zero.
Therefore,only the probability for values suggested by theSLU component has to be maintained.2.2 Generative model for belief updateSimilarly to the discriminative belief update, thegenerative model relies on factorisation of the fullbelief state into a product of marginal slot be-liefs and a simple dependency structure where aslot belief depends only on the previous slot be-lief, the slot observation distribution p(oit), andthe last system action at?1.
The dialogue modelp(st|at?1, st?1, ot) is further factored, however,into the transition model p(st|at?1, st?1) and theobservation model p(ot|st) as given in (2).The transition model describes the probabilitythat the user will change his/her goal, given theprevious goal and the last system action.
For ex-ample, if the system asks the user about a specificslot, then it is reasonable to have a larger prob-ability of this slot changing its value.
As notedfor the discriminative model, estimation of the di-alogue model parameters requires a large amountof data, which was not available in the challenge.Therefore, we used parameter tying as describedby Thomson and Young (2010), and set the tiedparameters manually:p(st|at?1, st?1) ={?t if st = st?11?
?t|values|?1 otherwise (6)where ?t describes the probability of a slot valuestaying the same and |values| denotes the numberof values for the slot.
In other words, the probabil-ity ?t sets a tradeoff between the system?s abilityto remember everything that was said in the pastand accepting new information from the user.
If ?tis too high, the system will put a strong emphasison the previous states and will largely ignore whatthe user is saying.
When testing different values of?t on heldout data, we observed that if they are se-lected reasonably, the overall performance of thesystem does not change much.
Therefore, the ?tvalue was fixed at 0.8 for all slots and all datasets.The observation model p(ot|st) describes thedependency between the observed values and theslot values.
Similarly to the transition model, pa-rameters of the observation probability distribu-tion were tied and set manually:p(ot|st) ={?o if ot = st1?
?o|values|?1 otherwise.
(7)where ?o defines the probability of the agreementbetween the observation and the slot value.
Theprobability of agreement describes how the modelis robust to noise and systematic errors in SLU.When ?o is set high, the model assumes that theSLU component makes perfect predictions, andtherefore the SLU output must agree with the slotvalues.
Based on manual tuning on held-out data,?o was set to 0.8.Inference in the presented model is performedwith Loopy Belief Propagation (LBP) (Pearl,1988).
LBP is an approximate message passinginference algorithm for Bayesian networks (BN).LBP can be computationally intensive if there arenodes with many parents in the network.
There-fore, as previously described, our model uses asimple dependency structure where slots dependonly on the same slot from the previous turn, andslot-level observations depend on the correspond-ing slot from the same turn.
To make the inferenceeven more efficient, one can take advantage of thetied observation and transition probabilities.
Wegroup all unobserved values in the nodes of BNtogether and maintain only a probability for thegroup as a whole, as suggested by Thomson andYoung (2010).3 EvaluationThe discriminative (DT) and generative dialogue(GT) trackers described in Sections 2.1 and 2.2were evaluated on the DSTC data.The input of DT and GT were the SLU n-bestlists either with original probabilities or the scoresmapped into the probability space.
The track-ers were evaluated on both live and batch data.The metrics were computed with Schedule 1 (seeWilliams et al(2013)).
In addition, we includeinto the evaluation the DSTC baseline tracker.
Theresults on the live and batch data are shown in Ta-ble 1 in the Appendix.
Please note that the resultsfor GT differ from the results submitted for DSTC.Only after the submission deadline, did we find454that some of the parameters in the transition modelwere set incorrectly.
After the setting was fixed,the results improved.The results show that the DT consistently out-performs the baseline tracker and the DT achievescomparable or better results than the GT.
The DTclearly provides better estimates of the dialoguestates because of the incorporation of the contextand the processing of multiple hypotheses.
Toassess the statistical significance of the accuracymetric, 95% confidence scores for all measure-ments were computed.
Overall, the confidence in-tervals were between 0.1% and 0.4% on the indi-vidual tests.
On this basis, all differences largerthan 1.0% can be considered statistically signifi-cant.The GT outperforms the baseline tracker on allbut the batch data.
Manual inspection of the re-sults revealed that the generative model is verysensitive to the probabilities assigned to the obser-vations.
For the batch data, presumably due to thescore normalisation, the probabilities of hypothe-ses in the n-best lists were very similar to eachother.
As a result, the generative model had dif-ficulties discriminating between the observed val-ues.In comparison with all trackers submitted forDSTC, the DT achieves second-best accuracyamong the submitted trackers and the GT is amongthe average trackers.
For more details see Table 2in the Appendix, where the average scores werecomputed from the accuracy and the Brier scoreon test sets 1, 2, 3, and 4.Regarding the Brier score, the results show thatthe DT outperforms the baseline tracker and esti-mates the belief state as well as the best trackerin the DSTC.
This can prove especially importantwhen the tracker is used within a complete dia-logue system where the policy decisions do notdepend on the best dialogue state but on the beliefstate.4 DiscussionThe presented discriminative and generative mod-els differ in two main areas: (1) how they incorpo-rate observations into the belief state and (2) com-putational efficiency.
(1) Both the DT and GT models can accumulateinformation from multiple hypotheses and frommultiple turns.
The GT, however, tends to ?forget?the dialogue history because the generative modelindiscriminately distributes some of the probabil-ity mass from a slot value that was not recentlymentioned to all other slot values each turn.
Thisbehaviour (see Table 3 for an example) is not easyto control because ?forgetting?
is a consequenceof the model being able to represent the dynamicsof a user changing his/her goal.
The DT does nothave this problem because the change in the goalis directly conditioned on the observations.
If theuser is silent, then the DT ?copies?
the past beliefstate and no probability in the belief state is dis-tributed as described in (5).
(2) The DT tracker is significantly faster com-pared with the GT tracker while offering compa-rable or better performance.
The slot level beliefupdate in the discriminative model has a complex-ity of O(n) whereas in the generative model it hasa complexity of O(n2), where n is the number ofvalues in the slot.
When tested on a regular per-sonal computer, the DT processed all four DSTCtest sets, 4254 dialogues in total, in 2.5 minuteswhereas the GT tracker needed 51 minutes.
There-fore, the DT tracker is about 20 times more com-putationally efficient on the DSTC data.
AlthoughGT achieved performance allowing real-time use(it needed 0.1 seconds per turn) in the Let?s Go do-main, for more complex applications the GT couldsimply be too slow.
In this case, the proposed dis-criminative tracker offers a very interesting alter-native.5 ConclusionThis paper described two dialogue state trackingmodels submitted for the DSTC challenge: (1)the discriminative tracker and (2) the generativetracker.
The discriminative tracker is based ona conceptually very simple dialogue model withdeterministic transition probability.
Interestingly,this discriminative model gives performance com-parable to the more complex generative tracker;yet it is significantly more computationally effi-cient.
An extended description of this work can befound in the technical report (Z?ilka et al 2013).AcknowledgementsThis research was partly funded by the Ministry ofEducation, Youth and Sports of the Czech Repub-lic under the grant agreement LK11221 and coreresearch funding of Charles University in Prague.The authors would like to thank Ondr?ej Dus?ek andOndr?ej Pla?tek for useful comments.455A Comparison of the BT, DT, and GTtrackerslive data metric BT DT GTtest1 accuracy 0.77 0.88 0.88Brier score 0.29 0.21 0.21test2 accuracy 0.79 0.89 0.85Brier score 0.27 0.20 0.23test3 accuracy 0.92 0.94 0.93Brier score 0.14 0.11 0.16test4 accuracy 0.82 0.86 0.87Brier score 0.24 0.21 0.20ALL accuracy 0.83 0.89 0.88Brier score 0.24 0.18 0.20batch data metric BT DT GTtest1 accuracy 0.75 0.88 0.74Brier score 0.35 0.27 0.39test2 accuracy 0.79 0.88 0.77Brier score 0.30 0.26 0.33ALL accuracy 0.77 0.88 0.76Brier score 0.32 0.27 0.36Table 1: Accuracy of the trackers on the live andbatch test sets, where BT stands for the DSTCbaseline tracker, DT denotes the discriminativetracker, and GT denotes the generative tracker.ALL denotes the average scores over the live andbatch test sets.B Comparison with the DSTC trackersteam/system accuracy Brier scoreBT - C 0.81 0.27BT 0.83 0.24DT 0.89 0.18GT 0.88 0.20team1 0.88 0.23team2 0.88 0.21team4 0.81 0.28team5 0.88 0.21team6 0.91 0.18team7 0.85 0.23team8 0.83 0.24team9 0.89 0.20Table 2: Accuracy of the trackers submitted forthe DSTC, where BT - C denotes the DSTC base-line tracker without removing the systematicallyerroneous SLU hypotheses, BT denotes the DSTCbaseline tracker, DT denotes the discriminativetracker, GT denotes the generative tracker, andteam* denote the best trackers submitted by otherteams.
The scores are averaged scores obtained onthe four DSTC test sets.C The problem of ?forgetting?
of theobserved values in the GT tracker# P SLU hyp.
slot value GS DS1 1.0 centre centre 0.8 1.00.0 null null 0.2 0.02 1.0 null centre 0.68 1.0null 0.32 0.03 1.0 null centre 0.608 1.0null 0.392 0.0Table 3: Example of three turns in which the gen-erative system ?forgets?
the observed value.
# de-notes the turn number, P denotes the probabilityof the observation, SLU hyp.
denotes the observedhypothesis, GS denotes the belief of the generativesystem, and DS denotes the belief of the discrimi-native system.ReferencesNeville Mehta, Rakesh Gupta, Antoine Raux, DeepakRamachandran, and Stefan Krawczyk.
2010.
Prob-abilistic ontology trees for belief tracking in dialogsystems.
In Proceedings of SigDial, pages 37?46.Association for Computational Linguistics.Judea Pearl.
1988.
Probabilistic reasoning in intelli-gent systems: networks of plausible inference.
Mor-gan Kaufmann Publishers Inc., San Francisco, CA,USA.Blaise Thomson and Steve Young.
2010.
Bayesianupdate of dialogue state: A POMDP framework forspoken dialogue systems.
Computer Speech andLanguage, 24(4):562?588.Jason D. Williams, Antoine Raux, Deepak Ramachan-dran, and Alan W. Black.
2013.
The Dialog StateTracking Challenge.
In Proceedings of SigDial,Metz, France.Jason D. Williams.
2007.
Using particle filters totrack dialogue state.
In IEEE Workshop on Auto-matic Speech Recognition & Understanding, 2007.ASRU, pages 502?507.
IEEE.Jason D. Williams.
2008.
Exploiting the ASR N-bestby tracking multiple dialog state hypotheses.
ProcICSLP, Brisbane.Steve Young, Milica Gas?ic?, Simon Keizer, FrancoisMairesse, Jost Schatzmann, Blaise Thomson, andKai Yu.
2010.
The Hidden Information StateModel: a practical framework for POMDP-basedspoken dialogue management.
Computer Speechand Language, 24(2):150?174.Luka?s?
Z?ilka, David Marek, Mate?j Korvas, and FilipJurc???c?ek.
2013.
Bayesian Discriminative and Gen-erative Models used in the 2012 Dialogue StateTracking Challenge.
Technical report, Faculty ofMathematics and Physics, Charles University inPrague, July.456
