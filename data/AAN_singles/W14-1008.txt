Proceedings of the 3rd Workshop on Hybrid Approaches to Translation (HyTra) @ EACL 2014, pages 42?47,Gothenburg, Sweden, April 27, 2014.c?2014 Association for Computational LinguisticsResumptive Pronoun Detectionfor Modern Standard Arabic to English MTStephen Tratz?Clare Voss?Jamal Laoudi?
?Army Research Laboratory, Adelphi, MD 20783?Advanced Resource Technologies, Inc. Alexandria, VA 22314{stephen.c.tratz.civ,clare.r.voss.civ,jamal.laoudi.ctr}@mail.milAbstractMany languages, including Modern Stan-dard Arabic (MSA), insert resumptive pro-nouns in relative clauses, whereas manyothers, such as English, do not, usingempty categories instead.
This discrep-ancy is a source of difficulty when trans-lating between these languages becausethere are words in one language that cor-respond to empty categories in the other,and these words must either be insertedor deleted?depending on translation di-rection.
In this paper, we first examinechallenges presented by resumptive pro-nouns in MSA-English translations and re-view resumptive pronoun translations gen-erated by a popular online MSA-EnglishMT engine.
We then present what is, tothe best of our knowledge, the first systemfor automatic identification of resumptivepronouns.
The system achieves 91.9 F1and 77.8 F1 on Arabic Treebank data whenusing gold standard parses and automaticparses, respectively.1 IntroductionOne of the challenges for modern machine trans-lation (MT) is the need to systematically insertor delete information that is overtly expressedin only one of the languages in order to main-tain intelligibility and/or fluency.
For example,word alignment between pro-drop and non-pro-drop languages can be negatively impacted by thesystematic dropping of pronouns in only one of thelanguages (Xiang et al., 2013).
A similar type oflinguistic phenomenon of great interest to linguiststhat has not yet received significant attention inMT research is the mismatch between languagesin their usage of resumptive pronouns.
Some lan-guages, such as Modern Standard Arabic (MSA),require the insertion of resumptive pronouns inmany relative clauses, whereas other languages,including English, rarely permit them.
An exam-ple of an MSA sentence is given below, with itsEnglish gloss showing the resumptive pronoun inbold, its reference translation (RT), and an MTsystem output where the roles of patient and doc-tor are incorrectly reversed:?J.fiJ.??
@ ?KY?K@ ?Y?@?flQ??
@IK@PGloss: I.saw the.patient who rescued.him the.doctor.RT: I saw the patient whom the doctor rescued.MT: I saw a patient who rescued the doctor.In this paper, we examine translations pro-duced by a popular online translation system forMSA resumptive pronouns occurring in severaldifferent syntactic positions to gain insight intothe types of errors generated by current MT en-gines.
In a test suite of 300 MSA sentences withresumptive pronouns, over 30% of the relativeclauses with resumptive pronouns were translatedinaccurately.
We then present an automatic classi-fier that we built for identifying MSA resumptivepronouns and the results obtained from using it inexperiments with the Arabic Treebank (Maamouriet al., 2004; Maamouri and Bies, 2004).
Thesystem achieves 91.9 F1 and 77.8 F1 on ArabicTreebank data when using gold standard parsesand automatic parses, respectively.
To the bestof our knowledge, this is the first attempt toautomatically identify resumptive pronouns in anylanguage.2 Relevant MSA LinguisticsMSA and English relative clauses differ in struc-ture, with one of the most prominent differencesbeing in regard to resumptive pronouns.
Resump-tive pronouns are required in many MSA rela-tive clauses but are almost never grammatical inEnglish.
In MSA, like English, if the external42Arabic (.
.
.?Q?
@) Gloss (I know...) English RT (I know...) MT Output (I know...)1a @QffiJ?
??
?Jfi.K ???
@?YJ??
@ the+lady whoiismiles a lot the lady whoiismiles a lot the lady who smiles a lot1b @QffiJ?
???Jfi.K?YJ?
lady ?ismiles ia lot a lady whoiismiles a lot a lot lady smiling1c @QffiJ?
???Jfi.K??
whoismiles ia lot whoiismiles a lot a lot of smiles2a ?g.Q?
@ A????
???
@??Q???
@ the+company thatifinanced+itithe+man the company thatithe man financed ithe company that financed the man2b ?g.Q?
@ A??????Q??
company ?ifinanced+itithe+man a company ?ithe man financed ia company funded by the man2c ?g.Q?
@ ????
A?
whatifinanced+itithe+man whatithe man financed iwhat the man-funded3a ????AJ??
@I??
?K ?Y?
@ Y???
@ the+boy whomitalked the+girl with+himithe boy whomithe girl talked with ithe boy who spoke with the girl3b ????AJ??
@I??
?K @Y??
boy ?italked the+girl with+himia boy ?ithe girl talked with ithe girl was born I spoke with him3c?AJ??
@I???K??
??
[with whom]italked the+girl i[with whom]ithe girl talked ifrom speaking with the girl4a ??Qffi?
PA?E @ ?Y?
@ ?g.Q?
@ the+man whoicollapsed house+hisithe man [whose house]iicollapsed a man who collapsed home4b ??Qffi?
PA?E @ Cg.P man ?icollapsed house+hisia man [whose house]iicollapsed a man of his house collapsed4c ??Qffi?
PA?E @??
whoicollapsed house+hisi[whose house]iicollapsed of his house collapsed5 ???J?
??
A?
whatiitilogical whatiiis logical what is logicalTable 1: A list of MSA sentences starting with relative clauses?Q?
@ (translation: I know) along with theirEnglish glosses, English reference translation (RT), and the output of MT system X.
Empty categoriesare indicated with  and empty WH nodes are indicated with ?.
Subscripts indicate coreference.
Toavoid clutter, the glosses do not explicitly indicate person, number, or gender.antecedent plays the role of the subject, no re-sumptive pronoun is inserted1; instead, MSA in-flects the verb to agree with the subject in numberand gender by attaching an affix2.
A second sig-nificant difference between the two languages isthat, in MSA, relative pronouns are required forrelative clauses modifying definite noun phrasesbut are prohibited when modifying indefinite nounphrases; in English, definitiveness neither preventsnor necessitates the inclusion of a relative pro-noun.
A third significant difference is that, for freerelative clauses?that is, relative clauses that arenot attached to an external antecedent?MSA hasa different set of relative pronouns for introducingthe clause3.
A fourth challenge is that MSA has noequivalent word for the English word ?whose?
and,to convey a similar meaning, employs resumptivepronouns as possessive modifiers.
Examples illus-trating these differences are provided in Table 1.For further background on MSA relative clausesand MSA grammar, we refer readers to books byRyding (2005) and Badawi et al.
(2004).1A notable exception to this rule is for equational sen-tences.
MSA lacks an overt copula corresponding to the En-glish word ?is?
and, to convey a similar meaning, resumptivesubject pronouns must be inserted in these contexts.2In standard VSO and VOS constructions, the verbs in-flect as singular regardless of the number of the subject.3These pronouns are also employed to introduce ques-tions.3 DataIn our research, we rely on the conversion of con-stituent into dependency structures and the train-ing/dev/test splits of the Arabic Treebank (ATB)parts 1, 2, & 3 (Maamouri et al., 2004; Maamouriand Bies, 2004) as presented by Tratz (2013).We extract features from labeled dependency trees(rather than constituent trees) generated by Tratz?s(2013) Arabic NLP system, which separates cli-tics, labels parts-of-speech, produces dependencyparses, and identifies and labels affixes.The original ATB dependency conversion doesnot mark pronouns for resumptiveness, so wemodify the conversion process to obtain this infor-mation.
The original ATB constituent trees markthis by labeling WHNP nodes and NP nodes withidentical indices.
If the NP node corresponds to anull subject and the head of the S under the SBARis a verb, we mark the inflectional affix on theverb, which agrees with the subject in gender andnumber, as resumptive.
These inflectional affixesare included as their own category within our anal-yses since their presence precludes the appearanceof another resumptive pronoun within the relativeclause (e.g., as a direct object).The total number of resumptive pronouns and?resumptive?
inflectional affixes in the training,dev, and test sections are presented in Table 2.
In43Training Dev TestPronouns 5775 794 796Inflectional affixes 6161 807 845Table 2: Number of resumptive pronouns and ?re-sumptive?
inflectional affixes by data section.the training data, the four most likely positions4for the resumptive pronouns are:i) direct object of relative clause?s main verb (33.9%)ii) object of a preposition attached to the verb (20.8%)iii) possessive modifier of the subject of the verb (5.4%)iv) subject pronoun in an equational sentence (4.2%).4 Translation Error AnalysisAs an exploratory exercise to gain insight into thetypes of errors generated by current MT engineswhen translating from a language that inserts re-sumptive pronouns (i.e., MSA) to one that doesn?t(i.e., English), we worked with a native Arabicspeaker to produce a list of Arabic sentences thatvary in terms of definitiveness (and existence, aswith free relatives) of the external antecedent, andthe syntactic position of the resumptive pronoun,along with English glosses and reference transla-tions for these sentences.
This set was then pro-cessed using a popular online translation system,which we refer to as system X.
The sentences,their glosses, reference translations, and automatictranslations are presented in Table 1.Although system X did not typically produceEnglish pronouns corresponding to the resumptivepronouns in the source, most of the translationsproved problematic, with many of the issues be-ing related to reordering.
Thus, while system Xappears to be good at not translating resumptivepronouns, its performance on the relative clausesthat contain them has ample room for improve-ment.
Our working hypothesis is that system X?sEnglish language model is effective in discount-ing candidate translations that keep the resumptivepronoun.As a second exploratory exercise, we automat-ically extracted all the resumptive pronoun exam-ples in the training section of the data describedin Section 3 and grouped them based upon the se-quence of dependency arc labels from the resump-tive pronoun up to the head of the relative clause4Examples of these frequent configurations are in Table 1.and the first letter of the POS tag of the interven-ing words (e.g., ?N?
for noun, ?A?
for adjective).For each of the thirty most common configura-tions, we took ten examples (for a total of 300), ranthem through system X?s Arabic-English modeland gave both the translation and the source textto our native Arabic expert.
Our expert examinedwhether 1) the translation engine generated a pro-noun corresponding to the source side resumptivepronoun and 2) whether the translation was correctlocally within the relative clause (whether the pro-noun was retained or not)5.
The results for thesetwo judgments are presented in Table 3.Corresponding Pronoun?Yes NoCorrect?Yes 17 189No 20 74Table 3: Expert judgmentsOur expert concluded that a corresponding En-glish pronoun was produced in only 37 of the300 examples (12.3%).
Seventeen of these werejudged correct, although in many of these cases asignificant portion of the relative clause was trans-lated incorrectly even though a small portion in-cluding the pronoun was translated properly, mak-ing judgment difficult.
Our expert noted that manyof the correct translations involved switching thevoice of the verb in the relative clause from ac-tive to passive voice using a past participle.
Ofthe 189 that had no corresponding pronoun andwere judged correct, 46 (24.3%) involved switch-ing to passive voice.
In general, it appears thatsystem X does a good job at not generating En-glish pronouns corresponding to MSA resumptivepronouns, although it makes numerous mistakeswith the data we presented to it.5 System DescriptionOur MSA resumptive pronoun identification sys-tem processes one sentence at a time and reliesupon the (averaged) structured perceptron algo-rithm (Collins, 2002) to rank the feasible actions.When processing a sentence containing n pro-nouns and affixes, a total of n iterations are per-formed.
During each processing iteration, thesystem considers two actions for every unlabeled5This latter task was challenging, but permitted, as in-tended, lenient judgment of the MT output.44Function Definitions:path(x) ?
returns a list of dependency arcs from x up through the first ?ripcmp?, ?rcmod?, or ?ROOT?
arc (link from affix to thecore word is also treated as an arc)rDescendants(x) ?
returns a list of paths (dependency arc lists) from x to each descendant already marked as resumptivepDescendants(x) ?
returns a list of paths (dependency arc lists) from x to each pronoun / verbal inflectional affix, not following?cc?, ?ripcmp?, or ?rcmod?
arcshasDepArc(x,y) ?
returns a Boolean value indicating if an arc with label y descends from xpathToString(x) ?
concatenates the labels of the arcs in a list to create a stringlast(x) ?
returns the last element in the list xsplit(x, y) ?
splits a string x apart wherever it contains substring y, returning these piecesdeps(x), parent(x) ?
return dependency arc(s) of which x is the {head, child}head(x), child(x) ?
returns the {head, child} of arc xpro(x) ?
if x is an affix, the word attached to it is returned, otherwise x is returnedl(x) ?
return the label/part-of-speech for a dependency arc, affix, or wordT(x), t(x), suffixes(x) ?
return the {type (?affix?
or ?pro?
), written text, suffixes} for xn(x,y) ?
returns the word node that is y words after pro(x)Given: p ?
pronoun or inflectional affixPseudocode:?0:?+T(p), ?1:?+t(p), ?2:?+l(p), ?3:?+l(parent(p)), for(s in split(l(p),?
?))
{ ?4:?+s }if(T(p)=?affix?)
{ for(a in deps(pro(p))) { ?5:?+l(a) }, if(T(p)=?pro?
or not(hasDepArc(pro(p), ?subj?)))
{ ?6?
}for(i in {-3,-2,-1,0,+1,+2,+3,+4}) { ?7:?+i+t(n(pro(p),i)), ?8:?+i+l(n(pro(p),i)), ?9:?+i+l(parent(n(pro(p),i))) }?10:?+pathToString(path(p)), end := last(path(p)), resumptives := rDescendants(child(end))if(l(end) != ?ROOT?)
{if(size(resumptives) > 0) {?11a? }
else {?11b?+(size(pDescendants(child(end))) > 0)}for(s in split(l(head(end)), ?
?))
?12:?+s, for(arc in path(p)) { ?13?+l(arc) }?14:?+t(head(end)), ?15:?+l(head(end)), ?16:?+l(parent(head(end)))?17:?+t(child(end)), ?18:?+l(child(end)), ?19:?+l(parent(child(end)))if(l(child(end)) = ?VB PV?
and size(suffixes(child(end)))=0) { ?20?
}for(suff in suffixes(head(end))) { for(s in split(l(suff), ?
?))
{ ?21:?+suff }} }Figure 1: Pseudocode for feature production.
Statements in bold font produce strings that are used toidentify features.
The feature set consists of all pairwise combinations of these strings.personal pronoun and inflectional verbal affix6within a given sentence, these actions being label-as-?resumptive?
and label-as-?not-resumptive?.The highest scored action is performed and thenewly-labeled pronoun or affix is removed fromfurther processing.The system scores each action by computing thedot product between the feature vector derived forthe pronoun/inflectional affix and the weight vec-tor.
The feature vectors consist entirely of Booleanvalues, each of which indicates the presence or ab-sence of a particular feature.
Each feature is iden-tified by a unique string and these strings are gen-erated using the pseudocode presented in Figure1.
(All pairwise combinations of the strings gen-erated by the pseudocode are included as features.
)For space reasons, we omit a review of the train-ing procedure for the structured perceptron and re-fer the interested reader to work by Goldberg andElhadad (2010).6Occasionally an imperfect verb will have both a writteninflectional prefix and a written inflectional suffix.
For thesecases, the system only considers the prefix as there is no needto make two separate judgments.6 ExperimentsWe trained our system on the training data us-ing the gold standard clitic segmentation, parse,and part-of-speech information and optimized itfor overall F1 (pronouns and inflectional affixescombined) on the development data.
Performancepeaked on training iteration 8, and we applied theresulting model to two treatments of the test data,once using the gold standard annotation and onceusing the Tratz (2013) Arabic NLP system to au-tomatically pre-process the data.6.1 Results and DiscussionThe scores for the development and test sections,both for gold and automatic annotation, are pre-sented in Table 4.The system performs well when given inputwith gold standard clitic segmentation, POS tags,and dependency parses, achieving 91.9 F1 for re-sumptive pronouns on the test set and 95.4 F1 forthe affixes.
Performance however degrades sub-stantially when automatic pre-processing of thesource is input instead.
Some of this drop canbe explained by the use of gold standard markupin training?more weight was likely assigned to45Pronoun Inflectional AffixP R F1 P R F1DevGold 92.5 92.8 92.6 96.7 96.4 96.5Auto 88.0 81.0 84.4 86.1 77.3 81.5TestGold 92.1 91.7 91.9 95.0 95.9 95.4Auto 83.6 72.8 77.8 86.6 76.0 81.0Table 4: Precision, recall, and F1 results for the?is-resumptive?
label on the development and testsets for gold standard clitic separation/POS tag-ging/parsing and automatic preprocessing.parse and POS tag-related features than wouldhave if automatic pre-processing of the source hadbeen used in training.Having examined the classification system er-rors on the development data, we conclude thatthe main source of this drop is due to poor iden-tification and attachment of bare relatives7by theTratz (2013) NLP system.
While the NLP systemachieves 88.5 UAS and 86.1 LAS on the develop-ment section,8its performance on identifying barerelatives is comparatively low, with 70.0 precisionand 60.5 recall.
For the test section, the NLP sys-tem performance on bare relatives is even lower at69.6 precision and 52.7 recall.
This helps to ex-plain why our resumptive pronoun classifier per-forms worse on the test data than on the devel-opment data when using automatic pre-processingbut not when using gold standard markup.7 Related WorkThe computational linguistics research most rele-vant to ours is the work on identifying empty cat-egories for several languages, including English,Chinese, Korean, and Hindi.
Empty categoriesare nodes in a parse tree that do not correspondto any written morpheme; these are used to han-dle several linguistic phenomena, including pro-drop.
Recent research demonstrates that recoveryof empty categories can lead to improved transla-tion quality for some language pairs (Chung andGildea, 2010; Xiang et al., 2013).
For more in-formation on the recovery of empty categories, werefer the interested reader to work by Kukkadapuand Mannem (2013), Cai et al.
(2011), Yang andXue (2010), Gabbard et al.
(2006), Schmid (2006),Dienes and Dubey (2003), and Johnson (2002).7Relative clauses lacking a relative pronoun.
As explainedin Section 2, MSA lacks relative pronouns for relative clausesmodifying indefinite noun phrases.8UAS and LAS stand for unlabeled and labeled attach-ment scores.8 ConclusionIn this paper, we present the challenge of translat-ing MSA relative clauses, which often contain re-sumptive pronouns, into English, which relies on(inferred) empty categories instead.
We examineerrors made by a popular online translation serviceon MSA relative clauses and present an automaticsystem for identifying MSA resumptive pronouns.The online translation service occasionally gen-erates English pronouns corresponding to MSAresumptive pronouns, producing resumptive pro-nouns for only 37 of 300 examples that cover avariety of frequent MSA relative clause structures.Our MSA resumptive pronoun identificationsystem achieves high levels of precision (92.1)and recall (91.7) on resumptive pronoun identifi-cation when using gold standard markup.
Perfor-mance drops significantly when using automaticpre-processing, with precision and recall falling to83.6 and 72.8, respectively.
One of the sourcesof the drop appears to be the weak performanceof the Tratz (2013) Arabic NLP system in identi-fying and attaching bare relative clauses?that is,relative clauses that lack a relative pronoun.This work is the first attempt we are aware of toautomatically identify resumptive pronouns in anylanguage, and it presents a baseline for compari-son for future research efforts.9 Future WorkGoing forward, we plan to experiment with apply-ing our resumptive pronoun identifier to enhanceMT performance, likely by deleting all resumptivepronouns during alignment and, again, at transla-tion time.
Another natural next step is to train thesystem using automatically generated parse, part-of-speech tag, and clitic segmentation informationinstead of gold standard annotation to see if thisproduces a similar drop in performance.
We alsoplan to investigate the use of frame information ofArabic VerbNet (Mousser, 2010) as features, andwe would like to focus in greater detail on the dif-ficulties in generating resumptive pronouns whentranslating from English into MSA.ReferencesElsaid Badawi, Michael G. Carter, and Adrian Gully.2004.
Modern Wrtitten Arabic: A ComprehensiveGrammar.
Psychology Press.46Shu Cai, David Chiang, and Yoav Goldberg.
2011.Language-independent parsing with empty ele-ments.
In ACL (Short Papers), pages 212?216.Tagyoung Chung and Daniel Gildea.
2010.
Effectsof empty categories on machine translation.
In Pro-ceedings of the 2010 Conference on Empirical Meth-ods in Natural Language Processing, pages 636?645.Michael J. Collins.
2002.
Discriminative TrainingMethods for Hidden Markov Models: Theory andexperiments with Perceptron Algorithms.
In Pro-ceedings of the 2002 Conference on Empirical Meth-ods in Natural Language Processing.P?eter Dienes and Amit Dubey.
2003.
Antecedent re-covery: Experiments with a trace tagger.
In Pro-ceedings of the 2003 conference on Empirical meth-ods in natural language processing, pages 33?40.Ryan Gabbard, Mitchell Marcus, and Seth Kulick.2006.
Fully parsing the penn treebank.
In Pro-ceedings of the Main Conference on Human Lan-guage Technology Conference of the North Amer-ican Chapter of the Association of ComputationalLinguistics, pages 184?191.Y.
Goldberg and M. Elhadad.
2010.
An efficientalgorithm for easy-first non-directional dependencyparsing.
In HLT-NAACL 2010.Mark Johnson.
2002.
A simple pattern-matching al-gorithm for recovering empty nodes and their an-tecedents.
In Proceedings of the 40th Annual Meet-ing on Association for Computational Linguistics,pages 136?143.Puneeth Kukkadapu and Prashanth Mannem.
2013.
Astatistical approach to prediction of empty categoriesin hindi dependency treebank.
In Fourth Workshopon Statistical Parsing of Morphologically Rich Lan-guages, page 91.Mohamed Maamouri and Ann Bies.
2004.
Developingan Arabic Treebank: Methods, Guidelines, Proce-dures, and Tools.
In Proceedings of the Workshop onComputational Approaches to Arabic Script-basedlanguages, pages 2?9.Mohamed Maamouri, Ann Bies, Tim Buckwalter, andWigdan Mekki.
2004.
The Penn Arabic Treebank:Building a Large-Scale Annotated Arabic Corpus.In NEMLAR Conference on Arabic Language Re-sources and Tools, pages 102?109.Jaouad Mousser.
2010.
A Large Coverage Verb Taxon-omy for Arabic.
In Proceedings of the 7th Interna-tional Conference on Language Resources and Eval-uation.Karin C. Ryding.
2005.
A Reference Grammar ofModern Standard Arabic.
Cambridge UniversityPress.Helmut Schmid.
2006.
Trace prediction and recov-ery with unlexicalized pcfgs and slash features.
InProceedings of the 21st International Conferenceon Computational Linguistics and the 44th AnnualMeeting of the Association for Computational Lin-guistics, pages 177?184.Stephen Tratz.
2013.
A cross-task flexible transitionmodel for arabic tokenization, affix detection, affixlabeling, pos tagging, and dependency parsing.
InFourth Workshop on Statistical Parsing of Morpho-logically Rich Languages.Bing Xiang, Xiaoqiang Luo, and Bowen Zhou.
2013.Enlisting the Ghost: Modeling Empty Categories forMachine Translation.
In Proceedings of the 51st An-nual Meeting of the Association for ComputationalLinguistic.Yaqin Yang and Nianwen Xue.
2010.
Chasing theghost: recovering empty categories in the chinesetreebank.
In Proceedings of the 23rd InternationalConference on Computational Linguistics: Posters,pages 1382?1390.47
