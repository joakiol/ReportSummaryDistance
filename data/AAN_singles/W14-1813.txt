Proceedings of the Ninth Workshop on Innovative Use of NLP for Building Educational Applications , pages 109?115,Baltimore, Maryland USA, June 26, 2014. c?2014 Association for Computational LinguisticsArCADE: An Arabic Corpus of Auditory Dictation ErrorsC.
Anton RyttingPaul RodriguesTim BuckwalterValerie NovakAric BillsUniversity of Maryland7005 52nd AvenueCollege Park, MD 20742{crytting,prr,tbuckwal,vnovak,abills}@umd.eduNoah H. SilbertCommunicationSciences & DisordersUniversity of Cincinnati2600 Clifton AvenueCincinnati, Ohiosilbernh@ucmail.uc.eduMohini MadgavkarIndependent Researcher6120 Dhaka Pl.
20189-6120Dhaka, Bangladeshmohini.madgavkar@gmail.comAbstractWe present a new corpus of word-level lis-tening errors collected from 62 native En-glish speakers learning Arabic designed toinform models of spell checking for thislearner population.
While we use the cor-pus to assist in automated detection andcorrection of auditory errors in electronicdictionary lookup, the corpus can also beused as a phonological error layer, to becombined with a composition error layerin a more complex spell-checking systemfor non-native speakers.
The corpus maybe useful to instructors of Arabic as a sec-ond language, and researchers who studysecond language phonology and listeningperception.1 IntroductionLearner corpora have received attention as an im-portant resource both for guiding teachers in cur-riculum development (Nesselhauf, 2004) and forproviding training and evaluation material the de-velopment of tools for computer-assisted languagelearning (CALL).
One of the most commonly usedtechnologies in CALL is spell correction.
Spellcorrection is used for providing automated feed-back to language learners (cf.
Warschauer andWare, 2006), automatic assessment (Bestgen andGranger, 2011), and in providing cleaner inputto downstream natural language processing (NLP)tools, thereby improving their performance (e.g.Nagata et al., 2011).
However, off-the-shelf spellcorrectors developed for native speakers of the tar-get language are of only limited use for repairinglanguage learners?
spelling errors, since their errorpatterns are different (e.g.
Hovermale, 2011; Mit-ton and Okada, 2007; Okada, 2005).Most learner corpora (and spell correctors) areunderstandably focused on learner-written texts.Thus, they allow a greater understanding (and im-provement) of learners?
writing skills.
However,another important aspect of language learning islistening comprehension (cf.
Field, 2008; Prince,2012).
A better understanding of listening errorscan guide teachers and curriculum developmentjust as written production errors do.
Listening er-ror data may also be helpful for improving tech-nologies for listening training tools, by helpingprioritize the most critical pairs of phonemes fordiscrimination, and pointing out the most trouble-some contexts for phoneme discrimination.Finally, spell correction specifically designedto correct listening errors may aid listening com-prehension and vocabulary acquisition.
If learn-ers are unable to hear, recall and record accu-rately what they heard, they will be less able tosearch dictionaries or the Web for more informa-tion on new vocabulary items they otherwise couldhave learned from listening exercises.
While data-driven spelling correction on popular search en-gines may catch some non-native errors, native er-rors are likely to ?drown out?
any non-native errorsthey conflict with due to larger numbers of nativeusers of these search engines.
On the other hand, ifthemost common listening and transcription errorsare automatically corrected within a search tool,learners will have greater success in finding thenew vocabulary items they may have misheard inspeech.Learner corpora focused on written productionmay not have enough samples of phonologically-based errors to aid in developing such tools, and109even in a large corpus, word avoidance strategiesand other biases would make the source unreli-able for estimating relative magnitudes of listeningproblems accurately.
It may be more effective totarget listening errors directly, through other taskssuch as listening dictation.2 Related WorkTools for language learning and maintenance, andlearner corpora fromwhich to build them, typicallyfocus on language pairs for which there is a largemarket.
Learner corpora for native English learn-ers of low resource languages such as Arabic havebeen until recently comparatively rare, and oftentoo small to be of practical use for the develop-ment of educational technology.
In the past fewyears, however, a number of learner corpora forArabic have become available, including a corpusof 19 non-native (mostlyMalaysian) students at AlAl-Bayt University (Abu al-Rub, 2007); the Ara-bic InterlanguageDatabase (ARIDA;Abuhakemaet al., 2008, 2009); the Arabic Learners Writ-ten Corpus from the University of Arizona Centerfor Educational Resources in Culture, Language,and Literacy (CERCLL; Farwaneh and Tamimi,2012);1 and the Arabic Learner Corpus v1 (Alfaifiand Atwell, 2013).2These corpora are all derived from learner writ-ing samples, such as essays, and as such they con-tainmany different types of errors, including errorsin morphology, syntax, and word choice.
Spellingerrors are also observed, but relatively rarely, andthe relevance of these spelling errors to listeningcompetence is unclear.
Hence, while they arelikely to be useful for many applications in teach-ing Arabic writing, their usefulness for other pur-poses, such as examining listening skills and theeffects of learner phonology on spelling, is limited.Corpora or datasets focused on speaking and lis-tening skills in Arabic are rarer.
One such corpus,the West Point Arabic Speech Corpus, availablefrom the LDC, contains one hour of non-native(learner) speech (LaRocca and Chouairi, 2002)Sethy et al.
(2005) describe a corpus of elicitedArabic speech, but because none of the partici-pants had prior exposure to Arabic, its use for un-1Available from http://l2arabiccorpus.cercll.arizona.edu/?q=homepage.2As of February 2014, a second version, with about 130Kwords from non-native speakers, is available from http://www.arabiclearnercorpus.com/.
It also has a small(three hour) speech component.derstanding learner Arabic is limited.
While therehave been a few studies of Arabic listening skills(e.g.
Huthaily, 2008; Faircloth, 2013), their cov-erage was not sufficiently broad to make reuse oftheir data likely to inform such purposes as the de-velopment of phoneme discrimination training orother CALL technology.3 MotivationWe present here the Arabic Corpus of AuditoryDictation Errors (ArCADE) version 1, a corpusof Arabic words as transcribed by 62 native En-glish speakers learning Arabic.
This corpus fillsthe current gap in non-native spelling error cor-pora, and particularly for spelling errors due to lis-tening difficulties.
Unlike error corpora collectedfrom non-native Arabic writing samples, it is de-signed to elicit spelling errors arising from percep-tual errors; it provides more naturalistic data thanis typical in phoneme identification or confusionstudies.A principal purpose for creating the corpus wasto aid in the development and evaluation of toolsfor detecting and correcting listening errors to aidin dictionary lookup of words learners encounteredin spoken language (cf.
Rytting et al., 2010).
Assuch, it serves as a complementary dataset for thedictionary search engine?s query logs, since in thiscase the intended target of each transcription isknown (rather than having to be inferred, in thecase of query logs).
We list three other potentialuses for this corpus in Section 5.4 Corpus Design and CreationThe ArCADE corpus was created through anelicitation experiment, similar in structure to anAmerican-style spelling test.
The principal differ-ence (other than the language) is that in this case,the participants are expected to be unfamiliar withthewords, and thus forced to rely onwhat they hearin the moment, rather than their lexical knowledge.We selected words from a commonly-used dictio-nary of Modern Standard Arabic such that the setof words would contain a complete set of non-glideconsonants in various phonetic contexts.4.1 Selection of Stimulus WordsSince the corpus was originally collected for astudy focused on the perception of consonantswithin the context of real Arabic words, the stim-ulus set was designed with three purposes in110mind: coverage of target sounds, exclusion of ba-sic words, and brevity (so that participants couldcomplete the task in one sitting).In order to differentiate consonants that are rela-tively unpredictable (and thus test listening ability)from consonants whose value could be predictedfrom non-acoustic cues (such as prior knowledgeof morphological structure), the corpus is anno-tated for target consonants vs. non-target conso-nants.
A target consonant is defined as a consonantthat should not be predictable (assuming the wordis unknown to the listener) except by the acousticcues alone.
Glides /w/ and /j/ were not targetedin the study because orthographic ambiguities be-tween glides and vowels would complicate the er-ror analysis.Each Arabic consonant other than the glides oc-curs as a target consonant in the stimulus set in sixconsonant/vowel/word-boundary contexts: C_V,V_C, V_V, #_V, V_#, and C_#.3 (The contexts#_C and C_C are phonotactically illegal in Mod-ern Standard Arabic.
)Consonants that were judged morphologicallypredictable within a word were considered non-target consonants.
These included: (1) non-rootconsonants, when Semitic roots were known to theresearchers; (2) consonants participating in a redu-plicative pattern such as /tamtam/ and /zalzala/;and (3) Consonants found in doubled (R2=R3)roots if the two consonants surfaced separately(e.g., in broken plurals such as /?asnan/).We excluded words from our stimulus set ifwe anticipated that an intermediate Arabic studentwould already be familiar with them or would eas-ily be able to guess their spellings.
Items foundin vocabulary lists associated with two commonly-used introductory textbooks (Al-Kitaab and Alif-Baa) were excluded (Brustad et al., 2004a,b).Loanwords from Western languages were also ex-cluded, as were well-known place names (e.g.,/?iskotlanda/ = ?Scotland?).
Words found only incolloquial dialects and terms that might be offen-sive or otherwise distracting (as judged by nativespeaker of Arabic) were removed, as well.In order to keep the stimulus set as short as pos-sible while maintaining coverage of the full set oftarget stimuli consonants in each targeted context,we chose words with multiple target consonantswhenever possible.
The final set of 261words con-3C = consonant, V = vowel, # = word boundary, and ?_?
(underscore) = location of target consonant.tained 649 instances of target consonants: one in-stance of each geminate consonant and between 17and 50 instances of each singleton consonant (atleast two instances for each of the six contexts),with a few exceptions.4 Although glides and vow-els were not specifically targeted, 6 instances of/w/, 10 instances of /j/, and at least 12 instances ofeach of the monophthong vowels (/a/, /i/, /u/, /a:/,/i:/, /u:/) occur in the stimulus set.4.2 Recording of the StimuliThe audio data used in the dictation was recordedin a sound-proof boothwith a unidirectionalmicro-phone (Earthworks SR30/HC) equippedwith a popfilter, and saved as WAV files (stereo, 44.1kHz,32-bit) with Adobe Audition.
The stimuli werespoken at a medium-fast rate.
The audio files weresegmented and normalized with respect to peakamplitude with Matlab.The nativeArabic speaker in the audio recordingis of Egyptian and Levantine background, but wasinstructed to speak with a neutral (?BBC Arabic?
)accent.4.3 Participants and MethodologySeventy-five participants were recruited from sixuniversities.
To be eligible, participants had to be18 years of age or older, native speakers of En-glish, and have no known history of speech lan-guage pathology or hearing loss.
Participants wererequired to have completed at least two semestersof university level Arabic courses in order to en-sure that they were able to correctly write the Ara-bic characters and to transcribe Arabic speech.Heritage speakers of Arabic and non-English dom-inant bilinguals were excluded from the study.
Thecorpus contains responses from 62 participants.The mean duration of Arabic study completed was5.6 semesters (median 4).Before beginning the experiment, participantswere asked to fill out a biographical questionnaire.This included questions about language exposureduring childhood and languages studied in a class-room setting.
There were additional questionsabout time spent outside of the United States toascertain possible exposure to languages not ad-dressed in previous questions.4These exceptions include only one instance of a phonerather than two for the following contexts: (1) /h/ in the con-text C_#, (2) /f/ in the context V_#, and (3) /z/ in the context#_V.
One geminate consonant, /x:/, was inadvertently omittedfrom the stimulus set.111Participants wrote their responses to the 261stimulus words on a response sheet that containednumbered boxes.
They were asked to use Arabicorthography with full diacritics and short vowels(fatha, damma, kasra, shadda and sukun).
Theshadda (gemination) mark was required in orderto analyze the participants?
perception of geminateconsonants; the other diacritics were included so asto not single out shadda for special attention (sinceparticipants were na?ve to the purpose of the study)and also to increase the value of the resulting errorcorpus for later analysis of short vowels.4.4 Presentation of the StumuliThe proctors who ran the experiment supplied aniPod Touch tablet to each participant, pre-loadedwith a custom stimuli presentation application.In this custom iPod application, 261 Arabicwords were randomized into 9 stimulus sets.
Eachstimulus set was preceded by four practice itemswhich were not scored; thus each participant saw265 items.
Each touch screen tablet was initializedby the testers to deliver a specific stimulus set.
Abutton on the touch screen allowed the participantsto begin the experiment.
After a few seconds?
de-lay, the first word was played.
A stimulus num-ber identifying the word appeared in a large fontto aid the participants in recording the word on pa-per.
Participants were given 15 seconds to writetheir response, before the tablet automatically ad-vanced to the next word.
Participants were not ableto replay a word.The participants used noise-canceling head-phones (Audio-Technica ATH-ANC7 or ATH-ANC7B) for listening to the audio stimuli.
Theexperiment was performed in a quiet classroom.4.5 Data CodingThe participants?
handwritten responses weretyped in as they were written, using Arabic Uni-code characters.
Any diacritics (short vowels orgemination) written by the participants were pre-served.
An automatic post-process was used to en-sure that the gemination mark was ordered prop-erly with respect to an adjacent short vowel mark.The corpus consists of twomain sections: ortho-graphic and phonemic.
The orthographic section isvery simple: each stimulus word is given in its tar-get orthography (with diacritics) and in each par-ticipant?s corresponding orthographic transcrip-tion (including diacritics if the participant providedthem as instructed).
The phonemic section is moreelaborate, containing additional fields designed fora phone level analysis of target consonants.
Itsconstruction is described in further detail below.Both the orthographic response and the canon-ical (reference) spelling were automatically con-verted to a phonemic representation.
This conver-sion normalizes certain orthographic distinctions,such as various spellings for word-final vowels.This phonemic representation of the response foreach stimulus item was then compared with thephonemic representation of the item?s canonicalpronunciation, and each phoneme of the responsewas aligned automatically with the most probablephoneme (or set of equally plausible phonemes)in the canonical phonemic representation of theauditory stimulus.
This alignment was done viadynamic programming with a weighted Leven-shtein edit distance metric.
Specifically, weightswere used to favor the alignment of vowels andglides with each other rather than with non-glideconsonants (since the scope of our original studywas non-glide consonants).
Thus substitutions be-tween short vowels, long vowels, and glides aregiven preference over other confusions.
This is in-tended to reduce the ambiguity of the alignmentsand to ensure that non-glide consonants are alignedwith non-glide consonants when possible, withoutintroducing any bias in the non-glide consonantsalignments.
When one unique alignment had thelowest cost, it was used as the alignment for thatitem.
In some cases, multiple alignments were tiedfor minimal cost.
In this case, all alignments wereused and assigned equal probability.Once the least-cost alignment(s) were found be-tween a response string and the reference string foran item, the target consonants within the referencestring were then each paired with the correspond-ing phonemes in the response, and an error cate-gory (<substitution>, <deletion>, or <match> forno error) was assigned.
In the case of geminatephonemes, two subtypes of <substitution>were in-troduced: <gemination> and <degemination>.Where an entire word had no response, ?NA?was used to indicate that no edit operation can beassigned.
(A total of 112 items were missing).Note that insertions were not marked, becauseonly the 649 instances of target consonants wereanalyzed for the phonemic portion of the corpus,and no other material in each stimulus word (in-cluding any possible insertion points for additionalmaterial) were annotated for errors.
Insertions can112be recovered from the orthographic portion of thecorpus.The coding method described above yielded aset of 41,121 target consonant records of partici-pants?
responses to target consonants (not count-ing the 112 non-response items), including 29,634matches (72.1%) and 11,487 errors (27.9%).
Atthe word level, there are 16,217 words, of which8321 (48.2%) contain at least one error in a tar-geted consonant, and 5969 (37.1%) are spelledperfectly (excluding diacritics).5 Potential Uses of the CorpusIn addition to the uses described in Section  3, webelieve the data could be used for several otheruses, such as examining linguistic correlates ofproficiency, developing phonemic training, and in-vestigating non-native Arabic handwriting.One potential use of the corpus is to analyze theerrors by individual learners to determine whichsounds are confused only by relatively beginninglearners (after two semesters) and which are con-fused by beginning and experienced learners alike.While hard measures of proficiency are not avail-able for the participants, the language question-naire includes time of study and self-report mea-sures of proficiency.
To the extent to which theseproxies are reliable, the corpus may lead to the de-velopment of hypotheses which can be tested inmore targeted studies.Since the corpus allows quantitative evidencefor the relative difficulty of particular sound pairsin particular contexts, it may guide the prioritiza-tion of foci for phonemic discrimination trainingand other listening exercises.
At the most basiclevel, a teacher can take our original audio stimuliand use them as dictation exercises for beginningstudents (who may not be ready for sentence orparagraph level dictation).
It may also form the ba-sis for automated phonemic discrimination train-ing, such as Michael et al.
(2013).
Cf.
Bradlow(2008) for a review.Since the participants handwrote their re-sponses, the corpus contains, as a byproduct, aset of 16,329 words in non-native handwriting andtheir digital transcriptions.
As Alfaifi and Atwell(2013) note, this could be used as a corpus of non-native handwriting for training or evaluating OCRon L2 Arabic script.
If corresponding native tran-scriptions of the same (or similar) strings were ob-tained, the corpus could also be used to differenti-ate native from non-native handwriting (cf.
Farooqet al., 2006; Ramaiah et al., 2013).6 Limitations and future workThe corpus as it currently stands has some limita-tions worth noting.
First, there is no control setof native Arabic listeners to provide a comparisonpoint for distinguishing non-native perceptual er-rors from acoustic errors that even native speakersare subject to.
Second, the survey does not con-tain proficiency ratings (except self-report) for theparticipants, making direct correlation of particu-lar confusion patterns with proficiency level moredifficult.Statistical analysis of the participants?
accuracyat distinguishing Arabic consonants is currentlyunderway (Silbert et al., in preparation).
An inves-tigation of the utility of the corpus for training andevaluating spelling correction for L1 English latelearners of Arabic, including the effects of trainingcorpus size on accuracy, is also in progress.7 ConclusionThe Arabic Corpus of Auditory Dictation Errors(ArCADE) version 1 provides a corpus of word-level transcriptions of Arabic speech by native En-glish speakers learning Arabic, ideal for the anal-ysis of within-word listening errors, as well as thedevelopment and evaluation of NLP tools that seekto aid either in developing listening skill or in com-pensating for typical non-native deficits in listen-ing.
Since most learner corpora only include writ-ten composition or spoken production from stu-dents, this corpus fills a gap in the resources avail-able for the study of Arabic as a second language.The corpus, along with the original audiostimuli and participants?
handwriting samples,is available at http://www.casl.umd.edu/datasets/cade/arcade/index.html.AcknowledgmentsThis material is based on work supported, in wholeor in part, with funding from the United StatesGovernment.
Any opinions, findings, and conclu-sions or recommendations expressed in this mate-rial are those of the authors and do not necessarilyreflect the views of the University of Maryland,College Park and/or any agency or entity of theUnited States Government.113ReferencesMuhammad Abu al-Rub.
2007.
????????
???????
?????.??????
????????
???????
?????
??????
???
???????
??????
???Tahl?
?l al-akht???
al-kit?b?yah ?ala mustaw?al-iml??
lad?
muta?allim?
al-lughah al-?arab?yahal-n?ti?q?na bi-ghayrih?
[Analysis of writtenspelling errors among non-native speak-ing learners of Arabic].
?????????
??????
???????.???????????
Dir?s?t, al-?Ul?m al-Ins?n?yah wa-al-Ijtim??
?yah [Humanities and Social Sciences],34(2).
http://journals.ju.edu.jo/DirasatHum/article/view/1911/1898.Ghazi Abuhakema, Anna Feldman, and EileenFitzpatrick.
2008.
Annotating an Arabic learnercorpus for error.
In Proceedings of the Interna-tional Conference on Language Resources andEvaluation (LREC 2008).
Marrakech, Morocco.Ghazi Abuhakema, Anna Feldman, and EileenFitzpatrick.
2009.
ARIDA: An Arabic inter-language database and its applications: A pilotstudy.
Journal of the National Council of LessCommonly Taught Languages (NCOLCTL),7:161?184.Abdullah Alfaifi and Eric Atwell.
2013.
Potentialuses of the Arabic Learner Corpus.
In LeedsLanguage, Linguistics, and Translation PGRConference 2013.
University of Leeds, Leeds,UK.Yves Bestgen and Sylvaine Granger.
2011.
Cat-egorising spelling errors to assess L2 writ-ing.
International Journal of Continuing En-gineering Education and Life-Long Learning,21(2/3):235?252.Ann Bradlow.
2008.
Training non-native languagesound patterns.
In Phonology and Second Lan-guage Acquisition, Benjamins, Amsterdam andPhiladelphia, pages 287?308.Kristin Brustad, Mahmoud Al-Batal, and AbbasAl-Tonsi.
2004a.
Al-Kitaab fii Ta?allum al-?Arabiyya, volume 1.
Georgetown UniversityPress, Washington, DC, 1st edition.Kristin Brustad, Mahmoud Al-Batal, and AbbasAl-Tonsi.
2004b.
Alif Baa: Introduction to Ara-bic Letters and Sounds.
Georgetown UniversityPress, Washington, DC, 2nd edition.Laura Rose Faircloth.
2013.
The L2 Perceptionof Phonemic Distinctions in Arabic by EnglishSpeakers.
BA Thesis, The College of Williamand Mary.
https://digitalarchive.wm.edu/bitstream/handle/10288/18160/FairclothLauraRose2013Thesis.pdf?sequence=1.Faisal Farooq, Liana Lorigo, and Venu Govin-daraju.
2006.
On the accent in handwrit-ing of individuals.
In Tenth Interna-tional Workshop on Frontiers in Hand-writing Recognition.
La Baule, France.http://hal.inria.fr/docs/00/11/26/30/PDF/cr103741695994.pdf.Samira Farwaneh and Mohammed Tamimi.
2012.Arabic learners written corpus: A resource forresearch and learning.
Available from theUniversity of Arizona Center for EducationalResources in Culture, Language, and Literacyweb site.
http://l2arabiccorpus.cercll.arizona.edu/?q=homepage.John Field.
2008.
Listening in the Language Class-room.
Cambridge University Press, Cambridge,UK.DJ Hovermale.
2011.
Erron: A Phrase-BasedMachine Traslation Approach to CustomizedSpelling Correction.
Ph.D. thesis, The OhioState University.Khaled Yahya Huthaily.
2008.
Second Lan-guage Instruction with Phonological Knowl-edge: Teaching Arabic to Speakers of English.Ph.D.
thesis, The University of Montana.Col.
Stephen A. LaRocca and Rajaa Chouairi.2002.
West Point Arabic speech corpus.
Tech-nical report, LDC, Philadelphia.Erica B. Michael, Greg Colflesh, Valerie Karuzis,Michael Key, Svetlana Cook, Noah H. Silbert,Christopher Green, Evelyn Browne, C. AntonRytting, Eric Pelzl, and Michael Bunting.
2013.Perceptual training for second language speechperception: Validation study to assess the ef-ficacy of a new training regimen (TTO 2013).Technical report, University of Maryland Cen-ter for Advanced Study of Language, CollegePark, MD.RogerMitton and Takeshi Okada.
2007.
The adap-tation of an English spellchecker for Japanesewriters.
Birbeck ePrints, London.
http://eprints.bbk.ac.uk/archive/00000592.Ryo Nagata, Edward Whittaker, and Vera Shein-man.
2011.
Creating a manually error-taggedand shallow-parsed learner corpus.
In Proceed-ings of the 49th Annual Meeting of the Asso-114ciation for Computational Linguistics.
Associ-ation for Computational Linguistics, Portland,OR, pages 1210?1219.Nadja Nesselhauf.
2004.
Learner corpora and theirpotential in language teaching.
In How to UseCorpora in Language Teaching, Benjamins,Amsterdam and Philadelphia, pages 125?152.Takeshi Okada.
2005.
Spelling errors made byJapanese EFL writers: with reference to errorsoccurring at the word-initial and word-final po-sitions.
In Vivian Cook and Benedetta Bassetti,editors, Second language writing systems, Mul-tilingual Matters, Clevedon, UK, pages 164?183.Peter Prince.
2012.
Writing it down: Issues re-lating to the use of restitution tasks in listeningcomprehension.
TESOL Journal, 3(1):65?86.Chetan Ramaiah, Arti Shivram, and VenuGovindaraju.
2013.
A Baysian frameworkfor modeling accents in handwriting.
In12th International Conference on Docu-ment Analysis and Recognition (ICDAR).http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6628752.C.
Anton Rytting, Paul Rodrigues, Tim Buckwal-ter, DavidM.
Zajic, Bridget Hirsch, Jeff Carnes,Nathanael Lynn, Sarah Wayland, Chris Taylor,Jason White, Charles Blake, Evelyn Browne,Corey Miller, and Tristan Purvis.
2010.
Errorcorrection for Arabic dictionary lookup.
In Sev-enth International Conference on Language Re-sources and Evaluation (LREC 2010).
Valletta,Malta.Abhinav Sethy, Shrikanth Narayanan, NicolausMote, and W. Lewis Johnson.
2005.
Modelingand automating detection of errors inArabic lan-guage learner speech.
In INTERSPEECH-2005.pages 177?180.Noah H. Silbert, C. Anton Rytting, Paul Ro-drigues, Tim Buckwalter, Valerie Novak, Mo-hiniMadgavkar, Katharine Burk, andAric Bills.in preparation.
Similarity and bias in non-nativeArabic consonant perception.Mark Warschauer and Paige Ware.
2006.
Auto-mated writing evaluation: Defining the class-room research agenda.
Language Teaching Re-search, 10(2):157?180.115
