Proceedings of the 8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH) @ EACL 2014, pages 1?8,Gothenburg, Sweden, April 26 2014. c?2014 Association for Computational LinguisticsA New Implementation for Canonical Text ServicesJochen TiepmarChristoph TeichmannGerhard HeyerComputer Science DepartmentLeipzig Universitybillion-words@e-humanities.netMonica BertiGregory CraneHumboldt Chair of Digital HumanitiesLeipzig Universitymonica.berti@uni-leipzig.decrane@informatik.uni-leipzig.deAbstractThis paper introduces a new implemen-tation of the Canonical Text Services(CTS) protocol intended to be capa-ble of handling thousands of editions.CTS was introduced for the Digital Hu-manities and is based on a hierarchicalstructuring of texts down to the level ofindividual words mirroring traditionalpractices of citing.
The paper givesan overview of CTS for those that areunfamiliar and establishes its place inthe Digital Humanities research.
Someexisting CTS implementations are dis-cussed and it is explained why thereis a need for one that is able to scaleto much larger text collections.
Eval-uations are given that can be used toillustrate the performance of the newimplementation.1 IntroductionCanonical Text Services (CTS) (Smith, 2009)1is a standard that resulted from research in theDigital Humanities community on citation ina digital context.
It consists of two parts: anURN scheme that is used to express citationsand a protocol for the interaction of a clientand a server to identify text passages and re-trieve them.CTS is an attempt to formalize citationpractices which allow for a persistent identi-fication of text passages and citations which1http://www.homermultitext.org/hmt-doc/index.htmlexpress an ontology of texts as well as links be-tween texts (Smith and Blackwell, 2012).
Thesame citation scheme can be used across dif-ferent versions of a text, even across languageborders.All these properties make CTS attractiveas an approach to the presentation of large,structured collections of texts.
The frame-work will have little impact however as longas there is no implementation that can scaleto the amount of texts currently available forDigital Humanities research and still performat a level that makes automatic processing oftexts attractive.
Therefore the implementa-tion of the scheme presented here allows forlarge repositories without becoming infeasiblyslow.2 Overview of Canonical TextServicesFor readers unfamiliar with Canonical TextServices this section provides a short introduc-tion to the CTS protocol and explains its rolein the wider context of the CITE architecture.In order to make the explanations given in thissection a little more concrete they are followedby example applications of CTS.
Before we gointo the technical details of the CTS format,a general review of the motivations and ap-proaches behind CTS will be helpful.CTS incorporates the idea that citationsprovide an inherent ontology of text passages.A citation of the first word of the first sen-tence of section 1 in this paper, when made inexactly that way, implies part-whole relation-ships between the word and the sentence, thesentence and the section and finally the sectionand the whole article.
Canonical Text Servicesderive their name from the assumption thateach text which is included in a CTS reposi-tory is associated with a canonical way of cit-1ing it which has been established by a com-munity of researchers working with the textor texts similar to it.
Where no such schemesexist they may be defined when a work firstenters a repository.
These canonical citationschemes are especially common in Classics re-search from which much of the work on CTSoriginated.
Such schemes often abstract awayfrom any concrete manifestation of a text2infavour of schemes that can be applied acrossdifferent incarnations.
Returning to the ex-ample task of citing portions of this article,one could cite the same word by referencinga specific line.
The latter approach is prob-lematic, since simply printing the article witha different font size could completely changethe lines in which words appear.
For this rea-son canonical citations generally rely on logicalproperties of the text.Using logical properties of the text impliesthat citations can be carried over from onespecific incarnation to another.
It may evenbe possible to apply the same citation schemeto versions that are written in different lan-guages.
This means that different versions ofa text can form another element of a hier-archy.
Here the part-whole relations are re-peated, with different versions of a text be-longing to larger groups as explained in section2.1.
When such citations are coupled with aservice that resolves the citations and is capa-ble of giving an inventory of all the citationsit can resolve, then this can be a powerful toolin Digital Humanities research.2.1 The CTS URN schemeWe give a short review of the structure of aCTS URN used to identify a text passage3.Any canonical reference must start with theprefix:urn:ctswhich simply identifies the string as an URNfor a canonical citation.
This is followed bythree parts that contain the main informationfor every citation.
The first of these parts iden-tifies a name space in which the following el-ements of the citation are meaningful.
Thispart allows for different authorities to define2For example a specific printing.3For a more extensive discussion seehttp://www.homermultitext.org/hmt-docs/specifications/ctsurn/their own schemes for citing works.
This sec-tion is followed by an identifier of the workthat is cited.
Finally the URN is completedby a string identifying a text node or passagein the work that is cited, which could corre-spond to a specific word, a section or even thecomplete work.
To summarize the format of aCTS URN is:urn:cts:name_space:work_identifier:passage_identifierwhere the final part can be dropped in or-der to identify the complete text of a work.The ontology for the work level is given bythe URN scheme itself which requires that thework identifier has the structure:text_group.work.version.exemplarhere only the text group part is mandatory.Every other section can be dropped if everyfollowing section is also dropped.
The textgroup can be used for any collection of textsthat the manager of a CTS service would liketo group together such as all the works of anauthor, all the works from a certain area or allthe works created at a certain time.
The workportion identifies a specific text within thatgroup.
The version part refers to a specificedition or translation of the work and finallythe exemplar identifier selects a specific exam-ple of a version of a text.
The latter three partsof a work identifier correspond to levels of thehierarchy posited by the Functional Require-ments for Bibliographic Records (FRBR).CTS URNs end with a passage identifier.This identifier can further be divided into theparts:Citable_Node@Subsectionwhere the citable node must correspond tosome XML element within the text that iscited.
The hierarchy that is used in thesenodes is up to the person managing the cita-tions.
The hierarchy can be expressed by sep-arating different levels with the delimiter ?.
?and every level can be omitted as long as allfollowing levels are also omitted.
A subsectioncan be used to select a smaller part of a citablenode by identifying words to select.
There aresome additional options that can be used in aCTS URN, among them the option to combinepassages into new subsections by using a rangeoperator, and the interested reader is encour-aged to consult the official documentation for2the standard.CTS URNs can be used to identify and con-nect text passages.
A natural task in connec-tion with citations is the retrieval of collectionsof citations and the text sections associatedwith them.
This task is addressed in the nextsection.2.2 The CTS ProtocolThis section summarizes the CTS protocol forthe retrieval of text sections and citations4.The first main request that the protocol de-fines is:GetPassagewhich can be used to retrieve a passage of atext associated to an URN in order to fulfil theactual purpose of a citation.
This request alsoshows one of the main uses of the ontology thatis implied in the way works and passages arecited.
When a work identifier is ?incomplete?then the service is allowed to pick an instanceof the work to deliver.
When a passage identi-fier is ?incomplete?
then the passage deliveredincludes all passages with identifiers that couldcomplete it.The second main request is:GetValidReffwhich is used to obtain all the citations ata certain level that the current repository cansupport.
Here it is possible to state how manylevels should be present in the answer.The final request that will be discussed inthis section is:GetCapabilitieswhich is used to obtain the different textsknown to a server and the way that they can becited i.e.
the structure of their passage identi-fiers.With the given requests it is possible to fulfilthe main tasks of a citation software: find cita-tions and/or resolve them.
Other systems canthen build on top of these requests.
One exam-ple for an architecture that includes CTS ca-pabilities in a wider framework is CITE whichis explained in the next section.4More information can be found athttp://www.homermultitext.org/hmt-docs/specifications/cts/2.3 CTS in the Context of the CITEArchitectureThe Collections, Indexes and Texts (CITE) ar-chitecture is a large framework for reference tothe objects of study in Digital Humanities5.The general design philosophy is to use URNsas a modern way of encoding citations.Besides providing a general framework forreferencing objects and texts, with the lattertask being implemented by CTS, CITE alsodefines a standard for encoding relations be-tween references.
An example would be to linka section of a text about geometry to a draw-ing which it uses as an example.
The CITEarchitecture also includes protocols for resolv-ing and obtaining the references that can bedefined within it.
Since CTS takes care of ci-tations concerning texts and the tasks associ-ated with them, an implementation of the CTSprotocol is an important first step towards acomplete implementation of the CITE archi-tecture.2.4 Example ApplicationsIn this section we review two example appli-cations for the CTS/CITE infrastructure: thegeneration of digital editions for the Classicsand creating editions of so called fragmentarytexts.2.4.1 New Features of Digital EditionsSeveral features of a true digital edition havealready begun to emerge: they have been im-plemented and they offer demonstrable ben-efits that justify such added labour as theydemand.
Each of the following features re-quires the ability to identify precise wordsand phrases in particular versions of a work.The CTS/CITE architecture provides a mech-anism to support core new functions withinthe emerging form of born-digital editions:1.
Translators must work with the realiza-tion that they are to be aligned to theoriginal and that they will, in fact, helpmake the original source text itself in-tellectually accessible to readers with noknowledge of the source language.
Ev-ery reader should use the Greek and the5More information on CITE can be foundat http://www.homermultitext.org/hmt-doc/cite/index.html3Latin.
Ideally, translators should aligntheir own translations to the source textand provide notes explaining where andwhy the source text and translation can-not be aligned.2.
We need multi-texts, i.e., editions thatcan encapsulate the entire textual historyof a work so that readers can see notonly variants from the manuscript tra-dition but also variations across editionsover time.
No reader should ultimatelyever have to wonder how a new editionvaries from its predecessors.
Encapsulat-ing the full textual tradition of every workwill take a very long time but we can be-gin by representing not only textual vari-ants but also providing more than one dig-itized edition.
Again, scholars need thefunctionality of the CTS/CITE architec-ture to represent the relationships amongdifferent versions of a work.3.
Editors of Greek and Latin texts mustencode, at the very least, their interpre-tations of the morpho-syntactic functionsof every word in every text.
This should,in fact, impose little extra cost if editorsare agonizing, as they should, over everyword.
Where the editor thinks that thereare multiple interpretations that shouldbe considered, then these should be pro-vided along with an explanation of each.The morpho-syntactic analyses are funda-mental to modern linguistic analysis andalso provide a wholly new form of readingsupport.4.
All proper names must be aligned toauthority lists such as the PleiadesGazetteer or the Perseus Smith Dictio-nary of Greek and Roman Biography.
Wealso need conventions for encoding ourtextual evidence for the relationship be-tween different named entities (e.g., X isthe son of Y).
Such annotations enablenew methods of analysing and visualis-ing our sources with methods from ge-ographic information systems and socialnetwork analysis.5.
All instances of textual reuse need to beannotated, including cases where we havereason to believe particular words andphrases are either quoted or paraphrased.2.4.2 Fragmentary TextsAmong various example applications (Smith,2009; Smith and Blackwell, 2012; Almas andBeaulieu, 2013), the CTS/CITE Architectureis being implemented by the Perseus Projectfor representing fragmentary texts of Classicallost authors.
By fragmentary texts we meantexts preserved only through quotations andreuses by later authors, such as verbatim quo-tations, paraphrases, allusions, translations,and so on (Berti et al., 2009; Almas and Berti,2013).The first need for representing such textsis to visualize them inside their embeddingcontext and this means to select the string ofwords that belong to the portion of text whichis classifiable as reuse.
The CTS/CITE Archi-tecture provides us with a standard identifiersyntax for texts, passages, and related objectsand with APIs for services which can retrieveobjects identified via these protocols (Smithand Blackwell, 2012).For example, the following set of identifiersmight be used to represent a reuse of a lost textof the Greek author Istros, which has been pre-served by Athenaeus of Naucratis in the Deip-nosophists, (Book 3, Chapter 6)6(Almas andBerti, 2013):urn:cts:greekLit:tlg0008.tlg001.perseus-grc1:3.6@???????[1]-??????????
[1]is a CTS URN for a subset of passage 3.6 inthe perseus-grc1 edition of the work identifiedby tlg001 in the group of texts associated withAthenaeus, identified by tlg0008.
The URNfurther specifies a string of text in that pas-sage starting at the first instance of the word?????????
and ending at the first instance ofthe word ???????????
?.urn:cite:perseus:lci.2is a CITE URN identifier for the instanceof lost text being reused.
This URN identifiesan object from the Perseus Collection of LostContent Items (lci) in which every item pointsto a specific text reuse of a lost author as it isrepresented in a modern edition.6For a prototype interface see http://perseids.org/sites/berti_demo/ (source code at https://github.com/PerseusDL/lci-demo)4These URNs represent distinct technology-independent identifiers for the two cited ob-jects, and by prefixing them with the http://data.perseus.org URI prefix (represent-ing the web address at which they can beresolved) we create stable URI identifiers forthem, making them compatible with linkeddata best practices7:http://data.perseus.org/citations/urn:cts:greekLit:tlg0008.tlg001.perseus-grc1:3.6@???????[1]-??????????
[1]8http://data.perseus.org/collections/urn:cite:perseus:lci.2The CITE Objects URNs may be organizedinto various types of collections of data, suchas representations of text reuses in traditionalprint editions, all text reuses attributed to aspecific author, all text reuses quoted by aspecific author, all text reuses dealing with aspecific topic, all text reuses attributed to aspecific time period, etc.
CITE collections areused to define and retrieve distinct digital rep-resentations of discrete objects, including as-sociated meta data about those objects.
Ex-ample CITE collections used to support theencoding of text reuses for this project includethe abstract lost text entities themselves, digi-tal images of manuscripts of the extant sourcetexts that quote those lost texts, commentarieson instances of text reuse and linguistic anno-tations of the quoted text (Almas et al., 2014).3 Existing ImplementationsThere are two general purpose implementa-tions of the CTS protocol that the authors ofthis paper are aware of.
The first is an imple-mentation based on a XML database.
This im-plementation is part of the Alpheios project9.Using a XML database seems natural consid-ering the fact that the CTS architecture re-quires data to take the form of XML files.
Itwould be interesting to compare the perfor-mance of this implementation with that of theone that will be presented here, but since theAlpheios tool is not yet complete and has only7http://sites.tufts.edu/perseusupdates/beta-features/perseus-stable-uris/8At the time of this writing, complete implemen-tation of the CTS standard for resolution of passagesubreferences at the data.perseus.org address is stillpending.9http://alpheios.net/been tested with a few hundred texts as in-put10any comparison would seem unfair.The second project to implement the CTSprotocol that we are aware of is based on aSparQL endpoint11.
Similar to the XML basedapproach the use of SparQL for CTS is intu-itive.
The part-of relations that are impliedby the structure of URNs could easily be mod-elled with triple expressions.
The implementa-tion has not yet been optimized to work withlarge numbers of input texts and is thereforenot suited to a comparison with the tool pre-sented in this paper.
While the use of triples toencode the logical relations seems natural, itis necessary to reconstruct all relations alreadyimplied by the structure of the URN Strings.This means that there is a potential for opti-mization that can be exploited by using thestructure of these strings in order to store allinformation implicitly.4 A New ImplementationSo far this paper has argued that CanonicalText Services can provide an important in-frastructure for Digital Humanities research.Recently it has also been highlighted (Craneet al., 2012) that repositories of texts such asthe Internet Archive12have the potential toallow Digital Humanities researchers to workwith text collections that encompass billionsor even trillions of words.
CTS is one tool inthe attempt to handle this mass of data with-out being overwhelmed by it.
Since existingimplementations of the CTS protocol are notyet able to scale to the data quantities thatthe Digital Humanities community could pro-vide, we found it necessary to create a newimplementation.
In order to find out whetherour implementation can deal with such a largenumber of texts, it will be necessary to givean evaluation of performance.
This section in-troduces the main ideas concerning this newimplementation and shows that it is indeed ca-pable of the required scaling.10Personal communication with Bridget Almas, themain developer of the Alpheios CTS implementation.11The implementation can be found at https://github.com/neelsmith/sparqlcts.12https://archive.org/index.php54.1 Using the Tree Structure of theDataThe main technical problem that needs to besolved in order to generate an efficient imple-mentation of the Canonical Text Services pro-tocol is the efficient mapping of URNs to texts,sections in these texts and the required metadata.
Both tasks require the fast mapping ofpossible prefixes of valid identifiers.
There aretwo obvious solutions to this problem.The first is the use of a prefix tree or triein order to be able to deal with underspecifieddata.
This would make it possible to read inthe portion of the URN that is specified andthen either have a copy of the text or text sec-tion associated with this prefix associated withthe tree node or construct the necessary infor-mation by visiting all daughter nodes.
Theformer choice would be more efficient in termsof nodes visited, but the latter choice wouldrequire less memory.The second option is the use ofthe lexicographic ordering of theURNs.
Consider the set of stringsS = {a.a.a, a.b.a, a.b.b, a.b.c, a.c.a, .
.
.}.
Ifall the strings are moved into a data structurethat respects the lexicographic ordering of thestrings, then all the strings matching a.b?13can be found by locating the position of thelargest string that is lexicographically smallerthan or equal to a.b14and then visiting allfollowing entries in the data structure untilone lexicographically equal to or greater thana.c15is found.
Since MySQL16already im-plements the B-Tree (Bayer and McCreight,1972) data structure to manage its tableindexes we chose this second approach forour implementation.
It is used for the workidentifiers to select a text that matches aprefix.
In the case of passage identifiers allnodes that match a certain prefix are visitedand the required text is constructed.
The firstapproach of using prefix trees was also testedbut did not lead to a significant decrease inthe time or memory requirements since it wasnot native to the database used.13Here?denotes an arbitrary sequence of charac-ters.14In this case a.a.a.15In this case a.c.a.16See www.mysql.com.4.2 Putting Everything into aRelational DatabaseWith the problem of handling the URNssolved by tree structures, all that remains is tomanage the data that can be found by usingthe URNs and keeping an index of the URNs.Because the CTS standard requires that theURNs of a work are ordered, this also meansthat this ordering needs to be preserved.
Thisis achieved by simply keeping a column thatstores a numbering.
It is ensured that thisnumbering is sequential without gaps.
Thismeans that it is possible to retrieve a certainnumber of neighbours by simply increment-ing and retrieving passages according to thiscounter.
As a result the efficient retrieval ofpassages that span a range of URNs is possiblewith only 3 requests, implemented by retriev-ing the number of the first and last URNs inthe range and then merging all text chunks inthis range into one passage.As mentioned earlier, the text of a retrievedsection is built up from smaller parts whena node higher in the hierarchy is retrieved.We thereby reduce the amount of memory re-quired since only segments of the data need tobe stored.
This is unlikely to be a bottleneck,since we assume that the length of a text isnot a variable that can grow arbitrarily.Meta data on the edition level is stored asa simple data entry.
For each individual URNwe store the language and type of its associ-ated content.4.3 EvaluationHere we want to show that our implementa-tion is able to scale to the large amounts ofdata potentially available to Digital Humani-ties researchers today and that it can handlethe large amounts of data potentially gener-ated by cooperative editing.
In order to dothis we designed tests that can be used to ac-cess the performance of our Canonical TextServices implementation.
The following Testswere used:1. retrieve a list of all editions, then get allthe valid URNs and the full passage foreach edition2.
collect the first 1000 editions, then obtainthe first URN at the lowest level within6each edition and its second neighbour, re-trieve the first full word for both17, finallyget the subsection between both words.Test 1 measures the speed with which thedata store can be explored even with a largenumber of editions and how quickly a passagespanning the whole edition can be constructed.It can be assumed that the time needed to exe-cute will increase with the amount of editionsthat are added to a repository and with thelength of the individual texts.Test 2 checks how quickly the implementa-tion can find subsections and is not expectedto take substantially longer for our implemen-tation as the number of editions increases.
Itis mainly intended to show that behaviour onsingle texts is not impacted by the number ofeditions managed and that the constructionof larger passages from elementary chunks ishandled efficiently.Both tests were run by using a small seedof data18that was copied repeatedly in orderto arrive at the number of necessary editions.The data will be made available.
Our imple-mentation ran on a server with a 2.4 GHz CPUand 1GB of RAM.
The requests necessary forour tests ran on a different machine in orderto factor in the problem of communication.
Infuture tests it would be possible to distributethe requests between different clients to focusmore on this point.Figure 1 contains the results for Test 1.
Theamount of time taken is linear in the numberof editions since every new text was generatedonce.
While the construction of all the textstook several hours for the larger collections,the list of all editions was retrieved within asecond or less.
There is a surprising spike thatcould be due to factors external to our pro-gram which could have a strong impact onsuch comparatively short time measurements.Figure 2 gives the results for Test 2.
As ex-pected the behaviour is not greatly impactedby the number of editions in the collection.The variation between the different numbersof editions is within a second for the com-plete task and the average time needed perretrieval task varies by only ten milliseconds.17A word not containing special characters andlonger than 2 characters.181000 editions.TimeinMilliseconds05?1061071.5?1072?1072.5?107Number Of Editions0 2000 4000 6000 8000 104TimeinMilliseconds02004006008001000Number Of Editions0 2000 4000 6000 8000 104Figure 1: Evaluation results for test 1.
Theupper graph shows the overall amount of timetaken to complete the test for different num-bers of editions.
The second graph shows thetime it took to just retrieve the list of all theeditions in the collection.TimeinMilliseconds05?167?05.
167?052167?2167?25N167?ubmreO f E t di4ions7 N777 ?777 .
777 2777 67?TimeinMilliseconds070N58080058272N58ubmreO f E t di4ions7 N777 ?777 .
777 2777 67?Figure 2: Evaluation results for test 2.
Theupper graph gives the amount of overall timeelapsed in the retrieval of the subsections.
Thelower graph gives the amount of time neededon average per subsection retrieved.
The av-erage was rounded down.7Both measures show a slight increase as thenumber of editions goes over 3000 but thenstabilise.Overall the experiments show that handlingthousands of text is indeed feasible with ourimplementation on a relatively modest servereven for the hardest possible task of recon-structing all the texts in the collection fromtheir smallest parts.
Subtasks that do not re-quire retrieving all the texts show little impactfrom increasing the number of editions.5 ConclusionThis paper gave a short introduction into theuse of the Canonical Text Services Protocolfor Digital Humanities research.
It also pre-sented a new implementation of the CTS pro-tocol that can handle large amounts of data.The tools that we presented will be made avail-able at:http://ctstest.informatik.uni-leipzig.de/This address is also used to house the datapresented in the evaluation as well as some ad-ditional statistics that were generated.At the time of this writing a new version ofthe CTS standard was close to completion.
Assoon as it is published we plan to make our im-plementation fully compliant.
Currently thereare still some details in which our implemen-tation diverges from this newest version of thestandard.
Once this process is complete thenext step will be the creation of a perma-nent CTS capable repository that will be inte-grated with the CLARIN research infrastruc-ture (Boehlke et al., 2013).AcknowledgementsParts of the work presented in this paperare the result of the project ?Die Biblio-thek der Milliarden Wo?rter?.
This project isfunded by the European Social Fund.
?DieBibliothek der Milliarden Wo?rter?
is a coop-eration project between the Leipzig Univer-sity Library, the Natural Language ProcessingGroup at the Institute of Computer Science atLeipzig University, and the Image and SignalProcessing Group at the Institute of ComputerScience at Leipzig University.ReferencesBridget Almas and Marie-Claire Beaulieu.
2013.Developing a new integrated editing platformfor source documents in classics.
Literary andLinguistic Computing, 28(4):493?503.Bridget Almas and Monica Berti.
2013.
Perseidscollaborative platform for annotating text re-uses of fragmentary authors.
In DH-Case 2013.Collaborative Annotations in Shared Environ-ments: metadata, vocabularies and techniques inthe Digital Humanities.Bridget Almas, Monica Berti, Dave Dubin, GretaFranzini, and Simona Stoyanova.
2014.
Thelinked fragment: TEI and the encoding of textreuses of lost authors.
paper submitted to theJournal of the Text Encoding Initiative - Issue 8- Selected Papers from the 2013 TEI Conference.Rudolf Bayer and Edward Meyers McCreight.1972.
Organization and maintenance of large or-dered indexes.
Acta Informatica, 1(3):173?189.Monica Berti, Matteo Romanello, Alison Babeu,and Gregory Crane.
2009.
Collecting fragmen-tary authors in a digital library.
In Proceedingsof the 9th ACM/IEEE-CS joint conference onDigital Libraries, pages 259?262.Volker Boehlke, Gerhard Heyer, and Peter Witten-burg.
2013.
IT-based research infrastructuresfor the humanities and social sciences ?
devel-opments, examples, standards, and technology.it - Information Technology, 55(1):26?33.Gregory Crane, Bridget Almas, Alison Babeu, LisaCerrato, Matthew Harrington, David Bamman,and Harry Diakoff.
2012.
Student researchers,citizen scholars and the trillion word library.
InProceedings of the 12th ACM/IEEE-CS JointConference on Digital Libraries, pages 213?222.D.
Neel Smith and Christopher W. Blackwell.2012.
Four URLs, limitless apps: Separation ofconcerns in the Homer Multitext architecture.In Donum natalicium digitaliter confectum Gre-gorio Nagy septuagenario a discipulis collegisfamiliaribus oblatum: A Virtual Birthday GiftPresented to Gregory Nagy on Turning Seventyby His Students, Colleagues, and Friends.
TheCenter of Hellenic Studies of Harvard Univer-sity.D.
Neel Smith.
2009.
Citation in classical studies.Digital Humanities Quarterly, 3(1).8
