A Representation for Complex and Evolving Data Dependenciesin GenerationC Me l l i sh  $, R Evans  t, L Cah i l l  t, C Doran  t, D Pa iva  t, M Reape $, D Scot t  t, N T ipper  tt Information Technology Research Institute, University of Brighton, Lewes Rd, Brighton, UKSDivision of Informatics, University of Edinburgh, 80 South Bridge, Edinburgh, UKrags@itri, brighton, ac.
ukhttp :/www.
itri.
brighton, ac.
uk/proj ect s/ragsAbst rac tThis paper introduces an approach to represent-ing the kinds of information that componentsin a natural language generation (NLG) sys-tem will need to communicate to one another.This information may be partial, may involvemore than one level of analysis and may needto include information about the history of aderivation.
We present a general representationscheme capable of handling these cases.
In ad-dition, we make a proposal for organising inter-module communication i an NLG system byhaving a central server for this information.
Wehave validated the approach by a reanalysis ofan existing NLG system and through a full im-plementation of a runnable specification.1 In t roduct ionOne of the distinctive properties of natural an-guage generation when compared with otherlanguage ngineering applications i that it hasto take seriously the full range of linguistic rep-resentation, from concepts to morphology, oreven phonetics.
Any processing system is onlyas sophisticated as its input allows, so while anatural language understanding system mightbe judged primarily by its syntactic prowess,even if its attention to semantics, pragmaticsand underlying conceptual analysis is minimal,a generation system is only as good as its deep-est linguistic representations.
Moreover, any at-tempt to abstract away from individual gener-ation systems to a more generic architecturalspecification faces an even greater challenge:not only are complex linguistic representationsrequired, able to support the dynamic evolu-tionary development of data during the gener-* Now at the MITRE Corporation, Bedford, MA, USA,cdoran@mitre, org.ation process, but they must do so in a genericand flexible fashion.This paper describes a representation devel-oped to meet these requirements.
It offers aformally well-defined eclarative representationlanguage, which provides a framework for ex-pressing the complex and dynamic data require-ments of NLG systems.
The approach supportsdifferent levels of representation, mixed repre-sentations that cut across levels, partial andshared structures and 'canned' representations,as well as dynamic relationships between dataat different stages in processing.
We are usingthe approach to develop a high level data modelfor NLG systems as part of a generic generationarchitecture called RAGS 1.The framework has been implemented in theform of a database server for modular genera-tion systems.
As proof of concept of the frame-work, we have reimplemented an existing NLGsystem.
The system we chose was the CaptionGeneration System (CGS) (Mittal et al, 1995;Mittal et al, 1998).
The reimplementation in-volved defining the interfaces to the modules ofCGS in terms of the RAGS representations andthen implementing modules that had the requi-site input and output representations.Generation systems, especially end-to-end,applied generation systems, have, unsurpris-ingly, many things in common.
Reiter (1994)proposed an analysis of such systems in termsof a simple three stage pipeline.
More recently,the RAGS project attempted to repeat he anal-1This work is supported by ESPRC grantsGR/L77041 (Edinburgh) and GR/L77102 (Brighton),RAGS: Reference Architecture for Generation Systems.We would also like to acknowledge the contribution ofJo Calder to the ideas and formalisation described inthis paper.
In particular, parts of this paper are basedon (Calder et al, 1999).119ysis (Cahill et al, 1999a), but found that whilemost systems did implement a pipeline, theydid not implement the same pipeline - differentfunctionalities occurred in different places anddifferent orders in different systems.
In orderto accommodate his result, we sought to de-velop an architecture that is more general thana simple pipeline, and thus supports the rangeof pipelines observed, as well as other more com-plex control regimes (see (Cahill et al, 1999a;Cahill et al, 1999b)).
In this paper, we arguethat supporting such an architecture requirescareful consideration of the way data represen-tations interact and develop.
Any formal frame-work for expressing the architecture must takeaccount of this.2 The  representat iona l  requ i rementso f  generat ion  sys temsWe noted in the introduction that generationsystems have to deal with a range of linguis-tic information.
It is natural, especially in thecontext of a generic architecture proposal, tomodel this breadth in terms of discrete layersof representation: (1999a) introduce layers suchas conceptual, semantic, rhetorical, syntacticand document structure, but the precise demar-cation is not as important here as the princi-ple.
The different kinds of information are typi-cally represented differently, and built up sepa-rately.
However the layers are far from indepen-dent: objects at one layer are directly related tothose at others, forming chains of dependencyfrom conceptual through rhetorical and seman-tic structure to final syntactic and document re-alisation.
This means that data resources, suchas grammars and lexicons, and processing mod-ules in the system, are often defined in terms ofmixed  data: structures that include informa-tion in more than one representation layer.
Sothe ability to represent such mixed structuresin a single formal framework is an importantproperty of a generic data proposal.In addition, it is largely standard in gener-ation as elsewhere in language applications, tomake extensive use of par t ia l  representations,often using a type system to capture grades ofunderspecification.
An immediate corollary ofproviding support for partial structures is thenotion that they may become further specifiedover time, that data structures evolve.
If theframework seeks to avoid over-commitment toparticular processing strategies it needs to pro-vide a way of representing such evolution ex-plicitly if required, rather than relying on de-structive modification of a structure.
Relatedto this, it should provide explicit support forrepresenting a l te rnat ive  specifications at anypoint.
Finally, to fully support efficient pro-cessing across the range of applications, fromthe simple to the most complex, the represen-tation must allow for compact sharing of infor-mation in tang led  structures (two structureswhich share components).In addition to these direct requirements of thegeneration task itself, additional requirementsarise from more general methodological consid-erations: we desire a representation that is for-mally well  def ined,  allows for theoretical rea-son ing about the data and performance of sys-tems, and supports control regimes from simpledeterministic pipelines to complex parallel ar-chitectures.3 The  Representat ion  SchemeIn this section, we present our proposal for ageneral representation scheme capable of cover-ing the above requirements.
Our formulation islayered: the foundation is a simple, flexible, rig-orously defined graph representation formalism,on top of which we introduce notions of com-plex types and larger data structures and rela-tionships between them.
This much is sufficientto capture the requirements just discussed.
Wesuppose a yet higher level of specification couldcapture a more constraining data model butmake no specific proposals about this here, how-ever the following sections use examples that doconform to such a higher level data model.The lowest level of the representation schemeis:?
re lat iona l :  the basic data entity is x -~ y,an ar row representing a relation from ob-ject x to object y;?
typed:  objects and arrows have an asso-ciated type system, so it is possible to de-fine classes and subclasses of objects andarrows.At the most fundamental level, this is more orless the whole definition.
There is no commit-ment to what object or arrow types there are or120how they relate to each other.
So a representa-tion allowed by the scheme consists of:?
a set of objects, organised into types;?
a set of binary relations, organised intotypes;?
a set of arrows, each indicating that a rela-tion holds between one object and anotherobject.Sets,  sequences  and  funct ionsFor the next level, we introduce more struc-ture in the type system to support sets, se-quences and functions.
Objects are alwaysatomic (though they can be of type set, se-quence or function) - it is not possible to makean object which actually is a set of two otherobjects (as you might with data structures in acomputer program).
To create a set, we intro-duce a set type for the object, and a set mem-bership arrow type (el), that links the set's el-ements to the set.
Similarly, for a sequence, weintroduce a sequence type and sequence mem-ber arrow types (1-el, 2-el, 3-el, .
.
.
), and for afunction, we have a complex type which spec-ifies the types of the arrows that make up thedomain and the range of the function.SemRep~ fun(Role.SemRep)7 V show SemRep SemRepFigure 1: The partial semantic representationof "The second chart shows the number of dayson the market"As an example, consider Figure 1, whichshows a semantic representation (SemRep) fromthe CGS reimplementation.
Here, the treenodes correspond to objects, each labelled withits type.
The root node is of type SemRep, andalthough it is not an explicit sequence type, wecan see that it is a triple, as it has three sequencemember arrows (with types 1-el, 2-el and 3-el).Its first arrow's target is an object of type DR(Discourse Referent).
Its second represents a setof SemPred (Semantic Predicate) objects, and inthis case there's just one, of type show.
Its thirdelement is a (partial) function, from Role arrowtypes (agent and affected are both subtypes ofRole) to SemReps.
(In this case, the SemRepshave not yet been fully specified.
)Local  and  non- loca l  a r rowsThe second extension to the basic representa-tion scheme is to distinguish two different ab-stract kinds of arrows - local and non-local.Fundamentally we are representing just a homo-geneous network of objects and relationships.
Inthe example above we saw a network of arrowsthat we might want to view as a single datastructure, and other major data types mightsimilarly appear as networks.
Additionally, wewant to be able to express relationships betweenthese larger 'structures' - between structuresof the same type (alternative solutions, or re-vised versions) or of different ypes (semanticand syntactic for example).
To capture thesedistinctions among arrows, we classify our ar-row types as local or non-local (we could dothis in the type system itself, or leave it as aninformal distinction).
Local arrows are used tobuild up networks that we think of as singledata structures.
Non-local arrows express rela-tionships between such data structures.All the arrow types we saw above were local.Examples of non-local arrows might include:real ises These arro~vs link something more ab-stract to something less abstract hat re-alises it.
Chains of realises arrows mightlead from the original conceptual input tothe generator through rhetorical, seman-tic and syntactic structures to the actualwords that express the input.revises These arrows link a structure to an-other one of the same type, which is con-sidered to be a 'better' solution - perhapsbecause it is more instantiated.
It is impor-tant to note that parts of larger structurescan be revised without revising the entirestructure.coreference These arrows link structureswhich are somehow "parallel" and whichperhaps hare some substructure, i.e., tan-gled structures.
For instance, documentrepresentations may be linked to rhetoricalrepresentations, either as whole isomorphicstructures or at the level of individual con-stituents.121Notice that the representation scheme doesnot enforce any kind of well-formedness withrespect o local and non-local arrows.
In fact,although it is natural to think of a 'structure' asbeing a maximal network of local arrows witha single root object, there's no reason why thisshould be so - networks with multiple roots rep-resent tangled structures (structures that sharecontent), networks that include non-local linksmight be mixed representations, containing in-formation of more than one sort.
Such tech-niques might be useful for improving generatorefficiency, or representing canned text or tem-plates, cf.
(Calder et al, 1999).Par t ia l  and  Opaque s t ruc turesPartial structures are essential when a moduleneeds to produce a skeleton of a representa-tion that it does not have the competence tocompletely fill out.
For instance, lexical choicebrings with it certain syntactic commitments,but in most NLG systems lexical choice occurssome time before a grammar is consulted toflesh out syntactic structure in detail.Figure 2: A partial structureBy simply leaving out local arrows, we canrepresent a range of partial structures.
Con-sider Fig.
2, where the triangles represent localstructure, representing a sentence object and itscomponent verb phrase.
There is a link to a sub-ject noun phrase object, but none of the localarrows of the actual noun phrase are present.
Insubsequent processing this local structure mightbe filled in.
This is possible as long as the nounphrase object has been declared to be of theright type.An opaque structure is one which has an in-complete derivational history - for example partof a syntactic structure without any correspond-ing semantic structure.
Three possible reasonsfor having such structures are (a) to allow struc-ture to be introduced that the generator is notcapable of producing directly, (b) to prevent hegenerator from interfering with the structurethus built (for example, by trying to modify anidiom in an inappropriate way), or (c) to im-prove generator efficiency by hiding detail thatmay lead to wasteful processing.
An opaquestructure is represented simply by the failureto include a rea l i ses  arrow to that structure.Such structures provide the basis for a gener-alised approach to "canning".4 Imp lementat ionThere are many ways that modules in anNLG system could communicate informationusing the representation scheme just outlined.Here we describe a particularly general modelof inter-module communication, based aroundmodules communicating with a single cen-tralised repository of data called the whiteboard(Calder et al, 1999).
A whiteboard is a cumu-lative typed relational blackboard:?
t yped  and  re lat iona l :  because it is basedon using the above representation scheme;?
a b lackboard :  a control architec-ture and data store shared betweenprocessing modules; typically, modulesadd/change/remove objects in the datastore, examine its contents, and/or ask tobe notified of changes;?
cumulat ive :  unlike standard blackboards,once data is added, it can't be changed orremoved.
So a structure is built incremen-tally by making successive copies of it (or ofconstituents of it) linked by rev ises  links(although actually, there's no constraint onthe order in which they are built).A whiteboard allows modules to add ar-rows (typically forming networks through ar-rows sharing source or target objects), to in-spect the set of arrows looking for particularconfigurations of types, or to be informed whena particular type of arrow (or group of arrows)is added.The whiteboard is an active database server.This means that it runs as an independent pro-cess that other modules connect o by appropri-ate means.
There are essentially three kinds ofinteraction that a module might have with thewhiteboard server:?
pub l i sh  - add an arrow or arrows to thewhiteboard;122?
query  - look for an arrow or arrows in thewhiteboard;?
wa i t  - register interest in an arrow or ar-rows appearing in the whiteboard.In both query and wait ,  arrows are specifiedby type, and with a hierarchical type system onobjects and relations, this amounts to a patternthat matches arrows of subtypes as well.
Thewait  function allows the whiteboard to take theinitiative in processing - if a module wai ts  on aquery then the whiteboard waits until the queryis satisfied, and then tells the module about it.So the module does not have to continuouslyscan the whiteboard for work to do, but canlet the whiteboard tell it as soon as anythinginteresting happens.Typically a module will start up and regis-ter interest in the kind of arrow that representsthe module's input data.
It will then wait forthe whiteboard to notify it of instances of thatdata (produced by other modules), and when-ever anything turns up, it processes it, addingits own results to the whiteboard.
All the mod-ules do this asynchronously, and processing con-tinues until no module has any more work todo.
This may sound like a recipe for confusion,but more standard pipelined behaviour is notmuch different.
In fact, pipelining is exactly adata-based constraint - the second module in apipeline does not start until the first one pro-duces its output.However, to be a strict pipeline, the first mod-ule must produce all of its output before the sec-ond one starts.
This can be achieved simply bymaking the first module produce all its outputat once, but sometimes that is not ideal - for ex-ample if the module is recursive and wishes toreact to its own output.
Alternative strategiesinclude the use of markers in the whiteboard,so that modules can tell each other that they'vefinished processing (by adding a marker), orextending the whiteboard architecture itself sothat modules can tell the whiteboard that theyhave finished processing, and other modules canwait for that to occur.5 Reconst ruct ion  o f  the  Capt ionGenerat ion  SystemIn order to prove this representation schemein practice, we have implemented the white-board in Sicstus Prolog and used it to supportdata communications between modules in a re-construction of the Caption Generation System(Mittal et al, 1995).
CGS is a system developedat the University of Pittsburgh, which takes in-put from the SAGE graphics presentation sys-tem (Roth et al, 1994) and generates captionsfor the graphics SAGE produces.
We selected itfor this effort because it appeared to be a fairlysimple pipelined system, with modules perform-ing clearly defined linguistic tasks.
As such, wethought it would be a good test case for ourwhiteboard specification.Although the CGS is organised as a pipeline,shown in Figure 3, the representations commu-nicated between the modules do not correspondto complete, separate instances of RAGS data-type representations.
Instead, the representa-tions at the various levels accumulate along thepipeline or are revised in a way that does notcorrespond exactly to module boundaries.
Fig-ure 3 gives a simple picture of how the differentlevels of representation build up.
The labels forthe RAGS representations refer to the following:?
I = conceptual;?
II -- semantic;?
I I I  = rhetorical;?
IV = document;?
V = syntactic.For instance, some semantic (II) information isproduced by the Text Planning module, andmore work is done on this by Aggregation, butthe semantic level of representation is not com-plete and final until the Referring Expressionmodule has run.
Also, for instance, at thepoint where the Ordering module has run, thereare partially finished versions of three differenttypes of representation.
It is clear from this thatthe interfaces between the modules are morecomplex than could be accounted for by just re-ferring to the individual evels of representationof RAGS.
The ability to express combinations ofstructures and partial structures was fundamen-tal to the reimplementation of CGS.
We high-light below a few of the interesting places wherethese features were used.123AbsSemRepI-el ~ ~  .................................... SemRep--(~------~_set{KBPredl ~ fun(Role,set(KBId)) I-el ~3-e l. .
.
.
/X  .
.
.
.
.
.
.
.el agent affected .
.
.
.
DR fun(Role,set(SemRep)) ~i/  ~ ..... ~ el?set(SemPredi~t A ~ .
?nresent set(KSld) 0 .
.
.
.
.
.
v ?
~--"- ................. / agen, /  \a\] Jec,eael / \ el .
.
.
.
.  "
.
.
.
.
.
.
.
.
.
.
~ ?J / "k~ present S~mRep SemRepchart1 chart2Figure 4: Combined Abstract Semantic Representation a d Concrete Semantic Representation forthe output: "These two charts present information about house sales from data-set ts-1740"CG$ aroh i ta ,~ lu 'e  RAGS representat/on$II I l l  IV ~' SAGE- -  .
.
.
.
.
.
.
.
.
.tuning II- .
.
.
.
.
.
.
.
.
.I1 I11 iV--' .
.
.
.
.
.
.
.
.
.I\[ I11 IV.
.
.
.
.
.
.
.
.
.
I ;11@11 III I v  v. .
.
.
.
.
.
.
.II I11 IV V. .
.
.
.
.
.
.
.
III1II 111 IV Vl - -  .
.
.
.
.
.
.
.
.
.
I I I I IFUFFigure 3: A RAGS view of the CGS system5.1 Referr ing Express ion Generat ionIn many NLG systems, (nominal) referring ex-pression generation is an operation that is in-voked at a relatively late stage, after the struc-ture of individual sentences i  fairly well speci-fied (at least semantically).
However, referringexpression generation eeds to go right back tothe original world model/knowledge base to se-lect appropriate semantic ontent o realise aparticular conceptual item as an NP (whereasall other content has been determined much ear-lier).
In fact, there seems to be no place toput referring expression generation i a pipelinewithout there being some resulting awkward-ness.In RAGS, pointers to conceptual items canbe included inside the first, "abstract", level ofsemantic representation (AbsSemRep), which isintended to correspond to an initial bundling ofconceptual material under semantic predicates.On the other hand, the final, "concrete", levelof semantic representation (SemRep) is morelike a fully-fledged logical form and it is nolonger appropriate for conceptual material tobe included there.
In the CGS reimplementa-tion, it is necessary for the Aggregation mod-ule to reason about the final high-level semanticrepresentation f sentences, which means thatthis module must have access to "concrete" se-mantic representations.
The Referring Expres-sion generation module does not run until later,which means that these representations cannotbe complete.Our way around this was to ensure that theinitial computation of concrete semantics fromabstract semantics (done as part of Aggrega-tion here) left a record of the relationship byincluding realises arrows between correspond-ing structures.
That computation could not becompleted whenever it reached conceptual ma-terial - at that point it left a "hole" (an ob-ject with no further specification) in the con-crete semantic representation li ked back to theconceptual material.
When referring expressionwas later invoked, by following the arrows in the124resulting mixed structure, it could tell exactlywhich conceptual entity needed to be referredto and where in the semantic structure the re-sulting semantic expression should be placed.Figure 4 shows the resulting arrangement forone example CGS sentence.
The dashed linesindicate realises, i.e.
non-local, arrows.5.2 Handling Centering InformationThe CGS Centering module reasons about theentities that will be referred to in each sentenceand produces a representation which records theforward and backward-looking centers (Grosz etal., 1995).
This representation is later used bythe Referring Expression generation module inmaking pronominalisation decisions.
This in-formation could potentially also be used in theRealisation module.Since Centering is not directly producing re-ferring expressions, its results have to sit arounduntil they can actually be used.
This poseda possible problem for us, because the RAGSframework does not provide a specific level ofrepresentation for Centering information andtherefore seems on first sight unable to accountfor this information being communicated be-tween modules.
The solution to the problemcame when we realised that Centering informa-tion is in fact a kind of abstract syntactic in-formation.
Although one might not expect ab-stract syntactic structure to be determined untilthe Realisation module (or perhaps lightly ear-lier), the CGS system starts this computation ithe Centering module.Thus in the reimplementation, the Centeringmodule computes (very partial) abstract syn-tactic representations for the entities that willeventually be realised as NPs.
These represen-tations basically just indicate the relevant Cen-tering statuses using syntactic features.
Figure5 shows an example of the semantics for a typi-cal output sentence and the two partial abstractsyntactic representations computed by the Cen-tering module for what will be the two NPs inthat sentence 2.
As before, dashed lines indicaterealises arrows.
Of course, given the discussionof the last section, the semantic representationobjects that are the source of these arrows are infact themselves linked back to conceptual enti-ties by being the destination of realises arrows2FVM = Feature Value Matrix.from them.When the Referring Expression generationmodule runs, it can recover the Centering infor-mation by inspecting the partial syntactic rep-resentations for the phrases it is supposed togenerate.
These partial representations are thenfurther instantiated by, e.g., Lexical Choice atlater stages of the pipeline.6 Conc lus ionThe representation scheme we have proposedhere is designed specifically to support he re-quirements of the current state-of-the-art NLGsystems, and our pilot implementation demon-strates the practical applicability of the pro-posal.
Tangled, partial and mixed structuresare of obvious utility to any system with a flex-ible control strategy and we have shown herehow the proposed representation scheme sup-ports them.
By recording the derivational his-tory of computations, it also supports decisionswhich partly depend on earlier stages of thegeneration process (e.g., possibly, lexical choice)and revision-based architectures which typicallymake use of such information.
We have shownhow the representation scheme might be the ba-sis for an inter-module communication model,the whiteboard, which supports a wide range ofprocessing strategies that require the represen-tation of complex and evolving data dependemcies.
The fact that the whiteboard is cumula-tive, or monotonic in a logical sense, means thatthe whiteboard also supports reasoning aboutthe behaviour of NLG systems implemented interms of it.
This is something that we wouldlike to exploit directly in the future.The reimplementation f the CGS systemin the RAGS framework was a challenge tothe framework because it was a system thathad already been developed completely inde-pendently.
Even though we did not always un-derstand the detailed motivation for the struc-ture of CGS being as it was, within a short timewe reconstructed a working system with mod-ules that corresponded closely to the originalCGS modules.
The representation scheme wehave proposed here was a key ingredient in giv-ing us the flexibility to achieve the particularprocessing scheme used by CGS whilst remain-ing faithful to the (relatively simple) RAGSdata model.125SemRepfun(Role,setlSemRep))sl S " ' .t t ~ .2 AbsSynRep "~ AbsSynRep _(:5 ~ ,, , / \ \ckward-looking-cemer ckward.looking-cenler+ +Figure 5: Arrangement of centering information for the output sentence aboveThe representation scheme is useful in situa-tions where modules need to be defined and im-plemented to work with other modules, possiblydeveloped by different people.
In such cases, therepresentation scheme we propose permits pre-cise definition of the interfaces of the modules,even where they are not restricted to a single'level' of representation.
Even though the con-trol structure of CGS is quite simple, we foundthat the use of a centralised whiteboard was use-ful in helping us to agree on interfaces and onthe exact contribution that each module shouldbe making.
Ultimately, it is hoped that the useof a scheme of this type will permit much morewidespread 'plug-and-play' among members ofthe NLG community.Re ferencesLynne Cahill, Christy Doran, Roger Evans, ChrisMellish, Daniel Paiva, Mike Reape, Donia Scott,and Neil Tipper.
1999a.
In Search of a ReferenceArchitecture for NLG Systems.
In Proceedings ofthe 7th European Workshop on Natural LanguageGeneration, pages 77-85, Toulouse.Lynne Cahill, Christy Doran, Roger Evans, ChrisMellish, Daniel Paiva, Mike Reape, Donia Scott,and Neil Tipper.
1999b.
Towards a ReferenceArchitecture for Natural Language Genera-tion Systems.
Technical Report ITRI-99-14,Information Technology Research Institute(ITRI), University of Brighton.
Available athttp://www, i t r i  .brighton.
ac.
uk/proj ects/rags.Jo Calder, Roger Evans, Chris Mellish, and MikeReape.
1999.
"Free choice" and templates: howto get both at the same time.
In "May I speakfreely?"
Between templates and free choice in nat-ural language generation, number D-99-01, pages19-24.
Saarbriicken.B.J.
Grosz, A.K.
Joshi, and S. Weinstein.
1995.Centering: a framework for modelling the local co-herence of discourse.
Computational Linguistics,21 (2):203-226.V.
O. Mittal, S. Roth, J. D. Moore, J. Mattis, andG.
Carenini.
1995.
Generating explanatory cap-tions for information graphics.
In Proceedings ofthe 15th International Joint Conference on Ar-tificial Intelligence (IJCAI'95), pages 1276-1283,Montreal, Canada, August.V.
O. Mittal, J. D. Moore, G. Carenini, and S. Roth.1998.
Describing complex charts in natural lan-guage: A caption generation system.
Computa-tional Linguistics, 24(3):431-468.Ehud Reiter.
1994.
Has a consensus NL generationarchitecture appeared and is it psycholinguisti-cally plausible?
In Proceedings of the Seventh In-ternational Workshop on Natural Language Gen-eration, pages 163-170, Kennebunkport, Maine.Steven F. Roth, John Kolojejchick, Joe Mattis, andJade Goldstein.
1994.
Interactive graphic designusing automatic presentation knowledge.
In Pro-ceedings of CHI'9~: Human Factors in ComputingSystems, Boston, MA.126
