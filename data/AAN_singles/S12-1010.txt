First Joint Conference on Lexical and Computational Semantics (*SEM), pages 65?69,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsSorting out the Most Confusing English Phrasal VerbsYuancheng TuDepartment of LinguisticsUniversity of Illinoisytu@illinois.eduDan RothDepartment of Computer ScienceUniversity of Illinoisdanr@illinois.eduAbstractIn this paper, we investigate a full-fledgedsupervised machine learning framework foridentifying English phrasal verbs in a givencontext.
We concentrate on those that we de-fine as the most confusing phrasal verbs, in thesense that they are the most commonly usedones whose occurrence may correspond eitherto a true phrasal verb or an alignment of a sim-ple verb with a preposition.We construct a benchmark dataset1 with 1,348sentences from BNC, annotated via an Inter-net crowdsourcing platform.
This dataset isfurther split into two groups, more idiomaticgroup which consists of those that tend to beused as a true phrasal verb and more compo-sitional group which tends to be used eitherway.
We build a discriminative classifier witheasily available lexical and syntactic featuresand test it over the datasets.
The classifieroverall achieves 79.4% accuracy, 41.1% er-ror deduction compared to the corpus major-ity baseline 65%.
However, it is even moreinteresting to discover that the classifier learnsmore from the more compositional examplesthan those idiomatic ones.1 IntroductionPhrasal verbs in English, are syntactically definedas combinations of verbs and prepositions or parti-cles, but semantically their meanings are generallynot the direct sum of their parts.
For example, givein means submit, yield in the sentence, Adam?s say-ing it?s important to stand firm , not give in to ter-rorists.
Adam was not giving anything and he was1http://cogcomp.cs.illinois.edu/page/resources/PVC Datanot in anywhere either.
(Kolln and Funk, 1998) usesthe test of meaning to detect English phrasal verbs,i.e., each phrasal verb could be replaced by a singleverb with the same general meaning, for example,using yield to replace give in in the aforementionedsentence.
To confuse the issue even further, somephrasal verbs, for example, give in in the follow-ing two sentences, are used either as a true phrasalverb (the first sentence) or not (the second sentence)though their surface forms look cosmetically similar.1.
How many Englishmen gave in to their emo-tions like that ?2.
It is just this denial of anything beyond what isdirectly given in experience that marks Berke-ley out as an empiricist .This paper is targeting to build an automatic learnerwhich can recognize a true phrasal verb from itsorthographically identical construction with a verband a prepositional phrase.
Similar to other typesof MultiWord Expressions (MWEs) (Sag et al,2002), the syntactic complexity and semantic id-iosyncrasies of phrasal verbs pose many particularchallenges in empirical Natural Language Process-ing (NLP).
Even though a few of previous workshave explored this identification problem empiri-cally (Li et al, 2003; Kim and Baldwin, 2009) andtheoretically (Jackendoff, 2002), we argue in this pa-per that this context sensitive identification problemis not so easy as conceivably shown before, espe-cially when it is used to handle those more com-positional phrasal verbs which are empirically usedeither way in the corpus as a true phrasal verb ora simplex verb with a preposition combination.
Inaddition, there is still a lack of adequate resourcesor benchmark datasets to identify and treat phrasal65verbs within a given context.
This research is alsoan attempt to bridge this gap by constructing a pub-licly available dataset which focuses on some of themost commonly used phrasal verbs within their mostconfusing contexts.Our study in this paper focuses on six of the mostfrequently used verbs, take, make, have, get, doand give and their combination with nineteen com-mon prepositions or particles, such as on, in, upetc.
We categorize these phrasal verbs according totheir continuum of compositionality, splitting theminto two groups based on the biggest gap withinthis scale, and build a discriminative learner whichuses easily available syntactic and lexical features toanalyze them comparatively.
This learner achieves79.4% overall accuracy for the whole dataset andlearns the most from the more compositional datawith 51.2% error reduction over its 46.6% baseline.2 Related WorkPhrasal verbs in English were observed as one kindof composition that is used frequently and consti-tutes the greatest difficulty for language learnersmore than two hundred and fifty years ago in SamuelJohnson?s Dictionary of English Language2.
Theyhave also been well-studied in modern linguisticssince early days (Bolinger, 1971; Kolln and Funk,1998; Jackendoff, 2002).
Careful linguistic descrip-tions and investigations reveal a wide range of En-glish phrasal verbs that are syntactically uniform,but diverge largely in semantics, argument struc-ture and lexical status.
The complexity and idiosyn-crasies of English phrasal verbs also pose a spe-cial challenge to computational linguistics and at-tract considerable amount of interest and investi-gation for their extraction, disambiguation as wellas identification.
Recent computational research onEnglish phrasal verbs have been focused on increas-ing the coverage and scalability of phrasal verbs byeither extracting unlisted phrasal verbs from largecorpora (Villavicencio, 2003; Villavicencio, 2006),or constructing productive lexical rules to gener-ate new cases (Villanvicencio and Copestake, 2003).Some other researchers follow the semantic regular-ities of the particles associated with these phrasalverbs and concentrate on disambiguation of phrasal2It is written in the Preface of that dictionary.verb semantics, such as the investigation of the mostcommon particle up by (Cook and Stevenson, 2006).Research on token identification of phrasal verbsis much less compared to the extraction.
(Li etal., 2003) describes a regular expression based sim-ple system.
Regular expression based method re-quires human constructed regular patterns and can-not make predictions for Out-Of-Vocabulary phrasalverbs.
Thus, it is hard to be adapted to other NLPapplications directly.
(Kim and Baldwin, 2009) pro-poses a memory-based system with post-processedlinguistic features such as selectional preferences.Their system assumes the perfect outputs of a parserand requires laborious human corrections to them.The research presented in this paper differs fromthese previous identification works mainly in twoaspects.
First of all, our learning system is fullyautomatic in the sense that no human interventionis needed, no need to construct regular patterns orto correct parser mistakes.
Secondly, we focus ourattention on the comparison of the two groups ofphrasal verbs, the more idiomatic group and themore compositional group.
We argue that whilemore idiomatic phrasal verbs may be easier to iden-tify and can have above 90% accuracy, there is stillmuch room to learn for those more compostionalphrasal verbs which tend to be used either positivelyor negatively depending on the given context.3 Identification of English Phrasal VerbsWe formulate the context sensitive English phrasalverb identification task as a supervised binary clas-sification problem.
For each target candidate withina sentence, the classifier decides if it is a true phrasalverb or a simplex verb with a preposition.
Formally,given a set of n labeled examples {xi, yi}ni=1, welearn a function f : X ?
Y where Y ?
{?1, 1}.The learning algorithm we use is the soft-marginSVM with L2-loss.
The learning package we useis LIBLINEAR (Chang and Lin, 2001)3.Three types of features are used in this discrimi-native model.
(1)Words: given the window size fromthe one before to the one after the target phrase,Words feature consists of every surface string ofall shallow chunks within that window.
It can bean n-word chunk or a single word depending on3http://www.csie.ntu.edu.tw/?cjlin/liblinear/66the the chunk?s bracketing.
(2)ChunkLabel: thechunk name with the given window size, such as VP,PP, etc.
(3)ParserBigram: the bi-gram of the non-terminal label of the parents of both the verb andthe particle.
For example, from this partial tree (VP(VB get)(PP (IN through)(NP (DT the)(NN day))),the parent label for the verb get is VP and the par-ent node label for the particle through is PP.
Thus,this feature value is VP-PP.
Our feature extractoris implemented in Java through a publicly availableNLP library4 via the tool called Curator (Clarke etal., 2012).
The shallow parser is publicly avail-able (Punyakanok and Roth, 2001)5 and the parserwe use is from (Charniak and Johnson, 2005).3.1 Data Preparation and AnnotationAll sentences in our dataset are extracted from BNC(XML Edition), a balanced synchronic corpus con-taining 100 million words collected from varioussources of British English.
We first construct a list ofphrasal verbs for the six verbs that we are interestedin from two resources, WN3.0 (Fellbaum, 1998)and DIRECT6.
Since these targeted verbs are alsocommonly used in English Light Verb Constructions(LVCs), we filter out LVCs in our list using a pub-licly available LVC corpus (Tu and Roth, 2011).
Theresult list consists of a total of 245 phrasal verbs.We then search over BNC and find sentences for allof them.
We choose the frequency threshold to be25 and generate a list of 122 phrasal verbs.
Finallywe manually pick out 23 of these phrasal verbs andsample randomly 10% extracted sentences for eachof them for annotation.The annotation is done through a crowdsourcingplatform7.
The annotators are asked to identify truephrasal verbs within a sentence.
The reported inner-annotator agreement is 84.5% and the gold aver-age accuracy is 88%.
These numbers indicate thegood quality of the annotation.
The final corpusconsists of 1,348 sentences among which, 65% witha true phrasal verb and 35% with a simplex verb-preposition combination.4http://cogcomp.cs.illinois.edu/software/edison/5http://cogcomp.cs.illinois.edu/page/software view/Chunker6http://u.cs.biu.ac.il/?nlp/downloads/DIRECT.html7crowdflower.com3.2 Dataset SplittingTable 1 lists all verbs in the dataset.
Total is the to-tal number of sentences annotated for that phrasalverb and Positive indicated the number of exampleswhich are annotated as containing the true phrasalverb usage.
In this table, the decreasing percent-age of the true phrasal verb usage within the datasetindicates the increasing compositionality of thesephrasal verbs.
The natural division line with thisscale is the biggest percentage gap (about 10%) be-tween make out and get at.
Hence, two groups aresplit over that gap.
The more idiomatic group con-sists of the first 11 verbs with 554 sentences and 91%of these sentences include true phrasal verb usage.This data group is more biased toward the positiveexamples.
The more compositional data group has12 verbs with 794 examples and only 46.6% of themcontain true phrasal verb usage.
Therefore, this datagroup is more balanced with respective to positiveand negative usage of the phrase verbs.Verb Total Positive Percent(%)get onto 6 6 1.00get through 61 60 0.98get together 28 27 0.96get on with 70 67 0.96get down to 17 16 0.94get by 11 10 0.91get off 51 45 0.88get behind 7 6 0.86take on 212 181 0.85get over 34 29 0.85make out 57 48 0.84get at 35 26 0.74get on 142 103 0.73take after 10 7 0.70do up 13 8 0.62get out 206 118 0.57do good 8 4 0.50make for 140 65 0.46get it on 9 3 0.33get about 20 6 0.30make over 12 3 0.25give in 118 27 0.23have on 81 13 0.16Total: 23 1348 878 0.65Table 1: The top group consists of the more idiomaticphrasal verbs with 91% of their occurrence within thedataset to be a true phrasal verb.
The second group con-sists of those more compositional ones with only 46.6%of their usage in the dataset to be a true phrasal verb.673.3 Experimental Results and DiscussionOur results are computed via 5-cross validation.
Weplot the classifier performance with respect to theoverall dataset, the more compositional group andthe more idiomatic group in Figure 1.
The clas-sifier only improves 0.6% when evaluated on theidiomatic group.
Phrasal verbs in this dataset aremore biased toward behaving like an idiom regard-less of their contexts, thus are more likely to be cap-tured by rules or patterns.
We assume this may ex-plain some high numbers reported in some previ-ous works.
However, our classifier is more effec-tive over the more compositional group and reaches73.9% accuracy, a 51.1% error deduction comparingto its majority baseline.
Phrasal verbs in this set tendto be used equally likely as a true phrasal verb andas a simplex verb-preposition combination, depend-ing on their context.
We argue phrasal verbs such asthese pose a real challenge for building an automaticcontext sensitive phrasal verb classifier.
The overallaccuracy of our preliminary classifier is about 79.4%when it is evaluated over all examples from thesetwo groups.00.20.40.60.811.2Overall Compositional IdiomaticAccuracyData GroupsClassifier Accuracy for Different Data GroupsComparison against their Majority Baselines RespectivelyMajority BaselineClassifier AccuracyFigure 1: Classifier Accuracy of each data group, com-paring with their baseline respectively.
Classifier learnsthe most from the more compositional group, indicatedby its biggest histogram gap.Finally, we conduct an ablation analysis to ex-plore the contributions of the three types of featuresin our model and their accuracies with respect toeach data group are listed in Table 2 with the bold-faced best performance.
Each type of features isused individually in the classifier.
The feature typeWords is the most effective feature with respect tothe idiomatic group and the overall dataset.
And thechunk feature is more effective towards the compo-sitional group, which may explain the linguistic in-tuition that negative phrasal verbs usually do not be-long to the same syntactic chunk.DatasetsOverall Compositional Idiom.Baseline 65.0% 46.6% 91%Words 78.6% 70.2% 91.4%Chunk 65.6% 70.7% 89.4%ParserBi 64.4% 67.2% 89.4%Table 2: Accuracies achieved by the classifier whentested on different data groups.
Features are used indi-vidually to evaluate the effectiveness of each type.4 ConclusionIn this paper, we build a discriminative learner toidentify English phrasal verbs in a given context.Our contributions in this paper are threefold.
Weconstruct a publicly available context sensitive En-glish phrasal verb dataset with 1,348 sentences fromBNC.
We split the dataset into two groups accordingto their tendency toward idiosyncrasy and compo-sitionality, and build a discriminative learner whichuses easily available syntactic and lexical features toanalyze them comparatively.
We demonstrate em-pirically that high accuracy achieved by models maybe due to the stronger idiomatic tendency of thesephrasal verbs.
For many of the more ambiguouscases, a classifier learns more from the composi-tional examples and these phrasal verbs are shownto be more challenging.AcknowledgmentsThe authors would like to thank four annonymousreviewers for their valuable comments.
The researchin this paper was supported by the Multimodal Infor-mation Access & Synthesis Center at UIUC, part ofCCICADA, a DHS Science and Technology Centerof Excellence and the Defense Advanced ResearchProjects Agency (DARPA) Machine Reading Pro-gram under Air Force Research Laboratory (AFRL)prime contract no.
FA8750-09-C-0181.
Any opin-ions and findings expressed in this material are thoseof the authors and do not necessarily reflect the viewof DHS, DARPA, AFRL, or the US government.68ReferencesD.
Bolinger.
1971.
The Phrasal Verb in English.
Har-vard University Press.C.
Chang and C. Lin, 2001.
LIBSVM: a libraryfor support vector machines.
Software available athttp://www.csie.ntu.edu.tw/?cjlin/libsvm.E.
Charniak and M. Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminative reranking.
InProceedings of ACL-2005.J.
Clarke, V. Srikumar, M. Sammons, and D. Roth.
2012.An NLP curator: How I learned to stop worrying andlove NLP pipelines.
In Proceedings of LREC-2012.P.
Cook and S. Stevenson.
2006.
Classifying particlesemantics in English verb-particle constructions.
InProceedings of the Workshop on Multiword Expres-sions: Identifying and Exploiting Underlying Proper-ties, pages 45?53, Sydney, Australia.C.
Fellbaum, editor.
1998.
WordNet: An Electronic Lex-ical Database.
MIT Press.R.
Jackendoff.
2002.
English particle constructions, thelexicon, and the autonomy of syntax.
In N. Dehe?,R.
Jackendoff, A. McIntyre, and S. Urban, editors,Verb-Particle Explorations, pages 67?94.
Mouton deGruyter.S Kim and T. Baldwin.
2009.
How to pick out tokeninstances of English verb-particle constructions.
Jour-nal of Language Resources and Evaluation.M.
Kolln and R. Funk.
1998.
Understanding EnglishGrammar.
Allyn and Bacon.W.
Li, X. Zhang, C. Niu, Y. Jiang, and R. Srihari.
2003.An expert lexicon approach to identifying Englishphrasal verbs.
In Proceedings of the 41st Annual Meet-ing of ACL, pages 513?520.V.
Punyakanok and D. Roth.
2001.
The use of classifiersin sequential inference.
In NIPS, pages 995?1001.I.
Sag, T. Baldwin, F. Bond, and A. Copestake.
2002.Multiword expressions: A pain in the neck for NLP.In Proc.
of the 3rd International Conference on Intel-ligent Text Processing and Computational Linguistics(CICLing-2002), pages 1?15.Y.
Tu and D. Roth.
2011.
Learning english light verbconstructions: Contextual or statistica.
In Proceedingsof the ACL Workshop on Multiword Expressions: fromParsing and Generation to the Real World.A.
Villanvicencio and A. Copestake.
2003.
Verb-particleconstructions in a computational grammar of English.In Proceedings of the 9th International Conference onHPSG, pages 357?371.A.
Villavicencio.
2003.
Verb-particle constructions andlexical resources.
In Proceedings of the ACL 2003Workshop on Multiword Expressions: Analysis, Acqui-sition and Treatment, pages 57?64.A.
Villavicencio, 2006.
Computational Linguistics Di-mensions of the Syntax and Semantics of Prepositions,chapter Verb-Particel Constructions in the World WideWeb.
Springer.69
