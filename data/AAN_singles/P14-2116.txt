Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 712?717,Baltimore, Maryland, USA, June 23-25 2014. c?2014 Association for Computational LinguisticsApplying Grammar Induction to Text MiningAndrew SalwayUni Research ComputingThorm?hlensgt.
55N-5008 BergenNorwayandrew.salway@uni.noSamia TouilebInformation Science and Media StudiesUniversity of BergenN-5020 BergenNorwaysamia.touileb@gmail.comAbstractWe report the first steps of a novelinvestigation into how a grammar inductionalgorithm can be modified and used toidentify salient information structures in acorpus.
The information structures are to beused as representations of semantic contentfor text mining purposes.
We modify thelearning regime of the ADIOS algorithm(Solan et al, 2005) so that text is presented asincreasingly large snippets around key terms,and instances of selected structures aresubstituted with common identifiers in theinput for subsequent iterations.
The techniqueis applied to 1.4m blog posts about climatechange which mention diverse topics andreflect multiple perspectives and differentpoints of view.
Observation of the resultinginformation structures suggests that theycould be useful as representations of semanticcontent.
Preliminary analysis shows that ourmodifications had a beneficial effect forinducing more useful structures.1 IntroductionThere is an obvious need for text miningtechniques to deal with large volumes of verydiverse material, especially since the advent ofsocial media and user-generated content whichincludes dynamic discussions of wide-rangingand controversial topics.In order to be portable across domains, textgenres and languages, current techniques tend totreat texts as bags of words when analyzingsemantic content, e.g.
for keyword-basedretrieval, summarization with word clouds, andtopic modelling.
Such techniques capture thegeneral ?aboutness?
of texts, but they do little toelucidate the actual statements that are madeabout key terms in the material.
More structuredand deeper semantic representations can begenerated by information extraction systems forrelatively restricted text genres and domains, buteven then they are costly to port.We see one particular area of application inelucidating the semantic content of social mediadebates about controversial topics, like climatechange, both for casual users, and for socialscientists studying online discourses.
Thecomplex, diverse and dynamic nature of the textcontent in such material presents a significantchallenge for elucidating semantics.
On the onehand, keywords alone will not convey what issaid about important concepts, nor differentpoints of view.
On the other hand, modelling thesemantics for information extraction purposesdoes not seem feasible given the breadth anddiversity of the material.Thus, we are motivated to develop a portabletechnique that generates representations ofsemantic content that are richer than keywords,and that can be applied to broad domains.Specifically, we seek to extract importantinformation structures from an unannotatedcorpus comprising texts of the same genre andrelating to the same domain.Rather than using language-specific ordomain-specific resources, we assume thatimportant information structures in such a corpuswill be reflected by patterning in the surfaceform of texts, such that they can be identifiedautomatically through a distributional analysis(Section 2).
Our approach is to induceinformation structures from an unannotatedcorpus by modifying and applying the ADIOSgrammar induction algorithm (Solan et al,2005): the modifications serve to focus thealgorithm on what is typically written about key-terms (Section 3).
To date we have implementedthe approach to process 1.4m English-languageblog posts about climate change: properevaluation is ongoing but we are able to show712examples of the semantic representationsgenerated, discuss how they elucidate semanticcontent, and suggest how they might be used forvarious NLP tasks (Section 4).
In closing, wemake tentative conclusions and describe ongoingwork (Section 5).2 BackgroundHarris (1954; 1988) demonstrated how linguisticunits and structures can be identified (manually)through a distributional analysis of partiallyaligned sentential contexts.
His work suggeststhat it should be possible to induce syntacticdescriptions from samples of unannotated text.An early attempt to apply this thinking tocomputational linguistics was made by Lamb(1961) who described procedures for identifying?H-groups?
and ?V-groups?.
An H-group is ahorizontal grouping of items (words and groups)that tend to appear sequentially, cf.
a syntagmaticlinguistic unit.
A V-group is a vertical groupingof items that occur in similar linguistic contextsin a corpus, cf.
a paradigmatic linguistic unit.
Asa toy example, take the H-group ?
(the (woman| man) went to the (pub | shop |park))?, with V-groups ?
(woman | man)?and ?
(pub | shop | park)?.In more recent times, Harris?
insights havebecome a cornerstone for some of the work inthe field of grammatical inference, whereresearchers attempt to induce grammaticalstructures from raw text, e.g.
ADIOS (Solan etal., 2005).
In this field the emphasis is ongenerating complete grammatical descriptionsfor text corpora in order to understand theprocesses of language learning, rather than textmining; see D?Ulizia et al (2011) for a review.The unsupervised ADIOS algorithmrecursively induces hierarchically structuredpatterns from sequential data, e.g.
sequences ofwords in unannotated text, using statisticalinformation in the sequential data.
Eachsequence (sentence) is loaded onto a directedpseudograph with one vertex for each vocabularyitem: this means that partially aligned sequencesshare sub-paths across the graph.In each iteration, the most significant patternis identified with a statistical criterion that favorsfrequent sequences that occur in a variety ofcontexts.
Then, the algorithm looks for possibleequivalence classes within the context of thepattern, i.e.
it identifies positions in the patternthat could be filled by different items and formsan equivalence class with those items.
At the endof the iteration, the new pattern and equivalenceclass become vocabulary items in the graph, sothat they can become part of further patterns andequivalence classes, and hence hierarchicalstructures are formed.
For us, the terms ?pattern?and ?equivalence class?
equate to the previouslymentioned ?H-group?
and ?V-group?
: we preferthe simplicity and literalness of these terms anduse them henceforth.3 ApproachFor text mining purposes we do not see the needto induce a complete grammar for the corpus thatwe are mining.
Rather, we are struck by Harris?further observation that the linguistic structuresderived from a distributional analysis may reflectinformation structures, especially in the?sublanguages?
of specialist domains (Harris,1988).
Thus, we propose to use a grammarinduction algorithm to identify the most salientinformation structures in a corpus and take theseas representations of important semantic content.ADIOS has been evaluated on an interestingrange of text corpora, and other kinds ofsequential data.
However, to the best of ourknowledge, it has not been shown to successfullyprocess a corpus with the scale and diversity ofmaterial that we envisage, e.g.
1.4m blog postsrelating to climate change.
This, along with ourobjective of identifying salient informationstructures rather than a complete grammaticaldescription, led us to modify the learning regimeto ADIOS.
In the rest of this section we explainthe modifications: please see 4.2.1 for a detaileddescription of how they were implemented.To address the large scale and complexity oflanguage use in social media, we modify the wayin which text is presented to ADIOS by focusingseparately on text around key terms of interest,rather than processing all sentences en masse.Our thinking here is in part influenced by thetheory of local grammar (Gross, 1997), i.e.
theidea that language is best described with wordclasses that are specific to local contexts, ratherthan general across the language.Firstly, for each key term, we present only textsnippets that contain that term: we expect thereto be more salient patterning in snippets around asingle key term because of repetition in the kindsof things written about it.
Secondly, blog postscontain long and complex sentences so weprocess the clause containing a key term, andignore the rest of the sentence.
Thirdly, since weexpect the key term to form more significant713units with words in its close proximity, wepresent the clauses in increasingly large snippetsaround the key term.A further modification targets the mostfrequent and meaningful structures.
After eachiteration in which H-groups and V-groups areinduced, the most frequent H-groups are filteredto remove any containing large V-groups whichare likely to be more semantically nebulous.Instances of the selected H-groups are replacedwith common identifiers in the input file so thatpatterning around them is more explicit insubsequent iterations.4 ImplementationHere we report our first attempt to applygrammar induction to text mining.
We chose towork with a corpus of blogs relating to climatechange because they provide a challengingscenario with complex semantics, in whichdiverse topics ?
causes, effects, solutions, etc.
?are discussed from multiple perspectives ?scientific, political, personal, etc.
?
and withdifferent beliefs (section 4.1).We describe how we modified the learningregime of the ADIOS algorithm in order toinduce H-groups and V-groups from anunannotated corpus (4.2.1).
At this stage in ourwork, our focus is on observing the kinds ofinformation structures that can be identified inthis way, and in considering their potentialapplications as representations of semanticcontent (4.2.2).
We also analyzed how resultswere affected by our modifications, i.e.
the useof incrementally bigger snippets rather thancomplete clauses, and the iterative selection andsubstitution of frequent H-groups (4.2.3).4.1 Input dataWe used a corpus of about 1.4m unannotatedEnglish-language blog posts from 3,000 blogsrelated to climate change (Salway et al, 2013).Based on the relative frequency of wordscompared with a general language corpus, andthe use of n-grams, we identified a set of domainkey terms, e.g.
?climate change?, ?greenhousegases?, ?carbon tax?, ?sea levels?.
From these weselected 17, with a mix of high (10,000?s),medium (1,000?s) and low (100?s) frequencies.For each key term we crudely extracted everyclause it occurred in by taking a clause to be asequence of words between punctuation.
Pre-processing involved conversion to lower case,joining the words of key terms to make singleitems, e.g.
?greenhouse_gases?, and substituting?dddd?
with ?YEAR?, and other digit sequenceswith ?NUMBER?
: these changes all serve tomake patterning more explicit.Then, from the clauses for each key term,snippets of varying sizes were created.
A snippetfile for a key term is defined by (min-max)where there must be at least min words to oneside of the key term, and no more than maxwords either side.
Sets of snippet files werecreated for three different increment values: i = 2(0-2, 3-4, 5-6, 7-8, 9-10, 11-12); i = 3 (0-3, 4-6,7-9, 10-12); and, i = 4 (0-4, 5-8, 9-12).4.2 Modifying the ADIOS learning regime4.2.1 MethodIn Section 3 we explained the rationale for ourmodifications to the ADIOS learning regime.They are detailed in steps 1 and 3-5 below.For one key term and one increment value:(1) INITIALIZE.
Set the current input file to bethe first snippet file for the key term andincrement value, i.e.
the smallest snippets.
(2) INDUCE CANDIDATE H-GROUPS AND V-GROUPS.
Run the ADIOS algorithm over thecurrent input file with default parametervalues, except E=0.9 (cf.
Solan et al 2005).
(3) SELECTION.
Filter the 5 most frequent H-groups to keep those that meet the followingcriterion: if the H-group contains a V-groupthen the V-group must contain < 6 elements.If none of the 5 most frequent H-groupsremain then go to (5).
(4) SUBSTITUTION.
For each selected H-group,replace all instances of it in the current inputfile with a common identifier.
Iterate 10times from (2).
(5) TRANSITION.
Until the final snippet file isreached, set the current input file to be thenext largest snippet file and substituteidentifiers for the instances of all H-groupsselected so far.
Go to (2).This process was executed for 17 key terms, withthree increment values (i = 2, 3, 4).
For furthercomparison, for each key term it was executedwith complete clauses (ten iterations withselection and substitution) and with completeclauses (one iteration).7141.
(((to (combat|fight))| (to (battle|slow|minimise|mitigate|tackle)))climate_change)2.
(climate_change (summit|adaptation|talks|meetings|convention))3.
(((greenhouse gases)|emissions|gases|(carbon emissions)|pollution) blamed((for|to) global_warming))4.
((cause|causes) (of global_warming))5.
((dangers|signs|effect|consequences|perils) (of global_warming))6.
(to (confuse|mislead|educate) the public) // from global_warming snippets7.
((anthropogenic|manmade|(man made)) global_warming)8.
((would|should|to|must) (control|reduce|regulate|regulating|release)greenhouse_gases)9.
((source|emitter|emitters|producers) of greenhouse_gases)10.
(the (effects|impact) ((under|of) ((a|its|the) carbon_tax)))11.
(a (modest|$_NUMBER a tonne|global|simple) carbon_tax)12.
((will|would|to) (push|raise|elevate) (sea_levels (around|by)))13.
(((due to)|(caused by)) ((climate change)|(global warming))) //fromsea_levels snippets14.
((((the|global|some|sophisticated|complex) climate_models)(hint|show|indicate) that)Table 1.
A small selection of H-groups induced from snippets for a variety of key terms (in bold).4.2.2 Results and potential applicationsTable 1 presents a small selection of 14 H-groupsthat were induced from snippets with various keyterms and increment values.
Here, H-groups andV-groups are bracketed and nested.
The elementsof H-groups are separated by white space and theelements of V-groups are separated by ?|?.
Recallthat the induction process selects frequent H-groups which, based on our assumptions, shouldreflect important semantic content.This output would benefit from some post-processing, which is part of ongoing work.
Forexample, in 1 there are two V-groups containingverbs that would be more elegantly expressed asa single V-group.
There are also H-groups inwhich not all V-group alternatives make sensewith the rest of the containing H-group due toover-generalization, e.g.
?to?
in ?
?blamed((for|to) global warming)?
in 3.
Despitethese issues, some interesting and potentiallyuseful structures are induced.Some H-groups, we assume those resultingfrom the most stylized use of language in blogs,could perhaps be taken as the basis forinformation extraction templates, e.g.
11 where?$_NUMBER?
is a slot for different amounts oftax, and 12 which captures various ways inwhich predictions about the amount of sea levelrise can be written.Other H-groups highlight some of the thingstypically written about key terms by groupingtogether different expressions of canonicalstatements, e.g.
3, 8 and 13.
These could be usedas a basis for summarizing the most importantpoints of a topic, i.e.
by taking 10,000?ssentences and reducing them to 10?s H-groups.For broad topics it is desirable to performfiner-grained text classification and retrieval.
Theinduction of H-groups such as 4 and 5 helps toidentify different facets of a topic.
In this case,the H-groups flag the causes of global warmingand the effects of global warming as sub-topics,and show different ways in which they may beexpressed.The alternation in V-groups contained by H-groups may reflect different beliefs and opinionswhich could be used for text classification andopinion mining.
In 14, the V-group?hint|show|indicate?
reflects differentdegrees of confidence that bloggers have inclimate models.
In 6, the alternatives in?confuse|mislead|educate?
reflectpositive and negative views about publiccommunication in the climate debate.Semantically related terms, such as thosecaptured in 1 and 5, have very differentconnotations and as such reflect different beliefs:consider the difference between someone writingabout the ?effect of global warming?
andthe ?perils of global warming?.
In othercases, alternation reflects different ways to saythe same thing, e.g.
the more or less synonymousterms that are captured in 2, 7 and 9 which wouldbe useful for query expansion.715Key Term Clauses Number of different H-groups and total instancesi=2 i=3 i=4 clauses-10 clauses-1climate change 48241 198 47000 105 52745 86 57799 8 31611 698 123531global warming  27582 191 25998 155 30001 104 31850 40 32315 397 57388greenhouse gases 20345 174 30148 136 34009 94 33846 28 25213 552 65167carbon tax 7751 106 6727 84 8341 80 9859 36 11393 128 14988sea levels 6448 138 8322 121 10246 118 11020 55 12090 240 16752climate models 6276 98 5041 91 6020 74 6399 26 6061 142 11058emissions trading scheme 2989 86 2243 65 3802 68 3140 50 7680 96 8118Table 2.
Numbers of different H-groups and total instances generated from different input data.4.2.3 The effects of our modificationsThe numbers of H-groups generated by differentexecutions of the induction process for each keyterm are shown in Table 2, i.e.
three executionsusing snippets with different values of i, and twoexecutions using clauses for comparison (cf.4.2.1).
The 10 omitted key terms (less than 1,000clauses each) generated less than 25 H-groupsfor each value of i.The high frequencies for clauses-1 are becauseno selection of H-groups took place, i.e.
wesimply take the normal ADIOS output.
Based onour own inspections, some potentially useful H-groups were found in this output but, comparedwith other outputs, it was more common to seeH-groups with large and semantically nebulousV-groups.
This observation supports the iterativeselection and substitution of H-groups with alimit on the size of V-groups.
We also looked atthe average number of V-groups in H-groups foreach execution, as a way to compare the amountof structure in H-groups.
This number wasconsistently lowest in results for clauses-1 whichfurther supports our modifications.A few potentially useful H-groups wereobserved in results for clauses-10, for whichselection and substitution were applied.
Howeverthe low numbers of different H-groups comparedwith all values of i suggests that it is better to usesnippets as input rather than clauses.The way in which the ratio of different H-groups and total instances varies for values of isuggests that starting with larger snippets (i=4)results in fewer H-groups but that these willcapture more instances, i.e.
they are moregeneral.
Whilst the H-groups for clauses-10 havemany instances these tend not to capture usefulpatterning, i.e.
they tended to describecombinations of key terms and function words.5 Closing RemarksAt this stage in the research any conclusionsmust be tentative.
However, it seems to us thatthe use of grammar induction to elucidatesemantic content for text mining purposes showspromise.
The H-groups shown in Table 1 providericher semantic descriptions of the domain thankeywords do, and we noted potential applicationsfor high-level summarization of a whole corpus,the creation of information extraction templatesand finer-grained text classification and retrieval.Importantly, the technique for generating H-groups would not require adaptation for use on adifferent corpus.
The analysis in 4.2.3 suggeststhat the modifications that we made to theADIOS learning regime had a beneficial effect.Without a thorough evaluation we cannotmake strong claims.
In particular, we have littlesense of the technique?s recall, i.e.
we do notknow what information structures it missed.
Thatsaid, it might be argued that since we expect thetechnique to be consistent in identifyingpatterning in the surface form of texts then itssuccess will depend on the extent to which keyterms are written about in consistent ways.
Thiswill of course vary between text genres anddomains.
Work has started on another corpuswith more restricted language use and richerstructuring was induced (Salway et al 2014).In other ongoing work we are looking moreinto the effects of the various parameters ofADIOS, and the necessity for our modifications.We are also seeking a deeper understanding ofhow the statistical information exploited byADIOS relates to that which is captured by n-gram language models to describe sequences ofwords (cf.
H-groups), and by establishedtechniques to form semantic classes based onshared linguistic contexts (cf.
V-groups).AcknowledgmentsWe are very grateful to Zach Solan for providingan implementation of the ADIOS algorithm, andto Knut Hofland and Lubos Steskal for their rolesin creating the NTAP blog corpus.
This researchwas supported by a grant from The ResearchCouncil of Norway?s VERDIKT program.716ReferencesArianna D?Ulizia, Fernando Ferri and PatriziaGrifoni.
2011.
A survey of grammatical inferencemethods for natural language learning.
ArtificialIntelligence Review 36(1):1-27.Maurice Gross.
1997.
The Construction of LocalGrammars.
In: E. Roche and Y. Schabes (eds.
),Finite-State Language Processing.
The MIT Press,Cambridge MA: 329-354.Zellig Harris.
1954.
Distributional Structure.
Word10(2/3):146-162.Zellig Harris.
1988.
Language and Information.Columbia University Press, New York.Sydney Lamb.
1961.
On the Mechanization ofSyntactic Analysis.
Int.
Conf.
Machine Translationof Languages and Applied Language Analysis.Andrew Salway, Knut Hofland and Samia Touileb.2013.
Applying Corpus Techniques to ClimateChange Blogs.
Procs.
Corpus Linguistics 2013,Lancaster University.Andrew Salway, Samia Touileb and EndreTvinnereim.
2014.
Inducing Information Structuresfor Data-driven Text Analysis.
To appear in: Procs.ACL Workshop on Language Technologies andComputational Social Science.Zach Solan, David Horn, Eytan Ruppin, and ShimonEdelman.
2005.
Unsupervised learning of naturallanguages.
Procs.
of the National Academy ofSciences 102(33):11629-11634.717
