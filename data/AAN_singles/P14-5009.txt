Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 49?54,Baltimore, Maryland USA, June 23-24, 2014.c?2014 Association for Computational LinguisticsWELT: Using Graphics Generation in Linguistic FieldworkMorgan Ulinski?mulinski@cs.columbia.eduAnusha Balakrishnan?ab3596@columbia.eduDaniel Bauer?bauer@cs.columbia.eduBob Coyne?coyne@cs.columbia.eduJulia Hirschberg?julia@cs.columbia.eduOwen Rambow?rambow@ccls.columbia.edu?Department of Computer Science?CCLSColumbia UniversityNew York, NY, USAAbstractWe describe the WordsEye Linguisticstool (WELT), a novel tool for the docu-mentation and preservation of endangeredlanguages.
WELT is based on Words-Eye (Coyne and Sproat, 2001), a text-to-scene tool that automatically generates 3Dscenes from written input.
WELT has twomodes of operation.
In the first mode, En-glish input automatically generates a pic-ture which can be used to elicit a de-scription in the target language.
In thesecond mode, the linguist formally docu-ments the grammar of an endangered lan-guage, thereby creating a system that takesinput in the endangered language and gen-erates a picture according to the grammar;the picture can then be used to verify thegrammar with native speakers.
We willdemonstrate WELT?s use on scenarios in-volving Arrernte and Nahuatl.1 IntroductionAlthough languages have appeared and disap-peared throughout history, today languages arefacing extinction at an unprecedented pace.
Over40% of the estimated 7,000 languages in the worldare at risk of disappearing.
When languages dieout, we lose access to an invaluable resource forstudying the culture, history, and experience ofpeoples around the world (Alliance for LinguisticDiversity, 2013).
Efforts to document languagesand develop tools in support of collecting data onthem become even more important with the in-creasing rate of extinction.
Bird (2009) empha-sizes a particular need to make use of computa-tional linguistics during fieldwork.To address this issue, we are developing theWordsEye Linguistics Tool, or WELT.
In the firstmode of operation, we provide a field linguist withtools for running custom elicitation sessions basedon a collection of 3D scenes.
In the second, inputin an endangered language generates a picture rep-resenting the input?s meaning according to a for-mal grammar.WELT provides important advantages for elic-itation over the pre-fabricated sets of static pic-tures commonly used by field linguists today.
Thefield worker is not limited to a fixed set of picturesbut can, instead, create and modify scenes in realtime, based on the informants?
answers.
This al-lows them to create additional follow-up scenesand questions on the fly.
In addition, since thepictures are 3D scenes, the viewpoint can easilybe changed, allowing exploration of linguistic de-scriptions based on different frames of reference.This will be particularly useful in eliciting spatialdescriptions.
Finally, since scenes and objects caneasily be added in the field, the linguist can cus-tomize the images used for elicitation to be maxi-mally relevant to the current informants.WELT also provides a means to document thesemantics of a language in a formal way.
Lin-guists can customize their studies to be as deep orshallow as they wish; however, we believe that amajor advantage of documenting a language withWELT is that it enables such studies to be muchmore precise.
The fully functioning text-to-scenesystem created as a result of this documentationwill let linguists easily test the theories they de-velop with native speakers, making changes togrammars and semantics in real time.
The result-ing text-to-scene system can be an important toolfor language preservation, spreading interest in thelanguage among younger generations of the com-munity and recruiting new speakers.We will demonstrate the features of WELTfor use in fieldwork, including designing elic-itation sessions, building scenes, recording au-dio, and adding descriptions and glosses to ascene.
We will use examples from sessions we49have conducted with a native speaker of Nahu-atl, an endangered language spoken in Mexico.We will demonstrate how to document seman-tics with WELT, using examples from Arrernte,an Australian aboriginal language spoken in AliceSprings.
We will also demonstrate a basic Arrerntetext-to-scene system created in WELT.In the following sections, we will mention re-lated work (Section 2), discuss the WordsEye sys-tem that WELT is based on (Section 3), describeWELT in more detail, highlighting the functional-ity that will appear in our demonstration (Section4), and briefly mention our future plans for WELT(Section 5).2 Related WorkOne of the most widely-used computer toolkits forfield linguistics is SIL Fieldworks.
FieldWorks isa collection of software tools; the most relevantfor our research is FLEx, Fieldworks LanguageExplorer.
FLEx includes tools for eliciting andrecording lexical information, dictionary develop-ment, interlinearization of texts, analysis of dis-course features, and morphological analysis.
Animportant part of FLEx is its ?linguist-friendly?morphological parser (Black and Simons, 2006),which uses an underlying model of morphologyfamiliar to linguists, is fully integrated into lexicondevelopment and interlinear text analysis, and pro-duces a human-readable grammar sketch as wellas a machine-interpretable parser.Several computational tools aim to simplify theformal documentation of syntax by eliminatingthe need to master particular grammar formalisms.First is the PAWS starter kit (Black and Black,2012), a system that prompts linguists with a seriesof guided questions about the target language anduses their answers to produce a PC-PATR gram-mar (McConnel, 1995).
The LinGO GrammarMatrix (Bender et al., 2002) is a similar tool de-veloped for HPSG that uses a type hierarchy torepresent cross-linguistic generalizations.The most commonly used resource for for-mally documenting semantics across languagesis FrameNet (Filmore et al., 2003).
FrameNetshave been developed for many languages, includ-ing Spanish, Japanese, and Portuguese.
Moststart with English FrameNet and adapt it for thenew language; a large portion of the frames endup being substantially the same across languages(Baker, 2008).
ParSem (Butt et al., 2002) is acollaboration to develop parallel semantic repre-sentations across languages, by developing seman-tic structures based on LFG.
Neither of these re-sources, however, are targeted at helping non-computational linguists formally document a lan-guage, as compared to the morphological parser inFLEx or the syntactic documentation in PAWS.3 WordsEye Text-to-Scene SystemWordsEye (Coyne and Sproat, 2001) is a systemfor automatically converting natural language textinto 3D scenes representing the meaning of thattext.
WordsEye supports language-based controlof spatial relations, textures and colors, collec-tions, facial expressions, and poses; it handlessimple anaphora and coreference resolution, al-lowing for a variety of ways of referring to ob-jects.
The system assembles scenes from a libraryof 2,500 3D objects and 10,000 images tied to anEnglish lexicon of about 15,000 nouns.The system includes a user interface where theuser can type simple sentences that are processedto produce a 3D scene.
The user can then modifythe text to refine the scene.
In addition, individualobjects and their parts can be selected and high-lighted with a bounding box to focus attention.Several thousand real-world people have usedWordsEye online (http://www.wordseye.com).
Ithas also been used as a tool in education, to en-hance literacy (Coyne et al., 2011b).
In this paper,we describe how we are using WordsEye to createa comprehensive tool for field linguistics.Vignette Semantics and VigNet To interpret in-put text, WordsEye uses a lexical resource calledVigNet (Coyne et al., 2011a).
VigNet is inspiredby and based on FrameNet (Baker et al., 1998),a resource for lexical semantics.
In FrameNet,lexical items are grouped together in frames ac-cording to their shared semantic structure.
Everyframe contains a number of frame elements (se-mantic roles) which are participants in this struc-ture.
The English FrameNet defines the mappingbetween syntax and semantics for a lexical item byproviding lists of valence patterns that map syntac-tic functions to frame elements.VigNet extends FrameNet in two ways in or-der to capture ?graphical semantics?,?
the knowl-edge needed to generate graphical scenes fromlanguage.
First, graphical semantics are addedto the frames by adding primitive graphical (typ-ically, spatial) relations between the frame ele-50ment fillers.
Second, VigNet distinguishes be-tween meanings of words that are distinguishedgraphically.
For example, the specific objectsand spatial relations in the graphical semantics forcook depend on the object being cooked and onthe culture in which it is being cooked (cookingturkey in Baltimore vs. cooking an egg in AliceSprings), even though at an abstract level cook anegg in Alice Springs and cook a turkey in Bal-timore are perfectly compositional semantically.Frames augmented with graphical semantics arecalled vignettes.4 WordsEye Linguistics Tool (WELT)In this section, we describe the two modes ofWELT, focusing on the aspects of our system thatwill appear in our demonstration.4.1 Tools for Linguistic FieldworkWELT includes tools that allow linguists to elicitlanguage with WordsEye.
Each elicitation sessionis organized around a set of WordsEye scenes.
Wewill demonstrate how a linguist would use WELTin fieldwork, including (1) creating an elicitationsession, either starting from scratch, or by import-ing scenes from a previous session; (2) buildingscenes in WordsEye, saving them to a WELT ses-sion, and modifying scenes previously added tothe session, either overwriting the original scene orsaving the changes as a new scene; (3) adding tex-tual descriptions, glosses, and notes to a scene; and(4) recording audio, which is automatically syncedto open scenes, and playingit back tto review anygiven scene.
A screen shot of the scene annotationwindow is included in Figure 1.To test the fieldwork capabilities of WELT,we created a set of scenes based on the MaxPlanck topological relations picture series (Bower-man and Pederson, 1992).
We used these scenes toelicit descriptions from a native Nahuatl speaker;some examples of scenes and descriptions are in-cluded in Figure 2.4.2 Formal Documentation of a LanguageWELT also provides the means to formally doc-ument the semantics of a language and create atext-to-scene system for that language.
The formaldocumentation allows precise description of thelexical semantics of a language.
We will demon-strate both the user interface for documenting se-mantics, as well as a text-to-scene system for Ar-Figure 1: WELT interface for annotating a scenerernte created with WELT.When a sentence is processed by WordsEye, itgoes through three main stages: (1) morphologicalanalysis and syntactic parsing, (2) semantic anal-ysis, and (3) graphical realization.
We will walkthrough these modules in the context of WELT,discussing (a) the formal documentation requiredfor that component, (b) the processing of an ex-ample sentence through that component, and (c)the parts of that component that will feature in ourdemonstration.
We will use the Arrernte sentenceshown in (1) as a running example.
(1) artwe le goal arrernememan ERG goal put.nonpastThe man kicks a goal.Morphology and Syntax WELT first parses asentence into its morphology and syntax.
Sincethe focus of WELT is documentation of semantics,the exact mechanisms for parsing the morphologyand syntax may vary.
To document Arrernte, weare using XFST (Karttunen et al., 1997) to modelthe morphology and XLE (Crouch et al., 2006) tomodel the syntax in the LFG formalism (Kaplanand Bresnan, 1982).
These are mature systemsthat we believe are sufficient for the formal doc-umentation of morphology and syntax.
In future,we will provide interfaces to the third-party toolsso that common information, like the lexicon, can51(a) in amat?
t?akentija se kutSarathe paper cover one spoon(b) in kwawit?
t?apanawi t?akoja se mansanathe stick pass.thru in.middle one appleFigure 2: Nahuatl examples elicited with WELTbe shared.Running each word of the sentence throughthe morphological analyzer in XFST transformsthe verb arrerneme into ?arrerne+NONPAST.?
Theother tokens in the sentence remain unchanged.Parsing the sentence with XLE gives the c-structure shown in Figure 3(a) and the f-structureshown in Figure 3(b).
The f-structure will bepassed on to the semantics module.
(a)(b)Figure 3: C-structure (a) and f-structure (b) forartwe le goal arrerneme.We have added one additional feature to themorphology and syntax module of WELT?s text-to-scene system: an interface for selecting an f-structure from multiple options produced by XLE,in case the grammar is ambiguous.
This way, alinguist can use the WELT text-to-scene systemto verify their semantic documentation even if thesyntactic documentation is fairly rough.
We willdemonstrate this feature when demonstrating theArrernte text-to-scene system.Semantics The WELT semantics is representedusing VigNet, which has been developed forWordsEye based on English.
We will assume thatlarge parts of VigNet are language-independent(for instance, the set of low-level graphical rela-tions used to express the graphical semantics isbased on physics and human anatomy and does notdepend on language).
Therefore, it should not benecessary to create a completely new VigNet forevery language that will be used in WELT.
In fu-ture, we will develop tools for modifying VigNetto handle linguistic and cultural differences as theyoccur.In order to use VigNet with other languages,we need to map between the formal syntax of thelanguage being studied and the (English) lexicalsemantics required currently by VigNet.
One in-stance showing why this is necessary occurs in ourexample Arrrente sentence.
When discussing foot-ball in English, one would say that someone kicksa goal or makes a goal.
In Arrente, one would saygoal arrerneme, which translates literally to ?puta goal.?
Although the semantics of both sentencesare the same, the entry for ?put?
in the EnglishVigNet does not include this meaning, but the Ar-rernte text-to-scene system needs to account for it.To address such instances, we have created aninterface for a linguist to specify a set of rules thatmap from syntax to semantics.
The rules take syn-tactic f-structures as input and output a high-levelsemantic representation compatible with VigNet.The left-hand side of a rule consists of a set of con-ditions on the f-structure elements and the right-hand side consists of the semantic structure thatshould be returned.
Figure 4(a) is an example ofa rule mapping Arrernte syntax to semantics, cre-ated in WELT.In addition to these rules, the linguist creates asimple table mapping lexical items into VigNet se-mantic concepts, so that nouns can be converted tographical objects.
We have created a mapping forthe lexical items in the Arrernte grammar; a partialmapping is shown in Table 1.We now describe the semantic processing of ourexample Arrernte sentence, assuming a set of rulesconsisting solely of the one in Figure 4(a) and thenoun mapping in Table 1.
The f-structure in Fig-52(a) (b)Figure 4: Syntax-semantics rule (a) and semantic category browser (b) from WELTLexical Item artwe panikane angepe akngwelye apwerte tipweleVigNet Concept PERSON.N CUP.N CROW.N DOG.N ROCK-ITEM.N TABLE.NTable 1: A mapping from nouns (lexical items) to VigNet semantic conceptsure 3(b) has main predicate arrerne with two ar-guments; the object is goal.
Therefore, it matchesthe left-hand-side of our rule.
The output ofthe rule specifies predicate CAUSE MOTION.KICKwith three arguments.
The latter two are straight-forward; the Theme is the VigNet object FOOTY-BALL.N, and the Goal is FOOTYGOAL.N.
To deter-mine the Agent, we need to find the VigNet con-cept corresponding to var-1, which occupies thesubject position in the f-structure.
The subject inour f-structure is artwe, and according to Table 1,it maps to the VigNet concept PERSON.N.
The re-sulting semantic representation is augmented withits graphical semantics, taken from the vignettefor CAUSE MOTION.KICK (vignette definition notshown for lack of space).
The final representationis shown in Figure 5, with lexical semantics at thetop and graphical semantics below.
The Words-Eye system then builds the scene from these con-straints and renders it in 3D.CAUSE_MOTION.KICKFOOTYBALLThemeFOOTYGOALGoalPERSONAgent20 ftFRONT-OFDistORIENT-TOPOSITION-BETWEENFigure GroundGoal GroundIN-POSEFigureSource SubjectFigurekickValueFigure 5: The semantics (lexical and graphical) forsentence (1)WELT provides an interface for creating rulesby defining the tree structures for the left-hand-side and right-hand-side of the rule.
Every node onthe left-hand-side can optionally contain booleanlogic, if for example we want to allow the sub-ject to be [(artwe ?man?
OR arhele ?woman?)
ANDNOT ampe ?child?
]; so rules can be as simple orcomplex as desired.
Rules need not specify lexicalitems directly; it is also possible to refer to moregeneral semantic categories.
For example, a rulecould select for all verbs of motion, or specify aparticular constraint on the subject or object.
Infigure 4(a), for instance, we may want to only al-low animate subjects.Semantic categories are chosen through abrowser that allows the user to search through allthe semantic categories defined in VigNet.
For ex-ample, if we want to find the semantic categoryto use as a constraint on our example subject, wemight start by searching for human.
This takes usto a portion of a tree of semantic concepts cen-tered around HUMAN.N.
The semantic categoriesare displayed one level at a time, so we initiallysee only the concepts directly above and directlybelow the word we searched for.
From there, it?seasy to select the concepts we are interested in,and go up or down the tree until we find the one wewant.
Below HUMAN.N are HUMAN-FEMALE.Nand HUMAN-MALE.N, but we are more interestedin the more general categories above the node.
Ascreen shot showing the result of this search isshown in Figure 4(b).
Above HUMAN.N is HU-MANOID.N; above that, ANIMATE-BEING.N.
Do-ing a quick check of further parents and chil-dren, we can see that for the subject of ?put goal,?we would probably want to choose ANIMATE-BEING.N over LIVING-THING.N.The table mapping lexical items to VigNet con-cepts is built in a similar way; the lexicon is au-tomatically extracted from the LFG grammar, andthe user can search and browse semantic conceptsto find the appropriate node for each lexical item.We will demonstrate the WELT user inter-53face which supports the creation of syntax-to-semantics rules, creates the mapping betweennouns in the lexicon and VigNet concepts, and ver-ifies the rules using the WELT text-to-scene sys-tem.
We will show examples from our documenta-tion of Arrernte and demonstrate entering text intothe Arrernte text-to-scene system to generate pic-tures.5 Summary and Future WorkWe have described a novel tool for linguists work-ing with endangered languages.
It provides a newway to elicit data from informants, an interfacefor formally documenting the lexical semantics ofa language, and allows the creation of a text-to-scene system for any language.This project is in its early stages, so we are plan-ning many additional features and improvements.For both modes of WELT, we want to generate pic-tures appropriate for the target culture.
To han-dle this, we will add the ability to include cus-tom objects and modify VigNet with new vignettesor new graphical semantics for existing vignettes.We also plan to build tools to import and exportthe work done in WELT in order to facilitate col-laboration among linguists working on similar lan-guages or cultures.
Sharing sets of scenes will al-low linguists to reuse work and avoid duplicatedeffort.
Importing different versions of VigNet willmake it easier to start out with WELT on a newlanguage if it is similar to one that has alreadybeen studied.
We might expect, for instance, thatother Australian aboriginal languages will requirethe same kinds of cultural modifications to VigNetthat we make for Arrernte, or that two languagesin the same family might also have similar syntaxto semantics rules.AcknowledgmentsThis material is based upon work supported bythe National Science Foundation under Grant No.1160700.ReferencesAlliance for Linguistic Diversity.
2013.
The En-dangered Languages Project.
http://www.endangeredlanguages.com/.C.
Baker, J. Fillmore, and J. Lowe.
1998.
The BerkeleyFrameNet project.
In 36th Meeting of the Associa-tion for Computational Linguistics and 17th Inter-national Conference on Computational Linguistics(COLING-ACL?98), pages 86?90, Montr?eal.C.
Baker.
2008.
FrameNet, present and future.
In TheFirst International Conference on Global Interoper-ability for Language Resources, pages 12?17.E.
Bender, D. Flickinger, and S. Oepen.
2002.
TheGrammar Matrix.
In J. Carroll, N. Oostdijk, andR.
Sutcliffe, editors, Workshop on Grammar En-gineering and Evaluation at the 19th InternationalConference on Computational Linguistics, pages 8?14, Taipei, Taiwan.S.
Bird.
2009.
Natural language processing andlinguistic fieldwork.
Computational Linguistics,35(3):469?474.C.
Black and H.A.
Black.
2012.
Grammars for thepeople, by the people, made easier using PAWS andXLingPaper.
In Sebastian Nordoff, editor, Elec-tronic Grammaticography, pages 103?128.
Univer-sity of Hawaii Press, Honolulu.H.A.
Black and G.F. Simons.
2006.
The SIL Field-Works Language Explorer approach to morphologi-cal parsing.
In Computational Linguistics for Less-studied Languages: Texas Linguistics Society 10,Austin, TX, November.M.
Bowerman and E. Pederson.
1992.
Topological re-lations picture series.
In S. Levinson, editor, Spacestimuli kit 1.2, page 51, Nijmegen.
Max Planck In-stitute for Psycholinguistics.M.
Butt, H. Dyvik, T.H.
King, H. Masuichi, andC.
Rohrer.
2002.
The parallel grammar project.
In2002 Workshop on Grammar Engineering and Eval-uation - Volume 15, COLING-GEE ?02, pages 1?7, Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.B.
Coyne and R. Sproat.
2001.
WordsEye: An au-tomatic text-to-scene conversion system.
In SIG-GRAPH.B.
Coyne, D. Bauer, and O. Rambow.
2011a.
Vignet:Grounding language in graphics using frame seman-tics.
In ACL Workshop on Relational Models of Se-mantics (RELMS), Portland, OR.B.
Coyne, C. Schudel, M. Bitz, and J. Hirschberg.2011b.
Evaluating a text-to-scene generation systemas an aid to literacy.
In SlaTE (Speech and LanguageTechnology in Education) Workshop at Interspeech,Venice.D.
Crouch, M. Dalrymple, R. Kaplan, T. King,J.
Maxwell, and P. Newman, 2006.
XLE Doc-umentation.
http://www2.parc.com/isl/groups/nltt/xle/doc/xle.C.
Filmore, C. Johnson, and M. Petruck.
2003.
Back-ground to FrameNet.
In International Journal ofLexicography, pages 235?250.R.M.
Kaplan and J.W.
Bresnan.
1982.
Lexical-functional grammar: A formal system for grammat-ical representation.
In J.W.
Bresnan, editor, TheMental Representation of Grammatical Relations.MIT Press, Cambridge, Mass., December.L.
Karttunen, T. Ga?al, and A. Kempe.
1997.
Xeroxfinite-state tool.
Technical report, Xerox ResearchCentre Europe, Grenoble.S.
McConnel, 1995.
PC-PATR Reference Manual.Summer Institute for Linguistics.54
