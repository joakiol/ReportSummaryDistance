Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 176?183,New York, June 2006. c?2006 Association for Computational LinguisticsA Fully-Lexicalized Probabilistic Modelfor Japanese Syntactic and Case Structure AnalysisDaisuke Kawahara?
and Sadao Kurohashi?Graduate School of Information Science and Technology, University of Tokyo7-3-1 Hongo Bunkyo-ku, Tokyo, 113-8656, Japan{kawahara,kuro}@kc.t.u-tokyo.ac.jpAbstractWe present an integrated probabilisticmodel for Japanese syntactic and casestructure analysis.
Syntactic and casestructure are simultaneously analyzedbased on wide-coverage case frames thatare constructed from a huge raw corpus inan unsupervised manner.
This model se-lects the syntactic and case structure thathas the highest generative probability.
Weevaluate both syntactic structure and casestructure.
In particular, the experimen-tal results for syntactic analysis on websentences show that the proposed modelsignificantly outperforms known syntacticanalyzers.1 IntroductionCase structure (predicate-argument structure or log-ical form) represents what arguments are related toa predicate, and forms a basic unit for conveying themeaning of natural language text.
Identifying suchcase structure plays an important role in natural lan-guage understanding.In English, syntactic case structure can be mostlyderived from word order.
For example, the left ar-gument of the predicate is the subject, and the rightargument of the predicate is the object in most cases.Blaheta and Charniak proposed a statistical method?Currently, National Institute of Information and Communi-cations Technology, JAPAN, dk@nict.go.jp?Currently, Graduate School of Informatics, Kyoto Univer-sity, kuro@i.kyoto-u.ac.jpfor analyzing function tags in Penn Treebank, andachieved a really high accuracy of 95.7% for syn-tactic roles, such as SBJ (subject) and DTV (da-tive) (Blaheta and Charniak, 2000).
In recent years,there have been many studies on semantic structureanalysis (semantic role labeling) based on PropBank(Kingsbury et al, 2002) and FrameNet (Baker et al,1998).
These studies classify syntactic roles into se-mantic ones such as agent, experiencer and instru-ment.Case structure analysis of Japanese is very differ-ent from that of English.
In Japanese, postpositionsare used to mark cases.
Frequently used postposi-tions are ?ga?, ?wo?
and ?ni?, which usually meannominative, accusative and dative.
However, whenan argument is followed by the topic-marking post-position ?wa?, its case marker is hidden.
In addi-tion, case-marking postpositions are often omitted inJapanese.
These troublesome characteristics makeJapanese case structure analysis very difficult.To address these problems and realize Japanesecase structure analysis, wide-coverage case framesare required.
For example, let us describe how toapply case structure analysis to the following sen-tence:bentou-wa taberulunchbox-TM eat(eat lunchbox)In this sentence, taberu (eat) is a verb, and bentou-wa (lunchbox-TM) is a case component (i.e.
argu-ment) of taberu.
The case marker of ?bentou-wa?is hidden by the topic marker (TM) ?wa?.
The an-alyzer matches ?bentou?
(lunchbox) with the most176suitable case slot (CS) in the following case frameof ?taberu?
(eat).CS examplestaberu ga person, child, boy, ?
?
?wo lunch, lunchbox, dinner, ?
?
?Since ?bentou?
(lunchbox) is included in ?wo?
ex-amples, its case is analyzed as ?wo?.
As a result, weobtain the case structure ??
:ga bentou:wo taberu?,which means that ?ga?
(nominative) argument isomitted, and ?wo?
(accusative) argument is ?bentou?(lunchbox).
In this paper, we run such case structureanalysis based on example-based case frames thatare constructed from a huge raw corpus in an unsu-pervised manner.Let us consider syntactic analysis, into which ourmethod of case structure analysis is integrated.
Re-cently, many accurate statistical parsers have beenproposed (e.g., (Collins, 1999; Charniak, 2000) forEnglish, (Uchimoto et al, 2000; Kudo and Mat-sumoto, 2002) for Japanese).
Since they somehowuse lexical information in the tagged corpus, they arecalled ?lexicalized parsers?.
On the other hand, un-lexicalized parsers achieved an almost equivalent ac-curacy to such lexicalized parsers (Klein and Man-ning, 2003; Kurohashi and Nagao, 1994).
Accord-ingly, we can say that the state-of-the-art lexicalizedparsers are mainly based on unlexical (grammatical)information due to the sparse data problem.
Bikelalso indicated that Collins?
parser can use bilexicaldependencies only 1.49% of the time; the rest ofthe time, it backs off to condition one word on justphrasal and part-of-speech categories (Bikel, 2004).This paper aims at exploiting much more lexicalinformation, and proposes a fully-lexicalized proba-bilistic model for Japanese syntactic and case struc-ture analysis.
Lexical information is extracted notfrom a small tagged corpus, but from a huge raw cor-pus as case frames.
This model performs case struc-ture analysis by a generative probabilistic modelbased on the case frames, and selects the syntacticstructure that has the highest case structure proba-bility.2 Automatically Constructed Case FramesWe employ automatically constructed case frames(Kawahara and Kurohashi, 2002) for our model ofTable 1: Case frame examples (examples are ex-pressed only in English for space limitation.
).CS examplesga <agent>, group, party, ?
?
?youritsu (1) wo <agent>, candidate, applicant(support) ni <agent>, district, election, ?
?
?ga <agent>youritsu (2) wo <agent>, member, minister, ?
?
?
(support) ni <agent>, candidate, successor.........itadaku (1) ga <agent>(have) wo soupga <agent>itadaku (2) wo advice, instruction, address(be given) kara <agent>, president, circle, ?
?
?.........case structure analysis.
This section outlines themethod for constructing the case frames.A large corpus is automatically parsed, and caseframes are constructed from modifier-head exam-ples in the resulting parses.
The problems of auto-matic case frame construction are syntactic and se-mantic ambiguities.
That is to say, the parsing re-sults inevitably contain errors, and verb senses areintrinsically ambiguous.
To cope with these prob-lems, case frames are gradually constructed from re-liable modifier-head examples.First, modifier-head examples that have no syn-tactic ambiguity are extracted, and they are dis-ambiguated by a couple of a verb and its closestcase component.
Such couples are explicitly ex-pressed on the surface of text, and can be consid-ered to play an important role in sentence mean-ings.
For instance, examples are distinguished notby verbs (e.g., ?tsumu?
(load/accumulate)), but bycouples (e.g., ?nimotsu-wo tsumu?
(load baggage)and ?keiken-wo tsumu?
(accumulate experience)).Modifier-head examples are aggregated in this way,and yield basic case frames.Thereafter, the basic case frames are clusteredto merge similar case frames.
For example, since?nimotsu-wo tsumu?
(load baggage) and ?busshi-wotsumu?
(load supply) are similar, they are clustered.The similarity is measured using a thesaurus (Ike-hara et al, 1997).Using this gradual procedure, we constructed caseframes from the web corpus (Kawahara and Kuro-177hashi, 2006).
The case frames were obtained fromapproximately 470M sentences extracted from theweb.
They consisted of 90,000 verbs, and the aver-age number of case frames for a verb was 34.3.In Figure 1, some examples of the resulting caseframes are shown.
In this table, ?CS?
means a caseslot.
<agent> in the table is a generalized example,which is given to the case slot where half of the ex-amples belong to <agent> in a thesaurus (Ikeharaet al, 1997).
<agent> is also given to ?ga?
caseslot that has no examples, because ?ga?
case com-ponents are usually agentive and often omitted.3 Integrated Probabilistic Model forSyntactic and Case Structure AnalysisThe proposed method gives a probability to eachpossible syntactic structure T and case structure Lof the input sentence S, and outputs the syntacticand case structure that have the highest probability.That is to say, the system selects the syntactic struc-ture Tbest and the case structure Lbest that maximizethe probability P (T,L|S):(Tbest, Lbest) = argmax(T,L)P (T,L|S)= argmax(T,L)P (T,L, S)P (S)= argmax(T,L)P (T,L, S) (1)The last equation is derived because P (S) is con-stant.3.1 Generative Model for Syntactic and CaseStructure AnalysisWe propose a generative probabilistic model basedon the dependency formalism.
This model considersa clause as a unit of generation, and generates theinput sentence from the end of the sentence in turn.P (T,L, S) is defined as the product of a probabilityfor generating a clause Ci as follows:P (T,L, S) =?i=1..nP (Ci|bhi) (2)where n is the number of clauses in S, and bhi isCi?smodifying bunsetsu1.
The main clause Cn at the end1In Japanese, bunsetsu is a basic unit of dependency, con-sisting of one or more content words and the following zero ormore function words.
It corresponds to a base phrase in English,and ?eojeol?
in Korean.Figure 1: An Example of Probability Calculation.of a sentence does not have a modifying head, butwe handle it by assuming bhn = EOS (End Of Sen-tence).For example, consider the sentence in Figure 1.There are two possible dependency structures, andfor each structure the product of probabilities indi-cated below of the tree is calculated.
Finally, themodel chooses the highest-probability structure (inthis case the left one).Ci is decomposed into its predicate type fi (in-cluding the predicate?s inflection) and the rest casestructure CSi.
This means that the predicate in-cluded in CSi is lemmatized.
Bunsetsu bhi is alsodecomposed into the content part whi and the typefhi .P (Ci|bhi) = P (CSi, fi|whi , fhi)= P (CSi|fi, whi , fhi)P (fi|whi , fhi)?
P (CSi|fi, whi)P (fi|fhi) (3)The last equation is derived because the content partin CSi is independent of the type of its modifyinghead (fhi), and in most cases, the type fi is indepen-dent of the content part of its modifying head (whi).For example, P (bentou-wa tabete|syuppatsu-shita)is calculated as follows:P (CS(bentou-wa taberu)|te, syuppatsu-suru)P (te|ta.
)We call P (CSi|fi, whi) generative model for casestructure and P (fi|fhi) generative model for predi-cate type.
The following two sections describe thesemodels.3.2 Generative Model for Case StructureWe propose a generative probabilistic model of casestructure.
This model selects a case frame that178Figure 2: An example of case assignment CAk.matches the input case components, and makes cor-respondences between input case components andcase slots.A case structure CSi consists of a predicate vi,a case frame CFl and a case assignment CAk.Case assignment CAk represents correspondencesbetween input case components and case slots asshown in Figure 2.
Note that there are various pos-sibilities of case assignment in addition to that ofFigure 2, such as corresponding ?bentou?
(lunch-box) with ?ga?
case.
Accordingly, the index k ofCAk ranges up to the number of possible case as-signments.
By splitting CSi into vi, CFl and CAk,P (CSi|fi, whi) is rewritten as follows:P (CSi|fi, whi) = P (vi, CFl, CAk|fi, whi)= P (vi|fi, whi)?
P (CFl|fi, whi , vi)?
P (CAk|fi, whi , vi, CFl)?
P (vi|whi)?
P (CFl|vi)?
P (CAk|CFl, fi) (4)The above approximation is given because it isnatural to consider that the predicate vi depends onits modifying headwhi , that the case frameCFl onlydepends on the predicate vi, and that the case assign-ment CAk depends on the case frame CFl and thepredicate type fi.The probabilities P (vi|whi) and P (CFl|vi) areestimated from case structure analysis results of alarge raw corpus.
The remainder of this section il-lustrates P (CAk|CFl, fi) in detail.3.2.1 Generative Probability of CaseAssignmentLet us consider case assignment CAk for eachcase slot sj in case frame CFl.
P (CAk|CFl, fi)can be decomposed into the following product de-pending on whether a case slot sj is filled with aninput case component (content part nj and type fj)or vacant:P (CAk|CFl, fi) =?sj :A(sj)=1P (A(sj) = 1, nj , fj |CFl, fi, sj)?
?sj :A(sj)=0P (A(sj) = 0|CFl, fi, sj)=?sj :A(sj)=1{P (A(sj) = 1|CFl, fi, sj)?P (nj , fj |CFl, fi, A(sj) = 1, sj)}?
?sj :A(sj)=0P (A(sj) = 0|CFl, fi, sj) (5)where the function A(sj) returns 1 if a case slot sjis filled with an input case component; otherwise 0.P (A(sj) = 1|CFl, fi, sj) and P (A(sj) =0|CFl, fi, sj) in equation (5) can be rewritten asP (A(sj) = 1|CFl, sj) and P (A(sj) = 0|CFl, sj),because the evaluation of case slot assignment de-pends only on the case frame.
We call these proba-bilities generative probability of a case slot, and theyare estimated from case structure analysis results ofa large corpus.Let us calculate P (CSi|fi, whi) using the ex-ample in Figure 1.
In the sentence, ?wa?
isa topic marking (TM) postposition, and hidesthe case marker.
The generative probability ofcase structure varies depending on the case slotto which the topic marked phrase is assigned.For example, when a case frame of ?taberu?
(eat) CFtaberu1 with ?ga?
and ?wo?
case slots isused, P (CS(bentou-wa taberu)|te, syuppatsu-suru)is calculated as follows:P1(CS(bentou-wa taberu)|te, syuppatsu-suru) =P (taberu|syuppatsu-suru)?
P (CFtaberu1|taberu)?
P (bentou,wa|CFtaberu1, te, A(wo) = 1,wo)?
P (A(wo) = 1|CFtaberu1,wo)?
P (A(ga) = 0|CFtaberu1, ga) (6)179P2(CS(bentou-wa taberu)|te, syupatsu-suru) =P (taberu|syuppatsu-suru)?
P (CFtaberu1|taberu)?
P (bentou,wa|CFtaberu1, te, A(ga) = 1, ga)?
P (A(ga) = 1|CFtaberu1, ga)?
P (A(wo) = 0|CFtaberu1,wo) (7)Such probabilities are computed for each case frameof ?taberu?
(eat), and the case frame and its cor-responding case assignment that have the highestprobability are selected.We describe the generative probability of a casecomponent P (nj , fj |CFl, fi, A(sj) = 1, sj) below.3.2.2 Generative Probability of CaseComponentWe approximate the generative probability of acase component, assuming that:?
a generative probability of content part nj is in-dependent of that of type fj ,?
and the interpretation of the surface case in-cluded in fj does not depend on case frames.Taking into account these assumptions, the genera-tive probability of a case component is approximatedas follows:P (nj , fj |CFl, fi, A(sj) = 1, sj) ?P (nj |CFl, A(sj) = 1, sj) P (fj |sj , fi) (8)P (nj |CFl, A(sj) = 1, sj) is the probability ofgenerating a content part nj from a case slot sj in acase frame CFl.
This probability is estimated fromcase frames.Let us consider P (fj |sj , fi) in equation (8).
Thisis the probability of generating the type fj of a casecomponent that has a correspondence with the caseslot sj .
Since the type fj consists of a surface casecj2, a punctuation mark (comma) pj and a topicmarker ?wa?
tj , P (fj |sj , fi) is rewritten as follows2A surface case means a postposition sequence at the end ofbunsetsu, such as ?ga?, ?wo?, ?koso?
and ?demo?.
(using the chain rule):P (fj |sj , fi) = P (cj , tj , pj |sj , fi)= P (cj |sj , fi)?
P (pj |sj , fi, cj)?
P (tj |sj , fi, cj , pj)?
P (cj |sj)?
P (pj |fi)?
P (tj |fi, pj) (9)This approximation is given by assuming that cjonly depends on sj , pj only depends on fj , and tjdepends on fj and pj .
P (cj |sj) is estimated from theKyoto Text Corpus (Kawahara et al, 2002), in whichthe relationship between a surface case marker anda case slot is annotated by hand.In Japanese, a punctuation mark and a topicmarker are likely to be used when their belong-ing bunsetsu has a long distance dependency.
Byconsidering such tendency, fi can be regarded as(oi, ui), where oi means whether a dependent bun-setsu gets over another head candidate before itsmodifying head vi, and ui means a clause type ofvi.
The value of oi is binary, and ui is one of theclause types described in (Kawahara and Kurohashi,1999).P (pj |fi) = P (pj |oi, ui) (10)P (tj |fi, pj) = P (tj |oi, ui, pj) (11)3.3 Generative Model for Predicate TypeNow, consider P (fi|fhi) in the equation (3).
This isthe probability of generating the predicate type of aclause Ci that modifies bhi .
This probability variesdepending on the type of bhi .When bhi is a predicate bunsetsu, Ci is a subor-dinate clause embedded in the clause of bhi .
As forthe types fi and fhi , it is necessary to consider punc-tuation marks (pi, phi) and clause types (ui, uhi).To capture a long distance dependency indicated bypunctuation marks, ohi (whether Ci has a possiblehead candidate before bhi) is also considered.PV Bmod(fi|fhi) = PV Bmod(pi, ui|phi , uhi , ohi)(12)When bhi is a noun bunsetsu, Ci is an embeddedclause in bhi .
In this case, clause types and a punc-tuation mark of the modifiee do not affect the prob-ability.PNBmod(fi|fhi) = PNBmod(pi|ohi) (13)180Table 2: Data for parameter estimation.probability what is generated dataP (pj |oi, uj) punctuation mark Kyoto Text CorpusP (tj |oi, ui, pj) topic marker Kyoto Text CorpusP (pi, ui|phi , uhi , ohi) predicate type Kyoto Text CorpusP (cj |sj) surface case Kyoto Text CorpusP (vi|whi) predicate parsing resultsP (nj |CFl, A(sj) = 1, sj) words case framesP (CFl|vi) case frame case structure analysis resultsP (A(sj) = {0, 1} |CFl, sj) case slot case structure analysis resultsTable 3: Experimental results for syntactic analysis.baseline proposedall 3,447/3,976 (86.7%) 3,477/3,976 (87.4%)NB?VB 1,310/1,547 (84.7%) 1,328/1,547 (85.8%)TM 244/298 (81.9%) 242/298 (81.2%)others 1,066/1,249 (85.3%) 1,086/1,249 (86.9%)NB?NB 525/556 (94.4%) 526/556 (94.6%)VB?VB 593/760 (78.0%) 601/760 (79.1%)VB?NB 453/497 (91.1%) 457/497 (92.0%)4 ExperimentsWe evaluated the syntactic structure and case struc-ture outputted by our model.
Each parameter is es-timated using maximum likelihood from the datadescribed in Table 2.
All of these data are notexisting or obtainable by a single process, but ac-quired by applying syntactic analysis, case frameconstruction and case structure analysis in turn.
Theprocess of case structure analysis in this table is asimilarity-based method (Kawahara and Kurohashi,2002).
The case frames were automatically con-structed from the web corpus comprising 470M sen-tences, and the case structure analysis results wereobtained from 6M sentences in the web corpus.The rest of this section first describes the exper-iments for syntactic structure, and then reports theexperiments for case structure.4.1 Experiments for Syntactic StructureWe evaluated syntactic structures analyzed by theproposed model.
Our experiments were run onhand-annotated 675 web sentences 3.
The web sen-tences were manually annotated using the same cri-teria as the Kyoto Text Corpus.
The system inputwas tagged automatically using the JUMAN mor-phological analyzer (Kurohashi et al, 1994).
Thesyntactic structures obtained were evaluated with re-3The test set is not used for case frame construction andprobability estimation.gard to dependency accuracy ?
the proportion ofcorrect dependencies out of all dependencies exceptfor the last dependency in the sentence end 4.Table 3 shows the dependency accuracy.
Inthe table, ?baseline?
means the rule-based syn-tactic parser, KNP (Kurohashi and Nagao, 1994),and ?proposed?
represents the proposed method.The proposed method significantly outperformed thebaseline method (McNemar?s test; p < 0.05).
Thedependency accuracies are classified into four typesaccording to the bunsetsu classes (VB: verb bun-setsu, NB: noun bunsetsu) of a dependent and itshead.
The ?NB?VB?
type is further divided intotwo types: ?TM?
and ?others?.
The type that is mostrelated to case structure is ?others?
in ?NB?VB?.Its accuracy was improved by 1.6%, and the errorrate was reduced by 10.9%.
This result indicatedthat the proposed method is effective in analyzingdependencies related to case structure.Figure 3 shows some analysis results, where thedotted lines represent the analysis by the baselinemethod, and the solid lines represent the analysis bythe proposed method.
Sentence (1) and (2) are in-correctly analyzed by the baseline but correctly ana-lyzed by the proposed method.There are two major causes that led to analysiserrors.Mismatch between analysis results and annota-tion criteriaIn sentence (3) in Figure 3, the baselinemethod correctly recognized the head of ?iin-wa?
(commissioner-TM) as ?hirakimasu?
(open).
How-ever, the proposed method incorrectly judged it as?oujite-imasuga?
(offer).
Both analysis results canbe considered to be correct semantically, but from4Since Japanese is head-final, the second last bunsetsu un-ambiguously depends on the last bunsetsu, and the last bunsetsuhas no dependency.181?
?
(1) mizu-ga takai tokoro-kara hikui tokoro-he nagareru.water-nom high ground-abl low ground-all flow(Water flows from high ground to low ground.)?
?
(2) ... Kobe shi-ga senmonchishiki-wo motsu volunteer-wo bosyushita ...Kobe city-nom expert knowledge-acc have volunteer-acc recruited(Kobe city recruited a volunteer who has expert knowledge, ...)??
(3) iin-wa, jitaku-de minasan-karano gosoudan-ni oujite-imasuga, ... soudansyo-wo hirakimasucommissioner-TM at home all of you consultation-dat offer window open(the commissioner offers consultation to all of you at home, but opens a window ...)Figure 3: Examples of analysis results.Table 4: Experimental results for case structure anal-ysis.baseline proposedTM 72/105 (68.6%) 82/105 (78.1%)clause 107/155 (69.0%) 121/155 (78.1%)the viewpoint of our annotation criteria, the latter isnot a syntactic relation, but an ellipsis relation.
Toaddress this problem, it is necessary to simultane-ously evaluate not only syntactic relations but alsoindirect relations, such as ellipses and anaphora.Linear weighting on each probabilityWe proposed a generative probabilistic model,and thus cannot optimize the weight of each proba-bility.
Such optimization could be a way to improvethe system performance.
In the future, we plan toemploy a machine learning technique for the opti-mization.4.2 Experiments for Case StructureWe applied case structure analysis to 215 web sen-tences which are manually annotated with casestructure, and evaluated case markers of TM phrasesand clausal modifiees by comparing them with thegold standard in the corpus.
The experimental re-sults are shown in table 4, in which the baselinerefers to a similarity-based method (Kawahara andKurohashi, 2002).
The experimental results were re-ally good compared to the baseline.
It is difficult tocompare the results with the previous work stated inthe next section, because of different experimentalsettings (e.g., our evaluation includes parse errors inincorrect cases).5 Related WorkThere have been several approaches for syntacticanalysis handling lexical preference on a large scale.Shirai et al proposed a PGLR-based syntacticanalysis method using large-scale lexical preference(Shirai et al, 1998).
Their system learned lexicalpreference from a large newspaper corpus (articlesof five years), such as P (pie|wo, taberu), but didnot deal with verb sense ambiguity.
They reported84.34% accuracy on 500 relatively short sentencesfrom the Kyoto Text Corpus.Fujio and Matsumoto presented a syntactic anal-ysis method based on lexical statistics (Fujio andMatsumoto, 1998).
They made use of a probabilisticmodel defined by the product of a probability of hav-ing a dependency between two cooccurring wordsand a distance probability.
The model was trainedon the EDR corpus, and performed with 86.89% ac-curacy on 10,000 sentences from the EDR corpus 5.On the other hand, there have been a numberof machine learning-based approaches using lexicalpreference as their features.
Among these, Kudoand Matsumoto yielded the best performance (Kudoand Matsumoto, 2002).
They proposed a chunking-based dependency analysis method using SupportVector Machines.
They used two-fold cross valida-tion on the Kyoto Text Corpus, and achieved 90.46%5The evaluation includes the last dependencies in the sen-tence end, which are always correct.182accuracy 5.
However, it is very hard to learn suffi-cient lexical preference from several tens of thou-sands sentences of a hand-tagged corpus.There has been some related work analyzingclausal modifiees and TM phrases.
For exam-ple, Torisawa analyzed TM phrases using predicate-argument cooccurences and word classifications in-duced by the EM algorithm (Torisawa, 2001).
Itsaccuracy was approximately 88% for ?wa?
and 84%for ?mo?.
It is difficult to compare the accuracyof their system to ours, because the range of tar-get expressions is different.
Unlike related work,it is promising to utilize the resultant case framesfor subsequent analyzes such as ellipsis or discourseanalysis.6 ConclusionWe have described an integrated probabilistic modelfor syntactic and case structure analysis.
This modeltakes advantage of lexical selectional preference oflarge-scale case frames, and performs syntactic andcase analysis simultaneously.
The experiments indi-cated the effectiveness of our model.
In the future,by incorporating ellipsis resolution, we will developan integrated model of syntactic, case and ellipsisanalysis.ReferencesCollin Baker, Charles Fillmore, and John Lowe.
1998.
TheBerkeley FrameNet Project.
In Proceedings of the 17th In-ternational Conference on Computational Linguistics andthe 36th Annual Meeting of the Association for Computa-tional Linguistics, pages 86?90.Daniel M. Bikel.
2004.
Intricacies of Collins?
parsing model.Computational Linguistics, 30(4):479?511.Don Blaheta and Eugene Charniak.
2000.
Assigning functiontags to parsed text.
In Proceedings of the 1st Meeting ofthe North American Chapter of the Association for Compu-tational Linguistics, pages 234?240.Eugene Charniak.
2000.
A maximum-entropy-inspired parser.In Proceedings of the 1st Meeting of the North AmericanChapter of the Association for Computational Linguistics,pages 132?139.Michael Collins.
1999.
Head-Driven Statistical Models forNatural Language Parsing.
Ph.D. thesis, University ofPennsylvania.Masakazu Fujio and Yuji Matsumoto.
1998.
Japanese depen-dency structure analysis based on lexicalized statistics.
InProceedings of the 3rd Conference on Empirical Methods inNatural Language Processing, pages 88?96.Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai, AkioYokoo, Hiromi Nakaiwa, Kentarou Ogura, YoshifumiOyama, and Yoshihiko Hayashi, editors.
1997.
JapaneseLexicon.
Iwanami Publishing.Daisuke Kawahara and Sadao Kurohashi.
1999.
Corpus-baseddependency analysis of Japanese sentences using verb bun-setsu transitivity.
In Proceedings of the 5th Natural Lan-guage Processing Pacific Rim Symposium, pages 387?391.Daisuke Kawahara and Sadao Kurohashi.
2002.
Fertilization ofcase frame dictionary for robust Japanese case analysis.
InProceedings of the 19th International Conference on Com-putational Linguistics, pages 425?431.Daisuke Kawahara and Sadao Kurohashi.
2006.
Case framecompilation from the web using high-performance comput-ing.
In Proceedings of the 5th International Conference onLanguage Resources and Evaluation.Daisuke Kawahara, Sadao Kurohashi, and Ko?iti Hasida.
2002.Construction of a Japanese relevance-tagged corpus.
In Pro-ceedings of the 3rd International Conference on LanguageResources and Evaluation, pages 2008?2013.Paul Kingsbury, Martha Palmer, and Mitch Marcus.
2002.Adding semantic annotation to the Penn TreeBank.
In Pro-ceedings of the Human Language Technology Conference.Dan Klein and Christopher D. Manning.
2003.
Accurate un-lexicalized parsing.
In Proceedings of the 41st Annual Meet-ing of the Association for Computational Linguistics, pages423?430.Taku Kudo and Yuji Matsumoto.
2002.
Japanese dependencyanalysis using cascaded chunking.
In Proceedings of theConference on Natural Language Learning, pages 29?35.Sadao Kurohashi and Makoto Nagao.
1994.
A syntactic anal-ysis method of long Japanese sentences based on the detec-tion of conjunctive structures.
Computational Linguistics,20(4):507?534.Sadao Kurohashi, Toshihisa Nakamura, Yuji Matsumoto, andMakoto Nagao.
1994.
Improvements of Japanese morpho-logical analyzer JUMAN.
In Proceedings of the Interna-tional Workshop on Sharable Natural Language, pages 22?28.Kiyoaki Shirai, Kentaro Inui, Takenobu Tokunaga, and HozumiTanaka.
1998.
An empirical evaluation on statistical parsingof Japanese sentences using lexical association statistics.
InProceedings of the 3rd Conference on Empirical Methods inNatural Language Processing, pages 80?87.Kentaro Torisawa.
2001.
An unsupervised method for canon-icalization of Japanese postpositions.
In Proceedings of the6th Natural Language Processing Pacific Rim Simposium,pages 211?218.Kiyotaka Uchimoto, Masaki Murata, Satoshi Sekine, and Hi-toshi Isahara.
2000.
Dependency model using posteriorcontext.
In Proceedings of the 6th International Workshopon Parsing Technology, pages 321?322.183
