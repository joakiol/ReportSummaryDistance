Proceedings of the SIGDIAL 2013 Conference, pages 363?365,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsDemonstration of the Emote Wizard of Oz Interface for EmpathicRobotic TutorsShweta Bhargava1, Srinivasan Janarthanam1, Helen Hastie1, Amol Deshmukh1,Ruth Aylett1, Lee Corrigan2, Ginevra Castellano 21School of Mathematical and Computer Sciences, Heriot-Watt University, Edinburgh2School of Electronic, Electrical and Computer Engineering, University of Birminghamsb426,sc445,h.hastie,a.deshmukh,r.s.aylett@hw.ac.uk,ljc228,g.castellano@bham.ac.ukAbstractWe present a Wizard of Oz (WoZ) envi-ronment that was designed to build an arti-ficial embodied intelligent tutoring system(ITS) that is capable of empathic conver-sations with school pupils aged between10-13.
We describe the components andthe data that we plan to collect using theenvironment.1 IntroductionWe present a Wizard of Oz (WoZ) environmentthat was built as a part of the EC FP7 EMOTEproject1.
The objective of this work is to col-lect multimodal interaction data to build an arti-ficial embodied intelligent tutoring system (ITS)that is capable of empathic conversations withschool pupils aged between 10-13.
Specifically,the EMOTE (EMbOdied-perceptive Tutors forEmpathy-based learning) project aims to designand evaluate a new generation of robotic tutorsthat have perceptive and expressive capabilitiesto engage in empathic interactions with learnersin schools and home environments.
The projectwill carry out interdisciplinary research on affectrecognition, learner models, adaptive behaviourand embodiment for human-robot interaction inlearning environments, grounded in psychologi-cal theories of emotion in social interaction andpedagogical models for learning facilitation.
Anoverview of the project can be found in (Desh-mukh et al 2013).Wizard of Oz is an effective technique in Hu-man Computer Interaction (HCI) studies wherean interactive agent, which is not yet fully au-tonomous, is remotely controlled by a human wiz-1http://emote-project.eu/ard.
However the participants who are interactingwith the agent are not told that the agent is beingremotely controlled.
The wizard may be taskedto control one or many parts of the agent suchas speech recognition and understanding, affectrecognition, dialogue management, utterance andgesture generation and so on.
Studies have shownthat users ?go easy?
on computers during inter-action and therefore interaction with ?wizarded?system are at the level of complexity that can belearned and emulated (Pearson et al 2006).The WoZ environment presented in this paperwill be used to collect data to inform the algo-rithms for affect recognition and empathic dia-logue management.
The WoZ environment is de-signed to collect data on how human tutors aidedwith a robotic interface adapt to learners?
emotionsand cognitive states in tutorial tasks.
In this study,the wizard plays the same role as that of affectrecognition and dialogue management modules inthe actual final system.2 Previous workWizard-of-Oz (WoZ) frameworks have been usedin several studies since (Fraser and Gilbert, 1991)in order to collect human-computer dialogue datato help design dialogue systems.
WoZ systemshave been used to collect data to learn (e.g.
(Strauss et al 2007)) and evaluate dialogue man-agement policies (e.g.
(Cuaya?huitl and Kruijff-Korbayova, 2012)).3 The EMOTE Wizard of OzenvironmentThe WoZ environment consists of the wizard?sdesk, the interactive touch table, sensors, and therobotic embodiment as shown in Figure 1.
The363wizard will be seated in a different room awayfrom the learner.Figure 1: Wizard of Oz environment3.1 Wizard?s deskThe wizard?s desk consists of two display screens.The touch table display at the user end will be mir-rored on to one of the displays at the wizard?s deskusing which the wizard can observe the learner?sactivities related to the educational application.Another display will contain the Wizard Interface,a software application that allows the wizard to in-teract with the learner (see Figure 2).
The Wiz-ard Interface consists of four panels: task control,information, learner response and operations.
Inthe task control panel, the wizard will beable to choose a task plan for the learner and ac-cess the tool and curriculum scripts (XML file).The tool script contains information on how to usethe tools that are at the disposal of the learner.
Forinstance, to create a marker on the map, one hasto click on the appropriate tool and click on themap and so on.
The curriculum script containsinformation on the skills that the learner needsto exercise or develop during his interaction withthe system.
For instance, in order to identify theright direction, the system will present the mneu-monic phrase ?Naughty Elephants Squirt Water?in various forms such as a hint, question, pump-ing move, etc.
to provide support to the learner.The information panel contains the videofeed from two cameras (see Section 3.4).
Thiswill allow the wizard to determine the affectivestate of the learner.
The learner?s response to theagent?s utterances (such as answering questions inthe curriculum scripts) will also be displayed inthe learner response panel.
Finally, theoperations panel provides options for theWizard to respond to the learner based on the toolsand curriculum scripts.
These responses are ei-ther customised or predefined.
The customisedresponses facilitate the wizard to execute robotmovements on lower level (individual head, armmovements) and predefined responses contain alist for combined predefined speech, sound and be-haviours.Figure 2: Wizard?s Interface3.2 Touch tableThe interactive touch table is a 55 inch Multitac-tion table capable of sensing multiple touch eventssimultaneously.
The educational application isdisplayed on the table surface.
A map based appli-cation has been developed to teach learners basicand advanced map reading skills (see Figure 3).The touch interface allows the learner to use touchto click, drag and zoom the map.
The applicationhas two panels of GUI objects such as buttons andtext boxes namely, the tools panel and the interac-tion panel.
The tools panel consists of tools thatthe learner can use to manipulate the map, whileusing the interaction panel the learner can interactwith the tutor.
Some of the tools that are currentlyavailable are to get grid references for a positionon the map, dropping markers on the map, changemap types, etc.
For instance, if the tutor asks ayes/no question, the learner can respond by press-ing the yes or the no button.
The learner can an-swer the tutor?s questions by typing into the textbox in the interaction panel.364Figure 3: Map reading skills application3.3 Robotic embodimentThe robotic embodiment is a Nao robot (torso ver-sion) that sits on the side of the touch table.
It iscapable of head, arm and body gestures in addi-tion to synthesised speech.
The robot receives thetext and gestures selected by the wizard throughthe Wizard Interface.
Tutor?s utterances will besynthesized into speech using the in-built text tospeech (TTS) engine while the gestures are re-alised using appropriate head, arm and body mo-tions.
To increase naturalness, the robot will alsohave idle movement in-between wizard selections.3.4 SensorsThe environment has an array of sensors such astwo video cameras and a Kinect sensor.
A Kinectsensor and a video camera are placed in front thelearner.
Another camera is placed in front of therobot (as shown in Figure 1).4 Data collectionIn this section, we discuss the data that we aimto collect using the WoZ environment.
We intendto collect these data during experiments where hu-man tutors play the wizard?s role and the learnersfrom in the 10-13 year age-range will play the roleof learners.
The task for the learner is to carryout an expedition using the map application thathe or she is provided with.
In order to solve thesteps of the expedition, the learner will have toexercise his/her map reading skills.
Map readingskills such as compass directions, contour lines,grid lines, etc.
will have to be exercised usingappropriate map tools provided in the application.The tutor?s role is to observe the learner responses(both verbal and physical) and respond to them ap-propriately using the interaction panel in the Wiz-ard Interface application.Simultaneous video feeds from two camerasand the Kinect sensor will be recorded during thetutor-learner interaction.
These data will be fur-ther used for affect recognition tasks based onlearner?s head, arm and body gestures.
The inter-action between the tutor and the learner in termsof tutor dialogue actions, utterances and learnerresponses in terms of button presses will also belogged.5 DemoWe propose to demonstrate the WoZ environmentset up using two laptops: learner desktop with themap application and another with the wizard?s in-terface.
The learner desktop will also display asimulated Nao robot.
We will also exhibit the logsthat we collect from the pilot studies with a Geogr-phy teacher acting as the wizard tutor and schoolpupils as tutees.AcknowledgementsThis work was partially supported by the Euro-pean Commission (EC) and was funded by theEU FP7 ICT-317923 project EMOTE.
The authorsare solely responsible for the content of this pub-lication.
It does not represent the opinion of theEC, and the EC is not responsible for any use thatmight be made of data appearing therein.ReferencesH.
Cuaya?huitl and I Kruijff-Korbayova.
2012.
An In-teractive Humanoid Robot Exhibiting Flexible Sub-Dialogues.
In Proceedings of the NAACL-HTL,Montreal, Canada.A.
Deshmukh, G. Castellano, A. Kappas, W. Baren-dregt, F. Nabais, A. Paiva, T. Ribeiro, I. Leite, andR.
Aylett.
2013.
Towards empathic artificial tutors.In Proceedings of the 8th ACM/IEEE internationalconference on Human-robot interaction.N.
Fraser and G. N. Gilbert.
1991.
Simulating speechsystems.
Computer Speech and Language, 5:81?99.J.
Pearson, J. Hu, H. P. Branigan, M. J. Pickering, andC.
Nass.
2006.
Adaptive language behavior in HCI:how expectations and beliefs about a system affectusers?
word choice.
In Proceedings of the SIGCHIconference on Human Factors in computing systems,Montral.P.
M. Strauss, H. Hoffmann, and S. Scherer.
2007.Evaluation and user acceptance of a dialogue sys-tem using Wizard-of-Oz recordings.
In Proceedingsof 3rd IET International Conference on IntelligentEnvironments.365
