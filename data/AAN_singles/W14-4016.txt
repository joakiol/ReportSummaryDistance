Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 135?137,October 25, 2014, Doha, Qatar.
c?2014 Association for Computational LinguisticsContext Sense Clustering for TranslationJo?o CasteleiroUniversidade Nova de LisboaDepartamento de Inform?tica2829-516 Caparica, Portugalcasteleiroalves@gmail.comGabriel LopesUniversidade Nova de LisboaDepartamento de Inform?tica2829-516 Caparica, Portugalgpl@fct.unl.ptJoaquim SilvaUniversidade Nova de LisboaDepartamento de Inform?tica2829-516 Caparica, Portugaljfs@fct.unl.ptExtended AbstractWord sense ambiguity is present in all wordswith more than one meaning in several naturallanguages and is a fundamental characteristic ofhuman language.
This has consequences in trans-lation as it is necessary to find the right sense andthe correct translation for each word.
For thisreason, the English word fair can mean reasona-ble or market such as plant also can mean factoryor herb.The disambiguation problem has been recog-nize as a major problem in natural languagesprocessing research.
Several words have severalmeanings or senses.
The disambiguation taskseeks to find out which sense of an ambiguousword is invoked in a particular use of that word.A system for automatic translation from Englishto Portuguese should know how to translate theword bank as banco (an institution for receiving,lending, exchanging, and safeguarding money),and as margem (the land alongside or slopingdown to a river or lake), and also should knowthat the word banana may appear in the samecontext as acerola and that these two belongs tohyperonym fruit.
Whenever a translation systemsdepends on the meaning of the text being pro-cessed, disambiguation is beneficial or even nec-essary.
Word Sense Disambiguation is thus es-sentially a classification problem; given a word Xand an inventory of possible semantic tags forthat word that might be translation, we seekwhich tag is appropriate for each individual in-stance of that word in a particularly context.In recent years research in the field hasevolved in different directions.
Several studiesthat combine clustering processes with wordsenses has been assessed by several.
Apidianakiin (2010) presents a clustering algorithm forcross-lingual sense induction that generates bi-lingual semantic inventories from parallel corpo-ra.
Li and Church in (2007) state that should notbe necessary to look at the entire corpus to knowif two words are strongly associated or not, thus,they proposed an algorithm for efficiently com-puting word associations.
In (Bansal et al.,2012), authors proposed an unsupervised methodfor clustering translations of words throughpoint-wise mutual information, based on a mono-lingual and a parallel corpora.
Gamallo, Agustiniand Lopes presented in (2005) an unsupervisedstrategy to partially acquire syntactic-semanticrequirements of nouns, verbs and adjectives frompartially parsed monolingual text corpora.
Thegoal is to identify clusters of similar positions byidentifying the words that define their require-ments extensionally.
In (1991) Brown et al.
de-scribed a statistical technique for assigning sens-es to words based on the context in which theyappear.
Incorporating the method in a machinetranslation system, they have achieved to signifi-cantly reduce translation error rate.
Tufis et al.
in(2004) presented a method that exploits wordclustering based on automatic extraction of trans-lation equivalents, being supported by availablealigned wordnets.
In (2013), Apidianaki de-scribed a system for SemEval-2013 Cross-lingual Word Sense Disambiguation task, whereword senses are represented by means of transla-tion clusters in a cross-lingual strategy.In this article, a Sense Disambiguation ap-proach, using Context Sense Clustering, within amono-lingual strategy of neighbor features isproposed.
We described a semi-supervised meth-od to classify words based on clusters of contextsstrongly correlated.
For this purpose, we used acovariance-based correlation measure (Equation1).
Covariance (Equation 2) measure how muchtwo random variables change together.
If thevalues of one variable (sense x) mainly corre-spond to the values of the other variable (sensey), the variables tend to show similar behavior135and the covariance is positive.
In the oppositecase, covariance is negative.
Note that this pro-cess is computationally heavy.
The system needsto compute all relations between all features ofall left words.
If the number of features is verylarge, the processing time increases proportional-ly.?)
???
?, ?)
=  ?
)??
?, ?
)??)??
?, ?)
+ ??)??
?, ?)(1)?)??
?, ?)
= 1?
?
1 ?
(???)?
?, ?).
???)?
?, ?))??????
(2)Our goal is to join similar senses of the sameambiguous word in the same cluster, based onfeatures correlation.
Through the analysis of cor-relation data, we easily induce sense relations.
Inorder to streamline the task of creating clusters,we opted to use WEKA tool (Hall et al., 2009)with X-means (Pelleg et al., 2000) algorithm.Clustersfructose, glucosefootball, chesstitle, appendix, annextelephone, faxliver, hepatic, kidneyaquatic, marinedisciplinary, infringement, criminalTable 1.
Well-formed resulting clustersIn order to determine the consistence of theobtained clusters, all of these were evaluatedwith V-measure.
V-measure introduce two crite-ria presented in (Rosenberg and Hirschberg,2007), homogeneity (h) and completeness (c).
Aclustering process is considered homogeneouslywell-formed if all of its clusters contain only datapoints which are members of a single class.Comparatively, a clustering result satisfies com-pleteness if all data points that are members of agiven class are elements of the same cluster.Analysing the results of context sense clustersobtained (Table 1) we easily understand that al-most all clusters are generally well formed, get-ting a final V-measure average rating of 67%.Finally, in order to train a classifier we chooseto use a training data set with 60 well formedclusters (with V-measure value ranging between0.9 and 1).
Our testing data set is composed by60 words related to the clusters but which are notcontained there.
The classifier used was a Sup-port Vector Machine (SVM) (2011).
The kerneltype applied was the Radial Basis Function(RBF).
This kernel non linearly maps samplesinto a higher dimensional space, so it can handlethe case when the relation between class labelsand attributes is nonlinear, that is the case.
Eachword of training and testing data sets were en-coded according the frequency in a corpora of allcharacteristics contained in the clusters.
Our pur-pose was to classify each one of the new poten-tial ambiguous words, and fit it in the corre-sponding cluster (Table 2 and Table 3).Test Words Label assigned by (SVM)Fruit Cluster 29Infectious Cluster 7Kiwi Cluster 60Back Cluster 57Legislative Cluster 34Grape Cluster 29Russian Cluster 59Table 2.
Results generated by (SVM)Clusters Content of ClustersCluster 7 Viral, contagious, hepaticCluster 29 Banana, appleCluster 34 Legal, criminal, infringementCluster 57 Cervical, lumbarCluster 59 French, Italian, Belgian, GermanCluster 60 Thyroid, mammaryTable 3.
Cluster correspondenceThe obtained results showed that almost allwords were tagged in the corresponding cluster.Evaluating system accuracy we obtained an av-erage value of 78%, which means that from the60 tested words, 47 words were assigned to thecorresponding context cluster.136ReferencesMarianna Apidianaki, Yifan He, et al.
2010.
Analgorithm for cross-lingual sense-clusteringtested in a mt evaluation setting.
In Proceed-ings of the International Workshop on SpokenLanguage Translation, pages 219?226.Li, P., Church, K.W.
: A sketch algorithm for es-timating two-way and multi-way associations.Computational Linguistics 33 (3), 305 - 354(2007).Bansal, M., DeNero, J., Lin, D.: Unsupervisedtranslation sense clustering.
In: Proceedings ofthe 2012 Conference of the North AmericanChapter of the Association for ComputationalLinguistics: Human Language Technologies.pp.
773-782.
Association for ComputationalLinguistics (2012).Gamallo, P., Agustini, A., Lopes, G.P.
: Cluster-ing syntactic positions with similar semanticrequirements.
Computational Linguistics31(1), 107-146 (2005).Brown, P.F., Pietra, S.A.D., Pietra, V.J.D., Mer-cer, R.L.
: Word-sense disambiguation usingstatistical methods.
In: Proceedings of the 29thannual meeting on Association for Computa-tional Linguistics.
pp.
264-270.
Associationfor Computational Linguistics (1991).TufiS, D., Ion, R., Ide, N.: Fine-grained wordsense disambiguation based on parallel corpo-ra, word alignment, word clustering andaligned wordnets.
In: Proceedings of the 20thinternational conference on ComputationalLinguistics.
p. 1312.
Association for Compu-tational Linguistics (2004).Apidianaki, M.: Cross-lingual word sense dis-ambiguation using translation sense clustering.In: Proceedings of the 7th International Work-shop on Semantic Evaluation (SemEval 2013).pp.
178-182.
*SEM and NAACL (2013)Mark Hall, Eibe Frank, Geoffrey Holmes, Bern-hard Pfahringer, Peter Reutemann, and Ian HWitten.
2009.
The weka data mining software:an update.
ACM SIGKDD ExplorationsNewsletter, 11(1):10?18.Dan Pelleg, Andrew W Moore, et al.
2000.
X-means: Extending k-means with efficient es-timation of the number of clusters.
In ICML,pages 727?734.Andrew Rosenberg and Julia Hirschberg.
2007.Vmeasure: A conditional entropy-based exter-nal cluster evaluation measure.
In EMNLP-CoNLL, volume 7, pages 410?420.Chih-Chung Chang and Chih-Jen Lin.
2011.Libsvm: a library for support vector machines.ACM Transactions on Intelligent Systems andTechnology (TIST), 2(3):27.137
