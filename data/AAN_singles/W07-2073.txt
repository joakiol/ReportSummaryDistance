Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 338?341,Prague, June 2007. c?2007 Association for Computational LinguisticsUA-ZSA: Web Page Clustering on the basis of Name DisambiguationZornitsa Kozareva, Sonia Vazquez, Andres MontoyoDLSI, University of AlicanteCarretera de San Vicente S/NAlicante, Spain03080zkozareva,svazquez,montoyo@dlsi.ua.esAbstractThis paper presents an approach for webpage clustering.
The different underlyingmeanings of a name are discovered on thebasis of the title of the web page, the bodycontent, the common named entities acrossthe documents and the sub-links.
This in-formation is feeded into a K-Means cluster-ing algorithm which groups together the webpages that refer to the same individual.1 IntroductionAmbiguity is the task of building up multiple alter-native linguistic structures for a single input.
Mostof the approaches focus on word sense disambigua-tion (WSD), where the sense of a word has to bedetermined depending on the context in which it isused.The same problem arises for named entitiesshared by different people or for grandsons namedafter their grandparents.
For instance, querying thename ?Michael Hammond?
in the World Wide Webwhere there are huge quantities of massive and un-structured data, a search engine retrieves thousandsof documents related to this name.
However, thereare several individuals sharing the name ?MichaelHammon?.
One is a biology professor at the Univer-sity of Arizona, another is at the University of War-wick, there is a mathematician from Toronto amongothers.
The question is which one of these refer-ents we are actually looking for and interested in.Presently, to be able to answer to this question, wehave to skim the content of the documents and re-trieve the correct answers on our own.To automate this process, the named entitiescan be disambiguated and the different underlyingmeanings of the name can be found.
On the basisof this information, the web pages can be clusteredtogether and organized in a hierarchical structurewhich can ease the documents?
browsing.
This isalso the objective of the Web People Search (WePS)task (Artiles et al, 2007).
What makes the WePStask even more challenging is the fact that in con-trast to WSD where the number of senses of a wordare predefined, in WePS we do not know the exactnumber of different individuals.For the resolution of the WePS task, we have de-veloped a web page clustering approach using thetitle and the body content of the web pages.
In ad-dition, we group together the documents that sharemany location, person and organization names, aswell as those that point out to the same sub-links.The rest of the paper is organized as follows.
InSection 2 we describe various approaches for namedisambiguation and discrimination.
Our approachis shown in Section 3, the obtained results and a dis-cussion are provided in Section 4 and finally we con-clude in Section 5.2 Related WorkEarly work in the field of name disambiguationis that of (Bagga and Baldwin, 1998) who pro-posed cross-document coreference resolution algo-rithm which uses vector space model to resolve theambiguities between people sharing the same name.The approach is evaluated on 35 different mentionsof John Smith and reaches 85% f-score.Mann and Yarowski (2003) developed an unsu-338HTML/XML cleaningSearchWebRetrieved DocumentsPreprocessingTitleContext informationBodyText Proper namesLinksClustersK-means Cluster analysis WEKALSA matrix transformationClusteringOn the basis of name disambiguationMatrix from contextFigure 1: Architecture of the WePS Systempervised approach to name discrimination where bi-ographical features (age, date of birth), familiar re-lationships (wife, son, daughter) and associations(country, company, organization) are considered.Therefore, in our approach we use person, organiza-tion and location names in order to construct a socialsimilarity network between two documents.Another unsupervised clustering technique forname discrimination of web pages is that of Peder-sen and Kulkarni (2007).
They used contextual vec-tors derived from bigrams, and measured the impactof several association measures.
During the evalu-ation, some names were easily discriminable com-pared to others categories for which was even diffi-cult to find and obtain discriminative feature.
Weworked with their unigram model (Purandare andPedersen, 2004) to cluster the web pages using thetext content between the title tags.3 Web Person DisambiguationOur web people clustering approach is presented inFigure 1 and consists of the following steps:?
HTML cleaning: all html tags are strippedaway, the javascript code is eliminated, the nonclosed WePS tags are repaired, the missing be-gin/end body tags are included and then thecontent between the title, the body and the an-chor tags is extracted.?
name matching: the location, person and orga-nization names in the body texts are identifiedwith the GATE1 system (Cunningham, 2005).Each named entity of a document is matchedwith its corresponding named entity categoryfrom the rest of the web pages.
This infor-mation is used to calculate the social semanticsimilarity of the person, the location and the or-ganization names.
Our hypothesis is that doc-uments with similar names tend to refer to thesame individual.
The output of this module isa matrix with binary values, where 1 stands forthe documents which share more than the halfof their proper names, and 0 otherwise.?
links: for each document, we extract the linkssituated between the anchor tags.
Since thelinks are too specific, we wrote an url functionwhich transform a given web page d1 with URLhttp://www.cs.ualberta.ca/?lindek/index.htminto www.cs.ualberta.ca/?lindek,and the web page d2 with URLhttp://www.cs.ualberta.ca/?lindek/demos.htminto www.cs.ualberta.ca/?lindek.
Accordingto our approach, the two web pages d1 and d2are linked to each other if their link structures(LS) intersect, that is LS(d1)?LS(d2) 6= 0.The output of this module is a matrix withbinary values, where 1 stands for two webpages having more than 3 links in common and0 otherwise.?
titles: for each document, we extract the textbetween the title tags.
We create a unigrammatrix which is feed into SenseClusters2.
Weuse automatic cluster stopping criteria with thegap statistics which groups the web pages intoseveral clusters according to the context of thetitles.
From the obtained clusters, we generatea new matrix with binary values, where 1 corre-sponds to the documents which were put in the1http://sourceforge.net/projects/gate2http://marimba.d.umn.edu/cgi-bin/SC-cgi/index.cgi339same cluster according to SenseClusters and 0otherwise.?
bodies: the text between the body tags is ex-tracted, tokenized and the part-of-speech (POS)tags 3 are determined.
The original text is trans-formed by encoding the POS tag information asfollows: ?water#v the#det flowers#n and#conjpass#v me#pron the#det glass#n of#prep wa-ter#n?.
This corpus transformation is done, be-cause we want the Latent Semantic Analysis(LSA) module to consider the syntactic cate-gories of the words and to construct a morereliable semantic space.
For instance, in theexample above, there are two different repre-sentations of water: the noun and the verb,while without the corpus transformation LSAsees only the string water.?
LSA4: the semantic similarity score for theweb-pages is calculated with Latent SemanticAnalysis (LSA).
From the encoded body texts,we build up a matrix, where the rows repre-sent the words of the web-page collection, thecolumns stand for the web-pages we want tocluster and the cells show the number of times aword of the corpus occurs in a web page.
In or-der to reduce the noise and the data sparsity, weapply the Singular Value Decomposition algo-rithm by reducing the original vector space into300 dimensions.
The output of the LSA mod-ule is a matrix, which represents the semanticsimilarity among the web pages.?
knowledge combination: the outputs of thename matching, link, title and body modulesare combined into a new matrix 100 ?
400 di-mensional matrix.
The rows correspond to thenumber of web pages and the columns repre-sent the obtained values of the link, title, bodyand name modules.
This matrix is fed intothe K-means clustering algorithm which deter-mines the final web page clustering.?
K-means5: the clustering of N web pagesinto K disjoint subsets Sj containing Nj data3http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/4infomap-nlp.sourceforge.net/5http://www.cs.waikato.ac.nz/ml/weka/points is done by the minimization of the sum-of-squares criterion J = ?Kj=1?n?Sj |xn ?muj |2, where xn is a vector representing thenth data point and muj is the geometric cen-troid of the data points in Sj .
The informa-tion matrix from which the web page cluster-ing is performed includes the similarity infor-mation for the title, link, proper name and body.The current implementation of K-means (Wit-ten and Frank, 2005) does not have an au-tomatic cluster stopping criteria, therefore thenumber of clusters is set up manually.4 Results and DiscussionTable 1 shows the obtained results for the test dataset.
The average performance of our system is 56%and we ranked on 10-th position from 16 participat-ing teams.
Although, we have used different sourcesof information and various approximations, in thefuture we have to surmount a number of obstacles.One of the limitations comes from the usage of thetext snippets situated between the body tags.
Thereare a number of web pages which do not contain anytext.
The semantic space for these documents cannotbe built with LSA and their similarity score is zero.Despite the fact that we have eliminated the stopwords from the documents and we have transformedthe web pages by encoding the syntactic categories,the classification power of LSA was different for theambiguous names and for the web pages.
To someextend this is due to the varying number of wordsin the web pages.
In the future, we want to con-duct experiments with a fixed context windows forall documents.In this task, the number of senses (e.g.
numberof different individuals that share the same name)is unknown, and one of the major drawbacks in ourapproach is related to the setting up of the numberof clusters.
The K-Means clustering algorithm weused, did not include an automatic cluster stoppingcriteria, and we had to set up the number of clus-ters manually.
To be able to do that, we have ob-served the average number of clusters per name inthe trial data.
We have evaluated the performanceof our approach with several different numbers ofclusters.
According to the obtained results, the bestclusters are 25 and 50.
We used the same number340Name Purity InversePurityF?=0.5F?=0.2Mark Johnson 0,55 0,74 0,63 0,69Sharon Goldwater 0,96 0,23 0,37 0,27Robert Moore 0,36 0,67 0,47 0,57Leon Barrett 0,62 0,51 0,56 0,52Dekang Lin 0,99 0,43 0,60 0,49Stephen Clark 0,52 0,75 0,62 0,69Frank Keller 0,38 0,67 0,48 0,58Jerry Hobbs 0,54 0,63 0,58 0,61James Curran 0,53 0,61 0,57 0,59Chris Brockett 0,73 0,40 0,51 0,44Thomas Fraser 0,66 0,57 0,61 0,58John Nelson 0,68 0,76 0,72 0,74James Hamilton 0,56 0,60 0,58 0,59William Dickson 0,59 0,78 0,67 0,73James Morehead 0,36 0,64 0,46 0,56Patrick Killen 0,56 0,69 0,62 0,66George Foster 0,46 0,70 0,56 0,64James Davidson 0,58 0,71 0,64 0,68Arthur Morgan 0,77 0,47 0,59 0,51Thomas Kirk 0,26 0,90 0,41 0,60Patrick Killen 0,56 0,69 0,62 0,66Harry Hughes 0,66 0,54 0,59 0,56Jude Brown 0,64 0,63 0,64 0,63Stephan Johnson 0,56 0,80 0,66 0,73Marcy Jackson 0,40 0,73 0,52 0,63Karen Peterson 0,56 0,72 0,63 0,68Neil Clark 0,68 0,36 0,47 0,40Jonathan Brooks 0,53 0,76 0,63 0,70Violet Howard 0,58 0,75 0,65 0,71Global average 0,58 0,64 0,58 0,60Table 1: Evaluation resultsof clusters for the test data, however this is a roughparameter estimation.5 ConclusionPerson name disambiguation is a very important taskwhose resolution can improve the performance ofthe search engine by grouping together web pageswhich refer to different individuals that share thesame name.For our participation in the WePS task, we pre-sented a name disambiguation approach which usesonly the information extracted from the web pages.We conducted an experimental study with the traildata set, according to which the combination ofthe title, the body, the proper names and sub-linksreaches the best performance.
Our current approachcan be improved with the incorporation of automaticcluster stopping criteria.So far we did not take advantage of the documentranking and the returned snippets, but we want to in-corporate this information by measuring the snippetsimilarity on the basis of relevant domain informa-tion (Kozareva et al, 2007).AcknowledgementsMany thanks to Ted Pedersen for useful commentsand suggestions.
This work was partially fundedby the European Union under the project QALLMEnumber FP6 IST-033860 and by the Spanish Min-istry of Science and Technology under the projectTEX-MESS number TIN2006-15265-C06-01.ReferencesJ.
Artiles, J. Gonzalo, and S. Sekine.
2007.
The semeval-2007 weps evaluation: Establishing a benchmark forthe web people search task.
In Proceedings of Semeval2007, Association for Computational Linguistics.A.
Bagga and B. Baldwin.
1998.
Entity-based cross-document coreferencing using the vector space model.In Proceedings of ACL, pages 79?85.H.
Cunningham.
2005.
Information Extraction, Auto-matic.
Encyclopedia of Language and Linguistics, 2ndEdition.Z.
Kozareva, S. Vazquez, and A. Montoyo.
2007.
Theusefulness of conceptual representation for the iden-tification of semantic variability expressions.
In Pro-ceedings of the Eighth International Conference on In-telligent Text Processing and Computational Linguis-tics, (CICLing-2007).G.
Mann and D. Yarowsky.
2003.
Unsupervised per-sonal name disambiguation.
In Proceedings of the sev-enth conference on Natural language learning at HLT-NAACL 2003, pages 33?40.T.
Pedersen and A. Kulkarni.
2007.
Discovering identi-ties in web contexts with unsupervised clustering.
InProceedings of the IJCAI-2007 Workshop on Analyticsfor Noisy Unstructured Text Data.A.
Purandare and T. Pedersen.
2004.
Senseclusters -finding clusters that represent word senses.
In AAAI,pages 1030?1031.I.
Witten and E. Frank.
2005.
Data Mining: Practi-cal machine learning tools and techniques, volume 2.Morgan Kaufmann.341
