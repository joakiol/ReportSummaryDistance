Proceedings of the EACL 2009 Workshop on Computational Linguistic Aspects of Grammatical Inference, pages 7?15,Athens, Greece, 30 March 2009. c?2009 Association for Computational LinguisticsDialogue Act Prediction Using Stochastic Context-Free GrammarInductionJeroen GeertzenResearch Centre for English & Applied LinguisticsUniversity of Cambridge, UKjg532@cam.ac.ukAbstractThis paper presents a model-based ap-proach to dialogue management that isguided by data-driven dialogue act predic-tion.
The statistical prediction is based onstochastic context-free grammars that havebeen obtained by means of grammaticalinference.
The prediction performance ofthe method compares favourably to that ofa heuristic baseline and to that of n-gramlanguage models.The act prediction is explored both fordialogue acts without realised semanticcontent (consisting only of communicativefunctions) and for dialogue acts with re-alised semantic content.1 IntroductionDialogue management is the activity of determin-ing how to behave as an interlocutor at a specificmoment of time in a conversation: which actioncan or should be taken at what state of the dia-logue.
The systematic way in which an interlocu-tor chooses among the options for continuing a di-alogue is often called a dialogue strategy.Coming up with suitable dialogue managementstrategies for dialogue systems is not an easy task.Traditional methods typically involve manuallycrafting and tuning frames or hand-crafted rules,requiring considerable implementation time andcost.
More recently, statistical methods are be-ing used to semi-automatically obtain models thatcan be trained and optimised using dialogue data.1These methods are usually based on two assump-tions.
First, the training data is assumed to berepresentative of the communication that may beencountered in interaction.
Second, it is assumedthat dialogue can be modelled as a Markov De-cision Process (MDP) (Levin et al, 1998), which1See e.g.
(Young, 2002) for an overview.implies that dialogue is modelled as a sequentialdecision task in which each contribution (action)results in a transition from one state to another.The latter assumption allows to assign a rewardfor action-state pairs, and to determine the dia-logue management strategy that results in the max-imum expected reward by finding for each statethe optimal action by using reinforcement learn-ing (cf.
(Sutton and Barto, 1998)).
Reinforce-ment learning approaches to dialogue manage-ment have proven to be successful in several taskdomains (see for example (Paek, 2006; Lemon etal., 2006)).
In this process there is no supervision,but what is optimal depends usually on factors thatrequire human action, such as task completion oruser satisfaction.The remainder of this paper describes and eval-uates a model-based approach to dialogue man-agement in which the decision process of takinga particular action given a dialogue state is guidedby data-driven dialogue act prediction.
The ap-proach improves over n-gram language modelsand can be used in isolation or for user simula-tion, without yet providing a full alternative to re-inforcement learning.2 Using structural properties oftask-oriented dialogueOne of the best known regularities that are ob-served in dialogue are the two-part structures,known as adjacency pairs (Schegloff, 1968), likeQUESTION-ANSWER or GREETING-GREETING.A simple model of predicting a plausible nextdialogue act that deals with such regularities couldbe based on bigrams, and to include more contextalso higher-order n-grams could be used.
For in-stance, Stolcke et al (2000) explore n-gram mod-els based on transcribed words and prosodic in-formation for SWBD-DAMSL dialogue acts in theSwitchboard corpus (Godfrey et al, 1992).
Aftertraining back-off n-gram models (Katz, 1987) of7different order using frequency smoothing (Wittenand Bell, 1991), it was concluded that trigrams andhigher-order n-grams offer a small gain in predi-cation performance with respect to bigrams.Apart from adjacency pairs, there is a varietyof more complex re-occurring interaction patterns.For instance, the following utterances with cor-responding dialogue act types illustrate a clarifi-cation sub-dialogue within an information-requestdialogue:1 A: How do I do a fax?
QUESTION2 B: Do you want to send QUESTIONor print one?3 A: I want to print it ANSWER4 B: Just press the grey button ANSWERSuch structures have received considerable at-tention and their models are often referred to asdiscourse/dialogue grammars (Polanyi and Scha,1984) or conversational/dialogue games (Levinand Moore, 1988).As also remarked by Levin (1999), predict-ing and recognising dialogue games using n-grammodels is not really successful.
There are vari-ous causes for this.
The flat horizontal structure ofn-grams does not allow (hierarchical) grouping ofsymbols.
This may weaken the predictive powerand reduces the power of the representation sincenested structures such as exemplified above cannotbe represented in a straightforward way.A better solution would be to express the struc-ture of dialogue games by a context-free grammar(CFG) representation in which the terminals aredialogue acts and the non-terminals denote con-versational games.
Construction of a CFG wouldrequire explicit specification of a discourse gram-mar, which could be done by hand, but it would bea great advantage if CFGs could automatically beinduced from the data.
An additional advantageof grammar induction is the possibility to assessthe frequency of typical patterns and a stochasticcontext-free grammar (SCFG) may be producedwhich can be used for parsing the dialogue data.3 Sequencing dialogue actsBoth n-gram language models and SCFG basedmodels work on sequences of symbols.
Usingmore complex symbols increases data sparsity:encoding more information increases the numberof unique symbols in the dataset and decreasesthe number of reoccurring patterns which could beused in the prediction.In compiling the symbols for the prediction ex-periments, three aspects are important: the identi-fication of interlocutors, the definition of dialogueacts, and multifunctionality in dialogue.The dialogue act taxonomy that is used in theprediction experiments is that of DIT (Bunt, 2000).A dialogue act is defined as a pair consisting of acommunicative function (CF) and a semantic con-tent (SC): a =< CF,SC >.
The DIT taxonomydistinguishes 11 dimensions of communicativefunctions, addressing information about the taskdomain, feedback, turn management, and othergeneric aspects of dialogue (Bunt, 2006).
Thereare also functions, called the general-purposefunctions, that may occur in any dimension.
Inquite some cases, particularly when dialogue con-trol is addressed and dimension-specific functionsare realised, the SC is empty.
General-purposefunctions, by contrast, are always used in combi-nation with a realised SC.
For example:dialogue actutterance function semantic contentWhat to do next?
SET-QUESTION next-step(X)Press the button.
SET-ANSWER press(Y) ?button(Y)The SC ?if realised?
describes objects, prop-erties, and events in the domain of conversation.In dialogue act prediction while taking multi-dimensionality into account, a dialogue D can berepresented as a sequence of events in which anevent is a set of one dialogue act or multiple di-alogue acts occurring simultaneously.
The infor-mation concerning interlocutor and multifunction-ality is encoded in a single symbol and denoted bymeans of a n-tuple.
Assuming that at most threefunctions can occur simultaneously, a 4-tuple isneeded2: (interlocutor,da1,da2,da3).
An ex-ample of a bigram of 4-tuples would then look asfollows:(A,<SET-Q,"next-step(X)">, , ) ,(B,<SET-A,"press(Y) ?
button(Y)">, , )Two symbols are considered to be identical whenthe same speaker is involved and when the sym-bols both address the same functions.
To make2Ignoring the half percent of occurrences with four simul-taneous functions.8it easy to determine if two symbols are identical,the order of elements in a tuple is fixed: func-tions that occur simultaneously are first ordered onimportance of dimension, and subsequently on al-phabet.
The task-related functions are consideredthe most important, followed by feedback-relatedfunctions, followed by any other remaining func-tions.
This raises the question how recognitionperformance using multifunctional symbols com-pares against recognition performance using sym-bols that only encode the primary function4 N-gram language modelsThere exists a significant body of work on the useof language models in relation to dialogue man-agement.
Nagata and Morimoto (1994) describe astatistical model of discourse based on trigrams ofutterances classified by custom speech act types.They report 39.7% prediction accuracy for the topcandidate and 61.7% for the top three candidates.In the context of the dialogue component of thespeech-to-speech translation system VERBMO-BIL, Reithinger and Maier (1995) use n-gram dia-logue act probabilities to suggest the most likelydialogue act.
In later work, Alexandersson andReithinger (1997) describe an approach whichcomes close to the work reported in this paper: Us-ing grammar induction, plan operators are semi-automatically derived and combined with a statis-tical disambiguation component.
This system isclaimed to have an accuracy score of around 70%on turn management classes.Another study is that of Poesio and Mikheev(1998), in which prediction based on the previousdialogue act is compared with prediction based onthe context of dialogue games.
Using the MapTask corpus annotated with ?moves?
(dialogueacts) and ?transactions?
(games) they showed thatby using higher dialogue structures it was possi-ble to perform significantly better than a bigrammodel approach.
Using bigrams, 38.6% accuracywas achieved.
Additionally taking game structureinto account resulted in 50.6%; adding informa-tion about speaker change resulted in an accuracyof 41.8% with bigrams, 54% with game structure.All studies discussed so far are only concernedwith sequences of communicative functions, anddisregard the semantic content of dialogue acts.5 Dialogue grammarsTo automatically induce patterns from dialoguedata in an unsupervised way, grammatical infer-ence (GI) techniques can be used.
GI is a branchof unsupervised machine learning that aims to findstructure in symbolic sequential data.
In this case,the input of the GI algorithm will be sequences ofdialogue acts.5.1 Dialogue Grammars InducerFor the induction of structure, a GI algorithm hasbeen implemented that will be referred to as Dia-logue Grammars Inducer (DGI).
This algorithm isbased on distributional clustering and alignment-based learning (van Zaanen and Adriaans, 2001;van Zaanen, 2002; Geertzen and van Zaanen,2004).
Alignment-based learning (ABL) is a sym-bolic grammar inference framework that has suc-cessfully been applied to several unsupervised ma-chine learning tasks in natural language process-ing.
The framework accepts sequences with sym-bols, aligns them with each other, and comparesthem to find interchangeable subsequences thatmark structure.
As a result, the input sequencesare augmented with the induced structure.The DGI algorithm takes as input time series ofdialogue acts, and gives as output a set of SCFGs.The algorithm has five phases:1.
SEGMENTATION: In the first phase of DGI,the time series are ?if necessary?
seg-mented in smaller sequences based on a spe-cific time interval in which no communica-tion takes place.
This is a necessary step intask-oriented conversation in which there isample time to discuss (and carry out) severalrelated tasks, and an interaction often con-sists of a series of short dialogues.2.
ALIGNMENT LEARNING: In the secondphase a search space of possible structures,called hypotheses, is generated by compar-ing all input sequences with each other andby clustering sub-sequences that share simi-lar context.
To illustrate the alignment learn-ing, consider the following input sequences:A:SET-Q, B:PRO-Q, A:PRO-A, B:SET-A.A:SET-Q, B:PAUSE, B:RESUME, B:SET-A.A:SET-Q, B:SET-A.The alignment learning compares all inputsequences with each other, and produces the9hypothesised structures depicted below.
Theinduced structure is represented using brack-eting.
[i A:SET-Q, [j B:PRO-Q, A:PRO-A, ]j B:SET-A.
]i[i A:SET-Q, [j B:PAUSE, A:RESUME, ]j B:SET-A.
]i[i A:SET-Q, [j ]j B:SET-A.
]iThe hypothesis j is generated because of thesimilar context (which is underlined).
Thehypothesis i, the full span, is introduced bydefault, as it might be possible that the se-quence is in itself a part of a longer sequence.3.
SELECTION LEARNING: The set of hypothe-ses that is generated during alignment learn-ing contains hypotheses that are unlikely tobe correct.
These hypotheses are filtered out,overlapping hypotheses are eliminated to as-sure that it is possible to extract a context-free grammar, and the remaining hypothesesare selected and remain in the bracketed out-put.
The decision of which hypotheses to se-lect and which to discard is based on a Viterbibeam search (Viterbi, 1967).4.
EXTRACTION: In the fourth phase, SCFGgrammars are extracted from the remaininghypotheses by means of recursive descentparsing.
Ignoring the stochastic informa-tion, a CFG of the above-mentioned examplelooks in terms of grammar rules as depictedbelow:S ?
A:SET-Q J B:SET-AJ ?
B:PRO-Q A:PRO-AJ ?
B:PAUSE A:RESUMEJ ?
?5.
FILTERING: In the last phase, the SCFGgrammars that have small coverage or involvemany non-terminals are filtered out, and theremaining SCFG grammars are presented asthe output of DGI.Depending on the mode of working, the DGIalgorithm can generate a SCFG covering the com-plete input or can generate a set of SCFGs.
In theformer mode, the grammar that is generated can beused for parsing sequences of dialogue acts and bydoing so suggests ways to continue the dialogue.In the latter mode, by parsing each grammar in theset of grammars that are expected to represent di-alogue games in parallel, specific dialogue gamesmay be recognised, which can in turn be used ben-eficially in dialogue management.5.2 A worked exampleIn testing the algorithm, DGI has been used toinfer a set of SCFGs from a development set of250 utterances of the DIAMOND corpus (see alsoSection 6.1).
Already for this small dataset, DGIproduced, using default parameters, 45 ?dialoguegames?.
One of the largest produced structureswas the following:4 S ?
A:SET-Q , NTAX , NTBT , B:SET-A4 NTAX ?
B:PRO-Q , NTFJ3 NTFJ ?
A:PRO-A1 NTFJ ?
A:PRO-A , A:CLARIFY2 NTBT ?
B:PRO-Q , A:PRO-A2 NTBT ?
?In this figure, each CFG rule has a number in-dicating how many times the rules has been used.One of the dialogue fragments that was used to in-duce this structure is the following excerpt:utterance dialogue actA1 how do I do a short code?
SET-QB1 do you want to program one?
PRO-QA2 no SET-AA3 I want to enter a kie* a short code CLARIFYB2 you want to use a short code?
PRO-QA4 yes PRO-AB3 press the VK button SET-AUnfortunately, many of the 45 induced struc-tures were very small or involved generalisationsalready based on only two input samples.
To en-sure that the grammars produced by DGI gen-eralise better and are less fragmented, a post-processing step has been added which traversesthe grammars and eliminates generalisations basedon a low number of samples.
In practice, thismeans that the post-processing requires the re-maining grammatical structure to be presented Ntimes or more in the data.3.
The algorithm withoutpost-processing will be referred to as DGI1; thealgorithm with post-processing as DGI2.6 Act prediction experimentsTo determine how to behave as an interlocutor ata specific moment of time in a conversation, theDGI algorithm can be used to infer a SCFG thatmodels the structure of the interaction.
The SCFG3N = 2 by default, but may increase with the size of thetraining data.10can then be used to suggest a next dialogue actto continue the dialogue.
In this section, the per-formance of the proposed SCFG based dialoguemodel is compared with the performance of thewell-known n-gram language models, both trainedon intentional level, i.e.
on sequences of sets of di-alogue acts.6.1 DataThe task-oriented dialogues used in the dialogueact prediction tasks were drawn from the DIA-MOND corpus (Geertzen et al, 2004), which con-tains human-machine and human-human Dutchdialogues that have an assistance seeking na-ture.
The dataset used in the experiments con-tains 1, 214 utterances representing 1, 592 func-tional segments from the human-human part ofcorpus.
In the domain of the DIAMOND data,i.e.
operating a fax device, the predicates and argu-ments in the logical expressions of the SC of thedialogue acts refer to entities, properties, events,and tasks in the application domain.
The appli-cation domain of the fax device is complex butsmall: the domain model consists of 70 entitieswith at most 10 properties, 72 higher-level actionsor tasks, and 45 different settings.Representations of semantic content are oftenexpressed in some form of predicate logic typeformula.
Examples are Quasi Logical Forms (Al-shawi, 1990), Dynamic Predicate Logic (Groe-nendijk and Stokhof, 1991), and UnderspecifiedDiscourse Representation Theory (Reyle, 1993).The SC in the dataset is in a simplified first orderlogic similar to quasi logical forms, and is suitableto support feasible reasoning, for which also theo-rem provers, model builders, and model checkerscan be used.
The following utterances and theircorresponding SC characterise the dataset:1 wat moet ik nu doen?
(what do I have to do now?
)?x .
next-step(x)2 druk op een toets(press a button)?x .
press(x) ?
button(x)3 druk op de groene toets(press the green button)?x .
press(x) ?
button(x) ?
color(x,?green?
)4 wat zit er boven de starttoets?
(what is located above the starttoets?
)?x .
loc-above(x,?button041?
)Three types of predicate groups are distin-guished: action predicates, element predicates,and property predicates.
These types have a fixedorder.
The action predicates appear before elementpredicates, which appear in turn before propertypredicates.
This allows to simplify the semanticcontent for the purpose of reducing data sparsityin act prediction experiments, by stripping awaye.g.
property predicates.
For instance, if desiredthe SC of utterance 3 in the example could be sim-plified to that of utterance 2, making the semanticsless detailed but still meaningful.6.2 Methodology and metricsEvaluation of overall performance in communi-cation is problematic; there are no generally ac-cepted criteria as to what constitutes an objectiveand sound way of comparative evaluation.
Anoften-used paradigm for dialogue system evalua-tion is PARADISE (Walker et al, 2000), in whichthe performance metric is derived as a weightedcombination of subjectively rated user satisfac-tion, task-success measures and dialogue cost.Evaluating if the predicted dialogue acts are con-sidered as positive contributions in such a waywould require the model to be embedded in a fullyworking dialogue system.To assess whether the models that are learnedproduce human-like behaviour without resortingto costly user interaction experiments, it is neededto compare their output with real human responsesgiven in the same contexts.
This will be done byderiving a model from one part of a dialogue cor-pus and applying the model on an ?unseen?
partof the corpus, comparing the suggested next dia-logue act with the observed next dialogue act.
Tomeasure the performance, accuracy is used, whichis defined as the proportion of suggested dialogueacts that match the observed dialogue acts.In addition to the accuracy, also perplexity isused as metric.
Perplexity is widely used in re-lation to speech recognition and language models,and can in this context be understood as a metricthat measures the number of equiprobable possi-ble choices that a model faces at a given moment.Perplexity, being related to entropy is defined asfollows:Entropy = ?
?ip(wi|h) ?
log2 p(wi|h)Perplexity = 2Entropy11where h denotes the conditioned part, i.e.
wi?1in the case of bigrams and wi?2, wi?1 in the caseof trigrams, et cetera.
In sum, accuracy could bedescribed as a measure of correctness of the hy-pothesis and perplexity could be described as howprobable the correct hypothesis is.For all n-gram language modelling tasks re-ported, good-turing smoothing was used (Katz,1987).
To reduce the effect of imbalances in thedialogue data, the results were obtained using 5-fold cross-validation.To have an idea how the performance of boththe n-gram language models and the SCFG mod-els relate to the performance of a simple heuris-tic, a baseline has been computed which suggestsa majority class label according to the interlocutorrole in the dialogue.
The information seeker hasSET-Q and the information provider has SET-A asmajority class label.6.3 Results for communicative functionsThe scores for communicative function predictionare presented in Table 1.
For each of the threekinds of symbols, accuracy and perplexity are cal-culated: the first two columns are for the main CF,the second two columns are for the combinationof speaker identity and main CF, and the third twocolumns are for the combination of speaker iden-tity and all CFs.
The scores for the latter two cod-ings could not be calculated for the 5-gram model,as the data were too sparse.As was expected, there is an improvement inboth accuracy (increasing) and perplexity (de-creasing) for increasing n-gram order.
After the4-gram language model, the scores drop again.This could well be the result of insufficient train-ing data, as the more complex symbols could notbe predicted well.Both language models and SCFG models per-form better than the baseline, for all three groups.The two SCFG models, DGI1 and DGI2, clearlyoutperform the n-gram language models with asubstantial difference in accuracy.
Also the per-plexity tends to be lower.
Furthermore, modelDGI2 performs clearly better than model DGI1,which indicates that the ?flattening?
of non-terminals which is described in Section 5 resultsin better inductions.When comparing the three groups of sequences,it can be concluded that providing the speakeridentity combined with the main communicativefunction results in better accuracy scores of 5.9%on average, despite the increase in data sparsity.
Asimilar effect has also been reported by Stolcke etal.
(2000).Only for the 5-gram language model, the databecome too sparse to learn reliably a languagemodel from.
There is again an increase in per-formance when also the last two positions in the4-tuple are used and all available dialogue act as-signments are available.
It should be noted, how-ever, that this increase has less impact than addingthe speaker identity.
The best performing n-gramlanguage model achieved 66.4% accuracy; thebest SCFG model achieved 78.9% accuracy.6.4 Results for dialogue actsThe scores for prediction of dialogue acts, includ-ing SC, are presented in the left part of Table 2.The presentation is similar to Table 1: for each ofthe three kinds of symbols, accuracy and perplex-ity were calculated.
For dialogue acts that may in-clude semantic content, computing a useful base-line is not obvious.
The same baseline as for com-municative functions was used, which results inlower scores.The table shows that the attempts to learn topredict additionally the semantic content of utter-ances quickly run into data sparsity problems.
Itturned out to be impossible to make predictionsfrom 4-grams and 5-grams, and for 3-grams thecombination of speaker and all dialogue acts couldnot be computed.
Training the SCFGs, by con-trast, resulted in fewer problems with data sparsity,as the models abstract quickly.As with predicting communicative functions,the SCFG models show better performance thanthe n-gram language models, for which the 2-grams show slightly better results than the 3-grams.
Where there was a notable performancedifference between DGI1 and DGI2 for CF pre-diction, for dialogue act prediction there is only avery little difference, which is insignificant con-sidering the relatively high standard deviation.This small difference is explained by the fact thatDGI2 becomes less effective as the size of thetraining data decreases.As with CF prediction, it can be concluded thatproviding the speaker identity with the main dia-logue act results in better scores, but the differenceis less big than observed with CF prediction due tothe increased data sparsity.12Table 1: Communicative function prediction scores for n-gram language models and SCFGs in accuracy(acc, in percent) and perplexity (pp).
CFmain denotes the main communicative function, SPK speakeridentity, and CFall all occurring communicative functions.CFmain SPK + CFmain SPK + CFallacc pp acc pp acc ppbaseline 39.1?0.23 24.2?0.19 44.6?0.92 22.0?0.25 42.9?1.33 23.7?0.412-gram 53.1?0.88 17.9?0.35 58.3?1.84 16.8?0.31 61.1?1.65 16.3?0.593-gram 58.6?0.85 17.1?0.47 63.0?1.98 14.5?0.26 65.9?1.92 14.0?0.234-gram 60.9?1.12 16.7?0.15 65.4?1.62 15.2?1.07 66.4?2.03 14.2?0.445-gram 60.3?0.43 18.6?0.21 - - - -DGI1 67.4?3.05 18.3?1.28 74.6?1.94 14.8?1.47 76.5?2.13 13.9?0.35DGI2 71.8?2.67 16.1?1.25 78.3?2.50 14.0?2.39 78.9?1.98 13.6?0.35Table 2: Dialogue act prediction scores for n-gram language models and SCFGs.
DAmain denotes thedialogue act with the main communicative function, and DAall all occurring dialogue acts.DAmain SPK + DAmain SPK + DAallfull SC simplified SCacc pp acc pp acc pp acc ppbaseline 18.5?2.01 31.0?1.64 19.3?1.79 27.6?0.93 18.2?1.93 31.6?1.38 18.2?1.93 31.6?1.382-gram 31.2?1.42 28.5?1.03 34.6?1.51 24.7?0.62 35.1?1.30 26.9?0.47 37.5?1.34 26.2?2.373-gram 29.0?1.14 34.7?2.82 31.9?1.21 30.5?2.06 - - 29.1?1.28 28.0?2.594-gram - - - - - - - -5-gram - - - - - - - -DGI1 38.8?3.27 25.1?0.94 42.5?0.96 25.0?1.14 42.9?2.44 27.3?1.98 46.6?2.01 24.6?2.24DGI2 39.2?2.45 25.0?1.28 42.7?1.03 25.3?0.99 42.4?2.19 28.0?1.57 46.4?1.94 24.7?2.55The prediction scores of dialogue acts with fullsemantic content and simplified semantic contentare presented in the right part of Table 2.
For bothcases multifunctionality is taken into account byincluding all occurring communicative functionsin each symbol.
As can be seen from the table,the simplification of the semantic content leads toimprovements in the prediction performance forboth types of model.
The best n-gram languagemodel improved with 2.4% accuracy from 35.1%to 37.5%; the best SCFG-based model improvedwith 3.7% from 42.9% to 46.6%.Moreover, the simplification of the semanticcontent reduced the problem of data-sparsity, mak-ing it also possible to predict based on 3-gramsalthough the accuracy is considerably lower thanthat of the 2-gram model.7 DiscussionBoth n-gram language models and SCFG basedmodels have their strengths and weaknesses.
n-gram models have the advantage of being very ro-bust and they can be easily trained.
The SCFGbased model can capture regularities that havegaps, and allow to model long(er) distance rela-tions.
Both algorithms work on sequences andhence are easily susceptible to data-sparsity whenthe symbols in the sequences get more complex.The SCFG approach, though, has the advantagethat symbols can be clustered in the non-terminalsof the grammar, which allows more flexibility.The multidimensional nature of the DIT++functions can be adequately encoded in the sym-bols of the sequences.
Keeping track of the inter-locutor and including not only the main commu-nicative function but also other functions that oc-cur simultaneously results in better performanceeven though it decreases the amount of data tolearn from.The prediction experiments based on main com-municative functions assume that in case of multi-functionality, a main function can clearly be iden-tified.
Moreover, it is assumed that task-relatedfunctions are more important than feedback func-tions or other functions.
For most cases, these as-sumptions are justified, but in some cases they are13problematic.
For instance, in a heated discussion,the turn management function could be consideredmore important for the dialogue than a simultane-ously occurring domain specific function.
In othercases, it is impossible to clearly identify a mainfunction as all functions occurring simultaneouslyare equally important to the dialogue.In general, n-grams of a higher order have ahigher predictability and therefore a lower per-plexity.
However, using high order n-grams isproblematic due to sparsity of training data, whichclearly is the case with 4-grams, and particularlywith 5-grams in combination with complex sym-bols as for CF prediction.Considerably more difficult is the prediction ofdialogue acts with realised semantic content, asis evidenced in the differences in accuracy andperplexity for all models.
Considering that thedata set, with about 1, 600 functional segments,is rather small, the statistical prediction of logicalexpressions increases data sparsity to such a de-gree that from the n-gram language models, only2-gram (and 3-grams to some extent) could betrained.
The SCFG models can be trained for bothCF prediction and dialogue act prediction.As noted in Section 6.2, objective evaluation ofdialogue strategies and behaviour is difficult.
Theevaluation approach used here compares the sug-gested next dialogue act with the next dialogue actas observed.
This is done for each dialogue act inthe test set.
This evaluation approach has the ad-vantage that the evaluation metric can easily be un-derstood and computed.
The approach, however,is also very strict: in a given dialogue context, con-tinuations with various types of dialogue acts mayall be equally appropriate.
To also take other pos-sible contributions into account, a rich dataset isrequired in which interlocutors act differently insimilar dialogue context with a similar establishedcommon ground.
Moreover, such a dataset shouldcontain for each of these cases with similar dia-logue context a representative set of samples.8 Conclusions and future workAn approach to the prediction of communicativefunctions and dialogue acts has been presentedthat makes use of grammatical inference to auto-matically extract structure from corpus data.
Thealgorithm, based on alignment-based learning, hasbeen tested against a baseline and several n-gramlanguage models.
From the results it can be con-cluded that the algorithm outperforms the n-grammodels: on the task of predicting the communica-tive functions, the best performing n-gram modelachieved 66.4% accuracy; the best SCFG modelachieved 78.9% accuracy.
Predicting the seman-tic content in combination with the communica-tive functions is difficult, as evidenced by moder-ate scores.
Obtaining lower degree n-gram lan-guage models is feasible, whereas higher degreemodels are not trainable.
Prediction works betterwith the SCFG models, but does not result in con-vincing scores.
As the corpus is small, it is ex-pected that with scaling up the available trainingdata, scores will improve for both tasks.Future work in this direction can go in sev-eral directions.
First, the grammar induction ap-proach shows potential of learning dialogue game-like structures unsupervised.
The performance onthis task could be tested and measured by applyingthe algorithm on corpus data that have been anno-tated with dialogue games.
Second, the modelscould also be extended to incorporate more infor-mation than dialogue acts alone.
This could makecomparisons with the performance obtained withreinforcement learning or with Bayesian networksinteresting.
Third, it would be interesting to learnand apply the same models on other kinds of con-versation, such as dialogue with more than two in-terlocutors.
Fourth, datasets could be drawn froma large corpus that covers dialogues on a smallbut complex domain.
This makes it possible toevaluate according to the possible continuationsas found in the data for situations with similar di-alogue context, rather than to evaluate accordingto a single possible continuation.
Last, the ratherunexplored parameter space of the DGI algorithmmight be worth exploring in optimising the sys-tem?s performance.ReferencesJan Alexandersson and Norbert Reithinger.
1997.Learning dialogue structures from a corpus.
InProceedings of Eurospeech 1997, pages 2231?2234,Rhodes, Greece, September.Hiyan Alshawi.
1990.
Resolving quasi logical forms.Computational Linguistics, 16(3):133?144.Harry Bunt.
2000.
Dialogue pragmatics and contextspecification.
In Harry Bunt and William Black, ed-itors, Abduction, Belief and Context in Dialogue;Studies in Computational Pragmatics, pages 81?150.
John Benjamins, Amsterdam, The Netherlands.14Harry Bunt.
2006.
Dimensions in dialogue annota-tion.
In Proceedings of the 5th International Confer-ence on Language Resources and Evaluation (LREC2006), pages 1444?1449, Genova, Italy, May.Jeroen Geertzen and Menno M. van Zaanen.
2004.Grammatical inference using suffix trees.
InProceedings of the 7th International Colloquiumon Grammatical Inference (ICGI), pages 163?174,Athens, Greece, October.Jeroen Geertzen, Yann Girard, and Roser Morante.2004.
The DIAMOND project.
Poster at the 8thWorkshop on the Semantics and Pragmatics of Dia-logue (CATALOG 2004), Barcelona, Spain, July.John Godfrey, Edward Holliman, and Jane McDaniel.1992.
SWITCHBOARD: Telephone speech corpusfor research and development.
In Proceedings of theICASSP-92, pages 517?520, San Francisco, USA.Jeroen Groenendijk and Martin Stokhof.
1991.
Dy-namic predicate logic.
Linguistics and Philosophy,14(1):39?100.Slava M. Katz.
1987.
Estimation of probabilities fromsparse data for the language model component of aspeech recognizer.
IEEE Transactions on Acoustics,Speech, and Signal Processing, 35(3):400?401.Oliver Lemon, Kallirroi Georgila, and James Hender-son.
2006.
Evaluating effectiveness and portabil-ity of reinforcement learned dialogue strategies withreal users: The talk towninfo evaluation.
In SpokenLanguage Technology Workshop, pages 178?181.Joan A. Levin and Johanna A. Moore.
1988.
Dialogue-games: metacommunication structures for naturallanguage interaction.
Distributed Artificial Intelli-gence, pages 385?397.Esther Levin, Roberto Pieraccini, and Wieland Eck-ert.
1998.
Using markov decision process forlearning dialogue strategies.
In Proceedings of theICASSP?98, pages 201?204, Seattle, WA, USA.Lori Levin, Klaus Ries, Ann Thyme?-Gobbel, and AlonLavie.
1999.
Tagging of speech acts and dialoguegames in spanish call home.
In Proceedings of ACL-99 Workshop on Discourse Tagging, College Park,MD, USA.Masaaki Nagata and Tsuyoshi Morimoto.
1994.
Firststeps towards statistical modeling of dialogue to pre-dict the speech act type of the next utterance.
SpeechCommunication, 15(3-4):193?203.Tim Paek.
2006.
Reinforcement learning for spokendialogue systems: Comparing strenghts and weak-nesses for practical deployment.
In InterspeechWorkshop on ?Dialogue on Dialogues?.Massimo Poesio and Andrei Mikheev.
1998.
Thepredictive power of game structure in dialogueact recognition: Experimental results using maxi-mum entropy estimation.
In Proceedings Interna-tional Conference on Spoken Language Processing(ICSLP-98), Sydney, Australia, December.Livia Polanyi and Remko Scha.
1984.
A syntactic ap-proach to discourse semantics.
In Proceedings ofthe 10th international conference on Computationallinguistics, pages 413?419, Stanford, CA, USA.Norbert Reithinger and Elisabeth Maier.
1995.
Uti-lizing statistical dialogue act processing in VERB-MOBIL.
In Proceedings of the 33rd annual meetingon the Association for Computational Linguistics(ACL), pages 116?121, Cambridge, Massachusetts.Association for Computational Linguistics (ACL).Uwe Reyle.
1993.
Dealing with ambiguities by under-specification: Construction, representation and de-duction.
Journal of Semantics, 10(2):123?179.Emanuel A. Schegloff.
1968.
Sequencing in con-versational openings.
American Anthropologist,70:1075?1095.Andreas Stolcke, Klaus Ries, Noah Coccaro, Eliza-beth Shriberg, Rebecca Bates, Daniel Jurafsky, PaulTaylor, Rachel Martin, Carol Van Ess-Dykema, andMarie Meteer.
2000.
Dialogue act modeling forautomatic tagging and recognition of conversationalspeech.
Computational Linguistics, 26(3):339?373.Richard S. Sutton and Andrew G. Barto.
1998.
Re-inforcement Learning: An Introduction (AdaptiveComputation and Machine Learning).
MIT Press,March.Menno van Zaanen and Pieter W. Adriaans.
2001.Comparing two unsupervised grammar inductionsystems: Alignment-Based Learning vs. EMILE.Technical Report TR2001.05, University of Leeds,Leeds, UK, March.Menno M. van Zaanen.
2002.
Bootstrapping Structureinto Language: Alignment-Based Learning.
Ph.D.thesis, University of Leeds, Leeds, UK, January.Andrew J. Viterbi.
1967.
Error bounds for convolu-tional codes and an asymptotically optimum decod-ing algorithm.
IEEE Transactions on InformationTheory, 13(2):260?269, April.Marilyn Walker, Candace Kamm, and Diane Litman.2000.
Towards developing general models of usabil-ity with paradise.
Natural Language Engineering,6(3-4):363?377.Ian H. Witten and Timothy C. Bell.
1991.
The zero-frequency problem: Estimating the probabilities ofnovel events in adaptive text compression.
IEEETransactions on Information Theory, 37(4):1085?1094.Steve Young.
2002.
The statistical approach to thedesign of spoken dialogue systems.
Technical Re-port CUED/F-INFENG/TR.433, Engineering De-partment, Cambridge University, UK, September.15
