Proceedings of the MultiLing 2013 Workshop on Multilingual Multi-document Summarization, pages 39?44,Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational LinguisticsCIST System Report for ACL MultiLing 2013-- Track 1: Multilingual Multi-document SummarizationLei Li, Wei Heng, Jia Yu, Yu Liu, Shuhong WanCenter for Intelligence Science and Technology (CIST),School of Computer Science and Technology,Beijing University of Posts and Telecommunications (BUPT), Chinaleili@bupt.edu.cnAbstractThis report provides a description of the meth-ods applied in CIST system participating ACLMultiLing 2013.
Summarization is based onsentence extraction.
hLDA topic model isadopted for multilingual multi-document mod-eling.
Various features are combined to evalu-ate and extract candidate summary sentences.1 IntroductionCIST system has participated Track 1: Multilin-gual Multi-document Summarization in ACLMultiLing 2013 workshop.
It could deal with allten languages: Arabic, Chinese, Czech, English,French, Greek, Hebrew, Hindi, Romanian andSpanish.
It summarizes every topic containing 10texts and generates a summary in plain text,UTF8 encoding, less than 250 words.2 System DesignThere have been many researches about multi-document summarization, (Wan et al 2006; Heet al 2008; Flore et al 2008; Bellemare et al2008; Conroy and Schlesinger, 2008; Zheng andTakenobu, 2009; Louis and Nenkova, 2009;Long et al 2009; Lin and Chen, 2009; Gong etal., 2010; Darling, 2010; Kumar et al 2010;Genest and Lapalme, 2010; Jin et al 2010; Ken-nedy et al 2010; Zhang et al 2011), but lessabout multilingual multi-document summariza-tion (Leuski et al 2003; Liu et al 2011; Conroyet al 2011; Hmida and Favre, 2011; Das andSrihari, 2011; Steinberger et al 2011; Saggion,2011; El-Haj et al 2011).This system must be applicable for unlimitedtopics, we couldn?t use topic knowledge.
Differ-ent topic has different language styles, so we usesentence as the processing unit and summariza-tion method based on sentence extraction.
It mustalso be available for different languages, wecouldn?t use much specific knowledge for alllanguages except one or two we understand.
Werefer to a statistical method, hLDA (hierarchicalLatent Dirichlet Allocation (LDA)).LDA has been widely applied.
(Arora andBalaraman, 2008; Krestel et al 2009).
Someimprovements have been made.
(Griffiths et al2005; Blei and Lafferty, 2006; Wang and Blei,2009).
One is to relax its assumption that topicnumber is known and fixed.
Teh et al(2006)provided an elegant solution.
Blei et al(2010)extended it to exploit the hierarchical tree struc-ture of topics, hDLA, which is unsupervisedmethod in which topic number could grow withthe data set automatically.
There?s no relationsbetween topics in LDA (Blei, 2003), but hLDAcould organize topics into a hierarchy, in whichhigher level topics are more abstractive.
Thiscould achieve a deeper semantic model similarwith human mind and is especially helpful forsummarization.
Celikyilmaz (2010) provided amulti-document summarization method based onhLDA with competitive results.
However, it hasthe disadvantage of relying on ideal summaries.To avoid this, the innovation of our work iscompletely dependent on data and hierarchy toextract candidate summary sentences.Figure 1 and 2 show the framework for tenlanguages.
Since Chinese Hanzi is different fromother languages, we treat it with special pro-cessing.
But the main modules are the same.
Thekernel one is constructing an hLDA model1.
It?slanguage independent.1 http://www.cs.princeton.edu/~blei/topicmodeling.html39Figure 1: framework for nine languages (no Chinese)Figure 2: framework for Chinese3 Text Pre-processingThere are some unified pre-processing steps forall languages and a special step for Chinese.3.1 Merging DocumentsWe treat multi-document together, so we firstlycombine them into a big text.
As to Chinese, wecombine and delete empty lines.
As to other ninelanguages, we do this when we split sentences.3.2 Splitting SentencesWe split sentences to get the processing unit.There are two lines of title and date ending withno punctuation mark.
We add a full stop our-selves to avoid them being connected with thefirst sentence.
For Chinese, we split sentencesaccording to ending punctuation marks, while forother nine languages, the full stop ?.?
could haveother functions.
We adopt machine learningmethod 2 .
After some experiments, we chooseSupport Vector Machine model for English andFrench, Na?ve Bayes model for other 7 languages.2 https://code.google.com/p/splitta/3.3 Removing Stop WordsWe add ICTCLAS3 word segmentation to Chi-nese to make all languages have the same wordseparator.
Then we could obtain words easily,among which are some stop words.
We constructstop lists.
For English and Chinese, the stop listcontains punctuation marks and some functionalwords, while for other languages, it containspunctuation marks, which could unified thewhole process easily although generally we donot treat punctuation marks as words.
At thesame time, all capitalized characters are changedto lower case.3.4 Generating Input File for hLDAWe build a dictionary for remaining words,which are sorted according to frequency.
Themore frequent words are located before the lessfrequent ones.
This is a mapping from word to anumber varying from 1 to dictionary size.
Finallywe generate an input file for hLDA, in whicheach line represents a sentence, in the followingform:[number of words in the sentence] [word-NumberA]:[local frequencyA] [word-NumberB]:[local frequencyB]...Figure 3 shows an example.
As we can seethat now it?s language independent.Figure 3: hLDA input file4 hLDA Topic ModelingGiven a collection of sentences in the input file,we wish to discover common usage patterns ortopics and organize them into a hierarchy.
Eachnode is associated with a topic, which is a distri-bution across words.
A sentence is generated bychoosing a path from the root to a leaf, repeated-ly sampling topics along that path, and samplingthe words from the selected topics.
Sentencessharing the same path should be similar to eachother because they share the same sub-topics.
Allsentences share the topic distribution associatedwith the root node.As to this system, we set hierarchy depth to 3,because we have found out in former experi-ments that 2 is too simple, and 4 or bigger is toocomplex for the unit of sentence.3 http://www.nlpir.org/download/ICTCLAS2012-SDK-0101.rar404.1 Hierarchy EvaluationIn order to make sure that a hierarchy is good,we need to evaluate its performance.
The bestmethod is human reading, but it?s too laboriousto browse all topics and all languages.
In fact, wecould not understand all ten languages at all.
Sowe build another simpler and faster evaluationmethod based on numbers.
According to formerempirical analysis, if a hierarchy has more than 4paths and the sentence numbers for all paths ap-pear in balanced order from bigger to smaller,and the sentences in bigger paths could occupy70-85% in all sentences, then we could possiblyinfer that this hierarchy is good.4.2 Parameter SettingWhen facing a new corpus, we could hardly setthe parameters automatically either by human ormachine.
There is a choice of sampling.
We triedit for all languages with 100000 iterations.
Butthe results are poor, even in the worst case eachsentence is set to a single path.
Thus we give upsampling and try to set the parameters by human.We begin with Chinese because it seems to bethe most difficult case.
We randomly choose twotopics for original testing and set some parame-ters according to former experience.
Then weevaluate the result using method in 4.1.
If it?s notgood, we go on to adjust the settings until weobtain a satisfactory result.
The satisfied settingsare then used originally for the whole corpus.Table 1 shows the details.Parameter SettingETA 1.2   0.5 0.05GAM 1.0   1.0GEM_MEAN 0.5GEM_SCALE 100SCALING_SHAPE 1.0SCALING_SCALING 0.5SAMPLE_ETA 0SAMPLE_GAM 0Table 1: Original parameter settingsLanguage TopicEnglish M006Hebrew M001 M006Romanian M002Spanish M003Chinese M004 M006Table 2: original bad resultAfter running the whole corpus, we evaluatethe results again.
We found out that for most cas-es, the hierarchy is good, but there are some cas-es not so good, as shown in Table 2.
So one setof parameter settings could not deal with all lan-guages and topics successfully.
The reason maybe that different language and different topicmust have different inherent features.4.3 Parameter AdjustmentWe analyze the bad results and try to adjust thesettings.
For instance, in English M006, there areonly two paths indicating that the tree is too clus-tered.
Parameter ETA should be reduced to sepa-rate more sub-topics.
But too small ETA maylead to hLDA failure without level assignmentresult in limited iterations.
So we also adjustGEM to get closer to the prior explanation ofcorpus.
In some case, the numbers are assignedtoo much to the former big paths, then we shouldadjust SCALING parameters to separate somenumbers to the smaller paths.
For the bad casesin Table 2, we finally use the settings in Table 3.Parameter SettingETA 5.2  0.005  0.0005GAM 1.0   1.0GEM_MEAN 0.35GEM_SCALE 100SCALING_SHAPE 2.0SCALING_SCALING 1.0SAMPLE_ETA 0SAMPLE_GAM 0Table 3: Adjusted parameter settingsFigure 4 shows an example of the modelingresult of M004 in English.Figure 4: hLDA result example5 Summary Generation5.1 Sentence EvaluationIn the hLDA result, sentences are clustered intosub-topics in a hierarchical tree.
A sub-topic ismore important if it contains more sentences.Trivial sub-topics containing only one or twosentences could be neglected.
Final summary41should cover those most important sub-topicswith their most representative sentences.
Weevaluate the sentence importance in a sub-topicconsidering three features.1) Sentence coverage, which means that howmuch a sentence could contain words appearingin more sentences for a sub-topic.
We considersentence coverage of each word in one sentence.The sentence weight is calculated as eq.(1).||)(||1snwnumSsiistf???
(1)Where wi is the ith word in sentence s, nums(wi)is the number of sentences that wi covers, | s | isthe number of words in the sentence, and n is thetotal number of all sentences.2) Word Abstractive level.
hLDA constructs ahierarchy by positioning all sentences on a three-level tree.
Level 0 is the most abstractive one,level 2 is the most specific one, and level 1 isbetween them.
We evaluate the sentence abstrac-tive feature as eq.(2).
(2)Where num(W0), num(W1), num(W2) arenumbers of level 0, 1 and 2 words respectively inthe sentence.
There are three parameters: a, b andc, which are used to control the weights forwords in different levels.
Although we hope thesummary to be as abstractive as possible, there isreally some specific information we also want.For instance, earthquake news needs specificinformation about death toll and money lost.3) Named entity.
We consider the number ofnamed entities in one sentence.
This time we on-ly have time to use Stanford?s named entityrecognition toolkit4, which could identify Englishperson, address and institutional names.
If onesentence contains more entities, then it has a highpriority to be chosen as candidate summary sen-tence.
Let Sn be the number of named entity cat-egories in one sentence.
For example, if one sen-tence has only person names, then Sn is 1; else ifit also has address information, then Sn is 2; elseif it contains all three categories, then Sn is 3.At last, we calculate sentence score S as eq.
(3,4), where d, e and f are feature weights:English:        (3)Others:                       (4)After experiments, we set {a, b, c, d, e, f} to{0.3, 1, 0.3, 2, 1, 0.05} for English, {a, b, c, d, e}4 http://nlp.stanford.edu/software/CRF-NER.shtmlto {1, 0.75, 0.25, 2, 1} for Chinese without M004and M006, and {0.3, 1, 0.3, 2, 1} for others.5.2 Summary GenerationWe extract 30 candidate sentences with high Sordered by S from bigger to smaller and checkthem one by one.
We use 30 sentences to makesure that when a candidate sentence is not goodto be in a final summary, we could have enoughother alternative sentences with less S. Then wegenerate the final summary as Figure 5.Figure 5: 250-summary generation flow chart6 EvaluationsWe?ve got only the automatic evaluation result.CIST could get best performance in some lan-guage, such as Hindi in ROUGE, and in sometopics, such as Arabic M104, English and Roma-nia M005, Czech M007, Spanish M103 etc.
in N-gram graph methods: AutoSummENG, MeMoGand NPowER.
CIST could also get nearly worstperformance in some cases, such as French andHebrew.
In other cases it gets middle perfor-mance.
But Chinese result looks very strange tous; we think that it needs more special discussion.7 Conclusion and Future WorkhLDA is a language independent model.
It couldwork well sometimes, but not stable enough.
Fu-ture work will focus on parameter adjustment,modeling result evaluation, sentence evaluationand good summary generation.AcknowledgmentsWe get support from NSFC 61202247, 71231002,Fundamental Research Funds for Central Uni-versities 2013RC0304 and Beijing Science andTechnology Information Institute.42ReferencesAbdullah Bawakid and Mourad Oussalah, 2008.
ASemantic Summarization System: University ofBirmingham at TAC 2008.
TAC 2008 Pro-ceedings.Alistair Kennedy, Terry Copeck, Diana Inkpen andStan Szpakowicz, 2010.Entropy-based SentenceSelection with Roget?s Thesaurus.
TAC 2010Proceedings.Annie Louis and Ani Nenkova, 2009.
PredictingSummary Quality using Limited Human Input.TAC 2009 Proceedings.Anton Leuski, Chin-Yewlin, Liang Zhou, UlrichGermann, Franz Josef Och, and Eduard Hovy,2003.Cross-Lingual C*ST*RD: English Access toHindi Information.
ACM Transactions onAsian Language Information Processing,2(3):245?269.Arora Rachit, and Balaraman Ravindran, 2008.
La-tent dirichlet alcation based multi-documentsummarization.
Proceedings of the secondworkshop on Analytics for noisy unstructuredtext data.
ACM, 2008.Asli Celikyilmaz and Dilek Hakkani-Tur.
2010.
Ahybrid hierarchical model for multi-documentsummarization.
Proceedings of the 48th An-nual Meeting of the Association for Computa-tional Linguistics, 815?824, Uppsala, Sweden,11-16 July 2010.Blei D. and Lafferty J., 2006.
Dynamic topic mod-els.
In International Conference on MachineLearning (2006).
ACM, New York, NY,USA:113?120.Blei D., Griffiths T. and Jordan M., 2010.
The nestedChinese restaurant process and Bayesiannonparametric inference of topic hierarchies.J.
ACM 57, 2 (2010):1?30.Chin-Yew Lin and Eduard Hovy, 2002.
AutomatedMulti-document Summarization in NeATS.Proceedings of HLT 2002, Second Interna-tional Conference on Human Language Tech-nology Research.Chong Long, Minlie Huang and  Xiaoyan Zhu, 2009.Tsinghua University at TAC 2009: Summariz-ing Multi-documents by Information Distance.TAC 2009 Proceedings.D.
M. Blei, A. Ng, and M. Jordan.
2003.Latent di-richlet alcation, Jrnl.
Machine Learning Re-search, 3:993-1022, 2003b.Feng Jin, Minlie Huang and Xiaoyan Zhu, 2010.TheTHU Summarization Systems at TAC 2010.TAC 2010 Proceedings.Firas Hmida and Benoit Favre, 2011.
LIF at TACMultiling: Towards a Truly Language Inde-pendent Summarizer.
TAC 2011 Proceedings.Griffiths T., Steyvers M., Blei D. and Tenenbaum J.,2005.
Integrating topics and syntax.
Advancesin Neural Information Processing Systems 17.L.
K. Saul, Y. Weiss, and L. Bottou, eds.
MITPress, Cambridge, MA,2005:537?544.Hongyan Liu, Ping?an Liu, Wei Heng and Lei Li,2011.The CIST Summarization System at TAC2011.
TAC 2011 Proceedings.Horacio Saggion, 2011.
Using SUMMA for Lan-guage Independent Summarization at TAC2011.
TAC 2011 Proceedings.John M. Conroy and Judith D. Schlesinger, 2008.CLASSY and TAC 2008 Metrics.
TAC 2008Proceedings.John M. Conroy, Judith D. Schlesinger and Dianne P.O?Leary, 2006.
Topic-Focused Multi-documentSummarization Using an Approximate OracleScore.
Proceedings of the COLING/ACL 2006Main Conference Poster Sessions: 152?159.John M. Conroy, Judith D. Schlesinger and Jeff Kubi-na, 2011.CLASSY 2011 at TAC: Guided andMulti-lingual Summaries and Evaluation Met-rics.
TAC 2011  Proceedings.Jorge Garc?a Flores, Laurent Gillard and Olivier Fer-ret, 2008.
Bag-of-senses versus bag-of-words:comparing semantic and lexical approacheson sentence extraction.
TAC 2008 Proceed-ings.Josef Steinberger, Mijail Kabadjov, Ralf Steinberger,Hristo Tanev, Marco Turchi and Vanni Zavarel-la,2011.
JRC?s Participation at TAC 2011:Guided and Multilingual Summarization Tasks.TAC 2011 Proceedings.Judith D. Schlesinger, Dianne P. O?Leary and John M.Conroy, 2008.
Arabic/English Multi-documentSummarization with CLASSY?The Past andthe Future.
CICLing 2008 Proceedings: 568?581.Krestel Ralf, Peter Fankhauser and Wolfgang Nejdl,2009.
Latent dirichlet alcation for tag rec-ommendation.
Proceedings of the third ACM43conference on Recommender systems.
ACM,2009.Mahmoud El-Haj, Udo Kruschwitz and Chris Fox,2011.
University of Essex at the TAC 2011Multilingual Summarisation Pilot.
TAC 2011Proceedings.Niraj Kumar, Kannan Srinathan and Vasudeva Varma,2010.
An Effective Approach for AESOP andGuided Summarization Task.
TAC 2010  Pro-ceedings.Pierre-Etienne Genest and Guy Lapalme, 2010.TextGeneration for Abstractive Summarization.TAC 2010  Proceedings.Pradipto Das and Rohini Srihari, 2011.Global andLocal Models for Multi-Document Summari-zation.
TAC 2011  Proceedings.Renxian Zhang, You Ouyang and Wenjie Li,2011.Guided Summarization with AspectRecognition.
TAC 2011  Proceedings.Shih-Hsiang Lin and Berlin Chen, 2009.
THE NTNUSUMMARIZATION SYSTEM AT TAC 2009.TAC 2009  Proceedings.Shu Gong, Youli Qu and Shengfeng Tian, 2009.Summarization using Wikipedia.
TAC 2010Proceedings.Sylvain Bellemare, Sabine Bergler and Ren e?
Witte,2008.
ERSS at TAC 2008.
TAC 2008 Proceed-ings.Teh Y., Jordan M., Beal M. and Blei D., 2006.
Hier-archical Dirichlet processes.
J.
Am.
Stat.
As-soc.
101, 476(2006):1566?1581.Tingting He, Jinguang Chen, Zhuoming Gui, andFang Li, 2008.
CCNU at TAC 2008 ?Proceeding on Using Semantic Method forAutomated Summarization Yield.
TAC 2008Proceedings.Wang C. and Blei D., 2009.
Decoupling sparsityand smoothness in the discrete hierarchicalDirichlet process.
Advances in Neural Infor-mation Processing Systems 22.
Y. Bengio, D.Schuurmans, J. Lafferty, C.William M. Darling, 2010.
Multi-Document Sum-marization from First Principles.
TAC 2010Proceedings.Xiaojun Wan, Jianwu Yang and Jianguo Xiao, 2006.Using Cross-Document Random Walks forTopic-Focused Multi-Document Summariza-tion.
WI 2006 Main Conference Proceedings.Yuanrong Zheng and Tokunaga Takenobu, 2009.
TheTITech Summarization System at TAC-2009.TAC 2009  Proceedings.44
