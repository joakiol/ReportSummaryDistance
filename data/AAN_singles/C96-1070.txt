I nc rementa l  T rans la t ionUt i l i z ing  Const i tuent  Boundary  Pat ternsOsamu FURUSE,  Hitoshi I IDAATR In terpret ing  Te lecommunicat ions  Research  Laborator ies2-2 t l ikar ida i ,  Seika-cho, Soraku-gun,  Kyoto ,  619-02, Japan{furuse, iida}@itl.atr.co.jpAbstractWe have proposed an incremental trans-lation method in Transfer-Driven Ma-chine Translation (TDMT).
In thismethod, constituent boundary patternsare applied to an input in a bottom-upfashion.
Also, by dealing with best-onlysubstructures, the explosion of structuralambiguity is constrained and an efficienttranslation of a lengthy input can beachieved.
Through preliminary exper-imentation our new TDMT has beenshown to be more efficient while main-tMning translation quality.1 IntroductionA system dealing with spoken language requires aquick response in order to provide smooth com-munication between humans or between a hu-man and a computer.
Thereibre, assuring effi-ciency in spoken-language translation is one ofthe most crucial tasks in devising such a system.In spoken language, the translation of lengthyutterances can yield a huge amount of struc-tural ambiguity, which needs to be efficiently pro-cessed by the system.
As a solution for achiev-ing an efficient spoken-language system, severaltechniques, such as incremental generation (Fin-kler, 1992; Kempen, 1987) and marker-passingmemory-based translation (Kitano, 1994), havebeen proposed.
Many of these techniques adopta left-to-right strategy to handle an input incre-mentally and a best-first strategy to avoid the ex-plosion of structural ambiguity.
These strategies(:an be achieved with bottom-up rocessing.We have already proposed Transfer-Driven Ma-chine Translation (TDMT) for efficient and ro-bust spoken-language translation (Furuse, 1994a;Furuse, 1994b).
However, the top-down andbreadth-first ranslation strategy in the earlierversions of TDMT, which yields a quick responsefor inputs with restricted lengths, may show poorefficiency when processing a very lengthy input orinputs having many competing structures.In a top-down and breadth-first application, allthe possible structures are retained until the wholeinput string is parsed.
This requires many compu-tations and results in inefficient ranslation.
Forinstance, the sentence below has many competingstructures, mainly because of possible combina-tions within noun sequences.
If this expression iscombined with another expression, the structurMambiguity will be further compounded.With bacon chicken eggs lettuce and tomato on it.In contrast, if structural ambiguities of sub-strings are always settled and are never inheritedto the upper structures, the explosion of struc-turM ambiguity could be constrained.
Thus, anincremental strategy that fixes partial results isnecessary for efficient processing and is achievedby bottom-up rocessing in left-to-right order.This paper proposes TDMT using an incremen-tal strategy for achieving efficient ranslation of alengthy input or one having a lot of structuralambiguity.
In this method, several constituentboundary patterns are applied to an input stringin a bottom-up fashion.
This bottom-up applica-tion, based on the concept of chart parsing, canconstrain the explosion of structural ambiguity bydealing with best-only substructures u ing seman-tic distance calculations.In this paper, we will first; outline our new trans-lation strategy.
We will then explain how con-stituent boundary patterns can be used to de-scribe the structure of an input string in TDMT.Then we will describe the bottom-up attern ap-plication, based on chart parsing.
Next, we willshow how the explosion of structural ambiguityis constrained by dealing with the best-only sub-structures, based on semantic distance calcula-tions.
By comparing the preliminary experimen-tal results from the former top-down method andthose from our new method, we will demonstratethe usefulness of our new method.
A summary ofour approach will conclude the paper.2 Translation strategyIn TDMT, translation is performed by applyingstored empirical transfer knowledge, which de-412scribes the correspondence between source lan-guage expressions and target language xpressionsat various linguistic levels.
The source and targetexpressions of tile transfer knowledge in TDMTarc ext)ressed by constituent boundary patterns,which represent meaningful units for linguisticstructure and transfer.
An efficient application oftransfer knowledge source parts to an input stringplays a key role in achieving quick translation.The procedure R)r applying constituent bound-ary patterns is perfomed after the assignment ofmorphological information to each word of an in-put string, and is as follows:(a) Insertion of constituent boundary marker;(b) 1)eriw~tion of possible structures;(e) Structural disambiguation 1)y semantic dis-lance calculation.In the top-down and breadth-tirst pattern ap-plication, the above procedure is executed in thedescribed order.
Because the selection of the beststructure might have to be postponed until all pos-sible structm'es are derived, the costs of transla-tion could be high.In contrast, the incremental method determinesthe best structure locally and (-an constrain thenumber of competing structures fbr the whole in-put by performing (b) in l)arallel with (c); conse-quently, translation costs are reduced.The structure selected in (c) (:ontains its trans-t~rred result and head word infbrination, which isused for semantic distance calculation when com-bining with other structures.
The output sentenceis generated as a translation result Dora the struc-ture for the whole inl)ut, which is composed ofbest-first substructures.In the three subsequent sections, we will explain(a), (b), and (c), focusing on the bottoir>up andbest-first ranslation strategy.3 Const i tuent  boundary  patternIn this section we will briefly explain how con-stituent boundary patterns are used to describethe structure of an int)ut string in TI)MT andwhat procedures arc applied before constituentboundary pattern applications (Furuse, 1994b).We will show bottom-up attern application bytranslating the following sample English sentenceinto Japanese:Thc bus goes to Chinatown at ten a.m.First, all the words in this sequence are assignedthe following parts-of-speech.article, noun, verb, preposition, proper-noun,preposition, numeral, postnominalA constituent boundary pattern is defined asa sequence that; consists of variables and sym-bols representing constituent boundaries.
A vari-able corresponds to some linguistic constituentand is expressed as a capital letter (e.g.
X).A constituent boundary is expressed by eithera functional word or a part-of-speech bigrammarker (e.g.
noun-verb).
Variables in tile sourcelanguage expression must be separated by con-stituent boundaries.For instance, the expression "goes to China-town" is divided into two constituents, i.e.
"goes"and "Chinalown".
The preposition "1o" can beidentified as a constituent boundary.
Therefor(;,in parsing "goes to Chinatown", we use the pat-tern "X to Y' ,  which has two variables X and Yand a constituent boundary "to".
'l'he expression "the b~zs goes" can be dividedinto two constituents "the bud' and "goes".
How-eve.r, there is no flmctional surface word that di-vides the expression into two constituents.
Insuch ('ases, we emt)loy part-of-speech bigrams asboundary markers.
"bus" and "goes" are a nounand a verb, respectively.
Thus the marker noun-verb can be inserted as a boundary marker into theinput "the bus goes", giving "The bus noun-verbgoes".
This sequence will now match tile generaltransfer knowledge pattern "X noun-verb Y".Of the possible bigrams in the above part-of~speech sequence, only "noun-verb" is an eligi-ble constituent boundary marker (Fro:use, 1994b).This marker is inserted into the above sentence:The bus noun-verb goes to Chinatown at ten a.m.Indices to possible patterns are obtained fromseveral words and bigrams in the above m~rker-inserted string (Table 1).Table 1 : Retrieved patternswordth c7~o?tn-vcrbtoatretrieved pattern (linguistic level)the X ((:ompound noun)X noun-verb Y (simple sentence)X to Y (verb phrase, noun phrase)X at Y (verb phrase, noun phrase)X a.ra.
(compound noun)The procedure xt)lained so far is the part that;the top-down and bot;tom-up attern applicationmethods have in common.4 Incrementa l  pattern applicationIn this section, we will show the application of con-stituent boundary patterns based on the conceptof bottom-up chart parsing.4.1 L inguist ic  levelIn order to limit the combinations of patternsduring pattern application, we distinguish patternlevels and for each linguistic level, we specify thelinguistic sublevels which are permitted to be usedin the assigned variables.Table 2 shows examples of the relationships be-tween linguistic levels.
A variable on a given level413is instantiated by a string on the lingustic levelsin the second column of Table 2.
For instance, inthe noun phrase "X of F' ,  the variables X and Ycannot be instantiated by a simple sentence, butcan be instatiated by a noun phrase, a compoundnoun, and so on.Table 2: Possible linguistic sublevels in variableslinguistic level sublevels of variablessimple sentence VP, NP, ...verb phrase (VP) VP, NP, verb, ...noun phrase (NP) NP, CN, proper-noun .
.
.
.compound noun (CN) CN, noun,.. .According to the regulation of the linguistic lev-els' relations hown in Table 2, a marker-insertedstring is parsed using the constituent boundarypatterns.4.2 Act ive  and  pass ive  arcsA chart parsing method (Kay, 1980) can avoid re-peatedly recomputing partial results and achieveincremental processing by using a bottom-up andleft-to-right strategy.
In chart parsing, an inputstring is parsed by combining active and passivearcs.
These can be assigned to a substring of aninput string when a pattern is applied to it.
If allthe variables of the applied pattern are instanti-ated or a substring can be matched to a patternwhose variables are all instantiated, a passive arcis created for the substring.
When a substring canbe matched to the left part of a pattern and theright variables of the pattern are not instatiated,an active arc is created for the substring.In conventional chart parsing, many arcs canbe created because every word can create ac-tive and passive arcs based on its part-of-speech.Also, many arcs can be chained via non-terminalsymbols such as a part-of-speech and NP (nounphrase).
For instance, the pronoun, "f' can createmany active arcs relevant o the rules "Pronoun1", "NP ~ Pronoun" and "S --+ NP VP", whichcan be chained.
Therefore, a lot of computationis required in conventional chart parsing.In contrast, chart parsing with constituentboundary patterns can constrain the number ofarc creations because only an constituent bound-ary creates active arcs while a variable (e.g.
X)never creates an arc.
We obtain indices to pat-terns from each word of the sentence.
With theseindices, patterns are retrieved and checked to de-termine whether each of them can create an arc.4.3 Pat tern  app l i ca t ion  a lgor i thmOur algorithm for bottom-up application of pat-terns is as follows.
If the whole input string canbe covered with a passive arc, the parsing will suc-ceed and the derivation of the passive arc will bethe parsed result.1.
If the processed string is a content word (e.g.noun, verb) create a passive arc.2.
If the processed string is a constituent bound-ary "a", create each kind of arc as follows,according to the pattern I retrieved from theconstituent boundary.2a.
If the retrieved pattern is of the type "X a Y"and a left-neighboring passive arc can satisfythe condition for X's instantiation, create anactive arc for "X a F ' ,  in which Y has notyet been instantiated.2b.
If the retrieved pattern is of the type "X a"and a left-neighboring passive arc can satisfythe condition for X's instantiation, create apassive are for "X a".2c.
If the retrieved pattern is of the type "a ~ ' ,create an active arc for "a ~ ' .3.
If the created passive arc satisfies the leftmostpart of an uninstantiated variable in the pat-tern of neighboring active arcs, the variable isinstantiated with the passive arc, and a newpassive or active arc is created.
If a passivearc is generated in this operation, repeat theprocedure until a new arc can no longer becreated.Figure 1 shows how an input string is parsedusing our bottom-up chart method.
A solid linedenotes a passive arc that covers a substring ofthe input below, while a dotted line denotes anactive arc.The content words "bus", "goes", "Chinatown"and "ten" create passive arcs.
The functionalword "the", which is relevant o the pattern "aX", creates an active arc.
The assignment of thefunctional word "a.m." to the pattern "X a" cre-ates a passive arc by combining another passivearc.
The boundary markers "noun-verb", "to" and"at", which are relevant o the pattern "X a Y",create active arcs by combining left-neighboringpassive arcs.First "the" creates the active arc (1) relevant othe pattern "the X".
"bug' creates the passive arc(2).
The passive arc (3) is created by combining(1) and (2).
"noun-verb" creates the act ive arc(4), whereby the variable X of "X noun-verb F'is matched against (3).
"bus" creates the passiveare (5), and the passive arc (6) is created by com-bining (4) and (5).
"to" creates the active are (7),whereby the variable X of "X to ~' at verb phraseis matched against (5).1There are other types of patterns, such as "X aY fl ~',  where ce and /3 are constituent boundaries.They can be easily processed by slightly extending thealgorithm.414(20)(16).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(12).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(11)(lO).
.
.
.
.
.
.
.
.
.
.
(7)(6).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(4)the bus noun-verb goes(9)18)to Chinatown at ten(15)(14)Figure 1: Chart diagram(19)(18)(1~)a .n2 .We continue the procedure incrementally.When the rightmost word has been processed, thederivation of the passive arc of the whole inputgives the parsed result, in our example the de-rived process of the passive arc (20), which is thecombination of (4) and (19).5 P re ference  o f  subst ructureThe passive arc (19), which is relevant o "goesto Chinatown at ten a.m.", h~ two competing rc-suits.
One is the combination of (7) and (18),where "X at F' is a noun phrase.
The other isthe combination of' (12) and (17), where "X at1("' is a verb phrase.
Thus, (19) has two possiblestructures by the application of "X at F'.
"X toF' at the verb phrase level and "X a.m." at thecompound noun level are also applied.The technique for obtaining substructure pref-erence is the determination of the best substruc-ture when a relative passive arc is created.
Onlythe best substructure can be retained and com-bined with other arcs.5.1 Semantic distanceThe most appropriate st~ructure is selected bycomputing tile total sum of all possible combi-nations of partial semantic distance values.
Thestructure with the least total distmme is judgedmost consistent with empirical knowledge and ischosen as the most plausible structure.The semantic distance between words is calcu-lated according to the relationship of tim positionsof words' semantic attributes in the thesaurus.The distance between expressions i the sum ofthe distance between the words comprising theexpressions, multiplied by some weights (Sumita,1992).5.2 Head word  in fo rmat ionThe head words within variable bindings serve asinput for distance calculations.
An input for dis-tance calculation consists of head words in vari-able parts.
The head part is designated in eachpattern.
Table 3 shows the head parts of the pos-sible substructures for "goes to Chinatown at tena.m.
", which corresponds to the passive arc (19).Table 3: Ilead words for (19)'s substructurespassive matched designated headarc pattern head word(9),(19) X to Y X goes(17) X a.m. a.m. a.m.(18) X at Y X Ch inatown(19) X at Y X goesIn "X at F' for the substring "goes to China-town at ten a.m" combined with (12) and (17),the variables X and Y are substituted for the com-pound expressions "goes to Chinatown" and "tena.m.
", respectively.
Thus, in "X at Y" for thestructure in (19), the input for distance calcula-tion is "goes" for "3;"' and "a.m." for "Y".
Sincethe head of "X at Y" is designated as "X',  "goes"becomes the \[lead word for (19).
This informa-tion is used when (19) is combined with anothersubstring.5.3 S t ructure  select ionThe difference in total distance value between thetwo possible structures i due only to the distancevalue of "X at F' .
Table 4 shows the results of thedistance calculation in "X at Y" for the combina-tion of (7) and (18), and for that of (12) and (17).
(goes, a.m.) expresses the bindings for variables X415and Y, where X ="goeg', and Y ="a.m.".
"X'"is the target expression corresponding to "~' .Table 4: Distance calculation in "X at F'levelinputclosest exampletargetdistance(7)+(18) 02)+07)noun phrase verb phrase(Chinatown, a.m.) (goes, a.m.)(morning, a.m.) (depart, a.m.)V no X' V ni X'0.50 0.21According to the distance calculation in thecombination of (7) and (18), "I/' no 3;'", with thedistance value 0.50, is selected as a target expres-sion.
In the combination of (12) and (17), "Y' niX'" with the distance value 0.21 is selected as atarget expression.
Thus, the combination of (12)and (17) is selected as the structure of the passivearc (19).
Based on the results of distance cabculations, other partial source patterns for (19),"X to Y" and "X a.m", are transferred to "Y' ni3('" with the distance value 0.12, and "gozen X ~j t '  with the distance value 0.00.
Thus, the pas-sive arc (19) has its source and target structurethrough the combination of (12) and (17), the to-tal distance value 0.33, and the head word "goes".Then, the structure of the whole input string,which corresponds to (20), is constructed by com-bining (19) with (4).
In this combination, "Xnoun-verb Y' matches the input string and istransferred to "X' wa Y'" based on the result ofdistance calulation.
From the combined structurefor (20), the sentence below is generated after ad-justment necessary for Japanese grammar.
Thewords "bus", "goes", and "Chinalown" are trans-ferred to "basu", "iku", and "Chainalaun ''2, re-spectively.Basu wa gozen i0 ji ni Chainataun ni iki masu"ik~" is the conjugated form of "iku" followedby masu, a polite sentential-final form.6 P re l iminary  Exper imentIn this section, we perform Fmglish-to-Japanesetranslation to compare the efficiency of the top-down pattern application with that of our newmethod, based on the bottom-up application andsubstructure preference in the TDMT prototypesystem.6.1 TDMT prototype  sys temThe TDMT prototype system, whose domainis travel conversations, is designed to achieve2The prototype system assigns a default arget ex-pression to a surface source expression.
Another tar-get expression is selected when a specific example inthe transfer knowledge is closest o the input.multi-lingual spoken-language translation (Fu-ruse, 1995).
While language-oriented modules,such as morphological analysis and generation,are provided to treat multi-lingual translation, thetransfer module, which is a central component, isa common part of the translation system for ev-ery language pair.
The system is written in LISPand runs on a UNIX machine.
Presently, the pro-totype system can translate bilingually betweenJapanese and English and between Japanese andKorean.
In English-to-Japanese translation, thepresent vocabulary size is about 3,000 words 3 andthe number of training sentences i about 2,000.6.2 Exper imenta l  resul tsWe have compared translation times in the TDMTprototype system for two cases.
One case utilizestop-down application; the other case utilizes thenew application method presented in this paper,which adopts bottom-up attern application andretains only one substructure using semantic dis-tance calculation.
The translation times are mea-sured using a Spare10 workstation.We have experimented with the translationtimes of some English sentences into Japanese.The following sentences cause only minor struc-tural ambiguity.
Note that a comma is not usedin the input sentence, because it is assumed tobe a spoken-language input such as the output ofspeech recognition.
(1) 1 have a reservation for tomorrow.
(2) Will my laundry be ready by tomorrow?
(3) You can walk there in about three minutes.
(4) Then may I have your credit card number please?Table 5 shows the translation time of the abovesentences.
For these translations, not much dif-ference could be seen between the new bottom-upmethod and the top-down method.
For such in-puts TDMT can quickly produce the same trans-lation results with either method.
'Fable 5: 'Danslation time for short sentencesinputsentence(1)(2)(3)(4)# of translation time (see)structures top~ new ~ - -2 0.18 0.174 0.17 0.204 0.38 0.3511 0.85 0.70The following sentences cause much structuralambiguity because of PP-attaehment, relativeclauses, conjunctions, etc.3In the Japanese-to-English translation system,the present vocabulary size is about 5,000 words.416(5) 7'his sales clerk doesn't understand anything 1 sayand i 'm wondering if you wouhl help me explainwhat \[ want.
(6) Could I please have your name the date of arrivaland the number of persons in your party?
(7) 7bll somcone at the, fl'ont desk what game youwant to scc and what type of seat you want andthey'll get the tickets for you.
(8) I h,fl somc laundry to be cleaned bul I can't re-member where the clcaners is and I was wonder-ing if you could help me.Table 6 shows the translation time of the abovesentences, hi the above translations the sametranslation results could again be obtained forboth methods, llowever the new method canachieve a far more efficient translation than thetol> down metho(t.Table 6: 'l'ranslation time for long sentencesi t ,  p U LS(!ll ~oell C(\](0)(r)(8)\[~ translation ti,ne\]!
4.oa // 2.at /1 le , .
to ~.~7_ 3# ofsLr l I ( :L  u res312442544696Average tramslation times in the top-downmethod were 1.15 seconds for a 10-word input and10.87 seconds for a 20-word input.
Average trans-lation times in the bottom-up method were 0.55se(:onds for a 10-word input and 2.04 seconds fora 20-word inl)ut.
The translation time in the top-down method is considere, d to t)e (:h)sely relate(lto the nnmber of possibh~ stru(;tures, while l,hetranslation time in our new method is not direcdyretle(-ted by this number.
The inc.rease in the.
num-ber of substructures retained will, the.
new methodis much smaller than that of the number of possi-ble structures in the top-down method.
Therefore,our new method can efficiently translate a longerinput string having many (-ompeting structures.Also, we have performed a small translation-quality experiment on the two pattern applicationmethods with the 95 untrained sentences withinthe system's vocabulary.
Both the tOl)-downmethod and the proposed bottom-up method gavethe correct translation \[br the same 60 sentenceswith a success rate of 63.2%.
~'o,.
only two sen-tences, difl>rent structures we.re produced by thetwo methods; however, all of them were incorrecttranslations.
This experimental result shows thatour new translation strategy maintains translationquMity.Similar results, which show the llSe~llhlesS ofthe new T I )MT tbr spokenJanguage translation,were obtained in other tyl)es of translation suchas Jal)anese-to-English (or,-Korean) translation.7 Conc lus ionWe have proposed an increlnental translationmethod in Transfer-Driven Machine 'lYanslation(TI)MT).
in this method, constituent boundarypatterns are applied to an input it, a bottom-upand left-to-right fhshion.
Additionally, by deal-ing with best-only substructures, the explosion ofstructural ambiguity is constrained and eflq(-icnttranslation of ~ lengthy input can be achieved.Through preliminary exl)erimentation , our newT I )MT has b('~e.n shown to be efficient and partic-ularly promising for spokendangnage translation.One important future research goal is tile in-('orporation of incremental n.orphologieal analy-sis and generation into the prot)osed translationstrategy, which would provide a sinmltaneous in-terpretation mechanism tbr N)plication to a t)ra('-ti('al spoken-lm,guage translation system.
Alsoimportant is the introduction of a repair mech-anism to correct the I)est-first results.Re ferencesW.
Finkler and A.
S('hauder 1992.
FAfects of In.
(-remental ()utl)ut on lncrementM Natural \],anguage (~eneration.
In IOlh I,\]uropean Confer?enee on Artif icial Intelligence, \[)ages 505- 507,Vienna, Austria.O.
l"uruse, l",.
Sull'lita, and H. \[ida.
1994a.
'l'ransfi:r--Driven Machine 'lYansladon Utilizingl,~mpirical Knowledge (in Japanese).
7'rans~actions of lnformahon Processing Sot,c@ ofJapan, Vol.
35, No.
3, pages 414 425.O.
Furuse, and il.
\]ida.
1994b.
ConstituentIk)undary Parsing for lCxample-llased Ma('hineTranslation.
In l)roe.
4 Uoling '9~, pages 105I I I .O.
li'uruse, J. Kawai, H. Iida, S. Akamine,and I).B.
Kim.
1995.
Multi-lingual Spokeml,anguage Translation Utilizing Translation Ex-amples.
In Prec.
of NLPRS'95,  pages 544 549.M.
Kay.
1980.
Algorithm Schemata nd DataStructures in Syntactic Processing.
7>chnicalReport USL-80-1~2, XI~;ROX Pale Alto ResearchCenter.C.
Kempen and l'\].
lh)enkamt).
1987.
An \]n('re-mental l~rocedural GraHunar for Sentence For-mulation.
Co.qnitivc Science, 2(11): pages 20:l258.il.
Kitano.
:1994.
The g<DMDIALOG System.In Speech-2b-Spcech 75"anslation, 11.
Kitano,Kluwer Academic Publishers, pages 47 113.lie Sumita and 1t.
1ida.
1992.
Example-BasedTransfer of Japanese Adnominal Particles intoEnglish.
IEICIs' 7'ransaclions on Informationand Syslems, F75-1), No.4, pages 585 594.417
