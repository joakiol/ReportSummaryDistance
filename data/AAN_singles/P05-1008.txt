Proceedings of the 43rd Annual Meeting of the ACL, pages 58?65,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsEmpirically-based Control of Natural Language GenerationDaniel S. Paiva Roger EvansDepartment of Informatics Information Technology Research InstituteUniversity of Sussex University of BrightonBrighton, UK Brighton, UKdanielpa@sussex.ac.uk Roger.Evans@itri.brighton.ac.ukAbstractIn this paper we present a new approach tocontrolling the behaviour of a natural lan-guage generation system by correlating in-ternal decisions taken during free generationof a wide range of texts with the surface sty-listic characteristics of the resulting outputs,and using the correlation to control the gen-erator.
This contrasts with the generate-and-test architecture adopted by most previousempirically-based generation approaches,offering a more efficient, generic and holis-tic method of generator control.
We illus-trate the approach by describing a system inwhich stylistic variation (in the sense ofBiber (1988)) can be effectively controlledduring the generation of short medical in-formation texts.1 IntroductionThis paper1 is concerned with the problem of con-trolling the output of natural language generation(NLG) systems.
In many application scenarios thegenerator?s task is underspecified, resulting in mul-tiple possible solutions (texts expressing the de-sired content), all equally good to the generator,but not equally appropriate for the application.Customising the generator directly to overcomethis generally leads to ad-hoc, non-reusable solu-tions.
A more modular approach is a generate-and-test architecture, in which all solutions are gener-ated, and then ranked or otherwise selected accord-ing to their appropriateness in a separate post-1Paiva and Evans (2004) provides an overview of ourframework and detailed comparison with previousapproaches to stylistic control (like Hovy (1988),Green and DiMarco (1993) and Langkilde-Geary(2002)).
This paper provides a more detailed accountof the system and reports additional experimental re-sults.process.
Such architectures have been particularlyprominent in the recent development of empiri-cally-based approaches to NLG, where generatoroutputs can be selected according to applicationrequirements acquired directly from human sub-jects (e.g.
Walker et al (2002)) or statisticallyfrom a corpus (e.g.
Langkilde-Geary (2002)).However, this approach suffers from a number ofdrawbacks:1.
It requires generation of all, or at leastmany solutions (often hundreds of thou-sands), expensive both in time and space,and liable to lead to unnecessary interac-tions with other components (e.g.
knowl-edge bases) in complex systems.
Recentadvances in the use of packed representa-tions ameliorate some of these issues, butthe basic need to compare a large numberof solutions in order to rank them remains.2.
The ?test?
component generally does notgive fine-grained control ?
for example,in a statistically-based system it typicallymeasures how close a text is to some sin-gle notion of ideal (actually, statisticallyaverage) output.3.
Use of an external filter does not combinewell with any control mechanisms withinthe generator: e.g.
controlling combinato-rial explosion of modifier attachment oradjective order.In this paper we present an empirically-basedmethod for controlling a generator which over-comes these deficiencies.
It controls the generatorinternally, so that it can produce just one (locally)optimal solution; it employs a model of languagevariation, so that the generator can be controlledwithin a multidimensional space of possible vari-ants; its view of the generator is completely holis-tic, so that it can accommodate any other controlmechanisms intrinsic to the generation task.58To illustrate our approach we describe a systemfor controlling ?style?
in the sense of Biber (1988)during the generation of short texts giving instruc-tions about doses of medicine.
The paper continuesas follows.
In ?2 we describe our overall approach.We then present the implemented system (?3) andreport on our experimental evaluation (?4).
We endwith a discussion of conclusions and future direc-tions (?5).2 Overview of the ApproachOur overall approach has two phases: (1) offlinecalculation of the control parameters, and(2) online application to generation.
In the firstphase we determine a set of correlation equations,which capture the relationship between surfacelinguistic features of generated texts and the inter-nal generator decisions that gave rise to those texts(see figure 1).
In the second phase, these correla-tions are used to guide the generator to producetexts with particular surface feature characteristics(see figure 2).corpuslinguisticfeaturesfactoranalysisvariationdimensionsNLGsystemtextCP2CP1CPnvariationscoresvariationmodelcorrelationanalysiscorrelationequations?generatordecisionsat differentchoicepointsinputFigure 1: Offline processingThe starting point is a corpus of texts whichrepresents all the variability that we wish to cap-ture.
Counts for (surface) linguistic features fromthe texts in the corpus are obtained, and a factoranalysis is used to establish dimensions of varia-tion in terms of these counts: each dimension isdefined by a weighted sum of scores for particularfeatures, and factor analysis determines the combi-nation that best accounts for the variability acrossthe whole corpus.
This provides a language varia-tion model which can be used to score a new textalong each of the identified dimensions, that is, tolocate the text in the variation space determined bythe corpus.The next step is to take a generator which cangenerate across the range of variation in the cor-pus, and identify within it the key choice points(CP1, CP2, ?
CPn) in its generation of a text.
Wethen allow the generator to freely generate all pos-sible texts from one or more inputs.
For each textso generated we record (a) the text?s score accord-ing to the variation model and (b) the set of deci-sions made at each of the selected choice points inthe generator.
Finally, for a random sample of thegenerated texts, a statistical correlation analysis isundertaken between the scores and the correspond-ing generator decisions, resulting in correlationequations which predict likely variation scoresfrom generator decisions.NLGsystemtext inspecifiedstyleCP2CP1CPncorrelationequations?targetvariationscoreinputFigure 2: Online processingIn the second phase, the generator is adapted touse the correlation equations to conduct a best-firstsearch of the generation space.
As well as the usualinput, the generator is supplied with target scoresfor each dimension of variation.
At each choicepoint, the correlation equations are used to predictwhich choice is most likely to move closer to thetarget score for the final text.This basic architecture makes no commitment towhat is meant by ?variation?, ?linguistic features?,?generator choice points?, or even ?NLG system?.The key ideas are that a statistical analysis of sur-face features of a corpus of texts can be used todefine a model of variation; this model can then beused to control a generator; and the model can alsobe used to evaluate the generator?s performance.
Inthe next section we describe a concrete instantia-tion of this architecture, in which ?variation?
is sty-listic variation as characterised by a collection ofshallow lexical and syntactic features.3 An Implemented SystemIn order to evaluate the effectiveness of this gen-eral approach, we implemented a system whichattempts to control style of text generated as de-59fined by Biber (1988) in short text (typically 2-3sentences) describing medicine dosage instruc-tions.3.1 Factor AnalysisBiber characterised style in terms of very shallowlinguistic features, such as presence of pronouns,auxiliaries, passives etc.
By using factor analysistechniques he was able to determine complex cor-relations between the occurrence and non-occurrence of such features in text, which he usedto characterise different styles of text.2We adopted the same basic methodology, ap-plied to a smaller more consistent corpus of justover 300 texts taken from proprietary patient in-formation leaflets.
Starting with around 70 surfacelinguistic features as variables, our factor analysisyielded two main factors (each containing linguis-tic features grouped in positive and negative corre-lated subgroups) which we used as our dimensionsof variation.
We interpreted these dimensions asfollows (this is a subjective process ?
factoranalysis does not itself provide any interpretationof factors): dimension 1 ranges from texts that tryto involve the reader (high positive score) to textthat try to be distant from the reader (high negativescore); dimension 2 ranges from texts with morepronominal reference and a higher proportion ofcertain verbal forms (high positive score) to textthat use full nominal reference (high negativescore).33.2 Generator ArchitectureThe generator was constructed from a mixture ofexisting components and new implementation, us-ing a fairly standard overall architecture as shownin figure 3.
Here, dotted lines show the controlflow and the straight lines show data flow ?
thechoice point annotations are described below.The input constructor takes an input specifica-tion and, using a background database of medicineinformation, creates a network of concepts and re-2Some authors (e.g.
Lee (1999)) have criticised Biberfor making assumptions about the validity and gener-alisability of his approach to English language as awhole.
Here, however, we use his methodology tocharacterise whatever variation exists without need-ing to make any broader claims.3Full details of the factor analysis can be found in(Paiva 2000).lations (see figure 4) using a schema-based ap-proach (McKeown, 1985).inputconstructorsplitnetworknetworkorderingreferringexpressionNP pruningrealiserinitial input networkssentence-size networkssubnetwork chosenreferring expression netpruned networksentenceinputspecificationchoicepoint 1:number ofsentenceschoicepoint 2:type ofreferringexpressionchoicepoint 3:choice ofmappingruleFigure 3: Generator architecture with choice pointsEach network is then split into subnetworks bythe split network module.
This partitions the net-work by locating ?proposition?
objects (markedwith a double-lined box in figure 4) which have noparent and tracing the subnetwork reachable fromeach one.
We call these subnetworks propnets.
Infigure 4, there are two propnets, rooted in [1:take]and [9:state] ?
proposition [15:state] is not a rootas it can be reached from [1:take].
A list of all pos-sible groupings of these propnets is obtained4, andone of the possible combinations is passed to thenetwork ordering module.
This is the first sourceof non-determinism in our system, marked aschoice point one in figure 3.
A combination ofsubnetworks will be material for the realisation ofone paragraph and each subnetwork will be real-ised as one sentence.4For instance, with three propnets (A, B and C) the listof combinations would be [(A,B,C), (A,BC), (AB, C),(AC,B), (ABC)].602:patient 1:take3:medicine12:freq15:state13:value(2xday)4:pres7:dose9:state8:value(2gram)10:pres14:presarg0 arg16:of11:ofarg0 arg0arg0arg0arg0arg0arg1arg1tensetensetensefreq5:patientproxyFigure 4: Example of semantic network produced by theinput constructor5The network ordering module receives a combi-nation of subnetworks and orders them based onthe number of common elements between eachsubnetwork.
The strategy is to try to maximise thepossibility of having a smooth transition from onesentence to the next in accordance with CenteringTheory (Grosz et al, 1995), and so increase thepossibility of having a pronoun generated.The referring expression module receives onesubnetwork at a time and decides, for each objectthat is of type [thing], which type of referring ex-pression will be generated.
The module is re-usedfrom the Riches system (Cahill et al, 2001) and itgenerates either a definite description or a pronoun.This is the second source of non-determinism inour system, marked as choice point two in figure 3.Referring expression decisions are recorded byintroducing additional nodes into the network, asshown for example in figure 5 (a fragment of thenetwork in figure 4, with the additional nodes).NP pruning is responsible for erasing from a re-ferring expression subnetwork all the nodes thatcan be transitively reached from a node marked tobe pronominalised.
This prevents the realiser fromtrying to express the information twice.
In figure 5,[7:dose] is marked to be pronominalised, so theconcepts [11:of] and [3:medicine] do not need to berealised, so they are pruned.5Although some of the labels in this figure look likewords, they bear no direct relation to words in thesurface text ?
for example, ?of?
may be realised as agenitive construction or a possessive.3:medicine7:dose11:ofarg0arg021:pronoun refexp22:definite refexpFigure 5: Referring expressions and pruningThe realiser is a re-implementation of Nicolov?s(1999) generator, extended to use the wide-coverage lexicalised grammar developed in theLEXSYS project (Carroll et al, 2000), with furthersemantic extensions for the present system.
It se-lects grammar rules by matching their semanticpatterns to subnetworks of the input, and tries togenerate a sentence consuming the whole input.
Ingeneral there are several rules linking each piece ofsemantics to its possible realisation, so this is ourthird, and most prolific, source of non-determinismin the architecture, marked as choice point three infigure 3.A few examples of outputs for the input repre-sented in figure 4 are:the dose of the patient 's medicine is taken twice aday.
it is two grams.the two-gram dose of the patient 's medicine istaken twice a day.the patient takes the two-gram dose of the patient 'smedicine twice a day.From a typical input corresponding to 2-3 sen-tences, this generator will generate over a 1000different texts.3.3 Tracing Generator BehaviourIn order to control the generator?s behaviour wefirst allow it to run freely, recording a ?trace?
of thedecisions it makes at each choice point during theproduction of each text.
Although there are onlythree choice points in figure 3, the control structureincluded two loops: an outer loop which rangesover the sequence of propnets, generating a sen-tence for each one, and an inner loop which rangesover subnetworks of a propnet as realisation rulesare chosen.
So the decision structure for even asmall text may be quite complex.In the experiments reported here, the trace of thegeneration process is simply a record of the num-ber of times each decision (choice point, and whatchoice was made) occurred.
Paiva (2004) discussesmore complex tracing models, where the context ofeach decision (for example, what the precedingdecision was) is recorded and used in the correla-tion.
However the best results were obtained using61just the simple decision-counting model (perhapsin part due to data sparseness for more complexmodels).3.4 Correlating Decisions with Text FeaturesBy allowing the generator to freely generate allpossible output from a single input, we recorded aset of <trace, text> pairs ranging across the fullvariation space.
From these pairs we derived corre-sponding <decision-count, factor-score> pairs, towhich we applied a very simple correlational tech-nique, multivariate linear regression analysis,which is used to find an estimator function for alinear relationship (i.e., one that can be approxi-mated by a straight line) from the data available forseveral variables (Weisberg, 1985).
In our case wewant to predict the value for a score in a stylisticdimension (SSi) based on a configuration of gen-erator decisions (GDj) as seen in equation 1.(eq.
1) SSi = x0 + x1GD1 + ?
+ xnGDn + ?
6We used three randomly sampled data sets of1400, 1400 and 5000 observations obtained from apotential base of about 1,400,000 different textsthat could be produced by our generator from asingle input.
With each sample, we obtained a re-gression equation for each stylistic dimensionseparately.
In the next subsections we will presentthe final results for each of the dimensions sepa-rately.Regression on Stylistic Dimension 1For the regression model on the first stylistic di-mension (SS1), the generator decisions that wereused in the regression analysis7 are: imperativewith one object sentences (IMP_VNP), V_NP_PPagentless passive sentences (PAS_VNPP), V_NP by-passives (BYPAS_VN), and N_PP clauses (NPP) andthese are all decisions that happen in the realiser,i.e., at the third choice point in the architecture.This resulted in the regression equation shown inequation 2.6SSi represents a stylistic score and is the dependentvariable or criterion in the regression analysis; theGDj?s represent generator decisions and are called theindependent variables or predictors; the xj?s areweights, and ?
is the error.7The process of determining the regression takes careof eliminating the variables (i.e.
generator decisions)that are not useful to estimate the stylistic dimensions.(eq.
2)SS1 = 6.459 ?
(1.460?NPP) ?
(1.273*BYPAS_VN)?
(1.826?PAS_VNPP) + (1.200?IMP_VNP)8The coefficients for the regression on SS1 areunstandardised coefficients, i.e.
the ones that areused when dealing with raw counts for the genera-tor decisions.The coefficient of determination (R2), whichmeasures the proportion of the variance of the de-pendent variable about its mean that is explainedby the independent variables, had a reasonablyhigh value (.895)9 and the analysis of variance ob-tained an F test of 1701.495.One of the assumptions that this technique as-sumes is the linearity of the relation between thedependent and the independent variables (i.e., inour case, between the stylistic scores in a dimen-sion and the generator decisions).
The analysis ofthe residuals resulted in a graph that had someproblems but that resembled a normal graph (see(Paiva, 2004) for more details).Regression on Stylistic Dimension 2For the regression model on the second stylisticdimension (SS2) the variables that we used were:the number of times a network was split (SPLIT-NET), generation of a pronoun (RE_PRON), auxil-iary verb (VAUX), noun with determiner (NOUN),transitive verb (VNP), and agentless passive(PAS_VNP) ?
the first type of decision happens inthe split network module (our first choice point);the second, in the referring expression module(second choice point); and the rest in the realiser(third choice point).The main results for this model are as follows:the coefficient of determination (R2) was .959 andthe analysis of variance obtained an F testof 2298.519.
The unstandardised regression coeffi-cients for this model can be seen in eq.
3.(eq.
3)SS2 = ?
27.208 ?
(1.530?VNP) + (2.002?RE_PRON)?
(.547?NOUN) + (.356?VAUX)+ (.860?SPLITNET) + (.213?PAS_VNP)108This specific equation came from the sample with5,000 observations ?
the equations obtained fromthe other samples are very similar to this one.9All the statistical results presented in this paper aresignificant at the 0.01 level (two-tailed).10This specific equation comes from one of the samplesof 1,400 observations.62With this second model we did not find any prob-lems with the linearity assumptions as the analysisof the residuals gave a normal graph.4 Controlling the GeneratorThese regression equations characterise the way inwhich generator decisions influence the final styleof the text (as measured by the stylistic factors).
Inorder to control the generator, the user specifies atarget stylistic score for each dimension of the textto be generated.
At each choice point during gen-eration, all possible decisions are collected in a listand the regression equations are used to orderthem.
The equations allow us to estimate the sub-sequent values of SS1 and SS2 for each of the pos-sible decisions, and the decisions are orderedaccording to the distance of the resulting scoresfrom the target scores ?
the closer the score, thebetter the decision.Hence the search algorithm that we are usinghere is the best-first search, i.e., the best local solu-tion according to an evaluation function (which inthis case is the Euclidian distance from the targetand the resulted value obtained by using the re-gression equation) is tried first but all the otherlocal solutions are kept in order so backtracking ispossible.In this paper we report on tests of two internalaspects of the system11.
First we wish to know howgood the generator is at hitting a user-specifiedtarget ?
i.e., how close are the scores given by theregression equations for the first text generated tothe user?s input target scores.
Second, we wish toknow how good the regression equation scores areat modelling the original stylistic factors ?
i.e., wewant to compare the regression scores of an outputtext with the factor analysis scores.
We addressthese questions across the whole of the two-dimensional stylistic space, by specifying a rectan-gular grid of scores spanning the whole space, andasking the generator to produce texts for each gridpoint from the same semantic input specification.11We are not dealing with external (user) evaluation ofthe system and of the stylistic dimensions we ob-tained ?
this was left for future work.
Nonetheless,Sigley (1997) showed that the dimensions obtainedwith factor analysis and people?s perception have ahigh correlation.-25-30-35-40-451086420-2-4-6-8-108079787776757473727170696867666564636261605958575655545352515049484746454443424140393837363534333231302928272625242322212019181716151413121110987654321Figure 6: Target scores for the textsIn this case we divided the scoring space withan 8 by 10 grid pattern as shown in figure 6.12 Eachpoint specifies the target scores for each text thatshould be generated (the number next to each pointis an identifier of each text).
For instance, textnumber 1 was targeted at coordinate (?7, ?44),whereas text number 79 was targeted at coordinate(+7, ?28).4.1 Comparing Target Points and RegressionScoresIn the first part of this experiment we wanted toknow how close to the user-specified target coor-dinates the resulting regression scores of the firstgenerated text were.
This can be done in two dif-ferent ways.
The first is to plot the resulting regres-sion scores (see figure 7) and visually check if itmirrors the grid-shape pattern of the target points(figure 6) ?
this can be done by inspecting the textidentifiers13.
This can be a bit misleading becausethere will always be variation around the targetpoint that was supposed to be achieved (i.e., thereis a margin for error) and this can blur the com-parison unfavourably.12The range for each scale comes from the maximumand minimum values for the factors obtained in thesamples of generated texts.13Note that some texts obtained the same regressionscore and, in the statistical package, only one wasnumbered.
Those instances are: 1 and 7; 18 and 24;22 and 28.63-25-30-35-40-451086420-2-4-6-8-10807978777675743727069686766656463626160595857565554535251504948474645444342414039383736354333231302928272625242322212019181716151413121110987654321Figure 7: Texts scored by using theregression equationA more formal comparison can be made by plot-ting the target points versus the regression resultsfor each dimension separately and obtaining a cor-relation measure between these values.
These cor-relations are shown in figure 8 for SS1 (left) andSS2 (right).
The degree of correlation (R2) betweenthe values of target and regression points is 0.9574for SS1 and 0.942 for SS2, which means that thesearch mechanism is working very satisfactorily onboth dimensions.1486420-2-4-6-8-1086420-2-4-6-8-10-25-30-35-40-45-25-30-35-40-45Figure 8: Plotting target points versus regression resultson SS1 (left) and SS2 (right)4.2 Comparing Target Points and StylisticScoresIn the second part of this experiment we wanted toknow whether the regression equations were doingthe job they were supposed to do by comparing theregression scores with stylistic scores obtained(from the factor analysis) for each of the generatedtexts.
In figure 9 we plotted the texts in a graph inaccordance with their stylistic scores (once again,some texts occupy the same point so they do notappear).14All the correlational figures (R2) presented for thisexperiment are significant at the 0.01 level (two-tailed).-25-30-35-40-451086420-2-4-6-8-108079787776757437271 7069686766656463626160595857565554535251504948474645444342414039383736354333231302928272625242322212019181716151413121110987654321Figure 9: Texts scored using the two stylistic dimensionobtained in our factor analysisIn the ideal situation, the generator would haveproduced texts with the perfect regression scoresand they would be identical to the stylistic scores,so the graph in the figure 9 would be like a grid-shape one as in figure 6.
However we have alreadyseen in figure 7, that this is not the case for the re-lation between the target coordinates and the re-gression scores.
So we did not expect the plot ofstylistic scores 1 (SS1) against stylistic scores 2(SS2) to be a perfect grid.Figure 10 (left-hand side) shows the relation be-tween the target points and the scores obtainedfrom the original factor equation of SS1.
The valueof R2, which represents their correlation, is high(0.9458), considering that this represents the possi-ble accumulation of errors of two stages: from thetarget to the regression scores, and then from theregression to the actual factor scores.
On the rightof figure 10 we can see the plotting of the targetpoints and their respective factor scores on SS2.The correlation obtained is also reasonably high(R2 = 0.9109).1086420-2-4-6-8-101086420-2-4-6-8-10-25-30-35-40-45-25-30-35-40-45Figure 10: Plotting target points versus factor scores onSS1 (left) and SS2 (right)5 Discussion and Future WorkThese results demonstrate that it is possible to pro-vide effective control of a generator correlatinginternal generator behaviour with characteristics ofthe resulting texts.
It is important to note that these64two sets of variables (generator decision and sur-face features) are in principle quite independent ofeach other.
Although in some cases there arestrong correlations (for example, the generator?suse of a ?passive?
rule, correlates with the occur-rence of passive participles in the text), in othersthe relationship is much less direct (for example,the choice of how many subnetworks to split a net-work into, i.e., SPLITNET, does not correspond toany feature in the factor analysis), and the way in-dividual features combine into significant factorsmay be quite different.Another feature of our approach is that we donot assume some pre-defined notion of parametersof variation ?
variation is characterised completelyby a corpus (in contrast to approaches which use acorpus to characterise a single style).
The disad-vantage of this is that variation is not grounded insome ?intuitive?
notion of style: the interpretationof the stylistic dimensions is subjective and tenta-tive.
However, as no comprehensive computation-ally realisable theory of style yet exists, we believethat this approach has considerable promise forpractical, empirically-based stylistic control.The results reported here also make us think thata possible avenue for future work is to explore theissue of what types of problems the generalisationinduced by our framework (which will be dis-cussed below) can be applied to.
This paper dealtwith an application to stylistic variation but, intheory, the approach can be applied to any kind ofprocess to which there is a sorting function that canimpose an order, using a measurable scale (e.g.,ranking), onto the outputs of another process.Schematically the approach can be abstracted toany sort of problem of the form shown in fig-ure 11.
Here there is a producer process outputtinga large number of solutions.
There is also a sorterprocess which will classify those solutions in a cer-tain order.
The numerical value associated with theoutput by the sorter can be correlated with the de-cisions the producer took to generate the output.The same correlation and control mechanism usedin this paper can be introduced in the producerprocess, making it controllable with respect to thesorting dimension.produceroutput 1output 2output moutput 3output 4...sortingdimensionsorteroutput 3output 1output 14output 10output m............Figure 11: The producer-sorter scheme.ReferencesBiber, Douglas (1988) Variation across speech and writing.Cambridge University Press.Cahill, Lynne; J. Carroll; R. Evans; D. Paiva; R. Power; D. Scott; andK.
van Deemter From RAGS to RICHES: exploiting the potentialof a flexible generation architecture.
Proceedings of ACL/EACL2001, pp.
98-105.Carroll, John; N. Nicolov; O. Shaumyan; M. Smets; and D. Weir(2000) Engineering a wide-coverage lexicalized grammar.
Pro-ceedings of the Fifth International Workshop on Tree AdjoiningGrammars and Related Frameworks.Green, Stephen J.; and C. DiMarco (1993) Stylistic decision-makingin NLG.
In Proceedings of the 4th  European Workshop on Natu-ral Language Generation.
Pisa, Italy.Grosz, Barbara J.; A.K.
Joshi; and S. Weinstein (1995) Centering: AFramework for Modelling the Local Coherence of Discourse.
In-stitute for Research in Cognitive Science, IRCS-95-01, Universityof Pennsylvania.Hovy, Eduard H. (1988) Generating natural language under prag-matic constraints.
Lawrence Erlbaum Associates.Langkilde-Geary, Irene.
(2002) An empirical verification of coverageand correctness for a general-purpose sentence generator.
Proceed-ing of INLG?02, pp.
17-24.Lee, David (1999) Modelling Variation in Spoken And Written Eng-lish: the Multi-Dimensional Approach Revisited.
PhD thesis, Uni-versity of Lancaster, UK.McKeown, Kathleen R. (1985) Text Generation: Using DiscourseStrategies and Focus Constraints to Generate Natural LanguageText.
Cambridge University Press.Nicolov, Nicolas (1999) Approximate Text Generation from Non-hierarchical Representations in a Declarative Framework.
PhDThesis, University of Edinburgh.Paiva, Daniel S. (2000) Investigating style in a corpus of pharmaceuti-cal leaflets: results of a factor analysis.
Proceedings of the StudentWorkshop of the 38th Annual Meeting of the Association for Com-putational Linguistics (ACL'2000), Hong Kong, China.Paiva, Daniel S. (2004) Using Stylistic Parameters to Controla Natural Language Generation System.
PhD Thesis, University ofBrighton, Brighton, UK.Paiva, Daniel S.; R. Evans (2004) A Framework for Stylistically Con-trolled Generation.
In Proceedings of the 3rd International Confer-ence on Natural Language Generation (INLG?04).
New Forest,UK.Sigley, Robert (1997) Text categories and where you can stick them: acrude formality index.
International Journal of Corpus Linguistics,volume 2, number 2, pp.
199-237.Walker, Marilyn; O. Rambow, and M. Rogati (2002) Training a Sen-tence Planner for Spoken Dialogue Using Boosting.
ComputerSpeech and Language, Special Issue on Spoken Language Genera-tion.
July.Weisberg, Sanford (1985) Applied Linear Regression, 2nd edition.John Wiley & Sons.65
