Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 571?578, Vancouver, October 2005. c?2005 Association for Computational LinguisticsA Cost-Benefit Analysis of Hybrid Phone-Manner Representations for ASREric Fosler-LussierDepartment of Computer Science and EngineeringDepartment of LinguisticsOhio State UniversityColumbus, OH 43210fosler@cse.ohio-state.eduC.
Anton RyttingDepartment of LinguisticsOhio State UniversityColumbus, OH 43210rytting@ling.ohio-state.eduAbstractIn the past decade, several researchershave started reinvestigating the use ofsub-phonetic models for lexical represen-tations within automatic speech recogni-tion systems.
Lest history repeat itself,it may be instructive to mine the furtherpast for models of lexical representationsin the lexical access literature.
In thiswork, we re-evaluate the model of Briscoe(1989), in which a hybrid strategy of lex-ical representation between phones andmanner classes is promoted.
While manyof Briscoe?s assumptions do not match upwith current ASR processing models, weshow that his conclusions are essentiallycorrect, and that reconsidering this struc-ture for ASR lexica is an appropriate av-enue for future ASR research.1 IntroductionAlmost every state-of-the-art large vocabulary au-tomatic speech recognition (ASR) system requiresthe sharing of sub-word units in order to achievethe desired vocabulary coverage.
Traditionally,these sub-word units are determined by the phonesor phonemes of a language (depending on desireddetail of representation).
However, phonetic (orphonemic) representation has its pitfalls (cf.
(Os-tendorf, 1999)).
Among the problems cited inthe literature are that (1) segments are often dif-ficult for machines to recognize from the acousticcues alone, because the acoustic cues to a particu-lar phoneme are multi-faceted, and (2) the intendedwords and phrases are not always recoverable evenfrom correctly recognized segments, because speak-ers themselves will also fail to articulate words withthe dictionary-listed phonemes.
The first of theseproblems refers to the discriminability of phonemeswithin an inventory; the second to the reliability of(actual) phone sequences mapping to the canonicalphonemic representations of words.
This is partic-ularly true in conversational speech (such as thatfound in the Switchboard corpus), where pragmaticcontext and conversational conventions assist humancomprehension (but not current ASR systems).A common approach for handling pronunciationvariation is to introduce alternative entries into thelexicon.
However, phones that are perceived as non-canonical (for example, when an /eh/ is heard asan /ih/ by linguistic transcribers) often are closerin acoustic space to the Gaussian means of thecanonical phones, rather than the perceived phones(Sarac?lar et al, 2000).
This insight suggests thatacoustic models need to be cognizant of potentialpronunciation changes.
Thus the lexical and acous-tic models should work hand in hand.Another way to model this type of pronunciationvariation is to find the commonalities that the canon-ical and perceived phone share in terms of a sub-phonetic representation.
In the past decade, a signif-icant community in acoustic-phonetic ASR researchhas been turning to distinctive features (Jakobson etal., 1952) for building ASR lexica.
While an ex-haustive description of these approaches is beyondthe scope of this paper, estimates of phonologicalfeature probabilities have been combined to obtainphone probabilities (Kirchhoff, 1998), or incorpo-rated into ?feature bundles?
that allow representa-571tion of phonological processes (Finke et al, 1999).More recent work has integrated phonologicalfeatures into graphical models (Livescu et al, 2003)and landmark based systems (Juneja and Espy-Wilson, 2004).
The common thread among thisresearch is the notion that acoustic models shouldbe sensitive to sub-phonetic information.
With thistrend in phonological representation research, it istime to re-examine some older hypotheses about lex-ical access and speech processing in order to gainsome insight in this current featural renaissance.Sub-phonetic ASR research is also driven by thefact that deviations from canonical pronunciationand from correct perception of phones is far fromrandom; indeed, there have been a number of stud-ies demonstrating that both of these variations havedefined, modelable trends.
Deviations from canon-ical pronunciation can be described by phonologi-cal rules, and errors in perception also tend to con-form to phonological patterns.
By and large, con-fusions occur (at least in humans) between phoneswith phonological features in common (e.g., (Millerand Nicely, 1955)).
In particular, three features(voicing, manner, and place) have been postulated asrelatively invariant (see e.g., (Stevens, 1981), quotedin (Church, 1987)).
It follows from this phonetic de-tection based on the most reliable features may han-dle highly variable speech more robustly than sys-tems which demand full identity over all the featuresfor a given phone or phone sequence.Consequently, a number of researchers have pre-viously suggested using certain broad classes of seg-ments, rather than full phonemic identification, for afirst pass on recognition.
For instance, Shipman andZue (1982), working on large-vocabulary isolatedword recognition, used both two-way consonant-vowel distinctions and a six-way distinction basedon manner in order to divide their 20,000-word dic-tionary into ?cohorts?
or groups of words.
Theyfound that this partial specification of segments re-duced the search space of word candidates signifi-cantly.
Carlson et al (1985) found similar resultsfor English and four other languages.2 A suggested compromise: a hybridphone-manner representationBriscoe (1989) extended this broad-class approachto address the problem of lexical access on con-nected speech.
However, Briscoe argues against theuse of broad, manner-based classes at all times.
Heargues that manner cues provide no particular ad-vantage for stressed syllables, but that all cues aresufficiently reliable in stressed syllables to justifya full segmental analysis.
Working with a 30,000-word lexicon, Briscoe shows that the manner-basedbroad classes for weak (reduced) syllables, togetherwith full identification of strong (unreduced) sylla-bles constrained the set of possible candidates satis-factorily.
Unfortunately, he only provides results forone sentence from his corpus.This approach proposes to adjust the granularityof recognition dynamically, depending on the stresslevel of the current syllable.
The details of how thiswould be managed are left somewhat vague.
As itstands, it would seem to depend crucially on first de-tecting the stress of each frame, so as to determinewhich alphabet of symbols to apply to incoming in-put.
Alternatively, it could recognize the broad classas a first pass, and then refine this into a full phone-mic analysis for stressed syllables in a second pass,at the cost of multiplying passes through the speechdata.
It is not possible in this system to recover fromthe miscategorization of stress.One possible remedy is to bypass a hard decisionon stress and run both a manner-based broad-classdetector and a traditional phonemic system in paral-lel.
These then may be combined according to theprobability of lexical stress, such that those framesjudged less likely to be stressed weight the broad-class analysis more heavily, and those judged morelikely to be stressed weight the narrow phonemicanalysis more heavily.
Its advantage is that a fullphonemic analysis is recoverable for each frame andphone, but those in weak syllables (and hence lesslikely to be accurate) weigh in less heavily.Briscoe?s analysis is in terms of lexical access ac-tivations: taking a cue from the lexical access com-munity, he assumes that any ?partially activated?word (e.g., ?boat?
and ?both?
being active after pro-cessing ?bo?)
will contribute linearly to the process-ing time in ASR.
However, most large-vocabularyASR systems today use a tree-based lexicon wherecommon phonetic prefixes of words are processedonly once, thus invalidating this conjecture.
Briscoeexperimented with several triggers for starting a newword ?
at every phone, at the beginnings of sylla-bles, at the beginnings of syllables with unreducedvowels, and at the beginnings of word boundaries.572Category Example (Vietnamese) Cohorts# of Words 6247Stress pattern only(lower bound) 0001 84Identify phonesin stressed syllables 0001:m iy z 4709+CV pattern ofunstressed syllables 0001:CV:VC:CV:m iy z 5609+manner pattern ofunstressed syllables 0001:FV:CS:NV:m iy z 6076Phonetic prons.
(upper bound) v iy .
eh t .
n aa .
m iy z 6152Table 1: Cohorts for varied lexical representationsHowever, the latter three require oracle informationas to where word or syllable boundaries can occur.
Amore appropriate measure commensurate with cur-rent ASR practice would be to only allow words tostart where a previous word hypothesis ends.In the remainder of the paper, we seek to validate(or invalidate) Briscoe?s claim that a hybrid phoneticand feature model is appropriate for ASR process-ing.
In the 15 years since Briscoe?s paper, the ASRcommunity has developed large phonetically tran-scribed corpora and more advanced computationaltools (such as the AT&T Finite-State Toolkit (Mohriet al, 2001)) that we can apply to this problem.3 Experiment 1: Effective Partitioning byManner-based Broad ClassesOur first experiment explores various types of broadclasses to determine the effects of these encodingson cohort size within a sample 6,000 word dictio-nary.1 Here we use the lexical stress-marked dictio-nary provided with the TIMIT database (Garofoloet al, 1993), which was syllabified using the NISTTsylb2 syllabifier (Fisher, 1996).Rather than calculate cohort size directly, we cal-culate the number of cohorts into which our dictio-nary is partitioned, a measure which Carlson et al(1985) showed to correlate well with expected co-hort size.
(Note that this is an inverse correlation.
)This describes the static discriminability of the lexi-con: systems that have words with the same lexicalrepresentation will not be able to discriminate be-tween these two words acoustically and must rely onthe language model to discriminate between them.1?Cohort size?
is used here (as with Shipman and Zue(1982)) to mean the number of distinct vocabulary items thatmatch a particular broad-class encoding.
It is not intended toimply a particular theory of lexical access.Before proceeding, it may useful to set upper andlower bounds for this exercise (Table 1).
An obvi-ous upper bound is the full phonemic disambigua-tion of every word.
Of the 6247 words in the dictio-nary, 6152 unique pronunciations are found (a fewcohorts consisting of sets of homophones).
A con-venient lower bound is the lexical stress pattern ofthe word, devoid of any segmental information: e.g.,?unidirectional?
has its stress on the 4th of 6 sylla-bles; hence, 000100 is its lexical-stress profile.
84unique lexical-stress profiles exist in the dictionary.Between these two bounds, three variant broad-class partitions were explored for isolated wordrecognition.
All three use the lower-bound stressprofile as a starting place, combined with full phone-mic information for the syllable with primary stress.The first, with no additional segmental information,produces 4709 distinct cohorts.
The second adds aconsonant-vowel (CV) profile for the unstressed syl-lables, which boosts the number of distinct cohortsto 5609.
The final partition replaces the CV pro-file with a six-class manner-based broad-class par-tition (Nasals, Stops, Fricatives, Glides, Liquids,and Vowels).
Including a manner-class representa-tion for unstressed vowels increases the number ofcohorts to 6076, which is very close to the upperbound.
Thus, there is not much loss of lexical dis-criminability when using this type of representation.3.1 CaveatsNow, for this scheme to be maximally useful forrecognition, several conditions must obtain.
First,we have assumed that we can reliably detect lex-ically stressed syllables within the speech signal.Waibel (Waibel, 1988) has shown that stress cor-relates with various acoustic cues such as spectralchange.
As a side experiment, we have shownthat very basic methods provide encouraging re-sults (only sketched here due to space constraints).We re-annotated TIMIT with lexical stress mark-ings, where all frames of each stressed syllable (in-cluding onset and coda consonants, not just the nu-cleus) were marked as stressed.
A multi-layer per-ceptron with 100 hidden units was trained to pre-dict P (Stress|Acoustics) with a nine-frame contextwindow.
No additional phonetic information be-sides the binary label stressed/unstressed was usedin training.
Frame-by-frame results on the TIMITtest set were 75% accurate (chance: 52%), and when573MLP output was greater than 0.9, a precision of 89%was obtained (recall: 20%).
While far from perfect,this result strongly suggests that even very simplemethods can predict lexical stress fairly reasonably.A second assumption in the above analysis wasthat words occur in isolation.
It is clear that in con-nected speech, there are a larger number of poten-tial lexical confusions.
A third assumption is thatthose features we are relying upon in our partitions(namely, all features within stressed syllables, andmanner of articulation for unstressed syllables) areperfectly reliable and discriminable.
In the next twosections, we relax these assumptions by applying ex-tensions of this method to connected speech.4 Experiment 2: What does a hybridrepresentation buy you?As Experiment 1 shows, the hybrid phone/featurerepresentation does not drastically decrease the dis-criminability of the (albeit small) lexicon.
It is alsopossible that such a representation reduces pronun-ciation variation, by allowing the canonical repre-sentation to more closely match actual pronuncia-tions.
For example, we have demonstrated that forcommon ASR corpora (Switchboard and TIMIT),segments in unstressed syllables were much morelikely to deviate from their canonical lexical rep-resentation (Fosler-Lussier et al, 1999).
If phonesthat deviate from canonical still keep the same man-ner class, then a dictionary built with Briscoe-esquerepresentations should more closely match the ac-tual pronunciations of words in running speech (astranscribed by a phonetician).4.1 MethodIn order to test this theory, we used phonetic datafrom (Fosler-Lussier et al, 1999) in which theICSI phonetic transcripts of the Switchboard corpus(Greenberg et al, 1996; NIST, 1992) were aligned toa syllabified version of the Pronlex dictionary (Lin-guistic Data Consortium (LDC), 1996), which has71014 entries for 66293 words.
In this alignment,for every canonical phone given by the lexicon, therewere zero or more corresponding realized phones.From these data we extracted the canonical and real-ized pronunciation of each word token, for a total of38,527 tokens.
Generally, high-frequency functionwords show the most variation, so they may benefitmost from a manner-based representation.Lexicon type Strict Matchingmatching w/ deletion1) Phonetic units 37.0% 50.1%2) Manner-based function words 50.2% 69.6%3) + Manner for unstressed syls 53.4% 74.6%4) + Manner for secondary stress 55.7% 77.9%5) Manner for all syls 60.7% 85.2%Table 2: Percent of words pronounced canonicallyfor phonetic and hybrid lexical representationsGiven these word pronunciation data, we can ex-amine how many word tokens have transcriptionsthat match their dictionary-listed pronunciations,given the broad-class mappings for various sets ofsyllables.
We built lexica and mapped phonetic tran-scriptions according to five different criteria:1.
Every segment is phone based (no classes).2.
Function words use manner-based classes.3.
Unstressed syllables and function words usemanner only.4.
Secondary stressed syllables also use manner.
(Primary stressed syllables are phone based.)5.
Every segment uses manner-based classes.We noted in the data (as others have done) that alarge proportion of the pronunciation variation wasdue to phone deletion (29% of words) ?
whichwould not be handled by the manner-based lexicon.However, it is likely that not every phone deletionleads to an ASR error (as attested by the fact thatstate-of-the-art Switchboard ASR error rates are typ-ically less than 29%).
Often there is enough residualphonetic evidence of the deleted phone, or enoughphonetic evidence in other parts of the word, to rec-ognize a word correctly despite the deletion.
Thus,we decided to use a two-part strategy in calculatingcanonical pronunciation (Table 2).
The first column,?strict matching?, allows no insertions or deletionswhen comparing the canonical and realized pronun-ciation.
?Matching with deletion?
reports the idealsituation where phone deletions were perfectly re-coverable in their canonical form.
Including and ig-noring deletions provides upper and lower boundson the true lexical access results.
(Insertions are rel-atively rare and not anticipated to affect the resultssignificantly, and hence are not examined.
)4.2 Results and DiscussionIn Table 2, we see that a standard ASR lexicon ap-proach (strict matching 1), does not match the tran-574scribed data very well, with only 37% of wordspronounced according to the dictionary.
The strictmatching hybrid scenario on line 3 most closely re-sembles Briscoe?s experiment, and shows a markedimprovement in matching the dictionary and real-ized pronunciations; comparing the two, we see thatusing manner-based broad classes reduces mismatchby 25% of the total error (from 63% error to 47%),most of which comes from improved modeling offunction words (line 2).
Whether this gain in repre-sentation is worthwhile will depend of course on thecost in terms of the increased hypothesis space.By allowing for perfect deletion recovery (whichwill of necessity entail another large expansion ofthe hypothesis space), a somewhat more optimisticis obtained.
Comparing the ?matching with dele-tion?
columns of lines 1 and 3, we see that a littleover half of the non-deletion pronunciation variationis due to manner changes in unstressed syllables.Again, a good chunk of this is in function words.By moving to manner class for stressed syllables aswell would bring the hypothetical error from 25% to15%, but at the cost of a huge explosion in the hy-pothesis space (as Briscoe rightly points out and asdiscussed in the next section).One interesting implication of this data is thatover all types of segments (stressed and unstressed),roughly three-quarters of word pronunciation vari-ants differ from the canonical only in terms ofwithin-manner variation and phonetic deletion.The moral of this story is that manner-based broadclasses may be a useful type of back off from trulyreduced and variable syllables (particularly func-tion words), but the full benefit of such a maneuverwould only be realized after a reasonable solutionfor recovering large-scale deletions is found.
Thismay come from predicting with increased specificitywhere deletions are likely to occur (e.g., complexcodas), and what reduced realizations (e.g., of func-tion words) are most common.5 Experiment 3: What is the cost of ahybrid representation?Briscoe measured the cost of hybrid representationin terms of the number of lexical activations thata partially-completed word creates (see Section 2).Yet Briscoe?s methodology has several shortcom-ings when applied to today?s ASR technology; asummary of the arguments presented above are: (1)Tree-based lexica now share processing for wordswith identical prefixes.
(2) New words are acti-vated only when other word hypotheses end.
(3) Wenow have a large amount of phonetically transcribed,spontaneous speech.
(4) Perfect stress detection isnot really achievable.Given criticism 1, a better measure of potentialprocessing requirements is to generate a lattice ofhypothesized words and count the number of arcs inthe lattice.
This lattice can be constructed in sucha way that criticism 2 is satisfied.
In the next sec-tion, we present a finite state machine formalism forgenerating such a lattice.We apply this technique to the phonetic transcrip-tion of the Switchboard corpus (thus alleviating crit-icism 3).
However, this introduces several problems.As Experiment 2 shows, many words have pronun-ciations that do not appear in the dictionary.
Thus,we must find a way to alleviate the mismatch be-tween the phonetic transcription and the dictionaryin a way that is plausible for ASR processing.We can address criticism 4 by creating phone-based and manner-based transcriptions that will runin parallel; thus, the lattice generator would befree to choose whichever representation allows thematching to a dictionary word.5.1 MethodIn this experiment we consider a finite-state trans-ducer model of the strategy described above.
Thiscorresponds not to the ASR system as a whole, butrather to the pronunciation model of a traditionalsystem.
We assume that the pronunciation as givenby the transcriber is correct, but we model the trans-formation of realized phones into canonical dictio-nary pronunciations.
Since we are only investigatingthe combined acoustic-phonetic-lexical representa-tion, we have left out the re-weighting and prun-ing of hypotheses due to integration of a languagemodel, discourse model, or any other constraints.Specifically, this model consists of three finitestate transducers composed.
The first FSM, R,encodes the representation of the realized phonetictranscription of the spoken corpus.
In order to matchthis to dictionary pronunciations, we train a confu-sion matrix on all realized/canonical phone pairs, toobtain P (dictionary phone|transcribed phone);these confusion probabilities are encoded as a finitestate transducer C. Thus, C is derived by computing575the strength of all correspondences between thephonetic transcription of what was actually saidat the phone level and the canonical pronuncia-tion of the corresponding words.
This confusionmatrix consists of three parts, corresponding tosubstitutions, insertions, and deletions.1.
Pairwise substitutions are counted to yield astandard confusion matrix.2.
Where two or more realized phones correspondto a single canonical phone (a rare occurrence,as in e.g., really /r iy l iy/ ?
[r ih ax l iy]), eachrealized phone is allowed (independently) to beeither deleted or substituted with its pairwiseconfusions from (1).3.
Deleted phones are assumed to be potentiallyrecoverable (as in Experiment 2), so both anepsilon transition and the canonical pronunci-ation are preserved in the confusion matrix.In each of these confusion matrices, we have al-ways preserved the pathway from each realized ut-terance to its canonical representation for the wholecorpus.
So for this seen corpus, it is always possi-ble in theory to recover the canonical representation,such that the right answer is always one of the pos-sible hypotheses.
While this may seem a bit strange,here we can only overestimate the potential hypoth-esis space (by adding the correct string and by as-suming that deletions are recoverable); the point ofthis exercise is to see the number of total hypotheses(the search space) generated under such a system.The third transducer, D, is the ASR dictionary thatwe wish to test.
Thus, composingR?C?Dwill givethe graph of all potential complete hypotheses in thisspace.
Figure 1 shows a pruned hypothesis graph forthe phrase ?it?s really sad?
(the full hypothesis graphhas 12216 arcs).5.2 Results and DiscussionBy choosing different sub-word representations, wecan test Briscoe?s contention that backing off tomanner-based broad classes for certain (e.g., un-stressed) syllables will reduce the search spaceand/or facilitate recovery of the intended wordstring.
When a phone is substituted with a mannerclass, we construct C so that the generated confu-sions are over manner classes rather than phones.01atitout2it?ssh3srirerearhee4rio5realreelrial6reallyriely<PHDEL>aareiohuhareorourwewereyeahyou7waswithaareiohuhsh8sadadaddFigure 1: Pruned hypothesis graph for It?s really sadFigure 2 shows how the number of hypotheses perword changes as a function of the number of wordsin the hypothesis.
Note that if the relationship werelinear, we would expect to see a flat line.
The figuredemonstrates that that Briscoe?s conclusions werecorrect, given the assumption that one can accu-rately detect lexical stress (as illustrated by the linewith circles on 2).
Across all utterances, the averagenumber of hypotheses per word for the hybrid dictio-nary was 510 (roughly 1/3 of the phone-based aver-age of 1429).
However, when one allows for the factthat stress detection is not perfect, one sees an in-crease in the amount of necessary computation: thenon-ideal hybrid dictionary has an average of 33220 2 4 6 8 10 12 14 16 18 2000.511.522.5x 104 Average number of hypotheses per word by number of words in utteranceNumber of words in transcriptAveragenumber of hypothesesper wordPhone?based lexiconPhone + manner lexicon, idealized syllable stressPhone + manner lexicon, non?idealized syllable stressManner?based lexiconFigure 2: Average number of hypotheses per wordas a function of number of words in utterance576hypotheses per word (2.3 times the phone-based av-erage).
Yet this is much lower than the potentialgrowth of the hypothesis space given with manner-only dictionaries.
This dictionary generated a hy-pothesis space 12 times as large as a phone baseddictionary (17186 hypotheses/word average); more-over, the curve grows significantly as a function ofthe number of words, so longer utterances will takedisproportionately more space.
Thus, Briscoe?s hy-pothesis that purely manner-based decoding is tooexpensive seems to be confirmed.6 Integration into ASRThis paper has investigated hybrid representationsalong computational phonology lines, but we havealso trained an ASR system with a hybrid lexicon forthe Wall Street Journal (WSJ0) corpus.
Space doesnot permit a full explanation of the experiment here(for more details, see (Fosler-Lussier et al, 2005)),but we include the results from this experiment asevidence of the validity of the approach.In this experiment, we trained phonetic andmanner-based acoustic models for all segments us-ing the flat-start recipe of the HTK recognizer(Young et al, 2002).
After a number of itera-tions of EM-training, we constructed a hybrid set ofacoustic models and lexicon in which phones in un-stressed syllables were replaced with manner classes(Hybrid-all).
We also derived a lexicon in which therecognizer could choose whether a manner or pho-netic representation was appropriate for unstressedsegments (Hybrid-choice).
During evaluation, wefound that the Hybrid-choice lexicon degraded onlyslightly over a phone-based lexicon (9.9% word er-ror vs. 9.1%), and in fact improved recognitionin mild (10dB SNR) additive car noise (13.0% vs.15.4%).
The Hybrid-all was worse on clean speech(13.1% WER) but statistically the same as phone-based on noisy speech (15.8%).
While not conclu-sive, this suggests that hybrid models may providean interesting avenue for robustness research.7 ConclusionOur studies verify to some degree Briscoe?s claimthat a hybrid representation for lexical modeling,with stressed syllables receiving full phonetic rep-resentation and unstressed syllables represented bymanner classes, can improve ASR processing.
How-ever, our analysis shows that the argument for thishypothesis plays out along very different lines thanin Briscoe?s study.
A hybrid phone-manner lexi-con can theoretically benefit ASR because (a) thediscriminative power of the lexicon is not reducedgreatly, (b) such a representation is a much bettermodel of the types of pronunciation variation seenin spontaneous speech corpora such as Switchboard,and (c) the theoretical average hypothesis space in-creases only by a little over a factor of 2.
Thislast fact is contrary to Briscoe?s finding that thesearch space would be reduced because it incorpo-rates more realistic assumptions about the detectionof stressed versus unstressed syllables.These experiments were designed primarily to in-vestigate the validity of Briscoe?s claims, and thuswe attempted to remain true to his model.
However,it is clear that our analysis can be extended in sev-eral ways.
We have begun experimenting with prun-ing the hypothesis graph to remove unlikely arcs ?this would give a more accurate model of the ASRprocessing that would occur.
However, this onlymakes sense if language model constraints are in-tegrated into the processing, since some word se-quences in the graph would be discarded as unlikely.This analysis could also benefit from a more accu-rate model of the ASR system?s transformation be-tween realized phones and lexical representations.This could be achieved by comparing the Gaussianacoustic model distributions in an HMM system orsampling the acoustic model?s space (McAllaster etal., 1998).
Both of these extensions will be consid-ered in future work.The results clearly indicate that further investiga-tion and development of a hybrid lexical strategy inan ASR system is worthwhile, particularly for spon-taneous speech corpora where the problem of pro-nunciation variation is most rampant.AcknowledgmentsThe authors would like to thank Keith Johnson,Monica Rajamanohar, and Yu Wang for discussionof this work.
This work was funded in part by NSFgrant ITR-0427413; the opinions and conclusionsexpressed in this work are those of the authors andnot of any funding agency.577ReferencesE.
J. Briscoe.
1989.
Lexical access in connected speechrecognition.
In Proc.
27th Annual Meeting of the As-sociation for Computational Linguistics, pages 84?90.R.
Carlson, K. Elenius, B. Granstro?m, and H. Hunni-cutt.
1985.
Phonetic and orthographic properties ofthe basic vocabulary of five european languages.
InSTL-QPSR 1/1985, pages 63?94, Stockholm.
SpeechTransmission Laboratory, Dept.
of Speech Communi-cation, Royal Institute of Technology.K.
W. Church.
1987.
Phonological Parsing in SpeechRecognition.
Kluwer, Dordrecht.M.
Finke, J. Fritsch, and D. Koll.
1999.
Modeling andefficient decoding of large vocabulary conversationalspeech.
In Conversational Speech Recognition Work-shop: DARPA Hub-5E Evaluation.W.
Fisher, 1996.
The tsylb2 Program: Algorithm De-scription.
NIST.
Part of the tsylb2-1.1 package.E.
Fosler-Lussier, S. Greenberg, and N. Morgan.
1999.Incorporating contextual phonetics into automaticspeech recognition.
In Int?l Congress of Phonetic Sci-ences, San Francisco, California.E.
Fosler-Lussier, C. A. Rytting, and S. Srinivasan.
2005.Phonetic ignorance is bliss: Investigating the effects ofphonetic information reduction on asr performance.
InProc.
Interspeech, Lisbon, Portugal.J.
Garofolo, L. Lamel, W. Fisher, J. Fiscus, D. Pallett, andN.
Dahlgren.
1993.
DARPA TIMIT acoustic-phoneticcontinuous speech corpus.
Technical Report NISTIR4930, NIST, Gaithersburg, MD.S.
Greenberg, J. Hollenbach, and D. Ellis.
1996.
Insightsinto spoken language gleaned from phonetic transcrip-tion of the switchboard corpus.
In Proc.
4th Int?l Con-ference on Spoken Language Processing.
Philadel-phia, PA.R.
Jakobson, G. Fant, and M. Halle.
1952.
Preliminar-ies to speech analysis.
Technical Report 13, AcousticsLaboratory, Massachusetts Instutite of Technology.A.
Juneja and C. Espy-Wilson.
2004.
Significance of in-variant acoustic cues in a probabilistic framework forlandmark-based speech recognition.
In From Sound toSense: Fifty+ Years of Discoveries in Speech Commu-nication, Cambridge, MA.
MIT.K.
Kirchhoff.
1998.
Combining articulatory and acousticinformation for speech recognition in noisy and rever-berant environments.
In Proc.
5th Int?l Conference onSpoken Language Processing, Sydney.Linguistic Data Consortium (LDC).
1996.
The PRON-LEX pronunciation dictionary.
Available from theLDC, ldc@unagi.cis.upenn.edu.
Part of the COMLEXdistribution.K.
Livescu, J.
Glass, and J. Bilmes.
2003.
Hiddenfeature models for speech recognition using dynamicbayesian networks.
In Proc.
8th European Conferenceon Speech Communication and Technology, Geneva,Switzerland.D.
McAllaster, L. Gillick, F. Scattone, and M. New-man.
1998.
Fabricating conversational speech datawith acoustic models: A program to examine model-data mismatch.
In Proc.
5th Int?l Conference on Spo-ken Language Processing, pages 1847?1850, Sydney,Australia.G.
Miller and P. Nicely.
1955.
Analysis of some per-ceptual confusions among some english consonants.Journal of Acoustical Society of America, 27:338?52.M.
Mohri, F. Pereira, and M. Riley, 2001.AT&T FSM LibraryTM ?
General-PurposeFinite-State Machine Software Tools.
AT&T,Florham Park, New Jersey.
Available athttp://www.research.att.com/sw/tools/fsm.NIST.
1992.
Switchboard Corpus: Recorded telephoneconversations.
National Institute of Standards andTechnology Speech Disc 9-1 to 9-25.M.
Ostendorf.
1999.
Moving beyound the ?beads-on-a-string?
model of speech.
In 1999 IEEE Workshopon Automatic Speech Recognition and Understanding,Keystone, Colorado.M.
Sarac?lar, H. Nock, and S. Khudanpur.
2000.
Pronun-ciation modeling by sharing Gaussian densities acrossphonetic models.
Computer Speech and Language,14:137?160.D.
W. Shipman and V. W. Zue.
1982.
Properties of largelexicons: Implications for advanced isolated wordrecognition systems.
In Proc.
Int?l Conference onAcoustics, Speech, and Signal Processing, volume 82,pages 546?549, Paris, France.K.
Stevens.
1981.
Invariant acoustic correlates of pho-netic features.
Journal of Acoustical Society of Amer-ica, 69 suppl.
1:S31.A.
Waibel.
1988.
Prosody and Speech Recognition.Morgan Kaufmann, San Mateo, California.S.
Young, G. Evermann, T. Hain, D. Kershaw,G.
Moore, J. Odell, D. Ollason, D. Povey,V.
Valtchev, and P. Woodland, 2002.
The HTKBook.
Cambridge Unveristy Engineering Department.http://htk.eng.cam.ac.uk.578
