Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 662?671,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsA Linear-Time Transition System for Crossing Interval TreesEmily Pitler Ryan McDonaldGoogle, Inc.{epitler,ryanmcd}@google.comAbstractWe define a restricted class of non-projectivetrees that 1) covers many natural languagesentences; and 2) can be parsed exactly witha generalization of the popular arc-eager sys-tem for projective trees (Nivre, 2003).
Cru-cially, this generalization only adds constantoverhead in run-time and space keeping theparser?s total run-time linear in the worstcase.
In empirical experiments, our proposedtransition-based parser is more accurate onaverage than both the arc-eager system orthe swap-based system, an unconstrained non-projective transition system with a worst-casequadratic runtime (Nivre, 2009).1 IntroductionLinear-time transition-based parsers that use eithergreedy inference or beam search are widely used to-day due to their speed and accuracy (Nivre, 2008;Zhang and Clark, 2008; Zhang and Nivre, 2011).
Ofthe many proposed transition systems (Nivre, 2008),the arc-eager transition system of Nivre (2003) isone of the most popular for a variety of reasons.
Thearc-eager system has a well-defined output space:it can produce all projective trees and only projec-tive trees.
For an input sentence with n words,the arc-eager system always performs 2n operationsand each operation takes constant time.
Anotherattractive property of the arc-eager system is theclose connection between the parameterization ofthe parsing problem and the final predicted outputstructure.
In the arc-eager model, each operation hasa clear interpretation in terms of constraints on thefinal output tree (Goldberg and Nivre, 2012), whichallows for more robust learning procedures (Gold-berg and Nivre, 2012).The arc-eager system, however, cannot producetrees with crossing arcs.
Alternative systems canproduce crossing dependencies, but at the cost oftaking O(n2) transitions in the worst case (Nivre,2008; Nivre, 2009; Choi and McCallum, 2013), re-quiring more transitions than arc-eager to produceprojective trees (Nivre, 2008; G?omez-Rodr?
?guez andNivre, 2010), or producing trees in an unknown out-put class1(Attardi, 2006).Graph-based non-projective parsing algorithms,on the other hand, have been able to preserve manyof the attractive properties of their correspondingprojective parsing algorithms by restricting searchto classes of mildly non-projective trees (Kuhlmannand Nivre, 2006).
Mildly non-projective classes oftrees are characterizable subsets of directed trees.Classes of particular interest are those that bothhave high empirical coverage and that can be parsedefficiently.
With appropriate definitions of fea-ture functions and output spaces, exact higher-ordergraph-based non-projective parsers can match theasymptotic time and space of higher-order projec-tive parsers (Pitler, 2014).In this paper, we propose a class of mildly non-projective trees (?3) and a transition system (?4) thatis sound and complete with respect to this class (?5)while preserving desirable properties of arc-eager:it runs in O(n) time in the worst case (?6), and eachoperation can be interpreted as a prediction about1A characterization independent of the transition system isunknown.662the final tree structure.
At the same time, it canproduce trees with crossing dependencies.
Acrossten languages, on average 96.7% of sentences havedependency trees in the proposed class (Table 1),compared with 79.4% for projective trees.
Theimplemented mildly non-projective transition-basedparser is more accurate than a fully projective parser(arc-eager, (Nivre, 2003)) and a fully non-projectiveparser (swap-based, (Nivre, 2009)) (?7.1).2 PreliminariesGiven an input sentence w1w2.
.
.
wn, a dependencytree for that sentence is a set of vertices V ={0, 1, .
.
.
, n} and arcs A ?
V ?
V .
Each vertexi corresponds to a word in the sentence and vertex 0corresponds to an artificial root word, which is stan-dard in the literature.
An arc (i, j) ?
A representsa dependency between a modifier wjand a head wi.Critically, the arc setA is constrained to form a validdependency tree: its root is at the leftmost vertex 0;each vertex i has exactly one incoming arc (except0, which has no incoming arcs); and there are no cy-cles.
A common extension is to add labels of syntac-tic relations to each arc.
For ease of exposition, wewill focus on the unlabeled variant during the discus-sion but use a labeled variant during experiments.A dependency tree is projective if and only if thenodes in the yield of each subtree form a contigu-ous interval with respect to the words and their orderin the sentence.
For instance, the tree in Figure 1ais non-projective since the subtrees rooted at cameand parade do not cover a contiguous set of words.Equivalently, a dependency tree is non-projective ifand only if the tree cannot be drawn in the planeabove the sentence without crossing arcs.
As wewill see, these crossing arcs are a useful measurewhen defining sub-classes of non-projectivity.
Wewill often reason about the set of vertices incident toa particular arc.
The incident vertices of an arc areits endpoints: for an arc (u, v), u and v are the twovertices incident to it.3 k-Crossing Interval TreesWe begin by defining a class of trees based on re-strictions on crossing dependencies.
The class def-inition is independent of any transition system; it iseasy to check whether a particular tree is within theroot Who do you think came to DC where a parade was held for Sam(a) A dependency tree with two disjoint sets (blueand dashed/red and dotted) of crossing arcs (bold).
(root, think) (came, Who)(DC, held) (held, where)(parade, for)(b) The auxiliary graph for the sentence above.There are two connected components of crossed arcs,one of which corresponds to the crossing interval[root, came] and the other [DC, for].Figure 1: A sentence with two crossing intervals.class or not.
We compare the coverage of this classon various natural language datasets with the cover-age of the class of projective trees.Definition 1.
Let A be a set of unlabeled arcs.
TheInterval of A, Interval(A), is the interval from theleftmost vertex inA to the rightmost vertex inA, i.e.,Interval(A) = [min(VA),max(VA)], where VA={v : ?u[(u, v) ?
A ?
(v, u) ?
A]}.Definition 2.
For any dependency tree T , thebelow procedure partitions the crossed arcs inT into disjoint sets A1, A2, .
.
.
., Alsuch thatInterval(A1), Interval(A2), .
.
.
, Interval(Al) are allvertex-disjoint.
These intervals are the crossing in-tervals of the tree T .Procedure: Construct an auxiliary graph with avertex for each crossed arc in the original tree.
Twosuch vertices are connected by an arc if the inter-vals defined by the arcs they correspond to have anon-empty intersection.
Figure 1b shows the aux-iliary graph for the sentence in Figure 1a.
Theconnected components of this graph form a parti-tion of the graph?s vertices, and so also partition thecrossed arcs in the original sentence.
The intervalsdefined by these groups cannot overlap, since thenthe crossed arcs that span the overlapping portionwould have been connected by an arc in the aux-iliary graph and hence been part of the same con-nected component.Definition 3.
A tree is a k-Crossing Interval tree iffor each crossing interval, there exists at most k ver-6632-Crossing 1-Endpoint-Language Interval Crossing ProjectiveBasque 93.5 94.7 74.8Czech 97.4 98.9 77.9Dutch 91.4 95.8 63.6English 99.2 99.3 93.4German 94.7 96.4 72.3Greek 99.1 99.7 84.4Hungarian 95.3 96.3 74.7Portuguese 99.0 99.6 83.3Slovene 98.2 99.5 79.6Turkish 99.1 99.3 89.9Average 96.7 98.0 79.4Table 1: Proportion of trees (excluding punctuation) ineach tree class for the CoNLL shared tasks training sets:Dutch, German, Portuguese, and Slovene are from Buch-holz and Marsi (2006); Basque, Czech, English, Greek,Hungarian, and Turkish data are from Nivre et al (2007).tices such that a) all crossed arcs within the intervalare incident to at least one of these vertices and b)any vertex in the interval that has a child on the farside of its parent is one of these k vertices.Figure 1a shows a 2-Crossing Interval tree.
Forthe first crossing interval, think and came satisfythe conditions; for the second, parade and helddo.
The coverage of 2-Crossing Interval trees isshown in Table 1.
Across datasets from ten lan-guages with a non-negligible proportion of cross-ing dependencies, on average 96.7% of dependencytrees are 2-Crossing Interval, within 1.3% of thelarger 1-Endpoint-Crossing class (Pitler et al, 2013)and substantially larger than the 79.4% coverage ofprojective trees.
Coverage increases as k increases;for 3-Crossing Interval trees, the average coveragereaches 98.6%.
Punctuation tokens are excludedwhen computing coverage to better reflect languagespecific properties rather than treebank artifacts; forexample, the Turkish CoNLL data attaches punctua-tion tokens to the artificial root, causing a 15% abso-lute drop in coverage for projective trees when punc-tuation tokens are included (89.9% vs. 74.7%).3.1 Connections to Other Tree Classesk = 0 or k = 1 gives exactly the class of projec-tive trees (even a single crossing implies two vertex-disjoint crossed edges).
2-Crossing Interval trees area subset of the linguistically motivated 1-Endpoint-Crossing trees (Pitler et al, 2013) (each crossededge is incident to one of the two vertices for theroot b a1b1a2b2.
.
.
an?1bn?1anbnaFigure 2: A 2-Crossing Interval tree that is not well-nested and has unbounded block degree.interval, so all edges that cross it are incident tothe other vertex for the interval); all of the exam-ples from the linguistics literature provided in Pitler(2013, p.132-136) for 1-Endpoint-Crossing trees are2-Crossing Interval trees as well.
2-Crossing In-terval trees are not necessarily well-nested and canhave unbounded block degree (Kuhlmann, 2013).Figure 2 shows an example of a 2-Crossing Inter-val tree (all crossed edges are incident to either a orb; no children are on the far side of their parent) inwhich the subtrees rooted at a and b are ill-nestedand each has a block degree of n+ 1.4 Two-Registers Transition SystemA transition system for dependency parsing com-prises: 1) an initial configuration for an input sen-tence; 2) a set of final configurations after which theparsing derivation terminates; and 3) a set of deter-ministic transitions for transitioning from one con-figuration to another (Nivre, 2008).Our transition system builds on one of the mostcommonly used transition systems for parsing pro-jective trees, the arc-eager system (Nivre, 2003).An arc-eager configuration, c, is a tuple, (?, ?,A),where 1) ?
is a stack consisting of a subset of pro-cessed tokens; 2) ?
is a buffer consisting of unpro-cessed tokens; and 3)A is the set of dependency arcsalready added to the tree.We define a new transition system called two-registers.
Configurations are updated to include tworegisters R1 and R2, i.e., c = (?, ?,R1, R2, A).
Aregister contains one vertex or is empty: R1, R2 ?V ?
{null}.
Table 2 defines both the arc-eager andtwo-registers transition systems.
The two-registerssystem includes the arc-eager transitions (top half ofTable 2) and three new transitions that make use ofthe registers (bottom half of Table 2):?
Store: Moves the token at the front of thebuffer into the first available register, optionally664Arc-Eager?
Initial configuration: ({0}, {1, .
.
.
, n}, {})?
Terminal configurations (?, {}, A)Two-Registers?
Initial configuration: ({}, {0, .
.
.
, n}, null, null, {})?
Terminal configurations: (?, {}, null, null, A)Transition ?
?
R1 R2 AArc-EagerLeft-Arc ?m..2?1..nR1 R2 A ?
{(?1, ?1)}Right-Arc ?m..1|?1?2..nR1 R2 A ?
{(?1, ?1)}Shift ?m..1|?1?2..nR1 R2 AReduce ?m..2?1..nR1 R2 A+Two-RegistersStore(arc) ?m..1?2..nR1?R2?A ?
BWhere: arc ?
{left, right, no-arc}B := {(?1, R1)} if arc=left, {(R1, ?1)} if arc=right, and ?
otherwise.R1?
:= (R1 = null) ?
?1: R1; R2?
:= (R1 = null) ?
R2 : ?1.Clear ?m..2|?
?|?1..nnull null AWhere: ?
:= (?1= ?1?
1) ?
?1: (R2 = ?1?
1) ?
R2 : null?
:= {?1} ?NotCovered(R1) ?NotCovered(R2)?
{?}
in left-to-right order,where NotCovered(x) := x if no edges in A cover x and ?
otherwise.Register-Stack(k, dir) ?m..2|?
?1..nR1 R2 A ?
BWhere: k ?
{1, 2} and dir ?
{to-register, to-stack}B := (dir = to-register) ?
{(?1, Rk)} : {(Rk, ?1)}?
:= (dir = to-stack ?
?1< Rk) ?
null : ?1Table 2: Transitions and the resulting state after each is applied to the configuration (?m..2|?1, ?1|?2..n, R1, R2, A).Transition ?
?
R1 R2 A. .
.
[that we Hans house] [helped paint] null null {(house, the)}Store(no-arc) [that we Hans house] [paint] helped nullStore(right) [that we Hans house] [] helped paint ?
{(helped, paint)}Register-Stack(2, to-stack) [that we Hans] [] helped paint ?
{(paint, house)}Register-Stack(1, to-stack) [that we] [] helped paint ?
{(helped, Hans)}Register-Stack(1, to-stack) [that] [] helped paint ?
{(helped, we)}Register-Stack(1, to-register) [that] [] helped paint ?
{(that, helped)}Clear [that] [paint] null nullTable 3: An excerpt from a gold standard derivation of the sentence in Figure 3.
The two words paint and house areadded to the registers and then crossed arcs are added between them and the top of the stack.Transition Precondition TypeLeft-Arc, Right-Arc R1 /?
(?1, ?1) ?R2 /?
(?1, ?1) (2)Store(?)
(R1 = null ?R2 = null) ?
(?1> last) (1)Clear (R1 6= null) ?
(R2 6= null ?
?1= null) ?
(?2< R1) ?
(?1/?
(R1, R2)) (1)Register-Stack(k, ?)
(?1> last) ?
(k = 1 ?
?IsCovered(R1)) (1)?2< Rright(2)Register-Stack(k, to-register) (Rclose, ?1) /?
A (3)Register-Stack(k, to-stack) (?1, Rfar) /?
A (3)Table 4: Preconditions that ensure the 2-Crossing Interval property for trees output by the two-registers transitionsystem, applied to a configuration (?m..1, ?1..n, R1, R2, A).
If ?1< R1, Rclose:= R1 and Rfar:= R2; otherwise,Rclose:= R2 and Rfar:= R1.
Rright:= (R2 = null) ?
R1 : R2.
Preconditions of type (1) ensure each pair ofregisters defines a disjoint crossing interval; type (2) that only edges incident to registers are crossed; and type (3) thatonly registers can have children on the far side of their parent.665das mer em Hans es huus halfed aastriichethat we Hans the house helped paintFigure 3: A clause with crossing edges (Shieber, 1985).adding an arc between this token and the tokenin the first register.?
Clear: Removes tokens from the registers, re-ducing them completely if they are covered byan edge inA or otherwise placing them back onthe stack in order.
If either R2 or the top of thestack is the token immediately to the left of thefront of the buffer, that token is placed back onthe buffer instead.?
Register-Stack: Adds an arc between the topof the stack and one of the registers.A derivation excerpt for the clause in Figure 3 isshown in Table 3.
The two tokens incident to allcrossed arcs helped and paint are stored in the reg-isters.
The crossed arcs are then added throughRegister-Stack transitions, working outward fromthe registers through the previous words in the sen-tence: (paint, house), then (helped, Hans), etc.
Afterall the crossed arcs incident to these two tokens havebeen added, the registers are cleared.Preconditions related to rootedness, single-headedness, and acyclicity follow the arc-eager sys-tem straightforwardly: each transition that adds anarc (h,m) checks that m is not the root, m does notalready have a head, and that h is not a descendant ofm.
Preconditions used to guarantee that trees outputby the system are within the desired class are listedin Table 4.
In particular, they ensure that all crossedarcs are incident to registers, and that each pair ofregisters entails an interval corresponding to a self-contained set of crossed edges.
To avoid travers-ingAwhile checking preconditions, two helper con-stants are used: IsCovered(Rk)2and last3.2IsCovered(R1) is true if there exists an arc in A withendpoints on either side of R1.
Rather than enumerating arcs,this boolean can be updated in constant time by setting it to trueonly after a Register-Stack(2, dir) transition with ?1< R1;likewise R2 can only be covered with a Register-Stack(1, dir)transition with ?1> R2.3last is used to indicate the rightmost partially processedunreduced vertex after the last pair of registers were cleared (setto the rightmost in ?, ?
after each Clear transition).Lemma 1.
In the two-registers system, all crossedarcs are added through register-stack operations.Proof.
Suppose for the sake of contradiction that aright arc (s, b) added when ?1= s and ?1= b iscrossed in the final output tree (the argument for left-arcs is identical).
Let (l, r) with l < r be an arc thatcrosses (s, b).
One of {l, r} must be within the openinterval (s, b) and one of {l, r} /?
[s, b].
When thearc (s, b) is added, no tokens in the open interval(s, b) remain.
They cannot be in the stack or buffersince the stack and buffer always remain in order;they cannot be in registers by the precondition R1 /?
(?1, ?1) ?
R2 /?
(?1, ?1) for Right-Arc transitions.Thus, (l, r) must already have been added.
It cannotbe that l ?
(s, b) and r > b, since the rest of thebuffer has never been accessible to tokens left of b.The ordering must then be l < s < r < b.
Figure 4shows that for each way (l, r) could have been added(Right-Arc, 4a; Store(right), 4b; Register-Stack(k,to-stack), 4c; Register-Stack(k, to-register), 4d), itis impossible to keep s unreduced without violatingone of the preconditions.The only other type of arc-adding operation isStore.
Similar logic holds: arcs added through Left-Arc and Right-Arc transitions cannot cross thesearcs, since they would violate the preconditionsR1 /?
(?1, ?1) ?
R2 /?
(?1, ?1); later arcs involv-ing other registers would imply Clear operations thatviolate ?2< R1 ?
?1/?
(R1, R2).5 Parsing 2-Crossing Interval Trees withthe Two-Registers Transition SystemIn this section we show the correspondence betweenthe two-registers transition system and 2-CrossingInterval trees: each forest output by the transitionsystem is a 2-Crossing Interval tree (soundness) andevery 2-Crossing Interval tree can be produced bythe two-registers system (completeness).5.1 Soundness: Two-Registers System?2-Crossing Interval treesProof.
Every crossed arc is incident to a token thatwas in a register (Lemma 1).
There cannot be anyoverlap between register arcs where the correspond-ing tokens were not in the registers simultaneously:the Clear transition updates the book-keeping con-stant last to be the rightmost vertex associated with666sr .
.
.
b .
.
.. .
.
l(a) Right-Arc: s would have been in a register, and the Right-Arcwould have violated R1 /?
(?1, ?1) ?R2 /?
(?1, ?1).lr.
.
.
b .
.
.. .
.
s .
.
.
(b) Store(right): s would be on the stack when the registers werecleared, so Clear would have violated ?2< R1??1/?
(R1, R2).l.
.
.
b .
.
.. .
.
s .
.
.
r(c) Register-Stack(k, to-stack): If s was on the stack, then if s >R2, Register-Stack(k, t-stack) would have violated ?2< R2; ifs < R2, then s ?
(R1, R2), and Clear would have violated?2< R1 ?
?1/?
(R1, R2).
If s instead was in R2 (not shown),then it would get covered by (l, r) and reduced by Clear.s r. .
.
b .
.
.. .
.
l(d) Register-Stack(k, to-register): s must have been in R2.
swould get covered by (l, r) and reduced by Clear.Figure 4: If a stack-buffer arc (s, b) is added in the two-registers system, there cannot have been an earlier arc (l, r)with l < s < r < b, since it would then be impossible to keep s unreduced without violating the preconditions.the registers being cleared, and subsequent actionscannot introduce crossed arcs to the last token orto its left (by the ?1> last and ?1> last pre-conditions on storing and register-stack arcs, re-spectively).
Thus, each set of tokens that were inregisters simultaneously defines a crossing interval.Condition (a) of Definition 3 is satisfied, since allcrossed arcs are incident to registers and at most twovertices are in registers at the same time.Assume that a vertex h, h /?
{R1, R2}, has achild m on the far side of its parent g (i.e., ei-ther h < g < m or m < g < h).
The edge(h,m) is guaranteed to be crossed and so was addedthrough a register-stack arc (Lemma 1).
The order-ing h < g < m is not possible, since if (g, h) hadbeen added through a left-arc, then h would havebeen reduced, and if (g, h) and (h,m) were bothadded through register-stack arcs, then one of themwould have violated the (Rclose, ?1) /?
A or the(?1, Rfar) /?
A precondition.
Similar reasoning canrule out m < g < h. Thus Condition (b) of Defini-tion 3 is also satisfied.5.2 Completeness: 2-Crossing Interval trees?Two-Registers SystemProof.
The portions of a 2-Crossing Interval tree in-between the crossing intervals can be constructedusing the transitions from arc-eager.
For a partic-ular crossing interval [l, r] and a particular choice oftwo vertices a and b incident to all all crossed arcs inthe interval (l ?
a < b ?
r), a and b divide the in-terval into: L = [l, a), a, M = (a, b), b, R = (b, r].All arcs incident to neither a nor b must lie entirelywithin L, M , or R.4The parser begins by adding all arcs withboth endpoints in L, using the standard arc-eagerShift/Reduce/Left-Arc/Right-Arc.
It then shifts untila is at the front of the buffer and stores a.
It then re-peats the same process to add the arcs lying entirelyin M until b reaches the front of the buffer, addingthe parent of a with a Register-Stack(1, to-register)transition if the parent is in M and the arc is un-crossed.
b is then stored, adding the arc between aand b if necessary.
Throughout this process, the pre-condition R1 /?
(?1, ?1) ?
R2 /?
(?1, ?1) for leftand right arcs is satisfied.Next, the parser will repeatedly take Register-Stack transitions, interspersed with Reduce transi-tions, to add all the arcs with one endpoint in {a, b}and the other in L or M , working right-to-left fromb (i.e., from the top of the stack downwards).
Noshifts are done at this stage, so the ?2< R2 pre-condition on Register-Stack arcs is always satisfied.The ?1> last precondition is also always satisfiedsince all vertices in the crossing interval will be tothe right of the previous crossing interval boundarypoint.
After all these arcs are done, if there are anyuncrossed arcs incident to a to the left that go outsideof the crossing interval, they are added now with aRegister-Stack transition.54E.g., if there were an arc not incident to a or b with oneendpoint left of a and one endpoint right of a, then this arcmust be crossed or lie outside of the crossing interval.5Only possible in the case l = a, in which case?ISCOVERED(a) and the transition is allowed.667Finally, the arcs with at least one endpoint in Rare added, using Register-Stack arcs for those withthe other endpoint in {a, b} and Left-Arc/Right-Arcfor those with both endpoints in R. Before any ver-tex incident to a or b is shifted onto the stack, alltokens on the stack to the right of b are reduced.After all these arcs are added, the crossing intervalis complete.
The boundary points of the interval thatcan still participate in uncrossed arcs with the exte-rior are left on the stack and buffer after the clearoperation, so the rest of the tree is still parsable.6 Worst-case RuntimeThe two-registers system runs in O(n) time: it com-pletes after at most O(n) transitions and each tran-sition takes constant time.The total number of arc-adding actions (Left-Arc,Right-Arc, Register-Stack, or a Store that includesan arc) is bounded by n, as there are at most n arcsin the final output.
The net result of {Store, Store,Clear} triples of transitions decreases the numberof tokens on the buffer by at least one, so thesetriples, plus the number of Shifts and Right-Arcs, arebounded by n. Finally, each token can be removedcompletely at most once, so the number of Left-Arcsand Reduces is bounded by n. Every transition fellinto one of these categories, so the total number oftransitions is bounded by 5n = O(n).Each operation can be performed in constant time,as all operations involve moving vertices and/oradding arcs, and at most three vertices are evermoved (Clear) and at most one arc is ever added.Most preconditions can be trivially checked in con-stant time, such as checking whether a vertex al-ready has a parent or not.
The non-trivial pre-condition to check is acyclicity, and this can alsobe checked by adding some book-keeping variablesthat can be updated in constant time (full proofomitted due to space constraints).
For example,in the derivation in Table 3, prior to the Register-Stack(2, to-stack) transition, R1 ?AR2 (helped?Apaint).
After the arc (R2, ?1) (paint, house)is added, R2?A?1and by transitivity, R1?A?1.The top of the stack is then reduced, and since ?2does not have a parent to its right, it is not a descen-dant of ?1, and so after Hans becomes the new ?1,the system makes the update that R1, R29A?1.7 ExperimentsThe experiments compare the two-registers transi-tion system for mildly non-projective trees proposedhere with two other transition systems: the arc-eager system for projective trees (Nivre, 2003) andthe swap-based system for all non-projective trees(Nivre, 2009).
We choose the swap-based systemas our non-projective baseline as it currently repre-sents the state-of-the-art in transition-based parsing(Bohnet et al, 2013), with higher empirical perfor-mance than the Attardi system or pseudo-projectiveparsing (Kuhlmann and Nivre, 2010).The arc-eager system is a reimplementation ofZhang and Nivre (2011), using their rich feature setand beam search.
The features for the two other tran-sition systems are based on the same set, but withslight modifications to account for the different rel-evant domains of locality.
In particular, for the swaptransition system, we updated the features to accountfor the fact that this transition system is based on thearc-standard model and so the most relevant posi-tions are the top two tokens on the stack.
For thetwo-register system, we added features over proper-ties of the tokens stored in each of the registers.
Allexperiments use beam search with a beam of size32 and are trained with ten iterations of averagedstructured perceptron training.
Training set treesthat are outside of the reachable class (projectivefor arc-eager, 2-Crossing Intervals for two-registers)are transformed by lifting arcs (Nivre and Nilsson,2005) until the tree is within the class.
The test setsare left unchanged.
We use the standard techniqueof parameterizing arc creating actions with depen-dency labels to produce labeled dependency trees.Experiments use the ten datasets in Table 1 fromthe CoNLL 2006 and 2007 shared tasks (Buch-holz and Marsi, 2006; Nivre et al, 2007).
Wereport numbers using both gold and automaticallypredicted part-of-speech tags and morphologicalattribute-values as features.
For the latter, the partof speech tagger is a first-order CRF model andthe morphological tagger uses a greedy SVM per-attribute classifier.
Evaluation uses CoNLL-X scor-ing conventions (Buchholz and Marsi, 2006) and wereport both labeled and unlabeled attachment scores.668LAS (UAS)Language eager swap two-registersBasque 70.50 (78.06) 69.66 (77.44) 71.10 (78.57)Czech 79.60 (85.55) 80.74 (86.82) 79.75 (85.93)Dutch 78.69 (81.41) 79.65 (82.69) 80.77 (83.91)English 90.00 (91.18) 90.16 (91.29) 90.36 (91.54)German 88.34 (91.01) 86.76 (89.56) 89.08 (91.95)Greek 77.34 (84.79) 76.90 (84.72) 77.59 (84.77)Hungarian 80.00 (84.20) 79.93 (84.40) 80.21 (84.91)Portuguese 88.30 (91.64) 87.92 (91.79) 87.40 (91.20)Slovene 75.68 (83.97) 76.34 (84.47) 76.08 (84.33)Turkish 68.83 (77.34) 70.71 (79.74) 70.94 (80.39)Average 79.73 (84.92) 79.88 (85.29) 80.33 (85.75)Table 5: Labeled and Unlabeled Attachment Scores (LASand UAS) on the CoNLL 2006/2007 Shared Task datasets(gold part-of-speech tags and morphology).LAS (UAS)Language eager swap two-registersBasque 64.36 (73.03) 63.23 (72.10) 64.27 (72.32)Czech 75.92 (83.79) 76.92 (84.54) 76.37 (83.79)Dutch 78.59 (81.07) 79.69 (83.03) 80.77 (83.71)English 88.19 (89.77) 88.68 (90.32) 88.93 (90.50)German 87.74 (90.62) 85.66 (88.40) 87.60 (90.48)Greek 77.46 (85.14) 76.29 (84.65) 77.22 (84.82)Hungarian 75.88 (81.61) 75.83 (81.89) 75.71 (82.43)Portuguese 86.07 (90.16) 85.65 (89.86) 85.91 (90.16)Slovene 71.72 (81.69) 71.36 (81.63) 71.58 (81.43)Turkish 62.18 (74.22) 63.12 (75.26) 64.06 (76.82)Average 76.81 (83.11) 76.64 (83.17) 77.24 (83.65)Table 6: Labeled and Unlabeled Attachment Scores (LASand UAS) on the CoNLL 2006/2007 Shared Task datasets(predicted part-of-speech tags and morphology).7.1 ResultsTable 5 shows the results using gold tags as fea-tures, which is the most common set-up in the lit-erature.
The two-registers transition system has onaverage 0.8% absolute higher unlabeled attachmentaccuracy than arc-eager across the ten datasets in-vestigated.
Its UAS is higher than arc-eager for eightout of the ten languages and is up to 2.5% (Dutch)or 3.0% (Turkish) absolute higher, while never morethan 0.4% worse (Portuguese).
The two-registerstransition system is also more accurate than the al-ternate non-projective swap system on seven out ofthe ten languages, with more than 1% absolute im-provements in UAS for Basque, Dutch, and German.The two-registers transition-system is still on aver-age more accurate than either the arc-eager or swapsystems using predicted tags as features (Table 6).Crossed / UncrossedLanguage eager swap two-registersBasque 33.10 / 83.32 39.37 / 82.52 34.49 / 83.58Czech 43.98 / 87.37 68.76 / 87.63 55.42 / 87.24Dutch 40.08 / 87.66 71.08 / 85.70 69.19 / 87.08English 27.66 / 91.98 42.55 / 92.00 42.55 / 92.09German 55.29 / 91.60 72.35 / 89.46 75.29 / 91.85Greek 29.94 / 84.79 33.12 / 84.76 30.57 / 84.94Hungarian 44.40 / 84.98 55.40 / 84.07 55.60 / 84.77Portuguese 48.17 / 90.98 58.64 / 90.79 57.07 / 89.96Slovene 41.83 / 83.60 47.91 / 84.05 44.11 / 83.65Turkish 45.07 / 86.20 70.39 / 86.15 56.25 / 87.31Average 32.51 / 87.25 55.96 / 86.72 52.05 / 87.25Table 7: UAS from Table 5 for tokens in which the in-coming arc in the gold tree is crossed or uncrossed (recallof both crossed and uncrossed arcs).Finally, we analyzed the performance of each ofthese parsers on both crossed and uncrossed arcs.Even on languages with many non-projective sen-tences, the majority of arcs are not crossed.
Ta-ble 7 partitions all scoring tokens into those whoseincoming arc in the gold tree is crossed and thosewhose incoming arc is not crossed, and presents theUAS scores from Table 5 for each of these groups.On the crossed arcs, the swap system does the best,followed by the two-registers system, with the arc-eager system about 20% absolute less accurate.
Onthe uncrossed arcs, the arc-eager and two-registerssystems are tied, with the swap system less accurate.8 Discussion and Related WorkThere has been a significant amount of recentwork on non-projective dependency parsing.
Inthe transition-based parsing paradigm, the pseudo-projective parser of Nivre and Nilsson (2005) wasan early attempt and modeled the problem by trans-forming non-projective trees into projective trees viatransformations encoded in arc labels.
While im-proving parsing accuracies for many languages, thismethod was both approximate and inefficient as theincrease in the cardinality of the label set affectedrun time.Attardi (2006) directly augmented the transitionsystem to permit limited non-projectivity by allow-ing transitions between words not directly at the topof the stack or buffer.
While this transition systemhad significant coverage, it is unclear how to pre-cisely characterize the set of dependency trees that it669covers.
Nivre (2009) introduced a transition systemthat covered all non-projective trees via a new swaptransition that locally re-ordered words in the sen-tence.
The downside of the swap transition is that itmade worst-case run time quadratic.
Also, as shownin Table 7, the attachment scores of uncrossed arcsdecreases compared with arc-eager.Two other transition systems that can be seen asgeneralizations of arc-eager are the 2-Planar tran-sition system (G?omez-Rodr?
?guez and Nivre, 2010;G?omez-Rodr?
?guez and Nivre, 2013), which addsa second stack, and the transition system of Choi(Choi and McCallum, 2013), which adds a deque.The arc-eager, 2-registers, 2-planar, and the Choitransition systems can be seen as along a continuumfor trading off various properties.
In terms of cover-age, projective trees (arc-eager) ?
2-Crossing Inter-val trees (this paper) ?
2-planar trees ?
all directedtrees (Choi).
The Choi system uses a quadratic num-ber of transitions in the worst case, while arc-eager,2-registers, and 2-planar all use at most O(n) transi-tions.
Checking for cycles does not need to be doneat all in the arc-eager system, can be with a few con-stant operations in the 2-registers system, and can bedone in amortized constant time for the other sys-tems (G?omez-Rodr?
?guez and Nivre, 2013).In the graph-based parsing literature, there hasalso been a plethora of work on non-projective pars-ing (McDonald et al, 2005; Martins et al, 2009;Koo et al, 2010).
Recent work by Pitler and col-leagues is the most relevant to the work describedhere (Pitler et al, 2012, 2013, 2014).
Like this work,Pitler et al define a restricted class of non-projectivetrees and then a graph-based parsing algorithm thatparses exactly that set.The register mechanism in two-registers transi-tion parsing bears a resemblance to registers in Aug-mented Transition Networks (ATNs) (Woods, 1970).In ATNs, global registers are introduced to accountfor a wide range of natural language phenomena.This includes long-distance dependencies, which isa common source of non-projective trees.
Whiletransition-based parsing and ATNs use quite differ-ent control and data structures, this observation doesraise an interesting question about the relationshipbetween these two parsing paradigms.There are many additional points of interest toexplore based on this study.
A first step wouldbe to generalize the two-registers transition systemto a k-registers system that can parse exactly k-Crossing Interval trees.
This will necessarily lead toan asymptotic increase in run-time as k approachesn.
With larger values of k, the system would needadditional transitions to add arcs between the reg-isters (extending the Store transition to consider allsubsets of arcs with the existing registers would be-come exponential in k).
If k were to increase all theway to n, such a system would probably look verysimilar to list-based systems that consider all pairsof arcs (Covington, 2001; Nivre, 2008).Another direction would be to define dynamicoracles around the two-registers transition system(Goldberg and Nivre, 2012; Goldberg and Nivre,2013).
The additional transitions here have inter-pretations in terms of which trees are still reachable(Register-Stack(?)
adds an arc; Store and Clear in-dicate that particular vertices should be incident tocrossed arcs or are finished with crossed arcs, re-spectively).
The two-registers system is not quitearc-decomposable (Goldberg and Nivre, 2013): ifthe wrong vertex is stored in a register then alater pair of crossed arcs might both be individu-ally reachable but not jointly reachable.
However,there may be a ?crossing-sensitive?
variant of arc-decomposability that takes into account the verticescrossed arcs are incident to that would apply here.9 ConclusionIn this paper we presented k-Crossing Interval trees,a class of mildly non-projective trees with high em-pirical coverage.
For the case of k = 2, we alsopresented a transition system that is sound and com-plete with respect to this class that is a generaliza-tion of the arc-eager transition system and main-tains many of its desirable properties, most notablya linear worst-case run-time.
Empirically, this tran-sition system outperforms its projective counterpartas well as a quadratic swap-based transition systemwith larger coverage.AcknowledgmentsWe?d like to thank Mike Collins, Terry Koo, JoakimNivre, Fernando Pereira, and Slav Petrov for helpfuldiscussions and comments.670ReferencesG.
Attardi.
2006.
Experiments with a multilanguagenon-projective dependency parser.
In Proceedings ofCoNLL, pages 166?170.B.
Bohnet, J. Nivre, I. Boguslavsky, R. Farkas, F. Ginter,and J. Hajic.
2013.
Joint morphological and syntacticanalysis for richly inflected languages.
TACL, 1:415?428.S.
Buchholz and E. Marsi.
2006.
CoNLL-X shared taskon multilingual dependency parsing.
In Proceedingsof CoNLL, pages 149?164.J.
D. Choi and A. McCallum.
2013.
Transition-based de-pendency parsing with selectional branching.
In ACL,pages 1052?1062.M.
A. Covington.
2001.
A fundamental algorithm fordependency parsing.
Proceedings of the 39th AnnualACM Southeast Conference, pages 95?102.Y.
Goldberg and J. Nivre.
2012.
A dynamic oracle forarc-eager dependency parsing.
In COLING.Y.
Goldberg and J. Nivre.
2013.
Training deterministicparsers with non-deterministic oracles.
TACL, 1:403?414.C.
G?omez-Rodr?
?guez and J. Nivre.
2010.
A transition-based parser for 2-planar dependency structures.
InProceedings of ACL, pages 1492?1501.C.
G?omez-Rodr?
?guez and J. Nivre.
2013.
Divisible tran-sition systems and multiplanar dependency parsing.Computational Linguistics, 39(4):799?845.T.
Koo, A. M. Rush, M. Collins, T. Jaakkola, and D. Son-tag.
2010.
Dual decomposition for parsing with non-projective head automata.
In Proceedings of EMNLP,pages 1288?1298.M.
Kuhlmann and J. Nivre.
2006.
Mildly non-projective dependency structures.
In Proceedings ofCOLING/ACL, pages 507?514.M.
Kuhlmann and J. Nivre.
2010.
Transition-basedtechniques for non-projective dependency parsing.Northern European Journal of Language Technology,2(1):1?19.M.
Kuhlmann.
2013.
Mildly non-projective dependencygrammar.
Computational Linguistics, 39(2).A.
F. T. Martins, N. A. Smith, and E. P. Xing.
2009.Concise integer linear programming formulations fordependency parsing.
In Proceedings of ACL, pages342?350.R.
McDonald, F. Pereira, K. Ribarov, and J. Haji?c.2005.
Non-projective dependency parsing using span-ning tree algorithms.
In Proceedings of HLT/EMNLP,pages 523?530.J.
Nivre and J. Nilsson.
2005.
Pseudo-projective depen-dency parsing.
In Proceedings of ACL, pages 99?106.J.
Nivre, J.
Hall, S. K?ubler, R. McDonald, J. Nilsson,S.
Riedel, and D. Yuret.
2007.
The CoNLL 2007shared task on dependency parsing.
In Proceedingsof the CoNLL Shared Task Session of EMNLP-CoNLL,pages 915?932.J.
Nivre.
2003.
An efficient algorithm for projective de-pendency parsing.
In Proceedings of the 8th Interna-tional Workshop on Parsing Technologies, pages 149?160.J.
Nivre.
2008.
Algorithms for deterministic incremen-tal dependency parsing.
Computational Linguistics,34(4):513?553.J.
Nivre.
2009.
Non-projective dependency parsing inexpected linear time.
In Proceedings of ACL, pages351?359.E.
Pitler, S. Kannan, and M. Marcus.
2012.
Dynamicprogramming for higher order parsing of gap-mindingtrees.
In Proceedings of EMNLP, pages 478?488.E.
Pitler, S. Kannan, and M. Marcus.
2013.
Finding opti-mal 1-Endpoint-Crossing trees.
TACL, 1(Mar):13?24.E.
Pitler.
2013.
Models for improved tractability andaccuracy in dependency parsing.
University of Penn-sylvania.E.
Pitler.
2014.
A crossing-sensitive third-order factor-ization for dependency parsing.
TACL, 2(Feb):41?54.S.
M. Shieber.
1985.
Evidence against the context-freeness of natural language.
Linguistics and Philoso-phy, 8(3):333?343.W.
A.
Woods.
1970.
Transition network grammarsfor natural language analysis.
Communications of theACM, 13(10):591?606.Y.
Zhang and S. Clark.
2008.
A tale of two parsers: in-vestigating and combining graph-based and transition-based dependency parsing using beam-search.
In Pro-ceedings of EMNLP, pages 562?571.Y.
Zhang and J. Nivre.
2011.
Transition-based depen-dency parsing with rich non-local features.
In Pro-ceedings of ACL (Short Papers), pages 188?193.671
