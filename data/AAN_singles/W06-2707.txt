Annotating text using the Linguistic Description Scheme of MPEG-7:The DIRECT-INFO ScenarioThierry Declerck, Stephan BusemannLanguage Technology LabDFKI GmbHSaarbr?cken, Germany{declerck|busemann}@dfki.deHerwig Rehatschek, Gert KienastInstitute for Information Systems &Information Management,JRS GmbHGraz, Austria{rehatschek|kienast}@joanneum.atAbstractWe describe the way we adapted a textanalysis tool for annotating with the Lin-guistic Description Scheme of MPEG-7text related to and extracted from multi-media content.
Practically applied in theDIRECT-INFO EC R&D project weshow how such linguistic annotation con-tributes to semantic annotation of multi-modal analysis systems, demonstratingalso the use of the XML schema ofMPEG-7 for supporting cross-media se-mantic content annotation.1 IntroductionIn the R&D project DIRECT-INFO the concretebusiness case of sponsorship tracking was tar-geted.
The scenario investigated within the pro-ject was that sponsors want to know how oftentheir brands are mentioned in connection withthe sponsored company.
The visual detection of abrand (e.g.
in videos) is not sufficient to meet therequirements of this business case.
Multimodalanalysis and fusion ?
as implemented within DI-RECT-INFO ?
is needed in order to fulfill theserequirements (Rehatschek, 2004).Within this context text analysis has been ap-plied to documents reporting on entities, likefootball teams, that have close relations to largesponsoring companies.
In the text analysis com-ponent of the system we had to detect if an entitywas mentioned positively, negatively or neu-trally.
Besides all the processing and annotationissues to positive or negative mentions, we hadto make our results available to a global MPEG-7document, which is encoding the annotation re-sults of various analysis of the modalities in-volved (logo detection, speech recognition, textanalysis etc.).
This global MPEG-7 documentwas the input for a fusion component.In the next sections we describe the TextAnalysis (TA) component of DIRECT-INFO.We then briefly describe the linguistic descrip-tion scheme (LDS) of MPEG-7 and show theannotation generated by the TA.
Finally webriefly discuss the role the LDS, and generallyspeaking MPEG-7, can play in supporting aninteroperable cross-media annotation strategy.
Itseems to us, that LDS is offering a good meanfor adding semantic metadata to image/video, butnot for a real semantic integration of text andmedia content annotation, which in the case ofDIRECT-INFO was performed by an additionalfusion component.2 The detection of positive/negativementioningOur work in DIRECT-INFO has been dedicatedin enhancing an already existing tool for linguis-tic annotation.
This tool, called SCHUG (Shal-low and CHunk-based Unification Grammartool), is annotating texts considering both lin-guistic constituency and dependency structures(T. Declerck, M. Vela 2005).A first development step was dedicated in cre-ating specialized lexicons for various types oflexical categories (like nouns, adjectives andverbs) that can bear the property of being intrin-sically positive or negative in a specific domain,as can be seen just below in the case of soccer:command => {POS => Noun, INT => "positive"}dominate => {POS => Verb, INT => "positive"}weak => {POS => Adj, INT => "negative"}Considering a sentence like ?ManU takes thecommand in the game against the weak Spanish53team?, the head-noun of the direct object (lin-guistically speaking) ?the command?
gets fromthe access to the specialized DIRECT-INFOlexicon a tag ?INTERPRETATION?
with value?positive?.
Whereas the adjective ?weak?
in thePP-adjunct ?in the game against the weak Span-ish team?
gets an ?INTERPRETATION?
tagwith value ?negative?.Once the words in the sentence have beenlexically tagged with respect to their interpreta-tion, the computing of the pos./neg.
interpreta-tion at the level of linguistic fragments and thenat the level of the sentences can start.
For this wehave defined heuristics along the lines of the de-pendency structures delivered by the linguisticanalysis.
So in the case of the NP ?the weakSpanish team?, the head noun ?team?, as such aneutral expression, is getting the ?INTERPRE-TATION?
tag with the value ?negative?, since itis modified by a ?negative?
adjective.
In case thereference resolution algorithm of the linguistictools has been able to specify that the ?Spanishteam?
is in fact ?Real Madrid?
this entity gets anegative ?INTERPRETATION?
tag.The head noun of the NP realizing the subjectof the sentence, ?ManU?
gets a positive mentiontag, since it is the subject of a positive verb anddirect object combination (the NP ?the com-mand?
having a positive reading, whereas theverb ?takes?
has a neutral reading).A last aspect to be mentioned here concernsthe treatment of the so-called polarity items.Specific words in natural language intrinsicallycarry a negation or position force (or scope).
Sothe words not, none or no have an intrinsic nega-tion force and negate the words and fragments inthe context in which those specific words areoccurring.
The context that is negated by suchwords can be also called the ?scope?
(or therange) of the negation.
Consider for example thesentence: ?I would definitely pay ?15 million toget Owen, not even a decent striker, instead?
?Our tools are able to detect that the NP ?decentstriker?
is negated, and therefore the positivereading of ?decent striker?
is being ruled out.3 Metadata DescriptionThe different content analysis modules of theDIRECT-INFO system extract different types ofmetadata, ranging from low-level audiovisualfeature descriptions to semantic metadata.
Theglobal metadata description must be rich and hasto clearly interrelate the various analysis results,as it is the input of the fusion component.4.1 Using MPEG-7 for Detailed Description ofAudiovisual ContentIn DIRECT-INFO the MPEG-7 standard is usedfor metadata description.
It is an excellent choicefor describing audiovisual content because of itscomprehensiveness and flexibility.
The compre-hensiveness results from the fact that the stan-dard has been designed for a broad range of ap-plications and thus employs very general andwidely applicable concepts.
The standard con-tains a large set of tools for diverse types of an-notations on different semantic levels.
The flexi-bility of MPEG-7, which is provided by a highlevel of generality, makes it usable for a broadapplication area without imposing strict con-straints on the metadata models of these applica-tions.
The flexibility is very much based on thestructuring tools and allows the description to bemodular and on different levels of abstraction.MPEG-7 supports fine grained description, and itis possible to attach descriptors to arbitrary seg-ments on any level of detail of the description.Among the descriptive tools developed withinthe MPEG-7 framework, one is concerned withthe use of natural language for adding metadatato the content description of image and video: theso-called Linguistic Description Scheme (LDS).4.2 MPEG-7: The Linguistic DescriptionScheme (LDS)MPEG-7 foresees four kinds of textual annota-tion that can be attached as metadata to someaudio-video content.
The natural language ex-pression used here is ?Spain scores a goal againstSweden.
The scoring player is Morientes?.Free Text Annotation: Here only tags are putaround the text:<TextAnnotation><FreeTextAnnotation xml:lang="en">Spain scores a goal against Sweden.The scoring player is Morientes.</FreeTextAnnotation></TextAnnotation>Key Word Annotation: Key Words are ex-tracted from text and correspondingly annotated:<TextAnnotation><KeywordAnnotation><Keyword>score</Keyword><Keyword>Sweden</Keyword><Keyword>Spain</Keyword><Keyword>Morientes</Keyword></KeywordAnnotation></TextAnnotation>54Structured Annotation: Question/Answeringlike semantics is associated to the text:<TextAnnotation><StructuredAnnotation><Who><Name>Spain</Name></Who><WhatAction><Name>scoregoal</Name></WhatAction><Where><Name>A Coru?a,Spain</Name></Where><When><Name>March 25,1998<Name></When></StructuredAnnotation></TextAnnotation>Dependency Structure: Here the full linguis-tic apparatus is used for annotating the text:<TextAnnotation><DependencyStructure><Sentence><Phrase operator="subject"><Head type="noun">Spain</Head></Phrase><Head type="verb" base-Form="score">scored</Head><Phrase operator="object"><Head type="article noun">agoal</Head></Phrase><Phrase><Headtype="preposition">against</Head><Phrase><Head>Sweden</Head></Phrase></Phrase></Sentence></DependencyStructure></TextAnnotation>14 MPEG-7 Format of the Text Analysiscomponent in DIRECT-INFOOn the base of the linguistic analysis of our de-pendency  parser, we generate the ?structuredannotation?
of the MPEG-7 Linguistic Descrip-tion Scheme.
We think that this kind of annota-tion is the most practical of LDS for adding se-mantics to multimedia content, since it is proba-bly more intuitive for the media expert as theunderlying linguistic dependency structure.
Atthe same  time it seems also straightforward togo first for a (internal) dependency analysis,since it is then relatively easy to map automati-cally dependency units to the ?Who?, ?WhatAc-tion?
and other tags of LDS.The MPEG-7 output of the TA module of DI-RECT-INFO looks like:<MediaInformation><MediaProfile><MediaFormat><Content href="http://www.direct-info.net/mpeg7/cs/ContentCS.2004.xml/di.content.writtenText"><Name>Written text</Name>1These examples are taken from a former and excellentonline tutorial on MPEG-7 by Philippe Salembier.</Content></MediaFormat><MediaInstance><InstanceIdentifier/><MediaLocator><!-- essence id--><MediaUri>5543</MediaUri></MediaLocator></MediaInstance></MediaProfile></MediaInformation><StructuralUnit href="http://www.direct-info.net/mpeg7/cs/StructuralUnitCS.2004.xml/di.vis.pdf"><Name>PDF</Name></StructuralUnit><!-- more than one page can be storedwithin a file --><SpatialDecomposition criteria="Page"><StillRegion id="TA_PAGE1"><StructuralUnithref="http://www.direct-info.net/mpeg7/cs/StructuralUnitCS.2004.xml/di.vis.page"><Name>Page</Name></StructuralUnit><SpatialDecomposition   crite-ria="TextAnalysis" gap="true" over-lap="false"><StillRegion><StructuralUnithref="http://www.direct-info.net/mpeg7/cs/StructuralUnitCS.2004.xml/di.vis.textAnal  ysisAnnotation"><Name>Text analysis annota-tion</Name></StructuralUnit><TextAnnotation><StructuredAnnotation><WhatObjecthref="http://www.direct-info.net/mpeg7/cs/LogoCS.2004.xml/di.ta.object.juventus"><Namexml:lang="it">Juventus</Name></WhatObject<WhatActionhref="http://www.direct-info.net/mpeg7/cs/TextAnalysisCS.2004.xml/di.ta.action.teamMentioned"><Name xml:lang="it">mentioning ofteam</Name></WhatAction><Why><Name xml:lang="it">295 771120 Con DVD Auto da Sogno Porschee 10, con calendario ufficiale 2006 Ju-ventus o Milan" o Inter o Palermo oFiorentina o Totti" o Wrestling" e 6, 9Euro 1, Poste Italiane Sped .
in A.P</Name></Why><How href="http://www.direct-info.net/mpeg7/cs/TextAnalysisCS.2004.xml/di.ta.mentioning.neut"><Name xml:lang="it">neut</Name></How></StructuredAnnotation></TextAnnotation></StillRegion>Without going into too much detail here, it isenough to stress that in the first part of the anno-tation, the link to the general multimedia andmultimodal repository is ensured.
We have to55deal with a PDF document that should be proc-essed by a Text Analysis tool.
The ?essence?
IDis giving information about the location wherethe application relevant data is stored and wherethe results of the Text Analysis should be stored.All this metadata is ensuring the combination ofthe results of the analysis of various modalitiesdealing with one application relevant dataset (forexample the combination of the logo detection ofa brand and the related positive or negative men-tioning of a team sponsored by this brand).
Forreason of place, we can not show and commenthere the complete (and multimodal) MPEG-7annotation, but details are given in (G. Kienast,2005).The second part of the annotation gives the re-sults of the combined linguistic and ?structured?analysis we are dealing with.
As mentionedabove, in the case of DIRECT-INFO, results oftext analysis are accessed via the structured an-notation of the Linguistic Description Schema ofMPEG-7.5 Conclusions and future WorkIn the DIRECT-INFO project we managed toinclude results of text analysis in an automatedfashion into a MPEG-7 description, which wasdealing with the XML representation of theanalysis of various modalities.
Using correspond-ing metadata, it was possible to ensure the en-coding/annotation of the related results in onefile and to facilitate the access to the separatedannotation using XPath.
As such the DIRECT-INFO MPEG-7 annotation schema is offering apracticable multi-dimensional annotationscheme, if we consider a ?dimensions?
as beingthe output of the analysis of various modalities.MPEG-7 proved to be generic and flexibleenough for combining, saving and accessingvarious types of annotation.Limitations of MPEG-7 were encounteredwhen the task was about fusion or merging ofinformation encoded in the various descriptors(or features), and this task was addressed in aposterior step, whereas the encoding scheme ofMPEG-7 was not longer helpful, in defining forexample relations between the annotation result-ing from the different modules or for definingconstraints between those annotation.
Thereseems to be a need for a higher level of represen-tation for annotation resulting from the analysisof distinct media, being low-level features forimages or high-level semantic features for texts.The need of  an ?ontologization?
of multime-dia features has been already recognized and pro-jects are already dealing with this, like AceMe-dia.
Initial work in relating multimodal annota-tion in DIRECT-INFO will be further developedin K-Space, a new Network of Excellence, whichgoal is to provide for support in semantic infer-ence for both automatic and semi-automatic an-notation and retrieval of multimedia content.
K-Space aims at closing the ?semantic gap?
be-tween the low-level content descriptions and therichness and subjectivity of semantics in high-level human interpretations of audiovisual media.6 AcknowledgementsThe R&D work presented in this paper was par-tially conducted within the DIRECT-INFO pro-ject, funded under the 6th Framework Programmeof the European Community within the strategicobjective "Semantic-based knowledge manage-ment systems" (IST FP6-506898).
Actual workon interoperability of media, language and se-mantic annotation is being funded by the Net-work of Excellence K-Space (IST FP6-027026).ReferencesT.
Declerck, J. Kuper, H. Saggion, A. Samiotou, P.Wittenburg, J. Contreras.
Contribution of NLP tothe Content Indexing of Multimedia Documents.
InLecture Notes in Computer Science Volume 3115 / 2004Pages 610-618,Springer-Verlag Heidelberg, 6 2004.T.
Declerck, M. Vela, ?Linguistic Dependencies as aBasis for the Extraction of Semantic Relations?, inProceedings of the ECCB'05 Workshop on Bio-medical Ontologies and Text Processing, Madrid(2005)G. Kienast, A. Horti, Andr?s, H. Rehatschek, S.Busemann, T.    Declerck, V. Hahn and R.
Cavet.
?DIRECT INFO: A Media Monitoring System forSponsorship Tracking.?
In Proceedings of theACM SIGIR Workshop on Multimedia InformationRetrieval.
2005.H.
Rehatschek: "DIRECT-INFO: Media monitoringand multimodal analysis for time critical deci-sions".
Proceedings of the 5th International Work-shop on Image Analysis for Multimedia InteractiveServices (WIAMIS), ISBN-972-98115-7-1, Lis-bon, April 2004.AceMedia project: http://www.acemedia.org/aceMediaDIRECT-INFO project: http://www.direct-info.net/K-Space project: http://kspace.qmul.net/MPEG-7: http://www.chiariglione.org/mpeg/56
