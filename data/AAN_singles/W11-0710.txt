Proceedings of the Workshop on Language in Social Media (LSM 2011), pages 76?85,Portland, Oregon, 23 June 2011. c?2011 Association for Computational LinguisticsLanguage use as a reflection of socialization in online communitiesDong NguyenCarnegie Mellon UniversityLanguage Technologies InstitutePittsburgh, PA 15213dongn@cs.cmu.eduCarolyn P. Rose?Carnegie Mellon UniversityLanguage Technologies InstitutePittsburgh, PA 15213cprose@cs.cmu.eduAbstractIn this paper we investigate the connection be-tween language and community membershipof long time community participants throughcomputational modeling techniques.
We re-port on findings from an analysis of languageusage within a popular online discussion fo-rum with participation of thousands of usersspanning multiple years.
We find communitynorms of long time participants that are char-acterized by forum specific jargon and a stylethat is highly informal and shows familiaritywith specific other participants and high emo-tional involvement in the discussion.
We alsofind quantitative evidence of persistent shiftsin language usage towards these norms acrossusers over the course of the first year of com-munity participation.
Our observed patternssuggests language stabilization after 8 or 9months of participation.1 IntroductionIn this paper we use text mining and machinelearning methodologies as lenses through which tounderstand the connection between language useand community membership in online communi-ties.
Specifically we examine an online medical sup-port community called breastcancer.org.
We presentanalyses of data from an active online communitywith the goal of uncovering the connection betweenlanguage and online community membership.
Inparticular, we will look at language changes that oc-cur over time as people continue to participate in anonline community.
Consistent with the Communi-ties of Practice theory of participation within a com-munity (Lave and Wenger, 1991), we find increas-ing conformity to community norms within the firstyear of participation that then stabilizes as partici-pants continue their involvement in the community.Within the Communities of Practice view, social-ization into a community begins with peripheral par-ticipation, during which individuals have the op-portunity to observe community norms.
Lave andWenger?s theory has been applied to both onlineand face-to-face communities.
In an online commu-nity, observing community norms begins with lurk-ing and reading messages before an initial post.
Thisis termed legitimate peripheral participation, and itis during this stage that potential new members ob-serve community norms in action.
With an initialpost, a user embarks upon the path of centripetalparticipation, as they are taking steps towards coreparticipation.Becoming a core member of a community meansadopting community norms.
Persistent languagechanges occur as an accumulation of local accom-modation effects (Labov, 2010a; Labov, 2010b).The extent of the adoption reflects the commitmentto community membership.
Thus, as an individualprogressively moves from the periphery of a com-munity towards the core, their behavior will progres-sively grow towards conformity with these norms,although total conformity very rarely occurs.
Thequantitative analysis we present in the form of aregression model is consistent with this theoreticalperspective and allows us to see what centripetal par-ticipation and core participation look like within thebreastcancer.org community.
We are able to test therobustness of these observations by using the extent76of conformity to community norms as a predictorof how long a member has been actively participat-ing in an online community.
We will present resultsfrom this predictive analysis as part of the quantita-tive evidence we provide in support of this model ofcommunity participation.Patterns of local accommodation and of long timelanguage change within communities have been ex-tensively studied in the field of variationist sociolin-guistics.
However, with respect to online commu-nities in particular, recent research has looked ataccommodation (Danescu-Niculescu-Mizil et al,2011; Nguyen et al, 2010) and some shorter termlanguage changes (i.e., over a period of a fewmonths).
However, longitudinal analyses of lan-guage change spanning long time periods (i.e., morethan a few months) in online communities as wepresent in this paper have been largely absent fromthe literature.
Typically, long term language changein sociolinguistics requires reconstructing the pastfrom the present using age grading techniques, sincea comprehensive historical record is typically absent(Labov, 2010a; Labov, 2010b).
Online communi-ties present a unique opportunity to study long termlanguage change from a much more comprehensivehistorical record of a community?s development.In the remainder of the paper, we first review priorwork on computational models of accommodationand language change.
We then present a qualitativeview of communication within the breastcancer.orgcommunity.
We then present two quantitative analy-ses, one that explores language change in the aggre-gate, and another that tests the robustness of findingsfrom the first analysis with a regression model thatallows us to predict how long a member has beenactive within the community.
We conclude with dis-cussion and future work.2 Related workFor decades, research under the heading of SocialAccommodation Theory (Giles et al, 1973) has at-tempted to layer a social interpretation on patterns oflinguistic variation.
This extensive line of researchhas provided ample quantitative evidence that peo-ple adjust their language within interactions, some-times to build solidarity or liking, and other timesto differentiate themselves from others (Eckert andRickford, 2001).In this line of work, people have often lookedat accommodation in small discussion groups anddyadic conversation pairs.
For example, Gonza-les et al (2010) analyzed style matching in smallgroup discussions, and used it to predict cohesive-ness and task performance in the groups.
Scis-sors et al (2009) analyzed conversational pairs play-ing a social dilemma game and interacting throughan instant messenger.
They found that certain pat-terns of high linguistic similarity characterize hightrusting pairs.
Niederhoffer and Pennebaker (2002)found linguistic style matching both at the conver-sation level and locally at a turn-by-turn level indyadic conversations.
Paolillo (2001) looked at theconnection between linguistic variation and strongand weak ties in an Internet Relay Chat channel.Nguyen et al (2010) found accommodation effectsin an online political forum that contains discus-sions between people with different political view-points.
Recently, Danescu-Niculescu-Mizil et al(2011) showed that accommodation was also presentin Twitter conversations.Lam (2008) gives an overview of work on lan-guage socialization in online communities.
Weknow that persistent language changes over longtime periods are the accumulated result of local ac-commodations that occur within short-term contextsfor social reasons (Labov, 2010a; Labov, 2010b).However, the process through which individualsadopt the language practices of online communi-ties has been barely explored so far.
One exam-ple of investigation within this scope is the workof Postmes et al (2000), in which we find analy-sis of the formation of group norms in a computer-mediated communication setting.
Specifically, theyfound that small groups were formed during the pro-cess and communication norms including languageusage patterns were present within those groups.Over time, conformity to these norms increased.Similarly, Cassell and Tversky (2005) looked at evo-lution of language patterns in an online community.In this work, the participants were students fromaround the world participating in the Junior Summitforum ?98.
Cassell and Tversky found that partic-ipants converged on style, topics, goals and strate-gies.
Analyses were computed using word frequen-cies of common classes (such as self references) and77Table 1: Statistics dataset.Posts 1,562,590Threads 68,226Users (at least one post) 31,307Time-span Oct 2002 - Jan 2011manual coding.
Huffaker et al (2006) examined asubset of the same data.
When comparing consec-utive weeks over a 6 week time period, they foundthat the language diverged.
They hypothesized thatthis was caused by external events leading to the in-troduction of new words.Our research differs from the research by Cas-sell and Tversky (2005), Huffaker et al (2006) andPostmes et al (2000) in several respects.
For ex-ample, in all of this work, participants joined thecommunity simultaneously at the inception of thecommunity.
In contrast, our community of inquiryhas evolved over time, with members joining inter-mittently throughout the history of the community.Additionally, our analysis spans much more time,specifically 2 years of data rather than 3 or 4 months.Thus, this research addresses a different questionfrom the way community norms are first establishedat the inception of a community.
In contrast, whatwe investigate is how new users are socialized intoan existing community in which norms have alreadybeen established prior to their arrival.We are not the first researchers to study our com-munity of inquiry (Jha and Elhadad, 2010).
How-ever, prior work on data from this forum was focusedon predicting the cancer stage of a patient rather thanissues related to language change that we investi-gate.3 Data descriptionWe analyze one of the largest breast cancer forumson the web (http://community.breastcancer.org/).All posts and user profiles of the forum were crawledin January 2011.The forum serves as a platform for many differ-ent kinds of interactions, and serving the needs of avariety of types of users.
For example, a large pro-portion of users only join to ask some medical ques-tions, and therefore do not stay active long.
In fact,we find that a lot of users (12,349) only post in thefirst week after their registration.
The distribution ofnumber of weeks between a user?s last post and reg-istration date follows a power law.
However, besidesthese short-term users, we also find a large numberof users who appear to be looking for more social in-volvement and continue to participate for years, evenafter their disease is in remission.This distinction in types of users is reflected in theforum structure.
The forum is well organized, con-taining over 60 subforums targeting different topics.Besides specific subforums targeting medical topics(such as ?Stage I and II Breast Cancer?
and ?Radi-ation Therapy - Before, During and After?
), thereare subforums for certain population groups (suchas ?Canadian Breast Cancer Survivors?
and ?Sin-gles with breast cancer?
), for social purposes (suchas ?Growing our Friendships After Treatment?, ?GetTogethers?, and ?CyberSisters Photo Album?)
andnon cancer related purposes (such as ?Humor andGames?).
In many of the subforums there are spe-cific threads that foster the formation of small subcommunities, for example threads for people whostarted chemotherapy in a certain month.In the data we find community norms of long timeparticipants that are characterized by forum specificjargon and a style that is highly informal and showsfamiliarity with specific other participants and highemotional involvement in the discussion.
We inferthat the forum specific jargon is distinct from whatwe would find in those users outside of it, in that thatthere are places in the forum explaining commonlyused abbreviations to new users.
We also observeposts within threads where users ask about certainabbreviations used in previous posts.
Some of theseabbreviations are cancer related and also used inplaces other than the forum, such as dx (diagnosis),and rads (radiation, radiotherapy).
Thus, they maybe reflective of identification with a broader commu-nity of cancer patients who are internet users.
Otheroften used abbreviations are dh (dear husband), dd(dear daughter), etc.
We also observed that users fre-quently refer to members of the community by nameand even as sister(s).Now let us look at some examples illustratingthese patterns of language change.
We take as an ex-ample a specific long-time user.
We start with a postfrom early in her participation, specifically from acouple of days after her registration:78I am also new to the forum, but not newto bc, diagnosed last yr, [..] My follow-up with surgeon for reports is not until8/9 over a week later.
My husband too isso wonderful, only married a yr in May,1 month before bc diagnosed, I could notget through this if it weren?t for him, nevermisses an appointment, [...] I wish every-one well.
We will all survive.The next two posts1 are from the same user, 2 to4 years after her registration date.
Both posts are di-rected to other forum members, very informal, andcontain a lot of abbreviations (e.g.
?DH?
(Dear Hus-band), ?DD?
(Dear Daughter), ?SIL?
(Son in Law)).Gee Ann I think we may have shared thesame ?moment in time?
boy I am gettingpaid back big time for my fun in the sun.Well Rose enjoy your last day of freedom- LOL.
Have lots of fun with DH ?TheHarley?.
Ride long and hard ( either oneyou choose - OOPS ).Oh Kim- sorry you have so much goingon - and an idiot DH on top of it all.[..]
Steph- vent away - that sucks - [..]XOXOXOXOXOXOXOX [..], quiet week-end kids went to DD?s & SIL on Fri-day evening, they take them to school [..],made an AM pop in as I am supposed to,SIL is an idiot but then you all know that.This anecdotal evidence illustrates the linguisticshift we will now provide quantitative evidence for.4 Patterns of language change4.1 ApproachIn this section we aggregate data across long timeparticipants and look at global patterns of languagechange.
Specifically, we will analyze patterns ofchange in the first year after registration of thesemembers, and show how language patterns consis-tently become more different from the first week ofparticipation and more similar to the stable patternfound within the second year of data.
Furthermore,when comparing consecutive weeks we find that the1Names are replaced in exampledifference increases and then stabilizes by the endof the first year.
The unit of analysis is one weekof data.
Because there are multiple ways to mea-sure the similarity or difference between two distri-butions, we explore the use of two different meth-ods.
The first metric we use is the Kullback-Leibler(KL) divergence.
Larger values indicate bigger dif-ferences in distribution.
P represents the true distri-bution.
Note that this metric is asymmetric.KL(P,Q) =?iP (i) logP (i)Q(i)We also explore using the Spearman?s Rank Corre-lation Coefficient (SRCC), which measures the sim-ilarity of two rankings:SRCC = 1?6?i d2in(n2 ?
1)Where di is the difference between the ranks of wordi in the two rankings and n is the total number ofwords.4.2 SamplingIn this analysis, we begin by aligning the data of ev-ery member by registration date.
We then aggregateposts of all users by week.
Thus, in week 1, we havethe posts from all users during the first week aftertheir registration.
Note that the actual week in timewould not be the same for each of these users sincethey did not all register at the same time.
In this way,a week worth of data represents the way users talkafter the corresponding number of weeks after regis-tering with the community rather than representinga specific period of time.
Because our dataset spansa large time period of time (i.e.
more than 8 years),it is very unlikely that patterns we find in the datareflect external events from any specific time period.As discussed before, a large proportion of mem-bers only post in their first week after registration.These short time members might already initiallydiffer from members who tend to participate longerin the forum.
Therefore, it might confuse the modelif we take these short time members into account.We may observe apparent changes in language thatare artifacts of the difference in distribution of usersacross weeks.
Thus, because we are interested inlanguage change specifically, we only consider postsof long-term participants.79In addition, we have limited our focus to the ini-tial two-year period of participation, because it isfor this length of participation that we have enoughusers and enough posts to make a computationalmodel feasible.
We have also limited ourselves toexamining high frequency words, because we havea large vocabulary but only a limited amount of dataper week.
Two weeks can look artificially similarif they both have a lot of non-occurring words.
Insummary, taking above considerations into account,we applied the following procedure:?
We only look at the first 2 years, for which westill have a large amount of data for every week.?
We only look at members who are long-termparticipants (2 years or longer), this leaves uswith 3,012 users.?
For every week, we randomly sample an equalnumber of posts (i.e., 600 from each week).
Allposts are taken into account (i.e.
both responsesas well as thread openings).?
We only look at the distribution change ofhigh frequency words (words occurring at least1,000 times), this leaves us with 1,540 uniquewords.
No stemming or stop word removal wasdone.4.3 Comparison with early and latedistributionsUsing the dataset described in the previous section,we compare the language of each week during thefirst year after registration with language in the veryfirst week and with language in the second year.First we analyze whether language in the first yearbecomes more similar to language used by membersin their second year as time progresses.
We there-fore compare the word distributions of the weeks ofthe first year with the overall word distribution ofthe second year.
We apply KL divergence wherewe consider the distribution of the second year asthe ?true distribution?.
The result is shown in Fig-ure 1.
We see that the KL divergence decreases,which means that as time progresses, the word dis-tributions look more like the distribution of the sec-ond year.
Fitting a Least Squares (LS) model, weget an intercept of 0.121033 and slope of -0.001080Figure 1: KL divergence between weeks in first year andoverall second year.Figure 2: KL divergence between weeks in first year andfirst week.
(r2 = 0.5528).
Using the Spearman Rank Correla-tion (SRCC) and fitting a LS model, we observe thesame pattern (r2 = 0.6435).Our second analysis involves comparing the dis-tributions of the first year (excluding the first week),with the distribution of the first week.
The result isshown in Figure 2.
We see that the KL divergenceincreases, meaning that as time progresses, the worddistributions become less similar with the first week.
(KL: r2 = 0.6643, SRCC: r2 = 0.7962).4.4 Comparing consecutive distributionsWe now compare the distributions of consecutiveweeks to see how much language change occurs indifferent time periods.
For KL divergence we use thesymmetric version.
Results are presented in Figure3 and show a divergence pattern throughout the firstyear that stabilizes towards the end of that first yearof participation.
(KL: r2 = 0.4726, SRCC: r2 =80Figure 3: KL divergence between consecutive weeks.0.8178).
The divergence pattern was also observedby Huffaker et al (2006) (related, but not equiva-lent setting, as mentioned in the literature review).We hypothesize that the divergence occurs becauseusers tend to talk about a progressively broader setof topics as they become more involved in the com-munity.
To confirm this hypothesis, we compare thedistributions of each week with the uniform distri-bution.
We indeed find that as time progresses, thedistributions for each week become more uniform.
(KL: r2 = 0.3283, SRCC: r2 = 0.6435).5 Predicting membership durationIn the previous section we found strong patterns oflanguage change in our data.
We are interested in theextent to which we can automatically predict howmany weeks the user has been a member, using onlytext or meta-features from that specific week.
Iden-tifying which features predict how long a memberhas been active can give more detailed insight intothe social language that characterizes the commu-nity.
In addition, it tells us how prominent the pat-tern is among other sources of language variation.5.1 DatasetFor this analysis, we set up the data slightly differ-ently.
Now, rather than combine data across users,we keep the data from each user for each week sep-arate so we can make a separate prediction for eachuser during each week of their participation.
Thus,for each person, we aggregate all posts per week.We only consider weeks in the first two years afterthe registration in which there were at least 10 postswith at least 10 tokens from that user.Table 2: Statistics dataset.#Docs #Persons #PostsTraining 13,273 1,591 380,143Development 4,617 548 122,489Test 4,571 548 134,1415.2 ApproachGiven an input vector x ?
Rm containing the fea-tures, we aim to find a prediction y?
?
R for the num-ber of weeks the person has been a member of thecommunity y ?
R using a linear regression model:y?
= ?0 + x>?
where ?0 and ?
are the parametersto estimate.
Usually, the parameters are learned byminimizing the sum of squared errors.In order to strive for a model with high explana-tory value, we use Linear Regression, with L1 reg-ularization (Tibshirani, 1996).
This minimizes thesum of squared errors, but in addition adds a penaltyterm ?
?mj=1 |?j |, the sum of absolute values of thecoefficients.
?
is a constant and can be found byoptimizing over the development data.
As a re-sult, this method delivers sparse models.
We useOrthant-Wise Limited-memory Quasi-Newton Op-timizer (Andrew and Gao, 2007) as our optimiza-tion method.
This method has proven to establishcompetitive performances with other optimizationmethods, while producing sparse models (Gao et al,2007).Because our observations suggest that languagechange decreases as members have been activelonger, we also experimented with applying a logtransformation on the number of weeks.5.3 FeaturesFor all features, we only use information that hasbeen available for that particular week.
We exploredifferent types of features related to the qualitativedifferences in language we discussed in Section 3:textual, behavioral, subforum and meta-features.5.3.1 Textual featuresWe explore the following textual features:?
Unigrams and bigrams.?
Part of Speech (POS) bigrams.
Text was taggedusing the Stanford POS tagger (Toutanova etal., 2003).81?
LIWC (Pennebaker et al, 2001), a word count-ing program that captures word classes andstylistic features.?
Usernames.
Because some of the usernamesare common words, we only consider user-names of users active in the same thread.?
Proper names.
We obtained a list containingcommon female names.
We ranked them ac-cording to frequency in our dataset, and manu-ally deleted common words in our dataset, suchas happy, hope, tuesday and may, from our list.?
Slang words.
We manually compile a list ofcommon abbreviations and their whole wordscounterpart.
We then count the number of ab-breviations and the number of whole wordsused in the post.
The feature value thenis (#abbrev?#wholewords)/#totalwords.Because in some contexts no abbreviationscan be used, this feature takes into account ifthe user actually chose to use the abbrevia-tion/whole word, or if there was no need forit.No stemming or stopword removal is used.
Fre-quencies are normalized by length.5.3.2 Behavioral featuresWe also explore additional features that indicatethe behavior of the user:?
Ratio (posts starting threads) / (total number ofposts).?
Number of posts.5.3.3 Subforum featuresWe include as features the distribution of subfo-rums the member has posted in.
This captures twointuitions.
First, it is an approximation of the currentphase in the cancer process for that member.
For ex-ample, we noticed that most of the new users havejust been diagnosed, while long term users have al-ready finished treatment.
Because the subforums arevery specific (such as ?Not Diagnosed with a Re-currence or Metastases but Concerned?
), we expectthese features to give a good approximation of thephase the user is currently in.
In addition, these sub-forums also give an indication of the user?s interest.Table 3: Results reported with Pearsons correlation (r).Run # Features Raw (r) Log (r)Unigrams + Bigrams 43,126 0.547 0.621POS 1,258 0.409 0.437LIWC 88 0.494 0.492Proper names 1 0.185 0.186Usernames 1 0.150 0.102Slang 1 0.092 0.176Behavior 2 0.139 0.243Subforum 65 0.404 0.419All above 44,542 0.581 0.649All above + Person 46,133 0.586 0.656For example, whether the user posts mostly in med-ical forums, or mostly in the social orientated subfo-rums.5.3.4 Other featuresMost of the persons appear multiple times in ourdataset (e.g.
multiple weeks).
To help the modelcontrol for idiosyncratic features of individual users,we include for every person a dummy variable asso-ciated with that user?s unique identity.
This helpsthe model at training time to separate variance inlanguage usage across users from general effects re-lated to length of participation.
Note that we do notuse these features as test time.5.4 ResultsWe experimented with individual types of featuresas well as all of them aggregated.
The results (corre-lations) can be found in Table 3.
The features havingthe most weight for long time participants in our bestmodel (All incl.
Person, Log) are presented in Table4.
We see that for most features the performancewas higher when applying the log transformation.This was especially the case with the unigrams andbigrams features.
For some features the differencewas less, such as for proper names and the subforumfeatures.
This could indicate that these features havea more linear pattern as time progresses, while wordpatterns such as unigrams tend to stabilize earlier.We find that both stylistic patterns (such as POS) aswell as patterns indicating conformity (social behav-ior, slang words) are individually already very pre-dictive.In our best performing model, we find that both82Table 5: Qualitative grouping of textual features.Type Short time members Long time membersAbbreviations Husband My DD (Dear Daughter), Your PS (Plastic Surgeon)Social networks Facebook, fbGreetings Hi all Hi girls, Hi galsI versus other LIWC-I, My, Me LIWC-other, We, SistersSocial support Hugs, Condolences, So sorryThanking Thanks, Thanx, ThxForum Bc org, On bcoIntroducing Newbie, New here, Am newAsking information Info, LIWC-qmarksTable 4: Top 10 features of long term users.Feature WeightMETA - slang 0.058362195META -propername 0.052984915year 0.050872918META - [person1] 0.050708718META - [person2] 0.040548104months 0.040400583META - [person3] 0.039806096LIWC - Othref 0.036080545META - [person4] 0.035605996POS - nnp prp 0.035033650the slang and proper name features get a high weightfor long time participants.
Furthermore, we observethat a lot of the person meta features are includedin the model when it is trained, although as men-tioned we do not use these features at testing time.The fact that the model assigns them weight indi-cates that idiosyncratic features of users explain a lotof variance in the data.
Our best performing modelhas 3,518 non zero features.
In Table 5 we qual-itatively grouped and contrasted features that weremore associated with short-term or long-term mem-bers.
We see that long-term members show muchmore social behavior and familiarity with each other.This is shown to references to each other, more so-cial support, references to social networks and waysof greeting.
They furthermore talk about the forumitself more often by using the abbreviation ?bco?.Short term members are characterized by words thatare used when they introduce themselves to others.Thus we find that long time participants are char-acterized by informal language, containing many fo-rum specific jargon, as well as showing emotionalinvolvement with other forum members.
Our bestrun obtained a correlation of r = 0.656, giving anr2 value of 0.430.
This means that 0.43 of the vari-ation can be explained by our model.
Since thereare many other factors that influence the writing ofusers, it is understandable that our model does notexplain all the variance.6 DiscussionAs discussed widely in previous literature, peo-ple become socialized into communities over timethrough their interactions with community mem-bers.
The extent of conformity to group norms re-flects commitment to the group.
Our first studyshowed evidence of increasing conformity to com-munity norms through changes in simple word dis-tributions.
The second study then tested the robust-ness of these findings through a prediction task andextended the language features of the first study.Since community members tend to conform in-creasingly to community norms over time, althoughthe target class for our predictive model is time, itis reasonable to assume that what the model reallylearns to predict is how long average communitymembers have been around by the time they soundlike that.
In other words, one can think about its timeprediction as a measure of how long it sounds likethat person has been in the community.
The modelwould therefore overpredict for members who movefrom the periphery to the core of a community fasterthan average while underpredicting for those who doso more gradually.
This would be consistent with the83idea that rate of commitment making and conformityis person specific.There are two limitations that need to be ad-dressed regarding the present studies.
First, thereare certain factors that influence the rate of adop-tion to the forum that we are not able to take intoaccount.
For example, some people might have al-ready been reading the forum for a while, beforethey actually decide to join the community.
Thesepeople are already exposed to the community prac-tices, and therefore might already show more con-formity in the beginning than others.Second, our experiments involved one onlinecommunity targeting a very specific topic.
Due tothe nature of the topic, most of the active users comefrom a small subpopulation (mostly women between40-60 years).
Therefore, it is a question how wellthese results can be applied to other online commu-nities.As a future application, a model that can capturethese changes could be used in research related tocommitment in online communities.7 ConclusionIt is widely accepted that persistent language changein individuals occurs over time as a result of theaccumulation of local processes of accommodation.Although previous research has looked at accommo-dation within short periods of time, including recentresearch on social media data, persistent languagechange as a result of longer term involvement in anonline community is still an understudied area.In this paper we have presented research aiming toclose this gap.
We have analyzed data from a largeonline breast cancer forum.
Analyzing data of longtime members, we found strong patterns indicatinglanguage changes as these members participated inthe community, especially over the course of theirfirst year of participation.We then presented a regression approach to pre-dict how long a person has been a member of thecommunity.
Long time participants were character-ized by showing more social behavior.
Furthermore,they used more forum specific language, such as cer-tain abbreviations and ways of greeting.
Due to thenature of our dataset, language was also influencedby external factors such as changes in the cancer pro-cess of individuals.Although our observations are intuitive and agreewith observations in previous, related literature re-garding socialization in communities, it is still aquestion whether our observations generalize toother online communities.In our current work we have looked at changesacross users and across contexts.
However, it is wellknown that individuals adapt their language depend-ing on local interactions.
Thus, a next step wouldbe to model the process by which local accommoda-tion accumulates and results in long term languagechange.AcknowledgmentsThe authors would like to thank Michael Heilmanfor the regression code and Noah Smith for ideas forthe regression experiments.
This work was fundedby NSF grant IIS-0968485.ReferencesGalen Andrew and Jianfeng Gao.
2007.
Scalable train-ing of l1-regularized log-linear models.
In Proceed-ings of the 24th international conference on Machinelearning, ICML ?07, pages 33?40, New York, NY,USA.
ACM.Justine Cassell and Dona Tversky.
2005.
The languageof online intercultural community formation.
Journalof Computer-Mediated Communication, 10:16?33.Cristian Danescu-Niculescu-Mizil, Michael Gamon, andSusan Dumais.
2011.
Mark my words!
linguisticstyle accommodation in social media.
In Proceedingsof WWW.Penelope Eckert and John R. Rickford.
2001.
Style andSociolinguistic Variation.
Cambridge: University ofCambridge Press.Jianfeng Gao, Galen Andrew, Mark Johnson, andKristina Toutanova.
2007.
A comparative study of pa-rameter estimation methods for statistical natural lan-guage processing.
In Proceedings of the 45th AnnualMeeting of the Association of Computational Linguis-tics, pages 824?831, Prague, Czech Republic, June.Association for Computational Linguistics.Howard Giles, Donald M. Taylor, and Richard Bourhis.1973.
Towards a theory of interpersonal accommoda-tion through language: some canadian data.
Languagein Society, 2(02):177?192.Amy L. Gonzales, Jeffrey T. Hancock, and James W. Pen-nebaker.
2010.
Language style matching as a predic-tor of social dynamics in small groups.
Communica-tion Research, 37(1):3?19, February.84David Huffaker, Joseph Jorgensen, Francisco Iacobelli,Paul Tepper, and Justine Cassell.
2006.
Computa-tional measures for language similarity across timein online communities.
In Proceedings of the HLT-NAACL 2006 Workshop on Analyzing Conversationsin Text and Speech, ACTS, pages 15?22, Stroudsburg,PA, USA.
Association for Computational Linguistics.Mukund Jha and Noe?mie Elhadad.
2010.
Cancer stageprediction based on patient online discourse.
In Pro-ceedings of the 2010 Workshop on Biomedical Natu-ral Language Processing, BioNLP ?10, pages 64?71,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.William Labov.
2010a.
Principles of Linguistic Change,Volume I, Internal Factors.
Wiley-Blackwell.William Labov.
2010b.
Principles of Linguistic Change,Volume I, Social Factors.
Wiley-Blackwell.Wan S. E. Lam.
2008.
Language socialization in on-line communities.
In Nancy H. Hornberger, editor, En-cyclopedia of Language and Education, pages 2859?2869.
Springer US.Jean Lave and Etienne Wenger.
1991.
Situated Learn-ing.
Legitimate peripheral participation.
Cambridge:University of Cambridge Press.Dong Nguyen, Elijah Mayfield, and Carolyn P. Rose.2010.
An analysis of perspectives in interactive set-tings.
In Proceedings of the 2010 KDD Workshop onSocial Media Analytics.Kate G. Niederhoffer and James W. Pennebaker.
2002.Linguistic style matching in social interaction.John C. Paolillo.
2001.
Language variation on internetrelay chat: A social network approach.
Journal of So-ciolinguistics, 5:180?213.James W. Pennebaker, Roger J. Booth, and Martha E.Francis, 2001.
Linguistic Inquiry and Word Count(LIWC): A Computerized Text Analysis Program.Tom Postmes, Russell Spears, and Martin Lea.
2000.The formation of group norms in computer-mediatedcommunication.
Human Communication Research,26(3):341?371.Lauren E. Scissors, Alastair J. Gill, Kathleen Geraghty,and Darren Gergle.
2009.
In cmc we trust: the roleof similarity.
In Proceedings of the 27th internationalconference on Human factors in computing systems,CHI ?09, pages 527?536, New York, NY, USA.
ACM.Robert Tibshirani.
1996.
Regression shrinkage and se-lection via the lasso.
Journal of the Royal StatisticalSociety.
Series B (Methodological), 58(1):267?288.Kristina Toutanova, Dan Klein, Christopher D. Manning,and Yoram Singer.
2003.
Feature-rich part-of-speechtagging with a cyclic dependency network.
In Pro-ceedings of the 2003 Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics on Human Language Technology - Volume 1,NAACL ?03, pages 173?180, Stroudsburg, PA, USA.Association for Computational Linguistics.85
