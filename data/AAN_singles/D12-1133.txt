Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 1455?1465, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsA Transition-Based System for Joint Part-of-Speech Taggingand Labeled Non-Projective Dependency ParsingBernd BohnetInstitute for Natural Language ProcessingUniversity Stuttgartbohnet@ims.uni-stuttgart.deJoakim NivreDepartment of Linguistics and PhilologyUppsala Universityjoakim.nivre@lingfil.uu.seAbstractMost current dependency parsers presupposethat input words have been morphologicallydisambiguated using a part-of-speech taggerbefore parsing begins.
We present a transition-based system for joint part-of-speech taggingand labeled dependency parsing with non-projective trees.
Experimental evaluation onChinese, Czech, English and German showsconsistent improvements in both tagging andparsing accuracy when compared to a pipelinesystem, which lead to improved state-of-the-art results for all languages.1 IntroductionDependency-based syntactic parsing has been thefocus of intense research efforts during the lastdecade, and the state of the art today is represent-ed by globally normalized discriminative modelsthat are induced using structured learning.
Graph-based models parameterize the parsing problem bythe structure of the dependency graph and normallyuse dynamic programming for inference (McDonaldet al 2005; McDonald and Pereira, 2006; Carreras,2007; Koo and Collins, 2010; Bohnet, 2010), butother inference methods have been explored espe-cially for non-projective parsing (Riedel and Clarke,2006; Smith and Eisner, 2008; Martins et al 2009;Martins et al 2010; Koo et al 2010).
Transition-based models parameterize the problem by elemen-tary parsing actions and typically use incrementalbeam search (Titov and Henderson, 2007; Zhangand Clark, 2008; Zhang and Clark, 2011).
Despitenotable differences in model structure, graph-basedand transition-based parsers both give state-of-the-art accuracy with proper feature selection and opti-mization (Koo and Collins, 2010; Zhang and Nivre,2011; Bohnet, 2011).It is noteworthy, however, that almost all depen-dency parsers presuppose that the words of an inputsentence have been morphologically disambiguatedusing (at least) a part-of-speech tagger.
This is in s-tark contrast to the best parsers based on PCFG mod-els, such as the Brown parser (Charniak and John-son, 2005) and the Berkeley parser (Petrov et al2006; Petrov and Klein, 2007), which not only canperform their own part-of-speech tagging but nor-mally give better parsing accuracy when they are al-lowed to do so.
This suggests that joint models fortagging and parsing might improve accuracy also inthe case of dependency parsing.It has been argued that joint morphological andsyntactic disambiguation is especially important forrichly inflected languages, where there is consid-erable interaction between morphology and syntaxsuch that neither can be fully disambiguated with-out considering the other.
Thus, Lee et al(2011)show that a discriminative model for joint morpho-logical disambiguation and dependency parsing out-performs a pipeline model in experiments on Latin,Ancient Greek, Czech and Hungarian.
However, Liet al(2011) and Hatori et al(2011) report improve-ments with a joint model also for Chinese, whichis not a richly inflected language but is neverthelessrich in part-of-speech ambiguities.In this paper, we present a transition-based mod-el for joint part-of-speech tagging and labeled de-pendency parsing with non-projective trees.
Exper-1455iments show that joint modeling improves both tag-ging and parsing accuracy, leading to state-of-the-artaccuracy for richly inflected languages like Czechand German as well as more configurational lan-guages like Chinese and English.
To our knowledge,this is the first joint system that performs labeled de-pendency parsing.
It is also the first joint system thatachieves state-of-the-art accuracy for non-projectivedependency parsing.2 Transition-Based Tagging and ParsingTransition-based dependency parsing was pioneeredby Yamada and Matsumoto (2003) and Nivre et al(2004), who used classifiers trained to predict indi-vidual actions of a deterministic shift-reduce parser.Recent research has shown that better accuracy canbe achieved by using beam search and optimizingmodels on the entire sequence of decisions neededto parse a sentence instead of single actions (Zhangand Clark, 2008; Huang and Sagae, 2010; Zhangand Clark, 2011; Zhang and Nivre, 2011; Bohnet,2011).
In addition, a number of different transitionsystems have been proposed, in particular for deal-ing with non-projective dependencies, which werebeyond the scope of early systems (Attardi, 2006;Nivre, 2007; Nivre, 2009; Titov et al 2009).In this section, we start by defining a transitionsystem for joint tagging and parsing based on thenon-projective transition system proposed in Nivre(2009).
We then show how to perform beam searchand structured online learning with this model, andconclude by discussing feature representations.2.1 Transition SystemGiven a set P of part-of-speech tags and a set Dof dependency labels, a tagged dependency tree fora sentence x = w1, .
.
.
, wn is a directed tree T =(Vx, A) with labeling functions pi and ?
such that:1.
Vx = {0, 1, .
.
.
, n} is a set of nodes,2.
A ?
Vx ?
Vx is a set of arcs,3.
pi : Vx ?
P is a labeling function for nodes,4.
?
: A?
D is a labeling function for arcs,5.
0 is the root of the tree.The set Vx of nodes is the set of positive integers upto and including n, each corresponding to the lin-ear position of a word in the sentence, plus an extraartificial root node 0.
The set A of arcs is a set ofpairs (i, j), where i is the head node and j is thedependent node.
The functions pi and ?
assign a u-nique part-of-speech label to each node/word and aunique dependency label to each arc, respectively.This notion of dependency tree differs from the s-tandard definition only by including part-of-speechlabels as well as dependency labels (Ku?bler et al2009).Following Nivre (2008), we define a transitionsystem for dependency parsing as a quadruple S =(C, T, cs, Ct), where1.
C is a set of configurations,2.
T is a set of transitions, each of which is a (par-tial) function t : C ?
C,3.
cs is an initialization function, mapping a sen-tence x to a configuration c ?
C,4.
Ct ?
C is a set of terminal configurations.A transition sequence for a sentence x in S is asequence of configuration-transition pairs C0,m =[(c0, t0), (c1, t1), .
.
.
, (cm, tm)] where c0 = cs(x),tm(cm) ?
Ct and ti(ci) = ci+1 (0 ?
i < m).1In this paper, we take the set C of configurationsto be the set of all 5-tuples c = (?, B,A, pi, ?)
suchthat ?
(the stack) and B (the buffer) are disjoin-t sublists of the nodes Vx of some sentence x, Ais a set of dependency arcs over Vx, and pi and ?are labeling functions as defined above.
We take theinitial configuration for a sentence x = w1, .
.
.
, wnto be cs(x) = ([0], [1, .
.
.
, n], { },?,?
), where ?is the function that is undefined for all arguments,and we take the set Ct of terminal configurationsto be the set of all configurations of the form c =([0], [ ], A, pi, ?)
(for anyA, pi and ?).
The tagged de-pendency tree defined for x by c = (?, B,A, pi, ?
)is the tree (Vx, A) with labeling functions pi and ?,which we write TREE(x, c).The set T of transitions is shown in Figure 1.
TheLEFT-ARCd and RIGHT-ARCd transitions both addan arc (with dependency label d) between the twonodes on top of the stack and replaces these nodesby the head node of the new arc (which is the right-most node for LEFT-ARCd and the leftmost node forRIGHT-ARCd).
The SHIFTp transition extracts the1This definition of transition sequence differs from that ofNivre (2008) but is equivalent and suits our presentation better.1456Transition ConditionLEFT-ARCd ([?|i, j], B,A, pi, ?)?
([?|j], B,A?
{(j, i)}, pi, ?
[(j, i)?
d]) i 6= 0RIGHT-ARCd ([?|i, j], B,A, pi, ?)?
([?|i], B,A?
{(i, j)}, pi, ?
[(i, j)?
d])SHIFTp (?, [i|?
], A, pi, ?)?
([?|i], ?, A, pi[i?
p], ?
)SWAP ([?|i, j], ?, A, pi, ?)?
([?|j], [i|?
], A, pi, ?)
0 < i < jFigure 1: Transitions for joint tagging and dependency parsing extending the system of Nivre (2009).
The stack ?
isrepresented as a list with its head to the right (and tail ?)
and the buffer B as a list with its head to the left (and tail ?
).The notation f [a?
b] is used to denote the function that is exactly like f except that it maps a to b.first node in the buffer, pushes it onto the stack andlabels it with the part-of-speech tag p. The SWAPtransition extracts the second topmost node from thestack and moves it back to the buffer, subject to thecondition that the two top nodes on the stack are stillin the order given by the sentence.Except for the addition of a tag parameter p tothe SHIFT transition, this is equivalent to the sys-tem described in Nivre (2009), which thanks to theSWAP transition can handle arbitrary non-projectivetrees.
The soundness and completeness results giv-en in that paper trivially carry over to the new sys-tem.
The only thing to note is that, before a terminalconfiguration can be reached, every word has to bepushed onto the stack in a SHIFTp transition, whichensures that every node/word in the output tree willbe tagged.2.2 Inference and LearningWhile early transition-based parsers generally usedgreedy best-first inference and locally trained clas-sifiers, recent work has shown that higher accura-cy can be obtained using beam search and globalstructure learning to mitigate error propagation.
Inparticular, it seems that the globally learned modelscan exploit a much richer feature space than local-ly trained classifiers, as shown by Zhang and Nivre(2011).
Since joint tagging and parsing increases thesize of the search space and is likely to require nov-el features, we use beam search in combination withstructured perceptron learning.The beam search algorithm used to derive the bestparse y for a sentence x is outlined in Figure 2.
Inaddition to the sentence x, it takes as input a weightvector w corresponding to a linear model for scor-ing transitions out of configurations and two prun-PARSE(x,w, b1, b2)1 h0.c?
cs(x)2 h0.s?
0.03 h0.f?
{0.0}dim(w)4 BEAM ?
[h0]5 while ?h ?
BEAM : h.c 6?
Ct6 TMP ?
[ ]7 foreach h ?
BEAM8 foreach t ?
T : PERMISSIBLE(h.c, t)9 h.f?
h.f + f(h.c, t)10 h.s?
h.s+ f(h.c, t) ?
w11 h.c?
t(h.c)12 TMP ?
INSERT(h, TMP)13 BEAM?
PRUNE(TMP, b1, b2)14 h?
TOP(BEAM)15 y ?
TREE(x, h.c)16 return yFigure 2: Beam search algorithm for joint tagging and de-pendency parsing of input sentence x with weight vectorw and beam parameters b1 and b2.
The symbols h.c, h.sand h.f denote, respectively, the configuration, score andfeature representation of a hypothesis h; h.c.A denotesthe arc set of h.c.ing parameters b1 and b2.
A parse hypothesis h isrepresented by a configuration h.c, a score h.s anda feature vector h.f for the transition sequence up toh.c.
Hypotheses are stored in the list BEAM, whichis sorted by descending scores and initialized to holdthe hypothesis h0 corresponding to the initial con-figuration cs(x) with score 0.0 and all features setto 0.0 (lines 1?4).
In the main loop (lines 5?13), aset of new hypotheses is derived and stored in thelist TMP, which is finally pruned and assigned asthe new value of BEAM.
The main loop terminates1457when all hypotheses in BEAM contain terminal con-figurations, and the dependency tree extracted fromthe top scoring hypothesis is returned (lines 14?16).The set of new hypotheses is created in two nest-ed loops (lines 7?12), where every hypothesis h inBEAM is updated using every permissible transitiont for the configuration h.c.
The feature representa-tion of the new hypothesis is obtained by adding thefeature vector f(t, h.c) for the current configuration-transition pair to the feature vector of the old hy-pothesis (line 9).
Similarly, the score of the newhypothesis is the sum of the score f(t, h.c) ?
w ofthe current configuration-transition pair and the s-core of the old hypothesis (line 10).
The featurerepresentation/score of a complete parse y for xwith transition sequence C0,m is thus the sum of thefeature representations/scores of the configuration-transition pairs in C0,m:f(x, y) =?
(c,t)?C0,mf(c, t)s(x, y) =?
(c,t)?C0,mf(c, t) ?
wFinally, the configuration of the new hypothesis isobtained by evaluating t(h.c) (line 11).
The new hy-pothesis is then inserted into TMP in score-sorted or-der (line 12).The pruning parameters b1 and b2 determine thenumber of hypotheses allowed in the beam and atthe same time control the tradeoff between syntacticand morphological ambiguity.
First, we extract theb1 highest scoring hypotheses with distinct depen-dency trees.
Then we extract the b2 highest scoringremaining hypotheses, which will typically be tag-ging variants of dependency trees that are already inthe beam.
In this way, we prevent the beam fromgetting filled up with too many tagging variants ofthe same dependency tree, which was found to beharmful in preliminary experiments.One final thing to note about the inference algo-rithm is that the notion of permissibility for a transi-tion t out of a configuration c can be used to capturenot only formal constraints on transitions ?
such asthe fact that it is impossible to perform a SHIFTptransition with an empty buffer or illegal to performa LEFT-ARCd transition with the special root nodeon top of the stack ?
but also to filter out unlike-ly dependency labels or tags.
Thus, in the experi-ments later on, we will typically constrain the parserso that SHIFTp is permissible only if p is one of thek best part-of-speech tags with a score no more than?
below the score of the 1-best tag, as determined bya preprocessing tagger.
We also filter out instancesof LEFT-ARCd and RIGHT-ARCd, where d does notoccur in the training data for the predicted part-of-speech tag combination of the head and dependent.This procedure leads to a significant speed up.In order to learn a weight vector w from a trainingset {(xj , yj)}Tj=1 of sentences with their tagged de-pendency trees, we use a variant of the structuredperceptron, introduced by Collins (2002), whichmakes N iterations over the training data and up-dates the weight vector for every sentence xj wherethe highest scoring parse y?
is different from yj .More precisely, we use the passive-aggressive up-date of Crammer et al(2006):wi+1 = wi + ?
(f(xj , yj)?
f(xj , y?))where?
=f(xj , yj)?
f(xj , y?
)||f(xj , yj)?
f(xj , y?
)||2We also use the early update strategy found benefi-cial for parsing in several previous studies (Collinsand Roark, 2004; Zhang and Clark, 2008; Huangand Sagae, 2010), which means that, during learn-ing, we terminate the beam search as soon as thehypothesis corresponding to the gold parse yj fallsout of the beam and update with respect to the par-tial transition sequence constructed up to that point.Finally, we use the standard technique of averagingover all weight vectors, as originally proposed byCollins (2002).2.3 Feature RepresentationsAs already noted, the feature representation f(x, y)of an input sentence x with parse y decomposes intofeature representations f(c, t) for the transitions t(c)needed to derive y from cs(x).
Features may refer toany aspect of a configuration, as encoded in the stack?, the bufferB, the arc setA and the labelings pi and?.
In addition, we assume that each word w in theinput is assigned up to k candidate part-of-speechtags pii(w) with corresponding scores s(pii(w)).1458Features involving word prefixes and suffixespii(B0)p2(B0), pii(B0)s2(B0), pii(B0)p1(B0)p1(?0)pii(?0)p1(?0)p1(?1), pii(?0)s1(?0)s1(?0)pii(?0)p2(?0)s3(?1),pii(?0)s3(?0)p2(?1)pii(?0)w(B0)s1(?0), pii(?0)w(B0)s2(?0)Features involving tag score differences and rankspii(B0)[s(pi1(B0))?
s(pii(B0))]pii(B0)pii(?0)[s(pi1(B0))?
s(pii(B0))] ipii(B0)[s(pi1(B0))?
s(pii(B0))]pi(?0)w(B0)[s(pi1(B0))?
s(pii(B0))]pi(?0)Figure 3: Specialized feature templates for tagging.
Weuse ?i and Bi to denote the ith token in the stack ?
andbufferB, respectively, with indexing starting at 0, and weuse the following functors to extract properties of a token:pii() = ith best tag; s(pii()) = score of ith best tag; pi() =finally predicted tag; w() = word form; pi() = word prefixof i characters; si() = word suffix of i characters.
Scoredifferences are binned in discrete steps of 0.05.The bulk of features used in our system are tak-en from Zhang and Nivre (2011), although with t-wo important differences.
First of all, like Hatori etal.
(2011), we have omitted all features that presup-pose an arc-eager parsing order, since our transitionsystem defines an arc-standard order.
Secondly, anyfeature that refers to the part-of-speech tag of a wordw in the buffer B will in our system refer to the top-scoring tag pi1(w), rather than the finally predictedtag.
By contrast, for a word in the stack ?, part-of-speech features refer to the tag pi(w) chosen whenshifting w onto the stack (which may or may not bethe same as pi1(w)).In addition to the standard features for transition-based dependency parsing, we have added featuresspecifically to improve the tagging step in the jointmodel.
The templates for these features, which arespecified in Figure 3, all involve the ith best tag as-signed to the first word of the buffer B (the nextword to be shifted in a SHIFTp transition) in combi-nation with neighboring words, word prefixes, wordsuffixes, score differences and tag rank.Finally, in some experiments, we make use of twoadditional feature sets, which we call graph features(G) and cluster features (C), respectively.
Graph fea-tures are defined over the factors of a graph-baseddependency parser, which was shown to improve theaccuracy of a transition-based parser by Zhang andClark (2008).
However, while their features werelimited to certain first- and second-order factors, weuse features over second- and third-order factors asfound in the parsers of Bohnet and Kuhn (2012).These features are scored as soon as the factors arecompleted, using a technique that is similar to whatHatori et al(2011) call delayed features, althoughthey use it for part-of-speech tags in the lookaheadwhile we use it for subgraphs of the dependency tree.Cluster features, finally, are features over word clus-ters, as first used by Koo et al(2008), which replacepart-of-speech tag features.2We use a hash kernel to map features to weights.It has been observed that most of the computing timein feature-rich parsers is spent retrieving the indexof each feature in the weight vector (Bohnet, 2010).This is usually done via a hash table, but significan-t speedups can be achieved by using a hash kernel,which simply replaces table lookup by a hash func-tion (Bloom, 1970; Shi et al 2009; Bohnet, 2010).The price to pay for these speedups is that there maybe collisions, so that different features are mapped tothe same index, but this is often compensated by thefact that the lower time and memory requirements ofthe hash kernel enables the use of negative features,that is, features that are never seen in the training setbut occur in erroneous hypotheses at training timeand can therefore be helpful also at inference time.As a result, the hash kernel often improves accuracyas well as efficiency compared to traditional tech-niques that only make use of features that occur ingold standard parses (Bohnet, 2010).3 ExperimentsWe have evaluated the model for joint tagging anddependency parsing on four typologically diverselanguages: Chinese, Czech, English, and German.3.1 SetupMost of the experiments use the CoNLL 2009 da-ta sets with the training, development and test s-plit used in the Shared Task (Hajic?
et al 2009),but for better comparison with previous work wealso report results for the standard benchmark datasets for Chinese and English.
For Chinese, this isthe Penn Chinese Treebank 5.1 (CTB5), converted2For replicability, a complete description of all features canbe found at http://stp.lingfil.uu.se/?nivre/exp/emnlp12.html.1459Parser Chinese Czech English Germank ?
TLAS LAS UAS POS TLAS LAS UAS POS TLAS LAS UAS POS TLAS LAS UAS POS1 0.0 73.85 76.12 80.01 92.78 82.36 82.65 88.03 93.26 85.82 87.17 90.41 97.32 85.08 86.60 89.17 97.242 0.1 74.39 76.52 80.41 93.37 82.74 83.01 88.34 99.39 86.43 87.79 91.02 97.49 86.12 87.22 89.69 97.853 0.1 74.47 76.63 80.50 93.38 82.76 82.97 88.33 99.40 86.40 87.78 90.99 97.43 86.03 87.27 89.60 97.743 0.2 74.35 76.48 80.38 93.43 82.85 83.11 88.44 99.32 86.35 87.79 91.01 97.52 86.24 87.37 89.72 97.903 0.3 74.18 76.33 80.28 93.48 82.78 83.05 88.38 99.33 85.94 87.57 90.87 96.97 86.35 87.46 89.86 97.903 0.4 86.14 87.23 89.66 97.79Table 1: Accuracy scores for the CoNLL 2009 shared task development sets as a function of the number of tags k andthe score threshold ?.
Beam parameters fixed at b1 = 40, b2 = 4.with the head-finding rules and conversion tools ofZhang and Clark (2008), and with the same split asin Zhang and Clark (2008) and Li et al(2011).3 ForEnglish, this is the WSJ section of the Penn Tree-bank, converted with the head-finding rules of Ya-mada and Matsumoto (2003) and the labeling rulesof Nivre (2006).4In order to assign k-best part-of-speech tags andscores to words in the training set, we used a per-ceptron tagger with 10-fold jack-knifing.
The sametype of tagger was trained on the entire training setin order to supply tags for the development and testsets.
The feature set of the tagger was optimizedfor English and German and provides state-of-the-art accuracy for these two languages.
The 1-besttagging accuracy for section 23 of the Penn Tree-bank is 97.28, which is on a par with Toutanova etal.
(2003).
For German, we obtain a tagging accura-cy of 97.24, which is close to the 97.39 achieved bythe RF-Tagger (Schmid and Laws, 2008), which toour knowledge is the best tagger for German.5 Theresults are not directly comparable to the RF-Taggeras it was evaluated on a different part of the TigerTreebank and trained on a larger part of the Tree-bank.
We could not use the larger training set asit contains the test set of the CoNLL 2009 data thatwe use to evaluate the joint model.
For Czech, the 1-best tagging accuracy is 99.11 and for Chinese 92.65on the CoNLL 2009 test set.We trained parsers with 25 iterations and report3Training: 001?815, 1001?1136.
Development: 886?931,1148?1151.
Test: 816?885, 1137?1147.4Training: 02-21.
Development: 24.
Test: 23.5The RF-Tagger can take advantage of an additional lexiconand then reaches 97.97.
The lexicon supplies entries for addi-tional words that are not found in the training corpus and addi-tional tags for words that do occur in the training data (Schmidand Laws, 2008).results for the model obtained after the last iteration.For cluster features, available only for English andGerman, we used standard Brown clusters based onthe English and German Gigaword Corpus.
We re-stricted the vocabulary to words that occur at least10 times, used 800 clusters, and took cluster prefix-es of length 6 to define features.We report the following evaluation metrics: part-of-speech accuracy (POS), unlabeled attachment s-core (UAS), labeled attachment score (LAS), andtagged labeled attachment score (TLAS).
TLAS isa new metric defined as the percentage of words thatare assigned the correct part-of-speech tag, the cor-rect head and the correct dependency label.
In linewith previous work, punctuation is included in theevaluation for the CoNLL data sets but excluded forthe two benchmark data sets.3.2 ResultsTable 1 presents results on the development sets ofthe CoNLL 2009 shared task with varying valuesof the two tag parameters k (number of candidates)and ?
(maximum score difference to 1-best tag) andbeam parameters fixed at b1 = 40 and b2 = 4.
Weuse the combined TLAS score on the developmentset to select the optimal settings for each language.For Chinese, we obtain the best result with 3 tagsand a threshold of 0.1.6 Compared to the baseline,we observe a POS improvement of 0.60 and a LASimprovement of 0.51.
For Czech, we get the best T-LAS with k = 3 and ?
= 0.2, where POS improvesby 0.06 and LAS by 0.46.
For English, the best set-ting is k = 2 and ?
= 0.1 with a POS improvement of0.17 and a LAS improvement of 0.62.
For German,finally, we see the greatest improvement with k = 36While tagging accuracy (POS) increases with larger valuesof ?, TLAS decreases because of a drop in LAS.1460Parser Chinese Czech English GermanTLAS LAS UAS POS TLAS LAS UAS POS TLAS LAS UAS POS TLAS LAS UAS POSGesmundo et al(2009) 76.11 92.37 80.38 99.33 88.79 97.48 87.28 95.46Bohnet (2010) 76.99 92.37 80.96 99.33 90.33 97.48 88.06 95.46Baseline (k = 1), b1 = 40 73.66 76.55 80.77 92.65 82.07 82.44 87.83 99.11 87.89 89.19 91.74 97.57 86.11 87.78 90.13 97.24Best dev setting, b1 = 40 74.72 77.00 81.18 93.06 82.56 82.70 88.07 99.32 88.26 89.54 92.06 97.77 86.91 88.23 90.43 97.63Adding G, b1 = 80 75.84 78.51 82.52 93.19 83.38 83.73 88.82 99.33 88.92 90.20 92.60 97.77 87.86 89.05 91.16 97.78Adding G+C, b1 = 80 89.22 90.60 92.87 97.84 88.31 89.38 91.37 98.05Table 2: Accuracy scores for the CoNLL 2009 shared task test sets.
Rows 1?2: Top performing systems in the sharedCoNLL Shared Task 2009; Gesmundo et al(2009) was placed first in the shared task; for Bohnet (2010), we includethe updated scores later reported due to some improvements of the parser.
Rows 3?4: Baseline (k = 1) and best settingsfor k and ?
on development set.
Rows 5?6: Wider beam (b1 = 80) and added graph features (G) and cluster features(C).
Second beam parameter b2 fixed at 4 in all cases.and ?
= 0.3, where POS improves by 0.66 and LASby 0.86.Table 2 shows the results on the CoNLL 2009 testsets.
For all languages except English, we obtainstate-of-the-art results already with b1 = 40 (row 4),and for all languages both tagging and parsing ac-curacy improve compared to the baseline (row 3).The improvement in TLAS is statistically significantwith p < 0.01 for all languages (paired t-test).
Row5 shows the scores with a beam of 80 and the addi-tional graph features.
Here the LAS scores for Chi-nese, Czech and German are higher than the best re-sults on the CoNLL 2009 data sets, and the scorefor English is highly competitive.
For Chinese, weachieve 78.51 LAS, which is 1.5 percentage pointshigher than the reference score, while the POS s-core is 0.54 higher than our baseline.
For Czech, weget 83.73 LAS, which is by far the highest score re-ported for this data set, together with state-of-the-artPOS accuracy.
For German, we obtain 89.05 LASand 97.78 POS, which in both cases is substantiallybetter than in the CoNLL shared task.
We believeit is also the highest POS accuracy ever reported fora tagger/parser trained only on the Tiger Treebank.Row 6, finally, presents results with added clusterfeatures for English and German, which results inadditional improvements in all metrics.Table 3 gives the results for the Penn Treebankconverted with the head-finding rules of Yamada andMatsumoto (2003) and the labeling rules of Nivre(2006).
We use k = 3 and ?
= 0.4, which gave thebest results on the development set.
The UAS im-proves by 0.24 when we do joint tagging and pars-ing.
The POS accuracy improves slightly by 0.12Parser TLAS UAS LAS POSMcDonald et al(2005) 90.9McDonald and Pereira (2006) 91.5Zhang and Clark (2008) 92.1Huang and Sagae (2010) 92.1Koo and Collins (2010) 93.04Zhang and Nivre (2011) 92.9Martins et al(2010) 93.26Koo et al(2008) ?
93.16Carreras et al(2008) ?
93.5Suzuki et al(2009) ?
93.79Baseline (k = 1), b1 = 40 89.42 92.79 91.71 97.28Best dev setting, b1 = 40 89.75 93.03 91.92 97.40Adding G, b1 = 40 90.12 93.38 92.44 97.33Adding G+C, b1 = 80 ?
90.41 93.67 92.68 97.42Table 3: Accuracy scores for WSJ-PTB converted withhead rules of Yamada and Matsumoto (2003) and labelingrules of Nivre (2006).
Best dev setting: k = 3, ?
= 0.4.Results marked with ?
use additional information sourcesand are not directly comparable to the others.but to a lower degree than for the English CoNL-L data where we observed an improvement of 0.20.Nonetheless, the improvement in the joint TLAS s-core is statistically significant at p < 0.01 (pairedt-test).
Our joint tagger and dependency parser withgraph features gives very competitive unlabeled de-pendency scores for English with 93.38 UAS.
Tothe best of our knowledge, this is the highest scorereported for a (transition-based) dependency parserthat does not use additional information sources.
Byadding cluster features and widening the beam tob1 = 80, we achieve 93.67 UAS.
We also obtaina POS accuracy of 97.42, which is on a par with thebest results obtained using semi-supervised taggers1461Parser TLAS UAS LAS POSMSTParser1 75.56 93.51MSTParser2 77.73 93.51Li et al(2011) 3rd-order 80.60 92.80Li et al(2011) 2nd-order 80.55 93.08Hatori et al(2011) HS 79.60 94.01Hatori et al(2011) ZN 81.20 93.94Baseline (k = 1), b1 = 40 61.95 80.33 76.79 92.81Best dev setting, b1 = 40 62.54 80.59 77.06 93.11Adding G, b1 = 80 63.20 81.42 77.91 93.24Table 4: Accuracy scores for Penn Chinese Treebankconverted with the head rules of Zhang and Clark (2008).Best dev setting: k = 3, ?
= 0.1.
MSTParser results fromLi et al(2011).
UAS scores from Li et al(2011) and Ha-tori et al(2011) recalculated from the separate accuracyscores for root words and non-root words reported in theoriginal papers.
(S?gaard, 2011).Table 4 shows the results for the Chinese PennTreebank CTB 5.1 together with related work.
In ex-periments with the development set, we could con-firm the results from the Chinese CoNLL data setand obtained the best results with the same settings(k = 3, ?
= 0.1).
With b1 = 40, UAS improves by0.25 and POS by 0.30, and the TLAS improvementis again highly significant (p < 0.01, paired t-test).We get the highest UAS, 81.42, with a beam of 80and added graph features, in which case POS accu-racy increases from 92.81 to 93.24.
Since our taggerwas not optimized for Chinese, we have lower base-line results for the tagger than both Li et al(2011)and Hatori et al(2011) but still manage to achievethe highest reported UAS.The speed of the joint tagger and dependencyparser is quite reasonable with about 0.4 secondsper sentence on the WSJ-PTB test set, given that weperform tagging and labeled parsing with a beam of80 while incorporating the features of a third-ordergraph-based model.
Experiments were performedon a computer with an Intel i7-3960X CPU (3.3 GHzand 6 cores).
These performance values are prelim-inary since we are still working on the speed-up ofthe parser.3.3 AnalysisIn order to better understand the benefits of the jointmodel, we performed an error analysis for GermanConfusion Baseline JointFreq F-score Freq F-scoreVVINF?
VVFIN 2891.1297.7VVINF?
VVPP|ADJ*|NN 5 9VVFIN?
VVINF 4394.2598.5VVFIN?
VVPP 20 2VAINF?
VAFIN 10 99.1 1 99.9NE?
NN 18490.712892.4NE?
ADJ*|ADV|FM 24 18NE?
XY 12 21NN?
NE 8597.56798.1NN?
ADJ*|XY|ADV|VV* 39 29PRELS?
ART 1392.9595.4PRELS?
PWS 0 2Table 5: Selected entries from the confusion matrix forparts of speech in German with F-scores for the left-hand-side category.
ADJ* (ADJD or ADJA) = adjective; ADV= adverb; ART = determiner; APPR = preposition; NE= proper noun; NN = common noun; PRELS = relativepronoun; VVFIN = finite verb; VVINF = non-finite verb;VAFIN = finite auxiliary verb; VAINF = non-finite auxil-iary verb; VVPP = participle; XY = not a word.
We use?
* to denote the set of categories with ?
as a prefix.and English, where we compared the baseline andthe joint model with respect to F-scores for individu-al part-of-speech categories and dependency labels.For the part-of-speech categories, we found an im-provement across the board for both languages, withno category having a significant decrease in F-score,but we also found some interesting patterns for cat-egories that improved more than the average.Table 5 shows selected entries from the confu-sion matrix for German, where we see substantialimprovements for finite and non-finite verbs, whichare often morphologically ambiguous but which canbe disambiguated using syntactic context.
We al-so see improved accuracies for common and propernouns, which are both capitalized in standard Ger-man orthography and therefore often mistagged, andfor relative pronouns, which are less often confusedfor determiners in the joint model.Table 6 gives a similar snapshot for English, andwe again see improvements for verb categories thatare often morphologically ambiguous, such as pastparticiples, which can be confused for past tenseverbs, and present tense verbs in third person sin-gular, which can be confused for nouns.
We alsosee some improvement for the singular noun catego-1462Confusion Baseline JointFreq F-score Freq F-scoreVBN?
VBD 4090.51991.5VBN?
JJ|VB|VBP|NN 13 18VBZ?
NN|NNS 1997.81398.3VBZ?
POS|JJ|RB 6 6NN?
VBG|VB|VBN|VBD 7296.85897.2NN?
JJ|JJR 79 69NN?
NN*|RB|IN|DT 58 57RB?
IN 12692.49392.9RB?
JJ*|RP|NN*|RBR|UH 86 89Table 6: Selected entries from the confusion matrix forparts of speech in English with F-scores for the left-hand-side category.
DT = determiner; IN = preposition or sub-ordinating conjunction; JJ = adjective; JJR = compara-tive adjective; NN = singular or mass noun; NNS = pluralnoun; POS = possessive clitic; RB = adverb; RBR = com-parative adverb; RP = particle; UH = interjection; VB =base form verb; VBD = past tense verb; VBG = gerund orpresent participle; VBN = past participle; VBP = presenttense verb, not 3rd person singular; VBZ = present tenseverb, 3rd person singular.
We use ?
* to denote the set ofcategories with ?
as a prefix.ry and for adverbs, which are less often confused forprepositions or subordinating conjunctions thanks tothe syntactic information in the joint model.For dependency labels, it is hard to extract anystriking patterns and it seems that we mainly see animprovement in overall parsing accuracy thanks toless severe tagging errors.
However, it is worth ob-serving that, for both English and German, we seesignificant F-score improvements for the core gram-matical functions subject (91.3?
92.1 for German,95.6 ?
96.1 for English) and object (86.9 ?
87.9for German, 90.2?
91.9 for English).4 Related WorkOur work is most closely related to Lee et al(2011),Li et al(2011) and Hatori et al(2011), who al-l present discriminative models for joint tagging anddependency parsing.
However, all three models onlyperform unlabeled parsing, while our model incor-porates dependency labels into the parsing process.Whereas Lee et al(2011) and Li et al(2011) takea graph-based approach to dependency parsing, Ha-tori et al(2011) use a transition-based model similarto ours but limited to projective dependency trees.Both Li et al(2011) and Hatori et al(2011) onlyevaluate their model on Chinese, and of these onlyHatori et al(2011) report consistent improvementsin both tagging and parsing accuracy.
Like our sys-tem, the parser of Lee et al(2011) can handle non-projective trees and experimental results are present-ed for four languages, but their graph-based modelis relatively simple and the baselines therefore wellbelow the state of the art.
We are thus the first toshow consistent improvements in both tagging and(labeled) parsing accuracy across typologically di-verse languages at the state-of-the-art level.
More-over, the capacity to handle non-projective depen-dencies, which is crucial to attain good performanceon Czech and German, does not seem to hurt per-formance on English and Chinese, where the bench-mark sets contain only projective trees.The use of beam search in transition-based depen-dency parsing in order to mitigate the problem oferror propagation was first proposed by Johanssonand Nugues (2006), although they still used a local-ly trained model.
Globally normalized models werefirst explored by Titov and Henderson (2007), whowere also the first to use a parameterized SHIFT tran-sition like the one found in both Hatori et al(2011)and our own work, although Titov and Henderson(2007) used it to define a generative model by pa-rameterizing the SHIFT transition by an input word.Zhang and Clark (2008) was the first to combinebeam search with a globally normalized discrimi-native model, using structured perceptron learningand the early update strategy of Collins and Roark(2004), and also explored the addition of graph-based features to a transition-based parser.
Thisapproach was further pursued in Zhang and Clark(2011) and was used by Zhang and Nivre (2011) toachieve state-of-the-art results in dependency pars-ing for both Chinese and English through the ad-dition of rich non-local features.
Huang and Sagae(2010) combined structured perceptron learning andbeam search with the use of a graph-structured stackto allow ambiguity packing in the beam, a techniquethat was reused by Hatori et al(2011).Finally, as noted in the introduction, althoughjoint tagging and parsing is rare in dependency pars-ing, most state-of-the-art parsers based on PCFGmodels naturally incorporate part-of-speech taggingand usually achieve better parsing accuracy (albeitnot always tagging accuracy) with a joint model than1463with a pipeline approach (Collins, 1997; Charniak,2000; Charniak and Johnson, 2005; Petrov et al2006).
Models that in addition incorporate mor-phological analysis and segmentation have been ex-plored by Tsarfaty (2006), Cohen and Smith (2007),and Goldberg and Tsarfaty (2008) with special ref-erence to Hebrew parsing.5 ConclusionWe have presented the first system for joint part-of-speech tagging and labeled dependency parsingwith non-projective dependency trees.
Evaluationon four languages shows consistent improvementsin both tagging and parsing accuracy over a pipelinesystem with state-of-the-art results across the board.The error analysis reveals improvements in taggingaccuracy for syntactically central categories, mainlyverbs, with improvement in syntactic accuracy forcore grammatical functions as a result.
In futurework we intend to explore joint models that incorpo-rate not only basic part-of-speech tags but also morefine-grained morphological features.ReferencesGiuseppe Attardi.
2006.
Experiments with a multilan-guage non-projective dependency parser.
In Proceed-ings of CoNLL, pages 166?170.Burton H. Bloom.
1970.
Space/time trade-offs in hashcoding with allowable errors.
Communications of theACM, 13:422?426.Bernd Bohnet and Jonas Kuhn.
2012.
The best ofboth worlds ?
a graph-based completion model fortransition-based parsers.
In Proceedings of EACL,pages 77?87.Bernd Bohnet.
2010.
Top accuracy and fast dependen-cy parsing is not a contradiction.
In Proceedings ofCOLING, pages 89?97.Bernd Bohnet.
2011.
Comparing advanced graph-basedand transition-based dependency parsers.
In Proceed-ings of the International Conference on DependencyLinguistics (Depling), pages 282?289.Xavier Carreras, Michael Collins, and Terry Koo.
2008.Tag, dynamic programming, and the perceptron for ef-ficient, feature-rich parsing.
In Proceedings of CoNL-L, pages 9?16.Xavier Carreras.
2007.
Experiments with a higher-orderprojective dependency parser.
In Proceedings of theCoNLL Shared Task of EMNLP-CoNLL 2007, pages957?961.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and MaxEnt discriminative rerank-ing.
In Proceedings of ACL, pages 173?180.Eugene Charniak.
2000.
A maximum-entropy-inspiredparser.
In Proceedings of NAACL, pages 132?139.Shay B. Cohen and Noah A. Smith.
2007.
Joint morpho-logical and syntactic disambiguation.
In Proceedingsof EMNLP-CoNLL, pages 208?217.Michael Collins and Brian Roark.
2004.
Incrementalparsing with the perceptron algorithm.
In Proceedingsof ACL, pages 112?119.Michael Collins.
1997.
Three generative, lexicalisedmodels for statistical parsing.
In Proceedings of ACL-EACL, pages 16?23.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: Theory and experi-ments with perceptron algorithms.
In Proceedings ofEMNLP, pages 1?8.Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer.
2006.
Online passive-aggressive algorithms.
Journal of Machine LearningResearch, 7:551?585.Andrea Gesmundo, James Henderson, Paola Merlo, andIvan Titov.
2009.
A latent variable model of syn-chronous syntactic-semantic parsing for multiple lan-guages.
In Proceedings of the 2009 CoNLL SharedTask, pages 37?42.Yoav Goldberg and Reut Tsarfaty.
2008.
A single gener-ative model for joint morphological segmentation andsyntactic parsing.
In Proceedings of ACL, pages 371?379.Jan Hajic?, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Anto`nia Mart?
?, L-lu?
?s Ma`rquez, Adam Meyers, Joakim Nivre, SebastianPado?, Jan S?te?pa?nek, Pavel Stran?a?k, Mihai Surdeanu,Nianwen Xue, and Yi Zhang.
2009.
The conll-2009shared task: Syntactic and semantic dependencies inmultiple languages.
In Proceedings of the 2009 CoN-LL Shared Task, pages 1?18.Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, andJun?ichi Tsujii.
2011.
Incremental joint pos taggingand dependency parsing in chinese.
In Proceedings ofIJCNLP, pages 1216?1224.Liang Huang and Kenji Sagae.
2010.
Dynamic program-ming for linear-time incremental parsing.
In Proceed-ings of ACL, pages 1077?1086.Richard Johansson and Pierre Nugues.
2006.
Investigat-ing multilingual dependency parsing.
In Proceedingsof CoNLL, pages 206?210.Terry Koo and Michael Collins.
2010.
Efficient third-order dependency parsers.
In Proceedings of ACL,pages 1?11.1464Terry Koo, Xavier Carreras, and Michael Collins.
2008.Simple semi-supervised dependency parsing.
In Pro-ceedings of ACL, pages 595?603.Terry Koo, Alexander M. Rush, Michael Collins, TommiJaakkola, and David Sontag.
2010.
Dual decomposi-tion for parsing with non-projective head automata.
InProceedings of EMNLP, pages 1288?1298.Sandra Ku?bler, Ryan McDonald, and Joakim Nivre.2009.
Dependency Parsing.
Morgan and Claypool.John Lee, Jason Naradowsky, and David A. Smith.
2011.A discriminative model for joint morphological disam-biguation and dependency parsing.
In Proceedings ofACL, pages 885?894.Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wen-liang Chen, and Haizhou Li.
2011.
Joint models forchinese POS tagging and dependency parsing.
In Pro-ceedings of EMNLP, pages 1180?1191.Andre Martins, Noah Smith, and Eric Xing.
2009.
Con-cise integer linear programming formulations for de-pendency parsing.
In Proceedings of ACL-IJCNLP,pages 342?350.Andre Martins, Noah Smith, Eric Xing, Pedro Aguiar,and Mario Figueiredo.
2010.
Turbo parsers: Depen-dency parsing by approximate variational inference.In Proceedings of EMNLP, pages 34?44.Ryan McDonald and Fernando Pereira.
2006.
On-line learning of approximate dependency parsing al-gorithms.
In Proceedings of EACL, pages 81?88.Ryan McDonald, Koby Crammer, and Fernando Pereira.2005.
Online large-margin training of dependencyparsers.
In Proceedings of ACL, pages 91?98.Joakim Nivre, Johan Hall, and Jens Nilsson.
2004.Memory-based dependency parsing.
In Proceedingsof CoNLL, pages 49?56.Joakim Nivre.
2006.
Inductive Dependency Parsing.Springer.Joakim Nivre.
2007.
Incremental non-projective depen-dency parsing.
In Proceedings of NAACL HLT, pages396?403.Joakim Nivre.
2008.
Algorithms for deterministic incre-mental dependency parsing.
Computational Linguis-tics, 34:513?553.Joakim Nivre.
2009.
Non-projective dependency pars-ing in expected linear time.
In Proceedings of ACL-IJCNLP, pages 351?359.Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In Proceedings of NAACLHLT, pages 404?411.Slav Petrov, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning accurate, compact, and in-terpretable tree annotation.
In Proceedings of COL-ING/ACL, pages 433?440.Sebastian Riedel and James Clarke.
2006.
Incrementalinteger linear programming for non-projective depen-dency parsing.
In Proceedings of EMNLP, pages 129?137.Helmut Schmid and Florian Laws.
2008.
Estimation ofconditional probabilities with decision trees and an ap-plication to fine-grained POS tagging.
In Proceedingsof COLING, pages 777?784.Qinfeng Shi, James Petterson, Gideon Dror, John Lang-ford, Alex Smola, Alex Strehl, and S V N Vish-wanathan.
2009.
Hash Kernels for Structured Data.In Journal of Machine Learning.David Smith and Jason Eisner.
2008.
Dependency pars-ing by belief propagation.
In Proceedings of EMNLP,pages 145?156.Anders S?gaard.
2011.
Semi-supervised condensed n-earest neighbor for part-of-speech tagging.
In Pro-ceedings of ACL, pages 48?52.Jun Suzuki, Hideki Isozaki, Xavier Carreras, and MichaelCollins.
2009.
An empirical study of semi-supervisedstructured conditional models for dependency parsing.In Proceedings of EMNLP, pages 551?560.Ivan Titov and James Henderson.
2007.
A latent variablemodel for generative dependency parsing.
In Proceed-ings of IWPT, pages 144?155.Ivan Titov, James Henderson, Paola Merlo, and GabrieleMusillo.
2009.
Online graph planarization for syn-chronous parsing of semantic and syntactic dependen-cies.
In Proceedings of IJCAI.Kristina Toutanova, Dan Klein, Christopher D. Manning,and Yoram Singer.
2003.
Feature-rich part-of-speechtagging with a cyclic dependency network.
In Pro-ceedings of NAACL, pages 252?259.Reut Tsarfaty.
2006.
Integrated morphological and syn-tactic disambiguation for modern hebrew.
In Pro-ceedings of the COLING/ACL 2006 Student ResearchWorkshop, pages 49?54.Hiroyasu Yamada and Yuji Matsumoto.
2003.
Statisticaldependency analysis with support vector machines.
InProceedings of IWPT, pages 195?206.Yue Zhang and Stephen Clark.
2008.
A tale of twoparsers: Investigating and combining graph-based andtransition-based dependency parsing.
In Proceedingsof EMNLP, pages 562?571.Yue Zhang and Stephen Clark.
2011.
Syntactic process-ing using the generalized perceptron and beam search.Computational Linguistics, 37:105?151.Yue Zhang and Joakim Nivre.
2011.
Transition-basedparsing with rich non-local features.
In Proceedingsof ACL.1465
