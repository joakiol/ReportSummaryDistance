THE STATISTICAL S IGNIF ICANCE OF THE MUC-4 RESULTSNancy Chinchor, Ph.D.Science Applications International Corporation10260 Campus Point Drive, M/S A2-FSan Diego, CA 92121chinchor@esosun.css.gov(619) 458-2614INTRODUCTIONThe MUC-4 scores of recall, precision, and the F-measures are used to measure the performance of the par-ticipating systems.
The differences in the scores between any two systems may be due to chance or may be due to asignificant difference between the two systems.
To rule out the possibility that the difference isdue to chance, statisti-cal hypothesis testing is used.
The method of hypothesis testing used is a computationally-intensive method known asapproximate randomization.
The method and the statistical significance of the results for the two MUC-4 test sets,TST3 and TST4, will be discussed in this paper.In our hypothesis testing, our objective was to determine whether a system is characteristically differentfrom another system.
This was achieved by comparing two systems to see if their actual difference in performancestands out in comparison with the results for random combinations of their scores.
If their actual difference standsout, then we know that this difference could not have arisen by chance.ELEMENTS OF HYPOTHESIS TESTINGA key element in hypothesis testing is obviously the hypothesis.
Statistics can be used to reject a hypothesis.In statistical hypothesis testing, it is important to compose the hypothesis n such a way as to be able to use statisticsto reject it and to thereby be able to conclude that something of interest is true.
The hypothesis formulated to berejected is called the null hypothesis.
In Table 1, some elementary terms are defined, including the null hypothesis.We axe interested in determining whether two systems are significantly different in their performance on aMUC-4 test set.
To conclude that two systems are significantly different, we would formulate null hypotheses of thefollowing form to be tested for each test set:The absolute value of the difference between System X's overall recall (precision, F-measure) scorefor the data extraction task and System Y's overall recall (precision, F-measure) score for the dataextraction task is approximately equal to zero.If this null hypothesis can be rejected, then we cart conclude that the systems are significantly different.Another key element in hypothesis testing found within the null hypothesis i  the test statistic.
A test statisticis a function which can be applied to a set of sample data to produce a single numerical value.
A simple example of atest statistic is recall, which is a function of the number correct, the number partially correct, and the number of pos-sible fills.
The test statistic we used in our hypothesis testing is the absolute value of the difference in recall, preci-sion, or F-measure of systems.
Observations are instances of a set of random variables.
An example of an observationis the four-tuple for a MUC-4 message consisting of the number possible, actual, correct, and partially correct.
Thisfour-tuple plays an important role in our application of the approximate randomization method.30O Null hypothesis  The hypothesis that  a relat ionship of interest  is not present.Examples (informal):1) system X and system Y do not differ in recall2) system X and system Y do not differ in precision3) system X and system Y do not differ in F-measure forequal  weight ing of recall and precision0 Test statist ic A function which can be appl ied to a set of sample data to producea single numer ica l  value.Examples: recall, precision, F-measure, difference in recallO Observat ions Instances of values of  a set o f  random variables.Example: number possible, actual, correct ,partially correctO Signif icance level The prebabiHty that  a test statist ic that  is as extreme or moreext reme than  the actual  value could have ar isen by chance, g iventhe null  hypothesis.The lower  the  significance level, the less probable  it is that  the nullhypothesis  holds.
In our  case, the lower the signif icance level, themore l ikely it is that  the two systems are signif icantly different.Table 1: Definition of TermsThe final key element in hypothesis testing is some means of generating the probability distribution of thetest statistic under the assumption that the null hypothesis true.
Instead of assuming a distribution, such as the Nor-real distribution, we empirically generate the distribution as illustrated in Figure 1.
As shown, the significance l vel isthe area under the distribution curve bounded on the lower end by the actual value of the test statistic.The significancelevel is the probability that a test statistic that is as extreme or more extreme than the actual value could have arisenby chance, given the null hypothesis.
Thus, the lower the significance l vel, the more likely it is that the two systemsare significantly differenLRelativefrequency  Empirical distributioniiM ................actualAbsolute value of they difference In recallFigure 1: Histogram of the Absolute Value of the Difference in Recall Scores31RANDOMIZATION TESTINGTraditional statistical analysis requires knowledge of or an assumption about he distribution of the data inthe sample.
We do not know the distribution for our sample ~d prefer to not make an assumption about it.
Computa-tionally-intensive methods empirically generate the distribution.
Exact randomization testing enerates all of the log-ically possible outcomes and compares the actual outcome to these.
This amount of generation is often impracticalbecause of the large number of data points involved, so approximate randomization is used instead.
A confidencelevel is calculated to indicate how close the approximate randomization is to the exact randomization.The method of approximate randomization i volves random shuffling of the data to generate the dislribu-tion.
We used the approximate randomization method escribed by Noreen in \[1\] with stratified shuffling to controlfor categorical variables that are not of primary interest in the hypothesis test.The first step in approximate randomization is to select a test statistic.
Our formulation of the null hypothesisindicates that the test statistic is the absolute value of the difference in recall, precision, or F-measure.
The next step isto input the data.
The data for each test set consists of the four-tuples of number possible, actual, correct, and partiallycorrect for each message for each system.
The actual statistic: is calculated for the pair of systems as they come underscrutiny.
The desired number of shuffles is set to 9,999 because it takes about eight hours to run the test for each testset and the confidence l vels can be easily looked up in a table given in \[1\].
We have arbitrarily chosen the cutoff con-fidence level to be a conservative 99%.
In a test of how the confidence l vels were affected by the number of shuff?es,9,999 shuffles produced slightly higher confidence l vels than 999 and were worth the 16-fold increase in computingtime.
Once the desired number of shuffles is set, the counters for the number of shuffles, ns, and the number of timesthe pseudostatistic is greater than or equal to the actual statistic, nge, are set to 0.
A loop then increments ns until ithas exceeded 9,999, the desired number of shuffles.
The first step in this loop is to shuffle the data, which is the firstmajor operation that occurs during approximate randomization.
Table 2 contains an outline of the major operationsinvolved in approximate randomization.
Figure 2 illustrates the stratified shuffling used for the analysis of the MUC-4 results.iAPPROXIMATE RANDOMIZATION1.
Shuffle ns t imes (ns is 9,999 in our  case).2.
Count the number  of  t imes (number  greater  than  or equal, nge) thatIstat....~.- atat...,,~..I ~ latatA- mt.
I(stat can be recall, precision, or F.measure in our  case).3.
The est imate of the signif icance level is (nge + 1) / (ns + 1)(the l 's  are  added to ensure the test  is valid).4.
The confidence level is found by calculat ion or  table lookup.Table 2: Operations in Approximate Randomization32SHUFFL INGSYSTEM A \](pos.zA aCt zA corlA parle(pOSlooA aCllooA cor.zooA parloo~rec A preA F-meas AI SYSTEM B I(posiB actiB COrZB pariB)(pOS.zooB act.zooB cOr.ZOOB par.zOOB)re% pres F-measBCoin FHp (100 t imes), heads  tai ls , PSEUDO SYSTEMA I ~ PSEUDO SYSTEMB I(pOSnx 7nx COrnx Pa ~ ~pOSny aCtny COrnyreCpseudoA prepseudoA F'meaSPseudoA reCpseudoB prepseudoB F'meaSpseudoBFigure 2: Shuffling for MUC-433In Figure 2, data is shuffled by exchange of the systems' message scores depending on the outcome of acomputer-simulated coin flip.
After 100 coin flips, one per naessage, the absolute value of the difference in the metricsof the resulting pseudosystems can be compared to the corresponding absolute value of the difference in the metricsof the actual systems.
The inequality for the comparison is shown in operation 2 of Table 2.
The value ofnge is incre-mented every time a randomized pair of pseudosystems salLisfies this inequality.
The significance l vel is calculatedaccording to the formula in operation 3of Table 2.
The corresponding confidence l vel is then found in the appropri-ate table in \[1 \].According to Noreen,Randomization is used to test the generic null hypothesis that one variable (or group ofvariables) is unrelated to another variable (or group of variables).
Significance isassessedby shuffling one variable (or set of variables) relative to another variable (or set of vari-ables).
Shuffling ensures that there is in fact no relationship between the variables.
If thevariables are related, then the value of the test statistic for the original unshuffled atashould be unusual relative to the values of the test statistic that are obtained after shuf-fling.
1In our case, the four-tuple of data associated with each message for each system is the dependent set of vari-ables that is shuffled.
The explanatory variable is the system.
Shuffling ensures that there is no relationship betweenthe differences in the scores and the systems that produced them, i.e., that he differences were achieved by chance.
Ifthey were not achieved by chance, then the value of the actual test statistic will be far enough out on the tail of theempirically-generated distribution to be significant.
The area under the distribution curve with the lower bound of theactual test statistic will be smaller than the cutoff in this case.
We have arbitrarily chosen the cutoff to be 0.1 becausewe are able to distinguish reasonable groupings of systems at this level.
At lower cutoffs, too many systems are notsignificantly different.
The choice of a cutoff has traditionally been based on the practical impfications of the choice.We need more data before we will know more of the implications of the cutoff given the sample sizes that we nowhave.The stratified shuffling that was limited to exchange at the message level was the most conservativeapproach to shuffling because it eliminated the effect of the varying number of slots filled per message in the key.
Wedid not want to introduce the effect of this nuisance variable.
Instead, we wanted the simplest, most straightforwardmethod to be used for the initial introduction of approximate randomization i  this application.
Further experimenta-tion with the parameters of stratification, the cutoff for significance level, and the cutoff for confidence level mayoccur in the future.ExamplesThese examples were obtained from \[3\] and are meant o give an intuitive sense of the results of the approx-imate randomization method.
In general, ff two systems hawe.
a large recall difference, they are likely to produce morehomogeneous p eudo systems; nge will be small and the significance l vel will be low.
On the other hand, if two sys-tems have similar ecall scores, they are likely to produce a high nge and a larger significance l vel, giving a lowerlikefihood that the differences are significant.A pair of messages that show consistent differences across a range of messages will be more likely to be sta-tistically significantly different in their score than two systems which have a small number of differences appearing injust a few messages.
Consider the following systems reporting precision results for a set of 100 messages.
System Ahas a score of 15/20 on each of 50 relevant messages and no spurious templates, for a total of 750/1000 = 75% preci-sion.
System B has the identical score on each of the relevant messages except for one, where its score is 0/20.
Sys-tem B has a precision of 735/1000 - 73.5%.
In the random shuffle, one of the pseudo systems will have the "0precision" template.
The pseudostafistic will always be the same as the measured absolute difference between the sys-tems, i.e., 1.5%, so the significance l vel is 1.0 and the difference is not statistically significant.1.
From page 9 of \[1\].34Let us suppose that there is a System C with a precision score of 18/20 on each of 50 relevant messages andwith no spurious templates.
Any random shuffle of Systems A and C is likely to produce asmaller difference than theabsolute value of the difference between A and C. The significance l vel will be extremely close to zero, indicatingwith virtual certainty that the two systems are significantly different.WHAT WE CANNOT CONCLUDE FROM APPROXIMATE RANDOMIZAT IONIt is the systems themselves that set the conditions for the shultle in the pairwise comparison.
The same dif-ference in scores between pairs of systems may not equate to the same significance l vel when different systems areinvolved in the pairwise comparison.
The statistical test measures the difference from what would have occtm'ed ran-domly.
Each pair of systems provides adifferent set of conditions for the stratified shuffle.
Thus, we cannot concludefrom the results of the approximate randomization tests that the evaluation scores are generally significant within acertain range of percentage points.
This cautionary note has further consequences which are discussed below in theresults for TST3.We also cannot conclude from the approximate randomization test whether our sample is sufficiently repre-sentative of newswire reports on activities concerning Latin America.
In addition, we do not know whether the size ofthe sample is large enough for all of our purposes.
The test sets were carefully collected in such a way as to reducebias by selecting the number of articles concerning certain countries based on the percentage of articles about hosecountries in the entire corpus for the associated time period.
In addition, the test articles were selected based solely onthe order in which they appeared in the larger corpus and not on their contents.
The size of the test sets was deter-mined by the practical limits of time allotted for composing answer keys, running the participating systems on the testsets, and scoring the results.
Even with these precautions, however, we still do not know whether the random sampleof test messages i  representative of the population from which they were drawn.
Our statistical testing is not aimed atanswering this question.WHAT WE CAN CONCLUDE FROM APPROXIMATE RANDOMIZAT IONTST3The results 'for TST3 of MUC-4 are presented in this section.
TST3 is the official test set for MUC-4.
Thesystems otticially report scores for recall, precision, and the F-measures for three weightings of recall and precisionbased on the ALL TEMPLATES row in the summary score report.
2 Approximate randomization was applied to eachpair of participating systems.
The approximate randomization method applied to the TST3 results randomly shufflesthe message-by-message cores for the two systems being compared and checks to see how many times the test statis-tic is as extreme as or more extreme than the actual test statistic.
The lower the number of times the pseudo test staffs-tic is greater than or equal to the actual test statistic, the lower the significance l vel and the more likely the actual teststatistic did not occur by chance.The results of this computer-intensive testing are reported in two formats.
The first format shows the signifi-cance levels for the pairwise comparison for each of the scores reported (Figures 3 - 6).
The second and more infor-mative format shows the significance groups or clusters based on the cutoffs at 0.I for significance l vel and 0.99 forconfidence l vel (Figures 7 - 11).
The significance groupings represent groups of systems which were not consideredto be significantly different from each other according to these cutoff criteria.
Please note that the F-measures are cal-culated using floating point arithmetic throughout and differ slightly from the F-measures in the official score reports,which were calculated based on the integer values of recall and precision.
These more accurate F-measures depictedin Figures 9 - 11 appear in tabular format in Appendix G.2.
For further information on the score report, see the paper "MUC-4 Evaluation Metrics" in these proceed-ings.35iii;ii~i~i~i I .
.
.
.
.
.
.
.
.
ooo o ~:i:: ii:i:i:::i:! "
" " " " ' "  I. .
.
.
.
.
.
.
.
.
.
.
.!ii!
:li~ili * ?
* * .
.
.
.
* * * " ?
* .
.
.
.
c~ 'ii::i.~ii::i: 1 I ~?
:~ ............ii;~ii .
.
.
.
.
.
.
.
.
.
.
.
~ .
.
.
.
c -  - -  o:o:o:-- - o- g_::::;:::::::::::: i " " " " " " "  ' '~iii~\]i::i::i::i::iii I .......... - - i ,~ ~.!
- - -, .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
,'iiii oo -o  oo  i?~:m:~:~: .
?
: ~ ?
o ,~ ~ o o ?
?
?
?
?
?
, ?
.
?
?.....
a~,~,~ii',',iili~,i'~""':" .':.
?
.
.
.
.
.
.
?
?
? "
?
.
.
.
.
?
?
? "
....... ~'i :?~o??
.
.
.
.
.
.
.
.
.
o ~ o ~ o~ o?~ o ~ o ~ o g o ~ o ~_ o . "
o~ o ~ " -~i~ .
.
.
.
.
i " ? "
" " ?
.
.
.
.
~ _o i  ~?i: .
:\[:: 0 0:!
.
.
.
.
~ .
.
.
.
I .
.
.
.
.
c~ I .
.
.
.
.
.
i::::ii::::i::::::ii::iiiii !
o o.......< ;;;:  .
.
.
.
.
.
.
.
.
.~',~',;',~i~i~i~ .
.
.
.
.
.
.
.
.
.
.
.
.. .
.
.
.
.
.
i" ' ' " " " "  ?
?
?
.
.
.
?
?
?
?
~ r O  O 0  O,q"  OC,  I O 0  ~ D  u ' ) ,~r  0 0ii!iii!i~ii!iiiii  .
.
.
.
.
.
?
?
?
- ."
."
."
."
."
."
."
."
."
I *~00 0?
'~10 ?~ 0000 ~ro   u') O0  0 0 0 0 0  ~ 0 tD .
0000!iii|iiiii:!:ilJ,l~!:!:!
,,i,i~i,li .
.
ooo ooo o ooo o ooo o oO __  ~!
I oo  o o  o o  o o  o ~.-~.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
~;  ~ ~o o~ ~ ~ o~o; Io;o~ o~o ~ ~ oOO~ ~ ~ ...... " ' ' '  .
?
, , .
.
?
* * !:!:!:!:!:!:~:!
:~:i ~ = mO 0  ~ 0  O0 O0 O0 ~U~ O 0 0 ~  O0 O0: : : : : : : : :  ::::::::::::::::::: ~\[~ ~.
::::::::::::::::: ??;?
:;: : :i oo  o?  "
' i  .
.
.
.
.
.
.
.
.
.
.
?
!?
.:.:.;-;-;.
:-;-: Ii:i~i~i::i:~i .
.
.
.
.
iiii!iiiiiiiiiiiiiiii ~ ' ?
~ o o o ~.
~ ~ o ~-  .
o .
,  o o o o , -  o o .
o o~ !!iiiiiiiiii!ii!i!!ii!
!iiii ~ o o o o o o o ~ o o ~ ~ o , ,  o o o o ~ o o o o o .
Oe~ 0 0 i 0 0  0 0  O0 O0 ~ '0  'q l 'O  0 0  04e~ O0 0 0  0?~i:i:i:~:!
:i::~ii~:i::i~ ~?-9 o o  o o  o o  o o  - -  ~o  o o  o o  ~ o  o o  ~,~ ~o o o~i:!
~,~i:i:i~ - - i 0 0 0 0 0 0 0 0 0 0 ~ 0 0 0 0 0 ~ O) 0 0 ~ ~ 0 0 0 0!
!i~ii~ii~!ii ......... oo  oo  c~d do  oo  oo  o?~ ?~d od  do  ?~c~ oo  do  do" rrr .
.
.
.
.
.iiiiiiiiiiiiiill o o o o ~ - o o o ~ o~ ~ o o0 0  O 0  ?
'~ O 0  0 ~ii~ : o -  o o  o ~oo eo  o o oo  o o ~ ~ o ?
?o o ?o  ?ii!iiii,i~iiiiiiiiii o?
: : :  :o  ?.
: :  o?
: : :  : :  o?o ?.
: :  : :  o?
: ooo ?
oO~ : :  :o  ?................- .
.-........ .-......... .
.
.
.
.
.
.
.
.
.
:::::::::.
:~i~::::: !
: :-?'
.~:~: : :::liT:::,~!- "!!:::::,:~!i0.
ot=?~\[,,T.,36i:i:i:i:!:!:!
: i :::::::::::::::::iiiiiii~ I .................,~,~,~, .
- : " iiiiiiiiiiiiiiiiiiiiiii~i " ~ ' ................ ?
: :!:!:!:!
:~:~:~:~:iiiiiii~ : ?
?
~* ~ 0 00 0 0 0 0 :0 0 0 0" iiiiiiiiiiiiiiiii ~ ~ o o ~ ~ o?
iiiiiiiiii!ii!i!i o o o o o o o o~|  o o o ~i  0 00 0 0 o 0 0 0 0o o o o o giiiiiiii ~O:  0 00 0 0 "~ 0 0 O~ 0 0iii~ :ii!iiiiii!il ~ o .
o--o o-0 0 0 0 0 0 O!
0 i 0 03?I+++I I I I I I I I I I I I I I I I  ............. +: .
.
.
.
: : : : : : +++++++++++++++ +++:  : : : ' ' 2 "  ""  ++++++++++++++++I++I l+l+i+ I  i+ I+ i+l ?
I+I l t+l+l++ IB/iHBHBHBI BBiB/HWHHnHHiHBI IBHBmHHHHiiHHBHB/I HH|HHHHRHHHHHHBHliHUHHHHIBRBBHHHBHIHHHHHWHHBHIHIBIHHHHHHHIHHHHHHHUHHHHHHHUHHHHHHH/HHHHHHHHEHBBBHHUHHHHHHHHHBHHHB/HHHHHHHHHH|HHBIUHHHHHHHHHHHUHHHIHHHHHHHHHHHHHUHIIHHHHHHHHHHHHHH|HmHHHHHHHHHHHHHHHUIHHHHHHHHHHHHHHHH"SC~38o ~.
.V V2 W ~~o~40 '1~C ~~.C  ~._~iUHHHHHHHHHHHHHH| | RH IN  HH n n Ht=0"S"S3910oRecal l9080706050403020100? i i i i i 1 i i i i I I f I1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17SystemFigure 7: Significance Groupings for Recall at the 0.10 Level with 0.99 Confidence for TST3100-Prec is ion90O0706050403020100Q-s I e i s | i0 1 2 3 ' ; 15 ; 8 ; 10 11 12 13 1; 15 16 1;SystemFigure 8: Significance Groupings for Precision at the 0.10 Level with 0.99 Confidence for TST340F-Equal100go80706050403020100?1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17SystemFigure 9: Significance Groupings for F-Measures (P&R) at the 0.10 Level with 0.99 Confidence for TST3lOOF-PTwicego8070605040302010 Ji , i i i i , | .
| i | w e !
!
|0 1 2 3 4 5 6 77 8 9 10  11 12  13  14  15  16  17SystemFigure 10: Significance Groupings for F-Measures (2P&R) at the 0.10 Level with 0.99 Confidence for TST341F.PHalf100gOSO70SO50403020100??0!
i | i !
i | i ?
| i ?
i ?
i ?
i0 1 2 3 4 5 6 7 $ 9 10 11 12 13 14 15 16 17SystemFigure 11: Significance Groupings for F-Measures (P&2R) at the 0.10 Level with 0.99 Confidence for TST3Although most of the information in the figures is self-explanatory, there are a few items of interest to bepointed out.
The first concerns the kinds of point spreads that occur within and between significance groupings.
Forexample, in Figure 7, the UMBC-Conquest team has a recall score of 2.5, which differs from the next higher ecallscore of 6.6 for USC by 4.1 percentage points.
Whereas, the first large group of four systems, MDC (20.4), NMSU-Brandeis (21.9), LSI (23.0), and SRA (26.9), has a spread of 6.5 percentage points.
This difference between what sep-arates two significantly different systems and what separates systems which are not significantly different illustratesthe cautionary note that this method is unable to determine that the evaluation scores are generally significant withina certain range of percentage points.Another anomaly in the results is in the precision scores.
In Figure 8, the UMBC- Conquest team has a pre-cision score of 20.8.
This score is not significantly different ~)m seven other sites, although those seven sites divideinto significance groupings of their own.
The reason for this is the low number of actuals generated by the system.Figure 9 illustrates two more examples of how the conditions et up by the systems influence the outcome ofthe statistical significance testing more than the actual test statistics themselves.
The first example involves MDC,Paramax, and SRA and the second involves GE, GE-CMU, and UMass.For the first example, the F-measures are as follows: lVIDC 24.33, Paramax 29.03, and SRA 29.33.
Paramaxand SRA are not significantly different at the 0.1 level with at least a confidence of 0.99; MDC and SRA are not, butMDC and Paramax are significantly different.
If the cautionary note did not hold, then these results would be anoma-lous, because SRA's F-measure ishigher than Paramax's.
Therefore, we would expect hat MDC and Paramax wouldnot be significantly different because MDC and SRA are not.
However, the F-measures are not the only factors affect-ing the results of the significance testing.
The conditions et up by the systems during the shuffling have more influ-ence than the raw results.
This case illustrates that we cannot conclude from an approximate randomization test thatthe evaluation scores are generally significant within a certain range of percentage points.In the case of GE, GE-CMU, and UMASS, we see a similar illustration of the cautionary note.
The F-mea-42sures are: GE 56.01, GE-CMU 51.98, and UMASS 51.61.
The significance l vels are GE and GE-CMU: 0.0415, GEand UMASS: 0.0994, and GE-CMU and UMASS: 0.8918.
GE and GE-CMU are significantly different at the 0.05level and GE-CMU and UMASS are not significantly different even at the 0.1 level.
The significance l vels show thatGE is significantly different from GE-CMU and UMASS at the 0.1 level.
However, the confidence l vel for the sig-nificance test for GE and UMASS does not meet he 0.99 cutoff because it is only 0.635.
So the pair cannot be consid-ered significantly different by our criteria.
The cautionary note explains why this situation could arise even though wewould expect that he significance l vel would have been higher for GE and GE-CMU than for GE and UMASS.TST4The results for TST4 of MUC-4 are presented in this section.
TST4 is a second test set chosen from an ear-lier time period.
It contains more straightforward messages concerning terrorism with fewer irrelevant messages thanTST3.
The significance r sults are presented in the same formats as those for TST3.
The first format is a matrix show-ing the significance l vels for the pairwise comparison for each of the scores reported (Figures 12 - 15).
The secondand more informative format is a scatterplot showing the significance groups or clusters based on the cutoffs at 0.1 forsignificance l vel and 0.99 for confidence l vel (Figures 16 - 20).
The significance groupings represent groups of sys-tems which were not considered tobe significantly different from each other according to these cutoff criteria.SUMMARYThe results of the statistical analysis of the MUC-4 scores on TST3 and TST4 have been presented with anexplanation of the computationally-intensive method of determining the statistical significance of the differencesbetween systems.
The method of approximate randomization was used to generate the probability distribution of thedifferences between systems.
The statistical significance of the actual results can be ascertained by calculating thesignificance l vel during the generation of the distribution and looking up the confidence l vel in a published table.Knowing the statistical significance of the MUC-4 results allows us to draw valid conclusions concerning the perfor-mance of the participating systems.ACKNOWLEDGEMENTSI would like to thank Christopher Cooper for our discussions concerning the adaptation of approximate ran-domization to the MUC-4 problem and Lynette Hirschman and David Lewis for their help in explicating the statisti-cal method for the computational linguistics community.REFERENCES\[1\] Noreen, E. W. (1989) Computer Intensive Methods for Testing Hypotheses: An Introduction.
New York."
JohnWiley & Sons.\[2\] Efron, B. and R. Tibshirani (1991) "Statistical Data Analysis in the Computer Age" Science, vol.
253, pp.
390- 395.\[3\] Chinchor, N., L. Hirschman, and D. Lewis (1991) "Evaluating Message Understanding Systems: An Analysisof the Third Message Understanding Conference (MUC-3)" submitted to Computational Linguistics.43I:iiiiiii!!iiiiiiil.
.
.
.
.
.
.
.
.
: :  .
: : .
: !
: :  : :  - -  .~:lEi~!~ * I * * * ?liiii~iii .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
:ii i i i i i i i i i i i .
.
.
.
.
.
.
.
.I ~ Q g0: .
:: : : :i!i!i!i::::::::::::::::::::::::::::::::::::::iliiii|iiiiii c .
.
.
.
.
.
.
.
.Iiiiiii~!iiiii ................... * ?
~ ' : "  ? "
?
i ?
"~!~!iiiiiiiiiii~ii\[i!!
!ii~i!iii!., c :  ?
:!
:~:~ ::~: ?
: .
.
.
.
.Q ~ ~ ~ g I Q 0?
?
?
?
?
?
?
?
?
?
i ?
* ?
.
.
.
.
.
.
.
.
.
.
.?
ii!
!iiii!ili!iMil:~:~:~:~:~:~:~:~:~:~I i:!:ii~:iii~i:i:i:!:.
.
: : .
:  : :  : -  ?
~c~?
".
~ '~+:.:.:.:.:.:+:..
.
.
.
.
'iiiiiiii .
.
.
.
.
.
.
.
.
.
.
.
.
o i~  ,~o  oo  .
.
.
o~ ~ ooOooO .
.
.
.
.
.
.
.
.
.I .
.
.
.
.
.
?
i :::::::::::::::::::iiiii ?
?
?
?
* * ~ .
'q rO Or , , , .
?~/o  ~- t~J  o r , , , .
?
?
?
.
.
.
?
?
~ 0  O 0  o o  f.,.,~l;" O ~."
?
?
: ?
~ ~ ~o~?
.
.
o ~oo?
'~oooo oo?
.
iiiiiii!iiii!i!iiil o o ~ o ~ ~ ~ ; ."
~ ~ ~ ~- i ~ ooo.
oO ~.o ~.~ ~.~ Ooo~ " ooO.~.?
.
.~ .
.
.
.~ .
oO.
~o oO.oO.
: .
.
.
.
.
.
!
.
.
OO o o  O 0  O 0~ 0 ~~ o~ ?
o?
~ ~ ~ ?
~ ?
~ ~ o~ ~ ?
~ oOO ?
~ ~ i :  ~"? "
" iiiiiiiiiiiiiiiiili .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
~ " :'::: :::::: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0iiiiiiiii|!iiiiii - o ~ o o_  o o ?
~ _ o o o ~ o ~ o o , .
~?
?
.
0 f~ , .O  O 0  O 0  ~'0  0 .
O 0  O 0  O 0  oar  0 ~ :i:!:!
:~:~:::: ?
?
.
.
?
?
?
.
:::::::::: ~ 0 ~ ~ ~ ~ 0 0 0 0 0 r-.
0 0 0 0 0 0 0 0 0 : 0 0 - -  0::::::~,~.t:::!
:~ .
?
?
?
?
?
?
?
::::::::::::::::::::: .
o : ?~ 'q" ~,o o o 0 0 0 0 0 0 0 0 0 0 o 0 0 o o 0Oo oo  c~o c~o o ~ c ;o  oo  oo  oo  oc~ oc~ oo.
.
.
.
.
o~ o o l o  ?
# ~" ,~  ; ~  .
~ ooo  Oo~ o ~ ~' o?o  o.o.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
!m.~ "ooo  oo  oo  oo  gO oo  !o  .:.:.:.:.:.:.:.:.:.
: 0 0 0 0 0 0 0 0 0 , 0 0" "  ' ' . "
"  " ' ' "  I......... li!i!~!~i~i i ii 0 ~"  ~ '::iii::::~::::~::~:: ? "
o o o ?
o ?
~ o ?
o ?
- '~ ~ o ?
~: o ~ o ?
~ ~ o ?
o ?
~o o  o .
.
.
.
.
.
.
~ .
.
.
.
.
.
.
.
.
.
.
~ .
"1  ?
~ ~ o?o ?- ooo o oo  ?.
~o ?
c?i~ o?.o ?.
~ o?~ oo?.
?I!
!i!iii~ii!~i!ii.i ::::::::::::::::::: i Ii~i~ii~i,.. ,,,,,,,,,,,~,,,,,~, oo  o o o o o o o o o o o ~ ; ~ ; e ; ;  ; e ; ;  ~ ;  oo  oo  oo  oo  oo  oc~ oo  oo  oo  o~ oo  oo~ .
.
.
.
.
.
.
.
.
.
.
::::::::::::::::::::::::::::::::: co o o o o o o o o o o o o o o o o o o o co o o o o ioi!
.
~ .
.
.
.
.
.
.
.
.
= .
; .oo .
-oo  oo??
oo  oo  ooU~JE-?
)44|g i i / l i / / i i i / i i i i |gili|ili/lliii||lilHiiiililili/|WHHBHHHHHHHBHUHHE/lillliliilUHH|mn/oinnnnulugHgHEBBBBHBBHHH|HHHHHHHBBHHBHHH|HHHHHHH|H|HHHHH|HHHHHHHHBHHHHBHIHHHHHHHHHHHHBHH|HHHHHHHHHHHH||H HHHHHHHHHHH|B/HHUHHHHHHHHHHHHHHHHHHHHHHHHHHHNI|HHHDHHHHHHHHHH|H|HHHHHHHHHHHHHEHUHHHHHHHHHHHHHHH(.,,~~3"SML..,45| i i i l i l i l i l i l i i i i |WHHHi/iBBHI/iHi|iU20V V..~ .~  V~o~?
I , l lW 4m ~~ ' ~.
,\[..J~.or4L~{/)r J,E-,46iiiiiiiiij ?
?
?
: .
.
.
.
.
.
.
.
.
:::::::w:: 41 e ?
?
4s ?
?
e e 41 ?
?
41ii~iiiiii~i 41 .is e .
.
.
.
e ?
?
?
?0....... i! "
.
i~i,i~i,,ii,i,i~ ~iiiii~ ?
?
ii!!
iii..............
I ?
?
i i i i i i l l  ~ iiii!iii~ .
.
~ ........ o!
..............
~iiiii!i!!!!~!!
!i iiiiiii!iiiiiiii i i!iiiiiill ~!iiiiiiiiE :::~:~:::~:~ o r,-" j .
:~::::~: o .
jiiiiiiiiiiiiiii!
o o?
~::::::::!
~ 0 0 0 ;?
.:-:-:.:.:.:.
:-:: 0 0 0 0 1iiiiiiiii~ ~ " !
-?
:::;;::: .
~ 0 O 0 iliiii?
!i~ ......... o ........... : ... o o o c~i!i!
iiii!!
!iiiiiiiii o o o o oi ;  ~ ~ ?
?
?
?
.
i~ii i \ [ i i  o o ~ o o o oiiiiiii" ?
?
?
?ii .
.
.
.
.
o N ~ o o o o ~ I. .
.
.
.
.
.
.
~ 0 0 0 0 0 0 0 0 I~,~,~,~,~ .
.
.
.
~ ~ o o o o o o o o:.:::::'..
. "
0 0 0 0 0 0 0 0 ~,1:':':':':':':" ~ ?
?
0 0 ?
:.:.:+:.:.:.
: 0 0 0 0 0 0 0 0 0 0 ~ !!!!!:!
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.?
?
0 ~ ,  0 0 ~f" 0 0 0 ,C~ 00 0 0 0 0 0 ~ ~ 0 0 0 0 0?
* * o c~ o o o o o o o o o o o0 0 0 0 0 0 ~ 0 ~,1 O 0~ i~" i  0 0 0 .
0 0 0 0 ~ 0 0!1 i i~  " i " o o o o o o o o o o o o~ :" ................. ~ o o o o o o o o o o o o oiiiiiiiiiiiiiiiii - o o o o o o o o o o o o o o 0 0 0 0 0 0 0 0 0 0 0 0 0 O":':':':':':': :~:i:~:~:~:~:~:~: 0 0 0 0 0 0 0 0 0 0 0 0 0 00 0 ~ 0 0 0 0 ~0 ~ ~ eO 0 ~ ~ 00 0 0 0 0 0 0 0 ~ 0 ~ ~ 0 ~ ~ 0?
...iiii!!~!~i~!
iii i!iiiiiiiiil o o o o o o o o o o o o o o o oE-c~0~L~~Lrcjr~L~4 '7100Recall9080706050403020100????
?
?
?
?
?
?
?
i ?
?
?
?
?
?
?
J ?0 1 2 $ 4 6 6 77 B 9 10 11 12 13 14 16 16 17SystemFigurel6: Significance Groupings for Recall at the 0,,10 Level with 0.99 Confidence for TST4100Precis ion2080702060403020lOoz oSystemFigure 17: Significance Groupings for Precision at the 0.10 Level with 0.99 Confidence for TST448lOOF-Equal90807060504030201000| w g i i i i i ~ ?
?
i ?
w i w |0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17z oSystemFignrel8: Significance Groupings for F-Measures (P&R) at the 0.10 Level with 0.99 Confidence for TST4lOOF-Ptwice905070605040302010S0 ?
?
0 )0 1 2 3 4 S 6 7 8 9 10 11 12 13 14 15 16 17SystemFigure 19: Significance Groupings for F-Measures (2P&R) at the 0.10 Level with 0.99 Confidence for TST449F-Phal f10090807060SO403020100?
?0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 18 16 17SystemFigure 20: Significance Groupings for F-Measures (P&2R) at the 0.10 Level with 0.99 Confidence for TST450
