Proceedings of CLIAWS3, Third International Cross Lingual Information Access Workshop, pages 30?37,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsDirections for Exploiting Asymmetries in Multilingual WikipediaElena FilatovaComputer and InformationSciences DepartmentFordham UniversityBronx, NY 10458, USAfilatova@cis.fordham.eduAbstractMultilingual Wikipedia has been used exten-sively for a variety Natural Language Pro-cessing (NLP) tasks.
Many Wikipedia entries(people, locations, events, etc.)
have descrip-tions in several languages.
These descriptions,however, are not identical.
On the contrary,descriptions in different languages created forthe same Wikipedia entry can vary greatly interms of description length and informationchoice.
Keeping these peculiarities in mind isnecessary while using multilingual Wikipediaas a corpus for training and testing NLP ap-plications.
In this paper we present prelimi-nary results on quantifying Wikipedia multi-linguality.
Our results support the observationabout the substantial variation in descriptionsof Wikipedia entries created in different lan-guages.
However, we believe that asymme-tries in multilingual Wikipedia do not makeWikipedia an undesirable corpus for NLP ap-plications training.
On the contrary, we out-line research directions that can utilize multi-lingual Wikipedia asymmetries to bridge thecommunication gaps in multilingual societies.1 IntroductionMultilingual parallel corpora such as translations offiction, European parliament proceedings, Canadianparliament proceedings, the Dutch parallel corpusare being used for training machine translation andparaphrase extraction systems.
All of these corporaare parallel corpora.Parallel corpora contain the same informationtranslated from one language (the source languageof the text) into a set of pre-specified languages withthe goal of preserving the information covered inthe source language document.
Translators work-ing with fiction also carefully preserve the stylisticdetails of the original text.Parallel corpora are a valuable resource for train-ing NLP tools.
However, they exist only for a smallnumber of language pairs and usually in a specificcontext (e.g., legal documents, parliamentary notes).Recently NLP community expressed a lot of interestin studying other types of multilingual corpora.The largest multilingual corpus known at the mo-ment is World Wide Web (WWW).
One part of par-ticular interest is the on-line encyclopedia-style site,Wikipedia.1 Most Wikipedia entries (people, loca-tions, events, etc.)
have descriptions in different lan-guages.
However, Wikipedia is not a parallel cor-pus as these descriptions are not translations of aWikipedia article from one language into another.Rather, Wikipedia articles in different languages areindependently created by different users.Wikipedia does not have any filtering on who canwrite and edit Wikipedia articles.
In contrast to pro-fessional encyclopedias (like Encyclopedia Britan-nica), Wikipedia authors and editors are not nec-essarily experts in the field for which they createand edit Wikipedia articles.
The trustworthinessof Wikipedia is questioned by many people (Keen,2007).The multilinguality of Wikipedia makes this situ-ation even more convoluted as the sets of Wikipediacontributors for different languages are not the same.1http://www.wikipedia.org/30Moreover, these sets might not even intersect.
Itis unclear how similar or different descriptions ofa particular Wikipedia entry in different languagesare.
Knowing that there are differences in descrip-tions for the same entry and the ability to identifythese differences is essential for successful commu-nication in multilingual societies.In this paper we present a preliminary study of theasymmetries in a subset of multilingual Wikipedia.We analyze the number of languages in which theWikipedia entry descriptions are created; and thelength variation for the same entry descriptions cre-ated in different languages.
We believe that this in-formation can be helpful for understanding asymme-tries in multilingual Wikipedia.
These asymmetries,in turn, can be used by NLP researchers for trainingsummarization systems, and contradiction detectionsystems.The rest of the paper is structured as follows.
InSection 2 we describe related work, including thework on utilizing parallel corpora.
In Section 3we provide examples of our analysis for severalWikipedia entries.
In Section 4 we describe our cor-pus, and the systematic analysis performed on thiscorpus.
In Section 5 we draw conclusions based onthe collected statistics and outline avenues for ourfuture research.2 Related WorkThere exist several types of multilingual corpora(e.g., parallel, comparable) that are used in the NLPcommunity.
These corpora vary in their nature ac-cording to the tasks for which these corpora werecreated.Corpora developed for multilingual and cross-lingual question-answering (QA), information re-trieval (IR), and information extraction (IE) tasksare typically compilations of documents on relatedsubjects written in different languages.
Documentsin such corpora rarely have counterparts in all thelanguages presented in the corpus (CLEF, 2000;Magnini et al, 2003).Parallel multilingual corpora such as Canadianparliament proceedings (Germann, 2001), Europeanparliament proceedings (Koehn, 2005), the Dutchparallel corpus (Macken et al, 2007), JRC-ACQUISMultilingual Parallel Corpus (Steinberger et al,2006), and so on contain documents that are exacttranslations of the source documents.Understanding the corpus nature allows systemsto utilize different aspects of multilingual corpora.For example, Barzilay et al (2001) use several trans-lations of the French text of Gustave Flaubert?snovel Madame Bovary into English to mine a corpusof English paraphrases.
Thus, they utilize the cre-ativity and language expertise of professional trans-lators who used different wordings to convey notonly the meaning but also the stylistic peculiaritiesof Flaubert?s French text into English.Parallel corpora are a valuable resource for train-ing NLP tools.
However, they exist only for a smallnumber of language pairs and usually in a specificcontext (e.g., legal documents, parliamentary notes).Recently NLP community expressed a lot of inter-est in studying comparable corpora.
Workshops onbuilding and using comparable corpora have becomea part of NLP conferences (LREC, 2008; ACL,2009).
A comparable corpus is defined as a set ofdocuments in one to many languages, that are com-parable in content and form in various degrees anddimensions.Wikipedia entries can have descriptions in severallanguages independently created for each language.Thus, Wikipedia can be considered a comparablecorpus.Wikipedia is used in QA for answer extractionand verification (Ahn et al, 2005; Buscaldi andRosso, 2006; Ko et al, 2007).
In summarization,Wikipedia articles structure is used to learn the fea-tures for summary generation (Baidsy et al, 2008).Several NLP systems utilize the Wikipedia multi-linguality property.
Adafre et al (2006) analyze thepossibility of constructing an English-Dutch parallelcorpus by suggesting two ways of looking for sim-ilar sentences in Wikipedia pages (using matchingtranslations and hyperlinks).
Richman et al (2008)utilize multilingual characteristics of Wikipedia toannotate a large corpus of text with Named Entitytags.
Multilingual Wikipedia has been used to fa-cilitate cross-language IR (Scho?nhofen et al, 2007)and to perform cross-lingual QA (Ferra?ndez et al,2007).One of the first attempts to analyze similaritiesand differences in multilingual Wikipedia is de-scribed in Adar et al (2009) where the main goal31is to use self-supervised learning to align or/and cre-ate new Wikipedia infoboxes across four languages(English, Spanish, French, German).
Wikipediainfoboxes contain a small number of facts aboutWikipedia entries in a semi-structured format.3 Analysis of Multilingual WikipediaEntry ExamplesWikipedia is a resource generated by collaborativeeffort of those who are willing to contribute their ex-pertise and ideas about a wide variety of subjects.Wikipedia entries can have descriptions in one orseveral languages.
Currently, Wikipedia has articlesin more than 200 languages.
Table 1 presents infor-mation about the languages that have the most ar-ticles in Wikipedia: the number of languages, thelanguage name, and the Internet Engineering TaskForce (IETF) standard language tag.2English is the language having the most numberof Wikipedia descriptions, however, this does notmean that all the Wikipedia entries have descriptionsin English.
For example, entries about people, lo-cations, events, etc.
famous or/and important onlywithin a community speaking in a particular lan-guage are not likely to have articles in many lan-guages.
Below, we list a few examples that illustratethis point.
Of course, more work is required to quan-tify the frequency of such entries.?
the Wikipedia entry about Mexican singer andactress Roc?
?o Banquells has only one descrip-tion: in Spanish;?
the Wikipedia entry about a mountain ski re-sort Falakro in northern Greece has descrip-tions in four languages: Bulgarian, English,Greek, Nynorsk (one of the two official Nor-wegian standard languages);?
the Wikipedia entry about Prioksko-TerrasnyNature Biosphere Reserve, a Russia?s small-est nature reserve, has descriptions in two lan-guages: Russian and English;2http://en.wikipedia.org/wiki/List_of_WikipediasWikipedia is changing constantly.
All the quotes and examplesfrom Wikipedia presented and analyzed in this paper werecollected on February 10, 2009, between 14:00 and 21:00 PST.Number or Articles Language IETF Tag2,750,000+ English en750,000+ German deFrench fr500,000+ Japanese jpPolish plItalian itDutch nlTable 1: Language editions of Wikipedia by number ofarticles.?
the Wikipedia entry about a Kazakhstani fig-ure skater Denis Ten who is of partial Koreandescent has descriptions in four languages: En-glish, Japanese, Korean, and Russian.At the same time, Wikipedia entries that are im-portant or interesting for people from many commu-nities speaking different languages have articles ina variety of languages.
For example, Newton?s lawof universal gravitation is a fundamental nature lawand has descriptions in 30 languages.
Interestingly,the Wikipedia entry about Isaac Newton who firstformulated the law of universal gravitation and whois know all over the world has descriptions in 111different languages.However, even if a Wikipedia entry has arti-cles in many languages, the information covered bythese articles can differ substantially.
The two mainsources of differences are:?
the amount of the information covered by theWikipedia articles (the length of the Wikipediaarticles);?
the choice of the information covered by theWikipedia articles.For example, Wikipedia entry about Isadora Dun-can has descriptions in 44 languages.
The length ofthe descriptions about Isadora Duncan is differentfor every language: 127 sentences for the article inEnglish; 77 - for French; 37 - for Russian, 1 - forGreek, etc.
The question arises: whether a shorterarticle can be considered a summary of a longer arti-cle, or whether a shorter article might contain infor-mation that is either not covered in a longer articleor contradicts the information in the longer article.32Isadora Duncan was a American-born dancer whowas very popular in Europe and was married to aRussian poet, Sergey Esenin.
Certain amount of in-formation facts (i.e., major biography dates) aboutIsadora Duncan are repeated in the articles in ev-ery language.
However, shorter articles are not nec-essarily summaries of longer articles.
For exam-ple, the article in Russian that is almost four timeshorter than the articles in English, contains infor-mation that is not covered in the articles written inEnglish.
The same can be noted about articles inFrench and Spanish.In this paper, we analyze the distribution of lan-guages used in Wikipedia for the list of 48 people inthe DUC 2004 biography generation task.
We ana-lyze, the number of languages that contain articlesfor each of the 48 DUC 2004 people.
We also ana-lyze the distribution of the lengths for the descrip-tions in different languages.
We believe that thisstatistics is important for the understanding of theWikipedia multilinguality nature and can be used bymany NLP applications.
Several NLP applicationsthat can leverage this information are listed in Sec-tion 5.4 Analysis of Wikipedia MultilingualityIn this paper, we propose a framework to quantifythe multilinguality aspect of Wikipedia.
In the cur-rent work we use a small portion of Wikipedia.
Ana-lyzing only a portion of Wikipedia allows us to com-pare in detail the multilinguality aspect for all theWikipedia entries in our data set.4.1 Data SetFor our analysis, we used the list of people createdfor the Task 5 of DUC 2004: biography generationtask (48 people).3First, we downloaded from Wikipedia all the arti-cles in all the languages corresponding to each per-son from the DUC 2004 evaluation set.
For ouranalysis we used Wikitext, the text that is used byWikipedia authors and editors.
Wikitext complieswith the wiki markup language and can be pro-cessed by the Wikimedia content manager systeminto HTML which can then be viewed in a browser.This is the text that can be obtained through the3http://duc.nist.gov/duc2004/tasks.html/Wikipedia dumps.4 For our analysis we removedfrom the wikitext all the markup tags and tabular in-formation (e.g., infoboxes and tables) and kept onlyplain text.
There is no commonly accepted standardwikitext language, thus our final text had a certainamount of noise which, however, does not affect theconclusions drawn from our analysis.For this work, for each Wikipedia entry (i.e.,DUC 2004 person) we downloaded the correspond-ing descriptions in all the languages, including sim-ple English, Esperanto, Latin, etc.
To facilitate thecomparison of descriptions written in different lan-guages we used the Google machine translation sys-tem5 to translate the downloaded descriptions intoEnglish.
The number of languages currently coveredby the Google translation system (41 language) issmaller than the number of languages in which thereexist Wikipedia articles (265 languages).
However,we believe that using for cross-lingual analysis de-scriptions only in those languages that can be han-dled by the Google translation system does not af-fect the generality of our conclusions.4.2 Data Processing ToolsAfter the Wikipedia descriptions for each personfrom the DUC 2004 set were collected and trans-lated, we divided the description texts into sentencesusing the LingPipe sentence chunker (Alias-i, 2009).We apply sentence splitter only to the English lan-guage documents: either originally created in En-glish or translated into English by the Google trans-lation system.4.3 Data AnalysisAs mentioned in Section 1, the goal of the analysisdescribed in this paper is to quantify the languagediversity in Wikipedia entry descriptions.We chose English as our reference and, for eachDUC 2004 person, compared a description of thisperson in English against the descriptions of this per-son in other languages.Language count: In Figure 1, we present infor-mation about descriptions in how many languagesare created in Wikipedia for each person from theDUC 2004 set.
All the people from the DUC 20044http://download.wikimedia.org/5http://translate.google.com/33Figure 1: Number of languages for DUC 2004 people Wikipedia entries.set have descriptions in English.
The results inFigure 1 are presented in sorted order: from theWikipedia entries with the largest number of de-scriptions (languages covered) to the Wikipedia en-tries with the smallest number of descriptions (lan-guages covered).
Five people from the DUC 2004set have only one description (English).
The per-son who has descriptions in the most number oflanguages for our data set is the former Secretary-General of the United Nations Kofi Annan (86 lan-guages).
Figure 1 also has information about de-scriptions in how many languages were translatedinto English (handled by the Google translation sys-tem).Despite the fact that English is the language hav-ing descriptions for more Wikipedia entries than anyother language, it does not always provide the great-est coverage for Wikipedia entries.
To show thiswe analyzed the length of Wikipedia entry descrip-tions for the people from the DUC 2004 set.
For ouranalysis, the length of a description is equal to thenumber of sentences in this description.
To countthe number of sentences in the uniform way for asmany languages as possible we used translations ofWikipedia description from languages that are cur-rently handled by the Google translation system intoEnglish.
Those five people from the DUC 2004 setthat have descriptions only in English are excludedfrom this analysis.
Thus, in the data set for the nextanalysis we have 43 data points.Sentence count: For every Wikipedia entry (per-son from the DUC 2004 set), we count the lengthof the descriptions originally created in English ortranslated into English by the Google translationsystem.
In Figure 2, we present information aboutthe length of the Wikipedia entity descriptions forEnglish and for the language other than Englishwith the maximum description length.
The resultsin Figure 2 are presented in sorted order: fromthe Wikipedia entry with the maximal longest de-scription in the language other than English to theWikipedia entry with the minimal longest descrip-tion in the language other than English for our dataset.
This sorted order does not correspond to thesorted order from Figure 1.
It is interesting so seethat the sorted order in Figure 2 does not correlateto the length distribution of English descriptions forour data set.Obviously, the descriptions in English are not al-34Figure 2: Number of sentences in the English description and the longest non-English description.ways the longest ones.
To be precise for 17 out of43 people from the DUC 2004 set, the correspondingWikipedia description in English was not the longestone.
In several cases, the length of the descriptionin English is several times shorter than the lengthof the longest (non-English) description.
For exam-ple, the description of Gu?nter Grass in German has251 sentences while his description in English has74 sentences.It is safe to assume that longer descriptionshave more information than shorter descriptionsand 17 out of 43 English language descriptions ofWikipedia entries in our data set can be naturallyextended with the information covered in the de-scriptions in other languages.
Thus, multilingualWikipedia gives a straight-forward way of extend-ing Wikipedia entry descriptions.It must be noted that the average length ofWikipedia descriptions (also presented on Figure 2)is very short.
Thus, many descriptions for Wikipediaentries are quite short.
The question arises how wellthe information covered in short descriptions corre-sponds to the information covered in long descrip-tions.Correlation Analysis: In this paper, we presentanalysis for a small portion of Wikipedia.
Currently,Wikipedia has more than more than 2, 750, 000 ar-ticles in English alone.
Thus, the question ariseswhether our analysis can be used without loss ofgenerality for the complete Wikipedia (i.e., all de-scriptions for all Wikipedia entries).6 To checkthis we analyzed the correspondence of how manyWikipedia entry descriptions are there for each lan-guage.
For the Wikipedia subset correspondingto the people from the DUC 2004 set we simplycounted how many Wikipedia entries have descrip-tions in each language.
For the complete set ofWikipedia descriptions we used the Wikipedia sizenumbers from the List of Wikipedias page.7 Af-ter getting the Wikipedia size numbers we kept thedata only for those languages that are used for de-scriptions of Wikipedia entries corresponding to theDUC 2004 people.To compute correlation between these two lists ofnumbers we ranked numbers in each of these lists.The Rank (Spearman) Correlation Coefficient for6It must be noted that the notion of complete Wikipedia iselusive as Wikipedia is changing constantly.7http://en.wikipedia.org/wiki/List_of_Wikipedias35the above two ranked lists is equal to 0.763 whichshows a high correlation between the two rankedlists.
Thus, the preliminary analysis presented inwork can be a good predictor for the descriptions?length distribution across descriptions in the com-plete multilingual Wikipedia.5 Conclusions and Future WorkIn this papers we presented a way of quantify-ing multilingual aspects of Wikipedia entry descrip-tions.
We showed that despite the fact that Englishhas descriptions for the most number of Wikipediaentries across all languages, English descriptionscan not always be considered as the most detaileddescriptions.
We showed that for many Wikipediaentries, descriptions in the languages other than En-glish are much longer than the corresponding de-scriptions in English.Our estimation is that even though Wikipedia en-try descriptions created in different languages arenot identical, they are likely to contain informa-tion facts that appear in descriptions in many lan-guages.
One research direction that we are inter-ested in pursuing is investigating whether the infor-mation repeated in multiple descriptions of a partic-ular entry corresponds to the pyramid summariza-tion model (Teufel and Halteren, 2004; Nenkova etal., 2007).
In case of the positive answer to thisquestion, multilingual Wikipedia can be used as areliable corpus for learning summarization features.Also, our preliminary analysis shows thatWikipedia entry descriptions might contain informa-tion that contradicts information presented in the en-try descriptions in other languages.
Even the choiceof a title for a Wikipedia entry can provide inter-esting information.
For example, the title for theWikipedia entry about Former Yugoslav Republic ofMacedonia in English, German, Italian, and manyother languages uses the term Republic of Macedo-nia or simply Macedonia.
However, Greece does notrecognize this name, and thus, the title of the corre-sponding description in Greek has a complete formalname of the country: Former Yugoslav Republic ofMacedonia.Multilingual Wikipedia is full of informationasymmetries.
Studying information asymmetries inmultilingual Wikipedia can boost research in newinformation and contradiction detection.
At thesame time, information symmetries in multilingualWikipedia can be used for learning summarizationfeatures.ReferencesACL.
2009.
Workshop on building and using compara-ble corpora: from parallel to non-parallel corpora.Sisay Fissaha Adafre and Maarten de Rijke.
2006.
Find-ing similar sentences across multiple languages inwikipedia.
In Proceedings of the Conference of theEuropean Chapter of the Association for Computa-tional Linguistics, Workshop on New Text ?
Wikis andblogs and other dynamic text sources, Trento, Italy,April.Eytan Adar, Michael Skinner, and Dan Weld.
2009.Information arbitrage in multi-lingual Wikipedia.
InProceedings of the Second ACM International Con-ference on Web Search and Data Mining, Barcelona,Spain, February.David Ahn, Valentin Jijkoun, Gilad Mishne, KarinMu?ller, Maarten de Rijke, and Stefan Schlobach.2005.
Using Wikipedia at the TREC QA track.
InProceedings of the Text REtrieval Conference (TREC2004).Alias-i.
2009.
Lingpipe 3.7.0.
(accessed January 19,2009).
http://alias-i.com/lingpipe.Fadi Baidsy, Julia Hirschberg, and Elena Filatova.
2008.An unsupervised approach to biography productionusing wikipedia.
In Proceedings of the 46th AnnualMeeting of the Association for Computational Linguis-tics (ACL-2008), Columbus, OH, USA, July.Regina Barzilaya and Kathleen McKeown.
2001.
Ex-tracting paraphrases from a parallel corpus.
In Pro-ceedings of the 39th Annual Meeting of the Associationfor Computational Linguistics (ACL-2001), Toulouse,France, July.Davide Buscaldi and Paolo Rosso.
2006.
Mining knowl-edge from wikipedia for the question answering task.In Proceedings of The Fifth international Conferenceon Language Resources and Evaluation (LREC-2006),Genoa, Italy, May.CLEF.
2000.
Cross-language evaluation forum (CLEF).http://www.clef-campaign.org.Sergio Ferra?ndez, Antonio Toral, ?Oscar Ferra?ndez, Anto-nio Ferra?ndez, and Rafael Munoz.
2007.
ApplyingWikipedia?s multilingual knowledge to cross-lingualquestion answering.
Lecture Notes in Computer Sci-ence (LNCS): Natural Language Processing and In-formation Systems, 4592:352?363.Ulrich Germann.
2001.
Aligned hansards ofthe 36th parliament of Canada.
Website.36http://www.isi.edu/natural-language/download/hansard/.Andrew Keen.
2007.
The Cult of the Amateur: HowToday?s Internet is Killing Our Culture.
DoubledayBusiness.Jeongwoo Ko, Teruko Mitamura, and Eric Nyberg.
2007.Language-independent probabilistic answer rankingfor multilingual question answering.
In Proceed-ings of the 45th Annual Meeting of the Associationfor Computational Linguistics (ACL-2007), Prague,Czech Republic, June.Philipp Koehn.
2005.
Europarl: A parallel corpus for sta-tistical machine translation.
In Proceedings of the Ma-chine Translation Summit (MT-2005), Phuket Island,Thailand, September.LREC.
2008.
Workshop on building and using compara-ble corpora.Lieve Macken, Julia Trushkina, and Lidia Rura.
2007.Dutch Parallel Corpus: MT corpus and translator?said.
In Proceedings of the Eleventh Machine Transla-tion Summit (MT-2007), pages 313?320, Copenhagen,Denmark, September.Bernardo Magnini, Simone Romagnoli, and Ro Vallin.2003.
Creating the DISEQuA corpus: A test setfor multilingual question answering.
In Proceedingsof the Cross-Lingual Evaluation Forum (CLEF-2003),Trondheim, Norway, August.Ani Nenkova, Rebecca Passonneau, and Kathleen McK-eown.
2007.
The Pyramid method: Incorporating hu-man content selection variation in summarization eval-uation.
ACM Transactions on Speech and LanguageProcessing, 4(2).Alexander Richman and Patrick Schone.
2008.
MiningWiki resources for multilingual named entity recogni-tion.
In Proceedings of the 46th Annual Meeting ofthe Association for Computational Linguistics (ACL-2008), Columbus, OH, USA, July.Pe?ter Scho?nhofen, Andra?s Benczu?r, Istva?n B?
?ro?, andKa?roly Csaloga?ny.
2007.
Performing cross-languageretrieval with wikipedia.
In Proceedings of the Work-ing Notes for the CLEF 2007 Workshop, Budapest,Hungary, September.Ralf Steinberger, Bruno Pouliquen, Anna Widiger,Camelia Ignat, Tomaz?
Erjavec, Dan Tufis, and Da?nielVarga.
2006.
The JRC-Acquis: A multilingualaligned parallel corpus with 20+ languages.
In Pro-ceedings of The Fifth international Conference onLanguage Resources and Evaluation (LREC-2006),Genoa, Italy, May.Simone Teufel and Hans Van Halteren.
2004.
Evaluatinginformation content by factoid analysis: Human anno-tation and stability.
In Proceedings of the 42th AnnualMeeting of the Association for Computational Linguis-tics (ACL-2004), Barcelona, Spain, July.37
