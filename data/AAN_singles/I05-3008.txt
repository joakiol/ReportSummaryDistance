Word Meaning Inducing via Character Ontology: A Survey on theSemantic Prediction of Chinese Two-Character WordsShu-Kai HsiehSeminar fu?r SprachwissenschaftAbt.
ComputerlinguistikUniversita?t Tu?bingen72074, Germanykai@hanzinet.orgAbstractThis paper presents a semantic classprediction model of Chinese two-character compound words based ona character ontology, which is set tobe a feasible conceptual knowledge re-source grounded in Chinese characters.The experiment we conduct yields sat-isfactory results which turn out to bethat the task of semantic prediction oftwo-character words could be greatlyfacilitated using Chinese characters asa knowledge resource.1 IntroductionThis paper describes the theoretical considera-tion concerning with the interaction of ontologyand morpho-semantics, and an NLP experimentis performed to do semantic class prediction ofunknown two-character words based on the on-tological and lexical knowledge of Chinese mor-phemic components of words (i.e., characters).The task that the semantic predictor (or classifier)performs is to automatically assign the (prede-fined) semantic thesaurus classes to the unknowntwo-character words of Chinese.Among these types of unknown words, Chenand Chen (2000) pointed out that compoundwords constitute the most productive type of un-known words in Chinese texts.
However, thecaveat at this point should be carefully formu-lated, due to the fact that there are no unequiv-ocal opinions concerning with some basic theo-retical settings in Chinese morphology.
The no-tion of word, morpheme and compounding arenot exactly in accord with the definition commonwithin the theoretical setting of Western morphol-ogy.
To avoid unnecessary misunderstanding, thepre-theoretical term two-character words will bemostly used instead of compound words in thispaper.2 Word Meaning Inducing viaCharacter Meaning2.1 Morpho-Semantic DescriptionAs known, ?bound roots?
are the largest classes ofmorpheme types in Chinese morphology, and theyare very productive and represent lexical ratherthan grammatical information (Packard 2000).This morphological phenomena leads many Chi-nese linguists to view the word components (i.e.,characters) as building blocks in the seman-tic composition process of dis- or multisyllabicwords.
In many empirical studies (Tseng andChen (2002); Tseng (2003); Lua (1993); Chen(2004)), this view has been confirmed repeatedly.In the semantic studies of Chinese word for-mation, many descriptive and cognitive seman-tic approaches have been proposed, such as ar-gument structure analysis (Chang 1998) and theframe-based semantic analysis (Chu 2004).
How-ever, among these qualitative explanation theoret-ical models, problems often appear in the lack ofpredictability on the one end of spectrum, or over-generation on the other.1 Empirical data have1For example, in applying Lieber?s (1992) analysis of ar-gument structure and theta-grid in Chinese V-V compounds,Chang (1998) found some examples which may satisfy thesemantic and syntactic constraints, but they may not be ac-56also shown that in many cases, ?
e.g., the abun-dance of phrasal lexical units in any natural lan-guage, ?
the principle of compositionality in astrict sense, that is, ?the meaning of a complexexpression can be fully derivable from the mean-ings of its component parts, and from the schemaswhich sanction their combination?
(Taylor 2002),which is taken to be a fundamental proposition insome of morpho-semantically motivated analysis,is highly questionable.This has given to the consideration of the em-beddedness of linguistic meanings within broaderconceptual structures.
In what follows, we willargue that an ontology-based approach wouldprovide an interesting and efficient prospectivetoward the character-triggered morpho-semanticanalysis of Chinese words.2.2 Conceptual Aggregate in Compounding:A Shift Toward Character OntologyIn prior studies, it is widely presumed that the cat-egory (be it syntactical or semantic) of a word, issomehow strongly associated with that of its com-posing characters.
The semantic compositionalityunderlying two-character words appears in differ-ent terms in the literature.2Word semantic similarity calculation tech-niques have been commonly used to retrieve thesimilar compositional patterns based on semantictaxonomic thesaurus.
However, one weak pointin these studies is that they are unable to sep-arate conceptual and semantic levels.
Problemraises when words in question are conceptuallycorrelated are not necessarily semantically corre-lated, viz, they might or might not be physicallyclose in the CILIN thesaurus (Mei et al1998).On closer observations, we found that most syn-onymic words (i.e., with the same CILIN seman-tic class) have characters which carry similar con-ceptual information.
This could be best illustratedby examples.
Table 1 shows the conceptual distri-bution of the modifiers of an example of VV com-pound by presuming the second character ?
as aceptable to native speakers.2Using statistical techniques, Lua (1993) found out thateach Chinese two-character word is a result of 16 types ofsemantic transformation patterns, which are extracted fromthe meanings of its constituent characters.
In Chen (2004),the combination pattern is referred to as compounding se-mantic template.head.
The first column is the semantic class ofCILIN (middle level), the second column lists theinstances with lower level classification number,and the third column lists their conceptual typesadopted from a character ontology we will discusslater.
As we can see, though there are 12 result-ing semantic classes for the * ?
compounds, themodifier components of these compounds involveonly 4 concept types as follows:11000 (SUBJECTIVE?
EXCITABILITY?
ABILITY?
ORGANIC FUNCTION)??,11010 (SUBJECTIVE?
EXCITABILITY?
ABILITY?
SKILLS) ?YL?T??,11011 (SUBJECTIVE?
EXCITABILITY?
ABILITY?
INTELLECT) ??5??p=,11110 (SUBJECTIVE?
EXCITABILITY?
SOCIAL EXPERIENCE?
DEAL WITH THINGS)Y???T??,?y???We defined these patterns as conceptual aggre-gate pattern in compounding.
Unlike statisticalmeasure of the co-occurrence restrictions or asso-ciation strength, a concept aggregate pattern pro-vides a more knowledge-rich scenario to repre-sent a specific manner in which concepts are ag-gregated in the ontological background, and howthey affect the compounding words.
We will pro-pose that the semantic class prediction of Chinesetwo-character words could be improved by mak-ing use of their conceptual aggregate pattern ofhead/modifier component.3 Semantic Prediction of UnknownTwo-Character WordsThe practical task intended to be experimentedhere involves the automatic classification of Chi-nese two-character words into a predeterminednumber of semantic classes.
Difficulties encoun-tered in previous researches could be summarizedas follows:First, many models (Chen and Chen1998;2000) cannot deal with the issue of?incompleteness?
of characters in the lexicon, forthese models depend heavily on CILIN, a ChineseThesaurus containing only about 4,133 monosyl-labic morphemic components (characters).
Asa result, if unknown words contain charactersthat are not listed in CILIN, then the predictiontask cannot be performed automatically.
Second,the ambiguity of characters is often shunned by57SC VV compounds Concept types of modifier componentEe 37 ??
11110Fa 05 Y?
08 ??
15 L?
11010Fc 05 =?
11011Gb 07 p?
11011Ha 06 T?
11110Hb 08 ??
12 ??
12 T?
12 ??
11110Hc 07 Y?
23 ??
25 ??
{11110;11011}Hi 27 ??
27 T?
{11010;11110}Hj 25 ??
25 ??
{11010;11110}Hn 03 ??
10 y?
12 Y?
11110If 09 5?
11011Je 12 ?
12 ??
12 ??
12 ??
12 ??
12 ??
12 ??
12 ??
12 ,?
12 i?
12 ??
12??
12 T?
{11000;11110;11011;11110}Table 1: Conceptual aggregate patterns in two-character VV (compound) words: An example of * ?manual pre-selection of character meaning in thetraining step, which causes great difficulty for anautomatic work.
Third, it has long been assumed(Lua 1997; Chen and Chen 2000) that the over-whelming majority of Chinese compounds aremore or less endocentric, where the compoundsdenote a hyponym of the head component in thecompound.
E.g, ?s (?electric-mail?
; e-mail)is a kind of mail.
So the process of identifyingsemantic class of a compound boils down to findand to determine the semantic class of its headmorpheme.
However, there is also an amountof exocentric and appositional compounds3where no straightforward criteria can be made todetermine the head component.
For example, ina case of VV compound o?
(?denounce-scold?,drop-on), it is difficult (and subjective) to saywhich character is the head that can assign asemantic class to the compound.To solve above-mentioned problems, Chen(2004) proposed a non head-oriented character-sense association model to retrieve the latentsenses of characters and the latent synonymouscompounds among characters by measuring sim-ilarity of semantic template in compounding byusing a MRD.
However, as the author remarkedin the final discussion of classification errors, theperformance of this model relies much on the pro-ductivity of compounding semantic templates ofthe target compounds.
To correctly predict the se-mantic category of a compound with an unpro-ductive semantic template is no doubt very dif-ficult due to a sparse existence of the template-3Lua reports a result of 14.14% (Z3 type).similar compounds.
In addition, the statisticalmeasure of sense association does not tell us anymore about the constraints and knowledge of con-ceptual combination.In the following, we will propose that a knowl-edge resource at the morpheme (character) levelcould be a straightforward remedy to these prob-lems.
By treating characters as instances of con-ceptual primitives, a character ontology thereofmight provide an interpretation of conceptualgrounding of word senses.
At a coarse grain, thecharacter ontological model does have advantagesin efficiently defining the conceptual space withinwhich character-grounded concept primitives andtheir relations, are implicitly located.4 A Proposed CharacterOntology-based ApproachIn carrying out the semantic prediction task,we presume the context-freeness hypothesis, i.e.,without resorting to any contextual information.The consideration is taken based on the observa-tion that native speaker seems to reconstruct theirnew conceptual structure locally in the processingof unknown compound words.
On the other hand,it has the advantage especially for those unknownwords that occur only once and hence have lim-ited context.In general, the approach proposed here differsin some ways from previous research based on thefollowing presuppositions:584.1 Character Ontology as a KnowledgeResourceThe new model that we will present below willrely on a coarsely grained upper-level ontologyof characters.4 This character ontology is a tree-structured conceptual taxonomy in terms of whichonly two kinds of relations are allowed: theINSTANCE-OF (i.e., certain characters are in-stances of certain concept types) and IS-A rela-tions (i.e., certain concept type is a kind of certainconcept type).In the character ontology, monosyllabic char-acters 5 are assigned to at least 6 one of 309 con-sets (concept set), a new term which is defined asa type of concept sharing a given putatively prim-itive meaning.
For instance, z (speak), ?
(chatter),x (say), ; (say), ?
(tell), s (inform), ?
(explain), ?
(nar-rate), ?
(be called), H (state), these characters are as-signed to the same conset.Following the basic line of OntoClear method-ology (Guarino and Welty (2002)), we use sim-ple monotonic inheritance, which means that eachnode inherits properties only from a single ances-tor, and the inherited value cannot be overwrittenat any point of the ontology.
The decision to keepthe relations to one single parent was made in or-der to guarantee that the structure would be ableto grow indefinitely and still be manageable, i.e.that the transitive quality of the relations betweenthe nodes would not degenerate with size.
Fig-ure 1 shows a snapshot of the character ontology.4.2 Character-triggered LatentNear-synonymsThe rationale behind this approach is that simi-lar conceptual primitives - in terms of characters- probably participate in similar context or havesimilar meaning-inducing functions.
This canbe rephrased as the following presumptions: (1).Near-synonymic words often overlap in senses,i.e., they have same or close semantic classes.
(2).Words with characters which share similar con-ceptual information tend to form a latent cluster4At the time of writing, about 5,600 characters have beenfinished in their information construction.
Please refer to [4]5In fact, in addition to monosyllabic morpheme, it alsocontains a few dissyllabic morphemes, and borrowed poly-syllabic morphemes.6This is due to the homograph.ROOTOBJSUBJCONCRETEABSTRACTEXISTENCEARTIFACTEXCITABLECOGNITIVESEMIOTICRELATIONALSENSATIONSTATEINNATESOCIALconset 1conset 309conset 2conset 3------------------------------------------------------------------------------------------conset 308conset 307{????????????}{????????????}{???????????}------------------------------------------------------------------------------------------------{???}{????????????????}{??????????????
}Figure 1: The character ontology: a snapshotof synonyms.
(2).
These similar conceptual in-formation can be formalized as conceptual aggre-gate patterns extracted from a character ontology.(3).
Identifying such conceptual aggregate pat-terns might thus greatly benefit the automaticallyacquired near-synonyms, which give a set of goodcandidates in predicting the semantic class of pre-viously unknown ones.The proposed semantic classification systemretrieves at first a set of near-synonym candidatesusing conceptual aggregation patterns.
Consid-erations from the view of lexicography can win-now the overgenerated candidates, that is, a finaldecision of a list of near-synonym candidates isformed on the basis of the CILIN?s verdict as towhat latent near-synonyms are.
Thus the semanticclass of the target unknown two-character wordswill be assigned with the semantic class of thetop-ranked near-synonym calculated by the sim-ilarity measurement between them.
This methodhas advantage of avoiding the snag of apparentmultiplicity of semantic usages (ambiguity) of acharacter.Take for an example.
Suppose that the seman-tic class of a two-character word \?
(protect;Hi37) is unknown.
By presuming the leftmostcharacter \ the head of the word, and the right-most character ?
as the modifier of the word,59we first identify the conset which the modifier?
belongs to.
Other instances in this conset are\, ?, {, ?, 7, G, ?, ., 1, ?, ?, etc.
So wecan retrieve a set of possible near-synonym can-didates by substitution, namely, NS1: {\\, \?,\{, \?, \7, \G, \?, \., \1, \?, \?
}; inthe same way, by presuming ?
as the head, wehave a second set of possible near-synonym can-didates, NS2: {?
?, ?
?, {?, ?
?, 7?, G?, ??,.
?, 1?, ?
?, ??}7.
Aligned with CILIN, thosecandidates which are also listed in the CILIN areadopted as the final two list of the near-synonymcandidates for the unknown word \?
: NS?1:{??
(Hi41), ??
(Hb04;Hi37), 7?
(Hi47), ??(Hi37),??
(Hd01)}, and NS?2: {\G(Hl33),\?
(Hj33), \?
(Ee39)}.4.3 Semantic Similarity Measure ofUnknown Word and its Near-SynonymsGiven two sets of character-triggered near-synonyms candidates, the next step is to calcu-late the semantic similarity between the unknownword (UW) and these near-synonyms candidates.CILIN Thesaurus is a tree-structured taxo-nomic semantic structure of Chinese words,which can be seen as a special case of seman-tic network.
To calculate semantic similarity be-tween nodes in the network can thus make use ofthe structural information represented in the net-work.Following this information content-basedmodel, in measuring the semantic similaritybetween unknown word and its candidate near-synonymic words, we use a measure metricmodelled on those of Chen and Chen (2000),which is a simplification of the Resnik algorithmby assuming that the occurrence probabilityof each leaf node is equal.
Given two sets(NS?1, NS?2) of candidate near synonyms, eachwith m and n near synonyms respectively, thesimilarity is calculated as in equation (1) and(2), where scuwc1 and scuwc2 are the semanticclass(es) of the first and second morphemic com-ponent (i.e., character) of a given unknown word,respectively.
sci and scj are the semantic classesof the first and second morphemic componentson the list of candidate near-synonyms NS?17Note that in this case, \ and ?
are happened to be inthe same conset.and NS?2.
f is the frequency of the semanticclasses, and the denominator is the total value ofnumerator for the purpose of normalization.
?and 1??
are the weights which will be discussedlater.
The Information Load (IL) of a semanticclass sc is defined in Chen and Chen (2004):IL(sc) = Entropy(system) ?
Entropy(sc)(3)' (?1q?log21q ) ?
(?1p?log21p)= log2 q ?
log2 p= ?
log2(pq ),if there is q the number of the minimal semanticclasses in the system,8 p is the number of the se-mantic classes subordinate sc.4.4 Circumventing ?Head-oriented?PresuppositionAs remarked in Chen (2004), the previous re-search concerning the automatic semantic classi-fication of Chinese compounds (Lua 1997; Chenand Chen 2000) presupposes the endocentric fea-ture of compounds.
That is, by supposing thatcompounds are composed of a head and a modi-fier, determining the semantic category of the tar-get therefore boils down to determine the seman-tic category of the head compound.In order to circumventing the strict ?head-determination?
presumption, which might suf-fer problems in some borderline cases of V-Vcompounds, the weight value (?
and 1 ?
?)
isproposed.
The idea of weighting comes fromthe discussion of morphological productivity inBaayen (2001).
We presume that, within a giventwo-character words, the more productive, thatis, the more numbers of characters a charac-ter can combine with, the more possible it is ahead, and the more weight should be given to it.The weight is defined as ?
= C(n,1)N , viz, thenumber of candidate morphemic components di-vided by the total number of N. For instance, inthe above-mentioned example, NS1 should gainmore weights than NS2, for ?
can combine withmore characters (5 near-synonyms candidates) in8In CILIN, q = 3915.60sim?
(UW,NS?1) = argmaxi=1,mIL(LCS(scuwc1, sci)) ?
fi?mi=1 IL(LCS(scuwc1, sci)) ?
fi(?)
(1)sim?
(UW,NS?2) = argmaxj=1,nIL(LCS(scuwc2, scj)) ?
fj?nj=1 IL(LCS(scuwc2, scj)) ?
fj(1 ?
?)
(2)NS1 than \ does in NS2 (3 near-synonyms can-didates).
In this case, ?
= 58 = 0.625.
It isnoted that the weight assignment should be char-acter and position independent.4.5 Experimental Settings4.5.1 ResourcesThe following resources are used in the ex-periments: (1)Sinica Corpus9, (2) CILIN The-saurus (Mei et al1998) and (3) a Chinese char-acter upper-level ontology.10 (1) is a well knownbalanced Corpus for modern Chinese used in Tai-wan.
(2) CILIN Thesaurus is a Chinese The-saurus widely accepted as a semantic categoriza-tion standard of Chinese word in Chinese NLP.In CILIN, a collection of about 52,206 Chinesewords are grouped in a Roget?s Thesaurus-likestructure based on categories within which thereare several 3 levels of finer clustering (12 major,95 minor and 1428 minor semantic classes).
(3) isan on-going project of Hanzi-grounded Ontologyand Lexicon as introduced.4.5.2 DataWe conducted an open test experiment, whichmeant that the training data was different from thetesting data.
800 two-character words in CILINwere chosen at random to serve as test data, andall the words in the test set were assumed to be un-known.
The distribution of the grammatical cate-gories of these data is: NN (200, 25%), VN (100,12.5%) and VV (500, 62.5%).4.5.3 BaselineThe baseline method assigns the semantic classof the randomly picked head component to the se-mantic class of the unknown word in question.
Itis noted that most of the morphemic components9http://www.sinica.edu.tw/SinicaCorpus/10http://www.hanzinet.org/HanziOnto/Compound types Baseline Our algorithmV-V 12.20% 42.00%V-N 14.00% 37.00%N-N 11.00% 72.50%Table 2: Accuracy in the test set (level 3)(characters) are ambiguous, in such cases, seman-tic class is chosen at random as well.4.5.4 Outline of the AlgorithmBriefly, the strategy to predict the seman-tic class of a unknown two-character wordis, to measure the semantic similarity of un-known words and their candidate near-synonymswhich are retrieved based on the characterontology.
For any unknown word UW ,which is the character sequence of C1C2,the RANK(sim?(?
), sim?
(1 ?
?))
is com-puted.
The semantic category sc of thecandidate synonym which has the value ofMAX(sim?(?
), sim?
(1 ?
?
)), will be the top-ranked guess for the target unknown word.4.6 Results and Error AnalysisThe correctly predicted semantic class is the se-matic class listed in CILIN.
In the case of ambigu-ity, when the unknown word in question belongsto more than one semantic classes, any one of theclasses of an ambiguous word is considered cor-rect in the evaluation.The SC prediction algorithm was performedon the test data for outside test in level-3 classi-fication.
The resulting accuracy is shown in Ta-ble 2.
For the purpose of comparison, Table 3also shows the more shallow semantic classifica-tion (the 2nd level in CILIN).Generally, without contextual information, theclassifier is able to predict the meaning of a Chi-nese two-character words with satisfactory accu-61Compound types Baseline Our algorithmV-V 13.20% 46.20%V-N 16.00% 42.00%N-N 12.50% 76.50%Table 3: Accuracy in the test set (level 2)racy against the baseline.
A further examina-tion of the bad cases indicates that error can begrouped into the following sources:?
Words with no semantic transparency:Like ?proper names?, these types have no se-mantic transparency property, i.e., the wordmeanings can not be derived from their mor-phemic components.
Loan words such as ??
(/sha?fa?/; ?sofa?)
are typical examples.?
Words with weak semantic transparency:These can be further classified into fourtypes:?
Appositional compounds: words whosetwo characters stand in a coordinate re-lationship, e.g.
?a (?east-west?, thing).?
Lexicalized idiomatic usage: For suchusage, each word is an indivisible con-struct and each has its meaning whichcan hardly be computed by adding upthe separate meaning of the compo-nents of the word.
The sources of theseidiomatic words might lie in the etymo-logical past and are at best meaninglessto the modern native speaker.
e.g, ??
(?salary-water?, salary).?
Metaphorical usage: the meaning ofsuch words are therefore different fromthe literal meaning.
Some testing datais not semantically transparent due totheir metaphorical uses, For instance, ?I (Aj) is assigned to the ??
(Bk).?
Derived words:Such as ??
(enter).
These could be filter outusing syntactical information.?
The quality and coverage of CILIN and char-acter ontology:Since our SC system?s test and training dataare gleaned from CILIN and the characterCompound types Our model Current bestmodelV-V 42.00% 39.80% (Chen2004)N-N 72.50% 81.00% (Chenand Chen 2000)Table 4: Level-3 performance in the outside test:a comparisonontology, the quality and coverage play acrucial role.
For example, for the unknowncompound word ??
(/sa?o-sa?o/; ?be in tu-mult?
), there not even an example whichhas ?
as the first character or as the sec-ond character.
the same problem such asfalling short on coverage and data sparse-ness goes to the character ontology, too.
Forinstance, there are some dissyllabic mor-phemes which are not listed in ontology,such as ??
(/j?`yu?/;?covet?
).4.7 EvaluationSo far as we know, no evaluation in the previousworks was done.
This might be due to many rea-sons: (1) the different scale of experiment (howmany words are in the test data?
), (2) the selec-tion of syntactic category (VV, VN or NN?)
ofmorphemic components, and (3) the number ofmorphemic components involved (two or three-character words?)..
etc.
Hence it is difficult tocompare our results to other models.
Among thecurrent similar works, Table 4 shows that our sys-tem outperforms Chen(2004) in VV compounds,and approximates the Chen and Chen(2000) inNN compounds.5 ConclusionIn this paper, we propose a system that aims togain the possible semantic classes of unknownwords via similarity computation based on char-acter ontology and CILIN thesaurus.
In gen-eral, we approach the task in a hybrid way thatcombines the strengths of ontology-based andexample-based model to achieve at better resultfor this task.The scheme we use for automatic semanticclass prediction takes advantage of the presump-tions that the conceptual information wired inChinese characters can help retrieve the near-62synonyms, and the near-synonyms constitute akey indicator for the semantic class guess of un-known words in question.The results obtained show that, our SC pre-diction algorithm can achieve fairly high level ofperformance.
While the work presented here instill in progress, a first attempt to analyze a testset of 800 examples has already shown a 43.60%correctness for VV compounds, 41.00% for VNcompounds, and 74.50% for NN compounds atthe level-3 of CILIN.
If shallow semantics is takeninto consideration, the results are even better.Working in this framework, however, one pointas suggested by other similar approach is that,human language processing is not limited to anabstract ontology alone (Hong et al 2004).
Inpractical applications, ontologies are seldom usedas the only knowledge resources.
For those un-known words with very weak semantic trans-parency, it would be interesting to show that anontology-based system can be greatly boostedwhen other information sources such as metaphorand etymological information integrated.
Fu-ture work is aimed at improving this accuracy byadding other linguistic knowledge sources and ex-tending the technique to WSD (Word Sense Dis-ambiguation).AcknowledgementsI would like to thank Erhard Hinrichs and LotharLemnitzer for their useful discussions.
I alsothank the anonymous referees for constructivecomments.
Thanks also go to the institute of lin-guistics of Academia Sinica for their kindly datasupport.ReferencesBaayen, Harald.
(2001).
Word frequency distributions.Kluwer Academic Publishers.Chen, Keh-Jiann and Chao-Jan Chen.
(2000).
Auto-matic semantic classification for Chinese unknowncompound nouns.
COLING 2000, Saarbru?cken,Germany.Chen, Chao-Ren.
(2004).
Character-Sense associationand compounding template similarity: Automaticsemantic classification of Chinese compounds.
The3rd SIGHAN Workshop.Chu, Yan.
(2004).
Semantic word formation of Chinesecompound words.
Peking University Press.HanziNet Project: http://www.hanzinet.org.Guarino, Nicola and Chris Welty.
(2002).
Evaluatingontological decisions with OntoClean.
In: Commu-nications of the ACM.
45(2):61-65.Hong, Li and Huang (2004).
Ontology-based Predic-tion of Compound Relations: A study based onSUMO.
PACLIC 18.Hsieh, Shu-Kai.
(2005).
HanziNet: An enriched con-ceptual network of Chinese characters.
The 5rdworkshop on Chinese lexical semantics, China: Xi-amen.Lin, Dekang.
(1998).
A information-theoretic defini-tion of similarity.
In:Proceeding of 15th Interna-tional Conference of Machine Learning..Lua, K. T. (1993).
A study of Chinese word semanticsand its prediction.
Computer Processing of Chineseand Oriental Languages, Vol 7.
No 2.Lua, K.T.
(1997).
Prediction of meaning of bisyl-labic Chinese words using back propagation neuralnetwork.
In:Computer Processing of Oriental Lan-guages.
11(2).Lua, K. T. (2002).
The Semantic Transformation ofChinese Compound Words (?x?????x<??
).The 3rd workshop on Chinese lexical semantics,Taipei.Packard, J. L. (2000).
The morphology of Chinese.Cambridge, UK: Cambridge University Press.Mei et al(1998).
?2???.
Dong-Hua Bookstore:Taipei.63
