A Probabilistic Approach to Compound Noun Indexing inKorean TextsHyouk  R .
Park  and  Young S. Han  and  Kang H .
LeeKorea  R&D In format ion  Center /K ISTP .O.
Box 122 YuSong Tae jon ,  305-600, Korea{ hrpark, yshan, khlee} @stissbs.kordic.re.krKey-Sun ChoiComputer  Sc ience Depar tment  KA ISTYuSong Tae jon ,  305-701, Koreakschoi(O)world, kaist, ac.
krAbst rac tIn this paper we address the prob-lem of compound noun indexing thatis about segmenting or decomposingcompound nouns into promising indexterms.
Compound nouns as index termsthat usually subscribe to specific no-tions tend to increase the precision ofretrieval performance.
The use of thecomponent nouns of a compound nounas index terms, on the other hand, mayimprove the recall performance, but candecrease the precision.Our proposed method to handle com-pound nouns with a goal to increasethe recall while preserving the preci-sion computes the relevance of the com-ponent nouns of a compound noun tothe document content by comparing thedocument sets that are supported bythe component nouns and the terms ofthe document.
The operational contentof a term is represented as the proba-bilistic distribution of the term over thedocument set.Experiments with a set of 1,000 docu-ments show that our method gains 33%increase of retrieval performance com-pared to the indexing method withoutcompound noun analysis, and is as goodas manual decomposition by human ex-perts.1 In t roduct ionAutomatic indexing renders a form of documentrepresentation that visualizes the content of thedocument more explicitly.
Indices that are care-fully chosen to represent a document will bringabout the improvement of retrieval performancein accuracy and time efficiency.
The potential ofa candidate index is often judged on the basis ofits discriminating power over a docmnent set aswell as its linguistic significance in the document.Thus, a good index term should distinguish a cer-tain class of documents from the rest of the doc-uments and be relevant o the subject matters ofthe class of documents to be indexed by the term.In general, automatic indexing consists of theidentification of index terms and the assignmentof weights to the terms (Salton 1983).An index term can be either a simple noun or acompound noun composed of more than one sim-ple nouns.
Compound nouns tend to carry morespecific contextual information than simple nouns,thus they are likely to contribute to the retrievalprecision.
Compound nouns may contain usefulsimple nouns that usually refer general contexts,and thus will boost the recall of retrieval.
Process-ing compound nouns is decomposing them intosimple nonns and evaluating the simple nouns aspotential index terms.
In both identifying andevaluating index terms, compound nouns requirea different strategy from that for simple nouns.The identification of compound nouns involves acertain degree of linguistic or statistical analysisthat varies from simple stemming to morphologi-cal analysis (Fagan 1989).What makes it even more complicated to han-dle compound nouns in Korean documents lies inthe convention of writing compound nouns.
InKorean, it is allowed to write compound nounswith or without intervening blanks between con-stituent nouns.
Arbitrarily long compound nounsare possible and not rare in real texts.
The de-composition of a compound noun is particularlyproblematic because of the severe ambiguity ofsegmentations.In this paper, we propose a method to iden-tify and evaluate the candidate index terms fromcompound nouns.
First, each possible decomposi-tion of a compound noun is identified.
To'see thepotential of the component nouns of the decom-position, we observe how the component nounsare distributed over the total document set, and514also examine how the simple and componnd nounsof the current document are distributed over thesame document set.
The similarity of the two dis-tributions implies how consistently the two termsets will behave given a query at retriewd time.The proposed method assumes a dictionary ofnouns that is automatically constructed from thedocument set.
3'his is the practice that has neverbeen tried in Korean document indexing, but hassome important merits.
A laborious work for themanual construction of nominal dictionaries is notneeded.
Since the noun dictionary contains onlythose in a document set, the ambiguity in analyz-ing words is greatly reduced.Previous researches on the problem of com-pound noun indexing in Korean have been done intwo directions.
One approach adopts a full-scalemorphological nalysis to decompose a word into asequence of the smallest morpheme units that areall treated as index terms.
The other approachtries to avoid the complexity of the full scale anal-ysis by using bigrams as in (Fnjii 199'3; l,ee 11996;Ogawa 1993).
Since these methods take all thecomponents of compound nouns as index termswithout evaluation, irrelewmt erms can decreaseretrieval precision.Experiments on 1000 documents how that ourevaluation scheme gave results closet" to the hu-man intuition and maintained the highest preci-sion ratio of tile existing methods.In the following section, a brief review of re-lated work on automatic indexing for Korean doc-nments is made.
Section 3 explains tile proposedmethod in detail.
The verification of the methodthrough experiments is described in section 4.Section 5 concludes the paper.2 Re la ted  WorkThe previous approaches to compound noun in-dexing are based either on full scale morpholog-ical analysis (Kang :1995; Kim 1983; Lee 1995;Seo 1993) or on the syllabic patterns (Fujii 1993; Lee 1996; Ogawa 1993).
Morphological anal-ysis will return morphologically valid componentwords constituting a given compound word.
Sincethis method does not exclude invalid or meaning-less words, it can result in the degradatiou of pre-cision.
Besides the employment of full morpho-logical analysis is often too expensive and requirescostly maintenance.Simpler methods egment componnd nouns me-chanically into unigram or bigram words that areall regarded as index terms (Lee 1996).
Bigram in-dexes shows better precision than unigrams, butcan suffer from big index size.
In general, the ex-isting methods for compound noun analysis havebeen focused mainly on recall performance withlittle attention to the precision.
The work pre-sented in this paper t'ries to achieve the improve-ment of recall without the deterioration of preci-documentsDictionarya document making7?
"epiz!ng .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Compound noun .
.
.
.
.
.
.
.
.- idictionaries :single nouns .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
:compound nounsIndex weightinglweighted indicesFigure 1: Compound noun indexing.sion.3 Probab i l i s t i c  Compound NounI ndex ingIn this section, we describe the algorithm to rec-ognize and evaluate candidate index terms fromcompound nouns.
Figure 1 summarizes the algo-rithm.
The tokenizer produces a list of simple andcompound nouns by utilizing the noun dictionaryand the basic stermning rules.
The noun dictio-nary is used to identify whether a noun is simple orcompound, and the basic stemming rules are usedto differentiate non-final words from others suchas function words and verbs.
The noun dictio-nary is automatically constructed from the obser-w~tion on the document set.
The compound nounanalyzer inw:stigates if the components of com-pound nouns are appropriate as indexes.
The in-dex terrns that include simple nouns prodnced asa result of compound noun analysis are weighted,which finishes the indexing.l,et ?'
and C denote the sets of simple and com-pound nouns, respectively.
Simple nouns are, bydefinition, those that do not have any of theirsubstrings as a noun according to the dictionary.Compound nouns are those one or more sub-strings of which are recognized as nouns.
LetT = {7'l,7~,...,5/~} = EUC be the set of allsimple and compound nouns of a document set.Also, let I) = {D1,Du, .
.
.
,Dg}  be the set of alldocuments.
A document is represented as a list ofterm-weight (2~, Wi) pairs.For a compound noun Ci of a document, a de-525composit ion is a sequence of nouns (!T'~7~ ...Tk.
).lit inany cases, there are there than one  de('olll-position, but only a few of thenl are sensible withrespect o tim conte.xt of the document.
Indiscreetuse of the component nouns lnay bring about theimprovement of reall, but can lead to the signif-icant decrease of i)recision.
In the following dis-cussions, we dest;ril)e the details of the algor ithmto select useful coinponent nouns from eOliipoundHouns.3.1 Dict ionary |)uildu I)It is very difficult to provide an \[t{ systeni withthe suf\[icient list of \[iOtlllS.
tleeause the nomi-nals o/itnl l lnber {tnd grow faster than other cat-egories of words, it is more elticient to halidlenon-nominal  words mamlal ly.
We consider buihl.ing noun dictionary by identifying the remainingstring as a no/ill ai%er e l iminat ing non-llOiliil-lalpart  of a word.
The non-nominals  are verbs, ad-verbs, adjectives, prelixes, aud suf\[ixes.The words in non-nominal  dict ionaries do notinclude those that  can also be used as notins,whi(;h is not a probleni since unlike, in English,the lmllt i -eategorial  words in Korean telld to beinvariant of meaning.
The non-nonl inal  dict ionar-ies aye made usually hy manual work.Those recognized as non-nominal words but notas \[unction words are regarded as llOl.lns.
'\['herecan he mult ip le interpretat ions in segnienthig aword due to the ambigui ty  of fi inction words asi l lustrated in the following examp\]e.Wellcalo .
.
.
.  )
.
wenealo (reactor),wenca-t-lo (with atom)a tom?lNST 17~U MI';NTALOne way to deal with the probleni is to nsetim i)robabil ity of each function word and choosethe one with the highest vahie.
More accuratemeasure woukl be made using a t l idden MarkerModel that  is about a stochastic process of fun(>-l ion words.
'Fhe function words are (:lassified into32 groups according to their roles and posit ion insentences.
In part icular ,  each segmentat ion of aword is evahtated as follows.P(G IG- ,  ) P(n) l ' ( i l n )  ?P(Ci ICi  - 1) is the probabi l i ty  of tl~e function cat-egory of current word given the category of theprevious word.
P(n)  is the probabi l i ty  of candi-date noun and l ' ( f ln  ) is the prot)abi l i ty e ra  fun(>tion word given the candidate noun.
The best se-quence of these segmentat ions for a sentence canbe obtained.
The candidate nouns n of the bestsequence are then 'added to the noun dictionary.a.2 Token iz ing  and  eo ln i )ound nounanalysisTokenizing aims at recognizing simple and com-pound nouns froni a text and report ing them asthe the final index terms.
The method for di(-tio-nary making is also us('.d for tokenizing.
Since thed ict ionary making method gives a list; of candidatenouns, we only need to ctaeck if a candidate is aCOml)ound noun and judge if the eompotl(mts el"the candidate compound noun e~re consistent, withthe content of the deemneat,.To deal with the notion of consistency, we haveto deiiue tile nwaning of a term or a set o\[" terms,It is a well recognized practice to regard the dis-cr iminat ing power of a terln as the value of theterm.
The qual ity of the ( l iserini inating power isthe distr ibut ion of the tel'ill over a document set.We define the distr ibut ion of a terln as the Hleati..ing of the terin.
S imi lar ly the meaning of a set ofterms is the distr ibut ion of terms on the dec/anentset.l,et M be the d istr ibut ion of a term ~/i~ over adocument set l) = I)1 .
.
.
I).,~ snch thatJOn(" deiinit ion of 54(.)
lnay be as follows.f ,.,:q('/; , :)j ):)5) -= )_Zk Dk)For the case o\[' multi i) le terms:E- :  i' l 'he s imi lar i ty  t)etween two Lel'lTis (or sets o\["terms) can be defined as any of vector s imilar ityliieaslires.
The Ii leasllrl;ln(Hlt of relative infortua-lion of the two distril)utions corresponding to thetwo tertns Rives the distauce between the distri-t)utions.
Given two (l istri l)utions Mi and k4) for~l} and :1) respectively, tim discr iminat ion L() isdefined as follows (la;lahut, \[988).I--t M~.i=0 MjSince we want the diss imi lar i ty between two dis~tr ibutions, divergence that  is a symmetr ic  versionof d iser imhiat ion is nlore appropr iate  for our case.It is defined as follows (I}lahut, 1988)./;(M~, MS) = i.
(M~, a45) + /;(Ms, Md.I,'igure 2 i lhistrates the different distr ibut ions ()t'terms over tile same docl i lnel l t  set suggesting theusefulness of the distr ibut ions as the representa-tion of tim terms.
'\['he divergence ~(.)
gives abouttile itfforination (uncertainty)  el' the two dist.ributions as cornpared with each other, and \]las thefollowing characteristics.
* Tim more uniform the distril)ution is,the larger L(-) will be.o '\['lie lilOrO the two distr ibut ions agree,the less L(.)
will he.516D1 D2 D3 D4 ... Dnl" iDlre 2: llhistra.l,ioTi o~' tern\[ disl,ributions overth(,, S&TIIe (\]Oelllil("ltl, Sel,.The eh;:u'a, cl,erisi, ics are useful because good hi-.
(\[ex tcrtns should be less ilnil'orni a,n(\[ sltare sim-ihu' eoii|,exts with other terTils in a dOCTTlileUt.\]1l rids respect,, i\]l\]'Ol;illa, ;iOli l,heoreti(' niea.sTire isit\[ore eollerete and l,\]uis possibly It\[ore &(W.ilrai, et\[ia.ii w.)ellor siTnilarity Tileastircs.l"or e~-~(:h de( :o lnpos i t ion  ( ' / i , ' " , ' l ) )  o\[' a (:OtTT-l)OTUid IIOITTI Ck, whal, we want 1,o see is how dir-feren{, l, he deconiposed terTns and t, he doCTilUeUl,i,(;T'TTtS a.,'e.
Thai, is, / , ({r l} , .
- .
, ; l )} ,  Ds<)I.x'o~.cstile score of the imrt iculm ?
deceiT\[position.
D?h;tl,we select he.re is OIT(; decolllpOSitiOll wit, h th(: low--est diverg(;nce.
Let, l;iug ~v a n(\[ r '  denol,e a, t\[eeOlll-position and l;he I)esl, (leeoluposit, ion resl)eetive/y ,i7- ~ art  TlTin/)(r, \])k).T'l'i~e following SliiTiTii~tt'iZeS ttw l)roc(;(hlre o\[' ex-tra('t ing shnple TiOlll\]S \['roil  COl\[tl)ounct llOllltS.i .
I{.eiiTOVe iTon-nonliTta.\[ words ushig tiletTTel,ilod for d ie t ioT lary  Ilial,:itTg.2.
ldcni,ify cO\[ill)el\[lid iiOliiis llSillg liOitt-htM diel, iona.ry.3.
For (xtelt (t(~conlt)osit, on mi o1" a. COl\[l-pound IIOTIII (\]i, colnpul, e \]\](rf, D).4.
Select, "~i with the lowest L(ri, l)).3.3 h l ( lox  we ight ingThere are three well known liter, hods \[()1' weighl,-ing iiTde?
l:erius. '
l ' l iey are based oit the infor--T/l~t{iO/l of i l lverse (\[OCtlltteiit fre(tuency, (\]iscriliiht~t-l,ion wthi(;, a.nd l)rol)abilisi, c vMue (Sail,on 1{)88).It, turned ()tit i,\]iat i;hese \[no\[hods lead to simi-lar per\['orTn~mcc, bTll~ inverse docunient frequencyis by fax \[l ie shnplest of \[\[toni iit l;ei'uis of l;hne(x)i))ple?il,y ;-Hid r(.
'(iuire(l resollFt:(}s (Sa,lt,()li 1{)887I \[arT~i3At n 19<(J7).\]llverse (\]O(:lTittelll, t'reqTtelley lt iethod is alSOshown to work with l i t t le  t)erl'orrnanc(; varbtl, iona, cross (|\]\]l'ercnl, (\]onl<'.-tins.
For tllis r(~.IISOTT> we~MOl)tCd inverse (\]o(-ulnent fre(luency hi Liie cxi)er-inmllLS.
\[t is defined as follows.,,,,q --- ,~J:~.j ?
log(~/ )Tnl)le I: The prol)ortion of COiTiltOITitd iiOiillS inl, he 1000 sciettce a,I)st, ra('t .
At)oTil, ,()% o f  l ie\[i l lS aA'eCOITII)O1TIId TtOIITIS.ITO.
O~ tX.
)IIIt)OII(tlIt;S lt()TllLq ltrOl)ortion.
.
.
.
.
.
.
T -4~)639 90.55 ~-2 4665 8,50 %3 469 .85 %4 53 .09 %5 6 .01 (7owhere wij  is l, he weight, of' i;hc i'l.h LerTtl iu the.i'l.h doellllTeill,, ~*.7 is the \]llTiiii)er o\[" oc('llrreTl(x;s(if' l, he i'l,h l,erln hi l, he j ' th  (toeuliTenl,, and dfi isthe liliTiibcr of dOCTITIielTI, S hi which the i'i,li l,ernTOCCTlrD4 l , \ ]xper iments'l'hc goal o\[ experi lu<its is to vali&~t,e the proposed algoril, hnl for a.na.lyzing compo.ud nou.sby co|np;u' ing il, with the mmmal  a.nalysis and l, hebigranl lnel, hod.The l,esl, dal, a set consists of 1000 science a l)stra(:~,s writl.en in Kore~ul (Kitu 1.99d).
All nomiNals nix> manual ly  \[aleut\[fled and eoinpoul id ltoilliswere deconq)oscd into ~q)proprinte simple nounsby &t\[ expert in(lexcr.
In the iirst (;xp(;rit.ent,our proposed Mgoril,h|u is asked to do t,\]lc sa.nmtiring over the test (lnta., and retri(;wd perl'orImuwes ou 1.he two ttitf(;reut, ouL('om(:s (m~munllyimlexed and aul;olual;ically iudexed al)stracl;s) are('omparec\[.
lIT t, lw S,eCOTT(\[ exl)erinl(?lH,S, the l)er-f'orma.nc(~s o\[" the proposed m('tho(l and t)igramTttetb.o(I a.re eoutl);u:e(I to oloserve how Lit(; preci.sion is all'eel,cal.As is showu at t~d~le l, the portion o\['(:Ollll)OtltiditOlll/S iS at)oIIt; 9~/{) O\[" I;OI, M I\[OIlIIS \['()lind ill I;\[TC Lestset,, but.
(:ml TTtM?C critical eil>('l,s on tile retriewd\[)erforlila.tlee bec&llSe oN;ell COIIT\[)OtlII(I JIOIIIIS e&rryiT\[g n lore sl)eeili(" information become t,.
more a,e-(:llT'~l,t(': ill(it;,*( too \[.he dOCIllltC'lttS.Figure 3 and 'l'~tble 2 summarize the perforumnce of the indexing me.t.hods: mauuM nnMysis, tim propose(I i)rolmbilisl,ie method,  and thebigr~mi utet\[lod.
<\['lit; proposed mel, ho(l showeda slightly bct;ter peT'f()riilatlee (around 3%) - 4(~J)them nlmnlM indexing or bigr~mi tilde?trig.
How-ever, otir method lifts wa.s il\]ore e\[lieient than t)igi'a, lit indexing in l, errns o\[' the llUli~ber o\[' inde~xLerlliS mid ti~e ~werage iilllTii)er of retrieved doeu-ltietltS per ~ query.The ~tverage anlbiguity of a col i lpoi/ l id i lol i ltis 1.43, and this low anibiguity niust ha.re eon-l;ributed l,o tile iiigli &grecnlent rat io of tile \]pro-posed indexing; method with l i l&li l l&l indexing.Tim low ~mibiguil, y is pari, ly ~tl, ixibuted 1;o thellOTlli d ict ionary that has 11o iiTilleeessa+ry entries57_7Recall Man.
Prob.
Big.
No Anal.0.00 0.871.9 0.8579 0.8406 0.79570.10 0.7719 0.7587 0.7841 0.64550.20 0.7122 0.6981 0.6812 0.58940.30 0.5895 0.6312 0.5939 0.49310.40 0.5458 0.5854 0.5637 0.41030.50 0.4957 0.5287 0.5240 0.36460.60 0.4272 0.4438 0.4370 0.28440.70 0.3304 0.3665 0.3322 0.23110.80 0.2552 0.2876 0.2569 0.16950.90 0.2102 0.2280!0.2028 0.09001.00 0.1428 0.1724 0.1600 0.0514:Table 2: Performance of Manual, Prob., and Bi-gram Indexing0.9 , i!
i "Manual" ~- -!
"P roba~i t l s t i c "  -4--.0.8  ~ .
.
.
.
.
.
.
.
.
.
.
.
.
~ i .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
i .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
"Btgram ~ , o - -?
'~ I .
.
.
.X. "
'5 , " ,  ~,.0 0.2 0.4 0.6 0,8 iFigure 3: Recall-Preeison curve of indexing meth-odsnot found at the documents.5 Conc lus ionThe compound analysis in automatic indexingaims at the improvement of recall performanceby extracting useful component nouns fi'om com-pound nouns.
The task for Korean texts requiresextra efforts due to the complexity of inflections.The proposed method gives better potential ofsustaining the precision while improving the recallthan other approaches by making use of proba-bilistic distributions ofterms as the representationof meaning of the terms.The proposed method to evaluate the coinpo-nents of compound nouns is unique in that it de-lines and uses term representation, which explainsthe superiority of the method to other methods.The method requires little human involvementand is very promising for the implementation fpractical systems by achieving efficiency and ac-curacy at the same time.Re ferencesBlahut, Richard E. (1987).
Principles and Prac-tice of Information Theory.
Addison-Wesley.Fagan, J. L. (1989).
The effectiveness ofa Nonsyn-tactic Approach to Automatic Phrase Indexingfor Document Retrieval, Journal of AmericanSociety for Information Science, Vol.
40, No.
2.iIarman, D. (1992).
"Ranking Algorithms" in In-formation Retrieval: Data Slructure and Algo-rithms, (Frakes, W. B., and Baeza-Yates, R.ed.)
Prentice Hall.Fujii, lI., and Croft, W. B.
(1993).
"A compar-ison of indexing techniques for Japanese textretrieval," In Proceedings of 16'th ACM SIGIRConference.Kang, S. S. (1995).
"Role of Morphological Anal-ysis for Korean Automatic Indexing,", In Pro-ceedings of the 22rid Korea Information ScienceSociety Conference.Kim, Y.
It.
(1983).
Automatic Indexing System ofKorean .Texts mixed with Chinese and EnglishM.S.
Thesis, Dept.
of Computer Science, KoreaAdvanced Institute of Science and Technology.Kim, S. H. (1994).
A Development of the 'l~stCollection for Estim~ting the Retrieval Perfor-mance of an Automatic Indexer, Journal of Ko-rea Information Management Society, Vol.
11,No.
1.Lee, J. lI.
(1996).
"n-Gram-Based Indexing forEffective Retrieval of Korean Texts," In Pro-ceedings of 1st Australian Document Comput-ing Symposium 1996Lee, It.
A.
(1995).
"Implementation f an IndexingSystem Based on Korean Morpheme StructuralRules,", In Proceedings of Spring Conference ofKorea Information Science Society.Ogawa Y.
(1993).
"Simple word strings as corn-pound keywords: An indexing and rankingmethod for Japanese texts,", In Proceedings of16'th ACM SIGIR Conference.Salt;on, G., and McGill M. J.
(1983).
Introductionlo Modern Information Retrieval McGraw-HillInc.Salton, G., and Buckey, C. (1988).
Term Weight--ing Approaches in Automatic Text P~etrieval,lnformalion Processing 2~ and Management,Vol.
24, No.
5.Seo, E. K. (1993).
An Experiment in AutomaticIndexing with Korean Texts: A Comparisonof Syntactico-Statistical and Manual Methods,Journal of Korea Information Managemenl So-ciety, Vol.
10, No.
1.518
