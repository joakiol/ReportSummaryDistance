Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 65?74,Atlanta, Georgia, 14 June 2013. c?2013 Association for Computational LinguisticsSentiment Analysis in Czech Social Media Using Supervised MachineLearningIvan HabernalNTIS ?
New Technologiesfor the Information Society,Faculty of Applied Sciences,University of West Bohemia,Univerzitn??
8, 306 14 Plzen?Czech Republichabernal@kiv.zcu.czToma?s?
Pta?c?ekDepartment of ComputerScience and Engineering,Faculty of Applied SciencesUniversity of West Bohemia,Univerzitn??
8, 306 14 Plzen?Czech Republictigi@kiv.zcu.czJosef SteinbergerNTIS ?
New Technologiesfor the Information Society,Faculty of Applied Sciences,University of West Bohemia,Univerzitn??
8, 306 14 Plzen?Czech Republicjstein@kiv.zcu.czAbstractThis article provides an in-depth research ofmachine learning methods for sentiment ana-lysis of Czech social media.
Whereas in En-glish, Chinese, or Spanish this field has along history and evaluation datasets for vari-ous domains are widely available, in case ofCzech language there has not yet been anysystematical research conducted.
We tacklethis issue and establish a common ground forfurther research by providing a large human-annotated Czech social media corpus.
Fur-thermore, we evaluate state-of-the-art super-vised machine learning methods for sentimentanalysis.
We explore different pre-processingtechniques and employ various features andclassifiers.
Moreover, in addition to our newlycreated social media dataset, we also report re-sults on other widely popular domains, suchas movie and product reviews.
We believethat this article will not only extend the currentsentiment analysis research to another familyof languages, but will also encourage competi-tion which potentially leads to the productionof high-end commercial solutions.1 IntroductionSentiment analysis has become a mainstream re-search field in the past decade.
Its impact can beseen in many practical applications, ranging fromanalyzing product reviews (Stepanov and Riccardi,2011) to predicting sales and stock markets using so-cial media monitoring (Yu et al 2013).
The users?opinions are mostly extracted either on a certain po-larity scale, or binary (positive, negative); variouslevels of granularity are also taken into account, e.g.,document-level, sentence-level, or aspect-based sen-timent (Hajmohammadi et al 2012).Most of the research in automatic sentiment ana-lysis of social media has been performed in Englishand Chinese, as shown by several recent surveys,i.e., (Liu and Zhang, 2012; Tsytsarau and Palpanas,2012).
For Czech language, there have been veryfew attempts, although the importance of sentimentanalysis of social media became apparent, i.e., dur-ing the recent presidential elections 1.
Many Czechcompanies also discovered a huge potential in socialmedia marketing and started launching campaigns,contests, and even customer support on Facebook?the dominant social network of the Czech onlinecommunity with approximately 3.5 million users.2However, one aspect still eludes many of them: au-tomatic analysis of customer sentiment of products,services, or even a brand or a company name.
Inmany cases, sentiment is still labeled manually, ac-cording to our information from one of the leadingCzech companies for social media monitoring.Automatic sentiment analysis in the Czech envi-ronment has not yet been thoroughly targeted by theresearch community.
Therefore it is necessary tocreate a publicly available labeled dataset as well asto evaluate the current state of the art for two rea-sons.
First, many NLP methods must deal with highflection and rich syntax when processing the Czechlanguage.
Facing these issues may lead to novel1http://www.mediaguru.cz/2013/01/analyza-facebook-rozhodne-o-volbe-prezidenta/ [inCzech]2http://www.czso.cz/csu/redakce.nsf/i/uzivatele facebooku [in Czech]65approaches to sentiment analysis as well.
Second,freely accessible and well-documented datasets, asknown from many shared NLP tasks, may stimulatecompetition which usually leads to the production ofcutting-edge solutions.3This article focuses on document-level sentimentanalysis performed on three different Czech datasetsusing supervised machine learning.
As the firstdataset, we created a Facebook corpus consistingof 10,000 posts.
The dataset was manually la-beled by two annotators.
The other two datasetscome from online databases of movie and prod-uct reviews, whose sentiment labels were derivedfrom the accompanying star ratings from users ofthe databases.
We provide all these labeled datasetsunder Creative Commons BY-NC-SA licence4at http://liks.fav.zcu.cz/sentiment ,together with the sources for all the presented exper-iments.The rest of this article is organized as follows.Section 2 examines the related work with a focuson the Czech research and social media.
Section 3thoroughly describes the datasets and the annotationprocess.
In section 4, we list the employed featuresand describe our approach to classification.
Finally,section 5 contains the results with a thorough discus-sion.2 Related workThere are two basic approaches to sentiment ana-lysis: dictionary-based and machine learning-based.While dictionary-based methods usually depend ona sentiment dictionary (or a polarity lexicon) and aset of handcrafted rules (Taboada et al 2011), ma-chine learning-based methods require labeled train-ing data that are later represented as features andfed into a classifier.
Recent attempts have also in-vestigated semi-supervised methods that incorporateauxiliary unlabeled data (Zhang et al 2012).3E.g., named entity recognition based on Conditional Ran-dom Fields emerged from CoNLL-2003 named entity recogni-tion shared task.4http://creativecommons.org/licenses/by-nc-sa/3.0/2.1 Supervised machine learning for sentimentanalysisThe key point of using machine learning for senti-ment analysis lies in engineering a representative setof features.
Pang et al(2002) experimented withunigrams (presence of a certain word, frequencies ofwords), bigrams, part-of-speech (POS) tags, and ad-jectives on a Movie Review dataset.
Martineau andFinin (2009) tested various weighting schemes forunigrams based on TFIDF model (Manning et al2008) and proposed delta weighting for a binary sce-nario (positive, negative).
Their approach was laterextended by Paltoglou and Thelwall (2010) who pro-posed further improvement in delta TFIDF weight-ing.The focus of the current sentiment analysis re-search is shifting towards social media, mainly tar-geting Twitter (Kouloumpis et al 2011; Pak andParoubek, 2010) and Facebook (Go et al 2009;Ahkter and Soria, 2010; Zhang et al 2011; Lo?pez etal., 2012).
Analyzing media with very informal lan-guage benefits from involving novel features, suchas emoticons (Pak and Paroubek, 2010; Montejo-Ra?ez et al 2012), character n-grams (Blamey et al2012), POS and POS ratio (Ahkter and Soria, 2010;Kouloumpis et al 2011), or word shape (Go et al2009; Agarwal et al 2011).In many cases, the gold data for training and test-ing the classifiers are created semi-automatically, asin, e.g., (Kouloumpis et al 2011; Go et al 2009;Pak and Paroubek, 2010).
In the first step, randomsamples from a large dataset are drawn according topresence of emoticons (usually positive and nega-tive) and are then filtered manually.
Although largehigh-quality collections can be created very quicklyusing this approach, it makes a strong assumptionthat every positive or negative post must contain anemoticon.Balahur and Tanev (2012) performed experimentswith Twitter posts as part of the CLEF 2012 Re-pLab5.
They classified English and Spanish tweetsby a small but precise lexicon, which contained alsoslang, combined with a set of rules that capture themanner in which sentiment is expressed in socialmedia.5http://www.limosine-project.eu/events/replab201266Since the limited space of this paper does not al-low us to present detailed evaluation from the relatedwork, we recommend an in-depth survey by Tsytsa-rau and Palpanas (2012) for actual results obtainedfrom the abovementioned methods.2.2 Sentiment analysis in Czech environmentVeselovska?
et al(2012) presented an initial researchon Czech sentiment analysis.
They created a corpuswhich contains polarity categories of 410 news sen-tences.
They used the Naive Bayes classifier anda classifier based on a lexicon generated from an-notated data.
The corpus is not publicly available,moreover, due to the small size of the corpus nostrong conclusions can be drawn.Steinberger et al(2012) proposed a semi-automatic ?triangulation?
approach to creating sen-timent dictionaries in many languages, includingCzech.
They first produced high-level gold-standardsentiment dictionaries for two languages and thentranslated them automatically into the third lan-guage by a state-of-the-art machine translation ser-vice.
Finally, the resulting sentiment dictionarieswere merged by taking overlap from the two auto-matic translations.A multilingual parallel news corpus annotatedwith opinions towards entities was presented in(Steinberger et al 2011).
Sentiment annotationswere projected from one language to several others,which saved annotation time and guaranteed compa-rability of opinion mining evaluation results acrosslanguages.
The corpus contains 1,274 news sen-tences where an entity (the target of the sentimentanalysis) occurs.
It contains 7 languages includingCzech.
Their research targets fundamentally differ-ent objectives from our research as they focus onnews media and aspect-based sentiment analysis.3 Datasets3.1 Social media datasetThe initial selection of Facebook brand pages for ourdataset was based on the ?top?
Czech pages, accord-ing to the statistics from SocialBakers.6 We focusedon pages with a large Czech fan base and a sufficientnumber of Czech posts.
Using Facebook Graph API6http://www.socialbakers.com/facebook-pages/brands/czech-republic/and Java Language Detector7 we acquired 10,000random posts in the Czech language from nine dif-ferent Facebook pages.
The posts were then com-pletely anonymized as we kept only their textualcontents.Sentiment analysis of posts at Facebook brandpages usually serves as a marketing feedback of useropinions about brands, services, products, or currentcampaigns.
Thus we consider the sentiment targetto be the given product, brand, etc.
Typically, users?complaints hold negative sentiment, whereas joy orhappiness about the brand is taken as positive.
Wealso added another class called bipolar which rep-resents both positive and negative sentiment in onepost.8 In some cases, the user?s opinion, althoughbeing somehow positive, does not relate to the givenpage.9 Therefore the sentiment is treated as neutralin these cases, according to our above-mentioned as-sumption.The complete 10k dataset was independently an-notated by two annotators.
The inter-annotatoragreement (Cohen?s ?)
between these two anno-tators reaches 0.66 which represents a substantialagreement level (Pustejovsky and Stubbs, 2013),therefore the task can be considered as well-defined.The gold data were created based on the agree-ment of the two annotators.
They disagreed in2,216 cases.
To solve these conflicts, we involveda third super-annotator to assign the final sentimentlabel.
However, even after the third annotator?s la-beling, there was still no agreement for 308 labels.These cases were later solved by a fourth annotator.We discovered that most of these conflicting caseswere classified as either neutral or bipolar.
Theseposts were often difficult to label because the authorused irony, sarcasm or the context or previous posts.These issues remain open.The Facebook dataset contains of 2,587 positive,5,174 neutral, 1,991 negative, and 248 bipolar posts,respectively.
We ignore the bipolar class later in allexperiments.
The sentiment distribution among the7http://code.google.com/p/jlangdetect/8For example ?to bylo moc dobry ,fakt jsem se nadlabla :-Dskoda ze uz neni v nabidce??
?It was very tasty, I really stuffedmyself :-D sad it?s not on the menu anymore?.9Certain campaigns ask the fans for, i.e., writing a poem?these posts are mostly positive (or funny, at least) but are irrele-vant for the desired task.67source pages is shown in Figure 1.
The statisticsreveal negative opinions towards cell phone oper-ators and positive opinions towards, e.g., perfumesand ZOO.Figure 1: Social media dataset statistics3.2 Movie review datasetMovie reviews as a corpus for sentiment analysishas been used in research since the pioneering re-search conducted by Pang et al(2002).
Thereforewe covered the same domain in our experiments aswell.
We downloaded 91,381 movie reviews fromthe Czech Movie Database10 and split them into 3categories according to their star rating (0?2 stars asnegative, 3?4 stars as neutral, 5?6 stars as positive).The dataset contains of 30,897 positive, 30,768 neu-tral, and 29,716 negative reviews, respectively.3.3 Product review datasetAnother very popular domain for sentiment analy-sis deals with product reviews (Hu and Liu, 2004).We crawled all user reviews from a large Czech e-shop Mall.cz11 which offers a wide range of prod-ucts.
The product reviews are accompanied with starratings on the scale 0?5.
We took a different strat-egy for assigning sentiment labels.
Whereas in themovie dataset the distribution of stars was rather uni-form, in the product review domain the ratings wereskewed towards the higher values.
After a manualinspection we discovered that 4-star ratings mostlycorrespond to neutral opinions and 3 or less stars de-note mostly negative comments.
Thus we split the10http://www.csfd.cz/11http://www.mall.czdataset into three categories according to this obser-vation.
The final dataset consists of 145,307 posts(102,977 positive, 31,943 neutral, and 10,387 nega-tive).4 Classification4.1 PreprocessingAs pointed out by Laboreiro et al(2010), tokeniza-tion significantly affects sentiment analysis, espe-cially in case of social media.
Although Ark-tweet-nlp tool (Gimpel et al 2011) was developed andtested in English, it yields satisfactory results inCzech as well, according to our initial experimentson the Facebook corpus.
Its significant feature isproper handling of emoticons and other special char-acter sequences that are typical for social media.Furthermore, we remove stopwords using the stop-word list from Apache Lucene project.12In many NLP applications, a very popular pre-processing technique is stemming.
We tested Czechlight stemmer (Dolamic and Savoy, 2009) and HighPrecision Stemmer13.
Another widely-used methodfor reducing the vocabulary size, and thus the featurespace, is lemmatization.
For Czech language theonly currently available lemmatizer is shipped withPrague Dependency Treebank (PDT) toolkit (Hajic?et al 2006).
However, we use our in-house JavaHMM-based implementation using the PDT train-ing data as we need a better control over each pre-processing step.Part-of-speech tagging is done using our in-houseJava solution that exploits Prague Dependency Tree-bank (PDT) data as well.
However, since PDT istrained on news corpora, we doubt it is suitable fortagging social media that are written in very infor-mal language (consult, i.e., (Gimpel et al 2011)where similar issues were tackled in English).Since the Facebook dataset contains a huge num-ber of grammar mistakes and misspellings (typ-ically ?i/y?,?e?/je/ie?, and others), we incorporatedphonetic transcription to International Phonetic Al-phabet (IPA) in order to reduce the effect of thesemistakes.
We rely on eSpeak14 implementation.
An-12http://lucene.apache.org/core/13Publication pending; please visithttp://liks.fav.zcu.cz/HPS/.14http://espeak.sourceforge.net68Pipe 1 Pipe 2 Pipe 3TokenizingArkTweetNLPPOS taggingPDTStem (S) Lemma (L)none (n) PDT (p)light (l)HPS (h)StopwordsremoveCasing (C) Phonetic (P) ?keep (k) eSpeak (e)lower (l)Table 1: The preprocessing pipes (top-down).
Variouscombinations of methods can be denoted using the ap-propriate labels, e.g.
?SnCk?
means 1. tokenizing, 2.POS-tagging, 3. no stemming, 4. removing stopwords,and 5. no casing, or ?Lp?
means 1. tokenizing, 2.
POS-tagging, 3. lemmatization using PDT, and 4. removingstopwords.other preprocessing step might involve removing di-acritics, as many Czech users type only using unac-cented characters.
However, posts without diacriticsrepresent only about 8% of our datasets, thus we de-cided to keep diacritics unaffected.The complete preprocessing diagram and its vari-ants is depicted in Table 1.
Overall, there are 10possible preprocessing ?pipe?
configurations.4.2 FeaturesN-gram features We use presence of unigramsand bigrams as binary features.
The feature space ispruned by minimum n-gram occurrence which wasempirically set to 5.
Note that this is the baselinefeature in most of the related work.Character n-gram features Similarly to the wordn-gram features, we added character n-gram fea-tures, as proposed by, e.g., (Blamey et al 2012).
Weset the minimum occurrence of a particular charac-ter n-gram to 5, in order to prune the feature space.Our feature set contains 3-grams to 6-grams.POS-related features Direct usage of part-of-speech n-grams that would cover sentiment patternshas not shown any significant improvement in the re-lated work.
Still, POS tags provide certain character-istics of a particular post.
We implemented variousPOS features that include, e.g., the number of nouns,verbs, and adjectives (Ahkter and Soria, 2010), theratio of nouns to adjectives and verbs to adverbs(Kouloumpis et al 2011), and number of negativeverbs.Emoticons We adapted the two lists of emoticonsthat were considered as positive and negative from(Montejo-Ra?ez et al 2012).
The feature capturesnumber of occurrences of each class of emoticonswithin the text.Delta TFIDF variants for binary scenarios Al-though simple binary word features (presence of acertain word) reach surprisingly good performance,they have been surpassed by various TFIDF-basedweighting, such as Delta TFIDF (Martineau andFinin, 2009), or Delta BM25 TFIDF (Paltoglou andThelwall, 2010).
Delta-TFIDF still uses traditionalTFIDF word weighting but treats positive and nega-tive documents differently.
However, all the exist-ing related works which use this kind of featuresdeal only with binary decisions (positive/negative),thus we filtered out neutral documents from thedatasets.15 We implemented the most promisingweighting schemes from (Paltoglou and Thelwall,2010), namely Augmented TF, LogAve TF, BM25TF, Delta Smoothed IDF, Delta Prob.
IDF, DeltaSmoothed Prob.
IDF, and Delta BM25 IDF.4.3 ClassifiersAll evaluation tests were performed using two clas-sifiers, Maximum Entropy (MaxEnt) and SupportVector Machines (SVM).
Although Naive Bayesclassifier is also widely used in the related work, wedid not include it as it usually performs worse thanSVM or MaxEnt.
We used a pure Java frameworkfor machine learning16 with default settings (linearkernel for SVM).5 ResultsFor each combination from the preprocessingpipeline (refer to Table 1) we assembled various setsof features and employed two classifiers.
In the first15Opposite to leave-one-out cross validation in (Paltoglouand Thelwall, 2010), we still use 10-fold cross validation in allexperiments.16http://liks.fav.zcu.cz/ml69scenario, we classify into all three classes (positive,negative, and neutral).17 In the second scenario,we follow a strand of related research, e.g., (Mar-tineau and Finin, 2009; Celikyilmaz et al 2010),that deals only with positive and negative classes.For these purposes we filtered out all the neutral doc-uments from the datasets.
Furthermore, in this sce-nario we evaluate only features based on weighteddelta-TFIDF, as, e.g., in (Paltoglou and Thelwall,2010).
We also involved only MaxEnt classifier intothe second scenario.All tests were conducted in the 10-fold cross val-idation manner.
We report macro F-measure, asit allows comparing classifier results on differentdatasets.
Moreover, we do not report micro F-measure (accuracy) as it tends to prefer performanceon dominant classes in highly unbalanced datasets(Manning et al 2008), which is, e.g., the case ofour Product Review dataset where most of the labelsare positive.5.1 Social mediaTable 2 shows the results for the 3-class classifica-tion scenario on the Facebook dataset.
The row la-bels denote the preprocessing configuration accord-ing to Table 1.
In most cases, maximum entropyclassifier significantly outperforms SVM.
The com-bination of all features (the last column) yields thebest results regardless to the preprocessing steps.The reason might be that the involved character n-gram feature captures subtle sequences which repre-sent subjective punctuation or emoticons, that werenot covered by the emoticon feature.
On average,the best results were obtained when HPS stemmerand lowercasing or phonetic transcription were in-volved (lines ShCl and ShPe).
This configurationsignificantly outperforms other preprocessing tech-niques for token-based features (see column Unigr+ bigr + POS + emot.
).In the second scenario we evaluated variousTFIDF weighting schemes for binary sentimentclassification.
The results are shown in Table 3.The three-character notation consists of term fre-quency, inverse document frequency, and normal-ization.
Due to a large number of possible combi-nations, we report only the most successful ones,17We ignore the bipolar posts in the current research.namely Augmented?a and LogAve?L term fre-quency, followed by Delta Smoothed??(t?
), DeltaSmoothed Prob.??(p?
), and Delta BM25??
(k)inverse document frequency; normalization was notinvolved.
We can see that the baseline (the first col-umn bnn) is usually outperformed by any weightedTFIDF technique.
Moreover, using any kind ofstemming (the row entitled various*) significantlyimproves the results.
For the exact formulas of thedelta TFIDF variants please refer to (Paltoglou andThelwall, 2010).We also tested the impact of TFIDF word fea-tures when added to other features from the first sce-nario (refer to Table 2).
Column FS1 in Table 3 dis-plays results for a feature set with the simple binarypresence-of-the-word feature (binary unigrams).
Inthe last column FS2 we replaced this binary featurewith TFIDF weighted feature a?(t?)n.
It turned outthat the weighed form of word feature does not im-prove the performance, when compared with sim-ple binary unigram feature.
Furthermore, a set ofdifferent features (words, bigrams, POS, emoticons,character n-grams) significantly outperforms a sin-gle TFIDF weighted feature.We also report the effect of the dataset size onthe performance.
We randomly sampled 10 subsetsfrom the dataset (1k, 2k, etc.)
and tested the per-formance; still using 10-fold cross validation.
Wetook the most promising preprocessing configura-tion (ShCl) and MaxEnt classifier.
As can be seen inFigure 2, while the dataset grows to approx 6k?7kitems, the performance rises for most combinationsof features.
At 7k-items dataset, the performancebegins to reach its limits for most combinations offeatures and hence adding more data does not leadto a significant improvement.5.1.1 Upper limits of automatic sentimentanalysisTo see the upper limits of the task itself, we alsoevaluate the annotator?s judgments.
Although thegold labels were chosen after a consensus of at leasttwo people, there were many conflicting cases thatmust have been solved by a third or even a fourthperson.
Thus even the original annotators do notachieve 1.00 F-measure on the gold data.We present ?performance?
results of both annota-tors and of the best system as well (MaxEnt classi-70Facebook dataset, 3 classesUnigrams Unigr + bigrams Unigr + bigr + Unigr + bigr + Unigr + bigr + POS +POS features POS + emot.
emot.
+ char n-gramsMaxEnt SVM MaxEnt SVM MaxEnt SVM MaxEnt SVM MaxEnt SVMSnCk 0.63 0.64 0.63 0.64 0.66 0.64 0.66 0.64 0.69 0.67SnCl 0.63 0.64 0.63 0.64 0.66 0.63 0.66 0.63 0.69 0.68SlCk 0.65 0.67 0.66 0.67 0.68 0.66 0.67 0.66 0.69 0.67SlCl 0.65 0.67 0.65 0.67 0.68 0.66 0.69 0.66 0.69 0.67ShCk 0.66 0.67 0.66 0.67 0.68 0.67 0.67 0.67 0.69 0.67ShCl 0.66 0.66 0.66 0.67 0.69 0.67 0.69 0.67 0.69 0.67SnPe 0.64 0.65 0.64 0.65 0.67 0.65 0.67 0.65 0.68 0.68SlPe 0.65 0.67 0.65 0.67 0.68 0.67 0.67 0.66 0.68 0.67ShPe 0.66 0.67 0.66 0.67 0.69 0.66 0.69 0.66 0.68 0.67Lp 0.64 0.65 0.63 0.65 0.67 0.64 0.67 0.65 0.68 0.67Table 2: Results on the Facebook dataset, classification into 3 classes.
Macro F-measure, 95% confidence interval= ?0.01.
Bold numbers denote the best results.Facebook dataset, positive and negative classes onlybnn a?(t?
)n a?(p?
)n a?
(k)n L?(t?
)n L?(p?
)n L?
(k)n FS1 FS2SnCk 0.83 0.86 0.86 0.86 0.85 0.86 0.86 0.90 0.89SnCl 0.84 0.86 0.86 0.86 0.86 0.86 0.86 0.90 0.90various* 0.85 0.88 0.88 0.88 0.88 0.88 0.88 0.90 0.90SnPe 0.84 0.86 0.86 0.86 0.86 0.86 0.86 0.90 0.90Lp 0.84 0.86 0.85 0.85 0.86 0.86 0.86 0.88 0.88* same results for ShCk, ShCl, SlCl, SlPe, SlCk, and ShPeFS1: Unigr + bigr + POS + emot.
+ char n-gramsFS2: a?(t?
)n + bigr + POS + emot.
+ char n-gramsTable 3: Results on the Facebook dataset for various TFIDF-weighted features, classification into 2 classes.
Macro F-measure, 95% confidence interval = ?0.01.
Underlined numbers show the best results for TFIDF-weighted features.Bold numbers denote the best overall results.Figure 2: Performance wrt.
data size.
Using ShCl pre-processing and MaxEnt classifier.fier, all features, ShCl preprocessing).
Table 4 showsthe results as confusion matrices.
For each class(p?positive, n?negative, 0?neutral) we also re-port precision, recall, and F-measure.
The row head-ings denote gold labels, the column headings repre-sent values assigned by the annotators or the sys-tem.18 The annotators?
results show what can be ex-pected from a ?perfect?
system that would solve thetask the way a human would.In general, both annotators judge all three classeswith very similar F-measure.
By contrast, the sys-tem?s F-measure is very low for negative posts (0.54vs.
?
0.75 for neutral and positive).
We offer thefollowing explanation.
First, many of the negativeposts surprisingly contain happy emoticons, which18Even though the task has three classes, the annotators alsoused ?b?
for ?bipolar and ???
for ?cannot decide?.71Annotator 10 n p ?
b P R Fm0 4867 136 115 2 54 .93 .94 .93n 199 1753 6 0 33 .93 .88 .90p 175 6 2376 0 30 .95 .92 .93Macro Fm: .92Annotator 20 n p ?
b P R Fm0 4095 495 573 3 8 .95 .79 .86n 105 1878 6 0 2 .79 .94 .86p 100 12 2468 3 4 .81 .95 .88Macro Fm: .86Best system0 n p P R Fm0 4014 670 490 .74 .78 .76n 866 1027 98 .57 .52 .54p 563 102 1922 .77 .74 .75Macro Fm: .69Table 4: Confusion matrices for three-class classification.
?Best system?
configuration: all features (unigram, bi-gram, POS, emoticons, character n-grams), ShCl prepro-cessing, and MaxEnt classifier.
95% confidence interval= ?0.01.could be a misleading feature for the classifier.
Sec-ond, the language of the negative posts in not as ex-plicit as for the positive ones in many cases; the neg-ativity is ?hidden?
in irony, or in a larger context (i.e.,?Now I?m sooo satisfied with your competitor :))?
).This remains an open issue for the future research.5.2 Product and movie reviewsFor the other two datasets, the product reviews andmovie reviews, we slightly changed the configura-tion.
First, we removed the character n-grams fromthe feature sets, otherwise the feature space wouldbecome too large for feasible computing.
Second,we abandoned SVM as it became computationallyinfeasible for such a large datasets.Table 5 (left-hand part) presents results on theproduct reviews.
The combination of unigrams andbigrams works best, almost regardless of the prepro-cessing.
By contrast, POS features rapidly decreasethe performance.
We suspect that POS features donot carry any useful information in this case and byintroducing a lot of ?noise?
they cause that the op-timization function in the MaxEnt classifier fails tofind a global minimum.In the right-hand part of Table 5 we can see theresults on the movie reviews.
Again, the bigram fea-ture performs best, paired with combination of HPSstemmer and phonetic transcription (ShPe).
AddingPOS-related features causes a large drop in perfor-mance.
We can conclude that for larger texts, thebigram-based feature outperforms unigram featuresand, in some cases, a proper preprocessing may fur-ther significantly improve the results.6 ConclusionThis article presented an in-depth research of super-vised machine learning methods for sentiment ana-lysis of Czech social media.
We created a largeFacebook dataset containing 10,000 posts, accom-panied by human annotation with substantial agree-ment (Cohen?s ?
0.66).
The dataset is freely avail-able for non-commercial purposes.19 We thoroughlyevaluated various state-of-the-art features and clas-sifiers as well as different language-specific prepro-cessing techniques.
We significantly outperformedthe baseline (unigram feature without preprocess-ing) in three-class classification and achieved F-measure 0.69 using a combination of features (un-igrams, bigrams, POS features, emoticons, charac-ter n-grams) and preprocessing techniques (unsu-pervised stemming and phonetic transcription).
Inaddition, we reported results in two other domains(movie and product reviews) with a significant im-provement over the baseline.To the best of our knowledge, this article is theonly of its kind that deals with sentiment analysisin Czech social media in such a thorough manner.Not only it uses a dataset that is magnitudes largerthan any from the related work, but also incorporatesstate-of-the-art features and classifiers.
We believethat the outcomes of this article will not only helpto set the common ground for sentiment analysis forthe Czech language but also help to extend the re-search outside the mainstream languages in this re-search field.AcknowledgementThis work was supported by grant no.
SGS-2013-029 Advanced computing and information19We encourage other researchers to download our datasetfor their research in the sentiment analysis field.72Product reviews, 3 classes Movie reviews, 3 classesFS1 FS2 FS3 FS4 FS1 FS2 FS3 FS4SnCk 0.70 0.74 0.52 0.49 0.76 0.77 0.71 0.61SnCl 0.71 0.75 0.51 0.52 0.76 0.77 0.71 0.70SlCk 0.67 0.75 0.59 0.55 0.78 0.78 0.73 0.72SlCl 0.67 0.75 0.56 0.57 0.78 0.78 0.71 0.71ShCk 0.67 0.75 0.57 0.57 0.78 0.78 0.74 0.72ShCl 0.67 0.74 0.55 0.57 0.77 0.78 0.73 0.73SnPe 0.69 0.74 0.50 0.55 0.77 0.78 0.69 0.72SlPe 0.67 0.75 0.55 0.57 0.78 0.78 0.73 0.73ShPe 0.68 0.74 0.56 0.59 0.78 0.79 0.74 0.73Lp 0.66 0.75 0.56 0.57 0.77 0.77 0.68 0.70Table 5: Results on the product and movie review datasets, classification into 3 classes.
FSx denote different featuresets.
FS1 = Unigrams; FS2 = Uni + bigrams; FS3 = Uni + big + POS features; FS4 = Uni + big + POS + emot.
MacroF-measure, 95% confidence interval ?0.002 (products), ?0.003 (movies).
Bold numbers denote the best results.systems and by the European Regional Develop-ment Fund (ERDF), project ?NTIS - New Tech-nologies for Information Society?, European Cen-ter of Excellence, CZ.1.05/1.1.00/02.0090.
Theaccess to computing and storage facilities ownedby parties and projects contributing to the Na-tional Grid Infrastructure MetaCentrum, providedunder the programme ?Projects of Large Infrastruc-ture for Research, Development, and Innovations?
(LM2010005) is highly acknowledged.ReferencesApoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow,and Rebecca Passonneau.
2011.
Sentiment analysisof twitter data.
In Proceedings of the Workshop onLanguages in Social Media, LSM ?11, pages 30?38,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Julie Kane Ahkter and Steven Soria.
2010.
Sentimentanalysis: Facebook status messages.
Technical report,Stanford University.
Final Project CS224N.Alexandra Balahur and Hristo Tanev.
2012.
Detectingentity-related events and sentiments from tweets us-ing multilingual resources.
In Proceedings of the 2012Conference and Labs of the Evaluation Forum Infor-mation Access Evaluation meets Multilinguality, Mul-timodality, and Visual Analytics.Ben Blamey, Tom Crick, and Giles Oatley.
2012.
R U: -) or : -( ?
character- vs. word-gram feature selec-tion for sentiment classification of OSN corpora.
InProceedings of AI-2012, The Thirty-second SGAI In-ternational Conference on Innovative Techniques andApplications of Artificial Intelligence, pages 207?212.Springer.A.
Celikyilmaz, D. Hakkani-Tu?r, and Junlan Feng.
2010.Probabilistic model-based sentiment analysis of twit-ter messages.
In Spoken Language Technology Work-shop (SLT), 2010 IEEE, pages 79?84.
IEEE.Ljiljana Dolamic and Jacques Savoy.
2009.
Indexing andstemming approaches for the czech language.
Infor-mation Processing and Management, 45(6):714?720,November.Kevin Gimpel, Nathan Schneider, Brendan O?Connor,Dipanjan Das, Daniel Mills, Jacob Eisenstein, MichaelHeilman, Dani Yogatama, Jeffrey Flanigan, andNoah A. Smith.
2011.
Part-of-speech tagging fortwitter: annotation, features, and experiments.
InProceedings of the 49th Annual Meeting of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies: short papers - Volume 2, HLT?11, pages 42?47, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Alec Go, Richa Bhayani, and Lei Huang.
2009.
Twit-ter sentiment classification using distant supervision.CS224N Project Report, Stanford.Jan Hajic?, Jarmila Panevova?, Eva Hajic?ova?, JarmilaPanevova?, Petr Sgall, Petr Pajas, Jan S?te?pa?nek, Jir??
?Havelka, and Marie Mikulova?.
2006.
Prague de-pendency treebank 2.0.
Linguistic Data Consortium,Philadelphia.Mohammad Sadegh Hajmohammadi, Roliana Ibrahim,and Zulaiha Ali Othman.
2012.
Opinion mining andsentiment analysis: A survey.
International Journal ofComputers & Technology, 2(3).Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the tenth73ACM SIGKDD international conference on Knowl-edge discovery and data mining, KDD ?04, pages 168?177, New York, NY, USA.
ACM.Efthymios Kouloumpis, Theresa Wilson, and JohannaMoore.
2011.
Twitter sentiment analysis: The goodthe bad and the OMG!
In Proceedings of the Fifth In-ternational Conference on Weblogs and Social Media,Barcelona, Catalonia, Spain, July 17-21, 2011.
TheAAAI Press.Gustavo Laboreiro, Lu?
?s Sarmento, Jorge Teixeira, andEuge?nio Oliveira.
2010.
Tokenizing micro-bloggingmessages using a text classification approach.
In Pro-ceedings of the fourth workshop on Analytics for noisyunstructured text data, AND ?10, pages 81?88, NewYork, NY, USA.
ACM.Bing Liu and Lei Zhang.
2012.
A survey of opinionmining and sentiment analysis.
In Mining Text Data,pages 415?463.
Springer.Roque Lo?pez, Javier Tejada, and Mike Thelwall.
2012.Spanish sentistrength as a tool for opinion mining pe-ruvian facebook and twitter.
In Artificial IntelligenceDriven Solutions to Business and Engineering Prob-lems, pages 82?85.
ITHEA, Sofia, Bulgaria.Christopher D. Manning, Prabhakar Raghavan, and Hin-rich Schu?tze.
2008.
Introduction to Information Re-trieval.
Cambridge University Press, New York, NY,USA.Justin Martineau and Tim Finin.
2009.
Delta TFIDF:An improved feature space for sentiment analysis.
InProceedings of the Third International Conference onWeblogs and Social Media, ICWSM 2009, San Jose,California, USA.
The AAAI Press.A.
Montejo-Ra?ez, E.
Mart?
?nez-Ca?mara, M. T.
Mart?
?n-Valdivia, and L. A. Uren?a Lo?pez.
2012.
Randomwalk weighting over sentiwordnet for sentiment po-larity detection on twitter.
In Proceedings of the 3rdWorkshop in Computational Approaches to Subjectiv-ity and Sentiment Analysis, WASSA ?12, pages 3?10,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Alexander Pak and Patrick Paroubek.
2010.
Twitter asa corpus for sentiment analysis and opinion mining.In Nicoletta Calzolari, Khalid Choukri, Bente Mae-gaard, Joseph Mariani, Jan Odijk, Stelios Piperidis,Mike Rosner, and Daniel Tapias, editors, Proceed-ings of the International Conference on Language Re-sources and Evaluation, LREC 2010.
European Lan-guage Resources Association.Georgios Paltoglou and Mike Thelwall.
2010.
A study ofinformation retrieval weighting schemes for sentimentanalysis.
In Proceedings of the 48th Annual Meetingof the Association for Computational Linguistics, ACL?10, pages 1386?1395, Stroudsburg, PA, USA.
Asso-ciation for Computational Linguistics.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: sentiment classification using ma-chine learning techniques.
In Proceedings of the ACL-02 conference on Empirical methods in natural lan-guage processing - Volume 10, EMNLP ?02, pages 79?86, Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.James Pustejovsky and Amber Stubbs.
2013.
NaturalLanguage Annotation for Machine Learning.
O?ReillyMedia, Sebastopol, CA 95472.Josef Steinberger, Polina Lenkova, Mijail AlexandrovKabadjov, Ralf Steinberger, and Erik Van der Goot.2011.
Multilingual entity-centered sentiment analy-sis evaluated by parallel corpora.
In Proceedings ofthe 8th International Conference on Recent Advancesin Natural Language Processing, RANLP?11, pages770?775.Josef Steinberger, Mohamed Ebrahim, Maud Ehrmann,Ali Hurriyetoglu, Mijail Alexandrov Kabadjov, PolinaLenkova, Ralf Steinberger, Hristo Tanev, SilviaVa?zquez, and Vanni Zavarella.
2012.
Creating senti-ment dictionaries via triangulation.
Decision SupportSystems, 53:689??694.E.A.
Stepanov and G. Riccardi.
2011.
Detecting gen-eral opinions from customer surveys.
In Data MiningWorkshops (ICDMW), 2011 IEEE 11th InternationalConference on, pages 115?122.Maite Taboada, Julian Brooke, Milan Tofiloski, KimberlyVoll, and Manfred Stede.
2011.
Lexicon-based meth-ods for sentiment analysis.
Computational Linguis-tics, 37(2):267?307.Mikalai Tsytsarau and Themis Palpanas.
2012.
Surveyon mining subjective data on the web.
Data Miningand Knowledge Discovery, 24(3):478?514, May.Kater?ina Veselovska?, Jan Hajic?
Jr., and Jana S?indlerova?.2012.
Creating annotated resources for polarity classi-fication in Czech.
In Proceedings of KONVENS 2012,pages 296?304.
O?GAI, September.
PATHOS 2012workshop.Liang-Chih Yu, Jheng-Long Wu, Pei-Chann Chang, andHsuan-Shou Chu.
2013.
Using a contextual entropymodel to expand emotion words and their intensityfor the sentiment classification of stock market news.Knowledge Based Syst, 41:89?97.Kunpeng Zhang, Yu Cheng, Yusheng Xie, Daniel Honbo,Ankit Agrawal, Diana Palsetia, Kathy Lee, Wei kengLiao, and Alok N. Choudhary.
2011.
SES: Sentimentelicitation system for social media data.
In Data Min-ing Workshops (ICDMW), 2011 IEEE 11th Confer-ence on, Vancouver, BC, Canada, December 11, 2011,pages 129?136.
IEEE.Dan Zhang, Luo Si, and Vernon J. Rego.
2012.
Senti-ment detection with auxiliary data.
Information Re-trieval, 15(3-4):373?390.74
