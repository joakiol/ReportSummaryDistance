Modularizing Codescriptive Grammars for Efficient Parsing*Walter  Kasper  and Hans -U l r i ch  Kr iegerGerman Research  Center  for Art i f ic ia l  In te l l igence (DFK I )S tuh lsatzenhausweg 3, D-66123 Saarbr / i cken ,  Germany{kasper ,  k r ieger}@dfk i ,  un i - sb ,  deAbst rac tUnification-based theories of grammar al-low to integrate different levels of linguis-tic descriptions in the common frameworkof typed feature structures.
Dependenciesamong the levels are expressed by corefer-ences.
Though highly attractive theoreti-cally, using such codescriptions for analysiscreates problems of efficiency.
We presentan approach to a modular use of codescrip-tions on the syntactic and semantic level.Grammatical nalysis is performed by tight-ly coupled parsers running in tandem, eachusing only designated parts of the grammat-ical description, in the paper we describethe partitioning of grammatical informationfor the parsers and present results about theperformance.1 In t roduct ionUnification-based theories of grammar allow foran integration of different levels of linguistic de-scriptions in a common framework of typed fea-ture structures.
In HPSG this assumption is em-bodied in the flmdamental concept of a sign (Pol-lard and Sag, 1987; Pollard and Sag, 1994).
Asign is a structure incorporating information fromall levels of linguistic analysis, such as phonology,syntax, and semantics.
This structure specifies in-teractions between these levels by means of cord-erences~ indicating the sharing of information.
Italso describes how the levels constrain each othermutually.
Such a concept of linguistic descriptionis attractive for several reasons:1. it supports the use of common formalisms anddata structures on all linguistic levels,2.
it provides declarative and reversible inter-face specifications between these levels,3.
all information is simultaneously available,and4.
no procedural interaction between linguisticmodules needs to be set up.
*This work was funded by the German FederalMinistry of Education, Science, Research and Tech-nology (BMBF) in the framework of the VerbmobilProject under Grant 01 IV 101 K/1.
The responsibil-ity for the content of this study lies with the authors.Similar approaches, especially for the syntax-semantics interface, have been suggested for allmajor kinds of unification-based theories, such asLFG or CUG.
(Halvorsen and Kaplan, 1988) callsuch approaches codescriptive in contrast to theapproach of description by analysis which is close-ly related to sequential architectures where lin-guistic levels correspond to components, operat-ing on the basis of the (complete) analysis resultsof lower levels.
In a codescriptive grammar se-mantic descriptions are expressed by additionalconstraints.Though theoretically very attractive, codescrip-tion has its price: (i) the grammar is difficult tomodularize due to the fact that the levels con-strain each other mutually and (ii) there is a com-putational overhead when parsers use the com-plete descriptions.
Problems of these kinds whichwere already noted by (Shieber, 1985) motivat-ed tile research described here.
The goal was todevelop more flexible ways of using codescriptivegrammars than having them applied by a pars-er with full informational power.
The underlyingobservation is that constraints in such grammarscan play different roles:?
Genuine constraints which relate directlyto tile grammaticality (wellformedness) of theinput.
Typically, these are t, he syntactic on-straints.?
Spur ious  const ra in ts  which basically buildrepresentational structures.
These are lessconcerned with wellformedness of the inputbut rather with output for other componentsin the overall system.
Much of semantic de-scriptions are of this kind.If a parser treats all constraints on a par, itcannot distinguish between the structure-buildingand the filtering constraints.
Since unification-based formalisms are monotonic, large structuresare built up and have to undergo all the steps ofunification, copying, and undoing in the proces-sor.
The cost, s of these operations (in time andspace) increase xponentially with the size of thestructures.In the VI,iRBMOBIL project, tile parser is usedwithin a speech translation system (Wahlster,1993; Kay, Gawron, and Norvig, 1994).
The pars-628- intrans-fin-verb-lexINDEX 10281np-nmn-typeSEM \[ cont2quantlSO ( CNI'-SYM rtp-ea, t\[syntax - type \SYN / , \[AGI{ \[\] \]"semantics-typeQUANT empty-diff-listSEMCON'FEN'r>\[ rp-typeAsubwff inst-shr-var"VAR \[\] \[ atornic-wff-type-/INST \[\]?
syntax- type \]J m AD \[aol  \[\]PtlON "kolnme"Figure 1: The simplified feature structure for theGerman verb komrne (to come).er input consists of word lattices of hypothesesfrom speech recognition.
Tile parser has to iden-tify those paths in tile lattice which represent agrammatically acceptable utterance.
Parser andrecognizer are increlnental and interactively run-ning in parallel?
Even for short utterances, thelattices can contain several mndreds of word hy-potheses, most of which do not combine to gram-matical utterances.
Parsing these lattices is muchmore complex than parsing written text.The basic idea presented here is to distributethe labour of evaluating the constraints in thegrammar on several processors (i.e., parsers).
Im-portant considerations in the design of the systemwere1.
increasing the Imrtbrmance,2.
achieving incremental and interactive be-haviour,3.
minimizing the ow~'rhead in communicationbetween the processors.We used a mid-size HPSG-kind German gram-mar written in the "/7)?
formalism (Krieger andSchgfer, 1994).
The grammar cospecifies yntaxand semantics in the attributes SYN and SEM.
Asimplified exmnple is shown in tile lexical entryfor the verb come in Fig.
1.In the following section, we start with a top-down view of the architecture.
Alter that we willdescribe the conmmnication protocol between theparsing processes.
Then several options for cre-ating subgrammars from the complete grammarwill be discussed.
The subgrammars epresent thedistribution of information across the parsers.
Fi-nally, some experimental results will be reported.2 The Arch i tec tureThe most important aspect for the distributionof analysis tasks and for defining modes of inter-action is that one of the processes must work asa filter on the input word lattices, reducing thesearch space.
The other component then worksonly with successflfl analysis results of the previ-ous one.
This means, that one parser is in controlover the other, whereas the latter one is not di-rectly exposed to the input.
For reasons whichwill become obvious below, we will call the firstof these parsers the SYN-parser, the second onecontrolled by the SYN-parser, the SEM-par'ser.Another consideration to be taken into account;is that the analysis should be incremental andt ime synchronous.
This implies that the SVN-parser should not send its results only when it iscompletely finished, thus forcing the SEM-parserto wait} Interactivity is another aspect we hadto consider.
Tile SF, M-parser must be able to re-port back to the SYN-parser at least when its hy-potheses failed.
This would not be possible whenthe SEM-parser has to wait till the SYN-parser isfinished.
This requirement also constrains the ex-change of messages.Incrementality and interactivity imply a steadyexchange of messages between the parsers.
An im-portant consideration then is that the overhead forthis communication should not outweigh the gainsof distributed processing.
This rules out that theparsers should communicate by exchanging theiranalysis results in terms of resulting feature struc-tures, since it; would imply that on each commu-nication event the parsers would have to analyzethe structures to detect changes, whether a struc-ture is part of other already known structures, etc.It is hard to see how this kind of communicationcan be interleaved with normal parsing activity inefficient ways.In contrast o this, our approach allows to ex-ploit tim fact that the grammars employed by theparsers are derived fl'om the same grammar andthereby "similar" in structure.
This makes it pos-sible to restrict the conmmnication between theparsers to intbrmation about what rules were suc-cessfiflly or nnsuccessfiflly applied.
Each parserthen can reconstruct on its side the state the otherparser is in how its chart; or analysis tree lookslike?
Both parsers try to maintain or arriw~ at1 Another l)roblem in incremental processing isthatit; is not known in advmme when an utte.rance istinished or a new utterance starts.
To deal withthis, prosodic information is taken into account; see(Kasper m~d Krieger, 1996) for more detmls.629isomorphic harts.
The approach allows that theparsers never need to exchange analysis results interms of structures as the parsers hould always beable to reconstruct these if necessary.
On the oth-er hand, this reconstructibility poses constraintson how the codescriptive grammar can be split upin subgrammars.The requirements of incrementality, interactivi-ty and efficient communication show that, our ap-proach does not ernulate the "description by anal-ysis" methodology in syntax-semantics interfaceson the basis of codescriptive grmnmars.3 The  Parsers  and  the  Pro toco lThe SYN-parser and the SEM-parser are agenda-driven chart parsers.
For speech parsing, thenodes represent points of times and edges repre-sent word hypotheses/paths in the word lattice.The parsers communicate by exchanging h~jpothe-ses, bottom-up hypotheses from syntax to seman-tics and top-down hypotheses from semantics tosyntax; see (Kasper, Krieger, Spilker, and Weber,1996) for an in-depth description of the currentsetup.?
Bot tmn-up hypotheses are emitted by theSYN-parser and sent to the SEM-parser.
Theyundergo verification at tile semantic level.A bot tom-up hypothesis describes a passiveedge (complete subtree) constructed by tilesyntax parser and consists of the identifier ofthe rule instantiation that represents the edgeand the completion history of the constructedpassive edge.
Having passive status is a nec-essary but not sufficient condition for an edgeto be sent as hypothesis.
Whether a hypothe-sis is sent also depends on other criteria, suchas its score.?
Top-Down hypotheses result from activ-ities of the SEM-parser, trying to verifybottom-up-hypotheses.
To keep the commu-nication efforts low, only failures are reportedback to the SYN-parser by sending simply thehypothesis' identifier.
This narrows the spaceof successflfl hypotheses on the SYN-parser'sside (see remarks in Section 4.3.1).The central data structure by which synchro-nization and communication between tile parsersis achieved is that of a completion history, con-taining a record on how a subtree was complet-ed.
Basically it tells us for each edge in the chartwhich other edges are spanned, The nodes in tilechart correspond to points in time and edges totime intervals spanned.
Completion histories aredescribed by the following EBNF:{R<rule-id><edge-id><start ><end>{E<edge-id>} *IL<lex-id><edge-id><st art ><end> }+<rule-id>, <lex-id>, <edge-id>, <start>, and<end> are integers.
R<rule-id> and L<lex-id>denote rules and lexicon entries, resp.
<edge-id>uniquely identifies a chart edge.
Finally, <star t>and <end> specify the start /end point of a span-ning edge.This protocol allows the parsers to efficientlyexchange information about the structure of theirchart without having to deal with explicit analysisresults as feature structures.
Since the SEM-parserdoes not directly work on linguistic input, thereare two possible parsing modes:?
Non-autonomous  parsing.
The parsingprocess mainly consists of constructing thetree described by tile completion history, us-ing the semantic counterparts of tile ruleswhich led to a syntactic hypothesis.
If thisfails, it is reported back to the SYN-parser.?
Quasi -autonomous parsing.
The parserextends the chart on its own through predic-tion and completion steps.
Obviously, thisis only possible after some initial informationby tile SYN-parser, since the S~;M-parser is notdirectly connected to the input word lattice.4 Compi la t ion  o f  SubgrammarsIn the following, we discuss possible options andproblems for the distribution of information in acospecifying rammar.
Our approach raises tilequestion which of tile parsers uses what informa-tion.
This set of information is what we call asubgrarnraar.
These subgrammars are generatedfrom a common source grammar.4.1 Reducing the Representat ionalOverhead by Separat ing  Syntax  andSemanticsAn obvious choice for splitting up the grammarwas to separate the linguistic levels (strata), suchas syntax and semantics.
This choice was alsomotivated by the observation that, typically themost important constraints on grammaticality ofthe input are in the syntactic part, while mostof the semantics is purely representational.
2 Astraightforward way to achieve this is by inanipu-bating grammar ules and lexicon entries for theSYN-parser, we recursively delete tile informationunder the SEM attributes and sinfilarly clear theSYN attributes to obtain the subgrammar for theSEM-parser.
We abbreviate these subgrammars byG~v.,- ~and G ....... and tile original grammar by G.This methodology reduces the size of tile struc-tures for the SYN-parser to about 30% of the eom-2This must be taken cu,n ,qrano salis as it dependson how a specific grammar draws the line betweensyntax and semantics: selecdonal constraints, e.g., forverb arguments, are typically part of semantics andare "true" constraints.
Also, semantic constraintswould have a much larger impact if, for instance,agreement constraints are considered as semantic, too,as (Pollard and Sag, 1994) suggest.630plete structure.
On(', disadvantage of this simpleal)proach is that coreferences between syntax andsemantics disappear (we call the collection of these(',Onllnon reentrancies the coref ske, lcton).
Thismight lead to several problems which we addressin Section 4.2.
Section 4.3 then discusses possiblesolutions.Another, more sophisticated way to keep thestructures small is due to the type expansionmechanism in 7T)?
(Krieger and SchMer, 1995).Instead of destructively modifying the feature.structures lmforehaml, we can elnl)loy type exl)an~sion to let SYN or SI,;M unexpan(le(l. This has thedesired eft'cot hat we (lo not lose the coreferenceconsl:raints and furthernlore are fl'ee to expan(lparts of the feature stru(',ture afterwards.
We willdiscuss this feature in Section 4.4.4.2 Prob lemsObviously, the major advantage of our method ixthat unification and copying l)ecome faster dur-ing processing, due to smaller structures.
We Calleven estimate the st)eedup ill the best case, viz.,quasi-linear w.r.t, input structure if only conjunc-tive structures are used.
Clearly, if many disjun(:-tions are involved, the speedut) might even be ex-ponential.However, the most imi)ortant disadwmtage ofthe conq)ilation mthod is that it no longer guar-antees soundness, that ix, the sut)grammar(s)might accel)t ul;terances which are ruled out hytile flfll grammar.
This is due to tile silnple factthat certain constraints have \])een elinfinated inthe subgranunars.
If at least, one such constraintis a filtering constrMnt, we automatically enlargethe language accepted 1)y this sul)grainmar w.r.t.the original granunar.
Clearly, completeness is notaffected, since we do not add further constrMntsto the sul)grannnars.At this 1)oint, let us focus on the estimationabove, since it is only a 1)est;-case forecast.
Clear-ly, the structures I)econm snmller; however, dueto the possil)le decrease of filter constraints, wenmst expect all increase of hypotheses in the pars-er.
In fact, tile experimental results ill Section5 show that our approach has a ditferent impacton tile SYN-parser and the Sl,;M-parser (see Figure2).
Our hope here, however, is that; the increaseof non-deternfinisut inside the parser is coml)en-sated by tile processing of smalh;r structures; see(Maxwell I I I  and Kaplan, 1991) for more argu-inents on this theme.In general, ewm the intersection of the lan-guages accepted by G~,v, ~and G~ ..... does not yieldthe language accepted by G only the weaker re-lation ?
(G) C ?
((;~y,~) O/2(G ..... )holds.
This t)e,-haviour is all outcome of our compilation schema,namely, cutting reentrancy points.
Thus, even ifan utterance is accepted by G with analysis fsencoded as a feature structure, it might be tilecase that the unifi(:ation of the corresponding re-suits for G.~.v,,.
and G ....... will truly subsume fs:A' -</,%.~ A f.~ .
.
.
.
.
.Let; us mention fllrther problems.
Firstly, ter-mination inight change ill case of tile sul)gram-mars.
Consider a subgranunar which containselnpty productions or unary (coercion) rules.
As-sume that such rules were previously "controlled"t)y constraints which are no longer presell(;.
Ob-viously, if a parser is not restricted through addi-tional (meta-)constraints, ile iterated al)l)licationof these rules could lead to all infinite computa-tion, i.e., a loop.
This was sometilnes the case.during our experin~ents.
Secondly, recursivc rulescouhl introduce infinitely nlany solutions for a giv-en utterance.
Theoretically, this might not pose aproblenl, since the intersection of two infinite setsof parse trees nfight be finite.
However in practice,l, his i)roblem might occur.4.a Solut ionsIn this section, we will discuss three solution tothe protflems mentioned before.4.3.1 Feedback  LoopAlthough senumtics construction is driven bythe speech pm'ser, the use of (titfelent subgram-mars suggest hat the sl)e, cch I)mser should alsobe guided 1)y the Sl,:M-parsel'.
This is achievedby sending 1)ack faIs~i/icd hypotheses.
Because hy-potheses are uniquely identitied in our framework,we must only send the integer that idenl;ities tilefalsified chart edge.
Ill the SYN-parser, this infer-mat;ion might either lead to a true ('hart revisionprocess or be employed as a filter to narrow theset of enfitted bottom-ul) hyl)otheses.4.3.2 Corer  Ske letonIn order to gjuarantee correctness of tll(., alml-ysis, we might unify the results of 1)oth parserswith the corresl)onding coref skeletons at the endof an analysis.
We (lid not tmrsue this strategysince it introduces an additional 1)recessing stepduring parsing.
Illstea(l, as explained above, it is1)referabh; to employ type expansion here, lettingSYN or SEM unexpanded, so that coreferences arepreserved.
This treatment will be inve, stigated inSection 4.4.4.3.3 Full-Size GrammarThe most straighttbrward way to guaranteesoundness is siml)ly by elnploying the full-sizegrammar ill one of the two parsers.
This mightsound strange, but if one processor lm.sieally onlyverifies hypotheses from tile other and doe, s notgenerate additional hyl)otheses, tile overhead isneglectat)le.
We have used this scheme ill thatthe SEM-parser oI)erates oil the full-size grammar,whereas the si)eech parser directly conlnmnicateswith tile word recognizer.
This makes sense since631the word lattice parser processes an order of mag-nitude more hypotheses than the SEM-parser; see(Kasper, Krieger, Spilker, and Weber, 1996) formore details.
Because the SEM-parser passes itssemantic representation to other components, itmakes further sense to guarantee total correctnesshere.4.4 hnprovementsThis section investigates several improvements ofour compilation approach, solving the problemsmentioned before.4.4.1 Identifying Functional StrataManuallyNormally, the grammarian "knows" which in-formation needs to be made explicit.
Hence, in-stead of differentiating between the linguistic stra-ta sYN and SEM, we let the linguist identify whichconstraints filter and which only serve as a meansfor representation; see also (Shieber, 1985).
Incontrast o the separation along linguistic levels,this approach adopts a functional view, cuttingacross linguistic strata.
On this view, the syntac-tic constraints together with, e.g., semantic selec-tion constraints would constitute a subgrammar.4.4.2 Bookkeeping UnificationsIn case that the grammarian is unaware of theseconstraints, it is at least possible to determinethem relatively to a training corpus, simply bycounting unifications.
Features that occur onlyonce on top of the input feature structures do notspecialize the information in the resulting struc-ture (actually the values of these features).
Fhr-thermore, unrestricted features (value T) do notconstrain the result.
For instance,indicates that only the path A needs to be madeexplicit, since its value is more specific than thecorresponding input values: say  -~ s and say  ~_ v.4.4.3 Partial EvaluationPartial evaluation, as known from function-al/logic programming, is a method of carryingout parts of computation at compile time thatwould otherwise be done at run time, hence im-proving run time performance of programs; see,e.g., (Jones, Gomard, ~and Stestoft, 1993).
Anal-ogous to partial evaluation of definite clauses, wecan partially evaluate annotated grammar ules,since they drive the derivation.
Partial evaluationmeans here to substitute type symbols by theirexpanded efinitions.Because a grammar contains finitely many rulesof the above form and because the daughters (theright hand side of the rule) are type symbols (andthere are only finitely many of them), a great dealof this partial evaluation process can be performedotttine.
In contrast o a pure CF grammar withfinitely many terminal/nonterminals, the evalua-tion process must; not terminate, due to eorefer-enee constraints within feature structures.
How-ever, recta-constraints such as of\]line parsabilityor lazy type expansion (see next section) help usto determine those features which actively partic-ipate in unification during partial evaluation.
Incontrast o the previous method, partial evalua-tion is corpus-independent.4.4.4 Lazy Type ExpansionWe have indicated earlier that type expansioncan be fruitfully employed to preserve the corefskeleton.
Type expansion can also be chosen toexpand parts of a feature structure on the fly atrun time.The general idea is as follows.
Guaranteeingthat the lexicon entries and the rules are consis-tent, we let everything unexpanded unless we areenforced to make structure xplicit.
As was the'case for the previous two strategies, this is onlynecessary if a path is introduced in the resultingstructure whose value is more specific than thevalue(s) in the input structure(s).The biggest advantage of this approach isobvious--only those constraints must be touchedwhich are involved in restricting the set of possi-ble solutions.
Clearly, such a test should be doneevery time the chart is extended.
The cost of suchtests and the on-line type expansions need furtherinvestigation.5 Exper imenta l  Resu l tsThis section presents experimental results of ourcompilation method, indicating that the simpleSYN/SEM separation does not match the distinc-tion between true and spurious constraints, most-ly due to semantic selectional constraints (see Fig.2).
The measurements have been obtained w.r.t.a corpus of 56 sentences/turns from 4 dialogsdnthe VERBMOBIL corpus.The column Syn shows that parsing with syn-tax only takes 50% of the time of parsing withthe complete grammar (SynSem).
The num-ber of readings, hypotheses, and chart edges on-ly slightly increase here.
The column SemNAshows the results for operating the SEM-parserin non-autonomous mode, that is, simply veri-lying/falsifying hypotheses fi'om the SYN-parser.The parsing time of the coupled system is slightlyhigher than that for SYN-parser alone, due to thefact that the SEM-parser can only terminate afterthe SYN-parser has sent its last hypothesis.
Nev-ertheless, the overall time is still only 50% of thesystem With the complete gramifiar (a sequentialcoupling only improves the overall run time forSemNA only by 5-10%).
This illustrates that632number of sentences: 56average ler, gth: 7.6'nSenlrim time: 30.6#readings: 1.7#hypotheses: 53.0~chart edges: 7t 92.0Syn SemNA Sem(% - -~%-0  - - -~15.2 50 15.4 50 45.82.1 123 1 1.7 1 ( ~58.1 \[ l{} ~ ~ ~215.0 112158.1 -~1-Figure 2: \]~xt)erimental results of SYN/SEM separation.
SemNA rot)resents results for tile SEM-p~u'serin 1ran-autonomous mode, SemQA the results tbr SEM-patwer as quasi-autonomous semantic parser.The percentage vahws are relative to SynSem.the efficiency of the parallel running system main-ly depends on that of the SYN-parser.
The colmnnSemQA shows the results for the m.:Mq)arser inquasi-autonomous mode.
Since no syntactic eon-st, raints are involved in filtering, we expect a con-siderable increase in processing time and numberof hypotheses.
In fact, our measurements indicatethat syntax (in our grammar) provides most of thegenuine constraints.These results show that the modularization ofthe grammar and the distribution of its informa-tion lead to a considerable increase ill parsing ef-ficiency, thus ilnproving the comimtational ppli-(:ability of codescriptive grmnmars.6 Conc lus ionsLinguistic theories like HPSG provide an integrat-ed view on linguistic objects by providing a uni-form fi'amework for all levels of linguistic analy-sis.
Though attractive from a theoretical I)ointof view, their implementation raises questions ofcoinputational tractability.
We subscribe to thatintegrated view on the level of linguistic descrip-tions and specitications.
However, fi'om a compu-tational view, we think that for special tasks notall that inforination is useful or required, at leastnot all at the same time.In this paper we described attelnpts to make amore flexible use of integrated linguistic descrip-tions by splitting them up into subi)ackages thatare handled by special processors.
We also devisedan efficient protocol for cominunication betweensuch processors and addressed a nmnber of t)rob-lems and solutions, some of which need fl~rtherempirical investigation.
The results obtained sofar indicate that our approach is very promisingfor making efficient use of codescriptive grmnmarsin natural anguage analysis.3ones, Nell 1)., Carsten K. Gomard, and Peter Stestoft1993.
Partial t"\]vahuttion and Automatic ProgramGeneration.
New York: Prentice \[lall.Kasper, Walter and ltans-Ulrich Krieger.
1996.
Inte-gration of Prosodic and Grammatical hfformationin the Analysis of t)ialogs.
Verbmobil Report.Kasper, Walter, ltans-Ulrich Krieger, J6rg Spilker,and llans Weber.
\[996.
From Word \[\[ypotheses to'Logical Form: An 1,3ficient Interleaved Approach.Verbmobil {eport.Kay, Martin, Jean Mark Gawron, and Peter Norvig.1994.
Verbmobil.
A Translation System for Face-to-Face Dialog.
CS\],\[ Lecture Notes, volume 33.Chicago University I)ress.Krieger, Hans-Ulrich and Ubich Sch'~fer.
1994. :f'D/2A Type Description Language for Constraint-Based(h'ammars.
In Proceedings of COLING-94, pages893 89(.
).Krieger, Hans-Ulrich and Ulrich Sch?fer.
1995.
Fill-clout l)arameterizal)le Type l,;xt)ansion tbr Typedli'eature Formalisms.
In Proceedings of IJUAI-95,pages \[428 1434.Maxwell Ill, John T. and Ronald M. Kaplan.
:1993.The Interface between Phrasal and 1,'mlctional Con-straints.
In Computational Linguistics, Vol.
19,No.
4, pages 571 590.Polhu'd, Carl and \[van A.
Sag.
1987. lnformation-Hased Syntax and Semantics.
Vol.
h Fmldamen-tals.
CSLI Lecture Notes, Volume 13.
Stanford:CSIA.Pollard, Carl and Ivan A.
Sag.
11994.
Head-DrivenPhrase Structure Grammar.
(\]hicago: University ofChicago Press.Shieber, Stuart M." 1985.
Using Restriction toExtend Parsing Algorithms for Complex-Feature-Based \]"ormalisms.
In Proceedings of ACL-85,pages 145-152.Wahlster, Wolfgang.
1993.
Verbmobih 0bersetzungvon Verhandhmgsdialogen.
Verbmobil Report.ReferencesIIalvorsen, Per-Kristian and Ronald M. Kaplan.
1988.Projections and Semantic Description in l,exical-Functional (\]ralnmar.
In Proceedings of 5th Gener-ation Computer System.s, pages 1116 1122.633
