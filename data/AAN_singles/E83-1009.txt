A PROLOG IMPLEMENTATION OF LEXICAL FUNCTIONAL GRAMMARAS A BASE FOR A NATURAL LANGUAGE PROCESSING SYSTEMWerner Frey and Uwe ReyleDepartment of L lngulst lcsUniversity of StuttgartW-GermanyO.
ABSIRACr~ne aim of this paper is to present parts of our system \[2\],which is to construct a database out of a narrative naturall a ~  text.
We think the parts are of interest in their o~.The paper consists of three sections:(I) We give a detailed description of the PROLOG -implementation of the parser which is based on the theory oflexical functional grammar (I/V.).
The parser covers thefragment described in \[1,94\].
I.e., it is able to analyseconstructions involving functional control and long distancedependencies.
We will to show that- PROLOG provides an efficient tool for LFG-implementation: aphrase structure rule annotated with ftmctional schemata l i ke~M~ w~is ~^ be interpreted as, first, identifying the specialgrmr, m/tical relation of subject position of any sentenceanalyzed by this clause to he the h~ appearing in it, andsecond, as identifying all g~,~mtical relations of the sentencewith those of the VP.
This ~iversal interpretation of the~tavar iab les  ~ and & corresponds to the universalquantification of variables appearing in PROl /~uses .
Theprocedural ssm~ntios of PROLOG is such that the instantietion ofthe ~ariables in a clause is inherited from the instantiationgiven by its subgoals, if they succeed.
Thus there is no needfor a separate component which solves the set of equationsobtained by applying the I/G algorithm.-there is a canonical way of translati~ LFG into a PROLOGprogz~,~.
(II) For the se~ntic representation of texts we use theDiscourse Representation q\]neory developped by Psns \[,a~p.
Atpresent the implerentation includes the fragment described in\[4\].
In addition it analyses different types of negation andcertain equi- and raising-verbs.
We postulate some requirenentsa semantic representation has to fulfill in order to he able toanalyse whole texts.
We show how K~p's theory meets theserequirements by analyzing sample disconrses involving amaphoric~'s.
(III) Finally we sketch how the parser formalism ca~ beaugmented to yield as output discourse representationstructures.
To do this we introduce the new notion of 'logicalhead' in addition to the LFG notion of 'grmmmtical head'.reason is the wellknown fact that the logical structure of asentence is induced by the determiners and not by the verb whichon the other hand determines the thenatic structure of thesentence.
However the verb is able to restrict quantifier scopeanbiguities or to induce a preference ordering on the set ofpossible quantifier scope relations.
~-erefore there must he aninteraction between the grammatical head and the logical head ofa phrase.I.
A PROLOG ~W\[/94~NTATION OF LFGA main topic in AI research is the interaction between differentcomponents of a systen.
But insights in this field areprimarily reached by experience in constructing a complemsystem.
Right frcm the beginning, however, one should chooseformalisms which are suitable for a s~nple and transparenttransportion of information.
We think LFG meets thisrequirenent.
The formalism exhibiting the analysis of asentence c~ he expanded in a simple way to contain entrieswhich are used during the parse of a whole text, for examplediscourse features like topic or domain dependent knowledgeconming from a database associated with the lexicon.
Since I/Gis a kind of u~_ification grammar it allows for constructingpatterns which enable the following sentences to refine or tochange the content of these disc~irse features.
Knowledgegathered by a preceding sentence can he used to lead the searchin the lexicon by demanding that certain feature values match.In short we hope that the nearly tmiform status of the differentdescription tools allows simple procedures for the expansion andmani~Llation by other components of the syst~n.But this was a look ahead.
Let us mow come to the lessa~bitious task of implementing the grmmmr of \[i,~4\].iexical functional g ~  (LFG) is a theory that extends phrasestructure ~L~,mrs without using transformations.
It ~nphasizesthe role of the grammatical f~Ictions and of the lexicon.Another powerful formalism for describing natural languagesfollows from a method of expressing grammars in logic calleddefinite clause gz~,srs (DOG).
A DOG constitutes a PROIOGprogramne.We %~nt to show first, how LFG can he tr-amslated into DOG andsecond, that PROLOC provides an efficient tool forI/D-Implementation in that it allows for the construction offunctional structures directly during the parsing process.
I.e.it is not necessary to have seperate components which firstderive a set of f~mctional equations from the parse tree andsecondly generate an f-str~ture by solving these equations.Let us look at an example to see how the LFG machinery works.We take as the sample sentence "a w~man expects an anerican towin'.
ql%e parsing of the sentence proceeds along the followinglines.
~ne phrase structure rules in (i) generate the phrasestructure tree in (2) (without considering the schemata writtenbeneath the rule elements).Q)  s - ->  NP vPVP - ->  V NP NP PP VP'~'= ~ (d'OBJ)=$ (~OBJ2)=&(?
(WPCASE)=% (#X~)4w"  - -> (to) vP?=~~R ~ - -> ~-T N=~ ~=~(2) ..I.
s ~ _ ~  v PFET Na worn expects & ~me~'ioan to winthe c-stru~ture will be annotated with the functionalschemata associated with the rules .
~he schemata found in thelexical entries are attached to the leave nodes of the tree.~his is shown in (3).5243)(4-SI~I)= 4,1 1(*SPEC)=A (+NLM)=SG(~NU'O=SG (+Gm)=F~(~PmS)=3(~mZD)='~ndAN"V NP VP"l~r  N VP1(~S~EC)=~(4m0---SC(+NU~)=SG4%~mS)=3(+PRED)= ' ~RICAN"(?
reED)=" E~ECT<(SUBJ) ( X~)>(  OBJ)'(4 ~ENSE)=mES\~=~V(~ suBJ ~M)=SG (?mED)='Wn~(SUBJ)>'(~S\[mJ ProS)=34+xcem su~J)=(osJ)(4) ( fl SIBJ) = f2 f3 = f6fl = f3 (f6 fRED) = "EXPECT<(SL~J)(XC~MP)>(OBJ)"f2 = f4 (f6 T~5~E) = PRESf2 = f5 (f6 ~ SUE/) = (f60BJ)(f5.Nt~0 = SC (f5 PRED) = 'we~er?Then the tree will he Indexed.
~e indices instantiate the up-and down-arrows.
An up-arrow refers to the node dominating thenode the schema is attached to.
A d~n-~ refers to the nodewhich carries the f~ctlonal schema.Tns result of the instantiation process is a set of ftmctionalequations.
We have listed part of them in 44).
TOe solving ofthese equations yields the f~ctional str~zture in (5).ED "l,~l~/'r' ~ 3NINSGreED "EX~ECT<(SU~) ( XCmP)> ( O~J)"A~mED 'A~m~C~ NU~ SG~ )It is composed of grammtical ftmction naras, s~antic forms andfeature symbols.
The crucial elements of LFG (in contrast totransformational g~n.ar)are the grammticel functiens likeSL~J, OBJ, XCCMP and so on.
The fu%ctional structure is to heread as containing pointers frem the funct io~ appearing inthe semantic forms to the corresponding f-structures.The ~,,atical functions assumed by LFG are classified insubcategorizable (or governable) and nonm~*zategorizablefunctions.
TOe subcategorizable ones are those to which lexlcalitems can make reference.
TOe item "expects' for e~smplesubcategorizes three functions, but only the material inside theangled brackets list the predicate's smmntic arguments.
X{I~Pand XAIU are ~/~e only open grammtical functions, i.e.
,they candenote functionally controlled clauses.
In our exhale thisphenomena is lexically induced by the verb "expects'.
Tnis isexpressed by its last sch~mm "(%XC\[~P SUBJ)=(@OBJ)".
It has theeffect that the 0 \ ]~of  the sentence will becmme the SUBJ of theXC~MP, that me.%ns in our example it becomes the argument of d~epredicate 'win'.Note that the analysis of the sentence "a woman promises an~merlcan to win" would differ in two respects.
First the verb'prcmlses' lists all the three ft~ctions subcategorized by it inits sem~ntlc argument structure.
And second 'premises" differsfrom "expects' just in its f~mctional control schema, i.e., herewe find the equation "(#X{~MP SUBJ)=(A~SLBJ) '' yielding an arrowfrom the SL~J of the XC~MP to the SUBJ of the sentence in thefinal f-structure.An f-structure must fulfill the following conditions in order tobe a solution-uniqueness: every f-nane which has a value has a ~ique value-completeness:the f-structure must contain f-values for all thef-na~es subcategorized by its predicate-coherence: all the subcate~orizable fzmctions the f-structurecontains must be ~tegor i sed  by its predicateThe ability of lexical irons to determine the features of otheritems is captured by the trivial equations.
Toey propagate thefeature set which is inserted by the lexical item up the tree.For e~mple the features of the verb become features of the VPend the features of the VP become features of S. The ~llquenessprinciple guarantees that any subject that the clause containswill have the features required by the verb.
The trivialequation makes it also possible that a lexical item, here theverb, can induce a f~mctional control relationship he~different f-structures of the sentence.
An ~mportant constraintfor all references to ftmctions and fonctional features is theprinciple of f~mctional locality: designators in lexical andgrmm~tical schemata can specify no more than two iteratedf~mction applications.Our claim is t|mt using DCG as a PROLOG programe the parsingprocess of a sentence according to the LFG-theory can be donemore efficiently by doing all the three steps described abovesimultaneously.Why is especially PROLOG useful for doing this?In the a;motated e-structure of the LFG theory the content ofthe f~mctional equations is only '"~wn" by the node theequation is annotated to and by the immediately dominating node.The memory is so to speak locally restricted.
Thus during theparse all those bits of info~tion have to be protocolled forso~e other nodes.
This is done by means of the equations.
In aPROIOG programme however the nodes turn into predicates witharEun*~ts.
Tns arguments could be the same for differentpredicates within a clause.
Therefore the memory is'~orizentall~' not restricted at all.
Furthermore by sharing ofvariables the predicates which are goals ca~ give infon~tion totheir subgoals.
In short, once a phrase structure grammr hasbeen translated into a PROIOG pragraune every node ispotentially able to grasp information from any other node.Nonetheless the parser we get by embedding the restricted LFGformalism Into the highly flexible r~G formalism respects theconstraints of Lexlcal ftmctlonal granular.Another important fact is that LFG tells the PROIOG programmerin an exact manner what information the purser needs at whichnode and just because this information is purely locallyrepresented in the LFG formalism it leads to the possibility oftranslating 12G into a PROLOG programme in a ca~mical wey.We have said that in solving the equations LFG sticks togetherinformations ?mmiog from different nodes to build up the finaloutput.
To mirror this the following PROLOG feature is ofgreatest importance.
For the construction of the wanted outputduring the parsing process structures can he built up piecsneal,leaving unspecified parts as variables.
The construction of theoutput need not he strictly parallel to the application of thecorresponding rules.
Variables play the role of placeholdersfor structures which are found possibly later in the parsingprocess.
A closer look at the verb entries as formulated by LFGreveals that the role of the f~mction names appearing there isto function as placeholders too.To summarize: By embedding the restricted LFG formalism intothe hlgly flexible definite clause grammr fonmg/ismwemakellfe easier.
Nonetheless the parser we get respects theconstraints which are formulated by the LFG theory.Let us now consider some of the details.
Xhe n~les under (i)53are transformed into the PROLOG programme in (6).
(* indicatesthe variables.
)(6) S (*el0 *ell *outps) <- -NP (*el0 *c12 *featnp *outpnp)VP (*c12 *ell (SIBJ (*outpnp *featnp)) T~ *outpa)VP (*clO *ell *outpsubj *featv *outps) <- -v (*cent (~o~mmb/~)  *leafy *outps)F~/~IP (*el0 *?12 OBJ ~ *ill)Ifun?tional FA(~ (*?12 *c13 OBJ2 ~ *~)controll FAf~=P (*el3 *el40BL ~ *~)FA?~" (*?14 *ell *oont xcem ~ nil) l i~iAst~FAOJP' (*clO *ell (*gf *cont) *gf ~ )  .
*i0) *10)~-VP" (*?I0 *ell *cont *outpxcomp)NP (*el0 *ell *ontpnp) <-lET (*el0 *?ii *ontpdet)N (*outpdet *outpnp)We use the content of the function assigning equations to buildup parts of the whole f-structure during the parsing process.Crur~al for this is the fact dmt every phrase has a ~miquecategory, called its head, with the property that the functionalfeatures of each phrase are identified with those of its head.The head category of a phrase is characterized by d~e assignmentof the trivial ft~%ctional-equation and by the property of beinga major category, ql%e output of each procedure is constructedby the subprocedure corresponding to the head.
~ means thatall information resulting from the other subprooedures is givento that goal.
ll~is is done by the 'outp' variables in theprogramme.
ThUS the V procedure builds up the f-structure ofthe sentence.
Since VP is the head of the S rule the VPprocedure has an argument variable for the SUB7 f-structure.Since V is the head of the VP rule this variable together withthe structures coming fore the sister nodes are given to V forthe construction of the final output.
As a consequence ouroutput does not contain pointers in contrast to Bresnan' soutput.
Rather the argument positions of the predicates areinstantiated by the indicated f-stmmtures.
For each categorythere is a fixed set of features, l~e head category is able toimpose restrictions on a fixed subset of that feature set.
Thissubset is placed on a prominent position, l~e correspondingfeature values percolating up towmrds the head category will endup in the sate position d&~anding that their values agree.
Toisis done by the ' feat" variables.
The ~aiqueneas condition istrivially fulfilled since the passing around of parts of thef-structure is done by variables, and PROIOG instantiates avariable with at most one value..(7) V ( (V(KEP (SL~J (*outpobj *featobj))) Ifenctional control\]((S\[BJ (*outpsubj (SG 3))) ~ Icheck listl(OBJ (*outpobj *featobJ)) (XC~MP *outpxcomp))+'- I output I((TK~SE m~)  (reED "EXPECt (*outpaubj *outpxcemp)')) )~he checking of the completeness and coherence condition is doneby the Verb procedure.
(7) shows the PROLOG assertioncorresponding to the lexical entry for 'expects'.
In everyassertion for verbs there is a list containing the g~=m~,~ticalftmctions subcategorized by the verb.
This is the secondargument in (7), called "check list'.
~ list is passedaround during the parse.
~lis is done by the list umderlinedwith waves in (6).
Every subcategorlzable f~action appearing inthe sentence must be able to shorten the llst.
Tnis guaranteescoherence.
In the end the list must have diminished to NIL.This guarantees completene&s.As can be seen in (7) a by-product of this passing around thecheck list is to bring the values of the grammtical functionssubcategorized by the verb down to the verb's predicate argumentstructure.To handle famctional control the verb entry contains an argumentto encode the controller.
Ibis is the first argument in (7).lhe procedure ~li.ch delivers XC~MP (here the VP" procedure)receives d~is variable (the underlined variable *cont in (6))since verbs can induce ft~ctional control only upon the opengrammtical famction XOCMP.
For toug~ement  constructionsthe s-prime procedure receives the controller variable too.
Butinside this clause the controller must be put onto the longdistance controller list, since SCCMP is not an open grammaticalfunction.That leads us to the long distance dependencies(8) The glrl wonders whose playmate's nurse the baby saw.
(9) S" - ->  NP .p \[\](+Focns)=~(10) / sNP /VP~V S'~, ,~ ~ N NP VP \i Y-k I IX / \ ,.il~ .~_  N I IET N V NP l"f~._w~ose playmate s nurse the baby saw e ~oIn Phglish ~st ions and relatives an element at the front ~ofthe clause is understood as filling a particular g r~t ica lrole within the clause, determined by the position of ac-structure gap .
Consider sentence (8).
This kind ofdependency is called constituent control, because in contrast tof~ctional control the constituent structure configurations arethe primary conditioning factors and not lexical irons.Bresnan/kaplan Introduce a new formal mechanism for represantinglong- distance dependencies.
To handle the embedded questionsentence they use the rule in (9).
The double arrow downwardsrepresents the controller of the constituent controlrelationship.
To this arrow corresponds another double arrowwhich points up~mrds and represents the oontrolee.
This one isattached for emanple to the empty string NP - ->~,  But as thearrow iode~d with \[4~fn\] shows the controller may affect also adesignated set of lexical items which includes interrogativepronoens , detsminers and adverbs.
"whose' for e.xanple has thelexlcal entry: whose N, (~PRED)= 'who', CASE = GI~1,~\[,~.
(~ds kind of control relationship is needed to an~yse thecomplex NP 'Whose playmate's mlrse" In sentence (8))The control relationships are illustrated in (I0).Corresponding controllers and controlees must have compatiblesubscripts.
~ subscripts indicate the category of thecontrolles.
Toe superscript S of the one controller indicatesthat the corresponding controlee has to be found in a S-rootedcontrol domain whereas the \[-kwh\] controlee for the othercontroller has to be found beneath a ~ node.Finally the box around the S-node reeds to be explained.
Itindicates the fact that the node is a boLmding node.Kaplan/Bresnan state the following conventionA node M helor~s to a control domain with root node R if andonly if R dominates M and there are no bo~iding nodes on thepath from M up to but not including R.Tnia c~nvention prevents constructions like the one in (ii).
(Ii) The girl wondered what the m~se asked who sawLong distance control is haldle by the programme using a longdistance controller list, enriched at some special nodes withnew oontrollers, passed down the tree and not allowed to gofurther at the bounding nodes.
(12) s" (*c_19"~I *outpsc) <--1!_onB NP (((_~_t~_ \]_).
*el 0) *cl l  *featnp *outpnp)d i_s_ta~e_con_tro!le_r - rest (*ell_ *clO)list l S ((*oL!t~np*f_eatnj~ !S_N~)) ~ *outpsc)Every time a controlne is found its subscript has to match thecorresponding entry of the first menber of the controller list.If this happens the first element will be deleted from the list.The fact that a controlee can only match the first elenentreflects the crossed dependency constraint.
*clO is the input54controller variable of the S" procedure in (12).
*cll is theoutput variable.
*clO is expanded by the \[4wh\] controllerwithin the NP subgoal.
This controller must find its controlleeduring d~e e~ecution of the NP goal.
Note that the outputvariable of the NP subgoal is identical with the output variableof the main goal and that the subgoal S" does have differentcontroller lists.
~ reflects the effect of the box aroLmdthe S-node, i.e.
no controller coming do,retards can find itscontrolee inside the S-prncedure.
l~e only controller goinginto the S goal is the one introduced below the NP node withdnmsln root S. Clearly the output variable of S has to be nil.There are rules which allow for certain controllers to pass aboxed node Bresna~Kaplan state for example the rule in (13).
(13) s" - ->  (nhat) sThis rule has the effect that S-rooted contollers are allowed topass the box.
Here we use a test procedure which puts only thecontollers iedexed by S onto the controller l i s t  going to the Sgoal.
~ereby we obtain the right treatment of sentence (14).
(14) the girl wondered who John believed that Mary claimed thatthe baby saw .In a corres~eding manner the complex NP 'whose playmate'snurse" of sentence (8) is analysed.II.
SEMANTIC REPRESD~jLTIONAs senantic representation we use the D(iscourse)R(epresentation) T(heory) developped by Hans Yamp \[4\].
I.e.
wedo not adopt the semantic theory for L(exical) F(unctional)C~rammr) proposed by Per-Kristian Halverson \[2\].
Halversontranslates the f~nctional structures of LFG into so-calledsemantic structures being of the same structural nature, namelyscyclic graphs.
The semlntin structures are the result of atranslation procedure which is based on the association offormulas of intensional logic to the semantic forms appearing inthe functional structure.
The reason not to take this approachwill be explained by postulating some requirements a se~anclcrepresentation has to fulfill in order to account for aprocessing of texts.
Tnen we will show that these requlr~entsare rP~I\]y necessary by analysing some sample sente,ces anddiscourses.
It will turn out that ~T accoante for them in anintuitively fully satisfactory ~y .Because we cannot review \[RT in detail here the reader shouldconsult one of the papers explaining the ftmdanentals of thetheory (e.g.
\[~\] ), or he should first look at the lastparagraph in which an outline is given of how our parser is tobe extended in order to yield an IRS-typed output - instead ofthe 'traditional' (semantic) flmctional structures.The basic building principle of a semantic representation is toassociate with every signlfic2mt lexical entry (i.e., everyentry which does contribute to the truthcondldtlonsl aspect ofthe meaning of a sentence) a semantic structure.
Compositionalprinciples, then, will construct the semantic representation ofa sentence by combining these se~antlc structures according totheir syntactic relations.
The desired underlying principle isthat the smmntlc structures associated with the semantic formsshould not be.
changed during the composition process.
To vat itdif6erently: one ~nts  the association of the semanticstructures to be independent of the syntactic context in whichthe semantic form appears.
This requirement leads todifficulties in the tradition of translating sentences intoformulas of e.g.
predicate or intentional logic.Consider sentences(I) If Johe admires a woman then he kisses herand(2) Every man who a~ires a woman kisses herthe truth conditions of which are determined by the first orderfommlas(3) Yx (wonmn(x) & a~mire(Jo~m,x) --> kiss(Jo,m.x) )and(4) vx vy (ran(x) & ~y)  & am~re(x,y) --> kiss(x,y) )respectively.
~le problem is that the definite description "awoman" reemerges as universally quantified in the logicalrepresentation- and there is no way out, because the prono~m"she" has to be boLmd to the wommn in question.
I~T provides ageneral acco~mt of the meaning of indefinite descriptions,conditionals, tmiversally quantified noun phrases and anaphoricpronoun, s.t.
our first requirement is satisfied.
1~esemantic represEmtations (called nRs's) which are assigned tosentences in which such constructions jointly appear have thetruth conditions which our intuitions attribute to them.The second reas~ why we decided to use I~R as semanticformalism for LFG is that the constraction principles for asentence S(i) of a text D = S(1), .... S(n) are fozmulated withrespect to the semantic representation of the prec~Ing  textS(1),... ,S(i-l).
1~erefore the theory can accotmt forintersentential semantic relationships in the same way as forintrasentential ones.
~ is the second requirement: as~antic representation has to represent the discourse as awhole and not as the mere union of the s~antic representationsof its isolated sentences.A third requirenent a senantlc representation has to fulfill isthe reflection of configurational restrictions on anaphoriclinks: If one embeds sentence (2) into a conditional(6) *If every man who admires a woman kisses her then she isstressedthe anaphoric link in (2) is preserved.
But (6) does - forconfigurational reasons - not allow for an anaphoric relationbetween the "she" and "a woman".
The same happensintersententially as shown by(7) If Jo~m admires a woman tl~n he kisses her.
*She isenraged.A last requirement we will stipulate here is the following: Itis neccessary to draw inferences already during the constructionof the semantic representation o f  a sentence S(i) of thediscourse.
The inferences must operate on the semanticrepresentation of the already analyzed discourse S(1),... ,S(i-l)as well as on a database containing the knowledge the text talksabout.
~ requirement is of major importance for the analysisof definite descriptions.
Consider(8) Pedro is a farmer.
If a woman loves him then he is happy.Mary loves Pedro.
The happy farmer marries herin which the definite description "the happy farme' is used torefer to refer to the individual denoted by "Pedro".
In orderto get this llnk one has to infer that Pedro is indeed a happyfarmer and that he is the only ore.
If this were not the casethe use of the definite description would not he appropriate.Such a deduction mechanism is also needed to analyse sentence(9) John bought a car.
the engine has 160 horse powersIn this case one has to take into account some ~nowledge of theworld, nanely the fact that every car has exactly one engine.To illustrate the ~y the s~mmtic representation has to beinterpreted let us have a brief look at the text-~RS for thesample discourse (8)\[ Pedrou v love(v,u)I leve(y,u)I~u ,v )ThUS a IRS K consists of(i) a set of discourse referents: discourse individuals,discourse events, discourse propositions, etc.
(il) a set of conditions of the following types- atomic conditions, i.e.
n-ary relations over discoursereferents- complex conditions, i.e.
n-ary relations (e.g.
--> or :)over sub-~S's and discourse referents (e.g.
K(1) --> K(2) or55p:K, where p is a discourse proposition)A whole ~S can be tmderstoed as partial model representing theindividuals introduced by the discourse as well as the facts andrules those individuals are subject to.The truth conditions state that a IRS K is true in a model M ifthere is a proper imbedding from K Into M. Proper embedding isdefined as a f~mction f from the set of discourse referents of Kin to M s.t.
(i) it is a homomorphism for the atomic conditionsof the IRS and (il) - for the c~se of a complex condition K(1)--> I((2) every proper embedding of K(1) that extends f isextendable to a proper embedding of K(2).- for the case of a complex condition p:K the modelthenretlcobject correlated with p (i.e.
a proposition if p is adiscourse proposition, an event if p is a discourse event, etc.
)must be such that it allows for a proper embedding of K in it.Note that the definition of proper embedding has to be made moreprecise in order to adapt it to the special s~nantica one usesfor propositional attitudes.
We cannot go into details bare.Nonet/~lese the truth condition as it stands should make clearthe following: whether a discourse referent introduced impliesexistence or not depends on its position in the hierarchy of theIRS's.
C/ven a nRS which is true in M then eactly thosereferents introduced in the very toplevel \[RS imply existence;all others are to he interpreted as ~iversally quantified, ifthey occur in an antecedent IRS, or as existentially quantifiedif they occur in a consequent BRS, or as having opaque status ifthey occur in a ~S specified by e.g.
a discourse proposition.Tnus the role of the hierarchical order of the BRS's is to builda base for the definition of truth conditions.
But furthemnorethe hierarchy defines an accessibility relation, which restrictsthe set of possible antecedents of anaphorie NP's.
Ibisaceessibiltity relation is (for the fra~nent in \[~\]) defined asfollows:For a given sub-ERS K0 all referents occurring in NO or in anyof the n~S's in which NO is embedded are accessible.Furthermore if NO is a consequent-~S then the referentsoccurring in its corresponding antecedent I\]~S on the left areaccessible too.This gives us a correct trea~aent for (6) and (7).For the time being - we have no algorithm which restricts andorders the set of possible anaphorie antecedents ~-*-ording tocontextual conditions as given by e.g.
(5) John is reading a book on syntax and Bill is reading a bookon s~-oatics oa paperback JTherefore our selection set is restricted only by theaccessibility relation and the descriptive content of theanaphoric NP" s. Of course for a~apheric pronouns this contentis reduced to a minimum, namely the grm~rstical featuresassociated to them by the lexical entries.
This accounts e.g.for the difference in acceptability of (I0) and (II).
(I0) Mary persuaded every man to shave |dmself(II) *~4ary promised every man to shave himselfThe ~S's for (i0) and (II) show that beth discourse referents,the one for '~r~' and the one for a '~an", are accessible fromthe position at which the reflexive prex~an has to be resolved.But if the '~dmselP' of (ii) is replaced by x it cannot heidentified with y having the (not explicitely shown) featurefemale.Ii0")I Y *~')/ / mary = y/ ipers~de(y~,p)l/ ~ prom~(y~,p)Definite d e s e ~ t u e  of thesemantic content of their co,mon-noun-phrases and the existenceand ~niqeeness conditions presupposed by th~n.
"~erefore inorder to analyse definite descriptions we look for a discoursereferent introduced in the preceding IRS for which thedescription holds and we have to check whether this descritionholds for one referent only.
Our algorithm proceeds as follows:First we build up a small IRS NO encoding the descriptivecontent of the common-no~-phrase of the definite descriptiontogether with its ~miqlmess and existency condition:El): xfarmer(x)happy(x)Y I L happy(y) _\],%econd we have to show that we can prove I<0 out of the text-nRSof the preceeding discourse , with the restriction that onlyaccessible referents are taken into account.
The instantiationof *x by this proof gives us the correct anteoedent the definitedescription refers to.
Now we forget about NO and replace theantecedent discourse referent for the definite noun phrase toget the whole text-IRS (8').Of course it is possible that the presuppositions are notmentioned explicitely in the discourse but follow implicitelyfrom the text alone or from the text together with the knowledgeof the domain it talks about.
So in cases like(9) John bought a car.
The engine has 260 horse powersPere the identified referent is functionally related toreferents that are more directly accessible, nmne_ly to John'scar.
Furthermore such a functional dependency confers to adefinite description the power of introducing a new discoursereferent, nanely the engine which is functionally determined bythe car of which it is part.
~ shifts the task from thesearch for a direct antecedent for "the engine" to the searchfor the referent it is f%mctionelly related to.
But the basicmechanism for finding this referent is the same deduct ivemechanism just outlined for the '~lappy farme~" example.III.
~CWARIB AN ~ f ~  ~ "GRAMMATICAL PARSIAK~' AND"lOGICAL P~RSIN~'In this section we will outline the principles anderlying theextension of our parser to produce ~S's  as output.
Becausenone of the fragments of ~T  contains Raising- and Equi-verbstaking infinitival or that-complements we are confronted withthe task of writing construction rules for such verbs.
It willturn out, however, that it is not difficult to see how to extend~T to eomprise such constructions.
"ibis is due to the factthat using LFG as syntactic base for IRT - and not thecategorial syntax of Kamp - the ~raveling of the thematicrelations in a sentence is already accomplished in f-structure.Therefore it is streightfo~rd to formulate construction ruleswhich give the correct readings for (i0) and (ii) of theprevious section, establish the propositional equivalence ofpairs with or without Raising, Equi (see (I), (2)), etc.
(I) John persuaded Mary to come(2) John persuaded ~%~ry that she should comelet us first describe the BRS construction rules by the f~niliarexample(3) every man loves a womanUsing Ksmp's categorial syntax, the construction rules operatetop down the tree.
The specification of the order in which theparts of the tree are to he treated is assumed to be given bythe syntactic rules.
I.e.
the specification of scope order isdirectly determined by the syntactic construction of thesentence.
We will deal with the point of scope ambiguitiesafter baying described the ~y  a BRS is constructed.
Ourdescription - operating bottom up instead top down - isdifferent from the one given in \[4\] in order to come closer tothe point we want to make.
But note that this differei~ce is not~l genuine one.
~hus according to the first requiranent of theprevious section we assume that to each semantic from a semanticstructure is associated.
For the lexical entries of (3) we ~mve56the follc~ing:man --> man(*) a -->woman--> woman(*) every --> \[ \[-x--\] -.
\[-~ \[loves --> love(*,*)Ehe semantic structures for the common nouns and the verbs eren-place predicates.
The structure for "a" is a IRSwithdiscourse individual v. introduced and conditions not yetspecified, q~e entry for "every' is a ~S with no discourseindividuals introduced an the toplevel.
It contains however acompl~ condition ED --> KI s.t a discourse individusl x isintreduced in ~3 and both ED and K1 contain any otherconditions.The IRS constroction rules specify how these s~nantic structuresare to be ecmbined by propagating them up the tree.
~e  easiestway to illustrate that is to do it by t_he following picture (forthe case of marrow scope readin~ of '% woman"):man(*) love(*,*) \ [ \ ]  woman(*)/ I I I Ievery man _ loves a womanFor the wide scope reading the 5R~-tree of "a wonmn" is treatedat the very end to giveY 1(5) ~ Woman(~The picture should make clear the way we ~mnt to extend theparsing mechanism described in section 1 in order to produce~S's as output ~ no more f-stroctures: instead of partiallyinstantiated f-structures determined by the lexical entriespartially instsntiated IRS's are passed eround the tree gettingaocc~plished by unification.
Toe control mechanism of LFG willautomatically put the discourse referents into the correctargument position of the verb.
lhus no additional work has tobe done for the g~=~,~atical relations of a sentence.But what about the logical relations?Recall that each clause has a unique head end that thefunctional features of each phrase are identified with those ofits head.
For (3) the head of S -~> NPVP is the VP and thehead of VP --> V NP is the V. %h~m the outstanding role of theverb to determine and restrict the grmmmtical'relations of thesentence is captured.
(4) , however, shows that the logicalrelations of the sentence are mainly determined by itsdeterminers, which are not ~eads of the NP-phrases and theNP~phrases thsmselves are not the heads of the VP- and S-phraserespectively.
To account foc this dichotomy we will call thesyntactically defined notion of head "grammatical head" and wewill introduce a further notion of "logical head" of a phrase.Of course, in order to make the definition work it has to beelaborated in a way that garantses that the logical head of aphrase is uniquely determied too.
Consider(~) John pe.rsuaded an american to win(7) John expected an american to winfor ~dch we propose the following ORS's|amerlcan(y) p: ~- -~\[persuade(j ,y,p)(7") " (7" )  j yJohn = j Jolm = J\[ expect(j ,p) amerlcaa(y)\[p:\[  y expect(j ,p)mmericm1(y) p:\[ hwin(y)The fact that (7) does not neccesserily imply existence of ~m8merlcan whereas (6) does is triggered by the difference betweenEqul- and R~dslng-verbe.Suppose we define the NP to he the logical hend of the phrase VP--> V NP VP I.
~ the logical relations of the VP would bethose of the ~E ~.
This amounts to incorporating the logicalstructures of the V and the VP ~ into the logical structure of theNP, which is for both (6) and (7)and thus would lead to the readings represented in (6") and(7").
0onsequentiy (7") ~mlld not he produced.Defining the logical head to be the VP | would exclude ther~a~.gs (6") and (7"').Evidently the last possibility of defining the logical head tobe identical to the grammatical head, namely the V itself, seemsto be the only solution.
But this would block the constructionalready at the stage of unifying the NP- and VPhstructures withpersuade(*,*,*) or expect(*,*).
At first thought one easy wayout of this dilemma is to associate with the lexical entry ofthe verb not the mere n-place predicate but a IRS containingthis predicate as atomic condition, lhis makes the ~lificationpossible but gives us the following result:Jo = j\[american(~)l ~~pers~de(j ,*,p)~ IOf course o o e ~ i s  open to produce the set of~S 's  representing (6) and (7).
BUt th is  means that one has towork on ( * )a f te r  having reached the top of the tree - aconsequence that seems undesirable to us.the only way out is to consider the logical  head as notbeing uniquely identified by the mere phrase structureconfigurations.
As the above example for the phrase VP --> V NPVP ~ shows its head depends on the verb class too.
But we willstill go further.We claim that it \[s possible to make the logical head toadditionslly depend on the order of the surface string, on theuse of active and passive voice and probably others.
Ibis willgive us a preference ordering of the scope ambiguities ofsentences as the following:- Every man loves a Woman- A Woman is loved by every man- A ticket is bought by every man- Every man bought a ticket%he properties of ~lification granmers listed above show thatthe theoretical frsm~ork does not impose any restrictions onthat plan.REFERENCESif\] Bresnsn, J.
(ed.
), "the Mental Representation of GrsmmaticalRelations".
MIT Press, Cambridge, Mmss., 1982\[2\] Frey, Weroer/ Reyle, L~e/ Rohrer, O~ristian, "A-tomaticConstruction of a Knowledge Base by Analysing Texts inNatural fan, rage", in: Proceedings of the Eigth Intern.Joint Conference on Artificial Intelligence II, \[g83\[3\] P~Iverson, P.-k., "S~antics for Lexicai FlmctionalGrammaP'.
In: Linguistic Inquiry 14, 1982\[4\] Kamp, Pmns, "A ~eory of Truth and S~m~ntic Representa=tion".
In: J.A.
Groenendijk, T.U.V.
(ed.
), FormalSemantics in the Study of Natural language I, 198157
