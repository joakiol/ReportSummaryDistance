Proceedings of the 4th Biennial International Workshop on Balto-Slavic Natural Language Processing, pages 78?83,Sofia, Bulgaria, 8-9 August 2013. c?2010 Association for Computational LinguisticsNamed Entity Recognition in EstonianAlexander TkachenkoInstitute of Computer ScienceUniversity of TartuLiivi 2, Tartu, Estoniaalex.tk.fb@gmail.comTimo PetmansonInstitute of Computer ScienceUniversity of TartuLiivi 2, Tartu, Estoniatimo p@ut.eeSven LaurInstitute of Computer ScienceUniversity of TartuLiivi 2, Tartu, Estoniaswen@math.ut.eeAbstractThe task of Named Entity Recognition(NER) is to identify in text predefinedunits of information such as person names,organizations and locations.
In this work,we address the problem of NER in Esto-nian using supervised learning approach.We explore common issues related tobuilding a NER system such as the us-age of language-agnostic and language-specific features, the representation ofnamed entity tags, the required corpus sizeand the need for linguistic tools.
Forsystem training and evaluation purposes,we create a gold standard NER corpus.On this corpus, our CRF-based systemachieves an overall F1-score of 87%.1 IntroductionNamed Entity Recognition (NER) is the task ofidentification of information units in text such asperson names, organizations and locations.
It isan important subtask in many natural languageprocessing (NLP) applications such as text sum-marization, information filtering, relation extrac-tion and question answering.
NER has beenextensively studied for widely spoken languagessuch as English with the state-of-the-art systemsachieving near-human performance (Marsh andPerzanowski, 1998), but no research has yet beendone in regards to Estonian.The main difference of Estonian, a Finno-Ugriclanguage, compared to English is high morpholog-ical richness.
Estonian is a synthetic language andhas relatively high morpheme-per-word ratio.
Ithas both agglutinative and fusional (inflective) el-ements: morphemes can express one or more syn-tactic categories of the word.
Although Estonian isconsidered a subject-verb-object (SVO) language,all phrase permutations are legal and widely used.These factors make NLP for Estonian particularlycomplicated.In this work, we address the problem of NER inEstonian using supervised learning approach.
Weexplore common issues related to building a NERsystem such as the usage of language-agnostic andlanguage-specific features, the representation ofnamed entity tags, the required corpus size and theneed for linguistic tools.To train and evaluate our system, we have cre-ated a gold standard NER corpus of Estonian newsstories, in which we manually annotated occur-rences of locations, persons and organizations.Our system, based on Conditional Random Fields,achieves an overall cross-validation F1-score of87%, which is compatible with results reported forsimilar languages.Related work.
The concept of NER originatedin the 1990s in the course of the Message Under-standing Conferences (Grishman and Sundheim,1996), and since then there has been a steady in-crease in research boosted by evaluation programssuch as CoNLL (Tjong Kim Sang and De Meul-der, 2003) and ACE (ACE, 2005).
The earliestworks mainly involved using hand-crafted linguis-tic rules (Grishman, 1995; Wakao et al 1996).Rule-based systems typically achieve high preci-sion, but suffer low coverage, are laborious tobuild and and not easily portable to new text do-mains (Lin et al 2003).
The current dominant ap-proach for addressing NER problem is supervisedmachine learning (Tjong Kim Sang and De Meul-der, 2003).
Such systems generally read a largeannotated corpus and induce disambiguation rulesbased on discriminative features.
Frequently usedtechniques include Hidden Markov Models (Bikelet al 1997), Maximum Entropy Models (Benderet al 2003) and Linear Chain Conditional Ran-dom Fields (McCallum and Li, 2003).
The down-side of supervised learning is the need for a large,78annotated training corpus.Recently, some research has been done on NERfor highly inflective and morphologically rich lan-guages similar to Estonian.
Varga and Simon(2007) report F1-score of 95% for Hungarian inbusiness news domain using a Maximum Entropyclassifier.
Notably, authors state that morpho-logical preprocessing only slightly improves theoverall performance.
Konkol and Konop?
?k (2011)also use Maximum Entropy based approach forNER in Czech achieving 79% F1-score.
Pinnis(2012) reports F-score of 60% and 65% for Lat-vian and Lithuanian languages respectively us-ing CRF classifier with morphological preprocess-ing and some custom refinements.
Ku?c?u?k andothers (2009) describe a rule-based NER systemfor Turkish language which achieves F1-score of79%.
We observe that the reported results are no-tably inferior compared to well-studied languagessuch as English.
This can be explained by the lan-guage complexity and the lack of required linguis-tic tools and annotated corpora.2 The CorpusPapers on NER for English language commonlyuse publicly available named entity tagged corporafor system development and evaluation (TjongKim Sang and De Meulder, 2003; Chinchor,1998).
As no such resources are available for theEstonian, we have built our corpus from scratch.Our corpus consists of 572 news stories publishedin the local online newspapers Delfi1 and Pos-timees2 between 1997 and 2009.
Selected articlescover both local and international news on a rangeof topics including politics, economics and sports.The total size of the corpus is 184,638 tokens.The raw text was preprocessed using the mor-phological disambiguator t3mesta (Kaalep andVaino, 1998).
The processing steps involve tok-enization, lemmatization, part-of-speech tagging,grammatical and morphological analysis.
The re-sulting dataset was then manually name entitytagged.
Due to the limited resources, the cor-pus was first tagged by one of the authors andthen examined by the other, after which conflictingcases were resolved.
Following the MUC guide-lines (Chinchor, 1998), we distinguish three typesof entities: person names (PER), locations (LOC)and organizations (ORG).
Words that do not fall1http://delfi.ee2http://postimees.eeFigure 1: Cumulative number of examples cov-ered by unique entities, starting with the most fre-quent.into any of these categories were tagged as other(O).
We assume that named entities do not over-lap.
In case a named entity is contained withinanother named entity, only the top-level entity isannotated.
Table 1 and Figure 1 give an overviewof named entity occurrences in the corpus.PER LOC ORG TotalAll 5762 5711 3938 15411Unique 3588 1589 1987 7164Table 1: Number of named entities in the corpus.The corpus is organized closely follow-ing CoNLL03 formatting conventions (TjongKim Sang and De Meulder, 2003).
In a data file,each line corresponds to a word with empty linesrepresenting sentence boundaries.
Each line con-tains four fields: the word itself, its lemma, itsgrammatical attributes3 and its named entity tag.Named entity tags are encoded using a widelyaccepted BIO annotation scheme (Ramshaw andMarcus, 1995).
Figure 2 demonstrates an examplesentence.The corpus is freely available for research pur-poses and is accessible at the repository of publiclanguage resources of Tartu University (Laur et al3Definition of the attributes can be found athttp://www.cl.ut.ee/korpused/morfliides/seletus.php?lang=en7911.
11.+0 O ?
Ojuunil juuni+l S sg ad Olaastas laasta+s V s Otromb tromb+0 S sg n ORaplamaal Rapla maa+l H sg ad B-LOCLo?pemetsa Lo?pe metsa+0 H sg g B-LOCku?la ku?la+0 S sg n I-LOC.
.
Z OFigure 2: An example sentence in the corpus: Onthe 11th of June, a tornado devastated Lypemetsavillage in Rapla county.2013).3 System OverviewTwo important components in the design of a NERsystem are features and a learning algorithm.
Fea-tures encode characteristic attributes of words rel-evant for the classification task.
Possible examplesof features are word lemma, part of speech, occur-rence in some dictionary.
The task of a learningalgorithm is to study the features over a large col-lection of annotated documents and identify rulesthat capture entities of a particular type.3.1 FeaturesIn our system, we have implemented the followinggroups of features:Base-Line Features.
This group includes fea-tures based mostly on the word?s orthog-raphy: (1) word itself in lowercase; (2)word prefixes and suffixes of lengths 3-4; (3)word type: is-capitalized, all-capitalized, is-number, is-alphanumeric, contains-dash, contains-apostrophe, contains-digit, contains-dot, contains-capitalized-letter, is-punctuation-mark; (4) wordparts before and after a dash in case of compoundwords; (5) whether the word is first in the sen-tence.Morphological Features.
These features arebased on information provided by morphologicaldisambiguator t3mesta: word lemma, POS-tag,word case, word ending, constituent morphemes.Dictionary-based Features.
We composed alarge dictionary of entities covering common per-son names and surnames, local and internationalorganizations and geographical locations.
The dic-tionary contains entities in both Estonian and En-glish.
The lists of Estonian entities were obtainedfrom multiple public on-line resources.
A largecollection of entities in English was downloadedfrom the web site of the Illinois Named EntityTagger (Ratinov and Roth, 2009).
Table 2 givesan overview of dictionary size and content.
Thedictionary covers 21% of the unique entities inthe corpus, out of which 41% are unambiguous,meaning that the entity matches exactly one cate-gory in the dictionary.Collected entities were preprocessed with amorphological disambiguator t3mesta.
Wordswere replaced with their lemmas and turned tolower case.
For a dictionary lookup we employeda leftmost longest match approach.Dictionary Type SizeCommon Estonian first names (KeeleWeb, 2010) 5538Common first and second names in English 9348(Ratinov and Roth, 2009)Person full names in English (Ratinov and Roth, 2009) 877037Estonian locations (Maa-amet, 2013) 7065International locations in Estonian (Pa?ll, 1999) 6864Locations in English (Ratinov and Roth, 2009) 5940Estonian organisations (Kaubandus-To?o?stuskoda, 2010) 3417International organisations (Ratinov and Roth, 2009) 329Total 903279Table 2: Dictionaries and numbers of entries.WordNet Features.
Estonian Wordnet is aknowledge base containing more than 27000different concepts (sets of synonymous words)(Kerner et al 2010).
Wordnet encodes various se-mantic relationships between the concepts, whichcan be used as valuable information in NER tasks.Based on the lemmas and their part-of-speech,we used Wordnet relations to encode hyperonymy,be in a state, belongs to a class and synset id infor-mation as extra features.Global features.
Global features enable to ag-gregate context from word?s other occurrences inthe same document (Chieu and Ng, 2003).
We im-plemented global features as described in (Ratinovand Roth, 2009).
For each occurrencew1, .
.
.
, wNof the word w the set of features c(wi) is gener-ated: (1) word is capitalized in document at anyposition, but the beginning of a sentence; (2) pre-ceding word is a proper name; (3) following wordis a proper name; (4) preceding word?s presencein gazetteers; (5) following word?s presence ingazetteers.
Then, a set of features of the word w isextended with the aggregated context?Ni=1 c(wi).803.2 Learning AlgorithmIn this work, we use conditional random fieldsmodel (CRFs).
CRFs are widely used for the taskof NER due to their sequential nature and abilityto handle a large number of features.
Our choiceis also substantiated by our earlier experiments onEstonian NER, where CRFs have demonstratedsuperior performance over a Maximum Entropyclassifier (Tkachenko, 2010).
We use CRFs imple-mented in the Mallet software package (McCal-lum, 2002).4 Experiments and ResultsIn this section, we conduct a number of experi-ments to investigate the system behavior with re-spect to different factors.We assess system performance using standardprecision, recall and F1 measure (Tjong Kim Sangand De Meulder, 2003).
Scores for individual en-tity types are obtained by averaging results of 10-fold cross-validation on the full dataset.
Whensplitting the data, document bounds are taken intoaccount so that content of a single document fullyfalls either into training or test set.
In this way,we minimize terminology transfer between sam-ples used for training and testing.
To summarizethe results of an experiment with a single number,we report the weighted average of a correspondingmeasure over all entity types.4.1 Named Entity Tag RepresentationThe choice of NE tag representation scheme hasbeen shown to have significant effect on NER sys-tem performance (Ratinov and Roth, 2009).
In thisexperiment, we set out to determine which schemeworks best for the Estonian language.
We considertwo frequently used schemes ?
BIO (Ramshawand Marcus, 1995) and BILOU.
BIO format iden-tifies each token as either the beginning, inside oroutside of NE.
BILOU format additionally distin-guishes the last token of multi-token NEs as wellas unit-length NEs.
Hence, given NEs of threetypes (per, loc, org), the BIO scheme will produce7 and BILOU 13 distinct tags.Table 3 compares system performance usingBIO and BILOU schemes.
BILOU outperformsBIO in both precision and recall achieving a mod-est, but statistically significant 0.3 ppt improve-ment in F1-score.
This agrees with related re-search for the English language (Ratinov andRoth, 2009).
In the following experiments we useScheme P (%) R (%) F1 (%)BIO 87.0 86.3 86.7BILOU 87.5 86.6 87.0Table 3: End system performance using BIO andBILOU tag representation schemes.
BILOU out-performs BIO (p-value 0.04).a superior BILOU scheme.4.2 Feature Utility AnalysisFeature group P (%) R (%) F1 (%)1) Baseline 83.3 76.8 79.92) 1) + Morphological 85.3 84.0 84.73) 2) + Dictionary 86.3 85.1 85.74) 2) + WordNet 85.4 84.2 84.85) 2) + Global 85.7 84.7 85.26) All Features 87.5 86.6 87.0Table 4: System performance using differentgroups of features.Table 4 illustrates system performance usinggroups of features introduced in Section 3.1.
Wenote that for each token we have included fea-tures from its immediate neighbors in the win-dow of size 2.
Morphological features demon-strate a major effect, increasing F1-score by 4.8ppt.
Further inclusion of Dictionary, WordNet andGlobal features improves F1-score by 1.0, 0.1 and0.5 ppt respectively.
By combining all groups offeatures, we achieve an overall F1-score of 87%.Results for individual types of named entities arepresented in Table 5.
It is worth mentioning, thatwe have also attempted to do automatic feature se-lection using ?2-test and by discarding infrequentfeatures.
However, both methods resulted in a sig-nificant loss of performance.NE type P (%) R (%) F1 (%)PER 90.2 91.6 90.9ORG 80.0 74.7 77.1LOC 89.4 89.6 89.5ALL 87.5 86.6 87.0Table 5: End-system performance.4.3 Corpus SizeIn this experiment, we study our system?s learningcapacity with respect to the amount of the train-ing material.
For this purpose, we repeat a 10-81fold cross-validation experiments with an increas-ing number of documents.
In Figure 3, we observethe steepest gain in performance up to 300 doc-uments, which further starts to flatten out.
Thisindicates that our corpus is of an appropriate sizefor the task at hand, and that our system design isfeasible.Figure 3: End-system smoothed F1-score withincreasing number of documents in the cross-validation corpus.
Shaded area depicts 95% confi-dence interval.4.4 NER without Morphological AnalysisIn the previous section, we have shown that ex-tending the baseline feature set with morpholog-ical features significantly boosts system perfor-mance.
However, morphological analysis was per-formed with a commercial tool which may not beavailable due to licensing restrictions.
It is, there-fore, interesting to explore system performancewithout using such language specific features.
Inthis experiment, we omit all the features producedby morphological analyzer.
Since we still want touse dictionary and global features, we need to ad-dress an issue of word form normalization.
Forthis purpose, we have built a simple statistical lem-matizer by analyzing lemmas and their inflectedforms in Estonian Reference Corpus (Kaalep et al2010).
As a result, we have achieved F1-score of84.8% ?
a 2.2 ppt decrease compared to the bestresult (see Table 6).We conclude that even for highly inflective lan-guages such as Estonian simple techniques forlemmatizer P (%) R (%) F1 (%)custom 86.4 83.3 84.8t3mesta 87.5 86.6 87.0Table 6: Performance comparison of NER systemsusing t3mesta and our custom-built lemmatizer.word form normalization, such as our lemmatizer,enable to achieve performance not much inferiorthan sophisticated linguistic tools.5 ConclusionsIn this work, we have addressed design challengesin building a robust NER system for Estonian.Our experiments indicate that a supervised learn-ing approach using a rich set of features can effec-tively handle the complexity of the language.
Wedemonstrated the importance of the features basedon linguistic information, external knowledge andcontext aggregation.
We observed that the choiceof tag representation scheme affects system per-formance with BILOU outperforming a widelyused BIO scheme.
We also showed that an accept-able performance in NER can be achieved with-out using sophisticated language-specific linguis-tic tools, such as morphological analyzer.
Last, butnot least, we have built a first gold standard cor-pus for NER in Estonian and made it freely avail-able for future studies.
On this corpus, our sys-tem achieves an overall cross-validation F1-scoreof 87%.AcknowledgmentsWe would like to thank Filosoft4 for kindly provid-ing us morphological disambiguator t3mesta.ReferencesACE.
2005.
Automatic content extraction 2005 eval-uation.
Webpage: http://www.itl.nist.gov/iad/mig//tests/ace/ace05/.Oliver Bender, Franz Josef Och, and Hermann Ney.2003.
Maximum entropy models for named entityrecognition.
In Proceedings of the seventh confer-ence on Natural language learning at HLT-NAACL,volume 4, pages 148?151.
Association for Compu-tational Linguistics.Daniel M Bikel, Scott Miller, Richard Schwartz, andRalph Weischedel.
1997.
Nymble: a high-performance learning name-finder.
In Proceedings4http://www.filosoft.ee82of the fifth conference on Applied natural languageprocessing, pages 194?201.
Association for Compu-tational Linguistics.Hai Leong Chieu and Hwee Tou Ng.
2003.
Named en-tity recognition with a maximum entropy approach.In In Proceedings of the Seventh Conference on Nat-ural Language Learning, pages 160?163.Nancy Chinchor.
1998.
Muc-7 named entity task defi-nition, version 3.5.
In Proc.
of the Seventh MessageUnderstanding Conference.Ralph Grishman and Beth Sundheim.
1996.
Messageunderstanding conference-6: A brief history.
In Pro-ceedings of COLING, volume 96, pages 466?471.Ralph Grishman.
1995.
The NYU system for MUC-6or where?s the syntax?
In Proceedings of the 6thconference on Message understanding, pages 167?175.
Association for Computational Linguistics.Heiki-Jaan Kaalep and Tarmo Vaino.
1998.
Kas valemeetodiga o?iged tulemused?
Statistikale tugineveesti keele morfoloogiline u?hestamine.
Keel ja Kir-jandus, pages 30?38.Heiki-Jaan Kaalep, Kadri Muischnek, Kristel Uiboaed,and Kaarel Veskis.
2010.
The Estonian ReferenceCorpus: its composition and morphology-aware userinterface.
In Proceedings of the 2010 conference onHuman Language Technologies?The Baltic Perspec-tive: Proceedings of the Fourth International Con-ference Baltic HLT 2010, pages 143?146.
IOS Press.Eesti Kaubandus-To?o?stuskoda.
2010.
List of Estonianorganizations.
Available at http://www.koda.ee/?id=1916.KeeleWeb.
2010.
List of common Estonian firstnames.
Available at http://www.keeleveeb.ee/.Kadri Kerner, Heili Orav, and Sirli Parm.
2010.Growth and revision of Estonian WordNet.
Princi-ples, Construction and Application of MultilingualWordnets, pages 198?202.Michal Konkol and Miloslav Konop??k.
2011.
Max-imum entropy named entity recognition for Czechlanguage.
In Text, Speech and Dialogue, pages 203?210.
Springer.Dilek Ku?c?u?k et al2009.
Named entity recognitionexperiments on Turkish texts.
In Flexible Query An-swering Systems, pages 524?535.
Springer.Sven Laur, Alexander Tkachenko, and Timo Petman-son.
2013.
Estonian NER corpus.
Available athttp://metashare.ut.ee/repository/search/?q=Estonian+NER+corpus.Winston Lin, Roman Yangarber, and Ralph Grishman.2003.
Bootstrapped learning of semantic classesfrom positive and negative examples.
In Proceed-ings of ICML-2003 Workshop on The Continuumfrom Labeled to Unlabeled Data, volume 1, page 21.Maa-amet.
2013.
List of Estonian locations.
Avail-able at http://www.maaamet.ee/index.php?lang_id=1&page_id=505.Elaine Marsh and Dennis Perzanowski.
1998.
Muc-7evaluation of IE technology: Overview of results.
InProceedings of the seventh message understandingconference (MUC-7), volume 20.Andrew McCallum and Wei Li.
2003.
Early results fornamed entity recognition with conditional randomfields, feature induction and web-enhanced lexicons.In Proceedings of the seventh conference on Nat-ural language learning at HLT-NAACL, volume 4,pages 188?191.
Association for Computational Lin-guistics.
TEST.Andrew Kachites McCallum.
2002.
Mallet: A ma-chine learning for language toolkit.
Available athttp://mallet.cs.umass.edu/.Ma?rcis Pinnis.
2012.
Latvian and Lithuanian namedentity recognition with TildeNER.
Seed, 40:37.Peeter Pa?ll.
1999.
Maailma kohanimed.
Eesti KeeleSihtasutus.
Available at http://www.eki.ee/knab/mkn_ind.htm.Lance A Ramshaw and Mitchell P Marcus.
1995.
Textchunking using transformation-based learning.
InProceedings of the Third ACL Workshop on VeryLarge Corpora, pages 82?94.
Cambridge MA, USA.Lev Ratinov and Dan Roth.
2009.
Design challengesand misconceptions in named entity recognition.
InProceedings of the Thirteenth Conference on Com-putational Natural Language Learning, pages 147?155.Erik F Tjong Kim Sang and Fien De Meulder.2003.
Introduction to the CoNLL-2003 shared task:Language-independent named entity recognition.
InProceedings of the seventh conference on Naturallanguage learning at HLT-NAACL, volume 4, pages142?147.
Association for Computational Linguis-tics.Alexander Tkachenko.
2010.
Named entity recogni-tion for the Estonian language.
Master?s thesis, Uni-versity of Tartu.Da?niel Varga and Eszter Simon.
2007.
Hungariannamed entity recognition with a maximum entropyapproach.
Acta Cybernetica, 18(2):293?301.Takahiro Wakao, Robert Gaizauskas, and YorickWilks.
1996.
Evaluation of an algorithm for therecognition and classification of proper names.
InProceedings of the 16th conference on Computa-tional linguistics-Volume 1, pages 418?423.
Asso-ciation for Computational Linguistics.83
