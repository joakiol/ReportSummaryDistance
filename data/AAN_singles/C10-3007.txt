Coling 2010: Demonstration Volume, pages 25?28,Beijing, August 2010YanFa: An Online Automatic Scoring and Intelligent FeedbackSystem of Student English-Chinese TranslationYan TianSchool of Foreign LanguagesShanghai Jiao Tong Universitytianyan@sjtu.edu.cnAbstractOnline learning calls for instant assess-ment and feedback.
YanFa is a systemdeveloped to score online English-Chinese translation exercises with intel-ligent feedback for Chinese non-Englishmajors.
With the aid of HowNet andCilin?Chinese Synonym Set (ExtendedVersion), the system adopts the hybridapproach to scoring student translationsemantically.
It compares student trans-lation with model translation by Syno-nym Matching, Sentence-pattern Match-ing and Word Similarity Calculating re-spectively.
The experiment results showthat the correlation ratio between thescores given by the system and by hu-man raters is 0.58, which indicates thatthe algorithm is able to fulfill the task ofautomated scoring.
YanFa is also able toprovide feedback on syntactic mistakesmade by students through interactingwith them.
It asks students to analyzethe English sentence elements.
Then itcompares the student analyses withthose of the parser and points out theparts which might lead to their wrongunderstanding as well as their wrongtranslating.1 IntroductionOnline language learning and instructing arepopular in the era of the Internet which calls forinstant automated assessment and intelligentfeedback.
How to provide online translationexercises with immediate scoring and intelligentfeedback is a challenging task.
Although someresearchers (Wang & Chang, 2009; Wen, et al,2009) have investigated ways to score studenttranslation, they did not aim at fully automatedscoring of translation, nor did they try to serveonline exercise scoring.
Wang & Changdiscussed methods of the human-aidedautomated assessment of translation tests infinal exams, and Wen adopted bilingualalignment technology to score translation inlanguage testing.
However, online fullyautomated scoring of translation exercises hasits own characteristics.
Besides, providingonline instant intelligent feedback for studentspresents another challenge to natural languageprocessing.
Up to now very little research, ifany, has addressed this topic.
In order to meetthe demand of online automated scoring oftranslation exercises and to help students withintelligent feedback, an online automatedscoring and intelligent feedback system, calledYanFa, has been developed.This paper aims to outline the framework ofYanFa.
The paper addresses this by explainingtwo modules of YanFa, namely, the automaticscoring module and the intelligent feedback25module.
In order to test the accuracy of YanFa,a study with 200 college students was carriedout at Shanghai Jiao Tong University.
The re-search intends to verify whether YanFa is ableto undertake the task of online automated scor-ing of student English-Chinese translation aswell as the task of providing students with feed-back on the mistakes in their comprehending ofEnglish sentences, which might lead to theirwrong Chinese translation.
This paper beginswith an introduction, followed by the explana-tion of the two modules.
The experiment is alsodescribed.
The research findings suggest thatYanFa is eligible not only to score studentonline translation, but also to provide feedbackon student syntactic mistakes in their under-standing.2 Automatic Scoring Module?Translating means translating meaning.?
(Nida,1986) Thus, ideally, automated translationscoring should be done at semantic level.Namely, the system should be able to judgewhether the student translation is correct inconveying the original meaning to the targetlanguage.
Therefore, the scoring module shouldbe able to analyze the meaning of studenttranslation which includes word meaning,phrase meaning as well as sentence meaningbecause translation involves two kinds oftransfer: lexical transfer and structural transfer(Hutchins, 1992).
Another consideration ofbuilding the module is to simulate the manualtranslation scoring practice in which thesentences are scored according to the correcttranslation of language points (words andphrases) and that of sentence structures.Usually, 3/4 scores are given to language pointsand 1/4 to sentence structures.The automatic scoring module is composedof two parts: the databases and the automaticscoring system.
The databases are English Pas-sage Pool, English Sentence Pool, Model Trans-lation Pool, Model Sentence Pattern Pool, Stu-dent Translation Pool.
The automatic scoringsystem is composed of a Chinese Parser(SharpICTCLAS.net with precision rate of97.58 % and recall rate of 90%), a Word Ana-lyzer, a Sentence Pattern Analyzer, a Rater.
Be-sides, Chinese resources, HowNet and Cilin?Chinese Synonym Set (Extended Version by theLab of Information Retrieval at Harbin Instituteof Technology), are also adopted.First, student translations are parsed bySharpICTCLAS.
Then the parsed sentences aresent to Word Analyzer to be compared with thepre-parsed model translations by the same par-ser.
Three different approaches are taken to dealwith different parts of speech respectively:nouns are compared with the synonyms in Cilin,of which the seed nouns are from the modeltranslations; verbs, adjectives and adverbs arecompared by calculating the word similaritywith the aid of HowNet.
Similarly, the seedverbs, adjectives and adverbs also come fromthe model translations.
The rest parts of speech,including idioms, are dealt with by key wordmatching method.
After word processing, Sen-tence Pattern Analyzer compares the sentencepatterns of student translations with the modelsentence patterns.
Last, the results of both ana-lyzers are sent to the Rater which calculates thefinal score of a student translation.
The formulasare as follows:The formula for Word Analyzer:Processing of nouns with Cilin:????????
)(,0)(,)(_skskkWWWCWlWclsem ?
?where )(_ kWclsem refers to the score of a nounin student translation, kW stands for a noun instudent translation, l  is the number of  parsedparts of speech in model translation, C is the26synonym set of Cilin which embraces the nounappeared in student translation, sW is a noun inmodel translation, ?
is the total score of thesentences, ?
is a constant.Processing of Verbs, Adjectives and Ad-verbs with HowNet:)),(()( maxarg1kimik WWsimWsimhn??
?where )( kWsimhn  is the maximum value of aprimitive, iW  is the primitive in HowNet, kW  isa word in student translation, 1<i <m means i isbigger than 1, but less than m (m is the numberof primitives).??
)()(_ kk WsimhnWhnsem ?where )(_ kWhnsem refers to the score of aword.Processing of other parts of speech:????????
)(,0)(,)(_skskkWTWWTWlWstsem ?
?where )(_ kWstsem means the score of otherparts of speech, T refers to the set of other partsof speech.The formula for Sentence Pattern Analyzer:(1 ) , ( Re )_ 0, ( Re )AnsTran reg Std gsim pat AnsTran reg Std g?
??
???
?
?
?where patsim_  stands for the score of thesentence pattern of a sentence, )Re( gStdregrefers to the set of model translation (standardversion) annotated by regular expression,AnsTran  means student translation.The formula for each sentence:_ ( ) (1 ) _kscore sim sem w sim pat??
?
??
?
?The formula for the total score of a passage(with 5 sentences to be translated as inYanFa system):5)_)1()(_( ????
patsimWsemsimTotalscore k ???
?3 Intelligent Feedback ModuleIt is believed that comprehending of a sourcelanguage plays a crucial role in its translation,especially when the source language is a foreignlanguage to a translator.
Accordingly, correctunderstanding of English sentences is essentialto its translating into Chinese.
Therefore, theintelligent feedback module focuses on whetherstudents could correctly understand the Englishsentences.
Specifically, feedback on correctunderstanding of clauses is provided rather thanthat of phrases because wrong translation occursfrequently on linguistic units larger than phraseswhen complex sentences are to be translated byChinese college students.The Intelligent Feedback Module iscomposed of three parts: parsing of the originalEnglish sentences, comparing student parsingresults with those of the parser, providingfeedback to students.3.1 ParsingThe module employs the English parser byCarnegie Mellon University (free online parser)to parse the original English sentences.
It takesthe advantage of the ?SBAR?
sign as the marksof clauses.
For example, following is the parsedresult of a sentence: ?Because I believe that lovebegins at home and if we can create a home forthe poor, I think that more and more love willspread.
?273.2 ComparingThe module asks students to mark clauses of theEnglish sentences.
Then it compares the markedclauses with the results parsed by the parserthrough string matching.
If the matching fails,the module comes to the decision that a wrongunderstanding happens.3.3 Providing feedbackThe module is able to provide students with thecomparison of their parsing with the right pars-ing of the whole sentences.
If requested, themodule is also able to present students with thecomparison of their wrongly parsed clauses withthe right ones.4 ExperimentIn order to test the accuracy of the automaticscoring system, 200 non-English majors atShanghai Jiao Tong University were invited totry the online scoring system at ?Shanghai JiaoTong University English Learning Center?(http://english.sjtu.edu.cn).
Then the scoreswere compared with those of two human raters.The correlation ratio is around 0.58 (the correla-tion ratio between the human raters is 0.67).Also, an online questionnaire was delivered tothose who have tried the system to learn theiropinions on the scores and the feedback they got.The statistics show that most of the studentsgave positive responses.5 ConclusionYanFa has been developed to score Chinesecollege students?
online English-Chinese trans-lation exercises as well as to provide feedbackon their mistakes of understanding the Englishsentences.
Semantic scoring has been exploredon lexical level with such resources as HowNetand Cilin.
While the scoring on sentence levelhas to yield to sentence pattern matching due tothe unsatisfactory performance of Chinese syn-tactic parsers.
Although this pilot research hasachieved its initial purpose, yet it is far fromsatisfactory.
Further efforts should be made inincreasing the scoring accuracy and more de-tailed feedback.ReferencesWaard, J.D.
& Nida, E.A., 1986.
From One Lan-guage to Another.
Thomas Nelson Publishers,Tennessee, U.S.AWang, L. & Chang, B.B., 2009.
Research on theHuman-aided Auto-assessment for TranslationTests in College English.
CAFLEC, No.
128,17-21Wen, Q.F.
et al, Application of Bilingual AlignmentTechnology to Automatic Translation Scoring ofEnglish Test.
CAFLEC, No.
125, 3-8Hutchins,W.
J.
& Somers H. L. ,1992.
An Introduc-tion to Machine Translation, ACADEMICPRESS LIMITED, Printed in Great Britain at theUniversity Press, Cambridge.
110-111D.
Callear, J. Jerrams-Smith, and V. Soh, ?CAA ofShort Non-MCQ Answers?, Fifth Internation-al Computer Assisted Assessment Conference,Loughborough University, 2001.Brown, H.D.1987.
Principles of Language Learningand Teaching [M].
Egnlewood Cliffs, NJ: Pren-tice Hall.28
