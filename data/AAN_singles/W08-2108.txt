CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 57?64Manchester, August 2008Fast Mapping in Word Learning: What Probabilities Tell UsAfra Alishahi and Afsaneh Fazly and Suzanne StevensonDepartment of Computer ScienceUniversity of Toronto{afra,afsaneh,suzanne}@cs.toronto.eduAbstractChildren can determine the meaning of anew word from hearing it used in a familiarcontext?an ability often referred to as fastmapping.
In this paper, we study fast map-ping in the context of a general probabilisticmodel of word learning.
We use our modelto simulate fast mapping experiments on chil-dren, such as referent selection and retention.The word learning model can perform thesetasks through an inductive interpretation ofthe acquired probabilities.
Our results suggestthat fast mapping occurs as a natural conse-quence of learning more words, and providesexplanations for the (occasionally contradic-tory) child experimental data.1 Fast MappingAn average six-year-old child knows over 14, 000words, most of which s/he has learned from hearingother people use them in ambiguous contexts (Carey,1978).
Children are thus assumed to be equipped withpowerful mechanisms for performing such a complextask so efficiently.
One interesting ability children asyoung as two years of age show is that of correctly andimmediately mapping a novel word to a novel objectin the presence of other familiar objects.
The term?fast mapping?
was first used by Carey and Bartlett(1978) to refer to this phenomenon.Carey and Bartlett?s goal was to examine how muchchildren learn about a word when presented in an am-biguous context, as opposed to concentrated teaching.They used an unfamiliar name (chromium) to refer toan unfamiliar color (olive green), and then askeda group of four-year-old children to select an objectfrom among a set, upon hearing a sentence explicitlyc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Somerights reserved.asking for the object of the new color, as in: bringthe chromium tray, not the blue one.
Children weregenerally good at performing this ?referent selection?task.
In a production task performed six weeks later,when children had to use the name of the new color,they showed signs of having learned something aboutthe new color name, but were not successful at pro-ducing it.
On the basis of these findings, Carey andBartlett suggest that fast mapping and word learningare two distinct, yet related, processes.Extending Carey and Bartlett?s work, much re-search has concentrated on providing an explanationfor fast mapping, and on examining its role in wordlearning.
These studies also show that children aregenerally good at referent selection, given a novel tar-get.
However, there is not consistent evidence regard-ing whether children actually learn the novel wordfrom one or a few such exposures (retention).
Forexample, whereas the children in the experiments ofGolinkoff et al (1992) and Halberda (2006) showedsigns of nearly-perfect retention of the fast-mappedwords, those in the studies reported by Horst andSamuelson (2008) did not (all participating childrenwere close in age range).There are also many speculations about the possiblecauses of fast mapping.
Some researchers considerit as a sign of a specialized (innate) mechanism forword learning.
Markman and Wachtel (1988), for ex-ample, argue that children fast map because they ex-pect each object to have only one name (mutual exclu-sivity).
Golinkoff et al (1992) attribute fast mappingto a (hard-coded) bias towards mapping novel namesto nameless object categories.
Some even suggest achange in children?s learning mechanisms, at aroundthe time they start to show evidence of fast mapping(which coincides with a sudden burst in their vocab-ulary), e.g., from associative to referential (Gopnikand Meltzoff, 1987; Reznick and Goldfield, 1992).
Incontrast, others see fast mapping as a phenomenonthat arises from more general processes of learning57and/or communication, which also underlie the im-pressive rate of lexical acquisition in children (e.g.,Clark, 1990; Diesendruck and Markson, 2001; Regier,2005; Horst et al, 2006; Halberda, 2006).In our previous work (Fazly et al, 2008), we pre-sented a word learning model which proposes a prob-abilistic interpretation of cross-situational learning,and bootstraps its own partially-learned knowledge ofthe word meanings to accelerate word learning overtime.
We have shown that the model can learn reason-able word?meaning associations from child-directeddata, and that it accounts for observed learning pat-terns in children, such as vocabulary spurt, withoutrequiring a developmental change in the underlyinglearning mechanism.
Here, we use this computationalmodel to investigate fast mapping and its relation toword learning.
Specifically, we take a close look atthe onset of fast mapping in our model by simulat-ing some of the psychological experiments mentionedabove.
We examine the behaviour of the model in var-ious referent selection and retention tasks, and pro-vide explanations for the (occasionally contradictory)experimental results reported in the literature.
We alsostudy the effect of exposure to more input on the per-formance of the model in fast mapping.Our results suggest that fast mapping can be ex-plained as an induction process over the acquired as-sociations between words and meanings.
Our modellearns these associations in the form of probabilitieswithin a unified framework; however, we argue thatdifferent interpretations of such probabilities may beinvolved in choosing the referent of a familiar as op-posed to a novel target word (as noted by Halberda,2006).
Moreover, the overall behaviour of our modelconfirms that the probabilistic bootstrapping approachto word learning naturally leads to the onset of fastmapping in the course of lexical development, with-out hard-coding any specialized learning mechanisminto the model to account for this phenomenon.2 Overview of the Computational ModelThis section summarizes the model presented in Fa-zly et al (2008).
Our word learning algorithm is anadaptation of the IBM translation model proposed byBrown et al (1993).
However, our model is incre-mental, and does not require a batch process over theentire data.2.1 Utterance and Meaning RepresentationsThe input to our word learning model consists of a setof utterance?scene pairs that link an observed scene(what the child perceives) to the utterance that de-scribes it (what the child hears).
We represent eachutterance as a sequence of words, and the correspond-ing scene as a set of meaning symbols.
To simulatereferential uncertainty (i.e., the case where the childperceives aspects of the scene that are unrelated to theperceived utterance), we include additional symbolsin the representation of the scene, e.g.
:Utterance: Joe rolled the ballScene: {joe, roll, the, ball, mommy, hand, talk}In Section 3.1, we explain how the utterances andthe corresponding semantic symbols are selected, andhow we add referential uncertainty.Given a corpus of such utterance?scene pairs, ourmodel learns the meaning of each word w as a prob-ability distribution, p(.|w), over the semantic sym-bols appearing in the corpus.
In this representation,p(m|w) is the probability of a symbol m being themeaning of a word w. In the absence of any priorknowledge, all symbols are equally likely to be themeaning of a word.
Hence, prior to receiving any us-ages of a given word, the model assumes a uniformdistribution over semantic symbols as its meaning.2.2 Meaning ProbabilitiesOur model combines probabilistic interpretations ofcross-situational learning (Quine, 1960) and of avariation of the principle of contrast (Clark, 1990),through an interaction between two types of prob-abilistic knowledge acquired and refined over time.Given an utterance?scene pair received at time t, i.e.,(U(t), S(t)), the model first calculates an alignmentprobability a for each w ?
U(t) and each m ?
S(t),using the meaning probabilities p(.|w) of all thewords in the utterance prior to this time.
The modelthen revises the meaning of the words in U(t) by in-corporating the alignment probabilities for the currentinput pair.
This process is repeated for all the inputpairs, one at a time.Step 1: Calculating the alignment probabilities.We estimate the alignment probabilities of wordsand meaning symbols based on a localized versionof the principle of contrast: that a meaning sym-bol in a scene is likely to be highly associated withonly one of the words in the corresponding utter-ance.1 For a symbol m ?
S(t) and a word w ?
U(t),the higher the probability of m being the meaningof w (according to p(m|w)), the more likely it isthat m is aligned with w in the current input.
Inother words, a(w |m, U(t), S(t)) is proportional top(t?1)(m|w).
In addition, if there is strong evidencethat m is the meaning of another word in U(t)?i.e., if p(t?1)(m|w?)
is high for some w?
?
U(t) other1Note that this differs from what is widely known as the prin-ciple of contrast (Clark, 1990), in that the latter assumes contrastacross the entire vocabulary rather than within an utterance.58than w?the likelihood of aligning m to w should de-crease.
Combining these two requirements:a(w |m, U(t), S(t)) =p(t?1)(m|w)?w??U(t)p(t?1)(m|w?
)(1)Due to referential uncertainty, some of the meaningsymbols in the scene might not have a counterpartin the utterance.
To accommodate for such cases, adummy word is added to each utterance before thealignment probabilities are calculated, in order to leta meaning symbol not be (strongly) aligned with anyof the words in the current utterance.Step 2: Updating the word meanings.
We need toupdate the probabilities p(.|w) for all words w ?
U(t),based on the evidence from the current input pair re-flected in the alignment probabilities.
We thus addthe current alignment probabilities for w and the sym-bols m ?
S(t) to the accumulated evidence from priorco-occurrences of w and m. We summarize thiscross-situational evidence in the form of an associa-tion score, which is updated incrementally:assoc(t)(w, m) = assoc(t?1)(w, m) +a(w|m, U(t), S(t)) (2)where assoc(t?1)(w, m) is zero if w and m have notco-occurred before.
The association score of a wordand a symbol is basically a weighted sum of their co-occurrence counts.The model then uses these association scores to up-date the meaning of the words in the current input:p(t)(m|w) =assoc(t)(m, w) + ?
?mj?Massoc(t)(mj, w) + ?
?
?
(3)where M is the set of all symbols encountered prior toor at time t, ?
is the expected number of symbol types,and ?
is a small smoothing factor.
The denominator isa normalization factor to get valid probabilities.
Thisformulation results in a uniform probability of 1/?over all m ?
M for a novel word w, and a probabilitysmaller than ?
for a meaning symbol m that has notbeen previously seen with a familiar word w.Our model updates the meaning of a word ev-ery time it is heard in an utterance.
The strengthof learning of a word at time t is reflected inp(t)(m = mw|w), where mwis the ?correct?
mean-ing of w: for a learned word w, the probability dis-tribution p(.|w) is highly skewed towards the correctmeaning mw, and therefore hearing w will trigger theretrieval of the meaning mw.22An input-generation lexicon contains the correct meaning foreach word, as described in Section 3.1.
Note that the model doesnot have access to this lexicon for learning; it is used only forinput generation and evaluation.From this point on, we simply use p(m|w) (omit-ting the superscript (t)) to refer to the meaning prob-ability of m for w at the present time of learning.2.3 Referent ProbabilitiesThe meaning probability p(m|w) is used to retrievethe most probable meaning for w among all the possi-ble meaning symbols m. However, in the referent se-lection tasks performed by children, the subject is of-ten forced to select the referent of a target word fromamong a limited set of objects, even when the mean-ing of the target word has not been accurately learnedyet.
For our model to perform such tasks, it has to de-cide how likely it is for a target word w to refer to aparticular object m, based on its previous knowledgeabout the mapping between m and w (i.e., p(m|w)),as well as the mapping between m and other words inthe lexicon.3The likelihood of using a particular name w to referto a given object m is calculated as:rf (w|m) = p(w|m)=p(m|w) ?
p(w)p(m)=p(m|w) ?
p(w)?w??Vp(m|w?)
?
p(w?
)(4)where V is the set of all words that the model has seenso far, and p(w) is the relative frequency of w:p(w) =freq(w)?w??Vfreq(w?
)(5)The referent of a target word w among the present ob-jects, therefore, will be the object m with the highestreferent probability rf (w|m).3 Experimental Setup3.1 The Input CorporaWe extract utterances from the Manchester corpus(Theakston et al, 2001) in the CHILDES database(MacWhinney, 2000).
This corpus contains tran-scripts of conversations with children between theages of 1; 8 and 3; 0 (years;months).
We use themother?s speech from transcripts of 6 children, re-move punctuation and lemmatize the words, and con-catenate the corresponding sessions as input data.There is no semantic representation of the corre-sponding scenes available from CHILDES.
There-fore, we automatically construct a scene representa-tion for each utterance, as a set containing the seman-tic referents of the words in that utterance.
We getthese from an input-generation lexicon that containsa symbol associated with each word as its semantic3All through the paper, we use m as both the meaning and thereferent of a word w.59referent.
We use every other sentence from the orig-inal corpus, preserving their chronological order.
Tosimulate referential uncertainty in the input, we thenpair each sentence with its own scene representationas well as that of the following sentence in the origi-nal corpus.
(Note that the latter sentence is not usedas an utterance in our input.)
The extra semantic sym-bols that are added to each utterance thus correspondto meaningful semantic representations, as opposedto randomly selected symbols.
In the resulting corpusof 92, 239 input pairs, each utterance is, on average,paired with 78% extra meaning symbols, reflecting ahigh degree of referential uncertianty.3.2 The Model ParametersWe set the parameters of our learning algorithm usinga development data set which is similar to our trainingand test data, but is selected from a non-overlappingportion of the Manchester corpus.
The expected num-ber of symbols, ?
in Eq.
(3), is set to 8500 based onthe total number of distinct symbols extracted for thedevelopment data.
Therefore, the default probabilityof a symbol for a novel word will be 1/8500.
A famil-iar word, on the other hand, has been seen with somesymbols before.
Therefore, the probability of a previ-ously unseen symbol for it (which, based on Eq.
(3),has an upper bound of ?)
must be less than the defaultprobability mentioned above.
Accordingly, we set ?to 10?5.3.3 The Training ProcedureIn the next section, we report results from the com-putational simulation of our model for a number ofexperiments.
All of the simulations use the same pa-rameter settings (as described in the previous section),but different input: in each simulation, a random por-tion of 1000 utterance?scene pairs is selected fromthe input corpus, and incrementally processed by themodel.
The size of the training corpus is chosen arbi-trarily to reflect a sample point in learning, and furtherexperiments have shown that increasing this numberdoes not change the pattern observed in the results.
Inorder to avoid behaviour that is specific to a particu-lar sequence of input items, the reported results in thenext section are averaged over 10 simulations.4 Experimental Results and Analysis4.1 Referent SelectionIn a typical word learning scenario, the child facesa scene where a number of familiar and unfamiliarobjects are present.
The child then hears a sentence,which describes (some part of) the scene, and is com-posed of familiar and novel words (e.g., hearing Joe iseating a cheem, where cheem is a previously unseenfruit).
In such a setting, our model aligns the objectsin the scene with the words in the utterance based onits acquired knowledge of word meanings, and thenupdates the meanings of the words accordingly.
Themodel can align a familiar word with its referent withhigh confidence, since the previously learned mean-ing probability of the familiar object given the famil-iar word, or p(m|w), is much higher than the meaningprobability of the same object given any other word inthe sentence.
In a similar fashion, the model can eas-ily align a novel word in the sentence with a novelobject in the scene, because the meaning probabilityof the novel object given the novel word (1/?, ac-cording to Eq.
(3)) is higher than the meaning proba-bility of that object for any previously heard word inthe sentence (the latter probability is smaller than ?
inEq.
(3), as explained in Section 3.2).Earlier fast mapping experiments on children as-sumed that it is such a contrast between the familiarand novel words in the same sentence that helps chil-dren select the correct target object in a referent selec-tion task.
For example, in Carey and Bartlett?s (1978)experiment, to introduce a novel word?meaning as-sociation (e.g., chromium?olive), the authors useboth the familiar and the novel words in one sentence(bring me the chromium tray, not the blue one.).
How-ever, further experiments show that children can suc-cessfully select the correct referent even if such a con-trast is not present in the sentence.
Many researchershave performed experiments where young subjectsare forced to choose between a novel and a familiarobject upon hearing a request, such as give me theball (familiar target), or give me the dax (novel tar-get).
In all of the reported experimental results, chil-dren can readily pick the correct referent for a famil-iar or a novel target word in such a setting (Golinkoffet al, 1992; Halberda and Goldman, 2008; Halberda,2006; Horst and Samuelson, 2008).However, Halberda?s eye-tracking experiments onboth adults and pre-schoolers suggest that the pro-cesses involved for referent selection in the familiartarget situation may be different from those in thenovel target situation.
In the latter situation, subjectsappear to systematically reject the familiar object asthe referent of the novel name before mapping thenovel object to the novel name.
In the familiar targetsituation, however, there is no need to reject the noveldistractor object, because the subject already knowsthe referent of the target.The difference between these two conditions can beexplained in terms of the meaning and referent proba-bilities of our model explained in Section 2.
In a typi-cal referent selection experiment, the child is asked to60?get the ball?
while facing a ball and a novel object(dax).
We assume that the child knows the meaningof verbs and determiners such as get and the, thereforewe simplify the familiar target condition in the formof the following input item:ball (FAMILIAR TARGET){ball, dax}A familiar word such as ball has a meaning prob-ability highly skewed towards its correct meaning.That is, upon hearing ball, the model can confidentlyretrieve its meaning ball, which is the one withthe highest probability p(m|ball) among all possiblemeanings m. In such a case, if ball is present in thescene, the model can easily pick it as the referent ofthe familiar target name, without processing the otherobjects in the scene.Now consider the condition where a novel targetname is used in the presence of a familiar and a pre-viously unseen object:dax (NOVEL TARGET){ball, dax}Since this is the first time the model has heard theword dax, both meanings ball and dax are equallylikely because p(.|dax ) is uniform.
Thus the mean-ing probabilities cannot be solely used for selectingthe referent of dax, and the model has to performsome kind of induction on the potential referents inthe scene based on what it has learned about eachof them.
The model can infer the referent of daxby comparing the referent probabilities rf (dax |ball)and rf (dax |dax) from Eq.
(4) after processing the in-put item.
Since ball has strong associations with an-other word ball, its referent probability for the novelname dax is much lower than the referent probabilityof dax, which does not have strong associations withany of the words in the learned lexicon.We simulate the process of referent selection in ourmodel as follows.
We train the model as describedin Section 3.3.
We then present the model with onemore input item, which represents either the FAMIL-IAR TARGET or the NOVEL TARGET condition.
Foreach condition, we compare the meaning probabilityp(object|target) for both familiar and novel objectsin the scene (see Table 1, top panel).
In the FA-MILIAR TARGET condition, the model demonstratesa strong preference towards choosing the familiar ob-ject as the referent, whereas in the NOVEL TARGETcondition, the model shows no preference towards anyof the objects based on the meaning probabilities ofthe target word.
Therefore, for the NOVEL TARGETcondition, we also compare the referent probabilitiesrf (target |object) for both objects after processingTable 1: Referent selection in FAMILIAR and NOVELTARGET conditions.UPON HEARING THE TARGET WORDCondition p(ball|target ) p(dax|target )FAMILIAR TARGET 0.843 ?0.056 ?
0.0001NOVEL TARGET 0.0001 ?0.00 0.0001 ?0.00AFTER PERFORMING INDUCTIONCondition rf (target |ball) rf (target |dax)NOVEL TARGET 0.127 ?0.127 0.993 ?0.002the input item as a training pair, simulating the in-duction process that humans go through to select thereferent in such cases.
This time, the model shows astrong preference towards the novel object as the ref-erent of the target word (see Table 1, bottom panel).Our results confirm that in both conditions, the modelconsistently selects the correct referent for the targetword across all the simulations.4.2 RetentionAs discussed in the previous section, results fromthe human experiments as well as our computationalsimulations show that the referent of a novel targetword can be selected based on the previous knowl-edge about the present objects and their names.
How-ever, the success of a subject in a referent selectiontask does not necessarily mean that the child/modelhas learned the meaning of the novel word based onthat one trial.
In order to better understand what andhow much children learn about a novel word from asingle ambiguous exposure, some studies have per-formed retention trials after the referent selection ex-periments.
Often, various referent selection trials areperformed in one session, where in each trial a novelobject?name pair is introduced among familiar ob-jects.
Some of the recently introduced objects arethen put together in one last trial, and the subjectsare asked to choose the correct referent for one of the(recently heard) novel target words.
The majority ofthe reported experiments show that children can suc-cessfully perform the retention task (Golinkoff et al,1992; Halberda and Goldman, 2008; Halberda, 2006).We simulate a similar retention experiment bytraining the model as usual.
We further present themodel with two experimental training items similar tothe one used in the NOVEL TARGET condition in theprevious section, with different familiar and novel ob-jects and words in each input:dax (REFERENT SELECTION TRIAL 1){ball, dax}cheem (REFERENT SELECTION TRIAL 2){pen, cheem}61Table 2: Retention of a novel target word from a setof novel objects.2-OBJECT RETENTION TRIALrf (dax |dax) rf (dax |cheem)0.996 ?0.001 0.501 ?0.0683-OBJECT RETENTION TRIALrf (dax |dax) rf (dax |cheem) rf (dax |lukk)0.995 ?0.001 0.407 ?0.062 0.990 ?0.001The training session is followed by a retention trial,where the two novel objects used in the previous ex-perimental inputs are paired with one of the novel tar-get words:dax (2-OBJECT RETENTION TRIAL){cheem, dax}After processing the retention input, we com-pare the referent probabilities rf (dax |cheem) andrf (dax |dax) to see if the model can choose the cor-rect novel object in response to the target word dax.The top panel in Table 2 summarizes the results of thisexperiment.
The model consistently shows a strongpreference towards the correct novel object as the ref-erent of the novel target word across all simulations.Unlike studies on referent selection, experimentalresults for retention have not been consistent acrossvarious studies.
Horst and Samuelson (2008) per-form experiments with two-year-old children involv-ing both referent selection and retention, and reportthat their subjects perform very poorly at the retentiontask.
One factor that discriminates the experimentalsetup of Horst and Samuelson from others (e.g., Hal-berda, 2006) is that, in their retention trials, they puttogether two recently observed novel objects with athird novel object that has not been seen in any of theexperimental sessions before.
The authors do not at-tribute their contradictory results to the presence ofthis third object, but this factor can in fact affect theperformance considerably.
We simulate this conditionby using the same input items for referent selectiontrials as in the previous simulation, but we replace theretention trial with the following:dax (3-OBJECT RETENTION TRIAL){cheem, dax, lukk}The third object, lukk, has not been seen by themodel before.
Results under the new condition are re-ported in the bottom panel of Table 2.
As can be seen,the model shows a strong tendency towards the cor-rect novel referent dax for the novel target dax, com-pared to the other recently seen novel object cheem.However, the probability of the unseen object lukkis also very high for the target word dax.
That is be-cause the model cannot use any previously acquired0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2x 10405101520253035time of first exposurenumber of usages neededtolearnFigure 1: Number of usages needed to learn a word,as a function of the word?s age of exposure.knowledge about lukk (i.e., associating it with an-other word) to rule it out as a referent for dax.
Theseresults show that introducing a new object for the firsttime in a retention trial considerably increases the dif-ficulty of the task.
This can explain the contradictoryresults reported in the literature: when the referentprobabilities are not informative, other factors mayinfluence the outcome of the experiment, such as theamount of training received for a novel word?object,or a possible delay between training and test sessions.4.3 The Effect of Exposure to More InputThe fast mapping ability observed in children impliesthat once children have learned a repository of words,they can easily link novel words to novel objects in afamiliar context based only on a few exposures.
Weexamine this effect in our model: we train the modelon 20, 000 input pairs, looking at the relation betweenthe time of first exposure to a word, and the numberof usages that the model needs for learning that word.Figure 1 plots this for words that have been learned atsome point during the training.4 We can see that themodel shows clear fast mapping behaviour?that is,words received later in time, on average, require fewerusages to be learned.
These results show that ourmodel exhibits fast mapping patterns once it has beenexposed to enough word usages, and that no changein the underlying learning mechanism is needed.5The effect of exposure to more input on fast map-ping can be described in terms of context familiarity:the more input the model has processed so far, themore likely it is that the context of the usage of a novelword (the other words in the sentence and the objectsin the scene) is familiar to the model.
This patternhas been studied through a number of experiments on4We consider a word w as learned if the meaning probabilityp(mw|w) is higher than a certain threshold ?.
For this experi-ment, we set ?
= 0.70.5In Fazly et al (2008), we reported a variation of this exper-iment, where we used a smaller training set, and also a differentsemantic representation for word meanings.62children.
For example, Gershkoff-Stowe and Hahn(2007) taught 16- to 18-month-olds the names of 24unfamiliar objects over 12 training sessions, whereunfamiliar objects were presented with varying fre-quency.
Data were compared to a control group ofchildren who were exposed to the same experimen-tal words at the first and last sessions only.
Their re-sults show that for children in the experimental group,extended practice with a novel set of words led tothe rapid acquisition of a second set of low-practicewords.
Children in the control group did not show thesame lexical advantage.Inspired by Gershkoff-Stowe and Hahn (2007), weperform an experiment to study the effect of con-text familiarity on fast mapping in our model.
Wechoose two sets of words, CONTEXT (containing 20words) and TARGET (containing 10 words), to con-duct a referent selection task as follows.
First, wetrain our model on a sequence of utterance?scenepairs constructed from the set CONTEXT ?
TARGET,as follows: the unified set is randomly shuffled anddivided into two subsets, words in each subset areput together to form an utterance, and the meaningsof the words in that utterance are put together toform the corresponding scene.
We repeat this processtwice, so that each word appears in exactly two inputpairs.
We train our model on the constructed pairs.6Next, we perform a referent selection task on eachword in the TARGET set: we pair each target wordw with the meaning of 10 randomly selected wordsfrom CONTEXT ?
TARGET, including the meaning ofthe target word itself (mw), and have the model pro-cess this test pair.
We compare the referent probabil-ity of w and each m ?
CONTEXT ?
TARGET to seewhether the model can correctly map the target wordto its referent.
We call this setting the LOW TRAIN-ING condition.In the above setting, the context words in the ref-erent selection trials are as new to the model as thetarget words.
We thus repeat this experiment witha familiar context: we first train the model over in-put pairs that are randomly constructed from wordsin CONTEXT only, using the same training proce-dure as described above.
This context-familiarizationprocess is followed by a similar training session onCONTEXT ?
TARGET, and a test session on targetwords, similar to the previous condition.
Again, wecount the number of correct mappings between a tar-get word and its referent based on the referent proba-bilities.
We call this setting the HIGH TRAINING con-dition.
Table 3 shows the results for both conditions.It can be seen that the accuracy of finding the referent6Unlike in previous experiments, here we do not use child-directed data as we want to control the familiarity of the context.Table 3: Average number of correct mappings and thereferent probabilities of target words for two condi-tions, LOW and HIGH TRAINING.Condition Correct mappings P (target |mtarget)LOW TRAINING %54 0.216?0.04HIGH TRAINING %90 0.494?0.79for a target word, as well as the referent probability ofa target word for its correct meaning, increase as a re-sult of more training on the context.
In other words, amore familiar context helps the model perform betterin a fast mapping task.5 Related Computational ModelsThe rule-based model of Siskind (1996), and the con-nectionist model proposed by Regier (2005), bothshow that learning gets easier as the model is exposedto more input?that is, words heard later are learnedfaster.
These findings confirm that fast mapping maysimply be a result of learning more words, and thatno explicit change in the underlying learning mech-anism is needed.
However, these studies do not ex-amine various aspects of fast mapping, such as ref-erent selection and retention.
Horst et al (2006) ex-plicitly test fast mapping in their connectionist modelof word learning by performing referent selection andretention tasks.
The behaviour of their model matchesthe child experimental data reported in a study by thesame authors (Horst and Samuelson, 2008), but notthat of the contradictory findings of other similar ex-periments.
Moreover, the model?s learning capacityis limited, and the fast mapping experiments are per-formed on a very small vocabulary.
Frank et al (2007)examine fast mapping in their Bayesian model by test-ing its performance in a novel target referent selectiontask.
However, the experiment is performed on an ar-tifical corpus.
Moreover, since the learning algorithmis non-incremental, the success of the model in refer-ent selection is determined implicitly: each possibleword?meaning mapping from the test input is addedto the current lexicon, and the consistency of the newlexicon is checked against the training corpus.6 Discussion and Concluding RemarksWe have used a general computational model of wordlearning (first introduced in Fazly et al, 2008) to studyfast mapping.
Our model learns a probabilistic asso-ciation between a word and its meaning, from expo-sure to word usages in naturalistic contexts.
We haveshown that these probabilities can be used to simu-late various fast mapping experiments performed onchildren, such as referent selection and retention.
Our63experimental results suggest that fast mapping can beexplained as an induction process over the acquiredassociations between words and objects.
In that sense,fast mapping is a general cognitive ability, and nota hard-coded, specialized mechanism of word learn-ing.7 In addition, our results confirm that the onsetof fast mapping is a natural consequence of learningmore words, which in turn accelerates the learning ofnew words.
This bootstrapping approach results in arapid pace of vocabulary acquisition in children, with-out requiring a developmental change in the underly-ing learning mechanism.Results of the referent selection experiments showthat our model can successfully find the referent ofa novel target word in a familiar context.
Moreover,our retention experiments show that the model canmap a recently heard novel word to its recently seennovel referent (among other novel objects) after onlyone exposure.
However, the strength of the associa-tion of a novel pair after one exposure shows a no-table difference compared to the association betweena ?typical?
familiar word and its meaning.8 This isconsistent with what is commonly assumed in the lit-erature: even though children learn something abouta word from only one exposure, they often need moreexposure to reliably learn its meaning (Carey, 1978).Various kinds of experiments have been performed toexamine how strongly children learn novel words in-troduced to them in experimental settings.
For exam-ple, children are persuaded to produce a fast-mappedword, or to use the novel word to refer to objectsthat are from the same category as its original refer-ent (e.g., Golinkoff et al, 1992; Horst and Samuelson,2008).
We intend to look at these new tasks in our fu-ture research.ReferencesBehrend, Douglas A., Jason Scofield, and Erica E.Kleinknecht 2001.
Beyond fast mapping: Young chil-dren?s extensions of novel words and novel facts.
De-velopmental Psychology, 37(5):698?705.Brown, Peter F., Stephen A. Della Pietra, Vincent J. DellaPietra, and Robert L. Mercer 1993.
The mathematicsof statistical machine translation: Parameter estimation.Computational Linguistics, 19(2):263?311.Carey, Susan 1978.
The child as word learner.
In Halle, M.,J.
Bresnan, and G. A. Miller, editors, Linguistic Theoryand Psychological Reality.
The MIT Press.Carey, Susan and Elsa Bartlett 1978.
Acquiring a singlenew word.
Papers and reports on Child Language De-velopment, 15:17?29.7In fact, similar fast mapping effects have been studied in con-texts other than language.
For example, Behrend et al (2001) re-port on children?s fast mapping of novel facts about novel objects.8After processing 1000 input pairs, the average meaning prob-ability of familiar words (those with frequency higher than 10) is0.77, whereas that of the novel word after one exposure is 0.64.Clark, Eve 1990.
On the pragmatics of contrast.
Journalof Child Language, 17:417?431.Diesendruck, Gil and Lori Markson 2001.
Children?savoidance of lexical overlap: A pragmatic account.
De-velopmental Psychology, 37(5):630?641.Fazly, Afsaneh, Afra Alishahi, and Suzanne Steven-son 2008.
A probabilistic incremental model of wordlearning in the presence of referential uncertainty.
InProceedings of the 30th Annual Conference of the Cog-nitive Science Society.Frank, Michael C., Noah D. Goodman, and Joshua B.Tenenbaum 2007.
A bayesian framework for cross-situational word-learning.
In Advances in Neural Infor-mation Processing Systems, volume 20.Gershkoff-Stowe, Lisa and Erin R. Hahn 2007.
Fast map-ping skills in the developing lexicon.
Journal of Speech,Language, and Hearing Research, 50:682?697.Golinkoff, Roberta Michnick, Kathy Hirsh-Pasek,Leslie M. Bailey, and Neil R. Wegner 1992.
Youngchildren and adults use lexical principles to learn newnouns.
Developmental Psychology, 28(1):99?108.Gopnik, Alison and Andrew Meltzoff 1987.
The develop-ment of categorization in the second year and its relationto other cognitive and linguistic developments.
ChildDevelopment, 58(6):1523?1531.Halberda, Justin 2006.
Is this a dax which I see beforeme?
use of the logical argument disjunctive syllogismsupports word-learning in children and adults.
CognitivePsychology, 53:310?344.Halberda, Justin and Julie Goldman 2008.
One-trial learn-ing in 2-year-olds: Children learn new nouns in 3 sec-onds flat.
(in submission).Horst, Jessica S., Bob McMurray, and Larissa K. Samuel-son 2006.
Online processing is essential for learning:Understanding fast mapping and word learning in a dy-namic connectionist architecture.
In Proc.
of CogSci?06.Horst, Jessica S. and Larissa K. Samuelson 2008.
Fastmapping but poor retention by 24-month-old infants.
In-fancy, 13(2):128?157.MacWhinney, B.
2000.
The CHILDES Project: Tools forAnalyzing Talk, volume 2: The Database.
MahWah, NJ:Lawrence Erlbaum Associates, third edition.Markman, Ellen M. and Gwyn F. Wachtel 1988.
Children?suse of mutual exclusivity to constrain the meanings ofwords.
Cognitive Psychology, 20:121?157.Quine, W.V.O.
1960.
Word and Object.
Cambridge, MA:MIT Press.Regier, Terry 2005.
The emergence of words: Atten-tional learning in form and meaning.
Cognitive Science,29:819?865.Reznick, J. Steven and Beverly A. Goldfield 1992.
Rapidchange in lexical development in comprehension andproduction.
Developmental Psychology, 28(3):406?413.Siskind, Jeffery Mark 1996.
A computational studyof cross-situational techniques for learning word-to-meaning mappings.
Cognition, 61:39?91.Theakston, A. L., E. V. Lieven, J. M. Pine, and C. F. Row-land 2001.
The role of performance limitations in theacquisition of verb-argument structure: An alternativeaccount.
Journal of Child Language, 28:127?152.64
