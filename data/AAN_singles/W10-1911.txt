Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 83?90,Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational LinguisticsDisease Mention Recognition with Specific FeaturesMd.
Faisal Mahbub Chowdhury ?
?
and Alberto Lavelli ?
?Human Language Technology Research Unit, Fondazione Bruno Kessler, Trento, Italy?
ICT Doctoral School, University of Trento, Italy{chowdhury,lavelli}@fbk.euAbstractDespite an increasing amount of researchon biomedical named entity recognition,there has been not enough work done ondisease mention recognition.
Difficulty ofobtaining adequate corpora is one of thekey reasons which hindered this particu-lar research.
Previous studies argue thatcorrect identification of disease mentionsis the key issue for further improvementof the disease-centric knowledge extrac-tion tasks.
In this paper, we present a ma-chine learning based approach that usesa feature set tailored for disease mentionrecognition and outperforms the state-of-the-art results.
The paper also discusseswhy a feature set for the well studiedgene/protein mention recognition task isnot necessarily equally effective for otherbiomedical semantic types such as dis-eases.1 IntroductionThe massive growth of biomedical literature vol-ume has made the development of biomedical textmining solutions indispensable.
One of the essen-tial requirements for a text mining application isthe ability to identify relevant entities, i.e.
namedentity recognition.
Previous work on biomedi-cal named entity recognition (BNER) has beenmostly focused on gene/protein mention recogni-tion.
Machine learning (ML) based approachesfor gene/protein mention recognition have alreadyachieved a sufficient level of maturity (Torii etal., 2009).
However, the lack of availability ofadequately annotated corpora has hindered theprogress of BNER research for other semantictypes such as diseases (Jimeno et al, 2008; Lea-man et al, 2009).Correct identification of diseases is crucial forvarious disease-centric knowledge extraction tasks(e.g.
drug discovery (Agarwal and Searls, 2008)).Previous studies argue that the most promisingcandidate for the improvement of disease relatedrelation extraction (e.g.
disease-gene) is the cor-rect identification of concept mentions includingdiseases (Bundschus et al, 2008).In this paper, we present a BNER system whichuses a feature set specifically tailored for diseasemention recognition.
The system1 outperformsother approaches evaluated on the Arizona Dis-ease Corpus (AZDC) (more details in Section 5.1).One of the key differences between our approachand previous approaches is that we put more em-phasis on the contextual features.
We exploit syn-tactic dependency relations as well.
Apart fromthe experimental results, we also discuss why thechoice of effective features for recognition of dis-ease mentions is different from that for the wellstudied gene/protein mentions.The remaining of the paper is organized as fol-lows.
Section 2 presents a brief description of pre-vious work on BNER for disease mention recog-nition.
Then, Section 3 describes our system andSection 4 the feature set of the system.
After that,Section 5 explains the experimental data, resultsand analyses.
Section 6 describes the differencesfor the choice of feature set between diseases andgenes/proteins.
Finally, Section 7 concludes thepaper with an outline of our future research.2 Related WorkNamed entity recognition (NER) is the task of lo-cating boundaries of the entity mentions in a textand tagging them with their corresponding seman-tic types (e.g.
person, location, gene and so on).Although several disease annotated corpora havebeen released in the last few years, they have beenannotated primarily to serve the purpose of re-lation extraction and, for different reasons, they1The source code of our system is available for downloadat http://hlt.fbk.eu/people/chowdhury/research83are not suitable for the development of ML baseddisease mention recognition systems (Leaman etal., 2009).
For example, the BioText (Rosarioand Hearst, 2004) corpus has no specific anno-tation guideline and contains several inconsisten-cies, while PennBioIE (Kulick et al, 2004) is veryspecific to a particular sub-domain of diseases.Among other disease annotated corpora, EBI dis-ease corpus (Jimeno et al, 2008) is not annotatedwith disease mention boundaries which makes itunsuitable for BNER evaluation for diseases.
Re-cently, an annotated corpus, named as ArizonaDisease Corpus (AZDC) (Leaman et al, 2009),has been released which has adequate and suitableannotation of disease mentions following specificannotation guidelines.There has been some work on identifying dis-eases in clinical texts, especially in the contextof CMC Medical NLP Challenge2 and i2b2 Chal-lenge3.
However, as noted by Meystre et al(2008), there are a number of reasons that makeclinical texts different from texts of biomedicalliterature, e.g.
composition of short, telegraphicphrases, use of implicit templates and pseudo-tables and so on.
Hence, the strategies adoptedfor NER on clinical texts are not the same as theones practiced for NER on biomedical literature.As mentioned before, most of the work todate on BNER is focused on gene/protein men-tion recognition.
State-of-the-art BNER systemsare based on ML techniques such as conditionalrandom fields (CRFs), support vector machines(SVMs) etc (Dai et al, 2009).
These systems useeither gene/protein specific features (e.g.
Greekalphabet matching) or post-processing rules (e.g.extension of the identified mention boundaries tothe left when a single letter with a hyphen precedesthem (Torii et al, 2009)) which might not be aseffective for other semantic type identification asthey are for genes/proteins.
There is a substantialagreement in the feature set that these systems use(most of which are actually various orthographicaland morphological features).Bundschus et al (2008) have used a CRFbased approach that uses typical features forgene/protein mention recognition (i.e.
no featuretailoring for disease recognition) for disease, geneand treatement recognition.
The work has beenevaluated on two corpora which have been anno-2http://www.computationalmedicine.org/challenge/index.php3https://www.i2b2.org/NLP/Relations/Main.phptated with those entities that participate in disease-gene and disease-treatment relations.
The reportedresults show F-measure for recognition of all theentities that participate in the relations and donot indicate which F-measure has been achievedspecifically for disease recognition.
Hence, the re-ported results are not applicable for comparison.To the best of our knowledge, the only sys-tematic experimental results reported for diseasemention recognition in biomedical literature usingML based approaches are published by Leamanand Gonzalez (2008) and Leaman et al (2009).4They have used a CRF based BNER system namedBANNER which basically uses a set of ortho-graphic, morphological and shallow syntactic fea-tures (Leaman and Gonzalez, 2008).
The systemachieves an F-score of 86.43 on the BioCreativeII GM corpus5 which is one of the best results forgene mention recognition task on that corpus.BANNER achieves an F-score of 54.84 for dis-ease mention recognition on the BioText corpus(Leaman and Gonzalez, 2008).
However, as saidabove, the BioText corpus contains annotation in-consistencies6.
So, the corpus is not ideal for com-paring system performances.
The AZDC corpusis much more suitable as it is annotated specifi-cally for benchmarking of disease mention recog-nition systems.
An improved version of BAN-NER achieves an F-score of 77.9 on AZDC cor-pus, which is the state of the art on ML based dis-ease mention recognition in biomedical literature(Leaman et al, 2009).3 Description of Our SystemThere are basically three stages in our approach ?pre-processing, feature extraction and model train-ing, and post-processing.3.1 Pre-processingAt first, the system uses GeniaTagger7 to tokenizetexts and provide PoS tagging.
After that, it cor-rects some common inconsistencies introduced byGeniaTagger inside the tokenized data (e.g.
Ge-niaTagger replaces double inverted commas with4However, there are some work on disease recognition inbiomedical literature using other techniques such as morpho-syntactic heuristic based approach (e.g.
MetaMap (Aronson,2001)), dictionary look-up method and statistical approach(Ne?ve?ol et al, 2009; Jimeno et al, 2008; Leaman et al,2009).5As mentioned in http://banner.sourceforge.net/6http://biotext.berkeley.edu/data/dis treat data.html7http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/tagger/84two single inverted commas).
These PoS taggedtokized data are parsed using Stanford parser8.The dependency relations provided as output bythe parser are used later as features.
The tokensare further processed using the following general-ization and normalization steps:?
each number (both integer and real) inside atoken is replaced with ?9??
each token is further tokenized if it containseither punctuation characters or both digitsand alphabetic characters?
all letters are changed to lower case?
all Greek letters (e.g.
alpha) are replaced withG and Roman numbers (e.g.
iv) with R?
each token is normalized using SPECIALISTlexicon tool9 to avoid spelling variations3.2 Feature extraction and model trainingThe features used by our system can be catego-rized into the following groups:?
general linguistic features (Table 1)?
orthographic features (Table 2)?
contextual features (Table 3)?
syntactic dependency features (Table 4)?
dictionary lookup features (see Section 4)During dictionary lookup feature extraction, weignored punctuation characters while matchingdictionary entries inside sentences.
If a sequenceof tokens in a sentence matches an entry in the dic-tionary, the leftmost token of that sequence is la-beled with B-DB and the remaining tokens of thesequence are labeled with I-DB.
The label B-DBindicates the beginning of a dictionary match.
If atoken belongs to several dictionary matches, thenall the other dictionary matches except the longestone are discarded.The syntactic dependency features are extractedfrom the output of the parser while the general lin-guistic features are extracted directly from the pre-processed tokens.
To collect the orthographic fea-tures, the original tokens inside the correspondingsentences are considered.
The contextual features8http://nlp.stanford.edu/software/lex-parser.shtml9http://lexsrv3.nlm.nih.gov/SPECIALIST/index.htmlare derived using other extracted features and theoriginal tokens.Tokens are labeled with the corresponding dis-ease annotations according to the IOB2 format.Our system uses Mallet (McCallum, 2002) to traina first-order CRF model.
CRF is a state-of-the-art ML technique applied to a variety of textprocessing tasks including named entity recogni-tion (Klinger and Tomanek, 2007) and has beensuccessfully used by many other BNER systems(Smith et al, 2008).3.3 Post-processingOnce the disease mentions are identified usingthe learned model, the following post-processingtechniques are applied to reduce the number ofwrong identifications:?
Bracket mismatch correction: If there is amismatch of brackets in the identified men-tion, then the immediate following (or pre-ceding) character of the corresponding men-tion is checked and included inside the men-tion if that character is the missing bracket.Otherwise, all the characters from the indexwhere the mismatched bracket exists insidethe identified mention are discarded from thecorresponding mention.?
One sense per discourse: If any instance ofa character sequence is identified as a diseasemention, then all the other instances of thatcharacter sequence inside the same sentenceare also annotated as disease mentions.?
Short/long form annotation: Using the algo-rithm of Schwartz and Hearst (2003), ?longform (short form)?
instances are detected in-side sentences.
If the short form is annotatedas disease mention, then the long form is alsoannotated and vice versa.?
Ungrammatical conjunction structure cor-rection: If an annotated mention containscomma (,) but there is no ?and?
in the fol-lowing character sequence (from the charac-ter index of that comma) of that mention, thenthe annotation is splitted into two parts (at theindex of the comma).
Annotation of the origi-nal mention is removed and the splitted partsare annotated as two separate disease men-tions.85?
Short and long form separation: If both shortand long forms are annotated in the samemention, then the original mention is dis-carded and the corresponding short and longforms are annotated separately.4 Features for Disease RecognitionThere are compelling reasons to believe that vari-ous issues regarding the well studied gene/proteinmention recognition would not apply to the othersemantic types.
For example, Jimeno et al (2008)argue that the use of disease terms in biomedicalliterature is well standardized, which is quite op-posite for the gene terms (Smith et al, 2008).After a thorough study and extensive experi-ments on various features and their possible com-binations, we have selected a feature set specificto the disease mention identification which com-prises features shown in Tables 1, 2, 4 and 3, anddictionary lookup features.Feature name DescriptionPoS Part-of-speech tagNormWord Normalized token(see Section 3.1)Lemma Lemmatized formcharNgram 3 and 4 character n-gramsSuffix 2-4 character suffixesPrefix 2-4 character prefixesTable 1: General linguistic features for tokeniFeature name DescriptionInitCap Is initial letter capitalAllCap Are all letters capitalMixCase Does contain mixed case lettersSingLow Is a single lower case letterSingUp Is a single upper case letterNum Is a numberPuncChar Punctuation character(if tokeni isa punctuation character)PrevCharAN Is previous characteralphanumericTable 2: Orthographic features for tokeniLike Leaman et al (2009), we have createda dictionary with the instances of the followingnine of the twelve UMLS semantic types fromFeature name DescriptionBi-gramk,k+1 Bi-grams offor i?
2 ?
k < i + 2 normalized tokensTri-gramk,k+1,k+2 Tri-grams offor i?
2 ?
k < i + 2 normalized tokensCtxPoSk,k+1 Bi-grams offor i ?
k < i + 2 token PoSCtxLemmak,k+1 Bi-grams offor i ?
k < i + 2 lemmatized tokensCtxWordk,k+1 Bi-grams offor i?
2 ?
k < i + 2 original tokensOffset conjunctions Extracted by Malletfrom featuresin the range fromtokeni?1 to tokeni+1Table 3: Contextual features for tokeniFeature name Descriptiondobj Target token(s) to which tokeniis a direct objectiobj Target token(s) to which tokeniis an indirect objectnsubj Target token(s) to which tokeniis an active nominal subjectnsubjpass Target token(s) to which tokeniis a passive nominal subjectnn Target token(s) to which tokeniis a noun compound modifierTable 4: Syntactic dependency features for tokeni.For example, in the sentence ?Clinton defeatedDole?, ?Clinton?
is the nsubj of the target token?defeated?.the semantic group ?DISORDER?10 from UMLSMetathesaurus (Bodenreider, 2004): (i) disease orsyndrome, (ii) neoplastic process, (iii) congenitalabnormality, (iv) acquired abnormality, (v) exper-imental model of disease, (vi) injury or poison-ing, (vii) mental or behavioral dysfunction, (viii)pathological function and (ix) sign or symptom.We have not considered the other three semantictypes (findings, anatomical abnormality and cellor molecular Dysfunction) since these three typeshave not been used during the annotation of Ari-zona Disease Corpus (AZDC) which we have usedin our experiments.Previous studies have shown that dictionarylookup features, i.e.
name matching against a10http://semanticnetwork.nlm.nih.gov/SemGroups/86dictionary of terms, often increase recall (Toriiet al, 2009; Leaman et al, 2009).
However,an unprocessed dictionary usually does not boostoverall performance (Zweigenbaum et al, 2007).So, to reduce uninformative lexical differences orspelling variations, we generalize and normalizethe dictionary entries using exactly the same stepsfollowed for the pre-processing of sentences (seeSection 3.1).To reduce chances of false and unlikelymatches, any entry inside the dictionary havingless than 3 characters or more than 10 tokens isdiscarded.5 Experiments5.1 DataWe have done experiments on the recently re-leased Arizona Disease Corpus (AZDC)11 (Lea-man et al, 2009).
The corpus has detailed annota-tions of diseases including UMLS codes, UMLSconcept names, possible alternative codes, andstart and end points of disease mentions insidethe corresponding sentences.
These detailed an-notations make this corpus a valuable resourcefor evaluating and benchmarking text mining so-lutions for disease recognition.
Table 5 shows var-ious characteristics of the corpus.Item name Total countAbstracts 793Sentences 2,783Total disease mentions 3,455Disease mentions without overlaps 3,093Disease mentions with overlaps 362Table 5: Various characteristics of AZDC.For the overlapping annotations, (e.g.
?endome-trial and ovarian cancers?
and ?ovarian cancers?
)we have considered only the larger annotationsin our experiments.
There remain 3,224 diseasementions after resolving overlaps according to theaforementioned criterion.
We have observed mi-nor differences in some statistics of the AZDC re-ported by Leaman et al (2009) with the statisticsof the downloadable version12 (Table 5).
How-11Downloaded from http://diego.asu.edu/downloads/AZDC/at 5-Feb-200912Note that ?Disease mentions (total)?
in the paper of Lea-man et al (2009) actually refers to the total disease mentionsafter overlap resolving (Robert Leaman, personal communi-cation).
One other thing is, Leaman et al (2009) mention 794ever, these differences can be considered negligi-ble.5.2 ResultsWe follow an experimental setting similar to theone in Leaman et al (2009) so that we can com-pare our results with that of the BANNER system.We performed 10-fold cross validation on AZDCin such a way that all sentences of the same ab-stract are included in the same fold.
The results ofall folds are averaged to obtain the final outcome.Table 6 shows the results of the experiments withdifferent features using the exact matching crite-rion.As we can see, our approach achieves signif-icantly higher result than that of BANNER.
Ini-tially, with only the general linguistic and or-thographic features the performance is not high.However, once the contextual features are used,there is a substantial improvement in the result.Note that BANNER does not use contextual fea-tures.
In fact, the use of contextual features is alsoquite limited in other BNER systems that achievehigh performance for gene/protein identification(Smith et al, 2008).Dictionary lookup features provide a very goodcontribution in the outcome.
This supports the ar-gument of Jimeno et al (2008) that the use of dis-ease terms in biomedical literature is well stan-dardized.
Post-processing and syntactic depen-dency features also increase some performance.We have done statistical significance tests forthe last four experimental results shown in Table 6.For each of such four experiments, the immediateprevious experiment is considered as the baseline.The tests have been performed using the approx-imate randomization procedure (Noreen, 1989).We have set the number of iterations to 1,000 andthe confidence level to 0.01.
According to thetests, the contributions of contextual features anddictionary lookup features are statistically signif-icant.
However, we have found that the contri-butions of post-processing rules and syntactic de-pendency features are statistically significant onlywhen the confidence level is 0.2 or more.
SinceAZDC consists of only 2,783 sentences, we canassume that the impact of post-processing rulesabstracts, 2,784 sentences and 3,228 (overlap resolved) dis-ease mentions in the AZDC.
But in our downloaded versionof AZDC, there is 1 abstract missing (i.e.
total 793 abstractsinstead of 794).
As a result, there is 1 less sentence and 4less (overlap resolved) disease mentions than the originallyreported numbers.87and syntactic dependency features has been not sosignificant despite of some performance improve-ment.5.3 Error analysisOne of the sources of errors is the annotationshaving conjunction structures.
There are 94 dis-ease mentions in the data which contain the word?and?.
The boundaries of 11 of them have beenwrongly identified during experiments, while 39of them have been totally missed out by our sys-tem.
Our system also has not performed wellfor disease annotations that have some specifictypes of prepositional phrase structures.
For ex-ample, there are 80 disease annotations having theword ?of?
(e.g.
?deficient activity of acid beta-glucosidase GBA?).
Only 28 of them are correctlyannotated by our system.
The major source of er-rors, however, concerns abbreviated disease names(e.g.
?PNH?).
We believe one way to reduce thisspecific error type is to generate a list of possi-ble abbreviated disease names from the long formsof disease names available in databases such asUMLS Metathesaurus.6 Why Features for Diseases andGenes/Proteins are not the SameMany of the existing BNER systems, which aremainly tuned for gene/protein identification, usefeatures such as token shape (also known as wordclass and brief word class (Settles, 2004)), Greekalphabet matching, Roman number matching andso forth.
As mentioned earlier, we have done ex-tensive experiments with various feature combina-tions for the selection of disease specific features.We have observed that many of the features usedfor gene/protein identification are not equally ef-fective for disease identification.
Table 7 showssome of the results of those experiments.This observation is reasonable becausegene/protein names are much more complex thanentities such as diseases.
For example, they oftencontain punctuation characters (such as paren-theses or hyphen), Greek alphabets and digitswhich are unlikely in disease names.
Ideally,the ML algorithm itself should be able to utilizeinformation from only the useful features andignore the others in the feature set.
But practically,having non-informative features often misleadthe model learning.
In fact, several surveys haveargued that the choice of features matter at leastas much as the choice of the algorithm if not more(Nadeau and Sekine, 2007; Zweigenbaum et al,2007).One of the interesting trends in gene/proteinmention identification is to not utilize syntacticdependency relations (with the exception of Vla-chos (2007)).
Gene/protein names in biomedi-cal literature are often combined (i.e.
withoutbeing separated by space characters) with othercharacters which do not belong to the correspond-ing mentions (e.g.
p53-mediated).
Moreover,as mentioned before, gene/protein mentions com-monly have very complex structures (e.g.
PKR(1-551)K64E/K296R or RXRalphaF318A).
So, it is acommon practice to tokenize gene/proten namesadopting an approach that split tokens as much aspossible to extract effective features (Torii et al,2009; Smith et al, 2008).
But while the extensivetokenization boosts performance, it is often diffi-cult to correctly detect dependency relations forthe tokens of the gene/protein names in the sen-tences where they appear.
As a result, use of thesyntactic dependency relations is not beneficial insuch approaches.13 In comparison, disease men-tions are less complex.
So, the identified depen-dencies for disease mentions are more reliable andhence may be usable as potential features (refer toour experimental results in Table 6).The above mentioned issues are some of thereasons why a feature set for the well studiedgene/protein focused BNER approaches is notnecessarily suitable for other biomedical semantictypes such as diseases.7 ConclusionIn this paper, we have presented a single CRF clas-sifier based BNER approach for disease mentionidentification.
The feature set is constructed us-ing disease-specific contextual, orthographic, gen-eral linguistic, syntactic dependency and dictio-nary lookup features.
We have evaluated our ap-proach on AZDC corpus.
Our approach achievessignificantly higher result than BANNER which isthe current state-of-the-art ML based approach fordisease mention recognition.
We have also ex-plained why the choice of features for the wellstudied gene/protein does not apply for other se-mantic types such as diseases.13We have done some experiments on Biocreative II GMcorpus with syntactic dependency relations of the tokens,which are not reported in this paper, and the results supportour argument.88System Note Precision Recall F-scoreBANNER (Leaman et al, 2009) 80.9 75.1 77.9Our system Using general linguistic and orthographic features 74.90 71.01 72.90Our system After adding contextual features 82.15 75.81 78.85Our system After adding post-processing 81.57 76.61 79.01Our system After adding syntactic dependency features 82.07 76.66 79.27Our system After adding dictionary lookup features 83.21 79.06 81.08Table 6: 10-fold cross validation results using exact matching criteria on AZDC.Experiment Note Precision Recall F-score(i) Using general linguistic, orthographic 82.15 75.81 78.85and contextual features(ii) After adding WC and BWC features in (i) 82.08 75.57 78.69(iii) After adding IsGreekAlphabet, HasGreekAlphabet 82.10 75.69 78.76and IsRomanNumber features in (i)Table 7: Experimental results of our system after using some of the gene/protein specific features fordisease mention recognition on AZDC.
Here, WC and BWC refer to the ?word class?
and ?brief wordclass?
respectively.Future work includes implementation of diseasemention normalization (i.e.
associating a uniqueidentifier for each disease mention).
We alsoplan to improve our current approach by includ-ing more contextual features and post-processingrules.AcknowledgmentsThis work was carried out in the context of theproject ?eOnco - Pervasive knowledge and datamanagement in cancer care?.
The authors wouldlike to thank Robert Leaman for sharing the set-tings of his experiments on AZDC.ReferencesAgarwal, P., Searls, D. 2008.
Literature mining in sup-port of drug discovery.
Brief Bioinform, 9(6):479?492.Aronson, A.
2001.
Effective mapping of biomedicaltext to the UMLS Metathesaurus: the MetaMap pro-gram.
In Proceedings AMIA Symposium, pages 17?21.Bodenreider, O.
2004.
The Unified Medical LanguageSystem (UMLS): integrating biomedical terminol-ogy.
Nucleic Acids Research, 32(suppl 1):D267?270, January.Bundschus, M., Dejori, M., Stetter, M., Tresp, V.,Kriegel, H. 2008.
Extraction of semantic biomed-ical relations from text using conditional randomfields.
BMC Bioinformatics, 9:207.Dai, H., Chang, Y., Tsai, R., Hsu, W. 2009.
Newchallenges for biological text-mining in the nextdecade.
Journal of Computer Science and Technol-ogy, 25(1):169?179.Jimeno, A., Jimnez-Ruiz, E., Lee, V., Gaudan, S.,Berlanga, R., Rebholz-Schuhmann, D. 2008.
As-sessment of disease named entity recognition on acorpus of annotated sentences.
BMC Bioinformat-ics, 9(S-3).Klinger, R., Tomanek, K. 2007.
Classical ProbabilisticModels and Conditional Random Fields.
TechnicalReport TR07-2-013, Department of Computer Sci-ence, Dortmund University of Technology, Decem-ber.Kulick, S., Bies, A., Liberman, M., Mandel, M., Mc-Donald, R., Palmer, M., Schein, A., Ungar, L. 2004.Integrated annotation for biomedical information ex-traction.
In Proceedings of HLT/NAACL 2004 Bi-oLink Workshop, pages 61?68.Leaman, R., Gonzalez, G. 2008.
Banner: An exe-cutable survey of advances in biomedical named en-tity recognition.
In Proceedings of Pacific Sympo-sium on Biocomputing, volume 13, pages 652?663.Leaman, R., Miller, C., Gonzalez, G. 2009.
Enablingrecognition of diseases in biomedical text with ma-chine learning: Corpus and benchmark.
In Proceed-ings of the 3rd International Symposium on Lan-guages in Biology and Medicine, pages 82?89.McCallum, A.
2002.
Mallet: A machine learning forlanguage toolkit.
http://mallet.cs.umass.edu,.Meystre, S., Savova, G., Kipper-Schuler, K., Hurdle,J.
2008.
Extracting information from textual doc-uments in the electronic health record: a review of89recent research.
IMIA Yearbook of Medical Infor-matics, pages 128?44.Ne?ve?ol, A., Kim, W., Wilbur, W., Lu, Z.
2009.
Explor-ing two biomedical text genres for disease recogni-tion.
In Proceedings of the BioNLP 2009 Workshop,pages 144?152, June.Nadeau, D., Sekine, S. 2007.
A survey of named entityrecognition and classification.
Linguisticae Investi-gationes, 30(1):3?26.Noreen, E.W.
1989.
Computer-Intensive Methodsfor Testing Hypotheses: An Introduction.
Wiley-Interscience.Rosario, B., Hearst, M. 2004.
Classifying semanticrelations in bioscience texts.
In Proceedings of the42nd Meeting of the Association for ComputationalLinguistics (ACL?04).Schwartz, A., Hearst, M. 2003.
A simple algorithmfor identifying abbreviation definitions in biomedi-cal text.
In Proceedings of Pacific Symposium onBiocomputing, pages 451?62.Settles, B.
2004.
Biomedical named entity recognitionusing conditional random fields and rich feature sets.In Proceedings of the International Joint Workshopon Natural Language Processing in Biomedicineand its Applications, pages 104?107.Smith, L., Tanabe, L., Ando, R., Kuo, C., et al 2008.Overview of BioCreative II gene mention recogni-tion.
Genome Biology, 9(Suppl 2).Torii, M., Hu, Z., Wu, C., Liu, H. 2009.
Biotagger-GM: a gene/protein name recognition system.
Jour-nal of the American Medical Informatics Associa-tion : JAMIA, 16:247?255.Vlachos, A.
2007.
Tackling the BioCreative2 genemention task with conditional random fields andsyntactic parsing.
In Proceedings of the 2nd BioCre-ative Challenge Evaluation Workshop, pages 85?87.Zweigenbaum, P., Demner-Fushman, D., Yu, H., Co-hen, K. 2007.
Frontiers of biomedical text mining:current progress.
Brief Bioinform, 8(5):358?375.90
