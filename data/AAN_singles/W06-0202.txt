Proceedings of the Workshop on Information Extraction Beyond The Document, pages 12?19,Sydney, July 2006. c?2006 Association for Computational LinguisticsComparing Information Extraction Pattern ModelsMark Stevenson and Mark A. GreenwoodDepartment of Computer ScienceUniversity of SheffieldSheffield, S1 4DP, UK{marks,m.greenwood}@dcs.shef.ac.ukAbstractSeveral recently reported techniques forthe automatic acquisition of InformationExtraction (IE) systems have used depen-dency trees as the basis of their extrac-tion pattern representation.
These ap-proaches have used a variety of patternmodels (schemes for representing IE pat-terns based on particular parts of the de-pendency analysis).
An appropriate modelshould be expressive enough to representthe information which is to be extractedfrom text without being overly compli-cated.
Four previously reported patternmodels are evaluated using existing IEevaluation corpora and three dependencyparsers.
It was found that one model,linked chains, could represent around 95%of the information of interest without gen-erating an unwieldy number of possiblepatterns.1 IntroductionA common approach to Information Extraction(IE) is to use patterns which match against textand identify items of interest.
Patterns are appliedto text which has undergone various levels of lin-guistic analysis, such as phrase chunking (Soder-land, 1999) and full syntactic parsing (Gaizauskaset al, 1996).
The approaches use different defini-tions of what constitutes a valid pattern.
For exam-ple, the AutoSlog system (Riloff, 1993) uses pat-terns which match certain grammatical categories,mainly nouns and verbs, in phrase chunked textwhile Yangarber et al (2000) use subject-verb-object tuples derived from a dependency parse.
Anappropriate pattern language must encode enoughinformation about the text to be able to accuratelyidentify the items of interest.
However, it shouldnot contain so much information as to be complexand impractical to apply.Several recent approaches to IE have used pat-terns based on a dependency analysis of the inputtext (Yangarber, 2003; Sudo et al, 2001; Sudo etal., 2003; Bunescu and Mooney, 2005; Stevensonand Greenwood, 2005).
These approaches haveused a variety of pattern models (schemes for rep-resenting IE patterns based on particular parts ofthe dependency tree).
For example, Yangarber(2003) uses just subject-verb-object tuples whileSudo et al (2003) allow any subpart of the tree toact as an extraction pattern.
The set of patterns al-lowed by the first model is a proper subset of thesecond and therefore captures less of the informa-tion contained in the dependency tree.
Little anal-ysis has been carried out into the appropriatenessof each model.
Sudo et al (2003) compared threemodels in terms of their ability to identify eventparticipants.The choice of pattern model has an effect onthe number of potential patterns.
This has impli-cations on the practical application for each ap-proach, particularly when used for automatic ac-quisition of IE systems using learning methods(Yangarber et al, 2000; Sudo et al, 2003; Bunescuand Mooney, 2005).
This paper evaluates the ap-propriateness of four pattern models in terms ofthe competing aims of expressive completeness(ability to represent information in text) and com-plexity (number of possible patterns).
Each modelis examined by comparing it against a corpus an-notated with events and determining the propor-tion of those which it is capable of representing.The remainder of this paper is organised as fol-lows: a variety of dependency-tree-based IE pat-12Figure 1: An example dependency tree.tern models are introduced (Sections 2 and 3).Section 4 describes experiments comparing eachmodel and the results are discussed in Section 5.2 Pattern ModelsIn dependency analysis (Mel?c?uk, 1987) the syn-tax of a sentence is represented by a set of directedbinary links between a word (the head) and one ofits modifiers.
These links may be labelled to in-dicate the grammatical relation between the headand modifier (e.g.
subject, object).
In generalcyclical paths are disallowed so that the analysisforms a tree structure.
An example dependencyanalysis for the sentence ?Acme Inc. hired MrSmith as their new CEO, replacing Mr Bloggs.
?is shown Figure 1.The remainder of this section outlines four mod-els for representing extraction patterns which canbe derived from dependency trees.Predicate-Argument Model (SVO): A simpleapproach, used by Yangarber (2003) and Steven-son and Greenwood (2005), is to use subject-verb-object tuples from the dependency parse as extrac-tion patterns.
These consist of a verb and its sub-ject and/or direct object1.
An SVO pattern is ex-tracted for each verb in a sentence.
Figure 2 showsthe two SVO patterns2 which are produced for thedependency tree shown in Figure 1.This model may be motivated by the assump-tion that many IE scenarios involve the extraction1Yangarber et al (2000) and Sudo et al (2003) used aslightly extended version of this model in which the patternalso included certain phrases which referred to either the sub-ject or object.2The formalism used for representing dependency pat-terns is similar to the one introduced by Sudo et al (2003).Each node in the tree is represented in the format a[b/c](e.g.
subj[N/bomber]) where c is the lexical item(bomber), b its grammatical tag (N) and a the dependencyrelation between this node and its parent (subj).
The rela-tionship between nodes is represented as X(A+B+C) whichindicates that nodes A, B and C are direct descendents of nodeX.of participants in specific events.
For example,the MUC-6 (MUC, 1995) management successionscenario concerns the identification of individualswho are changing job.
These events are often de-scribed using a simple predicate argument struc-ture, e.g.
?Acme Inc. fired Smith?.
However,the SVO model cannot represent information de-scribed using other linguistic constructions such asnominalisations or prepositional phrases.
For ex-ample, in the MUC6 texts it is common for job ti-tles to be mentioned within prepositional phrases,e.g.
?Smith joined Acme Inc. as CEO?.Chains: A pattern is defined as a path betweena verb node and any other node in the dependencytree passing through zero or more intermediatenodes (Sudo et al, 2001).
Figure 2 shows the eightchains which can be extracted from the tree in Fig-ure 1.Chains provide a mechanism for encoding in-formation beyond the direct arguments of predi-cates and includes areas of the dependency tree ig-nored by the SVO model.
For example, they canrepresent information expressed as a nominalisa-tion or within a prepositional phrase, e.g.
?Theresignation of Smith from the board of Acme ...?However, a potential shortcoming of this model isthat it cannot represent the link between argumentsof a verb.
Patterns in the chain model format areunable to represent even the simplest of sentencescontaining a transitive verb, e.g.
?Smith left AcmeInc.
?.Linked Chains: The linked chains model(Greenwood et al, 2005) represents extractionpatterns as a pair of chains which share the sameverb but no direct descendants.
This model gen-erates 14 patterns for the verb hire in Figure 1,examples of which are shown in Figure 2.
Thispattern representation encodes most of the infor-mation in the sentence with the advantage of beingable to link together event participants which nei-ther of the SVO or chain model can, for examplethe relation between ?Smith?
and ?Bloggs?.Subtrees: The final model to be considered isthe subtree model (Sudo et al, 2003).
In thismodel any subtree of a dependency tree can beused as an extraction pattern, where a subtree isany set of nodes in the tree which are connected toone another.
Single nodes are not considered to besubtrees.
The subtree model is a richer representa-tion than those discussed so far and can representany part of a dependency tree.
Each of the previ-13SVO Chains[V/hire](subj[N/Acme Inc.]+obj[N/Mr Smith]) [V/hire](subj[N/Acme Inc.])[V/replace](obj[N/Mr Bloggs]) [V/hire](obj[N/Mr Smith])[V/hire](obj[N/Mr Smith](as[N/CEO]))[V/hire](obj[N/Mr Smith](as[N/CEO](gen[N/their])))[V/hire](obj[N/Mr Smith](as[N/CEO](mod[A/new])))[V/hire](vpsc mod[V/replace])[V/hire](vpsc mod[V/replace](obj[N/Mr Bloggs]))[V/replace](obj[N/Mr Bloggs])Linked Chains[V/hire](subj[N/Acme Inc.]+obj[N/Mr Smith])[V/hire](subj[N/Acme Inc.]+obj[N/Mr Smith](as[N/CEO]))[V/hire](obj[N/Mr Smith]+vpsc mod[V/replace](obj[N/Mr Bloggs]))Figure 2: Example patterns for three modelsous models form a proper subset of the subtrees.By choosing an appropriate subtree it is possibleto link together any pair of nodes in a tree andconsequently this model can represent the relationbetween any set of items in the sentence.3 Pattern Enumeration and ComplexityIn addition to encoding different parts of the de-pendency analysis, each pattern model will alsogenerate a different number of potential patterns.A dependency tree, T , can be viewed as a setof N connected nodes.
Assume that V , such thatV ?
N , is the set of nodes in the dependency treelabelled as a verb.Predicate-Argument Model (SVO): The num-ber of SVO patterns extracted from T is:Nsvo (T ) = |V | (1)Chain Model: A chain can be created betweenany verb and a node it dominates (directly or indi-rectly).
Now assume that d(v) denotes the countof a node v and all its descendents then the numberof chains is given by:Nchains (T ) =?v?V( d (v) ?
1 ) (2)Linked Chains: Let C(v) denote the set of di-rect child nodes of node v and vi denote the i-thchild, so C(v) ={v1, v2, ...v|C(v)|}.
The numberof possible linked chains in T is given by:Nlinked chains (T ) =?v?V|C(v)|?i=1|C(v)|?j=i+1d (vi) d (vj)(3)Subtrees: Now assume that sub(n) is a func-tion denoting the number of subtrees, includingsingle nodes, rooted at node n. This can be de-fined recursively as follows:sub(n) =??
?1 if n is a leaf node|C(n)|?i=1(sub (ni) + 1) otherwise(4)The total number of subtrees in a tree is givenby:Nsubtree (T ) =(?n?Nsub(n))?
|N | (5)The dependency tree shown in Figure 1 gener-ates 2, 8, 14 and 42 possible SVO, chain, linkedchain and subtree patterns respectively.
The num-ber of SVO patterns is constant on the number ofverbs in the tree.
The number of chains is gener-ally a linear function on the size of the tree but,in the worst case, can be polynomial.
The linkedchain model generates a polynomial number ofpatterns while the subtree model is exponential.There is a clear tradeoff between the complex-ity of pattern representations and the practicalityof computation using them.
Some pattern rep-resentations are more expressive, in terms of theamount of information from the dependency treethey make use of, than others (Section 2) and aretherefore more likely to produce accurate extrac-tion patterns.
However, the more expressive mod-els will add extra complexities during computationsince a greater number of patterns will be gen-erated.
This complexity, both in the number ofpatterns produced and the computational effort re-quired to produce them, limits the algorithms thatcan reasonably be applied to learn useful extrac-tion patterns.For a pattern model to be suitable for an ex-traction task it needs to be expressive enough toencode enough information from the dependencyparse to accurately identify the items which needto be extracted.
However, we also aim for the14model to be as computationally tractable as pos-sible.
The ideal model will then be one with suffi-cient expressive power while at the same time notincluding extra information which would make itsuse less practical.4 ExperimentsWe carried out experiments to determine how suit-able the pattern representations detailed in Section2 are for encoding the information of interest toIE systems.
We chose a set of IE corpora anno-tated with the information to be extracted (detailedin Section 4.1), generated sets of patterns using avariety of dependency parsers (Section 4.2) whichwere then examined to discover how much of thetarget information they contain (Section 4.3).4.1 CorporaCorpora representing different genres of text werechosen for these experiments; one containingnewspaper text and another composed of biomed-ical abstracts.
The first corpus consisted of WallStreet Journal texts from the Sixth Message Un-derstanding Conference (MUC, 1995) IE evalu-ation.
These are reliably annotated with detailsabout the movement of executives between jobs.We make use of a version of the corpus pro-duced by Soderland (1999) in which events de-scribed within a single sentence were annotated.Events in this corpus identify relations betweenup to four entities: PersonIn (the person start-ing a new job), PersonOut (person leaving ajob), Post (the job title) and Organisation(the employer).
These events were broken downinto a set of binary relationships.
For exam-ple, the sentence ?Smith was recently made chair-man of Acme.?
contains information about thenew employee (Smith), post (chairman) and or-ganisation (Acme).
Events are represented as aset of binary relationships, Smith-chairman,chairman-Acme and Smith-Acme for thisexample.The second corpus uses documents taken fromthe biomedical domain, specifically the train-ing corpus used in the LLL-05 challenge task(Ne?dellec, 2005), and a pair of corpora (Cravenand Kumlien, 1999) which were derived from theYeast Proteome Database (YPD) (Hodges et al,1999) and the Online Mendelian Inheritance inMan database (OMIM) (Hamosh et al, 2002).Each of these corpora are annotated with binaryrelations between pairs of entities.
The LLL-05corpora contains interactions between genes andproteins.
For example the sentence ?Expressionof the sigma(K)-dependent cwlH gene dependedon gerE?
contains relations between sigma(K) andcwlH and between gerE and cwlH.
The YPD cor-pus is concerned with the subcellular compart-ments in which particular yeast proteins localize.An example sentence ?Uba2p is located largely inthe nucleus?
relates Uba2p and the nucleus.
Therelations in the OMIM corpora are between genesand diseases, for example ?Most sporadic colorec-tal cancers also have two APC mutations?
con-tains a relation between APC and colorectal can-cer.The MUC6 corpus contains a total of six pos-sible binary relations.
Each of the three biomedi-cal corpora contain a single relation type, giving atotal of nine binary relations for the experiments.There are 3911 instances of binary relations in allcorpora.4.2 Generating Dependency PatternsThree dependency parsers were used for these ex-periments: MINIPAR3 (Lin, 1999), the MachineseSyntax4 parser from Connexor Oy (Tapanainenand Ja?rvinen, 1997) and the Stanford5 parser(Klein and Manning, 2003).
These three parsersrepresent a cross-section of approaches to produc-ing dependency analyses: MINIPAR uses a con-stituency grammar internally before convertingthe result to a dependency tree, Machinese Syn-tax uses a functional dependency grammar, andthe Stanford Parser is a lexicalized probabilisticparser.Before these parsers were applied to the variouscorpora the named entities participating in rela-tions are replaced by a token indicating their class.For example, in the MUC6 corpus ?Acme hiredSmith?
would become ?Organisation hiredPersonIn?.
Each parser was adapted to dealwith these tokens correctly.
The parsers were ap-plied to each corpus and patterns extracted fromthe dependency trees generated.The analyses produced by the parsers were post-processed to make the most of the informationthey contain and ensure consistent structures fromwhich patterns could be extracted.
It was found3http://www.cs.ualberta.ca/?lindek/4http://www.connexor.com/software/syntax/5http://www-nlp.stanford.edu/software/15Parser SVO Chains Linked chains SubtreesMINIPAR 2,980 52,659 149,504 353,778,240,702,149,000Machinese Syntax 2,382 67,690 265,631 4,641,825,924Stanford 2,950 76,620 478,643 1,696,259,251,073Table 1: Number of patterns produced for each pattern model by different parsersthat the parsers were often unable to generate a de-pendency tree which included the whole sentenceand instead generate an analysis consisting of sen-tence fragments represented as separate tree struc-tures.
Some fragments did not include a verb sono patterns could be extracted.
To take account ofthis we allowed the root node of any tree fragmentto take the place of a verb in a pattern (see Sec-tion 2).
This leads to the generation of more chainand linked chain patterns but has no effect on thenumber of SVO patterns or subtrees.Table 1 shows the number of patterns generatedfrom the dependency trees produced by each of theparsers.
The number of subtrees generated fromthe MINIPAR parses is several orders of magnitudehigher than the others because MINIPAR allowscertain nodes to be the modifier of two separatenodes to deal with phenomena such as conjunc-tion, anaphora and VP-coordination.
For exam-ple, in the sentence ?The bomb caused widespreaddamage and killed three people?
the bomb is thesubject of both the verbs cause and kill.
We madeuse of this information by duplicating any nodes(and their descendants) with more than one head.6Overall the figures in Table 1 are consistent withthe analysis in Section 3 but there is great variationin the number of patterns produced by the differ-ent parsers.
For example, the Stanford parser pro-duces more chains and linked chains than the otherparsers.
(If we did not duplicate portions of theMINIPAR parses then the Stanford parser wouldalso generate the most subtrees.)
We found thatthe Stanford parser was the most likely to gen-erate a single dependency tree for each sentencewhile the other two produced a set of tree frag-ments.
A single dependency analysis contains agreater number of patterns, and possible subtrees,than a fragmented analysis.
One reason for thismay be that the Stanford parser is unique in allow-ing the use of an underspecified dependency rela-tion, dep, which can be applied when the role ofthe dependency is unclear.
This allows the Stan-6One dependency tree produced by MINIPAR, expanded inthis way, contained approximately 1 ?
1064 subtrees.
Theseare not included in the total number of subtrees for the MINI-PAR parses shown in the table.ford parser to generate analyses which span moreof the sentence than the other two.4.3 Evaluating Pattern ModelsPatterns from each of the four models are exam-ined to check whether they cover the informationwhich should be extracted.
In this context ?cover?means that the pattern contains both elementsof the relation.
For example, an SVO patternextracted from the dependency parse of ?Smithwas recently made chairman of Acme.?
would be[V/make](subj[N/Smith]+obj[N/chairman])which covers the relation between Smith andchairman but not the relations between Smithand Acme or chairman and Acme.
The coverageof each model is computed as the percentage ofrelations in the corpus for which at least one ofthe patterns contains both of the participatingentities.
Coverage is related to the more familiarIE evaluation metric of recall since the coverageof a pattern model places an upper bound on therecall of any system using that model.
The aimof this work is to determine the proportion ofthe relations in a corpus that can be representedusing the various pattern models rather than theirperformance in an IE system and, consequently,we choose to evaluate models in terms of theircoverage rather than precision and recall.7For practical applications parsers are requiredto generate the dependency analysis but these maynot always provide a complete analysis for everysentence.
The coverage of each model is influ-enced by the ability of the parser to produce a treewhich connects the elements of the event to be ex-tracted.
To account for this we compute the cov-erage of each model relative to a particular parser.The subtree model covers all events whose enti-ties are included in the dependency tree and, con-sequently, the coverage of this model representsthe maximum number of events that the model can7The subtree model can be used to cover any set of itemsin a dependency tree.
So, given accurate dependency anal-yses, this model will cover all events.
The coverage of thesubtree model can be determined by checking if the elementsof the event are connected in the dependency analysis of thesentence and, for simplicity, we chose to do this rather thanenumerating all subtrees.16represent for a given dependency tree.
The cover-age of other models relative to a dependency anal-ysis can be computed by dividing the number ofevents it covers by the number covered by the sub-tree model (i.e.
the maximum which can be cov-ered).
This measure is refered to as the boundedcoverage of the model.
Bounded coverage for thesubtree model is always 100%.5 ResultsCoverage and bounded-coverage results for eachpattern representation and parser combination aregiven in Table 2.
The table lists the corpus, thetotal number of instances within that corpus andthe results for each of the four pattern models.
Re-sults for the subtree model lists the coverage andraw count, the bounded-coverage for this modelwill always be 100% and is not listed.
Resultsfor the other three models show the coverage andraw count along with the bounded coverage.
Thecoverage of each parser and pattern representa-tion (combined across both corpora) are also sum-marised in Figure 3.The simplest representation, SVO, does not per-form well in this evaluation.
The highest bounded-coverage score is 15.1% (MUC6 corpus, Stanfordparser) but the combined average over all corporais less than 6% for any parser.
This suggeststhat the SVO representation is simply not expres-sive enough for IE.
Previous work which has usedthis representation have used indirect evaluation:document and sentence filtering (Yangarber, 2003;Stevenson and Greenwood, 2005).
While the SVOrepresentation may be expressive enough to allowa classifier to distinguish documents or sentenceswhich are relevant to a particular extraction task itseems too limited to be used for relation extrac-tion.
The SVO representation performs notice-ably worse on the biomedical text.
Our analysissuggests that this is because the items of interestare commonly described in ways which the SVOmodel is unable to represent.The more complex chain model covers a greaterpercentage of the relations.
However its bounded-coverage is still less than half of the relations in ei-ther the MUC6 corpus or the biomedical texts.
Us-ing the chain model the best coverage which canbe achieved over any corpus is 41.07% (MUC6corpus, MINIPAR and Stanford parser) which isunlikely to be sufficient to create an IE system.Results for the linked chain representation are0%10%20%30%40%50%60%70%80%90%100%MINIPAR Machinese Syntax StanfordCoverageSVO Chains Linked Chains SubtreesFigure 3: Coverage of various pattern representa-tion models for each of the three parsers.much more promising covering around 70% of allrelations using the MINIPAR and Machinese Syn-tax parsers and over 90.64% using the Stanfordparser.
For all three parsers this model achievesa bounded-coverage of close to 95%, indicatingthat this model can represent the majority of re-lations which are included in a dependency tree.The subtree representation covers slight more ofthe relations than linked chains: around 75% us-ing the MINIPAR or Machinese Syntax parsers and96.62% using the Stanford parser.A one-way repeated measures ANOVA was car-ried out to analyse the differences between the re-sults for each model shown in Table 2.
It wasfound that the differences between the SVO, chain,linked chain and subtree models are significant(p < 0.01).
A Tukey test was then applied to iden-tify which of the individual differences betweenpairs of models were significant.
Differences be-tween two pairs of models were not found to besignificant (p < 0.01): SVO and chains; linkedchains and subtrees.These results suggest that the linked chains andsubtree models can represent significantly more ofthe relations which occur in IE scenarios than ei-ther the SVO or chain models.
However, there islittle to be gained from using the subtree modelsince accuracy of the linked chain model is com-parable and the number of patterns generated isbounded by a polynomial rather than exponentialfunction.5.1 Analysis and DiscussionExamination of the relations which were cov-ered by the subtree model but not by linkedchains suggested that there are certain construc-tions which cause difficulties.
One such construc-tion is the appositive, e.g.
the relation between17# of SVO Chains Linked Chains SubtreesParser Corpus Relations %C %B-C %C %B-C %C %B-C %CMUC6 1322 7.49 (99) 9.07 41.07 (543) 49.73 81.92 (1083) 99.18 82.60 (1092)MINIPAR Biomed 2589 0.93 (24) 1.30 17.38 (450) 24.44 65.31 (1691) 91.85 71.11 (1841)Combined 3911 3.14 (123) 4.19 25.39 (993) 33.86 70.93 (2774) 94.58 74.99 (2933)Machinese MUC6 1322 2.12 (28) 2.75 35.70 (472) 46.41 76.32 (1009) 99.21 76.93 (1017)Syntax Biomed 2589 0.19 (5) 0.27 14.56 (377) 20.47 65.47 (1695) 92.02 71.15 (1842)Combined 3911 0.84 (33) 1.15 21.71 (849) 29.70 69.14 (2704) 94.58 73.10 (2859)MUC6 1322 15.05 (199) 15.10 41.07 (543) 41.20 94.78 (1253) 95.07 99.70 (1318)Stanford Biomed 2589 0.46 (12) 0.49 16.53 (428) 17.39 88.52 (2292) 93.13 95.06 (2461)Combined 3911 5.40 (211) 5.58 24.83 (971) 25.69 90.64 (3545) 93.81 96.62 (3779)Table 2: Evaluation results for the three different parsers.PersonOut and Organisation in the frag-ment ?Organisation?s Post, PersonOut,resigned yesterday morning?.
Certain nominal-isations may also cause problems for the linkedchains representation, e.g.
in biomedical textthe relation between Agent and Target in thenominalisation ?the Agent-dependent assemblyof Target?
cannot be represented by a linkedchain.
In both cases the problem is caused by thefact that the dependency tree generated includesthe two named entities in part of the tree domi-nated by a node marked as a noun.
Since eachlinked chain must be anchored at a verb (or theroot of a tree fragment) and the two chains can-not share part of their path, these relations are notcovered.
It would be possible to create anotherrepresentation which allowed these relations to becaptured but it would generate more patterns thanthe linked chain model.Our results also reveal that the choice of depen-dency parser effects the coverage of each model(see Figure 3).
The subtree model coverage scoresfor each parser shown in Table 3 represent the per-centage of sentences for which an analysis wasgenerated that included both items from the bi-nary relations.
These figures are noticably higherfor the Stanford parser.
We previously mentioned(Section 4.2) that this parser allows the use of anunderspecified dependency relation and suggestedthat this may be a reason for the higher cover-age.
The use of underspecified dependency re-lations may not be useful for all applications butis unlikely to cause problems for systems whichlearn IE patterns provided the trees generated bythe parser are consistent.
Differences between theresults produced by the three parsers suggest thatit is important to fully evaluate their suitability fora particular purpose.These experiments also provide insights into themore general question of how suitable dependencytrees are as a basis for extraction patterns.
De-pendency analysis has the advantage of generat-ing analyses which abstract away from the sur-face realisation of text to a greater extent thanphrase structure grammars tend to.
This leads tothe semantic information being more accessible inthe representation of the text which can be use-ful for IE.
For practical applications this approachrelies on the ability to accurately generate depen-dency analyses.
The results presented here sug-gest that the Stanford parser (Klein and Manning,2003) is capable of generating analyses for almostall sentences within corpora from two very differ-ent domains.
Bunescu and Mooney (2005) havealso demonstrated that dependency graphs can beproduced using Combinatory Categorial Grammar(CCG) and context-free grammar (CFG) parsers.6 ConclusionsThis paper compares four IE pattern models:SVO, chains, linked chains and subtrees.
Us-ing texts from the management succession andbiomedical domains it was found that the linkedchains model can represent around 95% of thepossible relations contained in the text, given a de-pendency parse.
Subtrees can represent all the re-lations contained within dependency trees but theiruse is less practical because enumerating all pos-sible subtrees is a more complex problem and thelarge number of resulting patterns could limit thelearning algorithms that can be applied.
This re-sult should be borne in mind during the design ofIE systems.AcknowledgementsThe authors are grateful to Mike Stannet for pro-viding the method for counting subtrees intro-duced in Section 3 and to Connexor Oy for useof the Machinese Syntax parser.
The research18described in this paper was funded by the En-gineering and Physical Sciences Research Coun-cil via the RESuLT project (GR/T06391) and par-tially funded by the IST 6th Framework project X-Media (FP6-26978).ReferencesRazvan Bunescu and Raymond Mooney.
2005.
Ashortest path dependency kernel for relation extrac-tion.
In Proceedings of the Human Language Tech-nology Conference and Conference on EmpiricalMethods in Natural Language Processing, pages724?731, Vancouver, B.C.Mark Craven and Johan Kumlien.
1999.
Construct-ing Biological Knowledge Bases by Extracting In-formation from Text Sources.
In Proceedings of theSeventh International Conference on Intelligent Sys-tems for Molecular Biology, pages 77?86, Heidel-berg, Germany.
AAAI Press.Robert Gaizauskas, Takahiro Wakao, KevinHumphreys, Hamish Cunningham, and YorickWilks.
1996.
Description of the LaSIE systemas used for MUC-6.
In Proceedings of the SixthMessage Understanding Conference (MUC-6),pages 207?220, San Francisco, CA.Mark A. Greenwood, Mark Stevenson, Yikun Guo,Henk Harkema, and Angus Roberts.
2005.
Au-tomatically Acquiring a Linguistically MotivatedGenic Interaction Extraction System.
In Proceed-ings of the 4th Learning Language in Logic Work-shop (LLL05), Bonn, Germany.Ada Hamosh, Alan F. Scott, Joanna Amberger, CarolBocchini, David Valle, and Victor A. McKusick.2002.
Online Mendelian Inheritance in Man(OMIM), a knowledgebase of human genes and ge-netic disorders.
Nucleic Acids Research, 30(1):52?55.Peter E. Hodges, Andrew H. Z. McKee, Brian P. Davis,William E. Payne, and James I. Garrels.
1999.
TheYeast Proteome Database (YPD): a model for the or-ganization and presentation of genome-wide func-tional data.
Nucleic Acids Research, 27(1):69?73.Dan Klein and Christopher D. Manning.
2003.
Ac-curate Unlexicalized Parsing.
In Proceedings of the41st Annual Meeting of the Association for Compu-tational Linguistics (ACL-03), pages 423?430, Sap-poro, Japan.Dekang Lin.
1999.
MINIPAR: A Minimalist Parser.In Maryland Linguistics Colloquium, University ofMaryland, College Park.Igor Mel?c?uk.
1987.
Dependency Syntax: Theory andPractice.
SUNY Press, New York.MUC.
1995.
Proceedings of the Sixth Message Un-derstanding Conference (MUC-6), San Mateo, CA.Morgan Kaufmann.Claire Ne?dellec.
2005.
Learning Language in Logic -Genic Interaction Extraction Challenge.
In Proceed-ings of the 4th Learning Language in Logic Work-shop (LLL05), Bonn, Germany, August.Ellen Riloff.
1993.
Automatically constructing a dic-tionary for information extraction tasks.
pages 811?816.Stephen Soderland.
1999.
Learning Information Ex-traction Rules for Semi-structured and free text.
Ma-chine Learning, 31(1-3):233?272.Mark Stevenson and Mark A. Greenwood.
2005.
ASemantic Approach to IE Pattern Induction.
In Pro-ceedings of the 43rd Annual Meeting of the Associa-tion for Computational Linguistics, pages 379?386,Ann Arbor, MI.Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.2001.
Automatic Pattern Acquisition for JapaneseInformation Extraction.
In Proceedings of the Hu-man Language Technology Conference (HLT2001).Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.2003.
An Improved Extraction Pattern Representa-tion Model for Automatic IE Pattern Acquisition.
InProceedings of the 41st Annual Meeting of the As-sociation for Computational Linguistics (ACL-03),pages 224?231, Sapporo, Japan.Pasi Tapanainen and Timo Ja?rvinen.
1997.
A Non-Projective Dependency Parser.
In Proceedings ofthe 5th Conference on Applied Natural LanguageProcessing, pages 64?74, Washington, DC.Roman Yangarber, Ralph Grishman, Pasi Tapanainen,and Silja Huttunen.
2000.
Automatic Acquisition ofDomain Knowledge for Information Extraction.
InProceedings of the 18th International Conference onComputational Linguistics (COLING 2000), pages940?946, Saarbru?cken, Germany.Roman Yangarber.
2003.
Counter-training in the Dis-covery of Semantic Patterns.
In Proceedings of the41st Annual Meeting of the Association for Compu-tational Linguistics (ACL-03), pages 343?350, Sap-poro, Japan.19
