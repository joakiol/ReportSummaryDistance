Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 1501?1510, Dublin, Ireland, August 23-29 2014.Annotating Argument Components and Relations in Persuasive EssaysChristian Stab?and Iryna Gurevych??
?Ubiquitous Knowledge Processing Lab (UKP-TUDA),Department of Computer Science, Technische Universita?t Darmstadt?Ubiquitous Knowledge Processing Lab (UKP-DIPF),German Institute for Educational Researchhttp://www.ukp.tu-darmstadt.deAbstractIn this paper, we present a novel approach to model arguments, their components and relationsin persuasive essays in English.
We propose an annotation scheme that includes the annotationof claims and premises as well as support and attack relations for capturing the structure of argu-mentative discourse.
We further conduct a manual annotation study with three annotators on 90persuasive essays.
The obtained inter-rater agreement of ?U= 0.72 for argument componentsand ?
= 0.81 for argumentative relations indicates that the proposed annotation scheme success-fully guides annotators to substantial agreement.
The final corpus and the annotation guidelinesare freely available to encourage future research in argument recognition.1 IntroductionThe ability of formulating persuasive arguments is a crucial aspect in writing skills acquisition.
On theone hand, well-defined arguments are the foundation for convincing an audience of novel ideas.
On theother hand, good argumentation skills are essential for analyzing different stances in general decisionmaking.
By automatically recognizing arguments in text documents, students will be able to inspecttheir texts for plausibility as well as revise the discourse structure for improving argumentation quality.This assumption is supported by recent findings in psychology, which confirm that even general tutorialseffectively improve the quality of written arguments (Butler and Britt, 2011).
In addition, argumentativewriting support systems will enable tailored feedback by incorporating argument recognition.
Therefore,it could be expected that they provide appropriate guidance for improving argumentation quality as wellas the student?s writing skills.An argument consists of several components (i.e.
claims and premises) and exhibits a certain structureconstituted by argumentative relations between components (Peldszus and Stede, 2013).
Hence, rec-ognizing arguments in textual documents includes several subtasks: (1) separating argumentative fromnon-argumentative text units, (2) identifying claims and premises, and (3) identifying relations betweenargument components.There exist a great demand for reliably annotated corpora including argument components as well asargumentative relations (Reed et al., 2008; Feng and Hirst, 2011) since they are required for supervisedmachine learning approaches for extracting arguments.
Previous argument annotated corpora are limitedto specific domains including legal documents (Mochales-Palau andMoens, 2008), newspapers and courtcases (Reed et al., 2008), product reviews (Villalba and Saint-Dizier, 2012) and online debates (Cabrioand Villata, 2012).
To the best of our knowledge, no work has been carried out to annotate argumentcomponents and argumentative relations in persuasive essays (section 2).
In addition, the reliability ofthe corpora is unknown, since only few of these works provide holistic inter-rater agreement scores andnone a detailed analysis and discussion of inter-rater agreement.In this work, we introduce a new argument annotation scheme and a corpus of persuasive essaysannotated with argument components and argumentative relations.
Our primary motivation is to createThis work is licensed under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/1501a corpus for argumentative writing support and to achieve a better understanding of how arguments arerepresented in texts.
In particular, the contributions of this paper are the following: First, we introducea novel annotation scheme for modeling arguments in texts.
Second, we present the findings of a pre-study and show how the findings influenced the definition of the annotation guidelines.
Third, we showthat the proposed annotation scheme and guidelines lead to substantial agreement in an annotation studywith three annotators.
Fourth, we provide the annotated corpus as freely available resource to encouragefuture research.12 Related Work2.1 Previous Argument Annotated CorporaCurrently, there exist only a few corpora that include argument annotations.
The work most similar toours with respect to the annotation scheme is Araucaria (Reed et al., 2008) since it also includes structuralinformation of arguments.
It is based on the Argumentation Markup Language (AML) that models argu-ment components in a XML-based tree structure.
Thus, it is possible to derive argumentative relationsbetween components though they are not explicitly included.
In contrast to our work, the corpus con-sists of several text genres including newspaper editorials, parliamentary records, judicial summaries anddiscussion boards.
In addition, the reliability of the annotations is unknown.
Nevertheless, researchersuse the corpus for different computational tasks, e.g.
separating argumentative from non-argumentativesentences (Mochales-Palau and Moens, 2011), identifying argument components (Rooney et al., 2012)and classifying argumentation schemes (Feng and Hirst, 2011).Mochales-Palau and Moens (2008) conduct an argument annotation study in legal cases of the Euro-pean Court of Human Rights (ECHR).
They experiment with a small corpus of 10 documents and obtainan inter-rater agreemnt of ?
= 0.58.
In a subsequent study, they elaborated their guidelines and obtainan inter-rater agreement of ?
= 0.75 on a corpus of 47 documents (Mochales-Palau and Moens, 2011).Unfortunately, the annotation scheme is not described in detail, but it can be seen from the examples thatit includes annotations for claims and supporting or refuting premises.
Unlike our work, the annotationscheme does not include argumentative relations.Cabrio and Villata (2012) annotate argumentative relations in debates gathered from Debatepedia.
In-stead of identifying argument components, they are interested in relations between arguments to identifywhich are the ones accepted by the community.
They apply textual entailment for identifying support andattack relations between arguments and utilize the resulting structure for identifying accepted arguments.Therefore, they annotate a pair of arguments as either entailment or not.
In contrast to our work, the ap-proach models relationships between pairs of arguments and does not consider components of individualarguments.
In addition, the work does not include an evaluation of the annotation?s reliability.Villalba and Saint-Dizier (2012) study argumentation annotation in a corpus of French and Englishproduct reviews.
Their goal is to identify arguments related to opinion expressions for recognizingreasons of customer opinions.
Their annotation scheme is limited to eight types of support (e.g.
jus-tification, elaboration, contrast).
Compared to our annotation scheme, the work distinguishes betweendifferent premise types.
However, the approach is tailored to product reviews, and the work does notprovide an inter-rater agreement study.In contrast to previous work, our annotation scheme includes argument components and argumentativerelations.
Both are crucial for argument recognition (Sergeant, 2013) and argumentative writing support.First, argumentative relations are essential for evaluating the quality of claims, since it is not possibleto examine how well a claim is justified without knowing which premises belong to a claim (Sampsonand Clark, 2006).
Second, methods that recognize if a statement supports or attacks a claim enablethe collection of additional evidence from other resources to recommend argument improvement.
Inaddition, we provide a detailed analysis of the inter-rater agreement and an analysis of disagreements.1http://www.ukp.tu-darmstadt.de/data/argumentation-mining15022.2 Persuasive EssaysPersuasive essays are extensively studied in the context of automated essay grading (Shermis andBurstein, 2013), which aims at automatically assigning a grade to a student?s essay by means of sev-eral features.
Since the argument structure is crucial for evaluating essay quality, Burstein et al.
(1998)propose an approach for identifying the argumentative discourse structure by means of discourse mark-ing.
They utilize a surface cue word and phrase lexicon to identify the boundaries of arguments at thesentence level in order to evaluate the content of individual arguments and to enrich their feature setfor determining precise grades.
Although the identification of argument boundaries is important for ar-gument recognition, our work allows a more fine-grained analysis of arguments since it also includesargument components and argumentative relations.Madnani et al.
(2012) studied persuasive essays for separating organizational elements from content.They argue that the detection of organizational elements is a step towards argument recognition andinferring the structure of persuasive discourse.
Further, they refer to organizational elements as claimand premise indicating word sequences which they call shell expressions.
They annotate 200 essays andestimate an inter-rater agreement of ?
= 0.699 and F1= 0.726 on a subset of 50 essays annotated bytwo annotators.
However, their annotation scheme is limited to shell expressions and compared to ourwork it does not include argument components or argumentative relations.Additional annotation studies on persuasive essays focus on identifying style criteria (Burstein andWolska, 2003), factual information (Beigman Klebanov and Higgins, 2012), holistic scores for argu-mentation quality (Attali et al., 2013) or metaphors (Beigman Klebanov and Flor, 2013).
We are notaware of an annotation study including argument components and argumentative relations in persuasiveessays.3 Annotation SchemeThe goal of our proposed annotation scheme is to model argument components as well as argumenta-tive relations that constitute the argumentative discourse structure in persuasive essays.
We propose anannotation scheme including three argument components and two argumentative relations (figure 1).Figure 1: Argument annotation scheme including argument components and argumentative relationsindicated by arrows below the components.3.1 Argument ComponentsPersuasive essays exhibit a common structure.
Usually, the introduction includes a major claim thatexpresses the author?s stance with respect to the topic.
The major claim is supported or attacked byarguments covering certain aspects in subsequent paragraphs.
Sentences (1?3) illustrate three examplesof major claims (the major claim is in bold face).2(1) ?I believe that we should attach more importance to cooperation during education.?
(2) ?From my viewpoint, people should perceive the value of museums in enhancing theirown knowledge.?
(3) ?Whatever the definition is, camping is an experience that should be tried by everyone.
?In the first example, the author explicitly states her stance towards cooperation during education.The major claims in the second and third example are taken from essays about museums and camping2We use examples from our corpus (5.1) without correcting grammatical or spelling errors.1503respectively.
In (1) and (2) a stance indicating expression (?I believe?
and ?Frommy viewpoint?)
denotesthe presence of the major claim.
Although, these indicators are frequent in persuasive essays, not everyessay contains an expression that denotes the major claim.
In those cases, the annotators are asked toselect the expression that is most representative with respect to the topic and author?s stance (cf.
(3)).The paragraphs between introduction and conclusion of persuasive essays contain the actual argumentswhich either support or attack the major claim.3Since argumentation has been a subject in philosophyand logic for a long time, there is a vast amount of argumentation theories which provide detailed defini-tions of argument components (Toulmin, 1958; Walton et al., 2008; Freemen, 2011).4All these theoriesgenerally agree that an argument consists of several components and that it includes a claim that is sup-ported or attacked by at least one premise.
Examples (4) and (5) illustrate two arguments containing aclaim (in bold face) and a premise (underlined).
(4) ?It is more convenient to learn about historical or art items online.
With Internet, peopledo not need to travel long distance to have a real look at a painting or a sculpture, whichprobably takes a lot of time and travel fee.?
(5) ?Locker checks should be made mandatory and done frequently because they assure se-curity in schools, makes students healthy, and will make students obey school policies.
?The claim is the central component of an argument.
It is a controversial statement that is either trueor false and should not be accepted by readers without additional support.
The premise underpins thevalidity of the claim.
It is a reason given by an author for persuading readers of the claim.
For instance, in(4) the author underpins his claim that Internet usage is convenient for exploring cultural items becauseof time and travel fee savings.
In this example, both components cover a complete sentence.
However,a sentence can also contain several argument components like in example (5).
Therefore, we do notpredefine the boundaries of the expression to be annotated (markable) in advance and annotate eachargument as a statement, which is a sequence of words that constitutes a grammatically correct sentence.To indicate if an argument supports or attacks a major claim, we add a stance attribute to the claimthat denotes the polarity of an argument with respect to the author?s stance.
This attribute can take thevalues for or against.
For example, the argument given in (4) refutes the major claim in example (2).Thus, the stance attribute of the claim in (4) is set to against in this example.3.2 Argumentative RelationsArgumentative relations model the discourse structure of arguments in persuasive essays.
They indicatewhich premises belong to a claim and constitute the structure of arguments.
We follow the approachproposed by Peldszus and Stede (2013) and define two directed relations between argument components:support and attack.5Both relations can hold between a premise and another premise, a premise and a(major-) claim, or a claim and a major claim (figure 1).
For instance, in example (4) the premise in thesecond sentence is a reason or justification for the claim in the first sentence and the claim in (4) attacksthe major claim of example (2).
Thus, an argumentative relation between two components indicatesthat the source component is a reason or a refutation for the target component.
The following exampleillustrates a more complex argument including one claim and three premises.
(6) ?Living and studying overseas is an irreplaceable experience when it comes to learnstanding on your own feet.
One who is living overseas will of course struggle with loneliness,living away from family and friends1but those difficulties will turn into valuable experiencesin the following steps of life2.
Moreover, the one will learn living without depending on anyoneelse3.
?Figure 2 illustrates the structure of this argument.
The claim is attacked by premise1, whereas premise2is a refutation of premise1.
The third premise is another reason that underpins the claim in this paragraph.3In some cases, the introduction or conclusion contains arguments as well, those are also annotated in the annotation study.4A review of argumentation theory is beyond the scope of this paper but a survey can be found in (Bentahar et al., 2010)5Peldszus and Stede also define a counter-attacking relation that is omitted in our scheme, since it can also be representedas a chain of attacking premises.1504This shows that it is not necessary to explicitly distinguish between supporting and attacking premises,since the relational structure and the type of argumentative relations implicitly denote the role of argu-ment components.
Additionally, argumentative relations enable the modeling of relationships betweenpairs of arguments on the macro level, e.g., by linking claims to the major claim.Figure 2: Argumentation structure of example (6)4 Pre-StudyWe conduct a preliminary study to define the annotation guidelines on a corpus of 14 short text snip-pets (1?2 sentences) that are either gathered from example essays or written by one of the authors.
Weask five non-trained annotators to classify each text as argumentative or non-argumentative.
If a text isclassified as argumentative, the annotators are asked to identify the claim and the premise.
In the firsttask, we obtain an inter-rater agreement of 58.6% and multi-?
= 0.171 (Fleiss, 1971)6.
We identified themarkables for measuring the inter-rater agreement of the second task by manually determining the state-ments in each of the 14 text snippets.
In total, we determined 32 statements and obtained an inter-rateragreement of 55.9% and multi-?
= 0.291.
These results indicate a low reliability of the annotations.
Inaddition, they emphasize the demand for a precisely defined argument annotation strategy.
In subsequentdiscussions, we discovered that the primary source of uncertainty is due to the missing context.
Sincethe text snippets are provided without any information about the topic, the annotators found it difficultto decide if a snippet includes an argument or not.
In addition, the annotators report that the author?sstance might facilitate the separation of argumentative from non-argumentative text and to determine thecomponents of arguments.According to these findings, we define a new top-down annotation process starting with the majorclaim and drill-down to the claims and premises.
Therefore, the annotators are aware of the author?sstance after identifying the major claim.
In addition, we ask the annotators to read the entire essay inorder to identify the topic before starting with the actual annotation task.
Although, this approach ismore time-consuming than a direct identification of argument components, we show in our annotationstudy (section 5) that it yields reliably annotated data.
In particular, the annotation guidelines consist ofthe following steps:1.
Topic and stance identification: Before starting with the annotation process, annotators identify thetopic and the author?s stance by reading the entire essay.2.
Annotation of argument components: In this step, the major claim is identified either in the intro-duction or in the conclusion of an essay.
Subsequently, annotators identify the claims and premisesin each paragraph.
We instruct the annotators to annotate each argument component as a state-ment covering an entire sentence or less.
We consolidate the annotations of all annotators beforecontinuing with the next step (section 5.4).3.
Annotation of argumentative relations: Finally, the claims and premises are linked within eachparagraph, and the claims are linked to the major claim either with a support or attack relation.6Although the coefficient was introduced by Fleiss as a generalization of Cohen?s ?
(Cohen, 1960), it is actually a gener-alization of Scott?s ?
(Scott, 1955), since it assumes a cumulative distribution of annotations by all annotators (Artstein andPoesio, 2008).
We follow the naming proposed by Artstein and Poesio and refer to the measure as multi-?.15055 Annotation StudyThree annotators participate in the study and annotate the essays independently using our described an-notation scheme.
We conduct several training sessions after each annotator has read the annotation guide-lines.
In these sessions, annotators collaboratively annotate 8 example essays for resolving disagreementsand obtaining a common understanding of the annotation guidelines.
For the actual annotation task, weused the brat annotation tool that is freely available.7It allows the annotation of text units with arbitraryboundaries as well as the linking of annotations for modeling argumentative discourse structures.5.1 DataOur corpus consists of 90 persuasive essays in English, which we selected from essayforum8.
Thisforum is an active community that provides writing feedback for different kinds of texts.
For instance,students post their essays for retrieving feedback about their writing skills while preparing themselvesfor standardized tests.
We randomly selected the essays from the writing feedback section of the forumand manually reviewed each essay.
Due to the non-argumentative writing style and significant languageflaws, we replaced 4 of them during a manual revision of the corpus.
The final corpus includes 1,673sentences with 34,917 tokens.
On average, each essay has 19 sentences and 388 tokens.5.2 Inter-rater AgreementWe evaluate the reliability of the argument component annotations using two strategies.
Since thereare no predefined markables in our study, annotators have to identify the boundaries of argument com-ponents.
We evaluate the annotations using Krippendorff?s ?U(Krippendorff, 2004).
It considers thedifferences in the markable boundaries of several annotators and thus allows for assessing the reliabilityof our annotated corpus.
In addition, we evaluate if a sentence contains an argument component of a par-ticular category using percentage agreement and two chance-corrected measures: multi-?
(Fleiss, 1971)and Krippendorff?s ?
(Krippendorff, 1980).
Since only 5.6% of the sentences contain several annota-tions of different argument components, evaluating the reliability at the sentence-level provides a goodapproximation of the inter-rater agreement.
In addition, it enables comparability with future argumentannotation studies that are conducted at the sentence-level.
The annotations yield the following classdistribution at the token-level: 3.5% major claim, 18.2% claim, 48.1% premise and 30.2% are not an-notated.
At the sentence-level 5.4% contain a major claim, 26.4% a claim, 61.1% a premise and 19.3%none annotation.
Thus, 12.2% of the sentences contain several annotations.% ?
?
?UMajorClaim .9827 .8334 .8365 .7726Claim .8690 .6590 .6655 .6033Premise .8618 .7075 .7131 .7594Table 1: Inter-rater agreement of argument component annotationsWe obtain the highest inter-rater agreement for the annotations of the major claim (table 1).
The inter-rater agreement of 98% and multi-?
= 0.833 indicates that the major claim can be reliably annotated inpersuasive essays.
In addition, there are few differences regarding the boundaries of major claims (?U=0.773).
Thus, annotators identify the sentence containing the major claim as well as the boundariesreliably.
We obtain an inter-rater agreement of multi-?
= 0.708 for premise annotations and multi-?
=0.66 for claims.
This is only slightly below the ?tentative conclusion boundary?
proposed by Carletta(1996) and Krippendorff (1980).
The unitized ?
of the major claim and the claim are lower than thesentence-level agreements (table 1).
Only the unitized ?
of the premise annotations is higher comparedto the sentence-level agreement.
Thus, the boundaries of premises are more precisely identified.
The jointunitized measure for all categories is ?U= 0.724.
Hence, we tentatively conclude that the annotation ofargument components in persuasive essays is reliably possible.7http://brat.nlplab.org8http://www.essayforum.com1506The agreement of the stance attribute is computed for each sentence.
We follow the same methodologyas for the computation of the argument component agreement, but treat each sentence containing a claimas either for or against according to the stance attribute (sentences not containing a claim are treated asnot annotated, but are included in the markables).
Thus, the upper boundary for the stance agreementconstitutes the agreement of the claim annotations.
The agreement of the stance attribute is only slightlybelow the agreement of the claim (86%; multi-?
= 0.643; ?
= 0.65).
Hence, the identification of eitherattacking or rebutting claims is feasible with high agreement.We determine the markables for evaluating the reliability of argumentative relations as the set of allpairs between argument components according to our annotation scheme.
So, the markables correspondto all relations that were possible during the annotation task.
In total, the markables include 5,137 pairsof which 25.5% are annotated as support relation and 3.1% as attack relations.
We obtain an inter-rateragreement above 0.8 for both support and attack relations (table 2) that is considered by Krippendorff(1980) as good reliability.
Therefore, we conclude that argumentative relations can be reliably annotatedin persuasive essays.% ?
?support .9267 .8105 .8120attack .9883 .8052 .8066Table 2: Inter-rater agreement of argumentative relation annotations5.3 Error AnalysisTo study the disagreements encountered during the annotation study, we created confusion probabilitymatrices (CPM) (Cinkova?
et al., 2012) for argument components and argumentative relations.
A CPMcontains the conditional probabilities that an annotator assigns a certain category (column) given that an-other annotator has chosen the category in the row for a specific item.
In contrast to traditional confusionmatrices, a CPM also enables the evaluation of confusions if more than two annotators are involved inan annotation study.Major Claim Claim Premise NoneMajor Claim .675 .132 .148 .045Claim .025 .552 .338 .086Premise .014 .163 .754 .069None .012 .123 .204 .660Table 3: Confusion probability matrix for argument component annotations (Category ?None?
indicatesargument components that are not identified by an annotator.
)The major disagreement is between claims and premises (table 3).
This could be expected since aclaim can also serve as premise for another claim, and it is difficult to distinguish these two concepts inthe presence of reasoning chains.
For instance, examples (7?9) constitute a reasoning chain in which (7)is supported by (8) and (8) is supported by (9):(7) ?Random locker checks should be made obligatory.?
(8) ?Locker checks help students stay both physically and mentally healthy.?
(9) ?It discourages students from bringing firearms and especially drugs.
?Considering this structure, (7) can be classified as claim.
However, if (7) is omitted, (8) becomes aclaim that is supported by (9).
Thus, the distinction between claims and premises depends not only on thecontext and the intention of the author but also on the structure of a specific argument.
Interestingly, thedistinction between major claims and claims is less critical.
Apparently, the identification of the majorclaim is easier since it is directly related to the author?s stance in contrast to more general claims thatcover a certain aspect with respect to the overall topic of the essay.The CPM for relations (table 4) reveals that the highest confusion is between support/attack relationsand none classified relations.
This could be due to the fact that it is difficult to identify the correct target ofa relation, especially in the presence of multiple claims or reasoning chains in a paragraph.
For instance,1507support attack nonesupport .750 .013 .238attack .104 .691 .205none .092 .001 .898Table 4: Confusion probability matrix for argumentative relation annotationsin the previous example an annotator could also link (9) directly to (7) or even to (7) and (8).
In bothcases, the argument would be still meaningful.
The distinction between support and attack relations doesnot reveal high disagreements.
To sum up, the error analysis reveals that the annotation of argumentativerelations yields more reliable results than that of argument components.
This could be due to the factthat in our studies, argument components are known before annotating the relations and thus the task iseasier.
Nevertheless, it could be interesting to annotate relations before classifying the types of argumentcomponents and to investigate if it positively influences the reliability of annotations.5.4 Creation of the Final CorpusThe creation of the final corpus consists of two independent tasks.
First, we consolidate the argumentcomponents before the annotation of argumentative relations.
So each annotator works on the sameargumentative components when annotating the relations.
Second, we consolidate the argumentativerelations to obtain the final corpus.
We follow a majority voting in both steps.
Thus, an annotation isadopted in the final corpus if at least two annotators agree on the category as well as on the boundaries.
Inapplying this strategy, we observed seven cases for argument components and ten cases for argumentativerelations that could not be solved by majority voting.
Those cases were discussed in the group of allannotators to reach an agreement.
Table 5 shows an overview of the final corpus.
It includes 90 majorALL avg.
per essay standard deviationSentence 1,673 19 7Tokens 34,917 388 124MajorClaim 90 1 0Claim 429 5 2Claim (for) 365 4 2Claim (against) 64 1 1Premises 1,033 11 6support 1,312 15 7attack 161 2 2Table 5: Statistics of the final corpusclaims (each essay contains exactly one), 429 claims and 1,033 premises.
This proportion betweenclaims and premises is common in argumentation and confirms the findings of Mochales-Palau andMoens (2011, p. 10) that claims are usually supported by several premises for ?ensuring a complete andstable standpoint?.6 Conclusion & Future WorkWe presented an annotation study of argument components and argumentative relations in persuasiveessays.
Previous argument annotation studies suffer from several limitations: Either they do not follow asystematic methodology and do not provide detailed inter-rater agreement studies or they do not includeannotations of argumentative relations.
Our annotation study is the first step towards computationalargument analysis in educational applications that provides both annotations of argumentative relationsand a comprehensive evaluation of the inter-rater agreement.
The results of our study indicate that theannotation guidelines yield substantial agreement.
The resulting corpus and the annotation guidelinesare freely available to encourage future research in argument recognition.In future work, we plan to utilize the created corpus as training data for supervised machine learningmethods in order to automatically identify argument components as well as argumentative relations.
Inaddition, there is a demand to scale the proposed annotation scheme to other genres e.g.
scientific articlesor newspapers and to create larger corpora.1508AcknowledgementsThis work has been supported by the Volkswagen Foundation as part of the Lichtenberg-ProfessorshipProgram under grant No.
I/82806.
We thank Piyush Paliwal and Krish Perumal for their valuable contri-butions and we thank the anonymous reviewers for their helpful comments.ReferencesRon Artstein and Massimo Poesio.
2008.
Inter-coder agreement for computational linguistics.
ComputationalLinguistics, 34(4):555?596.Yigal Attali, Will Lewis, and Michael Steier.
2013.
Scoring with the computer: Alternative procedures forimproving the reliability of holistic essay scoring.
Language Testing, 30(1):125?141.Beata Beigman Klebanov and Michael Flor.
2013.
Argumentation-Relevant Metaphors in Test-Taker Essays.
InProceedings of the First Workshop on Metaphor in NLP, pages 11?20, Atlanta, GA, USA.Beata Beigman Klebanov and Derrick Higgins.
2012.
Measuring the use of factual information in test-takeressays.
In Proceedings of the Seventh Workshop on Building Educational Applications Using NLP, pages 63?72, Montreal, Quebec, Canada.Jamal Bentahar, Bernard Moulin, and Micheline Be?langer.
2010.
A taxonomy of argumentation models used forknowledge representation.
Artificial Intelligence Review, 33(3):211?259.Jill Burstein and Magdalena Wolska.
2003.
Toward evaluation of writing style: finding overly repetitive word usein student essays.
In Proceedings of the tenth conference of European chapter of the Association for Computa-tional Linguistics, EACL ?03, pages 35?42, Budapest, Hungary.Jill Burstein, Karen Kukich, Susanne Wolff, Ji Lu, and Martin Chodorow.
1998.
Enriching Automated EssayScoring Using Discourse Marking.
In Proceedings of the Workshop on Discourse Relations and DiscourseMarkers, pages 15?21, Montreal, Quebec, Canada.Jodie A. Butler and M. Anne Britt.
2011.
Investigating Instruction for Improving Revision of ArgumentativeEssays.
Written Communication, 28(1):70?96.Elena Cabrio and Serena Villata.
2012.
Natural language arguments: A combined approach.
In Proceedings ofthe 20th European Conference on Artificial Intelligence, ECAI ?12, pages 205?210, Montpellier, France.Jean Carletta.
1996.
Assessing agreement on classification tasks: the kappa statistic.
Computational Linguistics,22(2):249?254.Silvie Cinkova?, Martin Holub, and Vincent Kr??z?.
2012.
Managing uncertainty in semantic tagging.
In Proceedingsof the 13th Conference of the European Chapter of the Association for Computational Linguistics, EACL ?12,pages 840?850, Avignon, France.Jacob Cohen.
1960.
A Coefficient of Agreement for Nominal Scales.
Educational and Psychological Measure-ment, 20(1):37?46.Vanessa Wei Feng and Graeme Hirst.
2011.
Classifying arguments by scheme.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT?11, pages 987?996, Portland, OR, USA.Joseph L. Fleiss.
1971.
Measuring nominal scale agreement among many raters.
Psychological Bulletin,76(5):378?382.James B. Freemen.
2011.
Argument Structure: Representation and Theory, volume 18 of Argumentation Library.Springer.Klaus Krippendorff.
1980.
Content Analysis: An Introduction to its Methodology.
Sage.Klaus Krippendorff.
2004.
Measuring the Reliability of Qualitative Text Analysis Data.
Quality & Quantity,38(6):787?800.Nitin Madnani, Michael Heilman, Joel Tetrault, and Martin Chodorow.
2012.
Identifying High-Level Organiza-tional Elements in Argumentative Discourse.
In Proceedings of the 2012 Conference of the North AmericanChapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ?12,pages 20?28, Montreal, Quebec, Canada.1509Raquel Mochales-Palau and Marie-Francine Moens.
2008.
Study on the Structure of Argumentation in CaseLaw.
In JURIX the twenty-first annual conference on legal knowledge and information systems, pages 11?20,Florence, Italy.Raquel Mochales-Palau and Marie-Francine Moens.
2011.
Argumentation mining.
Artificial Intelligence andLaw, 19(1):1?22.Andreas Peldszus and Manfred Stede.
2013.
From Argument Diagrams to Argumentation Mining in Texts: ASurvey.
International Journal of Cognitive Informatics and Natural Intelligence (IJCINI), 7(1):1?31.Chris Reed, Raquel Mochales-Palau, Glenn Rowe, and Marie-Francine Moens.
2008.
Language resources forstudying argument.
In Proceedings of the Sixth International Conference on Language Resources and Evalua-tion, LREC ?08, pages 2613?2618, Marrakech, Morocco.Niall Rooney, Hui Wang, and Fiona Browne.
2012.
Applying kernel methods to argumentation mining.
In Pro-ceedings of the Twenty-Fifth International Florida Artificial Intelligence Research Society Conference, FLAIRS?12, pages 272?275, Marco Island, FL, USA.Victor D. Sampson and Douglas B. Clark.
2006.
Assessment of argument in science education: A critical reviewof the literature.
In Proceedings of the 7th International Conference on Learning Sciences, ICLS ?06, pages655?661, Bloomington, IN, USA.William A. Scott.
1955.
Reliability of Content Analysis: The Case of Nominal Scale Coding.
Public OpinionQuarterly, 19(3):321?325.Alan Sergeant.
2013.
Automatic argumentation extraction.
In Proceedings of the 10th European Semantic WebConference, ESWC ?13, pages 656?660, Montpellier, France.Mark D. Shermis and Jill Burstein.
2013.
Handbook of Automated Essay Evaluation: Current Applications andNew Directions.
Routledge Chapman & Hall.Stephen E. Toulmin.
1958.
The uses of Argument.
Cambridge University Press.Maria Paz Garcia Villalba and Patrick Saint-Dizier.
2012.
Some facets of argumentmining for opinion analysis.
InProceeding of the 2012 conference on ComputationalModels of Argument, COMMA ?12, pages 23?34, Vienna,Austria.DouglasWalton, Chris Reed, and Fabrizio Macagno.
2008.
Argumentation Schemes.
Cambridge University Press.1510
