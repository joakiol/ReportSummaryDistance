The design of voice-driven interfacesAlexander I. RudnickySchool of Computer ScienceCarnegie Mellon UniversityPittsburgh, PA 15213AbstractThis paper presents some issues that arise in building voice-driven interfaces to complex applications and describes some ofthe approaches that we have developed for this purpose.
To testthese approaches, we have implemented a voice spreadsheet andhave begun observation ofusers interacting with it.IntroductionInteraction with a complex system imposes a substantialcognitive load on a human user.
Voice, being a naturalcommunication modality for humans, allows the user tospend less time on translating requests into keyboard actionsand more time on problem solving activities.
The benefitsof voice input will very likely be realized through such ob-servable consequences a  shorter completion times, fewererrors in finished work, and increased user satisfaction.
Thedesign of interactive systems that use continuous speech forcomplex problem-solving activity, however, is not well un-derstood.
This purpose of this paper is to describe an ap-proach to the problem of carrying out such designs.To study the variables that affect he behavior of a userperforming a task using voice, we must construct a suitableenvironment.
The choice of task is critical: simulations, forexample, while the allow the experimenter to control allaspects of the environment might not produce findings thatare easily Ixanslatable toother applications.
On the otherhand, some' 'real" tasks may not necessarily produce be-havior that is "interesting" from a spoken language systemperspective.
Simple data entry tasks might fall into thiscategory.
We believe that the spreadsheet environment hasthe desirable characteristics we are seeking in that it willpermit us to study a wide range of behavior.
We willdescribe it in greater detail below.
Before doing so, wewould like to review the issues that must be addressed in thecourse of building an interface.Speech Interface DesignDesigning a functioning spoken language system requiresattention to a number of factors.
This section reviews theseand describes some of the approaches we have taken.Language designLanguage design refers to the creation of a spoken lan-guage suitable for human interaction with an application.The goal is to create a habitable language that captures therange of expression to be expected from the typical user andmaps it into the capabiifies of the application.
From theperspective of the system we have been exploring, we canmake the further distinction between core language and tasklanguage.
Core language is a component that is not ex-pected to change from one circumstance to another and en-compasses certain common modes of expression.
A goodexample of such a core is the numbers.
There are manyways to express numeric information and in fact capturingthese leads to the construction of a fairly complex grammar.However, once created, it is clear that the number grammarfits not only into, say, the spreadsheet task but can be em-bedded in any number of tasks that require the specificationof numeric information.
A less general language, but onethat is still a core is the language that expresses the basiccommands available in a particular application.
Thus, acalculator core language might include arithmetic, assign-ment, and function statements.
Finally, we can talk aboutnon-core language that is task-specific.
An example of thisis the financial planning task described below, which bnngswith it an entire range of words (e.g., TAXES) that arespecific to that task only.Our approach to developing a task language has been tofirst study how humans peak in the task environment inquestion when given no constraint on how they express120Rudnickythemselves.
To do this, we have been conducting a series ofprotocol collection experiments in which users are asked toperform a task using only voice, but are given only minimalreslriction on what they may say.
This is meant o en-courage the participant to express intentions in the mostdirect fashion and not feel constrained by any perceivedlimitation in the capability of the interface (which in thecase of these experiments consists of a human operatortranslating the subject's verbal instructions into appropriatecommand sequences).
To this time, we have performed twoseries of experiments, one for a data-entry task embedded ina spreadsheet and the second for a "planning" task involv-ing the satisfaction of a series of constraints given a finan-cial summary.
The first study is described in more detail in(Rudnicky, et al, 1988)?
Figure 1 shows an excerpt fromone of the protocols generated in this experiment (a total oftwelve were collected, from different people)?We found that users, although they produce a seeminglybewildering variety of expression, tend to, as a whole, tospeak a language that is amenable to analysis and can bedescribed with sufficient precision to allow the constructionof a grammar.
Figure 2 show one of the categoriesrecovered through our analysis.
As can be noted, the gram-matical structures used are fairly straightforward.
We haveused these as a guide in implementing the language used inthe system to be described below?Figure 1: Sample protocolunder cable, enter fifteen dollars even \[*\]oka:y, go to the next screen \[*\]oka:y unde:r, movies .. in the entertainment, section, subsection.enter twenty-eight fifty \[*\]oka:y .. u:h in the.
FOOD subsection under HOSting \[*\]enter, hundred eighty dollars \[*\]on the line above that, enter a hundred seventy-five dollars \[*\]okay, go down to the oh waiton the CLOthing.
entry \[*\]ente:r, sum of.
eighty-five, eighty-nine, twenty-four \[*\]\[click\] okayand, under gasoline, enter twenty-two fifty \[*\]okay.
uh.
under child support slash day care \[*\]enter ..... uh FORTY times \[rustle\].
three: time four \[*\]okayu:m .. \[click\] okay, go down to the: uh, next screen \[*\]Figure 2: The DATA ENTRY categoryNumericsixty-five hundred ollarsAbsolute Locate and Enteruh go down to line six and enter four thousand five hundredRelative Locate and Enteron the next line enter seventy-five ninety-fourSymbofic Locate and Entergo to the cell for my salary and enter the amount six thousanfive hundred under credit card enter the amount zeroSymbolic Locate and Enter (no keyword)food two seventeen and eighty-five cents plus two hundred foAbsolute Locate and Enter (reverse order)enter six thousand five hundred in column b row 6Relative Locate and.
Enter (reverse order)enter seven hundred and forty-eight fifty-seven thereSymbolic Locate and Enter (reverse order)fifteen dollars under bank chargesFluent InteractionDefining a suitable spoken language is only one aspect ofbuilding a spoken-language system.
In addition, we need toprovide facilities in the interface that encourage f luentinteraction.
Fluency is achieved when a system creates forthe user the sense of communicating with a competent inter-locutor.
Some aspects of this competence are derived fromthe ability to model the progress of a dialog and building upa model of user characteristics.
Other aspects, and the onesof concern in the present case, have to do with providingfacilities that allow interaction to proceed smoothly.
Thereare three aspects to this: Giving the user sufficient feedbacksuch that there is a sense of control over the recognitionprocess, providing error repair facilities that allow naturalis-tic recovery from errors, and allowing the user to defmenew words and constructs for purposes of a task.Interaction control involves facilities uch as being ableto control whether the recognizer t ansmits nonsense to theapplication, providing feedback to the user to confirm thatactions have been taken, and allow the user to undo theeffects of unintended commands or misrecognized ut-terances.121RudnickyError repair provides the user with facilities for recover-ing from recognition errors.
Ideally this facility shouldfunction much like a human listener, providing the user witha variety of repair strategies.
At the same time, the usershould have access to an absolute override mechanism.
Wehave explored aspects of error correction based on repetition(Rudnicky and Hauptmann, 1989) and intend to explore anumber of strategies based on voice editing.
In our currentimplementation, users have only two ways of correcting anerror: repeating the utterance and hoping it is recognizedcorrectly, or manually editing a partially parsed version ofthe utterance.A new word mechanism allows the user to define newterms to be used in the course of the interaction.
There are anumber of compelling reasons for providing this facility.Humans find it much more natural to use symbolic labels torefer to objects in their workspace; there is even some quan-titative data that indicates that this is the case (Lerch, 1988).Certainly this was the case for the individuals in ourprotocol study.
An application such as the spreadsheet isnot tied to a particular domain and in fact needs to beprogrammed for each new task.
The ability to enter ap-propriate symbolic information is therefore critical to thefull usability of a voice spreadsheet.
A new word facility isuseful even for systems that do not necessarily deal withnew information, but wish to provide the user with theability to create synonyms for existing constructs.RecognitionAs necessary as a well-constructed language and a fluentinterface is the need for a high-performance recognition sys-tem.
For our present purposes, this means high accuracyand real-time.
High accuracy is necessary since without it,the user spends an unacceptable amount of time recoveringfrom recognition errors.
At some point, the cost of errorrecovery exceed that of using some other, presumably essdesirable but more reliable, input mode such as thekeyboard and causes the user to abandon voice input.
Real-time is essential because the user will be unwilling to waitfor speech to be understood, especially if a faster modalityis available (the keyboard, depending on the nature of theinput; for a highly optimized minimal-keystroke systemsuch as a spreadsheet, the margin is very thin; for involvingextended text strings, the margin is more forgiving butnevertheless there.
)Although SPHINX is a speaker-independent sys em, it isnevertheless a task-dependent o e, in that the phoneticmodels used in the system need to be retrained for each newtask.
In creating anumber of small tasks, we found that theproportion of models that can be reused from task to task isabout wo thirds.
Thus, if we were to take the triphonemodels trained for the Resource Management task and buildword models for the spreadsheet task, we would find thatonly about wo thirds of the necessary triphones were avail-able, and we would be forced to use monophone models forthe remainder of the vocabulary.
This may even understatethe lack of coverage, as relative word frequencies may besuch as to emphasize the triphone-poor words in the newvocabulary, leading to poorer than expected performance.To increase system accuracy, we undertook to recordseveral datasets that would provide suitable trainingmaterial for our needs.
To this date (February 1989) wehave collected approximately 4300 utterances, spanningthree domains: programmable calculator, spreadsheet com-mand seL and financial planning.
Tables 1 and 2 presentsome results we have obtained for recognition on two setsof utterances, using word-pair grammars.
The effects ofthree sets of training data re shown: Resource Management(RM), (nominally) 1000 calculator utterances, and(nominally) 2000 calculator, spreadsheet, and financialplanning sentences.
The first Table shows results for aspreadsheet language, the second table is for a languageaugmented by terms pecific to financial planning.
TheSpreadsheet dataset included 145 utterances with an averageutterance l ngth of 5.2 words.
The test-set perplexity israther high, 50.3, reflecting the relative lack of constraint inthe spreadsheet command language.
The Financial Plan-ning dataset included 96 utterances, with an average ut-terances of 2.8 words, comparatively short.
The test-setperplexity is 34.5 (since it emphasized the task-specificvocabulary and used a different, more constrainedgrammar).
Note that these results do not reflect raining onall the data we currently have available, only about half.We expect performance toimprove as models based on thefull dataset become available.A voice spreadsheet systemTo understand how the various factors affecting systemusability interact, we implemented a voice-based spread-sheet system and studied its behavior under different con-ditions.The Carnegie Mellon system uses a UNIX program "sc"as the back-end and the SPHINX recognition system as thefront-end.
To link the two, we built an interface, show inthe diagram in Figure 3.122RudnickyTable 1: Effect of training on SPREADSHEET(word-pair grammar, 119 word vocabulary)\[error rate\] Word % Sentence %RM 21.4 68.51000 utts 13.0 32.12000 utts 4.4 21.7Table 2: Effect of training on FINANCIAL PLANNING(word-pair grammar, 272 word vocabulary)\[error rate\] Word % Sentence %2000 utts 8.1 15.6Figure 3: Voice spreadsheet systemI RECOGNIZER IISPREADSHEET IINTERFACEMode Control IPreParserII II Utterancei ParserThe interface components include the following: a modecontrol that handles mode changes and controls feedbackfunctions; a preparser that both determines whether theinput is syntactically legal,parses core subvocabularies(such as numbers), and collapses ynonyms; an utteranceparser that maps the spoken command into the symbolicform required by the back-end.
There is also an edit bufferthat (optionally) allows the user to, manually edit the par-tially parsed input.
The mode control performs interactioncontrol functions.
The functionality of some of the com-ponents is minimal at present.
For example, the mode con-trol will eventually incorporate he new-word component ofthe system, while the manual editor will be supplementedwith or replaced by voice-driven error correction.A preliminary evaluation of usageTo gain some understanding of how humans might inter-act with a voice spreadsheet, we performed an experimentin which participants performed a financial data entry taskusing the system.
The tasks used were the same as those inthe protocol gathering experiment described earlier.
Theoperations that had to be performed to complete the taskincluded not only movement and numeric entry, but also theentry of arithmetic expressions, including addition and mul-tiplication.We have currently collected ata from three subjects.
Allthe participants had prior experience with spreadsheets,having used them in their own work.
Other than witnessingdemonstrations, one had used a speech recognition systembefore.
Three input modes were defined: keyboard only,voice with (keyboard) editing, and voice only.
In the firstcondition, users keyed in all information, using the spread-sheet as they might under conventional circumstances.
Inthe voice with editing condition, they spoke the commandsand had an opportunity oedit each preparser string before itwas acted upon.At the start of the session, the subjects were given ageneral description of the tasks they were to perform andasked to read a short summary of spreadsheet commands.They were then asked to do a short exercise involvingmovement, data entry, and arithmetic.
They did this usingthe keyboard, then repeated the same exercise using voice.The voice condition used for the exercise was the same asthe first one they would actually encounter.The subjects were given only minimal guidance as to theproper way to formulate commands and were encouraged tospeak in a manner they were comfortable.
Despite this, thesubjects had a tendency to adopt a "speaking to acomputer" speech style.
For example, one user persisted inentering numbers as digit strings, even when reminded thatthis was not necessary.123RudnickyThree different scripts were used, presented in the formof a sheaf of slips, each slip containing some informationcorresponding to a single spreadsheet cell.
This format al-lowed us to introduce situations in which the user had to"backtrack" and modify already entered information.
Eachscript contained an average of 38 data, six of these requiredthe use of arithmetic operations.
The orders of presentationfor scripts and conditions were counter-balanced accordingto a greco-latin design.The voice spreadsheet system was instrumented togenerate a variety of information: the command sequencesused and their corresponding spoken version (if applicable).Certain events were time-stamped, allowing us to recoverthe duration for different components of the interaction.Table 3 presents mean time-to-completion, thenumber ofseparate commands given by the three participants in eachof the conditions, and recognizer performance.
As can benoted from the table, keyboard input was fastest, with voice-only input the slowest.
The latter esult is distorted by thetime posted by one of the subjects.
This individual had acold and moreover persisted in certain behaviors that inter-acted unfavorably with the recognition system.
The lastcolumn lists utterance accuracy, the number of utterancesthat contain at least one word error.
The error rates arecomparable for the two voice conditions we examined and(as might be expected) are higher than those reported forrecordings of read speech (see Table 2).We are continuing to run subjects in this experiment andexpect to develop amore stable picture of the relationshipbetween the different conditions.Table 3: Evaluation resultstime commands SR errorkeyboard 12:39 187.3 - -voice & keybd 15:16 112.6 29%voice 19:21 134.0 25%ConclusionThis paper has presented a methodology for developingspoken language systems.
It's main points include:?
The observation of users performing the task byvoice in an unconstrained situation and thedevelopment ofa language model based on suchobservations.?
The design of an interface that includes variousfacilities that promote fluent interaction, errorrepair, and the capability to introduce new (task-specific) words.?
Task-specific training that allows the creating ofmodels phonetically appropriate for a task.An implementation f a voice spreadsheet based on theseprinciples was produced and it was shown that people canaccomplish useful work with it.
In our current work, we areextending our study of the voice spreadsheet system to en-compass additional metrics, more users, and different tasks(in particular planning).AcknowledgmentsA number of people have contributed tothe work described inthis paper.
Robert Brennan did the initial implementation f thevoice spreadsheet program, Joseph Polifroni conducted theprotocol studies, Janet Patterson and Robert Weide collected thea'aining data.The research described in this paper was sponsored by theDefense Advanced Research Projects Agency (DOD), Arpa OrderNo.
5167, monitored by SPAWAR under contract N00039-85-C-0163.
The views and conclusions contained in this documentare those of the authors and should not be interpreted asrepresent-ing the official policies, either expressed or implied, of the DefenseAdvanced Research Projects Agency or the US Government.ReferencesLerch, F.J., Mantei, M.M., & Olson, J.R. (1988).
Skilledfinancial planning: The cost of translating ideas intoaction (Tech.
Rep.).
Carnegie Mellon University:Center for the Management ofTechnology,Rudnicky, A. I. and Hauptmann, A.G. (March 1989).Errors, repetition, and contrastive stress emphasis nspeech recognition.
AAAI Spoken Language Sym-posium.Rudnicky, A.I., Polifroni, J.H., Thayer, E.H., and Brennan,R.A.
(1988).
Interactive problem solving withspeech.
Journal of the Acoustical Society of America,84, $213(A).124
