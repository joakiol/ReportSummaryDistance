INFORMATION EXTRACTION OVERVIEWMary Ellen OkurowskiDepartment of Defense.9800 Savage Road,Fort Meade, Md.
20755meokuro@ afterlife.ncsc.mil1.
DEF IN IT ION OF  INFORMATIONEXTRACTIONThe information explosion of the last decade has placedincreasing demands on processing and analyzing largevolumes of on-line data.
In response, the AdvancedResearch Projects Agency (ARPA) has been supportingresearch to develop a new technology called informationextraction.
Information extraction is a type of documentprocessing which capttnes and outputs factual informationcontained within a document.
Similar to an informationretrieval (lid system, an information extraction systemresponds to a user's information eed.
Whereas an IRsystem identifies a subset of documents in a large textdatabase or in a library scenario a subset of resources in alibrary, an information extraction system identifies a subsetof information within a document.
'ntis subset ofinformation is not necessarily a summary or gist of thecontents of the document.
Rather it corresponds to pre-defined genetic types of information of interest andrepresents specific instances found in the text.
For example,a user of a system may be interested in identifying anddatabasing information on all companies named within a setof documents, including companies not previously known tothe user.
An information extraction system can extract andoutput all of the occurrences of company names within atext with an accuracy of 75%.
Moreover, it is possible tospecify that the system only extract hose companies of acertain type, such as Japanese companies or companies inthe textile industry.Information extraction is also related to but distinct fromanother type of document processing, machine translation.Both technologies process texts in multiple languages.
Amachine translation system converts the entire text of asource document into a different target language; aninformation extraction system identifies and extractsrelevant information within a document in a particularlanguage.
There is no conversion from one language toanother.
An information extraction system in Japaneseoutputs informafiou in Japanese.Under ARPA sponsorship, research and development oninformation extraction systems has been oriented towardevaluation of systems engaged in a series of specificapplication tasks \[7\]\[8\].
The task has been template fillingfor populating a database.
For each task, a domain ofinterest (i.e.. topic, for example joint ventures ormicroelectronics chip fabrication) is selected.
Then thisdomain scope is narrowed by delineating the particulartypes of factual information of interest, specifically, thegeneric type of information to be extracted and the form ofthe output of that information.
This information needdefinition is called the template.
The design of a template,which corresponds to the design of the database to bepopulated, resembles any form that you may fdl out.
Forexample, certain fields in the template require normalizinginformation format (e.g.
dates) and others require selectingfrom a set list of choices (e.g hair color).
The templatedefinition is supplemented by a set of template fill ruleswhich document the conditions for extracting informationand formally serve as the extraction guidelines.
The fillrules may evolve as more and mtxe data is examined and theanalysts gain more understanding and control of theintricacies of an application.To date, information extraction has been performed almostentirely manually.
Even with careful template or databasedesign and expficit fill rules, manual information extractionis not at all error-free.
In carefully controlled experiments,Will found that analysts had an error rate of about 30% evenafter substantial training and several months of practice\[10\].
There was also little improvement after the initial fewmonths.
Some of these errors resulted from lapses ofattention caused by the tedium of performing a repetitivetask.
A substantial cause of this unexpected lack ofconsistency lies in the cognitive demands that informationextraction places on analysts.
A brief example demonstratesthis point.
Table 1 below identifies five types of informationto be extracted from one of the TIPSTER texts andcorrelates each type with a cognitive skill an analyst must117apply in extracting that informatiou.Within a document, ananalyst first locates a candidate ntity by identifying anddistinguishing a single entity from other entities, generallyon the basis of the entity name.
This candidate ntity mustbe kept distinct from other entities, but, in addition, otherreferences tothe same ntity using variations of the name oraliases must be merged so that there is only a single entity inthe extraction template.
Characteristics ofthe entity can alsobe assigned; the analyst can characterize the entity bynationality or classify the entity by type as one of a set ofchoices.
In an application where relationships amongentities are important, he analyst may need to link one entityto another.
All of these activities make for a complex set ofcognitive demands placed upon the analyst that often requiresubtle judgements obe made.Type of CognitiveInformation Skill ExampleName Identify Toyobo Co.Alias Merge ToyoboNationality Characterize JapaneseType Classify companyEntity-Rela- Link Toyobo Co.,fionship KanematsuCorp.Table 1: Cognitive Skills in Manual Extraction1.1.
Information Extraction System Architec-tureHow then does an information extraction system performthe kinds of complex processes required to identify andextract information?
In general terms, an informationextraction system is composed of a series of modules (orcomponents) that process text by applying rules \[2\].
Sinceinformation extraction involves elected pieces of data, anextraction system processes a text by creating computer datastructures for relevant sections of a text while at the sametime eliminating irrelevant sections from the processing.Although there will be variations among systems, generallythe functions for the following set of modules will beperformed somewhere in the processing.The initial module, a Text Zoner, takes a text as input andseparates the text into identifiable segments.
ThePreprocessor module then takes the segments that containtext (as opposed to formatted information) and, forindividual words within each sentence in those segments,accesses a lexicon (i.e.,dictionary) and associates propertieslike part-of-speech and meaning with each word.
To reducethe amount of information to be processed, the Filter modulesubseqnenfly eliminates entences that do not contain anyrelevant information for the application.The following modules, includin~ the optional Preparser andFragment Combiner modules, are geared toward analyzingthe grammatical relationships among the words to createdata structures from which sentence meaning can beinterpreted.
Because of the difficulty of analyzing theserelationships, more and more of the systems have developeda Preparser module here to identify sequences orcembinafions of words that form phrases.
Accessinggrammar rules, the next module, the Parser, analyzes thesequences ofwords and phrases and tries to understand thegrammatical relationships among the constituents.
Theoutput is either a successfully analyzed (parsed) sentencewith relationships among the sentence constituents labelledor a partially analyzed sentence with some constituentrelationships labelled and others constituents left asunattached fragments.
It is these unattached fragments thatbring the Fragment Combiner module into play to try to turna partially labelled sentence with fragments into acompletely abelled one.With the grammatical relationships identified, either a fullyanalyzed sentence or a partially analyzed sentencecontaining fragments is then processed by the SemanticInterpreter.
This module interprets the labelled grammaticalrelationships and generates a representation f the sentencemeaning in some form.
The next module, the LexicalDisambiguation module, replaces the representation of anyambiguous words within the sentence with a specific,unambiguous representation.The next step, the Coreference Resolution module, takes themeaning representation for the sentences within a text (frOththe Semantic Interpreter) and identifies which of the eventsor entities that occur in the data structures of the individualsentences actually refer to the same ntity or event in the realworld, a critical step to avoid database duplication.
The finalmodule is the Template CGenemtor in which informationoutput by the Semantic Interpreter and CoreferenceResolution modules is turned into template fills in thedesired format.1.2.
Other Tasks for Information ExtractionSystemsAn information extraction system ay also be configured toperform tasks other than template filling.
Such aconfiguration may involve use of some of the modules in afull system, use of modules in a different sequence thandescribed above, or modification of the modules themselves.118Examples of such tasks include text tagging and indicationsand warnings.
In a text tagging task, information of aparticular generic type is identified, such as persons,companies, or dates.
These types generally occur in a widerange of domains.
The information is identified in thePreparsing module and, for some types, must be processedby the Coreference Resolution module to eliminate multiplereferences.
The output of such a system might be used, forexample, to create indexes to documents for laterinformation retrieval applications.
Another example mightbe the display of the original text directly to an analyst, withrelevant types of information marked or hi,ghlighted insomeway.In an indications and warning task, an analyst is attemptingto identify information providing evidence that a particularevent or events have-occurred.
The system is fikely to beconfigured the same as for a template filling task, but withthe Template Generator Module modified.
Suchmedification can allow indications and warnin?
data to beoutput in whatever form is convenient for tim analystbecause he is using the system in some ways as asophisticated information retrieval mechanism.
He wants toidentify specific events of some generic type, but does notwant to database and track the information.
The dataextraction system is alerting the analyst o the presence ofcertain types of data.2.
T IPSTER TEXT PROGRAM GOALSAs information extraction technology has matured, thedesign of systems has responded to requirements f~  higheraccuracy, faster performance, broader coverage,extensibility within a domain, and portability to newdomains.
The Phase One extraction part of the TIPSTERText Program focused on further advancing informationextraction technology by setting two goals: (1) to developinformation extraction systems that include innovativealgorithms that improve overall system performance and (2)to demonstrate, through a task-oriented testbed appfication,the portability of these systems to new languages anddomains.Four contractor teams with different algorithmic approacheswere selected: Bolt Beranek & Newman, GE Corlxa'ateResearch and Development/Carnegie Mellon University/Martin Marietta Management and Data Systems.
NewMexico State University/Brandeis University, and theUniversity of Massachusetts/Hughes.
A template-fallingtask was defined for two domains and two languages \[5\].TheUniversity of Massachusetts/Hughes wa tasked to work inboth domains, and the other three teams were tasked to workin both domains and languages.
As is the case in any largescale research program in which a number of sites share thesame development data set and participate in regularlyscheduled evaluations, general trends in innovativealgorithm development appeared across systems.
Theseincluded statistical language modeling, the automatedacquisition of knowledge, generic tools and taggers, and theuse of finite-state pattern matching.These trends reflect he interrelatedness of the goals of theTIPSTER program, improvement of the technology withinthe context of a task.
The first goal, that of improving thetechnology, meant overcoming two central problems withwhich pre-TIPSTER information extraction systems hadbeen grappling.These were incomplete knowledge for textprocessing and inadequate text processing algorithms.Without adequam linguistic and domain knowledge, aninformation extraction system is brittle, and performance ispoor.
Without analysis of text processing algorithms andexperimentation with innovative extraction algorithms,there can be no serious re-engineering ofthe technology andsubsequent breakthroughs.
Under TIPSTER, systemdevelopers have increasingly adapted practical approachesin algorithm development, not simply by coping withdeficient information, but by overcoming the deficiency bycreatively redefining (1) which knowledge is acquired, (2)how that knowledge isacquired, and (3) how that knowledgeis applied.
They have continued the direction of redefininginformation extraction algorithms through redesign ofprocessing modules and their functions.
The second, goal,that of language and domain portability within the context ofa task, reeqnired understanding the task application itself andthe direct effect of this undexstanding upon the technologydevelopment.
The above-mentioned trends will be discussedin terms of these two goals.First, with the employment ofstatistical language modeling.we see an extension in the definition of knowledge, itsacquisition, and its application.
Knowledge sources aredefined to include not just linguistic and domain knowledge,but also statistical models of language as well.
Thisknowledge isacquired through training on archived texts ortemplates and applied to guide processing ou a new task,shoring up deficient linguistic and domain knowledge.
Forexample, the BBN PLUM system uses Markov modelingtechniques in its part-of-speech tagger, POST \[6\].
In thepreprocessing stage, POST assigns part-of-speech tags toknown words using probabilities derived from large corporaand probabilities for unknown or highly ambiguous wordsbased en word endings.
Later in template filling, BBNapplies a correctness probability model in order to estimatethe confidence for any given PLUM response.The model canalso be used to filter out hypothesized answers that fallbelow a given threshold cf rank and select among possible(slot) fillers.
That these types of knowledge were derivedautomatically from annotated text or templates i  an exampleof a shift in how knowledge can be acquired for information119extraction systems and a demonstration of the greater ease inporting to new domains and languages.The second trend, just touched upon in the discussion ofstatistical language modeling, is the automated acquisitionof knowledge.This includes both algorithms for automaticacquisition of knowledge from corpora or templates andautomated tools for acquiring knowledge from humanexperts.
The University of Massachusetts/Hughes sy tem,CIRCUS, for example, makes use of both forms ofautomated knowledge acquisition \[4\].
The systemdevelopment team focused their effort on automating theconstruction of domain-specific dictionaries and otherlanguage resources and thereby minimizing humanassistance incustomizing CIRCUS for specific applications.The dictionary construction tool, AutoSlog, is a goodillustration of this approach \[9\].Within CIRCUS, conceptnodes indicate potential extractable concepts.
AutoSlogproposes domain-specific concept node definitions to ahuman who selects good definitions, rejects bad ones, andthus creates the dictionary component of the CIRCUSsystem.
An initial experiment with two analysts, who hadfilled templates in the English joint venture domain,demonstrated that analysts can build effective dictionariesquickly for information extraction with the assistance ofAutoslog.
Learning algorithms, like those developed inPLUM and CIRCUS, signal new directions in automatingthe acquisition of knowledge.The two trends in new algorithms for information extractionprocessing reflect an evolving understanding of theinformation extraction task, in particular, the TIPSTER taskwith two different domains and languages.
Informationextraction can be viewed as an odd tug-of-war between twoopposing demands.
On the one hand, there are demands forgeneric systems created with general knowledge sourcesthat are broadly reusable across domains.
On the other hand,there is the reality of domain-specific requirements, iedultimately to the domain text, Reusability makesinformation extraction more feasible, tailoring makesinformation extraction more successfulThe need for generality has resulted in the third trend:reusable tools and taggers.
From the initial suite of templatefdling tools (that allow analysts performing manualextraction to easily organize information to fill in fields andthat can detect errors for analysts) to Tabula Rasa, NewMexico has driven tool design toward general, reusabletools for any demain in any language \[1\].
Tabula Rasaallows a developer to create acomplete t mplate-filling toolfor a new topic domain in an afternoon, once a templatedefinition is available.
In a similar way, annotated texttaggers represent a new understanding of the extractionprocess, perhaps affected to a large extent by the movementtoward object-oriented design.
Taggers are based on theassumption that there are types of information, dataelements, that occur across domains.
The New Mexico StateUniversity/Brandeis system DIDEROT uses finite-statefeature taggers to identify things such as names,organization names, place names, and dataexpressions.Taggers (al o known as specialists, recognizers,or concept aggers) identify information early on in theprocessing and label it.
This facilitates processing in laterstages by marking larger units fct processing, 'ntis ability oftaggers to be reusable gives systems aheadstart in a newapplication.The conflicting reality that a new application requiresspecific domain knowledge has resulted in the fourth trend:finite-state pattern matching.
Information extraction isviewed as a domain application, where content, specificallythe corpus, rather than linguistic knowledge sources, drivessystem development.
A number of different groups haveadopted this approach, including the TIPSTER site GE/CMU/MM.
Their SHOGUN system design illustrates thecentral role of pattern matching \[ 3 \].With domain/applicationpatterns central, the team essentially redefined theknowledge to be acquired as "domain knowledge" andacquired that type of knowledge by analysis of the &xnaincorpus.
To apply these patterns, they replaced the traditionalParsing module with a Pattern Matching module.
TheSHOGUN team's ccxnplementary focus on corpusknowledge acquisition and the relative ase of implementingfinite-state rules creates a reusable, simple approach for newdomains and languages.3.
OVERVIEW OF THE INFORMATIONEXTRACTION SECT IONThe hfformafion extraction section of this volume is acollection of papers that provide a broad perspective ofinformation extraction within the TIPSTER Text Program,Phase one.
This overview paper is followed by a paperdiscussing details of the extraction tasks "Tasks, Domains.and Languages for Information Extraction", a paperdescribing the selection of text corpora nd preparation offilled templates for the task, "Corpora nd Data Preparationfor Information Extraction", and a paper examining templatedesign issues, ''Template Design for InformationExtraction."
The next three papers help the reader interpretevaluation results.
In "TIPS'I~/MUC-5 InformationExtraction System Evaluation", the design and overallresults of the final evaluation of the TIPSTER Phase oneextraction systems are discussed.
The unexpected highersystem performance in Japanese is examined in the nextpaper.
"An Analysis of the Joint Venture Japanese TextPrototype and Its Effect on System Performance."
Theperformance of human analysts for the extraction task is120compared with that for machine systems in the third paper,"Comparing Human and Machine Performance for NaturalLanguage Information Ex~acfion".
Papers from each of theTIPSTER teams then provide a technical description of theirresearch and system development efforts: "BBN's PLUMProbabilistic Language Understanding System", "TheTIPSTER/SHOGUN Project", "CRL/Brandeis: TheDIDEROT System", and "UMasslHughes: Description ofthe CIRCUS System Used for TIPSTER Text" ("DictionaryConstruction by Domain Experts").1.2..4.5..7..9.10.R E F E R E N C E SCowie, Jim et ai., "CRL/Brandeis: The DIDEROT Sys-tem", In Proceedings offthe TIPSTER Text Program,Phase One, Morgan Kaufmann Publishers, San Mateo,Ca.,1994.Hobbs, Jerry, "The CGenede Information Extraction Sys-tem.
", In Proceedings offthe Fgth Message UnderstandingConference, (MUC-5).
Morgan Kaufmann Publishers, SanMateo, Ca., 1994.Jacobs, Paul S., et al,'The TIPSTER/SHOGUN Project",In Proceedings ofthe TIPSTER Text Program, Phase One,Morgan Kaufmann Publishers, San Mateo, Ca., 1994.Lehnert, Wendy, et ai.
"UMass/Hughes: Description ftheCIRCUS System Used for TIPSTER Text", In Proceed-ings of the TIPSTER Text Program, Phase One, MorganKaufmann Publishers, San Mateo, Ca., 1994.Onyshkevych, Boyan, et al, "TIPSTER Tasks, Domainsand Languages for Information Extraction", In Proceed-ings of the TIPSTER Text Program, Phase One, MorganKaufmann Publishers, San Matte.o, Ca., 1994.The Plum System Group, "BBN's PLUM ProbabilistieLanguage Understanding System", InProceedings oftheTIPSTER Text Program, Phase One, Morgan KaufmannPublishers, San Mateo, Ca., 1994.Proceedings ofthe Fourth Message Understanding Con-ference (MUC-4), Morgan Kaufmann Publishers, SanMateo, Ca., 1992.Proceedings ofthe F~h Message Understanding Confer-ence (MUC-5), Morgan Kaufmann Publishers, San Mateo,Ca., 1994.R.iloff, Ellen and Wendy G. Lehnert, "Dictionary Con-struetion by Domain Experts", InProceedings ofthe TIP-STER Text Program, Phase One, Morgan KaufmannPublishers, San Mateo, Ca., 1994.Will, Craig, "Comparing Human and Machine Perfor-mance", InProceedings ofthe TIPSTER Text Program,Phase One, Morgan Kaufmann Publishers, San Mateo,Ca., 1994.121
