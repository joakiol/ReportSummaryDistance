Statistical Sentence Condensation using Ambiguity Packing and StochasticDisambiguation Methods for Lexical-Functional GrammarStefan Riezler and Tracy H. King and Richard Crouch and Annie ZaenenPalo Alto Research Center, 3333 Coyote Hill Rd., Palo Alto, CA 94304{riezler|thking|crouch|zaenen}@parc.comAbstractWe present an application of ambiguity pack-ing and stochastic disambiguation techniquesfor Lexical-Functional Grammars (LFG) to thedomain of sentence condensation.
Our systemincorporates a linguistic parser/generator forLFG, a transfer component for parse reduc-tion operating on packed parse forests, and amaximum-entropy model for stochastic outputselection.
Furthermore, we propose the use ofstandard parser evaluation methods for auto-matically evaluating the summarization qual-ity of sentence condensation systems.
An ex-perimental evaluation of summarization qual-ity shows a close correlation between the au-tomatic parse-based evaluation and a manualevaluation of generated strings.
Overall sum-marization quality of the proposed system isstate-of-the-art, with guaranteed grammatical-ity of the system output due to the use of aconstraint-based parser/generator.1 IntroductionRecent work in statistical text summarization has put for-ward systems that do not merely extract and concate-nate sentences, but learn how to generate new sentencesfrom ?Summary, Text?
tuples.
Depending on the cho-sen task, such systems either generate single-sentence?headlines?
for multi-sentence text (Witbrock and Mittal,1999), or they provide a sentence condensation moduledesigned for combination with sentence extraction sys-tems (Knight and Marcu, 2000; Jing, 2000).
The chal-lenge for such systems is to guarantee the grammatical-ity and summarization quality of the system output, i.e.the generated sentences need to be syntactically well-formed and need to retain the most salient information ofthe original document.
For example a sentence extractionsystem might choose a sentence like:The UNIX operating system, with implementationsfrom Apples to Crays, appears to have the advan-tage.from a document, which could be condensed as:UNIX appears to have the advantage.In the approach of Witbrock and Mittal (1999), selec-tion and ordering of summary terms is based on bag-of-words models and n-grams.
Such models may wellproduce summaries that are indicative of the original?scontent; however, n-gram models seem to be insufficientto guarantee grammatical well-formedness of the systemoutput.
To overcome this problem, linguistic parsing andgeneration systems are used in the sentence condensationapproaches of Knight and Marcu (2000) and Jing (2000).In these approaches, decisions about which material to in-clude/delete in the sentence summaries do not rely on rel-ative frequency information on words, but rather on prob-ability models of subtree deletions that are learned froma corpus of parses for sentences and their summaries.A related area where linguistic parsing systemshave been applied successfully is sentence simplifica-tion.
Grefenstette (1998) presented a sentence reductionmethod that is based on finite-state technology for lin-guistic markup and selection, and Carroll et al (1998)present a sentence simplification system based on linguis-tic parsing.
However, these approaches do not employstatistical learning techniques to disambiguate simplifi-cation decisions, but iteratively apply symbolic reductionrules, producing a single output for each sentence.The goal of our approach is to apply the fine-grainedtools for stochastic Lexical-Functional Grammar (LFG)parsing to the task of sentence condensation.
The systempresented in this paper is conceptualized as a tool that canbe used as a standalone system for sentence condensationEdmonton, May-June 2003Main Papers , pp.
118-125Proceedings of HLT-NAACL 2003or simplification, or in combination with sentence extrac-tion for text-summarization beyond the sentence-level.
Inour system, to produce a condensed version of a sen-tence, the sentence is first parsed using a broad-coverageLFG grammar for English.
The parser produces a set offunctional (f )-structures for an ambiguous sentence in apacked format.
It presents these to the transfer compo-nent in a single packed data structure that represents inone place the substructures shared by several different in-terpretations.
The transfer component operates on thesepacked representations and modifies the parser output toproduce reduced f -structures.
The reduced f -structuresare then filtered by the generator to determine syntac-tic well-formedness.
A stochastic disambiguator using amaximum entropy model is trained on parsed and manu-ally disambiguated f -structures for pairs of sentences andtheir condensations.
Using the disambiguator, the stringgenerated from the most probable reduced f -structureproduced by the transfer system is chosen.
In contrastto the approaches mentioned above, our system guaran-tees the grammaticality of generated strings through theuse of a constraint-based generator for LFG which usesa slightly tighter version of the grammar than is used bythe parser.
As shown in an experimental evaluation, sum-marization quality of our system is high, due to the com-bination of linguistically fine-grained analysis tools andexpressive stochastic disambiguation models.A second goal of our approach is to apply the standardevaluation methods for parsing to an automatic evaluationof summarization quality for sentence condensation sys-tems.
Instead of deploying costly and non-reusable hu-man evaluation, or using automatic evaluation methodsbased on word error rate or n-gram match, summariza-tion quality can be evaluated directly and automaticallyby matching the reduced f -structures that were producedby the system against manually selected f -structures thatwere produced by parsing a set of manually created con-densations.
Such an evaluation only requires human laborfor the construction and manual structural disambigua-tion of a reusable gold standard test set.
Matching againstthe test set can be done automatically and rapidly, andis repeatable for development purposes and system com-parison.
As shown in an experimental evaluation, a closecorrespondence can be established for rankings producedby the f -structure based automatic evaluation and a man-ual evaluation of generated strings.2 Statistical Sentence Condensation in theLFG FrameworkIn this section, each of the system components will bedescribed in more detail.2.1 Parsing and TransferIn this project, a broad-coverage LFG gram-mar and parser for English was employed (seeRiezler et al (2002)).
The parser produces a set ofcontext-free constituent (c-)structures and associatedfunctional (f -)structures for each input sentence, repre-sented in packed form (see Maxwell and Kaplan (1989)).For sentence condensation we are only interested in thepredicate-argument structures encoded in f -structures.For example, Fig.
1 shows an f -structure manuallyselected out of the 40 f -structures for the sentence:A prototype is ready for testing, and Leary hopes toset requirements for a full system by the end of theyear.The transfer component for the sentence condensationsystem is based on a component previously used in a ma-chine translation system (see Frank (1999)).
It consistsof an ordered set of rules that rewrite one f -structureinto another.
Structures are broken down into flat listsof facts, and rules may add, delete, or change individ-ual facts.
Rules may be optional or obligatory.
In the caseof optional rules, transfer of a single input structure maylead to multiple alternate output structures.
The transfercomponent is designed to operate on packed input fromthe parser and can also produce packed representationsof the condensation alternatives, using methods adaptedfrom parse packing.1An example rule that (optionally) removes an adjunctis shown below:+adjunct(X,Y), in-set(Z,Y) ?=>delete-node(Z,r1), rule-trace(r1,del(Z,X)).This rule eliminates an adjunct, Z, by deleting the fact thatZ is contained within the set of adjuncts, Y, associatedwith the expression X.
The + before the adjunct(X,Y)fact marks this fact as one that needs to be present for therule to be applied, but which is left unaltered by the ruleapplication.
The in-set(Z,Y) fact is deleted.
Twonew facts are added.
delete-node(Z,r1) indicatesthat the structure rooted at node Z is to be deleted, andrule-trace(r1,del(Z,X)) adds a trace of thisrule to an accumulating history of rule applications.
Thishistory records the relation of transferred f -structures tothe original f -structure and is available for stochastic dis-ambiguation.Rules used in the sentence condensation transfer sys-tem include the optional deletion of all intersective ad-juncts (e.g., He slept in the bed.
can become He slept.,but He did not sleep.
cannot become He did sleep.
or He1The packing feature of the transfer component could notbe employed in these experiments since the current interfaceto the generator and stochastic disambiguation component stillrequires unpacked representations.
"A prototype is ready for testing , and Leary hopes to set requirements for a full system by the end of the year.
"?be<[93:ready]>[30:prototype]?PRED?prototype?PREDcountGRAINNTYPE?a?PREDDET?FORM a, DET?TYPE indefDETSPECCASE nom, NUM sg, PERS 330SUBJ?ready<[30:prototype]>?PRED [30:prototype]SUBJADEGREE positive, ATYPE predicative93XCOMP?for<[141:test]>?PRED?test?PREDgerundGRAINNTYPECASE acc, NUM sg, PERS 3, PFORM for, VTYPE main141OBJADV?TYPE vpadv, PSEM unspecified, PTYPE sem125ADJUNCTMOOD indicative, PERF ?_, PROG ?_, TENSE presTNS?ASPPASSIVE ?, STMT?TYPE decl, VTYPE copular[252:hope]>s73?hope<[235:Leary], [280:set]>?PRED?Leary?PREDproperGRAINnamePROPERNSEMNTYPEANIM +, CASE nom, NUM sg, PERS 3235SUBJ?set<[235:Leary], [336:requirement], [355:for]>?PRED [235:Leary]SUBJ?requirement?PREDunspecifiedGRAINNTYPECASE acc, NUM pl, PERS 3336OBJ?for<[391:system]>?PRED?system?PRED?full?PREDADEGREE positive, ADJUNCT?TYPE nominal, ATYPE attributive398ADJUNCTunspecifiedGRAINNTYPE?a?PREDDET?FORM a, DET?TYPE indefDETSPECCASE acc, NUM sg, PERS 3, PFORM for391OBJPSEM unspecified, PTYPE sem355OBL?by<[469:end]>?PRED?end?PRED?of<[519:year]>?PRED?year?PREDcountGRAINNTYPE?the?PREDDET?FORM the, DET?TYPE defDETSPECCASE acc, NUM sg, PERS 3, PFORM of519OBJADJUNCT?TYPE nominal, PSEM unspecified, PTYPE sem512ADJUNCTcountGRAINNTYPE?the?PREDDET?FORM the, DET?TYPE defDETSPECCASE acc, NUM sg, PERS 3, PFORM by469OBJADV?TYPE vpadv, PSEM unspecified, PTYPE sem451ADJUNCTPERF ?_, PROG ?_TNS?ASPINF?FORM to, PASSIVE ?, VTYPE main280XCOMPMOOD indicative, PERF ?_, PROG ?_, TENSE presTNS?ASPPASSIVE ?, STMT?TYPE decl, VTYPE main252COORD +_, COORD?FORM and, COORD?LEVEL ROOT197Figure 1: F -structure for non-condensed sentence.slept.
), the optional deletion of parts of coordinate struc-tures (e.g., They laughed and giggled.
can become Theygiggled.
), and certain simplifications (e.g.
It is clear thatthe earth is round.
can become The earth is round.
butIt seems that he is asleep.
cannot become He is asleep.
).For example, one possible post-transfer output of the sen-tence in Fig.
1 is shown in Fig.
2.2.2 Stochastic Selection and GenerationThe transfer rules are independent of the grammar and arenot constrained to preserve the grammaticality or well-formedness of the reduced f-structures.
Some of the re-duced structures therefore may not correspond to any En-glish sentence, and these are eliminated from future con-sideration by using the generator as a filter.
The filter-ing is done by running each transferred structure throughthe generator to see whether it produces an output string.If it does not, the structure is rejected.
For example, forthe f -structure in Fig.
1, the transfer system proposed32 possible reductions.
After filtering these structures bygeneration, 16 reduced f -structures comprising possible"A prototype is ready for testing.
"?be  <[93:ready]>[30:prototype]?PRED?prototype ?PREDcountGRAINNTYPE?a?PREDDET?FORM  a, DET?TYPE  indefDETSPECCASE nom, NUM sg, PERS 330SUBJ?ready<[30:prototype]>?PRED [30:prototype]SUBJADEGREE  positive , ATYPE  predicative93XCOMP?for<[141:test]>?PRED?test ?PREDgerundGRAINNTYPECASE acc, NUM sg, PERS 3, PFORM for, VTYPE main141OBJADV?TYPE  vpadv , PSEM  unspecified , PTYPE  sem125ADJUNCTMOOD	  indicative, PERF  ?_, PROG  ?_, TENSE presTNS?ASPPASSIVE ?, STMT?TYPE decl, VTYPE copular73Figure 2: Gold standard f -structure reduction.condensations of the input sentence survive.
The 16 well-formed structures correspond to the following strings thatwere outputted by the generator (note that a single struc-ture may correspond to more than one string and a givenstring may correspond to more than one structure):A prototype is ready.A prototype is ready for testing.Leary hopes to set requirements for a full system.A prototype is ready and Leary hopes to set require-ments for a full system.A prototype is ready for testing and Leary hopes toset requirements for a full system.Leary hopes to set requirements for a full system bythe end of the year.A prototype is ready and Leary hopes to set require-ments for a full system by the end of the year.A prototype is ready for testing and Leary hopes toset requirements for a full system by the end of theyear.In order to guarantee non-empty output for the over-all condensation system, the generation component hasto be fault-tolerant in cases where the transfer system op-erates on a fragmentary parse, or produces non-valid f -structures from valid input f -structures.
Robustness tech-niques currently applied to the generator include insertionand deletion of features in order to match invalid transfer-output to the grammar rules and lexicon.
Furthermore,repair mechanisms such as repairing subject-verb agree-ment from the subject?s number value are employed.
Asa last resort, a fall-back mechanism to the original un-condensed f -structure is used.
These techniques guaran-tee that a non-empty set of reduced f -structures yieldinggrammatical strings in generation is passed on to the nextsystem component.
In case of fragmentary input to thetransfer component, grammaticaliy of the output is guar-anteed for the separate fragments.
In other words, stringsgenerated from a reduced fragmentary f -structure will beas grammatical as the string that was fed into the parsingcomponent.After filtering by the generator, the remaining f -structures were weighted by the stochastic disambigua-tion component.
Similar to stochastic disambiguation forconstraint-based parsing (Johnson et al, 1999; Riezler etal., 2002), an exponential (a.k.a.
log-linear or maximum-entropy) probability model on transferred structures is es-timated from a set of training data.
The data for estima-tion consists of pairs of original sentences y and gold-standard summarized f -structures s which were manu-ally selected from the transfer output for each sentence.For training data {(sj , yj)}mj=1 and a set of possible sum-marized structures S(y) for each sentence y, the objectivewas to maximize a discriminative criterion, namely theconditional likelihood L(?)
of a summarized f -structuregiven the sentence.
Optimization of the function shownbelow was performed using a conjugate gradient opti-mization routine:L(?)
= logm?j=1e??f(sj)?s?S(yj)e?
?f(s).At the core of the exponential probability model is a vec-tor of property-functions f to be weighted by parameters?.
For the application of sentence condensation, 13,000property-functions of roughly three categories were used:?
Property-functions indicating attributes, attribute-combinations, or attribute-value pairs for f -structureattributes (?
1,000 properties)?
Property-functions indicating co-occurences of verbstems and subcategorization frames (?
12,000 prop-erties)?
Property-functions indicating transfer rules used toarrive at the reduced f - structures (?
60 properties).A trained probability model is applied to unseen databy selecting the most probable transferred f -structure,yielding the string generated from the selected struc-ture as the target condensation.
The transfered f -structurechosen for our current example is shown in Fig.
3.
"A prototype is ready.
"?be  <[93:ready]>[30:prototype]?PRED?prototype ?PREDcountGRAINNTYPE?a?PREDDET?FORM a, DET?TYPE indefDETSPECCASE nom, NUM  sg, PERS  330SUBJ?ready<[30:prototype]>?PRED [30:prototype]SUBJADEGREE positive , ATYPE predicative93XCOMPMOOD indicative, PERF ?_, PROG ?_, TENSE presTNS?ASPPASSIVE ?, STMT?TYPE decl, VTYPE copular73Figure 3: Transferred f -structure chosen by system.This structure was produced by the following set oftransfer rules, where var refers to the indices in the rep-resentation of the f -structure:rtrace(r13,keep(var(98),of)),rtrace(r161,keep(system,var(85))),rtrace(r1,del(var(91),set,by)),rtrace(r1,del(var(53),be,for)),rtrace(r20,equal(var(1),and)),rtrace(r20,equal(var(2),and)),rtrace(r2,del(var(1),hope,and)),rtrace(r22,delb(var(0),and)).These rules delete the adjunct of the first conjunct (fortesting), the adjunct of the second conjunct (by the endof the year), the rest of the second conjunct (Leary hopesto set requirements for a full system), and the conjunctionitself (and).3 A Method for Automatic Evaluation ofSentence SummarizationEvaluation of quality of sentence condensation systems,and of text summarization and simplification systems ingeneral, has mostly been conducted as intrinsic evalua-tion by human experts.
Recently, Papineni et al?s (2001)proposal for an automatic evaluation of translation sys-tems by measuring n-gram matches of the system out-put against reference examples has become popular forevaluation of summarization systems.
In addition, an au-tomatic evaluation method based on context-free deletiondecisions has been proposed by Jing (2000).
However, forsummarization systems that employ a linguistic parser asan integral system component, it is possible to employthe standard evaluation techniques for parsing directlyto an evaluation of summarization quality.
A parsing-based evaluation allows us to measure the semantic as-pects of summarization quality in terms of grammatical-functional information provided by deep parsers.
Further-more, human expertise was necessary only for the cre-ation of condensed versions of sentences, and for themanual disambiguation of parses assigned to those sen-tences.
Given such a gold standard, summarization qual-ity of a system can be evaluated automatically and re-peatedly by matching the structures of the system out-put against the gold standard structures.
The standardmetrics of precision, recall, and F-score from statisti-cal parsing can be used as evaluation metrics for mea-suring matching quality: Precision measures the numberof matching structural items in the parses of the sys-tem output and the gold standard, out of all structuralitems in the system output?s parse; recall measures thenumber of matches, out of all items in the gold stan-dard?s parse.
F-score balances precision and recall as(2 ?
precision ?
recall)/(precision + recall).For the sentence condensation system presented above,the structural items to be matched consist of rela-tion(predicate, argument) triples.
For example, the gold-standard f -structure of Fig.
2 corresponds to 23 depen-dency relations, the first 14 of which are shared with thereduced f -structure chosen by the stochastic disambigua-tion system:tense(be:0, pres),mood(be:0, indicative),subj(be:0, prototype:2),xcomp(be:0, ready:1),stmt_type(be:0, declarative),vtype(be:0, copular),subj(ready:1, prototype:2),adegree(ready:1, positive),atype(ready:1, predicative),det(prototype:2, a:7),num(prototype:2, sg),pers(prototype:2, 3),det_form(a:7, a),det_type(a:7, indef),adjunct(be:0, for:12),obj(for:12, test:14),adv_type(for:12, vpadv),psem(for:12, unspecified),ptype(for:12, semantic),num(test:14, sg),pers(test:14, 3),pform(test:14, for),vtype(test:14, main).Matching these f -structures against each other corre-sponds to a precision of 1, recall of .61, and F-score of.76.The fact that our method does not rely on a compar-ison of the characteristics of surface strings is a clearadvantage.
Such comparisons are bad at handling exam-ples which are similar in meaning but differ in word or-der or vary structurally, such as in passivization or nom-inalization.
Our method handles such examples straight-forwardly.
Fig.
4 shows two serialization variants of thecondensed sentence of Fig.
2.
The f -structures for theseexamples are similar to the f -structure assigned to thegold standard condensation shown in Fig.
2 (except forthe relations ADJUNT-TYPE:parenthetical ver-sus ADV-TYPE:vpadv versus ADV-TYPE:sadv).
Anevaluation of summarization quality that is based onmatching f -structures will treat these examples equally,whereas an evaluation based on string matching will yielddifferent quality scores for different serializations.
"A prototype, for testing, is ready.
"?be  <[221:ready]>[30:prototype]?PRED?prototype ?PREDcountGRAINNTYPE?a?PREDDET?FORM  a, DET?TYPE  indefDETSPECCASE nom, NUM sg, PERS 330SUBJ?ready<[30:prototype]>?PRED [30:prototype]SUBJADEGREE  positive , ATYPE  predicative221XCOMP?for<[117:test]>?PRED?test ?PREDgerundGRAINNTYPECASE acc, NUM sg, PERS 3, PFORM for, VTYPE main117OBJADJUNCT?TYPE  parenthetical , PSEM  unspecified , PTYPE  sem73ADJUNCTMOOD  indicative, PERF  ?_, PROG  ?_, TENSE presTNS?ASPPASSIVE ?, STMT?TYPE decl, VTYPE copular201"For testing, a prototype is ready.
"?be  <[177:ready]>[131:prototype]?PRED?prototype ?PREDcountGRAINNTYPE?a?PREDDET?FORM  a, DET?TYPE  indefDETSPECCASE nom, NUM sg, PERS 3131SUBJ?ready<[131:prototype]>?PRED [131:prototype]SUBJADEGREE  positive , ATYPE  predicative177XCOMP?for<[27:test]>?PRED?test ?PREDgerundGRAINNTYPECASE acc, NUM sg, PERS 3, PFORM for, VTYPE main27OBJADV?TYPE  sadv, PSEM  unspecified , PTYPE  sem11ADJUNCTMOOD  indicative, PERF  ?_, PROG  ?_, TENSE presTNS?ASPPASSIVE ?, STMT?TYPE decl, VTYPE copular83Figure 4: F -structure for word-order variants of goldstandard condensation.In the next section, we present experimental resultsof an automatic evaluation of the sentence condensationsystem described above.
These results show a close cor-respondence between automatically produced evaluationresults and human judgments on the quality of generatedcondensed strings.4 Experimental EvaluationThe sentences and condensations we used are taken fromdata for the experiments of Knight and Marcu (2000),which were provided to us by Daniel Marcu.
These dataconsist of pairs of sentences and their condensed versionsthat have been extracted from computer-news articles andabstracts of the Ziff-Davis corpus.
Out of these data, weparsed and manually disambiguated 500 sentence pairs.These included a set of 32 sentence pairs that were usedfor testing purposes in Knight and Marcu (2000).
In or-der to control for the small corpus size of this test set, werandomly extracted an additional 32 sentence pairs fromthe 500 parsed and disambiguated examples as a secondtest set.
The rest of the 436 randomly selected sentencepairs were used to create training data.
For the purposeof discriminative training, a gold-standard of transferredf -structures was created from the transfer output and themanually selected f -structures for the condensed strings.This was done automatically by selecting for each exam-ple the transferred f -structure that best matched the f -structure annotated for the condensed string.In the automatic evaluation of f -structure match, threedifferent system variants were compared.
Firstly, ran-domly chosen transferred f -structures were matchedagainst the manually selected f -structures for the man-ually created condensations.
This evaluation constitutesa lower bound on the F-score against the given goldstandard.
Secondly, matching results for transferred f -structures yielding the maximal F-score against the goldstandard were recorded, giving an upper bound for thesystem.
Thirdly, the performance of the stochastic modelwithin the range of the lower bound and upper bound wasmeasured by recording the F-score for the f -structure thatreceived highest probability according to the learned dis-tribution on transferred structures.In order to make our results comparable to the re-sults of Knight and Marcu (2000) and also to investigatethe correspondence between the automatic evaluation andhuman judgments, a manual evaluation of the strings gen-erated by these system variants was conducted.
Two hu-man judges were presented with the uncondensed sur-face string and five condensed strings that were displayedin random order for each test example.
The five con-densed strings presented to the human judges contained(1) strings generated from three randomly selected f -structures, (2) the strings generated from the f -structureswhich were selected by the stochastic model, and (3) themanually created gold-standard condensations extractedfrom the Ziff-Davis abstracts.
The judges were askedto judge summarization quality on a scale of increasingquality from 1 to 5 by assessing how well the generatedstrings retained the most salient information of the orig-inal uncondensed sentences.
Grammaticality of the sys-tem output is optimal and not reported separately.
Resultsfor both evaluations are reported for two test corpora of32 examples each.
Testset I contains the sentences andcondensations used to evaluate the system described inKnight and Marcu (2000).
Testset II consists of anotherrandomly extracted 32 sentence pairs from the same do-main, prepared in the same way.Fig.
5 shows evaluation results for a sentence conden-sation run that uses manually selected f -structures forthe original sentences as input to the transfer component.These results demonstrate how the condenstation systemperforms under the optimal circumstances when the parsechosen as input is the best available.
Fig.
6 applies thesame evaluation data and metrics to a sentence conden-sation experiment that performs transfer from packed f -structures, i.e.
transfer is performed on all parses for anambiguous sentence instead of on a single manually se-lected parse.
Alternatively, a single input parse could beselected by stochastic models such as the one describedin Riezler et al (2002).
A separate phase of parse disam-biguation, and perhaps the effects of any errors that thismight introduce, can be avoided by transferring from allparses for an ambiguous sentence.
This approach is com-putationally feasible, however, only if condensation canbe carried all the way through without unpacking.
Ourtechnology is not yet able to do this (in particular, as men-tioned earlier, we have not yet implemented a method forstochastic disambiguation on packed f -structures).
How-ever, we conducted a preliminary assessment of this pos-sibility by unpacking and enumerating the transferred f -structures.
For many sentences this resulted in more can-didates than we could operate on in the available timeand space, and in those cases we arbitrarily set a cut-offon the number of transferred f -structures we considered.Since transferred f -structures are produced according tothe number of rules applied to transfer them, in this setupthe transfer system produces smaller f -structures first,and cuts off less condensed output.
The result of this ex-periment, shown in Fig.
6, thus provides a conservativeestimate on the quality of the condensations we mightachieve with a full-packing implementation.In Figs.
5 and 6, the first row shows F-scores for arandom selection, the system selection, and the best pos-sible selection from the transfer output against the goldstandard.
The second rows show summarization qualityscores for generations from a random selection and thesystem selection, and for the human-written condensa-tion.
The third rows report compression ratios.
As cantestset I lowerboundsystemselectionupperboundF-score 58% 67.3% 77.2 %sum-quality 2.0 3.5 4.4compr.
50.2% 60.4% 54.9%testset II lowerboundsystemselectionupperboundF-score 59% 65.4% 83.3%sum-quality 2.1 3.4 4.6compr.
52.7% 65.9% 56.8%Figure 5: Sentence condensation from manually selectedf -structure for original uncondensed sentences.be seen from these tables, the ranking of system variantsproduced by the automatic and manual evaluation con-firm a close correlation between the automatic evaluationand human judgments.
A comparison of evaluation re-sults across colums, i.e.
across selection variants, showsthat a stochastic selection of transferred f -structures isindeed important.
Even if all f -structures are transferredfrom the same linguistically rich source, and all gener-ated strings are grammatical, a reduction in error rate ofaround 50% relative to the upper bound can be achievedby stochastic selection.
In contrast, a comparison be-tween transfer runs with and without perfect disambigua-tion of the original string shows a decrease of about 5% inF-score, and of only .1 points for summarization qualitywhen transferring from packed parses instead of from themanually selected parse.
This shows that it is more im-portant to learn what a good transferred f -structure lookslike than to have a perfect f -structure to transfer from.The compression rates associated with the systems thatused stochastic selection is around 60%, which is accept-able, but not as aggressive as human-written condensa-tions.
Note that in our current implementation, in somecases the transfer component was unable to operate onthe packed representation.
In those cases a parse was cho-sen at random as a conservative estimate of transfer fromall parses.
This fall-back mechanism explains the drop inF-score for the upper bound in comparing Figs.
5 and 6.5 ConclusionWe presented an approach to sentence condensationthat employs linguistically rich LFG grammars in aparsing/generation-based stochastic sentence condensa-tion system.
Fine-grained dependency structures are out-put by the parser, then modified by a highly expressivetransfer system, and filtered by a constraint-based gener-ator.
Stochastic selection of generation-filtered reducedstructures uses a powerful Maximum-Entropy model.As shown in an experimental evaluation, summarizationtestset I lowerboundsystemselectionupperboundF-score 55.2% 63.0% 72.0%sum-quality 2.1 3.4 4.4compres.
46.5% 61.6% 54.9%testset II lowerboundsystemselectionupperboundF-score 54% 59.7% 76.0 %sum-quality 1.9 3.3 4.6compres.
50.9% 60.0% 56.8%Figure 6: Sentence condensation from packed f -structures for original uncondensed sentences.quality of the system output is state-of-the-art, and gram-maticality of condensed strings is guaranteed.
Robustnesstechniques for parsing and generation guarantee that thesystem produces non-empty output for unseen input.Overall, the summarization quality achieved byour system is similar to the results reported inKnight and Marcu (2000).
This might seem disappoint-ing considering the more complex machinery employedin our approach.
It has to be noted that these re-sults are partially due to the somewhat artificial na-ture of the data that were used in the experiments ofKnight and Marcu (2000) and therefore in our experi-ments: The human-written condensations in the data setextracted from the Ziff-Davis corpus show the sameword order as the original sentences and do not exhibitany structural modification that are common in human-written summaries.
For example, humans tend to makeuse of structural modifications such as nominalizationand verb alternations such as active/passive or transi-tive/intransitive alternations in condensation.
Such alter-nations can easily be expressed in our transfer-basedapproach, whereas they impose severe problems to ap-proaches that operate only on phrase structure trees.
Inthe given test set, however, the condensation task re-stricted to the operation of deletion.
A creation of addi-tional condensations for the original sentences other thanthe condensed versions extracted from the human-writtenabstracts would provide a more diverse test set, and fur-thermore make it possible to match each system outputagainst any number of independent human-written con-densations of the same original sentence.
This idea ofcomputing matching scores to multiple reference exam-ples was proposed by Alshawi et al (1998), and later byPapineni et al (2001) for evaluation of machine transla-tion systems.
Similar to these proposals, an evaluationof condensation quality could consider multiple referencecondensations and record the matching score against themost similar example.Another desideratum for future work is to carrycondensation all the way through without unpackingat any stage.
Work on employing packing techniquesnot only for parsing and transfer, but also for genera-tion and stochastic selection is currently underway (seeGeman and Johnson (2002)).
This will eventually lead toa system whose components work on packed represen-tations of all or n-best solutions, but completely avoidcostly unpacking of representations.ReferencesHiyan Alshawi, Srinivas Bangalore, and Shona Douglas.1998.
Automatic acquisition of hierarchical trans-duction models for machine translation.
In Proceed-ings of the 36th Annual Meeting of the Association forComputational Linguistics (ACL?98), Montreal, Que-bec, Canada.John Carroll, Guido Minnen, Yvonne Canning, SiobhanDevlin, and John Tait.
1998.
Practical simplificationof english newspaper text to assist aphasic readers.
InProceedings of the AAAI Workshop on Integrating Arti-ficial Intelligence and Assistive Technology, Madison,WI.Anette Frank.
1999.
From parallel grammar develop-ment towards machine translation.
In Proceedings ofthe MT Summit VII.
MT in the Great Translation Era,pages 134?142.
Kent Ridge Digital Labs, Singapore.Stuart Geman and Mark Johnson.
2002.
Dynamicprogramming for parsing and estimation of stochas-tic unification-based grammars.
In Proceedings of the40th Annual Meeting of the Association for Computa-tional Linguistics (ACL?02), Philadelphia, PA.Gregory Grefenstette.
1998.
Producing intelligent tele-graphic text reduction to provide an audio scanningservice for the blind.
In Proceedings of the AAAISpring Workshop on Intelligent Text Summarization,Stanford, CA.Hongyan Jing.
2000.
Sentence reduction for automatictext summarization.
In Proceedings of the 6th AppliedNatural Language Processing Conference (ANLP?00),Seattle, WA.Mark Johnson, Stuart Geman, Stephen Canon, Zhiyi Chi,and Stefan Riezler.
1999.
Estimators for stochastic?unification-based?
grammars.
In Proceedings of the37th Annual Meeting of the Association for Computa-tional Linguistics (ACL?99), College Park, MD.Kevin Knight and Daniel Marcu.
2000.
Statistics-basedsummarization?step one: Sentence compression.
InProceedings of the 17th National Conference on Arti-ficial Intelligence (AAAI-2000), Austin, TX.John Maxwell and Ronald M. Kaplan.
1989.
Anoverview of disjunctive constraint satisfaction.
In Pro-ceedings of the International Workshop on ParsingTechnologies, Pittsburgh, PA.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2001.
Bleu: a method for automatic evalua-tion of machine translation.
Technical Report IBM Re-search Division Technical Report, RC22176 (W0190-022), Yorktown Heights, N.Y.Stefan Riezler, Tracy H. King, Ronald M. Kaplan,Richard Crouch, John T. Maxwell, and Mark John-son.
2002.
Parsing the Wall Street Journal using aLexical-Functional Grammar and discriminative esti-mation techniques.
In Proceedings of the 40th AnnualMeeting of the Association for Computational Linguis-tics (ACL?02), Philadelphia, PA.Michael J. Witbrock and Vibhu O. Mittal.
1999.
Ultra-summarization: A statistical approach to generatinghighly condensed non-extractive summaries.
In Pro-ceedings of the 22nd ACM SIGIR Conference on Re-search and Development in Information Retrieval,Berkeley, CA.
