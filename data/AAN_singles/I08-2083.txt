Analysis of Intention in Dialogues Using Category Trees andIts Application to Advertisement RecommendationHung-Chi Huang Ming-Shun Lin Hsin-Hsi ChenDepartment of Computer Science and Information EngineeringNational Taiwan UniversityTaipei, Taiwan{hchuang, mslin}@nlg.csie.ntu.edu.tw; hhchen@ntu.edu.twAbstractWe propose an intention analysis systemfor instant messaging applications.
Thesystem adopts Yahoo!
directory as categorytrees, and classifies each dialogue into oneof the categories of the directory.
Twoweighting schemes in information retrieval,i.e., tf and tf-idf, are considered in our ex-periments.
In addition, we also expandYahoo!
directory with the accompanyingHTML files and explore different featuressuch as nouns, verbs, hypernym, hyponym,etc.
Experiments show that category treesexpanded with snippets together with nounfeatures under tf scheme achieves a best F-score, 0.86, when only 37.46% of utter-ances are processed on the average.
Thismethodology is employed to recommendadvertisements relevant to the dialogue.1 IntroductionInstant messaging applications such as GoogleTalk, Microsoft MSN Messenger, Yahoo Messen-ger, QQ, and Skype are very popular.
In theblooming instant messaging markets, sponsor linksand advertisements support the free service.
Fig-ure 1 shows an example of sponsor links in instantmessage applications.
They are usually randomlyproposed and may be irrelevant to the utterance.Thus, they may not attract users?
attentions andhave no effects on advertisements.
This paperdeals with the analysis of intention in the dialoguesand the recommendation of relevant sponsor linksin an ongoing conversation.In the related works, Fain and Pedersen (2006)survey sponsored search, suggesting the impor-tance of matching advertising content to user inten-tions.
How to match advertiser content to userqueries is an important issue.
Yih et al (2006)aimed at extracting advertisement keywords fromthe intention on the web pages.
However, theseworks did not address the issues in dialogues.Figure 1.
A Sponsor Link in an IM ApplicationIn conventional dialogue management, how toextract semantic concepts, identify the speech act,and formulate the dialogue state transitions are im-portant tasks.
The domain shift is a challengingproblem (Lin and Chen, 2004).
In instant messageapplications, more challenging issues have to betackled.
Firstly, the discussing topics of dialoguesare diverse.
Secondly, the conversation may bequite short, so that the system should be responsiveinstantly when detecting the intention.
Thirdly, theutterance itself can be purely free-style and far be-yond the formal grammar.
That is, self-defined orsymbolic languages may be used in the dialogues.The following shows some example utterances.James: dud, i c ur foto on Kelly?s door~  ^^||Antony: Orz?.kill me pls.
><An intention detecting system has to extract wordsfrom incomplete sentences in dialogues.
Fourthly,the system should consider up-to-date terms, in-stead of just looking up conventional dictionaries.625Capturing the intention in a dialogue and rec-ommending the advertisements before its endingare the goal of this approach.
This paper is organ-ized as follows.
Section 2 shows an overview ofthe system architecture.
Section 3 discusses thecategory trees and the weighting functions foridentifying the intention.
Section 4 presents theexperimental results comparing with different usesof the category trees and word features.
Section 5concludes and remarks.2 System OverviewFain and Pedersen (2006) outlined six basicelements for sponsored search.
They are shown asfollows:(1) advertiser-provided content,(2) advertiser-provided bids,(3) ensuring that advertiser content is relevantto the target keyword,(4) matching advertiser content to user queries,(5) displaying advertiser content in some rankorder,(6) gathering data, metering clicks and charg-ing advertisers.In instant messaging applications, a dialogue iscomposed of several utterances issuing by at leasttwo users.
They are different from sponsoredsearch in that advertiser content is matched to userutterances instead of user queries.
While readingusers?
conversation, an intention detecting systemrecommends suitable advertiser information at asuitable time.
The time of the recommendationand the effect of advertisement have a strong rela-tionship.
The earlier the correct recommendationis, the larger the effect is.However, time and accuracy are trade-off.
Atthe earlier stages of a dialogue, the system mayhave deficient information to predict suitable ad-vertisement.
Thus, a false advertisement may beproposed.
On the other hand, the system may haveenough information at the later stages.
However,users may complete their talk at any time in thiscase, so the advertisement effect may be lowered.Figure 2 shows architecture of our system.
Ineach round of the conversation, we retrieve an ut-terance from a given instant message application.Then, we parse the utterance and try to predict in-tention of the dialogue based on current and previ-ous utterances, and consult the advertisement data-bases that provide sponsor links accordingly.
Ifthe information in the utterances is enough for pre-diction, then several candidates are proposed.
Fi-nally, based on predefined criteria, the best candi-date is selected and proposed to the IM applicationas the sponsor link in Figure 1.In the following sections, we will explore whento make sure the intention of a dialogue with con-fidence and to propose suitable recommendations.In addition, we will also discuss what word fea-tures (called cue words hereafter) in the utterancesare useful for the intention determination.
We as-sume sponsor links or advertisements are adjuncton the given category trees.Figure 2.
System Architecture3 Categorization of Dialogues3.1 Web Directory Used for CategorizationWe employ Yahoo!
directory1 to assign a dialogueor part of a dialogue in category representing itsintention.
Every word in dialogues is classified bythe directory.
For example, by searching the termBMW, we could retrieve the category path:>Business and Economy>?
Makers>VehiclesEach category contains subcategories, which in-clude some subsidiary categories.
Therefore, wecould take the directory as a hierarchical tree forsearching the intention.
Moreover, each node ofthe tree has attributes from the node itself and itsancestors.
Our idea is to summarize all intentionsfrom words in a dialog, and then conclude the in-tention accordingly.The nodes sometimes are overlapped, that is,one node could be found in more than one path.For example, the car maker BMW has at least twoother nodes:1 http://dir.yahoo.com626>Regional>Countries>Germany>Business andEconomy>?>Dealers>Recreation>Automotive>?Clubs and Organi-zations>BMW Car Club of AmericaThe categories of BMW include Business andEconomy, Regional, and Recreation.
This demon-strates the nature of the word ambiguity, and ischallenging when the system identifies the inten-tion embedded in the dialogs.The downloaded Yahoo!
directory brings upHTML documents with three basic elements, in-cluding titles, links and snippet as shown in Figure3.
The following takes the three elements from apopular site as an example.Title: The White HouseLink: www.WhiteHouse.govSnippet: Features statements and press releasesby President George W. Bush as well?Figure 3.
Sample HTML in Yahoo!
Directory TreeWe will explore different ways to use the threeelements during intention identification.
Table 1shows different models and total nodes.
YahooOand YahooX are two extreme cases.
The formeremploys the original category tree, while the latterexpands the category tree with titles, links andsnippets.
Thus, the former contains 7,839 nodesand the latter 78,519 nodes.Table 1.
Tree Expansion ScenariosTable 2.
Examples of Expanded NodesTable 2 lists some examples to demonstrate thecategory tree expansion.
Some words inside thethree elements rarely appear in dictionaries or en-cyclopedias.
Thus, we can summarize these treesand build a new dictionary with definitions.
Forexample, we could find the hottest web sites You-Tube and MySpace, and even the most popularChinese gamble game, Mahjong.3.2 Scoring Functions for CategorizationGiven a fragment F of a dialogue, which is com-posed of utterances reading up to now, Formula 1determines the intention IINT of F by counting totalscores of cue words w in F contributing to I.??
?=FwINT IwbwtfI ),()(maxarg  (1)where tf(w) is term frequency of w in F, and b(w,I)is 1 when w is in the paths corresponding to theintention IINT; b(w,I) is 0 otherwise.Formula 2 considers the discriminating capabil-ity of each cue word.
It is similar to tf-idf schemein information retrieval.???
?=FwIINT IwbwdfNwtfI ),()(log)(maxargwhere N is total number of intention(2)s, and df(w) ismarized in Table 3 withexplanation and examples.total intentions in which w appears.3.3 Features of Cue WordsThe features of possible cue words including nouns,verbs, stop-words, word length, hypernym, hypo-nym, and synonym are sum627Table 3.
Cue Words ExploredNouns and verbs form skeletons of concepts areimportant cues for similarity measures (Chen et al,2003), so that they are considered as features in ourmodel.
Word length is used to filter out some un-necessary words because the shorter the word is,the less meaningful the word might be.
Here wepostulate that instant messaging users are not will-ing to type long terms if unnecessary.In this paper, we regard words in an utterance ofdialogues as query terms.
Rosie et al (2006)showed that query substitution may be helpful toretrieve more meaningful results.
Here, we usehypernym, hyponym and synonym specified inWordNet (Fellbaum, 1998) to expand the originalutterance.3.4 Candidate RecommendationThe proposed model also provides the ability toshow the related advertisements after intention isconfirmed.
As discussed, for each of node in thecategory tree, there is an accompanying HTML fileto show some related web sites and even sponsors.Therefore, we can also use the category tree to putsponsor links into the HTML files, and just fetchthe sponsor links from the HTML file on the nodeto the customers.The algorithm to select the suitable candidatescould be shortly described as the Longest PathFirst.
Once we select the category of the intention,the nodes appearing in the chosen category willthen be collected into a set.
We will check thelongest path and provide the sponsor links from thenode.4 Experimental Results4.1 Performance of Different ModelsTo prepare the experimental materials, we col-lected 50 real dialogs from end-users, and askedannotators to tag the 50 dialogs with 14 given Ya-hoo!
directory categories shown in Table 4.
Aver-age number of sentences is 12.38 and averagenumber of words is 56.04 in each dialog.
Wecompare the system output with the answer keys,and compute precision, recall, and F-score for eachmethod.Table 4.
Category AbbreviationTable 5 shows the performance of using For-mula 1 (i.e., tf scheme).
This model is a combina-tion of a scenario shown in Table 1 and featuresshown in Table 3.
For example, the YahooS-nounmatches cue words of POS noun from utterances tothe category tree expanded with snippets.
WL de-notes word length.
Only cue words of length ?WL is considered.
C denotes the number of dia-logues correctly analyzed.
NA denotes the numberof undecidable dialogues.
P, R and F denote preci-sion, recall and F-score.Table 5 shows that YahooS with noun featuresachieves a best performance.
Noun feature worksimpressively well with the orders, YahooS, Ya-hooT, YahooX, and YahooL.
That meets our ex-pectation because the information from snippets iswell enough and does not bring in noise as the Ya-hooX.
YahooT, however, has good but insufficientinformation, while YahooL is only suitable for dia-logs directly related to links.Moreover, the experimental results show thatverb is not a good feature no matter whether thecategory tree is expanded or not.
Although someverbs can explicitly point out the intention of dia-logues, such as buy, sell, purchase, etc, the lack ofverbs in Yahoo!
directory makes the verb featuresless useful in the experiments.
Table 6 shows theperformance of using Formula 2 (i.e., tf-idfscheme).
The original category tree with hyponymachieves the best performance, i.e., 56.56%.
How-ever, it cannot compete with most of models with tfscheme.628Table 5.
Performance of Models with tf SchemeTable 6.
Performance of Models with tf-idf Scheme4.2 Hit SpeedBesides precision, recall and F-score, we are al-so interested if the system captures the intention ofthe dialogue at better timing.
We define one moremetric called hit speed in Formula (3).
It repre-sents how fast the sponsor links could be correctlysuggested during the progress of conversations.For each utterance in a dialogue, we mark either Xor a predicted category.
Here X denotes undecid-able.Assume we have a dialogue of 7 utterances andconsider the following scenario.
At first, our sys-tem could not propose any candidates in the firsttwo utterances.
Then, it decides the third and thefourth utterances are talking about Business andEconomy.
Finally, it determines the intention ofthe dialogue is Computer and Internet after readingthe next three utterances.
In this example, we getan answer string, XXBBCCC, based on the nota-tions shown in Table 4.
If the intention annotatedby human is Computer and Internet, then the sys-tem starts proposing a correct intention from the 5thutterance.
In other words, the information in thefirst 4 utterances is not sufficient to make any deci-sion or make wrong decision.Let CPL be the length of correct postfix of ananswer string, e.g., 3, and N be total utterances in adialogue, e.g., 7.
HitSpeed is defined as follows.NCPLHitSpeed =  (3)In this case, the hit speed of intention identificationis 3/7.
Intuitively, our goal is to get the hit speedas high as possible.
The sooner we get the correctintention, the better the recommendation effect is.The average hit speed is defined by Formulas (4)and (5).
The former considers only the correct dia-logues, and the latter considers all the dialogues.Let M and N denote total dialogues and total cor-rect dialogues, respectively.NHitSpeedvgHitSpeedMi i?
== 1A  (4)MHitSpeedvgHitSpeedMi i?
== 1A  (5)Figure 4.
Average Hit Speed by Formula (4)Figure 5.
Average Hit Speed by Formula (5)629Figures 4 and 5 demonstrate average hit speedscomputed by Formulas (4) and (5), respectively.Here four leading models shown in Table 5 areadopted and nouns are regarded as cue words.
Fig-ure 4 shows that the average hit speed in correctlyanswered dialogues is around 70%.
It means thesemodels can correctly answer the intention when adialogue still has 70% to go in the set of correctlyanswered dialogs.Figure 5 considers all the dialogues no matterwhether their intentions are identified correctly ornot.
We can still capture the intention with the hitspeed 62.54% for the best model, i.e., YahooS-noun.5 Concluding RemarksThis paper captures intention in dialogues of in-stant messaging applications.
A web directorysuch as Yahoo!
directory is considered as a cate-gory tree.
Two schemes, revised tf and tf-idf, areemployed to classify the utterances in dialogues.The experiments show that the tf scheme using thecategory tree expanded with snippets together withnoun features achieves the best F-score, 0.86.
Thehit speed evaluation tells us the system can startmaking good decision when near only 37.46% oftotal utterances are processed.
In other words, therecommended advertisements can be placed to at-tract users?
attentions in the rest 62.54% of totalutterances.Though the best model in the experiments is touse nouns as features, we note that another impor-tant language feature, verbs, is not helpful due tothe characteristic of the category tree we adopted,that is, the absence of verbs in Yahoo!
directory.
Ifsome other data sources can provide the cue infor-mation, verbs may be taken as useful features toboost the performance.In this paper, only one intention is assigned tothe utterances.
However, there may be many par-ticipants involving in a conversation, and the topicsthey are talking about in a dialogue may be morethan one.
For example, two couples are discussinga trip schedule together.
After the topic is finished,they may continue the conversation for selection ofhotels and buying funds separately in the same in-stant messaging dialogue.
In this case, our systemonly decides the intention is Recreation, but notincluding Business & Economy.Long time delay of response is another interest-ing topic for instant messaging dialogues.
Some-times one participant could send a message, buthave to wait for minutes or even hours to get re-sponse.
Because the receiver might be absent,busy or just off-line, the system should be capableof waiting such a long time delay before a com-plete dialogue is finished in practical applications.Opinion mining is also important to the pro-posed model.
For example, dialogue participantsmay talk about buying digital cameras, and one ofthem has negative opinions on some products.
Insuch a case, an intelligent recommendation systemshould not promote such products.
Once opinionextraction is introduced to intention analysis sys-tems, customers can get not only the conversation-related, but also personally preferred sponsor links.AcknowledgmentsResearch of this paper was partially supported byExcellent Research Projects of National TaiwanUniversity, under the contract 95R0062-AE00-02.ReferencesH.H.
Chen, J.J. Kuo, S.J.
Huang, C.J.
Lin and H.C.Wung.
2003.
A Summarization System for ChineseNews from Multiple Sources.
Journal of AmericanSociety for Information Science and Technology,54(13), pp.
1224-1236.D.
C. Fain and J. O. Pedersen.
2006.
Sponsored Search:A Brief History.
Bulletin of the American Societyfor Information Science and Technology, January.C.
Fellbaum.
1998.
WordNet: An Electronic LexicalDatabase.
The MIT Press.R.
Jones, B. Rey, O. Madani, and W. Greiner.
2006.Generating Query Substitutions.
In Proceedings ofthe 15th International Conference on World WideWeb, 2006, pp.
387-396.K.K.
Lin and H.H.
Chen.
2004.
Extracting DomainKnowledge for Dialogue Model Adaptation.
InProceedings of 5th International Conference on In-telligent Text Processing and Computational Lin-guistics, Lecture Notes in Computer Science,LNCS 2945, Springer-Verlag, pp.
70-78.W.
Yih, J. Goodman, and V. R. Carvalho.
2006.
FindingAdvertising Keywords on Web Pages.
In Proceed-ings of the 15th International Conference on WorldWide Web, pp.
213-222.630
