Dialogue Management for an Automated Multilingual Call CenterHilda Hardy, Tomek Strzalkowski and Min WuInstitute for Informatics, Logics and Security StudiesUniversity at Albany, Albany, NY  12222andThe AMITIES Consortium1hardyh,tomek,minwu@cs.albany.edu121 The AMITIES consortium members include University of Sheffield, CNRS-LIMSI, Duke University, SUNY Albany,VESCYS, and Viel et Cie.IntroductionThe AMITI?S project (Automated Multilingual Interac-tion with Information and Services) has been estab-lished under joint funding from the EuropeanCommission?s 5th Framework Program and the U.S.DARPA to develop the next generation of empirically-induced human-computer interaction capabilities inspoken language.
One of the central goals of this projectis to create a dialogue management system capable ofengaging the user in human-like conversation within aspecific domain.
The domain we selected is telephone-based customer service where the system has access toan appropriate information database to support callers?information needs.
Our objective is to automate at leastsome of the more mundane human functions in cus-tomer service call centers, but do so in a manner that ismaximally responsive to the customer.
This practicallyeliminates all prompt or menu based voice responsesystems used at commercial call centers today.Exploiting the corpus of hundreds (and soon to bethousands) of annotated dialogues, recorded at Euro-pean financial call centers, we have developed a calltriaging prototype for financial services domain.
Thisdemonstrator system handles the initial portion of a cus-tomer call: identifying the customer (based on a samplecustomer database) and determining the reason the cus-tomer is calling (based on a subset of transactions han-dled at the call center).
Our approach to dialogue actsemantics allows for mixed system/customer initiativeand spontaneous conversation to occur.
We are cur-rently extending this prototype beyond its triage role tonegotiate and execute the transactions requested by thecustomers, ranging from simple address changes tomore complex account payment transactions.The aim of AMITIES project is to build a large-scale, empirical system using data-driven design, de-rived from actual and purposeful (i.e., not acted or con-trived) human-to-human dialogues.
This proves to be alengthy and complicated process due to a variety of le-gal constraints we need to overcome to obtain real datain sufficient quantities.
We have devoted a considerableeffort to this issue, which only now is beginning tobring results.
The prototype described here has not beenempirically validated yet.Dialogue with Information and ServicesThe key concept underlying AMITIES dialogue man-ager is the notion of dialogue with data.
The prevalenttype of dialogue in a call center environment is informa-tion seeking/information access, which displays specificcharacteristics that can be exploited in the design of anautomated system.
In a human-operated call center, anoperator mediates between the caller and a variety ofdata sources: information about customers, products,regulations, etc.
Much of this data is in a structuredform, usually a relational database (accounts informa-tion), while some may remain in an unstructured form(e.g., text memos, flyers, regulations manuals.)
The ob-jective of an automated call center is to obtain a natu-rally interactive mediation, between the caller and theinformation which is as close to a human-human dia-logue as possible.This automated call center scenario applies to manycustomer service situations, including the following:?
Financial services (AMITIES primary domain)?
Product support?
Travel reservationswhere the objective is to locate, insert or update a single(or several) data object in a structured data base.
At amore abstract level, the call center of the type describedhere can be characterized as an Interaction with Struc-tured Data (ISD).
ISD consists of the following compo-nents:1.
Data structure, which defines the set of basic enti-ties (accounts, spare parts, flights) and their attrib-utes (account number, part size, destination city,etc.)
as well as methods for identifying referencesto these attributes in user statements.2.
List of basic transactions supported by the service(account payment, address change, locating aflight) along with methods to detect references tothese transactions.3.
Dialogue models for handling various conversa-tional situations in human-like fashion (e.g., re-sponding to requests, emotions, indecision) andconsistent with the character of the service (polite,helpful, caring).4.
Optional dialogue meta-strategy as required to ad-dress privacy and security concerns (e.g., positivecaller identification must precede exchange of anysensitive information.
)The components 1, 2 and 4 can be built using limitedamount of static data about the service and are to a largedegree domain-independent or domain-adaptable.
Thesecomponents are sufficient to design basic mixed-initiative dialogue capabilities, as explained further inthe following section.
Although the dialogue may notfeel very ?natural?
it will be quite efficient, giving theuser a broad initiative to conduct it as they wish.
Dia-logue models (component #3) are required to create anillusion of naturalness and these can only be derivedfrom large corpora of actual call center conversations.Large corpora of real conversations are also needed todevelop speech and prosody models.We have built a prototype caller triaging dialoguemanagement which has been incorporated in the firstAMITIES demonstrator.
The system is based on GalaxyCommunicator architecture (Seneff et al, 1998) in astandard configuration shown in Figure 1.
The DM canhandle dialogues in 3 European languages, and can ad-ditionally switch from one language to another in mid-conversation.Figure 1.
AMITI?S System Architecture3 Dialogue Manager/Frame RouterIn this section we explain some key principles of de-signing an interactive dialogue with Structured Data(ISD).
The overall strategy is to locate an item or itemsin the database that meet a number of specific condi-tions, for example, the most convenient flight, thecaller?s bank account, etc.
This overall objective is bro-ken down into a set of sub-goals some of which mayneed to be satisfied to achieve the objective.
The role ofISD dialogue is to chart a path through the sub-goals insuch as way that:1. the objective is achieved2.
any partial constraints on the order or selection ofthe sub-goals are met, and3.
the most efficient route is chosen.The dialogue manager identifies the goal of the con-versation and performs interactions to achieve that goal.The overall mechanism works by filling attribute valuesin frames representing transactions and the sub-goals.Spontaneous conversation works in this environment,because values may be filled in any order, or severalvalues may be supplied in one turn.
As attribute valuesin the frames are filled, the need for dialogue decreases.The system sets key milestones or goals to bereached by gathering sufficient information from thecustomer, but these milestones may be approached by avariety of different paths.
If the customer?s last name ismisrecognized, for example, or if there are multipledatabase records returned, the system will ask for a dif-ferent attribute, such as the address or postal code.
Re-prompts are used when necessary, but no more thanonce for any single attribute.
The process continues un-til a unique (e.g., bank account) or best (e.g., a flight)record is identified.
Thus the dialogue system has flexi-bility to deal with user input arriving in any order orform and the input that is not completely captured,without getting stuck on any single attribute.
The pathsto the key milestones, and even the order of the mile-stones, may be seen as a series of hidden transitions.This means exact progression of the dialogue is neverpre-set or can be known in advance ?
a major advanceover system-driven prompts.In order to keep the dialogue manager language- anddomain-independent, mechanisms were created to storethe language-specific and task-specific information inseparate modules, to be loaded as needed.
These areillustrated in Figure 2.Figure 2.
Dialogue Manager StructureHubSpeechRecognitionDialogueManagerDatabaseServerText-to-speechConversionNat?l LanguageUnderstandingFrenchGermanTelephonyServerResponseGenerationFrenchGermanCustomerDatabaseEngl.
(English)Keyword profilePrompt sequenceTask2 ?Response DecisionUser IDFrame RouterInput:from NLU via HubTask Properties FileUser Properties FileTask IDFrame RouterTask1account_number,fname, lname,post_code, ?In Fig.
2, the transaction identification module(TaskID Frame Router) matches the incoming user ut-terances to identify which transaction is being invoked.If multiple transactions are matched, their representa-tions (frames) are ranked in the likelihood order.
Eachframe consists of a keyword profile (a list of salientterms derived from human-human dialogues) and aprompt sequence, which is a list of attributes whosevalues must be collected in order to complete the trans-action.
This prompt sequence is passed to the DialogueManager which then handles it in a manner consistentwith the adopted dialogue model.
Task identificationsucceeds even with high speech recognition error rates,provided the keywords are detected accurately.2 Ties (ornear ties) are resolved through clarification dialogue bydetermining the value of some contrasting attribute,which is dynamically selected for each situation.
TheUser ID Frame Router operates analogously, with eachframe representing a different user (customer).Two simple dialogues with AMITIES are below:AMITI?S:  Amiti?s, how can I help, je vous ecoute, was kann ichf?r Sie tun?USER: Bonjour, je viens de quitter la r?gion parisienne, je voulaisvous donner l'adresse de ma nouvelle r?sidence.AMITI?S:  Pouvez-vous me donner votre nom et votre anciencode postal, s'il vous pla?t?USER: madame Cecile Brun, j'habite ?
Paris dans le ll?me codepostal 38200AMITI?S:  Merci, Mme Brun.
Alors je vais avoir quelquesrenseignements ?
vous demander pour mettre ?
jourvotre adresse.AMITI?S:  Amiti?s, how can I help, je vous ecoute, was kann ichf?r Sie tun?USER: Hi, I'm Margaret Roberts, post code CO4 3SQAMITI?S:  How can I help, Mrs. Roberts?USER: Can I get my card replaced?
My old one was stolen.AMITI?S:  Thank you, Mrs. Roberts.
I'll just ask you some ques-tions and have a new card sent to you.4Dialogue AnnotationsWorking with the real call center dialogues requiredus to develop a new method for dialogue annotation.The DAMSL functional annotation scheme had to bemodified and further augmented with semantic annota-tion.
To do so, we have created dialogue act taxonomyappropriate for ISD dialogues.
To capture the semantics,we used a domain-independent framework populatedwith domain-specific lists.
Furthermore, to facilitatespeedy annotation, we have designed a new flexible,annotation tool, XDMLTool, and annotated severalhundred French and English dialogues using it.In order to annotate semantic information withXDMLTool, the user makes entries for a particular turnor turn segment in a semantic table on the user interface.Transactions such as MAKEPYMNT or CHANGEADDR areselected and their attributes appear in combo-boxes onthe GUI.
If necessary, the user may type in new labels.To fill a value for an attribute, text from the displayeddialogue may be copied into a table cell.2 While different combinations of keywords may invoke atransaction frame, this process is robust because the selectionof transactions is limited to those known to the system.For example, the following exchange, part of aVERIFYID transaction, would be labeled with the attrib-utes Name and PostCode.
The values John Smith andAB1 1CD would be tagged for the answer.A: Your full name and postcode please?C: Yes it's err John Smith AB1 1CDThe new annotation scheme reflects our approach todialogue design ?
we hope it will help us to automati-cally derive appropriate dialogue strategies for novelISD situations, and beyond.3AcknowledgmentsThis paper is based on work supported in part by theEuropean Commission under the 5th FrameworkIST/HLT Programme, and by the U.S. Defense Ad-vanced Research Projects Agency.ReferencesJ.
Allen and M. Core.
1997.
Draft of DAMSL: DialogAct Markup in Several Layers.
http://www.cs.
roches-ter.
edu/research/cisd/resources/damsl/.J.
Allen, et al 1995.
The TRAINS Project:  A CaseStudy in Building a Conversational Planning Agent.Journal of Experimental and Theoretical AI, 7, 7?48.AMITI?S, http://www.dcs.shef.ac.uk/nlp/amities/.A.
Bagga, T. Strzalkowski and G. B.
Wise.
2000.
PartsID : A Dialogue-Based System for Finding Parts forMedical Systems.
In Proc.
of ANLP-2000.J.
Chu-Carroll and B. Carpenter.
1999.
Vector-BasedNatural Language Call Routing.
ComputationalLinguistics, 25 (3): 361?388.DARPA, http://www.darpa.mil/iao/Communicator.htm.L.
Devillers, S. Rosset, H. Maynard and L. Lamel.
May2002.
Annotations for Dynamic Diagnosis of theDialog State.
In Proc.
of LREC, Las Palmas.R.
Gaizauskas et al 1996.
GATE :  An Environment toSupport Research and Development in NaturalLanguage Engineering.
In Proc.
Of 8th IEEE Int.Conf.
on Tools with AI, Toulouse, France.A.
L. Gorin, G. Riccardi and J. Wright.
1997.
HowMay I Help You?
Speech Comm., 23 (1/2): 113?127.S.
Seneff, E et al  1998.
Galaxy-II:  A Reference Ar-chitecture for Conversational System Development.In Proc.
of ICSLP 98, Sydney, Australia.3 Some preliminary results of dialogue structure analysis areavailable but we lack space to include them in this note.
