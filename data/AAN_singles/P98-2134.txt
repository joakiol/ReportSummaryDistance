Bitext Correspondences through Rich Mark-upRaque l  Mar t lnezDepartamento de Sis.
Inform?ticos y ProgramaciSn, Facultad de Matem?ticasUniversidad Complutense de Madride -mai l  : raquel?eucmos,  s im.
ucm.
esJoseba  Aba i tuaFacultad de Filosofia y LetrasUniversidad e Deusto, Bilbaoe-mai l  : abaitua~fi l ,  deusto, esArantza  CasillasDepartamento de Autom~tica,  Universidad e Alcal~ de Henarese -mai l  : a rantza?aut ,  a l ca la ,  esAbst rac tRich mark-up can considerably benefit he processof establishing bitext correspondences, that is, thetask of providing correct identification and align-ment methods for text segments that are transla-tion equivalences of each other in a parallel corpus.We present a sentence alignment algorithm that, bytaking advantage ofpreviously annotated texts, ob-tains accuracy rates close to 100%.
The algorithmevaluates the similarity of the linguistic and extra-linguistic mark-up in both sides of a bitext.
Giventhat annotations are neutral with respect to typolog-ical, grammatical nd orthographical differences be-tween languages, rich mark-up becomes an optimalfoundation to support bitext correspondences.
Themain originality of this approach is that it makesmaximal use of annotations, which is a very sensibleand efficient method for the exploitation of parallelcorpora when annotations exist.1 In t roduct ionAdequate encoding schemes applied to largebodies of text in electronic form have been amain achievement in the field of humanitiescomputing.
Research in computational linguis-tics, which since the late 1980s has resorted tomethodologies involving statistics and probabil-ities in large corpora, has however largely ne-glected the existence and provision of extra in-formation from such encoding schemes.
In thispaper we present an approach to sentence align-ment that crucially relies on previously intro-duced annotations in a parallel corpus.
Fol-lowing (Harris 88), corpora containing bilingualtexts have been called "bitexts" (Melamed 97),(Martlnez et al 97).The utility of annotated bitexts will bedemonstrated by the proposition of a methodol-ogy that crucially takes advantage of rich mark-up to resolve bitext correspondences, that is,the task of providing correct identification andalignment methods for text segments that aretranslation equivalencies of each other (Chang& Chen 97).
Bitext correspondences provide agreat source of information for applications suchas example and memory based approaches tomachine translation (Sumita & Iida 91), (Brownet al 93), (Collins et al 96); bilingual termi-nology extraction (Kupiec 93), (Eijk 93), (Da-gan et al 94), (Smajda et al 96); bilinguallexicography (Catizione et al 93), (Daille etal.
94), (Gale & Church, 91b); multilingual in-formation retrieval (SIGIR 96), and word-sensedisambiguation (Gale et al 92), (Chan & Chen97).
Moreover, the increasing availability ofrunning parallel text in annotated form (e.g.WWW pages), together with evidence that poormark-up (as HTML) will progressively be re-placed by richer mark-up (e.g.
SGML/XML),are good enough reasons to investigate methodsthat benefit from such encoding schemes.We first provide details of how a bitext sam-ple has been marked-up, with particular em-phasis on the recognition and annotation ofproper nouns.
Then we show how sentencealignment relies on mark-up by the applicationof a methodology that resorts to annotations todetermine the similarity between sentence pairs.812This is the 'tags as cognates' algorithm, TasC.2 B i text  tagg ing  and  segmentat ionA large bitext has been compiled consisting of acollection of administrative and legal bilingualdocuments written both in Spanish and Basque,with close to 7 million words in each language.For the experiments, we have worked on a rep-resentative subset of around 500,000 words ineach language.
Several stages of automatic tag-ging, based on pattern matching and heuristics,were undertaken, rendering different descriptivelevels:General encoding (paragraph, sentence,quoted text, dates, numbers, abbrevia-tions, etc.).?
Document specific tags that identify doc-ument types and define document internalorganisation (sections, divisions, identifica-tion code, number and date of issue, issuer,lists, itemised sections, etc.).?
Proper noun tagging (identification andcategorisation of proper nouns into severalclasses, including: person, place, organi-sation, law, title, publication and uncate-gorised).This collection of tags (shown in Table 1) re-flects basic structural and referential features,which appear consistently at both sides of thebitext.
Although the alignment of smaller seg-ments (multi-word lexical units and colloca-tions) will require more expressive tagging, suchas part-of-speech tagging (POS), for the taskof sentence alignment, this is not only unnec-essary, but also inappropriate, since it wouldintroduce undesired language dependent infor-mation.
The encoding scheme has been basedon TEI's guidelines for SGML based mark-up(Ide & Veronis 95).2.1 P roper  noun tagg ingAs for many other text processing applications,proper noun tagging plays a key role in ourapproach to sentence alignment.
It has beenreported that proper nouns reach up to 10%of tokens in text (newswire text (Wakao et al96) and (Coates-Stephens 92)) and one third ofnoun groups (in the Agence France Presse flow(Wolinski et al 95)).
We have calculated thatproper nouns constitute a 15% of the tokens inour corpus.
The module for the recognition ofproper nouns relies on patterns of typography(capitalisation and punctuation) and on contex-tual information (Church 88).
It also makes useof lists with most common person, organisation,law, publication and place names.
The taggerannotates a multi-word chain as a proper nounwhen each word in the chain is uppercase initial.A closed list of functional words (prepositions,conjunctions, determiners, etc.)
is allowed toappear inside the proper noun chain, see exam-ples in Table 2.
A collection of heuristics dis-card uppercase initial words in sentence initialposition or in other exceptional cases.In contrast with other known classifications(e.g.
MUC-6 95), we exclude from our listof proper nouns time expressions, percentageexpression, and monetary amount expressions(which for us fall under a different descriptivelevel).
However, on top of organisation, personand location names, we include other entitiessuch as legal nomenclature, the name of publi-cations as well as a number of professional titleswhose occurrence in the bitext becomes of greatvalue for alignment.2.2 B i text  asymmetr iesBecause our approach to alignment relies onconsistent tagging, bitext asymmetries of anytype need to be carefully dealt with.
For exam-ple, capitalisation conventions across languagesmay show great divergences.
Although, in the-ory, this should not be the case between Spanishand Basque, since officially they follow identicalconventions for capitalisation (which are by theway the same as in French), in practise theseconventions have been interpreted very differ-ently by the writers of the two versions (lawyersin Spanish and translators in Basque).
In theBasque version, nouns referring to organisationssaila 'Department', professional titles diputatua'Deputy', as well as many orographic or geo-graphical sites arana 'Valley', are often writtenin lowercase, while in the Spanish original doc-uments these are normally written in uppercase(see Table 2).
These nouns belong to the typedescribed as 'trigger' words by (Wakao et al96), in the sense that they permit the identifi-cation of the tokens urrounding them as propernouns.
Then, it has been required to resort tocontextual information.
The results of the reso-lution of these singularities are shown in Table813\[\[ Descriptive l vels Tagset \[\]II General encoding <p>, <s>, <num>, <date> <abbr>, <q> IDocument especific <div>, <classCode> <keywords>, <dateline>, <list><seg>Proper nouns <rs>Table 1: Tagset used for sentence alignmentProper Noun Classes Spanish BasquePerson Ana Ferndndez Gutierrez-Crespo Ana Ferndndez Gutierrez-CrespoPlace Valle de Arratia Arratiko aranaOrganisation Departamento de Presidencia Lehendakaritza SailekoLaw Real Decreto Legislativo Legegintzazko Erret DekretukoTitle Diputado Foral de Urbanisrno Hirigintza foru diputatuaPublication Boletln Oficial de Bizkaia Bizkaiko Aldizkari OfizialeanUncategorised A nexo eraskinTable 2: Examples.3 Us ing  tags  as cognates  forsentence  a l ignmentAlgorithms for sentence alignment abound andrange from the initial pioneering proposals of(Brown et al 91), (Gale & Church 91a),(Church 93), or (Kay & Roscheisen 93), to themore recent ones of (Chang & Chen 97), or(Tillmann et al 97).
The techniques employedinclude statistical machine translation, cognatesidentification, pattern recognition, and digitalsignal and image processing.
Our algorithm,as (Simard et al 92), and (Melamed 97) em-ploys cognates to align sentences; and similar to(Brown et al 91), it also uses mark-up for thatpurpose.
Its singularity does not lie on the useof mark-up as delimiter of text regions (Brownet al 91) in combination with other techniques,but on the fact that it is the sole foundationfor sentence alignment.
We call it the 'tagsas cognates' algorithm, TasC.
This algorithm isnot disrupted by word order differences or smallasymmetries in non-literal translation, and, un-like other reported algorithms (Melamed 97),it possesses the additional advantage of beingportable to any pair of languages without theneed to resort to any language-specific heuris-tics.
Provided an adequate and consistent bi-text mark-up, sentence alignment becomes asimple and accurate process also in the case oftypologically disparate or orthographically dis-tinct language pairs for which techniques basedon lexical cognates may be problematic.
One ofof proper nounsthe best consequences of this approach is thatthe burden of language dependent processing isdispatched to the monolingual tagging and seg-mentation phase.3.1 Simi lar i ty calculus between b i textsThe alignment algorithm establishes similaritymetrics between candidate sentences which aredelimited by corresponding mark-up.
Dice's co-efficient is used to calculate these similarity met-rics (Dice 45).
The coefficient returns a real nu-meric value in the range 0 to 1.
Two sentenceswhich are totally dissimilar in the content oftheir internal mark-up will return a Dice scoreof 0, while two identical contents will return aDice score of 1.For two text segments, P and Q, one in eachlanguage, the formula for Dice's similarity coef-ficient will be:Dice(P, Q) -- 2FpQFp + FQwhere FpQ is the number of identical tags thatP and Q have in common, and Fp and FQ arethe number of tags contained by each text seg-ment P and Q.Since the alignment algorithm determinesthe best matching on the basis of tagsimilarity, not only tag names used tocategorise different cognate classes (num-ber, date, abbreviation, proper noun, etc.
),but also attributes contained by these tagsmay help identify the cognate itself: <numnum=57>57</num>.
Furthermore, attributes814Proper Noun ClassesPersonPlaceOrganisationLawTitlePublicationUncategorisedTotalSpanish BasquePrecision I Recall 1% Spanish PN Precision I Recall 1% Basque PN100% 100%100% 100%99.2% 97.8%99.2% 99.2%100% 100%100% 100%100% 100%4.48%6.38%23.96%47.93%6.55%2.58%8.10%100% 100% 4.76%100% 100% 6.95%100% 100% 24.17%100% 100% 46.15%97.2% 97.2% 6.59%100% 100% 2.74%100% 100% 8.60100% II 99.8% 199.8%\[ 100% II 99.4%199.1%\[Table 3: Results of proper noun identificationmay serve also to subcategorise proper nountags: <rs  type=place>Bi lbao</rs>.Such subcategorisations areof great value tocalculate the similarity metrics.
If mark-up isconsistent, he correlation between tags in thecandidate text segments will be high and Dice'scoefficient will come close to 1.
For a randomlycreated bitext sample of source sentences, Fig-ure 1 illustrates how correct candidate align-ments have achieved the highest Dice's coeffi-cients (represented by '*'s), while next highercoefficients (represented by 'o's ) have achievedsignificant lower values.
It must be noted thatthe latter do not correspond to correct values.The difference mean between Dice's coeffi-cients corresponding to correct alignments andnext higher values is:n~(DCc i  - DCwi)M = i=1 = 0.45nWhere for a given source sentence i, DCcirepresents Dice's coefficient corresponding to itscorrect alignment and DCwi  represents he nexthigher value of Dice's coefficients for the samesource sentence i.
In all the cases, this differenceis greater than 0.2.For consistently marked-up bitexts, these re-sults show that sentence alignment founded onthe similarity between annotations can be ro-bust criterion.Figure 2 illustrates how the Dice's coefficientis calculated between candidate sentences toalignment.3.2 The  s t ra tegy  of the  TasC algor i thmThe alignment of text segments can be for-malised by the matching problem in bipartite_0.5$ DC of correct  a l ignment  given a source sentenceo The  next h igher  DC for the same source sentenceoo o co oO co co oo  oo o o~ o o o~000 0 000  0 0 0 0 00 0 00 0 0 00 00 0 0 0o%~ooo0 oFigure 1: Values of Dice's coefficient betweencorresponding sentencesgraphs.
Let G = (V, E, U) be a bipartite graph,such that V and U are two disjoint sets ofvertices, and E is a set of edges connectingvertices from V to vertices in U.
Each edge inE has associated a cost.
Costs are representedby a cost matrix.
The problem is to find aperfect matching of G with minimum cost.The minimisation version of this problem iswell known in the literature as the assignmentproblem.Applying the general definition of the prob-lem to the particular case of sentence alignment:V and U represent two disjoint sets of verticescorresponding to the Spanish and Basque sen-tences that we wish to align.
In this case, eachedge has not a cost but a similarity metric quan-tified by Dice's coefficient.
The fact that ver-tices are materialised by sentences detracts gen-815Spanish Sentence:<s id=sESdoc5-4>Habi4ndose d tectado enel anuncio publicado en el ndmero<numnum=79> 79 </num> de fecha <datedate=2?/04>27 de abril</date> de este <rstype=publication>Boletfn</rs>, la omisi6ndel primer p~rrafo de la <rs type=law>OrdenForal</rs> de referencia, se procede a su ~ntegrapublicaci6n.
< / s >Basque Sentence:<s id=sEUdoc5-5>Agerkaria honetako <datedat e=27/04>apirilaren 27ko</date> <numnum=79>79k.an </num> argitaratutako ira-garkian aipameneko <rs type=law>ForuAginduaren</rs> lehen lerroaldea ez dela geridetektatu ondoren beraren argitarapen osoaegitera jo da.</s>The common tags are: <date date=27/04>, <num num=79>, <rs type=law>The Dice's similarity coefficient will be: Dice(P,Q)= 2x3 / 4+3 = 0.857Figure 2: Similarity calculus between candidate sentenceserality to the assignment problem and makes itpossible to add constraints to the solutions re-ported in the literature.
These constraints takeinto account the order in which sentences inboth the source and target exts have been writ-ten, and capture the prevailing fact that trans-lators maintain the order of the original textin their translations, which is even a strongerproperty of specialised texts,By default, a whole document delimits thespace in which sentence alignment will takeplace, although this space can be customisedin the algorithm.
The average number of sen-tences per document is approximately 18.
Twotypes of alignment can take place:?
1 to 1 alignment: when one sentence in thesource document corresponds to one sen-tence in the target document (94.39% ofthe cases).?
N to M alignment: when N sentences inthe source document correspond to M sen-tences in the target document (only 5.61%of the cases).
It includes cases of 1-2, 1-3and 0-1 alignments.Both alignment ypes are handled by the algo-rithm.3.3The.The algorithmTasC algorithm works in two steps:It obtains the similarity matrix S fromDice's coefficients corresponding to can-didate alignment options.
Each row inS represents the alignment options of asource sentence classified in decreasing or-der of similarity.
In this manner, each col-umn represents a preference position (1 thebest alignment option, 2 the second bestand so on).
Therefore, each Si,j is theidentification of one or more target sen-tences which match the source sentence iin the preference position j.
In order toobtain the similarity matrix, it is not nec-essary to consider all possible alignmentoptions.
Constraints regarding sentenceordering and grouping greatly reduce thenumber of cases to be evaluated by the al-gorithm.
In the algorithm each source sen-tence xi is compared with candidate targetsentences yj as follows: (xi, Yi); (xi, YjYj+I.
.
.
,  where YjYj+I represents the concate-nation of yj with Yj+I.
The algorithmmodule that deals with candidate align-ment options can be easily customised tocope with different bitext configurations(since bitexts may range from a very simpleone-paragraph text to more complex struc-tures).
In the current version of the al-gorithm seven alignment options are takeninto account.2.
The TasC algorithm solves an assignmentproblem with several constraints.
It alignssentences by assigning to each ith sourcesentence the Si,j target option with min-imum j value, that is, the option withmore similarity.
Furthermore, the algo-r ithm solves the possible conflicts when asentence matches with other sentences al-ready aligned.
The average cost of the al-gorithm, experimentally contrasted,  is lin-ear in the size of the input, although in theworst case the cost is bigger.The result of sentence alignment is reflectedin the bitext by the incorporation of the at-tribute ' cor resp  to sentence tags, as can be seen816Cases1-1N-M%Corpus94.39%% Accuracy100%5.61% 99.68%Table 4: TasC Algorithm resultsin Figure 3.
This attribute points to the cor-responding sentence identification code in theother language.4 Eva luat ionThe current version of the algorithm has beentested against a subcorpus of 500,000 words ineach language consisting of 5,988 sentences andhas rendered the results shown in Table 4.The accuracy of the 1 to 1 alignment is 100%.In the N to M case only 1 error occurred out of314 sentences, which reaches 99.68% accuracy.The algorithm to sentence alignment has beendesigned in such a modular way that it can eas-ily change the tagset used for alignment and theweight of each tag to adapt it to different bitextannotations.
The current version of the algo-rithm uses the tagset shown in Table 1 withoutweights.5 Future  workOnce sentences have been aligned, the nextstep is the alignment of sentence-internal seg-ments.
The sentence will delimit the searchspace for this alignment, and hence, by reduc-ing the search space, the alignment complexityis also reduced.5.1 P roper  noun a l ignmentProper nouns are a key factor for the efficientmanagement of the corpus, since they are thebasis for the indexation and retrieval of doc-uments in the two versions.
For this reason,at present we are concerned with proper nounalignment, something which is not usually donein the mapping of bitexts.
The alignment isachieved by resorting to:?
The identification of cognate nouns, aidedby a set of phonological rules that applywhen Spanish terms are taken to produceloan words in Basque.?
The restriction of cognate search space topreviously aligned sentences, and* The application of the TasC algorithmadapted to proper noun alignment.5.2 A l ignment  of  co l locat ionThe next step is the recognition and alignmentof other multi-word lexical units and colloca-tions.
Due to the still unstable translationchoices of much administrative t rminology inBasque, on top of the considerable typologicaland structural differences between Basque andSpanish, many of the techniques reported in theliterature (Smadja et al 96), (Kupiec 93) and(Eijk 93) cannot be effectively applied.
POStagging combined with recurrent bilingual glos-sary lookup is the approach we are currentlyexperimenting with.6 Conc lus ionsWe have presented a sentence alignment ap-proach that, by taking advantage of previouslyintroduced mark-up, obtains accuracy ratesclose to 100%.
This approach is not disruptedby word order differences and is portable to anypair of languages without the need to resort toany language specific heuristics.
Provided andadequate and consistent bitext mark-up, sen-tence alignment becomes an accurate and ro-bust process also in the case of typologicallydistinct language pairs for which other knowntechniques may be problematic.
The TasC algo-rithm has been designed in such a modular waythat it can be easily adapted to different bitextconfigurations as well as other specific tagsets.7 AcknowledgementsThis research is being partially supported by theSpanish Research Agency, project ITEM, TIC-96-1243-C03-01.Re ferencesBrown, P., Lai, J.C., Mercer, R. (1991).
Aligning Sentences inParallel Corpora.
Proceedings of the 29th Annual Meetingof the Association .for Computational Linguistics, 169-176,Berkeley, 1991.Brown, P., Della Pietra, V., Della Pietra, S., Mercer, R.(1993).
The mathematics of statistical machine transla-tion: parameter estimation.
Computational Linguistics19(2):263-301 1993.Catizone, R., Russell, G., Warwick, S. (1993).
Deriving Trans-lation Data from Bilingual Texts.
Proccedings of the FirstInternational Lexical Acquisition Workshop, Detroit, MI,1993.Chang, J. S., Chen, M. H. (1997).
An Alignment Method forNoisy Parallel Corpora based on Image Processing Tech-niques.
Proceedings of the 35th Annual Meeting of the As-sociation for Computational Linguistics, 297-304, 1997.817Spanish Sentence:<s  id=sESdoc5-4 corresp=sEUdoc5-5>Habi4n-dose detectado en el anuncio publicado en elndmero<num num=79> 79 </num> de fecha<date  date=27/04>27 de abril</date> deeste <rs type=pub l i ca t  ion>Bo le t fn</ rs>,la omisi6n del primer phrrafo de la <rstype=law>Orden Foral</rs> de referenciase procede a su integra publicaci6n.</s>Basque Sentence:<s id=sEUdoc5-5 corresp=sESdoc5-4>Agerkariahonetako <date date=27/04> apirilaren27ko</date> <num num=79>79k.an </num>argitaratutako iragarkian aipameneko <rstype=law>Foru  Ag induaren</rs> lehen ler-roaldea ez dela geri detektatu ondoren berarenargitarapen osoa egitera jo da .</s>Figure 3: Results of sentence alignment expressed by the corresp attributeChurch, K.W.
(1988).
A Stochastic parts program and nounphrase parser for unrestricted text.
Proceedings of the Sec-ond Conference on Applied Natural Language Processing,136-143, 1988.
Association for Computational Linguistics.Church, K.W.
(1993).
Char_Align: A Program for AligningParallel Texts at the Character Level.
Proceedings of the31th Annual Meeting of the Association for ComputationalLinguistics, Columbus, USA 1993.Coates-Stephen, S. (1992).
The Analysis and Acquisition ofProper Names for Robust Text Understanding, Ph.D. De-partment of Computer Science of City University, London,England, 1992.Collins, B., Cunningham, P., Veale, T. (1996).
An Exam-ple Based Approach to Machine Translation.
Expand-ing MT Horizonts: Proceedings of the Second Confer-ence of the Association for Machine Translation in theAmericas:AMTA-96, 125-134, 1996.Daille, B., Gaussier, E., Lange, J.M.
(1994).
Towards Auto-matic Extraction of Monolingual and Bilingual Terminol-ogy.
Proceedings of the 15th International Conference onComputational Linguistics, 515-521, Kyoto, Japan.Dagan, I., Church, K. (1994).
Termigh: Identifying and trans-lating Technical Terminology.
Proceedings Fourth Confer-ence on Applied Natural Language Processing (ANLP-94),Stuttgart, Germany, 34-40, 1994.
Association for Compu-tational Linguistics.Dice, L.R.
(1945).
Measures of the Amount of Ecologic Asso-ciation Between Species.
Ecology, 26, 297-302.Eijk, P. van der.
(1993).
Automating the acquisition of Bilin-gual Terminology.
Proceedings Sixth Conference of the Eu-ropean Chapter of the Association for Computational Lin-guistic, Utrecht, The Netherlands, 113-119, 1993.Gale, W., Church, K.W.
(1991a).
A Program for AligningSentences in Bilingual Corpora.
Proceedings of the 29thAnnual Meeting of the Association for Computational Lin-guistics, 177-184, Berkeley, 1991a.Gale, W., Church, K. W. (1991b).
Identifying Word Corre-spondences in Parallel Texts.
Proceedings of the DARPASNL Workshop, 1991.Gale, W., Church, K. W., Yarowsky, D. (1992).
Using Bilin-gual Materials to Develop Word Sense DisambiguationMethods.
Proceedings of the 4th International Confer-ence on Theoretical and Methodological Issues in MachineTranslation (TMI-92), 101-112, Montreal, Canada 1992.Harris, B.
(1988).
Bi-Text, a New Concept in Translation The-ory.
Language Monthly #54, 1988.Ide,N., Veronis, J.
(1994).
MULTEXT (Multilingual TextTools and Corpora.)
Proceedings of the InternationalWorkshop on Sharable Natural Language Resources, 90-96, 1994.Ide, N., Veronis, J.
(1995).
The Text Encoding Initiative:Background and Contexts.
Dordrecht: Kluwer AcademicPublishers, 1995.Kay, M., Roscheisen, M. (1993).
Text-Translation Alignment.Computational Linguistics, 19:1, 121-142, 1993.Kupiec, J.
(1993).
An algorithm for finding noun phrase cor-respondences in bilingual corpora.
Proceedings of the 31stAnnual Meeting of the ACL, Columbus, Ohio, 17-22.
As-sociation for Computational Linguistics 1993.Martinez, R., Casillas, A., Abaitua, J.
(1997).
Bilingual paral-lel text segmentation a d tagging for specialized ocumen-tation.
Proceedings of the International Conference RecentAdvances in Natural Language Processing, RANLP'97,369-372, 1997.Melamed, I.D.
(1997).
A Portable Algorithm for MappingBitext Correspondence.
Proceedings of the 35th AnnualMeeting of the Association for Computational Linguistics,305-312, 1997.MUC-6.
(1995).
Proceedings of the Sixth Message Under-standing Conference (MUC-6).
Morgan Kaufman.SIGIR.
(1996).
Workshop on Cross-linguistic Multilingual In-formation Retrieval, Zurich, 1996.Simard, M., Foster, G.F., Isabelle, P. (1992).
Using Cognatesto Align Sentences in Bilingual Corpora.
Proceedings ofthe Fourth International Conference on Theoretical andMethodological Issues in Machine Translation, Montreal,67-81, 1992.Smadja, F., McKeown, K., Hatzivassiloglou, V.(1996).
Trans-lating Collocations for Bilingual Lexicons: A StatisticalApproach.
Computational Linguistics Volume 22, No.
1,1996.Sumita, E., Iida, H. (1991).
Experiments and prospect ofexample-based machine translation.
Proceedings of the As-sociation for Computational Linguistics.
Berkeley,185-192,1991.Tillmann, C., Vogel, S., Ney, H., Zubiaga, A.
(1997).
A DPbased Search Using Monotone Alignments in StatisticalTranslation.
Proceedings of the 35th Annual Meeting ofthe Association for Computational Linguistics, 289-296,1997.Wakao, T., Gaizauskas, R., Wilks, Y.
(1996).
Evaluation ofan Algorithm for the Recognition and Classification ofProper Names.
Proceedings of the 16th International Con-ference on Computational Linguistics (COLING96),418-423, 1996.Wolinski, F., Vichot, F., Dillet, B.
(1995).
Automatic Process-ing of Proper Names in Texts.
The Computation and Lan-guage E-Print Archive, http : //xxx.lanl.gov/list/cmp -lg/9504001818
