NEUNLPLab Chinese Word Sense Induction System forSIGHAN Bakeoff 2010Hao Zhang Tong Xiao Jingbo Zhu1.
Key Laboratory of Medical Image Computing (Northeastern University), Ministryof Education2.
Natural Language Processing Laboratory, Northeastern Universityzhanghao1216@gmail.com{xiaotong, zhujingbo}@mail.neu.edu.cnAbstractThis paper describes a character-basedChinese word sense induction (WSI) sys-tem for the International Chinese Lan-guage Processing Bakeoff 2010.
Bycomputing the longest common sub-strings between any two contexts of theambiguous word, our system extractscollocations as features and does not de-pend on any extra tools, such as Chineseword segmenters.
We also design a con-strained clustering algorithm for this task.Experiemental results show that our sys-tem could achieve 69.88 scores ofFScore on the development data set ofSIGHAN Bakeoff 2010.1 IntroductionThe goal of word sense induction (WSI) is togroup occurrences containing a given ambiguousword into clusters with respect to sense.
Mostresearchers take the problem of word sense in-duction as a clustering problem.
Pantel & Lin(2002) clustered words on the basis of the dis-tances of their co-occurrence vectors, and usedglobal clustering as a solution.
Neill (2002) usedlocal clustering, and determined the senses of agiven word by clustering its close associations.In this paper, we propose a simple but effec-tive method to extract collocations as featuresfrom texts without pre-segmentations, and de-sign a constrained clustering algorithm to ad-dress the issue of Chinese word sense induction.By using our collocation extraction method, ourChinese WSI system is independent of any extranatural language processing tools, such as Chi-nese word segmenters.
On the development setof SIGHAN 2010 WSI task, the experimentalresults show that our system could achieve 69.88scores of FScore.
In addition, the official resultsshow that the performance of our system is67.15 scores of FScore on the test set ofSIGHAN Bakeoff 2010.The rest of this paper is organized as follows.In Section 2, we present the task description ofChinese word sense induction.
In Section 3, wefirst give an overview of our Chinese WSI sys-tem, and then propose our feature extractionmethod and constrained clustering algorithm.
InSection 4, we describe the evaluation methodand show the experimental results on the devel-opment and test data sets of the Bakeoff 2010.
InSection 5, we conclude our work.2 Task DescriptionGiven the number of senses S and occurrences ofthe ambiguous word w, a word sense inductionsystem is supposed to cluster the occurrencesinto S clusters, with each cluster representing asense of the ambiguous word w. For example,suppose that there are some sentences containingthe ambiguous word ????
(gloomy), and thesense number S is 2, the job of WSI system is tocluster these sentences into 2 clusters, with eachcluster representing a sense of ????.
Based onthis task description, it is obvious to regard theproblem of WSI as a clustering problem.Figures 1-2 shows example input and outputof our WSI system , where there are 6 sentencesand 2 resulting clusters.
In Figure 1, the firstcolumn are the identifiers of sentences contain-ing the word ???
?, and the second column arepart of the sentences.
In Figure 2, the first col-umn represents the identifiers of sentences, andthe second column represents the identifiers ofclusters generated by our Chinese WSI system.Figure 1 Part of input of word ????
for ourWSI systemFigure 2 Output of our WSI system for word???
?3 NEU Chinese WSI System3.1 System overviewOur Chinese word sense induction system isbuilt based on clustering work-frame.
There arefour major modules in the system, includingdata pre-processing, feature extraction, cluster-ing and data post-processing modules.
The ar-chitecture of our Chinese WSI system is illus-trated in Figure 3.3.2 Feature extractionSince there is no separators in Chinese like?space?
in English to mark word boundaries,most Chinese natural language processing appli-cations need to first apply a Chinese word seg-menter to segment Chinese sentences.
In ourChinese word sense induction system, we extractcollocations from sentences containing the am-biguous word as features.
To extract collocations,we might first segment the sentences into wordsequences, and then conduct feature extractionon the word-segmented corpus.
However, errorsmight be induced in the procedure due to un-avoidable incorrect segmentation results.
Ad-dressing this issue, we propose a method to di-rectly extract collocations from sentences with-out pre-segmentations.In our method, we extract two kinds of collo-cations, namely ?global collocation?
and ?localcollocation?.
Here global collocations are de-fined to be the words (or character sequences)that frequently co-occur with the ambiguousword, and local collocations are defined to bethe characters adjacent to the ambiguous word1.Figure 3 Architecture of our systemTo extract global collocations, we first com-pute all the longest common substrings betweenany two of the sentences containing the ambigu-ous word to form the set of candidate global col-locations.
For each candidate global collocation,we count the number of sentences containing it.We then reduce the size of the candidate set byeliminating candidates which contain only onecharacter or functional words.
We also removethe candidate with other candidates as its sub-strings.
Finally, we eliminate the candidateswhose count of the number of sentences is belowa certain threshold.
The threshold equals to twoin our experiments.
We regard the candidatesafter the above processing as global collocationsfor WSI.To extract local collocations, we simply ex-tract one character on both left and right sides ofthe ambiguous word to form the set of candidatelocal collocations.
We then refine the candidateset by eliminating candidates which are func-tional words or whose frequency is below a cer-tain threshold.
The threshold is set to two in ourexperiments.After extracting global collocations and localcollocations, we put them together to form the1Definitions of global collocation and local collocationmight be different from those in other papers.startdata pre-processingfeature extractionclusteringdata post-processingendfinal set of collocations and use them as featuresof our system.
For each collocation (or feature),we compute the list of indices of sentences thatcontaining the collocation.
Thus, every elementof the set of collocations has the data structure ofpair of ?key?
and ?value?, where ?key?
is thecollocation itself, and the ?value?
is the list ofindices.3.3 Clustering algorithmWe find that the high-confidence collocation is avery good indicator to distinguish the senses ofan ambiguous word.
However, the traditionalclustering methods are based on the vector rep-resentations of features, which probably de-creases the effect of dominant features (i.e.
high-confidence collocations).
To alleviate the prob-lem, a nice way is to incorporate collocationsinto the clustering process as constraints.
Moti-vated by this idea, we design a constrained clus-tering algorithm.
In this algorithm, we could en-sure that some occurrences of the ambiguousword must be in one cluster and some must notbe in one cluster.
The input for our constrainedclustering algorithm is the set of collocationsdescribed in the previous section and the processof our clustering algorithm is shown in Table 1.Here the notation starting with character ?C?represents a collocation, and the notations of?Sin?
and ?Srlt?
represent the collocation set andthe result set, respectively.Every element in the result set Srlt is regardedas one cluster for a given ambigous word, andthe list of the element records the indices of thesentences belonging to the cluster.4 Evaluation of Our SystemThe evaluation method is F-score which is pro-vided within the Bakeoff 2010 (Zhao andKarypis, 2005).
Suppose Cr is a class of the goldstandard, and Si is a cluster of our system gener-ated.
FScore is computed with the formulas be-low.
( , ) 2 * * / ( )F score Cr Si P R P R?
= +          (1)( ) max( ( , ))SiFScore Cr F score Cr Si= ?
(2)1( )crnrFScore FScore Crn==?
(3)We evaluate our Chinese word sense induc-tion system on the development data set and thetest data set of the Bakeoff 2010.
The details ofthe development data set and the test data set aresummarized in Table 2.For comparison, we develop a baseline systemthat also uses the collocations as features andclustering based on the vector representations offeatures.
On the development data set, we testour system and compare it with the baseline sys-tem.
The performance of our Chinese WSI sys-tem and the baseline system are shown in Table3.
From Table 3, we see that using our con-strained clustering algorithm is better than usingthe traditional hierarchical clustering methods by7.06 scores of FScore for our Chinese WSI sys-tem.
It indicates that our constrained clusteringalgorithm could avoid reducing the effect ofInput: collocation set Sinwhile there is available collocation Ci in theinput set Sinfor each collocation Ct in the set Sinif Ct not equals to Ci, and Ct is avail-ableif list of Ct has intersection withthat of Ci, or Ct and Ci have ameaningful substring (word orcharacter), compose list of Ct intolist of Ci, and mark Ct to be un-availableend ifend ifend forstore Ci and its list into result set Srlt, andmark Ci to be unavailableend whileif there are available collocations in the inputset Sinif the size of result set Srlt does not sat-isfy the given cluster number, devide therest collocations in Sin evenly into therest clusters, and append their lists totheir own clusters?
lists respectivelyelse add the rest collocations into the lastcluster, and append their list to the list ofthe last clusterend ifend ifreturn the result set SrltOutput: result set SrltTable 1 Constrained clustering algorithmhigh-confidence features (i.e.
high-confidencecollocations) and lead to better clustering results.This conclusion is also ensured by the compari-son between our constrained clustering algo-rithm and the traditional K-means clustering al-gorithm.In addition, our system achieves 67.15 scoresof FScore on the test data set reported by theSIGHAN Bakeoff 2010.data descriptionsDev setcontaining 50 ambiguous words,about 50 sentences for each am-biguous wordTest setcontaining 100 ambiguous words,about 50 sentences for each am-biguous wordTable 2 Data sets of SIGHAN Bakeoff 2010clustering methodsFScore ofour system(%)traditional hierarchical cluster-ing 62.82traditional K-means clustering 62.48our constrained clustering 69.88Table 3 System performance on dev set ofBakeoff 2010 using different clustering methods5 ConclusionsIn this paper, we propose a collocation extrac-tion method and a constrained clustering algo-rithm for Chinese WSI task.
By using the collo-cation extraction method and the clustering algo-rithm, our Chinese word sense induction systemis independent of any extra tools.
When testedon the test data set of the Bakeoff 2010, our sys-tem achieves 67.15 scores of FScore.ReferencesVickrey, David, Luke Biewald, Marc Teyssler, andDaphne Koller.
2005.
Word-sense disambiguationfor machine translation.
In Proceedings of the con-ference on Human Language Technology and Em-pirical Methods in Natural Language Processing,Morristown, NJ, USA, pages 771-778.Yarowsky, David.
1995.
Unsupervised word sensedisambiguation rivaling supervised methods.
InProceedings of 33rd Meeting of the Association forComputational Linguistics, Cambridge, MA, 189-196.Schutze, Hinrich.
1998.
Automatic word sense dis-crimination.
Computational Linguistics, Montreal,Canada, 24(1):97?123.Ng, Hwee Tou, Hian Beng Lee.
1996.
IntegratingMultiple Knowledge Sources to DisambiguateWord Sense: An Exemplar-Based Approach.
InProceedings of the 34th Meeting of the Associationfor Computational Linguistics, California, USA,pages 40-47.Daniel, Neill.
2002.
Fully Automatic Word SenseInduction by Semantic Clustering.
In ComputerSpeech, Cambridge University, Master?s Thesis.Pantel, Patrick, Dekang Lin.
2002.
Discovering wordsenses from text.
In Proceedings of ACM SIGKDD,Edmonton, 613-619.Rapp, Reinhard.
2004.
A Practical Solution to theProblem of Automatic Word Sense Induction.
InProceedings of the 42nd Meeting of the Associationfor Computational Linguistics, Barcelona, Spain.Zhao, Ying, George Karypis.
2005.
HierarchicalClustering Algorithms for Document Datasets.Data Mining and Knowledge Discovery, 10:141-168.
