Term Extraction Through Unithood And Termhood UnificationThuy VU, Ai Ti AW, Min ZHANGDepartment of Language Technology, Institute for Infocomm Research21 Heng Mui Keng Terrace, Singapore 119613{tvu, aaiti, mzhang}@i2r.a-star.edu.sgAbstractTerm Extraction (TE) is an important com-ponent of many NLP applications.
In gen-eral, terms are extracted for a given textcollection based on global context and fre-quency analysis on words/phrases associa-tion.
These extracted terms represent effec-tively the text content of the collection forknowledge elicitation tasks.
However, theyfail to dictate the local contextual informa-tion for each document effectively.
In thispaper, we refine the state-of-the-art C/NC-Value term weighting method by consider-ing both termhood and unithood measures,and use the former extracted terms to directthe local term extraction for each document.We performed the experiments on StraitsTimes year 2006 corpus and evaluated ourperformance using Wikipedia termbank.The experiments showed that our modeloutperforms C/NC-Value method for globalterm extraction by 24.4% based on termranking.
The precision for local term ex-traction improves by 12% when comparedto pure linguistic based extraction method.1 IntroductionTerminology Extraction (TE) is a subtask of in-formation extraction.
The goal of TE is to auto-matically extract relevant terms from a given cor-pus.
These extracted terms are used in a variety ofNLP tasks such as information retrieval, text min-ing, document summarization etc.
In our applica-tion scenario, we are interested in terms whoseconstituent words have strong collocation relationsand can be translated to another language in stablesingle word or multi-word translation equivalents.Thus, we define ?term?
as a word/phrase that car-ries a special meaning.A general TE consists of two steps.
The firststep makes use of various degrees of linguistic fil-tering (e.g., part-of-speech tagging, phrase chunk-ing etc.
), through which candidates of various lin-guistic patterns are identified (e.g.
noun-noun, ad-jective-noun-noun combinations etc.).
The secondstep involves the use of frequency- or statistical-based evidence measures to compute weights indi-cating to what degree a candidate qualifies as aterminological unit.
There are many methods inliterature trying to improve this second step.
Someof them borrowed the metrics from InformationRetrieval to evaluate how important a term iswithin a document or a corpus.
Those metrics areTerm Frequency/Inverse Document Frequency(TF/IDF), Mutual Information, T-Score, Cosine,and Information Gain.
There are also other works(Nakagawa and Mori, 2002; Frantzi andAnaniadou, 1998) that introduced better method toweigh the term candidates.Currently, the C/NC method (Frantzi andAnaniadou, 1998) is widely considered as thestate-of-the-art model for TE.
Although thismethod was first applied on English, it also per-formed well on other languages such as Japanese(Hideki Mima and Sophia Ananiadou, 2001), Slo-vene (?pela Vintar, 2004), and other domains suchas medical corpus (Frantzi and Ananiadou, 1998),and computer science (E. Milios et al 2003).In terminology research, a term is evaluated us-ing two types of feature: termhood1 and unithood1 Termhood refers to a degree of linguistic unit.
It considers aterm as a linguistic unit representative for the document con-tent.6312(Kyo Kageura, 1996).
In C/NC method, the fea-tures used to compute the term weight are based ontermhood only.
In this paper, we introduce a uni-thood feature, T-Score, to the C/NC method.
Ex-periment results show that by incorporating T-Score into C/NC to derive a new weight,NTCValue , it gives a better ranking of the globalterms and outperforms C/NC method by 24.4%.On the other hand, C/NC method extracts termcandidates using linguistic patterns and derivestheir weights based on distribution of terms overall documents.
The extracted terms thus representglobal content of the corpus, and do not representwell the contextual information for each individualdocument.
So, we propose a method to enrich thelocal terms through a Term Re-Extraction Model(TREM).
Experiment results show that the preci-sion for local TE has been improved significantly,by 12% when compared to pure linguistic basedextraction method.In the following sections, we introduce the state-of-the-art method, the C/NC Value method.
Wethen introduce our proposed methods, theNTCValue method on section 3, the Term Re-Extraction Model (TREM) on section 4 followedby the experiment results and conclusion.2 The C/NC value MethodC/NC method uses a combination of linguistic andstatistical information to evaluate the weight of aterm.
This method has two steps: candidateextraction and term weighting by C/NC value.2.1 Term Candidate ExtractionThis method uses 3 linguistic patterns to extract theterm candidates:?
(Noun+Noun);?
(Adj|Noun)+Noun;?
(Adj|Noun)+|((Adj|Noun)*(NounPrep)?
)(Adj|Noun)*)Noun.The term candidates are passed to the second step.2.2 Term Weighting2.2.1 CValueCValue  is calculated based on the frequency ofterm and its subterms.2 Unithood refers to a degree of strength or stability of syn-tagmatic combinations or collocations.
( ) ( ) ( ) ( )????????
?
?= ??
aTbabfTPafaaCValue1log2Where, ( )af  is the frequency of term a  with awords, aT  is the set of extracted candidate terms thatcontain a  and ( )aTP  is the total number of longercandidate terms that contain a .
The for-mula ( ) ( )??
aTba bfTP1will have value 0 when aT isempty.2.2.2 NC ValueNCValue combines the context information ofa term together with the CValue.
The weight of acontext word3 b is defined by the number of terms ( )bt in which it appears over the total number ofterms considered, n .
aC  is the set of distinct con-text words and ( )bfa is the frequency of b  as con-text word of a .
( ) ( )nbtbweight =( ) ( )??
?=aCba bweightbfNValue( ) ( ) ( )aNValueaCValueaNCValue ?+?= 2.08.0From the above formula, we find thatNCValue is mainly weighted by CValue .It treatsthe term candidate as a linguistic unit and evaluatesits weight based on characteristics of the termhood,i.e.
frequency and context word of the term candi-date.
The performance can be improved if featuremeasuring the adhesion of words within the term isincorporated.3 Enhancement on Global TE: theNTCValueTheoretically, the C/NC method can be improvedby adding unithood feature to the term weightingformula.
Based on the comparison of (Evert, S andB.
Krenn, 2001), we explore T-Score, acompetitive metric to evaluate the associationbetween two words, as a unithood feature.3 All experiments in this paper use the length of context is 3.6323.1 T-ScoreThe T-Score is used to measure the adhesionbetween two words in a corpus.
It is defined by thefollowing formula (Manning and Schuetze, 1999):( ) ( ) ( ) ( )( )NwwPwPwPwwPwwTSjijijiji ,.,,?=Where, ( )ji wwP , is the probability of bi-gramjiww  in the corpus, ( )wP  is the probability ofword w  in the corpus, and N  is the total numberof words in the corpus.
The adhesion is a type ofunithood feature since it is used to evaluate theintrinsic strength between two words of a term.3.2 Incorporate T-Score within C/NC valueAs discussed in 2.2, the most influential feature inthe C/NC method is the term frequency.
Our ideahere is to combine the frequency with T-Score, aunithood feature.
Taking the example in Table 1,the candidates have similar rank in the output usingC/NC termhood approach.massive tidal wavesgigantic tidal waveskiller tsunami tidal wavesdeadly tidal waveshuge tidal wavesgiant tidal wavestsunamis tidal wavesTable 1.
Example of similar terms 4To give better ranking and differentiation, weintroduce T-Score to measure the adhesion be-tween the words within the term.
We use theminimum T-Score of all bi-grams in term a , ( )aTSmin , as a weighted parameter for the termbesides the term frequency.
For aterm nwwwa .... 21= , the ( )aTSmin  is defined as: ( ) ( ){ } ( )1...1,,minmin 1 ?== + niwwTSaTS iiTerm ( )?TSminmassive tidal waves 4.56gigantic tidal waves 2.44killer tsunami tidal waves 3.99deadly tidal waves 3.15huge tidal waves 2.204 The italic means a week adhesion.giant tidal waves 1.35tsunamis tidal waves  5.06Table 2.
Term with Minimum T-Score valueTable 2 shows the ( )aTSmin  of the differentterms in table 1.
Since ( )aTSmin can have a nega-tive value, we only considered those terms with ( ) 0min >aTS  and combined it with the term fre-quency.
We redefine CValue to TCValue by re-placing ( )af  using ( )aF , as follows:( ) ( ) ( )( ) ( )( ) ( )???>+?
?=0minifmin2ln0minifaTSaTSafaTSafaF( ) ( ) ( ) ( )????????
?
?= ??
aTbabFTPaFaaTCValue1log2The final weight, defined as NTCValue, is com-puted using the same parameter as NCValue .
( ) ( ) ( )aNValueaTCValueaNTCValue ?+?= 2.08.04 Enhancement on Local Terms: TermRe-Extraction Method (TREM)The extracted term candidates are ranked globallywith best global terms promoted due to their dis-tinguishing power.
However, preliminary investi-gation on using linguistic patterns for extractingglobal term candidates for identifying term candi-dates of each document does not perform satisfac-tory, as high rank global terms do not reconcilewell with the local term candidates identified usingthe linguistic patterns.
A re-extraction process isthus evolved to derive local terms of a documentfrom global terms using the NTCValue of theglobal terms.4.1 Local Term Candidate ExtractionA string (or term candidate) extracted based onlinguistic pattern follows the maximum matchingalgorithm.
As long as the longest string whosepart-of-speech tag satisfies the linguistic pattern, itwill be extracted.
For this reason, some noises areextracted together with these candidates.
Table 3shows some examples of noisy term candidates.Strait Times yesterdayTHE World Cupgross domestic product growth forecastsenior vice-president of DBS Vickers securityon-lineTable 3.
Examples of noisy candidates.633Our intention here is to reduce the noise and alsomine more good terms embedded within the noiseby using the global terms.
We favor recall overprecision to get as many local terms as possible.The examples in table 3 show the problem in de-tecting term candidate?s boundary using linguisticpatterns.
The ?Strait Times yesterday?
is a badterm identified by linguistic patterns because allthree words are tagged as ?noun?.
The second oneis caused by an error of the POS tagger.
Because ofcapitalization, the word ?THE?
is being taggedwrongly as a ?proper-noun?
(NNP/NNPS), and notdeterminer (DT).
Similarly, ?gross domestic prod-uct growth forecast?
and ?senior vice-president ofDBS Vickers security on-line?
are complex noun-phrases that are not symbolized good terms in thedocument.
The more expressive terms would be?gross domestic product?, ?DBS Vickers security?,etc.Our proposed algorithm utilizes the term weightfrom section 3.2 to do term re-extraction for eachdocument through dynamic programming theory(Viterbi algorithm) to resolve the above problem.4.2 Proposed algorithmThe algorithm for term re-extraction is outlinedin Figure 1.Algorithm: Term re-extraction for a documentInput: L ?
global term list with NTCValueT ?
input for TREM nwww ...T 21=1: For 2=i  ?
n2:  If ( ) L...T 1,1 ?= ii ww3:   ( ) ( )iNTCiMaxNTC ,1T,1 =4:  Else ( ) 0,1 =iMaxNTC5:  End If6:  For 1=j  ?
1?i7:   If ( ) LT ?= ++ ijij ww ...1,18:    ( ) max,1 =iMaxNTC( ) ( ) ( ){ }iMaxNTCNTCjMaxNTC ij ,1;,1 ,1++ T9:   End If10:  End For11: End ForOutput: Updated term list for a documentFigure 1.
Term Re-Extraction AlgorithmWhere, ji,T  is the word chain formed by thewords from i  to j  of the term nwww ...T 21= ; ( )iMaxNTC ,1  is the maximum NTCValue valuefrom 1 to i  of the term nwww ...T 21= ; and ( )iNTC ,1T  is the NTCValue of ji,T .5 Experiments and Evaluations5.1 Term Bank CollectionTerm boundary is one of the main issues in termi-nology research.
In our experiments, we consider aterm based on the resources from Wikipedia.
Ineach Wikipedia article, the editor annotated the keyterminologies through the use of hyperlinks.
Weextracted the key terms for each article based onthis markup.
The entire Wikipedia contains about1,910,974 English articles and 8,964,590 key terms.These terms are considered as Wikipedia term-bank and we use it to evaluate our performance.An extracted term is considered correct if and onlyif it is in the term-bank.5.2 Corpus CollectionTo evaluate the model, we use the corpus collectedfrom Straits Times in year 2006.
We separate thedata into 12 months as showed in Table 4.Month Total articles Total words1 3,134 1,844,4192 3,151 1,824,9703 3,622 2,098,4594 3,369 1,969,6845 3,395 1,957,9626 3,187 1,781,6647 3,253 1,818,6068 3,497 1,927,1809 3,463 1,853,90210 3,499 1,870,41711 3,493 1,845,25412 3,175 1,711,168Table 4.
Evaluation data from Straits Times.5.3 NTCValue EvaluationWe evaluate the performance of global rankedterms using average-precision.
A higher average-precision would mean that the list contains moregood terms in higher rank.
The average precision ( ).PAve  of a term-list { }LtttL ,...,, 21=  with634cL as the list of all correct terms in L  ( )LLc ?
, iscalculated by the following formula:( ) ?
???
????????
??????
?=Lk kiikcrkrLLP1 111AveWhere:????
?=cicii LtLtr01Table 5 shows the comparison result of the ori-gin NCValue  and our NTCValue  on the rankingof global terms.
The experiment is conducted onthe data described in section 5.2.
We evaluate theperformance based on 8 different levels of topranking terms.Each cell in Table 5 contains a couple of ( ).PAve  for NCValue  and NTCValue( )NTCValueNCValue / respectively.
The( ).PAve  decreases gradually when we relax thethreshold for the evaluation .
The result shows thatthe term ranking using NTCValue  improves theperformance significantly.Number of top high term 01 02 03 04 05 0650 0.70/0.77 0.57/0.81 0.52/0.80 0.51/0.78 0.55/0.80 0.67/0.69100 0.60/0.73 0.59/0.77 0.51/0.79 0.50/0.74 0.57/0.78 0.64/0.70200 0.55/0.70 0.56/0.75 0.53/0.78 0.49/0.72 0.55/0.77 0.62/0.69500 0.53/0.67 0.54/0.70 0.54/0.71 0.48/0.68 0.53/0.71 0.57/0.651000 0.51/0.62 0.52/0.66 0.52/0.66 0.47/0.64 0.51/0.65 0.53/0.605000 0.48/0.58 0.49/0.61 0.49/0.62 0.45/0.60 0.49/0.61 0.49/0.5610000 0.43/0.52 0.44/0.55 0.44/0.56 0.42/0.54 0.44/0.56 0.44/0.50All_terms 0.38/0.47 0.39/0.49 0.40/0.50 0.37/0.48 0.39/0.49 0.38/0.45Number of top high term 07 08 09 10 11 1250 0.67/0.67 0.65/0.70 0.49/0.65 0.62/0.71 0.65/0.76 0.63/0.86100 0.64/0.71 0.62/0.74 0.47/0.66 0.59/0.74 0.59/0.76 0.61/0.82200 0.65/0.72 0.59/0.75 0.48/0.68 0.55/0.72 0.56/0.73 0.58/0.77500 0.62/0.71 0.56/0.70 0.50/0.66 0.52/0.66 0.54/0.67 0.55/0.691000 0.59/0.66 0.54/0.66 0.50/0.64 0.49/0.64 0.51/0.64 0.54/0.655000 0.54/0.60 0.51/0.62 0.49/0.60 0.46/0.61 0.48/0.60 0.51/0.6110000 0.46/0.53 0.46/0.55 0.45/0.55 0.43/0.56 0.44/0.55 0.46/0.55All_terms 0.40/0.47 0.40/0.50 0.40/0.50 0.38/0.49 0.38/0.48 0.39/0.48Table 5.
Performance of NTCValue with C/NC value.Method Without TREM TREM+NC TREM+NTCMonth Precision No.
terms Precision No.
terms Precision No.
terms1  44.98  23915  50.81  34910  50.85  349982  44.74  23772  50.22  34527  50.33  346573  44.39  28772  49.58  41691  49.59  417784  42.89  25857  48.78  38564  48.91  385895  44.67  25787  50.44  38252  50.38  383476  46.58  23293  51.80  33574  51.91  336517  46.35  23638  51.31  33990  51.35  340418  46.50  25869  51.91  37896  51.96  379739  46.16  25276  51.34  36632  51.39  3673110  45.79  24987  50.99  36082  51.05  3617911  45.28  24661  50.43  35894  50.54  3590612  45.67  22745  50.73  32594  50.73  32673Table 6.
Term Re-Extraction evaluation result.6355.4 TREM EvaluationWe evaluate TREM based on the term bank de-scribed in section 5.1.
Let iM  be the number ofextracted terms for article i , iN  be the number ofextracted terms in the term bank for article i , andn is the total articles in the test corpus.
The accu-racy is evaluated by the following formula:?==ni iiMNP1Table 6 shows the result of TREM.
From the re-sults, we can find that the accuracy has improvedsignificantly after the re-extraction process.
On topof that, the results of TREM based on NTCValueis also slightly better than using NCValue .
More-over, the number of correct terms extracted byTREM using NTCValue is higher than us-ing NCValue .6 Conclusions and Future WorksWe introduce a term re-extraction process (TREM)using Viterbi algorithm to augment the local TEfor each document in a corpus.
The results in Table6 show that TREM improves the precision of termsin local documents and also increases the numberof correct terms extracted.
We also propose amethod to combine the C/NC value with T-Score.The results of our method, NTCValue , show thatthe motivation to combine the termhood featuresused in C/NC method, with T-Score, a unithoodfeature, improves the term ranking result.
Resultson Table 6 also show that NTCValue gives a bet-ter result than the origin NCValue for TREM.In Table 5, the average scores for ?All Term?are 38.8% and 48.3% for NCValue  andNTCValue respectively.
Therefore, NTCValuemethod improves global TE by 24.4% when com-pared to the origin NCValue method.
With thesame calculation, we also conclude that TREMoutperforms the linguistic pattern method by 12%(average scores are 50.7% and 45.3% for TREMand TREM-NTC respectively).In the future, we will focus on improving theperformance of TREM by using more features,besides the weighting score.ReferencesC.
Manning and H. Schuetze.
1999.
Foundations of Sta-tistical Natural Language Processing.
MIT PressCambridge, Massachusetts.E.
Milios, Y. Zhang, B.
He, L. Dong.
2003.
AutomaticTerm Extraction and Document Similarity in SpecialText Corpora.
Proceedings of the 6th Conference ofthe Pacific Association for Computational Linguistics(PACLing'03), Halifax, Nova Scotia, Canada, pp.275-284.Evert, S. and B. Krenn.
2001.
Methods for QualitativeEvaluation of Lexical Association Measures.
Pro-ceedings of the 39th Annual Meeting of the Associa-tion for Computational Linguistics, pages 369 ?
381.Hideki Mima, Sophia Ananiadou.
2001.
An Applicationand Evaluation of the C/NC-Value Approach for theAutomatic Term Recognition of Multi-Word Units inJapanese.
International Journal on Terminology.Hiroshi Nakagawa, Tatsunori Mori.
2000.
AutomaticTerm Recognition based on Statistics of CompoundNouns.
Terminology, Vol.6, No.2, pp.195 ?
210.Hiroshi Nakagawa, Tatsunori Mori.
2002.
A Simple butPowerful Automatic Term Extraction Method.
2ndInternational Workshop on Computational Terminol-ogy, ACL.Katerine T. Frantzi, Sophia Ananiadou, and JunichiTsujii.
1998.
The C-Value/NC-Value Method ofAutomatic Recognition for Multi-word terms.
Journalon Research and Advanced Technology for DigitalLibraries.Kyo Kageura.
1996.
Methods of Automatic Term Rec-ognition - A Review.
Terminology, 3(2): 259 ?
289,1996.?pela Vintar.
2004.
Comparative Evaluation of C-valuein the Treatment of Nested Terms.
Memura 2004 ?Methodologies and Evaluation of Multiword Units inReal-World Applications.
Proceedings of the Interna-tional Conference on Language Resources andEvaluation 2004, pp.
54-57.636
