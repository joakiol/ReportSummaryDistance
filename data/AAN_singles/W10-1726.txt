Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 177?182,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsReproducible Results in Parsing-Based Machine Translation:The JHU Shared Task SubmissionLane Schwartz ?University of MinnesotaMinneapolis, MNlane@cs.umn.eduAbstractWe present the Johns Hopkins Univer-sity submission to the 2010 WMT sharedtranslation task.
We describe processingsteps using open data and open sourcesoftware used in our submission, and pro-vide the scripts and configurations re-quired to train, tune, and test our machinetranslation system.1 IntroductionResearch investigating natural language process-ing and computational linguistics can and shouldhave an extremely low barrier to entry.
The datawith which we work is customarily available incommon electronic formats.
The computationaltechniques which we apply can typically be per-formed on commodity computing resources whichare widely available.
In short, there should be noreason why small research groups and even loneresearchers should not be able to join and makesubstantive contributions furthering our field.
Thereality is less encouraging.Many published articles describe novel tech-niques and provide interesting results, yet fail todescribe technical details in sufficient detail to al-low their results to be reproduced by other re-searchers.
While there are notable and laudableexceptions, many publications fail to provide thesource code and scripts necessary to reproduce re-sults.
The use of restricted data, not freely avail-able for download by any interested researcheronly compounds these problems.
Pedersen (2008)rightly argues that the implementation details sooften ignored in publications are in fact essentialfor our research to be reproducible science.Reproducibility in machine translation is mademore challenging by the complexity of experi-mental workflows.
Results in machine translation?Research conducted as a visiting researcher at JohnsHopkins Universitytasks are dependent on a cascade of processingsteps and configurations.
While interesting sub-sets of these usually appear in experimental de-scriptions, many steps (preprocessing techniques,alignment parameters, translation rule extractionparameters, language model parameters, list offeatures used) are invariably omitted, even thoughthese configurations are often critical to reproduc-ing results.This paper describes the Johns Hopkins Univer-sity submission to the 2010 Workshop on Statis-tical Machine Translation shared translation task.Links to the software, scripts, and configurationsused to run the experiments described herein areprovided.
The remainder of this paper is struc-tured as follows.
Section 2 lists the major ex-amples of publicly available open source machinetranslation systems, parallel corpora, and machinetranslation workflow management systems.
Sec-tion 3 describes the experimental workflow usedto run the shared task translations, with the corre-sponding experimental design in section 4.
Sec-tion 5 presents the shared task results.2 Related WorkThe last four years have witnessed the implemen-tation and release of numerous open source ma-chine translation systems.
The widely used Mosessystem (Koehn et al, 2007) implements the stan-dard phrase-based translation model.
Parsing-based translation models are implemented byJoshua (Li et al, 2009), SAMT (Zollmann andVenugopal, 2006), and cdec (Dyer et al, 2010).Cunei (Phillips and Brown, 2009) implementsstatistical example-based translation.
Olteanu etal.
(2006) and Schwartz (2008) respectively pro-vide additional open-source implementations ofphrase-based and hierarchical decoders.The SRILM (Stolcke, 2002), IRSTLM (Fed-erico et al, 2008), and RandLM (Talbot and Os-borne, 2007) toolkits enable efficient training and177NormalizeRunMERTRunMBRonTruecasedTranslationsUnzipDataTokenizeHieroTranslateSubsampleforTruecasingTrainLMExtractTruecaseGrammarTrainTruecaseLMWMTScriptsSRILMRunMBRonTranslationsExtractGrammarAlignTruecasedDataAlignSubsampleRestoretoTruecaseJoshuaDownloadDataRemoveXMLBerkeleyAlignerFigure 1: Machine translation workflow.
Square nodes in grey indicate software and scripts.The scripts and configuration files used to implement and run this workflow are availablefor download at http://sourceforge.net/projects/joshua/files/joshua/1.3/wmt2010-experiment.tgz/download178querying of n-gram language models.Freely available parallel corpora for numer-ous European languages have also been releasedin recent years.
These include the Europarl(Koehn, 2005) and JRC-Acquis (Steinberger et al,2006) legislative corpora, each of which includesdata for most EU language pairs.
The smallerNews Commentary corpora (Callison-Burch et al,2007; Callison-Burch et al, 2008) provide smalleramounts of parallel data in the news genre.
The re-cent Fr-En 109 (Callison-Burch et al, 2009) cor-pus aggregates huge numbers of parallel French-English sentences from the web.Open source systems to address the complexworkflows required to run non-trivial machinetranslation experiments have also been developed.These include experiment.perl (Koehn etal., 2010), developed as a workflow managementsystem at the University of Edinburgh, and Loony-Bin (Clark et al, 2010), a general hyperworkflowmanagement utility from Carnegie Melon Univer-sity.3 Managing Experiment WorkflowsRunning a statistical machine translation system toachieve state-of-the-art performance involves theconfiguration and execution of numerous interde-pendent intermediate tools.
To manage task de-pendencies and tool configuration, our shared taskworkflow consists of a set of dependency scriptswritten for GNU Make (Stallman et al, 2006).Figure 1 shows a graph depicting the steps inour experimental workflow, and the dependenciesbetween steps.
Each node in the graph representsa step in the workflow; each step is implementedas a Make script that defines how to run the toolsrequired in that step.
In each experiment, an ad-ditional configuration script is provided for eachexperimental step, defining the parameters to beused when running that step in the current experi-ment.
Optional front-end wrapper scripts can alsobe provided, allowing for a complete experimentto be run - from downloading data and softwarethrough truecasing translated results - by execut-ing a single make file.This framework is also conducive to paralleliza-tion.
Many tasks, such as preprocessing numeroustraining files, are not dependent on one another.In such cases make can be configured to exe-cute multiple processes simultaneously on a singlemulti-processor machine.
In cases where sched-uled distributed computing environments such asthe Sun Grid Engine are configured, make files canbe processed by scheduler-aware make variants(distmake, SGE qmake, Sun Studio dmake)which distribute outstanding tasks to available dis-tributed machines using the relevant distributedscheduler.4 Experimental ConfigurationExperimental workflows were configured1 and runfor six language pairs in the translation sharedtask: English-French, English-German, English-Spanish, French-English, German-English, andSpanish-English.In all experiments, only data freely availablefor download was used.
No restricted data fromthe LDC or other sources was used.
Table 1 liststhe parallel corpora used in training the translationmodel for each experiment.
The monolingual cor-pora used in training each target language modelare listed in table 2.
In all experiments, news-test2008 was used as a development tuning corpusduring minimum error rate training; newstest2009was used as a development test set.
The sharedtask data set newstest2010 was used as a final blindtest set.All data was automatically downloaded, un-zipped, and preprocessed prior to use.
Files pro-vided in XML format were converted to plain textby selecting lines with <seg> tags, then removingthe beginning and end tags for each segment; thisprocessing was applied using GNU grep and sed.The tokenize.perl and lowercase.perlscripts provided for the shared task2 were appliedto all data.Interpolated n-gram language models for thefour target languages were built using the SRILanguage Model Toolkit3, with n-gram order setto 5.
The Chen and Goodman (1998) techniquefor modified Kneser-Ney discounting (Kneser andNey, 1995) was applied during language modeltraining.Following Li et al (2009), a subset of the avail-able training sentences was selected via subsam-1http://sourceforge.net/projects/joshua/files/joshua/1.3/wmt2010-experiment.tgz/download2http://www.statmt.org/wmt08/scripts.tgz with md5sum:tokenize.perl 45cd1832827131013245eca76481441alowercase.perl a1958ab429b1e29d379063c3b9cd70623http://www-speech.sri.com/projects/srilmSRILM version 1.5.7.
Our experimental workflow requiresthat SRILM be compiled separately, with the $SRILM envi-ronment variable set to the install location.179Source Target Parallel CorporaGerman English news-commentary10.de-en europarl-v5.de-enEnglish German news-commentary10.de-en europarl-v5.de-enFrench English news-commentary10.fr-en europarl-v5.fr-en giga-fren.release2 undoc.2000.en-frEnglish French news-commentary10.fr-en europarl-v5.fr-en giga-fren.release2 undoc.2000.en-frSpanish English news-commentary10.es-en europarl-v5.es-en undoc.2000.en-esEnglish Spanish news-commentary10.es-en europarl-v5.es-en undoc.2000.en-esTable 1: Parallel training data used for training translation model, per language pairTarget Monolingual CorporaEnglish europarl-v5.en news-commentary10.en news.en.shuffled undoc.2000.en-fr.en giga-fren.release2.enFrench europarl-v5.fr news-commentary10.fr news.fr.shuffled undoc.2000.en-fr.fr giga-fren.release2.frGerman europarl-v5.de news-commentary10.de news.de.shuffledSpanish europarl-v5.es news-commentary10.es news.es.shuffled undoc.2000.en-es.esTable 2: Monolingual training data used for training language model, per target languagepling; training sentences are selected based on theestimated likelihood of each sentence being usefullater for translating a particular test corpus.Given a subsampled parallel training corpus,word alignment is performed using the Berkeleyaligner4 (Liang et al, 2006).For each language pair, a synchronous contextfree translation grammar is extracted for a particu-lar test set, following the methods of Lopez (2008)as implemented in (Schwartz and Callison-Burch,2010).
For the largest training sets (French-English and English-French) the original (Lopez,2008) implementation included with Hiero wasused to save time during training5.Because of the use of subsampling, the ex-tracted translation grammars are targeted for usewith a specific test set.
Our experiments were be-gun prior to the release of the blind newstest2010shared task test set.
Subsampling was performedfor the development tuning set, news-test2008,and the development test set, newstest2009.
Oncethe newstest2010 test set was released, the processof subsampling, alignment, and grammar extrac-tion was repeated to obtain translation grammarstargeted for use with the shared task test set.Our experiments used hierarchical phrase-basedgrammars containing exactly two nonterminals -the wildcard nonterminal X, and S, used to glue4http://berkeleyaligner.googlecode.com/files/berkeleyalignerunsupervised-2.1.tar.gz ?
Berkeley aligner version 2.15It is expected that using the Joshua implementationshould result in nearly identical results, albeit with somewhatmore time required to extract the grammar.together neighboring constituents.
Recent workhas shown that parsing-based machine translationusing SAMT (Zollmann and Venugopal, 2006)grammars with rich nonterminal sets can demon-strate substantial gains over hierarchical grammarsfor certain language pairs (Baker et al, 2009).Joshua supports such grammars; the experimentalworkflow presented here could easily be extendedin future research to incorporate the use of SAMTgrammars with additional language pairs.The Z-MERT implementation (Zaidan, 2009) ofminimum error rate training (Och, 2003) was usedfor parameter tuning.
Tuned grammars were usedby Joshua to translate all test sets.
The Joshua de-coder produces n-best lists of translations.Rather than simply selecting the top candidatefrom each list, we take the preferred candidate af-ter perform minimum Bayes risk rescoring (Ku-mar and Byrne, 2004).Once a single translation has been extractedfor each sentence in the test set, we repeat theprocedures described above to train language andtranslation models for use in translating lower-cased results into a more human-readable true-cased form.
A truecase language model istrained as above, but on the tokenized (but notnormalized) monolingual target language corpus.Monotone word alignments are deterministicallycreated, mapping normalized lowercase trainingtext to the original truecase text.
As in bilin-gual translation, subsampling is performed forthe training set, and a translation grammar forlowercase-to-truecase is extracted.
No tuning is180performed.
The Joshua decoder is used to trans-late the lowercased target language test results intotruecase format.
The detokenize.perl andwrap-xml.perl scripts provided for the sharedtask were manually applied to truecased transla-tion results prior to final submission of results.The code used for subsampling, grammar ex-traction, decoding, minimum error rate training,and minimum Bayes risk rescoring is providedwith Joshua6, with the exception of the original(Lopez, 2008) grammar extraction implementa-tion.5 Experimental ResultsThe experiments described in sections 3 and4 above provided truecased translations forsix language pairs in the translation sharedtask: English-French, English-German, English-Spanish, French-English, German-English, andSpanish-English.
Table 3 lists the automatic met-ric scores for the newstest2010 test set, accord-ing to the BLEU (Papineni et al, 2002) and TER(Snover et al, 2006) metrics.Source Target BLEU BLEU- TERcasedGerman English 21.3 19.5 0.660English German 15.2 14.6 0.738French English 27.7 26.4 0.614English French 23.8 22.8 0.681Spanish English 29.0 27.6 0.595English Spanish 28.1 26.5 0.596Table 3: Automatic metric scores for the test setnewstest2010The submitted system ranked highest amongshared task participants for the German-Englishtask, according to TER.In order to provide points of comparison withthe 2009 Workshop on Statistical Machine Trans-lation shared translation task participants, table4 lists automatic metric scores for our systems?translations of the newstest2009 test set, which weused as a development test set.6 Steps to ReproduceThe experiments in this paper can be reproducedby running the make scripts provided in the6http://sourceforge.net/projects/joshua/files/joshua/1.3/joshua-1.3.tgz/download ?
Joshua version 1.3Source Target BLEUGerman English 18.19English German 13.57French English 26.41English French 25.28Spanish English 25.28English Spanish 24.02Table 4: Automatic metric scores for the develop-ment test set newstest2009following file: http://sourceforge.net/projects/joshua/files/joshua/1.3/wmt2010-experiment.tgz/download.The README file details how to configure theworkflow for your environment.
Note that SRILMmust be downloaded and compiled separatelybefore running the experimental steps.AcknowledgementsThis work was supported by the DARPA GALEprogram (Contract No HR0011-06-2-0001).ReferencesKathy Baker, Steven Bethard, Michael Bloodgood,Ralf Brown, Chris Callison-Burch, Glen Copper-smith, Bonnie Dorr, Wes Filardo, Kendall Giles,Anni Irvine, Mike Kayser, Lori Levin, Justin Mar-tineau, Jim Mayfield, Scott Miller, Aaron Phillips,Andrew Philpot, Christine Piatko, Lane Schwartz,and David Zajic.
2009.
Semantically informed ma-chine translation (SIMT).
SCALE summer work-shop final report, Human Language TechnologyCenter Of Excellence.Chris Callison-Burch, Cameron Fordyce, PhilippKoehn, Christof Monz, and Josh Schroeder.
2007.
(Meta-) evaluation of machine translation.
In Pro-ceedings of the Second Workshop on Statistical Ma-chine Translation (WMT07).Chris Callison-Burch, Cameron Fordyce, PhilippKoehn, Christof Monz, and Josh Schroeder.
2008.Further meta-evaluation of machine translation.
InProceedings of the Third Workshop on StatisticalMachine Translation (WMT08).Chris Callison-Burch, Philipp Koehn, Christof Monz,and Josh Schroeder.
2009.
Findings of the 2009Workshop on Statistical Machine Translation.
InProceedings of the Fourth Workshop on StatisticalMachine Translation (WMT09), March.Stanley Chen and Joshua Goodman.
1998.
An em-pirical study of smoothing techniques for languagemodeling.
Technical Report TR-10-98, HarvardUniversity, Cambridge, MA, USA, August.181Jonathan Clark, Jonathan Weese, Byung Gyu Ahn,Andreas Zollman, Qin Gao, Kenneth Heafield, andAlon Lavie.
2010.
The machine translation tool-pack for LoonyBin: Automated management ofexperimental machine translation hyperworkflows.The Prague Bulletin of Mathematical Linguistics,93:117?126, January.C.
Dyer, A. Lopez, J. Ganitkevitch, J. Weese,F.
Ture, P. Blunsom, H. Setiawan, V. Eidelman, andP.
Resnik.
2010. cdec: A decoder, alignment, andlearning framework for finite-state and context-freetranslation models.
In Proc.
ACL (DemonstrationTrack), Uppsala, Sweden.Marcello Federico, Nicola Bertoldi, and Mauro Cet-tolo.
2008.
IRSTLM: An open source toolkit forhandling large scale language models.
In Proc.
In-terspeech, Brisbane, Australia.Reinhard Kneser and Hermann Ney.
1995.
Improvedsmoothing for mgram language modeling.
In Pro-ceedings of the International Conference on Acous-tics, Speech and Signal Processing.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InProc.
ACL-2007 Demo and Poster Sessions.Philipp Koehn, Anthony Rousseau, Ben Gottesmann,Aurora Marsye, Fre?de?ric Blain, and Eun-Jin Park,2010.
An Experiment Management System.
FourthMachine Translation Marathon, Dublin, Ireland,January.Philipp Koehn.
2005.
A parallel corpus for statisticalmachine translation.
In Proceedings of MT-Summit,Phuket, Thailand.Shankar Kumar and William Byrne.
2004.
Minimumbayes-risk decoding for statistical machine transla-tion.
In Proceedings of HLT/NAACL.Zhifei Li, Chris Callison-Burch, Chris Dyer, Juri Gan-itkevitch, Sanjeev Khudanpur, Lane Schwartz, WrenThornton, Jonathan Weese, and Omar Zaidan.
2009.Joshua: An open source toolkit for parsing-basedmachine translation.
In Proceedings of the FourthWorkshop on Statistical Machine Translation, pages135?139, Athens, Greece, March.
Association forComputational Linguistics.P.
Liang, B. Taskar, and D. Klein.
2006.
Align-ment by agreement.
In North American Associationfor Computational Linguistics (NAACL), pages 104?111.Adam Lopez.
2008.
Machine Translation by PatternMatching.
Ph.D. thesis, University of Maryland.Franz Josef Och.
2003.
Minimum error rate trainingfor statistical machine translation.
In Proceedingsof ACL.Marian Olteanu, Chris Davis, Ionut Volosen, and DanMoldovan.
2006.
Phramer an open source statis-tical pharse-based translator.
In HLT-NAACL 2006:Proceedings of the Workshop on Statistical MachineTranslation, New York, June.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: A method for automaticevaluation of machine translation.
In Proceedingsof ACL.Ted Pedersen.
2008.
Empiricism is not a matter offaith.
Computational Linguistics, 34(3):465?470.Aaron B. Phillips and Ralf D. Brown.
2009.
Cunei ma-chine translation platform: System description.
In3rd Workshop on Example-Based Machine Transla-tion, Dublin, Ireland.Lane Schwartz and Chris Callison-Burch.
2010.
Hier-archical phrase-based grammar extraction in joshuasuix arrays and prex trees.
The Prague Bulletin ofMathematical Linguistics, 93:157?166.Lane Schwartz.
2008.
An open-source hierarchicalphrase-based translation system.
In Proceedings ofthe 5th Midwest Computational Linguistics Collo-quium (MCLC?08), May.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A study oftranslation edit rate with targeted human annotation.In Proceedings of AMTA.Richard M. Stallman, Roland McGrath, and Paul D.Smith, 2006.
GNU Make.
Free Software Founda-tion, Boston, MA, 0.70 edition, April.Ralf Steinberger, Bruno Pouliquen, Anna Widiger,Camelia Ignat, Tomaz Erjavec, Dan Tufis, andDaniel Varga.
2006.
The JRC-acquis: A multi-lingual aligned parallel corpus with 20+ languages.In Proceedings of the 5th International Conferenceon Language Resources and Evaluation (LREC),Genoa, Italy.Andreas Stolcke.
2002.
SRILM - an extensible lan-guage modeling toolkit.
In Proceedings of the Inter-national Conference on Spoken Language Process-ing, Denver, Colorado, September.David Talbot and Miles Osborne.
2007.
Randomisedlanguage modelling for statistical machine transla-tion.
In Proceedings of ACL.Omar F. Zaidan.
2009.
Z-MERT: A fully configurableopen source tool for minimum error rate training ofmachine translation systems.
The Prague Bulletin ofMathematical Linguistics, 91:79?88.Andreas Zollmann and Ashish Venugopal.
2006.
Syn-tax augmented machine translation via chart pars-ing.
In Proceedings of the NAACL-2006 Workshopon Statistical Machine Translation (WMT-06), NewYork, New York.182
