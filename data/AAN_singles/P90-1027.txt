AUTOMATED INVERSION OF  LOGIC  GRAMMARS FOR GENERATIONTomek Strzalkowski and Ping PengCourant Institute of  Mathematical SciencesNew York University251 Mercer StreetNew York, NY 10012ABSTRACTWe describe a system of reversible grammar inwhich, given a logic-grammar specification of anatural anguage, two efficient PROLOG programs arederived by an off-line compilation process: a parserand a generator for this language.
The centerpiece ofthe system is the inversion algorithm designed tocompute the generator code from the parser's PRO-LOG code, using the collection of minimal sets ofessential arguments (MSEA) for predicates.
The sys-tem has been implemented to work with DefiniteClause Grammars (DCG) and is a part of anEnglish-Japanese machine translation projectcurrently under development a  NYU's Courant Insti-tute.INTRODUCTIONThe results reported in this paper are part of theongoing research project o explore possibilities of anautomated derivation of both an efficient parser andan efficient generator for natural anguage, such asEnglish or Japanese, from a formal specification forthis language.
Thus, given a grammar-like descrip-tion of a language, specifying both its syntax as wellas "semantics" (by which we mean a correspondenceof well-formed expressions of natural language toexpressions of a formal representation language) wewant to obtain, by a fully automatic process, two pos-sibly different programs: a parser and a generator.The parser will translate well-formed expression ofthe source language into expressions of the languageof "semantic" representation, such as regularizedoperator-argument forms, or formulas in logic.
Thegenerator, on the other hand, will accept well-formedexpressions of the semantic representation languageand produce corresponding expressions in the sourcenatural anguage.Among the arguments for adopting the bidirec-tional design in NLP the following are perhaps themost widely shared:?
A bidirectional NLP system, or a system whoseinverse can be derived by a fully automated pro-cess, greatly reduces effort required for the sys-tem development, since we need to write only oneprogram or specification instead of two.
Theactual amount of savings ultimately depends uponthe extend to which the NLP system is madebidirectional, for example, how much of thelanguage analysis process can be inverted for gen-eration.
At present we reverse just a little morethan a syntactic parser, but the method can beapplied to more advanced analyzers as well.?
Using a single specification (a grammar) underly-ing both the analysis and the synthesis processesleads to more accurate capturing of the language.Although no NLP grammar is ever complete, thegrammars used in parsing tend to be "too loose",or unsound, in that they would frequently acceptvarious ill-formed strings as legitimate sentences,while the grammars used for generation are usu-ally made "too tight" as a result of limiting theiroutput o the "best" surface forms.
A reversiblesystem for both parsing and generation requires afinely balanced grammar which is sound and ascomplete as possible.?
A reversible grammar provides, by design, thematch between system's analysis and generationcapabilities, which is especially important ininteractive systems.
A discrepancy in this capa-city may mislead the user, who tends to assumethat what is generated as output is also acceptableas input, and vice-versa.?
Finally, a bidirectional system can be expected tobe more robust, easier to maintain and modify,and altogether more perspicuous.In the work reported here we concenlrated onunification-based formalisms, in particular DefiniteClause Grammars (Pereira & Warren, 1980), whichcan be compiled ually into PROLOG parser and gen-erator, where the generator is obtained from theparser's code with the inversion procedure describedbelow.
As noted by Dymetman and Isabelle (1988),this transformation must involve rearranging theorder of literals on the right-hand side of someclauses.
We noted that the design of the string gram-mar (Sager, 1981) makes it more suitable as a basisof a reversible system than other grammar designs,although other grammars can be "normalized"(Strzalkowski, 1989).
We also would like to point outthat our main emphasis is on the problem of212reversibility rather than generation, the latter involv-ing many problems that we don't deal with here (see,e.g.
Derr & McKeown, 1984; McKeown, 1985).RELATED WORKThe idea that a generator for a language mightbe considered as an inverse of the parser for the samelanguage has been around for some time, but it wasonly recently that more serious attention started to bepaid to the problem.
We look here only very brieflyat some most recent work in unificatlon-hased gram-mars.
Dymelman and Isabelle (1988) address theproblem of inverting a definite clause parser into agenerator in context of a machine translation systemand describe a top-down interpreter with dynamicselection of AND goals 1(and therefore more flexiblethan, say, left-to-right interpreter) that can execute agiven DCG grammar in either direction dependingonly upon the binding status of arguments in the top-level literal.
This approach, although conceptuallyquite general, proves far too expensive in practice.The main source of overhead comes, it is pointed out,from employing the nick known as goal freezing(Colmerauer, 1982; Naish, 1986), that stops expan-sion of currently active AND goals until certain vari-ables get instantiated.
The cost, however, is not theonly reason why the goal freezing techniques, andtheir variations, are not satisfactory.
As Shieber et al(1989) point out, the inherently top-down characterof goal freezing interpreters may occasionally causeserious troubles during execution of certain types ofrecursive goals.
They propose to replace thedynamic ordering of AND goals by a mixed top-down/bottom-up interpretation.
I  this technique, cer-tain goals, namely those whose expansion is definedby the so-called "chain rules "2, are not expanded dur-ing the top-down phase of the interpreter, but insteadthey are passed over until a nearest non-chain rule isreached.
In the bottom-up hase the missing parts ofthe goal-expansion tree will be filled in by applyingthe chain rules in a backward manner.
This tech-nique, still substantially more expensive than afixed-order top-down interpreter, does not by itselfguarantee that we can use the underlying rammarformalism bidirectionally.
The reason is that in orderto achieve bidirectionality, we need either to imposea proper static ordering of the "non-chain" AND* Literals on the right-hand side of a clause create ANDgoals; llterals with the same predicate names on the left-hand sidesof different ehuses create OR goals.2 A chain rule is one where the main binding-canying argu-ment is passed unchanged from the left-hand side to the righL Forexample, assert (P) --> subJ (PI), verb (P2),obJ (P1, P2, P).
is a chain rule with respect to the argmnent P.goals (i.e., those which are not responsible for mak-ing a rule a "chain rule"), or resort o dynamic order-ing of such goals, putting the goal freezing back intothe picture.In contrast with the above, the parser inversionprocedure described in this paper does not require arun-time overhead and can be performed by an off-line compilation process.
It may, however, requirethat the grammar is normalized prior to its inversion.We briefly discuss the grammar normalization prob-lem at the end of this paper.IN AND OUT ARGUMENTSArguments in a PROLOG literal can be markedas either "in" or "out" depending on whether they arebound at the time the literal is submitted for execu-tion or after the computation is completed.
Forexample, intovo  ( \[to, eat,  f i sh \ ] ,  T4,\[np, \[n, john\]  \] ,P3)the first and the third arguments are "in", while theremaining two are "out".
When tovo  is used forgeneration, i.e.,tovo  (TI, T4, PI,\[eat, \[rip, \[n, john\]  \],\[np, \[n, f i sh\ ]  \] \] )then the last argument is "in", while the first and thethird are "out"; T4 is neither "in" nor "out".
Theinformation about "in" and "out" status of argumentsis important in determining the "direction" in whichpredicates containing them can be run s .
Below wepresent a simple method for computing "in" and"out" arguments inPROLOG l iterals.
4An argument X of literal pred( ' "  X " "  ) onthe rhs of a clause is "in" if (A) it is a constant; or (B)it is a function and all its arguments are "in"; or (C) itis "in" or "out" in some previous literal on the rhs ofthe same clause, i.e., I(Y) :-r(X,Y),pred(X); or (D)it is "in" in the head literal L on lhs of the sameclause.An argument X is "in" in the head literalL = pred( .
.
.
X .
.
.  )
of a clause if (A), or (B), or (E)L is the top-level literal and X is "in" in it (known apriori); or ~ X occurs more than once in L and ats For a discussion on directed predicates in~OLOO see (Sho-ham and McDermott, 1984), and (Debray, 1989).4 This simple algorithm is all we need to complete the exper-iment at hand.
A general method for computing "in"/"out" argu-ments is given in (Strzalkowski, 1989).
In this and further algo-rithms we use abbreviations rhs and lhs to stand for right-hand sideand left-hand side (of a clause), respectively.213least one of these occurrences i "in"; or (G) forevery literal L 1 = pred (" ?
?
Y"  ?
? )
unifiable with Lon the rhs of any clause with the head predicatepredl  different han pred, and such that Y unifieswith X, Yis "in" inL1.A similar algorithm can be proposed for com-puting "out" arguments.
We introduce "unknwn" as athird status marker for arguments occurring in certainrecursive clauses.An argument X of literal pred ( .
?
?
X .
.
.  )
onthe rhs of a clause is "out" if (A) it is "in" inpred( .
.
.
X ?
?
?
); or (B) it is a functional expressionand all its arguments are either "in" or "out"; or (C)for every clause with the head literalpred(  .
.
.
Y ?
?
? )
unifiable with pred(  " ?
X " "  ) andsuch that Y unifies with X, Y is either "in", "out" or"unknwn", and Y is marked "in" or "out" in at leastone case.An argument X of literal pred( .
.
.
X .
.
.  )
onthe lhs of a clause is "out" if (D) it is "in" inpred( . '
.X .
.
. )
;  or (E) it is "out" in literalpred l ( "  ?
?
X .
. "
) on the rhs of this clause, providingthat predl  ~ pred; 5 if predl  = pred then X is marked"unknwn".Note that this method predicts the "in" and"out" status of arguments in a literal only if theevaluation of this literal ends successfully.
In case itdoes not (a failure or a loop) the "in"/"out" status ofarguments becomes irrelevant.COMPUTING ESSENTIAL ARGUMENTSSome arguments of every literal are essential inthe sense that the literal cannot be executed success-fully unless all of them are bound, at least partially, atthe time of execution.
For example, the predicatet ovo  ( T 1, T 4, P 1, P 3 ) that recognizes"to+verb+object" object strings can be executed onlyif either T1 or P3 is bound.
67 If tovo  is used toparse then T:I. must be bound; if it is used to gen-erate then P3 must be bound.
In general, a literalmay have several alternative (possibly overlapping)sets of essential arguments.
If all arguments in anyone of such sets of essential arguments are bound,s Again, we must take provisions to avoid infinite descend,c.f.
(G) in "in" algorithm.6 Assuming that tovo  is defined as follows (simplified):tovo(T1,T4,P1,P3) : -  to(T1,T2), v(T2,T3,P2),object (T3, T4,P1,P2,P3).7 An argument is consideredfu/ly bound is it is a constant orit is bound by a constant; an argument is partially bound if it is, oris bound by, a functional expression (not a variable) in which atleast one variable is unbound.214then the literal can be executed.
Any set of essentialarguments which has the above property is calledessential.
We shall call a set MSEA of essential argu-ments a minimal set o f  essential arguments if it isessential, and no proper subset of MSEA is essential.A collection of minimal sets of essential argu-ments (MSEA's)  of a predicate depends upon the waythis predicate is defined.
If we alter the ordering ofthe rhs literals in the definition of a predicate, wemay also change its set of MSEA's .
We call the setof MSEA's  existing for a current definition of a predi-cate the set of active MSEA 's  for this predicate.
Torun a predicate in a certain direction requires that aspecific MSEA is among the currently active MSEA'sfor this predicate, and if this is not already the case,then we have to alter the definition of this predicateso as to make this MSEA become active.
Considerthe following abstract clause defining predicate RfR i (X1 , " "  ,Xk):- (D1)Q I ( ' "  "),Q2( ' " ) ,a , ( .
.
. )
.Suppose that, as defined by (D1), Ri has the setMSi  ={ml, "" ?
,mj} of active MSEA's ,  and let MRi  ~ MSibe the set of all MSEA for Ri that can be obtained bypermuting the order of literals on the right-hand sideof (D1).
Let us assume further that R i occurs on rhsof some other clause, as shown below:e(x l , ' "  ,x.
):- (C1)R 1 (X1.1, "'" ,Xl,kl),R2(X2,1, .
.
.
,X2,kz),R,(X,, 1,""  ,X,,k,):We want to compute MS, the set of active MSEA'sfor P, as defined by (C1), where s _> 0, assuming thatwe know the sets of active MSEA for each R i on therhs.
s If s =0, that is P has no rhs in its definition, thenif P (X1, "'" ,X~) is a call to P on the rhs of someclause and X* is a subset of {X1, "'" ,X~} then X* isa MSEA in P if X* is the smallest set such that allarguments inX* consistently unify (at the same time)with the corresponding arguments in at most Ioccurrence of P on the lhs anywhere in the program.
9s MSEA's  of basic predicates, uch as concat, are assumed tobe known a priori; MSEA's  for reeursive predicates are first com-puted from non-n~cursive clauses.9 The at most 1 requirement is the strictest possible, and itcan be relaxed to at most n in specific applications.
The choice of nmay depend upon the nature of the input language being processed(it may be n-degree ambiguous), and/or the cost of backing upfrom unsuccessful calls.
For example, consider the words everyand all: both can be translated into a single universal quantifier, butupon generation we face ambiguity.
If the representation fromWhen s ___ 1, that is, P has at least one literal onthe rhs, we use the recursive procedure MSEAS tocompute the set of MSEA's for P, providing that wealready know the set of MSEA's for each literaloccurring on the rhs.
Let T be a set of terms, that is,variables and functional expressions, then VAR (T) isthe set of all variables occurring in the terms of T.Thus VAR({f(X),Y,g(c,f(Z),X)}) = {X,?,Z}.
Weassume that symbols Xi in definitions (C1) and (D1)above represent terms, not just variables.
The follow-ing algorithm is suggested for computing sets ofactive MSEA's in P where i >1.MSEAS (MS,MSEA, VP,i, OUT)(1) Start with VP =VAR({X1,-' .
,X,}), MSEA =Z, i=1, and OUT = ~.
When the computation iscompleted, MS is bound to the set of activeMSEA's for P.(2) Let MR 1 be the set of active MSEA's of R 1, andlet MRU1 be obtained from MR 1 by replacing allvariables in each member of MR1 by theircorresponding actual arguments of R 1 on the rhsof (C1).
(3) I fR I = P then for every ml.k e MRU1 if everyargument Y, e m 1,k is always unifiable with itscorresponding argument Xt in P then removeml.k from MRUI.
For every set ml.,i = ml,k u{XI.j}, where X1j is an argument in R1 suchthat it is not already in m ~,~ and it is not alwaysunifiable with its corresponding argument in P,and m 1,kj is not a superset of any other m uremaining in MRUI, add m 1.kj to MRUl.10(4) For each ml j  e MRU1 ( j= l ' " r l )  computeI.h.j := VAR(ml:)  c~ VP.
Let MP 1 = {IXl,j I~(I.h,j), j= l .
.
- r '} ,  where r>0, and ~(dttl,j) =\[J.tl, j ~: Q~ or (LLh, j = O and VAR(mI,j) = O)\].
IfMP1 = O then QUIT: (C1) is ill-formed and can-not be executed.which we generate is devoid of any constraints on the lexiealnumber of surface words, we may have to tolerate multiplechoices, at some point.
Any decision made at this level as to whicharguments are to be essential, may affect the reversibility of thegrammar.l0 An argument Y is always unifiable with an argument X ifthey unify regardless of the possible bindings of any variables oc-curring in Y (variables tandardized apart), while the variables oc-curring in X are unbound.
Thus, any term is always unifiable witha variable; however, a variable is not always unifiable with a non-variable.
For example, variable X is not always unifiable with f (Y)because if we substitute g (Z) for X then the so obtained terms donot unify.
The purpose of including steps (3) and (7) is to elim-inate from consideration certain 'obviously' ill-formed reeursiveclauses.
A more elaborate version of this condition is needed totake care of less obvious cases.215(5) For each ~h,j e MP1 we do the following: (a)assume that ~tl, j is "in" in R1; (b) compute setOUT1j of "out" arguments for R1; (c) callMSEAS(MSI,j,IXl.j,VP,2,0UTIj); (d) assignMS := t,_) MS 1,j.j=l..r(6) In some i-th step, where l<i<s, and MSEA =lxi-l,,, let's suppose that MRi and MRUi are thesets of active MSEA's and their instantiationswith actual arguments of R i, for the literal Ri onthe rhs of (C 1).
(7) If R i = P then for every mi.
u E MRUi if everyargument Yt e mi.
u is always unifiable with itscorresponding argument Xt in P then removemi.u from MRUi.
For every set mi.uj = mi.u u{Xij } where X u is an argument inR~ such that itis not already in mio u and it is not alwaysunifiable with its corresponding argument in Pand rai, uj is not a superset of any other rai, tremaining in MRUi, add mi.,j to MRU I.
(8) Again, we compute the set MPi = {!%.i Ij= l  .
.
.
r  i}, where ~tid = (VAR (mij) -OUTi_l,k), where OUTi_I, ~ is the set of all "out"arguments in literals R 1 to Ri_ 1 .
(9) For each I.t/d remaining in Me i where i$.s do thefollowing:(a) if lXij = O then: (i) compute the set OUTj of"out" arguments ofRi; (ii) compute the unionOUTi.j := OUTj u OUTi-l.k; (iii) callMSEAS (MSi.j,~ti_I.k, VP,i + I,OUTI.j);Co) otherwise, if ~ti.j *: 0 then find all distinctminimal size sets v, ~ VP such that wheneverthe arguments in v, are "in", then the argu-ments in l%d are "out".
If such vt's exist, thenfor every v, do: (i) assume vt is "in" in P; (ii)compute the set OUT,.j, of "out" arguments inall literals from R1 to Ri; (iii) callMSEAS (MSi.
h,la i_l,*t.mt, VP,i + 1,OUTi, h);(c) otherwise, if no such v, exist, MSid := ~.
(10)Compute MS := k.) MSi.y;j f l .
.
r(11)For i=s+l setMS := {MSEA}.The procedure presented here can be modified tocompute the set of all MSEA's for P by consideringall feasible orderings of literals on the rhs of (C1) andusing information about all MSEA's for Ri's.
Thismodified procedure would regard the rhs of (C1) asan tmordered set of literals, and use various heuristicsto consider only selected orderings.REORDERING LITERALS IN CLAUSESWhen attempting toexpand a literal on the rhsof any clause the following basic rule should beobserved: never expand a literal before at least one itsactive MSEA's is "in", which means that all argu-ments in at least one MSEA are bound.
The followingalgorithm uses this simple principle to reorder hs ofparser clauses for reversed use in generation.
Thisalgorithm uses the information about "in" and "out"arguments for literals and sets of MSEA's for predi-cates.
If the "in" MSEA of a literal is not active thenthe rhs's of every definition of this predicate is recur-sively reordered so that the selected MSEA becomesactive.
We proceed top-down altering definitions ofpredicates of the literals to make their MSEA's activeas necessary.
When reversing a parser, we start withthe top level predicate pa=a_gen (S, P) assumingthat variable t, is bound to the regularized parsestructure of a sentence.
We explicitly identify andmark P as "in" and add the requirement that S mustbe marked "out" upon completion of rhs reordering.We proceed to adjust he definition of para_gen toreflect hat now {P} is an active MSEA.
We continueuntil we reach the level of atomic or non-reversibleprimitives such as concat, member, or dictionarylook-up routines.
If this top-down process ucceeds atreversing predicate definitions at each level down tothe primitives, and the primitives need no re-definition, then the process is successful, and thereversed-parser generator is obtained.
The algorithmcan be extended in many ways, including inter-clausal reordering of literals, which may be requiredin some situations (Strzalkowski, 1989).INVERSE("head :- old-rhs",ins,outs);{ins and outs are subsets of VAR(head) whichare "in" and are required to be "out", respectively}begincompute M the set of all MSEA's for head;for every MSEA m e M dobeginOUT := ~;if m is an active MSEA such that me ins thenbegincompute "out" arguments inhead;add them to OUT;if outs cOUT then DONEChead:-old-rhs" )endelse if m is a non-active MSEA and m cins thenbeginnew-rhs := ~; QUIT := false;old-rhs-1 := old-rhs;for every literal L doM L := O;{done only once during the inversion}repeatmark "in" old-rhs-1 arguments which areeither constants, or marked "in" in head,or marked "in", or "out" in new-rhs; 216select a literal L in old-rhs-1 which hasan "in" MSEA m L and if m L is not active in Lthen either M L = O or m L e ML;set up a backtracking point containingall the remaining alternativesto select L from old-rhs-1;if L exists thenbeginif m L is non-active in L thenbeginif M L -- ~ then M L := M L u {mL};for every clause "L1 :- rhsu" such thatL1 has the same predicate as L dobeginINVERSECL1 :- rhsm",ML,~);if GIVEUP returned then backup, undoingall changes, to the latest backtrackingpoint and select another alternativeendend;compute "in" and "out" arguments in L;add "out" arguments o OUT;new-rhs := APPEND-AT-THE-END(new-rhs,L);old-rhs- 1 := REMOVE(old-rhs- 1,L)end {if}else beginbackup, undoing all changes, to the latestbacktracking point and select anotheralternative;if no such backtracking point exists thenQUIT := trueend {else}until old-rhs-1 = O or QUIT;if outs cOUT and not QUIT thenDONE("head:-new-rhs")end {elseif}end; {for}GIVEUPCcan't invert as specified")end;THE IMPLEMENTATIONWe have implemented an interpreter, whichtranslates Definite Clause Grammar dually into aparser and a generator.
The interpreter firsttransforms a DCG grammar into equivalent PROLOGcode, which is subsequently inverted into a generator.For each predicate we compute the minimal sets ofessential arguments that would need to be active ifthe program were used in the generation mode.
Next,we rearrange the order of the fight hand side literalsfor each clause in such a way that the set of essentialarguments in each literal is guaranteed to be boundwhenever the literal is chosen for expansion.
Toimplement the algorithm efficiently, we compute theminimal sets of essential arguments and reorder theliterals in the right-hand sides of clauses in one passthrough the parser program.
As an example, we con-sider the following rule in our DCG grammar: 11asser t ion  (S) ->sa  (SI) ,subject  (Sb),sa  ($2),verb  (V) ,{Sb:np:number  :: V:number},sa  (S3),object  (O,V, Vp, Sb, Sp),sa  ($4) ,{S.verb :head : : Vp:head},{S:verb:number  :: V:number},{S: tense  : : \ [V : tense ,  O : tense \ ]  },{S:subject  :: Sp},{S:object  :: O:core},{S:sa  : :\[$1: sa, $2 : sa, $3: sa,O: sa, S4 : sa\] }.When lranslated into PROLOG, it yields the followingclause in the parser:asser t ion  (S, LI, L2) ?
-sa  (SI, LI ,  L3) ,subject  (Sb, L3, L4),sa  (S2, L4, L5) ,verb  (V, L5, L6) ,Sb :np :number  :: V:number,sa  (S3, L6, L7),ob ject  (0, V, Vp, Sb, Sp, L7, L8),sa  ($4, L8, L2) ,S:verb :head : : Vp:head,S :verb :number  :: V:number,S: tense  :: \ [V : tense ,O: tense \ ] ,S:sub ject  : : Sp,S :ob ject  :: O:core,S:sa  : :\ [S l : sa ,  S2 :sa ,  S3 :sa ,O:sa ,  S4 :sa \ ]  .The parser program is now inverted using the algo-rithms described in previous ections.
As a result, theasser t ion  clause above is inverted into a genera-tor clause by rearranging the order of the literals onits right-hand side.
The literals are examined from theleft to right: if a set of essential arguments i bound,the literal is put into the output queue, otherwise thett The grammar design is based upon string rammar (Sager,1981).
Nonterminal net stands for a string of sentence adjuncts,such as prepositional or adverbial phrases; : : is a PROLOG-definedpredicate.
We show only one rule of the grammar due to the lackof space.217literal is put into the waiting stack.
In the example athand, the literal sa  (S l ,  L1, L3) is examined first.Its MSEA is {Sl}, and since it is not a subset of theset of variables appearing in the head literal, this setcannot receive a binding when the execution ofasser t ion  starts.
It may, however, contain "out"arguments in some other literals on the right-handside of the clause.
We thus remove the first saliteral from the clause and place it on hold until itsMSEA becomes fully instantiated.
We proceed toconsider the remaining literals in the clause in thesame manner, until we reach S: verb  ?
head : ?Vp : head.
One MSEA for this literal is { S }, which isa subset of the arguments in the head literal.
We alsodetermine that S is not an "out" argument in anyother literal in the clause, and thus it must be boundin asser t ion  whenever the clause is to be exe-cuted.
This means, in turn, that S is an essentialargument in asser t ion .
As we continue this pro-cess we find that no further essential arguments arerequired, that is, {S} is a MSEA for asser t ion .The literal S : verb: head : : Vp: head  is out-put and becomes the top element on the right-handside of the inverted clause.
After all literals in theoriginal clause are processed, we repeat his analysisfor all those remaining in the waiting stack until allthe literals are output.
We add prefix g_  to eachinverted predicate in the generator to distinguishthem from their non-inverted versions in the parser.The inverted asser t ion  predicate as it appears inthe generator is shown below.g_asser t ion  (S, L1, L2) ?
-S :verb :head  :: Vp:head,S :verb :number  :: V:number,S: tense  :: \ [V : tense ,O: tense \ ] ,S:subject  : : Sp,S:object  :: O:core,S:sa  : :\[SI : sa, $2 : sa, $3 : sa, O: sa, $4 : sa\] ,g_sa ($4, L3, L2) ,g_ob ject  (O,V, Vp, Sb, Sp, L4, L3),g_sa ($3, L5, L4),Sb :np:number  :: V:number,g_verb (V, L6, L5),g_sa  ($2, L7, L6) ,g_sub ject  (Sb, L8, L7),g_sa  ($1, LI, L8) .A single grammar is thus used both for sentence pars-ing and for generation.
The parser or the generator isinvoked using the same top-level predicatepars_gen(S,P)  depending upon the bindingstatus of its arguments: if S is bound then the parseris invoked, if P is bound the generator is called.I ?-yesI ?-P =yesload_gram (grammar) .pars_gen(\[jane,takes,a,course\],P).\[\[catlassertion\],\[tense,present,\[\]\],\[verbltake\],\[subject,\[np,\[headljane\],\[numberlsingular\],\[classlnstudent\],\[tpos\],\[apos\] ,\[modifier, null\] \] \],\[object,\[np,\[headlcourse\],\[numberlsingular\],\[classlncourse\],\[tpos I a\],\[apos\] ,\[modifier, null\] \] \],\[sa, \[1, \[1, \[1, \[1, \[111?- pars_gen(S,\[\[catlassertion\],\[tense,present,\[\]\],\[verbltake\],\[subject,\ [np, \ [headl jane\ ] ,\[numberlsingular\],\[classlnstudent\],\[tpos\],\[apos\],\[modifier, null\]\]\],\[object,\[np,\[headlcourse\],\[numberlsingular\],\[classlncourse\],\[tposla\],\[apos\],\[modifier,null\]I\],\[sa,\[\],\[\],\[\],\[\],\[\]\]\]).S = \ [ jane,takes,  a, course\]yesGRAMMAR NORMALIZATIONThus far we have tacitly assumed that thegrammar upon which our parser is based is wriuen in218such a way that it can be executed by a top-downinterpreter, such as the one used by PROLOG.
If this isnot the case, that is, if the grammar equires a dif-ferent kind of interpreter, then the question of inverti-bility can only be related to this particular type ofinterpreter.
If we want to use the inversion algorithmdescribed here to invert a parser written for an inter-preter different han top-down and left-to-right, weneed to convert he parser, or the grammar on whichit is based, into a version which can be evaluated in atop-down fashion.One situation where such normalization maybe required involves certain types of non-standardrecursive goals, as depicted schematically below.vp (A, P)vp (A, P)v(A,P)-> vp( f  (A, PI) ,P) ,compl  (PI) .-> v(A,P) .-> lex.If vp  is invoked by a top-down, left-to-right inter-preter, with the variable P instantiated, and if P1 isthe essential argument in comp1, then there is noway we can successfully execute the first clause,even if we alter the ordering of the literals on itsright-hand side, unless, that is, we employ the goalskipping technique discussed by Shieber et al How-ever, we can easily normalize this code by replacingthe first two clauses with functionally equivalent onesthat get the recursion firmly under control, and thatcan be evaluated in a top-down fashion.
We assumethat P is the essential argument in v (A, P) and thatA is "out".
The normalized grammar is given below.vp(A,P) -> v(B,P),vpI(B,A).vpl (f (B, PI) ,A) -> vpl (B,A), compl (PI) .vpl (A,A) .v(A,P) -> lex.In this new code the recursive second clause will beused so long as its first argument has a form f(a,fl),where u and 13 are fully instantiated terms, and it willstop otherwise (either succeed or fail depending uponinitial binding to A).
In general, the fact that a recur-sive clause is unfit for a top-down execution can beestablished by computing the collection of minimalsets of essential arguments for its head predicate.
Ifthis collection turns out to be empty, the predicate'sdefinition eed to be normalized.Other types of normalization i clude elimina-tion of some of the chain rules in the grammar, esl~-ciany if their presence induces undue non-determinism in the generator.
We may also, if neces-sary, tighten the criteria for selecting the essentialarguments, to further enhance the efficiency of thegenerator, providing, of course, that this move doesnot render the grammar non-reversible.
For a furtherdiscussion of these and related problems the reader isreferred to (Strzalkowski, 1989).CONCLUSIONSIn this paper we presented an algorithm forautomated inversion of a unification parser fornatural anguage into an efficient unification genera-tor.
The inverted program of the generator isobtainedby an off-line compilation process which directlymanipulates the PROLOG code of the parser program.We distinguish two logical stages of this transforma-tion: computing the minimal sets of essential argu-ments (MSEA's) for predicates, and generating theinverted program code with INVERSE.
The methoddescribed here is contrasted with the approaches thatseek to define a generalized but computationallyexpensive valuation strategy for running a grammarin either direction without manipulating its rules(Shieber, 1988), (Shieber et al, 1989), 0Vedekind,1989), and see also (Naish, 1986) for some relevanttechniques.
We have completed a first implementa-tion of the system and used it to derive both a parserand a generator from a single DCG grammar forEnglish.
We note that the present version ofINVERSE can operate only upon the declarativespecification of a logic grammar and is not preparedto deal with extra-logical control operators uch asthe cut.ACKNOWLEDGMENTSRalph Grishman and other members of theNatural Language Discussion Group provided valu-able comments to earlier versions of this paper.
Wealso thank anonymous reviewers for their sugges-tions.
This paper is based upon work supported bythe Defense Advanced Research Project Agencyunder Contract N00014-85-K-0163 from the Officeof Naval Research.REFERENCESColmerauer, Main.
1982.
PROLOG H:Manuel de reference et mode& theorique.
Grouped'Intelligence Artificielle, Faculte de Sciences deLuminy, Marseille.Debray, Saumya, K. 1989.
"Static InferenceModes and Data Dependencies in Logic Programs.
"ACM Transactions on Programming Languages andSystems, 11(3), July 1989, pp.
418-450.Derr, Marcia A. and McKeown, Kathleen R.1984.
"Using Focus to Generate Complex and Sim-ple Sentences."
Proceedings of lOth COLING,Bonn, Germany, pp.
319-326.219Dymetman, Marc and Isabelle, Pierre.
1988.
"Reversible Logic Grammars for Machine Transla-tion."
Proc.
of the Second Int.
Conference onMachine Translation, Pittsburgh, PA.Grishman, Ralph.
1986.
Proteus Parser Refer-ence Manual.
Proteus Project Memorandum #4,Courant Institute of Mathematical Sciences, NewYork University.McKeown, Kathleen R. 1985.
Text Genera-tion: Using Discourse Strategies and Focus Con-straints to Generate Natural Language Text.
Cam-bridge University Press.Naish, Lee.
1986.
Negation and Control inPROLOG.
Lecture Notes in Computer Science, 238,Springer.Pereira, Fernando C.N.
and Warren, DavidH.D.
1980.
"Definite clause grammars for languageanalysis."
Artificial Intelligence, 13, pp.
231-278.Sager, Naomi.
1981.
Natural Language Infor-mation Processing.
Addison-Wesley.Shieber, Stuart M. 1988.
"A uniform architec-ture for parsing and generation."
Proceedings of the12th COLING, Budapest, Hungary (1988), pp.
614-619.Shieber, Smart M., van Noord, Gertjan, Moore,Robert C. and Pereira, Feruando C.N.
1989.
"ASemantic-Head-Driven Generation Algorithm forUnification-Based Formalisms."
Proceedings of the27th Meeting of the ACL, Vancouver, B.C., pp.
7-17.Shoham, Yoav and McDermott, Drew V.
1984.
"Directed Relations and Inversion of PROLOG Pro-grams."
eroc.
of the Int.
Conference of Fifth Gen-eration Computer Systems.Strzalkowski, Tomek.
1989.
Automated Inver-sion of a Unification Parser into a Unification Gen-erator.
Technical Report 465, Department of Com-puter Science, Courant Institute of Mathematical Sci-ences, New York University.Strzalkowski, Tomek.
1990.
"An algorithmfor inverting a unification grammar into an efficientunification generator."
Applied Mathematics Letters,vol.
3, no.
1, pp.
93-96.
Pergamon Press.Wedekind, Jurgen.
1988.
"Generation asstructure driven derivation."
Proceedings of the 12thCOLING, Budapest, Hungary, pp.
732-737.
