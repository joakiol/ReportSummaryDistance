Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 521?525,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsDual Training and Dual Prediction for Polarity ClassificationRui Xia, Tao Wang, Xuelei HuDepartment of Computer ScienceNanjing University ofScience and Technologyrxia@njust.edu.cn,linclonwang@163.com,xlhu@njust.edu.cnShoushan LiNLP LabDepartment ofComputer ScienceSoochow Universityshoushan.li@gmail.comChengqing ZongNational Lab ofPattern RecognitionInstitute of AutomationCAScqzong@nlpr.ia.ac.cnAbstractBag-of-words (BOW) is now the most popularway to model text in machine learning basedsentiment classification.
However, the perfor-mance of such approach sometimes remainsrather limited due to some fundamental defi-ciencies of the BOW model.
In this paper, wefocus on the polarity shift problem, and pro-pose a novel approach, called dual training anddual prediction (DTDP), to address it.
Thebasic idea of DTDP is to first generate artifi-cial samples that are polarity-opposite to theoriginal samples by polarity reversion, andthen leverage both the original and oppositesamples for (dual) training and (dual) predic-tion.
Experimental results on four datasetsdemonstrate the effectiveness of the proposedapproach for polarity classification.1 IntroductionThe most popular text representation model inmachine learning based sentiment classificationis known as the bag-of-words (BOW) model,where a piece of text is represented by an unor-dered collection of words, based on which stand-ard machine learning algorithms are employed asclassifiers.
Although the BOW model is simpleand has achieved great successes in topic-basedtext classification, it disrupts word order, breaksthe syntactic structures and discards some kindsof semantic information that are possibly veryimportant for sentiment classification.
Such dis-advantages sometimes limit the performance ofsentiment classification systems.A lot of subsequent work focused on featureengineering that aims to find a set of effectivefeatures based on the BOW representation.
How-ever, there still remain some problems that arenot well addressed.
Out of them, the polarityshift problem is the biggest one.We refer to ?polarity shift?
as a linguistic phe-nomenon that the sentiment orientation of a textis reversed (from positive to negative or vice ver-sa) because of some particular expressions calledpolarity shifters.
Negation words (e.g., ?no?, ?not?and ?don?t?)
are the most important type of po-larity shifter.
For example, by adding a negationword ?don?t?
to a positive text ?I like this book?in front of ?like?, the orientation of the text isreversed from positive to negative.Naturally, handling polarity shift is very im-portant for sentiment classification.
However, theBOW representations of two polarity-oppositetexts, e.g., ?I like this book?
and ?I don?t like thisbook?, are considered to be very similar by mostof machine learning algorithms.
Although somemethods have been proposed in the literature toaddress the polarity shift problem (Das and Chen,2001; Pang et al, 2002; Na et al, 2004; Kenndeyand Inkpen, 2006; Ikeda et al, 2008; Li andHuang, 2009; Li et al, 2010), the state-of-the-artresults are still far from satisfactory.
For example,the improvements are less than 2% after consid-ering polarity shift in Li et al (2010).In this work, we propose a novel approach,called dual training and dual prediction (DTDP),to address the polarity shift problem.
By takingadvantage of the unique nature of polarity classi-fication, DTDP is motivated by first generatingartificial samples that are polarity-opposite to theoriginal ones.
For example, given the originalsample ?I don?t like this book.
It is boring,?
itspolarity-opposite version, ?I like this book.
It isinteresting?, is artificially generated.
Second, theoriginal and opposite training samples are usedtogether for training a sentiment classifier (calleddual training), and the original and opposite testsamples are used together for prediction (calleddual prediction).
Experimental results prove thatthe procedure of DTDP is very effective at cor-recting the training and prediction errors caused521by polarity shift, and it beats other alternativemethods of considering polarity shift.2 Related WorkThe lexicon-based sentiment classification sys-tems can be easily modified to include polarityshift.
One common way is to directly reverse thesentiment orientation of polarity-shifted words,and then sum up the orientations word by word(Hu and Liu, 2004; Kim and Hovy, 2004; Po-lanyi and Zaenen, 2004; Kennedy and Inkpen,2006).
Wilson et al (2005) discussed other com-plex negation effects by using conjunctive anddependency relations among polarity words.
Alt-hough handling polarity shift is easy and effec-tive in term-counting systems, they rarely outper-form the baselines of machine learning methods(Kennedy, 2006).The machine learning methods are generallymore effective for sentiment classification.
How-ever, it is difficult to handle polarity shift basedon the BOW model.
Das and Chen (2001) pro-posed a method by simply attaching ?NOT?
towords in the scope of negation, so that in the text?I don?t like book?, the word ?like?
is changed toa new word ?like-NOT?.
There were also someattempts to model polarity shift by using morecomplex linguistic features (Na et al, 2004;Kennedy and Inkpen, 2006).
But the improve-ments upon the baselines of machine learningsystems are very slight (less than 1%).Ikeda et al (2008) proposed a machine learn-ing method, to model polarity-shifters for bothword-wise and sentence-wise sentiment classifi-cation, based on a dictionary extracted fromGeneral Inquirer.
Li and Huang (2009) proposeda method first to classify each sentence in a textinto a polarity-unshifted part and a polarity-shifted part according to certain rules, then torepresent them as two bag-of-words for senti-ment classification.
Li et al (2010) further pro-posed a method to separate the shifted and un-shifted text based on training a binary detector.Classification models are then trained based oneach of the two parts.
An ensemble of two com-ponent parts is used at last to get the final polari-ty of the whole text.3 The Proposed ApproachWe first present the method for generating artifi-cial polarity-opposite samples, and then intro-duce the algorithm of dual training and dual pre-diction (DTDP).3.1 Generating Artificial Polarity-OppositeSamplesGiven an original sample and an antonym dic-tionary (e.g., WordNet 1 ), a polarity-oppositesample is generated artificially according to thefollowing rules:1) Sentiment word reversion: All sentimentwords out of the scope of negation are re-versed to their antonyms;2) Handling negation: If there is a negationexpression, we first detect the scope of nega-tion, and then remove the negation words(e.g., ?no?, ?not?, and ?don?t?).
The senti-ment words in the scope of negation are notreversed;3) Label reversion: The class label of the la-beled sample is also reversed to its opposite(i.e., Positive to Negative, or vice versa) asthe class label of newly generated samples(called polarity-opposite samples).Let us use a simple example to explain thegeneration process.
Given the original sample:The original sampleText:   I don?t like this book.
It is boring.Label: NegativeAccording to Rule 1, ?boring?
is reversed toits antonym ?interesting?
; According to Rule 2,the negation word ?don?t?
is removed, and ?like?is not reversed; According to Rule 3, the classlabel Negative is reversed to Positive.
Finally, anartificial polarity-opposite sample is generated:The generated opposite sampleText:   I like this book.
It is interesting.Label: PositiveAll samples in the training and test set are re-versed to their polarity-opposite versions.
Werefer to them as ?opposite training set?
and ?op-posite test set?, respectively.3.2 Dual Training and Dual PredictionIn this part, we introduce how to make use of theoriginal and opposite training/test data togetherfor dual training and dual prediction (DTDP).Dual Training: Let D = f(xi; yi)gNi=1 and~D = f(~xi; ~yi)gNi=1 be the original and oppositetraining set respectively, where x  denotes thefeature vector, y  denotes the class label, and Ndenotes the size of training set.
In dual training,D [ ~D  are used together as training data to learn1 http://wordnet.princeton.edu/522a classification model.
The size of training datais doubled in dual training.Suppose the example in Section 3.1 is used asone training sample.
As far as only the originalsample (?I don?t like this book.
It is boring.?)
isconsidered, the feature ?like?
will be improperlyrecognized as a negative indicator (since theclass label is Negative), ignoring the expressionof negation.
Nevertheless, if the generated oppo-site sample (?I like this book.
It is interesting.?
)is also used for training, ?like?
will be learnedcorrectly, due to the removal of negation in sam-ple reversion.
Therefore, the procedure of dualtraining can correct some learning errors causedby polarity shift.Dual Prediction: Given an already-trainedclassification model, in dual prediction, the orig-inal and opposite test samples are used togetherfor prediction.
In dual prediction, when we pre-dict the positive degree of a test sample, wemeasure not only how positive the original testsample is, but also how negative the oppositesample is.Let x  and ~x  denote the feature vector of theoriginal and opposite test samples respectively;let pd(cjx)  and pd(cj~x)  denote the predictions ofthe original and opposite test sample, based onthe dual training model.
The dual predictingfunction is defined as:pd(+jx; ~x) = (1?a)pd(+jx)+apd(?j~x),pd(?jx; ~x) = (1?a)pd(?jx)+apd(+j~x),where a  (06 a6 1 ) is the weight of the oppo-site prediction.Now suppose the example in Section 3.1 is atest sample.
As far as only the original test sam-ple (?I don?t like this book.
It is boring.?)
is usedfor prediction, it is very likely that it is falselypredicted as Positive, since ?like?
is a strong pos-itive feature, despite that it is in the scope of ne-gation.
While in dual prediction, we still measurethe ?sentiment-opposite?
degree of the oppositetest sample (?I like this book.
It is interesting.?
).Since negation is removed, it is very likely thatthe opposite test sample is assigned with a highpositive score, which could compensate the pre-diction errors of the original test sample.Final Output: It should be noted that alt-hough the artificially generated training and test-ing data are helpful in most cases, they still pro-duce some noises (e.g., some poorly generatedsamples may violate the quality of the originaldata set).
Therefore, instead of using all dualpredictions as the final output, we use the origi-nal prediction po(cjx)  as an alternate, in case thatthe dual prediction pd(cjx; ~x)  is not enough con-fident, according to a confidence threshold t .
Thefinal output is defined as:pf(cjx) =?
pd(cjx; ~x); if?p > tpo(cjx); if?p < twhere ?p= pd(cjx; ~x)?po(cjx).4 Experimental Study4.1 DatasetsThe Multi-Domain Sentiment Datasets2 are usedfor evaluations.
They consist of product reviewscollected from four different domains: Book,DVD, Electronics and Kitchen.
Each of themcontains 1,000 positive and 1,000 negative re-views.
Each of the datasets is randomly spit into5 folds, with four folds serving as training data,and the remaining one fold serving as test data.All of the following results are reported in termsof an average of 5-fold cross validation.4.2 Evaluated SystemsWe evaluate four machine learning systems thatare proposed to address polarity shift in docu-ment-level polarity classification:1) Baseline: standard machine learning meth-ods based on the BOW model, without han-dling polarity shift;2) Das-2001: the method proposed by Das andChen (2001), where ?NOT?
is attached to thewords in the scope of negation as a prepro-cessing step;3) Li-2010: the approach proposed by Li et al(2010).
The details of the algorithm is intro-duced in related work;4) DTDP: our approach proposed in Section 3.The WordNet dictionary is used for samplereversion.
The empirical value of the param-eter a  and t  are used in the evaluation.4.3 Comparison of the Evaluated SystemsIn table 1, we report the classification accuracyof four evaluated systems using unigram features.We consider two widely-used classification algo-rithms: SVM and Na?ve Bayes.
For SVM, theLibSVM toolkit3 is used with a linear kernel andthe default penalty parameter.
For Na?ve Bayes,the OpenPR-NB toolkit4 is used.2 http://www.cs.jhu.edu/~mdredze/datasets/sentiment/3 http://www.csie.ntu.edu.tw/~cjlin/libsvm/4 http://www.openpr.org.cn523DatasetSVM Na?ve BayesBaseline Das-2001 Li-2010 DTDP Baseline Das-2001 Li-2010 DTDPBook 0.745 0.763 0.760 0.800 0.779 0.783 0.792 0.814DVD 0.764 0.771 0.795 0.823 0.795 0.793 0.810 0.820Electronics 0.796 0.813 0.812 0.828 0.815 0.827 0.824 0.841Kitchen 0.822 0.820 0.844 0.849 0.830 0.847 0.840 0.859Avg.
0.782 0.792 0.803 0.825 0.804 0.813 0.817 0.834Table 1: Classification accuracy of different systems using unigram featuresDatasetSVM Na?ve BayesBaseline Das-2001 Li-2010 DTDP Baseline Das-2001 Li-2010 DTDPBook 0.775 0.777 0.788 0.818 0.811 0.815 0.822 0.840DVD 0.790 0.793 0.809 0.828 0.824 0.826 0.837 0.868Electronics 0.818 0.834 0.841 0.848 0.841 0.857 0.852 0.866Kitchen 0.847 0.844 0.870 0.878 0.878 0.879 0.883 0.896Avg.
0.808 0.812 0.827 0.843 0.839 0.844 0.849 0.868Table 2: Classification accuracy of different systems using both unigram and bigram featuresCompared to the Baseline system, the Das-2001 approach achieves very slight improve-ments (less than 1%).
The performance of Li-2010 is relatively effective: it improves the aver-age score by 0.21% and 0.13% on SVM and Na-?ve Bayes, respectively.
Yet, the improvementsare still not satisfactory.As for our approach (DTDP), the improve-ments are remarkable.
Compared to the Baselinesystem, the average improvements are 4.3% and3.0% on SVM and Na?ve Bayes, respectively.
Incomparison with the state-of-the-art (Li-2010),the average improvement is 2.2% and 1.7% onSVM and Na?ve Bayes, respectively.We also report the classification accuracy offour systems using both unigrams and bigramsfeatures for classification in Table 2.
From thistable, we can see that the performance of eachsystem is improved compared to that using uni-grams.
It is now relatively difficult to show im-provements by incorporating polarity shift, be-cause using bigrams already captured a part ofnegations (e.g., ?don?t like?
).The Das-2001 approach still shows very lim-ited improvements (less than 0.5%), whichagrees with the reports in Pang et al (2002).
Theimprovements of Li-2010 are also reduced: 1.9%and 1% on SVM and Na?ve Bayes, respectively.Although the improvements of the previoustwo systems are both limited, the performance ofour approach (DTDP) is still sound.
It improvesthe Baseline system by 3.7% and 2.9% on SVMand Na?ve Bayes, respectively, and outperformsthe state-of-the-art (Li-2010) by 1.6% and 1.9%on SVM and Na?ve Bayes, respectively.5 ConclusionsIn this work, we propose a method, called dualtraining and dual prediction (DTDP), to addressthe polarity shift problem in sentiment classifica-tion.
The basic idea of DTDP is to generate arti-ficial samples that are polarity-opposite to theoriginal samples, and to make use of both theoriginal and opposite samples for dual trainingand dual prediction.
Experimental studies showthat our DTDP algorithm is very effective forsentiment classification and it beats other alterna-tive methods of considering polarity shift.One limitation of current work is that the tun-ing of parameters in DTDP (such as a  and t ) isnot well discussed.
We will leave this issue to anextended version.AcknowledgmentsThe research work is supported by the JiangsuProvincial Natural Science Foundation of China(BK2012396), the Research Fund for the Doc-toral Program of Higher Education of China(20123219120025), and the Open Project Pro-gram of the National Laboratory of PatternRecognition (NLPR).
This work is also partlysupported by the Hi-Tech Research and Devel-opment Program of China (2012AA011102 and2012AA011101), the Program of IntroducingTalents of Discipline to Universities (B13022),and the Open Project Program of the Jiangsu KeyLaboratory of Image and Video Understandingfor Social Safety (30920130122006).524ReferencesS.
Das and M. Chen.
2001.
Yahoo!
for Amazon:Extracting market sentiment from stock mes-sage boards.
In Proceedings of the Asia Pacif-ic Finance Association Annual Conference.M.
Hu and B. Liu.
2004.
Mining opinion featuresin customer reviews.
In Proceedings of theNational Conference on Artificial Intelligence(AAAI).D.
Ikeda, H. Takamura L. Ratinov M. Okumura.2008.
Learning to Shift the Polarity of Wordsfor Sentiment Classification.
In Proceedingsof the International Joint Conference on Natu-ral Language Processing (IJCNLP).S.
Kim and E. Hovy.
2004.
Determining the sen-timent of opinions.
In Proceeding of the Inter-national Conference on Computational Lin-guistics (COLING).A.
Kennedy and D. Inkpen.
2006.
Sentimentclassification of movie reviews using contex-tual valence shifters.
Computational Intelli-gence, 22:110?125.S.
Li and C. Huang.
2009.
Sentiment classifica-tion considering negation and contrast transi-tion.
In Proceedings of the Pacific Asia Con-ference on Language, Information and Com-putation (PACLIC).S.
Li, S. Lee, Y. Chen, C. Huang and G. Zhou.2010.
Sentiment Classification and PolarityShifting.
In Proceeding of the InternationalConference on Computational Linguistics(COLING).J.
Na, H. Sui, C. Khoo, S. Chan, and Y. Zhou.2004.
Effectiveness of simple linguistic pro-cessing in automatic sentiment classificationof product reviews.
In Proceeding of the Con-ference of the International Society forKnowledge Organization.B.
Pang, L. Lee, and S. Vaithyanathan.
2002.Thumbs up?
: sentiment classification usingmachine learning techniques.
In Proceedingsof the Conference on Empirical Methods inNatural Language Processing (EMNLP).L.
Polanyi and A. Zaenen.
2004.
Contextual lex-ical valence shifters.
In Proceedings of theAAAI Spring Symposium on Exploring Attitudeand Affect in Text, AAAI technical report.P.
Turney.
2002.
Thumbs up or thumbs down?Semantic orientation applied to unsupervisedclassification of reviews.
In Proceeding of theAnnual Meeting of the Association for Compu-tational Linguistics (ACL).T.
Wilson, J. Wiebe, and P. Hoffmann.
2005.Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis.
In Proceedings ofthe Conference on Empirical Methods in Nat-ural Language Processing (EMNLP).525
