Proceedings of the Fourth Workshop on Teaching Natural Language Processing, pages 51?55,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsArtificial IntelliDance: Teaching Machine Learning through aChoreographyApoorv AgarwalDepartment of Computer ScienceColumbia University, New York, USAapoorv@cs.columbia.eduCaitlin TrainorDepartment of DanceBarnard College, Columbia Universitycaitlinmarytrainor@gmail.comAbstractIn this paper we present a choreography thatexplains the process of supervised machinelearning.
We present how a perceptron (in itsdual form) uses convolution kernels to learnto differentiate between two categories of ob-jects.
Convolution kernels such as string ker-nels and tree kernels are widely used in Nat-ural Language Processing (NLP) applications.However, the baggage associated with learn-ing the theory behind convolution kernels,which extends beyond graduate linear algebra,makes the adoption of this technology intrinsi-cally difficult.
The main challenge in creatingthis choreography was that we were requiredto represent these mathematical equations attheir meaning level before we could translatethem into the language of movement.
By or-chestrating such a choreography, we believe,we have obviated the need for people to possesadvanced math background in order to appre-ciate the core ideas of using convolution ker-nels in a supervised learning setting.1 IntroductionNatural Language Processing (NLP) and MachineLearning (ML) are making a significant impact inour day to day lives.
Advancement in these ar-eas of research is changing the way humans inter-act with each other and with objects around them.For example, speech to speech translation is makingit possible for people speaking different languagesto communicate seamlessly.1 In this eco-system,where machines and objects around us are becom-1http://www.bbn.com/technology/speech/speech to speech translationing smarter, there is a need to make this complextechnology available to a general audience.The Dance Your PhD competition2 is a recent ef-fort that encourages doctoral students pursuing re-search in Physics, Chemistry, Biology and SocialSciences to explain the scientific ideas in their the-ses through movement.
The main advantage of thisapproach is that the scientific ideas become avail-able to a general audience through a medium that isboth visual and entertaining.
The main challenge, ofcourse, is to abstract away from the technical vocab-ulary and physicalize these scientific ideas.In this paper, we present a choreography that ex-plains the process of learning from data in a super-vised setting.
Through this choreography, we bringout some of the main ideas of supervised machinelearning, including representing data as structuredobjects and formulating similarity functions that amachine uses to calculate distances between datapoints.
While these are general ideas, more rele-vant to an audience that is not familiar with machinelearning, the choreography may also be used for ex-plaining convolution kernels to researchers familiarwith machine learning but not necessarily familiarwith how a perceptron uses a convolution kernel inits dual form.The main challenge in creating this choreographywas that we were required to represent these mathe-matical equations at the meaning level before trans-lating them into the language of movement.
In doingso, our primary concerns were accuracy, aesthetics,and legibility.
The scientific ideas at hand could notbe compromised, and yet a literal representation ofthe symbols would negate the intent of the project.2http://gonzolabs.org/dance/51Equally vital to the success of the piece is the qual-ity of the choreography on its own formal and aes-thetic terms.
The challenge of the translation wasboth critical to the process and also enriching, be-cause it deepened our understanding of convolutionkernels.As Jason Eisner correctly notes in his paper oninteractive spreadsheets for teaching the forward-backward algorithm (Eisner, 2002) ?
They are con-crete, visual, playful, sometimes interactive, and re-main available to the students after the lecture ends?
we believe this choreography shares the samespirit.
Artificial IntelliDance functions to explain arelatively sophisticated machine learning paradigmin an accessible and entertaining format that can beviewed repeatedly.3The rest of the paper is structured as follows: Insection 2, we review the perceptron algorithm, itsdual form and convolution kernels.
In section 3 wepresent details of the choreography, focusing on theaspects that explain the process of supervised ma-chine learning and bring out the strengths and weak-nesses of kernel learning.
We conclude in Section 4.2 The Perceptron algorithm andConvolution KernelsThe perceptron algorithm is an online learning algo-rithm invented by Frank Rosenblatt in 1958 (Rosen-blatt, 1958).
Given a set of training data points,D = {(xi, yi)}, where yi ?
{1,?1}, the algorithmworks as follows:41.
Start with the all-zeroes weight vector w1 = 0,and initialize t to 1.2.
Given xi, predict positive if wt ?
xi > 03.
On a mistake, update as follows:wt+1 ?
wt + yixi4.
t?
t + 1In natural language, a perceptron maintains aweight vector wt at time instance t. The weight3The video is available at the following URL:http://tinyurl.com/mte8wda4From lecture notes of Avrim Blum:http://www.cs.cmu.edu/?avrim/ML09/lect0126.pdf.
Mod-ified for our purposes.vector is initialized to zero at the start of the algo-rithm.
The perceptron receives one data point afterthe other.
For each data point, it predicts the cate-gory of the data point by calculating its dot productwith the weight vector.
If the dot product is greaterthan zero, it predicts the category of the data pointas 1, and -1 otherwise.
On a mistake, the perceptronupdates the weight vector by adding the product ofthe data point (xi) and its category (1 or -1).The key idea here is that the weight vector is alinear combination of the training data points whosecategories the perceptron predicted incorrectly at thetime of training.
The algorithm remembers theseincorrectly classified data points by marking themwith their true category (1 or -1).
Abusing terminol-ogy, we refer to these incorrectly classified trainingdata points as support vectors.
Notationally, the finalweight vector then is w =?Nsk=1 ykxk, where Ns isthe number of support vectors.This simple fact that the weight vector is a linearcombination of the data points has a deeper conse-quence ?
to predict the category of an unseen exam-ple, call it x, all we need is a dot product of x withall the support vectors: w ?
x =?Nsk=1 yk(xk ?
x).This is usually referred to as the dual form of theperceptron.
The dual form allows for the use of ker-nels because the dot product between two examplescan be replaced by a kernel as follows: w ?
x =?Nsk=1 ykK(xk,x).
This is exactly where convolu-tion kernels come into the picture.
We review thosenext.Convolution kernels, first introduced by DavidHaussler (1999), can be viewed as functions thatcalculate similarities between abstract objects, K :X ?
X ?
R, where X is the set of abstract ob-jects.
Since their introduction, convolution kernelshave been widely used in many NLP applications(Collins and Duffy, 2002; Lodhi et al 2002; Ze-lenko et al 2003; Culotta and Sorensen, 2004; Mos-chitti, 2004; Zhou et al 2007; Moschitti et al 2008;Agarwal and Rambow, 2010; Agarwal et al 2011).The reason for their popular use in NLP applica-tions is that text has natural representations such asstrings, trees, and graphs.
Representing text in itsnatural representation alleviates the need for fine-grained feature engineering and is therefore a con-venient way of data representation.
Using this natu-ral data representation, convolution kernels calculate52the similarity between two objects by recursively di-viding the objects into ?parts?, calculating the simi-larity between smaller parts, and aggregating thesesimilarities to report a similarity between objects.For example, the way a string kernel will calcu-late the similarity between two strings (say ?abc?and ?aec?)
is by mapping each string into an im-plicit feature space and then calculating the similar-ity between the two strings by taking a dot productof the mappings (see Table 1).
The feature spaceis called implicit because the kernel never explicitlywrites out these features (or sub-structures).
It calcu-lates the similarity by using a dynamic program thatrecurses over these structures to find similar sub-structures.a b c e ab ac bc ae ec?abc?
1 1 1 0 1 1 1 0 0?aec?
1 0 1 1 0 1 0 1 1~v 1 0 1 0 0 1 0 0 0Table 1: An example showing how a string kernel willcalculate the similarity between two strings.
The implicitfeature space is {a, b, c, e, ab, ac, bc, ae, ec }.
~v refers tothe dot product of the vectors of the two strings.
Similar-ity between these two strings is?9i=1 vi = 3Thus, convolution kernels allow the learner tomake similarity calculations without compromisingthe original structure of the objects (unlike featureengineering, where every object is represented asa vector in a finite dimensional space, thus losingthe original structure of objects).
This was the keyobservation that lead us to define objects as danceforms, and to our choice of using convolution ker-nels for explaining the machine learning processthrough a choreography.
We discuss this in detailin the next section.3 Artificial IntelliDanceIn 2011, we created a choreography to present theidea of how a machine goes through the process oflearning from data.
We presented a perceptron, inits dual form, that uses convolution kernels to learnhow to differentiate between two categories of ob-jects.
The 15 minute choreography is supported bya narrative, which is an interaction between a ma-chine, depicted by a dancer, and a user, whose voiceis heard but who remains unseen.One of the main and early challenges we ran intoduring the ideation of the choreography had to dowith the definition of objects.
Though the centralgoal of the choreography was to explain a scientificidea, we wanted the choreography to maintain itsaesthetic value.
As a consequence of this constraint,we decided to stay away from defining objects asthings that would restrict the dancers from movingfreely in a natural way.As discussed in the previous section, since con-volution kernels allow for a natural representationof objects, we define our objects to be two danceforms: Ballet and Modern dance.
Much like stringkernels, where the implicit feature space is the spaceof sub-strings (that form a string), in our case, thehigh dimensional kernel space is the space of sub-movements (that form a movement).
Each dancer isa data point, seen as a sequence of movements in aninfinite dimensional space.Figure 1: Above is a scene from one of the performancesin which the machine, represented by the dancer in sil-ver, ?considers?
the data.
Prominently featured are datapoint dancers in red and yellow, both of whom have beenmarked with category-differentiating shapes (round forBallet and diamond for Modern).The choreography is broken into multiple phases.In the first phase, we motivate the need for ma-chine learning, or pattern recognition, by presentingan apparently chaotic scene; all of the dancers areonstage at once, performing unique movement se-quences, with only brief moments of synchronizedaction.
The cacophonous dancing conveys the over-whelming difficulty for data scientists to find pat-terns in data using the naked eye.
The dialogue ad-vances the choreography to the next phase, wherewe sketch out the learning process.In the learning phase, the machine starts by mak-53ing a prediction on the first data point.
Since themachine has no prior knowledge (w1 = 0), it makesa random prediction and gets the category wrong.The machine marks the dancer with a symbol in or-der to remember the data point (wt ?
wt + yixi).The machine is then asked to make a prediction on asecond data point.
The machine compares this newdata point with the data point it marked and makesa prediction (w ?
x =?Nsk=1 ykK(xk,x)).
Onceagain, it gets the category wrong and marks the sec-ond data point as well.
This process continues untilthe machine has seen all the training instances andhas selected data points it thinks encode structuresimportant for classification.Marking of dancers is done explicitly where themachine dancer attaches a round or triangular sym-bol to the data points: round is for Ballet and trian-gle is for Modern (see Figure 1).
This is analogousto how a perceptron attaches positive and negativeweights to the data points belonging to positive andnegative categories respectively.The narration points out a big limitation of con-volution kernel methods, which is, in the worst case,every data-point is compared with every other datapoint in the training data, thus making the learn-ing process slow (because the machine needs to gothrough the training data twice).We also differentiate between the low dimen-sional feature space, in which the machine is un-able to separate the data, and the high dimensionalspace, which offers distinguishability.
The set of in-active training data points, i.e.
the data points ina low dimensional feature space, is depicted by aclump of dancers in a corner who are hardly mov-ing.
The set of data points that are actively movinglie in a high dimensional feature space in which themachine learns a linear separator.The next phase is testing, in which the machinecompares the test dancers with the dancers it markedin the learning phase.
After comparing each testpoint with all the support vectors, the machinemakes a prediction.
This phase concludes by show-ing that the machine has in fact learned to differen-tiate between the two categories.The user is impressed and asks the machine toreveal the secret sauce.
In this part of the chore-ography we visually describe how convolution ker-nels go about calculating similarities between twoabstract objects, by breaking the object into parts,and recursing over the parts to calculate similarity.This action is illustrated by a comparison of simi-lar movements and sub-movements as executed by aballet and modern dancer.
Situated side by side, thetwo dancers fragment the movements into increas-ingly smaller bits so as to make differences in thetwo forms of dance (objects) more visibly compa-rable.
We also highlight the reason for the machineto look at a pair of data points instead of individ-ual data points.
The reason is that the machine doesnot remember the sub-structures important for clas-sification (because the implicit feature space is enor-mous).
By marking the data points, it only remem-bers the data points that encode these sub-structures.To this, the user voice points out another limita-tion of using convolution kernels; interpretability ofmodels is hard.
We can learn predictive models, butthe fine grained structures important for classifica-tion remain hidden.The piece ends with all the dancers linearly sepa-rated into categories in a high dimensional implicitfeature space.
Through the narration we point outthe main differences and similarities between thetwo forms of dance, which are aesthetically visiblebut are sometimes hard to articulate.4 ConclusionIn this paper, we presented a choreography that il-lustrates the process of supervised machine learn-ing using a perceptron and convolution kernels.
Thechoreography is structured around a scene in whichthe machine (represented by a dancer) learns to dif-ferentiate between two categories of objects, balletand modern dance.
The choreography not only ex-plains the process of machine learning and how con-volution kernels work, it also brings out two majorlimitations of using convolution kernels visually ?having to go through the data twice, which makesthe learning process slow, and that the interpretabil-ity of the models is hard, because the important sub-structures are not stored explicitly.
While the gen-eral ideas about supervised machine learning maybe more relevant to an audience that is not familiarwith machine learning, the choreography may alsobe used to explain convolution kernels (in a visualand entertaining way) to researchers familiar with54machine learning but not necessarily familiar withhow a perceptron uses a convolution kernel in itsdual form.Artificial IntelliDance premiered at Barnard Col-lege in April 2012, and has since been invited toperform at the World Science Festival 2012 andTEDx ColumbiaEngineering 2012.
The audiencewas comprised of a combination of scientists andnon-scientists, including dance artists, undergradu-ate and graduate students, and the general public.The primary concepts of the presentation were un-derstood clearly by a number of viewers lacking fa-miliarity with any machine learning paradigm as ev-idenced by the post-presentation discussions.
Unfor-tunately, we do not have a more precise evaluation asto how many people actually understood the scien-tific ideas.
The only ?evaluation?
we have is that thevideo continues to be showcased; we were recentlyinvited to showcase it at Australia?s National Sci-ence Week 2013.
However, we have not yet heardof the video being used in a Machine Learning lec-ture.In addition to functioning as an educational tool,a noteworthy outcome of the project is that it fostersdialogue between the general public and the arts andcomputer science communities.AcknowledgmentsWe would like to thank Caronae Howell, KapilThadani, and anonymous reviewers for useful com-ments.
We thank the dancers involved in the pro-duction and performance of the piece (in no par-ticular order): Aditi Dhruv, Jenna Simon, Mor-gan Caglianone, Maddie James, Claire Salant, AnnaBrown Massey, Emily Craver, Mindy Upin, Tem-ple Kemezis, Taylor Gordon, Chelsea Cusack, LaneHalperin, Lisa Fitzgerald and Eleanor Barisser.
Wewould like to thank Robert Boston for music andMarlon Cherry for voice of the user.ReferencesApoorv Agarwal and Owen Rambow.
2010.
Automaticdetection and classification of social events.
In Pro-ceedings of the 2010 Conference on Empirical Meth-ods in Natural Language Processing, pages 1024?1034, Cambridge, MA, October.
Association for Com-putational Linguistics.Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow,and Rebecca Passonneau.
2011.
Sentiment analy-sis of twitter data.
In Proceedings of the Workshopon Language in Social Media (LSM 2011), pages 30?38, Portland, Oregon, June.
Association for Computa-tional Linguistics.Michael Collins and Nigel Duffy.
2002.
New rank-ing algorithms for parsing and tagging: Kernels overdiscrete structures, and the voted perceptron.
In Pro-ceedings of the 40th annual meeting on association forcomputational linguistics, pages 263?270.
Associationfor Computational Linguistics.Aron Culotta and Jeffrey Sorensen.
2004.
Dependencytree kernels for relation extraction.
In Proceedings ofthe 42ndMeeting of the Association for ComputationalLinguistics (ACL?04), Main Volume, pages 423?429,Barcelona, Spain, July.Jason Eisner.
2002.
An interactive spreadsheet for teach-ing the forward-backward algorithm.
In Proceed-ings of the ACL-02 Workshop on Effective Tools andMethodologies for Teaching Natural Language Pro-cessing and Computational Linguistics, pages 10?18,Philadelphia, Pennsylvania, USA, July.
Associationfor Computational Linguistics.David Haussler.
1999.
Convolution kernels on discretestructures.
Technical report, University of Californiaat Santa Cruz.Huma Lodhi, Craig Saunders, John Shawe-Taylor, NelloChristianini, and Chris Watkins.
2002.
Text classifi-cation using string kernels.
The Journal of MachineLearning Research, 2:419?444.Alessandro Moschitti, Daniele Pighin, and RobertoBasili.
2008.
Tree kernels for semantic role labeling.Special Issue on Semantic Role Labeling, Computa-tional Linguistics Journal,.Alessandro Moschitti.
2004.
A study on convolutionkernels for shallow semantic parsing.
In Proceedingsof the 42nd Conference on Association for Computa-tional Linguistic.Frank Rosenblatt.
1958.
The perceptron.
Psych.
Rev,65(6):386?408.Dmitry Zelenko, Chinatsu Aone, and AnthonyRichardella.
2003.
Kernel methods for relationextraction.
The Journal of Machine LearningResearch, 3:1083?1106.GuoDong Zhou, Min Zhang, DongHong Ji, and QiaoM-ing Zhu.
2007.
Tree kernel-based relation extractionwith context-sensitive structured parse tree informa-tion.
In Proceedings of EMNLP-CoNLL.55
