Proceedings of The First Workshop on Computational Approaches to Code Switching, pages 133?138,October 25, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsIncremental N-gram Approach for Language Identification inCode-Switched TextPrajwol ShresthaKathmandu UniversityDepartment of Computer Science and EngineeringDhulikhel, Nepalprajwol.shrestha18@gmail.comAbstractA multilingual person writing a sentenceor a piece of text tends to switch be-tween languages s/he is proficient in.
Thisalteration between languages, commonlyknown as code-switching, presents us withthe problem of determining the correctlanguage of each word in the text.
Mymethod uses a variety of techniques basedupon the observed differences in the for-mation of words in these languages.
Mysystem was able to obtain third position inboth tweet and token level for the main testdataset as well as first position in the tokenlevel evaluation for the surprise datasetboth consisting of Nepali-English code-switched texts.1 IntroductionNowadays, it is common for people to be able tospeak in two or more languages.
So, the propen-sity to use code-switching in spoken as well asin written text has increased.
Code-switching oc-curs when a person uses two or more than twolanguages in a single piece of text.
According toElfardy and Diab (2012), the phenomenon wherespeakers switch between multiple languages be-tween the same utterance or across utteranceswithin the same conversation is referred to as Lin-guistic Code Switching.
English, being an univer-sal language is highly likely to be code-switchedwith some other language.
This is specially truewhen English is studied or spoken in the com-munity as the second language by a person.
Ina such case, the person is likely to use Englishwords with his/her native language to form code-switched, yet, syntactically correct and meaning-ful sentences.This paper deals with the code-switching thatoccurs when English is used with Spanish orNepali.
The problem of identifying code-switching is closely tied with figuring out how alanguage is acquired or learned.
Auer (1988) iden-tified the phenomenon of how Italians, who wereraised in Germany developed fluctuation and vari-ation in their native language as well as in German.They were also noticed to have a strong tendencyto have a conversation dominated by the Ger-man words.
This phenomenon was also observedby Dey and Fung (2014).
The strong influenceof Bollywood in the Indian culture and the highamount of code-switching with English in moviedialogues and song lyrics, led to Hindi-Englishcode-switching, being common for the average In-dian.
Finding out the points in the text where peo-ple are most likely to code-switch, what word of acertain language is more likely to be used than aword with the same meaning of another languageand which languages are more likely to be usedin code-switching than others are all important re-search questions.
Although my paper deals onlywith finding out the language a certain token in acode-switched text belongs to, this is a first steptowards answering those other questions.The main aim of this paper is to describemy system submission to the Computational Ap-proaches to Code Switching task (Solorio et al.,2014).
The training dataset provided for the clas-sification task were tweets composed of Spanishand English words or Nepali and English words.The test dataset also consisted of similar tweets.In addition to this, there was also a surprise datasetconsisting of Facebook posts and comments in theplace of tweets.
My system for this task performslanguage identification by using a number of tech-niques.
The first one is based upon an assump-tion that words of different languages have vary-ing sets of n-gram prefixes that occur predomi-nantly throughout the language.
There has beenprior research on language identification throughthe use of n-grams.
Cavnar et al.
(1994) have ap-133proached the task of identifying the language ofan electronic mail taken from Usenet newsgroupswith the use of n-grams.
They obtained train-ing sets for each language to be classified, whichacted as language category samples.
They com-puted n-gram frequency profiles on these train-ing sets.
They found that the top 300 n-grams ofeach language are used most frequently to formthe words of the language.
Nguyen and Dogruoz(2014) have used dictionary search and a n-grambased language model to identify the language onword-level of forum posts with Dutch and Turkishcode-switching.Lignos and Marcus (2013) found that data col-lected from social media to detect code-switchingcontained a lot of non-standard spellings of wordsand unnecessary capitalization.
It was also true forthis dataset.
So, I made use of a lightweight spellchecker in the event that the word was not spelledcorrectly and hence not categorised into any lan-guage.
I have also used a rule based classificationsystem that can also be used for named entities andnon-alphanumeric language classes.
With the sys-tem that I built based on these ideas, I achievedan accuracy of above 94% for English-Nepali andabove 80% for English-Spanish in the token levelevaluation.
As the system works as a pipeline ofsmaller systems, it was time consuming.
So, inorder to improve speed, it is built to run on a mul-tithreaded environment.Language identification by using these tech-niques overcomes the drawback of other simplermethods like extracting a token?s characters andthen using its Unicode value to determine its lan-guage.
But most of the time the words are not writ-ten in its own script by using Unicode, but rather,its Romanized form is used.
Some languages likeSpanish are almost fully written in roman letters,with exception being only a small subset of ac-cented characters.
Precisely these kinds of wordsrequire more robust classification techniques.
An-other alternative is manual classification but it hasthe downside of being time consuming and an un-economical alternative.
There is a need of an ap-plication that can overcome these drawbacks andcreate a system that can be used for similar sets ofdata.2 MethodologyThe classification of a token of a code-switchedtext into one of the six classes: lang1, lang2, am-biguous, named entity, mixed and other is per-formed by using four techniques described shortly.But before applying any of these techniques, thefirst step was the creation of a dictionary for eachclass by using the tokens from the training set.
Asa preprocessing step, for any token that starts with#, the # is removed.
Also, any token that startswith @ is given the ?other?
class label.
The tech-niques used in my system are detailed below.
Theyare applied in a pipeline, in the same order as theyare mentioned.2.1 Incremental N-Gram Occurrence Modelwith Dictionary SearchThis model is used for test tokens whose length(L) is greater than three in the case of Nepali-English code-switching task and is greater thantwo in the case of Spanish-English code-switchingtask.
Tokens that are shorter are classified by us-ing a simple dictionary lookup.
If the occurrencecount of the token in the dictionary of class C isthe highest, then the token is classified as belong-ing to class C.In order to assign a class label to a particular to-ken, this model uses only the first ngram of eachsize n ranging from 3 (for Spanish-English) or 4(for Nepali-English) to L-1.
The count of oc-currence of this ngram in each class dictionary istaken as the score.
The size n is increased itera-tively and the score from each iteration is added atthe end to obtain the final score.
For named entity(NE) and ambiguous dictionary search, the wholetoken is used instead of just the ngram since thesize of these dictionaries is small.
Since a wholetoken lookup was performed, the occurrence countscores from these dictionaries are rated to be threetimes higher.
After obtaining the final scores foreach class, the one with the highest score gets as-signed as the class label of the token.This method is based on the hypothesis that to-kens belonging to the same language will havemore overlap of the preceding characters.
If twotokens are from different languages, they mightstart the same way but will start deviating in theuse of characters faster than two tokens of thesame language.
The Incremental N-Gram Modelfor Nepali-English Classification is shown in Al-gorithm 1.Consider that we have to find the language ofthe Test token Parsin.
The following assumptionsare made:134Algorithm 1 Incremental N-gram Classificationif len(token) > 3 thenn = 4while n < len(token)?
1 doif token ?
dict[ambiguous, ne] thenIncrement Respective LanguageOccurrence Count by 3end ifif FirstN-Gram ?
Remaining ClassesthenFind the number of words ineach class dictionary that startswith the First N-Gram.Add this number with the previousoccurrence count for theparticular classend ifend whileend ifN-gramSizeFirstN-gramEnglish Nepali Ambiguous4 PARS 2 6 35 PARSI 2 6 36 PARSIN 1 0 3Total 7 12 9Table 1: Incremental N-gram Classification Ex-ample?
The Word Parsing occurs twice and Parsi-mony once in the English Language Dictio-nary.?
Word Parsi occurs 6 times in the NepaleseLanguage Dictionary (Parsi means the dayafter Tomorrow).?
Test token Parsin occurs 0 times in OtherLanguage and Named Entity Dictionary?
Test token Parsin occurs once each in Am-biguous words DictionaryThe algorithm works as shown in Table 1.2.2 Rule Based ClassificationA small fraction of test tokens are left unclassi-fied by the above method.
These tokens are fur-ther processed by using a rule based classificationsystem.
It consists of the following handwrittenrules:?
Check if the token is an emoticon against anemoticon list.
If the token is found in the list,it is of the class, ?other?.?
It was hard to find an off-the-shelf named en-tity recognizer for code-switched text.
So,a simple named entity recognition rule wasused.
For a token consisting of only alpha-betic characters, if there are more than oneuppercase letters in the token or if the tokenstarts with an uppercase letter, it is an NE.?
If the difference in the occurrence score ofa token in lang1 dictionary vs lang2 dictio-nary is higher than three, the token is clas-sified as belonging to the language with thehigher score.?
If the token occurs in lang1 and lang2 dictio-naries equally, the token is ?ambiguous?.2.3 Lightweight Spell CheckerThe test tokens that are still not classified arechecked for spelling errors using a simple spellingchecker, complementary to the idea of edit dis-tance.
If the above two classifiers were unable toclassify a token, it might be because these tokenswere misspelled.
This method is based upon theidea that misspelled tokens are still similar to thelanguage that they belong to.
The spell checkerchecks the test token against every token in thedictionaries for similarity (defined below).?Similarity?
is defined as follows: First, a?similar count?
score (SC) is calculated as thenumber of characters that match between twotokens in order.
A test token of length L1is said to be similar to a dictionary token oflength L2 if: SC>max(L1,L2)-1 when L1<7 orSC>max(L1,L2)-2 when L1 ?
7Here, when the test token is checked against atoken in the Nepali dictionary, the characters ?x?and ?6?
in both tokens are replaced with the char-acter sequence ?ch?.
This normalization is per-formed because it is very common for the lattercharacter sequence to be replaced by either of theformer two characters, in the Nepali language.
Ifa test token is found to be similar to a token in adictionary of a certain class, the similarity score tothe class is incremented.
The class with the maxi-mum similarity score is considered to be the classof the test token.1352.4 Special Characters CheckAt this stage, only a minimal number of tokensare left to be labeled.
These tokens are checked tosee if they contain characters not belonging to En-glish Unicode or modifiers.
If one such characteris found, the token is said to be from lang2, eitherSpanish or Nepalese.
All the remaining tokens arecategorized as ?other?.3 Experimental SettingsFor all my experiments, I divided the trainingdata into a ratio of 70:30 for training and cross-validation.
In order to tune the different param-eters, I had to repeat the experiments multipletimes.
So, in order to improve the runtime per-formance, I made use of multithreading.I tested the application by setting the first n-gram length in the Incremental N-Gram Model to3 and 4.
I varied the criteria of the least number ofcharacters that should match between two tokens,in order for the two tokens to be similar.
I observedthe highest accuracy of above 94% in Nepali- En-glish classification when the First n-gram lengthwas 4.
In the case of Spanish-English token clas-sification, I observed the highest accuracy of 88%when the n-gram length was 3.
The spellcheckergave the best results when it had the above men-tioned similarity criteria.The whole classifying task was sure to take along time so I built it to scale with the increas-ing number of CPUs.
I performed the experimentson a 1st Generation Core i7 (Eight Logical Cores)CPU and a Core 2 Duo CPU (2 logical Cores).I observed the best performance when the ap-plication created the number of threads equal tothe number of available CPU cores.
The classifi-cation task completed in the i7 CPU with 8 activethreads in 13 minutes compared to almost 35 min-utes with 2 active threads on the Core 2 Duo CPU.The task completed in around 38 minutes in the i7CPU with 2 active threads.4 Results and AnalysisLanguagePairRecall Precision F1-Score AccuracyNE-EN 0.980 0.968 0.974 0.951ES-EN 0.883 0.489 0.630 0.699Table 2: Tweet level results on the test data.My system obtained an accuracy of 95.1% inthe tweet-level evaluation and 79.4% accuracy inCategory Recall Precision F1-Scorelang1 0.944 0.949 0.947lang2 0.965 0.964 0.965mixed 0.000 1.000 0.000ne 0.510 0.657 0.574other 0.968 0.935 0.951Table 3: Token level results on the test data forNepali-English.Category Recall Precision F1-Scorelang1 0.866 0.761 0.810lang2 0.750 0.861 0.802mixed 0.000 1.000 0.000ambiguous 0.000 0.000 0.000ne 0.155 0.554 0.242other 0.847 0.823 0.835Table 4: Token level results on the test data forSpanish-English.the Facebook post-level evaluation of English-Nepali test tweets.
Although, it was third in tweet-level evaluation, it was only 0.7% behind the besttweet-level system in terms of accuracy.
My sys-tem was second in Facebook post-level evaluationby 6.9%.
It had an accuracy of 94.6% and 86.5%in the token level evaluation of English-Nepalitest tweets and Facebook posts respectively.
Themodel was third in the tweet-token evaluation butstood first in the Facebook-post token evaluation.These results align with the hypothesis of the In-cremental N-Gram Occurrence Model that tokenbelonging to the same language will have moreoverlap of the preceding characters.My system obtained an accuracy of 69.9% inthe tweet-level evaluation and 70.0% accuracy inthe Facebook post-level evaluation of the English-Spanish test data.
It was the least effective in boththe evaluation tasks.
My system had an accuracyof 80.3% and 87.6% in the token level evaluationof English-Spanish test tweets and Facebook postsrespectively.
The model was again the least ef-fective in both the token level evaluation task butby a smaller margin.
The results do not exactlyfollow the hypothesis, but we can say it supportsit because English and Spanish languages share alot of common word prefixes.
Hence my methodis more likely to incorrectly predict some Spanishwords as English and vice-versa.It is evident from the results that this model issuitable when the languages being classified are136LanguagePairRecall Precision F1-Score AccuracyNE-EN 0.900 0.486 0.632 0.794ES-EN 0.882 0.493 0.633 0.700Table 5: Tweet level results on the surprise data.Category Recall Precision F1-Scorelang1 0.913 0.802 0.854lang2 0.936 0.911 0.923ne 0.394 0.833 0.535other 0.886 0.696 0.780Table 6: Token level results on the surprise datafor Nepali-English.highly dissimilar in syntax and structure.
As En-glish and Nepali language do not have the sameancestry they have very different syntax and struc-ture.
The word prefixes used frequently to formNepali words and the syntax of forming variousparts of speech in Nepali language is quite differ-ent than in the English language.In both the training and test datasets, the ratio ofcode-switched to monolingual tweets is higher inNepali than in Spanish, which probably led to mysystem performing worse on tweet level for Span-ish.
Although, this distribution can be anticipatedbecause English is taught from primary schoolinglevels in Nepal.
Almost all the literate populationcan communicate pretty well in English.
Nepalis a country that relies heavily in the tourism in-dustry, and English being a universal language isa second language in major cities and travel desti-nations of the country.
All these factors have ledto a lot of code switching in tweets Nepali tweets.On the other hand, Spanish is a widely spoken lan-guage itself.
The people who know Spanish rarelyneed to learn a second language.
This might be thereason that there are less code-switched tweets forSpanish.My model also has a drawback, which is alsodemonstrated by my evaluation results.
Spanishand English languages do share a lot of commonprefixes.
This maybe due to their shared Indo-European ancestry and the fact that English lan-guage has borrowed a significant number of wordsfrom the French language, which is very similar tothe Spanish language.
The word ?precious?
and?bilingual?
in English is spelled ?precioso?
and?bilingue?
in Spanish.
This similarity of prefixesleads the Incremental N-gram model to classifytokens wrongly based upon the recurrence of theCategory Recall Precision F1-Scorelang1 0.853 0.756 0.801lang2 0.746 0.839 0.789mixed 0.000 1.000 0.000ambiguous 0.000 0.000 0.000ne 0.145 0.550 0.230other 0.826 0.808 0.817Table 7: Token level results on the surprise datafor Spanish-English.same prefixed words documented more frequentlyin one language than the other.
It further resultsin a large number of English-Spanish tweets andFacebook posts to be verified as code switched be-cause, just one token in a tweet that is wronglyclassified as belonging to another language class,will validate the tweet as code-switched.
Tocounter this drawback, when classifying words ofthe language that have the same ancestry and sim-ilar structure and syntax, only the prefixes shouldnot be considered.Another important thing to note is that the taskof evaluation is very taxing on the CPU and takesa lot of time.
Various evaluation techniques areapplied to a token before its correct class is deter-mined.
This time consuming process can be ac-celerated significantly by designing a system thatfollows the data and task parallelism principles i.e.multithreading.
The redesign of the system to sup-port multithreading made the training process al-most 3 times faster.5 Conclusion and Future WorkThe method described in this paper is useful inlanguage identification of code-switched text.
Itworks especially well when the two languages inquestion have different word formation syntax andstructure.
For the languages that are similar inancestry and when one language contains manywords derived from the other language, like Span-ish and English, this method is not very reliable.For these types of languages, considering that theyhave similar syntax and structure, the use of allthe possible n-grams of the tokens in the trainingset and their frequencies might be useful.
Alsoconsidering the suffixes of the word rather thanjust the prefixes might provide greater accuracy forprediction of these types of languages.
These tasksare left as future improvements.137AcknowledgmentI would like to thank the organizers of the Compu-tational Approaches to Code Switching Workshopat EMNLP?14 who gave me an opportunity to par-ticipate in this task.ReferencesPeter Auer.
1988.
A conversation analytic ap-proach to code-switching and transfer.
Codeswitch-ing: Anthropological and sociolinguistic perspec-tives, 48:187?213.William B Cavnar, John M Trenkle, et al.
1994.N-gram-based text categorization.
Ann Arbor MI,48113(2):161?175.Anik Dey and Pascale Fung.
2014.
A hindi-englishcode-switching corpus.
In The 9th InternationalConference on Language Resources and Evaluation(LREC), Reykjavik.Heba Elfardy and Mona T Diab.
2012.
Token levelidentification of linguistic code switching.
In COL-ING (Posters), pages 287?296, Mumbai, India.Constantine Lignos and Mitch Marcus.
2013.
To-ward web-scale analysis of codeswitching.
In An-nual Meeting of the Linguistic Society of America.Dong Nguyen and A Seza Dogruoz.
2014.
Wordlevel language identification in online multilingualcommunication.
In Proceedings of the 2013 Con-ference on Empirical Methods in Natural LanguageProcessing.Thamar Solorio, Elizabeth Blair, Suraj Maharjan, SteveBethard, Mona Diab, Mahmoud Gonheim, AbdelatiHawwari, Fahad AlGhamdi, Julia Hirshberg, AlisonChang, and Pascale Fung.
2014.
Overview for thefirst shared task on language identification in code-switched data.
In Proceedings of the First Workshopon Computational Approaches to Code-Switching.EMNLP 2014, Conference on Empirical Methods inNatural Language Processing, Doha, Qatar.138
