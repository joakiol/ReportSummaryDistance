A PROLOG Implementation of Government-Binding TheoryRobert J. KuhnsArtificial Intelligence CenterArthur D. Little, Inc.Cambridge, MA 02140 USAAbstrae_~tA parser which is founded on ChomskytsGovernment-Binding Theory and implemented inPROLOG is described.
By focussing on systems ofconstraints as proposed by this theory, thesystem is capable of parsing without anelaborate rule set and subcategorizationfeatures on lexical items.
In addition to theparse, theta, binding, and control relations aredetermined simultaneously.1.
IntroductionA number of recent research efforts haveexplicitly grounded parser design on linguistictheory (e.g., Bayer et al (1985), Berwick andWeinberg (1984), Marcus (1980), Reyle and Frey(1983), and Wehrli (1983)).
Although many ofthese parsers are based on generative grammar,and transformational grammar in particular, withfew exceptions (Wehrli (1983)) the modularapproach as suggested by this theory has beenlagging (Barton (1984)).
Moreover, Chomsky(1986) has recently suggested that rule-basedparsers are implausible and that parsers couldbe based on lexical properties and structuredetermining principles.This paper describes a principle-basedparser which is modular in design and whichprocesses sentences simultaneously with respectto modules of Government-Binding (GB) Theory(Chomsky (1981, 1982, 1986)).
This parserrequires few grammar rules and no explicitsubcategorization features for VPs.
We alsoattempt to show that logic programming(specifically, PROLOG (Clark and Tarnlund(1982), Clocksin and Mellish (1984), Hogger(1984), and Kowalski (1979))) makes perspicuousthe principles and constraints which underliethis parser.2.
Overview of Government-Binding TheoryGB-Theory (Chomsky (1981)) has shifted theemphasis of grammar from a system of rules to asystem of modules which include:X-barThetaCaseBoundingTraceControlBindingGovernmentFor the purposes (and space limitations) ofthis paper we only briefly describe the theoriesof X-bar, Theta, Control, and Binding.
We alsowill present three principles, viz., Theta-Criterion, Projection Principle, and BindingConditions.2.1  X-Bar TheoryX-bar theory is one part of GB-theory whichcaptures eross-categorial relations andspecifies the constraints on underlyingstructures.
The two general schemata of X-bartheory are:(1)a. X~Spec i f ie rb.
X-------~X ComplementThe types of categories that may precede orfollow a head are similar and Specifier andComplement represent this commonality of thepre-head and post-head categories, respectively.Although the parse operates in accordancewith X-bar theory, it does not require specificinstructions for each X (X = N, V, A, P).2.2 Theta-TheoryTheta-theory is the module which determinesa sentence's argument structure and theta orthematic-role (e.g., agency, theme, locative)assignments.
It is through theta-relations andgeneral principles that arguments and theirpossible positions can be predicted andexplained.Theta-roles are assumed to be assignedcompositionally, in that a head (i.e., X of anXP = X) assigns a theta-role to its complementand this pair (head and complement) in turndetermines the theta-role (if one exists) of itsspecifiers.
For example, in sentences:(2)a. John broke the bottle.h.
John broke his (own) leg.BREAK assigns the role of theme to pottle andin a. and b., respectively.
However, the VPbroke the bottle assigns the role of agent toJohn in a., while broke his leg assigns someother role (perhaps, experiencer) to John in b.546~ t v  CategoriesOne difficulty parsing strategies must solveis the detection of the presence of gaps orempty categories and their antecedents.
Thereare three different sets of properties that maybe associated with empty categories (Chomsky(1982)), and these sets determine whether anempty category is a trace, PRO, or a variable.While all of these empty categories arephonologically null, their location andinterpretation must be determined for a parse tobe complete.
In short, a trace remains at anextraction site of Move ~, PRO is a pronominalwhich may be present in ungoverned positions,and variables are Case-marked traces.2~4 Control TheorxControl theory determines the controller ofPRO.
In other words, the reference of PRO isderivable by Control theory which assigns aninterpretation to PRO as subjects of embeddedinfinitives:(3)a. John.
wants \[PRO.
to leave\].l lb.
John persuaded Bill i \[PROj to leave\].In both (3) a. and b., i=j, but in (3) a. Johnis the subject, and in b., Bill is the object.In other words, want and persuade are subjectand object control verbs, respectively, and arelexically marked as such.2.5 B i n d i n ~Binding theory constrains the assignment ofindices (which are interpreted as intendedcoreference).
The binding conditions are:(4)a.
An anaphor is bound in its governingcategory.b, A pronominal is free in its governingcategory.e.
An R-expression is free.An R-expression is a referential term such as aproper noun or a variable.
A governing categoryis the minimal S or NP which contains an anaphoror pronominal and a governor of that anaphor orpronominal.
And X is a governor of Y iff X = A,N, V, or P and Y is contained in the smallestmaximal projection of X (i.e., the smallest XP)and X c-commands Y. C-command is defined in theusual way, that is, X c-commands Y iff the firstbranching node dominating X also dominates Y,and X does not dominate Y.2.6 Cha in~ Theta -Cr i te r i~_~et ionPrinc\[LleIntuitively, a chain encodes the history ofmovement of a constituent.
We distinguishbetween two landing sites of movement, name\].y,an arg~unent position (A-position) and a non-argument position (A-position).
NP-movementmoves or relates a gap with another A-positionwithin an S while w__hh-movement relates a positionin an S to a position in COMP, which is outsideof S and is an A-position.
We will limit ourdiscussion to A-positions.Definition.
A chain ( e ~ .
.
.
.
_ %~ is aseque.ee consisting of a .oau1  locallyhound traces ~ 2''''' ~n'Definition.
A locally binds B iff either Ais the nearest head binding B or A is a locallybound trace which is the nearest binder of B.It should be noted that all arguments mustbe in one and only one chain.
It is argued inGB-theory that both Case and theta-roles areassigned to chains rather than individual NPs.Theta-roles are assigned according to a strictcondition called the Theta-criterion.
(5) Each chain receives one and only onetheta-role.This says basically that theta-role assignmentsare complete and well-defined.The question of where in a grammar theTheta-criterion holds is answered by theProjection Principle.
(6) The Theta-criterion is satisfied atall levels of syntactic represent-ation, name\].y, D-structure,S-structure, and LF (logical form).We exploit the notions of chains, andprinciples (5) and (6) in our system.
Since ahead theta-marks its colnplement as specified inthe lexicon, the force of (5) and (6) is thatD-structure, S-structure, and LF are projectionsfrom the lexicon.3.
Modules of the ParserThe parser processes a sentence and outputsa triple whose parts are simultaneouslydetermined and consists of a constituentanalysis, intended coreference relations(binding and control), and argument structures(theta-relations).
Since a distinguishingf&ature of this parser is the processing of thelatter two representations, we will discuss onlythe derivations of them.It should be noted that, although thestructural analysis of the parse will not bepresented in this paper, the parser is adeterministic one with a limited look-aheadfacility (Marcus (\].980)).
In essence, it: isdeterministic in that a\].l structures created arepermanent and cannot be modified or deleted, inother words, the structures created during theparse are equivalent to the structures of theoutput of the parse.The next two subsections will sketch thelexical component and the scope of the grammar,Binding, control, and theta conditions will bepresented in Sections 4. and 5.3.1 LexiconThe lexicon is a critical component; itcontains all the processable words and theirassociat:ed syntactic and semantic features.syntactic characterization includes X-barfeatures (iN, iV), tense, number, etc.The547Traditionally, the features also containsubcategorizations or templates which specifythe types of complements (if any) a lexicalentry could take.
For instance, a subcategor-ization would indicate whether or not a verb istransitive.
However, these templates areredundant in that we can replace them with thetheta-roles which an entry (e.g., a verb)assigns to or theta-marks its complement.
Fromthis, the parser derives the subcategorization.For instance, the verb told selects a goal and aproposition.
A goal is structurally realized asan NP and a proposition must be either an S oran NP.
The choice between the structure of S orNP is determinable given a particular S asinput.3,2 Grammar RulesIncorporating GB theory into the parserhelps to eliminate many grammar rules because oftheir redundancy.
As seen above, syntacticstructure is derivable from means other thanexplicit rules.
The parser does require a set ofgrammar rules and we hope to reduce this set inlater versions.
It should be noted that sincepriority during implementation was given toBinding theory, Theta-theory, and chains, somerules were used for ease of development.
Asmentioned above, we plan to eliminate ruleswhich are unnecessary because the structuresthey specify can be derived from other generalprinciples.
However, some rules which describelanguage-speclfic properties or markedstructures may be necessary and, thus, will haveto be stated explicitly.Some of the rules the parser presently needsare those that deal with NP constructions.
Therule S--n~NP INFL VP is used as well as somespecific rules for determining imperatives andinterrogatives (e.g., subject-auxiliaryinversion).We are using rule to mean a phrase structurerule (e.g., a familiar rewriting rule or anX-bar schema) within a grammar.
Rule can alsodenote an implementation of the above concept,i.e., a production rule or a PROLOG clause.
Thechoice of interpretation should be clear fromcontext.As contrasted with rules, principles aregeneral constraints on syntactic representations(and not on rule application as could beargued).
The significance of principles is toconstrain the class of possible syntacticrepresentations.
The Projection Principle (6),for instance, severely restricts the argumentstructure of D-structure, S-structure, and LF.This bound on syntactic representation enables aparser to predict syntactic structure withoutexplicit rules.4.
Implementation ConsiderationsThe next several sections will focus on theconceptual overview of the processors involvedin our system in addition to fragments of aPROLOG implementation of certain aspects of thesystem.5484.1 The InterpreterSimilar to Marcus (1980), the basic datastructures of this parser are two lists whoseelements are represented as terms of predicates.One list (INPUT-BUFFER) is for input and theother (PROCESSED-NODES) is for the (partially)processed nodes or subtrees.
These two listsare viewed as changing states rather thanpushing and popping stacks.
This approach seemsreasonable since the parser is not relying onproduction-l ike grammar rules.Although there are lower-level operations orpredicates, e.g., LABEL, which labels nodes withfeatures, the basic predicates which are centralare CREATE-NODE and INSERT.
CREATE-NODE willconstruct a new node of a pre-specified type andattach it to a child of a particular node.INSERT will insert a specific lexical item, atrace, or a PRO as appropriate.
Since theoutput that represents the structure is thefamiliar labelled bracketing, these predicatesdo call list manipulation predicates.It should be noted that many of the tree-walking algorithms that are needed to examineterms of PROCESSED-NODES can be succinctlyspecified while the underlying unification/resolution components of PROLOG produce thenecessary tree walk.4.2 Grammar InterfaceAs noted above, the parser is constrained byX-bar theory.
So, if a specifier of a categoryis the first term of INPUT-BUFFER, then byschema (1)a. the parser creates (using CREATE-NODE) first an XP, and then the specifier.
TheX-bar features specified in the lexicondetermine the type of XP.
Similarly, (1)b. willdetermine when the parser is to create an X nodeand a complement.Since all XPs must contain a head, apredicate CREATE-HEAD is a separate module.4.3 IndexingBinding theory (4)a.-e. is represented as anindexing scheme on the bracketed structure beinggenerated by the parser.
In order to illustratethemain  ideas, the heads of underlying lower-level predicates will only be described withouttheir bodies.
The predicates PARENT-OF (?child,?parent, ?structure) and DOMINATE (?nodel,?node2, ?structure) are fairly obvious in thatin the former ?parent is the node immediatelydominating ?child in some tree (?structure).DOMINATE states that ?nodel is dominated by?node2 in ?structure.It should be emphasized that Binding Theorycan apply only after structure has been built.So ?structure in both predicates refers to thetree in PROCESSED-NODES.BRANCHING-NODE, FIRST-BRANCHING-NODE, andC-COMMAND are defined in the obvious way.
Withthe assumption that only S and NP are cyclicnodes, the PROLOG representations of these factsare CYCLIC-NODE (S) and CYCLIC-NODE (NP).predicates are used to define Governing-Category.TheseBinding theory can now be clearly expressedas:(7)a. BINDING-THEORY (?argument,?structure):--ANAPHOR (?argument)GOVERNING-CATEGORY (?gov-cat,?argument, ?structure)BOUND (?gov-cat, ?argument,?structure)b. BINDING-THEORY (?argument,?structure):--PRONOMINAL (?argument)GOVERNING-CATEGORY (?gov-cat,?argument, ?structure)FREE (?gov-eat, ?argument,?structure)c. BINDING~THEORY (?argument,?structure):--R-EXPRESSION (?argument)ABSOLUTE-FREE (?sentence, ?argument,?structure).BOUND, FREE, and ABSOLUTE-FREE are thepredicates which have access to PROCESSED-NODESand they specify as to whether or not twoindices are to be unified.
BOUND will ensuretwo indices are identical and FREE and ABSOLUTE-FREE will  do otherwise.
The PROLOG statements(7)a,-c. are a natural expression of (4)a.-c.4.4 ChainsThe process by which chains are constructedand theta-roles assigned will be illustrated inthe next section.
The notion of chain and localbinding can easily be formalized as:(8)a.
CHAIN ( ).b.
CHAIN (?N):-- Head (?N).e.
CHAIN (?NI, ?N2 .
.
.
.
.
?NK):--.LOCAL-BIND (?NI, ?N2)CHAIN (?N2...?NK).(9)a.
LOCAL-BIND (?NI, ?N2):--HEAD (?NI)NEAREST-BINDER (?NI, ?N2).b.
LOCAL-BIND (?NI, ?N2):--TRACE (?NI)NEAREST-BINDER (?NI, ?N2).For expository reasons, the sequence processingpredicates have been suppressed and notationabused.
However, NEAREST-BINDER where the first:term binds the second will involve C-COMMAND andlocality constraints.
A chain consists ofeither a head ((8)b.)
or a sequence consistingof one head (?NI) and one or more traces(?N2 ..... ?NK).
The local binding condition inthe definition can be captured naturally by therecursive call in (8)e. The clause in (8)a. isthe exit of the recursion.5.
Two Examples of the Parsin S t r ~This section will provide two overlappingexamples to illustrate the strategy the parseruses to interface with the various modules ofGB-theory in order to arrive at a final parsecomplete with indexing and theta-relations.Suppose the input to the parser is thesentence:(i0) The instructor told the students toleave early.The parser first constructs the NP th_eeinstructor and then encounters the verb told.It determines (:from the lexicon) the theta-rolesassigned by told to its complements.
In thiscase, the theta-.roles are goal and proposition.As discussed above, a component of the parserinfers the constituent structure of thecategories marked by a verb.
Thus, the systemdetermines that there ought to be an NP adjacentto told in (I0) (otherwise, it inserts a tracein that position) followed by an NP or S. Withits limited look-ahead capability, the parsersees the two items too and the verb leave.
Itthen knows the realization (viz., S) of thesecond object arld is able to eolnplete the VPand, consequently, the parse.In order to see the interactions of theta-relations, Binding conditions, and Controltheory consider the sentence.
( I i )  The students were told to leave early.Suppressing unnecessary details, weconstruct the various representations of theparse as (ii) is processed.As the stndents is labelled, it is pushed onto achain CHAIN-l, and assigned an index.
With theverb to\].d being passivized, i.e., in theenvironment of Mere, the parser will detect agap.
As in (I0) the parser determines (from itstheta-markings) that two objects are requiredfor to\].d.
With no explicit NP object of toldpresent, it inserts a trace in the parsed treeand pushes the trace onto CHAIN-I and assignsCHAIN-I the theta-role of theme (this role isthe role which told theta-marks its firstobject).
The parser invokes principle (4)a.
(i.e., (7)a.)
of Binding Theory and co-indexesthe students and trace.
CHAIN-\].
is now completebecause CHAIN-I is assigned one (and only one)theta-role.Note that while this parser has a limitedlook-ahead, it is able to look at all partialstructures it has created (although it cannotalter any of them).
In this way, this parsercan determine local bindings as it processes.Thus, in this case, the parser knows that the NPthe students locally binds the trace after toldand CHAIN-I is well-formed.Again, as in (I0) the parser determines theexistence of an S and creates PRO as the subject549of the embedded infinitive< It pushes PRO ontoa new CHAIN-2 and later assigns it the role ofagent.
The parser also equates the indices ofCHAIN-I and CHAIN-2 because told is an objectcontrol verb and the parser already knows theindex of the trace.
In this way, Control theoryis maintained and the correct referentialrelations hold.
The parse is completed in theusual manner.With the construction of chains and theta-role assignment, we are able to arrive at a(formal) semantic relation while parsing, butunlike Marcus (1980), it is based on aprincipled, l inguistically-based representationof arguments.
Also, the binding relations arecomputed when sufficient information is presentto comply with Binding or Control theory.6.
Syntactic Scope and Implementation IssuesThe parser has a wide coverage of syntacticstructure.
It is capable of determining gaps in(multiple) wh-movements.
For instance, in(12) Who \[did Bill think \[t \[the doctortreated t\]\]\]there are two gaps, one in COMP and the other inthe object position of treated.
The latterempty category is determinable as in Section 5.However, the trace in COMP is inferred (usingBounding Theory or subjaeency conditions, whichrestrict distance between landing and extractionsites of movement) because who is in a COMPposition and must bind a variable.
However,this binding relation cannot be "too far" and solocal binders can be constructed when an S isencountered before a Case-marked trace (i.e., avariable) is.
In (12) we see that the lasttrace is the variable which is ultimately boundby who, but subjacency requires a local binderand it must be in anA position.
Thus, thetrace in COMP is inserted, although the variableis not yet visible to the parser.A fuller account of theta representations isalso being developed in that although chains areconstructed, the theta relations among chainsmust be obtained.
In (2)a. there are two chains(John) and (the bottle) and in (2)b. the chainsare (John) and (his leg).
However, it is theverb together with the chains (the bottle) and(his leg) which determine the theta-role of(John).
This requires a more substantiveaccount of theta-theory than is currentlyavailable in the literature.Some time is being spent in extending theparser to process parasitic gaps, to determinethe cases where pronouns behave as variables,and to determine quantifieational relations(Cushing (1982, 1983)).7.
ConclusionsWe believe that a modular parser grounded onGB theory, a theory of linguistic subsystems, isfeasible and significant in that it sheds lighton how a theory of competence may be embedded inone aspect of language use, namely, parsing.550Moreover, the strategy we are pursuing is toexploit the interfaces of GB subtheories whichseem to allow simultaneous processing ofsyntactic structure, theta-relations, andbinding conditions.
This may help to explainthe rapidity of h~nan sentence understanding.8.
AcknowledgementsI would like to thank Steven Cushing, DanielSullivan, and Mary Zickefoose for reading andcommenting on an earlier draft of this paper.9.
ReferencesBarton, Jr., G.E., (1984), "Toward a Principled-Based Parser," A.I.
Memo No.
788, MIT,Cambridge, MA.Bayer, S., L. Joseph, and C. Kalish, (1985),"Grammatical Relations as the Basis for NaturalLanguage Parsing and Text Understanding," Proc.of IJCAI-85, Los Angeles, CA, pp.
788-790.Berwick, R.C., and A.S. Weinberg, (1984), Th___eeGrammatical Basis of Linguistic Performance, TheMIT Press, Cambridge, MA.Chomsky, N., (1981), Lectures on Government andBinding, Foris Publications, Dordrecht-Holland.Chomsky, N., (1982), Some Concepts an___ddConsequences of the Theory of Government andBinding, The MIT Press, Cambridge, MA.Chomsky, N., (1986), K_Dowledge of Lan u~g~,Praeger, New York, NY.Clark, K.L., and S.-A.
Tarnlund, (1982),~ ,  Academic Press, New York, NY.Clocksin, W.F., and C.S.
Mellish, (1984),PrP~ramming in Prolog, Springer-Verlag, Berlin.Cushing, S., (1982), Quantifier Meanin s :~Study in t~ Dimensions of Semantic Competene~,North-Holland, Amsterdam.Cushing, S., (1983), "Abstract ControlStructures and the Semantics of Quantifiers,"Proceedings of the First Conference of theE u r o ~ t e r  of the Association forComputational L i n ~ ,  Pisa, Italy.Hogger, C.J., (\].984), Introduction to Log!~~ ,  Academic Press, New York, NY.Kowalski, R.A., (1979), Logic for ProblemSolving, Elsevier Science Publishing Co., Inc.,New York, NY.Marcus, M., (1980), A Theory of SyntacticRecognition for Natural Language, The MIT Press,Cambridge, MA.Reyle, V., and W. Frey, (1983), "A PROLOGImplementation of Lexical Functional Grammar,"Proc of IJCAI-83, Karlsruhe, West Germany,pp.
693-695.Wehrli, E., (1983), "A Modular Parser forFrench," Proc of IJCAI-_83, Karlsruhe, WestGermany, pp.
686-689.
