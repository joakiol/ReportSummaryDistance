Coling 2010: Demonstration Volume, pages 17?20,Beijing, August 2010Have2eat: a Restaurant Finder with Review Summarizationfor Mobile PhonesGiuseppe Di Fabbrizio and Narendra GuptaAT&T Labs - Research, Inc.{pino,ngupta}@research.att.com {sbesana,pmani}@attinteractive.comSveva Besana and Premkumar ManiAT&T Interactive - Applied ResearchAbstractHave2eat is a popular mobile applicationavailable for iPhone and Android-based de-vices that helps users to find and assessnearby restaurants.
It lists restaurants lo-cated around the device and provides a quickhighlight about the opinions expressed byonline reviewers.
Have2eat summarizes tex-tual reviews by extracting relevant sentencesand by automatically generating detailed rat-ings about specific aspects of the restaurant.A compact one-screen digest allows users toquickly access the information they need, ex-pand to full review pages, and report their ex-perience online by entering ratings and com-ments.1 IntroductionBloggers, professional reviewers, and consumerscontinuously create opinion-rich web reviews aboutproducts and services, with the result that textual re-views are now abundant on the web and often con-vey a useful overall rating.
However, an overall rat-ing cannot express the multiple or conflicting opin-ions that might be contained in the text and screen-ing the content of a large number of reviews couldbe a daunting task.
For example, a restaurant mightreceive a great evaluation overall, while the servicemight be rated below-average due to slow and dis-courteous wait staff.
Pinpointing opinions in doc-uments, and the entities being referenced, wouldprovide a finer-grained sentiment analysis and bet-ter summarize users?
opinions.
In addition, select-ing salient sentences from the reviews to textuallysummarize opinions would add useful details to con-sumers that are not expressed by numeric ratings.This is especially true for so-called road warriors andmobile users ?on the run?
who are often dealing withlimited time and display real estate in searching for arestaurant to make a decision.Have2eat1 is a popular2 mobile application avail-able for iPhone and Android-based devices that ad-dresses these challenges.
Have2eat uses the geo-location information either from the GPS device orexplicitly entered by the user to produce a list ofrestaurants sorted by distance and located within aspecific radius from the originating location.
In addi-tion, when restaurant reviews are available, a compactone-screen digest displays a summary of the reviewsposted on the web by other customers.
Customerscan expand to read a full review page and also entertheir own ratings, comments and feedback.
The re-view summaries are visualized on the mobile screen:?
graphically by thumbs-up (positive reviews)and thumbs-down (negative reviews) for differ-ent aspects of the restaurant;?
textually by a few sentences selected from re-view texts that best summarize the opinionsabout various aspects of the restaurant expressedin the reviews;Extracting opinions from text presents many nat-ural language processing challenges.
Prior work onsentiment analysis has been focusing on binary clas-sification of positive and negative opinions (Turney,2002; Pang et al, 2002; Yu and Hatzivassiloglou,2003), while aspect rating inference (e.g., the taskof determining the opinion polarity in a multi-pointscale) has been previously analyzed in Pang andLee (2005); Goldberg and Zhu (2006); Leung et al(2006).
More recently, Snyder and Barzilay (2007);Shimada and Endo (2008) extended the inferenceprocess to multi-aspect ratings where reviews includenumerical ratings from mutually dependent aspects.Snyder and Barzilay (2007) shows that modeling thedependencies between aspect ratings in the same re-views helps to reduce the rank-loss (Crammer andSinger, 2001).1www.have2eat.com2More than 400,000 downloads to-date for the iPhoneversion alone17There are similar mobile applications obtainableeither on the Apple iPhone App Store or as web-based mobile application, such as Zagat3, UrbanS-poon4, YP Mobile5, and Yelp6, but, to the extent ofour knowledge, most of them are only focused onfinding the restaurant location based on proximityand some restaurant filtering criterion.
When avail-able, restaurant reviews are simply visualized as con-tiguous list of text snippets with the overall experi-ence rating.
None of the listed applications includeextended rating predictions and reviews summariza-tion.2 System DescriptionThe have2eat system architecture is composed of twoparts: 1) predictive model training ?
illustrated in Fig-ure 1 and described in section 2.1, and 2) graphicaland textual summarization ?
shown in Figure 2 anddescribed in section 2.2.2.1 Graphical summarization by thumbsup/downThe majority of textual reviews available online areaccompanied by a single overall rating of the restau-rant.
To predict consistent ratings for different as-pects, namely food, service, atmosphere, value, andoverall experience, we use machine learning tech-niques to train predictive models, one for each as-pect; see Figure 1.
More specifically, we used ap-proximately 6,000 restaurant reviews scraped from arestaurant review website7.
On this website, besidestextual reviews, users have also provided numericalratings for the five aspects mentioned above.
Ratingsare given on a scale of 1 to 5, 1 being poor and 5excellent.
We experimented with different regressionand classification models using a host of syntactic andsemantic features.
We evaluated these models usingrank-loss metrics which measure the average differ-ence between predicted and actual ratings.
We foundthat a maximum entropy (Nigam et al, 1999) modelcombined with a re-ranking method that keeps in con-sideration the interdependence among aspect ratings,provided the best predictive model with an averagerank-loss of 0.617 (Gupta et al, 2010).
This resultsis better than previous work on the same task as de-scribed in Snyder and Barzilay (2007).To cope with the limited real estate on mobilephones for displaying and allowing users to inputtheir opinions, the predicted ratings were mappedonto thumbs?up and thumbs?down.
For each restau-3mobile.zagat.com4www.urbanspoon.com5m.yp.com6m.yelp.com7www.we8there.comrant the proportion of reviews with rating of 1 and 2was considered thumbs down and ratings of 4 and 5were mapped to thumbs up.
Table 1 shows an exam-ple of this mapping.Reviews Thumbsa b c Up DownAtmosphere 3 2 4 50% 50%Food 4 4 5 100% 0Value 3 2 4 50% 50%Service 5 5 5 100% 0Overall 4 4 5 100% 0Table 1: Mapping example between ratings andthumbs up/down.
Ratings of 3 are considered neutraland ignored in this mapping2.2 Textual summaries by sentence selectionFigure 2 shows how summary sentences are selectedfrom textual reviews.
As described in the previoussection, we trained predictive models for each aspectof the restaurant.
To select summary sentences wesplit the review text into sentences8.
Using the pre-dictive models and iterating over the restaurant list-ings, sentences in the reviews are classified by aspectratings and confidence score.
As a result, for eachsentence we get 5 ratings and confidence scores forthose ratings.
We then select a few sentences thathave extreme ratings and high confidence and presentthem as summary text.We evaluated these summaries using the followingmetrics.1.
Aspect Accuracy: How well selected sentencesrepresent the aspect they are supposed to.2.
Coverage: How many of the aspects present inthe textual reviews are represented in the se-lected sentences.8For this purpose we used a sentence splitter based onstatistical models which besides n-grams also uses wordpart-of-speech as features.
This sentence splitter wastrained on email data and is 97% accurate.Figure 1: Predictive model training18Figure 2: Graphical and textual summarization3.
Rating Consistency: How consistent the se-lected sentences with the summarizing aspectratings are.4.
Summary quality: Subjective human judgmentsas to how good the summaries are and automaticmulti-document summarization to how good thesummaries are compared to a manually createdGOLD standard using ROUGE-based (Lin, 2004)metrics.A detailed description of the summarization taskevaluation will be published elsewhere.3 DemonstrationWhen launching the application, users are presentedwith a list of twenty nearby restaurants.
The user canbrowse more restaurants by tapping on a link at thebottom of the page.
For each listing we show the dis-tance from the current location and, if available, weprovide a thumbs-up or thumbs-down, price informa-tion and the summary sentence with the highest confi-dence score across aspects.
Figure 3 shows an exam-ple of the List page.
If users want a list of restaurantsfor a different location they can tap the Change but-ton at the top of the page.
This action will bring upthe Location page where the user can enter city andstate and/or a street address.Users can select a restaurant in the list to view thedetails, see Figure 4.
Details include address, phonenumber and thumbs up/down for the overall, food,service, value and atmosphere aspects.
The user canprovide feedback by tapping on the thumbs-up orthumbs-down buttons, as well as by leaving a com-ment at the bottom of the screen.
This page also in-cludes a few summary sentences with extreme ratingsand high confidence scores.
An example of selectedsentences with their polarity is shown in Table 2.
Bytapping on any of the sentences the users can viewthe full text of the review from which the sentencewas selected.
Users can also add a new restaurant bytapping the Add icon in the tab bar.Figure 3: Have2eat listings screen shot on iPhoneFigure 5 displays the review selected in the Detailspage along with any other reviews which exist for therestaurant.
Users can give feedback on whether theyfound the review helpful or not by using a thumbs-upor a thumbs-down respectively.
Users can also add areview by tapping on a link at the bottom of the page.4 ConclusionThis demonstration has shown a restaurant finder ap-plication for mobile phones, which makes use ofsummarization techniques to predict aspect ratingsfrom review text and select salient phrases express-ing users?
opinions about specific restaurant aspects.Users can directly contribute with their feedback bytapping on the aspect thumbs buttons or by directlytyping comments.19Figure 4: Have2eat automatically predicted aspectratings and summaryRestaurant 1 (3 reviews)+ The soups are GREAT!
Everything that we have ever ordered hasexceeded the ex...+ Delivery is prompt and credit cards are welcome+ Their chicken fried rice is the second best in Southern California.Restaurant 2 (8 reviews)+ Great tasting burgers, friendly fast service!+ The inside is warm and even though the chairs looked uncomfort-able, they were not at all.- Too many other places to try to worry about getting mediocre foodas a high price.Restaurant 3 (4 reviews)+ The salads are tasty, the breadsticks are to die for.- We waited approximate 10 more minutes and then asked howmuch longer.+ A fun place to go with faimily or a date.+ If you like salt then this is the place to go, almost everything is fullof s...Table 2: Example of extracted summariesAcknowledgmentsWe thank Jay Lieske, Kirk Boydston, Amy Li, GwenChristian, and Remi Zajac for their contributions andgreat enthusiasm.ReferencesCrammer, Koby and Yoram Singer.
2001.
Pranking withranking.
In Thomas G. Dietterich, Suzanna Becker, andZoubin Ghahramani, editors, Neural Information Pro-cessing Systems: Natural and Synthetic (NIPS).
MITPress, Vancouver, British Columbia, Canada, pages641?647.Goldberg, Andrew B. and Jerry Zhu.
2006.
Seeingstars when there aren?t many stars: Graph-based semi-supervised learning for sentiment categorization.
InTextGraphs: HLT/NAACL Workshop on Graph-basedAlgorithms for Natural Language Processing.Gupta, Narendra, Giuseppe Di Fabbrizio, and PatrickHaffner.
2010.
Capturing the stars: Predicting ratingsfor service and product reviews.
In Proceedings of theHLT-NAACL Workshop on Semantic Search (Semantic-Search 2010).
Los Angeles, CA, USA.Figure 5: Have2eat reviewsLeung, Cane Wing-ki, Stephen Chi-fai Chan, and Fu-laiChung.
2006.
Integrating collaborative filtering and sen-timent analysis: A rating inference approach.
In Pro-ceedings of The ECAI 2006 Workshop on RecommenderSystems.
Riva del Garda, I, pages 62?66.Lin, Chin-Yew.
2004.
ROUGE: A package for automaticevaluation of summaries.
In Proc.
ACL workshop onText Summarization Branches Out.
page 10.Nigam, Kamal, John Lafferty, and Andrew Mccallum.1999.
Using maximum entropy for text classification.In IJCAI-99 Workshop on Machine Learning for Infor-mation Filtering.
pages 61?67.Pang, Bo and Lillian Lee.
2005.
Seeing stars: Exploitingclass relationships for sentiment categorization with re-spect to rating scales.
In Proceedings of the Associationfor Computational Linguistics (ACL).
pages 115?124.Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
Sentiment classification using ma-chine learning techniques.
In Proceedings of the Con-ference on Empirical Methods in Natural Language Pro-cessing (EMNLP).
pages 79?86.Shimada, Kazutaka and Tsutomu Endo.
2008.
Seeingseveral stars: A rating inference task for a documentcontaining several evaluation criteria.
In Advances inKnowledge Discovery and Data Mining, 12th Pacific-Asia Conference, PAKDD 2008.
Springer, Osaka, Japan,volume 5012 of Lecture Notes in Computer Science,pages 1006?1014.Snyder, Benjamin and Regina Barzilay.
2007.
Multipleaspect ranking using the Good Grief algorithm.
InProceedings of the Joint Human Language Technol-ogy/North American Chapter of the ACL Conference(HLT-NAACL).
pages 300?307.Turney, Peter.
2002.
Thumbs up or thumbs down?
Seman-tic orientation applied to unsupervised classification ofreviews.
In Proceedings of the Association for Compu-tational Linguistics (ACL).
pages 417?424.Yu, Hong and Vasileios Hatzivassiloglou.
2003.
Towardsanswering opinion questions: Separating facts fromopinions and identifying the polarity of opinion sen-tences.
In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing (EMNLP).20
