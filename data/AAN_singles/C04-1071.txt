Deeper Sentiment AnalysisUsing Machine Translation TechnologyKANAYAMA Hiroshi NASUKAWA TetsuyaWATANABE HideoTokyo Research Laboratory, IBM Japan, Ltd.1623-14 Shimotsuruma, Yamato-shi, Kanagawa-ken, 242-8502 Japan{hkana,nasukawa,hiwat}@jp.ibm.comAbstractThis paper proposes a new paradigm for senti-ment analysis: translation from text documentsto a set of sentiment units.
The techniques ofdeep language analysis for machine translationare applicable also to this kind of text miningtask.
We developed a high-precision sentimentanalysis system at a low development cost, bymaking use of an existing transfer-based ma-chine translation engine.1 IntroductionSentiment analysis (SA) (Nasukawa and Yi, 2003; Yiet al, 2003) is a task to obtain writers?
feelings as ex-pressed in positive or negative comments, questions,and requests, by analyzing large numbers of docu-ments.
SA is becoming a useful tool for the com-mercial activities of both companies and individualconsumers, because they want to sort out opinionsabout products, services, or brands that are scat-tered in online texts such as product review articles,replies given to questionnaires, and messages in bul-letin boards on the WWW.This paper describes a method to extract a setof sentiment units from sentences, which is the keycomponent of SA.
A sentiment unit is a tuple ofa sentiment1, a predicate, and its arguments.
Forexample, these sentences in a customer?s review ofa digital camera (1) contained three sentiment units(1a), (1b), and (1c).
Apparently these units indicatethat the camera has good features in its lens andrecharger, and a bad feature in its price.It has excellent lens, but the price is too high.I don?t think the quality of the rechargerhas any problem.???
(1)[favorable] excellent (lens) (1a)[unfavorable] high (price) (1b)[favorable] problematic+neg (recharger) (1c)The extraction of these sentiment units is not atrivial task because many syntactic and semantic op-erations are required.
First, the structure of a pred-icate and its arguments may be changed from the1Possible values of a sentiment are ?favorable?, ?unfavor-able?, ?question?, and ?request?.
In this paper the discussionis mostly focused on the first two values.syntactic form as in (1a) and (1c).
Also modal, as-pectual, and negation information must be handled,as in (1c).
Second, a sentiment unit should be con-structed as the smallest possible informative unit sothat it is easy to handle for the organizing processesafter extraction.
In (1b) the degree adverb ?too?
isomitted to normalize the expression.
For (1c), thepredicate ?problematic?
has the argument ?recharger?instead of the head word of the noun phrase ?thequality of the recharger?, because just using ?qual-ity?
is not informative to describe the sentiment ofthe attribute of a real-world object.
Moreover, dis-ambiguation of sentiments is necessary: in (1b) theadjective ?high?
has the ?unfavorable?
feature, but?high?
can be treated as ?favorable?
in the expression?resolution is high?.We regard this task as translation from text tosentiment units, because we noticed that the deeplanguage analysis techniques which are required forthe extraction of sentiment units are analogous tothose which have been studied for the purpose oflanguage translation.
We implemented an accuratesentiment analyzer by making use of an existingtransfer-based machine translation engine (Watan-abe, 1992), replacing the translation patterns andbilingual lexicons with sentiment patterns and a sen-timent polarity lexicon.
Although we used manytechniques for deep language analysis, the systemwas implemented at a surprisingly low developmentcost because the techniques for machine translationcould be reused in the architecture described in thispaper.We aimed at the high precision extraction of senti-ment units.
In other words, our SA system attachesimportance to each individual sentiment expression,rather than to the quantitative tendencies of repu-tation.
This is in order to meet the requirement ofthe SA users who want to know not only the over-all goodness of an object, but also the breakdown ofopinions.
For example, when there are many posi-tive opinions and only one negative opinion, the neg-ative one should not be ignored because of its lowpercentage, but should be investigated thoroughlysince valuable knowledge is often found in such aminority opinion.
Figure 1 illustrates an image ofthe SA output.
The outliner organizes positive andnegative opinions by topic words, and provides ref-erences to the original text.Favorable Unfavorablebattery long life - battery (3)good - battery (2):not good - battery (1)slens:nice - lens (2):(original document)When I bought this camera,I thought the batterywas not good, but theproblem was solved afterI replaced it with new one.Figure 1: An image of an outliner which uses SA output.Users can refer to the original text by clicking on thedocument icons.MT SAJapanesesentence?parserJapanesetree structure?
transfer jEnglishtree structureSentimentfragments?
generator ?EnglishsentenceSentimentunitsTransferpatternsFragmentpatternsBilinguallexiconPolaritylexiconFigure 2: The concept of the machine translation en-gine and the sentiment analyzer.
Some components areshared between them.
Also other components are similarbetween MT and SA.This means that the approach for SA should beswitched from the rather shallow analysis techniquesused for text mining (Hearst, 1999; Nasukawa andNagano, 2001), where some errors can be treated asnoise, into deep analysis techniques such as thoseused for machine translation (MT) where all of thesyntactic and semantic phenomena must be handled.We implemented a Japanese SA system using aJapanese to English translation engine.
Figure 2 il-lustrates our SA system, which utilizes a MT engine,where techniques for parsing and pattern matchingon the tree structures are shared between MT andSA.Section 2 reviews previous studies of sentimentanalysis.
In Section 3 we define the sentiment unitto be extracted for sentiment analysis.
Section 4presents the implementation of our system, compar-ing the operations and resources with those usedfor machine translation.
Our system is evaluatedin Section 5.
In the rest of paper we mainly useJapanese examples because some of the operationsdepend on the Japanese language, but we also useEnglish examples to express the sentiment units andsome language-independent issues, for understand-ability.2 Previous work on SentimentAnalysisSome prior studies on sentiment analysis focused onthe document-level classification of sentiment (Tur-ney, 2002; Pang et al, 2002) where a documentis assumed to have only a single sentiment, thusthese studies are not applicable to our goal.
Otherwork (Subasic and Huettner, 2001; Morinaga et al,2002) assigned sentiment to words, but they reliedon quantitative information such as the frequenciesof word associations or statistical predictions of fa-vorability.Automatic acquisition of sentiment expressionshave also been studied (Hatzivassiloglou and McKe-own, 1997), but limited to adjectives, and only onesentiment could be assigned to each word.Yi et al (2003) pointed out that the multiplesentiment aspects in a document should be ex-tracted.
This paper follows that approach, but ex-ploits deeper analysis in order to avoid the analyticfailures reported by Nasukawa and Yi (2003), whichoccurred when they used a shallow parser and onlyaddressed a limited number of syntactic phenomena.In our in-depth approach described in the next sec-tion, two types of errors out of the four reported byNasukawa and Yi (2003) were easily removed2.3 Sentiment UnitThis section describes the sentiment units which areextracted from text, and their roles in the sentimentanalysis and its applications.A sentiment unit consists of a sentiment, a predi-cate, its one or more arguments, and a surface form.Formally it is expressed as in Figure 3.The ?sentiment?
feature categorizes a sentimentunit into four types: ?favorable?
[fav], ?unfavorable?
[unf], ?question?
[qst], and ?request?
[req].
A predi-cate is a word, typically a verb or an adjective, whichconveys the main notion of the sentiment unit.
Anargument is also a word, typically a noun, whichmodifies the predicate with a case postpositional inJapanese.
They roughly correspond to a subject andan object of the predicate in English.For example, from the sentence (2)3, the extractedsentiment unit is (2a).ABC123-ha renzu-ga subarashii.ABC123-TOPIC lens-NOM excellent?ABC123 has an excellent lens.?
(2)[fav] excellent ?
ABC123, lens ?
(2a)The sentiment unit (2a) stands for the sentimentis ?favorable?, the predicate is ?excellent?
and its ar-guments are ?ABC123?
and ?lens?.
In this case, both?ABC123?
and ?lens?
are counted as words which areassociated with a favorable sentiment.
Argumentsare used as the keywords in the outliner, as in theleftmost column in Figure 1.
Predicates with no ar-gument are ignored, because they have no effects onthe view and often become noise.2Though this paper handles Japanese SA, we also imple-mented an English version of SA using English-French trans-lation techniques, and that system solved the problems whichwere mentioned in Nasukawa and Yi?s paper.3?ABC123?
is a fictitious product name.<sentiment unit> ::= <sentiment> <predicate> <argument>+ <surface><sentiment> ::= favorable | unfavorable | question | request<predicate> ::= <word> <feature>*<argument> ::= <word> <feature>*<surface> ::= <string>Figure 3: The definition of a sentiment unit.The predicate and its arguments can be differentfrom the surface form in the original text.
Seman-tically similar representations should be aggregatedto organize extracted sentiments, so the examples inthis paper use English canonical forms to representpredicates and arguments, while the actual imple-mentation uses Japanese expressions.Predicates may have features, such as negation,facility, difficulty, etc.
For example, ?ABC123doesn?t have an excellent lens.?
brings a sentimentunit ?
[unf] excellent+neg ?
ABC123, lens ??.
Alsothe facility/difficulty feature affects the sentimentssuch as ?
[unf] break+facil?
for ?easy to break?
and?
[unf] learn+diff?
?difficult to learn?.The surface string is the corresponding part in theoriginal text.
It is used for reference in the view ofthe output of SA, because the surface string is themost understandable notation of each sentiment unitfor humans.We use the term sentiment polarity for the se-lection of the two sentiments [fav] and [unf].
Theother two sentiments, [qst] and [req] are importantin applications, e.g.
the automatic creation of FAQ.Roughly speaking, [qst] is extracted from an inter-rogative sentence, and [req] is used for imperativesentences or expressions such as ?I want ...?
and?I?d like you to ...?.
From a pragmatic point of viewit is difficult to distinguish between them4, but weclassify them using simple rules.4 ImplementationThis section describes operations and resources de-signed for the extraction of sentiment units.
Thereare many techniques analogous to those for machinetranslation, so first we show the architecture of thetransfer-based machine translation engine which isused as the basis of the extraction of sentiment units.4.1 Transfer-based Machine TranslationEngineAs illustrated on the left side of Figure 2, thetransfer-based machine translation system consistsof three parts: a source language syntactic parser,a bilingual transfer which handles the syntactic treestructures, and a target language generator.
Herethe flow of the Japanese to English translation isshown with the following example sentence (3).4For example, the interrogative sentence ?Would you readit??
implies a request.kare hon kiiruwatashiha wo ninoFigure 4: The Japanese syntactic tree for the sen-tence (3).Kare-ha watashi-noHe-TOPIC I-GENhon-wo ki-ni iru.book-ACC mind-DAT enter?He likes my book.?
(3)First the syntactic parser parses the sentence (3)to create the tree structure as shown in Figure 4.Next, the transfer converts this Japanese parsetree into an English one by applying the translationpatterns as in Figure 5.
A translation pattern con-sists of a tree of the source language, a tree of thetarget language, and the word correspondences be-tween both languages.The patterns (a) and (b) in Figure 5 match withthe subtrees in Figure 4, as Figure 6 illustrates.This matching operation is very complicated becausethere can be an enormous number of possible combi-nations of patterns.
The fitness of the pattern com-binations is calculated according to the similarity ofthe source tree and the left side of the translationpattern, the specificity of the translation pattern,and so on.
This example also shows the processof matching the Japanese case markers (postposi-tional particles).
The source tree and the pattern(a) match even though the postpositional particlesare different (?ha?
and ?ga?).
This process may bemuch more complicated when a verb is transformedinto special forms e.g.
passive or causative.
Besidesthis there are many operations to handle syntacticand semantic phenomena, but here we take them forgranted because of space constraints.Now the target fragments have been created as inFigure 6, using the right side of the matched trans-lation patterns as in Figure 5.
The two fragmentsare attached at the shared node ?
noun2 ?, and lexi-calized by using the bilingual lexicon.
Finally thetarget sentence ?He likes my book.?
is generated bythe target language generator.irunoun noun kiga wo nilikenoun nounSUBJ OBJ(a)nounnowatashinounmy(b)Figure 5: Two examples of Japanese-English trans-lation patterns.
The left side and the right side areJapanese and English syntactic trees, respectively.The ?
noun ?
works as a wildcard which matches withany noun.
Curves stand for correspondences be-tween Japanese and English words.kare hon kiiruwatashiha wo nino(a)(b)likenoun1 noun2SUBJ OBJnoun2myFigure 6: Transferring the Japanese tree in Figure 4into the English tree.
The patterns in Figure 5 createtwo English fragments, and they are attached at thenodes ?
noun2 ?
which share the same correspondentnode in the source language tree.4.2 Techniques Required for SentimentAnalysisOur aim is to extract sentiment units with high pre-cision.
Moreover, the set of arguments of each pred-icate should be selected necessarily and sufficiently.Here we show that the techniques to meet these re-quirements are analogous to the techniques for ma-chine translation which have been reviewed in Sec-tion 4.1.4.2.1 Full parsing and top-down treematchingFull syntactic parsing plays an important role to ex-tract sentiments correctly, because the local struc-tures obtained by a shallow parser are not alwaysreliable.
For example, expressions such as ?I don?tthink X is good?, ?I hope that X is good?
are not fa-vorable opinions about X, even though ?X is good?appears on the surface.
Therefore we use top-downpattern matching on the tree structures from the fullparsing in order to find each sentiment fragment,that is potentially a part of a sentiment unit.In our method, initially the top node is examinedto see whether or not the node and its combinationof children nodes match with one of the patternsin the pattern repository.
In this top-down manner,the nodes ?don?t think?
and ?hope?
in the above ex-amples are examined before ?X is good?, and thusthe above expressions won?t be misunderstood to ex-press favorable sentiments.There are three types of patterns: principal pat-terns, auxiliary patterns, and nominal patterns.
Fig-ure 7 illustrates examples of principal patterns: thenounwaruiga [unf]bad ?
noun ?
(c)nounirukiwo ni [fav]like ?
noun ?
(d)Figure 7: Examples of principal patterns.declinabletoomowanaiunit+neg(e)declinablemononodeclinableunitunit(f)Figure 8: Examples of auxiliary patterns.?
declinable ?
denotes a verb or an adjective inJapanese.
Note that the two unit s on the right sideof (f) are not connected.
This means two separatedsentiment units can be obtained.pattern (c) converts a Japanese expression ?
noun -ga warui?
to a sentiment unit ?
[unf] bad ?
noun ?
?.The pattern (d) converts an expression ?
noun -woki-ni iru?
to a sentiment unit ?
[fav] like ?
noun ?
?,where the subject (the noun preceding the postpo-sitional ga) is excluded from the arguments becausethe subject of ?like?
is usually the author, who is notthe target of sentiment analysis.Another type is the auxiliary pattern, which ex-pands the scope of matching.
Figure 8 has twoexamples.
The pattern (e) matches with phrasessuch as ?X-wa yoi-to omowa-nai.
((I) don?t thinkX is good.)?
and produces a sentiment unit with thenegation feature.
When this pattern is attached toa principal pattern, its favorability is inverted.
Thepattern (f) allows us to obtain two separate senti-ment units from sentences such as ?Dezain-ga warui-monono, sousasei-ha yoi.
(The design is bad, but theusability is good.
)?.4.2.2 Informative noun phraseThe third type of pattern is a nominal pattern.
Fig-ure 9 shows three examples.
The pattern (g) is usedto avoid a formal noun (nominalizer) being an argu-ment.
Using this pattern, from the sentence ?Kawaiino-ga suki-da.
((I) like pretty things)?, ?
[fav] like?
pretty ??
can be extracted instead of ?
[fav] like?
thing ??.
The pattern (h) is used to convert anoun phrase ?renzu-no shitsu (quality of the lens)?into just ?lens?.
Due to this operation, from Sen-tence (4), an informative sentiment unit (4a) can beobtained instead of a less informative one (4b).Renzu-no shitsu-ga yoi.lens-GEN quality-NOM good?The quality of the lens is good.?
(4)[fav] good ?
lens ?
(4a)?
[fav] good ?
quality ?
(4b)adjnoadj(g)nounnoshitsunoun(h)nounnounnounnoun(i)Figure 9: Examples of nominal patterns.The pattern (i) is for compound nouns such as?juuden jikan (recharging time)?.
A sentimentunit ?long ?
time ??
is not informative, but ?long?
recharging time ??
can be regarded as a [unf] sen-timent.4.2.3 Disambiguation of sentiment polaritySome adjectives and verbs may be used for both fa-vorable and unfavorable predicates.
This variationof sentiment polarity can be disambiguated natu-rally in the same manner as the word sense dis-ambiguation in machine translation.
The adjective?takai (high)?
is a typical example, as in (5a) and(5b).
In this case the sentiment polarity depends onthe noun preceding the postpositional particle ?ga?
:favorable if the noun is ?kaizoudo (resolution)?, unfa-vorable if the noun is a product name.
The semanticcategory assigned to a noun holds the informationused for this type of disambiguation.Kaizoudo-ga takai.resolution-NOM high?The resolution is high.??
[fav] (5a)ABC123-ga takai.ABC123-NOM high (price)?ABC123 is expensive.??
[unf] (5b)4.2.4 Aggregation of synonymousexpressionsIn contrast to disambiguation, aggregation of syn-onymous expressions is important to organize ex-tracted sentiment units.
If the different expressionswhich convey the same (or similar) meanings areaggregated into a canonical one, the frequency in-creases and one can easily find frequently mentionedopinions.Using the translation architecture, any forms canbe chosen as the predicates and arguments by ad-justing the patterns and lexicons.
That is, monolin-gual word translation is done in our method.4.3 Resources for Sentiment AnalysisWe prepared the following resources for sentimentanalysis:Principal patterns: The verbal and adjectivalpatterns for machine translation were convertedto principal patterns for sentiment analysis.The left sides of the patterns are compatiblewith the source language parts of the originalpatterns, so we just assigned a sentiment po-larity to each word.
A total of 3752 principalpatterns were created.Auxiliary/Nominal patterns: A total of 95 aux-iliary patterns and 36 nominal patterns werecreated manually.Polarity lexicon: Some nouns were assigned sen-timent polarity, e.g.
[unf] for ?noise?.
This po-larity is used in expressions such as ?...
ga ooi.
(There are many ...)?.
This lexicon is also usedfor the aggregation of words.Some patterns and lexicons are domain-dependent.
The situation is the same as inmachine translation.
Fortunately the translationengine used here has a function to selectively usedomain-dependent dictionaries, and thus we canprepare patterns which are especially suited for themessages on bulletin boards, or for the domain ofdigital cameras.
For example, ?The size is small.
?is a desirable feature of a digital camera.
We canassign the appropriate sentiment (in this case, [fav])by using a domain-specific principal pattern.5 EvaluationWe conducted two experiments on the extraction ofsentiment units from bulletin boards on the WWWthat are discussing digital cameras.
A total of 200randomly selected sentences were analyzed by oursystem.
The resources were created by looking atother parts of the same domain texts, and thereforethis experiment is an open test.Experiment 1 measured the precision of the sen-timent polarity, and Experiment 2 evaluated the in-formativeness of the sentiment units.
In this sectionwe handled only the sentiments [fav] and [unf] senti-ments, thus the other two sentiments [qst] and [req]were not evaluated.5.1 Experiment 1: Precision and RecallIn order to see the reliability of the extracted sen-timent polarities, we evaluated the following threemetrics:Weak precision: The coincidence rate of the senti-ment polarity between the system?s output andmanual output when both the system and thehuman evaluators assigned either a favorable orunfavorable sentiment.Strong precision: The coincidence rate of the sen-timent polarity between the system?s outputand manual output when the system assignedeither a favorable or unfavorable sentiment.Recall: The detection rate of sentiment unitswithin the manual output.These metrics are measured by using two meth-ods: (A) our proposed method based on the machinetranslation engine, and (B) the lexicon-only method,which emulates the shallow parsing approach.
Thelatter method used the simple polarity lexicon of ad-jectives and verbs, where an adjective or a verb hadonly one sentiment polarity, then no disambigua-tion was done.
Except for the direct negation of(A) MT (B) Lexicon onlyWeak prec.
100% (31/31) 80% (41/51)Strong prec.
89% (31/35) 44% (41/93)Recall 43% (31/72) 57% (41/72)Table 1: Precision and recall for the extraction ofsentiment units from 200 sentences.
(A) MTManualf n uf 20 3 0Systemn 27 - 14u 0 1 11(B) Lexicon onlyManualf n uf 26 19 6Systemn 14 - 7u 4 23 15Table 2: The breakdown of the results of Experi-ment 1.
The columns and rows show the manualoutput and the system output, respectively (f: favor-able, n: non-sentiment, u: unfavorable).
The sum ofthe bold numbers equals the numerators of the pre-cision and recall.an adjective or a verb5, no translation patterns wereused.
Instead of the top-down pattern matching,sentiment units were extracted from any part of thetree structures (the results of full-parsing were usedalso here).Table 1 shows the results.
With the MT frame-work, the weak precision was perfect, and also thestrong precision was much higher, while the recallwas lower than for the lexicon-only method.
Theirbreakdowns in the two parts of Table 2 indicate thatmost of errors where the system wrongly assignedeither of sentiments (i.e.
human regarded an expres-sion as non-sentiment) have been reduced with theMT framework.All of the above results are consistent with intu-ition.
The MT method outputs a sentiment unitonly when the expression is reachable from the rootnode of the syntactic tree through the combina-tion of sentiment fragments, while the lexicon-onlymethod picks up sentiment units from any node inthe syntactic tree.
The sentence (6) is an exam-ple where the lexicon-only method output the wrongsentiment unit (6a).
The MT method did not out-put this sentiment unit, thus the precision values ofthe MT method did not suffer from this example.... gashitsu-ga kirei-da-to iu hyouka-hauke-masen-deshi-ta.
(6)?There was no opinion that the picture was sharp.??
[fav] clear ?
picture ?
(6a)In the lexicon-only method, some errors occurreddue to the ambiguity in sentiment polarity of an ad-jective or a verb, e.g.
?Kanousei-ga takai.
(Capa-bilities are high.)?
since ?takai (high/expensive)?
isalways assigned the [unf] feature.5?He doesn?t like it.?
is regarded as negation, but ?I don?tthink it is good.?
is not.declinablenoun noun nounga wo niFigure 10: A na?
?ve predicate-argument structureused by the system (C).
Nouns preceding three ma-jor postpositional particles ?ga?, ?wo?, and ?ni?
aresupported as the slots of arguments.
On the otherhand, in the system (A), there are over 3,000 prin-cipal patterns that have information on appropriatecombinations for each verb and adjective.
(A) MT (C) Na?
?veLess redundant 2/35 0/35More informative 13/35 1/35Both 1/35 0/35Table 3: Comparison of scope of sentiment units.The numbers mean the counts of the better outputfor each system among 35 sentiment units.
The re-mainder is the outputs that were the same in bothsystems.The recall was not so high, especially in the MTmethod, but according to our error analysis the re-call can be increased by adding auxiliary patterns.On the other hand, it is almost impossible to increasethe precision without our deep analysis techniques.Consequently, our proposed method outperforms theshallow (lexicon-only) approach.5.2 Experiment 2: Scope of Sentiment UnitWe also compared the appropriateness of the scopeof the extracted sentiment units between (A) theproposed method with the MT framework and(C) a method that supports only na?
?ve predicate-argument structures as in Figure 10 and doesn?t useany nominal patterns.According to the results shown in Table 3, the MTmethod produced less redundant or more informa-tive sentiment units than did relying on the na?
?vepredicate-argument structures in about half of thecases among the 35 extracted sentiment units.The following example (7) is a case where the sen-timent unit output by the MT method (7a) was lessredundant than that output by the na?
?ve method(7b).
The translation engine understood that thephrase ?kyonen-no 5-gatsu-ni (last May)?
held tem-poral information, therefore it was excluded fromthe arguments of the predicate ?enhance?, while both?function?
and ?May?
were the arguments of ?enhance?in (7b).
Apparently the argument ?May?
is not nec-essary here.... kyonen-no 5-gatsu-ni kinou-gakairyou-sare-ta you-desu.
(7)?It seems the function was enhanced last May.?
[fav] enhance ?
function ?
(7a)?
[fav] enhance ?
function, May ?
(7b)Example (8) is another case where the sentimentunit output by the MT method (8a) was more infor-mative than that output by the na?
?ve method (8b).Than the Japanese functional noun ?hou?, its modi-fier ?zoom?
was more informative.
The MT methodsuccessfully selected the noun ?zoom?
as the argu-ment of ?desirable?....
zuum-no hou-ga nozomashii.
(8)?A zoom is more desirable.?
[fav] desirable ?
zoom ?
(8a)?
[fav] desirable ?
hou ?
(8b)The only one case we encountered where theMT method extracted a less informative sentimentunit was the sentence ?Botan-ga satsuei-ni pittari-desu (The shutter is suitable for taking photos)?.The na?
?ve method could produce the sentiment unit?
[fav] suitable ?
shutter, photo ?
?, but the MTmethod created ?
[fav] suitable ?
shutter ??.
This isdue to the lack of a noun phrase preceding the post-positional particle ?ni?
in the principal pattern.
Suchproblems can be avoided by modifying the patterns,and thus the effect of the combination of patternsfor SA has been shown here.6 ConclusionThis paper has proposed a new approach to senti-ment analysis: the translation from text to a set ofsemantic fragments.
We have shown that the deepsyntactic and semantic analysis makes possible thereliable extraction of sentiment units, and the out-lining of sentiments became useful because of theaggregation of the variations in expressions, and theinformative outputs of the arguments.
The experi-mental results have shown that the precision of thesentiment polarity was much higher than for the con-ventional methods, and the sentiment units createdby our system were less redundant and more infor-mative than when using na?
?ve predicate-argumentstructures.
Even though we exploited many advan-tages of deep analysis, we could create a sentimentanalysis system at a very low development cost, be-cause many of the techniques for machine translationcan be reused naturally when we regard the extrac-tion of sentiment units as a kind of translation.Many techniques which have been studied for thepurpose of machine translation, such as word sensedisambiguation (Dagan and Itai, 1994; Yarowsky,1995), anaphora resolution (Mitamura et al, 2002),and automatic pattern extraction from corpora(Watanabe et al, 2003), can accelerate the furtherenhancement of sentiment analysis, or other NLPtasks.
Therefore this work is the first step towardsthe integration of shallow and wide NLP, with deepNLP.ReferencesIdo Dagan and Alon Itai.
1994.
Word sense dis-ambiguation using a second language monolingualcorpus.
Computational Linguistics, 20(4):563?596.Vasileios Hatzivassiloglou and Kathleen R. McKe-own.
1997.
Predicting the semantic orientationof adjectives.
In Proceedings of the 35th AnnualMeeting of the ACL and the 8th Conference of theEuropean Chapter of the ACL, pages 174?181.Marti A. Hearst.
1999.
Untangling text data min-ing.
In Proc.
of the 37th Annual Meeting of theAssociation for Computational Linguistics.Teruko Mitamura, Eric Nyberg, Enrique Torrejon,Dave Svoboda, Annelen Brunner, and KathrynBaker.
2002.
Pronominal anaphora resolution inthe kantoo multilingual machine translation sys-tem.
In Proc.
of TMI 2002, pages 115?124.Satoshi Morinaga, Kenji Yamanishi, Kenji Tateishi,and Toshikazu Fukushima.
2002.
Mining productreputations on the web.
In Proc.
of the 8th ACMSIGKDD Conference.Tetsuya Nasukawa and Tohru Nagano.
2001.
Textanalysis and knowledge mining system.
IBM Sys-tems Journal, 40(4):967?984.Tetsuya Nasukawa and Jeonghee Yi.
2003.
Senti-ment analysis: Capturing favorability using nat-ural language processing.
In Proc.
of the SecondInternational Conferences on Knowledge Capture,pages 70?77.Bo Pang, Lillian Lee, and ShivakumarVaithyanathan.
2002.
Thumbs up?
Sentimentclassification using machine learning techniques.In Proceedings of the 2002 Conference on Em-pirical Methods in Natural Language Processing(EMNLP), pages 79?86.Pero Subasic and Alison Huettner.
2001.
Affectanalysis of text using fuzzy semantic typing.
IEEETrans.
on Fussy Systems.Peter D. Turney.
2002.
Thumbs up or thumbsdown?
Semantic orientation applied to unsuper-vised classification of reviews.
In Proc.
of the 40thACL Conf., pages 417?424.Hideo Watanabe, Sadao Kurohashi, and Eiji Ara-maki.
2003.
Finding translation patterns from de-pendency structures.
In Michael Carl and AndyWay, editors, Recent Advances in Example-basedMachine Translation, pages 397?420.
Kluwer Aca-demic Publishers.Hideo Watanabe.
1992.
A similarity-driven trans-fer system.
In Proc.
of the 14th COLING, Vol.
2,pages 770?776.David Yarowsky.
1995.
Unsupervised word sensedisambiguation rivaling supervised methods.
InMeeting of the Association for ComputationalLinguistics, pages 189?196.Jeonghee Yi, Tetsuya Nasukawa, Razvan Bunescu,and Wayne Niblack.
2003.
Sentiment analyzer:Extracting sentiments about a given topic usingnatural language processing techniques.
In Pro-ceedings of the Third IEEE International Confer-ence on Data Mining, pages 427?434.
