Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 145?148,Ann Arbor, June 2005. c?Association for Computational Linguistics, 2005Combining Linguistic Data Views for Phrase-based SMTJesu?s Gime?nez and Llu?
?s Ma`rquezTALP Research Center, LSI DepartmentUniversitat Polite`cnica de CatalunyaJordi Girona Salgado 1?3, E-08034, Barcelona{jgimenez,lluism}@lsi.upc.eduAbstractWe describe the Spanish-to-English LDV-COMBO system for the Shared Task 2:?Exploiting Parallel Texts for StatisticalMachine Translation?
of the ACL-2005Workshop on ?Building and Using Par-allel Texts: Data-Driven Machine Trans-lation and Beyond?.
Our approach ex-plores the possibility of working withalignments at different levels of abstrac-tion, using different degrees of linguisticannotation.
Several phrase-based trans-lation models are built out from thesealignments.
Their combination significa-tively outperforms any of them in isola-tion.
Moreover, we have built a word-based translation model based on Word-Net which is used for unknown words.1 IntroductionThe main motivation behind our work is to intro-duce linguistic information, other than lexical units,to the process of building word and phrase align-ments.
Many other authors have tried to do so.
See(Och and Ney, 2000), (Yamada and Knight, 2001),(Koehn and Knight, 2002), (Koehn et al, 2003),(Schafer and Yarowsky, 2003) and (Gildea, 2003).Far from full syntactic complexity, we suggest togo back to the simpler alignment methods first de-scribed by (Brown et al, 1993).
Our approach ex-ploits the possibility of working with alignments attwo different levels of granularity, lexical (words)and shallow parsing (chunks).
In order to avoid con-fusion so forth we will talk about tokens instead ofwords as the minimal alignment unit.Apart from redefining the scope of the alignmentunit, we may use different degrees of linguistic an-notation.
We introduce the general concept of dataview, which is defined as any possible representationof the information contained in a bitext.
We enrichdata view tokens with features further than lexicalsuch as PoS, lemma, and chunk label.As an example of the applicability of data views,suppose the case of the word ?plays?
being seen inthe training data acting as a verb.
Representing thisinformation as ?playsVBZ?
would allow us to distin-guish it from its homograph ?playsNNS?
for ?plays?
asa noun.
Ideally, one would wish to have still deeperinformation, moving through syntax onto semantics,such as word senses.
Therefore, it would be possibleto distinguish for instance between two realizationsof ?plays?
with different meanings: ?hePRP playsVBGguitarNN?
and ?hePRP playsVBG basketballNN?.Of course, there is a natural trade-off between theuse of data views and data sparsity.
Fortunately, wehava data enough so that statistical parameter esti-mation remains reliable.2 System DescriptionThe LDV-COMBO system follows the SMT architec-ture suggested by the workshop organizers.First, training data are linguistically annotated forthe two languages involved (See subsection 2.1).10 different data views have been built.
Noticethat it is not necessary that the two parallel coun-terparts of a bitext share the same data view, as145long as they share the same granularity.
How-ever, in all our experiments we have annotated bothsides with the same linguistic information.
Seetoken descriptions: (W) word, (WL) word andlemma, (WP) word and PoS, (WC) word and chunklabel, (WPC) word, PoS and chunk label, (Cw)chunk of words (Cwl), chunk of words and lem-mas, (Cwp) chunk of words and PoS (Cwc) chunkof words and chunk labels (Cwpc) chunk of words,PoS and chunk labels.
By chunk label we re-fer to the IOB label associated to every word in-side a chunk, e.g.
?IB?NP declareB?V P resumedI?V PtheB?NP sessionI?NP ofB?PP theB?NP EuropeanI?NPParliamentI?NP .O?).
We build chunk tokens by ex-plicitly connecting words in the same chunk, e.g.?
(I)NP (declare resumed)V P (the session)NP (of)PP(the European Parliament)NP ?.
See examples ofsome of these data views in Table 1.Then, running GIZA++, we obtain token align-ments for each of the data views.
Combined phrase-based translation models are built on top of theViterbi alignments output by GIZA++.
See detailsin subsection 2.2.
Combo-models must be then post-processed in order to remove the additional linguis-tic annotation and split chunks back into words, sothey fit the format required by Pharaoh.Moreover, we have used the Multilingual CentralRepository (MCR), a multilingual lexical-semanticdatabase (Atserias et al, 2004), to build a word-based translation model.
We back-off to this modelin the case of unknown words, with the goal of im-proving system recall.
See subsection 2.3.2.1 Data RepresentationIn order to achieve robustness the same tools havebeen used to linguistically annotate both languages.The SVMTool1 has been used for PoS-tagging(Gime?nez and Ma`rquez, 2004).
The Freeling2 pack-age (Carreras et al, 2004) has been used for lemma-tizing.
Finally, the Phreco software by (Carreras etal., 2005) has been used for shallow parsing.No additional tokenization or pre-processingsteps other than case lowering have been performed.Special treatment of named entities, dates, numbers,1The SVMTool may be freely downloaded athttp://www.lsi.upc.es/?nlp/SVMTool/ .2Freeling Suite of Language Analyzers may be downloadedat http://www.lsi.upc.es/?nlp/freeling/currency, etc., should be considered so as to furtherenhance the system.2.2 Building Combined Translation ModelsBecause data views capture different, possibly com-plementary, aspects of the translation process itseems reasonable to combine them.
We considertwo different ways of building such combo-models:LPHEX Local phrase extraction.
To build a separatephrase-based translation model for each dataview alignment, and then combine them.
Thereare two ways of combining translation models:MRG Merging translation models.
We work ona weighted linear interpolation of models.These weights may be tuned, although auniform weight selection yields good re-sults.
Additionally, phrase-pairs may befiltered out by setting a score threshold.noMRG Passing translation models directly tothe Pharaoh decoder.
However, we en-countered many problems with phrase-pairs that were not seen in all single mod-els.
This obliged us to apply arbitrarysmoothing values to score these pairs.GPHEX Global phrase extraction.
To build a sin-gle phrased-based translation model from theunion of alignments from several data views.In its turn, any MRG operation performed on acombo-model results again in a valid combo-model.In any case, phrase extraction3 is performed as de-picted by (Och, 2002).2.3 Using the MCROuter knowledge may be supplied to the Pharaohdecoder by annotating the input with alternativetranslation options via XML-markup.
We enrichevery unknown word by looking up every possi-ble translation for all of its senses in the MCR.These are scored by relative frequency according tothe number of senses that lexicalized in the samemanner.
Let wf , pf be the source word and PoS,and we be the target word, we define a function3We always work with the union of alignments, no heuristicrefinement, and phrases up to 5 tokens.
Phrase pairs appearingonly once have been discarded.
Scoring is performed by relativefrequency.
No smoothing is applied.146It[PRP :B?NP ] would[MD:B?V P ] appear[VB:I?V P ] that[IN:B?SBAR] a[DT :B?NP ] speech[NN:I?NP ] made[VBN:B?V P ]at[IN:B?PP ] the[DT :B?NP ] weekend[NN:I?NP ] by[IN:B?PP ] Mr[NNP :B?NP ] Fischler[NNP :I?NP ]indicates[VBZ:B?V P ] a[DT :B?NP ] change[NN:I?NP ] of[IN:B?PP ] his[PRP$:B?NP ] position[NN:I?NP ] .[.
:O]WPCFischler[VMN:B?V P ] pronuncio?
[VMI:B?V P ] un[DI:B?NP ] discurso[NC:I?NP ] este[DD:B?NP ] fin[NC:I?NP ]de[SP :B?PP ] semana[NC:B?NP ] en[SP :B?PP ] el[DA:B?SBAR] que[PR0:I?SBAR] parec?
?a[VMI:B?V P ]haber[VAN:I?V P ] cambiado[VMP :I?V P ] de[SP :B?PP ] actitud[NC:B?NP ] .
[Fp:O](It[PRP :B?NP ]]) (would[MD:B?V P ]] appear[VB:I?V P ]) (that[IN:B?SBAR]) (a[DT :B?NP ] speech[NN:I?NP ])(made[VBN:B?V P ]) (at[IN:B?PP ]) (the[DT :B?NP ] weekend[NN:I?NP ]) (by[IN:B?PP ])(Mr[NNP :B?NP ] Fischler[NNP :I?NP ]) (indicates[VBZ:B?V P ]) (a[DT :B?NP ] change[NN:I?NP ])(of[IN:B?PP ]) (his[PRP$:B?NP ] position[NN:I?NP ]) (.[.
:O])Cwpc(Fischler[VMN:B?V P ]) (pronuncio?
[VMI:B?V P ]) (un[DI:B?NP ] discurso[NC:I?NP ]) (este[DD:B?NP ] fin[NC:I?NP ])(de[SP :B?PP ]) (semana[NC:B?NP ]) (en[SP :B?PP ]) (el[DA:B?SBAR] que[PR0:I?SBAR])(parec?
?a[VMI:B?V P ] haber[VAN:I?V P ] cambiado[VMP :I?V P ]) (de[SP :B?PP ]) (actitud[NC:B?NP ]) (.
[Fp:O])Table 1: An example of 2 rich data views: (WPC) word, PoS and IOB chunk label (Cwpc) chunk of word, PoS and chunk label.Scount(wf , pf , we) which counts the number ofsenses for (wf , pf ) which can lexicalize as we.
Atranslation pair is scored as:score(wf , pf |we) =Scount(wf , pf , we)?
(wf ,pf ) Scount(wf , pf , we)(1)Better results would be expected working withword sense disambiguated text.
We are not at thispoint yet.
A first approach could be to work with themost frequent sense heuristic.3 Experimental Results3.1 Data and Evaluation MetricsWe have used the data sets and language model pro-vided by the organization.
No extra training or de-velopment data were used in our experiments.We evaluate results with 3 different metrics: GTMF1-measure (e = 1, 2), BLEU score (n = 4) as pro-vided by organizers, and NIST score (n = 5).3.2 Experimenting with Data ViewsTable 2 presents MT results for the 10 elementarydata views devised in Section 2.
Default parametersare used for ?tm, ?lm, and ?w.
No tuning has beenperformed.
As expected, word-based views obtainsignificatively higher results than chunk-based.
Alldata views at the same level of granularity obtaincomparable results.In Table 3 MT results for different data view com-binations are showed.
Merged model weights areset equiprobable, and no phrase-pair score filteringdata view GTM-1 GTM-2 BLEU NISTW 0.6108 0.2609 25.92 7.1576WL 0.6110 0.2601 25.77 7.1496WP 0.6096 0.2600 25.74 7.1415WC 0.6124 0.2600 25.98 7.1852WPC 0.6107 0.2587 25.79 7.1595Cw 0.5749 0.2384 22.73 6.6149Cwl 0.5756 0.2385 22.73 6.6204Cwp 0.5771 0.2395 23.06 6.6403Cwc 0.5759 0.2390 22.86 6.6207Cwpc 0.5744 0.2379 22.77 6.5949Table 2: MT Results for the 10 elementary data views on thedevelopment set.is performed.
We refer to the W model as our base-line.
In this view, only words are used.
The 5W-MRGand 5W-GPHEX models use a combination of the 5word-based data views, as in MRG and GPHEX, re-spectively.
The 5C-MRG and 5C-GPHEX system usea combination of the 5 chunk based data views, asin MRG and GPHEX, respectively.
The 10-MRG sys-tem uses all 10 data views combined as in MRG.
The10-GPHEX/MRG system uses the 5 word based viewscombined as in GPHEX, the 5 chunk based viewscombined as in GPHEX, and then a combination ofthese two combo-models as in MRG.data view GTM-1 GTM-2 BLEU NISTW 0.6108 0.2609 25.92 7.15765W-MRG 0.6134 0.2631 26.25 7.21225W-GPHEX 0.6172 0.2615 26.95 7.28235C-MRG 0.5786 0.2407 23.18 6.67545C-GPHEX 0.5739 0.2368 22.80 6.571410-MRG 0.6130 0.2624 26.24 7.219610-GPHEX/MRG 0.6142 0.2600 26.58 7.2542Table 3: MT Results without tuning, for some data view com-binations on the development set.147It can be seen that results improve by combiningseveral data views.
Furthermore, global phrase ex-traction (GPHEX) seems to work much finer than lo-cal phrase extraction (LPHEX).Table 4 shows MT results after optimizing ?tm,?lm, ?w, and the weights for the MRG operation,by means of the Downhill Simplex Method in Multi-dimensions (William H. Press and Flannery, 2002).Observe that tuning the system improves the perfor-mance considerably.
The ?w parameter is particu-larly sensitive to tuning.Even though the performance of chunk-basedmodels is poor, the best results are obtained by com-binining the two levels of abstraction, thus provingthat syntactically motivated phrases may help.
10-MRG and 10-GPHEX models achieve a similar per-formance.
The 10-MRG-bestWN system correspondsto the 10-MRG model using WordNet.
The 10-MRG-subWN system is this same system at the time of sub-mission.
Results using WordNet, taking into accountthat the number of unknown4 words in the develop-ment set was very small, are very promising.data view GTM-1 GTM-2 BLEU NISTW 0.6174 0.2583 28.13 7.15405W-MRG 0.6206 0.2605 28.50 7.20765W-GPHEX 0.6207 0.2603 28.38 7.19925C-MRG 0.5882 0.2426 25.06 6.67735C-GPHEX 0.5816 0.2387 24.40 6.559510-MRG 0.6218 0.2623 28.88 7.249110-GPHEX/MRG 0.6229 0.2622 28.82 7.241410-MRGWN 0.6228 0.2625 28.90 7.258310-MRG-subWN 0.6228 0.2622 28.79 7.2528Table 4: MT Results for some data view combinations aftertuning on the development set.4 ConclusionsWe have showed that it is possible to obtain betterphrase-based translation models by utilizing align-ments built on top of different linguistic data views.These models can be robustly combined, signifi-cantly outperforming all of their components in iso-lation.
We leave for further work the experimen-tation of new data views such as word senses andsemantic roles, as well as their natural porting andevolution from the alignment step to phrase extrac-tion and decoding.4Translation for 349 unknown words was found in the MCR.AcknowledgementsThis research has been funded by the SpanishMinistry of Science and Technology (ALIADOTIC2002-04447-C02).
Authors are thankful to Pa-trik Lambert for providing us with the implementa-tion of the Simplex Method used for tuning.ReferencesJordi Atserias, Luis Villarejo, German Rigau, EnekoAgirre, John Carroll, Bernardo Magnini, and PiekVossen.
2004.
The meaning multilingual centralrepository.
In Proceedings of GWC, Brno, Czech Re-public, January.
ISBN 80-210-3302-9.Peter E Brown, Stephen A. Della Pietra, Robert L. Mer-cer, and Vincent J. Della Pietra.
1993.
The mathemat-ics of statistical machine translation: Parameter esti-mation.
Computational Linguistics, 19(2):263?311.Xavier Carreras, Isaac Chao, Llu?
?s Padro?, and MuntsaPadro?.
2004.
Freeling: An open-source suite of lan-guage analyzers.
In Proceedings of the 4th LREC.Xavier Carreras, Llu?
?s Ma?rquez, and Jorge Castro.
2005.Filtering-ranking perceptron learning for partial pars-ing.
Machine Learning, 59:1?31.Daniel Gildea.
2003.
Loosely tree-based alignment formachine translation.
In Proceedings of ACL.Jesu?s Gime?nez and Llu?
?s Ma`rquez.
2004.
Svmtool: Ageneral pos tagger generator based on support vectormachines.
In Proceedings of 4th LREC.Philipp Koehn and Kevin Knight.
2002.
Chunkmt:Statistical machine translation with richer linguisticknowledge.
Draft.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proceed-ings of HLT/NAACL.Franz Josef Och and Hermann Ney.
2000.
Improvedstatistical alignment models.
In Proceedings of ACL.Franz Josef Och.
2002.
Statistical Machine Transla-tion: From Single-Word Models to Alignment Tem-plates.
Ph.D. thesis, RWTH Aachen, Germany.Charles Schafer and David Yarowsky.
2003.
Statisticalmachine translation using coercive two-level syntactictransduction.
In Proceedings of EMNLP.William T. Vetterling William H. Press, Saul A. Teukol-sky and Brian P. Flannery.
2002.
Numerical Recipesin C++: the Art of Scientific Computing.
CambridgeUniversity Press.Kenji Yamada and Kevin Knight.
2001.
A syntax-basedstatistical translation model.
In Proceedings of ACL.148
