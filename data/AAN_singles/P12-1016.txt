Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 146?155,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsA Class-Based Agreement Model forGenerating Accurately Inflected TranslationsSpence GreenComputer Science Department, Stanford Universityspenceg@stanford.eduJohn DeNeroGoogledenero@google.comAbstractWhen automatically translating from a weaklyinflected source language like English to a tar-get language with richer grammatical featuressuch as gender and dual number, the outputcommonly contains morpho-syntactic agree-ment errors.
To address this issue, we presenta target-side, class-based agreement model.Agreement is promoted by scoring a sequenceof fine-grained morpho-syntactic classes thatare predicted during decoding for each transla-tion hypothesis.
For English-to-Arabic transla-tion, our model yields a +1.04 BLEU averageimprovement over a state-of-the-art baseline.The model does not require bitext or phrase ta-ble annotations and can be easily implementedas a feature in many phrase-based decoders.1 IntroductionLanguages vary in the degree to which surface formsreflect grammatical relations.
English is a weakly in-flected language: it has a narrow verbal paradigm, re-stricted nominal inflection (plurals), and only the ves-tiges of a case system.
Consequently, translation intoEnglish?which accounts for much of the machinetranslation (MT) literature (Lopez, 2008)?often in-volves some amount of morpho-syntactic dimension-ality reduction.
Less attention has been paid to whathappens during translation from English: richer gram-matical features such as gender, dual number, andovert case are effectively latent variables that mustbe inferred during decoding.
Consider the output ofGoogle Translate for the simple English sentence inFig.
1.
The correct translation is a monotone mappingof the input.
However, in Arabic, SVO word orderrequires both gender and number agreement betweenthe subject?PAJ??
@ ?the car?
and verb I.
?YK?go?.
TheMT system selects the correct verb stem, but withmasculine inflection.
Although the translation has(1)?PAJ??@the-carsg.def.femI.
?YKgosg.masc??Q??
.with-speedsg.femThe car goes quicklyFigure 1: Ungrammatical Arabic output of Google Trans-late for the English input The car goes quickly.
The subjectshould agree with the verb in both gender and number, butthe verb has masculine inflection.
For clarity, the Arabictokens are arranged left-to-right.the correct semantics, it is ultimately ungrammatical.This paper addresses the problem of generating textthat conforms to morpho-syntactic agreement rules.Agreement relations that cross statistical phraseboundaries are not explicitly modeled in most phrase-based MT systems (Avramidis and Koehn, 2008).We address this shortcoming with an agreementmodel that scores sequences of fine-grained morpho-syntactic classes.
First, bound morphemes in transla-tion hypotheses are segmented.
Next, the segmentsare labeled with classes that encode both syntacticcategory information (i.e., parts of speech) and gram-matical features such as number and gender.
Finally,agreement is promoted by scoring the predicted classsequences with a generative Markov model.Our model scores hypotheses during decoding.
Un-like previous models for scoring syntactic relations,our model does not require bitext annotations, phrasetable features, or decoder modifications.
The modelcan be implemented using the feature APIs of popularphrase-based decoders such as Moses (Koehn et al,2007) and Phrasal (Cer et al, 2010).Intuition might suggest that the standard n-gramlanguage model (LM) is sufficient to handle agree-ment phenomena.
However, LM statistics are sparse,and they are made sparser by morphological varia-tion.
For English-to-Arabic translation, we achievea +1.04 BLEU average improvement by tiling ourmodel on top of a large LM.146It has also been suggested that this setting requiresmorphological generation because the bitext may notcontain all inflected variants (Minkov et al, 2007;Toutanova et al, 2008; Fraser et al, 2012).
However,using lexical coverage experiments, we show thatthere is ample room for translation quality improve-ments through better selection of forms that alreadyexist in the translation model.2 A Class-based Model of Agreement2.1 Morpho-syntactic AgreementMorpho-syntactic agreement refers to a relationshipbetween two sentence elements a and b that musthave at least one matching grammatical feature.1Agreement relations tend to be defined for partic-ular syntactic configurations such as verb-subject,noun-adjective, and pronoun-antecedent.
In somelanguages, agreement affects the surface forms of thewords.
For example, from the perspective of gener-ative grammatical theory, the lexicon entry for theArabic nominal?PAJ??
@ ?the car?
contains a femininegender feature.
When this nominal appears in the sub-ject argument position, the verb-subject agreementrelationship triggers feminine inflection of the verb.Our model treats agreement as a sequence ofscored, pairwise relations between adjacent words.Of course, this assumption excludes some agreementphenomena, but it is sufficient for many commoncases.
We focus on English-Arabic translation asan example of a translation direction that expressessubstantially more morphological information in thetarget.
These relations are best captured in a target-side model because they are mostly unobserved (fromlexical clues) in the English source.The agreement model scores sequences of morpho-syntactic word classes, which express grammaticalfeatures relevant to agreement.
The model has threecomponents: a segmenter, a tagger, and a scorer.2.2 Morphological SegmentationSegmentation is a procedure for converting raw sur-face forms to component morphemes.
In some lan-guages, agreement relations exist between boundmorphemes, which are syntactically independent yetphonologically dependent morphemes.
For example,1We use morpho-syntactic and grammatical agreement inter-changeably, as is common in the literature.Pron+Fem+Sg Verb+Masc+3+Pl Prt Conjandwillthey writeitFigure 2: Segmentation and tagging of the Arabic tokenA?E?J.J?J??
?and they will write it?.
This token has four seg-ments with conflicting grammatical features.
For example,the number feature is singular for the pronominal objectand plural for the verb.
Our model segments the raw to-ken, tags each segment with a morpho-syntactic class (e.g.,?Pron+Fem+Sg?
), and then scores the class sequences.the single raw token in Fig.
2 contains at least fourgrammatically independent morphemes.
Because themorphemes bear conflicting grammatical features andbasic parts of speech (POS), we need to segment thetoken before we can evaluate agreement relations.2Segmentation is typically applied as a bitext pre-processing step, and there is a rich literature on theeffect of different segmentation schemata on transla-tion quality (Koehn and Knight, 2003; Habash andSadat, 2006; El Kholy and Habash, 2012).
Unlike pre-vious work, we segment each translation hypothesisas it is generated (i.e., during decoding).
This permitsgreater modeling flexibility.
For example, it may beuseful to count tokens with bound morphemes as aunit during phrase extraction, but to score segmentedmorphemes separately for agreement.We treat segmentation as a character-level se-quence modeling problem and train a linear-chainconditional random field (CRF) model (Lafferty etal., 2001).
As a pre-processing step, we group con-tiguous non-native characters (e.g., Latin charactersin Arabic text).
The model assigns four labels:?
I: Continuation of a morpheme?
O: Outside morpheme (whitespace)?
B: Beginning of a morpheme?
F: Non-native character(s)2Segmentation also improves translation of compoundinglanguages such as German (Dyer, 2009) and Finnish (Machereyet al, 2011).147Translation Modele Target sequence of I wordsf Source sequence of J wordsa Sequence ofK phrase alignments for ?e, f??
Permutation of the alignments for target word order eh Sequence ofM feature functions?
Sequence of learned weights for theM featuresH A priority queue of hypothesesClass-based Agreement Modelt ?
T Set of morpho-syntactic classess ?
S Set of all word segments?seg Learned weights for the CRF-based segmenter?tag Learned weights for the CRF-based tagger?o, ?t CRF potential functions (emission and transition)?
Sequence of I target-side predicted classespi T dimensional (log) prior distribution over classess?
Sequence of l word segments?
Model state: a tagged segment ?s, t?Figure 3: Notation used in this paper.
The convention eIiindicates a subsequence of a length I sequence.The features are indicators for (character, position,label) triples for a five character window and bigramlabel transition indicators.This formulation is inspired by the classic ?IOB?text chunking model (Ramshaw and Marcus, 1995),which has been previously applied to Chinese seg-mentation (Peng et al, 2004).
It can be learned fromgold-segmented data, generally applies to languageswith bound morphemes, and does not require a hand-compiled lexicon.3 Moreover, it has only four labels,so Viterbi decoding is very fast.
We learn the param-eters ?seg using a quasi-Newton (QN) procedure withl1 (lasso) regularization (Andrew and Gao, 2007).2.3 Morpho-syntactic TaggingAfter segmentation, we tag each segment with a fine-grained morpho-syntactic class.
For this task we alsotrain a standard CRF model on full sentences withgold classes and segmentation.
We use the same QNprocedure as before to obtain ?tag.A translation derivation is a tuple ?e, f, a?
wheree is the target, f is the source, and a is an alignmentbetween the two.
The CRF tagging model predicts atarget-side class sequence ????
= arg max?I?i=1?tag ?
{?o(?i, i, e) + ?t(?i, ?i?1)}where further notation is defined in Fig.
3.3Mada, the standard tool for Arabic segmentation (Habashand Rambow, 2005), relies on a manually compiled lexicon.Set of Classes The tagger assignsmorpho-syntacticclasses, which are coarse POS categories refined withgrammatical features such as gender and definiteness.The coarse categories are the universal POS tag setdescribed by Petrov et al (2012).
More than 25 tree-banks (in 22 languages) can be automatically mappedto this tag set, which includes ?Noun?
(nominals),?Verb?
(verbs), ?Adj?
(adjectives), and ?ADP?
(pre-and post-positions).
Many of these treebanks alsocontain per-token morphological annotations.
It iseasy to combine the coarse categories with selectedgrammatical annotations.For Arabic, we used the coarse POS tags plusdefiniteness and the so-called phi features (gender,number, and person).4 For example,?PAJ??
@ ?thecar?
would be tagged ?Noun+Def+Sg+Fem?.
Werestricted the set of classes to observed combinationsin the training data, so the model implicitly disallowsincoherent classes like ?Verb+Def?.Features The tagging CRF includes emission fea-tures ?o that indicate a class ?i appearing with variousorthographic characteristics of the word sequencebeing tagged.
In typical CRF inference, the entireobservation sequence is available throughout infer-ence, so these features can be scored on observedwords in an arbitrary neighborhood around the cur-rent position i.
However, we conduct CRF inferencein tandem with the translation decoding procedure(?3), creating an environment in which subsequentwords of the observation are not available; the MTsystem has yet to generate the rest of the translationwhen the tagging features for a position are scored.Therefore, we only define emission features on theobserved words at the current and previous positionsof a class: ?o(?i, ei, ei?1).The emission features are word types, prefixes andsuffixes of up to three characters, and indicators fordigits and punctuation.
None of these features arelanguage specific.Bigram transition features ?t encode local agree-ment relations.
For example, the model learns that theArabic class ?Noun+Fem?
is followed by ?Adj+Fem?and not ?Adj+Masc?
(noun-adjective gender agree-ment).4Case is also relevant to agreement in Arabic, but it is mostlyindicated by diacritics, which are absent in unvocalized text.1482.4 Word Class Sequence ScoringThe CRF tagger model defines a conditional distribu-tion p(?
|e; ?tag) for a class sequence ?
given a sen-tence e and model parameters ?tag.
That is, the sam-ple space is over class?not word?sequences.
How-ever, in MT, we seek a measure of sentence qualityq(e) that is comparable across different hypotheseson the beam (much like the n-gram language modelscore).
Discriminative model scores have been usedas MT features (Galley and Manning, 2009), but weobtained better results by scoring the 1-best class se-quences with a generative model.
We trained a simpleadd-1 smoothed bigram language model over goldclass sequences in the same treebank training data:q(e) = p(?)
=I?i=1p(?i|?i?1)We chose a bigram model due to the aggressiverecombination strategy in our phrase-based decoder.For contexts in which the LM is guaranteed to backoff (for instance, after an unseen bigram), our decodermaintains only theminimal state needed (perhaps onlya single word).
In less restrictive decoders, higherorder scoring models could be used to score longer-distance agreement relations.We integrate the segmentation, tagging, and scor-ing models into a self-contained component in thetranslation decoder.3 Inference during Translation DecodingScoring the agreement model as part of translationdecoding requires a novel inference procedure.
Cru-cially, the inference procedure does not measurablyaffect total MT decoding time.3.1 Phrase-based Translation DecodingWe consider the standard phrase-based approach toMT (Och and Ney, 2004).
The distribution p(e|f) ismodeled directly using a log-linear model, yieldingthe following decision rule:e?
= arg maxe,a,?
{M?m=1?mhm(e, f, a,?
)}(1)This decoding problem is NP-hard, thus a beam searchis often used (Fig.
4).
The beam search relies on threeoperations, two of which affect the agreement model:Input: implicitly defined search spacegenerate initial hypotheses and add toHsetHfinal to ?whileH is not empty:setHext to ?for each hypothesis ?
inH:if ?
is a goal hypothesis:add ?
toHfinalelse Extend ?
and add toHext IScore agreementRecombine and PruneHextsetH toHextOutput: argmax ofHfinalFigure 4: Breadth-first beam search algorithm of Och andNey (2004).
Typically, a hypothesis stackH is maintainedfor each unique source coverage set.Input: (eI1, n, is_goal)run segmenter on attachment eIn+1 to get s?L1get model state ?
= ?s, t?
for translation prefix en1initialize pi to ?
?set pi(t) = 0compute ??
from parameters ?s, s?L1 , pi, is_goal?compute q(eIn+1) = p(??)
under the generative LMset model state ?new = ?s?L, ??L?
for prefix eI1Output: q(eIn+1)Figure 5: Procedure for scoring agreement for each hy-pothesis generated during the search algorithm of Fig.
4.In the extended hypothesis eI1, the index n+ 1 indicatesthe start of the new attachment.?
Extend a hypothesis with a new phrase pair?
Recombine hypotheses with identical statesWe assume familiarity with these operations, whichare described in detail in (Och and Ney, 2004).3.2 Agreement Model InferenceThe class-based agreement model is implemented asa feature function hm in Eq.
(1).
Specifically, whenExtend generates a new hypothesis, we run the algo-rithm shown in Fig.
5.
The inputs are a translationhypothesis eI1, an index n distinguishing the prefixfrom the attachment, and a flag indicating if theirconcatenation is a goal hypothesis.The beam search maintains state for each deriva-tion, the score of which is a linear combination ofthe feature values.
States in this program depend onsome amount of lexical history.
With a trigram lan-guage model, the state might be the last two wordsof the translation prefix.
Recombine can be appliedto any two hypotheses with equivalent states.
As a149result, two hypotheses with different full prefixes?and thus potentially different sequences of agreementrelations?can be recombined.Incremental Greedy Decoding Decoding withthe CRF-based tagger model in this setting requiressome slight modifications to the Viterbi algorithm.We make a greedy approximation that permits recom-bination and works well in practice.
The agreementmodel state is the last tagged segment ?s, t?
of theconcatenated hypothesis.
We tag a new attachment byassuming a prior distribution pi over the starting posi-tion such that pi(t) = 0 and ??
for all other classes,a deterministic distribution in the tropical semiring.This forces the Viterbi path to go through t. We onlytag the final boundary symbol for goal hypotheses.To accelerate tagger decoding in our experiments,we also used tagging dictionaries for frequently ob-served word types.
For each word type observed morethan 100 times in the training data, we restricted theset of possible classes to the set of observed classes.3.3 Translation Model FeaturesThe agreement model score is one decoder featurefunction.
The output of the procedure in Fig.
5 is thelog probability of the class sequence of each attach-ment.
Summed over all attachments, this gives thelog probability of the whole class sequence.We also add a new length penalty feature.
To dis-criminate between hypotheses that might have thesame number of raw tokens, but different underlyingsegmentations, we add a penalty equal to the lengthdifference between the segmented and unsegmentedattachments |s?L1 | ?
|eIn+1|.4 Related WorkWe compare our class-based model to previous ap-proaches to scoring syntactic relations in MT.Unification-based Formalisms Agreement rulesimpose syntactic and semantic constraints on thestructure of sentences.
A principled way to modelthese constraints is with a unification-based gram-mar (UBG).
Johnson (2003) presented algorithms forlearning and parsing with stochastic UBGs.
However,training data for these formalisms remains extremelylimited, and it is unclear how to learn such knowledge-rich representations from unlabeled data.
One partialsolution is to manually extract unification rules fromphrase-structure trees.
Williams and Koehn (2011)annotated German trees, and extracted translationrules from them.
They then specified manual unifi-cation rules, and applied a penalty according to thenumber of unification failures in a hypothesis.
Incontrast, our class-based model does not require anymanual rules and scores similar agreement phenom-ena as probabilistic sequences.Factored Translation Models Factored transla-tion models (Koehn and Hoang, 2007) facilitate amore data-oriented approach to agreement modeling.Words are represented as a vector of features such aslemma and POS.
The bitext is annotated with separatemodels, and the annotations are saved during phraseextraction.
Hassan et al (2007) noticed that the target-side POS sequences could be scored, much as we doin this work.
They used a target-side LM over Combi-natorial Categorial Grammar (CCG) supertags, alongwith a penalty for the number of operator violations,and also modified the phrase probabilities based onthe tags.
However, Birch et al (2007) showed thatthis approach captures the same re-ordering phenom-ena as lexicalized re-ordering models, which werenot included in the baseline.
Birch et al (2007) theninvestigated source-side CCG supertag features, butdid not show an improvement for Dutch-English.Subotin (2011) recently extended factored transla-tion models to hierarchical phrase-based translationand developed a discriminative model for predictingtarget-side morphology in English-Czech.
His modelbenefited from gold morphological annotations onthe target-side of the 8M sentence bitext.In contrast to these methods, our model does not af-fect phrase extraction and does not require annotatedtranslation rules.Class-based LMs Class-based LMs (Brown et al,1992) reduce lexical sparsity by placing words inequivalence classes.
They have been widely usedfor speech recognition, but not for MT.
Och (1999)showed a method for inducing bilingual word classesthat placed each phrase pair into a two-dimensionalequivalence class.
To our knowledge, Uszkoreit andBrants (2008) are the only recent authors to show animprovement in a state-of-the-art MT system usingclass-based LMs.
They used a classical exchange al-gorithm for clustering, and learned 512 classes from150a large monolingual corpus.
Then they mixed theclasses into a word-based LM.
However, both Och(1999) and Uszkoreit and Brants (2008) relied onautomatically induced classes.
It is unclear if theirclasses captured agreement information.Monz (2011) recently investigated parameter es-timation for POS-based language models, but hisclasses did not include inflectional features.Target-Side Syntactic LMs Our agreement modelis a form of syntactic LM, of which there is a longhistory of research, especially in speech processing.5Syntactic LMs have traditionally been too slow forscoring during MT decoding.
One exception wasthe quadratic-time dependency language model pre-sented by Galley and Manning (2009).
They applieda quadratic time dependency parser to every hypothe-sis during decoding.
However, to achieve quadraticrunning time, they permitted ill-formed trees (e.g.,parses with multiple roots).
More recently, Schwartzet al (2011) integrated a right-corner, incrementalparser into Moses.
They showed a large improve-ment for Urdu-English, but decoding slowed by threeorders of magnitude.6 In contrast, our class-basedmodel encodes shallow syntactic information withouta noticeable effect on decoding time.Our model can be viewed as a way to score localsyntactic relations without extensive decoder modifi-cations.
For long-distance relations, Shen et al (2010)proposed a new decoder that generates target-sidedependency trees.
The target-side structure enablesscoring hypotheses with a trigram dependency LM.5 ExperimentsWe first evaluate the Arabic segmenter and taggercomponents independently, then provide English-Arabic translation quality results.5.1 Intrinsic Evaluation of ComponentsExperimental Setup All experiments use the PennArabic Treebank (ATB) (Maamouri et al, 2004) parts1?3 divided into training/dev/test sections accordingto the canonical split (Rambow et al, 2005).75See (Zhang, 2009) for a comprehensive survey.6In principle, their parser should run in linear time.
An imple-mentation issue may account for the decoding slowdown.
(p.c.
)7LDC catalog numbers: LDC2008E61 (ATBp1v4),LDC2008E62 (ATBp2v3), and LDC2008E22 (ATBp3v3.1).Full (%) Incremental (%)Segmenter 98.6 ?Tagger 96.3 96.2Table 1: Intrinsic evaluation accuracy [%] (developmentset) for Arabic segmentation and tagging.The ATB contains clitic-segmented text with per-segment morphological analyses (in addition tophrase-structure trees, which we discard).
For train-ing the segmenter, we used markers in the vocalizedsection to construct the IOB character sequences.
Fortraining the tagger, we automatically converted theATB morphological analyses to the fine-grained classset.
This procedure resulted in 89 classes.For the segmentation evaluation, we report per-character labeling accuracy.8 For the tagger, we re-port per-token accuracy.Results Tbl.
1 shows development set accuracy fortwo settings.
Full is a standard evaluation in whichfeatures may be defined over the whole sentence.
Thisincludes next-character segmenter features and next-word tagger features.
Incremental emulates the MTsetting in which the models are restricted to currentand previous observation features.
Since the seg-menter operates at the character level, we can usethe same feature set.
However, next-observation fea-tures must be removed from the tagger.
Nonetheless,tagging accuracy only decreases by 0.1%.5.2 Translation QualityExperimental Setup Our decoder is based on thephrase-based approach to translation (Och and Ney,2004) and contains various feature functions includ-ing phrase relative frequency, word-level alignmentstatistics, and lexicalized re-ordering models (Till-mann, 2004; Och et al, 2004).
We tuned the featureweights on a development set using lattice-based min-imum error rate training (MERT) (Macherey et al,The data was pre-processed with packages from the StanfordArabic parser (Green and Manning, 2010).
The corpus split isavailable at http://nlp.stanford.edu/projects/arabic.shtml.8We ignore orthographic re-normalization performed by theannotators.
For example, they converted the contraction ????
llback to ??@'??
l Al.
As a result, we can report accuracy sincethe guess and gold segmentations have equal numbers of non-whitespace characters.151MT04 (tune) MT02 MT03 MT05 AvgBaseline 18.14 23.87 18.88 22.60+POS 18.11 ?0.03 23.65 ?0.22 18.99 +0.11 22.29 ?0.31 ?0.17+POS+Agr 18.86 +0.72 24.84 +0.97 20.26 +1.38 23.48 +0.88 +1.04genres nw nw nw nw#sentences 1353 728 663 1056 2447Table 2: Translation quality results (BLEU-4 [%]) for newswire (nw) sets.
Avg is the weighted averaged (by number ofsentences) of the individual test set gains.
All improvements are statistically significant at p ?
0.01.MT06 MT08 AvgBaseline 14.68 14.30+POS 14.57 ?0.11 14.30 +0.0 ?0.06+POS+Agr 15.04 +0.36 14.49 +0.19 +0.29genres nw,bn,ng nw,ng,wb#sentences 1797 1360 3157Table 3: Mixed genre test set results (BLEU-4 [%]).
TheMT06 result is statistically significant at p ?
0.01; MT08is significant at p ?
0.02.
The genres are: nw, broadcastnews (bn), newsgroups (ng), and weblog (wb).2008).
For each set of results, we initialized MERTwith uniform feature weights.We trained the translation model on 502 millionwords of parallel text collected from a variety ofsources, including theWeb.
Word alignments were in-duced using a hidden Markov model based alignmentmodel (Vogel et al, 1996) initialized with bilexicalparameters from IBM Model 1 (Brown et al, 1993).Both alignment models were trained using two itera-tions of the expectation maximization algorithm.
Ourdistributed 4-gram language model was trained on600 million words of Arabic text, also collected frommany sources including the Web (Brants et al, 2007).For development and evaluation, we used the NISTArabic-English data sets, each of which contains oneset of Arabic sentences and multiple English refer-ences.
To reverse the translation direction for eachdata set, we chose the first English reference as thesource and the Arabic as the reference.The NIST sets come in two varieties: newswire(MT02-05) and mixed genre (MT06,08).
Newswirecontains primarily Modern Standard Arabic (MSA),while the mixed genre data sets also contain tran-scribed speech and web text.
Since the ATB containsMSA, and significant lexical and syntactic differencesmay exist between MSA and the mixed genres, weachieved best results by tuning on MT04, the largestnewswire set.We evaluated translation quality with BLEU-4 (Pa-pineni et al, 2002) and computed statistical signifi-cance with the approximate randomization methodof Riezler and Maxwell (2005).96 Discussion of Translation ResultsTbl.
2 shows translation quality results on newswire,while Tbl.
3 contains results for mixed genres.
Thebaseline is our standard system feature set.
Forcomparison, +POS indicates our class-based modeltrained on the 11 coarse POS tags only (e.g., ?Noun?
).Finally, +POS+Agr shows the class-based modelwith the fine-grained classes (e.g., ?Noun+Fem+Sg?
).The best result?a +1.04 BLEU average gain?was achieved when the class-based model trainingdata, MT tuning set, and MT evaluation set containedthe same genre.
We realized smaller, yet statisticallysignificant, gains on the mixed genre data sets.
Wetried tuning on both MT06 and MT08, but obtainedinsignificant gains.
In the next section, we investigatethis issue further.Tuning with a Treebank-Trained Feature Theclass-based model is trained on the ATB, which is pre-dominantly MSA text.
This data set is syntacticallyregular, meaning that it does not have highly dialectalcontent, foreign scripts, disfluencies, etc.
Conversely,the mixed genre data sets contain more irregulari-ties.
For example, 57.4% of MT06 comes from non-newswire genres.
Of the 764 newsgroup sentences,112 contain some Latin script tokens, while otherscontain very little morphology:9With the implementation of Clark et al (2011), available at:http://github.com/jhclark/multeval.152(2) ???g@mix1/21/2H.
?
?cup?gvinegarhA?KappleMix 1/2 cup apple vinegar(3)@YK.startl .?AKQK.program?
P?J?miozik?A?maatshMusicMatchMusicMatchStart the program music match (MusicMatch)In these imperatives, there are no lexically markedagreement relations to score.
Ex.
(2) is an excerptfrom a recipe that appears in full in MT06.
Ex.
(3)is part of usage instructions for the MusicMatch soft-ware.
The ATB contains few examples like these, soour class-based model probably does not effectivelydiscriminate between alternative hypotheses for thesetypes of sentences.Phrase Table Coverage In a standard phrase-based system, effective translation into a highly in-flected target language requires that the phrase tablecontain the inflected word forms necessary to con-struct an output with correct agreement.
If the requi-site words are not present in the search space of thedecoder, then no feature function would be sufficientto enforce morpho-syntactic agreement.During development, we observed that the phrasetable of our large-scale English-Arabic system didoften contain the inflected forms that we desired thesystem to select.
In fact, correctly agreeing alterna-tives often appeared in n-best translation lists.
Toverify this observation, we computed the lexical cov-erage of the MT05 reference sentences in the decodersearch space.
The statistics below report the token-level recall of reference unigrams:10?
Baseline system translation output: 44.6%?
Phrase pairs matching source n-grams: 67.8%The bottom category includes all lexical items thatthe decoder could produce in a translation of thesource.
This large gap between the unigram recallof the actual translation output (top) and the lexicalcoverage of the phrase-based model (bottom) indi-cates that translation performance can be improveddramatically by altering the translation model throughfeatures such as ours, without expanding the searchspace of the decoder.10To focus on possibly inflected word forms, we excludednumbers and punctuation from this analysis.Human Evaluation We also manually evaluatedthe MT05 output for improvements in agreement.11Our system produced different output from the base-line for 785 (74.3%) sentences.
We randomly sam-pled 100 of these sentences and counted agreementerrors of all types.
The baseline contained 78 errors,while our system produced 66 errors, a statisticallysignificant 15.4% error reduction at p ?
0.01 accord-ing to a paired t-test.In our output, a frequent source of remaining errorswas the case of so-called ?deflected agreement?
: inan-imate plural nouns require feminine singular agree-ment with modifiers.
On the other hand, animateplural nouns require the sound plural, which is indi-cated by an appropriate masculine or feminine suffix.For example, the inanimate plural HAKB??
@ ?states?
re-quires the singular feminine adjective?YjJ??
@ ?united?,not the sound plural H@YjJ??
@.
The ATB does not con-tain animacy annotations, so our agreement modelcannot discriminate between these two cases.
How-ever, Alkuhlani and Habash (2011) have recentlystarted annotating the ATB for animacy, and ourmodel could benefit as more data is released.7 Conclusion and OutlookOur class-based agreement model improves transla-tion quality by promoting local agreement, but witha minimal increase in decoding time and no addi-tional storage requirements for the phrase table.
Themodel can be implemented with a standard CRF pack-age, trained on existing treebanks for many languages,and integrated easily with many MT feature APIs.We achieved best results when the model trainingdata, MT tuning set, and MT evaluation set con-tained roughly the same genre.
Nevertheless, we alsoshowed an improvement, albeit less significant, onmixed genre evaluation sets.In principle, our class-based model should be morerobust to unseen word types and other phenomena thatmake non-newswire genres challenging.
However,our analysis has shown that for Arabic, these genrestypically contain more Latin script and transliteratedwords, and thus there is less morphology to score.One potential avenue of future work would be to adaptour component models to new genres by self-trainingthem on the target side of a large bitext.11The annotator was the first author.153AcknowledgmentsWe thank Zhifei Li and ChrisManningfor helpful discussions, and Klaus Macherey, WolfgangMacherey, Daisy Stanton, and Richard Zens for engineer-ing support.
This work was conducted while the first au-thor was an intern at Google.
At Stanford, the first authoris supported by a National Science Foundation GraduateResearch Fellowship.ReferencesS.
Alkuhlani and N. Habash.
2011.
A corpus for modelingmorpho-syntactic agreement in Arabic: Gender, number andrationality.
In ACL-HLT.G.
Andrew and J. Gao.
2007.
Scalable training of l1-regularizedlog-linear models.
In ICML.E.
Avramidis and P. Koehn.
2008.
Enriching morphologicallypoor languages for statistical machine translation.
In ACL.A.
Birch, M. Osborne, and P. Koehn.
2007.
CCG supertags infactored statistical machine translation.
In WMT.T.
Brants, A. C. Popat, P. Xu, F. J. Och, and J.
Dean.
2007.
Largelanguage models in machine translation.
In EMNLP-CoNLL.P.
F. Brown, P. V. deSouza, R. L. Mercer, V. J. Della Pietra,and J. C. Lai.
1992.
Class-based n-gram models of naturallanguage.
Computational Linguistics, 18:467?479.P.
F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L.Mercer.1993.
The mathematics of statistical machine translation:Parameter estimation.
Computational Linguistics, 19(2):263?313.D.
Cer, M. Galley, D. Jurafsky, and C. D.Manning.
2010.
Phrasal:A statistical machine translation toolkit for exploring newmodel features.
In HLT-NAACL, Demonstration Session.J.
H. Clark, C. Dyer, A. Lavie, and N. A. Smith.
2011.
Better hy-pothesis testing for statistical machine translation: Controllingfor optimizer instability.
In ACL.C.
Dyer.
2009.
Using a maximum entropy model to build seg-mentation lattices for MT.
In NAACL.A.
El Kholy and N. Habash.
2012.
Orthographic and mor-phological processing for English-Arabic statistical machinetranslation.
Machine Translation, 26(1-2):25?45.A.
Fraser, M. Weller, A. Cahill, and F. Cap.
2012.
Modelinginflection and word-formation in SMT.
In EACL.M.
Galley and C. D. Manning.
2009.
Quadratic-time dependencyparsing for machine translation.
In ACL-IJCNLP.S.
Green and C. D. Manning.
2010.
Better Arabic parsing:baselines, evaluations, and analysis.
In COLING.N.
Habash and O. Rambow.
2005.
Arabic tokenization, part-of-speech tagging and morphological disambiguation in one fellswoop.
In ACL.N.
Habash and F. Sadat.
2006.
Arabic preprocessing schemesfor statistical machine translation.
In NAACL.H.
Hassan, K. Sima?an, and A.
Way.
2007.
Supertagged phrase-based statistical machine translation.
In ACL.M.
Johnson.
2003.
Learning and parsing stochastic unification-based grammars.
In COLT.P.
Koehn and H. Hoang.
2007.
Factored translation models.
InEMNLP-CoNLL.P.
Koehn and K. Knight.
2003.
Empirical methods for compoundsplitting.
In EACL.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico,N.
Bertoldi, et al 2007.
Moses: Open source toolkit for sta-tistical machine translation.
In ACL, Demonstration Session.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Conditional ran-dom fields: Probablistic models for segmenting and labelingsequence data.
In ICML.A.
Lopez.
2008.
Statistical machine translation.
ACMComputingSurveys, 40(8):1?49.M.
Maamouri, A. Bies, T. Buckwalter, and W. Mekki.
2004.The Penn Arabic Treebank: Building a large-scale annotatedArabic corpus.
In NEMLAR.W.
Macherey, F. Och, I. Thayer, and J. Uszkoreit.
2008.
Lattice-basedminimum error rate training for statistical machine trans-lation.
In EMNLP.K.
Macherey, A. Dai, D. Talbot, A. Popat, and F. Och.
2011.Language-independent compound splitting with morphologi-cal operations.
In ACL.E.
Minkov, K. Toutanova, and H. Suzuki.
2007.
Generatingcomplex morphology for machine translation.
In ACL.C.
Monz.
2011.
Statistical machine translation with local lan-guage models.
In EMNLP.F.
J. Och and H. Ney.
2004.
The alignment template approachto statistical machine translation.
Computational Linguistics,30(4):417?449.F.
J. Och, D. Gildea, S. Khudanpur, A. Sarkar, K. Yamada,A.
Fraser, et al 2004.
A smorgasbord of features for sta-tistical machine translation.
In HLT-NAACL.F.
J. Och.
1999.
An efficient method for determining bilingualword classes.
In EACL.K.
Papineni, S. Roukos, T. Ward, and W. Zhu.
2002.
BLEU: amethod for automatic evaluation of machine translation.
InACL.F.
Peng, F. Feng, and A. McCallum.
2004.
Chinese segmentationand new word detection using conditional random fields.
InCOLING.S.
Petrov, D. Das, and R. McDonald.
2012.
A universal part-of-speech tagset.
In LREC.O.
Rambow, D. Chiang, M. Diab, N. Habash, R. Hwa, et al 2005.Parsing Arabic dialects.
Technical report, Johns HopkinsUniversity.L.
A. Ramshaw and M. Marcus.
1995.
Text chunking usingtransformation-based learning.
In Proc.
of the ThirdWorkshopon Very Large Corpora.S.
Riezler and J. T. Maxwell.
2005.
On some pitfalls in auto-matic evaluation and significance testing in MT.
In ACL-05Workshop on Intrinsic and Extrinsic Evaluation Measures forMachine Translation and/or Summarization (MTSE).L.
Schwartz, C. Callison-Burch, W. Schuler, and S. Wu.
2011.Incremental syntactic language models for phrase-based trans-lation.
In ACL-HLT.L.
Shen, J. Xu, and R. Weischedel.
2010.
String-to-dependencystatistical machine translation.
Computational Linguistics,36(4):649?671.154M.
Subotin.
2011.
An exponential translation model for targetlanguage morphology.
In ACL-HLT.C.
Tillmann.
2004.
A unigram orientation model for statisticalmachine translation.
In NAACL.K.
Toutanova, H. Suzuki, and A. Ruopp.
2008.
Applying mor-phology generation models to machine translation.
In ACL-HLT.J.
Uszkoreit and T. Brants.
2008.
Distributed word clusteringfor large scale class-based language modeling in machinetranslation.
In ACL-HLT.S.
Vogel, H. Ney, and C. Tillmann.
1996.
HMM-based wordalignment in statistical translation.
In COLING.P.
Williams and P. Koehn.
2011.
Agreement constraints forstatistical machine translation into German.
In WMT.Y.
Zhang.
2009.
Structured Language Models for Statistical Ma-chine Translation.
Ph.D. thesis, Carnegie Mellon University.155
