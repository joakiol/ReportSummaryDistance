Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 374?377,Prague, June 2007. c?2007 Association for Computational LinguisticsUCD-PN: Classification of Semantic Relations Between Nominalsusing WordNet and Web CountsPaul NultySchool of Computer Science and InformaticsUniversity College DublinDublin, Irelandpaul.nulty@ucd.ieAbstractFor our system we use the SMO implemen-tation of a support vector machine providedwith the WEKA machine learning toolkit.As with all machine learning approaches,the most important step is to choose a set offeatures which reliably help to predict thelabel of the example.
We used 76 featuresdrawn from two very different knowledgesources.
The first 48 features are booleanvalues indicating whether or not each of thenominals in the sentence are linked to cer-tain other words in the WordNet hypernymand meronym networks.
The remaining 28features are web frequency counts for thetwo nominals joined by certain commonprepositions and verbs.
Our system per-formed well on all but two of the relations;theme-tool and origin entity.1 Introduction and Related WorkThis paper describes a system for participatingin SemEval 2007 task 4; ?Classification of Seman-tic Relations Between Nominals?.
This SemEvaltask required systems to establish whether or not aparticular semantic relation held between twonominals in a sentence.
There were 7 semantic re-lations, with approximately 70 positive and 70negative example sentences for each relation.There were approximately 70 examples in the testsets for each relation.This task is similar to the problem of determin-ing what semantic relation holds between the con-stituents of a noun-noun compound.
Work in thisarea has used both statistical information about thefrequencies of lexical patterns and hand-builtknowledge databases such as WordNet and the-saura.
In our system we combine these two knowl-edge sources and build a set of features to use asinput to a Support Vector Machine learning algo-rithm.The use of hit counts from web search enginesto obtain lexical information was introduced byTurney (2001).
The idea of searching a large cor-pus for specific lexico-syntactic phrases to indicatea semantic relation of interest was first describedby Hearst (1992).
A lexical pattern specific enoughto indicate a particular semantic relation is usuallynot very frequent, and using the web as a corpusalleviates the data sparseness problem.
However, italso introduces some problems.
The number ofresults returned is unstable as pages are created anddeleted all the time, and the major search enginesreturn only rounded frequency estimates and donot allow a very sophisticated query interface.
Na-kov and Hearst (2005) examined the use of web-based n-gram frequencies for an NLP task andconcluded that these issues do not greatly impactthe interpretation of the results.Turney and Littman (2005) use web queries tothe AltaVista search engine as the basis for theirsystem to assign semantic relations to modifier-noun phrases.
They use a set of 64 short preposi-tional and conjunctive phrases (joining terms) togenerate exact queries of the form ?noun joiningterm modifier?, and ?modifier joining term noun?.Using 64 joining terms and trying the noun andmodifier in either order resulted in a vector of 128374hit counts for each noun-modifier pair.
These hitcounts were used with a supervised (nearestneighbor) algorithm to label the modifier-nounphrases.Nakov and Hearst (2006) use queries of the form?noun that * modifier?
where '*' is a wildcardoperator.
By retrieving the words that mostcommonly occurred in the place of the wildcardthey were able to identify very specific predicatesthat are likely to represent the relation betweennoun and modifier.There have also been several approaches whichused hand built knowledge sources.
Rosario andHearst (2001) used MeSH, a lexical hierarchy ofmedical terms.
They use this hierarchy to assignsemantic properties to head and modifier words inthe medical domain.
They use a neural networktrained on these attributes to assign the nounphrases a semantic relation.Nastase and Szpakowicz (2003) use the positionof the noun and modifier words within general se-mantic hierarchies (Roget's Thesaurus and Word-Net) as attributes for their learning algorithms.They experiment with decision trees, a rule induc-tion system, a relational learner and memory basedlearning.
They conclude that the rule inductionsystem is capable of generalizing to characterizethe noun phrases.Moldovan et al(2004) also use WordNet.
Theyexperiment with a Bayesian algorithm, decisiontrees, and their own algorithm; semantic scattering.As far as we are aware ours is the first system tocombine features derived from a hand-built lexicaldatabase with corpus frequencies of lexicalpatterns.2 System Description2.1 WordNet FeaturesOur system uses both features derived fromWordNet and features obtained by collecting webfrequencies for lexical patterns.
We did not use anyinformation from the sentence in which the twonominals appeared, nor did we use the query usedto retrieve the examples.
We did make use of theWordNet sense for the features we obtained fromWordNet.There are 48 features derived from WordNet.Most of these are boolean values indicatingwhether or not each of the nominals in the sentenceappear below certain other high-level concepts inthe hypernym hierarchy.
We chose 22 high levelconcepts we believed may be good predictors ofwhether or not a nominal could be an argument ofthe semantic relations used in this task.
Theseconcepts are listed below in table 1.Table 1.
Concepts in the WordNet hierarchy used togenerate features.For each of these WordNet entries we checkedwhether or not each of the nominals in the examplesentence appeared below the entry in the WordNethypernym tree.
This gave us 44 features.
We alsochecked whether the first nominal was a hypernymof the second; and vice-versa; and whether the firstnominal was a meronym of the second; and viceversa.
This gives us in total 48 boolean featuresderived from WordNet.2.2 Web FrequenciesThe remaining features were numerical valuesobtained by retrieving the frequencies of websearches for the two nominals joined by certaincommon prepositions and verbs.
These joiningterms are listed below in table 2.Table 2.
Joining terms used to generate features.physical_entitygroupingattributepsychological_featurequantitycontaineractworkbeingnatural_objectinstrumentationphysical_objectsubstancematterprocesscausal_agenttooldevicecontenteventunitstateofforinonatwithaboutproducesused forhascontainsfromcausesmade from375To obtain the frequencies we used the API to the?MSN Live?
search engine.Choosing a set of joining terms in a principledmanner is not an easy task, but there is certainlysome correlation between a prepositional term orshort linking verb and a semantic relation.
For ex-ample, ?contains?
tends to indicate a spatial rela-tion, while the preposition ?in?
indicates a locativerelation, either temporal or spatial.When collecting web frequencies we took ad-vantage of the OR operator provided by the searchengine.
For each joining term, we wanted to sumthe number of hits for the term on its own, the termfollowed by 'a', and the term followed by 'the'.
In-stead of conducting separate queries for each ofthese forms, we were able to sum the results withjust one search.
For example, if the two nominalsin the sentence were ?battery?
and ?phone?
; one ofthe queries would be:?battery in phone?
OR ?battery in a phone?
OR?battery in the phone?These features were numeric values; the raw num-ber of documents returned by the query.2.3 Learning AlgorithmAll of the features were used as input to ourlearning algorithm, which was a Support VectorMachine (SVM).
An SVM is a method for creatinga classification function which works by trying tofind a hypersurface in the space of possible inputsthat splits the positive examples from the negativeexamples for each class.
We did not normalizethese values as normalization is handled by theWEKA implementation which we used.WEKA is a machine learning toolkit written inJava (Witten and Frank, 1999).
The algorithm weused was an SVM trained with the SequentialMinimal Optimization method provided by Weka.3.
ResultsThe average f-value obtained by our system usingall of the training data was 65.4.
There was a sig-nificant difference in performance across differentrelations.
The results for each relation are below.Relation                         Pre   Rec    F     Acccause-effect  61.7  90.2  73.3  66.2instrument-agency  59.3  84.2  69.6  64.1product-producer  70.9  98.4  82.4  72.0origin-entity  51.4  50.0  50.7  56.8theme-tool  52.9  31.0  39.1  60.6part-whole  66.7  69.2  67.9  76.4content-container 71.4  78.9  75.0  73.0Average                        62.0  71.7  65.4  67.The standard deviation of the f-values is 13.9.The average of the f-values is brought down bytwo of the relations; origin-entity and theme-tool.The poor performance of these relations was notedduring early experimentation with the trainingdata; and the list of WordNet concepts and joiningterms was amended to try to improve classifica-tion, but no improvement was achieved.
If the re-sults for these relations are omitted the average f-score rises to 73.63.1 Information GainIn order to evaluate which features were themost useful for each relation, we used the Informa-tion Gain feature ranking tool in WEKA.
This toolmeasures the change in entropy attributed to eachfeature and ranks them accordingly.
In some caseswe found that the high ranking features for a rela-tion were ones which were intuitively relevant topredicting that relation; however some features stillhad high Information Gain despite seemingunlikely to be predictive of the relation.The eight most informative features for theCause-Effect and Content-Container relations areshown below.
WordNet features are in normalTable 3.
The features with the highest information gainfor cause-effect and content-container.Cause-Effect Content-Containerquantityatused for2groupingobject2substancesubstance2instrumentation2Instrumentation2Container2containsphysical_object2physical_entity2psychological_featuresubstance2device2376font; the joining terms for web searches in italics.The '2' after a feature indicates that the web searchwas of the form "N2 joining term N1"; or that theWordNet property holds for N2; where the relationis relation(N1,N2).Most of these features make sense.
For example,the search query ?contains?
and the Wordnet entry?Container?
linked to the second noun are the sec-ond and third most informative for the content con-tainer class, and the query ?N2 used for N1?
rankshighly in the cause-effect relation.
However, it isunclear why being a hyponym of ?quantity?
wouldprovide information about the cause-effect relation.4    Conclusion and Future WorkThis paper describes a system for participating inSemEval 2007 task 4; ?Classification of SemanticRelations Between Nominals?.
Our system com-bines features generated by analyzing the WordNethypernym tree with features which indicate thefrequencies of certain lexical patterns involving thenominals and common prepositions, using the webas a corpus.The performance of the system was above theaverage score of other systems which used theWordNet sense of the training examples but not thequery used to obtain them.
The system was heldback particularly by two relations, theme-tool andorigin-entity.There are many potential avenues for future workin this area.
We chose 48 features based on Word-Net and 28 lexical patterns to search the web for.These were chosen arbitrarily on the basis that theylooked like they would be informative in general,over all seven relations.
A more principled ap-proach would be to begin with a much larger num-ber of features and use information gain to selectthe most informative features for each relation in-dividually.
This should improve performance byensuring that only the most relevant features for aspecific relation are used to train the classifier forthat relation.Also, there is room for more investigation into howshort prepositional joining phrases map onto un-derlying semantic relations (Girjiu 2006).ReferencesRoxana Girju.
2006.
Out-of-context noun phrase seman-tic interpretation with cross-linguistic evidence.
InProceedings of the 15th ACM international confer-ence on Information and knowledge managementMarti A. Hearst: 1992.
Automatic Acquisition of Hypo-nyms from Large Text Corpora.
COLING:539-545Dan Moldovan, Adriana Badulescu, Marta Tatu, DanielAntohe and Roxana Girju.
2004.
Models for the Se-mantic Classification of Noun Phrases.
In Proceed-ings of the HLT/NAACL Workshop on ComputationalLexical Semantics.
Boston , MA.Preslav Nakov and Marti Hearst.
2006.
Using Verbs toCharacterize Noun-Noun Relations, in the Proceed-ings of AIMSA 2006,Preslav Nakov and Marti Hearst.
2005.
Using the Webas an Implicit Training Set: Application to StructuralAmbiguity Resolution, in HLT/EMNLP'05,Vivi Nastase and Stan Szpakowicz.
2003.
ExploringNoun-Modifier Semantic Relations.
InternationalWorkshop on Computational Semantics, Tillburg,Netherlands,  2003Barbara Rosario and Marti A. Hearst.
2001.
Classifyingthe semantic relations in noun compounds via a do-main-specific lexical hierarchy.
In Proceedings of the2001 Conference on Empirical Methods in NaturalLanguage Processing.
ACLPeter D. Turney.
2001.
Mining the web for synonyms:PM-IR vs LSA on TOEFL, Proceedings of theTwelth European Conference on machine learning,Peter D. Turney and Michael L. Littman.
2005.
Corpus-based learning of analogies and semantic relations.Machine Learning, 60(1?3):251?278Ian H. Witten and Eibe Frank.
1999.
Data Mining:Practical Machine Learning Tools and Techniqueswith Java Implementations, Morgan Kaufmann(1999)377
