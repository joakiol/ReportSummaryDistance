First Joint Conference on Lexical and Computational Semantics (*SEM), pages 374?377,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsSemEval-2012 Task 4: Evaluating Chinese Word SimilarityPeng Jin Yunfang WuSchool of Computer Science Institute of Computational LinguisticsLeshan Normal University Peking UniversityLeshan, 614000, China Beijing, 100871, Chinajandp@pku.edu.cn wuyf@pku.edu.cnAbstractThis task focuses on evaluating word similari-ty computation in Chinese.
We follow the wayof Finkelstein et al (2002) to select wordpairs.
Then we organize twenty under-graduates who are major in Chinese linguis-tics to annotate the data.
Each pair is assigneda similarity score by each annotator.
We rankthe word pairs by the average value of similarscores among the twenty annotators.
This datais used as gold standard.
Four systems partici-pating in this task return their results.
Weevaluate their results on gold standard data interm of  Kendall's tau value, and the resultsshow three of them have a positive correlationwith the rank manually created while the taus'value is very small.1 IntroductionThe goal of word similarity is to compute the simi-larity degree between words.
It is widely used innatural language processing to alleviate datasparseness which is an open problem in this field.Many research have focus on English language(Lin, 1998; Curran and Moens, 2003; Dinu andLapata, 2010), some of which rely on the manualcreated thesaurus such as WordNet (Budanitskyand Hirst, 2006), some of which obtain the similar-ity of the words via large scale corpus (Lee, 1999),and some research integrate both thesaurus andcorpus (Fujii et al, 1997).
This task tries to evalu-ate the approach on word similarity for Chineselanguage.
To the best of our knowledge, this is firstrelease of  benchmark data for this study.In English language, there are two data sets: Ru-benstein and Goodenough (1965) and Finkelsteinet al (2002) created a ranking of word pairs as thebenchmark data.
Both of them are manually anno-tated.
In this task, we follow the way to create thedata and annotate the similarity score betweenword pairs by twenty Chinese native speakers.Finkelstein et al (2002) carried out a psycholin-guistic experiment: they selected out 353 wordpairs, then ask the annotators assign a numericalsimilarity score between 0 and 10 (0 denotes thatwords are totally unrelated, 10 denotes that wordsare VERY closely related) to each pair.
By defini-tion, the similarity of the word to itself should be10.
A fractional score is allowed.It should be noted that besides the rank of wordpairs, the thesaurus such as Roget's thesaurus areoften used for word similarity study (Gorman andCurran, 2006).The paper is organized as follows.
In section 2we describe in detail the process of the data prepa-ration.
Section 3 introduces the four participatingsystems.
Section 4 reports their results and gives abrief discussion.. And finally in section 5 we bringforward some suggestions for the next campaignand conclude the paper.3742 Data Preparation2.1 Data SetWe use wordsim 353 (Finkelstein et al, 2002) asthe original data set.
First, each word pair is trans-lated into Chinese by two undergraduates who arefluent in English.
169 word pairs are the same intheir translation results.
To the rest 184 word pairs,the third undergraduate student check them   fol-lowing the rules:(i) Single character vs. two characters.
If onetranslator translate one English word into the Chi-nese word which consists only one Chinese charac-ter and the other use two characters to convey thetranslation, we will prefer to the later provided thatthese two translations are semantically same.
Forexample, "tiger" is translated into "?"
and "??
",we will treat them as same and use "??"
as thefinal translation.
This was the same case in "drug"("?"
and "??"
are same translations).
(ii) Alias.
The typical instance is "potato", both "??"
and "???"
are the correct translations.
Sowe will treat them as same and prefer "??"
as thefinal translation because it is more general usedthan the latter one.
(iii) There are five distinct word pairs  in thetranslations and are removed.At last, 348 word pairs are used in this task.Among these 348 word pairs, 50 ones are used asthe trial data and the rest ones are used as the testdata1.2.2 Manual AnnotationEach word pair is assigned the similarity score bytwenty Chinese native speakers.
The score rangesfrom 0 to 5 and 0 means two words have nothingto do with each other and 5 means they are identi-cally in semantic meaning.
The higher score meansthe more similar between two words.
Not only in-teger but also real is acceptable as the annotatedscore.
We get the average of all the scores given bythe annotators for each word pair and then sortthem according to the similarity scores.
The distri-bution of word pairs on the similar score is illus-trated as table 1.1 In fact there are 297 word pairs are evaluated because onepair is missed during the annotation.Score 0.0-1.0 1.0-2.0 2.0-3.0 3.0-4.0 4.0-5.0# Word pairs 39 90 132 72 13Table1: The distribution of similarity scoreRa-nkWord in Chi-nese/EnglishWord 2 inChinese/ Eng-lishSimi-larityscoreStd.devRSD(%)1 ?
?/football ?
?/soccer 4.98 0.1 2.02 ?
?/tiger ?
?/tiger 4.89 0.320 6.553 ?
?/planet ?
?/star 4.72 0.984 20.84 ???/admission?
?/ticket 4.60 0.516 11.25 ?/money ?
?/cash 4.58 0.584 12.76 ?
?/bank ?/cash 4.29 0.708 16.57 ?
?/cell ?
?/phone 4.28 0.751 17.58 ?
?/gem ?
?/jewel 4.24 0.767 18.19 ?
?/type ?
?/kind 4.24 1.000 23.610 ??
/ calcu-lation??
/ compu-tation4.14 0.780 19.0Avg - - 4.496 0.651 14.80Table 2: Top ten similar word pairsTable 2 and table 3 list top ten similar wordpairs and top ten un-similar word pairs individual-ly.
Standard deviation (Std.
dev) and relative standarddeviation (RSD) are also computed.
Obviously, the rela-tive standard deviation of top ten similar word pairs isfar less than the un-similar pairs.2.3 Annotation AnalysisFigure 1 illustrates the relationship between thesimilarity score and relative standard deviation.The digits in "x" axes are the average similarityscore of every integer interval, for an instance,1.506 is the average of all word pairs' similarityscore between 1.0 and 2.0.3 Participating SystemsFour systems coming from two teams participatedin this task.375Figure 1.
The relationship between RSD and simi-lar scoreRa-nkWord1 in Chi-nese/in EnglishWord2 in Chi-nese/in EnglishSimi-larityscoreStd.devRSD(%)1 ?
?/noon ?
?/string 0.06 .213 338.72 ?
?/king ??
?/cabbage0.16 .382 245.33 ??/production?
?/hike 0.17 .432 247.54 ?
?/delay ???
?/racism0.26 .502 191.15 ?
?/professor ?
?/cucumber 0.30 .62 211.16 ?
?/stock ??
?/jaguar 0.30 .815 268.27 ?
?/sign ?
?/recess 0.30 .655 215.48 ?
?/stock CD/CD 0.31 .540 173.69 ?/drink ?
?/ear 0.31 .833 264.810 ?
?/rooster ?
?/voyage 0.33 .771 236.7Avg - - 0.25 .576 239.2Table 3: Top ten un-similar word pairsMIXCC: This system used two machine reada-ble dictionary (MRD), HIT IR-Lab Tongyici Cilin(Extended) (Cilin) and the other is Chinese Con-cept Dictionary (CCD).
The extended CiLin con-sists of 12 large classes, 97 medium classes, 1,400small classes (topics), and 17,817 small synonymsets which cover 77,343 head terms.
All the itemsare constructed as a tree with five levels.
With theincreasing of levels, word senses are more fine-grained.
The Chinese Concept Dictionary is a Chi-nese WordNet produced by Peking University.Word concepts  are presented as synsets   corre-sponding to WordNet 1.6.
Besides synonym, anto-nym, hypernym/hyponym, holonym/meronym,there is another semantic relation type named asattribute which happens between two words withdifferent part-of-speeches.They first divide all word pairs into five partsand rank them according to their levels in Cilin indescending order.
For each part, they computedword similarity by Jiang and Conrath (1997) meth-od2.MIXCD: Different form MIXCC, this systemused the trial data to learn a multiple linear regres-sion functions.
The CCD was considered as a di-rected graph.
The nodes were synsets and edgeswere the semantic relations between two synsets.The features for this system were derived fromCCD and a corpus and listed as follows:?
the shortest path between two synsetswhich contain the words?
the rates of 5 semantic relation types?
mutual information of a word pair in thecorpusThey used the result of multiple linear regres-sions to forecast the similarity of other word pairsand get the rank.GUO-ngram: This system used the methodproposed by (Gabrilovich and Markovitch, 2007).They downloaded the Wikipedia on 25th Novem-ber, 2011 as the knowledge source.
In order to by-pass the Chinese segmentation, they extract onecharacter (uni-gram) and two sequential characters(bi-gram) as the features.GUO-words: This system is very similar toGUO-ngram except that the features consist ofwords rather than n-grams.
They implemented asimple index method which searches all continuouscharacter strings appearing in a dictionary.
For ex-ample, given a text string ABCDEFG in whichABC, BC, and EF appear in the dictionary.
Theoutput of the tokenization algorithm is the threewords ABC, BC, EF and the two characters E andG.2 Because there is no sense-tagged corpus for CCD, the fre-quency of each concept was set to 1 in this system.3764 ResultsEach system is required to rank these 500 wordpairs according to their similarity scores.
Table 4gives the overall results obtained by each of thesystems.Rank Team ID System ID Tau'svalue1libMIXCC 0.0502 MIXCD 0.0403Gfp1987Guo-ngram 0.0074 Guo-words -0.011Table 4: The results of four systmesThe ranks returned by these four systems will becompared with the rank from human annotation bythe Kendall Rank Correlation Coefficient:?
??
?2 ,1 1 / 2SN N?
??
?
?
?Where N  is the number of objects.
?
and ?
aretwo distinct orderings of a object in two ranks.
( , )S ?
?
is the minimum number of adjacenttranspositions needing to bring ?
and ?
(Lapata,2006).
In this metric, tau's value ranges from -1 to+1 and -1 means that the two ranks are inverse toeach other and +1 means the identical rank.From table 4, we can see that except the finalsystem, three of them got the positive tau's value.
Itis regret that the tau's is very small even if theMIXCC system  is the best one.5 ConclusionWe organize an evaluation task focuses on wordsimilarity in Chinese language.
Totally 347 wordpairs are annotated similarity scores by twenty na-tive speakers.
These word pairs are ordered by thesimilarity scores and this rank is used as bench-mark data for evaluation.Four systems participated  in this task.
Exceptthe system MIXCD, three ones got their own rankonly via the corpus.
Kendall's tau is used as theevaluation metric.
Three of them got the positivecorrelation rank compared with the gold standarddataGenerally the tau's value is very small, it indi-cates that obtaining a good rank is still difficult.We will provide more word pairs and distinct themrelatedness from similar, and attract more teams toparticipate in the interesting task.AcknowledgmentsThis research is supported by National NaturalScience Foundation of China (NSFC) under GrantNo.
61003206, 60703063.ReferencesA.
Budanitsky and G. Hirst.
Evaluating WordNet-basedMeasures of Lexical Semantic Relatedness.
Compu-tational Linguistics, 2006, 32(1):13-47.J.
Curran and M. Moens.
Scaling Context Space.
Pro-ceedings of ACL, 2002, pp.
231-238.G.
Dinu and M. Lapata.
Measuring Distributional Simi-larity in Context.
Proceedings of EMNLP, 2010, pp.1162-1172.L.
Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin, Z.Solan, G. Wolfman, and E. Ruppin.
2002.
PlacingSearch in Context: The Concept Revisited.
ACMTransactions on Information Systems, 20(1):116-131.A.
Fujii, T. Hasegawa, T. Tokunaga and H. Tanaka.Integration of Hand-Crafted and Statistical Resourcesin Measuring Word Similarity.
1997.
Proceedings ofWorkshop of Automatic Information Extraction andBuilding of Lexical Semantic Resources for NLP Ap-plications.
pp.
45-51.E.
Gabrilovich and S. Markovitch, Computing SemanticRelatedness using Wikipedia-based Explicit Seman-tic Analysis, Proceedings of IJCAI, Hyderabad, 2007,pp.
1606?1611.J.
Gorman and J. Curran.
Scaling Distributional Similar-ity to Large Corpora.
Proceedings of ACL, 2006, pp.361-368.J.
Jiang and D. Conrath.
1997.
Semantic similaritybased on corpus statistics and lexical taxonomy.
Pro-ceedings of International Conference on Research inComputational Linguistics, Taiwan.M.
Lapata.
Automatic Evaluation of Information Order-ing: Kendall's Tau.
Computational Linguistics, 2006,32(4):471-484.D.
Lin.
Automatic Retrieval and Clustering of SimilarWords.
Proceedings of ACL / COLING, 1998, pp.768-774.L.
Lee.
Measures of Distributional Similarity.
Proceed-ings of ACL, 1999, pp.
25-32.H.
Rubenstein and J.B. Goodenough.
1965.
Contextualcorrelates of synonymy.
Communications of the ACM,8(10):627-633.377
