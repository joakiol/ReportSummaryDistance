Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 129?132,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsIn-Browser Summarisation: Generating Elaborative Summaries BiasedTowards the Reading ContextStephen Wan and Ce?cile ParisICT Centre?CSIROLocked Bag 17, North Ryde, SydneyNSW 1670, AustraliaFirstname.Lastname@csiro.auAbstractWe investigate elaborative summarisation,where the aim is to identify supplementary in-formation that expands upon a key fact.
Weenvisage such summaries being useful whenbrowsing certain kinds of (hyper-)linked doc-ument sets, such as Wikipedia articles orrepositories of publications linked by cita-tions.
For these collections, an elaborativesummary is intended to provide additional in-formation on the linking anchor text.
Our con-tribution in this paper focuses on identifyingand exploring a real task in which summarisa-tion is situated, realised as an In-Browser tool.We also introduce a neighbourhood scoringheuristic as a means of scoring matches to rel-evant passages of the document.
In a prelim-inary evaluation using this method, our sum-marisation system scores above our baselinesand achieves a recall of 57% annotated goldstandard sentences.1 IntroductionIt has long been held that a summary is useful, par-ticularly if it supports the underlying task of the user?
for an overview of summarisation scenarios seeSpark Jones (1998).
For example, generic (that is,not query-specific) summaries, which are often in-dicative, providing just the gist of a document, areonly useful if they happen to address the underlyingneed of the user.In a push to make summaries more responsiveto user needs, the field of summarisation has ex-plored the overlap with complex question-answering?Information and Communication Technologies Centreresearch to produce query-focused summaries.
Suchwork includes the recent DUC challenges on query-focused summarisation,1 in which the user needs arerepresented by short paragraphs of text written byhuman judges.
These are then used as input to thesummarisation process.
However, modelling userneeds is a difficult task.
DUC descriptions of in-formation needs are only an artificial stipulation of auser?s interest.In this work, we propose a tool built into an inter-net browser that makes use of a very simple heuris-tic for determining user interest.2 The basic premiseof the heuristic is that the text currently being readprovides an approximation of the current user inter-est.
Specifically, as a user reads a sentence, it po-tentially represents a fine-grained information need.We identify the sentence of interest without com-plex methods, relying instead on the user to movethe mouse over the anchor text link to request a sum-mary of the linked document, thus identifying to thebrowser plug-in which sentence is now in focus.To generate the summary, the whole document,specifically the linking sentence that contains the an-chor text, serves as the reading context, a potentialindicator of the user interest.
An example of the cur-rent output on Wikipedia text is presented in Figure1.
It shows an elaborative summary of a documentabout the Space Shuttle Discovery expanding on thecontent of the linking sentence.
In this case, it givesfurther information about a space walk in which theshuttle was repaired inflight.Our summarisation tool, the In-Browser Elabora-1http://duc.nist.gov/guidelines/2006.html2We currently work with the Firefox browser.129Figure 1: A summary generated when moving the mouseover the link ?Discovery?s?
(mouse pointer omitted).tive Summariser (IBES), complements generic sum-maries in providing additional information about aparticular aspect of a page.3 Generic summariesthemselves are easy to generate due to rules enforcedby the Wikipedia style-guide, which dictates that alltitles be noun phrases describing an entity, thus serv-ing as a short generic summary.
Furthermore, thefirst sentence of the article should contain the titlein subject position, which tends to create sentencesthat define the main entity of the article.For the elaborative summarisation scenario de-scribed, we are interested in exploring ways inwhich the reading context can be leveraged to pro-duce the elaborative summary.
One method ex-plored in this paper attempts to map the content ofthe linked document into the semantic space of thereading context, as defined in vector-space.
We useSingular Value Decomposition (SVD), the underly-ing method behind Latent Semantic Analysis (Deer-wester et al, 1990), as a means of identifying latenttopics in the reading context, against which we com-pare the linked document.
We present our systemand the results from our preliminary investigation inthe remainder of this paper.3http://www.ict.csiro.au/staff/stephen.wan/ibes/2 Related WorkUsing link text for summarisation has been exploredpreviously by Amitay and Paris (2000).
They identi-fied situations when it was possible to generate sum-maries of web-pages by recycling human-authoreddescriptions of links from anchor text.
In our work,we use the anchor text as the reading context to pro-vide an elaborative summary for the linked docu-ment.Our work is similar in domain to that of the 2007CLEF WiQA shared task.4 However, in contrast toour application scenario, the end goal of the sharedtask focuses on suggesting editing updates for aparticular document and not on elaborating on theuser?s reading context.A related task was explored at the Document Un-derstanding Conference (DUC) in 2007.5 Here thegoal was to find new information with respect to apreviously seen set of documents.
This is similar tothe elaborative goal of our summary in the sense thatone could answer the question: ?What else can I sayabout topic X (that hasn?t already been mentionedin the reading context)?.
However, whereas DUCfocused on unlinked news wire text, we explore adifferent genre of text.3 AlgorithmOur approach is designed to select justification sen-tences and expand upon them by finding elaborativematerial.
The first stage identifies those sentencesin the linked document that support the semanticcontent of the anchor text.
We call those sentencesjustification material.
The second stage finds mate-rial that is supplementary yet relevant for the user.In this paper, we report on the first of these tasks,though ultimately both are required for elaborativesummaries.To locate justification material, we implementedtwo known summarisation techniques.
The firstcompares word overlap between the anchor text andthe linked document.
The second approach attemptsto discover a semantic space, as defined by the read-ing context.
The linked document is then mappedinto this semantic space.
These are referred to as theSimple Link method and the SVD method, where4http://ilps.science.uva.nl/WiQA/5http://duc.nist.gov/guidelines/2007.html130the latter divides further into two variants: SVD-Link and SVD-topic.3.1 Simple Link MethodThe first strategy, Simple Link, makes use of stan-dard vector space approaches from Information Re-trieval.
A vector of word frequencies, omitting stop-words, is used to represent each sentence in the read-ing context and in the linked document.
The vec-tor for the anchor sentence is compared with vectorsfor each linked document sentence, using the cosinesimilarity metric.
The highest scoring sentences arethen retrieved as the summary.3.2 Two Singular Value Decomposition (SVD)MethodsIn these approaches, the semantic space of the linkeddocument is mapped into that of the reading context.Intuitively, only those sentences that map well intothe reading context space and are similar to the link-ing sentence would be good justification material.To begin with, the reading context document isrepresented as a term-by-sentence matrix, A, wherestop words are omitted and frequencies are weightedusing inverse document frequency.
A Singular ValueDecomposition (SVD) analysis is performed (usingthe JAMA package6) on this matrix which providesthree resulting matrices: A = USV tr .The S-matrix defines the themes of the readingcontext.
The U-matrix relates the reading contextvocabulary to the discovered themes.
Finally, theV-matrix relates the original sentences to each of thethemes.
The point of the SVD analysis is to discoverthese themes based on co-variance between the wordfrequencies.
If words occur together, they are se-mantically related and the co-variance is marked asa theme, allowing one to capture fuzzy matches be-tween related words.
Crucially, each sentence cannow be represented with a vector of membershipscores to each theme.The first of the semantic space mapping methods,SVD-link, finds the theme that the anchor text be-longs to best.
This is done by consulting the V-matrix of the SVD analysis to find the highest scor-ing theme for that sentence, which we call the link-ing theme.
Each sentence in the linked document,6http://math.nist.gov/javanumerics/jama/after mapping it to the SVD-derived vector space, isthen examined.
The highest scoring sentences thatbelong to the linking theme are then extracted.The second method, SVD-topic, makes a differ-ent assumption about the nature of the reading con-text.
Instead of taking the anchor text as an indicatorof the user?s information need, it assumes that thetop n themes of the reading context document rep-resent the user?s interest.
Of the linked documentsentences, for each of those top n reading contextthemes, the best scoring sentence is extracted.4 EvaluationIn lieu of a user-centered experiment, our prelimi-nary experiments evaluated the effectiveness of thetool in terms of finding justification material for anelaborative summary.
We evaluated the three sys-tems described in Section 3.
Each system selected5 sentences.
We tested against two baselines.
Thefirst simply returns the first 5 sentences.
The secondproduces a generic summary based on Gong and Liu(2001), independently of the reading context.4.1 DataThe data used is a collection of Wikipedia articlesobtained automatically from the web.
The snap-shot of the corpus was collected in 2007.
Of these,links from about 600 randomly chosen documentswere filtered with a heuristic that enforced a sen-tence length of at least 10 words such that the link inthe anchor text occurred after this minimum length.This heuristic was used as an approximate meansof filtering out sentences where the linking sentencewas simply a definition of the entity linked.
In thesecases, the justification material is usually triviallyidentified as the first sentence of the linked docu-ment.
This leaves us with links that potentially re-quire more complicated summarisation methods.Of these cases, 125 cases were randomly selectedand the linked documents annotated for varying de-grees of relevancy.
This resulted in 50 relevant doc-ument links, which we further annotated, selectingsentences supporting the anchor sentence, with aCohen?s Kappa of 0.55.
The intersection of the se-lected sentences was then used as a gold standard foreach test case.131System Recall Precisiongeneric 0.13 0.05SVD-topic 0.14 0.06SVD-link 0.22 0.09simple-link 0.28 0.11Table 1: Recall and Precision figures for all summariserswithout the first 5 sentences.4.2 ResultsIt is difficult to beat the first-5 baseline, which attainsthe best recall of 0.52 and a precision of 0.2, with allother strategies falling behind.
However, we believethat this may be due to the presence of some typesof Wikipedia articles that are narrow in scope andcentered on specific events.
For such articles, wewould naturally advocate using the first N sentencesas a summary.To examine the performance of the summarisa-tion strategies on sentences beyond the top-N , wefiltered the gold standard sets to remove sentencesoccurring in positions 1-5 in the linked document,and tested recall and precision on the remainingsentences.
This reduces our test set by 10 cases.Since documents may be lengthy (more than 100sentences), selecting justification material is a dif-ficult task.
The results are shown in Table 1 and in-dicate that systems using reading context do betterthan a generic summariser.Thinking ahead to the second expansion step inwhich we find elaborative material, good candidatesfor such sentences may be found in the immedi-ate vicinity of justification sentences.
If so, nearmatches for justification sentences may still be use-ful in indicating that, at least, the right portion ofthe document was identified.
Thus, to test for nearmatches, we scored a match if the gold sentenceoccurred on either side of the system-selected sen-tence.
We refer to this as the neighbourhood heuris-tic.Table 2 shows the effect on recall and preci-sion if we treat each selected sentence as defining aneighbourhood of relevance in the linked document.Again, performance on the first 5 sentences were ig-nored.
Recall improved by up to 10% with only asmall drop in precision (6%).
When the neighbour-hood heuristic is run on the original gold sentenceSystem Recall Precisiongeneric 0.27 0.04SVD-topic 0.27 0.04SVD-link 0.30 0.05simple-link 0.38 0.06Table 2: Recall and Precision figures using the neigh-bourhood heuristic (without the first 5 sentences).set (with the first 5 sentences), recall reaches 0.57,which lies above an amended 0.55 baseline.5 Future Work and ConclusionsWe introduced the concept of a user-biased elabo-rative summarisation, using the reading context asan indicator of the information need.
Our paperpresents a scenario in which elaborative summari-sation may be useful and explored simple summari-sation strategies to perform this role.
Results areencouraging and our preliminary evaluation showsthat reading context is helpful, achieving a recallof 57% when identifying sentences that justify con-tent in the linking sentence of the reading context.In future work, we intend to explore other latenttopic methods to improve recall and precision per-formance.
Further development of elaborative sum-marisation strategies and a user-centered evaluationare also planned.ReferencesEinat Amitay and Ce?cile Paris.
2000.
Automaticallysummarising web sites: is there a way around it?
InProceedings of the 9th international conference on In-formation and knowledge management, NY, USA.Scott C. Deerwester, Susan T. Dumais, Thomas K. Lan-dauer, George W. Furnas, and Richard A. Harshman.1990.
Indexing by Latent Semantic Analysis.
Jour-nal of the American Society of Information Science,41(6):391?407.Yihong Gong and Xin Liu.
2001.
Generic text summa-rization using relevance measure and latent semanticanalysis.
In Proceedings of the 24th ACM SIGIR con-ference.
New Orleans, USA.Karen Spark Jones.
1998.
Automatic summarizing:factors and directions.
In I. Mani and M. May-bury (ed.
), Advances in Automatic Text Summarisa-tion.
MIT Press, Cambridge MA.132
