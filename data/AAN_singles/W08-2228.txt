Textual Entailment as anEvaluation Framework forMetaphor Resolution:A ProposalRodrigo AgerriJohn BarndenMark LeeAlan WallingtonUniversity of Birmingham (UK)email: r.agerri@cs.bham.ac.ukAbstractWe aim to address two complementary deficiencies in Natural LanguageProcessing (NLP) research: (i) Despite the importance and prevalence ofmetaphor across many discourse genres, and metaphor?s many functions,applied NLP has mostly not addressed metaphor understanding.
But,conversely, (ii) difficult issues in metaphor understanding have hinderedlarge-scale application, extensive empirical evaluation, and the handlingof the true breadth of metaphor types and interactions with other languagephenomena.
In this paper, abstracted from a recent grant proposal, a newavenue for addressing both deficiencies and for inspiring new basic re-search on metaphor is investigated: namely, placing metaphor researchwithin the ?Recognizing Textual Entailment?
(RTE) task framework forevaluation of semantic processing systems.357358 Agerri, Barnden, Lee, and Wallington1 IntroductionThe RTE task and annual Challenges (Dagan et al, 2007), starting in 2005, have arisenas an evaluation framework for applied semantics in response to the fact that in NLPapplications ?
such as Question Answering (QA), Information Retrieval/Extraction(IR, IE), etc.
?
the development of semantic algorithms and models have been scat-tered, or tailored to specific applications, making it difficult to compare and evaluatethem within one framework.
RTE is interesting because QA, IE, etc.
can all be castas RTE problems.
In RTE, one text fragment, the Text T, is said to entail another one,the Hypothesis H, when humans considering T and H judge that H follows from T(perhaps only plausibly/defeasibly).
Thus, entailment is a commonsense matter, not aprecise logic-based one.
An example of a T/H pair is as follows (metaphor in italics):(1) T: Lyon is actually the gastronomic capital of France.H: Lyon is the capital of France.Metaphor can roughly be characterized as describing something (the target) as if itwere something else (the source) to which it is perceived, or set forth, as being some-how analogous.
Metaphor has long been identified as being ubiquitous in language(Goatly, 1997), including ordinary conversation, newspaper articles, popular novels,popular science writing, classroom dialogue, etc.
In a study (Tech.
Rept.
CSRP-03-05at our School, 2003) we found one metaphorical term per 17.3 words, averaging acrossvarious discourses of different genres.
This is in line with other researchers?
studiesthough counts vary widely because of theory-relativity, researchers?
aims, and markedusage differences between genres.
Gedigian et al (2006) note that 90% of uses of aset of verbs of spatial motion, manipulation, and health in a Wall Street Journal corpuswere metaphorical.
Some metaphor examples arising in past RTE datasets are the Tsin T/H pairs (1?4), with human judgments No, Yes, No and No respectively.
(2) T: The technological triumph known as GPS was incubated in the mind of IvanGetting.H: Ivan Getting invented the GPS.
(3) T: Convinced that pro-American officials are in the ascendancy in Tokyo, theytalk about turning Japan into the Britain of the Far East.H: Britain is located in the Far East.
(4) T: Even today, within the deepest recesses of our mind, lies a primordial fearthat will not allow us to enter the sea without thinking about the possibility ofbeing attacked by a shark.H: A shark attacked a human being.Importantly, metaphor is often not just a matter of particular terms with particularmetaphorical senses that are entrenched (i.e., that are commonly used, default senses;and possibly listed in dictionaries).
Certainly the metaphorical senses of ?capital?
and?incubate?
used in (1) and (2) are at least moderately entrenched.
For ?incubate,?Textual Entailment as an Evaluation Framework for Metaphor Resolution 359some dictionaries list a slow, protective sense of development (in a general, possiblynon-physical sense), or for ?capital?
a sense like ?a city [or place more generally]preeminent in some special activity?
[Merriam-Websters].
But (3) shows one commontype of non-entrenchedmetaphor, of the general form ?the X of Y?, where X and/or Yare often named entities.
The point of such a metaphor is typically only clear with thehelp of context.
Reference to recesses of a mind as in (4) is common, and a lexiconcould reasonably include a metaphorical sense of ?recess?
that was directly applicableto minds (though WordNet 3.0, e.g, does not), or include ?within the recesses of [X?s]mind?
as a stock phrase with a sense of relative inaccessibility or unmodifiability ofa thought or feeling.
But the phraseology can be productively varied: e.g., ?deepest?can be omitted or replaced by ?dim?, ?darkest?, ?foulest?, ?hidden?, etc.
?
by anycompatible qualifier that emphasizes hiddenness or obstacles to accessibility.
And thefact that such access difficulties are being emphasized is a matter for general semanticreasoning about the qualifier.2 Why Metaphor in NLP?Generally, in metaphor understanding research, a specialized system has been fed arelatively small number of metaphorical inputs, and the correct outputs have beendictated by the researcher, (e.g.
Fass, 1997; Falkenhainer et al, 1989; Martin, 1990;Barnden et al, 2003).
However, metaphor in particular and figurative language ingeneral suffers a chronic lack of shared resources for proper evaluation of systems(Markert and Nissim, 2007).
In using the RTE evaluation framework, computationalmetaphor researchers may for the first time have sizable, shared datasets, and a uni-form evaluation method based on systematically and transparently collected humanjudgments.
Also, metaphor researchers will be challenged and inspired to connectmetaphor more than before to other complex linguistic phenomena.NLP applications that RTE serves have mostly not addressed metaphor, and nei-ther have RTE systems themselves.
Indeed, despite examples (1-4), RTE datasetshave tended to avoid metaphor of more difficult types.
Metaphor in general can in-troduce additional context-sensitivity and indeterminacy in entailment, whereas RTEChallenges have mainly concentrated on T/H pairs supporting relatively crisp, uncon-troversial judgments (Zaenen et al (2005); RTE organizers (personal communication);our own analysis of existing RTE datasets in Tech.
Rept.
CSRP-08-01, 2008).
In fact,on examples such as (1), a system must interpret ?capital?
metaphorically, but as Bosand Markert (2006) reported, the inability of their system to process metaphor meantthat it was incorrect on this example.Further evidence is given by results on example (1) of the four RTE-1 systems avail-able to us (out of 16 systems; the 4 include the 1st, 3rd and 4th best systems in terms ofaccuracy over whole dataset).
Only one reported system run was correct.
The systemsmostly performed worse across (1) together with 10 other metaphor cases than on thewhole dataset, with statistical significance at 0.05 level (Fisher?s independence test);only one system run gave a better performance.
In RTE-2 (23 systems), analysis of10 system runs shows that, across 9 metaphorical examples in the dataset, the systems(including the most accurate one over the whole dataset) performed worse than theydid over the rest of the dataset; in 7 of the 10 RTE-2 runs compared the deficit wasstatistically significant at < 0.05 level (Fisher?s test, see Tech Rept.
CSRP-08-01).360 Agerri, Barnden, Lee, and Wallington3 RoadMap: Datasets and Metaphor ProcessingOur initiative mainly consists of (A): Create a public, annotated, metaphor-focussedtext dataset suitable for RTE evaluation and testing of metaphor processing systems;and (B): Develop a prototype RTE system centred on processing (at least) the typesof metaphor arising in (A).
We will mainly address point (B) in this paper.
As forA, metaphors vary along several dimensions of interest, such as: the target subjectmatter (e.g., Lyon?s food, GPS development, Japanese foreign politics, shark fear inexamples 1?4); the source subject matter; what particular, familiar metaphorical views(e.g., Idea as Living Being, in (2)) are used; whether the meaning in context is listedin dictionaries, WordNet, etc; whether the wording is (a variant of) a familiar idiom;the syntax used.
Based on such dimensions, we will analyse the types of metaphorpresent in past RTE datasets and in the genres of text (e.g., newspapers) they drewfrom.
One particular source will be the 242K-word metaphor-orientated corpus thatwe derived from the British National Corpus.
To find metaphor examples elsewhere,we will use known metaphorical phrases and lexical/syntactic templates as seeds forautomated search over general corpora or web.
We will also investigate the use oradaptation of other researchers?
automated detection/mining techniques (e.g.
Birkeand Sarkar, 2006; Gedigian et al, 2006).4 Metaphor ProcessingWe will develop metaphor processing algorithms on an integrated spectrum goingfrom relatively ?shallow?
forms of processing to relatively ?deep?
forms.
The deeperare for when more inference is necessary and feasible; when less necessary or feasible,the shallower are appropriate (but they can still involve at least partial parsing, approx-imate semantic analysis, etc.).
A significant research issue will be how to choose theattempted depth(s) of analysis and how to choose or combine different methods?
re-sults.
The deeper and shallower ends of the spectrum will take as starting points ourtwo previous metaphor-understanding approaches, from our ATT-Meta and E-Dramaprojects respectively (Barnden et al, 2003; Wallington et al, 2008).For detectingmetaphor, we can extendmethods from our E-drama project (Walling-ton et al, 2008).
This involves a mixture of light semantic analysis via tools such asWordNet and recognition of lexical and syntactic signals of metaphoricity (Goatly,1997).
We aim also to recognize specific idiomatic phrases and systematic variationsof them.
We will consider looking for semantic restriction violations, which some-times accompany metaphor (cf.
Fass (1997) and Mason (2004)), and using statisticaltechniques borrowed from such work as Gedigian et al (2006).Example (4) about ?recesses?
is similar to metaphor examples studied in the ATT-Meta project, and ATT-Meta-style reasoning could handle the Text.
As for (2), notethat the word ?incubate?
may have a directly usable lexicon-listed meaning (e.g., helpto develop much as in WordNet 3.0).
However, if the system?s lexicon did not containsuch a sense, ATT-Meta-style processing would apply.
ATT-Meta processing wouldinvolve commonsense reasoning in source-domain terms (here, biological and otherphysical terms): e.g., to infer that the idea was a living being, Getting?s mind wasa physical region, the idea was kept warm in that region, and the idea consequentlybiologically developed there.
Hence, there was a relatively protracted, continuousTextual Entailment as an Evaluation Framework for Metaphor Resolution 361process; the idea became more functional as a living being; and the idea needed pro-tection from physical harm (= disenablement of function-inhibiting influences).
Thesedefault conclusions can then be translated into reality (target-based) terms: there wasa protracted, (non-physical) continuous process of change; the idea needed protectionduring it; and the idea ended up being more functional.
The basis for such translationis View-Neutral Mapping Adjuncts, a special type of mappings that cover the shapeof events and processes, temporal properties and relationships, causation, functioning,mental states, emotional states, value judgments and various other matters (Agerriet al, 2007; Barnden et al, 2003).RTE-2 organisers claimed there has been a trend towards using more deep inferenceand that this has been beneficial provided that it is based on enough knowledge.
(Seealso Bos and Markert (2006) and Clark et al (2007)).
The depth and knowledge needsof ATT-Meta?s processing are like those of deeper parts of existing RTE systems, butATT-Meta is currently equipped only with small, hand-constructed knowledge bases.So, our main focus in deeper processing will actually be on a shallowed, broadenedform of ATT-Meta-style reasoning.
In this sense, we aim to look at common-senseknowledge resources such as ConceptNet 3.0 which contains relationships such ascausation, function, etc.
?
the types of information transferred by some of ATT-Meta?s VNMAs ?
or modified WordNets enriched by extra, web-mined knowledge(Veale and Hao, 2008), where the extra knowledge is especially relevant to metaphor-ical usages.ATT-Meta?s reasoning is by backwards chaining from goals derivable from contextsurrounding a metaphor.
This relevance-based inference-focussingwill be key in otherprocessing we develop, and is highly RTE-compatible.
An RTE Hypothesis can act as(part of) a reasoning goal, with the metaphor?s within-Text context supplying furtherinformation or goal parts.
T?s own original context is of course unavailable, but thisobstacle faces human judges as well.We will also further extend our E-Drama project?s methods, based there on robustparsing using the Rasp system and computation over WordNet.
The methods are cur-rently largely confined to metaphors of ?X is Y?
form where X is a person and Yis some type of animal, supernatural being, artefact or natural physical object.
Wewill generalize to other categories for X and Y, and to cases where the categorizationis only implicit.
We will make the syntactic/semantic analysis of WordNet synset-glosses and the way the system traverses the network more advanced.
We will extendour associated treatment of metaphorically-used size adjectives (as in ?little bully?
).However, the methods are also currently confined to detecting emotional/valuejudgments about X (unpleasantness, etc.
), and mainly exploit metaphorical informa-tion that is already implicitly in WordNet, e.g., ?pig?
meaning a coarse, obnoxiousperson, in one synset.
Substantial research is needed to go beyond these limitations.One avenue will be to apply VNMAs: when a synset gloss couches a metaphoricalsense, we could extract not just affect but other types of information that VNMAshandle (causation, process shape, etc.
); and when a gloss couches a non-metaphoricalsense, we could translate some aspects of it via VNMAs.362 Agerri, Barnden, Lee, and Wallington5 Concluding RemarksThis paper aims to provide an avenue for giving metaphor-understanding the promi-nence it merits in NLP applications and in RTE, and thereby also to engender basicand applied research advances on metaphor by ourselves and others.RTE researchers and NLP applications developers will benefit, as systems will gainadded accuracy and coverage by addressing metaphor.
Beneficiary application areasaside from QA, IR, etc., include Knowledge Management, Information Access, andintelligent conversation agents.ReferencesAgerri, R., J. Barnden, M. Lee, and A. Wallington (2007).
Metaphor, inference anddomain independent mappings.
In Proceedings of Research Advances in NaturalLanguage Processing (RANLP 2007), Borovets, Bulgaria, pp.
17?24.Barnden, J., S. Glasbey, M. Lee, and A. Wallington (2003).
Domain-transcendingmappings in a system for metaphorical reasoning.
In Companion Proceedings ofthe 10th Conference on the European Chapter of the Association for ComputationalLinguistics (EACL-03), pp.
57?61.Birke, J. and A. Sarkar (2006).
A clustering approach for the nearly unsupervisedrecognition of nonliteral language.
In Proceedings of the 11th Conference on theEuropean Chapter of the Association for Computational Linguistics (EACL 2006),Trento, Italy, pp.
329?336.Bos, J. and K. Markert (2006).
Recognizing textual entailment with robust logicalinference.
In J. Qui?onero-Candela, I. Dagan, B. Magnini, and F. d?Alch?
Buc(Eds.
), MLCW 2005, Volume 3944 of LNAI, pp.
404?426.
Springer-Verlag.Clark, P., W. Murray, J. Thompson, P. Harrison, J. Hobbs, and C. Fellbaum (2007).
Onthe role of lexical and world knowledge in RTE3.
In Proceedings of the Workshopon Textual Entailment and Paraphrasing, Prague, pp.
54?59.
ACL 2007.Dagan, I., O. Glickman, and B. Magnini (2007).
The PASCAL Recognising Tex-tual Entailment challenge.
In J. Qui?onero-Candela, I. Dagan, B. Magnini, andF.
d?Alch?
Buc (Eds.
), MLCW 2005, Volume 3944 of LNAI, pp.
177?190.
Springer-Verlag.Falkenhainer, B., K. Forbus, and D. Gentner (1989).
The structure-mapping engine:algorithm and examples.
Artificial Intelligence 41(1), 1?63.Fass, D. (1997).
Processing metaphor and metonymy.
Greenwich, Connecticut:Ablex.Gedigian, M., J. Bryant, S. Narayanan, and B. Ciric (2006).
Catching metaphors.
InProceedings of the 3rd Workshop on Scalable Natural Language Understanding,New York, pp.
41?48.Goatly, A.
(1997).
The Language of Metaphors.
Routledge.Textual Entailment as an Evaluation Framework for Metaphor Resolution 363Markert, K. and M. Nissim (2007, June).
Semeval-2007: Metonymy resolution atsemeval-2007.
In International Workshop on Semantic Evaluations (SemEval-2007), Prague, pp.
36?41.
Association for Computational Linguistics (ACL-07).Martin, J.
(1990).
A computational model of metaphor interpretation.
New York:Academic Press.Mason, Z.
(2004).
CorMet: a computational, corpus-based conventional metaphorextraction system.
Computational Linguistics 30(1), 23?44.Veale, T. and Y. Hao (2008).
EnrichingWordNet with folk knowledge and stereotypes.In Proceedings of the 4th Global WordNet Conference, Szeged, Hungary.Wallington, A., R. Agerri, J. Barnden, M. Lee, and T. Rumbell (2008, May).
Affecttransfer by metaphor for an intelligent conversational agent.
In Proceedings of theLREC 2008 Workshop on Sentiment Analysis: Emotion, Metaphor, Ontology andTerminology (EMOT 08), Marrakech, Morocco, pp.
102?107.Zaenen, A., L. Karttunen, and R. Crouch (2005).
Local textual inference: Can it bedefined or circumscribed?
In Proceedings of the ACL 05 Workshop on EmpiricalModelling of Semantic Equivalence and Entailment, pp.
31?36.
