Proceedings of NAACL-HLT 2013, pages 777?782,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsDistant Supervision for Relation Extractionwith an Incomplete Knowledge BaseBonan Min, Ralph Grishman, Li WanNew York UniversityNew York, NY 10003{min,grishman,wanli}@cs.nyu.eduChang Wang, David GondekIBM T. J. Watson Research CenterYorktown Heights, NY 10598{wangchan,dgondek}@us.ibm.comAbstractDistant supervision, heuristically labeling acorpus using a knowledge base, has emergedas a popular choice for training relation ex-tractors.
In this paper, we show that a sig-nificant number of ?negative?
examples gen-erated by the labeling process are false neg-atives because the knowledge base is incom-plete.
Therefore the heuristic for generatingnegative examples has a serious flaw.
Buildingon a state-of-the-art distantly-supervised ex-traction algorithm, we proposed an algorithmthat learns from only positive and unlabeledlabels at the pair-of-entity level.
Experimentalresults demonstrate its advantage over existingalgorithms.1 IntroductionRelation Extraction is a well-studied problem(Miller et al 2000; Zhou et al 2005; Kambhatla,2004; Min et al 2012a).
Recently, Distant Super-vision (DS) (Craven and Kumlien, 1999; Mintz etal., 2009) has emerged to be a popular choice fortraining relation extractors without using manuallylabeled data.
It automatically generates training ex-amples by labeling relation mentions1 in the sourcecorpus according to whether the argument pair islisted in the target relational tables in a knowledgebase (KB).
This method significantly reduces humanefforts for relation extraction.The labeling heuristic has a serious flaw.
Knowl-edge bases are usually highly incomplete.
For exam-1An occurrence of a pair of entities with the source sentence.ple, 93.8% of persons from Freebase2 have no placeof birth, and 78.5% have no nationality (section 3).Previous work typically assumes that if the argumententity pair is not listed in the KB as having a re-lation, all the corresponding relation mentions areconsidered negative examples.3 This crude assump-tion labeled many entity pairs as negative when infact some of their mentions express a relation.
Thenumber of such false negative matches even exceedsthe number of positive pairs, by 3 to 10 times, lead-ing to a significant problem for training.
Previousapproaches (Riedel et al 2010; Hoffmann et al2011; Surdeanu et al 2012) bypassed this problemby heavily under-sampling the ?negative?
class.We instead deal with a learning scenario where weonly have entity-pair level labels that are either posi-tive or unlabeled.
We proposed an extension to Sur-deanu et al(2012) that can train on this dataset.
Ourcontribution also includes an analysis on the incom-pleteness of Freebase and the false negative matchrate in two datasets of labeled examples generatedby DS.
Experimental results on a realistic and chal-lenging dataset demonstrate the advantage of the al-gorithm over existing solutions.2 Related WorkDistant supervision was first proposed by Cravenand Kumlien (1999) in the biomedical domain.2Freebase is a large collaboratively-edited KB.
It is availableat http://www.freebase.com.3There are variants of labeling heuristics.
For example, Sur-deanu et al(2011) and Sun et al(2011) use a pair < e, v >as a negative example, when it is not listed in Freebase, but e islisted with a different v?.
These assumptions are also problem-atic in cases where the relation is not functional.777Since then, it has gain popularity (Mintz et al 2009;Bunescu and Mooney, 2007; Wu and Weld, 2007;Riedel et al 2010; Hoffmann et al 2011; Sur-deanu et al 2012; Nguyen and Moschitti, 2011).To tolerate noisy labels in positive examples, Riedelet al(2010) use Multiple Instance Learning (MIL),which assumes only at-least-one of the relation men-tions in each ?bag?
of mentions sharing a pair of ar-gument entities which bears a relation, indeed ex-presses the target relation.
MultiR (Hoffmann etal., 2011) and Multi-Instance Multi-Label (MIML)learning (Surdeanu et al 2012) further improve itto support multiple relations expressed by differentsentences in a bag.
Takamatsu et al(2012) mod-els the probabilities of a pattern showing relations,estimated from the heuristically labeled dataset.Their algorithm removes mentions that match low-probability patterns.
Sun et al(2011) and Min etal.
(2012b) also estimate the probablities of patternsshowing relations, but instead use them to relabel ex-amples to their most likely classes.
Their approachcan correct highly-confident false negative matches.3 Problem DefinitionDistant Supervision: Given a KB D (a collectionof relational tables r(e1, e2), in which r?R (R is theset of relation labels), and < e1, e2 > is a pair ofentities that is known to have relation r) and a cor-pus C, the key idea of distant supervision is that wealign D to C, label each bag4 of relation mentionsthat share argument pair < e1, e2 > with r, other-wise OTHER.
This generates a dataset that has labelson entity-pair (bag) level.
Then a relation extractoris trained with single-instance learning (by assum-ing all mentions have the same label as the bag), orMultiple-Instance Learning (by assuming at-least-one of the mentions expresses the bag-level label),or Multi-Instance Multi-Label learning (further as-suming a bag can have multiple labels) algorithms.All of these works treat the OTHER class as exam-ples that are labeled as negative.The incomplete KB problem: KBs are usuallyincomplete because they are manually constructed,and it is not possible to cover all human knowledge4A bag is defined as a set of relation mentions sharing thesame entity pair as relation arguments.
We will use the termsbag and entity pair interchangeably in this paper.nor stay current.
We took frequent relations, whichinvolve an entity of type PERSON, from Freebasefor analysis.
We define the incompleteness ?
(r) of arelation r as follows:?
(r) = |{e}|?|{e|?e?,s.t.r(e,e?)?D}||{e}|?
(r) is the percentage of all persons {e} that donot have an attribute e?
(with which r(e, e?)
holds).Table 1 shows that 93.8% of persons have no placeof birth, and 78.5% of them have no nationality.These are must-have attributes for a person.
Thisshows that Freebase is highly incomplete.Freebase relation types Incompleteness/people/person/education 0.792/people/person/employment history 0.923/people/person/nationality* 0.785/people/person/parents* 0.988/people/person/place of birth* 0.938/people/person/places lived* 0.966Table 1: The incompleteness of Freebase (* are must-have attributes for a person).We further investigate the rate of false negativematches, as the percentage of entity-pairs that arenot listed in Freebase but one of its mentions gen-erated by DS does express a relation in the tar-get set of types.
We randomly picked 200 unla-beled bags5 from each of the two datasets (Riedelet al 2010; Surdeanu et al 2012) generated by DS,and we manually annotate all relation mentions inthese bags.
The result is shown in Table 2, alongwith a few examples that indicate a relation holds inthe set of false negative matches (bag-level).
Bothdatasets have around 10% false negative matches inthe unlabeled set of bags.
Taking into considera-tion that the number of positive bags and unlabeledbags are highly imbalanced (1:134 and 1:37 in theRiedel and KBP dataset respectively, before under-sampling the unlabeled class), the number of falsenegative matches are 11 and 4 times the numberof positive bags in Reidel and KBP dataset, respec-tively.
Such a large ratio shows false negatives dohave a significant impact on the learning process.4 A semi-supervised MIML algorithmOur goal is to model the bag-level label noise,caused by the incomplete KB problem, in addition585% and 95.7% of the bags in the Riedel and KBP datasetshave only one relation mention.778Dataset(train-ing)# pos-itivebags# positive :# unlabeled% arefalsenegatives# positive: # falsenegativehas humanassessmentExamples of false negative mentionsRiedel 4,700 1:134(BD*) 8.5% 1:11.4 no(/location/location/contains)... in Brooklyn ?s Williamsburg.
(/people/person/place lived) Cheryl Rogowski , a farmer fromOrange County ...KBP 183,062 1:37(BD*) 11.5% 1:4 yes(per:city of birth) Juan Martn Maldacena (born September10, 1968) is a theoretical physicist born in Buenos Aires(per:employee of)Dave Matthews, from the ABC News, ...Table 2: False negative matches on the Riedel (Riedel et al 2010) and KBP dataset (Surdeanu et al 2012).
Allnumbers are on bag (pairs of entities) level.
BD* are the numbers before downsampling the negative set to 10% and5% in Riedel and KBP dataset, respectively.to modeling the instance-level noise using a 3-layerMIL or MIML model (e.g., Surdeanu et al(2012)).We propose a 4-layer model as shown in Figure 1.The input to the model is a list of n bags with avector of binary labels, either Positive (P), or Un-labled (U) for each relation r. Our model can beviewed as a semi-supervised6 framework that ex-tends a state-of-the-art Multi-Instance Multi-Label(MIML) model (Surdeanu et al 2012).
Since theinput to previous MIML models are bags with per-relation binary labels of either Positive (P) or Neg-ative (N), we add a set of latent variables ?
whichmodels the true bag-level labels, to bridge the ob-served bag labels y and the MIML layers.
We con-sider this as our main contribution to the model.
Ourhierarchical model is shown in Figure 1.Figure 1: Plate diagram of our model.Let i, j be the index in the bag and mention level,respectively.
Following Surdeanu et al(2012), wemodel mention-level extraction p(zrij |xij ;wz) andmulti-instance multi-label aggregation p(?ri |zi;wr?
)in the bottom 3 layers.
We define:?
r is a relation label.
r?R ?
{OTHER}, inwhich OTHER denotes no relation expressed.?
yri ?
{P,U}: r holds for ith bag or the bag isunlabeled.6We use the term semi-supervised because the algorithmuses unlabeled bags but existing solutions requires bags to belabeled either positive or negative.?
?ri ?
{P,N}: a hidden variable that denoteswhether r holds for the ith bag.?
?
is an observed constant controlling the totalnumber of bags whose latent label is positive.We define the following conditional probabilities:?
p(yri |?ri ) =??????
?1/2 if yri = P ?
?ri = P ;1/2 if yri = U ?
?ri = P ;1 if yri = U ?
?ri = N ;0 otherwise ;It encodes the constraints between true bag-level labels and the entity pair labels in the KB.?
p(?|?)
?
N (?ni=1?r?R ?
(?ri ,P )n , 1k ) where?
(x, y) = 1 if x = y, 0 otherwise.
k is a largenumber.
?
is the fraction of the bags that arepositive.
It is an observed parameter that de-pends on both the source corpus and the KBused.Similar to Surdeanu et al(2012), we also definethe following parameters and conditional probabili-ties (details are in Surdeanu et al(2012)):?
zij?R ?
{OTHER}: a latent variable that de-notes the relation type of the jth mention in theith bag.?
xij is the feature representation of the jth rela-tion mention in the ith bag.
We use the set offeatures in Surdeanu et al(2012).?
wz is the weight vector for the multi-class rela-tion mention-level classifier.?
wr?
is the weight vector for the rth binary top-level aggregation classifier (from mention la-bels to bag-level prediction).
We usew?
to rep-resent w1?
,w2?
, ...w|R|?
.?
p(?ri |zi;wr?)
?
Bern(f?(wr?
, zi)) where f?
isprobability produced by the rth top-level clas-sifier, from the mention-label level to the bag-label level.?
p(zrij |xij ;wz) ?
Multi(fz(wz,xij)) where fz779is probability produced by the mention-levelclassifier, from the mentions to the mention-label level.74.1 TrainingWe use hard Expectation-Maximization (EM) algo-rithm for training the model.
Our objective functionis to maximize log-likelihood:L(wz,w?)
= logp(y, ?|x;wz,w?
)= log?
?p(y, ?, ?|x;wz,w?
)Since solving it exactly involves exploring an expo-nential assignment space for ?, we approximate anditeratively set ??
= arg?
max p(?|y, ?,x;wz,w?
)p(?|y, ?,x;wz,w?)
?
p(y, ?, ?|x;wz,w?
)= p(y, ?|?,x)p(?|x;wz,w?
)= p(y|?)p(?|?)p(?|x;wz,w?
)Rewriting in log form:logp(?|y, ?,x;wz,w?
)= logp(y|?)
+ logp(?|?)
+ logp(?|x;wz,w?
)=n?i=1?r?Rlogp(yri |?ri )?
k(n?i=1?r?R?
(?ri , P )n ?
?
)2+n?i=1?r?Rlogp(?ri |xi;wz,w?)
+ constAlgorithm 1 Training (E-step:2-11; M-step:12-15)1: for i = 1, 2 to T do2: ?ri ?
N for all yri = U and r?R3: ?ri ?
P for all yri = P and r?R4: I = {< i, r > |?ri = N}; I ?
= {< i, r > |?ri = P}5: for k = 0, 1 to ?n?
|I ?| do6: < i?, r?
>= argmax<i,r>?I p(?ri |xi;wz,w?
)7: ?r?i?
?
P ; I = I\{< i?, r?
>}8: end for9: for i = 1, 2 to n do10: z?i = argmaxzi p(zi|?i,xi;wz,w?
)11: end for12: w?z = argmaxwz?ni=1?|xi|j=1 logp(zij |xij ,wz)13: for all r?R do14: wr(?)?
= argmaxwr?
?ni=1 p(?ri |zi,wr?
)15: end for16: end for17: return wz,w?7All classifiers are implemented with L2-regularized logisticregression with Stanford CoreNLP package.In the E-step, we do a greedy search (steps 5-8in algorithm 1) in all p(?ri |xi;wz,w?)
and update ?riuntil the second term is maximized.
wz , w?
are themodel weights learned from the previous iteration.After fixed ?, we seek to maximize:logp(?|xi;wz,w?)
=n?i=1logp(?i|xi;wz,w?
)=n?i=1log?zip(?i, zi|xi;wz,w?
)which can be solved with an approxi-mate solution in Surdeanu et al(2012)(step 9-11): update zi independently with:z?i = argmaxzi p(zi|?i,xi;wz,w?).
More detailscan be found in Surdeanu et al(2012).In the M-step, we retrain both of the mention-level and the aggregation level classifiers.The full EM algorithm is shown in algorithm 1.4.2 InferenceInference on a bag xi is trivial.
For each mention:z?ij = argzij?R?
{OTHER} max p(zij |xij ,wz)Followed by the aggregation (directly with w?):yr(?
)i = argyri ?
{P,N} max p(yri |zi;wr?
)4.3 Implementation detailsWe implement our model on top of theMIML(Surdeanu et al 2012) code base.8 Weuse the same mention-level and aggregate-levelfeature sets as Surdeanu et al(2012).
We adoptthe same idea of using cross validation for the Eand M steps to avoid overfitting.
We initialize ouralgorithm by sampling 5% unlabeled examples asnegative, in essence using 1 epoch of MIML toinitialize.
Empirically it performs well.5 ExperimentsData set: We use the KBP (Ji et al 2011)dataset9 prepared and publicly released by Surdeanuet al(2012) for our experiment since it is 1) largeand realistic, 2) publicly available, 3) most im-portantly, it is the only dataset that has associatedhuman-labeled ground truth.
Any KB held-out eval-uation without manual assessment will be signif-icantly affected by KB incompleteness.
In KBP8Available at http://nlp.stanford.edu/software/mimlre.shtml9Available from Linguistic Data Consortium (LDC).http://projects.ldc.upenn.edu/kbp/data/780Figure 2: Performance on the KBP dataset.
The figures on the left, middle and right show MIML, Hoffmann, andMintz++ compared to the same MIML-Semi curve, respectively.
MIML-Semi is shown in red curves (lighter curves inblack and white) while other algorithms are shown in black curves (darker curves in black and white).dataset, the training bags are generated by mappingWikipedia (http://en.wikipedia.org) infoboxes (aftermerging similar types following the KBP 2011 taskdefinition) into a large unlabeled corpus (consistingof 1.5M documents from the KBP source corpus anda complete snapshot of Wikipedia).
The KBP sharedtask provided 200 query named entities with their as-sociated slot values (in total several thousand pairs).We use 40 queries as development dataset (dev), andthe rest (160 queries) as evaluation dataset.
We set?
= 0.25 by tuning on the dev set and use it in theexperiments.
For a fair comparison, we follow Sur-deanu et al(2012) and begin by downsampling the?negative?
class to 5%.
We also set T=8 and usethe following noisy-or (for ith bag) of mention-levelprobability to rank predicted types (r) of pairs andplot the precision-recall curves for all experiments.Probi(r) = 1??j(1?
p(zij = r|xij ;wz))Evaluation: We compare our algorithm (MIML-semi) to three algorithms: 1) MIML (Surdeanu etal., 2012), the Multiple-Instance Multiple Label al-gorithm which labels the bags directly with the KB(y = ?).
2) MultiR (denoted as Hoffmann) (Hoff-mann et al 2011), a Multiple-Instance algorithmthat supports overlapping relations.
It also imposesy = ?.
3) Mintz++ (Surdeanu et al 2012), a vari-ant of the single-instance learning algorithm (section3).
The first two are stat-of-the-art Multi-InstanceMulti-Label algorithms.
Mintz++ is a strong base-line (Surdeanu et al 2012) and an improved ver-sion of Mintz et al(2009).
Figure 2 shows thatour algorithm consistently outperforms all three al-gorithms at almost all recall levels (with the excep-tion of a very small region in the PR-curve).
Thisdemonstrates that by treating unla-beled data set dif-ferently and leveraging the missing positive bags,MIML-semi is able to learn a more accurate modelfor extraction.
Although the proposed solution is aspecific algorithm, we believe the idea of treatingunlabeled data differently can be incorporated intoany of these algorithms that only use unlabeled dataas negative examples.6 ConclusionWe show that the distant-supervision labeling pro-cess generates a significant number of false nega-tives because the knowledge base is incomplete.
Weproposed an algorithm that learns from only positiveand unlabeled bags.
Experimental results demon-strate its advantage over existing algorithms.AcknowledgmentsSupported in part by the Intelligence Advanced Re-search Projects Activity (IARPA) via Department ofInterior National Business Center contract numberD11PC20154.
The U.S. Government is authorizedto reproduce and distribute reprints for Governmen-tal purposes notwithstanding any copyright annota-tion thereon.
The views and conclusions containedherein are those of the authors and should not beinterpreted as necessarily representing the officialpolicies or endorsements, either expressed or im-plied, of IARPA, DoI/NBC, or the U.S. Government.781ReferencesRazvan Bunescu and Raymond Mooney.
2007.
Learningto extract relations from the web using minimal super-vision.
In Proceedings of the 45th Annual Meeting ofthe Association for Computational Linguistics.Mark Craven and Johan Kumlien.
1999.
Constructing bi-ological knowledge bases by extracting informationfrom text sources.
In Proceedings of the Seventh Inter-national Conference on Intelligent Systems for Molec-ular Biology.Raphael Hoffmann, Congle Zhang, Xiao Ling, LukeZettlemoyer, and Daniel S. Weld.
2011.
Knowledge-based weak supervision for information extraction ofoverlapping relations.
In Proceedings of the AnnualMeeting of the Association for Computational Linguis-tics.Heng Ji, Ralph Grishman, and Hoa T. Dang.
2011.Overview of the TAC 2011 knowledge base popula-tion track.
In Proceedings of the Text Analytics Con-ference.Jing Jiang and ChengXiang Zhai.
2007.
A systematic ex-ploration of the feature space for relation extraction.
InProceedings of HLT-NAACL-2007.Nanda Kambhatla.
2004.
Combining lexical, syntactic,and semantic features with maximum entropy mod-els for information extraction.
In Proceedings of ACL-2004.Scott Miller, Heidi Fox, Lance Ramshaw, and RalphWeischedel.
2000.
A novel use of statistical parsingto extract information from text.
In Proceedings ofNAACL-2000.Bonan Min, Shuming Shi, Ralph Grishman and Chin-Yew Lin.
2012a.
Ensemble Semantics for Large-scaleUnsupervised Relation Extraction.
In Proceedings ofEMNLP-CoNLL 2012.Bonan Min, Xiang Li, Ralph Grishman and Ang Sun.2012b.
New York University 2012 System for KBPSlot Filling.
In Proceedings of the Text Analysis Con-ference (TAC) 2012.Mike Mintz, Steven Bills, Rion Snow, and Daniel Juraf-sky.
2009.
Distant supervision for relation extractionwithout labeled data.
In Proceedings of the 47th An-nual Meeting of the Association for ComputationalLinguistics.Truc Vien T. Nguyen and Alessandro Moschitti.
2011.End-to-end relation extraction using distant supervi-sion from external semantic repositories.
In Proceed-ings of the 49th Annual Meeting of the Association forComputational Linguistics: Human Language Tech-nologies.Sebastian Riedel, Limin Yao, and Andrew McCallum.2010.
Modeling relations and their mentions withoutlabeled text.
In Proceedings of the European Confer-ence on Machine Learning and Knowledge Discoveryin Databases (ECML PKDD 10).Ang Sun, Ralph Grishman, Wei Xu, and Bonan Min.2011.
New York University 2011 system for KBP slotfilling.
In Proceedings of the Text Analytics Confer-ence.Mihai Surdeanu, Sonal Gupta, John Bauer, David Mc-Closky, Angel X. Chang, Valentin I. Spitkovsky, andChristopher D. Manning.
2011.
Stanfords distantly-supervised slot-filling system.
In Proceedings of theText Analytics Conference.Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati,Christopher D. Manning.
2012.
Multi-instance Multi-label Learning for Relation Extraction.
In Proceed-ings of the 2012 Conference on Empirical Methods inNatural Language Processing and Natural LanguageLearning.TAC KBP 2011 task definition.
2011. http://nlp.cs.qc.cuny.edu/kbp/2011/KBP2011 TaskDefinition.pdfShingo Takamatsu, Issei Sato, Hiroshi Nakagawa.
2012.ReducingWrong Labels in Distant Supervision for Re-lation Extraction.
In Proceedings of 50th Annual Meet-ing of the Association for Computational Linguistics.Fei Wu and Daniel S. Weld.
2007.
Autonomously seman-tifying wikipedia.
In Proceedings of the InternationalConference on Information and Knowledge Manage-ment (CIKM-2007).Guodong Zhou, Jian Su, Jie Zhang and Min Zhang.
2005.Exploring various knowledge in relation extraction.
InProceedings of ACL-2005.782
