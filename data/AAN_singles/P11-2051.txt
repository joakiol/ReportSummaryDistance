Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 294?298,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsCorpus Expansion for Statistical Machine Translation withSemantic Role Label Substitution RulesQin Gao and Stephan VogelLanguage Technologies Institute, Carnegie Mellon University5000 Forbes AvenuePittsburgh, PA 15213{qing, stephan.vogel}@cs.cmu.eduAbstractWe present an approach of expanding paral-lel corpora for machine translation.
By uti-lizing Semantic role labeling (SRL) on oneside of the language pair, we extract SRL sub-stitution rules from existing parallel corpus.The rules are then used for generating newsentence pairs.
An SVM classifier is built tofilter the generated sentence pairs.
The fil-tered corpus is used for training phrase-basedtranslation models, which can be used directlyin translation tasks or combined with base-line models.
Experimental results on Chinese-English machine translation tasks show an av-erage improvement of 0.45 BLEU and 1.22TER points across 5 different NIST test sets.1 IntroductionStatistical machine translation (SMT) relies on par-allel corpus.
Aside from collecting parallel cor-pus, we have seen interesting research on automat-ically generating corpus from existing resources.Typical examples are paraphrasing using bilingual(Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data.
In this paper, we propose a dif-ferent methodology of generating additional parallelcorpus.
The basic idea of paraphrasing is to find al-ternative ways that convey the same information.In contrast, we propose to build new parallel sen-tences that convey different information, yet retaincorrect grammatical and semantic structures.The basic idea of the proposed method is to sub-stitute source and target phrase pairs in a sentencepair with phrase pairs from other sentences.
Theproblem is how to identify where a substitutionshould happen and which phrase pairs are valid can-didates for the substitution.
While syntactical con-straints have been proven to helpful in identifyinggood paraphrases (Callison-Burch, 2008), it is in-sufficient in our task because it cannot properly filterthe candidates for the replacement.
If we allow allthe NPs to be replaced with other NPs, each sen-tence pair can generate huge number of new sen-tences.
Instead, we resort to Semantic Role Labeling(Palmer et al, 2005) to provide more lexicalized andsemantic constraints to select the candidates.
Themethod only requires running SRL labeling on ei-ther side of the language pair, and that enables ap-plications on low resource languages.
Even with theSRL constraints, the generated corpus may still belarge and noisy.
Hence, we apply an additional fil-tering stage on the generated corpus.
We used anSVM classifier with features derived from standardphrase based translation models and bilingual lan-guage models to identify high quality sentence pairs,and use these sentence pairs in the SMT training.
Inthe remaining part of the paper, we introduce the ap-proach and present experimental results on Chinese-to-English translation tasks, which showed improve-ments across 5 NIST test sets.2 The Proposed ApproachThe objective of the method is to generate new syn-tactically and semantically well-formed parallel sen-tences from existing corpus.
To achieve this, we firstcollect a set of rules as the candidates for the substi-tution.
We also need to know where we should put inthe replacements and whether the resulting sentencepairs are grammatical.First, standard word alignment and phrase extrac-tion are performed on existing corpus.
Afterwards,we apply an SRL labeler on either the source or tar-get language, whichever has a better SRL labeler.Third, we extract SRL substitution rules (SSRs)from the corpus.
The rules carry information of se-mantic frames, semantic roles, and corresponding294.
! !   &12  ,+,2+% ,+ ",  & ,+,1+% ,+ ",.
! %(" #'!% ")"-	%!#"%#/!'!% ")"	 '  &"!%!#"%#%!"!"!%0!#"%" "!"!' ! !/!''  &Figure 1: Examples of extracting SSR and applying themon new sentences.
New phrases that will otherwise not beincluded in the phrase table are shown on the bottom.source and target phrases.
Fourth, we replace phrasepairs in existing sentences with the SSR if they havethe same semantic frames and semantic roles.The newly generated sentence pairs will passthrough a classifier to determine whether they areacceptable parallel sentences.
And, finally, we trainMT system using the new corpus.
The resultingphrase table can either be used directly in translationtasks or be interpolated with baseline phrase tables.3 SRL Substitution RulesSwapping phrase pairs that serve as the same seman-tic role of the same semantic frame can provide morecombinations of words and phrases.
Figure 1 showsan example.
The phrase pair ????????
?Xinjiang?s Yili will hold?
would not be observed inthe original corpus without substitution.
In this pa-per, we call a tuple of semantic frame and semanticrole a semantic signature.
Two phrase pairs with thesame semantic signature are considered valid substi-tutions of each other.The extraction of SSRs is similar to the well-known phrase extraction algorithm (Och and Ney,2004).
The criteria of a phrase pair to be included inthe SSR set are1:?
The phrase on side A must cover a whole se-mantic role constituent, and it must not contain1We call the language which has SRL labels side A, and theother language side B.words in any other semantic role constituent ofthe same frame.?
The phrase on side B must not contain wordsthat link to words not in the phrase on side A.?
Both of the two boundary words on side Bphrases must have at least one link to a wordof the phrases on side A.
The boundary wordson side A phrases can be unaligned only if theyare inside the semantic role constituent.Utilizing these rules, we can perform the sentencegeneration process.
For each semantic structure ofeach sentence,2 we determine the phrase pair to bereplaced by the same criteria as mention above, andsearch for suitable SSRs with the same semantic sig-nature.
Finally, we replace the original phrases withthe source and target side phrases given by the SSRs.Notice that for each new sentence generated, we al-low for application of only one substitution.Although the idea is straightforward, we face twoproblems in practice.
First, for frequent semanticframes, the number of substitution candidates can bevery large.
It will generate many new sentence pairs,and can easily exceed the capacity of our system.To deal with the problem, we pre-filter the SSRs sothat each semantic signature is associated with nomore than 100 SSRs.
As we can see from the cri-teria for extracting SSRs, all the entries in the SSRrule set satisfies the commonly used phrase extrac-tion heuristics.
Therefore, the set of SSRs is a subsetof the phrase table.
Because of this, We use the fea-tures in the phrase table to sort the rules, and keep100 rules with highest the arithmetic mean of thefeature values.The second problem is the phrase boundaries areoften inaccurate.
To handle this problem, we use asimple ?glue?
algorithm during the substitution.
Ifthe inserted phrase has a prefix or suffix sub-phrasethat is the same as the suffix or prefix of the adjacentparts of the original sentence, then the duplicationwill be removed.4 Classification of Generated SentencesWe can expect the generated corpus be noisy, andneeds to be filtered.
In this paper we use an SVMclassifier to perform this task.
First we label a set of2One sentence can have multiple semantic structures.295sentence pairs 3 randomly sampled from the gener-ated data.
We ask the following questions:1.
Are the two sentences grammatical, especiallyon the boundaries of substituted phrase pairs?2.
Are the two sentences still parallel?If both questions have positive answers, we labelthe sentence pair as positive.
We can then use the la-bels together with the features to train the classifier.It is worth mentioning that when we say ?grammat-ical?, we do not care about the validity of the actualmeaning of the sentence.The set of SSR is a subset of the phrase table.Therefore, the features in the phrase table can beused as features.
It includes the bidirectional phraseand lexicon translation probabilities.In addition, we use the language model features.The language model score of the whole sentenceis useless because it is dominated by words not af-fected by the substitution.
Therefore, we only con-sider n-grams that are affected by the substitution.I.e.
only the boundary words are taken into account.Given an n-gram language model, we only calculatethe scores in windows with the size 2n?2, centeredon the boundary of the substituted phrases.
In otherwords, n ?
1 words before and after the boundarieswill be included in the calculation.Finally, there are two additional features: theprobability of observing the source/target phrasegiven the semantic signature.
They can be calculatedby counting the frequencies of source/target phrasesand the semantic signature in extracted rules.As we have abundant sentence pairs generated,we prefer to apply a more harsh filtering, keepingonly the best candidates.
Therefore, when trainingthe SVM model, we intentionally increase the costof false positive errors, so as to maximize the pre-cision rate of positive decisions and reduce possiblecontamination.
In an experiment, we used 900 ofthe 1000 labeled sentence pairs as the training set,and the remaining 100 (41 positive and 59 negativesamples) sentence pairs as the test set.
By setting thecost of false positive errors to 1.33, we classified 20of 41 positive samples correctly, and only 3 of the59 negative samples are classified as positive.3We manually labeled 1000 sentence pairsCorpus Sents.
Words Avg.
Sent.
LenCh En Ch EnBaseline 387K 11.2M 14.7M 28.95 38.19Before-Filter 29.6M 970M 1.30B 32.75 44.08After-Filter 7.2M 239M 306M 32.92 42.16GALE 8.7M 237M 270M 27.00 30.69Table 1: Statistics of generated corpus.5 Utilizing the Generated CorpusWith the generated corpus, we perform training andgenerate a new phrase table.
There are many waysof utilizing the new phrase table; the simplest way isto use it directly for translation tasks.
However, thenew phrase table may be noisier than the originalone.
To solve this, we interpolate the new phrase ta-ble with the baseline phrase table.
If a phrase pair isonly observed in the baseline phrase table, we keepit intact in the interpolated phrase table.
If a phrasepair is observed only in the new phrase table, wediscount all the feature values by a factor of 2.
Andif the phrase pair is in both of the phrase tables, thefeature values will be the arithmetic mean of the cor-responding values in the two phrase tables.We also noticed that the new corpus may havevery different distribution of words comparing to thebaseline corpus.
The word alignment process us-ing generative models is more likely to be affectedby the radical change of distributions.
Therefore,we also experimented with force aligning the gener-ated corpus with the word alignment models trainedbaseline corpus before building the phrase table.6 ExperimentsWe performed experiments on Chinese to EnglishMT tasks with the proposed approach.
The base-line system is trained on the FBIS corpus, the statis-tics of the corpus is shown in Table 1.
We adoptedthe ASSERT English SRL labeler (Pradhan et al,2004), which was trained on PropBank data us-ing SVM classifier.
The labeler reports 81.87%precision and 73.21% recall rate on CoNLL-2005shared task on SRL.
We aligned the parallel sen-tences with MGIZA(Gao and Vogel, 2008), and per-formed experiments with the Moses toolkit (Koehnet al 2007).The rule extraction algorithm produces 1.3 mil-296BLEU scoresmt02 mt03 mt04 mt05 mt08 avgBL 32.02 29.75 33.12 29.83 24.15 n/aGS 31.09 29.39 32.86 29.29 23.57 -0.53IT 32.41 30.70 33.91 30.30 23.80 +0.45GA 32.57 30.13 33.50 30.42 23.87 +0.32IA 32.20 29.62 33.08 29.37 24.09 -0.10LS 32.52 31.67 33.36 31.58 24.81 +1.01TER scores for Full FBIS Corpusmt02 mt03 mt04 mt05 mt08 avgBL 68.94 70.21 66.67 70.35 69.33 n/aGS 69.97 70.22 66.74 70.32 69.96 +0.34IT 68.04 68.52 65.19 68.83 68.80 -1.22GA 67.12 68.38 64.75 67.90 68.37 -1.80IA 68.54 69.88 66.07 70.08 68.98 -0.39LS 68.15 68.56 66.01 68.71 69.37 -0.94Table 2: Experiment results on Chinese-English transla-tion tasks, the abbreviations for systems are as follows:BL: Baseline system, GS: System trained with only gen-erated sentence pairs, IT: Interpolated phrase table withGS and BL,.
GA and IA are GS and IT systems trainedwith baseline word alignment models accordingly.
LS isthe GALE system with 8.7M sentence pairs.lion SSRs.
As we can observe in Table 1, we gener-ated 29.6 million sentences from the 387K sentencepairs, and by using the SVM-based classifier, we fil-ter the corpus down to 7.2 million.
We also observedthat the average sentence length increases by 15% inthe generated corpus.
That is because longer sen-tences have more slots for substitution.
Therefore,they have more occurrences in the generated corpus.We used the NIST MT06 test set for tuning, andexperimented with 5 test sets, including MT02, 03,04, 05, 08.
Table 2 shows the BLEU and TER scoresof the experiments.
As we can see in the results,by using only the generated sentence pairs, the per-formance of the system drops.
However the inter-polated phrase tables outperform the baseline.
Onaverage, the improvements on all the 5 test sets are0.45 on BLEU score and -1.22 on TER when usingthe interpolated phrase table.
We do observe MT08drops on BLEU scores; however, the TER scoresare consistently improved across all the test sets.When using baseline alignment model, we observe aquite different phenomenon.
In this case, interpolat-ing the phrase tables no longer show improvements.However, using the generated corpus alone achievesPT size C.P.
D.S.
N.S.
T/S A.L.BL 30.0M 100% 12.5M 0 2.40 1.46GS 78.6M 46% 35.4M 28.2M 2.22 1.49IT 94.6M 100% 40.7M 28.2M 2.32 1.56GA 79.4M 56% 35.5M 27.7M 2.24 1.54IA 92.7M 100% 40.2M 27.7M 2.30 1.52LS 352M 55% 147.2M 142.7M 2.40 1.63Table 3: Statistics of phrase tables and translation out-puts, including the phrase tables (PT) size, the coverageof the BL phrase table entries (C.P.
), the number of sourcephrases (D.S.
), the number of new source phrases com-paring to BL system (N.S.
), the average number of alter-native translations of each source phrase (T/S) and theaverage source phrase length in the output (A.L.
)-1.80 on average TER.
An explanation is that us-ing identical alignment model makes the phrases ex-tracted from the baseline and generated corpus sim-ilar, which undermines the idea of interpolating twophrase tables.
As shown in Table 3, it generates lessnew source phrases and 10% more phrase pairs thatoverlaps with the baseline phrase table.
For com-parison, we also provide scores from a system thatuses the training data for GALE project, which has8.7M sentence pairs4.
In Table 3 we observe thatthe large GALE system yields better BLEU resultswhile the IT or GA systems have even better TERscores than the GALE system.
The expanded cor-pus performs almost as well as the GALE systemeven though the large system has a phrase table thatis four time larger.The statistics of the phrase tables and translationoutputs are listed in Table 3.
As we can see, thegenerated sentence introduces a large number of newsource phrases and the average lengths of matchingsource phrases of all the systems are longer than thebaseline, which could be an evidence for our claimthat the proposed approach can generate more highquality sentences and phrase pairs that have not beenobserved in the original corpus.7 ConclusionIn this paper we explore a novel way of generatingnew parallel corpus from existing SRL labeled cor-pus.
By extracting SRL substitution rules (SSRs) wegenerate a large set of sentence pairs, and by apply-ing an SVM-based classifier we can filter the corpus,4FBIS corpus is included in the GALE dataset297keeping only grammatical sentence pairs.
By inter-polating the phrase table with the baseline phrase ta-ble, we observed improvement on Chinese-Englishmachine translation tasks and the performance iscomparable to system trained with larger manuallycollected parallel corpus.
While our experimentswere performed on Chinese-English, the approach ismore useful for low resource languages.
The advan-tage of the proposed method is that we only need theSRL labels on either side of the language pair, andwe can choose the one with a better SRL labeler.The features we used in the paper are still prim-itive, which results in a classifier radically tunedagainst false positive rate.
This can be improved bydesigning more informative features.Since the method will only introduce new phrasesacross the phrase boundaries of phrases in existingphrase table, it is desirable to be integrated withother paraphrasing approaches to further increasethe coverage of the generated corpus.ReferencesChris Callison-Burch, Philipp Koehn, and Miles Os-borne.
2006.
Improved statistical machine translationusing paraphrases.
In Proceedings of the main con-ference on Human Language Technology Conferenceof the North American Chapter of the Association ofComputational Linguistics, HLT-NAACL ?06, pages17?24.Chris Callison-Burch.
2008.
Syntactic constraintson paraphrases extracted from parallel corpora.
InProceedings of the Conference on Empirical Meth-ods in Natural Language Processing, EMNLP ?08,pages 196?205, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Qin Gao and Stephan Vogel.
2008.
Parallel implemen-tations of word alignment tool.
In Software Engi-neering, Testing, and Quality Assurance for NaturalLanguage Processing, pages 49?57, Columbus, Ohio,June.
Association for Computational Linguistics.Philipp Koehn et al 2007.
Moses: Open source toolkitfor statistical machine translation.
In Proceedings ofthe 45th Annual Meeting of the Association for Com-putational Linguistics Companion Volume Proceed-ings of the Demo and Poster Sessions, pages 177?180,Prague, Czech Republic, June.
Association for Com-putational Linguistics.Franz Josef Och and Hermann Ney.
2004.
The align-ment template approach to statistical machine transla-tion.
Comput.
Linguist., 30:417?449, December.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The proposition bank: An annotated corpus ofsemantic roles.
Computational Linguistics, 31(1):71?106.Sameer S. Pradhan, Wayne Ward, Kadri Hacioglu,James H. Martin, and Daniel Jurafsky.
2004.
Shal-low semantic parsing using support vector machines.In Proceedings of the Human Language TechnologyConference/North American chapter of the Associa-tion for Computational Linguistics annual meeting(HLT/NAACL-2004).Chris Quirk, Chris Brockett, and William Dolan.
2004.Monolingual machine translation for paraphrase gen-eration.
In Proceedings of EMNLP 2004, pages 142?149, Barcelona, Spain, July.
Association for Computa-tional Linguistics.298
