B-SURE:  A BEL IEVED S ITUAT ION ANDUNCERTAIN-ACT ION REPRESENTATION ENVIRONMENTJOI/N K. MYI';1LSATR Interpreting Telephony Research l,aboratoriesSanpeidani, lnuidani, ,qcika-cho, Soraku-gsn, l(yoto 619-02, Japaltmyers@al.r ht.atLco.jpAbstractThis paper l)reseltts a system that is c~q)abte of representing sit-us,loss, states, anci nondeterminlstic lIOIlinOllOtollic Oil'COllieactions ,lccmTillg ill multiple possible worlds.
:\['he systcnl supports explicit representations of actions and situations usedin intentional ction theory and situation theory.
\[lath typesmid instances ere supported.
Situations ?md statc"a before a,daftel-llOllll/OllOtOnic actions c~ul be repl'esellted shnultaneously.Agents have free will as to whether to choose to peiform an ac:-lion or not.
Situations itud actions can have expected values,allowing the system to support decision making anti decision-based pleal isfferencing.
The system cau perform global rea-soning simultaneously across multiple possible worlds, withoutbeing forced to extend each world explicitly.
The resultingsystem isuseful for retch *tatural language t~-~ks a~ plan recog-nition, intentions modeling, attd parallel ta.~k scheduling.1.
In t roduct ionThe key to good reasoning is a powerful repre-sentation system that is able to accuratcly modeldetails of a problem.
Once a good represent.at,onhas been established, problem computations often be-come straightforward.I?~ecent advances in situation theory \[BP83,Bax89\]and the theory of intentions \[Bra87\] have offeredninny new insights on significant problems found innatural-language understanding.
However, these the-aries offer philosophical approaches only, and do notgive instructions for building concrete reprcsentationand reasoning engines.At the same time, the software systems that havebeen built for reasoning and representation fall shortin any ruunber of areas.
Production systems and se-mantic networks can follow chains of inferences, butcan only represent one possible world at a t imethey cannot reason with states that are both pos-sibly true and possibly not true, while keeping thechains of resulting inferences eparatc.
Most plasl-nets work with limited possible worlds, but callnotreason and perform inferences across multiple worldsat the salne time.
The classical ATMS 1 cal l  representand reason with multiple timeless possible worlds, butcalmot represent actions \[dK86\]-in particular, non-monotonic actions where a retracted state is bothbelieved'to be truc in the world before ttte actiontakes place, and believed to be not true in the worldrepresenting the situation after the retracting actionhas taken place, camtot be represented.
In addition,the ATMS only represents propositions that are in-stant'steal constants or Skolem constants; it does notrepresent uninstantiated variables.
A modified ATMSthat can represent nonmonotonic transitions betweenworlds has been developed \[MN86\], but this systemdoes not explicitly represent situation types and in-stances, action events, nor nondeterminism.
Mostplan inference systems have ignored free will and the1Aanumption-13tmed Truth Maintenta*ce Systenl \[dK86\]explicit representation f the right to choose actions,e.g.
to choose to he uncooperative.
Almost all prcvi-ous systems |lave ignored the nondetermimstie qual-ity of real-world actions that aecessitatcs commit-meat ill intentions.
Real actions call result in oneof several possible outcomc situations, where,xs al-olost all previous ystems are are completely unableto model uondcterminlstie outcomes.
Only dccision-analysis systems have modeled cxpected wdues ofactions, alnl they do not support inferencing.
See\[BL85\] fi)r an excellent summary of issues.Tile B-SURI~ (Believed Situation and Uncertain-action Representation Environment) packagc is animplemented system that supports representation,phmnmg, decision-making, and,plan recognition us-ing probabilistic ,and uncertain actions with nondetcrministic outcomes in multiple possiblc actionworlds.
Situations, states, and action events ,axe allrepresented explicitly, using types (wtriables) and in-stances.
The B-SURE systcm is iml)lemented as a se-ries of extensions to a classical ATMS.
The resultingsystem is very useful, and is being used in plan recog-nition, intentional agent, and scheduling research.2.
Situation TheoryIn \[BP83\], situations are divided into the categoriesabstract and real, and also into the categories "statesof affairs" alid "courses of events".
Abstract situ-ations denote situations that are mental representa-tions.
All the situations discussed in this paper are"abstract situations".
Real sitnations denote situa-tions as they actually are in the real world.
Since itbasically never makes sense to talk about real situ-ations in tile computer, there is no need to snpplythese in a representation e vironment.
"States of af-fairs" correspond to situations that axe static, calledsimply situations in this paper.
"Courses of events"correspond to situations that describe actions thatare being executed, called action events or actions inthis paper.
Barwise and Perry also make use of "rela-tions" defined over '*individuals" and "space-time lo-cations".
This paper takes as primitive the expressionof a relation, which will be termed a stats.
The user isfree to mention individuals or space-time locations instate descriptions as desired.
State descriptions maybe represented nsing logical forms, feature structures,or other methods~sinee th  contents of states are notused by B-SURE except for output, it does not mat-ter.
States, situations, and actions axe assigned oneof the belief values {def in i te ly  be l ieved tzate,possibly believed true, not believed true,believed not true, not believed}, other-wise known ms {actua/ ,  poss ib le ,  bypotheticed..incons is tent ,  nul l}, corresponding to the amountof snpport off, red by tile system's underlying ATMSACRES DE COLING-92, NAbffES, 7-3-28 AO(n" 1992 9 6 i PRec.
OF COLING-92, NANTES, AUG. 23-28, 1992precondition \] ~ | outcome i_\[-In2ge.?
, +,,.+~,,,.
+,,.. ~ ~cutm !~ trsnsition -*'I ---~ situation tripe ~ o( tUpesI .
.
.
.
.
.
.
.
.
.
.
,q~ ~e- JI t~___ J I  tuoe I ~ ~  t ~ - -  i ~ pusl -  PI~ ' " t rens i t i0n  #n rill ~ ~ stateI ~ ~ ~ s t ~ o ~ e  ~ /~?
!-~et~-\]YP ?sitiv?I action #n) - -  ~ j ~obtcome Iv~ "--'~'~-~ ~ .
~  \[situetioninstence *llKEY happens n ?ATMS implies ~ IIATMS mutualI V - ~ IJ -exclusive ~=sumpt, ons)lFigure 1: Structure for Representing Nondeterministie Actions~(Poss ib le  Outcune 51tnat ion ' :# i )(5 tar t |  ng 51 t u a t l o n ~  .
.
.
.
.
.
.~ "~'-"~(...Possible odtcone =51tuat ion ,  In  ~)Figure 2: Compact Graphical Representation which Omits States and Typesrepresentation (see \[Mye89\] for more information).~.
In tent iona l  Act ion  TheoryOne model of intentions tates that an intention isa choice to perform an action, plus a commitment toobtaining its desired outcome\[CL87\].
With determin-istic action outcomes, there is no real need for endeav-oring \[Brag7\], since once the action has been started,it is guaranteed to finish properly.
Many planners infact operate in this "fire and forget" mode.
However,once it is acknowledged that action execution is in factnondeterministic and can have undesirable outcomes,the need for endeavoring becomes clear.
The plannermust predict he likelihood of possible outcomes hap-pening, and judge which action sequence offers thebest chances.
It must interactively maintain a his-tory of past endeavors and results, and modify itsfuture behavior based on current outcomes.
Actingintentionally becomes ignificantly more interestingand realistic with the explicit representation f pos-sible chains of nondeterministic a tions.4.
P rev ious  E f fo r tsDeKleer \[dK86\] presents the first ATMS.
Morrisand Nado \[MN86\] present an ATMS that can representnonmonotonic transitions, but do not handle proba-bilities, uncertainties, explicit situation types, statetypes, nor action events.
Tile research of Allen (e.g.\[AK83, A1187\]), who uses a predicate-calculus rep-resentation, offers some of the best multiple-worlds(deterministic) action representation i this field.Charniak and Goldman \[CG89\] use probabilities andBayesian nets to represcnt he truth value of prob-abilistic statements and attack story understanding.Although nondetcrministic-outcomc actions are notrepresented, and Bayesian ets cannot support globalinferencing with nonnronotonic actions, their work isimportant.
Norvig and Wilensky \[NW90\] commenton problems of probabilistic statements.
"1'he mostsimilar work is recent research by Rao and Georgeff(e.g.
\[RGgl\]), who use a modal logic instead of anATMS to represent nondeterministic a tions.5.
B -SURE Ent i t ies  & Implementat ionThe underlying ATMS works with nodes, assnmp-tions, and implications (justifications).
See \[dK86\].A slate consists of a proposition about the world.States are primitives.
A situation is a set of positiveand negative (withdrawn) states.
An action eventrepresents he state that "execution of the action hasstarted".
States, situations, and actions have typesand instances.
See figure 1.
(The abridged repre-sentation of figure 1 is shown in figure 2.)
Existanceof an instance in a world always implies existance ofits type.
A chooses node is an assumption associ-ated with an action instance that represents whetheran agent chooses to execute that action or not.
Thechooses assumption together with the starting situ-ation instance imply the action instance.
Since anagent ypically can only execute one action in a givensituation, the situation's ensuing chooses assumptionsare rendered mutually exclusive (pairwise "nogood").Action types have precondition situation types.
Ac-tion instances are instantiated from types by first ver-ifying that the precondition situation type is believedtrue in that world.
Action instances transition froma starting situation instance to ouc of a number ofknown nondeterministic outcome situation instances.Actions have transitions.
A transition has an out-con,e situation and a probability or an uncertainty.An uncerlaiuty is defined as a probability randomvariable of range I0, 1\] together with an associatedsecond-order probability distrilmtion.
Uncertaintiesare initialized using maximum-entropy theory, andget updated as outcome observations are taken, to en-able the system to learn and estimate possible proba-bilities.
See Section 6.
Uncertainties are used to rep-resent confidence in likelihood values and to make de-cisions regarding information-gathering activity.
Thecalculus of uncertainties is too complex to explore fur-ther here, and is not required for understanding tilemum capabilities of the representation; probabilitiesare sufficient.
Transitions can be types or instances.ACRES DE COLING-92, NANIT~.
23-28 AOt~rr 1992 9 6 2 PROC.
OF COL1NG-92, NANTES, AUO.
23-28.
1992A transition instance is defined as a happens mssump-tion.
An action instance, together with a happensassumption, iulply the corresponding outcome situa-tion instance.
Typically only one outcome situationcan occur from a giveu action instance, so the action'shappens assun-|ptions are nlade mutually exclusive.
Asituation type is implied by its state types.
When anoutcome situation instance is iastantiated, all of itsnew positive states are instantiated and all of its ohlnegative states are retracted.
A positive nonperma-nent state instance is implied by a nol-relracled-yelassumption.
The outcome situation instance remem-bers these.
Situation and action instances store an ex-plicit environment history of all added state, chooses,and happens assumptions that are currently believedtrue in that possible world's timelinc.
A negativestate is retracted by making the situation instanceand the state's "not-rctrasted yet" ,assumption mutu-ally inconsistent, and deleting the state's assumptionfrom the outcome situation's environment history.
Astate type or instance or situation type's belief valuein a particular world is found by testing that nodeagainst a situation instance's environment history.Situation types and instances can have values.
Ac-tions can have costs.
The expected value of an actionis determined by summing the transition probabilitiestimes the expected values of the outcome situations,when known, and subtracting its cost.
Tim expectedvalue of a nonvalued situation instance is determinedby maximizing the expected values of the possiblesubsequent actions, when known.
In this manner,decision theory determines the course of action withthe maximum expected value at any one situation,for a planning agent.
This can bc used to predict theprobable next course of action of a planning agent byan observing agent performing plan recognition (ac-tually, "decision recognition") \[Mye91\].6.
Probability EstimationThe probability of an outcome situation i occur-ring following performance of an uncertain action isestimated using the new estimator ~ instead of ~ ,where m is the total number of previously observedtrials of that action type, k~ is the previously observednumber of ith situation-type outcomes, and n is thenumber of known possible outcome situations fromthat action.
The new estimator is optimal.
It repre-sents the center of mass of all possible probabilities,instead of the maximum-likelihood mode; it convergesfaster and on average is more accurate than the oldestimator; and, it can be used accurately with smallsample numbers and small snccess counts \[Mye92\].7.Maintaining an Interactive HistoryOne important advantage of the B-SURE system isthat not only can it be used for hypothetical reason-ing about future events, but the same structures canthen be used as a history mechanism for interastivelymonitoring and representing the history of the ac-tual events as they occur.
A user system should startout in a known situation, which is presumed actua l .Typically, the user system will use B-SUrtE to exploremany different nondeteeministic-action sequences andmake decisions ~s to which actions are tile best onesto perform.
The system will then start executing thefirst action m tile chosen sequence.
At.
this point,tile user system should instruct tile B-SUItE systemto presume the chooses assumption associated withtile chosen action being executed, which will changeits truth value from "possibly believed true" to "deli-nitely believed true".
If the chooses node has alreadybeen made inconsistent with other chooses nodes (be-cause the user-system or agent could ouly perform oneaction at a time), those other nodes are automati-cally rendered "believed not-true" at this point.
Thepresumption of the chooses node renders the associ-ated implied Action Event instantiation "definitelybelieved true" at this point, ,also.
This represents hefact that the action has s ta ted  and is currently beingexecnted.When the action finishes, it is necessary for theB-SURE system to realize which outcome occurred.This is typically performed by the system setting up arecognition demon that is attached to a separate stateor situation type that, when true, reliably indicatesthat a given outcome has occurred.
When the demonfires, it presumes the outeome's happens assumption.It is important to ensure ttlat one and only one recog-nition demon fires.
Alternatively, tile user can controlpresuming the happens nodes directly.
When a sin-gle happens assumption is presumed, it automaticallyrenders its sibling happens assumptions "de~in i t  e lybelieved not;-tzale".The combination of tile happens node being pre-sumed and the action event node already being be-lieved true renders the appropriate r sulting situationinstance believed true.
Note that if any instance be-comes true, so does its associated type node as well.At any one point in tinm, the states, situations,and action event instances that have happened in theworld already are believed true; and the situationsand events that have not happened yet but couldhappen are believed possible.
In this way, the sys-tem maintains a timehne history of the situations andaction events that have in fact occurred, while allow-ing hypothetical p anning and exploration of possiblefuture events in the same data structure.It is not necessary for the system to maintain onlya single timeline history.
It is possible to maintaindisjoint histories, to represent e.g.
progress made bydifferent processing agents, progress made in differentdomains, or progress made at different hierarchicallevels of abstraction.
It is possible to maintain forking(nondisjoint) histories if this makes sense, and timmutual exclusion options have been turned off (seeSection 10).Counter faetua ls  The system maintains thestructures of past possibilities that did not happen.Although these are not believed t rue ,  it is possiblefor the user to explore these structures and performreasoning on what could have occurred had certainactions been chosen or certain nondeterministic out-comes happened, by supplying an extra counierfac-tual assumption to justify the desired action or sit-ACRES DE COLING-92, NANTEs, 23-28 ^ o13"r 1992 9 6 3 Paoc.
OF COLING-92, NAI, rrEs.
AUG. 23-28, 1992O ere| I \ [~et \ [ r~g~ / ( t n K e - s u s c s u E t t ~ ~A \[RECP OFFICE\] \[x~r , Ed~cTe .
/ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.~(flEEOS-RIOE CfiLLEr)~/I \[CONT RIuE-rIOEIIj X .
.
.
.
.
.
.
.
.
OF~CE~)~ ~(Geta  there Late)Gets there Late~(TAKE-TAXI CALLER)~ - - - -  -- ~ ' ~(G~ts there On T~Figure 3: Modeling a Plan/Decision Inference Problem in Getting to a Conference On Timeuation instance.
It is even possible to add to thesestructures, if necessary.
This can be used to explic-itly represent newly-received p~st connterfactual iu-formation (e.g., "If you had applied for the conferencelast June, the cost would have been 35,000 yen") andthe associated reasoning derived from snch assertions.Such reasoning has traditionally been very difficult torepresent, because of the negative truth values.8.
Decision Inference ExampleA researcher is calling a conference office from tbetram station and wants to get to the conference ontime.
He has a choice between asking for taxi di-rections, or requesting the office to send a shuttle-bus out directly to give him a ride.
The shuttle willtake him directly to the conference on time.
If he re-quests and the office turns him down, he has a choicebetween taking a taxi, and taking the regular bus.These cost ditferent amounts of money and have dif-ferent chances of getting to the conference on time.See figure 3.
The plan inference system must pre-dict which paths of information he will explore, i.e.what he will say next; and then which decisions hewill make for his actions.
This is done using "deci-sion infcrence", by understanding which action treesoffer the best expected value based on the value andchances of outcomes.
Note that the shuttle-bus, thetaxi, and the regular bus will all three allow the re-searcher to possibly obtain his desired goal, but thereare definite preferences.
The system should not re-main uncommitted.
See \[Mye91\] for more details.9.Intentional Communication ExampleA recent analysis of 12 actual interpreted telephoneconversations revealed that 31% of the utteranceswere spent in requests for confirmation and repeti-tions of information such as telephone numbers, namespellings, and addresses, that were not completely un-derstood the first time \[OCP90\].
This means that thetraditional plan-recognition model of assuming thatthe hearer automatically understands the semanticcontent of the speaker's utterance is fallacious.
Thespeaker, and the system too, must consider the casein which the hearer does not understand an utter-ance.
Since the speaker wants and intends to commu-nicate specific information 2, the speaker will endeavorto ensure that the information is communicated, byrepeating an utterance when it is not understood.Thus, speaking an utterance is a nondeterministie ac-Lion; it, is unclear whether the hearer will uuderstaaldor not.
Intentional utterauce acts are therefore mod-eled ~ nondeterministic-outcome actions by B-SURE.l)ifi'erent courses of the conversation cat\] be repre-sented epending upon the outcomes of the utteranceacts.
See Figure 4.10.
Process Scheduling ExampleThe application of the BEHOLDEIL a limited-resourceparallel sehednling system to translation systems isbeing researched.
A hypothetical model system isused for testing.
The system will accept an inputcaa|didate from a speech recognition module, and at-tempt to quickly transfer tim result directly to out-put.
If required, a morphologicd analyzer will derivemultiple possible analyses candidates for each inputcandidate.
A pattern marcher will then recursivelyapply a body of patterns to each analysis candidate.Each pattern has a series of transfer-driven transla-tion templates; each template has a series of prototyp-icai exmnple bindings.
The highest-ranking structureof matching nested patterns and their bindings aresent to a template marcher.
The distances betweenthe pattern bindings and the template xamples foreach pattern in the structure are compared using athesaurus.
The template with the closest match foreach pattern will be used to assemble a translation.It is the responsibility of the BEHOLDER system toschedule this activity in an opportunistic fashion onmultiple processors.
There is no need to continue toexplore a branch if a good translation has been found.The BEH OLDER system must use value-of-informationtheory and decision theory to determine which pro-cess branches to explore next and when to stop.The BEIIOLDER scheduler uses the B-SURE systemto keep track of which processes are running andwhich have been executed.
Using this representation,it can plan ahead and decide how useful it is to ex-pand a particular path of execution.
As processes arestarted, the chooses nodes are presumed.
Figure 5shows a simulated run where the direct transfer, themorphological nalysis, one pattern match, and onetemplate match have been run.
The template matchhas examined two examples so far.Since in this ease more than one a~tion can be exe-cuted at a time, and one action cau legally have morethan one possible outcome, it was necessary to mod-ify the n-SORE system to allow local disabling of the2Note that people do not always decide to intend to en-deavor to do everything that they weatt.
Intending is qlfitedifferent from wmlting.aBeneficlal Entity for Heuristically Ordering processes un-der Limited resources and Decision-making for Execution inReal-time.ACRES DE COLING-92, NANTES, 23-28 AO(rr 1992 9 6 4 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992Doesn't Understand) ~ I r ~ ~ ~  neuter(~Oea er n tens  , /  .
.
.
.
.
.
~Hearer  Understands )k to Say "lZJ-qSfiT" ~ .
.
.
.
.
.
y IT~ ~ J~ ~ -(H .
.
.
.
.
D .
.
.
.
"t Understand)~ l e a ~ ~ ~  Understands)Figure .1: Mode}rag an Intention to Conrmuuicate a Telephoto.
Number CorrectlyfNo Good Resuits Obtk|ned ?|DIrEcT_TR/~NsFErkI~ , ,  ,.
~ ,.oRPh-AN~LY5 \ [ - -l"igore 5: S ~mutually-exclusive actions and outputs features.
\[CL87\]11.
Conc lus ion  A powerful situation represen-tation tool is required for representing past, present,and future nonmonotonic actions, when the actions \[dK86\]can have nondcterministic outeonms.
The B-SUREeuviromnent offers such a tool.
Being able to modelrealistic actions allows exploration of significant prob- \[MN86\]|eros in situation modeling, plan inference, intentionalactions research, and value-of-information theory 0.~applied to parallel process cheduling.
\[Mye89\]References\[AK83\] James F. Allen and Johannes A. Koomen.
Plan-ning using a temporal world model, ht IJ- \[Mye91\]CAI'83, pages 741-747, Kaxlsruhe, 1983.\[Al187\] James Allen.
Natural Language Understanding.Benjamin/Cummings, Menlo Park, CA, 1987.
\[Mye92\]\[Bar89\] Jolt Barwise.
The Situation in Logic.
Center forthe Study of Language and Information (CSLI),Stauford, CA., 1989.\[BL85\] lLonald J. Brachman and Hector J. Levesque.lleadi*Jgs it~ Knowledge Representation.
Morga~t \[NW90\]Kaufl~tann, Los Altos, CA, 1985.\[BP83\] Jon Barwise and John Perry.
Situations andAttitudes.
The MI'F Press, Cambridge, 1983.\[Bra87\] Michael E. Bratman.
Intention, Plans, and \[OCP90\]Practical Reason.
Harvard Univ.
Press, Cam-bridge, MA, 1987.\[CG89\] Eugene Charniak and Robert Goldman.
A \[RG91\]semanti~ for probabilistic quantilier-free first-order languages, with particular application tostory understanding.
Ira1JG'Al'89, pages 10741079, Detroit, MI, 1989.Pit}lip R. Cohen and Hector J. Levesque.
In-tention : choice + commitment.
In AAAl'87,pages 410-415, Seattle, WA, 1987.Johtm de Klcer.
An Assumption-based TMS.Artificial b~telligence, 28(2):127-162, March1986.Paul I1.
Morris and ttobert A. Nado.
Represent-ing actions with an Assmnption-based TMS.
InAAAl'86, Philadelphia, PA, 1986.John K. Myers.
An a-ssumption-bmsed plan in-ference system for conversation understanding.In WGNL Meeting o.\[ the \[PSJ, pages 73-80,Okinawa, Japan, June 1989.John K. Myers.
Plan inference withprobabilistic-outcome actions.
In Conj.
Proc.lnJormation Processing Society of Japan, vol-ume 3, pages 168-169, Tokyo, March 1991.John K. Myers.
An introduction to plannIngand meta-decision-making witt~ uncertain on-deterministic actions using 2nd-order probabili-ties.
In First Inter.
Conferettce on AI  PlanningSystems, College Park, Maryland, June 1992.Peter Norvig and Robert Wilensky.
Ab~duct}on models for semantic interpretation.In G'OLING-90, volume 3, pages 225-230,Ilelsinki, Finland, August 1990.Sharon L. Oviatt, Philip R. Cohen, and AnnPodlozny.
Spoken language in interpreted tele-phone dialogues.
TechnicM Report AI0-496,SRI International, Menlo Park, CA, 1990.Anad S. Rao and Michael P. Georgeff.
Asymme-try thesis and side-effect problems in linear-timeand branching-time intention logics.
In Procee&ings of 1JCAI-91, Sydney, Australia, 1991.ACRES DZ COLING-92, N^tcr~s, 23 28 Ao~rr 1992 9 6 5 Proc.
OF COLING-92.
NANTES.
AUG. 23-28, 1992
