Proceedings of the ACL 2011 Workshop on Relational Models of Semantics (RELMS 2011), pages 72?80,Portland, Oregon, USA, June 23, 2011. c?2011 Association for Computational LinguisticsIncorporating Coercive Constructions into a Verb LexiconClaire Bonial*, Susan Windisch Brown*, Jena D. Hwang*, Christopher Parisien**,Martha Palmer* and Suzanne Stevenson***Department of Linguistics, University of Colorado at Boulder**Department of Computer Science, University of Toronto{Claire.Bonial, Susan.Brown, hwangd, Martha.Palmer}@colorado.edu{chris, suzanne}@cs.toronto.eduAbstractWe take the first steps towards augmenting a lexicalresource, VerbNet, with probabilistic informationabout coercive constructions.
We focus on CAUSED-MOTION as an example construction occurring withverbs for which it is a typical usage or for which itmust be interpreted as extending the event semanticsthrough coercion, which occurs productively and addssubstantially to the relational semantics of a verb.However, through annotation we find that VerbNetfails to accurately capture all usages of theconstruction.
We use unsupervised methods toestimate  probabilistic measures from corpus data forpredicting usage of the construction across verbclasses in the lexicon and evaluate against VerbNet.We discuss how these methods will form the basis forenhancements for VerbNet supporting more accurateanalysis of the relational semantics of a verb acrossproductive usages.1 IntroductionAutomatic semantic analysis has been very successfulwhen taking a supervised learning approach on datalabeled with sense tags and semantic roles (e.g., seeM?rquez et al, 2008).
Underlying these recent successesare lexical resources, such as PropBank (Palmer et al,2005), VerbNet (Kipper et al, 2008), and FrameNet(Baker et al, 1998; Fillmore et al, 2002), which encodethe relational semantics of numerous lexical items,especially verbs.
However, because authors and speakersuse verbs productively in previously unseen ways,semantic analysis systems must not be limited to directextrapolation from previously seen usages licensed bystatic lexical resources (cf.
Pustejovsky & Jezek, 2008).To achieve more accurate semantic analyses, we mustaugment such resources with knowledge of theextensibility of verbs.Central to verb extensibility is the process of semanticand syntactic coercion.
Coercion allows a verb to be usedin ?atypical?
contexts that extend its relational semantics,thereby enabling expression of a novel concept, or simplymore fluid expression of a complex concept.
Forexample, consider a strictly intransitive action verb suchas blink.
This verb may instead be used in a constructionwith an object, as in She blinked the snow off her lashes,leading to an interpretation of the verb in which the objectis causally affected and changes location (the CAUSED-MOTION construction; Goldberg, 1995).
This type ofconstructional coercion is common in language andunderlies much extensibility of verb usages.Understanding such coercive processes thus hassignificant impact on how we should representknowledge about verbs in a lexical resource.Importantly, constructional coercion is not an all-or-nothing process ?
a word must be semantically andsyntactically compatible in some respects with a contextin order for its use to be extended to that context, but therestrictions on compatibility are not hard-and-fast rules(Langacker, 1987; Kay & Fillmore, 1999; Goldberg,2006; Goldberg, to appear).
Gradience of compatibilityplays an important role in coercion, suggesting that aprobabilistic approach may be necessary for encodingknowledge of constructional coercion in a verb lexicon(cf.
Lapata & Lascarides, 2003).Our hypothesis here is that, due to this gradient processof productivity, existing verb lexicons do not adequatelycapture the actual patterns of use of extensibleconstructions.
In this paper, we focus on the CAUSED-MOTION (CM) construction as an initial test case.
We firstannotate the classes of an extensive verb lexicon,VerbNet, as to whether the CM construction is allowedfor all, some, or none of the verbs in the class, notingadditionally whether it is a typical or coerced usage.
Wefind that many of the classes that allow the constructionfor at least some verbs do not include the CM frame intheir definition, indicating a significant shortcoming in therelational knowledge encoded in the lexicon.
Next, we72develop probabilistic measures for determining to whatdegree a class is likely to admit the CM construction.
Wethen test our measures over corpus data, manuallyannotated for use of the CM construction.
Finally, wepresent preliminary work on automatic techniques forcalculating the proposed measures in an unsupervisedway, to avoid the need for expensive manual annotation.This work forms the preliminary steps toward empiricallyaugmenting VerbNet?s predictive capabilities concerningthe event semantics of verbs in coercible constructions.2 Extensible Constructions and VerbNetConstruction grammar has much insight to offer on thetopic of productivity and on the resulting statisticalpatterns and gradience of usages (e.g., Langacker, 1987;Kay & Fillmore, 1999; Goldberg, 2006).
A constructionis formally defined to be any pairing of linguistic form(e.g., a syntactic frame) and meaning.
Words can be usedin constructions to the extent that their lexical semantics iscompatible with ?
or can be coerced to be compatiblewith ?
the semantic constraints on the construction.It is this notion of constructional coercion, and degreeof coercibility, that accounts for the richness of usagesthat go beyond those thought of as typical or definitionalfor a verb: by coercing a verb not normally associatedwith a particular frame to occur in it, the meaning of theevent can take on additional properties not considered acore part of the verb?s semantics.
For example, in the caseof the sentence discussed above, She blinked the snow offher lashes, it is not the verb but rather the CMconstruction itself that licenses the direct object and addsthe notion of ?motion causally affecting the object?
to theevent semantics.
Amongst other examples of well-knownconstructional coercions are: (1) The CAUSE-RECEIVEconstruction has the syntactic form of NP-V-NP-NP.
Forexample, in Bob painted Sally a picture, the simpletransitive verb paint gains the CAUSE TO RECEIVE sense,in which Sally is the recipient and the picture is thetransferred item.
(2) The WAY construction has the formof NP-V-[POSS way]-PP.
For example, in Frank foundhis way to New York, the construction allows the verbfind to gain a motion reading (i.e., ?Frank traveled to NewYork?)
that would not otherwise be allowed (e.g., *Frankfound to New York).Recognizing such extensions to the relationalsemantics of verbs is very important for accuratesemantic interpretation in NLP.
However, precisespecifications for capturing the notion of coercibleconstructions, such as are needed for a computationalresource, have heretofore been lacking.2.1 VerbNet & Knowledge of ConstructionsComputational verb lexicons are key to supporting NLPsystems aimed at semantic interpretation.
Verbs expressthe semantics of an event being described as well as therelational information among participants in that event,and project the syntactic structures that encode thatinformation.
Verbs are also highly variable, displaying arich range of semantic and syntactic behavior.Verb classifications help NLP systems to deal withthis complexity by organizing verbs into groups thatshare core semantic and syntactic properties.
Forexample, VerbNet (derived from Levin?s [1993] work,Kipper et al, 2008) is widely used for a number ofsemantic processing tasks, including semantic rolelabeling (Swier and Stevenson, 2004), the creation ofsemantic parse trees (Shi and Mihalcea, 2005), andimplicit argument resolution (Gerber and Chai, 2010).The detailed semantic predicates listed with eachVerbNet class also have the potential to contribute to text-specific semantic representations and, thereby, to tasksrequiring inferencing (Zaenen et al, 2008; Palmer et al,2009).VerbNet identifies semantic roles and syntacticpatterns characteristic of the verbs in each class makesexplicit the connections between the syntactic patternsand the underlying semantic relations that can be inferredfor all members of the class.
Each syntactic frame in aclass has a corresponding semantic representation thatdetails the semantic relations between event participantsacross the course of the event.
For example, one of thecharacteristic patterns listed for the Pour class is aCAUSED-MOTION pattern, which accounts for sentenceslike She poured water from the pitcher into the bowl.
Thisis represented in VerbNet as follows:Syntactic representation:NP V NP PP PPAgent V Theme Source LocationSemantic representation:MOTION (DURING(E), THEME)NOT (PREP (START(E), THEME, LOCATION))PREP (START(E), THEME, SOURCE)PREP (END(E), THEME, LOCATION)CAUSE (AGENT, E)This representation details connections between thesyntax and semantics using the semantic roles as links,indicating that the Agent is the Subject NP and hasCAUSED the Event, and that the Theme is the Object NPand has a new LOCATION at the end of the event.
Thesetypes of inferences provide the foundation for deepsemantic analysis of text.73However, the specifications in VerbNet (as in otherpredicate lexicons, such as FrameNet, Baker et al, 1998;Fillmore et al, 2002) are seen as definitional ?
they arerestricted to the core usages of the verbs that are valid forall verbs in the class.
However, as noted above, peopleoften use verbs productively, in ways that go beyond theboundaries of the verb class structure.
It is important tocorrectly identify these productive usages when theyoccur, since they may be explicitly adding crucialinferences.
If a construction is not recognized in the formof a syntactic frame in VerbNet, such inferences are notpossible, greatly reducing VerbNet?s utility and coverage.For example, creative uses of a verb, such as She blinkedthe snow off her lashes, would have no correspondingframe in blink?s class, the Hiccup class.
It contains oneintransitive frame:NP VAgent VBODY_PROCESS (E, AGENT)INVOLUNTARY (E, AGENT)Sentences that coerce the meaning of blink to fit with aCM event would currently be misanalysed.
One optionmight be to augment the Hiccup class with the CM framefrom the Pour class, which would ensure that suchsentences would be analyzed more accurately.
However,given the productive nature of constructional coercionand its widespread applicability, the approach of addingany possible pattern to each class is not appropriate: thiswould undermine the definitional distinctions betweenclasses and greatly lessen their usefulness.Complicating the issue is the phenomenon of regularsense extensions (Dang et al, 1998), where what oncemay have been coercion has become entrenched and isnow seen as a different sense of the verb.
For example,the verbs in the Push class express the general meaning ofexerting force on an object, such as She pushed on thewall.
Often, the exertion of force moves the object, whichcan be expressed in a CM construction such as Shepushed the box across the room.
VerbNet accounts forthis regular sense extension by including most of the Pushverbs in the Carry class as well, which has the CMconstruction as one of its frames.
Deciding when toinclude a verb in another class based on regular senseextensions, when to add a frame for a construction to aclass, or when to reject the frame as a defining part of aclass, is made difficult by the graded nature of matchesbetween verbs and a construction.
Our goal is to maintainthe advantages of the class structure of VerbNet whileenhancing it with a graded view of the applicability of aconstruction for each class.
Noting the applicability of aconstruction will enable the inclusion of its appropriatesemantic predicates, and the inferencing over them,which are currently not supported.3 Our Proposal: Constructional ProfilesWe aim to augment VerbNet with knowledge ofconstructions that are likely to be used extensibly with arange of verbs.
Such extensible constructions will be coreusages for some classes (such as the CM for the Pourclass, as noted above) but will be less characteristic of thefundamental semantics of other verb classes (such as CMfor the Hiccup class).
We propose to identify such aconstruction and its varying roles in the different classesby using relevant statistics over usages of verbs in acorpus ?
what we call a constructional profile.A constructional profile is a probabilistic assessmentof the usage of a particular construction by the verbs in aclass.
We developed the following three measures tocapture the relevant behavior, with the goal of providingboth type- and token-based views of the behavior of averb class with respect to a target construction:P1 Ptype(X|C): probability that a verb type in class C isattested in construction XP1 gives a type-based assessment, indicating howwidespread the use of the construction is across theverb types in the class.
For example, if 8 out of 10members of a class appear with the construction, wemight estimate P1 as 0.8.P2 Ptoken(X|C): probability that the instances of a typicalverb in class C occur in construction XP2 gives a token-based assessment, indicating, for atypical verb in the class, the relative amount of usage ofthe construction among all usages of the verb.
Forexample, to estimate this, we might average across allverbs in the class, the percentage of tokens in thisconstruction.P3: Ptoken(X|X-verbs-in-C): same as P2 but consideringonly verbs that have been attested in construction XP3 is the same as P2, but looking only at those verbs inthe class that have an attested usage of the construction,removing verbs without attested usages.We hypothesize that these measures will have highvalues for those classes for which the construction shouldbe definitional; very low values for those classes that arenot compatible with the construction; and varying valuesfor those classes that allow coerced usages to a greater orlesser extent.Although these probabilities are intuitively verysimple, estimating them from corpus data poses asignificant challenge.
Since a construction is a pairing ofform with meaning, recognizing the use of a particular74construction is not simply a matter of determining thesyntactic pattern of the usage; rather, certain semanticproperties and relations must co-occur with the syntacticpattern.
Earlier work has shown that a supervised learningmethod was able to discriminate potential usages of theCM construction given training sentences manuallylabeled as either CM or not (Hwang et al, 2010).
Here,we aim instead to identify usages of the CM construction,but without requiring an expensive manual annotationeffort.
That is, we seek an unsupervised method forestimating the probabilities in P1?P3 above.We approach this goal in steps as follows.
First, weexamine all the classes in VerbNet to see which allow theCM construction (Section 4).
This anno-tation revealsshortcomings in VerbNet?s representa-tion (classes thatallow the CM construction but do not list it) and alsoprovides a gold standard with which to evaluate ourmethod of identifying an exten-sible construction usingour constructional profiles.
Second, we use the manuallyannotated CM construction data from Hwang et al(2010) to estimate probabilities P1?P3 using maximumlikelihood formulations (Section 5).
An analysis of thepredictive power of these constructional profile measuresshows a good match with the distinctions made in thehuman annotation of the classes.
Thus, our annotationbased constructional profile measures show promise foridentifying relevant behaviors of the construction acrossthe classes.
Third, we explore automatic methods forestimating the constructional profile measures without theneed for manual annotations (Section 6).
We use ahierarchical Bayesian model that learns verb classes fromcorpus data to provide unsupervised estimates of theconstructional profiles, which also exhibit the relevantdistinctions across the classes.4 Annotating the VerbNet ResourceWe begin with a manual examination of the resource anda thorough annotation of the status of each class withrespect to the CM construction.
This effort reveals anumber of shortcomings in VerbNet, and the need fordeveloping methods that can support the extension ofVerbNet to better reflect the coercive uses ofconstructions across the classes.
The annotation describedhere also forms the basis for the evaluation in thefollowing sections of our new probabilistic measures, bymotivating hypotheses about the expected patterns of useof the CM construction across the classes.4.1 Annotation Guidelines and ResultsThe first goal of our manual annotation of VerbNetclasses was to determine which classes currentlyrepresent CM in one of their frames.
To this end, weidentified which classes contain the following frame:NP [Agent/Cause]-V-NP [Patient/Theme]-PP [Source/Destination/Recipient/Location]These frames correspond to classes such as Slide, with itsframe NP-V-NP-PP.Destination: Carla slid the books tothe floor.
We also examined classes with the patterns NP-V-NP-PP.Oblique, NP-V-NP-PP.
Theme2, and NP-V-NP-PP.Patient2.
In these classes, annotators had to judgewhether the final PP was compatible with CM.
Forexample, the Breathe class contains the frame NP-V-NP.Theme-PP.Oblique, The dragon breathed fire onMary, which is compatible with CM; whereas the samebasic frame in the Other_cos class is not: NP V NPPP.Oblique, The summer sun tanned her skin to a goldenbronze.In addition, we annotated which classes werepotentially compatible with CM for either all verbs in theclass or only some verbs.
The "some" classification hasthe drawback that it may be applied to classes with verydifferent proportions of compatible verbs; while suitablefor our exploratory work here, we plan to make finerdistinctions in the future.
A secondary determination waswhether or not the class was compatible with CM as partof its core semantics, or if it was compatible with CMbecause it was coercible into the construction.
A verb wasconsidered ?compatible with CM?
and ?not coerced?
ifthe verb could be used in the CM construction and itssemantics, as reflected in VerbNet?s semantic predicates,involved a CAUSE predicate in combination with anotherpredicate such as CONTACT, TRANSFER, (EN)FORCE,EMIT, TAKE_IN (predicates potentially involvingmovement along some path).
For example, although CMis not already included as a frame for the Bend classcontaining the verb fold, the semantics of this classinclude CAUSE and CONTACT, and the verb can be usedin a CM construction: She folded the note into herjournal.
Therefore, this class would have been considered?compatible with CM?
but ?not coerced?.
Conversely, averb was considered ?compatible with CM?
and?coerced?
if the verb could be used in the CMconstruction, yet its semantics, again as reflected inVerbNet, did not involve CAUSE and MOVEMENTALONG A PATH (e.g., the verb wiggle of theBody_internal_motion class: She wiggled her foot out ofthe boot).In summary, as presented in the table below, weannotated each class according to whether (1) the CMconstruction was already represented in VerbNet for thisclass, (2) the construction was possible for all, some, or75none of the verbs in that class, and (3) the verbs of anyclass compatible with CM were coerced into theconstruction or not.
The classification for (3) was maderegardless of whether ?all?
verbs or only ?some?
werecompatible with CM.
This determination was madeuniformly for a class: there were no classes in which onlycertain CM-compatible verbs were considered ?coerced?.VN class example[# of classes like this]CM inVNCM ispossibleCM iscoercedBanish [50] Yes All NoNonverbal_Expression [2] Yes All YesCheat [6] Yes Some NoExhale [18] No All NoHiccup [30] No All YesFill [46] No Some NoWish [54] No Some YesMatter [64] No None N/ANotably, we identified 206 classes where at least some ofthe verbs in that class are compatible with the CMconstruction; however, VerbNet currently onlyrecognizes the CM construction in 58 classes.
There wereseveral classes of interest: First, although it may seemunusual that CM is represented in 6 classes where wefound that only ?some?
verbs were compatible with CM(e.g., Cheat class), these were cases where only morerestricted subclasses are compatible with CM, and thissyntactic frame is listed for that subclass.
This suggestssubclasses may provide a more precise characterizationof which verbs are compatible with a construction.Secondly, we identified 18 classes in which all verbswere compatible with CM without coercion; thus, theseclasses could likely be improved by the addition of theCM syntactic frame.
Additionally, we found 30 classes inwhich all verbs are coercible into the CM construction;however, the actual likelihood of a verb in those classesoccurring in a CM construction remains to beinvestigated in the following sections.
Like those classeswhere it was determined that only ?some?
verbs arecompatible with CM, usefully incorporating the CMconstruction into classes that require coercion relies onaccurately determining the probability that verbs in thoseclasses will actually appear in the CM construction.For those classes in which ?all?
verbs are compatiblewith CM, our intuition was that some aspect of the verb?ssemantics either inherently includes or allows the verb tobe coerced into the CM construction.
Conversely, forthose classes in which no verbs are compatible with CM,presumably some aspect of the verb?s semantics islogically incompatible with CM.
Although pinpointingprecisely what aspect of a verb?s semantics makes itcompatible with CM may not be possible, we caninvestigate whether or not our intuitions are supported byexamining the actual frequencies of CM constructions forgiven verbs or a given class.4.2 HypothesesUsing these annotations, we were able to develop twosimple hypotheses.Hypothesis 1: We expect the constructional profilemeasures for the CM construction in a given corpus to behighest for those classes in which all verbs were found tobe compatible with CM; lower for classes in which onlysome verbs were found to be compatible; and lowest forclasses in which no verbs were found to be compatible.Hypothesis 2: We expect the constructional profilemeasures for the CM construction in a given corpus to behighest for verbs that fall into classes where CM is notconsidered coerced (for either some or all of the verbs inthe class); lower for verbs that fall into classes in whichthe CM construction only works through coercion (foreither some or all of the verbs in the class); and lowest forverbs that fall into classes in which no verbs arecompatible with CM.To investigate Hypothesis 1, we grouped the annotatedclasses according to whether all, some, or no verbs in theclass are compatible with CM:Class example # of classesAllowed by All Bring, Carry 106Allowed by Some Appoint, Lodge 100Allowed by None Try, Own 64To investigate Hypothesis 2, we did a second groupingof the classes according to whether CM is not coerced,CM is coerced, or CM is simply not compatible with theclass.
This second grouping did not distinguish whetherCM was compatible with ?all?
or ?some?
of the verbs ina given class.Class example # of classesNot Coerced Put, Throw 120Coerced Floss, Wink 86Not Compatible Differ 645 Evaluation using Constructional Profiles5.1 Annotated data descriptionOur research uses the data annotated for Hwang et al(2010), in which 1800 instances in the form NP-V-NP-PP were identified in the Wall Street Journal portion ofthe Penn Treebank II (Marcus et al, 1994).
Each instance76of the data was single annotated with one of the twolabels: CM or non-CM.
The annotation guidelines werebased on the CM analysis of Goldberg (1995).Our analysis began with the same data but adopted aslightly narrower definition of CM.
We diverged fromthe Hwang et al (2010) study in the following two ways:(1) sentences where the object NP is an item that iscreated by the event denoted by the verb were notconsidered CM (e.g., Mr. Pilson scribbled a frighteninglylarge figure on a slip of paper, where the figure is createdthrough the scribbling event); and (2) sentences in whichmovement is prevented were not considered CM (e.g.,He kept her at arm?s length).
In agreement with Hwanget al, our annotation included both metaphorical senses(e.g., [It] cast a shadow over world oil markets) andliteral senses (e.g., The company moved the employees toNew York) of CM.
Our annotation using the narrowerguidelines resulted in 85.8% agreement with the originalannotation.1  The distribution of labels in our data is21.8% for CM and 78.2% for NON-CM.5.2 Annotated data descriptionUsing statistics over the manually annotated data, wecalculate maximum likelihood estimates of the threeconstructional profile measures introduced in Section 3,as follows.
First, let the probability that a verb v is used inthe CM construction be estimated as:P(CM|v,C) =#(CM usages of     )#(CM+non-CM usages of    )That is, P(CM|v,C) is estimated as the relative frequencyof the CM construction for v out of all annotated usagesof v that are labeled as class C. Now let CCM be all verbs vin C with at least one usage annotated as CM; i.e.
:*      |  (  |   )    +Then we calculate estimates of P1?P3 as:P1: Ptype(CM|C) = |CCM |/|C|This measure indicates how widespread the use of CM isacross the verb types in the class.P2: Ptoken(CM|C) =,?
(  |   )   - | |?The average over all verbs v in C of P(CM|v,C)This indicates the relative amount of usage of CM amongall usages of the verbs in the class.P3: Ptoken(CM|v,C) = [?
(  |   ))- |   |The average over all verbs v in CCM of P(CM|v,C)P3 narrows the P2 measure to only those verbs in the1We found that 34.0% of the disagreements were directly due tothe changes in annotation resulting from our two new criteria.class for which there is an attested usage of CM.5.3 Analysis of the Constructional ProfilesThe tables below provide a summary of the profilemeasures P1-P3 for the groups of VerbNet classes asdefined in section 4.2.
For each group listed, we reportthe averages of P1-P3 over all classes in the group whereat least one verb in the class occurred in the datamanually annotated for CM usage.P1 P2 P3CM Allowed by All 0.413 0.323 0.437CM Allowed by Some 0.087 0.078 0.224CM Not Allowed 0.055 0.055 0.083As seen here, the constructional profile measures overCM in the data corroborate our Hypothesis 1 (Section4.2).
All three measures on average are highest for theclasses that fall into the ?all allowed?
group, next highestfor those in the ?some allowed?
group, and lowest for the?not allowed?
classes.P1 P2 P3CM Non-Coerced 0.354 0.274 0.418CM Coerced 0.091 0.091 0.185CM Not Allowed2 0.056 0.056 0.083Furthermore, the second table here confirms ourexpectations for Hypothesis 2 (Section 4.2).
Again, allthree measures on average are highest for classes that fallinto the ?non-coerced?
group, next highest for classes inthe ?coerced?
group (in which the construction isachievable only through coercion), and lowest for the?not allowed?
group.Thus, our two hypotheses are borne out, showing thatour constructional profile measures, when estimated overmanually annotated data, can be useful in capturingimportant distinctions among classes of verbs with regardto their usage in an extensible construction such as CM.6 Automatic Creation of ConstructionalProfiles Using a Bayesian ModelManually annotating a corpus for usages of a con-struction can be prohibitively expensive, so we alsoinvestigate the use of automatic methods to estimateconstructional profile measures.
By using a hierarchi-calBayesian model (HBM) that acquires latent prob-abilisticverb classes from corpus data, we provide unsupervised2 Note the non-zero values result from actual CM verb usages inthe data belonging to classes believed to be not compatible withCM by VerbNet expert annotators.77estimates of the constructional profiles.6.1 Overview of Model and DataWe use the HBM of Parisien & Stevenson (2011), amodel that automatically acquires probabilisticknowledge about verb argument structure and verbclasses from large-scale corpora.
The model is based on alarge body of research in nonparametric Bayesian topicmodeling (e.g., Teh et al, 2004), a robust method ofdiscovering syntactic and semantic structure in very largedatasets.
For each verb encountered in a corpus, themodel provides an estimate of the verb?s expected overallpattern of usage.
By using latent probabilistic verb classesto influence these expected usage patterns, the model can,for example, estimate the probability that a verb like blinkmight occur in a CM construction, even if no suchattested usages appear in the corpus.In this preliminary study, we use the corpus data fromParisien & Stevenson (2011), since the model has beentrained and evaluated on this data.
As that study wasaimed at modeling facts of child language acquisition, ituses child-directed speech from the Thomas corpus(Lieven et al, 2009), part of the CHILDES database(MacWhinney, 2000).
In this preliminary study, we usetheir development dataset containing approx.
170,000verb usages, covering approx.
1,400 verb types.
(Wereserve the test set for future experiments.)
For each verbusage in the input, a number of features are automaticallyextracted that indicate the number and type of syntacticarguments occurring with the verb and general semanticproperties of the verb.
The semantic features are drawnfrom the set of VerbNet semantic predicates, such asCAUSE, MOTION, and CONTACT.
These are automaticallyextracted from all classes compatible with the verb (withno sense disambiguation).6.2 Measures for Constructional ProfilesUsing the argument structure constructions, verb usagepatterns and classes learned by the model, we estimatethe three constructional profile measures in Section 3, asfollows.
First, we note that since the constructionsacquired by the model are probabilistic in nature, aparticular CM instance may be a partial match to morethan one of the model?s constructions.For each verb in the input, we consider the likelihoodof use of the CM construction to be the likelihood of acontrived frame intended to capture the importantproperties of a CM usage.
FCM is a usage taking a directobject and a prepositional phrase, and including thesemantic features CAUSE and MOTION, with all othersemantic features left unspecified.
For a given verb v, weestimate the likelihood of this CM usage, over allconstructions in the model, as follows:(   | )  ?
(   | ) (| )Here, P(FCM |k) is the likelihood of the CM usage FCMbeing an instance of the probabilistic construction k, andP(k|v) is the likelihood that verb v occurs withconstruction k. These component probabilities areestimated using the probability distributions acquired bythe model and averaged over 100 samples from theMarkov Chain Monte Carlo simulation, as described inParisien & Stevenson (2011).Now, we let CCM be the set of verbs in VerbNet classC where the expected likelihood of a CM usage is non-negligible (akin to the set of verbs with attested usage inSection 5.2):CCM = {v C | P(FCM|v)>?
}where ?
is a small threshold, here 0.0001.
Note that sincev is not disambiguated for class in our data, all usages of vcontribute to this estimate.The estimates of P1-P3 are comparable to those inSection 5.2.
The difference is that since we are un-able todisambiguate individual usages of the verbs, each usageof v is considered to belong to all possible classes C ofwhich v is a member.
P1 is estimated as before; P2 andP3 are averages of P(FCM|v).6.3 Analysis of the Constructional ProfilesThe tables below provide a summary of the profileestimates P1-P3 for the groups of VerbNet classes asgiven in Section 4.2.
For each group listed, we report theaverages of P1-P3 over all classes in the group where atleast one of the verbs in the class occurred in the traininginput to the model.P1 P2 P3All allowed 0.569 0.0180 0.0250Some allowed 0.449 0.0106 0.0192Not allowed 0.363 0.0044 0.0079These profile measures align with the hypotheses inSection 4.2 and with the measures based on manuallyannotated data in Section 5.2.
The estimates are high-estfor classes where all verbs permit the CM con-struction,second highest for classes where only some permit it, andlowest for classes that do not permit it.P1 P2 P3CM non-coerced 0.546 0.0178 0.0260CM coerced 0.458 0.0095 0.0167CM not allowed 0.363 0.0044 0.007978Again, the overall patterns of the profile measures alignwith Sections 4.2 and 5.2.
The profile estimates arehighest for classes annotated to be non-coerced usages ofCM, second highest for coerced classes, and lowest for?not allowed?.The measures show the overall differences amongclasses in the different groups (for both groupings) ?
i.e.,the average behavior among classes in the differentgroups varies as we predicted.
This indicates that themeasures are tapping into aspects of construction usagethat are relevant to making the desired distinctions inVerbNet, and validates the use of automatictechniques.
However, there is a substantial amount ofvariability in these measures across the classes, so we alsoconsider how well the estimates can predict theappropriate group for individual classes.
That is, can weautomatically predict whether the CM construction canbe used by all, some, or none of the verbs in a given verbclass, and can we predict whether such usages arecoerced?We consider the P3 measure as it provides the bestseparation among the class groupings.
The tables belowreport precision (P), recall (R) and F-measures (F) foreach group, where ?all?
and ?some?
have been collapsed.For exploratory purposes, we pick P3 = 0.006 as thevalue that optimizes F-measures of this classification.Future work will explore more principled means forsetting these thresholds.P R FCM allowed 0.880 0.742 0.806CM not allowed 0.407 0.636 0.497Only a 2-way distinction can be made reliably for theallowed grouping.
The F-score of over 80% for the?allowed?
label is very promising.
The low precision forthe ?not allowed?
case suggests that the model can?tgeneralize sufficiently due to sparse data.P R FCM non-coerced 0.691 0.491 0.574CM coerced 0.461 0.417 0.438CM not allowed 0.406 0.709 0.517We use thresholds of P3 = 0.021 to separate non-coercedfrom coerced classes, and P3 = 0.007 to separate coercedfrom not allowed classes.
The model estimates showmoderate success in distinguishing classes with coercedvs.
non-coerced usage of the CM construction.
However,our measures simply cannot distinguish non-occurrencedue to semantic incompatibility from non-occurrence dueto chance, given the expected low frequency of a novelcoerced use of a construction.
To separate the allowedcases into whether they are coerced or not requires amore detailed assessment of the semantic compatibility ofthe class, which means looking at finer-grained featuresof verb usages that are indicative of the semanticpredicates compatible with the particular construction.Moreover, this kind of assessment likely needs to beapplied on a verb-specific (and not just class-specific)level, in order to identify those verbs out of a potentiallycoercible class that are indeed coercible (i.e., identifyingthe coercible verbs in a class labeled as "some allowed").7 ConclusionOur investigation demonstrates that VerbNet does notcurrently represent the CM construction for all verbs orverb classes that are compatible with this construction,and the existing static representation of verbs isinadequate for analyzing extensions of verb meaningbrought about by coercion.
The utility of VerbNet wouldbe greatly enhanced by an improved representation ofconstructions: specifically, the incorporation ofprobabilities that verbs in a given (sub)class would occurin a particular construction, and whether this constitutes aregular sense extension.
This addition to VerbNet wouldincrease the resource?s coverage of syntactic frames thatare compatible with a given verb, and therefore enableappropriate inferences when coercion occurs.
We havemade preliminary steps towards developing thisprobabilistic distribution over both verb instances andclasses, based on a large corpus.
Unsupervised methodsfor estimating the probabilities achieve an F-score of over80% in distinguishing the classes that allow the targetconstruction.
However, making distinctions amongcoerced and non-coerced cases will require us to gobeyond these class-based probabilities to finer-grained,corpus-based assessments of a verb?s semanticcompatibility with a coercible construction.To move beyond these preliminary findings, we musttherefore shift our focus to the behavior of individualverbs.
Additionally, to reduce the impact of errorsresulting from low-frequency verbs and classes, we planto expand our research to more data, specifically theOntoNotes TreeBank data (Weischedel et al, 2011).Finally, to achieve our ultimate goal of creating a lexiconthat can flexibly account for a variety of constructions, wewill examine other constructions as well.
Whiledetermining the set of coercible constructions in alanguage is itself a topic of current research, we proposeinitially to include the widely recognized CAUSE-RECEIVE and WAY constructions in addition to CM.79ReferencesBaker, Collin F., Charles J. Fillmore, and John B. Lowe.
1998.The Berkeley FrameNet Project.
Proceedings of the 17thInternational Conference on Computational Linguistics(COLING/ACL-98), pp.
86?90, Montreal.Dang, HoaTrang, Karin Kipper, Martha Palmer, and JosephRosenzweig.
1998.
Investigating regular sense extensionsbased on intersective Levin classes.
Proceedings ofCOLING-ACL98, pp.
293?299.Fillmore, Charles J., Christopher R. Johnson, and Miriam R.L.Petruck.
2002.
Background to FrameNet.
InternationalJournal of Lexicography, 16(3):235-250.Gerber, Matthew, and Joyce Y. Chai.
2010.
BeyondNomBank: A study of implicit arguments for nominalpredicates.
Proceedings of the 48th Annual Meeting of theAssociation of Computational Linguistics, pp.
1583?1592,Uppsala, Sweden, July.Goldberg, A. E. 1995.
Constructions: A constructiongrammar approach to argument structure.
Chicago:University of Chicago Press.Goldberg, A. E. 2006.
Constructions at work: The nature ofgeneralization in language.
Oxford: Oxford UniversityPress.Goldberg, A. E. To appear.
Corpus evidence of the viability ofstatistical preemption.
Cognitive Linguistics.Hwang Jena D., Rodney D. Nielsen and Martha Palmer.
2010.Towards a domain-independent semantics: Enhancingsemantic representation with construction grammar.Proceedings of Extracting and Using Constructions inComputational Linguistic Workshop, held with NAACLHLT 2010, Los Angeles, June.Kay, P., and C. J. Fillmore.
1999.
Grammatical constructionsand linguistic generalizations: The What's X Doing Y?construction.
Language, 75:1?33.Kipper, Karin, Anna Korhonen, Neville Ryant, and MarthaPalmer.
2008.
A large-scale classification of English verbs.Language Resources and Evaluation Journal, 42:21?40.Langacker, R. W. 1987.
Foundations of cognitive grammar:Theoretical prerequisites.
Stanford, CA: StanfordUniversity Press.Lapata, M., and A. Lascarides.
2003.
Detecting novelcompounds: The role of distributional evidence.Proceedings of the 11th Conference of the EuropeanChapter of the Association for ComputationalLinguistics(EACL03), pp.235?242.
Budapest, Hungary.Levin, B.
1993.English Verb Classes and Alternations: APreliminary Investigation.
Chicago: Chicago UniversityPress.Lieven, E., D. Salomo, and M. Tomasello.
2009.
Two-year-old children?s production of multiword utterances: Ausage-based analysis.
Cognitive Linguistics 20(3):481?507.MacWhinney, B.
2000.The CHILDES Project: Tools foranalyzing talk (3rd ed., Vol.
2: The Database).
Erlbaum.M?rquez, L., X. Carreras, K. Litkowski, and S. Stevenson.2008.
Semantic role labeling: An introduction to the specialissue.
Computational Linguistics, 34(2): 145?159.Martha Palmer, Jena D. Hwang, Susan Windisch Brown,Karin Kipper Schuler and Arrick Lanfranchi.
2009.Leveraging lexical resources for the detection of eventrelations.
Proceedings of the AAAI 2009 SpringSymposium on Learning by Reading, Stanford, CA, March.Palmer, Martha, Daniel Gildea, and Paul Kingsbury.2005.The Proposition Bank: An annotated corpus of semanticroles.
Computational Linguistics, 31(1):71?106.Parisien, Christopher, and Suzanne Stevenson.
2011.
Toappear in Proceedings of the 33rd Annual Meeting of theCognitive Science Society, Boston, MA, July.Pustejovsky, J., and E. Jezek.
2008.
Semantic coercion inlanguage: Beyond distributional analysis.
Italian Journal ofLinguistics/RivistaItaliana di Linguistica 20(1): 181?214.Shi, Lei, and Rada Mihalcea.
2005.
Putting pieces together:Combining FrameNet, VerbNet and WordNet for robustsemantic parsing.
Proceedings of the 6th InternationalConference on Intelligent Text Processing andComputational Linguistics, Mexico City, Mexico.Swier, R., and S. Stevenson.
2004.
Unsupervised semanticrole labeling.
Proceedings of the 2004 Conf.
on EmpiricalMethods in Natural Language Processing, pp.
95?102,Barcelona, Spain.Teh, Y. W., M. I. Jordan, M. J.Beal, and D. M.Blei.2006.Hierarchical Dirichlet processes.
Jrnl of the AmericanStatistical Asscn, 101(476): 1566?1581.Weischedel, R., E. Hovy, M. Marcus, M. Palmer, .R.
Belvin,S.
Pradan, L. Ramshaw and N. Xue.
2011.OntoNotes: ALarge Training Corpus for Enhanced Processing.
In Part 1:Data Acquisition and Linguistic Resources of TheHandbook of Natural Language Processing and MachineTranslation: Global Automatic Language Exploitation,Eds.
: Joseph Olive, Caitlin Christianson, John McCary.Springer Verlag, pp.
54-63.Zaenen, A., C. Condoravdi, and D. G. Bobrow.
2008.
Theencoding of lexical implications in VerbNet.
Proceedingsof LREC 2008, Morocco, May.80
