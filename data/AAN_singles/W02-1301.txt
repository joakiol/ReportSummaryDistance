SPEECH-RELATED TECHNOLOGIESWhere will the field go in 10 years?Niels Ole Bernsen, NISLab, Denmark (editor)AbstractThis paper is a draft position paper for discussion at the ELSNET Brainstorming Workshop2000-2010 in Katwijk aan Zee, The Netherlands, on 23-24 November, 2000.
The paper firstdescribes some general emerging trends which are expected to deeply affect, or eventransform, the field of speech technology research in the future, including trends towardsadvanced systems research, natural interactivity, multimodality, and medium-scale science.
Atimeline survey of future speech-related technologies is then presented followed by analysisof some of the implications of the proposed timelines.
Timeline projections may turn out tohave been false, of course, but even their turning out to be true is subject to future actionswhich are (not) taken to make them true.
Accordingly, the final part of the paper discussessome actions which would seem desirable from the point of view of strengthening theposition of European speech-related research.1.
IntroductionThe term speech-related research has been chosen to designate the topic of the present paperfor lack of ability to invent a more appropriate term, if there is one.
At least, the term partlymanages to convey the author?s expectation that the field of speech research will changerather dramatically in the coming ten years as speech technologies become merged with othertechnologies into a field which, so far, lacks a name.According to many observers, the coming decade will be the decade of speech technologies.Computer systems, whether stationary or mobile, wired or wireless, will increasingly offerusers the opportunity to interact with information and people through speech.
This has beenmade possible by the arrival of relatively robust, speaker-independent, spontaneous (orcontinuous) spoken dialogue systems in the late 1990s as well as through the constantlyfalling costs of computer speed, bandwidth, storage, and component miniaturisation.
Thepresence of a speech recogniser in most appliances combined with distributed speechprocessing technologies will enable users to speak their native tongue when interacting withcomputer systems for a very large number of purposes.
Although no doubt exaggerated as justpresented, there probably is some truth to this vision of a breakthrough in the application ofspeech technologies in the coming years.
If this is the case, it would seem worthwhile that welift our sights and take a long-term view of the issues ahead.
This may help setting areasonable research agenda for the coming years of advanced speech systems research anddevelopment, one which does not succumb to the usual hype associated with fashionabletechnologies.
Today, some believe that ?the speech problem?
has been solved already.
Somebelieve that speech, because of its naturalness, is the solution to every conceivable problem ofuser-system interaction.
On the other hand, surprising as it may seem, some human factorsand interactive systems experts believe that we have just arrived at the touch-tone telephonystage and share no notion of the actual state-of-the-art in the field with its practitioners.
Sinceall of those beliefs are far from the truth, it is important to provide a more balanced picture ofthe state-of-the-art in speech technologies in order to set the stage for solid progress.In what follows, Section 2 presents some trends in the speech-related research field.
Section 3excels in guesswork by estimating the times of appearance of a range of novel speech-relatedtechnologies.
Section 4 discusses implications of the timelines presented in Section 3.
Section5 proposes a series of actions which would appear appropriate given the preceding discussion.2.
Some TrendsThe speech field is making progress on a broad scale as demonstrated by the 900 or so papersand posters presented at the recent International Conference on Spoken Language Processing(ICSLP) in Beijing, October 2000.
[To be illustrated by listing topics.]
Three points may bemade on the preceding list of current topics in speech research.
Firstly, the wealth of topicsthat are being addressed in current fundamental and applied research obviously demonstratesthat ?the speech problem?
has not been solved but continues to pose a series of major researchchallenges.
[Mention some of them.]
Secondly, the breadth of the speech topics that are beingaddressed could be taken as evidence that the speech field is simply doing business as usual,albeit on a larger and more ambitious scale than ever before.
Thirdly, however, it is clear fromthe topics list that the speech field is no longer separate from many other fields of researchbut is in a process of merging into something which might perhaps be called the general fieldof interactive technologies.
This latter trend, it may be argued, is the single most importantfactor which will influence the speech field in the future and which already suggests that thefield is in a state of profound transformation.Interactive technologiesIt is relatively straightforward to explain why the speech field is gradually merging into thegeneral field of interactive technologies.
Since speech now works for a broad range ofapplication purposes, a rapidly growing fraction of the speech research community arebecoming involved in advanced interactive systems research rather than continuing to workon improving the speech components which form part of those systems.
In advancedinteractive systems research, speech is increasingly being used not as a stand-alone interactivemodality as in, e.g., spoken language dialogue systems over the telephone, speech dictationsystems, or text-to-speech systems, but as a modality for exchanging information withcomputer systems in combination with other modalities of information representation andexchange.
Moreover, speech is not just an interactive technology among many others.Spontaneous speech is an extremely powerful input/output modality for interacting withcomputer systems, a modality which, furthermore, is available and natural to the largemajority of users without any need for training in using it for interactive purposes.The ongoing shift from speech components research to research on integrating speech incomplex interactive systems has a number of important implications for the speech field.Speech researchers are becoming systems researchers and engineers.
Far more thancomponents research, systems research and engineering is exposed to the full complexity oftoday?s world of information and telecommunications technologies.
Few, if any, groups canbuild full systems on their own from scratch.
To stay competitive, they have to follow closelythe global developments in relevant systems architectures, platforms, toolkits, availablecomponents of many different kinds, de facto standards, work in standards committees,market trends etc.
They need larger and much more interdisciplinary teams in order to keepup with competitive developments.
They need access to platforms and componenttechnologies in order to avoid having to do everything by themselves.
And they needexpertise in software systems engineering best practice as specialised to the kind of systemsthey are building, including expertise in systems and usability evaluation.
As we shall see inSection 4, they need even more than this, such as hardware access or expertise, developmentresources, behavioural research in new domains, and skills in form and contents design.Compared to traditional research on improving a particular speech component technology, theworld of advanced interactive systems research would appear to be orders of magnitude morecomplex.
Moreover, that world is quite diffuse for the time being.
It does not have a singleassociated research community, being inhabited instead by researchers from most traditionalITC (Information Technologies and Telecommunications) research communities.
The worldof advanced interactive systems research does not have any clear evolutionary direction,being characterised rather through ever-changing terms of fashion, such as ?ubiquitouscomputing?, ?things that think?, ?wearable computing?, ?the disappearing computer?
or?ambient intelligence?.
Significantly, all or most of those terms tend to refer to combinedhardware and software systems rather than to components, and none of them refer to thetraditional communities in the ITC field, such as speech processing, natural language (text)processing, machine vision, robotics, computer graphics, neural networks, machine learning,or telecommunication networks.
Indeed, most of our current stock of inspired and visionaryterms for describing the future of interactive technologies tends to be rather vague with regardto the technologies which they include or, if any, exclude.Rather than trying to clarify what might be meant by the terms of fashion mentioned above, itmay be useful to look at two other developments in conceptualising the field of advancedinteractive systems research of which speech research has begun to form a part.
To be sure,the concepts to be discussed are expressed by fashion terms as well, but at least it would seemthat those concepts are of a more systematic and theoretically stable nature at this point.Natural interactivityWhen being together, most humans interact through speech when they exchange information.The telephone allows them to use spoken interaction at a distance as well, and the function ofthe telephone will soon be shared, or even taken over, by computing systems.
When humansinteract through speech, it does not matter if they are just a twosome or if they are more thantwo together.
Moreover, except when speaking over the telephone, speech is not their onlymodality for information exchange.
Gesture, lip movements, facial expression, gaze, bodilyposture, and object manipulation all contribute to adding information, however redundant, tothe spoken message.
Together with speech, those modalities constitute full natural human-human communication.
Moving beyond current technologies, we envision not just a singlehuman speaking on the telephone or to a (desktop) computer in order to get a particular taskdone.
Rather, the vision is one in which multiple humans speak together whether or not theyare in the same physical location whilst using the system as an increasingly equal partner incommunication.
The system mediates their communication when needed, understands fullnatural communication, and produces full natural communication itself, increasingly acting asits human counterparts in communication.
In order to take this vision into account, it wouldseem timely to abandon the traditional model of interaction which is called ?human-computerinteraction?, and replace it with the more general model of natural human-human-systeminteraction (HHSI).
Natural HHSI, it appears, it a necessary end-point of current research inspeech technologies.
Thus, natural interactivity may serve as an important, even if distant,guidepost for the role of speech research in the complex world of interactive systemsresearch.The received picture of the role of theory in engineering goes something like this.
It is hardlyever possible to deduce from theory a complete specification of the artefact that wouldconstitute an optimal solution to some engineering problem.
The reason is that the complexityof the problem space involved always exceeds the power of theory.
On the other hand,without theory (of physics, chemistry, computation etc.
), it would not have been possible tobuild many of the artefacts we use in our daily lives.
Thus, theory has a necessary supportingfunction in engineering.
This is clear in the case of natural interactivity.
To achieve theultimate goal of natural HHSI, we need far better theory than is available at present: abouthow humans behave during natural interaction, about the behavioural phenomena which arerelevant to the development of fully natural interactive systems, about how these phenomenaare interrelated, about how they should be encoded etc.
We also need a novel theory ofnatural communication which can replace speech acts theory and discourse theory by takingthe notion of a complete communicative act as its basic notion.MultimodalityThe trend towards multimodal interactive systems reflects the trend towards blending oftraditional research communities noted above as well as the increasing role of speech in futureinteractive systems.
Multimodal systems are systems which offer the user combinations ofinput/output modalities for (or ways of) exchanging information with computer systems.Given the naturalness and expressive power of speech, speech input and speech output havethe potential for becoming key modalities in future interactive systems.
However, comparedto natural interactivity, our current understanding of multimodality is much less capable ofproviding guideposts for future advanced interactive systems research in general and researchon multimodal systems which include speech modalities in particular.
Much too little isknown about how to create good modality combinations which include speech for a variety ofinteractive purposes.
This topic has become an active field of research, however (Bernsen1997a, Benoit et al 2000, Bernsen 2001).
Further progress in this field is likely tocomplement research on natural interactivity in providing guideposts for speech-relatedresearch in the complex world of advanced interactive systems.
In fact, these two researchdirections are intertwined in so far as it remains an open issue for which application purposestechnologies, such as, e.g., animated speaking characters might provide useful solutions.Medium-scale scienceThe final trend to be mentioned is the trend towards medium-scale science in advancedinteractive systems research.
Increasingly, it is becoming evident that the standard 3/4/5-team,low-budget, 3-year isolated advanced systems research project is often an inefficient means ofachieving significant research progress.
In many projects, the participants share discouragingexperiences, such as the following: even if small, the project is only able to start almost oneyear after its conception because of the administrative processing needed to release thefunding for the project; when the project begins, the participants discover that their objectiveshave already been achieved elsewhere; the participants spend the first half of the projecttrying to identify the best platform to work from only to discover that they cannot get accessto it; the participants spend half of the project building and putting together a low-qualityversion of the contextual technologies they need before they can start addressing their coreresearch objectives; at the start of the project, the participants realise that it will take too longto produce the data resources they need, such as tagged corpora, and decide instead to workwith sub-optimal resources which they can get for free; etc.
One way to avoid, or reduce thenumber of, such experiences is to launch larger-scale concerted research efforts which have abetter chance of moving beyond the state of the art.
World-wide, experiments are currentlyunderway on how to carry out such medium-scale science.
In the US DARPA Communicatorproject which addresses spoken language and multimodal dialogue systems, for instance, allparticipants start from shared core technologies without having to build these themselves(http://fofoca.mitre.
org/).
In the German SmartKom project which addresses multimodalcommunication systems, the budget is large enough for the participants to build and integratethe technologies needed (http://smartkom.dfki.de/start.html).
In the European IntelligentInformation Interfaces (i3, http://www.i3net.org/) and CLASS (http://www.class-tech.org/)initiatives, whilst the traditional 3-year small-scale project topology has been preserved,major efforts are being made to promote cross-project collaboration, synergy, and criticalmass.For reasons too obvious to mention, relatively small-scale research should continue to exist,of course.
Still, the complexity of the world of advanced interactive systems research is notlikely to go away.
This raises the question of whether we need more medium-scale scienceand less small-scale science in order to make efficient use of the funds available for advancedinteractive systems research.
If this question is answered in the affirmative, the importantissue becomes how best to do medium-scale science, i.e.
which model(s) to adopt for thelarger-scale research efforts to come.3.
Estimated Technology TimelinesThis section attempts to estimate the time of first appearance of a broad selection of genericand/or landmark speech technologies including natural interactivity technologies andmultimodal technologies involving speech.
Some qualifications are necessary to the properinterpretation of the proposed predictions.
Despite the numerous uncertainties involved inestimating technology progress, timelines, when properly estimated, qualified, and peerreviewed, do seem a useful means of conveying a field?s expectations to the outside worldand serving as a basis for actions to be undertaken to support research in the field.Qualifications(a) As in all timeline forecasts, there is some uncertainty in the forecasts below with respect towhether the technology is deployable or will in fact have been deployed in products at thesuggested time.
The claim for the figures below rather tend towards the deployableinterpretation which is the one closest to the point of view of research.
The actual deploymentof a deployable technology is subject to an additional number of factors some of which areunpredictable, such as company technology exploitation strategies, pricing strategies, and themarket forecasts at deployability time.
Thus, several years may pass before some of thetechnologies below go from deployability to actually being used in mass products.
Thisimplies that one cannot from the estimations below construct scenarios for the InformationSociety in which people in general will be using the described technologies at the timesindicated.
In other words, the years below refer to ?earliest opportunity?
for actualdeployment in what may be sometimes rather costly systems to be embraced by relatively fewcustomers.
Similarly, given the fact that there are thousands of languages in the world, it goeswithout saying that a technology has been established when it works in at least one of the toplanguages, a ?top language?
being defined as a language used by developers in the moreaffluent parts of the world.
(b) Another point related to (a) above is to do with underlying ?production platforms?.
Formany advanced, and still somewhat futuristic, speech and language -related systems, it is onething to have produced a one-of-a-kind demonstrator system but quite another to haveproduced the system in a way which enables oneself or others to relatively quickly producemore-of-the-same systems in different application domains.
An example is the so-calledintelligent multimedia presentation systems which will be discussed in more detail in Section4.
Several examples exist, such as the German WIP system and corresponding systems fromthe USA.
However, as long as we haven?t solved the problem of how to produce this kind ofsystem in a relatively quick and standardised way, intelligent multimedia presentationsystems are not going to be produced in numbers but will remain research landmarks.
Thetimeline list below mostly avoids mentioning systems of this kind, assuming for the kinds ofsystems mentioned that the ?production platform?
issue has been solved to some reasonableextent at the time indicated.
(c) There is some, inevitable because of the brevity of the timeline entries, vagueness in whatthe described technologies can actually do.
(d) It is assumed that, after a certain point in time which could be, say, 2006, the distinctionbetween technology use for the web and technology use for other purposes will havevanished.
(e) There is no assumption about who (which country, continent, etc.)
will produce thedescribed landmark results.
However, given the virtually unlimited market opportunities forthe technologies listed as a whole, it is expected that a consolidated technology timeline listwill command keen interest among decision makers from industry and funding agencies.
(f) There is nothing about (software) agent technologies below.
It is simply assumed that whatis currently called software agent technologies will be needed to achieve the results describedand will be available as needed.
(g) In principle, of course, any technology timeline list is subject to basic uncertainty due tothe ?if anything is done about it?
?factor.
If nothing will be done, nothing will happen, ofcourse.
However, most of the technologies listed below are being researched already and therest will no doubt be investigated in due course.
The uncertainty only attaches to who will getthere first with respect to any given technology, who will produce the product winners, andhow much effort will be invested in order to achieve those results before anybody else.Technology timelinesBasic technologiesHypotheses lattices, island parsing, spotting in all shapes and sizes for spokendialogue 2001Continuous speech recognisers in OSs for workstations in top languages 2002Continuous speech recognisers in mobile devices (10000 words vocabulary) intop languages 2003High quality competitive (with concatenated speech) formant speech synthesisin top languages 2003Task-oriented spoken dialogue interpretation by plausibility in context and situation 2003Generally usable cross-language text retrieval 2003Multilingual authoring in limited domains by constructing conceptual representations  2003Usable ontological lexicons for limited domains 2003Usable translation systems for written dialogues (multilingual chatting) 2003Useful speaker verification technology 2004Seamless integration of spoken human/machine and human/human communication 2004First on-line prosodic formant speech synthesis in top languages 2004Simple task-oriented animated character spoken dialogue for the web 2004Concept-to-speech synthesis 2004Stylistically correct presentation of database content 2004Superficial semantic processing based on ontological lexicons 2004Max.
2000 words vocabulary task-oriented animated character dialogue for the web 2005Prosodic formant speech synthesis replaces concatenated speech in top languages 2005Full free linguistic generation (from concepts) 2005Robust, general meta-communication for spoken dialogue systems 2005Writer-independent handwriting recognition 2005Learning at the semantic and dialogue levels in spoken dialogue systems 2006Useful multiple-speaker meeting transcription systems 2006Task-oriented fully natural animated characters (speech, lips, facial expression,gesture) output (only) 2007Context sensitive summarization (responsive to user's specific needs) 2007Answering questions by making logical inferences from database content 2007Speech synthesis with several styles and emotions in top languages 2008Continuous speech understanding in workstations with standard dictionaries(50000 words) in top languages 2008Controlled languages with syntactic and semantic verification for specific domains 2008Large coverage grammars with automatic acquisition for syntactic and semanticprocessing for limited applications 2008Task-oriented fully natural speech, lips, facial expression, gestureinput understanding and output generation 2010SystemsFirst personalised spoken dialogue applications (book a personal service over the phone) 2002Useful speech recognition-based language tutor 2003Useful portable spoken sentence translation systems 2003Useful broadcast transcription systems for information extraction 2003First pro-active spoken dialogue with situation awareness 2003Current spoken dialogue systems technology for the web (office, home) 2004Satisfactory spoken car navigation systems 2004Current spoken dialogue systems technology for the web (in cars) 2005Useful special-purpose spoken sentence translation systems (portable, web etc.)
2005High quality translation systems for limited domains with automatic acquisition 2005Small-vocabulary (>1000 words) spoken conversational systems 2005Medium-complexity (wrt.
semantic items and their allowed combinations) task-orientedspoken dialogue systems 2005Multiple-purpose personal assistants (spoken dialogue, animated characters) 2006Task-oriented spoken translation systems for the web 2006Useful speech summarisation systems in top languages 2006Useful meeting summarisation systems 2008Usable medium-vocabulary speech/text translation systems for all non-criticalsituations 2010Medium-size vocabulary conversational systems 2010Tools, platforms, infrastructureStandard tool for cross-level, cross-modality coding of natural interactivity data 2002Infrastructure for rapid porting of spoken dialogue systems to new domains 2003Platform for generating intelligent multimedia presentation systems with spokeninteraction 2005Science-based general portability of spoken dialogue systems across domains and tasks 2006Other problems which were strongly felt when producing the list above include: (i) the factthat there is plenty of continuity in technology development.
?Continuity?
may not be theright term because what happens is that what is later perceived as a new technological stepforward is constituted by a large number of smaller steps none of which could be mentionedin a coarse-grained timeline exercise such as the one above.
General speaker identification,robust speech recognition in hard-to-model noise conditions, ?real?
speaker-independentrecognition (almost) no matter how badly people speak, or pronounce, some language, are allexamples of minute-step progress.
(ii) Another problem is to do with speech in fancy-termedcircumstances, such as ?ambient intelligence?
applications.
It may be that there is a hard-corestep of technological progress which is needed to achieve speech-related ambient intelligencebut then again, may be there isn?t.
Maybe this is all a matter of using the timelined speechtechnologies above for a wide range of systems and purposes.
Similarly, it is tempting to ask,for instance: ?When will I have a speech-driven personal assistant??.
But everything dependson what the personal assistant is supposed to be able to do.
Some personal assistanttechnologies exist already.
Thus, it does not seem possible to timeline the appearance ofspeech-driven personal assistants even if this might be attractive for the purpose ofadvertising the potential of speech technologies.How well is Europe doing?No attempt has been made, so far, to annotate the technology timelines with indications ofhow well, or how badly, European research is doing and hence how likely it is that aparticular technology will be made deployable in Europe before anywhere else.
In most of thetimelined cases above, this would seem to depend primarily on the financial resources andresearch support mechanism which will be available to European research in the comingdecade.
In some cases, the US is presently ahead of Europe, such as with respect tocontinuous speech recognisers in workstations or broadcast transcription systems.
In othercases, Europe has the lead, such as in building a standard tool for cross-level, cross-modalitycoding of natural interactivity data, continuous speech recognisers in mobile devices,advanced spoken dialogue systems, and spoken car navigation systems.Beyond 2010Beyond 2010 lie the dreams, such as unlimited-vocabulary spoken conversational systems,unlimited-vocabulary spoken translation systems, unlimited on-line generation of integratednatural speech, lips, facial expression and gesture communication, unlimited on-lineunderstanding of natural speech, lips, facial expression and gesture communication byhumans, summarisation-to-specification of any kind of communication, multimodal systemssolutions on demand, and, of course, full natural interactive communication.4.
Implications of the TimelinesWhen analysing the implications of the timelines in Section 3, a number of uncertainties comeup with respect to how the market for speech products will develop.
At present, most speechproducts are being marketed by some 5-10 major companies world-wide.
These companiesare growing fast as are hundreds of small start-up companies many of which use basictechnologies from the larger technology providers.
It may be assumed that this marketstructure will not continue in the future.
Rather, speech recognition and synthesistechnologies would seem likely to become cheap, or even free and open source, componentswhich will come with all manner of software and hardware systems.
The implication is thatall ITC providers who want to, will provide value-added speech products and that the basicspeech technologies will not be dominated by a small number of large suppliers.
Someimportant share of the speech market, including de facto standards in various areas, willprobably be picked up by large custom software and mobile phone technology suppliers, suchas Microsoft and Nokia, but that is likely to happen in any realistic scenario for the comingdecade.
The conclusion is that, during the coming decade, speech will be everywhere, in allsorts of products made by all sorts of companies.
But will speech be everywhere in bulk?
Thisraises a second uncertainty.In one scenario, speech will be present in all or most ITC products by 2010, and speech willbe popular and will be used as much as input keys, input buttons, and output graphics displaysare being used today.
In another scenario, however, speech uptake will be slow and arduous.Several reasons could be given for the latter scenario.
Thus, (a) it may take quite some timebefore speech recognition is being perceived by users to be sufficiently robust to make usersswitch to speech where speech is better ideally.
(b) It may take quite some time before thefield and the market has sorted out when to use speech as a stand-alone modality and when touse speech in combination with other input/output modalities.
If these two (a + b) take-upcurves do not grow in any steep manner, speech may still be widespread by 2010, but speechwill still not be as important an input/output modality as it is likely to become later on.
For thetime being, we would appear to have too little information to be able to decide between thetwo scenarios just discussed.
There is simply not enough data available on user uptake ofspeech technologies to enable a rational decision to be made.Exploitation todayAlready today, there is a great exploitation potential for speech technologies because of thesimple facts that (i) the technologies which already exist in a few top languages could beported to hundreds of other languages, and (ii) the types of applications which already existcan be instantiated into numerous other applications of similar complexity.
At this end of thespeech technology spectrum, the emphasis is on flexible and versatile production platforms,quality products, and low-cost production rather than on research.
This is particularly true oflow-complexity over-the-phone spoken language dialogue information systems usingcontinuous speech input.
Users would seem to have adopted these systems to a reasonableextent already.
The same degree of user acceptance does not appear to characterise the uptakeof, e.g., spoken language dictation systems or simple spoken command systems for operatingscreen menus.
Even if purchased by widely different groups of users, the former wouldappear to be used primarily by professionals, such as lawyers and medical doctors, and thelatter hardly seems to be used at all.
Also, text-to-speech systems for the disabled andincreasingly for all users, do appear to have a significant exploitation potential already.Key technologies: speech-onlyThe timelines in Section 3 highlight a series of key speech-only technologies which are still atthe research stage, including:?
prosody in on-line speech synthesis;?
multi-speaker broadcast and meeting transcription;?
speech summarisation;?
speech translation; and?
conversational spoken dialogue.Prosody in on-line speech synthesisProsody in on-line speech synthesis is probably important to the speed of take-up of speechtechnologies because users would appear likely to prefer prosodic speech output to non-prosodic speech output.
However, there do not seem to exist firm estimates as to how muchprosody matters.
Reasonably clear and intelligible non-prosodic text-to-speech already existsfor some top languages and might turn out to be satisfactory for most applications in theshort-to-medium term.Multi-speaker broadcast and meeting transcriptionMulti-speaker broadcast transcription forms the topic of massive US-initiated research at themoment and appears likely to start becoming widely used in practice relatively soon.
Likemeeting transcription technology, multi-speaker broadcast transcription technology has alarge potential for practical application as well as for acting as a driving force in speech andnatural language (text) processing research.
Once multi-speaker broadcast speech audio andmeeting speech audio can be useably transcribed so that first application paradigms for thesetechnologies have been achieved, the transcriptions can be further processed by othertechnologies, such as speech summarisation and speech translation technologies.
It would bevery valuable for European speech research if Europe could launch a meeting transcriptiontechnology evaluation campaign before the US (evaluation campaigns will be discussedbelow).Speech summarisationSpeech summarisation is being experimented with already, often by using text or transcribedspeech instead of raw speech data.
Speech and text summarisation technology includingintelligent speech and text search would seem to hold enormous potential by enabling users toobtain at-a-glance information on the contents of large repositories of information.
The sameapplies to related technologies, such as question-answer systems which enable the user toobtain answers to specific questions from large repositories of information.
Progress in thesefields is difficult because of the difficulty of the research which remains to be done.
However,the difficulties ahead are counter-balanced by expectations that far-less-than-perfect solutionscould help to establish first application paradigms which, in their turn, might help accelerateprogress.Speech translationDespite the embattled 40-year history of language (text) translation systems, speechtranslation is now being researched across the world because of the realisation that far-less-than-perfect paragraph-by-paragraph translation could yield useful applications in the shorterterm.
In their turn, those first application paradigms could serve as drivers of further progress.The German Verbmobil project (http://verbmobil.dfki.de/), for instance, demonstrated justhow difficult human-human spoken dialogue translation is.
Once application paradigms havebeen achieved, however, speech translation technology would appear set to gain an enormousmarket.
Still, it may take quite some time before there is a massive growth in the market forspeech translation products, due to the difficulty of the research which remains to be done.Conversational spoken dialogueFor some time, the term ?conversational spoken dialogue?
has been a catch-all for next-stepspoken language dialogue systems, such as those explored in the DARPA Communicatorproject.
However, the DARPA Communicator agenda remains focused on task-orienteddialogue, such as flight ticket reservation.
Even if conducted through mixed initiative spokendialogue in which the human and the machine exchange dialogue initiative in the course oftheir dialogue about the task, task-oriented spoken dialogue might not qualify asconversational spoken dialogue.
Conversational spoken dialogue is mixed-initiative, to besure, but in conversational spoken dialogue there is no single task and no limited number ofdistinct tasks which have to be accomplished.
Rather, spoken conversation systems may becharacterised as topic-oriented.
It is the breadth and complexity of the topic(s) on which thesystem is able to conduct conversation which determine its strength.
Research on spokenconversation systems is still limited.
Obviously, however, spoken conversation systems holdan enormous application potential because they represent the ultimate generalisation of thequalities which everybody seem to appreciate in task-oriented mixed initiative spokenlanguage dialogue systems.Key technologies: multimodal systemsIn addition to speech-only technologies, the timelines in Section 3 highlight a series ofmultimodal speech systems technologies which are still at the research stage in most cases,including:?
intelligent multimodal information presentation including speech;?
natural interactivity;?
immersive virtual reality and augmented reality.Intelligent multimodal information presentation including speechIntelligent multimodal information presentation including speech is a mixed bag of complextechnologies which do not seem to have any clear research direction at the present time.
Thereason is that the term multimodality, as pointed out in Section 2 above, refers to a virtuallyunlimited space of combinations of (unimodal) modalities.
Thus, Modality Theory (Bernsen1997b, 2001) has identified an exhaustive developers?
toolbox of unimodal input/outputmodalities in the media of graphics (or vision), acoustics (or hearing), and haptics (or touch)consisting of more than a hundred unimodal modalities.
The number of possible combinationsof these unimodal input/output modalities is evidently staggering and, so far, at least, no wayhas been found to systematically generate a subset of good and useful modality combinationswhich could be recommended to system developers.
The best current approach is to listmodality combinations which have been found useful already in experimental or developmentpractice.
Obviously, given the limited exploration of the space of possible modalitycombinations which has taken place so far, those combinations constitute but a tiny fractionof the modality combinations which eventually will be used in HHSI.
The same lack ofsystematicity applies to the subset of useful modality combinations which include speechoutput and/or speech input.
Thus, for instance, it is known that speech and static graphicsimage output is a useful modality combination for some purposes and that the same holds forcombined speech and pen input into various output domains as well as for speech andpointing gesture input into, e.g., a static graphics map output domain.
The qualifying termintelligent is being used to distinguish intelligent multimodal information presentationsystems from traditional multimedia presentations.
In traditional multimedia presentations,the user uses keyboard and mouse (or similar devices) to navigate among a fixed set of outputoptions all of which have been incorporated into the system at design-time.
In intelligentmultimodal information presentation systems, the system itself generates intelligentmultimodal output at run-time.
This may happen through run-time language and/or speechgeneration coordinated with run-time graphics image generation and in many other ways aswell.
Some years ago, a reference model for intelligent multimodal information presentationsystems was proposed by an international consortium of developers (Computer Standards andInterfaces 18, 6-7, 1997).
Since then, little systematic development has happened, it appears,which is probably due to the fact that the field is as open-ended at it is.
Still, it would appearthat (i) the field of intelligent multimodal information presentation systems is an extremelypromising approach to complex interactive information presentation, such as in interactivesystems for instruction tasks for which several output modalities are needed, includingspeech.
In order to advance research in this field, research is needed on Modality Theory inorder to identify potentially useful modality combinations as well as on next-steparchitectures and platforms for intelligent multimodal information presentation.Natural interactivityAs argued in Section 2, fully natural interactive systems represent a necessary vision for alarge part of the field of interactive systems.
Furthermore, spontaneous speech input/output isfundamental to natural interactive systems.
Given this (latter) fact, it would seem that speechresearch is set to take the leading role in the development of increasingly natural interactivesystems.
Already today, this research and development process can be broken down into acomprehensive, semi-ordered agenda of research steps.
The steps include, at least, (i)fundamental research on human communicative behaviour, including identification of therelevant phenomena which are being coordinated in human behaviour across abstractionlevels and modalities, such as speech prosody and facial expression; validated codingschemes for these phenomena; and standard tools for coding the phenomena in order to createresearch and training resources in an efficient and re-usable fashion; (ii) speech and graphicsintegration in order to achieve full run-time coordination of spoken output with lipmovement, facial expression, gaze, gesture and hand manipulation, and bodily posture; (iii)speech and machine vision integration in order to enable the system to carry out run-timeunderstanding of spoken input in combination with lip movement, facial expression, gaze,gesture and hand manipulation, and bodily posture; and (iv) conversational spoken dialogueas discussed above.
Other relevant technologies include, i.a., machine learning and 3Dgraphics modelling of human behaviour.
Although research in underway on (i) through (iv),there is no doubt that the field might benefit strongly from a focused effort which couldconnect the disparate research communities involved and set a stepwise agenda for achievingrapid progress.
The application prospects are virtually unlimited, as witnessed by theconsensus in the field that increased natural interaction tends to generate increased trust inHHSI.Immersive virtual reality and augmented realityIt is perhaps less clear what are the speech technology application prospects of immersivevirtual reality.
Today, immersive virtual reality requires that users are wired up with 3Dgoggles, force feedback data gloves, data suits, and/or wired surfaces and other wiredequipment, such as flight cockpits or bicycles.
At the present time, it seems uncertain towhich extent and for which purposes immersive virtual reality technologies will be founduseful in the future.
The primary purposes for which these technologies are being used to dayare advanced technology exhibition and demonstration, and the building of rather expensivesimulation setups, such as flight simulators.
Furthermore, it is far from clear which role(s)speech will come to play in immersive virtual environments.
These remarks also apply toaugmented reality technology.Other research and supporting measures neededIn order to promote efficient research progress on advanced interactive systems which includespeech as a modality, technology research is far from sufficient.
As pointed out in Section 2,present and future advanced systems research takes place in an extremely complex context inwhich leading research efforts must incorporate global state-of-the-art developments in manydifferent fields.
World-leading speech-related systems research should be accompanied by thefollowing kinds of research, at least:?
state-of-the-art generic platforms;?
generic architectures;?
hardware;?
specialised best practice in development and evaluation;?
standard re-usable resources;?
behavioural research;?
neural basis for human natural communicative behaviour;?
design of form and contents;?
porting technologies to languages, cultures and the web;?
the disabled;?
maintenance for uptake.State-of-the-art generic platformsIn order to effectively aim at exploitable results from early on, speech-related systemsresearch needs to build upon existing state-of-the-art generic platforms including APIs.
If astate-of-the-art generic platform is not available to the researchers, either because it does notyet exist or because it is inaccessible for proprietary reasons, researchers have to build itthemselves.
This is not possible in small-scale research projects which have an additionalresearch agenda which presupposes a working platform.
The consequence is that the researchproject will either build upon some sub-optimal platform in order to complete the researchagenda, or build a better platform but not complete the research agenda.
Both consequencesare unacceptable, of course, but the former may work temporarily if the research aims arevery advanced ones.
However, when the research aims have been achieved or, at least,somehow explored, there will typically be no practical way of continuing the research in orderto produce a state-of-the-art generic platform which could bring the research results towardsthe market.
Two implications seem to follow: (i) it would be highly desirable if companiescould be encouraged to make their most advanced platforms accessible to researchers.
(ii) If astate-of-the-art generic platform is missing altogether, it should either be produced in aseparate project or projects should be made so large as to include platform development.
Bothimplications would seem to require a transformation of existing European research fundingmechanisms.Generic architecturesIt would seem likely that overall research speed and efficiency in Europe could be acceleratedby research on generic architectures for future systems, such as conversational spokendialogue systems, intelligent multimodal information presentation systems which includespeech, or natural interactive systems.
In the absence of research initiatives on genericarchitectures for future systems, research projects are likely to specify idiosyncraticarchitectures which may satisfy their present needs but which do not sufficiently take intoaccount global developments nor prepare for the next steps in advanced systems development.For the time being, there does not appear to be any European speech-related initiative in thisfield apart from the CLASS project which was launched in the autumn of 2000(http://www.class-tech.org/).
For efficiency, work on generic architectures should be done asa collaborative effort between many small-scale research projects and industry as in CLASS,or between a medium-scale research project and industry.HardwareIncreasingly, advanced systems demonstrators require hardware design and development.
Formany research laboratories, this is a new challenge which they are ill-prepared to meet.Moreover, there is no strong tradition for involving hardware producers in the field of speechtechnologies, primarily because the need for involving them is a rather recent one.
Ways mustbe found to forge links with leading hardware producers in order to make emerging hardwareavailable to researchers.
This problem has much in common with the platform issue discussedabove.Specialised best practice in development and evaluationAdvanced speech systems research is conducted in a software engineering space bounded by,on the one hand, general software engineering best development and evaluation practice and,on the other, emerging ISO standards and de facto standards imposed by global industrialcompetition.
Between these boundaries lies software engineering best practice in developmentand evaluation specialised for various speech-related systems and component technologies.This field remains ill-described in the literature.
Apart from the DISC project on best practicein the development and evaluation of spoken language dialogue systems (www.disc2.dk),some work on evaluation in EAGLES Working Groups during the 1990s(http://www.ilc.pi.cnr.it/ EAGLES96/home.html), various national evaluation campaigns, andplanned work in CLASS, little work has been done in Europe.
By contrast, massive work hasbeen done on component evaluation in the US over the last fifteen years.
The result is that thespeech-related technology field is replete with trial and error, repetitions of mistakes, andgenerally sub-state-of-the-art approaches.
These negative effects are multiplied by thepresence in the field of a large number of developers who are new to the field.Admittedly, the field of software engineering best practice in development and evaluationspecialised for various speech systems and component technologies is difficult and costly todo something about under present conditions.
Technology evaluation campaigns are costly todo and require serious logistics.
Yet the US experience would seem to indicate thattechnology evaluation campaigns are worth the effort if carried out for key emergingtechnologies including some of the technologies described in this paper.
When a technologyhas gone to the market, industry does not want to participate any more and rather wants, e.g.,evaluation toolkits for internal use.
For emerging technologies, however, technologyevaluation campaigns are an efficient means of producing focused progress.
In fact, allparticipants tend to become winners in the campaigns irrespective of their comparativescorings according to the metrics employed, because everybody involved learns how toimprove, or when to discard, their technologies and approaches.
For Europe, technologyevaluation campaigns for key emerging technologies could be a means of creating lastingadvances on its global competitors.
In order to take care of the complex logistics needed forthe campaigns, it is worth considering to establish a European agency similar to the US NIST(National Institute for Standards in Technology) whose comprehensive experience withtechnology evaluation campaigns makes it comparatively easy to plan and launch campaignsin novel emerging technologies.
Alternatively, NIST might be asked to undertake to runtechnology development and evaluation campaigns in Europe, provided that this does notoffend political and industrial sensibilities too much.Effective development best practice work specialised for speech technologies is difficult to dounder the current European funding mechanisms.
The reason is that development best practicework requires access to many different components, systems and approaches in order tocreate an effective environment for the discussion and identification of best practice.
Thisenvironment can only be established across many different small-scale projects or withinmedium-scale projects.
CLASS is the first example of such an environment.Standard re-usable resourcesThe term resources covers raw data resources, annotated data resources, annotation schemesfor data annotation, and annotation tools for efficient automatic, semi-automatic or manualannotation of data.
Resources are crucial for many different purposes, such as research intocoding schemes or the training of components.
Also, resources tend to be costly to produce.This means that, if the relevant resources are not available, research projects often take theeasy way out which is to use less relevant but existing and accessible resources for theirresearch.
The results are sub-optimal research results and slowed-down progress.
Common toresources of any kind is the need for standardisation.
If some resource is not up to therequired standards, its production is often a waste of effort because the created resourcecannot be used for anything useful.
In its strategy paper from 1991, ELSNET(http://www.elsnet.org/) proposed the establishment of a European resources agency.
Thisrecommendation was adopted through the creation of ELRA (European Language ResourcesAgency http://www.icp.inpg.fr/ELRA/ home.html) in 1995.
ELRA is now a world-recognisedcounterpart to the US LDC (Linguistic Data Consortium, http://www.ldc.upenn.edu/).
Still,ELRA is far from having the capacity to produce on its own all the resources and standardsneeded for efficient research progress.
By contrast with technology evaluation campaigns,Europe has been active in the resources area during the 1990s.
Today, there is a strong need tocontinue activities in producing publicly available resources and standards for advancednatural language processing, natural interactive systems development, evaluation campaignsas described above, etc.
Recently, the ISLE (International Standards for LanguageEngineering) Working Group on Natural Interactivity and Multimodality(http://www.isle.nis.sdu.dk) has launched cross-Atlantic collaboration in the field of resourcesfor natural interactivity and multimodality.Behavioural researchHumans are still far superior to current systems in all aspects of natural interactivecommunication.
Furthermore, far too little is known about the natural interactive behaviourwhich future systems need to be able to reproduce as output or understand as input.
There is astrong need for basic research into human natural communicative behaviour in order to chartthe phenomena which future systems need to reproduce or understand.
This research willimmediately feed into the production of natural interactive resources for future systems andcomponents development, as described above.Neural basis for human natural communicative behaviourRelated to, but distinct from, basic research into human natural communicative behaviour isbasic research into the neural basis for human natural communicative behaviour.
In theheydays of cognitive science in the 1980s, many researchers anticipated steady progress in thecollaboration between research on speech and language processing, on the one hand, andresearch into the neural machinery which produces human speech and language on the other.However, massive difficulties of access to how human natural communicative behaviour isbeing produced by the brain turned out to prevent rapid progress in linking neuroscience withspeech and language processing research.
Today, however, due to the availability oftechnologies such as MR imaging and PET scanning, as well as the increasing sophisticationof the research agenda for the speech technology field, the question arises if it might be timelyto re-open the cognitive science agenda just described.
Potential results include, amongothers, input to generic architecture development (cf.
above), identification of biologicallymotivated units of processing, such as speech and lip movement coordination, andidentification of biologically motivated modalities for information representation andexchange.
Relevant research is already going on in the field of neuroscience but, so far, fewlinks have been established to the fields of speech technologies and natural interactivesystems more generally.Design of form and contentsYet another consequence of the increasing emphasis on systems as opposed to systemcomponents is the growing importance of form and contents design.
It is a well-establishedfact that design and development for the web requires skills in contents design and contentsexpression which are significantly different from those which have been developed throughcenturies for text on paper.
In order to develop good demonstrator systems for the web orotherwise, there is a need for strongly upgraded skills in the design and expression ofmultimodal digital contents.
For instance, it is far from sufficient to have somehow gleanedthat speech might be an appropriate modality for some intelligent multimodal informationpresentation instruction system and to have available a state-of-the-art development platformfor building the system.
To actually develop the system, professional expertise in form andcontents design is required.
At the present time, few groups or projects in the speech field areadequately staffed to meet this challenge.Porting technologies to languages, cultures and the webRight now, the gap between the ?have?
countries whose researchers have access to advancedspeech and natural interactivity components and platforms, and the ?have-not?
countrieswhose researchers cannot use those technologies for their own purposes because they speakdifferent languages and behave differently in natural interactive communication, seems to beincreasing.
There is therefore a need to port advanced technologies to different languages andcultures both in Europe and across the world.
The market will close the gap eventually in itsown way, of course.
However, in order to rally the full European research potential in thefield in a timely fashion, it would appear necessary to actively stimulate the porting oftechnologies to new languages and cultures.
From a research point of view, the best way tomake this happen might be to include in medium-to-large-scale projects the best researchersfrom ?have-not?
countries even if, by definition, those researchers have to spend significanttime catching up on basic technologies and resources before being able to activelycontributing to the research agenda.There is another sense of the ?porting technologies?
-phrase in which Europe as a whole risksfalling behind global developments.
It is that of porting speech, multimodal and naturalinteractivity technologies to the web.
The claim here is not that this is not happening already.The claim is that this cannot happen fast enough.
In order to increase the speed of portingtechnology to the web, it would seem necessary to strongly promote advanced componentsand systems development for the web.
It is far from sufficient to wait until some non-speechtechnology has been marketed for the web, such as electronic commerce applications, andthen try to ?add speech?
to the technology.
A much more pro-active stance would appearadvisable, including a strongly increased emphasis on form and contents design as arguedabove.The disabledAdvanced technologies for the disabled have a tendency to lag behind technologydevelopment more generally for the simple reason that the potential markets for technologiesfor the disabled are less profitable.
Correspondingly, advanced technologies development forthe disabled tends to be supported by small separate funding programmes rather than beingintegrated into mainstream programme research.
In many cases, however, it would appear thatsystems and components technologies could be developed for any particular group of usersbefore being transferred into applications for many other user groups.
To the extent that this isthe case, there may be less of a reason to confine the development of technologies for thedisabled to any particular research sub-programme.Maintenance for uptakeFinally, the small-scale science paradigm of small and isolated research projects does not atall cater for the fact that, in the complex world of advanced systems research, a wealth ofprototype systems, proto-standard resources, web-based specialised best practice guides, etc.,are being produced which have nowhere to go at the end of the projects in which they weredeveloped.
Their chances of industrial uptake, re-use by industry and research, impact ontheir intended users, etc., might become very substantially increased if it were possible tomaintain them and make them publicly accessible for, say, two years after the end of projects.For this to happen, there is a need for (i) a stable web portal which can host the results, suchas the present HLT (Human Language Technologies) portal under development(http://www.HLTCentral.org); (ii) open source clauses in research contracts for technologieswhich have nowhere to go at the end of a project; and (iii) financial support for maintenance.These requirement are likely to impose considerable strain of current European researchsupport mechanisms.
However, with some legal effort and a modest amount of financialsupport, the many research results produced in the speech-related field in Europe which arenot being taken up immediately and which are not within the remit of ELRA, could gainmuch more impact than is presently the case.5.
Proposed ActionsEarly preparations for the European Commission?s 6th Framework Programme (FP6)including IST (Information Society Technologies) research are now in progress.
It ispremature to make predictions with any degree of certainty as to how the IST part of FP6 willshape up.
Current information suggests an increased emphasis on basic research compared tothe present FP5.
In addition, it is possible that FP6 will include opportunities for the medium-scale research initiatives which were called for on several occasions above, i.e.
large-scale?clusters?
of projects all addressing the same research topic in a coordinated fashion.
Finally,the current covering title for FP6 IST research is ?ambient intelligence?
which is one of theterms of fashion quoted in the present paper.
Given the timelines and their analysis above, itdoes not seem to matter much which covering term is being chosen for FP6.
?Ambientintelligence?
is as apt as several others for FP6 and future advanced interactive systemsresearch but, as argued in Section 3, it is far from clear if ambient intelligence requires us tofocus on any particular segment of future speech-related technologies.
However, the possible,increased emphasis on basic research as well as the possibility of carrying out medium-scalescience in speech-related technologies are to be welcomed in the light of the argument above.5.1 Research priorities for speech-related technologies 2000-2010Taking into our stride the transformations of the field of speech-related research from speech-only to interactive systems in general, and from components research to interactive systemsresearch, the top priorities in speech-related technologies research are:?
multi-speaker meeting transcription development and evaluation campaigns;?
speech summarisation development and evaluation campaigns;?
speech translation prototypes, generic platforms, and generic architectures.Development and evaluation campaigns are highly desirable;?
conversational spoken dialogue prototypes, generic platforms, and genericarchitectures.
Development and evaluation campaigns are highly desirable;?
next-step prototypes, generic platforms, and generic architectures for intelligentmultimodal information presentation;?
next-step prototypes, generic platforms, and generic architectures for naturalinteractive systems.As soon as theoretically and practically feasible, all of the above advanced speech,multimodal and natural interactivity technologies should be developed for the web includinghardware, form and contents design.
The fact that some top research priorities have beenmentioned above emphatically does not preclude the desirability of continuing ?business asusual?
in the field of speech-related research, including continued research into all of thetechnologies which have been mentioned earlier in the present paper.
On the contrary,business as usual is actually assumed by the above top priorities list which focuses ontechnologies over and above business as usual.
This also applies to next-step research intoalready deployed speech-related technologies, such as mixed initiative, task-oriented spokendialogue systems.For basic research leading to novel concepts, theories and formalisations, the top prioritiesare:?
basic research into human natural communicative behaviour;?
a novel theory of natural communication which can replace speech acts theory anddiscourse theory by taking the notion of a complete communicative act as its basicnotion;?
research on Modality Theory in order to identify potentially useful modalitycombinations;?
establishment of collaborative links to research into the neural basis for human naturalcommunicative behaviour.5.2 Research organisation neededMedium-scale science is needed for, at least, the coordinated development of naturalinteractive systems prototypes, generic platforms, generic architectures, best practice indevelopment and evaluation, and standard resources.
A large, medium-scale science projectwith these objectives should include the porting of technologies to new languages andcultures.It is quite possible that the medium-scale science model could be applied to research intoother speech-related technologies, such as speech translation technologies, conversationalspoken dialogue systems, or speech technologies for ambient intelligence.For researchers in small-scale speech-related projects, in particular, the creation of a genericplatforms and hardware ?bourse?
through contributions from European industry would be ofgreat importance.Finally, we should stop having research programme ghettos for technologies for the disabled.5.3 Infrastructural actions neededIn order to promote maximum uptake of the research results produced, it would be highlydesirable to have funding for low-cost ways of maintaining research results for later uptake.Given the emphasis on technology development and evaluation campaigns above, Europeneeds to establish an evaluation and standards agency.
It is not evident to the present authorthat current political and industrial sensibilities would allow the US NIST to undertake to runtechnology development and evaluation campaigns in Europe.This having been said, there is much to be said for increasing global collaboration on manyaspects of speech-related research, such as creating a coordinated global infrastructure forresources distribution.ReferencesBenoit, C., Martin, J. C., Pelachaud, C., Schomaker, L., and Suhm, B.: Audio-Visual andMultimodal Speech-Based Systems.
In D. Gibbon, I. Mertens and R. Moore (Eds.
):Handbook of Multimodal and Spoken Dialogue Systems.
Dordrecht: Kluwer AcademicPublishers 2000, 102-203.Bernsen, N.
O.
(1997a): Towards a tool for predicting speech functionality.
SpeechCommunication 23, 1997, 181-210.Bernsen, N. O.
(1997b): Defining a Taxonomy of Output Modalities from an HCIPerspective.
Computer Standards and Interfaces, Special Double Issue, 18, 6-7, 1997, 537-553.Bernsen, N. O.: Multimodality in language and speech systems - from theory to designsupport tool.
In Granstr?m, B.
(Ed.
): Multimodality in Language and Speech Systems.Dordrecht: Kluwer Academic Publishers 2001 (to appear).CLASS: http://www.class-tech.org/Computer Standards and Interfaces, Special Double Issue, 18, 6-7, 1997.DARPA Communicator: http://fofoca.mitre.org/DISC www.disc2.dkEAGLES: http://www.ilc.pi.cnr.it/EAGLES96/home.htmlELRA: http://www.icp.inpg.fr/ELRA/home.htmlELSNET http://www.elsnet.org/i3: http://www.i3net.org/ISLE: http://www.ilc.pi.cnr.it/EAGLES96/isle/ISLE_Home_Page.htmISLE Working Group on Natural Interactivity and Multimodality: http://www.isle.nis.sdu.dkHLT portal: http://www.HLTCentral.orgLDC http://www.ldc.upenn.edu/SmartKom: http://smartkom.dfki.de/start.htmlVerbmobil: http://verbmobil.dfki.de/
