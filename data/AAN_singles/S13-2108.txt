Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 651?659, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsUTurku: Drug Named Entity Recognition and Drug-Drug InteractionExtraction Using SVM Classification and Domain KnowledgeJari Bjo?rne, Suwisa Kaewphan and Tapio SalakoskiTurku Centre for Computer Science (TUCS)Department of Information TechnologyUniversity of TurkuJoukahaisenkatu 3-5B, 20520 Turku, Finlandfirstname.lastname@utu.fiAbstractThe DDIExtraction 2013 task in the SemEvalconference concerns the detection of drugnames and statements of drug-drug interac-tions (DDI) from text.
Extraction of DDIsis important for providing up-to-date knowl-edge on adverse interactions between co-administered drugs.
We apply the machinelearning based Turku Event Extraction Sys-tem to both tasks.
We evaluate three fea-ture sets, syntactic features derived from deepparsing, enhanced optionally with features de-rived from DrugBank or from both DrugBankand MetaMap.
TEES achieves F-scores of60% for the drug name recognition task and59% for the DDI extraction task.1 IntroductionDrug-drug interactions (DDI) refer to one drug af-fecting the function of another when they are co-administered.
These interactions are often adverse,frequently not well known and a source of poten-tially life-threatening unintended consequences forthe patients.
Databases such as DrugBank and Mi-cromedex have been developed to store informa-tion about known DDIs, but at present their cover-age remains limited and there can be inconsistenciesin supplementary information (Knox et al 2011;Wong et al 2008).
Text mining has been proposedas a solution for providing not only lists of DDIsbut also a connection to the scientific evidence andsupplementary information in the literature (Tari etal., 2010).
Several groups of researchers are devel-oping text-mining techniques to extract DDIs fromliterature and pharmaceutical documents (Tari et al2010; Segura-Bedmar et al 2011a).The DDIExtraction 2013 shared task concerns thedetection of drug mentions and statements of DDIsfrom unannotated text (Segura-Bedmar et al 2013).The first version of the DDIExtraction shared taskwas organized in 2011, with 10 teams participat-ing from various universities (Segura-Bedmar et al2011b).
The best result of 65.74% was achievedby team WBI of Humboldt University of Berlin(Thomas et al 2011).
University of Turku partic-ipated also in this task, placing 4th with an F-scoreof 62.99%, using the Turku Event Extraction System(Bjo?rne et al 2011).The Turku Event Extraction System (TEES)1 isan open source program for extracting events and re-lations from biomedical texts.
It was originally de-veloped for extracting events in the BioNLP SharedTask scheme, and it models event extraction as agraph generation task, where keywords are nodesand the event arguments connecting them are edges.The system can be directly applied to pairwise re-lation extraction, representing relations as edges andthe words they connect as nodes.
The node detectionsystem is somewhat similar to named entity recog-nition (NER) tools, and while quite flexible, can inmany tasks exhibit lower performance and higherprocessing requirements than dedicated NER sys-tems.In the DDIExtraction 2013 task we apply theTurku Event Extraction system to detecting bothdrug name entities (task 9.1) as well as drug-druginteractions (task 9.2).
We evaluate three different1http://jbjorne.github.com/TEES/651feature sets for both tasks.
As a baseline system deepsyntactic parsing is used to generate large graph-based feature sets.
For additional features, we testthe impact of labeling examples with informationfrom external sources.
We test both the DrugBankOpen Data Drug & Drug Target database (Knox etal., 2011) as well as the MetaMap tool to enrich thefeatures derived from the corpus text.MetaMap is a publicly available program devel-oped at NLM for automatic mapping of texts toUMLS Metathesaurus concepts (Aronson, 2001).The UMLS Metathesaurus is an extensive reposi-tory of biomedical vocabularies that is derived fromNLM databases and other external sources that con-tain information about biomedical concepts, syn-onyms and the relationship among them (Bodenrei-der, 2004).The version of TEES used in the 2011 DDIEx-traction task had been publicly available as an opensource project since July 2012, but as small mod-ifications were required for compatibility with the2013 task, we published an updated 2.1 version thattask participants could use.
To simplify utilization ofthe numerous analyses TEES produces we also pro-vided our drug-drug interaction predictions freelyavailable for all DDIExtraction 2013 task partici-pants in the hope of encouraging further participa-tion in this interesting shared task.We demonstrate that TEES has good performancefor both drug name detection as well as drug-druginteraction detection, achieving an F-score of 60%in the drug name detection task 9.1 and an F-score of59% in the drug-drug interaction detection task 9.2.We show that external information from DrugBankand MetaMap can considerably improve extractionperformance, but observe that the use of such in-formation must always depend on the exact require-ments of each text mining task.2 MethodsWe present a unified approach to drug name andDDI extraction, utilizing largely the same machinelearning approaches in both tasks.
We develop threevariants for tasks 9.1 & 9.2 each, testing the base-line performance of TEES for these tasks, as well asthe impact of using external databases as additionaltraining data.2.1 Turku Event Extraction SystemThe Turku Event Extraction System is described indetail in Bjo?rne et al(2012).
Here we give a gen-eral overview about applying the system for the cur-rent task.
TEES processes text in a pipeline of com-ponents, starting from preprocessing tasks such asNER and parsing and proceeding to the multiple,consecutive steps of event extraction.
As tasks 9.1and 9.2 are independent of each other the entity andinteraction detection components of TEES are usedindependently, and for preprocessing, only the pars-ing is done (See Figure 1).2.2 Training data preparationTEES is a machine learning system based on sup-port vector machines (SVM) (Tsochantaridis et al2005).
To train the system for a new task, twodatasets are required: a training set on which theSVM model is trained, and a development set onwhich the newly trained model is tested to deter-mine parameter settings for optimal performance(See Figure 2).
The optimal model can then beused to detect what it was trained for on unannotateddatasets, such as the hidden shared task test set.The DDIExtraction 2013 corpus consists of twoparts: A training corpus used for system develop-ment and a test corpus for evaluating the participat-ing systems.
The annotation of the test corpus is notrevealed to task participants.
To develop the system,we estimate performance on the training corpus us-ing 10-fold cross validation.
To provide the datasetsTEES requires, the training corpus is randomly di-vided (on the document level) into ten parts.
Forpredicting drug names or DDIs for each part, sevenof the remaining nine parts are used as a trainingset and two as a development set for parameter opti-mization.
When producing the final models for clas-sifying the test corpus, five parts of the training cor-pus are used for training and the other five for pa-rameter optimization.
In both cases, the parameteroptimization set is merged with the training set whenproducing the final model for classifying the test set.The DDIExtraction 2013 corpus is provided in anXML format originally introduced as a unified for-mat for several pairwise protein-protein interaction(PPI) corpora (Pyysalo et al 2008).
TEES uses avariant of this format as its internal data representa-652DrugAminoglutethimide the of Drugcoumarin and Drugvarfarin .diminishes effecteffect effectA BNN DT IN NN CC .conj_and><dobj prep_of>NNprep_of>VBZ<nsubj <det NNpunct>Drug(Aminoglutethimide) Drug(coumarin)effectDrug(warfarin)effect negFigure 1: TEES graph representation for drug name and interaction extraction, with example sentence DDI-DrugBank.d372.s2 from the DDIExtraction 2013 training corpus.
A) Both the annotation (above the sentence) and thesyntactic parse (below the sentence) are represented as graphs.
Tokens form the nodes and dependencies the edges ofthe syntactic parse graph.
Drug names form the nodes and DDIs the edges of the annotation graph.
Drug name entitiesare linked to their syntactic head tokens, connecting the two graphs and allowing the parse to be used as a source offeatures.
For DDI edges, most features are derived from the shortest path of dependencies connecting the two drugentities.
B) For DDI extraction, one example is generated for each interaction type for each undirected pair of drugentities.
The gray neg class edge is a negative example.A) Corpustrain classifyparam.train classifyparameterstraindevelmodeltestmodeltestdatatestdataTraining corpus Test corpusC) Training the Final Model0 1 2 3 4 5 6 7 8 9train classifyparameterstrain classifyparameterstraindevelmodeltestmodelB) 10-fold cross-validation (for each set 0-9, shown for #9)90 1 2 3 4 5 6 7 80 1 2 3 4 5 6 7 8 9Figure 2: DDIExtraction 2013 corpus.
A) To evaluate performance, and to provide analyses for the full trainingcorpus, the training corpus is divided for 10-fold cross validation.
B) Each of the ten parts is classified using seven ofthe remaining parts for training the model and the last two for optimizing parameters.
After parameter optimization,all nine parts are used to train the model (with the optimal parameters) for classifying the test set.
C) To classify thehidden DDIExtraction 2013 corpus half of the training corpus is used for training and the other half for determiningoptimal parameters.
The test corpus is finally classified with a model trained using the full training corpus.653tion.
While close to the DDIExtraction 2013 format,some differences exist, so we preprocess the corporafor compatibility with TEES.
Namely, ddi elementsare renamed as interaction elements, entity elementsin task 9.2 are tagged with the given attribute to markthem as pre-annotated data for TEES and all charac-ter offsets are converted to the TEES format by in-creasing the end offset by one, resulting in spans de-noted with the beginning character and end charac-ter plus one, a common convention in programminglanguages such as Java and Python.Before use, all DDIExtraction 2013 corpora areparsed with the TEES preprocessing pipeline, usingthe BLLIP parser with David McClosky?s biomodelto produce a Penn-tree style parse which is con-verted with the Stanford parser tools to the collapsedCC processed Stanford dependency scheme (Char-niak and Johnson, 2005; McClosky, 2010; de Marn-effe et al 2006).2.3 Drug name recognition with TEESFor drug name recognition the TEES entity detectormodule is used.
Baseline syntactic features (model1) are generated from the parse, using both informa-tion on the tokens and their linear context, as wellas dependency chains starting from the entity headtoken.
External data is added to the head token fea-tures, from where it is combined into more complexfeatures.
One example is generated for each token inthe sentence, and these are classified into negativesor one of the positive classes.As a new feature we generate all substrings start-ing from the first and last characters of the drugname, with the intention of detecting common pre-fixes and suffixes among the drug names.2.4 Drug-drug interaction detection with TEESFor DDI extraction we use the TEES edge detec-tor module.
DDIs are typed, undirected edges, soone example is generated for each undirected pair ofdrug name entities present in the sentence (See Fig-ure 1).
The baseline syntactic features (model 1) aregenerated mostly from the shortest path of depen-dencies connecting the pair of drug name entities?head tokens.
From this shortest path several featuregroups are generated, including N-grams of variouslengths, governor?dependent information for depen-dencies etc.
External data is added into the two drugname entities, and combined into the path features.We also use the TEES modification from DDIEx-traction 2011 task where conj and dependencies areignored when calculating the shortest path, with theaim of including more of the relevant interactionwords in the path.2.5 Using DrugBank for Domain KnowledgeDrugBank2 is a public database of information ondrugs and drug targets.
We use the downloadableXML version of the database.For drug name recognition, for each candidate to-ken, we add as features its presence as a knowndrug name in DrugBank and the synonym, brand,group and category annotations this drug may have.We also mark whether the candidate token exactlyequals an annotation of one of these types, indicatingcases where the token is e.g.
a known brand name.For DDI extraction, we mark as a feature whetherthe drug name pair is listed in DrugBank as havinginteractions or not.
We also mark if one of the drugnames is not listed in DrugBank.2.6 Using MetaMap for Domain KnowledgeThe MetaMap program has been used extensivelyfor a wide array of BioNLP studies, such as auto-matic indexing of biomedical literature and concept-based text summarization (Reeve et al 2007;Quanzhi and Yi-Fang Brook, 2006).
For drug-related information extraction, two recent applica-tions demonstrated that integrating the MetaMapprogram to their existing systems produces highoverall performance in i.)
identification and clas-sification of the pharmaceutical substances and ii.
)extraction of drug indication information (Segura-Bedmar et al 2008; Fung et al 2013).MetaMap finds Metathesaurus concepts by per-forming a shallow syntactic analysis of the inputtext, producing a set of noun phrases.
The nounphrases are then used to generate sets of variantswhich are consequently looked up from the Metathe-saurus concepts.
Matching concepts are evaluatedagainst the original text and the strength of the map-pings are calculated.
The candidates are finallycombined and the final scores are computed, wherethe highest score of a complete mapping represents2http://www.drugbank.ca/654MetaMap?s interpretation of the text.The MetaMap program can be run both lo-cally and remotely3.
We ran the current version,MetaMap2012, remotely via the batch mode facil-ity by converting the sentences of the DDIExtrac-tion corpora into the MetaMap input format.
Manyof the applications that integrate MetaMap into theirsystems use the default settings that are claimed tobe suitable for general purposes.
However, we ap-plied different options with the aim of increasingthe coverage of Metathesaurus concepts found byMetaMap.
The parameter set that influences theperformance of MetaMap included; using a relaxedmodel, selecting the NLM2012AB Metathesaurusversion, including all derivational variants, enablingunique acronym/abbreviation variants only, allow-ing candidates from one or two character words, pre-ferring multiple concepts and using word sense dis-ambiguation.The Relaxed Model is provided by MetaMap inaddition to the strict model which is offered as adefault setting in which all types of filterings areapplied.
However, we chose the relaxed model inwhich only manual and lexical filterings are used.While the strict model is most appropriate for exper-iments that require the highest accuracy, it coversonly 53% of the Metathesaurus strings.
As we con-sider high coverage of concepts an important factor,we applied the relaxed model which consists of upto 83% of Metathesaurus strings.The versions of Metathesaurus, Base, USAbaseand NLM, provided with MetaMap are differentin their Metathesaurus coverage and the licensetype required for using vocabulary sources.
TheNLM2012AB version which is offered at no costfor research purposes and covers all of the providedMetathesaurus was used in our work.Variants, such as inflectional and derivationalvariants, are computed by MetaMap to account forthe textual variation in the text.
With this setting,many types of variants are generated recursively, andonly acronyms and abbreviations are restricted to theunique ones.
In addition, the candidates also includewords that can be prepositions, conjunctions or de-terminers if they occur often enough in Metathe-saurus.3http://metamap.nlm.nih.gov/Prefer multiple concepts causes MetaMap toscore the mappings with more concepts higher thanthose with fewer concepts.
This option is useful fordiscovering higher-order relationships among con-cepts found in the text and as such is assumed to behelpful for discovering the DDIs.Word sense disambiguation attempts to solve lex-ical ambiguities by identifying the correct meaningof a word based on its context.
By using this optionin MetaMap, the program attempts to solve the am-biguities among equally scoring concepts by choos-ing the concept(s) based on semantic type.We use the XML version of the MetaMap out-put which is post-processed by TEES to extract rel-evant features; candidate concepts, preferred con-cepts, CUI (Concepts Unique Identifier), score, se-mantic types and sources.For drug name recognition, these are added as bi-nary features for the candidate token, with the ex-ception of the score, the value of which is normal-ized into the [0, 1] range.
For DDI extraction, thebinary features are added for the two drug names,and combined into the shortest path features.2.7 Public analysesThe TEES 2.0 system used in DDIExtraction 2011Shared Task has been public since summer 2012.While only small modifications are needed to makethe DDIExtraction 2013 corpus usable with theTEES system, these can be complicated for newusers.
Therefore, to make sure our public DDIEx-traction 2011 system is usable not only in theory,but easy enough to use in practice, we updated thesystem into the 2.1 version capable of automaticallyconverting the DDIExtraction 2013 corpus and pro-vided with precalculated models for DDI prediction.To improve usability, we provided fully precal-culated analysis files for the DDIExtraction 2013corpus, produced using TEES 2.1.
These analysescontain the TEES drug-drug interaction predictions,BLLIP Penn tree-bank style parses (using the Mc-Closky biomodel), Stanford dependency parses (inthe collapsed CC processed format) and syntactichead offsets for drug entities.The analyses were calculated with the base-line TEES 2.1 system, without using the externaldatasets which were tested only later.
The analy-ses were provided for task 9.2, which is the direct655continuation of the 2011 task for which the publicTEES system was already available.The analyses for the DDIExtraction 2013 corpuswere made available on February 25th 2013.
De-spite being published quite late in the training pe-riod there was interest in this supporting data, andbefore the task result submission deadline the analy-ses were downloaded 14 times.
The test set analyseswere provided for registered DDIExtraction 2013participants during the test period.3 Results and DiscussionThree feature sets were used to produce the results.The baseline set (model 1) consisted of the TEESentity and edge detectors which build a large featureset from syntactic parses.
Model 2 adds DrugBankfeatures to this baseline and model 3 further extendsmodel 2 with MetaMap information.Three runs using these models were submitted forboth tasks 9.1 and 9.2.
The results indicate the sys-tem was capable of detecting both drug names anddrug-drug interactions with reasonable performance.The best F-scores were 60% for task 9.1 drug namedetection and 59% for task 9.2 DDI extraction.As task 9.1 is completely new, and task 9.2 wasextended from the 2011 DDI extraction task withtyped interactions and MEDLINE abstracts, the cur-rent results are not directly comparable with the2011 ones.
The evaluation metric closest to the 2011task is task 9.2 DDI detection regardless of type, us-ing only the DrugBank subset of the corpus.
Withthis metric, our system achieved an F-score of 72%in 2013 vs. 62.99% in 2011, which may indicatehigher baseline performance, potentially influencedby a larger training dataset.3.1 Drug name recognitionThe decision to not attempt detection of more thanone token per drug entity proved to be not too detri-mental to the final performance.
In the training cor-pus, there are 14,765 drug name entities of whichonly 2,768 (18.7%) consist of more than one to-ken, and of these only 38 are disjoint (not form-ing a continuous span).
For our best performingdrug name detection model (number 3) typed, par-tial span matching was at 78% F-score vs. typed,strict span matching at 65%.
Therefore, detectingonly a single token per entity resulted in a maximumloss of 13 percentage points (pp), but consideringthat a scheme designed to detect multi-token entitieswould be inherently more complex, potentially hav-ing lower performance, and that not all of the spanswould be correctly detected, we feel this tradeoff inperformance is worth it for the considerably moresimple system design it allows.Adding the external datasets to the classifier mod-els proved to have a considerable impact on the taskperformance (See Table 1).
The baseline systemreached an F-score of 47% which was increased by9 percentage points when including DrugBank infor-mation and a further 4 percentage points when alsoMetaMap information was included.As seen from the type-specific F-scores (on thetraining corpus), brand class entity detection wasimproved by 30 pp when DrugBank information wasadded, and increased slightly further with MetaMapinformation (See Table 2).
DrugBank lists brandnames for many drugs, and when this informationis added as a feature for each detected drug, deter-mining the type of the drug is greatly improved.The official primary metric in both tasks 9.1 and9.2 is a macro-averaged F-score, which gives equalweight to performance in each class, emphasizingthe importance of detecting also the difficult, smallclasses.
In particular, the class drug n (active sub-stances not approved for use in humans for medicalpurposes) was very difficult to detect for our system.While performance remained low for all three mod-els, including the MetaMap information gave a largerelative increase in drug n detection performance,increasing it from 2% F-score to 8% (See Table 2).With the macro-averaged overall performance, thisresulted in model three with the MetaMap informa-tion having notably higher performance.We hypothesized that the drug n category mightbe hard to detect as it could contain entities simi-lar to the drug category, which may differ only byapproval for use in humans, information that is notlikely present in the corpus.
Analysis of classifi-cation errors (See Table 3) confirms this hypothe-sis, showing that drug n entities are by far the mostcommonly misclassified ones.
Addition of Drug-Bank and MetaMap information considerably re-duces drug n misclassifications into the drug cate-gory.656M task P R F1 9.1 0.48 (0.70) 0.46 (0.51) 0.47 (0.59)2 9.1 0.6 (0.77) 0.52 (0.59) 0.56 (0.67)3 9.1 0.69 (0.76) 0.54 (0.59) 0.6 (0.66)1 9.2 0.73 (0.69) 0.47 (0.44) 0.57 (0.54)2 9.2 0.76 (0.69) 0.48 (0.45) 0.59 (0.55)3 9.2 0.73 (0.68) 0.48 (0.44) 0.58 (0.53)Table 1: Official results for TEES in the DDIExtrac-tion 2013 task and in parentheses corresponding 10-foldcross-validation results on the training corpus.
The threemodels (M) used are 1) baseline syntactic features, 2)baseline with DrugBank features and 3) baseline withboth DrugBank and MetaMap features.Task rules allowed using the test corpus of task9.2 (with annotated entities) as additional trainingdata for task 9.1.
Due to time constraints we did notuse it for training, but it is likely that performancecould be further enhanced by using it.3.2 Drug-drug interaction extractionPerformance of the three feature sets in the 9.2 DDIextraction task are much closer than in the 9.1 drugname recognition task.
Still, additional informa-tion from DrugBank and MetaMap slightly increaseperformance, but DrugBank alone outperforms us-ing both MetaMap and DrugBank.
With the perfor-mance difference range between the models beingonly 2 pp, we think the results remain inconclusive.That external data did not provide a further in-crease might indicate that drug-drug interaction de-tection is mostly a matter of interpreting the syn-tactic parse, whereas drug-name recognition benefitsmore from dictionary matching methods.As with task 9.1, we analyse the classification er-rors on the 10-fold classification performed on thetraining dataset for which annotations are publiclyavailable (See Table 4).
None of the DDI classes areas hard to detect as the drug name class drug n, butthe int class has much lower performance than theother classes, with most examples classified incor-rectly as negatives.4 ConclusionsWe applied the Turku Event Extraction System 2.1to detection of both drug names and drug-drug in-teractions in the DDIExtraction 2013 task.
The sys-model drug brand group drug n1 0.72 0.6 0.48 0.022 0.78 0.9 0.49 0.023 0.78 0.91 0.48 0.08Table 2: Per-class micro-average scores for the drugname recognition task 9.1.tem showed good performance for both tasks, but wemust consider that name and interaction detectionwere evaluated in isolation.
In real world text min-ing tasks, these steps will be consecutive and as suchresult in lower overall performance.
TEES achievesgood performance using deep syntactic parsing, butthis is a computationally expensive processing step.When drug names are detected with TEES, all in-put sentences need to be parsed, but if some othermethod is used for drug name recognition, TEES canparse just the sentences with drug names, as onlythey can potentially contain DDIs, enabling muchfaster DDI extraction.We showed that adding external data from theDrugBank database and from MetaMap prepro-cessing can considerably increase extraction perfor-mance.
However, we assume this makes the sys-tem more dependent on such data being availablefor candidate drug names and DDIs in the text be-ing processed, potentially making it harder to detectcompletely new names and interactions.
Therefore,using external data is likely to introduce a tradeoffof higher performance vs. wider detection.
Use ofsuch data should be chosen according to the task, asin some cases the goal is to retrieve documents withknown drugs and interactions, in others to maximizedetection of information not yet in the databases.As with previous TEES versions, we will pro-vide our source code freely available under an opensource license at the TEES project repository4.
Wewill also include a wrapper for using the MetaMaptool via the TEES preprocessing pipeline, allowingit to be easily integrated into event and relation ex-traction tasks.AcknowledgmentsWe thank CSC ?
IT Center for Science Ltd, Espoo,Finland for providing computational resources.4http://jbjorne.github.com/TEES/657neg brand drug n group drugneg 99.5799.6099.600.040.030.030.000.000.010.150.140.140.240.220.22brand 21.438.918.6367.9289.7089.980.070.070.070.630.210.289.951.111.04drug n 49.7063.2765.272.790.000.0012.1815.3715.370.401.001.2034.9320.3618.16group 13.8014.1314.040.120.000.060.030.030.0685.1584.9785.000.900.870.84drug 6.715.606.200.690.270.320.100.080.080.750.790.6991.7593.2792.72Table 3: Task 9.1 drug name classification errors for the training corpus.
Each cell in the table lists from top tobottom results for models one to three (baseline, baseline+DrugBank, baseline+DrugBank+MetaMap).
The resultsare percentage of SVM examples of each class (vertical) classified into each potential class (horizontal).neg int advise effect mechanismneg 97.2797.3297.400.020.030.030.520.490.471.091.061.041.091.091.05int 61.7061.7070.7422.8723.4019.150.530.000.009.578.517.455.326.382.66advise 34.5034.0233.540.120.240.2460.1760.0560.774.244.364.360.971.331.09effect 38.5938.4139.180.410.410.413.853.733.6854.0654.3053.593.083.143.14mechanism 50.3448.7552.160.150.150.232.051.821.295.085.085.0042.3844.2041.32Table 4: Task 9.2 drug-drug interaction classification errors for the training corpus.
Each cell in the table lists from topto bottom results for models one to three (baseline, baseline+DrugBank, baseline+DrugBank+MetaMap).
The resultsare percentage of SVM examples of each class (vertical) classified into each potential class (horizontal).658ReferencesAlan R Aronson.
2001.
Effective mapping of biomed-ical text to the UMLS Metathesaurus: the MetaMapprogram.
In Proceedings of the AMIA Symposium,page 17.
American Medical Informatics Association.Jari Bjo?rne, Antti Airola, Tapio Pahikkala, and TapioSalakoski.
2011.
Drug-drug interaction extractionfrom biomedical texts with SVM and RLS classifiers.In Proc.
of the 1st Challenge task on Drug-Drug In-teraction Extraction (DDIExtraction 2011) at SEPLN2011, volume 761, pages 35?42, Sept 5.Jari Bjo?rne, Filip Ginter, and Tapio Salakoski.
2012.University of Turku in the BioNLP?11 Shared Task.BMC Bioinformatics, 13(Suppl 11):S4.Olivier Bodenreider.
2004.
The unified medical lan-guage system (UMLS): integrating biomedical termi-nology.
Nucleic acids research, 32(suppl 1):D267?D270.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and MaxEnt discriminative rerank-ing.
In Proceedings of the 43rd Annual Meeting of theAssociation for Computational Linguistics (ACL?05),pages 173?180.
Association for Computational Lin-guistics.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher Manning.
2006.
Generating typed depen-dency parses from phrase structure parses.
In Proceed-ings of LREC-06, pages 449?454.Kin Wah Fung, Chiang S Jao, and Dina Demner-Fushman.
2013.
Extracting drug indication informa-tion from structured product labels using natural lan-guage processing.
Journal of the American MedicalInformatics Association.Craig Knox, Vivian Law, Timothy Jewison, Philip Liu,Son Ly, Alex Frolkis, Allison Pon, Kelly Banco,Christine Mak, Vanessa Neveu, Yannick Djoumbou,Roman Eisner, Anchi Guo, and David S. Wishart.2011.
Drugbank 3.0: a comprehensive resource foromics research on drugs.
Nucleic Acids Research,39(Database-Issue):1035?1041.David McClosky.
2010.
Any domain parsing: auto-matic domain adaptation for natural language pars-ing.
Ph.D. thesis, Department of Computer Science,Brown University.Sampo Pyysalo, Antti Airola, Juho Heimonen, JariBjo?rne, Filip Ginter, and Tapio Salakoski.
2008.Comparative analysis of five protein-protein interac-tion corpora.
BMC bioinformatics, 9(Suppl 3):S6.Li Quanzhi and Wu Yi-Fang Brook.
2006.
Identifyingimportant concepts from medical documents.
Journalof Biomedical Informatics, 39(6):668 ?
679.Lawrence H Reeve, Hyoil Han, and Ari D Brooks.
2007.The use of domain-specific concepts in biomedical textsummarization.
Information Processing & Manage-ment, 43(6):1765?1776.Isabel Segura-Bedmar, Paloma Mart?
?nez, and Mar??aSegura-Bedmar.
2008.
Drug name recognition andclassification in biomedical texts: a case study out-lining approaches underpinning automated systems.Drug discovery today, 13(17):816?823.Isabel Segura-Bedmar, Paloma Mart?
?nez, and Ce?sarde Pablo-Sa?nchez.
2011a.
A linguistic rule-based ap-proach to extract drug-drug interactions from pharma-cological documents.
BMC bioinformatics, 12(Suppl2):S1.Isabel Segura-Bedmar, Paloma Mart?
?nez, and DanielSa?nchez-Cisneros.
2011b.
The 1st DDIExtraction-2011 challenge task: extraction of drug-drug interac-tions from biomedical texts.
In Proceedings of the 1stChallenge Task on Drug-Drug Interaction Extraction2011: 7 Sep 2011; Huelva, Spain, pages 1?9.Isabel Segura-Bedmar, Paloma Mart?
?nez, and MariaHerrero-Zazo.
2013.
Semeval-2013 task 9: Extrac-tion of drug-drug interactions from biomedical texts.In Proceedings of the 7th International Workshop onSemantic Evaluation (SemEval 2013).Luis Tari, Saadat Anwar, Shanshan Liang, James Cai,and Chitta Baral.
2010.
Discovering drug?drug inter-actions: a text-mining and reasoning approach basedon properties of drug metabolism.
Bioinformatics,26(18):i547?i553.Philippe Thomas, Mariana Neves, Ille?s Solt, DomonkosTikk, and Ulf Leser.
2011.
Relation extraction fordrug-drug interactions using ensemble learning.
InProc.
of the 1st Challenge task on Drug-Drug Interac-tion Extraction (DDIExtraction 2011) at SEPLN 2011,page 11?18, Huelva, Spain, Sept 5.Ioannis Tsochantaridis, Thorsten Joachims, Thomas Hof-mann, and Yasemin Altun.
2005.
Large marginmethods for structured and interdependent output vari-ables.
Journal of Machine Learning Research (JMLR),6(Sep):1453?1484.Chen-May Wong, Yu Ko, and Alexandre Chan.
2008.Clinically significant drug-drug interactions betweenoral anticancer agents and nonanticancer agents: pro-filing and comparison of two drug compendia.
TheAnnals of pharmacotherapy, 42(12):1737?1748.659
