Proceedings of the 2010 Workshop on NLP and Linguistics: Finding the Common Ground, ACL 2010, pages 10?17,Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational LinguisticsEvidentiality for Text Trustworthiness DetectionQi Su1, 2, Chu-Ren Huang and Helen Kai-yun Chen1Depart of Chinese & Bilingual Studies, The Hong Kong Polytechnic University2Key Laboratory of Computational Linguistics, Peking Universitysukia@pku.edu.cn, {helenkychen, churen.huang}@gmail.comAbstractEvidentiality is the linguistic representation ofthe nature of evidence for a statement.
Inother words, it is the linguistically encodedevidence for the trustworthiness of a state-ment.
In this paper, we aim to explore howlinguistically encoded information of eviden-tiality can contribute to the prediction oftrustworthiness in natural language processing(NLP).
We propose to incorporate evidential-ity into a framework of machine learningbased text classification.
We first construct ataxonomy of evidentials.
Then experimentsinvolving collaborative question answering(CQA) are designed and implemented usingthis taxonomy.
The experimental results con-firm that evidentiality is an important clue fortext trustworthiness detection.
With the bi-narized vector setting, evidential based textrepresentation model has considerably per-formaned better than both the bag-of-wordmodel and the content word based model.Most crucially, we show that the best trust-worthiness detection result is achieved whenevidentiality is incorporated in a linguisticallysophisticated model where their meanings areinterpreted in both semantic and pragmaticterms.1 IntroductionWith the exponential increase in web sites anddocuments, the amount of information is nolonger a main concern for automatic knowledgeacquisition.
This trend raises, however, at leasttwo new issues.
The first is how to locate theinformation which exactly meets our needsamong the vast web content.
Efforts to addressthis issue can be exemplified by advanced re-search in information retrieval, information ex-traction, etc.
The second is how to judge the va-lidity of the acquired information, that is, thetrustworthiness of information.
This issue hasattracted considerable interest in some relatedresearch areas recently.
Taking the specific in-formation retrieval task, question answering(QA) as an example, a QA system attempts toretrieve the most appropriate answers to ques-tions from web resources.
To determine thetrustworthiness of the extracted candidate an-swers, a common approach is to exploit the co-occurrence frequency of questions and candidateanswers.
That is, if a candidate answer co-occursmore frequently with the question than othercandidates, the QA system may judge it as thebest answer (Magnini, 2002).
This approach pre-supposes and relies crucially on information re-dundancy.
Although this heuristic method issimple and straightforward, it is not applicableto all cases.
For the applications which don?tinvolve much information redundancy, the heu-ristic could cease to be effective.
The task ofcollaborative question answering (CQA) whichwe will address in this paper is just one of suchexamples.
For a user posted question, there areusually only few answers provided.
So, the heu-ristic is not useful in providing the best answer.In addition, since the spread of unsubstantiatedrumors on the Internet is so pervasive, the high-frequency information on the Web sometimesmay mislead the judgment of trustworthiness.
Interms of the above consideration, it is essentialto look for other approaches which allow di-rectly modeling of the trustworthiness of a text.Given that non-textual features (such as user'sWeb behavior) used in text trustworthiness de-tection are often manipulated by informationproviders, as well as no directly related textualfeatures for the task has been proposed up to10date, we need a more felicitous model for detect-ing the trustworthiness of statements.
Notingthat evidentiality is often linguistically encodedand hence provides inherent information ontrustworthiness for a statement, we propose toincorporate the linguistic model of evidentialityin our study.
Specifically, we incorporate evi-dentiality into a machine learning based textclassification framework, and attempt to verifythe validity of evidentiality in trustworthinessprediction of text information in the context ofcollaborative question answering.
The experi-mental results show that evidentials are impor-tant clues in predicting the trustworthiness oftext.
Since none of the task-specific heuristicshas been incorporated, the current approachcould also be easily adapted to fit other naturallanguage processing applications.The paper proceeds as follows.
In section 2we discuss related work on text trustworthinessdetection.
The section is divided into two parts:the current methodology and the textual featuresfor analysis in the task.
Section 3 introduces thelinguistic researches on evidentiality and ourtaxonomy of evidentials based on the trustwor-thiness indication.
Section 4 presents the ex-periment settings and results.
Finally, in section5 we discuss the experiment results and con-clude the current research.2 Related WorkThe research of text trustworthiness is veryhelpful for many other natural language process-ing applications.
For example, in their researchon question answering, Banerjee and Han (2009)modulate answer grade by using a weightedcombination of the original score and answercredibility evaluation.
Also, Weerkamp and Ri-jke (2008) incorporate textual credibility indica-tors in the retrieval process to improve topicalblog posts retrieval.
Gyongyi et al(2004) pro-pose a TrustRank algorithm for semi-automatically separating reputable, good Webpages from spams.2.1 General Approaches for Text Trust-worthiness DetectionIn past research, the judgment for the trustwor-thiness or credibility of a given text content isusually tackled from two aspects: entity orientedand content oriented (Rubin and Liddy, 2005).The former approach takes into considerationthe information providers?
individual profiles,such as their identity, reputation, authority andpast web behavior; whereas the latter approachconsiders the actual content of texts.
Metzger(2007) reviews several cognitive models ofcredibility assessment and points out that credi-bility is a multifaceted concept with two primarydimensions: expertise and trustworthiness.
Fol-lowing Matzger?s framework, Rubin and Liddy(2005) compile a list of factors that users maytake into account in assessing credibility of blogsites.
This list could also be summarized as theabove mentioned two-folds: the bloggers?
pro-files and the information posted in the entries.Comparing these two aspects, most existingresearch on text trustworthiness focuses on theuser oriented features.
Lots of user oriented fea-tures have been proposed in the research ofcredibility detection.
To score the user orientedfeatures such as user?s authority, a common ap-proach is based on a graph-based ranking algo-rithm such as HITS and PageRank (Zhang et al2007; Bouguessa et al 2008).In the research of text trustworthiness detec-tion, the overwhelmingly adaption of non-textual features such as entity profiles over textcontent based features reflect some researchers?belief that superficial textual features cannotmeet the need of text credibility identification(Jeon et al 2006).
In this paper, we examine thelexical semantic feature of evidential and arguethat evidentiality, as a linguistically instantiatedrepresentation of quality of information content,offers a robust processing model for text trust-worthiness detection.The detection of information trustworthinessalso has promising application values.
GoogleNews 1  is just such an application that rankssearch results according to the credibility of thenews.
Other online news aggregation service,such as NewTrust 2, also focuses on providingusers with credible and high quality news andstories.
The existed applications, however, relyon either the quality of web sites or user voting.So, it is anticipated that the improvement on thetechnology of text trustworthiness detection byincorporating lexical semantic cues such as evi-dentiality may shed light on these applications.2.2 Textual Feature Based Text Trustwor-thiness DetectionAlthough non-textual features have been popularin text credibility detection, there has been a fewresearch focusing on textual features so far.
Gil1 http://news.google.com/2 http://www.newstrust.net/11and Artz (2006) argue that the degree of trust inan entity is only one ingredient in decidingwhether or not to trust the information it pro-vides.
They further point out that entity-centeredissues are made with respect to publicly avail-able data and services, and thus will not be pos-sible in many cases.
In their research of topicalblog posts retrieval, Weerkamp and Rijke (2008)also consider only textual credibility indicatorssince they mentioned that additional resources(such as bloggers?
profiles) is hard to obtain fortechnical or legal reasons.However, most research which utilizes textualfeatures in text trustworthiness detection usuallyequates writing quality of document with itstrustworthiness.
Therefore, some secondary fea-tures which may not directly related to trustwor-thiness are proposed, including spelling errors,the lack of leading capitals, the large number ofexclamation markers, personal pronouns andtext length (Weerkamp and Rijke, 2008).
Therehas not been attempted to directly evaluate in-herent linguistic cues for trustworthiness of astatement.3 On Evidentiality in TextEvidentiality, as an explicit linguistic system toencode quality of information, offers obviousand straightforward evidence for text trustwor-thiness detection.
Yet it has not attracted the at-tention which it deserves in most of the naturallanguage processing studies.
In this paper, weaim to explore how we can incorporate the lin-guistic model of evidentiality into a robust andefficient machine learning based text classifica-tion framework.Aikhenvald (2003) observes that every lan-guage has some way of making reference to thesource of information.
Once the language is be-ing used, it always imprinted with the subjectiverelationship from the speakers towards the in-formation.
Evidentiality is information provid-ers?
specifications for the information sourcesand their attitudes toward the information.
As acommon linguistic phenomenon to all the lan-guages, it has attracted linguists?
attention sincethe beginning of 20th century.
In any language,evidentiality is a semantic category which couldbe expressed on both grammatical level (as insome American Indian language) and lexicallevel (as in English, Chinese and many otherlanguages).
The linguistic expressions of eviden-tiality are named as evidentials or evidentialmarkers.Mushin (2000) defines evidential as a markerwhich qualifies the reliability of information.
Itis an explicit expression of the speaker?s atti-tudes toward the trustworthiness of informationsource.
For instance,a).
It?s probably raining.b).
It must be raining.c).
It sounds like it?s raining.d).
I think/guess/suppose it?s raining.e).
I can hear/see/feel/smell it raining.It is obvious that the information provided inthe above examples is subjective.
The informa-tion expresses the personal experience or atti-tudes, while at the same time reflects the speak-ers?
estimation for the trustworthiness of thestatement by information providers.3.1 The Definition of EvidentialityThere are two dimensions of the linguistic defi-nition for evidentiality.
The term evidentiality isoriginally introduced by Jakobson (1957) as alabel for the verbal category indicating the al-leged source of information about the narratedevents.
In line with Jakobson?s definition, thenarrow definition of evidentiality proposed byother researchers focuses mainly on the specifi-cation of the information sources, that is, theevidence through which information is acquired(DeLancey, 2001).
Comparing with the narrowdefinition, the board definition explains eviden-tiality in a much wider sense, and characterizesevidentiality as expressions of speaker?s attitudetoward information, typically expressed by mo-dalities (Chafe, 1986; Mushin, 2000).Ifantidou (2001) also holds that evidential hastwo main functions: 1) indicating the source ofknowledge; 2) indicating the speaker?s degree ofcertainty about the proposition expressed.
Hefurther divides them in details as follows.a) Information can be acquired in variousways, including observation (e.g.
see), hearsay(e.g.
hear, reportedly), inference (e.g.
must, de-duce), memory (e.g.
recall).b) Evidentiality can indicate the speaker?s de-gree of certainty, including certain propositionalattitude (e.g.
think, guess) and adverbials (e.g.certainly, surely), also epistemic models (e.g.may, ought to).3.2 The Taxonomy of EvidentialsEvidentiality has its hierarchy which forms acontinuum that marks from the highest to theleast trustworthiness.
Up to now, there are manyhierarchical schemes proposed by researchers.12Table 1.
The Categorization and Inside Items of EvidentialityOswalt (1986) suggests a priority hierarchy ofevidentials as:Performative > Factual > Visual > Auditory >Inferential > QuotativeIn this evidential hierarchy, performative car-ries the highest degree of trustworthiness sinceOswalt considers that the speaker is speaking ofthe act he himself is performing.
It is the mostreliable source of evidence for the knowledge ofthat event.Whereas Barners (1984) proposes the follow-ing hierarchy:Visual > Non-visual > Apparent > Second-hand > AssumedHe points out that visual evidence takesprecedence over the auditory evidence and ismore reliable.The above two hierarchies are based on thenarrow definition of evidentiality mentionedabove.
There are also some hierarchies involvingthe board definition of evidentiality, such asChafe (1986)?s categories of evidentiality.In this paper, we adopt a broad definition ofevidentiality and focus on a trustworthinesscategorization.
This categorization follows themodel of four-dimensional certainty categoriza-tion by Rubin et al(2005).
In this model, it issuggested that the division of the certainty leveldimension into four categories - Absolute, High,Moderate and Low.
With some revision, thereare different items of evidential words andphrased that we extracted from the corpus.These items from each category to be adopted inour experiments are presented in Table 1.4 Incorporating Evidentiality into Ma-chine Learning for TrustworthinessDetectionIn this section, we apply evidentiality in an ac-tual implement of text trustworthiness detection.It is based on a specific web application service,collaborative question answering (CQA), inwhich the trustworthiness of text content is veryhelpful for finding the best answers in the ser-vice.With the development of Web2.0, the servicesof CQA in community media have largely at-tracted people?s attention.
Comparing with thegeneral ad hoc information searching, questionanswering could help in finding the most accu-rate answers extracted from the vast web content.Whereas in the collaborative question answering,the CQA community media just provide a webspace in which users can freely post their ques-tions, and at the same time other users may an-swer these questions based on their knowledgeand interests.
Due to the advantage of interactiv-ity, CQA usually could settle some questionswhich cannot be dealt with by ad hoc informa-tion retrieval.
However, since the platform isopen to anyone, the quality of the answers pro-vided by users is hard to identify.
People maypresent answers of various qualities due to thelimitation of their knowledge, attitude and pur-pose of answering the questions.
As a result, theissue of how to identify the most trustworthyanswers from the user-provided content turnsout to be the most challenging part to the system.As mentioned previously, the trustworthinessof text content could be identified from two di-mensions.
The first one relies on the featuresrelated with information distributors.
The secondone relies on the content of a text.
In current re-search we focus on textual features, especiallythe feature of evidentiality in texts.
The featurewill be incorporated into a machine learningbased text classification framework in order toidentify the best answers for CQA questions.Absolute High Moderate LowAttributive/modaladverbcertainly, sure, ofcourse, definitely, ab-solutely, undoubtedlyclearly, obviously, ap-parently, really, alwaysSeemingly,probablymaybe, personally,perhaps, possibly,presumablyLexical verbreport, certain believe, see seem, think, sound doubt, wish, wonder,infer, assume, fore-cast, fell, heardAuxiliary verb  must ought, should, would, could, canmay, mightEpistemic adjec-tivedefinite  possible, likely,unlikely, probable,positive, potentialnot sure, doubtful134.1 The DatasetFor the experiments, we use the snapshot of Ya-hoo!
Answers dataset which is crawled by Emo-ry University3.
Since our experiments only in-volve text features, we use the answer parts fromit without considering the question sets and userprofiles.
Such information could be incorporatedto achieve a higher performance in the future.With regard to the text classification problems,there is typically a substantial class distributionskew (Forman, 2003).
For the Yahoo!
Answersdataset, a question only has one best answer andaccordingly all the other answers will be markedas non-best answers.
Thus the class of best an-swer contains much fewer texts than the class ofnon-best answers.
In our dataset (a proportion ofthe overall CQA dataset provided by EmoryUniversity), the number of best answers is 2,165,and the number of non-best answers is 17,654.The proportion of the size of the two answer setsis around 1:8.15, showing a significant skews.For a better comparison of experimental results,we use a balanced dataset which is generatedfrom a normal distribution dataset.A 10-fold validation is used for the evaluation,where the datasets of best and non-best answersare divided into 10 subsets of approximatelyequal size respectively.
In the normally distrib-uted dataset, we use one of the ten subsets as thetest set, while the other nine are combined to-gether to from the training set.
In the balanceddataset, for each subset of the non-best answers,we only use the first k answers, in which k is thesize of each subset of best answers.
The trainingdata and test data used in the machine learningprocess are shown in Table 2.Training/Test SetBestanswerNon-bestanswertraining 19,490 158,889 normal distributiondataset test 2,165 17,654training 19,490 19,490 balanceddataset test 2,165 2,165Table 2.
The Dataset Used for the Experiments4.2 Experiment SettingsTo conduct a machine learning based classifica-tion for best answers and non-best answers, wefirst need to construct the feature vectors.
Therepresentation of text is the core issue in the ma-3 http://ir.mathcs.emory.edu/sharedchine learning model for text classification.
Intext domains, feature selection plays an essentialrole to make the learning task efficient and moreaccurate.
As the baseline comparison, we use thefollowing feature vector settings.
?Baseline1 represents using all the words inthe text as features (when the frequency of theword in the dataset is bigger than a predefinedthreshold j).?
Baseline2 represents using all the contentwords (here we include the four main categoriesof content words - nouns, verbs, adjectives andadverbs identified by a POS tagger) in the data-set as features.We use both the above two baselines.
Thebag-of-word model of Baseline1 is a conven-tional method in text representation.
However,since not all the words are linguistically signifi-cant, in Baseline2, we consider only the contentwords in the dataset, since content words conveythe core meaning of a sentence.For the evidentiality-based classification, weadopt the following feature vector settings.
?Evidential represents using all the evidentialsin text as features.?Evidential?
represents using all the eviden-tials except for those in the category of Moder-ate as features.
?Evid.cat4 represents using the four eviden-tiality categories of Absolute, High, Moderateand Low from Table 1.?Evid.cat2 represents using the two categoriesof Absolute and High as the positive evidentialand Moderate and Low as the negative evidential.?Evid.cat2?
omits the evidential category ofModerate, and represents using the two catego-ries of Absolute and High as the positive eviden-tial and only the category of Low as the negativeevidential feature.Some researchers have proved that usually aBoolean indicator of whether the feature itemoccurred in the document is sufficient for classi-fication (Forman, 2003).
Although there are alsosome other feature weighting schemes such asterm frequency (TF), document frequency (DF),etc, comparison of these different weightingschemes is not the object of the current research.So in this paper, we only consider Booleanweighting.
In the Boolean text representationmodel, each feature represents the Boolean oc-currence of a word, evidential, or evidential cat-egory according to the different feature settings.By the experimental settings, we want to verifythe hypothesis that incorporating the knowledge14of evidentiality into text representation can leadto improvement in classification performance.In our experiment, we perform text preproc-essing including word segmentation and part-of-speech (POS) tagging.
The Stanford Log-linearPart-Of-Speech Tagger (http://nlp.stanford.edu/software/tagger.shtml) is used for POS tagging.We adopt support vector machine (SVM) as themachine learning model to classify best answersfrom non-best ones, and use the SVMlight pack-age (http://svmlight.joachims.org) as the classi-fier with the default parameters and a linear ker-nel.
For the evaluation, we use the metrics ofprecision (Prec.
as in table 3), recall (Rec.
as intable 3), accuracy (Acc.
as in table 3) and F1:F1-measure, the harmonic mean of the precisionand recall.4.3 EvaluationTable 3 shows the experimental results using thebalanced dataset with Boolean weighting.
Thefocus of the experiment evaluation is on identi-fying the best answers, so the evaluation metricsare all for the best answers collection.
From thetable, we see increases of the two feature vectorsetting of evidentials over both baseline results.The highest improvement is 14.85%, achievedby the feature set of Evidential?.
However, thereis no increase found in the settings of using evi-dential categories.
This means that although thecategory of evidentials in indicating text trust-worthiness is obvious for human, it is not neces-sary a preferred feature for machine learning.Prec.
Rec.
Acc.
F1Baseline1 45.62% 51.51% 45.15% 47.94%Baseline2 59.58% 39.20% 56.30% 47.28%Evidential 67.78% 44.18% 61.59% 53.49%Evidential?
47.40% 90.12% 45.06% 62.13%Evid.cat4 64.15% 25.85% 55.70% 36.85%Evid.cat2 60.86% 28.21% 55.03% 38.55%Evid.cat2?
40.35% 25.85% 43.81% 31.51%Table 3.
Experimental Results Using the Bal-anced Training/Test Dataset (with BooleanWeighting)To eliminate the potential effect of termweighting scheme on performance trend amongdifferent text representation models, we alsoconduct experiments using TF weighting.
By theexperiments, we aim to compare the relative per-formances of different feature vectors con-structed with evidentials, and the results aredemonstrated in Table 4.Prec.
Rec.
Acc.
F1Evidential 66.78% 45.57% 61.45% 54.17%Evidential?
59.66% 20.82% 53.37% 30.87%Evid.cat4 50.00% 18.14% 50.00% 26.63%Evid.cat2 55.91% 16.39% 51.73% 25.35%Table 4.
Experimental Results Using the Bal-anced Training/Test Dataset (with TF Weighting)From the table, it can be observed that usingevidentials as features shows better improve-ment in the performance than the category ofevidentials as a feature.
A similar performancehas been summarized in Table 3.Finally, but not the least, to better understandthe effect of evidential category on the machinelearning performance, we design additional ex-periments as follows.
?Evid_cat1 stands for combining the four evi-dential categories into one, and uses only thisone category of evidential as a feature.
The ap-proach of Boolean weighting is actually thesame as a rule-based approach that classifies thetest dataset according to whether evidential oc-curs or not.BOOL Prec.
Rec.
Acc.
F1Evid_cat1 59.42% 61.59% 59.76% 60.49%Table 5.
Experimental Results Using the Bal-anced Training/Test Dataset (with BooleanWeighting; Only One Evidential Category)Table 5 presents a set of interesting experi-mental result.
In the result, all the four evalua-tion metrics show performance increases com-paring to the baseline, and it even outperformsalmost all the other results from both weightingschemes.
Based on this result, it is suggestedthat evidentiality still may contribute to the taskof text trustworthiness detection.
Moreover, itcan significantly reduce the dimensionality offeature space (e.g.
for Baseline 1, the dimen-sionality of feature dimension is 218,328 in oneof our cases; while for the experiment of Evi-dential, it reduced to only 51 as shown in Table151).
However, we should address the question ofwhy not all types of evidential features demon-strate improvement of detection.
We will furtherdiscuss the issue from a  pragmatic viewpoint inthe next section.5 Conclusion and DiscussionIn this paper, we propose to incorporate the lin-guistic knowledge of evidentiality in the NLPtask of trustworthiness prediction.
As evidential-ity is an integral and inherent part of any state-ment and explicitly expresses information aboutthe trustworthiness of this statement, it shouldprovide the most robust and direct model fortrustworthiness detection.
We first set up thetaxonomy of lexical evidentials.
By incorporat-ing evidentiality into a machine learning basedtext classification framework, we conduct ex-periments for a specific application, CQA.
Theevidentials in the dataset are extracted to formdifferent text representation schemes.
Our ex-perimental results using evidentials show im-provements up to 14.85% over the baselines.However, not all types of evidential featurescontributed to the improvement of detection.
Wealso compared the effect of different types ofevidential based feature representation schemeson the classification performance.The way to model evidentiality for trustwor-thiness detection which we adopted in our initialexperiment design actually could also be ex-plained by Grice?s Maxim of Quality: be truthful.As the Maxim of Quality requires one ?not tosay that for which one lacks adequate evidence?,we hypothesize that evidential constructionsmark the adequacy of evidence and should indi-cate reliable answers.
However, the results fromour experiments only partially supported thishypothesis.
The results showed a satisfactoryperformance was achieved when all evidentialmarkers were treated as negative evidence forreliability.
This result could then be accountedby invoking another Gricean maxim: Quantity.The Maxim of Quantity requires that ?onemakes his/her contribution as informative as isrequired, and at the same time does not make thecontribution more informative than is required.
?As evidentiality is not grammaticalized in Eng-lish, the use of evidentiality is not a requiredgrammatical element.
An answer marked by evi-dentials would violate Maxim of Quantity if it iscorrect.
The Maxim of Quantity predicts thatgood answers are plain statements without evi-dential markers.
On the frequent use of eviden-tial markers for less reliable answers can be ac-counted for by speakers?
attempt to follow bothMaxims of Quality and Quantity.
The evidentialmarks are used to compensate for the fact thatspeakers are not very confident about the answer,yet would like to adhere to the Maxim of Quality.In other words, evidentials are not likely to beused in reliable answers because of the Maximof Quality, but it is likely used in less reliableanswers because the speakers may try to provideproof of adequate evidence by a grammaticaldevice instead of providing true answer.Therefore, this model elaborated above takesinto account not only the grammatical functionof evidential constructions but also how this lin-guistic structure is used as a pragmatic/discoursedevice.
In other words, this study suggests thatmodeling linguistic theory in NLP needs to takea more comprehensive approach than the simplemodular approach where only one module(based on evidentiality) is used.
Linguistic mod-eling needs to consider both how linguisticstructure/knowledge is represented and proc-essed, we also need to model how a particularlinguistic device in use.In the further works, we plan to continue de-veloping and elaborate on a multi-modular lin-guistic model of evidentiality for knowledgeacquisition.
We will also explore the possibilityof incorporating other features, both textual andnon-textual, to further improve performances inthe tasks of text trustworthiness detection.ReferencesAgichtein E, Castillo C, and etc.
2008.
Finding high-quality content in social media.
In Proceedings ofWSDM2008.Aikhenvald A and Dixon, ed.
2003.
Studies in evi-dentiality.
Amsterdam/Philadelphia: John Benja-mins Publishing CompanyBanerjee P, Han H. 2009.
Credibility: A LanguageModeling Approach to Answer Validation, In Pro-ceedings of NAACL HLT 2009, Boulder, Bolorado,USBarners J.
1984.
Evidentials in the Tuyuca Verb.
INInternational Journal of American Linguistics, 50Bouguessa M, Dumoulin B, Wang S. 2008.
Identify-ing Authoritative Actors in Question-AnsweringForums - The Case of Yahoo!
Answers, In Pro-ceedings of KDD?08, Las Vegas, Nevada, USAChafe W. 1986.
Evidentiality: The Linguistic Codingof Epistemology, Evidentiality in English Conver-sation and Academic Writing.
In Chafe and Nich-16ols, (ed.).
Evidentiality: The Linguistic Coding ofEpistemology.
Norwood, NJ: AblexDeLancey S. 2001.
The mirative and evidentiality.
InJournal of Pragmatic, 33Forman G. 2003.
An Extensive Empirical Study ofFeature Selection Metrics for Text Classification,In Journal of Machine Learning Research, 3Gil Y, Artz D. 2006.
Towards Content Trust of WebResources, In Proceedings of the 15th InternationalWorld Wide Web Conference, Edinburgh, ScotlandGyongyi Z, Molina H, Pedersen J.
2004.
CombatingWeb Spam with TrustRank.
In Proceedings of the30th VLDB Conference, Toronto, CanadaIfantidou E. 2001.
Evidentials and Relevance.
JohnBenjamins Publishing Company.Jeon J, Croft W, Lee J and Park S. 2006.
A Frame-work to Predict the Quality of Answers with Non-textual Features, In Proceedings of SIGIR?06, Se-attle, Washington, USALeopold E, Kindermann J.
2002.
Text Categorizationwith Support Vector Machines.
How to RepresentTexts in Input Space?, In Machine Learning, 46,423-444Oswalt R. 1986.
The evidential system of Kashaya.IN Chafe W and Nichols (Eds.
), Evidentiality: Thelinguistic coding of epistemology.
Norwood, NJ:AblexRubin V, Liddy E, Kando N. 2005.
Certainty Identi-fication in Texts: Categorization Model and Man-ual Tagging Results, In Shanahan J and et al(Eds.
),Computing Attitude and Affect in Text: Theory andApplications (The Information Retrieval Series):Springer-Verlag New York, Inc.Rubin V, Liddy E. 2006.
Assessing Credibility ofWeblogs, In Proceedings of the AAAI Spring Sym-posium: Computational Approaches to AnalyzingWeblogs (CAAW)Magnini B, Negri M, Prevete R and Tanev H. 2002.Is It the Right Answer?
Exploiting Web Redun-dancy for Answer Validation, In Proceedings ofthe 40th Annual Meeting of the Association forComputational Linguistics, Philadelphia, PAMetzger M. 2007.
Evaluating Online Information andRecommendations for Future Research, Journal ofthe American Society for Information Science andTechnology, 58(13)Mushin  I.
2000.
Evidentiality and Deixis in Retelling,In Journal of Pragmatics, 32Weerkamp W, Rijke M. 2008.
Credibility ImprovesTopical Blog Post Retrieval.
In Proceedings ofACL08: HLTZhang J, Ackerman M, Adamic L. 2007.
ExpertiseNetworks in Online Communities: Structure andAlgorithms.
In Proceedings of the 16th ACM Inter-national World Wide Web Conference (WWW?07)17
