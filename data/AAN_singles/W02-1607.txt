Building a training corpus for word sense disambiguationin English-to-Vietnamese Machine TranslationDien DinhFaculty of IT, VNU-HCMC, Vietnamddien@saigonnet.vnAbstractThe most difficult task in machine translation is the elimination of  ambiguity in humanlanguages.
A certain word in English as well as Vietnamese often has different  meaningswhich depend on their syntactical position in the sentence and the actual context.
In order tosolve this ambiguation, formerly, people used to resort to many hand-coded rules.Nevertheless, manually building these rules  is a time-consuming and exhausting task.
So,we suggest an automatic method to solve the above-mentioned problem by usingsemantically tagged corpus.
In this paper, we mainly present building a semantically taggedbilingual corpus to word sense disambiguation (WSD) in English texts.
To assign semantictags, we have taken advantage of  bilingual texts via word alignments with semantic classnames of LLOCE (Longman Lexicon of Contemporary English).
So far, we have built5,000,000-word bilingual corpus in which 1,000,000 words have been semanticallyannotated with the accuracy of 70%.
We have evaluated our result of semantic tagging bycomparing with SEMCOR on SUSANNE part of our corpus.
This semantically annotatedcorpus will be used to extract disambiguation rules automatically by TBL (Transformation-based Learning) method.
These rules will be manually revised  before being applied to theWSD module in the English-to-Vietnamese Translation (EVT) system.1 IntroductionNowadays more and more people are interestedin word sense disambiguation (WSD).
Bilingualcorpora have been exploited in order to trainsuch WSD system, finding out the rules that canbe applied in Machine Translation (Zinovjeva,2000).
The statistical method based on bilingualcorpus is used to find and link words in bitextsfor English-French, English-Chinese, English-Japanese, etc.
(Isahara, Melamed, 2000).Regarding the English-Vietnamese bilingualcorpus, however, so far, we haven't seen anyworks yet.
In this paper, we present building anEnglish-Vietnamese bilingual corpus withsemantic tags.
This semantically-annotatedcoprus will be used to train the WSD module forour EVT in the future.
In this paper, we don'tconcentrate on word alignment or WSD, but weconcentrate on assigning semantic tags toEnglish and Vietnamese words via their class-based word-alignments (Dien Dinh, 2002).Thanks to aligned word-pairs along with theircorresponding semantic classes in LLOCE, wecan find the correct sense of a word and assign itto an appropriate semantic tag.
That is, we takeadvantage of manually correct translation ofEnglish and Vietnamese words to disambiguateword senses in semantic tagging.
The rest of thispaper consists of 4 following sections:- Section 2: Collecting English-Vietnamesebilingual texts.- Section 3:  Normalizing English-Vietnamese bilingual corpus.- Section 4:  Annotating bilingual corpus:assigning semantic tags to word-pairs incorpus and applying this semantically-annotated corpus to train the WSD module.- Section 5: Conclusion and futureimprovements.2 Collecting  English-Vietnamesebilingual textsWhen chosing this bilingual approach, we havemet many difficulties.
Firstly, due to no officialEnglish-Vietnamese bilingual corpus availableup to now, we have had to build them byourselves by collecting English-Vietnamesebilingual texts from selected sources.
Secondly,as most of these sources are not electronicforms, we must convert them into electronicform.
During the process of electronicconversion, we have met another drawback.That is: there is no effective OCR (OpticalCharacter Recognition) software available forVietnamese characters.
Compared with EnglishOCR softwares, Vietnamese OCR one is lowerjust because Vietnamese characters have  tonemarks (acute, breve, question, tilde, dot below)and diacritics (hook, caret,..).
So, we mustmanually input most of Vietnamese texts (low-quality hardcopies).
Only OCR of high-qualityhardcopies has been used and manually revised.During collecting English-Vietnamese bilingualtexts (figure 1), we choose only followingmaterials:- Science or techniques materials.- Conventional examples in dictionaries.- Bilingual texts that their translations areexact (translated by human translator andpublished by reputable publishers) and nottoo diversified (no "one-to-one"translation).So far, we have collected  a 5,000,000-wordcorpus containing 400,000 sentences (most ofthem are texts in science and conventionalfields).Table 1.
Collection of bilingual textsNo Sources Number ofEnglishwordsNumber ofVietnamese?words?
(2)1 English-VNDictionaries600,344 1018,6572 VN-EnglishDictionaries427,397 691,0965 LLOCE 305,975 402,0864 SUSANNE(1) 128,000 181,7816 TechnicalTextBooks226,953 297,9207 Children?sEncyclopedia52,836 72,2948 Other books 267,920 341,170Total 2,009,425 3,005,004Legend:(1) SUSANNE (Surface and Underlying StructuralANalyses of Naturalistic English) is constructedby Geoffrey Sampson (1995) at SussexUniversity, UK.
Vietnamese translation isperformed by English teacher of VNU-HCMC.
(2) Vietnamese "word" is a special linguistic unit inVietnamese language only, which is often called"tie?ng".
This lexical unit is lower than traditionalwords but higher than traditional morphemes.Fig.
1.
An example collected from English-Vietnamese dictionary3 Normalizing  English-Vietnamese bilingual corpusHowever, after the collection, we must convertthem into unified forms (normalization) byaligning sentences as follows.3.1 Sentence-alignment of bilingualcorpusDuring inputting this bilingual corpus, we havealigned sentences manually under the followingformat:*D02:01323: The announcement of the royalbirth was broadcast to the nation.+D02:01323: L?
?i loan ba?o s??
ra ??
?i cu?a ??
?acon hoa?ng to?c ?a?
???
?c truye?n thanh tre?n toa?nquo?c.
*D02:01324: Announcements of births,marriages and deaths appear in somenewspapers.+D02:01324: Nh?
?ng tho?ng ba?o ve?
s??
ra ???i,c??
?i ho?i, tang che?
xua?t hie?n tre?n mo?t va?i t?
?ba?o.In which, first characters are reference numbersindicating its sources and the position ofsentence in texts.Because most of our bilingual corpus aremanually typed, we haven't used automaticsentential alignment.
Automatic sententialalignment (Gale and Church, 1991) will benecessary if we have already had onlinebilingual texts.3.2 Spelling Checker of bilingual corpusAfter aligning sentences, we check the spell ofEnglish words and Vietnamese wordsautomatically.
Here, we have met anotherdrawback in processing the Vietnamese wordsegmentation because Vietnamese words(similar to Chinese words) are not delimited byspaces (Dien Dinh, 2001).
However, ourspelling checker is able to detect non-existentwords in English or Vietnamese only.
So, wemust review this corpus manually.
In fact,Vietnamese ?word?
here is only ?tie?ng?, whichis equivalent to Vietnamese ?spelling word?
or?morpheme?
(due to features of isolatedlanguage typology).4 Annotating bilingual corpusThe main section in this paper is to annotate thesemantic labels.
To carry out this task, we havetaken advantage of classification of semanticclasses in LLOCE.
We considered these classnames as semantic tags and assign them toEnglish words in source sentences.
In thissection, we concentrate on annotating  semantictags via class-based word alignment in English-Vietnamese bilingual corpus.There are many approaches to wordalignment in biligual corpora such as: statistics-based (Brown, 1993), patern-based mapping(Melamed I.D.
2000), class-based (Sue Ker J.and Jason Chang S. 1997), etc.
Because ourmain focus is semantical tagging, we havechosen the class-based approach to wordalignment.
This approach was firstly suggestedby Sue J.Ker and Jason S. Chang (1997) in wordalignment of English-Chinese bilingual corpus.However, instead of using LDOCE (LongmanDictionary Of Contemporary English) forEnglish and CILIN for Chinese, we use LLOCEenhanced by Synsets of WordNet for bothEnglish and Vietnamese.
Thank to this enhancedLLOCE (40,000 entries), our class dictionaryenjoys more coverage than the original LLOCE(only 16,000 entries).4.1 Classes in LLOCEAccording to a report of EAGLES (1998),LLOCE is a small size learner style dictionarylargely derived from LDOCE and organizedalong semantic principles.
A quantitative profileof the information provided is given in table 2below.Table 2.
Classes in LLOCENumber of entries 16,000Number of senses 25,000Major codes 14Group codes 127Semantic fieldsSet codes 2441Grammar codes same as LDOCESelectionalrestrictionssame as LDOCEDomain & registerLabelssame as LDOCESemantic classification in LLOCE is articulatedin 3 tiers of increasingly specific conceptsrepresented as major, group and set codes, e.g.<MAJOR: A> Life and living things<GROUP: A50-61> Animals/Mammals<SET: A53> The cat and similar animals: cat,leopard, lion, tiger,...Each entry is associated with a set code, e.g.<SET: A53> nouns The cat and similar animalsRelations of semantic similarity between codesnot expressed hierarchically are cross-referenced.There are 14 major codes, 127 group codes and2441 set codes.
The list of major codes belowprovides a general idea of the semantic areascovered:1.
<A> Life and living things2.
<B> The body, its functions and welfare3.
<C> People and the family4.
<D> Buildings, houses, the home, clothes,belongings, and personal care5.
<E> Food, drink, and farming6.
<F> Feelings, emotions, attitudes, andsensations7.
<G> Thought and communication, languageand grammar8.
<H> Substances, materials, objects, andequipment9.
<I> Arts and crafts, sciences andtechnology, industry and education10.
<J> Numbers, measurement, money, andcommerce11.
<K> Entertainment, sports, and games12.
<L> Space and time13.
<M> Movement, location, travel, andtransport14.
<N> General and abstract terms.4.2 Class-based word-alignmentWe can see clearly that computers cannotunderstand human dictionary, it only canrecognize machine dictionary (called MRD),leading to a limitation in vocabulary as well asambiguity in semantics when we align wordsrelying on dictionary.
So class-based alignmentis a solution supplementing the in-contexttranslations concept.In order to get a good result when usingclass-based algorithm, words in both Englishand Vietnamese have to be classified based ontheir senses (Resnik, 1999).
And the ways weuse to classify them should be as identical aspossible.
So we have chosen words in its classescorresponding to those in LLOCE.
Vietnameseword-classes are named after the availablenames of English ones.
These seed lexiconsmust have large coverages.
So after buildingthese lexicons, we use some more reliablethesauri to enrich them.4.2.1 Vietnamese word-class lexiconconstructionFor the sake of convenience, we call Vietnameseword-class lexicon ?CVDic?.
Words in thislexicon are classified into many groups.
Eachgroup has a unique name called class-code.
Ifknowing one class-code, we can easily know thenumber of words of that word-class and evenwhat these words are.Step 1:, translations of one English word inLLOCE are sequentially inserted in turn to thecorresponding class of CVDic.Consider ew = English wordvw = Vietnamese wordEC = English class-codeVC = Vietnamese class-codeWhen looking ew up in LLOCE, we obtain itssynonymous translations : vw1, vw2, vw3, ?Then vw1, vw2, vw3 ?
are added to CVDic as :VC vw1, vw2, vw3 ?As a result, each word class of CVDic includesat least one translation word.
Normally, thenumber of synonyms in Vietnamese are verylarge because the richness in the way oftranslation is one of the characteristics ofVietnamese.Step 2 :, we increase the coverage of the CVDicby using the English Vietnamese lexicon.
Sensesof one word of this English-Vietnamese lexiconare organised in synonym groups.
For each wordin the right hand side, we find if it appears insome word-classes of the CVDic, then addingthe whole group of VEDic to that class ofCVDic.We consider VG as a Vietnamese synonymgroup of EVDic :VGi = { a1,a2, ..., an } (i>0, n>0)In the Vietnamese-class lexicon, we have :word-class Cj  includes word set   VCj = { b1, b2,..., bm } (j>0,m>0).Then if (?bk ?
VCj, 1?k?m ?
bk ?
al ?
VGi,1?l?n) the class Cj ?
VCDic will contain thewords of VGi ?
VCj.4.2.2 Using WordNet to add synonyms toEnglish word-class lexiconAs you can see, Wordnet (Miller, 1996) is anon-line lexical reference system whose design isinspired by current psycholinguistic theories ofhuman lexical memory.
English nouns, verbs,and adjectives are organized into synonym sets.We take advantages of this valuable resource toadd more words to word classes in the Englishword-class lexicon, CEDic.In WordNet,  English words are grouped inSynsets (SN1,SN2,?
), this classification modelis much more detailed than the one in LLOCE.Therefore, if any two Synsets in these Synsetscontain two words which belong to the sameword-class, we add the words of the intersectionof these two Synsets to that word-class.
Thatmeans:ECewSNSNewECewECewSNewSNew ji??????????
),(,|,2121214.3 Word alignment algorithmBefore describing this algorithm briefly, wehave following conventions:S stands for English sentence and T stands forVietnamese one.
We have sentence pairtranslated by each other is (S,T), s is the word inS, t is the word in T which is translated by s in Sin context.
DTs is the set of dictionary meaningsfor s entry, each meaning is represented by d.WS = { s  }, set of English real words and idiomspresented in S.WT = { t | t ?T ?
t ?
VD }, set of Vietnamesepossible words presented in T.where :  VD is the Vietnamese Dictionarycontaining Vietnamese possible words andphrases.The problem is how computers can recognisewhich t in T will be aligned with which s in S.Relying on WT, we can solve the case resultingin the wrong definitions of words in Vietnamesesentences when we only carry out word segmentrelying on VD.
Our algorithm is in conformitywith the following steps.4.3.1 Dictionary-based word alignmentWe mainly calculate the similarity on morphemebetween each word d in DTs with all t in WTbased on formula calculating Dice coefficient(Dice, 1945) as follows:where: | d | and | t | : the number of morphemesin d and in t.| d ?
t | : the number of morphemes inthe intersection of d and t.Next, for each word pair (s, t) obtained fromDescartes product (WS x WT), we calculate thevalue of DTSim(s, t) presenting the likelihood ofa connection as follows :Examining a sample on following sentence pair:S =  ?The old man goes very fast?T =  ?O?ng cu?
?i qua?
nhanh?We will have:WS = { the, old, man, go, very, fast }WT = { o?ng, o?ng cu?, cu?, ?i, nhanh, qua?
}Suppose that we are examining on ?man?,DT(man) = { ng??
?i, ?a?n o?ng, nam nhi }So, we have:DTSim(man, o?ng) = max{ Sim(ng??
?i, o?ng),Sim (?a?n o?ng, o?ng), Sim(nam nhi, o?ng) }=max{(2x0)/(1+1),(2x1)/(2+1),(2x0)/(2+1)}= 0.67DTSim(man, o?ng cu?)
= max{ Sim(ng???i,o?ngcu?
), Sim(?a?n o?ng,o?ng cu?
), Sim(nam nhi, o?ngcu?
)}=max{(2x0)/(1+2),(2x1)/(2+2),(2x0)/(2+2)}=0.5Then, we choose candidate translation pairs ofgreatest likelihood of connection.4.3.2 Calculating the correlation betweentwo classes of two languagesThe correlation ratio of class X and class Y canbe measured using the Dice coefficient asfollows:Where |X|= the total number of the words in X,|Y|= the total number of the words in Y,From(a,Y) =1,if  ,),)(( ALLCONNyaYy ??
?= 0, otherwiseTo(X,b)= 1,   if  ,),)(( ALLCONNbxXx ??
?= 0, otherwise,ALLCONN : a list of initial connectionsobtained by running above dictionary-basedword alignment over the bilingual corpus.4.3.3 Estimating the  likelihood of candidatetranslation pairsA coefficient, presented by Brown (1993)establishing each connection is a probabilisticvalue Pr(s,t), showing translated probability ofeach pair  (s,t) in (S,T), calculated by product ofdictionary translated probability, t(s | t), anddislocated probability of words in sentences, d (i| j, l, m).
However Sue J. Ker and Jason S.Chang did not agree with it completely.
In theiropinion, it is very difficult to estimate t(s, t) andd(i, j) exactly for all values of s, t, i, j in theformula:We have the same opinion with them.
We cancreate functions based on dictionary, wordconcept and position of words in sentences tolimit cases to be examined and computed.The similar concept of word pair (s, t)  function:Then, combining with DTSim(s, t), we havefour value of t(s, t).
We have to combine withDTSim(s, t) because we are partially basing ondictionary.
Besides, we can solve the case thatthere are many words belonging to the sameclass in sentences.DTSim(s, t) = max Sim(d, t)||||),(),(),(YXbXToYaFromYXClassSim Xa Yb++=?
??
?Pr(s, t) = t(s, t) x d(i, j)ConceptSim(s,t) = maxClassSim(X,Y)s?X,t?Y(2)(4)(5)(3)2 x | d ?
t |Sim(d, t) =| d | + | t |(1)Table 3.
Constants in word alignmentDTSim(s, t) ConceptSim(s, t)a) t1 ?
h1 ?
h2b) t2 ?
h1 < h2c) t3 < h1 ?
h2d) t4 < h1 < h2Where h1 and h2 are thresholds chosen viaexperimental results.4.4 Result of sense tagging for corpusTable 6.
Result of sense tagged corpusJet planes fly about nine miles high.Ca?c phi c?
pha?n l?
?c bay cao ch?
?ng ch?n da?m.i 1 2 3 4 5 6 7S Jet planes fly about nine miles highTpha?nl?
?cca?c phic?
bay ch?
?ng ch?n da?m caoj 2 1 3 4 5 6 4M181 M180 M28 J4 J68 N305Because we have made use class-based wordalignment as described above, after aligningwords in bilingual corpus, we determine thesemantic class of each word.
For example:according to classification of LLOCE, theword ?letter?
has 2 meanings, one is?message?
(if it belongs to class G155) andone is ?alphabet?
(if it belongs to class G148).Table 4.
Result of sense tagging for ?letter?i 0 1 2 3 4 5 6S I write a letter to my friendT To?i vie?t mo?t b?
?cth?cho cu?ato?iba?nj 0 1 2 3 5 7 6G280G190G155G281C40Similarly, the word ?bank?
has 3meanings, one is ?money?
(if it belongs toclass J104), one is ?river?
(if it belongs to classL99) and one is ?line?
(if it belongs to J41class).
After aligning words, we have semantictags  as follows:Table 5.
Result of word alignment for ?bank?i 0 1 2 3S I enter the bankT To?i ?i va?o nha?
ba?ngj 0 1 2 3Class G280 M5 J104In this case, ?bank?
belongs to J104 class,that is the meaning of  ?bank?
is ?money?.4.5 Evaluation of sense tagging forcorpusTo evaluate the accuracy of our sensetagging in our corpus, we compare our resultwith SEMCOR (Shari Landes et.
al., 1999) onSUSANNE (Geoffrey Sampson, 1995) partonly.
We have done manual comparisonbecause there are differences between semantictags of LLOCE and SEMCOR.
The result is:70% of annotated words are assigned correctsense tags.4.6 Applying sense tagged corpus forWSDAfter annotating the bilingual corpus (mainlyEnglish texts), we will apply TBL method ofEric Brill (1993) to extract disambiguationrules based on POS, syntactic and semanticsinformation around the polysemous(ambiguous) words.Firstly, we proceed the initially tagging forall words (except stopwords) with ?naive?labels (most probable labels of this word).Secondly, the learner will generate rules thatmatch the templates showing the format of therules.All possible rules that match the templatesand replace the wrong tags with the correctones are generated  by the learner.
In order toknow whether this tag is correct or not, wemust base on the training corpus (annotatedcorpus from section 4).
TBL method has rulesunder following templates as follows:If we call semantic label (classification ofLLOCE) X and Y,.., the template will havefollowing format: ?Change X into Y if the Zcondition is met?.
The Z condition may be aword form, or a Part-Of-Speech (POS), or asyntactic label, or a semantic label.
Thus, wemust assign each English word to anappropriate  POS tag by an available POS-tagger (such as POS-tagger of Eric Brill) andsyntactic label by an available parser (such as :APP, PCPATR, ...).
After annotatingmorphological, syntactical  and semanticlabels, we will apply the above templates inwhich Z condition has one of followingformats:?
The ith -word to the left/right of theambiguous word is a certain ?word formW?
or a certain symbol.?
The ith -word to the left/right of theambiguous word is a certain POS k(lexical tag).?
The ith -word to the left/right of theambiguous word is  a syntactical function(e.g.
Subject or Object) of the ambiguousword (syntactic tags).?
The ith -word to the left/right of theambiguous word is  a certain semanticlabel L.After using the above templates to extracttransformation rules through training stages,we must manually revise them.
We willconsider these true and reasonabletransformation rules as disambiguation oneswhich can be applied in  the WSD module ofEnglish-to-Vietnamese MT system.5 ConclusionIn this paper , we have presented the buildingof semantically annotated bilingual corpus(based on semantic classes of LLOCE).
So far,we have built an English-Vietnamese bilingualcorpus with 5,000,000 words from selectedsources (in science-techniques andconventional fields).
We have also takenadvantage of corresponding features ofbilingual corpus to semantically annotate forEnglish (and Vietnamese) words via class-based word alignment.
This class-basedapproach has been experimented in ourEnglish-Vietnamese bilingual corpus andgiven encouraging results (nearly 70% ofambiguous words are assigned to correctsemantic labels).In the next stages, we will use thisannotated corpus as training corpus for WSDin our EVT with the machine learning methodof Eric Brill (TBL).ReferencesArthur.
1997.
Longman Lexicon OfContemporary English (Vietnamese version byTran Tat Thang), VN Education Publisher.Brown et al 1993.
The mathematics ofstatistical machine translation: Parameterestimation, Computational Linguistics, 19(2):263-311.Brill Eric.
1993.
A corpus-based approachto language learning, phi thesis, PennsylvaniaUni., USA.Gale W.A and Church K.W.
1991, Aprogram for aligning sentences in bilingualcorpora.
Proceedings of ACL-1991, ACL.Dice, 1945.
Measures of the amount ofecologic association between species.
Journalof Ecology, 26 pp.
297-302.Dien Dinh, Kiem Hoang, Toan NguyenVan, "Vietnamese Word Segmentation",Proceedings of NLPRS'01, Tokyo, Japan,10/2001, pp.
749-756.Dien Dinh, et al, "Word-alignment inEnglish-Vietnamese bilingual corpus",Proceedings of EALPIIT'02, HaNoi, Vietnam,1/2002, pp.
3-11.EAGLES.
1998.
An Extensible Architecturefor General Linguistic Engineering.Preliminary Recommendations on SemanticEncoding Interim Report.Geoffrey Sampson, 1995, English for theComputer.
Clarendon Press-Oxford.Isahara.
and Haruno.
2000.
Japanese-English aligned bilingual corpora, ParallelText Processing (edited by Jean Veronis),Kluwer Academic Press, 2000, pp.
313 ?
334.Melamed I.D.
2000.
Pattern recognitionfor mapping bitext correspondence, ParallelText Processing (edited by Jean Veronis),Kluwer Academic,  pp.
25 ?
48.Miller G.A.
1996.
Introduction to WordNet.5papers.ps: online lexical database athttp://www.cogsci.princeton.edu/~wn/.Princeton.Resnik P. 1999.
WordNet and Class-basedProbabilities, WORDNET: An ElectronicLexical Database (edited by ChristianeFellbaum), MIT Press,  pp.
239 ?
263.Shari Landes, Claudia Leacock, andRandee I.Tengi.
1999.
Building semanticconcordances.
WordNet : an electronic lexicaldatabase.Sue Ker J. and Jason Chang S. 1997.
AClass-based Approach to Word Alignment,Computational Linguistics, 23(2):313-343.Zinovjeva.
2000.
Learning sensedisambiguation rules for Machine Translation,MSc-thesis, Uppsala Uni.
