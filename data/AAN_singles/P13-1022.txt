Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 218?227,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsAdapting Discriminative Reranking to Grounded Language LearningJoohyun KimDepartment of Computer ScienceThe University of Texas at AustinAustin, TX 78701, USAscimitar@cs.utexas.eduRaymond J. MooneyDepartment of Computer ScienceThe University of Texas at AustinAustin, TX 78701, USAmooney@cs.utexas.eduAbstractWe adapt discriminative reranking to im-prove the performance of grounded lan-guage acquisition, specifically the task oflearning to follow navigation instructionsfrom observation.
Unlike conventionalreranking used in syntactic and semanticparsing, gold-standard reference trees arenot naturally available in a grounded set-ting.
Instead, we show how the weak su-pervision of response feedback (e.g.
suc-cessful task completion) can be used asan alternative, experimentally demonstrat-ing that its performance is comparable totraining on gold-standard parse trees.1 IntroductionGrounded language acquisition involves learn-ing to comprehend and/or generate language bysimply observing its use in a naturally occur-ring context in which the meaning of a sentenceis grounded in perception and/or action (Roy,2002; Yu and Ballard, 2004; Gold and Scassel-lati, 2007; Chen et al, 2010).
Bo?rschinger etal.
(2011) introduced an approach that reducesgrounded language learning to unsupervised prob-abilistic context-free grammar (PCFG) inductionand demonstrated its effectiveness on the task ofsportscasting simulated robot soccer games.
Sub-sequently, Kim and Mooney (2012) extended theirapproach to make it tractable for the more complexproblem of learning to follow natural-languagenavigation instructions from observations of hu-mans following such instructions in a virtual envi-ronment (Chen and Mooney, 2011).
The observedsequence of actions provides very weak, ambigu-ous supervision for learning instructional languagesince there are many possible ways to describe thesame execution path.
Although their approach im-proved accuracy on the navigation task comparedto the original work of Chen and Mooney (2011),it was still far from human performance.Since their system employs a generative model,discriminative reranking (Collins, 2000) could po-tentially improve its performance.
By training adiscriminative classifier that uses global featuresof complete parses to identify correct interpreta-tions, a reranker can significantly improve the ac-curacy of a generative model.
Reranking has beensuccessfully employed to improve syntactic pars-ing (Collins, 2002b), semantic parsing (Lu et al,2008; Ge and Mooney, 2006), semantic role la-beling (Toutanova et al, 2005), and named entityrecognition (Collins, 2002c).
Standard rerankingrequires gold-standard interpretations (e.g.
parsetrees) to train the discriminative classifier.
How-ever, grounded language learning does not providegold-standard interpretations for the training ex-amples.
Only the ambiguous perceptual contextof the utterance is provided as supervision.
Forthe navigation task, this supervision consists ofthe observed sequence of actions taken by a hu-man when following an instruction.
Therefore, itis impossible to directly apply conventional dis-criminative reranking to such problems.
We showhow to adapt reranking to work with such weaksupervision.
Instead of using gold-standard an-notations to determine the correct interpretations,we simply prefer interpretations of navigation in-structions that, when executed in the world, actu-ally reach the intended destination.
Additionally,we extensively revise the features typically used inparse reranking to work with the PCFG approachto grounded language learning.The rest of the paper is organized as fol-lows: Section 2 reviews the navigation task andthe PCFG approach to grounded language learn-ing.
Section 3 presents our modified approach toreranking and Section 4 describes the novel fea-tures used to evaluate parses.
Section 5 experi-mentally evaluates the approach comparing to sev-218(a) Sample virtual world of hallways with varying tiles,wallpapers, and landmark objects indicated by letters(e.g.
?H?
for hat-rack) and illustrating a sample pathtaken by a human follower.
(b) A sample natural language instruction and its formal land-marks plan for the path illustrated above.
The subset corre-sponding to the correct formal plan is shown in bold.Figure 1: Sample virtual world and instruction.eral baselines.
Finally, Section 6 describes relatedwork, Section 7 discusses future work, and Sec-tion 8 concludes.2 Background2.1 Navigation TaskWe address the navigation learning task intro-duced by Chen and Mooney (2011).
The goal isto interpret natural-language (NL) instructions in avirtual environment, thereby allowing a simulatedrobot to navigate to a specified location.
Figure 1ashows a sample path executed by a human follow-ing the instruction in Figure 1b.
Given no prior lin-guistic knowledge, the task is to learn to interpretsuch instructions by simply observing humans fol-low sample directions.
Formally speaking, giventraining examples of the form (ei, ai, wi), whereei is an NL instruction, ai is an executed actionsequence for the instruction, and wi is the initialworld state, we want to learn to produce an appro-priate action sequence aj given a novel (ej , wj).More specifically, one must learn a seman-tic parser that produces a plan pj using a for-mal meaning representation (MR) language intro-duced by Chen and Mooney (2011).
This plan isthen executed by a simulated robot in a virtual en-vironment.
The MARCO system, introduced byMacMahon et al (2006), executes the formal plan,flexibly adapting to situations encountered dur-ing execution and producing the action sequenceaj .
During learning, Chen and Mooney constructa landmarks plan ci for each training example,which includes the complete context observed inthe world-state resulting from each observed ac-tion.
The correct plan, pi, (which is latent andmust be inferred) is assumed to be composed froma subset of the components in the correspondinglandmarks plan.
The landmarks and correct plansfor a sample instruction are shown in Figure 1b.2.2 PCFG Induction for Grounded LanguageLearningThe baseline generative model we use for rerank-ing employs the unsupervised PCFG induction ap-proach introduced by Kim and Mooney (2012).This model is, in turn, based on the earlier modelof Bo?rschinger et al (2011), which transformsthe grounded language learning into unsupervisedPCFG induction.
The general approach usesgrammar-formulation rules which construct CFGproductions that form a grammar that effectivelymaps NL sentences to formal meaning represen-tations (MRs) encoded in its nonterminals.
Afterusing Expectation-Maximization (EM) to estimatethe parameters for these productions using the am-biguous supervision provided by the grounded-learning setting, it produces a PCFG whose mostprobable parse for a sentence encodes its correctsemantic interpretation.
Unfortunately, the initialapproach of Bo?rschinger et al (2011) produces ex-plosively large grammars when applied to morecomplex problems, such as our navigation task.Therefore, Kim and Mooney enhanced their ap-proach to use a previously learned semantic lexi-con to reduce the induced grammar to a tractablesize.
They also altered the processes for construct-ing productions and mapping parse trees to MRs inorder to make the construction of semantic inter-pretations more compositional and allow the ef-ficient construction of more complex representa-219Figure 2: Simplified parse for the sentence ?Turnleft and find the sofa then turn around the corner?for Kim and Mooney?s model.
Nonterminals showthe MR graph, where additional nonterminals forgenerating NL words are omitted.tions.The resulting PCFG can be used to producea set of most-probable interpretations of instruc-tional sentences for the navigation task.
Our pro-posed reranking model is used to discriminativelyreorder the top parses produced by this generativemodel.
A simplified version of a sample parse treefor Kim and Mooney?s model is shown in Figure 2.3 Modified Reranking AlgorithmIn reranking, a baseline generative model is firsttrained and generates a set of candidate outputsfor each training example.
Next, a second con-ditional model is trained which uses global fea-tures to rescore the candidates.
Reranking usingan averaged perceptron (Collins, 2002a) has beensuccessfully applied to a variety of NLP tasks.Therefore, we modify it to rerank the parse treesgenerated by Kim and Mooney (2012)?s model.The approach requires three subcomponents: 1)a GEN function that returns the list of top n can-didate parse trees for each NL sentence producedby the generative model, 2) a feature function ?that maps a NL sentence, e, and a parse tree, y,into a real-valued feature vector ?
(e, y) ?
Rd, and3) a reference parse tree that is compared to thehighest-scoring parse tree during training.However, grounded language learning tasks,such as our navigation task, do not provide ref-erence parse trees for training examples.
Instead,our modified model replaces the gold-standard ref-erence parse with the ?pseudo-gold?
parse treeAlgorithm 1 AVERAGED PERCEPTRON TRAIN-ING WITH RESPONSE-BASED UPDATEInput: A set of training examples (ei, y?i ),where ei is a NL sentence and y?i =arg maxy?GEN(ei) EXEC(y)Output: The parameter vector W?
, averagedover all iterations 1...T1: procedure PERCEPTRON2: Initialize W?
= 03: for t = 1...T, i = 1...n do4: yi = arg maxy?GEN(ei) ?
(ei, y) ?
W?5: if yi 6= y?i then6: W?
= W?
+ ?
(ei, y?i )?
?
(ei, yi)7: end if8: end for9: end procedurewhose derived MR plan is most successful at get-ting to the desired goal location.
Thus, the thirdcomponent in our reranking model becomes anevaluation function EXEC that maps a parse treey into a real number representing the success rate(w.r.t.
successfully reaching the intended destina-tion) of the derived MR plan m composed fromy.Additionally, we improve the perceptron train-ing algorithm by using multiple reference parsesto update the weight vector W?
.
Althoughwe determine the pseudo-gold reference tree tobe the candidate parse y?
such that y?
=arg maxy?GEN(e) EXEC(y), it may not actually bethe correct parse for the sentence.
Other parsesmay contain useful information for learning, andtherefore we devise a way to update weights us-ing all candidate parses whose successful execu-tion rate is greater than the parse preferred by thecurrently learned model.3.1 Response-Based Weight UpdatesTo circumvent the need for gold-standard refer-ence parses, we select a pseudo-gold parse fromthe candidates produced by the GEN function.
In asimilar vein, when reranking semantic parses, Geand Mooney (2006) chose as a reference parse theone which was most similar to the gold-standardsemantic annotation.
However, in the navigationtask, the ultimate goal is to generate a plan that,when actually executed in the virtual environment,leads to the desired destination.
Therefore, thepseudo-gold reference is chosen as the candidateparse that produces the MR plan with the great-220est execution success.
This requires an externalmodule that evaluates the execution accuracy ofthe candidate parses.
For the navigation task, weuse the MARCO (MacMahon et al, 2006) ex-ecution module, which is also used to evaluatehow well the overall system learns to follow direc-tions (Chen and Mooney, 2011).
Since MARCOis nondeterministic when executing underspecifiedplans, we execute each candidate plan 10 times,and its execution rate is the percentage of trialsin which it reaches the correct destination.
Whenthere are multiple candidate parses tied for thehighest execution rate, the one assigned the largestprobability by the baseline model is selected.
Ourmodified averaged perceptron procedure with sucha response-based update is shown in Algorithm 1.One additional issue must be addressed whencomputing the output of the GEN function.
The fi-nal plan MRs are produced from parse trees usingcompositional semantics (see Kim and Mooney(2012) for details).
Consequently, the n-best parsetrees for the baseline model do not necessarily pro-duce the n-best distinct plans, since many parsescan produce the same plan.
Therefore, we adaptthe GEN function to produce the n best distinctplans rather than the n best parses.
This mayrequire examining many more than the n bestparses, because many parses have insignificantdifferences that do not affect the final plan.
Thescore assigned to a plan is the probability of themost probable parse that generates that plan.
Inorder to efficiently compute the n best plans, wemodify the exact n-best parsing algorithm devel-oped by Huang and Chiang (2005).
The modifiedalgorithm ensures that each plan in the computedn best list produces a new distinct plan.3.2 Weight Updates Using Multiple ParsesTypically, when used for reranking, the averagedperceptron updates its weights using the feature-vector difference between the current best pre-dicted candidate and the gold-standard reference(line 6 in Algorithm 1).
In our initial modifiedversion, we replaced the gold-standard referenceparse with the pseudo-gold reference, which hasthe highest execution rate amongst all candidateparses.
However, this ignores all other candidateparses during perceptron training.
However, it isnot ideal to regard other candidate parses as ?use-less.?
There may be multiple candidate parses withthe same maximum execution rate, and even can-didates with lower execution rates could representthe correct plan for the instruction given the weak,indirect supervision provided by the observed se-quence of human actions.Therefore, we also consider a further mod-ification of the averaged perceptron algorithmwhich updates its weights using multiple candi-date parses.
Instead of only updating the weightswith the single difference between the predictedand pseudo-gold parses, the weight vector W?
isupdated with the sum of feature-vector differencesbetween the current predicted candidate and allother candidates that have a higher execution rate.Formally, in this version, we replace lines 5?6 ofAlgorithm 1 with:1: for all y ?
GEN(ei) where y 6= yi andEXEC(y) > EXEC(yi) do2: W?
= W?
+ (EXEC(y)?
EXEC(yi))?(?
(ei, y)?
?
(ei, yi))3: end forwhere EXEC(y) is the execution rate of the MRplan m derived from parse tree y.In the experiments below, we demonstrate that,by exploiting multiple reference parses, this newupdate rule increases the execution accuracy ofthe final system.
Intuitively, this approach gathersadditional information from all candidate parseswith higher execution accuracy when learning thediscriminative reranker.
In addition, as shown inline 2 of the algorithm above, it uses the differ-ence in execution rates between a candidate andthe currently preferred parse to weight the updateto the parameters for that candidate.
This allowsmore effective plans to have a larger impact on thelearned model in each iteration.4 Reranking FeaturesThis section describes the features ?
extractedfrom parses produced by the generative model andused to rerank the candidates.4.1 Base FeaturesThe base features adapt those used in previousreranking methods, specifically those of Collins(2002a), Lu et al (2008), and Ge and Mooney(2006), which are directly extracted from parsetrees.
In addition, we also include the log prob-ability of the parse tree as an additional feature.Figure 3 shows a sample full parse tree from ourbaseline model, which is used when explaining the221L1: Turn(LEFT), Verify(front : SOFA, back : EASEL),Travel(steps : 2), Verify(at : SOFA), Turn(RIGHT)L6: Turn()PhraseL6WordL6cornerPhXL6Word?thePhXL6WordL6aroundPhXL6WordL6turnPhXL6Word?thenL3: Travel(steps : 2),Verify(at : SOFA), Turn(RIGHT)L5: Travel(), Verify(at : SOFA)PhraseL5WordL5sofaPhXL5Word?thePhXL5WordL5findL2: Turn(LEFT),Verify(front : SOFA)L4: Turn(LEFT)PhraseL4Word?andPhL4WordL4leftPhXL4WordL4TurnFigure 3: Sample full parse tree for the sentence ?Turn left and find the soft then turn around the corner?used to explain reranking features.
Nonterminals representing MR plan components are shown, whichare labeled L1 to L6 for ease of reference.
Additional nonterminals such as Phrase, Ph, PhX , andWord are subsidiary ones for generating NL words from MR nonterminals.
They are also shown inorder to represent the entire process of how parse trees are constructed (for details, refer to Kim andMooney (2012)).reranking features below, each illustrated by an ex-ample.a) PCFG Rule.
Indicates whether a particularPCFG rule is used in the parse tree: f(L1 ?L2L3) = 1.b) Grandparent PCFG Rule.
Indicates whethera particular PCFG rule as well as the non-terminal above it is used in the parse tree:f(L3 ?
L5L6|L1) = 1.c) Long-range Unigram.
Indicates whether anonterminal has a given NL word below itin the parse tree: f(L2 ; left) = 1 andf(L4 ; turn) = 1.d) Two-level Long-range Unigram.
Indicateswhether a nonterminal has a child nontermi-nal which eventually generates a NL word inthe parse tree: f(L4 ; left|L2) = 1e) Unigram.
Indicates whether a nonterminalproduces a given child nonterminal or terminalNL word in the parse tree: f(L1 ?
L2) = 1and f(L1 ?
L3) = 1.f) Grandparent Unigram.
Indicates whethera nonterminal has a given child nontermi-nal/terminal below it, as well as a given parentnonterminal: f(L2 ?
L4|L1) = 1g) Bigram.
Indicates whether a given bigram ofnonterminal/terminals occurs for given a par-ent nonterminal: f(L1 ?
L2 : L3) = 1.h) Grandparent Bigram.
Same as Bigram, butalso includes the nonterminal above the parentnonterminal: f(L3 ?
L5 : L6|L1) = 1.i) Log-probability of Parse Tree.
Certainty as-signed by the base generative model.4.2 Predicate-Only FeaturesThe base features above generally include non-terminal symbols used in the parse tree.
In thegrounded PCFG model, nonterminals are namedafter components of the semantic representations(MRs), which are complex and numerous.
Thereare ' 2,500 nonterminals in the grammar con-structed for the navigation data, most of whichare very specific and rare.
This results in a verylarge, sparse feature space which can easily lead222the reranking model to over-fit the training dataand prevent it from generalizing properly.Therefore, we also tried constructing more gen-eral features that are less sparse.
First, we con-struct generalized versions of the base featuresin which nonterminal symbols use only predicatenames and omit their arguments.
In the navigationtask, action arguments frequently contain redun-dant, rarely used information.
In particular, theinterleaving verification steps frequently includemany details that are never actually mentioned inthe NL instructions.
For instance, a nonterminalfor the MRTurn(LEFT),Verify(at:SOFA,front:EASEL),Travel(steps:3)is transformed into the predicate-only formTurn(), Verify(), Travel(), and then used to construct more general versionsof the base features described in the previous sec-tion.
Second, another version of the base featuresare constructed in which nonterminal symbols in-clude action arguments but omit all interleavingverification steps.
This is a somewhat more con-servative simplification of the nonterminal sym-bols.
Although verification steps sometimes helpinterpret the actions and their surrounding context,they frequently cause the nonterminal symbols tobecome unnecessarily complex and specific.4.3 Descended Action FeaturesFinally, another feature group which we utilizecaptures whether a particular atomic action in anonterminal ?descends?
into one of its child non-terminals or not.
An atomic action consists of apredicate and its arguments, e.g.
Turn(LEFT),Travel(steps:2), or Verify(at:SOFA).When an atomic action descends into lower non-terminals in a parse tree, it indicates that it is men-tioned in the NL instruction and is therefore im-portant.
Below are several feature types related todescended actions that are used in our rerankingmodel:a) Descended Action.
Indicates whether a givenatomic action in a nonterminal descends to thenext level.
In Figure 3, f(Turn(LEFT)) = 1since it descends into L2 and L4.b) Descended Action Unigram.
Same as De-scended Action, but also includes the currentnonterminal: f(Turn(LEFT)|L1) = 1.c) Grandparent Descended Action Unigram.Same as Descended Action Unigram,but additionally includes the parentnonterminal as well as the current one:f(Turn(LEFT)|L2, L1) = 1.d) Long-range Descended Action Unigram.
Indi-cates whether a given atomic action in a non-terminal descends to a child nonterminal andthis child generates a given NL word below it:f(Turn(LEFT) ; left) = 15 Experimental Evaluation5.1 Data and MethodologyThe navigation data was collected by MacMahonet al (2006), and includes English instructionsand human follower data.1 The data contains 706route instructions for three virtual worlds.
The in-structions were produced by six instructors for 126unique starting and ending location pairs over thethree maps.
Each instruction is annotated with 1to 15 human follower traces with an average of10.4 actions per instruction.
Each instruction con-tains an average of 5.0 sentences each with an av-erage of 7.8 words.
Chen and Mooney (2011)constructed a version of the data in which eachsentence is annotated with the actions taken bythe majority of followers when responding to thissentence.
This single-sentence version is used fortraining.
Manually annotated ?gold standard?
for-mal plans for each sentence are used for evaluationpurposes only.We followed the same experimental methodol-ogy as Kim and Mooney (2012) and Chen andMooney (2011).
We performed ?leave one en-vironment out?
cross-validation, i.e.
3 trials oftraining on two environments and testing on thethird.
The baseline model is first trained on datafor two environments and then used to generatethe n = 50 best plans for both training and test-ing instructions.
As mentioned in Section 3.1, weneed to generate many more top parse trees to get50 distinct formal MR plans.
We limit the num-ber of best parse trees to 1,000,000, and even withthis high limit, some training examples were leftwith less than 50 distinct plans.2 Each candidate1Data is available at http://www.cs.utexas.edu/users/ml/clamp/navigation/29.6% of the examples (310 out of total 3237) producedless than 50 distinct MR plans in the evaluation.
This wasmostly due to exceeding the parse-tree limit and partly be-cause the baseline model failed to parse some NL sentences.223n 1 2 5 10 25 50Parse Accuracy F1 74.81 79.08 82.78 85.32 87.52 88.62Plan Execution Single-sentence 57.22 63.86 70.93 76.41 83.59 87.02Paragraph 20.17 28.08 35.34 40.64 48.69 53.66Table 1: Oracle parse and execution accuracy for single sentence and complete paragraph instructionsfor the n best parses.plan is then executed using MARCO and its rateof successfully reaching the goal is recorded.
Ourreranking model is then trained on the trainingdata using the n-best candidate parses.
We onlyretain reranking features that appear (i.e.
have avalue of 1) at least twice in the training data.Finally, we measure both parse and executionaccuracy on the test data.
Parse accuracy evalu-ates how well a system maps novel NL sentencesfor new environments into correct MR plans (Chenand Mooney, 2011).
It is calculated by compar-ing the system?s MR output to the gold-standardMR.
Accuracy is measured using F1, the harmonicmean of precision and recall for individual MRconstituents, thereby giving partial credit to ap-proximately correct MRs. We then execute the re-sulting MR plans in the test environment to seewhether they successfully reach the desired des-tinations.
Execution is evaluated both for sin-gle sentence and complete paragraph instructions.Successful execution rates are calculated by aver-aging 10 nondeterministic MARCO executions.5.2 Reranking ResultsOracle resultsAs typical in reranking experiments, we firstpresent results for an ?oracle?
that always returnsthe best result amongst the top-n candidates pro-duced by the baseline system, thereby providingan upper bound on the improvements possiblewith reranking.
Table 1 shows oracle accuracy forboth semantic parsing and plan execution for sin-gle sentence and complete paragraph instructionsfor various values of n. For oracle parse accuracy,for each sentence, we pick the parse that givesthe highest F1 score.
For oracle single-sentenceexecution accuracy, we pick the parse that givesthe highest execution success rate.
These single-sentence plans are then concatenated to produce acomplete plan for each paragraph instruction in or-der to measure overall execution accuracy.
Sincemaking an error in any of the sentences in an in-struction can easily lead to the wrong final destina-tion, paragraph-level accuracies are always muchlower than sentence-level ones.
In order to bal-ance oracle accuracy and the computational ef-fort required to produce n distinct plans, we chosen = 50 for the final experiments since oracle per-formance begins to asymptote at this point.Response-based vs. gold-standard referenceweight updatesTable 2 presents reranking results for our proposedresponse-based weight update (Single) for theaveraged perceptron (cf.
Section 3.1) comparedto the typical weight update method using gold-standard parses (Gold).
Since the gold-standardannotation gives the correct MR rather than a parsetree for each sentence, Gold selects as a singlereference parse the candidate in the top 50 whoseresulting MR is most similar to the gold-standardMR as determined by its parse accuracy.
Ge andMooney (2006) employ a similar approach whenreranking semantic parses.The results show that our response-based ap-proach (Single) has better execution accuracythan both the baseline and the standard approachusing gold-standard parses (Gold).
However,Gold does perform best on parse accuracy sinceit explicitly focuses on maximizing the accuracyof the resulting MR.
In contrast, by focusing dis-criminative training on optimizing performanceof the ultimate end task, our response-based ap-proach actually outperforms the traditional ap-proach on the final task.
In addition, it only uti-lizes feedback that is naturally available for thetask, rather than requiring an expert to laboriouslyannotate each sentence with a gold-standard MR.Even though Gold captures more elements of thegold-standard MRs, it may miss some critical MRcomponents that are crucial to the final naviga-tion task.
The overall result is very promising be-cause it demonstrates how reranking can be ap-plied to grounded language learning tasks wheregold-standard parses are not readily available.224Parse Acc Plan ExecutionF1 Single ParaBaseline 74.81 57.22 20.17Gold 78.26 52.57 19.33Single 73.32 59.65 22.62Multi 73.43 62.81 26.57Table 2: Reranking results comparing ourresponse-based methods using single (Single)or multiple (Multi) pseudo-gold parses to thestandard approach using a single gold-standardparse (Gold).
Baseline refers to Kim andMooney (2012)?s system.
Reranking results useall features described in Section 4.
?Single?
meansthe single-sentence version and ?Para?
means thefull paragraph version of the corpus.Weight update with single vs. multiplereference parsesTable 2 also shows performance when using mul-tiple reference parse trees to update weights (cf.Section 3.2).
Using multiple parses (Multi)clearly performs better for all evaluation met-rics, particularly execution.
As explained in Sec-tion 3.2, the single-best pseudo-gold parse pro-vides weak, ambiguous feedback since it only pro-vides a rough estimate of the response feedbackfrom the execution module.
Using a variety ofpreferable parses to update weights provides agreater amount and variety of weak feedback andtherefore leads to a more accurate model.3Comparison of different feature groupsTable 3 compares reranking results using the dif-ferent feature groups described in Section 4.
Com-pared to the baseline model (Kim and Mooney,2012), each of the feature groups Base (basefeatures), Pred (predicate-only and verification-removed features), and Desc (descended actionfeatures) helps improve the performance of planexecution for both single sentence and completeparagraph navigation instructions.
Among them,Desc is the most effective group of features.Combinations of the feature groups helps fur-3We also tried extending Gold to use multiple referenceparses in the same manner, but this actually degraded its per-formance for all metrics.
This indicates that, unlike Multi,parses other than the best one do not have useful informationin terms of optimizing normal parse accuracy.
Instead, ad-ditional parses seem to add noise to the training process inthis case.
Therefore, updating with multiple parses does notappear to be useful in standard reranking.Features Parse Acc Plan ExecutionF1 Single ParaBaseline 74.81 57.22 20.17Base 71.50 60.09 23.20Pred 71.61 60.87 24.13Desc 73.90 61.33 25.00Base+Pred 69.52 61.49 26.24Base+Desc 73.66 61.72 25.58Pred+Desc 72.56 62.36 26.04All 73.43 62.81 26.57Table 3: Reranking results comparing differentsets of features.
Base refers to base features (cf.Section 4.1), Pred refers to predicate-only fea-tures and also includes features based on remov-ing interleaving verification steps (cf.
Section 4.2),Desc refers to descended action features (cf.
Sec-tion 4.3).
All refers to all the features includingBase, Pred, and Desc.
All results use weightupdate with multiple reference parses (cf.
Sec-tion 3.2).ther improve the plan execution performance, andreranking using all of the feature groups (All)performs the best, as expected.
However, sinceour model is optimizing plan execution duringtraining, the results for parse accuracy are alwaysworse than the baseline model.6 Related WorkDiscriminative reranking is a common machinelearning technique to improve the output of gen-erative models.
It has been shown to be effectivefor various natural language processing tasks in-cluding syntactic parsing (Collins, 2000; Collins,2002b; Collins and Koo, 2005; Charniak andJohnson, 2005; Huang, 2008), semantic parsing(Lu et al, 2008; Ge and Mooney, 2006), part-of-speech tagging (Collins, 2002a), semantic rolelabeling (Toutanova et al, 2005), named entityrecognition (Collins, 2002c).
machine translation(Shen et al, 2004; Fraser and Marcu, 2006) andsurface realization in generation (White and Ra-jkumar, 2009; Konstas and Lapata, 2012).
How-ever, to our knowledge, there has been no pre-vious attempt to apply discriminative rerankingto grounded language acquisition, where gold-standard reference parses are not typically avail-able for training reranking models.Our use of response-based training is similar225to work on learning semantic parsers from execu-tion output such as the answers to database queries(Clarke et al, 2010; Liang et al, 2011).
Althoughthe demands of grounded language tasks, such asfollowing navigation instructions, are different, itwould be interesting to try adapting these alterna-tive approaches to such problems.7 Future WorkIn the future, we would like to explore the con-struction of better, more-general reranking fea-tures that are less prone to over-fitting.
Sincetypical reranking features rely on the combina-tion and/or modification of nonterminals appear-ing in parse trees, for the large PCFG?s producedfor grounded language learning, such features arevery sparse and rare.
Although the current featuresprovide a significant increase in performance, or-acle results imply that an even larger benefit maybe achievable.In addition, employing other reranking method-ologies, such as kernel methods (Collins, 2002b),and forest reranking exploiting a packed forest ofexponentially many parse trees (Huang, 2008), isanother area of future work.
We also would liketo apply our approach to other reranking algo-rithms such as SVMs (Joachims, 2002) and Max-Ent methods (Charniak and Johnson, 2005).8 ConclusionsIn this paper, we have shown how to adapt dis-criminative reranking to grounded language learn-ing.
Since typical grounded language learningproblems, such as navigation instruction follow-ing, do not provide the gold-standard referenceparses required by standard reranking models, wehave devised a novel method for using the weakersupervision provided by response feedback (e.g.the execution of inferred navigation plans) whentraining a perceptron-based reranker.
This ap-proach was shown to be very effective comparedto the traditional method of using gold-standardparses.
In addition, since this response-based su-pervision is weak and ambiguous, we have alsopresented a method for using multiple referenceparses to perform perceptron weight updates andshown a clear further improvement in end-taskperformance with this approach.AcknowledgmentsWe thank anonymous reviewers for their helpfulcomments to improve this paper.
This work wasfunded by the NSF grant IIS-0712907 and IIS-1016312.
Experiments were performed on theMastodon Cluster, provided by NSF Grant EIA-0303609.ReferencesBenjamin Bo?rschinger, Bevan K. Jones, and MarkJohnson.
2011.
Reducing grounded learning tasksto grammatical inference.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, EMNLP ?11, pages 1416?1425,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminativereranking.
In Proceedings of the 43nd Annual Meet-ing of the Association for Computational Linguistics(ACL-05), pages 173?180, Ann Arbor, MI, June.David L. Chen and Raymond J. Mooney.
2011.
Learn-ing to interpret natural language navigation instruc-tions from observations.
In Proceedings of the 25thAAAI Conference on Artificial Intelligence (AAAI-2011), San Francisco, CA, USA, August.David L. Chen, Joohyun Kim, and Raymond J.Mooney.
2010.
Training a multilingual sportscaster:Using perceptual context to learn language.
Journalof Artificial Intelligence Research, 37:397?435.James Clarke, Dan Goldwasser, Ming-Wei Chang, andDan Roth.
2010.
Driving semantic parsing fromthe world?s response.
In Proceedings of the Four-teenth Conference on Computational Natural Lan-guage Learning (CoNLL-2010), pages 18?27, Upp-sala, Sweden, July.
Association for ComputationalLinguistics.Michael Collins and Terry Koo.
2005.
Discriminativereranking for natural language parsing.
Computa-tional Linguistics, 31(1):25?69.Michael Collins.
2000.
Discriminative reranking fornatural language parsing.
In Proceedings of theSeventeenth International Conference on MachineLearning (ICML-2000), pages 175?182, Stanford,CA, June.Michael Collins.
2002a.
Discriminative training meth-ods for hidden Markov models: Theory and ex-periments with perceptron algorithms.
In Proceed-ings of the 2002 Conference on Empirical Meth-ods in Natural Language Processing (EMNLP-02),Philadelphia, PA, July.Michael Collins.
2002b.
New ranking algorithms forparsing and tagging: Kernels over discrete struc-tures, and the voted perceptron.
In Proceedings of226the 40th Annual Meeting of the Association for Com-putational Linguistics (ACL-2002), pages 263?270,Philadelphia, PA, July.Michael Collins.
2002c.
Ranking algorithms fornamed-entity extraction: Boosting and the votedperceptron.
In Proceedings of the 40th AnnualMeeting of the Association for Computational Lin-guistics (ACL-2002), pages 489?496, Philadelphia,PA.Alexander Fraser and Daniel Marcu.
2006.
Semi-supervised training for statistical word alignment.In Proceedings of the 21st International Conferenceon Computational Linguistics and the 44th annualmeeting of the Association for Computational Lin-guistics (ACL-06), pages 769?776, Stroudsburg, PA,USA.
Association for Computational Linguistics.R.
Ge and R. J. Mooney.
2006.
Discriminativereranking for semantic parsing.
In Proceedings ofthe 21st International Conference on ComputationalLinguistics and 44th Annual Meeting of the Associa-tion for Computational Linguistics (COLING/ACL-06), Sydney, Australia, July.Kevin Gold and Brian Scassellati.
2007.
A robot thatuses existing vocabulary to infer non-visual wordmeanings from observation.
In Proceedings of the22nd national conference on Artificial intelligence -Volume 1, AAAI?07, pages 883?888.
AAAI Press.Liang Huang and David Chiang.
2005.
Better k-best parsing.
In Proceedings of the Ninth Inter-national Workshop on Parsing Technology, Parsing?05, pages 53?64, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Liang Huang.
2008.
Forest reranking: Discrimina-tive parsing with non-local features.
In Proceedingsof ACL-08: HLT, pages 586?594, Columbus, Ohio,June.
Association for Computational Linguistics.Thorsten Joachims.
2002.
Optimizing search en-gines using clickthrough data.
In Proceedings ofthe Eighth ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining (KDD-2002), Edmonton, Canada.Joohyun Kim and Raymond J. Mooney.
2012.
Un-supervised PCFG induction for grounded languagelearning with highly ambiguous supervision.
In Pro-ceedings of the Conference on Empirical Methodsin Natural Language Processing and Natural Lan-guage Learning, EMNLP-CoNLL ?12.Ioannis Konstas and Mirella Lapata.
2012.
Concept-to-text generation via discriminative reranking.
InProceedings of the 50th Annual Meeting of the Asso-ciation for Computational Linguistics: Long Papers- Volume 1, ACL ?12, pages 369?378, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.Percy Liang, Michael I. Jordan, and Dan Klein.
2011.Learning dependency-based compositional seman-tics.
In Proceedings of ACL, Portland, Oregon, June.Association for Computational Linguistics.Wei Lu, Hwee Tou Ng, Wee Sun Lee, and Luke S.Zettlemoyer.
2008.
A generative model for pars-ing natural language to meaning representations.
InProceedings of the 2008 Conference on EmpiricalMethods in Natural Language Processing (EMNLP-08), Honolulu, HI, October.Matt MacMahon, Brian Stankiewicz, and BenjaminKuipers.
2006.
Walk the talk: connecting language,knowledge, and action in route instructions.
In pro-ceedings of the 21st national conference on Artifi-cial intelligence - Volume 2, AAAI?06, pages 1475?1482.
AAAI Press.Deb Roy.
2002.
Learning visually grounded wordsand syntax for a scene description task.
ComputerSpeech and Language, 16(3):353?385.Libin Shen, Anoop Sarkar, and Franz Josef Och.
2004.Discriminative reranking for machine translation.
InDaniel Marcu Susan Dumais and Salim Roukos, ed-itors, HLT-NAACL 2004: Main Proceedings, pages177?184, Boston, Massachusetts, USA, May 2 -May 7.
Association for Computational Linguistics.Kristina Toutanova, Aria Haghighi, and Christopher D.Manning.
2005.
Joint learning improves semanticrole labeling.
In Proceedings of the 43nd AnnualMeeting of the Association for Computational Lin-guistics (ACL-05), pages 589?596, Ann Arbor, MI,June.Michael White and Rajakrishnan Rajkumar.
2009.Perceptron reranking for CCG realization.
In Pro-ceedings of the 2009 Conference on Empirical Meth-ods in Natural Language Processing: Volume 1 -Volume 1, EMNLP ?09, pages 410?419, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Chen Yu and Dana H. Ballard.
2004.
On the integra-tion of grounding language and learning objects.
InProceedings of the Nineteenth National Conferenceon Artificial Intelligence (AAAI-04), pages 488?493.227
