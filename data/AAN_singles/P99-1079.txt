Analysis of Syntax-Based Pronoun Resolution MethodsJ oe l  R .
Tet reau l tUniversity of RochesterDepartment  of Computer  ScienceRochester, NY, 14627tetreaul@cs, rochester ,  eduAbst rac tThis paper presents a pronoun resolution algo-r ithm that adheres to the constraints and rulesof Centering Theory (Grosz et al, 1995) andis an alternative to Brennan et al's 1987 algo-rithm.
The advantages of this new model, theLeft-Right Centering Algorithm (LRC), lie inits incremental processing of utterances and inits low computational overhead.
The algorithmis compared with three other pronoun resolu-tion methods: Hobbs' syntax-based algorithm,Strube's S-list approach, and the BFP Center-ing algorithm.
All four methods were imple-mented in a system and tested on an annotatedsubset of the Treebank corpus consisting of 2026pronouns.
The noteworthy results were thatHobbs and LRC performed the best.1 In t roduct ionThe aim of this project is to develop a pro-noun resolution algorithm which performs bet-ter than the Brennan et al 1987 algorithm 1as a cognitive model while also performing wellempirically.A revised algorithm (Left-Right Centering)was motivated by the fact that the BFP al-gorithm did not allow for incremental process-ing of an utterance and hence of its pronouns,and also by the fact that it occasionally im-poses a high computational load, detractingfrom its psycholinguistic plausibility.
A sec-ond motivation for the project is to remedythe dearth of empirical results on pronoun res-olution methods.
Many small comparisons ofmethods have been made, such as by Strube(1998) and Walker (1989), but those usuallyconsist of statistics based on a small hand-tested corpus.
The problem with evaluating1Henceforth BFPalgorithms by hand is that it is time consum-ing and difficult to process corpora that arelarge enough to provide reliable, broadly basedstatistics.
By creating a system that can runalgorithms, one can easily and quickly analyzelarge amounts of data and generate more reli-able results.
In this project, the new algorithmis tested against hree leading syntax-based pro-noun resolution methods: Hobbs' naive algo-r ithm (1977), S-list (Strube 1998), and BFP.Section 2 presents the motivation and algo-r ithm for Left-Right Centering.
In Section 3,the results of the algorithms are presented andthen discussed in Section 4.2 Left-Right Centering Algor i thmLeft-Right Centering (LRC) is a formalizedalgorithm built upon centering theory's con-straints and rules as detailed in Grosz et.
al(1995).
The creation of the LRC Algorithmis motivated by two drawbacks found in theBFP method.
The first is BFP's limitation asa cognitive model since it makes no provisionfor incremental resolution of pronouns (Kehler1997).
Psycholinguistic research support theclaim that listeners process utterances one wordat a time, so when they hear a pronoun theywill try to resolve it immediately.
If new infor-mation comes into play which makes the reso-lution incorrect (such as a violation of bindingconstraints), the listener will go back and find acorrect antecedent.
This incremental resolutionproblem also motivates Strube's S-list approach.The second rawback to the BFP algorithm isthe computational explosion of generating andfiltering anchors.
In utterances with two ormore pronouns and a Cf-list with several can-didate antecedents for each pronoun, thousandsof anchors can easily be generated making fora time consuming filtering phase.
An exam-602ple from the evaluation corpus illustrates thisproblem (the italics in Un-1 represent possibleantecedents for the pronouns (in italics) of Un):Un-l: Separately, the Federal Energy Regu-latory Commission turned down for now a re-quest by Northeast seeking approval of its possi-ble purchase of PS of New Hampshire.Un: Northeast said it would refile its requestand still hopes for an expedited review by theFERC so that it could complete the purchaseby next summer if its bid is the one approvedby the bankruptcy court.With four pronouns in Un, and eight possibleantecedents for each in Un-1, 4096 unique Cf-lists are generated.
In the cross-product phase,9 possible Cb's are crossed with the 4096 Cf's,generating 36864 anchors.Given these drawbacks, we propose a revisedresolution algorithm that adheres to centeringconstraints.
It works by first searching for anantecedent in the current utterance 2, if one isnot found, then the previous Cf-lists (startingwith the previous utterance) are searched left-to-right for an antecedent:1.
Preprocess ing - from previous utterance:Cb(Un-1) and Cf(Un-1) are  available.2.
Process Utterance - parse and extractincrementally from Un all references to dis-course entities.
For each pronoun do:(a) Search for an antecedent intrasenten-tially in Cf-partial(Un) 3 that meetsfeature and binding constraints.If one is found proceed to the next pro-noun within utterance.
Else go to (b).
(b) Search for an antecedent intersenten-tially in Cf(Un-1) that meets featureand binding constraints.3.
Create  C f -  create Cf-list of Un by rank-ing discourse ntities of Un according togrammatical function.
Our implementa-tion used a left-right breadth-first walk ofthe parse tree to approximate sorting bygrammatical function.2In this project, a sentence is considered an utterance3Cf-partial is a list of all processed iscourse ntitiesin Un4.
Ident i fy  Cb - the backward-looking cen-ter is the most highly ranked entity fromCf(Un-1) rea l i zed  in  Cf(Un).5.
Ident i fy  Transit ion - with the Cb and Cfresolved, use the criteria from (Brennan etal., 1987) to assign the transition.It should be noted that BFP makes use ofCentering Rule 2 (Grosz et al, 1995), LRC doesnot use the transition generated or Rule 2 insteps 4 and 5 since Rule 2's role in pronounresolution is not yet known (see Kehler 1997 fora critique of its use by BFP).Computational overhead is avoided since noanchors or auxiliary data structures need to beproduced and filtered.3 Evaluation of AlgorithmsAll four algorithms were run on a 3900 utterancesubset of the Penn Treebank annotated corpus(Marcus et al, 1993) provided by Charniak andGe (1998).
The corpus consists of 195 differentnewspaper articles.
Sentences are fully brack-eted and have labels that indicate word-classand features.
Because the S-list and BFP algo-rithms do not allow resolution of quoted text,all quoted expressions were removed from thecorpus, leaving 1696 pronouns (out of 2026) tobe resolved.For analysis, the algorithms were broken upinto two classes.
The "N" group consists of al-gorithms that search intersententially throughall Cf-lists for an antecedent.
The "1" groupconsists of algorithms that can only search foran antecedent in Cf(Un-1).
The results for the"N" algorithms and "1" algorithms are depictedin Figures 1 and 2 respectively.For comparison, a baseline algorithm was cre-ated which simply took the most recent NP (bysurface order) that met binding and feature con-straints.
This naive approach resolved 28.6 per-cent of pronouns correctly.
Clearly, all four per-form better than the naive approach.
The fol-lowing section discusses the performance of eachalgorithm.4 DiscussionThe surprising result from this evaluation isthat the Hobbs algorithm, which uses the leastamount of information, actually performs thebest.
The difference of six more pronouns right603Algorithm Right % Right % Right Intra % Right InterHobbs 1234 72.8 68.4 85.0LRC-N 1228 72.4 67.8 85.2Strube-N 1166 68.8 62.9 85.2Figure 1: "N" algorithms: search all previous Cf listsAlgorithmLRC-1Strube-1BFPRight % Right % Right Intra % Right Inter1208 71.2 68.4 80.71120 66.0 60.3 71.1962 56.7 40.7 78.8Figure 2: "1" algorithms: search Cf(Un-1) onlybetween LRC-N and Hobbs is statistically in-significant so one may conclude that the newcentering algorithm is also a viable method.Why do these algorithms perform better thanthe others?
First, both search for referents in-trasententially and then intersentially.
In thiscorpus, over 71% of all pronouns have intrasen-tential referents, so clearly an algorithm thatfavors the current utterance will perform bet-ter.
Second, both search their respective datastructures in a salience-first manner.
Inter-sententially, both examine previous utterancesin the same manner.
LRC-N sorts the Cf-list by grammatical function using a breadth-first search and by moving prepended phrasesto a less salient position.
While Hobbs' algo-r ithm does not do the movement i  still searchesits parse tree in a breadth-first manner thusemulating the Cf-list search.
Intrasententially,Hobbs gets slightly more correct since it firstfavors antecedents close to the pronoun beforesearching the rest of the tree.
LRC favors en-tities near the head of the sentence under theassumption they are more salient.
The similar-ities in intra- and intersentential evaluation arereflected in the similarities in their percent rightfor the respective categories.Because the S-list approach incorporates bothsemantics and syntax in its familiarity rank-ing scheme, a shallow version which only usessyntax is implemented in this study.
Eventhough several entities were incorrectly labeled,the shallow S-list approach still performed quitewell, only 4 percent lower than Hobbs and LRC-i .The standing of the BFP algorithm shouldnot be too surprising iven past studies.
Forexample, Strube (1997) had the S-list algorithmperforming at 91 percent correct on three NewYork Times articles while the best version ofBFP performed at 81 percent.
This ten per-cent difference is reflected in the present eval-uation as well.
The main drawback for BFPwas its preference for intersentential resolution.Also, BFP as formally defined does not havean intrasentential processing mechanism.
Forthe purposes of the project, the LRC intrasen-tential technique was used to resolve pronounsthat were unable to be resolved by the BFP (in-tersentential) algorithm.In additional experiments, Hobbs and LRC-N were tested with quoted expressions included.LRC used an approach similar to the oneproposed by Kamayema (1998) for analyzingquoted expressions.
Given this new approach,70.4% of the 2026 pronouns were resolved cor-rectly by LRC while Hobbs performed at 69.8%,a difference of only 13 pronouns right.5 Conc lus ionsThis paper first presented a revised pronounresolution algorithm that adheres to the con-straints of centering theory.
It is inspired bythe need to remedy a lack of incremental pro-cessing and computational issues with the BFPalgorithm.
Second, the performance of LRCwas compared against hree other leading pro-noun resolution algorithms based solely on syn-tax.
The comparison of these algorithms is604significant in its own right because they havenot been previously compared, in computer-encoded form, on a common corpus.
Coding allthe algorithms allows one to quickly test themall on a large corpus and eliminates human er-ror, both shortcomings of hand evaluation.Most noteworthy is the performance ofHobbsand LRC.
The Hobbs approach reveals that awalk of the parse tree performs just as well assalience based approaches.
LRC performs justas well as Hobbs, but the important point isthat it can be considered as a replacement forthe BFP algorithm not only in terms of perfor-mance but in terms of modeling.
In terms ofimplementation, Hobbs is dependent on a pre-cise parse tree for its analysis.
If no parse treeis available, Strube's S-list algorithm and LRCprove more useful since grammatical functioncan be approximated by using surface order.6 Future  WorkThe next step is to  test all four algorithms ona novel or short stories.
Statistics from theWalker and Strube studies suggest hat BFPwill perform better in these cases.
Other futurework includes constructing a hybrid algorithmof LRC and S-list in which entities are rankedboth by the familiarity scale and by grammati-cal function.
Research into how transitions andthe Cb can be used in a pronoun resolution al-gorithm should also be examined.
Strube andHahn (1996) developed a heuristic of rankingtransition pairs by cost to evaluate different Cf-ranking schemes.
Perhaps this heuristic couldbe used to constrain the search for antecedents.It is quite possible that hybrid algorithms (i.e.using Hobbs for intrasentential resolution, LRCfor intersentential) may not produce any sig-nificant improvement over the current systems.If so, this might indicate that purely syntacticmethods cannot be pushed much farther, andthe upper limit reached can serve as a base linefor approaches that combine syntax and seman-tics.7 AcknowledgmentsI am grateful to Barbara Grosz for aiding mein the development of the LRC algorithm anddiscussing centering issues.
I am also grate-ful to Donna Byron who was responsible formuch brainstorming, cross-checking of results,and coding of the Hobbs algorithm.
Specialthanks goes to Michael Strube, James Allen,and Lenhart Schubert for their advice andbrainstorming.
We would also like to thankCharniak and Ge for the annotated, parsedTreebank corpus which proved invaluable.Partial support for the research reported inthis paper was provided by the National Sci-ence Foundation under Grants No.
IRI-90-09018, IRI-94-04756 and CDA-94-01024 to Har-yard University and also by the DARPA re-search grant no.
F30602-98-2-0133 to the Uni-versity of Rochester.ReferencesSusan E. Brennan, Marilyn W. Friedman, andCarl J. Pollard.
1987.
A centering approachto pronouns.
In Proceedings, 25th AnnualMeeting of the ACL, pages 155-162.Niyu Ge, John Hale, and Eugene Charniak.1998.
A statistical approach to anaphora res-olution.
Proceedings of the Sixth Workshopon Very Large Corpora.Barbara J. Grosz, Aravind K. Joshi, and ScottWeinstein.
1995.
Centering: A frameworkfor modeling the local coherence of discourse.Computational Linguistics, 21 (2):203-226.Jerry R. Hobbs.
1977.
Resolving pronoun ref-erences.
Lingua, 44:311-338.Megumi Kameyama.
1986.
Intrasentential cen-tering: A case study.
In Centering Theory inDiscourse.Andrew Kehler.
1997.
Current theories of cen-tering for pronoun interpretation: A crit-ical evaluation.
Computational Linguistics,23(3):467-475.Mitchell P. Marcus, Beatrice Santorini, andMary Ann Marcinkiewicz.
1993.
Buildinga large annotated corpus of english: Thepenn treebank.
Computational Lingusitics,19(2):313-330.Michael Strube and Udo Hahn.
1996.
Func-tional centering.
In Association for Compu-tational Lingusitics, pages 270-277.Michael Strube.
1998.
Never look back: Analternative to centering.
In Association forComputational Lingusitics, pages 1251-1257.Marilyn A. Walker.
1989.
Evaluating discourseprocessing algorithms.
In Proceedings, 27thAnnual Meeting of the Association for Com-puational Linguisites, pages 251-261.605
