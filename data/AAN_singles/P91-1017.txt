Two Languages Are More Informative Than One *Ido DaganComputer Science DepartmentTechnion, Haifa, IsraelandIBM Scientific CenterHaifa, Israeldagan@cs.technion.ac.ilAlon ItaiComputer Science DepartmentTechnion, Haifa, Israelitai~cs.technion.ac.ilUlrike SchwallIBM Scientific CenterInst i tute for KnowledgeBased SystemsHeidelberg, Germanyschwall@dhdibmlAbst rac tThis paper presents a new approach for resolving lex-ical ambiguities inone language using statistical dataon lexical relations in another language.
This ap-proach exploits the differences between mappings ofwords to senses in different languages.
We concen-trate on the problem of target word selection in ma-chine translation, for which the approach is directlyapplicable, and employ astatistical model for the se-lection mechanism.
The model was evaluated usingtwo sets of Hebrew and German examples and wasfound to be very useful for disambiguation.1 In t roduct ionThe resolution of hxical ambiguities innon-restrictedtext is one of the most difficult asks of natural lan-guage processing.
A related task in machine trans-lation is target word selection - the task of decidingwhich target language word is the most appropriateequivalent of a source language word in context.
Inaddition to the alternatives introduced from the dif-ferent word senses of the source language word, thetarget language may specify additional alternativesthat differ mainly in their usages.Traditionally various linguistic levels were usedto deal with this problem: syntactic, semantic andpragmatic.
Computationally the syntactic methodsare the easiest, but are of no avail in the frequentsituation when the different senses of the word show*This research was partially supported by grant number120-741 of the Iarael Council for Research and Developmentthe same syntactic behavior, having the same part ofspeech and even the same subcategorization frame.Substantial application of semantic or pragmaticknowledge about he word and its context for broaddomains requires compiling huge amounts of knowl-edge, whose usefulness for practical applications hasnot yet been proven (Lenat et al, 1990; Nirenburg etal., 1988; Chodorow et al, 1985).
Moreover, suchmethods fail to reflect word usages.It is known for many years that the use of a word inthe language provides information about its meaning(Wittgenstein, 1953).
Also, statistical approacheswhich were popular few decades ago have recentlyreawakened and were found useful for computationallinguistics.
Consequently, a possible (though partial)alternative tousing manually constructed knowledgecan be found in the use of statistical data on the oc-currence of lexical relations in large corpora.
Theuse of such relations (mainly relations between verbsor nouns and their arguments and modifiers) for var-ious purposes has received growing attention in re-cent research (Church and Hanks, 1990; Zernik andJacobs, 1990; Hindle, 1990).
More specifically, tworecent works have suggested to use statistical dataon lexical relations for resolving ambiguity cases ofPP-attachment (Hindle and Rooth, 1990) and pro-noun references (Dagan and Itai, 1990a; Dagan andItai, 1990b).Clearly, statistical methods can be useful also fortarget word selection.
Consider, for example, theHebrew sentence xtracted from the foreign newssection of the daily Haaretz, September 1990 (tran-scripted to Latin letters).130(1) Nose ze maria' mi-shtei ha-mdinot mi-lahtom 'alhoze shalom.This sentence would translate into English as:(2) That issue prevented the two countries fromsigning a peace treaty.The verb 'lab_tom' has four word senses: 'sign','seal', 'finish' and 'close'.
Whereas the noun 'hose'means both 'contract' and 'treaty'.
Here the differ-ence is not in the meaning, but in usage.One possible solution is to consult a Hebrew corpustagged with word senses, from which we would prob-ably learn that the sense 'sign' of 'lahtom' appearsmore frequently with 'hoze' as its object than all theother senses.
Thus we should prefer that sense.
How-ever, the size of corpora required to identify lexicalrelations in a broad domain is huge (tens of millionsof words) and therefore it is usually not feasible tohave such corpora manually tagged with word senses.The problem of choosing between 'treaty' and 'con-tract' cannot be solved using only information on He-brew, because Hebrew does not distinguish betweenthem.The solution suggested in this paper is to iden-tify the lexical relationships in corpora of the targetlanguage, instead of the source language.
Consult-ing English corpora of 150 million words, yields thefollowing statistics on single word frequencies: 'sign'appeared 28674 times, 'seal' 2771 times, 'finish' ap-peared 15595 times, 'close' 38291 times, 'treaty' 7331times and 'contract' 30757 times.
Using a naive ap-proach of choosing the most frequent word yields(3) *That issue prevented the two countries fromclosing a peace contract.This may be improved upon if we use lexical rela-tions.
We consider word combinations and count howoften they appeared in the same syntactic relationas in the ambiguous sentence.
For the above exam-ple, among the successfully parsed sentences of thecorpus, the noun compound 'peace treaty' appeared49 times, whereas the compound 'peace contract' didnot appear at all; 'to sign a treaty' appeared 79 timeswhile none of the other three alternatives appearedmore than twice.
Thus we first prefer 'treaty' to 'con-tract' because of the noun compound 'peace treaty'and then proceed to prefer 'sign' since it appearsmost frequently having the object 'treaty' (the or-der of selection is explained in section 3).
Thus inthis case our method yielded the correct translation.Using this method, we take the point of view thatsome ambiguity problems are easier to solve at thelevel of the target language instead of the sourcelanguage.
The source language sentences are con-sidered as a noisy source for target language sen-tences, and our task is to devise a target languagemodel that prefers the most reasonable translation.Machine translation (MT) is thus viewed in partas a recognition problem, and the statistical modelwe use specifically for target word selection may becompared with other language models in recognitiontasks (e.g.
Katz (1985) for speech recognition).In contrast o this view, previous approaches in MTtypically resolved examples like (1) by stating variousconstraints in terms of the source language (Niren-burg, 1987).
As explained before, such constraintscannot be acquired automatically and therefore areusually limited in their coverage.The experiment conducted to test the statisticalmodel clearly shows that the statistics on lexical re-lations are very useful for disambiguation.
Most no-table is the result for the set of examples for Hebrewto English translation, which was picked randomlyfrom foreign news sections in Israeli press.
For thisset, the statistical model was applicable for 70% ofthe ambiguous words, and its selection was then cor-rect for 92% of the cases.These results for target word selection in machinetranslation suggest o use a similar mechanism evenif we are interested only in word sense disambigua-tion within a single language!
In order to select heright sense of a word, in a broad coverage applica-tion, it is useful to identify lexical relations betweenword senses.
However, within corpora of a single lan-guage it is possible to identify automatically only re-lations at the word level, which are of course not use-ful for selecting word senses in that language.
Thisis where other languages can supply the solution, ex-ploiting the fact that the mapping between wordsand word senses varies significantly among differentlanguages.
For instance, the English words 'sign' and'seal' correspond to a very large extent o two distinctsenses of the Hebrew word 'lab_tom' (from example(1)).
These senses hould be distinguished by mostapplications of Hebrew understanding programs.
Tomake this distinction, it is possible to do the sameprocess that is performed for target word selection,by producing all the English alternatives for the lex-ical relations involving 'lahtom'.
Then the Hebrewsense which corresponds to the most plausible En-glish lexical relations is preferred.
This process re-quires a bilingual lexicon which maps each Hebrewsense separately into its possible translations, imilar131to a Hebrew-Hebrew-English lexicon (like the OxfordEnglish-English-Hebrew dictionary (Hornby et al,1980)).In some cases, different senses of a Hebrew wordmap to the same word also in English.
In these cases,the lexical relations of each sense cannot be identi-fied in an English corpus, and a third language isrequired to distinguish among these senses.
As along term vision, one can imagine a multilingual cor-pora based system, which exploits the differences be-tween languages to automatically acquire knowledgeabout word senses.
As explained above, this knowl-edge would be crucial for lexical disambiguation, andwill also help to refine other types of knowledge ac-quired from large corpora 1 .2 The Linguistic ModelThe ambiguity of a word is determined by the num-ber of distinct, non-equivalent representations intowhich the word can be mapped (Van Eynde et al,1982).
In the case of machine translation the ambi-guity of a source word is thus given by the numberof target representations for that word in the bilin-gual lexicon of the translation system.
Given a spe-cific syntactic ontext he ambiguity can be reducedto the number of alternatives which may appear inthat context.
For instance, if a certain translationof a verb corresponds to an intransitive occurrenceof that verb, then this possibility is eliminated whenthe verb occurs with a direct object.
In this workwe are interested only in those ambiguities that areleft after applying all the deterministic syntactic on-straints.For example, consider the following Hebrew sen-tence, taken from the daily Haaretz, September 1990:(4) Diplomatim svurim ki hitztarrfuto shell HonSun magdila et ha.sikkuyim l-hassagat hitqad-dmut ba-sihot.Here, the ambiguous words in translation to En-glish are 'magdila', hitqaddmut' and 'sih_ot'.
To fa-cilitate the reading, we give the translation of thesentence to English, and in each case of an ambiguousselection all the alternatives are listed within curlybrackets, the first alternative being the correct one.1For inatanoe, Hindie (1990) indicates the need to dis-tlnguhsh among aeaases of polysemic words for his statisticalc\]~Hic~tlon method.132(5) Diplomats believe that the joining of HonSun { increases I enlarges I magnifies } thechances for achieving { progress \[ advance Iadvancement } in the { talks I conversations Icalls }.We use the term a lezical relation to denote thecooccurrence r lation of two (or possibly more) spe-cific words in a sentence, having a certain syntac-tic relationship between them.
Typical relations arebetween verbs and their subjects, objects, comple-ments, adverbs and modifying prepositional phrases.Similarly, nouns are related also with their objects,with their modifying nouns in compounds and withtheir modifying adjectives and prepositional phrases.The relational representation f a sentence is sim-ply the list of all lexical relations that occur in thesentence.
For our purpose, the relational represen-tation contains only those relations that involve atleast one ambiguous word.
The relational represen-tation for example (4) is given in (6) (for readabilitywe represent the Hebrew word by its English equiv-alent, prefixed by 'H' to denote the fact that it is aHebrew word):(6) a.
(subj-verb: H-joining H-increase)b.
(verb-obj: H-increase H-chance)c. (verb-obj: H-achieve H-progress)d. (noun-pp: H-progress H-in H-talks)The relational representation f a source sentenceis reflected also in its translation to a target sen-tence.
In some cases the relational representation fthe target sentence is completely equivalent to thatof the source sentence, and can be achieved just bysubstituting the source words with target words.
Inother cases, the mapping between source and targetrelations is more complicated, as is the case for thefollowing German example:(7) Der Tisch gefaellt mir.
- -  I like the table.Here, the original subject of the source sentencebecomes the object in the target sentence.
This kindof mapping usually influences the translation processand is therefore ncoded in components of the trans-lation program, either explicitly or implicitly, espe-cially in transfer based systems.
Our model assumesthat such a mapping of source language relations totarget language relations is possible, an assumptionthat is valid for many practical cases.When applying the mapping of relations on onelexicai relation of the source sentence we get severalalternatives for a target relation.
For instance, ap-plying the mapping to example (6-c) we get threealternatives for the relation in the target sentence:(8) (verb-obj: achieve progress)(verb-obj: achieve advance)(verb-obj: achieve advancement)For example (6-d) we get 9 alternatives, sinceboth 'H-progress' and 'H-talks' have three alterna-tive translations.In order to decide which alternative is the mostprobable, we count the frequencies of all the alter-native target relations in very large corpora.
For ex-ample (8) we got the counts 20, 5 and 1 respectively.Similarly, the target relation 'to increase chance' wascounted 20 times, while the other alternatives werenot observed at all.
These counts are given as inputto the statistical model described in the next section,which performs the actual target word selection.3 The Statist ical  ModelOur selection algorithm is based on the following sta-tistical model.
Consider first a single relation.
Thelinguistic model provides us with several alternativesas in example (8).
We assume that each alternativehas a theoretical probability Pi to be appropriate forthis case.
We wish to select he alternative for whichPi is maximal, provided that it is significantly largerthan the others.We have decided to measure this significance bythe odds ratio of the two most probable alternativesP = Pl/P2.
However, we do not know the theoreticalprobabilities, therefore we get a bound for p usingthe frequencies of the alternatives in the corpus.Let/3 i be the probabilities as observed in the cor-pus (101 = ni/n, where ni is the number of times thatalternative i appeared in the corpus and n is the to-tal number of times that all the alternatives for therelation appeared in the corpus).For mathematical convenience we bound In p in-stead of p. Assuming that samples of the alternativerelations are distributed normally, we get the follow-ing bound with confidence 1- a:where Z is the eonfidenee coefficient.
We approxi-mate the variance by the delta method (e.g.
John-son and Wichern (1982)):= ,n_ 1 p~(1 - p~) -) 1 p~(1 - p~) + 2 P*P~p~ n p~ n npxI~1 1 1 1 1 1 = + ~, + =~+~.npa nI~ n~x n~ nl n2Therefore we get that with probability at least1--or,In _> In - Z l -a  +We denote the right hand side (the bound) byB~,(nl, n2).In sentences with several relations, we consider thebest two alternatives for each relation, and take therelation for which B,, is largest.
If this Ba is less thana specified threshold then we do not choose betweenthe alternatives.
Otherwise, we choose the most fre-quent alternative to this relation and select the tar-get words appearing in this alternative.
We theneliminate all the other alternative translations for theselected words, and accordingly eliminate all the al-ternatives for the remaining relations which involvethese translations.
In addition we update the ob-served probabilities for the remaining relations, andconsequently the remaining Ba's.
This procedure isrepeated until all target words have been determinedor the maximal Ba is below the threshold.The actual parameters we have used so far werec~ = 0.05 and the bound for Bawas -0.5.To illustrate the selection algorithm, we give thedetails for example (6).
The highest bound for theodds ratio (Ba = 1.36) was received for the relation'increase-chance', thus selecting the translation 'in-crease' for 'H-increase'.
The second was Ba = 0.96,133for 'achieve-progress'.
This selected the transla-tions 'achieve' and 'progress', while eliminating theother senses of 'H-progress' in the remaining rela-tions.
Then, for the relation 'progress-in-talks' wegot Ba = 0.3, thus selecting the appropriate transla-tion for 'H-talks'.4 The Exper imentAn experiment was conducted to test the perfor-mance of the statistical model in translation fromHebrew and German to English.
Two sets of para-graphs were extracted randomly from current He-brew and German press.
The Hebrew set con-tained 10 paragraphs taken from foreign news sec-tions, while the German set contained 12 paragraphsof text not restricted to a specific topic.Within these paragraphs we have (manually) iden-tified the target word selection ambiguities, using abilingual dictionary.
Some of the alternative transla-tions in the dictionary were omitted if it was judgedthat they will not be considered by an actual compo-nent of a machine translation program.
These casesincluded very rare or archaic translations (that wouldnot be contained in an MT lexicon) and alternativesthat could be eliminated using syntactic knowledge(as explained in section 2) 2 .
For each of the remain-ing alternatives, it was judged if it can serve as anacceptable translation in the given context.
This apriori judgment was used later to decide whether theselection of the automatic procedure is correct.
As aresult of this process, the Hebrew set contained 105ambiguous words (which had at least one unaccept-able translation) and the German set 54 ambiguouswords.Now it was necessary to identify the lexical rela-tions within each of the sentences.
As explained be-fore, this should be done using a source languageparser, and then mapping the source relations tothe target relations.
At this stage of the research,we still do not have the necessary resources to per-form the entire process automatically s, therefore wehave approximated it by translating the sentencesinto English and extracting the lexical relations us-ing the English Slot Grammar (ESG) parser (mc-2Due to some technicalities, we have also restricted theexperiment to cases in which all the relevant ranslations ofa word consists exactly one English word, which is the mostfrequent situaticm.awe are currently integrating this process within GSG(German Slot Gr~nmm') and LMT-GE (the Germs~a toEn-glish MT prototype).Cord, 1989) 4.
Using this parser we have classifiedthe lexical relations to rather general classes of syn-tactic relations, based on the slot structure of ESG.The important syntactic relations used were betweena verb and its arguments and modifiers (counting asone class all objects, indirect objects, complementsand nouns in modifying prepositional phrases) andbetween a noun and its arguments and modifiers(counting as one class all noun objects, modifyingnouns in compounds and nouns in modifying prepo-sitional phrases).
The success of using this generallevel of syntactic relations indicates that even a roughmapping of source to target language relations wouldbe useful for the statistical model.The statistics for the alternative English relationsin each sentence were extracted from three cor-pora: The Washington Post articles (about 40 mil-lion words), Associated Press news wire (24 million)and the Hansard corpus of the proceedings of theCanadian Parliament (85 million words).
The statis-tics were extracted only from sentences of up to 25words (to facilitate parsing) which contained alto-gether about 55 million words.
The lexical relationsin the corpora were extracted by ESG, in the sameway they were extracted for the English version of theexample sentences ( ee Dagan and Itai (1990a) for adiscussion on using an automatic parser for extract-ing lexical relations from a corpus, and for the tech-nique of acquiring the statistics).
The parser failedto produce any parse for about 35% of the sentences,which further reduced the actual size of the corporawhich was used.5 EvaluationTwo measurements, applicability and precision, areused to evaluate the performance of the statisticalmodel.
The applicability denotes the proportion ofcases for which the model performed a selection, i.e.those cases for which the bound Bapassed the thresh-old.
The precision denotes the proportion of cases forwhich the model performed a correct selection out ofall the applicable cases.We compare the precision of the model to thatof the "word frequencies" procedure, which alwaysselects the most frequent arget word.
This naive"straw-man" is less sophisticated than other meth-ods suggested in the literature but it is useful as acommon benchmark (e.g.
Sadler (1989)) since it can4The parsing process was controlled manually to make surethat we do not get wrong relational representation f the exoamp\]es due to parsing errors.134be easily implemented.
The success rate of the "wordfrequencies" procedure can serve as a measure for thedegree of lexical ambiguity in a given set of examples,and thus different methods can be partly comparedby their degree of success relative to this procedure.Out of the 105 ambiguous Hebrew words, for 32the bound Badid not pass the threshold (applicabil-ity of 70%).
The remaining 73 examples were dis-tributed according to the following table:\[ Hebrew-Engiish \]\] Word Frequenciescorrect I incorrect IRelations Statistics \[ correctThus the precision of the statistical model was 92%(67/73) 5while relying just on word frequencies yields64% (47/73).Out of the 54 ambiguous German words, for 22 thebound Badid not pass the threshold (applicability of59%).
The remaining 32 examples were distributedaccording to the following table:Oerm  English II Word  equeoci  I,, correct \] incorrectRelations Statistics \[ correct 8 in?
?rre ' \[\[ I 0 IThus the precision of the statistical model was 75%(24/32), while relying just on word frequencies yields53% (18/32).
We attribute the lower success rate forthe German examples to the fact that they were notrestricted to topics that are well represented in thecorpus.Statistical nalysis for the larger set of Hebrew ex-amples hows that with 95% confidence our methodsucceeds in at least 86% of the applicable xamples(using the parameters of the distribution of propor-tions).
With the same confidence, our method im-proves the word frequency method by at least 18%(using confidence interval for the difference of pro-portions in multinomial distribution, where the fourcells of the multinomial correspond to the four entriesin the result table).In the examples that were treated correctly by our5An a posteriorl observation showed that in three of thesix errors the selection of the model was actually acceptable,and the a priori judgment of the hnman translator was too se-vere.
For example, in one of these cases the statistics electedthe expression 'to begin talks' while the human translator re-garded this expression as incorrect and selected 'to start talks'.If we consider these cases as correct then there are only threeselection errors, getting a 96% precision.method, such as the examples in the previous ec-tions, the statistics ucceeded to capture two majortypes of disambiguating data.
In preferring 'sign-treaty' upon 'seal-treaty', the statistics reflect therelevant semantic onstraint.
In preferring 'peace-treaty' upon 'peace-contract', the statistics reflectthe hxical usage of 'treaty' in English which differsfrom the usage of 'h_oze' in Hebrew.6 Failures and Possible Im-provementsA detailed analysis of the failures of the method ismost important, as it both suggests possible improve-ments for the model and indicates its limitations.As described above, these failures include either thecases for which the method was not applicable (noselection) or the cases in which it made an incorrectselection.
The following paragraphs list the variousreasons for both types.6.1 InapplicabilityInsufficient data.
This was the reason for nearlyall the cases of inapplicability.
For instance, none ofthe alternative relations 'an investigator f corrup-tion' (the correct one) or 'researcher of corruption'(the incorrect one) was observed in the parsed cor-pus.
In this case it is possible to perform the correctselection if we used only statistics about the cooc-currences of 'corruption' with either 'investigator' r'researcher', without looking for any syntactic rela-tion (as in Church and Hanks (1990)).
The use ofthis statistic is a subject for further esearch, but ourinitial data suggests hat it can substantially increasethe applicability of the statistical method with justa little decrease in its precision.Another way to deal with the lack of statisticaldata for the specific words in question is to usestatistics about similar words.
This is the basis forSadler's Analogical Semantics (1989) which has notyet proved effective.
His results may be improved ifmore sophisticated techniques and larger corpora reused to establish similarity between words (such asin (Hindle, 1990)).Conflicting data.
In very few cases two alterna-tives were supported equally by the statistical data,thus preventing a selection.
In such cases, both alter-natives are valid at the independent level of the lexi-cal relation, but may be inappropriate for the specificcontext.
For instance, the two alternatives of'to take135a job' or 'to take a position' appeared in one of theexamples, but since the general context concernedwith the position of a prime minister only the latterwas appropriate.
In order to resolve such examplesit may be useful to consider also cooccurrences ofthe ambiguous word with other words in the broadercontext.
For instance, the word 'minister' seems tocooccur in the same context more frequently with'position' than with 'job'.In another example both alternatives were appro-priate also for the specific context.
This happenedwith the German verb 'werfen', which may be trans-lated (among other options) as 'throw', 'cast' or'score'.
In our example 'werfen' appeared in the con-text of 'to throw/cast light' and these two correct al-ternatives had equal frequencies in the corpus ('score'was successfully eliminated).
In such situations anyselection between the alternatives will be appropriateand therefore any algorithm that handles conflictingdata will work properly.6.2 Incorrect Select ionUsing the  inappropr ia te  re lat ion.
One of the ex-amples contained the Hebrew word 'matzav', whichtwo of its possible translations are 'state' and 'po-sition'.
The phrase which contained this word was:'to put an end to the {state I position} of war .
.
.
'.The ambiguous word is involved in two syntactic rela-tions, being a complement of 'put' and also modifiedby 'war'.
The corresponding frequencies were:(9) verb-comp: put-position 320verb-comp: put-state 18noun-nob j: state-war 13noun-nob j: position-war 2The bound of the odds ration (Ba) for the first re-lation was higher than for the second, and thereforethis relation determined the translation as 'position'.However, the correct ranslation should be 'state', asdetermined by the second relation.This example suggests that while ordering the in-volved relations (or using any other weighting mech-anism) it may be necessary to give different weightsto the different ypes of syntactic relations.
For in-stance, it seems reasonable that the object of a nounshould receive greater weight in selecting the noun'ssense than the verb for which this noun serves as acomplement.Confus ing senses.
In another example, theHebrew word 'qatann', which two of its meaningsare 'small' and 'young', modified the word 'sikkuy',which means 'prospect' or 'chance'.
In this context,the correct sense is necessarily 'small'.
However, therelation that was observed in the corpus was 'youngprospect', relating to the human sense of 'prospect'which appeared in sport articles (a promising youngperson).
This borrowed sense of 'prospect' is nec-essarily inappropriate, since in Hebrew it is repre-sented by the equivalent of 'hope' ('tiqva'), and notby 'sikkuy'.The reason for this problem is that after producingthe possible target alernatives, our model ignoresthe source language input as it uses only a mono-lingual target corpus.
This can be solved if we usean aligned bilingual corpus, as suggested by Sadler(1989) and Brown et al (1990).
In such a cor-pus the occurrences of the relation 'young prospect'will be aligned to the corresponding occurrences ofthe Hebrew word 'tiqva', and will not be used whenthe Hebrew word 'sikkuy' is involved.
Yet, it shouldbe brought in mind that an aligned corpus is the re-sult of manual translation, which can be viewed asa manual tagging of the words with their equivalentsenses in the other language.
This resource is muchmore expensive and less available than the untaggedmonolingual corpus, while it seems to be necessaryonly for relatively rare situations.Lack o f  deep unders tand ing .
By their nature,statistical methods rely on large quantities of shallowinformation.
Thus, they are doomed to fail when dis-ambiguation can rely only on deep understanding ofthe text and no other surface cues are available.
Thishappened in one of the Hebrew examples, where thetwo alternatives were either 'emigration law' or 'im-migration law' (the Hebrew word 'hagira' is used forboth subsenses).
While the context indicated thatthe first alternative is correct, the statistics preferredthe second alternative.
It seems that such cases arequiet rare, but only further evaluation will show theextent o which deep understanding is really needed.7 Conclus ionsThe method presented takes advantage of two lin-guistic phenomena: the different usage of words andword senses among different languages and the im-portance of lexical cooccurrences within syntactic re-lations.
The experiment shows that these phenom-ena are indeed useful for practical disambiguation.We suggest hat the high precision received in theexperiment relies on two characteristics of the am-136biguity phenomena, namely the sparseness and re-dundancy of the disambiguating data.
By sparsenesswe mean that within the large space of alternativeinterpretations produced by ambiguous utterances,only a small portion is commonly used.
Thereforethe chance of an inappropriate interpretation to beobserved in the corpus (in other contexts) is low.Redundancy relates to the fact that different infor-mants (such as different lexical relations or deep un-derstanding) tend to support rather than contradictone another, and therefore the chance of picking a"wrong" informant is low.The examination of the failures suggests that fu-ture research may improve both the applicability andprecision of the model.
Our next goal is to handle in-applicable cases by using cooccurrence data regard-less of syntactic relations and similarities betweenwords.
We expect hat increasing the applicabilitywill lead to some decrease inprecision, similar to thetradeoff between recall and precision in informationretrieval.
Pursuing this tradeoff will improve the per-formance of the method and reveal its limitations.8 AcknowledgmentsWe would like to thank Mori Rimon, Peter Brown,Ayala Cohen, Ulrike Rackow, Herb Leass and HansKarlgren for their help and comments.References\[1\] Brown, P., Cocks, J., Della Pietra, S., DellaPietra, V., Jelinek, F., Mercer, R.L.
and RossinP.S., A statistical approach to language transla-tion, Computational Linguistics, vol.
16(2), 79-85 (1990).\[2\] Chodorow, M. S., R. J. Byrd and G. E. Heidron,Extracting Semantic Hierarchies from a LargeOn-Line Dictionary.
Proc.
of the 23rd AnnualMeeting of the ACL, 299-304 (1985).\[3\] Church, K. W., and Hanks, P., Word associa-tion norms, mutual information, and Lexicogra-phy, Computational Linguistics, vol.
16(1), 22-29 (1990).\[4\] Dagan, I. and A. Itai, Automatic Acquisitionof Constraints for the Resolution of AnaphoraReferences and Syntactic Ambiguities, COLING1990, Helsinki, Finland.\[5\] Dagan, I. and A. Itai, A Statistical Filter forResolving Pronoun References, Proc.
of the 7thIsraeli Sym.
on Artificial Intelligence and Com-puter Vision, 1990.\[6\] Hindle, D. Noun Classification from Predicate-Argument Structures, Proc.
of the 28rd AnnualMeeting of the ACL, (1990).\[7\] Hindle D. and M. Rooth, Structural Ambiguityand Lexical Relations, Proc.
of the Speech andNatural Language Workshop, (DARPA), June1990.\[8\] Hornby, A. S., C. Ruse, J.
A. Reif and Y.Levy, Ozford Student's Dictionanary for He-brew Speakers, Kernerman Publishing Ltd, Lon-nie Kahn & Co. Ltd. (1986).\[9\] Johnson, R. A. and D. W. Wichern, MultivariateStatistical Analysis, Prentice-Hall, 1982.\[10\] Katz, S., Recursive m-gram language model viaa smoothing of Turing's formula, IBM Tech.
Dis-closure Bull., 1985.\[11\] Lenat, D. B., R. V. Guha, K. Pittman, D. Prattand M. Shepherd, Cyc: toward programs withcommon sense, Comm.
ACM, vol.
33(8), 1990.\[12\] McCord, M. C., A new version of slot grammar,Research Report RC 1~506, IBM Research Di-vision, Yorktown Heights, NY, 1989.\[13\] Sirenburg, S., (ed.
), Machine Translation, Cam-bridge University Press (1987).\[14\] Nirenburg, S., I. Monarch, T. Kaufmann, I.Nirenburg and J. Carbonell.
Acquisition ofVery Large Knowledge Bases: Methodology,Tools and Applications, Center for MachineTranslation, Carnegie-Mellon, CMU-CMT-88-108, (1988).\[15\] Sadler, V., Working with analogical semantics:disambiguation techniques in DLT, Foris Publi-cations, 1989.\[16\] Van Eynde, F. et al: The Task of Transfer vis-a-vis Analysis and Generation.
Eurotra Final Re-port ET-10-B/NL, (1982).\[17\] Wittgenstein, L. Philosophical Investigations,Oxford (1953).\[18\] Zernik U., and P. Jacobs, Tagging for Learn-ing: Collecting Thematic Relations from Cor-pus.
Proc.
COLING 1990.137
