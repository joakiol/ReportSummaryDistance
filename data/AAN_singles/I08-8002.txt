Speech-to-Speech Translation Activities in ThailandChai Wutiwiwatchai, Thepchai Supnithi, Krit KosawatHuman Language Technology LaboratoryNational Electronics and Computer Technology Center112 Pahonyothin Rd., Klong-luang, Pathumthani 12120 Thailand{chai.wut, thepchai.sup, krit.kos}@nectec.or.thAbstractA speech-to-speech translation project(S2S) has been conducted since 2006 bythe Human Language Technology labora-tory at the National Electronics and Com-puter Technology Center (NECTEC) inThailand.
During the past one year, therehappened a lot of activities regarding tech-nologies constituted for S2S, includingautomatic speech recognition (ASR), ma-chine translation (MT), text-to-speech syn-thesis (TTS), as well as technology for lan-guage resource and fundamental tool de-velopment.
A developed prototype of Eng-lish-to-Thai S2S has opened several re-search issues, which has been taken intoconsideration.
This article intensively re-ports all major research and developmentactivities and points out remaining issuesfor the rest two years of the project.1 IntroductionSpeech-to-speech translation (S2S) has been ex-tensively researched since many years ago.
Most ofworks were on some major languages such astranslation among European languages, AmericanEnglish, Mandarin Chinese, and Japanese.
There isno initiative of such research for the Thai language.In the National Electronics and Computer Tech-nology Center (NECTEC), Thailand, there is asomewhat long history of research on Thai speechand natural language processing.
Major technolo-gies include Thai automatic speech recognition(ASR), Thai text-to-speech synthesis (TTS), Eng-lish-Thai machine translation (MT), and languageresource and fundamental tool development.
Thesebasic technologies are ready to seed for S2S re-search.
The S2S project has then been conducted inNECTEC since the end of 2006.The aim of the 3-year S2S project initiated byNECTEC is to build an English-Thai S2S serviceover the Internet for a travel domain, i.e.
to be usedby foreigners who journey in Thailand.
In the firstyear, the baseline system combining the existingbasic modules applied for the travel domain wasdeveloped.
The prototype has opened several re-search issues needed to be solved in the rest twoyears of the project.
This article summarizes allsignificant activities regarding each basic technol-ogy and reports remaining problems as well as thefuture plan to enhance the baseline system.The rest of article is organized as follows.
Thefour next sections describe in details activitiesconducted for ASR, MT, TTS, and language re-sources and fundamental tools.
Section 6 summa-rizes the integration of S2S system and discusseson remaining research issues as well as on-goingworks.
Section 7 concludes this article.2 Automatic Speech Recognition (ASR)Thai ASR research focused on two major topics.The first topic aimed to practice ASR in real envi-ronments, whereas the second topic moved to-wards large vocabulary continuous speech recogni-tion (LVCSR) in rather spontaneous styles such asnews broadcasting and telephone conversation.Following sub-sections give more details.2.1 Robust speech recognitionTo tackle the problem of noisy environments,acoustic model selection was adopted in our sys-tem.
A tree structure was constructed with eachleaf node containing speaker-, noise-, and/or SNR-specific acoustic model.
The structure allowed ef-ficient searching over a variety of speech environ-ments.
Similar to many robust ASR systems, theselected acoustic model was enhanced by adaptingby the input speech using any adaptation algorithmsuch as MLLR or MAP.
In our model, however,simulated-data adaptation was proposed (That-phithakkul et al, 2006).
The method synthesizedan adaptation set by adding noise extracted fromthe input speech to a pre-recorded set of cleanspeech.
A speech/non-speech detection moduledetermined in the input speech the silence portions,which were assumed to be the environmental noise.This approach solved the problem of incorrecttranscription in unsupervised adaptation and en-hanced the adaptation performance by increasingthe size of adaptation data.2.2 Large-vocabulary continuous speech rec-ognition (LVCSR)During the last few years, researches on continuousspeech recognition were based mainly on two da-tabases, the NECTEC-ATR (Kasuriya et al,2003a) and the LOTUS (Kasuriya et al, 2003b).The former corpus was for general purposes,whereas the latter corpus was well designed forresearch on acoustic phonetics as well as researchon 5,000-word dictation systems.
A number of re-search works were reported, starting by optimizingthe Thai phoneme inventory (Kanokphara, 2003).Recently, research has moved closer to real andspontaneous speech.
The first task collaboratedwith a Thai telephone service provider was to builda telephone conversation corpus (Cotsomrong et al,2007).
To accelerate the corpus development,Thatphithakkul et al (2007) developed a speakersegmentation model which helped separatingspeech from two speakers being conversed.
Themodel was based on the simple Hidden Markovmodel (HMM), which achieved over 70% accuracy.Another on-going task is a collection of broadcastnews video.
The aim of the task is to explore thepossibility to use the existing read-speech model toboot broadcast news transcription.
More detailswill be given in Section 5.3 Machine Translation (MT)It was a long history of the NECTEC English-to-Thai machine translation (MT) which has beenpublicly serviced online.
The ?Parsit?
1  systemmodified from the engine developed by NEC, Ja-pan, which was a rule-based MT (RBMT).
Over900 parsed rules were coded by Thai linguists.
Thesystem recognized more than 70,000 lexical wordsand 120,000 meanings.Figure 1.
Examples of using MICG to solve twomajor problems of parsing Thai, (a) coordinationwith gapping and (b) verb serialization.3.1 Thai-to-English MTRecently, there has been an effort to develop thefirst rule-based system for Thai-to-English MT.The task is much more difficult than the originalEnglish-to-Thai translation since the Thai wordsegmentation, sentence breaking, and grammarparser are all not complete.
Coding rules for pars-ing Thai is not trivial and the existing approachused to translate English to Thai cannot be appliedcounter wise.
Last year, a novel rule-based ap-proach appropriate for Thai was proposed(Boonkwan and Supnithi, 2007).
The approach,called memory-inductive categorical grammar(MICG), was derived from the categorical gram-mar (CG).
The MICG introduced memorizationand induction symbols to solve problems of ana-lytic languages such as Thai as well as many spo-1Parsit MT, http://www.suparsit.com/ken languages.
In parsing Thai, there are two majorproblems, coordination with gapping and verb se-rialization.
Figure 1 shows examples of the twoproblems with the MICG solution, where thesquare symbol denotes the chunk to be memorizedand the diamond symbol denotes the chunk to beinduced.
A missing text chunk can be induced byseeking for its associated memorized text chunk.3.2 TM and SMTIn order to improve the performance of our transla-tion service, we have adopted a translation memory(TM) module in which translation results correctedby users are stored and reused.
Moreover, the ser-vice system is capable to store translation results ofindividual users.
A na?ve user can select from thelist of translation results given by various users.Figure 3 captures the system interface.Due to powerful hardware today, research hasturned to rely more on statistical approaches.
Thisis also true for the machine translation issue.
Sta-tistical machine translation (SMT) has played animportant role on modeling translation given alarge amount of parallel text.
In NECTEC, we alsorealize the benefit of SMT especially on its adapta-bility and naturalness of translation results.
How-ever, a drawback of SMT compared to RBMT isthat it works quite well on a limited domain, i.e.translating in a specific domain.
This is actuallysuitable to the S2S engine which has been designedto work in only a travel domain.
Therefore, in par-allel to RBMT, SMT is being explored for limiteddomains.
Two parallel text corpora have been con-structed.
The first one, collected by ATR under theAsian speech translation advanced research (A-STAR)2 consortium, is a Thai incorporated versionof the Basic travel expression (BTEC) corpus (Ki-kui et al, 2003).
This corpus will seed the devel-opment of S2S in the travel domain.
The secondparallel corpus contains examples of parallel sen-tences given in several Thai-English dictionaries.The latter corpus has been used for a generalevaluation of Thai-English SMT.
Details of bothcorpora will be given in the Section 5.4 Text-to-Speech Synthesis (TTS)Thai TTS research has begun since 2000.
At pre-sent, the system utilizes a corpus-based unit-2A-STAR consortium, http://www.slc.atr.jp/AStar/selection technique.
A well-constructed phoneti-cally-balanced speech corpus, namely ?TSynC-1?,containing approximately 13 hours is embedded inthe TTS engine, namely ?Vaja?3.
Although the lat-est version of Vaja achieved a fair speech quality,there are still a plenty of rooms to improve the sys-tem.
During the past few years, two major issueswere considered; reducing the size of speech cor-pus and improving unit selection by prosody in-formation.
Following sub-sections describe thedetail of each issue.4.1 Corpus space reductionA major problem of corpus-based unit-selectionTTS is the large size of speech corpus required toobtain high-quality, natural synthetic-speech.
Scal-ability and adaptability of such huge database be-come a critical issue.
We then need the most com-pact speech corpus that still provides acceptablespeech quality.
An efficient way to reduce the sizeof corpus was recently proposed (Wutiwiwatchai etal., 2007).
The method incorporated Thai phoneticsknowledge in the design of phoneme/diphone in-ventory.
Two assumptions on diphone characteris-tics were proved and used in the new design.
Onewas to remove from the inventory the diphonewhose coarticulation strength between adjacentphonemes was very weak.
Normally, the corpuswas designed to cover all tonal diphones in Thai.The second strategy to reduce the corpus was toignore tonal levels of unvoiced phonemes.
Ex-periments showed approximately 30% reduction ofthe speech corpus with the quality of synthesizedspeech remained.4.2 Prosody-based naturalness improvementThe baseline TTS system selected speech units byconsidering only phoneme and tone context.
In thepast few years, analyses and modeling Thai pro-sodic features useful for TTS have been exten-sively explored.
The first issue was to detectphrasal units given an input text.
After several ex-periments (Tesprasit et al, 2003; Hansakunbun-theung et al, 2005), we decided to develop a clas-sification and decision tree (CART) for phrasebreak detection.The second issue was to model phoneme dura-tion.
Hansakunbuntheung et al (2003) comparedseveral models to predict the phoneme duration.3Vaja TTS, http://vaja.nectec.or.th/Mainly, we found linear regression appropriate forour engine as its simplicity and efficiency.
Bothtwo prosody information were integrated in ourVaja TTS engine, which achieved a better synthe-sis quality regarding subjective and objectiveevaluations (Rugchatjaroen et al, 2007).5 Language Resources and ToolsA lot of research issues described in previous sec-tions definitely requires the development and as-sessment of speech and language corpora.
At thesame time, there have been attempts to enhance theexisting language processing tools that are com-monly used in a number of advanced applications.This section explains the activities on resource andtool development.5.1 Speech and text corporaTable 1 summarizes recent speech and text corporadeveloped in NECTEC.
Speech corpora in NEC-TEC have been continuously developed since 2000.The first official corpus under the collaborationwith ATR was for general purpose (Kasuriya et al,2003a).
The largest speech corpus, called LOTUS(Kasuriya et al, 2003b), was well-designed readspeech in clean and office environments.
It con-tained both phonetically balanced utterances andnews paper utterances covering 5,000 lexicalwords.
The latter set was designed for research onThai dictation systems.
Several research worksutilizing the LOTUS were reported as described inthe Section 2.2.The last year was the first-year collaboration ofNECTEC and a telephone service provider to de-velop the first Thai telephone conversation speechcorpus (Cotsomrong et al, 2007).
The corpus hasbeen used to enhance the ASR capability in dealingwith various noisy telephone speeches.Regarding text corpora, as already mentioned inthe Section 3, two parallel text corpora were de-veloped.
The first corpus was a Thai version of theBasic travel expression corpus (BTEC), which willbe used to train a S2S system.
The second corpusdeveloped ourselves was a general domain.
It willbe used also in the SMT research.
Another impor-tant issue of corpus technology is to create goldenstandards for several Thai language processing top-ics.
Our last year attempts focused on two sets; agolden standard set for evaluating MT and agolden standard set for training and evaluatingThai word segmentation.
Finally, the most basicbut essential in all works is the dictionary.
Withinthe last year, we have increased the number ofword entries in our lexicon from 35,000 English-to-Thai and 53,000 Thai-to-English entries to over70,000 entries both.
This incremental dictionarywill be very useful in sustaining improvement ofmany language processing applications.Table 1.
Recent speech/text corpora in NECTEC.Corpus Purpose DetailsLOTUSWell-designedspeech utterances for5,000-word dictationsystems- 70 hours of pho-netically balancedand 5,000-wordcoverage setsTSynC-1 Corpus-based unit-selection Thai speechsynthesis- 13 hours pros-ody-tagged fluentspeechThai BTEC Parallel text andspeech corpora fortravel-domain S2S- 20,000 textualsentences and asmall set of speechin travel domainParallel text Pairs of Thai-Englishsample sentencesfrom dictionariesused for SMT- 0.2M pairs ofsentencesNECTEC-TRUETelephone conversa-tion speech foracoustic modeling- 10 hours conver-sational speech invarious telephonetypes5.2 Fundamental language toolsTwo major language tools have been substantiallyresearched, word segmentation and letter-to-soundconversion.
These basic tools are very useful inmany applications such as ASR, MT, TTS, as wellas Information retrieval (IR).Since Thai writing has no explicit word and sen-tence boundary marker.
The first issue on process-ing Thai is to perform word segmentation.
Ourbaseline morphological analyzer determined wordboundaries and word part-of-speech (POS) simul-taneously using a POS n-gram model and a prede-fined lexicon.
Recently, we have explored Thainamed-entity (NE) recognition, which is expectedto help alleviating the problem of incorrect wordsegmentation.
Due to the difficulty of Thai wordsegmentation, we initiated a benchmark evaluationon Thai word segmentation, which will be held in2008.
This will gather researchers who are inter-ested in Thai language processing to consider theproblem on a standard text corpus.The problem of incorrect word segmentationpropagates to the letter-to-sound conversion (LTS)module which finds pronunciations on the wordbasis.
Our original LTS algorithm was based onprobabilistic generalized LR parser (PGLR).
Re-cently, we proposed a novel method to automati-cally induce syllable patterns from a large text withno need for any preprocessing (Thangthai et al,2006).
This approach largely helped alleviating thetedious work on text corpus annotation.Another important issue we took into accountwas an automatic approach to find pronunciationsof English words using Thai phonology.
The issueis particularly necessary in many languages wheretheir local scripts are always mixed with Englishscripts.
We proposed a new model that utilizedboth English graphemes and English phonemes, iffound in an English pronunciation dictionary, topredict Thai phonemes of the word (Thangthai etal., 2007).6 Speech-to-Speech Translation (S2S)In parallel to the research and development of in-dividual technology elements, some efforts havebeen on the development of Thai-English speech-to-speech translation (S2S).
Wutiwiwatchai (2007)already explained in details about the activities,which will be briefly reported in this section.As described briefly in the Introduction, the aimof our three-year S2S project is to develop an S2Sengine in the travel domain, which will be givenservice over the Internet.
In the last year, we de-veloped a prototype English-to-Thai S2S engine,where major tasks turned to be the development ofEnglish ASR in the travel domain and the integra-tion of three core engines, English ASR, English-to-Thai RBMT, and Thai TTS.6.1 System developmentOur current prototype of English ASR adopted awell-known SPHINX toolkit, developed by Carne-gie Mellon University.
An American Englishacoustic model has been provided with the toolkit.An n-gram language model was trained by a smallset of sentences in travel domain.
The training textcontains 210 patterns of sentences spanning over480 lexical words, all prepared by hands.
Figure 2shows some examples of sentence pattern.Figure 2.
Examples of sentence patterns for lan-guage modeling (uppercases are word classes,bracket means repetition).In the return direction, a Thai ASR is required.Instead of using the SPHINX toolkit4, we built ourown Thai ASR toolkit, which accepts an acousticmodel in the Hidden Markov toolkit (HTK)5 for-mat proposed by Cambridge University.
The ?iS-peech?6 toolkit that supports an n-gram languagemodel is currently under developing.The English ASR, English-to-Thai RBMT, andThai TTS were integrated simply by using the 1-best result of ASR as an input of MT and generat-ing a sound of the MT output by TTS.
The proto-type system, run on PC, utilizes a push-to-talk in-terface so that errors made by ASR can be allevi-ated.6.2 On-going worksTo enhance the acoustic and language models, aThai speech corpus as well as a Thai-English paral-lel corpus in the travel domain is constructing asmentioned in the Section 5.1, the Thai version ofBTEC corpus.
Each monolingual part of the paral-lel text will be used to train a specific ASR lan-guage model.For the MT module, we can use the parallel textto train a TM or SMT.
We expect to combine thetrained model with our existing rule-based model,which will be hopefully more effective than eachindividual model.
Recently, we have developed aTM engine.
It will be incorporated in the S2S en-gine in this early stage.In the part of TTS, several issues have been re-searched and integrated in the system.
On-goingworks include incorporating a Thai intonation4CMU SPHINX, http://cmusphinx.sourceforge.net/5HTK, Cambridge University, http://htk.eng.cam.ac.uk/6iSpeech ASR, http://www.nectec.or.th/rdi/ispeech/model in unit-selection, improving the accuracy ofThai text segmentation, and learning for hiddenMarkov model (HMM) based speech synthesis,which will hopefully provide a good frameworkfor compiling TTS on portable devices.7 ConclusionThere have been a considerable amount of researchand development issues carried out under thespeech-to-speech translation project at NECTEC,Thailand.
This article summarized and reported allsignificant works mainly in the last few years.
In-deed, research and development activities in eachtechnology element, i.e.
ASR, MT, and TTS havebeen sustained individually.
The attempt to inte-grate all systems forming an innovative technologyof S2S has just been carried out for a year.
Thereare many research and development topics left toexplore.
Major challenges include at least but notlimited to the following issues: The rapid development of Thai-specific ele-ments such as robust Thai domain-specificASR and MT Migration of the existing written languagetranslation to spoken language translationRecently, there have been some initiations ofmachine translation among Thai and other lan-guages such as Javi, a minor language used in thesouthern part of Thailand and Mandarin Chinese.We expect that some technologies carried out inthis S2S project will be helpful in porting to theother pairs of languages.AcknowledgementThe authors would like to thank the ATR, Japan, ininitiating the fruitful A-STAR consortium and inproviding some resources and tools for our re-search and development.ReferencesBoonkwan, P., Supnithi, T., 2008.
Memory-inductivecategorial grammar: an approach to gap resolutionin analytic-language translation, To be presented inIJCNLP 2008.Cotsomrong, P., Saykham, K., Wutiwiwatchai, C.,Sreratanaprapahd, S., Songwattana, K., 2007.
A Thaispontaneous telephone speech corpus and its appli-cations to speech recognition, O-COCOSDA 2007.Hansakunbuntheung, C., Tesprasit, V., Siricharoenchai,R., Sagisaka, Y., 2003.
Analysis and modeling of syl-lable duration for Thai speech synthesis, EU-ROSPEECH 2003, pp.
93-96.Hansakunbuntheung, C., Thangthai, A., Wutiwiwatchai,C., Siricharoenchai, R., 2005.
Learning methods andfeatures for corpus-based phrase break prediction onThai, EUROSPEECH 2005, pp.
1969-1972.Kanokphara, S., 2003.
Syllable structure based phoneticunits for context-dependent continuous Thai speechrecognition, EUROSPEECH 2003, pp.
797-800.Kasuriya, S., Sornlertlamvanich, V., Cotsomrong, P.,Jitsuhiro, T., Kikui, G., Sagisaka, Y., 2003a.
NEC-TEC-ATR Thai speech corpus, O-COCOSDA 2003.Kasuriya, S., Sornlertlamvanich, V., Cotsomrong, P.,Kanokphara, S., Thatphithakkul, N., 2003b.
Thaispeech corpus for speech recognition, InternationalConference on Speech Databases and Assessments(Oriental-COCOSDA).Kikui, G., Sumita, E., Takezawa, T., Yamamoto, S.,2003.
Creating corpora for speech-to-speech transla-tion, EUROSPEECH 2003.Tesprasit, V., Charoenpornsawat, P., Sornlertlamvanich,V., 2003.
Learning phrase break detection in Thaitext-to-speech, EUROSPEECH 2003, pp.
325-328.Rugchatjaroen, A., Thangthai, A., Saychum, S., That-phithakkul, N., Wutiwiwatchai, C., 2007.
Prosody-based naturalness improvement in Thai unit-selectionspeech synthesis, ECTI-CON 2007, Thailand.Thangthai, A., Hansakunbuntheung, C., Siricharoenchai,R., Wutiwiwatchai, C., 2006.
Automatic syllable-pattern induction in statistical Thai text-to-phonetranscription, INTERSPEECH 2006.Thangthai, A., Wutiwiwatchai, C., Ragchatjaroen, A.,Saychum, S., 2007.
A learning method for Thai pho-netization of English words, INTERSPEECH 2007.Thatphithakkul, N., Kruatrachue, B., Wutiwiwatchai, C.,Marukatat, S., Boonpiam, V., 2006.
A simulated-dataadaptation technique for robust speech recognition,INTERSPEECH 2006.Wutiwiwatchai, C., 2007.
Toward Thai-English speechtranslation, International Symposium on UniversalCommunications (ISUC 2007), Japan.Wutiwiwatchai, C., Saychum, S., Rugchatjaroen, A.,2007.
An intensive design of a Thai speech synthesiscorpus, To be presented in International Symposiumon Natural Language Processing (SNLP 2007).
