Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 155?164,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsUnsupervised Solution Post Identification from Discussion ForumsDeepak PIBM Research - IndiaBangalore, Indiadeepak.s.p@in.ibm.comKarthik VisweswariahIBM Research - IndiaBangalore, Indiav-karthik@in.ibm.comAbstractDiscussion forums have evolved into a de-pendable source of knowledge to solvecommon problems.
However, only a mi-nority of the posts in discussion forumsare solution posts.
Identifying solutionposts from discussion forums, hence, is animportant research problem.
In this pa-per, we present a technique for unsuper-vised solution post identification leverag-ing a so far unexplored textual feature, thatof lexical correlations between problemsand solutions.
We use translation mod-els and language models to exploit lex-ical correlations and solution post char-acter respectively.
Our technique is de-signed to not rely much on structural fea-tures such as post metadata since suchfeatures are often not uniformly availableacross forums.
Our clustering-based itera-tive solution identification approach basedon the EM-formulation performs favor-ably in an empirical evaluation, beatingthe only unsupervised solution identifica-tion technique from literature by a verylarge margin.
We also show that our unsu-pervised technique is competitive againstmethods that require supervision, outper-forming one such technique comfortably.1 IntroductionDiscussion forums have become a popular knowl-edge source for finding solutions to common prob-lems.
StackOverflow1, a popular discussion forumfor programmers is among the top-100 most vis-ited sites globally2.
Now, there are discussion fo-rums for almost every major product ranging from1http://www.stackoverflow.com2http://www.alexa.com/siteinfo/stackoverflow.comautomobiles3to gadgets such as those of Mac4orSamsung5.
These typically start with a registereduser posting a question/problem6to which otherusers respond.
Typical response posts include so-lutions or clarification requests, whereas feedbackposts form another major category of forum posts.As is the case with any community of humans,discussion forums have their share of inflamma-tory remarks too.
Mining problem-solution pairsfrom discussion forums has attracted much atten-tion from the scholarly community in the recentpast.
Since the first post most usually containsthe problem description, identifying its solutionsfrom among the other posts in the thread has beenthe focus of many recent efforts (e.g., (Gandhe etal., 2012; Hong and Davison, 2009)).
Extract-ing problem-solution pairs from forums enablesthe usage of such knowledge in knowledge reuseframeworks such as case-based reasoning (Kolod-ner, 1992) that use problem-solution pairs as rawmaterial.
In this paper, we address the problemof unsupervised solution post identification7fromdiscussion forums.Among the first papers to address the solutionidentification problem was the unsupervised ap-proach proposed by (Cong et al, 2008).
It em-ploys a graph propagation method that prioritizesposts that are (a) more similar to the problem post,(b) more similar to other posts, and (c) authoredby a more authoritative user, to be labeled as so-lution posts.
Though seen to be effective in iden-tifying solutions from travel forums, the first twoassumptions, (a) and (b), were seen to be not very3http://www.cadillacforums.com/4https://discussions.apple.com/5http://www.galaxyforums.net/6We use problem and question, as well as solution andanswer interchangeably in this paper.7This problem has been referred to as answer extractionby some papers earlier.
However, we use solution identifica-tion to refer to the problem since answer and extraction haveother connotations in the Question-Answering and Informa-tion Extraction communities respectively.155reliable in solution identification in other kinds ofdiscussion boards.
(Catherine et al, 2012) reportsa study that illustrates that non-solution posts are,on an average, as similar to the problem as solutionposts in technical forums.
The second assump-tion (i.e., (b) above) was also not seen to be use-ful in discussion forums since posts that are highlysimilar to other posts were seen to be complaints,repetitive content being more pervasive amongcomplaint posts than solutions (Catherine et al,2013).
Having exhausted the two obvious textualfeatures for solution identification, subsequent ap-proaches have largely used the presence of lexi-cal cues signifying solution-like narrative (e.g., in-structive narratives such as ?check the router forany connection issues?)
as the primary content-based feature for solution identification.All solution identification approachessince (Cong et al, 2008) have used super-vised methods that require training data in theform of labeled solution and non-solution posts.The techniques differ from one another mostlyin the non-textual features that are employed inrepresenting posts.
A variety of high precision as-sumptions such as solution post typically followsa problem post (Qu and Liu, 2011), solution postsare likely to be within the first few posts, solutionposts are likely to have been acknowledged bythe problem post author (Catherine et al, 2012),users with high authoritativeness are likely toauthor solutions (Hong and Davison, 2009), andso on have been seen to be useful in solutionidentification.
Being supervised methods, theabove assumptions are implicitly factored inby including the appropriate feature (e.g., postposition in thread) in the feature space so that thelearner may learn the correlation (e.g., solutionposts typically are among the first few posts)using the training data.
Though such assumptionson structural features, if generic enough, may bebuilt into unsupervised techniques to aid solutionidentification, the variation in availability ofsuch features across forums limits the usage ofmodels that rely heavily on structural features.For example, some forums employ chronologicalorder based flattening of threads (Seo et al, 2009)making reply-to information unavailable; modelsthat harness reply-to features would then havelimited utility on identifying solutions withinsuch flattened threads.
On medical forums,privacy considerations may force forum data tobe dumped without author information, making ahost of author-id based features unavailable.
Ondatasets that contain data from across forums,the model may have to be aware of the absenceof certain features in subsets of the data, or bemodeled using features that are available on allthreads.Our Contribution: We propose an unsuper-vised method for solution identification.
The cor-nerstone of our technique is the usage of a hith-erto unexplored textual feature, lexical correla-tions between problems and solutions, that is ex-ploited along with language model based charac-terization of solution posts.
We model the lexicalcorrelation and solution post character using reg-ularized translation models and unigram languagemodels respectively.
To keep our technique appli-cable across a large variety of forums with vary-ing availability of non-textual features, we designit to be able to work with minimal availability ofnon-textual features.
In particular, we show thatby using post position as the only non-textual fea-ture, we are able to achieve accuracies compara-ble to supervision-based approaches that use manystructural features (Catherine et al, 2013).2 Related WorkIn this section, we provide a brief overview of pre-vious work related to our problem.
Though mostof the answer/solution identification approachesproposed so far in literature are supervised meth-ods that require a labeled training corpus, there area few that require limited or no supervision.
Ta-ble 1 provides an overview of some of the morerecent solution identification techniques from lit-erature, with a focus on some features that we wishto highlight.
The common observation that mostproblem-solving discussion threads have a prob-lem description in the first post has been explic-itly factored into many techniques; knowing theproblem/question is important for solution iden-tification since author relations between problemand other posts provide valuable cues for solutionidentification.
Most techniques use a variety ofsuch features as noted in Section 1.
SVMs havebeen the most popular method for supervised andsemi-supervised learning for the task of solutionidentification.Of particular interest to us are approaches thatuse limited or no supervision, since we focus onunsupervised solution identification in this paper.156Paper Reference Supervision Assumptions on Features other than LearningProblem Position Post Content Used Technique(Qu and Liu, 2011) Supervised First Post likely HMM assumes Naive Bayesto be problem solution follows problem & HMM(Ding et al, 2008) Supervised First Post Post Position, Author, CRFsContext Posts(Kim et al, 2010) Supervised None Post Position, Author, MaxEnt,Previous Posts, Profile etc.
SVM, CRF(Hong and Davison, 2009) Supervised First Post Post Position, Author, SVMAuthor Authority(Catherine et al, 2012) Supervised First Post Post Position, Author, Problem SVMAuthor?s activities wrt Post(Catherine et al, 2013) Limited First Post Post Position/Rating, Author, SVMs &Supervision Author Rating, Post Ack Co-Training(Cong et al, 2008) Unsupervised None Author, Author Authority, GraphRelation to Problem Author PropagationOur Method Unsupervised First Post Post Position TranslationModels & LMTable 1: Summary of Some Solution Identification TechniquessThe only unsupervised approach for the task, thatfrom (Cong et al, 2008), uses a graph propaga-tion method on a graph modeled using posts asvertices, and relies on the assumptions that poststhat bear high similarity to the problem and otherposts and those authored by authoritative users aremore likely to be solution posts.
Some of those as-sumptions, as mentioned in Section 1, were laterfound to be not generalizable to beyond travel fo-rums.
The semi-supervised approach presentedin (Catherine et al, 2013) uses a few labeledthreads to bootstrap SVM based learners which arethen co-trained in an iterative fashion.
In additionto various features explored in literature, they useacknowledgement modeling so that posts that havebeen acknowledged positively may be favored forbeing labeled as solutions.We will use translation and language modelsin our method for solution identification.
Usageof translation models for modeling the correlationbetween textual problems and solutions have beenexplored earlier starting from the answer retrievalwork in (Xue et al, 2008) where new queries wereconceptually expanded using the translation modelto improve retrieval.
Translation models were alsoseen to be useful in segmenting incident reportsinto the problem and solution parts (Deepak et al,2012); we will use an adaptation of the generativemodel presented therein, for our solution extrac-tion formulation.
Entity-level translation modelswere recently shown to be useful in modeling cor-relations in QA archives (Singh, 2012).3 Problem DefinitionLet a thread T from a discussion forum be madeup of t posts.
Since we assume, much likemany other earlier papers, that the first post isthe problem post, the task is to identify whichamong the remaining t ?
1 posts are solutions.There could be multiple (most likely, different)solutions within the same thread.
We may nowmodel the thread T as t ?
1 post pairs, eachpair having the problem post as the first element,and one of the t ?
1 remaining posts (i.e., re-ply posts in T ) as the second element.
Let C ={(p1, r1), (p2, r2), .
.
.
, (pn, rn)} be the set of suchproblem-reply pairs from across threads in the dis-cussion forum.
We are interested in finding a sub-set C?of C such that most of the pairs in C?areproblem-solution pairs, and most of those in C?C?are not so.
In short, we would like to find problem-solution pairs from C such that the F-measure8forsolution identification is maximized.4 Our Approach4.1 The Correlation AssumptionCentral to our approach is the assumption of lex-ical correlation between the problem and solution8http://en.wikipedia.org/wiki/F1 score157texts.
At the word level, this translates to assum-ing that there exist word pairs such that the pres-ence of the first word in the problem part pre-dicts the presence/absence of the second word inthe solution part well.
Though not yet harnessedfor solution identification, the correlation assump-tion is not at all novel.
Infact, the assumptionthat similar problems have similar solutions (ofwhich the correlation assumption is an offshoot)forms the foundation of case-based reasoning sys-tems (Kolodner, 1992), a kind of knowledge reusesystems that could be the natural consumers ofproblem-solution pairs mined from forums.
Theusage of translation models in QA retrieval (Xue etal., 2008; Singh, 2012) and segmentation (Deepaket al, 2012) were also motivated by the correlationassumption.
We use an IBM Model 1 translationmodel (Brown et al, 1990) in our technique; sim-plistically, such a model m may be thought of asa 2-d associative array where the value m[w1][w2]is directly related to the probability ofw1occuringin the problem when w2occurs in the solution.4.2 Generative model for Solution PostsConsider a unigram language model SSthat mod-els the lexical characteristics of solution posts, anda translation model TSthat models the lexical cor-relation between problems and solutions.
Our gen-erative model models the reply part of a (p, r) pair(in which r is a solution) as being generated fromthe statistical models in {SS, TS} as follows.?
For each word wsoccuring in r,1.
Choose z ?
U(0, 1)2.
If z ?
?, Choose w ?
Mult(SS)3.
Else, Choose w ?
Mult(TpS)where TpSdenotes the multionomial distribu-tion obtained from TSconditioned over the wordsin the post p; this is obtained by assigning eachcandidate solution word w a weight equal toavg{TS[w?][w]|w??
p}, and normalizing suchweights across all solution words.
In short, eachsolution word is assumed to be generated fromthe language model or the translation model (con-ditioned on the problem words) with a probabil-ity of ?
and 1 ?
?
respectively, thus accountingfor the correlation assumption.
The generativemodel above is similar to the proposal in (Deepaket al, 2012), adapted suitably for our scenario.
Wemodel non-solution posts similarly with the soledifference being that they would be sampled fromthe analogous models SNand TNthat characterizebehavior of non-solution posts.Example: Consider the following illustrativeexample of a problem and solution post:?
Problem: I am unable to surf the web on theBT public wifi.?
Solution: Maybe, you should try disconnect-ing and rejoining the network.Of the solution words above, generic wordssuch as try and should could probably be ex-plained by (i.e., sampled from) the solution lan-guage model, whereas disconnect and rejoin couldbe correlated well with surf and wifi and hence aremore likely to be supported better by the transla-tion model.4.3 Clustering-based ApproachWe propose a clustering based approach so as tocluster each of the (p, r) pairs into either the so-lution cluster or the non-solution cluster.
The ob-jective function that we seek to maximize is thefollowing:?
(p,r)?C{F ((p, r),SS, TS) if label((p,r))=SF ((p, r),SN, TN) if label((p,r))=N(1)F ((p, r),S, T ) indicates the conformance ofthe (p, r) pair (details in Section 4.3.1) with thegenerative model that uses the S and T models asthe language and translation models respectively.The clustering based approach labels each (p, r)pair as either solution (i.e., S) or non-solution (i.e.,N ).
Since we do not know the models or the la-belings to start with, we use an iterative approachmodeled on the EM meta-algorithm (Dempster etal., 1977) involving iterations, each comprising ofan E-step followed by the M-step.
For simplicityand brevity, instead of deriving the EM formula-tion, we illustrate our approach by making an anal-ogy with the popular K-Means clustering (Mac-Queen, 1967) algorithm that also uses the EM for-mulation and crisp assignments of data points likewe do.
K-Means is a clustering algorithm thatclusters objects represented as multi-dimensionalpoints into k clusters where each cluster is rep-resented by the centroid of all its members.
Eachiteration in K-Means starts off with assigning each158In K-Means In Our ApproachData Multi-dimensional Points (p, r) pairsCluster Model Respective Centroid Vector Respective S and T Models for each clusterInitialization Random Choice of Centroids Models learnt using (p, r) pairs labeledusing the Post Position of rE-Step label(d) = label((p, r)) = argmaxiF ((p, r),Si, Ti)argminidist(d, centroidi) (Sec 4.3.1), and learn solution wordsource probabilities (Sec 4.3.2)M-Step centroidi= avg{d|label(d) = i} Re-learn SSand TSusing pairs labeled SSNand TNusing pairs labeled N (Sec 4.3.3)Output The clustering of points (p, r) pairs labeled as STable 2: Illustrating Our Approach wrt K-Means Clusteringdata object to its nearest centroid, followed by re-computing the centroid vector based on the assign-ments made.
The analogy with K-Means is illus-trated in Table 2.Though the analogy in Table 2 serves to providea high-level picture of our approach, the details re-quire further exposition.
In short, our approach isa 2-way clustering algorithm that uses two pairs ofmodels, [SS, TS] and [SN, TN], to model solutionpairs and non-solution pairs respectively.
At eachiteration, the post-pairs are labeled as either solu-tion (S) or non-solution (N ) based on which pairof models they better conform to.
Within the sameiteration, the four models are then re-learnt usingthe labels and other side information.
At the endof the iterations, the pairs labeled S are output assolution pairs.
We describe the various details inseparate subsections herein.4.3.1 E-Step: Estimating LabelsAs outlined in Table 2, each (p, r) pair wouldbe assigned to one of the classes, solution ornon-solution, based on whether it conforms betterwith the solution models (i.e., SS& TS) or non-solution models (SN& TN), as determined usingthe F ((p, r),S, T ) function, i.e.,label((p, r)) = argmaxi?
{S,N}F ((p, r),Si, Ti)F (.)
falls out of the generative model:F ((p, r),S, T ) =?w?r??S[w]+(1??
)?Tp[w]where S[w] denotes the probability of w fromS and Tp[w] denotes the probability of w fromthe multinomial distribution derived from T con-ditioned over the words in p, as in Section 4.2.4.3.2 E-Step: Estimating Reply Word SourceSince the language and translation models operateat the word level, the objective function entails thatwe let the models learn based on their fractionalcontribution of the words from the language andtranslation models.
Thus, we estimate the propor-tional contribution of each word from the languageand translation models too, in the E-step.
The frac-tional contributions of the word w ?
r in the (p, r)pair labeled as solution (i.e., S) is as follows:f(p,r)SS(w) =SS[w]SS[w] + TpS[w]f(p,r)TS(w) =TpS[w]SS[w] + TpS[w]The fractional contributions are just the actualsupports for the word w, normalized by the to-tal contribution for the word from across the twomodels.
Similar estimates, f(p,r)SN(.)
and f(p,r)SN(.
)are made for reply words from pairs labeled N .In our example from Section 4.2, words such asrejoin are likely to get higher f(p,r)TS(.)
scores dueto being better correlated with problem words andconsequently better supported by the translationmodel; those such as try may get higher f(p,r)SS(.
)scores.4.3.3 M-Step: Learning ModelsWe use the labels and reply-word source estimatesfrom the E-step to re-learn the language and trans-lation models in this step.
As may be obviousfrom the ensuing discussion, those pairs labeledas solution pairs are used to learn the SSand TSmodels and those labeled as non-solution pairs are159used to learn the models with subscript N .
We leteach reply word contribute as much to the respec-tive language and translation models according tothe estimates in Section 4.3.2.
In our example, ifthe word disconnect is assigned a source proba-bility of 0.9 and 0.1 for the translation and lan-guage models respectively, the virtual document-pair from (p, r) that goes into the training of therespective T model would assume that disconnectoccurs in r with a frequency of 0.9; similarly, therespective S would account for disconnect with afrequency of 0.1.
Though fractional word frequen-cies are not possible in real documents, statisticalmodels can accomodate such fractional frequen-cies in a straightforward manner.
The languagemodels are learnt only over the r parts of the (p, r)pairs since they are meant to characterize reply be-havior; on the other hand, translation models learnover both p and r parts to model correlation.Regularizing the T models: In our formula-tion, the language and translation models may beseen as competing for ?ownership?
of reply words.Consider the post and reply vocabularies to beof sizes A and B respectively; then, the transla-tion model would have A ?
B variables, whereasthe unigram language model has only B variables.This gives the translation model an implicit edgedue to having more parameters to tune to the data,putting the language models at a disadvantage.To level off the playing field, we use a regular-ization9operation in the learning of the transla-tion models.
The IBM Model 1 learning pro-cess uses an internal EM approach where the E-step estimates the alignment vector for each prob-lem word; this vector indicates the distribution ofalignments of the problem word across the solu-tion words.
In our example, an example alignmentvector for wifi could be: {rejoin : 0.4, network :0.4, disconnect : 0.1, .
.
.}.
Our regularizationmethod uses a parameter ?
to discard the long tailin the alignment vector by resetting entries hav-ing a value ?
?
to 0.0 followed by re-normalizingthe alignment vector to add up to 1.0.
Such prun-ing is performed at each iteration in the learn-ing of the translation model, so that the followingM-steps learn the probability matrix according tosuch modified alignment vectors.The semantics of the ?
parameter may be in-9We use the word regularization in a generic sense tomean adapting models to avoid overfitting; in particular, itmay be noted that we are not using popular regularizationmethods such as L1-regularization.Alg.
1 Clustering-based Solution IdentificationInput.
C, a set of (p, r) pairsOutput.
C?, the set of identified solution pairsInitialization1.
?
(p, r) ?
C2.
if(r.postpos = 2) label((p, r)) = S3.
else label((p, r)) = N4.
Learn SS& TSusing pairs labeled S5.
Learn SN& TNusing pairs labeled NEM Iterations6.
while(not converged ?#Iterations < 10)E-Step:7.
?
(p, r) ?
C8.
label((p, r)) = argmaxiF ((p, r),Si, Ti)9.
?w ?
r10.
Estimate f(p,r)Slabel(p,r)(w) , f(p,r)Tlabel(p,r)(w)M-Step:11.
Learn SS& TSfrom pairs labeled Susing the f(p,r)SS(.)
f(p,r)TS(.)
estimates12.
Learn SN& TNfrom pairs labeled Nusing the f(p,r)SN(.)
f(p,r)TN(.)
estimatesOutput13.
Output (p, r) pairs from C withlabel((p, r)) = S as C?tuitively outlined.
If we would like to allow align-ment vectors to allow a problem word to align withupto two reply words, we would need to set ?
toa value close to 0.5(=12); ideally though, to al-low for the mass consumed by an almost inevitablelong tail of very low values in the alignment vec-tor, we would need to set it to slightly lower than0.5, say 0.4.4.3.4 InitializationK-Means clustering mostly initializes centroidvectors randomly; however, it is non-trivial to ini-tialize the complex translation and language mod-els randomly.
Moreover, an initialization such thatthe SSand TSmodels favor the solution pairsmore than the non-solution pairs is critical so thatthey may progressively lean towards modeling so-lution behaviour better across iterations.
Towardsthis, we make use of a structural feature; in partic-ular, adapting the hypothesis that solutions occurin the first N posts (Ref.
(Catherine et al, 2012)),we label the pairs that have the the reply from thesecond post (note that the first post is assumed tobe the problem post) in the thread as a solution160post, and all others as non-solution posts.
Suchan initialization along with uniform reply wordsource probabilities is used to learn the initial es-timates of the SS, TS, SNand TNmodels to beused in the E-step for the first iteration.
We willshow that we are able to effectively perform solu-tion identification using our approach by exploit-ing just one structural feature, the post position,as above.
However, we will also show that we canexploit other features as and when available, to de-liver higher accuracy clusterings.4.3.5 Method SummaryThe overall method comprising the steps thathave been described is presented in Algorithm 1.The initialization using the post position (Ref.Sec 4.3.4) is illustrated in Lines 1-5, whereas theEM-iterations form Steps 6 through 12.
Of these,the E-step incorporates labeling (Line 8) as de-scribed in Sec 4.3.1 and reply-word source estima-tion (Line 10) detailed in Sec 4.3.2.
The modelsare then re-learnt in the M-Step (Lines 11-12) asoutlined in Sec 4.3.3.
At the end of the iterationsthat may run up to 10 times if the labelings do notstabilize earlier, the pairs labeled S are output asidentified solutions (Line 13).Time Complexity: Let n denote |C|, and thenumber of unique words in each problem and re-ply post be a and b respectively.
We will de-note the vocabulary size of problem posts as Aand that of reply posts as B.
Learning of thelanguage and translation models in each iterationcosts O(nb + B) and O(k?
(nab + AB)) respec-tively (assuming the translation model learningruns for k?iterations).
The E-step labeling andsource estimation cost O(nab) each.
For k iter-ations of our algorithm, this leads to an overallcomplexity of O(kk?
(nab+AB)).5 Experimental EvaluationWe use a crawl of 140k threads from Apple Dis-cussion forums10.
Out of these, 300 threads (com-prising 1440 posts) were randomly chosen andeach post was manually tagged as either solutionor non-solution by the authors of (Catherine et al,2013) (who were kind enough to share the datawith us) with an inter-annotator agreement11of0.71.
On an average, 40% of replies in each threadand 77% of first replies were seen to be solutions,10http://discussions.apple.com11http://en.wikipedia.org/wiki/Cohen?s kappaFigure 1: F% (Y) vs. #Iterations (X)TSProblemWord, SolutionWord TS[p][s]network, guest 0.0754connect, adaptor 0.0526wireless, adaptor 0.0526translat, shortcut 0.0492updat, rebuilt 0.0405SSSolutionWord SS[s]your 0.0115try 0.0033router 0.0033see 0.0033password 0.0023Table 4: Sample TSand SSEstimatesleading to an F-measure of 53% for our initializa-tion heuristic.
We use the F-measure12for solu-tion identification, as the primary evaluation mea-sure.
While we vary the various parameters sep-arately in order to evaluate the trends, we use adataset of 800 threads (containing the 300 labeledthreads) and set ?
= 0.5 and ?
= 0.4 unless other-wise mentioned.
Since we have only 300 labeledthreads, accuracy measures are reported on those(like in (Catherine et al, 2013)).
We pre-processthe post data by stemming words (Porter, 1980).5.1 Quality EvaluationIn this study, we compare the performance of ourmethod under varying settings of ?
against theonly unsupervised approach for solution identi-fication from literature, that from (Cong et al,2008).
We use an independent implementationof the technique using Kullback-Leibler Diver-gence (Kullback, 1997) as the similarity measurebetween posts; KL-Divergence was seen to per-form best in the experiments reported in (Cong etal., 2008).Table 3 illustrates the comparative performance12http://en.wikipedia.org/wiki/F1 score161Technique Precision Recall F-MeasureUnsupervised Graph Propagation (Cong et al, 2008) 29.7 % 55.6 % 38.7 %Our Method with only Translation Models (?
= 0.0) 41.8 % 86.8 % 56.5 %Our Method with only Language Models (?
= 1.0) 63.2 % 62.1 % 62.6 %Our Method with Both Models (?
= 0.5) 61.3 % 66.9 % 64.0 %Methods using Supervision (Catherine et al, 2013)ANS CT 40.6 % 88.0 % 55.6 %ANS-ACK PCT 56.8 % 84.1 % 67.8%Table 3: Quality EvaluationFigure 2: F% (Y) vs. ?
(X) Figure 3: F% (Y) vs. ?
(X) Figure 4: F% (Y) vs. #Threads (X)on various quality metrics, of which F-Measure istypically considered most important.
Our pure-LM13setting (i.e., ?
= 1) was seen to perform upto 6 F-Measure points better than the pure-TM14setting (i.e., ?
= 0), whereas the uniform mix isseen to be able to harness both to give a 1.4 point(i.e., 2.2%) improvement over the pure-LM case.The comparison with the approach from (Cong etal., 2008) illustrates that our method is very clearlythe superior method for solution identification out-performing the former by large margins on all theevaluation measures, with the improvement on F-measure being more than 25 points.Comparison wrt Methods from (Catherine etal., 2013): Table 3 also lists the performance ofSVM-based methods from (Catherine et al, 2013)that use supervised information for solution iden-tification, to help put the performance of our tech-nique in perspective.
Of the two methods therein,ANS CT is a more general method that uses twoviews (structural and lexical) of solutions whichare then co-trained.
ANS-ACK PCT is an en-hanced method that requires author-id informa-tion and a means of classifying posts as acknowl-edgements (which is done using additional super-vision); a post being acknowledged by the prob-lem author is then used as a signal to enhancethe solution-ness of a post.
In the absence ofauthor information (such as may be common in13Language Model14Translation Modelprivacy-constrained domains such as medical fo-rums) and extrinsic information to enable identifyacknowledgements, ANS CT is the only techniqueavailable.
Our technique is seen to outperformANS CT by a respectable margin (8.6 F-measurepoints) while trailing behind the enhanced ANS-ACK PCT method with a reasonably narrow 3.8F-measure point margin.
Thus, our unsupervisedmethod is seen to be a strong competitor even fortechniques using supervision outlined in (Cather-ine et al, 2013), illustrating the effectiveness ofLM and TM modeling of reply posts.Across Iterations: For scenarios where com-putation is at a premium, it is useful to know howquickly the quality of solution identification sta-bilizes, so that the results can be collected afterfewer iterations.
Figure 1 plots the F-measureacross iterations for the run with ?
= 0.5, ?
= 0.4setting, where the F-measure is seen to stabilize inas few as 4-5 iterations.
Similar trends were ob-served for other runs as well, confirming that therun may be stopped as early as after the fourth it-eration without considerable loss in quality.Example Estimates from LMs and TMs: Inorder to understand the behavior of the statisticalmodels, we took the highest 100 entries from bothSSand TSand attempted to qualitatively evalu-ate semantics of the words (or word pairs) corre-sponding to those.
Though the stemming made ithard to make sense of some entries, we presentsome of the understandable entries from among162the top-100 in Table 4.
The first three entries fromTSdeal with connection issues for which adaptoror guest account related solutions are proposed,whereas the remaining have something to do withthe mac translator app and rebuilding libraries af-ter an update.
The top words from SSinclude im-perative words and words from solutions to com-mon issues that include actions pertaining to therouter or password.5.2 Varying Parameter SettingsWe now analyse the performance of our approachagainst varying parameter settings.
In particular,we vary ?
and ?
values and the dataset size, andexperiment with some initialization variations.Varying ?
: ?
is the weighting parameter thatindicates the fraction of weight assigned to LMs(vis-a-vis TMs).
As may be seen from Figure 2,the quality of the results as measured by the F-measure is seen to peak around the middle (i.e.,?
= 0.5), and decline slowly towards either ex-treme, with a sharp decline at ?
= 0 (i.e., pure-TM setting).
This indicates that a uniform mix isfavorable; however, if one were to choose only onetype of model, usage of LMs is seen to be prefer-able than TMs.Varying ?
: ?
is directly related to the extent ofpruning of TMs, in the regularization operation;all values in the alignment vector ?
?
are pruned.Thus, each problem word is roughly allowed to bealigned with at most ?1?solution words.
Thetrends from Figure 3 suggests that allowing a prob-lem word to be aligned to up to 2.5 solution words(i.e., ?
= 0.4) is seen to yield the best performancethough the quality decline is graceful towards ei-ther side of the [0.1, 0.5] range.Varying Data Size: Though more data alwaystends to be beneficial since statistical models ben-efit from redundancy, the marginal utility of ad-ditional data drops to very small levels beyonda point; we are interested in the amount of databeyond which the quality of solution identifica-tion flattens out.
Figure 4 suggests that there isa sharp improvement in quality while increasingthe amount of data from 300 threads (i.e., 1440(p, r) pairs) to 550 (2454 pairs), whereas the in-crement is smaller when adding another 250 pairs(total of 3400 pairs).
Beyond 800 threads, the F-measure was seen to flatten out rapidly and stabi-lize at ?
64%.Initialization: In Apple discussion forums,posts by Apple employees that are labeled withthe Apple employees tag (approximately ?
7% ofposts in our dataset) tend to be solutions.
So areposts that are marked Helpful (?
3% of posts) byother users.
Being specific to Apple forums, wedid not use them for initialization in experimentsso far with the intent of keeping the techniquegeneric.
However, when such posts are initial-ized as solutions (in addition to first replies as wedid earlier), the F-score for solution identificationfor our technique was seen to improve slightly, to64.5% (from 64%).
Thus, our technique is ableto exploit any extra solution identifying structuralfeatures that are available.6 Conclusions and Future WorkWe considered the problem of unsupervised so-lution post identification from discussion forumthreads.
Towards identifying solutions to the prob-lem posed in the initial post, we proposed the us-age of a hitherto unexplored textual feature forthe solution identification problem; that of lexicalcorrelations between problems and solutions.
Wemodel and harness lexical correlations using trans-lation models, in the company of unigram lan-guage models that are used to characterize replyposts, and formulate a clustering-based EM ap-proach for solution identification.
We show thatour technique is able to effectively identify solu-tions using just one non-content based feature, thepost position, whereas previous techniques in liter-ature have depended heavily on structural features(that are not always available in many forums) andsupervised information.
Our technique is seen tooutperform the sole unsupervised solution identi-fication technique in literature, by a large margin;further, our method is even seen to be competi-tive to recent methods that use supervision, beat-ing one of them comfortably, and trailing anotherby a narrow margin.
In short, our empirical analy-sis illustrates the superior performance and estab-lishes our method as the method of choice for un-supervised solution identification.Exploration into the usage of translation modelsto aid other operations in discussion forums suchas proactive word suggestions for solution author-ing would be interesting direction for follow-upwork.
Discovery of problem-solution pairs incases where the problem post is not known before-hand, would be a challenging problem to address.163ReferencesPeter F Brown, John Cocke, Stephen A Della Pietra,Vincent J Della Pietra, Fredrick Jelinek, John D Laf-ferty, Robert L Mercer, and Paul S Roossin.
1990.A statistical approach to machine translation.
Com-putational linguistics, 16(2):79?85.Rose Catherine, Amit Singh, Rashmi Gangadharaiah,Dinesh Raghu, and Karthik Visweswariah.
2012.Does similarity matter?
the case of answer extrac-tion from technical discussion forums.
In COLING(Posters), pages 175?184.Rose Catherine, Rashmi Gangadharaiah, KarthikVisweswariah, and Dinesh Raghu.
2013.
Semi-supervised answer extraction from discussion fo-rums.
In IJCNLP.Gao Cong, Long Wang, Chin-Yew Lin, Young-In Song,and Yueheng Sun.
2008.
Finding question-answerpairs from online forums.
In Proceedings of the31st annual international ACM SIGIR conference onResearch and development in information retrieval,pages 467?474.
ACM.P.
Deepak, Karthik Visweswariah, Nirmalie Wiratunga,and Sadiq Sani.
2012.
Two-part segmentation oftext documents.
In CIKM, pages 793?802.Arthur P Dempster, Nan M Laird, and Donald B Ru-bin.
1977.
Maximum likelihood from incompletedata via the em algorithm.
Journal of the Royal Sta-tistical Society.
Series B (Methodological), pages 1?38.Shilin Ding, Gao Cong, Chin-Yew Lin, and XianyanZhu.
2008.
Using conditional random fields to ex-tract contexts and answers of questions from onlineforums.
In ACL.Ankur Gandhe, Dinesh Raghu, and Rose Catherine.2012.
Domain adaptive answer extraction for dis-cussion boards.
In Proceedings of the 21st interna-tional conference companion on World Wide Web,pages 501?502.
ACM.Liangjie Hong and Brian D Davison.
2009.
Aclassification-based approach to question answeringin discussion boards.
In Proceedings of the 32nd in-ternational ACM SIGIR conference on Research anddevelopment in information retrieval, pages 171?178.
ACM.Su Nam Kim, Li Wang, and Timothy Baldwin.
2010.Tagging and linking web forum posts.
In Proceed-ings of the Fourteenth Conference on ComputationalNatural Language Learning, pages 192?202.
Asso-ciation for Computational Linguistics.Janet L Kolodner.
1992.
An introduction to case-basedreasoning.
Artificial Intelligence Review, 6(1):3?34.Solomon Kullback.
1997.
Information theory andstatistics.
Courier Dover Publications.James MacQueen.
1967.
Some methods for classi-fication and analysis of multivariate observations.In Proceedings of the fifth Berkeley symposium onmathematical statistics and probability, volume 1,page 14.
California, USA.Martin F Porter.
1980.
An algorithm for suffix strip-ping.
Program: electronic library and informationsystems, 14(3):130?137.Zhonghua Qu and Yang Liu.
2011.
Finding problemsolving threads in online forum.
In IJCNLP, pages1413?1417.Jangwon Seo, W Bruce Croft, and David A Smith.2009.
Online community search using thread struc-ture.
In Proceedings of the 18th ACM conferenceon Information and knowledge management, pages1907?1910.
ACM.Amit Singh.
2012.
Entity based q&a retrieval.
InEMNLP-CoNLL, pages 1266?1277.Xiaobing Xue, Jiwoon Jeon, and W. Bruce Croft.
2008.Retrieval models for question and answer archives.In SIGIR, pages 475?482.164
