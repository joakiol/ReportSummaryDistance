Proceedings ofEACL '99Automatic Authorship Attr ibutionE.
Stamatatos, N. Fakotakis and G. KokkinakisDept.
of Electrical and Computer EngineeringUniversity of Patras26500 - PatrasGREECEstamatatos@wcl.ee.upatras.grAbstractIn this paper we present an approach toautomatic authorship attribution dealingwith real-world (or unrestricted) text.Our method is based on thecomputational analysis of the input textusing a text-processing tool.
Besides thestyle markers relevant o the output ofthis tool we also use analysis-dependentstyle markers, that is, measures thatrepresent the way in which the text hasbeen processed.
No word frequencycounts, nor other lexically-basedmeasures are taken into account.
Weshow that the proposed set of stylemarkers is able to distinguish texts ofvarious authors of a weekly newspaperusing multiple regression.
All theexperiments we present were performedusing real-world text downloaded fromthe World Wide Web.
Our approach iseasily trainable and fully-automatedrequiring no manual text preprocessingnor sampling.1 IntroductionThe vast majority of the attempts to computer-assisted authorship attribution has been focusedon literary texts.
In particular, a lot of attentionhas been paid to the establishment of theauthorship of anonymous or doubtful texts.
Atypical paradigm is the case of the Federalistpapers twelve of which are of disputedauthorship (Mosteller and Wallace, 1984;Holmes and Forsyth, 1995).
Moreover, the lackof a generic and formal definition of theidiosyncratic style of an author has led to theemployment of statistical methods (e.g.,discriminant analysis, principal components,etc.).
Nowadays, the wealth of text available inthe World Wide Web in electronic form for awide variety of genres and languages, as well asthe development of reliable text-processing toolsopen the way for the solution of the authorshipattribution problem as regards real-world text.The most important approaches to authorshipattribution involve lexically based measures.
Alot of style markers have been proposed formeasuring the richness of the vocabulary usedby the author.
For example, the type-token ratio,the hapax legomena (i.e., once-occurringwords), the hapax dislegomena (i.e., twice-occurring words), etc.
There are also functionsthat make use of these measures such as Yule'sK (Yule, 1944), Honore's R (Honore, 1979), etc.A review of this metrics can be found in(Holmes, 1994).
In (Holmes and Forsyth, 1994)five vocabulary richness functions were used inthe framework of a multivariate statisticalanalysis of the Federalist papers and a principalcomponents analysis was performed.
All thedisputed papers lie in the side of James Madison(rather than Alexander Hamilton) in the space ofthe first two principal components.
However,such measures require the development of largelexicons with specialized information i  order todetect he various forms of the lexical units thatconstitute an author's vocabulary.
For languageswith a rich morphology, i.e.
Modem Greek, thisis an important shortcoming.Instead of counting how many words occurcertain number of times, Burrows (1987)proposed the use of a set of common function(or context-free) word frequencies in the sampletext.
This method combined with a principalcomponents analysis achieved remarkableresults when applied to a wide variety of authors(Burrows, 1992).
On the other hand, a lot of158Proceedings of EACL '99effort is required regarding the selection of themost appropriate set of words that bestdistinguish a given set of authors (Holmes andForsyth, 1995).
Moreover, all the lexically-based style markers are highly author andlanguage dependent.
The results of a work usingsuch measures, therefore, can not be applied to adifferent group of authors nor another language.In order to avoid the problems of lexically-based measures, (Baayen, et al, 1996) proposedthe use of syntax-based ones.
This approach isbased on the frequencies of the rewrite rules asthey appear in a syntactically annotated corpus.Both high-frequent and low-frequent rewriterules give accuracy results comparable tolexically-based methods.
However, thecomputational analysis is considered as asignificant limitation of this method since therequired syntactic annotation scheme is verycomplicated and current text-processing toolsare not capable of providing automatically suchinformation, especially in the case ofunrestricted text.To the best of our knowledge, there is nocomputational system for the automaticdetection of authorship dealing with real-worldtext.
In thispaper, we present an approach tothis problem.
In particular, our aim is thediscrimination between the texts of variousauthors of a Modem Greek weekly newspaper.We use an already existing text processing toolable to detect sentence and chunk boundaries inunrestricted text for the extraction of stylemarkers.
Instead of trying to minimize thecomputational nalysis of the text, we attempt totake advantage of this procedure.
In particular,we use a set of analysis-level style markers, i.e.,measures that represent he way in which thetext has been processed by the tool.
Forexample, a useful measure is the percentage ofthe sample text remaining unanalyzed after theautomatic processing.
In other words, weattempt to adapt the set of the style markers tothe method used by the sentence and chunkdetector in order to analyze the sample text.
Thestatistical technique of multiple regression is,then, used for extracting a linear combination ofthe values of the style markers that manages todistinguish the different authors.
Theexperiments we present, for both authoridentification and author verification tasks, wereperformed using real-world text downloadedfrom the World Wide Web.
Our approach iseasily trainable and fully automated requiring nomanual text preprocessing or sampling.A brief description of the extraction of thestyle markers is given in section 2.
Section 3describes the composition of the corpus of real-world text used in the experiments.
The trainingprocedure is given in section 4 while section 5comprises analytical experimental results.Finally, in section 6 some conclusions are drawnand future work directions are given.2 Extraction of Style MarkersAs aforementioned, an already existing tool isused for the extraction of the style markers.
Thistool is a Sentence and Chunk BoundariesDetector (SCBD) able to deal with unrestrictedModem Greek text (Stamatatos, et aL,forthcoming).
Initially, SCBD segments theinput text into sentences using a set ofdisambiguation rules, and then detects theboundaries of intrasentential phrases (i.e.,chunks) such as noun phrases, prepositionalphrases, etc.
It has to be noted that SCBD makesuse of no complicated resources (e.g., largelexicons).
Rather, it is based on common wordsuffixes and a set of keywords in order to detectthe chunk boundaries using empirically derivedrules.
A sample of its output is given below:VP\[Aev 0~ko~ va p~\ ]  NP\[XdSt\] PP\[tm 1q0co~td\] CON\[akkd\] VP\[ma~m3co\]CON\[6~t\] NP\[I\] sml3dpvvml\] PP\[oxovnpoiJ~oko'/togr\] PP\[a~6 zoa)q 13ovksm~q\]VP\[Sev gnopei va xpoagezpeixat\] g6voPP\[ge za "5 *Sto.
*Spz.
zcovctvaSpogtKrbv\] xov  NP\[xqlpav ze)~evzai.a\]VP\[xpo,:a~.rbv~aq\] NP\[vr I 5voq0opia "CrlqKotvClq $vcbgrlq\].Based on the output of this tool, thefollowing measures are provided:Token-leveh sentence count, word count,punctuation mark count, etc.Phrase-level: noun phrase count, wordincluded in noun phrases countprepositional phrase count, word includedin prepositional phrases count etc.In addition, we use measures relevant o thecomputational nalysis of the input text:159Proceedings ofEACL '99Table 1.
The Corpus Consisting of Texts Taken from the Weekly Newspaper TO BHMA.CodeA01A02A03A04A05A06A07A08A09A10Author  name Texts Tota l  words  Themat ic  areaD.
Maronitis 20 11,771 Culture, societyM.
Ploritis 20 22,947 Culture, historyK.
Tsoukalas 20 30,316 International ffairsC.
Kiosse 20 34,822 ArcheologyS.
Alachiotis 20 19,162 BiologyG.
Babiniotis 20 25,453 LinguisticsT.
Tasios 20 20,973 Technology, societyG.
Dertilis 20 18,315 History, societyA.
Liakos 20 25,826 History, societyG.
Vokos 20 20,049 Philosophy?
Analysis- level:  unanalyzed word count aftereach pass, keyword count, non-matchingword count, and assigned morphologicaldescriptions for both words and chunks.The latter measures can be calculated onlywhen this particular computational tool isutilized.
In more detail, SCBD performsmultiple pass parsing (i.e., 5 passes).
Eachparsing pass analyzes a part of the sentence,based on the results of the previous passes, andthe remaining part is kept for the subsequentpasses.
The first passes try to detect he simplestcases of the chunk boundaries which are easilyrecognizable while the last ones deal with morecomplicated cases using the findings of theprevious passes.
The percentage of the wordsremaining unanalyzed after each parsing pass,therefore, is an important stylistic factor thatrepresents he syntactic omplexity of the text.Additionally, the measure of the detectedkeywords and the detected words that do notmatch any of the stored suffixes include crucialstylistic information.The vast majority of the natural languageprocessing tools can provide analysis-level stylemarkers.
However, the manner of capturing thestylistic information may differ since it dependson the method of analysis.In order to normalize the calculated stylemarkers we make use of ratios of them (e.g.,words / sentences, noun phrases / total detectedchunks, words remaining unanalyzed afterparsing pass 1 / words, etc.).
The total set ofstyle markers comprises 22 markers, namely: 3token-level, 10 phrase-level, and 9 analysis-levelones.3 CorpusThe corpus used for this study consists of textsdownloaded from the World Wide Web-site ofthe Modem Greek weekly newspaper TO BHMA(Dolnet, 1998).
This newspaper comprisesseveral supplements.
We chose to deal withauthors of the supplement B, entitled NEEZEHOXEZ (i.e., new ages), which comprisesessays on science, culture, history, etc.
since insuch writings the indiosyncratic style of theauthor is not likely to be overshadowed by thecharacteristics of the corresponding text-genre.In general, the texts included in the supplementB are written by scholars, writers, etc., ratherthan journalists.
Moreover, there is a closed setof authors that regularly publish their writings inthe pages of this supplement.
The collection of aconsiderable amount of texts by an author was,therefore, possible.Initially, we selected l0 authors whosewritings are frequently published in thissupplement.
No special criteria have been takeninto account.
Then, 20 texts of each author weredownloaded from the Web-site of thenewspaper.
No manual text preprocessing nortext sampling was performed aside fromremoving unnecessary headings.
All thedownloaded texts were taken from issuespublished uring 1998 in order to minimize thepotential change of the personal style of anauthor over time.
Some statistics of thedownloaded corpus are shown in table 1.
Thelast column of this table refers to the thematicarea of the majority of the writings of eachauthor.
Notice that this information was not160Proceedings ofEACL '99taken into account during the construction of thecorpus.4 TrainingThe corpus described in the previous sectionwas divided into a training and a test corpus.
Asit is shown by Biber (1990; 1993), it is possibleto represent he distributions of many corelinguistic features of a stylistic category basedon relatively few texts from each category (i.e.,as few as ten texts).
Thus, for each author 10texts were used for training and I 0 for testing.All the texts were analyzed using SCBD whichprovided a vector of 22 style markers for eachtext.
Then, the statistical methodology ofmultivariate linear multiple regression wasapplied to the training corpus.
Multipleregression provides predicting values of a groupof response (dependent) variables from acollection of predictor (independent) variablevalues.
The response is expressed as a linearcombination of the predictor variables, namely:y~=bo + zlblt + z2b2i +...  + zrbri + e~where y, is the response for the i-th author, zi,ze,..and Zr are the predictor variables (i.e., in ourcase r=22), bo, bl,, b2,,..., and br,, are theunknown coefficients, and e, is the randomerror.
During the training procedure theunknown coefficients for each author aredetermined using binary values for the responsevariable (i.e., I for the texts written by theauthor in question, 0 for the others).
Thus, thegreater the response variable of a certain author,the more likely to be the author of the text.Some statistics measuring the degree towhich the regression functions fit the trainingdata are presented in table 2.
Notice that R e isthe coefficient o f  determination defined asfollows:t/R 2 - j=l~--~(yj _ y)2j=lwhere n is the total number of training data(texts), y is the mean response, )3j and yj arethe estimated response and the training responsevalue of the j-th author respectively.Additionally, a significant F-value implies that astatistically significant proportion of the totalvariation in the dependent variable is explained.Table 2.
Statistics of the Regression Functions.Code l R 2 \[ FVa lueA01 0.40 2.32A02 0.72 9.12A03 0.44 2.80A04 0.44 2.80A05 0.32 1.61A06 0.51 3.57A07 0.59 5.13A08 0.35 1.87A09 0.53 4.00A10 0.63 5.90It has to be noted that we use this particulardiscrimination method ue to the facility offeredin the computation of the unknown coefficientsas well as the computationally simplecalculation of the predictor values.
However, webelieve that any other methodology fordiscrimination-classification can be applied(e.g., discriminant analysis, neural networks,etc.
).5 PerformanceBefore proceeding to the presentation of theanalytical results of our disambiguation method,a representation of the test corpus into adimensional space would illustrate the maindifferences and similarities between the authors.Towards this end, we performed a principalcomponents analysis and the representation fthe 100 texts of the test corpus in the spacedefined by the first and the second principalcomponents (i.e., accounting for the 43% of thetotal variation) is depicted in figure 1.
As can beseen, the majority of the texts written by thesame author tend to cluster.
Nevertheless, theseclusters cannot be clearly separated.According to our approach, the criterion foridentifying the author of a text is the value of theresponse linear function.
Hence, a text isclassified to the author whose response value isthe greatest.
The confusion matrix derived fromthe application of the disambiguation procedureto the test corpus is presented in table 3, whereeach row contains the responses for the ten testtexts of the corresponding author.
The lastcolumn refers to the identification error (i.e.,161Proceedings of EACL '99ii?
3 -26 7!
)4)X'Oi0A X- - -00-4 .?
+-6 --8 .
+t-o@-10 JFirst principal componentXXX ??
~ ~.g  \[\]Arl?
&2\[\]+@+\[\]?
+++ ?++ ?
?+Figure 1.
The Test Corpus in the Space of the First Two Principal Components.Table 3.
Confusion Matrix of the Author Identification Experiment.?
A01?
A02t, A03X A046o A05?
A06+ A07\[\] A08- A09&AI0Actual GuessA01 A02 .IA03 \]A04 A05 A06 A07 A08A01 3 2 0 0 2 0 0 2A02 0 10 0 0 0 0 0 0A03 0 0 8 0 0 0 0 1A04 0 0 0 9 0 0 0 0A05 0 0 0 3 3 1 0 0A06 2 1 0 0 0 7 0 0A07 0 0 0 0 0 0 10 0A08 1 2 0 1 0 2 0 4A09 0 0 0 0 0 0 0 1A10 0 0 2 1 1 0 0 0A09 I A100 10 00 10 13 00 00 00 09 00 6AverageError0.70.00.20.10.70.30.00.60.10.4erroneously classified texts / total texts) for eachauthor.
Approximately 65% of the averageidentification error corresponds to three authors,namely: A01, A05, and A08.
Notice that theseare the authors with an average text-size smallerthan 1,000 words (see table 1).
It appears,therefore, that a text sample of  relatively shortsize (i.e., less than 1,000 words) is not adequatefor the representation of  the stylisticcharacteristics of  an author's style.
Notice thatsimilar conclusions are drawn by Biber (1990;1993).Instead of trying to identify who the authorof a text is, some applications require theverification of the hypothesis that a given personis the author of the text.
In such a case, only theresponse function of the author in question isinvolved.
Towards this end, a threshold valuehas to be defined for each response function.Thus, if the response value for the given authoris greater than the threshold then the author isaccepted.Additionally, for measuring, the accuracy ofthe author verification method as regards a162Proceedings ofEACL '99FR .
.
.
.
.
.
.
FA .
.
.
.
Mean.
9 - z0.80.7 ~0.6 ~-0.4 ~ "-.i "e0.3 ~ "'.
/ ~-0.2 ~- -  ' ~"" " .
.
.
.
.
.
.
.
.
1 .
.
.
.
T .
.
.
.
.
.
.
I i0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1xRFigure 2.
FR, FA, and Mean Error as Functions of Subdivisions of R.certain author, we defined False Rejection (FR)and False Acceptance (FA) as follows:FR = rejected texts of  the authortotal texts of the authorFA = accepted texts of the authortotal text of other authorsSimilar measures are widely utilized in thearea of speaker recognition in speech processing(Fakotakis, et al, 1993).The multiple correlation coefficientR = +x/R 2 of a regression function (see table 2)equals 1 if the fitted equation passes through allthe data points.
At the other extreme, it equals 0.The fluctuation of average FR, FA, and meanerror (i.e., (FR+FA)/2) for the entire test corpususing subdivisions of R as threshold (x-axis) isshown in figure 2, and the minimum mean errorcorresponds to R/2.
Notice that by choosing thethreshold based on the minimal mean error themajority of applications i covered.
On the otherhand, some applications require either minimalFR or FA, and this fact has to be taken intoaccount during the selection of the threshold.The results of the author verificationexperiment using R/2 as threshold are presentedin table 4.
Approximately 70% of the total falserejection corresponds to the authors A01, A05,A08 as in the case of author identification.
Onthe other hand, false acceptance seems to behighly relevant to the threshold value.
Thesmaller the threshold value, the greater the falseacceptance.
Thus, the authors A03, A04, A05,and A08 are responsible for 72% of the totalfalse acceptance error.Table 4.
Author Verification Results"threshold=R/2).Code I R/2 \[ FR I FAA01 0.32 0.3 0.022A02 0.42 0.0 0.044A03 0.33 0.0 0.155A04 0.33 0.1 0.089A05 0.28 0.6 0.144A06 0.36 0.2 0.011A07 0.38 0.0 0.022A08 0.30 0.6 0.100A09 0.36 0.0 0.055A10 0.40 0.4 0.033Average 0.35 0.22 \[ 0.068Finally, the total time cost (i.e., textprocessing by SCBD, calculation of stylemarkers, computation of response values) for theentire test corpus was 58.64 seconds, or 1,971words per second, using a Pentium at 350 MHz.6 Conc lus ionsWe presented an approach to automaticauthorship attribution of real-world texts.
A163Proceedings of EACL '99computational tool was used for the automaticextraction of the style markers.
In contrast oother proposed systems we took advantage ofthis procedure in order to extract analysis-levelstyle markers that represent the way in whichthe text has been analyzed.
The experimentsbased on texts taken from a weekly ModemGreek newspaper prove that the stylisticdifferences among a wide range of authors canbe easily detected using the proposed set of stylemarkers.
Both author identification and authorverification tasks have given encouragingresults.Moreover, no lexically-based measures, uchas word frequencies, are involved.
Thisapproach can be applied to a wide-variety ofauthors and types of texts since any domain-dependent, genre-dependent, author-dependentstyle marker have not been taken into account.Although our method has been tested on ModemGreek, it requires no language-specificinformation.
The only prerequisite of thismethod in order to be employed in anotherlanguage is the availability of a text-processingtool of general purpose and the appropriateselection of the analysis-level measures.The presented approach is fully-automatedsince it is not based on specialized textpreprocessing requiring manual effort.Nevertheless, we believe that the accuracyresults may be significantly improved byemploying text-sampling procedures forselecting the parts of text that best illustrate thestylistic features of an author.Regarding the amount of required trainingdata, we proved that ten texts are adequate forrepresenting the stylistic features of an author.Some experiments we performed using morethan ten texts as training corpus for each authordid not improved significantly the accuracyresults.
It has been also shown that a lowerbound of the text-size is 1,000 words.Nevertheless, we believe that this limitationaffects mainly authors with vague stylisticcharacteristics.We are currently working on the applicationof the presented methodology to text-genredetection as well as to any stylisticallyhomogeneous group of real-world texts.
We alsoaim to explore the usage of a variety ofcomputational tools for the extraction ofanalysis-level style markers for Modem Greekand other natural languages.ReferencesBaayen, H., H. Van Halteren, and F. Tweedie1996, Outside the Cave of Shadows: UsingSyntactic Annotation to Enhance AuthorshipAttribution, Literary and Linguistic Computing,11(3): 121-131.Biber, D. 1990, Methodological IssuesRegarding Corpus-based Analyses of LinguisticVariations, Literary and Linguistic Computing,5: 257-269.Biber, D. 1993, Representativeness in CorpusDesign, Literary and Linguistic Computing, 8:1-15.Burrows, J.
1987, Word-patterns and Story-shapes: The Statistical Analysis of NarrativeStyle, Literary and Linguistic Computing, 2(2):61-70.Burrows, J.
1992, Not Unless You AskNicely: The Interpretative Nexus BetweenAnalysis and Information, Literary andLinguistic Computing, 7(2): 91-109.Dolnet, 1998, TO BHMA, LambrakisPublishing Corporation, http://tovima.dolnet.gr/Fakotakis, N., A. Tsopanoglou, and G.Kokkinakis, 1993, A Text-independent SpeakerRecognition System Based on Vowel Spotting,Speech Communication, 12: 57-68.Holmes, D. 1994, Authorship Attribution,Computers and the Humanities, 28: 87-106.Holmes, D. and R. Forsyth 1995, TheFederalist Revisited: New Directions inAuthorship Attribution, Literary and LinguisticComputing, 10(2): 111-127.Honore, A., 1979, Some Simple Measures ofRichness of Vocabulary, Association forLiterary and Linguistic Computing Bulletin,7(2): 172-177.Mosteller, F. and D. Wallace 1984, AppliedBayesian and Classical Inference."
The Case ofthe Federalist Papers, Addison-Wesley,Reading, MA.Stamatatos, E., N. Fakotakis, and G.Kokkinakis forthcoming, On Detecting Sentenceand Chunk Boundaries in Unrestricted TextBased on Minimal Resources.Yule, G. 1944, The Statistical Study ofLiterary Vocabulary, Cambridge UniversityPress, Cambridge.164
