Proceedings of the ACL Student Research Workshop, pages 1?8,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsCategorization of Turkish News Documents with Morphological AnalysisBurak Kerim Akkus?Computer Engineering DepartmentMiddle East Technical UniversityAnkara, Turkeyburakkerim@ceng.metu.edu.trRuket C?ak?c?Computer Engineering DepartmentMiddle East Technical UniversityAnkara, Turkeyruken@ceng.metu.edu.trAbstractMorphologically rich languages such asTurkish may benefit from morphologicalanalysis in natural language tasks.
In thisstudy, we examine the effects of morpho-logical analysis on text categorization taskin Turkish.
We use stems and word cate-gories that are extracted with morphologi-cal analysis as main features and comparethem with fixed length stemmers in a bagof words approach with several learningalgorithms.
We aim to show the effectsof using varying degrees of morphologicalinformation.1 IntroductionThe goal of text classification is to find the cat-egory or the topic of a text.
Text categorizationhas popular applications in daily life such as emailrouting, spam detection, language identification,audience detection or genre detection and has ma-jor part in information retrieval tasks.The aim of this study is to explain the impact ofmorphological analysis and POS tagging on Turk-ish text classification task.
We train various classi-fiers such as k-Nearest Neighbours (kNN), NaiveBayes (NB) and Support Vector Machines (SVM)for this task.
Turkish NLP tasks have been provento benefit from morphological analysis or segmen-tation of some sort (Eryig?it et al 2008; C?etinog?luand Oflazer, 2006; C?ak?c?
and Baldridge, 2006).Two different settings are used throughout the pa-per to represent different degrees of stemming andinvolvement of morphological information.
Thefirst one uses the first n-characters (prefixes) ofeach word in a bag of words approach.
A varietyof number of characters are compared from 4 to 7to find the optimal length for data representation.This acts as the baseline for word segmentationin order to make the limited amount of data lesssparse.
The second setting involves word stemsthat are extracted with a morphological analysisfollowed by disambiguation.
The effects of part ofspeech tagging are also explored.
Disambiguatedmorphological data are used along with the part ofspeech tags as informative features about the wordcategory.Extracting an n-character prefix is simple andconsiderably cheap compared to complex state-of-the-art morphological analysis and disambigua-tion process.
There is a trade-off between qualityand expense.
Therefore, we may choose to use acheap approximation instead of a more accuraterepresentation if there is no significant sacrifice inthe success of the system.
Turkish is an agglutina-tive language that mostly uses suffixes1.
There-fore, approximate stems that are extracted withfixed size stemming rarely contain any affixes.The training data used in this study consist ofnews articles taken from Milliyet Corpus that con-tains 80293 news articles published in the news-paper Milliyet (Hakkani-Tu?r et al 2000) 2.
Thearticles we use for training contain a subset of doc-uments indexed from 1000-5000 and have at least500 characters.
The test set is not included in theoriginal corpus, but it has also been downloadedform Milliyet?s public website 3.The data used in this study have been ana-lyzed with the morphological analyser describedin Oflazer (1993) and disambiguated with Sak etal.
(2007)?s morphological disambiguator.
Thedata have been manually labelled for training andtest.
The annotated data is made available for pub-1It has only one prefix for intensifying adjectives and ad-verbs (s?ms?cak: very hot).
It is just a modified version of thefirst syllable of the original word and also it is not common.There are other prefixes adopted from foreign languages suchas anormal (abnormal), antisosyal (antisocial) or namert (notbrave).2Thanks to Kemal Oflazer for letting us use the corpus3http://www.milliyet.com.tr1lic use 4.
By making our manually annotated dataavailable, we hope to contribute to future work inthis area.The rest of the paper is organized as follows.Section 2 briefly describes the classification meth-ods used, section 3 explains how these methodsare used in implementation and finally the paper isconcluded with experimental results.2 BackgroundSupervised and unsupervised methods have beenused for text classification in different languages(Amasyal?
and Diri, 2006; Beil et al 2002).Among these are Naive Bayes classification (Mc-Callum and Nigam, 1998; Schneider, 2005), deci-sion trees (Johnson et al 2002) , neural networks(Ng et al 1997), k-nearest neighbour classifiers(Lim, 2004) and support-vector machines (Shana-han and Roma, 2003).Bag-of-words model is one of the more intu-itive ways to represent text files in text classi-fication.
It is simple, it ignores syntax, gram-mar and the relative positions of the words inthe text (Harris, 1970).
Each document is repre-sented with an unordered list of words and each ofthe word frequencies in the collection becomes afeature representing the document.
Bag-of-wordsapproach is an intuitive way and popular amongdocument classification tasks (Scott and Matwin,1998; Joachims, 1997).Another way of representing documents withterm weights is to use term frequency - inversedocument frequency (Sparck Jones, 1988).
TFIDFis another way of saying that a term is valuable fora document if it occurs frequently in that docu-ment but it is not common in the rest of the collec-tion.
TFIDF score of a term t in a document d in acollection D is calculated as below:tfidft,d,D = tft,d ?
idft,Dtft,d is the number of times t occurs in d and idft,Dis the number of documents in D over the numberof document that contain t.The idea behind bag of words and TFIDF is tofind a mapping from words to numbers which canalso be described as finding a mathematical rep-resentation for text files.
The output is a matrixrepresentation of the collection.
This is also calledvector space model representation of the collec-4http://www.ceng.metu.edu.tr/ burakkerim/text cattion in which we can define similarity and dis-tance metrics for documents.
One way is to usedot product since each document is represented asa vector (Manning et al 2008).
A number of dif-ferent dimensions in vector spaces are comparedin this study to find the optimal performance.2.1 MorphologyLanguages such as Turkish, Czech and Finnishhave more complex morphology and cause addi-tional difficulties which requires special handlingon linguistic studies compared to languages suchas English (Sak et al 2007).
Morphemes maycarry semantic or syntactic information, but mor-phological ambiguity make it hard to pass this in-formation on to other level in a trivial manner es-pecially for languages with productive morphol-ogy such as Turkish.
An example of possible mor-phological analyses of a single word in Turkish ispresented in Table 1.al?n+Noun+A3sg+Pnon+Nom (forehead)al+Adj?DB+Noun+Zero+A3sg+P2sg+Nom (your red)al+Adj?DB+Noun+Zero+A3sg+Pnon+Gen (of red)al+Verb+Pos+Imp+A2pl ((you) take)al+Verb?DB+Verb+Pass+Pos+Imp+A2sg ((you) be taken)al?n+Verb+Pos+Imp+A2sg ((you) be offended)Table 1: Morphological analysis of the word?al?n?
in Turkish with the corresponding mean-ings.We aim to examine the effects of morpholog-ical information in a bag-of-words model in thecontext of text classification.
A relevant studyexplores the prefixing versus morphological anal-ysis/stemming effect on information retrieval inCan et al(2008).
Several stemmers for Turkishare presented for the indexing problem for infor-mation retrieval.
They use Oflazer?s morphologi-cal analyzer (Oflazer, 1993), however, they do notuse a disambiguator.
Instead they choose the mostcommon analysis among the candidates.
Their re-sults show that among the fixed length stemmers5-character prefix is the the best and the lemma-tizer based stemmer is slightly better than the fixedlength stemmer with five characters.
However,they also note that the difference is statistically in-significant.
We use Sak et al(2007)?s disambigua-tor which is reported with a 96.45% accuracy intheir study and with a 87.67% accuracy by Eryig?it(2012)2Figure 1: Learning curves with first five charactersFigure 2: Learning curves with stems3 ImplementationIn the first setting, up to first N characters of eachword is extracted as the feature set.
A compari-son between 4, 5, 6 and 7 characters is performedto choose the best N. In the second setting weuse morphological analysis.
Each word in docu-ments is analysed morphologically with morpho-logical analyser from Oflazer (1993) and wordstems are extracted for each term.
Sak?s mor-phological disambiguator for Turkish is used atthis step to choose the correct analysis (Sak etal., 2007).
Stems are the primary features usedfor classification.
Finally, we add word categoriesfrom this analysis as features as POS tags.We compare these settings in order to see howwell morphological analysis with disambiguationperforms against a simple baseline of fixed lengthstemming with a bag-of-words approach.
Bothstem bags and the first N-character bags are trans-formed into vector space with TFIDF scoring.Then, different sizes of feature space dimensionsare used with ranking by the highest term fre-quency scores.
A range of different dimensionsizes from 1200 to 7200 were experimented on tofind the optimal dimension size for this study (Ta-ble 2).
After the collection is mapped into vectorspace, several learning algorithms are applied forclassification.
K-Nearest neighbours was imple-mented with weighted voting of 25 nearest neigh-bours based on distance and Support Vector Ma-chine is implemented with linear kernel and de-fault parameters.
These methods are used withPython, NLTK (Loper and Bird, 2002) and Sci-Kit(Loper and Bird, 2002; Pedregosa et al 2011).Training data contains 872 articles labelled anddivided into four categories as follows: 235 ar-ticles on politics, 258 articles about social newssuch as culture, education or health, 177 arti-cles on economics and 202 about sports.
Thisdata are generated using bootstrapping.
Docu-ments are hand annotated with an initial classi-fier that is trained on a smaller set of hand la-belled data.
Classifier is used on unknown sam-3ples, then the predictions are manually checked togather enough data for each class.
Test data con-sists of 160 articles with 40 in each class.
Theseare also manually labelled.4 ExperimentsExperiments begin with searching the optimal pre-fix length for words with different classifiers.
Af-ter that, stems are used as features and evaluatedwith the same classifiers.
Section 4.3 containsthe comparison of these two features.
Finally,morphological information is added to these fea-tures and the effects of the extra information is in-spected in Section 4.4 .4.1 Optimal Number of CharactersThis experiment aims to find out the optimal pre-fix length for the first N-character feature to rep-resent text documents in Turkish.
We conjecturethat we can simulate stemming by taking a fixedlength prefix of each word.
This experiment wasperformed with all of the 872 training files and160 test files.
Table 2 shows the results of the ex-periments where columns represent the number ofcharacters used and rows represent the number offeatures used for classification.The best performance is acquired using the firstfive characters of each word for TFIDF transfor-mation for all classifiers.
Can et al(2008) alsoreported that the five character prefix in the fixedlength stemmer performed the best in their ex-periments.
Learning curves for 5-character pre-fixes are presented in Figure 1.
Although, SVMperforms poorer on average compared to NaiveBayes, their best performances show no signifi-cant statistical difference according to McNemar?sTest.
On the other hand, kNN falls behind thesetwo on most of the configurations.4.2 StemsAnother experiment was conducted with the wordstems extracted with a morphological analyser anda disambiguator (Sak et al 2007).
kNN, NaiveBayes and SVM were trained with different fea-ture sizes with increasing training data sizes.
Thelearning curves are presented in Figure 2.Naive Bayes performs best in this setting evenwith a small feature set with few training sam-ples.
When the corpus size is small, using lessfeatures gives better results in SVM and NaiveBayes.
As the number of features used in classi-fication increases, the number of samples neededfor an adequate classification also increases forNaive Bayes.
The performance of SVM also in-creases with the number of data used in training.More documents leave space for repetitions forstop words and common less informative words antheir TFIDF scores decrease and the get less im-pact on the classification while informative wordsin each category get relatively higher scores, there-fore an increase in data size also increases perfor-mance.
As the training size increases feature spacedimension becomes irrelevant and the results con-verge to a similar point for Naive Bayes.
On theother hand, 1200 features are not enough for kNNand SVM.
With larger feature sets kNN and SVMalso give similar results to Naive Bayes althoughkNN is left behind especially with less number offeatures since it directly relies on the similaritybased on these features in vector space and most ofthem are same in each document since we choosethem with term frequency.4.3 5-Character Prefixes vs StemsThis section provides a comparison between twomain features used in this study with three differ-ent classifiers.
F1 scores for the best and worstconfigurations with each of the three classifiers arepresented in Table 3.
Using five character prefixesgives better results than using stems.
Naive Bayeswith stems and five character prefixes disagreeonly on six instances out of 160 test instances withF1 scores of 0.92 and 0.94 respectively in the bestconfigurations.
There is no statistically significantdifference.Similarly, results for SVM with stems for thebest and the worst configurations is considered tobe not statistically significant.
McNemar?s Test(McNemar, 1947) is shown to have low error indetecting a significant difference when there isnone (Dietterich, 1998).Worst BestFirst 5 Stems First 5 StemsKNN 91.250 86.875 92.500 91.875NB 92.500 91.250 94.375 91.875SVM 91.250 88.750 93.175 92.500Table 3: Comparison of F1-scores for best andworst results in each classifier with each feature.4(a) Learning curves without tags(b) Learning curves with stem tags(c) Learning curves with word tagsFigure 3: Learning curves for SVM5KNN NB SVM4 5 6 7 4 5 6 7 4 5 6 71200 90.00 91.25 86.87 84.37 93.12 92.50 93.12 90.00 89.37 91.250 90.62 88.752400 89.37 91.25 87.50 86.62 89.37 91.25 87.50 86.62 90.62 91.87 90.00 88.123600 86.87 91.25 90.00 88.17 93.75 93.75 92.50 91.87 90.62 91.87 90.00 88.124800 90.00 91.87 91.25 88.17 93.12 93.75 91.87 91.25 90.62 91.87 90.00 88.126000 88.75 91.87 91.87 90.62 92.50 93.75 92.50 90.62 90.62 93.12 93.12 90.007200 89.37 92.50 91.25 89.37 90.62 94.37 91.87 91.25 90.62 92.50 91.25 90.62Table 2: F1-scores with different prefix lengths and dimensions.4.4 SVM with POS TagsThe final experiment examines the effects of POStags that are extracted via morphological analy-sis.
Two different features are extracted and com-pared with the base lines of classifiers with stemsand first five characters without tags.
Stem tag isthe first tag of the first derivation and the wordtag is the tag of the last derivation and examplefeatures are given in Table 4.
Since derivationalmorphemes are also present in the morphologicalanalyses word tags may differ from stem tags.
Inaddition, words that are spelled in the same waymay belong to different categories or have dif-ferent meanings that can be expressed with POStags.
Al+Verb (take) and Al+Adj (red) are differ-ent even though their surface forms are the same.Analysis al+Adj?DB+Noun+Zero+A3sg+Pnon+Gen (of red)First 5 characters.
al?n ( of red, forehead,(you) be taken, (you) be of-fended ...)Stem al ( red, take )Stem + Stem Tag al+Adj ( red )Stem + Word Tag al+Noun ( red )Table 4: Example features for word ?al?n?.Using POS tags with stems increases the suc-cess rate especially when the number of featuresis low.
However, using tags of the stems doesnot make significant changes on average.
The bestand the worst results differ with baseline with lessthan 0.01 points in F1 scores as seen in Figure 3.This may be due to the fact that the same stemhas a higher chance of being in the same cate-gory even though the derived final form is differ-ent.
Even though, this may add extra informationto the stems, results show no significant differ-ence.
Adding stem or word tags to the first fivecharacters increases the success when the numberof training instances are low, however, it has nosignificant effect on the highest score.
Using tagswith five characters has positive effects when thenumber of features are low and negative effectswhen the number of features are high.5 ConclusionIn this study, we use K-Nearest Neighbours, NaiveBayes and Support Vector Machine classifiers forexamining the effects of morphological informa-tion on the task of classifying Turkish news arti-cles.
We have compared their performances ondifferent sizes of training data, different numberof features and different feature sets.
Results sug-gest that the first five characters of each word canbe used for TFIDF transformation to represent textdocuments in classification tasks.
Another fea-ture used in the study is word stems.
Stems areextracted with a morphological analyser which iscomputationally expensive and takes a lot of timecompared to extracting first characters of a word.Although different test sets and training data maychange the final results, using a simple approxi-mation with first five characters to represent doc-uments instead of results of an expensive morpho-logical analysis process gives similar or better re-sults with much less cost.
Experiments also indi-cate that there is more place for growth if moretraining data is available as most of the learningcurves presented in the experiments point.
Weparticularly expect better results with POS tagexperiments with more data.
Actual word cate-gories and meanings may differ and using POStags may solve this problem but sparsity of the datais more prominent at the moment.
The future workincludes repeating these experiments with largerdata sets to explore the effects of the data size.6ReferencesCharu C. Aggarwal and Philip S. Yu.
2000.
Findinggeneralized projected clusters in high dimensionalspaces.
SIGMOD Rec., 29(2):70?81.M.
Fatih Amasyal?
and Banu Diri.
2006.
AutomaticTurkish text categorization in terms of author, genreand gender.
In Proceedings of the 11th internationalconference on Applications of Natural Languageto Information Systems, NLDB?06, pages 221?226,Berlin, Heidelberg.
Springer-Verlag.Florian Beil, Martin Ester, and Xiaowei Xu.
2002.
Fre-quent term-based text clustering.
In Proceedings ofthe eighth ACM SIGKDD international conferenceon Knowledge discovery and data mining, KDD ?02,pages 436?442, New York, NY, USA.
ACM.Fazl?
Can, Seyit Koc?berber, Erman Balc?
?k, Cihan Kay-nak, H. C?ag?das?
O?calan, and Onur M. Vursavas?.2008.
Information retrieval on turkish texts.
JA-SIST, 59(3):407?421.Ruket C?ak?c?
and Jason Baldridge.
2006.
Projectiveand non-projective Turkish parsing.
In Proceedingsof the 5th International Treebanks and LinguisticTheories Conference, pages 43?54.O?zlem C?etinog?lu and Kemal Oflazer.
2006.Morphology-syntax interface for Turkish LFG.
InProceedings of the 21st International Conferenceon Computational Linguistics and the 44th annualmeeting of the Association for Computational Lin-guistics, ACL-44, pages 153?160, Stroudsburg, PA,USA.
Association for Computational Linguistics.Thomas G. Dietterich.
1998.
Approximate statis-tical tests for comparing supervised classificationlearning algorithms.
Neural Computation, 10:1895?1923.Gu?ls?en Eryig?it.
2012.
The impact of automatic mor-phological analysis & disambiguation on depen-dency parsing of turkish.
In Proceedings of theEighth International Conference on Language Re-sources and Evaluation (LREC), Istanbul, Turkey,23-25 May.Gu?ls?en Eryig?it, Joakim Nivre, and Kemal Oflazer.2008.
Dependency parsing of Turkish.
Comput.Linguist., 34(3):357?389, September.George Forman.
2003.
An extensive empirical studyof feature selection metrics for text classification.
J.Mach.
Learn.
Res., 3:1289?1305, March.Dilek Z. Hakkani-Tu?r, Kemal Oflazer, and Go?khan Tu?r.2000.
Statistical morphological disambiguation foragglutinative languages.
In Proceedings of the 18thconference on Computational linguistics - Volume1, COLING ?00, pages 285?291, Stroudsburg, PA,USA.
Association for Computational Linguistics.Zelig Harris.
1970.
Distributional structure.
In Pa-pers in Structural and Transformational Linguis-tics, pages 775?794.
D. Reidel Publishing Company,Dordrecht, Holland.M.
Ikonomakis, S. Kotsiantis, and V. Tampakas.
2005.Text classification: a recent overview.
In Proceed-ings of the 9th WSEAS International Conference onComputers, ICCOMP?05, pages 1?6, Stevens Point,Wisconsin, USA.
World Scientific and EngineeringAcademy and Society (WSEAS).Thorsten Joachims.
1997.
A probabilistic analysis ofthe rocchio algorithm with tfidf for text categoriza-tion.
In Proceedings of the Fourteenth InternationalConference on Machine Learning, ICML ?97, pages143?151, San Francisco, CA, USA.
Morgan Kauf-mann Publishers Inc.D.
E. Johnson, F. J. Oles, T. Zhang, and T. Goetz.
2002.A decision-tree-based symbolic rule induction sys-tem for text categorization.
IBM Syst.
J., 41(3):428?437, July.Heui-Seok Lim.
2004.
Improving kNN based textclassification with well estimated parameters.
InNikhil R. Pal, Nikola Kasabov, Rajani K. Mudi,Srimanta Pal, and Swapan K. Parui, editors, Neu-ral Information Processing, 11th International Con-ference, ICONIP 2004, Calcutta, India, November22-25, 2004, Proceedings, volume 3316 of Lec-ture Notes in Computer Science, pages 516?523.Springer.Tao Liu, Shengping Liu, and Zheng Chen.
2003.
Anevaluation on feature selection for text clustering.
InIn ICML, pages 488?495.Edward Loper and Steven Bird.
2002.
Nltk: the nat-ural language toolkit.
In Proceedings of the ACL-02 Workshop on Effective tools and methodologiesfor teaching natural language processing and com-putational linguistics - Volume 1, ETMTNLP ?02,pages 63?70, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Christopher D. Manning and Hinrich Schu?tze.
1999.Foundations of statistical natural language process-ing.
MIT Press, Cambridge, MA, USA.Christopher D. Manning, Prabhakar Raghavan, andHinrich Schu?tze.
2008.
Introduction to InformationRetrieval.
Cambridge University Press, New York,NY, USA.Andrew McCallum and Kamal Nigam.
1998.
A com-parison of event models for naive bayes text classifi-cation.
In Proceesings of the Workshop on learningfor text categorization, AAAI?98, pages 41?48.Quinn McNemar.
1947.
Note on the Sampling Errorof the Difference Between Correlated Proportions orPercentages.
Psychometrika, 12(2):153?157.7Hwee Tou Ng, Wei Boon Goh, and Kok Leong Low.1997.
Feature selection, perceptron learning, and ausability case study for text categorization.
In Pro-ceedings of the 20th annual international ACM SI-GIR conference on Research and development in in-formation retrieval, SIGIR ?97, pages 67?73, NewYork, NY, USA.
ACM.Kemal Oflazer.
1993.
Two-level description of Turk-ish morphology.
In Proceedings of the sixth con-ference on European chapter of the Association forComputational Linguistics, EACL ?93, pages 472?472, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.F.
Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,B.
Thirion, O. Grisel, M. Blondel, P. Pretten-hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-sos, D. Cournapeau, M. Brucher, M. Perrot, andE.
Duchesnay.
2011.
Scikit-learn: Machine learn-ing in Python.
Journal of Machine Learning Re-search, 12:2825?2830.Has?im Sak, Tunga Gu?ngo?r, and Murat Sarac?lar.
2007.Morphological disambiguation of Turkish text withperceptron algorithm.
In Proceedings of the 8thInternational Conference on Computational Lin-guistics and Intelligent Text Processing, CICLing?07, pages 107?118, Berlin, Heidelberg.
Springer-Verlag.Karl-Michael Schneider.
2005.
Techniques for im-proving the performance of naive bayes for textclassification.
In In Proceedings of CICLing 2005,pages 682?693.Sam Scott and Stan Matwin.
1998.
Text classificationusing WordNet hypernyms.
In Workshop: Usage ofWordNet in Natural Language Processing Systems,ACL?98, pages 45?52.James G. Shanahan and Norbert Roma.
2003.
Boost-ing support vector machines for text classificationthrough parameter-free threshold relaxation.
InProceedings of the twelfth international conferenceon Information and knowledge management, CIKM?03, pages 247?254, New York, NY, USA.
ACM.Karen Sparck Jones.
1988.
A statistical interpretationof term specificity and its application in retrieval.In Peter Willett, editor, Document retrieval systems,pages 132?142.
Taylor Graham Publishing, London,UK, UK.Yiming Yang and Xin Liu.
1999.
A re-examinationof text categorization methods.
In Proceedings ofthe 22nd annual international ACM SIGIR confer-ence on Research and development in informationretrieval, SIGIR ?99, pages 42?49, New York, NY,USA.
ACM.Yiming Yang and Jan O. Pedersen.
1997.
A compar-ative study on feature selection in text categoriza-tion.
In Proceedings of the Fourteenth InternationalConference on Machine Learning, ICML ?97, pages412?420, San Francisco, CA, USA.
Morgan Kauf-mann Publishers Inc.8
