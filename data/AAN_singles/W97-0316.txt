Lexicon Effects on Chinese Information RetrievalK.L.
KwokComputer  Sc ience Dept.,  Queens Col lege,  City Univers i ty  o f  NY ,Flushing, NY  11367, USA.kklqc @cunyvm.cuny .eduAbstractWe investigate the effects of lexicon size andstopwords on Chinese information retrievalusing our method of short-word segmentationbased on simple language usage rules andstatistics.
These rules allow us to employ asmall lexicon of only 2,175 entries and providequite admirable retrieval results.
It is noticedthat accurate segmentation is not essential forgood retrieval.
Larger lexicons can lead toincremental improvements.
The presence ofstopwords do not contribute much noise to IR.Their removal risks elimination of crucialwords in a query and adversely affect retrieval,especially when the queries are short.
Shortqueries of a few words perform more than 10%worse than paragraph-size queries.1 IntroductionIt is well known that a sentence in Chinese (or severalother oriental languages) consists of a continuousstring of 'characters' without delimiting white spacesto identify words.
In Chinese, the characters are calledideographs.
This makes it difficult to do machinestudies on these languages ince isolated words areneeded for many purposes, such as linguistic analysis,machine translation, etc.
Automatic methods forcorrectly isolating words in a sentence -- a processcalled word segmentation -- is therefore an importantand necessary first step to be taken before otheranalysis can begin.
Many researchers have proposedpractical methods to resolve this problem such as (Nieet al, 1995, Wu and Tsang, 1995, Jin & Chen, 1996,Ponte & Croft, 1996, Sproat et al, 1996, Sun et al,1997).Information retrieval (IR) deals with the problem ofselecting relevant documents for a user need that isexpressed in free text.
The document collection isusually huge, of gigabyte size, and both queries anddocuments are domain unrestricted and unpredictable.When one does IR in the Chinese language with itspeculiar property, then one would assume that accurateword segmentation is also a crucial first step beforeother processing can begin.However, in the recent 5th Text REtrievalConference (TREC-5) where a fairly large scaleChinese IR experiment was performed \[Kwok andGrunfeld, 199x\], we have demonstrated that a simpleword segmentation method, couple with a powerfulretrieval algorithm, is sufficient o provide quite goodretrieval results.
Moreover, experiments by othersusing even simpler bigram representation f text (i.e.all consecutive overlapping two characters), bothwithin and outside the TREC environment, alsoproduce good results \[Ballerini et al, 199x, Buckley etal., 199x, Chien, 1995, Liang et al, 1996\].
This is abit counter-intuitive b cause the bigram method leadsto three times as large an indexing feature spacecompared with our segmentation (approximately 1.5million vs 0.5 million), and one would expect hatthere are many random, non-content matchingsbetween queries and documents that may adverselyaffect precision.
Apparently, this is not so.
Based onthis observation, we made some adjustments to ourlexicon, and provide some experimental results of thelexicon effects on retrieval effectiveness.2 Short-Word SegmentationWhile word segmentation for linguistic analysis mayaim at the longest string that carry a specific semanticcontent, his may not be ideal for IR because one thenhas to deal with the problem of partial string matchingwhen a query term matches only part of a documentterm or vice versa.
Instead, we aim at segmentingtexts into short words of one to three characters longthat function like English content terms.
Our processis based on the following four steps A to D:A) facts - lookup on a manually created 2175-entrylexicon called L0.
This is small, consisting ofcommonly used words of 1 to 3 characters, with someproper nouns of size 4.
Each entry is tagged as 0(useful: total 1337), 1 (stopword: 671), s (symbol: 88),6 (numeric: 37), 4 (punctuation: 9), and 2 or 3 for therules below.
Other researchers have used lexicons ofhundreds of thousands.
We do not have such a largeresource; besides, maintenance of such a list is nottrivial.
We try to remedy this via rules.Given an input string, we scan left to right and141perform longest matching when searching on thelexicon.
Any match will result in breaking a sentenceinto smaller chunks of texts.
Fig.lb shows the resultof processing an original TREC query (Fig.la) afterour lexicon lookup process.B) rules - for performing further segmentation onchunks.
Words in any language are dynamic and onecan never capture 'all' Chinese words in a lexicon forsegmentation purposes.
We attempt to identify somecommon language usage ad-hoc rules that can beemployed to further split the chunks into short words.The rules that we use, together with their rationale andexamples and counter-examples are described below:below (ex.7-13).
When character p is tagged '2', wealso try to identify common words where p is used asa word in the construct yp, and these are entered intothe lexicon, yp may or may not be a stopword.
Thisway a string like ..ypx.. would be split 'yp x' ratherthan 'y px', dictionary entries being of higherprecedence.
This rule works in many cases, but webelieve that our list may be too long, and many wordsthat have content (such as ex.14-15) are stopped.Rule 3: xQ, where Q currently has only 2 specialcharacters, are stopwords for any x -- these are tagged'3' and is a complement to Rule 2 (see ex.16-19 andcounter-examples ex.20-21).Rule D (for double): any two adjacent similarcharacters xx are considered stopwords -- thisidentifies double same characters that are often used asadjectives or adverbs that do not carry much content(see ex.
1-3 below).
However, some Chinese names douse double same characters (ex.4) and we would 'stop'them wrong.
Other cases such as 'Japan Honshu'(ex.5), 'U.S.
Congress' (ex.6) requires splittingbetween the same two characters.
In these cases werely on 'Japan' or 'U.S.'
being on the lexicon andidentified first before applying this rule.Rule 3Examp 1 es:(16)(19)Counter-Examp les :(2e)   iP'il\](21)wetheythosemoI~teachersmore d i l igentRule DExamples:(1) ~ .
dai ly(z) slowly(3) ~ every uhereCounter-Examples:(4) ~ person name(5) H~21-~I Japan Honshu(e) u.s. congressRule 2: Px, where P is a small set of 31 specialcharacters, are stopwords for any x -- these charactersare tagged '2' in our lexicon and examples are shownRule 2Examples:(7) ~:~ a branch/stick of(8) - -~  early(9) - -~  together(18) (~,~)~ ( th is ,  that) kind(11) (~,~)~ ( th is ,  that) time(12) ~ consider to be(13) ~,,~.\]~.
in earnestCounter-Examples:(14) - - \ [ \ ]  one country(15) ~ admit mistakeRule E (for even): any remaining sequence of evennumber of characters are segmented two by two -- thisarises from the observation that 70-80% of Chinesewords are 2-characters long, and the rhythm ofChinese are often bi-syllable punctuated with mono-syllables and tri-syllables.
If one can identify wherethe single character words occur, the rest of the stringquite often can be split as such when it is even.
Thesesingle characters are often stopwords that hopefully arein our lexicon.
Examples 22 to 26 below show chunksthat are even, being surrounded by punctuation signsor stopwords.
They will be segmented correctly.Examples 27 to 29 show counter-examples with evennumber of characters that do not obey this rule.In addition, numeric entries are also removed asstopwords although one can often detect a sequence ofthem and have it identified as a number.C) frequency filter - after a first pass through thetest corpus via steps A and B, a list of candidate short-words will be generated with their frequency ofoccurrence.
A threshold is used to extract he mostcommonly occurring ones.
These are our new short-words that are 'data-mined' from the corpus itself.D) iteration - using the newly identified short-wordsof Step C all tagged useful for segmentation purposes,we expand our initial lexicon in step A and re-processthe corpus.
In theory, we could continue to iterate, butwe have only done one round.
With a frequencythreshold value in Step C of 30, a final lexicon size of15,234 called L01 was obtained.We believe the rules we use for Step B, though142Rule EExamp Ies:czz  .
.
t n1cz3  .
.
n1 1cz4) .
.
nczs  .
.
I1 1!!
1Coun~er-examp les :cz ) .
.simple, are useful.
They naturally do not work always,but may work correctly often enough for IR purposes.Fig.lc shows the results of processing the TREC-5query #28 based on these rules after Step A.Comparison with a manual short word segmentation fthe set of 28 TREC-5 queries shows that we achieve91.3% recall and 83% precision on average.
It ispossible that these queries are easy to segment.
Ourmethod of segmentation is certainly too approximatefor other applications such as linguistic analysis, text-to-speech, etc.
For IR, where the purpose is to detectdocuments with high probability of relevance ratherthan exact matching of meaning and is a moreforgiving environment, it may be adequate.
Besides,one also has other tools in IR to remedy the situation.These are discussed below.3 The Retr ieval  Env i ronmentOur investigations are based on the TREC-5 Chinesecollection of 24,988 Xinhua and 139,801 People'sDaily news articles totaling about 170 MB.
To guardagainst very long documents which can lead to outlierin frequency estimates, these are divided intosubdocuments of about 475 characters in size endingon a paragraph boundary.
This produces a total of247,685 subdocuments which are segmented into short-words as described in Section 2.
In addition, thesingle characters from each word of length two orgreater are also used for indexing purposes to guardagainst wrong segmentation.Provided with the TREC-5 collection are 28 verylong and rich Chinese topics, mostly on current affairs.They are processed like documents into queries.
Thesetopics representing user needs have also been manuallyjudged with respect o the (most fruitful part of the)collection at NIST so that a set of relevant documentsfor each query is known.
This allows retrieval resultsto be evaluated against known answers.For retrieval, we use our PIRCS (acronym forProbabilistic Indexing and Retrieval - Components -System) engine that has been documented elsewhere\[Kwok 1990,1995\] and has participated in the past fiveTREC experiments with admirable results \[see forexample Kwok & Grunfeld 1996\].
PIRCS is anautomatic, learning-based IR system that isconceptualized as a 3-layer network and operates viaactivation spreading.
It combines differentprobabilistic methods of retrieval that can account forlocal as well as global term usage evidence.
Ourstrategy for ad-hoc retrieval involves two stages.
Thefirst is the initial retrieval where a raw query is useddirectly.
The d best-ranked ocuments from thisretrieval are then regarded as relevant without userjudgment, and employed as feedback data to train theinitial query term weights and to add new terms to thequery - query expansion.
This process has been calledpseudo-feedback.
This expanded query retrieval thenprovides the final result.
This second retrieval ingeneral can provide substantially better esults than theinitial if the initial retrieval is reasonable and has somerelevants within the d best-ranked ocuments.
Theprocess is like having a dynamic thesaurus bringing insynonymous or related terms to enrich the raw query.As an example of a retrieval, we have shown inTable 1 comparing the TREC-5 Chinese experimentusing bigram representation with our method of textsegmentation i the PIRCS system.
The table is astandard for the TREC evaluation.
Precision is definedas the proportion of retrieved ocuments which arerelevant, and recall that of relevant documents whichare retrieved.
In general when more documents areretrieved, precision falls as recall increases.
It can beRepresent'n: Bigram Short-Word SegmTotal number of documents over all queriesRetrieved: 28000 28000Relevant: 2182 2182Rel_ret: 2125 2015Interpolated Recall - Precision Averages:at 0.10 0.6978 0.6521at 0.30 0.5428 0.5650at 0.50 0.4477 0.4716at 0.70 0.3688 0.3616at 0.90 0.2592 0.2493Average precision (non-interpolated) over0.4477 0.4516Precision At:5 docs: 0.6429 0.664310 does: 0.6036 0.600020 does: 0.5625 0.548230 does: 0.5214 0.5321100 does: 0.3796 0.3693all rel doesExact: 0.4557 0.4522Table 1: Bigram and Short-Word SegmentationRetrieval Results Averaged over 28 Queries143seen that the two methods provide quite similarperformance - bigram method ranks 2125 of the 2182known relevant documents within the first 1000retrieved for the 28 queries while the short-wordmethod has about 5% less, at 2015.
The latter has aslight edge in average precision (0.4516 vs 0.4477).Average precision is often used as a standard forcomparison.The precision at different number of documentsretrieved, a user-oriented measure, are also comparablein both cases.4 Lexicon Effects on RetrievalIn bigram representation f text, no lexicon is used andmany meaningless bigrams as well as many that aretrue stopwords are included.
Yet they do not seem toaffect retrieval effectiveness.
We take this as a cluethat stopword removal may not play an important rolein Chinese IR and lead us to investigate its effect.
Wealso like to see how lexicon size can affect retrieval.Usually one needs as large a dictionary as possible sothat many segmentation patterns are available for thesystem to select he correct one.An entry in our lexicon list can serve the purpose ofa segmentation marker or, in addition, for detection ofstopwords.
In our system stopwords can bedetermined in three ways based on: lexicon, rule orfrequency threshold (statistical).
The last categoryarises from Zipfian behavior of terms and is standardfor IR processing: features with frequencies that aretoo high or too low have adverse ffects on retrievaleffectiveness and efficiency.
This is done as a default,and is also performed for bigrams.Our lexicon-based stopwords consists of 671 entriesin our list tagged as '1'.
The major rule-basedstopword removal is Rule 2, while others have minoreffects because they occur much less often.
A runthrough the collection shows that the number of timestag 1 and Rule 2 were exercised are about 1.9m and2.1m.We have enabled Rules D and E, tags 0,3 and 4 tobe effective for segmentation as a default, and performexperiments where the lexicon (tag 1 & 6) and rule-based (Rule 2) stopword removal (and segmentation)can be activated or deactivated as follows:tag 1,6 Rule 2ExpTyp.1segment yes yes.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.ExpTyp.2stop & segm yessegment yes.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Exp'ryp.3stop & segm yessegment yes.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.ExpTyp.4stop & segm yes yesLexicon: < .
.
.
.
L0 .
.
.
.
> < .
.
.
.
L01 .
.
.
.
>ExpTyp: 1 2 3 4 5 1 2 3 4 5Total number of documents over all queriesRetrieved: < .....Relevant: < .....Rel_ret: 2059 2062 2047 204628000 ..... >2182 ..... >2013 2058 2060 2041 2040 2012Interpolated Recall-Precision Averages:.1 .688 .682 .699 .689 .671 .673 .676 .678 .675 .655.3 .557 .557 .555 .555 .549 .564 .563 .564 .568 .560.5 .467 .473 .470 .473 .466 .474 .481 .475 .483 .469.7 .375 .374 .373 .367 .356 .378 .376 .380 .376 .365~.9  .249 .253 .246 .239 .233 .252 .257 .250 .254 .246Average precision (non-interpolated) over all reldocs.455 .457 .456 .457 .448 .461 .462 .460 .460 .451Precision At:5 docs: .650 .657 .664 .650 .650 .664 .657 .664 .643 .68610 docs: .596 .589 .611 .611 .596 .593 .596 .621 .614 .60720 docs: .564 .559 .557 .561 .566 .555 .552 .554 .558 .55230does: .526 .533 .535 .537 .537 .531 .533 .525 .536 .535100docs: .373 .376 .372 .373 .368 .380 .377 .370 .371 .368Exact: .455 .465 .460 .463 .455 .453 .457 .462 .462 .452Table 2: Effect of Lexicon-based and Rule-based Stopwords on Long Query Retrieval using L0 & L01144For example, ExpTyp.2 means lexicon entries withtags 1,6 are used for segmentation ly, while thoseobeying Rule 2 serve to segment and removed as well.An ExpTyp.5 will be explained later.
Retrievals usinglexicons of four different sizes with long and shortversions of the TREC-5 queries were performed andevaluated.5 Results and Discussion5.1 Long QueriesTable 2 tabulates the precision and recall valuesaveraged over 28 long queries using L0, the 2175-entry and L01, the 15234-entry lexicons.
InExpTyp.
1 under L0 for example, where tags 1 & 6 aswell as Rule 2 are in effect for segmentation ly, anaverage precision of 0.455 and recall of relevants (at1000 retrieved) of 2059 out of 2182 are achieved.
Onaverage close to 5.96 out of the first 10 retrieveddocuments are relevant.
This is very goodperformance for a purely statistical retrieval system.It is also interesting to see that the small lexicon issufficient to yield this good result.
Indirectly, it showsthat our rule-based segmentation (Rule D, E, 2) candefine sufficiently good features for retrieval, andremedies our deficiency in lexicon size.
When bothtag 1,6 entries and Rule 2 are used for stopwordremoval (ExpTyp.4, L0), average precision remainspractically the same at 0.457.
Similarly for ExpTyps.2& 3 L0, where either Rule2 or tag 1,6 are used forstopword removal, effectiveness does not seem to altermuch.
Removal of tag 1,6 words however decreasesthe number of relevants lightly from 2060 to around2040.
It appears that the presence of stopwords havelittle effect on Chinese IR, just as noticed for bigrams.ExpTyp.5 L0 in Table 2 is included as ademonstration f the perils associated with stopwordremoval.
It shows about a 2% drop in averageprecision as well as in relevants retrieved comparedwith ExpTyp.4 L0 due to bad result of one singlequery.
Query #19 asks for documents on 'ProjectHope', and the Chinese query is shown below.
TheTI~EC-5 Chinese Querg 119::~'~C= hope);I~ (= project).~ , ~ I ~ ~~ ~ , ~ ~ ~~ ~ ~ I ~ .word 'hope' is often used in the context of 'We hopeto/that..' or 'My hope is ..' and quite non-contentbearing.
It is not unreasonable to regard it as astopword in both English and Chinese.
However, forthis query it is crucial.
ExpTyp.5 L0 is done under thesame circumstances a ExpTyp.4 L0 except hat theword 'hope' is changed to be a stopword (tag 1).
Thisquery then practically accounts for all the adverseeffect.
Since the presence of stopwords has beenshown to have a benign effect on Chinese retrieval, itappears advisable to keep them as indexing terms toguard against such unexpected results.In Table 2 under L01, we repeat the sameexperiments u ing our larger lexicon which is derivedfrom the collection using L0 as the basis.
It is seenthat the larger lexicon improves average precision byabout 1%, from around 0.456 to about 0.461.Otherwise, the two sets of experiments arequalitatively similar.
Since retrieval is cruciallydependent on how well the queries are processed, itappears that the 28 are well-prepared for retrievalusing the original 2175-entry lexicon.Recently, we further augment our L0 to a largerinitial lexicon L1 with 27,147 entries.
This derivesL11, a 42,822-entry lexicon from the collection basedon our segmentation procedure.
Results of repeatingthe retrieval experiments using these two largerlexicons are shown in Table 3.
There is incrementalimprovements in average precision by using the largerlexicon: e.g.
for ExpTyp.1, from 0.455 (L0) to 0.463(Lll), about 2%.
The removal of stopwords for L l l(ExpTyp.4 vs 1) does not lead to much difference,Le~con: <- L1 -> <- L l l  ->E~T~.
:  1 4 1 4 5Total number of documents over all queriesRetrieved: < .... .
.
28000 .... .
.
.
>Relevant: < ...... 2182 .... .
.
.
>Rel_ret: 2062 2056 2061 2056 2008In~rpolatedRecall-PrecisionAverages:at.1 .684 .673 .696 .695 .688at.3 .555 .553 .558 .567 .558at.5 .478 .475 .478 .479 .465.7 .381 .375 .384 .379 .358~.9  .254 .262 .256 .262 .247Average precision (non-interpol~ed) over all rel docs.460 .459 .463 .464 .451Precision At:5 docs: .650 .643 .671 .693 .69310 docs: .614 .604 .604 .611 .60720docs: .561 .555 .563 .550 .54330 docs: .529 .524 .525 .521 .516100 docs: .373 .373 .373 .374 .366Exact: .460 .466 .461 .468 .458Table 3: Effect of Lexicon-based and Rule-basedStopwords on Long Query Retrieval using L1 andL l l145but the peril of accidentally removing a crucial wordremains, leading again to about 2% drop ineffectiveness (ExpTyp.5 vs 4 L11).5.2 Shor t  Quer iesIt has been pointed out that the paragraph-sizeTREC queries are long and unrealistic because real-lifequeries are usually very short, like one or two words.One or two words, on the other hand, often do notsupply sufficient clues to a retrieval engine.
To studythe effects of lexicons on short queries, we furtherperform retrievals using only the first sentence of eachquery that belongs to the 'title' section of an originaltopic.
They average to a few short-words and we hopeto see more pronounced effects.
These results areshown in Table 4.As expected, retrieval effectiveness decreasessubstantially over 10% compared to the full lengthqueries: from around 0.463 to 0.409 (ExpTyp.1 L l l ,Tables 3&4).
The larger lexicon L11 also has an edgeover L0 (average precision 0.409 vs 0.398 Table 4),and the use stopwords (ExpTyp.4 vs 1 L l l )  canimprove precision as for long queries, but theaccidental removal of a crucial word can lead to amuch bigger adverse effect of 6% drop in averageprecision (ExpTyp.5 vs ExpTyp.4).
Especially hard hitis the number of relevants at 1000 retrieved, whichdecreases by 11% (1962 vs 1732).
The reason for thispronounced effect is that when a query is short (liketwo words 'Project Hope') and a crucial word (' Hope')is removed, what is left for retrieval is practicallyuseless.
In long queries however, many other termsare still available to remedy the removed crucial word,Lexicon: <- L0 .> <- L01 -> <- L1 -> <-- L l l  -->ExpTyp: 1 4 1 4 5 1 4 1 4 5Total number of documents over all queriesRetrieved: < .....Relevant: < .....Rei_ret: 1958 1929 1961 191428000 .... .
>2182 ... .
.
>1684 1970 1952 1975 1962 1732In~rpolated Recall-Precision Averages:~ .1  .608 .596 .609 .614 .579 .579 .578 .586 .605 .569.3 .502 .498 .500 .486 .456 .496 .495 .492 .493 .458m.5 .410 .409 .410 .415 .383 .420 .426 .427 .434 .402~.7  .336 .346 .345 .344 .321 .348 .349 .351 .355 .333.9 .217 .223 .227 .233 .232 .234 .235 .234 .241 .241Average precision (non-interpolated) over ai l reldocs.398 .405 .408 .407 .382 .405 .409 .409 .417 .391Precision At:5 does: .579 .550 .579 .564 .529 .586 .586 .593 .607 .57110 does: .534 .532 .568 .554 .518 .550 .554 .564 .571 .53620 does: .495 .496 .516 .502 .466 .488 .489 .488 .495 .45930 does: .466 .474 .481 .473 .437 .467 .464 .469 .475 .439100 does: .334 .336 .339 .335 .301 .330 .329 .333 .335 .301Exact: .403 .404 .406 .406 .381 .399 .405 .398 .409 .385Table 4: Effect of Lexicon-based and Rule-based Stopwords on Short Query Retrieval using L00, L01, L1& L l l .and the effect is less pronounced.6 Conc lus ionFor the TREC-5 Chinese collection of documents andqueries, it is found that a small 2175-lexicon coupledwith some simple linguistic rules is sufficient toprovide indexing features for good retrieval results.Larger lexicons can give incremental improvements.Lexicon or rule-based stopword removal havenegligible effect on retrieval with long queries.
Forshort queries with a large lexicon, stopwordelimination can lead to some improvements, but runsthe risks of accidentally deleting a crucial word in aquery that can adversely affect retrieval significantly.It appears advisable to keep all stopwords and usethem for segmentation purposes.
One needs onlyretain high and low frequency thresholds to screen outfrequency-based statistical stopwords.
Experimentationwith more varied queries is needed to verify thesefindings.1467 AcknowledgmentsThis work is partially supported by a Tipster grantfrom the U.S. Department ofDefense.
Xianlin Zhangand Jing Yan helped prepare the lexicons.ReferencesBuckley, C., Singhal, A & Mandar, M. 199x.
Usingquery zoning and correlation within SMART: TREC 5.In: The Fifth Text REtrieval Conference (TREC-5).Harman, D.K.
(Ed.).
To appear.Chien, L.F. 1995.
Fast and quasi-natural languagesearch for gigabytes of Chinese texts.
In: Proc.
18thACM SIGIR Conf.
on R&D in IR.
Fox, E., Ingwersen,P.
& Fidel, R.
(eds.)
ACM:NY, NY.
pp.l12-120.Jin W. & Chen, L. 1995.
Identify unknown words inChinese corpus.
In: Proc.
of 3rd NLP Pacific-RimSymposium (NLPRS'95).
Seoul, Korea.
Vol.
1, pp.234-9.Kwok, K.L.
& Grunfeld, L. 199x.
TREC-5 Englishand Chinese retrieval experiments u ing PIRCS.In: The Fifth Text REtrieval Conference (TREC-5).Harman, D.K.
(ed.).
To appear.Kwok, K.L.
1990.
Experiments with a componenttheory of probabilistic information retrieval based onsingle terms as document components.
ACMTransactions on Office Information Systems,8:363-386.Kwok, K.L.
1995.
A network approach toprobabilistic nformation retrieval.
ACM Transactionson Office Information Systems, 13:325-353.Liang, T, Lee, S.Y & Yang W,P.
1996.
Optimalweight assignment for a Chinese signature file.Information Processing & Management, 2:227-237.\[NiBR95\] Nie, J.Y, Hannan, ML & Jin, WY (1995).Unknown word detection and segmentation f Chineseusing statistical and heuristic knowledge\[PoCr96\] Ponte, J t~ Croft, W.B (1996).
USeg: aretargetable word segmentation procedure forinformation retrieval.
In: Symposium on documentanalysis and information retrieval (SDAIR '96).Sproat, R., Shih, C., Gale W. & Chang, N. 1996.
Astochastic finite-state word-segmentation algorithm forChinese.
Computational Linguistics, 22:377-404.Sun, M., Shen, D. & Huang, C. 1997.
CSeg&Tagl.0:A practical word segmenter & POS tagger for Chinesetexts.
In: Proc.
5th Conference on Applied NaturalLanguage Processing, Mar 31 - Apr 3, 1997. pp.119-124.Wu, Z & Tseng, G. 1995.
ACTS: An automaticChinese text segmentation system for full text retrieval.Journal of the American Society of InformationScience, 46:83-96.147(a) TREC-5 Chinese Query #Z8: The Spread of Cel lu la r  Phones in China~ J ~ ~ N ~  ?~ , ~ , ~ J ~ ,  R~,  ~ I~.~(b) In i t ia l  Segmentation using Lexicon LO only:1 1 44 4 4 4 Z0 8 4 0 40 1 1 1 00 1 411 4 1 1 4(c) Further Segmentation Result using Rule E:EEE E EEE E E EEF ig .
t (a -c ) :  R TREC-5 query and i t s  Processing by Lexicon and Rules148
