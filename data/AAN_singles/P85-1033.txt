A TOOL KIT FOR LEXICON BUILDINGThomas E. AhlswedeComputer Science DepartmentI l l inois Institute of TechnologyChicago, I l l inois 6e616, USAABSTRACTThis paper describes a set ofinteractive routines that can be used tocreate, maintain, and update a computerlexicon.
The routines are avai lable tothe user as a set of commands resembling asimple operating system.
The lexicon pro-duced by this system is based on lexi-cal-semantic relations, but is compatiblewith a variety of other models of lexiconstructure.
The lexicon builder is suit-able for the generation of moderate-sizedvocabularies and has been used toconstruct a lexicon for a small medicalexpert system.
A future version of thelexicon builder will create a much largerlexicon by parsing definit ions frommachine-readable dictionaries.INTRODUCTIONNatural language processing systemsneed much larger lexicons than thoseavailable today.
Furthermore, a good com-puter lexicon with semantic as well assyntactic information is elaborate andhard to construct.
We have created aprogram which enables its user to inter-actively build and extend a lexicon.
Theprogram sets up a user environment similarto a simple interactive operating system;in this environment lexical entries can beproduced through a small set of commands,combined with prompts specified by theuser for the desired kind of lexicon.The interactive lexicon builder isbeing used to help construct entries for alexicon to be used to parse and generatestroke case reports.
Many terms in thismedical sublanguage either do not appearin standard dictionaries or are used inthe sublanguage with special meanings.The design of the lexicon builder isinuended to be general enough to make ituseful for others building lexicons forlarge natural language processing systemsinvolving different sublanguages.The interactive lexicon bui lder wil lbe the basis for a fully automatic lexiconbuilder which uses Sager's Linguist icString Parser (LSP) to parse machine-readable text into a relational networkbased on a modif ied version of Werner'sNTQ (Modif ication-Taxonomy-Queueing)schema.
Initial ly this program will beappl ied to Webster's Seventh Col legiateDict ionary and the Longman Dict ionary ofContemporary English, both of which areavailable in machine-readable form.LEXICAL-SENANTIC RELATIONSThe semantic component of the lexiconproduced by this system consists princi-pally of a network of lexical-semanticrelations.
That is, the meaning of a wordin the lexicon is indicated as far aspossible by its relat ionships with otherwords.
These relations often have seman-tic content themselves and thus contributeto the definit ion of the words they link.The two most familiar such relationsare synonymy and antonymy, but others areinteresting and important.
For instance,to take an example from the vocabulary ofstroke reports, the carotid is a kind ofartery and an artery is a kind of bloodVessel.
This "is a kind of" relation istaxonomy.
We express the taxonomic rela-tions of "carotid', "artery" and "bloodvessel" with the relational arcscarotid T arteryartery T blood vesselAnother important relation is that ofthe part to the whole:ventricle PART heartBroca's area PART brainNote that taxonomy is transitive: ifthe carotid is an artery and an artery isa blood vessel, then the carotid is ablood vessel.
The presence or absence ofthe properties of transitivity, reflexiv-ity and symmetry are important in us ingrelations to make inferences.268The part-whole relation is morecomplicated than taxonomy in its proper-ties; some instances of it are transitiveand others are not.
From this and othercriteria, Iris et al (forthcoming)dist inguish four different part-wholerelations.Taxonomy and part-whole are verycommon relations, by no means restrictedto any particular sublanguage.
Sublan-guages may, however, use relations thatare rare or nonexistent in the generallanguage.
In the stroke vocabulary, thereare many words for pathological condit ionsinvolving the failure of some physical ormental function.
We have invented a rela-tion NNABLE to express the connectionbetween the condition and the function:aphasia NNABLE speechamnesia NNABLE memoryRelations such as T, PART, and NNABLEare especial ly useful in making infer-ences.
For instance, if we have anotherrelation FUNC, describing the typicalfunction of a body part, we might combinethe relational arcspeech FUNC Broca's areawith the arcaphasia NNABLE speechto infer that when aphasia is present, thediagnostician should check for the possl-bil ity of damage to Broca's area (as wellas to any other body part which has speechas a function).Figure i.
Part of a relational networkAnother kind of relation is the "col-locational relation', which governs thecombining of words.
These are particu-larly useful for generating idiomatictext.
Consider the "typical preposit ion"relation PREP:on PREP listwhich says that an item may be "on a list"as opposed to "in a list" or "at a list.
"Although the lexicon builder is basedon a relational model, it can be adaptedfor use in connection with a variety ofmodels of lexicon structure.
A semantic-field approach can be handled by the samemechanism as relations; the lexiconbuilder also recognizes unary attr ibutesof words, and these attr ibutes can betreated as semantic features if one wishesto build a feature-based lexicon.APPLICATIONS FOR THE LEXICON BUILDERThis project was motivated partly bytheoretical questions of lexicon designand partly by projects which required theuse of a lexicon.For instance, the Michael Reese Hos-pital Stroke Registry includes a textgeneration module powered by a relationallexicon (Evens et al, 1984).
This appli-cation provided a framework of goalswithin which the interactive lexiconbuilder was developed.
The vocabularyrequired for the Stroke Registry textgenerator is of moderate size, about 2000words and phrases.
This is small enoughthau a lexicon for it can be builtinteractively.One can imagine many applications fora large lexicon such as the automaticlexicon builder wil l  construct.
Questionanswering is one of our original areas ofinterest; a large, densely connectedvocabulary will greatly add to the varietyof inferences a question answering systemcan make.
Another area is information re-trieval, where experiments (Evens et al,forthcoming) have shown that the use of arelational thesaurus leads to improvementsin both recall and precision.On a more theoretical level, theautomatic lexicon builder will add greatlyto our understanding of sublanguages,notably that of the dictionary itself.
Wehave noted that a specialized relationsuch as NNABLE, unusual in the generallanguage, may be important in a sub-language.
We believe that such specificrelations are part of the distinctivecharacter of every sublanguage.
The verypossibi l i ty of creating a large, general-269language lexicon points toward a time whensublanguages will be obsolete for many ofthe purposes for which they are now used;but they will still be useful andinteresting for a long time to come, andthe automat ic  lexicon builder gives us anew tool for analyzing them.THE INTERACTIVE LEXICON BUILDERCommandsThe interactive lexicon builderconsists of an operat lng-system-l ikeenvironment in which the user may invokethe following commands:HELP displays a set of one-l inesummar ies  of the commands, or a paragraph-length description of a specif ied command.This paragraph describes the command-l inearguments, optional or required, for thegiven command, and briefly explains thefunction of the command.ADDENTRY provides a series of promptsto enable the user to create a lexicalentry.
Some of these prompts are hardcoded; others can be set up in advance bythe user so that the lexicon can betai lored to the user's needs.EDIT enables the user to modify anexisting entry.
It displays the existingcontents of the entry item by item,prompting for changes or additions.
Ifthe desired entry is not already in thelexicon, EDIT behaves in the same way asADDENTRY.DELETE lets the user delete one ormore entries.
An entry is not physical lydeleted; it is removed from the direc-tory, and all entries with arcs pointingto it are modif ied to el iminate thosearcs.
(This is simple to do, since forevery such arc there is an inverse arcpointing to that entry from the deletedone.)
On the next PACK operation (seebelow) the deleted entry will not bepreserved in the lexicon.This command can also be used todelete the defective entries that areoccasionally caused by unresolved bugs inthe entry-creating routines, or whichmight arise from other circumstances.
Aspecial option with this command searchesthe directory for a variety of "illegal"conditions such as nonprinting characters,zero-length names, etc.LIST gives one-line l istings of someor all of the entries in the lexicon.
Thelisting for each entry includes the name(the word itself), sense number, part ofspeech, and the first forty characters ofthe definit ion if there is one.SHOW displays the full contents ofone or more entries.RELATIONS displays a table of thelexical-semantic relations used by thelexicon builder.
This table is created bythe user in a separate operation.UNDEF is a special form of EDIT.
Increating an entry, the user may createrelational arcs from the current word toother words that are not in the lexicon.The system keeps a queue of undefinedwords.
UNDEF invokes EDIT for the word atthe head of the queue, thus saving theuser the trouble of looking up undefinedwords.PACK performs file management on thelexicon, sorting the entries and elimi-nating space left by deleted ones.This routine works in two passes.
Inthe first pass, the entries are copiedfrom the existing lexicon file to a newfile in lexicographic order and a table iscreated that maps the entries from theirold locations to their new ones.
At thisstage, a relational arc from one entry toanother still points to the other entry'sold location.
The second pass updates thenew lexicon, modifying all relational arcsto point to the correct new locations.QUIT exits from the lexicon builderenvironment.
Any new entries or changesmade during the lexicon building sessionare incorporated and the directory isupdated.Extensions to  the commandsAll of the commands can be abbrevi-ated; so far they all have dist inct iveinitials and can thus be called with asingle keystroke.Each command may be accompanied bycommand-l ine arguments to define its ac-tion more precisely.
Display commands,such as HELP or SHOW, allow the user toget a printout of the display.
Where anentry name is to be specified, the usercan get more than one entry by means of"wild cards."
For instance, the command"LIST produc= might yield a list showingentries for "produce', "produced", "pro-duces", "producing', "product', and"production.
~Additional commands are currentlybeing developed to help the user managethe relation table and the attr ibute listfrom within the lexicon builderenvironment.270The design of the user interface tookinto account both the available facil it iesand the expected users.
The lexiconbuilder runs on a VAX 11-75B, normallyaccessed with l ine-edlting terminals.This suggests that a single-l ine commandformat is most appropriate.
Since much ofthe work with the system is done over 3~0baud telephone lines, conciseness is alsoimportant.
The users have all had someprogramming experience (though not neces-sarily very much) so an operating-system-like interface is easy for them to getused to.
If the lexicon builder becomespopular, we hope to have the opportunityto develop a more sophist icated interface,perhaps with a combination of features forbeginners and more experienced users.Structure of a lexlcal entryA complete lexical entry consists of:i.
The "name" of the entry -- itscharacter-str ing form.2.
Its sense.
We represent sensesby simple numbers, not attempting toformally distinguish polysemy and homo-nymy, or any other degree of semanticdifference.
The system leaves to the userthe problem of dist inguishing differentsenses from extensions of a single sense:that is, where a word has already beenentered in some sense, the user mustdecide whether to modify the entry forthat sense or create a new entry for a newsense.3.
Part of speech, or "class."
Ourclassif ication of parts of speech isbasically the traditional classif icationwith some convenient additions, largelydrawn from the classif ication used bySager in the LSP (Sager, 1981).
Most ofthe additions are to the category ofverbs:  "verb" to the lexicon builder de-notes the stem form, while the thirdperson and past tense are dist inguished as" f in i te  verb', and the past and presentparticiples are classif ied separately.4.
The text of the definition,entered by the user.At th i s  stage in our work, thedefinit ion is not parsed or otherwise ana-lyzed, so its presence is more forpurposes of documentation than anythingelse.
In future versions of the lexiconbuilder, the definit ion will play animportant role in constructing the entrybut in the entry itself will be replacedby information derived from its analysis.5.
A list of attributes (or semanticfeatures), each with its value, which maybe binary or scalar.6.
A predicate calculus definition.For example, for the most common sense ofthe verb "promise', the predicate calculusdefinit ion is expressed aspromiseix,y,z) = say(x,w,z)_eventiy) => w = will happen(y)_thing(y) => w = will receive(z,y)or, in freer form,ix promises y to z} = ix says w to z)where w =(y will happen)if y is an event(z will receive y)if y is a physical object.This is entered by the user.We have been inclined to think of therelational lexicon as a network, since thenetwork representation vividly brings outthe interconnected quality which therelational model gives to the lexicon.Predicate calculus is better in otherrespects; for instance, it expresses theabove definit ion of "promise" much moreelegantly than any network notation could.The two methods of representation havetradit ionally been seen as alternativesrather than as supplementing each other;we believe that predicate calculus has animportant supplementary role to play indefining the core vocabulary of thelexicon, although we are not sure yet howto use it.7.
Case structure (for verbs).
Thisis a table describing, for each syntacticslot associated with the verb (subject,direct object, etc.)
the semantic case orcases that may be used in that slot('age,in, "experiencer', etc.
), whether itis required, optional, or may be expressedel l iptical ly (as with the direct andindirect object in "I promisei" referringto an earlier statement).Space is reserved in this structurefor selection restrictions.
A relationalmodel gives us the much more powerful op-tion of indicating through relations suchas "permissible subject', "permissibleobject', etc., not only what words may gowith what others, but whether the usage isliteral, a conventional figure of speech,fanciful, or whatever.
Selection restric-tions do, however, have the virtue ofconciseness, and they permit us to makegeneralizations.
Relational arcs may thenbe used to mark exceptions.8.
A list of zero or more relations,each with one or more pointers to otherentries, to which the current entry isconnected by that relation.271We find it convenient to treat mor-phological derivations such as plural ofnouns, tenses and part ic iples of verbs, asrelations connecting separate entries.The entry for a regularly derived formsuch as a noun plural is a minimal one,consisting of name, sense, part of speech,and one relational arc, l inking the entryto the stem form.
The lexicon buildergenerates these regular forms automati-cally.
It also dist inguishes these "regu-lar" entries from "undefined" entries,which have been entered indirectly astarget words of relational arcs and whichare on the queue accessed by UNDEF, aswell as from "defined" entries.namesenseclasstext ofdefinit ionattribute listpredicatecalculusdefinit ioncase structuretablere la t ion~listw2-I w2 1.2\[l :IFigure 2, Structure of a lexical entryFile structure of the lexiconThere are four data fileswi~h the lexicon.associatedThe first is the lexicon proper.
Thebiggest complicating factor in the designof the lexicon is the extremely inter-connected nature of the data; a change inone portion of the file may necessitatechanges in many other places in the file.Each entry is l inked through relationalarcs to many other entries; and for everyarc pointing from wordl to word2, theremust be an inverse arc from word2 towordl.
This means that whenever we createa new arc in the course of bui lding ormodifying an entry for wordl, we mustupdate the entry for word2 so that it wil lcontain the appropriate inverse arc backto wordl?
Word2~s entry has to be updatedor created from scratch; we need tostructure the lexicon file so that thisupdatin9 process, which may take placeanywhere in the file, can be done with theleast possible dislocation.aphasia (1) n.definitiona disorder of language due to injuryto the brainattr ibutesnonhumancol lectivepredicate calculushave(x, aphasia) -- "able(speak(x))relationsTAX\[aphasia is a kind of x\]deficitdisorderlossinabil ity"TAXIx is a kind of aphasia\]anomicglobalgerstmann ' ssemanticWe rnicke ' sSroca ' sconductiontranscorticalSYMPTOM\[aphasia is a symptom of x\]strokeTIAASSOC\[aphasia may be associated with x\]apraxia_CAUSE\[x is a cause of aphasia\]injurylesionNNABLE\[aphasia is the inabil ity to do x\]speechlanguageFigure 3.
Lexical entry for "aphasia"The size of an entry can varyenormously.
Regular derived forms containonly the name, sense, class and one rela-tional arc (to the stem form), as well asa certain amount of overhead for thedefinition, predicate calculus def init ionand attribute list although these are notused.
The smallest possible entry takesup about thirty bytes.
At the otherextreme, a word may have an extensiveattr ibute list, elaborate text  andpredicate calculus definit ions, and dozens272or even (eventually) hundreds of rela-tional arcs.
"Aphasia', a moderatelylarge entry with 19 arcs, occupies 322bytes.
Like all entries in the currentlexicon, it wil l be subject to updatingand will certainly become much larger.With this range of entry sizes, thechoice between fixed-size and variable-size records becomes somewhat painful.Variable-size records would be highlyconvenient as well as eff icient except forthe fact that when we add a new entry thatis related to existing entries, we mustadd new arcs to those entries.
Theexisting entries thus no longer fit intotheir previous space and must be eitherbroken up or moved to a new space.
Theformer option creates problems ofidentifying the various pieces of theentry; the latter requires that yet moreexisting entries be modified.Because of these problems, we haveopted for a fixed-size record.
Some spaceis wasted, either in empty space if therecord is too large or through prol i fera-tion of pointers if the record is toosmall; but the amount of necessary up-dating is much less, and the file can bekept in order through frequent use of thePACK command.
The choice of record sizeis conditioned by many factors, systemrequirements as well as the range of entrysizes.
We are currently working on deter-mining the best record size for the MRHapplication.So far the user does not have the op-tion of saving or rejecting the results ofa lexicon building session, since entriesare written to the file as soon as theyare created.
We are studying ways ofproviding this option.
A brute force waywould be to keep the entire lexicon inmemory and rewrite it at the end of thesession.
This is feasible if the hostcomputer is large and the lexicon issmall.
The 2~g0-word lexicon for theMichael Reese stroke database takes upabout a third of a megabyte, so thisapproach would work on a mainframe or alarge minicomputer such as our Vax 75g,but could not readily be ported to asmaller machine; nor could we handle amuch larger vocabulary such as we plan tocreate with the automatic lexicon builder.The second file is a directory,showing each entry's name, sense, andstatus (defined, undefined or regularderivauive), with a pointer to the appro-priate entry in the lexicon proper.
Thedirectory entries are linked in lexico-graphic order.
When the lexicon builderis invoked, the entire directory is readinto a buffer in memory, and this bufferis update~ as entries are created,modif ied or deleted.
At the end of alexicon building session, the updateddirectory is written out to disk.The third (optional) file is a tableof attributes, with pointers into thelexicon proper.
This can be extended intoa feature matrix.The fourth (also optional) is a tableof pre-defined relations.
This tableincludes, for each relation:(i) its mnemonic name.
(2) its properties.
A relation maybe reflexive, symmetric or transitive;there may be other properties worthincluding.
(3) a pointer to the relation'sinverse.
If x REL y, then we can definesome REL such that y REL x.
If REL isreflexive or symmetric, then REL = REL.
(4) the appropriate parts of speechfor the words linked by the relation.
Forinstance, the NNABLE relation links twonouns, while the col locational PREP rela-tion links a preposit ion to a noun.Taxonomy can link any two words (apartfrom prepositions, conjunctions, etc.)
aslong as they are of the same part ofspeech: nouns to nouns, verbs to verbs,etc .
(5) the text of a prompt.
ADDENTRYuses this prompt when querying the userfor the occurrence of relational arcsinvolving this relation.
For instance, ifwe are entering the word "promise" and ourapplication uses the taxonomy relation, wemight choose a short prompt, in which casethe query for taxonomy might take the form"promise" T: \[user enters word2 here\]or we could use something more explicit:"promise" is a kind of:Users familiar with lexical-semanticrelations might prefer the shortermnemonic prompt, whereas other users mightprefer a prompt that better expressed thesignif icance of the relation.THE AUTOMATIC LEXICON BUILDERBu i ld ing  a very  la rge  lex iconThere  are  numerous  log is t i ca l  p rob-lems in  imp lement ing  the  sor t  o f  very73large lexicon that would result from anal-ysis of an entire dictionary, as the workof Amsler and White (1979) or Kelly andStone (1975) shows.
Integrating thelexicon builder with the LSP, and writingpreprocessors for dictionary data, willalso be big jobs.
Fully automatic analy-sis of dictionary material, then, is along-range goal.A major problem in the relationalanalysis of the dictionary is that ofdetermining what relations to use.
Nounand verb definitions rely on taxonomh ~ to agreat extent (e.g.
Amsler and White,1979) but there are definitions that donot clearly fit this pattern; further-more, even in a taxonomic definition, muchsemantic information is contained in thequalifying or differentiating part of thedefinition.Adjective definitions are anotherproblem area.
Adjectives are usuallydefined in terms of nouns or verbs ratherthan other adjectives, so simple taxonomydoes not work neatly.
In a sample ofabout 7 ,0~ definitions from W7, weidentified nineteen major relations uniqueto adjective definitions, and thesecovered only half of the sample.
Theremaining definitions were much morevaried and would probably require far morethen nineteen additional relations.
Andfor each relation, we had to identifywords or phrases (the "defining formulas')that signaled the presence of therelation.The M'~ modelFor these reasons as well astheoretical ones, we need a simplifyingmodel of relations, a model that enablesus either to avoid the endless identifica-tion of new relations or to conduct theidentification within an orderly frame-work.
Werner's MTQ schema (Werner, 1978;Werner and Topper, 1976) seems to providethe basis for such a model.Werner idennifies only three rela-tions: modification, taxonomy and queue-ing.
He asserts that all other relationscan be expressed as compounds of theserelations and of lexical items -- forinstance, the PART relation can beexpressed, with the help of the lexicalitem "part', by the relational arcsBroca's area T partbrain M partwhich say in effect that Broca's area is akind of part, specifically a "brain-part.
"werner's concept of modification andtaxonomy reflects Aristotle's model of thedefinition as consisting of species, genusand differentiae -- taxonomy links thespecies to the genus and modificationlinks the differentiae to the genus.
Astudy of definitions in W7 and LDOCE showsthat they do indeed follow this pattern,although (as in adjective definitions) thepattern is not always obvious.The special power of MTQ in theanalysis of definitions is that in adefinition following the Aristotelianstructure, taxonomy and modification canbe identified by purely syntactic means.One (or occasionally more than one) wordin the definition is modified directly orindirectly by all the other words.
Thecore word is linked to the defined word bytaxonomy; all the others are linked tothe core word by modification.
(Queueingso far does not seem to be important inthe analysis of definitions.
)In order to avoid certain ambiguitiesthat arise in a very elaborate networksuch as that generated from a large dic-tionary, we have replaced the separatemodification and taxonomy arcs with asingle, ternary relational arc that keepsthe species, genus and differentiatingitems of any particular definition linkedto each other.The problem of identifying "higherlevel" relations such as PART and NNABLEin an MT0 network still remains.
At thispoint it seems to be similar to the prob-lem of identifying higher level relationsfrom defining formulas.Another pleasant discovery is thatthe Linguistic String Parser, which wehave used successfully for some years, isexceptionally well suited for this strat-egy, since it is geared toward an analysisof sentences and phrases in terms of"centers" or "cores" with their modifying"adjuncts', which is exactly the kind ofanalysis we need to do.Design of the automatic lexicon builderThe automatic lexicon builder willcontain at least the following suDsystems:I.
The standard data structure fo rthe lexical entry, as described for theinteractive lexicon builder, with slightchanges to adjust to the use of MTQ.The relation list is presentlystructured as a linked list of relations,each pointing to a linked list of wordis.
('Wordi" refers to any word related to the274word (=wordl') we are currently investi-gating.)
Incorporating the ternary MTQmodel, we would have two relation lists:a T list and an M list.
The T list wouldbe a linked list of words connected towordl by the T relation; its structurewould be identical to the present relationlist except that its nodes would belexical entry pointers instead of rela-tions.
Each of these lexical entry point-ers would, like the relation nodes in theexisting implementation, point to a linkedlist of word2s.
The word2s in the T listwould be connected to the T words by aninverse-modification relation ('M) and theword2s in the M list would be connected tothe M words by inverse taxonomy ('T).2.
Preprocessors to convert pre-existing data to the standard form.
Thepreprocessor need not be intelligent; itsjob is to identify and decode part-of-speech and other such information, sepa-rating this from the definition proper.Part of the preprocessing phase is togenerate a "dictionary" for the LSP.
Thisdictionary need only contain part-of-speech information for all the wordsthat will be used in definitions; otherinformation such as part- of-speechsubclass and selection restrictions ishelpful but not necessary.
Sager and herassociates (198B) have created programs todo this.3.
Batch and interactive inputmodules.
The batch input reads a datafile in standard form, perhaps optionallynoting where further information would beespecially desirable.
The interactiveinput is preserved from the interactiveversion of the system and allows the userto "improve" on dictionary data as well asto observe the results of the dictionaryparse.4.
Definition analyzer.
In thismodule, the LSP will parse the definitionto produce a parse tree.
which will thenbe converted into an MTQ network to belinked into the overall lexical network.5.
Entry generator.
This module,like the preprocessor, can be tailored tothe user's needs.SU~XA program has been written thatenables a user interested in creating alexicon for natural language processing togenerate lexical entries interactively andlink them automatically to other lexicalentries through lexical-semantic rela-tions.
The program provides a small setof commands that allow the user to create,modify, delete, and display lexicalentries, among other operations.The immediate motivation for theprogram was to produce a relationallexicon for text generation of clinicalreports by a diagnostic expert system.
Itis now being used for that purpose.
Itcan equally well be used in any other sub-language environment; in addition, it isintended to be compatible, as far aspossible, with models of lexicon structureother than the relational model on whichit is based.The interactive lexicon builder isfurther intended as the starting point fora fully automatic lexicon building programwhich will create a large, general purposerelational lexicon from machine readabledictionary text, using a slightly modifiedform of Werner's Modification-Taxonomy-Queueing relational model.REFERENCESAhlswede, Thomas E., and Evens, Martha W.,1983.
"Generating a Relational Lexiconfrom a Machine-Readable Dictionary.
"Proceedings of the Conference onArtificial Intelligence, Oakland Univer-sity, Rochester, Michigan.Ahlswede, Thomas E., and Evens, Martha W.,1984.
"A Lexicon for a Medical ExpertSystem."
Presented at the Workshop onRelational Models, Coling '84, StanfordUniversity, Palo Alto, California.Ahlswede, Thomas E., in press.
=A Lin-guistic String Grammar of AdjectiveDefinitions."
In S. Williams, ed.
Humansand Machines: The Interface ThroughLanguage, Ablex.Amsler, Robert A., and White, John S.,1979.
Development of a ComputationalMethodology for Deriving Natural LanguageSemantic Structures via Analysis ofMachine Readable Dictionaries.
Linguis-tics Research Center, University of Texas.Evens, Martha W., Ahlswede, Thomas E.,Hill, Howard, and Li, Ping-Yang, 1984.
"Generating Case Reports from the MichaelReese Stroke Database."
Proc.
1984Conference on Intelligent Systems andMachines, Oakland University, Rochester,Michigan, April.Evens, Martha W., Vandendorpe, James, andWang, Yih-Chen, in press.
"Lexical-Semantic Relations in Information Retriev-al," In S. Williams, ed.
Humans andMachines: The Interface Through Language,Ablex.275Iris, Madelyn, Litowitz, Bonnie, andEvens, Martha W., unpublished.
"ThePart-Whole Relation in the Lexicon: anInvestigation of Semantic Primitives.
"Kelly, Edward F., and Stone.
Philip J.,1975.
Computer Recognition of EnglishWord Senses.
North-Holland, Amsterdam.Sager, Naomi, 1981.Information Processing.New York.Natural LanguageAddison-Wesley,Sager Naomi, Hirschman, Lynette, White,Carolyn, Foster, Carol, Wolff, Susanne,Grad, Robert, and Fitzpatrick, Eileen,198~.
Research into Methods for AutomaticClassification and Fact Retrieval inScience Subfields.
String Reports No.13, New York University.Werne~, Oswald, 1978.
"The SyntheticInformant Model: the Simulation of LargeLexical/Semantic Fields."
In M. Loflinand J. Silverberg, eds., Discourse andDifference in Cognitive Anthropology.Mouton, The Hague.Warner, Oswald, and Topper, Martin D.,1976.
"On the Theoretical Unity ofEthnoscience Lexicography and EthnoscienceEthnographies."
In C. Rameh, ed., Seman-tics, Theory and Application, Proc.Georgetown University Round Table onLanguage and Linguistics.276
