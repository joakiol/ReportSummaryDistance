Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 257?266,Singapore, 6-7 August 2009. c?2009 ACL and AFNLPClustering to Find Exemplar Terms for Keyphrase ExtractionZhiyuan Liu, Peng Li, Yabin Zheng, Maosong SunDepartment of Computer Science and TechnologyState Key Lab on Intelligent Technology and SystemsNational Lab for Information Science and TechnologyTsinghua University, Beijing 100084, China{lzy.thu, pengli09, yabin.zheng}@gmail.com, sms@tsinghua.edu.cnAbstractKeyphrases are widely used as a briefsummary of documents.
Since man-ual assignment is time-consuming, vari-ous unsupervised ranking methods basedon importance scores are proposed forkeyphrase extraction.
In practice, thekeyphrases of a document should not onlybe statistically important in the docu-ment, but also have a good coverage ofthe document.
Based on this observa-tion, we propose an unsupervised methodfor keyphrase extraction.
Firstly, themethod finds exemplar terms by leverag-ing clustering techniques, which guaran-tees the document to be semantically cov-ered by these exemplar terms.
Then thekeyphrases are extracted from the doc-ument using the exemplar terms.
Ourmethod outperforms sate-of-the-art graph-based ranking methods (TextRank) by9.5% in F1-measure.1 IntroductionWith the development of Internet, information onthe web is emerging exponentially.
How to effec-tively seek and manage information becomes animportant research issue.
Keyphrases, as a briefsummary of a document, provide a solution to helporganize, manage and retrieve documents, and arewidely used in digital libraries and information re-trieval.Keyphrases in articles of journals and booksare usually assigned by authors.
However,most articles on the web usually do not havehuman-assigned keyphrases.
Therefore, automatickeyphrase extraction is an important research task.Existing methods can be divided into supervisedand unsupervised approaches.The supervised approach (Turney, 1999) re-gards keyphrase extraction as a classification task.In this approach, a model is trained to determinewhether a candidate term of the document is akeyphrase, based on statistical and linguistic fea-tures.
For the supervised keyphrase extractionapproach, a document set with human-assignedkeyphrases is required as training set.
However,human labelling is time-consuming.
Therefore, inthis study we focus on unsupervised approach.As an example of an unsupervised keyphraseextraction approach, the graph-based ranking (Mi-halcea and Tarau, 2004) regards keyphrase extrac-tion as a ranking task, where a document is repre-sented by a term graph based on term relatedness,and then a graph-based ranking algorithm is usedto assign importance scores to each term.
Existingmethods usually use term cooccurrences within aspecified window size in the given document as anapproximation of term relatedness (Mihalcea andTarau, 2004).As we know, none of these existing worksgives an explicit definition on what are appropri-ate keyphrases for a document.
In fact, the existingmethods only judge the importance of each term,and extract the most important ones as keyphrases.From the observation of human-assignedkeyphrases, we conclude that good keyphrasesof a document should satisfy the followingproperties:1.
Understandable.
The keyphrases are un-derstandable to people.
This indicates theextracted keyphrases should be grammatical.For example, ?machine learning?
is a gram-matical phrase, but ?machine learned?
is not.2.
Relevant.
The keyphrases are semanticallyrelevant with the document theme.
For ex-ample, for a document about ?machine learn-ing?, we want the keyphrases all about thistheme.3.
Good coverage.
The keyphrases should257cover the whole document well.
Sup-pose we have a document describing ?Bei-jing?
from various aspects of ?location?,?atmosphere?
and ?culture?, the extractedkeyphrases should cover all the three aspects,instead of just a partial subset of them.The classification-based approach determineswhether a term is a keyphrase in isolation, whichcould not guarantee Property 3.
Neither does thegraph-based approach guarantee the top-rankedkeyphrases could cover the whole document.
Thismay cause the resulting keyphrases to be inappro-priate or badly-grouped.To extract the appropriate keyphrases for a doc-ument, we suggest an unsupervised clustering-based method.
Firstly the terms in a document aregrouped into clusters based on semantic related-ness.
Each cluster is represented by an exemplarterm, which is also the centroid of each cluster.Then the keyphrases are extracted from the docu-ment using these exemplar terms.In this method, we group terms based on se-mantic relatedness, which guarantees a good cov-erage of the document and meets Property 2 and3.
Moreover, we only extract the keyphrases in ac-cordance with noun group (chunk) patterns, whichguarantees the keyphrases satisfy Property 1.Experiments show that the clustering-basedmethod outperforms the state-of-the-art graph-based approach on precision, recall and F1-measure.
Moreover, this method is unsupervisedand language-independent, which is applicable inthe web era with enormous information.The rest of the paper is organized as follows.In Section 2, we introduce and discuss the re-lated work in this area.
In Section 3, we give anoverview of our method for keyphrase extraction.From Section 4 to Section 7, the algorithm is de-scribed in detail.
Empirical experiment results aredemonstrated in Section 8, followed by our con-clusions and plans for future work in Section 9.2 Related WorkA straightforward method for keyphrase extrac-tion is to select keyphrases according to frequencycriteria.
However, the poor performance of thismethod drives people to explore other methods.
Apioneering achievement is carried out in (Turney,1999), as mentioned in Section 1, a supervised ma-chine learning method was suggested in this paperwhich regards keyphrase extraction as a classifi-cation task.
In this work, parameterized heuristicrules are combined with a genetic algorithm into asystem for keyphrase extraction.
A different learn-ing algorithm, Naive Bayes method, is applied in(Frank et al, 1999) with improved results on thesame data used in (Turney, 1999).
Hulth (Hulth,2003; Hulth, 2004) adds more linguistic knowl-edge, such as syntactic features, to enrich termrepresentation, which significantly improves theperformance.
Generally, the supervised methodsneed manually annotated training set, which maysometimes not be practical, especially in the webscenario.Starting with TextRank (Mihalcea and Tarau,2004), graph-based ranking methods are becom-ing the most widely used unsupervised approachfor keyphrase extraction.
The work in (Litvakand Last, 2008) applies HITS algorithm on theword graph of a document under the assumptionthat the top-ranked nodes should be the documentkeywords.
Experiments show that classification-based supervised method provides the highest key-word identification accuracy, while the HITS al-gorithm gets the highest F-measure.
Work in(Huang et al, 2006) also considers each documentas a term graph where the structural dynamics ofthese graphs can be used to identify keyphrases.Wan and Xiao (Wan and Xiao, 2008b) use asmall number of nearest neighbor documents toprovide more knowledge to improve graph-basedkeyphrase extraction algorithm for single docu-ment.
Motivated by similar idea, Wan and Xiao(Wan and Xiao, 2008a) propose to adopt cluster-ing methods to find a small number of similar doc-uments to provide more knowledge for buildingword graphs for keyword extraction.
Moreover,after our submission of this paper, we find thata method using community detection on seman-tic term graphs is proposed for keyphrase extrac-tion from multi-theme documents (Grineva et al,2009).
In addition, some practical systems, suchas KP-Miner (Elbeltagy and Rafea, 2009), alsodo not need to be trained on a particular human-annotated document set.In recent years, a number of systems are de-veloped for extracting keyphrases from web docu-ments (Kelleher and Luz, 2005; Chen et al, 2005),email (Dredze et al, 2008) and some other spe-cific sources, which indicates the importance ofkeyphrase extraction in the web era.
However,258none of these previous works has overall consid-eration on the essential properties of appropriatekeyphrases mentioned in Section 1.We should also note that, although the preci-sion and recall of most current keyphrase extrac-tors are still much lower compared to other NLP-tasks, it does not indicate the performance is poorbecause even different annotators may assign dif-ferent keyphrases to the same document.
As de-scribed in (Wan and Xiao, 2008b), when two anno-tators were asked to label keyphrases on 308 doc-uments, the Kappa statistic for measuring inter-agreement among them was only 0.70.3 Algorithm OverviewThe method proposed in this paper is mainly in-spired by the nature of appropriate keyphrasesmentioned in Section 1, namely understandable,semantically relevant with the document and highcoverage of the whole document.Let?s analyze the document describing ?Bei-jing?
from the aspects of ?location?, ?atmosphere?and ?culture?.
Under the bag-of-words assump-tion, each term in the document, except for func-tion words, is used to describe an aspect of thetheme.
Based on these aspects, terms are groupedinto different clusters.
The terms in the same clus-ter are more relevant with each other than withthe ones in other clusters.
Taking the terms ?tem-perature?, ?cold?
and ?winter?
for example, theymay serve the aspect ?atmosphere?
instead of ?lo-cation?
or some other aspects when talking about?Beijing?.Based on above description, it is thus reason-able to propose a clustering-based method forkeyphrase extraction.
The overview of the methodis:1.
Candidate term selection.
We first filter outthe stop words and select candidate terms forkeyphrase extraction.2.
Calculating term relatedness.
We use somemeasures to calculate the semantic related-ness of candidate terms.3.
Term clustering.
Based on term relatedness,we group candidate terms into clusters andfind the exemplar terms of each cluster.4.
From exemplar terms to keyphrases.
Fi-nally, we use these exemplar terms to extractkeyphrases from the document.In the next four sections we describe the algo-rithm in detail.4 Candidate Term SelectionNot all words in a document are possible to be se-lected as keyphrases.
In order to filter out the noisywords in advance, we select candidate terms usingsome heuristic rules.
This step proceeds as fol-lows.
Firstly the text is tokenized for English orsegmented into words for Chinese and other lan-guages without word-separators.
Then we removethe stop words and consider the remaining singleterms as candidates for calculating semantic relat-edness and clustering.In methods like (Turney, 1999; Elbeltagy andRafea, 2009), candidate keyphrases were firstfound using n-gram.
Instead, in this method, wejust find the single-word terms as the candidateterms at the beginning.
After identifying the ex-emplar terms within the candidate terms, we ex-tract multi-word keyphrases using the exemplars.5 Calculating Term RelatednessAfter selecting candidate terms, it is important tomeasure term relatedness for clustering.
In this pa-per, we propose two approaches to calculate termrelatedness: one is based on term cooccurrencewithin the document, and the other by leveraginghuman knowledge bases.5.1 Cooccurrence-based Term RelatednessAn intuitive method for measuring term relat-edness is based on term cooccurrence relationswithin the given document.
The cooccurrencerelation expresses the cohesion relationships be-tween terms.In this paper, cooccurrence-based relatedness issimply set to the count of cooccurrences within awindow of maximum w words in the whole doc-ument.
In the following experiments, the windowsize w is set from 2 to 10 words.Each document can be regarded as a word se-quence for computing cooccurrence-based relat-edness.
There are two types of word sequencefor counting term cooccurrences.
One is the origi-nal word sequence without filtering out any words,and the other is after filtering out the stop wordsor the words with specified part-of-speech (POS)tags.
In this paper we select the first type becauseeach word in the sequence takes important role formeasuring term cooccurrences, no matter whether259it is a stop word or something else.
If we filterout some words, the term relatedness will not beas precise as before.In experiments, we will investigate how thewindow size influences the performance ofkeyphrase extraction.5.2 Wikipedia-based Term RelatednessMany methods have been proposed for measuringthe relatedness between terms using external re-sources.
One principled method is leveraging hu-man knowledge bases.
Inspired by (Gabrilovichand Markovitch, 2007), we adopt Wikipedia, thelargest encyclopedia collected and organized byhuman on the web, as the knowledge base to mea-sure term relatedness.The basic idea of computing term related-ness by leveragting Wikipedia is to consider eachWikipedia article as a concept.
Then the se-mantic meaning of a term could be representedas a weighted vector of Wikipedia concepts, ofwhich the values are the term?s TFIDF within cor-responding Wikipedia articles.
We could com-pute the term relatedness by comparing the con-cept vectors of the terms.
Empirical evaluationsconfirm that the idea is effective and practicalfor computing term relatedness (Gabrilovich andMarkovitch, 2007).In this paper, we select cosine similarity, Eu-clidean distance, Point-wise Mutual Informationand Normalized Google Similarity Distance (Cili-brasi and Vitanyi, 2007) for measuring term relat-edness based on the vector of Wikipedia concepts.Denote the Wikipedia-concept vector of theterm tias Ci= {ci1, ci2, ..., ciN}, where N in-dicates the number of Wikipedia articles, and cikis the TFIDF value of wiin the kth Wikipedia ar-ticle.
The cosine similarity is defined ascos(i, j) =Ci?
Cj?Ci??Cj?
(1)The definition of Euclidean distance iseuc(i, j) =????N?k=1(cik?
cjk)2 (2)Point-wise Mutual Information (PMI) is a com-mon approach to quantify relatedness.
Here wetake three ways to measure term relatedness usingPMI.
One is based on Wikipedia page count,pmip(i, j) = log2N ?
p(i, j)p(i) ?
p(j)(3)where p(i, j) is the number of Wikipedia articlescontaining both tiand tj, while p(i) is the numberof articles which contain ti.
The second is basedon the term count in Wikipedia articles,pmit(i, j) = log2T ?
t(i, j)t(i) ?
t(j)(4)where T is the number of terms in Wikipedia,t(i, j) is the number of tiand tjoccurred adja-cently in Wikipedia, and t(i) is the number of tiinWikipedia.
The third one is a combination of theabove two PMI ways,pmic(i, j) = log2N ?
pt(i, j)p(i) ?
p(j)(5)where pt(i, j) indicates the number of Wikipediaarticles containing tiand tjas adjacency.
It is ob-vious that pmic(i, j) ?
pmip(i, j), and pmic(i, j)is more strict and accurate for measuring related-ness.Normalized Google Similarity Distance (NGD)is a new measure for measuring similarity betweenterms proposed by (Cilibrasi and Vitanyi, 2007)based on information distance and Kolmogorovcomplexity.
It could be applied to compute termsimilarity from the World Wide Web or any largeenough corpus using the page counts of terms.NGD used in this paper is based on Wikipedia ar-ticle count, defined asngd(i, j) =max(log p(i), log p(j)) ?
logp(i, j)logN ?
min(logp(i), logp(j))(6)where N is the number of Wikipedia articles usedas normalized factor.Once we get the term relatedness, we could thengroup the terms using clustering techniques andfind exemplar terms for each cluster.6 Term ClusteringClustering is an important unsupervised learningproblem, which is the assignment of objects intogroups so that objects from the same cluster aremore similar to each other than objects from dif-ferent clusters (Han and Kamber, 2005).
In thispaper, we use three widely used clustering algo-rithms, hierarchical clustering, spectral clusteringand Affinity Propagation, to cluster the candidateterms of a given document based on the semanticrelatedness between them.2606.1 Hierarchical ClusteringHierarchical clustering groups data over a varietyof scales by creating a cluster tree.
The tree is amultilevel hierarchy, where clusters at one levelare joined as clusters at the next level.
The hier-archical clustering follows this procedure:1.
Find the distance or similarity between everypair of data points in the dataset;2.
Group the data points into a binary and hier-archical cluster tree;3.
Determine where to cut the hierarchical treeinto clusters.
In hierarchical clustering, wehave to specify the cluster number m in ad-vance.In this paper, we use the hierarchical cluster-ing implemented in Matlab Statistics Toolbox.Note that although we use hierarchical clusteringhere, the cluster hierarchy is not necessary for theclustering-based method.6.2 Spectral ClusteringIn recent years, spectral clustering has become oneof the most popular modern clustering algorithms.Spectral clustering makes use of the spectrum ofthe similarity matrix of the data to perform dimen-sionality reduction for clustering into fewer di-mensions, which is simple to implement and oftenoutperforms traditional clustering methods such ask-means.
Detailed introduction to spectral cluster-ing could be found in (von Luxburg, 2006).In this paper, we use the spectral clustering tool-box developed by Wen-Yen Chen, et al (Chen etal., 2008) 1.
Since the cooccurrence-based termrelatedness is usually sparse, the traditional eigen-value decomposition in spectral clustering willsometimes get run-time error.
In this paper, weuse the singular value decomposition (SVD) tech-nique for spectral clustering instead.For spectral clustering, two parameters are re-quired to be set by the user: the cluster numberm, and ?
which is used in computing similaritiesfrom object distancess(i, j) = exp(?d(i, j)22?2) (7)where s(i, j) and d(i, j) are the similarity and dis-tance between i and j respectively.1The package could be accessed via http://www.cs.ucsb.edu/?wychen/sc.html.6.3 Affinity PropagationAnother powerful clustering method, AffinityPropagation, is based on message passing tech-niques.
AP was proposed in (Frey and Dueck,2007), where AP was reported to find clusters withmuch lower error than those found by other meth-ods.
In this paper, we use the toolbox developedby Frey, et al 2.Detailed description of the algorithm could befound in (Frey and Dueck, 2007).
Here we intro-duced three parameters for AP:?
Preference.
Rather than requiring prede-fined number of clusters, Affinity Propaga-tion takes as input a real number p for eachterm, so that the terms with larger p are morelikely to be chosen as exemplars, i.e., cen-troids of clusters.
These values are referredto as ?preferences?.
The preferences are usu-ally be set as the maximum, minimum, meanor median of s(i, j), i 6= j.?
Convergence criterion.
AP terminates if (1)the local decisions stay constant for I1itera-tions; or (2) the number of iterations reachesI2.
In this work, we set I1to 100 and I2to1, 000.?
Damping factor.
When updating the mes-sages, it is important to avoid numerical os-cillations by using damping factor.
Eachmessage is set to ?
times its value from theprevious iteration plus 1 ?
?
times its pre-scribed updated value, where the dampingfactor ?
is between 0 and 1.
In this paper weset ?
= 0.9.7 From Exemplar Terms to KeyphrasesAfter term clustering, we select the exemplarterms of each clusters as seed terms.
In AffinityPropagation, the exemplar terms are directly ob-tained from the clustering results.
In hierarchicalclustering, exemplar terms could also be obtainedby the Matlab toolbox.
While in spectral cluster-ing, we select the terms that are most close to thecentroid of a cluster as exemplar terms.As reported in (Hulth, 2003), most manuallyassigned keyphrases turn out to be noun groups.Therefore, we annotate the document with POS2The package could be accessed via http://www.psi.toronto.edu/affinitypropagation/.261tags using Stanford Log-Linear Tagger 3, and thenextract the noun groups whose pattern is zero ormore adjectives followed by one or more nouns.The pattern can be represented using regular ex-pressions as follows(JJ) ?
(NN |NNS|NNP )+where JJ indicates adjectives and various formsof nouns are represented using NN , NNS andNNP .
From these noun groups, we select theones that contain one or more exemplar terms tobe the keyphrases of the document.In this process, we may find single-wordkeyphrases.
In practice, only a small fraction ofkeyphrases are single-word.
Thus, as a part ofpostprocessing process, we have to use a frequentword list to filter out the terms that are too com-mon to be keyphrases.8 Experiment Results8.1 Datasets and Evaluation MetricThe dataset used in the experiments is a collec-tion of scientific publication abstracts from the In-spec database and the corresponding manually as-signed keyphrases 4.
The dataset is used in both(Hulth, 2003) and (Mihalcea and Tarau, 2004).Each abstract has two kinds of keyphrases: con-trolled keyphrases, restricted to a given dictionary,and uncontrolled keyphrases, freely assigned bythe experts.
We use the uncontrolled keyphrasesfor evaluation as proposed in (Hulth, 2003) andfollowed by (Mihalcea and Tarau, 2004).As indicated in (Hulth, 2003; Mihalcea andTarau, 2004), in uncontrolled manually assignedkeyphrases, only the ones that occur in the cor-responding abstracts are considered in evaluation.The extracted keyphrases of various methods andmanually assigned keyphrases are compared afterstemming.In the experiments of (Hulth, 2003), for her su-pervised method, Hulth splits a total of 2, 000 ab-stracts into 1, 000 for training, 500 for validationand 500 for test.
In (Mihalcea and Tarau, 2004),due to the unsupervised method, only the test setwas used for comparing the performance of Tex-tRank and Hulth?s method.3The package could be accessed via http://http://nlp.stanford.edu/software/tagger.shtml.4Many thanks to Anette Hulth for providing us the dataset.For computing Wikipedia-based relatedness,we use a snapshot on November 11, 2005 5.
Thefrequent word list used in the postprocessing stepfor filtering single-word phrases is also computedfrom Wikipedia.
In the experiments of this pa-per, we add the words that occur more than 1, 000times in Wikipedia into the list.The clustering-based method is completely un-supervised.
Here, we mainly run our method ontest set and investigate the influence of relatednessmeasurements and clustering methods with differ-ent parameters.
Then we compare our methodwith two baseline methods: Hulth?s method andTextRank.
Finally, we analyze and discuss the per-formance of the method by taking the abstract ofthis paper as a demonstration.8.2 Influence of Relatedness MeasurementsWe first investigate the influence of semantic re-latedness measurements.
By systematic experi-ments, we find that Wikipedia-based relatednessoutperforms cooccurrence-based relatedness forkeyphrase extraction, though the improvement isnot significant.
In Table 1, we list the perfor-mance of spectral clustering with various related-ness measurements for demonstration.
In this ta-ble, the w indicates the window size for countingcooccurrences in cooccurrence-based relatedness.cos, euc, etc.
are different measures for com-puting Wikipedia-based relatedness which we pre-sented in Section 5.2.Table 1: Influence of relatedness measurementsfor keyphrase extraction.Parameters Precision Recall F1-measureCooccurrence-based Relatednessw = 2 0.331 0.626 0.433w = 4 0.333 0.621 0.434w = 6 0.331 0.630 0.434w = 8 0.330 0.623 0.432w = 10 0.333 0.632 0.436Wikipedia-based Relatednesscos 0.348 0.655 0.455euc 0.344 0.634 0.446pmip0.344 0.621 0.443pmit0.344 0.619 0.442pmic0.350 0.660 0.457ngd 0.343 0.620 0.4425The dataset could be get from http://www.cs.technion.ac.il/?gabr/resources/code/wikiprep/.262We use spectral clustering here because it out-performs other clustering techniques, which willbe shown in the next subsection.
The results in Ta-ble 1 are obtained when the cluster number m =23n, where n is the number of candidate terms ob-tained in Section 5.
Besides, for Euclidean dis-tance and Google distance, we set ?
= 36 of For-mula 7 to convert them to corresponding similari-ties, where we get the best result when we conductdifferent trails with ?
= 9, 18, 36, 54, though thereare only a small margin among them.As shown in Table 1, although the method usingWikipedia-based relatedness outperforms that us-ing cooccurrence-based relatedness, the improve-ment is not prominent.
Wikipedia-based related-ness is computed according to global statistical in-formation on Wikipedia.
Therefore it is more pre-cise than cooccurrence-based relatedness, which isreflected in the performance of the keyphrase ex-traction.
However, on the other hand, Wikipedia-based relatedness does not catch the document-specific relatedness, which is represented by thecooccurrence-based relatedness.
It will be an in-teresting future work to combine these two typesof relatedness measurements.From this subsection, we conclude that, al-though the method using Wikipedia-based related-ness performs better than cooccurrence-based one,due to the expensive computation of Wikipedia-based relatedness, the cooccurrence-based one isgood enough for practical applications.8.3 Influence of Clustering Methods andTheir ParametersTo demonstrate the influence of clustering meth-ods for keyphrase extraction, we fix the relat-edness measurement as Wikipedia-based pmic,which has been shown in Section 8.2 to be the bestrelatedness measurement.In Table 2, we show the performance of threeclustering techniques for keyphrase extraction.For hierarchical clustering and spectral clustering,the cluster number m are set explicitly as the pro-portion of candidate terms n, while for AffinityPropagation, we set preferences as the minimum,mean, median and maximum of s(i, j) to get dif-ferent number of clusters, denoted as min, mean,median and max in the table respectively.As shown in the table, when cluster number mis large, spectral clustering outperforms hierarchi-cal clustering and Affinity Propagation.
AmongTable 2: Influence of clustering methods forkeyphrase extraction.Parameters Precision Recall F1-measureHierarchical Clusteringm =14n 0.365 0.369 0.367m =13n 0.365 0.369 0.367m =12n 0.351 0.562 0.432m =23n 0.346 0.629 0.446m =45n 0.340 0.657 0.448Spectral Clusteringm =14n 0.385 0.409 0.397m =13n 0.374 0.497 0.427m =12n 0.374 0.497 0.427m =23n 0.350 0.660 0.457m =45n 0.340 0.679 0.453Affinity Propagationp = max 0.331 0.688 0.447p = mean 0.433 0.070 0.121p = median 0.422 0.078 0.132p = min 0.419 0.059 0.103these methods, only Affinity Propagation undersome parameters performs poorly.8.4 Comparing with Other AlgorithmsTable 3 lists the results of the clustering-basedmethod compared with the best results reportedin (Hulth, 2003; Mihalcea and Tarau, 2004) onthe same dataset.
For each method, the table liststhe total number of assigned keyphrases, the meannumber of keyphrases per abstract, the total num-ber of correct keyphrases, and the mean number ofcorrect keyphrases.
The table also lists precision,recall and F1-measure.
In this table, hierarchicalclustering, spectral clustering and Affinity Propa-gation are abbreviated by ?HC?, ?SC?
and ?AP?respectively.The result of Hulth?s method listed in this ta-ble is the best one reported in (Hulth, 2003) on thesame dataset.
This is a supervised classification-based method, which takes more linguistic fea-tures in consideration for keyphrase extraction.The best result is obtained using n-gram as candi-date keyphrases and adding POS tags as candidatefeatures for classification.The result of TextRank listed here is the bestone reported in (Mihalcea and Tarau, 2004) on thesame dataset.
To obtain the best result, the authorsbuilt an undirected graph using window w = 2on word sequence of the given document, and ran263Table 3: Comparison results of Hulth?s method, TextRank and our clustering-based method.Assigned CorrectMethod Total Mean Total Mean Precision Recall F1-measureHulth?s 7,815 15.6 1,973 3.9 0.252 0.517 0.339TextRank 6,784 13.7 2,116 4.2 0.312 0.431 0.362HC 7,303 14.6 2,494 5.0 0.342 0.657 0.449SC 7,158 14.3 2,505 5.0 0.350 0.660 0.457AP 8,013 16.0 2,648 5.3 0.330 0.697 0.448PageRank on it.In this table, the best result of hierarchical clus-tering is obtained by setting the cluster numberm =23n and using Euclidean distance for comput-ing Wikipedia-based relatedness.
The parametersof spectral clustering are the same as in last sub-section.
For Affinity Propagation, the best resultis obtained under p = max and using Wikipedia-based Euclidean distance as relatedness measure.From this table, we can see clustering-based method outperforms TextRank and Hulth?smethod.
For spectral clustering, F1-measureachieves an approximately 9.5% improvement ascompared to TextRank.Furthermore, since the clustering-based methodis unsupervised, we do not need any set for train-ing and validation.
In this paper, we also carry outan experiment on the whole Hulth?s dataset with2, 000 abstracts.
The performance is similar tothat on 500 abstracts as shown above.
The bestresult is obtained when we use spectral clusteringby setting m = 23n with Wikipedia-based pmicrelatedness, which is the same in 500 abstracts.
Inthis result, we extract 29, 517 keyphrases, amongwhich 9, 655 are correctly extracted.
The preci-sion, recall and F1-measure are 0.327, 0.653 and0.436 respectively.
The experiment results showthat the clustering-based method is stable.8.5 Analysis and DiscussionsFrom the above experiment results, we can see theclustering-based method is both robust and effec-tive for keyphrase extraction as an unsupervisedmethod.Here, as an demonstration, we use spectral clus-tering and Wikipedia-based pmicrelatedness toextract keyphrases from the abstract of this pa-per.
The extracted stemmed keyphrases under var-ious cluster numbers are shown in Figure 1.
Inthis figure, we find that when m = 14n,13n,12n,the extracted keyphrases are identical, where theexemplar terms under m = 13n are marked inboldface.
We find several aspects like ?unsuper-vised?, ?exemplar term?
and ?keyphrase extrac-tion?
are extracted correctly.
In fact, ?clusteringtechnique?
in the abstract should also be extractedas a keyphrase.
However, since ?clustering?
istagged as a verb that ends in -ing, which disagreesthe noun group patterns, thus the phrase is notamong the extracted keyphrases.When m = 23n, the extracted keyphrasesare noisy with many single-word phrases.
Asthe cluster number increases, more exemplarterms are identified from these clusters, and morekeyphrases will be extracted from the documentbased on exemplar terms.
If we set the clusternumber to m = n, all terms will be selected asexemplar terms.
In this extreme case, all noungroups will be extracted as keyphrases, whichis obviously not proper for keyphrase extraction.Thus, it is important for this method to appropri-ately specify the cluster number.In the experiments, we also notice that frequentword list is important for keyphrase extraction.Without the list for filtering, the best F1-measurewill decrease by about 5 percent to 40%.
How-ever, the solution of using frequent word list issomewhat too simple, and in future work, we planto investigate a better combination of clustering-based method with traditional methods using termfrequency as the criteria.9 Conclusion and Future WorkIn this paper, we propose an unsupervisedclustering-based keyphrase extraction algorithm.This method groups candidate terms into clus-ters and identify the exemplar terms.
Thenkeyphrases are extracted from the document basedon the exemplar terms.
The clustering based onterm semantic relatedness guarantees the extractedkeyphrases have a good coverage of the document.Experiment results show the method has a good ef-264Figure 1: Keyphrases in stemmed form extractedfrom this paper?s abstract.Keyphrases when m = 14n,13n,12nunsupervis method; various unsupervis rankmethod; exemplar term; state-of-the-artgraph-bas rank method; keyphras; keyphrasextractKeyphrases when m = 23nunsupervis method; manual assign; brief sum-mari; various unsupervis rank method; exem-plar term; document; state-of-the-art graph-basrank method; experi; keyphras; import score;keyphras extractfectiveness and robustness, and outperforms base-lines significantly.Future work may include:1.
Investigate the feasibility of clustering di-rectly on noun groups;2.
Investigate the feasibility of combiningcooccurrence-based and Wikipedia-based re-latedness for clustering;3.
Investigate the performance of the method onother types of documents, such as long arti-cles, product reviews and news;4.
The solution of using frequent word listfor filtering out too common single-wordkeyphrases is undoubtedly simple, and weplan to make a better combination ofthe clustering-based method with traditionalfrequency-based methods for keyphrase ex-traction.AcknowledgmentsThis work is supported by the National 863 Projectunder Grant No.
2007AA01Z148 and the Na-tional Science Foundation of China under GrantNo.
60621062.
The authors would like to thankAnette Hulth for kindly sharing her datasets.ReferencesMo Chen, Jian-Tao Sun, Hua-Jun Zeng, and Kwok-YanLam.
2005.
A practical system of keyphrase extrac-tion for web pages.
In Proceedings of the 14th ACMinternational conference on Information and knowl-edge management, pages 277?278.Wen Y. Chen, Yangqiu Song, Hongjie Bai, Chih J. Lin,and Edward Chang.
2008.
Psc: Paralel spectralclustering.
Submitted.Rudi L. Cilibrasi and Paul M. B. Vitanyi.
2007.
Thegoogle similarity distance.
IEEE Transactions onKnowledge and Data Engineering, 19(3):370?383.Mark Dredze, Hanna M. Wallach, Danny Puller, andFernando Pereira.
2008.
Generating summary key-words for emails using topics.
In Proceedings of the13th international conference on Intelligent user in-terfaces, pages 199?206.S.
Elbeltagy and A. Rafea.
2009.
Kp-miner: Akeyphrase extraction system for english and arabicdocuments.
Information Systems, 34(1):132?144.Eibe Frank, Gordon W. Paynter, Ian H. Witten, CarlGutwin, and Craig G. Nevill-Manning.
1999.Domain-specific keyphrase extraction.
In Proceed-ings of the 16th International Joint Conference onArtificial Intelligence, pages 668?673.Brendan J J. Frey and Delbert Dueck.
2007.
Clusteringby passing messages between data points.
Science.E.
Gabrilovich and S. Markovitch.
2007.
Computingsemantic relatedness using wikipedia-based explicitsemantic analysis.
In Proceedings of the 20th Inter-national Joint Conference on Artificial Intelligence,pages 6?12.M.
Grineva, M. Grinev, and D. Lizorkin.
2009.
Ex-tracting key terms from noisy and multi-theme docu-ments.
In Proceedings of the 18th international con-ference on World wide web, pages 661?670.
ACMNew York, NY, USA.Jiawei Han and Micheline Kamber.
2005.
Data Min-ing: Concepts and Techniques, second edition.
Mor-gan Kaufmann.Chong Huang, Yonghong Tian, Zhi Zhou, Charles X.Ling, and Tiejun Huang.
2006.
Keyphrase extrac-tion using semantic networks structure analysis.
InProceedings of the 6th International Conference onData Mining, pages 275?284.Anette Hulth.
2003.
Improved automatic keyword ex-traction given more linguistic knowledge.
In Pro-ceedings of the 2003 conference on Empirical meth-ods in natural language processing, pages 216?223.A.
Hulth.
2004.
Reducing false positives by expertcombination in automatic keyword indexing.
Re-cent Advances in Natural Language Processing III:Selected Papers from RANLP 2003, page 367.Daniel Kelleher and Saturnino Luz.
2005.
Automatichypertext keyphrase detection.
In Proceedings of the19th International Joint Conference on Artificial In-telligence.265Marina Litvak and Mark Last.
2008.
Graph-basedkeyword extraction for single-document summariza-tion.
In Proceedings of the workshop Multi-sourceMultilingual Information Extraction and Summa-rization, pages 17?24.Rada Mihalcea and Paul Tarau.
2004.
Textrank:Bringing order into texts.
In Proceedings of the2004 Conference on Empirical Methods in NaturalLanguage Processing.Peter D. Turney.
1999.
Learning to Extract Keyphrasesfrom Text.
National Research Council Canada, In-stitute for Information Technology, Technical ReportERB-1057.U.
von Luxburg.
2006.
A tutorial on spectral clus-tering.
Technical report, Max Planck Institute forBiological Cybernetics.Xiaojun Wan and Jianguo Xiao.
2008a.
Col-labrank: Towards a collaborative approach to single-document keyphrase extraction.
In Proceedings ofCOLING, pages 969?976.Xiaojun Wan and Jianguo Xiao.
2008b.
Singledocument keyphrase extraction using neighborhoodknowledge.
In Proceedings of the Twenty-ThirdAAAI Conference on Artificial Intelligence, pages855?860.266
