QUANTITATIVE MODELING OF SEGMENTAL DURATIONJan P. H. van SantenAT&T Bel l  Laborator ies600 Mounta in  AvenueMurray  Hill, NJ  07974-0636,  U.S.A.ABSTRACTIn natural speech, durations of phonetic segments are strongly de-pendent on contextual factors.
Quantitative descriptions of thesecontextual effects have appfications in text-to-speech synthesis andin automatic speech recognition.
Inthis paper, we describe a speaker-dependent system for predicting segmental duration from text, withemphasis on the statistical methods used for its construction.
Wealso report results of a subjective listening experiment evaluating animplementation of this system for text-to-speech synthesis purposes.1.
INTRODUCTIONThis paper describes a system for prediction of segmentalduration from text.
In most text-to-speech synthesizer ar-chitectures, a duration prediction system is embedded in asequence of modules, where it is preceded by modules thatcompute various linguistic features ~from text.
For example,the word "unit" might be represented asa sequence of fivefeature vectors: (< At/, word - initial, monosyllabic,.. .
, >)? "
(< / t /~rs t ,  word-  final, monosyllabic, .
.
.
, >).
Inautomatic speech recognition, a (hypothesized) phone is usu-ally annotated only in terms of the preceding and followingphones.
If some form of lexical access is performed, morecomplete contextual feature vectors can be computed.Broadly speaking, construction ofduration prediction systemshas been approached in two ways.
One is to use general-purpose statistical methods uch as CART 2 or neural nets.
InCART, for example, a tree is constructed by making binarysplits on factors that minimize the variance of the durationsin the two subsets defined by the split \[2\].
These methods arecalled "general purpose" because they can be used across avariety of substantive domains.There also exists an older tradition exemplified by Klatt \[3,4, 5\] and others \[6, 7, 8, 9\] where duration is computed withduration models, i.e., simple arithmetic models specificallydesigned for segmental duration.
For example, in Klatt'slWe define a factor, FFi, to be a partition of mutually exclusive and ex-haustive possibilities such as {1-stressed, 2-stressed, unstressed}.
A featureis a "level" on a factor such as 1-stressed.
The feature space F is the productspace of all factors: Fl ?
-.
- ?
Fn.
Because of phonotactic and other con-straints, only a small fraction of this space can actually occur in a language;we call this the linguistic space.2Classification and Regression Trees \[1 \].model the duration for feature vector f E F is given byDUR(f) =S l , l ( f l )  X " ' "  X Sl,n-I- I(A-.
I - I)  -'\[- S2 ,n+l ( j~+1) -  ( i )Here, fj is the j-th component s of the vector f, the secondsubscript (j) in s~,j likewise refers to this component, and thefirst subscript (i) refers to the fact that the model consists oftwoproduct terms numbered 1 and 2.
The parameters si,./arecalled factor scales.
For example, Sl,l (stressed) = 1.40.All current duration models have in common that they (1) usefactor scales, and (2) combine the effects of multiple factorsusing only the addition and multiplication operations.
Thegeneral class of models defined by these two characteristics,sums-of-productsmodels, hasbeen found to have useful math-ematical and statistical properties \[10\].Briefly, here is how these two standard approaches comparewith ours.
We share with general-purpose statistical methodsthe emphasis on formal data analysis methods, and with theolder tradition the usage of sums-of-products models.
Ourapproach differs in the following respects.
First, although weconcur with the modeling tradition that segmental durationdata - and in particular the types of interactions one oftenfinds in these data - can be accurately described by sums-of-products models, this class of models is extremely large sothat one has to put considerable effort in searching for themost appropriate model.
4 The few models that this traditionhas generated make up a vanishingly small portion of a vastspace of possibilities, and because they have not been system-atically tested against hese other possibilities \[11\] we shouldconsider the search for better models completely open.
Sec-ond, in contrast with the general-purpose m thods approach,the process by which we construct our prediction system isnot a one-step rocedure but is a multi-step rocess with animportant role being played by various forms of exploratorydata analysis.3In its original form, the Klatt model uses p for the phonetic segmentfactor where we use fn+l.4For example, for two factors there are already five models: 81,1 x 81,2,81,1 + 82,2~ 81,1 X 81,2 --1- 82,1, 81,1 X 81,2 + 82,2, and81,1 X 81, 2 + 82,1 -.
{- 83,2 (note the use of subscdpts).3232.
PROPERTIES OF SEGMENTALDURATION DATAIn this section, we first discuss properties of segmental dura-tion data that pose serious obstacles for prediction, and nextproperties that may help in overcoming these obstacles.2.1.
Interactions between contextual factorsA first reason for duration prediction being difficult is thatsegmental duration is affected by many interacting factors.
Ina recent study, we found eight factors to have large effects onvowel duration \[12\], and if one were to search the literaturefor all factors that at least one study found to have statisticallysignificant effects the result would be a list of two dozen ormore factors \[13, 14, 15\].Segment/ s /  149/ f /  126/t/b~,~,t 71/P/bu,.,* 61/d/bu~t 12/b/bur,t 9/t/closure 75Iplczo,u,o 90/n /  63/m/  75Unstressed/ Stressed/Stressed UnstressedDiffer-ence112 37101 269 6218 437 58 120 5568 2239 2462 14Percent33257162386712274336222Table 1: Durations (in ms) of intervocalic conso-nants in two stress conditions: unstressed~stressed anstressed~unstressed.These factors interact in the quantitative s nse that the mag-nitude of an effect (in ms or in percent) is affected by otherfactors.
Table 1 shows durations of intervocalic consonantsin two contexts defined by syllabic stress: preceding vowelunstressed/following vowel stressed (Ifl in "before"); and:preceding vowel stressed/following vowel unstressed (/f/in"buffer"; It/is usually flapped in this context).
The Tableshows that the effects of stress are much larger for some con-sonants than for others: a consonant ?
stress interaction.Other examples of interactions include postvocalic onso-nant x phrasal position and syllabic stress ?
pitch accent\[121.These interactions imply that segmental duration can be de-scribed neither by the additive model \[9\] (because the differ-ences vary) nor by the multiplicative model \[7\] (because thepercentages vary)) In contrast, the Klatt model was specif-5In the additve model DUR(f)  = al,l ( f l )  + "'" + Sn,n(fn); in themulfiplicadve model DUR(f)  = sl, l  ( f l  ) ? "'"
?
Sl,n ( fn) .ically constructed todescribe certain interactions, in particu-lar the postvocalic consonant ?
phrasal position interaction.However, in an effort o use the Klatt model for text-to-speechsynthesis it became clear that this model needed significantmodifications todescribe interactions involving other factors\[5\].
Recent ests further confirmed systematic violations ofthe model \[11\].Thus, the existence of large interactions i undeniable, butcurrent sums-of-products models have not succeeded in cap-turing these interactions.
General-purpose prediction systemssuch as CART, of course, can handle arbitrarily intricate in-teractions \[16\].2.2.
Lopsided sparsityBecause there are many factors - several of which have morethan two values - the feature space is quite large.
The statis-tical distribution of the feature vectors exhibits an unpleasantproperty that we shall call "lopsided sparsity".
We mean bylopsided sparsity that the number of very rare vectors is solarge that even in small text samples one is assured to en-counter at least one of them.Sample Size Type Count Lowest TypeFrequency203205,12081,9201,310,72022,249,882182541,7675,70711,57617,54713<1<1<1<1Table 2: Type counts and lowest ype frequencies (per million)of contextual vectors for various ample sizes.Table 2 illustrates the concept.
We analyzed 797,524sentences, names, and addresses (total word token count:5,868,172; total segment count 22,249,882) by computingfor each segment the feature vector characterizing those as-pects of the context that we found to be relevant for segmentalduration.
This characterization is relatively coarse and leavesout many distinctions ( uch as - for vowel duration- the placeof articulation of post-vocalic consonants).
Nevertheless, thetotal feature vector type count was 17,547.
Of these 17,547types, about 10 percent occurred only once in the entire database and 40 percent occurred less than once in a million.Two aspects of the table are of interest.
The second columnshows that once sample size exceeds 5,000 the type count in-creases linearly with the logarithm of the sample size, with nosigns of deceleration.
In other words, although the linguisticspace is certainly much smaller than the feature space, it isunknown whether its size is 20,000, 30,000, or significantly324larger than that.
The third column shows that even in samplesas small as 320 segments (the equivalent of a small paragraph)one can be certain to encounter feature vectors that occur onlyonce in a million segment tokens.It is often suspected that general-purpose prediction systemscan have serious problems with frequency imbalance in thetraining set, in particular when many feature vectors are out-right missing.
Experiments performed with CART confirmedthis suspicion.
In a three-factor, 36-element feature space,with artificial durations generated by the Klatt model, wefound that removing 66 percent of the feature vectors from thetraining set produced a CART tree that performed quite poorlyon test data.
Similarly, neural nets can have the property thatdecision boundaries are sensitive to relative frequencies offeature vectors in the training sample (e.g., \[17\]), therebyleading to poor performance on infrequent vectors.The key reason for these difficulties is that the ability to ac-curately predict durations for feature vectors for which thetraining set provides few or no data points is a form of interpo-lation, which in turn requires assumptions about he generalform of the mapping from the feature space onto durations(the response surface).
Precisely because they are general-purpose, these methods make minimal assumptions about heresponse surface, which in practice often means that the dura-tion assigned to a missing feature vector is left to chance.
Forexample, in CART an infinitesimal disturbance an have a ma-jor impact on the tree branching pattern.
Even when this haslittle effect on the fit of the tree to the training data, it can havelarge effects on which duration is assigned to a missing fea-ture vector.
In subsection 2.4, we will argue that the responsesurface for segmental duration can be described particularlywell by sums-of-products models, so that these models areable to generate accurate durations for (near-) missing featurevectors.It should be noted that for certain applications, in particu-lar automatic speech recognition, poor performance on in-frequent feature vectors need not be critical because lexicalaccess can make up for errors.
Current implementations oftext-to-speech synthesis ystems, however, do not have errorcorrection mechanisms.
Having a seriously flawed segmentalduration every few sentences i not acceptable.2.3.
Text-independent variabilityA final complicating aspect of segmental duration is that,given the same input text, the same speaker (speaking at thesame speed, and with the same speaking instructions) pro-duces durations that are quite variable.
For example, wefound that vowel duration had a residual standard eviation of21.4 ms, representing about 15 percent of average duration.This means that one needs either multiple observations foreach feature vector so that statistically stable mean values canbe computed, or data analysis techniques that are relativelyinsensitive to statistical noise.In large linguistic spaces, text-independent variability impliesthat training data may require tens of thousands of sentences,even if one uses text selection techniques that maximize cov-erage such as greedy algorithms\[20\].
And even such textswill still contain serious frequency imbalances.2.4.
Ordinal patterns in dataA closer look at the interactions in Table 1 reveals that theyare, in fact, quite well-behaved, as is shown by the followingpatterns:Pattern 1.
The durations in the first column are always largerthan those in the second column.Pattern 2.
The effects of stress - whether measured as differ-ences or as percentages - are always larger for alveolars thanfor labials in the same consonant class (i.e., having the samemanner of production and voicing feature).Pattern 3.
Within alveolars and labials, the effects of stress(measured as differences) have the same order 6over conso-nant classes (voiceless top bursts largest, voiced stop burstssmallest).Pattern 4.
However, the order of the durations of the con-sonants is not the same in the two stress conditions.
Forexample, It/is longer than In/in the first column, but muchshorter in the second column.This pattern of reversals and non-reversals, or ordinal pattern,can be captured by the following sums-of-product model:DUR(C, P, S) =.~,,(c) x *~,2(e) x .~,3(s) + .2,~(c) x .2,2(P) (2)Here, C is consonant class, P place of articulation, and S stresscondition; it is assumed that factor scales have positive valuesonly.
It is easy to show that this model implies Patterns 1-3(for differences).
Pattern 4 is not in any way implied by themodel, but can be accommodated by appropriate selectionof factor scale values.
This accommodation would not bepossible if the second term had been absent.There are many other factors that exhibit similarly regular or-dinal patterns \[11, 12, 18\].
In general, factors often interact,but the interactions tend to be well-behaved so that the re-sponse surface can be described by simple sums-of-productsmodels.Now, showing that an ordinal pattern can be captured bya sums-of-products model does not imply that there aren'tmany other types of models that can accomplish the same.6Except for one minor reversal: 22 ms vs. 26 ms for /P \ [c losure vs. / f  \[.325Intuitiw~ly, itwould appear that ordinal patterns are not terriblyconstraining.
However, there exist powerful mathematicalresults that show this intuition to be wrong \[19\].
For example,there are results howing that if data exhibit a certain ordinalpattern then we can be assured that the additive model willfit.
Similar results have been shown for certain classes ofsums-of-products models (see \[19\], Ch.
7).
Taken togetherthese results make it quite plausible that when data exhibit hetypes of ordinal patterns often observed insegmental duration,some sums-of-products model will fit the data.To really make the case for the importance ofordinal patterns,we must make the further key assumption that the ordinal pat-terns of the response surface discovered in the training database can be feund in the language in general (restricted to thesame speaker and speaking mode).
This is based on the beliefthat the structure discovered in the data is the result of stableproperties of the speech production apparatus.
For example,the non-reversal ofthe syllabic stress factor can be linked to thesupposition that stressed syllables are pronounced with moresubglottai pressure, increased tension of the vocal chords, andlarger articulatory excursions than unstressed syllables.
Asystematic by-product of these differences would be a differ-ence in timing.3.
SYSTEM CONSTRUCTIONWe now describe construction ofa duration prediction systembased on sums-of-products models.3.1.
Training dataThe data base is described in detail elsewhere \[12\].
Amale American English speaker ead 2,162 isolated, short,meaningful sentences.
The utterances contained 41,588 seg-ments covering 5,073 feature vector types.
Utterances werescreened for disfluencies and re-recorded until none were ob-served.
The database was segmented manually aided by soft-ware which displays the speech wave, spectrogram, and otheracoustic representations.
Manual segmentation was highlyreliable, as shown by an average rror of only 3 ms (this wasobtained by having four segmentors independently segment aset of 38 utterances).3.2.
Category structureFirst, we have to realize that modeling segmental durationfor the entire linguistic space with a single sums-of-productsmodel is a lost cause because of the tremendous heterogeneityof this space in terms of articulatory properties and phoneticand prosodic environments.
For example, the factor "stressof the surrounding vowels" was shown to be a major factoraffecting durations of intervocalic consonants; however, thisfactor is largely irrelevant for the - barely existing - classof intervocalic vowels.
Thus, we have to construct a cate-gory structure, or tree, that divides the linguistic space intocategories and develop separate sums-of-products models forthese categories.
In our system, we first distinguish betweenvowels and consonants.
Next, for consonants, we distinguishbetween intervocalic and non-intervocalic consonants.
Non-intervocalic consonants are further divided into consonantsoccurring in syllable onsets vs. non-phrase-final syllable co-das vs. phrase-final syllable codas.
Finally, all of these aresplit up by consonant class.
Note that construction of thiscategory structure is not based on statistical analysis but onstandard phonetic and phonological distinctions.3.3.
Factor relevance and distinctionsFor each category (e.g., non-intervocalic voiceless top burstsin syllable onsets), we perform apreliminary statistical naly-sis to decide which factors are relevant and which distinctionsto make on these factors (see \[12\] for details).3.4.
Model selectionWe already hinted that the number of distinct sums-of-products models increases harply with the number of fac-tors; for example, for five factors there are more than 2 billionsums-of-products models, and for the eight factors we used formodeling vowel duration there are more than 1076 models.
7Thus, in cases with more than three or four factors it is com-putationally unattractive to fit all possible models and selectthe one that fits best.
Fortunately, there are methods that allowone to find the best model with far less computational effort\[10, 11\] - requiring only 31 analyses (each the computationalequivalent of an analysis of variance) for five factors.
Thesemethods are "diagnostiC' because they can detect trends in thedata that eliminate ntire classes of sums-of-products modelsfrom consideration.3.5.
Parameter estimationOnce a sums-of-products is selected, parameters are esti-mated with a weighted least-squares method using a simpleparameter-wise gradient technique.4.
RESULTS4.1.
Statistical fitForty-two sums-of-products models were constructed - onefor each "leaf" of the category tree.
Overall, 619 parameterswere estimated (32 for vowels, 196 for intervocalic conso-nants, and 391 for non-intervocalic consonants).
On average,each parameter was based on eight data points.The overall correlation (over all 41,588 segments) betweenobserved and predicted urations was 0.93 (0.90, 0.90, and0.87, when computed separately for vowels, intervocalic con-7The number of  distinct models converges to 2 2'~ -1 _ 1, where n is thenumber of factors.326sonants, and non-intervocalic consonants, respectively).When we computed average durations for each feature vec-tor in two equal-sized subsets of the data base, and estimatedparameters for the sums-of-products model for vowels sep-arately on each subset, the durations predicted from the twoparameter sets correlated 0.987.
Similarly, when we estimatedparameters from data obtained on a second (female) speaker,male durations (feature vector means) were predicted with acorrelation of 0.96.In addition to these correlational findings, we also found thatthe key interactions were mimicked closely by the predicteddurations (e.g., see Figs.
14-16 in \[12\]).4.2.
Text-to-speech synthesizer evaluationA new duration module for the AT&T Bell Laboratories text-to-speech synthesizer was written based on the 42 sums-of-products models and their parameter stimates.
We then com-pared the durations generated by the new module with thosegenerated by the old module in a subjective listening exper-iment using naive listeners (see \[20\] for details).
The oldmodule consists of a list of several hundred uration rulessimilar to, but somewhat simpler than, the Klatt rules \[5\].
Inthe experiment, a listener heard two versions of the same sen-tence, selected the preferred version, and indicated strengthof choice on a 1---6 scale (where 1 denotes complete indiffer-ence and 6 the strongest possible preference).
All listenerspreferred the new version.
Across listeners, the new versionwas preferred on 73 percent of the presentations (80 percentfor strength ratings of three or more).
On only one of the200 sentences was there a statistically significant majority oflisteners preferring the old version; on 81 percent of the sen-tences listeners preferred the new version- on 60 percent witha statistically significant majority.5.
DISCUSSIONThe approach taken in the paper aises some general issuesthat we want to briefly touch upon here.5.1.
"With Enough Data"A general theme in our approach to modeling segmental du-ration is that this domain has properties distinguishing it fromother domains and that this requires pecial-purpose methods.However, the ever-increasing amount of data that can be col-lected, processed, and stored, may lead one to believe thatin the near future general-purpose prediction systems will beable to outperform any special-purpose ystem - the "WithEnough Data" argument.
We submit hat this may rest on amisappreciation f the magnitude of sparsity encountered incertain linguistic spaces.
When a training set does not providea good number of data points for every feature vector in thelinguistic space, it is unclear how general-purpose methodscan be called upon to fill in the holes in the response surfacewithout making explicit assumptions about the phenomenabeing modeled, or, in other words, without de facto being aspecial-purpose system.5.2.
Manually vs. automatically generated seg-ment boundariesAlthough manually generated phoneme boundaries have somedegree of arbitrariness, there is enough overlap between var-ious conventions to produce a remarkable degree of consen-sus between durational findings obtained in different studies.However, automatic speech recognition systems often pro-duce phoneme boundaries that do not correspond to thoseproduced manually, which may lead to very different dura-tional behavior.
For example, we found in a sub-word unitbased system that vowels followed by/z /were quite short,whereas in manually segmented data such vowels tend to belong \[12\].
Apparently, the training algorithm achieved higherlikelihoods by putting the boundary well into the vowel.
Mis-matches uch as these make duration models based on manu-ally segmented data irrelevant for speech recognition.
Thus,either one has to develop models for these automatically gen-erated segment durations, or one has to constrain training al-gorithms to produce boundaries that correspond more closelyto those generated manually.5.3.
Segments vs. other unitsThe final issue concerns the use of segments vs. larger units,in particular syllables.
It has been suggested that not segmentsbut syllables hould play a central role in duration prediction\[21, 22\], the hypothesis being that speakers control durationsof syllables more carefully than the durations of the segmentsthat make up a syllable.
However, the following three consid-erations make this proposal somewhat less appealing.
First,in our factorial characterization f context, the role of thesyllable is as important as that of the segment or the word.To illustrate, we define within-word position in terms of syl-lables (and segments, but only to distinguish between openvs.
closed syllables), and within-phrase position in terms ofwords, syllables, and segments.Second, there are implications from research on sub-segmental timing effects \[23, 24, 25\].
An example of such aneffect is that the steady-state part of laY/expands much morethan the glide part (comparing "bite" with "bide"); in otherdiphthongs or in vowels, primarily the final part is stretched.Timing of some of these phenomena appears to be quite pre-cise: Gay \[23\] found near-identical formant velocities acrossthree different speaking rates.
These findings urge closescrutiny of the claim that larger units are timed with moreprecision than smaller units.
They also imply that whateverunit one selects for the lead role, timing must be specified ona fine, sub-segmental scale.327Third, il; is not clear how to explain the well-documented factthat phrasal position amplifies the effects of post-vocalic voic-ing on 'vowel duration.
In Campbell's \[21\] approach, eachsegment is characterized by a mean duration and an "elas-ticity" (variance) parameter to allow for some segments tobe stretched more than others when a syllable is stretchedby extra-syllabic factors.
Because elasticity is assumedto be a context-independent segmental parameter, it cannotexplain the amplification effect of phrasal position.
Al-though syllable-based conceptualizations other than Camp-bell's might be able to address this problem, the challenge ofhow to specify sub-syllabic timing within a syllabic frame-work is clearly a serious one.A possible resolution of the unit issue is that it may not needto be resolved.
The timing pattern of speech might be viewedas the resultant of multiple constraints - some computablelocally and others, say, at the paragraph level; some beinginescapable consequences of the physiology of the vocal tractand others under voluntary control.
These constraints couldbe embedded in a multi-level model where no unit or level ismore central than others, but where timing is computed on asub-segmental scale.It should also be understood that the very concept of unittacitly makes the concatenative assumption.
This assumptionis not shared by approaches based on asynchronous entitiessuch as feature bundles \[26\] or formant control parameters\[27\].
In these systems, at any point in time more than oneentity can be "on" and their on- and offsets need not coincide.References1.
Breiman, L., Friedman, J. H., Olshen, R. A., and Stone, C. J.,Classification and regression trees.
Wadsworth & Brooks,Monterey, CA, 1984.2.
Riley, M. D., "Tree-based modeling for speech synthesis", InG.
Bailly, C. Benoit, and T.R.
SawaUis, editors, Talking Ma-chines: Theories, Models, and Designs, pp.
265-273, Elsevier,Amsterdam, 1992.3.
Klatt, D. H., "Linguistic uses of segmental duration in English:Acoustic and perceptual evidence", Journal of the AcousticalSociety ofAmerica, Vol.
59, 1976, pp.
1209-1221.4.
Klatt, D. H. , "Review of text-to-speech conversion for En-glish", Journal of the Acoustical Society of America, Vol.
82(3),1987, pp.
737-793.5.
Allen, J., Hunnicut, S., and Klatt, D. H., From Text o Speech:The MITalk System.
Cambridge University press, Cambridge,U.K., 1987.6.
Coker, C. H., Umeda, N., and Browman, C. P., "Automaticsynthesis from ordinary English text", IEEE Transactions onAudio and Electroacoustics, AU-21 (3), 1973, pp.
293-298.7.
Lindblom, D., and Rapp, K., "Some temporal properties ofspoken Swedish", PILUS, Vol.
21, 1973, pp.
1-59.8.
Carlson, R. , "Duration models in use", In Proceedings ofthe XIIth Meeting, Aix-en-Provence, France.
InternationalCongress of Phonetic Sciences, 1991.9.
Kaiki, N., Takeda, K., and Sagisaka, Y., "Statistical analysisfor segmental duration rules in Japanese speech synthesis", InProceedings ICSLP '90, 1990, pp.
17-20.10. van Santen, J. P. H., "Analyzing n-way tables with sums-of-products models", Journal of Mathematical Psychology, Vol.37, 1993 (In press).11. van Santen, J. P. H., and Olive, J. P., "The analysis of con-textual effects on segmental duration", Computer Speech andLanguage, Vol.
4, 1990, pp.
359-391.12. van Santen, J. P. H., "Contextual effects on vowel duration",Speech Communication, Vol.
11, 1992, pp.
513-546.13.
Crystal, T. H. , and House, A. S., "Segmental durations inconnected-speech signals: Current results", Journal of theAcoustical Society of America, Vol.
83, 1988a, pp.
1553-1573.14.
Crystal, T. H. , and House, A. S., "Segmental durations inconnected-speech signals: Syllabic stress", Journal of theAcoustical Society of America, Vol.
83, 1988b, pp.
1574--1585.15.
Crystal, T. H. , and House, A. S. , 1990.
"Articulation rateand the duration of syllables and stress groups in connectedspeech", Journal of the Acoustical Society of America, Vol.
88,1990, pp.
101-112.16.
Hasfie, T. J., and Tibshirani, R. J., GeneralizedAdditive Mod-e/s.
Chapman and Hall, London, 1990.17.
Sabourin, M., and Mitiche, A., "Optical character recognitionby a neural network", Neural Networks, Vol.
5, 1992, pp.
843-852.18. van Santen, J. P. H., "Deriving text-to-speech durations fromnatural speech", In G. Bailly and C. Benoit, editors, TalkingMachines: Theories, Models, and Designs, pp.
275-285, Else-vier, Amsterdam, 1992.19.
Krantz, D. H.,  Lute, R. D. , Suppes, P. , and Tverskky, A. ,Foundations of Measurement, Vol.
L Wiley, New York, 1971.20. van Santen, J. P. H. , "Perceptual experiments for diagnos-tic testing of text-to-speech systems", Computer Speech andLanguage, Vol.
7, 1993 (In press).21.
Campbell, W. N. , "Syllable-based segmental duration", InG.
Bailly, C. Benoit, and T.R.
Sawallis, editors, Talking Ma-chines: Theories, Models, and Designs, pp.
211-224, Elsevier,Amsterdam, 1992.22.
Collier, R., "A comment on the prediction of prosody", InG.
Bailly, C. Benoit, and T.R.
Sawallis, editors, Talking Ma-chines: Theories, Models, and Designs, pp.
205-207, Elsevier,Amsterdam, 1992.23.
Gay' Th" ' "Effect ?f speaking rate ?n diphth?ng f?rmant m?ve-ments", Journal of the Acoustical Society of America, Vol.
44,t968, pp.
1570-1573.24.
Hertz, S. R., "Streams, phones and transitions: toward a newphonological nd phonetic model of formant timing", Journalof Phonetics, Vol.
19, 1991, pp.
91-109.25. van Santen, J. P. H., Coleman, J. C., and Randolph, M. A.,"Effects of postvocalic voicing on the time course of vowelsand diphthongs", J. Acoust.
Soc.
Am., Vol.
92(4, Pt.
2), 1992,pp.
2444.26.
Coleman, J.S., "Synthesis-by-rule" without segments ofrewrite-rules", In G. Bailly, C. Benoit, and T.R.
Sawallis, ed-itors, Talking Machines: Theories, Models, and Designs, pp.43-60, Elsevier, Amsterdam, 1992.27.
Stevens, K. N., and Bickley, C. A., "Constraints among param-eters simplify control of Klatt formant synthesizer", Journal ofPhonetics, Vol.
19, 1991, pp.
161-174.328
