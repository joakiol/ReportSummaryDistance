Proceedings of the Workshop on BioNLP: Shared Task, pages 119?127,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsSyntactic Dependency Based Heuristics for Biological Event ExtractionHalil Kilicoglu and Sabine BerglerDepartment of Computer Science and Software EngineeringConcordia University1455 de Maisonneuve Blvd.
WestMontre?al, Canada{h kilico,bergler}@cse.concordia.caAbstractWe explore a rule-based methodology for theBioNLP?09 Shared Task on Event Extrac-tion, using dependency parsing as the under-lying principle for extracting and characteriz-ing events.
We approach the speculation andnegation detection task with the same princi-ple.
Evaluation results demonstrate the util-ity of this syntax-based approach and point outsome shortcomings that need to be addressedin future work.1 IntroductionExponential increase in the amount of genomic datanecessitates sophisticated approaches to accessingknowledge in molecular biology literature, which re-mains the primary medium for disseminating newknowledge in molecular biology.
Extracting rela-tions and events directly from free text facilitatessuch access.
Advances made in foundational areas,such as parsing and named entity recognition, booststhe interest in biological event extraction (Zweigen-baum et al, 2007).
The BioNLP?09 Shared Task onEvent Extraction illustrates this shift and is likely toinform future endeavors in the field.The difficulty of extracting biological events fromscientific literature is due to several factors.
First,sentences are long and often have long-range depen-dencies.
In addition, the biological processes de-scribed are generally complex, involving multiplegenes or proteins as well as other biological pro-cesses.
Furthermore, biological text is rich in higherlevel phenomena, such as speculation and negation,which need to be dealt with for correct interpreta-tion of the text.
Despite all this complexity, how-ever, a closer look at various biological corpora alsosuggests that beneath the complexity lie regularities,which may potentially be exploited using relativelysimple heuristics.We participated in Task 1 and Task 3 of theShared Task on Event Extraction.
Our approachdraws primarily from dependency parse representa-tion (Mel?c?uk, 1988; deMarneffe et al, 2006).
Thisrepresentation, with its ability to reveal long-rangedependencies, is suitable for building event extrac-tion systems.
Dependencies typed with grammaticalrelations, in particular, benefit such applications.
Todetect and characterize biological events (Task 1),we constructed a dictionary of event triggers basedon training corpus annotations.
Syntactic depen-dency paths between event triggers and event partic-ipants in the training corpus served in developing agrammar for participant identification.
For specula-tion and negation recognition (Task 3), we extendedand refined our prior work in speculative languageidentification, which involved dependency relationsas well.
Our results show that dependency relations,despite their imperfections, provide a good founda-tion, on which accurate and reliable event extractionsystems can be built and that the regularities of bio-logical text can be adequately exploited with a lim-ited set of syntactic patterns.2 Related WorkCo-occurrence based approaches (Jenssen et al,2001; Ding et al, 2002) to biological relation ex-traction provide high recall at the expense of low119precision.
Shallow parsing and syntactic templates(Blaschke et al, 1999; Rindflesch et al, 2000; Fried-man et al, 2001; Blaschke and Valencia, 2001;Leroy et al, 2003; Ahlers et al, 2007), as well asfull parsing (Daraselia et al, 2004; Yakushiji et al,2005), have also been explored as the basis for re-lation extraction.
In contrast to co-occurrence basedmethods, these more sophisticated approaches pro-vide higher precision at the expense of lower recall.Approaches combining the strengths of complemen-tary models have also been proposed (Bunescu et al,2006) for high recall and precision.More recently, dependency parse representationhas found considerable use in relation extraction,particularly in extraction of protein-protein interac-tions (PPI).
Fundel et al (2007) use Stanford depen-dency parses of Medline abstracts as the basis forrules that extract gene/protein interactions.
Rinaldiet al (2007) extract relations combining a hand-written grammar based on dependency parsing witha statistical language model.
Airola et al (2008) ex-tract protein-protein interactions from scientific lit-erature using supervised machine learning based onan all-dependency-paths kernel.The speculative aspect of the biomedical literature(also referred to as hedging) has been the focus ofseveral recent studies.
These studies primarily dealtwith distinguishing speculative sentences from non-speculative ones.
Supervised machine learning tech-niques mostly dominate this area of research (Lightet al, 2004; Medlock and Briscoe, 2007; Szarvas,2008).
A more linguistically-based approach, rely-ing on lexical and syntactic patterns, has been ex-plored as well (Kilicoglu and Bergler, 2008).
Thescope of speculative statements is annotated in theBioScope corpus (Vincze et al, 2008); however, ex-periments in detecting speculation scope have yet tobe reported.Recognizing whether extracted events are negatedis crucial, as negation reverses the meaning of aproposition.
Most of the work on negation inthe biomedical domain focused on finding negatedterms or concepts.
Some of these systems arerule-based and rely on lexical or syntactic informa-tion (Mutalik et al, 2001; Chapman et al, 2001;Sanchez-Graillet and Poesio, 2007); while others(Averbuch et al, 2004; Goldin and Chapman, 2003)experiment with machine learning techniques.
A re-cent study (Morante et al, 2008) focuses on learn-ing negation scope using memory-based classifierstrained on the BioScope corpus.Our approach to Task 1 is most similar to workof Fundel et al (2007) as it builds on dependency-based heuristics.
However, we address a larger num-ber of event classes, including regulatory events al-lowing participation of other events.
In addition,event triggers are central to our approach, contrast-ing with their system and most other PPI systemsthat rely on finding dependency paths between enti-ties.
We extended prior work for Task 3 and obtainedstate of the art results.3 Event Detection and CharacterizationAs preparation for biological event extraction, wecombined the provided annotations, tokenized in-put and dependency parses in an XML representa-tion.
Next, we determined good trigger words forevent classes and scored them.
Finally, we devel-oped a dependency-based grammar for event partici-pant identification, which drives our event extractionsystem.3.1 Data PreprocessingOur event detection and characterization pipeline re-quires XML representation of a document as in-put.
Here, the XML representation of a documentcontains sentences, their offset positions and de-pendency parses as well as entities (Proteins) andtheir offset positions in addition to word information(tokens, part-of-speech tags, indexes and lemmas).We used the Stanford Lexicalized Parser (Klein andManning, 2003) to extract word-related information,as well as for dependency parsing.3.2 Event TriggersAfter parsing the training corpus and creating an en-riched document representation, we proceeded withconstructing a dictionary of event triggers, draw-ing from training corpus annotations of triggers andmaking further refinements, as described below.We view event triggers essentially as predicatesand thus restricted event triggers to words carryingverb, noun or adjective part-of-speech tags.
Ouranalysis suggests that, in general, trigger words withother POS tags are tenuously annotated event trig-gers and in fact require more context to qualify as120event triggers.
In Example (1), by is annotatedas trigger for a Positive regulation event;however, it seems that the meaning of the entireprepositional phrase introduced with by contributesto trigger such an event:(1) These data suggest a general role for Tax in-duction of IL-1alpha gene transcription by theNF-kappaB pathway.We refined the event trigger list further throughlimited term expansion and filtering, based on sev-eral observations:1.
The event triggers with prefixes, such asco, down and up, (e.g., coexpression, down-regulate) were expanded to include both hy-phenated and non-hyphenated forms.2.
For a trigger that has inflectional/derivationalforms acting as triggers in the development cor-pus but not in the training corpus, we addedthese forms as event triggers.
Examples includeadding dimerization after dimerize and dimin-ished(adj) after diminish, among others.3.
We removed several event triggers, which, weconsidered, required more context to qualifyas event triggers for the corresponding eventclasses.
(e.g., absence, absent, follow, lack)Finally, we did not consider multi-word eventtriggers.
We observed that core trigger meaninggenerally came from a single word token (gener-ally head of a noun phrase) in the fragment an-notated as event trigger.
For instance, for triggertranscriptional activation, the annotated event classis Positive regulation, which suggests thatthe head activation carries the meaning in this in-stance (since transcriptional is an event trigger forthe distinct Transcription event class).
In an-other instance, the trigger binding activity is anno-tated as triggering a Binding event, indicating thatthe head word activity is semantically empty.
Wenoted some exceptions to this constraint (e.g., neg-atively regulate, positive regulation) and dealt withthem in the postprocessing step.For the remaining event triggers, we computed a?goodness score?
via maximum likelihood estima-tion.
For a given event class C and event trigger t,the ?goodness score?
G(t,C) then is:G(t,C) = w(C:t)/w(t)where w(C:t) is the number of times t occurs as atrigger for event class C and w(t) is the frequencyof trigger t in the training corpus.
The newly addedevent triggers were assigned the same scores as thetrigger they are derived from.In the event extraction step, we do not considerevent triggers with a score below an empirically de-termined threshold.3.3 Dependency relations for event participantidentificationTo identify the event participants Theme and Cause,we developed a grammar based on the ?collapsed?version of Stanford Parser dependency parses ofsentences.
Grammar development was driven byextraction and ranking of typed dependency rela-tion paths connecting event triggers to correspond-ing event participants in the training data.
We thenanalyzed these paths and implemented as rules thosedeemed to be both correct and sufficiently general.More than 2,000 dependency paths were ex-tracted; however, their distribution was Zipfian, withapproximately 70% of them occurring only once.We concentrated on the most frequent, thereforegeneral, dependency paths.
Unsurprisingly, the mostfrequent dependency path involved the dobj (directobject) dependency between verbal event triggersand Theme participants, occurring 826 times.
Nextwas the nn (nominal modifier) dependency betweennominal event triggers and their Theme participants.The most frequent dependency for Cause partici-pants was, again unsurprisingly, nsubj (nominal sub-ject).
The ranking of dependency paths indicatedthat path length is inversely proportional to reliabil-ity.
We implemented a total of 27 dependency pathpatterns.Some of these patterns specifically address de-ficiencies of the Stanford Parser.
Prepositionalphrases are often attached incorrectly, causing prob-lems in participant identification.
Consider, for ex-ample, one of the more frequent dependency paths,dobj-prep on (direct object dependency followed byprepositional modifier headed in on), occurring be-tween the event trigger (effect) and participant (ex-pression, itself a sub-event trigger):(2) We have examined the effect of leukotriene B4121(LTB4), a potent lipid proinflammatory medi-ator, on the expression of the proto-oncogenesc-jun and c-fos.dobj(examined,effect)prep on(examined,expression)This dependency path occurs almost exclusivelywith PP attachment errors involving on, leading usto stipulate a ?corrective?
dependency path, imple-mented for certain trigger words (e.g., effect, influ-ence, impact in this case).
Postnominal preposi-tional attachment heuristics detailed in Schuman andBergler (2006) helped determine 6 such patterns.Two common verbs (require and involve) deservespecial attention, as the semantic roles of their sub-ject/object constituents differ from typical verbs.The prototypical Cause dependency, nsubj, indicatesa Theme in the following sentence:(3) Regulation of interleukin-1beta transcriptionby Epstein-Barr virus involves a number of la-tent proteins via their interaction with RBP.nsubj(involves,Regulation)For these two verbs, participant identification rulesare reversed.An interesting phenomenon is NPs with hyphen-ated adjectival modifiers, occurring frequently inmolecular biology texts (e.g., ?...
LPS-mediatedTF expression...?).
The majority of these cases in-volve regulatory events.
Such cases do not in-volve a dependency path, as the participant (inthis case, LPS) and the event trigger (mediated)form a single word.
An additional rule ad-dresses these cases, stipulating that the substringpreceding the hyphen is the Cause of the regu-latory event triggered by the substring followingthe hyphen.
(Positive regulation (Trig-ger=mediated,Theme=TF expression,Cause=LPS)).Events allowing event participants (regulatoryevents) are treated essentially the same way asevents taking entity participants.
The main differ-ence is that, when sub-events are considered, a de-pendency path is found between the trigger of themain event and the trigger of its sub-event, ratherthan an annotated entity, as was shown above in Ex-ample (2).3.4 Extracting EventsThe event detection and characterization pipeline(Task 1) consists of three steps:1.
Determining whether a word is an event trigger.2.
If the word is an event trigger, identifying itspotential participant(s).3.
If the event trigger corresponds to a regula-tory event and it has a potential sub-eventparticipant, determining in a recursive fashionwhether the sub-event is a valid event.The first step is a simple dictionary lookup.
Pro-vided that a word is tagged as noun, verb or adjec-tive, we check whether it is in our dictionary, and ifso, determine the event class for which it has a scoreabove the given threshold.
This word is consideredthe clue for an event.We then apply our dependency-based rules to de-termine whether any entity or event trigger (in thecase of regulatory events) in the sentence qualifiesas an argument of the event clue.
Grammar rules areapplied in the order of simplicity; rules that involvea direct dependency between the clue and any wordof the entity are considered first.Once a list of potential participants is obtainedby consecutive application of the rules, one oftwo things may happen: Provided that sub-eventsare not involved and appropriate participants havebeen identified (e.g., a Theme is found for aLocalization event), the event is simply addedto the extracted event list.
Otherwise, we proceedrecursively to determine whether the sub-event par-ticipant can be resolved to a simple event.
If thisyields no such simple event in the end, the event inquestion is rejected.
In the following example, theevent triggered by inhibit is invalid even though itsCause JunB is recognized, because its Theme, sub-event triggered by activation, cannot be assigned aTheme and therefore is considered invalid.
(4) ..., JunB, is shown to inhibit activation medi-ated by JunD.After events are extracted in this manner, twopostprocessing rules ensure increased accuracy.One rule deals with a limited set of multi-word event triggers.
If a Regulation event122has been identified and the event trigger ismodified by positive or negative (or inflec-tional forms positively, negatively), the eventclass is updated to Positive regulation orNegative regulation, respectively.
The sec-ond rule deals with the limitation of not allowingmultiple events on the same trigger and adds tothe extracted event list a Positive regulationevent, if a Gene expression event was recog-nized for certain triggers, including overexpressionand several others related to transfection (e.g., trans-fect, transfection, cotransfect).Two grammatical constructions are crucial to de-termining the event participants: coordination andapposition.
We summarize how they affect event ex-traction below.3.4.1 CoordinationCoordination plays two important roles in eventextraction:1.
When the event trigger is conjoined with an-other word token, dependency relations con-cerning the other conjunct are also consideredfor participant identification.2.
When an event is detected and its participantis found to be coordinated with other entities,new events are created with the event triggerand each of these entities.
An exception areBinding events, which may have multipleThemes.
In this case, we add conjunct entitiesas the Themes of the base event.Coordination between words is largely determinedby dependency relations.
The participants of a de-pendency with a type descending from conj (con-junct) are considered coordinated (e.g., conj and,conj or).Recognizing that Stanford dependency parsingmisses some expressions of coordinated entities typ-ical of biological text (in particular, those involvingparentheses), we implemented a few additional rulesto better resolve coordinated entities.
These rulesstipulate that entities that have between them:1.
Only a comma (,) or a semi-colon (;)2.
A word with CC (coordinating conjunction)part-of-speech tag3.
A complete parenthetical expression4.
Any combination of the aboveare coordinated.
For instance, in Example (5), werecognize the coordination between interleukin-2and IL-4, even though the parser does not:(5) The activation of NFAT by TCR signals hasbeen well described for interleukin-2 (IL-2)and IL-4 gene transcription in T cells.conj and(interleukin-2,transcription)3.4.2 AppositionWords in an apposition construction are con-sidered equivalent for event extraction purposes.Therefore, if an appropriate dependency exists be-tween a word and the trigger and the word is in ap-position with an entity, that entity is marked as theevent participant.
In Example 6, the appos (apposi-tive) dependency shown serves to extract the eventPositive regulation (Trigger=upregulation,Theme=intercellular adhesion molecule-1):(6) ... upregulation of the lung vascular adhesionmolecule, intercellular adhesion molecule-1,was greatly reduced by...appos(molecule,molecule-1)prep of(upregulation,molecule)The dependencies that we consider to encode ap-position constructions are: appos (appositive), ab-brev (abbreviation), prep {including, such as, com-pared to, compared with, versus} (prepositionalmodifier marked with including, such as, comparedto, compared with or versus).3.5 Speculation and Negation DetectionOnce an event list is obtained for a sentence,our speculation and negation module determineswhether these events are speculated and/or negated,using additional dependency-based heuristics thatconsider the dependencies between the event triggerand speculation/negation cues.3.5.1 Speculation RecognitionWe refined an existing speculation detection mod-ule in two ways for Task 3.
First, we noted thatmodal verbs (e.g., may) and epistemic adverbs (e.g.,probably) rarely mark speculative contexts in the123training corpus, demonstrating the lack of a stan-dardized notion of speculation among various cor-pora.
For Task 3, we ignored lexical cues in theseclasses completely for increased accuracy.
Sec-ondly, corpus analysis revealed a new syntactic pat-tern for speculation recognition.
This pattern in-volves the class of verbs that we called active cogni-tion verbs (e.g., examine, evaluate, analyze, study,investigate).
We search for a Theme dependencypattern between one of these verbs and an event trig-ger and mark the event as speculated, if such a pat-tern exists.
Nominalizations of these verbs are alsoconsidered.
In Example (7), the event triggered byeffects is speculated, since effects is the direct object(therefore, Theme) of studied:(7) We have studied the effects of prednisone(PDN), ... on the production of cytokines (IL-2,IL-6, TNF-alpha, IL-10) by peripheral T lym-phocytes...3.5.2 Negation DetectionNegation detection is similar to speculation detec-tion.
Several classes of negation cues have been de-termined based on corpus analysis and the negationmodule negates events if there is an appropriate de-pendency between one of these cues and the eventtriggers.
The lexical cues and the dependencies thatare sought are given in Table 1.Negation Cue Dependencylack, absence prep of(Cue,Trigger)unable, <not> able, fail xcomp(Cue,Trigger)inability, failure infmod(Cue, Trigger)no, not, cannot det(Trigger, Cue)Table 1: Negation cues and the corresponding depen-dencies (xcomp: clausal complement, infmod: infinitivalmodifier, det: determiner)Additionally, participation of event triggersin dependencies of certain types is sufficientfor negating the event it triggers.
Such depen-dency types are neg (negation) and conj negcc(negated coordination).
A neg dependency ap-plies to event triggers only, while conj negcc issought between event participants, as well asevent triggers.
Therefore, in Example (8), an event(Positive regulation(Trigger=transactivate,Theme: GM-CSF, Cause=ELF1)) is negated, basedon the dependencies below:(8) Exogenous ETS1, but not ELF1, can transacti-vate GM-CSF, ..., in a PMA/ionomycin depen-dent manner.conj negcc(ETS1, ELF1)nsubj(transactivate, ETS1)dobj(transactivate, GM-CSF)Finally, if none of the above applies and the wordpreceding the event trigger or one of the event partic-ipants is a negation cue (no, not, cannot), the eventis negated.4 Results and DiscussionOur event extraction system had one of the best per-formances in the shared task.
With the approxi-mate span matching/approximate recursive match-ing evaluation criteria, in Task 1, we were rankedthird, while our speculation and negation detectionmodule performed best among the six participatingsystems in Task 3.
Not surprisingly, our system fa-vors precision, typical of rule-based systems.
Fullresults are given in Table 2.The results reported are at goodness score thresh-old of .08.
Increasing the threshold increases preci-sion, while lowering recall.
The threshold was de-termined empirically.Our results confirm the usefulness of dependencyrelations as foundation for event extraction systems.There is much room for improvement, particularly interms of recall, and we believe that incremental na-ture of our system development accommodates suchimprovements fairly easily.Our view of event triggers (?once a trigger, alwaysa trigger?
), while simplistic, provides a good start-ing point by greatly reducing the number of triggercandidates in a sentence and typed dependencies toconsider.
However, it also leads to errors.
One suchexample is given in Example (9):(9) We show that ..., and that LPS treatment en-hances the oligomerization of TLR2.where we identify the event Binding (Trig-ger=oligomerization,Theme=TLR2).
We consideroligomerization a reliable trigger, since it occurstwice in the training corpus, both times as event trig-gers.
However, in this instance, it does not trigger124Event Class Recall Precis.
F-scoreLocalization 35.63 92.54 51.45Binding 20.46 40.57 27.20Gene expression 55.68 79.45 65.47Transcription 15.33 60.00 24.42Protein catabolism 64.29 56.25 60.00Phosphorylation 69.63 95.92 80.69EVT-TOTAL 43.10 73.47 54.33Regulation 24.05 45.75 31.53Positive regulation 28.79 50.45 36.66Negative regulation 26.65 51.53 35.13REG-TOTAL 27.47 49.89 35.43Negation 14.98 50.75 23.13Speculation 16.83 50.72 25.27MOD-TOTAL 15.86 50.74 24.17ALL-TOTAL 32.68 60.83 42.52Table 2: Evaluation resultsan event.
This narrow view also leads to recall er-rors, in which we do not recognize an event triggeras such, simply because we have not encountered itin the training corpus, or it does not have an appro-priate part-of-speech tag.
A more sophisticated trig-ger learning approach could aid in better detectingevent triggers.We dealt with some deficiencies of Stanford de-pendency parsing through additional rules, as de-scribed in Section 3.3.
However, many depen-dency errors are still generated, due to the com-plexity of biological text.
For instance, in Exam-ple (10), there is a coordination construction be-tween NF-kappaB nuclear translocation and tran-scription of E-selectin and IL-8.
However, this con-struction is missed and an erroneous prep of de-pendency is found, leading to two false positiveerrors: Localization (Trigger=translocation,Theme=E-selectin) and Localization (Trig-ger=translocation, Theme=IL-8).
(10) ... leading to NF-kappaB nuclear translocationand transcription of E-selectin and IL-8, whichresults in ...conj and(transcription, translocation)prep of(translocation, E-selectin)conj and(E-selectin, IL-8)These errors can be corrected via other ?corrective?dependency paths; however, first, a closer examina-tion of such error patterns is necessary.In other instances, the required dependency iscompletely missed by the parser, leading to recallerrors.
For instance, in Example (11), we are un-able to recognize two events (Regulation(Trigger=regulation, Theme=4E-BP1) andRegulation (Trigger=regulation, Theme=4E-BP2)), due to lack of apposition dependenciesbetween repressors and 4E-BP1 or 4E-BP2:(11) ... specific regulation of two repressors oftranslation initiation, 4E-BP1 and 4E-BP2.prep of(regulation,repressors)prep of(repressors, initiation)conj and(intiation, 4E-BP1)conj and(initiation, 4E-BP2)Typical of rule-base systems, we miss events ex-pressed using less frequent patterns.
Event partic-ipants expressed as prepositional modifiers markedwith from is one such case.
An example is givenbelow:(12) Calcineurin activates transcription from theGM-CSF promoter ...In this case, the event Transcription (Trig-ger=transcription, Theme=GM-CSF) is missed.
It isfairly easy to add a rule to address such occurrences.We have not attempted to resolve anaphoric ex-pressions for the shared task, which led to a fairnumber of recall errors.
In a similar vein, we ig-nored events spanning multiple sentences.
We ex-pect that several studies addressing anaphora res-olution in biomedical text (Castan?o et al, 2002;Gasperin and Briscoe, 2008) will inform our nearfuture efforts in this area.Evaluation results regarding Task 3 may seempoor at first; however, most of the errors concernmisidentified or missed base events.
Thus, in thissection, we focus on errors specifically triggered byspeculation and negation module.
In the develop-ment corpus, we identified 39 speculation instances,4 of which were errors due to speculation process-ing.
Of 95 annotated speculation instances, 7 weremissed due to deficiencies in speculation processing.125Similarly, negation processing led to 5 false posi-tives in 31 negation instances we identified and to 5false negatives in 107 annotated negation instances.We found that speculation false positive er-rors are exclusively cases for which speculationcould be argued.
For instance, in Example (13),we recognize that appears to scopes over eventNegative regulation (Trigger=negativelyregulate, Theme=IL-2R), rendering it speculative.However, it is not annotated as such.
This isfurther evidence for the difficulty of annotating suchphenomena correctly and consistently, since theexact meaning is somewhat elusive.
(13) An unidentified Ets family protein binds to theEBS overlapping the consensus GAS motif andappears to negatively regulate the human IL-2R alpha promoter.Negation pattern that involves negation cues(no,not,cannot) in the token preceding an event trig-ger or participant, a pattern initially considered toincrease recall, caused most of negation false posi-tive errors.
An example is given in (14):(14) The finding that HL-60/vinc/R cells respond toTPA with induction of a monocytic phenotype,but not c-jun expression, suggests that ...Complex and less frequent patterns of expressingspeculation and negation were responsible for morerecall errors.
Two such examples are given below:(15) (a) These results ... and suggest a molecularmechanism for the inhibition of TLR2 byDN variants.
(b) Galectin-3 is ... and is expressed in manyleukocytes, with the notable exception ofB and T lymphocytes.In (15a), speculation is detected; however, we areunable to recognize that it scopes over the eventtriggered by inhibition.
In (15b), the prepositionalphrase, with the notable exception, is not consideredto indicate negation.5 Conclusions and Future WorkWe explored a rule-based approach to biologicalevent detection driven by typed dependency rela-tions.
This study marks our first foray into bio-eventextraction in a general way and, thus, we considerthe results very encouraging.
In one area we investi-gated before, speculation detection, our system per-formed best and this confirms the portability and ex-tensibility of our approach.Modest recall figures point to areas of improve-ment.
We plan to address anaphora resolution andmultiple sentence spanning events in the near fu-ture.
Our na?
?ve approach to event triggers needsrefinement and we believe that sophisticated super-vised machine learning techniques may be helpful.In addition, biomedical lexical resources, includ-ing UMLS SPECIALIST Lexicon (McCray et al,1994), may be useful in improving event triggerdetection.
Finally, dependency relations based onthe Stanford Parser provided better performance inour case, in contrast to general consensus that thosebased on Charniak Parser (Charniak and Johnson,2005) are superior, and this, too, deserves further in-vestigation.ReferencesC B Ahlers, M Fiszman, D Demner-Fushman, F M Lang,and T C Rindflesch.
2007.
Extracting semantic predi-cations from Medline citations for pharmacogenomics.Pac Symp Biocomput, pages 209?220.A Airola, S Pyysalo, J Bjo?rne, T Pahikkala, F Ginter, andT Salakoski.
2008.
All-paths graph kernel for protein-protein interaction extraction with evaluation of cross-corpus learning.
BMC Bioinformatics, 9 Suppl 11:s2.M Averbuch, T Karson, B Ben-Ami, O Maimon, andL Rokach.
2004.
Context-sensitive medical informa-tion retrieval.
In Proc MEDINFO-2004, pages 1?8.C Blaschke and A Valencia.
2001.
The potential useof SUISEKI as a protein interaction discovery tool.Genome Inform, 12:123?134.C Blaschke, M A Andrade, C Ouzounis, and A Valencia.1999.
Automatic extraction of biological informationfrom scientific text: protein-protein interactions.
InProc Int Conf Intell Syst Mol Biol, pages 60?67.R Bunescu, R Mooney, A Ramani, and E Marcotte.
2006.Integrating co-occurrence statistics with informationextraction for robust retrieval of protein interactionsfrom Medline.
In Proc BioNLP Workshop on Link-ing Natural Language Processing and Biology, pages49?56.J Castan?o, J Zhang, and J Pustejovsky.
2002.
Anaphoraresolution in biomedical literature.
In Proc Interna-tional Symposium on Reference Resolution for NLP.126W W Chapman, W Bridewell, P Hanbury, G F Cooper,and B G Buchanan.
2001.
A simple algorithm foridentifying negated findings and diseases in dischargesummaries.
J Biomed Inform, 34(5):301?310.E Charniak and M Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminative reranking.
InProc 43rd Meeting of the Association for Computa-tional Linguistics, pages 173?180.N Daraselia, A. Yuryev, S Egorov, S Novichkova,A Nikitin, and I Mazo.
2004.
Extracting human pro-tein interactions from MEDLINE using a full-sentenceparser.
Bioinformatics, 20(5):604?611.M C deMarneffe, B MacCartney, and C D Manning.2006.
Generating typed dependency parses fromphrase structure parses.
In Proc 5th International Con-ference on Language Resources and Evaluation, pages449?454.J Ding, D Berleant, D Nettleton, and E Wurtele.
2002.Mining MEDLINE: abstracts, sentences, or phrases?Pac Symp Biocomput, 7:326?337.C Friedman, P Kra, M Krauthammer, H Yu, and A Rzhet-sky.
2001.
GENIES: a natural-langauge processingsystem for the extraction of molecular pathways fromjournal articles.
Bioinformatics, 17(1):74?82.K Fundel, R Ku?ffner, and R Zimmer.
2007.
RelEx re-lation extraction using dependency parse trees.
Bioin-formatics, 23(3):365?371.C Gasperin and T Briscoe.
2008.
Statistical anaphoraresolution in biomedical texts.
In Proc COLING 2008.I M Goldin and W W Chapman.
2003.
Learning to detectnegation with not in medical texts.
In Proc Workshopon Text Analysis and Search for Bioinformatics at the26th ACM SIGIR Conference.T K Jenssen, A Laegreid, J Komorowski, and E Hovig.2001.
A literature network of human genes for high-throughput analysis of gene expression.
Nat Genet,28:21?28.H Kilicoglu and S Bergler.
2008.
Recognizing specu-lative language in biomedical research articles: a lin-guistically motivated perspective.
BMC Bioinformat-ics, 9 Suppl 11:s10.D Klein and C D Manning.
2003.
Accurate unlexicalizedparsing.
In Proc 41th Meeting of the Association forComputational Linguistics, pages 423?430.G Leroy, H Chen, and J D Martinez.
2003.
A shallowparser based on closed-class words to capture relationsin biomedical text.
Journal of Biomedical Informatics,36:145?158.M Light, X Y Qiu, and P Srinivasan.
2004.
The languageof bioscience: facts, speculations, and statements inbetween.
In BioLINK 2004: Linking Biological Liter-ature, Ontologies and Databases, pages 17?24.A T McCray, S Srinivasan, and A C Browne.
1994.
Lex-ical methods for managing variation in biomedical ter-minologies.
In Proc 18th Annual Symposium on Com-puter Applications in Medical Care, pages 235?239.B Medlock and T Briscoe.
2007.
Weakly supervisedlearning for hedge classification in scientific literature.In Proc 45th Meeting of the Association for Computa-tional Linguistics, pages 992?999.I A Mel?c?uk.
1988.
Dependency syntax: Theory andPractice.
State University Press of New York, NY.R Morante, A Liekens, and W Daelemans.
2008.
Learn-ing the scope of negation in biomedical text.
In ProcConference on Empirical Methods in Natural Lan-guage Processing, pages 715?724.P G Mutalik, A Deshpande, and P M Nadkarni.
2001.Use of general-purpose negation detection to augmentconcept indexing of medical documents: A quantita-tive study using the UMLS.
J Am Med Inform Assoc,8(6):598?609.F Rinaldi, G Schneider, K Kaljurand, M Hess, C Andro-nis, O Konstandi, and A Persidis.
2007.
Mining ofrelations between proteins over biomedical scientificliterature using a deep-linguistic approach.
Artif.
In-tell.
Med., 39(2):127?136.T C Rindflesch, L Tanabe, J N Weinstein, and L Hunter.2000.
EDGAR: Extraction of drugs, genes, and rela-tions from the biomedical literature.
In Proc PacificSymposium on Biocomputing, pages 514?525.O Sanchez-Graillet and M Poesio.
2007.
Negation ofprotein protein interactions: analysis and extraction.Bioinformatics, 23(13):424?432.J Schuman and S Bergler.
2006.
Postnominal prepo-sitional phrase attachment in proteomics.
In ProcBioNLP Workshop on Linking Natural Language Pro-cessing and Biology, pages 82?89.G Szarvas.
2008.
Hedge classification in biomedicaltexts with a weakly supervised selection of keywords.In Proc 46th Meeting of the Association for Computa-tional Linguistics, pages 281?289.V Vincze, G Szarvas, R Farkas, G Mora, and J Csirik.2008.
The BioScope corpus: biomedical texts anno-tated for uncertainty, negation and their scopes.
BMCBioinformatics, 9 Suppl 11:S9.A Yakushiji, Y Miyao, Y Tateisi, and J Tsujii.
2005.Biomedical event extraction with predicate-argumentstructure patterns.
In Proc First International Sympo-sium on Semantic Mining in Biomedicine, pages 60?69.P Zweigenbaum, D Demner-Fushman, H Yu, and K BCohen.
2007.
Frontiers of biological text mining: cur-rent progress.
Briefings in Bioinformatics, 8(5):358?375.127
