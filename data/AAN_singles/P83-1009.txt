AN IMPROPER TREATMENT OF QUANTIFICATION IN ORDINARY ENGLISHJerry R. HobbsSRI InternationalMenlo Park, Californiai.
The ProblemConsider the sentenceIn most democratic countries most politicianscan fool most of the people on almost everyissue most of the time.In the currently standard ways of representingquantif ication in logical form, this sentence has120 different readings, or quantifier scopings.Moreover, they are truly distinct, in the sensethat for any two readings, there is a model thatsatisfies one and not the other.
With thestandard logical forms produced by the syntacticand semantic translation components of currenttheoretical frameworks and implemented systems, itwould seem that an inferencing component mustprocess each of these 120 readings in turn inorder to produce a best reading.
Yet it isobvious that people do not entertain all 120possibilities, and people really do understand thesentence.
The problem is not Just thatinferencing is required for disamblguation.
It isthat people never do dlsambiguate completely.
Asingle quantifier scoping is never chosen.
(VanLehn \[1978\] and Bobrow and Webber \[1980\] have alsomade this point.)
In the currently standardlogical notations, it is not clear how thisvagueness can be represented.
1What is needed is a logical form for suchsentences that is neutral with respect to thevarious scoplng possibilities.
It should be anotation that can be used easily by an inferenclngcomponent.
That is, it should be easy to definedeductive operations on it, and the lo~ical formsof typical sentences should not be unwieldy.Moreover, when the inferenclng component discoversfurther information about dependencies among setsof entities, it should entail only a minormodification in the logical form, such asconjoining a new proposition, rather than a majorrestructuring.
Finally, since the notion of"scope" is a powerful tool in semantic analysis,there should be a fairly transparent relationshipbetween dependency information In the notation andstandard representations of scope.Three possible approaches are ruled out bythese criteria.i.
Representing the sentence as adisjunction of the various readings.
This isimpossibly unwieldy.I Many people feel that most sentences exhibit toofew quantifier scope ambiguities for much effortto be devoted to this problem, but a casualinspection of several sentences from any textshould convince almost everyone otherwise.2.
Using as the logical notation a tripleconsisting of an expression of the propositionalcontent of the sentence, a store of quantif ierstructures (e.g., as in Cooper \[1975\], Woods\[19781), and a set of constraints on how thequantifier structures could be unstored.
Thiswould adequately capture the vagueness, but it isdifficult to imagine defining inference proceduresthat would work on such an object.
Indeed, Cooperdid no inferenclng; Woods did little and chose adefault reading heuristically before doing so.3.
Using a set-theoretlc notation like thatof (I) below, pushing all the universalquantifiers to the outside and the existentialquantifiers to the inside, and replacing theexistentially quantified variables by Skolemfunctions of all the universally quantlf~edvariables.
Then when inferencing discovers anondependency, one of the arguments is droppedfrom one of the Skolem functions.
One difficultywith this is that it yields representations thatare too general, being satisfied by models thatcorrespond to none of the possible intendedinterpretations.
Moreover, in sentences in whichone quantified noun phrase syntactically embedsanother (what Woods \[1978\] calls "functionalnesting"), as inEvery representative of a company arrived.no representation that is neutral between the twois immediately apparent.
With wide scope, "acompany" is existential, with narrow scope it isuniversal, and a shift in commitment from one tothe other would involve significant restructuringof the logical form.The approach taken here uses the notion ofthe "typical element'" of a set, to produce a flatlogical form of conjoined atomic predications.
Atreatment has been worked out only for monotoneincreasing determiners; this is described inSection 2.
In Section 3 some ideas about otherdeterminers are discussed.
An inferenclngcomponent, such as that explored in Hobbs \[1976,1980\], capable of resolving coreference, doingcoercions, and refining predicates, will beassumed (but not discussed).
Thus, translatingthe quantifier scoping problem into one of thosethree processes will count as a solution for thepurposes of this paper.This problem has received little attention inlinguistics and computational linguistics.
Thosewho have investigated the processes by which arich knowledge base is used in interpreting textshave largely ignored quantifier ambiguities.Those who have studied quantifiers have generallynoted that inferencing is required for57disambiguation, without attempting to provide anotation that would accommodate this inferencing.There are some exceptions.
Bobrow and Webber\[1980\] discuss many of the issues involved, but itis not entirely clear what their proposals are.The work of Webber \[1978\] and Melllsh \[1980\] arediscussed below.2.
Monotone I~creasin~ Determiners2.1.
A Set-Theoretic NotationLet us represent the pattern of a simpleintransit ive sentence with a quantif ier as "Q PsR".
In '~ost men work," Q - "most", P = "man",and R - "work".
Q wil l  be referred to as adeterminer.
A determiner Q is monotone increasingif and only if for any RI and R2 such that thedenotation of R1 is a subset of the denotation ofR2, "Q Ps RI" implies "Q Ps R2" (Barwlse andCooper \[1981\]).
For example, letting RI - "workhard" and R2 = "work", since "most men work hard"implies "most men work," the determiner "most" ismonotone increasing.
Intuitively, making the verbphrase more general doesn't change the truthvalue.
Other monotone increasing determiners are"every", "some", "many", "several", "'any" and "afew".
"No" and "few" are not.Any noun phrase Q Ps with a monotoneincreasing determiner Q involves two sets, anintensionally defined set denoted by the nounphrase minus the determiner, the set of all Ps,and a nonconstructlvely specified set denoted bythe entire noun phrase.
The determiner Q can beviewed as expressing a relation between these twosets.
Thus the sentence pattern Q Fs R can berepresented as follows:41) (Ts ) (Q(s ,{x  I P(x)}) & (VY) (~s  -> R(y)))That is, there is a set s which bears the relationQ to the set of all Ps, and R is true of everyelement of s. (Barwlse and Cooper call s a"witness set".)
"Most men work" would berepresented(~ s)(most(s,{x I man(x)})& (~ y)(y~s -> work(y)))For collective predicates such as "meet" and"agree", R would apply to the set rather than toeach of its elements.
(3 s) 0(s,{x I F(x)}) ~ R(s)Sometimes with singular noun phrases anddeterminers llke "a", "some" and "any" it will bemore convenient to treat the determiner as arelation between a set and one of its elements.
(B Y) 0(y,{x I P(x)}) & R(y).According to notation (i) there are twoaspects to quantification.
The first, whichconcerns a relation between two sets, is discussedin Section 2.2.
The second aspect involves apredication made about the element~ of one of thesets.
The approach taken here to this aspect ofquantif ication is somewhat more radical, anddepends on a view of semantics that might becalled "ontological promiscuity".
This isdescribed briefly in Section 2.3.
Then in Section2.4 the scope-neutral representation is presented.2.2.
Determiners as Relations between SetsExpressing determiners as relations betweensets allows us to express as axioms in a knowledgebase more refined properties of the determinersthan can be captured by representing them in termsof the standard quantlflers.First let us note that, with the properdefinitions of "every" and "some",(V sl,s2) every(sl,s2) <-> s l= s2(y x,s2) some(x, s2) <-> x~s2formula (I) reduces to the standard notation.
(This can be seen as explaining why therestriction is implicative in universalquantif ication and conjunctive in existentialquantif ication.
)A meaning postulate for "most" that isperhaps too mathematical is(~s l , s2 )  most(sl,s2) -> Isll > i/2 Is21Next, consider "any".
Instead of trying toforce an interpretation of "any" as a standardquantifier, let us take it to mean "a randomelement of".
(2) (~x ,s )  any(x,s) ~> x = random(s),where "random" is a function that returns a randomelement of a set.
This means that theprototypical use of "any" is in sentences likePick any card.Let me surround this with caveats.
This can't beright, if for no other reason than that "any" issurely a more "primitive" notion in language than"random".
Nevertheless, mathematics gives us firmintuitions about "random" and (2) may thus shedlight on some linguistic facts.Many of the linguistic facts about "any" canbe subsumed under two broad characterizations:i.
It requires a "modal" or "nondeflnlte"context.
For example, "John talks to any woman"must be interpreted dispositlonally.
If we adopt(2), we can see this as deriving from the natureof randomness.
It simply does not make sense tosay of an actual entity that it is random.2.
It normally acts as a universalquantif ier outside the scope of the most immediatemodal embedder.
This is usually the most naturalinterpretation of "random".Moreover, since "any" extracts a singleelement, we can make sense out of cases in which"any" fails to act llke "every".58I'Ii talk to anyone but only to one person.
* I'Ii talk to everyone but only to one person.John wants to marry any Swedish woman.
* John wants to marry every Swedish woman.
(The second pair is due to Moore \[1973\].
)This approach does not, however, seem tooffer an especially convincing explanation as towhy "any" functions in questions as an existentialquantifier.2.3.
Ontological PromiscuityDavidson \[1967\] proposed a treatment ofaction sentences in which events are treated asindividuals.
This facilitated the representationof sentences with adverbials.
But virtually everypredication that can be made in natural languagecan be modified adverbially, be specified as totime, function as a cause or effect of somethingelse, constitute a belief, be nominalized, and bereferred to pronominally.
It is thereforeconvenient to extend Davidson's approach to allpredications, an approach that might be called"ontological promiscuity".
One abandons allontological scruples.
A similar approach is usedin many AI systems.We will use what might be called a"nomlnalization" operator ..... for predicates.Corresponding to every n-ary predicate p therewill be an n+l-ary predicate p" whose firstargument can be thought of as a condition of p'sbeing true of the subsequent arguments.
Thus, if"see(J,B)" means that John sees Sill,"see'(E,J,S)" will mean that E is John's seeing ofBill.
For the purposes of this paper, we canconsider that the primed and unprimed predicatesare related by the following axiom schema:(3) (~ x,e) p'(e,x) -> p(x)(Vx) (~e)  p(x) -> p'(e,x)It is beyond the scope of this paper toelaborate on the approach further, but it will beassumed, and taken to extremes, in the remainderof the paper.
Let me illustrate the extremes towhich it will be taken.
Frequently we want torefer to the condition of two predicates p and qholding simultaneously of x.
For this we willrefer to the entity e such thatand'\[e,el,e2) & p*(el,x) & q'(e2,x)Here el is the condition of p being true of x, e2is the condition of q being true of X, and e thecondition of the conjunction being true.2.4.
The Scope-Neu?ral RepresentationWe will assume that a set has a typicalelement and that the logical form for a pluralnoun phrase will include reference to a set andits ~z~ical element.
2 The linguistic intuition2 Woods \[1978\] mentions something llke thisapproach, but rejects it because difficulties thatare worked out here would have to be worked out.behind this idea is that one can use singularpronouns and definite noun phrases as anaphors forplurals.
Definite and indefinite generics canalso be understood as referring to the typicalelement of a set.In the spirit of ontological promiscuity, wesimply assume that typical elements of s~ ~rethings that exist, and encode in meaningpostulates the necessary relations between a set'stypical element and its real elements.
This moveamounts to reifying the universally quantifiedvariable.
The typical element of s will bereferred to as ~(s).There are two very nearly contradictoryproperties that typical elements must have.
Thefirst is the equivalent of universalinstantiation; real elements should inherit theproperties of the typical element.
The second isthat the typical element cannot itself be anelement of the set, for that would lead tocardinallty problems.
The two together wouldimply the set has no elements.
3We could get around this problem by positinga special set of predicates that apply to typicalelements and are systematically related to thepredicates that apply to real elements.
This ideashould be rejected as being ad  ho__~c, if aid did notcome to us from an unexpected quarter -- thenotion of "grain size".When utterances predicate, it is normally atsome degree of resolution, or "grain".
At afairly coarse grain, we might say that John is atthe post office -- "at(J,PO)".
At a more refinedgrain, we have to say that he is at the stampwindow -- "at(J,SW)'" We normally think of grainin terms of distance, but more generally we canmove from entities at one grain to entities at acoarser grain by means of an arbitrary partition.Fine-grained entities in the same equivalenceclass are indistinguishable at the coarser grain.Given a set S, consider the partition thatcollapses all elements of S into one element andleaves everything else unchanged.
We can view thetypical element of S as the set of real elementsseen at this coarser grain -- a grain at which,precisely, the elements of the set areindistinguishable.
Formally, we can define anoperator ~ which takes a set and a predicate asits arguments and produces what will be referredto as an "indexed predicate":T, if x=T(s) & (V yes) p(y),<;'(s,p)(x) = F, if x=~(s) &~(F  y~s) p(y),p(x) otherwise.We will frequently abbreviate this "P5 " Notethat predicate indexing gets us out of the above3 An alternative approach would be to say that thetypical element is in fact one of the realelements of the set, but that we will never knowwhich one, and that furthermore, we will neverknow about the typical element any property thatis not true of all the elements.
This approachruns into technical difficulties involving theempty set.59contradiction, for now "~(s )  E 5 s" is not onlytrue but tautologous.We are now in a position to state theproperties typical elements should have.
Thefirst implements universal instantiation:(4) (Us ,y )  p$(~(s)) & yes -> p(y)(5) (Vs)( \ [ (?x~s) p(x)\] -> p~(~s)))That is, the properties of the typical element atthe coarser grain are also the properties of thereal elements at the finer grain, and the typicalelement has those properties that all the realelements have.Note that while we can infer a property fromset membership, we cannot infer set membershipfrom a property.
That is, the fact that p istrue of a typical element of a set s and p is trueof an entity y, does not imply that y is anelement of s. After all, we will want "three men"to refer to a set, and to be able to infer fromy's being in the set the fact that y is a man.But we do not want to infer from y's being a manthat y is in the set.
Nevertheless, we will needa notation for expressing this stronger relationamong a set, a typical element, and a definingcondition.
In particular, we need it forrepresenting "every man", Let us develop thenotation from the standard notation forintensionally defined sets,(6) s - {x f p<x)},by performing a fairly straightforward, thoughontological ly promiscuous, syntactic translationon it.
First, instead of viewing x as auniversal ly quantified variable, let us treat itas the typical element of s. Next, as a way ofgetting a handle on "p(x)", we will use thenominalization operator .... to reify it, and referto the condition e of p (or p$) being true of thetypical element x of s -- "p~ (e,x)".
Expression(6) can then be translated into the following flatpredlcate-argument form:(7) set(s,x,e) & p~ (e,x)This should be read as saying that s is a setwhose typical element is x and which is defined bycondition e, which is the condition of p(interpreted at the level of the typical element)being true of x.
The two critical properties ofthe predicate "set" which make (7) equivalent to(6) are the following:(8) ~s ,x ,e ,y)  set(s,x,e) & p~ (e,x) & p(y) -> yes(9) (~s,x,e) set(s,x,e) -> x "T (s )Axiom schema (8) tells us that if an entity y hasthe defining property p of the set s, then y is anelement of s. Axiom (9), along with axiom schemas(4) and (3), tells us that an element of a set hasthe act's defining property.With what we have, we can represent thedistinction between the distr ibutive andcollective readings of a sentence like(I0) The men lifted the piano.For the collective reading the representationwould include "llft(m)" where m is the set of men.For the distr ibutive reading, the representationwould have " l i f t (~(m))" ,  where ~(m)  is thetypical element of the set m. To represent theambiguity of (I0), we could use the devicesuggested in Hobbs \[1982 I for preposit ional phraseand other ambiguities, and wr~te "llft(x) & (x=m vx- ~(m) )".This approach involves a more thorough use oftypical elements than two previous approaches.Webber \[1978\] admitted both set and prototype (mytypical element) interpretations of phrases like"each man'" in order to have antecedents for both"they" and "he", but she maintained a distinctionbetween the two.
Essentially, she treated "eachman" as ambiguous, whereas the present approachmakes both the typical element and the setavailable for subsequent reference.
Mellish\[1980 1 uses =yplcal elements strictly as anintermediate representation that must be resolvedinto more standard notation by the end ofprocessing.
He can do this because he is workingin a task domain -- physics problems -- in whichsets are not just finite but small, and vaguenessas to their composition must be resolved.
Webberdid not attempt to use typical elements to derivea scope-neutral representation; Mell ish did soonly in a limited way.Scope dependencies can now be represented asrelations among typical elements.
Consider thesentence(II) Most men love several women,under the reading in which there is a differentset of women for each man.
We can define adependency function f which for each man returnsthe set of women whom that man loves.f(m) = {w \[ woman(w) & love(m,w)}The relevant parts of the initial logical form,produced by a syntactic and semantic translationcomponent, for sentence (Ii) will be(12) love(~(m),~(w)) & most(m,ml) & manl(~(ml))& several(w) & womanl(~(w))where ml is the set of all men, m the set of mostof them referred to by the noun phrase "most men",and w the set referred to by the noun phrase"several women", and where "manl = ~'(ml,man)" and"womanl = ~" (w,woman)'.
When the inferenclngcomponent discovers there is a different set w foreach element of the set m, w can be viewed asrefering to the typical element of this set ofsets:w-T({ f<x> { x~m})60To eliminate the set notation, we can extend thedefinit ion of the dependency function to thetypical element of m as follows:f(~(m)) -Z({f(x) I x~m})That is, f maps the typical element of a set intothe typical element of the set of images under fof the elements of the set.
From here on, we willconsider all dependency functions so extended tothe typical elements of their domains.The identity "w - f (~(m))"  nowsimultaneously encodes the scoplng information andinvolves only existentially quantified variablesdenoting individuals in an (admittedlyontologlcal ly promiscuous) domain.
Expressionsllke (12) are thus the scope-~eutralrepresentation, and scoplng information is addedby conjoining such identities.Let us now consider several examples in whichprocesses of interpretation result in theacquisit ion of scoplng information.
The firstwill involve interpretation against a small model.The second will make use of world knowledge, whilethe third illustrates the treatment of embeddedquantlflers.First the simple, and classic, example.
(13) Every man loves some woman.The initial logical form for this sentenceincludes the following:lovel(r(ms),w) & manl(~(ms)) & woman(w)where "lovel -@(mS,Ax\[love(x,w)\])'" and "manl -(ms,man)".
Figure i i l lustrates two small modelsof this sentence.
M is the set of men {A,B}, W isthe set of women {X,Y}, and the arrows signifylove.
Let us assume that the process ofinterpreting this sentence is Just the process ofidentifying the existentially quantified variablesms and w and possibly coercing the predicates, ina way that makes the sentence true.
4M W M WA ~ X A ------~ XB / Y  B ~ Y(a) (b)Figure I.
Two models of sentence (13).In Figure l(a), "'love(A,X)" and "love(B,X)"are both true, so we can use axiom schema (5) toderive "lovel('~(M),X)".
Thus, theidentifications "ms - M'" and "w = X'" result in thesentence being true.In Figure l(b), "love(A,X)" and "love(B,Y)"are both true, but since these predications differ4 Bobrow and Webber \[1980\] similarly show scoplnginformation acquired by Interpretatlon against asmall model.in more than one argument, we cannot apply axiomschema (5).
First we define a dependency functionf, mapping each man into a woman he loves,yielding "love(A,f(A))" and "love(B,f(B))".
Wecan now apply axiom schema (5) to derive'" love2 ('~ (M), f (~  (M)) ) ", where "love2 =~(M,Ax \ [ love(x , f (x ) ) \ ] ) " .
Thus, we can make thesentence true by identifying ms with M and w withf(~'(M)), and by coercing "love" to "'love2" and"woman" to "~ (W,woman)".
,In each case we see that the identif icationof w is equivalent to solving the scope ambiguityproblem.In our subsequent examples we will ignore theindexing on the predicates, until it must bementioned in the case of embedded quantifiers.Next consider an example in which worldknowledge leads to disamblguatlon:Three women had a baby.Before inferencing, the scope-neutralrepresentation ishad(~Z~ws),b) & lwsI=3 & woman(~(ws)) & baby(b)Let us suppose the inferencing component hasaxioms about the functionality of having a baby --something llke(~ x,y) had(x,y) -> x = mother-of(y)and that we know about cardlnallty the fact thatfor any function g and set s,Ig(s)l ~ fslThen we know the following:3 - lwsl = Imother-of(b) I ~ IblThis tells us that b cannot be an individual butmust be the typical element of some set.
Let f bea dependency function such thatwEws & f(w) = x -> had(w,x)that is, a function that maps each woman into somebaby she had.
Then we can identify b withf('~'(ws)), or equivalently, with~({f (w)  I w~ ws}), giving us the correct scope.Finally, let us return to interpretation withrespect to small models to see how embeddedquantiflers are represented.
Consider(14) Every representative of a company arrived.The initial logical form.includesarrive(r) & set(rs,r,ea) & and'(ea,er,eo)& rep'(er,r) & of'(eo,r,c) & co(c)That is, r arrives, where r is the typical elementof a set rs defined by the conjunction ea of r'sbeing a representative and r's being of c, where cis a company.
We will consider the two models in61Figure 2.
R is the set of representatives{A,B,(C)}, K is the set of companies {X,Y,(Z,W)},there is an arrow from the representatives to thecompanies they represent, and the representativeswho arrived are circled.R K R K(a) (b)Figure 2.
Two models of sentence (14).In Figure 2(a), "of(A,X)", "of(B,Y)" and "of(B,Z)"are true.
Define a dependency function f to map Ainto X and B into Y.
Then "of(A,f(A))" and"of(B,f(B))" are both true, so that"o f (~(R) , f (~(R) ) ) "  is also true.
Thus we havethe following identifications:c = f (Z(R) )  =~({X,Y}) ,  rs = R, r -t(R)In Figure 2(b) "o f (B~"  and "of(C,Y)'" areboth true, so "'of(~'(Rl),~)is also.
Thus we maylet c be Y and rs be RI, giving us the widereading for "a company".In the case where no one represents anycompany and no one arrived, we can let c beanything and rs be the empty set.
Since, by thedefinit ion of o" , any predicate indexed by theempty set will be true of the typical element ofthe empty set, "a r r lve#(~(# ))" wil l  be true,and the sentence will be satisfied.It is worth pointing out that this approachsolves the problem of the classic "donkeysentences".
If in sentence (14) we had had theverb phrase "hates it", then "it" would beresolved to c, and thus to whatever c was resolvedto.So far the notation of typical elements anddependency functions has been introduced; it hasbeen shown how scope information can berepresented by these means; and an example ofinferential processing acquiring that scopeinformation has been given.
Now the preciserelation of this notation to standard notationmust be specified.
This can be done by means ofan algorithm that takes the inferential notation,together with an indication of which propositionis asserted by the sentence, and produces In theconventional form all of the readings consistentwith the known dependency information.First we must put the sentence into what wil lbe called a "bracketed notation".
We associatewith each variable v an indication of thecorresponding quantifier; this is determined fromsuch pieces of the inferential logical form asthose involving the predicates "set" and "most";in the algorithm below it is refered to as"Quant(v)".
The translation of the remainder ofthe inferential logical form into bracketednotation is best shown by example.
For thesentenceA representative of every company saw a samplethe relevant parts of the inferential logical formaresee(r,s) & rep(r) & of(r,c) & co(c) & sample(s)where "see(r,s) '?
is asserted.
This is translated "in a straightforward way into(18) see(It I rep(r) & of(r,\[c I co(c)l)\],Is I sample(s)\])This may be read "An r such that r is arepresentative and r is of a c such that c is acompany sees an s such that s is a sample.The nondeterministic algorithm belowgenerates all the scoplngs from the bracketednotation.
The function TOPBVS returns a llst ofall the top-level bracketed variables in Form,that is, all the bracketed variables except thosewithin the brackets of some other variable -- in(18) r and s but not c. BRANCHnondetermlnist ical ly generates a separate processfor each element in a list it is given asargument.
A four-part notation is used forquantifiers (similar to that of Woods \[1978\]) --"(quantifier varlabie restriction body)".G(Form) :if \[vlRl ~ BRANCH(TOPBVS(Form))then Form ~ (Quant(v) v BRANCH({R,G(R)}) Form~.~if Form is whole sentencethen Return G(Form)else Return BRANCH({Form,G(Form)})else Return FormIn this algorithm the first BRANCH corresponds tothe choice in ordering the top-level quantifiers.The variable chosen will  get the narrowest scope.The second BRANCH corresponds to the decision ofwhether or not to give an embedded quantifier awide reading.
The choice R corresponds to a widereading, G(R) to a narrow reading.
The thirdBRANCH corresponds to the decision of how wide areading to give to an embedded quantifier.Dependency constraints can be built into thisalgorithm by restricting the elements of itsargument that BRANCH can choose.
If the variablesx and y are at the same level and y is dependenton x, then the first BRANCH cannot choose x.
If yis embedded under x and y is dependent on x, thenthe second BRANCH must choose G(R).
In the thirdBRANCH, if any top-level bracketed variable inForm is dependent on any variable one level ofrecurslon up, then G(Form) must be chosen.A fuller explanation of this algorithm andseveral further examples of the use of thisnotation are given in a longer version of thispaper.623.
Other DetermlnersThe approach of Section 2 will not work formonotone decreasing determiners, such as "few" and"no".
Intuitively, the reason is that thesentences they occur in make statements aboutentities other than just those in the setsreferred to by the noun phrase.
Thus,Few men work.is more a negative statement about all but a fewof the men than a positive statement about few ofthem.
One possible representation would besimilar to (I), but wlth the implication reversed.
(Bs)(q(s,{x I P(x)})& (~ y)(P(y) & R(y) -> yes))This is unappealing, however, among other things,because the predicate P occurs twice, making therelation between sentences and logical forms lessdirect.Another approach would take advantage of theabove intuition about what monotone decreasingdeterminers convey.
(7 s)(Q(s,{x \[ P(x)}) & (~y)(y?s->-~R(y)) )That is, we convert the sentence into a negativeassertion about the complement of the noun phrase,reducing this case tO the monotone increasingcase.
For example, "few men work" would berepresented as follows:(~ s)( \ [~w(s,{x I man(x)})& (Vy) (y~s  ->~work(y ) ) )  5(Th is  fo rmula t ion  i s  equ iva lent  to ,  but notidentical with, Barwlse and Cooper's \[1981\]witness set condition for monotone decreasingdeterminers.
)Some determiners are neither monotoneincreasing nor monotone decreasing, but Barwlseand Cooper conjecture that it is a linguisticuniversal that all such determiners can beexpressed as conjunctions of monotone determiners.For example, "exactly three" means "at least threeand at most three".
If this is true, then theyall yield to the approach presented here.Moreover, because of redundancy, only two newconjuncts would be introduced by this method.AcknowledgmentsI have profited considerably in this researchfrom discussions with Lauri Kartunnen, Bob Moore,Fernando Pereira, Stan Rosenscheln, and StuShleber, none of whom would necessarily agree withwhat I have written, nor even view it withsympathy.
This research was supported by theDefense Advanced Research Projects Agency underContract No.
N00039-82-C-0571, by the NationalLibrary of Medicine under Grant No.
IR01 LM03611-5 "~w'  is pronounced "few bar".01, and by the National Science Foundation underGrant No.
IST-8209346.REFERENCESBarwise, Jo and R. Cooper 1981.
Generalizedquantifiers and natural language.
Lln~uisticsand philosophy, Vol.
4, No.
2, 159-219.Bobrow, R. and B. Webber 1980.
PSI-KLONE: Parsingand semantic interpretation in the BBNnatural language understanding system.Proceedings, Third National Conference ofCanadian Society for Computational Studies ofIntelli~ence.
131-142.
Victoria, BritishColumbia.
May 1980.Cooper, R. 1975.
Montague's semantic theory andtransformational syntax.
Ph.D. thesis.University of Massachusetts.Davidson, D. 1967.
The logical form of actionsentences.
In N. Rescher (Ed.
), The Logic ofDecision and Action.
81-95.
Un{versity o-fPittsburgh Press, Pittsburgh, Pennsylvania.Hobbs, J.
1976.
A computational approach todiscourse analysis.
Research Report 76-2,Department of Computer Sciences, CityCollege, City University of New York.Hobbs, J.
1980.
Selective inferencing.ProceedinBs, Third National Conference ofCanadian Society f_or Computational Studies ofIntelll~ence.
101-114.
Victoria, BritishColumbia.
May 1980.Hobbs, J.
1982.
Representing ambiguity.Proceedln~s of the First West CoastConference on Formal Linguistics.
15-28.Stanford, California.Melllsh, C. 1980.
Coping with uncertainty: Nounphrase interpretation and early semanticanalysis.
Ph.D. thesis.
University ofEdinburgh.Moore, R. 1973.
Is there any reason to wantlexical decomposition?
Unpublishedmanuscript.Van Lehn, K~ 1978.
Determining the scope ofEnglish quantlflers.
Massachusetts Instituteof Technology Artificial IntelligenceLaboratory Technical Report AI-TR-483.Webber, B.
1978.
A formal approach to discourseanaphora.
Technical Report 3761, Bolt Beranekand Newman, Inc. Cambridge, Massachusetts.Woods, W. 1977.
Semantics and quantification innatural language question answering.
Advancesi__~n Computers, Vol.
17.
1-87.
Academic Press,New York.63
