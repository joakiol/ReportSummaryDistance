COPYING IN NATURAL LANGUAGES, CONTEXT-FREENESS, AND QUEUE GRAMMARSAlex is  Manaster-RamerUnivers i ty of Michigan2236 Ful ler Road #108Ann Arbor, MI 48105ABSTRACTThe documentation of (unbounded-len~h) copying andcross-serial constructions in a few languages in the recentliterature is usually taken to mean that natural languagesare slightly context-sensitive.
However, this ignores thosecopying constructions which, while productive, cannot beeasily shown to apply to infinite sublanguages.
To allow suchfinite copying constructions to be taken into account in formalmodeling, it is necessary to recognize that natural anguagescannot be realistically represented by formal languages of theusual sort.
Rather, they must be modeled as families offormal languages or as formal languages with indefinitevocabularies.
Once this is done, we see copying as a trulypervasive and fundamental process in human language.Furthermore, the absence of mirror-image constructions inhuman languages means that it is not enough to extendContext-free Grammars in the direction of context-sensitivity.Instead, a class of grammars must be found which handles(context-sensitive) copying but not (context-free) mirrorimages.
This suggests that human linguistic processes usequeues rather than stacks, making imperative thedevelopment of a hierarchy of Queue Grammars as acounterweight to the Chomsky Grammars.
A simple class ofContext-free Queue Grammars is introduced and discussed.IntroductionThe claim that at least some human languages cannotbe described by a Context-free Grammar no matter how largeor complex has had an interesting career.
In the late 1960'sit might have seemed, given the arguments of Bar-Hillel andShamir (1960) about respect ively coordinations in English,Postal (1964) about reduplication-cum-incorporation of objectnoun stems in Mohawk, and Chomsky (1963) about Englishcomparative deletion, that this claim was firmly established.Potentially serious--and at any rate embarrassing--problems with both the formal and the linguistic aspects ofthese arguments kept popping up, however (Daly, 1974;Levelt, 1974), and the partial fixes provided by BrandtCorstius (as reported in Levelt, 1974) for the respect ivelyarguments and by Langendoen (1977) for that as well as theMohawk argument did not deter Pullum and Gazdar (1982)from claiming that "it seems reasonable to assume that thenatural languages are a proper subset of the infinite-cardinality CFL's, until such time as they are validly shownnot to be".
Two new arguments, Higginbotham's (1984) oneinvolving such  that  relativization and Postal andLangendoen's (1984) one about sluicing were dismissed ongrounds of descriptive inadequacy by Pullum (1984a), who,however, suggested that the Langendoen and Postal (1984)argument about the doubling relativization construction maybe correct (all these arguments deal with English).Pullum (1984b) likewise heaped scorn on my argumentthat English reshmuplicative constructions show non-CFness,but he accepted (1984a; 1984b) Culy's (1985) argumentabout noun reduplication in Bambara and Shieber's (1985)one about Swiss German cross-serial constructions ofcausative and perception verbs and their objects.
Gazdar andPullum (1985) also cite these two, as well as an argument byCarlson (1983) about verb phrase reduplication i  Engenni.They also refer to my discovery of the X or  no X ...construction i  English I and mention that "Alexis Manaster-Ramer ... in unpublished lectures finds reduplicationconstructions that appear to have no length bound in Polish,Turkish, and a number of other languages".
While they donot refer to my 1983 reshmuplication argument, which theypresumably still reject, the Turkish construction they alludeto was cited in my 1983 paper and is similar to the Englishreshmuplication in form as well as function (see below).In any case, the acceptance of even one case of non-CFness in one natural anguage by the only active advocatesof the CF position would seem to suffice to remove the issuefrom the agenda.
Any additional arguments, uch as Kac (toappear), Kac, Manaster-Ramer, and Rounds (to appear), andManaster-Ramer (to appear a; to appear b) may appear to beno more than flogging of dead horses.
However, as I arguedin Manaster-Ramer (1983) and as recent work (Manaster-Ramer, to appear a; Rounds, Manaster-Ramer, andFriedman, to appear) shows ever more clearly, thisconception of the issue (viz., Is there one natural languagesthat is weakly noncontext-free?)
makes very little differenceand not much sense.First of all, if non-CFness is so hard to find, then it ispresumably linguistically marginal.
Second, weak generativearguments cannot be made to work for natural languages,because of their high degree of structural ambiguity and thegreat difficulty in excluding every conceivable interpretationon which an apparently ungrammatical string might turnout -on  reflection--to be in the language.
Third, weakgenerative capacity is in any case not a very interestingproperty of a formal grammar, especially from a linguisticpoint of view, since linguistic models are judged by othercriteria (e.g., natural anguages might well be regular withoutthis making CFGs any the more attractive as models forthem).
Fourth, results about the place of natural languagesin the Chomsky Hierarchy seem to be should be considered inlight of the fact that there is no reason to take the ChomskyHierarchy as the appropriate formal space in which to lookfor them.
Fifth, models of natural languages that areactually in use in theoretical, computational, and descriptivelinguistics are -and  always have been--only remotelyrelated to the Chomsky Grammars, which means that resultsabout the latter may be of little relevance to linguistic models.85As I argued in 1983, we should go beyond piecemealdebunking of invalid arguments  against  CFGs and by thesame token it seems to me that  we must  go beyond piecemealrestatements  of such arguments .
Rather,  we should focus ongeneral issues and ones that  have implications for themodeling of human languages.
One such issue is, it seems tome, the kind of context-sensit ivity found in naturallanguages.
It appears that the counterexamples to context-freeness are all rather similar.
Specifically, they all seem toinvolve some kind of cross-serial dependency, i.e., adependency between the nth e lements of two or moresubstr ings.
This- -unl ike the s ta tement  that naturallanguages are noncontext- f ree--might  mean something if weknew what  kinds of models were appropriate for cross-serialdependencies.
Given that  not every kind of context-sensitiveconstruction is found in human languages,  it should be clearthat  there is nothing to be gained by invoking the dubiousslogan of context-sensit ivity.Another relevant question is the centrality orperipherality of these constructions in natural  languages.The relevant l i terature makes  it appear that  they aresomewhat  marginal  at best.
This would explain the torturedhistory of the at tempts  to show that  they exist at all.However, this appears to be wrong, at least when weconsider copying constructions.
The requirement of full ornear identity of two or more subparts  of a sentence (or adiscourse) is a very widespread phenomenon.
In this paper, Iwill focus on the copying constructions precisely because theyare so common in human languages.In addition to such questions, which appear to focus onthe linguistic side of things, there are also the moremathemat ica l  and conceptual problems involved in the wholeenterprise of modeling human languages in formal terms.My own belief is that  both kinds of issues must  be solved intandem, since we cannot know what  kind of formal models wewant  until we know what  we are going to model, and wecannot know what  human languages are or are not like untilwe know hot, to represent hem and what  to compare themto.
This paper is intended as a contribution to this kind ofwork.Copy ing  Dependenc iesThe examples of copying (and other) constructions whichhave figured in the great  context-freeness debate have allinvolved at tempts  to show that  a whole (natural) language isnoncontext free.
Now, while it is often easy to find anoncontext-free subset of such a language, it is not alwayspossible to isolate that  subset  formally from the rest  of thelanguage in such a way as to show that  the language as awhole is noncontext-free.
There is so much ambiguity innatural  languages that  it is strictly speaking impossible toisolate any construction at the level of str ings, thusinvalidating all arguments  against  CFGs or even RegularGrammars  that  refer to weak generative capacity.
However,the a rguments  can be reconstructed by making use of thenotion of classificatory capacity of formal g rammars ,introduced in Manaster -Ramer  (to appear a) and Manaster-Ramer  and Rounds (to appear).
The classificatory capacity isthe set of languages generated by the various subgrammarsof a g rammar ,  and if we are willing to assume that  l inguistscan tell which sentences in a language xemplify the same ordifferent syntactic patterns,  then we can usual ly simplydemonstrate that, e.g., no CFG can have a subgrammargenerat ing all and only the sentences of some particularconstruction if that construction involves reduplication.
Thiswill shot '  the inadequacy of CFGs, even if the str ing set as awhole may be strictly speaking regular.
Note that  thisapproach holds that  it is impossible to determine with anyconfidence that  a particular str ing qua str ing isungrammat ica l ,  but that  it may  be possible to tell oneconstruction from another,  and that  the lat ter - -and not theformer- - is  the real basis of all l inguistic work, theoretical,computational,  and descriptive.Finite CopyingThe counterexamples to context-freeness in thel iterature have all been claimed to crucially involveexpressions of unbounded length.
This seemed necessary inview of the fact that  an upper bound on length would implyf initeness of the subset  of str ings involved, which would as aresult  be of no formal language theoretic interest.
However, itis often difficult to make a case for unbounded length, and themain result  has  been that,  even though every l inguist knowsabout reduplication, it seemed nearly impossible to find aninstance of reduplication that  could be used to make a formala rgument  against  CFGs, even though no one would ever usea CFG to describe reduplication.For, in addition to reduplications that  can apply tounboundedly long expressions,  there is a much better knownclass of reduplications exemplified by Indonesianpluralization of nouns.
Here it is difficult to show that  thereduplicated forms are infinite in number ,  because compoundnouns are not pluralized in the same way, and ignoringcompounding, it would seem that  the number  of fiouns isfinite.
However, this number  is very large and moreover it isprobably not well defined.
The class of noun s tems is open,and can be enriched by borrowing from foreign languages andneologisms, and all of these spontaneously pluralize byreduplication.Rounds, Manaster -Ramer ,  and Fr iedman (to appear)argue that  facts like this mean that  a natura l  languageshould not be modeled as a formal language but  rather  as afamily of languages,  each of which may be taken as anapproximation to an ideal language.
In the case before us,we could argue that  each of the approximations has  only afinite number  of nouns,  for example,  but a different numberin different approximations.
This idea, related to the work ofYuri Gurevich on finite dynamic models of computation,allows us to state the argument  hat  the existence of an openclass of reduplications i sufficient o show the inadequacy ofCFGs for that  family of approximations.
The basis of thea rgument  is the observation that  while each of theapproximate languages could in principle have a CFG, eachsuch CFG would differ from the next  not only in the additionof a new lexical item but  also in the addition of a newreduplication rule (for that  particular item).To capture what  is really going on, we require ag rammar  that is the same for each approximation modulo thelexicon.
This g rammar  in a sense generates the infinite ideal,but actually each actual approximate grammar  only has  afinite lexicon and hence actually only generates a finitenumber  of reduplications.
In order to model the flexibility ofthe natural  language vocabulary, we assume that  eachmember  of the family has  the same grammar  modulo theterminal  vocabulary and the rules which insert  terminals.Another way of stat ing this is that  the lexicon ofIndonesian is finite but  of an indefinite size (what Gurevichcalls "uncountably finite").
A CFG would still have to containa separate rule for the plural of every noun and henc,would have to be of an indefinite size.
Thus,  with86addition of a new noun, the grammar  would have to add anew rule.
However, this would mean that  the grammar  atany given time can only form the plurals of nouns that  havealready been learned.
Since speakers of the language knowin advance how to pluralize unfamil iar nouns, this cannot betrue.
Rather the grammar  at any given time must  be able toform plurals of nouns that have not yet been learned.
This inturn means  that an indefinite number  of plurals can beformed by a grammar  of a determinate finite size.
Hence, ineffect, the number of rules for plural formation must  besmaller than the number  of plural forms that  can begenerated, and this in turn means  that  there is no CFG ofIndonesian.This brings up a crucial issue, of which we are allpresumably aware but  which is usual ly lost sight of inpractice, namely,  that  the way a mathemat ica l  model (in thiscase, formal language theory) is applied to a physical ormental  domain (in this case, natural  language) is a matter  ofutility and not itself subject to proof or disproof.
Formallanguage theory deals with sets of str ings over well-definedfinite vocabularies (also often called alphabets) such as thehackneyed {a, b}.
It has  been all too easy to fall into the trapof equating the formal language theoretic notion ofvocabulary (alphabet) with the linguistic notion of vocabularyand likewise to confuse the formal language theoretic notionof a str ing (word) over the vocabulary (alphabet) with thelinguistic notion of sentence.However, the fundamenta l  fact about all known naturallanguages is the openness of at  least some classes of words(e.g., nouns but perhaps not prepositions or, in somelanguages, verbs), which can acquire new members  throughborrowing or through various processes of new formation,many  of them apparent ly not rule-governed, and which canalso lose members,  as words are forgotten.
Thus, the well-defined finite vocabularies of formal language theory are nota very good model of the vocabularies of natural  languages.Whether we decide to introduce the notion of families oflanguages or that  of uncountably finite sets or whether werather choose to say that  the vocabulary of a naturallanguage is really infinite (being the set of all str ings over thesounds or letters of the language that  could conceivably be orbecome lexical i tems in it), we end up having to conclude thatany language which productively reduplicates some openword class to form some grammatica l  category cannot have aCFG.Copying in EnglishIt should now be noted that  reduplications (andreiterations generally) are extremely common in naturallanguages.
Jus t  how common follows from an inspection ofthe bewildering variety of such constructions that  are foundin English.
All the examples cited here are productive thoughthey may be of bounded length.Linguistics shminguist ics.Linguistics or no linguistics, (I am going home).A dog is a dog is a dog.Philosophize while the philosophizing is good!Moral is as moral does.Is she beautiful or is she beautiful?These are clause-level constructions, but we also findones restricted to the phrase level.
(He) deliberates, deliberates, deliberates (all day long).
(He worked slowly) theorem by theorem.
(They form) a church within a church.
(He debunks) theory after theory.Also relevant are cases where a copying dependencyextends across sentence boundaries, as in discourses like:A: She is fat.B: She is fat, my foot.It is interest ing that several of these types areproductive even though they appear to be based on whatoriginally must  have been more restricted, idiomaticexpressions.
The pattern a X within a X, for example, issurely derived from the single example a state within a state,yet has become quite productive.Many of these patterns have analogues in otherlanguages.
For example, the X after X construction appearsto involve quantification and this may be related to the factthat, for example, Bambara  uses reduplication to mean'whatever '  and Sanskr i t  to mean 'every'  (P~nini 8.1.4).English reshmupl icat ion has  close analogues in manylanguages, including the whole Dravidian and Turkiclanguage families.
Tamil kiduplication (e.g.
pustakamkistakarn) and Turkish meduplication (e.g., kitap mitap) areinstances of this, though the semantic range is somewhatdifferent.
In both of these, the sense is more like that ofEnglish books and things, books and such, i.e., a combinationof deprecation and etceteraness rather than the purelyderisive function of English books shmoohs.
The English X orno X ... pattern is very similar to a Polish constructionconsisting of the form X (nominative) X ( instrumental) ... inits range of applications.
The repetition of a verb or verbalphrase to deprecate excessive repetition or intensity of anaction seems to be found in many  languages as well.I have not tried here to survey the uses to which copyingconstructions are put in different languages or even todocument fully their wide incidence, though the examplescited should give some indication of both.
It does appear thatcopying constructions are extremely common and pervasive,and this in turn suggests that they are central to man 'slinguistic faculties.
When we consider such additional factsas the frequency of copying in child language, we may betempted to take copying as one of the basic linguisticoperations.Copies  vs. mi r ro r  imagesThe existence and the central ity of copying constructionsposes interesting questions that  go beyond the inadequacy ofCFGs.
For example, why should natural  languages havereduplications when they lack mirror- image constructions,which are context-free?
This asymmetry  (first noted inManaster -Ramer  and Kac, 1985, and Rounds, Manaster -Ramer,  and Fr iedman op.
cit.)
argues that  it is not enough tomake a small  concession to context-sensitivity, as the sayinggoes.
Rather than grudgingly clambering up the ChomskyHierarchy towards Context-sensit ive Grammars ,  we shouldconsider going back down to Regular Grammars  and striking87out in a different direction.
The simplest alternative proposalis a class of g rammars  which intuitively have the samerelation to queues that  CFGs have to stacks.
The idea, ~vhichI owe to Michael Kac, would be that  human linguisticprocesses make little if any use of stacks and employ queuesinstead.Queue  GrammarsThis suggests  that  CFGs are not just  inadequate asmodels of natural  languages but inadequate in a particularlydamaging way.
They are not even the right point ofdeparture, since they not only undergenerate but alsoovergenerate.
This leads to the idea of a hierarchy ofg rammars  whose relation to queues is like that  of theChomsky Grammars  to stacks.
A queue-based analogue toCFG is being developed, under the name of Context - f reeQueue Grammar .
The current  version is allowed rules ofthe following form:A ->aA - ->  aBA - -  > aB .
.
.bA - -> a...bA - -> ...BWhatever  appears to the r ight of the three dots is put atthe end of the str ing being rewritten.
Otherwise, alldefinitions are as in a corresponding restricted CFG.
Thus,the grammarS - > aS...aS - > bS...bS - -> a...aS - ->  b...bwill generate the copying language over {a,b} excluding thenull str ing and define derivations like the following:S ->  aSa -> abSab - ->  abaabaS ->  bSb - ->  baSba - > baaSbaa - ->  baabSbaabOn the other hand, I conjecture that  the correspondingxmi(x) language cannot be generated by such a grammar .Even at this early stage of inquiry into these formalisms,then, we have some tangible promise of being able to explainwhy natura l  languages should have reduplications but notmirror- image constructions.
Various xh(x) constructions suchas the respectively ones and the cross-serial verb constructionscan be handled in the same way as reduplications.While the idea of taking queues as opposed to stacks asthe principal nonfinite-state resource available to humanlinguistic processes would explain the prevalence of copyingand the absence of mirror images, it does not explain thecoexistence of center-embedded constructions with cross-serialones or the relative scarcity of cross-serial constructions otherthan copying ones.For this reason, if for no other, the CFQGs could not bean adequate model of natural  language.
In fact, there arefurther problems with these grammars .
One way in whichthey fail is that  they apparently can only generate twocopies--or two cross-serially dependent subst r ings- -whereasnatural  languages seem to allow more (as in Grammar isgrammar is grammar).
This is similar to the limitation ofHead Grammars  and Tree Adjoining Grammars  to generat ingno more than four copies (Manaster-Ramer to appear a).However, a more general class of Queue Grammars  appearsto be within reach which will generate an arbitrary number ofcopies.Perhaps more serious is the fact that  CFQGs apparentlycan only generate copying constructions at  the cost ofprofligacy (as defined in Rounds, Manaster -Ramer ,  andFr iedman,  to appear).
The repair of this defect is lessobvious, but  it appears that  the fundamenta l  idea of basingmodels of natural  languages on queues rather  than stacks isnot undermined.
Rather,  what  is at  issue is the way in whichinformation is entered into and retrieved from the queue.The CFQGs suggest  a piecemeal process but theconsiderations cited here seem to argue for a global one.
Anumber  of formal isms with these properties are beingexplored.On the other hand, it may  be that  something much likethe simple CFQG is a natural  way of captur ing cross-serialdependencies in cases other than copying.
To see exactlywhat  is involved, consider the difference between copying andother cross-serial dependencies.
This difference has  little todo with the form of the strings.
Rather,  in the case of othercross-serial dependencies, there is a syntactic and semant icrelation between the nth  elements of two or more structures.For example, in ~ respectively construction involving aconjoined subject arid a conjoined predicate, each conjunct ofthe former is semantical ly combined with the correspondingconjunct of the latter.
In the case of copying constructions,there is nothing analogous.
The corresponding parts of thetwo copies do not bear any relations to each other.
Thus  itmakes  some sense to build up the corresponding parts  ofcross-serial construction in a piecemeal fashion, but  thisappears to be inapplicable in the case of copyingconstructions.In view of all these limitations, the CFQGs might  seemto be a non-starter.
However, their importance lies in thefact that  they are the first step in reorienting our notions ofthe formal space for models of natural  language.
Any realsuccess in the theoretical models of human language dependson the development of appropriate mathemat ica l  concepts andon closing the gap between formal language and naturallanguage theory.
One of the first steps in this direction mustinvolve breaking the spell of CFGs and the ChomskyHierarchy.
The CFQGs seem to be cut out for this task.Moreover, the idea that  queues rather  than  stacks areinvolved in human language appears to be correct, and thismore general result  is independent of the l imitations ofCFQGs.
However, given my stated goals for formal models,it is necessary to develop models such as CFQGs beforeproceeding to more complex ones precisely in order to developan appropriate notion of formal space within which we willhave to work.The other main point addressed in this paper, the needto model human languages as families of formal languages oras formal languages with indefinite terminal  vocabularies, isintended in the same spirit.
The allure of identifying formallanguage theoretic cor~cepts with linguistic ones in thesimplest possible way is hard to overcome, but  it must  be if88we are to get any meaningful results about natural anguagesthrough the formal route.
It will, again, be necessary to domore work on these concepts, but it is beginning to look asthough we have found the right direction.REFERENCESCarlson, Greg N. 1983.
MarkingConstituents.
L inguist ic Categories (Frank Heny and BarryRichards, eds.
), 1: Categories, 69-98.
Dordrecht: Reidel.Chomsky, Noam.
1963.
Formal Properties ofGrammars.
Handbook of Mathematical  Psychology(R. Duncan Luce at al., eds.
), 2: 323-418.
New York: Wiley.Culy, Christopher.Vocabulary of Bambara.345-351.1985.
The Complexity of theLinguistics and Philosophy, 8:Daly, R. T. 1974.
Appl icat ions of the MathematicalTheory of Linguistics.
The Hague: Mouton.Gazdar, Gerald, and Geoffrey K. Pullum.
1985.Computationally Relevant Properties of Natural Languagesand Their Grammars.
New Generat ion Computing, 3: 273-306.Higginbotham, James.
1984.
English is not a Context-free Language.
Linguist ic Inquiry,  15: 225-234.Kac, Michael B.
To appear.
Surface Transitivity andContext-freeness.Kac, Michael B., Alexis Manaster-Ramer, and WilliamC.
Rounds.
To appear.
Simultaneous-distributiveCoordination and Context-freeness.
Computat ionalLinguistics.Langendoen, D. Terence.
1977.
On the Inadequacy ofType-3 and Type-2 Grammars for HumanLanguages.
Studies in Descriptive and HistoricalLinguistics: Festschri f t  for Winfred P. Lehmann (PaulHopper, ed.
), 159-171.
Amsterdam: Benjamins.Langendoen, D. Terence, and Paul M. Postal.
1984.Comments on Pullum's Criticisms.
CL, 8: 187-188.Levelt, W. J. M. 1974.
Formal Grammars inLinguistics and Psychol inguist ics.
The Hague: Mouton.Manaster-Ramer, Alexis.
1983.
The Soft FormalUnderbelly of Theoretical Syntax.
CLS, 19: 256-262.Manaster-Ramer, Alexis.
To appear a. Dutch as aFormal Language.
Linguistics and Phi losophy.Manaster-Ramer, Alexis.
To appear b. Subject-verbAgreement in Respective Coordinations in English.Manaster-Ramer, Alexis, and Michael B. Kac.
1985.Formal Languages and Linguistic Universals.
Paper read atthe Milwaukee Symposium on Typology and Universals.Postal, Paul M. 1964.
Limitations of Phrase StructureGrammars.
The Structure of Language: Readings in thePhi losophy of Language (Jerry A. Fodor and JerroldJ.
Katz, eds.
), 137-151.
Englewood Cliffs, NJ: Prentice-Hall.Postal, Paul M., and D. Terence Langendoen.
1984.English and the Class of Context-free Languages.
CL,10:177-181.Pullum, Geoffrey K., and Gerald Gazdar.
1982.
NaturalLanguages and Context-free Languages.
Linguistics andPhilosophy, 4: 471-504.Pullum, Geoffrey K. 1984a.
On Two Recent Attempts toShow that English is not a CFL.
CL, 10: 182-186.Pullum, Geoffrey K. 1984b.
Syntactic and SemanticParsability.
Proceedings of COLING84, 112-122.Stanford, CA: ACL.Rounds, William C., Alexis Manaster-Ramer, and JoyceFriedman.
To appear.
Finding Natural Languages a Home inFormal Language Theory.
Mathemat ics  of Language(Alexis Manaster-Ramer, ed.).
Amsterdam: JohnBenjamins.Shieber, Stuart M. 1985.
Evidence against the Context-freeness of Natural Language.
Linguistics and Phi losophy,8: 333-343.89
