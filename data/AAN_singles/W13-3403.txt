Proceedings of the Fourth Workshop on Teaching Natural Language Processing, pages 18?26,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsIntroducing Computational Concepts in a Linguistics OlympiadPatrick LittellDepartment of LinguisticsUniversity of British ColumbiaVancouver, BC V6T1Z4, Canadalittell@interchange.ubc.caLori LevinLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213, USAlsl@cs.cmu.eduJason EisnerComputer Science DepartmentJohns Hopkins UniversityBaltimore, MD 21218, USAjason@cs.jhu.eduDragomir R. RadevDepartment of EECSSchool of Informationand Department of LinguisticsUniversity of Michiganradev@umich.eduAbstractLinguistics olympiads, now offeredin more than 20 countries, providesecondary-school students a compellingintroduction to an unfamiliar field.
TheNorth American Computational Lin-guistics Olympiad (NACLO) includescomputational puzzles in addition topurely linguistic ones.
This paper ex-plores the computational subject matterwe seek to convey via NACLO, as wellas some of the challenges that arisewhen adapting problems in computationallinguistics to an audience that may haveno background in computer science,linguistics, or advanced mathematics.We present a small library of reusabledesign patterns that have proven usefulwhen composing puzzles appropriate forsecondary-school students.1 What is a Linguistics Olympiad?A linguistics olympiad (LO) (Payne and Derzhan-ski, 2010) is a puzzle contest for secondary-schoolstudents in which contestants compete to solveself-contained linguistics problem sets.
LOs havetheir origin in the Moscow Traditional Olympiadin Linguistics, established in 1965, and have sincespread around the world; an international contest(http://www.ioling.org) has been heldyearly since 2003.In an LO, every problem set is self-contained,so no prior experience in linguistics is necessaryto compete.
In fact, LO contests are fun and re-warding for exactly this reason: by the end of thecontest, contestants are managing to read hiero-glyphics, conjugate verbs in Swahili, and performother amazing feats.
Furthermore, they have ac-complished this solely through their own analyti-cal abilities and linguistic intuition.Based on our experience going into highschools and presenting our material, this ?linguis-tic?
way of thinking about languages almost al-ways comes as a novel surprise to students.
Theylargely think about languages as collections ofknown facts that you learn in classes and frombooks, not something that you can dive into andfigure out for yourself.
This is a hands-on antidoteto the common public misconception that linguistsare fundamentally polyglots, rather than languagescientists, and students come out of the experiencehaving realized that linguistics is a very differentfield (and hopefully a more compelling one) thanthey had assumed it to be.2 Computational Linguistics at the LOOur goal, since starting the North AmericanComputational Linguistics Olympiad (NACLO) in2007 (Radev et al 2008), has been to explore howthis LO experience can be used to introduce stu-dents to computational linguistics.
Topics in com-putational linguistics have been featured before inLOs, occasionally in the Moscow LO and withsome regularity in the Bulgarian LO.Our deliberations began with some trou-bling statistics regarding enrollments in computerscience programs (Zweben, 2013).
Between2003 and 2007 enrollments in computer sciencedropped dramatically.
This was attributed in partto the dip in the IT sector, but it also stemmed in18part from a perception problem in which teenagersview computer science careers as mundane andboring: ?I don?t want to be Dilbert,1 sitting in acubicle programming payroll software my wholelife.?
This is an unrealistically narrow percep-tion of the kinds of problems computer scientiststackle, and NACLO began in part as a way to pub-licize to teenagers that many interesting problemscan be approached using computational methods.Although enrollments are not yet back to the2003 levels, there has been a sharp increase since2007 (Zweben, 2013).
The resurgence can be at-tributed in part to the strength of the IT sector, butalso to the realization that computer science is rel-evant to almost every area of science and technol-ogy (Thibodeau, 2013).
NACLO aims to be partof this trend by showing students that computerscience is used in studying fascinating problemsrelated to human language.Even ?traditional?
LO puzzles are inherentlycomputational in that they require pattern recog-nition, abstraction, generalization, and establish-ing and pruning a solution space.
However, wealso want to teach computational linguistics moreexplicitly.
NACLO puzzles have featured a widevariety of topics in computational linguistics andcomputer science; they may focus on the applica-tion itself, or on concepts, tools, and algorithmsthat underlie the applications.
Broadly, computa-tional LO topics fall into three types, summarizedbelow.2.1 Technological applicationsNACLO has included puzzles on technologies thatmost people are familiar with, including spellchecking, information retrieval, machine transla-tion, document summarization, and dialogue sys-tems.
In a typical applications puzzle, the contes-tants would discover how the application works,how it handles difficult cases, or what its limita-tions are.
In ?Summer Eyes?
(Radev and Hester-berg, 2009), the contestant discovers the featuresthat are used for selecting sentences in a sum-marization program, including the position of asentence in the article, the number of words thesentence shares with the title, etc.
In ?Spring-ing Up Baby?
(Srivastava and Bender, 2008) and?Running on MT?
(Somers, 2011), contestants ex-plore word sense disambiguation in the context of1An engineer in the eponymous American comic strip,Dilbert has a famously dysfunctional workplace and unre-warding job.machine translation, while ?Tiger Tale?
(Radev,2011) highlights some realistic sources of knowl-edge for machine translation such as cognatesand cross-language syntactic similarities.
?ThornyStems?
(Breck, 2008) and ?A fox among the h?
(Littell, 2012b) introduce stemming.2.2 Formal grammars and algorithmsSome puzzles introduce the formal tools of com-putational linguistics and linguistic concepts thatare important in computational linguistics, of-ten in a whimsical way.
For example, ?Sk8Parsr?
(Littell, 2009) introduces shift-reduce pars-ing by means of a hypothetical skateboardingvideo game.
?Aw-TOM-uh-tuh?
(Littell, 2008)introduces a finite-state machine that determineswhich strings form legal words in the Rotokaslanguage.
?Orwellspeak?
(Eisner, 2009) askssolvers to modify a simple context-free grammar,and then to discover that a 4-gram model can-not model this language without precision or re-call errors.
?Twodee?
(Eisner, 2012) invents atwo-dimensional writing system, shown below, asa vehicle for helping students discover parsingambiguity?and production ambiguity?withoutthe full formal apparatus of grammars, nontermi-nals, or tree notation.
?The Little Engine That Could.
.
.
Read?
(Littelland Pustejovsky, 2012) explores quantifier mono-tonicity, while ?Grice?s Grifter Gadgets?
(Boyd-Graber, 2013) covers Grice?s maxims as part of thespecification of a computerized game assistant.2.3 Computational conceptsNACLO puzzles have also introduced computa-tional concepts that go beyond computational lin-guistics.
?Texting, Texting, One Two Three?
(Lit-tell, 2010b) and ?The Heads and Tails of Huff-man?
(DeNero, 2013) introduce data compression.
?One, Two, Tree?
(Smith et al 2012) introducesthe Catalan numbers and other recurrences via bi-nary bracketing of ambiguous compound nouns.19?Nok-nok?
(Fink, 2009) introduces Levenshteindistance by describing a hypothetical typing tutorfor very bad spellers.3 The Challenge of WritingComputational ProblemsTo achieve our goals, it becomes necessary towrite computational linguistics puzzles in such away that they are self-contained, requiring no priorexperience in linguistics, computer science, or ad-vanced math.
This has proven very difficult, butnot impossible, and in the past seven years we havemanaged to learn a lot about how to (and how notto) write them.Perhaps the hardest part of writing any LO puz-zle is that authors have to remove themselves fromtheir knowledge and experience: to forget techni-cal definitions of ?phrase?
or ?noun?
or ?string?
or?function,?
and to forget the facts and insights andhistory that formed our modern understanding ofthese.
This is doubly hard when it comes to puz-zles involving computational methods.
The abilityto write an algorithm that a computer could actu-ally interpret is a specialized skill that we learnedthrough education, and it is very, very hard to backup and imagine what it would be like to not beable to think like this.
(It is almost like trying toremember what it was like to not be able to read?not simply not knowing a particular alphabet orlanguage, but not even understanding how readingwould work.
)Here is an illustration of an interesting butnonetheless inappropriate LO puzzle:Here are fourteen English compoundwords:birdhouse houseworkblackbird tablespoonblackboard teacupboardroom teaspoonboathouse workhousecupboard workroomhouseboat worktableEven if you didn?t know any English, youcould probably determine by looking atthis list which English words were usedto make up the compounds: ?black?,?bird?, ?board?, etc...How would you do this if you were acomputer?This task, although potentially appropriate for aprogramming competition, is inappropriate for anLO: the intended task requires some prior knowl-edge about what computers can and cannot do.Note that nowhere in the puzzle itself are the prop-erties of this imaginary computer specified.
It isassumed that the solver knows roughly the state ofmodern computing machinery and what kinds ofinstructions it can execute.Imagine for a moment what a right answer tothis puzzle would look like, and then picture whata wrong answer might look like.
Your right answerwas probably an algorithm that could run on an ab-stract computer with capabilities very much likereal computers.
The wrong answer probably madeincorrect assumptions about what sorts of opera-tions computers are capable of, or treated enor-mously complex operations as if they were primi-tive.2The problem with the above puzzle is that it isvery open-ended, and in the absence of a largebody of shared knowledge between the author andthe solver, the solver cannot know what it is theauthor wants or when they have solved it to theauthor?s satisfaction.In order to avoid this, it is best to set up the puz-zle so that the ?search space?
for possible answersis relatively constrained, and the ?win?
conditionsare clear.
Ideally, if a contestant has solved a puz-zle, they should know they have solved it, and thusbe able to move on confidently to the next puz-zle.3 In this respect, LO puzzles are akin to cross-word puzzles, problems from other Olympiads, oronline puzzle games.
This feeling of accomplish-ment is key to the kind of rewarding learning ex-perience that have made LOs so successful.4 Design Patterns for CL PuzzlesOver the years, we have found several reliablestrategies for turning ideas and topics from com-putational linguistics into solvable, rewarding puz-2Keep in mind that today?s contestants were born in thelate 1990s.
They are unlikely to even remember a world with-out ubiquitous Internet and powerful natural language search.Their conception of ?what computers basically do?
is not nec-essarily going to be the same as those of us who encounteredcomputers when they were still recognizable as a kind of so-phisticated calculator.3This is not to say, however, that only those who solve apuzzle in its entirety should feel accomplished or rewarded.The best puzzles often contain layers of mysteries: it may bethat only a few will solve every mystery in the puzzle, butmost contestants come away with the satisfaction of havingdiscovered something.20zles.Not every computational puzzle makes use ofthese?some are entirely unique?but many do.In addition, these strategies are not mutually ex-clusive; many computational puzzles utilize sev-eral of these at once.
For example, a ?Broken Ma-chine?
puzzle may then present the solver with a?Troublemaker?
task, or an ?Assembly Required?machine may, upon assembly, turn out to be a?Broken?
one.4.1 Assembly RequiredThe solver is presented with a task to complete,and also a partially specified algorithm for doingso.
The partial specification illustrates the de-sired formal notation and the model of computa-tion.
But it may be missing elements, or the or-dering or relationship between the elements is un-clear, or some other aspect of the system remainsunfinished.
The solver is asked to complete thesystem so that it performs the appropriate task orproduces the appropriate outputs.For example, NACLO 2008 included a puzzleon stemming, ?Thorny Stems?
(Breck, 2008), inwhich contestants help develop an algorithm toisolate the stems of various words.
In this puzzle,the solver is not required to invent an algorithmex nihilo; this would merely have rewarded thosewho already understand algorithms, not introducealgorithmic thinking to neophytes.
Instead, theoverall structure of the intended algorithm (an or-dered sequence of if-thens) is made explicit, andthe solver?s task is to fill in the details:Rule 1: If a word ends in , thenreplace with to form thestem.Rule 2: If a word ends in , thenreplace with to form thestem.In another puzzle from the same contest, ?Aw-TOM-uh-tuh?
(Littell, 2008), the solver mustcomplete an unfinished finite-state automaton sothat it performs a language recognition task.
Thesolver is given a brief introduction to FSAs and asimple sample FSA, and then given an incompleteFSA whose labels lack edges.
The solver?s task isto place the labels on the correct edges so that theFSA accepts certain inputs and rejects others.Other examples of the ?Assembly Required?pattern can be found in the puzzles ?Sk8 Parsr?
(Littell, 2009), ?The Heads and Tails of Huff-man?
(DeNero, 2013), and ?BrokEnglish!?
(Lit-tell, 2011).4.2 Black BoxThe solver is presented with the inputs to a systemand the outputs, and must work out how the systemgenerated the outputs.
Unlike in the ?AssemblyRequired?
pattern, little or no information aboutthe algorithm is provided to the solver; the solver?sfundamental task is to characterize this unknownalgorithm as thoroughly as possible.For example, NACLO 2010 featured a puzzleon Huffman text compression, ?Texting, Texting,One Two Three?
(Littell, 2010b), in which an un-specified algorithm converts strings of letters tostrings of numbers:Testing testing = 33222143224142341-1222143224142341331Does anyone copy = 33233322143131-42343324221124232342343331Working out the basic number-letter correspon-dences is relatively straightforward, but the realpuzzle is working out the rationale behind thesecorrespondences.
Some of the answers require let-ters (like ?r?
and ?x?)
that do not occur anywherein the data, but can be deduced once the system asa whole is fully understood.NACLO 2009 featured a puzzle on Levenshteindistance, ?Nok-nok!?
(Fink, 2009), that alsoused this pattern.
In it, a spell-checker is rat-ing how well (or poorly) a user has spelled a word.21User Input Correct word Outputowll owl ?almost right?ples please ?quite close?reqird required ?quite close?plez please ?a bit confusing?mispeln misspelling ?very confusing?The solver?s task is to work out the algorithm suf-ficiently to predict how the system would respondto novel inputs.Other examples of the ?Black Box?
pattern canbe found in ?The Deschamps Codice?
(Piperski,2012) and ?The Little Engine that Could.
.
.
Read?
(Littell and Pustejovsky, 2012).Depending on the intended algorithm, the?Black Box?
pattern may or may not be appro-priate.
This pattern works best when the natureof the transformation between input and output isrelatively straightforward and the purpose of thetransformation is relatively clear.
In the Huff-man coding puzzle, for example, the nature ofthe transformation is entirely obvious (replace let-ters with number sequences) and thus the solutionspace of the puzzle is relatively constrained (figureout which letters correspond to which number se-quences and then try to figure out why).
In thespell-checking puzzle, the purpose of the trans-formation is easily understood, giving the solvera head start on figuring out which features of theinput the algorithm might be considering.When the nature of the transformation is lessobvious?for example, the generation of numbersof unclear significance, rating some unknown as-pect of a text passage?
?Black Box?
is not as ap-propriate as the other patterns.
The potential prob-lem is that not only must the solver come up withan algorithm on their own, they must come up withthe same algorithm the author did.
Given a com-plicated algorithm, even small implementation de-tails may lead to very different outputs, so a solvercan even have found a basically correct solutionbut nevertheless not managed to produce the in-tended outputs.In such cases, the ?Assembly Required?
or?Broken Machine?
patterns are potentially moreappropriate.4.3 Broken MachineThe solver is presented with a system that purportsto perform a particular task, but actually fails onparticular inputs.
The solver is tasked with fig-uring out what went wrong and, potentially, fixingthe system so that it works.
In some cases, the sys-tem simply has an error in it; in others, the systemis correct but cannot handle certain difficult cases.NACLO has featured a wide variety of brokenmachines, often with humorous outputs.
?Help myCamera!?
(Bender, 2009) features a dialogue sys-tem that could not correctly resolve pronoun refer-ences:Human: ?There?s this restaurant onBancroft that?s supposed to be reallygood that I heard about from my mother.Can you help me find it?
?Computer: ?Where did you last see yourmother???BrokEnglish!?
(Littell, 2011) features a run-away script that replaced certain ISO 639-1 codeswith language names:Hebrewy, ChamorRomanianrICHebre-wcHebrewnlandic!
whEnglish youget a FrEnglishcHebrewe momEnglisht,cHebrewck out thICHebrewcHebrewn-landic niCHebrewcHebrewn little pRo-maniangram i wRomaniante.Solvers are then tasked with determining whythis script produced such a bizarre output, and ad-ditionally tasked with determining in what orderthe replacements had to have occurred in order toget this exact output.?Orwellspeak?
(Eisner, 2009) involves acontext-free grammar that produces sentencesthat were grammatically correct but counter to theideals of a fictional totalitarian Party.
The solvermust rewrite the grammar so that only ?correct?thoughts can be uttered.
In the second part of thepuzzle, the solver must show that Markov modelswould be inherently broken.Other examples of ?Broken Machines?
are ?TheLost Tram?
(Iomdin, 2007), ?Sk8 Parsr?
(Lit-tell, 2009), ?A fox among the h?
(Littell, 2012b),?The Little Engine that Could.
.
.
Read?
(Littell andPustejovsky, 2012), and ?Grice?s Grifter Gadgets?
(Boyd-Graber, 2013).4.4 TroublemakerThe solver is presented with a system and somesample inputs and outputs, and must discover aninput that causes the system to fail, or produce out-puts that are strange, suboptimal, or have some un-usual property.22Few puzzles make use of only the ?Trouble-maker?
pattern.
Many are basically ?AssemblyRequired?
or ?Broken Machine?
puzzles that use a?Troublemaker?
task to get the contestant thinkingabout the ways in which the system is limited orimperfect.
They are also often creative?the con-testant usually invents their own inputs?and thuscan serve as a refreshing change of pace.4NACLO 2009 featured a ?Broken Machine?puzzle about shift-reduce parsing (?Sk8 Parsr?
)(Littell, 2009), couched in terms of a fictionalskateboarding videogame.
The solver is given analgorithm by which button presses are transformedinto skateboard trick ?combos?
like those shownbelow, but many well-formed ?combos?
cannotcorrectly be parsed due to a shift-reduce conflict.The solver is given an example of one such classof inputs, and then asked to discover other classesof inputs that likewise fail.?Troublemaker?
puzzles are not alwayscouched in terms of bugs.
?This problem is pretty// easy?
(Radev, 2007a) asks solvers to constructeye-catching garden path sentences.
In theHuffman text compression puzzle detailed above(?Texting, Texting, One Two Three?)
(Littell,2010b), a ?Troublemaker?
task is introduced toget contestants thinking about the limits of com-pression.
Although the compression algorithmis not ?broken?
in any way, any compressionalgorithm will ?fail?
on some possible input andreturn an output longer than the input, and thesolver is tasked to discover such an input.?Troublemaker?
tasks can also be found in?Grammar Rules?
(Schalley and Littell, 2013) and?Yesbot?
(Mitkov and Littell, 2013).4If the ?Troublemaker?
task asks for an input with a par-ticular formal property (i.e., a sentence generated or not gen-erated from a particular grammar), automated grading scriptscan determine the correctness of the answer without humanintervention.
This means that contestants can get a chanceto enter ?creative?
answers even in large contests (like theNACLO Open Round) that utilize automatic grading.4.5 JabberwockNot all puzzle types revolve around abstract ma-chines.
Another recurring puzzle type, the ?Jab-berwock?, involves asking the solver to puzzle outthe syntactic or semantic properties of unknownwords.
Often these words are nonsense words, butthis puzzle type can also work on natural languagedata.
To perform this task, solvers often have touse the same methods that a computer would.
?We are all molistic in a way?
(Radev, 2007b)asks solvers to infer the polarity of various non-sense adjectives based on a series of sentences.5The teacher is danty and cloovy.Mary is blitty but cloovy.Strungy and struffy, Diane was a plea-sure to watch.Even though weasy, John is strungy.Carla is blitty but struffy.The solver must work out from sentences suchas these whether words like ?danty?
and ?weasy?have positive or negative associations.
In doing so,the solver has essentially constructed and solved asemi-supervised learning problem.In ?Gelda?s House of Gelbelgarg?
(Littell,2010a), solvers are presented with a page of fab-ricated restaurant reviews for an entirely fictionalcuisine:?A hidden gem in Lower Uptown!
Getthe fa?rsel-fo?rsel with gorse-weebel andyou?ll have a happy stomach for a week.And top it off with a flebba of sweet-bolger while you?re at it!
?5The list given here includes a subset of the examples usedin the real puzzle in 2007.23?I found the food confusing and disori-enting.
Where is this from?
I randomlyordered the fa?rsel-fo?rsel and had to sendthem back!
?Using various grammatical cues (article and pro-noun choice, ?less?
vs.
?fewer?, etc.
), solvers haveto sort the items into things most likely to be dis-crete, countable objects, things most likely to beliquids or masses, and things most likely to be con-tainers or measures.This type of puzzle often violates the commonLO restriction on using nonsense words and made-up languages, but it is not always possible to basethis sort of puzzle on a completely unfamiliar lan-guage.
Many ?Jabberwock?
puzzles involve infer-ring syntactic or semantic information about un-known words in an otherwise known language.The two puzzles above therefore require contes-tants to consult their own intuitions about English.These puzzles would have been entirely different(and prohibitively difficult) if the language hadbeen completely unfamiliar.Other Jabberwock puzzles include ?Tiger Tale?
(Radev, 2011) and ?Cat and Mouse Story?
(Littell,2012a).4.6 Combinatorial ProblemsSome puzzles effectively force the solver to designand run an algorithm, to get an answer that wouldbe too difficult to compute by brute force.
Suchpuzzles involve computational thinking.
But sincethe solver only has to give the output of the algo-rithm, there is no need to agree on a type of com-puting device or a notation for writing algorithmsdown.Such puzzles include combinatorial tasks thatinvolve the counting, maximization, or existenceof linguistic objects.
They require mathematicaland algorithmic skills (just as in math or program-ming competitions), and demonstrate how theseskills apply to linguistics or NLP.Portions of ?One, Two, Tree?
(Smith etal., 2012) and ?Twodee?
(Eisner, 2012) requiresolvers to count all ways to parse a sentence, orto count all sentences of a certain type.
Becausethe counts are large, the solver must find the pat-tern, which involves writing down a closed-formformula such as 2n or a more complex dynamicprogramming recurrence.5 ConclusionsResearchers and teachers from the ACL commu-nity are invited to contact the NACLO organizingcommittee at naclo14org@umich.edu6 withtheir ideas for new puzzles or new types of puz-zles.
All of the past puzzles and solutions canbe browsed at http://www.naclo.cs.cmu.edu/practice.html.
In general, puzzles inRound 1 each year should be easier and automat-ically gradable.
Puzzles in Round 2 permit moreinvolved questions and answers; this is a smallercontest in which the top Round 1 scorers (usu-ally, the top 10 percent) can qualify for the Inter-national Linguistic Olympiad.Thus far, NACLO?s computational puzzles havereached at least 6,000 students at more than 150testing sites7 in the U.S. and Canada, as well as atleast 10,000 students in the three other English-language countries that share LO puzzles withNACLO.We observe that most computational puzzles donot need obscure languages, staying on the contes-tant?s home turf of English and technology.
Thisdoes not mean, however, that the computationalpuzzles are purely formal and lack linguistic con-tent.
Some of them in fact probe subtle facts aboutEnglish (the introspective method in linguistics),and some of them cover areas of linguistics thatare underserved by traditional LO puzzles.
Tra-ditional LO puzzles instead ask the solver to sortout vocabulary and basic morphophonological ororthographic patterns in a mystery language (thefieldwork method in linguistics).
Students who en-joy ?top-down?
thinking or who are deeply inter-ested in ?how to do things with words?
may preferthe former kind of puzzle.Competitions are popular in many North Amer-ican high schools, perhaps in part as a way to im-press college admissions officers.
We have ex-ploited this to give students a taste of our inter-disciplinary field before they choose a college ma-jor.
Some students may be specifically attracted toNACLO by the word ?computational?
or the word?linguistics,?
or may be intrigued by their juxta-position.
Many NACLO participants reveal thatthey had started to study linguistics on their ownbefore encountering NACLO, and have welcomed6Or nacloXXorg@umich.edu, where XX is the lasttwo digits of the calendar year of the upcoming February.7NACLO tests have been given at more than 100 highschools and more than 50 university sites; the latter are opento students from all local high schools.24NACLO as an outlet for their enthusiasm and aplace where they can interact with other studentswho have the same interests.NACLO?s past puzzles remain freely availableon the web for anyone who is interested.
Twovolumes of NACLO-style puzzles (most of themfrom real competitions), edited by program chairDragomir Radev, have recently been published bySpringer (Radev, 2013a; Radev, 2013b).
Adulthobbyists and home-schooled students may dis-cover computational linguistics through encoun-tering these puzzles.
Avid LO contestants usethem to prepare for upcoming contests.
Finally,high school and college teachers can use themas the basis of whole-class or small-group class-room activities that expose students to computa-tional thinking.AcknowledgmentsWe would like to thank the National Science Foun-dation for supporting NACLO through the fol-lowing grants: IIS0633871, BCS1137828, andIIS0838848.
We also express our gratitude to NSFprogram managers Tatiana Korelsky, Terry Lan-gendoen, and Joan Maling for their effort in ini-tiating and maintaining NACLO.
The LinguisticSociety of America and the North American Chap-ter of the Association for Computational Linguis-tics provide ongoing support.
Other sponsors, vol-unteers, and problem writers are too numerous toname.
They are listed on the contest booklets eachyear, which can be found on the NACLO web site:http://www.naclo.cs.cmu.edu.ReferencesEmily Bender.
2009.
Help my camera!
InNorth American Computational LinguisticsOlympiad 2009. http://www.naclo.cs.cmu.edu/assets/problems/naclo09F.pdf.Jordan Boyd-Graber.
2013.
Grice?s grifter gad-gets.
In North American Computational Linguis-tics Olympiad 2013. http://www.naclo.cs.cmu.edu/2013/NACLO2013ROUND2.pdf.Eric Breck.
2008.
Thorny stems.
In North Amer-ican Computational Linguistics Olympiad 2008.http://www.naclo.cs.cmu.edu/assets/problems/NACLO08h.pdf.John DeNero.
2013.
The heads and tails of Huff-man.
In North American Computational Linguis-tics Olympiad 2013. http://www.naclo.cs.cmu.edu/2013/NACLO2013ROUND1.pdf.Jason Eisner.
2009.
Orwellspeak.
In North Amer-ican Computational Linguistics Olympiad 2009.http://www.naclo.cs.cmu.edu/assets/problems/naclo09M.pdf.Jason Eisner.
2012.
Twodee.
In NorthAmerican Computational Linguistics Olympiad2013.
http://www.naclo.cs.cmu.edu/problems2012/NACLO2012ROUND2.pdf.Eugene Fink.
2009.
Nok-nok!
In North Ameri-can Computational Linguistics Olympiad 2009.http://www.naclo.cs.cmu.edu/assets/problems/naclo09B.pdf.Boris Iomdin.
2007.
The lost tram.
In North Amer-ican Computational Linguistics Olympiad 2007.http://www.naclo.cs.cmu.edu/assets/problems/naclo07 f.pdf.Patrick Littell and James Pustejovsky.
2012.The little engine that could.
.
.
read.
In NorthAmerican Computational Linguistics Olympiad2012.
http://www.naclo.cs.cmu.edu/problems2012/NACLO2012ROUND2.pdf.Patrick Littell.
2008.
Aw-TOM-uh-tuh.
In NorthAmerican Computational Linguistics Olympiad2008.
http://www.naclo.cs.cmu.edu/assets/problems/NACLO08i.pdf.Patrick Littell.
2009.
Sk8 parsr.
In North Ameri-can Computational Linguistics Olympiad 2009.http://www.naclo.cs.cmu.edu/assets/problems/naclo09G.pdf.Patrick Littell.
2010a.
Gelda?s house of gelbel-garg.
In North American Computational Linguis-tics Olympiad 2010. http://www.naclo.cs.cmu.edu/problems2010/A.pdf.Patrick Littell.
2010b.
Texting, texting, one twothree.
In North American Computational Linguis-tics Olympiad 2010. http://www.naclo.cs.cmu.edu/problems2010/E.pdf.Patrick Littell.
2011.
BrokEnglish!
In North Amer-ican Computational Linguistics Olympiad 2011.http://www.naclo.cs.cmu.edu/problems2011/E.pdf.Patrick Littell.
2012a.
Cat and mouse story.
In NorthAmerican Computational Linguistics Olympiad2012.
http://www.naclo.cs.cmu.edu/problems2012/NACLO2012ROUND1.pdf.Patrick Littell.
2012b.
A fox among theh.
In North American Computational Linguis-tics Olympiad 2012. http://www.naclo.cs.cmu.edu/problems2012/NACLO2012ROUND2.pdf.Ruslan Mitkov and Patrick Littell.
2013.
Grammarrules.
In North American Computational Linguis-tics Olympiad 2013. http://www.naclo.cs.cmu.edu/2013/NACLO2013ROUND2.pdf.25Thomas E. Payne and Ivan Derzhanski.
2010.
The lin-guistics olympiads: Academic competitions in lin-guistics for secondary school students.
In KristinDenham and Anne Lobeck, editors, Linguistics atschool.
Cambridge University Press.Alexander Piperski.
2012.
The Deschampscodice.
In North American Computational Linguis-tics Olympiad 2012. http://www.naclo.cs.cmu.edu/problems2012/NACLO2012ROUND2.pdf.Dragomir Radev and Adam Hesterberg.
2009.
Sum-mer eyes.
In North American Computational Lin-guistics Olympiad 2009. http://www.naclo.cs.cmu.edu/assets/problems/naclo09E.pdf.Dragomir R. Radev, Lori Levin, and Thomas E.Payne.
2008.
The North American Computa-tional Linguistics Olympiad (NACLO).
In Proceed-ings of the Third Workshop on Issues in TeachingComputational Linguistics, pages 87?96, Colum-bus, Ohio, June.
Association for Computational Lin-guistics.
http://www.aclweb.org/anthology/W/W08/W08-0211.Dragomir Radev.
2007a.
This problem is pretty //easy.
In North American Computational Linguis-tics Olympiad 2007. http://www.naclo.cs.cmu.edu/assets/problems/naclo07 h.pdf.Dragomir Radev.
2007b.
We are all molistic in away.
In North American Computational Linguis-tics Olympiad 2007. http://www.naclo.cs.cmu.edu/assets/problems/naclo07 a.pdf.Dragomir Radev.
2011.
Tiger tale.
In North AmericanComputational Linguistics Olympiad 2011. http://www.naclo.cs.cmu.edu/problems2011/F.pdf.Dragomir Radev, editor.
2013a.
Puzzles in Logic,Languages, and Computation: The Green Book.Springer: Berlin.Dragomir Radev, editor.
2013b.
Puzzles in Logic, Lan-guages, and Computation: The Red Book.
Springer:Berlin.Andrea Schalley and Patrick Littell.
2013.
Grammarrules!
In North American Computational Linguis-tics Olympiad 2013. http://www.naclo.cs.cmu.edu/2013/NACLO2013ROUND1.pdf.Noah Smith, Kevin Gimpel, and Jason Eisner.2012.
One, two, tree.
In North AmericanComputational Linguistics Olympiad 2012.http://www.naclo.cs.cmu.edu/problems2012/NACLO2012ROUND2.pdf.Harold Somers.
2011.
Running on MT.
In NorthAmerican Computational Linguistics Olympiad2011.
http://www.naclo.cs.cmu.edu/problems2011/A.pdf.Ankit Srivastava and Emily Bender.
2008.
Springingup baby.
In North American Computational Lin-guistics Olympiad 2008. http://www.naclo.cs.cmu.edu/assets/problems/prob08b.pdf.Patrick Thibodeau.
2013.
Computer science en-rollments soared last year, rising 30%, March.http://www.computerworld.com/s/article/9237459/Computer science enrollments soared last yearrising 30 .Stuart Zweben.
2013.
Computing degree and enroll-ment trends, March.
http://cra.org/govaffairs/blog/wp-content/uploads/2013/03/CRA Taulbee CSDegrees and Enrollment 2011-12.pdf.26
