Using a Corpus of Sentence Orderings Defined by Many Expertsto Evaluate Metrics of Coherence for Text StructuringNikiforos KaramanisComputational Linguistics Research GroupUniversity of Wolverhampton, UKN.Karamanis@wlv.ac.ukChris MellishDepartment of Computing ScienceUniversity of Aberdeen, UKcmellish@csd.abdn.ac.ukAbstractThis paper addresses two previously unresolved is-sues in the automatic evaluation of Text Structuring(TS) in Natural Language Generation (NLG).
First,we describe how to verify the generality of an exist-ing collection of sentence orderings defined by onedomain expert using data provided by additionalexperts.
Second, a general evaluation methodol-ogy is outlined which investigates the previouslyunaddressed possibility that there may exist manyoptimal solutions for TS in the employed domain.This methodology is implemented in a set of ex-periments which identify the most promising can-didate for TS among several metrics of coherencepreviously suggested in the literature.11 IntroductionResearch in NLG focused on problems related to TS fromvery early on, [McKeown, 1985] being a classic example.Nowadays, TS continues to be an extremely fruitful field ofdiverse active research.
In this paper, we assume the so-called search-based approach to TS [Karamanis et al, 2004]which employs a metric of coherence to select a text struc-ture among various alternatives.
The TS module is hypothe-sised to simply order a preselected set of information-bearingitems such as sentences [Barzilay et al, 2002; Lapata, 2003;Barzilay and Lee, 2004] or database facts [Dimitromanolakiand Androutsopoulos, 2003; Karamanis et al, 2004].Empirical work on the evaluation of TS has become in-creasingly automatic and corpus-based.
As pointed out by[Karamanis, 2003; Barzilay and Lee, 2004] inter alia, usingcorpora for automatic evaluation is motivated by the fact thatemploying human informants in extended psycholinguisticexperiments is often simply unfeasible.
By contrast, large-scale automatic corpus-based experimentation takes placemuch more easily.
[Lapata, 2003] was the first to present an experimental set-ting which employs the distance between two orderings to es-timate automatically how close a sentence ordering produced1Chapter 9 of [Karamanis, 2003] reports the study in more detail.by her probabilistic TS model stands in comparison to order-ings provided by several human judges.
[Dimitromanolaki and Androutsopoulos, 2003] derivedsets of facts from the database of MPIRO, an NLG systemthat generates short descriptions of museum artefacts [Isardet al, 2003].
Each set consists of 6 facts each of which cor-responds to a sentence as shown in Figure 1.
The facts ineach set were manually assigned an order to reflect what adomain expert, i.e.
an archaeologist trained in museum la-belling, considered to be the most natural ordering of thecorresponding sentences.
Patterns of ordering facts were au-tomatically learned from the corpus created by the expert.Then, a classification-based TS approach was implementedand evaluated in comparison to the expert?s orderings.Database fact Sentencesubclass(ex1, amph) ?
This exhibit is an amphora.painted-by(ex1, p-Kleo) ?
This exhibit was decorated bythe Painter of Kleofrades.painter-story(p-Kleo, en4049) ?
The Painter of Kleofradesused to decorate big vases.exhibit-depicts(ex1, en914) ?
This exhibit depicts a warrior performingsplachnoscopy before leaving for the battle.current-location(ex1, wag-mus) ?
This exhibit is currently displayedin the Martin von Wagner Museum.museum-country(wag-mus, ger) ?
The Martin von Wagner Museumis in Germany.Figure 1: MPIRO database facts corresponding to sentencesA subset of the corpus created by the expert in the previousstudy (to whom we will henceforth refer as E0) is employedby [Karamanis et al, 2004] who attempt to distinguish be-tween many metrics of coherence with respect to their use-fulness for TS in the same domain.
Each human ordering offacts in the corpus is scored by each of these metrics whichare then penalised proportionally to the amount of alternativeorderings of the same material that are found to score equallyto or better than the human ordering.
The few metrics whichmanage to outperform two simple baselines in their overallperformance across the corpus emerge as the most suitablecandidates for TS in the investigated domain.
This method-ology is very similar to the way [Barzilay and Lee, 2004]evaluate their probabilistic TS model in comparison to theapproach of [Lapata, 2003].Because the data used in the studies of [Dimitromanolakiand Androutsopoulos, 2003] and [Karamanis et al, 2004]are based on the insights of just one expert, an obvious un-resolved question is whether they reflect general strategiesfor ordering facts in the domain of interest.
This paper ad-dresses this issue by enhancing the dataset used in the twostudies with orderings provided by three additional experts.These orderings are then compared with the orders of E0 us-ing the methodology of [Lapata, 2003].
Since E0 is foundto share a lot of common ground with two of her colleaguesin the ordering task, her reliability is verified, while a fourth?stand-alone?
expert who uses strategies not shared by anyother expert is identified as well.As in [Lapata, 2003], the same dependent variable whichallows us to estimate how different the orders of E0 are fromthe orders of her colleagues is used to evaluate some of themetrics which perform best in [Karamanis et al, 2004].
Asexplained in the next section, in this way we investigate thepreviously unaddressed possibility that there may exist manyoptimal solutions for TS in our domain.
The results of thisadditional evaluation experiment are presented and emphasisis laid on their relation with the previous findings.Overall, this paper addresses two general issues: a) how toverify the generality of a dataset defined by one expert usingsentence orderings provided by other experts and b) how toemploy these data for the automatic evaluation of a TS ap-proach.
Given that the methodology discussed in this paperdoes not rely on the employed metrics of coherence or the as-sumed TS approach, our work can be of interest to any NLGresearcher facing these questions.The next section discusses how the methodology imple-mented in this study complements the methods of [Karamaniset al, 2004].
After briefly introducing the employed metricsof coherence, we describe the data collected for our exper-iments.
Then, we present the employed dependent variableand formulate our predictions.
In the results section, we statewhich of these predictions were verified.
The paper is con-cluded with a discussion of the main findings.2 An additional evaluation testAs [Barzilay et al, 2002] report, different humans often ordersentences in distinct ways.
Thus, there might exist more thanone equally good solution for TS, a view shared by almostall TS researchers, but which has not been accounted for inthe evaluation methodologies of [Karamanis et al, 2004] and[Barzilay and Lee, 2004].2Collecting sentence orderings defined by many experts inour domain enables us to investigate the possibility that theremight exist many good solutions for TS.
Then, the measureof [Lapata, 2003], which estimates how close two orderingsstand, can be employed not only to verify the reliability of E0but also to compare the orderings preferred by the assumedTS approach with the orderings of the experts.However, this evaluation methodology has its limitationsas well.
Being engaged in other obligations, the experts nor-mally have just a limited amount of time to devote to the2A more detailed discussion of existing corpus-based methodsfor evaluating TS appears in [Karamanis and Mellish, 2005].NLG researcher.
Similarly to standard psycholinguistic ex-periments, consulting these informants is difficult to extendto a larger corpus like the one used e.g.
by [Karamanis et al,2004] (122 sets of facts).In this paper, we reach a reasonable compromise by show-ing how the methodology of [Lapata, 2003] supplements theevaluation efforts of [Karamanis et al, 2004] using a similar(yet by necessity smaller) dataset.
Clearly, a metric of coher-ence that has already done well in the previous study, gainsextra bonus by passing this additional test.3 Metrics of coherence[Karamanis, 2003] discusses how a few basic notions of co-herence captured by Centering Theory (CT) can be used todefine a large range of metrics which might be useful for TSin our domain of interest.3 The metrics employed in the ex-periments of [Karamanis et al, 2004] include:M.NOCB which penalises NOCBs, i.e.
pairs of adjacentfacts without any arguments in common [Karamanis andManurung, 2002].
Because of its simplicity M.NOCBserves as the first baseline in the experiments of [Kara-manis et al, 2004].PF.NOCB, a second baseline, which enhances M.NOCBwith a global constraint on coherence that [Karamanis,2003] calls the PageFocus (PF).PF.BFP which is based on PF as well as the original for-mulation of CT in [Brennan et al, 1987].PF.KP which makes use of PF as well as the recent re-formulation of CT in [Kibble and Power, 2000].
[Karamanis et al, 2004] report that PF.NOCB outper-formed M.NOCB but was overtaken by PF.BFP and PF.KP.The two metrics beating PF.NOCB were not found to differsignificantly from each other.This study employs PF.BFP and PF.KP, i.e.
two of the bestperforming metrics of the experiments in [Karamanis et al,2004], as well as M.NOCB and PF.NOCB, the two previouslyused baselines.
An additional random baseline is also definedfollowing [Lapata, 2003].4 Data collection16 sets of facts were randomly selected from the corpus of[Dimitromanolaki and Androutsopoulos, 2003].4 The sen-tences that each fact corresponds to and the order defined byE0 was made available to us as well.
We will subsequentlyrefer to an unordered set of facts (or sentences that the factscorrespond to) as a Testitem.4.1 Generating the BestOrders for each metricFollowing [Karamanis et al, 2004], we envisage a TS ap-proach in which a metric of coherence M assigns a score to3Since discussing the metrics in detail is well beyond the scopeof this paper, the reader is referred to Chapter 3 of [Karamanis, 2003]for more information on this issue.4These are distinct from, yet very similar to, the sets of facts usedin [Karamanis et al, 2004].each possible ordering of the input set of facts and selects thebest scoring ordering as the output.
When many orderingsscore best, M chooses randomly between them.
Crucially, ourhypothetical TS component only considers orderings startingwith the subclass fact (e.g.
subclass(ex1, amph)in Figure 1) following the suggestion of [Dimitromanolakiand Androutsopoulos, 2003].
This gives rise to 5!
= 120orderings to be scored by M for each Testitem.For the purposes of this experiment, a simple algorithmwas implemented that first produces the 120 possible order-ings of facts in a Testitem and subsequently ranks them ac-cording to the scores given by M. The algorithm outputs theset of BestOrders for the Testitem, i.e.
the orderings whichscore best according to M. This procedure was repeated foreach metric and all Testitems employed in the experiment.4.2 Random baselineFollowing [Lapata, 2003], a random baseline (RB) was im-plemented as the lower bound of the analysis.
The randombaseline consists of 10 randomly selected orderings for eachTestitem.
The orderings are selected irrespective of theirscores for the various metrics.4.3 Consulting domain expertsThree archaeologists (E1, E2, E3), one male and two females,between 28 and 45 years of age, all trained in cataloguingand museum labelling, were recruited from the Departmentof Classics at the University of Edinburgh.Each expert was consulted by the first author in a separateinterview.
First, she was presented with a set of six sentences,each of which corresponded to a database fact and was printedon a different filecard, as well as with written instructions de-scribing the ordering task.5 The instructions mention that thesentences come from a computer program that generates de-scriptions of artefacts in a virtual museum.
The first sentencefor each set was given by the experimenter.6 Then, the expertwas asked to order the remaining five sentences in a coherenttext.When ordering the sentences, the expert was instructed toconsider which ones should be together and which shouldcome before another in the text without using hints other thanthe sentences themselves.
She could revise her ordering atany time by moving the sentences around.
When she was sat-isfied with the ordering she produced, she was asked to writenext to each sentence its position, and give them to the ex-perimenter in order to perform the same task with the nextrandomly selected set of sentences.
The expert was encour-aged to comment on the difficulty of the task, the strategiesshe followed, etc.5 Dependent variableGiven an unordered set of sentences and two possible order-ings, a number of measures can be employed to calculate the5The instructions are given in Appendix D of [Karamanis, 2003]and are adapted from the ones used in [Barzilay et al, 2002].6This is the sentence corresponding to the subclass fact.distance between them.
Based on the argumentation in [How-ell, 2002], [Lapata, 2003] selects Kendall?s ?
as the most ap-propriate measure and this was what we used for our analysisas well.
Kendall?s ?
is based on the number of inversionsbetween the two orderings and is calculated as follows:(1) ?
= 1?
2IPN = 1?2IN(N?1)/2PN stands for the number of pairs of sentences and N is thenumber of sentences to be ordered.7 I stands for the numberof inversions, that is, the number of adjacent transpositionsnecessary to bring one ordering to another.
Kendall?s ?
rangesfrom ?1 (inverse ranks) to 1 (identical ranks).
The higher the?
value, the smaller the distance between the two orderings.Following [Lapata, 2003], the Tukey test is employed to in-vestigate significant differences between average ?
scores.8First, the average distance between (the orderings of)9 twoexperts e.g.
E0 and E1, denoted as T (E0E1), is calculated asthe mean ?
value between the ordering of E0 and the order-ing of E1 taken across all 16 Testitems.
Then, we computeT (EXPEXP ) which expresses the overall average distancebetween all expert pairs and serves as the upper bound for theevaluation of the metrics.
Since a total of E experts gives riseto PE = E(E?1)2 expert pairs, T (EXPEXP ), is computedby summing up the average distances between all expert pairsand dividing the sum by PE .While [Lapata, 2003] always appears to single out a uniquebest scoring ordering, we often have to deal with many bestscoring orderings.
To account for this, we first compute theaverage distance between e.g.
the ordering of an expert E0and the BestOrders of a metric M for a given Testitem.
Inthis way, M is rewarded for a BestOrder that is close to theexpert?s ordering, but penalised for every BestOrder that isnot.
Then, the average T (E0M ) between the expert E0 andthe metric M is calculated as their mean distance across all16 Testitems.
Finally, yet most importantly, T (EXPM ) is theaverage distance between all experts and M. It is calculated bysumming up the average distances between each expert and Mand dividing the sum by the number of experts.
As the nextsection explains in more detail, T (EXPM ) is compared withthe upper bound of the evaluation T (EXPEXP ) to estimatethe performance of M in our experiments.RB is evaluated in a similar way as M using the 10 ran-domly selected orderings instead of the BestOrders for eachTestitem.
T (EXPRB) is the average distance between all ex-perts and RB and is used as the lower bound of the evaluation.7In our data, N is always equal to 6.8Provided that an omnibus ANOVA is significant, the Tukey testcan be used to specify which of the conditions c1, ..., cn measuredby the dependent variable differ significantly.
It uses the set of meansm1, ...,mn (corresponding to conditions c1, ..., cn) and the meansquare error of the scores that contribute to these means to calculatea critical difference between any two means.
An observed differ-ence between any two means is significant if it exceeds the criticaldifference.9Throughout the paper we often refer to e.g.
?the distance be-tween the orderings of the experts?
with the phrase ?the distancebetween the experts?
for the sake of brevity.E0E1: ** ** **0.692 E0E2: ** ** **0.717 E1E2: ** ** **0.758 E0E3:CD at 0.01: 0.338 0.258 E1E3:CD at 0.05: 0.282 0.300 E2E3:F(5,75)=14.931, p<0.000 0.192Table 1: Comparison of distances between the expert pairs6 PredictionsDespite any potential differences between the experts, one ex-pects them to share some common ground in the way they or-der sentences.
In this sense, a particularly welcome result forour purposes is to show that the average distances betweenE0 and most of her colleagues are short and not significantlydifferent from the distances between the other expert pairs,which in turn indicates that she is not a ?stand-alone?
expert.Moreover, we expect the average distance between the ex-pert pairs to be significantly smaller than the average distancebetween the experts and RB.
This is again based on the as-sumption that even though the experts might not follow com-pletely identical strategies, they do not operate with absolutediversity either.
Hence, we predict that T (EXPEXP ) will besignificantly greater than T (EXPRB).Due to the small number of Testitems employed in thisstudy, it is likely that the metrics do not differ significantlyfrom each other with respect to their average distance fromthe experts.
Rather than comparing the metrics directly witheach other (as [Karamanis et al, 2004] do), this study com-pares them indirectly by examining their behaviour with re-spect to the upper and the lower bound.
For instance, al-though T (EXPPF.KP ) and T (EXPPF.BFP ) might not besignificantly different from each other, one score could be sig-nificantly different from T (EXPEXP ) (upper bound) and/orT (EXPRB) (lower bound) while the other is not.We identify the best metrics in this study as the ones whoseaverage distance from the experts (i) is significantly greaterfrom the lower bound and (ii) does not differ significantlyfrom the upper bound.107 Results7.1 Distances between the expert pairsOn the first step in our analysis, we computed the T scorefor each expert pair, namely T (E0E1), T (E0E2), T (E0E3),T (E1E2), T (E1E3) and T (E2E3).
Then we performed all15 pairwise comparisons between them using the Tukey test,the results of which are summarised in Table 1.11The cells in the Table report the level of significance re-turned by the Tukey test when the difference between two10Criterion (ii) can only be applied provided that the average dis-tance between the experts and at least one metric Mx is found tobe significantly lower than T (EXPEXP ).
Then, if the average dis-tance between the experts and another metric My does not differsignificantly from T (EXPEXP ), My performs better than Mx.11The Table also reports the result of the omnibus ANOVA, whichis significant: F(5,75)=14.931, p<0.000.E0E1: ** ** **0.692 E0E2: ** ** **0.717 E1E2: ** ** **0.758 E0RB :CD at 0.01: 0.242 0.323 E1RB :CD at 0.05: 0.202 0.347 E2RB :F(5,75)=18.762, p<0.000 0.352E0E3:0.258 E1E3:0.300 E2E3:CD at 0.01: 0.219 0.192 E3RB :CD at 0.05: 0.177 0.302F(3,45)=1.223, p=0.312Table 2: Comparison of distances between the experts (E0,E1, E2, E3) and the random baseline (RB)distances exceeds the critical difference (CD).
Significancebeyond the 0.05 threshold is reported with one asterisk (*),while significance beyond the 0.01 threshold is reported withtwo asterisks (**).
A cell remains empty when the differencebetween two distances does not exceed the critical difference.For example, the value of T (E0E1) is 0.692 and the value ofT (E0E3) is 0.258.
Since their difference exceeds the CD atthe 0.01 threshold, it is reported to be significant beyond thatlevel by the Tukey test, as shown in the top cell of the thirdcolumn in Table 1.As the Table shows, the T scores for the distance betweenE0 and E1 or E2, i.e.
T (E0E1) and T (E0E2), as well as theT for the distance between E1 and E2, i.e.
T (E1E2), are quitehigh which indicates that on average the orderings of the threeexperts are quite close to each other.
Moreover, these T scoresare not significantly different from each other which suggeststhat E0, E1 and E2 share quite a lot of common ground inthe ordering task.
Hence, E0 is found to give rise to similarorderings to the ones of E1 and E2.However, when any of the previous distances is comparedwith a distance that involves the orderings of E3 the differ-ence is significant, as shown by the cells containing two as-terisks in Table 1.
In other words, although the orderings ofE1 and E2 seem to deviate from each other and the orderingsof E0 to more or less the same extent, the orderings of E3stand much further away from all of them.
Hence, there ex-ists a ?stand-alone?
expert among the ones consulted in ourstudies, yet this is not E0 but E3.This finding can be easily explained by the fact that by con-trast to the other three experts, E3 followed a very schematicway for ordering sentences.
Because the orderings of E3manifest rather peculiar strategies, at least compared to the or-derings of E0, E1 and E2, the upper bound of the analysis, i.e.the average distance between the expert pairs T (EXPEXP ),is computed without taking into account these orderings:(2) T (EXPEXP ) = 0.722 = T (E0E1)+T (E0E2)+T (E1E2)37.2 Distances between the experts and RBAs the upper part of Table 2 shows, the T score between anytwo experts other than E3 is significantly greater than theirdistance from RB beyond the 0.01 threshold.
Only the dis-tances between E3 and another expert, shown in the lowersection of Table 2, are not significantly different from the dis-tance between E3 and RB.Although this result does not mean that the orders of E3are similar to the orders of RB,12 it shows that E3 is roughlyas far away from e.g.
E0 as she is from RB.
By contrast,E0 stands significantly closer to E1 than to RB, and the sameholds for the other distances in the upper part of the Table.In accordance with the discussion in the previous section, thelower bound, i.e.
the overall average distance between theexperts (excluding E3) and RB T (EXPRB), is computed asshown in (3):(3) T (EXPRB) = 0.341 = T (E0RB)+T (E1RB)+T (E2RB)37.3 Distances between the experts and each metricSo far, E3 was identified as an ?stand-alone?
expert standingfurther away from the other three experts than they stand fromeach other.
We also identified the distance between E3 andeach expert as similar to her distance from RB.Similarly, E3 was found to stand further away from themetrics compared to their distance from the other three ex-perts.13 This result, gives rise to the set of formulas in (4) forcalculating the overall average distance between the experts(excluding E3) and each metric.
(4) (4.1): T (EXPPF.BFP ) = 0.629 =T (E0PF.BFP )+T (E1PF.BFP )+T (E2PF.BFP )3(4.2): T (EXPPF.KP ) = 0.571 =T (E0PF.KP )+T (E1PF.KP )+T (E2PF.KP )3(4.3): T (EXPPF.NOCB) = 0.606 =T (E0PF.NOCB)+T (E1PF.NOCB)+T (E2PF.NOCB)3(4.4): T (EXPM.NOCB) = 0.487 =T (E0M.NOCB)+T (E1M.NOCB)+T (E2M.NOCB)3In the next section, we present the concluding analysis forthis study which compares the overall distances in formu-las (2), (3) and (4) with each other.
As we have alreadymentioned, T (EXPEXP ) serves as the upper bound of theanalysis whereas T (EXPRB) is the lower bound.
The aimis to specify which scores in (4) are significantly greater thanT (EXPRB), but not significantly lower than T (EXPEXP ).7.4 Concluding analysisThe results of the comparisons of the scores in (2), (3) and (4)are shown in Table 3.
As the top cell in the last column ofthe Table shows, the T score between the experts and RB,T (EXPRB), is significantly lower than the average distancebetween the expert pairs, T (EXPEXP ) at the 0.01 level.12This could have been argued, if the value of T (E3RB) had beenmuch closer to 1.13Due to space restrictions, we cannot report the scores for thesecomparisons here.
The reader is referred to Table 9.4 on page 175of Chapter 9 in [Karamanis, 2003].This result verifies one of our main predictions showing thatthe orderings of the experts (modulo E3) stand much closerto each other compared to their distance from randomly as-sembled orderings.As expected, most of the scores that involve the met-rics are not significantly different from each other, ex-cept for T (EXPPF.BFP ) which is significantly greater thanT (EXPM.NOCB) at the 0.05 level.
Yet, what we are mainlyinterested in is how the distance between the experts and eachmetric compares with T (EXPEXP ) and T (EXPRB).
Thisis shown in the first row and the last column of Table 3.Crucially, T (EXPRB) is significantly lower thanT (EXPPF.BFP ) as well as T (EXPPF.NOCB) andT (EXPPF.KP ) at the 0.01 level.
Notably, even the dis-tance of the experts from M.NOCB, T (EXPM.NOCB), issignificantly greater than T (EXPRB), albeit at the 0.05level.
These results show that the distance from the experts issignificantly reduced when using the best scoring orderingsof any metric, even M.NOCB, instead of the orderings ofRB.
Hence, all metrics score significantly better than RB inthis experiment.However, simply using M.NOCB to output the bestscoring orders is not enough to yield a distance fromthe experts which is comparable to T (EXPEXP ).
Al-though the PF constraint appears to help towards this di-rection, T (EXPPF.KP ) remains significantly lower thanT (EXPEXP ), whereas T (EXPPF.NOCB) falls only 0.009points short of CD at the 0.05 threshold.
Hence, PF.BFPis the most robust metric, as the difference betweenT (EXPPF.BFP ) and T (EXPEXP ) is clearly not signifi-cant.Finally, the difference between T (EXPPF.NOCB) andT (EXPM.NOCB) is only 0.006 points away from the CD.This result shows that the distance from the experts is reducedto a great extent when the best scoring orderings are com-puted according to PF.NOCB instead of simply M.NOCB.Hence, this experiment provides additional evidence in favourof enhancing M.NOCB with the PF constraint of coherence,as suggested in [Karamanis, 2003].8 DiscussionA question not addressed by previous studies making use ofa certain collection of orderings of facts is whether the strate-gies reflected there are specific to E0, the expert who createdthe dataset.
In this paper, we address this question by enhanc-ing E0?s dataset with orderings provided by three additionalexperts.
Then, the distance between E0 and her colleaguesis computed and compared to the distance between the otherexpert pairs.
The results indicate that E0 shares a lot of com-mon ground with two of her colleagues in the ordering taskdeviating from them as much as they deviate from each other,while the orderings of a fourth ?stand-alone?
expert are foundto manifest rather individualistic strategies.The same variable used to investigate the distance betweenthe experts is employed to automatically evaluate the bestscoring orderings of some of the best performing metrics in[Karamanis et al, 2004].
Despite its limitations due to thenecessarily restricted size of the employed dataset, this eval-EXPEXP : ** ** **0.722 EXPPF.BFP : * **0.629 EXPPF.NOCB : **0.606 EXPPF.KP : **CD at 0.01: 0.150 0.571 EXPM.NOCB : *CD at 0.05: 0.125 0.487 EXPRB :F(5,75)=19.111, p<0.000 0.341Table 3: Results of the concluding analysis comparing the distance between the expert pairs (EXPEXP ) with the distancebetween the experts and each metric (PF.BFP, PF.NOCB, PF.KP, M.NOCB) and the random baseline (RB)uation task allows us to explore the previously unaddressedpossibility that there exist many good solutions for TS in theemployed domain.Out of a much larger set of possibilities, 10 metrics wereevaluated in [Karamanis et al, 2004], only a handful of whichwere found to overtake two simple baselines.
The additionaltest in this study carries on the elimination process by point-ing out PF.BFP as the single most promising metric to be usedfor TS in the explored domain, since this is the metric thatmanages to clearly survive both tests.Equally crucially, our analysis shows that all employedmetrics are superior to a random baseline.
Additional evi-dence in favour of the PF constraint on coherence introducedin [Karamanis, 2003] is provided as well.
The general evalu-ation methodology as well as the specific results of this studywill be useful for any subsequent attempt to automaticallyevaluate a TS approach using a corpus of sentence orderingsdefined by many experts.As [Reiter and Sripada, 2002] suggest, the best way to treatthe results of a corpus-based study is as hypotheses whicheventually need to be integrated with other types of evalua-tion.
Although we followed the ongoing argumentation thatusing perceptual experiments to choose between many possi-ble metrics is unfeasible, our efforts have resulted into a sin-gle preferred candidate which is much easier to evaluate withthe help of psycholinguistic techniques (instead of having todeal with a large number of metrics from very early on).
Thisis indeed our main direction for future work in this domain.AcknowledgmentsWe are grateful to Aggeliki Dimitromanolaki for entrustingus with her data and for helpful clarifications on their use; toMirella Lapata for providing us with the scripts for the com-putation of ?
together with her extensive and prompt advice;to Katerina Kolotourou for her invaluable assistance in re-cruiting the experts; and to the experts for their participation.This work took place while the first author was studying atthe University of Edinburgh, supported by the Greek StateScholarship Foundation (IKY).References[Barzilay and Lee, 2004] Regina Barzilay and Lillian Lee.
Catch-ing the drift: Probabilistic content models with applications togeneration and summarization.
In Proceedings of HLT-NAACL2004, pages 113?120, 2004.
[Barzilay et al, 2002] Regina Barzilay, Noemie Elhadad, andKathleen McKeown.
Inferring strategies for sentence orderingin multidocument news summarization.
Journal of Artificial In-telligence Research, 17:35?55, 2002.
[Brennan et al, 1987] Susan E. Brennan, Marilyn A. Fried-man [Walker], and Carl J. Pollard.
A centering approach to pro-nouns.
In Proceedings of ACL 1987, pages 155?162, Stanford,California, 1987.
[Dimitromanolaki and Androutsopoulos, 2003] Aggeliki Dimitro-manolaki and Ion Androutsopoulos.
Learning to order facts fordiscourse planning in natural language generation.
In Proceed-ings of the 9th European Workshop on Natural Language Gener-ation, Budapest, Hungary, 2003.
[Howell, 2002] David C. Howell.
Statistical Methods for Psychol-ogy.
Duxbury, Pacific Grove, CA, 5th edition, 2002.
[Isard et al, 2003] Amy Isard, Jon Oberlander, Ion Androutsopou-los, and Colin Matheson.
Speaking the users?
languages.
IEEEIntelligent Systems Magazine, 18(1):40?45, 2003.
[Karamanis and Manurung, 2002] Nikiforos Karamanis andHisar Maruli Manurung.
Stochastic text structuring using theprinciple of continuity.
In Proceedings of INLG 2002, pages81?88, Harriman, NY, USA, July 2002.
[Karamanis and Mellish, 2005] Nikiforos Karamanis and ChrisMellish.
A review of recent corpus-based methods for evaluat-ing text structuring in NLG.
2005.
Submitted to Using Corporafor NLG workshop.
[Karamanis et al, 2004] Nikiforos Karamanis, Chris Mellish, JonOberlander, and Massimo Poesio.
A corpus-based methodologyfor evaluating metrics of coherence for text structuring.
In Pro-ceedings of INLG04, pages 90?99, Brockenhurst, UK, 2004.
[Karamanis, 2003] Nikiforos Karamanis.
Entity Coherence for De-scriptive Text Structuring.
PhD thesis, Division of Informatics,University of Edinburgh, 2003.
[Kibble and Power, 2000] Rodger Kibble and Richard Power.
Anintegrated framework for text planning and pronominalisation.
InProceedings of INLG 2000, pages 77?84, Israel, 2000.
[Lapata, 2003] Mirella Lapata.
Probabilistic text structuring: Ex-periments with sentence ordering.
In Proceedings of ACL 2003,pages 545?552, Saporo, Japan, July 2003.
[McKeown, 1985] Kathleen McKeown.
Text Generation: UsingDiscourse Strategies and Focus Constraints to Generate NaturalLanguage Text.
Studies in Natural Language Processing.
Cam-bridge University Press, 1985.
[Reiter and Sripada, 2002] Ehud Reiter and Somayajulu Sripada.Should corpora texts be gold standards for NLG?
In Proceedingsof INLG 2002, pages 97?104, Harriman, NY, USA, July 2002.
