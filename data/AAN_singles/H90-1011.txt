Performing Integrated Syntactic and Semantic ParsingUsing ClassificationRobert T. Kasper and Eduard H. HovyInformation Sciences Institute of USC4676 Admiralty WayMarina del Rey, CA 90292-6695IntroductionThis paper describes a particular approach to parsingthat utilizes recent advances in unification-based parsingand in classification-based knowledge representation.
Asunification-based grammatical frameworks are extended tohandle richer descriptions of linguistic information, they be-gin to share many of the properties that have been developedin KL-ONE-Iike knowledge representation systems.
Thiscommonality suggests that some of the classification-basedrepresentation techniques can be applied to unification-basedlinguistic descriptions.
This merging supports the integrationof semantic and syntactic information i to the same system,simultaneously subject o the same types of processes, in anefficient manner.
The result is expected to be more efficientparsing due to the increased organization of knowledge.The use of a KL-ONE style representation for parsing andsemantic interpretation was first explored in the PSI-KLONEsystem \[2\], in which parsing is characterized asan inferenceprocess called incremental description refinement.
The keyidea underlying this process is that a description of an objectcan become increasingly more specific as additional featuresare learned from multiple knowledge sources, which is es-sentially the same idea that underlies most unification-basedapproaches.
Bobrow and Webber identified four crucial ca-pabilities that a representational system should have in orderto support he process of incremental description refinement.These capabilities, not all available to Bobrow and Webberi n  1980, have recently been developed in the Loom knowl-edge representation system \[ 12\] and hence nable the practicaldevelopment of the new parsing method.
They are:1.
What properties of a structured object provide sufficientinformation toguarantee the applicability of a descriptionto (some portion of) that object- -  i.e., criteriality condi-tions.
Loom provides a separation of definition (neces-sary and sufficient conditions) and constraints (impliedfeatures).2.
What mappings are possible between classes of relations- -  e.g., how functional relationships between syntac-tic constituents map onto semantic relationships.
Thisis not part of Loom, but can be captured in the inter-relationships between a syntax-oriented grammar and asemantics-oriented concept taxonomy.3.
Which pairs of descriptions are mutually incompatible- -  i.e., which cannot both apply to a single individual.Loom provides more complete inference of disjointnessthan previous ystems in the KL-ONE family.4.
Which sub-categorizations of descriptions are exhaus-tive - -  i.e., at least one of the subcategories applies toanything to which the more general description applies.Loom provides inference with respect to coverings, im-plemented by disjunctive descriptions.This paper outlines how a parser can be built using Loom'sclassifier as the primary inference operation.
It first describesthe process of unification, then points out similarities betweenunification and classification, then describes the process ofparsing using the classifier with an example.
The integrationof semantic and syntactic information i to the same system isdiscussed.
Finally, the efficiency benefits of the new methodare mentioned.Constraints in Unification-based Gram-marsA variety of current approaches to parsing in computationallinguistics emphasize declarative r presentations of grammarwith logical constraints stated in terms of feature and cate-gory structures.
These approaches have collectively becomeknown as the unification-based grammars, because unificationis commonly used as the primary operation for building andcombining feature structures.
Some of the simplest of thesegrammatical frameworks, as exemplified by the PATR-II sys-tem \[16\], state constraints on features entirely in terms of setsof unifications that must be simultaneously satisfied whenevera grammatical rule is used.
In such systems all constraints ona rule or lexical item are interpreted conjunctively.
Manyof the more recent frameworks also use other general logicalconnectives, such as disjunction, egation and implication, intheir representation f constraints.
The utility of such logicalconstraints i abundantly illustrated by linguistic models, in-cluding Systemic Grammar (SG) \[5\] and Head Driven PhraseStructure Grammar (HPSG) \[14\], and by computational toolssuch as Functional Unification Grammar (FUG) \[11\].
Forexample, SG and FUG even use disjunctive alternations offeatures, instead of structural rules, as the primary units ofgrammatical organization.
While the intuitive interpretationof these logical constraints i  rather straightforward, and they54are quite natural for linguists to formulate, large-scale imple-mentations of them have typically involved finding a balancebetween expressive power and computational efficiency, notan easy task.Some difficulties can be expected in developing a systemfor computing with disjunctive and negative feature con-straints, because it has been established that common op-erations on such descriptions, uch as unification and sub-sumption, are NP-complete and require exponential time inthe worst case \[15\].
The most common and obvious way todeal with disjunctive constraints i to expand the grammat-ical description to disjunctive normal form (DNF) during apre-processing step, thereby eliminating disjunction from therules that are actually used by the parser.
Though this methodworks reasonably well for small grammars, it turns out to beunsatisfactory for larger grammars.It is possible to avoid exponential expansion for most prac-tical grammars, and several unification algorithms for disjunc-tive feature descriptions have been developed inrecent years:\[6, 10, 4\].
The latter two algorithms allow general disjunc-tive descriptions, and avoid expansion to DNF by exploitinglogical equivalences between descriptions to produce normalforms that allow a more compact representation.
Kasper'salgorithm is based on a normal form that divides each de-scription into definite and indefinite components.
The definitecomponent contains no disjunction, and the indefinite compo-nent contains a list of disjunctions that must be satisfied.
Thealgorithm of Eisele and Doerre uses a different normal formthat guarantees the detection of any inconsistencies during thenormalization process by selectively expanding disjunctionsthat might possibly interact with other information i  the de-scription.
The Kasper algorithm was first implemented asanextension to the unification algorithm of the PATR-II parser,and it has been further developed to handle conditional de-scriptions and a limited type of negation \[8\].
These extensionsto PATR-II have been used to construct an experimental parserfor systemic grammars \[9\], which has been tested with a largegrammar of English called Nigel, which is part of the Penmanlanguage generation system \[13\].Although these methods for processing complex featureconstraints are generally much more efficient han expansionto DNF, they still have several significant sources of ineffi-ciency:1. a large amount of structure must be copied in order toguarantee correct unification;2. consistency checks are required between components ofa description that do not share any features in common,because unification cannot determine whether any de-pendencies xist between two structures without actuallyunifying them;3. repeated computations are often required over sub-expressions of descriptions, because the results of priorunifications (and compatibility ests) are not saved.These sources of inefficiency are not unique to one methodof parsing with disjunctive descriptions; imilar shortcom-ings are commonly reported for most unification-based sys-tems.
The unification literature contains everal techniquesfor reducing the amount of copying by structure sharing, butthese techniques appear to solve only part of the problem.
Amore general approach to improving the efficiency of unifi-cation may be available by adopting methods that are used inclassification-based ystems.Classification-based KnowledgeRepresentationUnfortunately, as a grammar (or knowledge base) grows insize and complexity, it becomes increasingly less efficientto simply unify partial descriptions of constituents with adescription from the grammar (as in most unification-basedframeworks).
Instead, it becomes preferable to classify eachpartial description of a constituent with respect to the objectsthat are defined by the grammar, exploiting known relation-ships between components of the grammatical description.Since the components of the grammar are known before pars-ing commences, various relationships, uch as subsumptionand compatibility, can be used to construct a lattice of gram-matical objects, eliminating the need to derive those relation-ships repeatedly atparse time.The KL-ONE family of knowledge representation sys-tems is based on an explicit logical formalization of manyof the constructs that have been explored in semantic net-works and frame-based representation systems.
They or-ganize information about objects and the relations betweenthem into hierarchies according to specificity, with more spe-cific objects placed below more general ones.
For example,a hierarchy of English word classes would probably containVerbs, Transitive-Verbs a a subclass of Verbs, and the word"like" as an instance of Transitive-Verbs.
Each hierarchy isa subsumption-ordered lattice based upon logical propertiesthat can be deduced from the definitions of objects and thefacts known about them.
In these systems, classification isthe operation that places a new class or object into the latticeaccording to the subsumption order.
A primary benefit ofclassification is that it organizes large collections of knowl-edge in such a way that properties shared by many objectsneed only be represented once, yet they can still be efficientlyaccessed by inheritance.KL-ONE and similar frameworks have been used for se-mantic interpretation in some natural language processing sys-tems \[18\], but usually in a way that is quite separate from thegrammatical parsing process (an exception is the aforemen-tioned PSI-KLONE system).
Recent research indicates thatit may be advantageous to make use of a classification-basedframework for processing rammatical knowledge as well.Many formal properties are shared by the feature descrip-tions used in unification-based grammars and the termino-logical definitions used in KL-ONE.
Generally speaking, lin-guistic categories correspond to concepts, and their features(or attributes) correspond to binary relations in the knowl-edge representation system.
The similarity between thesetwo types of descriptions has been most clearly documentedby Smotka \[17\] in his development of a logic that integrates asignificant combination oftheir expressive capabilities.
Manytheoretical results have also been based on the observation that55feature structures can be implicitly organized into a subsump-tion lattice of types according to their information content.In most unification-based systems the lattice is not explicitlyconstructed, but a classification-based system can be used toplace the feature structures of a grammar and lexicon intoa structure-sharing lattice, potentially improving both spaceand time efficiency.Despite the underlying similarities between the KL-ONEframework and unification-based grammars, there are signifi-cant differences in the expressive capabilities that are usuallyprovided.
In particular, the knowledge representation systemstypically have general constraints on relations with multiplevalues, whereas most unification-based systems do not pro-vide a direct representation for features with set values.
Onthe other hand, complex logical constraints involving dis-junction and negation have been more extensively developedin unification-based systems than in classification-based sys-tems.
The Loom system \[12\], which has been developed atUSC/ISI, appears to be the first in the KL-ONE family tohave included general disjunction and negation in its conceptdefinition language.
The implementation f classification fordisjunctive concepts has been based on several refinements ofa strategy that was originally developed for unification withdisjunctive feature descriptions \[10\].
The implementationof classification for concepts defined by negation is still inprogress.
With these extensions, the Loom system is able tohandle a much fuller range of constraints hat have been usedin actual linguistic descriptions of feature structures.An Experiment in Classification-basedParsingIn order to explore a strategy for parsing based on classifica-tion, we have to represent Penman's grammar in Loom andreplace the existing unification component of our parser \[9\]with activations of Loom's classifier.
Motivating this actionare two primary goals:1. to investigate the extent o which classification can beused to organize the knowledge contained in linguisticdescriptions so that it can be more efficiently accessedduring the parsing process;2. to develop a suitable architecture for integrating seman-tic information into the parsing process, in a way thatknowledge specific to application domains does not haveto be re-organized for parsing.It is straightforward to convert he feature constraints ofthe grammar into a set of definitions that can be processed byLoom, because of the underlying correspondences betweenLoom's concept definitions and linguistic feature descriptionsthat we have already described.
It is also straightforwardto perform an operation that is equivalent to the unificationof feature structures within Loom.
This is accomplished byforming an object having a type that is defined as the conjunc-tion of the types corresponding to the feature structures.
Con-junction of types yields a type which captures the unificationof descriptions in a non-destructive way.
Loom also supportsmerging of instances, corresponding to destructive unifica-tion, which is necessary inorder to satisfy feature quivalenceconstraints.
When two instances are merged, the resulting in-stance has a type which is a conjunction of the types of thetwo original instances.A disjunction is represented in Loom by an object hat gen-eralizes (i.e., classifies above) each of the disjuncts.
It isimportant to note that a disjunctive description entails morethan a simple generalization.
It is possible to satisfy a gener-alization without satisfying any of the disjuncts, but in orderto satisfy a disjunction, an object must satisfy one of the dis-juncts.Instead of unifying a partial description of a constituentwith a grammatical description, we classify the description ofthe constituent with respect to an object-oriented representa-tion of the grammar, in which each object stores informationand constraints associated with a particular type of grammati-cal constituent.
The classifier determines which grammaticalclasses the constituent instantiates, and the constraints asso-ciated with these classes can be used to give a more complete(grammatical, semantic, pragmatic) description of the con-stituent.Classification provides a way of decomposing a large de-' scription into types, and organizing these types into a latticeso that they can be efficiently searched.
Thus, it can providea more efficient mechanism for unifying large descriptions.Two immediate benefits of the lattice representation are:1. the descriptions ofthe grammar do not need to be copiedeach time that they are unified with a constituent, and2.
each constituent does not need to have an explicit repre-sentation of a complete set of its grammatical features,because many of these are entailed by its type.Classification has the effect of abstracting frequently usedcombinations of features into a type hierarchy.
By factoringdescriptions of types of objects out of the feature structuresthat represent constituents, it is often possible to reduce thenumbers of features that need to be unified (recursively) whenthe constituent is used as a role-filler (in multiple parses),because the type encapsulates restrictions on those features.A Simple ExampleIn an example, consider how classification with respect to asimple grammar may be used in parsing the sentence: Davidlikes computers.
Assume that a lexical/morphological ana-lyzer gives the following type membership information foreach word:David: Noun.computers: Noun.likes: Verb Trans i t ive Present.Also assume that a rather simple context-free grammar canbe used to recognize possible constituents, and that it can beannotated to assign grammatical functions 1.
In the example1 Using the classification-based approach outlined here, itis theoreticallypossible to perform the parsing completely using only classification.
How-ever, such a parser would have to examine all substrings ofthe input in order56sentence, this grammar proposes a constituent c with the typeCl au s e and the following grammatical functions:sub jec t  : dav idprocess  : l i kesdob jec t  : computersThis initial description of the constituent, c, is then givento the classifier, which deduces the most specific types that itbelongs to.
The classifier begins by considering types that aredirectly below the initial type, i.e., Int rans -C lause  andTrans -C lause .
The definition of I n t rans -C lausestates that it is a Clause  with a process  of typeIn t rans i t i ve .
This definition is not satisfied by c, be-cause it does not have a process of type In t rans i t i ve .Next, the classifier considers T rans -C lause ,  which has adefinition stating that it is a C lause  with a process  oftype Trans i t i ve .
This definition is satisfied by c. In ad-dition, T rans -C lause  has a constraint: it implies the typeAct ive  OR P as  s ive ,  which means thatany object whichis a member of Trans -C lause  must also be a member ofAct ive  OR Pass ive  (that is, Ac t ive  and Pass iveform a disjoint covering of Trans-Clause) .
Therefore,Ac t ive  OR Pass ive  is added to the list of types that cbelongs to.BecauseAct ive OR Passiveisadisjunction,itispos-sible to infer membership in one of the disjuncts by prov-ing incompatibility with all other disjuncts, c is compatiblewith all of the constraints of Ac t ive ,  but it is not compat-ible with the constraints of Pass ive :  it has a processof type Present ,  Pass ive  requires a process  of typePastPart ,  and the types Present  and PastPar t  spe-ciaiize the disjoint types, F in i te  and Nonf in i te .
Byeliminating the P a s s ive  disjunct from consideration, mem-bership in the Act ive  disjunct can be inferred.
Ac t ive  isthe most specific type that can be inferred for c, because itspecializes all other types that c belongs to (and there are nomore specific types defined in this simple example).As a consequence of acquiring membership in the typeAct ive ,  c inherits all constraints that are associated withAct ive .
These constraints require that the ac tor  andsub  j ec t  roles are identical (i.e., that the values of these tworoles should be unified), and that the goa l  and dob jec troles are identical.
Satisfying these constraints yields thefollowing information about he roles of c:actor  : dav idgoa l  : computersThus, given the initial assumption that c is a clausewith particular constituents filling the grammatical functionsproces  s, sub jec t  and dob  ject, classification deduces:1. a more specific type: that c is an active clause;to find all possible constituents, unless ufficient constraints onconstituentordering can be applied early enough inthe parsing process.
By performinga sha/low structural parse before starting the deep classification-based parse,one gains a large improvement in efficiency, because even askeletal context-free grammar can provide the basic segmentation of the input sentence intoits major constituents.
Thus, a simple context-free parsing component wasused for this purpose with success inthe prototype system.2.
values for previously unspecified roles: actor  andgoal.The classifier uses the lattice representation f defined typesto guide its search for types that are satisfied by a given object.It does not need to consider any types that fall below a typethat the object is known not to specialize, such as all typesbelow In t rans -C lause  and Pass ive  for the object c.The power of using this kind of classification scheme maybe further exploited by associating semantic and pragmaticconstraints with each grammatical type, in addition to thegrammatical constraints which have been illustrated.Integrating Semantic Information intothe Parsing ProcessOne of the greatest advantages of this method of parsing isthe possibility of performing integrated semantic and syntacticprocessing.
KL-ONE systems uch as Loom were tradition-ally developed to represent semantic information, and withthe inclusion of syntactic information as required for the workdescribed here, both types of knowledge reside in the samesystem and are accessible to a single classification process.The advantages for processing are clear.
By being able op-portunistically toaccess both semantic and syntactic knowl-edge at any point during the process, the parser can resolveambiguities sooner than in the traditional pipeline model, inwhich syntactic parsing is completed before semantic parsingcommences.
Many of the structural ambiguities that ariseduring parsing are only resolvable by semantic knowledge,and pipeline parsers have to maintain all the syntactic possi-bilities until the semantic parsing phase.
Non-pipelineparsershave to perform acomplex interweaving of semantic and syn-tactic processing, requiring increased bookkeeping and morecomplex system architecture.
In the method outlined in thispaper, the parser's ingle call to the classifier will result in themost appropriate information - -  both semantic and syntactic- -  being found and being reconciled, if possible by the normalaction of the classifier.Another benefit is the increased portability provided by aknowledge representation paradigm used in the Penman sys-tem.
In order to achieve greater portability, Penman containsa general taxonomic ontology of concepts called the UpperModel \[ 1\], under which the concepts from various applicationdomains are subordinated.
By inheriting information fromthe Upper Model, domain concepts can be handled appropri-ately by the Penman language generator without he generatorever having to be explicitly informed of their individual na-ture.
Similarly, the parser can exploit inherited Upper Modelinformation when trying to place words appropriately intostructures.
More information can be found in \[7\].Efficiency ConsiderationsThe classification-based architecture used by Loom solvesa whole class of related efficiency problems by explicitlyconstructing and maintaining a subsumption-ordered latticewith inheritance.
In particular, it may provide substantialimprovements for some of the abovementioned sources of57inefficiency that have been observed with unification-basedparsers:Structure Sharing: In most unification-based parsers, it isnecessary tomake new copies of the feature structures that areassociated with lexical items or grammatical rules wheneverthey are used in building a description of a sentence (or oneof its constituents).
In a classification-based ystem the entirestructure does not need to be copied, because the descriptionof a constituent can contain pointers to the classes of objectsthat it instantiates.
This representation not only saves space,but it also allows the parser to make use of information that hasalready been precomputed ( uring the classification process)for classes of objects in the grammar and lexicon.
Hencethe organization of descriptions into a lattice automaticallyprovides agreat amount of structure sharing.Indexing Dependencies: Theprocess ofclassification alsokeeps track of dependencies between different objects, elimi-nating the need for checking consistency between componentsof a description that have no features in common.
In effect, anindex is incrementally constructed from features to descrip-tions that contain them.
This contrasts with most unification-based systems, in which feature structures are represented bydirected graphs (or by first order terms, as in Prolog).Avoiding Redundant Computations: With un-typed fea-ture structures, each unification isperformed on a pair of struc-tures without reference to any stored knowledge, i.e., there isno way for simple unification to use the results of previousunification and subsumption computations, even if many ob-jects with identical features have already been unified.
Byexplicitly representing the types of objects in a lattice, infor-mation can be stored for classes of objects, making it possibleto avoid repeated computations for multiple objects havingthe same type (or any more specific type).
Thus the firsttime a component of a description is classified, it is placedinto the lattice containing all other descriptions in the knowl-edge base.
Since the lattice xplicitly represents he types ofobjects, it makes full-depth consistency checks unnecessarybetween objects that are known to be in a subsumption rela-tionship, and subsumption (success) and consistency (failure)tests only need be computed once for all objects that belongto the same types.Using Classification as a Grammar Compiler: In sum-mary, classification can be seen as providing a capabilitysimilar to that provided by compilers in programming sys-tems.
Although a simpler unification-based system mayprovide acceptable results with somewhat less overheadthan a classification-based approach on a limited scale, aclassification-based ystem is almost certainly to be preferablefor applications that are necessarily knowledge-intensive.Concluding RemarksThis work is part of an effort to provide the Penman sys-tem at ISI/USC with full natural language input and outputcapabilities.
An experimental prototype of this parser usingunification and a feature structure representation f part ofPenman's grammar has been completed successfully.
Mostof the work in constructing a parser using the classification-based architecture of Loom and to reproduce the functionalityof the unification-based system, now operating on the wholeof the grammar, has been completed.If successful, this experiment should enable a comparisonof classification and unification as mechanisms for parsing.The classification scheme appears to provide a way of sub-stantially reducing several of the most general sources of inef-ficiency that are observed in current unification-based parsers.However, this conjecture needs to be examined by performingexperiments with several real grammars and applications.In addition to providing an efficient engine for processingthe constraints of linguistic feature descriptions, we also ex-pect this type of information organization to provide a strongbasis for integrating semantic knowledge and knowledge spe-cific to particular applications into the parsing process.AcknowledgmentThis research was sponsored in part by the United StatesDefense Advanced Research Projects Agency under contractMDA903-87-C-641 and in part by the United States Air ForceOffice of Scientific Research under contract F49620-87-C-0005.
The opinions expressed here are solely those of theauthors.Thanks to Bob MacGregor for many cooperative discus-sions and help with a partial implementation f these ideasusing Loom.References\[1\] Bateman, J.A., Kasper, R.T., Moore, J.D., Whitney, R.A.A General Organization of Knowledge for Natural Lan-guage Processing: The Penman Upper Model.
USCBSITechnical Report, Marina del Rey, 1990.\[2\] Bobrow, Robert and Webber, Bonnie.
Knowledge Rep-resentation for Syntactic/Semantic Processing.
In Pro-ceedings of AAAI-80, The First National Conference onArtificial Intelligence, Stanford, CA, August 1980.\[3\] Brachman, Ronald and Schmolze, James.
An Overviewof the KL-ONE Knowledge Representation System.Cognitive Science, Vol.
9:2, 1985.\[4\] Eisele, Andreas and Doerre, Jocben.
Unification of Dis-junctive Feature Descriptions.
InProceedings ofthe 26thAnnual Meeting of the Association for ComputationalLinguistics, Buffalo, NY, June 1988.\[5\] Halliday, Michael.
System and Function in Language.Kress G., (ed.
), Oxford University Press, 1976.\[6\] Karttunen, Lauri.
Features and Values.
In Proceedingsof the lOth International Conference on ComputationalLinguistics: COLING 84, Stanford, CA, July 1984.\[7\] Kasper, Robert.
A Flexible Interface for Linking Ap-plications to Penman's Sentence Generator.
In Proceed-ings of the DARPA Workshop on Speech and NaturalLanguage, Philadelphia, PA, February 1989.58[8] Kasper, Robert.
Conditional Descriptions in FunctionalUnification Grammar.
In Proceedings ofthe 26th AnnualMeeting of the Association for Computational Linguis-tics, Buffalo, NY, June 1988.
[9] Kasper, Robert.
An Experimental Parser for SystemicGrammars.
In Proceedings of the 12th InternationalConference on Computational Linguistics, Budapest,August 1988.
[10] Kasper, Robert.
A Unification Method for DisjunctiveFeature Descriptions.
In Proceedings of the 25th An-nual Meeting of the Association for Computational Lin-guistics, Stanford, CA, July 1987.
Also available asUSC/Information Sciences Institute Reprint RS-87 -187.
[11] Kay, Martin.
Parsing in Functional Unification Gram-mar.
In Natural Language Parsing, Dowty D., KarttunenL., and Zwicky A.
(eds.
), Cambridge University Press,1985.
[12] MacGregor, Robert.
A Deductive Pattern Matcher.
InProceedings ofAAAI-88, The Sixth National Conferenceon Artificial Intelligence, St. Paul, MN, August 1988.
[13] The Penman Project.
The Penman Primer, User Guide,Reference Manual, and Nigel Manual.
System docu-mentation, USC/ISI Technical Report, Marina del Rey,1989.
[14] Pollard, Carl and Sag, Ivan.
Information Based Syntax.CSLI Lecture Notes Number 13, University of ChicagoPress, 1987.
[ 15] Rounds, William and Kasper, Robert.
A Complete Log-ical Calculus for Record Structures Representing Lin-guistic Information.
In Proceedings ofthe IEEE Sympo-sium on Logic in Computer Science, Cambridge, MA,June 1986.
[16] Shieber, Stuart.
The Design of a Computer Languagefor Linguistic Information.
In Proceedings ofthe TenthInternational Conference on ComputationalLinguistics:COLING 84, Stanford, CA, July 1984.
[17] Smolka, Gert.
A Feature Logic with Subsorts.
LILOGReport 33, IBM Deutschland, Stuttgart, West Germany,May 1988.
[18] Sondheimer, Norman K., Weischedel, Ralph M. and Bo-brow, Robert J. Semantic Interpretation Using KL-ONE.In Proceedings ofthe Tenth International Conference onComputational Linguistics: COLING 84, Stanford, CA,July 1984.59
