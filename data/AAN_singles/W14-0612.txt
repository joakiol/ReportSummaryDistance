Proceedings of the 8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH) @ EACL 2014, pages 86?90,Gothenburg, Sweden, April 26 2014.c?2014 Association for Computational LinguisticsCorA: A web-based annotation tool for historicaland other non-standard language dataMarcel Bollmann, Florian Petran, Stefanie Dipper, Julia KrasseltDepartment of LinguisticsRuhr-University Bochum, 44780 Bochum, Germany{bollmann|petran|dipper|krasselt}@linguistics.rub.deAbstractWe present CorA, a web-based annotationtool for manual annotation of historical andother non-standard language data.
It allowsfor editing the primary data and modify-ing token boundaries during the annotationprocess.
Further, it supports immediate re-training of taggers on newly annotated data.1 Introduction1In recent years, the focus of research in naturallanguage processing has shifted from highly stan-dardized text types, such as newspaper texts, to texttypes that often infringe orthographic, grammaticaland stylistic norms normally associated with writ-ten language.
Prime examples are language dataproduced in the context of computer-mediated com-munication (CMC), such as Twitter or SMS data,or contributions in chat rooms.
Further examplesare data produced by learners or historical texts.Tools trained on standardized data perform con-siderably worse on ?non-standard varieties?
suchas internet data (cf.
Giesbrecht and Evert (2009)?swork on tagging the web or Foster et al.
(2011)?sresults for parsing Twitter data) or historical lan-guage data (Rayson et al., 2007; Scheible et al.,2011).
This can mainly be attributed to the factsthat tools are applied out of domain, or only smallamounts of manually-annotated training data areavailable.A more fundamental problem is that commonand established methods and categories for lan-guage analysis often do not fit the phenomena oc-curring in non-standard data.
For instance, gram-maticalization is a process of language evolutionwhere new parts of speech are created or wordsswitch from one class to another.
It is difficult todraw strict categorial boundaries between words1The research reported here was financed by DeutscheForschungsgemeinschaft (DFG), Grant DI 1558/5-1.that take part in a continuous smooth transition ofcategories.
Factors like these can also affect theway the data should be tokenized, along with otherproblems such as the lack of a fixed orthography.In the light of the above, we developed a web-based tool for manual annotation of non-standarddata.
It allows for editing the primary data, e.g.for correcting OCR errors of historical texts, orfor modifying token boundaries during the annota-tion process.
Furthermore, it supports immediateretraining of taggers on newly annotated data, toattenuate the problem of sparse training data.CorA is currently used in several projects thatannotate historical data, and one project that ana-lyzes chat data.
So far, about 200,000 tokens in84 texts have been annotated in CorA.
Once theannotation process is completed, the transcriptionsand their annotations are imported into the ANNIScorpus tool (Zeldes et al., 2009) where they can besearched and visualized.The paper focuses on the annotation of historicaldata.
Sec.
2 presents the tool, and Sec.
3 describesthe data model.
Sec.
4 concludes.2 Tool DescriptionCorA uses a web-based architecture:2All datais stored on a server, while users can access andedit annotations from anywhere using their webbrowser.
This approach greatly simplifies collabo-rative work within a project, as it ensures that allusers are working on the same version of the dataat all times, and requires no software installationon the user?s side.
Users can be assigned to indi-vidual project groups and are only able to accessdocuments within their group(s).2.1 The annotation editorAll annotation in CorA is done on a token level;the currently supported annotation types are part-2It implements a standard AJAX architecture using PHP 5,MySQL, and JavaScript.86Figure 1: Web interface of CorA showing the annotation editorof-speech tags, morphology tags, lemmatization,and (spelling) normalization.
The tool is designedto increase productivity for these particular an-notation tasks, while sacrificing some amount offlexibility (e.g., using different annotation layers,or annotating spans of tokens).
Note that this ismainly a restriction of the web interface; the under-lying database structure is much more flexible (cf.Sec.
3), facilitating the later addition of other typesof annotation, if desired.Tokens are displayed vertically, i.e., one tokenper line.
This way, the annotations also line upvertically and are always within view.
Addition-ally, a horizontal text preview can be displayed atthe bottom of the screen, which makes it easierto read a continuous text passage.
Fig.
1 shows asample screenshot of the editor window.3Userscan customize the editor, e.g.
by hiding selectedcolumns.Parts-of-speech and morphology Within theeditor, both POS and morphology tags can be se-lected from a dropdown box, which has the ad-vantage of allowing both mouse-based and fasterkeyboard-based input.
Tagsets can be defined in-dividually for each text.
If morphology tags areused, the selection of tags in the dropdown box isrestricted by the chosen POS tag.3The user interface is only available in German at the timeof writing, but an English version is planned.Lemmatization Lemma forms are entered intoa text field, which can optionally be linked to apre-defined lexicon from which it retrieves auto-completion suggestions.
Furthermore, if an identi-cal token has already been annotated with a lemmaform elsewhere within the same project, that lemmais always displayed as a highlighted suggestion.Normalization For corpora of non-standard lan-guage varieties, spelling normalization is oftenfound as an annotation layer, see, e.g., Scheibleet al.
(2011) for historical data and Reznicek et al.
(2013) for learner data.In addition to normalization, an optional mod-ernization layer can be used that defaults to thecontent of the normalization field.
The normaliza-tion layer can be used for standardizing spelling,and the modernization layer for standardizing in-flection and semantics (Bollmann et al., 2012).Meta information CorA features a progress indi-cator which can be used to mark annotations as ver-ified (see the green bar in Fig.
1).
Besides servingas a visual aid for the annotator, it is also used forthe automatic annotation component (cf.
Sec.
2.2).Additionally, tokens can be marked as needing fur-ther review (indicated with a red checkbox), andcomments can be added.2.2 Automatic annotationCorA supports (semi-)automatic annotation by in-tegrating external annotation software on the server87side.
Currently, RFTagger (Schmid and Laws,2008) and the Norma tool for automatic normaliza-tion (Bollmann, 2012) are supported, but in princi-ple any other annotation tool can be integrated aswell.
The ?retraining?
feature collects all verifiedannotations from a project and feeds them to thetools?
training functions.
The user is then able toinvoke the automatic annotation process using thenewly trained parametrizations, which causes alltokens not yet marked as verified to be overwrittenwith the new annotations.The retraining module is particularly relevant fornon-standard language varieties where appropriatelanguage models may not be available.
The ideais that as more data is manually annotated withina corpus, the performance of automatic annotationtools increases when retrained on that data.
Thisin turn makes it desirable to re-apply the automatictools during the annotation process.2.3 Editing primary dataIn diplomatic transcriptions of historicalmanuscripts, the transcripts reproduce themanuscripts in the most accurate way, by encodingall relevant details of special graphemes anddiacritics, and also preserving layout information.Transcribers often use ASCII-based encodings forspecial characters, e.g., the dollar sign $ in placeof a long s (???
).The data model of CorA (cf.
Sec.
3) distin-guishes between different types of token representa-tions.
In the annotation editor, the user can chooseto display either the original transcription layer orthe UTF-8 representation.If an error in the primary data?e.g., a transcrip-tion error or wrong tokenization?is noticed duringthe annotation, it can be corrected directly withinthe editor.
CorA provides functionality to edit, add,or delete existing tokens.
Furthermore, externalscripts can be embedded to process any changes,by checking an edited token for validity (e.g., iftokens need to conform to a certain transcriptionformat), or generating the UTF-8 representationby interpreting special characters (e.g., mapping $to ?
).2.4 Comparison to related toolsThere is a range of annotation tools that can beused for enriching data with different kinds of an-notations.
Prominent examples are GATE, EX-MARaLDA, MMAX2, brat, and WebAnno.4Manyannotation projects nowadays require distributedcollaborative working of multiple parties.
The cur-rently preferred solution is to use a tool with anunderlying database which is operated through astandard web-browser.
Among the tools above,only brat and WebAnno are web-based tools.
Com-pared to CorA, these tools are more flexible inthat they support more annotation layers and morecomplex (e.g., multi-word) annotations.
WebAnno,in addition, offers facilities for measuring inter-annotator agreement and data curation.
However,brat and WebAnno do not allow edits to the sourcedocument from within the tool, which is particu-larly relevant for non-standard language varieties.Similarly, they do not support retraining on newlyannotated data.3 Data ModelThe requirements described in Sec.
2 present vari-ous challenges to the data storage, which necessi-tated the development of our own data model.
Adata model in this context is a conceptual modelof the data structure that allows serialization intovarious representations such as XML or databases.Such a model also allows for easy conversion be-tween serializations and hence facilitates interop-erability with existing formats and tools.
Thecomplex, multi-layered layout, the differences intokenization, and the fine-grained description ofgraphematic pecularities in the primary data cannotbe captured well using existing formats.
For exam-ple, tokenization differences as they are handledby formats such as <tiger2/> (Bosch et al., 2012)pertain only to the contraction of underlying unitsto original forms, and not the other way around.This means that while a conversion in such formatsis easily possible, some of the data structure thatis captured by our model is necessarily lost in theprocess.
To come up with a data model that min-imizes redundancy and allows for flexibility andextensibility, and accomodates the work flow ofour transcriptors and annotators, we employed nor-malization techniques from database development.A slightly simplified version of the data model isshown in Fig.
2.4GATE: http://gate.ac.uk/EXMARaLDA: http://www.exmaralda.org/MMAX2: http://mmax2.sourceforge.net/brat: http://brat.nlplab.org/WebAnno: https://code.google.com/p/webanno/88Figure 2: Data model used for CorAToken and Text The model is centered aroundtwo units, a text and a token.
A token is a virtualunit that can manifest in two ways, the diplomatictoken and the modern token, each of which hasa one-to-many relation with a token (cf.
Fig.
3).Diplomatic tokens are tokens as they appear inthe original, historical text, while modern tokensmirror modern conventions for token boundaries,representing suitable units for further annotations,e.g.
with POS tags.
All physical layout informationon the other hand relates to the diplomatic token.The text is the entirety of a transcribed documentthat can be partitioned in various ways.
The layoutis captured by its relation to the page, column, andline, which in turn relate to the diplomatic tokens.Furthermore, a text can be assigned one or moretagsets.
The tagsets in turn can be open, such aslemmatization tags, or closed, such as POS tags.Each text can be assigned different tagsets.Extensions In addition, the data model also al-lows for the import of markup annotations with thetexts, which may denote layout-related or linguisticpeculiarities encoded by the transcriptors, as wellas information about its annotation status such asprogress, or dubious annotations.
The model iseasily extendable for user management that can tiein to the text table, e.g., a user can be set as owneror creator of a text.As XML serialization is not optimized for datawhich is not strictly hierarchically structured, stor-age and retrieval is rather inefficient, and extensionsare not easily possible.
For this reason, we choseto implement the application with an SQL database<token><!-- diplomatic tokenization --><dipl trans="ober"/><dipl trans="czugemich"/><!-- modern tokenization --><mod trans="oberczuge"><norm tag="?berzeuge"/><pos tag="VVIMP.Sg"/></mod><mod trans="mich"><norm tag="mich"/><pos tag="PPER.1.Sg.
*.Acc"/></mod></token>Figure 3: Example serialization of ober czugemich(modern ?berzeuge mich ?convince me?)
in XMLserialization of the data model.4 ConclusionWe described CorA, a web-based annotation tool.Its main features are the integration of automaticannotation software, the possibility of making editsto the source document, and the conceptual dis-tinction between diplomatic and modern tokens inthe data model.
We believe that these features areparticularly useful for annotators of non-standardlanguage data such as historical texts, and set CorAapart from other existing annotation tools.We plan to make the tool available under anopen source license eventually.
However, we arecurrently still working on implementing additionalfunctionality.
In future work, we plan to integratefeatures to evaluate annotation quality, such as au-tomatically calculating inter-annotator agreement.89ReferencesMarcel Bollmann, Stefanie Dipper, Julia Krasselt, andFlorian Petran.
2012.
Manual and semi-automaticnormalization of historical spelling ?
case studiesfrom Early New High German.
In Proceedings ofthe First International Workshop on Language Tech-nology for Historical Text(s) (LThist2012), Vienna,Austria.Marcel Bollmann.
2012.
(Semi-)automatic normaliza-tion of historical texts using distance measures andthe Norma tool.
In Proceedings of the Second Work-shop on Annotation of Corpora for Research in theHumanities (ACRH-2), Lisbon, Portugal.Sonja Bosch, Key-Sun Choi, ?ric de la Clergerie, AlexChengyu Fang, Gertrud Faa?, Kiyong Lee, AntonioPareja-Lora, Laurent Romary, Andreas Witt, AmirZeldes, and Florian Zipser.
2012.
<tiger2/> as astandardised serialisation for ISO 24615.
In Pro-ceedings of the 11th Workshop on Treebanks andLinguistic Theory (TLT), Lisbon, Portugal.Jennifer Foster, Ozlem Cetinoglu, Joachim Wagner,Joseph Le Roux, Stephen Hogan, Joakim Nivre,Deirdre Hogan, and Josef van Genabith.
2011.#hardtoparse: POS tagging and parsing the twitter-verse.
In Proceedings of AAAI-11 Workshop onAnalysing Microtext, San Francisco, CA.Eugenie Giesbrecht and Stefan Evert.
2009.
Part-of-speech tagging ?
a solved task?
An evaluation ofPOS taggers for the German Web as Corpus.
InProceedings of the 5th Web as Corpus Workshop(WAC5), pages 27?35, San Sebastian, Spain.Paul Rayson, Dawn Archer, Alistair Baron, JonathanCulpeper, and Nicholas Smith.
2007.
Tagging theBard: Evaluating the accuracy of a modern POS tag-ger on Early Modern English corpora.
In Proceed-ings of Corpus Linguistics 2007, University of Birm-ingham, UK.Marc Reznicek, Anke L?deling, and HagenHirschmann.
2013.
Competing target hypothesesin the Falko Corpus: A flexible multi-layer corpusarchitecture.
In Ana D?az-Negrillo, Nicolas Ballier,and Paul Thompson, editors, Automatic Treatmentand Analysis of Learner Corpus Data, pages101?123.
Amsterdam: Benjamins.Silke Scheible, Richard J. Whitt, Martin Durrell, andPaul Bennett.
2011.
Evaluating an ?off-the-shelf?POS-tagger on Early Modern German text.
In Pro-ceedings of the ACL-HLT 2011 Workshop on Lan-guage Technology for Cultural Heritage, Social Sci-ences, and Humanities (LaTeCH 2011), pages 19?23, Portland, Oregon, USA.Helmut Schmid and Florian Laws.
2008.
Estimation ofconditional probabilities with decision trees and anapplication to fine-grained POS tagging.
In Proceed-ings of COLING ?08, Manchester, Great Britain.Amir Zeldes, Julia Ritz, Anke L?deling, and ChristianChiarcos.
2009.
ANNIS: a search tool for multi-layer annotated corpora.
In Proceedings of CorpusLinguistics, Liverpool, UK.90
