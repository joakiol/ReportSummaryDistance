Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 255?262,Sydney, July 2006. c?2006 Association for Computational LinguisticsConceptual Coherence in the Generation of Referring ExpressionsAlbert GattDepartment of Computing ScienceUniversity of Aberdeenagatt@csd.abdn.ac.ukKees van DeemterDepartment of Computing ScienceUniversity of Aberdeenkvdeemte@csd.abdn.ac.ukAbstractOne of the challenges in the automaticgeneration of referring expressions is toidentify a set of domain entities coher-ently, that is, from the same conceptualperspective.
We describe and evaluatean algorithm that generates a conceptuallycoherent description of a target set.
Thedesign of the algorithm is motivated by theresults of psycholinguistic experiments.1 IntroductionAlgorithms for the Generation of Referring Ex-pressions (GRE) seek a set of properties that dis-tinguish an intended referent from its distractorsin a knowledge base.
Much of the GRE litera-ture has focused on developing efficient contentdetermination strategies that output the best avail-able description according to some interpretationof the Gricean maxims (Dale and Reiter, 1995),especially Brevity.
Work on reference to sets hasalso proceeded within this general framework (vanDeemter, 2002; Gardent, 2002; Horacek, 2004).One problem that has not received much atten-tion is that of conceptual coherence in the genera-tion of plural references, i.e.
the ascription of re-lated properties to elements of a set, so that theresulting description constitutes a coherent coverfor the plurality.
As an example, consider a ref-erence to {e1, e3} in Table 1 using the Incremen-tal Algorithm (IA) (Dale and Reiter, 1995).
IAsearches along an ordered list of attributes, select-ing properties of the intended referents that re-move some distractors.
Assuming the ordering inthe top row, IA would yield the postgraduate andthe chef, which is fine in case occupation is therelevant attribute in the discourse, but otherwise isarguably worse than an alternative like the italianand the maltese, because it is more difficult to seewhat a postgraduate and a chef have in common.type occupation nationalitye1 man postgraduate maltesee2 man undergraduate greeke3 man chef italianTable 1: Example domainSuch examples lead us to hypothesise the follow-ing constraint:Conceptual Coherence Constraint(CC): As far as possible, describeobjects using related properties.Related issues have been raised in the formalsemantics literature.
Aloni (2002) argues that anappropriate answer to a question of the form ?Whx??
must conceptualise the different instantiationsof x using a perspective which is relevant given thehearer?s information state and the context.
Kron-feld (1989) distinguishes a description?s functionalrelevance ?
i.e.
its success in distinguishing a ref-erent ?
from its conversational relevance, whicharises in part from implicatures.
In our example,describing e1 as the postgraduate carries the im-plicature that the entity?s academic role is relevant.When two entities are described using contrastingproperties, say the student and the italian, the con-trast may be misleading for the listener.Any attempt to port these observations to theGRE scenario must do so without sacrificing logi-cal completeness.
While a GRE algorithm shouldattempt to find the most coherent description avail-able, it should not fail in the absence of a coher-ent set of properties.
This paper aims to achievea dual goal.
First (?2), we will show that the CCcan be explained and modelled in terms of lexi-cal semantic forces within a description, a claimsupported by the results of two experiments.
Ourfocus on ?low-level?, lexical, determinants of ad-equacy constitutes a departure from the standardGricean view.
Second, we describe an algorithm255motivated by the experimental findings (?3) whichseeks to find the most coherent description avail-able in a domain according to CC.2 Empirical evidenceWe take as paradigmatic the case where a pluralreference involves disjunction/union, that is, hasthe logical form ?x (p(x) ?
q(x)), realised as adescription of the form the N1 and the N2.
By hy-pothesis, the case where all referents can be de-scribed using identical properties (logically, a con-junction), is a limiting case of CC.Previous work on plural anaphor processing hasshown that pronoun resolution is easier when an-tecedents are ontologically similar (e.g.
all hu-mans) (Kaup et al, 2002; Koh and Clifton, 2002).Reference to a heterogeneous set increases pro-cessing difficulty.Our experiments extended these findings to fulldefinite NP reference.
Throughout, we used a dis-tributional definition of similarity, as defined byLin (1998), which was found to be highly corre-lated to people?s preferences for disjunctive de-scriptions (Gatt and van Deemter, 2005).
The sim-ilarity of two arbitrary objects a and b is a functionof the information gained by giving a joint descrip-tion of a and b in terms of what they have in com-mon, compared to describing a and b separately.The relevant data in the lexical domain is thegrammatical environment in which words occur.This information is represented as a set of triples?rel, w,w?
?, where rel is a grammatical relation,w the word of interest and w?
its co-argumentin rel (e.g.
?
premodifies, dog, domestic ?).
LetF (w) be a list of such triples.
The informationcontent of this set is defined as mutual informationI(F (w)) (Church and Hanks, 1990).
The similar-ity of two words w1 and w2, of the same grammat-ical category, is:?
(w1, w2) =2 ?
I(F (w1) ?
F (w2))I(F (w1)) + I(F (w2))(1)For example, if premodifies is one of the rele-vant grammatical relations, then dog and cat mightoccur several times in a corpus with the same pre-modifiers (tame, domestic, etc).
Thus, ?
(dog, cat)is large because in a corpus, they often occur inthe same contexts and there is considerable infor-mation gain in a description of their common data.Rather than using a hand-crafted ontology to in-fer similarity, this definition looks at real languageCondition a b c distractorHDS spanner chisel plug thimbleLDS toothbrush knife ashtray clockFigure 1: Conditions in Experiment 1use.
It covers ontological similarity to the extentthat ontologically similar objects are talked aboutin the same contexts, but also cuts across ontolog-ical distinctions (for example newspaper and jour-nalist might turn out to be very similar).We use the information contained in theSketchEngine database1 (Kilgarriff, 2003), alargescale implementation of Lin?s theory basedon the BNC, which contains grammatical triplesin the form of Word Sketches for each word, witheach triple accompanied by a salience value in-dicating the likelihood of occurrence of the wordwith its argument in a grammatical relation.
Eachword also has a thesaurus entry, containing aranked list of words of the same category, orderedby their similarity to the head word.2.1 Experiment 1In Experiment 1, participants were placed in a sit-uation where they were buying objects from an on-line store.
They saw scenarios containing four pic-tures of objects, three of which (the targets) wereidentically priced.
Participants referred to them bycompleting a 2-sentence discourse:S1 The object1 and the object 2 cost amount.S2 The object3 also costs amount.If similarity is a constraint on referential coher-ence in plural references, then if two targets aresimilar (and dissimilar to the third), a plural refer-ence to them in S1 should be more likely, with thethird entity referred to in S2.Materials, design and procedure All the pic-tures were artefacts selected from a set of draw-ings normed in a picture-naming task with BritishEnglish speakers (Barry et al, 1997).Each trial consisted of the four pictures ar-ranged in an array on a screen.
Of the three targets(a, b, c), c was always an object whose name inthe norms was dissimilar to that of a and b. Thesemantic similarity of (nouns denoting) a and bwas manipulated as a factor with two levels: HighDistributional Similarity (HDS) meant that b oc-curred among the top 50 most similar items to a inits Sketchengine thesaurus entry.
Low DS (LDS))1http://www.sketchengine.co.uk256meant that b did not occur in the top 500 entriesfor a.
Examples are shown in Figure 2.1.Visual Similarity (VS) of a and b was also con-trolled.
Pairs of pictures were first normed with agroup who rated them on a 10-point scale basedon their visual properties.
High-VS (HVS) pairshad a mean rating ?
6; Low-VS LVS) pairs hadmean ratings ?
2.
Two sets of materials were con-structed, for a total of 2 (DS) ?
2 (V S) ?
2 = 8trials.29 self-reported native or fluent speakers of En-glish completed the experiment over the web.
Tocomplete the sentences, participants clicked on theobjects in the order they wished to refer to them.Nouns appeared in the next available space2.Results and discussion Responses were codedaccording to whether objects a and b were referredto in the plural subject of S1 (a + b responses) ornot (a?
b responses).
If our hypothesis is correct,there should be a higher proportion of a + b re-sponses in the HDS condition.
We did not expectan effect of VS.
In what follows, we report by-subjects Friedman analyses (?21); by-items analy-ses (?22); and by-subjects sign tests (Z) on propor-tions of responses for pairwise comparisons.Response frequencies across conditions differedreliably by subjects (?21 = 46.124, p < .001).The frequency of a + b responses in S1 was re-liably higher than that of a ?
b in the HDS condi-tion (?22 = 41.371, p < .001), but not the HVScondition (?22 = 1.755, ns).
Pairwise compar-isons between HDS and LDS showed a signif-icantly higher proportion of a + b responses inthe former (Z = 4.48, p < .001); the differ-ence was barely significant across VS conditions(Z = 1.9, p = .06).The results show that, given a clear choice ofentities to refer to in a plurality, people are morelikely to describe similar entities in a plural de-scription.
However, these results raise two furtherquestions.
First, given a choice of distinguishingproperties for individuals making up a target set,will participants follow the predictions of the CC?
(In other words, is distributional similarity rele-vant for content determination?)
Second, does thesimilarity effect carry over to modifiers, such asadjectives, or is the CC exclusively a constraint ontypes?2Earler replications involving typing yielded parallel re-sults and high conformity between the words used and thosepredicted by the picture norms.Three millionaires with a passion for antiques were spotteddining at a London restaurant.e1 One of the men, a Rumanian, is a dealeri .e2 The second, a princej , is a collectori .e3 The third, a dukej , is a bachelor.The XXXX were both accompanied by servants, but thebachelor wasn?t .Figure 2: Example discourses2.2 Experiment 2Experiment 2 was a sentence continuation task,designed to closely approximate content determi-nation in GRE.
Participants saw a series of dis-courses, in which three entities (e1, e2, e3) wereintroduced, each with two distinguishing proper-ties.
The final sentence in each discourse had amissing plural subject NP referring to two of these.The context made it clear which of the three en-tities had to be referred to.
Our hypothesis wasthat participants would prefer to use semanticallysimilar properties for the plural reference, even ifdissimilar properties were also available.Materials, design and procedure Materialsconsisted of 24 discourses, such as those in Fig-ure 2.2.
After an initial introductory sentence, the3 entities were introduced in separate sentences.In all discourses, the pairs {e1, e2} and {e2, e3}could be described using either pairwise similar ordissimilar properties (similar pairs are coindexedin the figure).
In half the discourses, the dis-tinguishing properties of each entity were nouns;thus, although all three entities belonged to thesame ontological category (e.g.
all human), theyhad distinct types (e.g.
duke, prince, bachelor).
Inthe other half, entities were of the same type, thatis the NPs introducing them had the same nominalhead, but had distinguishing adjectival modifiers.For counterbalancing, two versions of each dis-course were constructed, such that, if {e1, e2} wasthe target set in Version 1, then {e2, e3} was thetarget in Version 2.
Twelve filler items requiringsingular reference in the continuation were also in-cluded.
The order in which the entities were intro-duced was randomised across participants, as wasthe order of trials.
The experiment was completedby 18 native speakers of English, selected from theAberdeen NLG Group database.
They were ran-domly assigned to either Version 1 or 2.Results and discussion Responses were coded1 if the semantically similar properties were used(e.g.
the prince and the duke in Fig.
2.2); 2 if the257similar properties were used together with otherproperties (e.g.
the prince and the bachelor duke);3 if a superordinate term was used to replace thesimilar properties (e.g.
the noblemen); 4 otherwise(e.g.
The duke and the collector).Response types differed significantly in thenominal condition both by subjects (?21 =45.89, p < .001) and by items (?22 = 287.9, p <.001).
Differences were also reliable in the mod-ifier condition (?21 = 36.3, p < .001, ?22 =199.2, p < .001).
However, the trends across con-ditions were opposed, with more items in the 1 re-sponse category in the nominal condition (53.7%)and more in the 4 category in the modifier condi-tion (47.2%).
Recoding responses as binary (?sim-ilar?
= 1,2,3; ?dissimilar?
= 4) showed a significantdifference in proportions for the nominal category(?2 = 4.78, p = .03), but not the modifier cate-gory.
Pairwise comparisons showed a significantlylarger proportion of 1 (Z = 2.7, p = .007) and2 responses (Z = 2.54, p = .01) in the nominalcompared to the modifier condition.The results suggest that in a referential task, par-ticipants are likely to conform to the CC, but thatthe CC operates mainly on nouns, and less so on(adjectival) modifiers.
Nouns (or types, as we shallsometimes call them) have the function of cate-gorising objects; thus similar types facilitate themental representation of a plurality in a concep-tually coherent way.
According to the definitionin (1), this is because similarity of two types im-plies a greater likelihood of their being used inthe same predicate-argument structures.
As a re-sult, it is easier to map the elements of a plural-ity to a common role in a sentence.
A relatedproposal has been made by Moxey and Sanford(1995), whose Scenario Mapping Principle holdsthat a plural reference is licensed to the extent thatthe elements of the plurality can be mapped to acommon role in the discourse.
This is influencedby how easy it is to conceive of such a role for thereferents.
Our results can be viewed as providinga handle on the notion of ?ease of conception of acommon role?
; in particular we propose that likeli-hood of occurrence in the same linguistic contextsdirectly reflects the extent to which two types canbe mapped to a single plural role.As regards modifiers, while it is probably pre-mature to suggest that CC plays no role in modifierselection, it is likely that modifiers play a differentrole from nouns.
Previous work has shown thatid base type occupation specialisation girthe1 woman professor physicist plumpe2 woman lecturer geologist thine3 man lecturer biologist plumpe4 man chemist thinTable 2: An example knowledge baserestrictions on the plausibility of adjective-nouncombinations exist (Lapata et al, 1999), and thatusing unlikely combinations (e.g.
the immaculatekitchen rather than the spotless kitchen) impactsprocessing in online tasks (Murphy, 1984).
Unliketypes, which have a categorisation function, mod-ifiers have the role of adding information about anelement of a category.
This would partially ex-plain the experimental results: When elements ofa plurality have identical types (as in the modifierversion of our experiment), the CC is already satis-fied, and selection of modifiers would presumablydepend on respecting adjective-noun combinationrestrictions.
Further research is required to ver-ify this, although the algorithm presented belowmakes use of the Sketch Engine database to takemodifier-noun combinations into account.3 An algorithm for referring to setsOur next task is to port the results to GRE.
Themain ingredient to achieve conceptual coherencewill be the definition of semantic similarity.
Inwhat follows, all examples will be drawn from thedomain in Table 3.We make the following assumptions.
There isa set U of domain entities, properties of whichare specified in a KB as attribute-value pairs.
Weassume a distinction between types, that is, anyproperty that can be realised as a noun; and modi-fiers, or non-types.
Given a set of target referentsR ?
U , the algorithm described below generates adescription D in Disjunctive Normal Form (DNF),having the following properties:1.
Any disjunct in D contains a ?type?
property,i.e.
a property realisable as a head noun.2.
If D has two or more disjuncts, each a con-junction containing at least one type, then thedisjoined types should be as similar as pos-sible, given the information in the KB andthe completeness requirement: that the algo-rithm find a distinguishing description when-ever one exists.258We first make our interpretation of the CC moreprecise.
Let T be the set of types in the KB, andlet ?
(t, t?)
be the (symmetrical) similarity betweenany two types t and t?.
These determine a seman-tic space S = ?T, ??.
We define the notion of aperspective as follows.Definition 1.
PerspectiveA perspective P is a convex subset of S, i.e.
:?t, t?, t??
?
T :{t, t?}
?
P ?
?
(t, t??)
?
?
(t, t?)
?
t??
?
PThe aims of the algorithm are to describe ele-ments of R using types from the same perspective,failing which, it attempts to minimise the distancebetween the perspectives from which types are se-lected in the disjunctions of D. Distance betweenperspectives is defined below.3.1 Finding perspectivesThe system makes use of the SketchEnginedatabase as its primary knowledge source.
Sincethe definition of similarity applies to words, ratherthan properties, the first step is to generate all pos-sible lexicalisations of the available attribute-valuepairs in the domain.
In this paper, we simplify byassuming a one-to-one mapping between proper-ties and words.Another requirement is to distinguish betweentype properties (the set T ), and non-types (M )3.The Thesaurus is used to find pairwise similarityof types in order to group them into related clus-ters.
Word Sketches are used to find, for each type,the modifiers in the KB that are appropriate to thetype, on the basis of the associated salience values.For example, in Table 3, e3 has plump as the valuefor girth, which combines more felicitously withman, than with biologist.Types are clustered using the algorithm de-scribed in Gatt (2006).
For each type t, the al-gorithm finds its nearest neighbour nt in seman-tic space.
Clusters are then found by recursivelygrouping elements with their nearest neighbours.If t, t?
have a common nearest neighbour n, then{t, t?, n} is a cluster.
Clearly, the resulting sets areconvex in the sense of Definition 1.
Each modi-fier is assigned to a cluster by finding in its WordSketch the type with which it co-occurs with thegreatest salience value.
Thus, a cluster is a pair3This is determined using corpus-derived information.Note that T and M need not be disjoint, and entities can havemore than one type propertyT: {lecturer, professor}T: {woman, man}M: {plump, thin}T: {geologist, physicist,biologist, chemist}32110.61Figure 3: Perspective Graph?P,M ??
where P is a perspective, and M ?
?
M .The distance ?
(A,B) between two clusters A andB is defined straightforwardly in terms of the dis-tance between their perspectives PA and PB:?
(A,B) = 11 +Px?PA,y?PB?
(x,y)|PA?PB |(2)Finally, a weighted, connected graph G =?V,E, ??
is created, where V is the set of clus-ters, and E is the set of edges with edge weightsdefined as the semantic distance between perspec-tives.
Figure 3.1 shows the graph constructed forthe domain in Table 3.We now define the coherence of a descriptionmore precisely.
Given a DNF description D, weshall say that a perspective P is realised in D ifthere is at least one type t ?
P which is in D.Let PD be the set of perspectives realised in D.Since G is connected, PD determines a connectedsubgraph of G. The total weight of D, w(D) is thesum of weights of the edges in PD.Definition 2.
Maximal coherenceA description D is maximally coherent iff thereis no description D?
coextensive with D such thatw(D) > w(D?).
(Note that several descriptions of the same ref-erent may all be maximally coherent.
)3.2 Content determinationThe core of the content determination proceduremaintains the DNF description D as an associa-tive array, such that for any r ?
R, D[r] is a con-junction of properties true of r. Given a cluster?P,M?, the procedure searches incrementally firstthrough P, and then M , selecting properties thatare true of at least one referent and exclude somedistractors, as in the IA (Dale and Reiter, 1995).By Definition 2, the task of the algorithm isto minimise the total weight w(D).
If PD is the259set of perspectives represented in D on termina-tion, then maximal coherence would require PDto be the subgraph of G with the lowest total costfrom which a distinguishing description could beconstructed.
Under this interpretation, PD corre-sponds to a Shortest Connection, or Steiner, Net-work.
Finding such networks is known to be NP-Hard.
Therefore, we adopt a weaker (greedy) in-terpretation.
Under the new definition, if D isthe only description for R, then it trivially satis-fies maximal coherence.
Otherwise, the algorithmaims to maximise local coherence.Definition 3.
Local coherenceA description D is locally coherent iff:a. either D is maximally coherent orb.
there is no D?
coextensive with D, obtainedby replacing types from some perspective inPD with types from another perspective suchthat w(D) > w(D?
).Our implementation of this idea begins thesearch for distinguishing properties by identifyingthe vertex of G which contains the greatest num-ber of referents in its extension.
This constitutesthe root node of the search path.
For each nodeof the graph it visits, the algorithm searches forproperties that are true of some subset of R, andremoves some distractors, maintaining a set N ofthe perspectives which are represented in D up tothe current point.
The crucial choice points arisewhen a new node (perspective) needs to be visitedin the graph.
At each such point, the next node nto be visited is the one which minimises the totalweight of N , that is:minn?V?u?Nw(u, n) (3)The results of this procedure closely approxi-mate maximal coherence, because the algorithmstarts with the vertex most likely to distinguishthe referents, and then greedily proceeds to thosenodes which minimise w(D) given the currentstate, that is, taking all previously used nodes intoaccount.As an example of the output, we will takeR = {e1, e3, e4} as the intended referents in Table3.
First, the algorithm determines the cluster withthe greatest number of referents in its extension.In this case, there is a tie between clusters 2 and3 in Figure 3.1, since all three entities have typeproperties in these clusters.
In either case, theentities are distinguishable from a single cluster.If cluster 3 is selected as the root, the output is?x [physicist(x) ?
biologist(x) ?
chemist(x)].In case the algorithm selects cluster 2 as theroot node the final output is the logical form?x [man(x) ?
(woman(x) ?
plump(x))].There is an alternative description that thealgorithm does not consider.
An algorithmthat aimed for conciseness would generate?x [professor(x) ?man(x)] (the professor andthe men), which does not satisfy local coherence.These examples therefore highlight the possibletension between the avoidance of redundancy andachieving coherence.
It is to an investigation ofthis tension that we now turn.4 EvaluationIt has been known at least since Dale and Reiter(1995) that the best distinguishing description isnot always the shortest one.
Yet, brevity plays apart in all GRE algorithms, sometimes in a strictform (Dale, 1989), or by letting the algorithm ap-proximate the shortest description (for example, inthe Dale and Reiter?s IA).
This is also true of refer-ences to sets, the clearest example being Gardent?sconstraint based approach, which always finds thedescription with the smallest number of logical op-erators.
Such proposals do not take coherence (inour sense of the word) into account.
This raisesobvious questions about the relative importance ofbrevity and coherence in reference to sets.The evaluation took the form of an experimentto compare the output of our Coherence Modelwith the family of algorithms that have placedBrevity at the centre of content determination.
Par-ticipants were asked to compare pairs of descrip-tions of one and the same target set, selecting theone they found most natural.
Each descriptioncould either be optimally brief or not (?b) and alsoeither optimally coherent or not (?c).
Non-briefdescriptions, took the form the A, the B and the C.Brief descriptions ?aggregated?
two disjuncts intoone (e.g.
the A and the D?s where D comprises theunion of B and C).
We expected to find that:H1 +c descriptions are preferred over ?c.H2 (+c,?b) descriptions are preferred over onesthat are (?c,+b).H3 +b descriptions are preferred over ?b.Confirmation of H1 would be interpreted as ev-idence that, by taking coherence into account, our260Three old manuscripts were auctioned at Sotheby?s.e1 One of them is a book, a biography of a composer.e2 The second, a sailor?s journal, was publishedin the form of a pamphlet.
It is a record of a voyage.e3 The third, another pamphlet, is an essay by Hume.
(+c,?b) The biography, the journal and the essay were sold to a col-lector.
(+c, +b) The book and the pamphlets were sold to a collector.
(?c, +b) The biography and the pamphlets were sold to a collector.
(?c,?b) The book, the record and the essay were sold to a collector.Figure 4: Example domain in the evaluationalgorithm is on the right track.
If H3 were con-firmed, then earlier algorithms were (also) on theright track by taking brevity into account.
Con-firmation of H2 would be interpreted as meaningthat, in references to sets, conceptual coherence ismore important than brevity (defined as the num-ber of disjuncts in a disjunctive reference to a set).Materials, design and procedure Six dis-courses were constructed, each introducing threeentities.
Each set of three could be describedusing all 4 possible combinations of ?b ?
?c(see Figure 4).
Entities were human in two ofthe discourses, and artefacts of various kinds inthe remainder.
Properties of entities were intro-duced textually; the order of presentation was ran-domised.
A forced-choice task was used.
Eachdiscourse was presented with 2 possible continua-tions consisting of a sentence with a plural subjectNP, and participants were asked to indicate the onethey found most natural.
The 6 comparisons cor-responded to 6 sub-conditions:C1.
Coherence constanta.
(+c,?b) vs. (+c,+b)b.
(?c,?b) vs. (?c,+b)C2.
Brevity constanta.
(+c,?b) vs. (?c,?b)b.
(+c,+b) vs. (?c,+b)C3.
Tradeoff/controla.
(+c,?b) vs. (?c,+b)b.
(?c,?b) vs. (+c,+b)Participants saw each discourse in a single con-dition.
They were randomly divided into sixgroups, so that each discourse was used for a dif-ferent condition in each group.
39 native Englishspeakers, all undergraduates at the University ofAberdeen, took part in the study.Results and discussion Results were coded ac-cording to whether a participant?s choice was ?bC1a C1b C2a C2b C3a C3b+b 51.3 43.6 ?
?
30.8 76.9+c ?
?
82.1 79.5 69.2 76.9Table 3: Response proportions (%)and/or ?c.
Table 4 displays response propor-tions.
Overall, the conditions had a significantimpact on responses, both by subjects (Friedman?2 = 107.3, p < .001) and by items (?2 =30.2, p < .001).
When coherence was kept con-stant (C1a and C1b), the likelihood of a responsebeing +b was no different from ?b (C1a: ?2 =.023, p = .8; C1b: ?2 = .64, p = .4); the con-ditions C1a and C1b did not differ significantly(?2 = .46, p = .5).
By contrast, conditionswhere brevity was kept constant (C2a and C2b)resulted in very significantly higher proportions of+c choices (C2a: ?2 = 16.03, p < .001; C2b:?2 = 13.56, p < .001).
No difference was ob-served between C2a and C2b (?2 = .08, p = .8).In the tradeoff case (C3a), participants were muchmore likely to select a +c description than a +bone (?2 = 39.0, p < .001); a majority optedfor the (+b,+c) description in the control case(?2 = 39.0, p < .001).The results strongly support H1 and H2, sinceparticipants?
choices are impacted by Coherence.They do not indicate a preference for brief de-scriptions, a finding that echoes Jordan?s (2000),to the effect that speakers often relinquish brevityin favour of observing task or discourse con-straints.
Since this experiment compared our al-gorithm against the current state of the art in ref-erences to sets, these results do not necessarilywarrant the affirmation of the null hypothesis inthe case of H3.
We limited Brevity to number ofdisjuncts, omitting negation, and varying only be-tween length 2 or 3.
Longer or more complex de-scriptions might evince different tendencies.
Nev-ertheless, the results show a strong impact of Co-herence, compared to (a kind of) brevity, in strongsupport of the algorithm presented above, as a re-alisation of the Coherence Model.5 Conclusions and future workThis paper started with an empirical investigationof conceptual coherence in reference, which ledto a definition of local coherence as the basis fora new greedy algorithm that tries to minimise thesemantic distance between the perspectives repre-261sented in a description.
The evaluation stronglysupports our Coherence Model.We are extending this work in two directions.First, we are investigating similarity effects acrossnoun phrases, and their impact on text readabil-ity.
Finding an impact of such factors would makethis model a useful complement to current theoriesof discourse, which usually interpret coherence interms of discourse/sentential structure.Second, we intend to relinquish the assumptionof a one-to-one correspondence between proper-ties and words (cf.
Siddharthan and Copestake(2004)), making use of the fact that words can bedisambiguated by nearby words that are similar.To use a well-worn example: the ?financial institu-tion?
sense of bank might not make the river andits bank lexically incoherent as a description of apiece of scenery, since the word river might causethe hearer to focus on the aquatic reading of theword anyway.6 AcknowledgementsThanks to Ielka van der Sluis, ImtiazKhan, Ehud Reiter, Chris Mellish, GraemeRitchie and Judith Masthoff for useful com-ments.
This work is part of the TUNAproject (http://www.csd.abdn.ac.uk/research/tuna), supported by EPSRC grantno.
GR/S13330/01ReferencesM.
Aloni.
2002.
Questions under cover.
In D. Barker-Plummer, D. Beaver, J. van Benthem, and P. Scottode Luzio, editors, Words, Proofs, and Diagrams.CSLI, Stanford, Ca.C.
Barry, C. M. Morrison, and A. W. Ellis.
1997.Naming the snodgrass and vanderwart pictures.Quarterly Journal of Experimental Psychology,50A(3):560?585.K.
W. Church and P. Hanks.
1990.
Word associationnorms, mutual information and lexicography.
Com-putational Linguistics, 16(1):22?29.R.
Dale and E. Reiter.
1995.
Computational interpre-tation of the Gricean maxims in the generation of re-ferring expressions.
Cognitive Science, 19(8):233?263.Robert Dale.
1989.
Cooking up referring expressions.In Proc.
27th Annual Meeting of the Association forComputational Linguistics.C.
Gardent.
2002.
Generating minimal definite de-scriptions.
In Proc.
40th Annual Meeting of the As-sociation for Computational Linguistics.A.
Gatt and K. van Deemter.
2005.
Semantic simi-larity and the generation of referring expressions: Afirst report.
In Proceedings of the 6th InternationalWorkshop on Computational Semantics, IWCS-6.A.
Gatt.
2006.
Structuring knowledge for referencegeneration: A clustering algorithm.
In Proc.
11thConference of the European Chapter of the Associa-tion for Computational Linguistics.H.
Horacek.
2004.
On referring to sets of objects natu-rally.
In Proc.
3rd International Conference on Nat-ural Language Generation.P.
W. Jordan.
2000.
Can nominal expressions achievemultiple goals?
In Proceedings of the 38th AnnualMeeting of the Association for Computational Lin-guistics.B.
Kaup, S. Kelter, and C. Habel.
2002.
Represent-ing referents of plural expressions and resolving plu-ral anaphors.
Language and Cognitive Processes,17(4):405?450.A.
Kilgarriff.
2003.
Thesauruses for natural languageprocessing.
In Proc.
NLP-KE, Beijing.S.
Koh and C. Clifton.
2002.
Resolution of the an-tecedent of a plural pronoun: Ontological categoriesand predicate symmetry.
Journal of Memory andLanguage, 46:830?844.A.
Kronfeld.
1989.
Conversationally relevant descrip-tions.
In Proc.
27th Annual Meeting of the Associa-tion for Computational Linguistics.M.
Lapata, S. McDonald, and F. Keller.
1999.
Deter-minants of adjective-noun plausibility.
In Proc.
9thConference of the European Chapter of the Associa-tion for Computational Linguistics.D.
Lin.
1998.
An information-theoretic definitionof similarity.
In Proc.
International Conference onMachine Learning.L.
Moxey and A. Sanford.
1995.
Notes on plural refer-ence and the scenario-mapping principle in compre-hension.
In C.Habel and G.Rickheit, editors, Focusand cohesion in discourse.
de Gruyter, Berlin.G.L.
Murphy.
1984.
Establishing and accessing refer-ents in discourse.
Memory and Cognition, 12:489?497.A.
Siddharthan and A. Copestake.
2004.
Generat-ing referring expressions in open domains.
In Proc.42nd Annual Meeting of the Association for Compu-tational Linguistics.K.
van Deemter.
2002.
Generating referring expres-sions: Boolean extensions of the incremental algo-rithm.
Computational Linguistics, 28(1):37?52.262
