Session 11: Natural Language IIDeborah A. Dahl, ChairUnisys Defense SystemsCenter  for Advanced Information TechnologyPaoli, PA 19301Three of the four papers in this session described workaimed at reducing the amount of labor-intensive "hand-crafting" of natural anguage systems.
The fourth paperdescribed the current need for machine translation andmachine-assisted translation and advocated an interlingualapproach involving acoordinated effort by several sites.It is extremely encouraging to see that new ideas arebeing explored for reducing the effort required to developnew applications of natural language understanding.
Theseideas will clearly be needed to enable natural anguagetechnology to be applied to real problems.
The first threepapers described three different approaches tothis problem- using statistical automatic training techniques (BBN),developing "generic" text processing capabilities (GE), andthe use of analogical reasoning to hypothesize new wordsenses (Berkeley).
The work described in these papers wasgenerally exploratory in nature.
It will be exciting to seehow these approaches continue to develop and become in-tegrated into full-scale systems.The first paper, by Ayuso, et.
al.
from BBN, describedthree experiments in statistical pproaches - part of speechtagging, probabilistic parsing, and acquisition of lexicalsyntax.
The most intriguing aspect of this work was thepotential for synergy among the various tools described.For example, one suggestion was that the probabilisficparsing could be used to control the ambiguity inherent indealing with unknown words.The second paper, by Jacobs, et.
al., from GE, describedan approach to handling large amounts of unrestricted textwhich involves developing generic text processingcapabilities.
This paper eports on some of the tools whichunderlie this approach, including the development of a10,000 word lexicon and various text preprocessing tools.These tools are used to produce a text tagged with wordsenses.
This result is interesting because it shows that it ispossible to produce at least part of a semantic analysis(word sense tagging) for arbitrary text.Robert Wilensky's paper on lexical acquisition was thethird paper in this session.
This work uses lexical sub-regularities to extend the meaning of words used in newsenses.
This paper lists a number of lexical subregularitiesand outlines apreliminary procedure for lexical acquisition.This work is in its early stages and it should be very inter-esting to see how it develops.
This capability should bequite useful for making natural language systems more in-dependent of their developers.The final paper in the session (Wilks, et.
al.)
was aproposal for a new effort in machine translation, based onan interlingua approach.
It makes a strong case for the needfor such work, since currently available machine translationsystems are based on very old technology, although theneed for translation assistance is so great hat they are stillbeing used.Several interesting points were made in the discussionof the Wilks paper.
One criticism was made that theproposal offered no striking new ideas.
The response to thiswas that the project would pull together existing skills.
Inaddition, it should also be noted that there are many currentideas in areas such as parsing that have not yet been ex-ploited in machine translation systems.
Other discussionsconcerned the relative merits of transfer vs. interlingua p-proaches, and statistical vs. knowledge-based t chniques.353
