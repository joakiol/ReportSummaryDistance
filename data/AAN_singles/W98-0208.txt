Semantic VisualizationPenny Chase, Ray D'Amore*, Nahum Gershon*, Rod Holland, Rob Hyland, Inderjeet Mani*,Mark Maybury, Andy Merlino, Jim RaysonThe MITRE Corporation202 Burlington RoadBedford, MA 01730, USA* 1820 Dolley Madison Blvd.McLean, VA 22102, USA{pc, rdamore, gershon, rholland, hyland, imani, maybury, andy, jrayson}@rnitre.orgACL-COLING Workshop on Content Visualization and Intermedia RepresentationsAbstractThis paper summarizes several initiatives at MITREthat are investigating the visualization of a range ofcontent.
We present results of our work in relevancyvisualization, news visualization, world eventsvisualization and sensor/battlefield visualization toenhance user interaction in information access andexploitation tasks.
We summarize several initiativeswe are currently pursuing and enumerate unsolvedproblems.1.
Visualizing Semantic ContentVisualization can support effective and efficientinteraction with a range of information for avariety of tasks.
As Figure 1 illustrates,information (data elements, attributes, relations,events) can be encoded in (possibly interactive)visual displays which users can exploit for avariety of cognitive tasks such as retrieval,analysis (e.g., of trends, anomalies, relations),summarization, and inference.
In this paper weconsider a range of semantic content, visualmechanisms, and cognitive tasks to deepen ourunderstanding of the role of interactivevisualization.f21~ ....Figure 1.
Information Visualization Process2.
Document Relevancy VisualizationToday's users are faced with a dizzying array ofinformation sources.
MITRE's Forager forInformation on the SuperHighway (FISH)(Smotroff, Hirschrnan, and Bayer 1995) wasdeveloped to enable the rapid evaluation ofinformation sources and servers.
Figure 2aillustrates the application of FISH to three WideArea Information Server (WAIS) TM databasescontaining information on joint ventures from theMessage Understanding Conference (MUC).Figure 2b illustrates the application of FISH tovisualize e-mail clustered by topic type for amoderator supporting a National PerformanceReview electronic town hall.52Figure 2a.
WAIS FISH Figure 2b.
NPR FISHThe traditional WAIS interface of a query boxand a list of resulting hits is replaced by aninterface which includes a query box, a historicallist of queries, and a graphically encoded isplayof resulting hits (an example of which is shownin Figure 2a).
In WAIS, the relevancy of adocument to a given keyword query is measuredon a scale from 1-1000 (where 1000 is thehighest relevancy) by the frequency and locationof (stems of) query keywords in documents.Motivated by the University of Maryland'sTreeMap research for hierarchical informationvisualization, FISH encodes the relevance ofeach document o a given query (or set ofcompound queries) using both color saturationand size.In the example presented in Figure 2a, eachdatabase is allocated screen size in proportion tothe number of and degree with which documentsare relevant to the given query.
For example, theMEAD database on the left of the output windowis given more space than the PROMT database inthe middle because it has many more relevantdocuments.
Similarly, individual documents hathave higher elevancy measures for a given queryare given proportionally more space and a highercolor saturation.
In this manner, a user canrapidly scan several arge lists of documents tofind relevant ones by focusing on those withhigher color saturation and more space.Compound queries can be formulated via the"Document Restrictions" menu by selecting theunion or intersection of previous queries, ineffect an AND or OR Boolean operator acrossqueries.In Figure 2a, the user has selected the union ofdocuments relevant to the query "japan" and thequery "automobile", which will return alldocuments which contain the keywords "japan"or "automobile".
Color coding can be varied onthese documents, for example, to keep their colorsaturation distinct (e.g., blue vs. red) to enablerapid contrast of hits across queries withindatabases (e.g., hits on Japan vs. hits onautomobile) or to mix their saturation so thatintersecting keyword hits can be visualized (e.g.,bright blue-reds could indicate highly relevantJapanese automobile documents, dark theopposite).
In the example in Figure 2a, blueencodes Japan, red Automobile; the color codingis set for mixed saturation, the union of therelevant document sets for those two keywords isselected, and the order (from top to bottom in thedisplay) is used to encode the WAIS relevancyranking.
One issue is just how effectively userscan discriminate mixed colors.fGA.O study hnk$ (hemi<al Oou~le clkk to edit (ol~s: ~rag (o remanget -e,ghtj I~r?,du~ t -e~.
t lt og/~ 3/96-T RANSC RtPT: Jmako n=~lt on the tame ~*vli c~b leic .
.
.
.
.
.
.
.
.
.
,~..: ,,~0 ~ c.~, L .~.
"IL,*2U;,?o'Z~%"-;';:' ,~%;;;: ~'0, ,, ............ ,,,J,1: ............................. ,IxFigure 2c.
J-FISH Multiserver VisualizationMore recently, we have explored multiple serverevaluation on popular World Wide Web searchengines.
For example, Figure 2c illustrates aquery across multiple servers.
Research issuesinclude differences in relevancy rankingalgorithms, encoding of multiple attributesbeyond relevancy using color or size (e.g., length,53quality, cost, source), and document collectionswhich are heterogeneous in size, content, andformat.3.
Document Structure/Content VisualizationFigure 3a (Gershon et al 1995; Gershon 1996)illustrates another navigation mechanism inwhich the user is able to view a hierarchy of thebrowse space.
The left: hand of Figure 3adisplays the traditional HTML layout of a webpage whereas the right hand side illustrates ahierarchical, navigable view automaticallygenerated from the underlying structure of thebrowsing space.
The user can create a personalspace by interactively and visually modify thestructure of hyperspace or extracting segments ofthe documents.T'h?
M I T~4.E ~'por  md4n k ?
mudWac~c~'o*'idm t~ekn.,e'tJ tnd ma,tepc paidmseeItn~ ?lr~irau~t i1 i~n~ i\u~ ~kHFigure 3a.
Hyperspace Structure VisualizationFor discovery and analysis of new informationand relationships in retrieved documents, wehave developed a method for aggregatingrelevant information and representing it visually(Gershon, et al 1995).
The method is based onrepresenting correlations of words within adocument in a table.
These tables could be verylarge depending on the size of the document thusmaking it difficult for the user to perceive andmake sense of all the highly relevant correlations.Since the order of the words is not usually basedon contents, the order of the words is permuteduntil the highly relevant correlations areconcentrated in one comer.FatFatigue 22Aches 10Alments 2nausea 15Smoking3Snacks471133sedentary24FatigueAchesNauseaAilmentsfat snacks221015smoking3 4711 3 433 5 12 4sedentary2Figure 3b.
Example of Unaggregated (top) andAggregated (bottom) TablesOther research at MITRE has focused onautomatic discovery and visualization ofsemantic relations among individual and groupsof documents (Mani and Bloedom 1997).
Figure3c illustrates the results of visualization of a setof documents using the NetMap visualizationsoftware after clustering these into related groupswhich appear around a circle.
Outside of eachcluster on the circle are displayed intraclusterrelations; in the center of the circle areintercluster relations (e.g., a shared named entitysuch as a person, place, or thing which appears inmultiple documents).
The user can zoom in anypart of the graph.
This is shown in Figure 3d,which shows individual people (green) andorganizations (aquamarine).Selecting an individual entity from a documentreturns adisplay such as that in Figure 3e.
Figure3e illustrates individual entities encoded withcolor and shapes (e.g., people in green stickfigures, organizations in aquamarine diamonds,locations in purple jagged rectangles, documentsin yellow circles, person-organization relations inwhite squares).
Lines and their properties (e.g.,color, dashed) can encode relations among theseentities (e.g., co-occurrence in documents).
Thisprovides a richer mechanism for discovering54interdocument and interentity relationshipsduring analysis.
Current research isinvestigating the role of automated textsummarization, document retrieval andnavigation and visualization.Figure 3d.
Zooming in on Document ClusterFigure 3c.
Document Cluster VisualizationFigure 3e.
Entity Relation Visualization554.
Named Entity/News VisualizationMITRE's Broadcast News Navigator (BNN) is asystem that is investigating analysis of trends innews reporting.
BNN performs multistream(audio, video, text) analysis to eliminatecommercials, segment stories, extract namedentities (i.e., people, organization, location) andkeyframes, and classify and summarize stories(Merlino, Morey, and Maybury 1997).
BNN'sintuitive web-based interface gives the user theability to browse, query, extract from andcustomize digitized broadcasts.
Figure 4illustrates a trend analysis display from BNN thatshows the most frequently mentioned namedentities reported on CNN Prime News TM fromOctober to November of 1997.
"China" spikes inthe center of the graph, associated with a statevisit to Washington.
Later "Iraq" spikes which iscorrelated with news regarding UN siteinspections.
The user can click on any point onthe line graphs and be brought o a list of storiesthat mention that named entity.I k ' l lq~ 11~.~Figure 4.
Broadcast News Visualization \]In contrast, the user can formulate a queryspecifying keywords, named entities or subjects.Figure 5a shows the results of executing thequery: Find me stories which have a topic of1 Note in the display the occurrence of the terms "U.S." and"United States".
BNN performs no co-reference r solution,a topic of current research at MITRE.
"chemicals", the keywords "chemical weapons",person "Sadam Hussein", organization"Pentagon", and location "Iraq".
Each story inthis "Story Skim" view is represented by akeyframe and the three most frequent namedentities.
Selecting one of these stories yields a"Story Detail" display, which as shown in Figure5b including a keyframe, named entities, subjectclassification and pointers to the closed captionand video source.Figure 5a.
BNN "Story Skim" VisualizationSummary Closed Source TopicsFigure 5b.
"Story Detail" visualizationCurrent research is exploring connecting thesebroadcast news stories withvisualizing topic frequenciesmechanisms for low qualitytranscriptions of broadcast56intemet stones,over time, andspoken languagestories.
Otherinvestigations are focusing on which presentationmixes (e.g., keyffames, named entities, one linesummary, full video source) are most effectivefor story retrieval and fact extraction from news(Merlino and Maybury 1998).5.
Geographic Event VisualizationThe Geospatial News on Demand Environment(GeoNODE) initiative at MITRE is a new projectinvestigating visualizing geographic aspects ofnews events.
This program builds on MITRE'sBNN, described in the previous section, andMSIIA, addressed in the subsequent section.GeoNODE is based on the research area ofGeographic Visualization which investigatesmethods and tools that impact the way scientistsand others conceptualize and exploregeoreferenced data, make decisions critical tosociety, and learn about the world (MacEachrenand Ganter 1990, Taylor 1991).
Since newsreports are about events in the world, the reportedevents and trends can be assessed, queried, andreviewed effectively by leveraging a person'spreexisting knowledge of the world's geography.The objective of GeoNODE is to understand theinformation integration of geospatial/temporalvisualizations, information retrieval, multimedia,and other technologies to support browsing,analysis, and rapid inference from broadcastnews.As shown in Figure 6, GoeNODE will analyzeglobal and local cooperation and conflict foundin broadcast news, internet, newswire and radiosources as well as broadcast news.
Processingwill include the identification, extraction, andsummarization of events from national andinternational sources.
GeoNODE will considerevent types (e.g., terrorist acts, narcotrafficking,peace accords), frequency, and severity in aninteractive geo-spatial/temporal context thatsupports browsing, retrieval, analysis andinference.57Figure 6.
GeoNODE ArchitectureAlthough a geographical context can enhance aperson's understanding of reported events andtherefore facilitate news retrieval and furtherqueries, the same familiar visualization concernsapply to geographic presentation that are salientin visualizing any data rich multivariateinformation space.
The GeoNODE userexperience is derived from research, experienceand standard practice in the visual search andretrieval domains: Overview first, zoom andfilter, then details-on-demand (Shneiderman1994).
During each stage of the visualizationprocess, cartographic methods and spatialanalysis techniques are applied.
These can beconsidered as a kind of grammar that allows forthe optimal design, production and use of maps,depending on the application (Kraat 1997).
Selectcartographic generalization operators are appliedto address key multi-scale and informationoverload problems (Buttenfield 1991).GeoNODE addresses Knowledge Representation(KR) and information fusion issues that areimportant o the news event presentation.
TheKR activities specific to GeoNODE areconcerned with discovering and manipulatinggeospatial and temporal information, specificallyinvestigating the following:improved natural anguage processing ofplace names that are central tounderstanding a news report?
news event modeling?
cartographic generalization rules?
transformation f news events to visualmetaphorsSpatial information management is currentlygrowing in its utility to commercial pplications,and several industries have already begun toexplicitly rely on GIS systems, although most(53%) companies are evaluating while an averageof only 7% are implementing or using a GIS(IDC 1997).
Accompanying the growing interestin spatial information is a technology trendinfluencing the architecture of GeoNODE,mainly, a shift from single-purpose/standaloneGIS applications to geospatial extensions andservices for databases, component frameworks,data warehouses and data analysis applications.By supporting a component-based architecture,GeoNODE can more readily take advantage offuture geospatial services and an expandingnumber of news sources (internet, newswire,radio, and other broadcast ources).Further esearch will investigate incorporation ofsummarization, geospatial/temporal KR, andother traditional visualization techniques.
Forexample, Figure 7 illustrates some of the kinds ofvisualizations that are being explored by otherresearchers, such as the use of color andgeolocation to encode relations amonggeographic entries.
Figure 7 is a geographicvisualization of early WWW usage available athttp ://www.cybergeography.org/atlas/atlas.html.These and other research threads will shapeGeoNODE into a visualization component forreasoning about news events in geographic space.As a long term objective, the system architectureshould allow for navigation and retrieval fromtopic, conceptual, and web spaces where a usercan access, update and annotate xisting datawith spatial information.Figure 7.
Visualization of Geospatial Relationships6.
Sensor VisualizationThe Multisource Integrated Information Analysis(MSIIA) project, led by Steve Hansen at MITRE,is exploring effective mechanisms for sensor andbattlefield visualization.
For example, nationaland military intelligence analysts are chargedwith monitoring and exploiting dozens of sourcesof information in real time.
These range fromsensors which capture images (infrared, electro-optical, multispectral) tomoving target indicatorscharacterized by a point and some features (e.g.,tracked vs. wheeled vehicle) to signalsintelligence characterized by centroids and errorelipses.
Knowing which source to select andwhich sensors to task is paramount to successfulsituation assessment.
An integrated view intowhat sensors are where when, as well as a fusedpicture of their disparate information types andoutputs, would be invaluable.
Figure 8 illustratesone such visualization.
The x-y dimension of theupper display captures the coordinates of ageospatial rea whereas the y coordinate displaystime.
This enables the user to view which areasare being sensed by which type of sensor(encoded by color or implicitly by the resultantcharacteristic shape).
For example, a largepurple cylinder represents the area over timeimaged by a geosychronous satellite, the greencylinders are images taken over time of spots onthe surface of the earth, whereas the wavy blueline is the ground track of a sensor flying acrossan area (e.g., characteristic of a unmanned airvehicle such as predator).
If we take a slice at aparticular time of the upper display in Figure 8we get the coverage of particular areas from aspecific time.
If we project all sensor coverages58over an area downward to the surface, we obtainthe image shown in the lower display of Figure 8.military for planning and training.
The sand canbe sculpted to match the terrain in a specificgeographic region.
People standing around thetable can place plastic or metal models ofvehicles and other assets over this terrain modelto indicate force deployment and move themaround the terrain to indicate and/or rehearseforce movements.Figure 8.
Sensor Coverage VisualizationA user can utilize this display to determine whatmaterial is available for a given time and space,analyze unattended coverage areas, and planfuture collections.
MSIIA is also investigatinggeoregistration and display of the results ofcollections in an integrated, synthetic view of theworld (e.g., fusing maps with images with radarreturns).
We consider next another example ofsynthetic views of the world.7.
Collaboration and Battlefield VisualizationJust as visualization plays an important role ininformation space visualization for MSIIA,MITRE's research on the CollaborativeOmniscient Sandtable Metaphor (COSM) seeksto define a new generation of human-machineinterfaces for military Command and Control(C2).
The "sandtable" underlying COSM is aphysical table whose top is rimmed with shortwalls and filled with sand.
It is used in the59In defining COSM, we expanded thefunctionality of a sandtable and moved it into anelectronic domain.
It now taps into globalgigabyte databases of C2 information whichrange from static data on airfield locations, toreal-time feeds from hundreds ground, air, andspace based sensors.
This data is used tosynthesize macroscopic or microscopic views ofthe world that form the foundation of acollaborative visualization system.
Manipulatingthese views leads not only to modifying data, butalso directing the actions of the underlyingphysical assets (e.g., moving an icon causes anaircraft o be redirected from point A to point B).A conceptual view of COSM is shown in Figure9, where participants at air, land, and sealocations collaborate over an electronicsandtable.
Some users are physically present,while others are represented by their avatars.The key elements of COSM are geographicindependence (transparent access to people, data,software, or assets regardless of location), amultimodal, direct manipulation i terface with aninitial emphasis is on the visual modality,heterogeneous platform support (enabling usersto tailor data depictions to a range of platformcapabilities), and data linkage (maintaining allparent, child, and peer relationships in the data).Figure 9.
Conceptual View of COSMFigure 10.
Virtual Reality InstantiationA first instantiation of COSM was implementedusing Virtual Reality (VR) technology, asillustrated in Figure 10.
The table is astereoscopic projection system driven by agraphics workstation.
It uses a horizontal displaysurface approximately 6 feet wide and 4 feet deepto display maps, imagery, and models of theterrain and objects upon or above the terrain.Since it is stereoscopic, objects above the terrain,such as airbome aircraft, appear to be above thesurface of the table.
The vertical screen behindthe table is a rear-projection display usedprimarily used for collaboration support.
At thetop, we see a panel of faces representing all theremote users who have similar systems and arecurrently connected to this one with audio, video,and data links.
The table serves as a sharedwhiteboard that is visible to all the users and canbe manipulated by them.
The larger faces at thebottom of the vertical screen are two users whohave "stepped up to the podium" and currentlyhave control of what it being seen on the table.The figure shows the user interacting with thetable through the use of two magnetic positiontrackers.
The first is attached to a pair ofstereoscopic glasses, and as the user moves hishead and walks around the table the computerdetermines his eyepoint location from the trackerand recomputes his view accordingly.
Thesecond tracker is attached to a glove that servesas an input device.
The user's gloved handbecomes a cursor and he can use his fingers totouch an object to indicate selection or grab andmove an object o indicate an action.Several different kinds of information can bedisplayed on the table.
Figure 11 illustrates adisplay of current air and ground information.There are several aircraft depicted as realisticmodels, with the relative scale of the modelsrepresenting the relative sizes of the respectiveaircraft.
They move in real-time, with thestereoscopic display making them appear to beflying above the table.
Conceptually, thepositions of the aircraft are provided in real-timeby a radar system and the user has the option ofdisplaying them as symbols or models.
Remoteusers worldwide have real-time access to thedata.
The hemisphere in the upper left is asimple, unclassified representation f the threatdome of a Surface to Air Missile (SAM)emplacement.
The large arrow is a cursor that iscontrolled by a remote user who is collaboratingover this display.
The amorphous blob in thelower left is a depiction of a small storm cell thatis also moving through the region.
This weatherdata is visually integrated in real-time with thecurrent air picture data.
The aircraft position,weather, and threat information are all providedby different sensor systems.
However, they sharea common spatiotemporal reference that allowsthem to be fused in this real-time synthetic viewof the world.
Every object in this synthetic viewalso serves as a visual index into the underlyingglobal C2 database.
Selecting an aircraft wouldlet us determine its current status (airborne with acertain speed and heading) and plans (origin,60destination, and mission), as well as associatedinformation such as logistics at its base of origin.Figure 11.
Synthetic View of the WorldOur current research is focused on the use ofaggregation and deaggregation of data withinvisual depictions, in order to support a widerange of users.
A weaponeer wants to study thedetails of a target (e.g., construction material,distance below ground) that is only a fewhundred feet by a few hundred feet in size.
Acommander wants an overview of all airborneassets, targets, etc.
for a region that is severalhundred by several hundred miles in size.However, those examining an overview willfrequently wish to "drill down" for maximumdetail in certain areas, while those examining adetailed area may wish to examine a more globalview to retain context.
Allowing thevisualization of data with this wide range ofgeographic scopes, as well as iterative travelbetween detail and overview, poses challenges inboth data depiction, data simplification, andintuitive navigation techniques.8.
Conclusion and Research AreasThe above varied and rich application spaces -e.g., visualizing search results, topics, relationsand events in news broadcasts, battlefieldactivities - provide a number of challenges forvisualization research.
Fundamental issuesinclude:1.
What are effective information encoding/visualization techniques for static anddynamic information visualization, includingcomplex semantic objects uch as properties,relations, and events?2.
What are the most effective methods forutilizing eospatial, temporal, and othercontexts in synthetic displays of real worldevents that facilitate interface tasks (e.g.,location, navigation), comprehension,analysis and inference?3.
What kinds of interactive devices (e.g., visualand spatial query) are most effective forwhich kinds of tasks (e.g., anomaly detection,trend analysis, comparative analysis).4.
What new evaluation methods, metrics, andmeasures are necessary for these newvisualization methods?In visualization, we tend to deal with complexitythrough methodologies involving abstraction,aggregation, filtering, and focusing.
Insightsfrom natural language processing promise to helpextract semantic information from text channels,to provide a richer, task-relevant characterizationof the information space.
Visualization cancertainly benefit from other aspects naturallanguage processing in achieving economy ofinteraction such as notions of context inreference (e.g., "fast_forward <the next week>")or relation (e.g., move "<enemy_icon> behind<Bunker Hill_icon>" in the currently focuseddisplay).
An investigation of many applications,tasks, and interaction methods will be required tomake progress in better understanding andanswering these and other ~ndamentalquestions.61ReferencesMacEachren, A. M. Department of Geography,Pennsylvania State University, USA.
Chair, ICACommission on Visualization to be published in theProceedings of the Polish Spatial InformationAssociation Conference, May, 1998, Warsaw Poland(http://www.geog.psu.edu/ica/icavis/polandl .html)Buttenfield, B. and McMaster, R. (1991).
MapGeneralization: Making Rules for KnowledgeRepresentation, Longman Scientific Technical,England.Exploratory Cartography: Maps as tools for discovery byMenno-Jan Kraat http://www.itc.nl/~arto/kraak/Gershon, N., LeVasseur, Winstead, J., Croall, J., Pemick,A., and Rue, W. (1995).
"Visualizing IntemetResources," In Gershon, N. & Eick, S.G. (eds),Proceedings for Information Visualization T95Symposium, (pp.
122-128) IEEE Computer SocietyPress.Gershon, N. (1996).
"Moving Happily through the WorldWide Web."
IEEE Computer Graphics andApplications, March 1966 (pp.
72-75).Gershon, N. and Eick, S. G.
(eds.)
1997.
Introduction:Information Visualization.
IEEE Computer Graphicsand Applications.
17 (4).
July/August.MacEachren, A. M. and Ganter, J. H. (1990).
A patternidentification approach to cartographic visualization.Cartographica, 27(2): 64-81Mani, I. and Bloedom, E. (1997).
Summarizing Similaritiesand Differences among Related Documents.
InProceedings of the Fourteenth National Conference onArtificial Intelligence, (pp.
622-628).
AAAI Press,Menlo Park, CA.Merlino, A., Morey, D. and Maybury, M.
(1997).
"Broadcast News Navigation using Story Segments",ACM International Multimedia Conference, Seattle,WA, November 8-14, (pp.
381-391).
(http://www.mitre.org/resources/centers/advanced_info/g04 ffonn/mmhomeext.html)Merlino, A. and Maybury, M. to appear.
An EmpiricalStudy of the Optimal Presentation of MultimediaSummaries of Broadcast News.
In Mani, I. andMaybury, M.
(eds.)
Automated Text Summarization.Mitchell, R., Day, D., and Hirschman, L. (1995).
"Fishingfor Information on the Intemet."
In Gershon, N. &Eick, S.G. (eds), Proceedings for InformationVisualization T95 Symposium, (pp.
105-111) IEEEComputer Society Press.
October.Morris, H. and Sonnen, D. (1997).
Spatial Information inData Warehouses: Business Potential and Risks,Bulletin #14753, International data Corporation,November 1997. http://www.itresearch.com/Shneiderman, B., (1994) Dynamic queries for visualinformation seeking, IEEE Software 11(6): 70-77.Smotroff, I., Hirschman, L., and Bayer, S.
(1995).
"Integrating Natural Language with Large DataspaceVisualization," In Adam, N. and Bhargava, B.
(eds),Advances in Digital Libraries, Lecture Notes inComputer Science, (pp.
209-224) Springer Verlag.Taylor, D. R. F., Ed.
(1991).
Geographic informationsystems: The microcomputer and modern cartography.Oxford, UK: Pergamon.62
