Non-determinist ic  Recursive Ascent ParsingRen~ LeermakersPhi l ips Research Laborator ies,P.O.
Box 80.000, 5600 JA  Eindhoven, The Nether landsE-mai l : leermake@rosetta.pr l .phi l ips.n lABSTRACTA purely functional implementation of LR-parsers isgiven, together with a simple correctness proof.
It ispresented as a generalization of the recursive descentparser.
For non-LR grammars the time-complexity ofour parser is cubic if the functions that constitute theparser are implemented as memo-functions, i.e.
func-tions that memorize the results of previous invocations.Memo-functions also facilitate a simple way to constructa very compact representation of the parse forest.
ForLR(0) grammars, our algorithm is closely related to therecursive ascent parsers recently discovered by Kruse-man Aretz \[1\] and Roberts \[2\].
Extended CF grammars(grammars with regular expressions at the right handside) can be parsed with a simple modification of theLR-parser for normal CF grammars.1 In t roduct ionIn this paper we give a purely functional implementa-tion of LR-parsers, applicable to general CF grammars.It will be obtained as a generalization of the well-knownrecursive descent parsing technique.
For LR(0) gram-mars, our result implies a deterministic parser that isclosely related to the recursive ascent parsers discoveredby Kruseman Aretz \[1\] and Roberts \[2\].
In the gen-eral non-deterministic case, the parser has cubic timecomplexity if the parse functions are implemented asmemo-functions \[3\], which are functions that memorizeand re-use the results of previous invocations.
Memo-functions are easily implemented in most programminglanguages.
The notion of memo-functions i  also usedto define an algorithm that constructs a cubic represen-tation for the parse forest, i.e.
the collection of parsetrees.It has been claimed by Tomita that non-deterministicLR-parsers are useful for natural language processing.In \[4\] he presented a discussion about how to do non-deterministic LR-parsing, with a device called a graph-structured stack.
With our parser we show that no ex-plicit stack manipulations are needed; they can be ex-pressed implicitly with the use of appropriate program-ming language concepts.Most textbooks on parsing do not include propercorrectness proofs for LR-parsers, mainly because suchproofs tend to be rather involved.
The theory of LR-parsing should still be considered underdeveloped, forthis reason.
Our presentation, however, contains a sur-prisingly simple correctness proof.
In fact, this proof isthis paper's major contribution to parsing theory.
Oneof its lessons is that the CF grammar class is often thenatural one to proof parsers for, even if these parsers aredevoted to some special class of grammars.
If the gram-marlis restricted in some way, a parser for general CFgrammars may have properties that enable smart imple-mentation tricks to enhance fficiency.
As we show be-low, the relation between LR-parsers and LR-grammarsis of this kind.Especially in natural language processing, standardCF grammars are often too limited in their strong gen-erative power.
The extended CF grammar formalism,allowing rules to have regular expressions at the righthand side, is a useful extension, for that reason.
It is notdifficult to generalize our parser to cope with extendedgrammars, although the application of LR-parsing toextended CF grammars is well-known to be problematic\[5\].We first present the recursive descent recognizer ina way that allows the desired generalization.
Then weobtain the recursive ascent recognizer and its proof.
Ifthe grammar is LR(0) a few implementation tricks leadto the recursive ascent recognizer of ref.
\[1\].
Subse-quently, the time and space complexities of the recog-nizer are analysed, and the algorithm for constructinga cubic representation for parse forests is given.
Thepaper ends with a discussion of extended CF grammars.2 Recurs ive  descentConsider CF grammar G, with terminals VT and non-terminals V/v.
Let V = VN U VT. A well-known top-down parsing technique is the recursive descent parser.Recursive descent parsers consist of a number of pro-cedures, usually one for each non-terminal.
Here wepresent a variant that consists of functions, one for eachitem (dotted rule).
We use the unorthodox embracingoperator \[.\] to map each item to its function: (we usegreek letters for arbitrary elements of V*)\ [A  -~  a .~\ ]  : N - - .
2 Nwhere N is the set of integers, or a subset (0...nm~x),with nma= the maximum seutence length.
The functionsare to meet the following specification:\[A --, a. l(0 = {Jl  -*"- 63  -with x~...xn the sentence to be parsed.
A recursive im-plementation for these functions is given by (b ?
VT, B ?v,,)\[A --* a.\](i) = {i}\[a --* a.b-r\](i) = {jib = zi+,  ^  j E \[A ~ ab.-r\](i + 1)}\[A ---, a.B-r\](i) ={Jl~ ?
\[B ~ .~\]( i )^j  ?
\[A - ;  ~a.-r\](~)}We keep to the custom of omitt ing existential quantifi-cation (here for k,/f) in definit ions of this kind.The proof is elementary and ba#ed on3~(3 = x~+a-r A -r ~*  zi+~...~:s)V3B-~$k(3 = B-r ^  B --~ 8 A 8 --;* z i+a.. .x~^-r --~* 2;k+l...2~j)If we add a grammar ule S '  --* S to G, with S '  (\[ Vthen S --** x~...xn is equivalent to n ?
\[S' --* .S\](0).The recursive descent recognizer works for any CFgrammar except for grammars for which ~A~(A ---*aAcr --** A3).
For such left-recursive grammars the rec-ognizer does not terminate, as execution of \[A --* .a\](i)will lead to a call of itself.
The recognition is not a l inearprocess in general: the function calls \[A --- a.B3"\](i) leadto calls \[B --* ./i\](i) for all values of ~ such that B ---,is a grammar ule.3 The  ascent  recogn izerOne way to make the recognizer more deterministic s bycombining functions corresponding to a number of com-peting items into one function.
Let the set of all itemsof G be given by In .
Subsets of I6; are called states, andwe use q to be an arbitrary state, lWe associate to eachstate q a function, re-using the above operator \[.\],\[q\] : N ~ 2 I?
?Nthat meets the specification\[q\](i) ---- {(A - -  a .3 , j ) l  A --.
a .3  ?
q ^  3 --*" zi+~...xi}As above, the function reports which parts of the sen-tence can be derived.
But as the function is associatedto a set q of items, it has to do so for each item inq.
If we define the initial state q0 = {S' --* .S}, nowS --," xl .
.
.xn is equivalent o (S' ---* .S,n)  ?
\[q0\](0).Before proceeding, we need a couple of definitions.Let ini(q) be the set of initial items for state q, thatare derived from q by the closure operation:ini(q) = { B --* .AIB - .
A ^ A --* a .3  ?
q A 3 =?
B-r}.The double arrow =?, denotes a left-most-symbol rewrit-ing Ba =e~ Cf la,  using a non-e rule B ---, Cfl.
Thetransit ion function goto is defined by (B ?
V)goto(q, B)  = {A -* aB .3 \ ]A  --* a .B3  ?
(q U ini(q))}Also definepop(A ---, aB .3)  = A --', a .B3lhs(A --* a.fl) = Af ina l (A  --.
a .3)  = (131 = 0)with B E V, and 1/31 the number of symbols in 3 (withH = 0).
A recursive ascent recognizer may be obtainedby relating to each state q not only the above \[q\], butalso a function__ that we take to be the result of applyingoperator \[.\] to the state:\[q\] : V x N --* 2 I?
xNIt has the specification\[q\](B,i) = {(A --* a .3 , j ) lA  --* a.3 e qA3 =~* B- rAT  ---,* xi+a...xj}For i >.nn (n is the sentence length) it follows that\[q\](i) = \[q\](B,i) = $, whereas for i _< n the functionsare recursively implemented by\[q\](i) = \[q\](x,+l, i + 1)u{(1, j ) IB  --* .e e i n i (q )A  ( l ,  j )  E -~(B ,  i)}U{( l , i ) l I  ?
q ^  f ina l ( l )}\[q\](B, i) = { (pop(l),  J)l(1,j) ?
\[ooto(q, B)\](i)^ pop(l) ?
q}U{(I,4)1(J, k) ?
\[goto(q, B) I~^pop(J)  ?
ini(q)  ^  (1, j )  ?
\[q\](lhs(S), k)}Proof:First we notice that/8 "** xi+l.
.-xj3~(3 ~*  z i+l ' t  ^  7 ~"  z ,+2.
.
.z j )v3B~(3 ~"  B-r ^  B ~ c ^  -y --."
z ,+~.. .z j )v(~=~^i=j )Hence\[q\](i) ={(A --* a.3,J) l(A --* a.3,  j )  ?
r~(z ,+~,  i+  1)}u{(A --, ,~.3, J)lB -.-.
eA(A  --, a .3 , j )  ?
\ [q\] (B, i )}u{(A --~ a .
, i ) la  --* a. ?
q}This is equivalent to the earlier version because we mayreplace the clause B ~ e by B ---, .e ?
ini(q).
Indeed,if state q has item A --* a.f l  and if there is a left-most-symbol derivation/3 =~* B-r then all items B --* .A areincluded in ini(q).For establishing the correctness of \[q--\] notice that3 ~*  B3" either contains zero steps, in which case3 = B'r, or it contains at least one step:3.y(3 =~* B3" A 3' --*" xi+a ...zs) =3~(3 = B-r ^  -r - - "  x i+l .
.
.z j )V3ce.~k(~8 :=~* C-rAG --* B~S A~5 -.
*" xi+ l...x~,A -r -'**xk+l ...x j )Hence \[q\](B, i) may be written as the union of two sets,\[q\](B, i) = So USa:So = {(A --~ a.B3",j)\]A ---.
ct.B3" ?
qA-r  ---** xs+l .
.
.x j}S~ = {(a  --.
a .3 , j ) lA  --* a.3 ?
q ^  3 =~" C-r^C ---* B~ ^  $ --** zi+l...xk ^  3' --*" zk+l.
.
.z i}.By the definition of goto, if A ---, a.B-r  ?
q then A --,aB.-r ?
goto(q, B).
tlence, with the specification of \[q\],So may be rewritten asSo = {(A --.
a.B-r , j ) IA --.
a.B-r ?
q^(A ---* aB.3", j )  ?
\[goto(q, B)\](i)}- 64  -The set $1 may be rewritten using the specification of\[q\](C, k):S1 : {(A -'~ a.~, j ) l (A  -~ a .~, j )  E \[q\](C,k)AC --* B6 A 6 --," xi+,...xk}.Also, as before, ~ =~* C'r implies that all items C ~ .gare in ini(q), and the existence of C -* .B~ in ini(q)implies C ~ B.~ E goto(q, B):Sx = {(A ~ a .~, j ) l (A  ~ ~.B, j )  E \[q\](C, k)AC --~ .B~ E ini(q)A(C --.
B.6, k) ~ \[goto(q, B)\](i)}.nIn the computation of \[q0\](0), functions are neededonly for states in the canonical collection of LR(0) states\[6\] for G, i.e.
for every state that can be reached from theinitial state by repeated application of the goto function.Note that in general the state ?
will be among these, andthat both \[?\](i) and \[g\](B, i) are empty sets for all i _> 0and B E V.4 Determin ist ic  variantsOne can prove that, if the grammar is LR(0), each rec-ognizer function for a canonical LR(0) state results ina set with at most one element.
The functions for non-empty q may in this case be rephrased as\[q\](i):if, for some I ,  I E q A f ina l ( l )  t__hen return {(I, i)} elseif B --..e E ini(q) then ret__.urn \[q\](B, i)else if i < n then return \[q\](xi+~, i + 1)else returnfi\[q\](B,i):if \[9oto(q, B)\](i) = ?
then return ~ elselet (I, j )  be the unique element of \[goto(q, B)\](i).
Then:if pop(I) E q then return {(pop(l), j )}else return \[q\](Ihs(l), j )flfiReversely, the implementations of \[q\](i) and \[q\](B,i) ofthe previous section can be seen as non-deterministicversions of the present formulation, which therefore pro-vides an intuitive picture that may be helpful to under-stand the non-deterministic parsing process in an oper-ational way.Each function can be replaced by a procedure that,instead of returning a function result, assigns the resultto a global (set) variable.
As this set variable may con-tain at most one element, it can be represented by threevariables, a boolean b, an item R and an integer i. Ifa function would have resulted in the set {( I , j )},  theglobal variables are set to b = TRUE,  R = I and i = j .A function value ~ is represented by b = FALSE.
Alsothe arguments of the functions are superfluous now.
Therble of argument i can be played by the global variablewith the same na__.rne, and lhs(R)can be used instead ofargument B of \[q\].
Consequently, procedure \[?\] becomesa statement b := FALSE,  whereas for non-emp.~, q onegets the procedures (keeping the names \[q\] and \[q\], trust-ing no confusion will arise):\[q\] :if, for some I, I E q A f ina l ( l )  then R := Ielse if B --..?
E ini(q) then R := B - -  e.; \[q\] __else if i < n then R := xi+a - -  xi+l.
; i := i + 1; \[q\]else b := FALSEfiNM:\[goto(q, Ihs(R))l;if b. thenif pop(R) E q then R := pop(R).else \[q\]f ifiNote that these procedures do not depend on the detailsof the right hand side of R. Only the number of sym-bols before the dot is relevant for the test "pop(R) E q".Therefore, R can be replaced by two variables X E Vand an integer I, making the following substitutions inthe previous procedures:R :=A- -*a .
=~ X:=A; I := Ic r lR:=pop(R)  =~ l := l -1pop(R) E q =~ l # l v X = S'lhs( R) =~ XAfter these substitutions, one gets close to the recursiveascent recognizer as it was presented in \[1\].
A recognizerthat is virtually the same as in \ [ l~s  obtained by replac-ing the tail-recursive procedure \[q\] by an iterative loop.Then one is left with one procedure for each state.
Whileparsing there is, at each instance, a stack of activatedprocedures that corresponds to the stacks that are ex-plicitly maintained in conventional implementations ofdeterministic LR-parsers.5 Complex i tyFor LL(0) grammars the recursive descent recognizer isdeterministic and works in linear time.
The same istrue of the ascent recognizer for LR(0) grammars.
Inthe general, non-deterministic, ase the recursive de-scent and ascent recognizers need exponential time un-less the functions are implemented as memo-functions\[3\].
Memo-functions memorize for which arguments theyhave been called.
If a function is called with the samearguments as before, the function returns the previousresult without recomputing it.
In conventional program-ming languages memo-functions are not available, butthey can easily be implemented.
Devices like graph-structured stacks \[4\], parse matrices \[7\], or welbformed- 65  -substring tables \[8\], are in fact low-level realizations ofthe abstract notion of memo-functions.
The complex-ity analysis of the recognizers i quite simple.
There areO(n) different invocations ofparser functions.
The func-tions call at most O(n) other functions, that all resultin a set with O(n) elements (note that there exist onlyO(n) pairs (I, j )  with I E IG, i _< j _< n).
Merging thesesets to one set with no duplicates can be accomplished inO(n 2) time on a random access machine.
Hence, the to-tal time-complexity is O(na).
The space needed for stor-ing function results is O(n) per invocation, i.e.
O(n 2)for the whole recognizer.The above considerations only hold if the parser ter-minates.
The recursive descent parser terminates for allgrammars that are not left-recursive.
For the recursiveascent parser, the situation is more complicated.
If thegra_m.mmar has a cyclic derivation B -** B, the executionof \[q\](B, i) leads to a call of itself.
Also, there may be acycle of transitions labeled by non-terminals that derivee, e.g.
if goto(q, B) = q A B ---, e, so that the executionof \[q\](i) leads to a call of itself.
There are non-cyclicgrammars that suffer from such a cycle (e.g.
S --* SSb,S --* e).
Hence, the ascent parser does not terminate ifthe grammar is cyclic or if it leads to a cycle of transi-tions labeled b_.~ non-terminals that derive e. Otherwise,execution of \[q\](B, i) can only lead to calls of \[p\](i) withp ~ q and to calls of \[q\](C,k), such that either k > ior C--** BAC ~ B.
As there are only finitely manysuch p, C, the parser terminates.
Note that both the re-cursive descent and ascent recognizer terminate for anygrammar, if the recognizer functions are implementedas memo-functions with the property that a call of afunction with some arguments yields $ while it is underexecution.
For instance, if execution of \[q\](i) leads toa call of itself, the second call is to yield ~.
A remarkof this kind, for the recursive descent parser, was firstmade in ref.
\[8\].
The recursive descent parser then be-comes virtually equivalent to a version of the standardEarley algorithm \[9\] that stores items A ---* a./~ in parsematrix entry Ti i if/~ ---,* xi+l...xi, instead of storing itif a --*?
x~+l .
.
.x j .The space required for a parser that also calculatesa parse forest, is dominated by this forest.
We showin the next section that it may be compressed into acubic amount of space.
In the complexity domain ourascent parser beats its rival, Tomita's parsing method\[4\], which is non-polynomial: for each integer k thereexists a grammar such that the complexity of the Tomitaparser is worse than n k.In addition to the complexity as a function of sen-tence length, one may also consider the complexity asa function of grammar size.
It is clear that both timeand space complexity are proportional to the number ofparsing procedures.
The number of procedures of therecursive descent parser is proportional to the numberof items, and hence a linear function of the grammarsize.
The recursive ascent parser, however, contains twofunctions for each LR-state and is hence proportional tothe size of the canonical collection of LR(0) states.
Inthe worst case, this size is an exponential function ofgrammar size, but in the average natural anguage casethere seems to be a linear, or even sublinear, dependence\[4\].6 Parse forestUsually, the recognition process is followed by the con-struction of parse trees.
For ambiguous grammars, itbecomes an issue how to represent the set of parse treesas compactly as possible.
Below, we describe how toobtain a cubic representation in cubic time.
We do soin three steps.In the first step, we observe that ambiguity oftenarises locally: given a certain context C\[-\], there mightbe several parse subtrees tl...tk (all deriving the samesubstring xi+l...xj from the same symbol A) that fitin that same context, leading to the parse trees C\[tl\],eft2\] .
.
.
.
.
c\[th\] for the given string zl...zn.
Instead ofrepresenting these parse trees separately, repeating eachtime the context C, we can represent them collectivelyas C\[{~1, ..., tk}\].
Of course, this idea should be appliedrecursively.
Technically, this leads to a kind of tree-llkestructure in which each child is a set of substructuresrather than a single one.The sharing of context can be carried one step further.If we have, in one and the same context, a number ofapplied occurrences of a production rule A ---, a/~ whichshare also the same parse forest for a, we can representthe context of A ---* a~ itself and the common parseforest for a only once and fit the set of parse forests forfl into that.
Again this idea has to be applied recursively.Technically, this leads to a binary representation f parsetrees, with each node having at most two sons, and tothe application of the context sharing technique to thisbinary representation.These two ideas are captured by introducing a func-tion f with the interpretation that f(f3, i , j )  representsthe parse forest of all derivations from /~ E V* tozi+~...x~, for all i , j  such that 0 < i < j < n. Thefollowing recursive definitions fix the parse forest repre-sentation formally:f(~, i , j )  ={\[l\[i = J},f(a, i, j) = {alj = i + 1 ^  x,+l = a}, for all a e liT,f (A , i , j )  = {(A,f(ot, i , j ) ) lA ~ aAa .---*" xi+l...x~}, for all A E VN,f(AB/3, i, j)  = {(f(A, i, k), f (B#,  k, J))li < k < jAA  ---," xi+l...Xk ^  B/~ --~" xk+l...xj}, forall A, B E V.The representation for the set of parse trees is then justf (S ,  0, n).We now come to our third step.
Suppose, for the mo-ment, that the guards a ---,* xi+l...xj and the like, oc-curring above, can be evaluated in some way or another.Then we can use function f to compute the representa-tion of the set of parse trees for sentence xl...xn.
If wemake use of memo-functions to avoid repeated compu-tation of a function applied to the same arguments, wesee that there are at most O(n 2) function evaluations.- 66  -If we represent function values by re\]erences to the setrepresentations rather than by the sets themselves, themost complicated function evaluation consumes an ad-ditional amount of storage that is O(n): for j - i + 1values of k we have to perform the construction of apair of (copies of) two references, costing a unit amountof storage each.
Therefore, the total amount of spaceneeded for the representation f all parse trees is O(n3).The evaluation of the guards ct ---."
xi+l...xj etc.amounts exactly to solving a collection of recognitionproblems.
Note that a top-down parser is possiblethat merges the recognition and tree-building phases,by writingf (A , i , j )  = {(A,f(ot, i , j ) ) lA -., a A f (a , i , j )  # ~}, forall A E VN,I (AB/ i ,  i, j)  = {(f(A, i, k) , / (B/ i ,  k, J))li < k < j A f (A , i , k )  # ?
A f (B / i , k , j )  # ~},for all A, B E V,the other cases for f being left unchanged.
Note the sim-ilarity between the recognizing part of this algorithmand the descent recognizer of section 2.
Again, thisparser is a cubic algorithm if we use memo-functions.Another approach is to apply a bottom-up recognizerfirst and derive from it a set P containing triples (/i, i , j )only if/3 ---'" xi+l...xj, and at least those triples (/i, i , j )for which the guards/3 ---** xi+a ...xj are evaluated ur-ing the computation of f(S,  O, n) (i.e., for each deriva-tion S ---."
xl...xkAxj+l...Zn "-* Xl...XkOl/iXj+l...Xn "-'**zl...xiflzj+l...xn "~" xl...xn, the triples (/ i , i , j )  and(A ,k , j )  should be in P).
The simplest way to obtainsuch P from our recognizer is to assume an implementa-tion of memo-functions that enables access to the mem-oized function results, after executing \[q0\](O).
Then onehas the disposal of the set{(/i, i,j)l\[q\](i ) was invocated and(A --* a./i, j)  e \[q\](i)}Clearly, ( / i , i , j )  is only in this set if /i --+" xi+l...x i.Note, however, that no pairs (A --~ ./i, j) are includedin \[q\](i) (except if A = S').
We remedy th__is with aslight change of the specifications of \[q\] and \[q\], defining~ q U ini(q):\[q\](i) ={(A --.
* a.3, j ) lA --~ c~./~ E ~A/ i  ---** xi+l...xj}\[q\](B,i) = {(a ---* a./ i , j) lA ---* a./i E "~At3 ~*  BT A 7 ""* Xi+l"'Xj}A recursive implementation f the recognition functionsnow is\[q\](i) = {(I,Y)l(I, j) e \[q\](~+~, i + l\[}.p{(l , j ) l  B --.
.
,  e ini(q) A ( I , j )  E \[q\](B,i)}U{(I, i)lI E ~ A final(l)}\[q\](B, i) = {(pop(I), J ) l ( l ,  J) E \[goto(q, B) \ ] ( i ) lu{(I, j ) l ( J ,  k} e \[goto(q, B)I~}Apop(J) E ini(q) A ( I , j )  e \[q\](lhs(J),k)}If we define, for this revised recognizer,P = {(3, i, j)l\[q\](i) was invocated and(A - .
.
.~ ,  j)  e \[q\](i)}u{(A, i, j)l\[q\](i) was invocated and(a --, .~,j) e \[q\](i)}u{(x~+~, i , i+  DI0 < i < n},it contains all triples that are needed in f (S,  O, n), andwe may write the forest constructing function asf (A , i , j )  = {(a , f (a , i , j ) ) lA  --, a^ (a, i , j )  E P}, forall A E V~,f(AB/i, i, j) ---- {(I(A, i, k), f(B/3, k, J))l(A, i, k) e P A (Bit, k, j) e P}, for all A, B e V,the other cases for f being left unchanged again.
Thereexists a representation f P in quadratic space such thatthe presence or absence of an arbitrary triple can be de-cided upon in unit time.
As a result, the time complexityof f (S,  O, n) is cubic.7 Extended CF grammarsAn extended CF grammar consists of grammar uleswith regular expressions at the right hand side.
Everyextended CF grammar can be translated into a normalCF grammar by replacing each right hand side by aregular (sub)grammar.
The strong generative power isdifferent from CF grammars, however, as the degree ofthe nodes in a derivation tree is unbounded.
To applyour recognizer directly to extended grammars, a few ofthe foregoing definitiovs have to be revised.As before, a grammar rule is written A --, a, but witha now a regular expression with Na symbols (elementsof V).
Defining T + = 1...N,, and Ta = 0...Na, regularexpression tr can be characterized by1.
a mapping ?~ : T~ + ~ V associating a grammarsymbol to each number.2.. a function succo : To --* 2 T+ mapping each num-ber to its set of successors.
The regular expressioncan start with tile symbols corresponding to thenumbers in succo(O).3. a set a,~ E 2 7`0 of numbers of symbols the regularexpression can end with.Note that 0 is not associated to a symbol in V and is nota possible lement of succ,,(k).
It can be element of a,~though, in which case there is an empty path throughthe regular expression.We define an item as a pair (A --, a,k),  with theinterpretation that number k is 'just before the dot'.The correspondence with dotted rules is the following.Let a = B1...Bt, then a is a simple regular expressioncharacterized by ~ba(k) = Bk, succa(k) = {k + 1} if0 < k < l, succo(l) = {~, and a,, = {I}.
Item (A ---.
a,0)corresponds to the initial item A ---* .a and (A ---* a, k)to the dotted-rule item with the dot just after Bk.The predicate final for the new kind of items is definedbyf inal((A ---* a, k)) = (k E an)Given a set q of items, we define- 67  -ini(q) = {(A - -  a ,0) l (B  ---* fl, l) ?
qAk ?
s .
cc , (0  ^ ?a(k)  ~"  A~}The function pop becomes et-valued and the transitionfunction can be defined in terms of it (remember: ~ =q U ini(q)):pop((A ~ a ,  l)) = {(a  --.
a ,  k)ll ?
succ.
(k)}goto(q, B) = {(a  ---, a, k ) l * .
(k )  = B a I ?
~AI ?
pop((a --* a, k))}A recursive ascent recognizer is now implemented by\[q\](i) = \[q\](~ci+l, i + 1)U{(I, j ) l J e  ini(q) ^  f inal( J)A( I , j )  ?
\[q\](lhs(J), i)}U{( I ,  i)ll ?
q ^  f inal(\[))\[q\](B,i) = {J, j) l J  ?
q ^  J ?
pop(I)^(1, j) ?
\[goto(q, B)\ ] ( i )}Ut ( I , j ) l ( J ,  k) ?
\[goto(q,B)\](i) A K ?
ini(q)^K ?
pop( J )^ ( l , j )  ?
\[q\](lhs(J), k)}The initial state q0 is {(S' ---* S, 0)}, and a sentencex l .
.
.x ,  is grammatical if ((S' --* S, 0), n) ?
\[qo\](O).
Therecognizer is deterministic f1.
there is no shift-reduce or reduce-reduce conflict,i.e.
every state has at most one final item, and incase it has a final item it has no items (A --, ~ , j )with k e succ,~(j) A ~b,~(k) ?
VT.2.
for all reachable states q, q N ini(q) = ~, and for allI there is at most one J ?
~ such that J E pop(I).In the deterministic case, the analysis of section 4 can berepeated with one exception: extended grammar itemscan not be represented by a non-terminal nd an integerthat equals the number of symbols before thc dot, as thisnotion is irrelevant in the case of regular expressions.
Instandard presentations of deterministic LR-parsing thisleads to almost unsurmountable problems \[5\].8 Conc lus ionsWe established a very simple and elegant implementa-tion of LR(0) parsing.
It is easily extended to LALR(k)parsing by letting the functions \[q\] produce pairs withfinal items only after inspection of the next k input sym-bols.The functional LR-parser provides a high-level view ofLR-parsing, compared to conventional implementations.A case in point is the ubiquitous tack, that simply cor-responds to the procedure stack in the functional case.As the proof of a functional LR-parser is not hinderedby unnecessary implementation details, it can be verycompact.
Nevertheless, the functional implementationis as efficient as conventional ones.
Also, the notion ofmemo-functions i  an important primitive for present-ing algorithms at a level of abstraction that can notbe achieved without them, as is exemplified by this pa-per's presentation of both the recognizers and the parseforests.For non-LR grammars, there is no reason to usethe complicated Tomita algorithm.
If indeed non-deterministic LR-parsers beat the Earley algorithm forsome natural anguage grammars, as claimed in \[4\], thisis because the number of LR(0) states may be smallerthan the size of IG for such grammars.
Evidently, for thegrammars examined in \[4\] this advantage compensatesthe loss of efficiency caused by the non-polynomialityof Tomita's algorithm.
The present algorithm seems tohave the possible advantage of Tomita's parser, whilebeing polynomial.AcknowledgementA considerable part of this research was done in collabo-ration with Lex Augusteyn and Frans Kruseman Aretz.Both are colleagues at Philips Research.References1 F.E.J.
Kruseman Aretz, On a recursive ascent parser,In\]ormation Processing Letters (1988) 29:201-206.2 G.H.
Roberts, Recursive Ascent: An LR Analogto Recursive Descent, SIGPLAN Notices (1988)23(8):23-29.3 J. Hughes, Lazy Memo-Functions in Functional Pro-gramming Languages and Computer Architectureedited by J.-P. Jouannaud, Springer Lecture Notesin Computer Science (1985) 201.4 M. Tomita, Efficient Parsing \]or Natural Language(Kluwer Academic Publishers, 1986).5 P.W.
Purdorn and C.A.
Brown, Parsing extendedLR(k) grammars, Acta lnformatica (1981) 15:115-127.6 A.V.
Aho and J D. Ullman, Principles of CompilerDesign (Addison-Wesley publishing company,1977)7 A,V.
Aho and J.D.
Ulhnan, The theory o\] parsing,translation, and compiling (Prentice Hall Inc. En-glewood Cliffs N.J.,1972).8 B.A.
Shell.
Observations on Context Free Parsing inStatistical Methods in Linguistics (Stockhohn (Swe-den) 1976).Also: Technical Report TR 12-76, Center for Re-search in Computing Technology, Aiken Computa-tion Laboratory, Harvard Univ., Cambridge (Mas-sachusetts).9 J. Earley, 1970.
An Efficient Context-Free ParsingAlgorithm, Communications ACM 13(2):94-102.- 68  -
