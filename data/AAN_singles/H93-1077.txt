MACHINE LEARNING TECHNIQUES FOR DOCUMENT F ILTERINGRichard M. Tong, Lee A. AppelbaumAdvanced Dec is ion  Systems(a d iv is ion o f  BoozoAl len  & Hami l ton ,  Inc.)1500 P lymouth  Street, Mounta in  View, CA 94043PROJECT GOALSBoozoAllen & Hamilton's Advanced Decision SystemsDivision is conducting a program of research to investi-gate machine learning techniques that can automaticallyconstruct probabilistic structures from a training set ofdocuments with respect o a single target filtering con-cept, or a set of related concepts.
These structures canthen be applied to individual documents to derive a pos-terior probability that the document is about a particulartarget concept.Our primary goal is to investigate the use of the CART(Classification and Regression Trees) algorithm as thebasis of a totally automatic approach to generating doc-ument classification structures, working only with infor-mation need statements and training data supplied byusers.
That is, we are interested in testing the hypothesisthat effective descriptions of what constitutes a "rele-vant document" can be constructed using just documentexemplars and broad statements about document fea-tures.
Such a scenario is common in organizations thatmonitor large volumes of real-time electronic docu-ments.RECENT RESULTSOur most recent results are those from the first ARPAsponsored TREC (Text Retrieval Conference) held inNovember 1992.The TREC corpus represents a significant challenge forour approach.
Our previous results with a small corpus,while encouraging, did not allow us to evaluate howwell the technique might do with realistically sized doc-ument collections.
Our conclusion based on the resultswe have from TREC is that CART does exhibit someinteresting behaviors on a realistic corpus, and that,despite the small size of the training sets and therestricted choice of features, for some topics it producescompetitive results.
So although the overall perfor-mance is moderate (relative to the better performingsystems at TREC), we believe that the absolute perfor-mance (given that the system is totally automatic) is atleast encouraging and definitely acceptable in severalinstances.Some specific observations on the performance of thecurrent implementation f the CART algorithm as usedfor TREC are:?
Relying on the re-substitution estimates for the ter-minal nodes is a very weak method for producingan output ranking.
A scheme that makes use of sur-rogate split information to generate a post hocranking shows much promise as a technique forimproving our scores in the TREC context.?
While our approach is totally automatic, werestricted ourselves to using as features only thosewords that appear in the information eed state-ment.
This is obviously a severe limitation sincethe use of even simple query expansion techniques(e.g., stemming and/or a synonym dictionary) islikely to provide a richer and more effective set ofinitial features.?
Using words as features is possibly too "low-level" to ever allow stable, robust classificationtrees to be produced.
At a minimum, we probablyneed to consider working with concepts rather thanindividual words.
Not only would this reduce thesize of the feature space but would probably resultin more intuitive trees.?
We need to work with much bigger and more rep-resentative training sets.
Our preliminary experi-ment in this area shows, not surprisingly, thatadding more training examples can lead to dra-matic changes in the classification trees.PLANS FOR THE COMING YEARThe main activity planned for the coming year is to par-ticipate in TREC 2.
We intend to perform a series ofadditional experiments designed to explore some obvi-ous extensions suggested by the TREC 1 results.
That iswe will perform experiments odetermine: (1) the effectof training set size on the overall performance of thelearning algorithm, (2) the effectiveness of using surro-gate splits information to help perform a post hoc rank-ing of the documents classified as relevant, (3) theeffectiveness ofknowledge-based query expansion tech-niques, and (4) the value of using concepts, detectedusing our RUBRIC text retrieval technology, as docu-ment features.To facilitate the experimental procedure we plan to inte-grate the CART technology into BoozoAllen & Hamil-ton's distributed information integration system(MINERVA).
The primary feature of MINERVA is adistributed operating environment, which is an imple-mentation of an intelligent Ethernet oken ring that usesTCP/IP and standard UNIX socket protocols.
This pro-vides a unique transport layer that allows multiple data-bases and information access services to communicatetransparently using a common metalanguage.383
