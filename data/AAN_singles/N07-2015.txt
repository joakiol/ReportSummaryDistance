Proceedings of NAACL HLT 2007, Companion Volume, pages 57?60,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsAre Very Large N-best Lists Useful for SMT?Sas?a Hasan, Richard Zens, Hermann NeyHuman Language Technology and Pattern RecognitionLehrstuhl fu?r Informatik 6 ?
Computer Science DepartmentRWTH Aachen University, D-52056 Aachen, Germany{hasan,zens,ney}@cs.rwth-aachen.deAbstractThis paper describes an efficient methodto extract large n-best lists from a wordgraph produced by a statistical machinetranslation system.
The extraction is basedon the k shortest paths algorithm whichis efficient even for very large k. Weshow that, although we can generate largeamounts of distinct translation hypothe-ses, these numerous candidates are notable to significantly improve overall sys-tem performance.
We conclude that largen-best lists would benefit from better dis-criminating models.1 IntroductionThis paper investigates the properties of large n-best lists in the context of statistical machine trans-lation (SMT).
We present a method that allows forfast extraction of very large n-best lists based onthe k shortest paths algorithm by (Eppstein, 1998).We will argue that, despite being able to generate amuch larger amount of hypotheses than previouslyreported in the literature, there is no significant gainof such a method in terms of translation quality.In recent years, phrase-based approaches evolvedas the dominating method for feasible machinetranslation systems.
Many research groups use a de-coder based on a log-linear approach incorporatingphrases as main paradigm (Koehn et al, 2003).
As aby-product of the decoding process, one can extractn-best translations from a word graph and use thesefully generated hypotheses for additional reranking.In the past, several groups report on using n-bestlists with n ranging from 1 000 to 10 000.
The ad-vantage of n-best reranking is clear: we can applycomplex reranking techniques, based e.g.
on syntac-tic analyses of the candidates or using huge addi-tional language models, since the whole sentence isalready generated.
During the generation process,these models would either need hard-to-implementalgorithms or large memory requirements.1.1 Related workThe idea of n-best list extraction from a word graphfor SMT was presented in (Ueffing et al, 2002).
In(Zens and Ney, 2005), an improved method is re-ported that overcomes some shortcomings, such asduplicate removal by determinization of the wordgraph (represented as a weighted finite state automa-ton) and efficient rest-cost estimation with lineartime complexity.There are several research groups that use a two-pass approach in their MT systems.
First, they gen-erate n-best translation hypotheses with the decoder.Second, they apply additional models to the out-put and rerank the candidates (see e.g.
(Chen et al,2006)).Syntactic features were investigated in (Och et al,2004) with moderate success.
Although complexmodels, such as features based on shallow parsing ortreebank-based syntactic analyses, were applied tothe n-best candidates, the ?simpler?
ones were morepromising (e.g.
IBM model 1 on sentence-level).In the following section 2, we describe our SMTsystem and explain how an improved n-best extrac-tion method is capable of generating a very largenumber of distinct candidates from the word graph.In section 3, we show our experiments related ton-best list reranking with various sizes and the cor-responding performance in terms of MT evaluationmeasures.
Finally, we discuss the results in section 4and give some conclusive remarks.572 Generating N-best listsWe use a phrase-based SMT system (Mauser et al,2006) and enhance the n-best list extraction withEppstein?s k shortest path algorithm which allowsfor generating a very large number of translationcandidates in an efficient way.2.1 Baseline SMT systemThe baseline system uses phrases automatically ex-tracted from a word-aligned corpus (trained withGIZA++) and generates the best translations usingweighted log-linear model combination with severalfeatures, such as word lexicon, phrase translationand language models.
This direct approach is cur-rently used by most state-of-the-art decoders.
Themodel scaling factors are trained discriminatively onsome evaluation measure, e.g.
BLEU or WER, usingthe simplex method.2.2 N-best list extractionWe incorporated an efficient extraction of n besttranslations using the k shortest path algorithm(Eppstein, 1998) into a state-of-the-art SMT system.The implementation is partly based on code that ispublicly available.1Starting point for the extraction is a word graph,generated separately by the decoder for each sen-tence.
Since these word graphs are directed andacyclic, it is possible to construct a shortest path treespanning from the sentence begin node to the endnode.
The efficiency of finding the k shortest pathsin this tree lies in the book-keeping of edges througha binary heap that allows for an implicit representa-tion of paths.
The overall performance of the algo-rithm is efficient even for large k. Thus, it is feasi-ble to use in situations where we want to generate alarge number of paths, i.e.
translation hypotheses inthis context.There is another issue that has to be addressed.In phrase-based SMT, we have to deal with differ-ent phrase segmentations for each sentence.
Due tothe large number of phrases, it is possible that wehave paths through the word graph representing thesame sentence but internally having different phraseboundaries.
In n-best list generation, we want to getrid of these duplicates.
Due to the efficiency of thek shortest paths algorithm, we allow for generatinga very large number of hypotheses (e.g.
100 ?
n) and1http://www.ics.uci.edu/?eppstein/pubs/graehl.zipthen filter the output via a prefix tree (also calledtrie) until we get n distinct translations.With this method, it is feasible to generate100 000-best lists without much hassle.
In gen-eral, the file input/output operations are more time-consuming than the actual n-best list extraction.The average generation time of n-best candidatesfor each of the sentences of the development listis approximately 30 seconds on a 2.2GHz Opteronmachine, whereas 7.4 million hypotheses are com-puted per sentence on average.
The overall extrac-tion time including filtering and writing to hard-disktakes around 100 seconds per sentence.
Note thatthis value could be optimized drastically if checkingfor how many duplicates are generated on averagebeforehand and adjusting the initial number of hy-potheses before applying the filtering.
We only usethe k = 100 ?
n as a proof of concept.2.3 Rescoring modelsAfter having generated the 100 000-best lists, wehave to apply additional rescoring models to all hy-potheses.
We select the models that have shownto improve overall translation performance as usedfor recent NIST MT evaluations.
In addition to themain decoder score (which is already a combinationof several models and constitutes a strong baseline),these include several large language models trainedon up to 2.5 billion running words, a sentence-levelIBM model 1 score, m-gram posterior probabilitiesand an additional sentence length model.3 ExperimentsThe experiments in this section are carried out on n-best lists with n going up to 100 000.
We will showthat, although we are capable of generating this largeamount of hypotheses, the overall performance doesnot seem to improve significantly beyond a certainthreshold.
Or to put it simple: although we generatelots of hypotheses, most of them are not very useful.As experimental background, we choose the largedata track of the Chinese-to-English NIST task,since the length of the sentences and the large vo-cabulary of the task allow for large n-best lists.
Forsmaller tasks, e.g.
the IWSLT campaign, the domainis rather limited such that it does not make senseto generate lists reaching beyond several thousandhypotheses.
As development data, we use the 2002eval set, whereas for test, the 2005 eval set is chosen.The corpus statistics are shown in Table 1.58Chinese EnglishTrain Sentence Pairs 7MRunning Words 199M 213MVocabulary Size 222K 351KDev Sentence Pairs 878 3 512Running Words 25K 105KTest Sentence Pairs 1 082 4 328Running Words 33K 148KTable 1: Corpus statistics for the Chinese-EnglishNIST MT task.3.1 Oracle-best hypothesesIn the first experiment, we examined the oracle-besthypotheses in the n-best lists for several list sizes.For an efficient calculation of the true BLEU oracle(the hypothesis which has a maximum BLEU scorewhen compared to the reference translations), weuse approximations based on WER/PER-oracles, i.e.we extract the hypotheses that have the lowest editdistance (WER, word error rate) to the references.The same is applied by disregarding the word or-der (leading to PER, position-independent word er-ror rate).As can be seen in Table 2, the improvements aresteadily decreasing, i.e.
with increasing number ofgenerated hypotheses, there are less and less use-ful candidates among them.
For the first 10 000candidates, we therefore have the possibility to findhypotheses that could increase the BLEU score byat least 8.3% absolute if our models discriminatedthem properly.
For the next 90 000 hypotheses, thereis only a small potential to improve the whole sys-tem by around 1%.
This means that most of thegenerated hypotheses are not very useful in terms oforacle-WER and likely distracting the ?search?
forthe needle(s) in the haystack.
It has been shown in(Och et al, 2004) that true BLEU oracle scores onlists with much smaller n ?
4096 are more or lesslinear in log(n).
Our results support this claim sincethe oracle-WER/PER is a lower bound of the realBLEU oracle.
For the PER criterion, the behavior ofthe oracle-best hypotheses is similar.
Here we cannotice that after 10,000 hypotheses, the BLEU scoreof the oracle-PER hypotheses stays the same.These observations already impair the allegedusefulness of a large amount of translation hypothe-ses by showing that the overall possible gain with in-creasing n gets disproportionately small if one putsit in relation to the exponential growth of the n.Oracle-WER [%] Oracle-PER [%]N BLEU abs.
imp.
BLEU abs.
imp.1 36.1 36.110 38.8 +2.7 38.0 +1.9100 41.3 +2.5 39.8 +1.81000 43.3 +2.0 41.0 +1.210000 44.4 +1.1 42.0 +1.0100000 45.3 +0.9 42.0 +0.0Table 2: Dev BLEU scores of oracle-best hypothe-ses based on minimum WER/PER.3.2 Rescoring performanceAs a next step, we show the performance of tuningthe model scaling factors towards best translationperformance.
In our experiments, we use the BLEUscore as objective function of the simplex method.Figure 1 shows the graphs for the development(on the left) and test set (on the right).
The up-per graphs depict the oracle-WER BLEU scores (cf.also Table 2) for comparison.
As was already stated,these are a lower bound since the real oracle-BLEUhypotheses might have even higher scores.
Still, it isan indicator of what could be achieved if the modelsdiscriminated good from bad hypotheses properly.The lower two graphs show the behavior when(a) optimizing and extracting hypotheses on a sub-set (the first n) of the 100k-best hypotheses and (b)optimizing on a subset but extracting from the full100k set.
As can be seen, extracting from the fullset does not even help for the development data onwhich the scaling factors were tuned.
Experimentson the test list show similar results.
We can alsoobserve that the improvement declines rapidly withhigher n. Note that an optimization on the full 100klist was not possible due to huge memory require-ments.
The highest n that fit into the 16GB machinewas 60 000.
Thus, this setting was used for extrac-tion on the full 100k set.The results so far indicate that it is not very use-ful to go beyond n = 10000.
For the developmentset, the baseline of 36.1% BLEU can be improvedby 1.6% absolute to 37.7% for the first 10k entries,whereas for the 60k setting, the absolute improve-ment is only increased by a marginal 0.1%.
For thechosen setting, whose focus was on various list sizesfor optimization and extraction, the improvementson the development lists do not carry over to the testlist.
From the baseline of 31.5%, we only get a mod-erate improvement of approximately 0.5% BLEU.5936373839404142434445461  10  100  1000  10000  100000BLEU[%]NOracle-WER(a) opt.
on N, extr.
on N(b) opt.
on N, extr.
on 100k31323334353637381  10  100  1000  10000  100000BLEU[%]NOracle-WER(a) extraction on N(b) extraction on 100kFigure 1: BLEU scores of the reranked system.
Development set (left) vs. Test set (right).One possible explanation for this lies in the poorperformance of the rescoring models.
A short testwas carried out in which we added the referencetranslations to the n-best list and determined the cor-responding scores of the additional models, such asthe large LM and the IBM model 1.
Interestingly,only less than 1/4 of the references was ranked asthe best hypothesis.
Thus, most reference transla-tions would never have been selected as final candi-dates.
This strongly indicates that we have to comeup with better models in order to make significantimprovements from large n-best lists.
Furthermore,it seems that the exponential growth of n-best hy-potheses for maintaining a quasilinear improvementin oracle BLEU score has a strong impact on theoverall system performance.
This is in contrast to aword graph, where a linear increment of its densityyields disproportionately high improvements in ora-cle BLEU for lower densities (Zens and Ney, 2005).4 ConclusionWe described an efficient n-best list extractionmethod that is based on the k shortest paths algo-rithm.
Experiments with large 100 000-best lists in-dicate that the models do not have the discriminatingpower to separate the good from the bad candidates.The oracle-best BLEU scores stay linear in log(n),whereas the reranked system performance seems tosaturate at around 10k best translations given the ac-tual models.
Using more hypotheses currently doesnot help to significantly improve translation quality.Given the current results, one should balance theadvantages of n-best lists, e.g.
easily testing com-plex rescoring models, and word graphs, e.g.
repre-sentation of a much larger hypotheses space.
How-ever, as long as the models are not able to correctlyfire on good candidates, both approaches will staybeneath their capabilities.AcknowledgmentsThis material is partly based upon work supported by the De-fense Advanced Research Projects Agency (DARPA) underContract No.
HR0011-06-C-0023, and was partly funded bythe Deutsche Forschungsgemeinschaft (DFG) under the project?Statistische Textu?bersetzung?
(NE 572/5-3).ReferencesB.
Chen, R. Cattoni, N. Bertoldi, M. Cettolo, and M. Federico.2006.
The ITC-irst SMT system for IWSLT 2006.
In Proc.of the International Workshop on Spoken Language Transla-tion, pages 53?58, Kyoto, Japan, November.D.
Eppstein.
1998.
Finding the k shortest paths.
SIAM J. Com-puting, 28(2):652?673.P.
Koehn, F. J. Och, and D. Marcu.
2003.
Statistical phrase-based translation.
In Proc.
of the Human Language Tech-nology Conf.
(HLT-NAACL), pages 127?133, Edmonton,Canada, May/June.A.
Mauser, R. Zens, E. Matusov, S. Hasan, and H. Ney.
2006.The RWTH statistical machine translation system for theIWSLT 2006 evaluation.
In Proc.
of the International Work-shop on Spoken Language Translation, pages 103?110, Ky-oto, Japan, November.F.
J. Och, D. Gildea, S. Khudanpur, A. Sarkar, K. Yamada, A.Fraser, S. Kumar, L. Shen, D. Smith, K. Eng, V. Jain, Z. Jin,and D. Radev.
2004.
A smorgasbord of features for statisti-cal machine translation.
In Proc.
2004 Meeting of the NorthAmerican chapter of the Association for Computational Lin-guistics (HLT-NAACL), pages 161?168, Boston, MA, May.N.
Ueffing, F. J. Och, and H. Ney.
2002.
Generation of wordgraphs in statistical machine translation.
In Proc.
of theConf.
on Empirical Methods for Natural Language Process-ing (EMNLP), pages 156?163, Philadelphia, PA, July.R.
Zens and H. Ney.
2005.
Word graphs for statistical ma-chine translation.
In 43rd Annual Meeting of the Assoc.
forComputational Linguistics: Proc.
Workshop on Building andUsing Parallel Texts, pages 191?198, Ann Arbor, MI, June.60
