Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 205?208,Sydney, July 2006. c?2006 Association for Computational LinguisticsUsing Part-of-Speech Reranking to Improve Chinese Word SegmentationMengqiu Wang Yanxin ShiLanguage Technologies InstituteSchool of Computer ScienceCarnegie Mellon UniversityPittsburgh, PA 15213, USA{mengqiu,yanxins}@cs.cmu.eduAbstractChinese word segmentation and Part-of-Speech (POS) tagging have been com-monly considered as two separated tasks.In this paper, we present a system thatperforms Chinese word segmentation andPOS tagging simultaneously.
We train asegmenter and a tagger model separatelybased on linear-chain Conditional Ran-dom Fields (CRF), using lexical, morpho-logical and semantic features.
We proposean approximated joint decoding methodby reranking the N-best segmenter out-put, based POS tagging information.
Ex-perimental results on SIGHAN Bakeoffdataset and Penn Chinese Treebank showthat our reranking method significantlyimprove both segmentation and POS tag-ging accuracies.1 IntroductionWord segmentation and Part-of-speeching (POS)tagging are the most fundamental tasks in Chinesenatural language processing (NLP).
Traditionally,these two tasks were treated as separate and in-dependent processing steps chained together in apipeline.
In such pipeline systems, errors intro-duced at the early stage cannot be easily recov-ered in later steps, causing a cascade of errorsand eventually harm overall performance.
Intu-itively, a correct segmentation of the input sen-tence is more likely to give rise to a correct POStagging sequence than an incorrect segmentation.Hinging on this idea, one way to avoid error prop-agation in chaining subtasks such as segmentationand POS tagging is to exploit the learning trans-fer (Sutton and McCallum, 2005) among sub-tasks, typically through joint inference.
Sutton etal.
(2004) presented dynamic conditional randomfields (DCRF), a generalization of the traditionallinear-chain CRF that allow representation of in-teraction among labels.
They used loopy beliefpropagation for inference approximation.
Theirempirical results on the joint task of POS taggingand NP-chunking suggested that DCRF gave supe-rior performance over cascaded linear-chain CRF.Ng and Low (2004) and Luo (2003) also trainedsingle joint models over the Chinese segmentationand POS tagging subtasks.
In their work, theybrought the two subtasks together by treating it asa single tagging problem, for which they trained amaximum entropy classifier to assign a combinedword boundary and POS tag to each character.A major challenge, however, exists in doingjoint inference for complex and large-scale NLPapplication.
Sutton and McCallum (Sutton andMcCallum, 2005) suggested that in many cases ex-act inference can be too expensive and thus formi-dable.
They presented an alternative approach inwhich a linear-chain CRF is trained separately foreach subtask at training time, but at decoding timethey combined the learned weights from the CRFcascade into a single grid-shaped factorial CRFto perform joint decoding and make predictionsfor all subtasks.
Similar to (Sutton and McCal-lum, 2005), in our system we also train a cas-cade of linear-chain CRF for the subtasks.
Butat decoding time, we experiment with an alterna-tive approximation method to joint decoding, bytaking the n-best hypotheses from the segmenta-tion model and use the POS tagging model forreranking.
We evaluated our system on the opentracks of SIGHAN Bakeoff 2006 dataset.
Fur-thermore, to evaluate our reranking method?s im-pact on the POS tagging task, we also performed10-fold cross-validation tests on the 250k Penn205Chinese Treebank (CTB) (Xue et al, 2002).
Re-sults from both evaluations suggest that our simplereranking method is very effective.
We achieveda consistent performance gain on both segmenta-tion and POS tagging tasks over linearly-cascadedCRF.
Our official F-scores on the 2006 Bakeoffopen tracks are 0.935 (UPUC), 0.964 (CityU),0.952 (MSRA) and 0.949 (CKIP).2 AlgorithmGiven an observed Chinese character sequenceX = {C1, C2, ..., Cn}, let S and T denote a seg-mentation sequence and a POS tagging sequenceover X.
Our goal is to find a segmentation se-quence S?
and a POS tagging sequence T?
that max-imize the posterior probability :P (S,T|X = {C1, C2, ..., Cn}) (1)Applying chain rule, we can further derive fromEquation 1 the following:< S?, T?
>= arg maxS,TP (T|S,X = {C1, C2, ..., Cn})?P (S|X = {C1, C2, ..., Cn}) (2)Since we have factorized the joint probabilityin Equation 1 into two terms, we can now modelthese two components using conditional randomfields (Lafferty et al, 2001).
Linear-chain CRFmodels define conditional probability, P (Z|X), bylinear-chain Markov random fields.
In our case, Xis the sequence of characters or words, and Z isthe segmentation labels for characters (START orNON-START, used to indicate word boundaries)or the POS tagging for words (NN, VV, JJ, etc.
).The conditional probability is defined as:P (Z|X) = 1N(X) exp (T?t=1K?k=1?kfk(Z,X, t))(3)where N(X) is a normalization term to guaran-tee that the summation of the probability of alllabel sequences is one.
fk(Z,X, t) is the kthlocalfeaturefunction at sequence position t. Itmaps a pair of X and Z and an index t to {0,1}.
(?1, ..., ?K) is a weight vector to be learned fromtraining set.
A large positive value of ?i meansthat the ith feature function?s value is frequent tobe 1, whereas a negative value of ?i means the ithfeature function?s value is unlikely to be 1.At decoding time, we are interested in findingthe segmentation sequence S?
and POS tagging se-quence T?
that maximizes the probability definedin Equation 2.
Instead of exhaustively searchingthe whole space of all possible segmentations, werestrict our searching to S = {S1,S2, ...,SN},where S is the restricted search space consistingof N-best decoded segmentation sequences.
ThisN-best list of segmentation sequences, S, can beobtained using modified Viterbi algorithm and A*search (Schwartz and Chow, 1990).3 Features3.1 Features for SegmentationWe adopted the basic segmentation features usedin (Ng and Low, 2004).
These features are summa-rized in Table 1 ((1.1)-(1.7)).
In these templates,C0 refers to the current character, and C?n, Cn re-fer to the characters n positions to the left and rightof the current character, respectively.
Pu(C0) in-dicates whether C0 is a punctuation.
T (Cn) clas-sifies the character Cn into four classes: num-bers, dates (year, month, date), English letters andall other characters.
LBegin(C0), LEnd(C0) andLMid(C0) represent the maximum length of wordsfound in a lexicon1 that contain the current char-acter as either the first, last or middle character, re-spectively.
Single(C0) indicates whether the cur-rent character can be found as a single word in thelexicon.Besides the adopted basic features mentionedabove, we also experimented with additional se-mantic features (Table 1 (1.8)).
For (1.8), Sem0refers to the semantic class of current character,and Sem?1, Sem1 represent the semantic classof characters one position to the left and right ofthe current character, respectively.
We obtaineda character?s semantic class from HowNet (Dongand Dong, 2006).
Since many characters havemultiple semantic classes defined by HowNet, itis a non-trivial task to choose among the differ-ent semantic classes.
We performed contextualdisambiguation of characters?
semantic classes bycalculating semantic class similarities.
For ex-ample, let us assume the current character is(look,read) in a word context of ?
(read1We compiled our lexicon from three external re-sources.
HowNet: www.keenage.com; On-Line ChineseTools: www.mandarintools.com; Online Dictionary fromPeking University: http://ccl.pku.edu.cn/doubtfire/Course/Chinese%20Information%20Processing/Source Code/Chapter 8/Lexicon full 2000.zip206newspaper).
The character (look) has two se-mantic classes in HowNet, i.e.
?
(read) and ?(doctor).
To determine which class is moreappropriate, we check the example words illus-trating the meanings of the two semantic classes,given by HowNet.
For ?
(read), the exam-ple word is V(read book); for ?
(doctor),the example word is >(see a doctor).
Wethen calculated the semantic class similarityscores between?
(newspaper) andV(book), and?
(newspaper) and >(illness), using HowNet?sbuilt-in similarity measure function.
Since?
(newspaper) and V(book) both have seman-tic class ?V(document), their maximum simi-larity score is 0.95, where the maximum similar-ity score between ?
(newspaper) and >(illness)is 0.03478.
Therefore, Sem0Sem1 =?(read),?V(document).
Similarly, we can figure outSem?1Sem0.
For Sem0, we simply picked thetop four semantic classes ranked by HowNet, andused ??NONE??
for absent values.Segmentation features(1.1) Cn, n ?
[?2, 2](1.2) CnCn+1, n ?
[?2, 1](1.3) C?1C1(1.4) Pu(C0)(1.5) T (C?2)T (C?1)T (C0)T (C1)T (C2)(1.6) LBegin(C0), LEnd(C0)(1.7) Single(C0)(1.8) Sem0, SemnSemn+1, n ?
?1, 0POS tagging features(2.1) Wn, n ?
[?2, 2](2.2) WnWn+1, n ?
[?2, 1](2.3) W?1W1(2.4) Wn?1WnWn+1, n ?
[?1, 1](2.5) Cn(W0), n ?
[?2, 2](2.6) Len(W0)(2.7) Other morphological featuresTable 1: Feature templates list3.2 Features for POS TaggingThe bottom half of Table 1 summarizes the featuretemplates we employed for POS tagging.
W0 de-notes the current word.
W?n and Wn refer to thewords n positions to the left and right of the cur-rent word, respectively.
Cn(W0) is the nth char-acter in current word.
If the number of charactersin the word is less than 5, we use ?NONE?
for ab-sent characters.
Len(W0) is the number of char-acters in the current word.
We also used a groupof binary features for each word, which are used torepresent the morphological properties of currentword, e.g.
whether the current word is punctua-tion, number, foreign name, etc.4 Experimental ResultsWe evaluated our system?s segmentation results onthe SIGHAN Bakeoff 2006 dataset.
To evaluateour reranking method?s impact on the POS taggingpart, we also performed 10-fold cross-validationtests on the 250k Penn Chinese Treebank (CTB250k).
The CRF model for POS tagging is trainedon CTB 250k in all the experiments.
We report re-call (R), precision (P), and F1-score (F) for bothword segmentation and POS tagging tasks.
Nvalue is chosen to be 20 for the N-best list rerank-ing, based on cross validation.
For CRF learningand decoding, we use the CRF++ toolkit2.4.1 Results on Bakeoff 2006 DatasetR P F Roov RivUPUC 0.942 0.928 0.935 0.711 0.964CityU 0.964 0.964 0.964 0.787 0.971MSRA 0.949 0.954 0.952 0.692 0.958CKIP 0.953 0.946 0.949 0.679 0.965Table 2: Performance of our system on open tracksof SIGHAN Bakeoff 2006.We participated in the open tracks of theSIGHAN Bakeoff 2006, and we achieved F-scoresof 0.935 (UPUC), 0.964 (CityU), 0.952 (MSRA)and 0.949 (CKIP).
More detailed performancesstatistics including in-vocabulary recall (Riv) andout-of-vocabulary recall (Roov) are shown in Table2.More interesting to us is how much the N-bestlist reranking method using POS tagging helpedto increase segmentation performance.
For com-parison, we ran a linear-cascade of segmentationand POS tagging CRFs without reranking as thebaseline system, and the results are shown in Table3.
We can see that our reranking method consis-tently improved segmentation scores.
In particu-lar, there is a greater improvement gained in recallthan precision across all four tracks.
We observedthe greatest improvement from the UPUC track.We think it is because our POS tagging model istrained on CTB 250k, which could be drawn fromthe same corpus as the UPUC training data, andtherefore there is a closer mapping between seg-mentation standard of the POS tagging trainingdata and the segmentation training data (at this2http://chasen.org/ taku/software/CRF++/2071 2 3 4 5 6 7 8 9 10939495969710 cross?fold validation testF?Measure(%)CTB Segmentation Resultsbaselinefinal system1 2 3 4 5 6 7 8 9 10878889909192939410 cross?fold validation testF?Measure(%)CTB POS Tagging Resultsbaselinefinal systemFigure 1: Segmentation and POS tagging resultson CTB corpus.point we are not sure if there exists any overlapbetween the UPUC test data and CTB 250k).Baseline system Final systemR P F R P FUPUC 0.910 0.924 0.917 0.942 0.928 0.935CityU 0.954 0.963 0.958 0.964 0.964 0.964MSRA 0.935 0.953 0.944 0.949 0.954 0.952CKIP 0.932 0.942 0.937 0.953 0.946 0.949Table 3: Comparison of the baseline system (with-out POS reranking) and our final system.4.2 Results on CTB CorpusTo evaluate our reranking method?s impact on thePOS tagging task, we also tested our systems onCTB 250k corpus using 10-fold cross-validation.Figure 1 summarizes the results of segmentationand POS tagging tasks on CTB 250k corpus.
Fromfigure 1 we can see that our reranking method im-proved both the segmentation and tagging accu-racies across all 10 tests.
We conducted pairwiset-tests and our reranking model was found to bestatistically significantly better than the baselinemodel under significance level of 5.0?4 (p-valuefor segmentation) and 3.3?5 (p-value for POS tag-ging).5 ConclusionOur system uses conditional random fields for per-forming Chinese word segmentation and POS tag-ging tasks simultaneously.
In particular, we pro-posed an approximated joint decoding method byreranking the N-best segmenter output, based POStagging information.
Our experimental results onboth SIGHAN Bakeoff 2006 datasets and ChinesePenn Treebank showed that our reranking methodconsistently increased both segmentation and POStagging accuracies.
It is worth noting that ourreranking method can be applied not only to Chi-nese segmentation and POS tagging tasks, but alsoto many other sequential tasks that can benefitfrom learning transfer, such as POS tagging andNP-chunking.AcknowledgmentThis work was supported in part by ARDA?sAQUAINT Program.ReferencesZhengdong Dong and Qiang Dong.
2006.
HowNetAnd The Computation Of Meaning.
World Scien-tific.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.
In Proceedings of ICML ?01.Xiaoqiang Luo.
2003.
A maximum entropy Chinesecharacter-based parser.
In Proceedings of EMNLP?03.Hwee Tou Ng and Jin Kiat Low.
2004.
Chinese part-of-speech tagging: One-at-a-time or all-at-once?word-based or character-based?
In Proceedings ofEMNLP ?04.Richard Schwartz and Yen-Lu Chow.
1990.
The n-best algorithm: An efficient and exact procedure forfinding the n most likely sentence hypotheses.
InProceedings of ICASSP ?90.Charles Sutton and Andrew McCallum.
2005.
Compo-sition of conditional random fields for transfer learn-ing.
In Proceedings of HLT/EMNLP ?05.Charles Sutton, Khashayar Rohanimanesh, and An-drew McCallum.
2004.
Dynamic conditional ran-dom fields: Factorized probabilistic models for la-beling and segmenting sequence data.
In Proceed-ings of ICML ?04.Nianwen Xue, Fu-Dong Chiou, and Martha StonePalmer.
2002.
Building a large-scale annotated Chi-nese corpus.
In Proceedings of COLING ?02.208
