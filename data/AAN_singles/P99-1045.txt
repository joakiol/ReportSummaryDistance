Less is more:El iminating index terms from subordinate clausesSimon H. Corston-Oliver and William B. DolanMicrosoft ResearchOne Microsoft WayRedmond WA 98052{ simonco, billdol } @microsoft.comAbstractWe perform a linguistic analysis ofdocuments during indexing for informationretrieval.
By eliminating index terms thatoccur only in subordinate clauses, index sizeis reduced by approximately 30% withoutadversely affecting precision or recall.
Theseresults hold for two corpora: a sample of theworld wide web and an electronicencyclopedia.1 IntroductionEfforts to exploit natural languageprocessing (NLP) to aid information retrieval(IR) have generally involved augmenting astandard index of lexical terms with morecomplex terms that reflect aspects of thelinguistic structure of the indexed text (Fagan1988, Katz 1997, Arampatzis et al 1998,Strzalkowski et al 1998, inter alia).
This papershows that NLP can benefit information retrievalin a very different way: rather than increasingthe size and complexity of an IR index,linguistic information can make it possible tostore less information i  the index.
In particular,we demonstrate that robust NLP technologymakes it possible to omit substantial portions ofa text from the index without dramaticallyaffecting precision or recall.This research is motivated by insights fromRhetorical Structure Theory (RST) (Mann &Thompson 1986, 1988).
An RST analysis is adependency analysis of the structure of a text,whose leaf nodes are the propositions encoded inclauses.
In this structural analysis, somepropositions in the text, called "nuclei," aremore centrally important in realizing the writer'scommunicative goals, while other propositions,called "satellites," are less central in realizingthose goals, and instead provide additionalinformation about the nuclei in a mannerconsistent with the discourse relation betweenthe nucleus and the satellite.
This asymmetry hasan analogue in sentence structure: main clausestend to represent nuclei, while subordinateclauses tend to represent satellites (Matthiessenand Thompson 1988, Corston-Oliver 1998).From the perspective of discourse analysis,the task of information retrieval can be viewedas attempting to identify the "aboutness," orglobal topicality, of a document in order todetermine the relevance of the document as aresponse to a user's query.
Given an RSTanalysis of a document, we would expect hat forthe purposes of predicting document relevance,information that occurs in nucleic propositionsought to be more useful than information thatoccurs in satellite propositions.
To test thisexpectation, we experimented with eliminatingfrom an IR index those terms that occurred incertain kinds of subordinate clauses.2 System descriptionAt the core of the Microsoft EnglishGrammar (MEG), is a broad-coverage parserthat produces conventional phrase structureanalyses augmented with grammatical relations;this parser is the basis for the grammar checkerin Microsoft Word (Heidorn 1999).
Syntacticanalyses undergo further processing in order toderive logical forms (LFs), which are graphstructures that describe labeled dependenciesamong content words in the original input.
LFsnormalize certain syntactic alternations (e.g.active/passive) and resolve both intrasententialanaphora nd long-distance d pendencies.Over the past two years we have beenexploring the use of MEG LFs as a means of349improving IR precision.
This work, which isembodied in a natural anguage query feature inthe Microsoft Encarta 99 encyclopedia,augments a traditional keyword document indexwith a second index that contains linguistically-informed terms.
Two types of terms are stored inthis linguistic index:1.
LF triples.
These are subgraphsextracted from the LF.
Each triple has theform wordl-relation-word2, describing adependency relation between two contentwords.
For example, for the sentenceAbraham Lincoln, the president, wasassassinated by John Wilkes Booth, weextract he following LF triples: tassassinate--LSubj--John_Wilkes_Boothassassinate--LOb j--Abraham_LincolnAbraham_Lincoln--Equiv--president2.
Subject erms.
These are terms thatindicate which words served as thegrammatical head of a surface syntacticsubject in the document, for example:Subject: Abraham_LincolnThis linguistic index is used to postfilter theoutput of a conventional statistical searchalgorithm.
An input natural language query isfirst submitted to the statistical search algorithmas a set of content words, resulting in a rankedset of documents.
This ranked set is then re-ranked by attempting to find overlap betweenthe set of linguistic terms stored for each ofthese documents and corresponding linguisticterms determined by processing the query inMEG.
Documents that contain linguisticmatches are heuristically ranked according to thenature of the match.
Documents that fail tomatch do not receive a rank, and are typicallynot displayed to the user.
The process ofbuilding a secondary linguistic index andmatching terms from the query is referred to asnatural language matching (NLM) in thediscussion below.
NLM has been used to filterdocuments retrieved by several different searchtechnologies operating on different genres oftext.Since NLM was intended for use inconsumer products, it was important tominimize index size.
We needed an algorithmthat would enable us to achieve reductions inindex size without adversely affecting precisionand recall.
At the time when we were conductingthese experiments, there did not exist anysufficiently large publicly available corpora ofquestions and relevant documents for the twogenres of interest to us: the word wide web andencyclopedia text.
We therefore gathered queriesand documents for a web sample (section 3.2)and Encarta 99 (section 3.3), and had non-linguists perform double-blind evaluations ofrelevance.Three implementation-specific aspects of theNLM index should be noted.
First, in order tolimit index size, duplicate instances of a termoccurring in the same document are stored onlyonce.
Second, because of the particularcompression scheme used to build the index, allterms require the same number of bits forstorage, regardless of the length or number ofwords they contain.
Third, the top ten percent ofthe NLM terms were suppressed, by analogywith stop words in conventional indexingschemes.
Such high frequency terms tended notto be good predictors of document relevance.3 ExperimentsWe conducted experiments in which weeliminated terms from the NLM index, and thenmeasured precision and recall.
The experimentswere performed on two test corpora: web pagesreturned by the Alta Vista search service(section 3.2) and articles from the Encartaelectronic encyclopedia (section 3.3).3.1 The kinds of subordinate clausesIn order to test the hypothesis thatinformation contained in subordinate clauses isless useful for IR than matrix clauseinformation, we modified the indexing algorithmso that it eliminated terms that occurred incertain kinds of subordinate clauses.
Weexperimented with the following clause types:I LSubj denotes a logical subject, LObj a logicalobject and Equiv an equivalence r lation.350Abbreviated Clause (ABBCL)Until further indicated, lunch will be servedat 1 p.m.Complement Clause (COMPCL)\[ told the telemarketer that you weren'thome.Adverbial Clause (ADVCL)After John went home, he ate dinner.Infinitival Clause (INFCL)John decided to go home.Relative Clause (RELCL)I saw the man, who was wearing a greenha__!.Present Participial Clause(PRPRTCL)Napoleon attacked the fleet,destroying it.completelyIn the experiments described below, termswere eliminated from documents duringindexing.
However, terms were never eliminatedfrom the queries.3.2 Alta Vista experimentsWe gathered 120 natural language queriesfrom colleagues for submission to Alta Vista.
2The queries averaged 3.7 content words, with astandard deviation of 1.7.
3 The following areillustrative of the queries ubmitted:Are there any air-conditioned hotels in Bali?Has anyone ported Eliza to Win95?What are the current weather conditions atSteven' s Pass ?What makes a cat purr?Where is Xian ?When will the next non-rerun showing ofStar Trek air?2 Alta Vista's main search page(http://altavista.com) encourages users to submitnatural anguage queries.3 Words like "know" and "find", which arecommon in natural anguage queries, are included inthese counts.We examined the first thirty documentsreturned by Alta Vista (or fewer documents forqueries that did not return at least thirtydocuments).
This document set comprised 3,440documents.
Since we were not able to determinewhat percentage of the web Alta Vista accountedfor, it was not possible to calculate the recall ofthis document set.
In the discussion below, wecalculate recall as a percentage of the relevantdocuments returned by Alta Vista.
Precision andrecall are averaged across all queries submittedto Alta Vista.
The documents returned by AltaVista were indexed using NLM (section 2) andfiltered to retain only documents that containedmatches.Table 1 contrasts the baseline NLM figures(indexing based on terms in all clauses) with theresults of eliminating from the documents allterms that occurred in subordinate clauses.To measure the trade-off between precisionand recall, we calculated the F-measure (VanRij sbergen 1980), defined asF - (f12 + 1 .0)PR,  where P is precision, R isf l2p  + Rrecall and \[3 is the relative weight assigned toprecision and recall (for these experiments,13= 1).As Table 1 shows, by eliminating termsfrom all subordinate clauses in the documents,the NLM index size was reduced by 31.4% withonly a minor impact (-0.82%) on F-measure.Given unique indexing of terms per document,and a constant size per term (section 2), we candeduce that 31.4% of the terms in the NLMindex occurred only in subordinate clauses.
Hadthey occurred even once in a main clause, theywould not have been removed from the index.We ran two comparison experiments.
In thefirst comparison, we deleted one third of allterms as they were produced.
Table 2 gives theaverage results of three runs of this experiment.In each run, a different set of one third of theterms was deleted.
Although fewer terms wereomitted (28.8% 4 versus 31.4% when all terms in4 TelTflS eliminated from a subordinate clause inone sentence might persist in the index if theyoccurred in the main clause of another sentence in thesame document, hence a reduction of slightly lessthan 33.3%.351subordinate clauses were eliminated) thedetrimental effect on F-measure was 5.3 timesgreater than when terms occuring in subordinateclauses were deleted.Table 1 Alta Vista: Effects of eliminating subordinate clausesAlgorithm Precision Recall F % Changein F 5Baseline NLM 34.3 43.2 38.24 0.00Subordinate clauses 35.9 40.2 37.93 -0.82% Change inindex size0.0-31.4Table 2 Alta Vista: Average effect of eliminating one third of termsPrecision Recall F % Change % Change inin F index size36.9 36.4 36.65 -4.34 -28.8In the second comparison experiment, wetested the converse of the operation describedin the discussion of Table 1 above: weeliminated all search terms from the mainclauses of documents, leaving only searchterms that occurred in subordinate clauses.Table 3 shows the dramatic effect of thisoperation: as we expected, the index size wasgreatly reduced (by 73.8%).
However, F-measure was seriously affected, by more thantwo thirds, or -68.99%.
The effect on F-measure is primarily due to the severe impacton recall, which fell from a tolerable baselineof 43.2% to an unacceptable 7.5%.
Comparingthe reduction in index size to the reductionwhen subordinate clause information waseliminated (73.8% versus 31.4%, a factor ofapproximately 2:1) to the reduction in F-measure (-68.99 versus -0.82, a factor ofapproximately 84:1), it is clear that the impacton F-measure from eliminating terms in mainclauses is disproportionate to the reduction inindex size.Table 3 Alta Vista: Effect of diminating main clausesPrecision Recall F % Change % Change inin F index size28.3 7.5 11.86 -68.99 -73.8Table 4 isolates the effects of deleting eachkind of subordinate clause.
Most remarkable isthe fact that eliminating terms that only occur inrelative clauses (RELCL) yields a 7.3%reduction in index size while actually improvingF-measure.
Also worthy of special note is thefact that two kinds of subordinate clauses can beeliminated with no perceptible ffect on F-measure: eliminating complement clauses(COMPCL), yields a reduction in index size of7.4%, and eliminating present participial clauses(PRPRTCL) yields a reduction in index size of4.2%.5 F is calculated from the underlying figures, to minimise the effects of rounding errors.352Table 4 Alta Vista: Effect of eliminating different kinds of subordinate clausesAlgorithm Precision Recall F % Change % Change inin F index sizeBaseline NLM 34.3 43.2 38.24 0.00 0.0ADVCL 34.6 42.1 37.98 -0.67 -7.0ABBCL ~ 34.3 43.2 38.24 0.00 -0.3INFCL 34.8 42.1 38.10 -0.36 -11.8RELCL 34.9 42.6 38.37 0.33 -7.3COMPCL 34.5 42.9 38.24 0.00 -7.4PRPRTCL 34.5 42.9 38.24 0.01 -4.2Because of interactions among the differentclause types, the effects illustrated in Table 4 arenot additive.
For example, an infinitival clause(INFCL) may contain a noun phrase with anembedded relative clause (RELCL).
Eliminationof all terms in the infinitival clause wouldtherefore also lead to elimination of terms in therelative clause.3.3 Encarta experimentsWe gathered 348 queries from middle-school students for submission to Encarta, anelectronic encyclopedia.
The queries averaged3.4 content words, with a standard eviation of1.4.
The following are illustrative of the queriessubmitted:How many people live in Nebraska ?How many valence electrons does sodiumhave ?I need to know where hyenas live.In what event is Amy VanDyken the closestto the world record in swimming ?What color is a giraffe's tongue ?What is the life-expectancy of an elephant?We indexed the text of the Encarta rticles,approximately 33,000 files containingapproximately 576,000 sentences, using asimple statistical indexing engine.
We thensubmitted each query and gathered the firstthirty ranked documents, for a total of 5,218documents.
We constructed an NLM index forthe documents returned and, in a second pass,filtered ocuments u ing NLM.
In the discussionbelow, recall is calculated as a percentage of therelevant documents that the statistical searchreturned.Table 5 compares the baseline NLMaccuracy (indexing all terms) to the accuracy ofeliminating terms that occurred in subordinateclauses.
The reduction in index size (29.0%) iscomparable tothe reduction observed in the AltaVista experiment (31.4%).
However, the effecton F-measure of eliminating terms fromsubordinate clauses is more marked (-4.91%)than in the Alta Vista experiment (-0.82%).Table 5 Encarta: Effects of eliminating subordinate clausesAlgorithmBaseline NLMSubordinate clausesPrecision39.241.1Recall29.025.9F33.3431.78% Change % Change inin F index size0.00 0.0-4.91 -29.0The impact on F-measure is stillsubstantially ess than the average of three runsduring which arbitrary non-overlapping thirds ofthe terms were eliminated, as illustrated in353Table 6.
This arbitrary deletion of terms resultsin an 11.57% reduction in F-measure comparedto the baseline, approximately 2.4 times greaterthan the impact of eliminating materialsubordinate clauses.inTable 6 Encarta: Effects of eliminating one third of termsPrecision Recall F % Change % Change inin F index size40.2 23.8 29.88 - 11.57 -29.5As Table 7 shows, eliminating terms frommain clauses and retaining information insubordinate clauses has a profound effect onrecall for the Encarta corpus.
As with the AltaVista experiment (section 3.2), it is instructiveto compare the results in Table 7 to the resultsobtained when terms in subordinate clauseswere deleted (Table 5).
Approximately 2.7times as many terms were eliminated from theindex, yet the effect on F-measure is almostthirteen times worse.Table 7 Encarta: Effect of eliminating main clausesPrecision Recall40.9 7.4F % Changein F12.53 -62.41% Change inindex size-77.1Table 8 isolates the effects for Encarta ofeliminating terms from each kind of subordinateclause.
It is interesting to compare the reductionin index size and the relative change in F-measure for Encarta, a relatively homogeneouscorpus of academic articles, to theheterogeneous web sample of section 3.2.
Forboth corpora, eliminating terms that only occurin abbreviated clauses (ABBCL) or presentparticipial clauses (PRPRTCL) results in modestreductions in index size without negativelyaffecting F-measure.
Eliminating terms fromadverbial clauses (ADVCL) or infinitival clauses(INFCL) also produces a similar effects on thetwo corpora: a reduction in index size with amodest (less than 1%) reduction in F-measure.Relative clauses (RELCL) and complementclauses (COMPCL), however, behavedifferently across the two corpora.
In both cases,the effects on F-measure are positive for webdocuments and negative for Encarta rticles.
Thenegative impact of the elimination of materialfrom relative clauses in Encarta can perhaps beattributed to the pervasive use of non-restrictiverelative clauses in the definitional encyclopediatext, as illustrated by the underlined sections ofthe following examples:Sargon H (ruled 722-705 BC), who followedTiglath-pileser's successor, Shalmaneser V(ruled 727-722 BC), to the throne, extendedAssyrian domination in all directions, fromsouthern Anatolia to the Persian GulfAmaral, Tarsila do (1886-1973), Brazilianpainter whose works were instrumental in thedevelopment ofmodernist painting in Brazil.After the so-called Boston Tea Party in 1773,when Bostonians destroyed tea belonging to theEast India Company, Parliament enacted fourmeasures as an example to the other rebelliouscolonies.Another peculiar characteristic of theEncarta corpus, namely the pervasive use of354complement taking nominal expressions such asthe belief that and the fact that, possiblyexplains the negative impact of the eliminationof complement clause material in Table 8.Table 8 Encarta: Effect of eliminating different kinds of subordinate clausesAlgorithm Precision Recall F % Change % Change inin F index sizeBaseline NLM 39.2 29.0 33.34 0.00 0.0ADVCL 39.9 28.4 33.18 -0.47 -5.8ABBCL 39.6 29.0 33.48 0.43 -0.4INFCL 40.0 28.3 33.15 -0.57 -9.2RELCL 39.7 28.2 32.98 - 1.10 -9.5COMPCL 38.9 28.3 32.76 - 1.75 -3.3PRPRTCL 39.8 29.0 33.55 0.64 -5.54 DiscussionAlthough the results presented in section 3are compelling, it may be possible to refine theidentification ofclauses from which index termscan be eliminated.
In particular, complementclauses subordinate to speech act verbs wouldappear from failure analysis to warrant specialattention.
For example, in the following sentenceour linguistic intuitions uggest that the contentof the complement clause is more informativethan the attribution to a speaker in the mainclause: John said that the President would notresign in disgrace.
Of course, more fine-graineddistinctions of this type can only be made givensufficiently rich linguistic analyses as input.Another compelling topic for future researchwould be the impact of less sophisticatedanalyses to identify various kinds of subordinateclauses.The terms eliminated in the experimentspresented in this paper were linguistic in nature.However, we would expect similar results ifconventional word-based terms were eliminatedin similar fashion.
In future research, we intendto experiment with eliminating terms from aconventional statistical engine, combining thistechnique with the standard method ofeliminating high frequency index terms.. Ratherthan eliminating terms from an index, it mayalso prove fruitful to investigate weighting termsaccording to the kind of clause in which theyoccur.5 ConclusionsWe have demonstrated that, as implicitlypredicted by RST, index terms may beeliminated from certain kinds of subordinateclauses without substantially affecting precisionor recall.
Rather than using NLP to generatemore index terms, we have found tremendousgains from systematically eliminating terms.
Theexact severity of the impact on precision andrecall that results from eliminating terms variesby genre.
In all cases, however, the systematicelimination of subordinate clause material issubstantially better than arbitrary deletion ofindex terms or the deletion of index terms thatoccur only in main clauses.Future research shall attempt to refine theanalysis of the kinds of subordinate clauses fromwhich index terms can be omitted, and tointegrate these findings with conventionalstatistical IR algorithms.AcknowledgementsOur thanks go to Lisa Braden-Harder, SusanDumais, Raman Chandrasekar, Eric Ringger,Monica Corston-Oliver, Lucy Vanderwende andthe three anonymous reviewers for their help andcomments on an earlier draft of this paper and toJing Lou for assistance in configuring a testenvironment.355ReferencesArampatzis, A. T., T. Tsoris, C. H. A. Koster, T. P.Van Der Weide.
(1998) "Phrase-based informationretrieval", Information Processing andManagement 34:693-707.Corston-Oliver, S. H. (1998) ComputingRepresentations of the Structure of WrittenDiscourse.
Ph.D. dissertation.
University ofCalifornia, Santa Barbara.Fagan, J. L. (1988) Experiments in Automatic PhraseIndexing for Document Retrieval: A Comparison ofSyntactic and Non-syntactic Methods.
Ph.D.dissertation.
Cornell University.Heidorn, G. (1999) "Intelligent writing assistance.
"To appear in Dale, R., H. Moisl and H.
Somers(eds.
), A Handbook of Natural LanguageProcessing Techniques.
Marcel Dekker.Katz, B.
(1997) "Annotating the World Wide WebUsing Natural Language."
Proceedings of RIAO97, Computer-assisted Information Search onlnternet, McGill University, Quebec, Canada, 25-27 June 1997.
Vol.
1:136-155.Mann, W. C. and Thompson, S. A.
(1986)"Relational Propositions in Discourse."
DiscourseProcesses 9:57-90.Mann, W. C. and Thompson, S. A.
(1988)"Rhetorical Structure Theory: Toward a functionaltheory of text organization."
Text 8:243-281.Matthiessen, C. and Thompson, S. A.
(1988) "Thestructure of discourse and 'subordination'."
InHaiman, J. and S. A. Thompson, (eds.).
1988.Clause Combining in Grammar and Discourse.John Benjamins: Amsterdam and Philadelphia.275-329.Strzalkowski, T. G. Stein, G. B.
Wise, J. Perez-Carball, P. Tapanainen, T. Jarvinent, A.Voutilainen, J. Karlgren.
(1997)Natural LanguageInformation Retrieval: TREC-7 Report.Van Rijsbergen, C. J.
(1980) Information Retrieval.Butterworths: London and Boston.356
