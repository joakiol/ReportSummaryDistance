Grammar and Lexicon in the Robust Parsing of ItalianTowards a Non-Na?ve InterplayRobertoBARTOLINIIstituto di LinguisticaComputazionale CNRArea della RicercaVia Moruzzi 156100 PISA (Italy)AlessandroLENCIUniversit?
di PisaVia Santa Maria 3656100 PISA (Italy)SimonettaMONTEMAGNIIstituto di Linguistica Com-putazionale CNRArea della RicercaVia Moruzzi 156100 PISA (Italy)VitoPIRRELLIIstituto di LinguisticaComputazionale CNRArea della RicercaVia Moruzzi 156100 PISA (Italy){roberto.bartolini, alessandro.lenci, simonetta.montemagni, vito.pirrelli}@ilc.cnr.itAbstractIn the paper we report a qualitative evalua-tion of the performance of a dependencyanalyser of Italian that runs in both a non-lexicalised and a lexicalised mode.
Resultsshed light on the contribution of types oflexical information to parsing.IntroductionIt is widely assumed that rich computationallexicons form a fundamental component of reli-able parsing architectures and that lexical infor-mation can only have beneficial effects onparsing.
Since the beginning of work on broad-coverage parsing  (Jensen 1988a, 1988b), thekey issue has been how to make effective use oflexical information.
In this paper we put theseassumptions to the test by addressing the follow-ing questions: to what extent should a lexicon betrusted for parsing?
What is the neat contributionof lexical information to overall parse success?We present here the results of a preliminaryevaluation of the interplay between lexical andgrammatical information in parsing Italian usinga robust parsing system based on an incrementalapproach to shallow syntactic analysis.
The sys-tem can run in both a non-lexicalised and a lexi-calised mode.
Careful analysis of the resultsshows that contribution of lexical information toparse success is more selective than commonlyassumed,  thus raising the parallel issues of howto promote a more effective integration betweenparsers and lexicons and how to develop betterlexicons for parsing.1 Syntactic parsing lexiconsSyntactic lexical information generally feedsparsing systems distilled in subcategorizationframes.
Subcategorization is a formal specifica-tion of a predicate phrasal context in terms of thetype of arguments syntactically selected by thepredicate entry (e.g.
the verb hit selects for asubject NP and an object NP).
Lexical framescommonly include: i.)
number of selected argu-ments, ii.)
syntactic categories of their possiblerealization (NP, PP, etc.
), iii.)
lexical constraintson the argument realization (e.g.
the prepositionheading a PP complement), and iv.)
the argu-ment functional role.
Other types of syntactic in-formation that are also found in syntacticlexicons are: argument optionality, verb control,auxiliary selection, order constraints, etc.
On theother hand, collocation-based lexical informa-tion is only rarely provided by computationallexicons, a gap often lamented in robust parsingsystem development.A number of syntactic computational lexi-cons are nowadays available to the NLP com-munity.
Important examples are LDOCE(Procter 1987), ComLex (Grishman et al 1994),PAROLE (Ruimy et al 1998).
These lexiconsare basically hand-crafted by expert lexicogra-phers, and their natural purpose is to providegeneral purpose, domain-independent syntacticinformation, covering the most frequent entriesand frames.
On the other hand, parsing systemsoften complement general lexicons with corpus-driven, automatically harvested syntactic infor-mation (Federici et al 1998b, Briscoe 2001,Korhonen 2002).
Automatic acquisition of sub-categorization frames allows systems to accesshighly context dependent constructions, to fill inpossible lexical gaps and eventually rely on fre-quency information to tune the relative impact ofspecific frames (Carroll et al 1998).Lexicon coverage is usually regarded as themain parameter affecting use of lexical informa-tion for parsing.
However, the real comparativeimpact of the type (rather than the mere quan-tity) of lexical information has been seldom dis-cussed.
Our results show that the contribution ofvarious lexical information types to parse suc-cess is not uniform.
The experiment focuses on aparticular subset of the information available insyntactic lexicons - the representation of PPcomplements in lexical frames - tested on thetask of PP-attachment.
The reason for thischoice is that this piece of information occupiesa central and dominant position in existing lexi-cons.
For instance in the Italian PAROLE lexi-con, more than one third of verb frames containpositions realized by a PP, and this percentageraises up to the near totality noun-headedframes.2 Robust Parsing of ItalianThe general architecture of the Italian parsingsystem used for testing adheres to the followingprinciples: 1) modular approach to parsing, 2)underspecified output (whenever required), 3)cautious use of lexical information, generally re-sorted to in order to refine and/or further specifyanalyses already produced on the basis ofgrammatical information.
These principles un-derlie other typical robust parsing architectures(Chanod 2001, Briscoe and Carroll 2002).The system consists of i.)
CHUNK-IT(Federici et al 1998a), a battery of finite stateautomata for non-recursive text segmentation(chunking), and ii.)
IDEAL (Lenci et al 2001), adependency-based analyser of the full range ofintra-sentential functional relations (e.g.
subject,object, modifier, complement, etc.).
CHUNK-ITrequires a minimum of lexical knowledge:lemma, part of speech and morpho-syntactic fea-tures.
IDEAL includes in turn two main compo-nents: (i.)
a Core Dependency Grammar ofItalian; (ii.)
a syntactic lexicon of ~26,400 sub-categorization frames for nouns, verbs and ad-jectives derived from the Italian PAROLEsyntactic lexicon (Ruimy et al 1998).
TheIDEAL Core Grammar is formed by ~100 rules(implemented as finite state automata) coveringmajor syntactic phenomena,1 and organized intostructurally-based rules and lexically-basedrules.
IDEAL adopts a slightly simplified ver-sion of the FAME annotation scheme (Lenci etal.
2000), where functional relations are head-based and hierarchically organised to make pro-vision for underspecified representations ofhighly ambiguous functional analyses.
This fea-ture allows IDEAL to tackle cases where lexicalinformation is incomplete, or where functionalrelations cannot be disambiguated conclusively(e.g.
in the case of the argument vs. adjunct dis-tinction).
A ?confidence score?
is associatedwith some of the identified dependency relationsto determine a plausibility ranking among dif-ferent possible analyses.In IDEAL, lexico-syntactic information inter-venes only after possibly underspecified de-pendency relations have been identified on thebasis of structural information only.
At this sec-ond stage, the lexicon is accessed to provide ex-tra conditions on parsing, so that the first stageparse can be non-monotonically altered in vari-ous ways (see section 3.3).
This strategy mini-mises the impact of lexical gaps (whether at thelevel of lemma or of the associated subcategori-zation frames) on the system performance (inparticular on its coverage).3 The Experiment3.1 The Test Corpus (TC)The test corpus contains a selection of sentencesextracted from the balanced partition of the Ital-ian Syntactic Semantic Treebank (ISST, Mon-temagni et al 2000), including articles from1 Adjectival and adverbial modification; negation; (non-extraposed) sentence arguments (subject, object, indirectobject); causative and modal constructions; predicativeconstructions; PP complementation and modification; em-bedded finite and non-finite clauses; control of infinitivalsubjects; relative clauses (main cases); participial construc-tions; adjectival coordination; noun-noun coordination(main cases); PP-PP coordination (main cases); cliticiza-tion.contemporary Italian newspapers and periodicalscovering a high variety of topics (politics, econ-omy, culture, science, health, sport, leisure, etc.
).TC consists of 23,919 word tokens, correspond-ing to 721 sentences (with a mean sentencelength of 33.18 words, including punctuation to-kens).
The mean number of grammatical rela-tions per sentence is 18.3.2 The Baseline Parser (BP)The baseline parser is a non-lexicalised versionof IDEAL including structurally-based rulesonly.
The mean number of grammatical relationsper sentence detected by BP in TC is 15.The output of the baseline parser is shallow indifferent respects.
First, it contains underspeci-fied analyses, resorted to whenever availablestructural information does not allow for a morespecific syntactic interpretation: e.g.
at this level,no distinction is made between arguments andmodifiers, which are all generically tagged as?complements?.
Concerning attachment, the sys-tem tries all structurally-compatible attachmenthypotheses and ranks them according to a confi-dence score.
Strong preference is given torightmost attachments: e.g.
a prepositional com-plement is attached with the highest confidencescore (50) to the closest, or rightmost, availablelexical head.
In the evaluation reported in section4, we consider top-ranked dependents only, i.e.those enforcing rightmost attachment.
Moreover,in matching the relations yielded by the parserwith the ISST relations in TC we make allowancefor one level of subsumption, i.e.
a BP relation canbe one level higher than its ISST counterpart inthe hierarchy of dependency relations.
Finally, theBP output is partial with respect to those depend-encies (e.g.
a that-clause or a direct object) thatwould be very difficult to identify with a suffi-cient degree of confidence through structurally-based rules only.3.3 The Lexically-Augmented Parser (LAP)The lexically-augmented version of IDEAL in-cludes both structurally-based and lexically-based rules (using the PAROLE lexicon).
In thislexically-augmented configuration, IDEAL firsttries to identify as many dependencies as possi-ble with structural information.
Lexically-basedrules intervene later to refine and/or completestructurally-based analyses.
Those structurally-based hypotheses that find support in the lexiconare assigned the highest score (60).
The contri-bution of lexically-based rules is non-monotonic:old relations can eventually be downgraded, asthey happen to score, in the newly ranked list ofpossible relations, lower than their lexically-based alternatives.
Furthermore, specification ofa former underspecified relation is always ac-companied by a re-ranking of the relations iden-tified for a given sentence; from this re-ranking,restructuring (e.g.
reattachment of complements)of the final output may follow.LAP output thus includes:a) fully specified dependency relations: e.g.
anunderspecified dependency relation such as?complement?
(COMP), identified by a struc-turally-based rule, is rewritten, when lexi-cally-supported, as ?indirect object?
(OBJI)and assigned a higher confidence value;b) new dependency relations: this is the case,for instance, of that-clauses, direct objectsand other relation types whose identificationis taken to be too difficult and noisy withoutsupport of lexical evidence;c) underspecified dependency relations, forthose cases that find no lexical support.The mean number of grammatical relations persentence detected by LAP in TC is 16.
In theevaluation of section 4, we consider top-rankeddependents only (confidence score  50), corre-sponding to either lexically-supported dependencyrelations or ?
in their absence ?
to rightmost at-tachments.
Again, in matching the relationsyielded by the parser with the ISST relations inTC we make allowance for one level of subsump-tion.4 Analysis of ResultsThe parsing outputs of BP and LAP were com-pared and projected against ISST annotation toassess the contribution of lexical information toparse success.
In this paper, we focus on theevaluation of how and to which extent lexico-syntactic information contributes to identifica-tion of the proper attachment of prepositionalcomplements.
For an assessment of the role andimpact of lexical information in the analysis ofdependency pairs headed by specific words, theinterested reader is referred to Bartolini et al(2002).4.1 Quantitative EvaluationTable 1 summarises the results obtained by thetwo different parsing configurations (BP andLAP) on the task of attaching prepositionalcomplements (PC).
Prepositional complementsare classified with respect to the governing head:PC_VNA refers to all prepositional comple-ments governed by V(erbal), N(ominal) orA(djectival) heads.
PC_V is the subset with aV(erbal) head and PC_N the subset with aN(ominal) head.
For each PC class, precision,recall and f score figures are given for the differ-ent parsing configurations.
Precision is definedas the ratio of correctly identified dependencyrelations over all relations found by the parser(prec = correctly identified relations / total num-ber of identified relations); recall refers to the ra-tio of correctly identified dependency relationsover all relations in ISST (recall = correctlyidentified relations / ISST relations).
Finally, theoverall performance of the parsing systems isdescribed in terms of the f score, computed asfollows: 2 prec recall / prec + recall.BP LAP ISSTPrec recall F score Prec recall f scorePC_VNA 3458 75,53 57,40 65,23 74,82 61,02 67,22PC_V 1532 75,43 45,50 56,76 74,23 49,50 61,22PC_N 1835 73,53 80,82 77,00 72,76 81,36 76,82Table 1.
Prepositional complement attachment in BP and LAPTable 2.
Lexicalised attachmentsTo focus on the role of the lexicon in either con-firming or revising structure-based dependen-cies, lexically-supported attachments are singledout for evaluation in Table 2.
Their cumulativefrequency counts are reported in the first threecolumns of Table 2 (?Lexicalised attachments?
),together with their distribution per head catego-ries.
Lexicalised attachments include both thosestructure-based attachments that happen to beconfirmed lexically (?Confirmed attachments?
),and restructured attachments, i.e.
when a prepo-sitional complement previously attached to theclosest available head to its left is eventually re-assigned as the dependent of a farther head, onthe basis of lexicon look-up (?Restructured at-tachments?).
Table 2 thus shows the impact oflexical information on the task of PP attachment.In most cases, 89% of the total of lexicalised at-tachments, LAP basically confirms dependencyrelations already assigned at the previous stage.Newly discovered attachments, which are de-tected thanks to lexicon look-up and re-ranking,amount to only 11% of all lexicalised attach-ments, less than 3% of all PP attachmentsyielded by LAP.4.3 Discussion4.3.1 Recall and precision on noun and verbheadsLet us consider the output of BP first.
The strik-ing difference in the recall of noun-headed vsverb-headed prepositional attachments (on com-parable levels of precision, rows 2 and 3 of Ta-ble 1) prompts the suggestion that the typicalcontext of use of a noun is more easily describedin terms of local, order-contingent criteria (e.g.rightmost attachment) than a verb context is.
Wecan give at least three reasons for that.
First,frame bearing nouns tend to select fewer argu-Lexicalised atts Confirmed atts Restructured attstotal OK prec Total OK prec total OK precPP_VNA 919 819 89,12 816 771 94,49 103 65 63,11PP_V 289 244 84,43 201 194 96,52 88 61 69,32PP_N 629 575 91,41 614 577 93,97 15 4 26,67ments than verbs do.
In our lexicon, 1693 verb-headed frames out of 6924 have more than onenon subject argument (24.4%), while there beingonly 1950 noun-headed frames out of 15399with more than one argument (12.6%).
In TC, of2300 head verb tokens, 328 exhibit more thanone non subject argument (14%).
Rightmost at-tachment trivially penalises such argumentchains, where some arguments happen to beovertly realised in context one or more steps re-moved from their heads.
The second reason issensitive to language variation: verb argumentstend to be dislocated more easily than noun ar-guments, as dislocation heavily depends on sen-tence-level (hence main verb-level) phenomenasuch as shift of topic or emphasis.
In Italian,topic-driven argument dislocation in preverbalposition is comparatively frequent and repre-sents a problem for the baseline parser, whichworks on a head-first assumption.
Thirdly, verbsare typically modified by a wider set of syntacticsatellites than nouns are, such as temporal andcircumstantial modifiers (Dik 1989).
For exam-ple, deverbal nouns do not inherit the possibletemporal modifiers of their verb base (I run themarathon in three hours, but *the run of themarathon in three hours).
Modifiers of this sorttend to be distributed in the sentence much morefreely than ordinary arguments.4.3.2 Impact of the lexicon on recallOf the three above mentioned factors, only thefirst one has an obvious lexical character.
Wecan provide a rough estimate of the impact oflexical information on the performance of LAP.The lexicon filter contributes a 9% increase ofrecall on verb complements (4% over 45.5%),by correctly reattaching to the verbal head thosearguments (61) that were wrongly attached totheir immediately preceding constituent by BP.This leads to an overall 49.5% recall.
All re-maining false negatives (about 48%) are i) eitherverb modifiers or ii) proper verb arguments ly-ing out of the reach of structure-based criteria,due to syntactic phenomena such as complementdislocation, complex coordination, parentheticconstructions and ellipsis.
We shall return to amore detailed analysis of false negatives in sec-tion 4.3.4.
In the case of noun complements, useof lexical information produces a negligible in-crease of recall: 0.6% ( 0.5% over 80.8%).
Thisis not surprising, as our test corpus contains veryfew cases of noun-headed argument chains,fewer than we could expect if the probability oftheir occurrence reflected the (uniform) type dis-tribution of noun frames in the lexicon.
The vastmajority of noun-headed false negatives, as weshall see in more detail in a moment, is repre-sented by modifiers.4.3.3 Impact of the lexicon on precisionReattachment is enforced by LAP when thepreposition introducing a candidate complementin context is found in the lexical frame of itshead.
Table 2 shows that ~37% of the 103 re-structured attachments proposed by the lexiconare wrong.
Even more interestingly, there is astrong asymmetry between nouns and verbs.With verb heads, precision of lexically-drivenreattachments is fairly high (~70%), nonethelesslower than precision of rightmost attachment(~75%).
In the case of noun heads, the numberof lexically reattached dependencies is insteadextremely low.
The percentage of mistakes ishigh, with precision dropping to 26.6%.The difference in the total number of restruc-tured attachment may be again due to the richercomplementation patterns exhibited by verbs inthe lexicon.
However, while in the case of verbslexical information produces a significant im-provement on restructured attachment precision,this contribution drops considerably for nouns.The main reason for this situation is that nounstend to select semantically vacuous prepositionssuch as of much more often than verbs do.
In ourlexicon, out of 4157 frames headed by a noun,4015 contain the preposition di as an argumentintroducer (96.6%).
Di is in fact an extremelypolysemous preposition, heading, among others,also possessive phrases and other kinds of modi-fiers.
This trivially increases the number of casesof attachment ambiguity and eventually the pos-sibility of getting false positives.
Conversely, asshown by the number of confirmed attachmentsin Table 2, the role of lexical information in fur-ther specifying an attachment with no restructur-ing is almost uniform across nouns and verbs.4.3.4 False negativesThe vast majority of undetected verb comple-ments (80.6%) are modifiers of various kind.The remaining set of false negatives consists of48 complements (7.7%), 30 indirect objects(4.8%) and 43 oblique arguments (6.9%).
Mostsuch complements are by-phrases in passiveconstructions which are not as such very diffi-cult to detect but just happen to fall out of thecurrent coverage of LAP.
More interestingly, 2/3of the remaining false negatives elude LAP be-cause they are overtly realised far away fromtheir verb head, often to its left.
Most of theseconstructions involve argument dislocation andellipsis.
We can thus preliminarily conclude thatargument dislocation and ellipsis accounts forabout 14% of false negatives (7% over 50%).Finally, the number of false negatives due to at-tachment ambiguity is almost negligible in thecase of verbal heads.On the other hand, the impact of undetectedmodifiers of a verbal head on attachment recallis considerable.
The most striking feature of thislarge subset is the comparative sparseness ofmodifiers introduced by di (of): 31 out of 504(6.2%).
At a closer scrutiny, the majority ofthese di-phrases are either phraseological adver-bial modifiers (di recente ?of late?, del resto ?be-sides?
etc.)
or quasi-arguments headed byparticiple forms.
Notably, 227 undetected modi-fiers (45% of the total) are selected by semanti-cally heavy and complex (possiblydiscontinuous) prepositions (davanti a ?in frontof?, in mezzo a ?amid?, verso ?towards?, intornoa ?around?, contro ?against?, da ... a ?from ...
to?etc.).
As to the remaining 241 undetected modi-fiers (48%), they are introduced by ?light?prepositions such as a ?to?, in ?in?
and da ?from?.Although this 48% contains a number of diffi-cult attachments, one can identify subsets offairly reliable modifiers by focusing on the nounhead introduced by the preposition, which usu-ally gives a strong indication of the nature of themodifier, especially in the case of measure, tem-poral and locative expressions.4.3.5 False positivesTable 2 shows a prominent asymmetry in theprecision of confirmed and restructured attach-ments.
Wrong restructured attachments aremainly due to a misleading match between thepreposition introducing a PC and that introduc-ing a slot in the lexical frame of its candidatehead (~85%).
This typically occurs with ?light?prepositions (e.g.
di, a, etc.).
Most notably, in arelevant subset of these mistakes, the verb ornoun head belongs to an idiomatic multi-wordexpression.
In the case of confirmed attach-ments, about one third of false positives (~5%)involve multi-word expressions, in particularcompound terms such as presidente del consig-lio ?prime minister?, where the rightmost ele-ment of the compound is wrongly selected as thehead of the immediately following PP.
In bothrestructured and confirmed attachments, the re-maining cases (on average ~4%) are due tocomplex syntactic structures (e.g.
appositiveconstructions, complex coordination, ellipsisetc.)
which are outside the coverage of the cur-rent grammar.ConclusionLarger lexicons are not necessarily better forparsing.
The issue of the interplay of lexicon andgrammar, although fairly well understood at thelevel of linguistic theory, still remains to be fullyinvestigated at the level of parsing.
In this paper,we tried to scratch the surface of the problemthrough a careful analysis of the performance ofan incremental dependency analyser of Italian,which can run in both a non-lexicalised and alexicalised mode.The contribution of lexical information toparse success is unevenly distributed over bothpart of speech categories and frame types.
Forreasons abundantly illustrated in section 4, theframes of noun heads are not quite as useful asthose of verb heads, especially when availableinformation is only syntactic.
Moreover, whileinformation on verb transitivity or clause em-bedding is crucial to filter out noisy attachments,information on the preposition introducing theoblique complement or the indirect object of averb can be misleading, and should thus be usedfor parsing with greater care.
The main reason isthat failure to register in the lexicon all possibleprepositions actually found in real texts maycause undesired over-filtering of genuinearguments (false negatives).
In many cases,argument prepositions are actually selected bythe lexical head of the subcategorised argument,rather than by its subcategorising verb.
Simi-larly, while information about argument option-ality vs obligatoriness is seldom confirmed inreal language use, statistical preferences on theorder of argument realisation can be very useful.Most current lexicons say very little abouttemporal and circumstantial modifiers, but muchmore can be said about them that is useful toparsing.
First, some prepositions only occur tointroduce verb modifiers.
These semanticallyheavy prepositions, often consisting of morethan one lexical item, play a fundamental role inthe organization of written texts, and certainlydeserve a special place in a parsing-orientedlexicon.
Availability of this type of lexical in-formation could pave the way to the develop-ment of specialised ?mini-parsers?
of thosesatellite modifiers whose structural position inthe sentence is subject to considerable variation.These mini-parsers could benefit from informa-tion about semantically-based classes of nouns,such as locations, measure terms, or temporalexpressions, which should also contain indica-tion of the preposition they are typically intro-duced by.
Clearly, this move requiresabandoning the prejudice that lexical informa-tion should only flow from the head to itsdependents.
Finally, availability of largerepertoires of multi word units (both complexprepositions and compound terms) appears tohave a large impact on improving parse preci-sion.There is no doubt that harvesting such a widerange of lexical information in the quantityneeded for accurate parsing will require exten-sive recourse to bootstrapping methods of lexi-cal knowledge acquisition from real texts.ReferencesBartolini R., Lenci A., Montemagni S, Pirrelli V.(2002) The Lexicon-Grammar Balance in RobustParsing of Italian, in Proceedings of the 3rd Inter-national Conference on Language Resources andEvaluation, Las Palmas, Gran Canaria.Briscoe, E.J.
(2001) From dictionary to corpus toself-organizing dictionary: learning valency asso-ciations in the face of variation and change, inProceedings of Corpus Linguistics 2001, LancasterUniversity, pp.
79-89.Briscoe T., Carroll J., (2002) Robust Accurate Statis-tical Annotation of General Text, in Proceedings ofthe 3rd International Conference on Language Re-sources and Evaluation, Las Palmas, Gran Canaria.Carroll, J., Minnen G., Briscoe E.J.
(1998) Can sub-categorisation probabilities help a statisticalparser?, in Proceedings of the 6th ACL/SIGDATWorkshop on Very Large Corpora, Montreal, Can-ada.
118-126.Chanod J.P. (2001) Robust Parsing and Beyond, inJ.C.
Junqua and G. van Noord (eds.)
Robustness inLanguage and Speech Technology, Dordrecht,Kluwer, pp.
187-204.Federici, S., Montemagni, S., Pirrelli, V. (1998a)Chunking Italian: Linguistic and Task-orientedEvaluation, in Proceedings of the LREC Workshopon ?Evaluation of Parsing Systems?, Granada,Spain.Federici, S., Montemagni, S., Pirrelli, V., Calzolari,N.
(1998b) Analogy-based Extraction of LexicalKnowledge from Corpora: the SPARKLE Experi-ence, in Proceedings of the 1st International Con-ference on Language resources and Evaluation,Granada, Spain.Grishman, R., Macleod C., Meyers A.
(1994)COMLEX Syntax: Building a Computational Lexi-con, in Proceedings of Coling 1994, Kyoto.Jensen K. (1988a) Issues in Parsing, in A.
Blaser(ed.
), Natural Language at the Computer, SpringerVerlag, Berlin, pp.
65-83.Jensen K. (1988b) Why computational grammarianscan be skeptical about existing linguistic theories,in Proceedings of COLING-88, pp.
448-449.Lenci, A., Bartolini, R., Calzolari, N., Cartier, E.(2001) Document Analysis, MLIS-5015 MUSI, De-liverable D3.1,.Lenci, A., Montemagni, S., Pirrelli, V., Soria, C.(2000) Where opposites meet.
A Syntactic Meta-scheme for Corpus Annotation and ParsingEvaluation, in Proceedings of the 2nd InternationalConference on Language Resources and Evalua-tion, Athens, Greece.Montemagni S., Barsotti F., Battista M., Calzolari N.,Corazzari O., Zampolli A., Fanciulli F., MassetaniM., Raffaelli R., Basili R., Pazienza M.T., SaracinoD., Zanzotto F., Mana N., Pianesi F., Delmonte R.(2000) The Italian Syntactic-Semantic Treebank:Architecture, Annotation, Tools and Evaluation, inProceedings of the COLING Workshop on ?Lin-guistically Interpreted Corpora (LINC-2000)?,Luxembourg, 6 August 2000, pp.
18-27.Procter, P. (1987) Longman Dictionary of Contempo-rary English, Longman, London.Ruimy, N., Corazzari, O., Gola, E., Spanu, A., Cal-zolari, N., Zampolli, A.
(1998) The European LE-PAROLE Project: The Italian Syntactic Lexicon, inProceedings of the 1st International Conference onLanguage resources and Evaluation, Granada,Spain, 1998.
