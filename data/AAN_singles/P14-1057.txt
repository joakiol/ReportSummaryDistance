Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 603?612,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsA Study of Concept-based Weighting Regularizationfor Medical Records SearchYue Wang, Xitong Liu, Hui FangDepartment of Electrical & Computer Engineering,University of Delaware, USA{wangyue,xtliu,hfang}@udel.eduAbstractAn important search task in the biomedicaldomain is to find medical records of pa-tients who are qualified for a clinical trial.One commonly used approach is to applyNLP tools to map terms from queries anddocuments to concepts and then computethe relevance scores based on the concept-based representation.
However, the map-ping results are not perfect, and none ofprevious work studied how to deal withthem in the retrieval process.
In this pa-per, we focus on addressing the limitationscaused by the imperfect mapping resultsand study how to further improve the re-trieval performance of the concept-basedranking methods.
In particular, we ap-ply axiomatic approaches and propose twoweighting regularization methods that ad-just the weighting based on the relationsamong the concepts.
Experimental resultsshow that the proposed methods are effec-tive to improve the retrieval performance,and their performances are comparable toother top-performing systems in the TRECMedical Records Track.1 IntroductionWith the increasing use of electronic healthrecords, it becomes urgent to leverage this richinformation resource about patients?
health condi-tions to transform research in health and medicine.As an example, when developing a cohort fora clinical trial, researchers need to identify pa-tients matching a set of clinical criteria based ontheir medical records during their hospital visits(Safran et al, 2007; Friedman et al, 2010).
Thisselection process is clearly a domain-specific re-trieval problem, which searches for relevant medi-cal records that contain useful information abouttheir corresponding patients?
qualification to thecriteria specified in a query, e.g., ?female patientwith breast cancer with mastectomies during ad-mission?.Intuitively, to better solve this domain-specificretrieval problem, we need to understand the re-quirements specified in a query and identify thedocuments satisfying these requirements based ontheir semantic meanings.
In the past decades,significant efforts have been put on constructingbiomedical knowledge bases (Aronson and Lang,2010; Lipscomb, 2000; Corporation, 1999) anddeveloping natural language processing (NLP)tools, such as MetaMap, to utilize the informa-tion from the knowledge bases (Aronson, 2001;McInnes et al, 2009).
These efforts make it pos-sible to map free text to concepts and use theseconcepts to represent queries and documents.Indeed, concept-based representation is oneof the commonly used approaches that leverageknowledge bases to improve the retrieval perfor-mance (Limsopatham et al, 2013d; Limsopathamet al, 2013b).
The basic idea is to representboth queries and documents as ?bags of concepts?,where the concepts are identified based on the in-formation from the knowledge bases.
This methodhas been shown to be more effective than tra-ditional term-based representation in the medicalrecord retrieval because of its ability to handle theambiguity in the medical terminology.
However,this method also suffers the limitation that its ef-fectiveness depends on the accuracy of the conceptmapping results.
As a result, directly applyingexisting weighting strategies might lead to non-optimal retrieval performance.In this paper, to address the limitation caused bythe inaccurate concept mapping results, we pro-pose to regularize the weighting strategies in theconcept-based representation methods.
Specifi-cally, by applying the axiomatic approaches (Fangand Zhai, 2005), we analyze the retrieval func-603tions with concept-based representation and findthat they may violate some reasonable retrievalconstraints.
We then propose two concept-basedweighting regularization methods so that the reg-ularized retrieval functions would satisfy the re-trieval constraints and achieve better retrieval per-formance.
Experimental results over two TRECcollections show that both proposed concept-based weighting regularization methods can im-prove the retrieval performance, and their perfor-mance is comparable with the best systems ofthe TREC Medical Records tracks (Voorhees andTong, 2011; Voorhees and Hersh, 2012).Many NLP techniques have been developed tounderstand the semantic meaning of textual in-formation, and are often applied to improve thesearch accuracy.
However, due to the inherent am-biguity of natural languages, the results of NLPtools are not perfect.
One of our contributions isto present a general methodology that can be usedto adjust existing IR techniques based on the inac-curate NLP results.2 Related WorkThe Medical Records track of the Text REtrievalConference (TREC) provides a common platformto study the medical records retrieval problemand evaluate the proposed methods (Voorhees andTong, 2011; Voorhees and Hersh, 2012).Concept-based representation has been studiedfor the medical record retrieval problem (Lim-sopatham et al, 2013d; Limsopatham et al,2013b; Limsopatham et al, 2013a; Qi and La-querre, 2012; Koopman et al, 2011; Koopman etal., 2012).
For example, Qi and Laquerre usedMetaMap to generate the concept-based repre-sentation and then apply a vector space retrievalmodel for ranking, and their results are one ofthe top ranked runs in the TREC 2012 Medi-cal Records track (Qi and Laquerre, 2012).
Tofurther improve the performance, Limsopathamet al proposed a task-specific representation,i.e., using only four types of concepts (symp-tom, diagnostic test, diagnosis and treatment) inthe concept-based representation and a query ex-pansion method based on the relationships amongthe medical concepts (Limsopatham et al, 2013d;Limsopatham et al, 2013a).
Moreover, they alsoproposed a learning approach to combine bothterm-based and concept-based representation tofurther improve the performance (Limsopatham etFigure 1: Example of MetaMap result for a query.al., 2013b).Our work is also related to domain-specificIR (Yan et al, 2011; Lin and Demner-Fushman,2006; Zhou et al, 2007).
For example, Yan etal.
proposed a granularity-based document rank-ing model that utilizes ontologies to identify doc-ument concepts.
However, none of the previouswork has studied how to regularize the weight ofconcepts based on their relations.It is well known that the effectiveness of a re-trieval function is closely related to the weight-ing strategies (Fang and Zhai, 2005; Singhal etal., 1996).
Various term weighting strategies havebeen proposed and studied for the term-basedrepresentation (Amati and Van Rijsbergen, 2002;Singhal et al, 1996; Robertson et al, 1996).However, existing studies on concept-based rep-resentation still used weighting strategies devel-oped for term-based representation such as vectorspace models (Qi and Laquerre, 2012) and diver-gence from randomness (DFR) (Limsopatham etal., 2013a) and did not take the inaccurate con-cept mapping results into consideration.
Com-pared with previous work, we focus on address-ing the limitation caused by the inaccurate con-cept mapping.
Note that our efforts are orthogonalto existing work, and it is expected to bring addi-tional improvement to the retrieval performance.3 Concept-based Representation forMedical Records Retrieval3.1 Problem FormulationWe follow the problem setup used in the TRECmedical record track (Voorhees and Tong, 2011;Voorhees and Hersh, 2012).
The task is to retrieverelevant patient visits with respect to a query.Since each visit can be associated with multiplemedical records, the relevance of a visit is relatedto the relevance of individual associated medicalrecords.
Existing studies computed the relevance604scores at either visit-level, where all the medicalrecords of a visit are merged into a visit document(Demner-Fushman et al, 2012; Limsopatham etal., 2013c), or record-level, where we can firstcompute the relevance score of individual recordsand then aggregate their scores as the relevancescore of a visit (Limsopatham et al, 2013c; Zhuand Carterette, 2012; Limsopatham et al, 2013d).In this paper, we focus on the visit-level relevancebecause of its simplicity.
In particular, given a pa-tient?s visit, all the medical records generated fromthis visit are merged as a document.
Note that ourproposed concept-weighting strategies can also beeasily applied to record-level relevance modeling.Since the goal is to retrieve medical records ofpatients that satisfying requirements specified in aquery, the relevance of medical records should bemodeled based on how well they match all the re-quirements (i.e., aspects) specified in the queries.3.2 Background: UMLS and MetaMapUnified Medical Language System (UMLS) is ametathesaurus containing information from morethan 100 controlled medical terminologies such asthe Systematized Nomenclature of Medicine Clin-ical Terms (SNOMED-CT) and Medical SubjectHeadings (MeSH).
Specifically, it contains the in-formation about over 2.8 million biomedical con-cepts.
Each concept is labeled with a ConceptUnique Identifier (CUI) and has a preferred nameand a semantic type.Moreover, NLP tools for utilizing the informa-tion from UMLS have been developed.
In partic-ular, MetaMap (Aronson, 2001) can take a textstring as the input, segment it into phrases, andthen map each phrase to multiple UMLS CUIswith confidence scores.
The confidence score isan indicator of the quality of the phrase-to-conceptmapping by MetaMap.
It is computed by four met-rics: centrality, variation, coverage and cohesive-ness (Aronson, 2001).
These four measures try toevaluate the mapping from different angles, suchas the involvement of the central part, the distanceof the concept to the original phrase, and how wellthe concept matches the phrase.
The maximumconfidence in MetaMap is 1000.Figure 1 shows the MetaMap results for an ex-ample query ?children with dental caries?.
Twoquery aspects, i.e., ?children?
and ?dental caries?,are identified.
Each of them is mapped to multipleconcepts, and each concept is associated with theconfidence score as well as more detailed informa-tion about this concept.3.3 Concept-based RepresentationTraditional retrieval models are based on ?bag ofterms?
representation.
One limitation of this rep-resentation is that relevance scores are computedbased on the matching of terms rather than themeanings.
As a result, the system may fail to re-trieve the relevant documents that do not containany query terms.To overcome this limitation, concept-based rep-resentation has been proposed to bridge the vo-cabulary gap between documents and queries(Qi and Laquerre, 2012; Limsopatham et al,2013b; Koopman et al, 2012).
In particular,MetaMap is used to map terms from queriesand documents (e.g., medical records) to thesemantic concepts from biomedical knowledgebases such as UMLS.
Within the concept-basedrepresentation, the query can then be repre-sented as a bag of all the generated CUIsin the MetaMap results.
For example, thequery from Figure 1 can be represented as{C0008059, C0680063, C0011334, C0333519,C0226984}.
Documents can be represented in asimilar way.After converting both queries and documentsto concept-based representations using MetaMap,previous work applied existing retrieval functionssuch as vector space models (Singhal et al, 1996)to rank the documents.
Note that when referringto existing retrieval functions in the paper, theyinclude traditional keyword matching based func-tions such as pivoted normalization (Singhal etal., 1996), Okapi (Robertson et al, 1996), Dirich-let prior (Zhai and Lafferty, 2001) and basic ax-iomatic functions (Fang and Zhai, 2005).4 Weighting Strategies forConcept-based Representation4.1 MotivationAlthough existing retrieval functions can be di-rectly applied to concept-based representation,they may lead to non-optimal performance.
Thisis mainly caused by the fact that MetaMap maygenerate more than one mapped concepts for anaspect, i.e., a semantic unit in the text.Ideally, an aspect will be mapped to only oneconcept, and different concepts would representdifferent semantic meanings.
Under such a situ-605Figure 2: Exploratory data analysis (From left to right are choosing minimum, average and maximumIDF concepts as the representing concepts, respectively.
The removed concepts are highlighted in thefigures.
).ation, traditional retrieval functions would likelywork well and generate satisfying retrieval per-formance since the relations among concepts areindependent which is consistent with the assump-tions made in traditional IR (Manning et al, 2008).However, the mapping results generated byMetaMap are not perfect.
Although MetaMap isable to rank all the candidate concepts with theconfidence score and pick the most likely one,the accuracy is not very high.
In particular, ourpreliminary results show that turning on the dis-ambiguation functionality provided by MetaMap(i.e., returning only the most likely concept foreach query) could lead to worse retrieval per-formance than using all the candidate mappings.Thus, we use the one-to-many mapping resultsgenerated by MetaMap, in which each aspect canbe mapped to multiple concepts.Unfortunately, such one-to-many concept map-pings could hinder the retrieval performance in thefollowing two ways.?
The multiple concepts generated from thesame aspect are related, which is inconsis-tent with the independence assumption madein the existing retrieval functions (Manninget al, 2008).
For example, as shown in Fig-ure 1, ?dental caries?
is mapped to three con-cepts.
It is clear that the concepts are related,but existing retrieval functions are unable tocapture their relations and would compute theweight of each concept independently.?
The one-to-many mapping results generatedby MetaMap could arbitrarily inflate theweights of some query aspects.
For exam-ple, as shown in Figure 1, query aspect ?chil-dren?
is mapped to 2 concepts while ?den-tal caries?
is mapped to 3 concepts.
In theexisting retrieval functions, term occurrencesare important relevance signals.
However,when converting the text to concepts repre-sentation using MetaMap, the occurrences ofthe concepts are determined by not only theoriginal term occurrences, a good indicatorof relevance, but also the number of mappedconcepts, which is determined by MetaMapand has nothing to do with the relevance sta-tus.
As a result, the occurrences of conceptsmight not be a very accurate indicator of im-portance of the corresponding query aspect.To address the limitations caused by the inac-curate mapping results, we propose to apply ax-iomatic approaches (Fang and Zhai, 2005) to reg-ularize the weighting strategies for concept-basedrepresentation methods.
In particular, we firstformalize retrieval constraints that any reasonableconcept-based representation methods should sat-isfy and then discuss how to regularize the existingweighting strategies to satisfy the constraints andimprove the retrieval performance.We first explain the notations used in this sec-tion.
Q and D denote a query and a documentwith the concept-based representation.
S(Q,D)is the relevance score of D with respect to Q. eidenotes a concept, and A(e) denotes the queryaspect associated with e, i.e., a set of conceptsthat are mapped to the same phrases as e by us-ing MetaMap.
i(e) is the normalized confidencescore of the mapping for concept e generated byMetaMap.
c(e,D) denotes the occurrences ofconcept e in document D, df(e) denotes the num-ber of documents containing e. |D| is the docu-ment length of D. Impc(e) is the importance ofthe concept such as the concept IDF value, andImpA(A) is the importance of the aspect.6064.2 Unified concept weighting regularizationWe now discuss how to address the first challenge,i.e,.
how to regularize the weighting strategy sothat we can take into consideration the fact thatconcepts associated with the same query aspect arenot independent.
We call a concept is a variant ofanother one if both of them are associated with thesame aspect.Intuitively, given a query with two aspects, adocument covering both aspects should be rankedhigher than those covering only one aspect.
Wecan formalize the intuition in the concept-basedrepresentation as the following constraint.Unified Constraint: Let query be Q ={e1, e2, e3}, and we know that e2is a variant ofe3.
Assume we have two documents D1and D2with the same document length, i.e., |D1| = |D2|.If we know that c(e1, D1) = c(e3, D2) > 0,c(e1, D2) = c(e3, D1) = 0 and c(e2, D1) =c(e2, D2) > 0, then S(Q,D1) > S(Q,D2).It is clear that existing retrieval functions wouldviolate this constraint since they ignore the rela-tions among concepts.One simple strategy to fix this problem is tomerge all the concept variants as a single conceptand select one representative concept to replace alloccurrences of other variants in both queries anddocuments.
By merging the concepts together, weare aiming to purify the concepts and make thesimilar concepts centralized so that the assumptionthat all the concepts are independent would hold.Formally, the adjusted occurrences of a concepte in a document D is shown as follows:cmod(e,D)={?e?
?EC(e)c(e?, D) e=Rep(EC(e))0 e 6=Rep(EC(e))(1)where c(e,D) is the original occurrence of con-cept e in document D, EC(e) denotes a set ofall the variants of e including itself (i.e., all theconcepts with the same preferred name as e), andRep(EC(e)) denotes the representative conceptfrom EC(e).It is trivial to prove that, with such changes, ex-isting retrieval functions would satisfy the aboveconstraint since the constraint implies TFC2 con-straint defined in the previous study (Fang et al,2004).Now the remaining question is how to select therepresentative concept from all the variants.
Thereare three options: select the concept with the maxi-mum IDF, average IDF, or minimum IDF.
We con-duct exploratory data analysis on these three op-tions.
In particular, for each option, we generatea plot indicating the correlation between the IDFvalue of a concept and the relevance probability ofthe concept (i.e., the probability that a documentcontaining the concept is relevant).
Note that bothoriginal and replaced IDF values are shown in theplot for each option.
Figure 2 shows the results.
Itis clear that the right plot (i.e., selecting the con-cept with the maximum IDF as the representativeconcept) is the best choice since the changes makethe points less scattered.
In fact, this can also beconfirmed by experimental results as reported inTable 5.
Thus, we use the concept with the max-imum IDF value as the representative concept ofall the variants.4.3 Balanced concept weightingregularizationWe now discuss how to address the second chal-lenge, i.e., how to regularize the weighting strat-egy to deal with the arbitrarily inflated statisticscaused by the one-to-many mappings.The arbitrary inflation could impact the impor-tance of the query aspects.
For example, as shownin Figure 1, one aspect is mapped to two con-cepts while the other is mapped to three.
More-over, it could also impact the accuracy of the con-cept IDF values.
Consider ?colonoscopies?
and?adult?, it is clear that the first term is more im-portant than the second one, which is consistentwith their term IDF values, i.e., 7.52 and 2.92, re-spectively.
However, with the concept-based rep-resentation, the IDF value of the concept ?colono-scopies?
(C0009378) is 2.72, which is even smallerthan that of concept ?adult?
(C1706450), i.e., 2.92.To fix the negative impact on query aspects, wecould leverage the findings in the previous study(Zheng and Fang, 2010) and regularize the weight-ing strategy based on the length of query aspectsto favor documents covering more query aspects.Since each concept mapping is associated with aconfidence score, we can incorporate them into theregularization function as follows:f(e,Q) = (1?
?)
+ ?
?(?e??Qi(e?)?e???A(e)i(e??
)), (2)where i(e) is the normalized confidence score ofconcept e generated by MetaMap, and ?
is a pa-rameter between 0 and 1 to control the effect of theregularization.
When ?
is set to 0, there is no reg-ularization.
This regularization function aims to607penalize the weight of concept e based on its vari-ants as well as the concepts from other aspects.
Inparticular, a concept would receive more penalty(i.e., its weight will be decreased more) when ithas more variants and the mappings of these vari-ants are more accurate.To fix the negative impact on the concept IDFvalues, we propose to regularize the weightingbased on the importance of the query aspect.
Thisregularization can be formalized as the followingconstraint.Balanced Constraint: Let Q be a querywith two concepts and the concepts are associ-ated with different aspects, i.e., Q = {e1, e2},and A(e1) 6= A(e2).
Assume D1and D2are two documents with the same length, i.e.,|D1| = |D2|, and they cover different conceptswith the same occurrences, i.e., c(e1, D1) =c(e2, D2) > 0 and c(e2, D1) = c(e1, D2) =0.
If we know Impc(e1) = Impc(e2) andImpA(A(e1)) < ImpA(A(e2)), then we haveS(Q,D1) < S(Q,D2).This constraint requires that the relevance scoreof a document should be affected by not only theimportance of the concepts but also the importanceof the associated query aspect.
In a way, the con-straint aims to counteract the arbitrary statistics in-flation caused by MetaMap results and balance theweight among concepts based on the importanceof the associated query aspects.
And it is not dif-ficult to show that existing retrieval functions vio-late this constraint.Now the question is how to revise the retrievalfunctions to make them satisfy this constraint.
Wepropose to incorporate the importance of query as-pect into the previous regularization function inEquation (2) as follows:f(e,Q) = (1??)+?
?(?e??Qi(e?)?e???A(e)i(e??))?ImpA(A(e)).
(3)Note that ImpA(A(e)) is the importance of aquery aspect and can be estimated based on theterms from the query aspect.
In this paper, weuse the maximum term IDF value from the aspectto estimate the importance, which performs betterthan using minimum and average IDF values asshown in the experiments (i.e., Table 6).
We planto study other options in the future work.4.4 DiscussionsBoth proposed regularization methods can becombined with any existing retrieval functions.
Inthis paper, we focus on one of the state of theart weighting strategies, i.e., F2-EXP function de-rived from axiomatic retrieval model (Fang andZhai, 2005), and explain how to incorporate theregularization methods into the function.The original F2-EXP retrieval function is shownas follows:S(Q,D) =?e?Q?Dc(e,Q) ?
(Ndf(e))0.35?c(e,D)c(e,D) + b +b?|D|avdl(4)where b is a parameter control the weight of thedocument length normalization.With the unified concept weighting regulariza-tion, the revised function based on F2-EXP func-tion, i.e., Unified, is shown as follows:S(Q,D)=?e?Q?Dcmod(e,Q)?
(Ndf(t))0.35?cmod(e,D)cmod(e,D)+b+b?|D|avdl(5)where cmod(e,D) and cmod(e,Q) denote themodified occurrences as shown in Equation (1).
Itcan be shown that this function satisfies the unifiedconstraint but violates the balanced constraint.Following the similar strategy used in the previ-ous study (Zheng and Fang, 2010), we can furtherincorporate the regularization function proposedin Equation (3) to the above function to make itsatisfy the balanced constraint as follows:S(Q,D) =?e?Q?Dcmod(e,Q)?
(Ndf(t))0.35?f(e,Q) (6)?cmod(e,D)cmod(e,D)+b+b?|D|avdlwhere f(e,Q) is the newly proposed regular-ization function as shown in Equation (3).
Thismethod is denoted as Balanced, and can be shownthat it satisfies both constraints.Table 1: Statistics of collections.# of unique tokens AvgDL AvgQL11 AvgQL12Term 263,356 2,659 10.23 8.82Concept 58,192 2,673 8.79 7.815 Experiments5.1 Experiment SetupWe conduct experiments using two data sets fromthe TREC Medical Records track 2011 and 2012.608Table 2: Description of MethodsName Representation Ranking strategiesTerm-BL Term F2-EXP (i.e., Equation (4))Concept-BL Concept (i.e., Section 3.3) F2-EXP (i.e., Equation (4))TSConcept-BL Task specific concept ((Limsopatham et al, 2013d)) F2-EXP (i.e., Equation (4))Unified Concept (i.e., Section 4.2) F2-EXP + Unified (i.e., Equation (5))Balanced Concept (i.e., Section 4.3) F2-EXP + Balanced (i.e., Equation (6))Table 3: Performance under optimized parameter settingsMed11 Med12MAP bpref infNDCG infAPTerm-BL 0.3474 0.4727 0.4695 0.2106Concept-BL 0.3967 0.5476 0.5243 0.2497TSConcept-BL 0.3964 0.5329 0.5283 0.2694Unified 0.4235T0.5443T0.5416T0.2586TBalanced 0.4561T ,C ,TS0.5697T ,C ,TS0.5767T ,C ,TS0.2859T ,C ,TSThe data sets are denoted as Med11 and Med12.Both data sets used the same document collectionwith 100,866 medical records, each of which is as-sociated with a unique patient visit to the hospi-tal or emergency department.
Since the task is toretrieve relevant visits, we merged all the recordsfrom a visit to form a single document for the visit,which leads to 17,198 documents in the collection.There are 34 queries in Med11 and 47 in Med12.These queries were developed by domain expertsbased on the ?inclusion criteria?
of a clinical study(Voorhees and Tong, 2011; Voorhees and Hersh,2012).After applying MetaMap to both documents andqueries, we can construct a concept-based collec-tion.
Since documents are often much longer, wecan first segment them into sentences, get the map-ping results for each sentence, and then mergethem together to generate the concept-based rep-resentation for the documents.Table 1 compares the statistics of the term-based and the concept-based collections, includingthe number of unique tokens in the collection (i.e.,the number of terms for term-based representa-tion and the number of concepts for concept-basedrepresentation), the average number of tokens inthe documents (AvgDL) and the average numberof tokens in the queries for these two collections(AvgQL11 and AvgQL12).
It is interesting to seethat the number of unique tokens is much smallerwhen using the concept-based indexing.
This isexpected since terms are semantically related anda group of related terms would be mapped to onesemantic concept.
Moreover, we observe that thedocument length and query length are similar forboth collections.
This is caused by the fact thatconcepts are related and the MetaMap would mapan aspect to multiple related concepts.Table 2 summarizes the methods that we com-pare in the experiments.
Following the evalua-tion methodology used in the medical record track,we use MAP@1000 as the primary measure forMed11 and also report bpref.
For Med12, we takeinfNDCG@100 as the primary measure and alsoreport infAP@100.
Different measures were cho-sen for these two sets mainly because differentpooling strategies were used to create the judg-ment pools (Voorhees and Hersh, 2012).5.2 Performance ComparisonTable 3 shows the performance under optimizedparameter settings for all the methods over bothdata sets.
The performance is optimized in termsof MAP in Med11, and infNDCG in Med12, re-spectively.
?
and b are tuned from 0 to 1 with thestep 0.1.
Note thatT,CandTSindicate improve-ment over Term-BL, Concept-BL and TSConcept-BL is statistically significant at 0.05 level based onWilcoxon signed-rank test, respectively.Results show that Balanced method can signifi-cantly improve the retrieval performance over bothcollections.
Unified method outperforms the base-line methods in terms of the primary measure onboth collections, although it fails to improve theinfAP on Med12 for one baseline method.
It is notsurprising to see that Balanced method is more ef-fective than Unified since the former satisfies bothof the proposed retrieval constraints while the lat-609Table 4: Testing PerformanceTrained on Med12 Med11Tested on Med11 Med12Measures MAP bpref infNDCG infAPTerm-BL 0.3451 0.4682 0.4640 0.2040Concept-BL 0.3895 0.5394 0.5194 0.2441TSConcept-BL 0.3901 0.5286 0.5208 0.2662Unified 0.4176T,C0.5391T0.5346T0.2514TBalanced 0.4497T ,C ,TS0.5627T ,C ,TS0.5736T ,C ,TS0.2811T ,C ,TSter satisfies only one.
Finally, we noticed thatthe performance difference between TSConcept-BL and Concept-BL is not as significant as theones reported in the previous study (Limsopathamet al, 2013d), which is probably caused by thedifference of problem set up (i.e., record-level vs.visit-level as discussed in Section 3.1).We also conduct experiments to train parame-ters on one collection and compare the testing per-formance on the other collection.
The results aresummarized in Table 4.
Clearly, Balanced is stillthe most effective regularization method.
The test-ing performance is very close to the optimal per-formance, which indicates that the proposed meth-ods are robust with respect to the parameter set-ting.Moreover, we would like to point out that thetesting performance of Balanced is comparableto the top ranked runs from the TREC Medicalrecords track.
For example, the performance ofthe best automatic system in Med11 (e.g., Cen-gageM11R3) is 0.552 in terms of bpref, whilethe performance of the best automatic systemin Med12 (e.g., udelSUM) is 0.578 in terms ofinfNDCG.
Note that the top system of Med12 usedmultiple external resources such as Wikipedia andWeb, while we did not use such resources.
More-over, our performance might be further improvedif we apply the result filtering methods used bymany TREC participants (Leveling et al, 2012).Table 5: Selecting representative conceptsMAP bprefUnified (i.e., Unified-max) 0.4235 0.5443Unified-min 0.3894 0.5202Unified-avg 0.4164 0.53035.3 More AnalysisIn the Unified method, we chose the concept withthe maximum IDF as the representative conceptTable 6: Estimating query aspect importanceMAP bprefBalanced (i.e., Balanced-max) 0.4561 0.5697Balanced-min 0.4216 0.5484Balanced-avg 0.4397 0.5581Table 7: Regularization components in BalancedMAP bprefBalanced 0.4561 0.5697Confidence only 0.4294 0.5507Importance only 0.4373 0.5598among all the variants.
We now conduct experi-ments on Med11 to compare its performance withthose of using average IDF and minimum IDFones as the representative concept.
The results areshown in Table 5.
It is clear that using maximumIDF is the best choice, which is consistent withour observation from the data exploratory analysisshown in Figure 2.In the Balanced method, we used the maximumIDF value to estimate the query importance.
Wealso conduct experiments to compare its perfor-mance with those using the minimum and aver-age IDF values.
Table 6 summarizes the results,and shows that using the maximum IDF value per-forms better than the other choices.As shown in Equation (3), the Balanced methodregularizes the weights through two components:(1) normalized confidence score of each aspect,i.e.,?e??Qi(e?)?e???A(e)i(e??
); and (2) the importance of thequery aspect, i.e., ImpA(A(e)).
To examine theeffectiveness of each component, we conduct ex-periments using the modified Balanced methodwith only one of the components.
The results areshown in Table 7.
It is clear that both componentsare essential to improve the retrieval performance.Finally, we report the performance improve-ment of the proposed methods over the Concept-BL for each query in Figure 3.
Clearly, both of the610-0.2-0.100.10.20.30.40.50.60.70.8101 106 111 116 121 126 131 136 141 146 151 156 161 165 171 176 181 185PerformanceDifferenceQuery IDImprovement(Unified)Improvement(Balanced)Figure 3: Improvement of proposed methods (Compared with the Concept-BL method).proposed methods can improve the effectivenessof most queries, and the Balanced method is morerobust than the Unified method.6 Conclusions and Future WorkMedical record retrieval is an important domain-specific IR problem.
Concept-based representa-tion is an effective approach to dealing with am-biguity terminology in medical domain.
How-ever, the results of the NLP tools used to gen-erate the concept-based representation are oftennot perfect.
In this paper, we present a generalmethodology that can use axiomatic approachesas guidance to regularize the concept weightingstrategies to address the limitations caused by theinaccurate concept mapping and improve the re-trieval performance.
In particular, we proposedtwo weighting regularization methods based onthe relations among concepts.
Experimental re-sults show that the proposed methods can signif-icantly outperform existing retrieval functions.There are many interesting directions for our fu-ture work.
First, we plan to study how to automat-ically predict whether to use concept-based index-ing based on the quality of MetaMap results, andexplore whether the proposed methods are appli-cable for other entity linking methods.
Second,we will study how to leverage other informationfrom knowledge bases to further improve the per-formance.
Third, more experiments could be con-ducted to examine the effectiveness of the pro-posed methods when using other ranking strate-gies.
Finally, it would be interesting to study howto follow the proposed methodology to study otherdomain-specific IR problems.ReferencesGianni Amati and Cornelis Joost Van Rijsbergen.2002.
Probabilistic models of information retrievalbased on measuring the divergence from random-ness.
ACM TOIS.Alan R. Aronson and Franc?ois-Michel Lang.
2010.
Anoverview of metamap: historical perspective and re-cent advances.
JAMIA, 17(3):229?236.Alan R. Aronson.
2001.
Effective mapping of biomed-ical text to the UMLS Metathesaurus: the MetaMapprogram.
In Proceedings of AMIA Symposium.Practice Management Information Corporation.
1999.ICD-9-CM: International Classification of Dis-eases, 9th Revision, Clinical Modification, 5th Edi-tion.
Practice Management Information Corpora-tion.Dina Demner-Fushman, Swapna Abhyankar, Anto-nio Jimeno-Yepes, Russell Loane, Francois Lang,James G. Mork, Nicholas Ide, and Alan R. Aron-son.
2012.
NLM at TREC 2012 Medical RecordsTrack.
In Proceedings of TREC 2012.Hui Fang and ChengXiang Zhai.
2005.
An explorationof axiomatic approaches to information retrieval.
InProceedings of SIGIR?05.Hui Fang, Tao Tao, and ChengXiang Zhai.
2004.
Aformal study of information retrieval heuristics.
InProceedings of SIGIR?04.Charles P. Friedman, Adam K. Wong, and David Blu-menthal.
2010.
Achieving a nationwide learninghealth system.
Science Translational Medicine.Beval Koopman, Michael Lawley, and Peter Bruza.2011.
AEHRC & QUT at TREC 2011 MedicalTrack : a concept-based information retrieval ap-proach.
In Proceedings of TREC?11.Bevan Koopman, Guido Zuccon, Anthony Nguyen,Deanne Vickers, Luke Butt, and Peter D. Bruza.6112012.
Exploiting SNOMED CT Concepts & Re-lationships for Clinical Information Retrieval: Aus-tralian e-Health Research Centre and QueenslandUniversity of Technology at the TREC 2012 Med-ical Track.
In Proceedings of TREC?12.Johannes Leveling, Lorraine Goeuriot, Liadh Kelly,and Gareth J. F. Jones.
2012.
DCU@TRECMed2012: Using adhoc Baselines for Domain-SpecificRetrieval.
In Proceedings of TREC 2012.Nut Limsopatham, Craig Macdonald, and Iadh Ou-nis.
2013a.
Inferring conceptual relationships toimprove medical records search.
In Proceedings ofOAIR?13.Nut Limsopatham, Craig Macdonald, and Iadh Ou-nis.
2013b.
Learning to combine representationsfor medical records search.
In Proceedings of SI-GIR?13.Nut Limsopatham, Craig Macdonald, and Iadh Ounis.2013c.
Learning to selectively rank patients?
medi-cal history.
In Proceedings of CIKM?13.Nut Limsopatham, Craig Macdonald, and Iadh Ounis.2013d.
A task-specific query and document repre-sentation for medical records search.
In Proceedingsof ECIR?13.Jimmy Lin and Dina Demner-Fushman.
2006.
Therole of knowledge in conceptual retrieval: a studyin the domain of clinical medicine.
In Proceedingsof the 29th annual international ACM SIGIR confer-ence on Research and development in informationretrieval, SIGIR ?06, pages 99?106, New York, NY,USA.
ACM.Carolyn E Lipscomb.
2000.
Medical Subject Headings(MeSH).
The Medical Library Association.Christopher D. Manning, P. Raghavan, and H. Schutze.2008.
Introduction to Information Retrieval.
Cam-bridge University Press.Bridget T. McInnes, Ted Pedersen, and Serguei V. S.Pakhomov.
2009.
UMLS-Interface and UMLS-Similarity : Open Source Software for MeasuringPaths and Semantic Similarity.
In Proceedings ofAMIA Symposium.Yanjun Qi and Pierre-Francois Laquerre.
2012.
Re-trieving Medical Records: NEC Labs America atTREC 2012 Medical Record Track.
In Proceedingsof TREC 2012.S.E.
Robertson, S. Walker, S. Jones, M.M.
Hancock-Beaulieu, and M. Gatford.
1996.
Okapi at TREC-3.pages 109?126.Charles Safran, Meryl Bloomrosen, W. EdwardHammond, Steven Labkoff, Suzanne Markel-Fox,Paul C. Tang, and Don E. Detmer.
2007.
White pa-per: Toward a national framework for the secondaryuse of health data: An american medical informaticsassociation white paper.
JAMIA, 14(1):1?9.Amit Singhal, Chris Buckley, and Mandar Mitra.
1996.Pivoted document length normalization.
In Pro-ceedings of SIGIR?96.Ellen M. Voorhees and William Hersh.
2012.Overview of the TREC 2012 Medical RecordsTrack.
In Proceedings of TREC 2012.Ellen M. Voorhees and Richard M. Tong.
2011.Overview of the TREC 2011 Medical RecordsTrack.
In Proceedings of TREC 2011.Xin Yan, Raymond Y.K.
Lau, Dawei Song, Xue Li,and Jian Ma.
2011.
Toward a semantic granular-ity model for domain-specific information retrieval.ACM TOIS.Chengxiang Zhai and John Lafferty.
2001.
A studyof smoothing methods for language models appliedto Ad Hoc information retrieval.
In Proceedings ofSIGIR?01.Wei Zheng and Hui Fang.
2010.
Query aspectbased term weighting regularization in informationretrieval.
In Proceedings of ECIR?10.Wei Zhou, Clement Yu, Neil Smalheiser, Vetle Torvik,and Jie Hong.
2007.
Knowledge-intensive concep-tual retrieval and passage extraction of biomedicalliterature.
In Proceedings of SIGIR?07.Dongqing Zhu and Ben Carterette.
2012.
Combiningmulti-level evidence for medical record retrieval.
InProceedings of SHB?12.612
