Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1421?1431,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsThe Teams Corpus and Entrainment in Multi-Party Spoken DialoguesDiane LitmanUniversity of PittsburghPittsburgh, PASusannah PaletzUniversity of MarylandCollege Park, MDZahra Rahimi and Stefani Allegretti and Caitlin RiceUniversity of PittsburghPittsburgh, PAAbstractWhen interacting individuals entrain, they be-gin to speak more like each other.
To sup-port research on entrainment in cooperativemulti-party dialogues, we have created a cor-pus where teams of three or four speakers playtwo rounds of a cooperative board game.
Wedescribe the experimental design and techni-cal infrastructure used to collect our corpus,which consists of audio, video, transcriptions,and questionnaire data for 63 teams (47 hoursof audio).
We illustrate the use of our corpusas a novel resource for studying team entrain-ment by 1) developing and evaluating team-level acoustic-prosodic entrainment measuresthat extend existing dyad measures, and 2)investigating relationships between team en-trainment and participation dominance.1 IntroductionLinguistic entrainment1 refers to the convergence of(para)linguistic features across speakers during con-versation (Brennan and Clark, 1996; Porzel et al,2006).
Research has found that speakers entrain toboth human and computer conversational partners,with the amount of entrainment often positively re-lated to conversational and task success.
However,most prior work has focused on the study of entrain-ment during two-party dialogues, rather than duringthe multi-party conversations typical of teams.To support the study of entrainment during multi-party cooperative dialogue, we have created a large-scale corpus (over 47 hours of recordings) of teams1Other terms in the literature include accommodation, adap-tation, alignment, convergence, coordination and priming.of three or four speakers playing a cooperative boardgame requiring conversation.
The corpus consists ofaudio, video, transcriptions, and questionnaire datafor 63 teams.
The goal of the corpus is to providea freely-available data resource for the developmentand evaluation of multi-party entrainment measuresthat can be 1) computed using language technolo-gies, 2) motivated and validated by the literature onteams, and 3) associated with measures of task anddialogue success.In this paper, we first describe the experimentaldesign and technical infrastructure used to create ourcorpus.
We then present two case studies illustrat-ing the use of our corpus as a novel resource forstudying team entrainment: quantifying acoustic-prosodic entrainment at the team-level rather thanthe dyad-level, and incorporating a construct fromthe teamwork literature into the study of entrain-ment.2 Background and Related WorkThe development of methods for automaticallyquantifying entrainment in text and speech data isan active research area, as entrainment has beenshown to correlate with success measures or withsocial variables for a variety of phenomena, e.g.,acoustic-prosodic, lexical, and syntactic (Nenkovaet al, 2008; Reitter and Moore, 2007; Mitchell etal., 2012; Levitan et al, 2012; Lee et al, 2011;Stoyanchev and Stent, 2009; Lopes et al, 2013;Lubold and Pon-Barry, 2014; Moon et al, 2014;Sinha and Cassell, 2015).
Such research, in turn,requires corpora with certain properties.
A high-quality spoken language corpus for studying entrain-1421ment would include transcriptions suitable for nat-ural language processing, audio recordings suitablefor signal processing, and meta-data such as tasksuccess or speaker demographics.While most research has focused on quantify-ing the amount of entrainment between pairs ofspeakers, recent work has started to develop mea-sures for quantifying entrainment between largergroups of speakers (Friedberg et al, 2012; Danescu-Niculescu-Mizil et al, 2012; Gonzales et al, 2010).To date, however, mainly simple methods such asunweighted averaging have been used to move frompairs to groups, and the focus of prior work hasbeen on text rather than speech (e.g., Wikipedia,computer-mediated discussions, lexical analysis oftranscriptions).
In this paper we both investigategroup acoustic-prosodic entrainment and examinerelationships between group entrainment and a fac-tor from the teamwork literature called participationequality / dominance (Paletz and Schunn, 2011).Also, while freely available speech corpora havesupported the study of entrainment in two-party di-alogues (e.g., Switchboard, Maptask, the ColumbiaGames Corpus, Let?s Go), few community resourcesexist for the study of multi-party entrainment.
Somemulti-party resources are only text-based (e.g., theonline Slashdot forum (Allen et al, 2014), chat di-alogues (Afantenos et al, 2015)).
Those speechresources that do exist are often less than ideal asthey were created for other purposes (e.g., SupremeCourt arguments (Ben?us?
et al, 2014; Danescu-Niculescu-Mizil et al, 2012), the AMI meeting cor-pus (Carletta et al, 2006)).
Although not cre-ated to study entrainment, the KTH-Idiap Group-Interviewing corpus (Oertel et al, 2014) is perhapsmost relevant as it was explicitly designed to sup-port research on group dynamics.
However, the cor-pus contains only 5 hours of speech, and participantswere PhD students so did not differ on variables suchas age and social status.The Teams corpus presented and used in this pa-per was designed to add several notable extensionsto existing multi-party spoken dialogue resources.In particular, the Teams corpus was experimentallycollected to constrain the team processes, tasks, andoutcomes in ways that facilitate an investigation ofteam entrainment.
First, the corpus consists of over45 hours of cooperative task-oriented dialogues be-tween three or four speakers, where audio and videofiles were collected and transcribed using best prac-tices for computational processing.
Second, thecorpus was collected using an experimental manip-ulation informed by the organizational and socialpsychological literature on team processes in orderto create high versus low-entrainment conditions.Third, since the social psychological literature sug-gests that team dynamics are more complex than anaverage of dyadic interactions, validated question-naires were used to collect relevant variables of in-terest to researchers on teams, and individual par-ticipants were recruited so that teams would exhibitdiversity with respect to these variables.3 Experimental StudyThe Teams corpus was collected in a laboratoryexperiment.
The laboratory setting enabled high-quality audio and video capture, while the experi-mental study allowed manipulations to vary entrain-ment and to collect measures of team processes.23.1 DesignOur data collection was via an experiment with a2 by 2 within-and-between subjects design.
Teamsof 3-4 participants spent 2-3 hours in our lab tak-ing self-report questionnaires and being audio andvideo-taped playing a cooperative board game.
Twomanipulations were designed to increase the like-lihood of task success and entrainment 3.
Forthe first manipulation, half the teams were given ateamwork training intervention in which participantswere given specific advice based on a needs analy-sis of the team skills important to the game (Gregoryet al, 2013).
Such mixed teamwork/taskwork train-ing has been shown to improve team process out-comes (Salas et al, 2008).
The other half only had2A lab experiment involving a two-player game requir-ing spoken communication was similarly used to collect theColumbia Games Corpus of 12 spontaneous task-orienteddyadic conversations, which has been used in multiple studiesof two-party entrainment (Levitan and Hirschberg, 2011; Lev-itan et al, 2012; Levitan et al, 2011).
Our corpus is approxi-mately 5 times larger, includes speech from teams rather thanfrom dyads, and relatedly includes new types of team-relatedmeta-data.
Our corpus also contains both video and audio asour dialogues were face-to-face rather than restricted to voice.3As discussed in Section 2, prior research has often foundpositive relationships between success and entrainment.1422Figure 1: Dialogue excerpt from a Forbidden IslandTM game.E=Engineer, M=Messenger, and P=Pilot roles in the game.Square brackets indicate overlapping speech.training on the rules of the game, which all teamsreceived.For the second manipulation, each team playedtwo isomorphic versions of the game.
The gamewas originally designed to be played multiple times,with each session unique depending on the randomplacement of specific board tiles and the order ofdeck cards.
To maintain experimental control, twospecific deck card orders and board tile patterns thathad the same underlying opportunities and obstacleswere created.
33 teams played one game first, and30 teams played the other game first.
In either case,by the second time, the team should have a bettergrasp of the game and appropriate strategies.3.2 TaskFor the team task, we chose the cooperative boardgame Forbidden IslandTM , where players take onthe roles of adventurers seeking treasures on an is-land before it is flooded.
We chose this game be-cause it both demands collaboration and is logisti-cally feasible for our experiment.
The cooperativetask-oriented nature of the game requires players tocommunicate to achieve their goals (e.g., discussingcards and strategies in real time, see Figure 1), lend-ing itself directly to eliciting entrainment.
Further,the game gives each player a different role to achievethe team goals, as well as game-specific terminol-ogy, generalizing to real-world situations with team-work (e.g.
aviation, health care).
Logistically, For-bidden IslandTM can be played equally well withthree or four players.
This feature allowed us toschedule teams of four participants, but still play thegame even if only three showed up.
A typical gameis also short enough to be played twice within an ex-perimental session.
Game rules were adapted to en-sure the game difficulty was suitable for novice play-ers (e.g., requiring three rather than four treasuresbe found before completing the game).
As noted inSection 3.1, two isomorphic versions of the gamewere constructed so that the first and second gameswould appear visually different but the difficultylevel would be identical between and within teams.This isomorphism was accomplished by maintain-ing the position of tiles and cards that determinedorder-of-play and game difficulty, while systemat-ically shifting the position of non-critical tiles andcards.3.3 RecruitmentParticipants aged 18 years and older who are na-tive speakers of American English were recruitedvia electronic and hardcopy flyers and paid for theirtime.
They were males and females of any ethnic-ity from a university and its surrounding community.To increase ethnicity, race, and age diversity (rare incorpora typically drawn only from student samples),we advertised in non-student locations in predomi-nantly ethnic minority neighborhoods.3.4 ProcedureAs a team?s participants arrived in the lab, each com-pleted a questionnaire to collect personality, demo-graphic, and other information such as experiencewith the game Forbidden IslandTM .
Participantswere then taught how to play the game by watchinga video and playing a tutorial game, then given a fewminutes to ask specific questions.
Teams in the inter-vention condition (the between-subjects manipula-tion of our experimental design) were given an extra10 minutes before the first game to receive trainingabout teamwork strategies such as team roles, com-munication needs, and how to coordinate their ac-tions (Gregory et al, 2013), as well as additional in-formation adapted for the Forbidden IslandTM taskitself.
Then each team played the game twice for nomore than 35 minutes per game.
Teams were toldthat not completing a game in 35 minutes countedas a loss, and that winning scores for the rest of thegames would be inversely related to game length (atimer was displayed on a computer monitor duringeach game).
The intervention condition teams werealso given an additional 5 minutes before the sec-ond game to discuss what went well and poorly withtheir team processes.
Finally, both between and afterthe two games, all participants filled out question-1423naires regarding their team processes.3.5 Data CaptureGame participants were located around a round ta-ble 48 inches in diameter in our game-playing lab,enabling comfortable participant access to the gameboard.
Each participant sat in a particular locationdepending on their role in the game.
The survey datawere collected in a separate workstation lab usingQualtrics, a web-based, survey software tool.To collect high-quality speech data with minimalcross-talk, audio was recorded using Sennheiser ME3-ew close-talk microphones.
Each microphone wasconnected to a Presonus AudioBox 1818VSL multi-channel audio interface sampling at 96k, 24 bits.Audio recordings were monitored using Reaper Dig-ital Audio Workstation v 4.76.
Each game yieldedone stereo recording with the synchronized speechfrom all speakers, along with 3 or 4 individual files(one per participant) representing the audio record-ing from each microphone.
Reaper was used to ren-der .WAV files with a 48000 Hz sampling rate and a16 bit PCM Wav bit depth.To complement the speech, four wall-mountedZoom Q4 cameras captured WVGA/30 .MOV videorecordings.
The audio streams recorded from thecameras are at the central room, not the individual,level.
A master audio signal was used to synchronizethe videos with each other and with the audio fromthe microphones.
Note that the videos also providebackup audio streams (recording at 256kbps AAC)for the microphones.
In addition, the videos provideinformation about the games that are not always ob-vious from the audio4, as well as non-verbal data forfuture analysis (e.g., of gesture or posture).4 The Teams CorpusOur experiment ran from February through August2015, yielding over 47 hours of recordings from 63teams5 (216 individuals).4.1 Descriptive StatisticsThe 216 participants in our experiment were on av-erage 25.3 years old (min=18, max=67, SD=11.3).4We are currently using the videos to annotate game-specificmeasures of task success.5A power analysis for our experiment yielded a minimumtarget sample size of 52 teams.Control Intervention(n=31) (n=32)3-per.
4-per.
3-per.
4-per.# of teams 20 11 16 16avg g1 time 26.6 28.0 26.4 27.3avg g2 time 18.0 17.7 18.2 19.7Table 1: Team descriptives (n = 63).There were 135 females (62.5%) and 81 males(37.5%).
The highest level of education (whethercompleted or not) ranged from high school (28participants, 13.0%) to undergraduate (153 partici-pants, 70.8%) to postgraduate/professional (35 par-ticipants, 16.2%).
145 participants (67.1%) werecurrently students.
35 participants (16.2%) knewat least one of their team members.
The most fre-quent self-reported ethnicity/races were Caucasian(166), Asian (31), Black (24), and Hispanic (10)(multiple ethnicities were allowed).
Thus, our re-cruitment yielded demographically diverse partici-pants in ways that are useful for team research.Table 1 shows the distribution of the teams in ourcorpus by experimental condition (control versus in-tervention) and team size (3 versus 4 person).
Foreach of these groups of teams, the table also showsthe average time they took in minutes to play games1 and 2, respectively.
A 3-way ANOVA shows asignificant within-team effect for game, with firstgames taking significantly longer than second games(27.1 vs. 18.4 minutes, p < .001).
The averagegame length did not significantly differ by experi-mental condition (p > .7) or by team size (p > .3),and there were also no interaction effects.Our team-level data provides preliminary evi-dence for the success of one of our experimentalmanipulations, as second games were significantlyshorter than first games.
64.2 Audio Segmentation and TranscriptionAfter the experiment was completed, our multi-ple audio track speech was manually segmentedand transcribed using the Higgins Annotation Tool7.6The time to complete a game is an easy to compute but ashallow (inverse) success measure.
We are currently annotat-ing our data for game-specific and dialogue-based success mea-sures, and will also examine success in terms of team processmeasures computable from the questionnaires (Section 4.3).7http://www.speech.kth.se/hat/1424Each audio track, which corresponds to each indi-vidual player, appears on a separate line in Higgins.A time stamp line applies to all of the (synchro-nized) audio tracks.
To do transcription, each par-ticipant?s speech is first segmented into inter-pausalunits, pause-free chunks of speech from a singlespeaker (Levitan and Hirschberg, 2011).
The thresh-old used for pause length (i.e., silence) for our cor-pus is 200 milliseconds.
Once speech is segmentedin a specific audio track, a corresponding text lineappears where the transcriber manually types in thetext for the corresponding audio segment.
Withineach transcription, text segments may also be de-fined and assigned values.
We are using segmentsto annotate non-lexical aspects such as laughs.4.3 Questionnaire DataThe pre-game questionnaire was used to collect in-dividual demographic information such as discussedin Section 4.1, and self-reported data related to per-sonality (John et al, 1991), cognitive styles (Mironet al, 2004), and collective orientation (?the propen-sity to work in a collective manner in team set-tings?
(Driskell et al, 2010)).
The between and post-game questionnaires elicited perceptions of teamprocesses such as cohesion, satisfaction, and po-tency/efficacy (Wendt et al, 2009; Wageman et al,2005; Guzzo et al, 1993).
Such information wascollected as a novel resource for studying multi-party entrainment, since team processes have beenshown to be positively related to performance (Bealet al, 2003; Mullen and Copper, 1994).4.4 Public ReleaseThe Teams corpus will be freely available for re-search purposes8, with the first release coordinatedwith the publication of this paper.
The team levelcontents of the first release will consist of 63 game 1and 62 9 game 2 WAV files.
The individual levelcontents of this release will consist of the demo-graphic responses for the 216 participants in XLSXformat.
Later corpus releases will include associ-ated audio segmentations and transcriptions in XML8https://sites.google.com/site/teamentrainmentstudy/corpus9One audio file was not properly saved during the experi-ment.
The corresponding single-channel audio extracted fromthe game?s video will be provided instead.format, game-level video files, and personality andteam process measures.5 Case Studies Using the Teams CorpusThis section presents results from two case studiesillustrating the use of the Teams corpus for novel re-search in multi-party dialogue entrainment.
The firststudy proposes new team level measures that buildon existing dyad-level measures of proximity andconvergence, then uses these team measures to in-vestigate whether prior dyad-level acoustic-prosodicentrainment findings generalize to teams.
The sec-ond study investigates relationships between teamconvergence and participation equality / dominance.5.1 Acoustic-Prosodic Team EntrainmentSpeakers do not entrain on all linguistic featuresof conversations, and when they do entrain, theymay entrain in different ways on different features.In this section we examine whether teams entrainon different acoustic-prosodic features during eachof their two game conversations.
Our current ap-proach to measuring team-level entrainment is basedon averaging dyad-level measures.
We build ontwo dyad measures, namely, proximity and conver-gence (Levitan and Hirschberg, 2011).
In a conver-sation, proximity measures feature similarity overthe entire conversation, while convergence measuresan increase in feature proximity over time.5.1.1 Feature Extraction from Speaker AudioWe focus on the acoustic-prosodic dimensionsof pitch, intensity, and voice quality, followingprevious work on dyad entrainment (Levitan andHirschberg, 2011; Lubold and Pon-Barry, 2014;Borrie et al, 2015).
Pitch is related to the frequencyof the sound wave.
Intensity describes the rate of en-ergy flow.
Jitter and shimmer are measures of vari-ations of frequency and energy, respectively, whichare descriptive of voice quality.
We use the Praatsoftware (Boersma and Heuven, 2002) to extract thefollowing 9 acoustic-prosodic features: minimum(min), maximum (max), mean and standard devi-ation (SD) of pitch; min, max, mean of intensity;1425local jitter10; and local shimmer11.
Features areextracted separately for each speaker and for eachgame.
Before feature extraction, each game-levelaudio file for each speaker is pre-processed to re-move silences (using a threshold of 1 second).5.1.2 Measuring Team ProximityProximity quantifies the similarity of a featurevalue between conversational partners over their en-tire conversation.
Intuitively, if a team has entrainedon a feature in terms of proximity during a partic-ular game, speakers within the same team shouldbe more similar (or equivalently, less different) toeach other than to all the other speakers in the corpuswho are not on their team and are playing the samegame (i.e., game 1 or game 2).
For each game wecomputed a team-level partner difference (TDiffp)and a team-level other difference (TDiffo).
In Sec-tion 5.1.4 we report paired t-test analyses to inferentrainment within a game when TDiffp is signifi-cantly smaller than TDiffo.The partner difference for a speaker in adyad (Levitan and Hirschberg, 2011) is the absolutedifference between the feature value for a speakerand her partner.
For each team, we averaged theseabsolute values for all members of the team:TDiffp =?
?i 6=j?team(|speakeri ?
speakerj |)|team| ?
(|team| ?
1) (1)The other difference for a speaker in a dyad (Levitanand Hirschberg, 2011) is the mean of the absolutedifferences between the speaker?s value for a featureand the values of each of the speakers in the corpus(for the same game number) with whom the speakerwas not partnered (set X in Formula 2).
For eachteam, we averaged these means for all the membersof the team:TDiffo =?
?i?team(?j |speakeri?Xj ||X| )|team| (2)For proximity, all of the feature values were normal-ized within a game based on gender12 using z-scores10The average absolute difference between the amplitudes ofconsecutive periods, divided by the average amplitude.11The average absolute difference between consecutive peri-ods, divided by the average amplitude.12Normalization is done only for proximity, since compar-isons for convergence are within (rather than between) teams.Feature Game1 Game2Pitch-min 0.844 0.193Pitch-max ?1.092 0.022Pitch-mean ?1.297 ?1.294Pitch-sd ?0.407 ?1.652Intensity-mean ?4.469* ?4.911*Intensity-min ?2.653* ?2.069*Intensity-max ?3.625* ?2.853*Shimmer-local ?2.390* ?2.782*Jitter-local ?1.242 ?2.702*Table 2: Proximity t-values of a paired t-test comparing team-level partner (TDiffp) vs. other (TDiffo).
Negative t-valuesindicate that partner differences are smaller than other differ-ences.
* p < .05. n = 62.
(z = vij?
?j?j ; vij = value of speaker i in game jwhere j ?
{1, 2}, ?j = gender mean in game j, and?j = gender standard deviation in game j.
)5.1.3 Measuring Team ConvergenceIntuitively, there is evidence of convergence whenspeakers within a conversation become more similarto each other later in the conversation.
While featurevalue differences are compared across teams to in-fer proximity entrainment, feature value differenceswithin a single team are compared across time forconvergence entrainment.
Since differing time inter-vals have been examined in the dyad literature, wecompared features extracted from the first versus lastthree, five, and seven minutes of each game, as wellas from the two game halves.13 Convergence wasinferred via paired t-tests when the partner differ-ences (Equation 1) in the second time interval weresignificantly smaller than in the earlier time interval(e.g., the TDiffp in the last 3 minutes of game 1 issmaller than TDiffp in the first 3 minutes of game1).
To break the games into different time intervalsfor feature extraction, we used the raw audio files toextract the breaking points of the conversation andthen mapped these points to each of the processedaudio files where silence was removed.5.1.4 Team-Level Entrainment ResultsThe proximity results are shown in Table 2.
Nega-tive t-values indicate that differences between speak-13(Levitan and Hirschberg, 2011) also looked for conver-gence between the two halves of the first game in their corpus.1426First vs. last 3 minutes First vs. last 5 minutes First vs. last 7 minutes First vs. second halfFeature Game1 Game2 Game1 Game2 Game1 Game2 Game1 Game2Pitch-min 2.474* ?0.709 1.487 ?1.299 1.359 ?1.622 0.329 ?0.884Pitch-max 4.947* 1.260 1.892 ?0.468 1.348 ?0.424 0.457 0.627Pitch-mean ?2.687* 0.109 ?2.900* 0.417 ?2.965* ?0.361 ?1.905 ?0.266Pitch-sd 1.364 0.409 1.919 0.591 1.807 0.576 1.271 0.089Intensity-mean ?0.275 ?2.946* ?0.454 ?2.245* ?0.229 ?1.825 ?0.360 ?1.540Intensity-min 0.595 ?3.188* ?0.136 ?4.335* 0.009 ?3.317* ?0.972 ?3.324*Intensity-max 0.328 0.327 ?0.731 1.081 ?0.140 0.511 ?0.222 0.469Shimmer-local 2.896* ?0.476 3.396* ?1.941 3.006* ?1.704 2.794* ?0.914Jitter-local 3.205* 0.725 2.796* 0.242 2.867* 0.469 2.973* 0.260Table 3: Convergence t-values of paired t-tests comparing team-level partner differences (TDiffp) of first 3, 5, 7 minutes vs.last 3, 5, 7 minutes, respectively, and of first vs. second game half, for each game.
Positive t-values indicate convergence (i.e.,that partner differences in the second interval are smaller than in the first).
Negative t-values indicate divergence.
Significantconvergence results are in bold.
* p < .05. n = 62.ers who are all within the same team are smallerthan differences between team members and otherspeakers in the corpus.
Thus, negative values areindicative of team entrainment.
The results showthat the team members were significantly more sim-ilar to each other than to other speakers on inten-sity mean, min, and max and on shimmer for bothgames.
Team-level entrainment on jitter was signif-icant for only the second game.The convergence results are shown in Table 3 forfour different temporal comparison intervals.
Com-parison of the significant game 1 results shows thatteams entrained on pitch min, pitch max, shimmer,and jitter in at least one of the intervals.
Both shim-mer and jitter converged for all choices of temporalunits.
For pitch, convergence was instead only seenusing the first and last 3 minutes, which are the inter-vals farthest in the game from each other.
The onlyfeature that diverged during game 1 is pitch-mean.The rest of the features did not show significantteam-level partner differences during game 1 for anytemporal interval and thus exhibited maintenance,meaning that the team members neither convergednor diverged.
During game 2, we observed mainte-nance for all features except for intensity-mean andintensity-min, which diverged.
Together our resultssuggest that when teams in our corpus convergedon a feature, they did so earlier in the experiment(namely, just during the first game, and sometimesjust in the earliest part of the first game).As a divergent validity check for convergence, foreach of the 62 teams, we constructed artificial ver-sions of the real conversations between team mem-bers: For each member of the team, we randomlypermuted the silence and speech intervals extractedby Praat.
Ideally, we should not see evidence ofconvergence within these constructed conversations.Our results confirm that there was no significant en-trainment on either of the two constructed games, forall temporal comparison intervals and all features.In summary, team acoustic-prosodic entrainmentdid not occur for all features.
For the features thatdid show entrainment, results varied depending onwhether proximity or convergence was examined,and by the time intervals compared.
With respectto type of entrainment, when looking at the entiregame 1, there was significant evidence of entrain-ment (proximity) on mean, min, max intensity, andshimmer.
Although there was no significant prox-imity for min, max pitch and jitter, they did becomemore similar (converged) over time.
With respect totime, team convergence was found for shimmer andjitter independently of temporal interval examined,but for pitch only when comparing the most distanttemporal intervals in game 1.5.2 Participation Equality / DominanceWithin psychology, equality of participation hasbeen associated with successful team performanceand decision-making (e.g., (Mesmer-Magnus andDeChurch, 2009; Stasser and Titus, 1987)).
Withincomputational linguistics, balance of participationwith respect to proposal of ideas was associatedwith more productive small group (online) conversa-tions (Niculae and Danescu-Niculescu-Mizil, 2016).Extending this literature, we perform a novel in-1427Model 1 Model 2B SEB ?
B SEB ?Session Length 0.187 0.067 0.328* 0.197 0.064 0.344*Team Size 108.706 47.398 0.269* 69.721 47.980 0.173Participation Dominance ?1077.747 429.130 ?0.299*Model R2 0.186 0.266Model F 6.761* 7.015*Table 4: Summary of hierarchical regression analysis for variables predicting entrainment on pitch-max.
* p < .05. n = 62.vestigation of the association between participationequality/dominance and team entrainment, focusingon the time interval showing the most significantconvergence results in Section 5.1.4 (entrainment onpitch-max, pitch-min, jitter, and shimmer from thefirst to last 3 minutes of game 1).Equation 3 defines the participation of player iin a team, where speech lengthi is the sum of thelengths of the speech intervals of player i:participationi =speech lengthi?m?team speech lengthm(3)Participation dominance in turn is the standard de-viation of the participation for all team members:Dominance = ?
(Participation),Participation = {participationi|i ?
team} (4)Higher standard deviations indicate a greater rangeof participation from team members, and lower stan-dard deviations indicate more participation equality.We performed a hierarchical regression analysisfor each of the four acoustic-prosodic features notedabove as the target entrainment variable.
As in theconvergence section, we measured entrainment asthe average differences (TDiffp) of the team in thefirst interval minus the second interval.
Larger pos-itive numbers are indicative of more entrainment.The independent variables we included in our anal-ysis are: team size, session length, average age ofthe team members, percentage of the female play-ers in each team, and participation dominance.
Thefirst four are covariates that have been found to beor are likely related to team communication and/ordynamics.
We hypothesized that participation dom-inance would be related to entrainment above andbeyond these other potential variables.Table 4 presents the results with pitch-max forentrainment.
(The other 3 entrainment variablesdid not show significant relationships with partici-pation.)
The standardized ?s indicate the effect sizeand direction of the individual variables on pitch-max, whereas the R2 indicates the effect size of themodel of all the variables together.
Average age andpercent female were not significantly related to en-trainment on pitch-max, so were excluded from thefinal analyses.First, both team size and session length were en-tered as potential independent variables into the re-gression analysis with pitch-max as the dependentvariable.
This model (Model 1) was significant.Specifically, team size and session length were bothsignificantly positively associated with entrainmenton pitch-max.
That is, as team size or session lengthincreased, entrainment also increased.Participation dominance was then entered to cre-ate Model 2, which included team size, sessionlength, and participation dominance.
The amount ofvariance explained for participation dominance wassignificant above and beyond the variables enteredin Model 1, ?R2 = 0.08, ?F (1, 58) = 6.307,p = 0.015.
Specifically, there was a significant neg-ative association between participation dominanceand entrainment on pitch-max, such that greater par-ticipation equality was related to greater entrain-ment.
This suggests that the more each team mem-ber is given a chance to equally contribute, the morelikely they are to entrain on their maximum pitch.6 Summary and Broader ImplicationsThe long-term goal of our research is to use speechand language processing, informed by the team-work literature, to develop computational measuresof conversational team entrainment that will be use-ful for predicting team success.
We first describedthe design and contents of the Teams corpus, whichis being made freely available for research pur-poses.
Experimental manipulations, high-quality1428audio and video with time-aligned transcriptions,and self-reported team process data make the cor-pus a unique resource for studying multi-party dia-logue entrainment.
We provided two examples il-lustrating the use of the Teams corpus to facilitatenew directions in the study of entrainment: quantify-ing acoustic-prosodic entrainment at the team ratherthan the dyad-level, and incorporating the teamworkconstruct of participation dominance into the studyof entrainment.
Our current plans include contin-ued corpus development (recall Section 4.4), and us-ing more sophisticated methods than dyad averaging(e.g., using weighting based on team process mea-sures) to move from dyads to teams.With respect to broader impact, our entrainmentmeasures could be used to mine existing corporafor naturalistic successful and unsuccessful conver-sations, or to trigger online interventions by dia-logue systems participating in multi-party conversa-tions.
After additional research understanding theimportant thresholds for entrainment, organizationscould unobtrusively measure team effectiveness dur-ing entrainment, and intervene with training to aidteams with low entrainment.
Similar interventionswould be useful for conversational agents that mon-itor and facilitate group interactions (e.g., in edu-cation via computer-supported collaborative learn-ing).
Our work could also support the developmentof data mining applications for corpora such as teammeetings or discussions, from classrooms to board-rooms.
Finally, our corpus could support natural lan-guage processing research regarding any other as-pect of teamwork (e.g., affect, conflict, topic mod-eling).
In sum, the Teams Corpus should provideusable, multi-channel data for examining team pro-cesses for a range of purposes and research disci-plines.AcknowledgmentsThis material is based upon work supported bythe National Science Foundation under Grant Nos.1420784 and 1420377.
Any opinions, findings, andconclusions or recommendations expressed in thismaterial are those of the authors and do not necessar-ily reflect the views of the National Science Founda-tion.
The authors wish to thank Catharine Oertel andMattias Heldner for advice regarding both lab andequipment needs, and the Learning Research andDevelopment Center at the University of Pittsburghfor lab renovation.
Finally, we would like to thankAnish Kumar, the Pitt NLP group, and the anony-mous reviewers for their help in improving the pa-per.ReferencesStergos Afantenos, Eric Kow, Nicholas Asher, andJe?re?my Perret.
2015.
Discourse parsing for multi-party chat dialogues.
In Proceedings of the 2015 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 928?937.Kelsey Allen, Giuseppe Carenini, and Raymond Ng.2014.
Detecting disagreement in conversations usingpseudo-monologic rhetorical structure.
In Proceed-ings of the 2014 Conference on Empirical Methods inNatural Language Processing (EMNLP), pages 1169?1180.Daniel J. Beal, Robin.
R. Cohen, Michael J. Burke, andChristy L. McLendon.
2003.
Cohesion and per-formance in groups: A meta-analytic clarification ofconstruct relations.
Journal of Applied Psychology,88:989?1004.S?tefan Ben?us?, Agust?
?n Gravano, Rivka Levitan, Sarah ItaLevitan, Laura Willson, and Julia Hirschberg.
2014.Entrainment, dominance and alliance in supreme courthearings.
Knowledge-Based Systems, 71:3?14.Paul Boersma and Vincent van Heuven.
2002.
Praat, asystem for doing phonetics by computer.
Glot inter-national, 5(9/10):341?345.Stephanie A Borrie, Nichola Lubold, and Heather Pon-Barry.
2015.
Disordered speech disrupts conversa-tional entrainment: a study of acoustic-prosodic en-trainment and communicative success in populationswith communication challenges.
Frontiers in psychol-ogy, 6.Susan E. Brennan and Herbert H. Clark.
1996.
Concep-tual pacts and lexical choice in conversation.
Journalof Experimental Psychology: Learning, Memory, andCognition, 22(6):1482?1493.Jean Carletta, Simone Ashby, Sebastien Bourban, MikeFlynn, Mael Guillemot, Thomas Hain, JaroslavKadlec, Vasilis Karaiskos, Wessel Kraaij, MelissaKronenthal, Guillaume Lathoud, Mike Lincoln, AgnesLisowska, Iain McCowan, Wilfried Post, Dennis Rei-dsma, and Pierre Wellner.
2006.
The ami meeting cor-pus: A pre-announcement.
In Steve Renals and SamyBengio, editors, Machine Learning for Multimodal In-teraction, volume 3869 of Lecture Notes in ComputerScience, pages 28?39.1429Cristian Danescu-Niculescu-Mizil, Lillian Lee, Bo Pang,and Jon Kleinberg.
2012.
Echoes of power: Languageeffects and power differences in social interaction.
InProceedings of WWW, pages 699?708.James E. Driskell, Eduardo Salas, and Sandra Hughes.2010.
Collective orientation and team performance:Development of an individual differences measure.Human Factors: The Journal of the Human Factorsand Ergonomics Society, 52:316?328.Heather Friedberg, Diane Litman, and Susannah B. F.Paletz.
2012.
Lexical entrainment and success in stu-dent engineering groups.
In Proceedings Fourth IEEEWorkshop on Spoken Language Technology (SLT), Mi-ami, Florida, December.Amy L. Gonzales, Jeffrey T. Hancock, and James W. Pen-nebaker.
2010.
Language style matching as a predic-tor of social dynamics in small groups.
Communica-tion Research, 37:3?19.M.
E. Gregory, J. Feitosa, T. Driskell, E. Salas, and W. B.Vessey, 2013.
Developing and enhancing teamworkin organizations: Evidence-based best practices andguidelines, chapter Designing, delivering, and evaluat-ing team training in organizations.
Jossey-Bass, SanFrancisco.Richard A. Guzzo, Paul R. Yost, Richard J. Campbell,and Gregory P. Shea.
1993.
Potency in groups: Artic-ulating a construct.
British Journal of Social Psychol-ogy, 32:87?106.O.
P. John, E. M. Donahue, and R. L. Kentle.
1991.The big five inventory-versions 4a and 54.
Universityof California, Berkeley, Institute of Personality andSocial Research.
http://www.ocf.berkeley.edu/ john-lab/bfi.htm.Chi-Chun Lee, Athanasios Katsamanis, Matthew P.Black, Brian R. Baucom, Panayiotis G. Georgiou, andShrikanth Narayanan.
2011.
An analysis of pca-basedvocal entrainment measures in married couples?
affec-tive spoken interactions.
In INTERSPEECH, pages3101?3104.Rivka Levitan and Julia Hirschberg.
2011.
Measuringacoustic-prosodic entrainment with respect to multiplelevels and dimensions.
In Interspeech.Rivka Levitan, Agust?
?n Gravano, and Julia Hirschberg.2011.
Entrainment in speech preceding backchannels.In Proceedings of ACL/HLT, June.Rivka Levitan, Agust?
?n Gravano, Laura Willson, StefanBenus, Julia Hirschberg, and Ani Nenkova.
2012.Acoustic-prosodic entrainment and social behavior.
In2012 Conference of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language Technologies, pages 11?19.Jose?
Lopes, Maxine Eskenazi, and Isabel Trancoso.2013.
Automated two-way entrainment to improvespoken dialog system performance.
In ICASSP, pages8372?8376.Nichola Lubold and Heather Pon-Barry.
2014.
Acoustic-prosodic entrainment and rapport in collaborativelearning dialogues.
In Proceedings of the 2014 ACMworkshop on Multimodal Learning Analytics Work-shop and Grand Challenge, pages 5?12.
ACM.Jessica R. Mesmer-Magnus and Leslie A. DeChurch.2009.
Information sharing and team performance:A meta-analysis.
Journal of Applied Psychology,94:535?546.Ella Miron, Miriam Erez, and Eitan Naveh.
2004.
Dopersonal characteristics and cultural values that pro-mote innovation, quality, and efficiency compete orcomplement each other?
Journal of OrganizationalBehavior, 25:175?199.Christopher Michael Mitchell, Kristy Elizabeth Boyer,and James C. Lester.
2012.
From strangers to part-ners: Examining convergence within a longitudinalstudy of task-oriented dialogue.
In SIGDIAL Confer-ence, pages 94?98.Seungwhan Moon, Saloni Potdar, and Lara Martin.
2014.Identifying student leaders from mooc discussion fo-rums through language influence.
In Proceedings ofthe EMNLP 2014 Workshop on Analysis of Large ScaleSocial Interaction in MOOCs, pages 15?20.Brian Mullen and Carolyn Copper.
1994.
The relationbetween group cohesiveness and performance: An in-tegration.
Psychological Bulletin, 115(2):210?227.Ani Nenkova, Agust?
?n Gravano, and Julia Hirschberg.2008.
High frequency word entrainment in spoken di-alogue.
In Proceedings of the 46th Annual Meetingof the Association for Computational Linguistics onHuman Language Technologies: Short Papers, HLT-Short ?08, pages 169?172.Vlad Niculae and Cristian Danescu-Niculescu-Mizil.2016.
Conversational markers of constructive discus-sions.
arXiv preprint arXiv:1604.07407.Catharine Oertel, Kenneth A. Funes Mora, SamiraSheikhi, Jean-Marc Odobez, and Joakim Gustafson.2014.
Who will get the grant?
: A multimodal corpusfor the analysis of conversational behaviours in groupinterviews.
In Proceedings of the 2014 Workshop onUnderstanding and Modeling Multiparty, MultimodalInteractions, pages 27?32.Susanah B. F. Paletz and Christian D. Schunn.
2011.
As-sessing group-level participation in fluid teams: Test-ing a new metric.
Behavioral Research Methods,43:522?536.Robert Porzel, Annika Scheffler, and Rainer Malaka.2006.
How entrainment increases dialogical effective-ness.
In Proceedings of the IUI?06 Workshop on Effec-tive Multimodal Dialogue Interaction, pages 35?42.1430David Reitter and Johanna D. Moore.
2007.
Predictingsuccess in dialogue.
In Proceedings of the 45th Meet-ing of the Association of Computational Linguistics,pages 808?815.Eduardo Salas, Deborah DiazGranados, Cameron Klein,C.
Shawn Burke, Kevin C. Stagl, Gerald F. Goodwin,and Stanley M. Halpin.
2008.
Does team trainingimprove team performance?
a meta-analysis.
HumanFactors, 50:903?933.Tanmay Sinha and Justine Cassell.
2015.
Fine-grainedanalyses of interpersonal processes and their effect onlearning.
In Artificial Intelligence in Education: 17thInternational Conference, pages 781?785.Garold Stasser and William Titus.
1987.
Effects of in-formation load and percentage of shared informationon the dissemination of unshared information duringgroup discussion.
Journal of Personality and SocialPsychology, 53:81?93.Svetlana Stoyanchev and Amanda Stent.
2009.
Lexi-cal and syntactic priming and their impact in deployedspoken dialog systems.
In Proceedings of Human Lan-guage Technologies: The 2009 Annual Conference ofthe North American Chapter of the Association forComputational Linguistics, Companion Volume: ShortPapers, NAACL-Short ?09, pages 189?192, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Ruth Wageman, J. Richard Hackman, and Erin Lehman.2005.
Team diagnostic survey: Development of aninstrument.
Journal of Applied Behavioral Science,41:373?398.Hein Wendt, Martin C. Euwema, and I. J. Hetty vanEmmerik.
2009.
Leadership and team cohesivenessacross cultures.
The Leadership Quarterly, 20:358?370.1431
