Chart Parsing of Stochastic Spoken Language ModelsChar les  Hemphi l l  and  Joseph P iconeTexas InstrumentsSpeech and Image Understanding LaboratoryP.O.
Box 655474, MS 238Dallas, Texas 75265, USAAbstractPerformance in speech recognition systems has progressed to the point where it is now realistic to beginintegrating speech with natural language systems to produce spoken language systems.
Two factors havecontributed to the advances in speech: statistical modeling of the input signal and language constraints.To produce spoken language systems, then, the grammar formalisms used in natural language systemsmust incorporate statistical information and efficient parsers for these stochastic language models must bedeveloped.
In this paper we outline how chart parsing techniques provide advantages in both computationand accuracy for spoken language systems.
We describe asystem that models all levels of the spoken languagesystem using stochastic language models and present experimental results.IntroductionSpeech technology has recently made tremendous progress toward speaker-independent large-vocabularyspeech recognition (e.g., Lee and Hon, 1988).
These sorts of systems rely on Hidden Markov Models (HMMs)of the speech signal and language constraints of the application to achieve good performance.
It is importantto observe that the language model provides top-down information to reduce the search space during pro-cessing.
Kubala et al(1988) have shown that the perplexity (roughly the number of choices) of the languagemodel correlates with recognition performance.
Because of the tendency for Finite State language modelsto drastically increase in perplexity as coverage increases, it is unlikely that these systems will extend tospoken language systems.Natural language technology has steadily moved toward the unification grammar paradigm (Shieber,1986).
These formalisms allow various kinds of agreement by generalizing the notion of a grammar symbolto include features and variables.
This approach offers advantages in elegantly integrating syntax, semanticsand pragmatics while providing domain independence (Mani and Hemphill, 1988).
The combination of theseconstraints during sentence processing can be used to greatly reduce perplexity, but unification grammarshave not yet been integrated with speech systems.
To do this, the parser must support stochastic grammars(grammars with rule probabilities), comprehend probabilistic hypotheses, and operate frame-synchronouslyto mesh with the speech system.Various bottom-up approaches to combining speech and natural anguage have been tried (e.g., Tomita,1986).
These systems uffer from many problems: top-down information is not available for lower levels,separate grammars must be used for both systems, missing words in the word lattice prove fatal, andprobability is usually not available for pruning.
Ney (1987) describes a combined top-down and bottom-upapproach using the CYK algorithm, but this algorithm has bad average time complexity (the number ofinput frames cubed).250Our experience with unification grammars has shown us that word hypotheses may be efficiently producedduring sentence processing (Hemphill et al 1987).
To facilitate integration with speech, we have developed achart parser specialized to process N levels of stochastic regular grammars.
This enables a conceptual shiftfrom the paths and state probabilities found in current systems to symbols that best explain a segment ofspeech data.
We have also constructed a probabilistic version of Earley's algorithm based on observationsfound in Aho and Peterson (1972).
We are currently extending this latter algorithm to support he style ofunification grammars found in our earlier work.We demonstrate he feasibility of a completely symbol-based approach to speech processing by achievingthe same performance with layers of stochastic regular grammars as our best FSA-based system (Picone etal, 1988).
HMMs easily map to both stochastic RGs and FSAs, but the combined top-down and bottom-upparsing algorithm used in this system differs substantially from FSA processing techniques.
Most impor-tantly, the parsing algorithm offers computational dvantages when hypothesis are needed more than onceat the same time frame.
This occurs frequently in large grammars and the proper treatment of this conditionis essential for processing unification grammars appropriate for spoken language.Stochastic Spoken Language Models and ParsingFinite State Automata (FSA) have traditionally been used in speech processing, but they are clearlyinappropriate for spoken language systems.
In this section, we contrast unification grammars (UGs) withContext-Free grammars (CFGs) and discuss extensions needed for spoken language systems.
These exten-sions involve both the formalism and the parser.Natural language systems have benefited significantly from the advent of unification grammars.
Thesegrammars allow a significant reduction in the number of grammar rules required to represent an application.For example, the following unification grammar ule represents a simple modifying phrase for a relation (R)and attribute (A) in a database:rood(R) ~ whose, attr(R, A), is, value(R, A).This rule allows phrases uch as "Find parts whose color ks red."
If this rule were expanded for a CFG-basedsystem, it would result in a number of rules equal to the number of all attributes for all relations.
This problembecomes even larger in a complete grammar.
For example, an interface using only 41 unification grammarrules has been constructed for the Force Requirements Expert System (FRESH), but when expanded toCFG rules, over 1000 rules result.
Furthermore, processing the unification grammar ules requires less timeand space and allows more flexibility in coverage.The FRESH interface deals primarily with semantic agreement, but UGs also model syntactic and prag-matic phenomena well (Mani and Hemphill, 1988).
These three sources of information may be combinedin on-line parsing to reduce the search space during processing.
On-line processing refers to left-to-rightprocessing of the input as it becomes available.
This allows the prediction of needed words at each point inprocessing, making the method appropriate for spoken language systems.On-line parsing is normally achieved by chart parsing algorithms (Winograd 1983).
These algorithmsprovide mechanisms for efficiently processing rammars by avoiding duplicate work when expanding sym-bols.
Grammars associate symbols with both observations (terminal symbols) and alternate xplanations(nonterminal symbols), allowing the elimination of duplicate work in re-hypotheslzing the same observationsand partial sentence hypotheses.Spoken language systems, however, deal with probabilistic symbols and both the grammar formalismand the parsing algorithm must accommodate hese (Hemphill and Picone, 1989).
We have developed achart parsing algorithm that allows on-line parsing and correctly operates with probabilities.
Basically, itis similar to Earley's algorithm (Earley, 1970), augmented with unification (Pereira and Warren, 1983) andprobability (Paeseler, 1987), but with a delayed commitment approach to scoring (Aho and Peterson, 1972).This algorithm operates from left to right in a combined bottom-up and top-down fashion, providing terminalhypotheses at each time frame to lower levels and accepting completed hypotheses that began at some timein the past.
The algorithm has not yet been fully implemented for UGs, but the following section exploresthe ramifications of this type of approach.251tBest+BeamIn P1BestFigure h Effect of chart parsing on pruning.Probabilistic Chart ParsingIn this section, we describe the chart parser as applied to stochastic regular grammars.
This providesan indication that the ideas are appropriate for speech processing and calibrates the system with respect oexisting FSA-based HMM systems.
Three concepts found in speech systems are then applied to the chartparsing framework: pruning, garbage collection, training.The chart parser can process N layers of stochastic regular grammars.
The layers allow expansion of morethan one symbol in a rule as in CFGs, but without recursive ability.
Specifically, terminal symbols at onelayer correspond to start symbols at the next layer.
The layers correspond to such things as sentence, word,and phone-model grammars.
The top level grammar dictates which hypotheses propagate to lower levelsat each frame.
Each grammar level in turn propagates hypotheses needed in order to successfully returncomplete observations.
The last level includes a set of grammars that represent an HMM for each acousticmodel.
Appropriate reference data from this level is compared with the current input speech vector.
Theprocessor then incorporates the reference probabilities into the current state of the parse and any completedhypotheses pass to the next higher level as observations.
Hypotheses and observations ateach level propagatedown and up at each frame until all of the speech data may be explained by the formation of a completesentence.As a practical consideration, treatment of symbols in this manner interacts with pruning.
This is illus-trated in Figure 1 for a standard beam search pruning strategy.
In stochastic chart parsing, the same symbolmay be needed for several different explanations ofthe speech signal, but only the most likely representativeactually becomes hypothesized (tl).
The probability of the completed observation is then used in extendinghypotheses awaiting that observation (t~).
This leads to a situation where a lower probability explanationof the symbol may not only survive where it otherwise would have been pruned (tj), but the subsequenthypotheses using this symbol may actually give the more probable xplanation (tz).
Furthermore, since thechart parser expands only the most likely symbol, the less likely hypotheses cause no additional computationduring evaluation of the symbol.Pruning helps reduce the amount of memory required uring processing, but not sufficiently.
Spokenlanguage systems will contain large vocabularies and require processing of long sentences and sentences indiscourse.
To address this problem, we have embedded a time-stamp garbage collection scheme into thechart parser.
This algorithm reduces memory requirements by an order of magnitude and adds only a smallfraction to processing time.
Because the algorithm operates on symbols, it applies to stochastic spokenlanguage models in general.252Table h Grammars in the experiments.Task Level Rules NontermsULCD 0 14 11 1994 1172RM 0 21025 47441 1017 5782 26111 13017CKCD 0 83688 I 8781i 4026 I 1919Terminals1351757810171200121711Finally, to become fully general, spoken language systems must support training.
The layered grammarapproach, although not strictly necessary with CFGs and UGs, allows training above the acoustic modellevel.
For example, phone transition probabilities may be obtained using maximum likelihood training (Fu,1982).
This technique applies to symbols generalized with feature sets and logical variables and will beimportant as unification grammars find their way into the phonetic level.Experimental ResultsThree recognition experiments have been performed to calibrate the system with respect o an existingFSA system (Picone et al 1988): unknown length continuous digit (ULCD) strings (Doddington, 1989), the1O00-word Resource Management (RM) task (Price et al 1988), and fixed length continuous digit stringswith a checksum encoded in the grammar (CKCD).
The first two systems use 18-element reference vectorswith a 20 rnsec frame period and pooled covariance.
The third experiment uses only 16-element referencevectors.
Because of the grammars involved, chart parsing offers no advantage in the first experiment, asmall advantage in the second, and maximal advantage in the third.
In all experiments, both systems obtainidentical results when pruning is not a factor (i.e., errors occur because of the models, not pruning).
Table 1indicates the relative size of the grammars.The ULCD experiment consists of two levels of grammars.
The first grammar allows zero or moreoccurrences of oh, zero - nine, a silence model, and a null-speech model.
The second grammar containsthe HMMs for each of these.
Although multiple hypotheses of the same symbol at the same time occur inthe HMM grammar, the hypotheses at this level correspond to reference vectors of one frame in durationand the FSA-based system evaluates these only once.
Additionally, the FSA system evaluates hypothesesonce per source node, making the one node sentence automata especially favorable for this system.The RM experiment consists of three levels of grammars.
The first contains a canonicalized gram-mar representing the various sentence patterns desired for the task, the second maps word types (e.g.,'<ship-name>')  to words, and the third defines the HMM models for the words.
Only the first level in thisexperiment benefits from the chart parsing approach.The CKCD experiment consists of two levels of grammars.
The first grammar allows a fixed numberof the digits zero - n ine (with a male and female model for each) and a silence model.
This grammarimplements a checksum function with the last two digits serving as the checksum.
The bottom level againcontains HMM word models.
The large branching factor in the sentence grammar creates a situation wherechart parsing can help tremendously.Table 2 summarizes the ratio of chart parsing time to FSA processing time for each experiment.
The firstexperiment indicates that the overhead of chart parsing is at most a factor of two.
The second experimentshows that even for small perplexity grammars (perplexity 9 for RM), the benefits of chart parsing beginto compensate for the overhead in the lower levels.
The third experiment was conducted for three differentnormalized pruning values: 0.2 and 0.3, 0.35.
The lower value greatly reduces the number of evaluatedhypotheses and therefore favors the FSA processor.
However, at this pruning level, the FSA processor253Table 2: T ime ratios for RG and FSA processors.
Table 3: Effects of pruning on accuracy for CKCD.Task RG/FSA timeULCDRMCKCD (0.20)CKCD (0.30)CKCD (0.35)1.9I .
I1.21"0.7o.6tBeam0.200.300.35FSA Sent Corr90~98%96%~RG Sent Corr94%98%98%t sub-optimal resultsmemory overflows in FSA systemTable 4: Garbage collection in chart parsing.Task Ave.
Peak Ave. TotalULCDRMCKCD (0.20)CKCD (0.30)CKCD (0.35)2023 390748461 1202275692 25487922241 66865943576 1013254correctly recognizes 90% of the sentences while the chart parsing technique recognizes 94% (Table 3).
Thisprovides evidence for the phenomena illustrated in Figure 1.
At 0.3, both methods recognize 98% of thesentences, with a time advantage for the chart parsing approach.
At 0.35, the time advantage increasesfor the chart parsing approach and, additionally, the FSA method exhausts memory when processing somesentences.Table 4 summarizes the effect of garbage collection on space requirements for the chart parser in eachof the experiments.
The average peak memory column indicates the peak memory requirements over allframes for each sentence.
The average total memory column indicates the amount of memory needed foreach sentence without garbage collection.
Note that the memory savings is in addition to pruning.
As canbe seen, there is a substantial savings, and in fact, the last two experiments could not be performed withoutthis algorithm.
The FSA system also uses this same method, but pursuing each hypothesis separately resultsin memory overflow in the last experiment.Conclus ionsWe have demonstrated that chart parsing techniques successfully apply to stochastic language models.In the process, we have demonstrated an approach to speech recognition in which the entire recognitionprocess, including acoustic processing, consists of a hierarchy of grammars.
A shift from automata togrammars allows efficient processing of complex language models by hypothesizing symbols once per frame,no matter how many times they are needed.
We have further shown that pruning, garbage collection, andtraining algorithms may be successfully incorporated into a chart parser for stochastic language models.The layers of regular grammars used in the experiments are completely compatible with a unificationgrammar framework.
We believe that the further development ofefficient parsers for stochastic unificationgrammars i a required step toward spoken language systems.
Future work will focus on development of theseparsers, grammars that make effective use of contextual information, and more robust distance measuresthat comprehend this information.254AcknowledgmentsWe would like to thank George Doddington for much assistance with the FSA system, for invaluable insight onpruning and garbage collection, for sharing his expertise on HMMs, and for providing the digit experiments.We would also like to thank Jack Godfrey for sharing his knowledge on phonetics for many experiments.References\[1\] A. V. Aho and T. G. Peterson, "A Minimum Distance Error-Correcting Parser for Context-Free Lan-guages," SIAM Journal on Computing, Vol.
1, No.
4, Dec. 1972.\[2\] G. R. Doddington, "Phonetically Sensitive Discriminants for Improved Speech Recognition," Proc.ICASSP, Glasgow, Scotland, 1989.\[3\] J. Earley, "An Efficient Context-Free Parsing Algorithm," CACM, Vol.
13, No.
2, 1970, pp.
94-102.\[4\] K. S. Fu, Syntactic Pattern Recognition and Applications, Prentice-Hall, 1982.\[5\] C. T. Hemphill, I. Mani, and S. L. Bossie, "A Combined Free-Form and Menu-Mode Natural LanguageInterface," Abridged Proc.
of the Snd Intl.
Conf.
on Human-Computer Interaction, Honolulu, Hawaii,1987.\[6\] C. T. Hemphill and J. Picone, "Speech Recognition in a Unification Grammar Framework," Proc.ICASSP, Glasgow, Scotland, May 1989.\[7\] F. Kubala, Y. Chow, A. Derr, M. Feng, O. Kimball, J. Makhoul, P. Price, J. Rohlicek, S. Roucos, R.Schwartz, and J. Vandegrift, "Continuous Speech Recognition Results of the BYBLOS System on theDARPA 1000-Word Resource Management Database," Proc.
ICASSP, 1988, pp.
291-294.\[8\] K. Lee and H. Hon, "Large-Vocabulary Speaker-Independent Continuous Speech Recognition usingHMM," Proc.
ICASSP, 1988, pp.
123-126.\[9\] I. Mani and C. T. Hemphill, "A Natural Language Interface for Knowledge Based Systems," Proc.
ofThird Annual User-System Interface Conf., Austin, TX, Feb., 1988.\[10\] H. Ney, "Dynamic Programming Speech Recognition using a Context-Free Grammar," Proc.
ICASSP,1987, pp 3.2.1-4.\[11\] A. Paeseler, "Modification of Earley's Algorithm for Speech Recognition," Proc.
of NATO ASI, BadWindsheim, 1987.\[12\] F. C. N. Pereira, and D. H. D. Warren, "Parsing as Deduction," Proc.
of ACL, Boston, MA, June, 1983.\[13\] J. Picone, G.R.
Doddington, and J.J. Godfrey, A Layered Grammar Approach To Speaker IndependentSpeech Recognition," presented at the 1988 Speech Recognition Workshop, Harriman, NY, June 1988.\[14\] P. Price, W. Fisher, J. Bernstein, and D. Pallett, "The DARPA 1000-Word Resource ManagementDatabase for Continuous Speech Recognition," Proc.
ICASSP, NY, NY, April, 1988.\[15\] S. M. Shieber, An Introduction to Unification-Based Approaches to Grammar, CSLI Lecture Notes, No.4, 1986.\[16\] Tomita, M., "An Efficient Word Lattice Parsing Algorithm for Continuous Speech Recognition," Proc.ICASSP, Tokyo, 1986, pp.
1569-1572.\[17\] T. Winograd, Language as a Cognitive Process, Addison-Wesley, 1983.255
