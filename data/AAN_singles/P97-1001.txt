Interleaving Universal Principles And RelationalConstraints Over Typed Feature LogicTh i lo  G i i t z  and Detmar  MeurersSFB 340, Univers i t~t  T i ib ingen,  Kleine Wi lhe lmstraf le  113,72074 T i ib ingen,  Germany.
{tg, dm}~sf s. nphil, uni-tuebingen, deAbstractWe introduce a typed feature logic system providingboth universal implicational principles as well as defi-nite clauses over feature terms.
We show that such anarchitecture supports a modular encoding of linguistictheories and allows for a compact representation usingunderspecification.
The system is fully implementedand has been used as a workbench to develop and testlarge HPSG grammars.
The techniques described inthis paper are not restricted to a specific implementa-tion, but could be added to many current feature-basedgrammar development systems.In t roduct ionA significant part of the development of formalisms forcomputational linguistics has been concerned with find-ing the appropriate data structures to model the lin-guistic entities.
The first order terms of Prolog andDCGs were replaced by feature structures in PATR stylesystems, 1 and in recent years systems using typed fea-ture structures have been developed.Following the tradition of DCG and PATR, these typedfeature systems are generally definite clause based, e.g.,CUF (D5rre and Dorna 1993), or phrase structure based,e.g., ALE (Carpenter and Penn 1994).
Instead of per-mitting the grammar writer to express universal well-formedness constraints directly, the systems require thegrammar writer to express relational constraints andattach them locally at the appropriate places in thegrammar.
2We believe there are several reasons why the advancesin the linguistic data structures hould entail the de-velopment of systems offering more expressive meansfor designing grammars.
Using universal implicativeconstraints, or universal principles as they are usuallycalled in the linguistic literature, grammatical generali-1Cf.
Shieber (1986) for a discussion of these formalisms.2ALE has a restricted form of universal constraints, eethe comparison section.sations can be expressed in a more compact and modu-lar way.
Another advantage of an architecture includ-ing principles is that it computationally realizes the ar-chitecture assumed in Pollard and Sag (1994) for HPSG.It thus becomes possible to develop and test HPSG gram-mars in a computational system without having to re-code them as phrase structure or definite clause gram-mars.
The architecture can also serve as extended ar-chitecture for principle based parsing (e.g., Stabler andJohnson 1993) since it facilitates the implementation fGB-style universal principles.
Offering both more per-spicuous grammar code and closeness to linguistic the-ory, it seems well motivated to explore an architecturewhich allows both relational constraints and universalrestrictions to be expressed.Our implementation is based on the idea to compileimplicational constraints into a relational representa-tion (GStz and Meurers 1995) where calls to the con-straint solver are made explicit.
This allows for anintegration of implicational and relational constraintsand a uniform evaluation strategy.
Efficient processingis achieved through user-supplied elay patterns thatwork on both relations and implicational constraints,as well as preferred execution of deterministic goals atrun-time.The paper is organised as follows.
We will start outby illustrating our architecture with an example.
Wethen go on to describe the key aspects of the imple-mentation.
We compare our work to other approachesbefore presenting some conclusions and open issues inthe last section.Mot ivat ing  the  arch i tec tureConsider the Head Feature Principle (HFP) of Pollardand Sag (1994) as an introductory example for a gram-matical principle.
The HFP requires that in a headedconstruction the head features of the mother are iden-tified with the head features of the head daughter.
In atyped feature logic 3 this may be expressed by the prin-ciple shown in Fig.
1.phrase A dtrs : headed-struc -+synsem : loc : cat : head : X Adtrs : head-dtr : synsem : loc : cat : head : XFigure 1: A Head-Feature PrincipleIn CUF, we can encode the HFP as a clause defining aunary relation hfp as shown in Fig.
2.
4h/p := synsem : loc : cat : head: X Adtrs : head-dtr : synsem : loc : cat : head : XFigure 2: A relation encoding the HFPFor the relation hfp to take effect, calls to it needto be attached at the appropriate places.
Expressinggrammatical constraints in such a way is both time con-suming and error prone.Suppose we want to define the unary relation wf-phrase to hold of all grammatical phrases.
In case allgrammatical phrases are constrained by a term ?
andsome relation P, we can define the relation wf-phraseshown in Fig.
3.w/-phrase := phrase A ?
A PFigure 3: Defining the relation wf-phraseTo specify that ?
A P holds for all phrases while theHFP only holds for headed phrases, we now have to man-ually split the definition into two clauses, the subcasewe want to attach the HFP to and the other one.This is both inelegant and, barring a clever indexingscheme, inefficient.
Using universal principles on theother hand, the global grammar organisation does notneed to account for every possible distinction.
The or-ganisation of the data structure as typed feature struc-tures already provides the necessary structure and thegrammatical constraints only need to enforce additionalconstraints on the relevant subsets.
Thus, the implica-3Following King (1989) and Carpenter (1992), we usea typed feature logic with appropriateness re trictions forthe domains and ranges of features.
For space reasons wecannot provide a formal definition of the logic here, butthe interested reader is referred to Carpenter (1992) for anexposition.4Throughout the paper and as syntax for the systemdiscussed here we use the functional style notation of CUE(DSrre and Dorna 1993) for our relations, where a desig-nated result argument is made explicit.
The denotation ofa relation thus is a set of objects just like the denotation ofany other feature term.w\]-phrase := phrase A dtrs : headed-strucA h~pA CAPwf-phrase := phrase  A dtrs : -~headed-strucACAPFigure 4: Splitting up the wf-phrase relation to accom-modate the HFP calltional constraint encoding the HFP shown in Fig.
1 con-strains only the headed phrases, and the non-headedones do not need to be considered.Finally, a system providing both universal principlesand relational constraints at the same level offers alarge degree of flexibility.
While in ttPSG theories theprinciples usually form the main part of the grammarand relations uch as append are used as auxiliary con-straints called by the principles, a more traditional kindof grammar for which one prefers a relational organisa-tion can also be expressed more compactly by addingsome universal principles constraining the arguments ofthe relations to the relational core.
Both kinds of inter-action are possible in the non-layered architecture wepropose.With respect o our example, the first kind of inter-action would be obtained by also expressing the generalrestriction on phrase as a universal constraint as shownin Fig.
5, while the more traditional kind of grammarphrase  -+ CAPFigure 5: A universal constraint on phraseswould keep the relation defining well-formed phrasesshown in Fig.
3 and combine it with the universal con-straint of Fig.
1 in order to avoid splitting up the re-lation as was shown in Fig.
4.
The proper interactionof relational and universal constraints then needs to betaken care of by the system.An  example  grammarTo further motivate our approach, we now show howto code a simple principle based grammar in our frame-work.
Figure 6 shows the inheritance hierarchy of typeswhich we will use for our example with the appropri-ateness conditions attached.Our example grammar consists of some universalprinciples, phrase structure rules and a lexicon.
Thelexicon and phrase structure rules are encoded in thewfs (well-formed sign) relation shown in Fig.
7 and theimplicational principles in Fig.
8.
The wfs predicatetakes three arguments: a difference list pair threadingthe string through the tree in the style of DCGS, andlevelz e r o ~ ~ o ~  ~ s t/ I I e-list rne-list 1 ~ /  / I Ltlhdlast:mJverb noun adj p ry  \[I atomi ign \] ead catbar level Iubcat list JpW?rdatom\] rphrase sign\] hon Ihead-dtrLcomp-dtr sign\]arthur sleeps loves tintagelFigure 6: A type hierarchythe syntactic ategory (sign) as functional style resultargument, s The analysis tree is encoded in two daugh-ters features as part of the syntactic ategories in thestyle of HPSG.
Clause 1 of wfs combines a verbal projec-tion with its subject, and clause 2 with its complements.The lexical entries for the verbs "loves" and "sleeps" arespecified in clauses 3 and 4, respectively.
Finally, clause5 defines lexical entries for the proper names "Arthur"and "Tintagel".Now consider the principles defined in Fig.
8.Constraints 1-4 encode a simple version of X-bar theory,constraint 5 ensures the propagation of categorial infor-mation along the head path, and constraint 6 ensuresthat complements obey the subcategorization require-ments of the heads.We may now ask the system for a solution to querieslike wfs(\[arthur, sleeps\], D).
The solution in this case isthe AVM in Fig.
9.We can also query for a term like word A subcat :he-list and check it against the implications alone, asit contains no relational goals.
The result in Fig.
10shows that our X-bar principles have applied: bar leveltwo requires that the subcat list must be empty, and barlevel one can only appear on phrases.
The system thuscorrectly infers that only bar level zero is possible.5We use standard abbreviatory bracket notation for lists.1.
wfs(PO,P) :--phrase A head : verb A subeat : \[\] Abar : two A comp-dtr : wfs(PO, P1) Ahead-rift : wfs( P1, P)2. wfs(PO, P) :=phrase A head : verb A subcat : ne-list Ahead-dtr : wfs(PO, P1) Aeomp-dtr : wfs(P1, P)3. wfs(\[XlY\],Y) :=word A head : verb A bar : zero Asubcat : \[head : noun, head : noun\] Aphon : (loves A X)4. wfs(\[X\[Y\],Y) :=word A head : verb A bar : zero Asubcat : \[head : noun\] h phon : (sleeps A X)5. wfs(\[XIY\],Y) :=word A head : noun Abar : two A subcat : \[\] Aphon : ( ( arthur V tintageO A X)Figure 7: Phrase structure rules and the lexicon1.
bar: zero -+ word2.
bar: one ~ head-dtr : bar: (-~two)3. bar:two -~ subcat : \[ \]4. phrase -~ comp-dtr : bar : two5.
phrase --~ head : X A head-dtr : head : X6.
phrase --+ comp-dtr : X A subeat : Y Ahead-dtr : subcat : \[XIY \]Figure 8: X-bar theory, head feature principle and sub-cat principleThe advantages of such a modular encoding of gram-matical principles are obvious.
The intuition behindthe constraints i clear, and new rules are easily added,since the principles apply to any rule.
On the otherhand, one can experiment with individual principleswithout having to change the other principles or rules.Finally, the option of encoding rammatical constraintsas either implicational constraints or relations opens thepossibility to chose the encoding most naturally suitedto the specific problem.
We feel that this improves onearlier, purely definite-clause-based approaches.Imp lementat ionCompi la t ion  Building on the compilation methoddescribed in GStz and Meurers (1995), our compiler"phraseBAR t~oHEAD \[\] verbSUBCAT \[\]\[w?rd r\] PHON arthltCOMP-DTR \[\] /BAR tWO \[IHEAD noun \]LSUBCAT e-list J-wordPHON sleepsBAR zeroHEAD-DTR HEAD \[\]\[ne-list tl~UBCAT /HD \[\]\[TL \[\] e-lisFigure 9: Solution to the query wfs(\[arthur, sleeps\], H)word zero \]BARSUBCAT ne-listJFigure 10: Solution for the query wordA subcat : ne-listcollects the types for which principles are formulated,defines a relational encoding of the principles, and at-taches calls to the relations at the places in the gram-mar where a constrained type can occur.
We assumethat the grammar writer guarantees that each type inthe grammar is consistent (for a grammar G and ev-ery type t there is a model of G that satisfies t).
Onetherefore does not need to attach calls to each possibleoccurrence of a constrained type, but only to those oc-currences where the grammar contains additional spec-ifications which might lead to an inconsistency (GStzand Meurers 1996).
The interpretation of the resultingprogram is lazy in the sense that we do not enumer-ate fully specific solutions but compute more generalanswers for which a grammatical instantiation is guar-anteed to exist.
A good example for this behaviour wasshown in Fig.
10: the system does not instantiate thePHON and the HEAD values of the solution, since theexistence of grammatical values for these attributes isindependent of the query.A way in which we deviate from the compilationmethod of GStz and Meurers (1995) is that our sys-tem performs all constraint inheritance at compile-time.While inheriting all principles to the most specific typesand transforming the resulting constraints to a disjunc-tive normal form can significantly slow down compiletimes, the advantage is that no inheritance needs tobe done on-line.
To influence this trade-off, the usercan instruct the system to hide a disjunctive principlein an auxiliary relation in order to keep it from beingmultiplied out with the other constraints.
Such auxil-iary relations, which will be discussed further in con-nection with the delay mechanism, have turned out tobe especially useful in conjunction with principles withcomplex antecedents.
The reason is that our compilertransforms an implication with complex antecedents oan implication with a type antecedent.
The negationof the complex antecedent is added to the consequent,which can result in highly disjunctive specifications.Interpretation As a guiding principle, the inter-preter follows the ideas of the Andorra Model 6 inthat it always executes deterministic goals before non-deterministic ones.
We consider determinacy only withrespect o head unification: a goal is recognised to bedeterminate if there is at most one clause head thatunifies with it.
This evaluation strategy has two ad-vantages: it reduces the number of choice points to aminimum, and it leads to early failure detection.
Inour implementation, the overhead of determining whichgoals are determinate has turned out to be by far out-weighed by the reduction in search space for our lin-guistic applications.
An additional speed-up can be ex-pected from applying known pre-processing techniques(Santos Costa, Warren, and Yang 1991) to automati-cally extract so-called determinacy code.The execution order of non-determinate goals can beinfluenced by the user with wait declarations (Naish1985).
The execution of some goal is postponed un-til the call is more specific than a user-specified term.Speculative computation may thus be reduced to a nec-essary minimum.
For our previous example, we mightdefine the delay statements in Fig.
11.
The first state-delay(wfs,argl:list)delay(phrase,subcat:list)delay_deterministic(sign)Figure 11: Controlstatementexamplesment says that calls to wfs must be delayed until thefirst argument is instantiated to some list value.
Sim-ilarly, the second statement delays the principles onphrase until the subcat information is known.
, Thethird statement is of a slightly different form, based onthe preferred treatment of determinate goals describedabove.
Instead of specifying the instantiation state re-quired for execution, the delay_deterministic statement6Cf.
Haxidi and Janson (1990) and references citedtherein.4specifies that the universal principles about signs canonly be executed in case they are determinate.The delay mechanism for relational goals is very closeto the one used in CUF.
We extended this mechanismto the universal principles: the constraints on a certaintype were only checked, once certain attributes weresufficiently instantiated (w.r.t.
the delay statement).Our experience has shown, however, that delaying uni-versal principles in such a way turns out to be too weak.Instead of delaying all constraints on a type until somecondition is met, one wants to be able to postpone theapplication of some particular universal principle.
Asubcategorization principle applying to phrases, for ex-ample, should be delayed until the valence requirementsof the mother or the daughters are known.
We thereforeallow the user to name a principle and supply it with aspecific delay.
Internally, this corresponds to introduc-ing an auxiliary relation under the name supplied bythe user and delaying it accordingly so that the choicepoints introduced by the principle are hidden.Let us illustrate the problem and its solution with aschematic example.
Suppose the grammar writer writesa principle ?
--4 ?.
Our compiler will generate from thisa constraint  --~ (-~?)
V (?
A ?
), for some appropriatetype t. If ?
is a complex conjunctive description, thenthe result of normaiising -~?
might be highly disjunc-tive.
This has two undesirable consequences.
Firstly,if there is another constraint  --4 ~ with disjunctive ~,then the compiler will need to normalise the expression((-~?)V(?A?))A~.
This is the appropriate thing to do inthose cases where many of the generated isjuncts areinconsistent and the resulting disjunction thus turns outto be small.
If, however, these constraints talk aboutdifferent parts of t's structure, then the resulting dis-junction will be big and the expansion at compile-timeshould be avoided.The other problem is that we can only specify delayson all constraints on t at once, and cannot delay indi-vidual principles.
In other words, the control for theexecution of principles is not fine-grained enough.We solved these problems by offering the user thepossibility to name constraints, e.g., principle1 : ?
--4 ?.This prohibits the compile-time cross-multiplication de-scribed above, and it allows the user to specify delaysfor such a principle, e.g.
de lay(pr inc ip le l  .
.
.
.
)or even delay_deterministic (principlel), if that isappropriate.Debugg ing  Having addressed the key issues behindcompilation and interpretation, we now turn to a prac-tical problem which quickly arises once one tries to im-plement larger grammars.
On the one hand, the com-plex data structures of such grammars contain an over-whelming number of specifications which are difficultto present to the user.
On the other hand, the in-teraction of universal principles and relations tends toget very complex for realistic linguistic theories.
Whilea powerful graphical user interface 7 solves the presen-tation problem, a sophisticated tracing and debuggingtool was developed to allow stepwise inspection of thecomplex constraint resolution process.
The debuggerdisplays the feature structure(s) to be checked for gram-maticality and marks the nodes on which constraintsstill have to be checked.
As a result of the determinacycheck, each such node can also be marked as failed,delayed or deterministic.
Similar to standard Prologdebuggers, the user can step, skip, or fail a constrainton a node, or request all deterministic processing tobe undertaken.
An interesting additional possibility fornon-deterministic goals is that the user can inspect hematching defining clauses and chose which one the sys-tem should try.
Figure 12 below shows a screen shot ofthe debugger.The debugger has turned out to be an indispensabletool for grammar development.
As grammar size in-creases, it becomes very difficult to track down bugsor termination problems without it, since these prob-lems are often the result of some global interaction andthus cannot be reduced to a manageable sub-part of thegrammar.The reader interested in further practical aspects ofour system is referred to (GStz and Meurers 1997)Compar i son  w i th  prev ious  workThere are quite a number of typed feature systemsavailable today, among them ALE (Carpenter and Penn1994), CUF (DSrre and Dorna 1993) and TFS (Emeleand Zajac 1990; Emele 1994).TFS also offered type constraints and relations and toour knowledge was the first working typed feature sys-tems.
However, it had some serious drawbacks.
TFSdid not allow universal principles with complex an-tecedents, but only type constraints.
And the systemdid not include a delay mechanism, so that it was oftenimpossible to ensure termination or efficient processing.The addition of a delay mechanism as described in thispaper would certainly increase the efficiency of TFS.ALE provides relations and type constraints (i.e., onlytypes as antecedents), but their unfolding is neitherlazy, nor can it be controlled by the user in any way.7To view grammars and computations our system usesa GUI which allows the user to interactively view (parts of)AVMS, compare and search AVM8, etc.
The ouI comes with aclean backend interface and has already been used as front-end for other natural anguage applications, e.g., in VERB-MOBIL.
The GUI was developed by Carsten Hess.5This can lead to severe termination problems with re-cursive constraints.
The ALE type constraints were de-signed to enhance the typing system, and not for recur-sive computation.
This should be done in the phrasestructure or procedural attachment part.
However, webelieve that the addition of delaying and an interpre-tation strategy as described in this paper would add tothe attractiveness of ALE as a constraint-based gram-mar development platform.The definite clause part of our system is very similarto the one of CUF: both use delay statements and pre-ferred execution of deterministic goals.
Although CUFdoes not offer universal principles, their addition shouldbe relatively simple.
Given that CUF already offers thecontrol strategies required by our scheme, the changesto the run-time system would be minimal.Conc lus ion  and  fu ture  researchWe have presented an architecture that integrates rela-tional and implicational constraints over typed featurelogic.
We showed how such an architecture facilitatesthe modular and compact encoding of principle basedgrammars.Our implementation has been tested with severalsmaller and one large (> 5000 lines) grammar, alinearisation-based grammar of a sizeable fragment ofGerman (Hinrichs et al 1997).
As the grammarconstraints combine sub-strings in a non-concatenativefashion, we use a preprocessor that "chunks" the inputstring into linearisation domains, which are then fedto the constraint solver.
With our Prolog based inter-preter, parse times axe around 1-5 sec.
for 5 word sen-tences and 10-60 sec.
for 12 word sentences.
It shouldbe pointed out that parsing with such a grammar wouldbe difficult with any system, as it does neither have norallow the addition of a context-free backbone.We are currently experimenting with a C based com-piler (Zahnert 1997) using an abstract machine with aspecialised set of instructions based on the WAM (War-ren 1983; A~-Kaci 1991).
This compiler is still underdevelopment, but it is reasonable to expect speed im-provements ofat least an order of magnitude.
Abstract-machine-based compilation of typed feature logic lan-guages has recently received much attention (Carpenterand Qu 1995, Wintner 1997, Penn in prep.).
True com-pilation is the logical development in a maturing fieldthat has hitherto relied on interpreters in high-level pro-gramming languages such as Prolog and Lisp.We also plan to investigate a specialised constraintlanguage for linearisation grammars, to be able to opti-raise the processing of freer word order languages suchas German.ReferencesAi-Kaci, H. (1991).
Warren's Abstract Machine.
MITPress.Carpenter, B.
(1992).
The logic of typed feature struc-tures, Volume 32 of Cambridge Tracts in Theo-retical Computer Science.
Cambridge UniversityPress.Carpenter, B. and G. Penn (1994).
ALE - The At-tribute Logic Engine, User's Guide, Version 2.0.1,December 1994.
Technical report, Carnegie Mel-lon University.Carpenter, B. and Y. Qu (1995).
An abstract ma-chine for attribute-value logics.
In Proceedings ofthe Fourth International Workshop on ParsingTechnology.
Prague.DSrre, J. and M. Dorna (1993, August).
CUF -a formalism for linguistic knowledge representa-tion.
In J. DSrre (Ed.
), Computational spects ofconstraint based linguistic descriptions I, pp.
1-22.
Universit~it Stuttgart: DYANA-2 DeliverableR1.2.A.Emele, M. C. (1994).
The typed feature structurerepresentation formalism.
In Proceedings of theInternational Workshop on Sharable Natural Lan-guage Resources, Ikoma, Nara, Japan.Emele, M. C. and R. Zajac (1990).
Typed unifica-tion grammars.
In Proceedings of the 13 th Inter-national Conference on Computational Linguis-tics.GStz, T. and W. D. Meurers (1995).
CompilingHPSG type constraints into definite clause pro-grams.
In Proceedings of the Thrirty-Third An-nual Meeting of the A CL, Boston.
Association forComputational Linguistics.GStz, T. and W. D. Meurers (1996).
The importanceof being lazy - using lazy evaluation to processqueries to HPSG grammars.
In P. Blache (Ed.
),Acres de la troisi~me confdrence anuelle sur letraitment automatique du langage naturel.GStz, T. and W. D. Meurers (1997).
The ConTrollsystem as large grammar development platform.In Proceedings of the A CL/EA CL post-conferenceworkshop on Computational Environments forGrammar Development and Linguistic Engineer-ing, Madrid, Spain.Haridi, S. and S. Janson (1990).
Kernel Andorra Pro-log and its computation model.
In D. H. D. War-ren and P. Szeredi (Eds.
), Proceedings of the sev-enth international conference on logic program-ming, pp.
31-46.
MIT Press.6Hinrichs, E., D. Meurers, F. Richter, M. Sailer,and H. Winhart (1997).
Ein HPSG-Fragment desDeutschen, Teil 1: Theorie.
Arbeitspapiere desSFB 340 Nr.
95, Universit~it Tiibingen.King, P. J.
(1989).
A logical formalism for head-driven phrase structure grammar.
Ph.
D. thesis,University of Manchester.Naish, L. (1985).
Negation and Control in Prolog.Springer-Verlag.Penn, G. (in prep.).
Statistical Optimizations in aFeature Structure Abstract Machine.
Ph.D. the-sis, Carnegie Mellon University.Pollard, C. and I.
A.
Sag (1994).
Head-DrivenPhrase Structure Grammar.
Chicago: Universityof Chicago Press.Santos Costa, V., D. H. D. Warren, and R. Yang(1991).
The Andorra-I preprocessor: Supportingfull Prolog on the Basic Andorra model.
In Pro-ceedings of the Eighth International Conferenceon Logic Programming, pp.
443-456.Shieber, S. M. (1986).
An Introduction to Unifi-cation-Based Approaches to Grammar.
Number 4in CSLI Lecture Notes.
Center for the Study ofLanguage and Information.Stabler, E. P. and M. Johnson (1993).
Topics in prin-ciple based parsing.
Course notes for the 1993LSA Summer Institute.Warren, D. H. D. (1983).
An abstract Prolog instruc-tion set.
Technical note 309, SRI International.Wintner, S. (1997).
An Abstract Machine for Unifi-cation Grammars.
Ph.D. thesis, Technion, Haifa,Israel.Zahnert, A.
(1997).
fl2c - ein Compiler ffirCLP(TFS).
Diplomarbeit, Fakult/it f/ir Infor-matik, Universit/it Tiibingen.7" ? "
' "  IJPort: 3CALLtl:ion 171 1./.$~asem " ~lo? '
l ayoat ca~head\ [ \ ]frontedoonstl~l siv@le wordphon \[~"< z'az,r/a >s~ns  era \[ ~/zoo ~r~ / /oat\[ ~L~atu~ ~,~status co~p1e~eI spnsem\[ sy~se~I / lool'z~I / /?atr  ' ' '?I / / Iva-'-r'~ I / \[ \[ L??
'~"s<-L>\[ Lstatus ~o~.l'e ~aadtr \[\] \[ ~,.2~ze..,,~z-d 1phon ~ ~ IIspnsem F ~ 11l ,l cat ca~ head \ [ \ ]append_string ( \ [ \ ]  , \[51 <> \ [ \ ]  )~append_st r iug  ( \[\] \ [ \ ]  \ [ \ ]  ) JIpp_adj rip ( \ [ \ ]  , < \ [ \ ]  \ [ \ ]  < I~ l l ' s .~.ze  word  l f f~l  <> > >/~hon ,1 / s~,ns erar syr ,~ l poor~.
::> :!
"i .~JI phrasq41k cmep.
;~,,L skip ~'v'~ unfoM?
31 F~_:'~Figure 12: A screen shot of the graphical debugger8
