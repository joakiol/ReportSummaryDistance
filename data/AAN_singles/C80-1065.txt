PRESENT AND FUTURE PARADIGMSIN THE AUTOMATIZED TRANSLATION"OF NATURAL LANGUAGES.Ch.
BOITET, P. CHATELIN, P. DAUN FRAGAGETA, F-38041 GRENOBLE CEDEX 53X, PRANCE.AbstractUseful automatized translation must beconsidered in a problem-solving setting,composed of a linguistic environment and acomputer environment.
We examine the facets ofthe problem which we believe to be essential,and try to give some paradigms along each ofthem.
Those facets are the linguistic strategy,the programming tools, the treatment of seman-tics, the computer environment and the types ofimplementation.IntroductionMachine Translation has been a recurringtheme ~n applied linguistics and computerscience since the early fifties.
Having not yetattained the enviable status of a science, itis best considered as an art in the same way asKnuth considers computer programming.
Failure torecognize that MT must be treated in a problem-solving setting, that is, as a class of problemsto be solved in various environments and accor-ding to various quality and cost criteria, hasled and still leads to impassionate, antiscien-tific attitudes, ranging polemically betweendreamy optimism and somber pessimism.
Using thefairly large body of experience gained since thebeginning of MT research, we try in this paperto extract the most essential facets of theproblem and to propose some paradigms, alongsideeach of those facets, for usable computersystems which should appear in the near - ormiddle - term future.As a matter of fact, the phrase 'MachineTranslation" is nowadays misleading and inade-quate.
We shall replace it by the more appro-priate term "Automatized Translation" (ofnatural languages) and abbreviate it to AT.Part I tries to outline the problemsituations in which AT can be considered.
Thefollowing parts examine the different facets inturn.
Part II is concerned with the linguisticstrategy, Part III with the programming tools,Part IV with semantics, Part V with the computerenvironment and Part VI with possible types ofimplementation.I - Applicability, quality and cost : a problemsituation.1.
The pastAutomatized translation systems were firstenvisaged and developed for informationgathering purposes.The output was used by specialists to scanthrough a mass of documents, and, as RADC userreport shows \[49\], the users were quite satisfied.This is no more the case with the growing needfor the diffusion of information.
Here, thefinal output must be a good translation.
Secondgeneration systems were designed with this goalin mind, and with the assumption that goodenough translations cannot nOW be obtained auto-matically on a large scale, but for very res-tricted domains (see METEO).
Hence, a realisticstrategy is to try to automate as much aspossible of the translation proc~s.
This is theapproach taken by GETA, TAUM, LOGOS, PROVOH andmany others.
Here, the problem is to answerexisting needs by letting man and machine worktogether.Another approach comes from AI and isbest exemplified in \[9\].
Here, the goal is moretheoretical : how to simulate a human producingcompetent translations ?
We will argue that themethods developed in this framework are not yetcandidates for immediate applicability.PARADIGM 1 : Future MT systems wil l  beAT (automated) systems rather than completeleyautomatic systems.2.
ApplicabilityAutomated translation is clearly neededby large organizations as the EC or big indus-tries having to translate tens or hundreds ofmillions of pages per year.
Translations arevery often urgent, and there is a human impossi-bility, as translations needs increase muchfaster than the number of available translators.Translators are specialized to certainkinds of texts.
In the same way, AT systems,which are costly to develop and maintain, shouldbe tailored to some kind of texts : AT is appli-cable when there is a constant flow of veryhomogeneous and repetitive texts, hopefullyalready in machine-readable form.
AT shouldallow to integrate automatic rough translationand human on- or off- line revision.3.
QualityThis is a crucial point, when it comesto acceptability by revisors and/or end-users.The quality of translation is a very subjectivenotion, relative to the need and knowledge ofthe reader.
Traditional counts of grammaticalerrors, false senses,nansenses give onlyindications.- 430-We believe that quality should be esti-mated by the amount of revision work needed, tocompare it with human (rough) translation, whichis also very often of poor quality.
As errors ofAT systems are certain to be different from tho~of humans, revisors must have a certain trainingbefore such a comparison can be made.Another measure could be to compare finaltranslations, with the same amount of revision.We believe this not to be realistic, as costmust also be taken into account : translatorswill turn to revision, which is much faster thantranslation, so that they will gain time even ifthey work for revision.4.
CostThe cost of AT should be divided into thecosts of development, maintenance and use.
It isof course related to the linguistic and computerenvironments.
First, the graph of language-pairsshould be considered, as development costs foran analyzer, say, may be charged to differentpairs with the same source, of course if a~a-lys~ and synthesis are str ict ly  monolingual.Easy maintenance calls for sophisticatedcomputer systems having an interactive data-b~easpect and concise metalanguages with good,incremental compilers.Machine time tends to be a minor componentof the cost of use.
Important savings come fromthe integration of the human revision in the ATsystem (see TAUM, LOGOS, GETA), as no furthertyping is required.5.
Text typologyAT systems developed for simple texts willcertainly be less expensive (and probably better)than those for complex texts.
Let use give atentative hierarchy.
The easiest texts are per-haps already preedited abstract~ regularlyentered into data bases.
Then come abs~y~a0~,which may present surprising difficulties mainlydue to the tendency to write everything in onelong and badly constructed sentence.Technical documentation, maintenancemanuals, etc.
are more and more written in asystematic way, which permits to tailor an ATsystem to their form and their content.
Seehowever TAUM-AVIATION reports for a soberingview on their apparent facility !
Minutes ofmeetings and working document~ may be s t i l lharder.Newspaper articles, even on scientificsubject matters, tend to accumulate difficultor incorrect constructions, and also to jump faraway from the current subject matter.Until AI methods ("third" or "fourth")generation are practicable with really largedata, we don't believe AT systems should eventry to handle literary, normative or diplomatictexts.
Revision would just be a new translation.PARADIGM 2 : AT systems are now applicableonly in restr icted environments and must betai lored to part icular 'kinds of texts.II - Linguistic strategyI.
Multilingual or pair-oriented systems ?Almost all AT systems divide the processof translation in three main logical steps, ana-lysis, transfer and synthesis.
At one extreme,some systems (like METEO) are strongly orientedtowards a particular pair of languages.
Thismeans that analysis of the source language isperformed with the knowledge of the target lan-guage.
Target lexical units may appear duringanalysis, and syntactic or semantic ambiguitiesin the source are handled contrastively.The other extreme is the complete indepen-dence of analysis and synthesis.
This is theapproach taken in multi l ingually oriented sys-tems (like ARIANE-78 \[7, 36, 50\], SUSY \[51\],SALAT \[18, 20\], TAUM/AVIATION \[33\]).
This inde-pendence enhances modularity and economicallyjustified, as analysis or synthesis are writtenonce for each language.
Analysis usually repre-sents at least 2/3 of the programming effort andcomputing time.PARADIGM 3 : We advocate for mult i l ingual lyoriented systems, where the basic softwarei t se l f  guarantees independence of analysis andsynthesis.2.
What kind of analysis ?Should the analysis deliver a structuraldescriptor of the unit of translation, or arepresentation of its meaning, static or dyna-mic ?
With the first approach, the transfer stepincludes necessarily a lexical transfer and astructural transfer.
With the second one, theresult of the analysis is a language-independentrepresentation of the unit of translation (sen-tence, paragraph(s)).
When the lexical unitsthemselves are language-free, as in SAM \[9\], wecall it "pure pivot" approach.
When only therelations between units are language-free, wecall it "hybrid pivot" approach (as in the firstCETA \[34, 35\] system).
In the first case, thereis no transfer, in the second, transfer ispurely lexical.The pivot approach is theoretically veryelegant.
However, past experience with it (on acorpus of more than a mill ion words, seeVauquois (1975)) shows that it is quite inade-quate in real situations, where, very often,this representation cannot be obtained, or notfor all parts of the translation unit.
Also,human professional translators seem very oftento produce quite acceptable results withoutactually abstracting the deep meaning and re-phrasing it, but rather by using standard syn-tactic transformations (like active-passive,reordering of nominal groups, passive-impersonal,splitting up sentences, etc.)
and ... multiple431--choice bilingual dictionaries.
If deep compre-hension fails, it is hence necessary and possibleto fall back on lower levels of information.PARADIGM 4 : The result of analysis shouldbe a structural descriptor of the unit of trans-lat ion,  where the lexical units are s t i l l  sourcelexical units and where the l ingu is t ic  informa-tion is "mult i - level"  : logical relat ions,  syn-tact ic  functions, ~syntactic classes, semanticfeatures (al l  universal for large families oflanguages), and trace information (proper to thesource language).As we argue in Part IV, we don't think theresult of analysis should include a dynamiccomprehension of "what is described to happen",at least in AT systems for the near future.
Letus quote Carbonell & al (1978) : "What kind ofknowledge is needed for the translation of text?Consider the task of translating the followingstory about eating in a restaurant...".
Unfor-tunately, the texts to be translated, as we saidin Part I, are not stories, but rather abstracts,manuals, working documents ... of a very diffe-rent nature.3.
Strategical aspectsThere are some problems the analysis writercan not escape.
Should problems such as ambigui-ties be solved as soon as they appear, or not besolved altogether, or is it better to devisestrategies to decide as late as possible, ormore complex heuristics ?PARADIGM 5 : AT systems to be developed inthe near future should allow complex l inguist icheuristics.
That is ,  we feel that preferencescomputed by the use of weights derived from somefrequency counts are not enough, and that l in -guists should program what they see as beingessential ly heurist ic in the l ingu is t ic  pro-cesses.
Hence further requirements on the pro-gramming tools, which should at least includesuch control structures as controlled non-determinism.I I I -  Programming tools : algorithmic models andmetalanguagesI.
HistoryThe first MT researchers programmed direc-tly in machine language.
Until now, SYSTRANsystems are essentially made of programs andtables written in IBM 370 macroassembler.
Thencame systems based on a simple formal model,like context-free grammars and Q-systems.
Thesesystems rely on a general algorithm over whichthe rules have no control.
Systems allowing suchcontrols (PROLOG \[52\], ATEF \[14, 15\], ROBRA \[50\],ATNs \[47\] and derived models like REZO \[32\],PLATO, DEDUKT \[18, 20\]) were created in theseventies.Now, the programming languages used towrite the linguistic part of AT systems includeusual programming languages such as macro-assembler, FORTRAN, ALGOL, PL/I, LISP, as wellas specialized languages (see above).2.
The need for powerful data and controlstructuresIn our view, usual programming languagesare inadequate as metalanguages to be used forwriting the linguistic data and procedures in anAT system.PARADIGM 6 : Adequate metalanguages shouldinclude bu i l t - in  complex data-types such asdecorated trees and graphs as well as controlstructures for non-deterministic, parallel andheuristi  c programming.Note that parallelism may be of two diffe-rent kinds : processors working independently onindependent data structures and processors wor-king on a common data structure (e.g.
a normalcontext-sensitive grammar is not equivalent tothe same grammar used in parallel, seeS ~ AB,  A ~ a/-B, B ?
b/A-).
Many recent specia-lized programming languages include a form ofnon-determinism, but very few have parallelism(ROBRA) or control functions for heuristics(PROLOG, ATEF, REZO).Of course, these metalanguages shouldinclude more classical control structures suchas iteration, recursion or selection.
Note thatdictionaries are simply big "select" constructs,possibly non-deterministic (one-many).3.
Complexity, decidability, adequacyIf one takes all necessary data-types withall possible operators and all control struc-tures, the model obtained is very likely to havethe (maximal) computing power of a Turing machi-ne.
Hence, no general bound or estimate for thedynamic complexity of programs written in thatformalism may be given.
On the other hand, asall we want to program in AT systems is cer-tainly sdbrecursive, another approach is todefine several subrecursive algorithmic modelswith associated known (or studyable) complexityclasses.
This was the original approach at GETA,with the ATEF, ROBRA, TRANSF and SYGMOR algo-rithmic models, designed to be decidable and oflinear complexity.As a matter of fact, decidability is avery practical requirement.
However, generalconstraints imposed to guarantee decidabilitymay make certain things unnecessarily clumsy towrite.
Perhaps a better idea (implemented inATNs, ATEF and ROBRA) is to build algorithmicmodels as extensions of decidable models, insuch a manner that sources of undecidability areeasy to locate, so that particular decidabilityproofs may be looked for.
For example, the fun-damental operator of ROBRA is the parallelapplication of the rules of a transformationalgrammar to an object tree.432-Normal iteration of this operator must termi-nate, due to some marking mechanism.
However, agrammar in "free" iteration mode may neverterminate.Last, but not least, these algorithmicmodels must be adequate, in the sense of easeand concision of writing.
We sum up withPARADIGM 7 : The complex operators asso-ciated with the data types should be adequate,their complexity (time and space) should bereasonably bounded (O(n) to O(n3) ?)
and thereshould be decidable underlying algorithmicmodels, so that so'urces of undecidability couldeasily be traced.IV - Semanticsi.
Two different notionsSemantics are understood differently inlinguistics, logic and computer science.
In thelatter, attention is focused on the ways ofexpressing data and processes.
A system is saidto be "syntactic" if it operates within theframework of formal language theory, that is bycombinatorial processes on classes or "features'~In a "static" semantic system, there is afixed model of some universe, possibly repre-sented as a thesaurus, or as a set of formulaein some logic, on which a formal language isinterpreted.A system incorporates "dynamic semantics",or "pragmatics", if the interpretation of thedata it processes may alter the model of theuniverse, or create a parallel model of some"situation" in this universe.2.
Classical approachesExisting AT systems of reasonable size,that is incorporating several thousands of lexi-cal units and quite exhaustive grammars, relyessentially on semantics by features.
They maybe quite refined and specialized to a domain(e.g.
METEO), and, in that case, this methodmay give surprisingly good results.Although the basic softwares allows torelate lexical units by using (monolingual orbilingual) dictionaries, this possibility ishardly used in the current applications at TAUMsee TAUM/AVIATION) or at GETA (see \[50\]).
Forinstance, classical relations such as antonymy,generalization, particularization are not codedin the dictionaries.3.
AI proposalsAI proposals fall into two classes.
Thefirst refers essentially to static semantics,and may be illustrated by Wilks' "preferencesemantics" \[37-44\] or Simmons "semantic net-works" \[30\].As applied to AT, these methods have only beenincorporated in very small size test programsincorporating at most some hundreds lexicalunits.
However, we feel that their simplicityand relative economy in coding effort make themusable in near-term AT systems, under the essen-tial condition that, as in Wilks' model, it isnot necessary to code completely every lexicalunit, and that the associated computing effortis controlled by the linguist and undertakenonly when necessary, that is when a problem(like ambiguity or anaphoric reference) has notbeen solved by s~mpler means.The second class of AI proposals relatesto dynamic semantics and originates in the"frames" proposed by Minsky \[12\], and now pro-posed by other teams as "scripts", "plans" or"goals" \[9, 27-29\].
They are certainly veryattractive, but have been demonstrated on veryparticular and very small size situations.As we said above, texts to be translatedwith AT systems are more likely to be technicaldocuments, abstracts, instructions for use, main-tenance manuals, etc., than stories about res-taurants or earthquakes.
Each text doesn't relyon one clear-cut "script", or "type of situa-tion", known a priori.
Rather, such texts veryoften don't describe situations (see a computermanual), or, at the other extreme, their contentmight be understood as ... the description ofhundreds of scripts (see aviation maintenancemanuals).Hence, our objection to the use of suchmethods is twofold.
First, the coding effort,in principle, would be enormous.
Charniak'sframe for painting \[;2\], although admittedlyincomplete, is 19 pages of listing long (in ahigh-level language !
), and we suppose he spentrather a long time on it.
Just think of what itwould cost to code 5000 basic frames, which webelieve would be reasonable for, say, thedomain of computers.
Second, if the texts des-cribe types of situations, then it is necessaryto understand these texts in order to code thenecessary scripts, which will be used ... tounderstand the text again !This circularity has two consequences.First, only very general scripts might be hu-manly coded by using general previous knowledgeabout the domain.
Second, if we want to use suchmethods extensively and at levels of detail atwhich they begin to give better results thansimple approaches, then AI researchers shouldprovide methods for the automatic extraction ofscripts or frames from large bodies of texts, inan efficient (and perhaps interactive) way.
Thatis, the use of such methods on wide domains andlarge amounts of texts entails automatic lear-ning.
Another problem is to automatically findwhich script is relevant to the current portionor text.--433--4.
Concluding remarksAs in other problem-solving situations,simple methods should continue to be used inconjunction with more sophisticated ones.Unfortunately, proponents of "very high" seman-tics seem too often to concentrate on interes-ting high level phenomenaeas anaphoric reference,discourse structure, causality and reasoning andto forget at the same time persisting and veryfrequent lower-level difficulties such as ambi-guity of prepositional group dependency.
TakeRiesbeck's \[25 p. l l \ ]  example ,'John hurt Marybecause Mary informed Bill that John advisedRita to prevent Bill from buying the book bygiving the look to John".
It seems obvious tothe author that "by giving" relates to "prevent".However, it could also relate to "hurt","informed" and "advised" ("buying" being exclu-ded because of the coincidence of reference dueto "the").
Take also Vauquois' example "theminister spoke of the candidate to the presi-dency", and many other occurring with conjunc-tion and enumeration.PARADIGM 8 : Reasonably large scale ATsystems can rely only On semantics by featuresand stat ic semantics in the near future.
Scrip__tl ike methods must be complete d by automaticscript generation and retrieval proceduresbefore they can be used extensively.
Semanticmethods must complete and not discord previousones.V - Computer environment for the usersI.
Essential functions and types of usersThe are different kinds of users of ATsystems, intervening in different ways for dif-ferent purposes, related to the functions ofcreation, maintenance and use.
Specializgdlinguists create the linguistic systems orsubsystems, lexicographs and terminologistscreate and update the dictionaries, revisersand translaters use the system as a tool toproduce translations, and the end user wants toknow nothing about it, but is nevertheless thefinal judge.PARADIGM 9 : A modern AT system mustallow large degrees of interact iv i ty  at ailfunctional levels, be transparent to the user,contain a (possibly specialized) data-basemanagement system (for handling grammars, dic-tionaries, texts and their different versionsas well as intermediate results and stat ist icalinformation) and be integrated (from preeditingand/or checking to revision and (photo)composition).2.
Types of useAt creation time, interactivity is cer-tainly essential, even during parts which willbe fully automatic in a production environment.Perhaps a mode should be provided in which thesystem could ask simple questions (choice ofequivalents, for instance) to a translatorsitting at a screen while doing the automaticrough translation part.
Even that may be toocostly in a production environment.For maintenance and updating of the lin-guistic data, we believe it is essential that anAT system provides ways of feed-back and commu-nication between the different kinds of users,and between users and the system.3.
Human aspectsThe human and social aspects should not beneglected.
To force a rigid system on revisorsand translators is a guarantee of failure.
Itmust be realized that AT can only be introducedstep by step into some preexisting organizatio-nal structure.
The translators and revisors ofthe EC did not only reject Systran because ofits poor quality but also because they feltthemselves becoming "slaves of the machine", andcondemned to a repetitive and frustrating kindof work.PARADIGM I0  : AT systems must be such thatthe users keep control over them, and not viceversa.VI - Types of implementationThis section is voluntarily short, as thisquestion is not particular to AT systems.
Hard-ware requirements for large MT systems arealready met by minicomputers like IBM's 4300series.
Software requirements such as time-sharing and virtual memory are also available.Typically, GETA's current prototype Russian-French translation system executes with a cen-tral memory less than 1,5 Mbyte without anydisk-access during the translation process, anduses 12 Mbytes on disk for linguistic files andthe text data-bases.
If the dictionaries wouldincrease in size to, say, 40000 lexical units(more general than words, or roots), than3 Mbyt~of  virtual memory and 20 to 25 Mbyteson disk would be needed.
Even microcomputersmight support such systems in the (longer term)future.For the time being, such systems may becentralized, and operate on big computers, orbe distributed on minicomputers, possibly lin-ked through a network.
The machine may be dedi-cated or not, and so forth.
In addition to thehardware side, the software side is also impor-tant.
Portability and efficiency are often con-flicting goals.
The implementation language(s)(~0?
the metalanguages) may be low-level(assembler, LP language) or high-level (FORTRAN,PASCAL, PL/I, ALGOL68, LISP, ADA,...).
Anotherpossibility is to devise a special abstractmachine for the metalanguage.434We believe that only the last two solutionsshould be considered, with re~?
portability andefficiency as the main criterion for choosing ahigh-level language.As a likely development, we foresee the useof AT systems first on big computers in largeorganizations, with or without teleprocessing,and then, in bureautics, on local minicomputers.However, some recent experience indicates thatlocal development of user-tailored applicationsmay well be done before bureaucratic inertia inlarge organizations allows decisions to be taken.AcknowledgmentsWe would llke to thank Pr.
Vauquois as aprincipal inspirator of this work, although theerrors are of course ours, and although his ideason some points are certainly more advanced thanthose exposed here in the framework of possiblenear-immediate large scale applications.B IBL IOGRAPHY.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.\[I\] Y. Bar-Hillel (1960), "The present status ofAutomatic Translation of languages" in :Advances in Computers, VI, 91-163.\[2\] Y. Bar-Hillel (1967), "Die Zukunft dermaschinellen Uebersetzung, oder : warumMaschinen das Uebersetzen nicht erlernen",Sprache im technischen Zeitalter, 23.\[3\] Y. Bar-Hillel (1971), "Some reflections onthe present outlook for High Quality MachineTranslation", in : Feasibility study on fullyautomatic high quality translation, (RADC)Univ.
of Texas.\[4\] Ch.
Boitet (1976), "M6thodes s~mantiques enTA", TA-informations n ?
l, 3-42.\[5\] Ch.
Boitet (1976), "Un essai de r~ponsequelques questions th~oriques et pratiquesli6es ~ la traduction automatique.
D6fini-tion d'un syst~me prototype".
Th~se d'Etat,Univ.
de Grenoble.\[6\] Ch.
Boitet (1976), "Probl~mes actuels entraduction automatique.
Un essai de r~ponse",COLING-76, Ottawa, Preprint n ?
33.\[7\] Ch.
Boitet (1977), red., "O~ enest  le GETAd6but 1977 ?
", Comm.
groupie, 3~me congrgseurop~en "Franchir la barri~re linguistique",Luxembourg, p. 599-636.
Also available inEnglish and German.\[8\]\[9\]\ [ io\]\[11\]\[;2\]\[13\]\[14\]\[~5\]\[16\]\[17\]\ [18\ ]\[19\]\[20\]\[21\]\[22\]Ch.
Boitet (1977), "MT and the problem ofunderstanding natural language", colloquefranco-sovi~tique sur la TA, Moscou,dgc.
1977.J.
Carbonnel, R.E.
Cullingford,A.V.
Gershman (1978), "Knowledge basedMachine Translation, RR ~146,  AI Project,Yale Univ., and Proc.
COLING-78, Bergen.E.
Charniak (1975), "A partial taxonomy ofknowledge about actions", ISSCO, WP ~13,Castagnola.E.
Charniak (1975), "Organization and infe-rence in a frame-like system of commonsense knowledge", ISSCO, WP~I4 ,  Castagnola.E.
Charniak (1978), "A framed painting-representation of a common-sense knowledgefragment", Cognitive Science, V2, Nl.J.
Chauch~ (1974), "Transducteurs et arbo-rescences.
Etude et rgalisation de syst~mesappliqugs aux grammaires transformation-nelles".
Th~se d'Etat, Univ.
de Grenoble.J.
Chauch~ (1975), "The ATEF and CETAsystems", TA-informations n ?
2 & AJCL,Microfiche 17, 21-39.J.
Chauch~, P. Guillaume, M. Qu~zel-Ambrunaz (1973), "Le syst~me ATEF",Doc.
GETA G-2600-A, Univ.
de Grenoble.A.
Colmerauer (1971), "Les syst~mes-Q, ouun formalisme pour analyser et synth~tiserdes phrases sur ordinateur", in : TAUM-71,Univ.
de Montreal.R.W.
Floyd (1967), "Non-deterministicalgorithms", JACM, VI4, N4, 636-644.C.
Hauenschild, E. Huekert, R. Maier (1978),"SALAT : Machine Translation via semanticrepresentation", in : B~uerle & al.Th.
Hoffman (1978), "Semantics in aid ofautomatic translation", COLING-78, Bergen.E.
Huckert (1979), "Automatische Synthesedes Franz~sischen aus einer logischenBasis", AQ-Verlag, Dudweiler, Saarland.R.
Kittredge, L. Bourbeau, P. Isabelle(1978), "Design and implementation of anEnglish-French Transfer Grammar", COLING-~,Bergen.N.
Nedobejkine (1976), "Niveaux d'interpr~-tation dans une traduction multilingue :application g l'analyse du russe",COLING-76, Ottawa.--435--\[23\]\[24\]\[25\]\[26\]\[27\]\[282\[29\]\[3o\]\[31\]\[32\]\[33\]\[34\]\[35\]\[36\]\[37\]\[38\]R.
Quillian (1968), "Semantic memory", in :Semantic information processing, MIT Press,216-270.R.
Quillian (1969), "The teachable lan-guage comprehender : a simulation programand a theory of language", CACM, V12, N8,459-476.C.K.
Riesbeck (1974), "Computationalunderstanding : analysis of sentences andcontext", ISSCO, WP~4,  Castagnola, 241 p.E.
Sandewall (1971), "Representing naturallanguage information in predicate calculus",in : Machine Intelligence 6, Meltzer &Mitchie, ed., American Elsevier.R.C.
Shank (\]973), "Identification ofconceptualizations underlying natural lan-guage", in \[48\], 187-247.R.C.
Shank (1974), "Understanding para-graphs", ISSCO, WP~6,  Castagnola.R.C.
Shank, C.J.
Rieger III (1974),"Inference and the computer understandingof natural languages", Artificial intel-ligence 5, 373-412.R.F.
Simmons (1973), "Semantic networks :their computation and use for understandingenglish sentences", in \[48\], 63-113.R.F.
Simmons, J. Slocum (1972), "Generationof english discourse from semantic net-works", CACM, VI5, NIO, 89\]-905.G.
Stewart (1975), "Le langage de program-mation REZO", TAUM, Univ.
de Montreal.TAUM (1979), "Presentation de la cha~ne detraduction informatis~e TAUM/AVIATION",Univ.
de Montreal, 27 mars 1979.B.
Vauquois (1968), "Structures profondeset traduction automatique.
Le syst~me duCETA", Revue Roumaine de linguistique,13, 1057130.B.
Vauquois (1975), "La traductionautomatique ~ Grenoble", Doc.
de Linguis-tique Quantitative n ?
24, Dunod, 184 p.B.
Vauquois (1976), "Automatic translation-a survey of different approaches",COLING-76, Ottawa, and SMIL I, 127-135.Y.
Wilks (1968), "On-line semantic ana-lysis of english texts", MechanicalTranslation, V|;, N3 & 4, 59-72.Y.
Wilks (1972), "Grammar, meaning and themachine analysis of language", RoutledgeLondon, 198 p.\[39\]\[40\]\[41\]\[42\]\[43\]\[44\]\[45\]\[46\]\[47\]\[48\]\[49\]\[5o\]Y. Wilks (1973), "An artificial intelli-gence approach to machine translation",in \[48\], 114-151.Y.
Wilks (1973), "Preference semantics",Stanford AI lab., AIM-206, CS-73-377.Y.
Wilks (1975), "An intelligent analyzerand understander of english", CACM, V\]8,N5, 264-274.Y.
Wilks (1975), "Seven theses on artifi-cial intelligence and natural language",ISSCO, WP~17,  Castagnola.Y.
Wilks (1976), "A preferential, pattern-seeking, semantics for natural languageinference", Artificial Intelligence 6.Y.
Wilks & M. King (1976), "Semantics,Preference and Inference.
A full descrip-tion of a system and a program", ISSCO,WP~18,  Geneva.T.
Winograd (1971), "Procedures as a repre-sentation for data in a computer programfor understanding natural language",AI-TR-17, MIT.T.
Winograd (1973), "Procedural model oflanguage understanding", in \[48\],152-186.W.A.
Woods (1975), "Syntax, semantics andspeech", BBN report n o 3067, AI report n?27.Shank & Colby, ed.
(1973), "Computer modelsof thought and language", Freeman & Co,San Francisco.Z.L.
Pankowicz, technical evaluator (1973),"User's evaluation of machine translationGeorgetown MT system (1963-1973)",RADC-TR-73-239, Univ.
of Texas at Austin.C.
Boitet, N. N~dobejkine (1980), "RussianFrench at GETA : outline of the method anddetailed example", to appear in the Proc.of COLING-80, Tokyo.\[51\] H.D.
Maas (1978), "Das Saarbr~eker Ueber-setzungssystem SUSY", Sprache und Datenve-rarbeitung, 43-62.\[52\] A. Colmerauer, H. Kanoui, M. Van Caneghem(1979), "Etude et r~alisation d'un syst~mePROLOG", Groupe d'Intelligence Artificielle,Univ.
d'Aix-Marseille II.Note : ECAIEuropean CommunityArtificial Intelligence--436-
