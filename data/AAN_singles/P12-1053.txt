Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 506?515,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsStrong Lexicalization of Tree Adjoining GrammarsAndreas Maletti?IMS, Universita?t StuttgartPfaffenwaldring 5b70569 Stuttgart, Germanymaletti@ims.uni-stuttgart.deJoost EngelfrietLIACS, Leiden UniversityP.O.
Box 95122300 RA Leiden, The Netherlandsengelfri@liacs.nlAbstractRecently, it was shown (KUHLMANN, SATTA:Tree-adjoining grammars are not closed un-der strong lexicalization.
Comput.
Linguist.,2012) that finitely ambiguous tree adjoininggrammars cannot be transformed into a nor-mal form (preserving the generated tree lan-guage), in which each production contains alexical symbol.
A more powerful model, thesimple context-free tree grammar, admits sucha normal form.
It can be effectively con-structed and the maximal rank of the non-terminals only increases by 1.
Thus, simplecontext-free tree grammars strongly lexicalizetree adjoining grammars and themselves.1 IntroductionTree adjoining grammars [TAG] (Joshi et al, 1969;Joshi et al, 1975) are a mildly context-sensitivegrammar formalism that can handle certain non-local dependencies (Kuhlmann and Mohl, 2006),which occur in several natural languages.
A goodoverview on TAG, their formal properties, their lin-guistic motivation, and their applications is pre-sented by Joshi and Schabes (1992) and Joshi andSchabes (1997), in which also strong lexicalizationis discussed.
In general, lexicalization is the processof transforming a grammar into an equivalent one(potentially expressed in another formalism) suchthat each production contains a lexical item (or an-chor).
Each production can then be viewed as lex-ical information on its anchor.
It demonstrates asyntactical construction in which the anchor can oc-cur.
Since a lexical item is a letter of the string?
Financially supported by the German Research Founda-tion (DFG) grant MA 4959 / 1-1.alphabet, each production of a lexicalized gram-mar produces at least one letter of the generatedstring.
Consequently, lexicalized grammars offersignificant parsing benefits (Schabes et al, 1988)as the number of applications of productions (i.e.,derivation steps) is clearly bounded by the lengthof the input string.
In addition, the lexical itemsin the productions guide the production selection ina derivation, which works especially well in sce-narios with large alphabets.1 The GREIBACH nor-mal form (Hopcroft et al, 2001; Blum and Koch,1999) offers those benefits for context-free gram-mars [CFG], but it changes the parse trees.
Thus,we distinguish between two notions of equivalence:Weak equivalence (Bar-Hillel et al, 1960) only re-quires that the generated string languages coincide,whereas strong equivalence (Chomsky, 1963) re-quires that even the generated tree languages coin-cide.
Correspondingly, we obtain weak and stronglexicalization based on the required equivalence.The GREIBACH normal form shows that CFGcan weakly lexicalize themselves, but they cannotstrongly lexicalize themselves (Schabes, 1990).
It isa prominent feature of tree adjoining grammars thatthey can strongly lexicalize CFG (Schabes, 1990),2and it was claimed and widely believed that they canstrongly lexicalize themselves.
Recently, Kuhlmannand Satta (2012) proved that TAG actually can-not strongly lexicalize themselves.
In fact, theyprove that TAG cannot even strongly lexicalize theweaker tree insertion grammars (Schabes and Wa-ters, 1995).
However, TAG can weakly lexicalizethemselves (Fujiyoshi, 2005).1Chen (2001) presents a detailed account.2Good algorithmic properties and the good coverage of lin-guistic phenomena are other prominent features.506Simple (i.e., linear and nondeleting) context-freetree grammars [CFTG] (Rounds, 1969; Rounds,1970) are a more powerful grammar formalism thanTAG (Mo?nnich, 1997).
However, the monadic vari-ant is strongly equivalent to a slightly extended ver-sion of TAG, which is called non-strict TAG (Kepserand Rogers, 2011).
A GREIBACH normal form for asuperclass of CFTG (viz., second-order abstract cat-egorial grammars) was discussed by Kanazawa andYoshinaka (2005) and Yoshinaka (2006).
In particu-lar, they also demonstrate that monadic CFTG canstrongly lexicalize regular tree grammars (Ge?csegand Steinby, 1984; Ge?cseg and Steinby, 1997).CFTG are weakly equivalent to the simple macrogrammars of Fischer (1968), which are a notationalvariant of the well-nested linear context-free rewrit-ing systems (LCFRS) of Vijay-Shanker et al (1987)and the well-nested multiple context-free grammars(MCFG) of Seki et al (1991).3 Thus, CFTG aremildly context-sensitive since their generated stringlanguages are semi-linear and can be parsed in poly-nomial time (Go?mez-Rodr?
?guez et al, 2010).In this contribution, we show that CFTG canstrongly lexicalize TAG and also themselves, thusanswering the second question in the conclusionof Kuhlmann and Satta (2012).
This is achievedby a series of normalization steps (see Section 4)and a final lexicalization step (see Section 5), inwhich a lexical item is guessed for each produc-tion that does not already contain one.
This itemis then transported in an additional argument untilit is exchanged for the same item in a terminal pro-duction.
The lexicalization is effective and increasesthe maximal rank (number of arguments) of the non-terminals by at most 1.
In contrast to a transforma-tion into GREIBACH normal form, our lexicalizationdoes not radically change the structure of the deriva-tions.
Overall, our result shows that if we consideronly lexicalization, then CFTG are a more naturalgeneralization of CFG than TAG.2 NotationWe write [k] for the set {i ?
N | 1 ?
i ?
k},where N denotes the set of nonnegative integers.
Weuse a fixed countably infinite set X = {x1, x2, .
.
.
}3Kuhlmann (2010), Mo?nnich (2010), and Kanazawa (2009)discuss well-nestedness.of (mutually distinguishable) variables, and we letXk = {xi | i ?
[k]} be the first k variables from Xfor every k ?
N. As usual, an alphabet ?
is a finiteset of symbols, and a ranked alphabet (?, rk) adds aranking rk : ?
?
N. We let ?k = {?
| rk(?)
= k}be the set of k-ary symbols.
Moreover, we justwrite ?
for the ranked alphabet (?, rk).4 We buildtrees over the ranked alphabet ?
such that the nodesare labeled by elements of ?
and the rank of the nodelabel determines the number of its children.
In addi-tion, elements of X can label leaves.
Formally, theset T?
(X) of ?-trees indexed by X is the smallestset T such that X ?
T and ?
(t1, .
.
.
, tk) ?
T for allk ?
N, ?
?
?k, and t1, .
.
.
, tk ?
T .5We use positions to address the nodes of a tree.
Aposition is a sequence of nonnegative integers indi-cating successively in which subtree the addressednode is.
More precisely, the root is at position ?
andthe position ip with i ?
N and p ?
N?
refers tothe position p in the ith direct subtree.
Formally, theset pos(t) ?
N?
of positions of a tree t ?
T?
(X) isdefined by pos(x) = {?}
for x ?
X andpos(?
(t1, .
.
.
, tk)) = {?}
?
{ip | i ?
[k], p ?
pos(ti)}for all symbols ?
?
?k and t1, .
.
.
, tk ?
T?
(X).The positions are indicated as superscripts of the la-bels in the tree of Figure 1.
The subtree of t at posi-tion p ?
pos(t) is denoted by t|p, and the label of tat position p by t(p).
Moreover, t[u]p denotes thetree obtained from t by replacing the subtree at p bythe tree u ?
T?(X).
For every label set S ?
?,we let posS(t) = {p ?
pos(t) | t(p) ?
S} bethe S-labeled positions of t. For every ?
?
?,we let pos?
(t) = pos{?}(t).
The set C?
(Xk) con-tains all trees t of T?
(X), in which every x ?
Xkoccurs exactly once and posX\Xk(t) = ?.
Givenu1, .
.
.
, uk ?
T?
(X), the first-order substitutiont[u1, .
.
.
, uk] is inductively defined byxi[u1, .
.
.
, uk] ={ui if i ?
[k]xi otherwiset[u1, .
.
.
, uk] = ?
(t1[u1, .
.
.
, uk], .
.
.
, tk[u1, .
.
.
, uk])for every i ?
N and t = ?
(t1, .
.
.
, tk) with ?
?
?kand t1, .
.
.
, tk ?
T?(X).
First-order substitution isillustrated in Figure 1.4We often decorate a symbol ?
with its rank k [e.g.
?
(k)].5We will often drop quantifications like ?for all k ?
N?.507?[?]?[1]?
[11] x[12]2?
[2]x[21]1 ?
[22][ ?
?, x1]=???
x1???
?Figure 1: Tree in C?
(X2) ?
T?
(X) with indicated po-sitions, where ?
= {?, ?, ?}
with rk(?)
= 2, rk(?)
= 1,and rk(?)
= 0, and an example first-order substitution.In first-order substitution we replace leaves (ele-ments of X), whereas in second-order substitutionwe replace an internal node (labeled by a symbolof ?).
Let p ?
pos(t) be such that t(p) ?
?k,and let u ?
C?
(Xk) be a tree in which the vari-ables Xk occur exactly once.
The second-order sub-stitution t[p ?
u] replaces the subtree at position pby the tree u into which the children of p are (first-order) substituted.
In essence, u is ?folded?
into t atposition p. Formally, t[p?
u] = t[u[t|1, .
.
.
, t|k]]p.Given P ?
pos?
(t) with ?
?
?k, we let t[P ?
u]be t[p1 ?
u] ?
?
?
[pn ?
u], where P = {p1, .
.
.
, pn}and p1 > ?
?
?
> pn in the lexicographic order.Second-order substitution is illustrated in Figure 2.Ge?cseg and Steinby (1997) present a detailed intro-duction to trees and tree languages.3 Context-free tree grammarsIn this section, we recall linear and nondeletingcontext-free tree grammars [CFTG] (Rounds, 1969;Rounds, 1970).
The property ?linear and nondelet-ing?
is often called ?simple?.
The nonterminals ofregular tree grammars only occur at the leaves andare replaced using first-order substitution.
In con-trast, the nonterminals of a CFTG are ranked sym-bols, can occur anywhere in a tree, and are replacedusing second-order substitution.6 Consequently, thenonterminals N of a CFTG form a ranked alpha-bet.
In the left-hand sides of productions we writeA(x1, .
.
.
, xk) for a nonterminal A ?
Nk to indi-cate the variables that hold the direct subtrees of aparticular occurrence of A.Definition 1.
A (simple) context-free tree gram-mar [CFTG] is a system (N,?, S, P ) such that?
N is a ranked alphabet of nonterminal symbols,?
?
is a ranked alphabet of terminal symbols,76see Sections 6 and 15 of (Ge?cseg and Steinby, 1997)7We assume that ?
?N = ?.??
??
?[?????
x2?x1 ?]=???
??
???
?Figure 2: Example second-order substitution, in whichthe boxed symbol ?
is replaced.?
S ?
N0 is the start nonterminal of rank 0, and?
P is a finite set of productions of the formA(x1, .
.
.
, xk) ?
r, where r ?
CN??
(Xk)and A ?
Nk.The components ` and r are called left- and right-hand side of the production ` ?
r in P .
We saythat it is an A-production if ` = A(x1, .
.
.
, xk).
Theright-hand side is simply a tree using terminal andnonterminal symbols according to their rank.
More-over, it contains all the variables ofXk exactly once.Let us illustrate the syntax on an example CFTG.
Weuse an abstract language for simplicity and clarity.We use lower-case Greek letters for terminal sym-bols and upper-case Latin letters for nonterminals.Example 2.
As a running example, we consider theCFTG Gex = ({S(0), A(2)},?, S, P ) where?
?
= {?
(2), ?
(0), ?
(0)} and?
P contains the productions (see Figure 3):8S ?
A(?, ?)
| A(?, ?)
| ?
(?, ?
)A(x1, x2)?
A(?
(x1, S), ?
(x2, S)) | ?
(x1, x2) .We recall the (term) rewrite semantics (Baaderand Nipkow, 1998) of the CFTG G = (N,?, S, P ).Since G is simple, the actual rewriting strategyis irrelevant.
The sentential forms of G are sim-ply SF(G) = TN??(X).
This is slightly more gen-eral than necessary (for the semantics of G), but thepresence of variables in sentential forms will be use-ful in the next section because it allows us to treatright-hand sides as sentential forms.
In essence in arewrite step we just select a nonterminal A ?
N andan A-production ?
?
P .
Then we replace an occur-rence of A in the sentential form by the right-handside of ?
using second-order substitution.Definition 3.
Let ?, ?
?
SF(G) be sentential forms.Given an A-production ?
= ` ?
r in P and an8We separate several right-hand sides with ?|?.508S ?A?
?S ???
?S ?A?
?Ax1 x2?A?x1 S?x2 SAx1 x2?
?x1 x2Figure 3: Productions of Example 2.A-labeled position p ?
posA(?)
in ?, we write?
?
?,pG ?
[p ?
r].
If there exist ?
?
P andp ?
pos(?)
such that ?
?
?,pG ?, then ?
?G ?.9 Thesemantics JGK of G is {t ?
T?
| S ?
?G t}, where?
?G is the reflexive, transitive closure of?G.Two CFTGG1 andG2 are (strongly) equivalent ifJG1K = JG2K.
In this contribution we are only con-cerned with strong equivalence (Chomsky, 1963).Although we recall the string corresponding to a treelater on (via its yield), we will not investigate weakequivalence (Bar-Hillel et al, 1960).Example 4.
Reconsider the CFTG Gex of Exam-ple 2.
A derivation to a tree of T?
is illustrated inFigure 4.
It demonstrates that the final tree in thatderivation is in the language JGexK generated byGex.Finally, let us recall the relation between CFTGand tree adjoining grammars [TAG] (Joshi et al,1969; Joshi et al, 1975).
Joshi et al (1975)show that TAG are special footed CFTG (Kepserand Rogers, 2011), which are weakly equivalentto monadic CFTG, i.e., CFTG whose nonterminalshave rank at most 1 (Mo?nnich, 1997; Fujiyoshiand Kasai, 2000).
Kepser and Rogers (2011) showthe strong equivalence of those CFTG to non-strictTAG, which are slightly more powerful than tradi-tional TAG.
In general, TAG are a natural formalismto describe the syntax of natural language.104 Normal formsIn this section, we first recall an existing normalform for CFTG.
Then we introduce the property offinite ambiguity in the spirit of (Schabes, 1990; Joshiand Schabes, 1992; Kuhlmann and Satta, 2012),which allows us to normalize our CFTG even fur-ther.
A major tool is a simple production elimination9For all k ?
N and ?
?G ?
we note that ?
?
CN??
(Xk) ifand only if ?
?
CN??
(Xk).10XTAG Research Group (2001) wrote a TAG for English.scheme, which we present in detail.
From now on,let G = (N,?, S, P ) be the considered CFTG.The CFTG G is start-separated if posS(r) = ?for every production `?
r ?
P .
In other words, thestart nonterminal S is not allowed in the right-handsides of the productions.
It is clear that each CFTGcan be transformed into an equivalent start-separatedCFTG.
In such a CFTG we call each production ofthe form S ?
r initial.
From now on, we assume,without loss of generality, that G is start-separated.Example 5.
Let Gex = (N,?, S, P ) be the CFTGof Example 2.
An equivalent start-separated CFTGis G?ex = ({S?
(0)} ?N,?, S?, P ?
{S?
?
S}).We start with the growing normal form of Stamerand Otto (2007) and Stamer (2009).
It requires thatthe right-hand side of each non-initial productioncontains at least two terminal or nonterminal sym-bols.
In particular, it eliminates projection produc-tions A(x1) ?
x1 and unit productions, in whichthe right-hand side has the same shape as the left-hand side (potentially with a different root symboland a different order of the variables).Definition 6.
A production ` ?
r is growing if|posN??
(r)| ?
2.
The CFTG G is growing if allof its non-initial productions are growing.The next theorem is Proposition 2 of (Stamer andOtto, 2007).
Stamer (2009) provides a full proof.Theorem 7.
For every start-separated CFTG thereexists an equivalent start-separated, growing CFTG.Example 8.
Let us transform the CFTG G?ex of Ex-ample 5 into growing normal form.
We obtain theCFTG G?
?ex = ({S?
(0), S(0), A(2)},?, S?, P ??)
whereP ??
contains S?
?
S and for each ?
?
{?, ?
}S ?
A(?, ?)
| ?
(?, ?)
| ?
(?, ?)
(1)A(x1, x2)?
A(?
(x1, S), ?
(x2, S)) (2)A(x1, x2)?
?(?
(x1, S), ?
(x2, S)) .From now on, we assume thatG is growing.
Next,we recall the notion of finite ambiguity from (Sch-abes, 1990; Joshi and Schabes, 1992; Kuhlmann andSatta, 2012).11 We distinguish a subset ?
?
?0 oflexical symbols, which are the symbols that are pre-served by the yield mapping.
The yield of a tree is11It should not be confused with the notion of ?finite ambigu-ity?
of (Goldstine et al, 1992; Klimann et al, 2004).509S ?GA?
??GA??
S??
S?GA??
A?
???
S?GA??
A?
???
??
???G???
??
???
??
?Figure 4: Derivation using the CFTG Gex of Example 2.
The selected positions are boxed.a string of lexical symbols.
All other symbols aresimply dropped (in a pre-order traversal).
Formally,yd?
: T?
?
??
is such that for all t = ?
(t1, .
.
.
, tk)with ?
?
?k and t1, .
.
.
, tk ?
T?yd?
(t) ={?
yd?
(t1) ?
?
?
yd?
(tk) if ?
?
?yd?
(t1) ?
?
?
yd?
(tk) otherwise.Definition 9.
The tree language L ?
T?
has finite?-ambiguity if {t ?
L | yd?
(t) = w} is finite forevery w ?
?
?.Roughly speaking, we can say that the set L hasfinite ?-ambiguity if eachw ?
??
has finitely manyparses in L (where t is a parse of w if yd?
(t) = w).Our example CFTG Gex is such that JGexK has finite{?, ?
}-ambiguity (because ?1 = ?
).In this contribution, we want to (strongly) lexical-ize CFTG, which means that for each CFTG G suchthat JGK has finite ?-ambiguity, we want to con-struct an equivalent CFTG such that each non-initialproduction contains at least one lexical symbol.This is typically called strong lexicalization (Sch-abes, 1990; Joshi and Schabes, 1992; Kuhlmannand Satta, 2012) because we require strong equiva-lence.12 Let us formalize our lexicalization property.Definition 10.
The production ` ?
r is ?-lexical-ized if pos?
(r) 6= ?.
The CFTG G is ?-lexicalizedif all its non-initial productions are ?-lexicalized.Note that the CFTG G?
?ex of Example 8 is not yet{?, ?}-lexicalized.
We will lexicalize it in the nextsection.
To do this in general, we need some auxil-iary normal forms.
First, we define our simple pro-duction elimination scheme, which we will use inthe following.
Roughly speaking, a non-initial A-production such that A does not occur in its right-hand side can be eliminated fromG by applying it in12The corresponding notion for weak equivalence is calledweak lexicalization (Joshi and Schabes, 1992).all possible ways to occurrences in right-hand sidesof the remaining productions.Definition 11.
Let ?
= A(x1, .
.
.
, xk) ?
r in Pbe a non-initial production such that posA(r) = ?.For every other production ??
= `?
?
r?
in P andJ ?
posA(r?
), let ?
?J = `?
?
r?
[J ?
r].
The CFTGElim(G, ?)
= (N,?, S, P ?)
is such thatP ?
=???=`??r??P\{?}{?
?J | J ?
posA(r?)}
.In particular, ???
= ??
for every production ?
?,so every production besides the eliminated produc-tion ?
is preserved.
We obtained the CFTG G?
?ex ofExample 8 as Elim(G?ex, A(x1, x2) ?
?
(x1, x2))from G?ex of Example 5.Lemma 12.
The CFTG G and G??
= Elim(G, ?
)are equivalent for every non-initial A-production?
= `?
r in P such that posA(r) = ?.Proof.
Clearly, every single derivation step of G?
?can be simulated by a derivation of G using poten-tially several steps.
Conversely, a derivation of Gcan be simulated directly by G??
except for deriva-tion steps ?
?,pG using the eliminated production ?.Since S 6= A, we know that the nonterminal at po-sition p was generated by another production ??.
Inthe given derivation of G we examine which non-terminals in the right-hand side of the instance of ?
?were replaced using ?.
Let J be the set of positionscorresponding to those nonterminals (thus p ?
J).Then instead of applying ??
and potentially severaltimes ?, we equivalently apply ?
?J of G?
?.In the next normalization step we use our pro-duction elimination scheme.
The goal is to makesure that non-initial monic productions (i.e., produc-tions of which the right-hand side contains at mostone nonterminal) contain at least one lexical sym-bol.
We define the relevant property and then present510the construction.
A sentential form ?
?
SF(G)is monic if |posN (?
)| ?
1.
The set of all monicsentential forms is denoted by SF?1(G).
A pro-duction ` ?
r is monic if r is monic.
The nextconstruction is similar to the simultaneous removalof epsilon-productions A ?
?
and unit productionsA ?
B for context-free grammars (Hopcroft et al,2001).
Instead of computing the closure under thoseproductions, we compute a closure under non-?-lexicalized productions.Theorem 13.
If JGK has finite ?-ambiguity, thenthere exists an equivalent CFTG such that all its non-initial monic productions are ?-lexicalized.Proof.
Without loss of generality, we assume thatG is start-separated and growing by Theorem 7.Moreover, we assume that each nonterminal is use-ful.
For every A ?
N with A 6= S, we computeall monic sentential forms without a lexical sym-bol that are reachable from A(x1, .
.
.
, xk), wherek = rk(A).
Formally, let?A = {?
?
SF?1(G) | A(x1, .
.
.
, xk)?+G?
?}
,where?+G?
is the transitive closure of?G?
and theCFTG G?
= (N,?, S, P ?)
is such that P ?
containsexactly the non-?-lexicalized productions of P .The set ?A is finite since only finitely many non-?-lexicalized productions can be used due to thefinite ?-ambiguity of JGK.
Moreover, no senten-tial form in ?A contains A for the same reasonand the fact that G is growing.
We construct theCFTG G1 = (N,?, S, P ?
P1) such thatP1 = {A(x1, .
.
.
, xk)?
?
| A ?
Nk, ?
?
?A} .Clearly, G and G1 are equivalent.
Next, we elimi-nate all productions of P1 from G1 using Lemma 12to obtain an equivalent CFTG G2 with the produc-tions P2.
In the final step, we drop all non-?-lexicalized monic productions of P2 to obtain theCFTG G, in which all monic productions are ?-lexicalized.
It is easy to see that G is growing, start-separated, and equivalent to G2.The CFTG G?
?ex only has {?, ?
}-lexicalized non-initial monic productions, so we use a new example.Example 14.
Let ({S(0), A(1), B(1)},?, S, P ) bethe CFTG such that ?
= {?
(2), ?
(0), ?
(0)} andAx1?G???
Bx1?G???
?x1 ?Bx1?G?
?x1 ?Figure 5: The relevant derivations using only productionsthat are not ?-lexicalized (see Example 14).P contains the productionsA(x1)?
?
(?,B(x1)) B(x1)?
?
(x1, ?)
(3)B(x1)?
?
(?,A(x1)) S ?
A(?)
.This CFTG Gex2 is start-separated and growing.Moreover, all its productions are monic, and JGex2Kis finitely ?-ambiguous for the set ?
= {?}
oflexical symbols.
Then the productions (3) are non-initial and not ?-lexicalized.
So we can run theconstruction in the proof of Theorem 13.
The rel-evant derivations using only non-?-lexicalized pro-ductions are shown in Figure 5.
We observe that|?A| = 2 and |?B| = 1, so we obtain the CFTG({S(0), B(1)},?, S, P ?
), where P ?
contains13S ?
?(?,B(?))
| ?
(?, ?
(?, ?))B(x1)?
?
(?, ?(?,B(x1)))B(x1)?
?
(?, ?
(?, ?
(x1, ?)))
.
(4)We now do one more normalization step beforewe present our lexicalization.
We call a production` ?
r terminal if r ?
T?
(X); i.e., it does not con-tain nonterminal symbols.
Next, we show that foreach CFTG G such that JGK has finite ?-ambiguitywe can require that each non-initial terminal produc-tion contains at least two occurrences of ?-symbols.Theorem 15.
If JGK has finite ?-ambiguity, thenthere exists an equivalent CFTG (N,?, S, P ?)
suchthat |pos?
(r)| ?
2 for all its non-initial terminalproductions `?
r ?
P ?.Proof.
Without loss of generality, we assume thatG is start-separated and growing by Theorem 7.Moreover, we assume that each nonterminal is use-ful and that each of its non-initial monic produc-tions is ?-lexicalized by Theorem 13.
We obtainthe desired CFTG by simply eliminating each non-initial terminal production ` ?
r ?
P such that|pos?
(r)| = 1.
By Lemma 12 the obtained CFTG13The nonterminal A became useless, so we just removed it.511Ax1 x2?A?x1 S?x2 S?A,?
?x1 x2 x3??A,??
?x1 S?x2 Sx3?A,?
?x1 x2 x3??A,??
?x1 ?S, ???
?x2 Sx3Figure 6: Production ?
= `?
r of (2) [left], a corresponding production ??
of P ?
[middle] with right-hand side r?,2,and a corresponding production of P ???
[right] with right-hand side (r?,2)?
(see Theorem 17).is equivalent to G. The elimination process termi-nates because a new terminal production can only beconstructed from a monic production and a terminalproduction or several terminal productions, but thosecombinations already contain two occurrences of ?-symbols since non-initial monic productions are al-ready ?-lexicalized.Example 16.
Reconsider the CFTG obtained in Ex-ample 14.
Recall that ?
= {?}.
Production (4) isthe only non-initial terminal production that violatesthe requirement of Theorem 15.
We eliminate it andobtain the CFTG with the productionsS ?
?(?,B(?))
| ?
(?, ?
(?, ?
))S ?
?
(?, ?
(?, ?
(?, ?
(?, ?))))B(x1)?
?
(?, ?(?,B(x1)))B(x1)?
?
(?, ?
(?, ?
(?, ?
(?, ?
(x1, ?)))))
.5 LexicalizationIn this section, we present the main lexicalizationstep, which lexicalizes non-monic productions.
Weassume that JGK has finite ?-ambiguity and is nor-malized according to the results of Section 4: nouseless nonterminals, start-separated, growing (seeTheorem 7), non-initial monic productions are ?-lexicalized (see Theorem 13), and non-initial termi-nal productions contain at least two occurrences of?-symbols (see Theorem 15).The basic idea of the construction is that we guessa lexical symbol for each non-?-lexicalized produc-tion.
The guessed symbol is put into a new param-eter of a nonterminal.
It will be kept in the pa-rameter until we reach a terminal production, wherewe exchange the same lexical symbol by the pa-rameter.
This is the reason why we made surethat we have two occurrences of lexical symbols inthe terminal productions.
After we exchanged onefor a parameter, the resulting terminal production isstill ?-lexicalized.
Lexical items that are guessedfor distinct (occurrences of) productions are trans-ported to distinct (occurrences of) terminal produc-tions [cf.
Section 3 of (Potthoff and Thomas, 1993)and page 346 of (Hoogeboom and ten Pas, 1997)].Theorem 17.
For every CFTG G such that JGKhas finite ?-ambiguity there exists an equivalent?-lexicalized CFTG.Proof.
We can assume that G = (N,?, S, P ) hasthe properties mentioned before the theorem withoutloss of generality.
We let N ?
= N ??
be a new setof nonterminals such that rk(?A, ??)
= rk(A) + 1for every A ?
N and ?
?
?.
Intuitively, ?A, ?
?represents the nonterminal A, which has the lexicalsymbol ?
in its last (new) parameter.
This parameteris handed to the (lexicographically) first nonterminalin the right-hand side until it is resolved in a termi-nal production.
Formally, for each right-hand sider ?
TN?N ???
(X) such that posN (r) 6= ?
(i.e., itcontains an original nonterminal), each k ?
N, andeach ?
?
?, let r?,k and r?
be such thatr?,k = r[?B, ??
(r1, .
.
.
, rn, xk+1)]pr?
= r[?B, ??
(r1, .
.
.
, rn, ?
)]p ,where p is the lexicographically smallest elementof posN (r) and r|p = B(r1, .
.
.
, rn) with B ?
Nand r1, .
.
.
, rn ?
TN?N ???(X).
For each non-terminal A-production ?
= `?
r in P let??
= ?A, ??
(x1, .
.
.
, xk+1)?
r?,k ,where k = rk(A).
This construction is illustratedin Figure 6.
Roughly speaking, we select the lexi-cographically smallest occurrence of a nonterminalin the right-hand side and pass the lexical symbol ?in the extra parameter to it.
The extra parameter isused in terminal productions, so let ?
= `?
r in P512S ???
?
?S, ??x1?
?x1 ?Figure 7: Original terminal production ?
from (1) [left]and the production ?
(see Theorem 17).be a terminal A-production.
Then we define?
= ?A, r(p)?
(x1, .
.
.
, xk+1)?
r[xk+1]p ,where p is the lexicographically smallest elementof pos?
(r) and k = rk(A).
This construction isillustrated in Figure 7.
With these productions weobtain the CFTG G?
= (N ?
N ?,?, S, P ), whereP = P ?
P ?
?
P ??
andP ?
=?
?=`?r?P6`=S,posN (r)6=?{??
| ?
?
?}
P??
=?
?=`?r?P6`=S,posN (r)=?{?}
.It is easy to prove that those new productions man-age the desired transport of the extra parameter if itholds the value indicated in the nonterminal.Finally, we replace each non-initial non-?-lexi-calized production in G?
by new productions thatguess a lexical symbol and add it to the new parame-ter of the (lexicographically) first nonterminal of Nin the right-hand side.
Formally, we letP nil = {`?
r ?
P | ` 6= S, pos?
(r) = ?
}P ???
= {`?
r?
| `?
r ?
P nil, ?
?
?}
,of which P ???
is added to the productions.
Note thateach production ` ?
r ?
P nil contains at least oneoccurrence of a nonterminal ofN (because all monicproductions of G are ?-lexicalized).
Now all non-initial non-?-lexicalized productions from P can beremoved, so we obtain the CFTGG?
?, which is givenby (N ?N ?,?, S,R) with R = (P ?
P ???)
\ P nil.
Itcan be verified that G??
is ?-lexicalized and equiva-lent to G (using the provided argumentation).Instead of taking the lexicographically smallestelement of posN (r) or pos?
(r) in the previousproof, we can take any fixed element of that set.
Inthe definition of P ?
we can change posN (r) 6= ?to |pos?
(r)| ?
1, and simultaneously in the defini-tion of P ??
change posN (r) = ?
to |pos?
(r)| ?
2.With the latter changes the guessed lexical item isonly transported until it is resolved in a productionwith at least two lexical items.Example 18.
For the last time, we consider theCFTG G?
?ex of Example 8.
We already illustrated theparts of the construction of Theorem 17 in Figures6 and 7.
The obtained {?, ?
}-lexicalized CFTG hasthe following 25 productions for all ?, ??
?
{?, ?}:S?
?
SS ?
A(?, ?)
| ?
(?, ?)
| ?
(?, ?)S?(x1)?
A?(?
?, ?
?, x1) | ?
(x1, ?)S?(x1)?
?
(x1, ?
)A(x1, x2)?
A?(?
(x1, S), ?
(x2, S), ?)
(5)A?
(x1, x2, x3)?
A?(?
(x1, S??(??
)), ?
(x2, S), x3)A(x1, x2)?
?(?
(x1, S?(?
)), ?
(x2, S))A?
(x1, x2, x3)?
?(?
(x1, S?
(x3)), ?
(x2, S??(??)))
,where A?
= ?A, ??
and S?
= ?S, ?
?.If we change the lexicalization construction asindicated before this example, then all the produc-tions S?
(x1) ?
A?(?
?, ?
?, x1) are replaced by theproductions S?
(x1) ?
A(x1, ?).
Moreover, theproductions (5) can be replaced by the productionsA(x1, x2) ?
A(?
(x1, S?(?
)), ?
(x2, S)), and thenthe nonterminalsA?
and their productions can be re-moved, which leaves only 15 productions.ConclusionFor k ?
N, let CFTG(k) be the set of those CFTGwhose nonterminals have rank at most k. Since thenormal form constructions preserve the nonterminalrank, the proof of Theorem 17 shows that CFTG(k)are strongly lexicalized by CFTG(k+1).
Kepser andRogers (2011) show that non-strict TAG are stronglyequivalent to CFTG(1).
Hence, non-strict TAG arestrongly lexicalized by CFTG(2).It follows from Section 6 of Engelfriet et al(1980) that the classes CFTG(k) with k ?
N in-duce an infinite hierarchy of string languages, but itremains an open problem whether the rank increasein our lexicalization construction is necessary.Go?mez-Rodr?
?guez et al (2010) show that well-nested LCFRS of maximal fan-out k can be parsedin time O(n2k+2), where n is the length of the in-put string w ?
??.
From this result we concludethat CFTG(k) can be parsed in time O(n2k+4), inthe sense that we can produce a parse tree t thatis generated by the CFTG with yd?
(t) = w. It isnot clear yet whether lexicalized CFTG(k) can beparsed more efficiently in practice.513ReferencesFranz Baader and Tobias Nipkow.
1998.
Term Rewritingand All That.
Cambridge University Press.Yehoshua Bar-Hillel, Haim Gaifman, and Eli Shamir.1960.
On categorial and phrase-structure grammars.Bulletin of the Research Council of Israel, 9F(1):1?16.Norbert Blum and Robert Koch.
1999.
Greibach normalform transformation revisited.
Inform.
and Comput.,150(1):112?118.John Chen.
2001.
Towards Efficient Statistical Parsingusing Lexicalized Grammatical Information.
Ph.D.thesis, University of Delaware, Newark, USA.Noam Chomsky.
1963.
Formal properties of gram-mar.
In R. Duncan Luce, Robert R. Bush, and EugeneGalanter, editors, Handbook of Mathematical Psychol-ogy, volume 2, pages 323?418.
John Wiley and Sons,Inc.Joost Engelfriet, Grzegorz Rozenberg, and Giora Slutzki.1980.
Tree transducers, L systems, and two-way ma-chines.
J. Comput.
System Sci., 20(2):150?202.Michael J. Fischer.
1968.
Grammars with macro-likeproductions.
In Proc.
9th Ann.
Symp.
Switching andAutomata Theory, pages 131?142.
IEEE ComputerSociety.Akio Fujiyoshi.
2005.
Epsilon-free grammars andlexicalized grammars that generate the class of themildly context-sensitive languages.
In Proc.
7th Int.Workshop Tree Adjoining Grammar and Related For-malisms, pages 16?23.Akio Fujiyoshi and Takumi Kasai.
2000.
Spinal-formedcontext-free tree grammars.
Theory Comput.
Syst.,33(1):59?83.Ferenc Ge?cseg and Magnus Steinby.
1984.
Tree Au-tomata.
Akade?miai Kiado?, Budapest.Ferenc Ge?cseg and Magnus Steinby.
1997.
Tree lan-guages.
In Grzegorz Rozenberg and Arto Salomaa,editors, Handbook of Formal Languages, volume 3,chapter 1, pages 1?68.
Springer.Jonathan Goldstine, Hing Leung, and Detlef Wotschke.1992.
On the relation between ambiguity and nonde-terminism in finite automata.
Inform.
and Comput.,100(2):261?270.Carlos Go?mez-Rodr?
?guez, Marco Kuhlmann, and Gior-gio Satta.
2010.
Efficient parsing of well-nested lin-ear context-free rewriting systems.
In Proc.
Ann.
Conf.North American Chapter of the ACL, pages 276?284.Association for Computational Linguistics.Hendrik Jan Hoogeboom and Paulien ten Pas.
1997.Monadic second-order definable text languages.
The-ory Comput.
Syst., 30(4):335?354.John E. Hopcroft, Rajeev Motwani, and Jeffrey D. Ull-man.
2001.
Introduction to automata theory, lan-guages, and computation.
Addison-Wesley series incomputer science.
Addison Wesley, 2nd edition.Aravind K. Joshi, S. Rao Kosaraju, and H. Yamada.1969.
String adjunct grammars.
In Proc.
10th Ann.Symp.
Switching and Automata Theory, pages 245?262.
IEEE Computer Society.Aravind K. Joshi, Leon S. Levy, and Masako Takahashi.1975.
Tree adjunct grammars.
J. Comput.
System Sci.,10(1):136?163.Aravind K. Joshi and Yves Schabes.
1992.
Tree-adjoining grammars and lexicalized grammars.
InMaurice Nivat and Andreas Podelski, editors, Tree Au-tomata and Languages.
North-Holland.Aravind K. Joshi and Yves Schabes.
1997.
Tree-adjoining grammars.
In Grzegorz Rozenberg and ArtoSalomaa, editors, Beyond Words, volume 3 of Hand-book of Formal Languages, pages 69?123.
Springer.Makoto Kanazawa.
2009.
The convergence of well-nested mildly context-sensitive grammar formalisms.Invited talk at the 14th Int.
Conf.
Formal Gram-mar.
slides available at: research.nii.ac.jp/?kanazawa.Makoto Kanazawa and Ryo Yoshinaka.
2005.
Lexical-ization of second-order ACGs.
Technical Report NII-2005-012E, National Institute of Informatics, Tokyo,Japan.Stephan Kepser and James Rogers.
2011.
The equiv-alence of tree adjoining grammars and monadic lin-ear context-free tree grammars.
J. Log.
Lang.
Inf.,20(3):361?384.Ines Klimann, Sylvain Lombardy, Jean Mairesse, andChristophe Prieur.
2004.
Deciding unambiguity andsequentiality from a finitely ambiguous max-plus au-tomaton.
Theoret.
Comput.
Sci., 327(3):349?373.Marco Kuhlmann.
2010.
Dependency Structures andLexicalized Grammars: An Algebraic Approach, vol-ume 6270 of LNAI.
Springer.Marco Kuhlmann and Mathias Mohl.
2006.
Extendedcross-serial dependencies in tree adjoining grammars.In Proc.
8th Int.
Workshop Tree Adjoining Grammarsand Related Formalisms, pages 121?126.
ACL.Marco Kuhlmann and Giorgio Satta.
2012.
Tree-adjoining grammars are not closed under strong lex-icalization.
Comput.
Linguist.
available at: dx.doi.org/10.1162/COLI_a_00090.Uwe Mo?nnich.
1997.
Adjunction as substitution: Analgebraic formulation of regular, context-free and treeadjoining languages.
In Proc.
3rd Int.
Conf.
FormalGrammar, pages 169?178.
Universite?
de Provence,France.
available at: arxiv.org/abs/cmp-lg/9707012v1.Uwe Mo?nnich.
2010.
Well-nested tree languages and at-tributed tree transducers.
In Proc.
10th Int.
Conf.
TreeAdjoining Grammars and Related Formalisms.
YaleUniversity.
available at: www2.research.att.com/?srini/TAG+10/papers/uwe.pdf.514Andreas Potthoff and Wolfgang Thomas.
1993.
Reg-ular tree languages without unary symbols are star-free.
In Proc.
9th Int.
Symp.
Fundamentals of Compu-tation Theory, volume 710 of LNCS, pages 396?405.Springer.William C. Rounds.
1969.
Context-free grammars ontrees.
In Proc.
1st ACM Symp.
Theory of Comput.,pages 143?148.
ACM.William C. Rounds.
1970.
Tree-oriented proofs of sometheorems on context-free and indexed languages.
InProc.
2nd ACM Symp.
Theory of Comput., pages 109?116.
ACM.Yves Schabes.
1990.
Mathematical and ComputationalAspects of Lexicalized Grammars.
Ph.D. thesis, Uni-versity of Pennsylvania, Philadelphia, USA.Yves Schabes, Anne Abeille?, and Aravind K. Joshi.1988.
Parsing strategies with ?lexicalized?
grammars:Application to tree adjoining grammars.
In Proc.
12thInt.
Conf.
Computational Linguistics, pages 578?583.John von Neumann Society for Computing Sciences,Budapest.Yves Schabes and Richard C. Waters.
1995.
Tree in-sertion grammar: A cubic-time parsable formalismthat lexicalizes context-free grammars without chang-ing the trees produced.
Comput.
Linguist., 21(4):479?513.Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii, andTadao Kasami.
1991.
On multiple context-free gram-mars.
Theoret.
Comput.
Sci., 88(2):191?229.Heiko Stamer.
2009.
Restarting Tree Automata: FormalProperties and Possible Variations.
Ph.D. thesis, Uni-versity of Kassel, Germany.Heiko Stamer and Friedrich Otto.
2007.
Restarting treeautomata and linear context-free tree languages.
InProc.
2nd Int.
Conf.
Algebraic Informatics, volume4728 of LNCS, pages 275?289.
Springer.K.
Vijay-Shanker, David J. Weir, and Aravind K. Joshi.1987.
Characterizing structural descriptions producedby various grammatical formalisms.
In Proc.
25thAnn.
Meeting of the Association for ComputationalLinguistics, pages 104?111.
Association for Compu-tational Linguistics.XTAG Research Group.
2001.
A lexicalized tree adjoin-ing grammar for English.
Technical Report IRCS-01-03, University of Pennsylvania, Philadelphia, USA.Ryo Yoshinaka.
2006.
Extensions and Restrictions ofAbstract Categorial Grammars.
Ph.D. thesis, Univer-sity of Tokyo.515
