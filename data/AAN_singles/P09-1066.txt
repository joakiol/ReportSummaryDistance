Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 585?592,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPCollaborative Decoding: Partial Hypothesis Re-rankingUsing Translation Consensus between DecodersMu Li1, Nan Duan2, Dongdong Zhang1, Chi-Ho Li1, Ming Zhou11Microsoft Research Asia                                        2Tianjin UniversityBeijing, China                                                     Tianjin, China{muli,v-naduan,dozhang,chl,mingzhou}@microsoft.comAbstractThis paper presents collaborative decoding(co-decoding), a new method to improve ma-chine translation accuracy by leveraging trans-lation consensus between multiple machinetranslation decoders.
Different from systemcombination and MBR decoding, which post-process the n-best lists or word lattice of ma-chine translation decoders, in our method mul-tiple machine translation decoders collaborateby exchanging partial translation results.
Us-ing an iterative decoding approach, n-gramagreement statistics between translations ofmultiple decoders are employed to re-rankboth full and partial hypothesis explored indecoding.
Experimental results on data sets forNIST Chinese-to-English machine translationtask show that the co-decoding method canbring significant improvements to all baselinedecoders, and the outputs from co-decodingcan be used to further improve the result ofsystem combination.1 IntroductionRecent research has shown substantial improve-ments can be achieved by utilizing consensusstatistics obtained from outputs of multiple ma-chine translation systems.
Translation consensuscan be measured either at sentence level or atword level.
For example, Minimum Bayes Risk(MBR) (Kumar and Byrne, 2004) decoding overn-best list tries to find a hypothesis with lowestexpected loss with respect to all the other transla-tions, which can be viewed as sentence-levelconsensus-based decoding.
Word based methodsproposed range from straightforward consensusvoting (Bangalore et al, 2001; Matusov et al,2006) to more complicated word-based systemcombination model (Rosti et al, 2007; Sim et al,2007).
Typically, the resulting systems take out-puts of individual machine translation systems asinput, and build a new confusion network forsecond-pass decoding.There have been many efforts dedicated to ad-vance the state-of-the-art performance by com-bining multiple systems?
outputs.
Most of thework focused on seeking better word alignmentfor consensus-based confusion network decoding(Matusov et al, 2006) or word-level systemcombination (He et al, 2008; Ayan et al, 2008).In addition to better alignment, Rosti et al(2008) introduced an incremental strategy forconfusion network construction; and Hildebrandand Vogel (2008) proposed a hypotheses re-ranking model for multiple systems?
outputs withmore features including word translation proba-bility and n-gram agreement statistics.A common property of all the work mentionedabove is that the combination models work onthe basis of n-best translation lists (full hypo-theses) of existing machine translation systems.However, the n-best list only presents a verysmall portion of the entire search space of a Sta-tistical Machine Translation (SMT) model whilea majority of the space, within which there aremany potentially good translations, is prunedaway in decoding.
In fact, due to the limitationsof present-day computational resources, a consi-derable number of promising possibilities have tobe abandoned at the early stage of the decodingprocess.
It is therefore expected that exploringadditional possibilities beyond n-best hypotheseslists for full sentences could bring improvementsto consensus-based decoding.In this paper, we present collaborative decod-ing (or co-decoding), a new SMT decodingscheme to leverage consensus information be-tween multiple machine translation systems.
Inthis scheme, instead of using a post-processingstep, multiple machine translation decoders col-laborate during the decoding process, and trans-lation consensus statistics are taken into accountto improve ranking not only for full translations,but also for partial hypotheses.
In this way, we585expect to reduce search errors caused by partialhypotheses pruning, maximize the contributionof translation consensus, and result in better finaltranslations.We will discuss the general co-decoding mod-el, requirements for decoders that enable colla-borative decoding and describe the updated mod-el structures.
We will present experimental re-sults on the data sets of NIST Chinese-to-Englishmachine translation task, and demonstrate thatco-decoding can bring significant improvementsto baseline systems.
We also conduct extensiveinvestigations when different settings of co-decoding are applied, and make comparisonswith related methods such as word-level systemcombination of hypothesis selection from mul-tiple n-best lists.The rest of the paper is structured as follows.Section 2 gives a formal description of the co-decoding model, the strategy to apply consensusinformation and hypotheses ranking in decoding.In Section 3, we make detailed comparison be-tween co-decoding and related work such as sys-tem combination and hypotheses selection out ofmultiple systems.
Experimental results and dis-cussions are presented in Section 4.
Section 5concludes the paper.2 Collaborative Decoding2.1 OverviewCollaborative decoding does not present a fullSMT model as other SMT decoders do such asPharaoh (Koehn, 2004) or Hiero (Chiang, 2005).Instead, it provides a framework that accommo-dates and coordinates multiple MT decoders.Conceptually, collaborative decoding incorpo-rates the following four constituents:1.
Co-decoding model.
A co-decoding modelconsists of a set of member models, whichare a set of augmented baseline models.
Wecall decoders based on member modelsmember decoders, and those based on base-line models baseline decoders.
In our work,any Maximum A Posteriori (MAP) SMTmodel with log-linear formulation (Och,2002) can be a qualified candidate for abaseline model.
The requirement for a log-linear model aims to provide a natural way tointegrate the new co-decoding features.2.
Co-decoding features.
Member models arebuilt by adding additional translation consen-sus -based co-decoding features to baselinemodels.
A baseline model can be viewed as aspecial case of member model with all co-decoding feature values set to 0.
Accordingly,a baseline decoder can be viewed as a specialsetting of a member decoder.3.
Decoder coordinating.
In co-decoding, eachmember decoder cannot proceed solely basedon its own agenda.
To share consensus statis-tics with others, the decoding must be per-formed in a coordinated way.4.
Model training.
Since we use multiple inter-related decoders and introduce more featuresin member models, we also need to addressthe parameter estimation issue in the frame-work of co-decoding.In the following sub-sections we first establish ageneral model for co-decoding, and then presentdetails of feature design and decoder implemen-tation, as well as parameter estimation in the co-decoding framework.
We leave the investigationof using specific member models to the experi-ment section.2.2 Generic Collaborative Decoding ModelFor a given source sentence f, a member modelin co-decoding finds the best translation ?
?among the set of possible candidate translations?(?)
based on a scoring function ?:??
= argmax???(?)?(?)
(1)In the following, we will use ??
to denote the???
member decoder, and also use the notation??(?)
for the translation hypothesis space of fdetermined by ??
.
The ???
member model canbe written as:??
?
= ??
(?, ?)
+ ??(?,??(?))?,???
(2)where ??
(?, ?)
is the score function of the ??
?baseline model, and each ??(?,??(?))
is a par-tial consensus score function with respect to ?
?and is defined over e and ??
?
:??
?,??
?
= ??
,?
??,?(?,??
?
)?
(3)where each ??
,?(?,??
? )
is a feature functionbased on a consensus measure between e and??
?
, and ??,?
is the corresponding featureweight.
Feature index l ranges over all consen-sus-based features in Equation 3.2.3 Decoder CoordinationBefore discussing the design and computation oftranslation consensus -based features, we first586describe the multiple decoder coordination issuein co-decoding.
Note that in Equation 2, thoughthe baseline score function ??
?, ?
can becomputed inside each decoder, the case of??(?,??(?))
is more complicated.
Becauseusually it is not feasible to enumerate the entirehypothesis space for machine translation, we ap-proximate ??
?
with n-best hypotheses byconvention.
Then there is a circular dependencybetween co-decoding features and ??(?)
: onone hand, searching for n-best approximation of??(?)
requires using Equation 2 to select top-ranked hypotheses; while on the other hand, Eq-uation 2 cannot be computed until every ??(?
)is available.We address this issue by employing a boot-strapping method, in which the key idea is thatwe can use baseline models?
n-best hypothesesas seeds, and iteratively refine member models?n-best hypotheses with co-decoding.
Similar to atypical phrase-based decoder (Koehn, 2004), weassociate each hypothesis with a coverage vectorc to track translated source words in it.
We willuse ??(?,?)
for the set of hypotheses associatedwith c, and we also denote with ??(?)
=??(?,?)?
the set of all hypotheses generatedby member decoder ??
in decoding.
The co-decoding process can be described as follows:1.
For each member decoder ??
, perform de-coding with a baseline model, and memorizeall translation hypotheses generated duringdecoding in ??(?);2.
Re-group translation hypotheses in ??(?
)into a set of buckets  ??
?,?
by the cover-age vector c associated with each hypothesis;3.
Use member decoders to re-decode sourcesentence ?
with member models.
For mem-ber decoder ??
, consensus-based features ofany hypotheses associated with coveragevector c are computed based on current set-ting of ??
?,?
for all s but k. New hypo-theses generated by ??
in re-decoding arecached in ???
(?);4.
Update all ??(?)
with ???
(?);5.
Iterate from step 2 to step 4 until a presetiteration limit is reached.In the iterative decoding procedure describedabove, hypotheses of different decoders can bemutually improved.
For example, given two de-coders ?1  and ?2  with hypotheses sets ?1  and?2 , improvements on ?1  enable ?2  to improve?2, and in turn ?1 benefits from improved ?2,and so forth.Step 2 is used to facilitate the computation offeature functions ??
,?(?,??
? )
, which requireboth e and every hypothesis in ??
?
should betranslations of the same set of source words.
Thisstep seems to be redundant for CKY-style MTdecoders (Liu et al, 2006; Xiong et al, 2006;Chiang, 2005) since the grouping is immediatelyavailable from decoders because all hypothesesspanning the same range of source sentence havebeen stacked together in the same chart cell.
Butto be a general framework, this step is necessaryfor some state-of-the-art phrase-based decoders(Koehn, 2007; Och and Ney, 2004) because inthese decoders, hypotheses with different cover-age vectors can co-exist in the same bin, or hypo-theses associated with the same coverage vectormight appear in different bins.Note that a member model does not enlargethe theoretical search space of its baseline model,the only change is hypothesis scoring.
By re-running a complete decoding process, membermodel can be applied to re-score all hypothesesexplored by a decoder.
Therefore step 3 can beviewed as full-scale hypothesis re-ranking be-cause the re-ranking scope is beyond the limitedn-best hypotheses currently cached in ??
.In the implementation of member decoders,there are two major modifications compared totheir baseline decoders.
One is the support forco-decoding features, including computation offeature values and the use of augmented co-decoding score function (Equation 2) for hypo-thesis ranking and pruning.
The other is hypothe-sis grouping based on coverage vector and a me-chanism to effectively access grouped hypothes-es in step 2 and step 3.2.4 Co-decoding FeaturesWe now present the consensus-based featurefunctions  ??
,?(?,??
? )
introduced in Equation3.
In this work all the consensus-based featureshave the following formulation:??
,?
?,??
?
=  ?
??
??
??
(?, ??)?????
?
(4)where e is a translation of f by decoder ??
(?
??
), ?
?
is a translation in ??
?
and ?
??
??
isthe posterior probability of translation ?
?
deter-mined by decoder ??
given source sentence f.??
(?, ??)
is a consensus measure defined on e and?
?, by varying which different feature functionscan be obtained.587Referring to the log-linear model formulation,the translation posterior ?
??
??
can be com-puted as:?
??
??
=exp ???
?
?exp ???
???
???
???
?
(5)where ??(?)
is the score function given in Equa-tion 2, and  ?
is a scaling factor following thework of Tromble et al (2008)To compute the consensus measures, we fur-ther decompose each ??
?, ??
into n-grammatching statistics between e and ??.
Here we donot discriminate among different lexical n-gramsand are only concerned with statistics aggrega-tion of all n-grams of the same order.
For each n-gram of order n, we introduce a pair of comple-mentary consensus measure functions ?
?+ ?, ?
?and ???
?, ??
described as follows:?
?+ ?, ??
is the n-gram agreement measurefunction which counts the number of occurrencesin ?
?of n-grams in e. So the corresponding fea-ture value will be the expected number of occur-rences in ??
?
of all n-grams in e:?
?+ ?, ??
= ?(???+?
?1 , ??)?
?
?+1?=1where ?(?,?)
is a binary indicator function ??
???+?
?1 , ??
is 1 if the n-gram ???+?
?1 occurs in?
?
and 0 otherwise.???
?, ??
is the n-gram disagreement meas-ure function which is complementary to?
?+ ?, ??
:???
?, ??
=  1?
?
???+?
?1 , ???
?
?+1?=1This feature is designed because ?
?+ ?, ?
?does not penalize long translation with low pre-cision.
Obviously we have the following:?
?+ ?, ??
+ ???
?, ??
=  ?
?
?
+ 1So if the weights of agreement and disagree-ment features are equal, the disagreement-basedfeatures will be equivalent to the translationlength features.
Using disagreement measuresinstead of translation length there could be twopotential advantages: 1) a length feature has beenincluded in the baseline model and we do notneed to add one; 2) we can scale disagreementfeatures independently and gain more modelingflexibility.Similar to a language model score, n-gramconsensus -based feature values cannot besummed up from smaller hypotheses.
Instead, itmust be re-computed when building each newhypothesis.2.5 Model TrainingWe adapt the Minimum Error Rate Training(MERT) (Och, 2003) algorithm to estimate pa-rameters for each member model in co-decoding.Let ??
be the feature weight vector for memberdecoder ??
, the training procedure proceeds asfollows:1.
Choose initial values for ?1 ,?
,??2.
Perform co-decoding using all member de-coders on a development set D with?1 ,?
,??
.
For each decoder ??
, find a newfeature weight vector ???
which optimizesthe specified evaluation criterion L on D us-ing the MERT algorithm based on the n-bestlist ??
generated by ??
:???
= argmax?
?
(?|?,??
,?
))where T denotes the translations selected byre-ranking the translations in ??
using anew feature weight vector ?3.
Let ?1 = ?1?
,?
,??
= ???
and repeat step 2until convergence or a preset iteration limit isreached.Figure 1.
Model training for co-decodingIn step 2, there is no global criterion to optim-ize the co-decoding parameters across membermodels.
Instead, parameters of different membermodels are tuned to maximize the evaluation cri-teria on each member decoder?s own n-best out-put.
Figure 1 illustrates the training process ofco-decoding with 2 member decoders.Source sentencedecoder1decoder2?1MERT?2MERTco-decodingref1??
2?
?5882.6 Output SelectionSince there is more than one model in co-decoding, we cannot rely on member model?sscore function to choose one best translationfrom multiple decoders?
outputs because themodel scores are not directly comparable.
Wewill examine the following two system combina-tion -based solutions to this task:?
Word-level system combination (Rosti et al,2007) of member decoders?
n-best outputs?
Hypothesis selection from combined n-bestlists as proposed in Hildebrand  and Vogel(2008)3 ExperimentsIn this section we present experiments to eva-luate the co-decoding method.
We first describethe data sets and baseline systems.3.1 Data and MetricWe conduct our experiments on the test datafrom the NIST 2005 and NIST 2008 Chinese-to-English machine translation tasks.
The NIST2003 test data is used for development data toestimate model parameters.
Statistics of the datasets are shown in Table 1.
In our experiments allthe models are optimized with case-insensitiveNIST version of BLEU score and we report re-sults using this metric in percentage numbers.Data set # Sentences # WordsNIST 2003 (dev) 919 23,782NIST 2005 (test) 1,082 29,258NIST 2008 (test) 1,357 31,592Table 1: Data set statisticsWe use the parallel data available for theNIST 2008 constrained track of Chinese-to-English machine translation task as bilingualtraining data, which contains 5.1M sentencepairs, 128M Chinese words and 147M Englishwords after pre-processing.
GIZA++ is used toperform word alignment in both directions withdefault settings, and the intersect-diag-grow me-thod is used to generate symmetric word align-ment refinement.The language model used for all models (in-clude decoding models and system combinationmodels described in Section 2.6) is a 5-grammodel trained with the English part of bilingualdata and xinhua portion of LDC English Giga-word corpus version 3.3.2 Member DecodersWe use three baseline decoders in the experi-ments.
The first one (SYS1) is re-implementationof Hiero, a hierarchical phrase-based decoder.Phrasal rules are extracted from all bilingual sen-tence pairs, while rules with variables are ex-tracted only from selected data sets includingLDC2003E14, LDC2003E07, LDC2005T06 andLDC2005T10, which contain around 350,000sentence pairs, 8.8M Chinese words and 10.3MEnglish words.
The second one (SYS2) is a BTGdecoder with lexicalized reordering model basedon maximum entropy principle as proposed byXiong et al (2006).
We use all the bilingual datato extract phrases up to length 3.
The third one(SYS3) is a string-to-dependency tree ?baseddecoder as proposed by Shen et al (2008).
Forrule extraction we use the same setting as inSYS1.
We parsed the language model trainingdata with Berkeley parser, and then trained a de-pendency language model based on the parsingoutput.
All baseline decoders are extended withn-gram consensus ?based co-decoding featuresto construct member decoders.
By default, thebeam size of 20 is used for all decoders in theexperiments.
We run two iterations of decodingfor each member decoder, and hold the value of?
in Equation 5 as a constant 0.05, which istuned on the test data of NIST 2004 Chinese-to-English machine translation task.3.3 Translation ResultsWe first present the overall results of co-decoding on both test sets using the settings aswe described.
For member decoders, up to 4-gram agreement and disagreement features areused.
We also implemented the word-level sys-tem combination (Rosti et al, 2007) and the hy-pothesis selection method (Hildebrand and Vogel,2008).
20-best translations from all decoders areused in the experiments for these two combina-tion methods.
Parameters for both system com-bination and hypothesis selection are also tunedon NIST 2003 test data.
The results are shown inTable 2.NIST 2005 NIST 2008SYS1 38.66/40.08 27.67/29.19SYS2 38.04/39.93 27.25/29.14SYS3 39.50/40.32 28.75/29.68Word-level Comb 40.45/40.85 29.52/30.35Hypo Selection 40.09/40.50 29.02/29.71Table 2: Co-decoding results on test data589In the Table 2, the results of a member decod-er and its corresponding baseline decoder aregrouped together with the later one for the mem-ber decoders.
On both test sets, every memberdecoder performs significantly better than itsbaseline decoder (using the method proposed inKoehn (2004) for statistical significance test).We apply system combination methods to then-best outputs of both baseline decoders andmember decoders.
We notice that we can achieveeven better performance by applying systemcombination methods to member decoders?
n-best outputs.
However, the improvement marginsare smaller than those of baseline decoders onboth test sets.
This could be the result of less di-versified outputs from co-decoding than thosefrom baseline decoders.
In particular, the resultsfor hypothesis selection are only slightly betterthan the best system in co-decoding.We also evaluate the performance of systemcombination using different n-best sizes, and theresults on NIST 2005 data set are shown in Fig-ure 2, where bl- and co- legends denote combina-tion results of baseline decoding and co-decodingrespectively.
From the results we can see thatcombination based on co-decoding?s outputs per-forms consistently better than that based on base-line decoders?
outputs for all n-best sizes we ex-perimented with.
However, we did not observeany significant improvements for both combina-tion schemes when n-best size is larger than 20.Figure 2.
Performance of system combinationwith different sizes of n-best listsOne interesting observation in Table 2 is thatthe performance gap between baseline decodersis narrowed through co-decoding.
For example,the 1.5 points gap between SYS2 and SYS3 onNIST 2008 data set is narrowed to 0.5.
Actuallywe find that the TER score between two memberdecoders?
outputs are significantly reduced (asshown in Table 3), which indicates that the out-puts become more similar due to the use of con-sensus information.
For example, the TER scorebetween SYS2 and SYS3 of the NIST 2008 out-puts are reduced from 0.4238 to 0.2665.NIST 2005 NIST 2008SYS1 vs. SYS2 0.3190/0.2274 0.4016/0.2686SYS1 vs. SYS3 0.3252/0.1840 0.4176/0.2469SYS2 vs. SYS3 0.3498/0.2171 0.4238/0.2665Table 3: TER scores between co-decodingtranslation outputsIn the rest of this section we run a series ofexperiments to investigate the impacts of differ-ent factors in co-decoding.
All the results arereported on NIST 2005 test set.We start with investigating the performancegain due to partial hypothesis re-ranking.
Be-cause Equation 3 is a general model that can beapplied to both partial hypothesis and n-best (fullhypothesis) re-scoring, we compare the results ofboth cases.
Figure 3 shows the BLEU scorecurves with up to 1000 candidates used for re-ranking.
In Figure 3, the suffix p denotes resultsfor partial hypothesis re-ranking, and f for n-bestre-ranking only.
For partial hypothesis re-ranking, obtaining more top-ranked results re-quires increasing the beam size, which is not af-fordable for large numbers in experiments.
Wework around this issue by approximating beamsizes larger than 20 by only enlarging the beamsize for the span covering the entire source sen-tence.
From Figure 3 we can see that all decoderscan gain improvements before the size of candi-date set reaches 100.
When the size is larger than50, co-decoding performs consistently and sig-nificantly better than the re-ranking results onany baseline decoder?s n-best outputs.Figure 3.
Partial hypothesis vs. n-best re-rankingresults on NIST 2005 test dataFigure 4 shows the BLEU scores of a two-system co-decoding as a function of re-decodingiterations.
From the results we can see that theresults for both decoders converge after two ite-rations.In Figure 4, iteration 0 denotes decoding withbaseline model.
The setting of iteration 1 can beviewed as the case of partial co-decoding, in39.539.840.040.340.540.841.041.310 20 50 100 200bl-combco-combbl-hyposelco-hyposel38.038.539.039.540.040.541.041.510 20 50 100 200 500 1000SYS1fSYS2fSYS3fSYS1pSYS2pSYS3p590which one decoder uses member model and theother keeps using baseline model.
The resultsshow that member models help each other: al-though improvements can be made using a singlemember model, best BLEU scores can only beachieved when both member models are used asshown by the results of iteration 2.
The resultsalso help justify the independent parameter esti-mation of member decoders described in Section2.5, since optimizing the performance of one de-coder will eventually bring performance im-provements to all member decoders.Figure 4.
Results using incremental iterationsin co-decodingNext we examine the impacts of different con-sensus-based features in co-decoding.
Table 4shows the comparison results of a two-systemco-decoding using different settings of n-gramagreement and disagreement features.
It is clear-ly shown that both n-gram agreement and disa-greement types of features are helpful, and usingthem together is the best choice.SYS1 SYS2Baseline 38.66 38.04+agreement ?disagreement 39.36 39.02?agreement +disagreement  39.12 38.67+agreement +disagreement 39.68 39.61Table 4: Co-decoding with/without n-gramagreement and disagreement featuresIn Table 5 we show in another dimension theimpact of consensus-based features by restrictingthe maximum order of n-grams used to computeagreement statistics.SYS1 SYS21 38.75 38.272  39.21 39.103 39.48 39.254 39.68 39.615 39.52 39.366 39.58 39.47Table 5: Co-decoding with varied n-gram agree-ment and disagreement featuresFrom the results we do not observe BLEU im-provement for ?
> 4.
One reason could be thatthe data sparsity for high-order n-grams leads toover fitting on development data.We also empirically investigated the impact ofscaling factor ?
in Equation 5.
It is observed inFigure 5 that the optimal value is between 0.01 ~0.1 on both development and test data.Figure 5.
Impact of scaling factor ?4 DiscussionWord-level system combination (system combi-nation hereafter) (Rosti et al, 2007; He et al,2008) has been proven to be an effective way toimprove machine translation quality by usingoutputs from multiple systems.
Our method isdifferent from system combination in severalways.
System combination uses unigram consen-sus only and a standalone decoding model irrele-vant to single decoders.
Our method uses agree-ment information of n-grams, and consensus fea-tures are integrated into decoding models.
Byconstructing a confusion network, system com-bination is able to generate new translations dif-ferent from any one in the input n-best lists,while our method does not extend the searchspaces of baseline decoding models.
Memberdecoders only change the scoring and ranking ofthe candidates in the search spaces.
Results inTable 2 show that these two approaches can beused together to obtain further improvements.The work on multi-system hypothesis selec-tion of Hildebrand and Vogel (2008) bears moreresemblance to our method in that both make useof n-gram agreement statistics.
They also empiri-cally show that n-gram agreement is the mostimportant factor for improvement apart fromlanguage models.Lattice MBR decoding (Tromble et al, 2008)also uses n-gram agreement statistics.
Their workfocuses on exploring larger evidence space byusing a translation lattice instead of the n-best list.They also show the connection between expectedn-gram change and corpus Log-BLEU loss.37.538.038.539.039.540.00 1 2 3 4SYS1SYS238.038.539.039.540.00 0.01 0.03 0.05 0.1 0.2 0.5 1Dev SYS1Dev SYS2Test SYS1Test SYS25915 ConclusionImproving machine translation with multiple sys-tems has been a focus in recent SMT research.
Inthis paper, we present a framework of collabora-tive decoding, in which multiple MT decodersare coordinated to search for better translationsby re-ranking partial hypotheses using aug-mented log-linear models with translation con-sensus -based features.
An iterative approach isproposed to re-rank all hypotheses explored indecoding.
Experimental results show that withcollaborative decoding every member decoderperforms significantly better than its baselinedecoder.
In the future, we will extend our methodto use lattice or hypergraph to compute consen-sus statistics instead of n-best lists.ReferencesNecip Fazil Ayan,  Jing Zheng, and Wen Wang.
2008.Improving alignments for better confusion net-works for combining machine translation systems.In Proc.
Coling, pages 33-40.Srinivas Bangalore, German Bordel and GiuseppeRiccardi.
2001.
Computing consensus translationfrom multiple machine translation systems.
InProc.
ASRU, pages 351-354.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Proc.ACL, pages 263-270.Xiaodong He, Mei Yang, Jianfeng Gao, PatrickNguyen, and Robert Moore.
2008.
Indirect-hmm-based hypothesis for combining outputs from ma-chine translation systems.
In Proc.
EMNLP, pages98-107.Almut Silja Hildebrand and Stephan Vogel.
2008.Combination of machine translation systems viahypothesis selection from combined n-best lists.
In8th AMTA conference, pages 254-261.Philipp Koehn, 2004.
Statistical significance tests formachine translation evaluation.
In Proc.
EMNLP.Philipp Koehn, 2004.
Pharaoh: a beam search decoderfor phrase-based statistical machine translationmodel.
In Proc.
6th AMTA Conference, pages 115-124.Philipp Koehn, Hieu Hoang, Alexandra Brich, ChrisCallison-Burch, Marcello Federico, Nicola Bertol-di, Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, Evan Herbst.
2007.
Moses: opensource toolkit for statistical machine translation.
InProc.
ACL, demonstration session.Shankar Kumar and William Byrne 2004.
MinimumBayes-Risk Decoding for Statistical MachineTranslation.
In HLT-NAACL, pages 169-176.Yang Liu, Qun Liu, Shouxun Lin.
2006.
Tree-to-string alignment template for statistical machinetranslation.
In Proc.
ACL-Coling, pages 609-616.Evgeny Matusov, Nicola Ueffi ng, and Hermann Ney.2006.
Computing consensus translation from mul-tiple machine translation systems using enchancedhypotheses alignment.
In Proc.
EACL, pages 33-40.Franz Och and Hermann Ney.
2002.
Discriminativetraining and maximum entropy models for statis-tical machine translation.
In Proc.
ACL, pages 295-302.Franz Och.
2003.
Minimum error rate training in sta-tistical machine translation.
In Proc.
ACL, pages160-167.Franz Och and Hermann Ney.
2004.
The alignmenttemplate approach to statistical machine transla-tion.
Computational Linguistics, 30(4), pages 417-449Antti-Veikko Rosti, Necip Fazil Ayan, Bing Xiang,Spyros Matsoukas, Richard Schwartz, and BonnieDorr.
2007.
Combining outputs from multiple ma-chine translation systems.
In HLT-NAACL, pages228-235Antti-Veikko Rosti, Bing Zhang, Spyros Matsoukas,and Richard Schwartz.
2008.
Incremental hypothe-sis alignment for building confusion networks withapplication to machine translation system combina-tion.
In Proc.
Of the Third ACL Workshop on Sta-tistical Machine Translation, pages 183-186.K.C.
Sim, W. Byrne, M. Gales, H. Sahbi, and P.Woodland.
2007.
Consensus network decoding forstatistical machine translation system combination.In ICASSP.Libin Shen, Jinxi Xu, and Ralph Weischedel.
2008.
Anew string-to-dependency machine translation al-gorithm with a target dependency language model.In Proc.
HLT-ACL, pages 577-585.Roy W. Tromble, Shankar Kumar, Franz Och, andWolfgang Macherey.
2008.
Lattice minimumbayes-risk decoding for statistical machine transla-tion.
In Proc.
EMNLP, pages 620-629.Deyi Xiong, Qun Liu and Shouxun Lin.
2006.
Maxi-mum entropy based phrase reordering model forstatistical machine translation.
In Proc.
ACL, pages521-528.592
