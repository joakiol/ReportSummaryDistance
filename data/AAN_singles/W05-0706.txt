Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages, pages 39?46,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsChoosing an Optimal Architecture for Segmentation and POS-Tagging ofModern HebrewRoy Bar-HaimDept.
of Computer ScienceBar-Ilan UniversityRamat-Gan 52900, Israelbarhair@cs.biu.ac.ilKhalil Sima?anILLCUniversiteit van AmsterdamAmsterdam, The Netherlandssimaan@science.uva.nlYoad WinterDept.
of Computer ScienceTechnionHaifa 32000, Israelwinter@cs.technion.ac.ilAbstractA major architectural decision in de-signing a disambiguation model for seg-mentation and Part-of-Speech (POS) tag-ging in Semitic languages concerns thechoice of the input-output terminal sym-bols over which the probability distribu-tions are defined.
In this paper we de-velop a segmenter and a tagger for He-brew based on Hidden Markov Models(HMMs).
We start out from a morpholog-ical analyzer and a very small morpholog-ically annotated corpus.
We show that amodel whose terminal symbols are wordsegments (=morphemes), is advantageousover a word-level model for the task ofPOS tagging.
However, for segmentationalone, the morpheme-level model has nosignificant advantage over the word-levelmodel.
Error analysis shows that bothmodels are not adequate for resolving acommon type of segmentation ambiguityin Hebrew ?
whether or not a word in awritten text is prefixed by a definitenessmarker.
Hence, we propose a morpheme-level model where the definiteness mor-pheme is treated as a possible feature ofmorpheme terminals.
This model exhibitsthe best overall performance, both in POStagging and in segmentation.
Despite thesmall size of the annotated corpus avail-able for Hebrew, the results achieved us-ing our best model are on par with recentresults on Modern Standard Arabic.1 IntroductionTexts in Semitic languages like Modern Hebrew(henceforth Hebrew) and Modern Standard Ara-bic (henceforth Arabic), are based on writing sys-tems that allow the concatenation of different lexi-cal units, called morphemes.
Morphemes may be-long to various Part-of-Speech (POS) classes, andtheir concatenation forms textual units delimited bywhite space, which are commonly referred to aswords.
Hence, the task of POS tagging for Semiticlanguages consists of a segmentation subtask anda classification subtask.
Crucially, words can besegmented into different alternative morpheme se-quences, where in each segmentation morphemesmay be ambiguous in terms of their POS tag.
Thisresults in a high level of overall ambiguity, aggra-vated by the lack of vocalization in modern Semitictexts.One crucial problem concerning POS tagging ofSemitic languages is how to adapt existing methodsin the best way, and which architectural choices haveto be made in light of the limited availability of an-notated corpora (especially for Hebrew).
This paperoutlines some alternative architectures for POS tag-ging of Hebrew text, and studies them empirically.This leads to some general conclusions about the op-timal architecture for disambiguating Hebrew, and(reasonably) other Semitic languages as well.
Thechoice of tokenization level has major consequencesfor the implementation using HMMs, the sparsenessof the statistics, the balance of the Markov condi-39tioning, and the possible loss of information.
Thepaper reports on extensive experiments for compar-ing different architectures and studying the effectsof this choice on the overall result.
Our best resultis on par with the best reported POS tagging resultsfor Arabic, despite the much smaller size of our an-notated corpus.The paper is structured as follows.
Section 2 de-fines the task of POS tagging in Hebrew, describesthe existing corpora and discusses existing relatedwork.
Section 3 concentrates on defining the dif-ferent levels of tokenization, specifies the details ofthe probabilistic framework that the tagger employs,and describes the techniques used for smoothing theprobability estimates.
Section 4 compares the differ-ent levels of tokenization empirically, discusses theirlimitations, and proposes an improved model, whichoutperforms both of the initial models.
Finally, sec-tion 5 discusses the conclusions of our study for seg-mentation and POS tagging of Hebrew in particular,and Semitic languages in general.2 Task definition, corpora and relatedworkWords in Hebrew texts, similar to words in Ara-bic and other Semitic languages, consist of a stemand optional prefixes and suffixes.
Prefixes includeconjunctions, prepositions, complementizers and thedefiniteness marker (in a strict well-defined order).Suffixes include inflectional suffixes (denoting gen-der, number, person and tense), pronominal comple-ments with verbs and prepositions, and possessivepronouns with nouns.By the term word segmentation we henceforth re-fer to identifying the prefixes, the stem and suffixesof the word.
By POS tag disambiguation we meanthe assignment of a proper POS tag to each of thesemorphemes.In defining the task of segmentation and POS tag-ging, we ignore part of the information that is usu-ally found in Hebrew morphological analyses.
Theinternal morphological structure of stems is not an-alyzed, and the POS tag assigned to stems includesno information about their root, template/pattern, in-flectional features and suffixes.
Only pronominalcomplement suffixes on verbs and prepositions areidentified as separate morphemes.
The constructstate/absolute,1 and the existence of a possessivesuffix are identified using the POS tag assigned tothe stem, and not as a separate segment or feature.Some of these conventions are illustrated by the seg-mentation and POS tagging of the word wfnpgfnw(?and that we met?, pronounced ve-she-nifgashnu):2w/CC: conjunctionf /COM: complementizernpgfnw/VB: verbOur segmentation and POS tagging conform withthe annotation scheme used in the Hebrew Treebank(Sima?an et al, 2001), described next.2.1 Available corporaThe Hebrew Treebank (Sima?an et al, 2001) con-sists of syntactically annotated sentences taken fromarticles from the Ha?aretz daily newspaper.
We ex-tracted from the treebank a mapping from each wordto its analysis as a sequence of POS tagged mor-phemes.
The treebank version used in the currentwork contains 57 articles, which amount to 1,892sentences, 35,848 words, and 48,332 morphemes.In addition to the manually tagged corpus, we haveaccess to an untagged corpus containing 337,651words, also originating from Ha?aretz newspaper.The tag set, containing 28 categories, was ob-tained from the full morphological tagging by re-moving the gender, number, person and tense fea-tures.
This tag set was used for training the POStagger.
In the evaluation of the results, however, weperform a further grouping of some POS tags, lead-ing to a reduced POS tag set of 21 categories.
Thetag set and the grouping scheme are shown below:{NN}, {NN-H}, {NNT}, {NNP}, {PRP,AGR}, {JJ}, {JJT},{RB,MOD}, {RBR}, {VB,AUX}, {VB-M}, {IN,COM,REL},{CC}, {QW}, {HAM}, {WDT,DT}, {CD,CDT}, {AT}, {H},{POS}, {ZVL}.2.2 Related work on Hebrew and ArabicDue to the lack of substantial tagged corpora, mostprevious corpus-based work on Hebrew focus on the1The Semitic construct state is a special form of a wordthat participates in compounds.
For instance, in the Hebrewcompound bdiqt hjenh (?check of the claim?
), the word bdiqt(?check of?/?test of?)
is the construct form of the absolute formbdiqh (?check?/?test?
).2In this paper we use Latin transliteration for Hebrew lettersfollowing (Sima?an et al, 2001).40development of techniques for learning probabilitiesfrom large unannotated corpora.
The candidate anal-yses for each word were usually obtained from amorphological analyzer.Levinger et al (1995) propose a method forchoosing a most probable analysis for Hebrewwords using an unannotated corpus, where eachanalysis consists of the lemma and a set of morpho-logical features.
They estimate the relative frequen-cies of the possible analyses for a given word w bydefining a set of ?similar words?
SW (A) for eachpossible analysis A of w. Each word w?
in SW (A)corresponds to an analysis A?
which differs from Ain exactly one feature.
Since each set is expected tocontain different words, it is possible to approximatethe frequency of the different analyses using the av-erage frequency of the words in each set, estimatedfrom the untagged corpus.Carmel and Maarek (1999) follow Levinger etal.
in estimating context independent probabilitiesfrom an untagged corpus.
Their algorithm learns fre-quencies of morphological patterns (combinationsof morphological features) from the unambiguouswords in the corpus.Several works aimed at improving the ?similarwords?
method by considering the context of theword.
Levinger (1992) adds a short context filter thatenforces grammatical constraints and rules out im-possible analyses.
Segal?s (2000) system includes,in addition to a somewhat different implementationof ?similar words?, two additional components: cor-rection rules a` la Brill (1995), and a rudimentary de-terministic syntactic parser.Using HMMs for POS tagging and segmentingHebrew was previously discussed in (Adler, 2001).The HMM in Adler?s work is trained on an untaggedcorpus, using the Baum-Welch algorithm (Baum,1972).
Adler suggests various methods for perform-ing both tagging and segmentation, most notable are(a) The usage of word-level tags, which uniquely de-termine the segmentation and the tag of each mor-pheme, and (b) The usage of a two-dimensionalMarkov model with morpheme-level tags.
Only thefirst method (word-level tags) was tested, resultingin an accuracy of 82%.
In the present paper, bothword-level tagging and morpheme-level tagging areevaluated.Moving on to Arabic, Lee et al (2003) describe aword segmentation system for Arabic that uses an n-gram language model over morphemes.
They startwith a seed segmenter, based on a language modeland a stem vocabulary derived from a manually seg-mented corpus.
The seed segmenter is improved it-eratively by applying a bootstrapping scheme to alarge unsegmented corpus.
Their system achievesaccuracy of 97.1% (per word).Diab et al (2004) use Support Vector Machines(SVMs) for the tasks of word segmentation and POStagging (and also Base Phrase Chunking).
For seg-mentation, they report precision of 99.09% and re-call of 99.15%, when measuring morphemes thatwere correctly identified.
For tagging, Diab et alreport accuracy of 95.49%, with a tag set of 24 POStags.
Tagging was applied to segmented words, us-ing the ?gold?
segmentation from the annotated cor-pus (Mona Diab, p.c.
).3 Architectures for POS tagging SemiticlanguagesOur segmentation and POS tagging system consistsof a morphological analyzer that assigns a set ofpossible candidate analyses to each word, and a dis-ambiguator that selects from this set a single pre-ferred analysis per word.
Each candidate analysisconsists of a segmentation of the word into mor-phemes, and a POS tag assignment to these mor-phemes.
In this section we concentrate on the ar-chitectural decisions in devising an optimal disam-biguator, given a morphological analyzer for He-brew (or another Semitic language).3.1 Defining the input/outputAn initial crucial decision in building a disambigua-tor for a Semitic text concerns the ?tokenization?
ofthe input sentence: what constitutes a terminal (i.e.,input) symbol.
Unlike English POS tagging, wherethe terminals are usually assumed to be words (de-limited by white spaces), in Semitic texts there aretwo reasonable options for fixing the kind of termi-nal symbols, which directly define the correspond-ing kind of nonterminal (i.e., output) symbols:Words (W): The terminals are words as they ap-pear in the text.
In this case a nonterminal athat is assigned to a word w consists of a se-quence of POS tags, each assigned to a mor-41pheme of w, delimited with a special segmenta-tion symbol.
We henceforth refer to such com-plex nonterminals as analyses.
For instance,the analysis IN-H-NN for the Hebrew wordbbit uniquely encodes the segmentation b-h-bit.In Hebrew, this unique encoding of the segmen-tation by the sequence of POS tags in the anal-ysis is a general property: given a word w anda complex nonterminal a = [t1 .
.
.
tp] for w, itis possible to extend a back to a full analysisa?
= [(m1, t1) .
.
.
(mp, tp)], which includes themorphemes m1 .
.
.mp that make out w. This isdone by finding a match for a in Analyses(w),the set of possible analyses of w. Except forvery rare cases, this match is unique.Morphemes (M): In this case the nonterminals arethe usual POS tags, and the segmentation isgiven by the input morpheme sequence.
Notethat information about how morphemes arejoined into words is lost in this case.Having described the main input-output options forthe disambiguator, we move on to describing theprobabilistic framework that underlies their work-ings.3.2 The probabilistic frameworkLet wk1 be the input sentence, a sequence of wordsw1 .
.
.
wk.
If tokenization is per word, then thedisambiguator aims at finding the nonterminal se-quence ak1 that has the highest joint probability withthe given sentence wk1 :argmaxak1P (wk1 ,ak1) (1)This setting is the standard formulation of proba-bilistic tagging for languages like English.If tokenization is per morpheme, the disambigua-tor aims at finding a combination of a segmentationmn1 and a tagging tn1 for mn1 , such that their jointprobability with the given sentence, wk1 , is maxi-mized:argmax(mn1 ,tn1 )?ANALY SES(wk1 )P (wk1 ,mn1 , tn1 ), (2)where ANALY SES(wk1) is the set of possibleanalyses for the input sentence wk1 (output by themorphological analyzer).
Note that n can be dif-ferent from k, and may vary for different segmen-tations.
The original sentence can be uniquely re-covered from the segmentation and the tagging.Since all the ?mn1 , tn1 ?
pairs that are the input forthe disambiguator were derived from wk1 , we haveP (wk1 |mn1 , tn1 ) = 1, and thus P (wk1 ,mn1 , tn1 ) =P (tn1 ,mn1 ).
Therefore, Formula (2) can be simpli-fied as:argmax(mn1 ,tn1 )?ANALY SES(wk1 )P (mn1 , tn1 ) (3)Formulas (1) and (3) can be represented in a unifiedformula that applies to both word tokenization andmorpheme tokenization:argmax(en1 ,An1 )?ANALY SES(wk1 )P (en1 , An1 ) (4)In Formula (4) en1 represents either a sequence ofwords or a sequence of morphemes, depending onthe level of tokenization, and An1 are the respectivenonterminals ?
either POS tags or word-level anal-yses.
Thus, the disambiguator aims at finding themost probable ?terminal sequence, nonterminalsequence?
for the given sentence, where in thecase of word-tokenization there is only one possibleterminal sequence for the sentence.3.3 HMM probabilistic modelThe actual probabilistic model used in this work forestimating P (en1 , An1 ) is based on Hidden MarkovModels (HMMs).
HMMs underly many successfulPOS taggers , e.g.
(Church, 1988; Charniak et al,1993).For a k-th order Markov model (k = 1 or k = 2),we rewrite (4) as:argmaxen1 ,An1P (en1 , An1 ) ?argmaxen1 ,An1n?i=1P (Ai | Ai?k, .
.
.
, Ai?1)P (ei | Ai)(5)For reasons of data sparseness, actual models we usework with k = 2 for the morpheme level tokeniza-tion, and with k = 1 for the word level tokenization.42For these models, two kinds of probabilities needto be estimated: P (ei | Ai) (lexical model) andP (Ai |Ai?k, .
.
.
, Ai?1) (language model).
Becausethe only manually POS tagged corpus that was avail-able to us for training the HMM was relatively small(less than 4% of the Wall Street Journal (WSJ) por-tion of the Penn treebank), it is inevitable that majoreffort must be dedicated to alleviating the sparsenessproblems that arise.
For smoothing the nonterminallanguage model probabilities we employ the stan-dard backoff smoothing method of Katz (1987).Naturally, the relative frequency estimates ofthe lexical model suffer from more severe data-sparseness than the estimates for the languagemodel.
On average, 31.3% of the test words donot appear in the training corpus.
Our smooth-ing method for the lexical probabilities is describednext.3.4 Bootstrapping a better lexical modelFor the sake of exposition, we assume word-leveltokenization for the rest of this subsection.
Themethod used for the morpheme-level tagger is verysimilar.The smoothing of the lexical probability of a wordw given an analysis a, i.e., P (w | a) = P (w,a)P (a) ,is accomplished by smoothing the joint probabilityP (w,a) only, i.e., we do not smooth P (a).3 Tosmooth P (w,a), we use a linear interpolation ofthe relative frequency estimates from the annotatedtraining corpus (denoted rf tr(w,a)) together withestimates obtained by unsupervised estimation froma large unannotated corpus (denoted emauto(w,a)):P (w,a) = ?
rf tr(w,a)+(1??)
emauto(w,a)(6)where ?
is an interpolation factor, experimentally setto 0.85.Our unsupervised estimation method can beviewed as a single iteration of the Baum-Welch(Forward-Backward) estimation algorithm (Baum,1972) with minor differences.
We apply this methodto the untagged corpus of 340K words.
Our methodstarts out from a naively smoothed relative fre-3the smoothed probabilities are normalized so that?w P (w,a) = P (a)quency lexical model in our POS tagger:PLM0(w|a) ={(1 ?
p0) rf tr(w,a) ftr(w) > 0p0 otherwise(7)Where ftr(w) is the occurrence frequency of w inthe training corpus, and p0 is a constant set experi-mentally to 10?10.
We denote the tagger that em-ploys a smoothed language model and the lexicalmodel PLM0 by the probability distribution Pbasic(over analyses, i.e., morpheme-tag sequences).In the unsupervised algorithm, the model Pbasicis used to induce a distribution of alternative analy-ses (morpheme-tag sequences) for each of the sen-tences in the untagged corpus; we limit the num-ber of alternative analyses per sentence to 300.
Thisway we transform the untagged corpus into a ?cor-pus?
containing weighted analyses (i.e., morpheme-tag sequences).
This corpus is then used to calcu-late the updated lexical model probabilities usingmaximum-likelihood estimation.
Adding the testsentences to the untagged corpus ensures non-zeroprobabilities for the test words.3.5 Implementation4The set of candidate analyses was obtained from Se-gal?s morphological analyzer (Segal, 2000).
Theanalyzer?s dictionary contains 17,544 base formsthat can be inflected.
After this dictionary was ex-tended with the tagged training corpus, it recog-nizes 96.14% of the words in the test set.5 For eachtrain/test split of the corpus, we only use the trainingdata for enhancing the dictionary.
We used SRILM(Stolcke, 2002) for constructing language models,and for disambiguation.4 EvaluationIn this section we report on an empirical comparisonbetween the two levels of tokenization presented inthe previous section.
Analysis of the results leads toan improved morpheme-level model, which outper-forms both of the initial models.Each architectural configuration was evaluated in5-fold cross-validated experiments.
In a train/test4http://www.cs.technion.ac.il/?barhaim/MorphTagger/5Unrecognized words are assumed to be proper nouns, andthe morphological analyzer proposes possible segmentations forthe word, based on the recognition of possible prefixes.43split of the corpus, the training set includes 1,598sentences on average, which on average amount to28,738 words and 39,282 morphemes.
The test setincludes 250 sentences.
We estimate segmentationaccuracy ?
the percentage of words correctly seg-mented into morphemes, as well as tagging accu-racy ?
the percentage of words that were correctlysegmented for which each morpheme was assignedthe correct POS tag.For each parameter, the average over the five foldsis reported, with the standard deviation in parenthe-ses.
We used two-tailed paired t-test for testing thesignificance of the difference between the averageresults of different systems.
The significance level(p-value) is reported.The first two lines in Table 1 detail the results ob-tained for both word (W) and morpheme (M) lev-els of tokenization.
The tagging accuracy of theAccuracy per word (%)Tokenization Tagging SegmentationW 89.42 (0.9) 96.43 (0.3)M 90.21 (1.2) 96.25 (0.5)M+h 90.51 (1.0) 96.74 (0.5)Table 1: Level of tokenization - experimental resultsmorpheme tagger is considerably better than whatis achieved by the word tagger (difference of 0.79%with significance level p = 0.01).
This is in spite ofthe fact that the segmentation achieved by the wordtagger is a little better (and a segmentation error im-plies incorrect tagging).
Our hypothesis is that:Morpheme-level taggers outperformword-level taggers in their tagging ac-curacy, since they suffer less from datasparseness.
However, they lack someword-level knowledge that is required forsegmentation.This hypothesis is supported by the number ofonce-occurring terminals in each level: 8,582 in theword level, versus 5,129 in the morpheme level.Motivated by this hypothesis, we next considerwhat kind of word-level information is required forthe morpheme-level tagger in order to do better insegmentation.
One natural enhancement for themorpheme-level model involves adding informationabout word boundaries to the tag set.
In the en-hanced tag set, nonterminal symbols include addi-tional features that indicate whether the tagged mor-pheme starts/ends a word.
Unfortunately, we foundthat adding word boundary information in this waydid not improve segmentation accuracy.However, error analysis revealed a very commontype of segmentation errors, which was found to beconsiderably more frequent in morpheme taggingthan in word tagging.
This kind of errors involvesa missing or an extra covert definiteness marker ?h?.For example, the word bbit can be segmented eitheras b-bit (?in a house?)
or as b-h-bit (?in the house?
),pronounced bebayit and babayit, respectively.
Un-like other cases of segmentation ambiguity, whichoften just manifest lexical facts about spelling of He-brew stems, this kind of ambiguity is productive: itoccurs whenever the stem?s POS allows definiteness,and is preceded by one of the prepositions b/k/l.
Inmorpheme tagging, this type of error was found onaverage in 1.71% of the words (46% of the segmen-tation errors).
In word tagging, it was found onlyin 1.36% of the words (38% of the segmentation er-rors).Since in Hebrew there should be agreement be-tween the definiteness status of a noun and its relatedadjective, this kind of ambiguity can sometimes beresolved syntactically.
For instance:?bbit hgdwl?
implies b-h-bit (?in the big house?
)?bbit gdwl?
implies b-bit (?in a big house?
)By contrast, in many other cases both analysesare syntactically valid, and the choice between themrequires consideration of a wider context, or someworld knowledge.
For example, in the sentencehlknw lmsibh (?we went to a/the party?
), lmsibhcan be analyzed either as l-msibh (indefinite,?to aparty?)
or as l-h-mbsibh (definite,?to the party?
).Whether we prefer ?the party?
or ?a party?
dependson contextual information that is not available forthe POS tagger.Lexical statistics can provide valuable informa-tion in such situations, since some nouns are morecommon in their definite form, while other nouns aremore common as indefinite.
For example, considerthe word lmmflh (?to a/the government?
), which canbe segmented either as l-mmflh or l-h-mmflh.
The44Tokenization AnalysisW (lmmflh IN-H-NN)M (IN l) (H h) (NN mmflh)M+h (IN l) (H-NN hmmflh)Table 2: Representation of l-h-mmflh in each levelof tokenizationstem mmflh (?government?)
was found 25 times inthe corpus, out of which only two occurrences wereindefinite.
This strong lexical evidence in favor ofl-h-mmflh is completely missed by the morpheme-level tagger, in which morphemes are assumed tobe independent.
The lexical model of the word-level tagger better models this difference, since itdoes take into account the frequencies of l-mmflhand l-h-mmlh, in measuring P(lmmflh|IN-NN) andP(lmmflh|IN-H-NN).
However, since the word tag-ger considers lmmflh, hmmflh (?the government?
),and mmflh (?a government?)
as independent words,it still exploits only part of the potential lexical evi-dence about definiteness.In order to better model such situations, wechanged the morpheme-level model as follows.
Indefinite words the definiteness article h is treatedas a manifestation of a morphological feature of thestem.
Hence the definiteness marker?s POS tag (H)is prefixed to the POS tag of the stem.
We refer byM+h to the resulting model that uses this assump-tion, which is rather standard in theoretical linguisticstudies of Hebrew.
The M+h model can be viewed asan intermediate level of tokenization, between mor-pheme and word tokenization.
The different analy-ses obtained by the three models of tokenization aredemonstrated in Table 2.As shown in Table 1, the M+h model showsremarkable improvement in segmentation (0.49%,p < 0.001) compared with the initial morpheme-level model (M).
As expected, the frequency of seg-mentation errors that involve covert definiteness (h)dropped from 1.71% to 1.25%.
The adjusted mor-pheme tagger also outperforms the word level taggerin segmentation (0.31%, p = 0.069).
Tagging wasimproved as well (0.3%, p = 0.068).
According tothese results, tokenization as in the M+h model ispreferable to both plain-morpheme and plain-wordtokenization.5 ConclusionDeveloping a word segmenter and POS tagger forHebrew with less than 30K annotated words fortraining is a challenging task, especially given themorphological complexity and high degree of am-biguity in Hebrew.
For comparison, in English abaseline model that selects the most frequent POStag achieves accuracy of around the 90% (Charniaket al, 1993).
However, in Hebrew we found that aparallel baseline model achieves only 84% using theavailable corpus.The architecture proposed in this paper addressesthe severe sparseness problems that arise in a num-ber of ways.
First, the M+h model, which wasfound to perform best, is based on morpheme-level tokenization, which suffers of data sparse-ness less than word tokenization, and makes use ofmulti-morpheme nonterminals only in specific caseswhere it was found to be valuable.
The number ofnonterminal types found in the corpus for this modelis 49 (including 11 types of punctuation marks),which is much closer to the morpheme-level model(39 types) than to the word-level model (205 types).Second, the bootstrapping method we present ex-ploits additional resources such as a morphologicalanalyzer and an untagged corpus, to improve lexi-cal probabilities, which suffer from data sparsenessthe most.
The improved lexical model contributes1.5% to the tagging accuracy, and 0.6% to the seg-mentation accuracy (compared with using the basiclexical model), making it a crucial component of oursystem.Among the few other tools available for POS tag-ging and morphological disambiguation in Hebrew,the only one that is freely available for extensivetraining and evaluation as performed in this paperis Segal?s ((Segal, 2000), see section 2.2).
Com-paring our best architecture to the Segal tagger?s re-sults under the same experimental setting shows animprovement of 1.5% in segmentation accuracy and4.5% in tagging accuracy over Segal?s results.Moving on to Arabic, in a setting comparable to(Diab et al, 2004), in which the correct segmenta-tion is given, our tagger achieves accuracy per mor-pheme of 94.9%.
This result is close to the re-45sult reported by Diab et al, although our result wasachieved using a much smaller annotated corpus.We therefore believe that future work may benefitfrom applying our model, or variations thereof, toArabic and other Semitic languages.One of the main sources for tagging errors in ourmodel is the coverage of the morphological analyzer.The analyzer misses the correct analysis of 3.78% ofthe test words.
Hence, the upper bound for the accu-racy of the disambiguator is 96.22%.
Increasing thecoverage while maintaining the quality of the pro-posed analyses (avoiding over-generation as muchas possible), is crucial for improving the tagging re-sults.It should also be mentioned that a new version ofthe Hebrew treebank, now containing approximately5,000 sentences, was released after the current workwas completed.
We believe that the additional an-notated data will allow to refine our model, both interms of accuracy and in terms of coverage, by ex-panding the tag set with additional morpho-syntacticfeatures like gender and number, which are prevalentin Hebrew and other Semitic languages.AcknowledgmentsWe thank Gilad Ben-Avi, Ido Dagan and Alon Itaifor their insightful remarks on major aspects of thiswork.
The financial and computational support ofthe Knowledge Center for Processing Hebrew isgratefully acknowledged.
The first author would liketo thank the Technion for partially funding his partof the research.
The first and third authors are grate-ful to the ILLC of the University of Amsterdam forits hospitality while working on this research.
Wealso thank Andreas Stolcke for his devoted technicalassistance with SRILM.ReferencesMeni Adler.
2001.
Hidden Markov Model for Hebrewpart-of-speech tagging.
Master?s thesis, Ben GurionUniversity, Israel.
In Hebrew.Leonard Baum.
1972.
An inequality and associated max-imization technique in statistical estimation for proba-bilistic functions of a Markov process.
In InequalitiesIII:Proceedings of the Third Symposium on Inequali-ties, University of California, Los Angeles, pp.1-8.Eric Brill.
1995.
Transformation-based error-drivenlearning and natural language processing: A casestudy in part-of-speech tagging.
Computational Lin-guistic, 21:784?789.David Carmel and Yoelle Maarek.
1999.
Morphologicaldisambiguation for Hebrew search systems.
In Pro-ceedings of the 4th international workshop,NGITS-99.Eugene Charniak, Curtis Hendrickson, Neil Jacobson,and Mike Perkowitz.
1993.
Equations for part-of-speech tagging.
In National Conference on ArtificialIntelligence, pages 784?789.K.
W. Church.
1988.
A stochastic parts program andnoun phrase parser for unrestricted text.
In Proc.
ofthe Second Conference on Applied Natural LanguageProcessing, pages 136?143, Austin, TX.Mona Diab, Kadri Hacioglu, and Daniel Jurafsky.
2004.Automatic tagging of Arabic text: From raw text tobase phrase chunks.
In HLT-NAACL 2004: Short Pa-pers, pages 149?152.S.M.
Katz.
1987.
Estimation of probabilities from sparsedata from the language model component of a speechrecognizer.
IEEE Transactions of Acoustics, Speechand Signal Processing, 35(3):400?401.Young-Suk Lee, Kishore Papineni, Salim Roukos, Os-sama Emam, and Hany Hassan.
2003.
Languagemodel based Arabic word segmentation.
In ACL,pages 399?406.M.
Levinger, U. Ornan, and A. Itai.
1995.
Morphologicaldisambiguation in Hebrew using a priori probabilities.Computational Linguistics, 21:383?404.Moshe Levinger.
1992.
Morphological disambiguationin Hebrew.
Master?s thesis, Computer Science Depart-ment, Technion, Haifa, Israel.
In Hebrew.Erel Segal.
2000.
Hebrew morphological ana-lyzer for Hebrew undotted texts.
Master?s the-sis, Computer Science Department, Technion,Haifa, Israel.
http://www.cs.technion.ac.il/-?erelsgl/bxi/hmntx/teud.html.K.
Sima?an, A. Itai, Y.
Winter, A. Altman, and N. Nativ.2001.
Building a tree-bank of Modern Hebrew text.Traitment Automatique des Langues, 42:347?380.Andreas Stolcke.
2002.
SRILM - an extensible languagemodeling toolkit.
In ICSLP, pages 901?904, Denver,Colorado, September.46
