Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 176?180,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsTransforming Standard Arabic to Colloquial ArabicEmad Mohamed, Behrang Mohit and Kemal OflazerCarnegie Mellon University - QatarDoha, Qataremohamed@qatar.cmu.edu, behrang@cmu.edu, ko@cs.cmu.eduAbstractWe present a method for generating ColloquialEgyptian Arabic (CEA) from morphologically dis-ambiguated Modern Standard Arabic (MSA).When used in POS tagging, this process improvesthe accuracy from 73.24% to 86.84% on unseenCEA text, and reduces the percentage of out-of-vocabulary words from 28.98% to 16.66%.
Theprocess holds promise for any NLP task targetingthe dialectal varieties of Arabic; e.g., this approachmay provide a cheap way to leverage MSA dataand morphological resources to create resourcesfor colloquial Arabic to English machine transla-tion.
It can also considerably speed up the annota-tion of Arabic dialects.1.
IntroductionMost of the research on Arabic is focused on Mod-ern Standard Arabic.
Dialectal varieties have notreceived much attention due to the lack of dialectaltools and annotated texts (Duh and Kirchoff,2005).
In this paper, we present a rule-based me-thod to generate Colloquial Egyptian Arabic (CEA)from Modern Standard Arabic (MSA), relying onsegment-based part-of-speech tags.
The transfor-mation process relies on the observation that di-alectal varieties of Arabic differ mainly in the useof affixes and function words while the word stemmostly remains unchanged.
For example, given theBuckwalter-encoded MSA sentence ?AlAxwAnAlmslmwn lm yfwzwA fy AlAntxbAt?
the rules pro-duce ?AlAxwAn Almslmyn mfAzw$ f AlAntxAbAt?(?????????
?
??????
????????
?????
?, The Muslim Bro-therhood did not win the elections).
The availabili-ty of segment-based part-of-speech tags is essentialsince many of the affixes in MSA are ambiguous.For example, lm could be either a negative particleor a question work, and the word AlAxwAn couldbe either made of two segments (Al+<xwAn, thebrothers), or three segments (Al+>xw+An, the twobrothers).We first introduce the transformation rules, andshow that in many cases it is feasible to transformMSA to CEA, although there are cases that requiremuch more than POS tags.
We then provide a typ-ical case in which we utilize the transformed textof the Arabic Treebank (Bies and Maamouri, 2003)to build a part-of-speech tagger for CEA.
The tag-ger improves the accuracy of POS tagging on au-thentic Egyptian Arabic by 13% absolute (from73.24% to 86.84%) and reduces the percentage ofout-of-vocabulary words from 28.98% to 16.66%.2.
MSA to CEA Conversion RulesTable 1 shows a sentence in MSA and its CEAcounterpart.
Both can be translated into: ?We didnot write it for them.?
MSA has three words whileCEA is more synthetic as the preposition and thenegative particle turn into clitics.
Table 1 illu-strates the end product of one of the Imperfecttransformation rules, namely the case where theImperfect Verb is preceded by the negative particlelm.Arabic BuckwalterMSA ???
??????
??
lm nktbhA lhnCEA ??????????
mktbnhlhm$English We did not write it for themTable 1: a sentence in MSA and CEAOur 103 rules cover nominals (number and caseaffixes), verbs (tense, number, gender, and modali-ty), pronouns (number and gender), and demon-strative pronouns (number and gender).The rules also cover certain lexical items as 400words in MSA have been converted to their com-176mon CEA counterparts.
Examples of lexical con-versions include ZlAm and Dlmp (darkness), rjland rAjl (man), rjAl and rjAlp (men), and kvyr andktyr (many), where the first word is the MSA ver-sion and the second is the CEA version.Many of the lexical mappings are ambiguous.For example, the word rjl can either mean man orleg.
When it means man, the CEA form is rAjl, butthe word for leg is the same in both MSA andCEA.
While they have different vowel patterns(rajul and rijol respectively), the vowel informa-tion is harder to get correctly than POS tags.
Theproblem may arise especially when dealing withraw data for which we need to provide POS tags(and vowels) so we may be able to convert it to thecolloquial form.
Below, we provide two samplerules:The imperfect verb is used, inter alia, to expressthe negated past, for which CEA uses the perfectverb.
What makes things more complicated is thatCEA treats negative particles and prepositionalphrases as clitics.
An example of this is the wordmktbthlhm$ (I did not write it for them) in Table 1above.
It is made of the negative particle m, thestem ktb (to write), the object pronoun h, the pre-position l, the pronoun hm (them) and the negativeparticle $.
Figure 1, and the following steps showthe conversions of lm nktbhA lhm tomktbnhAlhm$:1.
Replace the negative word lm with one ofthe prefixes m, mA or the word mA.2.
Replace the Imperfect Verb prefix with itsPerfect Verb suffix counterpart.
For exam-ple, the IV first person singular subject pre-fix > turns into t in the PV.3.
If the verb is followed by a prepositionalphrase headed by the preposition l that con-tains a pronominal object, convert the pre-position to a prepositional clitic.4.
Transform the dual to plural and the pluralfeminine to plural masculine.5.
Add the negative suffix $ (or the variant $y,which is less probable)As alluded to in 1) above, given that colloquialorthography is not standardized, many affixes andclitics can be written in different ways.
For exam-ple, the word mktbnhlhm$, can be written in 24ways.
All these forms are legal and possible, asattested by their existence in a CEA corpus (theArabic Online Commentary Dataset v1.1), whichwe also use for building a language model later.Figure 1: One negated IV form in MSA can generate 24(3x2x2x2) possible forms in CEAMSA possessive pronouns inflect for gender, num-ber (singular, dual, and plural), and person.
InCEA, there is no distinction between the dual andthe plural, and a single pronoun is used for theplural feminine and masculine.
The three MSAforms ktAbhm, ktAbhmA and ktAbhn (their bookfor the masculine plural, the dual, and the feminineplural respectively) all collapse to ktAbhm.Table 2 has examples of some other rules we haveapplied.
We note that the stem, in bold, hardlychanges, and that the changes mainly affect func-tion segments.
The last example is a lexical rule inwhich the stem has to change.Rule MSA CEAFuture swf  yktb Hyktb/hyktbFuture_NEG ln >ktb m$ hktb/ m$ HktbIV yktbwn byktbw/ bktbw/ bktbwAPassive ktb Anktb/ AtktbNEG_PREP lys mnhn mmnhm$Lexical trkhmA sAbhmTable 2: Examples of Conversion Rules.3.
POS Tagging Egyptian ArabicWe use the conversion above to build a POS taggerfor Egyptian Arabic.
We follow Mohamed andKuebler (2010) in using whole word tagging, i.e.,without any word segmentation.
We use the Co-lumbia Arabic Treebank 6-tag tag set: PRT (Par-ticle), NOM (Nouns, Adjectives, and Adverbs),PROP (Proper Nouns), VRB (Verb), VRB-pass(Passive Verb), and PNX (Punctuation) (Habashand Roth, 2009).
For example, the wordwHnktblhm (and we will write to them, ?????????
)receives the tag PRT+PRT+VRB+PRT+NOM.This results in 58 composite tags, 9 of which occur5 times or less in the converted ECA training set.177We converted two sections of the Arabic Tree-bank (ATB): p2v3 and p3v2.
For all the POS tag-ging experiments, we use the memory-based POStagger (MBT) (Daelemans et al, 1996) The bestresults, tuned on a dev set,  were obtained, in non-exhaustive search,  with the Modified Value Dif-ference Metric as a distance metric and with k  (thenumber of nearest neighbors) = 25.
For knownwords, we use the IGTree algorithm and 2 words tothe left, their POS tags, the focus word and its listof possible tags, 1 right context word and its list ofpossible tags as features.
For unknown words, weuse the IB1 algorithm and the word itself, its first 5and last 3 characters, 1 left context word and itsPOS tag, and 1 right context word and its list ofpossible tags as features.3.1.
Development and Test DataAs a development set, we use 100 user-contributedcomments (2757 words) from the website ma-srawy.com, which were judged to be highly collo-quial.
The test set contains 192 comments (7092words) from the same website with the same crite-rion.
The development and test sets were hand-annotated with composite tags as illustrated aboveby two native Arabic-speaking students.The test and development sets contained spel-ling errors (mostly run-on words).
The most com-mon of these is the vocative particle yA, which isusually attached to following word (e.g.
yArAjl,(you man, ??????)).
It is not clear whether it shouldbe treated as a proclitic, since it also occurs as aseparate word, which is the standard way of writ-ing.
The same holds true for the variation betweenthe letters * and z, (?
and ?
in Arabic) which arepronounced exactly the same way in CEA to theextent that the substitution may not be considered aspelling error.3.2.
Experiments and ResultsWe ran five experiments to test the effect of MSAto CEA conversion on POS tagging: (a) Standard,where we train the tagger on the ATB MSA data,(b) 3-gram LM, where for each MSA sentence wegenerate all transformed sentences (see Section 2.1and Figure 1) and pick the most probable sentenceaccording to a trigram language model built froman 11.5 million words of user contributedcomments.1 This corpus is highly dialectal1Available from  http://www.cs.jhu.edu/~ozaidan/AOCEgyptian Arabic, but like all similar collections, itis diglossic and demonstrates a high degree ofcode-switching between MSA and CEA.
We usethe SRILM toolkit (Stolcke, 2002) for languagemodeling and sentence scoring, (c) Random,where we choose a random sentence from all thecorrect sentences generated for each MSAsentence, (d) Hybrid, where we combine the datain a) with the best settings (as measured on the devset) using the converted colloquial data (namelyexperiment c).
Hybridization is necessary sincemost Arabic data in blogs and comments are a mixof MSA and CEA, and (e) Hybrid + dev, wherewe enrich the Hybrid training set with the dev data.We use the following metrics for evaluation:KWA: Known Word Accuracy (%), UWA:Unknown Word Accuracy (%), TA: Total Accuracy(%), and UW: unknown words (%) in therespective set in the respective experiment.
Table3(a) presents the results on the development setwhile Table 3(b) the results on the test set.Experiment KWA UWA TA UW(a) Standard 92.75 39.68 75.77 31.99(b) 3-gram LM 89.12 43.46 76.21 28.29(c) Random 92.36 43.51 79.25 26.84(d) Hybrid 94.13 52.22 84.87 22.09Table 3(a): POS results on the development set.We notice that randomly selecting a sentence fromthe correct generated sentences yields better resultsthan choosing the most probable sentence accord-ing to a language model.
The reason for this maybe that randomization guarantees more coverage ofthe various forms.
We have found that the vocabu-lary size (the number of unique word types) for thetraining set generated for the Random experimentis considerably larger than the vocabulary size forthe 3-gram LM experiment (55367 unique wordtypes in Random versus 51306 in 3-gram LM),which results in a drop of 4.6% absolute in the per-centage of unknown words: 27.31% versus22.30%).
This drop in the percentage of unknownwords may indicate that generating all possiblevariations of CEA may be more useful than using alanguage model in general.
Even in a CEA corpusof 35 million words, one third of the words gener-ated by the rules are not in the corpus, while many178of these are in both the test set and the develop-ment set.Experiment KWA UWA TA UW(a) Standard 89.03 40.67 73.24 28.98(b) 3-gram LM 84.33 47.70 74.32 27.31(c) Random 90.24 48.90 79.67 22.70(d) Hybrid 92.22 53.92 83.81 19.45(e) Hybrid+dev 94.87 56.46 86.84 16.66Table 3(b): POS results on the test setWe also notice that the conversion alone im-proves tagging accuracy from 75.77% to 79.25%on the development set, and from 73.24% to79.67% on the test set.
Combining the originalMSA and the best scoring converted data (Ran-dom) raises the accuracies to 84.87% and 83.81%respectively.
The percentage of unknown wordsdrops from 29.98% to 19.45% in the test set whenwe used the hybrid data.
The fact that the percen-tage of unknown words drops further to 16.66% inthe Hybrid+dev experiment points out the authen-tic colloquial data contains elements that have notbeen captured using conversion alone.4.
Related WorkTo the best of our knowledge, ours is the first workthat generates CEA automatically from morpholog-ically disambiguated MSA, but Habash et al(2005) discussed root and pattern morphologicalanalysis and generation of Arabic dialects withinthe MAGED morphological analyzer.
MAGEDincorporates the morphology, phonology, and or-thography of several Arabic dialects.
Diab et al(2010) worked on the annotation of dialectal Arab-ic through the COLABA project, and they used the(manually) annotated resources to facilitate theincorporation of the dialects in Arabic informationretrieval.Duh and Kirchhoff (2005) successfully designeda POS tagger for CEA that used an MSA morpho-logical analyzer and information gleaned from theintersection of several Arabic dialects.
This is dif-ferent from our approach for which POS tagging isonly an application.
Our focus is to use any exist-ing MSA data to generate colloquial Arabic re-sources that can be used in virtually any NLP task.At a higher level, our work resembles that ofKundu and Roth (2011), in which they chose toadapt the text rather than the model.
While theyadapted the test set, we do so at the training setlevel.5.
Conclusions and Future WorkWe have a presented a method to convert ModernStandard Arabic to Egyptian Colloquial Arabicwith an example application to the POS taggingtask.
This approach may provide a cheap way toleverage MSA data and morphological resources tocreate resources for colloquial Arabic to Englishmachine translation, for example.While the rules of conversion were mainlymorphological in nature, they have proved usefulin handling colloquial data.
However, morphologyalone is not enough for handling key points of dif-ference between CEA and MSA.
While CEA ismainly an SVO language, MSA is mainly VSO,and while demonstratives are pre-nominal in MSA,they are post-nominal in CEA.
These phenomenacan be handled only through syntactic conversion.We expect that converting a dependency-basedtreebank to CEA can account for many of the phe-nomena part-of-speech tags alone cannot handleWe are planning to extend the rules to other lin-guistic phenomena and dialects, with possible ap-plications to various NLP tasks for which MSAannotated data exist.
When no gold standard seg-ment-based POS tags are available, tools that pro-duce segment-based annotation can be used, e.g.segment-based POS tagging (Mohamed and Kueb-ler, 2010) or MADA (Habash et al 2009), althoughthese are not expected to yield the same results asgold standard part-of-speech tags.AcknowledgementsThis publication was made possible by a NPRPgrant (NPRP 09-1140-1-177) from the Qatar Na-tional Research Fund (a member of The QatarFoundation).
The statements made herein are sole-ly the responsibility of the authors.We thank the two native speaker annotators andthe anonymous reviewers for their instructive andenriching feedback.179ReferencesBies, Ann and Maamouri, Mohamed  (2003).
PennArabic Treebank guidelines.
Technical report, LDC,University of Pennsylvania.Buckwalter, T. (2002).
Arabic Morphological Analyz-er (AraMorph).
Version 1.0.
Linguistic Data Consor-tium, catalog number LDC2002L49 and ISBN 1-58563-257- 0Daelemans, Walter and van den Bosch, Antal ( 2005).Memory Based Language Processing.
Cambridge Uni-versity Press.Daelemans, Walter; Zavrel, Jakub; Berck, Peter, andSteven Gillis (1996).
MBT: A memory-based part ofspeech tagger-generator.
In Eva Ejerhed and Ido Dagan,editors, Proceedings of the 4th Workshop on Very LargeCorpora, pages 14?27, Copenhagen, Denmark.Diab, Mona; Habash, Nizar; Rambow, Owen; Altan-tawy, Mohamed, and Benajiba, Yassine.
COLABA:Arabic Dialect Annotation and Processing.
LREC 2010.Duh, K. and Kirchhoff, K. (2005).
POS Tagging ofDialectal Arabic: A Minimally Supervised Approach.Proceedings of the ACL Workshop on ComputationalApproaches to Semitic Languages, Ann Arbor, June2005.Habash, Nizar; Rambow, Own and Kiraz, George(2005).
Morphological analysis and generation forArabic dialects.
Proceedings of the ACL Workshop onComputational Approaches to Semitic Languages, pages17?24, Ann Arbor, June 2005Habash, Nizar and Roth, Ryan.
CATiB: The Colum-bia Arabic Treebank.
Proceedings of the ACL-IJCNLP2009 Conference Short Papers, pages 221?224, Singa-pore, 4 August 2009. c 2009 ACL and AFNLPHabash, Nizar, Owen Rambow and Ryan Roth.
MA-DA+TOKAN: A Toolkit for Arabic Tokenization, Dia-critization, Morphological Disambiguation, POS Tag-ging, Stemming and Lemmatization.
In Proceedings ofthe 2nd International Conference on Arabic LanguageResources and Tools (MEDAR), Cairo, Egypt, 2009Kundu, Gourab abd Roth, Don (2011).
Adapting Textinstead of the Model: An Open Domain Approach.
Pro-ceedings of the Fifteenth Conference on ComputationalNatural Language Learning, pages 229?237,Portland,Oregon, USA, 23?24 June 2011Mohamed, Emad.
and Kuebler, Sandra (2010).
IsArabic Part of Speech Tagging Feasible Without WordSegmentation?
Proceedings of HLT-NAACL 2010, LosAngeles, CA.Stolcke, A.
(2002).
SRILM - an extensible languagemodeling toolkit.
In Proc.
of ICSLP, Denver, Colorado180
