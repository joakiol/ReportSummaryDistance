Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 332?343, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsUniversal Grapheme-to-Phoneme Prediction Over Latin AlphabetsYoung-Bum Kim and Benjamin SnyderUniversity of Wisconsin-Madison{ybkim,bsnyder}@cs.wisc.eduAbstractWe consider the problem of inducinggrapheme-to-phoneme mappings for un-known languages written in a Latin alphabet.First, we collect a data-set of 107 languageswith known grapheme-phoneme relationships,along with a short text in each language.
Wethen cast our task in the framework of super-vised learning, where each known languageserves as a training example, and predictionsare made on unknown languages.
We inducean undirected graphical model that learnsphonotactic regularities, thus relating textualpatterns to plausible phonemic interpretationsacross the entire range of languages.
Ourmodel correctly predicts grapheme-phonemepairs with over 88% F1-measure.1 IntroductionWritten language is one of the defining technologiesof human civilization, and has been independentlyinvented at least three times through the course ofhistory (Daniels and Bright, 1996).
In many wayswritten language reflects its more primary spokencounterpart.
Both are subject to some of the sameforces of change, including human migration, cul-tural influence, and imposition by empire.
In otherways, written language harkens further to the past,reflecting aspects of languages long since gone fromtheir spoken forms.
In this paper, we argue that thisimperfect relationship between written symbol andspoken sound can be automatically inferred fromtextual patterns.
By examining data for over 100languages, we train a statistical model to automat-ically relate graphemic patterns in text to phonemicsequences for never-before-seen languages.We focus here on the the alphabet, a writing sys-tem that has come down to us from the Sumerians.In an idealized alphabetic system, each phonemein the language is unambiguously represented by asingle grapheme.
In practice of course, this idealis never achieved.
When existing alphabets aremelded onto new languages, they must be imper-fectly adapted to a new sound system.
In this paper,we exploit the fact that a single alphabet, that of theRomans, has been adapted to a very large variety oflanguages.Recent research has demonstrated the effective-ness of cross-lingual analysis.
The joint analysis ofseveral languages can increase model accuracy, andenable the development of computational tools forlanguages with minimal linguistic resources.
Previ-ous work has focused on settings where just a hand-ful of languages are available.
We treat the taskof grapheme-to-phoneme analysis as a test case forlarger scale multilingual learning, harnessing infor-mation from dozens of languages.On a more practical note, accurately relatinggraphemes and phonemes to one another is cru-cial for tasks such as automatic speech recognitionand text-to-speech generation.
While pronunciationdictionaries and transcribed audio are available forsome languages, these resources are entirely lack-ing for the vast majority of the world?s languages.Thus, automatic and generic methods for determin-ing sound-symbol relationships are needed.Our paper is based on the following line of rea-soning: that character-level textual patterns mirror332phonotactic regularities; that phonotactic regulari-ties are shared across related languages and uni-versally constrained; and that textual patterns for anewly observed language may thus reveal its under-lying phonemics.
Our task can be viewed as an easycase of lost language decipherment ?
one where theunderlying alphabetic system is widely known.Nevertheless, the task of grapheme-to-phonemeprediction is challenging.
Characters in the Romanalphabet can take a wide range of phonemic valuesacross the world?s languages.
For example, depend-ing on the language, the grapheme ?c?
can representthe following phonemes:1?
/k/ (unvoiced velar plosive)?
/c/ (unvoiced palatal plosive)?
/s/ (unvoiced alveolar fricative)?
/|/ (dental click)?
/>dZ/ (affricated voiced postalveolar fricative)?
/>tS/ (affricated unvoiced postalveolar fricative)?
/>ts/ (affricated unvoiced alveolar fricative)To make matters worse, the same language mayuse a single grapheme to ambiguously representmultiple phonemes.
For example, English orthog-raphy uses ?c?
to represent both /k/ and /s/.
Ourtask is thus to select a subset of phonemes for eachlanguage?s graphemes.
We cast the subset selec-tion problem as a set of related binary predictionproblems, one for each possible grapheme-phonemepair.
Taken together, these predictions yield thegrapheme-phoneme mapping for that language.We develop a probabilistic undirected graphicalmodel for this prediction problem, where a large setof languages serve as training data and a single held-out language serves as test data.
Each training andtest language yields an instance of the graph, bound1For some brief background on phonetics, see Section 2.Note that we use the term ?phoneme?
throughout the paper,though we also refer to ?phonetic?
properties.
As we are deal-ing with texts (written in a roughly phonemic writing system),we have no access to the true contextual phonetic realizations,and even using IPA symbols to relate symbols across languagesis somewhat theoretically suspect.together through a shared set of features and param-eter values to allow cross-lingual learning and gen-eralization.In the graph corresponding to a given language,each node represents a grapheme-phoneme pair(g : p).
The node is labeled with a binary value toindicate whether grapheme g can represent phonemep in the language.
In order to allow coupled label-ings across the various grapheme-phoneme pairs ofthe language, we employ a connected graph struc-ture, with an automatically learned topology sharedacross the languages.
The node and edge featuresare derived from textual co-occurrence statistics forthe graphemes of each language, as well as generalinformation about the language?s family and region.Parameters are jointly optimized over the traininglanguages to maximize the likelihood of the node la-belings given the observed feature values.
See Fig-ure 1 for a snippet of the model.We apply our model to a novel data-set consistingof grapheme-phoneme mappings for 107 languageswith Roman alphabets and short texts.
In this set-ting, we consider each language in turn as the testlanguage, and train our model on the remaining 106languages.
Our highest performing model achievesan F1-measure of 88%, yielding perfect predictionsfor over 21% of languages.
These results comparequite favorably to several baselines.Our experiments lead to several conclusions.
(i)Character co-occurence features alone are not suf-ficient for cross-lingual predictive accuracy in thistask.
Instead, we map raw contextual counts to morelinguistically meaningful generalizations to learn ef-fective cross-lingual patterns.
(ii) A connected graphtopology is crucial for learning linguistically co-herent grapheme-to-phoneme mappings.
Withoutany edges, our model yields perfect mappings foronly 10% of test languages.
By employing struc-ture learning and including the induced edges, wemore than double the number of test languages withperfect predictions.
(iii) Finally, an analysis of ourgrapheme-phoneme predictions shows that they donot achieve certain global characteristics observedacross true phoneme inventories.
In particular, thelevel of ?feature economy?
in our predictions is toolow, suggesting an avenue for future research.333ph:/ph/th:/th/q:/!/q:/k/x:/>ks/c:/k/w:/w/c:/s/Figure 1: A snippet of our undirected graphical model.
The binary-valued nodes represent whether a particulargrapheme-phoneme pair is allowed by the language.
Sparse edges are automatically induced to allow joint trainingand prediction over related inventory decisions.2 Background and Related WorkIn this section, we provide some background on pho-netics and phoneme inventories.
We also reviewprior work on grapheme-to-phoneme prediction andmultilingual modeling.2.1 Phoneme InventoriesThe sounds of the world?s languages are producedthrough a wide variety of articulatory mechanisms.Consonants are sounds produced through a partialor complete stricture of the vocal tract, and can beroughly categorized along three independent dimen-sions: (i) Voicing: whether or not oscillation of thevocal folds accompanies the sound.
For example, /t/and /d/ differ only in that the latter is voiced.
(ii)Place of Articulation: where in the anatomy of thevocal tract the stricture is made.
For example, /p/ isa bilabial (the lips touching one another) while /k/is a velar (tongue touching touching the soft palate).
(iii) Manner of Articulation: the manner in whichthe airflow is regulated.
For example, /m/ is a nasal(air flowing through the nostrils), while /p/ is a plo-sive (obstructed air suddenly released through themouth).In contrast, vowels are voiced sounds producedwith an open vocal tract.
They are categorized pri-marily based on the position of the tongue and lips,along three dimensions: (i) Roundedness: whetheror not the lips are rounded during production ofthe sound; (ii) Height: the vertical position of thetongue; (iii) Backness: how far forward the tonguelies.Linguists have noted several statistical regulari-ties found in phoneme inventories throughout theworld.
Feature economy refers to the idea that lan-guages tend to minimize the number of differenti-ating characteristics (e.g.
different kinds of voic-ing, manner, and place) that are used to distinguishconsonant phonemes from one another (Clements,2003).
In other words, once an articulatory featureis used to mark off one phoneme from another, it willlikely be used again to differentiate other phonemepairs in the same language.
The principle of Maxi-mal perceptual contrast refers to the idea that the setof vowels employed by a language will be locatedin phonetic space to maximize their perceptual dis-tances from one another, thus relieving the percep-tual burden of the listener (Liljencrants and Lind-blom, 1972).
In an analysis of our results, we willobserve that our model?s predictions do not alwaysfollow these principles.Finally, researchers have noted that languagesexhibit set patterns in how they sequence theirphonemes (Kenstowicz and Kisseberth, 1979).
Cer-tain sequences are forbidden outright by languages,while others are avoided or favored.
While manyof these patterns are language-specific, others seemmore general, either reflecting anatomical con-334straints, common language ancestry, or universal as-pects of the human language system.
These phono-tactic regularities and constraints are mirrored ingraphemic patterns, and as our experiments show,can be explicitly modeled to achieve high accuracyin our task.2.2 Grapheme-to-Phoneme PredictionMuch prior work has gone into developing meth-ods for accurate grapheme-to-phoneme prediction.The common assumption underlying this researchhas been that some sort of knowledge, usually in theform of a pronunciation dictionary or phonemicallyannotated text, is available for the language at hand.The focus has been on developing techniques fordealing with the phonemic ambiguity present both inannotated and unseen words.
For example, Jiampo-jamarn and Kondrak (Jiampojamarn and Kondrak,2010) develop a method for aligning pairs of writ-ten and phonemically transcribed strings; Dwyerand Kondrak (Dwyer and Kondrak, 2009) developa method for accurate letter-to-phoneme conversionwhile minimizing the number of training examples;Reddy and Goldsmith (Reddy and Goldsmith, 2010)develop an MDL-based approach to finding sub-word units that align well to phonemes.A related line of work has grown around the taskof machine transliteration.
In this task, the goal is toautomatically transliterate a name in one languageinto the written form of another language.
Often thisinvolves some level of phonetic analysis in one orboth languages.
Notable recent work in this vein in-cludes research by Sproat et alproat et al2006)on transliteration between Chinese and English us-ing comparable corpora, and Ravi and Knight (Raviand Knight, 2009) who take a decipherment ap-proach to this problem.Our work differs from all previous work ongrapheme-to-phoneme prediction in that (i) we as-sume no knowledge for our target language beyonda small unannotated text (and possibly some regionor language family information), and (ii) our goalis to construct the inventory of mappings betweenthe language?s letters and its phonemes (the latterof which we do not know ahead of time).
When agrapheme maps to more than one phoneme, we donot attempt to disambiguate particular instances ofthat grapheme in words.A final thread of related work is the task of quan-titatively categorizing writing systems according totheir levels of phonography and logography (Sproat,2000; Penn and Choma, 2006).
As our data-setconsists entirely of Latin-based writing systems, ourwork can be viewed as a more fine-grained compu-tational exploration of the space of writing systems,with a focus on phonographic systems with the Latinpedigree.2.3 Multilingual AnalysisAn influential thread of previous multilingual workstarts with the observation that rich linguistic re-sources exist for some languages but not others.The idea then is to project linguistic informa-tion from one language onto others via paralleldata.
Yarowsky and his collaborators first devel-oped this idea and applied it to the problems ofpart-of-speech tagging, noun-phrase bracketing, andmorphology induction (Yarowsky and Wicentowski,2000; Yarowsky et al2000; Yarowsky and Ngai,2001), and other researchers have applied the ideato syntactic and semantic analysis (Hwa et al2005;Pad?
and Lapata, 2006) In these cases, the existenceof a bilingual parallel text along with highly accuratepredictions for one of the languages was assumed.Another line of work assumes the existence ofbilingual parallel texts without the use of any super-vision (Dagan et al1991; Resnik and Yarowsky,1997).
This idea has been developed and applied toa wide variety tasks, including morphological anal-ysis (Snyder and Barzilay, 2008a; Snyder and Barzi-lay, 2008b), part-of-speech induction (Snyder et al2008; Snyder et al2009a; Naseem et al2009), andgrammar induction (Snyder et al2009b; Blunsomet al2009; Burkett et al2010).
An even more re-cent line of work does away with the assumption ofparallel texts and performs joint unsupervised induc-tion for various languages through the use of cou-pled priors in the context of grammar induction (Co-hen and Smith, 2009; Berg-Kirkpatrick and Klein,2010).In contrast to these previous approaches, themethod we propose does not assume the existenceof any parallel text, but instead assumes that labeleddata exists for a wide variety of languages.
In this re-gard, our work most closely resembles recent workwhich trains a universal morphological analyzer us-335phonemes #lang enta /a/ /5/ /A/ /@/ /2/ 106 1.25c /c/ />dZ/ /k/ /s/ />ts/ />tS/ /|/ 62 2.33ch /k/ />tS/ /x/ /S/ 39 1.35e /e/ /i/ /?/ /@/ /E/ 106 1.82h /-/ /h/ /x/ /?/ /H/ 85 1.24i /i/ /j/ /I/ 106 0.92j />dZ/ /h/ /j/ />tS/ /x/ /?/ /Z/ 79 2.05o /o/ /u/ /6/ /0/ 103 1.47ph /f/ /ph/ 15 0.64q /k/ /q/ /!/ 32 1.04r /r/ /?/ /R/ /?/ /K/ 95 1.50th /th/ /T/ 15 0.64u /u/ /w/ /y/ /1/ /U/ /Y/ 104 0.96v /b/ /f/ /v/ /w/ /B/ 70 1.18w /u/ /v/ /w/ 74 0.89x />ks/ /x/ /{/ /S/ 44 1.31z />dz/ /s/ />ts/ /z/ /T/ 72 0.93Table 1: Ambiguous graphemes and the set of phonemesthat they may represent among our set of 107 languages.ing a structured nearest neighbor approach for 8 lan-guages (Kim et al2011).
Our work extends thisidea to a new task and also considers a much largerset of languages.
As our results will indicate, wefound that a nearest neighbor approach was not aseffective as our proposed model-based approach.3 Data and FeaturesIn this section we discuss the data and features usedin our experiments.3.1 DataThe data for our experiments comes from threesources: (i) grapheme-phoneme mappings from anonline encyclopedia, (ii) translations of the Univer-sal Declaration of Human Rights (UDHR)2, and (iii)entries from the World Atlas of Language Structures(WALS) (Haspelmath and Bibiko, 2005).To start, we downloaded and transcribed im-age files containing grapheme-phoneme mappingsfor several hundred languages from an online en-2http://www.ohchr.org/en/udhr/pages/introduction.aspxcyclopedia of writing systems3.
We then cross-referenced the languages with the World Atlasof Language Structures (WALS) database (Haspel-math and Bibiko, 2005) as well as the translationsavailable for the Universal Declaration of HumanRights (UDHR).
Our final set of 107 languages in-cludes those which appeared consistently in all threesources and that employ a Latin alphabet.
See Fig-ure 2 for a world map annotated with the locationslisted in the WALS database for these languages, aswell as their language families.
As seen from the fig-ure, these languages cover a wide array of languagefamilies and regions.We then analyzed the phoneme inventories for the107 languages.
We decided to focus our attentionon graphemes which are widely used across theselanguages with a diverse set of phonemic values.We measured the ambiguity of each grapheme bycalculating the entropy of its phoneme sets acrossthe languages, and found that 17 graphemes had en-tropy > 0.5 and appeared in at least 15 languages.Table 1 lists these graphemes, the set of phonemesthat they can represent, the number of languages inour data-set which employ them, and the entropyof their phoneme-sets across these languages.
Thedata, along with the feature vectors discussed below,are published as part of this paper.3.2 FeaturesThe key intuition underlying this work is thatgraphemic patterns in text can reveal the phonemeswhich they represent.
A crucial step in operational-izing this intuition lies in defining input features thathave cross-lingual predictive value.
We divide ourfeature set into three categories.Text Context Features: These features representthe textual environment of each grapheme in a lan-guage.
For each grapheme g, we consider counts ofgraphemes to the immediate left and right of g in theUDHR text.
We define five feature templates, in-cluding counts of (1) single graphemes to the left ofg, (2) single graphemes to the right of g, (3) pairs ofgraphemes to the left of g, (4) pairs of graphemes tothe right of g, and (5) pairs of graphemes surround-ing g. As our experiments below show, this set offeatures on its own performs poorly.
It seems that3http://www.omniglot.com/writing/langalph.htm#latin336Figure 2: Map and language families of languages in our data-setthese features are too language specific and not ab-stract enough to yield effective cross-lingual gener-alization.
Our next set of features was designed toalleviate this problem.Phonemic Context Features: A perfect feature-set would depend on the entire set of grapheme-to-phoneme predictions for a language.
In otherwords, we would ideally map all the graphemes inour text to phonemes, and then consider the plau-sibility of the resulting phoneme sequences.
Inpractice, of course, this is impossible, as the setof possible grapheme-to-phoneme mappings is ex-ponentially large.
As an imperfect proxy for thisidea, we made the following observation: for mostLatin graphemes, the most common phonemic valueacross languages is the identical IPA symbol of thatgrapheme (e.g.
the most common phoneme for g is/g/, the most common phoneme for t is /t/, etc).
Us-ing this observation, we again consider all contextsin which a grapheme appears, but this time map thesurrounding graphemes to their IPA phoneme equiv-alents.
We then consider various linguistic prop-erties of these surrounding ?phonemes?
?
whetherthey are vowels or consonants, whether they arevoiced or not, their manner and places of articulation?
and create phonetic context features.
The processis illustrated in Figure 3.
The intuition here is thatthese features can (noisily) capture the phonotacticcontext of a grapheme, allowing our model to learngeneral phonotactic constraints.
As our experimentsbelow demonstrate, these features proved to be quitepowerful.Language Family Features: Finally, we considerfeatures drawn from the WALS database whichcapture general information about the language ?specifically, its region (e.g.
Europe), its small lan-guage family (e.g.
Germanic), and its large languagefamily (e.g.
Indo-European).
These features al-low our model to capture family and region specificphonetic biases.
For example, African languagesare more likely to use c and q to represents clicksthan are European languages.
As we mention be-low, we also consider conjunctions of all features.Thus, a language family feature can combine witha phonetic context feature to represent a family spe-cific phonotactic constraint.
Interestingly, our exper-iments below show that these features are not neededfor highly accurate prediction.3.3 Feature Discretization and FilteringIt is well known that many learning techniques per-form best when continuous features are binned and337Raw Context FeaturesL1:k =15L1:b=3L1:g=7Noisy IPA ConversionL1:/k/ =15L1:/b/=3L1:/g/=7Phonetic Context FeaturesL1:velar=22L1:bilabial=3L1:voiced=10L1:unvoiced=15L1:consonant=25Figure 3: Generating phonetic context features.
First, character context features are extracted for each grapheme.The features drawn here give the counts of the character to the immediate left of the grapheme.
Next, the contextualcharacters are noisily converted to phones using their IPA notation.
Finally, phonetic context features are extracted.
Inthis case, phones /k/ and /g/ combine to give a ?velar?
count of 22, while /g/ and /b/ combine to give a ?voiced?
countof 10.converted to binary values (Dougherty et al1995).As a preprocessing step, we therefore discretize andfilter the count-based features outlined above.
Weadopt the technique of Recursive Minimal EntropyPartitioning (Fayyad and Irani, 1993).
This tech-nique recursively partitions feature values so as tominimize the conditional entropy of the labels.
Par-titioning stops when the gain in label entropy fallsbelow the number of additional bits in overheadneeded to describe the new feature split.
This leadsto a (local) minimum description length discretiza-tion.We noticed that most of our raw features (espe-cially the text features) could not achieve even a sin-gle split point without increasing description length,as they were not well correlated with the labels.
Wedecided to use this heuristic as a feature selectiontechnique, discarding such features.
After this dis-cretization and filtering, we took the resulting binaryfeatures and added their pairwise conjunctions to theset.
This process was conducted separately for eachleave-one-out scenario, without observation of thetest language labels.
Table 2 shows the total numberof features before the discretization/filtering as wellas the typical numbers of features obtained after fil-tering (the exact numbers depend on the training/testsplit).4 ModelUsing the features described above, we develop anundirected graphical model approach to our predic-Raw Filtered# Text Features 28,474 1,848# Phonemic Features 28,948 7,799# Family Features 66 32Total 57,488 9,679Table 2: Number of features in each category beforeand after discretization/filtering.
Note that the pair-wiseconjunction features are not included in these counts.tion task.
Corresponding to each training language isan instance of our undirected graph, labeled with itstrue grapheme-phoneme mapping.
We learn weightsover our features which optimally relate the inputfeatures of the training languages to their observedlabels.
At test-time, the learned weights are used topredict the labeling of the held-out test language.More formally, we assume a set of graph nodes1, ...,m with edges between some pairs of nodes(i, j).
Each node corresponds to a grapheme-phoneme pair (g : p) and can be labeled with a bi-nary value.
For each training language ?, we observea text x(?)
and a binary labeling of the graph nodesy(?).
For each node i, we also obtain a feature vectorfi(x(?
)), by examining the language?s text and ex-tracting textual and noisy phonetic patterns (as de-tailed in the previous section).
We obtain similarfeature vectors for edges (i, j): gjk(x(?)).
We thenparameterize the probability of each labeling usinga log-linear form over node and edge factors:44The delta function ?
(p) evaluates to 1 when predicate p is338logP(y(?)|x(?
))=?i?i ?[fi(x(?))
?(y(?
)i = 1)]+?j,k?jk1 ?[gjk(x(?))
?(y(?
)j = 1 ?
y(?
)k = 1)]+?j,k?jk2 ?[gjk(x(?))
?(y(?
)j = 1 ?
y(?
)k = 0)]+?j,k?jk3 ?[gjk(x(?))
?(y(?
)j = 0 ?
y(?
)k = 1)]?
logZ(x(?
), ?
)The first term sums over nodes i in the graph.
Foreach i, we extract a feature vector fi(x(?)).
If thelabel of node i is 1, we take the dot product of thefeature vector and corresponding parameters, other-wise the term is zeroed out.
Likewise for the graphedges j, k: we extract a feature vector, and depend-ing on the labels of the two vertices yj and yk, takea dot product with the relevant parameters.
The finalterm is a normalization constant to ensure that theprobabilities sum to one over all possible labelingsof the graph.Before learning our parameters, we first automat-ically induce the set of edges in our graph, usingthe PC graph structure learning algorithm (Spirteset al2000).
This procedure starts with a fully con-nected undirected graph structure, and iteratively re-moves edges between nodes that are conditionallyindependent given other neighboring nodes in thegraph according to a statistical independence testover all training languages.
In our graphs we have75 nodes, and thus 2,775 potential edges.
Run-ning the structure learning algorithm on our datayields sparse graphs, typically consisting of about50 edges.
In each leave-one-out scenario, a singlestructure is learned for all languages.Once the graph structure has been induced, welearn parameter values by maximizing the L2-penalized conditional log-likelihood over all train-ing languages:5L(?)
=??logP(y(?)|x(?))?
C||?||2true, and to 0 when p is false.5In our experiments, we used an L2 penalty weight of .5for node features and .1 for edge features.
Similar results areobserved for a wide range of values.The gradient takes the standard form of a differencebetween expected and observed feature counts (Laf-ferty et al2001).
Expected counts, as well aspredicted assignments at test-time, are computedusing loopy belief propagation (Murphy et al1999).
Numerical optimization is performed usingL-BFGS (Liu and Nocedal, 1989).5 ExperimentsIn this section, we describe the set of experimentsperformed to evaluate the performance of our model.Besides our primary undirected graphical model, wealso consider several baselines and variants, in or-der to assess the contribution of our model?s graphstructure as well as the features used.
In all cases,we perform leave-one-out cross-validation over the107 languages in our data-set.5.1 BaselinesOur baselines include:1.
A majority baseline, where the most commonbinary value is chosen for each grapheme-phoneme pair,2.
two linear SVM?s, one trained using the dis-cretized and filtered features described in Sec-tion 3.2, and the other using the raw continuousfeatures,3.
a Nearest Neighbor classifier, which choosesthe closest training language for eachgrapheme-phoneme pair in the discretizedfeature space, and predicts its label, and4.
a variant of our model with no edges betweennodes (essentially reducing to a set of indepen-dent log-linear classifiers).5.2 EvaluationWe report our results using three evaluation metricsof increasing coarseness.1.
Phoneme-level: For individual grapheme-phoneme pairs (e.g.
a:/5/, a:/2/, c:/k/, c:/tS/)our task consists of a set of binary predic-tions, and can thus be evaluated in terms ofprecision, recall, and F1-measure.
We reportmicro-averages of these quantities across all339Phoneme Grapheme LanguagePrecision Recall F1 Accuracy AccuracyMAJORITY 80.47 57.47 67.06 55.54 2.8SVM CONTINUOUS 79.87 64.48 79.87 59.07 3.74SVM DISCRETE 90.55 78.27 83.97 70.78 8.41NEAREST NEIGHBOR 85.35 79.43 82.28 67.97 2.8MODEL: NO EDGES 89.35 82.05 85.54 73.96 10.28FULL MODEL 91.06 83.98 87.37 78.58 21.5MODEL: NO FAMILY 92.43 84.67 88.38 80.04 19.63MODEL: NO TEXT 89.58 81.43 85.31 75.86 15.89MODEL: NO PHONETIC 86.52 74.19 79.88 69.6 9.35Table 3: The performance of baselines and variants of our model, evaluated at the phoneme-level (binary predictions),whole-grapheme accuracy, and whole-language accuracy.grapheme-phoneme pairs in all leave-one-outtest languages.2.
Grapheme-level: We also report grapheme-level accuracy.
For this metric, we con-sider each grapheme g and examine its pre-dicted labels over all its possible phonemes:(g : p1), (g : p2), ..., (g : pk).
If all k binarypredictions are correct, then the grapheme?sphoneme-set has been correctly predicted.
Wereport the percentage of all graphemes withsuch correct predictions (micro-averaged overall graphemes in all test language scenarios).3.
Language-level: Finally, we assess language-wide performance.
For this metric, we re-port the percentage of test languages for whichour model achieves perfect predictions on allgrapheme-phoneme pairs, yielding a perfectmapping.5.3 ResultsThe results for the baselines and our model areshown in Table 3.
The majority baseline yields 67%F1-measure on the phoneme-level binary predictiontask, with 56% grapheme accuracy, and about 3%language accuracy.Using undiscretized raw count features, the SVMimproves phoneme-level performance to about 80%F1, but fails to provide any improvement ongrapheme or language performance.
In contrast, theSVM using discretized and filtered features achievesperformance gains in all three categories, achieving71% grapheme accuracy and 8% language accuracy.The nearest neighbor baseline achieves performancesomewhere in between the two SVM variants.The unconnected version of our model achievessimilar, though slightly improved performance overthe discretized SVM.
Adding the automatically in-duced edges into our model leads to significantgains across all three categories.
Phoneme-levelF1 reaches 87%, grapheme accuracy hits 79%, andlanguage accuracy more than doubles, achieving22%.
It is perhaps not surprising that the biggestrelative gains are seen at the language level: byjointly learning and predicting an entire language?sgrapheme-phoneme inventory, our model ensuresthat language-level coherence is maintained.Recall that three sets of features are used by ourmodels.
(1) language family and region features,(2) textual context features, and (3) phonetic contextfeatures.
We now assess the relative merits of eachset by considering our model?s performance whenthe set has been removed.
Table 3 shows severalstriking results from this experiment.
First, it ap-pears that dropping the region and language familyfeatures actually improves performance.
This resultis somewhat surprising, as we expected these fea-tures to be quite informative.
However, it appearsthat whatever information they convey is redundantwhen considering the text-based feature sets.
Wenext observe that dropping the textual context fea-tures leads to a small drop in performance.
Finally,we see that dropping the phonetic context featuresseriously degrades our model?s accuracy.
Achievingrobust cross-linguistic generalization apparently re-quires a level of feature abstraction not achieved by340character-level context features alone.6 Global Inventory AnalysisIn the previous section we saw that our modelachieves relatively high performance in predictinggrapheme-phoneme relationships for never-before-seen languages.
In this section we analyze the pre-dicted phoneme inventories and ask whether theydisplay the statistical properties observed in thegold-standard mappings.As outlined in Section 2, consonant phonemes canbe represented by the three articulatory features ofvoicing, manner, and place.
The principle of fea-ture economy states that phoneme inventories willbe organized to minimize the number of distinct ar-ticulatory features used in the language, while max-imizing the number of resulting phonemes.
Thisprinciple has several implications.
First, we canmeasure the economy index of a consonant systemby computing the ratio of the number of conso-nantal phonemes to the number of articulatory fea-tures used in their production: #consonants#features (Clements,2003).
The higher this value, the more economicalthe sound system.Secondly, for each articulatory dimension we cancalculate the empirical distribution over values ob-served across the consonants of the language.
Sinceconsonants are produced as combinations of thethree articulatory dimensions, the greatest numberof consonants (for a given set of utilized featurevalues) will be produced when the distributions areclose to uniform.
Thus, we can measure how eco-nomical each feature dimension is by computing theentropy of its distribution over consonants.
For ex-ample, in an economical system, we would expectroughly half the consonants to be voiced, and half tobe unvoiced.Table 4 shows the results of this analysis.
First,we notice that the average entropy of voiced vs. un-voiced consonants is nearly identical in both cases,close to the optimal value.
However, when we ex-amine the dimensions of place and manner, we no-tice that the entropy induced by our model is not ashigh as that of the true consonant inventories, imply-ing a suboptimal allocation of consonants.
In fact,when we examine the economy index (ratio of con-sonants to features), we indeed find that ?
on aver-H(voice)H(place)H(manner)EconomyIndexTrue 0.9739 2.7355 2.4725 1.6536Predicted 0.9733 2.6715 2.4163 1.6337Table 4: Measures of feature economy applied to the pre-dicted and true consonant inventories (averaged over all107 languages).age ?
our model?s predictions are not as economi-cal as the gold standard.
This analysis suggests thatwe might obtain a more powerful predictive modelby taking the principle of feature economy into ac-count.7 ConclusionsIn this paper, we considered a novel problem: thatof automatically relating written symbols to spo-ken sounds for an unknown language using a knownwriting system ?
the Latin alphabet.
We constructeda data-set consisting of grapheme-phoneme map-pings and a short text for over 100 languages.
Thisdata allows us to cast our problem in the supervisedlearning framework, where each observed languageserves as a training example, and predictions aremade on a new language.
Our model automaticallylearns how to relate textual patterns of the unknownlanguage to plausible phonemic interpretations us-ing induced phonotactic regularities.AcknowledgmentsThis work is supported by the NSF under grant IIS-1116676.
Any opinions, findings, or conclusions arethose of the authors, and do not necessarily reflectthe views of the NSF.ReferencesTaylor Berg-Kirkpatrick and Dan Klein.
2010.
Phyloge-netic grammar induction.
In Proceedings of the ACL,pages 1288?1297, Uppsala, Sweden, July.
Associationfor Computational Linguistics.P.
Blunsom, T. Cohn, C. Dyer, and M. Osborne.
2009.A gibbs sampler for phrasal synchronous grammar in-duction.
In Proceedings of the Joint Conference of the34147th Annual Meeting of the ACL and the 4th Interna-tional Joint Conference on Natural Language Process-ing of the AFNLP: Volume 2-Volume 2, pages 782?790.
Association for Computational Linguistics.David Burkett, Slav Petrov, John Blitzer, and Dan Klein.2010.
Learning better monolingual models with unan-notated bilingual text.
In Proceedings of CoNLL.G.N.
Clements.
2003.
Feature economy in sound sys-tems.
Phonology, 20(3):287?333.Shay B. Cohen and Noah A. Smith.
2009.
Shared lo-gistic normal distributions for soft parameter tying inunsupervised grammar induction.
In Proceedings ofthe NAACL/HLT.Ido Dagan, Alon Itai, and Ulrike Schwall.
1991.
Twolanguages are more informative than one.
In Proceed-ings of the ACL, pages 130?137.P.T.
Daniels and W. Bright.
1996.
The world?s writingsystems, volume 198.
Oxford University Press NewYork, NY.James Dougherty, Ron Kohavi, and Mehran Sahami.1995.
Supervised and unsupervised discretization ofcontinuous features.
In ICML, pages 194?202.K.
Dwyer and G. Kondrak.
2009.
Reducing the anno-tation effort for letter-to-phoneme conversion.
In Pro-ceedings of the Joint Conference of the 47th AnnualMeeting of the ACL and the 4th International JointConference on Natural Language Processing of theAFNLP: Volume 1-Volume 1, pages 127?135.
Associ-ation for Computational Linguistics.Usama M Fayyad and Keki B Irani.
1993.
Multi-intervaldiscretization of continuous-valued attributes for clas-sification learning.
In Proceedings of the InternationalJoint Conference on Uncertainty in AI, pages 1022?1027.M.
Haspelmath and H.J.
Bibiko.
2005.
The world atlasof language structures, volume 1.
Oxford UniversityPress, USA.R.
Hwa, P. Resnik, A. Weinberg, C. Cabezas, and O. Ko-lak.
2005.
Bootstrapping parsers via syntactic projec-tion across parallel texts.
Journal of Natural LanguageEngineering, 11(3):311?325.S.
Jiampojamarn and G. Kondrak.
2010.
Letter-phonemealignment: An exploration.
In Proceedings of the 48thAnnual Meeting of the Association for ComputationalLinguistics, pages 780?788.
Association for Computa-tional Linguistics.M.J.
Kenstowicz and C.W.
Kisseberth.
1979.
Generativephonology.
Academic Press San Diego, CA.Young-Bum Kim, Jo?o Gra?a, and Benjamin Snyder.2011.
Universal morphological analysis using struc-tured nearest neighbor prediction.
In Proceedings ofthe 2011 Conference on Empirical Methods in Natu-ral Language Processing, pages 322?332, Edinburgh,Scotland, UK., July.
Association for ComputationalLinguistics.John D. Lafferty, AndrewMcCallum, and Fernando C. N.Pereira.
2001.
Conditional random fields: Probabilis-tic models for segmenting and labeling sequence data.In Proceedings of the Eighteenth International Con-ference on Machine Learning, pages 282?289.J.
Liljencrants and B. Lindblom.
1972.
Numerical simu-lation of vowel quality systems: the role of perceptualcontrast.
Language, pages 839?862.D.C.
Liu and J. Nocedal.
1989.
On the limited memorybfgs method for large scale optimization.
Mathemati-cal programming, 45(1):503?528.K.P.
Murphy, Y. Weiss, and M.I.
Jordan.
1999.
Loopybelief propagation for approximate inference: An em-pirical study.
In Proceedings of the Fifteenth confer-ence on Uncertainty in artificial intelligence, pages467?475.
Morgan Kaufmann Publishers Inc.Tahira Naseem, Benjamin Snyder, Jacob Eisenstein, andRegina Barzilay.
2009.
Multilingual part-of-speechtagging: two unsupervised approaches.
Journal of Ar-tificial Intelligence Research, 36(1):341?385.Sebastian Pad?
and Mirella Lapata.
2006.
Optimal con-stituent alignment with edge covers for semantic pro-jection.
In Proceedings of ACL, pages 1161 ?
1168.G.
Penn and T. Choma.
2006.
Quantitative methods forclassifying writing systems.
In Proceedings of the Hu-man Language Technology Conference of the NAACL,Companion Volume: Short Papers, pages 117?120.Association for Computational Linguistics.S.
Ravi and K. Knight.
2009.
Learning phoneme map-pings for transliteration without parallel data.
In Pro-ceedings of Human Language Technologies: The 2009Annual Conference of the North American Chapter ofthe Association for Computational Linguistics, pages37?45.
Association for Computational Linguistics.S.
Reddy and J. Goldsmith.
2010.
An mdl-based ap-proach to extracting subword units for grapheme-to-phoneme conversion.
In Human Language Technolo-gies: The 2010 Annual Conference of the North Amer-ican Chapter of the Association for ComputationalLinguistics, pages 713?716.
Association for Compu-tational Linguistics.Philip Resnik and David Yarowsky.
1997.
A perspectiveon word sense disambiguation methods and their eval-uation.
In Proceedings of the ACL SIGLEX Workshopon Tagging Text with Lexical Semantics: Why, What,and How?, pages 79?86.B.
Snyder and R. Barzilay.
2008a.
Unsupervised multi-lingual learning for morphological segmentation.
Pro-ceedings of ACL-08: HLT, pages 737?745.Benjamin Snyder and Regina Barzilay.
2008b.
Cross-lingual propagation for morphological analysis.
InProceedings of the AAAI, pages 848?854.342Benjamin Snyder, Tahira Naseem, Jacob Eisenstein, andRegina Barzilay.
2008.
Unsupervised multilinguallearning for POS tagging.
In Proceedings of EMNLP,pages 1041?1050.B.
Snyder, T. Naseem, J. Eisenstein, and R. Barzilay.2009a.
Adding more languages improves unsuper-vised multilingual part-of-speech tagging: A bayesiannon-parametric approach.
In Proceedings of HumanLanguage Technologies: The 2009 Annual Conferenceof the North American Chapter of the Association forComputational Linguistics, pages 83?91.
Associationfor Computational Linguistics.Benjamin Snyder, Tahira Naseem, and Regina Barzilay.2009b.
Unsupervised multilingual grammar induc-tion.
In Proceedings of the ACL, pages 73?81.P.
Spirtes, C.N.
Glymour, and R. Scheines.
2000.
Cau-sation, prediction, and search, volume 81.
The MITPress.R.
Sproat, T. Tao, and C.X.
Zhai.
2006.
Named entitytransliteration with comparable corpora.
In Proceed-ings of the 21st International Conference on Compu-tational Linguistics and the 44th annual meeting of theAssociation for Computational Linguistics, pages 73?80.
Association for Computational Linguistics.R.W.
Sproat.
2000.
A computational theory of writingsystems.
Cambridge Univ Pr.David Yarowsky and Grace Ngai.
2001.
Inducing mul-tilingual pos taggers and np bracketers via robust pro-jection across aligned corpora.
In Proceedings of theNAACL, pages 1?8.David Yarowsky and Richard Wicentowski.
2000.
Min-imally supervised morphological analysis by multi-modal alignment.
In ACL ?00: Proceedings of the38th Annual Meeting on Association for Computa-tional Linguistics, pages 207?216, Morristown, NJ,USA.
Association for Computational Linguistics.David Yarowsky, Grace Ngai, and Richard Wicentowski.2000.
Inducing multilingual text analysis tools via ro-bust projection across aligned corpora.
In Proceedingsof HLT, pages 161?168.343
