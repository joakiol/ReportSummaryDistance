Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 1?9,Baltimore, Maryland USA, June 27 2014.c?2014 Association for Computational LinguisticsRevisiting Word Neighborhoods for Speech RecognitionPreethi Jyothi?Beckman InstituteUniversity of Illinois, Urbana, ILpjyothi@illinois.eduKaren LivescuToyota Technological Institute at ChicagoChicago, ILklivescu@ttic.eduAbstractWord neighborhoods have been suggestedbut not thoroughly explored as an ex-planatory variable for errors in automaticspeech recognition (ASR).
We revisit thedefinition of word neighborhoods, proposenew measures using a fine-grained artic-ulatory representation of word pronuncia-tions, and consider new neighbor weight-ing functions.
We analyze the signifi-cance of our measures as predictors of er-rors in an isolated-word ASR system anda continuous-word ASR system.
We findthat our measures are significantly betterpredictors of ASR errors than previouslyused neighborhood density measures.1 IntroductionAn important pursuit for both human and ma-chine speech recognition research is to under-stand the factors that affect word recognition ac-curacy.
In the substantial body of work on hu-man word recognition, it has been shown thatit is harder to recognize words that have many?similar?
neighboring words than words with fewneighbors (Luce and Pisoni, 1998), and that fre-quent words are recognized faster and more accu-rately than are infrequent words (Marslen-Wilson,1987; Luce and Pisoni, 1998; Vitevitch and Luce,1999).
In the ASR research community, priorwork has also investigated various factors thatbenefit or disrupt recognition.
Examples of suchfactors include word frequency, speaking rate,and prosodic factors (Fosler-Lussier and Morgan,1999; Shinozaki and Furui, 2001; Hirschberg etal., 2004; Goldwater et al., 2010).
There has alsobeen prior work that uses word confusability mea-sures to predict speech recognition errors (Fosler-Lussier et al., 2005; Jyothi and Fosler-Lussier,2009).
?Supported by a Beckman Postdoctoral Fellowship.Word neighborhood measures have been stud-ied more heavily for human word recognition thanas predictors of ASR errors.
Although not stud-ied specifically in prior work (Fosler-Lussier et al.,2005; Jyothi and Fosler-Lussier, 2009), word con-fusability measures used in predicting ASR errorscould be utilized to build word neighborhoods.Goldwater et al.
(2010) examine the behavior ofcertain standard neighborhood density measuresas predictors of ASR errors.
To our knowledge,this is the only study that explicitly considers wordneighborhoods as a potential factor in ASR.In this work, we investigate word neighborhoodmeasures as predictors of ASR errors.
We pro-pose new neighborhood measures that we find tobe more well-suited to ASR than standard neigh-borhood density measures.
We also propose anew mechanism to incorporate frequency weight-ing within the measures.
Finally, we analyze themeasures as predictors of errors in an isolated-word recognition system and a continuous-wordrecognition system for conversational speech.2 Related Work: Neighborhood DensityMeasuresIn much of the prior work in the psycholinguisticsliterature, the notion of word similarity is quanti-fied by a simple one-phone-away rule: A word w?is a neighbor of wordw ifw andw?differ by a sin-gle phone, via a substitution, deletion, or insertion.We refer to this density measure as ?ND?.ND =?w??ND(w,w?
)where ?ND(w,w?)
= 1 if w and w?differ by aphone and 0 otherwise.The frequencies of the neighbors are often ac-counted for in the neighborhood density measureby computing the sum of the raw (or log) frequen-cies of a word?s neighbors (Luce and Pisoni, 1998;Vitevitch and Luce, 1999); the word frequencies1are derived from a large corpus.
We refer to thisfrequency-weighted measure as ?wND?.wND =?w??ND(w,w?)
?
pi(w?
)where pi(w?)
is the frequency of the word w?.1Both ND and wND are popular measures for wordneighborhoods that we consider to be our base-lines; Goldwater et al.
(2010) also make use ofthese two density measures.2Neither of these measures account for the fre-quency of the word itself.
In continuous ASR,which uses a language model, frequent words aremore likely to be recognized correctly (Fosler-Lussier and Morgan, 1999).
To account for this,instead of using absolute frequencies of the neigh-boring words, we use their relative frequencies todefine a third baseline density measure,?rwND?
(relative-wND):rwND =?w??ND(w,w?)
?pi(w?
)pi(w)Relative frequencies have appeared in priorwork (Luce, 1986; Luce and Pisoni, 1998; Scar-borough, 2012).
In fact, the measure used by Scar-borough (2012) is the reciprocal of rwND.3 Proposed Neighborhood MeasuresOur new neighborhood measures are defined interms of a distance function between a pair ofwords, ?, and a weighting function, ?.
The pro-posed measures are not densities in the same senseas ND, wND, rwND, but are scores that we mayexpect to correlate with recognition errors.
We de-fine the neighborhood score for a word w as:score(w) =?w?6=w?(w,w?)
??(w,w?)
(1)Intuitively, ?
is an averaging function that weighsthe importance of each neighboring word.
For ex-ample, Yarkoni et al.
(2008) use a neighborhoodmeasure that gives equal importance to the top1Here we use raw rather than log frequencies.
The base-line density measures in this section perform better with rawrather than log frequencies on our evaluation data.
Our pro-posed measures perform significantly better than the baselinemeasures using both raw and log frequencies.2Goldwater et al.
(2010) also consider the number of ho-mophones (words that share a pronunciation with the tar-get word) and frequency-weighted homophones as additionalneighborhood measures.
In our data there is insufficient ho-mophony for these measures to be significant, so we do notreport on experiments using them.20 closest neighbors and rejects the others.
Therest of the section presents multiple choices for ?and ?
which will define our various neighborhoodmeasures via Equation 1.3.1 Distance FunctionsAll of our distance functions are based on an editdistance between a pair of words, i.e., the mini-mum cost incurred in converting one word to theother using substitutions, insertions and deletionsof the sub-word units in the word.
In additionto binary edit costs, we consider edit costs thatdepend on sub-phonetic properties of the phonesrather than a uniform cost across all phones.
Sec-ond, instead of a single pronunciation for a word,we consider a distribution over multiple pronun-ciations.
These distance functions can be easilycomputed via finite-state transducer (FST) opera-tions, as explained below (see also Figure 1).Edit Distance (?ED): This is the simplest editdistance function that incurs an equal cost of 1 forany substitution, insertion, or deletion.
To com-pute the distance between a pair of words, eachword w is represented as a finite state acceptor,Fw, that accepts the pronunciations (phone se-quences) of the word.
We also introduce a memo-ryless transducer, T , that maps an input phone toany output phone, with arc weights equal to thecorresponding substitution costs (mapping to orfrom epsilon indicates a deletion or an insertion).The weight of the shortest path in the composedFST, Fw?T ?Fw?, gives the edit distance betweenw and w?.
When either w or w?has more thanone pronunciation, ?EDis the minimum edit dis-tance among all pairs of pronunciations.
This editdistance function has been previously proposedas a measure of phonological similarity betweenwords (Hahn and Bailey, 2005).
Similar distancefunctions have also been used for neighborhooddensity measures in visual word recognition stud-ies (Yarkoni et al., 2008).Simple Articulatory Feature-based Edit Dis-tance (?AF): The distance function ?EDpe-nalizes an incorrect substitution equally regardlessof the phone identity; for example, the phone [p]can be substituted with [b] or [aa] with equal costaccording to ?ED, although we know it is morelikely for [p] to be produced as [b] than as [aa].
Toaccount for this, we adopt a finer-grained repre-sentation of the phone as a vector of discrete artic-ulatory ?features?.
Our features are derived from2?AF:0 1 2 3?0?0 1 2 3k ah m k aapk:/3.364m:p/3.464k:k/0?
?
?
?AFx:0 1234 5?0?0 1234 5kggclkclahaxemkclmahah nax nkggclkclaaaopclppclah nahax nk:/3.364m:p/3.464k:k/0?
?
?Figure 1: Distance functions implemented using finite-state machines.the vocal tract variables of articulatory phonol-ogy (Browman and Goldstein, 1992), includingthe constriction degrees and locations of the lips,tongue tip, tongue body, velum and glottis.We bor-row a particular feature set from (Livescu, 2005).3The substitution cost between two phones is de-fined as the L1 distance between the articulatoryvectors corresponding to the phones.
We set theinsertion and deletion costs to the mean substitu-tion cost between the articulatory vectors for allphone pairs.
These new costs will appear as the arcweights on the edit transducer T .
This is shownin Figure 1; apart from the difference in the arcweights on T , ?AFis the same as ?ED.Extended Articulatory Feature-based Edit Dis-tance (?AFx): The words in our dictionary areassociated with one or more canonical pronuncia-tions written as sequences of phones.
The distancefunctions ?EDand ?AFmake use of this small setof canonical pronunciations and do not capture thevarious other ways in which a word can be pro-nounced.
An alternative, explored in some priorwork on pronunciation modeling (Deng and Sun,1994; Richardson et al., 2003; Livescu and Glass,2004; Mitra et al., 2011; Jyothi et al., 2011), isto model the pronunciation of a word as multiple,possibly asynchronous streams of fine-grained ar-ticulatory features, again inspired by articulatoryphonology.
Such a model can be implemented asa dynamic Bayesian network (DBN) with multi-ple variables representing the articulatory features3The mapping of phones to their articulatory feature val-ues is defined in Appendix B of Livescu (2005).
This map-ping includes a probability distribution over feature valuesfor certain phones; in these cases, we choose the articulatoryfeature value with the highest probability.in each time frame; please refer to (Livescu andGlass, 2004; Livescu, 2005; Jyothi et al., 2011)for more details.
In this approach, deviations froma dictionary pronunciation are the result of eitherasynchrony between the articulatory streams (ac-counting for effects such as nasalization, round-ing, and epenthetic stops) or the substitution of onearticulatory feature value for another (accountingfor many reduction phenomena).Jyothi et al.
(2012) describe an approach toencode such a DBN model of pronunciation asan FST that outputs an articulatory feature tu-ple for each frame of speech.
We modify thisFST by mapping each articulatory feature tupleto a valid phone as per the phone-to-articulatory-feature mapping used for ?AF(discarding arcswhose labels do not correspond to a valid phone).The resulting FSTs are used to define ?AFxbycomposing with the edit transducer T as in thedefinition of ?AF.
For computational efficiency,we prune these FSTs to retain only paths that arewithin three times the weight of the shortest path.The pruned FSTs have hundreds of arcs and ?50states on average.
A schematic diagram is used toillustrate the computation of ?AFxin Figure 1.3.2 Weighting FunctionsOur weighting functions can be appropriately de-fined to discount the contributions of words thatare infrequent or are very far away.
We note herethat unlike the density measures in Section 2, thelower the distance-based score for a word (fromEquation 1), the more confusable it would be withits neighbors.
One approach, as pursued in Nosof-sky (1986) and Bailey and Hahn (2001), is to usescore(w) =?w?g(?(w,w?))
where g is an expo-3r1r200.20.40.60.81?
(r)Figure 2: Let w1and w2be the two closestwords to w. The area of the shaded region shows?
(w,w2) where ri= Rw(wi) = i.
In theweighted case given in Equation 4, r1= R?w(w1),r2= R?w(w2) and r2?
r1= ?w(w2).nentially decreasing function.
This, however, hasthe disadvantage of being very sensitive to the dis-tance measure used: Slight changes in the distancecan alter the score significantly, even if the overallordering of the distances is preserved.
We proposean alternative approach that keeps the score as alinear function of the distances as long as the or-dering is fixed.
For this, we introduce ?(w,w?)
inEquation 1 and let it be a (possibly exponentially)decreasing function of the rank of w?.Formally, we define the rank of w?with re-spect to w, Rw(w?
), as follows: Fix an orderingof all N ?
1 words in the vocabulary other thanw as (w1, w2, .
.
.
, wN?1) such that ?
(w,wi) ??
(w,wi+1) for all i ?
{1, .
.
.
, N ?
2}.
ThenRw(w?)
= j if w?= wjin the above ordering.We then define ?
in terms of a ?decay?
function ?:?(w,w?)
=?Rw(w?)Rw(w?)?1?
(r)dr (2)If ?
is monotonically decreasing, Equation 2 en-sures that neighbors with a higher rank (i.e., fur-ther away) contribute less weight than neighborswith a lower rank.
For example, a measurethat gives equal weight to the k closest neigh-bors (Yarkoni et al., 2008) corresponds to?
(r) ={1 if r ?
k0 otherwiseInstead of a step function that gives equal weightto all k neighbors, we define ?
as an exponen-tially decreasing function of rank: ?
(r) = e?r.Then, from Equation 2, we obtain ?(w,w?)
=(e?1)e?Rw(w?).
Figure 2 shows the exponentiallydecreasing ?
(r) and a sample ?(w,w?
).We know from prior work that it is also impor-tant to distinguish among the neighbors dependingon how frequently they appear in the language.
Toaccount for this, we define a frequency-weightedrank function, R?w(w?):R?w(w?)
=Rw(w?
)?i=1?w(wi) (3)where ?wis a suitably defined frequency function(see below).
We now redefine ?
as:?(w,w?)
=?R?w(w?)R?w(w?)??w(w?)?
(r)dr (4)Note that when ?w(w?)
= 1 for all w?, Equation 4reduces to Equation 2.
?(w,w?)
is robust in thatit is invariant to the ordering used to define rank,R?w, i.e.
words with the same distance from w canbe arbitrarily ordered.
Also, multiple words at thesame distance contribute to ?
equally to a singleword at the same distance with a frequency that isthe sum of their frequencies.We use three choices for ?w(w?):1.
The first choice is simply ?w(w?)
= 1 for allw?.2.
Let pi(w?)
be the unigram probability of w?.
Wethen define ?w(w?)
= P ?
pi(w?)
where P isa scaling parameter.
One natural choice forP is the perplexity of the unigram probabilitydistribution, pi, i.e., 2?
?wpi(w) log(pi(w)).
Withthis choice of P , when pi is a uniform distribu-tion over all words in the vocabulary, we have?w(w?)
= 1 for all w?, and R?w(w?)
= Rw(w?).3.
As defined above, ?w(w?)
does not depend onw.
Our third choice for the frequency func-tion considers the frequency of w?relative tow: ?w(w?)
=pi(w?
)/pi(w)To summarize, Equation 1 gives the neighbor-hood score for w in terms of ?
and ?.
We usethree choices for ?
as specified in Section 3.
?is defined by Equation 4 where R?wis definedby Equation 3 in terms of the frequency function?w.
We use the three choices described above for?w.
The resulting nine score functions are sum-marized in Table 1.
For completeness, we alsoinclude the neighborhood density baseline mea-sures and represent them using our notation witha distance function defined as ?ND(w,w?)
=4Measure ?
(r) ?(w,w?)
?w(w?
)ND1 ?ND1wND pi(w?)rwNDpi(w?
)pi(w)EDe?r?ED1wED pi(w?)
?
PrwEDpi(w?
)pi(w)AF?AF1wAF pi(w?)
?
PrwAFpi(w?
)pi(w)AFx?AFx1wAFx pi(w?)
?
PrwAFxpi(w?
)pi(w)Table 1: Summary of neighborhood measures.1(?ED(w,w?)
= 1) (i.e.
?ND(w,w?)
= 1 if?ED(w,w?)
= 1 and 0 otherwise) and ?
= 1.With ?
= 1 and ?(w,w?)
= ?w(w?
), the threechoices of ?wgive us ND, wND and rwND, asshown in Table 1.
The notation ?ND(w,w?)
isto highlight the inverse relationship of the densitymeasures with our distance-based measures.4 ExperimentsWe provide an individual analysis of each neigh-borhood measure as it relates to recognition errorrate.
We also present a matrix of pairwise com-parisons among all of the neighborhood measureswith respect to their ability to predict recognitionerrors.
We study the relationship between neigh-borhood measures and ASR errors in two settings:?
Isolated-word ASR: Psycholinguistic stud-ies typically use isolated words as stimuli to studythe influence of neighborhood measures on recog-nition (e.g., see Goldwater et al.
(2010) and ref-erences therein).
Motivated by this, we build anASR system that recognizes words in isolationand analyze the relationship between its errors andeach neighborhood measure.
Further details ofthis analysis are described in Section 4.1.?
Continuous-word ASR: ASR systems typ-ically deal with continuous speech.
However,the usefulness of neighborhood measures forcontinuous-word ASR has received little atten-tion, with the notable exception of Goldwater etal.
(2010).
We further this line of investigation inour second set of experiments by analyzing the re-lationship between errors made by a continuous-word ASR system and our new measures.
Theseare described in more detail in Section 4.2.4.1 Isolated-Word ASRExperimental Setup: We extract isolated wordsfrom a subset of the Switchboard-I conversationalspeech corpus (Godfrey et al., 1992) called theSwitchboard Transcription Project, STP (Green-berg et al., 1996; STP, 1996), which is phonet-ically labeled at a fine-grained level.
Isolatedwords were excised from continuous utterances insets 20?22 in the STP corpus.
We use a total of401 word tokens (247 unique words) derived fromthe 3500 most frequent words in Switchboard-I,excluding non-speech events and partial words.These words make up the development and eval-uation sets used in prior related work on pronun-ciation modeling (Livescu and Glass, 2004; Jyothiet al., 2011; Jyothi et al., 2012).
We use the dictio-nary that accompanies the Switchboard-I corpusconsisting of 30,241 words; ?98% of these wordsare associated with a single pronunciation.The recognition system for this isolated worddataset was built using the Kaldi toolkit (Poveyet al., 2011; Kal, 2011).
We use an acous-tic model that is trained on all of Switchboard-I, excluding the sentences from which our 401-word set was drawn.
The ASR system uses stan-dard mel frequency cepstral coefficients with theirfirst and second derivatives (deltas and double-deltas) as acoustic features, with standard normal-ization and adaptation techniques including cep-stral mean and variance normalization and maxi-mum likelihood linear regression.
Linear discrim-inant analysis (LDA) and maximum likelihood lin-ear transform (MLLT) feature-space transforma-tions were applied to reduce the feature-space di-mensionality (Povey et al., 2011).
The acous-tic models are standard Gaussian mixture model-Hidden Markov models (GMM-HMMs) for tied-state triphones.
The recognition vocabulary in-cludes 3328 words, consisting of the 3500 mostfrequent words from Switchboard excluding par-tial and non-speech words.4Since this is anisolated-word task, the ASR system does not useany language model.Results and Discussion: In order to individu-ally analyze each of the neighborhood measures,4Large-vocabulary automatic recognition of isolatedwords is a hard task due to the absence of constraints froma language model.
Using the entire Switchboard vocabularywould greatly deteriorate the recognition performance on analready hard task.
Thus, we restrict the vocabulary to 1/10thof the original size in order to obtain reasonable performancefrom the isolated ASR system.50 10 20 30 40 50 600.00.20.40.60.81.0NDER0.000 0.010 0.0200.00.20.40.60.81.0wNDER5 10 150.00.20.40.60.81.0wAFxER(a) Neighborhood measures ND, wND and wAFx as predictors of isolated-word error rate (ER).ND ED AF AFx wND wED wAF wAFxND - - - - - - - -ED - - - - - - - -AF - - - - - - - -AFx - - - - - - - -wND - - - - - - - -wED - - - - - - - -wAF - - - - - - - -wAFx - - - - - - - -null 5?68?55?71?78?82?83?106?110 0.0001 0.001 0.01 0.05 0.1 1(b) Pairwise comparison of word neighborhood measures as predictors of errors from the isolated-word ASR system usingp-values.
Many low p-values (darker cells) along a column implies the corresponding measure is a significant predictor of ER.Figure 3: Analysis of neighborhood measures with isolated word ASR.following Goldwater et al.
(2010), we use a logis-tic regression model implemented using the glmfunction in R (R Development Core Team, 2005).The logistic regression model fits the log-odds ofa binary response variable with a linear combina-tion of one or more predictor variables.
For ourisolated-word task, the response variable takes avalue of either 1 or 0 corresponding to the pres-ence or absence of an error, respectively; we willrefer to it as ?ER?.
We build a separate logis-tic regression model for each neighborhood mea-sure acting as the only predictor of ER.
We userestricted cubic splines, using the rcs (Harrell Jr.,2012) function in R, to model non-linear predic-tive relationships.
In order to determine whethera neighborhood measure is a significant predictorof ER, we use a likelihood-ratio test (using theanova function in R) that compares the fit of themodel including only that neighborhood measureas a predictor against the fit of a baseline model in-cluding only an intercept and no other predictors.All of the neighborhood measures were found tobe significant predictors, with our measures wAFand wAFx being most significant.
The p-valuesfrom this test are shown in a separate row underthe header ?null?
in Figure 3(b); here, 5?6standsfor 5?
10?6and so forth.
We note that the neigh-borhood measures are significantly correlated withER as individual predictors, but classifiers builtwith each individual measure as the only featureare not good predictors of ASR errors.
This isunsurprising as we expect many other predictorsother than neighborhood measures, as outlined inGoldwater et al.
(2010), to influence ASR errors.This paper focuses only on analyzing each neigh-borhood measure as an individual predictor; jointmodels will be explored as part of future work.Figure 3(a) shows the relationship between er-rors from the isolated ASR system and threeneighborhood measures: the best-performingmeasure (wAFx) and the two standard densitymeasures (ND, wND).
The feature values are ag-gregated into roughly equal-sized bins and theaverage error rate for each bin is plotted.
The60.000 0.005 0.010 0.015 0.0200.00.20.40.6wNDIWER0 10 20 30 400.00.20.40.6rwNDIWER2 4 6 8 100.00.20.40.6rwAFxIWER(a) Neighborhood measures wND, rwND and rwAFx as predictors of IWER.ND ED AF AFx wND wED wAF wAFx rwND rwED rwAF rwAFxND - - - - - - - - - - - -ED - - - - - - - - - - - -AF - - - - - - - - - - - -AFx - - - - - - - - - - - -wND - - - - - - - - - - - -wED - - - - - - - - - - - -wAF - - - - - - - - - - - -wAFx - - - - - - - - - - - -rwND - - - - - - - - - - - -rwED - - - - - - - - - - - -rwAF - - - - - - - - - - - -rwAFx - - - - - - - - - - - -null 0.09 0.72 0.08 0.04 0.18 0.14 0.002 0.03 0.001 0.02 2?52?50 0.0001 0.001 0.01 0.05 0.1 1(b) Pairwise comparison of all word neighborhood measures as predictors of IWER from the continuous-word ASR system.Figure 4: Analysis of neighborhood measures with continuous-word ASR system.solid line shows the probability of an error fromthe corresponding logistic regression model andthe dashed lines show a 95% confidence interval.The dotted line is the average error rate from theentire data set of 401 words, 0.483.
The plotsclearly show the inverse relationship between ourdistance-based measure (wAFx) and the densitymeasures (ND and wND).
The slope of the fittedprobabilities from the logistic regression modelfor a measure is indicative of the usefulness of themeasure in predicting ER.
All of the measures aresignificant predictors having non-zero slope with aslightly larger slope for wAFx than ND and wND.ND and wND being significant predictors of errorsfor isolated words is consistent with prior stud-ies from human speech recognition.
The proposedmeasures, wAF and wAFx, stand out as the bestpredictors of errors.
We next analyze the differ-ences between the measures more closely.Figure 3(b) shows a pairwise comparison of theword neighborhood measures.
Each cell {i, j}shows a p-value range from a likelihood-ratio testthat compares the fit of a logistic regression modelusing only measure i as a predictor with the fit of amodel using both measures i and j as independentpredictors.
Lower p-values (darker cells) indicatethat adding the measure in column j significantlyimproves the ability of the model to predict ER, asopposed to only using the measure along row i.5We use such nested models to compare the modelfits using likelihood-ratio significance tests.
It isclear from Figure 3(b) that our measures wAF andwAFx are the most significant predictors.5The relative frequency-weighted measures (rwND,rwED, rwAF, rwAFx) were omitted since (wND, wED, wAF,wAFx) are significantly better predictors.
This could be be-cause the isolated-word system has no language model and isthus unaffected by the target word frequency.74.2 Continuous-word ASRExperimental Setup: For the continuous-wordtask, our evaluation data consists of full sentencesfrom Switchboard-I that were used to extract theisolated words in Section 4.1.
For our analysis, weinclude all the words in the evaluation sentencesthat are 3 or more phonemes long and occur 100times or more in the training set.
This gives us atotal of 1223 word tokens (459 word types).The continuous-word ASR system uses anacoustic model trained on all of Switchboard-I excluding the above-mentioned evaluation sen-tences.
The acoustic models are GMM-HMMs fortied-state triphones using MFCC + delta + double-delta features with LDA and MLLT feature-spacetransformations and speaker adaptation.
They arealso trained discriminatively using boosted maxi-mum mutual information training from the Kalditoolkit.
We use the entire Switchboard vocabu-lary of 30,241 words and a 3-gram language modeltrained on all of the training sentences.
The worderror rate on the evaluation sentences is 28.3%.6Results and Discussion: Unlike the isolated-word task, the continuous-word ASR system givesword error rates over full utterances.
Since weneed to measure the errors associated with the in-dividual words, we use the individual word er-ror rate (IWER) metric proposed by Goldwater etal.
(2010).
The IWER for wordwiis ?
?ini+deli+subiwhere iniis the number of insertions adja-cent to wi; delior subiis 1 if wiis either deletedor substituted, respectively.
?
is chosen such that?
?
?iini= I where I is the total number of inser-tions for the entire dataset.As in the isolated-word task, we fit logistic re-gression models to analyze the neighborhood mea-sures as predictors of IWER.
Figure 4(a) shows fit-ted probabilities from a logistic regression modelfor IWER built individually using each of the mea-sures wND, rwND and rwAFx as predictors.
Thenumber of frequency-weighted neighbors, wND(as well as the number of neighbors, ND), wasnot found to be a significant predictor of IWER.This is consistent with the findings in Goldwateret al.
(2010) that show weak correlations between6The training set includes other utterances from the samespeakers in the STP evaluation utterances.
This allows foran additional boost in performance from the speaker adaptedacoustic models during recognition.
Ideally, the training andevaluation sets should not contain utterances from the samespeakers.
We allow for this to get word error rates that aremore comparable to state-of-the-art results on this corpus.the number of frequency-weighted neighbors andthe probability of misrecognizing a word.
How-ever, we find that using the number of frequency-weighted neighbors relative to the frequency ofthe word (rwND) improves the correlation withthe probability of error (seen in Figure 4(a) as anincrease in slope).
Using our proposed distancemeasures with relative frequency weighting im-proves the correlation even further.Figure 4(b) shows a pairwise comparison of allmeasures in Table 1; the interpretation is sim-ilar to Figure 3(b).
We observe that the rela-tive frequency-weighted measures (rwND, rwED,rwAF, rwAFx) are consistently better than theirunweighted (ND, ED, AF, AFx) and frequency-weighted (wND, wED, wAF, wAFx) counterparts,with rwAF and rwAFx being most significant.This suggests that the relative frequency-weightedmeasures are taking precedence in the continuous-word task as significant predictors of IWER (un-like in the isolated-word task) due to the presenceof a strong language model.5 ConclusionIn this work, we propose new word neighborhoodmeasures using distances between words that em-ploy a fine-grained articulatory feature-based rep-resentation of the word.
We present a new rank-based averaging method to aggregate the word dis-tances into a single neighborhood score.
We alsosuggest multiple ways of incorporating frequencyweighting into this score.
We analyze the signifi-cance of our word neighborhood measures as pre-dictors of errors from an isolated-word ASR sys-tem and a continuous-word ASR system.
In bothcases, our measures perform significantly betterthan standard neighborhood density measures.This work reopens the question of whether wordneighborhood measures are a useful variable forASR.
There are many possible directions for fu-ture work.
Our measures could be refined fur-ther, for example by exploring alternative distancemeasures, different articulatory feature sets, dif-ferent choices of ?
and ?
in the weighting func-tion, or automatically learned costs and distances.Also, our analysis currently looks at each neigh-borhood measure as an individual predictor; wecould jointly analyze the measures to account forpossible correlations.
Finally, it may be possibleto use neighborhood measures in ASR confidencescoring or even directly in recognition as an addi-tional feature in a discriminative model.8ReferencesT.
M. Bailey and U. Hahn.
2001.
Determinantsof wordlikeness: Phonotactics or lexical neigh-borhoods?
Journal of Memory and Language,44(4):568?591.C.
P. Browman and L. Goldstein.
1992.
Articulatoryphonology: An overview.
Phonetica, 49(3-4):155?180.L.
Deng and D.X.
Sun.
1994.
A statistical approachto automatic speech recognition using the atomicspeech units constructed from overlapping articula-tory features.
The Journal of the Acoustical Societyof America, 95(5):2702?2719.E.
Fosler-Lussier and N. Morgan.
1999.
Effects ofspeaking rate and word frequency on pronunciationsin conversational speech.
Speech Communication,29(2):137?158.E.
Fosler-Lussier, I. Amdal, and H-K. J. Kuo.
2005.
Aframework for predicting speech recognition errors.Speech Communication, 46(2):153?170.J.
J. Godfrey, E. C. Holliman, and J. McDaniel.
1992.SWITCHBOARD: Telephone speech corpus for re-search and development.
In Proc.
of ICASSP.S.
Goldwater, D. Jurafsky, and C. D. Manning.
2010.Which words are hard to recognize?
Prosodic,lexical, and disfluency factors that increase speechrecognition error rates.
Speech Communication,52(3):181?200.S.
Greenberg, J. Hollenback, and D. Ellis.
1996.
In-sights into spoken language gleaned from phonetictranscription of the Switchboard corpus.
In Proc.
ofICSLP.U.
Hahn and T. M. Bailey.
2005.
What makes wordssound similar?
Cognition, 97(3):227?267.F.
E. Harrell Jr. 2012.
RMS: Regression ModelingStrategies.
R package version 3.5-0.J.
Hirschberg, D. Litman, and M. Swerts.
2004.Prosodic and other cues to speech recognition fail-ures.
Speech Communication, 43(1):155?175.P.
Jyothi and E. Fosler-Lussier.
2009.
A comparison ofaudio-free speech recognition error prediction meth-ods.
In Proc.
of Interspeech.P.
Jyothi, K. Livescu, and E. Fosler-Lussier.
2011.Lexical access experiments with context-dependentarticulatory feature-based models.
In Proc.
ofICASSP.P.
Jyothi, E. Fosler-Lussier, and K. Livescu.
2012.
Dis-criminatively learning factorized finite state pronun-ciation models from dynamic Bayesian networks.
InProc.
of Interspeech.2011.
Kaldi.
http://kaldi.sourceforge.net/.K.
Livescu and J.
Glass.
2004.
Feature-based pronun-ciation modeling with trainable asynchrony proba-bilities.
In Proc.
of ICSLP.K.
Livescu.
2005.
Feature-based Pronunciation Mod-eling for Automatic Speech Recognition.
PhD Dis-sertation, MIT EECS department.P.
A. Luce and D. B. Pisoni.
1998.
Recognizing spo-ken words: The neighborhood activation model.
Earand hearing, 19:1?36.P.
A. Luce.
1986.
Neighborhoods of words in the men-tal lexicon.
Research on Speech Perception, (Tech-nical Report No.
6.).W.
D. Marslen-Wilson.
1987.
Functional parallelismin spoken word-recognition.
Cognition, 25(1):71?102.V.
Mitra, H. Nam, C. Y. Espy-Wilson, E. Saltzman,and L. Goldstein.
2011.
Articulatory informationfor noise robust speech recognition.
IEEE Transac-tions on Audio, Speech, and Language Processing,19(7):1913?1924.R.
M. Nosofsky.
1986.
Attention, similarity, and theidentification?categorization relationship.
Journalof Experimental Psychology: General, 115(1):39.D.
Povey, A. Ghoshal, et al.
2011.
The Kaldi speechrecognition toolkit.
Proc.
of ASRU.R Development Core Team.
2005.
R: A language andenvironment for statistical computing.
R foundationfor Statistical Computing.M.
Richardson, J. Bilmes, and C. Diorio.
2003.Hidden-articulator Markov models for speech recog-nition.
Speech Communication, 41(2-3):511?529.R.
A. Scarborough.
2012.
Lexical confusability anddegree of coarticulation.
In Proceedings of the An-nual Meeting of the Berkeley Linguistics Society.T.
Shinozaki and S. Furui.
2001.
Error analysis usingdecision trees in spontaneous presentation speechrecognition.
In Proc.
of ASRU.1996.
The Switchboard Transcription Project.http://www1.icsi.berkeley.edu/Speech/stp/.M.
S. Vitevitch and P. A. Luce.
1999.
Probabilis-tic phonotactics and neighborhood activation in spo-ken word recognition.
Journal of Memory and Lan-guage, 40(3):374?408.T.
Yarkoni, D. Balota, and M. Yap.
2008.
Mov-ing beyond Coltheart?s N: A new measure of ortho-graphic similarity.
Psychonomic Bulletin & Review,15(5):971?979.9
