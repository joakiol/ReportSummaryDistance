EVENT RELATIONS AT THE PHONETICS/PHONOLOGY INTERFACEJULIE CARSON-BERNDSENDAFYDD GIBBONUniversitiit BielefeldFakultiit fiir Linguistik und LiteraturwissenschaftPostfaeh 86404800 Bielefeld 1GermanySummaryIn this paper a procedure for the constrnction of eventrelations at the phonetics/phonolngy interface ispresented.
The approach goes further than previousformal interpretations of autosegmental phonology inthat phonological relations are explicitly related tointervals in actual speech signals as required by aspeech recognition system.
An event structurecontaining the temporal relations of overlap,precedence and inclusion is automatically constructedon the basis of an event lattice with time annotationsderived from the speech signal.
The event structure canbe interpreted linguistically as an antosegmentalrepresentation with assimilation, hmg components orcoarticulation.
The theoretical interest of this work liesin its contrilmtion to the solution of the projectionproblem in speech recognition, since a rigid mapping tosegments i not required.t.
MotivationIn the processing of speech one nf the majorproblems is the projection problem at thephonetics/phonology interface: sounds and words arerealised with different degrees of coarticulation(overlap of properties) iu different lexical, syntactic,and phonostylistic contexts and thus a segmentationinto phonemes alone is too rigid in order to capture allvariants.
Furthermore, the set of possible words innatural languages, analogous to the set of sentences, isinfinite, in fact, even subsets of these sets may be solarge that a simple list is no longer tractable.
This hasso far proved to be an insuperable problem for thesimple concatenative word inodels of current speechrecognition systems, whether phoneme, disyllable, orword based.
In this paper, a new approach to thisproblem is proposed, starting from recent well-motivated developments in phonology such asautosegmental phonology (Goldsmith, 1976,1~)0),artietdatory phonology (Browman & Goldstein,1986,1989), underspecification theory (Archangeli, 1988;Keating, 1988) and phonological events (Bird & Klein,1990).
The overall context for the work presented hereis a further development of the PhoPa system (Carson,1988; Carson-Berndsen, It)0()) for phonological wordparsing with a feature-based phonotactic net.
Thepresent approach goes beyond these studies in derivingphonological relations directly from speech data, and inproviding detailed languageospecific top-downphonotactic coustraints.For phonological parsing a flexible notion ofcompositiouality is utilised based on underspecifiedstructures with 'autosegmental' tiers of parallel phono-logical events which avoid a rigid mapping fromphonetic parameters tosimple sequences of segments.The motivation for using an event-based phonologicalrcprescutatiou was to use phonological knowledge asrepresented in the phonotactic net (thus alsomaintaining the notion of underspecification andoptimisation by the use of feature ooccurrence r stric-tions) while cateriug for those phenomena arising incontinuous peech which do not correspond to thephonotactics of the lm~guage.
An example of this kindof phenomenon found during the labelling of theEUROM-0 speech data in the SAM project (F~SPRIT2589 of.
Brauu, 1991b) is the cluster \[szs\] in theGerman word \[vE:RUNsz.stc:m\] asa pronunciation of/vE:RUNszYste:m/ WctTmtngs.,ystem (seesection 3).By using a phonotactic description based ou auautosegmental representation of events and thetemporal relations which exist between them, a rigids%,mentatkm at the phonetic level is no longernecessary.
A further advantage ofan event representa-tiou with temporal annotatkms at the phonetics-phonology interface coucerns the exchange of differingtypes of information between the two levels.
An eventis interpreted as an interval with a particular property,and it is not necessary to confine the possible set ofproperties to couventional phonological features uchas vnice or nasal but acoustic properties of actualspeech signals such as "fi'icatiou noise" or "syllablepeak" may be included.2.
Event RelationsThree stages are involved in the determinationof signal-derived event relations at the pho-netics/phonology interface.
These are: (1) Event Detec-tion, which will be discussed from the point of view ofphonetic and phonological levels of representation insection 2.1., (2) Event Mapping where the relationsbetween the individual events are constructedautomatically, which is discussed in section 2.2 and (3)Evnut Structure Constraints, defining phonologicalACTES D1!
COLING-92, NArcre's, 23-28 Ao~ 1992 1 2 6 9 PROC.
OF COl JNG-92, NAWrES, Ant;.
23-28, 1992structure, which are discussed in section 2.3.
The workdescribed here ks concerned primarily with speechrecognition rather than synthesis and in particular withits phonological parsing component as opposed to theacoustic front end.
The event relations generated atthe phonetics/phonology interface serve as input to aconstraint-based phonological parser whose knowledgebase is an event-based description of the phonotacticsof the language.2.1.
Phonetic and Phonological EventsAssuming that the feature detectors at the acousticlevel recognise vents each consisting of a property andan interval together with a measure of confidence, it ispossible to define a procedure which automaticallyconstructs temporal relations of overlap, precedenceand inclusion over intervals Bird & Klein (1990) havesome reservations about the use of endpoints ofintervals at tile phonological level.
However, absolutetemporal annotatious must indeed be provided at thephonetic level on the basis of threshold and confidencevalues for a particular acoustic event in a speech signaltoken, and the use of these in the calculation oftemporal relations for a given signal within an actualspeech recognition procedure ks in fact necessary, notan option.At the phonological level, an event is simply a pairof a property and an interval < P, 1 >.
At the phoneticlevel, an event is a quadruple <P, ts, t~, C>, providinginformation on event-type (property), start of interval,end of interval and confidence value.
This serves asinput to event mapping.
The output of the mapping isa set of tuples <ei, R, ej> where ei and ej representevents and R is the temporal relation which existsbetween them (overlap, precedence or temporalinclusion).
Using phonological constraints based onsimplex and complex phonolological event structures,the phonologically relevant information is abstractedfrom this set of tuples.
It is not the temporallyannotated events themselves which are interesting forthe phonological parser but the temporal relationswhich exist between these events (cf.
section 2.3).2.2.
Event Mappinglu the speech recognition context there is amapping of absolute phonetic eveuts to abstract tem-poral relations between events is described.
Thealgorithm for the automatic onstruction of eventrelations has the following properties: Each event pairis tested only once; there is no explicit statement ofreflexivity.
The reflexivity and symmetry of overlap areuot reflected in the output, but can be inferred byModus Poneos fi'om the axioms at the phonologicallevel.
Inclusion is a special case of overlap; thus, whenan event is temporally included in another these eventsalso overlap, and the algorithm makes use of this fact.There are nine types of overlap, seven of which areinstances of inclusion, and all are catered for by thealgorithm.
It was flmnd that the relation of temporalinclusion played an important role in the constraintsneeded for phonological parsing (Carson-Berndsen,1991).
Simultaneity was not considered ue to the factthat phonetic decisions are made on the basis of con-fidence values and thus the likelihood of truesimultaneity is low.
There is no difficulty, however, inaugmenting the algorithm to cater for this if requiredsince it is in fact a relationship of mutual temporalinclusion.The relations of overlap and precedence whichhold between pairs of events are governed by a set ofaxioms; event structures are defined as a collection ofevents and constraints.
These axioms can be regardedas having three different functions: inference, ab-breviation and consistency checking.With respect to the abbreviation function of theaxioms, this feature is not currently availed of in thealgorithm as this would not reduce the search space.The consistency hecking function of the axioms wouldbe an extra step after the relations have beenconstructed.
The output of the event mapping is anevent lattice, analogous to the traditional disjunctivelattices of phoneme, syllable or word-based speechrecognition, but not so far considered in previous workbased on autosegmeutal structures.2.3.
Event Structure ConstraintsThere is clearly no direct correspondencebetween events as measured in a signal, and abstractphonological structures.
These levels differ in fivemajor ways: first, the signal-derived relations may beincomplete, owing to noisy input; second, the signal-derived event relations approximate to the transitiveclosure of the phonologically relevant minimalspecification of the event structure, and must thereforebe reduced by appropriate criteria; third, contextuallyconditioned phonetic reductions, assimilations andepentheses must be resolved; lourth, explicit complexphonological structures need to be defined; fifth, theremay be no simple relation between event endpoints andnodes in parse chart structures.
To complete themapping from phonetic events to phonological eventstructures, constraiuts must be formulated which fulfilthese tasks.
The third type will be briefly discussed insection 3; the rest of the present section is mainlyconcerned with the fourth type.
For the phonologicalcomponent in the present system, a distinction is madebetween simplex and complex events.A simplex phonological event is defined as thebasic unit of input from the phonetic omponent; at thephonetic level these events are in general a function ofseveral parameters and are therefore by no means'simplex' at this level.
A complex phonological event isconstructed compositionally in terms of the precedence,overlap and inclusion relations at the phonologicallevel.
So for example the composition of the simplexevents occlusion, transient and noise results in thecomplex event plosive.
Complex events also refer toAclT.
'.s DE COIANG-92.
NANqlLS, 23-28 AO~':I" 1992 1 2 7 0 PROC.
OF COL1NG-92, NANTES, AUG. 23-28, 1992larger structures relevant at the phonological level suchas syllable onset or reduced syllable.
Using theco~mtraint axiom set, further relations between thesecomplex events are inferred.
In the speech recognitioncontext, absolute speech signal constants are requiredto be assigned to the largest complex events in order topermit synchronisation at higher levels.
The output ofconstraint application is thus a complex event latticewhich is subsequently mapped to a linguistic parsechart (cf.
Chien & al.
1990).3.
An ExampleIn this section, an example of input and output inthe system for generating the relations betweenphonetic events in a token of the English word p_aLm__lm/pa:m/ is  discussed (cf.
also Carson-Berndsen, 1991).The speech signal k~ shown in Figure 1; the phonemicannotations and display were produced with theSAMLAB speech signal labelling system (Braun,1991a).
The events used in this analysis are based on afeature set proposed by Fant (1973); although thefeatures have labels which indicate articulatory features,they are in fact acoustically based.
A diagrammaticrepresentation of the detected events in anapproximately 520 msec interval is shown in Figure 2.The temporally annotated events arc passed to thephonological component of the speech recognitionsystem in the interface format given in (3), Before thealx)ve algorithm is applied, the tuples are uniquelyidentified and translated into a variety of attribute-valuenotation as shown in (4) (note that confidence valuesare not considered further here).
(3) T.empor~l input from the phonetic leve_l<voiceless, 0 91A9, C><voiced, 91.2, 517.5, C><glide, 452.6, 498.2, C><occlusive, 0, 35.4, C><transient, 34.5, 641.6, C><noise, (:~).61, 91.16, C><vowellike, 94.29, 392.6, C><nasal, 402.9, 518.6, C><bilabial, 20.45, 93.2, C><tongue-retracted, 93.21, 392.6, C><bilabial, 392.62, 518.2, C >(4) Ev?nt invent~)r3~et: VOI (voiceless, < 0,91.19 > )e2: VOl(voiced,<91.2,517.5>)e~: GLt(glide, < 452.6,498.2 >)e~: OCC(oeclusive,<0,35.4>)es: TRA(transient,< 34.5,60.6>)e6: NOl(noise, < 60.61,91.16 > )eT: VOW(vowellike, <94.29,392.6 >)es: NAS(nasal, < 402.9,518.6 > )e~: LAB(bilabial, < 20.45,93.2 >)et0: TON(retracted, < 93.21,392.6 > )eL~: LAB(bilabial, < 392.62,518.2 > )Of particular interest to the phonological parser are theprecedence r lations between those event properties ofthe same type and the overlap and temlx~ral inclusionrelations between event properties of differing types.Initially all relations between the individual events aregenerated automatically in (5).
The temporal relationsof overlap, precedence and inclusion are represented bythe symbols '?
', '<'  and '{' respectively.One of the motivations for having chosen anevent-based phonology for coping with the interfacebetween phonetics and phonology was to be able tocater for phenomena which do not correspond to thephonotactics of the language.
It may be the case, asgiven in the example Wi#Jrungssystern in section 2, thatthe information on the centre portion of the signal,which is shown in (6) after the translation intoattribute-value structure, is provided by the phoneticcomponent.
(6) TCmp0rol annotations for !szstl clostere: FRICATION(fricative, < 0, 3(}1.3 > )e~: VOICE(voiced, < 79.9, 229.3 > )e~: VOWELLIKE(vowellike, < 128.5, 202.6 >)e~: OCCLUSION(occlusive, <301.31, 334.6>)There is not a fall match between the output of theevent mapping and any phonological representation,because FRICATION is continuous throughout andand thus overlaps VOWELLIKE rather than bothpreceding and following it.
\]However, the pbonologicalconstraints include information on possible phonotacticstructures; these will not be discussed here in detail(but cf.
Carson-Bcrndsea 1992).
Positions in thesestrnctures ;ire underspecificd in terms of events, thusindirectly defining apriority between specified and non~specified event ypes at those positions.
In this case, atthe relevant VOWELLIKE interval FRICATIONoverlap is not specified, and titus a phonotactic matchis permitted; VOICE is also not specified for initialsibilants.
Note that vowel quality does not need to bespecified in detail in the phonotactics, if an actuallexical item is morc highly specified at these positions,it will match this part of the phonotactic structure, thusultimately allowing the relevant portion of phonologicalrepresentation f Wii.hrttngs.wstetn to be derived.
(7) Constraints tor \[sz~st\] ?
!~!~t~r (fra~mCn 0c~ < c4 (explicitly required by phonotactics)e2 < e4 (explicitly required by phonotactic~s)e 3 < e 4 (explicitly required by phonotaetics)el ?
e2 (not specified by phonotactics)e~ ?
e~ (not specified by phonotactics)e 2 ?
c~ (explicitly required by phonotactics)AC'I~ES DE COLING-92.
NA1VI~S.
23-28 Ao(rr 1992 I 2 7 I PJtoc.
OF COLING-92.
NANTES, AUG. 23-28.
1992m!
!& ,a:mulll L I | i  ......... r _ " -  ...... " .....a:9 M~-z8 M~7 M~6 M~4z5MHz4 M~z3 M~2M~zI M~z.... i i~i~!
:.i~i~i~!~a:iii ~ ,~I~I .
-Figure.
1vo ice lessvo icedocc lus iont rans ientnoiseg l idevowel l ikenasalb i lab ia ltongue retracteda:(5) Outvut of Automatic<el, <, e2><el,  ?, 05><el,  <, e7><el,  <, e11><e5, <, e2><02, 0, e8><e2, ?, e l l><07, <, e3><el0, <, e3><04, <, 06><e4, <, el0><05, <, 08><e5, <, e l l><09, {, 06><09, <, 07><e9, <, e8><e9, <, e l l>Even Maoaing<el  <, 03><el {, 05><el  <, 08><e2 ?, e3><e6 <, e2>< 02 ?, e9 ><04 <, 03><08 ?, e3><e l l  ?, e3><el <, e7><el <, e l l><e9 0, e5><e6 <, e7><e6 <, el0><el0 ?, e7><el0  <, e8><el0.
<, e l l>Figure 2<el, ?, e4><el, ?, e6><el, ?, e9><e2, {, e3>< e2, o, 07 ><e2, ?, e10><05, <, 03><e8, {, e3><el l ,  {, 03><04, <, 08><e5, <, 06><e9, {, e5><06, <, 08><e6, <, e l l><e10, {, e7><e8, ?, e l l><el, {, e4><01, {, e6><el <, e10><04 <, 02><e2 {, e7><e2 {, e10><06 <, 03><09 <, 03><04 o, 05><e4 ?, e9><e5 <, e7><e5 <, el0><e9 ?, e6><e7 <, e8><e7 <, 011><09 <, el0>ACRES Dr. COLING.92.
NAh~ES, 23-28 Aof;r 1992 12 7 2 Pgoc.
OF COLING-92, NANTES, AUG. 23-28.
19924.
Final RemarksIn this paper a new solution to the projectionproblem in speech recognition isproposed in the formof a three-stage procedure for the automaticconstruction of event relations and phonological eventstructures, tarting with an event lattice of simplexevents in the form of temporal annotations provided bythe acoustic phonetic component of a speechrecognition system.
In contrast to the purelyconcatenative solutions to word compositionality whichare conventionally used, the present flexible approachusing the three compositional relations of overlap,precedence and temporal inclusion promise aprincipled and effective solution to the projectionproblem at the phonetics/phonology interface.5.
BibliographyBird, S; E, Klein (1990):Phonological Events, In: Journal of Linguistics 26,33-56.Braun, G. (1991a):SAMLAB.
Ms. University of Bielefeld.Braun, G. (1991b):Tools in Speech Technology: Problems inSegmental Labelling.
Paper held at the Workshopon Computational (Morpho)Phonology, ZiF,Universit/it Bielefeld, 23-25 October 1991.Browman C.P.
; L. Goldstein (1986):Towards an articulatory phonology.
In: PhonologyYearbook 3:219-252Browman C.P.
; L. Goldstein (1989):Articulatory gestures as phonological units.
In:Phonology 6, Cambridge: Cambridge UniversityPress, 201-251Carson, J.
(1988):Unification and Transduction in ComputationalPhonology.
In: Proceedings of the 12th InternationalConference on Computational Linguistics, Budapest,106-111.Carson-Berndsen, J.; D. Gibbon; K. Kn~ipel (1989):Interim Report 31.03.89 and Final Report 30.09.89Forschungsprojekt: Entwicklung phonologischerRegelsysteme und Untersuchungen zurAutomatisierung der Regelerstellung fiir Zwecke derautomatischen Spracherkennung.
Forschungsprojektfinanziert yon der Deutschen Bundespost, Ms.Universit~it BielefeldCarson-Berndsen, J.
(1990):Phonological Processing of Speech Variants.
In:Proceedings of the 13th h~ternational Conferenceon Computational Linguistics, Helsinki 3:21-24Carson-Berndsen, J.
(1991):Ereignisstntkturen far phonologisches Parsen.Project Report: ASL-TR-9-91/UBI, Universityof Bielefeld, August 19")1Carson-Berndsen(1992):An event-based phonotactics for German.
ASL~TR-29-92/UBI, University of Bielefeld, February1992Chien, L-F., K.J.Chen, L-S.Lee (1990).
:An augmented chart data structure with efficientword lattice parsing scheme in speechrecognition applications.
COLING 90, Vol.
2:60-65.
Helsinki.Fant, G. (1973):Speech SouncL~ and Features.
Cambridge,Massachusetts: MIT Press.Goldsmith J.
(1976):Autosegmental Phonology.
Bloomington, Indiana:Indiana University Linguistics Club.Goldsmith, J.
(1990):Autosegmental and Metrical Phonology.Cambridge, Massachusetts: Basil Blackwell Inc.Note: The work presented in this paper was financedby the German Ministry for Research and Technologywithin the project Architectures for Speech andLanguage Systems (VERBMOBIL-ASL-Nord).ACRES DE COLING-92, NAN'I~S, 23-28 AO(~q' 1992 l 2 7 3 PROC.
O~: COLING-92, NANTES.
AUG. 23-28, 1992
