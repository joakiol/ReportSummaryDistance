ON TIIE PORTABILITY OF COMPLEX CONSTRAINT-BASEDGRAMMARSC.J.
Rupp* and Rod JohnsonFormerly of IDS\[A, Corso Elvezia 36, C11900 Lugano1 Int roduct ion\]{.ec('.nt years have seen tile appearance of' a number ofgrammar  f'ormalisms 1 sharing a strong family resem-blance, which we have characterised elsewhere \[R,uppet al, 199d\] as tim property of being constraint-based.As well as having in common many formal proper-ties, these formalisms also support,  often by explicitde.sign, descriptions from a similarly convergent rangeo\[' l inguistic theories, which we might reasonably label"\[ lPSG-l ike".Given the considerable common ground betweensuch formalisms, it is reasonable to begin to ~sk ques-tions about their intertranslatal)i l ity, or, ht program-nling language terms, the relative ease with which itis possible to "port" a grammar  from one such formal-isnl to another.
Such questious are clearly of interest\['or tile enterprise of recovering a.s much as possible ofthe existing stock of already encoded linguistic knowl-edge, perhaps for reuse in a more modern theoretical\['ramework.
They are also of relevance for any attemptsto build in portabi l i ty from the start  in ongoing newgrammar  writing.At present, the criteria for determining whether aparticular translat ion is successful are extremely fuzzy.Apart from anything else, they will presumably de-pend to some extent on external goals, such as, forexample, whether the results will be used in a prac-tical, rnnning system or just in a laboratory experi-ment  to show the feasibility of a particular theoreticalapproach.
In our work, we have.
a.ssulned that,  if thetranslation is intended ,as more than a sterile exercise,then the information in the source description must beworth conserving and hence worth translating.
More-over, we suppose that the resulting target gramInarwill need to be mainta ined and extendcd, and henceshould be wel l -understood and well-behaved.
Giventhese assumptions,  we can begin to impose some con-ditions on what constitutes a "good" translation; ineffect, in a translat ion from grammar  A to grammarB:*Currently affiliated to the Institute for ComputationalIAnguistics, University of Stuttgart, Azenbergstr.12, 70174Stuttgart, Germany, cj(~ims.mfi-stuttgart.dc) In the interests of brevity, we shall often use the term gram-mar to refer to the collection of formal devices which compriseall aspects of a linguistic description, encomn&sslng both gram-maticM and lexical inforrn,~tion.
This is purely a notational con-venience and in no way implies a commitment to the primacyof syntax.?
B and A should have the same input-output be-haviour.?
B should conserve as much as possible of the con-ceptual shape of A.?
B should have comparable or better run-t ime per-formance with respect to A.The first condition is a consequence, if somewhatoversimplified, of tile assumptions we made above,that  the main purpose of the exercise is to preserveusefltl information.The second condit ion h~Ls to do with the relativeexpressivity of tile two formalisms involved.
In ef-fect, tLow much of the conceptual and organisatioualstructure of a linguistic description can pass over un-.changed, and to what extent do conceptual changesthat may have to be made obscure our subsequent un-derstanding of the description as a whole?The question of performance is not l imited to therelative execution speed of source and target gram-mars, though its importance for subsequent mainte-nance and development cannot be overstated, l low dowe approach the case, for example, where the sourcegrammar  uns normally in its native environment butthe translated form fails to terminate unless the de-scription is completely restructured?
And what if thetwo systems use conflicting criteria for the apport ion-ment  of procedural control between the linguist andthe implementat ion?Over the past year, we have been engaged on a nun>bet of experiments designed to investigate these porta-bility issues, and in particular to bring out the impli-cations behind the two related sets of questions aboutexpressivity and performance.
In some ways, our workis similar in spirit to the reusabil ity experiments re-ported in \[Arnold el al., 1993\], though these appearto have been l imited to translation to a single, rathergeneral formalism, and to have been concerned ahnostentirely with questions of relative expressivity.The remainder of this paper discusses our own ex-perinrents and comlnents ou some of our more impor-tant findings so far..900i 'rl 's It c/31," I\[al,U ATypeltierarchyI i~xplici~ l)edicatedl'ars~r ~_ Morphologyyes  llO IlOyes _y(~ _~ yes(Jontol Lazy Hostl)etermiued Evaluation LanguagegloballygloballylocallylocallyyesyesyesnoCommon LispCommon Lispl'rologPrologTable 1: A checklist of tile signiticant properties of the sample implementations2 FormalismsIn our experiments to explore the portability of com-plex constraint-ba.qed grammars we have considered asample of four imt)lemented formalisms:.
UI) (Unillcation Device) \[Johnson and l{.osner,1989, lt.upp cl ql., 1992\] 2 .?
"FFS (Typed l"eature Structures) \[l,hnele and Za-jac, 1990\].?
CUI" (Comprehensive Unification i"ormalism)\[l)i;rre and l';isele, 199l, l)grre and l)orna, 1993\]?
ALE (Al, tribnte l,ogic Engine) \[Carpenter, 195)2\]The original reason for selecting this sample waspractical: the availability of these systems in tile put)liedomain at; the alqu'opriate time3; but on filrther reflec-tion this sample turns ()tit to be quite representative ofthe major differences which may occur in formalismsof this type (cf the very coarse-grained ela.ssilieation iTal)\[e 1)4 The consequences of these distinctions areexplored ira more detail below.The nal, ure of experinmnts in portability requiresnol, otdy tim selection of source and target tbrmalisms,but also of exatnl)le descriptions to be translat.ed.
Inthis respect we opted for taking grammars "fronl thewild", i.e.
native, code from one of the sample formalis,ns that was not designed with ally prior consid-eration of its potential portal)ility.
To be more precise,we have worked with a small, lint formally represen-(.alive IIPSG grammar, originally provided as sampledata with the TI"S system, and a somewhat larger andquite intricate gl) grammar of French, which toucheson such thorny issues ;us clitic placement and objectagreement.
'Fhe init, ial experiments were iu translat-ing the TFS grammar into (Jl), and then subsequentlyinl, o the other two formalisms.
Our attempts to trails--late the ul) French gramtnar into ALl", were Ilot quiteas successful, as a substantive alteration to tit(', strucolure of the syntactic analysis proved necessary, Thesituation with CUF is more.
promising, even thoughthe delinition of an explicit parsing strategy withinthe formalism was required.
'fires(: two issues are dis--cussed further in Section 4.2\[,'or the purposes of this paper  wc see no signif icant dif-ferences bel, wecn UD and its derivatiw~" El ,U, ,uee e.g.
\[lgstival.,19510\].awe did toy with the idea of ent i t l ing this paper :  "OIi' theOUI," reread'ks on how much AI,I'; I J I) need to make  sense of ~LTIeS grmnmar" ,  but  thought  bet ter  of it.4See also \[l{upp, 1992, Johnson and l{upp, 1993\]3 ExpressivityThe underlying assumption that; is crncial to the na-ture of this work is that these formalisms have highlycomparable expressivity, i.e.
they share more than sel>arates them.
This is central to the success of the en-terprise since preservation of concepts defined by thelinguist is an essential part of grammar translation.Consequently, we are I)articularly concerned here withthe main constructs of a linguistic description: types,relations and lists.
We also consider, though to a lesserexl,el,t, purely notational devices like lnacros, whichcan be useful in organising the conceptual structure ofa description.
Of lesser importance in the present con-text.
is the treatment of logical structure, in particulardisjunction; iu any case, this topic has received a gooddeal of attention elsewhere (cf \[Trost, 1993\]).3.1 Types'Fhc role of f~at, ure structure types in constraint-based linguistics t1~ gained increasing importanceas a result of the increa~slng popularity, some mights~y donlinance, of IIPSG \[Pollard and Sag, 1987,Pollard and Sag, forthcoming\].
In HPSG the type sys-tem, or type signature, plays a signitlcant role in deiln-ing the (:lass of legal linguistic objects.
In fact in thecurrent version of the theory only objects wlmse typ-ing information is fldly resolved are considered to beadequate models of naturally occurring linguistic con-structs.
Each of the formalisms we consider permitsthe delinition of feature structure types, but the formand expressivity of these type definitions differ quiteconsiderably, a~s does the significance of type defini-.tions in the description a.s a whole.
The extreme casesare TFS, in which the type system is virtually all thereis, and ol), where type dellnitions imply constrain theattributes which can occur on a feature structure.At this point we should note that a type system inthe "true" or IIPSG sense, requires a notion of typeinheritance which can be further subdivided into threeCOllCeDt8:?
subtype/supertype relations?
feature appropriateness conditions?
closure conditionsType detinitions which form a type system usually en-code immediate subtypes and feature appropriatenessconditions, which specify, at le~Lst, ire attributes which901head = subst  I funct, head(X):  !subst (X)subst = noun I verb I adj I prep.subst\[PKD:boolean\].noun \[CASE: case\] .verb\[VFOKM:vform,AUX: boolean,INV: boolean\].Figure h A fragmentary type system rootcd in headand written in TFSare licensed by the type and the types of their values,as in Figure 1.
Closure is usually a derived notion,in that only attributes licensed by the type or one ofits supertypes may occur, an unlicensed attr ibute in-curring either further subtyping or inconsistency.
UDtype definitions cannot of themselves be used to definea hierarchical type system.
They give an entirely fiatsystem with the most absolute closure and the mostminimal appropriateness conditions.
The type defini-tions of the other formalisms, TFS, CUF and ALE, dif-fer mainly in the expressivity of their appropriatenessconditions, in order of decremsing expressivity, cf \[Man-andhar, 1993\] for a more detailed comparison of thesetype systems.Evidently, one of the most basic hurdles to translat-ing any of the other formMisms into UD is the recon-struction of the type system.
This was the problemposed in our initial experiment of porting an IIPSGgrammar encoded in TFS into up.
Our solution tothis problem, cf Figure 2, consists of separating out thehierarchies of sub- and supertype dependencies fromthose of feature appropriateness, so that each nodein the type hierarchy is represented by two unary ab-straction definitions in the UP encoding.
UD types ~ areonly utilised on the terminal nodes of the type hierar-chy to ensure ult imate closure.
In principle the use ofany pseudo-type definition will work its way down thedependency hierarchy to the terminal node and thenback up the appropriateness hierarchy to gain more in-formation.
While this sounds dreadfully inefficient helazy evaluation strategy adopted in UD in fact avoidsmost of the computational overhead.3 .2  Re la t ionsThe other main constructs used for expressing linguis-tic concepts are relations - or more specifically def-inite relations since most of these formalisnls are infact instantiations of the tIShfeld and Smolka notionof a Constraint Logic Programming language \[tI6hfcldand Smolka, 1988\].
While the same essential notion oc-curs in all thcse formalisms the terminology is quite5Type a~ssignmcnts i  UD have the form: Variable == type,head(X): !funct(X)subst(X): !noun(X)subst (X) :  !verb(X)subst(X): !adj(X)subst (X) :  !prep(X)Subst(X) :  <X prd> = yes /nonoun(X) X == noun!Subst(X)!case(<X case>)verb(X) X = =  verb!Subst(X)<X aux> = yes/no<X inv> = yes/no!vform(<X Worm>)Figure 2: The head system rewritten in UDdiverse, including, for instance, relational abstractions(UD) and parametric sorts (CUF).
In fact in TFS rela-tional constructs actually take the form of types withfeatures expressing their argument structure, althougha relational notation is provided to sweeten the syn-tax slightly.
Since definite relations occur in each of theformalisms, their translation does not pose any imme-diate problems, and many of their usages are the same,e.g.
accounting for relational dependencies and princi-ples in l lPSG-style grammars, cf Figure 3.
Difficultiesdo however occur where the usage of relational con-structs is restricted.
ALE imposes the restriction thattrue definite relations may only be used in the phrasaldomain, attached to phrase structure rules.
On firstimpression, this could pose a serious problem for trans-lations from other formalisms where relations may beused freely in the lexicon.
Our experience has shownthat many such lexical relations can in fact be en-coded using ALE macros, as in Figure 4, which maybe parameterised, but require a deterministic expan-sion.
Where operations involving reeursive or disjunc-tive relations are required there is still the option ofencoding the construct as a lexical rule, though withthe risk of losing some of the conceptual structure.hfp(synsem: loc: cat: head: Head) :=synsem: loc: cat: head: Head.Figure 3: A CUF encoding of a Head Feature Principle.as a unary parametric sort902r ip(Case) macro~nominal(Case),@saturated ,~lex(false).Figure 4: An ALI'\] macro definition3.3  ListsThe last cbuss of constructs that we consider in detailarc' lists, or sequences.
Our objective here is slightlydifferent than in the last two c~mes, since all the for-malisms upport lists and most even supply the same,Prolog-style, notation.
There is however a more sub-tie difference between uB and the more strongly typedforrnalisms, since in all the other formalisms the listnotation is purely syntactic and masks a typed featurestructure that is either atomic or has two attributes.\[n UP where lists are "real" objects, the nnitier ismore explicitly polynlorl)hie , \])lit also admits tin; pro-vision of built-in functions over sequence data-types,whose computational behaviour is more predictablethan that of defined constructs like relations.
Ul) pro-rides both append and member (or perhaps better "ex--tract") over lists and since strings are also a fldldata type concal, enation over strings.
The elfectson perlornrance of hard-coding frequenl,ly used construets can be quite dramatic.
We do not pursue thisquestion here since the tmsociated esign issues areCOml)atral)le with those associated with the decision toincorporate dedicated modnles which are discussed illthe next section.4 Per fo rmanceThe second class of issues which affect the porting of agrammar frolu one forlnalisln to another is COlmeete.dwith the relative perfornlance of the two instantia-tions.
We consider two aspects of this topic, the provi--sion of explicit modules for processing in a particulardomaiu, such as syntactic or morllhological analysers,~md the complex and thorny issue of control informa-tion, or who gets control of control.
First, though, itis worth emphasising wily we (:onsider performance tobe a signilicant issue at all.
We are not - yet, anywayparticularly concerned with the real time perfor-mance of "end-user" allplications.
Wc view all of thesystelns that implenmnt these formalisms as development environments, even if timy were originally devel-oped as "academic" protol,ypes, in several cases witha view to demonstrating it particular theoretical per-spective.
Accordingly, we feel that it is more appropri-ate to evaluate their perfornlance with respect to thedevelopment loop ~ussociated with grammar writing.More.
concretely, if either the analysis or compilationtimes exceed certain acceptable bounds (determinedby pragmatic, external considerations like the atten-tion sl)an of a grammar (levelol)er or lexicographer),then the grammar under development should be re?garded as being, in a purely practical sense, no longerextensible.
These may be rather harsh criteria, but webelieve they reflect a more realistic sense of what thesesystems are good for%4.1  Dedicated  Modu lesA further explicit distinction arises between thosetbrmalisrns which include explicit modules for treat-ing either phrasal or morphological structure (UD,ALl';), and those which only l)rovide a theorem proverover linguistic constraints (TFS, CUF).
In general, weexpect that, other things being equal, a formalismwhose implementation contains dedicated processorsfor phrase structure parsing and/or string processingwill have better run-time performance than one whichdoes not, and this is indeed borne out empirically inthe behaviour of the systems we considered.The prc'senee or absence of an explicit parser alsoha~s obvious consequences for porting experiments.
Ifthere is a parser in the target system and not in thesource system then seine phrase structure componentmust be supplied.
This may just be a vacuous struc-ture or it; may he derived from existing components ofthe source description, llence we have produced threeinstantiations of the UD translatiou of the TFS-I IPSGgra,mnar: one inw~lving a vacuous phrase structure de-scription, one in which grammar rules are derived fromthe phrase structure delinitions of the TFS encodingand one ill which full strings are associated with a lex-icon of garbage tokens to awfid invoking either of UD'sdedicated modnles lbr morphology and syntax.Portability in the other direction poses considerablygreater problems, since not only must the phrase strnc-ture description he encoded, but some parsing strategymust also be detined.
In translating the UD grammarinto (J/Jl" we encoded a head coruer  parser  (cf e.g.\[van Noord, t994\]) directly in the CUF formalism.
Inorder to obtain adequate results with this strategy itwas necessary to make use of all the facilities offeredfor determining both global and local process control.This sheds a certain anionnt of doubt on the possibil-ity of replicating the CUI" resnlts within TFS, whereexplicit local control statements are not permitted.
Weaddress the more general i)roblems with the incorpo-ration of control information in the next section.While the question of translating more or less ex-plicit phra~se structure information is already a diificultone, the issue of porting morphological information isquite chaotic.
There is even less agreement on the in.-formation structure of morphological regnlarities thanthere is on syntactic patterning, avd this fact is re,?tlected in the fact that two of tile systems we havebeen working with do not oiler any apparatus at allfor dealing with sub-word-level phenomena.
Moreover,the two formalisms in our sample which (to admit ex-plicit morphological descriptions differ so greatly ill6That is apart froln acquiring publication.~ (,r qualilicati(ms903the form that these components take that they arenot directly comparable ven with each other .4 .2  Cont ro l  In fo rmat ionThe final issue that wc turn to is one which is in ef-fect most revealing about how system developers viewtheir users.
In terms of our sample formalisms, weonce again can distinguish a two-way split, which ac-tually cuts across all of the groupings that we haveobserved above.
The crude characterisation f this dis-tinction is that some formalisms permit the grammarwriter to influence the local processing strategy, eitherin the good, old-fashioned Prolog manner of orderingclauses, as in ALE, or by providing additional controlinformation, such as delay statements in CUF.
Theother two systems eschew this kind of local tweak-ing of the processing strategy and rely on a globalspecification of processing behaviour.
Of course, thisapparent dichotomy is to some extent illusory.
Thosesystems which retain global control usually permit theuser to modify certain parameters of this behaviour,and those that permit local control information mustalso assnme a global control strategy which may bcless forgiving than that in an apparently more totali-tarian system.
We have two observations in respect ofthe control strategies adopted by these systems.The first of these is that some form of lazy evalua-tion, such as that assumed as a global strategy in bothUD and TFS, can become a requirement of a target sys-tem when the source system permits lazy evaluation.More explicitly a description may rely on a particu-lar evaluation strategy that cannot be emulated in thetarget system.
This situation actually occurred in theporting of the UD French grammar to ALE.
The lack ofa lazy evaluation strategy in ALE required a change inthe analysis of verbal structure s , so the ALE descrip-tion is actually different from the original UD one.
Ina very real sense the port failed, in that, even thoughin terms of the declarative formalism a compatible de-scription was definable, it turned out that this was notrunnable.
The class of portable descriptions betweenALE and any of the other formalisms is therefore fur-ther constrained by the ALE's underlying evahlationstrategy.The second point we would like to make harksback, in many ways, to the warnings inherent in Ka-plan's "procedural seduction".
Kaplan \[Kaplan, 1987\]reports experiences with the use of ATN parsers whichended with both grammar writers and system devel-opers attempting to improve the performance of thesame parser and effectively getting in each other's way.More generally, every time we think we may be mak-ing a smart move by some kind of local fix to the con-7In the case of ALE it would probably be incorrect o speakof a lnorphological nalyser since lexical forms are expanded atcompile time.SAt the corresponding point in the CUb" translation lazyevaluation had to be explicitly enforced by the use of a delaystatementtrol strategy we also make it more difficult for a reallysmart optimising controller to do its job properly.
Ofcourse we have progressed considerably in the declar-ativity and monotonicity of our formalisms which wenow tend to view as st)ecialiscd logics, but where wehave not learnt so much is in our view of the kindof people who arc going to use the implemented sys-tem and what they are capable of.
Where local con-trol information is specified in the ordering of state-ments in definitions, we are effectively requiring thatthe grammar writer be an accomplished logic program-mer.
Where local control information is added to sup-plement an existing grammar description the implicitassumption is even more demanding: that there areindividuals capable of appcudiug local control infor-mation to descriptions that other people have written--- or worse still translated - -  and of getting it right.Both of these approaches ult imately assume that itis not only possible but relatively easy to retain a de-tailed picture of the behaviour of a complex constraintsolver.When translating to a formalism which permits lo-cal control from one which does not, the, issue maycome down simply to a question of rclativc speed ofcomputation, which is important enough iu itself inpractical situations, as we have already pointed out.In cases where the target formalism, like ALE, requireslocal control information in order to guarantee termi-nation, much more is at stake.5 ConclusionWe readily admit that the experiments reported hereare still quite unscientific -- or, we would prefer tothink, prescientific and we are still feeling ourway towards a more rigorous approach to the ques-tion of comparability of implemented formalisms, eventhough the task is noticeably simplified by recent con-vergence of goals and methods in constraint-ba.sedcomputational linguistics.Nonetheless, our experience already suggests, inkeeping with \[Arnold et al, 1993\], that from the pointof view of relative expressivity it is possible to movegrammars from one formalism to another, and evenperhaps to conceive of new grammars which arc de-signed from the start to be portable across a range ofrelated formalisms.As regards the set of issues which we have classed to~gethcr under the heading of performance, on the otherhand, there are still many open questions whicb needto be addressed before porting grammars to serious,extensible and maintainable applications can becomea realistic enterprise.AcknowledgementsThe research reported in this paper was funded bythe Swiss National Fund for Scientific Research, un-der project No.
12-32604.9l Situations and Discourse.904This work would not have been possible without thecooperation of the developers of the various ystems.We would like to t, hank Martin Emele, aochen I)5rre,Michael Dorna, Bob Carl)enter and Gerald Penn formaking their systems available and for their patiencein answering questions, even when these were eithertrivial or relatively I)izarre.
Any misrepresentation oftheir work that occurs here is entirely the fault of theauthors.
We would also like to thank Mike Calcagnofor ~sisting us in some of this work aud carrying outthe translation ofthe TFS-tIPSG grammar into ALE.No thanks are due to Angelo Dalle Molle and his foun-dation whose antics have made completion ofthe workreported here more dilfieult han it need have been.References\[Arnold et al, 1993\] Doug Arnold, Toni Badia,Josef wm Genabith, Stella Markantonatou, StefanMomma, Louisa Sadler, and Paul Schmidt.
Exper-iments in reusability of grammatical resources.
InProceedings of the Sixth Conference of the EuropeanChapter of the Association for Computational Lin-guislics, pages 12 -20, Utrecht, 1993.\[Carpenter, 1992\] B. Carpenter.
The Attribute LogicEngine User's Guide.
Laboratory for Con>putational Linguistics, Philosophy l)epartment,Carnegie Mellon University, Pittsburgh PA 15213,December 1992.\[Dgrre and l)orna, 1993\] J. Dgrre and M. Dorna.CUF - a formalism for linguistic knowledge repre-sentation.
In J. I)5rre, editor, Computational As-pects of Constraint-Based Linguistic Description I,pages 1 22.
ILI~C/l)epartment of Philosophy, Uni-versity of Amsterdam, 1993.
DYANA-2 Deliverable11.1.2.A.\[I)6rre and 1,3isele, 1991\] J. Dgrre and A. Eisele.
Acomprehensive unification-based grammar formal-ism.
DYANA deliverable R3.1.B, Centre for Cog-nitive Science, University of Edinburgh, Scotland,January 19!
)1.\[Emele and Zajac, 1990\] M. Emele and R.
Zajae.
'l~yped unification grammars.
In Proceedings of theISth International Conference on ComputationalLinguistics, COLING 90, pages 293 298, lIelsinki,1990.\[l~,stival, 1990\] D. Estival.
(Jenerat, ing french witha reversible uniIication grammar.
In Proceedingsof the 13th International Conference on Compu-tational Linguistics, COLING 90, volume 2, pages106-111, 1990.\[lIShfeld and Smolka, 1988\] M. lIghfeld andG.
Smolka.
Definite relations over constraintlanguages.
LILOG-Report 53, IBM l)eutschlandGmbll, Stuttgart, 1988.\[Johnson and Rosner, 1989\] IL Johnson andM.
Rosner.
A rich environment forexperimentation with unification grammars.
InProceedings of the Fourth Conference of theEuropean Chapter of the Association forComputational Linguistics, pages 182- 189,Manchester, 1989.\[Johnson and Rupp, 1993\] R. Johnson and C. J.Rupp.
Evaluating complex constraints iu linguistictbrmalisms.
In tl.
'Frost, editor, Featurel, brmalisms and Linguistic Ambiguity.
Ellisllorwoood, Chiehester, 1993.\[Kaplan, 1987\] R. M. Kaplan.
Three seductions ofcomputational psyeholinguistics.
In P. Whitclock,M.
M. Wood, t1.
L. Seiners, P~.
Johnson, andP.
Bennett, editors, Linguistic Theory andComputer Applications, pages 149-188.
AcademicPress, London, 1987.\[Manandhar, 1993\] Suresh Manandhar.
CUF incontext.
In J. DSrre, editor, ComputationalAspects of Constraint-Based Linguistic DescriptionI, pages 43 53.
ILLC/l)epartment of Philosophy,University of Amsterdam, 19,(t3.
I)YANA-2Deliverable R1.2.A.\[Pollard and Rag, 1987\] C. Pollard and I.
A. Sag.hfformation-Based Syntax and Semantics: Volume1 Fundamentals.
Number 13 in CSLI LectureNotes.
CELl, Stanford University, 1987.\[Pollard and Sag, forthcoming\] C. l'ollard and I. A.Sag.
Head-Driven Phrase Structure Grammar.CSLI and University of Chicago Press, Stanfordand Chicago, forthcoming.\[Rupp el al., 1992\] C. J. Rupp, R.. Johnson, andM.
l{osner.
Situation schemata nd linguisticrepresentation.
I  M. Rosner and R,.
Johnson,editors, Computational Linguistics and FormalSemantics, pages 191-221.
Cambridge UniversityPress, Cambridge, 1992.\[Rupp el al., 1994\] C. J. Rnpp, 11.. Johnson, andM.
Rosner.
Overview.
In C. J. ll~upp, M. R.osner,and R.. Johnson, editors, Constraints, Language,and Computation, pages xi-xxiii.
Academic Press,London, 1994.\[Rupp, 1992\] C. J. Rupp.
Abstraction mechanisms inconstraint-based linguistic formalisms.
WorkingPaper 6, IDSIA, 1992.\[Trost, 1993\] I1.
Trost.
Feature Formalisms andLinguistic Ambiguity.
Ellis Ilorwoood, Chichester,1993.\[van Noord, 1994\] G. van Noord.
Head cornerparsing.
In C. J. Rupp, M. Rosner, andIL Johnson, editors, Constraints, Language, andComputation, pages 315-338.
Academic Press,London, 1994.905
