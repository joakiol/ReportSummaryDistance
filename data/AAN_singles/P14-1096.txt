Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1020?1029,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsThat?s sick dude!
:Automatic identification of word sense change across different timescalesSunny Mitra1, Ritwik Mitra1, Martin Riedl2,Chris Biemann2, Animesh Mukherjee1, Pawan Goyal11Dept.
of Computer Science and Engineering,Indian Institute of Technology Kharagpur, India ?
7213022FG Language Technology, Computer Science Department, TU Darmstadt, Germany1{sunnym,ritwikm,animeshm,pawang}@cse.iitkgp.ernet.in2{riedl,biem}@cs.tu-darmstadt.deAbstractIn this paper, we propose an unsupervisedmethod to identify noun sense changesbased on rigorous analysis of time-varyingtext data available in the form of millionsof digitized books.
We construct distribu-tional thesauri based networks from dataat different time points and cluster eachof them separately to obtain word-centricsense clusters corresponding to the differ-ent time points.
Subsequently, we com-pare these sense clusters of two differenttime points to find if (i) there is birth ofa new sense or (ii) if an older sense hasgot split into more than one sense or (iii)if a newer sense has been formed from thejoining of older senses or (iv) if a partic-ular sense has died.
We conduct a thor-ough evaluation of the proposed method-ology both manually as well as throughcomparison with WordNet.
Manual eval-uation indicates that the algorithm couldcorrectly identify 60.4% birth cases froma set of 48 randomly picked samples and57% split/join cases from a set of 21 ran-domly picked samples.
Remarkably, in44% cases the birth of a novel sense isattested by WordNet, while in 46% casesand 43% cases split and join are respec-tively confirmed by WordNet.
Our ap-proach can be applied for lexicography, aswell as for applications like word sensedisambiguation or semantic search.1 IntroductionTwo of the fundamental components of a natu-ral language communication are word sense dis-covery (Jones, 1986) and word sense disambigua-tion (Ide and Veronis, 1998).
While discoverycorresponds to acquisition of vocabulary, disam-biguation forms the basis of understanding.
Thesetwo aspects are not only important from the per-spective of developing computer applications fornatural languages but also form the key compo-nents of language evolution and change.Words take different senses in different contextswhile appearing with other words.
Context playsa vital role in disambiguation of word senses aswell as in the interpretation of the actual mean-ing of words.
For instance, the word ?bank?
hasseveral distinct interpretations, including that of a?financial institution?
and the ?shore of a river.
?Automatic discovery and disambiguation of wordsenses from a given text is an important and chal-lenging problem which has been extensively stud-ied in the literature (Jones, 1986; Ide and Vero-nis, 1998; Sch?utze, 1998; Navigli, 2009).
How-ever, another equally important aspect that has notbeen so far well investigated corresponds to oneor more changes that a word might undergo in itssense.
This particular aspect is getting increas-ingly attainable as more and more time-varyingtext data become available in the form of millionsof digitized books (Goldberg and Orwant, 2013)gathered over the last centuries.
As a motivat-ing example one could consider the word ?sick??
while according to the standard English dictio-naries the word is normally used to refer to somesort of illness, a new meaning of ?sick?
refer-ring to something that is ?crazy?
or ?cool?
is cur-rently getting popular in the English vernacular.This change is further interesting because whiletraditionally ?sick?
has been associated to some-thing negative in general, the current meaning as-sociates positivity with it.
In fact, a rock bandby the name of ?Sick Puppies?
has been foundedwhich probably is inspired by the newer sense ofthe word sick.
The title of this paper has beenmotivated by the above observation.
Note thatthis phenomena of change in word senses has ex-isted ever since the beginning of human commu-nication (Bamman and Crane, 2011; Michel et1020al., 2011; Wijaya and Yeniterzi, 2011; Mihalceaand Nastase, 2012); however, with the advent ofmodern technology and the availability of hugevolumes of time-varying data it now has becomepossible to automatically track such changes and,thereby, help the lexicographers in word sense dis-covery, and design engineers in enhancing vari-ous NLP/IR applications (e.g., disambiguation, se-mantic search etc.)
that are naturally sensitive tochange in word senses.The above motivation forms the basis of thecentral objective set in this paper, which is to de-vise a completely unsupervised approach to tracknoun sense changes in large texts available overmultiple timescales.
Toward this objective wemake the following contributions: (a) devise atime-varying graph clustering based sense induc-tion algorithm, (b) use the time-varying senseclusters to develop a split-join based approach foridentifying new senses of a word, and (c) evalu-ate the performance of the algorithms on variousdatasets using different suitable approaches alongwith a detailed error analysis.
Remarkably, com-parison with the English WordNet indicates thatin 44% cases, as identified by our algorithm, therehas been a birth of a completely novel sense, in46% cases a new sense has split off from an oldersense and in 43% cases two or more older senseshave merged in to form a new sense.The remainder of the paper is organized as fol-lows.
In the next section we present a short re-view of the literature.
In Section 3 we brieflydescribe the datasets and outline the process ofco-occurrence graph construction.
In Section 4we present an approach based on graph cluster-ing to identify the time-varying sense clusters andin Section 5 we present the split-merge based ap-proach for tracking word sense changes.
Evalu-ation methods are summarized in Section 6.
Fi-nally, conclusions and further research directionsare outlined in Section 7.2 Related workWord sense disambiguation as well as word sensediscovery have both remained key areas of re-search right from the very early initiatives in nat-ural language processing research.
Ide and Vero-nis (1998) present a very concise survey of the his-tory of ideas used in word sense disambiguation;for a recent survey of the state-of-the-art one canrefer to (Navigli, 2009).
Some of the first attemptsto automatic word sense discovery were made byKaren Sp?arck Jones (1986); later in lexicography,it has been extensively used as a pre-processingstep for preparing mono- and multi-lingual dictio-naries (Kilgarriff and Tugwell, 2001; Kilgarriff,2004).
However, as we have already pointed outthat none of these works consider the temporal as-pect of the problem.In contrast, the current study, is inspired byworks on language dynamics and opinion spread-ing (Mukherjee et al, 2011; Maity et al, 2012;Loreto et al, 2012) and automatic topic detectionand tracking (Allan et al, 1998).
However, ourwork differs significantly from those proposed inthe above studies.
Opinion formation deals withthe self-organisation and emergence of shared vo-cabularies whereas our work focuses on how thedifferent senses of these vocabulary words changeover time and thus become ?out-of-vocabulary?.Topic detection involves detecting the occurrenceof a new event such as a plane crash, a murder, ajury trial result, or a political scandal in a streamof news stories from multiple sources and track-ing is the process of monitoring a stream of newsstories to find those that track (or discuss) thesame event.
This is done on shorter timescales(hours, days), whereas our study focuses on largertimescales (decades, centuries) and we are inter-ested in common nouns, verbs and adjectives asopposed to events that are characterized mostly bynamed entities.
Other similar works on dynamictopic modelling can be found in (Blei and Laf-ferty, 2006; Wang and McCallum, 2006).
Googlebooks n-gram viewer1is a phrase-usage graphingtool which charts the yearly count of selected lettercombinations, words, or phrases as found in over5.2 million digitized books.
It only reports fre-quency of word usage over the years, but does notgive any correlation among them as e.g., in (Heyeret al, 2009), and does not analyze their senses.A few approaches suggested by (Bond et al,2009; P?a?akk?o and Lind?en, 2012) attempt to aug-ment WordNet synsets primarily using methodsof annotation.
Another recent work by Cook etal.
(2013) attempts to induce word senses and thenidentify novel senses by comparing two differentcorpora: the ?focus corpora?
(i.e., a recent versionof the corpora) and the ?reference corpora?
(olderversion of the corpora).
However, this methodis limited as it only considers two time points to1https://books.google.com/ngrams1021identify sense changes as opposed to our approachwhich is over a much larger timescale, thereby, ef-fectively allowing us to track the points of changeand the underlying causes.
One of the closestwork to what we present here has been put forwardby (Tahmasebi et al, 2011), where the authors an-alyze a newspaper corpus containing articles be-tween 1785 and 1985.
The authors mainly reportthe frequency patterns of certain words that theyfound to be candidates for change; however a de-tailed cause analysis as to why and how a particu-lar word underwent a sense change has not beendemonstrated.
Further, systematic evaluation ofthe results obtained by the authors has not beenprovided.All the above points together motivated us toundertake the current work where we introduce,for the first time, a completely unsupervised andautomatic method to identify the change of a wordsense and the cause for the same.
Further, we alsopresent an extensive evaluation of the proposed al-gorithm in order to test its overall accuracy andperformance.3 Datasets and graph constructionIn this section, we outline a brief descriptionof the dataset used for our experiments andthe graph construction procedure.
The primarysource of data have been the millions of digitizedbooks made available through the Google Bookproject (Goldberg and Orwant, 2013).
The GoogleBook syntactic n-grams dataset provides depen-dency fragment counts by the years.
However, in-stead of using the plain syntactic n-grams, we usea far richer representation of the data in the form ofa distributional thesaurus (Lin, 1997; Rychl?y andKilgarriff, 2007).
In specific, we prepare a distri-butional thesaurus (DT) for each of the time peri-ods separately and subsequently construct the re-quired networks.
We briefly outline the procedureof thesauri construction here referring the readerto (Riedl and Biemann, 2013) for further details.In this approach, we first extract each word and aset of its context features, which are formed by la-beled and directed dependency parse edges as pro-vided in the dataset.
Following this, we computethe frequencies of the word, the context and thewords along with their context.
Next we calculatethe lexicographer?s mutual information LMI (Kil-garriff, 2004) between a word and its features andretain only the top 1000 ranked features for ev-ery word.
Finally, we construct the DT network asfollows: each word is a node in the network andthe edge weight between two nodes is defined asthe number of features that the two correspondingwords share in common.4 Tracking sense changesThe basic idea of our algorithm for tracking sensechanges is as follows.
If a word undergoes asense change, this can be detected by comparingits senses obtained from two different time pe-riods.
Since we aim to detect this change au-tomatically, we require distributional representa-tions corresponding to word senses for differenttime periods.
We, therefore, utilize the basic hy-pothesis of unsupervised sense induction to in-duce the sense clusters over various time periodsand then compare these clusters to detect sensechange.
The basic premises of the ?unsupervisedsense induction?
are briefly described below.4.1 Unsupervised sense inductionWe use the co-occurrence based graph clusteringframework introduced in (Biemann, 2006).
Thealgorithm proceeds in three basic steps.
Firstly,a co-occurrence graph is created for every targetword found in DT.
Next, the neighbourhood/egograph is clustered using the Chinese Whispers(CW) algorithm (see (McAuley and Leskovec,2012) for similar approaches).
The algorithm, inparticular, produces a set of clusters for each targetword by decomposing its open neighborhood.
Wehypothesize that each different cluster correspondsto a particular sense of the target word.
For a de-tailed description, the reader is referred to (Bie-mann, 2011).If a word undergoes sense change, this can bedetected by comparing the sense clusters obtainedfrom two different time periods by the algorithmoutlined above.
For this purpose, we use statis-tics from the DT corresponding to two differenttime intervals, say tviand tvj.
We then run thesense induction algorithm over these two differentdatasets.
Now, for a given word w that appearsin both the datasets, we get two different set ofclusters, say Ciand Cj.
Without loss of gener-ality, let us assume that our algorithm detects msense clusters for the word w in tviand n senseclusters in tvj.
Let Ci= {si1, si2, .
.
.
, sim} andCj= {sj1, sj2, .
.
.
, sjn}, where skzdenotes zthsense cluster for word w during time interval tvk.1022We next describe our algorithm for detecting sensechange from these sets of sense clusters.4.2 Split, join, birth and deathWe hypothesize that word w can undergo sensechange from one time interval (tvi) to another(tvj) as per one of the following scenarios:Split A sense cluster sizin tvisplits into two (ormore) sense clusters, sjp1and sjp2in tvjJoin Two sense clusters siz1and siz2in tvijoin tomake a single cluster sjpin tvjBirth A new sense cluster sjpappears in tvj,which was absent in tviDeath A sense cluster sizin tvidies out and doesnot appear in tvjTo detect split, join, birth or death, we build an(m+1)?
(n+1) matrix I to capture the intersec-tion between sense clusters of two different timeperiods.
The first m rows and n columns corre-spond to the sense clusters in tviand tvjespec-tively.
We append an additional row and column tocapture the fraction of words, which did not showup in any of the sense clusters in another time in-terval.
So, an element Iklof the matrix?
1 ?
k ?
m, 1 ?
l ?
n: denotes the frac-tion of words in a newer sense cluster sjl,that were also present in an older sense clus-ter sik.?
k = m + 1, 1 ?
l ?
n: denotes the fractionof words in the sense cluster sjl, that were notpresent in any of the m clusters in tvi.?
1 ?
k ?
m, l = n + 1: denotes the fractionof words in the sense cluster sik, that did notshow up in any of the n clusters in tvj.Thus, the matrix I captures all the four possiblescenarios for sense change.
Since we can notexpect a perfect split, birth etc., we used certainthreshold values to detect if a candidate word isundergoing sense change via one of these fourcases.
In Figure 1, as an example, we illustratethe birth of a new sense for the word ?compiler?.4.3 Multi-stage filteringTo make sure that the candidate words obtainedvia our algorithm are meaningful, we appliedmulti-stage filtering to prune the candidate wordlist.
The following criterion were used for the fil-tering:Stage 1 We utilize the fact that the CW algorithmis non-deterministic in nature.
We apply CWthree times over the source and target time inter-vals.
We obtain the candidate word lists using ouralgorithm for the three runs, then take the inter-section to output those words, which came up inall the three runs.Stage 2 From the above list, we retain only thosecandidate words, which have a part-of-speech tag?NN?
or ?NNS?, as we focus on nouns for thiswork.Stage 3 We sort the candidate list obtained inStage 2 as per their occurrence in the first timeperiod.
Then, we remove the top 20% and thebottom 20% words from this list.
Therefore, weconsider the torso of the frequency distributionwhich is the most informative part for this typeof an analysis.5 Experimental frameworkFor our experiments, we utilized DTs created for8 different time periods: 1520-1908, 1909-1953,1954-1972, 1973-1986, 1987-1995, 1996-2001,2002-2005 and 2006-2008 (Riedl et al, 2014).The time periods were set such that the amountof data in each time period is roughly the same.We will also use T1to T8to denote these time pe-riods.
The parameters for CW clustering were setas follows.
The size of the neighbourhood (N )to be clustered was set to 200.
The parameter nregulating the edge density in this neighbourhoodwas set to 200 as well.
The parameter a was set tolin, which corresponds to favouring smaller clus-ters by hub downweighing2.
The threshold valuesused to detect the sense changes were as follows.For birth, at least 80% words of the target clustershould be novel.
For split, each split cluster shouldhave at least 30% words of the source cluster andthe total intersection of all the split clusters shouldbe > 80%.
The same parameters were used for thejoin and death case with the interchange of sourceand target clusters.5.1 Signals of sense changeMaking comparisons between all the pairs of timeperiods gave us 28 candidate words lists.
For2data available at http://sf.net/p/jobimtext/wiki/LREC2014_Google_DT/1023Figure 1: Example of the birth of a new sense for the word ?compiler?each of these comparison, we applied the multi-stage filtering to obtain the pruned list of candidatewords.
Table 1 provides some statistics about thenumber of candidate words obtained correspond-ing to the birth case.
The rows correspond to thesource time-period and the columns correspond tothe target time periods.
An element of the tableshows the number of candidate words obtainedby comparing the corresponding source and targettime periods.Table 1: Number of candidate birth senses be-tween all time periodsT2T3T4T5T6T7T8T12498 3319 3901 4220 4238 4092 3578T21451 2330 2789 2834 2789 2468T3917 1460 1660 1827 1815T4517 769 1099 1416T5401 818 1243T6682 1107T7609The table clearly shows a trend.
For most ofthe cases, the number of candidate birth sensestends to increase as we go from left to right.
Sim-ilarly, this number decreases as we go down inthe table.
This is quite intuitive since going fromleft to right corresponds to increasing the gap be-tween two time periods while going down cor-responds to decreasing this gap.
As the gap in-creases (decreases), one would expect more (less)new senses coming in.
Even while moving diago-nally, the candidate words tend to decrease as wemove downwards.
This corresponds to the factthat the number of years in the time periods de-creases as we move downwards, and therefore, thegap also decreases.5.2 Stability analysis & sense change locationFormally, we consider a sense change from tvito tvjstable if it was also detected while com-paring tviwith the following time periods tvks.This number of subsequent time periods, wherethe same sense change is detected, helps us to de-termine the age of a new sense.
Similarly, for acandidate sense change from tvito tvj, we say thatthe location of the sense change is tvjif and onlyif that sense change does not get detected by com-paring tviwith any time interval tvk, intermediatebetween tviand tvj.Table 1 gives a lot of candidate words for sensechange.
However, not all the candidate wordswere stable.
Thus, it was important to prune theseresults using stability analysis.
Also, it is to benoted that these results do not pin-point to the ex-act time-period, when the sense change might havetaken place.
For instance, among the 4238 candi-date birth sense detected by comparing T1and T6,many of these new senses might have come up inbetween T2to T5as well.
We prune these lists fur-ther based on the stability of the sense, as well asto locate the approximate time interval, in whichthe sense change might have occurred.Table 2 shows the number of stable (at leasttwice) senses as well as the number of stablesense changes located in that particular time pe-riod.
While this decreases recall, we found this tobe beneficial for the accuracy of the method.Once we were able to locate the senses as wellas to find the age of the senses, we attempted to1024Table 2: Number of candidate birth senses ob-tained for different time periodsT2T3T4T5T6T7T12498 3319 3901 4220 4238 4092stable 537 989 1368 1627 1540 1299located 537 754 772 686 420 300T21451 2330 2789 2834 2789stable 343 718 938 963 810located 343 561 517 357 227select some representative words and plotted themon a timeline as per the birth period and their agein Figure 2.
The source time period here is 1909-1953.6 Evaluation frameworkDuring evaluation, we considered the clusters ob-tained using the 1909-1953 time-slice as our refer-ence and attempted to track sense change by com-paring these with the clusters obtained for 2002-2005.
The sense change detected was categorizedas to whether it was a new sense (birth), a singlesense got split into two or more senses (split) ortwo or more senses got merged (join) or a particu-lar sense died (death).
We present a few instancesof the resulting clusters in the paper and refer thereader to the supplementary material3for the restof the results.6.1 Manual evaluationThe algorithm detected a lot of candidate wordsfor the cases of birth, split/join as well as death.Since it was difficult to go through all the candi-date sense changes for all the comparisons man-ually, we decided to randomly select some can-didate words, which were flagged by our algo-rithm as undergoing sense change, while compar-ing 1909-1953 and 2002-2005 DT.
We selected 48random samples of candidate words for birth casesand 21 random samples for split/join cases.
Oneof the authors annotated each of the birth casesidentifying whether or not the algorithm signalleda true sense change while another author did thesame task for the split/join cases.
The accuracy asper manual evaluation was found to be 60.4% forthe birth cases and 57% for the split/join cases.Table 3 shows the evaluation results for a fewcandidate words, flagged due to birth.
Columns3http://cse.iitkgp.ac.in/resgrp/cnerg/acl2014_wordsense/correspond to the candidate words, words obtainedin the cluster of each candidate word (we will usethe term ?birth cluster?
for these words, hence-forth), which indicated a new sense, the resultsof manual evaluation as well as the possible sensethis birth cluster denotes.Table 4 shows the corresponding evaluation re-sults for a few candidate words, flagged due tosplit or join.A further analysis of the words marked dueto birth in the random samples indicates thatthere are 22 technology-related words, 2 slangs,3 economics related words and 2 general words.For the split-join case we found that there are3 technology-related words while the rest of thewords are general.
Therefore one of the key ob-servations is that most of the technology relatedwords (where the neighborhood is completelynew) could be extracted from our birth results.
Incontrast, for the split-join instances most of the re-sults are from the general category since the neigh-borhood did not change much here; it either gotsplit or merged from what it was earlier.6.2 Automated evaluation with WordNetIn addition to manual evaluation, we also per-formed automated evaluation for the candidatewords.
We chose WordNet for automated evalua-tion because not only does it have a wide coverageof word senses but also it is being maintained andupdated regularly to incorporate new senses.
Wedid this evaluation for the candidate birth, join andsplit sense clusters obtained by comparing 1909-1953 time period with respect to 2002-2005.
Forour evaluation, we developed an aligner to alignthe word clusters obtained with WordNet senses.The aligner constructs a WordNet dictionary forthe purpose of synset algnment.
The CW clus-ter is then aligned to WordNet synsets by compar-ing the clusters with WordNet graph and the synsetwith the maximum alignment score is returned asthe output.
In summary, the aligner tool takes asinput the CW cluster and returns a WordNet synsetid that corresponds to the cluster words.
The eval-uation settings were as follows:Birth: For a candidate word flagged as birth, wefirst find out the set of all WordNet synset ids forits CW clusters in the source time period (1909-1953 in this case).
Let Sinitdenote the union ofthese synset ids.
We then find WordNet synset idfor its birth-cluster, say snew.
Then, if snew/?1025Figure 2: Examples of birth senses placed on a timeline as per their location as well as ageTable 3: Manual evaluation for seven randomly chosen candidate birth clusters between time periods1909-1953 and 2002-2005Sl Candidate birth cluster Evaluation judgement,No.
Word comments1 implant gel, fibre, coatings, cement, materials, metal, filler No, New set of words butsilicone, composite, titanium, polymer, coating similar sense already existed2 passwords browsers, server, functionality, clients, workstation Yes, New sense relatedprinters, software, protocols, hosts, settings, utilities to ?a computer sense?3 giants multinationals, conglomerates, manufacturers Yes, New sense as ?ancorporations, competitors, enterprises, companies organization with very greatbusinesses, brands, firms size or force?4 donation transplantation, donation, fertilization, transfusions Yes, The new usage of donationtransplant, transplants, insemination, donors, donor ... associated with body organs etc.5 novice negro, fellow, emigre, yankee, realist, quaker, teen No, this looks like a falsemale, zen, lady, admiring, celebrity, thai, millionaire ... positive6 partitions server, printers, workstation, platforms, arrays Yes, New usage related tomodules, computers, workstations, kernel ... the ?computing?
domain7 yankees athletics, cubs, tigers, sox, bears, braves, pirates Yes, related to the ?Newcardinals, dodgers, yankees, giants, cardinals ... York Yankees?
teamSinit, it implies that this is a new sense that wasnot present in the source clusters and we call it a?success?
as per WordNet.Join: For the join case, we find WordNet synsetids s1and s2for the clusters obtained in thesource time period and snewfor the join clusterin the target time period.
If s16= s2and snewiseither s1or s2, we call it a ?success?.Split: For the split case, we find WordNet synsetid soldfor the source cluster and synset ids s1and s2for the target split clusters.
If s16= s2and either s1, or s2retains the id sold, we call it a?success?.Table 5 show the results of WordNet based eval-uation.
In case of birth we observe a success ofTable 5: Results of the automatic evaluation usingWordNetCategory No.
of Candidate Words Success CasesBirth 810 44%Split 24 46%Join 28 43%44% while for split and join we observe a successof 46% and 43% respectively.
We then manuallyverified some of the words that were deemed assuccesses, as well as investigated WordNet sensethey were mapped to.
Table 6 shows some of thewords for which the evaluation detected successalong with WordNet senses.
Clearly, the clusterwords correspond to a newer sense for these words1026Table 4: Manual evaluation for five randomly chosen candidate split/join clusters between time periods1909-1953 and 2002-2005Sl Candidate Source and target clustersNo.
Word1 intonation S: whisper, glance, idioms, gesture, chant, sob, inflection, diction, sneer, rhythm, accents ...(split) T1: nod, tone, grimace, finality, gestures, twang, shake, shrug, irony, scowl, twinkle ...T2: accents, phrase, rhythm, style, phonology, diction, utterance, cadence, harmonies ...Yes, T1corresponds to intonation in normal conversations while T2corresponds to the use of accents informal and research literature2 diagonal S: coast, edge, shoreline, coastline, border, surface, crease, edges, slope, sides, seaboard ...(split) T1: circumference, center, slant, vertex, grid, clavicle, margin, perimeter, row, boundary ..T2: border, coast, seaboard, seashore, shoreline, waterfront, shore, shores, coastline, coastsYes, the split T1is based on mathematics where as T2is based on geography3 mantra S1: sutra, stanza, chanting, chants, commandments, monologue, litany, verse, verses ...(join) S2: praise, imprecation, benediction, praises, curse, salutation, benedictions, eulogy ...T : blessings, spell, curses, spells, rosary, prayers, blessing, prayer, benediction ...Yes, the two seemingly distinct senses of mantra - a contextual usage for chanting and prayer (S1)and another usage in its effect - salutations, benedictions (S2) have now merged in T .4 continuum S: circumference, ordinate, abscissa, coasts, axis, path, perimeter, arc, plane axis ...(split) T1: roadsides, corridors, frontier, trajectories, coast, shore, trail, escarpment, highways ...T2: arc, ellipse, meridians, equator, axis, axis, plane, abscissa, ordinate, axis, meridian ....Yes, the split S1denotes the usage of ?continuum?
with physical objects while thethe split S2corresponds to its usages in mathematics domain.5 headmaster S1: master, overseer, councillor, chancellor, tutors, captain, general, principal ...(join) S2: mentor, confessor, tutor, founder, rector, vicar, graduate, counselor, lawyer ...T : chaplain, commander, surveyor, coordinator, consultant, lecturer, inspector ...No, it seems a false positiveand the mapped WordNet synset matches the birthcluster to a very high degree.6.3 Evaluation with a slang listSlangs are words and phrases that are regarded asvery informal, and are typically restricted to a par-ticular context.
New slang words come up everynow and then, and this plays an integral part in thephenomena of sense change.
We therefore decidedto perform an evaluation as to how many slangwords were being detected by our candidate birthclusters.
We used a list of slangs available fromthe slangcity website4.
We collected slangs for theyears 2002-2005 and found the intersection withour candidate birth words.
Note that the websitehad a large number of multi-word expressions thatwe did not consider in our study.
Further, someof the words appeared as either erroneous or verytransient (not existing more than a few months) en-tires, which had to be removed from the list.
Allthese removal left us with a very little space forcomparison; however, despite this we found 25slangs from the website that were present in ourbirth results, e.g.
?bum?, ?sissy?, ?thug?, ?dude?
etc.4http://slangcity.com/email_archive/index_2003.htm6.4 Evaluation of candidate death clustersMuch of our evaluation was focussed on the birthsense clusters, mainly because these are more in-teresting from a lexicographic perspective.
Addi-tionally, the main theme of this work was to de-tect new senses for a given word.
To detect atrue death of a sense, persistence analysis was re-quired, that is, to verify if the sense was persist-ing earlier and vanished after a certain time period.While such an analysis goes beyond the scope ofthis paper, we selected some interesting candidate?death?
senses.
Table 7 shows some of these inter-esting candidate words, their death cluster alongwith the possible vanished meaning, identified bythe authors.
While these words are still used in arelated sense, the original meaning does not existin the modern usage.7 ConclusionsIn this paper, we presented a completely unsu-pervised method to detect word sense changesby analyzing millions of digitized books archivedspanning several centuries.
In particular, we con-structed DT networks over eight different timewindows, clustered these networks and comparedthese clusters to identify the emergence of novel1027Table 6: Example of randomly chosen candidate birth clusters mapped to WordNetSl Candidate birth cluster Synset Id,No.
Word WordNet sense1 macro code, query, handler, program, procedure, subroutine 6582403, a set sequence of steps,module, script part of larger computer program2 caller browser, compiler, sender, routers, workstation, cpu 4175147, a computer thathost, modem, router, server provides client stations with access to files3 searching coding, processing, learning, computing, scheduling 1144355, programming: setting anplanning, retrieval, routing, networking, navigation order and time for planned events4 hooker bitch, whore, stripper, woman slut, prostitute 10485440, a woman whogirl, dancer ... engages in sexual intercourse for money5 drones helicopters, fighters, rockets, flights, planes 4264914, a craft capable ofvehicles, bomber, missions, submarines ... traveling in outer space6 amps inverters, capacitor, oscillators, switches, mixer 2955247, electrical device characterizedtransformer, windings, capacitors, circuits ... by its capacity to store an electric charge7 compilers interfaces, algorithms, programming, software 6566077, written programs pertainingmodules, libraries, routines, tools, utilities ... to the operation of a computer systemTable 7: Some representative examples for candidate death sense clustersSl Candidate death cluster Vanished meaningNo.
Word1 slop jeans, velveteen, tweed, woollen, rubber, sealskin, wear clothes and bedding supplied tooilskin, sheepskin, velvet, calico, deerskin, goatskin, cloth ... sailors by the navy2 blackmail subsidy, rent, presents, tributes, money, fine, bribes Origin: denoting protection moneydues, tolls, contributions, contribution, customs, duties ... levied by Scottish chiefs3 repertory dictionary, study, compendium, bibliography, lore, directory Origin: denoting an indexcatalogues, science, catalog, annals, digest, literature ... or catalog: from late Latin repertorium4 phrasing contour, outline, construction, handling, grouping, arrangement in the sense ?style or manner ofstructure, modelling, selection, form ...
expression?
: via late Latin Greek phrasissenses.
The performance of our method has beenevaluated manually as well as by comparison withWordNet and a list of slang words.
Through man-ual evaluation we found that the algorithm couldcorrectly identify 60.4% birth cases from a set of48 random samples and 57% split/join cases froma set of 21 randomly picked samples.
Quite strik-ingly, we observe that (i) in 44% cases the birth ofa novel sense is attested by WordNet, (ii) in 46%cases the split of an older sense is signalled oncomparison with WordNet and (iii) in 43% casesthe join of two senses is attested by WordNet.These results might have strong lexicographic im-plications ?
even if one goes by very moderate es-timates almost half of the words would be candi-date entries in WordNet if they were not alreadypart of it.
This method can be extremely usefulin the construction of lexico-semantic networksfor low-resource languages, as well as for keepinglexico-semantic resources up to date in general.Future research directions based on this workare manifold.
On one hand, our method can beused by lexicographers in designing new dictio-naries where candidate new senses can be semi-automatically detected and included, thus greatlyreducing the otherwise required manual effort.On the other hand, this method can be directlyused for various NLP/IR applications like seman-tic search, automatic word sense discovery as wellas disambiguation.
For semantic search, takinginto account the newer senses of the word can in-crease the relevance of the query result.
Similarly,a disambiguation engine informed with the newersenses of a word can increase the efficiency ofdisambiguation, and recognize senses uncoveredby the inventory that would otherwise have to bewrongly assigned to covered senses.
In addition,this method can be also extended to the ?NNP?part-of-speech (i.e., named entities) to identifychanges in role of a person/place.
Furthermore,it would be interesting to apply this method to lan-guages other than English and to try to align newsenses of cognates across languages.AcknowledgementsAM would like to thank DAAD for supporting thefaculty exchange programme to TU Darmstadt.PG would like to thank Google India Private Ltd.for extending travel support to attend the confer-ence.
MR and CB have been supported by an IBMSUR award and by LOEWE as part of the researchcenter Digital Humanities.1028ReferencesJ.
Allan, R. Papka and V. Lavrenko.
1998.
On-linenew event detection and tracking.
In proceedings ofSIGIR, 37?45, Melbourne, Australia.D.
Bamman and G. Crane.
2011.
Measuring HistoricalWord Sense Variation.
In proceedings of JCDL, 1?10, New York, NY, USA.C.
Biemann.
2006.
Chinese whispers - an efficientgraph clustering algorithm and its application to nat-ural language processing problems.
In proceedingsof TextGraphs, 73?80, New York, USA.C.
Biemann.
2011.
Structure Discovery in NaturalLanguage.
Springer Heidelberg Dordrecht LondonNew York.
ISBN 978-3-642-25922-7.D.
Blei and J. Lafferty.
2006.
Dynamic topic mod-els.
In proceedings of ICML, 113?120, Pittsburgh,Pennsylvania.F.
Bond, H. Isahara, S. Fujita, K. Uchimoto, T. Kurib-ayash and K. Kanzaki.
2009.
Enhancing theJapanese WordNet.
In proceedings of workshop onAsian Language Resources, 1?8, Suntec, Singapore.P.
Cook, J. H. Lau, M. Rundell, D. McCarthy, T. Bald-win.
2013.
A lexicographic appraisal of an auto-matic approach for detecting new word senses.
Inproceedings of eLex, 49-65, Tallinn, Estonia.Y.
Goldberg and J. Orwant.
2013.
A dataset ofsyntactic-ngrams over time from a very large cor-pus of English books.
In proceedings of the JointConference on Lexical and Computational Seman-tics (*SEM), 241?247, Atlanta, GA, USA.G.
Heyer, F. Holz and S. Teresniak.
2009.
Change oftopics over time ?
tracking topics by their change ofmeaning.
In proceedings of KDIR, Madeira, Portu-gal.N.
Ide and J. Veronis.
1998.
Introduction to the specialissue on word sense disambiguation: The state of theart.
Computational Linguistics, 24(1):1?40.A.
Kilgarriff, P. Rychly, P. Smrz, and D. Tugwell.2004.
The sketch engine.
In Proceedings of EU-RALEX, 105?116, Lorient, France.A.
Kilgarriff and D. Tugwell.
2001.
Word sketch: Ex-traction and display of significant collocations forlexicography.
In proceedings of COLLOCATION:Computational Extraction, Analysis and Exploita-tion, 32?38, Toulouse, France.D.
Lin.
1997.
Using syntactic dependency as localcontext to resolve word sense ambiguity.
In pro-ceedings of ACL/EACL, 64?71, Madrid, Spain.V.
Loreto, A. Mukherjee and F. Tria.
2012.
On the ori-gin of the hierarchy of color names.
PNAS, 109(18),6819?6824.S.
K. Maity, T. M. Venkat and A. Mukherjee.
2012.Opinion formation in time-varying social networks:The case of the naming game.
Phys.
Rev.
E, 86,036110.J.
McAuley and J. Leskovec.
2012.
Learning to dis-cover social circles in ego networks.
In proceedingsof NIPS, 548?556, Nevada, USA.J.-B.
Michel, Y. K. Shen, A. P. Aiden, A. Veres, M. K.Gray, J. P. Pickett, D. Hoiberg, D. Clancy, P. Norvig,J.
Orwant, S. Pinker, M. A. Nowak and E. L. Aiden.2011.
Quantitative analysis of culture using millionsof digitized books.
Science, 331(6014):176?182.R.
Mihalcea and V. Nastase.
2012.
Word epoch disam-biguation: finding how words change over time.
Inproceedings of ACL, 259?263, Jeju Island, Korea.A.
Mukherjee, F. Tria, A. Baronchelli, A. Puglisi and V.Loreto.
2011.
Aging in language dynamics.
PLoSONE, 6(2): e16677.R.
Navigli.
2009.
Word sense disambiguation: a sur-vey.
ACM Computing Surveys, 41(2):1?69.P.
P?a?akk?o and K. Lind?en.
2012.
Finding a locationfor a new word in WordNet.
In proceedings of theGlobal WordNet Conference, Matsue, Japan.M.
Riedl and C. Biemann.
2013.
Scaling to large3data: An efficient and effective method to computedistributional thesauri.
In proceedings of EMNLP,884?890, Seattle, Washington, USA.M.
Riedl, R. Steuer and C. Biemann.
2014.
Distributeddistributional similarities of Google books over thecenturies.
In proceedings of LREC, Reykjavik, Ice-land.P.
Rychl?y and A. Kilgarriff.
2007.
An efficient al-gorithm for building a distributional thesaurus (andother sketch engine developments).
In proceedingsof ACL, poster and demo sessions, 41?44, Prague,Czech Republic.H.
Sch?utze.
1998.
Automatic word sense discrimina-tion.
Computational Linguistics, 24(1):97?123.K.
Sp?ark-Jones.
1986.
Synonymy and Semantic Clas-sification.
Edinburgh University Press.
ISBN 0-85224-517-3.N.
Tahmasebi, T. Risse and S. Dietze.
2011.
Towardsautomatic language evolution tracking: a study onword sense tracking.
In proceedings of EvoDyn, vol.784, Bonn, Germany.X.
Wang and A. McCallum.
2006.
Topics over time:a non-Markov continuous-time model of topicaltrends.
In proceedings of KDD, 424?433, Philadel-phia, PA, USA.D.
Wijaya and R. Yeniterzi.
2011.
Understanding se-mantic change of words over centuries.
In proceed-ings of the workshop on Detecting and ExploitingCultural Diversity on the Social Web, 35?40, Glas-gow, Scotland, UK.1029
