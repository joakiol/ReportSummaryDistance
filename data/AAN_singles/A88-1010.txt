EVALUATION OF A PARALLEL  CHART PARSERRalph  Gr i shman and Mahesh  Ch i t raoComputer  Sc ience Depar tmentNew York  Un ivers i ty251 Mercer  S t reetNew York ,  New York  10012Abst ractWe descr ibe  a para l le l  imp lementat ion  of  achart parser for a shared-memory multipro-cessor.
The speed-ups obtained with thisparser have been measured for a numberof small natural-language rammars.
Forthe largest of these, part of an operationalquestion-answering system, the parser an 5to 7 times faster than the serial version.1.
In t roduct ionWe report here on a series of experiments o deter-mine whether the parsing component of a naturallanguage analyzer can be easily converted to a par-allel program which provides ignificant speed-upover the serial program.These experiments were prompted in part bythe rapidly growing availability of parallel proces-sor systems.
Parsing remains a relatively time-consuming component of language analysis sys-tems.
This is particularly so if constraints arebeing systematically relaxed in order to handleill-formed input (as suggested, for example, in(Weischedel and Sondheimer, 1983)) or if there isuncertainty regarding the input (as is the case forspeech input, for example).
This time could bereduced if we can take advantage of the new par-allel architectures.
Such a parallel parser could becombined with parallel implementations of othercomponents (the acoustic component of a speechsystem, for example) to improve overall systemperformance.2.
BackgroundThere have been a number of theoretical and algo-rithmic studies of parallel parsing, beginning wellbefore the current availability of suitable experi-mental facilities.For general context-free grammars, it is possi-ble to adapt the Cocke-Younger-Kasami algorithm(Aho and Ullman 1972, p. 314 if) for parallel use.This algorithm, which takes time proportional tort 3 (rt -" length of input string) on a single pro-cessor, can operate in time n using n 2 proces-sors (with shared memory and allowing concur-rent writes).
This algorithm, and its extensionto unification grammars, has been described byHaas (1987b).
The matrix form of this algorithmis well suited to large arrays of synchronous pro-cessors.
The algorithm we describe below is basi-cally a CYK parser with top-down filtering 1, butthe main control structure is an event queue ratherthan iteration over a matrbc.
Because tile CYKmatrix is large and typically sparse 2, we felt thatthe event-driven algorithm would be more efficientin our environment of a small number of asyn-chronous processors (<< n 2 for our longest sen-tences) and grammars augmented by conditionswhich must be checked on each rule applicationand which vary widely in compute time.Cohen et al (1982) present a general upperbound for speed-up in parallel parsing, based outhe number of processors and properties of thegrammar.
Their more detailed analysis, and thesubsequent work of Sarkar and Deo (1985) focuson algorithms and speed-ups for parallel parsing ofdeterministic ontext-free grammars.
Most pro-gramming language grammars are deterministic,but most natural language grammars are not, sothis work (based on shift-reduce parsers) does notseem directly applicable.Experimental data involving actual imple-mentations is more limited.
Extensive measure-ments were made on a parallel version of the1 We also differ from CYK in that  we do not merge dif-ferent analyses of the same str ing as the same symbol.
Asa result, our procedure would not operate in l inear t ime forgeneral (ambiguous) grammars .2For g rammar  #4 given below and a 15-word sentence,the matr ix  would have roughly 15,000 entries (one entry foreach substr ing and each symbol  in the equivalent Chomskynormal  form $ranunar) ,  of which only about  1000 entriesare filled.71Hearsay-II speech understanding system (R. Fen-nel and V. Lesser, 1977).
However, the syntacticanalysis was only one of many knowledge sources,so it is difficult to make any direct comparison be-tween their results and those presented here.
BoltBeranek and Newman is currently conducting ex-periments with a parallel parser quite similar tothose described below (Haas, 1987a).
BBN usesa unification grammar in place of the proceduralrestrictions of our system.
At the time of this writ-ing, we do not yet have detailed results from BBNto compare to our own.3.
Env i ronmentOur programs were developed for the NYU Ultra-computer (Gottlieb et al, 1983), a shared-memoryMIMD parallel processor with a special instruc-tion, fetch-and-add, for processor synchronization.The programs hould be easily adaptable to anysimilar shared memory architecture.The programs have been written in ZLISP,a version of LISP for the Ultracomputer whichhas been developed by Isaac Dimitrovsky (1987).Both an interpreter and a compiler are avail-able.
ZLISP supports several independent pro-cesses, and provides both global variables (sharedby all processes) and variables which are local toeach process.
Our programs have used low-levelsynchronization operations, which directly accessthe fetch-and-add primitive.
More recent versionsof ZLISP also support higher level synchroniza-tion primitives and data structures uch as parallelqueues and parallel stacks.4.
A lgor i thmsOur parser is intended as part of the PROTEUSsystem (Ksiezyk et al 1987).
PROTEUS usesaugmented context-free grammars - context-freegrammars augmented by procedural restrictionswhich enforce syntactic and semantic onstraints.The basic parsing algorithm we use is a chartparser (Thompson 1981, Thompson and Ritchie,1984).
Its basic data structure, the chart, consistsof nodes and edges.
For an n word sentence, thereare n + 1 nodes, numbered O to n. These nodesare connected by active and inactive edges whichrecord the state of the parsing process.
If AW X Y Z is a production, an active edge fromnode nl to n2 labeled by A -+ W X .
Y Zindicates that the symbols W X of this productionhave been matched to words nl + 1 through n2of the sentence.
An inactive edge from nl to n2labeled by a category Y indicates that words n 1 + 1through n2 have been analyzed as a constituent oftype Y.
The "fundamental rule" for extending anactive edge states that if we have an active edgeA ---* W X .
Y Z from nl to n 2 and an inactiveedge of category Y from n 2 to n3, we can build anew active edgeA---* WX Y .Z  f romnl  ton3.If we also have an inactive edge of type Z from n 3to n4, we can then extend once more, creating thistime an inactive edge of type A (corresponding toa completed production) from nl to n4.If we have an active edge A ---* W X .
Y Zfrom nl to n2, and this is the first time we havetried to match symbol Y starting at n2 (there areno edges labeled Y originating at n~), we performa seek on symbol Y at n2: we create an activeedge for each production which expands Y, andtry to extend these edges.
In this way we generateany and all analyses for Y starting at n2.
Thisprocess of seeks and extends forms the core of theparser.
We begin by doing a seek for the sentencesymbol S starting a node 0.
Each inactive edgewhich we finally create for S from node 0 to noden corresponds to a parse of the sentence.The serial (uniprocessor) procedure 3 uses atask queue called an agenda .
Whenever a seek isrequired during the process of extending an edge,an entry is made on the agenda.
When we canextend the edge no further, we go to the agenda,pick up a seek task, create the corresponding ac-tive edge and then try to extend it (possibly givingrise to more seeks).
This process continues untilthe agenda is empty.Our initial parallel implementation wasstraightforward: a set of processors all execute themain loop of the serial program (get task fromagenda / create edge / extend edge), all operat-ing from a single shared agenda.
Thus the ba-sic unit of computation being scheduled is a seek,along with all the associated edge extensions.
Ifthere are many different ways of extending an edge(using the edges currently in the chart) this mayinvolve substantial computation.
We therefore de-veloped a second version of the parser with more-fine-grained parallelism, in which each step of ex-tending an active edge is treated as a separate taskwhich is placed on the agenda.
We present somecomparisons of these two algorithms below.There was one complication which arose inthe parallel implementations: a race condition inthe application of the "fundamental rule".
Sup-pose processor P1 is adding an active edge to the3written by Jean Mark Gawron.72chart from node nl to n2 with the label AW X .
Y Z and, at the same time, processor P2 isadding an inactive edge from node n2 to n3 withthe label Y.
Each processor, when it is finishedadding its edge, will check the chart for possibleapplication of the fundamental rule involving thatedge.
P1 finds the inactive edge needed to furtherextend the active edge it just created; similarly,P2 finds the active edge which can be extendedusing the inactive edge it just created.
Both pro-cessors therefore nd up trying to extend the edgeA ---* W X .
Y Z and we create duplicate copiesof the extended edge A ---* W X Y .
Z.
This racecondition can be avoided by assigning a unique(monotonically increasing) number to each edgeand by applying the fundamental rule only if theedge in the chart is older (has a smaller number)than the edge just added by the processor.As we noted above, the context-free gram-mars are augmented by procedural restrictions.These restrictions are coded in PROTEUS Re-striction Language and then compiled into LISP.A restriction either succeeds or fails, and in ad-dition may assign features to the edge currentlybeing built.
Restrictions may examine the sub-structure through which an edge was built up fromother edges, and can test for features on these con-stituent edges.
There is no dependence on implicitcontext (e.g., variables et by another estriction).As a result, the restrictions impose no complica-tions on the parallel scheduling; they are simplyinvoked as part of the process of extending anedge.5.
GrammarsThese algorithms were tested on four grammars:1.
A "benchmark" grammar:S ~ XXXXXXXXXXXXX~alb lc ld le l f lg lh l i l J2.
A very small English grammar, taken from(Grishman, 1986) and used for teaching pur-poses.
It has 23 nonterminal symbols and 38productions.3.
Grammar #2, with four restrictions added.4.
The grammar for the PROTEUS question-answering system, which includes yes-no andwh- questions, relative and reduced relativeclauses.
It has 35 non-terminal symbols and77 productions.6.
MethodThe programs were run in two ways: on a proto-type parallel processor, and in simulated parallelmode on a standard uniprocessor (the uniproce-cessor version of ZLISP provides for relatively effi-cient simulation of multiple concurrent processes).The runs on our prototype multiprocessor, theNYU Ultracomputer, were limited by the size ofthe machine to 8 processors.
Since we found thatwe could sometimes make effective use of largernumbers of processors, most of our data was col-lected on the simulated parallel system.
For smallnumbers of processors (1-4) we had good agree-ment (within 10%, usually within 2%) between thespeed-ups obtained on the Ultracomputer and un-der simulation 47.
Resu l tsWe consider first the results for the test grammar,#1, analyzing the sentence333333333333This grammar is so simple that we can readily vi-sualize the operation of the parser and predict thegeneral shape of the speed-up curve.
At each to-ken of the sentence, there are 10 productions whichcan expand X, so 10 seek tasks are added to theagenda.
If 10 processors are available, all 10 taskscan be executed in parallel.
Additional processorsproduce no further speed-up; having fewer proces-sors requires some processors to perform severaltasks, reducing the speed-up.
This general behav-ior is borne out by the curve shown in Figure 1.Note that because the successful seek (for the pro-duction X --0 j )  leads to the creation of an inactiveedge for X and extension of the active edge for S,and these operations must be performed serially,the maximal parallelism is much less than 10.The next two figures compare the effective-ness of the two algorithms - the one with coarse-grained parallelism (only seeks as separate tasks)and the other with finer-grain parallelism (eachseek and extend as a separate task).
The finer-grain algorithm is able to make use of more par-allelism in situations where an edge can be ex-tended in several different ways.
On the other4For larger numbers of processors (5-8) the speed-upwith the Ultracomputer was consistently below that withthe simulator.
This was due, we believe, to memory con-tention in the Ultracomputer.
This contention is a prop-erty of the current bus-based prototype and would begreatly reduced in a machine using the target, network-based architecture.73Sp 'EEDUP'2, | |5, I0 15PROCESSORSISSI*E :E "I0I )UP21?
;0  2'o ~0 , ,'0PROCESSORSFigure 1: Speed-up (relative to serial parser) forgrammar ~1 and sentence jjj.~i~_~j.sp ?
2D.
, i iI 0  20  30  40PROCESSORSFigure 2: Speed-up (relative to serial parser) forgrammar ~2 (small grammar without restrictions)on a 3-word sentence for the coarse-grained algo-rithm (1) and the fine-grained algorithm(2).hand, it will have more scheduling overhead, sinceeach extend operation has to be entered on andremoved from the agenda.
We therefore can ex-pect the finer-grained algorithm to do better onmore complex sentences, for which many differentextensions of an active edge will be possible.
Wealso expect he finer-grained algorithm to do bet-ter on grammars with restrictions, ince the evalu-ation of the restriction substantially increases thetime required to extend an edge, and so reducesin proportion the fraction of time devoted to thescheduling overhead.
The expectations are con-firmed by the results shown in Figures 2 and 3.Figure 2, which shows the results using a shortsentence and grammar ~2 (without restrictions),shows that neither algorithm obtains substantialspeed-up and that the fine-grained algorithm isFigure 3: Speed-up (relative to serial parser) forgrammar #3 (small grammar with restrictions)on a 14-word sentence for the coarse-grained al-gorithm (1) and the fine-grained algorithm(2).in fact slightly worse.
Figure 3, which shows theresults using a long sentence and grammar ~3(with restrictions), shows that the fine-grained al-gorithm is performing much better.The remaining three figures how speed-up re-sults for the fine-grained algorithm for grammars2, 3, and 4.
For each figure we show the speed-" up for three sentences: a very short sentence (2-3words), an intermediate one, and a long sentence(14-15 words).
In all cases the graphs plot thenumber of processors vs. the true speed-up - thespeed-up relative to the serial version of the parser.The value for 1 processor is therefore below 1, re-flecting the overhead in the parallel version for en-forcing mutual exclusion in access to shared dataand for scheduling extend tasks.Grammars 2 and 3 are relatively small (38productions) and have few constraints, in par-ticular on adjunct placement.
For short sen-tences these grammars therefore yield a chart withfew edges and little opportunity for parallelism.For longer sentences with several adjuncts, onthe other hand, these grammars produce lots ofparses and hence offer much greater opportunityfor parallelism.
Grammar 4 is larger (77 produc-tions) and provides for a wide variety of sentencetypes (declarative, imperative, wh-question, yes-no-question), but also has tighter constraints, in-cluding constraints on adjunct placement.
Thenumber of edges in the chart and the opportu-nity for parallelism are therefore fairly large forshort sentences, but grow more slowly for longersentences than with grammars 2 and 3.These differences in grammars are reflected74i5~3.....,i 2i | , i10 20 ~,0 40PROCESSORS.Figure 4: Speed-up (relative to serial parser) forgrammar ~2 (small grammar without restrictions)using the fine-grained algorithm for three sen-tences: a 10 word sentence (curve 1), a 3-wordsentence (curve 2) and a 14-word sentence (curve3).
!S I0.PEEDUp 5Sp 2"EEDUP.IA i10 20  3'0 40PROCESSORSFigure 5: Speed-up 'relative to serial parser) forgrammar ~3 (small grammar with restrictions)using the fine-grained algorithm for three sen-tences: a 14-word sentence (curve 1), a 5-wordsentence (curve 2), and a 3-word sentence (curve3).p.6EEDU 4p.-----* I?
10  20  30  " 40PROCESSORS"Figure 6: Speed-up (relative to serial parser) forgrammar ~4 (question-answering grammar) us-ing the fine-grained algorithm for three sentences:a 15-word sentence (curve 1), a 2-word sentence(curve 2), and a 8-word sentence (curve 3).in the results shown in Figures 4-6.
For thesmall grammar without restrictions (grammar#2), the scheduling overhead for fine-grain par-allelism largely defeats the benefits of parallelism,and the overall speed-up is small (Figure 4).
Forthe same grammar with restrictions (grammar#3), the effect of the scheduling overhead is re-duced, a.s we explained above.
The speed-up ismodest for the short sentences, but high (15) forthe long sentence with 15 parses (Figure 5).
Forthe question-answering grammar (grammar ~4),the speed-up is fairly consistent for short and longsentences (Figure 6).8.
DiscussionThrough relatively small changes to an existing se-rial chart parser, we have been able to construct aneffective parallel parsing procedure for natural lan-guage grammars.
For our largest grammar (#4),we obtained consistent speed-ups in the range ofh-7.
Grammars for more complex applications, andthose allowing for ill-formed input, will be consid-erably larger and we can expect higher speed-ups.One issue which should be re-examined in theparallel environment is the effectiveness of top-down filtering.
This filtering, which is relativelyinexpensive, blocks the construction of a substan-tial number of edges and so is generally beneficialin a. serial implementation.
In a parallel environ-ment, however, the filtering enforces a left-to-rightsequencing and so reduces the opportunities forparallelism.
We intend in the near future to trya version of our algorithm without top-down ill-75tering in order to determine the balance betweenthese two effects.9.
AcknowledgementsThis report is based upon work supported by theDefense Advanced Research Projects Agency un-der Contract N00014-85-K-0163 from the Officeof Naval Research, by the National Science Foun-dation under Grant No.
DCR-8501843 and by theInternational Business Machines Corp. under con-tract 534816.References\[1\] Alfred Aho and Jeffrey Ullman, 1972, TheTheory of Parsing, Translation, and Compiling- Volume I: Parsing, Prentice-Hall, EnglewoodCliffs, NJ.\[2\] Jacques Cohen, Timothy Hickey, and Joel Kat-coff, 1982 Upper bounds for speedup in parallelparsing, J. Assn.
Comp.
Mach.
29 (2), pp.
408-428.\[3\] Isaac Dimitrovsky, 1987 ZLISP 0.7 ReferenceManual, Department of Computer Science, NewYork University, New York.\[4\] R. Fennel and V. Lesser, 1977, Parallelism inAI problem solving: a case study of Hearsay II,IEEE Trans.
Comp.
C-26, pp.
98-111.\[5\] Allan Gottlieb, Ralph Grishman, ClydeP.
Kruskal, Kevin P. McAuliffe, LawrenceRudolph, and Marc Snir, 1983, The NYU Ultra-computer - Designing an MIMD Shared Mem-ory Parallel Computer, IEEE Trans.
Comp.,pp.
175-189.\[6\] Andrew Haas, 1987a, Parallel parsing, Talkat Workshop on JANUS and Parallel Parsing,Feb.
24-25, Bolt Beranek and Newman, Cam-bridge, MA.\[7\] Andrew Haas, 1987b, Parallel Parsing for Uni-fication Grammars.
Proc.
IJCAI-87, pp.
615-618.\[8\] Tomasz Ksiezyk, Ralph Grishman, and JohnSterling, 1987, An equipment model and itsrole in the interpretation ofnoun phrases.
Proc.IJCAI-87, pp.
692-695.\[9\] Dilip Sarkar and Narsingh Deo, 1985, Esti-mating the speedup in parsing, Report CS-85-135, Computer Science Dept., WashingtonState University.\[10\] Henry Thompson, 1981, Chart parsing andrule schemata in phrase structure grammar,Proc.
19th Annl.
Meeting Assn.
ComputationalLinguistics, Stanford, CA, 167-72.\[11\] Henry Thompson and Graeme Ritchie, 1984,Implementing natural language parsers.
In Ar-tificial Intelligence Tools, Techniques and Ap-plications, T. O'Shea and M. Eisenstadt, eds.,Harper and Row, New York.\[12\] Ralph M. Weischedel and Norman K. Sond-helmet, 1983, Meta-rules as a Basis for Pro-cessing Ill-Formed Input, Am.
J. ComputationalLinguistics, 9(3-4), pp.
161-177.76
