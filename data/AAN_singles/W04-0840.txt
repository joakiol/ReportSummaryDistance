Senseval 3 Logic Forms: A System and Possible ImprovementsAltaf Mohammed, Dan Moldovan, and Paul ParkerLanguage Computer CorporationRichardson, TX 75080{altaf, moldovan, parker}@languagecomputer.comAbstractLogic Forms, particular powerful logicrepresentations presented in Moldovanand Rus (2001), are simple yet highly ef-fective.
In this paper, the structure ofLogic Forms and their generation frominput text are described.
The results of anevaluation comparing the Logic Formsgenerated by hand with those generatedautomatically are also reported.
Finally,we suggest some improvements to therepresentation used in the LFI task basedon our results.1 IntroductionLogic Forms are first order logic representationsof natural language text.
The notation is veryclose to the natural language.
A Logic Form is acollection of predicate instances derived fromtext.
A detailed description of the notation is pre-sented in Moldovan and Rus (2001).Logic Forms can be utilized by a wide varietyof applications.
A Logic Prover (Rus, 2002;Moldovan et al, 2003) utilizing the axioms gen-erated by the Logic Form generation systemboosts the performance of the Question Answer-ing system.
The Prover essentially takes as inputthe Logic Forms of the question and one or moreanswers and then proceeds to justify (and rank)the answers based on (i) world knowledge axi-oms, and (ii) NLP axioms.
The Logic Prover de-veloped at Language Computer Corporation hasincreased the performance of the QA system by30%.2 Automatic Generation of Logic Forms2.1 Parse Tree ConstructionLogic Forms are derived from the output of asyntactic parser.
The first step is the identifica-tion of word collocations (based on those identi-fied by WordNet (Miller, 1995)).
The parser thenproceeds to identify (i) parts of speech of indi-vidual words, and (ii) syntactic structure of thetext, based on grammar rules.
It also differenti-ates active verb constructs from passive ones.The output is a parse tree.
We also include in theparse tree (i) word senses, based on WordNet,and (ii) named-entity tags (Surdeanu and Hara-bagiu, 2002).
Named-entity tags are tags associ-ated with a word or group of words, indicatingthat they belong to a particular category, for in-stance, currency, time, date, place, human, etc.The word senses from the parse tree are simplyincluded in the Logic Form as is (for subsequentuse in applications), while the named-entity tagsare additionally used in the generation of LogicForms.2.2 Logic Form GenerationFirst we identify independent arguments (thosearguments which are generated anew for certainpredicates).
These include arguments for nouns,Association for Computational Linguisticsfor the Semantic Analysis of Text, Barcelona, Spain, July 2004SENSEVAL-3: Third International Workshop on the Evaluation of Systemsverbs (action/eventuality only), and compoundnouns and coordinating conjunctions (for both ofthese, only the result argument (or the first one)).Independent arguments are also generated forcertain adjectival phrases and/or determiners inthe rare cases when they do not qualify a nounphrase, but stand all by themselves.
The inde-pendent arguments, once generated, are propa-gated up the parse tree (as predicates form theleaves of the parse tree).
In this way, heads ofphrases are marked.Next comes the identification of dependent ar-guments (those which are derived from other in-dependent and/or dependent arguments).
Thesemay include arguments for modifiers (adjectives,adverbs), secondary verb slots (all except thefirst) and secondary coordinating conjunctionslots (all except the resulting argument), or link-ing words (prepositions, subordinating conjunc-tions, etc).
The derivation of these argumentsfollows from a slot-filling approach and is basedon the interpretation of the parse tree structureand the associated transformation rule (Moldovanand Rus, 2001).
This is a rule that says how aparticular parse tree structure must be handled,for instance, 'S -> NP VP' says that the subject ofthe main/action verb of VP is the head of phraseof NP.3 Dealing with Ambiguous StructuresNamed-entity tags are helpful when parsing cer-tain ambiguous structures.
Take, for instance, thefollowing two sentences:(i) They gave the visiting team a heavy loss.
(ii) They played football every evening.The grammar rule for the verb phrase in bothsentences is 'VP -> VB NP NP'.Whereas, in sentence (i), the first NP is the in-direct object and the second one the direct, ex-actly the converse is true for sentence (ii).
Uponcloser examination, it is found that 'every eve-ning' being an indicator of time, does not qualifyfor the position of the direct object.The named-entity recognition system marks allsuch indicators of time/date.
This enables us todisqualify these noun phrases as candidates forthe position of the direct object of a verb.The aforementioned is just one kind of ambi-guity that we have addressed.
Another kind ofambiguity that we encountered (but have not im-plemented a solution for yet) is the reduction ofcertain words to base forms.
Consider, for in-stance,(i) John found the key.
(?find?
in VBN form)(ii) The King promised to found a similar insti-tution.
(?found?
in VB form)A possible solution we considered was lookingat part-of-speech tags (VBN vs. VB) to resolveambiguity, but have not pursued this further inthe (current) absence of a database that maintainsa mapping from inflected word and part-of-speech pairs to the corresponding base forms.Another approach considered was choosing thebase form whose frequency of occurrence in theBrown corpus, as reflected in WordNet, washighest.4 Changes/Improvements for Senseval 3Since no complete specification was given for theproper formation of logic forms for many specialcases, we chose to model our Senseval 3 LogicForm system on the provided examples.
The LFsystem was updated to model the Senseval 3 be-havior in the following ways.4.1 Adverbs Modifying AdjectivesThese adverbs are assigned the same argument asthe adjective they modify (Mohammed, 2003).For instance, ?the extremely fast athlete?
is rep-resented as ?extremely:r_ (x1) fast:a_ (x1) ath-lete:n_ (x1)?.4.2 Variable Slots for VerbsThe verbs are now given a variable number ofarguments (minimum two: the action/eventualityand the subject).
They get arguments for all verbobjects, including prepositional attachments.Previously, we had a fixed slot allocationmechanism for verbs, specifying always the ac-tion, the subject, and the direct object.
Theseslots were filled with dummy arguments in theabsence of proper arguments.Example:S: John gave Mary the book on Saturday.LF (previous notation)John:n_ (x1) give:v_ (e1, x1, x3) Mary:n_ (x2)book:n_ (x3) on (e1, x4) Saturday:n_ (x4)LF (Senseval 3 notation)John:n_ (x1) give:v_ (e1, x1, x3, x2, x4) Mary:n_(x2) book:n_ (x3) on (e1, x4) Saturday:n_ (x4)4.3 Subordinating ConjunctionsThese conjunctions are given two arguments.
Thesecond argument is the main/action verb of thesubordinate clause.
The first argument is as-signed as follows: (i) if the clause attaches to asentence (or a verb phrase), then the main/actionverb of this sentence (or verb phrase), (ii) if theclause attaches to a noun phrase, then the head ofthe noun phrase.
Additional details are presentedin Mohammed (2003).Example:If you heat ice, it melts.LF:If (e2, e1) you (x1) heat:v_ (e1, x1, x2) ice:n_(x2) it (x3) melt:v_ (e2, x3)5 Impact of Parse Tree Accuracy onLogic FormsThe Logic Forms are derived directly from theparse trees.
This makes the generation of accurateparse trees extremely important.
We have ana-lyzed the performance of automatically generatedLogic Forms based on both the machine-generated (hence necessarily somewhat errone-ous) parse trees and parse trees generated by hu-man annotators.The following results are based on the set of300 test sentences provided for the Logic FormsIdentification task at Senseval 3.
The number ofsentences with all predicates correctly identifiedhas increased from 155 to 191, an improvementof 23.2%.
The number of sentences with all cor-rect arguments and all correct predicates (in otherwords, 100% correct Logic Forms) has increasedfrom 65 to 98, a 50.7% improvement over LogicForms derived from machine-generated parsetrees.
The results are presented in Table 1.
Notethat the row captioned ?Predicates?
indicates thenumber of sentences for which all predicateswere correctly identified, while the row cap-tioned ?Entire LF?
indicates those for which allpredicates as well as all associated argumentswere correctly identified.MachineParseHandParseImprove-mentPredicates 155 / 300 191 / 300 23.2%Entire LF 65 / 300 98 / 300 50.7%Table 1: Performance of LF GenerationSystem6 RecommendationsThe sample data provided for the LFI task wasused as the model for expected system behavior.A few recommendations that we believe wouldbe improvements are below.
Note that neitherspace nor time permitted an extensive considera-tion of other alternatives.6.1 Possessive PronounsPossessive pronouns are treated as mere adjec-tives in the sample data.
A better way would beto handle these as any other possession indicator,and thus treat them as two-argument predicates.Example:S: John drives his car.LF (Sample data):John:n_ (x1) drive:v_ (e1, x1, x2) his (x2) car:n_(x2)LF (recommendation):John:n_ (x1) drive:v_ (e1, x1, x2) his (x2, x1)car:n_ (x2)6.2 Hybrid Verb Slot RepresentationA verb's slots are supposed to signify their rela-tion to the verb.
The first slot is always reservedfor the action/eventuality expressed by the verb.The second, then, is always for the subject of theverb.
Now, the third slot should be reserved forthe direct object of the verb (if any), and then,additional slots should be filled if and only ifthere are indirect objects associated with theverb.We propose using either dummy or null argu-ments for certain slots.
For instance, for a verbthat has only indirect objects (apart from a sub-ject), the representation for the verb can be, forinstance,run:v_ (e1, x3, 0, x4, x6, ...), orrun:v_ (e1, x3, x9, x4, x6, ...), where 'x9' is adummy argument that is not referenced anywhereelse in the Logic Form.Moreover, the inclusion of prepositional at-tachments in the verb slots is a kind of redun-dancy that should be avoided.
The followingexamples will make this proposal clear.S: John plays at the park.LF: John:n_ (x1) play:v_ (e1, x1) at (e1, x2)park:n_ (x2)S: John plays every day at the park.LF: John:n_ (x1) play:v_ (e1, x1, 0, x2)every:a_ (x2) day:n_ (x2) at (e1, x3) park:n_ (x3)S: John plays tennis every day at the park.LF: John:n_ (x1) play:v_ (e1, x1, x2, x3) ten-nis:n_ (x2) every:a_ (x3) day:n_ (x3) at (e1, x4)park:n_ (x4)S: John gives Mary the book every evening inthe library.LF: John:n_ (x1) give:v_ (e1, x1, x3, x2, x4)Mary:n_ (x2) book:n_ (x3) every:a_ (x4) eve-ning:n_ (x4) in (e1, x5) library:n_ (x5)Note that none of the examples include the ar-guments for ?park?
or ?library?
in the slots forverbs.
Since these predicates are already con-nected to the verbs via prepositions, it is unnec-essary to also include them in verb slots.ReferencesGeorge A. Miller.
1995.
WordNet: A lexical databasefor English.
In Communications of the ACM, pages39-41.Altaf Mohammed.
2003.
Logic Form Transformationof WordNet Glosses.
Master?s dissertation, Univer-sity of Texas at Dallas, Richardson, TX.Dan I. Moldovan and Vasile Rus.
2001.
Logic FormTransformation of WordNet and its Applicability toQuestion Answering.
In Proceedings of the ACL2001 Conference, July 2001, Toulouse, France.Dan Moldovan et al 2003.
COGEX: A Logic Proverfor Question Answering.
In Proceedings of theHuman Language Technology Conference.Vasile Rus.
2002.
Logic Forms for WordNet Glosses.Ph.D.
dissertation, Southern Methodist University,Dallas, TX.Mihai Surdeanu and Sanda Harabagiu.
2002.
Infra-structure for Open-Domain Information Extraction.In Proceedings of the Human Language Technol-ogy Conference (HLT 2002): 325-330.
