Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 160?170,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsSemantic Parsing to Probabilistic Programs forSituated Question AnsweringJayant Krishnamurthy and Oyvind Tafjord and Aniruddha KembhaviAllen Institute for Artificial Intelligencejayantk,oyvindt,anik@allenai.orgAbstractSituated question answering is the problemof answering questions about an environmentsuch as an image or diagram.
This problemrequires jointly interpreting a question and anenvironment using background knowledge toselect the correct answer.
We present Parsingto Probabilistic Programs (P 3), a novel situ-ated question answering model that can usebackground knowledge and global features ofthe question/environment interpretation whileretaining efficient approximate inference.
Ourkey insight is to treat semantic parses as prob-abilistic programs that execute nondetermin-istically and whose possible executions repre-sent environmental uncertainty.
We evaluateour approach on a new, publicly-released dataset of 5000 science diagram questions, outper-forming several competitive classical and neu-ral baselines.1 IntroductionSituated question answering is a challenging prob-lem that requires reasoning about uncertain inter-pretations of both a question and an environmenttogether with background knowledge to determinethe answer.
To illustrate these challenges, considerthe 8th grade science diagram questions in Figure 1,which are motivated by the Aristo project (Clark andEtzioni, 2016).
These questions require both com-puter vision to interpret the diagram and composi-tional question understanding.
These components,being imperfect, introduce uncertainty that must bejointly reasoned about to avoid implausible interpre-tations.
These uncertain interpretations must further1.
According to the given food chain, what is the num-ber of organisms that eat deer?
(A) 3 (B) 2 (C) 4 (D) 12.
Which organism is both predator and prey?
(A) BarkBeetles (B) Insect-eating birds (C) Deer (D) Hawks3.
Based on the given food web, what would happen ifthere were no insect-eating birds?
(A) The grasshop-per population would increase.
(B) The grasshop-per population would decrease.
(C) There would be nochange in grasshopper number.Figure 1: Example food web questions.
A food web depictsa collection of organisms in an ecosystem with an arrow fromorganism x to y indicating that y eats x.
Questions may requirecounting (1), knowing animal roles (2) and reasoning aboutpopulation changes (3).be combined with background knowledge, such asthe definition of a ?predator,?
to determine the cor-rect answer.The challenges of situated question answeringhave not been completely addressed by prior work.Early ?possible worlds?
models (Matuszek et al,2012; Krishnamurthy and Kollar, 2013; Mali-nowski and Fritz, 2014) were capable of composi-tional question understanding and using backgroundknowledge, but did not jointly reason about environ-160ment/question uncertainty.
These models also usedunscalable inference algorithms for reasoning aboutthe environment, despite the lack of joint reasoning.More recent neural models (Antol et al, 2015; Mali-nowski et al, 2015; Yang et al, 2015) are incapableof using background knowledge and it remains un-clear to what extent these models can represent com-positionality in language.We present Parsing to Probabilistic Programs(P 3), a novel approach to situated question answer-ing that addresses these challenges.
It is motivatedby two observations: (1) situated question answer-ing can be formulated as semantic parsing with anexecution model that is a learned function of theenvironment, and (2) probabilistic programming isa natural and powerful method for specifying thespace of permissible execution models and learningover it.
In P 3, we define a domain theory for the taskas a probabilistic program, then train a joint loglin-ear model to semantically parse questions to logi-cal forms in this theory and execute them in an en-vironment.
Importantly, the model includes globalfeatures over parsing and execution that enable itto avoid unlikely joint configurations.
P 3 lever-ages semantic parsing to represent compositionalityin language and probabilistic programming to spec-ify background knowledge and perform linear-timeapproximate inference over the environment.We present an experimental evaluation of P 3 on anew data set of 5000 food web diagram questions(Figure 1).
We compare our approach to severalbaselines, including possible worlds and neural net-work approaches, finding that P 3 outperforms both.An ablation study demonstrates that global featureshelp the model achieve high accuracy.
We alsodemonstrate that P 3 improves accuracy on a previ-ously published data set.
Finally, we have releasedour data and code to facilitate further research.2 Prior WorkSituated question answering is often formulated interms of parsing both the question and environmentinto a common meaning representation where theycan be combined to select the answer.
This gen-eral approach has been implemented using differentmeaning representations:Possible world models use a logical meaningrepresentation defined by a knowledge base schema.These models train a semantic parser to map ques-tions to queries and an environment model to mapenvironments to knowledge bases in this schema.Executing the queries against the knowledge basesproduces answers.
These models assume that theparser and environment model are independent andfurthermore that the knowledge base consists ofindependent predicate instances (Matuszek et al,2012; Krishnamurthy and Kollar, 2013; Malinowskiand Fritz, 2014).
Despite these strong independenceassumptions, these models have intractable infer-ence.
An exception is Seo et al, (2015) who in-corporate hard constraints on the joint question/envi-ronment interpretation; however, this approach doesnot generalize to soft constraints or arbitrary logicalforms.
In some work only the environment modelis learned (Kollar et al, 2010; Tellex et al, 2011;Howard et al, 2014b; Howard et al, 2014a; Berantet al, 2014; Krishnamurthy and Mitchell, 2015).Neural networks use a vector meaning repre-sentation that encodes both the question and envi-ronment as vectors.
These networks have mostlybeen applied to visual question answering (Antol etal., 2015), where many architectures have been pro-posed (Malinowski et al, 2015; Yang et al, 2015;Fukui et al, 2016).
It is unclear to what extent thesenetworks can represent compositionality in languageusing their vector encodings.
Dynamic Neural Mod-ule Networks (Andreas et al, 2016a; Andreas et al,2016b) are the exception to the above generaliza-tion.
This approach constructs a neural network torepresent the meaning of the question via semanticparsing, then executes this network against the im-age to produce an answer.
Our approach is similarexcept that we construct and execute a probabilisticprogram.
Advantages of our approach are that it nat-urally represents the discrete structure of food websand can use background knowledge.Preliminaries for our work are semantic pars-ing and probabilistic programming.
Semantic pars-ing translates natural language questions into exe-cutable logical forms and has been used in applica-tions such as question answering against a knowl-edge base (Zelle and Mooney, 1993; Zettlemoyerand Collins, 2005; Liang et al, 2011; Kwiatkowskiet al, 2013; Berant et al, 2013; Reddy et al, 2014;Yih et al, 2015; Xu et al, 2016), direction following161(Chen and Mooney, 2011; Artzi and Zettlemoyer,2013), and information extraction (Krishnamurthyand Mitchell, 2012; Choi et al, 2015).
Semanticparsing alone is insufficient for situated question an-swering because it does not interpret the environ-ment; many of the above approaches use semanticparsing as a component in a larger model.Probabilistic programming languages extend pro-gramming languages with primitives for nondeter-ministic choice (McCarthy, 1963; Goodman andStuhlmu?ller, 2014).
We express logical formsin a probabilistic variant of Scheme similar toChurch (Goodman et al, 2008); however, this paperuses Python-like pseudocode for clarity.
The lan-guage has a single choice primitive called choosethat nondeterministically returns one of its argu-ments.
For example choose(1,2,3) can executethree ways, returning either 1, 2, or 3.
Multiplecalls to choose can be combined.
For example,choose(1,2)+choose(1,2) adds two nondeter-ministically chosen values, and therefore has fourexecutions that return 2, 3, 3 and 4.
Each executionalso has a probability; in our case, these probabili-ties are assigned by a trained model given the envi-ronment and not explicitly specified in the program.3 Parsing to Probabilistic Programs (P 3)The P 3 model is motivated by two observations.The first is that situated question answering can beformulated as semantic parsing with an executionmodel that is a learned function of the environment.Consider the first question in Figure 1.
The meaningof this question could be represented by a logicalform such as COUNT(?x.EATS(x, DEER)), whichwe could train a semantic parser to predict given asuitable domain theory of functions such as COUNTand EATS.
However, the information required toexecute this logical form and answer the questionmust be extracted from the diagram.
Specifically,EATS(x, y) depends on whether an arrow is presentbetween x and y, which we must train a visionmodel to determine.
Thus, EATS should be a learnedfunction of the environment.This first observation suggests a need for a for-malism for representing uncertainty and performinglearning over the domain theory?s functions.
Oursecond observation is that probabilistic program-ming is a natural fit for this task.
In this paradigm,the domain theory is a probabilistic program that de-fines the information to be extracted from the envi-ronment by using choose.
To a first approximation,the diagram question theory includes:def eats(x, y)choose(true, false)Logical forms are then probabilistic programs,each of whose possible executions represents a dif-ferent interpretation of the environment.
For exam-ple, executing EATS(LION, DEER) hits the choosein the above definition, resulting in two executionswhere the lion either eats or does not eat the deer.In the COUNT example above, each execution rep-resents a different set of animals that eat the deer.To learn the correct environment interpretation, wetrain an execution model to assign a probability toeach execution given features of the environment.Using probabilistic programming enables us to com-bine learned functions, such as EATS, with back-ground knowledge functions, such as COUNT, andalso facilitates inference.According to these observations, applying P 3 hastwo steps.
The first step is to define an appropriatedomain theory.
This theory is the main design de-cision in instantiating P 3 and provides a powerfulway to encode domain knowledge.
The second stepis to train a loglinear model consisting of a semanticparser and an execution model.
This model learnsto semantically parse questions into logical forms inthe theory and execute them in the environment toanswer questions correctly.
We defer discussion ofthe diagram question domain theory to Section 4 andfocus on the loglinear model in this section.3.1 Model OverviewThe input to the P 3 model is a question and an en-vironment and its output is a denotation, which isa formal answer to the question.
P 3 is a loglinearmodel with two factors: a semantic parser and an ex-ecution model.
The semantic parser scores syntac-tic parses and logical forms for the question.
Theselogical forms are probabilistic programs with mul-tiple possible executions (specified by the domaintheory), each of which may return a different denota-tion.
The execution model assigns a score to each ofthese executions given the environment.
Formally,162ifS/N/S :?x.?y.
?f.CAUSE(x, f(y))miceN :MICEdieS\N :?x.DECREASE(x)S : DECREASE(MICE)S/N : ?y.
?f.CAUSE(DECREASE(MICE), f(y))snakesN :SNAKESwill ?skipS : ?f.CAUSE(DECREASE(MICE), f(SNAKES))Figure 2: Example CCG parse of a question as predicted by thesemantic parser fp.
The logical form ` for the question is shownon the bottom line.the model predicts a denotation ?
for a question q inan environment v using three latent variables:P (?|v, q; ?)
=?e,`,tP (e, `, t|v, q; ?
)1(ret(e) = ?
)P (e, `, t|v, q; ?)
= 1Zq,vfex(e, `, v; ?ex)fp(`, t, q; ?p)The model is composed of two factors.
fp repre-sents the semantic parser that scores logical forms` and syntactic parse trees t given question q andparameters ?p.
fex represents the execution model.Given parameters ?ex, this factor assigns a score to alogical form ` and its execution e in environment v.The denotation ?, i.e., the formal answer to the ques-tion, is simply the value returned by e. Zq,v repre-sents the model?s partition function.
The followingsections describe these factors in more detail.3.2 Semantic ParserThe factor fp represents a Combinatory CategorialGrammar (CCG) semantic parser (Zettlemoyer andCollins, 2005) that scores logical forms for a ques-tion.
Given a lexicon1 mapping words to syntacticcategories and logical forms, CCG defines a set ofpossible syntactic parses t and logical forms ` fora question q.
Figure 3.2 shows an example CCGparse.
fp is a loglinear model over parses (`, t):fp(`, t, q; ?p) = exp{?Tp ?
(`, t, q)}The function ?maps parses to feature vectors.
Weuse a rich set of features similar to those for syn-tactic CCG parsing (Clark and Curran, 2007); a fulldescription is provided in an online appendix.3.3 Execution ModelThe factor fex is a loglinear model over the execu-tions of a logical form given an environment.
Log-ical forms in P 3 are probabilistic programs with a1In our experiments, we automatically learn the lexicon in apreprocessing step.
See Section 5.2 for details.set of possible executions, where each execution eis a sequence, e = [e0, e1, e2, ..., en].
e0 is the pro-gram?s starting state, ei represents the state immedi-ately after the ith call to choose, and en is the stateat termination.
The score of an execution is:fex(e, `, v; ?ex) =n?i=1exp{?Tex?
(ei?1, ei, `, v)}In the above equation, ?ex represents the model?sparameters and ?
represents a feature function thatproduces a feature vector for the difference betweensequential program states ei?1 and ei given environ-ment v and logical form `.
?
can include arbitraryfeatures of the execution, logical form and environ-ment, which is important, for example, to detect cy-cles in a food web (Section 4.3).3.4 InferenceP 3 is designed to rely on approximate inference:our goal is to use rich features to accurately makelocal decisions, as in linear-time parsers (Nivre etal., 2006).
We perform approximate inference us-ing a two-stage beam search.
Given a question q,the first stage performs a beam search over CCGparses to produce a list of logical forms scored byfp.
This step is performed by using a CKY-stylechart parsing algorithm then marginalizing out thesyntactic parses.
The second stage performs a beamsearch over executions of each logical form.
Thespace of possible executions of a logical form isa tree (Figure 4.2) where each internal node rep-resents a partial execution up to a choose call.The search maintains a beam of partial executionsat the same depth, and each iteration advancesthe beam to the next depth, discarding the lowest-scoring executions according to fex to maintain afixed size beam.
This procedure runs in time linearto the number of choose calls.
We implement thesearch by rewriting the probabilistic program intocontinuation-passing style, which allows choose tobe implemented as a function that adds multiple con-tinuations to the search queue; we refer the reader toGoodman and Stuhlmu?ller (2014) for details.
Ourexperiments use a beam size of 100 in the seman-tic parser, executing each of the 10 highest-scoringlogical forms with a beam of 100 executions.1633.5 TrainingP 3 is trained by maximizing loglikelihood withstochastic gradient ascent.
The training data{(qi, vi, ci)}ni=1 is a collection of questions qi andenvironments vi paired with supervision oracles ci.ci(e) = 1 for a correct execution e and ci(e) = 0otherwise.
The oracle ci can implement variouskinds of supervision, including: (1) labeled denota-tions, by verifying the value returned by e and (2) la-beled environments, by verifying each choice madeby e. The oracle for diagram question answeringcombines both forms of supervision (Section 4.5).The objective function O is the loglikelihood ofpredicting a correct execution:O(?)
=n?i=1log?e,l,tci(e)P (e, `, t|qi, vi; ?
)We optimize this objective function usingstochastic gradient ascent, using the approximate in-ference algorithm from Section 3.4 to estimate thenecessary marginals.
When computing the marginaldistribution over correct executions, we filter eachstep of the beam search using the supervision oracleci to improve the approximation.4 Diagram Question Answering with P 3As a case study, we apply P 3 to the task of answer-ing food web diagram questions from an 8th gradescience domain.
A few steps are required to applyP 3.
First, we create a domain theory of food websthat represents extracted information from the dia-gram and background knowledge for the domain.Second, we define the features of the executionmodel that are used to learn how programs in thedomain theory execute given a diagram.
Third, wedefine a component to select a multiple-choice an-swer given a denotation.
Finally, we define the su-pervision oracle used for training.4.1 Food Web Diagram QuestionsWe consider the task of answering food web diagramquestions.
The input consists of a diagram depictinga food web, a natural language question and a listof natural language answer options (Figure 1).
Thegoal is to select the correct answer option.
This taskhas many regularities that require global features:for example, food webs are usually acyclic and cer-tain animals usually have certain roles (e.g., mice areherbivores).
We have collected and released a dataset for this task (Section 5.1).We preprocess the diagrams in the data set us-ing a computer vision system that identifies can-didate diagram elements (Kembhavi et al, 2016).This system extracts a collection of text labels (viaOCR), arrows, arrowheads and objects, each withcorresponding scores.
It also extracts a collection ofscored linkages between these elements.
These ex-tractions are noisy and contain many discrepanciessuch as overlapping text labels and spurious link-ages.
We use these extractions to define a set of can-didate organisms (using the text labels), and also todefine features of the execution model.4.2 Domain TheoryThe domain theory is a probabilistic program encod-ing the information to extract from the environmentas well as background knowledge about food webs.It represents the structure of a food web using twofunctions.
These functions are predicates that invokechoose to return either true or false.
The executionmodel learns to predict which of these values is cor-rect for each set of arguments given the diagram.
Itfurthermore has a collection of deterministic func-tions that encode domain knowledge, including def-initions of animal roles such as HERBIVORE and amodel of population change causation.Figure 4.2 shows pseudocode for a portion ofthe domain theory.
Food webs are representedusing two functions over the extracted text la-bels: ORGANISM(x) indicates whether the labelx is an organism (as opposed to, e.g., the dia-gram title); and EATS(x, y).
The definitions ofthese functions invoke choose while rememberingpreviously chosen values to avoid double countingprobabilities when executing logical forms such asORGANISM(DEER) ?
ORGANISM(DEER).
The re-membered values are stored in a global variable thatis also used to implement the supervision oracle.Deterministic functions such as CAUSE are definedin terms of these learned functions.The uses of choose in the domain theory createa tree of possible executions for every logical form.Figure 4.2 illustrates this tree for the logical form?f.CAUSE(DECREASE(MICE), f(SNAKES)), which164# initialize predicate instance variables# from text labels in environmentworld = {"mice": undef,("mice", "snakes"): undef, ...}def organism(name)if (world[name] == undef)world[name] = choose(true, false)return world[name]def eats(x, y)# same as organism but with pairs.# entities referenced in the logical form# must be organisms.
choose() represents# failure; it returns no values.def getOrganism(x)if (organism(x)) return x else choose()# change events are direction/# text label tuplesdef decrease(x)return ("decrease", x)def cause(e1, e2)e12 = eats(e1[1], e2[1])e21 = eats(e2[1], e1[1])# deterministic model with cases.
e.g.# if eats(y, x) then (cause (decrease x)# (decrease y)) -> truereturn doCause(e1[0], e2[0], e12, e21)Figure 3: Domain theory pseudocode for diagram question an-swering.corresponds to the question ?what happens to thesnakes when the mice decrease??
This logical formis shorthand for the following program:filter(lambda f.cause(decrease(getOrganism("mice")),f(getOrganism("snakes"))),set(decrease, increase, unchanged))Specifically, entities such as MICE are created bycalling getOrganism and logical forms with func-tional types implicitly represent filters over the ap-propriate argument type.
Executing this programfirst applies the filter predicate to decrease.
Next,it evaluates getOrganism("mice"), which callsorganism and encounters the first call to choose.This call is shown as the first branch of the tree inFigure 4.2.
The successful branch proceeds to eval-uate getOrganism("snakes"), shown as the sec-ond branch.
Finally, the successful branch evaluatescause, which calls eats twice, resulting in the finaltwo branches.
The value returned by each branch isdetermined by the causation model which performsorganism(mice)fail organism(snakes)fail eats(mice,snakes)eats(snakes,mice){unch.}
{dec.}eats(snakes,mice){inc.} {}false truefalse truefalsefalse truetruefalse trueFigure 4: Tree of possible executions for the logical form?f.CAUSE(DECREASE(MICE), f(SNAKES)).
Each path fromroot to leaf represents a single execution that returns the indi-cated denotation or fails, and each internal node represents anondeterministic choice made with choose.some deterministic logic on the truth values of thetwo eats relations.4.3 Execution FeaturesThe execution model uses three sets of features: in-stance features, predicate features, and denotationfeatures.
Instance features treat each predicate in-stance independently, while the remainder are globalfeatures of multiple predicate instances and the log-ical form.
We provide a complete listing of featuresin an online appendix.Instance features fire whenever an executionchooses a truth value for a predicate instance.
Thesefeatures are similar to the per-predicate-instance fea-tures used in prior work to produce a distributionover possible worlds.
For ORGANISM(x), our fea-tures are the vision model?s extraction score for xand indicator features for the number of tokens inx.
For EATS(x, y), our features are various combi-nations of the vision model?s scores for arrows thatmay connect the text labels x and y.Predicate features fire based on the global as-signment of truth values to all instances of a singlepredicate.
The features for ORGANISM count oc-currences of overlapping text labels among true in-stances.
The features for EATS include cycle countfeatures for various cycle lengths and arrow reusefeatures.
The cycle count features help the modellearn that food webs are typically, but not always,acyclic and the arrow reuse features aim to preventthe model from predicting two different EATS in-stances on the basis of a single arrow.165Denotation features fire on the return value of anexecution.
There are two kinds of denotation fea-tures: size features that count the number of entitiesin denotations of various types and denotation ele-ment features for specific logical forms.
The sec-ond kind of feature can be used to learn that the de-notation of ?x.HERBIVORE(x) is likely to containMOUSE, but unlikely to contain WOLF.4.4 Answer SelectionP 3 predicts a distribution over denotations for eachquestion, which for our problem must be mappedto a distribution over multiple choice answers.
An-swer selection performs this task using string matchheuristics and an LSTM (Hochreiter and Schmidhu-ber, 1997).
The string match heuristics score eachanswer option given a denotation then select thehighest scoring answer, abstaining in the case of atie.
The score computation depends on the denota-tion?s type.
If the denotation is a set of entities, thescore is an approximate count of the number of enti-ties in the denotation mentioned in the answer usinga fuzzy string match.
If the denotation is a set ofchange events, the score is a fuzzy match of both thechange direction and the animal name.
If the denota-tion is a number, string matching is straightforward.Applying these heuristics and marginalizing out de-notations yields a distribution over answer options.A limitation of the above approach is that it doesnot directly incorporate linguistic prior knowledgeabout likely answers.
For example, ?snake?
is usu-ally a good answer to ?what eats mice??
regardlessof the diagram.
Such knowledge is known to be es-sential for visual question answering (Antol et al,2015; Andreas et al, 2016b) and important in ourtask as well.
We incorporate this knowledge in astandard way, by training a neural network on ques-tion/answer pairs (without the diagram) and combin-ing its predictions with the string match heuristicsabove.
The network is a sequence LSTM that is ap-plied to the question concatenated with each answeroption a to produce a 50-dimensional vector va foreach answer.
The distribution over answers is thesoftmax of the inner product of these vectors witha learned parameter vector w. For simplicity, wecombine these two components using a 50/50 mixof their answer distributions.4.5 Supervision OracleThe supervision oracle for diagram question answer-ing combines supervision of both answers and envi-ronment interpretations.
We assume that each dia-gram has been labeled with a food web.
An exe-cution is correct if and only if (1) all of the chosenvalues in the global variable encoding the food webare consistent with the labeled food web, and (2)string match answer selection applied to its denota-tion chooses the correct answer.
The first constraintguarantees that every logical form has at most onecorrect execution for any given diagram.5 EvaluationOur evaluation compares P 3 to both possible worldsand neural network approaches on our data set offood web diagram questions.
An ablation studydemonstrates that both sets of global features im-prove accuracy.
Finally, we demonstrate P 3?s gen-erality by applying it to a previously-published dataset, obtaining state-of-the-art results.Code, data and supplementary material for thispaper are available at: http://www.allenai.org/paper-appendix/emnlp2016-p35.1 FOODWEBS Data SetFOODWEBS consists of ?500 food web diagramsand ?5000 questions designed to imitate actualquestions encountered on 8th grade science exams.The train/validation/test sets contain ?300/100/100diagrams and their corresponding questions.
Thedata set has three kinds of annotations in addition tothe correct answer for each question.
First, each di-agram is annotated with the food web that it depictsusing ORGANISM and EATS.
Second, each diagramhas predictions from a vision system for various dia-gram elements such as arrows and text labels (Kem-bhavi et al, 2016).
These are noisy predictions, notground truth.
Finally, each question is annotated bythe authors with a logical form (or null if its mean-ing is not representable in the domain theory).
Theselogical forms are not used to train P 3 but are usefulto measure per-component error.We collected FOODWEBS by using a crowdsourc-ing process to expand a collection of real exam ques-tions.
First, we collected 89 questions from 4th and8th grade exams and 500 food web diagrams us-166ing an image search engine.
Second, we generatedquestions for these diagrams using Mechanical Turk.Workers were shown a diagram and a real questionfor inspiration and asked to write a new questionand its answer options.
We validated each gener-ated question by asking 3 workers to answer it, dis-carding questions where at least 2 did not choose thecorrect answer.
We also manually corrected any am-biguous (e.g., two answer options are correct) andpoorly-formatted (e.g., two answer options have thesame letter) questions.
The final data set has highquality: a human domain expert correctly answered95 out of 100 randomly-sampled questions.5.2 Baseline ComparisonOur first experiment compares P 3 with several base-lines for situated question answering.
The first base-line, WORLDS, is a possible worlds model based onMalinowski and Fritz (2014).
This baseline learnsa semantic parser P (`, t|q) and a distribution overfood webs P (w|v), then evaluates ` on w to pro-duce a distribution over denotations.
This model isimplemented by independently training P 3?s CCGparser (on question/answer pairs and labeled foodwebs) and a possible-worlds execution model (on la-beled food webs).
The CCG lexicon for both P 3 andWORLDS was generated by applying PAL (Krishna-murthy, 2016) to the same data.
Both models selectanswers as described in Section 4.4.We also compared P 3 to several neural networkbaselines.
The first baseline, LSTM, is the text-only answer selection model described in Section4.4.
The second baseline, VQA, is a neural net-work for visual question answering.
This modelrepresents each image as a vector by using the fi-nal layer of a pre-trained VGG19 model (Simonyanand Zisserman, 2014) and applying a single fully-connected layer.
It scores answer options by usingthe answer selection LSTM to encode question/an-swer pairs, then computing a dot product betweenthe text and image vectors.
This model is somewhatlimited because VGG features are unlikely to encodeimportant diagram structure, such as the content oftext labels.
Our third baseline, DQA, is a neural net-work that rectifies this limitation (Kembhavi et al,2016).
It encodes the diagram predictions from thevision system as vectors and attends to them usingthe LSTM-encoded question vector to select an an-AccuracyModel Accuracy (Unseen Organisms)P 3 69.1 57.7WORLDS 63.6 50.8LSTM 60.3 34.7VQA 56.5 36.8DQA 59.3 33.0Random 25.2 25.2Table 1: Accuracy of P 3 and several baselines on the FOOD-WEBS test set and a modified test set with unseen organisms.Model Accuracy ?P 3 69.1-LSTM 59.8 -9.3-LSTM -denotation 55.8 -13.3-LSTM -denotation -predicate 52.4 -16.7Table 2: Test set accuracy of P 3 removing LSTM answer se-lection (Section 4.4), denotation features and predicate features(Section 4.3).swer.
This model is trained with question/answerpairs and diagram parses, which is roughly compa-rable to the supervision used to train P 3.Table 5.2 compares the accuracy of P 3 to thesebaselines.
Accuracy is the fraction of questions an-swered correctly.
LSTM performs well on this dataset, suggesting that many questions can be answeredwithout using the image.
This result is consistentwith results on visual question answering (Antolet al, 2015).
The other neural network modelshave similar performance to LSTM, whereas bothWORLDS and P 3 outperform it.
We also find thatP 3 outperforms WORLDS likely due to its globalfeatures, which we investigate in the next section.Given these results, we hypothesized that the neu-ral models were largely memorizing common pat-terns in the text and were not able to interpret thediagram.
We tested this hypothesis by running eachmodel on a test set with unseen organisms created byreversing the organism names in every question anddiagram (Table 5.2, right column).
As expected, theaccuracy of LSTM is considerably reduced on thisdata set.
VQA and DQA again perform similarlyto LSTM, which is consistent with our hypothesis.In contrast, we find that the accuracies of WORLDSand P 3 are only slightly reduced, which is consistentwith superior diagram interpretation abilities but in-effective LSTM answer selection.1675.3 Ablation StudyWe performed an ablation study to further under-stand the impact of LSTM answer selection andglobal features.
Table 5.2 shows the accuracy ofP 3 trained without these components.
We find thatLSTM answer selection improves accuracy by 9points, as expected due to the importance of linguis-tic prior knowledge.
Global features improve accu-racy by 7 points, which is roughly comparable to thedelta between P 3 and WORLDS in Table 5.2.5.4 Component Error AnalysisOur third experiment analyses sources of error bytraining and evaluating P 3 while providing the goldlogical form, food web, or both as input.
Table5.5 shows the accuracy of these three models.
Thefinal entry shows the maximum accuracy possiblegiven our domain theory and answer selection.
Thelarger accuracy improvement with gold food webssuggests that the execution model is responsible formore error than semantic parsing, though both com-ponents contribute.5.5 SCENE ExperimentsOur final experiment applies P 3 to the SCENE dataset of Krishnamurthy and Kollar (2013).
In this dataset, the input is a natural language expression, suchas ?blue mug to the left of the monitor,?
and theoutput is the set of objects in an image that the ex-pression denotes.
The images are annotated with abounding box for each candidate object.
The dataset includes a domain theory that was automaticallygenerated by creating a category and/or relation perword based on its part of speech.
It also includes aCCG lexicon and image features.
We use these re-sources, adding predicate and denotation features.Table 5.5 compares P 3 to prior work on SCENE.The evaluation metric is exact match accuracy be-tween the predicted and labeled sets of objects.
Weconsider three supervision conditions: QA trainswith question/answer pairs, QA+E further includeslabeled environments, and QA+E+LF further in-cludes labeled logical forms.
We trained P 3 in thefirst two conditions, while prior work trained in thefirst and third conditions.
KK2013 is a possibleworlds model with a max-margin training objective.P 3 slightly outperforms in the QA condition and P 3Model Accuracy ?P 3 69.1+ gold logical form 75.1 +6.0+ gold food web 82.3 +13.2+ both 91.6 +22.5Table 3: Accuracy of P 3 when trained and evaluated with la-beled logical forms, food webs, or both.SupervisionModel QA QA+E QA+E+LFP 3 68 75 ?KK2013 67 ?
70Table 4: Accuracy on the SCENE data set.
KK2013 results arefrom Krishnamurthy and Kollar (2013).trained with labeled environments outperforms priorwork trained with additional logical form labels.6 ConclusionParsing to Probabilistic Programs (P 3) is a novelmodel for situated question answering that jointlyreasons about question and environment interpreta-tions using background knowledge to produce an-swers.
P 3 uses a domain theory ?
a probabilisticprogram ?
to define the information to be extractedfrom the environment and background knowledge.A semantic parser maps questions to logical forms inthis theory, which are probabilistic programs whosepossible executions represent possible interpreta-tions of the environment.
An execution model scoresthese executions given features of the environment.Both the semantic parser and execution model arejointly trained in a loglinear model, which therebylearns to both parse questions and interpret environ-ments.
Importantly, the model includes global fea-tures of the logical form and executions, which helpthe model avoid implausible interpretations.
Wedemonstrate P 3 on a challenging new data set of5000 science diagram questions, where it outper-forms several competitive baselines.AcknowledgmentsWe gratefully acknowledge Minjoon Seo, Mike Sal-vato and Eric Kolve for their implementation help,Isaac Cowhey and Carissa Schoenick for their helpwith the data, and Oren Etzioni, Peter Clark, MattGardner, Hannaneh Hajishirzi, Mike Lewis, andJonghyun Choi for their comments.168ReferencesJacob Andreas, Marcus Rohrbach, Trevor Darrell, andDan Klein.
2016a.
Deep compositional question an-swering with neural module networks.
In CVPR.Jacob Andreas, Marcus Rohrbach, Trevor Darrell, andDan Klein.
2016b.
Learning to compose neural net-works for question answering.
In NAACL.Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Mar-garet Mitchell, Dhruv Batra, C. Lawrence Zitnick, andDevi Parikh.
2015.
VQA: Visual question answer-ing.
In International Conference on Computer Vision(ICCV).Yoav Artzi and Luke Zettlemoyer.
2013.
Weakly su-pervised learning of semantic parsers for mapping in-structions to actions.
Transactions of the Associationfor Computational Linguistics.Jonathan Berant, Andrew Chou, Roy Frostig, and PercyLiang.
2013.
Semantic parsing on Freebase fromquestion-answer pairs.
In Proceedings of the 2013Conference on Empirical Methods in Natural Lan-guage Processing.Jonathan Berant, Vivek Srikumar, Pei-Chun Chen,Abby Vander Linden, Brittany Harding, Brad Huang,Peter Clark, and Christopher D. Manning.
2014.Modeling biological processes for reading comprehen-sion.
In Proceedings of EMNLP.David L. Chen and Raymond J. Mooney.
2011.
Learn-ing to interpret natural language navigation instruc-tions from observations.
In Proceedings of the 25thAAAI Conference on Artificial Intelligence.Eunsol Choi, Tom Kwiatkowski, and Luke Zettlemoyer.2015.
Scalable semantic parsing with partial ontolo-gies.
In Proceedings of the 2015 Association for Com-putational Linguistics.Stephen Clark and James R. Curran.
2007.
Wide-coverage efficient statistical parsing with CCG andlog-linear models.
Computational Linguistics,33(4):493?552.Peter Clark and Oren Etzioni.
2016.
My computer is anhonor student - but how intelligent is it?
standardizedtests as a measure of ai.
AI Magazine, 37:5?12.Akira Fukui, Dong Huk Park, Daylen Yang, AnnaRohrbach, Trevor Darrell, and Marcus Rohrbach.2016.
Multimodal compact bilinear pooling forvisual question answering and visual grounding.arXiv:1606.01847.Noah D Goodman and Andreas Stuhlmu?ller.
2014.
TheDesign and Implementation of Probabilistic Program-ming Languages.
http://dippl.org.
Accessed: 2016-2-25.Noah D. Goodman, Vikash K. Mansinghka, Daniel M.Roy, Keith Bonawitz, and Joshua B. Tenenbaum.2008.
Church: A language for generative models.
InUncertainty in Artificial Intelligence.Sepp Hochreiter and Ju?rgen Schmidhuber.
1997.
Longshort-term memory.
Neural computation, 9(8):1735?1780.Thomas M. Howard, Istvan Chung, Oron Propp,Matthew R. Walter, and Nicholas Roy.
2014a.
Effi-cient natural language interfaces for assistive robots.In IEEE/RSJ International Conference on IntelligentRobots and Systems (IROS) Workshop on Rehabilita-tion and Assistive Robotics, September.Thomas M Howard, Stefanie Tellex, and Nicholas Roy.2014b.
A natural language planner interface for mo-bile manipulators.
In 2014 IEEE International Con-ference on Robotics and Automation (ICRA).Aniruddha Kembhavi, Mike Salvato, Eric Kolve,Min Joon Seo, Hannaneh Hajishirzi, and Ali Farhadi.2016.
A diagram is worth a dozen images.
In Euro-pean Conference on Computer Vision (ECCV).Thomas Kollar, Stefanie Tellex, Deb Roy, and NicholasRoy.
2010.
Toward understanding natural languagedirections.
In Proceedings of the 5th ACM/IEEE In-ternational Conference on Human-Robot Interaction.Jayant Krishnamurthy and Thomas Kollar.
2013.
Jointlylearning to parse and perceive: Connecting natural lan-guage to the physical world.
Transactions of the Asso-ciation of Computational Linguistics ?
Volume 1.Jayant Krishnamurthy and Tom M. Mitchell.
2012.Weakly supervised training of semantic parsers.
InProceedings of the 2012 Joint Conference on Empir-ical Methods in Natural Language Processing andComputational Natural Language Learning.Jayant Krishnamurthy and Tom M. Mitchell.
2015.Learning a compositional semantics for freebase withan open predicate vocabulary.
Transactions of the As-sociation for Computational Linguistics, 3:257?270.Jayant Krishnamurthy.
2016.
Probabilistic models forlearning a semantic parser lexicon.
In NAACL.Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and LukeZettlemoyer.
2013.
Scaling semantic parsers withon-the-fly ontology matching.
In Proceedings of the2013 Conference on Empirical Methods in NaturalLanguage Processing.Percy Liang, Michael I. Jordan, and Dan Klein.
2011.Learning dependency-based compositional semantics.In Proceedings of the Association for ComputationalLinguistics.Mateusz Malinowski and Mario Fritz.
2014.
A multi-world approach to question answering about real-world scenes based on uncertain input.
In Advancesin Neural Information Processing Systems.Mateusz Malinowski, Marcus Rohrbach, and Mario Fritz.2015.
Ask your neurons: A neural-based approach to169answering questions about images.
In InternationalConference on Computer Vision.Cynthia Matuszek, Nicholas FitzGerald, Luke Zettle-moyer, Liefeng Bo, and Dieter Fox.
2012.
A jointmodel of language and perception for grounded at-tribute learning.
In Proceedings of the 29th Interna-tional Conference on Machine Learning.John McCarthy.
1963.
A basis for a mathematical the-ory of computation.
In Computer Programming andFormal Systems.Joakim Nivre, Johan Hall, and Jens Nilsson.
2006.
Malt-parser: A data-driven parser-generator for dependencyparsing.
In Proceedings of the 21st International Con-ference on Computational Linguistics and 44th AnnualMeeting of the Association for Computational Linguis-tics.Siva Reddy, Mirella Lapata, and Mark Steedman.
2014.Large-scale semantic parsing without question-answerpairs.
Transactions of the Association for Computa-tional Linguistics.Minjoon Seo, Hannaneh Hajishirzi, Ali Farhadi, Oren Et-zioni, and Clint Malcolm.
2015.
Solving geometryproblems: Combining text and diagram interpretation.In Proceedings of the 2015 Conference on EmpiricalMethods in Natural Language Processing.Karen Simonyan and Andrew Zisserman.
2014.
Verydeep convolutional networks for large-scale imagerecognition.
CoRR, abs/1409.1556.Stefanie Tellex, Thomas Kollar, Steven Dickerson,Matthew Walter, Ashis Banerjee, Seth Teller, andNicholas Roy.
2011.
Understanding natural languagecommands for robotic navigation and mobile manipu-lation.
In AAAI Conference on Artificial Intelligence.Kun Xu, Siva Reddy, Yansong Feng, Songfang Huang,and Dongyan Zhao.
2016.
Question Answeringon Freebase via Relation Extraction and Textual Ev-idence.
In Proceedings of the Association for Compu-tational Linguistics (ACL 2016).Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, andAlexander J. Smola.
2015.
Stacked attention net-works for image question answering.
arXiv preprintarXiv:1511.02274.Wen-tau Yih, Ming-Wei Chang, Xiaodong He, and Jian-feng Gao.
2015.
Semantic parsing via staged querygraph generation: Question answering with knowl-edge base.
In Proceedings of the 53rd Annual Meet-ing of the Association for Computational Linguisticsand the 7th International Joint Conference on NaturalLanguage Processing (Volume 1: Long Papers).John M. Zelle and Raymond J. Mooney.
1993.
Learningsemantic grammars with constructive inductive logicprogramming.
In Proceedings of the 11th NationalConference on Artificial Intelligence.Luke S. Zettlemoyer and Michael Collins.
2005.
Learn-ing to map sentences to logical form: structured clas-sification with probabilistic categorial grammars.
InUAI ?05, Proceedings of the 21st Conference in Un-certainty in Artificial Intelligence.170
