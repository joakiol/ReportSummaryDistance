Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 766?776, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsCross-Lingual Language Modeling with Syntactic Reordering forLow-Resource Speech RecognitionPing Xu and Pascale FungHuman Language Technology CenterDepartment of Electronic and Computer EngineeringThe Hong Kong University of Science and Technology, Clear Water Bay, Hong Kongxuping@ust.hk, pascale@ece.ust.hkAbstractThis paper proposes cross-lingual languagemodeling for transcribing source resource-poor languages and translating them into tar-get resource-rich languages if necessary.
Ourfocus is to improve the speech recognitionperformance of low-resource languages byleveraging the language model statistics fromresource-rich languages.
The most challeng-ing work of cross-lingual language modelingis to solve the syntactic discrepancies betweenthe source and target languages.
We thereforepropose syntactic reordering for cross-linguallanguage modeling, and present a first resultthat compares inversion transduction grammar(ITG) reordering constraints to IBM and lo-cal constraints in an integrated speech tran-scription and translation system.
Evaluationson resource-poor Cantonese speech transcrip-tion and Cantonese to resource-rich Mandarintranslation tasks show that our proposed ap-proach improves the system performance sig-nificantly, up to 3.4% relative WER reductionin Cantonese transcription and 13.3% relativebilingual evaluation understudy (BLEU) scoreimprovement in Mandarin transcription com-pared with the system without reordering.1 IntroductionStatistical language modeling techniques haveachieved remarkable success in speech and languageprocessing (Clarkson and Rosenfeld, 1997; Stolcke,2002).
However, this success largely depends on theavailability of a large amount of suitable text data ina language.
Without sufficient text data for training,it is very difficult to build a practical and usable sta-tistical language model.
Therefore, most of the ad-vances have been reported in so called resource-richlanguage such as English, Mandarin and Japanese,after creating linguistic resources of these languagesat considerable cost.
Today there are more than6000 living languages spoken in the world (Gordonet al2005), and most of them have little transcribedtexts and are considered as resource-poor languages(Nakov and Ng, 2009).
Many of these languages areactually spoken by a huge number of speakers (e.g.some Chinese and Indian languages), and thus thereis still a great demand to build speech and languageprocessing systems for these languages.Owing to data scarcity, most often an interpo-lation (Bellegarda, 2004) of language models be-tween a resource-poor language and a resource-richlanguage is used in most low-resource ASR sys-tems.
Some researchers have proposed transform-ing resource-rich language models to resource-poorlanguage models by word-level transduction, eitherin a context-independent or context-dependent man-ner (Hori et al2003; Akita and Kawahara, 2006;Jensson et al2009; Neubig et al2010).
In (Jens-son et al2009), a simple dictionary based context-independent transduction from a resource-rich lan-guage to a resource-poor language is exploited toimprove speech recognition of the resource-poorlanguage.
In (Hori et al2003; Akita and Kawahara,2006; Neubig et al2010), context-dependent trans-duction is exploited.
In their case, the resource-poorlanguage is a spoken language, and the resource-richlanguage is a written language.
They carried out lan-guage model transformation since the input speech766is in speaking-style and the output text is in written-style.Others have investigated cross-lingual informa-tion between a resource-poor language and aresource-rich language.
In (Khudanpur and Kim,2002), cross-language cues are used to improve alanguage model of a resource-poor language.
Theyused cross-lingual unigram probabilities trainedfrom a story-specific parallel corpus of the resource-poor and resource-rich languages.
They interpo-late the language model of the resource-poor lan-guage with those unigram probabilities.
In (Kim andKhudanpur, 2003), an n-gram language model in aresource-poor language is interpolated with cross-lingual unigram trigger probabilities.
These triggersare word pairs of the resource-poor and resource-rich languages with the highest mutual informationacross these two languages.
Another way of esti-mating those unigram probabilities is using latentsemantic analysis by measuring cosine similaritiesfrom a document-aligned corpus for any given wordpair (Kim and Khudanpur, 2004).Both interpolation and word-level transductionapproaches fail to meet the challenge of syntac-tic discrepancies between the resource-poor andresource-rich languages.
This syntactic discrepan-cies exist, for example, even between the Sinitic lan-guages and Indian languages1 of the same family.Sinitic languages such as Cantonese/Yue, Shang-hai/Wu, etc.
are officially considered as ?dialects?of the standard Chinese Mandarin (or Putonghua)2.However, they differ greatly from Mandarin in allaspects and are not mutually comprehensible.
Forinstance, in addition to lexical and pronunciationdifferences, Cantonese Chinese (Lee, 2011) differssyntactically from Mandarin as well - we found thatthere are approximately 10% syntactic inversionsbetween sentences of the two forms of Chinese.We suggest that a better approach than interpo-lation and word-level transduction is to use cross-lingual language modeling with syntactic reorder-1For example, Hindi and Malayalam (Geethakumary, 2002).2Since Cantonese does not have an official written form,there are very few written texts available for training languagemodels.
In this paper, we treat Cantonese as a typical resource-poor language and Mandarin as a typical resource-rich lan-guage.
This language pair will be used for illustration purposesthroughout this paper.ing.
A reordering model with reordering constraints,such as ITG constraints (Wu, 1997), IBM con-straints (Berger et al1996), and local constraints(Kumar and Byrne, 2005) can account for the syn-tactic differences.
It has been shown in (Zens andNey, 2003; Kanthak et al2005; Dreyer et al2007)that ITG constraints perform better than other con-straints when tackling the reordering between manylanguage pairs.
Previous work on weighted finite-state transducer (WFST) based speech translationsuch as (Casacuberta et al2004; Zhou et al2005;Zhou et al2006; Mathias and Byrne, 2006; Ma-tusov et al2006; Saon and Picheny, 2007) onlytrain the reordering model using IBM constraints,local constraints or ad hoc rules.
We will useITG constraints, which have only been applied totext translation tasks before, to model the syntacticdifferences in cross-lingual language modeling forspeech recognition.We will implement a cross-lingual languagemodel using WFSTs, and integrate it into a WFST-based speech recognition search space to give bothresource-poor language and resource-rich languagetranscriptions.
This creates an integrated speechtranscription and translation framework.This paper is organized as follows: Section 2presents our proposed cross-lingual language mod-eling with syntactic reordering.
In Section 3, we dis-cuss speech recognition with cross-lingual languagemodels.
Section 4 and 5 give the experimental setupand results.
We conclude our work at the end of thispaper.2 Cross-lingual Language Modeling withSyntactic ReorderingIn automatic speech recognition (ASR), given an ob-served source speech vector X, the decoding pro-cess searches the best word sequence v?I1 (consistsof words v1, v2, ..., vI ) by maximizing the posteriorprobability P (vI1 |X), where vI1 is the source tran-script representing the transcription of the sourcespeech (see Eq.
(1)).
According to Bayes?
law,we can decompose P (vI1 |X) into an acoustic modelP (X|vI1) and a language model P (vI1).
If a sourcelanguage Lv is a resource-rich language, then thelanguage model P (vI1) can be well estimated fromsufficient training texts.
However, if the source lan-767guage Lv is a resource-poor language, then the lan-guage model P (vI1) cannot be reliably or robustlyestimated due to lack of training texts.v?I1 = argmaxvI1P (vI1 |X) (1)= argmaxvI1P (X|vI1)P (vI1)= argmaxvI1P (X|vI1)?wJ1P (vI1 |wJ1 )P (wJ1 )?
argmaxvI1P (X|vI1)maxwJ1P (vI1 |wJ1 )P (wJ1 )Since this paper tackles the language modelingchallenge for low-resource speech recognition, herewe just assume that the source language Lv is aresource-poor language.
We further assume thatthere is a target language Lw, which is a resource-rich language closely related to the language Lv.In order to improve the language model P (vI1)of the resource-poor language Lv, we introducecross-lingual language modeling by decomposingthe language model P (vI1) into a translation modelP (vI1 |wJ1 ) and a language model P (wJ1 ) of theresource-rich language Lw (see Eq.
(1)).
wJ1 isthe target resource-rich language transcript that con-sists of words w1, w2, ..., wJ .
P (vI1 |wJ1 )P (wJ1 ) isdefined as a cross-lingual language model.
It lever-ages the abundant statistics from the language modelP (wJ1 ) to improve the language model P (vI1) of theresource-poor language.The translation model P (vI1 |wJ1 ) can be esti-mated by addressing the discrepancies between theresource-poor language Lv and the resource-richlanguage Lw, which can be modeled from a paral-lel corpus of the Lv transcript vI1 and the Lw tran-script wJ1 .
For the syntactic inversions, we reorderthe word or phrase positions of the Lw languagemodel into those of the Lv language model.
Wehave observed that most of the words are alignedmonotonically between Lv and Lw within a phrase.This paper, therefore only considers phrase-level re-ordering, which effectively preserves the monotonicword sequences within phrases, and significantly re-duces the number of reordering paths compared withword-level reordering.2.1 Preprocessing: Phrase Extraction andSegmentationOur discussion starts with phrase extraction from theparallel corpus.
We define a phrase sequence v?K1(consists of phrases v?1, v?2, ..., v?K ) segmented fromthe word-level Lv transcript vI1 and w?K1 (consists ofphrases w?1, w?2, ..., w?K ) segmented from the word-level Lw transcript wJ1 .
Furthermore, we define areordering sequence rK1 , of which the detail can befound in Section 2.2.The phrase-level translation model P (vI1 |wJ1 ) isdecomposed into four components (see Eq.
(2)):segmentation model P (w?K1 |wJ1 ), phrasal reorder-ing model P (rK1 |w?K1 , wJ1 ), phrase-to-phrase trans-duction model P (v?K1 |rK1 , w?K1 , wJ1 ) and reconstruc-tion model P (vI1 |v?K1 , rK1 , w?K1 , wJ1 ).
Before present-ing each component model, we need to extract twophrase tables for the Lv transcript and the Lw tran-script, respectively.P (vI1 |wJ1 ) ?
maxv?K1 ,rK1 ,w?K1P (w?K1 |wJ1 ) ?P (rK1 |w?K1 , wJ1 ) ?P (v?K1 |rK1 , w?K1 , wJ1 ) ?P (vI1 |v?K1 , rK1 , w?K1 , wJ1 ) (2)The phrase extraction is based on word-to-wordalignments of the parallel corpus.
We train wordalignments in both directions with GIZA++, andthen symmetrize the two alignments using the re-fined method (Och and Ney, 2003).
Figure 1 showsan example of word-to-word alignment results be-tween an Lv transcript (Cantonese) and an Lwtranscript (Mandarin), from which phrase-to-phrasealignments are derived by identifying deletion, sub-stitution, insertion and inversion.Prior to phrasal reordering, the segmentationmodel P (w?K1 |wJ1 ) implemented by a segmentationWFST Sw is applied to segment a word sequencewJ1 in the Lw language model into a phrase sequence{w?1, w?2, ..., w?K}.
The maximum number of wordsthat can be segmented into one phrase is controlledby a segmentation order s. An example of Sw isshown in Figure 3(a1).
It segments a word sequence{w1, w2, w3} into a phrase sequence {w1, w2 w3}after performing composition (Mohri, 2009) with thetarget Lw language model (see Figure 3(b1 & b2))3.3The ?
?
symbol is used to indicate the concatenation of con-768DeletionSubstitution Inversion Inversion & Insertioniivji'~kvkw~jwj4-64-71 21-1 2-2???
?k?=133-4?k?=24?k?=355-8?
?k?=466-5?k?=57 87-3 8-3?
?k?=6??k=121?k=23?k=34?k=45?
?k=56 7?
?k=68Substitution SubstitutionFigure 1: An example (in English: Please give me an ad-dress first) of phrase extraction from word-to-word align-ments.
i and j are word indexes.
k?
and k are phraseindexes.
i?j represents the word-to-word alignment.k?k?
represents the indentified phrase-to-phrase align-ment.2.2 Phrasal Reordering ModelGiven a phrase sequence {w?1, w?2, ..., w?K} of theLw transcript, the role of the reordering modelP (rK1 |w?K1 , wJ1 ) is to reorder phrase positions of theLw transcript into those of the Lv transcript by per-mutation of w?K1 according to a reordering sequence{rK1 : rk ?
{1, 2, ...,K}, rk 6= rk?
6=k}.
Thephrase sequence {w?1, w?2, ..., w?K} is therefore re-ordered into {w?r1 , w?r2 , ..., w?rK } consequently (seeFigure 2 where K = 3).
Since arbitrary permuta-tions of K phrases are NP-hard (Knight, 1999), re-ordering constraints have to be set over rK1 to reducethe number of permutations.There are three reordering constraints widely usedin statistical machine translation, namely local con-straints, IBM constraints and ITG constraints.
Herewe would like to point out that this is the firsttime that reordering constraints have been incorpo-rated into a cross-lingual language model for speechrecognition.Reordering ConstraintsLocal constraints make the restriction that onephrase can jump at most L?1 phrases either forwardor backward, where L is the reordering distance (orwindow size of permutation)4 .
The generation of rK1under local constraints can be viewed as solving ofthe following problem (Kl?ve, 2009):secutive words forming a phrase.4The concept of reordering distance also applies to otherconstraints.How many permutations of{1, 2, .
.
.
k .
.
.
,K} satisfy |rk ?
k| < Lfor all k?IBM constraints, a superset of local constraints(Dreyer et al2007), generate permutations rK1 de-viate from the monotonic phrase order {rK1 : rk =k}.
More specifically, any phrase position rk can beselected from the positions of the first m yet uncov-ered phrases (see Eq.
(3)).
A typical value of m is 4(Zens and Ney, 2003), and we write IBM constraintswith m = 4 as IBM(4).rk ????????????
{1, 2, ..., k ?
1 +m; rk 6= rk?
6=k}if k ?
K + 1?m,{1, 2, ...,K; rk 6= rk?
6=k}if K + 1?m < k ?
K.(3)ITG constraints provide a more faithful coverageof syntactic reordering in the parallel data than lo-cal constraints and IBM constraints.
Our presenta-tion of ITG constraints starts with defining of somepermutation sets.
Let SK be the set of permuta-tions on {1,2,. .
.
,K}.
A permutation rK1 ?
SK ,where rK1 = r1r2 .
.
.
rK , contains a subsequenceof type ?
?
SM if and only if a sequence of in-dices 1 ?
i1 < i2 < .
.
.
< iM ?
K exists suchthat ri1ri2 .
.
.
riM has all the same pairwise compar-isons as ?
.
We denote the set of permutations of SKnot containing subsequences of type ?
by SK(?).
Ifwe have sets SK(?1), .
.
.
, SK(?p), we denote the setSK(?1)?
.
.
.
?SK(?p) by SK(?1, .
.
.
, ?p) (Barcucciet al2000).
ITG constraints allow the permutationset SK(3142, 2413), which forbids subsequence oftype (3, 1, 4, 2) and its dual (2, 4, 1, 3).
Explicitly,ITG constraints avoid any permutation rK1 satisfy-ing either ri2 < ri4 < ri1 < ri3 or ri3 < ri1 <ri4 < ri2 , where 1 ?
i1 < i2 < i3 < i4 ?
K .
In(Wu, 1997), these forbidden subsequences are called?inside-out?
transpositions.
They are fairly distortedmatchings, and hardly observed in real parallel data.In order to get an intuitive sense of the reorderingcapability of those three constraints, we list the num-ber of permutations under local constraints, IBMconstraints as well as ITG constraints5 in Table 1.5Interestingly, when K = L, the number of permuta-tions under ITG constraints NITG = |SK(3142, 2413)|, and|SK(3142, 2413)| equals the K?1-th Schro?der numbers sK?1(Ehrenfeucht et al1998)769Table 1: Comparison of permutation number under local constraints (NLocal), IBM constraints (NIBM(4)) and ITGconstraints (NITG).
The comparison is constrained by the phrase number K and the reordering distance L.K=2 K=3 K=4 K=5 K=6 K=7 K=8 K=9 K=10NLocal 2 3 5 8 13 21 34 55 89L=2 NIBM(4) 2 3 5 8 13 21 34 55 89NITG 2 3 5 8 13 21 34 55 89NLocal 2 6 14 31 73 172 400 932 2177L=3 NIBM(4) 2 6 14 31 73 172 400 932 2177NITG 2 6 12 25 57 124 268 588 1285NLocal 2 6 24 78 230 675 2069 6404 19708L=4 NIBM(4) 2 6 24 78 230 675 2069 6404 19708NITG 2 6 22 52 122 321 885 2304 5880NLocal 2 6 24 120 504 1902 6902 25231 95401L=5 NIBM(4) 2 6 24 96 330 1066 3451 11581 39264NITG 2 6 22 90 236 602 1714 5269 16385NLocal 2 6 24 120 720 3720 17304 76110 329462L=6 NIBM(4) 2 6 24 96 384 1374 4718 16275 57749NITG 2 6 22 90 394 1108 3014 9038 29618We can see that given the same K (K ?
10) andL (L ?
6), IBM constraints have less permutationsthan local constraints, and ITG constraints have lesspermutations than IBM constraints in general (onlyone exception when K = L = 6).
These obser-vations indicate that ITG constraints can filter outmore unlikely permutations for a fixed reorderingdistance, resulting in longer distance reordering ca-pability.Table 1 also tells us that the phrase number Kand the reordering distance L for any of the con-straints cannot be too large for practical implemen-tation.
For instance, if L = 6 and K goes from 6 to7, the order of magnitude of NLocal, NIBM(4) andNITG increases from 2 to 3.
Hence, phrases for per-mutation should be selective to cover the most pos-sible re-orderings.
If long reordering distances areallowed, unlikely permutations should be pruned sothat the memory consumption becomes manageable.Reordering Sequence DistributionSo far we have discussed the issue that how togenerate permutations for the reordering model us-ing reordering constraints.
Another issue is how toparameterize the reordering sequence distribution.Both ITG constraints and other constraints assumethat all permutations are equally probable.
However,it makes sense to restrict those non-monotonic re-orderings when performing the translation.
This notonly helps the search of the most likely permutation,but also guides the pruning of unlikely permutations.P (rK1 |w?K1 , wJ1 ) = P (r1)K?k=2P (rk|rk?1, w?K1 )= P (r1)K?k=2P (rk|rk?1) (4)We make a first order Markov assumption over thephrasal reordering model P (rK1 |w?K1 , wJ1 ) (see Eq.(4)).
The reordering sequence distribution is param-eterized to assign decreasing likelihood to phrase re-orderings {w?r1 , w?r2 , .
.
.
, w?rK} that diverge from theoriginal word order (Och et al1999; Kumar et al2005).
Suppose w?rk = wl?l and w?rk?1 = wq?q , thereordering sequence distribution is set as Eq.
(5),where p0 is a tuning factor.
We normalize the proba-bilities P (rk|rk?1) such that?Kk?=1,k?
6=rk?1 P (rk =k?|rk?1) = 1.P (rk|rk?1) = p|l?q?
?1|0P (r1 = k) =1K ; k ?
{1, 2, ...,K}(5)770Assume that we have a phrase sequence{w?1, w?2, w?3}, Figure 2 shows the phrasal reorderingmodel implemented by a reordering WFST ?r underthe first order Markov assumption for this phrase se-quence.Figure 3(a2) gives one more example of ?r,which reorders the phrase sequence {w1, w2 w3}into {w2 w3, w1}6.
Within the WFST paradigm, re-ordering models under any of those constraints canbe integrated into the cross-lingual language model.
)(/~:~ 111 rPwwr )|(/~:~ 1222 rrPwwr )|(/~:~ 2333 rrPwwrFigure 2: An example of reordering WFST ?r imple-menting the phrasal reordering model under the first or-der Markov assumption.2.3 Phrase-to-Phrase Transduction ModelOnce the phrase sequence of the Lw transcriptis reordered into the Lv transcript order, we usethe phrase-to-phrase transduction model specified inEq.
(6) to perform the cross-language transduction.Given sufficient parallel training data, the context-dependent phrase-to-phrase transduction model canbe estimated using the GIATI method (Casacu-berta and Vidal, 2004).
However, for the trans-lation task with scarce training data, the context-dependent transduction probabilities may not be re-liably estimated.
Therefore, we assume that a phrasev?k is generated independently by each phrase w?rk .C(v?k, w?rk) is the number of times that phrase v?k isaligned to w?rk in the parallel corpus.
This model canbe implemented by a WFST Tvw which transducesv?k to w?rk .
Figure 3(a3) shows an example of Tvwtransducing v2 v3 to w2 w3.P (v?K1 |rK1 , w?K1 , wJ1 ) = P (v?K1 |rK1 , w?K1 )=K?k=1Pk(v?k|w?rk)=K?k=1C(v?k, w?rk)?v?kC(v?k, w?rk)(6)2.4 Reconstruction ModelReconstruction model P (vI1 |v?K1 , rK1 , w?K1 , wJ1 ) oper-ates in the opposite direction as the segmentation6For simplicity, reordering sequence distributions are notshown there.model.
It generates a word sequence vI1 from aphrase sequence v?K1 .
The reconstruction model canbe implemented by a WFST Rv.
An example ofRv is shown in Figure 3(a4), which reconstructs aphrase v2 v3 into a word sequence {v2, v3}.3 Speech Recognition with Cross-LingualLanguage ModelsThe translation model P (vI1 |wJ1 ) can be constructedvia WFST composition (denoted by ?)
(Mohri,2009) of all the component models as shown in Eq.
(7) and Figure 3, where T is the final composedWFST that transduces vI1 to wJ1 .T = Rv ?
Tvw ?
?r ?
Sw (7)The cross-lingual language model Gcl is con-structed through composition (see Eq.
(8)) ofthe translation model and a resource-rich languagemodel G.Gcl = T ?G = Rv ?
Tvw ?
?r ?
Sw ?G (8)As the way of integrating a resource-rich lan-guage model G into ASR search space (Mohri et al2008), we can integrate the cross-lingual languagemodel Gcl into ASR search space in a globally op-timized way as well.
The search space can be im-plemented using a transducer ASR, which is for-mulated with a unified WFST approach as shownin Eq.
(9).
Here H transduces HMM states tocontext-dependent phones.
C represents a trans-duction from context-dependent phones to context-independent phones.
L is a lexicon transducer whichmaps context-independent phone sequences to wordstrings restricted to the input symbols of the cross-lingual language model transducer Gcl.ASR = H ?
C ?
L ?Gcl (9)Eq.
(9) outputs the recognition result in a resource-rich language.
If recognition system requires recog-nition outputs in a resource-poor language, then thesearch space should be constructed as Eq.
(10),where ?
is a projection (Mohri, 2009) operatorwhich projects the input label to the output label.Before decoding, the recognition transducer ASRcan be optimized by a determinization operationright after each composition.ASR = H ?
C ?
L ?
?
(Gcl) (10)771    (a1) Segmentation WFST Sw (b1) Written-style language model G0 1w 1 : w 12w 2 : w 23w 2 _ w 3 : w 2 4w 3 : w 3- :w3(a2) Reordering WFST ?r (b2) Sw ?G				(a3) Phrase-to-phrase transduction WFST Tvw (b3) ?r ?
Sw ?G 		01w 1 : w 12v2_v3:w13w 1 _ # 1 : w 14v2_v3:w2w 1 : w 2v 2 _ v 3 _ # 1 : w 25w 2 : w 26- :w3w 3 : w 3(a4) Reconstruction WFST Rv (b4) Tvw ?
?r ?
Sw ?G 	(b5) Rv ?
Tvw ?
?r ?
Sw ?GFigure 3: Illustration of constructing a cross-lingual language model via WFSTs: a word sequence {w1, w2, w3}represented by the Lw language model G (b1) is segmented into a phrase sequence {w1, w2 w3} (b2); {w1, w2 w3} isreordered into {w2 w3, w1} (b3); phrase w2 w3 is transduced to v2 v3 (b4); phrase v2 v3 is reconstructed into a wordsequence {v2, v3} (b5).
wk and vk represent wk and vk, respectively.
?-?
refers to ?
or null symbol.
Auxiliary symbols#1,#2, ?
?
?
are used to make the WFST determinizable (Mohri, 2009) such that the transducer can be optimized by adeterminization (Mohri, 2009) operation which significantly reduces the search network size.7724 Experimental Setup4.1 Corpus and Model TrainingTo investigate the performance of our proposedcross-lingual language models, we have chosenCantonese as a resource-poor language and Man-darin as a resource-rich language.
We have col-lected Cantonese parliamentary speech from theHong Kong Legislative Council.
Currently we onlyhave 4152 parallel transcribed sentences containing19.4 hours of speech.
It is separated into three sets,a training set (11.9 hours, 2700 sentences), a de-velopment set (3.7 hours, 788 sentences), and anevaluation set (3.8 hours, 664 sentences).
The sen-tences in the evaluation set are a bit longer thanthose in the development set.
The parallel transcrip-tions of the training set constitute a parallel cor-pus, which includes Cantonese transcription (man-ual transcription) of 106k words and Mandarin tran-scription (Hansard7 transcription) of 80k words.
Thestatistics of substitutions, insertions, deletions andinversions identified in the parallel corpus are shownin Table 2.
Besides the parallel corpus, we have aset of additional Mandarin transcriptions, which has31M words.Table 2: No.
of substitutions, insertions, deletions andinversions identified in the parallel corpus with differentsegmentation order s.Segmentation Order s = 2 s = 3 s = 4 s = 5Substitutions 30921 22723 19011 17106Insertions 4657 3820 3641 3295Deletions 1365 1158 1066 1030Inversions 3000 2876 2814 2779Total 39943 30577 26532 24210The training set is used for training an acous-tic model (including H and C) using a MaximumLikelihood criterion.
It adopts 13 MFCC coeffi-cients, together with 13 delta coefficients and 13 ac-celeration coefficients as the acoustic features.
Theacoustic model comprises 73 Hidden Markov Mod-els (HMMs) to represent 70 Cantonese phonemes aswell as silence, short pause, and noise.
During theacoustic model training, tied-state cross-word tri-phones are constructed by decision tree clustering.7Hansard is a name of the printed transcripts of parliamen-tary debates.The parallel corpus is used for training the trans-lation model T .
Together with the parallel corpus,the additional Mandarin transcriptions are used fortraining an interpolated word-level trigram languagemodel G, where the lexicon size is about 28K.
Amodified scheme of Kneser-Ney discounting is ap-plied for the language model G with a back-offthreshold of 1 for unigram and 2 for bigram.
Thecross-lingual language model Gcl can be obtainedby composition of T and G.4.2 Decoding and Evaluation MethodDecoding of the speech recognition search spaceASR is performed by T 3 Decoder (Dixon etal., 2009), which is a state-of-the-art WFST-basedLVCSR speech decoder.
Decoding of ASR in Eq.
(9) gives Mandarin outputs.
Decoding of ASR inEq.
(10) gives Cantonese outputs.In our experiments, we use the following evalua-tion criteria:WER (word error rate).
The WER is computedas the minimum number of substitution, insertionand deletion operations that have to be performedto convert the generated sentence into the referencesentence (Zens et al2004).
The WER relates thespeech recognition accuracy.
The lower WER, thebetter.BLEU (bilingual evaluation understudy) score.The BLEU score measures the precision of n-grams(unigrams, bigrams, trigrams and fourgrams) withrespect to a reference translation with a penalty fortoo short sentences (Papineni et al2002).
TheBLEU score reflects the translation accuracy.
Thelarger BLEU score, the better.We perform WER evaluation of decoding out-puts of Eq.
(10) and BLEU score evaluation ofdecoding outputs of Eq.
(9) using the evaluationset.
The WER evaluation is on the Cantonese outputagainst the Cantonese reference transcription (man-ual transcription).
The BLEU score evaluation is onthe Mandarin output against the Mandarin referencetranscription (Hansard transcription).4.3 Parameter SettingsThe performance of our proposed cross-lingual lan-guage models is sensitive to many parameters.Firstly, segmentation order s affects phrase extrac-tion.
The optimal value depends on the language773Table 3: WER and BLEU score for decoding results of H ?
C ?
L ?G, H ?
C ?
L ?
?
(Gcl) without reordering, andH ?
C ?
L ?
?
(Gcl) with reordering under various constraints.Models H ?
C ?
L ?GH ?
C ?
L ?
?
(Gcl) H ?
C ?
L ?
?
(Gcl)Gcl = T3 ?G Gcl = T3 ?G,T3 = Rv ?
Tvw ?
?r ?
SwT3 = Rv ?
Tvw ?
Sw Local Constraints IBM Constraints ITG ConstraintsWER(%) 29.85 27.05 26.35 26.20 26.13BLEU N/A 29.23 32.29 32.81 33.12pair and the size of corpus.
Secondly, p0 in thefirst order Markov assumption affects the decodingresults.
Thirdly, the number of reordering permu-tations or paths are formidable when the reorder-ing distance L is long as suggested by Table 1.Therefore, we apply histogram pruning to reorder-ing paths, which only maintains top N most likelyones.
The development set is used for tuning param-eters p0 and N .5 Experimental ResultsThe evaluation results of the proposed cross-linguallanguage models Gcl with reordering under variousconstraints are presented in Table 3, where Gcl =Ts?G = T3?G.8 In general, reordering has a signif-icant effect on enhancing the performance of recog-nition and translation in the sense of WER reduc-tion and BLEU improvement.
Compared with thecross-lingual language model without reordering,the cross-lingual language model with reorderingunder local constraints gives 0.70% absolute WERreduction and 3.06 absolute BLEU improvement.The cross-lingual language model with reorderingunder IBM constraints gives 0.85% absolute WERreduction and 3.58 absolute BLEU improvement.The cross-lingual language model with reorderingunder ITG constraints yields the best performance,with 0.92% absolute WER reduction and 3.89 abso-lute BLEU improvement.
All WER improvementspointed out here are statistically significant at 99%confidence according to a two-proportional z-test,and all BLEU improvements are statistically signifi-cant at 95% confidence according to a paired studentt-test using bootstrap resampling.8We have chosen segmentation order s = 3 because it worksthe best in our system.6 ConclusionsWe have proposed cross-lingual language model-ing with phrase-level syntactic reordering for low-resource speech recognition.
The cross-lingual lan-guage modeling enriches a resource-poor languagemodel by leveraging the language model from aclosely related resource-rich language.
It providesan effective method to solve the low-resource lan-guage modeling challenge by using a large amountof resource-rich language (e.g.
Mandarin) dataand a small amount of resource-poor language (e.g.Cantonese) data, as well as some parallel data ofresource-poor and resource-rich languages.
Witha cross-lingual language model, our ASR systemcan decode speech into transcriptions, either in aresource-poor language or a resource-rich language,using a single WFST-based speech decoder.We have presented a first end-to-end WFSTsource to target language transcription and transla-tion system with syntactic reordering and global op-timization.
Our work is the first to use ITG con-straints for the syntactic reordering in such an in-tegrated system.
We also did comparative studyof ITG constraints, IBM constraints and local con-straints in the reordering model, for completeness.We have also presented the determinizable design ofeach transducer for composing a cross-lingual lan-guage model such that we can optimize the searchnetwork by determinization.
This is crucially im-portant to successfully build a practical integratedsystem, and, of course, the work is extremely chal-lenging.Experiments on Cantonese recognition and Can-tonese to Mandarin translation tasks have shown thatour proposed cross-lingual language model substan-tially improves the performance of the recognitionand translation.
The best system gives 12.5% rel-ative WER reduction in Cantonese (resource-poor774language) transcriptions over the system using inter-polation.
The best reordering model gives 3.4% rela-tive WER reduction and 13.3% relative BLEU scoreimprovement in Mandarin (resource-rich language)transcriptions over the system without reordering.The improvements have been found to be statisti-cally significant.Even though the objective of our work is forspeech recognition, our proposed cross-lingual lan-guage modeling can be easily applied to speechtranslation of other language pairs for efficient di-rect decoding from source speech to target text.7 AcknowledgmentsThis work is partially supported by ITS/189/09 andCERG#612211.
The authors would like to thank Dr.Tasuku Oonishi for providing access to the T 3 de-coder, and thank Prof. Sadaoki Furui and his teamfor useful discussions.
Thanks should go to Yue Yuand Percy Cheung for collecting the Cantonese andMandarin parallel data.
Thanks also go to RickyChan for training the Cantonese acoustic model andDr.
Markus Saers for helping on training the GIZAword-to-word alignment models.ReferencesY.
Akita and T. Kawahara.
2006.
Efficient estimationof language model statistics of spontaneous speech viastatistical transformation model.
In Proceedings of theIEEE International Conference on Acoustics, Speechand Signal Processing, volume 1, pages 1049?1052.E.
Barcucci, A. Del Lungo, E. Pergola, and R. Pinzani.2000.
Permutations avoiding an increasing numberof length-increasing forbidden subsequences.
Dis-crete Mathematics and Theoretical Computer Science,4(1):31?44.J.R.
Bellegarda.
2004.
Statistical language model adap-tation: review and perspectives.
Speech communica-tion, 42(1):93?108.A.L.
Berger, P.F.
Brown, S.A. Della Pietra, V.J.Della Pietra, A.S. Kehler, and R.L.
Mercer.
1996.Language translation apparatus and method us-ing context-based translation models.
US Patent5,510,981.F.
Casacuberta and E. Vidal.
2004.
Machine translationwith inferred stochastic finite-state transducers.
Com-putational Linguistics, 30(2):205?225.F.
Casacuberta, H. Ney, F.J. Och, et al004.
Some ap-proaches to statistical and finite-state speech-to-speechtranslation.
Computer Speech & Language, 18(1):25?47.P.
Clarkson and R. Rosenfeld.
1997.
Statistical lan-guage modeling using the cmu-cambridge toolkit.
In5th European Conference on Speech Communicationand Technology.P.R.
Dixon, T. Oonishi, K. Iwano, and S. Furui.
2009.Recent development of wfst-based speech recognitiondecoder.
In Proceedings of 2009 APSIPA Annual Sum-mit and Conference, pages 138?147, Sapporo, Japan.M.
Dreyer, K. Hall, and S. Khudanpur.
2007.
Compar-ing reordering constraints for smt using efficient bleuoracle computation.
In Proceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structurein Statistical Translation, pages 103?110, Rochester,New York.A.
Ehrenfeucht, T. Harju, P. Ten Pas, and G. Rozenberg.1998.
Permutations, parenthesis words, and schro?dernumbers.
Discrete mathematics, 190(1):259?264.V.
Geethakumary.
2002.
A contrastive analysis of hindiand malayalam.
Language in India.R.G.
Gordon, B.F. Grimes, and Summer Institute of Lin-guistics.
2005.
Ethnologue: Languages of the world,volume 15.
SIL International, Dallas TX, USA.T.
Hori, D. Willett, and Y. Minami.
2003.
Lan-guage model adaptation using wfst-based speaking-style translation.
In Proceedings of the IEEE Inter-national Conference on Acoustics, Speech and SignalProcessing, volume 1, pages 228?231.A.T.
Jensson, T. Oonishi, K. Iwano, and S. Furui.
2009.Development of a wfst based speech recognition sys-tem for a resource deficient language using machinetranslation.
In Proceedings of APSIPA ASC 2009:Asia-Pacific Signal and Information Processing Asso-ciation, 2009 Annual Summit and Conference, pages50?56.S.
Kanthak, D. Vilar, E. Matusov, R. Zens, and H. Ney.2005.
Novel reordering approaches in phrase-basedstatistical machine translation.
In Proceedings of theACL Workshop on Building and Using Parallel Texts,pages 167?174.
Association for Computational Lin-guistics.S.
Khudanpur and W. Kim.
2002.
Using cross-languagecues for story-specific language modeling.
In 7th In-ternational Conference on Spoken Language Process-ing.W.
Kim and S. Khudanpur.
2003.
Cross-lingual lexicaltriggers in statistical language modeling.
In Proceed-ings of the 2003 conference on Empirical methods innatural language processing, pages 17?24.
Associa-tion for Computational Linguistics.W.
Kim and S. Khudanpur.
2004.
Cross-lingual latentsemantic analysis for language modeling.
In Proceed-775ings of the IEEE International Conference on Acous-tics, Speech and Signal Processing, volume 1, pagesI257?I260.
IEEE.T.
Kl?ve.
2009.
Generating functions for the numberof permutations with limited displacement.
The Elec-tronic Journal of Combinatorics, 16(R104).K.
Knight.
1999.
Decoding complexity in word-replacement translation models.
Computational Lin-guistics, 25(4):607?615.S.
Kumar and W. Byrne.
2005.
Local phrase reorder-ing models for statistical machine translation.
InProceedings of Human Language Technology Confer-ence / Conference on Empirical Methods in NaturalLanguage Processing (HLT/EMNLP), pages 161?168,Vancouver, Canada.S.
Kumar, Y. Deng, and W. Byrne.
2005.
A weightedfinite state transducer translation template model forstatistical machine translation.
Natural Language En-gineering, 12(1):35?75.J.
Lee.
2011.
Toward a parallel corpus of spoken can-tonese and written chinese.
In Proceedings of the 5thInternational Joint Conference on Natural LanguageProcessing, pages 1462?1466, Chiang Mai, Thailand.L.
Mathias and W. Byrne.
2006.
Statistical phrase-basedspeech translation.
In Proceedings of the IEEE Inter-national Conference on Acoustics, Speech and SignalProcessing, volume 1, pages 561?564.E.
Matusov, S. Kanthak, and H. Ney.
2006.
Integratingspeech recognition and machine translation: Where dowe stand?
In Proceedings of the IEEE InternationalConference on Acoustics, Speech and Signal Process-ing, volume 5, pages V1217?V1220.
IEEE.M.
Mohri, F. C. N. Pereira, and M. Riley.
2008.Speech recognition with weighted finite-state trans-ducers.
Handbook on Speech Processing and SpeechCommunication, Part E: Speech Recognition.M.
Mohri.
2009.
Weighted automata algorithms.
Hand-book of Weighted Automata, pages 213?254.P.
Nakov and H.T.
Ng.
2009.
Improved statistical ma-chine translation for resource-poor languages using re-lated resource-rich languages.
In Proceedings of the2009 Conference on Empirical Methods in NaturalLanguage Processing, volume 3, pages 1358?1367.Association for Computational Linguistics.G.
Neubig, Y. Akita, S. Mori, and T. Kawahara.
2010.Improved statistical models for smt-based speakingstyle transformation.
In Proceedings of the IEEE In-ternational Conference on Acoustics, Speech and Sig-nal Processing, pages 5206?5209.F.J.
Och and H. Ney.
2003.
A systematic comparison ofvarious statistical alignment models.
ComputationalLinguistics, 29(1):19?51.F.J.
Och, C. Tillmann, and H. Ney.
1999.
Improvedalignment models for statistical machine translation.In Proceedings of the Joint SIGDAT Conf.
on EMNLPand VLC, pages 20?28, College Park, MD, USA.K.
Papineni, S. Roukos, T. Ward, and W.J.
Zhu.
2002.Bleu: a method for automatic evaluation of machinetranslation.
In Proceedings of the 40th annual meet-ing on association for computational linguistics, pages311?318.
Association for Computational Linguistics.G.
Saon and M. Picheny.
2007.
Lattice-based viterbidecoding techniques for speech translation.
In Au-tomatic Speech Recognition & Understanding, 2007.ASRU.
IEEE Workshop on, pages 386?389.
IEEE.A.
Stolcke.
2002.
Srilm-an extensible language model-ing toolkit.
In 7th International Conference on SpokenLanguage Processing.D.
Wu.
1997.
Stochastic inversion transduction gram-mars and bilingual parsing of parallel corpora.
Com-putational Linguistics, 23(3):377?403.R.
Zens and H. Ney.
2003.
A comparative study on re-ordering constraints in statistical machine translation.In Proceedings of the 41st Annual Meeting on Associ-ation for Computational Linguistics, pages 144?151,Sapporo, Japan.
Association for Computational Lin-guistics.R.
Zens, H. Ney, T. Watanabe, and E. Sumita.
2004.Reordering constraints for phrase-based statistical ma-chine translation.
In Proceedings of the 20th interna-tional conference on Computational Linguistics, pages205?211, Geneva, Switzerland.
Association for Com-putational Linguistics.B.
Zhou, S.F.
Chen, and Y. Gao.
2005.
Constrainedphrase-based translation using weighted finite-statetransducers.
In Proceedings of the IEEE InternationalConference on Acoustics, Speech and Signal Process-ing, volume 1, pages 1017?1020.B.
Zhou, S. F. Chen, and Y. Gao.
2006.
Folsom: A fastand memory-efficient phrase-based approach to statis-tical machine translation.
In Spoken Language Tech-nology Workshop, pages 226?229.
IEEE.776
