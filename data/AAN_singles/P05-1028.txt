Proceedings of the 43rd Annual Meeting of the ACL, pages 223?230,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsExploring and Exploiting the Limited Utility of Captions in RecognizingIntention in Information Graphics?Stephanie Elzer1 and Sandra Carberry2 and Daniel Chester2 and Seniz Demir2 andNancy Green3 and Ingrid Zukerman4 and Keith Trnka21Dept.
of Computer Science, Millersville University, Millersville, PA 175512Dept.
of Computer Science, University of Delaware, Newark, DE 197163Dept.
of Mathematical Sciences, Univ.
of NC at Greensboro, Greensboro, NC 274024School of CS & Software Engrg, Monash Univ., Clayton, Victoria 3800 AustraliaAbstractThis paper presents a corpus study that ex-plores the extent to which captions con-tribute to recognizing the intended mes-sage of an information graphic.
It thenpresents an implemented graphic interpre-tation system that takes into account a va-riety of communicative signals, and anevaluation study showing that evidenceobtained from shallow processing of thegraphic?s caption has a significant impacton the system?s success.
This work is partof a larger project whose goal is to providesight-impaired users with effective accessto information graphics.1 IntroductionLanguage research has posited that a speaker orwriter executes a speech act whose intended mean-ing he expects the listener to be able to deduce, andthat the listener identifies the intended meaning byreasoning about the observed signals and the mutualbeliefs of author and interpreter (Grice, 1969; Clark,1996).
But as noted by Clark (Clark, 1996), lan-guage is more than just words.
It is any ?signal?
(orlack of signal when one is expected), where a sig-nal is a deliberate action that is intended to convey amessage.Although some information graphics are only in-tended to display data values, the overwhelming ma-jority of the graphics that we have examined (taken?Authors can be reached via email as fol-lows: elzer@cs.millersville.edu, nlgreen@uncg.edu,{carberry, chester, demir, trnka}@cis.udel.edu, In-grid.Zukerman@infotech.monash.edu.au.1998 1999 2000 200110001500200025003000personal filingsLocal bankruptcyFigure 1: Graphic from a 2001 Local Newspaperfrom newspaper, magazine, and web articles) ap-pear to have some underlying goal or intended mes-sage, such as the graphic in Figure 1 whose com-municative goal is ostensibly to convey the sharp in-crease in local bankruptcies in the current year com-pared with the previous decreasing trend.
ApplyingClark?s view of language, it is reasonable to presumethat the author of an information graphic expects theviewer to deduce from the graphic the message thatthe graphic was intended to convey, by reasoningabout the graphic itself, the salience of entities inthe graphic, and the graphic?s caption.This paper adopts Clark?s view of language as anydeliberate signal that is intended to convey a mes-sage.
Section 3 investigates the kinds of signals usedin information graphics.
Section 4 presents a cor-pus study that investigates the extent to which cap-tions capture the message of the graphic, illustratesthe issues that would arise in trying to fully under-stand such captions, and proposes shallow process-ing of the caption to extract evidence from it.
Sec-tion 5 then describes how evidence obtained froma variety of communicative signals, including shal-low processing of the graphic?s caption, is used in aprobabilistic system for hypothesizing the intendedmessage of the graphic.
Section 6 presents an eval-223105150?680+ 65?79 7?19 35?4980+65?7950?6435?491051520?347?190?6 20?3450?64(a) (b)Figure 2: Two Alternative Graphs from the Same Datauation showing the system?s success, with particu-lar attention given to the impact of evidence fromshallow processing of the caption, and Section 7 dis-cusses future work.Although we believe that our findings are ex-tendible to other kinds of information graphics, ourcurrent work focuses on bar charts.
This research ispart of a larger project whose goal is a natural lan-guage system that will provide effective access toinformation graphics for individuals with sight im-pairments, by inferring the intended message under-lying the graphic, providing an initial summary ofthe graphic that includes the intended message alongwith notable features of the graphic, and then re-sponding to follow-up questions from the user.2 Related WorkOur work is related to efforts on graph summariza-tion.
(Yu et al, 2002) used pattern recognition tech-niques to summarize interesting features of automat-ically generated graphs of time-series data from agas turbine engine.
(Futrelle and Nikolakis, 1995)developed a constraint grammar for parsing vector-based visual displays and producing representationsof the elements comprising the display.
The goalof Futrelle?s project is to produce a graphic thatsummarizes one or more graphics from a document(Futrelle, 1999).
The summary graphic might be asimplification of a graphic or a merger of severalgraphics from the document, along with an appropri-ate summary caption.
Thus the end result of summa-rization will itself be a graphic.
The long range goalof our project, on the other hand, is to provide alter-native access to information graphics via an initialtextual summary followed by an interactive follow-up component for additional information.
The in-tended message of the graphic will be an importantcomponent of the initial summary, and hypothesiz-ing it is the goal of our current work.3 Evidence about the Intended MessageThe graphic designer has many alternative ways ofdesigning a graphic; different designs contain differ-ent communicative signals and thus convey differ-ent communicative intents.
For example, considerthe two graphics in Figure 2.
The graphic in Fig-ure 2a conveys that average doctor visits per yearis U-shaped by age; it starts out high when one isvery young, decreases into middle age, and thenrises again as one ages.
The graphic in Figure 2bpresents the same data; but instead of conveying atrend, this graphic seems to convey that the elderlyand the young have the highest number of doctor vis-its per year.
These graphics illustrate how choice ofdesign affects the message that the graphic conveys.Following the AutoBrief work (Kerpedjiev andRoth, 2000) (Green et al, 2004) on generatinggraphics that fulfill communicative goals, we hy-pothesize that the designer chooses a design that bestfacilitates the perceptual and cognitive tasks thatare most important to conveying his intended mes-sage, subject to the constraints imposed by compet-ing tasks.
By perceptual tasks we mean tasks thatcan be performed by simply viewing the graphic,such as finding the top of a bar in a bar chart; bycognitive tasks we mean tasks that are done via men-tal computations, such as computing the differencebetween two numbers.Thus one source of evidence about the intendedmessage is the relative difficulty of the perceptualtasks that the viewer would need to perform in orderto recognize the message.
For example, determining224the entity with maximum value in a bar chart will beeasiest if the bars are arranged in ascending or de-scending order of height.
We have constructed a setof rules, based on research by cognitive psycholo-gists, that estimate the relative difficulty of perform-ing different perceptual tasks; these rules have beenvalidated by eye-tracking experiments and are pre-sented in (Elzer et al, 2004).Another source of evidence is entities that havebeen made salient in the graphic by some kind of fo-cusing device, such as coloring some elements of thegraphic, annotations such as an asterisk, or an arrowpointing to a particular location in a graphic.
Enti-ties that have been made salient suggest particularinstantiations of perceptual tasks that the viewer isexpected to perform, such as comparing the heightsof two highlighted bars in a bar chart.And lastly, one would expect captions to help con-vey the intended message of an information graphic.The next section describes a corpus study that weperformed in order to explore the usefulness of cap-tions and how we might exploit evidence from them.4 A Corpus Study of CaptionsAlthough one might suggest relying almost ex-clusively on captions to interpret an informationgraphic, (Corio and Lapalme, 1999) found in a cor-pus study that captions are often very general.
Theobjective of their corpus study was to categorize thekinds of information in captions so that their find-ings could be used in forming rules for generatinggraphics with captions.Our project is instead concerned with recogniz-ing the intended message of an information graphic.To investigate how captions might be used in a sys-tem for understanding information graphics, we per-formed a corpus study in which we analyzed thefirst 100 bar charts from our corpus of informationgraphics; this corpus contains a variety of bar chartsfrom different publication venues.
The followingsubsections present the results of this corpus study.4.1 Do Captions Convey the IntendedMessage?Our first investigation explored the extent to whichcaptions capture the intended message of an infor-mation graphic.
We extracted the first 100 graphicsCategory #Category-1: Captures intention (mostly) 34Category-2: Captures intention (somewhat) 15Category-3: Hints at intention 7Category-4: No contribution to intention 44Figure 3: Analysis of 100 Captions on Bar Chartsfrom our corpus of bar charts.
The intended mes-sage of each bar chart had been previously annotatedby two coders.
The coders were asked to identify1) the intended message of the graphic using a listof 12 high-level intentions (see Section 5 for exam-ples) and 2) the instantiation of the parameters.
Forexample, if the coder classified the intended mes-sage of a graphic as Change-trend, the coder wasalso asked to identify where the first trend began,its general slope (increasing, decreasing, or stable),where the change in trend occurred, the end of thesecond trend, and the slope of the second trend.
Ifthere was disagreement between the coders on eitherthe intention or the instantiation of the parameters,we utilized consensus-based annotation (Ang et al,2002), in which the coders discussed the graphic totry to come to an agreement.
As observed by (Anget al, 2002), this allowed us to include the ?harder?or less obvious graphics in our study, thus loweringour expected system performance.
We then exam-ined the caption of each graphic, and determined towhat extent the caption captured the graphic?s in-tended message.
Figure 3 shows the results.
44%of the captions in our corpus did not convey to anyextent the message of the information graphic.
Thefollowing categorizes the purposes that these cap-tions served, along with an example of each:?
general heading (8 captions): ?UGI MonthlyGas Rates?
on a graphic conveying a recentspike in home heating bills.?
reference to dependent axis (15 captions):?Lancaster rainfall totals for July?
on agraphic conveying that July-02 was the driestof the previous decade.?
commentary relevant to graphic (4 captions):?Basic performers: One look at the best per-forming stocks in the Standard&Poor?s 500 in-dex this year shows that companies with ba-sic businesses are rewarding investors?
on a225graphic conveying the relative rank of differentstocks, some of which were basic businessesand some of which were not.
This type of in-formation was classified as deductive by (Corioand Lapalme, 1999) since it draws a conclusionfrom the data depicted in the graphic.?
commentary extending message of graphic (8captions): ?Profits are getting squeezed?
ona graphic conveying that Southwest Airlinesnet income is estimated to increase in 2003 af-ter falling the preceding three years.
Here thecommentary does not draw a conclusion fromthe data in the graphic but instead supplementsthe graphic?s message.
However this type ofcaption would probably fall into the deductiveclass in (Corio and Lapalme, 1999).?
humor (7 captions): ?The Sound of Sales?
ona graphic conveying the changing trend (down-ward after years of increase) in record albumsales.
This caption has nothing to do with thechange-trend message of the graphic, but ap-pears to be an attempt at humor.?
conclusion unwarranted by graphic (2 cap-tions): ?Defense spending declines?
on agraphic that in fact conveys that recent defensespending is increasing.Slightly over half the captions (56%) contributedto understanding the graphic?s intended message.34% were judged to convey most of the intendedmessage.
For example, the caption ?Tennis play-ers top nominees?
appeared on a graphic whose in-tended message is to convey that more tennis playerswere nominated for the 2003 Laureus World SportsAward than athletes from any other sport.
Since weargue that captions alone are insufficient for inter-preting information graphics, in the few cases whereit was unclear whether a caption should be placedin Category-1 or Category-2, we erred on the sideof over-rating the contribution of a caption to thegraphic?s intended message.
For example, considerthe caption ?Chirac is riding high in the polls?which appeared on a graphic conveying that therehas been a steady increase in Chirac?s approval rat-ings from 55% to about 75%.
Although this captiondoes not fully capture the communicative intentionof the graphic (since it does not capture the steadyincrease conveyed by the graphic), we placed it inthe first category since one might argue that ridinghigh in the polls would suggest both high and im-proving ratings.15% of the captions were judged to convey onlypart of the graphic?s intended message; an exampleis ?Drug spending for young outpace seniors?
thatappears on a graphic whose intended message ap-pears to be that there is a downward trend by age forincreased drug spending; we classified the captionin Category-2 since the caption fails to capture thatthe graphic is talking about percent increases in drugspending, not absolute drug spending, and that thegraphic conveys the downward trend for increases indrug spending by age group, not just that increasesfor the young were greater than for the elderly.7% of the captions were judged to only hint at thegraphic?s message.
An example is ?GM?s MoneyMachine?
which appeared on a graphic whose in-tended message was a contrast of recent perfor-mance against the previous trend ?
ie., that al-though there had been a steady decrease in the per-centage of GM?s overall income produced by its fi-nance unit, there was now a substantial increase inthe percentage provided by the finance unit.
Sincethe term money machine is a colloquialism that sug-gests making a lot of money, the caption was judgedto hint at the graphic?s intended message.4.2 Understanding CaptionsFor the 49 captions in Category 1 or 2 (where thecaption conveyed at least some of the message ofthe graphic), we examined how well the captioncould be parsed and understood by a natural lan-guage system.
We found that 47% were fragments(for example, ?A Growing Biotech Market?
), or in-volved some other kind of ill-formedness (for ex-ample, ?Running tops in sneaker wear in 2002?
or?More seek financial aid?1).
16% would require ex-tensive domain knowledge or analogical reasoningto understand.
One example is ?Chirac is ridinghigh in the polls?
which would require understand-ing the meaning of riding high in the polls.
Anotherexample is ?Bad Moon Rising?
; here the verb ris-ing suggests that something is increasing, but the1Here we judge the caption to be ill-formed due to the ellip-sis since More should be More students.226system would need to understand that a bad moonrefers to something undesirable (in this case, delin-quent loans).4.3 Simple Evidence from CaptionsAlthough our corpus analysis showed that captionscan be helpful in understanding the message con-veyed by an information graphic, it also showed thatfull understanding of a caption would be problem-atic; moreover, once the caption was understood, wewould still need to relate it to the information ex-tracted from the graphic itself, which appears to bea difficult problem.Thus we began investigating whether shallow pro-cessing of the caption might provide evidence thatcould be effectively combined with other evidenceobtained from the graphic itself.
Our analysis pro-vided the following observations:?
Verbs in a caption often suggest the kind ofmessage being conveyed by the graphic.
Anexample from our corpus is ?Boating deathsdecline?
; the verb decline suggests that thegraphic conveys a decreasing trend.
Anotherexample from our corpus is ?American Expresstotal billings still lag?
; the verb lag suggeststhat the graphic conveys that some entity (inthis case American Express) is ranked behindsome others.?
Adjectives in a caption also often suggest thekind of message being conveyed by the graphic.An example from our corpus is ?Air Force haslargest percentage of women?
; the adjectivelargest suggests that the graphic is conveyingan entity whose value is largest.
Adjectives de-rived from verbs function similarly to verbs.An example from our corpus is ?Soaring De-mand for Servers?
which is the caption on agraphic that conveys the rapid increase in de-mand for servers.
Here the adjective soaring isderived from the verb soar, and suggests thatthe graphic is conveying a strong increase.?
Nouns in a caption often refer to an entity thatis a label on the independent axis.
When thisoccurs, the caption brings the entity into focusand suggests that it is part of the intended mes-sage of the graphic.
An example from our cor-pus is ?Germans miss their marks?
where thegraphic displays a bar chart that is intended toconvey that Germans are the least happy withthe Euro.
Words that usually appear as verbs,but are used in the caption as a noun, may func-tion similarly to verbs.
An example is ?CableOn The Rise?
; in this caption, rise is used as anoun, but suggests that the graphic is conveyingan increase.5 Utilizing EvidenceWe developed and implemented a probabilisticframework for utilizing evidence from a graphic andits caption to hypothesize the graphic?s intendedmessage.
To identify the intended message of anew information graphic, the graphic is first givento a Visual Extraction Module (Chester and Elzer,2005) that is responsible for recognizing the indi-vidual components of a graphic, identifying the re-lationship of the components to one another and tothe graphic as a whole, and classifying the graphicas to type (bar chart, line graph, etc.
); the result isan XML file that describes the graphic and all of itscomponents.Next a Caption Processing Module analyzes thecaption.
To utilize verb-related evidence from cap-tions, we identified a set of verbs that would indicateeach category of high-level goal2, such as recoverfor Change-trend and beats for Relative-difference;we then extended the set of verbs by examiningWordNet for verbs that were closely related in mean-ing, and constructed a verb class for each set ofclosely related verbs.
Adjectives such as more andmost were handled in a similar manner.
The CaptionProcessing Module applies a part-of-speech taggerand a stemmer to the caption in order to identifynouns, adjectives, and the root form of verbs andadjectives derived from verbs.
The XML represen-tation of the graphic is augmented to indicate anyindependent axis labels that match nouns in the cap-tion, and the presence of a verb or adjective class inthe caption.The Intention Recognition Module then analyzesthe XML file to build the appropriate Bayesian net-work; the current system is limited to bar charts, but2As described in the next paragraph, there are 12 categoriesof high-level goals.227the principles underlying the system should be ex-tendible to other kinds of information graphics.
Thenetwork is described in (Elzer et al, 2005).
Verybriefly, our analysis of simple bar charts has shownthat the intended message can be classified into oneof 12 high-level goals; examples of such goals in-clude:?
Change-trend: Viewer to believe that thereis a <slope-1> trend from <param1>to <param2> and a significantly differ-ent <slope-2> trend from <param3> to<param4>?
Relative-difference: Viewer to believe that thevalue of element <param1> is <comparison>the value of element <param2> where<comparison> is greater-than, less-than, orequal-to.Each category of high-level goal is represented by anode in the network (whose parent is the top-levelgoal node), and instances of these goals (ie., goalswith their parameters instantiated) appear as chil-dren with inhibitory links (Huber et al, 1994) cap-turing their mutual exclusivity.
Each goal is brokendown further into subtasks (perceptual or cognitive)that the viewer would need to perform in order toaccomplish the goal of the parent node.
The net-work is built dynamically when the system is pre-sented with a new information graphic, so that nodesare added to the network only as suggested by thegraphic.
For example, low-level nodes are added forthe easiest primitive perceptual tasks and for per-ceptual tasks in which a parameter is instantiatedwith a salient entity (such as an entity colored dif-ferently from others in the graphic or an entity thatappears as a noun in the caption), since the graphicdesigner might have intended the viewer to performthese tasks; then higher-level goals that involve thesetasks are added, until eventually a link is establishedto the top-level goal node.Next evidence nodes are added to the network tocapture the kinds of evidence noted in Sections 3and 4.3.
For example, evidence nodes are added tothe network as children of each low-level perceptualtask; these evidence nodes capture the relative dif-ficulty (categorized as easy, medium, hard, or im-possible) of performing the perceptual task as esti-mated by our effort estimation rules mentioned inSection 3, whether a parameter in the task refers toan entity that is salient in the graphic, and whethera parameter in the task refers to an entity that is anoun in the caption.
An evidence node, indicatingfor each verb class whether that verb class appearsin the caption (either as a verb, or as an adjective de-rived from a verb, or as a noun that can also serve asa verb) is added as a child of the top level goal node.Adjectives such as more and most that provide evi-dence are handled in a similar manner.In a Bayesian network, conditional probability ta-bles capture the conditional probability of a childnode given the value of its parent(s).
For example,the network requires the conditional probability ofan entity appearing as a noun in the caption giventhat recognizing the intended message entails per-forming a particular perceptual task involving thatentity.
Similarly, the network requires the condi-tional probability, for each class of verb, that theverb class appears in the caption given that the in-tended message falls into a particular intention cat-egory.
These probabilities are learned from our cor-pus of graphics, as described in (Elzer et al, 2005).6 EvaluationIn this paper, we are particularly interested inwhether shallow processing of captions can con-tribute to recognizing the intended message of aninformation graphic.
As mentioned earlier, the in-tended message of each information graphic in ourcorpus of bar charts had been previously annotatedby two coders.
To evaluate our approach, we usedleave-one-out cross validation.
We performed a se-ries of experiments in which each graphic in the cor-pus is selected once as the test graphic, the probabil-ity tables in the Bayesian network are learned fromthe remaining graphics, and the test graphic is pre-sented to the system as a test case.
The system wasjudged to fail if either its top-rated hypothesis didnot match the intended message that was assignedto the graphic by the coders or the probability rat-ing of the system?s top-rated hypothesis did not ex-ceed 50%.
Overall success was then computed byaveraging together the results of the whole series ofexperiments.Each experiment consisted of two parts, one in228Diner?s ClubDiscoverAmerican ExpressMastercardVisa400 600200Total credit card purchases per year in billionsFigure 4: A Graphic from Business Week3which captions were not taken into account in theBayesian network and one in which the Bayesiannetwork included evidence from captions.
Ouroverall accuracy without the caption evidence was64.5%, while the inclusion of caption evidence in-creased accuracy to 79.1% for an absolute increasein accuracy of 14.6% and a relative improvement of22.6% over the system?s accuracy without captionevidence.
Thus we conclude that shallow process-ing of a caption provides evidence that can be effec-tively utilized in a Bayesian network to recognizethe intended message of an information graphic.Our analysis of the results provides some interest-ing insights on the role of elements of the caption.There appear to be two primary functions of verbs.The first is to reflect what is in the data, therebystrengthening the message that would be recognizedwithout the caption.
One example from our corpusis a graphic with the caption ?Legal immigration tothe U.S. has been rising for decades?.
Althoughthe early part of the graphic displays a change fromdecreasing immigration to a steadily increasing im-migration trend, most of the graphic focuses on thedecades of increasing immigration and the captionstrengthens increasing trend in immigration as theintended message of the graphic.
If we do not in-clude the caption, our system hypothesizes an in-creasing trend message with a probability of 66.4%;other hypotheses include an intended message thatemphasizes the change in trend with a probabilityof 15.3%.
However, when the verb increasing fromthe caption is taken into account, the probability ofincreasing trend in immigration being the intendedmessage rises to 97.9%.3This is a slight variation of the graphic from BusinessWeek.
In the Business Week graphic, the labels sometimes ap-The second function of a verb is to focus atten-tion on some aspect of the data.
For example, con-sider the graphic in Figure 4.
Without a caption, oursystem hypothesizes that the graphic is intended toconvey the relative rank in billings of different creditcard issuers and assigns it a probability of 72.7%.Other possibilities have some probability assignedto them.
For example, the intention of conveyingthat Visa has the highest billings is assigned a prob-ability of 26%.
Suppose that the graphic had a cap-tion of ?Billings still lag?
; if the verb lag is takeninto account, our system hypothesizes an intendedmessage of conveying the credit card issuer whosebillings are lowest, namely Diner?s Club; the prob-ability assigned to this intention is now 88.4%, andthe probability assigned to the intention of convey-ing the relative rank of different credit card issuersdrops to 7.8%.
This is because the verb class con-taining lag appeared in our corpus as part of the cap-tion for graphics whose message conveyed an en-tity with a minimum value, and not with graphicswhose message conveyed the relative rank of all thedepicted entities.
On the other hand, if the captionis ?American Express total billings still lag?
(whichis the caption associated with the graphic in our cor-pus), then we have two pieces of evidence from thecaption ?
the verb lag, and the noun American Ex-press which matches a label.
In this case, the proba-bilities change dramatically; the hypothesis that thegraphic is intended to convey the rank of AmericanExpress (namely third behind Visa and Mastercard)is assigned a probability of 76% and the probabilitydrops to 24% that the graphic is intended to con-vey that Diner?s Club has the lowest billings.
This isnot surprising.
The presence of the noun AmericanExpress in the caption makes that entity salient andis very strong evidence that the intended messageplaces an emphasis on American Express, thus sig-nificantly affecting the probabilities of the differenthypotheses.
On the other hand, the verb class con-taining lag occurred both in the caption of graphicswhose message was judged to convey the entity withthe minimum value and in the caption of graphicspear on the bars and sometimes next to them, and the headingfor the dependent axis appears in the empty white space of thegraphic instead of below the values on the horizontal axis as weshow it.
Our vision system does not yet have heuristics for rec-ognizing non-standard placement of labels and axis headings.229that conveyed an entity ranked behind some others.Therefore, conveying the entity with minimum valueis still assigned a non-negligible probability.7 Future WorkIt is rare that a caption contains more than one verbclass; when it does happen, our current system bydefault uses the first one that appears.
We need toexamine how to handle the occurrence of multipleverb classes in a caption.
Occasionally, labels in thegraphic appear differently in the caption.
An exam-ple is DJIA (for Dow Jones Industrial Average) thatoccurs in one graphic as a label but appears as Dowin the caption.
We need to investigate resolving suchcoreferences.We currently limit ourselves to recognizing whatappears to be the primary communicative intentionof an information graphic; in the future we will alsoconsider secondary intentions.
We will also extendour work to other kinds of information graphics suchas line graphs and pie charts, and to complex graph-ics, such as grouped and composite bar charts.8 SummaryTo our knowledge, our project is the first to inves-tigate the problem of understanding the intendedmessage of an information graphic.
This paperhas focused on the communicative evidence presentin an information graphic and how it can be usedin a probabilistic framework to reason about thegraphic?s intended message.
The paper has givenparticular attention to evidence provided by thegraphic?s caption.
Our corpus study showed thatabout half of all captions contain some evidence thatcontributes to understanding the graphic?s message,but that fully understanding captions is a difficultproblem.
We presented a strategy for extracting ev-idence from a shallow analysis of the caption andutilizing it, along with communicative signals fromthe graphic itself, in a Bayesian network that hy-pothesizes the intended message of an informationgraphic, and our results demonstrate the effective-ness of our methodology.
Our research is part of alarger project aimed at providing alternative accessto information graphics for individuals with sightimpairments.ReferencesJ.
Ang, R. Dhillon, A. Krupski, E. Shriberg, and A. Stol-cke.
2002.
Prosody-based automatic detection of an-noyance and frustration in human-computer dialog.
InProc.
of the Int?l Conf.
on Spoken Language Process-ing (ICSLP).D.
Chester and S. Elzer.
2005.
Getting computers to seeinformation graphics so users do not have to.
To ap-pear in Proc.
of the 15th Int?l Symposium on Method-ologies for Intelligent Systems.H.
Clark.
1996.
Using Language.
Cambridge UniversityPress.M.
Corio and G. Lapalme.
1999.
Generation of textsfor information graphics.
In Proc.
of the 7th EuropeanWorkshop on Natural Language Generation, 49?58.S.
Elzer, S. Carberry, N. Green, and J. Hoffman.
2004.Incorporating perceptual task effort into the recogni-tion of intention in information graphics.
In Proceed-ings of the 3rd Int?l Conference on Diagrams, LNAI2980, 255?270.S.
Elzer, S. Carberry, I. Zukerman, D. Chester, N. Green,S.
Demir.
2005.
A probabilistic framework for recog-nizing intention in information graphics.
To appear inProceedings of the Int?l Joint Conf.
on AI (IJCAI).R.
Futrelle and N. Nikolakis.
1995.
Efficient analysis ofcomplex diagrams using constraint-based parsing.
InProc.
of the Third International Conference on Docu-ment Analysis and Recognition.R.
Futrelle.
1999.
Summarization of diagrams in docu-ments.
In I. Mani and M. Maybury, editors, Advancesin Automated Text Summarization.
MIT Press.Nancy Green, Giuseppe Carenini, Stephan Kerpedjiev,Joe Mattis, Johanna Moore, and Steven Roth.
Auto-brief: an experimental system for the automatic gen-eration of briefings in integrated text and informationgraphics.
International Journal of Human-ComputerStudies, 61(1):32?70, 2004.H.
P. Grice.
1969.
Utterer?s Meaning and Intentions.Philosophical Review, 68:147?177.M.
Huber, E. Durfee, and M. Wellman.
1994.
The auto-mated mapping of plans for plan recognition.
In Proc.of Uncertainty in AI, 344?351.S.
Kerpedjiev and S. Roth.
2000.
Mapping communica-tive goals into conceptual tasks to generate graphics indiscourse.
In Proc.
of Int.
Conf.
on Intelligent UserInterfaces, 60?67.J.
Yu, J.
Hunter, E. Reiter, and S. Sripada.
2002.Recognising visual patterns to communicate gas tur-bine time-series data.
In ES2002, 105?118.230
