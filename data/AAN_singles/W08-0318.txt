Proceedings of the Third Workshop on Statistical Machine Translation, pages 139?142,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsTowards better Machine Translation Qualityfor the German?English Language PairsPhilipp Koehn Abhishek Arun Hieu HoangSchool of InformaticsUniversity of Edinburghpkoehn@inf.ed.ac.uk a.arun@sms.ed.ac.uk h.hoang@sms.ed.ac.ukAbstractThe Edinburgh submissions to the shared taskof the Third Workshop on Statistical MachineTranslation (WMT-2008) incorporate recentadvances to the open source Moses system.We made a special effort on the German?English and English?German language pairs,leading to substantial improvements.1 IntroductionEdinburgh University participated in the shared taskof the ThirdWorkshop on Statistical Machine Trans-lation (WMT-2008), which is partly funded by theEUROMATRIX project, which also funds our work.In this project, we set out to build machine trans-lation systems for all language pairs of official EUlanguages.
Hence, we also participated in the sharedtask in all language pairs.For all language pairs, we used the Moses decoder(Koehn et al, 2007), which follows the phrase-basedstatistical machine translation approach (Koehnet al, 2003), with default settings as a startingpoint.
We recently added minimum Bayes risk de-coding and reordering constraints to the decoder.
Weachieved consistent increase in BLEU scores withthese improvements, showing gains of up to 0.9%BLEU on the 2008 news test set.Most of our efforts were focused on the languagepairs German?English and English?German.
Forboth language pairs, we explored language-specificand more general improvements, resulting in gainsof up to 1.5% BLEU for German?English and 1.4%BLEU for English?German.2 Recent ImprovementsOver the last months, we added minimum Bayes riskdecoding and additional reordering constraints to theMoses decoder.
The WMT-2008 shared task offeredthe opportunity to assess these components over alarge range of language pairs and tasks.For all our experiments, we trained solely on theEuroparl corpus, which allowed us to treat the 2007news commentary test set (nc-test2007) as a stand-in for the 2008 news test set (news-2008), for whichwe have no in-domain training data.
This may haveresulted in lower performance due to less (and veryrelevant) training data, but it also allowed us to opti-mize for a true out-of-domain test set.The baseline training uses Moses default param-eters.
We use a maximum sentence length of 80, aphrase translation table with the five traditional fea-tures, lexicalized reordering, and lowercase trainingand test data.
All reported BLEU scores are not case-sensitive, computed using the NIST tool.2.1 Minimum Bayes Risk DecodingMinimum Bayes risk decoding was proposed by Ku-mar and Byrne (2004).
Instead of selecting the trans-lation with the highest probability, minimum Bayesrisk decoding selects the translation that is most sim-ilar to the highest scoring translations.
Intuitively,this avoid the selection of an outlier as the best trans-lation, since the decision rule prefers translationsthat are similar to other high-scoring translations.Minimum Bayes risk decoding is defined as:eMBR = argmaxe?e?L(e, e?)
p(e?|f)As similarity function L, we use sentence-levelBLEU with add-one smoothing.
As highest scoringtranslations, we consider the top 100 distinct trans-lations, for which we convert the translation scoresinto a probability distribution p (with a scaling fac-tor of 1).
We tried other n-best list sizes and scalingfactors, with very similar outcomes.139Language Pair Baseline MBR MP MBR+MPSpanish?German news 11.7 11.8 (+0.1) 11.9 (+0.2) 12.0 (+0.3)Spanish?German ep 20.7 21.0 (+0.3) 20.8 (+0.1) 21.0 (+0.3)German?Spanish news 16.2 16.3 (+0.1) 16.4 (+0.2) 16.6 (+0.4)German?Spanish ep 28.5 28.6 (+0.1) 28.5 (?0.0) 28.6 (+0.1)Spanish?English news 19.8 20.2 (+0.4) 20.2 (+0.4) 20.3 (+0.5)Spanish?English ep 33.6 33.7 (+0.1) 33.6 (?0.0) 33.7 (+0.1)English?Spanish news 20.1 20.5 (+0.4) 20.5 (+0.4) 20.7 (+0.6)English?Spanish ep 33.1 33.1 (?0.0) 33.0 (?0.1) 33.1 (?0.0)French?English news 18.5 19.1 (+0.6) 19.1 (+0.6) 19.2 (+0.7)French?English ep 33.5 33.5 (?0.0) 33.4 (?0.1) 33.5 (?0.0)English?French news 17.8 18.0 (+0.2) 18.2 (+0.4) 18.3 (+0.5)English?French ep 31.1 31.1 (?0.0) 31.1 (?0.0) 31.1 (?0.0)Czech?English news 14.2 14.4 (+0.2) 14.3 (+0.1) 14.5 (+0.3)Czech?English nc 22.8 23.0 (+0.2) 22.9 (+0.2) 23.0 (+0.2)English?Czech news 9.6 9.6 (?0.0) 9.7 (+0.1) 9.6 (?0.0)English?Czech nc 12.9 13.0 (+0.1) 12.9 (?0.0) 13.0 (+0.1)Hungarian?English news 7.9 8.3 (+0.4) 8.5 (+0.6) 8.8 (+0.9)English?Hungarian news 6.1 6.3 (+0.2) 6.4 (+0.3) 6.5 (+0.4)average news - +0.26 +0.33 +0.46average ep - +0.08 ?0.02 +0.08Table 1: Improvements in BLEU on the test sets test2008 (ep), newstest2008 (news) and nc-test2008 (nc) for minimumBayes risk decoding (MBR) and the monotone-at-punctuation reordering (MP) constraint.2.2 Monotone at PunctuationThe reordering models in phrase-based translationsystems are known to be weak, since they essentiallyrelies on the interplay of language model, a generalpreference for monotone translation, and (in the caseof lexicalized reordering) a local model based on awindow of neighboring phrase translations.
Allow-ing any kind of reordering typically reduces transla-tion performance, so reordering is limited to a win-dow of (in our case) six words.One noticeable weakness is that the current modelfrequently reorders words beyond clause bound-aries, which is almost never well-motivated, andleads to confusing translations.
Since clause bound-aries are often indicated by punctuation such ascomma, colon, or semicolon, it is straight-forwardto introduce a reordering constraint that addressesthis problem.Our implementation of a monotone-at-punc-tuation reordering constraint (Tillmann and Ney,2003) requires that all input words before clause-separating punctuation have be translated, beforewords afterwards are covered.
Note that this con-straint does not limit in any way phrase translationsthat span punctuation.2.3 ResultsTable 1 summarizes the impact of minimumBayes risk decoding (MBR) and the monotone-at-punctuation reordering constraint (MP).
Scoresshow higher gains for out-of-domain news test sets(+0.46) than for in-domain Europarl sets (+0.08).3 German?EnglishTranslating between German and English is surpris-ingly difficult, given that the languages are closelyrelated.
The main sources for this difficulty is thedifferent syntactic structure at the clause level andthe rich German morphology, including the mergingof noun compounds.In prior work, we addressed reordering with apre-order model that transforms German for train-ing and testing according to a set of hand-craftedrules (Collins et al, 2005).
Employing this methodto our baseline system leads to an improvement of+0.8 BLEU on the nc-test2007 set and +0.5 BLEU onthe test2007 set.140German?English nc-test2007 test2007baseline 20.3 27.6tokenize hyphens 20.1 (?0.2) 27.6 (?0.0)tok.
hyph.
+ truecase 20.7 (+0.4) 27.8 (+0.2)Table 2: Impact of truecasing on case-sensitive BLEUIn a more integrated approach, factored transla-tion models (Koehn and Hoang, 2007) allow us toconsider grammatical coherence in form of part-of-speech language models.
When translating intooutput words, we also generate a part-of-speech tagalong with each output word.
Since there are only 46POS tags in English, we are able to train high-ordern-gram models of these sequences.
In our experi-ments, we used a 7-gram model, yielding improve-ments of +0.2/?0.1.
We obtained the POS tags usingBrill?s tagger (Brill, 1995).Next, we considered the problem of unknown in-put words, which is partly due to hyphenated words,noun compounds, and morphological variants.
Us-ing the baseline model, 907 words (1.78%) in nc-test2007 and 262 (0.47%) in test2007 are unknown.First we separate our hyphens by tokenizing wordssuch as high-risk into high @-@ risk.
This reducesthe number of unknown words to 791/224.
Unfor-tunately, it hurts us in terms of BLEU (?0.1/?0.1).Second, we split compounds using the frequency-based method (Koehn and Knight, 2003), reducingthe number of unknown words to than half, 424/94,improving BLEU on nc-test2007 (+0.5/?0.2).A final modification to the data preparation istruecasing.
Traditionally, we lowercase all trainingand test data, but especially in German, case marksimportant distinctions.
German nouns are capital-ized, and keeping case allows us to make the dis-tinction between, say, the noun Wissen (knowledge)and the verb wissen (to know).
By truecasing, weonly change the case of the first word of a sentenceto its most common form.
This method still needssome refinements, such as the handling of headlinesor all-caps text, but it did improve performance overthe hyphen-tokenized baseline (+0.3/+0.2) and theoriginal baseline (+0.2/+0.1).Note that truecasing simplifies the recasing prob-lem, so a better way to gauge its effect is to lookat the case-sensitive BLEU score.
Here the dif-ference are slightly larger over both the hyphen-tokenized baseline (+0.6/+0.2) and the original base-German?English nc-test2007 test2007baseline 21.3 28.4pos lm 21.5 (+0.2) 28.3 (?0.1)reorder 22.1 (+0.8) 28.9 (+0.5)tokenize hyphens 21.2 (?0.1) 28.3 (?0.1)tok.
hyph.
+ split 21.8 (+0.5) 28.2 (?0.2)tok.
hyph.
+ truecase 21.5 (+0.2) 28.5 (+0.1)mp 21.6 (+0.3) 28.2 (?0.2)mbr 21.4 (+0.1) 28.3 (?0.1)big beam 21.3 (?0.0) 28.3 (?0.1)Table 3: Impact of individual modifications for German?English, measured in BLEU on the development setsGerman?English nc-test2007 test2007baseline 21.3 28.4+ reorder 22.1 (+0.8) 28.9 (+0.5)+ tokenize hyphens 22.1 (+0.8) 28.9 (+0.5)+ truecase 22.7 (+1.3) 28.9 (+0.5)+ split 23.0 (+1.7) 29.1 (+0.7)+ mbr 23.1 (+1.8) 29.3 (+0.9)+ mp 23.3 (+2.0) 29.2 (+0.8)Table 4: Impact of combined modifications for German?English, measured in BLEU on the development setsline (+0.4/+0.2).
See the Table 2 for details.As for the other language pairs, using themonotone-at-punctuation reordering constraint(+0.3/?0.2) and minimum Bayes risk decoding(+0.1/?0.1) mostly helps.
We also tried biggerbeam sizes (stack size 1000, phrase table limit 50),but without gains in BLEU (?0.0/?0.1).Table 3 summarizes the contributions of the indi-vidual modifications we described above.
For our fi-nal system, we added the improvements one by one(see Table 4), except for the bigger beam size andthe POS language model.
This led to an overall in-crease of +2.0/+0.8 over the baseline.
Due to a bugin splitting, the system we submitted to the sharedtask had a score of only +1.5/+0.6 over the baseline.4 English?GermanFor English?German, we applied many of the samemethods as for the inverse language pair.
Tok-enizing out hyphens has questionable impact (?0.1/+0.1), while truecasing shows minor gains(?0.0/+0.1), slightly higher for case-sensitive scor-ing (+0.2/+0.3).
We have not yet developed amethod that is the analog of the compound splitting141English?German nc-test2007 test-2007baseline 14.6 21.0tokenize hyphens 14.5 (?0.1) 21.1 (+0.1)tok.
hyph.
+ truecase 14.6 (?0.0) 21.1 (+0.1)morph lm 15.7 (+1.1) 21.2 (+0.2)mbr 14.9 (+0.3) 21.0 (?0.0)mp 14.8 (+0.2) 20.9 (?0.1)big beam 14.7 (+0.1) 21.0 (?0.0)Table 5: Impact of individual modifications for English?German, measured in BLEU on the development setsmethod ?
compound merging.
We consider this aninteresting challenge for future work.While the rich German morphology on the sourceside mostly poses sparse data problems, on the tar-get side it creates the problem of which morpholog-ical variant to choose.
The right selection hingeson grammatical agreement within noun phrases, therole that each noun phrase plays in the clause, andthe grammatical nature of the subject of a verb.
Weuse LoPar (Schmidt and Schulte im Walde, 2000),which gives us morphological features such ascase, gender, count, although in limited form, it of-ten opts for more general categories such as not gen-itive.
We include these features in a sequence model,as we used a sequence model over part-of-speechtags previously.
The gains of this method are espe-cially strong for the out-of-domain set (+1.1/+0.2).Minimum Bayes risk decoding (+0.3/?0.0),themonotone-at-punctuation reordering constraint(+0.2/?0.1), and bigger beam sizes (+0.1/?0.0)have similar impact as for the other language pairs.See Table 5 for a summary of all modifications.
Bycombining everything except for the bigger beamsize, we obtain overall gains of +1.4/+0.4 over thebaseline.
For details, refer to Table 6.5 ConclusionsWe built Moses systems trained on either only Eu-roparl data or, for Czech and Hungarian, the avail-able training data.
We showed gains with minimumBayes risk decoding and a reordering constraint in-volving punctuation.
For German?English, we em-ployed further language-specific improvements.Acknowledgements: This work was supported in partunder the EuroMatrix project funded by the EuropeanCommission (6th Framework Programme).English?German nc-test2007 test2007baseline 14.6 21.0+ tokenize hyphens 14.5 (?0.1) 21.1 (+0.1)+ truecase 14.6 (?0.0) 21.1 (+0.1)+ morph lm 15.4 (+0.8) 21.3 (+0.3)+ mbr 15.7 (+1.1) 21.4 (+0.4)+ mp 16.0 (+1.4) 21.4 (+0.4)Table 6: Impact of combined modifications for English?German, measured in BLEU on the development setsReferencesBrill, E. (1995).
Transformation-based error-driven learningand natural language processing: A case study in part ofspeech tagging.
Computational Linguistics, 21(4).Collins, M., Koehn, P., and Kucerova, I.
(2005).
Clause re-structuring for statistical machine translation.
In Proceed-ings of the 43rd Annual Meeting of the Association for Com-putational Linguistics (ACL?05), pages 531?540, Ann Arbor,Michigan.
Association for Computational Linguistics.Koehn, P. and Hoang, H. (2007).
Factored translation mod-els.
In Proceedings of the 2007 Joint Conference on Empiri-cal Methods in Natural Language Processing and Computa-tional Natural Language Learning (EMNLP-CoNLL), pages868?876.Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico,M., Bertoldi, N., Cowan, B., Shen, W., Moran, C., Zens, R.,Dyer, C., Bojar, O., Constantin, A., and Herbst, E. (2007).Moses: Open source toolkit for statistical machine trans-lation.
In Proceedings of the 45th Annual Meeting of theAssociation for Computational Linguistics Companion Vol-ume Proceedings of the Demo and Poster Sessions, pages177?180, Prague, Czech Republic.
Association for Compu-tational Linguistics.Koehn, P. and Knight, K. (2003).
Empirical methods for com-pound splitting.
In Proceedings of Meeting of the Euro-pean Chapter of the Association of Computational Linguis-tics (EACL).Koehn, P., Och, F. J., and Marcu, D. (2003).
Statistical phrasebased translation.
In Proceedings of the Joint Conference onHuman Language Technologies and the Annual Meeting ofthe North American Chapter of the Association of Computa-tional Linguistics (HLT-NAACL).Kumar, S. and Byrne, W. (2004).
Minimum bayes-risk decod-ing for statistical machine translation.
In Proceedings of theJoint Conference on Human Language Technologies and theAnnual Meeting of the North American Chapter of the Asso-ciation of Computational Linguistics (HLT-NAACL).Schmidt, H. and Schulte im Walde, S. (2000).
Robust Germannoun chunking with a probabilistic context-free grammar.
InProceedings of the International Conference on Computa-tional Linguistics (COLING).Tillmann, C. and Ney, H. (2003).
Word reordering and a dy-namic programming beam search algorithm for statisticalmachine translation.
Computational Linguistics, 29(1).142
