Representing Conceptual and Linguistic Knowledge for Multi-LingualGeneration in a Technical DomainStefan SvenbergDepar tment  of In fo rmat ion  and  Computer  ScienceL inkSp ing  Univers i ty ,  S-581 83 L inkSping,  Swedene-mail :  ssv@ida.
l iu.seAbstractWe report on a head-driven way to generate a language-specific representation for a language-independent con-ceptual structure.
With a grammar oriented towardsconceptual rather than phrasal structure, the approachshows some advant~ages over previous works in head-driven generation.
~It is particularly suited for multi-lingual generation systems where language-independentrepresentations andlprocesses should be maintained to amaximum extent.
We briefly sketch the architecture ofour Genie system based on some results of an analysis ofa technical manual for a gearbox.i I I Comb inatory Thematic info (from textspee) II rulesI ~ Sentence objects: I Texts:r and spec" I -- I prOcessOr I ~ English.,-,~, surface form ~ EnglishI C?ntent/ ~Eng l i sh  and I descrip--\]tions~ "~d ish  categoriesConceptual ~ Conceptual t~nceptual rulesknowledgebase ~ processor l--'~and lexiconFigure 1: The architecture of Genie1 Int roduct ionThe Genie system explores a way to rationalize multi-lingual production of technical documentation.
The sys-tem is semi-automatic in that the user designs an inter-lingual text specification describing content and form fora document.
Genie constructs the document in the de-sired languages as modelled by the specification, match-ing contents to a knowledge base, constructing categories,and forming sentences according to combinatory rules.The paper focusses on generation of language-specificcategories from language independent conceptual struc-tures.2 The Document  Analys isWe have chosen a ll0-page manual, English (\[3\]) andSwedish (\[8\]), of the truck gearbox R1000 to analyse.
Themanual is for expert servicemen and shows the design,function, and service instructions.The manual communicates some different kinds of do-main information.
We choose here to concentrate on thefollowing two:?
Static information (i.e what something is).
Exam-ples:(1) The R1000 is a gearbox.
(2) The.gearbox has nineforward gears.
(3) The gearbox is mechanically operated.
(1) RIO00 ar en v~xell?da.
(2) V?xell?dan hat nio v~xlarfram?t.
(3) V~xell~dan manSvreras mekaniskt?
Processive information (i.e what something does).Examples:(4) The purpose of the inhibitor valve is to prevent in-advertant shifting of the range gear when a gear in thebasic box is in mesh.
(5) The inhibitor cylinder preventsinadvertant shiRing in the basic box when range shiftsare being carried out.
(4) Sp~rrventilen har till uppgift att fbrhindra v~xling avrangev~xeln n~r n?gon av v~xlarna i basl?dan ligger i in-grepp.
(5) Sp~rrcylindern f6rhindrar v~xling i basl?dann~r v?xling reed rangen sker.The text can be broken down into approximatelysentence-sized units, each one communicating a piece ofinformation considered true in the domain.
We observea tight correspondence b tween the kind of informationand its textual realization.
The carefully defined termi-nology not only determines words, but their combina-tions as well.The text structure follows from conventions of lan-guage use for efficient communication about the domain.2457th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994These findings are in line with the issue of domain com-munication knowledge (Kittredge \[7\]).
Rhsner and Stede(\[9\]) distinguish similarly between the macro and microstructure of texts.
The architecture of Genie is builtup around the division of sentence and text structure;the user incorporates the conventions in the specificationwhile Genie provides the terminological definitions.The English and Swedish versions of the manual alignat sentence level.
Genie can cope with semantically non-equivalent sentence pairs, but not the very rare onesdiffering in content.
Nevertheless, the documents cor-respond nicely compared to the difficulties Bateman re-ports (\[1\]) on a study of medical didactic texts.
Groteand Rhsner (\[5\]) have studied car manuals for the TECH-DOC system, and they observe a close correspondence.We have employed Functional Grammar (FG) (c.f \[6\])as a principal analysis tool to developing representationsfor domain and language.3 Domain  Representat ionDomain representation is based on conceptual structures(Sowa \[11\]) and the transitivity structure of FG.
Conceptnodes are typed in an inheritance network.
We followSowa's definition and notation of conceptual graphs.Next, we sketch how static and processive informationare represented as facts, called aspects and transitions,respectively, in the knowledge base.3.1 AspectsAn aspect contains a simple conceptual graph where anobject has an attributive relation to a value.
We definethe is-a link as attributive and the type becomes thevalue.
Sentence (1) and (2) are:\[rlO00\] - -  (isa) --* \[gearbox\]\[riO00\] --* (f-gears) -+ \[f-gear:colllfl, f2, ..., f9}@9\]Both aspects happen to be close to their linguistic real-izations, which is not necessarily always the case.3 .2  T rans i t ionsA transition is a concept trans with three relations, pre,means, and post.
means has an event as value, pre andpost hold circumstances that obtain before and after theevent has occurred.An event carries mandatory, e.g actor, goal, and pe-ripheral role relations, e.g instr to other objects.
We candifferentiate roles into subtypes, e.g i-instr inhibits theevent.A circumstance can be: (i) a state characterized as asetting of some variable parameter.
An example is in theaspect for sentence (4):\[ trans\] -(pre) -~ \[ basic-boz-gears: disj { * ) \] -(in-mesh) --* \[4-\](means) ~ \[range-shifting\]-( i-instr) ---~ \[ inh-valve\](if) As an event, exhibited by sentence (5):\[trans\] -(gen-dur-pre)-  \[trans\] -(means)--~ \[range-shifting\](means) ~ \[basic-box-shifting\]-( i-instr) \ [ inh-cyOSub-events have their own transitions as value for pre andpost, which allows us to link events together, gen-dur-preis a version of pre used to give a meaning to "... beingcarried out".Transitions are more powerful than what has been out-lined here.
Much of their internal temporal constituency,complex parameters, lambda-abstractions, and differentkinds of constraints have been left out for clarity.4 L ingu is t ic  Representat ionThis section describes how Genie derives categories fora fact, as part of generation.
We first describe Englishcategories briefly.4 .1  Categor iesCategories are expressed in a language of typed featurestructures.
We define how categories can be formed, theirdifferent ypes and content.Construction of categories are inspired by modern Cat-egorial Grammars (CG), such as UCG (c.f \[12\]), but dif-fer in some respects.
The set of categories g is definedrecursively, (i) Basic categories E g. (if) If A and B E g,then the complex category AIB E g.The differences from CG are (i) the association of cat-egories to facts and concepts, and (if) complex categoriesare non-directed.Categories compose using the reduction rule to unify:AIB, B ~ ACategories are expressed as typed feature structures (tfs)(c.f Carpenter \[2\]).
a(name) denotes the set of attributesthe type name carries, and s(name) the immediate sub-types, cat is the root with a(cat) = {}, s(cat) ={zcat, bcat), xcat is the I operator, bcat are the basiccategories, a(bcat) = {:fb, s t ) ,  s(bcat) = {Icat,pcat).Icat and pcat are the lexical and phrasal categories.
Theattribute fb holds some feature bundle, rooted at fb andnamed appropriately, e.g np-fb, n-fb, agr-fb, st has a FG246i7th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994mood-structure to hold subcategories.
A peat has a cer-tain tfs under the type st to encode the structure, whilea lcat has a pointer into a surface lexicon, s-st is thestructure for clauses.
Elements are coded as attributes,e.g subj, fin, compl etc.4.2 Conceptual GrammarFacts are associated to categories composed of those ob-tained from the conceptual constituents.
The grammarrules state that a particular domain type corresponds toa category with certain combinatorial properties.
If vi-olated, the rule cannot derive an adequate category forthe fact.
Concept nodes are associated to a number ofcategories as defined by lexical rules.We call this a conceptual grammar, since it is tied toconceptual rather than phrase structures.
The rules arelanguage independent as the linguistic material is effec-tively hidden within the basic categories.
Rules have thefollowing notation:<head> when <body>.<head> carries an association of the general form cscat, where cs is a conceptual structure, and cat isthe category.
_<head> holds whenever all constraints in<body> hold 1.
Help associations (arrow with a symbolon top) support ~ with extra material.
We describerules for atoms, objects, aspects and transitions.4.2.1 Atoms and Objectsatoms have a rather simple and direct association:\[mechanicaO ~ a\[st:mechanicaO\[9\] ~ det\[fb:det-fb\[agr: agr-fb\[numb:p~\]s'g :ng\]'The type of category depends on how it will be used, butshould be basic.
The examples are typical.The object R10001gives "a gearbox" in:\[r10001cnp\[fb: np-fb\[agr :Agr-- agr-fb\[numb :sg, pers: 3rd\]spee:inde)~s c: np-st\[n: \[fb: n-fb\[agr:Agr\]st: gearbozl\]\]There are potentially many alternative associations.
Lex-ical choice is not addressed in this paper, although werecognize its necessity in generation systems.4.2.2 AspectsThe category for the relation in an aspect is seen as afunction of the categories for the two concepts.
The1 Like a Prolog rule.
!grammar ule for aspects fetches and applies the func-tion.
A relation operation, as in the aspect for sentence(3), has a category slnpla:\[operation\]s\[st:s-st\[subj :Subjfin:v\[fb: -\] \[pass:+, agr:agr= ag -N\]pred: v\[st: ope ration\]compl:Compl\]\] ISubj=np\[fb:np-fbKagr:agr\]\] lCompl= a\[fb: a-y \[aav: +\]\]The rule says that one category should fill the complelement as an adverbial, and another to become an np inthe subj element.
Note the subject-verb agreement.The aspect rule simply reduces the relation categorywith the categories obtained from the concepts:O=\[concept\] - rt=(re0 V=\[concept\] AwhenR ~ A=catlB=catlC=cat, V ~ C, 0 ~ B.An aspect is matched to the right hand side of the headto bind the variables O, R and V. The rule proves thefollowing category for sentence (3):\[rlO00\] ~ (operation) - -  \[mechanica 04 t: -st\[subj : ndfb:np-5\[agr:agr= agr 5\[n b:sgpers:3rd\]spec:/nde\]\]t:gearbo \]\]\]f in: v\[fb: v-Jb~as s:+agr:agr= agr-fb\]\]pred: v\[ st  : ope ration\]compl: a\[fb: a-fb lady :-/-\]st:mechanica~\]\]4.2.3 Transit ionsassociations for transitions are more complex, but stillcompositional.
The idea is to get a category for the eventand reduce it with all roles to obtain a basic category.This is reduced with the transition type category andwith those for pre and post relations and values.The association for trans is defined by the rule:Trans=\[trans\] -(means) -- Ev=\[event\]Pre-R=(pre) ~ Pre-C=conceptPost-R=(post) --~ Post-C=conceptRes whenTrans ~ Resl=cat\[Event=catPre-R ~ Res2= cat IResl \[Pre= catPre-C ~ PrePost-R ~ Res\[Res21Post=ca~Post-C ~ Post, Ev ==-z Event2477th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994The transition is matched to bind variables in the head.retrieves the complex category of one argument forthe mandatory event, pre and post are optional and havetheir own categories, e.g:\[gen-dur-pre\]=~ SlPre=progressive-s\] S=s\[st:s-st\[pre:Pre\]\]The category constrains the category in the pre to be aprogressive-s.
The rule for events basically looks like:EV=\[event\] -(mre/) ~ OMl=\[concept\](rare 0 -- OMn=\[concept\]PRl=(pre0 OPl=\[concep \]Prtm=(pre0 -- OPm=\[concep \]RES=ca~ whenEV ~ PCAT0=cat\]ARGn=cat\] .
.
.
\ ]ARGi= catfor i=l .
.n  do OMi :::::::?~ ARGifor j= l .
.m doPRj ~ PCAT j=cat IPCAT j_ i=cat IARGj=catOPj ~ ARGjRES = PCATmThe event category reduces with the mandatory rolevalues to reveal the innermost result category for theevent.
It will then reduce with the peripheral roles.An example of an event category carried by\[lock\] ~ s\ [st :s -st \ [subj :SVSJ:fin: v\[:fb: v-fb\[agz:AGR, pass :-\]\]pred:v\[st:lock\]compl:OBJ\]\] ISUBJ=np\[:fb:np-fb\[agr:AGR=agr-fb\]\] \[ OB J=np4.3 DiscussionThe conceptual grammar is a semantic-head grammar,where the semantic head is the top node of the graph arule analyzes?
The grammar processor is a plain Pro-log resolution.
It behaves as the standard semantic-head driven generator (SHDG) (Shieber et al\[10\]) doeswhen all nodes are pivots, i.e a purely top-down man-ner.
SHDGs in general are quite different from ours inthe way knowledge is organized.
They follow the struc-ture of categories in grammars that are more suitable forparsing, i.e allowing content-less words but not word-lesscontents.
Hence, there is an assymetry between compo-sitionality of words and semantics (Dymetman \[4\]).
Acontent-less word can potentially occur anywhere in theoutput string and a generator must consider this to ter-minate gracefully.
Problems of ensuring coherence andcompleteness degrade efficiency further.
Our generatorresembles a parser to a large extent, having a conceptualstructure instead of a string to work on.
As such, it isfree from the problems and can potentially benefit di-rectly from many research results in parsing technology.The rules are designed to work on any language, thuslessening the burden when adding more linguistic sup-port.
More rules have to be written only when newkinds of facts are added to the knowledge base, to ac-count for their structures.
We do not need a reachabilityrelation, as the problem of goal-directedness in genera-tion is achieved by doing clever choices of categories inlexical rules.The relations between domain types and categories aresimilar to the semantic type assignments in classic CGs.Our version is more flexible as a consequence of the typesystem.Genie is in an experimental state (about 20 aspects and10 transitions), but has proven feasability of the issuesdiscussed in this paper.
It  is less competent in lexicalchoice and the combinatory grammar.
Development iscontinuing in the Life environment.References\[1\] John A. Bateman, Liesbeth Degand, and Elke Teich.
Towardsmultilingual textuality: some experiences from multilingualtext generation.
In $th European Workshop on NLG, pages5-17, 1993.\[2\] Bob Carpenter.
The Logic o\] Typed Feature Structures.
Cam-bridge University Press, 1992.\[3\] Volvo Truck Corporation.
Service Manual Trucks: GearboxRIO00.
Volvo Truck Corporation, 1988.\[4\] Marc Dymetman, Pierre Isabelle, and Francgis Perrault.
Asymmetrical pproach to parsing and generation.
In Proc.
ofColing-90, volume 3, pages 90-96, 1990.\[5\] Brigitte Grote and Dietmar RSsner.
Representation levels inmultilingual text generation.
In From Knowledge to Language- Three Papers on Multilingual Text Generation, FAW-TR-93019.
FAW Ulna, Germany, 1993.\[6\] M. A. K. Halliday.
An Introduction to Functional Grammar.Edward Arnold, 1985.
ISBN 0-7131-6365-8.\[7\] Richard Kittredge, Tanya Korelsky, and Owen Rainbow.
Onthe need for domain communication k owledge.
CanadianComputational Intelligence Journal, 7(4):305-314, 1991.?
\[8\] Volvo Lastvagnar.
Servicehandbok Lastvagnar: VgxellgdaR1000.
Volvo Lastvagnar, 1988.\[9\] Dietmar RSsner and Manfred Stede.
Custorrfizing rst for theautomatic production of technical manuals.
In Aspects of Au-tomated NLG: 6th International Workshop on NLG, pages199-214, 1992.\[10\] Stuart M. Shieber, Fernando C. N. Pereira, Gertjan van No-ord, and Robert C. Moore.
Semantic-head-driven g eration.Computational Linguistics, 16(1):30-42, March 1990.\[11\] J. F. Sown.
Conceptual Structures.
Addison-Wesley, 1984.\[12\] Henk Zeevat, Ewan Klein, and Jonathan Calder.
Unificationcategorial grammar.
Technical Report EUCCS/RP-21, Cen-tre for Cognitive Science, University of Edinburgh, Scotland,1987.248
