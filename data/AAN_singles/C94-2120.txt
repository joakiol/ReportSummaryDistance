INCREMENTAb INTERPRETAT ION:APPL ICAT IONS,  THEORY,  AND RF, LAT IONSHIP  TO DYNAMIC  SEMANTICS*Dav id  M i lward  & Rob in  CooperCentre for Cognitive Science, University of Edinburgh2, Buccleuch Place, Edinburgh, EH8 91,W, Scot, land, davidm@cogsci.ed.ac.ukABSTRACTWhy should computers interpret language incremen-tally?
In recent years psycholinguistic evidence for in-cremental interpretation has become more and morecompelling, suggesting that humans perlTorm semanticinterpretation before constituent boundaries, possiblyword by word.
However, possible computational p-plications have received less attention.
In this paperwe consider various potential applications, in parti-cular graphical interaction and dialogue.
We then re-view the theoretical and computational tools availablefor mapping from fragments of sentences to flflly sco-ped semantic representations.
Finally, we tease apartthe relationship between dynamic semantics and in-creinental interpretation.APPL ICAT IONSFollowing the work of, for example, Marslen-Wilson(1973), .lust and Carpenter (1980) and Altma.nn al\]dSteedrnan (1988), it has heroine widely accepted thatsemantic i11terpretation i  hnman sentence processingcan occur beibre sentence boundaries and even beforeclausal boundaries.
It is less widely accepted thatthere is a need for incremental interpretation i com-putational applications.In the \[970s and early 1980s several compntationalimplementations motivated the use of' incremental in-.terpretation as a way of dealing with structural andlexical ambiguity (a survey is given in Haddock 1989).A sentence snch as the following has 4862 differentsyntactic parses due solely to attachment ambiguity(Stabler 1991).1) I put the bouquet of flowers that you gave me forMothers' Day in the vase that you gave me for mybirthday on the chest of drawers that you gave melbr Armistice Day.Although some of the parses can be ruled out usingstructural preferences during parsing (such as \[,ateC'losure or Minimal Attachment (Frazier 1979)), extraction of the correct set of plausible readings requi-res use of real world knowledge.
Incremental inter-pretation allows on-line semantic tiltering, i.e.
parsesof initial fragments which have an implausible or an-olnalous interpretation are rqiected, thereby preven-*'.lPhis research was supported by the UK Science and Gn-glneerlng l~.esearch Council, H, esearch Grant 1tR30718.Ling ambiguities from multiplying as the parse pro-ceeds.However, onqine semantic filtering for sentence pro-cessing does have drawbacks.
Firstly, for sentenceprocessing using a serial architecture (rather than onein which syntactic and semantic processing is perfor-lned in parallel), the savings in computation obtainedfrom on-line filtering have to be balanced against theadditional costs of performing selnan~ic computationsfor parses of fl:agments which would eventually be ru-led out anyway from purely syntactic onsiderations.Moreow~r, there are now relatively sophisticated waysof packing ambiguities during parsing (e.g.
by the nseof graph-structured stacks and packed parse forests(2blnita 1985)).
Secondly, the task of judging plausi-bility or anomaly according to context and real worldknowledge is a difficult problem, except in some verylilnited domains.
It, contrast, statistical techniqnesusing lexeme co-occurrence provide a relatively sim-ple mechanism which can imitate semantic filteringin many cases.
1,br example, instead of judging bankas a lhmncial institution as more plansible than bankas a riverbank in the noun phrase the rich bank, wecan cornpare the number of co-occurrences of the le-xemcs r ich and bank1 (= riverbank) versus r ich andbank2 (= financial institution) in a semantically ana-lysed corpus.
Cases where statistical techniques eemless appropriate arc where plausibility is affected bylocal context.
For example, consider the ambiguoussentence, The decorators painted a wall with cracks intim two contexts 517~c room was supposed to look" run-down vs.
The clients couhln't afford wallpaper.
Suchcases involve reasoning with an interpretation in itsimmediate context, as opposed to purely .judging thelikelihood of a particular linguistic expression in a gi-ven application domain (see e.g.
Cooper 1993 for dis-cussion).Although the usefulness of on-line semantic filteringduring the processing of complete sentences is deba-table, filtering has a more plausible role to play in in-teractive, real-time nvironments, uch as interactivespell checkers (see e.g.
Wirdn (1990) I'or arguments forincremental parsing in such environnlents).
IIere thechoice is between whether or not to have semantic ill-tering at all, rather than whether to do it on-line, orat the end of the sentence.q'he concentration in early literature on using in-cremental interpretation for semantic filtering hasperha.ps distracted f'roln SOlne other applicationswhich provide less controversial pplications.
We will748consider two in detai l  here: graphical  interfaces, ~mdd ialogttc,The I,'ounda.tions for Intel l igent Cral)hics I'roje(:{;(I,' l(l) I (:onsidered various wa,ys in which natura l  hm--gu;~ge input  could be used within eoml}uter a.idcd de-sign syste, ms (the i}~rl;ieula.r al)plicai;ion studied waseoull)ul;er aided kitchen design, where users would notuecessarily I)e professional designers).
Incremental  in-terpretat ion was considered to be useful in enabl ingimme(li;m~ visual feedl)aek.
Visual feedback could beused to l}rovide Colllh:lna.I;ion (\[or ex;tlnl)le~ l)y hig-hl ight ing a.n olo.ieet \].el'erred to by a stleeeSSFlll deli-nite des('xiption), or i{; could be used to give the tibera.n iml)roved ch3.l\]{;e of a.
('.llievillg suc{:essi'ttl r{?l'{~'l'elice.I,'or Cxmul)le, if sets o\[ possil}le ref(:l'en~s \['or a dellnit.enoun phrase a.re highl ighted chlrillg wol'(I I)y word i)1'oeessillp; then the user knows how mue\], or how littleinfornt~t,ion is re{luire(l for su(:{:esslid refepenee.
:~'I luma,  n dia.logue, in \]);n'tieular, I;ask oriented (lialo-guc is eha.rac:terised I)y a. large numl)ers of sell-rel)airs(l,eve\[t 198:I, ( 'a r lc t ta  et ;d.
\[9!
}:1), such as hesita.ti-.
()\]IS} il/;~el;tiol.ls} ;l l l( l  ix~.\[)\]~l/;elllelltS, \[1, iS ~L\]SO Cot| l l l \ [{)\]tto l lnd interrupt ions reqltesting exti:a ela.rilieati(m, ordisagreements I)cl'ore I;he (211(I of  ~t.
Sell\[ell(;{'.
I(, iS eveltl)ossil)le for seutenecs tnr{.cd I) 5, one (lialogtte 1)acl, ici -pant  to be \[in\[shed 1)), a.nother.
Al)l}lieations involvingI;hc understa, tlcLing of  dia.logues inehn(le informal.ionextract ion I?om eonversal, ional (latal)ases, or eoml)U-ter moni tor ing of conversal.ions.
It.
also m&~y I)e usefulto include SOllle \['(20~Ltll?es of \]l/ll\[i;I.ll dialogue in manm~u:hine (lia.logue.
I,'ov ('.Xaml)le, inl.,~rru\[}t:ions (::m I)eIlSe(-1 D)\]' ear ly  signall ing of er rors  and  P~.nll)iguit,ies.I,(21; us tirsl; eonsidcl' SOl\[l{2 eXaml)les of sel\[2rel)air.IllSel:l;iOllS a,dd extl'~l, infol 'nmtion, usually uto(li\[iel:S(2 .~.2) We sLarl, in {,\].le middle wil, h .... in the mid(lie ofthe i)N)er with  a. I)h\]e disc (I,evelt 1983:ex.3)l\]e\])l~cements corr('.et l)ieees o\[ infotnlal,ion e.g.3) (I() from left, again to uh ..., from pink ap;~iu toI)lue (I,evelt 1983:ex.2)In s(n ne eases informal;ion from \[.he orre{?e{l nlaterialis ineorl)oI'a.ted il~l:,) \[,he fin;d messnp.
;e, l,'or examl)le ,{:ot\]s\[(\[er ;~ :d) a The three main sources of data  come., uh ...,they can I}e Found in the vet'erenee~b ,Iohn t)ol.ic~(t hat  the (,\[{l mau and his wife, uhL.\[oIIIL (JOtlllCiIs Initi~tive in Cognitive L;c ieuce/ l l ( J I ,  (h':mt;8826213, IBdCAAI) and ()entre for (Mgni{:ive Science, /\]ldver-sity o\[ l,Minburgh.2Thls exmnple was inspired by the work of I1;uldock (1 !
)87)on in{:pcmenl~t\[ hltcrl)retatlon of de\[\[nile nouu l)hrases, llad-d\[)cl,\[ iI~;(!d ;l~li ill(21'(!lli(!ll{;:ll C{}li~;I,iNtilll~ I};\]~st1{t al)\[}ro;~{ h followingMellish {198s) t;o l}r(wide ;m explanaCi(~tl of why it i:~ i}{,~sil}le{.o use I;he llOllll i)hl'~ts(!
\[h{" ~'a6~)it ?7l t\],~: t~a\[ e'?C:ll whell t:hm'eare I.w{} h;M.s, bul.
only on(: h;tt wilh ~ P;d}h\]l in il.8 \[,;Xallll)le (;t) iS i'ecollslJrll(:lJed i'l'onl ttli ;IC|,(ID~\] iil;tet;~.llCe.
J')xD.|llpl(2b (I)) D~lld ({i) *,V{'I'?
: COIIS{|'/IC{;{2d..... that  the man got into t,he ear and the wifewas with h im when fl\]ey left the housee \]!
',very boy took, uh ..., he should have takeA| awater 1)ottle wil.h h imIn (a.
), the corrected ma.terial the thre, .main .sou.rcc.sof data come, provides {,he anteeedent for the pronon\]~the:\].
In (b) the corrected m:~terial tells us that  thema.n is boCh old mid has a. wife.
In (e), the pronounhe is bound I)y \[,he qmmtif ier ever:/boy.l"or ~ system to understand ia.logues involving se l lrepa.irs such as {,hose iu (d) would seem t,o require.either a.n ~d)ility to interl)ret increment, a.lly, or theuse of a grammar  which in(:ludes self repa.ir as asynta.etic {:onst, ruetion a.kin to non-const i tuent  coor-d inat ion (the relationshil)I)ctwec, n coordin;~t,ion ands(;li2eorrection is noted I)y I,evelt (1983)).
1:or a. sy--stenl to generate self tel)airs might  also I:equire in-ePel/iCltta\] i lltel?\[)lX;\[,atiOll\] aSStllnilt~ ~/ \])Poeess whelx2the sys te ln  i)erI'oP1\]ts on - l ine  n |o l l i to r i l lg  o f  its ol l l ;put(a.kiu to l,evelC's Inodel of the hulmm sell2rel)a.ic me-eha.uism).
I1; has been suggested t.hat geltel'al;iOll ofseir tel)airs is useful in eases where there are severet ime const::~ints, o," where there is rapidly cha.ngingI)a.ckground inform;~t, ion (Ca.tier\[a, l).e.
).A more cOral)ell\[rig al'gttmetlt for inerententaI in teri)rcta.tiolt is in'ovided I)y considering dialogues involr ing  illtel?rtll)tiOllS.
Consider tit(' following dialoguefrom \[,he TILAINS COl?pits ((:II'()S,S el, al.
1 1!
)9!1):5) A: so we should move the engin0 a.t Avon,engine l!
;, l:o ...B :  engine E IA: 1')1l~: okayA: {mgiue I'21, \[,(} Bath  ...This re{luires hlterl)l:ctatiol| by Sl){'.aker I~ I)el'ore theend o\[' A's sente,lee to allow ol).iection to the al)po.siLion, lhe cn:/mc al Auon, {m:lbzc 1?.
Al l  exa.ml)Ie o\['the potential  use of iltterl'uI)tiolls in Illllllat\] eotnl)uterintecaction is the followiug:6) User :  Pitt {;lie pl l l leh ()lit() ...( \ ]Ol l l I ) l l | ; (w: The  i)1111(211 (;;lll~l; 1)(' IIv.)ved.
It}s b()\]-t,ed to the lloor.lit th is  exa ln l ) le  , interl)ret, a.tion lllUSL l ie\[ Oll\]y /)e I)e-12)r( the end o\[' l:he Sellt,ell('e, I)ul; I)el'ol:e a (:otmt.il, uent,I)otm(lary (Idle vePI)I)hrase in the user's eomntand hasnot yet I)e.eu {:Oml)lel.e(I ),( JURREN' I ?
TOOLS1.. Syntax  to  S{mmnt i ( :  lh~i ) resentat ionIn {.his section we shall briefly review work on pro-vicling semantic representat;ions (e.g.
lambda, expres..sions) word I)y word.
Tradi t iomd layered models o\[selll,ell(te \])l 'oeessit/g lips\[ huild a.
Full synta.x \[,FC:e fOF a.Setttellee} al ld thetl  extl;aeL a. sel \[ la l l t ic  i;el)l'eSellt+/,tiollf't'om \[.his.
To adapt  this to an in{zrement,al l)erspec-1,ire, we I/eed to \])e ~d)le to l}rovide synt, a.ci;ie Sgt?tlCtUt:es749(of some sort) for fragments of sentences, and be ableto extract semantic representations from these.One possibility, which has been explored mainlywithin the Categorial Grammar tradition (e.g.
Steed-man 1.988) is to provide a grammar which can treatmost if not all initial fragments as constituents.
'Pheythen have full syntax trees from which the semanticscan be calculated.However, an alternative possibility is to directlylink the partial syntax trees which can be %rmed fol:nOl>COnstituents with flmctional semantic representa-tions.
For example, a fragment missing a noun phrasesuch as John likes can be associated with a seman-I, ies which is a function from entities to truth values.Ilence, tam partial syntax tree given in Fig.
14,S/ \np vpJohn / \v np~likesF'ig.
Icall be associated with a semantic representation,Ax.
l i kes ( john ,x ) .13oth Categoria l approaches t;o incremental inter-pretation and approaches which use partial syntaxtrees gel; into difficulty in cases of left recurs|on.
Con-sider the sentence fragment, Mary thinks dohn.
Apossible partial syntax tree is provided by Fig.
2.S/ \np vpMary / \v Sthinks / \np vp}JohnFig.
2llowever, this is l ie| the only possible partial tree.la fact there are infinitely many cliff>rent rees possi-ble.
The completed sente.nce may have an arbitrarilylarge number of intermediate nodes between the lowers node and the lower hi).
For exarnple, John  couldbe embedded within a gerund e.g.
Mary thil&s Johnleaving here was a mistake, and this in turn could beenfl)e(lded e.g.
Mary thinks John leaving here beinga mistake is surprising.
J ohn  could also be embed-ded within a sentence which has a sentence modifierrequiring its own s node e.g.
Mary thinks John willgo home probably 5, and this can be flu'ther embedded4'Phe downarrow notat ion for miss ing const i tuents  is adop-ted from Synchronous Tree Adjo in ing (}rammm" (Shleber &Schabes 1990).5'\['he t reatment  of p robab ly  as a modif ier  of a sentenceis perhaps controversial .
I lowever,  t reatment  of it: as a verbphrase modi l ier  wauld merely shift the potenl, ia\] left recurs|on~o Ihe verb phrase node.e.g.
Mary thinks John will go home Frobablg becausehe is tired.The problem of there being an arbitrary mmg)er ofdifferent partial trees for a particular fragment is re-fleeted in most current approaches to incrementM in-terpretation being either incomplete, or not flflly wordby word.
For example, incomplete parsers have beenproposed by Stabler (11991) and Moortga.t (1988).
Sta-bler's system is a simple top-down parser which doesnot deal with left recursive grammars.
Moortgat'sM-Syste ln  is based on the Lambek (~ah:ulus: the pro-blem of an infinite lmmber of possible tree ka.gmentsis replaced by a corresponding problem of initiM fl:ag-ments having an infinite number of possible types.
Acolnplete incremental parser, which is not fully wordby word, was proposed by Pul lnan (1986).
This is ba.~sed on arc-eager left-corner parsing (see e.g.
l{esnikTo elmbIe complete, fully word by word parsing requires a way of encoding an intinite nmnber of partiMl, rees.
There are several possibilities.
'Fhe first is touse a language describing trees where we can expressthe fact that ,\]ohn is donfinatcd by the suode,  butdo not have to speciiy what it.
is i lmnediately domina-ted by (e.g.
D-Theory, Marcus et ah 198a).
Semanticrepresentations could be tbrmed word by word by ex-tracting 'default' syntax trees (by strengthening do-minance links into immediated ominance links whe-rever possible).A second possibility is to factor out recursive struc-tures from a grammar.
Thompson et al (1991) showhow this can be done for a phrase structure gram-mar (creating an equivalent 'Pree Adjoining ( ; rammar(,Ioshi I987)).
The parser for the resulting grammarallows linear parsing tbr an (infinitely) parallel sy-stem, with Cite absorption of each word performedin constant time.
At each choice point, there areonly a finite number of possible new partial TAG trees(the TAG trees represents the possibly inlinite nmn-bet of trees which can be forlned using adjunct|on).It should agMn be possible to extract 'default'  seman-tic values, by taking the semantics from the TA(I tree(i.e.
by assuming that there are to be ,to adj unctions).A somewhat similar system has recently been propo-sed by Shieber and Johnson (191t3).The third possibility is suggested by consideringthe semantic representations which are appropria.teduring a word by word parse.
Although there areany number of dill'trent partial trees for the fragmentMary thinks John, the semautics of the fragment canbe represented using just two lambda expressions6:AP.
thinks(mary,I)(john))AP.
AQ.
Q(thinks(mary, P(john)))Consider the tlrst.
The lambda abstraction (over a(;Two representa~,ions are appropr ia te  if t:here are no VP-modif iers as it, dependency grammar .
If V1)-modif icat lon isMlowed, I, wo more expressions are required:AP.
AR,.
( I I , ( kx .
th inks (mary ,  x ) ) ) (P ( john) )  and5p.
an.. aQ Q((ll,(Xx.thhlks(mary,x)))(P(john))).750f imctional item of type e--}l;) can 1)e thought of as~t way of encoding mt intinite set of pnrt ial  sema.ntie(tree) structures.
For cxmnple, the eventual semant icstructure may embed john  at ~my depth e.g.t hinks(nm.ry,sleeps (j oh n))thinks(nmry,possibly(sh' .eps(johu)))etc.The second exl)re.ssion (~ fimctiona\] i tem over typee-+t; and t -+t ) ,  allows for eventual structures wherethe main  senten<:e is embedde.d e.g.l>ossibly(l, h inks(nmry,s leeps( john)))This third possibil ity is therefor<; to l>rovide a, syntac-tic correlate of lambda expressions.
In l)rm:tice, ho--wever, l)rovided we are only interested in mai)l)ingfrom ~ str ing of words to ~ semant ic  representa.tion,~md don' t  need explicit synta.x trees I.o be eonstru(>I;e(|, we (:tin \]nerely use the types of the 'synta(:-tic lambda, expressions',  ra~ther them the expressionsthemselves.
Th is  is essential ly the approach taken inMilward (\]992) in order to provid(; eontplete, wordl)y word, incrementM interpretat ion using simple \]e-?ieMised gr~umna.rs, snch as a lexiealised version offormal dependen<'y g;ral-lnrlar and simple eategorialgra.lll llar 7 .2.
Logi( :a l  Forms to  Smnant ic  F i l t ;e r ingIn l)ro(:essing the sent(race A,larg introduced John toSusan, a, word-by-word ;~l)l)roach such as Milward(1992) provides the following logical fornls alTte, r theeorresl>OlMing sentence fr~gments are al~sorbe(l:Mary M ).
l ) ( mary )Mary introduced Ax.
Ay.inl.r (mary,x,y)M~wy introduced John Ay.intr(mary,john,y)Mary iul;rodu(:ed .John to Xy.inLr(mm'y,john,y)Mary introdn(:ed .John to Su<: ini.l'(mary,,john,sne)li':mh input  level rel)res(mtatiotl is apl)ropria.tc for themealf ing ol7 ~n incomplel, e senl;enee, I)eing either ~ pro-positi(m or a, function into a proposit ion./n Cha.ter et al (1990) it is argue(1 t lmt l, heinerementMly derived meanings are not .indged\[br plausibi l i ty directly, but instead ~re first tur~ned into existential ly (luantified proposit io.s ,  l,brexa.mp\[e, instead of .ju(lghtg tim plausiiMity of)~x..~y.int:r(Inary, x ,y) ,  we judge the plausil~ility of_~(x ,q ' ,3 (y ,T , in t r (mary ,  x y ) ) )  s. This i~ just theproposit ion Mart introduced something to somethingusing ~ general ized quanti l ier not~tion or the tbrmQuant i t ie .
r  (Var iab le ,R( : s t r i ( ' to r ,Body) .A | though the lambd:~ exl)ressions are built ul) mo-notonieMly, word by word, the, l)rOl)ositions \[brined7Whe version of categorial grammar used is AP.
(SttcgorialC, rmnmar with Associativity.~'\[hc prol)oSil;ion '.P is alw~Lys true.
See Chatter et ~tl.
(IDg,t)for discussion (ff whether it; is more  al)prol)ri~tl:(: to use ~t lit-HI-trivial rcsl, rictor.from them may need to be retraeted, a.long with allthe result ing infi~relmeS.
I,'or examl)le, Mart intro-duced something to something is ina.pl)ropriate if thethml sentence is Marg introduced noone to anybodg.
Arough algor i thm is as follows:l. Parse a. new word, Word/2.
l"orm ~ new lambda expression by eoml)ining thelambda~ exl>ression formed after parsing Wordi_  1 withthe lexieal semantics h)r Word/3.
Form a. proposit ion, Pi, by existentia.lly quantit):-.ing over the la.mbda a/)stracted va.riables.4.
Assert Pi.
If Pi does not ent~dl Pi-1 retraet I)i_~md all conclusious made ft:om it s.5.
Judge the.
phmsilfi l ity of Pi.
If iml)hmsible, blockthis del:iwlLio,.It is worth uoting tht~t the need for retract ion is notdue to ~x failure to extract the eorrect qeast eolnDlit-menC' propositiotl from the semaut ic  (:ontent of thefragment Mary introduced, 'l'hi~ is due to tim fm:tthat it, is I)ossible to find pairs of l)ossible eontinuati-ous which m:e the negation el  each other (e.g.
M(rrgintrod'ltccd noonc to anybody and Mary inl,'rodltced so-meone to somebody).
The only proposit iou comps>tibk', with both a proposit ion, p, and its negation, ~1 )is the trivial proposit ion, "P (see (.
:hater et al forfurther discussion).3.
IneremeiH;a l  Quant i th~r  Seep ingSo fa.r we have only considered semant ie r(~presental.i-ons which do not involve (lll~uttiliel'S (except I'or theexist(mtial quantif ier introduced by the mechan is t ,~d)ove).In senten(:es with two oF more qmmtiliel;s, there isgenerally ~m ~mabiguity eon(:erning whiC| quantif ierhas wider s(:ope.
1"or exm:nple, in sentence (a) belowtim preferred reading is lbr the same kid to have ('Aim-bed every tree (i.e.
the ml.iversal quanti l ier  is withinthe scope of the existeutia.I) whereas in sentence (b)the preferred reading is where the universal quantif ierhas scope over the existential.7) a A I, ireless kid eliml)ed every tre.e.b There was ~ tish on every l~latc '.Scope prefiwenees omet imes eem to I)c esl, al)lishedbel'ore the end of tz sentence.
\],'or example,  in seutenee(a) below, there s('.ellla a l)referell(:e for all Oll(,er seol)ereading for the first quantif ier as soon as we inl;erl)rel;child.
Ill (13) the i)refereu(:e, by the t ime we get to e.g.gram.mar, is \[~.
)r adl ituwr scope re~ding for the lh:stqu a.ntiller.8) a A te~eher gave every child a great deal of he-.mework Oll gralflnlar.91{ctractlon call be performed by using ~t tagged dattd)ase,whm'e e:tch In'OpOsition is l)alrcd with a sel: ,f s()tll'C(~ (!.~.given (P-~Q,{u4}), and (P,{nS})then(Q,{u4dtS}),:ml I,cdeduced.Z~Ib Every gM in the class showed a rather strictnew teacher the results of her attempt to getthe grammar exercises correct.This intuitive evidence can be backed up by consi-dering garden path effects with quantifier scope tun-biguities (called jungle paths by Barwise 1987).
Theoriginal examples, such ~s the fbllowing,9) Statistics show that every 11 seconds a man ismugged here in New York city.
We are here todayto interview hilnshowed that preferences for a particular scope areestablished and are overturned.
'Po show that pre-ferences are sometimes established before the end of'a sentence, and before a potential sentence nd, weneed to show ga.rden path effects in examples uch asthe following:10) Mary pttt the inIbrmation that statistics showthat every 11 seconds a man is mugged here inNew York city and that she was to interview himin her diaryMost psycholinguistic experimentation has been con-cerned with which scope preferences are made, ratherthan the point at which the preferences are establis-hcd (see e.g.
Kurtzman and MacDonald, 1993).
Giventile illtuitive evidence, our hypothesis is that scopepreferences can sometimes be established early, befbrethe end ofa  sentence.
This leaves open the possibilitythat in other cases, where the scoping inIbrmation isnot particularly of interest o the hearer, preferencesare determined late, if at all.3.1 Inc re lnenta l  Quant i f ie r  Scoping: hnp le -lnent, at ionDealing with quantifiers incrementally is a rather si-mila.r problem to dealing with h'aglnents of trees incre-mentally, a,st  as it is in-,possible to predict the levelof embedding of ~r noun phrase such as John from tilefragment Mary thinL's John, it is also impossible topredict the scope of a quantifier in a fragment withrespect ~o the arbitrarily large number of quantilierswhich might appear later in the sentence.
Again theproblem can be avoided by a tbrm of pacldng.
A par-ticularly simple way of doing this is to use unseopedlogical forms where qmmtifiers are left in situ (silni-lar to the representations u ed by Hobbs and Shieber(1987), or to Quasi Logical Form (Alshawi 1990)).
Forexample, the fl'agment Every man gives a boot" can begiven the tbllowing representation:I1) kz.gives(< V,x,nlan(x)>,< ~,y,book(y)>,z)Each qnantitied term consists of' a quantitier, a va.ria-ble and a restrictor, but, no body.
To convert lambdaexpressions to unscoped propositions, we replace anoccurrence of each argument with an empty existen-tia.l quantitier term.
In this case we obtain:12) gives(< V,X,ITIall(X)>,< 3,y,book(y)>,< -~,z,'l'>)Scoped propositions can then be obtained by using anoutside-in quantifier scoping algorithm (Lewin, 1990),or an inside-out algorithm with a free w~riable con-straint (IIobbs and Shieber, 1987).
The propositionsfbrlncd can then be judged for plausibility.To imitate jungle path phenomena, these pla.usi obility judgements need to feed back into the scopingprocedure for the next fragment.
For example, if' everyman is taken to be scoped outside a book after proces-sing the fragment l?vcry man ga~c.
a book, \[;hen thispreference should be preserved when deterlnining thescope for the full sentence l?very uza~t gave a book loa child.
Thus instead of doing ~dl quantitier scopingat the end of the sentence, each new quantilier is sco-ped relative to the existing quantifiers (and operatorssuch as negation, intensional verbs etc.).
A prelimi-nary irnplemenl, ation achieves this by annotating thesemantic representations with node nantes, a.nd re-cording which quantifiers are 'discharged' at.
whichnodes, and in which order.DYNAMIC SEMANTICSl)ynamic semantics adopts the view that "the mea--ning of a sentence does not lie ill its truth conditi-ons, but rather in the way ill which it changes (tilerepresentation of) the in\[brmation of the intcrl)reter"(Groencndijk and Stokho\[', \]991).
At first glance sucha.
view seems ideally suited t.o incremental interpreta-tion.
Indeed, Groenendijk and Stokhof claim that thecompositional nature o\[' l)ynamic Predicate Logic en-ables one to "interpret a text ir~ an on-line ntauner,i.e., incrementally, processing a.nd interpreting eachbasic unit as it comes along, in the context createdby the  interpretation of the t.ext so fa.r'.Putting these two quotes together is, however, mis-leading, since it suggests a more direct mapping bet-ween incremental sem~mtics and dyna.mh: semanticsthan is actually possible.
In an incremental semantics,we would expect the informtttiou state, of an interpre-ter to be updated word by word.
In contrast, in dyna-mic semantics, the ol:der in which states are updatedis determined by semantic st;ructure, not by left-to-right order (see e.g.
I,ewiu, 1992 \[br discussion).
Forexample, in 1)ynanfic Predicate Logic ((~roenendijk ,~Stokhof, 1991), states are threaded from the antece-dent of a conditional into I, he conseque~d~, and froma restrictor of' a quantitier into I;he body.
Thus, ininterpreting,13) John will buy it right away, if a car impresses himthe input state for evMuation of .John will bug it rightaway is the output state from the a.ntecedent a earhnp,vsses hhn.
in this ease the threading throughsemantic structure is in the opposite order to the orderin which the two clauses appear in the sentence.Some intuitive justification for the direction ofthreading in dynamic semantics is provided by cou-sidering appropriate orders for evaluation of proposi-tions against a database: the natural order in which752l,o cvMual;e a, conditiona,1 is first, 1,o add the antecedenl;,illl(\[ thell see if I.he COllSC(lUOlll, c{i.ll 17c: l)roveli.
\]to is()li ly ai, t i le sentence lew;l iu ,siniple na,rrative texLs0ha,t I,he l)l;esenl;al, ion ordor itl ld I,ho iw, l, ur~d order o\[4"wahl3J;ion necx~s,<sarily coincide.The orderh ig  of a,n~tl)hors and theii: autel:edent, s iso\[l;en used in l 'or inMly/ ,o  jusl, i fy lefl,-l,o-riglll; i, hreadiugor thi:eadil ig through selllaait, ic sl;rtlC(,llrO, l lowew',r,(,\]iroa(lingj fl;Olll \]el'\[,-to-righ{ disa,llows cX;/llllJlcs (3\]" Ol)(;tonal c;d;aphoi;a,, as i l l  example (1'3), mid examI)leso\[' c:oiilpll|sory c,a.l;a,p}lora, a,s ill :14) I lesitle her> every gir l  could see a, large cl:acl~Sitnihu:ly, l;\]irei~ding li 'oin the aui;ccedeui,s o1' conditio--ua, lS into t;he COllSl'x\[llOll\[; fails f'()r (!X31ill)JeS sHCh &s:15) EVC'L'y boy wi l l  be a.I)lc t,(i s(!
(', olLi, <)\[' a window i lhe walll;s I,()I{, is also 1)ossilTle l;o gel; ,SOli{,ellCCS with <(\[Olil,:cy'rea,dhlgs, })ill; whei:c the inde\[inil;c is hi I, hc conse-qllOlil,:\[6) A 81,11de, tit wi l t  a, t teud the COli\['creliCe it' we C(~II ~2~(\]0l;ogei,hoi: enough lliOli(?y \[or her air \[areThis  ,qCli\[;OliCO ,q(!oHis \[;o g(;1L, ;i, reading where we aro liOt,la lk ing  &l)ollb it particul~u' sl0tl(i()tll, (~/11 O\[IL(H' exist, on0ial) ,  or  ~d)Olil; i~ typic~d stu(\]cul, (a geiloric, reading).Mol;0Ovo, i;, as noi;ed by Zcewd; (\] {).90), t;}10 115(!
of ~:lllykind o\[' o.rch?rcd i;hl:0a,dhig wi l l  tend 1;o tail Ibr l~ach-I)el;ers s(}ii\[a'~lll':os~ sllc, h {ts:17) I,;vcry man who loves lwl: a.pl~reciai,es a wonlanwho liw~s with  h imI"or t l i is l,:hid o f  e?ainple,  il, is sti l l  possible t,o il~;C iisl,a, ndard t ly i i t t ln ic SOliH'~.lll;\]c,q~ I)lll; on ly  if  i, hei!e is SOlilepr ior  level of FOt'OI!el\]CC rcsohll; ioi l  which reorders thea.iil;ccedonl, s al ld  a. l la\]) l lors appropr ia te ly .
FOI: c.X;llllI)le, \[\[' (I 7) is converl,ed into  t, he ~(ionl,:ey' selil,el\]ce:1 8) I,\]vel'y ill&It who loves a. wollH/,ll who lives wMi  hi inal)preciai, es hotWhe, n we consider t\]lreading (7\[' possible wor\]ds, ashi (JIMal, e Seuia,ui;\]cs (Ve\ ] tman 19{)0)> l:he noed I;o (\]i-si, inguish bci;woen L\]le orcler o\[ eva,\[uai, ion aitd l;he oi;(ler of I)resentat, ion I)ccolues inore cl(~ar cut,.
(ton,siderI,i:yiug LO 17e\]'l()r\[n i;hroa,dh\]g hi le\['D-l;o-rigiil, Ol:dO..r t l i lr ing in/;el:ITrel, al;iol\] o\ [  l,he s(~ll|;(~ltCO~ ,loire h:fl i f  Margl<ffl,.
Afi, cr processiltg the 1)roposition , ioh, left I;heset, o\[' worlds is refined down to those, worlds in which.lolu~ left, Now consider processing 0 Mary lejT.
\[Ierewe wa,nl; l,o ix;ilti;rodtlce 8OlllC' Wt)i:i(\[S, \[;\]lOSO in whichnoit, hor Ma.ry or &)hn le\['L I lowever,  1,tits is nor allo-wed by {Jpc\[atc ,qenlanl,ics whMl  is ~limilmtiv< cactinew piece of  in\[orma.t, ion cAlli ou ly  l'tii'l,\[lei: i'e\[hic l,hcset; of  worlds.It  is woiq;h l iOl; ing t, hal; I.he diliii:nll,ic!,~ in l;l'3'illg1;0 c, onl l ) ine c\] iui inal; ive seiuaili;ics wi th  le\['tq,o-righl,tlu:e~t(linp; a.pply t,o c, ousl;i:a.illl, basc(l ,Seliiaili,ic.s as weltas I;o Upda,te Sema.ntics.
t laddock (1987) uses iucre.-inentM re{inenient of sets of possible ret~rents, l 'or exainl)le , the ell'cot, of processing t/w rabbit in I;he ttOllliplll'aSc Utc ~ rabbil ht l/to hat is to provide it set of alll;~dol)ii,s.
The pi:oces,sing o\[' i~t I't?IIII(!S this sel~ to ra.b-bil;s which are ill SOlllCl,liillg;.
h'inaHy, proccsSillg o17 \[hc\]lal relines the sol; t,o i:~d)lfits which al:(} ill a. ha, t. I I o"W(\]veI' 1 I1()'~?
COllSid(;r \]l.i'oces,sing th<~ rclblTit 71l #loltc ofthc bomcs.
Ily tile {inie Uu: rabbit in has been proces-so'd, the only ra.bloits i:eula,ining in c.onsidcra,l;ioll arer~d)bits which arc in solncl;hing.
This im:orrecLly l:ule,~(ml, the possibilii, y of the uoun phrase referring to a,I:~d)l)ii, which is in nothing a.l, a.\[l. The case is *u'l;uallya parMle/ to the earlier example of Mary introducedsom, e, olm, to somethin,q being iimpl)rOl)rial;e if the finalsontcncc is Mar.Is i*~h'odtu:cd noonc to asqjbodg.A/ldlough t, hi,s discussion has argued {haA i~ is no1.possilTle to i;hread the sti~t('s which are us(:d by a, ( lyua-l i l le (71" el iHl imigive setlta.ill, ics troll\] 1(;\['1, 1;o i'ip;\[il,, wordby woM,  t;liis s l iould not; Im taken as a.ll a, rgtlfiiOllt,against 1,he ilSf!
0|' SIlC,\[I ;I, ,S(~,IIItI, I I;IcS ill i l/creiitelll;a\[ iit-l;erpretal, ion.
\?hai, is rcqlt ired is it slight, ly IIIOl'O indi-rect al)proach, \[11 the I)l:f.',ql'!ltl, iUll)ielllenlLa, l ioll , SOlllall-I;IC .M,I;tlCI, II'(;S (akin tt7 logica,l f(71HIIS) ;11:(\] bui l t  wordI)y word, allel (;ach StlTIlCtltre i,~ then ewdlta.l;ed indc-pclldcntly tiSillg ~t dynalnit: SOlilltlll, i(:8 (with t;hl;C/i..dili{{l)erf'ornied ~c<:ording I,o t;he sl,rHct;ure of  1;he logica.I\['Orlrl).IMP I ,EMENTATIONAt, present there, is ~r Iimii;cd implenicn/,al;ion, whichi)ertbrui;~ t iuapping from sent, cm'e \['ragmcut.s I;o l'ullyscol)ed Iogi('iL\[ rel)resenta.t, ions.
'1'o i l lustrate its ope-ration, (:ousider the, Ibllowing discourse:19) London has a lower.
Every pa, reni; shows it .. .
.We assume ghat, the \[irst so'hi;once has 1oceu processed,aml coilcentra.l,e on i)ro(:esshig i, he l"ra,glnen{.
The iul--\[)l(:lil(',lll;a,l, iOll COllSiSi,,s (7\[ flVO lnodules:I.
A word- J )y-word hicreiricltl, a,i parser \['or a, lexicldi-sod vcrsioli oi c' del)el/denc, y gl:alltlrlal: (Milward, 1992).
'l'hi,s I;akes f\]:aginettts of sentences and l i iaps them I,oI lnscoped logical forlns.IN I>UT: Ew' , ry  | la ro l l l ;  shows  i tOIJ'I'I>UT:Xz.show(< V,x,pareiit  (x) >,< pronou u,y>,z)2.
A nio(hde which replaces la.inl)di~ a.bstra.ci, c'd varia-.bk~s wil,h cxist;cnl;ial quanl, i\[iers in sil;u.INI)tJT: ()ll|;\[)llt frolli \].
()\[I'I'I~{ST: show(< V,x, l) l trO.l l l ; (x)),<prOllfTI l l t ,y>,<_t,z,T>)~{.
A I)l;OiK)Ull co indexing procedlu:e which replace,si)lX)liOlln varia,1)l<'s w\]l;ll a. val:ia,I)le \[roll l  ghe, s;tlnc son-ICll(;(;~ or froltt the 17recediug COligOxt,.IN  I>lJ'l': ()lll,lTlli;(s) \['i:onl :2 a.ll(I a l ist o\[' wu'ia.bles ava,ilablo \['roln ti le c, ontcxl;.
()\[}TI)/J'I': show(< V~x,17areltl;(x)\]>~w,'< )\],z~'l).'>)7534.
An outs ide- in quantif ier seopiug a lgor i thm basedon l,ewin (1990).\ [NPUT:  Output  fl:om 3.OU'PPUTI:  V(x ,parent  (x),3 (z ,T ,show (x,w,z)))CUll 'PUT2: 3 (z ,T ,V(x ,parent  (x) ,show (x,w,z)))5.
An 'eva luat ion '  procedure based on Lewin (I 992),which takes a logical form conta in ing free variables(such as the w in the LF above), and evahlates it usinga dyualn ie  se,nant ics  in the eontext given by the pre-ceding sentences.
The  outl)ut is a new logical fol:mrepresent ing the context  as a whole, with all variablescorrecLly bottlld.INPUT:  Output (s )  fi'om d, and the eolltext,3 (w,m, tower (w)  &: has ( london ,w) )OUq)PUTI: ~(w,T , tower (w)  & has( london ,w)  8zV(x ,parent (x )  ,3 ( z ,T , show(x ,w,z ) ) ) )OUTPU'I?2: 3(w,T ,~(z ,T , tower (w)  &: has (hmdon,w)& V(x ,parent  (x ) , show (x,w,z)))).
;\~ present, the coverage of modu le  5 is l imited, andmodule  3 is a naive coindexing procedure which al-lows a pronoun to be coindexed with any quantif iedvariable or proper noun in the context  or the currentSelltence.CONCLUSIONSThe  paper described some potent ial  appl icat ions 0\]7 in-cremental  interpretat ion.
It then described the seriesof steps required in mapp ing  fi'Oln initial f ragmentsof sentences to proposi t ions which can I)e judged forplausibil ity.
I,'inally, it argued that  the apparent lyclose re lat ionship between the states used in incre-menta l  semant ics  and dynamic  semant ics  fails to holdI)elt)w the sentence level, and briefly presented a moreindirect way of  us ing dynamic  semant ics  in increinen-tal interpretat ion.REFER,ENCESAlshawi, II.
(1990).
Hesolving Quasi Logical Forms.
Co'mpu-tational Linguistics, 16, p,133-144.Alt;lnann, (\].T.M.
and M.J. Steeclinan (1988).
Interaction wiH~Context during Hmnan Speech Coml)rehension.
Cognition,30, 11.191-238.Barwise, J.
(11987).
Noun Phrases, Generalized QuanLifiersand Allaphors.
\]n P. Gardenfors, F,d., Generalized Quanti-tiers, 11.1-29, Dordrecht: l{eidel.
(Jarletta, J., H. Caley and S. Isard 11993).
A Collection ofSelf-repairs from the Map Task Corl)us.
\]{esearch Heport,HGI{C/TR-,tT, Uniwq'sity of Eclinburgh.Chater, N., M.J. Pickerillg and \]).H.
Milward 11994).
Whatis Increnaental Interpretation?
ms. '15 appear in EdinburghWorking Papers in Cognitive Science.Cooper, H. (1993).
A Note on t;he l/elal;ionship between Lin-guistic :\['heory and Linguistic Engineering.
l{esem'ch Heport,IICI~C/ItP-,t2, University of 13clinburgh.Frazier, L. (1979).
On Cornprehendiny .5'e~tences: SyntacticParsim.\] Strategies.
Ph.D. Thesis, lJnive.rsil~y of Connecticut.l:)uhlished by lilclim,a University I,inguistics Club.Groenendijk, J. and M. Stokhof (1991).
l)ynamic PredicateLogic.
Linguistics and Philosophy, 1~, I).39-100.Gross, 1)., J. Allen and I).
'lYaum (1993).
The THA\[NS 91Dialogues.
TllAINS Technical Nol~e 92-.:l, Computer Selence1)el)i;., University of Hochester.IIadd0ck, N.J. (1987).
Incremental semantic interpretationand incremental syntactic analysis.
Ph.l).
q'hesis, Univer-sity of Edinburgh.\]laddock, N.J. (:\[989).
Computational Models of hmrementa\]Sentant;ic \]nterpretation.
LarLquaqe a~d Cognillve Proces-ses, It, (3/41, Special issue, p.337-368.Hobbs, J.\[I.. and S.M.
Shieber (t987).
An Algorithm fin' (\]e-nerating Quantifier Scoping.
Computational Linguistics,8, t)47-63.Joshi, A,K.
(1987).
An Introduction to Tree AdjoiningC~rammars.
In Mmmster-l/alner, Ed., Mathematics of Lan~guage, Amsterdam: John Benjamins.Just, M. and P. Carl)enter 119801.
A Theory of Headingfrom Eye Fixations to Comprehension.
Psychological Re-view, 87, p.329-354.Kurtzman, H.S.
mad M.C.
MacDonMd 119931. l{esolutionof Quantifier Scope Ambiguities.
Cognition, 48131, p.243-279.l,ewin, i.
(1990).
A Quantifier Scoplng Algorithm wlthcmt aFree Variable Constraint.
In Procccdinos of COLING 90,Helsinki, vol 3, p. 190-194.Lewin, i.
(19921.
Dynamic Quantification i Logic and Com-putathJnal Senlantlcs.
l~esearch reporl;, Centre for (:ogni-tive Science, University of Edinl)urgh,Levelt, W.J.M.
(1983).
Modelling alld Self-Hepair in Speech.Cognition, 1~, p.,t1-10,1.Marcus, M., D. IIindle, and M. Fleck (1983).
D:I'heory:qhlking about Talking about Trees.
Ill Procecdisi.qs of thegist A CL, CamlJridge, Mass.
p.129-130.Marslen-Wilson, W. (1973).
Linguistic Structure and SpeechShadowing at Very Short \],atencies.
Nature, 244 , p.522-523.Mellish, C.S.
119851.
Computer lnterprclation of NaturalLanguage Descriptions.
Chlchester: Ellis Horwood.Milward, D.IL (1991).
Axiomatic (@ammar,Non-Constituent; Coordination, and incremental Interpre-tation.
Ph.D. Thesis, University of Cambridge.Milward, D.R.
(t992).
Dynamics, \])ependency (3rammarand \[ncremental Interpretation.
\[n Proecedinqs of CO-LIN(~ 92, Nanies, vo\] ,t, i).1095-1099.Moortgat, M. (t988).
Catcgorial nve.stigatlons: Logical a,dLinguistic Aspects o/the Lambek Calculus, Dordrecht: Fo-ris.Puhnan, S.G. (1986).
(-~rannnaI'S, Parsers, and Memory IA-mitations.
Language ,nd Co~lnitiv~ l'rotesses, 1(.?
), 1).197-225.Hesnik, P. (19921.
Left-corner Parsing and PsychologicalPlausibility.
In Proceedings of COLING 92, Nantes, vo\[ 1,p.191-197.Shieber, S.M.
and M..Iolu~on (1993).
Variations on Incre-lnental Interpretation..lour~*al of l~sycholinguistic Rese-arch, 2212), I).287-318.Shieher, S.M.
and Y. Schabes (19901.
Synchronous Tree-Adjoining Grammars.
In Proceedings of COLING 90, \[\[el-sinki, vol 3, p.253-258.Stabler, E.P.
1199\[).
Avoid the pedestrian's paradox.
IntL Berwick, S. Abney, and C. Tenny, Eds., Principle-BasedParsing: Computation and Psgcholinguisties.
l(luwer.Steedman, M. (1988).
Colnbinators and Grammars.
InH.
Oehrle et al, Eds., Catcgorial Grammars and Natu-ral Language Structures, pal  %442.Thompson, II., M. Dixon, and J. Lalnping (1991).
Compose-Heduce Parsing.
In Proceedings of the 29th A CL, 11.87-97.Tomita, M. (19851.
Efficient Parsing for Natural Languaqe.Kluwer.Veltman F. (1990).
\])efaults in Update Semantics.
InH.
Kaml), Ed., Conditionals, Defaults and Belief Rcvi.sion,DYANA Report 2.5.A, Uentre for Cog,fitive Science, Uni-versity of Edinburgh.Wirdn, M. (1990).
Incremental Parsing and l{eason Main-ienance.
In Proceedi'a9 s of COLIN(; 90, Helsilfld, vol 3,p.287-292.ZeevaG II.
(1990).
S\[.al.ic Semantics.
in ,J. van Benthem, F,d.,Partial and Dynamic Semantics I, I)YANA Iieport 2.I.A,Centre for Cognitive Science, LTniversity of \]gdlnburgh.754
