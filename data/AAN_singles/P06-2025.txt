Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 191?198,Sydney, July 2006. c?2006 Association for Computational LinguisticsA Modified Joint Source-Channel Model for TransliterationAsif EkbalComp.
Sc.
& Engg.
Deptt.Jadavpur UniversityIndiaekbal_asif12@yahoo.co.inSudip Kumar NaskarComp.
Sc.
& Engg.
Deptt.Jadavpur UniversityIndiasudip_naskar@hotmail.comSivaji BandyopadhyayComp.
Sc.
& Engg.
Deptt.Jadavpur UniversityIndiasivaji_cse_ju@yahoo.comAbstractMost machine transliteration systemstransliterate out of vocabulary (OOV)words through intermediate phonemicmapping.
A framework has beenpresented that allows directorthographical mapping between twolanguages that are of different originsemploying different alphabet sets.
Amodified joint source?channel modelalong with a number of alternatives havebeen proposed.
Aligned transliterationunits along with their context areautomatically derived from a bilingualtraining corpus to generate thecollocational statistics.
The transliterationunits in Bengali words take the patternC+M where C represents a vowel or aconsonant or a conjunct and M representsthe vowel modifier or matra.
The Englishtransliteration units are of the form C*V*where C represents a consonant and Vrepresents a vowel.
A Bengali-Englishmachine transliteration system has beendeveloped based on the proposed models.The system has been trained totransliterate person names from Bengalito English.
It uses the linguisticknowledge of possible conjuncts anddiphthongs in Bengali and theirequivalents in English.
The system hasbeen evaluated and it has been observedthat the modified joint source-channelmodel performs best with a WordAgreement Ratio of 69.3% and aTransliteration Unit Agreement Ratio of89.8%.1 IntroductionIn Natural Language Processing (NLP)application areas such as information retrieval,question answering systems and machinetranslation, there is an increasing need totranslate OOV words from one language toanother.
They are translated throughtransliteration, the method of translating intoanother language by expressing the originalforeign words using characters of the targetlanguage preserving the pronunciation in theiroriginal languages.
Thus, the central problem intransliteration is predicting the pronunciation ofthe original word.
Transliteration between twolanguages, that use the same set of alphabets, istrivial: the word is left as it is.
However, forlanguages that use different alphabet sets, thenames must be transliterated or rendered in thetarget language alphabets.Technical terms and named entities make upthe bulk of these OOV words.
Named entitieshold a very important place in NLP applications.Proper identification, classification andtranslation of named entities are very crucial inmany NLP applications and pose a very bigchallenge to NLP researchers.
Named entities areusually not found in bilingual dictionaries andthey are very productive in nature.
Translation ofnamed entities is a tricky task: it involves bothtranslation and transliteration.
Transliteration iscommonly used for named entities, even whenthe words could be translated.
Different types ofnamed entities are translated differently.Numerical and temporal expressions typicallyuse a limited set of vocabulary words (e.g.,names of months, days of the week etc.)
and canbe translated fairly easily using simpletranslation patterns.
The named entity machinetransliteration algorithms presented in this work191focus on person names, locations andorganizations.
A machine transliteration systemthat is trained on person names is very importantin a multilingual country like India where largename collections like census data, electoral rolland railway reservation information must beavailable to multilingual citizens of the countryin their vernacular.
In the present work, thevarious proposed models have been evaluated ona training corpus of person names.A hybrid neural network and knowledge-basedsystem to generate multiple English spellings forArabic personal names is described in (Arbabi etal., 1994).
(Knight and Graehl, 1998) developeda phoneme-based statistical model using finitestate transducer that implements transformationrules to do back-transliteration.
(Stalls andKnight, 1998) adapted this approach for backtransliteration from Arabic to English for Englishnames.
A spelling-based model is described in(Al-Onaizan and Knight, 2002a; Al-Onaizan andKnight, 2002c) that directly maps English lettersequences into Arabic letter sequences withassociated probability that are trained on a smallEnglish/Arabic name list without the need forEnglish pronunciations.
The phonetics-based andspelling-based models have been linearlycombined into a single transliteration model in(Al-Onaizan and Knight, 2002b) fortransliteration of Arabic named entities intoEnglish.Several phoneme-based techniques have beenproposed in the recent past for machinetransliteration using transformation-basedlearning algorithm (Meng et al, 2001; Jung etal., 2000; Vigra and Khudanpur, 2003).
(Abduljaleel and Larkey, 2003) have presented asimple statistical technique to train an English-Arabic transliteration model from pairs of names.The two-stage training procedure first learnswhich n-gram segments should be added tounigram inventory for the source language, andthen a second stage learns the translation modelover this inventory.
This technique requires noheuristic or linguistic knowledge of eitherlanguage.
(Goto et al, 2003) described an English-Japanese transliteration method in which anEnglish word is divided into conversion unitsthat are partial English character strings in anEnglish word and each English conversion unit isconverted into a partial Japanese Katakanacharacter string.
It calculates the likelihood of aparticular choice of letters of chunking intoEnglish conversion units for an English word bylinking them to Katakana characters usingsyllables.
Thus the English conversion unitsconsider phonetic aspects.
It considers theEnglish and Japanese contextual informationsimultaneously to calculate the plausibility ofconversion from each English conversion unit tovarious Japanese conversion units using a singleprobability model based on the maximumentropy method.
(Haizhou et al, 2004) presented a frameworkthat allows direct orthographical mappingbetween English and Chinese through a jointsource-channel model, called n-gramtransliteration model.
The orthographicalignment process is automated using themaximum likelihood approach, through theExpectation Maximization algorithm to derivealigned transliteration units from a bilingualdictionary.
The joint source-channel model triesto capture how source and target names can begenerated simultaneously, i.e., the contextinformation in both the source and the targetsides are taken into account.A tuple n-gram transliteration model (Marinoet al, 2005; Crego et al, 2005) has been log-linearly combined with feature functions todevelop a statistical machine translation systemfor Spanish-to-English and English-to-Spanishtranslation tasks.
The model approximates thejoint probability between source and targetlanguages by using trigrams.The present work differs from (Goto et al,2003; Haizhou et al, 2004) in the sense thatidentification of the transliteration units in thesource language is done using regularexpressions and no probabilistic model is used.The proposed modified joint source-channelmodel is similar to the model proposed by (Gotoet.
al., 2003) but it differs in the way thetransliteration units and the contextualinformation are defined in the present work.
Nolinguistic knowledge is used in (Goto et al,2003; Haizhou et al, 2004) whereas the presentwork uses linguistic knowledge in the form ofpossible conjuncts and diphthongs in Bengali.The paper is organized as follows.
Themachine transliteration problem has beenformulated under both noisy-channel model andjoint source-channel model in Section 2.
Anumber of transliteration models based oncollocation statistics including the modified jointsource-channel model and their evaluationscheme have been proposed in Section 3.
TheBengali-English machine transliteration scenariohas been presented in Section 4.
The proposed192models have been evaluated and the result ofevaluation is reported in Section 5.
Theconclusion is drawn in Section 6.2 Machine Transliteration and JointSource-Channel ModelA transliteration system takes as input a characterstring in the source language and generates acharacter string in the target language as output.The process can be conceptualized as two levelsof decoding: segmentation of the source stringinto transliteration units; and relating the sourcelanguage transliteration units with units in thetarget language, by resolving differentcombinations of alignments and unit mappings.The problem of machine transliteration has beenstudied extensively in the paradigm of the noisychannel model.For a given Bengali name B as the observedchannel output, we have to find out the mostlikely English transliteration E that maximizesP(E?B).
Applying Bayes?
rule, it means to findE to maximizeP(B,E) = P(B?E) * P(E)                             (1)with equivalent effect.
This is equivalent tomodelling two probability distributions: P(B|E),the probability of transliterating E to B through anoisy channel, which is also calledtransformation rules, and P(E), the probabilitydistribution of source, which reflects what isconsidered good English transliteration ingeneral.
Likewiswe, in English to Bengali (E2B)transliteration, we could find B that maximizesP(B,E) = P(E?B) * P(B)                               (2)for a given English name.
In equations (1) and(2), P(B) and P(E) are usually estimated using n-gram language models.
Inspired by researchresults of grapheme-to-phoneme research inspeech synthesis literature, many have suggestedphoneme-based approaches to resolving P(B?E)and P(E?B), which approximates the probabilitydistribution by introducing a phonemicrepresentation.
In this way, names in the sourcelanguage, say B, are converted into anintermediate phonemic representation P, and thenthe phonemic representation is further convertedinto the target language, say English E. InBengali to English (B2E) transliteration, thephoneme-based approach can be formulated asP(E?B) = P(E?P) * P(P?B) and conversely wehave P(B?E) = P(B?P) * P(P?E) for E2B back-transliteration.However, phoneme-based approaches arelimited by a major constraint that couldcompromise transliteration precision.
Thephoneme-based approach requires derivation ofproper phonemic representation for names ofdifferent origins.
One may need to preparemultiple language-dependent grapheme-to-phoneme(G2P) and phoneme-to-grapheme(P2G)conversion systems accordingly, and that is noteasy to achieve.In view of close coupling of the source andtarget transliteration units, a joint source-channelmodel, or n-gram transliteration model (TM) hasbeen proposed in (Haizhou et al, 2004).
For Kalligned transliteration units, we haveP(B,E) = P(b1, b2.....bk, e1, e2......ek )= P (<b,e>1, <b,e>2, .....<b,e>k)K= ?
P ( <b,e>k?
<b,e>1k-1)               (3)k=1which provides an alternative to the phoneme-based approach for resolving equations (1) and(2) by eliminating the intermediate phonemicrepresentation.Unlike the noisy-channel model, the jointsource-channel model does not try to capturehow source names can be mapped to targetnames, but rather how source  and target namescan be generated simultaneously.
In other words,a joint probability model is estimated  that can beeasily marginalized in order to yield conditionalprobability models for both transliteration  andback-transliteration.Suppose that we have a Bengali name ?
=x1x2............xm  and an English transliteration ?
=y1y2........yn where xi, i = 1: m are Bengalitransliteration units and yj, j = 1: n are Englishtransliteration units.
An English transliterationunit may correspond to zero, one or more thanone transliteration unit in Bengali.
Often thevalues of m and n are different.x1 x2x3..... xi-1xixi+1....xmy1      y2 ..yi .... ynwhere there exists an alignment ?
with <b,e>1= <x1,y1>; <b,e>2 = <x2x3, y2>; ?.
and <b,e>k =<xm,yn>.
A transliteration unit correspondence<b, e> is called a transliteration pair.
Thus B2Etransliteration can be formulated as?
= argmax P (?, ?, ? )
(4)?, ?and similarly the E2B back-transliteration as193?
= argmax P (?, ?, ? )
(5)?, ?An n-gram transliteration model is defined asthe conditional probability or transliterationprobability of a transliteration pair <b, e>kdepending on its immediate n predecessor pairs:P (B, E) = P (?, ?, ?
)K= ?
P ( <b, e>k?
<b, e>k-n+1k-1)     (6)k=13 Proposed Models and EvaluationSchemeMachine transliteration has been viewed as asense disambiguation problem.
A number oftransliteration models have been proposed thatcan generate the English transliteration from aBengali word that is not registered in anybilingual or pronunciation dictionary.
TheBengali word is divided into TransliterationUnits (TU) that have the pattern C+M, where Crepresents a vowel or a consonant or conjunctand M represents the vowel modifier or matra.An English word is divided into TUs that havethe pattern C*V*, where C represents aconsonant and V represents a vowel.
The TUsare considered as the lexical units for machinetransliteration.
The system considers the Bengaliand English contextual information in the formof collocated TUs simultaneously to calculate theplausibility of transliteration from each BengaliTU to various English candidate TUs andchooses the one with maximum probability.
Thisis equivalent to choosing the most appropriatesense of a word in the source language to identifyits representation in the target language.
Thesystem learns the mappings automatically fromthe bilingual training corpus guided by linguisticfeatures.
The output of this mapping process is adecision-list classifier with collocated TUs in thesource language and their equivalent TUs incollocation in the target language along with theprobability of each decision obtained from atraining corpus.
The machine transliteration ofthe input Bengali word is obtained using directorthographic mapping by identifying theequivalent English TU for each Bengali TU inthe input and then placing the English TUs inorder.
The various proposed models differ in thenature of collocational stastistics used duringmachine transliteration process: monogrammodel with no context, bigram model withprevious (with respect to the current TU to betransliterated) source TU as the context, bigrammodel with next source TU as the context,bigram model with previous source and targetTUs as the context (this is the joint sourcechannel model), trigram model with previous andnext source TUs as the context and the modifiedjoint source-channel model with previous andnext source TUs and the previous target TU asthe context.?
Model AIn this model, no context is considered ineither the source or the target side.
This isessentially the monogram model.KP(B,E) = ?
P(<b,e>k)k=1?
Model BThis is essentially a bigram model withprevious source TU, i.e., the source TU occurringto the left of the current TU to be transliterated,as the context.KP(B,E) = ?
P(<b,e>k | bk-1)k=1?Model CThis is  essentially a bigram model with nextsource TU, i.e., the source TU occurring to theright of the current TU to be transliterated, as thecontext.KP(B,E) =  ?
P(<b,e>k?
bk+1 )k=1?
Model DThis is essentially the joint source-channelmodel where the previous TUs in both the sourceand the target sides are considered as the context.The previous TU on the target side refers to thetransliterated TU to the immediate left of thecurrent target TU to be transliterated.KP(B,E) =  ?
P( <b,e>k ??
| <b,e>k-1)k=1194?
Model EThis is basically the trigram model where theprevious and the next source TUs are consideredas the contextKP(B,E) =  ?
P(<b,e>k | bk-1, bk+1)k=1?
Model FIn this model, the previous and the next TUs inthe source and the previous target TU areconsidered as the context.
This is the modifiedjoint source-channel model .KP(B,E) = ?
P (<b,e>k | <b,e>k-1, bk+1)k=1The performance of the system is evaluated interms of Transliteration Unit Agreement Ratio(TUAR) and Word Agreement Ratio (WAR)following the evaluation scheme in (Goto et al,2003).
The evaluation parameter CharacterAgreement Ratio in (Goto et al, 2003) has beenmodified to Transliteration Unit AgreementRatio as vowel modifier matra symbols inBengali words are not independent and mustalways follow a consonant or a conjunct in aTransliteration Unit.
Let, B be the input Bengaliword, E be the English transliteration given bythe user in open test and E/ be the systemgenerates the transliteration..TUAR is defined as,TUAR = (L-Err)/ L, where L is the number ofTUs in E, and Err is the number of wronglytransliterated TUs in E/ generated by the system.WAR is defined as, WAR= (S-Err/) / S, where Sis the test sample size and Err/ is is the number oferroneous names generated by the system (whenE/ does not match with E).
Each of these modelshas been evaluated with linguistic knowledge ofthe set of possible conjuncts and diphthongs inBengali and their equivalents in English.
It hasbeen observed that the Modified Joint SourceChannel Model with linguistic knowledgeperforms best in terms of Word Agreement Ratioand Transliteration Unit Agreement Ratio.4 Bengali-English MachineTransliterationTranslation of named entities is a tricky task: itinvolves both translation and transliteration.Transliteration is commonly used for namedentities, even when the words could be translated[LXT??
V_ (janata dal) is translated to Janata Dal(literal translation) although LXT??
(Janata) andV_ (Dal) are vocabulary words].
On the otherhand ^?V[?Y??[?
?[?
?`?[?V?
?_?^  (jadavpurviswavidyalaya) is translated to JadavpurUniversity in which ^?V[?Y??[?
(Jadavpur) istransliterated to Jadavpur and ?[?
?`?[?V?
?_?^(viswavidyalaya) is translated to University.A bilingual training corpus has been kept thatcontains entries mapping Bengali names to theirrespective English transliterations.
Toautomatically analyze the bilingual trainingcorpus to acquire knowledge in order to map newBengali names to English, TUs are extractedfrom the Bengali names and the correspondingEnglish names, and Bengali TUs are associatedwith their English counterparts.Some examples are given below:%?\?X?VX (abhinandan) ?
[% | ?\?
| X | ?V | X]abhinandan  ?
[a | bhi | na | nda | n ]E??b?]??T??
(krishnamoorti) ?
[E??
| b?
| ]?
| ?T??
]krishnamurthy ?
[ kri | shna | mu | rthy ]?`?E?????
(srikant) ?
[ ?`?
| E??
| ???
]srikant ?
[ sri | ka | nt ]After retrieving the transliteration units from aBengali-English name pair, it associates theBengali TUs to the English TUs along with theTUs in context.For example, it derives the followingtransliteration pairs or rules from the name-pair:?[??[??
?V?X?U (rabindranath)  ?
rabindranathSource Language                 Target Languageprevious TU  TU  next TU       previous TU    TU-            ?[?
[??
?
-                ra?
[          [??
?V?
?
ra               bi[??
?V?
X?
?
bi             ndra?V?
X?
U    ?
ndra            naX?
U       -    ?
na              th195But, in some cases, the number oftransliteration units retrieved from the Bengaliand English words may differ.
The [ [??L?
]?c?X(brijmohan) ?
brijmohan ] name pair yields  5TUs  in Bengali side and  4 TUs in English side[ [??
| L | ?]?
| c?
| X ?
bri | jmo | ha | n].
In suchcases, the system cannot align the TUsautomatically and linguistic   knowledge is usedto resolve the confusion.
A knowledge base thatcontains a list of Bengali conjuncts anddiphthongs and their possible Englishrepresentations has been kept.
The hypothesisfollowed in the present work is that the problemTU in the English side has always the maximumlength.
If more than one English TU has thesame length, then system starts its analysis fromthe first one.
In the above example, the TUs briand jmo have the same length.
The systeminteracts with the knowledge base and ascertainsthat bri is valid and jmo cannot be a valid TU inEnglish since there is no corresponding conjunctrepresentation in Bengali.
So jmo is split up into2 TUs j and mo, and the system aligns the 5 TUsas [[??
| L | ?]?
| c?
| X ?
bri | j | mo | ha | n].Similarly, [?_?E?X?U (loknath) ?
loknath] isinitially split as [ ?_?
| E?
| X?
| U ]   ?
lo | kna |th], and then as [ lo | k | na | th ] since kna has themaximum length and it does not have any validconjunct representation in Bengali.In some cases, the knowledge of Bengalidiphthong resolves the problem.
In the followingexample, [ ?[??
| + | ]?
(raima) ?
rai | ma], thenumber of TUs on both sides do notmatch.
The English TU rai is chosen for analysisas its length is greater than the other TU ma.
Thevowel sequence ai corresponds to a diphthong inBengali that has two valid representations < %?+,B >.
The first representation signifies that amatra is associated to the previous characterfollowed by the character +.
This matches thepresent Bengali input.
Thus, the English vowelsequence ai is separated from the TU rai (rai ?
r| ai) and the intermediate form of the name pairappears to be [?[??
| + | ]?
(raima) ?
r | ai | ma].Here, a matra is associated with the Bengali TUthat corresponds to English TU r and so theremust be a vowel attached with the TU r. TU ai isfurther splitted as a and i (ai ?
a | i) and the firstone (i.e.
a) is assimilated with the previous TU(i.e.
r) and finally the name pair appears as: [ ?[??
|+ | ]?
(raima) ?
ra | i | ma].In the following two examples, the number ofTUs on both sides does not match.
[ ?V | [?
| ?[??
| L (devraj)    ?
de | vra | j ][ ?a?
| ] | X?
| U (somnath) ?
so | mna | th]It is observed that both vr and mn representvalid conjuncts in Bengali but these examplescontain the constituent Bengali consonants inorder and not the conjunct representation.
Duringthe training phase, if, for some conjuncts,examples with conjunct representation areoutnumbered by examples with constituentconsonants representation, the conjunct isremoved from the linguistic knowledge base andtraining examples with such conjunctrepresentation are moved to a Direct examplebase which contains the English words and theirBengali transliteration.
The above two namepairs can then be realigned as[ ?V | [?
| ?[??
| L (devraj)    ?
de | v | ra | j ][ ?a?
| ] | X?
| U (somnath) ?
so | m | na | th]Otherwise, if such conjuncts are included inthe linguistic knowledge base, training exampleswith constituent consonants representation are tobe moved to the Direct example base.The Bengali names and their Englishtransliterations are split into TUs in such a waythat, it   results in a one-to-one correspondenceafter using the linguistic information.
But insome       cases there exits zero-to-one or many-to-one relationship.
An example of Zero-to-Onerelationship [?
?
h] is the name-pair [%?
| {?
(alla) ?
a | lla | h] while the name-pair [%?
| + |?\?
(aivy)   ?
i | vy] is an example of Many-to-One relationship [%?, + ?
i].
These bilingualexamples should also be included in the Directexample base.In some cases, the linguistic knowledgeapparently solves the mapping problem, but notalways.
From the name-pair [[??[?F?
(barkha) ?barkha], the system initially generates themapping [[?
| ?[?
| F?
?
ba | rkha] which is notone-to-one.
Then it consults the linguisticknowledge base and breaks up the transliterationunit as (rkha ?
rk | ha ) and generates the final196aligned transliteration pair [[?
| ?[?
| F?
?
ba | rk |ha ] (since it finds out that rk has a valid conjunctrepresentation in Bengali but not rkh), which isan incorrect transliteration pair to train   thesystem.
It should have been [[?
| ?[?
| F?
?
ba | r |kha].
Such type of errors can be detected byfollowing the alignment process from the targetside during the training phase.
Such trainingexamples may be either manually aligned ormaintained in the Direct Example base.5 Results of the Proposed ModelsApproximately 6000 Indian person names havebeen collected and their English transliterationshave been stored manually.
This set acts as thetraining corpus on which the system is trained togenerate the collocational statistics.
Thesestatistics serve as the decision list classifier toidentify the target language TU given the sourcelanguage TU and its context.
The system alsoincludes the linguistic knowledge in the form ofvalid conjuncts and diphthongs in Bengali andtheir English representation.All the models have been tested with an opentest corpus of about 1200 Bengali names thatcontains their English transliterations.
The totalnumber of transliteration units (TU) in these1200 (Sample Size, i.e., S) Bengali names is4755 (this is the value of L), i.e., on an average aBengali name contains 4 TUs.
The test set wascollected from users and it was checked that itdoes not contain names that are present in thetraining set.
The total number of transliterationunit errors (Err) in the system-generatedtransliterations and the total number of wordserroneously generated (Err/) by the system havebeen shown in Table 1 for each individual model.The models are evaluated on the basis of the twoevaluation metrics, Word Agreement Ratio(WAR) and Transliteration Unit AgreementRatio (TUAR).
The results of the tests in termsof the evaluation metrics are shown in Table 2.The modified joint source-channel model (ModelF) that incorporates linguistic knowledgeperforms best among all the models with a WordAgreement Ratio (WAR) of 69.3% and aTransliteration Unit Agreement Ratio (TUAR) of89.8%.
The joint source-channel model withlinguistic knowledge (Model D) has notperformed well in the Bengali-English machinetransliteration whereas the trigram model (ModelE) needs further attention as its result arecomparable to the modified joint source-channelmodel (Model F).
All the models were also testedfor back-transliteration, i.e., English to Bengalitransliteration, with an open test corpus of 1000English names that contain their Bengalitransliterations.
The results of these tests in termsof the evaluation metrics WAR and TUAR areshown in Table 3.
It is observed that themodified joint source-channel model performsbest in back-transliteration with a WAR of67.9% and a TUAR of 89%.Model Error in TUs(Err)Error words(Err/)A 990 615B 795 512C 880 532D 814 471E 604 413F 486 369Table 1: Value of Err and Err/ for each model(B2E  transliteration)Model WAR(in %)TUAR(in %)A 48.8 79.2B 57.4 83.3C 55.7 81.5D 60.8 82.9E 65.6 87.3F 69.3 89.8Table 2: Results with Evaluation Metrics(B2E  transliteration)Model WAR(in %)TUAR(in %)A 49.6 79.8B 56.2 83.8C 53.9 82.2D 58.2 83.2E 64.7 87.5F 67.9 89.0Table 3: Results with Evaluation Metrics(E2B transliteration)6.
ConclusionIt has been observed that the modified jointsource-channel model with linguistic knowledgeperforms best in terms of Word Agreement Ratio(WAR) and Transliteration Unit AgreementRatio (TUAR).
Detailed examination of the197evaluation results reveals that Bengali hasseparate short and long vowels and thecorresponding matra representation while thesemay be represented in English by the samevowel.
It has been observed that most of theerrors are at the matra level i.e., a short matramight have been replaced by a long matra or viceversa.
More linguistic knowledge is necessary todisambiguate the short and the long vowels andthe matra representation in Bengali.
The systemincludes conjuncts and diphthongs as part of thelinguistic knowledge base.
Triphthongs ortetraphthongs usually do not appear in Indiannames.
But, inclusion of them will enable thesystem to transliterate those few names that mayinclude them.
The models are to be trainedfurther on sets of additional person names fromother geographic areas.
Besides person names,location and organization names are also to beused for training the proposed models.AcknowledgementOur thanks go to Council of Scientific andIndustrial Research, Human ResourceDevelopment Group, New Delhi, India forsupporting Sudip Kumar Naskar under SeniorResearch Fellowship Award (9/96(402) 2003-EMR-I).ReferencesAbdul Jaleel Nasreen and Leah S. Larkey.
2003.Statistical Transliteration for English-Arabic CrossLanguage Information Retrieval.
Proceedings ofthe Twelfth International Conference onInformation and Knowledge Management (CIKM2003), New Orleans, USA, 139-146.Al-Onaizan Y. and Knight K. 2002a.
Named EntityTranslation: Extended Abstract.
Proceedings of theHuman Language Technology Conference (HLT2002), 122-124.Al-Onaizan Y. and Knight K.2002b.
TranslatingNamed Entities Using Monolingual and BilingualResources.
Proceedings of the 40th AnnualMeeting of the ACL (ACL 2002), 400-408.Al-Onaizan Y. and Knight K. 2002c.
MachineTransliteration of Names in Arabic Text.Proceedings of the ACL Workshop onComputational Approaches to Semitic Languages.Arbabi Mansur, Scott M. Fischthal, Vincent C.Cheng, and Elizabeth Bar.
1994.
Algorithms forArabic name transliteration.
IBM Journal ofResearch and Development, 38(2): 183-193.Crego J.M., Marino J.B. and A. de Gispert.
2005.Reordered Search and Tuple Unfolding for Ngram-based SMT.
Proceedings of the MT-Summit X,Phuket, Thailand, 283-289.Marino J.
B., Banchs R., Crego J. M., A. de Gispert,P.
Lambert, J.
A. Fonollosa and M. Ruiz, BilingualN-gram Statistical Machine Translation.Proceedings of the MT-Summit X, Phuket,Thailand, 275-282.Goto I., N. Kato, N. Uratani, and T. Ehara.
2003.Transliteration considering Context Informationbased on the Maximum Entropy Method.Proceeding of the MT-Summit IX, New Orleans,USA, 125?132.Haizhou Li, Zhang Min, Su Jian.
2004.
A JointSource-Channel Model for MachineTransliteration.
Proceedings of the 42nd AnnualMeeting of the ACL (ACL 2004), Barcelona,Spain, 159-166.Jung Sung Young, Sung Lim Hong, and Eunok Paek.2000.
An English to Korean Transliteration Modelof Extended Markov Window.
Proceedings ofCOLING 2000, 1, 383-389.Knight K. and J. Graehl.
1998.
MachineTransliteration, Computational Linguistics, 24(4):599-612.Meng Helen M., Wai-Kit Lo, Berlin Chen and KarenTang.
2001.
Generating Phonetic Cognates tohandle Name Entities in English-Chinese Cross-language Spoken Document Retrieval.
Proceedingsof the Automatic Speech Recognition andUnderstanding (ASRU) Workshop, Trento, Italy.Stalls, Bonnie Glover and Knight K. 1998.Translating names and technical terms in Arabictext.
Proceedings of the COLING/ACL Workshopon Computational Approaches to SemiticLanguages, Montral, Canada, 34-41.Virga Paola and Sanjeev Khudanpur.
2003.Transliteration of Proper Names in CrosslingualInformation Retrieval.
Proceedings of the ACL2003 Workshop on Multilingual and Mixed-language Named Entity Recognition, Sapporo,Japan, 57-60.198
