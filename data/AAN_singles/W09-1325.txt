Proceedings of the Workshop on BioNLP, pages 193?200,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsSemantic Annotation of Papers: Interface & Enrichment Tool (SAPIENT)Maria Liakata?, Claire Q?
?, Larisa N.
Soldatova??
?Department of Computer ScienceUniversity of Wales, AberystwythSY23 3DB UK?mal@aber.ac.uk, ?
?ceq08@aber.ac.uk, ??
?lss@aber.ac.ukAbstractIn this paper we introduce a web application(SAPIENT) for sentence based annotation offull papers with semantic information.
SAPI-ENT enables experts to annotate scientific pa-pers sentence by sentence and also to link re-lated sentences together, thus forming spansof interesting regions, which can facilitate textmining applications.
As part of the system,we developed an XML-aware sentence split-ter (SSSplit) which preserves XML markupand identifies sentences through the additionof in-line markup.
SAPIENT has been usedin a systematic study for the annotation ofscientific papers with concepts representingthe Core Information about Scientific Papers(CISP) to create a corpus of 225 annotated pa-pers.1 IntroductionGiven the rapid growth in the quantity of scientificliterature, particularly in the Biosciences, there isan increasing need to work with full papers ratherthan abstracts, both to identify their key contribu-tions and to provide some automated assistance toresearchers (Karamanis et al, 2008; Medlock andBriscoe, 2007).
Initiatives like OTMI1, which aimto make full papers available to researchers for textmining purposes is further evidence that relyingsolely on abstracts presents important limitations forsuch tasks.
A recent study on whether informationretrieval from full text is more effective than search-ing abstracts alone (Lin Jimmy, 2009) showed that1http://opentextmining.org/wiki/Main Pagethe former is indeed the case.
Their experimental re-sults suggested that span-level analysis is a promis-ing strategy for taking advantage of the full papers,where spans are defined as paragraphs of text as-sessed by humans and deemed to be relevant to oneof 36 pre-defined topics.
Therefore, when workingwith full papers, it is important to be able to iden-tify and annotate spans of text.
In previous research,sentence based annotation has been used to identifytext regions with scientific content of interest to theuser (Wilbur et al, 2006; Shatkay et al, 2008) orzones of different rhetorical status (AZ) (Teufel andMoens, 2002).
Sentences are the structural units ofparagraphs and can be more flexible than paragraphsfor text mining purposes other than information re-trieval.Current general purpose systems for linguistic an-notation such as Callisto2 allow the creation of asimple annotation schema that is a tag set augmentedwith simple (e.g.
string) attributes for each tag.Knowtator (Ogren, 2006) is a plug-in of the knowl-edge representation tool Prote?ge?3, which works asa general purpose text annotation tool and has theadvantage that it can work with complex ontology-derived schemas.
However, these systems are notparticularly suited to sentence by sentence annota-tion of full papers, as one would need to highlightentire sentences manually.
Also these systems workmainly with plain text, so they do not necessarilyinterpret the structural information already availablein the paper, which can be crucial to annotation deci-sions for the type of high level annotation mentioned2http://callisto.mitre.org/manual/use.html3http://protege.stanford.edu/193above.
The OSCAR3 (Corbett et al, 2007) tool forthe recognition and annotation of chemical namedentities fully displays underlying paper informationin XML but is not suited to sentence by sentence an-notation.To address the above issues, we present a sys-tem (SAPIENT) for sentence by sentence annota-tion of scientific papers which supports ontology-motivated concepts representing the core informa-tion about scientific papers (CISP) (Soldatova andLiakata, 2007).
An important aspect of the system isthat although annotation is sentence based, the sys-tem caters for identifiers, which link together sen-tences pertaining to the same concept.
This wayspans of interest or key regions are formed.
SAPI-ENT also incorporates OSCAR3 capability for theautomatic recognition of chemical named entitiesand runs within a browser, which makes it platformindependent.
SAPIENT takes as input full scien-tific papers in XML, splits them into individual sen-tences, displays them and allows the user to anno-tate each sentence with one of 11 CISP concepts aswell as link the sentence to other sentences refer-ring to the same instance of the concept selected.The system is especially suitable for so called multi-dimensional annotation (Shatkay et al, 2008) orontology-motivated annotation, where a label origi-nates from a class with properties.
SAPIENT is cur-rently being employed by 16 Chemistry experts todevelop a corpus of scientific papers (ART Corpus)annotated with Core Information about ScientificPapers (CISP) covering topics in Physical Chemistryand Biochemistry.2 SAPIENT System DescriptionWe chose to implement SAPIENT as a web appli-cation, so as to make it platform independent andeasier to incorporate as part of an online workflow.We have used state of the art web technologies todevelop SAPIENT, namely Java, Javascript (withAsynchronous JavaScript and XML (AJAX) func-tionality), XSLT, CSS and XML.
The system has aclient-server architecture (see Figure 1), with pa-pers being uploaded and stored on the server butfunctionality for annotation contained in Javascript,which runs client-side in the browser.
This is in-spired by but in contrast with OSCAR3 (Corbettet al, 2007), which also allows manual annota-tion alongside the automated annotation of chemicalnamed entities, but where each minor edit is savedto the server, writing to a file.
We chose to makemore of the functionality client-side in order to re-duce the number of server requests, which could be-come problematic if the system became widely dis-tributed.SAPIENT ArchitectureUser Input Browser XML HttprequestresponseClick on paperPaper in.xml Page for paper upload &links to uploadedpapersPaper displayedin dynamic htmlJavascript basedannotation with CISP   Processing    with .xslClick on SaveServerAnnotations savedIn mode2.xmlPaper saved as source.xml1) Paper is splitinto sentenceswith SSSplit2) Paper savedas mode2.xmlOSCAR annotationsFigure 1: Architecture of the SAPIENT SystemSAPIENT has been designed to take as input fullpapers in XML, conforming to the SciXML schema(Rupp et al, 2006)(see Section 3).To view or annotate a paper, a user must first up-load it.
The index page of SAPIENT shows a listof papers already uploaded (available as links) andan interface for uploading more papers (See Figure2).
Once the user selects a link to a paper, the pa-per is split into sentences using the XML-aware sen-tence splitter SSSplit which we have developed (Seesection 4) and is included in the server-side Java.The resultant XML file is stored alongside the origi-nal upload.
Sentence splitting involves detecting theboundaries of sentences and, in this context, mark-ing the latter by inline <s></s> tags added to theoriginal XML.
The <s></s> tags contain an id at-tribute enumerating the sentence.After sentence splitting, the new XML filecontaining sentence boundaries marked by <sid=#NUM>< /s> tags is parsed by XSLT intoHTML, so that it displays in the browser.
In theHTML interface dynamically generated in this way,Javascript annotation drop-downs are available for194Figure 2: Index page of the SAPIENT Systemeach sentence.
The user can perform annotationsby selecting items from the drop-downs and all thecorresponding annotation information is stored inJavascript until a request to save is made by the user.The Javascript drop-downs allow annotation attwo levels (Figure 3), enabling a sentence to have asemantic label (type) with properties (subtypes) andan identifier (conceptID).In the current implementation of SAPIENT, Thetype drop-down value corresponds to the selectionof one out of 11 general scientific concepts (Li-akata and Soldatova, 2008), namely (?Background?,?Conclusion?, ?Experiment?, ?Goal of the Investi-gation?, ?Hypothesis?,?Method?, ?Model?, ?Motiva-tion?, ?Object of the Investigation?, ?Observation?,?Result?).
These labels originate from a set ofmeta-data (The Core Information about ScientificConcepts (CISP) (Soldatova and Liakata, 2007)which were constructed using an ontology method-ology, based on an ontology of experiments EXPO(Soldatova and King, 2006).
Because these labelsmap to ontology classes, they can also have prop-erties.
For example, ?Method?
has the property?New?/?Old?,?Advantage?/?Disadvantage?.
Theseproperties are dependent on the type selected andare expressed in terms of the subtype drop-down.The third drop-down, concept ID allows a user toprovide a concept identifier.
The latter is an entityformed by the name of a concept and a number (e.g.?Res2?).
Concept identifiers uniquely identify an in-stance of a concept (e.g.
the second Result), but nota sentence.
That is, concept identifiers designate andlink together instances of the same semantic con-cept, spread across different sentences, which canbe in different parts of the paper.
For example, thesecond result (?Res2?)
can be referred to by 1 sen-tence in the abstract, 5 sentences in the Discussionand 2 sentences in the Conclusion sections.The distinction between sentence identifiers andconcept identifiers is an important characteristic ofthe system.
It means that the system does not neces-sarily assume a ?1-1?
correspondence between a sen-tence and a concept, but rather that concepts can berepresented by spans of often disjoint text.
There-fore, SAPIENT indirectly allows the annotation ofdiscourse segments beyond the sentence level andalso keeps track of co-referring sentences.2.1 SAPIENT UsabilityEven though SAPIENT has been primarily designedto work with CISP concepts, it can be used to an-notate papers according to any sentence based anno-tation scheme.
Changes required can be easily per-formed by modifying the XSL sheet which dynami-cally generates HTML from XML and organises thestructure of drop-down menus.
Automated noun-phrase based annotation from existing ontologiesis available to SAPIENT users through OSCAR3(Corbett et al, 2007), since SAPIENT incorporatesOSCAR3 functionality for chemical named entityrecognition.
The latter is implemented as a linkwhich when selected calls the OSCAR3 workflow(integrated in the system) to automatically recognisechemical named entities (NEs) (See Figure 5).When all annotations (both sentence based andchemical NEs) are saved to the server, a new ver-sion of the XML file is produced, which containsin-line annotation for sentences as well as extra in-line annotation for the semantic concepts and NEsembedded within <s></s> tags.
These annotationtags are compliant with the SciXML schema (Ruppet al, 2006) and in the case of sentence-based anno-tations are of the form:<annotationART atype=??GSC??type=#TYPEconceptID=#CONCEPTIDnovelty=??Yes/No??advantage=??Yes/No?
?</annotationART>(See Figure 4).
The attribute type, stands for theCISP concept selected for the sentence in question.The conceptID attribute is an enumerator of the par-ticular concept, which the sentence refers to.
For195example, two different sentences will have differ-ent sentence ids but if they refer to the same con-cept (e.g.
the same ?Conclusion?)
, they will beassigned the same concept ID (e.g.
?Con3?).
Theattributes novelty and advantage, are properties ofthe concepts assigned to a sentence and dependon the concept selection.
They take boolean val-ues or the dummy value ?None?
if the propertiesare not defined for a particular concept.
For ex-ample, these attributes are relevant when the con-cept selected is a ?Method?, in which case themethod can be ?New/Old?
and/or have an ?Advan-tage/Disadvantage?.
The novelty and advantage at-tributes co-exist in the annotation (as can be seen inFigure 4) but they are not set by the system at thesame time.
For instance, if a sentence refers to a newmethod, it will be given the type ?Method?
and thesubtype ?New?
; this sets the novelty attribute in theunderlying XML to ?Yes?
and leaves the advantageattribute set to the default ?None?.
The sentence willalso be given a conceptID, e.g.
?Met1?.
If anothersentence refers to an advantage of this method, thenthe new sentence will be assigned the type ?Method?,the subtype ?Advantage?
(which sets the underlyingadvantage attribute to ?Yes?)
and the same concep-tID ?Met1?.
The novelty attribute value is then in-herited from the novelty attribute value of the firstcoreferring sentence, which in this case is ?New?.3 Input: Paper in XMLSAPIENT currently accepts as input papers in XML,especially ones compliant with the SciXML schema(Rupp et al, 2006).
SciXML is ideally suited forthis purpose as it was developed for representing thelogical structure of scientific research papers.
Tagsused in the schema serve the purpose of paper iden-tification (e.g.
<TITLE>,<AUTHOR>), definingsections of the paper (e.g.
<DIV>,<HEADER>),text sections with specific function and formatting(e.g.
<ABSTRACT>, <EQUATION>), paragraphtags <P>, references, tables, figures and footnotes,lists, bibliography.
SAPIENT operates only on the<TITLE>, <ABSTRACT> ,<BODY> and <P>tags, leaving out any list elements following thebody, such as acknowledgements, figures or refer-ences at the end of the paper.
This is because wemake the assumption that only the abstract and thebody contain sentences with semantic content of anyimportance to the research carried out in the paper.This would have been different if SAPIENT anno-tated figures as well, but such provision is not cur-rently made.
Tags such as <REF>, citations in thetext, are included within the sentence boundaries.Even though SAPIENT was developed with theSciXML schema in mind, it will work with anywell formed XML document that has <PAPER>as the root node and which also contains an<ABSTRACT> and <BODY> node.
Therefore, itis relatively easy to adapt SAPIENT to other XMLschemas.4 SSSplit: Sapient Sentence Splitting4.1 Sentence MatchingThe reason for developing our own sentence split-ter was that sentence splitters widely available couldnot handle XML properly.
The XML markup con-tains useful information about the document struc-ture and formatting in the form of inline tags,which is important for determining the logical struc-ture of the paper.
The latter is worth preserv-ing for our purposes, since it can influence theannotation of individual sentences.
XML markup(e.g.
<ABSTRACT>,<REF>,<EQUATION>)needs to be combined carefully with tags designat-ing sentence boundaries (<s></s>), so that theresulting document is in well formed XML.
Cur-rent sentence splitters ignore XML markup, whichmeans that any document formatting/informationwould have to be removed in order to use them.RASP (Briscoe et al, 2006), the sentence splitterused in the Sciborg project4 at the University ofCambridge, can deal with XML but has to be com-piled for different operating systems, which wouldresult in compromising the platform independenceof SAPIENT.
A recent MPhil thesis (Owusu, 2008)has also developed an XML-aware sentence splitterbut the code is in Microsoft C#.Net and therefore notplatform independent.We have written the XML-aware sentence split-ter SSSplit in the platform-independent Java lan-guage (version 1.6), based on and extending opensource Perl code5 for handling plain text.
In or-4http://www.cl.cam.ac.uk/research/nl/sciborg/www/5http://search.cpan.org/ tgrose/HTML-Summary-0.017/196Figure 3: Example of SAPIENT annotation through selection from drop-down menu.Figure 4: Behind the scenes: Example XML fragment of a paper annotated using SAPIENT.Figure 5: Incorporation of OSCAR3 annotations in SAPIENT, after selecting the link ?Auto Annotate?197der to make our sentence splitter XML aware, wetranslated the Perl regular expression rules into Javaand modifed them to make them compatible with theSciXML(Rupp et al, 2006) schema.
We then fur-ther improved the rules, by training on a set of 14papers in SciXML.
This involved displaying the pa-pers, checking whether the XML was well formedand making corrections accordingly.
We would ob-serve cases of oversplit and undersplit sentences andamend the rules while keeping them as general aspossible.
The rules in SSSplit were evaluated bycomparing the system output against a gold standardof 41 papers, where sentence boundaries had beenprovided by human experts (See section 4.2).
Thesentence splitter is integrated within the SAPIENTsystem but is also available as a separate package(?SSSplit?).
This should enable any future work toeasily incorporate or extend it.
It is currently trainedfor splitting papers in SciXML, but can be easilyported to any other kind of XML, as discussed insection 3.4.2 SSSplit EvaluationSAPIENT and SSSplit have been have been em-ployed by more than 20 different users to success-fully display 270 full papers.
For a more accurateevaluation of the quality of the sentences producedby SSSplit, we used a Perl script which comparedthe sentence boundaries (start and end) generatedby SSSplit, to sentence tags in a set of 41 papers(SciXML files) annotated manually by human ex-perts.
If both the start and end of a sentence matchedup in the generated and manual versions, we consid-ered this a true positive result.
In the case where asentence did not match in the two versions, we firstsearched for a matching end in our generated set ofsentences and then in the hand annotated version.
Ifthe ?true?
end of the sentence (as defined by the man-ual annotation) was found in later sentences in theSSSplit version, this meant that the system had splita sentence too early, or ?oversplit?.
This we consid-ered to be a false positive, since we had detected asentence boundary where in reality there was none.This would result in the following sentence beingmatched at the end only, which also counts as a falsepositive.
In the case where the end of the SSSplitsentence was found in a later sentence, within theset of ?true?
sentences, it meant that our sentenceRASP Owusu SSSplitPrecision 0.994 0.996 0.964Recall 0.983 0.990 0.994F-measure 0.988 0.992 0.978Table 1: Comparison of sentence splitters in RASP,Owusu and SSSplit.spanned too wide, or that the system had ?under-split?.
These cases we considered to be false nega-tives, as we had failed to detect a sentence boundarywhere there was one.Our training consisted of 14 papers in the fields ofphysical chemistry and biochemistry.
A different setof 41 papers distinct from the training set but fromthe same thematic domain was used as a test set.
Outof these 41 papers, 36 feature as a test set (with n-fold validation) also for the sentence splitters RASP(Briscoe et al, 2006) and the XML-aware sentencesplitter developed by (Owusu, 2008).
The results forall three systems, obtained as medians of Precision,Recall and F-measure for the 36 papers are shown inTable 1.Precision is the proportion of true positives overall end and start tags returned, giving a measure ofthe number of boundaries identified correctly.
Re-call is the proportion of true positives over all therelevant start and end tags in the hand-annotated pa-pers, giving a measure of the number of boundariesactually found.
F-Measure combines Precision andRecall to give a more balanced view on the systemperformance.In comparison with RASP and the XML-Awaresplitter of (Owusu, 2008), SSSplit performed well,though it did not outperform these systems.
Theirhighest result for precision was 0.996 (vs 0.964 forSSSplit) and for recall 0.990 (vs 0.994 for SSSplit).We can explain their higher results somewhat bytheir use of n-fold cross-validation on 36 out of thesame 41 papers that we used, which can allow in-formation from the test set to leak into the trainingdata.
We did not perform n-fold cross-validation, asthis would have involved going through each of thepapers and removing any potential influence on ourregular expression rules of the sentences includedwithin, which is a non-trivial process.
Our test datawas completely unseen, which meant that our eval-198Training Testing(1979 sentences) (5002 sentences)Precision 0.961 0.964Recall 0.995 0.994F-measure 0.96875 0.978Table 2: Comparison of SSSplit on the training and test-ing papers.
The training set consisted of 14 papers (1979sentences) and the testing set of 41 papers (5002 sen-tences).uation is stricter, avoiding any influence from thetraining data.In addition to the comparison between SSSplitand the other two XML-aware sentence splitters, wealso performed a comparison between our trainingand testing sets, depicted in Table 2.As can be seen in Table 2, recall was only slightlybetter on the training set than the test set, but preci-sion was worse on the training set, presumably be-cause of lack of attention being paid to the oversplit-ting in a particular paper (?b103844n?).
This showsthat we have not overfitted to the training set in de-veloping our splitter.
Our recall is particularly high,indicating that our splitter makes very few false neg-ative errors.
We can attribute many of the false pos-itive errors to our somewhat small set of abbrevi-ations considered, resulting in oversplit sentences.We would like to incorporate a more sophisticatedapproach to abbreviations in the future.5 Performing CISP AnnotationsWithin the context of the ART project (Soldatova etal., 2007), SAPIENT has been used by 16 Chem-istry experts to annotate 265 papers from RSC Pub-lishing journals, covering topics in Physical Chem-istry and Biochemistry.
Experts have been anno-tating the papers sentence by sentence, assigningeach sentence one of 11 core scientific concepts andlinking together sentences across a paper which re-fer to the same instance of a concept.
The aimis to create a corpus of annotated papers (ART-corpus) with regions of scientific interest identifiedby CISP concepts (?Result?,?Conclusion?, ?Obser-vation?,?Method?
and so on).A preliminary evaluation of the experts?
agree-ment on the ART Corpus, based on a sample of41 papers, annotated by the 16 experts in non-overlapping groups of 3, shows significant agree-ment between annotators, given the difficulty ofthe task (an average kappa co-efficient of 0.55 pergroup).
The details of this work are beyond thescope of the current paper, but the preliminary re-sults underline the usability of both the CISP meta-data and SAPIENT.
In the future, we plan to furtherevaluate the ART Corpus by incorporating existingmachine learning algorithms into SAPIENT and au-tomating the generation of CISP meta-data.
Thiswould make SAPIENT a very useful tool and wouldindeed add a lot more value to the meta-data, sincetraining and paying annotators is a costly processand manually annotating papers is incredibly timeconsuming.6 Conclusion and Future WorkWe have presented SAPIENT, a web-based tool forthe annotation of full papers, sentence by sentence,with semantic information.
We have also discussedhow these annotations result in the indirect defini-tion of regions of interest within the paper.
The sys-tem has been already tested in a systematic studyand has been employed for the creation of a corpusof papers annotated with CISP concepts (ART Cor-pus).
In the future we plan to extend SAPIENT sothat the system can itself suggest annotation labelsto users.
We also plan to target the needs of partic-ular users such as authors of papers, reviewers andeditors.SAPIENT, SSSplit and their documenta-tion are both available for download fromhttp://www.aber.ac.uk/compsci/Research/bio/art/sapient/.AcknowledgmentsWe would like to thank Peter Corbett, AmandaClare, Jem Rowland and Andrew Sparkes forreading and commenting on earlier versionsof this paper.
We would also like to thankthe anonymous reviewers for their useful com-ments.
This work was part of the ART Project(http://www.aber.ac.uk/compsci/Research/bio/art/),funded by the U.K. Higher Education JointInformation Services Committee (JISC).199ReferencesE.
Briscoe, J. Carroll and R. Watson 2006.
The Sec-ond Release of the RASP System.
Proceedings of theCOLING/ACL 2006 Interactive Presentation Sessions,Sydney, Australia.P.
Corbett, P. Batchelor and S. Teufel.
2007.
Annotationof Chemical Named Entities.
Proc.
BioNLP.Nikiforos Karamanis, Ruth Seal, Ian Lewin, Peter Mc-Quilton, Andreas Vlachos, Caroline Gasperin, RachelDrysdale and Ted Briscoe.
2008.
Natural LanguageProcessing in aid of FlyBase curators.
BMC Bioinfor-matics, 9:193.Maria Liakata and Larisa N. Soldatova.
2008.
Guide-lines for the annotation of General Scientific ConceptsJISC Project Report, http://ie-repository.jisc.ac.uk/.Jimmy Lin 2009.
Is Searching Full Text More Effec-tive Than Searching Abstracts?
BMC Bioinformatics,10:46.Ben Medlock and Ted Briscoe.
2007.
Weakly supervisedlearning for hedge classification in scientific literature.45th Annual Meeting of the Association for Compu-tational Linguistics, 23-30 Jun 2007, Prague, CzechRepublic.P.
Ogren.
2006.
Knowtator: a Prote?ge?
plug-in for an-notated corpus construction.
Proceedings of the 2006Conference of the North American Chapter of the As-sociation For Computational Linguistics on HumanLanguage Technology: Companion Volume: Demon-strations, New York Press, New York, June 04 - 09,2006.Lawrence Owusu.
2008.
XML-Aware Sentence Splitter.MPhil thesis, Cambridge, UK.CJ Rupp, Ann Copestake, Simone Teufel and Ben Wal-dron.
2006.
Flexible Interfaces in the Application ofLanguage Technology to an eScience Corpus.
Pro-ceedings of the UK e-Science Programme All HandsMeeting 2006 (AHM2006), Nottingham, UKHagit Shatkay, Fengxia Pan, Andrey Rzhetsky and W.John Wilbur.
2008.
Multi-dimensional classificationof biomedical text: Toward automated, practical pro-vision of high-utility text to diverse users.
Bioinfor-matics, 24(18):2086?2093.Larisa N. Soldatova and Maria Liakata.
2007.
An ontol-ogy methodology and CISP - the proposed Core Infor-mation about Scientific Papers.
JISC Project Report,http://ie-repository.jisc.ac.uk/137/.L.
Soldatova, C. Batchelor, M. Liakata, H. Fielding, S.Lewis and R. King 2007.
ART: An ontology basedtool for the translation of papers into Semantic Webformat.
Proceedings of the SIG/ISMB07 ontologyworkshop., p.33?36.Larisa N. Soldatova and Ross D. King.
2006.
An On-tology of Scientific Experiments.
Journal of the RoyalSociety Interface, 3:795?803.S.
Teufel and M. Moens.
2002.
Summarizing ScientificArticles ?
Experiments with Relevance and RhetoricalStatus.
Computational Linguistics, 28(4).
(preprint)W. Wilbur, A. Rzhetsky and H. Shatkay.
2006.
New Di-rections in Biomedical Text Annotations: Deifinitions,Guidelines and Corpus Construction.
BMC Bioinfor-matics, 7:356.200
