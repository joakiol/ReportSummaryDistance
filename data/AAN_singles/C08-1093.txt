Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 737?744Manchester, August 2008Translating Queries into Snippets for Improved Query ExpansionStefan Riezler and Yi Liu and Alexander VassermanGoogle Inc.1600 Amphitheatre ParkwayMountain View, CA 94043{riezler,yliu,avasserm}@google.comAbstractUser logs of search engines have recentlybeen applied successfully to improve var-ious aspects of web search quality.
In thispaper, we will apply pairs of user queriesand snippets of clicked results to train amachine translation model to bridge the?lexical gap?
between query and documentspace.
We show that the combination ofa query-to-snippet translation model witha large n-gram language model trainedon queries achieves improved contextualquery expansion compared to a systembased on term correlations.1 IntroductionIn recent years, user logs of search engines have at-tracted considerable attention in research on queryclustering, query suggestions, query expansion, orgeneral web search.
Besides the sheer size of thesedata sets, the main attraction of user logs lies inthe possibility to capitalize on users?
input, eitherin form of user-generated query reformulations, orin form of user clicks on presented search results.However noisy, sparse, incomplete, and volatilethese data may be, recent research has presentedimpressive results that are based on simply takingthe majority vote of user clicks as a signal for therelevance of results.In this paper we will apply user logs to the prob-lem of the ?word mismatch?
or ?lexical chasm?
(Berger et al, 2000) between user queries anddocuments.
The standard solution to this prob-lem, query expansion, attempts to overcome thisc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.mismatch in query and document vocabularies byadding terms with similar statistical properties tothose in the original query.
This will increase thechances of matching words in relevant documentsand also decrease the ambiguity of the overallquery that is inherent to natural language.
A suc-cessful approach to this problem is local feed-back, or pseudo-relevance feedback (Xu and Croft,1996), where expansion terms are extracted fromthe top-most documents that were retrieved in aninitial retrieval round.
Because of irrelevant resultsin the initial retrieval, caused by ambiguous termsor retrieval errors, this technique may cause expan-sion by unrelated terms, leading to query drift.
Fur-thermore, the requirement of two retrieval steps iscomputationally expensive.Several approaches have been presented that de-ploy user query logs to remedy these problems.One set of approaches focuses on user reformu-lations of queries that differ only in one segment(Jones et al, 2006; Fonseca et al, 2005; Huanget al, 2003).
Such segments are then identifiedas candidate expansion terms, and filtered by var-ious signals such as cooccurrence in similar ses-sions or log-likelihood ratio of original and ex-pansion phrases.
Other approaches focus on therelation of queries and retrieval results, either bydeploying the graph induced by queries and userclicks in calculating query similarity (Beefermanand Berger, 2000; Wen et al, 2002; Baeza-Yatesand Tiberi, 2007), or by leveraging top results frompast queries to provide greater context in find-ing related queries (Raghavan and Sever, 1995;Fitzpatrick and Dent, 1997; Sahami and Heilman,2006).
Cui et al (2002) present an all together dif-ferent way to deploy user clickthrough data by ex-tracting expansion terms directly from clicked re-sults.
They claim significant improvements over737the local feedback technique of Xu and Croft(1996).Cui et al?s (2002) work is the closest to ours.We follow their approach in extracting expansionterms directly from clicked results, however, with afocus on high precision of query expansion.
Whileexpansion from the domain of document terms hasthe advantage that expansion terms are guaranteedto be in the search domain, expansion precisionmay suffer from the noisy and indirect ?approval?of retrieval results by user clicks.
Thus expansionterms from the document domain are more likelyto be generalizations, specifications, or otherwiserelated terms, than terms extracted from query sub-stitutions that resemble synonyms more closely.Furthermore, if the model that learns to correlatedocument terms to query terms is required to ig-nore context in order to generalize, finding appro-priate expansions for ambiguous query terms isdifficult.Our approach is to look at the ?word mismatch?problem as a problem of translating from a sourcelanguage of queries into a target language of docu-ments, represented as snippets.
Since both queriesand snippets are arguably natural language, sta-tistical machine translation technology (SMT) isreadily applicable to this task.
In previous work,this has been done successfully for question an-swering tasks (Riezler et al, 2007; Soricut andBrill, 2006; Echihabi and Marcu, 2003; Berger etal., 2000), but not for web search in general.
Cui etal.
?s (2002) model is to our knowledge the first todeploy query-document relations for direct extrac-tion of expansion terms for general web retrieval.Our SMT approach has two main advantages overCui et al?s model: Firstly, Cui et al?s model re-lates document terms to query terms by using sim-ple term frequency counts in session data, with-out considering smoothing techniques.
Our ap-proach deploys a sophisticated machine learningapproach to word alignment, including smooth-ing techniques, to map query phrases to snippetphrases.
Secondly, Cui et al?s model only indi-rectly uses context information to disambiguateexpansion terms.
This is done by calculating therelationship of an expansion term to the wholequery by multiplying its contributions to all queryterms.
In our SMT approach, contextual disam-biguation is done by deploying an n-gram lan-guage model trained on queries to decide about theappropriateness of an expansion term in the con-text of the rest of the query terms.
As shown inan experimental evaluation, together the orthogo-nal information sources of a translation model anda language model provide significantly better con-textual query expansion than Cui et al?s (2002)correlation-based approach.In the following, we recapitulate the essentialsof Cui et al?s (2002) model, and contrast it withour SMT-based query expansion system.
Further-more, we will present a detailed comparison of thetwo systems on a real-world query expansion task.2 Query-Document Term CorrelationsThe query expansion model of Cui et al (2002)is based on the principle that if queries containingone term often lead to the selection of documentscontaining another term, then a strong relationshipbetween the two terms is assumed.
Query termsand document terms are linked via clicked docu-ments in user sessions.
Formally, Cui et al (2002)compute the following probability distribution ofdocument words wdgiven query words wqfromcounts over clicked documents D:P (wd|wq) =?DP (wd|D)P (D|wq) (1)The first term in the righthandside of equation 1 isa normalized tfidf weight of the the document termin the clicked document, and the second term is therelative cooccurrence of document and query termin sessions.Since equation 1 calculates expansion probabil-ities for each term separately, Cui et al (2002)introduce the following cohesion formula that re-spects the whole query Q by aggregating the ex-pansion probabilities for each query term:CoWeightQ(wd) = ln(?wq?QP (wd|wq) + 1) (2)In contrast to local feedback techniques (Xuand Croft, 1996), Cui et al?s algorithm allows toprecompute term correlations offline by collectingcounts from query logs.
This reliance on pure fre-quency counting is both a blessing and a curse: Onthe one hand it allows for efficient non-iterative es-timation, on the other hand it makes the implicitassumption that data sparsity will be overcome bycounting from huge datasets.
The only attempt atsmoothing that is made in this approach is a recur-rence to words in query context, using equation 2,when equation 1 assigns zero probability to unseenpairs.7383 Query-Snippet TranslationThe SMT system deployed in our approach isan implementation of the alignment template ap-proach of Och and Ney (Och and Ney, 2004).
Thebasic features of the model consist of a translationmodel and a language model which go back to thenoisy channel formulation of machine translationin Brown et al (1993).
Their ?fundamental equa-tion of machine translation?
defines the job of atranslation system as finding the English string?ethat is a translation of a foreign string f such that?e = argmaxeP (e|f)= argmaxeP (f |e)P (e) (3)Equation 3 allows for a separation of a languagemodel P (e), and a translation model P (f |e).
Ochand Ney (2004) reformulate equation 3 as a lin-ear combination of feature functions hm(e, f) andweights ?m, including feature functions for trans-lation models hi(e, f) = P (f |e) and languagemodels hj(e) = P (e):?e = argmaxeM?m=1?mhm(e, f) (4)The translation model used in our approach isbased on the sequence of alignment models de-scribed in Och and Ney (2003).
The relationship oftranslation model and alignment model for sourcelanguage string f = fJ1and target string e = eI1is via a hidden variable describing an alignmentmapping from source position j to target positionaj:P (fJ1|eI1) =?aJ1P (fJ1, aJ1|eI1) (5)The alignment aJ1contains so-called null-wordalignments aj= 0 that align source words to theempty word.
The different alignment models de-scribed in Och and Ney (2003) each parameter-ize equation 5 differently so as to capture differ-ent properties of source and target mappings.
Allmodels are based on estimating parameters ?
bymaximizing the likelihood of training data con-sisting of sentence-aligned, but not word-alignedstrings {(fs, es) : s = 1, .
.
.
, S}.
Since each sen-tence pair is linked by a hidden alignment variablea = aJ1, the optimal??
is found using unlabeled-data log-likelihood estimation techniques such asthe EM algorithm (Dempster et al, 1977):??
= argmax?S?s=1?ap?
(fs,a|es) (6)The final translation model is calculated from rel-ative frequencies of phrases, i.e.
consecutive se-quences of words occurring in text.
Phrases areextracted via various heuristics as larger blocks ofaligned words from best word alignments, as de-scribed in Och and Ney (2004).Language modeling in our approach deploys ann-gram language model that assigns the followingprobability to a string wL1of words (see Brants etal.
(2007)):P (wL1) =L?i=1P (wi|wi?11) (7)?L?i=1P (wi|wi?1i?n+1) (8)Estimation of n-gram probabilities is done bycounting relative frequencies of n-grams in a cor-pus of user queries.
Remedies against sparse dataproblems are achieved by various smoothing tech-niques, as described in Brants et al (2007).For applications of the system to translate un-seen queries, a standard dynamic-programmingbeam-search decoder (Och and Ney, 2004) thattightly integrates translation model and languagemodel is used.
Expansion terms are taken fromthose terms in the 5-best translations of the querythat have not been seen in the original query string.In our opinion, the advantages of using analignment-based translation model to correlatedocument terms with query terms, instead of rely-ing on a term frequency counts as in equation 1, areas follows.
The formalization of translation mod-els as involving a hidden alignment variable allowsus to induce a probability distribution that assignssome probability of being translated into a targetword to every source word.
This is a crucial steptowards solving the problem of the ?lexical gap?described above.
Furthermore, various additionalsmoothing techniques are employed in alignmentto avoid overfitting and improved coping with rarewords (see Och and Ney (2003)).
Lastly, estima-tion of hidden-variable models can be based onthe well-defined framework of statistical estima-tion via the EM algorithm.Similar arguments hold for the language model:N-gram language modeling is a well-understood739sentence source targetpairs words wordstokens 3 billion 8 billion 25 billionavg.
length - 2.6 8.3Table 1: Statistics of query-snippet training datafor translation model.problem, with a host of well-proven smoothingtechniques to avoid data sparsity problems (seeBrants et al (2007).
)In combination, translation model and languagemodel provide orthogonal sources of informationto the overall translation quality.
While the trans-lation model induces a smooth probability distri-bution that relates source to target words, the lan-guage model deploys probabilities of target lan-guage strings to assess the adequacy of a targetword as a translation in context.
Reliance on or-dering information of the words in the context of asource word is a huge advantage over the bag-of-words aggregation of context information in Cui etal?s (2002) model.
Furthermore, in the SMT modelused in our approach, translation model and lan-guage model are efficiently integrated in a beam-search decoder.In our application of SMT to query expansion,queries are considered as source language sen-tences and snippets of clicked result documentsas target sentences.
A parallel corpus of sentence-aligned data is created by pairing each query witheach snippet of its clicked results.
Further adjust-ments to system parameters were applied in or-der to adapt the training procedure to this specialdata set.
For example, in order to account for thedifference in sentence length between queries andsnippets, we set the null-word probability to 0.9.This allows us to improve precision of alignmentof noisy data by concentrating the alignment to asmall number of key words.
Furthermore, extrac-tion of phrases in our approach is restricted to theintersection of alignments from both translation di-rections, thus favoring precision over recall also inphrase extraction.
The only major adjustment ofthe language model to the special case of query-snippet translation is the fact that we train our n-gram model on queries taken from user logs, in-stead of on standard English text.1-grams 2-grams 3-grams9 million 1.5 billion 5 billionTable 2: Statistics of unique query n-grams in lan-guage model.items disagreementsw/ agreement included# items 102 125mean item score 0.333 0.27995% conf.
int.
[0.216, 0.451] [0.176, 0.381]Table 3: Comparison of SMT-based expan-sion with correlation-based expansion on 7-pointLikert-type scale.4 Experimental Evaluation4.1 DataThe training data for the translation model andthe correlation-based model consist of pairs ofqueries and snippets for clicked results taken fromanonymized query logs.
Using snippets instead offull documents makes iterative training feasibleand also reduces noise considerably.
This parallelcorpus of query-snippet pairs is fed into a standardSMT training pipeline (modulo the adjustments toword and phrase alignment discussed above).
Theparallel corpus consists of 3 billion query-snippetpairs that are input to training of word and phrasealignment models.
The resulting phrase translationtable that builds the basis of the translation modelconsists 700 million query-snippet phrase transla-tions.
A collection of data statistics for the trainingdata is shown in table 1.The language model used in our experiment is atrigram language model trained on English queriesin user logs.
N-grams were cut off at a minimumfrequency of 4.
Data statistics for resulting uniquen-grams are shown in table 2.4.2 Experimental ComparisonOur experimental setup for query expansion de-ploys a real-world search engine, google.com, fora comparison of expansions from the SMT-basedsystem and the correlation-based system.
The ex-perimental evaluation was done as direct compari-son of search results for queries where both exper-imental systems suggested expansion terms.
Sinceexpansions from both experimental systems aredone on top of the same underlying search engine,this allows us to abstract away from interactionswith the underlying system.
The queries used forevaluation were extracted randomly from 3+ word740query SMT-based expansions corr-based expansions scoreapplying U.S. passport passport - visa applying - home -1.0configure debian to use dhcp debian - linux configure - configuring -1.0configure - installhow many episodes of 30 rock?
episodes - season how many episodes - tv -0.83episodes - series many episodes - wikipedialampasas county sheriff department department - office department - home -0.83sheriff - officeweakerthans cat virtue chords chords - guitar cat - tabs -0.83chords - lyrics chords - tabschords - tabHenry VIII Menu Portland, Maine menu - restaurant portland - six 1.3menu - restaurants menu - englandladybug birthday parties parties - ideas ladybug - kids 1.3parties - partypolitical cartoon calvin coolidge cartoon - cartoons political cartoon - encyclopedia 1.3top ten dining, vancouver dining - restaurants dining vancouver - 10 1.3international communication communication - communications international communication - college 1.3in veterinary medicine communication - skillsTable 4: SMT-based versus correlation-based expansions with mean item score.queries in user logs in order to allow the systemsto deploy context information for expansion.In order to evaluate Cui et al?s (2002)correlation-based system in this setup, we requiredthe system to assign expansion terms to particu-lar query terms.
This could be achieved by usinga linear interpolation of scores in equation 2 andequation 1.
Equation 1 thus introduces a prefer-ence for a particular query term to the whole-queryscore calculated by equation 2.
Our reimplementa-tion uses unigram and bigram phrases in queriesand expansions.
Furthermore, we use Okapi BM25instead of tfidf in the calculation of equation 1 (seeRobertson et al (1998)).Query expansion for the SMT-based system isdone by extracting terms introduced in the 5-bestlist of query translations as expansion terms for therespective query terms.The evaluation was performed by three in-dependent raters.
The raters were given task-specific rating guidelines, and were shown queriesand 10-best search results from both systems,anonymized, and presented randomly on left orright sides.
The raters?
task was to evaluate the re-sults on a 7-point Likert-type1scale, defined as:-1.5: much worse-1.0: worse-0.5: slightly worse1Likert?s (1932) original rating system is a 5-point scaleusing integer scores 1 through 5.
Our system uses averagescores over three raters for each item, and uses a 7-point in-stead of a 5-point scale.
See Dawes (2008) on the compara-bility of 5-, 7-, or 10-point scales.0: about the same0.5: slightly better1.0: better1.5: much betterResults on 125 queries where both systems sug-gested expansion terms are shown in table 3.
Foreach query, rating scores are averaged over thescores assigned by three raters.
The overall meanitem score for a comparison of SMT-based ex-pansion against correlation-based expansion was0.333 for 102 items with rater agreement, and0.279 for 125 items including rater disagreements.All result differences are statistically significant.Examples for SMT-based and correlation-basedexpansions are given in table 4.
The first five ex-amples are losses for the SMT-based system.
Inthe first example, passport is replaced by the re-lated, but not synonymous term visa in the SMT-based expansion.
The second example is a loss forSMT-based expansion because of a replacement ofthe specific term debian by the more general termlinux.
The correlation-based expansions tv 30 rockin the third example, lampasas county sheriff homein the fourth example, and weakerthans tabs in thefifth example directly hit the title of relevant webpages, while the SMT-based expansion terms donot improve retrieval results.
However, even fromthese negative examples it becomes apparent thatthe SMT-based expansion terms are clearly relatedto the query terms, and for a majority cases thishas a positive effect.
Such examples are shown in741(herbs , herbs) ( for , for) ( chronic , chronic) ( constipation , constipation)(herbs , herb) ( for , for) ( chronic , chronic) ( constipation , constipation)(herbs , remedies) ( for , for) ( chronic , chronic) ( constipation , constipation)(herbs , medicine) ( for , for) ( chronic , chronic) ( constipation , constipation)(herbs , supplements) ( for , for) ( chronic , chronic) ( constipation , constipation)(herbs , herbs) ( for , for) ( mexican , mexican) ( cooking , cooking)(herbs , herbs) ( for , for) ( cooking , cooking) ( mexican , mexican)(herbs , herbs) ( for , for) ( mexican , mexican) ( cooking , food)(mexican , mexican) ( herbs , herbs) ( for , for) ( cooking , cooking)(herbs , spices) ( for , for) ( mexican , mexican) ( cooking , cooking)Table 5: Unique 5-best phrase-level translations of queries herbs for chronic constipation and herbs formexican cooking.query terms n-best expansionsherbs com treatment encyclopediachronic interpret treating comconstipation interpret treating comherbs for medicinal support womenfor chronic com gold encyclopediachronic constipation interpret treatingherbs cooks recipes commexican recipes com cookscooking cooks recipes comherbs for medicinal women supportfor mexican cooks com allrecipesTable 6: Correlation-based expansions for queries herbs for chronic constipation and herbs for mexicancooking.the second set of expansions.
SMT-based expan-sions such as henry viii restaurant portland, maine,or ladybug birthday ideas, or top ten restaurants,vancouver achieve a change in retrieval results thatdoes not result in a query drift, but rather in im-proved retrieval results.
In contrast, the terms in-troduced by the correlation-based system are eitheronly vaguely related or noise.5 DiscussionWe attribute the experimental result of a signif-icant preference for SMT-based expansions overcorrelation-based expansions to the fruitful com-bination of translation model and language modelprovided by the SMT system.
The SMT approachcan be viewed as a combined system that proposescandidate expansion via the translation model, andfilters them by the language model.
Thus we mayfind a certain amount of non-sensical expansioncandidates at the phrase translation level.
This canbe seen from inspecting table 7 which shows themost probable phrase translations that are applica-ble to the queries herbs for chronic constipationand herbs for mexican cooking.
The phrase tableincludes identity translations and closely relatedterms as most probable translations for nearly ev-ery phrase, however, it also clearly includes noisyand non-related terms.
More importantly, an ex-traction of expansion terms from the phrase tablealone would not allow to choose the appropriateterm for the given query context.
This can be at-tained by combining the phrase translations with alanguage model: As shown in table 5, the 5-besttranslations of the full queries attain a proper dis-ambiguation of the senses of herbs by replacingthe term by remedies, medicine, and supplementsfor the first query, and with spices for the secondquery.
Expansion terms highlighted in bold face.The fact that the most probable translation forthe whole query mostly is the identity translationcan be seen as a feature, not as a bug, of the SMT-based approach: By the option to prefer identitytranslations or word reorderings over translationsof source words, the SMT model effectively canchoose not to generate any expansion terms.
Thiswill happen if none of the candidate phrase trans-lations fit with high enough probability into thecontext of the whole query, as assessed by the lan-guage model.In contrast to the SMT model, the correlation-based model cannot fall back onto the ordering in-formation of the language model, but aggregatesinformation for the whole query from a bag-of-words of query terms.
Table 6 shows the top three742correlation-based expansion terms assigned to uni-grams and bigrams in the queries herbs for chronicconstipation and herbs for mexican cooking.
Ex-pansion terms are chosen by overall highest weightand shown in bold face.
Relevant expansion termssuch as treatment or recipes that would disam-biguate the meaning of herbs are in fact proposedby the correlation-based model, however, the cohe-sion score also promotes terms such as interpret orcom as best whole-query expansions, thus leadingto query drift.6 ConclusionWe presented an approach to contextual query ex-pansion that deploys natural language technologyin form of statistical machine translation.
The keyidea of our approach is to consider the problemof the ?lexical gap?
between queries and docu-ments from a linguistic point of view, and at-tempt to bridge this gap by translating from thequery language into the document language.
Us-ing search engine user logs, we could extract largeamounts of parallel data of queries and snippetsfrom clicked documents.
These data were used totrain an alignment-based translation model, andan n-gram based language model.
The same datawere used to train a reimplementation of Cuiet al?s (2002) term-correlation based query ex-pansion system.
An experimental comparison ofthe two systems showed a considerable prefer-ence for SMT-based expansions over correlation-based expansion.
Our explanation for this resultis the fruitful combination of the orthogonal in-formation sources from translation model and lan-guage model.
While in the SMT approach expan-sion candidates proposed by the translation modelare effectively filtered by ordering informationon the query context from the language model,the correlation-based approach resorts to an in-ferior bag-of-word aggregation of scores for thewhole query.
Furthermore, each component of theSMT model takes great care to avoid sparse dataproblems by various sophisticated smoothing tech-niques.
In contrast, the correlation-based model re-lies on pure counts of term frequencies.An interesting task for future work is to dis-sect the contributions of translation model andlanguage model, for example, by combining acorrelation-based system with a language modelfilter.
The challenge here is a proper integration ofn-gram lookup into correlation-based expansion.ReferencesBaeza-Yates, Ricardo and Alessandro Tiberi.
2007.Extracting semantic relations from query logs.
InProceedings of the 13th ACM SIGKDD Confer-ence on Knowledge Discovery and Data Mining(KDD?07), San Jose, CA.Beeferman, Doug and Adam Berger.
2000.
Agglom-erative clustering of a search engine query log.
InProceedings of the 6th ACM SIGKDD InternationalConference on Knowledge Discovery and Data Min-ing (KDD?00), Boston, MA.Berger, Adam L., Rich Caruana, David Cohn, DayneFreitag, and Vibhu Mittal.
2000.
Bridging the lexi-cal chasm: Statistical approaches to answer-finding.In Proceedings of SIGIR?00, Athens, Greece.Brants, Thorsten, Ashok C. Popat, Peng Xu, Franz J.Och, and Jeffrey Dean.
2007.
Large language mod-els in machine translation.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing (EMNLP?07), Prague, Czech Re-public.Brown, Peter F., Stephen A. Della Pietra, VincentJ.
Della Pietra, and Robert L. Mercer.
1993.The mathematics of statistical machine translation:Parameter estimation.
Computational Linguistics,19(2):263?311.Cui, Hang, Ji-Rong Wen, Jian-Yun Nie, and Wei-YingMa.
2002.
Probabilistic query expansion usingquery logs.
In Proceedings of WWW 2002, Hon-olulu, Hawaii.Dawes, John.
2008.
Do data characteristics change ac-cording to the number of scale points used?
An ex-periment using 5-point, 7-point and 10-point scales.International Journal of Market Research, 50(1):61?77.Dempster, A. P., N. M. Laird, and D. B. Rubin.
1977.Maximum Likelihood from Incomplete Data via theEM Algorithm.
Journal of the Royal Statistical So-ciety, 39(B):1?38.Echihabi, Abdessamad and Daniel Marcu.
2003.
Anoisy-channel approach to question answering.
InProceedings of the 41st Annual Meeting of the As-sociation for Computational Linguistics (ACL?03),Sapporo, Japan.Fitzpatrick, Larry and Mei Dent.
1997.
Automaticfeedback using past queries: Social searching?
InProceedings of SIGIR?97, Philadelphia, PA.Fonseca, Bruno M., Paulo Golgher, Bruno Possas,Berthier Ribeiro-Neto, and Nivio Ziviani.
2005.Concept-based interactive query expansion.
In Pro-ceedings of the 14th Conference on Information andKnowledge Management (CIKM?05), Bremen, Ger-many.743Huang, Chien-Kang, Lee-Feng Chien, and Yen-JenOyang.
2003.
Relevant term suggestion in interac-tive web search based on contextual information inquery session logs.
Journal of the American Societyfor Information Science and Technology, 54(7):638?649.Jones, Rosie, Benjamin Rey, Omid Madani, and Wi-ley Greiner.
2006.
Generating query substitutions.In Proceedings of the 15th International World WideWeb conference (WWW?06), Edinburgh, Scotland.Likert, Rensis.
1932.
A technique for the measurementof attitudes.
Archives of Psychology, 140:5?55.Och, Franz Josef and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Och, Franz Josef and Hermann Ney.
2004.
The align-ment template approach to statistical machine trans-lation.
Computational Linguistics, 30(4):417?449.Raghavan, Vijay V. and Hayri Sever.
1995.
On thereuse of past optimal queries.
In Proceedings of SI-GIR?95, Seattle, WA.Riezler, Stefan, Alexander Vasserman, IoannisTsochantaridis, Vibhu Mittal, and Yi Liu.
2007.Statistical machine translation for query expansionin answer retrieval.
In Proceedings of the 45th An-nual Meeting of the Association for ComputationalLinguistics (ACL?07), Prague, Czech Republic.Robertson, Stephen E., Steve Walker, and MichelineHancock-Beaulieu.
1998.
Okapi at TREC-7.
InProceedings of the Seventh Text REtrieval Confer-ence (TREC-7), Gaithersburg, MD.Sahami, Mehran and Timothy D. Heilman.
2006.
Aweb-based kernel function for measuring the sim-ilarity of short text snippets.
In Proceedings ofthe 15th International World Wide Web conference(WWW?06), Edinburgh, Scotland.Soricut, Radu and Eric Brill.
2006.
Automatic questionanswering using the web: Beyond the factoid.
Jour-nal of Information Retrieval - Special Issue on WebInformation Retrieval, 9:191?206.Wen, Ji-Rong, Jian-Yun Nie, and Hong-Jiang Zhang.2002.
Query clustering using user logs.
ACM Trans-actions on Information Systems, 20(1):59?81.Xu, Jinxi and W. Bruce Croft.
1996.
Query expansionusing local and global document analysis.
In Pro-ceedings of SIGIR?96, Zurich, Switzerland.herbs herbsherbalmedicinalspicessupplementsremediesherbs for herbs forherbsherbs andwith herbsherbs for chronic herbs for chronicand herbs for chronicherbs forfor forfor chronic for chronicchronicof chronicfor chronic constipation for chronic constipationchronic constipationfor constipationchronic chronicacutepatientstreatmentchronic constipation chronic constipationof chronic constipationwith chronic constipationconstipation constipationbowelcommonsymptomsfor mexican for mexicanmexicanthe mexicanof mexicanfor mexican cooking mexican foodmexican food andmexican glossarymexican mexicanmexicothe mexicanmexican cooking mexican cookingmexican foodmexicancookingcooking cookingculinaryrecipescookfoodrecipeTable 7: Phrase translations applicable to sourcestrings herbs for chronic constipation and herbsfor mexican cooking.744
