Towards Robust Animacy Classification Using MorphosyntacticDistributional FeaturesLilja ?vrelidNLP-unit, Dept.
of SwedishGo?teborg UniversitySE-40530 Go?teborg, Swedenlilja.ovrelid@svenska.gu.seAbstractThis paper presents results from ex-periments in automatic classification ofanimacy for Norwegian nouns usingdecision-tree classifiers.
The methodmakes use of relative frequency measuresfor linguistically motivated morphosyn-tactic features extracted from an automati-cally annotated corpus of Norwegian.
Theclassifiers are evaluated using leave-one-out training and testing and the initial re-sults are promising (approaching 90% ac-curacy) for high frequency nouns, howeverdeteriorate gradually as lower frequencynouns are classified.
Experiments at-tempting to empirically locate a frequencythreshold for the classification method in-dicate that a subset of the chosen mor-phosyntactic features exhibit a notable re-silience to data sparseness.
Results will bepresented which show that the classifica-tion accuracy obtained for high frequencynouns (with absolute frequencies >1000)can be maintained for nouns with consid-erably lower frequencies (?50) by back-ing off to a smaller set of features at clas-sification.1 IntroductionAnimacy is a an inherent property of the referentsof nouns which has been claimed to figure as aninfluencing factor in a range of different gram-matical phenomena in various languages and itis correlated with central linguistic concepts suchas agentivity and discourse salience.
Knowledgeabout the animacy of a noun is therefore rele-vant for several different kinds of NLP problemsranging from coreference resolution to parsing andgeneration.In recent years a range of linguistic studies haveexamined the influence of argument animacy ingrammatical phenomena such as differential ob-ject marking (Aissen, 2003), the passive construc-tion (Dingare, 2001), the dative alternation (Bres-nan et al, 2005), etc.
A variety of languages aresensitive to the dimension of animacy in the ex-pression and interpretation of core syntactic argu-ments (Lee, 2002; ?vrelid, 2004).
A key general-isation or tendency observed there is that promi-nent grammatical features tend to attract otherprominent features;1 subjects, for instance, willtend to be animate and agentive, whereas objectsprototypically are inanimate and themes/patients.Exceptions to this generalisation express a moremarked structure, a property which has conse-quences, for instance, for the distributional prop-erties of the structure in question.Even though knowledge about the animacy ofa noun clearly has some interesting implications,little work has been done within the field of lex-ical acquisition in order to automatically acquiresuch knowledge.
Ora?san and Evans (2001) makeuse of hyponym-relations taken from theWord Netresource (Fellbaum, 1998) in order to classify ani-mate referents.
However, such a method is clearlyrestricted to languages for which large scale lexi-cal resources, such as the Word Net, are available.Merlo and Stevenson (2001) present a method forverb classification which relies only on distribu-tional statistics taken from corpora in order to traina decision tree classifier to distinguish betweenthree groups of intransitive verbs.1The notion of prominence has been linked to severalproperties such as most likely as topic, agent, most availablereferent, etc.47This paper presents experiments in automaticclassification of the animacy of unseen Norwe-gian common nouns, inspired by the method forverb classification presented in Merlo and Steven-son (2001).
The learning task is, for a given com-mon noun, to classify it as either belonging to theclass animate or inanimate.
Based on correlationsbetween animacy and other linguistic dimensions,a set of morphosyntactic features is presented andshown to differentiate common nouns along thebinary dimension of animacy with promising re-sults.
The method relies on aggregated relative fre-quencies for common noun lemmas, hence mightbe expected to seriously suffer from data sparse-ness.
Experiments attempting to empirically lo-cate a frequency threshold for the classificationmethod will therefore be presented.
It turns outthat a subset of the chosen morphosyntactic ap-proximators of animacy show a resilience to datasparseness which can be exploited in classifica-tion.
By backing off to this smaller set of features,we show that we can maintain the same classifica-tion accuracy also for lower frequency nouns.The rest of the paper is structured as follows.Section 2 identifies and motivates the set of chosenfeatures for the classification task and describeshow these features are approximated through fea-ture extraction from an automatically annotatedcorpus of Norwegian.
In section 3, a group of ex-periments testing the viability of the method andchosen features is presented.
Section 4 goes on toinvestigate the effect of sparse data on the clas-sification performance and present experimentswhich address possible remedies for the sparsedata problem.
Section 5 sums up the main find-ings of the previous sections and outlines a fewsuggestions for further research.2 Features of animacyAs mentioned above, animacy is highly correlatedwith a number of other linguistic concepts, suchas transitivity, agentivity, topicality and discoursesalience.
The expectation is that marked configu-rations along these dimensions, e.g.
animate ob-jects or inanimate agents, are less frequent in thedata.
However, these are complex notions to trans-late into extractable features from a corpus.
Inthe following we will present some morphologicaland syntactic features which, in different ways, ap-proximate the multi-faceted property of animacy:Transitive subject and (direct) object As men-tioned earlier, a prototypical transitive rela-tion involves an animate subject and an inan-imate object.
In fact, a corpus study of an-imacy distribution in simple transitive sen-tences in Norwegian revealed that approxi-mately 70% of the subjects of these typesof sentences were animate, whereas as manyas 90% of the objects were inanimate (?vre-lid, 2004).
Although this corpus study in-volved all types of nominal arguments, in-cluding pronouns and proper nouns, it stillseems that the frequency with which a cer-tain noun occurs as a subject or an object ofa transitive verb might be an indicator of itsanimacy.Demoted agent in passive Agentivity is anotherrelated notion to that of animacy, animate be-ings are usually inherently sentient, capableof acting volitionally and causing an event totake place - all properties of the prototypi-cal agent (Dowty, 1991).
The passive con-struction, or rather the property of being ex-pressed as the demoted agent in a passiveconstruction, is a possible approximator ofagentivity.
It is well known that transitiveconstructions tend to passivize better (hencemore frequently) if the demoted subject bearsa prominent thematic role, preferably agent.Anaphoric reference by personal pronounAnaphoric reference is a phenomenon wherethe animacy of a referent is clearly expressed.The Norwegian personal pronouns distin-guish their antecedents along the animacydimension - animate han/hun ?he/she?
vs.inanimate den/det ?it-MASC/NEUT?.Anaphoric reference by reflexive pronounReflexive pronouns represent another formof anaphoric reference, and, may, in contrastto the personal pronouns locate their an-tecedent locally, i.e.
within the same clause.In the prototypical reflexive constructionthe subject and the reflexive object arecoreferent and it describes an action directedat oneself.
Although the reflexive pronoun inNorwegian does not distinguish for animacy,the agentive semantics of the constructionmight still favour an animate subject.Genitive -s There is no extensive case system forcommon nouns in Norwegian and the only48distinction that is explicitly marked on thenoun is the genitive case by addition of -s.The genitive construction typically describespossession, a relation which often involves ananimate possessor.2.1 Feature extractionIn order to train a classifier to distinguish betweenanimate and inanimate nouns, training data con-sisting of distributional statistics on the above fea-tures were extracted from a corpus.
For this end,a 15 million word version of the Oslo Corpus, acorpus of Norwegian texts of approximately 18.5million words, was employed.2 The corpus is mor-phosyntactically annotated and assigns an under-specified dependency-style analysis to each sen-tence.3For each noun, relative frequencies for the dif-ferent morphosyntactic features described abovewere computed from the corpus, i.e.
the frequencyof the feature relative to this noun is divided bythe total frequency of the noun.
For transitive sub-jects (SUBJ), we extracted the number of instanceswhere the noun in question was unambiguouslytagged as subject, followed by a finite verb and anunambiguously tagged object.4 The frequency ofdirect objects (OBJ) for a given noun was approx-imated to the number of instances where the nounin question was unambiguously tagged as object.We here assume that an unambiguously taggedobject implies an unambiguously tagged subject.However, by not explicitly demanding that the ob-ject is preceded by a subject, we also capture ob-jects with a ?missing?
subject, such as objects oc-curring in relative clauses and infinitival clauses.As mentioned earlier, another context where an-imate nouns might be predominant is in the by-phrase expressing the demoted agent of a passiveverb (PASS).
Norwegian has two ways of express-ing the passive, a morphological passive (verb +s) and a periphrastic passive (bli + past participle).The counts for passive by-phrases allow for bothtypes of passives to precede the by-phrase contain-ing the noun in question.2The corpus is freely available for research purposes, seehttp://www.hf.uio.no/tekstlab for more information.3The actual framework is that of Constraint Grammar(Karlsson et al, 1995), and the analysis is underspecifiedas the nodes are labelled only with their dependency func-tion, e.g.
subject or prepositional object, and their immediateheads are not uniquely determined.4The tagger works in an eliminative fashion, so tokensmay bear two or more tags when they have not been fullydisambiguated.With regard to the property of anaphoric ref-erence by personal pronouns, the extraction wasbound to be a bit more difficult.
The anaphoricpersonal pronoun is never in the same clause asthe antecedent, and often not even in the same sen-tence.
Coreference resolution is a complex prob-lem, and certainly not one that we shall attempt tosolve in the present context.
However, we mightattempt to come up with a metric that approxi-mates the coreference relation in a manner ade-quate for our purposes, that is, which captures thedifferent coreference relation for animate as op-posed to inanimate nouns.
To this end, we makeuse of the common assumption that a personal pro-noun usually refers to a discourse salient elementwhich is fairly recent in the discourse.
Now, ifa sentence only contains one core argument (i.e.an intransitive subject) and it is followed by a sen-tence initiated by a personal pronoun, it seems rea-sonable to assume that these are coreferent (Haleand Charniak, 1998).
For each of the nouns then,we count the number of times it occurs as a sub-ject with no subsequent object and an immediatelyfollowing sentence initiated by (i) an animate per-sonal pronoun (ANAAN) and (ii) an inanimate per-sonal pronouns (ANAIN).The feature of reflexive coreference is easierto approximate, as this coreference takes placewithin the same clause.
For each noun, the num-ber of occurrences as a subject followed by averb and the 3.person reflexive pronoun seg ?him-/her-/itself?
are counted and its relative frequencyrecorded.
The genitive feature (GEN) simply con-tains relative frequencies of the occurrence of eachnoun with genitive case marking, i.e.
the suffix -s.3 Method viabilityIn order to test the viability of the classificationmethod for this task, and in particular, the chosenfeatures, a set of forty highly frequent nouns wereselected - twenty animate and twenty inanimatenouns.
A frequency threshold of minimum onethousand occurrences ensured sufficient data forall the features, as shown in table 1, which reportsthe mean values along with the standard deviationfor each class and feature.
The total data pointsfor each feature following the data collection areas follows: SUBJ: 16813, OBJ: 24128, GEN:7830, PASS: 577, ANAANIM: 989, ANAINAN:944, REFL: 558.
As we can see, quite a few ofthe features express morphosyntactic cues that are49SUBJ OBJ GEN PASS ANAAN ANAIN REFLClass Mean SD Mean SD Mean SD Mean SD Mean SD Mean SD Mean SDA 0.14 0.05 0.11 0.03 0.04 0.02 0.006 0.005 0.009 0.006 0.003 0.003 0.005 0.0008I 0.07 0.03 0.23 0.10 0.02 0.03 0.002 0.002 0.003 0.002 0.006 0.003 0.001 0.0008Table 1: Mean relative frequencies and standard deviation for each class (A(nimate) vs.
I(nanimate))from feature extraction (SUBJ=Transitive Subject, OBJ=Object, GEN=Genitive -s, PASS=Passive by-phrase, ANAAN=Anaphoric reference by animate pronoun, ANAIN=Anaphoric reference by inanimatepronoun, REFL=Anaphoric reference by reflexive pronoun).Feature % AccuracySUBJ 85.0OBJ 72.5GEN 72.5PASS 62.5ANAAN 67.5ANAIN 50.0REFL 82.5Table 2: Accuracy for the in-dividual features using leave-one-out training and testingFeatures used Feature Not Used % Accuracy1.
SUBJ OBJ GEN PASS ANAAN ANAIN REFL 87.52.
OBJ GEN PASS ANAAN ANAIN REFL SUBJ 85.03.
SUBJ GEN PASS ANAAN ANAIN REFL OBJ 87.54.
SUBJ OBJ PASS ANAAN ANAIN REFL GEN 85.05.
SUBJ OBJ GEN ANAAN ANAIN REFL PASS 82.56.
SUBJ OBJ GEN PASS ANAIN REFL ANAAN 82.57.
SUBJ OBJ GEN PASS ANAAN REFL ANAIN 87.58.
SUBJ OBJ GEN PASS ANAAN ANAIN REFL 75.09.
OBJ PASS ANAAN ANAIN SUBJ GEN REFL 77.5Table 3: Accuracy for all features and ?all minus one?
using leave-one-outtraining and testingrather rare.
This is in particular true for the passivefeature and the anaphoric features ANAAN, ANAINand REFL.
There is also quite a bit of variation inthe data (represented by the standard deviation foreach class-feature combination), a property whichis to be expected as all the features represent ap-proximations of animacy, gathered from an auto-matically annotated, possibly quite noisy, corpus.Even so, the features all express a difference be-tween the two classes in terms of distributionalproperties; the difference between the mean fea-ture values for the two classes range from doubleto five times the lowest class value.3.1 Experiment 1Based on the data collected on seven different fea-tures for our 40 nouns, a set of feature vectors areconstructed for each noun.
They contain the rel-ative frequencies for each feature along with thename of the noun and its class (animate or inan-imate).
Note that the vectors do not contain themean values presented in Table 1 above, but ratherthe individual relative frequencies for each noun.The experimental methodology chosen for theclassification experiments is similar to the one de-scribed in Merlo and Stevenson (2001) for verbclassification.
We also make use of leave-one-out training and testing of the classifiers and thesame software package for decision tree learning,C5.0 (Quinlan, 1998), is employed.
In addition, allour classifiers employ the boosting option for con-structing classifiers (Quinlan, 1993).
For calcula-tion of the statistical significance of differences inthe performance of classifiers tested on the samedata set, McNemar?s test is employed.Table 2 shows the performance of each individ-ual feature in the classification of animacy.
Aswe can see, the performance of the features dif-fer quite a bit, ranging from mere baseline per-formance (ANAIN) to a 70% improvement of thebaseline (SUBJ).
The first line of Table 3 shows theperformance using all the seven features collec-tively where we achieve an accuracy of 87.5%, a75% improvement of the baseline.
The SUBJ, GENand REFL features employed individually are thebest performing individual features and their clas-sification performance do not differ significantlyfrom the performance of the combined classifier,whereas the rest of the individual features do (atthe p<.05 level).The subsequent lines (2-8) of Table 3 show theaccuracy results for classification using all fea-tures except one at a time.
This provides an in-dication of the contribution of each feature to theclassification task.
In general, the removal of afeature causes a 0% - 12.5% deterioration of re-sults, however, only the difference in performancecaused by the removal of the REFL feature is sig-nificant (at the p<0.05 level).
Since this feature isone of the best performing features individually, itis not surprising that its removal causes a notabledifference in performance.
The removal of the50ANAIN feature, on the other hand, does not haveany effect on accuracy whatsoever.
This featurewas the poorest performing feature with a base-line, or mere chance, performance.
We also see,however, that the behaviour of the features in com-bination is not strictly predictable from their indi-vidual performance, as presented in table 2.
TheSUBJ, GEN and REFL features were the strongestfeatures individually with a performance that didnot differ significantly from that of the combinedclassifier.
However, as line 9 in Table 3 shows, theclassifier as a whole is not solely reliant on thesethree features.
When they are removed from thefeature pool, the performance (77.5% accuracy)does not differ significantly (p<.05) from that ofthe classifier employing all features collectively.4 Data sparseness and back-offThe classification experiments reported above im-pose a frequency constraint (absolute frequencies>1000) on the nouns used for training and test-ing, in order to study the interaction of the differ-ent features without the effects of sparse data.
Inthe light of the rather promising results from theseexperiments, however, it might be interesting tofurther test the performance of our features in clas-sification as the frequency constraint is graduallyrelaxed.To this end, three sets of common nouns eachcounting 40 nouns (20 animate and 20 inanimatenouns) were randomly selected from groups ofnouns with approximately the same frequency inthe corpus.
The first set included nouns with anabsolute frequency of 100 +/-20 (?100), the sec-ond of 50+/-5 (?50) and the third of 10+/-2 (?10).Feature extraction followed the same procedure asin experiment 1, relative frequencies for all sevenfeatures were computed and assembled into fea-ture vectors, one for each noun.4.1 Experiment 2: Effect of sparse data onclassificationIn order to establish how much of the generaliz-ing power of the old classifier is lost when the fre-quency of the nouns is lowered, an experiment wasconducted which tested the performance of the oldclassifier, i.e.
a classifier trained on all the morefrequent nouns, on the three groups of less fre-quent nouns.
As we can see from the first col-umn in Table 4, this resulted in a clear deteriora-tion of results, from our earlier accuracy of 87.5%to new accuracies ranging from 70% to 52.5%,barely above the baseline.
Not surprisingly, theresults decline steadily as the absolute frequencyof the classified noun is lowered.Accuracy results provide an indication that theclassification is problematic.
However, it does notindicate what the damage is to each class as such.A confusion matrix is in this respect more infor-mative.
Confusion matrices for the classificationof the three groups of nouns, ?100, ?50 and?10,are provided in table 5.
These clearly indicate thatit is the animate class which suffers when data be-comes more sparse.
The percentage of misclas-sified animate nouns drop drastically from 50%at ?100 to 80% at ?50 and finally 95% at ?10.The classification of the inanimate class remainspretty stable throughout.
The fact that a major-ity of our features (SUBJ, GEN, PASS, ANAAN andREFL) target animacy, in the sense that a higherproportion of animate than inanimate nouns ex-hibit the feature, gives a possible explanation forthis.
As data gets more limited, this differentia-tion becomes harder to make, and the animate fea-ture profiles come to resemble the inanimate moreand more.
Because the inanimate nouns are ex-pected to have low proportions (compared to theanimate) for all these features, the data sparsenessis not as damaging.
In order to examine the effecton each individual feature of the lowering of thefrequency threshold, we also ran classifiers trainedon the high frequency nouns with only individualfeatures on the three groups of new nouns.
Theseresults are depicted in Table 4.
In our earlier exper-iment, the performance of a majority of the indi-vidual features (OBJ, PASS, ANAAN, ANAIN) wassignificantly worse (at the p<0.05 level) than theperformance of the classifier including all the fea-tures.
Three of the individual features (SUBJ, GEN,REFL) had a performance which did not differ sig-nificantly from that of the classifier employing allthe features in combination.As the frequency threshold is lowered, how-ever, the performance of the classifiers employ-ing all features and those trained only on individ-ual features become more similar.
For the ?100nouns, only the two anaphoric features ANAANand the reflexive feature REFL, have a performancethat differs significantly (p<0.05) from the clas-sifier employing all features.
For the ?50 and?10 nouns, there are no significant differencesbetween the classifiers employing individual fea-51Freq All SUBJ OBJ GEN PASS ANAAN ANAIN REFL?100 70.0 75.0 80.0 72.5 65.0 52.5 50.0 60.0?50 57.5 75.0 62.5 77.5 62.5 57.5 50.0 55.0?10 52.5 52.5 65.0 50.0 57.5 50.0 50.0 50.0Table 4: Accuracy obtained when employing the old classifier on new lower-frequency nouns with leave-one-out training and testing: all and individual features?100 nouns(a) (b) ?
classified as10 10 (a) class animate2 18 (b) class inanimate?50 nouns(a) (b) ?
classified as4 16 (a) class animate1 19 (b) class inanimate?10 nouns(a) (b) ?
classified as1 19 (a) class animate20 (b) class inanimateTable 5: Confusion matrices for classification of lower frequency nouns with old classifiertures only and the classifiers trained on the featureset as a whole.
This indicates that the combinedclassifiers no longer exhibit properties that are notpredictable from the individual features alone andthey do not generalize over the data based on thecombinations of features.In terms of accuracy, a few of the individual fea-tures even outperform the collective result.
On av-erage, the three most frequent features, the SUBJ,OBJ and GEN features, improve the performanceby 9.5% for the ?100 nouns and 24.6% for the?50 nouns.
For the lowest frequency nouns (?10)we see that the object feature alone improves theresult by almost 24%, from 52.5% to 65 % accu-racy.
In fact, the object feature seems to be themost stable feature of all the features.
When ex-amining the means of the results extracted for thedifferent features, the object feature is the featurewhich maintains the largest difference between thetwo classes as the frequency threshold is lowered.The second most stable feature in this respect isthe subject feature.The group of experiments reported above showsthat the lowering of the frequency threshold for theclassified nouns causes a clear deterioration of re-sults in general, and most gravely when all the fea-tures are employed together.4.2 Experiment 3: Back-off featuresThe three most frequent features, the SUBJ, OBJand GEN features, were the most stable in thetwo experiments reported above and had a perfor-mance which did not differ significantly from thecombined classifiers throughout.
In light of thiswe ran some experiments where all possible com-binations of these more frequent features were em-ployed.
The results for each of the three groups ofnouns is presented in Table 6.
The exclusion of theless frequent features has a clear positive effect onthe accuracy results, as we can see in table 6.
Forthe?100 and?50 nouns, the performance has im-proved compared to the classifier trained both onall the features and on the individual features.
Theclassification performance for these nouns is nowidentical or only slightly worse than the perfor-mance for the high-frequency nouns in experiment1.
For the ?10 group of nouns, the performanceis, at best, the same as for all the features and atworse fluctuating around baseline.In general, the best performing feature com-binations are SUBJ&OBJ&GEN and SUBJ&OBJ .These two differ significantly (at the p<.05 level)from the results obtained by employing all the fea-tures collectively for both the ?100 and the ?50nouns, hence indicate a clear improvement.
Thefeature combinations both contain the two moststable features - one feature which targets the an-imate class (SUBJ) and another which target theinanimate class (OBJ), a property which facilitatesdifferentiation even as the marginals between thetwo decrease.It seems, then, that backing off to the mostfrequent features might constitute a partial rem-edy for the problems induced by data sparse-ness in the classification.
The feature combina-tions SUBJ&OBJ&GEN and SUBJ&OBJ both sig-nificantly improve the classification performanceand actually enable us to maintain the same accu-racy for both the ?100 and ?50 nouns as for thehigher frequency nouns, as reported in experiment1.52Freq SUBJ&OBJ&GEN SUBJ&OBJ SUBJ&GEN OBJ&GEN?100 87.5 87.5 77.5 85.0?50 82.5 90.0 70.0 77.5?10 57.5 50.0 50.0 47.5Table 6: Accuracy obtained when employing the old classifier on new lower-frequency nouns: combina-tions of the most frequent features4.3 Experiment 4: Back-off classifiersAnother option, besides a back-off to more fre-quent features in classification, is to back off toanother classifier, i.e.
a classifier trained on nounswith a similar frequency.
An approach of this kindwill attempt to exploit any group similarities thatthese nouns may have in contrast to the mores fre-quent ones, hopefully resulting in a better classifi-cation.In this experiment classifiers were trained andtested using leave-one-out cross-validation on thethree groups of lower frequency nouns and em-ploying individual, as well as various other fea-ture combinations.
The results for all features aswell as individual features are summarized in Ta-ble 7.
As we can see, the result for the classifieremploying all the features has improved somewhatcompared to the corresponding classifiers in ex-periment 3 (as reported above in Table 4) for allour three groups of nouns.
This indicates that thereis a certain group similarity for the nouns of sim-ilar frequency that is captured in the combinationof the seven features.
However, backing off to aclassifier trained on nouns that are more similarfrequency-wise does not cause an improvement inclassification accuracy.
Apart from the SUBJ fea-ture for the ?100 nouns, none of the other clas-sifiers trained on individual or all features for thethree different groups differ significantly (p<.05)from their counterparts in experiment 3.As before, combinations of the most frequentfeatures were employed in the new classifierstrained and tested on each of the three frequency-ordered groups of nouns.
In the terminology em-ployed above, this amounts to a backing off bothclassifier- and feature-wise.
The accuracy mea-sures obtained for these experiments are summa-rized in table 8.
For these classifiers, the backedoff feature combinations do not differ significantly(at the p<.05 level) from their counterparts in ex-periment 3, where the classifiers were trained onthe more frequent nouns with feature back-off.5 ConclusionThe above experiments have shown that the classi-fication of animacy for Norwegian common nounsis achievable using distributional data from a mor-phosyntactically annotated corpus.
The chosenmorphosyntactic features of animacy have provento differentiate well between the two classes.
Aswe have seen, the transitive subject, direct objectand morphological genitive provide stable featuresfor animacy even when the data is sparse(r).
Fourgroups of experiments have been reported abovewhich indicate that a reasonable remedy for sparsedata in animacy classification consists of back-ing off to a smaller feature set in classification.These experiments indicate that a classifier trainedon highly frequent nouns (experiment 1) backedoff to the most frequent features (experiment 3)sufficiently capture generalizations which pertainto nouns with absolute frequencies down to ap-proximately fifty occurrences and enables an un-changed performance approaching 90% accuracy.Even so, there are certainly still possibilities forimprovement.
As is well-known, singleton occur-rences of nouns abound and the above classifica-tion method is based on data for lemmas, ratherthan individual instances or tokens.
One possibil-ity to be explored is token-based classification ofanimacy, possibly in combination with a lemma-based approach like the one outlined above.Such an approach might also include a finersubdivision of the nouns.
We have chosen to clas-sify along a binary dimension, however, it mightbe argued that this is an artificial dichotomy.
(Za-enen et al, 2004) describe an encoding schemefor the manual encoding of animacy informa-tion in part of the English Switchboard corpus.They make a three-way distinction between hu-man, other animates, and inanimates, where the?other animates?
category describes a rather het-erogeneous group of entities: organisations, an-imals, intelligent machines and vehicles.
How-ever, what these seem to have in common is thatthey may all be construed linguistically as ani-53Freq All SUBJ OBJ GEN PASS ANAAN ANAIN REFL?100 85.0 52.5 87.5 65.0 70.0 50.0 57.5 50.0?50 77.5 77.5 75.0 75.0 50.0 50.0 50.0 50.0?10 52.5 50.0 62.5 50.0 50.0 50.0 50.0 50.0Table 7: Accuracy obtained when employing a new classifier on new lower-frequency nouns: all andindividual featuresFreq SUBJ&OBJ&GEN SUBJ&OBJ SUBJ&GEN OBJ&GEN?100 85.0 85.0 67.5 82.5?50 75.0 80.0 75.0 70.0?10 62.5 62.5 50.0 62.5Table 8: Accuracy obtained when employing a new classifier on new lower-frequency nouns: combina-tions of the most frequent featuresmate beings, even though they, in the real world,are not.
Interestingly, the two misclassified inani-mate nouns in experiment 1, were bil ?car?
and fly?air plane?, both vehicles.
A token-based approachto classification might better capture the context-dependent and dual nature of these types of nouns.Automatic acquisition of animacy in itself is notnecessarily the primary goal.
By testing the use ofacquired animacy information in various NLP ap-plications such as parsing, generation or corefer-ence resolution, we might obtain an extrinsic eval-uation measure for the usefulness of animacy in-formation.
Since very frequent nouns are usuallywell described in other lexical resources, it is im-portant that a method for animacy classification isfairly robust to data sparseness.
This paper sug-gests that a method based on seven morphosyntac-tic features, in combination with feature back-off,can contribute towards such a classification.ReferencesJudith Aissen.
2003.
Differential Object Marking:Iconicity vs. Economy.
Natural Language and Lin-guistic Theory, 21:435?483.Joan Bresnan, Anna Cueni, Tatiana Nikitina and Har-ald Baayen.
2005.
Predicting the Dative Alterna-tion.
To appear in Royal Netherlands Academy ofScience Workshop on Foundations of Interpretationproceedings.Shipra Dingare.
2001.
The effect of feature hierarchieson frequencies of passivization in English.
M.A.Thesis, Stanford University.David Dowty.
1991.
Thematic Proto-Roles and Argu-ment Selection.
Language, 67(3):547?619.John Hale and Eugene Charniak.
1998.
Getting UsefulGender Statistics from English Text.
Technical Re-port, Comp.
Sci.
Dept.
at Brown University, Provi-dence, Rhode Island.Christiane Fellbaum, editor.
1998.
WordNet, an elec-tronic lexical database.
MIT Press.Fred Karlsson and Atro Voutilainen and Juha Heikkila?and Atro Anttila.
1995.
Constraint Grammar:A language-independent system for parsing unre-stricted text.
Mouton de Gruyer.Hanjung Lee.
2002.
Prominence Mismatch andMarkedness Reduction in Word Order.
Natural Lan-guage and Linguistic Theory, 21(3):617?680.Paola Merlo and Suzanne Stevenson.
2001.
Auto-matic Verb Classification Based on Statistical Distri-butions of Argument Structure.
Computational Lin-guistics, 27(3):373?408.Constantin Ora?san and Richard Evans.
2001.
Learningto Identify Animate References.
in Proceedings ofthe Workshop on Computational Natural LanguageLearning, ACL-2001.Lilja ?vrelid.
2004.
Disambiguation of syntactic func-tions in Norwegian: modeling variation in word or-der interpretations conditioned by animacy and def-initeness.
in Fred Karlsson (ed.
): Proceedings ofthe 20th Scandinavian Conference of Linguistics,Helsinki.J.
Ross Quinlan.
1998.
C5.0: An Informal Tutorial.http://www.rulequest.com/see5-unix.html.J.
Ross Quinlan.
1993.
C4.5: Programs for machinelearning.
Morgan Kaufmann Publishers, Series inMachine Learning.Annie Zaenen, Jean Carletta, Gregory Garretson,Joan Bresnan, Andrew Koontz-Garboden, TatianaNikitina, M. Catherine O?Connor and Tom Wasow.2004.
Animacy encoding in English: why and how.in D. Byron and B. Webber (eds.
): Proceedings ofACL Workshop on Discourse Annotation, Barcelona.54
