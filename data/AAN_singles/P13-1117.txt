Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1190?1200,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsCross-lingual Transfer of Semantic Role Labeling ModelsMikhail Kozhevnikov and Ivan TitovSaarland University, Postfach 15 11 5066041 Saarbru?cken, Germany{mkozhevn|titov}@mmci.uni-saarland.deAbstractSemantic Role Labeling (SRL) has be-come one of the standard tasks of naturallanguage processing and proven useful asa source of information for a number ofother applications.
We address the prob-lem of transferring an SRL model fromone language to another using a sharedfeature representation.
This approach isthen evaluated on three language pairs,demonstrating competitive performance ascompared to a state-of-the-art unsuper-vised SRL system and a cross-lingual an-notation projection baseline.
We also con-sider the contribution of different aspectsof the feature representation to the perfor-mance of the model and discuss practicalapplicability of this method.1 Background and MotivationSemantic role labeling has proven useful in manynatural language processing tasks, such as ques-tion answering (Shen and Lapata, 2007; Kaisserand Webber, 2007), textual entailment (Sammonset al, 2009), machine translation (Wu and Fung,2009; Liu and Gildea, 2010; Gao and Vogel, 2011)and dialogue systems (Basili et al, 2009; van derPlas et al, 2009).Multiple models have been designed to auto-matically predict semantic roles, and a consider-able amount of data has been annotated to trainthese models, if only for a few more popular lan-guages.
As the annotation is costly, one would liketo leverage existing resources to minimize the hu-man effort required to construct a model for a newlanguage.A number of approaches to the construction ofsemantic role labeling models for new languageshave been proposed.
On one end of the scale isunsupervised SRL, such as Grenager and Manning(2006), which requires some expert knowledge,but no labeled data.
It clusters together argumentsthat should bear the same semantic role, but doesnot assign a particular role to each cluster.
On theother end is annotating a new dataset from scratch.There are also intermediate options, which oftenmake use of similarities between languages.
Thisway, if an accurate model exists for one language,it should help simplify the construction of a modelfor another, related language.The approaches in this third group often use par-allel data to bridge the gap between languages.Cross-lingual annotation projection systems (Pado?and Lapata, 2009), for example, propagate infor-mation directly via word alignment links.
How-ever, they are very sensitive to the quality of par-allel data, as well as the accuracy of a source-language model on it.An alternative approach, known as cross-lingualmodel transfer, or cross-lingual model adaptation,consists of modifying a source-language model tomake it directly applicable to a new language.
Thisusually involves constructing a shared feature rep-resentation across the two languages.
McDon-ald et al (2011) successfully apply this idea tothe transfer of dependency parsers, using part-of-speech tags as the shared representation of words.A later extension of Ta?ckstro?m et al (2012) en-riches this representation with cross-lingual wordclusters, considerably improving the performance.In the case of SRL, a shared representation thatis purely syntactic is likely to be insufficient, sincestructures with different semantics may be realizedby the same syntactic construct, for example ?inAugust?
vs ?in Britain?.
However with the help ofrecently introduced cross-lingual word represen-1190tations, such as the cross-lingual clustering men-tioned above or cross-lingual distributed word rep-resentations of Klementiev et al (2012), we maybe able to transfer models of shallow semantics ina similar fashion.In this work we construct a shared feature repre-sentation for a pair of languages, employing cross-lingual representations of syntactic and lexical in-formation, train a semantic role labeling model onone language and apply it to the other one.
Thisapproach yields an SRL model for a new languageat a very low cost, effectively requiring only asource language model and parallel data.We evaluate on five (directed) language pairs ?EN-ZH, ZH-EN, EN-CZ, CZ-EN and EN-FR, whereEN, FR, CZ and ZH denote English, French, Czechand Chinese, respectively.
The transferred modelis compared against two baselines: an unsuper-vised SRL system and a model trained on the out-put of a cross-lingual annotation projection sys-tem.In the next section we will describe our setup,then in section 3 present the shared feature repre-sentation we use, discuss the evaluation data andother technical aspects in section 4, present theresults and conclude with an overview of relatedwork.2 SetupThe purpose of the study is not to develop a yetanother semantic role labeling system ?
any exist-ing SRL system can (after some modification) beused in this setup ?
but to assess the practical ap-plicability of cross-lingual model transfer to thisproblem, compare it against the alternatives andidentify its strong/weak points depending on a par-ticular setup.2.1 Semantic Role Labeling ModelWe consider the dependency-based version of se-mantic role labeling as described in Hajic?
et al(2009) and transfer an SRL model from one lan-guage to another.
We only consider verbal pred-icates and ignore the predicate disambiguationstage.
We also assume that the predicate identifi-cation information is available ?
in most languagesit can be obtained using a relatively simple heuris-tic based on part-of-speech tags.The model performs argument identificationand classification (Johansson and Nugues, 2008)separately in a pipeline ?
first each candidate isclassified as being or not being a head of an argu-ment phrase with respect to the predicate in ques-tion and then each of the arguments is assigned arole from a given inventory.
The model is factor-ized over arguments ?
the decisions regarding theclassification of different arguments are made in-dependently of each other.With respect to the use of syntactic annotationwe consider two options: using an existing depen-dency parser for the target language and obtainingone by means of cross-lingual transfer (see sec-tion 4.2).Following McDonald et al (2011), we assumethat a part-of-speech tagger is available for the tar-get language.2.2 SRL in the Low-resource SettingSeveral approaches have been proposed to obtainan SRL model for a new language with little orno manual annotation.
Unsupervised SRL mod-els (Lang and Lapata, 2010) cluster the argumentsof predicates in a given corpus according to theirsemantic roles.
The performance of such modelscan be impressive, especially for those languageswhere semantic roles correlate strongly with syn-tactic relation of the argument to its predicate.However, assigning meaningful role labels to theresulting clusters requires additional effort and themodel?s parameters generally need some adjust-ment for every language.If the necessary resources are already availablefor a closely related language, they can be uti-lized to facilitate the construction of a model forthe target language.
This can be achieved ei-ther by means of cross-lingual annotation projec-tion (Yarowsky et al, 2001) or by cross-lingualmodel transfer (Zeman and Resnik, 2008).This last approach is the one we are consideringin this work, and the other two options are treatedas baselines.
The unsupervised model will be fur-ther referred to as UNSUP and the projection base-line as PROJ.2.3 Evaluation MeasuresWe use the F1 measure as a metric for the argu-ment identification stage and accuracy as an ag-gregate measure of argument classification perfor-mance.
When comparing to the unsupervised SRLsystem the clustering evaluation measures are usedinstead.
These are purity and collocation1191PU = 1N?imaxj|Gj ?
Ci|CO = 1N?jmaxi|Gj ?
Ci|,where Ci is the set of arguments in the i-th inducedcluster, Gj is the set of arguments in the jth goldcluster and N is the total number of arguments.We report the harmonic mean of the two (Lang andLapata, 2011) and denote it F c1 to avoid confusingit with the supervised metric.3 Model TransferThe idea of this work is to abstract the model awayfrom the particular source language and apply itto a new one.
This setup requires that we use thesame feature representation for both languages, forexample part-of-speech tags and dependency rela-tion labels should be from the same inventory.Some features are not applicable to certain lan-guages because the corresponding phenomena areabsent in them.
For example, consider a stronglyinflected language and an analytic one.
While thelatter can usually convey the information encodedin the word form in the former one (number, gen-der, etc.
), finding a shared feature representationfor such information is non-trivial.
In this studywe will confine ourselves to those features that areapplicable to all languages in question, namely:part-of-speech tags, syntactic dependency struc-tures and representations of the word?s identity.3.1 Lexical InformationWe train a model on one language and apply it to adifferent one.
In order for this to work, the wordsof the two languages have to be mapped into acommon feature space.
It is also desirable thatclosely related words from both languages havesimilar representations in this space.Word mapping.
The first option is simply to usethe source language words as the shared represen-tation.
Here every source language word wouldhave itself as its representation and every targetword would map into a source word that corre-sponds to it.
In other words, we supply the modelwith a gloss of the target sentence.The mapping (bilingual dictionary) we use isderived from a word-aligned parallel corpus, byidentifying, for each word in the target language,the word in the source language it is most oftenaligned to.Cross-lingual clusters.
There is no guaranteethat each of the words in the evaluation data ispresent in our dictionary, nor that the correspond-ing source-language word is present in the trainingdata, so the model would benefit from the abilityto generalize over closely related words.
This can,for example, be achieved by using cross-lingualword clusters induced in Ta?ckstro?m et al (2012).We incorporate these clusters as features into ourmodel.3.2 Syntactic InformationPart-of-speech Tags.
We map part-of-speech tagsinto the universal tagset following Petrov et al(2012).
This may have a negative effect on theperformance of a monolingual model, since mostpart-of-speech tagsets are more fine-grained thanthe universal POS tags considered here.
For exam-ple Penn Treebank inventory contains 36 tags andthe universal POS tagset ?
only 12.
Since the finer-grained POS tags often reflect more language-specific phenomena, however, they would only beuseful for very closely related languages in thecross-lingual setting.The universal part-of-speech tags used in eval-uation are derived from gold-standard annotationfor all languages except French, where predictedones had to be used instead.Dependency Structure.
Another important aspectof syntactic information is the dependency struc-ture.
Most dependency relation inventories arelanguage-specific, and finding a shared representa-tion for them is a challenging problem.
One couldmap dependency relations into a simplified formthat would be shared between languages, as it isdone for part-of-speech tags in Petrov et al (2012).The extent to which this would be useful, however,depends on the similarity of syntactic-semantic in-terfaces of the languages in question.In this work we discard the dependency rela-tion labels where the inventories do not match andonly consider the unlabeled syntactic dependencygraph.
Some discrepancies, such as variations inattachment order, may be present even there, butthis does not appear to be the case with the datasetswe use for evaluation.
If a target language is poorin resources, one can obtain a dependency parserfor the target language by means of cross-lingualmodel transfer (Zeman and Resnik, 2008).
We1192take this into account and evaluate both using theoriginal dependency structures and the ones ob-tained by means of cross-lingual model transfer.3.3 The ModelThe model we use is based on that of Bjo?rkelundet al (2009).
It is comprised of a set of linear clas-sifiers trained using Liblinear (Fan et al, 2008).The feature model was modified to accommodatethe cross-lingual cluster features and the rerankercomponent was not used.We do not model the interaction between differ-ent argument roles in the same predicate.
Whilethis has been found useful, in the cross-lingualsetup one has to be careful with the assumptionsmade.
For example, modeling the sequence ofroles using a Markov chain (Thompson et al,2003) may not work well in the present setting,especially between distant languages, as the orderor arguments is not necessarily preserved.
Mostconstraints that prove useful for SRL (Chang etal., 2007) also require customization when appliedto a new language, and some rely on language-specific resources, such as a valency lexicon.
Tak-ing into account the interaction between differentarguments of a predicate is likely to improve theperformance of the transferred model, but this isoutside the scope of this work.3.4 Feature SelectionCompatibility of feature representations is neces-sary but not sufficient for successful model trans-fer.
We have to make sure that the features we useare predictive of similar outcomes in the two lan-guages as well.Depending on the pair of languages in ques-tion, different aspects of the feature representationwill retain or lose their predictive power.
We canbe reasonably certain that the identity of an ar-gument word is predictive of its semantic role inany language, but it might or might not be trueof, for example, the word directly preceding theargument word.
It is therefore important to pre-POS part-of-speech tagsSynt unlabeled dependency graphCls cross-lingual word clustersGloss glossed word formsDeprel dependency relationsTable 1: Feature groups.vent the model from capturing overly specific as-pects of the source language, which we do by con-fining the model to first-order features.
We alsoavoid feature selection, which, performed on thesource language, is unlikely to help the model tobetter generalize to the target one.
The experi-ments confirm that feature selection and the useof second-order features degrade the performanceof the transferred model.3.5 Feature GroupsFor each word, we use its part-of-speech tag,cross-lingual cluster id, word identity (glossed,when evaluating on the target language) and itsdependency relation to its parent.
Features associ-ated with an argument word include the attributesof the predicate word, the argument word, its par-ent, siblings and children, and the words directlypreceding and following it.
Also included are thesequences of part-of-speech tags and dependencyrelations on the path between the predicate and theargument.Since we are also interested in the impact of dif-ferent aspects of the feature representation, we di-vide the features into groups as summarized in ta-ble 1 and evaluate their respective contributions tothe performance of the model.
If a feature groupis enabled ?
the model has access to the corre-sponding source of information.
For example, ifonly POS group is enabled, the model relies onthe part-of-speech tags of the argument, the pred-icate and the words to the right and left of the ar-gument word.
If Synt is enabled too, it also usesthe POS tags of the argument?s parent, childrenand siblings.Word order information constitutes an implicitgroup that is always available.
It includes thePosition feature, which indicates whether theargument is located to the left or to the right ofthe predicate, and allows the model to look up theattributes of the words directly preceding and fol-lowing the argument word.
The model we com-pare against the baselines uses all applicable fea-ture groups (Deprel is only used in EN-CZ andCZ-EN experiments with original syntax).4 Evaluation4.1 Datasets and PreprocessingEvaluation of the cross-lingual model transfer re-quires a rather specific kind of dataset.
Namely,the data in both languages has to be annotated1193with the same set of semantic roles following thesame (or compatible) guidelines, which is seldomthe case.
We have identified three language pairsfor which such resources are available: English-Chinese, English-Czech and English-French.The evaluation datasets for English and Chi-nese are those from the CoNLL Shared Task2009 (Hajic?
et al, 2009) (henceforth CoNLL-ST).Their annotation in the CoNLL-ST is not identi-cal, but the guidelines for ?core?
semantic rolesare similar (Kingsbury et al, 2004), so we eval-uate only on core roles here.
The data for thesecond language pair is drawn from the PragueCzech-English Dependency Treebank 2.0 (Hajic?et al, 2012), which we converted to a format simi-lar to that of CoNLL-ST1.
The original annotationuses the tectogrammatical representation (Hajic?,2002) and an inventory of semantic roles (or func-tors), most of which are interpretable across vari-ous predicates.
Also note that the syntactic anno-tation of English and Czech in PCEDT 2.0 is quitesimilar (to the extent permitted by the differencein the structure of the two languages) and we canuse the dependency relations in our experiments.For English-French, the English CoNLL-STdataset was used as a source and the model wasevaluated on the manually annotated dataset fromvan der Plas et al (2011).
The latter contains onethousand sentences from the French part of the Eu-roparl (Koehn, 2005) corpus, annotated with se-mantic roles following an adapted version of Prop-Bank (Palmer et al, 2005) guidelines.
The au-thors perform annotation projection from Englishto French, using a joint model of syntax and se-mantics and employing heuristics for filtering.
Weuse a model trained on the output of this projec-tion system as one of the baselines.
The evalua-tion dataset is relatively small in this case, so weperform the transfer only one-way, from Englishto French.The part-of-speech tags in all datasets were re-placed with the universal POS tags of Petrov et al(2012).
For Czech, we have augmented the map-pings to account for the tags that were not presentin the datasets from which the original mappingswere derived.
Namely, tag ?t?
is mapped to?VERB?
and ?Y?
?
to ?PRON?.We use parallel data to construct a bilingualdictionary used in word mapping, as well asin the projection baseline.
For English-Czech1see http://www.ml4nlp.de/code-and-data/treex2conlland English-French, the data is drawn from Eu-roparl (Koehn, 2005), for English-Chinese ?
fromMultiUN (Eisele and Chen, 2010).
The wordalignments were obtained using GIZA++ (Ochand Ney, 2003) and the intersection heuristic.4.2 Syntactic TransferIn the low-resource setting, we cannot alwaysrely on the availability of an accurate dependencyparser for the target language.
If one is not avail-able, the natural solution would be to use cross-lingual model transfer to obtain it.Unfortunately, the models presented in the pre-vious work, such as Zeman and Resnik (2008),McDonald et al (2011) and Ta?ckstro?m et al(2012), were not made available, so we repro-duced the direct transfer algorithm of McDonaldet al (2011), using Malt parser (Nivre, 2008) andthe same set of features.
We did not reimple-ment the projected transfer algorithm, however,and used the default training procedure instead ofperceptron-based learning.
The dependency struc-ture thus obtained is, of course, only a rough ap-proximation ?
even a much more sophisticated al-gorithm may not perform well when transferringsyntax between such languages as Czech and En-glish, given the inherent difference in their struc-ture.
The scores are shown in table 2.We will henceforth refer to the syntactic annota-tions that were provided with the datasets as orig-inal, as opposed to the annotations obtained bymeans of syntactic transfer.4.3 BaselinesUnsupervised Baseline: We are using a versionof the unsupervised semantic role induction sys-tem of Titov and Klementiev (2012a) adapted toSetup UAS, %EN-ZH 35ZH-EN 42EN-CZ 36CZ-EN 39EN-FR 67Table 2: Syntactic transfer accuracy, unlabeled at-tachment score (percent).
Note that in case ofFrench we evaluate against the output of a super-vised system, since manual annotation is not avail-able for this dataset.
This score does not reflect thetrue performance of syntactic transfer.1194the shared feature representation considered in or-der to make the scores comparable with thoseof the transfer model and, more importantly, toenable evaluation on transferred syntax.
Notethat the original system, tailored to a more ex-pressive language-specific syntactic representa-tion and equipped with heuristics to identify ac-tive/passive voice and other phenomena, achieveshigher scores than those we report here.Projection Baseline: The projection baseline weuse for English-Czech and English-Chinese is astraightforward one: we label the source side of aparallel corpus using the source-language model,then identify those verbs on the target side that arealigned to a predicate, mark them as predicates andpropagate the argument roles in the same fashion.A model is then trained on the resulting trainingdata and applied to the test set.For English-French we instead use the output ofa fully featured projection model of van der Plas etal.
(2011), published in the CLASSiC project.5 ResultsIn order to ensure that the results are consistent,the test sets, except for the French one, were par-titioned into five equal parts (of 5 to 10 thousandsentences each, depending on the dataset) and theevaluation performed separately on each one.
Allevaluation figures for English, Czech or Chinesebelow are the average values over the five sub-sets.
In case of French, the evaluation dataset istoo small to split it further, so instead we ran theevaluation five times on a randomly selected 80%sample of the evaluation data and averaged overthose.
In both cases the results are consistent overthe subsets, the standard deviation does not exceed0.5% for the transfer system and projection base-line and 1% for the unsupervised system.5.1 Argument IdentificationWe summarize the results in table 3.
Argumentidentification is known to rely heavily on syntac-tic information, so it is unsurprising that it provesinaccurate when transferred syntax is used.
Oursimple projection baseline suffers from the sameproblem.
Even with original syntactic informationavailable, the performance of argument identifica-tion is moderate.
Note that the model of (van derPlas et al, 2011), though relying on more expres-sive syntax, only outperforms the transferred sys-tem by 3% (F1) on this task.Setup Syntax TRANS PROJEN-ZH trans 34.5 13.9ZH-EN trans 32.6 15.6EN-CZ trans 46.3 12.4CZ-EN trans 42.3 22.2EN-FR trans 61.6 43.5EN-ZH orig 51.7 19.6ZH-EN orig 53.2 29.7EN-CZ orig 63.9 59.3CZ-EN orig 67.3 60.9EN-FR orig 71.0 51.3Table 3: Argument identification, transferredmodel vs. projection baseline, F1.Most unsupervised SRL approaches assumethat the argument identification is performedby some external means, for example heuristi-cally (Lang and Lapata, 2011).
Such heuristicsor unsupervised approaches to argument identifi-cation (Abend et al, 2009) can also be used in thepresent setup.5.2 Argument ClassificationIn the following tables, TRANS column containsthe results for the transferred system, UNSUP ?for the unsupervised baseline and PROJ ?
for pro-jection baseline.
We highlight in bold the higherscore where the difference exceeds twice the max-imum of the standard deviation estimates of thetwo results.Table 4 presents the unsupervised evaluation re-sults.
Note that the unsupervised model performsas well as the transferred one or better where theSetup Syntax TRANS UNSUPEN-ZH trans 83.3 73.9ZH-EN trans 79.2 67.6EN-CZ trans 66.4 66.1CZ-EN trans 68.2 68.7EN-FR trans 74.6 65.1EN-ZH orig 84.5 89.7ZH-EN orig 79.2 83.0EN-CZ orig 74.1 74.0CZ-EN orig 74.6 76.7EN-FR orig 73.3 72.3Table 4: Argument classification, transferredmodel vs. unsupervised baseline in terms of theclustering metric F c1 (see section 2.3).1195Setup Syntax TRANS PROJEN-ZH trans 70.1 69.2ZH-EN trans 65.6 61.3EN-CZ trans 50.1 46.3CZ-EN trans 53.3 54.7EN-FR trans 65.1 66.1EN-ZH orig 71.7 69.7ZH-EN orig 66.1 64.4EN-CZ orig 59.0 53.2CZ-EN orig 61.0 60.8EN-FR orig 63.0 68.0Table 5: Argument classification, transferredmodel vs. projection baseline, accuracy.original syntactic dependencies are available.
Inthe more realistic scenario with transferred syn-tax, however, the transferred model proves moreaccurate.In table 5 we compare the transferred systemwith the projection baseline.
It is easy to seethat the scores vary strongly depending on the lan-guage pair, due to both the difference in the anno-tation scheme used and the degree of relatednessbetween the languages.
The drop in performancewhen transferring the model to another languageis large in every case, though, see table 6.Setup Target SourceEN-ZH 71.7 87.1ZH-EN 66.1 86.2EN-CZ 59.0 80.1CZ-EN 61.0 75.4EN-FR 63.0 82.5Table 6: Model accuracy on the source and targetlanguage using original syntax.
The source lan-guage scores for English vary between languagepairs because of the difference in syntactic anno-tation and role subset used.We also include the individual F1 scores forthe top-10 most frequent labels for EN-CZ trans-fer with original syntax in table 7.
The modelprovides meaningful predictions here, despite lowoverall accuracy.Most of the labels2 are self-explanatory: Pa-tient (PAT), Actor (ACT), Time (TWHEN), Effect(EFF), Location (LOC), Manner (MANN), Ad-dressee (ADDR), Extent (EXT).
CPHR marks the2http://ufal.mff.cuni.cz/?toman/pcedt/en/functors.htmlLabel Freq.
F1 Re.
Pr.PAT 14707 69.4 70.0 68.7ACT 14303 81.1 81.7 80.4TWHEN 3631 70.6 65.1 77.0EFF 2601 45.4 67.2 34.3LOC 1990 41.8 35.3 51.3MANN 1208 54.0 63.8 46.9ADDR 1045 30.2 34.4 26.8CPHR 791 20.4 13.1 45.0EXT 708 42.2 40.5 44.1DIR3 695 20.1 17.3 23.9Table 7: EN-CZ transfer (with original syntax), F1,recall and precision for the top-10 most frequentroles.nominal part of a complex predicate, as in ?to have[a plan]CPHR?, and DIR3 indicates destination.5.3 Additional ExperimentsWe now evaluate the contribution of different as-pects of the feature representation to the perfor-mance of the model.
Table 8 contains the resultsfor English-French.Features Orig TransPOS 47.5 47.5POS, Synt 53.0 53.1POS, Cls 53.7 53.7POS, Gloss 63.7 63.7POS, Synt, Cls 55.9 56.4POS, Synt, Gloss 65.2 66.3POS, Cls, Gloss 61.5 61.5POS, Synt, Cls, Gloss 63.0 65.1Table 8: EN-FR model transfer accuracy with dif-ferent feature subsets, using original and trans-ferred syntactic information.The fact that the model performs slightly bet-ter with transferred syntax may be explained bytwo factors.
Firstly, as we already mentioned, theoriginal syntactic annotation is also produced au-tomatically.
Secondly, in the model transfer setupit is more important how closely the syntactic-semantic interface on the target side resembles thaton the source side than how well it matches the?true?
structure of the target language, and in thisrespect a transferred dependency parser may havean advantage over one trained on target-languagedata.The high impact of the Gloss features here1196may be partly attributed to the fact that the map-ping is derived from the same corpus as the eval-uation data ?
Europarl (Koehn, 2005) ?
and partlyby the similarity between English and French interms of word order, usage of articles and prepo-sitions.
The moderate contribution of the cross-lingual cluster features are likely due to the insuf-ficient granularity of the clustering for this task.For more distant language pairs, the contribu-tions of individual feature groups are less inter-pretable, so we only highlight a few observations.First of all, both EN-CZ and CZ-EN benefit notice-ably from the use of the original syntactic annota-tion, including dependency relations, but not fromthe transferred syntax, most likely due to the lowsyntactic transfer performance.
Both perform bet-ter when lexical information is available, althoughthe improvement is not as significant as in the caseof French ?
only up to 5%.The situation with Chinese is somewhat compli-cated in that adding lexical information here failsto yield an improvement in terms of the metricconsidered.
This is likely due to the fact that weconsider only the core roles, which can usually bepredicted with high accuracy based on syntacticinformation alone.6 Related WorkDevelopment of robust statistical models for coreNLP tasks is a challenging problem, and adapta-tion of existing models to new languages presentsa viable alternative to exhaustive annotation foreach language.
Although the models thus obtainedare generally imperfect, they can be further refinedfor a particular language and domain using tech-niques such as active learning (Settles, 2010; Chenet al, 2011).Cross-lingual annotation projection (Yarowskyet al, 2001) approaches have been applied ex-tensively to a variety of tasks, including POStagging (Xi and Hwa, 2005; Das and Petrov,2011), morphology segmentation (Snyder andBarzilay, 2008), verb classification (Merlo et al,2002), mention detection (Zitouni and Florian,2008), LFG parsing (Wro?blewska and Frank,2009), information extraction (Kim et al, 2010),SRL (Pado?
and Lapata, 2009; van der Plas et al,2011; Annesi and Basili, 2010; Tonelli and Pi-anta, 2008), dependency parsing (Naseem et al,2012; Ganchev et al, 2009; Smith and Eisner,2009; Hwa et al, 2005) or temporal relation pre-diction (Spreyer and Frank, 2008).
Interestingly,it has also been used to propagate morphosyntac-tic information between old and modern versionsof the same language (Meyer, 2011).Cross-lingual model transfer methods (McDon-ald et al, 2011; Zeman and Resnik, 2008; Durrettet al, 2012; S?gaard, 2011; Lopez et al, 2008)have also been receiving much attention recently.The basic idea behind model transfer is similar tothat of cross-lingual annotation projection, as wecan see from the way parallel data is used in, forexample, McDonald et al (2011).A crucial component of direct transfer ap-proaches is the unified feature representation.There are at least two such representations oflexical information (Klementiev et al, 2012;Ta?ckstro?m et al, 2012), but both work on wordlevel.
This makes it hard to account for phenom-ena that are expressed differently in the languagesconsidered, for example the syntactic function ofa certain word may be indicated by a preposi-tion, inflection or word order, depending on thelanguage.
Accurate representation of such infor-mation would require an extra level of abstrac-tion (Hajic?, 2002).A side-effect of using adaptation methods is thatwe are forced to use the same annotation schemefor the task in question (SRL, in our case), whichin turn simplifies the development of cross-lingualtools for downstream tasks.
Such representationsare also likely to be useful in machine translation.Unsupervised semantic role labeling meth-ods (Lang and Lapata, 2010; Lang and Lapata,2011; Titov and Klementiev, 2012a; Lorenzo andCerisara, 2012) also constitute an alternative tocross-lingual model transfer.For an overview of of semi-supervised ap-proaches we refer the reader to Titov and Klemen-tiev (2012b).7 ConclusionWe have considered the cross-lingual model trans-fer approach as applied to the task of semantic rolelabeling and observed that for closely related lan-guages it performs comparably to annotation pro-jection approaches.
It allows one to quickly con-struct an SRL model for a new language withoutmanual annotation or language-specific heuristics,provided an accurate model is available for one ofthe related languages along with a certain amountof parallel data for the two languages.
While an-1197notation projection approaches require sentence-and word-aligned parallel data and crucially de-pend on the accuracy of the syntactic parsing andSRL on the source side of the parallel corpus,cross-lingual model transfer can be performed us-ing only a bilingual dictionary.Unsupervised SRL approaches have their ad-vantages, in particular when no annotated data isavailable for any of the related languages and thereis a syntactic parser available for the target one,but the annotation they produce is not always suf-ficient.
In applications such as Information Re-trieval it is preferable to have precise labels, ratherthan just clusters of arguments, for example.Also note that when applying cross-lingualmodel transfer in practice, one can improve uponthe performance of the simplistic model we usefor evaluation, for example by picking the featuresmanually, taking into account the properties of thetarget language.
Domain adaptation techniquescan also be employed to adjust the model to thetarget language.AcknowledgmentsThe authors would like to thank Alexandre Kle-mentiev and Ryan McDonald for useful sugges-tions and Ta?ckstro?m et al (2012) for sharing thecross-lingual word representations.
This researchis supported by the MMCI Cluster of Excellence.ReferencesOmri Abend, Roi Reichart, and Ari Rappoport.
2009.Unsupervised argument identification for semanticrole labeling.
In Proceedings of the Joint Con-ference of the 47th Annual Meeting of the ACLand the 4th International Joint Conference on Nat-ural Language Processing of the AFNLP, ACL ?09,pages 28?36, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Paolo Annesi and Roberto Basili.
2010.
Cross-lingualalignment of FrameNet annotations through hiddenMarkov models.
In Proceedings of the 11th interna-tional conference on Computational Linguistics andIntelligent Text Processing, CICLing?10, pages 12?25, Berlin, Heidelberg.
Springer-Verlag.Roberto Basili, Diego De Cao, Danilo Croce, Bonaven-tura Coppola, and Alessandro Moschitti.
2009.Cross-language frame semantics transfer in bilin-gual corpora.
In Alexander F. Gelbukh, editor, Pro-ceedings of the 10th International Conference onComputational Linguistics and Intelligent Text Pro-cessing, pages 332?345.Anders Bjo?rkelund, Love Hafdell, and Pierre Nugues.2009.
Multilingual semantic role labeling.
In Pro-ceedings of the Thirteenth Conference on Computa-tional Natural Language Learning (CoNLL 2009):Shared Task, pages 43?48, Boulder, Colorado, June.Association for Computational Linguistics.Ming-Wei Chang, Lev Ratinov, and Dan Roth.
2007.Guiding semi-supervision with constraint-drivenlearning.
In ACL.Chenhua Chen, Alexis Palmer, and Caroline Sporleder.2011.
Enhancing active learning for semantic rolelabeling via compressed dependency trees.
In Pro-ceedings of 5th International Joint Conference onNatural Language Processing, pages 183?191, Chi-ang Mai, Thailand, November.
Asian Federation ofNatural Language Processing.Dipanjan Das and Slav Petrov.
2011.
Unsupervisedpart-of-speech tagging with bilingual graph-basedprojections.
Proceedings of the Association forComputational Linguistics.Greg Durrett, Adam Pauls, and Dan Klein.
2012.
Syn-tactic transfer using a bilingual lexicon.
In Pro-ceedings of the 2012 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning, pages 1?11,Jeju Island, Korea, July.
Association for Computa-tional Linguistics.Andreas Eisele and Yu Chen.
2010.
MultiUN:A multilingual corpus from United Nation docu-ments.
In Proceedings of the Seventh InternationalConference on Language Resources and Evaluation(LREC?10).
European Language Resources Associ-ation (ELRA).Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
LIBLINEAR:A library for large linear classification.
Journal ofMachine Learning Research, 9:1871?1874.Kuzman Ganchev, Jennifer Gillenwater, and BenTaskar.
2009.
Dependency grammar induction viabitext projection constraints.
In Proceedings of the47th Annual Meeting of the ACL, pages 369?377,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Qin Gao and Stephan Vogel.
2011.
Corpus expan-sion for statistical machine translation with seman-tic role label substitution rules.
In Proceedings ofthe 49th Annual Meeting of the Association for Com-putational Linguistics: Human Language Technolo-gies, pages 294?298, Portland, Oregon, USA.Trond Grenager and Christopher D. Manning.
2006.Unsupervised discovery of a statistical verb lexicon.In Proceedings of EMNLP.Jan Hajic?.
2002.
Tectogrammatical representation:Towards a minimal transfer in machine translation.In Robert Frank, editor, Proceedings of the 6th In-ternational Workshop on Tree Adjoining Grammars1198and Related Frameworks (TAG+6), pages 216?226, Venezia.
Universita di Venezia.Jan Hajic?, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Anto`nia Mart?
?, Llu?
?sMa`rquez, Adam Meyers, Joakim Nivre, SebastianPado?, Jan S?te?pa?nek, Pavel Stran?a?k, Mihai Surdeanu,Nianwen Xue, and Yi Zhang.
2009.
The CoNLL-2009 shared task: Syntactic and semantic dependen-cies in multiple languages.
In Proceedings of theThirteenth Conference on Computational NaturalLanguage Learning (CoNLL 2009): Shared Task,pages 1?18, Boulder, Colorado.Jan Hajic?, Eva Hajic?ova?, Jarmila Panevova?, PetrSgall, Ondr?ej Bojar, Silvie Cinkova?, Eva Fuc??
?kova?,Marie Mikulova?, Petr Pajas, Jan Popelka, Jir??
?Semecky?, Jana S?indlerova?, Jan S?te?pa?nek, JosefToman, Zden?ka Ures?ova?, and Zdene?k Z?abokrtsky?.2012.
Announcing Prague Czech-English depen-dency treebank 2.0.
In Nicoletta Calzolari (Con-ference Chair), Khalid Choukri, Thierry Declerck,Mehmet Ug?ur Dog?an, Bente Maegaard, Joseph Mar-iani, Jan Odijk, and Stelios Piperidis, editors, Pro-ceedings of the Eight International Conference onLanguage Resources and Evaluation (LREC?12), Is-tanbul, Turkey, May.
European Language ResourcesAssociation (ELRA).Rebecca Hwa, Philip Resnik, Amy Weinberg, ClaraCabezas, and Okan Kolak.
2005.
Bootstrappingparsers via syntactic projection across parallel text.Natural Language Engineering, 11(3):311?325.Richard Johansson and Pierre Nugues.
2008.Dependency-based semantic role labeling of Prop-Bank.
In Proceedings of the 2008 Conference onEmpirical Methods in Natural Language Process-ing, pages 69?78, Honolulu, Hawaii.Michael Kaisser and Bonnie Webber.
2007.
Questionanswering based on semantic roles.
In ACL Work-shop on Deep Linguistic Processing.Seokhwan Kim, Minwoo Jeong, Jonghoon Lee, andGary Geunbae Lee.
2010.
A cross-lingual an-notation projection approach for relation detection.In Proceedings of the 23rd International Conferenceon Computational Linguistics, COLING ?10, pages564?571, Stroudsburg, PA, USA.
Association forComputational Linguistics.Paul Kingsbury, Nianwen Xue, and Martha Palmer.2004.
Propbanking in parallel.
In In Proceedingsof the Workshop on the Amazing Utility of Paral-lel and Comparable Corpora, in conjunction withLREC?04.Alexandre Klementiev, Ivan Titov, and Binod Bhat-tarai.
2012.
Inducing crosslingual distributed rep-resentations of words.
In Proceedings of the Inter-national Conference on Computational Linguistics(COLING), Bombay, India.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Conference Pro-ceedings: the tenth Machine Translation Summit,pages 79?86, Phuket, Thailand.
AAMT.Joel Lang and Mirella Lapata.
2010.
Unsuper-vised induction of semantic roles.
In Human Lan-guage Technologies: The 2010 Annual Conferenceof the North American Chapter of the Associationfor Computational Linguistics, pages 939?947, LosAngeles, California, June.
Association for Compu-tational Linguistics.Joel Lang and Mirella Lapata.
2011.
Unsupervisedsemantic role induction via split-merge clustering.In Proc.
of Annual Meeting of the Association forComputational Linguistics (ACL).Ding Liu and Daniel Gildea.
2010.
Semantic rolefeatures for machine translation.
In Proceedings ofthe 23rd International Conference on ComputationalLinguistics (Coling 2010), Beijing, China.Adam Lopez, Daniel Zeman, Michael Nossal, PhilipResnik, and Rebecca Hwa.
2008.
Cross-languageparser adaptation between related languages.
InIJCNLP-08 Workshop on NLP for Less PrivilegedLanguages, pages 35?42, Hyderabad, India, Jan-uary.Alejandra Lorenzo and Christophe Cerisara.
2012.Unsupervised frame based semantic role induction:application to French and English.
In Proceedingsof the ACL 2012 Joint Workshop on Statistical Pars-ing and Semantic Processing of MorphologicallyRich Languages, pages 30?35, Jeju, Republic of Ko-rea, July.
Association for Computational Linguistics.Ryan McDonald, Slav Petrov, and Keith Hall.
2011.Multi-source transfer of delexicalized dependencyparsers.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,EMNLP ?11, pages 62?72, Stroudsburg, PA, USA.Association for Computational Linguistics.Paola Merlo, Suzanne Stevenson, Vivian Tsang, andGianluca Allaria.
2002.
A multi-lingual paradigmfor automatic verb classification.
In Proceedingsof the 40th Annual Meeting of the Association forComputational Linguistics (ACL?02), pages 207?214, Philadelphia, PA.Roland Meyer.
2011.
New wine in old wineskins?
?Tagging old Russian via annotation projectionfrom modern translations.
Russian Linguistics,35(2):267(15).Tahira Naseem, Regina Barzilay, and Amir Globerson.2012.
Selective sharing for multilingual dependencyparsing.
In Proceedings of the 50th Annual Meet-ing of the Association for Computational Linguis-tics, pages 629?637, Jeju Island, Korea, July.
Asso-ciation for Computational Linguistics.Joakim Nivre.
2008.
Algorithms for deterministic in-cremental dependency parsing.
Comput.
Linguist.,34(4):513?553, December.1199Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1).Sebastian Pado?
and Mirella Lapata.
2009.
Cross-lingual annotation projection for semantic roles.Journal of Artificial Intelligence Research, 36:307?340.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The Proposition Bank: An annotated cor-pus of semantic roles.
Computational Linguistics,31:71?105.Slav Petrov, Dipanjan Das, and Ryan McDonald.
2012.A universal part-of-speech tagset.
In Proceedings ofLREC, May.Mark Sammons, Vinod Vydiswaran, Tim Vieira,Nikhil Johri, Ming wei Chang, Dan Goldwasser,Vivek Srikumar, Gourab Kundu, Yuancheng Tu,Kevin Small, Joshua Rule, Quang Do, and DanRoth.
2009.
Relation alignment for textual en-tailment recognition.
In Text Analysis Conference(TAC).Burr Settles.
2010.
Active learning literature survey.Computer Sciences Technical Report, 1648.Dan Shen and Mirella Lapata.
2007.
Using semanticroles to improve question answering.
In EMNLP.David A Smith and Jason Eisner.
2009.
Parser adap-tation and projection with quasi-synchronous gram-mar features.
In Proceedings of the 2009 Confer-ence on Empirical Methods in Natural LanguageProcessing, pages 822?831.
Association for Com-putational Linguistics.Benjamin Snyder and Regina Barzilay.
2008.
Cross-lingual propagation for morphological analysis.
InProceedings of the 23rd national conference on Ar-tificial intelligence.Anders S?gaard.
2011.
Data point selection for cross-language adaptation of dependency parsers.
In Pro-ceedings of the 49th Annual Meeting of the Associ-ation for Computational Linguistics: Human Lan-guage Technologies, volume 2 of HLT ?11, pages682?686, Stroudsburg, PA, USA.
Association forComputational Linguistics.Kathrin Spreyer and Anette Frank.
2008.
Projection-based acquisition of a temporal labeller.
Proceed-ings of IJCNLP 2008.Oscar Ta?ckstro?m, Ryan McDonald, and Jakob Uszko-reit.
2012.
Cross-lingual word clusters for directtransfer of linguistic structure.
In Proc.
of the An-nual Meeting of the North American Associationof Computational Linguistics (NAACL), pages 477?487, Montre?al, Canada.Cynthia A. Thompson, Roger Levy, and Christopher D.Manning.
2003.
A generative model for seman-tic role labeling.
In Proceedings of the 14th Eu-ropean Conference on Machine Learning, ECML2003, pages 397?408, Dubrovnik, Croatia.Ivan Titov and Alexandre Klementiev.
2012a.
ABayesian approach to unsupervised semantic role in-duction.
In Proc.
of European Chapter of the Asso-ciation for Computational Linguistics (EACL).Ivan Titov and Alexandre Klementiev.
2012b.
Semi-supervised semantic role labeling: Approachingfrom an unsupervised perspective.
In Proceedingsof the International Conference on ComputationalLinguistics (COLING), Bombay, India, December.Sara Tonelli and Emanuele Pianta.
2008.
Frame infor-mation transfer from English to Italian.
In Proceed-ings of LREC 2008.Lonneke van der Plas, James Henderson, and PaolaMerlo.
2009.
Domain adaptation with artificialdata for semantic parsing of speech.
In Proc.
2009Annual Conference of the North American Chap-ter of the Association for Computational Linguistics,pages 125?128, Boulder, Colorado.Lonneke van der Plas, Paola Merlo, and James Hen-derson.
2011.
Scaling up automatic cross-lingualsemantic role annotation.
In Proceedings of the 49thAnnual Meeting of the Association for Computa-tional Linguistics: Human Language Technologies,HLT ?11, pages 299?304, Stroudsburg, PA, USA.Association for Computational Linguistics.Alina Wro?blewska and Anette Frank.
2009.
Cross-lingual projection of LFG F-structures: Buildingan F-structure bank for Polish.
In Eighth Interna-tional Workshop on Treebanks and Linguistic Theo-ries, page 209.Dekai Wu and Pascale Fung.
2009.
Can semanticrole labeling improve SMT?
In Proceedings of 13thAnnual Conference of the European Association forMachine Translation (EAMT 2009), Barcelona.Chenhai Xi and Rebecca Hwa.
2005.
A backoffmodel for bootstrapping resources for non-Englishlanguages.
In Proceedings of the conference on Hu-man Language Technology and Empirical Methodsin Natural Language Processing, pages 851?858,Stroudsburg, PA, USA.David Yarowsky, Grace Ngai, and Ricahrd Wicen-towski.
2001.
Inducing multilingual text analysistools via robust projection across aligned corpora.
InProceedings of Human Language Technology Con-ference.Daniel Zeman and Philip Resnik.
2008.
Cross-language parser adaptation between related lan-guages.
In Proceedings of the IJCNLP-08 Workshopon NLP for Less Privileged Languages, pages 35?42, Hyderabad, India, January.
Asian Federation ofNatural Language Processing.Imed Zitouni and Radu Florian.
2008.
Mention detec-tion crossing the language barrier.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing.1200
