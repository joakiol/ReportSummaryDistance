Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 61?66,Baltimore, Maryland USA, June 23-24, 2014.c?2014 Association for Computational LinguisticsDKPro TC: A Java-based Framework for Supervised LearningExperiments on Textual DataJohannes Daxenberger?, Oliver Ferschke?
?, Iryna Gurevych?
?and Torsten Zesch???
UKP Lab, Technische Universit?t Darmstadt?
Information Center for Education, DIPF, Frankfurt?
Language Technology Lab, University of Duisburg-Essenhttp://www.ukp.tu-darmstadt.deAbstractWe present DKPro TC, a framework forsupervised learning experiments on tex-tual data.
The main goal of DKPro TC isto enable researchers to focus on the actualresearch task behind the learning problemand let the framework handle the rest.
Itenables rapid prototyping of experimentsby relying on an easy-to-use workflow en-gine and standardized document prepro-cessing based on the Apache Unstruc-tured Information Management Architec-ture (Ferrucci and Lally, 2004).
It shipswith standard feature extraction modules,while at the same time allowing the userto add customized extractors.
The exten-sive reporting and logging facilities makeDKPro TC experiments fully replicable.1 IntroductionSupervised learning on textual data is a ubiquitouschallenge in Natural Language Processing (NLP).Applying a machine learning classifier has be-come the standard procedure, as soon as there isannotated data available.
Before a classifier canbe applied, relevant information (referred to asfeatures) needs to be extracted from the data.
Awide range of tasks have been tackled in this wayincluding language identification, part-of-speech(POS) tagging, word sense disambiguation, sen-timent detection, and semantic similarity.In order to solve a supervised learning task,each researcher needs to perform the same set ofsteps in a predefined order: reading input data,preprocessing, feature extraction, machine learn-ing, and evaluation.
Standardizing this processis quite challenging, as each of these steps mightvary a lot depending on the task at hand.
To com-plicate matters further, the experimental processis usually embedded in a series of configurationchanges.
For example, introducing a new fea-ture often requires additional preprocessing.
Re-searchers should not need to think too much aboutsuch details, but focus on the actual research task.DKPro TC is our take on the standardization ofan inherently complex problem, namely the imple-mentation of supervised learning experiments fornew datasets or new learning tasks.We will make some simplifying assumptionswherever they do not harm our goal that the frame-work should be applicable to the widest possiblerange of supervised learning tasks.
For example,DKPro TC only supports a limited set of machinelearning frameworks, as we argue that differencesbetween frameworks will mainly influence run-time, but will have little influence on the final con-clusions to be drawn from the experiment.
Themain goal of DKPro TC is to enable the researcherto quickly find an optimal experimental configura-tion.
One of the major contributions of DKPro TCis the modular architecture for preprocessing andfeature extraction, as we believe that the focus ofresearch should be on a meaningful and expressivefeature set.
DKPro TC has already been applied toa wide range of different supervised learning tasks,which makes us confident that it will be of use tothe research community.DKPro TC is mostly written in Java and freelyavailable under an open source license.12 RequirementsIn the following, we give a more detailed overviewof the requirements and goals we have identifiedfor a general-purpose text classification system.These requirements have guided the developmentof the DKPro TC system architecture.1http://dkpro-tc.googlecode.com61Single-label Multi-label RegressionDocument Mode?
Spam Detection?
Sentiment Detection?
Text Categorization?
Keyphrase Assignment?
Text ReadabilityUnit/Sequence Mode?
Named Entity Recognition?
Part-of-Speech Tagging?
Dialogue Act Tagging ?
Word DifficultyPair Mode?
Paraphrase Identification?
Textual Entailment?
Relation Extraction ?
Text SimilarityTable 1: Supervised learning scenarios and feature modes supported in DKPro TC, with example NLPapplications.Flexibility Users of a system for supervisedlearning on textual data should be able to choosebetween different machine learning approachesdepending on the task at hand.
In supervised ma-chine learning, we have to distinguish between ap-proaches based on classification and approachesbased on regression.
In classification, given adocument d ?
D and a set of labels C ={c1, c2, ..., cn}, we want to label each documentd with L ?
C, where L is the set of relevantor true labels.
In single-label classification, eachdocument d is labeled with exactly one label, i.e.|L| = 1, whereas in multi-label classification, aset of labels is assigned, i.e.
|L| ?
1.
Single-label classification can further be divided into bi-nary classification (|C| = 2) and multi-class clas-sification (|C| > 2).
In regression, real numbersinstead of labels are assigned.Feature extraction should follow a modular de-sign in order to facilitate reuse and to allow seam-less integration of new features.
However, the wayin which features need to be extracted from the in-put documents depends on the the task at hand.We have identified several typical scenarios in su-pervised learning on textual data and propose thefollowing feature modes:?
In document mode, each input document willbe used as its own entity to be classified, e.g.an email classified as wanted or unwanted(spam).?
In unit/sequence mode, each input documentcontains several units to be classified.
Theunits in the input document cannot be dividedinto separate documents, either because thecontext of each unit needs to be preserved(e.g.
to disambiguate named entities) or be-cause they form a sequence which needs tobe kept (in sequence tagging).?
The pair mode is intended for problemswhich require a pair of texts as input, e.g.a pair of sentences to be classified as para-phrase or non-paraphrase.
It represents aspecial case of multi-instance learning (Sur-deanu et al., 2012), in which a document con-tains exactly two instances.Considering the outlined learning approaches andfeature modes, we have summarized typical sce-narios in supervised learning on textual data in Ta-ble 1 and added example applications in NLP.Replicability and Reusability As it has beenrecently noted by Fokkens et al.
(2013), NLP ex-periments are not replicable in most cases.
Theproblem already starts with undocumented pre-processing steps such as tokenization or sentenceboundary detection that might have heavy impacton experimental results.
In a supervised learningsetting, this situation is even worse, as e.g.
fea-ture extraction is usually only partially describedin the limited space of a research paper.
For ex-ample, a paper might state that ?n-gram features?were used, which encompasses a very broad rangeof possible implementations.In order to make NLP experiments replicable, atext classification framework should (i) encouragethe user to reuse existing components which theycan refer to in research papers rather than writ-ing their own components, (ii) document all per-formed steps, and (iii) make it possible to re-runexperiments with minimal effort.Apart from helping the replicability of experi-ments, reusing components allows the user to con-centrate on the new functionality that is specificto the planned experiment instead of having toreinvent the wheel.
The parts of a text classifi-cation system which can typically be reused are62preprocessing components, generic feature extrac-tors, machine learning algorithms, and evaluation.3 ArchitectureWe now give an overview of the DKPro TC archi-tecture that was designed to take into account therequirements outlined above.
A core design deci-sion is to model each of the typical steps in textclassification (reading input data and preprocess-ing, feature extraction, machine learning and eval-uation) as separate tasks.
This modular architec-ture helps the user to focus on the main problem,i.e.
developing and selecting good features.In the following, we describe each module inmore detail, starting with the workflow engine thatis used to assemble the tasks into an experiment.3.1 Configuration and Workflow EngineWe rely on the DKPro Lab (Eckart de Castilhoand Gurevych, 2011) workflow engine, which al-lows fine-grained control over the dependenciesbetween single tasks, e.g.
the pre-processing of adocument obviously needs to happen before thefeature extraction.
In order to shield the userfrom the complex ?wiring?
of tasks, DKPro TCcurrently provides three pre-defined workflows:Train/Test, Cross-Validation, and Prediction (onunseen data).
Each workflow supports the featuremodes described above: document, unit/sequence,and pair.The user is still able to control the behavior ofthe workflow by setting parameters, most impor-tantly the sources of input data, the set of featureextractors, and the classifier to be used.
Internally,each parameter is treated as a single dimensionin the global parameter space.
Users may pro-vide more than one value for a certain parame-ter, e.g.
specific feature sets or several classifiers.The workflow engine will automatically run allpossible parameter value combinations (a processcalled parameter sweeping).3.2 Reading Input DataInput data for supervised learning tasks comes inmyriad different formats which implies that read-ing data cannot be standardized, but needs to behandled individually for each data set.
However,the internal processing should not be dependent onthe input format.
We therefore use the CommonAnalysis Structure (CAS), provided by the ApacheUnstructured Information Management Architec-ture (UIMA), to represent input documents andannotations in a standardized way.Under the UIMA model, reading input datameans to transform arbitrary input data into aCAS representation.
DKPro TC already providesa wide range of readers from UIMA componentrepositories such as DKPro Core.2The readeralso needs to assign to each classification unit anoutcome attribute that represents the relevant label(single-label), labels (multi-label), or a real value(regression).
In unit/sequence mode, the readeradditionally needs to mark the units in the CAS.In pair mode, a pair of texts (instead of a singledocument) is stored within one CAS.3.3 PreprocessingIn this step, additional information about the docu-ment is added to the CAS, which efficiently storeslarge numbers of stand-off annotations.
In pairmode, the preprocessing is automatically appliedto both documents.DKPro TC allows the user to run arbitraryUIMA-based preprocessing components as longas they are compatible with the DKPro type sys-tem that is currently used by DKPro Core andEOP.3Thus, a large set of ready-to-use prepro-cessing components for more than ten languagesis available, containing e.g.
sentence boundary de-tection, lemmatization, POS-tagging, or parsing.3.4 Feature ExtractionDKPro TC ships a constantly growing number offeature extractors.
Feature extractors have accessto the document text as well as all the additionalinformation that has been added in the form ofUIMA stand-off annotations during the prepro-cessing step.
Users of DKPro TC can add cus-tomized feature extractors for particular use caseson demand.Among the ready-to-use feature extractors con-tained in DKPro TC, there are several ones ex-tracting grammatical information, e.g.
the plural-singular ratio or the ratio of modal to all verbs.Other features collect information about stylisticcues of a document, e.g.
the number of exclama-tions or the type-token-ratio.
DKPro TC is able toextract n-grams or skip n-grams of tokens, charac-ters, and POS tags.Some feature extractors need access to informa-tion about the entire document collection, e.g.
in2http://dkpro-core-asl.googlecode.com3http://hltfbk.github.io/Excitement-Open-Platform/63order to weigh lexical features with tf.idf scores.Such extractors have to declare that they dependon collection level information and DKPro TCwill automatically include a special task that isexecuted before the actual features are extracted.Depending on the feature mode which has beenconfigured, DKPro TC will extract informationon document level, unit- and/or sequence-level, ordocument pair level.DKPro TC stores extracted features in its inter-nal feature store.
When the extraction process isfinished, a configurable data writer converts thecontent from the feature store into a format whichcan be handled by the utilized machine learningtool.
DKPro TC currently ships data writers forthe Weka (Hall et al., 2009), Meka4, and Mallet(McCallum, 2002) frameworks.
Users can alsoadd dedicated data writers that output features inthe format used by the machine learning frame-work of their choice.3.5 Supervised LearningFor the actual machine learning, DKPro TC cur-rently relies on Weka (single-label and regres-sion), Meka (multi-label), and Mallet (sequencelabeling).
It contains a task which trains a freelyconfigurable classifier on the training data andevaluates the learned model on the test data.Before training and evaluation, the user may ap-ply dimensionality reduction to the feature set, i.e.select a limited number of (expectedly meaning-ful) features to be included for training and eval-uating the classifier.
DKPro TC uses the featureselection capabilities of Weka (single-label and re-gression) and Mulan (multi-label) (Tsoumakas etal., 2010).DKPro TC can also predict labels on unseen(i.e.
unlabeled) data, using a trained classifier.
Inthat case, no evaluation will be carried out, but theclassifier?s prediction for each document will bewritten to a file.3.6 Evaluation and ReportingDKPro TC calculates common evaluation scoresincluding accuracy, precision, recall, and F1-score.
Whenever sensible, scores are reported foreach individual label as well as aggregated overall labels.
To support users in further analyz-ing the performance of a classification workflow,DKPro TC outputs the confusion matrix, the ac-4http://meka.sourceforge.nettual predictions assigned to each document, and aranking of the most useful features based on theconfigured feature selection algorithm.
Additionaltask-specific reporting can be added by the user.As mentioned before, a major goal ofDKPro TC is to increase the replicability of NLPexperiments.
Thus, for each experiment, all con-figuration parameters are stored and will be re-ported together with the classification results.4 Tweet Classification: A Use CaseWe now give a brief summary of what a supervisedlearning task might look like in DKPro TC usinga simple Twitter sentiment classification example.Assuming that we want to classify a set of tweetseither as ?emotional?
or ?neutral?, we can use thesetup shown in Listing 1.
The example uses theGroovy programming language which yields bet-ter readable code, but pure Java is also supported.Likewise, a DKPro TC experiment can also be setup with the help of a configuration file, e.g.
inJSON or via Groovy scripts.First, we create a workflow as a BatchTask-CrossValidation which can be used to runa cross-validation experiment on the data (using10 folds as configured by the corresponding pa-rameter).
The workflow uses LabeledTweet-Reader in order to import the experiment datafrom source text files into the internal documentrepresentation (one document per tweet).
Thisreader adds a UIMA annotation that specifies thegold standard classification outcome, i.e.
the rel-evant label for the tweet.
In this use case, pre-processing consists of a single step: running theArkTweetTagger (Gimpel et al., 2011), a spe-cialized Twitter tokenizer and POS-tagger that isintegrated in DKPro Core.
The feature mode is setto document (one tweet per CAS), and the learningmode to single-label (each tweet is labeled withexactly one label), cf.
Table 1.Two feature extractors are configured: One forreturning the number of hashtags and another onereturning the ratio of emoticons to tokens in thetweet.
Listing 2 shows the Java code for the sec-ond extractor.
Two things are noteworthy: (i) doc-ument text and UIMA annotations are readilyavailable through the JCas object, and (ii) this isreally all that the user needs to write in order toadd a new feature extractor.The next item to be configured is the Weka-DataWriter which converts the internal fea-64BatchTaskCrossValidation batchTask = [experimentName: "Twitter-Sentiment",preprocessingPipeline: createEngineDescription(ArkTweetTagger), // PreprocessingparameterSpace: [ // multi-valued parameters in the parameter space will be sweptDimension.createBundle("reader", [readerTrain: LabeledTweetReader,readerTrainParams: [LabeledTweetReader.PARAM_CORPUS_PATH, "src/main/resources/tweets.txt"]]),Dimension.create("featureMode", "document"),Dimension.create("learningMode", "singleLabel"),Dimension.create("featureSet", [EmoticonRatioExtractor.name, NumberOfHashTagsExtractor.name]),Dimension.create("dataWriter", WekaDataWriter.name),Dimension.create("classificationArguments", [NaiveBayes.name, RandomForest.name])],reports: [BatchCrossValidationReport], // collects results from foldsnumFolds: 10];Listing 1: Groovy code to configure a DKPro TC cross-validation BatchTask on Twitter data.public class EmoticonRatioFeatureExtractorextends FeatureExtractorResource_ImplBase implements DocumentFeatureExtractor{@Overridepublic List<Feature> extract(JCas annoDb) throws TextClassificationException {int nrOfEmoticons = JCasUtil.select(annoDb, EMO.class).size();int nrOfTokens = JCasUtil.select(annoDb, Token.class).size();double ratio = (double) nrOfEmoticons / nrOfTokens;return new Feature("EmoticonRatio", ratio).asList();}}Listing 2: A DKPro TC document mode feature extractor measuring the ratio of emoticons to tokens.ture representation into the Weka ARFF format.For the classification, two machine learning algo-rithms will be iteratively tested: a Naive Bayesclassifier and a Random Forest classifier.
Pass-ing a list of parameters into the parameter spacewill automatically make DKPro TC test all pos-sible parameter combinations.
The classificationtask automatically trains a model on the trainingdata and stores the results of the evaluation onthe test data for each fold on the disk.
Finally,the evaluation scores for each fold are collectedby the BatchCrossValidationReport andwritten to a single file using a tabulated format.5 Related WorkThis section will give a brief overview about toolswith a scope similar to DKPro TC.
We only listfreely available software, most of which is open-source.
Unless otherwise indicated, all of the toolsare written in Java.ClearTK (Ogren et al., 2008) is conceptuallyclosest to DKPro TC and shares many of its dis-tinguishing features like the modular feature ex-tractors.
It provides interfaces to machine learn-ing libraries such as Mallet or libsvm, offers wrap-pers for basic NLP components, and comes witha feature extraction library that facilitates the de-velopment of custom feature extractors within theUIMA framework.
In contrast to DKPro TC, it israther designed as a programming library than acustomizable research environment for quick ex-periments and does not provide predefined textclassification setups.
Furthermore, it does not sup-port parameter sweeping and has no explicit sup-port for creating experiment reports.Argo (Rak et al., 2013) is a web-based work-bench with support for manual annotation and au-tomatic analysis of mainly bio-medical data.
LikeDKPro TC, Argo is based on UIMA, but focuseson sequence tagging, and it lacks DKPro TC?s pa-rameter sweeping capabilities.NLTK (Bird et al., 2009) is a general-purposeNLP toolkit written in Python.
It offers com-ponents for a wide range of preprocessing tasksand also supports feature extraction and machinelearning for supervised text classification.
LikeDKPro TC, it can be used to quickly setup baselineexperiments.
As opposed to DKPro TC, NLTKlacks a modular structure with respect to prepro-cessing and feature extraction and does not sup-port parameter sweeping.Weka (Hall et al., 2009) is a machine learningframework that covers only the last two steps ofDKPro TC?s experimental process, i.e.
machinelearning and evaluation.
However, it offers no ded-icated support for preprocessing and feature gener-ation.
Weka is one of the machine learning frame-works that can be used within DKPro TC for ac-tual machine learning.Mallet (McCallum, 2002) is another machine65learning framework implementing several super-vised and unsupervised learning algorithms.
Asopposed to Weka, is also supports sequence tag-ging, including Conditional Random Fields, aswell as topic modeling.
Mallet can be used as ma-chine learning framework within DKPro TC.Scikit-learn (Pedregosa et al., 2011) is a ma-chine learning framework written in Python.
Itoffers basic functionality for preprocessing, fea-ture selection, and parameter tuning.
It providessome methods for preprocessing such as convert-ing documents to tf.idf vectors, but does not offersophisticated and customizable feature extractorsfor textual data like DKPro TC.6 Summary and Future WorkWe have presented DKPro TC, a comprehensiveand flexible framework for supervised learning ontextual data.
DKPro TC makes setting up exper-iments and creating new features fast and simple,and can therefore be applied for rapid prototyp-ing.
Its extensive logging capabilities emphasizethe replicability of results.
In our own researchlab, DKPro TC has successfully been applied to awide range of tasks including author identification,text quality assessment, and sentiment detection.There are some limitations to DKPro TC whichwe plan to address in future work.
To reduce theruntime of experiments with very large documentcollections, we want to add support for parallelprocessing of documents.
While the current maingoal of DKPro TC is to bootstrap experiments onnew data sets or new applications, we also plan tomake DKPro TC workflows available as resourcesto other applications, so that a model trained withDKPro TC can be used to automatically label tex-tual data in different environments.AcknowledgmentsThis work has been supported by the Volks-wagen Foundation as part of the Lichtenberg-Professorship Program under grant No.
I/82806,and by the Hessian research excellence pro-gram ?Landes-Offensive zur EntwicklungWissenschaftlich-?konomischer Exzellenz?
(LOEWE) as part of the research center ?DigitalHumanities?.
The authors would like give specialthanks to Richard Eckhart de Castilho, NicolaiErbs, Lucie Flekova, Emily Jamison, KrishPerumal, and Artem Vovk for their contributionsto the DKPro TC framework.ReferencesS.
Bird, E. Loper, and E. Klein.
2009.
Natural Lan-guage Processing with Python.
O?Reilly Media Inc.R.
Eckart de Castilho and I. Gurevych.
2011.
ALightweight Framework for Reproducible Parame-ter Sweeping in Information Retrieval.
In Proc.
ofthe Workshop on Data Infrastructures for Support-ing Information Retrieval Evaluation, pages 7?10.D.
Ferrucci and A. Lally.
2004.
UIMA: An Ar-chitectural Approach to Unstructured InformationProcessing in the Corporate Research Environment.Natural Language Engineering, 10(3-4):327?348.A.
Fokkens, M. van Erp, M. Postma, T. Pedersen,P.
Vossen, and N. Freire.
2013.
Offspring fromReproduction Problems: What Replication FailureTeaches Us.
In Proc.
ACL, pages 1691?1701.K.
Gimpel, N. Schneider, B. O?Connor, D. Das,D.
Mills, J. Eisenstein, M. Heilman, D. Yogatama,J.
Flanigan, and N. Smith.
2011.
Part-of-speechtagging for Twitter: annotation, features, and exper-iments.
In Proc.
ACL, pages 42?47.M.
Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reute-mann, and I. Witten.
2009.
The WEKA Data Min-ing Software: An Update.
SIGKDD Explorations,11(1):10?18.A.
McCallum.
2002.
MALLET: A Machine Learningfor Language Toolkit.P.
Ogren, P. Wetzler, and S. Bethard.
2008.
ClearTK:A UIMA toolkit for statistical natural language pro-cessing.
In Towards Enhanced Interoperability forLarge HLT Systems: UIMA for NLP workshop atLREC, pages 32?38.F.
Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,B.
Thirion, O. Grisel, M. Blondel, P. Pretten-hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-sos, D. Cournapeau, M. Brucher, M. Perrot, andE.
Duchesnay.
2011.
Scikit-learn: Machine Learn-ing in Python.
Journal of Machine Learning Re-search, 12:2825?2830.R.
Rak, A. Rowley, J. Carter, and S. Ananiadou.2013.
Development and Analysis of NLP Pipelinesin Argo.
In Proc.
ACL, pages 115?120.M.
Surdeanu, J. Tibshirani, R. Nallapati, and C. Man-ning.
2012.
Multi-instance multi-label learning forrelation extraction.
In Proc.
EMNLP-CoNLL, pages455?465.G.
Tsoumakas, I. Katakis, and I. Vlahavas.
2010.
Min-ing Multi-label Data.
Transformation, 135(2):1?20.66
