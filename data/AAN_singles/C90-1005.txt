Tagging for Learning:Collecting Thematic Relations from CorpusUri Zernik and Paul JacobsArtificial Intelligence ProgramGE Research and Development CenterSchenectady, NY 12301USAAbstractRecent work in text analysis has suggestedthat data on words that frequently occur to-gether reveal important information abouttext content.
Co-occurrence relations canserve two main purposes in language pro-cessing.
First, the statistics of co-occurrencehave been shown to produce accurate resultsin syntactic analysis.
Second, the way thatwords appear together can help in assign-ing thematic roles in semantic interpreta-tion.
This paper discusses a method for col-lecting co-occurrence data, ~quir ing lexicalrelations from the data, and applying theserelations to semantic analysis.1 IntroductionTwo text processing problems rely heavily on co-occurrence patterns-  the way that words appear to-gether, possibly idiosyncraticly.
First, statisticallyweighted co-occurrence information can assist in the"bracketing" of noun groups, which can otherwiselead to a eombinatoric explosion of parse trees \[1\].Second, co-occurrence r lations can provide evidenceof semantic information for thematic-role assignment,an important ask that is otherwise fraught with in-accuracy.Only co-occurrence patterns collected over a corpuscan help to determine which is .object and which isrecipient in PAID DIVIDEND (IS SECURE) vs. PAIDSHAREHOLDERS (ARE SATISFIED).
A sufficientlyrich lexicon would include the semantic preferencesfor distinguishing these thematic roles, but such alexicon does not yet exist.Co-occurrence patterns are a means of probing aglobal corpus for clues that help resolve ambiguity atthe local sentence level.
Patterns such as PAID TOSHAREHOLDERS and PAID THEM THE DIVIDENDare detected in the corpus at large.
Through theselatter examples, in which the distinction between re-cipient and object relative to the dative verb PAY ismade explicit, the former cases in which tile relationis implicit can be resolved.In contrast o previous work which addressed theidentification of surface relations, i.e., SVO triples \[2\],in our work we address the acquisition of semantic re-lations, focussing at the assigment of thematic roles.This task (i.e.
tagging for acquisition) requires highreliability and so it relies less on statistical propertiesand more on deterministic local marking.In this paper we discuss a technique for parsingand semanticly analyzing complex sentences with theaid of co-occurrence relations, and show how theserelations are acquired from tagged corpus.1.1 The  PhenomenonConsider, for example, the sentence below, takenfrom the Dow-Jones newswire:THE LARGEST CO~iPANY ON THE LIST,WHICH LAST PAID SHAREHOLDERS IN JANUARY,SAID THE 5 PC STOCK DIVIDEND WOULD BEPAYABLE FOLLOWING THE PAYMENT OF THECASH DIVIDEND.
(DJ, October 27, 1988)For this sentence, which is not exotic or unusualin its complexity, there are 24 non-trivial differentparse trees.
Human readers, in contrast to mostprograms, can quickly identify groups of words that"hang together" such as COMPANY PAID A DIVI-DEND, STOCK DIVIDEND, and CASH DIVIDEND,and use these clusters to understand the sentenceunambiguously.
Moreover, a human reader can eas-ily recognize SHAREHOLDERS as recipient and DIV-IDEND as the object of PAY.
Along these lines, ourprogram develops the capability to identify such pat-terns by training on a large corpus of examples.1.2 The  Tra in ing  CorpusThe training corpus, from which our lexical infor-mation is extracted, consists of more than ten rail-34 ilion words from the Dow Jones newswire (10 monthsworth of stories).
For the root PAY, for instance, wecollected more than 6000 examples, 20 of which aregiven below.To exploit this data, a system must transform com-mon patterns into operational templates, encoding acore relation between the words.
The sections thatfollow describe the evolution and implementation ofthis acquisition technique.2 Co-occur rence :  P rev ious  WorkGarside \[4\] and Church et al \[1\] provided a majorimpetus for this line of work.
In Church's work, acollection of English collocations bootstrapped from atagged corpus facilitated the construction of an adap-tive "tagger", a program that annotates a text withpart-of-speech information.Frank Smadja \[7\] continued Church's effort bycollecting operational pairs such as verb-noun andadjective-noun pairs.
Smadja used these pairs to con-strain \]\[exical choice in a language generator; for ex-ample, the system prefers "deposit a check" to "placea check" based on the frequency of co-occurrence ofdeposit and check.Ido Dagan \[3\] pursued this topic further by pro-jecting co-occurrences beyond the local context, us-ing collocations for anaphora resolution.
For examplein,THE CAR WAS DRIVING ON THE ROAD.SUDDENLY IT BRAKED.CAR is selected over ROAD as the anaphor of IT, sinceCAR BRAKE is a stronger collocation than ROADBRAKE.
Interestingly, this idea complements Wilks'preference semantics \[8\], in which preference is basedon a semantic hierarchy.
In Dagan's method, prefer-ences are based on word patterns acquired from cor-pus.Our work further emphasizes globM-sentence con-nections.
An example that highlights the use of co-occurrence is given on the next page.THE CHAIRMAN AND CHIEF EXECUTIVE OF FRANKL-IN FIRST FEDERAL SAVINGS ~ LOAN ASSOCIAT-ION OF WILKES-BARRE, \[SAID\] FRANKLIN FIRSTFEDERAL'S PLAN OF CONVERSION HAD BEENAPPROVED BY THE FEDERAL HOME LOAN BANKBOARD \[AND THAT\] THE OFFERING OF COMMONSHARES IN FRANKLIN FIRST FINANCIAL CORP.HAD BEEN APPROVED BY THE BANK BOARD AND BYTHE SEC.
(D J, 07-25-88).What  is the attachment of THAT?
THAT couldpotentially attach to almost any preceding word,e.g., FEDERAL THAT, BOARD THAT, CONVERSIONTHAT, SAID THAT, etc.
The affinity of the wordpair SAY THAT (although it does not appear in thissentence as a collocation) supports the appropriateattachment.Furthermore, co-occurrence relations supportthematic-role assignment.
This is important for ourultimate objective of producing more accurate con-ceptual information from news stories \[5\].
The textbelow illustrates one type of problem in role assign-ment:THE LARGEST COMPANY ON THE LIST,WHICH LAST PAID SHAREHOLDERS IN JANUARY,SAID THE 5 PC STOCK DIVIDEND WOULD BEPAYABLE FOLLOWING THE PAYMENT OF THECASH DIVIDEND.
(D J, October 27, 1988)Who paid what to whom and when?
Co-occurrence-based analysis generates lexical relationssuch as subj-verb, verb-obj, and verb-obj2, relationswhich are further mapped into appropriate thematicand semantic roles.
The program thus determinesthat COMPANY is the payer of PAID, SHAREHOLD-ERS the payee, and DIVIDEND the payment.3 Lex ica l  Representat ionAn acquired lexical structure called a Thematic Re-lations (Figure 2) facilitates this analysis.
For a pairof content words, a relation provides (1) a strength ofassociation (or "mutual affinity"), and (2) a structuretype.This table is acquired from corpus by a taggerbased on morphology and local syntax.4 Ext ract ing  Co-occur renceRe la t ions  f rom CorpusThe algorithm operates in three steps: (1) tag thecorpus for morphology and part of speech, (2) col-lect collocations using relative frequency, and (3) usetagging to determine lexical relations within colloca-tions.4.1 Part-of-speech TaggingSince the corpus size is about 10-million words, a full-fledged global sentence parsing is prohibitively ex-pensive, and tagging must be carried out by localistmethods, i.e., by means of morphology and local syn-tactic markers.
There are three degrees of difficultyof cases to be tagged.Morpho logy-based  Tagging: Only a few wordscan be tagged using morphology alone.
WhilePAYMENT and SHAREHOLDERS are unambigu-ously nouns, morphology-based tagging is am-biguous for most words.
For example, PAID andSAID could be either verb or adjective (i.e.
par-ticiple modifier); STOCK and CASH could be ei-ther noun or verb.2 35REEMENT, IT HAS AGREED NOT TOD THAT IT INTENDS TO CONTINUETIONS AND MODIFIYING DIVIDENDA PATTERN FOR THE FUTURE.
ITJUNE 30.
THE COMPANY LASTA 10 PC STOCK DIVIDEND TO BEN INCOME DIVIDEND OF 1C A SHRAUG.
1S.
THE COMPANY LASTUT THE SPECIAL DIVIDEND TO BECT.
21.
THE COMPANY LAST10 PER SHARE SPECIAL DIVIDENDPER SHARE.
THE DIVIDEND ISTED FOR A 5 PC STOCK DIVIDENDERLY DIVIDEND OF 68.75 CENTSTERLY DIVIDEND OF 12 CENTS ISHE SPLIT AND THE DIVIDEND ARE1.5 MILLION.
THE DIVIDEND ISF THE COMPANY ON ANY DIVIDENDN THE UPCOMING FINAL DIVIDENDLDING ONE ADDITIONAL DIVIDENDPAY ANY FUTURE CASH DIVIDENDS, INCLUDING THEPAYING THE DIVIDEND.
-0-; 11 08 AM EDT 07-22-PAYING A STOCK OF 60 CENTS FOR A TOTAL OF $1.PAID A SPECIAL DIVIDEND OF 8C LAST YEAR.
-O-PAID A 7.5C DIVIDEND ON MAY 9.
GROW GROUPPAID AUG. 18.
-0-; 2 09 PM EDT 07-28-88:"?PAID IN FEBRUARY.
-0-; 3 10 PM EDT 07-28-88:PAID A lOC SPECIAL DIVIDEND IN SEPTEMBER 1987PAID FROM PROCEEDS OF THE SALE TO $6 A SHAREPAID A DIVIDEND OF 11 CENTS A SHARE ON J~Y  2PAID TO STOCKHOLDERS ON JAN. 5, 1988.
TOPPPAYABLEPAYABLEPAYABLEPAYABLEPAYABLEPAYABLEPAYMENTPAYMENTPAYMENTTO SHAREHOLDERS OF RECORD JULY 5.AUG.
12 TO HOLDERS OF RECORD JULY 15.OCT.
I WILL BE PAYED IN THE USUAL MANAUG.
29 TO HOLDERS OF RECORD AUG. 12.SEPT.
14 TO HOLDERS OF RECORD AUG. 22AUG.
18 TO HOLDERS OF RECORD AUG. 8.DATE ON OR AFrER AUG. 1, 1990, FOR THOF 10.85 PENCE A SHARE.
HEIGHTENINGOVER A 12-MONTH PERIOD.
DUE THURSDAY.Figure h PAY Sentences in Corpus0 .150 560 730 110 190 220 46predicate:PAYpredicate:PAYpredicate:PAYpredicate:PAYpredicate:PAYpredicate:PAYpredicate:PAYsubject:COMPANYobject:DIVIDENDobject2:SHAREHOLDERobject:MILLIONobject:CASHobject:*number* PCobject:TOP RATESFigure 2: Word Pairs Indicat ing Mutual  Affinity and Themat ic  Roles36 3Syntax-based  Tagging: Local syntactic markershelp to remove most cases of ambiguity.
For ex-ample, was SAID (read: the word SAID precededby was) can be unambiguously tagged a verb;the PAID shareholders, is an adjective; and theSTOCK is definitely a noun.S tat i s t i cs -Based Tagging: Taggers reported by \[4;1\] have capitalized on a large collection of bi-grams plus statistically weighted grammar ules.In this method, statistical properties are ac-quired from a large training corpus which wastagged manually.
Statistical methods haveproved very effective, and attained a high levelof accuracy \[6\].4.2 P rob lemat ic  CasesSome cases prove even more difficult and cannot beresolved by localist methods.
Consider the followingtwo examples.?
"The company preferred stock PAID .
.
. "
.
Inthis clause, PAID, could be either an adjectiveor a verb (see "the horse raced past the barn").Indeed, this clause could probably be determinedby a global parse, however, this would be tooexpensive computationally.?
"CONVINCING MANAGEMENT proved tough"is even harder since it presents a Necker cubesituation (i. e. changing the interpretation ofeither word seems immediately to change the in-terpretation of the pair).
Is it an adjective-nounor is it a verb-noun pair?
In general, the analy-sis of such pairs requires deeper understanding ofword relationships.
Consider another example:LATER IN THE DAY BUYING INTERESTDIMINISHED .
.
.Again, it is difficult to tell whether INTEI~ESTin BUYING diminished or the BUYING of IN-TERESTs diminished.
Thus, local clues do notcontribute towards the proper resolution of suchcc'~3es.The incorrect resolution of such cases, which un-fortunately are pervasive in the corpus, impinges ontwo objectives: performance and learning.In order to perform text analysis, in the first caseone must determine whether management was con-vinced, or the management convinced some secondparty; in the second case, one must determine thesubject of the main verb of the sentence, i.e., whichis the ,subject of DIMINISHED?
Many applicationsrequire an unambiguous result.
Thus a call must bemade one way or another.
Statistical means mightmake that call slightly more judiciuos on the aver-age.However, when tagging is used for learning of the-matic roles, inappropriate r solution of such cases candrastically contaminate the final results by biasing itin a certain direction.
Results are far more accuratewhen ambiguous cases are left out altogether.4.3 Tagging for Learn ingOur tagger is based on a 7,000-root lexicon that facili-tates accurate morphological nalysis, and about I00local-syntax rules.
It produces tagging for about 60%of the content words in the corpus.
Tagged outputfor a sample sentence is given below.THE///DT LARGEST/IARGE/EST/AD CONPANYI//NNoNIIIPP THE///DT LIST///ml *co~ma*///SPWHICH///CC LAST///AD PAID/PAY/ED/?
SHAREHO-LDEmS/SHARZHOLDER/S/NN IN///PP JANUARY///DD*comma*///CC SAID/SAY/ED/??
THE///DT 8//lADPC///NN STOCK///??
DIVIDEND///NN WOULD/WII~//AX BE///AX PAYABLE/PAY/ABLE/AD FOLLOWING/FOLLOW/ING/??
THE///DT PAYMENT/PAY/HENT/NNOF///PP THE///DT CASH///NN DIVIDEND///NN*period*///SPA 4-tuple in the sentence above is aword/root/affix/part-of-speech.
As expected, manycontent words in this sentence cannot be unambigu-ously tagged, and are marked ?, i.e., undetermined.In particular, notice that PAID remains unresolved.Fortunately, most PAY cases in the corpus are sim-pler and are appropriately tagged.OF///PP THE///DT CASH///NN DIVIDEND///NNTHE///DT COMPANY///NN LAST///JJ PAID/PAY/ED/VA A///DT 5///NN DIVIDEND///NN 0N///PP ,,\]'A-NUARYI I IDD .
.
.For purposes of thematic role acquisition the iden-tification of passive and active voice is crucial.
In thesample sentence above, PAID is appropriately taggedas a verb in the active voice (marked as VA).4.4 Col lect ing Col locat ionsBased on the tagging above (the root field), all collo-cations in the corpus are counted, and the followingtable is generated.This table is similar to Smadja's \[7\], and it providesthe position of collocative words relative to PAY, andthe total count within 4 words in either direction.4.5 Determin ing  Lexical  Relat ionsLexical relations are determined using the knownfunctionality of the verb (see \[9\]) and supporting ex-amples.
PAY is marked in the lexicon as a dativeverb.Consider 5 cases containing the pair PAY SHARE-HOLDER, from which the thematic relation is in-duced (VA stands for verb, active voice; VP  for verb,passive voice; AD for adjective).4 37word -4 -3 -2 -1 0 +1 +2 +3 +4 totalPRICE 5 14 438 38 0 17 12 32 12 558COMPANY 47 53 71 26 0 2 6 1 161 367DIVIDEND 37 42 36 121 0 11 1 14 25 287RATE 6 5 16 109 0 14 112 16 3 281MILLION 9 28 12 2 0 4 102 53 53 263STOCK 35 0 134 2 0 7 1 22 2 203MAJOR 0 2 0 6 0 2 0 92 80 182DUE 1 4 35 16 0 4 39 66 7 172INTEREST 1 3 5 74 0 8 14 29 34 168SPECIAL 13 5 5 84 0 3 17 9 24 160CASH 3 11 9 71 0 3 8 23 17 145CENT 19 26 10 11 0 3 33 26 10 138SHARE 9 25 0 29 0 4 7 23 33 130AMOUNT 24 43 15 10 0 3 1 18 16 130PC 12 30 14 23 0 4 2 21 11 117SPLIT 2 10 25 57 0 0 4 0 0 98DATE 29 0 1 3 0 22 29 10 1 95Figure 3: A Distance Matrix between Word Pairs(I) STINGHOUSE SAID IT INTENDS TO PAY/va THE TWO SHAREHOLDERS/nn $2.08 A SHARE PLUS A(2) ONTROL OF THE COMPANY WITHOUT PAYING/va ALL SHAREHOLDERS/rm A FAIR PRICE.
THE(3) THE CASH PORTION OF THE PRICE PAID/??
TO POLYSAR COMMON SHAREHOLDERS/nn WILL, INCR(4) CIPATING SHAREHOLDERS/nn WILL BE PAID/vp $3 A SHARE CASH.
NO BROKERAGE FEES OR T(5) PER SHARE.
THE DIVIDEND IS PAYABLE/ad TO SHAREHOLDERS/nn OF RECORD JULY ~.
(6) ENTS A SHARE FROM 37.5 CENTS, PAYABLE/ad SEPT.
I TO SHAREHOLDERS/nn OF RECORD AUGFigure 4: Word Pairs Tagged as to their Part of Speech38 5Exanlples (1), (4), and (5) support he hypothesisthat StIAREHOLDER is an object2 (the recipient)of PAY.5 Cur rent  S ta tus  and  Conc lus ionsBased on a number of tagged sentences, the systemdetermines that SHAREHOLDERS are recipients ofPAY, while DIVIDENDS axe objects.
This general-ized lexical relation enables the semantic resolutionof more difficult cases uch as DIVIDEND PAYMENTand COMPANY PAID STOCK DIVIDEND.The implemented system using these techniquesincludes several elements: (1) morphology analysis- currently produces accurate results for all the re-quired cases; (2) tagging - produces results for only60% of the required examples; more detailed rulescould improve this figure to about 70%; (3) rule form-ing - currently works only with dative verbs such asPAY and SELL.A number of important pieces of recent researchhave highlighted the power of co-occurrence informa-tion in text.
In the techniques described here, wehave extended this research to use co-occurrence in-formation for discriminating thematic roles.
Thesetechniques combine data acquisition from a taggedcorpus with relation-driven language analysis to de-rive thematic knowledge from the text.Re ferences\[1\] K. Church, W. Gale, P. Hanks, and D. Hin-die.
Parsing, word associations, and predicate-argument relations.
In Proceedings of the In-ternational Workshop on Parsing Technologies,Carnegie Mellon University, 1989.\[2\] K. Church, W. Gale, P. Hanks, and D. Hindle.
Us-ing statistics in lexical analysis.
In U. Zernik, ed-itor, Lezical Acquisition: Exploiting On-Line Re-sources.
Lawrence Erlbanm Associates, Hillsdale,NJ, 1990.\[3\] I. Dagan.
Using collocation in anaphora resolu-tion.
Technical report, Technion, Computer Sci-ence Deptartment, Haifa, Israel, 1989.\[4\] G. Leech R. Garside and G. Sampson.
The Com-putational Analysis of English.
Longman, Lon-don, Britain, 1987.\[5\] Lisa F. Ran, Paul S. Jacobs, and Uri Zernik.Information extraction and text summarizationusing linguistic knowledge acquisition.
Informa-tion Processing and Management, 25(4):419-428,1989.\[6\] B. Santorini.
Annotation manual for the pentreebank project.
Technical report, Universityof Pennsylvania, Computer and Information Sci-ence, Philadelphia, PA, 1990.\[7\] F. Smadja.
Macrocoding the lexicon with co-occurrence knowledge.
In U. Zernik, editor, FirstInternational Le~:ical Acquisition Workshop.
1989.\[8\] Y. Wilks.
A preferential, pattern-matching se-mantics for natural anguage understanding.
Ar-tificial Intelligence, 6, 1975.\[9\] U. Zernik.
Lexical acquisition: Learning from cor-pus by capitalizing on lexieal categories.
In Pro-ceedings of the Eleventh International Joint Con-ference on Artificial Intelligence, Detroit, Michi-gan, 1989.6 39
