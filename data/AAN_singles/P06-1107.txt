Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 849?856,Sydney, July 2006. c?2006 Association for Computational LinguisticsDiscovering asymmetric entailment relations between verbsusing selectional preferencesFabio Massimo ZanzottoDISCoUniversity of Milano-BicoccaVia Bicocca degli Arcimboldi 8, Milano, Italyzanzotto@disco.unimib.itMarco Pennacchiotti, Maria Teresa PazienzaART Group - DISPUniversity of Rome ?Tor Vergata?Viale del Politecnico 1, Roma, Italy{pennacchiotti, pazienza}@info.uniroma2.itAbstractIn this paper we investigate a novelmethod to detect asymmetric entailmentrelations between verbs.
Our starting pointis the idea that some point-wise verb selec-tional preferences carry relevant seman-tic information.
Experiments using Word-Net as a gold standard show promising re-sults.
Where applicable, our method, usedin combination with other approaches, sig-nificantly increases the performance of en-tailment detection.
A combined approachincluding our model improves the AROCof 5% absolute points with respect to stan-dard models.1 IntroductionNatural Language Processing applications oftenneed to rely on large amount of lexical semanticknowledge to achieve good performances.
Asym-metric verb relations are part of it.
Consider forexample the question ?What college did MarcusCamby play for??.
A question answering (QA)system could find the answer in the snippet ?Mar-cus Camby won for Massachusetts?
as the ques-tion verb play is related to the verb win.
The vice-versa is not true.
If the question is ?What collegedid Marcus Camby won for?
?, the snippet ?Mar-cus Camby played for Massachusetts?
cannot beused.
Winnig entails playing but not vice-versa, asthe relation between win and play is asymmetric.Recently, many automatically built verb lexical-semantic resources have been proposed to sup-port lexical inferences, such as (Resnik and Diab,2000; Lin and Pantel, 2001; Glickman and Dagan,2003).
All these resources focus on symmetricsemantic relations, such as verb similarity.
Yet,not enough attention has been paid so far to thestudy of asymmetric verb relations, that are oftenthe only way to produce correct inferences, as theexample above shows.In this paper we propose a novel approach toidentify asymmetric relations between verbs.
Themain idea is that asymmetric entailment relationsbetween verbs can be analysed in the context ofclass-level and word-level selectional preferences(Resnik, 1993).
Selectional preferences indicatean entailment relation between a verb and its ar-guments.
For example, the selectional preference{human} win may be read as a smooth constraint:if x is the subject of win then it is likely that xis a human, i.e.
win(x) ?
human(x).
It fol-lows that selectional preferences like {player} winmay be read as suggesting the entailment relationwin(x) ?
play(x).Selectional preferences have been often used toinfer semantic relations among verbs and to buildsymmetric semantic resources as in (Resnik andDiab, 2000; Lin and Pantel, 2001; Glickman andDagan, 2003).
However, in those cases these areexploited in a different way.
The assumption isthat verbs are semantically related if they sharesimilar selectional preferences.
Then, accordingto the Distributional Hypothesis (Harris, 1964),verbs occurring in similar sentences are likely tobe semantically related.The Distributional Hypothesis suggests ageneric equivalence between words.
Relatedmethods can then only discover symmetric rela-tions.
These methods can incidentally find verbpairs as (win,play) where an asymmetric entail-ment relation holds, but they cannot state the di-rection of entailment (e.g., win?play).As we investigate the idea that a single rel-evant verb selectional preference (as {player}849win) could produce an entailment relation betweenverbs, our starting point can not be the Distribu-tional Hypothesis.
Our assumption is that somepoint-wise assertions carry relevant semantic in-formation (as in (Robison, 1970)).
We do not de-rive a semantic relation between verbs by compar-ing their selectional preferences, but we use point-wise corpus-induced selectional preferences.The rest of the paper is organised as follows.In Sec.
2 we discuss the intuition behind our re-search.
In Sec.
3 we describe different types ofverb entailment.
In Sec.
4 we introduce our modelfor detecting entailment relations among verbs .
InSec.
5 we review related works that are used bothfor comparison and for building combined meth-ods.
Finally, in Sec.
6 we present the results of ourexperiments.2 Selectional Preferences and VerbEntailmentSelectional restrictions are strictly related to en-tailment.
When a verb or a noun expects a modi-fier having a predefined property it means that thetruth value of the related sentences strongly de-pends on the satisfiability of these expectations.For example, ?X is blue?
implies the expectationthat X has a colour.
This expectation may be seenas a sort of entailment between ?being a modi-fier of that verb or noun?
and ?having a property?.If the sentence is ?The number three is blue?,then the sentence is false as the underlying entail-ment blue(x) ?
has colour(x) does not hold (cf.
(Resnik, 1993)).
In particular, this rule applies toverb logical subjects: if a verb v has a selectionalrestriction requiring its logical subjects to satisfy aproperty c, it follows that the implication:v(x) ?
c(x)should be verified for each logical subject x of theverb v. The implication can also be read as: if xhas the property of doing the action v this impliesthat x has the property c. For example, if the verbis to eat, the selectional restrictions of to eat wouldimply that its subjects have the property of beinganimate.Resnik (1993) introduced a smoothed versionof selectional restrictions called selectional pref-erences.
These preferences describe the desiredproperties a modifier should have.
The claim isthat if a selectional preference holds, it is moreprobable that x has the property c given that itmodifies v rather than x has this property in thegeneral case, i.e.
:p(c(x)|v(x)) > p(c(x)) (1)The probabilistic setting of selectional prefer-ences also suggests an entailment: the implica-tion v(x) ?
c(x) holds with a given degree ofcertainty.
This definition is strictly related to theprobabilistic textual entailment setting in (Glick-man et al, 2005).We can use selectional preferences, intendedas probabilistic entailment rules, to induce entail-ment relations among verbs.
In our case, if a verbvt expects that the subject ?has the property of do-ing an action vh?, this may be used to induce thatthe verb vt probably entails the verb vh, i.e.
:vt(x) ?
vh(x) (2)As for class-based selectional preference ac-quisition, corpora can be used to estimatethese particular kinds of preferences.
For ex-ample, the sentence ?John McEnroe won thematch...?
contributes to probability estimation ofthe class-based selectional preference win(x) ?human(x) (since John McEnroe is a human).
Inparticular contexts, it contributes also to the induc-tion of the entailment relation between win andplay, as John McEnroe has the property of play-ing.
However, as the example shows, classes rele-vant for acquiring selectional preferences (such ashuman) are explicit, as they do not depend fromthe context.
On the contrary, properties such as?having the property of doing an action?
are lessexplicit, as they depend more strongly on the con-text of sentences.
Thus, properties useful to deriveentailment relations among verbs are more diffi-cult to find.
For example, it is easier to derive thatJohn McEnroe is a human (as it is a stable prop-erty) than that he has the property of playing.
In-deed, this latter property may be relevant only inthe context of the previous sentence.However, there is a way to overcome this lim-itation: agentive nouns such as runner make ex-plicit this kind of property and often play subjectroles in sentences.
Agentive nouns usually denotethe ?doer?
or ?performer?
of some action.
This isexactly what is needed to make clearer the relevantproperty vh(x) of the noun playing the logical sub-ject role.
The action vh will be the one entailed bythe verb vt heading the sentence.
As an examplein the sentence ?the player wins?, the action play850evocated by the agentive noun player is entailedby win.3 Verb entailment: a classificationThe focus of our study is on verb entailment.
Abrief review of the WordNet (Miller, 1995) verbhierarchy (one of the main existing resources onverb entailment relations) is useful to better ex-plain the problem and to better understand the ap-plicability of our hypothesis.In WordNet, verbs are organized in synonymysets (synsets) and different kinds of seman-tic relations can hold between two verbs (i.e.two synsets): troponymy, causation, backward-presupposition, and temporal inclusion.
All theserelations are intended as specific types of lexicalentailment.
According to the definition in (Miller,1995) lexical entailment holds between two verbsvt and vh when the sentence Someone vt entailsthe sentence Someone vh (e.g.
?Someone wins?entails ?Someone plays?).
Lexical entailment isthen an asymmetric relation.
The four types ofWordNet lexical entailment can be classified look-ing at the temporal relation between the entailingverb vt and the entailed verb vh.Troponymy represents the hyponymy relationbetween verbs.
It stands when vt and vh are tem-porally co-extensive, that is, when the actions de-scribed by vt and vh begin and end at the sametimes (e.g.
limp?walk).
The relation of temporalinclusion captures those entailment pairs in whichthe action of one verb is temporally included in theaction of the other (e.g.
snore?sleep).
Backward-presupposition stands when the entailed verb vhhappens before the entailing verb vt and it is nec-essary for vt. For example, win entails play viabackward-presupposition as it temporally followsand presupposes play.
Finally, in causation theentailing verb vt necessarily causes vh.
In thiscase, the temporal relation is thus inverted withrespect to backward-presupposition, since vt pre-cedes vh.
In causation, vt is always a causativeverb of change, while vh is a resultative stativeverb (e.g.
buy?own, and give?have).As a final note, it is interesting to notice that theSubject-Verb structure of vt is generally preservedin vh for all forms of lexical entailment.
The twoverbs have the same subject.
The only exception iscausation: in this case the subject of the entailedverb vh is usually the object of vt (e.g., X give Y?
Y have).
In most cases the subject of vt carriesout an action that changes the state of the object ofvt, that is then described by vh.The intuition described in Sec.
2 is then applica-ble only for some kinds of verb entailments.
First,the causation relation can not be captured sincethe two verbs should have the same subject (cf.eq.
(2)).
Secondly, troponymy seems to be lessinteresting than the other relations, since our fo-cus is more on a logic type of entailment (i.e., vtand vh express two different actions one depend-ing from the other).
We then focus our study andour experiments on backward-presupposition andtemporal inclusion.
These two relations are orga-nized in WordNet in a single set (called ent) partedfrom troponymy and causation pairs.4 The methodOur method needs two steps.
Firstly (Sec.
4.1),we translate the verb selectional expectationsin specific Subject-Verb lexico-syntactic patternsP(vt, vh).
Secondly (Sec.
4.2), we define a statis-tical measure S(vt, vh) that captures the verb pref-erences.
This measure describes how much the re-lations between target verbs (vt, vh) are stable andcommonly agreed.Our method to detect verb entailment relationsis based on the idea that some point-wise asser-tions carry relevant semantic information.
Thisidea has been firstly used in (Robison, 1970) andit has been explored for extracting semantic re-lations between nouns in (Hearst, 1992), wherelexico-syntactic patterns are induced by corpora.More recently this method has been applied forstructuring terminology in isa hierarchies (Morin,1999) and for learning question-answering pat-terns (Ravichandran and Hovy, 2002).4.1 Nominalized textual entailmentlexico-syntactic patternsThe idea described in Sec.
2 can be applied togenerate Subject-Verb textual entailment lexico-syntactic patterns.
It often happens that verbs canundergo an agentive nominalization, e.g., play vs.player.
The overall procedure to verify if an entail-ment between two verbs (vt, vh) holds in a point-wise assertion is: whenever it is possible to ap-ply the agentive nominalization to the hypothesisvh, scan the corpus to detect those expressions inwhich the agentified hypothesis verb is the subjectof a clause governed by the text verb vt.Given a verb pair (vt, vh) the assertion is for-851Lexico-syntactic patternsnominalizationPnom(vt, vh) = {?agent(vh)|num:sing vt|person:third,t:pres?,?agent(vh)|num:plur vt|person:nothird,t:pres?,?agent(vh)|num:sing vt|t:past?,?agent(vh)|num:plur vt|t:past?
}happens-before(Chklovski and Pantel, 2004)Phb(vt, vh) = {?vh|t:inf and then vt|t:pres?,?vh|t:inf * and then vt|t:pres?,?vh|t:past and then vt|t:pres?,?vh|t:past * and then vt|t:pres?,?vh|t:inf and later vt|t:pres?,?vh|t:past and later vt|t:pres?,?vh|t:inf and subsequently vt|t:pres?,?vh|t:past and subsequently vt|t:pres?,?vh|t:inf and eventually vt|t:pres?,?vh|t:past and eventually vt|t:pres?
}probabilistic entailment(Glickman et al, 2005)Ppe(vt, vh) = {?vh|person:third,t:pres?
?
?vt|person:third,t:pres?,?vh|t:past?
?
?vt|t:past?,?vh|t:pres cont?
?
?vt|t:pres cont?,?vh|person:nothird,t:pres?
?
?vt|person:nothird,t:pres?
}additional setsFagent(v) = {?agent(v)|num:sing?, ?agent(v)|num:plur?
}F(v) = {?v|person:third,t:present?,?v|person:nothird,t:present?, ?v|t:past?
}Fall(v) = {?v|person:third,t:pres?, ?v|t:pres cont,?v|person:nothird,t:present?, ?v|t:past?
}Table 1: Nominalization and related textual entailment lexico-syntactic patternsmalized in a set of textual entailment lexico-syntactic patterns, that we call nominalized pat-terns Pnom(vt, vh).
This set is described in Tab.
1.agent(v) is the noun deriving from the agentifi-cation of the verb v. Elements such as l|f1,...,fNare the tokens generated from lemmas l by ap-plying constraints expressed via the feature-valuepairs f1, ..., fN .
For example, in the case of theverbs play and win, the related set of textual en-tailment expressions derived from the patterns arePnom(win, play) = {?player wins?, ?playerswin?, ?player won?, ?players won?}.
In the ex-periments hereafter described, the required verbalforms have been obtained using the publicly avail-able morphological tools described in (Minnen etal., 2001).
Simple heuristics have been used toproduce the agentive nominalizations of verbs1.Two more sets of expressions, Fagent(v) andF(v) representing the single events in the pair,are needed for the second step (Sec.
4.2).This two additional sets are described inTab.
1.
In the example, the derived expressionsare Fagent(play) = {?player?,?players?}
andF(win) = {?wins?,?won?
}.4.2 Measures to estimate the entailmentstrengthThe above textual entailment patterns define point-wise entailment assertions.
If pattern instances arefound in texts, the related verb-subject pairs sug-gest but not confirm a verb selectional preference.1Agentive nominalization has been obtained adding ?-er?to the verb root taking into account possible special casessuch as verbs ending in ?-y?.
A form is retained as a correctnominalization if it is in WordNet.The related entailment can not be considered com-monly agreed.
For example, the sentence ?Like awriter composes a story, an artist must tell a goodstory through their work.?
suggests that composeentails write.
However, it may happen that thesecorrectly detected entailments are accidental, thatis, the detected relation is only valid for the giventext.
For example, if the text fragment ?The writ-ers take a simple idea and apply it to this task?is taken in isolation, it suggests that take entailswrite, but this could be questionable.In order to get rid of these wrong verb pairs,we perform a statistical analysis of the verb selec-tional preferences over a corpus.
This assessmentwill validate point-wise entailment assertions.Before introducing the statistical entailment in-dicator, we provide some definitions.
Given a cor-pus C containing samples, we will refer to the ab-solute frequency of a textual expression t in thecorpus C with fC(t).
The definition can be easilyextended to a set of expressions T .Given a pair vt and vh we define the fol-lowing entailment strength indicator S(vt, vh).Specifically, the measure Snom(vt, vh) is derivedfrom point-wise mutual information (Church andHanks, 1989):Snom(vt, vh) = logp(vt, vh|nom)p(vt)p(vh|pers)(3)where nom is the event of having a nominalizedtextual entailment pattern and pers is the event ofhaving an agentive nominalization of verbs.
Prob-abilities are estimated using maximum-likelihood:p(vt, vh|nom) ?fC(Pnom(vt, vh))fC(?Pnom(v?t, v?h)),852p(vt) ?
fC(F(vt))/fC(?F(v)), andp(vh|pers) ?
fC(Fagent(vh))/fC(?Fagent(v)).Counts are considered useful when they aregreater or equal to 3.The measure Snom(vt, vh) indicates the relat-edness between two elements composing a pair,in line with (Chklovski and Pantel, 2004; Glick-man et al, 2005) (see Sec.
5).
Moreover, ifSnom(vt, vh) > 0 the verb selectional preferenceproperty described in eq.
(1) is satisfied.5 Related ?non-distributional?
methodsand integrated approachesOur method is a ?non-distributional?
approach fordetecting semantic relations between verbs.
Weare interested in comparing and integrating ourmethod with similar approaches.
We focus on twomethods proposed in (Chklovski and Pantel, 2004)and (Glickman et al, 2005).
We will shortly re-view these approaches in light of what introducedin the previous sections.
We also present a simpleway to combine these different approaches.The lexico-syntactic patterns introduced in(Chklovski and Pantel, 2004) have been devel-oped to detect six kinds of verb relations: similar-ity, strength, antonymy, enablement, and happens-before.
Even if, as discussed in (Chklovski andPantel, 2004), these patterns are not specificallydefined as entailment detectors, they can be use-ful for this purpose.
In particular, some of thesepatterns can be used to investigate the backward-presupposition entailment.
Verb pairs related bybackward-presupposition are not completely tem-porally included one in the other (cf.
Sec.
3):the entailed verb vh precedes the entailing verbvt.
One set of lexical patterns in (Chklovski andPantel, 2004) seems to capture the same idea: thehappens-before (hb) patterns.
These patterns areused to detect not temporally overlapping verbs,whose relation is semantically very similar to en-tailment.
As we will see in the experimental sec-tion (Sec.
6), these patterns show a positive re-lation with the entailment relation.
Tab.
1 re-ports the happens-before lexico-syntactic patterns(Phb) as proposed in (Chklovski and Pantel, 2004).In contrast to what is done in (Chklovski andPantel, 2004) we decided to directly count pat-terns derived from different verbal forms and notto use an estimation factor.
As in our work,also in (Chklovski and Pantel, 2004), a mutual-information-related measure is used as statisticalindicator.
The two methods are then fairly in line.The other approach we experiment is the?quasi-pattern?
used in (Glickman et al, 2005) tocapture lexical entailment between two sentences.The pattern has to be discussed in the more gen-eral setting of the probabilistic entailment betweentexts: the text T and the hypothesis H .
The idea isthat the implication T ?
H holds (with a degreeof truth) if the probability that H holds knowingthat T holds is higher that the probability that Hholds alone, i.e.
:p(H|T ) > p(H) (4)This equation is similar to equation (1) in Sec.
2.In (Glickman et al, 2005), words in H and T aresupposed to be mutually independent.
The previ-ous relation between H and T probabilities thenholds also for word pairs.
A special case can beapplied to verb pairs:p(vh|vt) > p(vh) (5)Equation (5) can be interpreted as the result ofthe following ?quasi-pattern?
: the verbs vh andvt should co-occur in the same document.
It ispossible to formalize this idea in the probabilisticentailment ?quasi-patterns?
reported in Tab.
1 asPpe, where verb form variability is taken into con-sideration.
In (Glickman et al, 2005) point-wisemutual information is also a relevant statistical in-dicator for entailment, as it is strictly related to eq.
(5).For both approaches, the strength indicatorShb(vt, vh) and Spe(vt, vh) are computed as fol-lows:Sy(vt, vh) = logp(vt, vh|y)p(vt)p(vh)(6)where y is hb for the happens-before patterns andpe for the probabilistic entailment patterns.
Prob-abilities are estimated as in the previous section.Considering independent the probability spaceswhere the three patterns lay (i.e., the space ofsubject-verb pairs for nom, the space of coordi-nated sentences for hb, and the space of docu-ments for pe), the combined approaches are ob-tained summing up Snom, Shb, and Spe.
We willthen experiment with these combined approaches:nom+pe, nom+hb, nom+hb+pe, and hb+pe.6 Experimental EvaluationThe aim of the experimental evaluation is to es-tablish if the nominalized pattern is useful to help85300.20.40.60.810 0.2 0.4 0.6 0.8 1Se(t)1?
Sp(t)(a)nomhbpehb + pehb + pe + nom00.20.40.60.810 0.2 0.4 0.6 0.8 1Se(t)1?
Sp(t)(b)hbhb + pehb + pe + nhb + pe + nFigure 1: ROC curves of the different methodsin detecting verb entailment.
We experiment withthe method by itself or in combination with othersets of patterns.
We are then interested only inverb pairs where the nominalized pattern is ap-plicable.
The best pattern or the best combinedmethod should be the one that gives the highestvalues of S to verb pairs in entailment relation,and the lowest value to other pairs.We need a corpus C over which to estimateprobabilities, and two dataset, one of verb entail-ment pairs, the True Set (TS), and another withverbs not in entailment, the Control Set (CS).
Weuse the web as corpus C where to estimate Smiand GoogleTM as a count estimator.
The web hasbeen largely employed as a corpus (e.g., (Turney,2001)).
The findings described in (Keller and La-pata, 2003) suggest that the count estimations weneed in our study over Subject-Verb bigrams arehighly correlated to corpus counts.6.1 Experimental settingsSince we have a predefined (but not exhaustive)set of verb pairs in entailment, i.e.
ent in Word-Net, we cannot replicate a natural distribution ofverb pairs that are or are not in entailment.
Re-call and precision lose sense.
Then, the best wayto compare the patterns is to use the ROC curve(Green and Swets, 1996) mixing sensitivity andspecificity.
ROC analysis provides a natural meansto check and estimate how a statistical measureis able to distinguish positive examples, the TrueSet (TS), and negative examples, the Control Set(CS).
Given a threshold t, Se(t) is the probabilityof a candidate pair (vh, vt) to belong to True Set ifthe test is positive, while Sp(t) is the probabilityof belonging to ControlSet if the test is negative,i.e.
:Se(t) = p((vh, vt) ?
TS|S(vh, vt) > t)Sp(t) = p((vh, vt) ?
CS|S(vh, vt) < t)The ROC curve (Se(t) vs. 1 ?
Sp(t)) natu-rally follows (see Fig.
1).
Better methods willhave ROC curves more similar to the step func-tion f(1 ?
Sp(t)) = 0 when 1 ?
Sp(t) = 0 andf(1?
Sp(t)) = 1 when 0 < 1?
Sp(t) ?
1.The ROC analysis provides another useful eval-uation tool: the AROC, i.e.
the total area underthe ROC curve.
Statistically, AROC representsthe probability that the method in evaluation willrank a chosen positive example higher than a ran-domly chosen negative instance.
AROC is usuallyused to better compare two methods that have sim-ilar ROC curves.
Better methods will have higherAROCs.As True Set (TS) we use the controlled verb en-tailment pairs ent contained in WordNet.
As de-scribed in Sec.
3, the entailment relation is a se-mantic relation defined at the synset level, stand-ing in the verb sub-hierarchy.
That is, each pairof synsets (St, Sh) is an oriented entailment rela-tion between St and Sh.
WordNet contains 409entailed synsets.
These entailment relations areconsequently stated also at the lexical level.
Thepair (St, Sh) naturally implies that vt entails vhfor each possible vt ?
St and vh ?
Sh.
It is pos-sible to derive from the 409 entailment synset atest set of 2,233 verb pairs.
As Control Set weuse two sets: random and ent.
The random set854is randomly generated using verb in ent, takingcare of avoiding to capture pairs in entailment re-lation.
A pair is considered a control pair if it isnot in the True Set (the intersection between theTrue Set and the Control Set is empty).
The ent isthe set of pairs in ent with pairs in the reverse or-der.
These two Control Sets will give two possibleways of evaluating the methods: a general and amore complex task.As a pre-processing step, we have to clean thetwo sets from pairs in which the hypotheses cannot be nominalized, as our pattern Pnom is appli-cable only in these cases.
The pre-processing stepretains 1,323 entailment verb pairs.
For compara-tive purposes the random Control Set is kept withthe same cardinality of the True Set (in all, 1400verb pairs).S is then evaluated for each pattern over theTrue Set and the Control Set, using equation (3)for Pnom, and equation (6) for Ppe and Phb.
Thebest pattern or combined method is the one thatis able to most neatly split entailment pairs fromrandom pairs.
That is, it should in average assignhigher S values to pairs in the True Set.6.2 Results and analysisIn the first experiment we compared the perfor-mances of the methods in dividing the ent test setand the random control set.
The compared meth-ods are: (1) the set of patterns taken alone, i.e.nom, hb, and pe; (2) some combined methods,i.e.
nom + pe, hb + pe, and nom + hb + pe.
Re-sults of this first experiment are reported in Tab.
2and Fig.
1.(a).
As Figure 1.
(a) shows, our nom-inalization pattern Pnom performs better than theothers.
Only Phb seems to outperform nominal-ization in some point of the ROC curve, wherePnom presents a slight concavity, maybe due to aconsistent overlap between positive and negativeexamples at specific values of the S threshold t.In order to understand which of the two patternshas the best discrimination power a comparison ofthe AROC values is needed.
As Table 2 shows,Pnom has the best AROC value (59.94%) indi-cating a more interesting behaviour with respectto Phb and Ppe.
It is respectively 2 and 3 abso-lute percent point higher.
Moreover, the combi-nations nom + hb + pe and nom + pe that in-cludes the Pnom pattern have a very high perfor-mance considering the difficulty of the task, i.e.66% and 64%.
If compared with the combina-AROC best accuracyhb 56.00 57.11pe 57.00 55.75nom 59.94 59.86nom+ pe 64.40 61.33hb+ pe 61.44 58.98hb+ nom+ pe 66.44 63.09hb 61.64 62.73hb+ pe 69.03 64.71hb+ nom+ pe 70.82 66.07Table 2: Performances in the general case: ent vs.randomAROC best accuracyhb 43.82 50.11nom 54.91 54.94hb 56.18 57.16hb+ nom 49.35 51.73hb+ nom 57.67 57.22Table 3: Performances in the complex case: entvs.
enttion hb+pe that excludes the Pnom pattern (61%),the improvement in the AROC is of 5% and 3%.Moreover, the shape of the nom + hb + pe ROCcurve in Fig.
1.
(a) is above all the other in all thepoints.In the second experiment we compared methodsin the more complex task of dividing the ent setfrom the ent set.
In this case methods are askedto determine if win ?
play is a correct entail-ment and play ?
win is not.
Results of these setof experiments is presented in Tab.
3.
The nom-inalized pattern nom preserves its discriminativepower.
Its AROC is over the chance line evenif, as expected, it is worse than the one obtainedin the general case.
Surprisingly, the happens-before (hb) set of patterns seems to be not cor-related the entailment relation.
The temporal re-lation vh-happens-before-vt does not seem to becaptured by those patterns.
But, if this evidence isseen in a positive way, it seems that the patternsare better capturing the entailment when used inthe reversed way (hb).
This is confirmed by itsAROC value.
If we observe for example one ofthe implications in the True Set, reach ?
go whatis happening may become clearer.
Sample sen-tences respectively for the hb case and the hb caseare ?The group therefore elected to go to Tyso andthen reach Anskaven?
and ?striving to reach per-sonal goals and then go beyond them?.
It seemsthat in the second case then assumes an enablingrole more than only a temporal role.
After this sur-855prising result, as we expected, in this experimenteven the combined approach hb + nom behavesbetter than hb + nom and better than hb, respec-tively around 8% and 1.5% absolute points higher(see Tab.
3).The above results imposed the running of a thirdexperiment over the general case.
We need tocompare the entailment indicators derived exploit-ing the new use of hb, i.e.
hb, with respect to themethods used in the first experiment.
Results arereported in Tab.
2 and Fig.
1.(b).
As Fig.
1.
(b)shows, the hb has a very interesting behaviour forsmall values of 1 ?
Sp(t).
In this area it be-haves extremely better than the combined methodnom+hb+pe.
This is an advantage and the com-bined method nom+hb+pe exploit it as both theAROC and the shape of the ROC curve demon-strate.
Again the method nom + hb + pe that in-cludes the Pnom pattern has 1,5% absolute pointswith respect to the combined method hb + pe thatdoes not include this information.7 ConclusionsIn this paper we presented a method to discoverasymmetric entailment relations between verbsand we empirically demonstrated interesting im-provements when used in combination with simi-lar approaches.
The method is promising and thereis still some space for improvements.
As implic-itly experimented in (Chklovski and Pantel, 2004),some beneficial effect can be obtained combiningthese ?non-distributional?
methods with the meth-ods based on the Distributional Hypothesis.ReferencesTimoty Chklovski and Patrick Pantel.
2004.
VerbO-CEAN: Mining the web for fine-grained semanticverb relations.
In Proceedings of the 2004 Con-ference on Empirical Methods in Natural LanguageProcessing, Barcellona, Spain.Kenneth Ward Church and Patrick Hanks.
1989.
Wordassociation norms, mutual information and lexicog-raphy.
In Proceedings of the 27th Annual Meet-ing of the Association for Computational Linguistics(ACL), Vancouver, Canada.Oren Glickman and Ido Dagan.
2003.
Identifying lex-ical paraphrases from a single corpus: A case studyfor verbs.
In Proceedings of the International Con-ference Recent Advances of Natural Language Pro-cessing (RANLP-2003), Borovets, Bulgaria.Oren Glickman, Ido Dagan, and Moshe Koppel.
2005.Web based probabilistic textual entailment.
In Pro-ceedings of the 1st Pascal Challenge Workshop,Southampton, UK.David M. Green and John A. Swets.
1996.
Signal De-tection Theory and Psychophysics.
John Wiley andSons, New York, USA.Zellig Harris.
1964.
Distributional structure.
In Jer-rold J. Katz and Jerry A. Fodor, editors, The Philos-ophy of Linguistics, New York.
Oxford UniversityPress.Marti A. Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceedings ofthe 15th International Conference on ComputationalLinguistics (CoLing-92), Nantes, France.Frank Keller and Mirella Lapata.
2003.
Using the webto obtain frequencies for unseen bigrams.
Computa-tional Linguistics, 29(3), September.Dekan Lin and Patrick Pantel.
2001.
DIRT-discoveryof inference rules from text.
In Proc.
of the ACMConference on Knowledge Discovery and Data Min-ing (KDD-01), San Francisco, CA.George A. Miller.
1995.
WordNet: A lexicaldatabase for English.
Communications of the ACM,38(11):39?41, November.Guido Minnen, John Carroll, and Darren Pearce.
2001.Applied morphological processing of english.
Nat-ural Language Engineering, 7(3):207?223.Emmanuel Morin.
1999.
Extraction de liensse?mantiques entre termes a` partir de corpus detextes techniques.
Ph.D. thesis, Univesite?
de Nantes,Faculte?
des Sciences et de Techniques.Deepak Ravichandran and Eduard Hovy.
2002.
Learn-ing surface text patterns for a question answeringsystem.
In Proceedings of the 40th ACL Meeting,Philadelphia, Pennsilvania.Philip Resnik and Mona Diab.
2000.
Measuring verbsimilarity.
In Twenty Second Annual Meeting of theCognitive Science Society (COGSCI2000), Philadel-phia.Philip Resnik.
1993.
Selection and Information:A Class-Based Approach to Lexical Relationships.Ph.D.
thesis, Department of Computer and Informa-tion Science, University of Pennsylvania.Harold R. Robison.
1970.
Computer-detectable se-mantic structures.
Information Storage and Re-trieval, 6(3):273?288.Peter D. Turney.
2001.
Mining the web for synonyms:Pmi-ir versus lsa on toefl.
In Proc.
of the 12th Eu-ropean Conference on Machine Learning, Freiburg,Germany.856
