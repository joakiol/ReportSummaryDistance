Proceedings of the NAACL HLT Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 22?30,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsIntegrated NLP Evaluation System for Pluggable Evaluation Metricswith Extensive Interoperable ToolkitYoshinobu Kano1   Luke McCrohon1   Sophia Ananiadou2   Jun?ichi Tsujii1,21 Department of Computer Science, University of TokyoHongo 7-3-1, Bunkyo-ku, Tokyo 113-0033 Tokyo2School of Computer Science, University of Manchester and National Centre forText Mining, 131 Princess St, M1 7DN, UK[kano,tsujii]@is.s.u-tokyo.ac.jpluke.mccrohon@gmail.comsophia.ananiadou@manchester.ac.ukAbstractTo understand the key characteristics of NLPtools, evaluation and comparison against dif-ferent tools is important.
And as NLP applica-tions tend to consist of multiple semi-independent sub-components, it is not alwaysenough to just evaluate complete systems, afine grained evaluation of underlying compo-nents is also often worthwhile.
Standardizationof NLP components and resources is not onlysignificant for reusability, but also in that it al-lows the comparison of individual componentsin terms of reliability and robustness in a wid-er range of target domains.
But as many eval-uation metrics exist in even a single domain,any system seeking to aid inter-domain eval-uation needs not just predefined metrics, butmust also support pluggable user-defined me-trics.
Such a system would of course need tobe based on an open standard to allow a largenumber of components to be compared, andwould ideally include visualization of the dif-ferences between components.
We have de-veloped a pluggable evaluation system basedon the UIMA framework, which provides vi-sualization useful in error analysis.
It is a sin-gle integrated system which includes a largeready-to-use, fully interoperable library ofNLP tools.1 IntroductionWhen building NLP applications, the same sub-tasks tend to appear frequently while construct-ing different systems.
Due to this, the reusabilityof tools designed for such subtasks is a commondesign consideration; fine grained interoperabili-ty between sub components, not just betweencomplete systems.In addition to the benefits of reusability, inte-roperability is also important in evaluation ofcomponents.
Evaluations are normally done bycomparing two sets of data, a gold standard dataand test data showing the components perfor-mance.
Naturally this comparison requires thetwo data sets to be in the same data format withthe same semantics.
Comparing of "Apples toApples" provides another reason why standardi-zation of NLP tools is beneficial.
Another advan-tage of standardization is that the number of goldstandard data sets that can be compared against isalso increased, allowing tools to be tested in awider range of domains.The ideal is that all components are standar-dized to conform to an open, widely used intero-perability framework.
One possible such frame-work is UIMA; Unstructured Information Man-agement Architecture (Ferrucci et al, 2004),which is an open project of OASIS and Apache.We have been developing U-Compare (Kano etal., 2009)1, an integrated testing an evaluationplatform based on this framework.1 Features described in this paper are integrated as U-Compare system, publicly available from:http://u-compare.org/22Although U-Compare already provided a widerange of tools and NLP resources, its inbuiltevaluation mechanisms were hard coded into thesystem and were not customizable by end users.Furthermore the evaluation metrics used werebased only on simple strict matchings which se-verely limited its domains of application.
Wehave extended the evaluation mechanism to al-low users to define their own metrics which canbe integrated into the range of existing evalua-tion tools.The U-Compare library of interoperable toolshas also been extended; especially with regard toresources related to biomedical named entity ex-traction.
U-Compare is currently providing theworld largest library of type system compatibleUIMA components.In section 2 of this paper we first look at theunderlying technologies, UIMA andU-Compare.
Then we describe the new plugga-ble evaluation mechanism in section 3 and ourinteroperable toolkit with our type system in sec-tion 4 and 5.2 Background2.1 UIMAUIMA is an open framework specified by OA-SIS2.
Apache UIMA provides a reference im-plementation as an open source project, withboth a pure java API and a C++ development kit .UIMA itself is intended to be purely a frame-work, i.e.
it does not intend to provide specifictools or type system definitions.
Users shoulddevelop such resources themselves.
In the fol-lowing subsections, we briefly describe the basicconcepts of UIMA, and define keywords used toexplain our system in later sections.2.1.1 CAS and Type SystemThe UIMA framework uses the ?stand-off anno-tation?
style (Ferrucci et al, 2006).
The underl-ing raw text of a document is generally kept un-changed during analysis, and the results ofprocessing the text are added as new stand-offannotations with references to their positions inthe raw text.
A Common Analysis Structure(CAS) holds a set of such annotations.
Each ofwhich is of a given type as defined in a specified2 http://www.oasis-open.org/committees/uima/hierarchical type system.
Annotation3 types maydefine features, which are themselves typed.Apache UIMA provides definitions of a range ofbuilt in primitive types, but a more complete typesystem should be specified by developers.
Thetop level Apache UIMA type is referred to asTOP, other primitive types include.
int, String,Annotation and FSArray (an array of any annota-tions).2.1.2 Component and CapabilityUIMA components receive and update CAS oneat a time.
Each UIMA component has a capabili-ty property, which describes what types of anno-tations it takes as input and what types of anno-tations it may produce as output.UIMA components can be deployed either lo-cally, or remotely as SOAP web services.
Re-motely deployed web service components andlocally deployed components can be freely com-bined in UIMA workflows.2.1.3 Aggregate Component and Flow Con-trollerUIMA components can be either primitive oraggregate.
Aggregate components include othercomponents as subcomponents.
Subcomponentsmay themselves be aggregate.
In the case wherean aggregate has multiple subcomponents theseare by default processed in linear order.
This or-dering can be customized by implementing acustom flow controller.2.2 U-CompareU-Compare is a joint project of the University ofTokyo, the Center for Computational Pharma-cology at the University of Colorado School ofMedicine, and the UK National Centre for TextMining.U-Compare provides an integrated platformfor users to construct, edit and compareworkflows compatible with any UIMA compo-nent.
It also provides a large, ready-to-use toolkitof interoperable NLP components for use withany UIMA based system.
This toolkit is currentlythe world largest repository of type system com-patible components.
These all implement the U-Compare type system described in section 3.3  In the UIMA framework, Annotation is a basetype which has begin and end offset values.
In this paperwe call any objects (any subtype of TOP) as annotations.232.2.1 Related WorksThere also exist several other public UIMAcomponent repositories: CMU UIMA componentrepository, BioNLP UIMA repository (Baum-gartner et al, 2008), JCoRe (Hahn et al, 2008),Tsujii Lab Component Repository at the Univer-sity of Tokyo (Kano et al, 2008a), etc.
Eachgroup uses their own type system, and so com-ponents provided by each group are incompatible.Unlike U-Compare these repositories are basical-ly only collections of UIMA components, U-Compare goes further by providing a fully inte-grated set of UIMA tools and utilities.2.2.2 Integrated PlatformU-Compare provides a variety of features as partof an integrated platform.
The system can belaunched with a single click in a web browser; allrequired libraries are downloaded and updatedautomatically in background.The Workflow Manager GUI helps users tocreate workflows in an easy drag-and-drop fa-shion.
Similarly, import/export of workflows,running of workflows and saving results can allbe handled via a graphical interface.U-Compare special parallel aggregate compo-nents allow combinations of specified compo-nents to be automatically combined and com-pared based on their I/O capabilities (Kano et al,2008b).
When workflows are run, U-Compareshows statistics and visualizations of results ap-propriate to the type of workflow.
For examplewhen workflows including parallel aggregatecomponents are run comparison statistics be-tween all possible parallel component combina-tions are given.3 Integrated System for PluggableEvaluation MetricsWhile U-Compare already has a mechanism toautomatically create possible combinations ofcomponents for comparison from a specifiedworkflow, the comparison (evaluation) metricitself was hard coded into the system.
Only com-parison based on simple strict matching waspossible.However, many different evaluation metricsexist, even for the same type of annotations.
Forexample, named entity recognition results areoften evaluated based on several different anno-tation intersection criteria: exact match, left/rightonly match, overlap, etc.
Evaluation metrics fornested components can be even more complex(e.g.
biomedical relations, deep syntactic struc-tures).
Sometimes new metrics are also requiredfor specific tasks.
Thus, a mechanism for plugg-able evaluation metrics in a standardized way isseen as desirable.3.1 Pluggable Evaluation ComponentOur design goal for the evaluation systems is todo as much of the required work as possible andto provide utilities to reduce developer?s labor.We also want our design to be generic and fixwithin existing UIMA standards.The essential process of evaluation can be ge-neralized and decomposed as follows:(a) prepare a pair of annotation sets whichwill be used for comparison,(b) select annotations which should be in-cluded in the final evaluation step,(c) compare selected annotations againsteach other and mark matched pairs.For example, in the case of the Penn Treebankstyle syntactic bracket matching, these steps cor-respond to (a) prepare two sets of constituentsand tokens, (b) select only the constituents (re-moving null elements if required), (c) compareconstituents between the sets and return anymatches.In our new design, step (a) is performed by thesystem, (b) and (c) are performed by an evalua-tion component.
The evaluation component isjust a normal UIMA component, pluggable basedon the UIMA standard.
This component is run ona CAS which was constructed by the system dur-ing step (a).
This CAS includes an instance ofComparisonSet type and its features GoldAnno-tationGroup and TestAnnotationGroup.
Corres-ponding to step (b), based on this input the com-parison component should make a selection ofannotations and store them as FSArray for bothGoldAnnotations and TestAnnotations.
Finallyfor step (c), the component should perform amatching and store the results as MatchedPairinstances in the MatchedAnnotations feature ofthe ComparisonSet.Precision, recall, and F1 scores are calculatedby U-Compare based on the outputted Compari-sonSet.
These calculation can be overridden andcustomized if the developer so desires.Implementation of the compare() method ofthe evaluation component is recommended.
It isused by the system when showing instance basedevaluations of what feature values are used in24matching, which features are matched, and whichare not.3.2 Combinatorial Evaluation and Er-ror AnalysisBy default, evaluation statistics are calculated bysimply counting the numbers of gold, test,matched annotations in the returned Compari-sonSet instance.
Then precision, recall, and F1scores for each CAS and for the complete set ofCASes are calculated.
Users can specify whichevaluation metrics are used for each type of an-notations based on the input specifications theyset for supplied evaluation components.Normally, precision, recall, and F1 scores arethe only evaluation statistics used in the NLPcommunity.
It is often the case in many researchreports that a new tool A performs better thananother tool B, increasing the F1 score by 1%.
Insuch cases it is important to analysis what pro-portion of annotations are shared between A, B,and the gold standard.
Is A a strict 1% increaseover B?
Or does it cover 2% of instances Bdoesn?t but miss a different 1%?
Our systemprovides these statistics as well.Further, our standardized evaluation systemmakes more advanced evaluation available.Since the evaluation metrics themselves are moreor less arbitrary, we should carefully observe theresults of evaluations.
When two or more metricsare available for the same type of annotations,we can compare the results of each to analyzeand validate the individual evaluations.An immediate application of such comparisonwould be in a voting system, which takes theresults of several tools as input and selects com-mon overlapping annotations as output.U-Compare also provides visualizations ofevaluation results allowing instance-based erroranalysis.4 U-Compare Type SystemU-Compare currently provides the world largestset of type system compatible UIMA compo-nents.
We will describe some of these in section5.
In creating compatible components in UIMA akey task is their type system definitions.The U-Compare type system is designed in ahierarchical fashion with distinct types to achievea high level of interoperability.
It is intended tobe a shared type system capable of mappingtypes originally defined as part of independenttype systems (Kano et al, 2008c).
In this sectionwe describe the U-Compare type system in detail.4.1 Basic TypesWhile most of the U-Compare types are inherit-ing a UIMA built-in type, Annotation (Figure 1),there are also types directly extending the TOPtype; let us call these types as metadata types.AnnotationMetadata holds a confidence value,which is common to all of the U-Compare anno-tation types as a feature of BaseAnnotation type.BaseAnnotation extends DiscontinuousAnnota-tion, in which fragmental annotations can bestored as a FSArray of Annotations, if any.ExternalReference is another common meta-data type where namespace and ID are stored,referring to an external ontology entity outsideUIMA/U-Compare.
Because it is not realistic torepresent everything like such a detailed ontolo-gy hierarchy in a UIMA type system, this meta-data is used to recover original information,which are not expressed as UIMA types.
Refe-renceAnnotation is another base annotation type,which holds an instance of this ExternalRefe-rence.UniqueLabel is a special top level type for ex-plicitly defined finite label sets, e.g.
the PennTreebank tagset.
Each label in such a tagset ismapped to a single type where UniqueLabel as itsBaseAnnotation<AnnotationMetadata>SyntacticAnnotationTokenPOSToken<POS>RichToken<String>baseSentence Dependency<DependencyLabel>StanfordDependencyTreeNode<TOP>parent<FSArray>childrenAbstractConstituentNullElement<NullElementLabel><Constituent>Constituent<ConstituentLabel>FunctionTaggedConstituent<FunctionLabel>TemplateMappedConstituent<Constituent>TOPCoordinations<FSArray>Figure 2.
Syntactic Types in U-Compare.25ancestor, putting middle level types if possible(e.g.
Noun type for the Penn Treebank POS tag-set).
These types are omitted in the figure.4.2 Syntactic TypesSyntacticAnnotation is the base type of all syn-tactic types (Figure 2).
POSToken holds a POSlabel, RichToken additionally holds a base form.Dependency is used by dependency parsers,while TreeNode is for syntactic tree nodes.
Con-stituent, NullElement, FunctionTaggedConsti-tiuent, TemplateMappedConstituent are designedto fully represent all of the Penn Treebank styleannotations.
Coordination is a set of references tocoordinating nodes (currently used by the GeniaTreebank).
We are planning on extending the setof syntactic types to cover the outputs of severaldeep parsers.4.3 Semantic TypesSemanticAnnotation is the base type for semanticannotations; it extends ReferenceAnnotation byholding the original reference.SemanticClassAnnotation is a rather complextype designed to be somewhat general.
In manycases, semantic annotations may reference othersemantic annotations, e.g.
references betweenbiological events.
Such references are often la-beled with their roles which we express with theExternalReference type.
Such labeled referencesare expressed by LinkingAnnotationSet.
As a rolemay refer to more than one annotation, Linkin-gAnnotationSet has an FSArray of SemanticAn-notation as a feature.There are several biomedical types included inFigure 3, e.g.
DNA, RNA, Protein, Gene, Cel-lLine, CellType, etc.
It is however difficult todecide which ontological entities should be in-cluded in such a type system.
One reason for thisis that such concepts are not always distinct; dif-ferent ontologies may give overlapping defini-tions of these concepts.
Further, the number ofpossible substance level entities is infinite; caus-ing difficult in their expression as individualtypes.
The current set of biomedical types in theU-Compare type system includes types which arefrequently used for evaluation in the BioNLPresearch.4.4 Document TypesDocumentAnnotation is the base type for docu-ment related annotations (Figure 4).
It extendsDocumentClassAnnotation<FSArray:DocumentAttribute><FSArray:ReferenceAnnotation>DocumentAttribute<ExternalReference>DocumentAnnotationDocumentReferenceAttribute<ReferenceAnnotation>DocumentValueAttribute<String>valueReferenceAnnotation TOPFigure 4.
Document types in the U-Compare type system.SemanticAnnotationReferenceAnnotationSemanticClassAnnotation<FSArray:LinkedAnnotationSet>NamedEntity EventAnnotationCellType CellLine GeneOrGeneProductRNADNAProperNameTitlePlace Protein GenePersonProteinRegionDNARegionLinkingAnnotationSet<ExternalReference><FSArray:SemanticAnnotation>CoreferenceAnnotation DiscourseEntity ExpressionNegationTOPSpeculationFigure 3.
Semantic types in the U-Compare type system.26ReferenceAnnotation to reference the full exter-nal type in the same way as SemanticAnnotation.187The document length in bytes isoutput in the first line (end withnew line),DocumentClassAnnotation together with Do-cumentAttribute are intended to express XMLstyle data.
XML tags may have fields storingtheir values, and/or idref fields refering to othertags.
DocumentValueAttiributerepresents simplevalue field, while DocumentReferenceAttributerepresents idref type fields.
A DocumentClas-sAnnotation corresponds to the tag itself.then the raw text follows as is(attaching a new line in the end),finally annotations follow line byline.0 187 Document id="u1"0 3 POSToken id="u2" pos="DT"....Although these types can represent most doc-ument structures, we still plan to add severalspecific types such as Paragraph, Title, etc.Figure 5.
An example of the U-Compare simple I/Oformat.5 Interoperable Components and Utili-tiesIn this section, we describe our extensive toolkitof interoperable components and the set of utili-ties integrated into the U-Compare system.
All ofthe components in our toolkit are compatiblewith the U-Compare type system described in theprevious section.5.1 Corpus Reader ComponentsIn the UIMA framework, a component whichgenerates CASes is called a Collection Reader.We have developed several collection readerswhich read annotated corpora and generates an-notations using the U-Compare type system.Because our primary target domain was bio-medical field, there are corpus readers for thebiomedical corpora; Aimed corpus (Bunescu etal., 2006) reader and BioNLP ?09 shared taskformat reader generate event annotations likeprotein-protein interaction annotations; Readersfor BIO/IOB format, Bio1 corpus (Tateisi et al,2000), BioCreative (Hirschman et al, 2004) task1a format, BioIE corpus (Bies et al, 2005),NLPBA shared task dataset (Kim et al, 2004),Texas Corpus (Bunescu et al, 2005), YapexCorpus (Kristofer Franzen et al, 2002), generatebiomedical named entities, and Genia Treebankcorpus (Tateisi et al, 2005) reader generatesPenn Treebank (Marcus et al, 1993) style brack-eting and part-of-speech annotations.
Formatreaders require users to prepare annotated data,while others include corpora themselves, auto-matically downloaded as an archive on users?demand.In addition, there is File System CollectionReader from Apache UIMA which reads files asplain text.
We have developed an online interac-tive text reader, named Input Text Reader.5.2 Analysis Engine ComponentsThere are many tools covering from basic syn-tactic annotations to the biomedical annotations.Some of the tools are running as web services,but users can freely mix local services and webservices.For syntactic annotations: sentence detectorsfrom GENIA, LingPipe, NaCTeM, OpenNLPand Apache UIMA; tokenizers from GENIA tag-ger (Tsuruoka et al, 2005), OpenNLP, ApacheUIMA and Penn Bio Tokenizer; POS taggersfrom GENIA tagger, LingPipe, OpenNLP andStepp Tagger; parsers from OpenNLP (CFG),Stanford Parser (dependency) (de Marneffe et al,2006), Enju (HPSG) (Miyao et al, 2008).For semantic annotations: ABNER (Settles,2005) for NLPBA/BioCreative trained models,GENIA Tagger, NeMine, MedT-NER, LingPipeand OpenNLP NER, for named entity recogni-tions.
Akane++ (S?tre et al, 2007) for protein-protein interaction detections.5.3 Components for DevelopersAlthough Apache UIMA provides APIs in bothJava and C++ to help users develop UIMA com-ponents, a level of understanding of the UIMAframework is still required.
Conversion of exist-ing tools to the UIMA framework can also bedifficult, particularly when they are written inother programming languages.We have designed a simple I/O format tomake it easy for developers who just want toprovide a UIMA wrapper for existing tools.Input of this format consists of two parts: rawtext and annotations The first line of the raw textsection is an integer of byte count of the lengthof the text.
The raw text then follows with a new-line character appended at the end.
Annotationsare then included; one annotation per line, some-times referring another annotation by assignedids (Figure 5).
A line consists of begin position,27end position, type name, unique id, and featurevalues if any.
Double newlines indicates an endof a CAS.Output of the component is lines of annota-tions if any created by the component.U-Compare provides a wrapper componentwhich uses this I/O format, communicating withwrapped tools via standard I/O streams.5.4 Type System ConvertersAs U-Compare is a joint project, the U-Comparetoolkit includes UIMA components originallydeveloped using several different type systems.In order to integrate these components into theU-Compare type system, we have developedtype system converter components for each ex-ternal type system.The CCP team at the University of Coloradomade a converter between their CCP type systemand our type system.
We also developed conver-ters for OpenNLP components and Apache UI-MA components.
These converters remove anyoriginal annotations not compatible with the U-Compare type system.
This prevents duplicatedconverters from translating external annotationmultiple times in the same workflow.We are providing such non U-Compare com-ponents by aggregating with type system conver-ters, so users do not need to aware of the typesystem conversions.5.5 Utility ToolsWe have developed and integrated several utilitytools, especially GUI tools for usability and erroranalysis.Figure 6 is showing our workflow managerGUI, which provides functions to create a userworkflow by an easy drag-and-drop way.
Byclicking ?Run Workflow?
button in that managerwindow, statistics will be shown (Figure 8).Figure 6.
A sThere are also a couple of annotation visuali-zation tools.
Figure 7 is showing a viewer fortree structures and HPSG feature structures.
Fig-ure 9 is showing a general annotation viewer,when annotations have complex inter-dependencies.6 Summary and Future DirectionsWe have designed and developed a pluggableevaluation system based on the UIMA frame-work.
This evaluation system is integrated withthe U-Compare combinatorial comparison me-chanism which makes evaluation of many factorsavailable automatically.creenshot of Workflow ManagerGUI and Component Library.Since the system behavior is dependent on thetype system used, we have carefully designed theU-Compare type system to cover a broad rangeof concepts used in NLP applications.
Based di-rectly on this type system, or using type systemconverters, we have developed a large toolkit oftype system compatible interoperable UIMAcomponent.
All of these features are integratedinto U-Compare.Figure 7.
A screenshot of HPSG feature structureviewer, showing a skeleton CFG tree, feature valuesand head/semhead links.28In future we are planning to increase the num-ber of components available, e.g.
more syntacticparsers, corpus readers, and resources for lan-guages other than English.
This will also re-quired enhancements to the existing type systemto support additional components.
Finally wealso hope to add integration with machine learn-ing tools in the near future.Acknowledgmentsonal Centre for Text Mining isFigure 8.
A screenshot of a comparison statistics showing number of instances (gold, test, andmatched), F1, precision, and recall scores of two evaluation metrics on the same data.We wish to thank Dr. Lawrence Hunter?s textmining group at Center for Computational Phar-macology, University of Colorado School ofMedicine, for helping build the type system andfor making their tools available for this research.This work was partially supported by Grant-in-Aid for Specially Promoted Research (MEXT,Japan).
The Natifunded by JISC.W.ning sys-tems.
J Biomed Discov Collab, 3(1), 1.Anie in the Sky, ACL, Ann Arbor,Michigan, USA.Ratificial Intelligence in Medi-cine, 33(2), 139-155.ReferencesA.
Baumgartner, Jr., K. B. Cohen, and L. Hunter.2008.
An open-source framework for large-scale,flexible evaluation of biomedical text min  Bies, Seth Kulick, and Mark Mandel.
2005.
Pa-rallel entity and treebank annotation.
In Proceed-ings of the the Workshop on Frontiers in CorpusAnnotations II: Pzvan  Bunescu, Ruifang Ge, Rohit J. Kate, EdwardM.
Marcotte, Raymond J. Mooney, Arun KumarRamani, et al 2005.
Comparative experiments onlearning information extractors for proteins andtheir interactions.
ArFigure 9.
A screenshot of a visualization of com-plex annotations.29Razvan Bunescu, and Raymond Mooney.
2006.
Sub-sequence Kernels for Relation Extraction.
In Y.Weiss, B. Scholkopf and J. Platt (Eds.
), Advancesin Neural Information Processing Systems 18 (171--178).
Cambridge, MA: MIT Press.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.In Proceedings of the the 5th International Confe-rence on Language Resources and Evaluation(LREC 2006).David Ferrucci, and Adam Lally.
2004.
Building anexample application with the Unstructured Infor-mation Management Architecture.
Ibm SystemsJournal, 43(3), 455-475.David Ferrucci, Adam Lally, Daniel Gruhl, and Ed-ward Epstein.
2006.
Towards an InteroperabilityStandard for Text and Multi-Modal Analytics.U.
Hahn, E. Buyko, R. Landefeld, M. M?hlhausen, M.Poprat, K.  Tomanek, et al 2008, May.
An Over-view of JCoRe, the JULIE Lab UIMA ComponentRepository.
In Proceedings of the LREC'08 Work-shop, Towards Enhanced Interoperability for LargeHLT Systems: UIMA for NLP, Marrakech, Moroc-co.Lynette Hirschman, Alexander Yeh, ChristianBlaschke, and Antonio Valencia.
2004.
Overviewof BioCreAtIvE: critical assessment of informationextraction for biology.
BMC Bionformatics,6(Suppl 1:S1).Yoshinobu Kano, William A Baumgartner, LukeMcCrohon, Sophia Ananiadou, Kevin B Cohen,Lawrence Hunter, et al 2009.
U-Compare: shareand compare text mining tools with UIMA.
Bioin-formatics, accepted.Yoshinobu Kano, Ngan Nguyen, Rune S?tre, Keiichi-ro Fukamachi, Kazuhiro Yoshida, Yusuke Miyao,et al 2008c, January.
Sharable type system designfor tool inter-operability and combinatorial com-parison.
In Proceedings of the the First Internation-al Conference on Global Interoperability for Lan-guage Resources (ICGL), Hong Kong.Yoshinobu Kano, Ngan Nguyen, Rune S?tre, Kazuhi-ro Yoshida, Keiichiro Fukamachi, Yusuke Miyao,et al 2008b, January.
Towards Data And GoalOriented Analysis: Tool Inter-Operability AndCombinatorial Comparison.
In Proceedings of the3rd International Joint Conference on Natural Lan-guage Processing (IJCNLP), Hyderabad, India.Yoshinobu Kano, Ngan Nguyen, Rune S?tre, Kazuhi-ro Yoshida, Yusuke Miyao, Yoshimasa Tsuruoka,et al 2008a, January.
Filling the gaps betweentools and users: a tool comparator, using protein-protein interaction as an example.
In Proceedingsof the Pacific Symposium on Biocomputing (PSB),Hawaii, USA.Jin-Dong Kim, Tomoko Ohta, Yoshimasa Tsuruoka,Yuka Tateisi, and Nigel Collier.
2004.
Introductionto the Bio-Entity Recognition Task at JNLPBA.
InProceedings of the International Workshop on Nat-ural Language Processing in Biomedicine and itsApplications (JNLPBA-04), Geneva, Switzerland.Kristofer Franzen, Gunnar Eriksson, Fredrik Olsson,Lars Asker, Per Liden, and Joakim Coster.
2002.Protein names and how to find them.
InternationalJournal of Medical Informatics, 67(1-3), 49-61.Mitchell P. Marcus, Mary Ann Marcinkiewicz, andBeatrice Santorini.
1993.
Building a large anno-tated corpus of English: the penn treebank.
Com-putational Linguistics, 19(2), 313-330.Yusuke Miyao, and Jun'ichi Tsujii.
2008.
FeatureForest Models for Probabilistic HPSG Parsing.Computational Linguistics, 34(1), 35-80.Rune S?tre, Kazuhiro Yoshida, Akane Yakushiji,Yusuke Miyao, Yuichiro Matsubayashi, and To-moko Ohta.
2007, April.
AKANE System: Protein-Protein Interaction Pairs in BioCreAtIvE2 Chal-lenge, PPI-IPS subtask.
In Proceedings of theSecond BioCreative Challenge Evaluation Work-shop.Burr Settles.
2005.
ABNER: an open source tool forautomatically tagging genes, proteins and otherentity names in text.
Bioinformatics, 21(14), 3191-3192.Yuka Tateisi, Tomoko Ohta, Nigel Collier, ChikashiNobata, and Jun'ichi Tsujii.
2000, August.
Buildingan Annotated Corpus from Biology Research Pa-pers.
In Proceedings of the COLING 2000 Work-shop on Semantic Annotation and Intelligent Con-tent, Luxembourg.Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, andJun'ichi Tsujii.
2005, October.
Syntax Annotationfor the GENIA Corpus.
In Proceedings of the theSecond International Joint Conference on NaturalLanguage Processing (IJCNLP '05), Companionvolume, Jeju Island, Korea.Yoshimasa Tsuruoka, Yuka Tateishi, Jin Dong Kim,Tomoko Ohta, J. McNaught, Sophia Ananiadou, etal.
2005.
Developing a robust part-of-speech tag-ger for biomedical text.
In Advances in Informatics,Proceedings (Vol.
3746, 382-392).
Berlin: Sprin-ger-Verlag Berlin.30
