Message Unders tand ing  Conference  - 6:A Br ie f  H is toryRalph GrishmanDept.
of Computer ScienceNew York University715 Broadway, 7th FloorNew York, NY 10003, USAgrishman@c s. nyu.
eduAbstractWe have recently completed the sixthin a series of "Message UnderstandingConferences" which are designed to pro-mote and evaluate research in informa-tion extraction.
MUC-6 introduced sev-eral innovations over prior MUCs, mostnotably in the range of different asks forwhich evaluations were conducted.
Wedescribe some of the motivations for thenew format and briefly discuss some ofthe results of the evaluations.1 The MUC EvaluationsWe have just completed the sixth in a series ofMessage Understanding Conferences, which havebeen organized by NRAD, the RDT&E division ofthe Naval Command, Control and Ocean Surveil-lance Center (formerly NOSC, the Naval OceanSystems Center) with the support of DARPA,the Defense Advanced Research Projects Agency.This paper looks briefly at the history of theseConferences and then examines the considerationswhich led to the structure of MUC-6}The Message Understanding Conferences wereinitiated by NOSC to assess and to foster researchon the automated analysis of military messagescontaining textual information.
Although called"conferences", the distinguishing characteristic ofthe MUCs are not the conferences themselves,but the evaluations to which participants mustsubmit in order to be permitted to attend theconference.
For each MUC, participating roupshave been given sample messages and instructionson the type of information to be extracted, andhave developed a system to process uch messages.Then, shortly before the conference, participantsare given a set of test messages to be run throughtheir system (without making any changes to thesystem); the output of each participant's system1The full proceedings of the conference are to bedistributed by Morgan Kaufmann Publishers, San Ma-teo, California; earlier MUC proeeedings~ for MUC-3,4, and 5, are also available from Morgan Kaufmann.Beth SundheimNaval Command, Control andOcean Surveillance CenterResearch, Development, Test andEvaluation Division (NRaD)Code 4420853140 Gatchell RoadSan Diego, CMifornia 92152-7420sundhe im@poj  ke .
nosc .
mi lis then evaluated against a manually-prepared an-swer key.The MUCs are remarkable in part because ofthe degree to which these evaluations have defineda prograin of research and development.
DARPAhas a number of information science and technol-ogy programs which are driven in large part, byregular evaluations.
The MUCs are notable, how-ever, in that they in large part have shaped theresearch program in information extraction andbrought it to its current state}2 Early HistoryMUC-1 (1987) was basically exploratory; eachgroup designed its own format for recording theinformation in the document, and there was noformal evaluation.
By MUC-2 (1989), the taskhad crystalized as one of template filling.
One re-ceives a description of a class of events to be iden-tiffed in the text; for each of these events one mustfill a template with information about the event.The template has slots for information about theevent, such as the type of event, the agent, thetime and place, the effect, etc.
For MUC-2, thetemplate had 10 slots.
Both MUC-1 and MUC-2 involved sanitized forms of military messagesabout naval sightings and engagements.The second MUC also worked out the details ofthe primary evaluation measures, recall and pre-cision.
To present it in simplest terms, supposethe answer key has Nke~ filled slots; and that asystem fills Neor,.~t slots correctly and Nin~or,,~tincorrectly (with some other slots possibly left un-filled).
ThenNcorrect recall -Nkey2There were, however, a number of individual re-scm'eh efforts in information extraction underway be-\[bre the first MUC, including the work on informationformatting of medieM narrative by Sager at New YorkUniversity; the formatting of naval equipment failurereports by Marsh at the Naval Research Laboratory;and the DBG work by Logieon for RADC.466Nco,,;,.ectprec is ion  =Ncorrect + NincorrectFor MUC-3 (1991), tile task shifted to reportsof terrorist events ill Central and South Amer-ica, as reported in articles provided by the For-eign Broadcast Information Service, and the tem-plate becmne somewhat more complex (18 slots).This same task was used for MUC-4 (1992), with afurther small increase in template complexity (24slots).MUC-5 (1993), which was conducted as part ofthe Tipster program, a represented a substantialfllrther jump in task complexity.
Two tasks wereinvolved, international joint ventures and elec-tronic circuit fabrication, in two hmgnages, En-glish and Japanese.
The joint venture task re-quired 11 templates with a total of 47 slots forthe output double tile number of slots definedfor MUC-4  and the task documentation wasover 40 pages long.One innovation of MUC-5 was the use of anested template structure.
In earlier MUCs, eachevent had been represented as a single temi)late?
in effect, a single record in a data l)ase, with alarge nuinber of attributes.
This format provedawkward when an event had several participmlts(e.g., several victims of a terrorist attack) and onewanted to record a set of facts about each partic-ipant.
This sort of information (:ould be ranchmore easily recorded in the hierarchical structureintroduced for MUC-5, in which there was a singletemplate for an event, which pointed to a list oftemI(lates, one for each particii)mlt in tile event;.
43 MUC-6 :  initial goals1)ARI)A convened a meeting of Tipster partici-pants and government representatives in Decca>bet' 1993 to define goals and tasks tot MUC-6)Among the goals which were identified were?
demonstrating taskqndependent componenttechnologies of information extraction whichwould be immediately useflfl?
encouraging work to make information ex-tractioil systems in<)re portable?
encouraging work on "deeper understanding"aTipster is a U.S. Govermnent program of researchand development in the areas of inibrmation retrievaland information extraction.4In fact the MUC-5 structure wa~s much (nor(; com-plex, because there were separate temt)lates for prod-ucts, time, activities of organizations, etc.
'~The representatives of the resear(:h communitywere Jim Cowie, lS(.alph Grishman (commit;tee chair),Jerry Hobbs, Paul Jacobs, Lea Schubert, Carl Weir,and Ralph Weischedel.
The government people at-tending wcre George Doddington, Donna Harman,Boyan Onyshkevych, John Prangc, Bill Schultheis,and Beth Sundheim.Each of these can been seen in part as a reactionto the trends in the prior MUCs.
The MUC-5tasks, in particular, had been quite complex anda great effort had been invested by the governmentin preparing the training and test data and by theparticipants in adapting their systems for thesetasks.
Most participants worked on the tasks for6 months; a few (the Tipster contractors) hadbeen at work on the tasks tbr consi(lerably longer.While the performance of solne systems was quiteimpressive (the best got 57% recall, 64% precisionoverall, with 73% recall and 74% t)recision on the4 "(:or(;" template types), tile question naturallyarose as to whether there were many apl)lieationstbr which art investment of one or several develop-ers over half->year (or more) could be justified.Furthermore, while so much effort had been ex-pended, a large portion was specific to tire partic-ular tasks.
It wasn't clear whether much progresswas being made on the underlying technologieswhich would be needed for hetter understanding.To address these goals, the meeting formulatedan ambitious menu of tasks for MUC-6, with theidea that individual participants could choose asubset of these tasks.
We consider the three goalsin the three sections below, and describe the taskswhich were developed to address each goal.4 Short-term subtasksThe first goal was to identit~y, from the compo-nent technologies being developed for informationextraction, flmctions which would be of 1)racticaluse, would be largely domain indet)endent, andcouhl in the near term be performed automaticallywith high ac('uracy.
To meet this goal the con>mittce developed the "named entity" task, whicht(asically involves identifying the names of all thepeople, organizations, and geographic locations ina text.The final task specification, which also involvedtime, currency, and percentage xpressions, usedSGML markup to identify the names in a text.Figure 1 shows a sample sentence with named en-tity annotations.
The tag ENAMEX ("entity nameexpression") is used for both people and organiza-tion names; the tag NUNEX ( "numer ic  expression")is used for currency and I)ercentages.5 PortabilityThe second goal was 1;o focus on portability inthe inibrmation extraction task the ability torapidly retarget a system to extract; informationabout a different class of events.
The comnfit-tee felt that it was important o demonstrate thatuseful extraction systems eouht be created in afew weeks.
To meet this goal, we decided thatthe infbrmation extraction task for MUC-6 wouhlhave to involve a relatively simple template, morelike MUC-2 than MUC-5; this was duhbed "mini-467Mr.
<ENAMEX TYPE="PERSON">Dooner</ENAMEX> met with <ENAMEX:TYPE="PERSON">MartinPuris</ENAMEX>, president and chief executive officer of <ENAMEXTYPE="ORGANIZATION">Ammirati & Puris</ENAMEX>, about <ENAMEXTYPE="ORGANIZATION">McCann</ENAMEX>~s acquiring the agency with billings of <NUMEXTYPE="MONEY">$400 million</NUMEX>, but nothing has materialized.Figure 1: Sample named entit;y annotation.MUC".
In keeping with |;he hierarchical tem-plate structure introduced in MUC-5, it was envi-sioned |;hat the inini-MUC would have an event-level template pointing to templates representing|;he partieitmnts in the event (people, orgmfiza-tions, products, e.tc.
), me(liated perhaps by a "re-lational" level template.To further increase portability, a proposal wasmade to standardize the lowest-level tenlplates(for peoph',, orgaIfizations, etc.
), since these basic(:lasses are involved in a wide variety of actions.
Inthis way, MUC participants could develop code forthese low-level telnplates once, and then use themwith many different types of events.
These low-level t;emptates were named "telnplate lements".As the specification finally deveh)ped, tit(; rein-plate element for orgalfizations had six slots, forthe inaximal organization alne, any aliases, thetype, a descriptive noun phrase, the locale (inostspecific location), and country.
Slots are tilh,donly if inforlnation is explicitly given in the text(or, ill the ease of the country, can be inDrredDoln an explicit locale).
The textWe are striving to have a strong re-newed creative partnership with Coca-Cola," Mr. Dooner says.
However, o(ldsof that hapt;ening are slim since wordfrom Coke headquarters in Atlanta isthat...wouht yiehl an organization telnplate elenmntwith live of these six slots filled:<0RGANIZATION-9402240133-5> :=ORG NAME: "Coca-Cola"ORG ALIAS: "Coke"ORG TYPE: COMPANYORG_LOCALE: Atlanta CITYORG COUNTRY: United States(the first line identities this as organization tenl-plate 5 from article 9402240\]33).Ever on the lookout for additional ewfluationmeasm'es, the committee decide, d to nlake the cre-ation of telnI)late eh,ments tbr all the people andorganizations in a text a separate MUC task.
lakethe named entil;y task, this was also seen as apotential demonstration of the ability of systelns1;o pertbrm a useflfl, relatively dolnain indepen-dent task with near-term extraction te(:hnoh)gy(although it was recognized as being more dilli-cult than named entity, since it required merginginformation from several places in the text).
Theold-style MUC information extraction task, basedon a description of a particular (:lass of events(a "scenario") was called the "scenario template"task.
A sample scenario template is shown in theappendix.6 Measures  o f  deep  unders tand ingAnother concern which was noted about theMUCs is that tile systenls we.re tending to-wards relatively shallow understanding techlfiques(based IIrimarily on local pa.ttern inatching), andthat not enough work was being done to buildup the mechanisms needed for deeper understand-ing.
Therefore, tile committee, with strong en-couragement front I)AII.PA, included three MUCtasks which were intended to measure, aspex:ts ofthe internal processing of an inforlnation extra(:-lion or hmguage understanding systenL Thesethree tasks, which were collectively called Se-mEwfl ("Senmntic Ewfluation") were:?
Core ference:  the systent would have tomark coreferential noun t)hrases (the initialSlmCification envisioned marking set-subsel;and part-whole relations, ill addition to iden-tity relations)?
Word  sense d i sambiguat ion :  for eachope.n (:lass word (noun, verb, a, djective, ad-verb) in the text, the systein would have todetermine its sense using the Wordlmt clas-s|Ileal|on (its "synset", in Wordnet termii~ofogy)?
Pred icate -argument  s t ruc ture :  the sys-tem wouhl have to create a tree interrelatingthe constituellts of the sentence, using sonmset of gralnma.tical flnmtional relationsThe committee recognized that, in seh;eting snehinternal measures, it, was inaking sortie presumI)tion regarding the structures and decisions whichan analyzer should make in understanding a doc-llmellt.
Not everyone would share these pre, sump-lions, lint participants in the next MU(J wouldbe free 1;o enter the infornlation extraction evalu-ation and skip some or all of these internal ewdua-Lions.
Language understanding technology mightdevelop in ways very diIii?rent from those imaginedby the committee, and these internal evaluationsmight turn ollt t() t)e irrelevant distractions.
How-ever, froln the current perslmctive of tnost of theeolnmittec, @ese seenmd fairly \])asic aspects ofunde, rstanding, and so an experinmnt in evahlat-ing them (and encouraging improvem(mt in them)4:68would I)e worl;hwhil(~.7 Preparat ion  processRound 1: Reso lu t ion  o f  SemEva lThe  committee,  had l)ropos(;(t a ve.ry anl l ) i t iousI ) rogrmn of cvahu~l;ions.
Wc now had to r(xhlce.these I)roi)osals to (let;ailed spe.cifi(:ations.
The.first step was t;o (lo some ma,mlal te.xl; anuol:a.--l ion for the fore ~,asks named em;ity mM theSelnt,;val t r iad  whi(:h were quit(: (tifii!r(!nt fromwhat  had be(m l;rie(l before, lh'M!
sp(~(:ifi(:ationswere prepared  for ca(:h task,  and in the sl)ring of\] 994 a grou I) of vohmt(~ers (most;ly vel;(n:ans ()f ear-.l ier MU(Js) annol:~mxl a shorl: newst)~p(w m'tM(',using ('.ach set of specif i(:ations.Prot) lems arose with ea.
(:h of t;he SemEva l  tasks.
* For  corefcren('e., ther(', were prob lems i(hull;i\[y-ing i)art-whoh~ and sei;-sul)s(?
rela.tions, mMd is t ingu ish ing  the, two; a decis ion wa.s lm;ermade to l imit  ourselv(;s I;() i(lenLi(;y rela.I;ions.?
bbr sens(' I:~gging, l;h(; ~l.llllOl;tl, ,()l'S forum that,in some cases Wordn(,t  made very \[ine dis-1;incl;ions a,nd thai; mak ing  l;hese (list, inct i (mscons is tent ly  ill l ;agging was very ditticulI;.e For  p red icate -argumeal t  sl;ru(;l;llr(',, pracl; ical lyevery new CoIIS\[;Ill(;l; 1)(;y()lI(l s imple clausesand noun l)hrases r;tise(l new issues which hadI;o t)e toilet:l ively r(:solve(l.Beyon(l  th(;se in(l ividuM t)rolflenls, il; was fell:l;hal; l;he menu was s imply  (;oo anfl)il, ious, mM l;hal;w('.
would do t)('.l:t('x by (:on(:entrat, ing on out; (',le-menl: of the Sem(;v;fl l,riad for MUC-6;  at  a. me('.l;-ing hehl in .hllm 1994, a decis ion was mad(; togo with coref('xea,(:('..
In i/arl;, this r(~tl(w.l;est a feel-ing that  the t)rol)lems wi@ Lh(', (:()refl',ren(:(~ Sl)(X>ili(:a.I;ion w('.re l:he mosl; mn(mable l:o solul i (m, lilt,also re.fle(:i;ed a.
(:onvicl;ion I;hal; (:or(ff('r(m(:(~ idea>t:i l ication had 1)een, &nd would re, main,  cr i t ical1;o success ill inforina.t;iou cxl;r~mi;ion, au(1 st) itwgts \[IIlpor\[;~l,ll\[; 1;o (?llC()llrtl,~(~ a, dvtl~ltc(;s in  (:or(',\[ km(;nc(;, tin contrasl;,  mosl; (;xt, rat:l;ion sysl;emsdid nol; buil(t fltll t)redi(:ate-atrgument sl;ru(:l;ures,and word-sense ( l ismnbigual; ion p layed a relal;iv('lystnal l  role ill exl;ra(:l;ion (par t i cu lar ly  since (;xl;l';t(>l;ion sysl;ems o l )erated in a nar row domain) .
'Phe (:or('~h'a'(;n(:('~ task,  like.
the nam(xl  entil;yl;ask, was a.nnotal;ed us ing SGMI ,  n()tal;i()tl.
AC{\]REF tag has mt ID ai;l;ri|)ul;(' whi(:h i(lenl;ifies l;hetagged noult 1)hrase or l)ron(mn, ll; tn;ty also ha.vca.n at,l;ril)ut;(' of the \[orm REF--n, which indi(:al,esthai; this lf ln'ase is (:or(,fe, r(mtiM with I;he 1)hrascwit;h I1) n. Figure, 2 shows an (;x(:('rt)I; fl'om ;mm'tMe,  ann(/l;al;c(t \[or (;orefereal(;e. (;6 'The TYPE mM M\]~N ;tl;l;I'il)uLes which appear in l, he;tctmd annot;al;ion have been omitted here fin the s~tkeof readM)ilil;y.Round 2: annotat ionThe next st;(; 1) was the IWel)axal;hm of a substa.nt;ia.1Lra.illing corpllS for LII(~ l;wo novel t, asks which re-nmined (nmued Clll;il;y &lid COI'(~,f(~,FO,1IC(Q. SRA Co ll)orat:ion k indly  prov ided  tools which a ided in t;hea nnol;at ion process.
Aga in  a sl;alwa.rt grtml) of vt)l-uui;e(w a.nn()i;alx)rs was assenfl) led; 7 each was 1)to -vide(l with 25 m't;i(:lcs f rom 1;h('.
Wal l  St reet  .\]our-na.l.
There.
was SOlUe over lap b(!Lween t;hc arLi(:lesassigned,  s() t, haL we could IIIO&Slll'(!
~;}1( ~.cons is tencyof a.mloi;m;ion /w.|:weeu silx~s.
Th is  amloi ,at ion w~s(lone.
in I.he winter  o\[ 1994-95.A major  role o\[ the.
mmol;aLion l)ro(:e.ss was Loi( lemify and res()lv(~ l)r(fl)h!ms wil;h l;he task Sl)(X>ifi(:a.tions.
For na.nied cnl;iifies, this was rel~tl;ivelyst, rtdght, forwar(\[.
For COI'(~\[(~I'(;I/(',(;, it proved r(',-markat) ly  (lifli(:ult to f()rmutat;e guitl(,l ines whichwere reasonal) ly  comI/lel;(~ a, nd <:onsist, ent.. sRomM 3: d ry  rml()nee the t;ask sl)e(:ifica.l;ions eemed r(~asonablystM)l(b N lbd)  ()rg;ufiz(~(l a "(lry run" a full-s(:al(~r(~hearsal for MUC-6 ,  I)ul; wi th all result:s r('4)ori;eda.nouymously.
The dry  run Ix)ok t)l;u:e in Apr i l1995, wil;h a s(:enario iuvolving labor  union (:()n.l,ra,c.t; n(~gotia.l:i(ms. ()f  0m sil;es whi(:h we.re in-volved in t;he annot;at ion l/r()(:('~s,q, t;en 1)arl:i(:ipatx~(lin lhe dry  run.
Resul ts  of t;h(~ dry  run were r(>l)()rWxl n.I, l;he Tit)sl:er I)hase II 12--mout;h me(Mugin May 1995.8 The fo rmal  eva luat ionThe MUC6 formal  ewflu;tt ion was /mhl in,~{(q)l:emt)ex 1995.
The s(:(;nario (l(~finil;ion w;L,q dis-t, ribuIxxt at, t;he t)egimling ()\[' S(q)tember I l;he testdata  was disiaibut, cd four we('.ks late.r, wi th result;s due by (,he end ()\[' th(; w('.ek.
The ,qcena.rioinvolv(M (;h;l,II~O,S ill COI'|)OF;I,I;(~ (LK(~CIII;iv(; II\],%II;/,~C-m('.n(; p('a,~onn(~l.
The.
(;valua.1;i(m reel; mmly  ()I 1;t1('.f~oals which had /)(~en set, 1)y th('~ iniLial p lann ing(:onfer(mt:e. in l)e(:emlmr ()f 1993.There  were (;va\]u;Lti(ms for \[our t, asks: 1HIIII(RIentit;y, (:orel'('.re.n(:e, 1;eml)lat(, c, lt!inenI;, }l, l l(t s(;c--nmio  I;e, mt~lm;(u Ttmre w('r(; 16 t)m'ti(;ipmfl;s; 11.51)arti(:it)al;e(l in the nmne(l  ent, it, y task,  7 in (',oref-(~l'O, ll(~(~,, \] 1 ill t(',ml)lat;(; elemenl;, an(l 9 in s(:enari()l,(;mi)lal;(,,.Name( l  en i ; i ty  was inl;(mdcd to b(; a siml)h~task  on whi(:h syst, ems coul(t ( lernoustrat, e a highlevel of 1)(!rforumn(:e ... high enough for imme(l i -m;e use.
Our  su(:(;(;ss iu I;his t, ask (~x(:(;(~(le(l our>l'he annol;;)A;ion groups were from BBN, Brall(t(fisUniv., t~he Univ.
of Durham, Lo(:kheed-Marl;in, NewMexico Sl;ai;e Univ., N lbd) ,  New York Univ., PRC,l;he, Univ.
of l)(mnsylwmia, SAIC (San /)iego), SRA,SR\[, the Univ.
of Shefliehl, SouLhe, rn Metlmdisl; Univ.,mr(1 Ultisys.SAs exl)e, rienced (:Oml)ut~tional linguists, we 1)rol)-ably should ha,re kuown 1)el;l;(',r l;han to l;hink this wa.san easy t~ask.469Maybe <COREF ID="136" REF="I34">he</CSREF>'II even leave something from <COREFID="138" REF="I39"><COREF ID="137" REF="I36">his</COREF> office</COREF> for <CSREFID="I40" REF="91">Mr.
Dooner</COREF>.
Perhaps <COREF ID="144">a framed page fromthe New York Times, dated Dec. 8, 1987, showing a year-end chart of the stock marketcrash earlier that year</COREF>.
<COREF ID="I41" REF="I37">Mr.
James</COREF> says<COREF ID="142" REF="I41">he</COREF> framed <COREF ID="143" REF="I44"STATUS="OPT">it</COREF> and kept <COREF ID="145" REF="I44">it</COREF> by <COREFID="146" REF="I42">his</COREF> desk as a "personal reminder.
It can all be gone likethat .
"Figure 2: Sample coreference annotation.expectations.
The majority of sites had recalland precision over 90%; the highest-scoring sys-tem had a recall of 96% and a precision of 97%.Although one must keep in mind the somewhatlimited range of texts in the test set (all are fromthe Wall Street Journal, in particular), the re-sults are excellent.
A couple of these systems havebeen commercialized, and several are being incor-porated into government text-processing systems.Given this level of performance, there is probablylittle point in repeating this task with the sameground rules in a future MUC (although theremight be interest in processing monoease text andin performing comparable tasks oil a more variedcorpus and for languages other than English).The template  e lement  task, while superfi-cially similar to named entities - ~ it is also basedon identifying people and organizations ~ is sig-nificantly more difficult.
One has to identify de-scriptions of entities ("a distributor of kumquats")as well as names.
If an entity is mentioned sev-eral times, possibly using descriptions or differ-ent forms of a name, these need to be identifiedtogether; there should be only one template ele-ment for each entity in an article.
Consequently,the scores were appreciably lower, ranging acrossmost systems from 65 to 75% in recall, and from75% to 85% in precision.
The top-scoring sys-tem had 75% recall, 86% precision.
Systems didparticularly poorly in identifying descriptions; thehighest-scoring system had 38% recall and 51%precision for descriptions.There seemed general agreement that havingprepared code for template elements in advancedid make it easier to port a system to a new see-nario in a few weeks.
This factor, and the roomthat exists for improvement in performance, sug-gest that including this task in a future MUC maybe worthwhile.The goal for scenar io  templates  mini-MUC - -  was to demonstrate that effective infor-mation extraction systems could be created in afew weeks.
This too was successful.
Although it isdifficult to meaningfully compare results on differ-ent scenarios, the scores obtained by most systemsafter a few weeks (40% to 50% recall, 60% to 70%precision) were comparable to the best scores ob-tained in prior MUCs.
The highest performanceoverall was 47% recall and 70% precision.One can observe an increasing convergence ofmethods tbr information extraction.
Most ofthe systems participating in MUC-6 employed acascade of finite-state pattern recognizers, withthe earlier pattern sets recognizing entities, andthe later sets recognizing scenario-specific pat-terns.
This convergence may be one reason fortile bunching of scores for this task -- most sys-tems fell in a rather narrow range in both recalland precision.The results of this MUC provide valuable pos-itive testimony on behalf of information extra(>tion, but further improvement in both portabilityand performance is needed tbr many applications.With respect o port~bility, custoiners would liketo have systems which can be ported in a t'ewhours, or at most a few days, by someone withless expertise than a system developer.
How thismight be tested in the context of a MUC is not en-tirely clear.
For one thing, most sites spent severaldays just studying the scenario description andannotated corpus, in order to understand tile sce-nario definition, before coding began.
Perhaps amicro-MUC 9 with an even simpler template struc-ture, is needed to push the limits of port, ability.Getting systems which can be custonfized by oth-ers is also a tall order, given the complexity andvariety of knowledge sources needed for a typicalMUC information extraction task.With respect to performance, tile bunching ofscores uggests that many sites were able to solve acommon set of "easy" problems, but were stymiedin processing messages which involved "hard"problems.
Whether this is true, and just whatthe hard problems are, will require more extensiveanalysis of the results of MUC-6.
Are the short-comings due primarily to a lack of coverage in thebasic patterns, to a lack of background knowledgein the domain, to failures in coreference, or some-thing else?
We.
may hope that the failings areprimarily in one area, so that we may concentrateour energies there, but more likely the failings willbe in many areas, and broad improvements in ex-traction engines will be needed to improve perfor-mance.9a term suggested by George Krupka470Pushing improvements in the underlying tech-nology was one of tlm goals of SemEval and itscurrent survivor, eoreference.. Much of tile en-ergy for the current round, however, went intohoning the definition of the task.
Philosol)hersof language have been arguing over reference andcoreferencc for centuries, so we should not havebeen surprised that it would t)e so hard to pre-pare a precise and consistent definition.
Addi-tional work on the definition will he necessary,and it may be necessary to narrow the task fllr-ther.
Despite these distractions, a few interestingearly results were ol)tained regarding eoreferencemethods; we may hot)e that, once the task specifi-cation settles down, the availability of coreference-aimotated corpora nd the chance for glory ill fltr-ther evaluations will ein'ourage more work in thisarea.Append ix :  Sample  Scenar ioTemplateShown below is a set of templates for the MUC-6 scenario template task.
Tile scenario involvedchanges in corporate executive management per-sonnel.
~br the text;McCann has initiated a new so-calledglobal collaborative system, (:omposedof world-wide account directors pairedwith creative partners.
In addition, P(>ter Kim was hired from WPP Grout)'s .I.Walter Thompson last; Septenfl)er as vicechairman, chief strategy officer, worhl-wide.the following templates were to be generated:<SUCCESSION_EVENT-9402240133-3> :=SUCCESSION_ORG : <ORGANIZATION-9402240133-1>POST: "v ice chairman, ch ie f  s t ra tegyoff icer,  wor ld-wide"IN_AND_OUT : < IN_AND_OUT-9402240 i33~5>VACANCY_REASON : OTH_UNK< IN_AND_OUT-9402240133-5> :=IO_PERSON : <PERSON-9402240133-5>NEW_STATUS : INON_THE_ JOB : YESOTHER_ORG : <ORGANIZAT ION-9402240133-8>REL_OTHER ORG : OUTSIDE_ORG<ORGANIZAT ION-9402240133-  i> :=ORG_NAME : "McCann"ORG_TYPE : COMPANY<ORGANIZAT ION-9402240133-8> :=ORG_NAME: "J. Walter  Thompson"ORG_TYPE : COMPANY<PERSON-9402240133-5> :=PER NAME: "Peter Kim"Although we cannot explain al\] tile details ofthe template here, a few highlights shouht benoted.
For each executive post; one generates aSUCCESSION_EVENT template, which containsrefl~rences to the ORGANIZATION template forthe organization i volved, and the IN_AND OUTtemplate for the activity involving that post (ifan article describes a person leaving and a per-son start;ing the same job, there will be twoIN_AND_OUT templates).
The IN_AND_OUTtemplate contains references to the tmnt)lates fl)rthe PERSON and tbr the ORGANIZATI()N fromwhich the person came (if he/she is starting anew job).
The PERSON and ORGANIZATIONtemplates are the "temt)late lement" templates,which are invariant across scenarios.471
