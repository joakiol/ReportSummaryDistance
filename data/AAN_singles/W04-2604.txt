Using prepositions to extend a verb lexiconKarin Kipper, Benjamin Snyder, Martha PalmerUniversity of Pennsylvania200 South 33rd StreetPhiladelphia, PA 19104 USAfkipper,bsnyder3,mpalmerg@linc.cis.upenn.eduAbstractThis paper presents a detailed account ofprepositional mismatch between our hand-crafted verb lexicon and a semantically an-notated corpus.
The analysis of these mis-matches allows us to rene the lexicon andto create a more robust resource capableof better semantic predictions based on theverb-preposition relations.1 IntroductionThere is currently much interest in training super-vised systems to perform shallow semantic annota-tion tasks such as word sense tagging and semanticrole labeling.
These systems are typically trained onannotated corpora such as the Penn Treebank [Mar-cus1994], and perform best when they are tested ondata from the same genre.
A more long-term goalis to develop systems that will perform equally wellon diverse genres, and that will also be able to per-form additional, more complex, semantic annotationtasks.
With this end in mind, we have been man-ually developing a large-scale, general purpose hi-erarchical verb lexicon that, in addition to links toWordNet senses [Miller1985, Fellbaum1998], has ex-plicit and detailed syntactic and semantic informa-tion associated with each entry.
Much of the syn-tactic information is derived from the Levin verbclasses, although the classication has been extendedand modied.
Sets of syntactic frames are associatedwith each verb class, and specic prepositions areoften listed as well.
We are interested in evaluatinghow well our lexicon predicts syntactic frames in nat-urally occurring data.
This will give us an estimateof its likely usefulness in extending the coverage ofsystems trained on one genre to other genres.This paper presents a comparison between our hi-erarchical verb lexicon, VerbNet [Kipper et al2000,Dang et al2000], and a corpus annotated seman-tically with predicate-argument structure, Prop-Bank [Kingsbury and Palmer2002].
We briey de-scribe an experiment which established a baseline forthe syntactic coverage of the verb lexicon and moreextensively we compare and discuss the prepositionmismatches found while doing this evaluation.
Weused this experiment, which used almost 50,000 verbinstances, to measure how well the linguistic intu-itions motivating our verb lexicon are attested to inthe actual data.
It allowed us to determine whichof the expected syntactic frames and specic prepo-sitions occur and which do not, and also look forunexpected occurrences.
Although prepositions aregenerally described as restrictions on syntax, theirsignicance goes far beyond that of a syntactic re-striction.
Verb-preposition relations can also allowus to make predictions about the semantic contentsof a verb-frame.The mapping between the two resources was doneby assigning verb classes to the dierent senses inPropBank and by assigning the thematic roles usedto describe VerbNet classes to argument roles ofPropBank.
The criteria used for matches includesboth a notion of exact frame match where the en-countered preposition was explicitly listed in theframe, as well as a more relaxed notion of framematch that allows alternative prepositions.
We foundthat under the former, our lexicon correctly predictsover 78% of all the syntactic frames found in Prop-Bank, while under the latter criterion, the results goup to 81%.
This dierential hints at the di?culty ofaccounting for semantically signicant prepositionsin sentences.
We believe that it is precisely becausethe preposition-semantics relationship is so complexthat properly accounting for it will lead to a morerobust natural language resource.The remainder of this paper is organized as follows.Sections 2 and 3 present the lexical resources used forthe experiment.
Section 4 discusses the evaluationof VerbNet against PropBank and Section 5 showsexamples of preposition mismatches between the tworesources.2 VerbNet's componentsVerbNet is an on-line broad-coverage domain-independent lexical resource with syntactic descrip-tions for over 4,100 verbs organized into classes ac-cording to the Levin classication [Levin1993].
It isa general purpose verb lexicon created initially withthe task of instructing a virtual character in a simu-lated environment in mind [Badler et al1999,Bindi-ganavale et al2000].VerbNet extends Levin's classication by pro-viding explicit syntactic and semantic informationabout the verbs it describes.
In addition, the lex-icon is organized hierarchically so that all verbs ina class (or subclass) share these syntactic descrip-tions and have common semantics.
Each verb class iscompletely described by the set of its members (eachverb has links to the appropriate senses in WordNet,thematic roles for the predicate-argument structureof the members, selectional restrictions on these ar-guments to express preferred argument types, andframes.
Each frame consists of a brief description,an example, a syntactic description corresponding toone of Levin's alternations, and a set of semanticpredicates.
In addition, each predicate has a timefunction to show at what stage of the event the pred-icate holds true, in a manner similar to the eventdecomposition of Moens and Steedman (1988) .
Inorder for the members of each class to be coherentwith respect to the thematic roles, selectional restric-tions, syntactic frames, and semantics they allow, werened the original Levin classes and added 74 newsubclasses.VerbNet's broad-coverage, with explicit syntaxand semantics, attempts to address several gapspresent in other resources.
WordNet was designedmainly as a semantic network, and contains littlesyntactic information.
VerbNet, in contrast, includesexplicit predicate argument structures for verbs intheir classes, as well as a way to systematically ex-tend those senses based on the semantics of eachclass.
FrameNet [Baker et al1998] and VerbNet bothcontain the notion of verb groupings.
The group-ings in FrameNet however are based solely on thesemantic roles shared by the members of a class.These members do not need to have the same set ofsyntactic frames, and lack explicit semantics otherthan what is provided by the semantic labels.
Un-like VerbNet, which uses a small set of thematic rolesfor all classes, FrameNet uses frame elements whichare particular to a lexical item or to small groups offrames.
Besides, one of the benets of constructinga general lexicon like VerbNet is that it allows oneto extend the coverage of resources tied to speciccorpora.The syntactic frames in VerbNet describe the sur-face realization for constructions such as transitive,intransitive, prepositional phrases, resultatives, anda large set of Levin's alternations.
A syntactic frameconsists of the thematic roles, the verb, and otherlexical items which may be required for a particu-lar construction or alternation.
Additional restric-tions may be further imposed on the thematic roles(quotation, plural, innitival, etc.).
Illustrations ofsyntactic frames are shown in examples 1, 2, and 3.
(1) Agent V Patient(John hit the ball)(2) Agent V at Patient(John hit at the window)(3) Agent V Patient[+plural] together(John hit the sticks together)VerbNet alo includes a hierarchy of prepositions,with 57 entries, derived from an extended versionof work described in Sparck-Jones and Boguraev(1987).
This restriction is necessary in order to spec-ify which prepositions are possible in a particularframe since many of Levin's alternations require spe-cic prepositions such as `as' or `with/against'.
Apartial and somewhat simplied hierarchy is shownin Figure 1.
This gure shows the spatial preposi-tions hierarchy divided into path and locative prepo-sitions.
Path prepositions are further subdivided intosource, direction, and destination prepositions.
Asyntactic frame with Prep[+src] as a constraint willallow only those specic prepositions (from, out, outof, etc) that are part of the spatial, path, source hi-erarchy.The semantic information for the verbs in Verb-Net is expressed as a conjunction of semantic pred-icates, any of which may be negated.
These seman-tic predicates fall into four categories: general pred-icates such as motion and cause which are widelyused across classes; variable predicates whose mean-ing is assumed to be in a one-to-one relation with aset of words in the language; predicates that are spe-cic to certain classes; and predicates for multipleevents which are used to express relations betweenevents.
The semantic predicates can take argumentsover the verb complements, as well as over implicitexistentially quantied event variables.Relations between verbs (or between verb classes)such as antonymy and entailment present in Word-spatialpathsrcfromoutout of.
.
.diracrossalongarounddown.
.
.destdest-confintoontodest-dirforattotowardslocaboutaboveagainst.
.
.Figure 1: Partial hierarchy of prepositions of the verb lexiconNet can be predicted upon verication of the pred-icates used.
Relations between verbs (and verbclasses) such as the ones predicted in FrameNet, canalso be veried by the semantic predicates, for in-stance all of the Communication classes have thesame predicates of cause and transfer info.
Aspect inVerbNet is captured by the time function argumentpresent in the predicates.3 PropBankThe PropBank project [Kingsbury and Palmer2002]is annotating the Penn Treebank with predicate-argument structures.
Semantic roles are dened foreach verb in PropBank.
These roles are meant to betheory neutral and are simply numbered.
Verb sensesare distinguished by dierent Framesets, with a sep-arate set of numbered roles, called a roleset, denedfor each Frameset.
An example of the Framesets forthe verb leave can be seen in Figure 2.
Arg0 is usuallyassociated with Agent and Arg1 is usually similar toTheme or Patient.
However, argument labels are notnecessarily signicant across dierent verb meaningsor across dierent verbs.Roleset leave.01 \move away from":Arg0: entity leavingArg1: place leftArg3: attributeEx: [ARG0The move] [relleft] [ARG1thecompanies] [ARG3 asas outside bidders.
]Roleset leave.02 \give":Arg0: giverArg1: thing givenArg2: beneciaryEx: [ARG0John] [relleft] [ARG1cookies][ARG2 forfor Mary]Figure 2: Framesets for the verb leave in PropBank4 Matching syntactic coveragebetween the two resourcesIn order to test the syntactic coverage of VerbNet, weperformed an experiment to identify which syntacticframes found in the PropBank corpus are representedin our verb lexicon.
As expected, we uncovered syn-tactic frames and prepositions not initially predictedin our resource which may now be added.For this evaluation 49,073 PropBank annotated in-stances were used, which translated into 1,678 verbentries in VerbNet.
Since the notion of a Prop-Bank Frameset and a VerbNet class are not perfectlyequivalent, an individual Frameset may be mappedto multiple classes.
In order to put the two re-sources in correspondence we created mappings be-tween the Framesets and our verb classes, as well asmappings between the argument labels in the rolesetof a Frameset to the thematic roles in our classes.The process of assigning a verb class to a Framesetwas performed manually during the creation of newPropBank frames.
The thematic role assignment, onthe other hand, is a semi-automatic process whichnds the best match for the argument labels, basedon their descriptors, to the set of thematic roles ofVerbNet.To verify whether a particular syntactic framefound in PropBank was present in our lexicon, wetranslated the PropBank annotated sentence intoVerbNet-style frames.
An example of this transla-tion for the verb leave is given below.
Example sen-tence (4) is taken from the corpus, its PropBank an-notation can be seen in (5), and the VerbNet-styleframe is shown in (6).
In this example, the verbleave is mapped to two VerbNet classes 51.2 (Leaveclass), and 13.3 (Future-having class), with dierentroles mapped to the argument labels in each of theseclasses.
(4) wsj/05/wsj 0568.mrg 12 4:The tax payments will leave Unisys with $ 225million *U* in loss carry-forwards that *T*-1 willcut tax payments in future quarters .
(5) [ARG0The tax payments] [relleave] [ARG2Unisys][ARG1 withwith $ 225 million](6) (a) leave-51.2: Theme V NP Prep(with) Source(b) future having-13.3: Agent V RecipientPrep(with) ThemeIn this instance, only the latter of the two con-structed frames matches a frame in VerbNet.
In ef-fect, this serves as a sort of sense disambiguation, asthe leave entry in class 51.2 has the sense \to exit,"while the entry in class 13.3 has a sense similar tothe verb \to give."
In fact the sense of \leave" in thesentence is the latter, and the single matched frameconrms this.In general, we used several criteria when attempt-ing to match a constructed frame to a frame in Verb-Net.
Two of these criteria are of primary interest forthis paper:1. the exact frame description was present in Verb-Net (henceforth called \exact match", or amatch under the strict criterion);2. the frame description is present in VerbNet butthere is a preposition mismatch (henceforth re-ferred as a \relaxed match").For instance, if the translated corpus sentenceis Agent V Prep(as) Theme, but VerbNet predictsAgent V Prep(for) Theme for verbs in the class, thisannotation would be considered a relaxed match,but not an exact match.
VerbNet predicts 78% offrames found in PropBank under the strict criterionand 81% of those frames under the relaxed criterion.More details of this experiment are described in Kip-per et al (2004) .5 Using prepositions from thecorpus to rene verb classesBy comparing our theoretically motivated sets ofsyntactic frames for an individual verb with the ac-tual data, we can evaluate both the coverage of ourlexicon and its theoretical underpinnings.
There aremany questions to be addressed with respect to cov-erage: Do the predicted syntactic frames occur?
Dothe predicted prepositions occur?
Do other, unpre-dicted prepositions occur as well?
Depending on theanswers to these questions, prepositions (or syntacticframes) may be inserted into or deleted from specicclasses and entire classes may be restructured.Our verb lexicon matches over 78% of all the syn-tactic frames found in PropBank.
However, whenrestricting the frames found in PropBank to thosewithout prepositions, the resulting match rate is al-most 81%.
This dierence hints at the di?cultyof accounting for semantically signicant preposi-tions in sentences, and a proper account of thispreposition-semantic relationship seems essential tous in order to build a more robust lexical resource.5.1 Prepositions in the CorpusVerb occurrences are partitioned according towhether a preposition occurs or not in the instanceframe, and according to how well the constructedframe matches a VerbNet frame.
Almost 4/5 of theverb instances studied do not contain a signicantpreposition in their PropBank annotation (and con-sequently their constructed frames do not includeany prepositions).1On these instances, we obtaineda 81% match rate under the strict criterion.1We consider a preposition \signicant" if the prepo-sition object is a PropBank argument with a mapping toa thematic role, excluding preposition \by".Of the 49,073 verb instances we are looking at,9,304 instances had a signicant preposition, withconstructed frames including one or more preposi-tional items.
For those we obtain match rates of65% and 76% (depending on whether prepositionmismatches were allowed or not).The dierence between the 81% match rate of theframes without prepositions and the 65%-76% matchrate in the frames with prepositions is substantialenough to lead us to believe that a close examina-tion of the sentences containing a preposition andtheir comparison to VerbNet frames would allow usto improve the coherence of our verb classes.5.2 Prepositional MismatchFor the instances with signicant prepositionalitems, 65% (6,033 instances) have constructed frameswith an exact match to VerbNet.
Of the remaining3,271 instances, 1,015 are relaxed matches, and 2,256do not bear any matches to VerbNet frames.We focused on those verb instances which wouldhave matched a VerbNet frame if only a dierentpreposition had been used in the sentence or if theVerbNet frame had included a wider range of prepo-sitions.
In addition to the 1,015 instances, we lookedat 652 verb instances, all of which share the follow-ing two properties: (i) that the verb in question iscontained in multiple VerbNet classes, and (ii) thatalthough the constructed frame matches one of thoseVerbNet classes exactly, there is at least one otherclass where it matches only under the relaxed crite-rion (when the value of the preposition is ignored).These instances are important because the value ofthe preposition in these cases can help decide whichis the most appropriate VerbNet class for that in-stance.
This information could then be used forcoarse-grained automatic sense tagging { either toestablish a PropBank Frameset or a set of WordNetsenses for those instances, since verbs instances inour verb lexicon are mapped to that resource.These 1,667 verb instances (1,015 preposition mis-matches + 652 exact matches) comprise 285 uniqueverbs and are mapped to a total of 97 verb classes.5.3 Explanation of MismatchAfter a close examination of these 1,667 instances,we veried that the mismatches can be explained anddivided into the following cases:1. cases where a preposition should be added to aVerbNet class (in some of these cases, a rene-ment of the class into more specic subclasses isneeded, since not all members take the includedpreposition);2. cases where the particular usage of the verb isnot captured by any VerbNet entry (this is thecase with metaphorical uses of certain verbs);3. incorrect mappings between PropBank andVerbNet;24. cases where the PropBank annotation is incon-sistent;5. cases where the particular instance belongs toanother VerbNet class (which are expected sincethe PropBank data used does not yet providesense tags).As an example, in the PropBank annotated corpuswe nd the sentence:\Lotus Development Corp. feeds its evaluationsinto a computer...",The verb to feed is present in four VerbNet classes.The frame resulting from translating the PropBankannotation to a VerbNet-style frame Agent V ThemePrep(into) Recipient bears a resemblance to a framepresent in one of the classes (Give-13.1, syntacticframe Agent V Theme Prep(to) Recipient).
This isa case where a VerbNet class requires renements(with addition of new subclasses) to account forprepositions unique to a subset of the verbs in theclass.
It is an open question whether such rene-ments, taken to completion, would result in sub-classes that are so ne-grained they have a mem-bership of one.
If so, it may be more appropriate toadd verb-specic preposition preferences to existingclasses.Another example is the following use of \build" inthe PropBank corpus:\...to build their resumes through good grades andleadership roles ..."This sentence yields the frame Agent V ProductPrep(through) Material after translating the Prop-Bank annotation to a VerbNet-style frame.
Thisframe bears a relaxed match to the Agent V ProductPrep(from, out of) Material syntactic frame foundin the Build-26.1 class.
In VerbNet, the phrase\..through good grades ..." is considered an adjunctand therefore not relevant for the syntactic frame.In PropBank, however, this phrase is annotated asan argument (Arg2), which maps to the \Material"thematic role in VerbNet.
This example shows, as ex-pected, mismatches between argument and adjunctsin the two resources.As a nal example, consider the following use ofthe verb lease:2We asserted an error of 6.7% for the automatic map-pings in a random sample of the data.\The company said it was leasing the site of therenery from Aruba.
"Two frames are constructed for this verb instance,one for each of the VerbNet classes to which thePropBank lease Frameset is mapped.
Its member-ship in class Get-13.5.1, and class Give-13.1 respec-tively yield the following two VerbNet-style frames:(a) 13.1: Agent V Theme Prep(from) Recipient(b) 13.5.1: Agent V Theme Prep(from) Source.The rst frame bears a relaxed match to a framein its class (Agent V Theme Prep(to) Recipient)whereas the second is an exact match to a framein the second class.
In this instance, the preposition`selects' the appropriate VerbNet class.3In fact, weexpect this to happen in all the 652 instances with ex-act matches, since in those instances, the constructedframe bears an exact match to one VerbNet class, buta relaxed match to another.
The dierent Framesetsof a verb are typically mapped to distinct sets ofVerbNet classes.
If the preposition present in thesentence matches frames in only a subset of thoseVerbNet classes, then we are able to rule out cer-tain Framesets as putative senses of the instance ina sense tagging task.6 ConclusionWe presented a detailed account of how prepositionstaken from a semantically annotated corpus can beused to extend and rene a hand-crafted resourcewith syntactic and semantic information for Englishverbs.
That the role of prepositions should not beneglected can be clearly seen from the dierential inmatch rates between those sentences with preposi-tions and those without.
The signicance of prepo-sitions and their relation with verbs is of the utmostimportance for a robust verb lexicon, not only asa syntactic restrictor, but also as a predictor of se-mantic content.
On the basis of these experimentswe are adding 132 new subclasses to VerbNet's ini-tial 191 classes and 74 subclasses, going far beyondbasic Levin Classes.One of the payos of constructing a general lexiconlike VerbNet is that it allows one to extend the cov-erage of resources tied to specic corpora (e.g.
Prop-Bank, FrameNet).
Currently we are in the process ofadding mappings between our verbs and FrameNetverbs and mappings between our syntactic framesand Xtag [XTAG Research Group2001] trees.
These3It was pointed out that a possible interpretation isthat \from Aruba" is linked to the \renery" argument,in which case this instance would be translated as AgentV Theme and therefore have a perfect match to the Give-13.1 class.mappings will allow us to more deeply investigateverb behavior.AcknowledgmentsThis work was partially supported by NSF Grant9900297, DARPA Tides Grant N66001-00-1-891 andACE Grant MDA904-00-C-2136.ReferencesNorman I. Badler, Martha Palmer, and Rama Bindi-ganavale.
1999.
Animation control for real-timevirtual humans.
Communications of the ACM,42(7):65{73.Collin F. Baker, Charles J. Fillmore, and John B.Lowe.
1998.
The Berkeley FrameNet project.
InProceedings of the 17th International Conferenceon Computational Linguistics (COLING/ACL-98), pages 86{90, Montreal.
ACL.Rama Bindiganavale, William Schuler, Jan M. All-beck, Norman I. Badler, Aravind K. Joshi, andMartha Palmer.
2000.
Dynamically AlteringAgent Behaviors Using Natural Language Instruc-tions.
Fourth International Conference on Au-tonomous Agents, June.Hoa Trang Dang, Karin Kipper, and Martha Palmer.2000.
Integrating compositional semantics intoa verb lexicon.
In Proceedings of the EighteenthInternational Conference on Computational Lin-guistics (COLING-2000), Saarbrucken, Germany,July-August.Christiane Fellbaum, editor.
1998.
WordNet: AnEletronic Lexical Database.
Language, Speech andCommunications.
MIT Press, Cambridge, Mas-sachusetts.Karen Sparck Jones and Branimir Boguraev.
1987.A note on a study of cases.
American Journal ofComputational Linguistics, 13((1-2)):65{68.Paul Kingsbury and Martha Palmer.
2002.
Fromtreebank to propbank.
In Proceedings of the 3rdInternational Conference on Language Resourcesand Evaluation (LREC-2002), Las Palmas, Ca-nary Islands, Spain.Karin Kipper, Hoa Trang Dang, and Martha Palmer.2000.
Class-based construction of a verb lexicon.In Proceedings of the Seventh National Conferenceon Articial Intelligence (AAAI-2000), Austin,TX, July-August.Karin Kipper, Benjamin Snyder, and MarthaPalmer.
2004.
Extending a verb-lexicon using asemantically annotated corpus.
In Proceedings ofthe 4th International Conference on Language Re-sources and Evaluation (LREC-04), Lisbon, Por-tugal.Beth Levin.
1993.
English Verb Classes and Alterna-tion, A Preliminary Investigation.
The Universityof Chicago Press.Mitch Marcus.
1994.
The penn treebank: A revisedcorpus design for extracting predicate-argumentstructure.
In Proceedings of the ARPA HumanLanguage Technology Workshop, Princeton, NJ,March.George Miller.
1985.
Wordnet: A dictionarybrowser.
In Proceedings of the First InternationalConference on Information in Data, Waterloo,Ontario.M.
Moens and M. Steedman.
1988.
Temporal On-tology and Temporal Reference.
ComputationalLinguistics, 14:15{38.XTAG Research Group.
2001.
A lexicalized treeadjoining grammar for english.
Technical ReportIRCS-01-03, IRCS, University of Pennsylvania.
