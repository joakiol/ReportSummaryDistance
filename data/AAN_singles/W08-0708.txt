Proceedings of the Tenth Meeting of the ACL Special Interest Group on Computational Morphology and Phonology, pages 49?58,Columbus, Ohio, USA June 2008. c?2008 Association for Computational LinguisticsEvaluating an Agglutinative Segmentation Model for ParaMorChristian Monson, Alon Lavie, Jaime Carbonell, Lori LevinLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15217, USA{cmonson, alavie, jgc, lsl}@cs.cmu.eduAbstractThis paper describes and evaluates a modifica-tion to the segmentation model used in the un-supervised morphology induction system, Pa-raMor.
Our improved segmentation modelpermits multiple morpheme boundaries in asingle word.
To prepare ParaMor to effectivelyapply the new agglutinative segmentationmodel, two heuristics improve ParaMor?s pre-cision.
These precision-enhancing heuristicsare adaptations of those used in other unsuper-vised morphology induction systems, includingwork by Hafer and Weiss (1974) and Gold-smith (2006).
By reformulating the segmenta-tion model used in ParaMor, we significantlyimprove ParaMor?s performance in all lan-guage tracks and in both the linguistic evalua-tion as well as in the task based information re-trieval (IR) evaluation of the peer operatedcompetition Morpho Challenge 2007.
Para-Mor?s improved morpheme recall in the lin-guistic evaluations of German, Finnish, andTurkish is higher than that of any system whichcompeted in the Challenge.
In the three lan-guages of the IR evaluation, our enhanced Pa-raMor significantly outperforms, at averageprecision over newswire queries, a morpho-logically na?ve baseline; scoring just behind theleading system from Morpho Challenge 2007in English and ahead of the first place systemin German.1 Unsupervised Morphology InductionAnalyzing the morphological structure of wordscan benefit natural language processing (NLP) ap-plications from grapheme-to-phoneme conversion(Demberg et al, 2007) to machine translation(Goldwater and McClosky, 2005).
But many of theworld?s languages currently lack morphologicalanalysis systems.
Unsupervised induction could fa-cilitate, for these lesser-resourced languages, thequick development of morphological systems fromraw text corpora.
Unsupervised morphology induc-tion has been shown to help NLP tasks includingspeech recognition (Creutz, 2006) and informationretrieval (Kurimo et al, 2007b).
In this paper wework with languages like Spanish, German, andTurkish for which morphological analysis systemsalready exist.The baseline ParaMor algorithm which we ex-tend here competed in the English and Germantracks of Morpho Challenge 2007 (Monson et al,2007b).
The peer operated competitions of theMorpho Challenge series standardize the evalua-tion of unsupervised morphology induction algo-rithms (Kurimo et al, 2007a; 2007b).
The ParaMoralgorithm showed promise in the 2007 Challenge,placing first in the linguistic evaluation of German.Developed after the close of Morpho Challenge2007, our improvements to the ParaMor algorithmcould not officially compete in this Challenge.However, the Morpho Challenge 2007 OrganizingCommittee (Kurimo et al, 2008) graciously over-saw the quantitative evaluation of our agglutinativeversion of ParaMor.1.1 Related WorkA variety of approaches to unsupervised morphol-ogy induction have shown promise in past work:Here we highlight three techniques which havebeen used in a number of unsupervised morphol-ogy induction algorithms.
Since character se-quences are less predictable at morpheme bounda-ries than within any particular morpheme (see dis-cussion in section 2.1), a first unsupervised mor-49phology induction technique measures the predict-ability of word-internal character sequences.
Harris(1955) was the first to propose the branching factorof the character tree of a corpus vocabulary as ameasure of character predictability.
Character treeshave been incorporated into a number of more re-cently proposed unsupervised morphology induc-tion systems (Schone and Jurafsky, 2001; Wicen-towski, 2002; Goldsmith, 2006; Bordag, 2007).Johnson and Martin (2003) generalize from charac-ter trees and model morphological character se-quences with minimized finite state automata.Bernhard (2007) measures character predictabilityby directly computing transitional probabilities be-tween substrings of words.A second successful technique has used theminimum description length principle to capturethe morpheme as a recurrent structure of morphol-ogy.
The Linguistica system of Goldsmith (2006),the Morfessor system of Creutz (2006), and thesystem described in Brent et al (1995) take thisapproach.A third technique leverages inflectional para-digms as the organizational structure of morphol-ogy.
The ParaMor algorithm, which this paper ex-tends, joins Snover (2002), Zeman (2007), andGoldsmith?s Linguistica in building morphologymodels around the paradigm.ParaMor tackles three challenges that face mor-phology induction systems which Goldsmith's Lin-guistica algorithm does not yet address.
First, sec-tion 2.2 of this paper introduces an agglutinativesegmentation model.
This agglutinative model seg-ments words into as many morphemes as the datajustify.
Although Goldsmith (2001) and Goldsmithand Hu (2004) discuss ideas for segmenting indi-vidual words into more than two morphemes, theimplemented Linguistica algorithm, as presented inGoldsmith (2006), permits at most a single mor-pheme boundary in each word.
Second, ParaMordecouples the task of paradigm identification fromthat of word segmentation (Monson et al, 2007b).In contrast, morphology models in Linguistica in-herently encode both a belief about paradigmstructure on individual words as well as a segmen-tation of those words.
Without ParaMor?s decoup-ling of paradigm structure from specific segmenta-tion models, our algorithm for agglutinative seg-mentation (section 2.2) would not have been possi-ble.
Third, the evaluation of ParaMor in this paperis over much larger corpora than any publishedevaluation of Linguistica.
Goldsmith (2006) seg-ments the Brown corpus of English, which, afterdiscarding numbers and punctuation, has a vocabu-lary size of 47,607 types.
Using Linguistica, Creutz(2006) successfully segments a Finnish corpus of250,000 tokens (approximately 130,000 types), butCreutz notes that Linguistica is memory intensiveand not runable for larger corpora.
In the evalua-tions of Morpho Challenge 2007, ParaMor seg-mented the words from corpora with over 42 mil-lion tokens and vocabularies as large as 2.2 milliontypes.2 ParaMorThis section briefly outlines the high level struc-ture of ParaMor as described in detail in Monson etal.
(2007a; 2007b).
ParaMor takes the inflectionalparadigm as the basic building block of morphol-ogy.
A paradigm is a mutually substitutable set ofmorphological operations.
For example, most ad-jectives in Spanish inflect for two paradigms.
First,adjectives are marked for gender: an a suffixmarks feminine, an o masculine.
Then Spanish ad-jectives mark number: an s suffix signals plural,while no marking, ?
in this paper, indicates singu-lar.
The four surface forms of the cross-product ofthe gender and number paradigms on the Spanishword for ?beautiful?
are then: bello, bella, bellos,and bellas.ParaMor is a two stage algorithm.
In the firststage, ParaMor identifies candidate paradigmswhich likely model suffixes of morphological pa-radigms and their cross-products.
Since some 70%of the world?s languages are significantly suffixing(Dryer, 2005), ParaMor only attempts to identifysuffix paradigms.
ParaMor?s first stage consists ofthree pipelined steps.
In the first step, ParaMorsearches a space of candidate partial paradigms,called schemes, for those which possibly modelsuffixes of true paradigms.
The second step mergesselected schemes which appear to model the sameparadigm.
And in the third step, ParaMor discardsscheme clusters which likely do not model trueparadigms.The second stage of the ParaMor algorithmsegments word forms using the candidate para-digms identified in the first stage.
Section 2.2 ofthis paper introduces a new segmentation modelfor ParaMor?s second stage that allows more thanone morpheme boundary in a single word?as is50needed to correctly segment Spanish plural adjec-tives.
As this agglutinative segmentation model re-lies on the paradigms learned in ParaMor?s firststage, section 2.1 presents solutions to two types ofparadigm model error that the baseline ParaMorsystem makes.
The solutions to these two errortypes are similar in nature to ideas proposed in theunsupervised morphology induction work of Haferand Weiss (1974) and Goldsmith (2006).2.1 Precision at Paradigm IdentificationTable 1 presents 14 of the more than 8000 schemesidentified during one baseline run of ParaMor?sscheme search step.
Each row of Table 1 lists ascheme that was selected while searching over aSpanish newswire corpus of 50,000 types.
On thefar left of Table 1, the Rank column states the or-dinal rank at which that row?s scheme was selectedduring the search procedure: the first scheme Pa-raMor selects is ?.s; a.as.o.os is the second; ido.-idos.ir.ir?
is the 1566th selected scheme, etc.
Theright four columns of Table 1, present raw data onthe selected schemes, giving the number of can-didate suffixes in that scheme, the proposed suf-fixes themselves, the number of candidate stems inthe scheme, and a sample of those candidate stems.Each candidate stem in a ParaMor scheme forms aword that occured in the input corpus with eachcandidate suffix belonging to that scheme; forexample, from the first selected scheme, the candi-date stem apoyada joins to the candidate suffix s toform the word apoyadas ?supported (adjectivefeminine plural)?
?a word which occured in theSpanish newswire corpus.Between the rank on the left and the schemedetails on the right of Table 1, are columns whichcategorize the scheme on its success, or failure, tomodel a true paradigm of Spanish.
A dot appears inthe columns marked Noun, Adjective, or Verb if themajority of the candidate suffixes in a row?sscheme attempt to model suffixes in a paradigm ofthat part of speech.
A dot appears in the Derivationcolumn if one or more candidate suffixes of thescheme models a Spanish derivational suffix.
TheGood column is marked if the candidate suffixes ofa scheme take the surface form of true paradig-matic suffixes.
Initially selected schemes in Table1 that correctly capture suffixes of real Spanishparadigms are the 1st, 2nd, 5th, 13th, 30th, and 1566thselected schemes.
While some smaller paradigmsof Spanish are perfectly identified (including ?.s,which marks singular and plural on many nounsand adjectives, and the adjectival cross-productparadigm of gender and number, a.as.o.os) manyselected schemes do not satisfactorily model Span-ish suffixes.
Incorrect schemes in Table 1 aremarked in the Error columns.The vast majority of unsatisfactory paradigmmodels fail for one of two reasons.
First, manyschemes contain candidate suffixes which system-Model of ErrorVerbRankNounAdjectivear er irDerivationGoodStemInternalSuffix InternalChanceCandidate Suffixes Candidate Stems1 ?
?
?
2 ?.s 5513 apoyada, barata, hombro, oficina, reo, ?2  ?
?
4 a.as.o.os 899 apoyad, captad, dirigid, junt, pr?xim, ?3   ?
?
14 ?.ba.ban.da.das.do.dos.n.ndo.r.ron.rse.r?.r?n 25 apoya, disputa, lanza, lleva, toma, ?5   ?
?
15 a.aba.aban.ada.adas.ado.ados.an.ando.ar.aron.arse.ar?.ar?n.?
24 apoy, desarroll, disput, lanz, llev, ?11  ?
?
?
5 ta.tamente.tas.to.tos 22 cier, direc, ins?li, modes, sangrien, ?12   ?
?
?
14 ?.ba.ci?n.da.das.do.dos.n.ndo.r.ron.r?.r?n.r?a 16 acepta, concentra, fija, provoca, ?13   ?
?
15 a.aba.ada.adas.ado.ados.an.ando.ar.aron.ar?.ar?n.e.en.?
20 apoy, declar, enfrent, llev, tom, ?30    ?
?
?
11 a.e.en.ida.idas.ido.idos.iendo.ieron.i?.
?a 15 cumpl, escond, recib, transmit, vend, ?1000          ?
3 ?.g.gs 4 h, k, on, s1566     ?
?
4 ido.idos.ir.ir?
6 conclu, cumpl, distribu, exclu, reun, segu2000      ?
?
2 lia.liana 5 austra, ita, ju, sici, zu3000          ?
3 ?.a.anar 4 all, am, g, s4000          ?
3 ?.e.ince 4 l, pr, qu, v8000   ?
?
2 trada.trarnos 3 concen, demos, enconTable 1.
Candidate partial paradigms, or schemes, that the baseline ParaMor algorithm selected during its first step,search, of its first stage, paradigm identification.
This baseline ParaMor run was over a Spanish newswire corpus of50,000 types.
While some selected schemes contain suffixes from true paradigms, other schemes contain incorrectlysegmented candidate suffixes.51atically misanalyze word forms.
These schemesconsistently hypothesize either stem-internal orsuffix-internal morpheme boundaries.
Schemeswhich hypothesize incorrect morpheme boundariesinclude the 3rd, 11th, 12th, 2000th, and 8000th se-lected schemes of Table 1.
Among these, the 3rdand 12th selected schemes place morpheme boun-daries internal to true suffixes.
For example, the 3rdselected scheme contains truncated forms of suf-fixes that occur correctly in the 5th selectedscheme.
Symmetrically, the candidate suffixes inthe 11th, 2000th, and 8000th selected schemes hy-pothesize morpheme boundaries internal to trueSpanish stems, inadvertently including portions ofstems within their suffix lists.
In a random sampleof 100 schemes from the 8240 schemes that thebaseline ParaMor algorithm selects over our Span-ish corpus, 59 schemes hypothesized an incorrectmorpheme boundary.The second most prevalent reason for modelfailure occurs when the candidate suffixes of ascheme are related not by belonging to the sameparadigm, but rather by a chance co-occurrence ona few candidate stems of the text.
Schemes whicharise from chance string collisions in Table 1 in-clude the 1000th, 3000th, and 4000th selectedschemes.
The string lengths of the candidate stemsand candidate suffixes of these chance schemes areoften quite short.
The longest candidate stem inany of the three chance-error schemes of Table 1 isthree characters long; and all three selectedschemes propose the suffix ?, which has lengthzero.
Short stems and short suffixes in selectedschemes are easily explained combinatorially: Theinventory of possible strings grows exponentiallywith the length of the string.
Because there justaren?t very many length one, length two, or evenlength three strings, it should come as no surprisewhen a variety of candidate suffixes happen to oc-cur attached to the same set of short stems.
In ourrandom sample of 100 initially selected schemes,35 were erroneously selected as a result of achance collision of word types.The next two sub-sections present solutions tothe two types of paradigm model failure in thebaseline algorithm that are exemplified in Table 1.These first two extensions aim to improve preci-sion by reducing the number of schemes ParaMorerroneously selects.Correcting Morpheme Boundary ErrorsMost of the baseline selected schemes which incor-rectly hypothesize a morpheme boundary do so atstem-internal positions.
Indeed, in our randomsample of 100 schemes, 51 of the 59 schemes withmorpheme boundary errors incorrectly hypothe-sized a boundary stem-internally.
For this reason,the baseline ParaMor algorithm already discardedschemes that likely misplace a boundary stem-internally (Monson et al, 2007b).
Although thereare fewer schemes that misplace a morphemeboundary suffix-internally, suffix-internal errorschemes contain short suffixes that can generalizeto segment a large number of word forms.
(Seesection 2.2 for a description of ParaMor?s morpho-logical segmentation model).
To measure the in-fluence of suffix-internal error schemes on mor-pheme segmentation, we examined ParaMor?sbaseline segmentations of a random sample of 100word forms from the 50,000 words of our Spanishcorpus.
In these 100 words, 82 morpheme bounda-ries were introduced that should not have been.And 40 of these 82 incorrectly proposed bounda-ries were placed by schemes which hypothesized amorpheme boundary internal to true suffixes.To address the problem of suffix-internal mis-placed boundaries we adapt an idea originally pro-posed by Harris (1955) and extended by Hafer andWeiss (1974): Take any string t. Let F be the set ofstrings such that for each Ff ?
, t.f is a word formof a particular natural language.
Harris noted thatwhen the boundaries between t and each f fall atmorpheme boundaries, the strings in F typicallybegin in a wide variety of characters; but when thet-f boundaries are morpheme-internal, each legiti-mate word final string must first complete the er-roneously split morpheme, and so the strings in Fwill begin with one of a very few characters.
Thisargument similarly holds when the roles of t and fare reversed.
Hafer and Weiss (1974) describe anumber of variations to Harris?
letter variety algo-rithm.
Their most successful variation uses entropyto measure character variety.Goldsmith?s (2006) Linguistica algorithm pio-neered the use of entropy in a paradigm-based un-supervised morphology induction system.
Linguis-tica measures the entropy of stem-final charactersin a set of initially selected paradigm models.When entropy falls below a threshold, Linguisticaconsiders relocating the morpheme boundary of52each word covered by that paradigm model.
If, af-ter boundary relocation, the resulting descriptionlength of Linguistica?s morphology model de-creases, Linguistica accepts the relocated bounda-ries.To identify suffix-internal morpheme boundaryerrors among ParaMor?s initially selected schemes,we follow Hafer and Weiss (1974) and Goldsmith(2006) in using entropy as a measure of the varietyin boundary-adjacent character distributions.
In aParaMor style scheme, the candidate stems form aset of word-initial strings, and the candidate suf-fixes a set of word-final strings.
If a scheme?sstems end in a very few unique characters, thescheme has likely hypothesized an incorrect suffix-internal morpheme boundary.
Consider the 3rd se-lected scheme in Table 1.
All 25 of the 3rdscheme?s stems end in the character ?a?.
Conse-quently, we measure the entropy of the distributionof final characters in each scheme?s candidatestems.
Where Linguistica modifies paradigm mod-els which appear to incorrectly place morphemeboundaries, our extension to ParaMor permanentlyremoves schemes.
To avoid introducing a free pa-rameter, our extension to ParaMor flags a schemeas a likely boundary error only when virtually allof that scheme?s candidate stems end in the samecharacter.
We flag a scheme if its entropy is belowa threshold set close to zero, 0.5.
The baseline Pa-raMor algorithm discards schemes which it be-lieves hypothesize an incorrect stem-internal mor-pheme boundary only after the scheme clusteringstep of ParaMor?s paradigm identification stage.Our extension follows suit: If we flag more thanhalf of the schemes in a cluster as likely proposinga suffix-internal boundary, then we discard thatcluster.
Referencing Table 1, this first extension toParaMor successfully removes both the 3rd and the12th selected schemes.Correcting Chance String Collision ErrorsScheme errors due to chance string collisions arethe second most prevalent error type.
As describedabove, the string lengths of the candidate stemsand suffixes of chance schemes are typically short.When the stems and suffixes of a scheme are short,then the underlying types which support a schemeare also short.
Where the baseline ParaMor algo-rithm explicitly builds schemes over all types in acorpus, we modify ParaMor to exclude short typesfrom the vocabulary during morphology induction.Goldsmith (2006) also uses string-length thresh-olds to restrict what paradigm models the Linguis-tica algorithm produces.Excluding short types during ParaMor?s mor-phology induction stage does not preclude shorttypes from being analyzed as containing multiplemorphemes during ParaMor?s segmentation stage.As section 2.2 describes, ParaMor?s segmentationalgorithm is independent of the set of types fromwhich schemes and scheme clusters are built.The string length that types must meet to jointhe induction vocabulary is a free parameter.
Pa-raMor is designed to identify the productive inflec-tional paradigms of a language.
Unless a paradigmis restricted to occur only with short stems, a pos-sible but unusual scenario (as with the English ad-jectival comparative, c.f.
faster but *exquisiter) wecan expect a productive paradigm to occur with areasonable number of longer stems in a corpus.Hence, ParaMor needn?t be overly concernedabout discarding short types.
A qualitative exam-ination of Spanish data suggested discarding typesfive characters or less in length; we use this cutoffin all experiments described in this paper.Excluding short types from the paradigm induc-tion vocabulary virtually eliminates the entire cate-gory of chance scheme.
In a random sample of 100schemes that ParaMor selected when short typeswere excluded, only one scheme contained typesrelated only by chance string similarity, down from35 when short types were not excluded.
Returningto Table 1, excluding types five characters or lessin length bars ten of the twelve word types whichsupport the erroneous 3000th selected scheme ?.a.-anar.
Among the excluded types are valid Spanishwords such as ganar ?to gain?.
But also eliminatedare several meaningless acronyms such as the sin-gle letters g and s. Without these short types, Pa-raMor rightly cannot select the 3000th scheme.2.2 SegmentationAn Agglutinative ModelWith the improvement in scheme precision that re-sults from the two extensions discussed in section2.1, we are ready to propose a more realistic modelof morphology.
ParaMor?s baseline segmentationalgorithm distrusts ParaMor?s induced schememodels.
The baseline algorithm assumes each wordform can contain at most a single morphemeboundary.
If it detects more than one morpheme53boundary, then the baseline algorithm proposes aseparate morphological analysis for each possibleboundary.
In contrast, our extended model of seg-mentation vests more trust in the induced schemes,assuming that scheme clusters which propose dif-ferent morpheme boundaries are simply modelingdifferent valid morpheme boundaries.
And our ex-tension proposes a single morphological analysiscontaining all hypothesized morpheme boundaries.To detect morpheme boundaries, ParaMormatches each word, w, in the full vocabulary of acorpus against the clusters of schemes which arethe final output of ParaMor?s paradigm identifica-tion stage.
When a suffix, f, of some scheme-cluster, C, matches a word-final string of w, i.e.fuw .= , ParaMor attempts to replace f in turn witheach suffix f ?
of C. If the string fu ?.
occurs inthe full corpus vocabulary, then, on the basis ofthis paradigmatic evidence, ParaMor identifies amorpheme boundary in w between u and f .For example, to detect morpheme boundaries inthe Spanish word apoyados ?supports (adjectivemasculine plural)?, ParaMor matches all word-final strings of apoyados against the candidate suf-fixes of ParaMor?s induced scheme clusters.
Theword-final strings of apoyados are s, os, dos, ados,yados, ?.
The scheme clusters that our extendedversion of ParaMor induces include clusters whichcontain schemes very similar to the 1st, 2nd, and 5thbaseline selected schemes, see Table 1.
In particu-lar, our extended ParaMor identifies separatescheme clusters that contain the candidate suffixes:s and ?
; os and o; and ados and ado.
Substituting?
for s, o for os, or ado for ados yields the Spanishstring apoyado ?supports (adjective masculine sin-gular)?.
It so happens, that apoyado does occur inour Spanish corpus, and so ParaMor has foundparadigmatic evidence for three morpheme boun-daries.
Crucially, our ParaMor extension from sec-tion 2.1 that removes schemes which hypothesizesuffix internal morpheme boundaries correctly dis-cards all schemes which contained the candidatesuffix dos.
Consequently, no scheme cluster existsto incorrectly suggest the morpheme boundary*apoya + dos, as the 3rd baseline selected schemewould have.
Where ParaMor?s baseline segmenta-tion algorithm would propose three separate analy-ses of apoyados, one for each detected morphemeboundary: apoy +ados, apoyad +os, and apoyado+s; our extended segmentation algorithm producesthe single correct analysis: apoy +ad +o +s.It is interesting to note that although each of Pa-raMor?s individual paradigm models proposes asingle morpheme boundary, our agglutinative seg-mentation model can recover multiple boundariesin a single word.
Using this idea it may be possibleto quickly adapt Linguistica for agglutinative lan-guages.
Instead of interpreting the sets of stemsand affixes that Goldsmith?s Linguistica algorithmproduces as immediate segmentations of words,these signatures can be thought of as models ofparadigms that may generalize to new words.Augmenting ParaMor?s SegmentationsWith its focus on the paradigm, ParaMor special-izes at analyzing inflectional morphology (Monsonet al, 2007a).
Morpho Challenge 2007 requires al-gorithms to analyze both inflectional and deriva-tional morphology (Kurimo et al, 2007a; 2007b).To compete in the challenge, we combine Pa-raMor?s morphological segmentations with seg-mentations from Morfessor (Creutz, 2006), an un-supervised morphology induction algorithm whichlearns both inflectional and derivational morphol-ogy.
We incorporate the segmentations from Mor-fessor into the segmentations that the ParaMor sys-tem produces by straightforwardly adding the Mor-fessor segmentation for each word as an additionalseparate analysis to those ParaMor produces (Mon-son et al, 2007b).
Morfessor has one free parame-ter, which we optimize separately for each lan-guage of Morpho Challenge 2007.ParaMor also has several free parameters, in-cluding the type length parameter and the parame-ter over stem-final character entropy described insection 2.1.
We do not adjust any of ParaMor?s pa-rameters from language to language, but fix themat values that produce reasonable Spanish para-digms and segmentations.
As in Monson et al(2007b), to avoid adjusting ParaMor?s parameterswe limit ParaMor?s paradigm induction vocabularyto 50,000 frequent types for each language.3 EvaluationTo evaluate our extensions to the ParaMor algo-rithm, we follow the methodology of the peer op-erated Morpho Challenge 2007.
All segmentationsproduced by our extensions were sent to the Mor-pho Challenge Organizing Committee (Kurimo etal., 2008).
The Organizing Committee evaluatedour segmentations and returned the automatically54calculated quantitative results.
Using the evalua-tion methodology of Morpho Challenge 2007 per-mits us to compare our algorithms against the un-supervised morphology induction systems whichcompeted in the 2007 Challenge.
Of the many al-gorithms for unsupervised morphology inductiondiscussed with the related work in section 1.1, fiveparticipated in Morpho Challenge 2007.
Unless analgorithm has been given an explicit name, mor-phology induction algorithms will be denoted inthis paper by the name of their lead author.
Thefive algorithms which participated in the 2007Challenge are: Bernhard (2007), Bordag (2007),Zeman (2007), Creutz?s (2006) Morfessor, and Pa-raMor (2007b).Morpho Challenge 2007 had participating algo-rithms analyze words in four languages: English,German, Finnish, and Turkish.
The Challengeevaluated each algorithm?s morphological analysesin two ways.
First, a linguistic evaluation measuredeach algorithm?s precision, recall, and F1 at mor-pheme identification against an answer key of mor-phologically analyzed word forms.
Scores werenormalized when a system proposed multipleanalyses of a single word, as our combined Pa-raMor-Morfessor submissions do.
For further de-tails on the linguistic evaluation in Morpho Chal-lenge 2007, see Kurimo et al (2007a).
The secondevaluation of Morpho Challenge 2007 was a taskbased evaluation.
Each algorithm?s analyses wereimbedded in an information retrieval (IR) system.The IR evaluation consisted of queries over a lan-guage specific collection of newswire articles.
Allword forms in all queries and all documents werereplaced with the morphological decompositions ofeach individual analysis algorithm.
Separate IRtasks were run for English, German, and Finnish,but not Turkish.
For additional details on the IRevaluation of Morpho Challenge 2007 please refer-ence Kurimo et al (2007b).Tables 2 and 3 present, respectively, the lin-guistic and IR evaluation results.
In these two ta-bles, the top two rows contain results for segmen-tations produced by versions of ParaMor that in-clude our extensions.
The topmost row in each ta-ble, labeled ?+P +Seg?, gives the results for ourfully augmented version of ParaMor, which in-cludes our two extensions designed to improveprecision as well as our new segmentation modelwhich can propose multiple morpheme boundariesin a single analysis of a word form.
The secondrow of each table, labeled ?+P ?Seg?, augments Pa-raMor only with the two enhancements designed toimprove precision.
The third row of each tablegives the Challenge results for the ParaMor base-line algorithm.
Rows four through seven of eachtable give scores from Morpho Challenge 2007 forthe best performing unsupervised systems.
If mul-tiple versions of a single algorithm competed in theChallenge, the scores reported here are the highestF1 or Average Precision score of any algorithmvariant at a particular task.
In all test scenarios butFinnish IR, we produced Morfessor segmentationsto augment ParaMor that are independent of theMorfessor runs which competed in Morpho Chal-lenge.
If our Morfessor runs gave a higher F1 orAverage Precision, then we report this higherscore.
Finally, scores reported on rows eight andbeyond are from reference algorithms that are notunsupervised.
Reference algorithms appear in ital-ics.
A double line bisects both Table 2 and Table 3horizontally.
All results which appear above thedouble line were evaluated after the final deadlineof Morpho Challenge 2007.
In particular, ParaMorofficially competed only in the English and Ger-man tracks of the Challenge.The Linguistic EvaluationTable 2 contains the results from the linguisticevaluation of Morpho Challenge.
The MorphoChallenge Organizing Committee did not provideus with data on the statistical significance of theresults for the enhanced versions of ParaMor.
Butmost score differences are statistically signifi-cant?All F1 differences of more than 0.5 betweensystems which officially competed in MorphoChallenge 2007 were statistically significant (Ku-rimo et al, 2007a).In German, Finnish, and Turkish our fully en-hanced version of ParaMor achieves a higher F1than any system that competed in Morpho Chal-lenge 2007.
In English, ParaMor?s precision scoredrags F1 under that of the first place system, Bern-hard; In Finnish, the Bernhard system?s F1 is likelynot statistically different from that of our system.Our final segmentation algorithm demonstratesconsistent performance across all four languages.In Turkish, where the morpheme recall of otherunsupervised systems is anomalously low, our al-gorithm achieves a recall in a range similar to itsrecall scores for the other languages.
ParaMor?s ul-timate recall is double that of any other unsuper-55vised Turkish system, leading to an improvementin F1 over the next best system, Morfessor alone,of 13.5% absolute or 22.0% relative.In all four languages, as expected, the combina-tion of removing short types from the training data,and the additional filtering of scheme clusters,?+P?, significantly improves precision scores overthe ParaMor baseline.
Allowing multiple mor-pheme boundaries in a single word, ?+Seg?, in-creases the number of words ParaMor believesshare a morpheme.
Some of these new words do infact share a morpheme, some, in reality do not.Hence, our extension of ParaMor to agglutinativesequences of morphemes increases recall but low-ers precision across all four languages.
The effectof agglutinative segmentations on F1, however, dif-fers with language.
For the two languages whichmake limited use of suffix sequences, English andGerman, a model which hypothesizes multiplemorpheme boundaries can only moderately in-crease recall and does not justify, by F1, the manyincorrect segmentations which result.
On the otherhand, an agglutinative model significantly im-proves recall for true agglutinative languages likeFinnish and Turkish, more than compensating in F1for the drop in precision over these languages.
Butin all four languages, the agglutinative version ofParaMor outperforms the baseline unenhanced ver-sion at F1.The final row of Table 2 is the evaluation of areference algorithm submitted by Tepper (2007).While not an unsupervised algorithm, Tepper?sreference parallels ParaMor in augmenting seg-mentations produced by Morfessor.
Where Pa-raMor augments Morfessor with special attentionto inflectional morphology, Tepper augments Mor-fessor with hand crafted morphophonology rulesthat conflate multiple surface forms of the sameunderlying suffix.
Like ParaMor, Tepper?s algo-rithm significantly improves on Morfessor?s recall.With two examples of successful system augmen-tation, we suggest that future research take a closerlook at building on existing unsupervised mor-phology induction systems.The IR EvaluationTurn now to results from the IR evaluation in Ta-ble 3.
Although ParaMor does not fair as well inFinnish, in German, the fully enhanced version ofParaMor places above the best system from the2007 Challenge, Bernhard, while our score onEnglish rivals this same best system.
Morpho Chal-lenge 2007 did not measure the statistical signifi-cance of uninterpolated average precision scores inthe IR evaluation.
It is not clear what feature of Pa-raMor?s Finnish analyses causes comparativelylow average precision.
Perhaps it is simply that Pa-raMor attains a lower morpheme recall over Fin-nish than over English or German.
And unfortu-nately, Morpho Challenge 2007 did not run IR ex-periments over the other agglutinative language inthe competition, Turkish.
When ParaMor does notcombine multiple morpheme boundaries into a sin-gle analysis, as in the baseline and ?+P ?Seg?
sce-Table 2.
Unsupervised morphology induction systems evaluated for precision (P), recall (R), and F1 at morphemeidentification using the methodology of the linguistic competition of Morpho Challenge 2007.English German Finnish TurkishP R F1 P R F1 P R F1 P R F1+P +Seg 50.6 63.3 56.3 49.5 59.5 54.1 49.8 47.3 48.5 51.9 52.1 52.0+P ?Seg 56.2 60.9 58.5 57.4 53.5 55.4 60.5 33.9 43.5 62.0 38.2 47.3ParaMor&MorfessorBaseline 41.6 65.1 50.7 51.5 55.6 53.4 55.0 35.6 43.2 53.2 41.6 46.7Bernhard 61.6 60.0 60.8 49.1 57.4 52.9 59.7 40.4 48.2 73.7 14.8 24.7Bordag 59.7 32.1 41.8 60.5 41.6 49.3 71.3 24.4 36.4 81.3 17.6 28.9Morfessor 82.2 33.1 47.2 67.6 36.9 47.8 76.8 27.5 40.6 73.9 26.1 38.5Zeman 53.0 42.1 46.9 52.8 28.5 37.0 58.8 20.9 30.9 65.8 18.8 29.2Tepper 69.2 52.6 59.8 - - - 62.0 46.2 53.0 70.3 43.0 53.356narios, average precision is comparatively poor.Where the linguistic evaluation did not always pe-nalize a system for proposing multiple partialanalyses, real NLP applications, such as IR, can.The reference algorithms for the IR evaluationare: Dummy, no morphological analysis; Oracle,where all words in the queries and documents forwhich the linguistic answer key contains an entryare replaced with that answer; Porter, the standardEnglish Porter stemmer; and Tepper describedabove.
While the hand built Porter stemmer stilloutperforms the best unsupervised systems on Eng-lish, these same best unsupervised systems outper-form both the Dummy and Oracle references for allthree evaluated languages?strong evidence thatunsupervised induction algorithms are not onlybetter than no morphological analysis, but that theyare better than incomplete analysis as well.4 Conclusions and Future DirectionsAugmenting ParaMor with an agglutinative modelof segmentation produces an unsupervised mor-phology induction system with consistent andstrong performance at morpheme identificationacross all four languages of Morpho Challenge2007.
By first cleaning up the paradigm modelsthat ParaMor learns, we raise ParaMor?s segmenta-tion precision and allow the agglutinative model tosignificantly improve ParaMor?s morpheme recall.Looking forward to future improvements, weexamined by hand the final set of scheme clustersthat the current version of ParaMor produces overour newswire corpus of 50,000 Spanish types.
Pa-raMor?s paradigm identification stage outputs 41separate clusters.
Among these final scheme clus-ters are those which model all major productiveparadigms of Spanish.
In fact, there are often mul-tiple scheme clusters which model portions of thesame true paradigm.
As an extreme case, 12 sepa-rate scheme clusters contain suffixes from theSpanish ar verbal paradigm.
Relaxing restrictionson ParaMor?s clustering algorithm (Monson et al,2007a) may address this paradigm fragmentation.The second significant shortcoming which sur-faces among ParaMor?s 41 final scheme clusters isthat ParaMor currently does not address morpho-phonology.
Among the final scheme clusters, 12attempt to model morphophonological change byincorporating the phonological change either intothe stems or into the suffixes of the scheme cluster.But ParaMor currently has no mechanism for de-tecting when a cluster is modeling morphophonol-ogy.
Perhaps ideas on morphophonology fromGoldsmith (2006) could be adapted to work withthe ParaMor algorithm.
Finally, we plan to look atscaling the size of the vocabulary used both duringparadigm induction and during morpheme segmen-tation.
We are particularly interested in the possi-bility that ParaMor may  be able to identify para-digms from much less data than 50,000 types.AcknowledgementsWe kindly thank Mikko Kurimo, Ville Turunen,Matti Varjokallio, and the full Organizing Com-mittee of Morpho Challenge 2007, for running theevaluations of ParaMor.
These dedicated workersproduced impressively fast turn around for evalua-tions on sometimes rather short notice.The research described in this paper was sup-ported by NSF grants IIS-0121631 (AVENUE) andIIS-0534217 (LETRAS), with supplemental fund-ing from NSF?s Office of Polar Programs and Of-fice of International Science and Education.Table 3.
Unsupervised morphology induction sys-tems evaluated for uninterpolated average precisionusing the methodology of the IR competition ofMorpho Challenge 2007.
These results use Okapiterm weighting (Kurimo et al, 2008b).
*Only a subset of the words which occurred in theIR evaluation of this language was analyzed by thissystem.Eng.
Ger.
Finn.
Tur.+P +Seg 39.3 48.4 42.6 -+P ?Seg 35.1 43.1 37.1 -ParaMor&MorfessorBaseline 34.4 40.1 35.9 -Bernhard 39.4 47.3 49.2 -Bordag 34.0 43.1 43.1 -Morfessor 38.8 46.0 44.1 -Zeman  26.7*  25.7*  28.1* -Dummy 31.2 32.3 32.7 -Oracle 37.7 34.7 43.1 -Porter 40.8 - - -Tepper  37.3* - - -57ReferencesBernhard, Delphine.
Simple Morpheme Labeling in Un-supervised Morpheme Analysis.
Working Notes forthe CLEF 2007 Workshop.
Budapest, Hungary, 2007.Bordag, Stefan.
Unsupervised and Knowledge-freeMorpheme Segmentation and Analysis.
WorkingNotes for the CLEF 2007 Workshop.
Budapest, Hun-gary, 2007.Brent, Michael R., Sreerama K. Murthy, and AndrewLundberg.
Discovering Morphemic Suffixes: A CaseStudy in MDL Induction.
The Fifth InternationalWorkshop on Artificial Intelligence and Statistics.Fort Lauderdale, Florida, 1995.Creutz, Mathias.
Induction of the Morphology of Natu-ral Language: Unsupervised Morpheme Segmenta-tion with Application to Automatic Speech Recogni-tion.
Ph.D. Thesis.
Computer and Information Sci-ence, Report D13.
Helsinki: University of Technol-ogy, Espoo, Finland, 2006.Demberg, Vera, Helmut Schmid, and Gregor M?hler.Phonological Constraints and Morphological Pre-processing for Grapheme-to-Phoneme Conversion.Association for Computational Linguistics.
Prague,Czech Republic, 2007.Dryer, Matthew S. Prefixing vs. Suffixing in Inflec-tional Morphology.
In The World Atlas of LanguageStructures.
Eds.
Martin Haspelmath, Matthew S.Dryer, David Gil, and Bernard Comrie.
2005.Goldsmith, John.
Unsupervised Learning of the Mor-phology of a Natural Language.
Computational Lin-guistics.
27.2:153-198.
2001.Goldsmith, John.
An Algorithm for the UnsupervisedLearning of Morphology.
Natural Language Engi-neering.
12.4:335-351.
2006.Goldsmith, John, and Yu Hu.
From Signatures to FiniteState Automata.
Paper presented at the MidwestComputational Linguistics Colloquium.
Blooming-ton, Indiana, 2004.Goldwater, Sharon, and David McClosky.
ImprovingStatistic MT through Morphological Analysis.
Em-pirical Methods in Natural Language Processing.Vancouver, Canada, 2005.Hafer, Margaret A. and Stephen F. Weiss.
Word Seg-mentation by Letter Successor Varieties.
InformationStorage and Retrieval, 10:371-385.
1974.Harris, Zellig.
From Phoneme to Morpheme.
Language31.2:190-222.
1955.
Reprinted in Harris (1970).Harris, Zellig.
Papers in Structural and Transforma-tional Linguists.
Ed.
D. Reidel, Dordrecht.
1970.Johnson, Howard, and Joel Martin.
UnsupervisedLearning of Morphology for English and Inuktitut.Human Language Technology Conference / NorthAmerican Chapter of the Association for Computa-tional Linguistics.
Edmonton, Canada, 2003.Kurimo, Mikko, Mathias Creutz, and Matti Varjokallio.Unsupervised Morpheme Analysis Evaluation by aComparison to a Linguistic Gold Standard ?
MorphoChallenge 2007.
Working Notes for the CLEF 2007Workshop.
Budapest, Hungary, 2007a.Kurimo, Mikko, Mathias Creutz, and Ville Turunen.Unsupervised Morpheme Analysis Evaluation by IRExperiments ?
Morpho Challenge 2007.
WorkingNotes for the CLEF 2007 Workshop.
Budapest, Hun-gary, 2007b.Kurimo, Mikko, Mathias Creutz, and Matti Varjokallio.Unsupervised Morpheme Analysis -- Morpho Chal-lenge 2007.
January 10, 2008.
<http://www.cis.hut.-fi/morphochallenge2007/>.
2008.Monson, Christian, Jaime Carbonell, Alon Lavie, andLori Levin.
ParaMor: Minimally Supervised Induc-tion of Paradigm Structure and MorphologicalAnalysis.
Computing and Historical Phonology: TheNinth Meeting of the ACL Special Interest Group inComputational Morphology and Phonology.
Prague,Czech Republic, 2007a.Monson, Christian, Jaime Carbonell, Alon Lavie, andLori Levin.
ParaMor: Finding Paradigms acrossMorphology.
Working Notes for the CLEF 2007Workshop.
Budapest, Hungary, 2007b.Schone, Patrick, and Daniel Jurafsky.
Knowledge-FreeInduction of Inflectional Morphologies.
NorthAmerican Chapter of the Association for Computa-tional Linguistics.
Pittsburgh, Pennsylvania, 2001.Snover, Matthew G. An Unsupervised Knowledge FreeAlgorithm for the Learning of Morphology in NaturalLanguages.
M.S.
Thesis.
Computer Science, SeverInstitute of Technology, Washington University,Saint Louis, Missouri, 2002.Tepper, Michael A.
Using Hand-Written Rewrite Rulesto Induce Underlying Morphology.
Working Notesfor the CLEF 2007 Workshop.
Budapest, Hungary,2007.Wicentowski, Richard.
Modeling and Learning Multi-lingual Inflectional Morphology in a Minimally Su-pervised Framework.
Ph.D. Thesis.
Johns HopkinsUniversity, Baltimore, Maryland, 2002.Zeman, Daniel.
Unsupervised Acquiring of Morpho-logical Paradigms from Tokenized Text.
WorkingNotes for the CLEF 2007 Workshop.
Budapest, Hun-gary, 2007.58
