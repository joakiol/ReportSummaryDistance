A cross-comparison of two clustering methodsOlivier FerretCEA SaclayDTI/SITI91191 Gif-sur-Yvette Cedexferret@sphinx.cea.frBrigitte grau and Miche`le JardinoLIMSI CNRSBP13391403 Orsay, Francebg,jardino@limsi.frAbstractMany Natural Language Processing ap-plications require semantic knowledgeabout topics in order to be possible or tobe efficient.
So we developed a system,SEGAPSITH, that acquires it automat-ically from text segments by using anunsupervised and incremental cluster-ing method.
In such an approach, animportant problem consists of the vali-dation of the learned classes.
To do that,we applied another clustering method,that only needs to know the numberof classes to build, on the same sub-set of text segments and we reformu-late our evaluation problem in compar-ing the two classifications.
So, we es-tablished different criteria to comparethem, based either on the words as classdescriptors or on the thematic units.Our first results lead to show a greatcorrelation between the two classifica-tions.1 IntroductionAmong all the applications in Natural LanguageProcessing (NLP), many require semantic knowl-edge about topics in order to be possible or tobe efficient.
These applications are, for exam-ple, topic segmentation and identification or textclassification.
As this kind of knowledge is noteasy to build manually, we developed a system,SEGAPSITH (Ferret and Grau, 1998a), (Fer-ret and Grau, 1998b), to acquire it automatically.In this field, there are two classes of approaches.Supervised learning that requires to know a pri-ori which topics have to be learned and to pos-sess a tagged corpus as a learning set.
It is theapproach generally adopted by the different sys-tems, as those participating to TREC or TDT.However, we wanted to design a system allow-ing us to work in open domain, without any re-striction about the subjects to be represented and,thus, to be recognized in texts.
SEGAPSITHis grounded on an unsupervised and incrementallearning based on a conceptual clustering method.After a thematic segmentation of the texts thatdivides a text in segments made of lemmatizedwords, i. e. thematic units, the system aggregatessimilar enough thematic units.
Aggregation con-sists of regrouping all the words of the differentsimilar units and associating to them a weight ac-cording to their occurrence number.
This weightrepresents the importance of a word relative to thedescribed topic.
The incremental aspect allows usto augment topic knowledge by treating succes-sive corpora without reconsidering the knowledgealready existing.In such an approach, an important problemconsists of the validation of the learned classes.As we do not possess an existing classifica-tion that agrees with the granularity level of ourclasses, we decided to accomplish this evaluationby using a second classification method on thesame data and by comparing their results.
Thissecond method is an entropy-based method, andrequires to know the number of classes to form.So, if both results are similar enough, althoughthe methods applied are different, we could con-clude that the learned classes are quite relevantand that the two methods are efficient.After applying the second method, we pos-sess two sets composed by the same number ofclasses.
Each class regroups thematic units andis described by a set of words.
So, we establisheddifferent criteria to compare them, based either onthe words as class descriptors or on the thematicunits they gather.
After the presentation of thetwo methods, we shall present our tests and thefirst results we obtained.2 Semantic domain learningThis description aims at showing the data used forlearning, and the specificity of the learned classes.2.1 The thematic segmentation:SEGCOHLEXStudied texts are newspaper articles coming fromtwo corpora: ?Le Monde?
and ?AFP?.
Some ofthese texts have been used to build a lexical net-work where links between two words represent anevaluation of their mutual information to capturesemantic and pragmatic relations between them,computed from their co-occurrence count.
In or-der to build class of words linked to a same topic,we first realize a topic segmentation of the textsin thematic units (TU) whose words refer to thesame topic, and learning is applied on these the-matic units.Text segmentation is based on the use of thecollocation network.
A topic is detected by com-puting a cohesion value for each word resultingfrom the relations found in the network betweenthese words and their neighbors in a text.
As inKozima?s work (Kozima, 1993), this computa-tion operates on words belonging to a focus win-dow that is moved all over the text.The cohe-sion values lead to build a graph and by succes-sive transformations applied to it, texts are auto-matically divided in discourse segments.
Such amethod leads to delimit small segments, whosesize is equivalent to a paragraph, i. e. capa-ble of retrieving topic variations in short texts,as newswires for example.
Table 1 shows an ex-tract of the words belonging to a cohesive seg-ment about a dedication of a book.2.2 Semantic Domain learning inSEGAPSITHLearning a semantic domain consists of aggre-gating all the most cohesive thematic units, TUs,that are related to a same subject, i. e. a samekind of situation.
We only retain segments whosecohesion value is higher than a threshold, in or-der to ground our learning on the more reliableunits.
Similarity between a thematic unit anda semantic domain is evaluated from their com-mon words.
When the similarity value exceeds athreshold, the thematic unit is aggregated to thesemantic domain, otherwise a new domain is cre-ated.
Each aggregation of a new thematic unit in-creases the system?s knowledge about one topicby reinforcing recurrent words and adding newones.
Weights on words represent their impor-tance relative to the topic and are computed fromthe number of occurrences of these words in theTUs.Units related to a same topic are found in dif-ferent texts and often develop different points ofview of a same type of subject.
To ensure a bettersimilarity between them, SEGAPSITH enrichesa particular description given by a text segmentby adding to these units those words of the collo-cation network that are particularly linked to thewords found in the segment.
Table 2 gives an ex-tract of the words added to the segment of Table1.This method leads SEGAPSITH to learn spe-cific topic representations (see Table 3) as op-posed to (Lin, 1997) for example, whose methodbuilds general topic descriptions as for economy,sport, etc.
Moreover, it does not depend on any apriori classification of the texts.We applied the learning module of SEGAP-SITH on one month (May 1994) of AFPnewswires, corresponding to 7823 TUs.
In ourexperiments (Ferret and Grau, 1998a), (Ferretand Grau, 1998b), we showed that domains reacha stability at 15 to 20 aggregations, and that wordshaving a weight below 0.1 are rarely related to thedomain.
Thus, we only selected domains result-ing from at least 15 aggregations for our cross-comparison, i.e.
71 domains regrouping 4935TUs and 4380 words having a weight upon 0.1.A lot of domains share common words, and areclose enough to be considered as different repre-sentations of specific points of view of a generaltopic, as economy, sport, etc.3 Entropy-based clusteringThe second clustering method gives an optimalpartition of the 4935 thematic units in 71 non-words weight words weightstrider 0.683 entourer (to surround) 0.368toward 0.683 signature (signature) 0.366de?dicacer (to dedicate) 0.522 exemplaire (exemplar) 0.357apposer (to append) 0.467 page (page) 0.332pointu (sharp-pointed) 0.454 train (train) 0.331relater (to relate) 0.445 centaine (hundred) 0.330boycottage (boycotting) 0.436 sentir (to feel) 0.328autobus (bus) 0.435 livre (book) 0.289enfoncer (to drive in) 0.410 personne (person) 0.267Table 1: Extract of a segment about a dedicationinferred words weight inferred words weightparaphe (paraph) 0.522 imprimerie (press) 0.418presse parisien (parisian-press) 0.480 e?diter (to publish) 0.407best seller (best seller) 0.477 biographie (biography) 0.406maison d?e?dition (publishing house) 0.450 librairie (bookshop) 0.405libraire (bookseller) 0.447 poche (pocket) 0.389tome (tome) 0.445 e?diteur (publisher) 0.363Grasset (a publisher) 0.440 lecteur (reader) 0.355re?e?diter (to republish) 0.428 israe?lien (Israeli) 0.337parution (appearance) 0.427 e?dition (publishing) 0.333Table 2: Extract of words selected in the collocation network for the segment of Table 1words occurrences weightjuge d?instruction (examining judge) 58 0.501garde a` vue (police custody) 50 0.442bien social (public property) 46 0.428inculpation (charging) 49 0.421e?crouer (to imprison) 45 0.417chambre d?accusation (court of criminal appeal) 47 0.412recel (receiving stolen goods) 42 0.397pre?sumer (to presume) 45 0.382police judiciaire (criminal investigation department) 42 0.381escroquerie (fraud) 42 0.381Table 3: The most representative words of a domain about justiceoverlapping clusters according to the word dis-tributions in the units.
It is realized with an al-gorithm which looks like K-means (here K=71).Each cluster is the merge of several thematic unitsand is represented by its centroid.
We searchfor the partition which minimizes the Kullback-Leibleir divergence (Cover and Thomas, 1991)between the word distributions of the thematicunits and those of of their centroids.
This entropy-based measure is convex (Jardino, 2000), this pro-priety permits to get an optimal partition whateverthe initial conditions.3.1 EntropyWe assume that each thematic unit is representedby one quantitative vector whose components arethe relative occurrences of a selection of words re-lated to the unit.
The advantages of this normal-ization is that the representation of the thematicunits does not depend on the length of the unitsand can be modelized in the frame of the infor-mation theory (Cover and Thomas, 1991).Assuming that Ow;tuis the occurrence of theword labelled w in the thematic unit labelled tuand that Otuis the occurrence of all the words inthe thematic unit tu, such that Otu=PwOw;tu,each thematic unit vector component , p(w=tu),is :p(w=tu) =Ow;tuOtu(1)When the thematic units are unclassed, theirentropy is given by (Cover and Thomas, 1991):HTU=  Xw;tup(w; tu)  ln[p(wjtu)] (2)with p(w; tu) = Ow;tuPw;tuOw;tuWhen the thematic units are gathered in K clus-ters, labelled k, the cluster entropy is, HK:HK=  Xw;kp(w; k)  ln[p(wjk)] (3)where p(wjk) is defined as :p(wjtu 2 k) = p(wjk) =Ow;kOk(4)with Ow;k=Ptu2kOw;tu, Ok=Ptu2kOtuandp(w; k) =Ow;kPw;kOw;kThe cluster entropy is always higher than orequal to the unit entropy (log-sum rule (Cover andThomas, 1991)), so that the Kullback-Leibleir di-vergence defined as:DKL= HK HTU(5)is always higher than or equal to 0.3.2 Clustering algorithmMinimizing the Kullback-Leibler divergenceamounts to minimize the entropy HKbecauseHTUdoes not depend on the clusters.The number of possible partitions is huge,roughly 493571.
We have observed that a randomsearch is faster than a systematic one (Jardino,2000), and we have used this paradigm to buildthe algorithm described below:1- Define a priori, K, the cluster number, hereK=71.2- Initialize: put all the thematic units in one clus-ter, calculate the entropy HK(equation 3).
Theremaining K-1 clusters are empty.3- Do the random selection of one thematic unitand of another cluster for this unit.4- Move the unit from its former cluster to the newrandomly selected one, calculate the new entropy.5- If the new entropy is lower, leave the unit in itsnew cluster, otherwise move it back to its initialcluster.6- Repeat 3 to 5 until there is no more change.The optimal clustering of the 4935 thematicunits in 71 clusters is performed on a workstation(SGI Indy) within twenty minutes.4 Comparing two classificationsWe established different criteria for comparingthe two classifications, based on the elementsused to describe the classes.
First, each class is aset of words with an occurrence number for eachof them; second it is also a set of thematic units.So, the comparison can be done along these twopoints of view.In order to evaluate the overlapping of theclasses of words, we applied each classifica-tion method on the two classification results:the classes of words resulting from the secondmethod are classified relative to the semantic do-mains.
For comparing the classes of TUs, we ap-plied the entropy measure on one hand to measurethe overlapping of the classes, and  and Manteltests on the other hand to evaluate the differencesin the repartition of all the TUs.4.1 The word point of view4.1.1 Classification by similarityThe classification of the clusters relative to thesemantic domains exploits the same similaritymeasure than the one used for the learning phase.In a first step, some domains are selected accord-ing to the value of the activ function:activ(d) =XiWd;iWc;i(6)where Wd;iis the weight of the word i in thesemantic domain d and Wc;iis the weight of thesame word in the cluster c. This first step wasused in the learning phase because the number ofsemantic domains was increasing rapidly and thismeasure leads to a first fast selection of interestingdomains before evaluating an in-depth similarity.We kept this step, even if it was not necessary,in order to apply exactly the same method in theevaluation phase.
Afterwards, each selected do-main can be compared to the cluster by using thesimilarity measure given below.
If one of thesesimilarity values is greater than a given threshold,fixed to 0.25 in our tests, the cluster is linked tothe domain that is the most similar to it.
The sim-ilarity measure is:sim(d; c) =4rPwWd;wPtWd;tPwOd;wPtOd;tPwWc;wPtWc;tPwOc;wPtOcl;t(7)where the w index is used for indicating com-mon words between the cluster c and the seman-tic domain d and the t index, for indicating allthe words of the cluster or the domain.
W is theweight of a word and O its occurrence number.The similarity measure is only based on thecommon words.
As learning is unsupervised andincremental, differences at time t might disappearat time t+1.
The comparison is based on the pro-portion of common words relative to the total ofwords of each entity to be compared.
The evalu-ation of the common words in each entity is doneaccording to their occurrence number and theirweight.
So, we avoid to obtain a high similarityvalue between two entities that only share veryfew words having a high weight.
We combinethese criteria in a geometrical mean for evaluatingeach entity and for computing the global similar-ity from the evaluation of the two entities in orderto smooth the effect of few recurrent words whenthe domains are in their formation phase, wordsthat would act as attractors otherwise.4.1.2 Entropy-based classificationFor each of the 71 clusters, we have searchedfor the nearest domain obtained with the samekind of entropy-based measure defined above.
Weassume that we have a probabilistic model whichgives the predictions of the words according to thedomains.
In order to avoid the null value, non-learned events are infered using the Witten-Bellinterpolation (Witten and Bell, 1991).
The inter-polated value of the prediction of a word w, know-ing the domain d is p0(wjd) such that:p0(wjd) =O(w; d) + nsw(d)=VO(d) + nsw(d)(8)where nsw(d) is the number of words seen in eachdomain and V the size of the vocabulary.
Eachcluster is also defined by a set of words and wecompare the distribution of the words in the clus-ter with the distributions of the words in the do-mains (equation 8) with the Kullback-Leibler di-vergence.
Each cluster is associated with the near-est domain.4.1.3 ComparisonThe results of the two classifications describedabove are given in Table 4.
For the similarity-based classification, only 3 clusters do not matchwith any domain and 47 different domains are se-lected for the 68 remaining clusters with 34 linksthat are one cluster-one domain.
For the entropy-based classification, 44 clusters have been associ-ated to the 71 domains.Several clusters are linked to the same domain.This can been explained by the closeness of someof the domains.
This is shown when they are hi-erarchically classified; we obtain then 34 generaldomains that regroup 1 to 5 domains each.
Wealso observe that most clusters are only linked toone domain.
The two methods give almost thesame results and show that the two classificationsare similar.domain)cluster links linkslink (similarity) (entropy)no link 31!1 34 291!2 8 81!3 3 41!4 1 21!5 11!6 1Table 4: Number of links between one domainand the clusters4.2 The TU point of view4.2.1 A simple comparisonOne domain and one cluster are associated toeach thematic unit.
It is then possible to calcu-late the number of domains and clusters whichpartially or fully overlap.
Table 5 represents theintersection between the two partitions.
For eachdomain we chose the cluster which has the highestintersection with the domain.
Then we calculatedthe percentage of thematic units of this domainwhich are both in the domain and in this chosencluster.coverage number of clusterscov=100% 880%cov?100% 1660%cov?80% 1940%cov?60% 1920%cov?40% 8cov<20% 1Table 5: Coverage rates of UT which are commonto each domain and those of the associated clus-ters which correspond to the highest intersectionHeight domains are identical to height clusters.The lowest coverage (18%) is obtained for onedomain.
The other seventy domains cover morethan 20% of the clusters.4.2.2 Comparison with the  coefficientIn order to compare more precisely our twoclassifications, we used the  coefficient as it wasdone by Dietterich in (Dietterich, 2000) and as itis often done in the field of remote sensing for ex-ample.
The  coefficient measures the degree ofagreement among several judgements and is ex-pressed as follows:k =1  21  2(9)where 1is the proportion of times that thejudgments agree and 2is the proportion of timesthat we could expect the judgments to agree bychance.
As we are in a case of unsupervised clas-sification whereas Dietterich?s work was aboutsupervised classification (building of decisiontrees), we have first set a one-to-one mappingbetween the semantic domains and the clusters.This was done by a very simple procedure: wecomputed the size of the intersection betweeneach cluster and each domain; then we iterativelymapped the cluster and the domain that had thelargest intersection until each cluster was mappedwith a domain.
Of course, this is not an optimalprocedure in order to ensure that the intersectionof each couple of classes is the largest one but itcan be considered as a baseline.Then, the evaluation of the  coefficient wasdone by building a matrix K  K, with K, thenumber of classes (clusters or domains), such thateach element ki;jis equal to the number of TUsassigned to the class i by SEGAPSITH and to theclass j by the entropy-based clustering.
1, whichestimates the probability that the two classifica-tions agree, is defined by:1=PKi=1ki;iN(10)where N is the total number of TUs.
It eval-uates the proportion of TUs that were put in thesame classes by the two clustering algorithms.2, which estimates the probability that the twoalgorithms agree by chance, is given by:2=KXi=1(ki+Nk+iN) (11)where k+iNand ki+Nare the marginal distribu-tions.The  coefficient that results from the evalu-ation of 1and 2is equal to 0 when the twoclustering algorithms agree only by chance andto 1 when they really agree for each TU.
Negativevalues occur when there is a systematic disagree-ment.For the 71 classes of our test set, we computedthe  coefficient in two cases.
First, with a ran-dom mapping of the clusters and domains.
Wegot K = -0.013, which is very close to the agree-ment by chance.
Second, we applied the abovemapping procedure and got K = 0.484, which in-dicates a significant correlation between the twoclassifications.
We think that with a more com-plex mapping procedure, the  would be higher.4.2.3 Application of the Mantel TestIn this paradigm, each classified thematic unit,tu, is described according to its position in theclassification in relation to all the classified el-ements.
This position is characterized by a dis-tance between tu and each other element.
In thework we present here, we choose a simple dis-tance: dist(tu1; tu2) = 0 if tu1and tu2are partof the same class; otherwise, dist(tu1; tu2) = 1.However more complex distances may be usedwhen the classifications are hierarchical ones forexample.
After this first step, each tuiof the twoclassifications to compare is characterized by avector, each element of which, dij, is equal tothe distance between tuiand tuj.
Hence, eachclassification is characterized by a distance ma-trix, which is a square symmetric matrix of sizeN2= 49352.
Comparing the two classifica-tions amounts to compare their distance matrices.In the ecology field, such kind of comparison isachieved by a statistical test, called the Manteltest (Mantel, 1967).
In (Legendre, 2000), Legen-dre defines the Mantel test as ?
a procedure to testthe hypothesis that the distances among objectsin a matrix A are linearly independent of the dis-tances among the same objects in another matrixB.
The result of this test may be used as supportfor or against the hypothesis that the process thatgenerated the first set of distances is independentof the process that generated the second set.
Theunique feature of the Mantel test is the use of alinear statistic to assess the relationship betweentwo distance matrices?.
The basic statistic used inthe Mantel test is the Z statistic:ZS =i=NXi=1j=NXj=1xijyijAs the elements of a distance matrix are not in-dependent, the significance of ZS, the Z statisticthat is computed for the two distance matrices tocompare, is evaluated by comparing this value tothe Z statistic that is computed for matrices whoserows and columns are randomly permuted.
A dis-tribution of random values is obtained by comput-ing the statistic for many permuted matrices andif ZS is significantly above this distribution, thehypothesis that the two matrices are independentis rejected 1.1The Z statistic is maximal when the two distance matri-ces are identical: the xijyijterm is not equal to zero only ifxijand yijare equal to 1.
Hence, each difference that couldbe introduced between the two matrices, decreases its value.As an exploratory step, we applied the Man-tel test in order to compare the results of the twoclassification methods we presented in this arti-cle.
We used the software developed by AdamLiedloff (Liedloff, 1999).
As the number ofTUs is too large in comparison with the capabil-ities of this software, we experimented the Man-tel test only on a subset of 1000 TUs.
With thedistance matrix computed from the results of thetwo classification methods, we got a Z statistic(ZS) equal to 940; 894.
The maximum value ofZS is 978; 460 for the domains and 948; 608 forthe clusters.
The random distribution was builtfrom 99 permuted matrices and its ZS value is937; 708  232.
As the proportion of the val-ues from the random distribution that are aboveZS is equal to zero, we can reject the hypothe-sis that the two matrices are independent and as aconsequence, we can think that the two comparedclassifications are globally similar.
However, asthe results of the Mantel test are not easy to inter-pret, further tests must be performed to see whatare the relations between these results and thoseof the other comparing methods and to determineif this test is actually suited for comparing suchkind of classifications.5 ConclusionWe presented in this paper an approach for eval-uating the results of an unsupervised learningmethod, when no human evaluation is possible orwhen no classification exists as a reference.
Asa result, this method builds classes of weightedwords that regroup thematic units.
We definedin a previous work a stability threshold of theseclasses, thus we aim at evaluating this subset ofclasses.
To do that, we applied another clusteringmethod that only needs to know the number ofclasses to build on the same subset of TUs and wereformulate our evaluation problem in comparingthe two classifications.
Our first results lead toshow a great correlation between the two results.We now have to develop other tests, for exam-ple on a different number of classes, to verify ourfirst results.
A second step will be to evaluate themethods on the same task, as a classification taskfor example, whose protocol has to be defined.ReferencesT.
Cover and J. Thomas.
1991.
Elements of Informa-tion Theory.
Wiley & sons, New York.T.
G. Dietterich.
2000.
An experimental comparisonof three methods for constructing ensembles of de-cision trees: Bagging, boosting, and randomization.Machine Learning, 40:139?158.O.
Ferret and B. Grau.
1998a.
A thematic segmen-tation procedure for extracting semantic domainsfrom texts.
In ECAI, Brighton, UK.O.
Ferret and B. Grau.
1998b.
Structuration d?unre?seau de cooccurrences lexicales en domaines se?-mantiques par analyse de textes.
In NLPIA, Monc-ton, Canada.M.
Jardino.
2000.
Unsupervised non-hierarchicalentropy-based clustering.
In H.A.L.Kiers, J.-Rasson, P.J.F.Groenen, and M.Schader, editors,Data Analysis, Classification, and Related Meth-ods.
Springer.H.
Kozima.
1993.
Text segmentation based on sim-ilarity between words.
In ACL (Student Session),Ohio, USA.P.
Legendre.
2000.
Comparison of permutation meth-ods for the partial correlation and partial correla-tion and partial mantel tests.
Statistical Computa-tion and Simulation, 67:37?73.Liedloff.
1999.
Mantel nonparametric test calculator.http://www.sci.qut.edu.au/nrs/mantel.htm.C.-Y.
Lin.
1997.
Robust Automated Topic Identifica-tion.
Ph.D. thesis, University of Southern Califor-nia.N.
Mantel.
1967.
The detection of disease cluster-ing and a generalized regression approach.
CancerRes., 27:209?220.I.T.
Witten and T.C.
Bell.
1991.
The zero-frequencyproblem: estimating the probabilities of novelevents in adaptative text compression.
IEEE Trans-actions on Information Theory, 37(3):1085?1094.
