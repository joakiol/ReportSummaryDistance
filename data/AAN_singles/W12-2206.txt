NAACL-HLT 2012 Workshop on Predicting and Improving Text Readability for target reader populations (PITR 2012)., pages 40?48,Montre?al, Canada, June 7, 2012. c?2012 Association for Computational LinguisticsMaking Readability Indices ReadableSara TonelliFBK, Trento, Italysatonelli@fbk.euKe Tran ManhCharles University, Prague, CRketranmanh@gmail.comEmanuele PiantaFBK, Trento, Italypianta@fbk.euAbstractAlthough many approaches have been pre-sented to compute and predict readability ofdocuments in different languages, the infor-mation provided by readability systems oftenfail to show in a clear and understandable wayhow difficult a document is and which aspectscontribute to content readability.
We addressthis issue by presenting a system that, for agiven document in Italian, provides not onlya list of readability indices inspired by Coh-Metrix, but also a graphical representationof the difficulty of the text compared to thethree levels of Italian compulsory education,namely elementary, middle and high-schoollevel.
We believe that this kind of represen-tation makes readability assessment more in-tuitive, especially for educators who may notbe familiar with readability predictions via su-pervised classification.
In addition, we presentthe first available system for readability as-sessment of Italian inspired by Coh-Metrix.1 IntroductionThe task of readability assessment consists in quan-tifying how difficult a text is for a reader.
This kindof assessment has been widely used for several pur-poses, such as evaluating the reading level of chil-dren and impaired persons and improving Web con-tent accessibility for users with low literacy level.While indices and methodologies for readabil-ity assessment of English have been widely investi-gated, and research on English readability has beencontinuously progressing thanks to advances in psy-cholinguistic research and in natural language pro-cessing, only limited efforts have been made to ex-tend current approaches to other languages.
Anadaptation of the basic Flesch Index (Flesch, 1946)exists for many languages, but only in few casesmore sophisticated approaches have been adopted,taking into account recent studies on text cohesion,readability and simplification.With this work, we aim at bridging the gap be-tween the standard approach to Italian readabilitybased on the Gulpease index (following the samecriteria of the Flesch Index) and the more advancedapproaches to readability currently available for En-glish and based on psycholinguistic principles.
Inparticular, we present a set of indices for Ital-ian readability covering different linguistics aspects,from the lexical to the discourse level, which are in-spired by Coh-Metrix (Graesser et al, 2004).
Wemake this analysis available online, but we differ-entiate our service from that of Coh-Metrix1 in thatwe provide a graphical representation of the aspectsaffecting readability, comparing a document withthe average indices of elementary, middle and high-school level texts.
This makes readability analysisreally intuitive, so that a user can straightforwardlyunderstand how difficult a document is, and see ifsome aspects (e.g.
lexicon, syntax, discourse) affectreadability more than others.Our research goals are: i) to analyze the adequacyof the Gulpease index for discriminating betweenthe readability levels of texts used for teaching andtesting in the Italian school practice, ii) to implementan adaptation of Coh-Metrix indices for Italian, iii)to make the readability analysis available online and1http://cohmetrix.memphis.edu40understandable to naive users.2 Related workThe first formulas to automatically compute the dif-ficulty of a text were devised for English, startingfrom the Flesch Index (Flesch, 1946), followed bythe Gunning Fog (Gunning, 1952), the SMOG index(McLaughlin, 1969) and the Fleisch-Kincaid (Kin-caid et al, 1975).
These metrics combine factors,such as word and sentence length, that are easy tocompute and that should approximate the linguisticelements that impact on readability.
Similar indexeshave been proposed also for other languages suchas German (Bamberger and Vanecek, 1984), French(Kandel and Moles, 1958) and Spanish (Huerta,1959).The first readability formula for Italian, theFlesch-Vacca (Franchina and Vacca, 1986), was in-troduced in the early seventies and was based on anadaptation of the Flesch index (Flesch, 1946).
How-ever, it has been widely replaced by the Gulpeaseindex (Lucisano and Piemontese, 1988), which wasintroduced in the eighties by the Gruppo Universi-tario Linguistico Pedagogico (GULP) of the Univer-sity of Rome.
The Gulpease index takes into accountthe length of a word in characters rather than in syl-lables, which proved to be more reliable for assess-ing the readability of Italian texts.
The index rangesfrom 0 (lowest readability) to 100 (maximum read-ability).In recent years, research on English readabilityhas progressed toward more sophisticated modelsthat take into account difficulty at syntactic, seman-tic and discourse level thanks to advances in psy-cholinguistic accounts of text processing (Graesseret al, 2004) and to the availability of a wide rangeof NPL tools (e.g.
dependency and constituencyparsers, anaphora resolution systems, etc.)
and re-sources (e.g.
WordNet).
However, for many otherlanguages current approaches for readability assess-ment still rely on few basic factors.
A notable ex-ception is the Coh-Metrix-PORT tool (Scarton et al,2009; Aluisio et al, 2010), which includes 60 read-ability measures for Brazilian Portuguese inspiredby the Coh-Metrix (Graesser et al, 2004).A different approach has been followed by the de-velopers of the DeLite system for German (Glo?ckneret al, 2006; von der Bru?ck et al, 2008): the toolcomputes a set of indices measuring the linguisticcomplexity of a document through deep parsing andoutputs a final readability score obtained by apply-ing the k-nearest neighbor algorithm based on 3,000ratings from 300 users.As for Italian, the only work aimed at improvingon the performance of standard readability indiceshas been proposed by Dell?Orletta et al (2011), whoimplement a set of lexical and morpho-syntactic fea-tures to distinguish between normal and simplifiednewspaper articles in a binary classification task.Our work differs from their approach in that wechoose a different type of corpus for a different au-dience (i.e.
children with different proficiency levelsvs.
adults with low literacy skills or mild cognitiveimpairment).
We also enrich their feature set in thatour indices capture also semantic and discourse as-pects of a text.
In this respect, we take advantageof cognitive and psycholinguistic evidence support-ing the idea behind Coh-Metrix that high textual co-herence and cohesion result in improved readabilitywith any type of readers (Beck et al, 1984s; Cataldoand Oakhill, 2000; Linderholm et al, 2000), and thatdiscourse connectives and spatio-temporal informa-tion in a text strongly contribute to cohesion.3 The corpusOur goal is to develop a system that can be used inreal scenarios, for instance by teachers who want toassess if a text is understandable by children in acertain class.
Therefore, we avoid collecting a cor-pus with documents showing different degrees ofsimplification according to a ?controlled?
scenario.This strategy was adopted for instance by Crossleyet al (2011), who compared different readability in-dices using news texts manually simplified into ad-vanced, intermediate and beginning difficulty level.Also the experiments on readability assessment ofPortuguese texts by Scarton et al (2009) were con-ducted on a corpus of news articles manually simpli-fied by a linguist according to a natural and a strongsimplification level.Our approach is different in that we take textsused for teaching and comprehension exercises inItalian schools and divide them into three classes,according to the class level in which they are em-41Class 1 Class 2 Class 3(63 docs) (55 docs) (62 docs)Doc.
length 530 776 1085in tokens (?
273) (?
758) (?
1152)Gulpease 55.92 53.88 50.54(?
6.35) (?
6.13) (?
6.98)Table 1: Corpus statistics.
All values are averaged.
StDevis reported between parenthesis.ployed.
This means that in Class 1 we collectall documents written for children in elementaryschools (aged 6-10), in Class 2 we collect textsfor children in middle schools (aged 11-13), and inClass 3 we gather documents written for teenagersin high schools (aged 14-18).
The classes containrespectively 63, 55 and 62 documents.As shown in Table 1, the average length of thedocuments increases with the school level.
How-ever, the single documents show high variability,especially those in Class 3.
Texts have been se-lected so as to represent the most common genresand knowledge domains in school texts.
Thus, thecorpus contains a balanced selection of both narra-tive and expository texts.
The latter belong mostly tothe following domains: history, literature, biology,physics, chemistry, geography and philosophy.
Thecorpus includes also all official text comprehensiontests used in Italy in the INVALSI school proficiencyevaluation campaign2.4 Readability assessment based onGulpeaseWe first analyze the behaviour of the Gulpease in-dex in our corpus, in order to assess if this measureis adequate for capturing the readability of the doc-uments.
We compute the index by applying to eachdocument the standard formula:Gulpdoc = 89 +(300 ?
#sentsdoc) ?
(10 ?
#charsdoc)#tokensdocAverage Gulpease and standard deviation for eachclass are reported in Table 1.2National Institute for the Evaluation of the EducationalSystem by the Ministry of Research and University, http://www.invalsi.it/invalsi/index.phpFig.
1 shows the distribution of the Gulpease in-dex in the corpus.
On the x axis the document id isreported, with document 1?63 belonging to Class 1(elementary), document 64?118 to Class 2 (middle)and 119?180 to Class 3 (high school).
On the y axis,the Gulpease index is reported, ranging from 41 (i.e.the lowest readability level in the corpus) to 87 (i.e.highest readability).Although the highest readability score is obtainedby a document of Class 1, and the lowest scoresconcern documents in Class 3, the three classes donot seem to be separable based solely on Gulpease.In particular, documents in Class 2, written for stu-dents in middle school, show scores partly overlap-ping with Class 1 and partly with Class 3.
Further-more, the great majority of the documents in the cor-pus have a Gulpease index included between 50 and60 and the average Gulpease does not differ consis-tently across the three classes (Table 1).Figure 1: Distribution of Gulpease index in the corpus.Document id on x axis, and Gulpease on y axisFor children in the elementary school, a text witha Gulpease index between 0 and 55 usually corre-sponds to the frustration level.
For children in themiddle school, the frustration level is reached with aGulpease index between 0 and 35.
For high-schoolstudents, this level is reached with Gulpease beingbetween 0 and 10.33More information on how to interpret Gulpease for eachof the three classes is reported at http://www.eulogos.net/ActionPagina_1045.do424.1 Coh-Metrix for EnglishCoh-Metrix is a computational tool available on-line at http://cohmetrix.memphis.edu thatcan analyze an English document and produce a listof indices expressing the cohesion of the text.
Theseindices have been devised based on psycholinguisticstudies on the mental representation of textual con-tent (McNamara et al, 1996) and address variouscharacteristics of explicit text, from lexicon to syn-tax, semantics and discourse, that contribute to thecreation of this representation.
Although the tool re-lies on widely used NLP techniques such as PoS tag-ging and parsing, there have been limited attempts toemploy it in studies on automatic assessment of textcohesion.
Nevertheless, recent works in the NLPcommunity investigating the impact of entity grids(Barzilay and Lapata, 2008) or of discourse relations(Pitler and Nenkova, 2008) on text coherence andreadability go in the same direction as research onCoh-Metrix, in that they aim at identifying the lin-guistic features that best express readability at syn-tactic, semantic and discourse level.The indices belonging to Coh-Metrix are dividedinto five main classes:?
General Word and Text Information: The in-dices in this class capture the correlation be-tween brain?s processing time and word-levelinformation.
For example, many syllables in aword or many words in a sentence are likely tomake a document more difficult for the brain toprocess it.
Also, if the type/token ratio is high,the text should be more difficult because thereare many unique words to be decoded.?
Syntactic Indices: The indices in this class as-sess syntactic complexity and the frequency ofparticular syntactic constituents in a text.
Theintuition behind this class is that high syntacticcomplexity makes a text more difficult to pro-cess, lowering its readability, because it usuallyimplies syntactic ambiguity, structural density,high number of embedded constituents.?
Referential and Semantic Indices: These in-dices assess the negative impact on readabilityof cohesion gaps, which occur when the wordsin a sentence do not connect to other sentencesin the text.
They are based on coreference andanaphoric chains as well as on semantic simi-larity between segments of the same documentexploiting Latent Semantic Analysis (LSA).?
Indices for Situation Model Dimensions: Theindices in this class express the degree of com-plexity of the mental model evoked by a doc-ument (Dijk and Kintsch, 1983) and involvesfour main dimensions: causality, intentionality,time and space.?
Standard readability indices: They comprisetraditional indices for readability assessmentincluding Flesch Reading Ease and Flesch Kin-caid Grade Level.Although the developers of Coh-Metrix claim thatthe internal version of the tool includes hundreds ofmeasures, the online demo shows only 60 of them.This is partly due to the fact that some metrics arecomputed using resources protected by copyright,and partly because the whole framework is still un-der development.
We refer to these 60 metrics in or-der to implement the Coh-Metrix version for Italian,that we call Coease.4.2 Coease: Coh-Metrix for ItalianIn the Coh-Metrix adaptation for Italian, we followas much as possible the description of the single in-dices reported on the official Coh-Metrix documen-tation.
However, in some cases, not all implementa-tion details are given, so that we may have slightlydifferent versions of single indices.
Besides, oneset of indices is based on the MRC Psycholinguis-tic Database (Wilson, 2003), a resource includingaround 150,000 words with concreteness ratings col-lected through psycholinguistic experiments, whichis not available for Italian.
In general terms, how-ever, we try to have some indices for each of theclasses described in Section 4.1, in order to repre-sent all relevant aspects of text cohesion.The list of all indices is reported in Table 2.
In-dices from 1 to 6 capture some information about thelength of the documents in terms of syllables, words,sentences and paragraphs.
Syllables are computedusing the Perl module Lingua::IT::Hyphenate4.4http://search.cpan.org/?acalpini/Lingua-IT-Hyphenate-0.14/43Indices from 7 to 10 focus on familiarity of con-tent words (verbs, nouns, adjectives and adverbs)measured as their frequency in a reference corpus.While in English the frequency list was the CELEXdatabase (Baayen et al, 1995), for Italian we ex-tracted it from the dump of Italian Wikipedia5.
Theidea behind these indices is that unfamiliar words ortechnical terminology should have a low frequencyin the reference corpus, which is supposed to bea general corpus representing many domains.
In-dex 8 is the logarithm of raw frequency of contentwords, because logarithm proved to be compatiblewith reading time (Haberlandt and Graesser, 1985).Index 9 is obtained by computing first the lowest fre-quency score among all the content words in eachsentence, and then calculating the mean.
Index 10 isobtained by computing first the lowest log frequencyscore among all content words in each sentence, andthen calculating the mean.
Content words were ex-tracted by running the TextPro NLP suite for Italian(Pianta et al, 2008)6 and keeping only words taggedwith one of WordNet PoS, namely v, a, n and r.Indices 11 and 12 compute the abstractness ofnouns and verbs by measuring the distance betweenthe WordNet synset containing the lemma (most fre-quent sense) and the root.
Then, the mean distanceof all nouns and verbs in the text is computed.
Weobtain this index using MultiWordNet (Pianta et al,2002), the Italian version of WordNet, aligned atsynset level with the English one.Indices from 13 to 17 measure the syntactic com-plexity of sentences based on parsing output.
Indices13-15 are computed after parsing each sentence withthe Italian version of Berkeley constituency-basedparser (Lavelli and Corazza, 2009)7.
NP incidenceis the incidence of atomic NPs (i.e.
not containingany other NPs) per 1000 words.
Higher-level con-stituents index is the mean distance between eachterminal word in the text and the parse tree root.Main verb information needed for computing index16 is obtained by parsing each sentence with Maltparser for Italian (Lavelli et al, 2009) and taking thesentence root as main verb.
The index accounts for5http://it.wikipedia.org6TextPro achieved 95% PoS tagging accuracy at Evalita2009 evaluation campaign for Italian tools.7The parser achieved 84% F1 at Evalita 2011 evaluationcampaign for Italian tools.the memory load needed by a reader to understand asentence.
Index 17 is calculated by comparing eachtoken to a manual list of negations and computingthe total number of negations per 1000 words.Indices 18 and 19 are computed again usingTextPro and the output of Berkeley parser.
Index 18is the ratio of words labelled as pronouns to the in-cidence of all NPs in the text.
High pronoun densityimplies low readability, because it makes referentialcohesion less explicit.Indices from 20 to 29 capture the cohesion ofsentences by taking into account different types ofconnectives.
In order to compute them, we manu-ally create lists of connectives divided into additive,causal, logical and temporal.
Then, for each list, weidentify positive (i.e.
extending events) and negative(i.e.
ceasing to extend expected events) connectives.For instance, ?inoltre?
(?moreover?)
is a positive ad-ditive connective, while ?ma?
(?but?)
is a negative ad-ditive connective.
We further compute the incidenceof conditional operators by comparing each token toa manual list.
In order to create such lists, we stickto their English version by first translating them intoItalian and then manually adding some missing con-nectives.
However, this does not avoid ambiguity,since some connectives with high frequency can ap-pear in more than one list, for instance ?e?
(?and?
),which can be both temporal and additive.Indices 30 and 31 capture syntactic similarity ofsentences and are based on the assumption that adocument showing high syntactic variability is moredifficult to understand.
This index computes the pro-portion of intersecting nodes between two syntactictrees by looking for the largest common subtree, sothat every node except terminal node has the sameproduction rule in both trees.
Index 32 calculatesthe proportion of adjacent sentences that share atleast one argument expressed by a noun or a pro-noun, while indices 33 and 34 compute this propor-tion based on stems and content words.
Stems areobtained by applying the Snowball stemmer8 to thelemmatized documents.Indices 35?40 capture the situation model dimen-sions of the text.
Causal and intentional cohesioncorresponds to the ratio between causal or inten-tional particles (i.e.
connectives and adverbs) and8http://snowball.tartarus.org/44causal or intentional verbs.
The rationale behindthis is that a text with many causal verbs and fewcausal particles is less readable because the con-nections between events is not explicitly expressed.Since no details where given on how these particlesand verbs were extracted for English, we devise ourown methodology.
First, we produce manual listsof causal and intentional particles in Italian.
As forcausal verbs, we first select all synsets in the En-glish WordNet containing ?cause to?
in their glosses,and then obtain the corresponding version in Ital-ian through MultiWordNet.
Intentional verbs areobtained by first extracting all verbs from EnglishWordNet that belong to the following categories:cognition, communication, competition, consump-tion, contact, creation, emotion, motion and percep-tion, and then mapping them to the Italian corre-sponding verbs in MultiWordNet.
Temporal cohe-sion is computed as the average of repetitions oftense and aspect in the document.
Repetitions arecalculated by mapping the output of TextPro mor-phological analysis of verbs to the labels consideredfor tense, i.e.
past, present and future, and for as-pect, i.e.
static, completed and in progress.
Spa-tial cohesion reflects the extent to which the sen-tences are related by spatial particles or relations,and corresponds to the mean of location and mo-tion ratio score.
Location score is the incidence oflocative prepositions (LSP) divided by LPS plus theincidence of location nouns.
Location nouns are ob-tained from WordNet and from the Entity Recog-nizer of TextPro.
Motion score is the incidence ofmotion particles (MSP) divided by MSP plus the in-cidence of motion verbs.
Motion verbs informationis extracted from WordNet as well.
As for motionand locative particles, we first create a manual list,which however contains particles that can expressboth location and motion (for instance ?in?).
The dis-tinction between the two types of particles is basedon the dependency structure of each sentence: if theparticle is headed by a motion verb and dominatesa location noun, then we assume that it is a motionparticle.
Instead, if it heads a location noun but isnot dominated by a motion verb, then it is a locativeparticle.
We are aware of the fact that this selectionprocess is quite coarse-grained and can be biased bywrong dependency structures, ambiguity of nounsand verbs and limited extension of Italian WordNet.However, it is a viable solution to approximate theinformation conveyed by the corresponding indicesin English, given that no clear explanation for theirimplementation is given.4.3 Additional indicesWe implement also three additional indices that arenot part of Coh-Metrix for English.
They are re-ported in Table 2 with the ID 41?46.Indices 41 and 42 are based on the Basic Ital-ian Vocabulary (de Mauro, 2000).
This resourceincludes a list of 7,000 words, which were manu-ally classified as highly familiar to native speakers ofItalian.
We introduce these indices because past ex-periments on Italian readability by Dell?Orletta et al(2011) showed that, by combining this informationwith some basic features such as word and sentencelength, it was possible to achieve 0.95 accuracy ina binary classification task aimed at distinguishingstandard newspaper articles from simplified articlesfor L2 readers.
Index 41 corresponds to the percent-age of tokens whose base form is listed in the BasicItalian Vocabulary, while index 42 is the percentageof (unique) lemmas.
The latter is the same featureimplemented by Dell?Orletta et al (2011).Index 43 is Gulpease, computed following the for-mula reported in Section 4.
We add it to our in-dex list in line with Coh-Metrix, which includes alsostandard readability metrics such as Flesch-ReadingEase and Flesch-Kincaid.5 The Online SystemThe Coease indices have been made availableonline through a Web interface at http://readability.fbk.eu.
This allows users tocopy and paste a document in the text field and tocompute all available indices, similar to the func-tionalities of the English Coh-Metrix tool.
We havenormalized each index so that it is comprised be-tween -1 and +1 using the scaling function availablein LIBSVM (Chang and Lin, 2011).
Low scores ex-press low readability for the given index while highscores correspond to highly readable texts.In order to identify the indices that are most cor-related with the readability levels, we computedPearson correlation coefficients between each indexand the three classes, similar to Pitler and Nenkova45(2008).
The ten most correlated indices are markedwith (*) in Table 2.
It is interesting to note that 6out of 10 indices are not part of the standard Coh-Metrix framework, and account for lexical informa-tion.
In all cases, correlation is moderate, being0.3 ?
r ?
0.6.Figure 2: Graphical representation of readability as plot-ted by the Coease web interface.
Index id on x axis, andnormalized value on y axisCoease is designed in order to enable users tocompute readability of a given document and com-pare it with the average values for the three classes inour reference corpus (Section 3).
Therefore, the av-erage normalized score of each index for each classhas been computed based on the corpus.
Then, everytime a new document is analyzed, the output scoresare plotted together with the average scores for eachof the three classes.
This allows a user to comparedifferent aspects of the current document, such asthe lexicon or the syntax, with the averages of thethree classes.
For example, a user may discover thata document is highly complex from the lexical pointof view, since its lexical indices are in line with thoseof high-school texts.
However, its syntax may berather simple, having syntax-based indices similar tothose of elementary textbooks.
This kind of compar-ison provides information that are generally not cap-tured via supervised classification.
If we trained aclassifier using the indices as features, we would beable to assign a new document to elementary, mid-dle or high-school level, but a naive user would notbe able to understand how the single indices affectclassification.
Besides, this graphical representationallows a user to identify documents that should notbe classified into a specific class, because its indicesfall into different classes.
Furthermore, we can de-tect documents with different degrees of readabilitywithin each class.As an example, we report in Fig.
2 the graphicalrepresentation returned by the system after analyz-ing an article taken from ?Due Parole?9 (labeled as?current?
), an online newspaper for adult L2 learn-ers.
The scores are compared with the average val-ues of the 10 most correlated indices, which are re-ported on the x axis in the same order as they aredescribed in Table 2.
According to the plot, the ar-ticle has a degree of readability similar to the ?high-school?
class, although some indices show that itsreadability is higher (see for instance the index n. 9,i.e.
lexical overlap with Class 3 documents).The current system version returns only the 10most correlated indices for the sake of clarity.
How-ever, it easy configurable in order to plot all indices,or just a subset selected by the user.6 Conclusions and Future WorkWe present Coease, a system for readability assess-ment of Italian inspired by Coh-Metrix principles.This set of indices improves on Gulpease index inthat it takes into account discourse coherence, syn-tactic parsing and semantic complexity in order toaccount for the psycholinguistic and cognitive rep-resentations involved in reading comprehension.We make Coease available through an online in-terface.
A user can easily analyze a document andcompare its readability to three difficulty levels, cor-responding to average elementary, middle and high-school readability level.
The graphical representa-tion returned by the system makes this comparisonstraightforward, in that the indices computed for thecurrent document are plotted together with the 10most correlated indices in Coease.In the future, we will analyze the reason why lex-ical indices are among the most correlated ones withthe three classes.
The lower impact of syntactic in-formation, for instance, could be affected by parsingperformance.
However, this could depend also onhow syntactic indices are computed in Coh-Metrix:9http://www.dueparole.it/46we will investigate whether alternative ways to cal-culate the indices may be more appropriate for Ital-ian texts.In addition, we plan to use the indices as featuresfor predicting the readability of unseen texts.
In aclassification setting, it will be interesting to see ifthe 10 best indices mentioned in the previous sec-tions are also the most predictive features, given thatsome information may become redundant (for in-stance, the Gulpease index).AcknowledgmentsThe work described in this paper has been partiallyfunded by the European Commission under the con-tract number FP7-ICT-2009-5, Terence project.ReferencesSandra Aluisio, Lucia Specia, Caroline Gasperin, andCarolina Scarton.
2010.
Readability assessment fortext simplification.
In Proceedings of the NAACLHLT 2010 Fifth Workshop on Innovative Use of NLPfor Building Educational Applications, pages 1?9,Stroudsburg, PA, USA.R.
H. Baayen, R. Piepenbrock, and L. Gulikers.
1995.The CELEX Lexical Database (release 2).
CD-ROM.Richard Bamberger and Erich Vanecek.
1984.
Lesen-Verstehen-Lernen-Schreiben.
Jugend un Volk Verlags-gesellschaft.Regina Barzilay and Mirella Lapata.
2008.
Modelinglocal coherence: An entity-based approach.
Computa-tional Linguistics, 34:1?34, March.I.
L. Beck, M. G. McKeown, G. M. Sinatra, and J. A.Loxterman.
1984s.
Revisiting social studies textfrom a text-processing perspective: Evidence of im-proved comprehensibility.
Reading Research Quar-terly, 26:251?276.M.
G. Cataldo and J. Oakhill.
2000.
Why are poor com-prehenders inefficient searchers?
An investigation intothe effects of text representation and spatial memoryon the ability to locate information in text.
Journal ofEducational Psychology, 92:791?799.Chih-Chung Chang and Chih-Jen Lin.
2011.
LIBSVM:A library for support vector machines.
ACM Transac-tions on Intelligent Systems and Technology, 2:27:1?27:27.
Software available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Scott A. Crossley, David B. Allen, and Danielle S. Mc-Namara.
2011.
Text readability and intuitive simplifi-cation: A comparison of readability formula.
Readingin a Foreign Language, 23(1):84?101.Tullio de Mauro.
2000.
Il Dizionario della Lingua Ital-iana.
Paravia, Torino, Italy.Felice Dell?Orletta, Simonetta Montemagni, and Giu-lia Venturi.
2011.
READ?IT: Assessing Readabilityof Italian Texts with a View to Text Simplification.In Proceedings of the Second Workshop on Speechand Language Processing for Assistive Technologies,pages 73?83, Edinburgh, Scotland, UK, July.
Associa-tion for Computational Linguistics.T.
A.
Van Dijk and W. Kintsch.
1983.
Strategies of dis-course comprehension.
Academic Press, New York,US.Rudolf Flesch.
1946.
The Art of plain talk.
Harper.V.
Franchina and R. Vacca.
1986.
Adaptation of Fleschreadability index on a bilingual text written by thesame author both in Italian and English languages.Linguaggi, 3:47?49.Ingo Glo?ckner, Sven Hartrumpf, Hermann Helbig, Jo-hannes Leveling, and Rainer Osswald.
2006.
An ar-chitecture for rating and controlling text readability.
InProceedings of KONVENS 2006, pages 32?35, Kon-stanz, Germany, October.A.
Graesser, D. McNamara, M. Louwerse, and Z. Cai.2004.
Coh-Metrix: Analysis of text on cohesion andlanguage.
Behavioral Research Methods, Instruments,and Computers, 36:193?202.Robert Gunning.
1952.
The technique of clear writing.McGraw-Hill.Karl F. Haberlandt and Arthur C. Graesser.
1985.
Com-ponent processes in text comprehension and some oftheir interactions.
Journal of Experimental Psychol-ogy, 114(3):357?374.F.
Huerta.
1959.
Medida sencillas de lecturabilidad.Consigna, 214:29?32.L.
Kandel and A. Moles.
1958.
Application de l?Indicede Flesch a` la langue franc?aise.
Cahiers d?Etudes deRadio-Television, pages 253?274.J.P.
Kincaid, R.P.
Fishburne, R.L.
Rogers, and B.S.Chissom.
1975.
Derivation of New Readability For-mulas for Navy Enlisted Personnel.
Research BranchReport.Alberto Lavelli and Anna Corazza.
2009.
The BerkeleyParser at EVALITA 2009 Constituency Parsing Task.In Proceedings of EVALITA Evaluation Campaign.A.
Lavelli, J.
Hall, J. Nilsson, and J. Nivre.
2009.MaltParser at the EVALITA 2009 Dependency ParsingTask.
In Proceedings of EVALITA Evaluation Cam-paign.T.
Linderholm, M. G. Everson, P. van den Broek,M.
Mischinski, A. Crittenden, and J. Samuels.
2000.Effects of Causal Text Revisions on More- and Less-Skilled Readers?
Comprehension of Easy and DifficultTexts.
Cognition and Instruction, 18:525?556.47Pietro Lucisano and Maria Emanuela Piemontese.
1988.Gulpease.
Una formula per la predizione della diffi-colta` dei testi in lingua italiana.
Scuola e Citta`, 3:57?68.G.
H. McLaughlin.
1969.
SMOG grading: A new read-ability formula.
Journal of Reading, 12(8):639?646.D.S.
McNamara, E. Kintsch, N.B.
Songer, andW.
Kintsch.
1996.
Are good texts always better?
Textcoherence, background knowledge, and levels of un-derstanding in learning from text.
Cognition and In-struction, pages 1?43.Emanuele Pianta, Luisa Bentivogli, and Christian Gi-rardi.
2002.
MultiWordNet: developing an alignedmultilingual database.
In First International Confer-ence on Global WordNet, pages 292?302, Mysore, In-dia.Emanuele Pianta, Christian Girardi, and Roberto Zanoli.2008.
The TextPro tool suite.
In Proc.
of the 6th Lan-guage Resources and Evaluation Conference (LREC),Marrakech, Morocco.Emily Pitler and Ani Nenkova.
2008.
Revisiting Read-ability: A Unified Framework for Predicting TextQuality.
In Proceedings of the 2008 Conference onEmpirical Methods in Natural Language Processing,pages 186?195, Honolulu.Caroline E. Scarton, Daniel M. Almeida, and Sandra M.Alu??sio.
2009.
Ana?lise da Inteligibilidade de tex-tos via ferramentas de Processamento de L?
?ngua Natu-ral: adaptando as me?tricas do Coh-Metrix para o Por-tugue?s.
In Proceedings of STIL-2009, Sa?o Carlos,Brazil.Tim von der Bru?ck, Sven Hartrumpf, and Hermann Hel-big.
2008.
A Readability Checker with Super-vised Learning using Deep Architecture.
Informatica,32:429?435.Michael Wilson.
2003.
MRC PsycholinguisticDatabase: Machine Usable Dictionary, Version 2.00.Rutherford Appleton Laboratory, Oxfordshire, Eng-land.ID Feature listGeneral word and text informationBasic Count1-3 N. of words, sents and parag.
in text4 Mean n. of syllables per content word*5 Mean n. of words per sentence6 Mean n. of sentences per paragraphFrequencies7 Raw frequency of content words8 Log of raw frequency of content words9 Min raw frequency of content words10 Log min raw frequency of content wordsHypernymy11 Mean hypernym value of nouns12 Mean hypernym value of verbsSyntactic indicesConstituents information13 Noun phrase incidence14 Mean n. of modifiers per NP15 Higher level constituents16 Mean n. of words before main verb17 Negation incidencePronouns, Types, Tokens18 Pronoun ratio19 Type-token ratioConnectives20 Incidence of all connectives21-22 Incidence of pos./neg.
additive conn.23-24 Incidence of pos./neg.
temporal conn.25-26 Incidence of pos./neg.
causal conn.27-28 Incidence of pos./neg.
* logical conn.29 Incidence of conditional operatorsSyntactic similarity30 Tree intersection between adj.
sentences31 Tree intersection between all sentencesReferential and Semantic IndicesCoreference32 Adjacent argument overlap*33 Stem overlap between adjacent sentences34 Content word overlap between adj.
sents.Situation model dimensions35-36 Causal content and cohesion37-38 Intentional content and cohesion*39-40 Temporal and spatial cohesionFeatures not included in Coh-Metrix41 Lemma overlap with VBI (token-based)*42 Lemma overlap with VBI (type-based)*43 Gulpease index*44 Lexical overlap with Class 1*45 Lexical overlap with Class 2*46 Lexical overlap with Class 3*Table 2: Coease indices for readability assessment.
(*)shows the indices with highest Pearson correlation.48
