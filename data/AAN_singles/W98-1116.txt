What  grammars  te l l  us about  corpora :the  case o f  reduced  re la t ive  c lausesPao la  Mer loLATL-Univers i ty of GenevaIRCSUniversity of Pennsylvania3401 Walnut St Suite 400APhi ladelphia PA 19104-6228U.S.A.merloOlinc, cis.
upenn, eduAbstractWe present a large (65 million words of WallStreet Journal) and in-depth corpus study ofa particular syntactic ambiguity to investigate(1) to what extent the structure of a grammaris reflected in a corpus, and (2)how proba-bility flmctions defined according to a gram-mar fit independently established measures ofsyntactic disambiguation preference.
We lookat the well-known case of the ambiguity be-tween a main clause and reduced relative con-struction.
We measure the probability distri-butions of several inguistic features (transitiv-ity.
tense, voice) over a sample of optionally in-transitive verbs.
In agreement with recent re-suits on parsing with lexicalised probabilisticgrammars (Collins, 1997; Srinivas, 1997), wefind that statistics over lexical, as opposed tostructural, features best correspond to humanintuitive .judgments and to experimental find-ings.
These results are enlightening to inves-tigate novel uses of corpora, by assessing theportability of statistics across tasks, and by de-termining what is needed for useful syntacticannotation of corpora.1 I n t roduct ionMost linguistic work until the 1950s studied lan-guage use.
which required attention to detailand exceptions, and led to the development ofdata-driven theories and to the use of corporato model naturally occurring language.
Lateron.
linguists mostly studied grammars, whichfocussed on generalities and regularities, andled to the formulation of strong theories and tothe study of similarity across languages.
Someof the current "empirical" approaches integratetlle corpus-based lessons with the depth of in-sight that the study of grammar has brought tothe study of language.Suzanne StevensonDept of Computer  Scienceand Center for Cognit ive Science (RuCCS)Rutgers UniversityCoRE Building, Busch CampusNew Brunswick.
NJ 08903U.S.A.suzanne~ruccs ,  ru tgers ,  eduEmpirically-induced models that learn a lin-guistically meaningflll grammar (Collins, 1997)seem to give tile best practical results in statis-tical natural language processing.
One of thereasons wily these models perform so well com-pared to probabilistic ontext-free grammars isthat they incorporate detailed lexical knowl-edge at all points in tile derivation (Charniak,1997).
At the same time they perform betterthan string-based approaches because they re-tain structural knowledge, such as phrase struc-ture, subcategorization and long distance de-pendencies.
So they are equally capable ofmodelling the fine lexical idiosyncrasies and tilemore general syntactic regularities.Given an annotated training corpus, suchmethods learn its distributions (the lexical co-occurrences), which requires being given thecorrect space of events in the model- - that  is,the grammar--accurately enough that they canparse new instances of the same corpus.
Thesuccess of such models suggests that a statisti-cal model nmst have access to tile appropriatelinguistic features to make accurate predictions.We might want to ask the question: whathappens if what one wants to do with anno-tated text is not to annotate more text.
butto perform some other task'?
Are.
the same in-sights valid, so that annotated text can be usedto help in other tasks, for instance generationor translation?
Can we use annotated text toinvestigate properties of language(s) systemat-ically?
In other words, can we use annotatedtext as a repository of information?
The an-swer is a qualified yes.In this paper we look at one type of infor-mation that is plentiflflly present in a corpus--syntactic preferences--and we argue that cor-pora can be very usefifl even for tasks thatdo not invoh'e parsing directly, but that mak-134ing corpora useful for other tasks might re-quire more a priori information than expected.Precisely, we ask the following question: arethe percentages of occurrence of linguistically-defined units in a large corpus in accord withwhat is known about preferences for these unitscollected in other ways, such as unedited sen-tence production, experimental findings, or in-tuitive native speakers' judgments?This question is relevant as there is evidencein the literature of human parsing preferencesthat is in apparent disagreement with predic-tions of preferences derived from frequencies ina corpus (Brysbaert et al, 1998).
Beside the in-terest ill modelling human performance (whichis, however, not the focus of the current pa-per), it is important o investigate the sourcesof this disagreement between production prefer-mine data (frequencies in a text) and perceptiondata (parsing preferences by humans), if theplentiflfl informatioIl stored in text is to be usedsuccessflfily.
Distributional properties of texts if,mderstood, can be used to approximate resolu-tion of ambiguity in several tasks which involvedeeper natural anguage understanding: a gen-eration system can use distributional propertiesto reproduce users' preference data; automatictranslation can use monolingual distributions tomodel cross-linguistic variation accurately, andautomatic lexical acquisition can use distribu-tional properties of text to bootstrap a processof organisation of lexical information.The method we use to address the question isas follows.
We present a large in-depth corpus-based case study (65 million words of WSJ) toinvestigate (1) how the structure of a grammaris reflected in a corpus, and (2) how probabil-ity functions defined according to a grammar fitnative speakers' linguistic behaviour in syntac-tic disambiguation.
We look at the well-known,:;use of tile ambiguity between a main clause anda reduced relative construction, which arises be-cause regular verbs in English present an ambi-guity between the simple past and the past par-ticle (the -ed form).
We measure the probabilitydistributions of several linguistic features (tran-sitivity, tense, voice) over a sample of optionallyintransitive verbs.
We do this by hypothesizingand testing several probability functions overthe sample.
In agreement with recent resultson parsing with lexicalised probabilistic gram-mars (Collins, 1997; Srinivas, 1997; Charniak,1997), our main result is that statistics over lex-ical features best correspond to independentlyestablished truman intuitive preferences and ex-perimental findings.We discuss several consequences.
Method-ologically, this result casts light oll the relation-ship between different ways of collecting pref-erence information.
It shows that some appar-ently contradictory results that have been dis-cussed ill the literature can be reconciled.
ThecruciM factor is the level of specificity one looksat.
Theoretically, not all lexical features axeequally good predictors of linguistic behaviour,and they vary in their ability to correctly clas-sify linguistic phenomena.
Finally, from thepoint of view of language ngineering, this re-sults provides a strong indication on what unitsnfight port better across tasks, and what are thefeatures that would be most useflfl in a syntac-tically annotated corpus..2 Reduced Re la t ive  C lauses2.1 Linguist ic  P roper t iesThe following classic "'garden-path" exam-ple demonstrates tlm sew:re processing diffi-culty that can be associated with the mainverb/reduced relatiw: (MV/RR) ambiguity(Bever, 1970):(1) The horse raced past the barn fell.Problems arise here because the vcrb raced canbe interpreted as either a past tense main verb,or as a past participle within a reduced rela-tive clause (i.e., the hor.s't?
\[that was\] raced pastthe barn).
Because fell is the main verb of (1),the reduced relative interpretation of raced isrequired for a coherent analysis of the completesentence.
But the inain verb interpretation ofraced is so strongly preferred that the humanlanguage processor breaks down at the verb fell,unable to integrate it with the interpretationthat has been developed to that point.This construction is representative of theproblem we want to address.
It.
is very frequent(MacDonald et al, 1994).
hence it constitutes aproblem that is relevant for any application.
Itis both lexically and structurally ambiguous, soit constitutes a hard problem.
It is well-studied:there are plentiful data on lmman processingand their relation to fi'equency of the stimuli(MacDonald, 1994; Trueswell.
1996: Trueswell135VERB TYPE EXAMPLE .JUDGMENTunergative The horse raced past the barn fell hardunaccusative The butter melted m the pan was rancid easyobject-drop The player kicked i:a the soccer game was angry easyTable 1: Processing difficulty of different classes of optionally intransitiw; verbs ac~:ording to speak-ers' intuitionset al, 1994).Over the last several years, it has becomeclear that not all reduced relatives are as dif-ficult as sentence (1) above, and that the diffi-culty in processing reduced relatives is directlylinked to the lexical items in the sentence.
Inparticular the difficulty appears to be relatedto the type of verb which is involved in the am-biguity.
For the ambiguity to arise, the w.'rbinvolved--raced in this case--must be option-ally transitive.
English has three types of op-tionally transitive verbs, which differ both intheir lexical semantics and in their syntacticproperties.Sentence (1) uses a manner of motion verb,raced.
In English, these verbs form a subclass ofmmrgative verbs (Levin and Rappaport Hovav,1995), intransitive action verbs that may appearin a transitive form:(2a) The horse raced past the barn.
(2b) The rider raced the horse past the barn.The transitive form of an unergative (2b) isthe causative counterpart of the intransitiveform (2a), in which the subject of the intransi-tive becomes the object of the transitive (Haleand Keyser: 1993; Levin and Rappaport Hovav,1995).
Sentences (3a) and (3b) use an unac-mlsative verb.
melt:(3a) The butter melted in the pan.
(3b) The cook melted the butter in the pan.Unaccusatives are intransitive change of stateverbs which also have a causative transitiveform.
They differ from unergatives becausetheir alternating theta role is a theme (butter),while for unergatives it is an agent (horse).
Fi-nally, sentences (4a) and (4b) use.
an object-drop verb.
kicked; these verbs have a non-causative transitive/intransitive alternation, inwhich the object NP is optional:(4a) The player kicked the referee.
(4b) The player kicked.2.2 Process ing  Di f f icu l ty(Stevenson and Merlo.
1997) asked naive in-formants for acceptability judgments on sen-tences with reduced relatives (RRs) contain-ing these verbs.
They found that unergativeverbs, such as raced or j,m,ped, unitbrmly ledto a severe garden path in tim R R construc-tion.
while unaccusat ivc  vm'l)s were ()verwhehn-ingly judged completely fine in the R R.. with afew responses of them I,,~ing; slightly degradedThey did not ask tbr .iu,lgments on (fl~ject-dropverbs; native speakers" intuitions are that theyare readily interpretabh', in ;t RR.
Supl)ort forthis view comes fi'om CXl)Criments which in-cluded object-drop verbs, that showed that R.R.sare relatively easy to ,rodin'stand given a con-text that is not strongly I)iased toward a mainverb reading (MacDonakl.
1994).
Tlms.
the digficulty of the RR intcrpret}ttion l);ttterns alongverb class lines, with ,m,.rgatives difficult, andunaccusatives and obj,,,:t-drol~ vm'bs relativelyeasy.
V~re summarise these results in Table 1.2.3 Stat i s t i ca l  P roper t iesWe measured the prolmbility distrilmtions ofseveral linguistic t(.
';ttures (transitivity: tense,voice) over a sample of optionally transitiveverbs fi'om the three lcxical semantic lasses de-scribed above.
We proceeded by hYlmthesizingand testing several probability flmctions overthe sample, and proposing an ev,mt ,:lassifica-tion that best fits the native sp,,aker judgmentsdescribed above.In our view.
a grammar is a wav ,ff classifyingelements in a language.
Our sample of languageis a text, and our grammar is the space of el-ementary events we define on the text.
So ourgrammar is the space, of events over which wecalculate tim probability distributions.
The em-phasis on lexicalised grammars, both in linguis-tics, sentence processing and statistical NLP,points towards statistics ,:Omlmted at the level136RR MV Pass  Act Trans hitr I PRT MV AD.\] nonAD.\]Unergatives .... 7 4910i 139 5330 463 5065 647 4910 21 626Unaccusatives 21 3321 717 393O 2402 2359 1476 3321 155 1321Object-drops 202 2316 1339 3074 3355 922 1939 2316 176 1719Table 2: Raw Countsof lexical items or their subfeatures.A probability space is a triple ~, .T', P, wheref2 is the sample space, .T" is the event space andP is a function P : F ~ \[0, 1\].
In the discussionbelow, we assume 5 different probability spaces,in which the event space is defined by sublexicalproperties of verbs.First, we counted the occurrences of the verbsas a simple past main verb (MV) and the occur-rences of the verbs as a reduced relative (RR).Second, we counted the occurrences of the verbsin a transitive (TRANS) or intransitive (INTR)form.
Third, we counted the occurrences ofthe verbs in an active (ACT) or passive (PASS)form.
Then, we counted the occurrences of theverbs as a simple past main verb (MV) andthe occurrences of the verbs as a past participle(PRT).
These features were chosen because theynfinimally distinguish main clause from reducerelative forms.
Finally, we counted how oftenthe past participle form was used adjectivally.This last count was chosen because only cer-tain lexical semantic lasses of verbs (excludingmmrgative verbs) can occur as adjectives (Levinand Rappaport 1986).Prccisely,7= {MV, RR}, .Tr"= {TRANS, INTR},5'"={PASS, ACT}, $"'"={MV, PAT}, ~ ' "={NON - ADJ.
ADJ}.
In all cases, we assumethat the probabilities of the events are indicatedby their relative frequency.We test the following hypothesis:H0: differences in processing pref-erences correspond to differences inthe distributions of the measured vari-ables.2.3.1 Materials and MethodWe chose a set of 10 verbs from each class,based primarily on the classification of verbs in(Levin.
1993): the unergatives are manner ofmotion verbs (jumped, rushed, marched, leaped,floated, raced, hurried, wandered, vaulted, pa-faded), the unaccusatives are verbs of changeof state (opened.
ezploded, flooded, dissolved,cracked, hardened, boiled, melted, fractured, so-Iidified), and the object-drop verbs are unspec-ified object alternation verbs (played.
painted,kicked, carved, reaped, washed, danced, yelled,typed, knitted).
Each w;rb presented the sameform in the simple past and in the past partici-ple, as in the MV/RR ambiguity.
All verbs canoccur in the transitiw~, and in the passive.
Theverbs in the three sets were matched pairwisein frequency, and their logarithmic fi'cquencyvaries between 2 and 4 ilmlusive.In performing this kind of corpus analysis,one has to take into accomlt the fact that cur-rent corpus annotations do not distinguish verbsenses.
The verbs in the materials were chosenbecause they did not show massive departuresfrom the intended verb sense: tbr example, ina different study run w;u~ eliminated becauseit occurs ulost often in phrases such ;us run ameeting, where it is not a manner of motion use.However, in these comlts, we did not distinguisha core sense of the verl) fi'om an cxtendcd useof the verb.
So.
for instance, the sentence Con-sumer spending jumped 1.7 ~ in February aftera sharp drop the month before (from Wall StreetJournal 1987) is counted as an occurrence ofthe manner-of-motion verb j'amp in its intransi-tive form.
This is an assmnption that is likelyto introduce more variance than if we had onlycounted core senses of these verbs, but it is anunavoidable limitation at the current state ofannotation of corpora.Counts were performed on the tagged ver-sion of the Brown Corpus and on the portionof the Wall Street Journal distributed by theACL/DCI (years 1987, 1988, 1989), a combinedcorpus in excess of 65 million words.
Five pairsof counts were collected, for which the raw ag-gregated results are shown in Table 2.
First,each verb was counted in its main w.,rb (i.e.,simple past) and past participle uses.
based on137If _PROPERTY VERB TYPE RESULTS a main verb unerg/unacc F(18)= 4.058 p=0.059 unacc/obj-drop F(18)= 1.498 p=0.237Ilsimple past unerg/unacc F(18)=14.927 p=0.0011\[_ unacc/obj-drop F(18)= 0.317 p=0.580l active unerg/unacc F(18)= 9.578 p=0.006?
unacc/obj-drop F(18)= 0.067 p=0.799l intransitive unerg/unacc F(18)= 7.487 p=0.014unacc/obj-drop F(18)= 2.514 p=0.130II"non-adj unerg/unacc F(14)=13.283 p=0.003I1 unacc/obj-drop F(14)= 0.311 p=0.586Table 3: Results of anovasthe part of speech tag of the verb in the cor-pora.
Second, active and passive uses of theverbs were counted: cases in which usage couldnot 1)e determined by a simple pattern searchw,;re classified by hand.
The third count alsor,:quired manual intervention: verbs were ini-tially classified as transitive or intransitive ac-,:ording to a set of regular search patterns, thenindividual inspection of verbs was carried out tocorrect item-specific errors.
In the fourth count,uses of the verb form as inain verb or ms reducedrelative were collected.
Reduced relatives were,:o,mtcd by hand after extracting fi'om the cor-pus all occurrences of the past participle pre-ceded by a noun.
In the fifth count, uses of theverbs as prenominal adjectives were counted.None of the verb forms are explicitly marked asadjectives in these corpora.
To deternfine the,xmnts of adjectival uses, we simply divided theverb occurrences labelled with the past partici-ple part of speech tag into prenominal and otheruses.
The only unexpected result we found wasthe occurrence of unergative adjectival forms.On inspection all these forms occurred with twoverbs: hurried occurred 20 times, and rushedonce.
These were not the causative use of theverb.
So these verbs were removed from theanalysis of variance reported below.
The unac-,:usatives and object-drops that were matchedin frequency to hurried and rushed were also re-moved (unaccusatives: boiled, fractured; object-drop: danced, typed).2.4  Resu l ts  and  Discuss ionThe raw aggregated data in Table 2 showthat properties related to the main verb(MV) usage--intransitivity, active voice, non-adjectival use and simple past use.
as well as theMV construction itself--were more frequent forunergatives than for unaccusatives, and morefrequent for unaccusatives than tbr object-dropverbs.
The mnnerical trend is in accord withthe simplest explanation on the use of frequencyby humans: more fl'equently occurring struc-tures are preferrcd over less fl'equent alterna-tives.
However, not all numerical differences aresignificant, as indicated in Table 3.The data in Table 2 were entered in 10 dif-ferent analyses of variance on the proportion ofcases that indicate a use of the verb as a mainverb and its related lexical and sublexical prop-erties - -  simple past.
active, intransitive andnon-adjectival use.
Results of the ANOVAs areshown in Table 3.
The ANOVAS were run todetermine if verbs that belong to a class havea significantly different distribution than verbsthat belong to one of the other two classes.
Wechose to perform analysis of variance becausethis test compares variance within a group tovariance between groups, thus it is not distortedby the fact that there is great w~riation fromlexical item to lexical item within each group.A simplified summary of the res,flts and thecorresponding human intuitive dat}t is given inTable 4.All the data sets show the same pattern.
Forthe lexical features-- simple past.
active, in-transitive and non-adjectival use - -  the differ-ences between the unergative and unaccusativedistributions for each property are lfighly sig-nificant (p < 0.05), but the differences between138VERB TYPE JUDGMENT SIGNIFICANCE TESTMV/RR MV/PTR ACT/PASS INTR/TRANS, ADJ/NON-ADJmmrgati~,e hard non-sig sig sig sig sigunaccusative !easymmccusative easy non-sig non-sig non-sig nOll-sig non-sigobject-drop easyTable 4: Processing difficulty of different classes of optionally intransitive verbs according to speak-~ws' intuitions compared to the results of significance test on pairwise comparisons of corpus datathe unaccusative and object-drop distributionsare not (p > 0.05).
This could explain whythe unergatives are significantly more difficultin the RR, while the other classes of verbs arenot perceived as different.Interestingly, a more direct count of the con-struction itself (the MV/RR probability space)gives different results.
Numerically, the countsof RR for unaccusatives arc very small, butnative speakers do not find RR with unac-,:usative verbs particularly difficult.
Stati.sti-,:ally, mmrgatives are not significantly differ-,mr from unaccusatives (p = 0.059), but nativespeakers find RR with unaccusative verbs con-siderably easier than with unergatives.The picture that emerges from these findingsis coherent and in accordance with current de-w~lopments in statistical parsing and grammati-,:al theory in two important respects.
First, thediscrepancy between the frequencies of each ofthe lexical features and the frequencies of them:tual construction suggests that the frequencyof a construction is a composition fimction of (atleast some of) its lexical features, even if sucht};atures are not-independent.
Models that canhandle non-independent lexical features havegiven very good results both for part-of-speechand structural disambiguation (Ratnaparkhi,1996; Ratnaparkhi, 1997; Ratnaparkhi, 1998).Second, we observe that the lexical and sub-lexical features we counted are not sufficient oidentify all the relevant linguistic classes: sta-tistical tests fail to differentiate between unac-cusatives and object-drop verbs.
In order todistinguish between these two classes of verbsone needs to look at some of the surroundingcontext.
This result is expected.
Performancemeasures of statistical parsers how that statis-tics based on one word give poor results, butthat statistics on bigrams have much better per-formance (Charniak, 1997).3 Genera l  D iscuss ion3.1 Relationship between DifferentKinds of  MethodsOur results cast some light on an importantmethodological question: can frequencies in an-notated corpora be considered a good approxi-mation of speakers' preferences?
Recent resultsin the literature have argued that they cannot,showing large discrepancies between data col-lection methods (Merle, 1994), ,:omprehensionand production (Gibson et al.
1996), and on-line preferences and corpora counts (Brysbaertet al, 1998).
Several explanations have beenproposed, mostly dismissive of some particularmethod to collect data: tbr example: frequency-based preferences are not used by hmnans; thewi'ong frequencies had been ,:omltcd: experi-mental results are not representative of naturallinguistic behaviour: or corpora are not repre-sentative of natural linguistic behaviom'.
Thefindings in this study show a way of reconcil-ing results obtained by different data collectionmethods: if we count at the level of lexical andsublexical features, we find that differences innative speakers' preferences do correspond tosignificant differences in distributions.
Similarconclusions are being reached in (Roland andJurafsky, 1998), who compare different corpora.3.2 Classi f icat ion Proper t ies  of  LexicalFeatures and ConsequencesLooking at the frequencies of the Iexical featuresin Table 2, we can observe that P12T, PASS andTRANS have counts that can be used to di-rectly predict the difficulty of the 1212. construc-tion.
This observation can be used beneficiallyin a task different fl'om parsing, for instancein a generation system.
Some current meth-139ods have a generate and filter approach (Knightand Hatzivassiloglou, 1995): all constructic,nsare generated and then filtered based on a sl~a-tistical model.
If the trigram model has a goodfit with text, our experiments indicates that itwould eliminate many RRs for unaccusativesthat would be considered acceptable by speak-ers.
If instead the filtering is based on, for ex-ample, the frequency of the past participle use,the system would correctly allow unaccusativeRRs, but filter out unergative RRs.Moreover, we notice that all the lexical fea-tures reproduce the well-known relation be-tween markedness within a language and typol-ogy of languages: what is an existing but infre-quent construction i a few languages i absentin many languages.
In this instance, the transi-tive use of manner of motion verbs - -  The r iderraced the horse  - -  is a marked construction inEnglish, in the sense that while it is grammati-cal.
this use is only restricted to a subset of man-ner of motion verbs.
This construction whichis marked in English is ungrammatical in R.o-lnance: languages uch as Italian or French donot have a grammatical direct translation forthe sentence above.
This is called in the socialsciences a zero- rare  distribution, where a fea-ture that is generally already rare is howevernever  present in one subclass of the eases.Interestingly, the lexical feature ADJ presentsa distribution that reflects this cross-linguistict;act internally to English: unergative verbsnever occur prenominally, even those that canoccur transitively, passively and in reduced rel-ative clauses.This is a particularly useful distributional cuetbr verb classification.
On observing the com-plete absence of prenominal adjectives derivedfrom transitive verbs one can classify the verbas unergative.
Or, the cue provided can be usedin a translation task: one of the typical ar-gument structure divergences between Englishand Romance languages can be inferred by look-ing at distributional data.
Thus, by observingthe absence of prenominal adjectives in Englishthe translation system can avoid proposing theRR alternative in the target language, where itwould be ungrammatical.3.3 Language EngineeringFinally, this kind of in-depth corpus analysisgives us indications on what kind of syntacticannotation is needed ill order to lye able to usea corpus to perform tasks at the sentence level,and also, possibly, how to bootstrap a syntacticannotation process in a way that does not re-quire much in-depth semantic knowledge aboutwords.Had we wanted to imrform ~_he study re-ported in this paper by simple counting of oc-currences in an appropriately annotated text- -  thus eliminating the need tbr the tediousand time-consuming filtering of the automaticextraction which was necessary in the presentstudy - -  we would have needed a text anno-tated with categories deriw~d fl'mn knowledgeabout individual lexical items and a small por-tion of the tree surrounding them.
First.
all ourcomlts assumed knowledge of the verb classifi-cation in unergative, unaccusative and object-drop, which requires mmotation of the thematicroles of the verb.
Furthermore.
tin" the cmmtsof the several variables described we needed theverb items and the preceding auxiliary (active-passive and MV/p~st l~articiple), the follow-ing noun phrase and knowledge about whetherthe noun phrase was the direct object of theverb or not (transitive-intransitive).
the preced-ing noun phrase and knowledge about whetherthe noun phrase wm~ the subject of the verb orrather an adjunct head (MV/reduced relative),an.d the preceding deterlniner (adjective-non-adjective).
This is evidence in favour of annota-tion using a lexicalised formalism, whose mainunits are argument-structure dependencies be-tween words, whether em:oded structurally, asin LTAG (Schabes and .loshi.
1991).
or as gram-matical relations, as in dclmmlency grammar(Hudson, 1990: Mel'cuk.
1988).
From the pointof view of parsing, these cmmts require only onechunk of text each.As an example, consider a grammatical for-malisms, such as LTAG (Schabes and .loshi,1991), which is both lexicalised and has beenused to chunk text without pertbrnfing a fifllparse.
An LTAG lexicon is a tbrest of lexi-calised elementary trees.
For verbs, the treestructure corresponds to their argument struc-ture.
Thus, each of the lexical items and portionof tree mentioned abow,, correspond to a dif-ferent elementary tree.
im:luding the unergativeand unaccusative distinction, encoded by differ-ent labels referring to theinatic roles.
Current140LTAG part-of-speech taggers, called supertag-gets (Joshi and Srinivas, 1994; Srinivas, 1997)assign a set of elementary trees to each word, ineffect chunking the text.
The counts performedin the study reported here would have requiredsimply counting the occurrences of the labelsassigned to the words in the text by such a su-pertagger.
Refinements in this direction of theannotation of the grammar used by the XTAGsystem (Doran et al, 1994) are actually tinderway.We also can see, from the raw frequencies ob-tained, that when collecting counts about syn-tactic phenomena, corpora must be in the orderof hundreds of millions of words for the statisticsto be reliable.4 Conc lus ionsOur main result in this paper is that statisticsover lezical features best correspond to indepen-dently established human intuitive judgments.We have argued that, methodologically, this re-sult casts light on the relationship between dif-ferent data collection methods, and shows thatsome apparently contradictory results can bereconciled by defining probability spaces at thelexical and sublexical level.
From the point ofview of language ngineering, we have arguedthat this result provides an indication of whatunits might reflect preferences that port acrosstasks, and what type of syntactic annotation ofcorpora is going to be most useful.5 AcknowledgmentsThis research was partly sponsored by the SwissNational Science Foundation, under fellowship8210-46569 to P. Merlo, and by the US NationalScience Foundation, under grant #9702331 toS.
Stevenson.
We thank Aravind Joshi, MarthaPahner and Adwait Ratnaparkhi for useful com-ulents.ReferencesThomas G. Bever.
1970.
The cognitive basis forlinguistic structure.
In J. R. Hayes, editor,Cognition and the Development ofLanguage.John Wiley, New York.M.
Brysbaert, D.C. Mitchell, and Stefan Gron-delaers.
1998.
Cross-linguistic differences inmodifier attachment biases: Evidence againstGricean and Tuning accounts, manuscript.141Eugene Charniak.
1997.
Statistical parsingwith a context-free gramnmr and word statis-tics.
In Proc.
of the l~th National Conferenceon AI.Michael Jolm Collins.
1997.
Three generative,lexicalised models for statistical parsing.
InProc.
of the 35th Annual Meeting of the A CL,pages 16-23.Christy Doran, Dania Egedi, Beth Aml Hockey,B.
Srinivas, and Martin Zaidel.
1994.
XTAGsystem - a wide coverage grammar for En-glish.
In Proceedings of the 15th Interna-tional Conference on Conl.putational Linguis-tics (COLING g4); pages 922-92& Kyoto,Japan.E.
Gibson: C. Schiitze.
and A. Salomon.
1996.The relationship between the fl'equency andthe processing complexity of linguistic struc-ture.
J. of Psych.
Research.
25(1):59-92.Ken Hale and Jay Keyser.
1993.
On argumentstructure and the lexical representation ofsyntactic relations.
In K. Hah: and J. Keyser,editors, The View from Bwildin~.\] 20, pages53-110.
MIT Press.Richard Hudson.
1990.
ET~.glish Word Gram-mar.
Basil Blackwell.A.
Joshi and B. Srinivas.
1994.
Disaml)iguationof super parts of speech (Sul)ertags): Ahnostparsing.
In Proc.
of Coling 94.
Kyoto, Japan.Kevin Knight and Vasileios Hatziva.ssiloglou.1995.
Two-level.
many-paths generation.
InProc.
of the 3.Tth Annual ~14ceting ofth.e ACL,pages 252-260, Cambridge.MA.Beth Levin and Malka Rappaport Hovav.
1995.Unaccusativity.
MIT Press.
Cambridge, MA.Beth Levin.
1993.
English Verb Classesand Alternations.
Chicago University Press,Chicago, IL.Maryellen C. MacDonahl, Neal .l.
Pearhnutter,and Mark Seidenberg.
1994.
The lexical na-ture of syntactic ambiguity resolution.
Psy-eholo9ical Review.Maryellen MacDonald.
1994.
Probabilistic on-straints and syntactic ambiguity resolution.Language and Cognitive Proce.~scs, 9(2):157-201.I.
Mel'cuk.
1988.
Dependenc.y S:qntax: Theoryand practice.
SUNY Press, All)any.Paola Merlo.
1994.
A corpus-based analysisof verb continuation fiequencies for syntac-tic processing.
Journal of PsycholinguisticsResearch, 23(6):435-457.Aclwait Ratnaparkhi.
1996.
A maximum en-tropy part-of-speech tagger.
In Proceedingsoff the Empirical Methods in Natural Lan-guage Processing Conference, Philadelphia,PA.
University of Pennsylvania.A(lwait Ratnaparkhi.
1997.
A linear observedtime statistical parser based on maximumentropy models.
In 2nd Conf.
on EmpiricalMethods in NLP, pages 1-10, Providence, RI.Adwait Ratnaparkhi.
1998.
Statistical modelsfor unsupervised prepositional phrase attach-ment.
In Proc.
of the 36th Annual Meeting ofthe A CL, Montreal, CA.Doug Roland and Dan Jurafsky.
1998.
Howverb subcategorization frequencies are af-fected by corpus choice.
In Proc.
of the 36thAnnual Meeting of the ACL.
Montreal, CA.Yvc~s Schabes and Aravind Joshi.
1991.
Pars-ing with lexicalized tree adjoining grammars.In Masaru Tomita, editor, Current Issues.
inPar.sing Technology.
Kluwer Academic Pub-lishers.B.
Srinivas.
1997.
Complezity of Lezical De-scriptions and its Relevance to Partial Pars-ing.
Ph.D. thesis, University of Pennsylvania.Suzanne Stevenson and Paola Merlo.
1997.Lexical structure and processing complexity.Language and Cognitive Processes.?
lohn Trueswell, Michael Tanenhaus, and SusanGarnsey.
1994.
Semantic influences on pars-ing: Use of thematic role information in syn-tactic ambiguity resolution..lournal of Mem-ory and Language, 33:285-318.John Trueswell.
1996.
The role of lexicalfrequency in syntactic ambiguity resolution.J.
of Memory and Language, 35:566-585.142
