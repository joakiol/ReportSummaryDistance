Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 789?798,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsEnhancing domain portability of Chinese segmentation modelusing chi-square statistics and bootstrappingBaobao Chang, Dongxu HanInstitute of Computational Linguistics, Peking UniversityKey Laboratory of Computational Linguistics(Peking University), Ministry Education, ChinaBeijing, 100871, P.R.Chinachbb@pku.edu.cn,hweibo@126.comAbstractAlmost all Chinese language processing tasksinvolve word segmentation of the languageinput as their first steps, thus robust and reli-able segmentation techniques are always re-quired to make sure those tasks well-performed.
In recent years, machine learningand sequence labeling models such as Condi-tional Random Fields (CRFs) are often used insegmenting Chinese texts.
Compared withtraditional lexicon-driven models, machinelearned models achieve higher F-measurescores.
But machine learned models heavilydepend on training materials.
Although theycan effectively process texts from the samedomain as the training texts, they performrelatively poorly when texts from new do-mains are to be processed.
In this paper, wepropose to use ?2 statistics when training anSVM-HMM based segmentation model to im-prove its ability to recall OOV words and thenuse bootstrapping strategies to maintain itsability to recall IV words.
Experiments showthe approach proposed in this paper enhancesthe domain portability of the Chinese wordsegmentation model and prevents drastic de-cline in performance when processing textsacross domains.1 IntroductionChinese word segmentation plays a fundamentalrole in Chinese language processing tasks, becausealmost all Chinese language processing tasks areassumed to work with segmented input.
After in-tensive research for more than twenty years, theperformance of Chinese segmentation made con-siderable progress.
The bakeoff series hosted bythe Chinese Information Processing Society (CIPS)and ACL SIGHAN shows that an F measure of0.95 can be achieved in the closed test tracks, inwhich only specified training materials can be usedin learning segmentation models1.Traditional word segmentation approaches arelexicon-driven (Liang, 1987) and assume prede-fined lexicons of Chinese words are available.Segmentation results are obtained by finding a bestmatch between the input texts and the lexicons.Such lexicon-driven approaches can be rule-based,statistic-based or in some hybrid form.Xue (2003) proposed a novel way of segmentingChinese texts, and it views the Chinese word seg-mentation task as a character tagging task.
Accord-ing to Xue?s approach, no predefined Chineselexicons are required; a tagging model is learnedby using manually segmented training texts.
Themodel is then used to assign each character a tagindicating the position of this character within aword.
Xue?s approach has become the most popu-lar approach to Chinese word segmentation for itshigh performance and unified way of dealing without-of-vocabulary (OOV) issues.
Most segmenta-tion work began to follow this approach later.
Ma-jor improvements in this line of research include: 1)More sophisticated learning models were intro-duced other than the maximum entropy model thatXue used, such as the conditional random fields(CRFs) model which fits the sequence taggingtasks much better than the maximum entropymodel (Tseng et al,2005).
2) More tags were in-1 http://www.sighan.org/bakeoff2005/data/results.php.htm789troduced, as Zhao et al (2006) shows 6 tags aresuperior to 4 tags.
3) New feature templates wereadded, such as the templates that were used in rep-resenting numbers, dates, letters etc.
(Low et al,2005)Character tagging approaches require manuallysegmented training texts to learn models usually ina supervised way.
The performance is always eva-luated on a test set from the same domain as thetraining set.
Such evaluation does not reveal itsability to deal with domain variation.
Actually,when test set is from other domains than the do-main where training set is from, the learned modelnormally underperforms substantially.One of the main reasons of such performancedegradation lies in the model?s ability to cope withOOV words.
Actually, even when the test set hasthe same domain properties as the training set, theability of the model to recall OOV words is still themain obstacle to achieve better performance ofsegmentation.
However, when the test set is differ-ent with the training set in nature, the OOV recallnormally drops much more substantially, and be-comes much lower.Apart from the supervised approach, Sun et al(2004) proposed an unsupervised way of Chineseword segmentation.
The approach did not use anypredefined lexicons or segmented texts.
A statisticnamed as md, combining the mutual informationand t score, was proposed to measure whether astring of characters forms word.
The unsupervisednature of the approach means good ability to dealwith domain variation.
However, the approach didnot show a segmentation performance as good asthat of the supervised approach.
The approach wasnot evaluated in F measurement, but in accuracy ofword break prediction.
As their experiment showed,the approach successfully predicted 85.88% of theword breaks, which is much lower than that of thecharacter tagging approach if in terms of F meas-urement.Aiming at preventing the OOV recall fromdropping sharply and still maintaining an overallperformance as good as that of the state-of-artsegmenter when working with heterogeneous testsets, we propose in this paper to use a semi-supervised way for Chinese word segmentationtask.
Specifically, we propose to use ?2 statisticstogether with bootstrapping strategies to build Chi-nese word segmentation model.
The experimentshows the approach can effectively promote theOOV recall and lead to a higher overall perform-ance.
In addition, instead of using the popular CRFmodel, we use another sequence labeling model inthis paper --- the hidden Markov Support VectorMachines (SVM-HMM) Model (Altun et al, 2003).We just wish to show that there are alternativesother than CRF model to use and comparable re-sults can be obtained.Our work differs from the previous supervisedwork in its ability to cope with domain variationand differs from the previous unsupervised work inits much better overall segmentation performance.The rest of the paper is organized as follows: Insection 2, we give a brief introduction to the hid-den Markov Support Vector Machines, on whichwe rely to build the segmentation model.
In section3, we list the segmentation tags and the basic fea-ture templates we used in the paper.
In section 4we show how ?2 statistics can be encoded as fea-tures to promote OOV recall.
In section 5 we givethe bootstrapping strategy.
In section 6, we reportthe experiments and in section 7 we present ourconclusions.2 The hidden Markov support vector ma-chinesThe hidden Markov support vector machine(SVM-HMM) is actually a special case of thestructural support vector machines proposed byTsochantaridis et al (2005).
It is a powerful modelto solve the structure predication problem.
It dif-fers from support vector machine in its ability tomodel complex structured problems and shares themax-margin training principles with support vectormachines.
The hidden Markov support vector ma-chine model is inspired by the hidden Markovmodel and is an instance of structural support vec-tor machine dedicated to solve sequence labelinglearning, a problem that CRF model is assumed tosolve.
In the SVM-HMM model, the sequence la-beling problem is modeled by learning a discrimi-nant function F: X?Y?R over the pairs of inputsequence and label sequence, thus the prediction ofthe label sequence can be derived by maximizing Fover all possible label sequences for a specific giv-en input sequence x.
);,(maxarg);( wyxwxyFfY?=In the structural SVMs, F is assumed to be linear790in some combined feature representation of theinput sequence and the label sequence ?
(x,y), i.e.
),(,);,( yx?wwyx =FWhere w denotes a parameter vector, for the SVM-HMMs, the discriminant function is defined as fol-lows.?
?????==??
??+?
?+=1..1..1'1', )',(),(?
),()(,);,(TtTty yttyyyttyyyyyyyyxF???
?wx?wwHere )?,( www =  , ?
(xt) is the vector of features ofthe input sequence.
?
(yt, y) is the Kronecker func-tion, i.e.,???
?==yyyyyy tttif0if1),(?The first term of the discriminant function is usedto model the interactions between input featuresand labels, and the second term is used to modelinteractions between nearby labels.
?
> 0 is a scal-ing factor which balances the two types of contri-butions.
(Tsochantaridis et al, 2005)Like SVMs, parameter vector w is learned withthe maximum margin principle by using trainingdata.
To control the complexity of the trainingproblem, the cutting plane method is used to solvethe resulted constrained optimization problem.Thus only a small subset of constraints from thefull-sized optimization is checked to ensure a suf-ficiently accurate solution.
Roughly speaking,SVM-HMM differs from CRF in its principle oftraining, and both of them could be used to dealwith sequence labeling problem like Chinese wordsegmentation.3 The tag set and the basic feature tem-platesAs in most other work on segmentation, we use a4-tag tagset, that is S for the character being a sin-gle-character-word by itself, B for the characterbeginning a multi-character-word, E for the char-acter ending a multi-character-word and M for acharacter occurring in the middle of a multi-character-word.We use the following feature templates, as arewidely used in most segmentation work:(a) Cn (n = -2, -1, 0, 1, 2)(b) CnCn+1 (n = -2, -1, 0, 1)(c) C-1C+1Here C refers to a character; n refers to the positionindex relative to the current character.
By settingthe above feature templates, we actually set a 5-character window to extract features, the currentcharacter, 2 characters to its left and 2 characters toits right.In addition, we also use the following featuretemplates to extract features representing the char-acter type:(d) Tn (n = -2, -1, 0, 1, 2)(e) TnTn+1 (n = -2, -1, 0, 1)(f) T-1T+1Here T refers to a character type, and its value canbe digit, letter, punctuation or Chinese character.The type feature is important, for there are twoversions of Arabic numbers, Latin alphabets andpunctuations in the Chinese texts.
This is becauseall three kinds of characters have their internalcodes defined in ASCII table, but the Chinese en-coding standard like GB18030 assigns them withother double-byte codes.
This causes problems formodel learning as we encounter in the experiment.The training data we adopt in this paper only usenumbers, letters and punctuation of double-bytecodes.
But the test data use both the double-byteand single-byte codes.
If the type features are notintroduced, most of the numbers, letters and punc-tuation of single-byte can not be segmented cor-rectly.
The type feature establishes links betweenthe two versions of codes, for both versions of adigit, a letter or punctuation share the same typefeature value.
Actually, the encoding problemcould be alternatively solved by a character nor-malization process.
That is the mapping all single-byte versions of digits, letters and punctuations inthe test sets into their double-byte counterparts asin the training set.
We use the type features here toavoid any changes to the test sets.4 The ?2 statistic features?2 test is one of hypothesis test methods, which canbe used to test if two events co-occur just bychance or not.
A lower ?2 score normally meansthe two co-occurred events are independent; oth-erwise they are dependent on each other.
?2 scoreis widely used in computational linguistics to ex-tract collocations or terminologies.
Unsupervisedsegmentation approach also mainly relies on mu-tual information and t-score to identify words inChinese texts (Sun et al, 2004).
Inspired by their791work, we believe that ?2 statistics could also beincorporated into supervised segmentation modelsto deal with the OOV issue.
The idea is verystraightforward.
If two continuous characters in thetest set have a higher ?2 score, it is highly likelythey form a word or are part of a word even theyare not seen in the training set.The ?2 score of a character bigram (i.e.
two con-tinuous characters in the text) C1C2 can be com-puted by the following formula.
)()()()()(),(2212dcdbcabacbdanCC +?+?+?+???
?=?Here,a refers to all counts of bigram C1C2 in the text;b refers to all counts of bigrams that C1 oc-cursbut C2 does not;c refers to all counts of bigrams that C1 does notoccur but C2 occurs;d refers to all counts of bigrams that both C1 andC2 do not occur.n refers to total counts of all bigrams in the text,apparently, n= a + b + c + d.We do the ?2 statistics computation to the train-ing set and the test set respectively.
To make the ?2statistics from the training set and test set compa-rable, we normalize the ?2 scores by the followingformula.??????
??
?= 10),(),( 2min2max2min212212?????
CCCCnormTo make the learned model sensitive to the ?2 sta-tistics, we then add two more feature templates asfollows:(g) XnXn+1 (n = -2, -1, 0, 1)(h) X-1X+1The value of the feature XnXn+1 is the normalized ?2score of the bigram CnCn+1.
Note we also computethe normalized ?2 score to bigram C-1C+1, which isto measure the association strength of two inter-vened characters.By using the ?2 features, statistics from the testset are introduced into segmentation model, and itmakes the resulted model more aware of the testset and therefore more robust to test domains otherthan training domains.Because the normalized ?2 score is one of 11possible values 0, 1, 2, ?, 10,  templates (g)-(h)generate 55 features in total.All features generated from the templates (a)-(f)together with the 55 ?2 features form the wholefeature set.
The training set and test set are thenconverted into their feature representations.
Thefeature representation of the training set is thenused to learn the model and the feature representa-tion of the test set is then used for segmentationand evaluated by comparison with gold standardsegmentation.
The whole process is shown in Fig-ure-1.Figure-1.
The workflowBy this way, an OOV word in the test set might befound by the segmentation model if the bigramsextracted from this word take higher ?2 scores.5 the bootstrapping strategyThe addition of the ?2 features can be also prob-lematic as we will see in the experiments.
Eventhough it could promote the OOV recall signifi-cantly, it also leads to drops in in-vocabulary (IV)recall.We are now in a dilemma.
If we use ?2 features,we get high OOV recall but a lower IV recall.
Ifwe do not use the ?2 feature, we get a lower OOVrecall but a high IV recall.
To keep the IV recallfrom falling, we propose to use a bootstrappingmethod.
Specifically, we choose to use both mod-els with ?2 features and without ?2 features.
Wetraining set test set?2 score computation ?2 score computationfeaturerepresenationfeature setfeaturerepresenationmodel learningsegmentationmodel segmentationsegmentationresult792train two models firstly, one is ?2-based and theother not.
Then we do the segmentation for the testset with the two models simultaneously.
Two seg-mentation results can be obtained.
One result isproduced by the ?2-based model and has a highOOV recall.
The other result is produced by thenon- ?2-based model and has a higher IV recall.Then we compare the two results and extract allsentences that have equal segmentations with thetwo models as the intersection of the two results.
Itis not difficult to understand that the intersection ofthe two results has both high OOV recall and highIV recall, if we also extract these sentences fromthe gold standard segmentation and performevaluations.
We then put the intersection resultsinto the training set to form a new training set.
Bythis new training set, we train again to get two newmodels, one ?2-based and the other not.
Then thetwo new models are used to segment the test set.Then we do again intersection to the two resultsand their common parts are again put into the train-ing set.
We repeat this process until a plausibleresult is obtained.The whole process can be informally describedas the following algorithm:1. let training set T to be the original training set;2. for I = 0 to K1) train the ?2-based model by using trainingset T;2) train the non- ?2-based model by usingtraining set T;3) do segmentation by using the ?2-basedmodel;4) do segmentation by using the non- ?2-based model;5) do intersection to the two segmentation re-sults6) put the intersection results into the trainingset and get the enlarged training set T3.
train the non- ?2-based model using trainingset T, and take the output of this model as thefinal output;4. end.6 The experiments and discussions6.1  On the training set and test setFor training the segmentation model, we use thetraining data provided by Peking University forbakeoff 20052 .
The training set has about 1.1 mil-lion words in total.
The PKU training data is actu-ally consisted of all texts of the People?s Dailynewspaper in January of 1998.
So the training datarepresents very formal written Chinese and mainlyare news articles.
A characteristic of the PKU datais that all Arabic numbers, Latin letters and punc-tuations in the data are all double-byte GB codes;there are no single-byte ASCII versions of thesecharacters in the PKU training data.We use three different test sets.
The first one(denoted by A) is all texts of the People?s Daily ofFebruary in 19983 .
Its size and the genre of thetexts are very similar to the training data.
We usethis test set to show how well the SVM-HMM canbe used to model segmentation problem and theperformance that a segmentation model achieveswhen applied to the texts from the same domain.The second and the third test sets are set to testhow well the segmentation model can apply totexts from other domains.
The second test set (de-noted by B) is from the literature domain and thethird (denoted by C) from computer domain.
Wesegmented them manually according to the guide-lines of Peking University4 to use as gold standardsegmentations.
The genres of the two test set arevery different from the training set.
There are eventypos in the texts.
In the computer test set, there aremany numbers and English words.
And most of thenumbers and letters are single-byte ASCII codes.The sizes and the OOV rates of the three testsets are shown in Table-1.Table-1.
Test sets statisticstest set domain word count OOV rateA Newspaper 1,152,084 0.036B Literature 72,438 0.058C Computer 69,671 0.159For all the experiments, we use the same evalua-tion measure as most of previous work on segmen-tation, that is the Recall(R), Precision(P), Fmeasure (F=2PR/(P+R)), IV word recall and OOVword recall.
In addition, we also evaluate all thetest results with sentence accuracies (SA), which isthe proportion of the correctly segmented sen-tences in the test set.2 can be download from http://www.sighan.org/bakeoff2005/3 The corpus can be licensed from Peking University.4 See http:// www.sighan.org/bakeoff2005/7936.1 SVM-HMM vs. CRFTo show how well the SVM-HMM model can beused to model segmentation tasks and its perform-ance compared to that of CRF model, we use thetraining set to train two models, one with SVM-HMM and the other with CRF.The implementations of SVM-HMM and CRFmodel we use in the paper can be found and down-loaded respectively via Internet.
5To make the results comparable, we use thesame feature templates, that is feature template (a)-(c).
However, SVM-HMM takes interactions be-tween nearby labels into the model, which meansthere is a label bigram feature template implicitlyused in the SVM-HMM.
So when training the CRFmodel we also use explicitly the label bigram fea-5 http://www.cs.cornell.edu/People/tj/svm_light/svm_hmm.html, and http://sourceforge.net/projects/crfpp/ture template to model interactions between nearbylabels6.For the SVM-HMM model, we set ?
to 0.25.This is a parameter to control the accuracy of thesolution of the optimization problem.
We set C tohalf of the number of the sentences in the trainingdata according to our understanding to the models.The C parameter is set to trade off the margin sizeand training error.
For CRF model, we use all pa-rameters to their default value.
We do not do pa-rameter optimizations to both models with respecttheir performances.We use test set A to test both models.
For bothmodels, we use the same cutoff frequency to fea-ture extraction.
Only those features that are seenmore than three times in texts are actually used inthe models.
The performances of the two modelsare shown in Table-2, which shows SVM-HMMcan be used to model Chinese segmentation tasks6 specified by the B template as the toolkit requires.Table-2.
Performance of the SVM-HMM  and CRF modelModels P R F Riv Roov SASVM-HMM 0.9566 0.9528 0.9547 0.9620 0.7041 0.5749CRF 0.9541 0.9489 0.9515 0.9570 0.7185 0.5570Table-3.
Performance of the basic modeltest set P R F Riv Roov SAA 0.9566 0.9528 0.9547 0.9620 0.7041 0.5749B 0.9135 0.9098 0.9116 0.9295 0.5916 0.4698C 0.7561 0.8394 0.7956 0.9325 0.3487 0.2530Table-4.
Performance of the type sensitive modeltest set P R F Riv Roov SAA 0.9576 0.9522?
0.9549 0.9610?
0.7161 0.5766B 0.9176 0.9095?
0.9136 0.9273?
0.6228 0.4832C 0.9141 0.8975 0.9057 0.9381 0.6839 0.4287Table-5.
Performance of the ?2-based modeltest set P R F Riv Roov SAA 0.9585 0.9518?
0.9552 0.9602?
0.7274 0.5736?B 0.9211 0.8971?
0.9090?
0.9104?
0.6825 0.4648?C 0.9180 0.8895?
0.9035?
0.9209?
0.7239 0.4204?Table-6.
Performance of the bootstrapping modeltest set P R F Riv Roov SAB 0.9260 0.9183 0.9221 0.9329 0.6830 0.5120C 0.9113?
0.9268 0.9190 0.9482 0.8138 0.5039794and comparable results can be achieved like CRFmodel.6.2 The baseline modelTo test how well the segmentation model applies toother domain texts, we only use the SVM-HMMmodel with the same parameters as in section 6.1and the same cutoff frequency.For a baseline model, we only use feature tem-plates (a)-(c), the performances of the basic modelon the three test sets are shown in Table-3.For the test set A, which is from the same do-main as the training data, an F-score 0.95 isachieved.For test set B and C, both are from different do-mains with the training data, the F-scores drop sig-nificantly.
Especially the OOV recalls falldrastically, which means the model is very sensi-tive to the domain variation.
Even the IV recallsfall significantly.
This also shows the domain port-ability of the segmentation model is still an obsta-cle for the segmentation model to be used in cross-domain applications.6.3 The type featuresAs we noted before, there are different encodingtypes for the Arabic numbers, Latin letters andpunctuations.
Especially, test set C is full of single-byte version of such numbers, letters and punctua-tions.
The introduction of type features may im-prove performance of the model to the test set.Therefore, we use the feature tem-plates (a)-(f) totrain a type sensitive model with the training data.This gives segmentation results shown in table-4.
(The symbol ?
means performance drop comparedwith a previous model)As we can see, for test set A, the type featuresalmost contribute nothing; the F-score has a veryslight change.
The IV recall even has a slight fallwhile the OOV recall rises a little.For test set C, the type features bring about verysignificant improvement.
The F-score rises from0.7956 to 0.9057, and the OOV recall rises from0.3487 to 0.6839.
Different with the test set A,even the IV recall for test set C rises slightly.
Thereason of such a big improvement lies in that thereare many single-byte digits, letters and punctua-tions in the texts.Unlike test set C, there are not so many single-byte characters in test set B.
Even though the OOVrecall does rise significantly, the change in OOVrecall for test set B is not as much as that for testset B.
Type features contribute much to cross do-main texts.6.4 The ?2-based modelCompared with OOV recall for test set A, the OOVrecall for test set B and C are still lower.
To pro-mote the OOV recall, we use the feature templates(a)-(h) to train a ?2-based model with the trainingdata.
This gives segmentation results shown in ta-ble-5.As we see from table-5, the introduction of the?2 features does not improve the overall perform-ance.
Only F-score for test set A improves slightly,the other two get bad.
But the OOV recall for thethree test sets does improve, especially for test setB and C. The IV recalls for the three test sets drop,especially for test set B and C. That's why the Fscores for test B and C drop.6.5 BootstrappingTo increase the OOV recall and prevent the IV re-call from falling, we use the bootstrapping strategyin section 5.We set K = 3 and run the algorithm shown insection 5.
We just do the bootstrapping to test set Band C, because what we are concerned with in thispaper is to improve the performance of the modelto different domains.
This gives results shown inTable-6.
As we see in Table-6, almost all evalua-tion measurements get improved.
Not only theOOV recall improves significantly, but also the IVrecall improves compared with the type-sensitivemodel.To illustrate how the bootstrapping strategyworks, we also present the performance of the in-termediate models on test set C in each pass of thebootstrapping in table-7 and table-8.
Table-7 isresults of the intermediate ?2-based models for testset C. Table-8 is results of the intermediate non-?2-based models for test set C. Figure-2 illustrateschanges in OOV recalls of both non- ?2-basedmodels and ?2-based models as the bootstrappingalgorithm advances for test set C. Figure-3 illus-trates changes in IV re-calls of both non- ?2-basedmodels and ?2-based models for test set C. As wecan see from Figure-2 and Figure-3, the ability ofnon- ?2-based model gets improved to the OOV795recall of the ?2-based model as the bootstrappingalgorithm advances.
The abilities to recall IVwords of both models improve, and even the finalIV recall of the ?2-based model surpasses the IVrecall of the type sensitive model shown in Table-3.
(0.9412 vs. 0.9381).
To save the space of the paper,we do not list all the intermediate results for testset B.
We just show the changes in OOV recallsand IV recalls as illustrated in Figure-4 and Figure-5.
One can see from Figure-4 and Figure-5, thebootstrapping strategy also works for test set B in asimilar way as it works for test set C.0.60.650.70.750.80.850 1 2 3 4without chi-square features with chi-square featuresFigure-2 the Changes in OOV recalls for test set Cas boot-strapping algorithm advances0.9050.910.9150.920.9250.930.9350.940.9450.950.9550 1 2 3 4without chi-square features with chi-square featuresFigure-3 the Changes in IV recalls for test set C asboot-strapping algorithm advances0.60.620.640.660.680.70.720 1 2 3 4without chi-square features with chi-square featuresFigure-4 the Changes in OOV recalls for test set Bas boot-strapping algorithm advancesTable-7.
Performance of the intermediate ?2-based models for test set CI P R F Riv Roov SA0 0.9180 0.8895 0.9035 0.9209 0.7239 0.42041 0.9084 0.9186 0.9134 0.9387 0.8126 0.47622 0.9083 0.9187 0.9134 0.9386 0.8138 0.48223 0.9068 0.9208 0.9137 0.9412 0.8131 0.4816Table-8.
Performance of the intermediate non-?2-based modelsfor test set CI P R F Riv Roov SA0 0.9141 0.8975 0.9057 0.9381 0.6839 0.42871 0.9070 0.9249 0.9159 0.9478 0.8044 0.48692 0.9093 0.9254 0.9173 0.9476 0.8087 0.49473 0.9111 0.9266 0.9188 0.9481 0.8133 0.50304 0.9113 0.9268 0.9190 0.9482 0.8138 0.5039Table-9.
Performance of the intersection of the intermediate ?2-basedmodel and non-?2-based model for test CI P R F Riv Roov SA0 0.9431 0.9539 0.9485 0.9664 0.8832 0.67831 0.9259 0.9434 0.9345 0.9609 0.8491 0.59922 0.9178 0.9379 0.9277 0.9582 0.8316 0.57243 0.9143 0.9347 0.9244 0.9559 0.8250 0.56167960.90.9050.910.9150.920.9250.930.9351 2 3 4 5without chi-square features with chi-square featuresFigure-5 the Changes in IV recalls for test set Bas boot-strapping algorithm advancesAs we mentioned in section 5, the intersection ofthe results produced by ?2-based model and non-?2-based model has both high OOV recall andhigh IV recall, that?s the reason why bootstrappingstrategy works.
This can be seen from Table-9.However, as the algorithm progresses, both theOOV recall and IV recall of the intersection resultsfall, but are still higher than OOV recall and IVrecall of the final results on the whole test set.As we said before, we give also sentence accu-racies of all segmentation models.
With the ?2 sta-tistics and bootstrapping strategies, the sentenceaccuracy also rises.
2.8% more sentences on testset B and 7.5% more sentences on test set C arecorrectly segmented, compared with the type-sensitive model.7 ConclusionsSequence labeling models are widely used in Chi-nese word segmentation recently.
High perform-ance can be achieved when the test data is from thesame domain as the training data.
However, if thetest data is assumed to be from other domains thanthe domain of the training data, the segmentationmodels always underperform substantially.
To en-hance the portability of the sequence labeling seg-mentation models to other domains, this paperproposes to use ?2 statistics and bootstrappingstrategy.
The experiment shows the approach sig-nificantly increases both IV recall and OOV recallwhen processing texts from different domains.We also show in this paper that hidden Markovsupport vector machine which is also a sequencelabeling model like CRF can be used to model theChinese word segmentation problem, by whichhigh F-score results can be obtained like those ofCRF model.One concern to the bootstrapping approach inthis paper is that it takes time to work with, whichwill make it difficult to be incorporated into lan-guage applications that need to responses in realtime.
However, we believe that such an approachcan be used in offline contexts.
For online use in aspecified domain, one can first train models byusing the approach in the paper with prepared rawtexts from the specified domain and then use thefinal non-?2-based model to segment new texts ofthe same domain, since statistics of the target do-main are more or less injected into the model bythe iteration of bootstrapping.AcknowledgmentsThis work is supported by National Natural Sci-ence Foundation of China under Grant No.60975054 and National Social Science Foundationof China under Grant No.
06BYY048.We would like to give thanks to Prof. DuanHuiming for her work in preparing the gold stan-dard segmentation and to the anonymous reviewersfor their comments to the paper.ReferencesAltun,Yasemin et al,2003, Hidden Markov SupportVector Machines.
Proceedings of the Twentieth Iter-national Conference on Machine Learning (ICML-2003), Washington DC, 2003.Gao, Jianfeng et al, 2005, Chinese Word Segmentationand Named Entity Recognition: A Pragmatic Ap-proach, Computational Linguis-tics,Vol.31, No.4,pp531-574.Huang, Changning et al 2007, Chinese word segmenta-tion: a decade review.
Journal of Chinese Informa-tion Processing, Vol.21, NO.3,pp8?19.
(in Chinese)Liang, Nanyuan, 1987.
?
?written Chinese text segmenta-tion system--cdws?.
Journal of Chinese InformationProcessing, Vol.2, NO.2, pp44?52.
(in Chinese)Low, Jin Kiat et al,2005, A Maximum Entropy Ap-proach to Chinese Word Segmentation.
Proceedingsof the Fourth SIGHAN Workshop on Chinese Lan-guage Processing, Jeju Island, Ko-rea,.
pp161-164Sun, Maosong et al, 2004, Chinese word segmentationwithout using dictionary based on unsupervisedlearning strategy.
Chinese Journal of Computers.Vol.27, No.6, pp736-742.
(in Chinese)797Tseng, Huihsin et al, 2005, A conditional random fieldword segmenter for SIGHAN 2005, Proceedings ofthe fourth SIGHAN workshop on Chinese languageprocessing.
Jeju Island, Korea.
pp168-171Tsochantaridis,Ioannis et al, 2005, Large Margin Meth-ods for Structured and Interdependent Output Vari-ables, Journal of Machine Learning Research(JMLR), No.6, pp1453-1484.Xue, Nianwen, 2003, Chinese Word Segmentation asCharacter Tagging, Computational Linguistics andChinese Language Processing.
Vol.8, No.1, pp29-48.Zhao, Hai et al, 2006, Effective tag set selection inChinese word segmentation via conditional randomfield modeling, Proceedings of the 20th Pacific AsiaConference on language, Information and Computa-tion (PACLIC-20), Wuhan, China, pp87-94798
