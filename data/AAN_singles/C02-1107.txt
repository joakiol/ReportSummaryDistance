Example-based Speech Intention Understanding andIts Application to In-Car Spoken Dialogue SystemShigeki Matsubara? Shinichi Kimura?
Nobuo Kawaguchi?Yukiko Yamaguchi?
and Yasuyoshi Inagaki?
?Information Technology Center, Nagoya University?Graduate School of Engineering, Nagoya UniversityCIAIR, Nagoya UniversityFuro-cho, Chikusa-ku, Nagoya, 464-8601, Japanmatubara@itc.nagoya-u.ac.jpAbstractThis paper proposes a method of speech inten-tion understanding based on dialogue examples.The method uses a spoken dialogue corpus withintention tags to regard the intention of each in-put utterance as that of the sentence to which itis the most similar in the corpus.
The degree ofsimilarity is calculated according to the degreeof correspondence in morphemes and dependen-cies between sentences, and it is weighted bythe dialogue context information.
An exper-iment on inference of utterance intentions us-ing a large-scale in-car spoken dialogue corpusof CIAIR has shown 68.9% accuracy.
Further-more, we have developed a prototype system ofin-car spoken dialogue processing for a restau-rant retrieval task based on our method, andconfirmed the feasiblity of the system.1 IntroductionIn order to interact with a user naturally andsmoothly, it is necessary for a spoken dialoguesystem to understand the intentions of utter-ances of the user exactly.
As a method of speechintention understanding, Kimura et al has pro-posed a rule-based approach (Kimura et al,1998).
They have defined 52 kinds of utteranceintentions, and constructed rules for inferringthe intention from each utterance by taking ac-count of the intentions of the last utterances, averb, an aspect of the input utterance, and soon.
The huge work for constructing the rules,however, cannot help depending on a lot ofhands, and it is also difficult to modify the rules.On the other hand, a technique for tagging di-alogue acts has been proposed so far (Araki etal., 2001).
For the purpose of concretely deter-mining the operations to be done by the system,the intention to be inferred should be more de-tailed than the level of dialogue act tags such as?yes-no question?
and ?wh question?.This paper proposes a method of understand-ing speeches intentions based on a lot of dia-logue examples.
The method uses the corpus inwhich the utterance intention has given to eachsentence in advance.
We have defined the ut-terance intention tags by extending an annota-tion scheme of dialogue act tags, called JDTAG(JDRI, 2000), and arrived at 78 kinds of tagspresently.
To detail an intention even on thelevel peculiar to the task enables us to describethe intention linking directly to operations ofthe system.In the technique for the intention inference,the degree of similarity of each input utter-ance with every sentence in a corpus is calcu-lated.
The calculation is based on the degree ofmorphologic correspondence and that of depen-dency correspondence.
Furthermore, the degreeof similarity is weighted by using dialogue con-text information.
The intention of the utteranceto which the maximum score is given in the cor-pus, will be accepted as that of the input utter-ance.
Our method using dialogue examples hasthe advantage that it is not necessary to con-struct rules for inferring the intention of everyutterance and that the system can also robustlycope with the diversity of utterances.An experiment on intention inference hasbeen made by using a large-scale corpus of spo-ken dialogues.
The experimental result, provid-ing 68.9% accuracy, has shown our method tobe feasible and effective.
Furthermore, we havedeveloped, based on our method, a prototypesystem of in-car spoken dialogue processing fora restaurant retrieval task, and confirmed thefeasiblity of the system.Chikaku-ni chushajo-wa aru-ka-na(Is there a parking lot nearby?
)Kono chikaku-ni firstfood aru?
(Is there a first food shop near here?Mosburger-ga gozai-masu-ga(Mosburger is near here.
)Spoken dialoguecorpus withintention tags?????????????????????????????????????????????????????????????
?Dependency and morpheme analysisSystem?sspeechIntensionsprobabilityCalculationof similarityweightingUtterance intension: ?parking lot question?Context informationUser?sspeechFigure 1: Flow of the intention inference pro-cessing2 Outline of Example-basedApproachIntentions of a speaker would appear in the vari-ous types of phenomenon relevant to utterances,such as phonemes, morphemes, keywords, sen-tential structures, and contexts.
An example-based approach is expected to be effective fordeveloping the system which can respond to thehuman?s complicated and diverse speeches.
Adialogue corpus, in which a tag showing an ut-terance intention is given to each sentence, isused for our approach.
In the below, the outlineof our method is explained by using an inferenceexample.Figure 1 shows the flow of our intentioninference processing for an input utterance?Chikaku-ni chushajo-wa aru-ka-na ?
(Is therea parking lot nearby?)?.
First, morphologicalanalysis and dependency analysis to the utter-ance are carried out.Then, the degree of similarity of each inpututterance with sentences in the corpus can becalculated by using the degree of correspon-dence since the information on both morphol-ogy and dependency are given to all sentencesin the corpus in advance.
In order to raise theaccuracy of the intention inference, moreover,the context information is taken into consid-eration.
That is, according to the occurrenceprobability of a sequence of intentions learnedfrom a dialogue corpus with the intention tags,the degree of similarity with each utterance isweighted based on the intentions of the last ut-terances.
Consequently, if the utterance whosedegree of similarity with the input utterance isthe maximum is ?sono chikaku-ni chushajo ari-masu-ka?
(Is there a parking lot near there?
)?,the intention of the input utterance is regardedas ?parking lot question?.3 Similarity and its CalculationThis section describes a technique for calculat-ing the degree of similarity between sentencesusing the information on both dependency andmorphology.3.1 Degree of Similarity betweenSentencesIn order to calculate the degree of similarity be-tween two sentences, it can be considered tomake use of morphology and dependency infor-mation.
The calculation based on only mor-phemes means that the similarity of only sur-face words is taken into consideration, and thusthe result of similarity calculation may becomelarge even if they are not so similar from a struc-tural point of view.
On the other hand, the cal-culation based on only dependency relations hasthe problem that it is difficult to express the lex-ical meanings for the whole sentence, in partic-ular, in the case of spoken language.
By usingboth the information on morphology and de-pendency, it can be expected to carry out morereliable calculation.Formula (1) defines the degree of similaritybetween utterances as the convex combination?
of the degree of similarity on dependency, ?d,and that on morpheme, ?m.?
= ?
?d + (1 ?
?
)?m (1)?d : the degree of similarity in dependency?m: the degree of similarity in morphology?
: the weight coefficient (0 ?
?
?
1)Section 3.2 and 3.3 explain ?d and ?m, re-spectively.3.2 Dependency SimilarityGenerally speaking, a Japanese dependency re-lation means the modification relation betweena bunsetsu and a bunsetsu.
For example,a spoken sentence ?kono chikaku-ni washoku-no mise aru?
(Is there a Japanese restau-rant near here?)?
consists of five bunsetsus of?kono (here)?, ?chikaku-ni (near)?, ?washoku-no (Japanese-style food)?, ?mise (a restau-rant)?, ?aru (being)?, and there exist some de-pendencies such that ?mise?
modifies ?aru?.
Inthe case of this instance, the modifying bun-setsu ?mise?
and the modified bunsetsu ?aru?are called dependent and head, respectively.
Itis said that these two bunsetsus are in a depen-dency relation.
Likewise, ?kono?, ?chikaku-ni?and ?washoku-no?
modify ?chikaku-ni?, ?aru?and ?mise?, respectively.
In the following of thispaper, a dependency relation is expressed as theorder pair of bunsetsus like (mise, aru), (kono,chikaku-ni).A dependency relation expresses a part ofsyntactic and semantic characteristics of thesentence, and can be strongly in relation to theintentional content.
That is, it can be expectedthat two utterances whose dependency relationsare similar each other have a high possibilitythat the intentions are also so.A formula (2) defines the degree of similar-ity in Japanese dependency, ?D, between twoutterances SA and SB as the degree of corre-spondence between them.
?d =2CDDA + DB(2)DA: the number of dependencies in SADB: the number of dependencies in SBCD : the number of dependencies in corre-spondenceHere, when the basic forms of independentwords in a head bunsetsu and in a dependentbunsetsu correspond with each other, these de-pendency relations are considered to be in cor-respondence.
For example, two dependencies(chikaku-ni, aru) and (chikaku-ni ari-masu-ka)correspond with each other because the inde-pendent words of the head bunsetsu and the de-pendent bunsetsu are ?chikaku?
and ?aru?, re-spectively.
Moreover, each word class is givento nouns and proper nouns characteristic of adialogue task.
If a word which constitutes eachdependency belongs to the same class, these de-pendencies are also considered to be in corre-spondence.3.3 Morpheme SimilarityA formula (3) defines the degree of similarity inmorpheme ?m between two sentences SA and?????????????
??????????????
(Is there a Japanese restaurant near here?)???
?Japanese dependency4 dependenciescommon dependencies: 3?d = 0.86Japanese morphemecommon morphemes: 6?m = 0.80?= 0.82Degree of SimilarityIf?= 0.4,= 0.4*0.86+0.6*0.807 morphemesUser?s utterance unit: Si?????????????????????
??????????
????
(Is there a European restaurant nearby?
)Example of utterance: Se3 dependencies 8 morphemesFigure 2: Example of similarity calculationSB.
?m =2CMMA + MB(3)MA: the number of morphemes in SAMB: the number of morphemes in SBCM : the number of morphemes in correspon-denceIn our research, if a word class is given tonouns and proper nouns characteristic of a di-alogue task and two morphemes belong to thesame class, these morphemes are also consid-ered to be in correspondence.
In order to ex-tract the intention of the sentence more simi-lar as the whole sentence, not only independentwords and keywords but also all the morphemessuch as noun and particle are used for the cal-culation on correspondence.3.4 Calculation ExampleFigure 2 shows an example of the calculationof the degree of similarity between an input ut-terance Si ?kono chikaku-ni washoku-no misearu?
(Is there a Japanese restaurant nearhere?)?
and an example sentence in a corpus,Se, ?chikaku-ni yoshoku-no mise ari-masu-ka (Isthere a European restaurant located nearby?
)?,when a weight coefficient ?
= 0.4.
The num-ber of the dependencies of Si and Se is 4 and3, respectively, and that of dependencies in cor-respondence is 2, i.e., (chikaku, aru) and (mise,aru).
Moreover, since ?washoku (Japanese-stylefood)?
and ?yoshoku?
(European-style food)belong to the same word class, the dependencies(washoku, aru) and (yoshoku, aru) also corre-spond with each other.
Therefore, the degreeof similarity in dependency ?d comes to 0.86by the formula (2).
Since the number of mor-phemes of Si and Se are 7 and 8, respectively,and that of morphemes in correspondence is 6,i.e., ?chikaku?, ?ni?, ?no?, ?mise?, ?aru(i)?
and?wa(yo)shoku?.
Therefore, ?m comes to 0.80by a formula (3).
As mentioned above, ?
us-ing both morphemes and dependencies comesto 0.82 by a formula (1).4 Utilizing Context InformationIn many cases, the intention of a user?s utter-ance occurs in dependence on the intentions ofthe previous utterances of the user or those ofthe person to which the user is speaking.
There-fore, an input utterance might also receive theinfluence in the contents of the speeches beforeit.
For example, the user usually returns theanswer to it after the system makes a question,and furthermore, may ask the system a ques-tion after its response.
Then, in our technique,the degree of similarity ?, which has been ex-plained in Section 3, is weighted based on theintentions of the utterances until it results in auser?s utterance.
That is, we consider the oc-currence of a utterance intention In at a certaintime n to be dependent on the intentions of thelast N ?
1 utterances.
Then, the conditionaloccurrence probability P (In|In?1n?N+1) is definedas a formula (4).P (In|In?1n?N+1) =C(Inn?N+1)C(In?1n?N+1)(4)Here, we write a sequence of utterance in-tentions In?N+1 ?
?
?In as Inn?N+1, call it in-tentions N-gram, and write the number ofappearances of them in a dialogue corpus asC(Inn?N+1).
Moreover, we call the conditionaloccurrence probability of the formula (4), in-tentions N-gram probability.The weight assignment based on the inten-tions sequences is accomplished by reducing thevalue of the degree of similarity when the in-tentions N-gram probability is smaller than athreshold.
That is, a formula (5) defines the de-gree of similarity ?
using the weight assignmentby intentions N-gram probability.SearchCondition searchParking searchNearness questionShop questionBusiness hours questionDistance questionTime questionRank questionMenu price questionNumber of car questionParking price question Parking question??
?intention tag??
?dialogue act tag??
?conditional tagleafYes-no question Wh question ??
?Unknown informationUnknown informationFigure 3: Decision tree of intention tag (a part)?
={??
(P (In|In?1n?N+1) ?
?)?
(otherwise)(5)?
: weight coefficient (0 ?
?
?
1)?
: the degree of similarity?
: thresholdA typical example of the effect of using inten-tions N-gram is shown below.
For an input ut-terance ?chikaku-ni chushajo-wa ari-masu-ka?
(Is there a parking lot located nearby?
)?, thedegree of similarity with a utterance with atag ?parking lot question?
which intends toask whether a parking lot is located aroundthe searched store, and a utterance with a tag?parking lot search?
which intends to search aparking lot located nearby, becomes the maxi-mum.
However, if the input utterance has oc-curred after the response intending that thereis no parking lot around the store, the systemcan recognize its intention not to be ?parkinglot question?
from the intentions N-gram prob-abilities learned from the corpus, As a result,the system can arrive at a correct utterance in-tention ?parking lot search?.5 EvaluationIn order to evaluate the effectiveness of ourmethod, we have made an experiment on ut-terance intention inference.5.1 Experimental DataAn in-car speech dialogue corpus which hasbeen constructed at CIAIR (Kawaguchi et al,0.40.450.50.550.60.650.70 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1weight coefficient ?accuracyrecall precisionFigure 4: Relation between the weight coeffi-cient ?
and the accuracy (?
= 0.3)2001), was used as a corpus with intention tags,and analyzed based on Japanese dependencygrammar (Matsubara et al, 2002).
That is,the intention tags were assigned manually intoall sentences in 412 dialogues about restaurantsearch recorded on the corpus.
The intentions2-gram probability was learned from the sen-tences of 174 dialogues in them.
The standardfor assigning the intention tags was establishedby extending the decision tree proposed as a di-alogue tag scheme (JDRI, 2000).
Consequently,78 kinds of intention tags were prepared in all(38 kinds are for driver utterances).
The inten-tion tag which should be given to each utter-ance can be defined by following the extendeddecision tree.
A part of intention tags and thesentence examples is shown in Table 1, and apart of the decision tree for driver?s utterancesis done in Figure 3 1.A word class database (Murao et al, 2001),which has been constructed based on the cor-pus, was used for calculating the rates of cor-respondence in morphemes and dependencies.Moreover, Chasen (Matsumoto et al, 99) wasused for the morphological analysis.5.2 Experiment5.2.1 Outline of ExperimentWe have divided 1,609 driver?s utterances of238 dialogues, which is not used for learningthe intentions 2-gram probability, into 10 piecesequally, and evaluated by cross validation.
Thatis, the inference of the intentions of all 1,609 sen-1In Figure 3, the description in condition branches isomitted.???????????????????????????????
???
???
???
???
???
???
???
???
???
????????????????????????????????????????????????????????????????
?Figure 5: Relation between the weight coeffi-cient ?
and the accuracytences was performed, and the recall and preci-sion were calculated.
The experiments based onthe following four methods of calculating the de-gree of similarity were made, and their resultswere compared.1.
Calculation using only morphemes2.
Calculation using only denpendencies3.
Calculation using both morphemes anddenpendencies (With changing the value ofthe weight coefficient ?)4.
Calculation using intentions 2-gram prob-abilities in addition to the condition of 3.
(With changing the value of the weight co-efficient ?
and as ?
= 0)5.2.2 Experimental ResultThe experimental result is shown in Figure 4.63.7% as the recall and 48.2% as the precisionwere obtained by the inference based on theabove method 1 (i.e.
?
= 0), and 62.6% and58.6% were done in the method 2 (i.e.
?
= 1.0).On the other hand , in the experiment on themethod 3, the precision became the maximumby ?
= 0.2, providing 61.0%, and the recall by?
= 0.3 was 67.2%.
The result shows our tech-nique of using both information on morphologyand dependency to be effective.When ?
?
0.3, the precision of the method3 became lower than that of 1.
This is becausethe user speaks with driving a car (Kawaguchiet al, 2000) and therefore there are much com-paratively short utterances in the in-car speechcorpus.
Since there is a few dependencies perTable 1: Intention tags and their utterance examplesintention tag utterance examplesearch Is there a Japanese restaurant near here?request Guide me to McDonald?s.parking lot question Is there a parking lot?distance question How far is it from here?nearness question Which is near here?restaurant menu question Are Chinese noodles on the menu?Morphological &IntensionIntensionActionDependency analysisShopinformationdatabaseSearchResponseinferencegenerationIn-carspokendialoguecorpus withintension tags CalculationIntensions 2-gramprobabilityWeightingDictionary &parsing rulesIntension-actiontransfer rulesContextstackDecisionAnalysisResultsUser?s UtteranceSystem?s utteranceFigure 6: Configuration of the prototype systemone utterance, a lot of sentences in the corpustend to have the maximum value in inferenceusing dependency information.Next, the experimental result of the inferenceusing weight assignment by intentions 2-gramprobabilities, when considering as ?
= 0.3, isshown in Figure 5.
At ?
= 0.8, the maximumvalues in both precision and recall were provided(i.e., the precision is 68.9%).
This shows ourtechnique of learning the context informationfrom the spoken dialogue corpus to be effective.6 In-car Spoken Dialogue SystemIn order to confirm our technique for automat-ically inferring the intentions of the user?s ut-terances to be feasible and effective for task-oriented spoken dialogue processing, a proto-type system for restaurant retrieval has beendeveloped.
This section describes the outline ofthe system and its evaluation.6.1 Implementation of the SystemThe configuration of the system is shown in Fig-ure 6.Table 2: Comparison between the results on in-ferred intentions and those on given intentionsInferred GivenIntentions num.
rate num.
rateCorrect 31 51.7% 42 70.0%Partially corr.
5 8.3% 4 6.7%Incorrect 7 11.7% 2 3.3%No action 17 28.3% 12 20.0%1.
Morphological and dependency anal-ysis: For the purpose of example-basedspeech understanding, the morphologicaland dependency analyses are given to eachuser?s utterance by referring the dictionaryand parsing rules.
Morphological analy-sis is executed by Chasen (Matsumoto etal., 99).
Dependency parsing is done basedon a statistical approach (Matsubara et al,2002).2.
Intentions inference: As section 3 and4 explain, the intention of the user?s ut-terance is inferred according to the degreeof similarity of it with each sentence in acorpus, and the intentions 2-gram proba-bilities.3.
Action: The transfer rules from theuser?s intentions to the system?s actionshave been made so that the system canwork as the user intends.
We have al-ready made the rules for all of 78 kindsof intentions.
The system decides the ac-tions based on the rules, and executesthem.
After that, it revises the contextstack.
For example, if a user?s utteranceis ?kono chikaku-ni washoku-no mise ari-masu-ka (Is there a Japanese restaurantnear here?
)?, its intention is ?search?.
In-ferring it, the system retrieves the shopinformation database by utilizing the key-words such as ?washoku (Japanese restau-rant)?
and ?chikaku (near)?.4.
Response generation: The system re-sponds based on templates which includethe name of shop, the number of shops, andso on, as the slots.6.2 Evaluation of the SystemIn order to confirm that by understanding theuser?s intention correctly the system can behaveappropriately, we have made an experiment onthe system.
We used 1609 of driver?s utterancesin Section 5.2.1 as the learning data, and theintentions 2-gram probabilities learned by 174of dialogues in Section 5.1.
Furthermore, 60 ofdriver?s utterances which are not included in thelearning data were used for the test.
We havecompared the results of the actions based on theinferred intentions with those based on the givencorrect intentions.
The results have been classi-fied into four groups: correct, partially correct,incorrect, and no action.The experimental result is shown in Table2.
The correct rate including partial correct-ness provides 76.7% for the giving intentionsand 60.0% for the inferred intentions.
We haveconfirmed that the system could work appropri-ately if correct intentions are inferred.The causes that the system based on givenintentions did not behave appropriately for 14utterances, have been investigated.
6 utterancesare due to the failure of keywords processing,and 8 utterances are due to that they are out ofthe system?s expectation.
It is expected for theimprovement of the transfer rules to be effectivefor the former.
For the latter, it is consideredto turn the responses such as ?I cannot answerthe question.
If the questions are about ?
?
?, Ican do that.
?7 Concluding RemarksThis paper has proposed the example-basedmethod for inferring speaker?s intention.
Theintention of each input utterance is regarded asthat of the most similar utterance in the cor-pus.
The degree of similarity is calculated basedon the degrees of correspondence in both mor-phemes and dependencies, taking account of theeffects of a sequence of the previous utterance?sintentions.
The experimental result using 1,609driver?s utterances of CIAIR in-car speech cor-pus has shown the feasibility of example-basedspeech intention understanding.
Furthermore,we have developed a prototype system of in-carspoken dialogue processing for a restaurant re-trieval task based on our method.Acknowledgement: The authors would liketo thank Dr. Hiroya Murao, Sanyo Electric Co.LTD.
for his helpful advice.
This work is par-tially supported by the Grand-in-Aid for COEResearch of the Ministry of Education, Sci-ence, Sports and Culture, Japan.
and KayamoriFoundation of Information Science Advance-ment.ReferencesAraki, M., Kimura, Y., Nishimoto, T. and Ni-imi, Y.: Development of a Machine LearnableDiscourse Tagging Tool, Proc.
of 2nd SIGdialWorkshop on Discourse and Dialogue, pp.
20?25 (2001).The Japanese Discouse Research InitiativeJDRI: Japanese Dialogue Corpus of Multi-level Annotation, Proc.
of 1st SIGdial Work-shop on Discourse and Dialogue (2000).Kawaguchi, N., Matsubara, S., Iwa, H., Ka-jita, S, Takeda, K., Itakura, F. and Inagaki,Y.
: Construction of Speech Corpus in Mov-ing Car Environment, Proc.
of ICSLP-2000,Vol.
III, pp.
362?365 (2000).Kawaguchi, N., Matsubara, S., Takeda, K.and Itakura, F.: Multimedia Data Collec-tion of In-car Speech Communication, Proc.of Eurospeech-2001, pp.
2027?2030 (2001).Kimura, H., Tokuhisa, M., Mera, K., Kai, K.and Okada, N.: Comprehension of Intentionsand Planning for Response in Dialogue, Tech-nical Report of IEICE, TL98-15, pp:25?32(1998).
(In Japanese)Matsubara, S., Murase, T., Kawaguchi, N. andInagaki, Y.: Stochastic Dependency Parsingof Spontaneous Japanese Spoken Language,Proc.
of COLING-2002 (2002).Matsumoto, Y., Kitauchi, A., Yamashita, T.and Hirano, Y.: Japanese MorphologicalAnalysis System Chasen version 2.0 Man-ual, NAIST Techinical Report, NAIST-IS-TR99009 (1999).Murao, H., Kawaguchi, N., Matsubara, S. andInagaki, Y.: Example-based Query Genera-tion for Spontaneous Speech, Proc.
of ASRU-2000 (2001).
