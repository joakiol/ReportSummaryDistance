A Preliminary Look intothe Use of Named Entity Informationfor Bioscience Text TokenizationRobert ArensDepartment of Computer ScienceUniversity of IowaIowa City, Iowa, USArobertarens@uiowa.eduAbstractTokenization in the bioscience domain is oftendifficult.
New terms, technical terminology, andnonstandard orthography, all common inbioscience text, contribute to this difficulty.This paper will introduce the tasks oftokenization, normalization before introducingBAccHANT, a system built for bioscience textnormalization.
Casting tokenization /normalization as a problem of punctuationclassification motivates using machine learningmethods in the implementation of this system.The evaluation of BAccHANT's performanceincluded error analysis of the system'sperformance inside and outside of namedentities (NEs) from the GENIA corpus, whichled to the creation of a normalization systemtrained solely on data from inside NEs,BAccHANT-N.
Evaluation of this new systemindicated that normalization systems trained ondata inside NEs perform better than systemstrained both inside and outside NEs, motivatinga merging of tokenization and named entitytagging processes as opposed to the standardpipelining approach.1 IntroductionFor the purposes of this paper, a token can be defined asthe smallest discrete unit of meaning in a documentrelevant to the task at hand, the smallest entity ofinformation that cannot be further reduced in form andstill carry that information.
This definition of a token isdependent on both the type of information we wish toextract from a document, and the nature of the documentitself; that is, tokenization is task-specific.
For example,tokenizing technical reports in order to search them bykeyword may require a conservative tokenizationscheme; e.g.
a document containing the term "2.0-gigahertz processor" would not want to tokenize "2.0"away from "gigahertz" for fear that the document wouldbe missed if the user searched for that exact phrase.However, if the same set of documents was beingtokenized to build a database of processor speeds, "2.0"would need to be tokenized away from "gigahertz" inorder to store its speedTokenization is often straightforward; discoveringthe words in the sentence, "I saw a cat."
is not difficult,as the tokens are bounded by punctuation, includingspace characters.
However, discovering the words in thesentence, "I studied E. coli in a 2.5% solution."
presentssome problems.
The period following ?E.?
is being usedto indicate an acronym instead of a sentence boundary,and must be recognized as such.
Even if we were not toconcern ourselves with sentence boundaries, decidingthat any period simply ends a token, the sentence wouldagain present a problem since we would not want totokenize the 2 from the 5 in "2.5".The difficulty in tokenization stems from ambiguouspunctuation.
In order to tokenize, one must be able totell with certainty when a piece of punctuation ends atoken.The bioscience domain presents additionaldifficulties to tokenizing.
Bioscience literature containstechnical terminology and includes ambiguouspunctuation, similar to the E. coli sentence above.
Thedomain is dynamic, with thousands of researchersadding to the literature (the MEDLINE database addsapproximately 400,000 new entries consisting of journalarticles and abstracts per year (MEDLINE Fact Sheet,2002)).
Bioscience literature contains heterogeneousorthographics; for example, the literature contains theterms "NF-kappaB", "NF-kappa B", and "NF-kappa-B,"and while each refers to the same protein, tokenizersusing spaces and dashes as breaking criteria will return adifferent tokenization of each term though one standardtokenization would be preferable.The problem of nonstandard orthography is ofparticular importance for document retrieval.
Considerthe NF-kappaB example above; if a document repositorycontains documents with different orthographic versionsof NF-kappaB, a researcher searching for NF-kappaBwould have to search for all possible orthographicvariations and would miss documents containingunanticipated orthography.
Normalization attempts tosolve this problem by removing orthographic variationfrom tokens, bringing them to one normalized form.
Forexample, if all three versions of NF-kappaB had allspaces and dashes removed, all three would look like?NFkappaB,?
and a document retrieval system wouldfind all instances in a search.
A related strategy, queryexpansion, attempts to solve the same problem byaccounting for as many orthographic variants of the userquery as possible, and searching for all of them.Normalization acts as a special case of tokenization bydeciding which instances of punctuation break a token,and removing all punctuation that does not break thetoken in order to bring it to a normalized form.The remainder of this paper will consider workrelevant to tokenization and normalization for thebioscience domain.
Casting tokenization, and byextension normalization, as a classification problemmotivates the creation of BAccHANT, a machinelearning system designed to normalize bioscience text.Evaluation of this system includes an evaluation of thesystem's performance inside and outside of namedentities, and results from this evaluation motivate thecreation of a new system, BAccHANT-N, trained solelyon date from inside NEs.
The improvement inperformance of BAccHANT-N over BAccHANT whennormalizing inside NE text indicates that named entityinformation is useful for bioscience text tokenizationtasks, motivating future work in systems that performtokenization and NE tagging concurrently.2 Related workAs noted in Habert et al (1998), standard methods forevaluating the quality of tokens produced bytokenization systems do not exist.
Though a necessaryfirst step to tasks such as document retrieval, sentenceboundary finding, parsing, etc., there exists workinvolving these tasks that take tokenization for granted(e.g.
Chang, Schutze and Altman (2002), Seki andMostafa (2003)), mention tokenization without detailingthe tokenization scheme (e.g.
Fukuda et al (1998)), orindicate use of a tokenization system withoutmentioning its performance (e.g.
Bennet et al (1999),Yamamoto et al (2003)).
To the author's knowledge,there exists no work analyzing the impact oftokenization performance on bioinformatics tasks.Tokenization methods for bioinformatics tasks rangefrom simple to complex.
Bennet et al (1999) tokenizedfor noun phrase extraction, tokenizing based onwhitespace, with additional modification to take?specialized nomenclature?
into account.
Yamamoto etal.
(2003) developed a morphological analyzer forprotein name tagging which tokenized, part-of-speechtagged, and stemmed documents.
Seki and Mostafa(2003) essentially tokenized by dictionary lookup forprotein name extraction, using hand-crafted rules andfiltering to identify protein name candidates to checkagainst their dictionary.Relevant work on normalization can be found in theproceedings of the 2003 Text REtrieval Conference(TREC) Genomics track competition.
The competitioninvolved two tasks.
The first task was for gene orprotein X, find all MEDLINE references that focus onthe basic biology of the gene/protein from thedesignated organism.
Basic biology includes isolation,structure, genetics and function of genes/proteins innormal and disease states.
The second task was toextract GeneRIF statements from records from theMEDLINE biomedical and health abstract repository.Kayaalp et al (2003) normalized by converting allletters to lower case, and expanded queries byidentifying terms with both alphabetic and numericalcharacters and searching for hyphenated variants, i.e.JAK2 and JAK-2.
de Bruijn and Martin (2003) usedmorphological query expansion along with a relevancefeedback engine.
Osborne et al used a number of queryexpansion strategies, including appending parentheticalinformation, acronym expansions, words followinghyphens, lower and uppercase versions of terms, etc.de Brujin and Martin (2003) and Osborne et al(2003) both indicate that query expansion was beneficialto the performance of their systems.
However, noauthors gave performance measures for their queryexpansion methods independent of their final systems.To the author's knowledge, there exists no workanalyzing the performance of normalization systems forbioscience literature.Named entities are ?proper names and quantities ofinterest?
(Chinchor (1998)) in a document.
Named entitytagging involves discovering and marking these entitiesin a document, e.g.
finding all proteins in a documentand labeling them as such.
Having biomedicaldocuments tagged with NEs allows for betterinformation extraction, archival, searching, etc.
of thosedocuments.
The GENIA corpus (Kim et al (2003)) is acorpus of 2000 MEDLINE abstracts tagged for parts ofspeech and hand-tagged for NEs.
NE tags in the GENIAcorpus are based on an ontology, consisting of aminoacids, proteins, organisms and their tissues, cells, andother.3 MethodologyFrom a machine learning perspective, one way to look ata tokenization task, including normalization, is as aclassification problem.
As stated before, the problem oftokenization is that of ambiguous punctuation ?
onemust be able to tell whether or not a piece ofpunctuation should be included in a token.
A documentcan be tokenized by classifying each piece ofpunctuation in the document as part of a token or as atoken boundary.
Removing the pieces of punctuationclassified as part of the token will normalize the token.Possible features for classifying punctuation mayinclude the piece of punctuation itself, character orcharacters to the left/right of the punctuation, type ofcharacter[s] to the left/right of the punctuation (i.e.uppercase, lowercase, number, etc.
), the length of thesentence or article the term occurs in, the type ofsentence or article the term occurs in, etc.The system presented here, BAccHANT (BioscienceAnd Health Article Normalizing Tokenizer), wascreated to normalize MEDLINE text for the TRECGenomics track, as presented earlier.
It classifies piecesof punctuation in bioscience text based on thesurrounding characters, determining whether thepunctuation is a token boundary or needs to be removedfor normalization.The features chosen for BAccHANT were thefollowing: piece of punctuation being classified (Punc),character to the left of the punctuation (CL), type ofcharacter to the left of the punctuation (TL), character tothe right of the punctuation (CR), type of character tothe right of the punctuation (TR), and whether thepunctuation should be removed for normalization, orbreak the token (Class).
These features were chosen bythe author.
Feature selection using information gainratio indicated that all five should be used.Feature ValuesPunc .
,  -  (  )  /  ;  [  ]  :  \  {  }  <space>CL / CR <the character itself>TL / TR lower, cap, num, space, otherClass remove, breakTable 1: The features and their possible values.Values for Punc and CL/CR are self-explanatory.Values for TL/TR are as follows:* lower: Character is lowercase* cap: Character is a capital letter* num: Character is a number* space: Character is whitespace (space, tab, etc.
)* other: Character is none of the aboveValues for Class are as follows:* remove: The punctuation should be removed* break: The punctuation should break the tokenThe 'remove' class is of chief importance for thenormalization task, since classifying a piece ofpunctuation as 'remove' means the punctuation will beremoved for normalization.Sample feature vectors:* "NF-kappaB"  ==  ['F', -, 'k', cap, lower, remove]* "T cells" ==  ['T',  , 'c',cap, lower, remove]* "alpha gene" == ['a',  , 'g',lower, lower, break]* "yATF-binding" == ['F', -, 'b', cap, lower, break]The training / testing set for BAccHANT wasconstructed from 67 MEDLINE abstracts, handtokenized by the author using the tokenization schemepresented in the appendix.
A domain expert1 wasavailable for determining difficult tokenizations.
The 67abstracts yielded 17253 pieces of punctuation.Distributions follow.
The feature vectors created fromthe set were used to create a decision tree, implementedusing the Weka tool set (Witten and Frank).
The treeused reduced error pruning to increase accuracy.PunctuationType Total remove break<space> 14476 463 14013- 1103 737 366.
637 12 625, 577 6 571( 186 8 178) 186 7 179/ 45 7 38: 18 0 18[ 9 6 2] 9 7 2; 7 2 5Totals 17253 1255 15998Table 2: Punctuation distribution of the MEDLINEtrain/test set4 EvaluationThe baseline used for evaluation was to simply break onevery instance of punctuation; that is, assume nopunctuation needs to be removed.
This achieves anaccuracy of 92.73%, where accuracy is the percentage ofcorrectly classified punctuation.
This baseline waschosen for its high accuracy; however, as it is a simplemajority class baseline which always predicts 'break',giving it a precision score of 1, a recall score of 0, andan f-measure of 0 for the 'remove' class.BAccHANT was trained and tested using 10-foldcross-validation.
It achieved an accuracy of 96.60%,which was a statistically significant improvement overthe baseline (all significance testing was done using atwo-tailed t-test with a p-value of 0.05).
More detailedresults follow.1 Dr. Vladimir Leontiev, University of Iowa, Departmentof Anatomy and Cell BiologyClassremove breakPrecision 0.832 0.974Recall 0.668 0.989F-Measure 0.741 0.982Table 3: Precision, recall, and f-measureThe 'break' classification reached high precision andrecall.
This is unsurprising as 96.7% of all <space>punctuation classified as 'break', and <space>punctuation made up 83.9% of all punctuation.
Commasand periods were similarly easy to classify as 'break'.
Ofmore interest is the 'remove' classification, as this classindicates punctuation to be normalized.
The recall wasnot as good as was hoped, with BAccHANT discoveringroughly 2 out of every 3 instances present, though itcorrectly classified roughly 5 out of 6 instances it foundWe suspected that punctuation was being useddifferently inside of named entities vs. outside of NEs.To investigate this suspicion, we tested BAccHANT onNE data from the GENIA corpus.
The testing set createdfrom GENIA consisted wholly of character data frominside NEs.
The set contained 5798 instances ofpunctuation.
Punctuation distribution for the GENIAcorpus test set follows.PunctuationType Total remove break<space> 4849 157 4692- 304 192 112.
237 4 233, 187 2 185( 62 3 59) 62 3 59/ 14 4 10: 2 0 2[ 0 0 0] 0 0 0; 0 0 0Totals 5798 365 5433Table 4: Punctuation distribution in the GENIAcorpus test setThe accuracy of BAccHANT on this test set was90%.
More detailed results for the 'remove' class follow.BAccHANT  performanceTest Set All text GENIA corpusAccuracy 0.966 0.900Precision 0.832 0.546Recall 0.688 0.453F-Measure 0.741 0.500Table 5: Accuracy, precision, recall, and F-measurefor BAccHANT tested on all text vs. inside NEs.Precision, recall and f-measure are given for the'remove' classFurther testing revealed that accuracy outside NEswas near 99%.
The statistically significant degradationin performance of BAccHANT inside NEs vs.performance both inside and outside NEs indicates thatdata inside named entities is more difficult to normalizethan data outside named entities.These results seem to indicate that a normalizationsystem trained solely on data inside NEs could performbetter than a system trained on both named and non-named data when normalizing NEs.
A newnormalization system trained on NE data, BAccHANT-N, was built to test this.The new system was trained and tested using theGENIA corpus test set.
BAccHANT-N was createdsimilarly to BAccHANT, with identical features, andimplemented as a decision tree using reduced errorpruning.
It was trained and tested using 10-fold cross-validation and achieved an accuracy of 96.5%.
Moredetailed results follow.Classremove breakPrecision 0.833 0.980Recall 0.789 0.985F-Measure 0.811 0.983Table 6: Precision, recall, and F-measure forBAccHANT-N tested on named entity data.Below is a results summary table, giving accuracyfor both classes, and precision, recall, and f-measure forthe 'remove' class across all systems presented.BAccHANT-N showed statistically significantimprovement over BAccHANT when normalizingnamed entity data.
These results show that a systemtrained on data inside NEs shows improvement inperformance over a system trained on data from insideand outside NEs.Baseline BAccHANTTrainingsetAll Text NamedEntitiesTest set All NE All NE All NEAccuracy 0.927 0.914 0.966 0.900 0.965Precision 1 1 0.832 0.546 0.833Recall 0 0 0.688 0.453 0.789F-Measure 0 0 0.741 0.500 0.811Table 7: Results summary across all systems.Precision, recall, and f-measure are given for the'remove' class.5 Future WorkCurrently, BAccHANT looks only at one character toeither side of the piece of punctuation to be classified.By expanding the number of characters examined fromone to a certain number of characters (a window),accuracy should increase.
Since BAccHANT decisiontree learns based on context, greater context may allowfor better learning, and a window of characters willexpand context.Also, a window of characters will introduce newfeatures to learn from.
Since a decision tree's featuresdetermine how it learns from context, adding betterfeatures to the decision tree may help the tree learnbetter.
Examples of new features include:* Mixed case - does the window include bothuppercase and lowercase characters?
* Mixed type - does the window include a mix ofletters, numbers, and other character types?
* Boundary size - is there a definite token boundarywithin the character window, and if so, how far into thewindow is the boundary?Error analysis of BAccHANT on named entitytagged data led to the creation of a normalization systemtrained on data from inside NEs which performed betterthan BAccHANT, and hence would be a better choicefor normalizing inside NEs.
However, this normalizerwould necessarily need to be run on named entity taggeddata, as it has not been trained to deal with text outsideof NEs.
To accomplish this, a system to simultaneouslytag named entities and normalize at the same time wouldbe desirable.
This could be accomplished viahierarchical hidden Markov models (Fine et.
al., 1998).A system of this type involves "tiering" hidden Markovmodels within each other.
This model could be used tostatistically compute the most likely name for a sectionof text, and then normalize appropriately in one pass.
Ashidden Markov models have been used both for name-finding (Bikel et al (1997)) and tokenization (Cutting etal.
(1992)), this seems to be a promising researchpossibility.6 ConclusionThis paper has introduced a system to normalizebioscience and health articles based on learning featuressurrounding punctuation which may need to be removedfor normalization.
The system performed significantlybetter than the baseline system.By analyzing the system's performance on namedentity data from the GENIA corpus, it was discoveredthat named entities seemed to be more difficult tonormalize than surrounding non-named text.
Thisfinding led to the creation of another normalizationsystem trained on named entity data, which showedsignificant improvement over the first system whentested on named entities.
This improvement seems toindicate that a system which would compute namedentities in parallel with normalization would be useful.ReferencesNuala A. Bennet, Qin He, Kevin Powell, and Bruce R.Schatz.
1999.
Extracting noun phrases for all ofMEDLINE.
In Proceedings of the AMIA Symposium,671-65Daniel M. Bikel, Scott Miller, Richard Schwartz andRalph Weischedel.
1997.
Nymble: a High-Performance Learning Name-finder.
In Proceedingsof the Conference on Applied Natural LanguageProcessing, 1997.Stephen Blott, Cathal Gurrin, Gareth J. F. Jones, Alan F.Smeaton, and Thomas Sodring.
2003.
On the Use ofMeSH Headings to Improve Retrieval Effectiveness.In Proceedings of The 12th Text RetrievalConference, Gaithersburg, Md, November 2003.Eric W. Brown, Andrew Dolbey, Lawrence Hunter.2003.
IBM Research and the University of ColoradoTREC 2003 Genomics Track.
In Proceedings of The12th Text Retrieval Conference, Gaithersburg, Md,November 2003.Berry de Brujin, and Joel Martin.
2003.
Finding GeneFunction Using LitMiner.
In Proceedings of The 12thText Retrieval Conference, Gaithersburg, Md,November 2003.Jeffery T. Chang, Hinrich Scuhtze, and Russ B. Altman.2002.
Creating an Online Dictionary ofAbbreviations from MEDLINE.
Journal of AmericanMedical Informatics Association, 9(6): 612-620.Nancy A. Chinchor.
1998.
Overview of MUC-7/MET-2.In Proceedings of the Seventh MessageUnderstanding Conference (MUC-7).Doug Cutting, Julian Kupiec, Jan Pedersen, andPenelope Sibun.
1992.
A practical part-of-speechtagger.
In Proceedings of the Third Conference onApplied Natural Language Processing.
133-140Shai Fine, Yoram Singer, and Naftali Tishby.
1998.
Thehierarchical hidden Markov model: Analysis andapplications.
Machine Learning, 32(1):41-62Ken-ichiro Fukuda, Tatsuhiko Tsunoda, AyuchiTamura, and Toshihisa Takagi.
1998.
TowardInformation Extraction: Identifying Protein Namesfrom Biological Papers.
In Proceedings of the PacificSymposium on Biocomputing '98 (PSB'98).B.
Habert, G. Adda, M. Adda-Decker, P. Boula deMareuil, S. Ferrari, O. Ferret, G. Illouz, and P.Paroubek.
1998.
Towards Tokenization Evaluation.In Proceedings of LREC-98, 427-431.William R. Hersh and Ravi T. Bhupatiraju.
2003.
TRECGenomics Track Overview.
In Proceedings of The12th Text Retrieval Conference, Gaithersburg, Md,November 2003.Lynette Hirschman, Alexander A. Morgan, andAlexander S. Yeh.
2002.
Rutabaga by any othername: extracting biological names.
Journal ofBiomedical Informatics.
35(4): 247-259.MEDLINE Fact Sheet.
(2002).
Retrieved November 2,2003 fromhttp://www.nlm.nih.gov/pubs/factsheets/medline.htmlMehmet Kayaalp, Alan R. Aronson, Susanne M.Humphrey, Nicholas C. Ide, Lorraine K. Tanabe,Lawrence H. Smith, Dina Demner, Russell R. Loane,James G. Mork, and Olivier Bodenreidera.
2003.Methods for accurate retrieval of MEDLINE citationsin functional genomics.
In Proceedings of The 12thText Retrieval Conference, Gaithersburg, Md,November 2003.Jun'ichi Kazama, Takaki Makino, Yoshihiro Ohta,Jun'ichi Tsujii.
2002.
Tuning Support VectorMachines for Biomedical Named Entity Recognition.In Proceedings of the Workshop on NaturalLanguage Processing in the Biomedical Domain.
1-8.Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi and Jun-ichiTsujii.
2003.
GENIA corpus ?
a semanticallyannotated corpus for bio-textmining.
Bioinformatics,19(1):180-182.Andrei Mikheev.
2003.
Text Segmentation.
In R.Mitkov (Ed.
), The Oxford Handbook ofComputational Linguistics (pp.
201-218).
New York:Oxford University Press, Inc.Miles Osborne, Jeffrey Chang, Mark Cumiskey, NipunMehra, Veronica Rotemberg, Gail Sinclair, MatthewSmillie, Russ B. Altman, and Bonnie Webber.
2003.Edinburgh-Stanford TREC 2003 Genomics Track:Notebook Paper.
In Proceedings of The 12th TextRetrieval Conference, Gaithersburg, Md, November2003.David D. Palmer.
1994.
Satz - An Adaptive SentenceSegmentation System.
M.S.
Thesis and UC-BerkeleyTechnical Report UCB/CSD 94-846.Kazuhiro Seki and Javed Mostafa.
2003.
An Approachto Protein Name Extraction using Heuristics and aDictionary.
Retrieved November 11, 2003, fromlair.indiana.edu/research/capris/papers/lair03-04.pdfLorraine Tanabe and W. John Wilbur.
2002.
TaggingGene and Protein Names in Full Text Articles.
InProceedings of the Workshop on Natural LanguageProcessing in the Biomedical Domain.
9-13.Ian H. Witten and Eibe Frank.
1999.
Data Mining:Practical Machine Learning Tools and Techniqueswith Java Implementations.
San Francisco: MorganKaufman Publishers.Kaoru Yamamoto, Taku Kudo, Akihiko Konagaya, andYuji Matsumoto.
2003.
Protein Name Tagging forBiomedical Annotation in Text.
In Proceedings ofthe ACL 2003 Workshop on Natural LanguageProcessing in Biomedicine, pp.
65-72.Appendix - Hand tokenizing MEDLINEabstracts for normalizationThe goal of this tokenization scheme is to processplain-text MEDLINE abstracts into a tokenized goldstandard.
The format will be one token per line, withbreaking punctuation occupying a line by itself.The rule of thumb for tokenizing in this fashion is,include only punctuation critical for the unique namingof proteins, genes, compounds, etc.
found in bioscienceliterature.
Else, the punctuation should be broken on.Expanded forms of acronyms present an ambiguityproblem for tokenization.
While we want to keep theacronym ?NF-kappa B?
as one token, its expanded form?nuclear factor-kappa beta?
should be tokenized on allpunctuation.
While the heterogeneous orthography of?NF-kappa B?
must be taken into account since ?NF-kappaB?
and ?NF-kappa-B?
both appear in theliterature, the literature does not contain instances of?nuclearfactor-kappa beta?
or ?kappabeta?.Dashes represent the greatest punctuation ambiguityin the literature, with two out of three instances beingremoved for normalization.
In particular, break if:* there is a prefix before the dash, as in ?anti-DNA?or ?non-IL?.
* the dash indicates a number range, as in ?1-3hours?.
* the token candidate following the dash is somekind of modifying noun, gerund or adjective as in ?REL-binding?
or ?Duffy-negative?.
* there are multiple dashes stringing a number oftokens together, as in ?neck-spine-torso axis?.
* the dash indicates a negative number.The gold standards used for training and testing areavailable from the author by request, or by download at:http://que.info-science.uiowa.edu/~bob/name-gold(data from inside named entities)http://que.info-science.uiowa.edu/~bob/all-gold(data from inside and outside named entities)
