Template-Filtered Headline SummarizationLiang Zhou and Eduard HovyUSC Information Sciences Institute4676 Admiralty WayMarina del Rey, CA 90292-6695{liangz, hovy}@isi.eduAbstractHeadline summarization is a difficult task be-cause it requires maximizing text content inshort summary length while maintaining gram-maticality.
This paper describes our first attempttoward solving this problem with a system thatgenerates key headline clusters and fine-tunesthem using templates.1    IntroductionProducing headline-length summaries is a chal-lenging summarization problem.
Every word be-comes important.
But the need forgrammaticality?or at least intelligibility?
some-times requires the inclusion of non-content words.Forgoing grammaticality, one might compose a?headline?
summary by simply listing the mostimportant noun phrases one after another.
At theother extreme, one might pick just one fairly in-dicative sentence of appropriate length, ignoringall other material.
Ideally, we want to find a bal-ance between including raw information and sup-porting intelligibility.We experimented with methods that integratecontent-based and form-based criteria.
The proc-ess consists two phases.
The keyword-clusteringcomponent finds headline phrases in the begin-ning of the text using a list of globally selectedkeywords.
The template filter then uses a collec-tion of pre-specified headline templates and sub-sequently populates them with headline phrases toproduce the resulting headline.In this paper, we describe in Section 2 previouswork.
Section 3 describes a study on the use ofheadline templates.
A discussion on the process ofselecting and expanding key headline phrases is inSection 4.
And Section 5 goes back to the idea oftemplates but with the help of headline phrases.Future work is discussed in Section 6.2    Related WorkSeveral previous systems were developed to ad-dress the need for headline-style summaries.A lossy summarizer that ?translates?
news sto-ries into target summaries using the ?IBM-style?statistical machine translation (MT) model wasshown in (Banko, et al, 2000).
Conditional prob-abilities for a limited vocabulary and bigram tran-sition probabilities as headline syntaxapproximation were incorporated into the transla-tion model.
It was shown to have worked surpris-ingly well with a stand-alone evaluation ofquantitative analysis on content coverage.
The useof a noisy-channel model and a Viterbi search wasshown in another MT-inspired headline summari-zation system (Zajic, et al, 2002).
The methodwas automatically evaluated by BiLingual Evalua-tion Understudy (Bleu) (Papineni, et al, 2001)and scored 0.1886 with its limited length model.A nonstatistical system, coupled with linguisti-cally motivated heuristics, using a parse-and-trimapproach based on parse trees was reported in(Dorr, et al, 2003).
It achieved 0.1341 on Bleuwith an average of 8.5 words.Even though human evaluations were con-ducted in the past, we still do not have sufficientmaterial to perform a comprehensive comparativeevaluation on a large enough scale to claim thatone method is superior to others.3    First Look at the Headline TemplatesIt is difficult to formulate a rule set that defineshow headlines are written.
However, we may dis-cover how headlines are related to the templatesderived from them using a training set of 60933(headline, text) pairs.3.1 Template CreationWe view each headline in our training corpus as apotential template.
For any new text(s), if we canselect an appropriate template from the set and fillit with content words, then we will have a well-structured headline.
An abstract representation ofthe templates suitable for matching against newmaterial is required.
In our current work, we buildtemplates at the part-of-speech (POS) level.3.2 Sequential Recognition of TemplatesWe tested how well headline templates overlapwith the opening sentences of texts by matchingPOS tags sequentially.
The second column of Ta-ble 1 shows the percentage of files whose POS-level headline words appeared sequentially withinthe context described in the first column.Text Size Files from corpus (%)First sentence 20.01First two sentences 32.41First three sentences 41.90All sentences 75.55Table 1: Study on sequential template matchingof a headline against its text, on training data3.3 Filling Templates with Key WordsFilling POS templates sequentially using tagginginformation alone is obviously not the most ap-propriate way to demonstrate the concept of head-line summarization using template abstraction,since it completely ignores the semantic informa-tion carried by words themselves.Therefore, using the same set of POS headlinetemplates, we modified the filling procedure.Given a new text, each word (not a stop word) iscategorized by its POS tag and ranked within eachPOS category according to its tf.idf weight.
Aword with the highest tf.dif weight from that POScategory is chosen to fill each placeholder in atemplate.
If the same tag appears more than oncein the template, a subsequent placeholder is filledwith a word whose weight is the next highest fromthe same tag category.
The score for each filledtemplate is calculated as follows:score _ t(i) =W jj =1N?| desired _ len - template _ len |+1where score_t(i) denotes the final score assignedto template i of up to N placeholders and Wj is thetf.idf weight of the word assigned to a placeholderin the template.
This scoring mechanism preferstemplates with the most desirable length.
Thehighest scoring template-filled headline is chosenas the result.4    Key Phrase SelectionThe headlines generated in Section 3 are gram-matical (by virtue of the templates) and reflectsome content (by virtue of the tf.idf scores).
Butthere is no guarantee of semantic accuracy!
Thisled us to the search of key phrases as the candi-dates for filling headline templates.
Headlinephrases should be expanded from single seedwords that are important and uniquely reflect thecontents of the text itself.
To select the best seedwords for key phrase expansion, we studied sev-eral keyword selection models, described below.4.
1 Model SelectionBag-of-Words Models1) Sentence Position Model: Sentence positioninformation has long proven useful in identifyingtopics of texts (Edmundson, 1969).
We believethis idea also applies to the selection of headlinewords.
Given a sentence with its position in text,what is the likelihood that it would contain thefirst appearance of a headline word:Count _ Posi = P(Hk |W j)j =1N?k=1M?P(Posi) =Count _ PosiCount _ PosQi =1Q?Over all M texts in the collection and over allwords from the corresponding M headlines (eachhas up to N words), Count_Pos records the num-ber of times that sentence position i has the firstappearance of any headline word Wj.
P(Hk | Wj) isa binary feature.
This is computed for all sentencepositions from 1 to Q.
Resulting P(Posi) is a tableon the tendency of each sentence position contain-ing one or more headlines words (without indicat-ing exact words).2) Headline Word Position Model: For eachheadline word Wh , it would most likely first ap-pear at sentence position Posi:P(Posi |Wh) =Count(Posi,Wh )Count(PosQ,Wh )i=1Q?The difference between models 1 and 2 is thatfor the sentence position model, statistics werecollected for each sentence position i; for theheadline word position model, information wascollected for each headline word Wh.3) Text Model: This model captures the correla-tion between words in text and words in headlines(Lin and Hauptmann, 2001):P(Hw |Tw) =(doc _ tf (w, j) ?
title _ tf (w, j))j =1M?doc _ tf (w, j)j=1M?doc_tf(w,j) denotes the term frequency of word win the j th document of all M documents in the col-lection.
title_tf(w,j) is the term frequency of wordw in the j th title.
Hw and Tw are words that appear inboth the headline and the text body.
For each in-stance of Hw and Tw pair, Hw = Tw.4) Unigram Headline Model: Unigram probabili-ties on the headline words from the training set.5) Bigram Headline Model: Bigram probabilitieson the headline words from the training set.Choice on Model CombinationsHaving these five models, we needed to determinewhich model or model combination is best suitedfor headline word selection.
The blind data wasthe DUC2001 test set of 108 texts.
The referenceheadlines are the original headlines with a total of808 words (not including stop words).
The evalua-tion was based on the cumulative unigram overlapbetween the n top-scoring words and the referenceheadlines.
The models are numbered as in Section4.1.
Table 2 shows the effectiveness of eachmodel/model combination on the top 10, 20, 30,40, and 50 scoring words.Clearly, for all lengths greater than 10,  sen-tence position (model 1) plays the most importantrole in selecting headline words.
Selecting the top50 words solely based on position informationmeans that sentences in the beginning of a text arethe most informative.
However, when we are wor-Model(s) 10w 20w 30w 40w 50w1 2 3 4 5  79 118 147 189 2162 3 4 5  74 110 145 178 2061 3 4 5  74 116 146 176 2081 2 4 5  63 99 144 176 2021 2 3 5  87 122 155 187 2231 2 3 4  96 149 187 214 2303 4 5  61 103 134 170 1992 4 5  54 94 137 168 1922 3 5  82 117 148 183 2122 3 4  67 119 167 192 2171 4 5  55  101 126 149 1931 3 5  84 113 144 181 2161 3 4  97 144 186 212 2341 2 5  70 102 146 179 2081 4 5  55 101 126 149 1931 2 3  131 181 205 230 2504 5  46 84 117 140 1823 5 72 107 134 166 2043 4 58 103 136 165 1962 5 62 96 135 172 2042 4 38 80 114 144 1792 3  100 150 187 215 2351 5 72 98 139 158 2031 4 69 111 144 169 1931 3 154 204 244 271 2921 2 74 138 174 199 2325 58 84 114 140 1714 35 60 87 111 1363 86 137 169 208 2272 45 94 135 163 1971 113 234 275 298 310Table 2: Results on model combinationsking with a more restricted length requirement,text model (model 3) adds advantage to the posi-tion model (highlighted, 7th from the bottom ofTable 2).
As a result, the following combinationof sentence position and text model was used:P(H |Wi) = P(H | Posi )?
P(Hw i |Twi )4.2    Phrase Candidates to Fill TemplatesSection 4.1 explained how we select headline-worthy words.
We now need to expand them intophrases as candidates for filling templates.
As il-lustrated in Table 2 and stated in (Zajic et al,2002), headlines from newspaper texts mostly usewords from the beginning of the text.
Therefore,we search for n-gram phrases comprising key-words in the first part of the story.
Using themodel combination selected in Section 4.1, 10top-scoring words over the whole story are se-lected and highlighted in the first 50 words of thetext.
The system should have the ability of pullingout the largest window of top-scoring words toform the headline.
To help achieve grammatical-ity, we produced bigrams surrounding each head-line-worthy word (underlined), as shown in Figure1.
From connecting overlapping bigrams insequence, one sees interpretable clusters of wordsforming.
Multiple headline phrases are consideredas candidates for template filling.
Using a set ofhand-written rules, dangling words were removedfrom the beginning and end of each headlinephrase.5   Filling Templates with Phrases5.1    MethodKey phrase clustering preserves text content, butlacks the complete and correct representation forstructuring phrases.
The phrases need to gothrough a grammar filter/reconstruction stage togain grammaticality.A set of headline-worthy phrases with their cor-responding POS tags is presented to the templatefilter.
All templates in the collection are matchedagainst each candidate headline phrase.
Strict tagmatching produces a small number of matchingtemplates.
To circumvent this problem, a moregeneral tag-matching criterion, where tags belong-ing to the same part-of-speech category can bematched interchangeably, was used.Headline phrases tend to be longer than most ofthe templates in the collection.
This results in onlypartial matches between the phrases and the tem-plates.
A score of fullness on the phrase-templatematch is computed for each candidate template fti:fti =length (t i) + matched _ length(hi )length(t i) + length(h i)ti is a candidate template and hi is a headlinephrase.
The top-scoring template is used to filtereach headline phrase in composing the final multi-phrase headline.
Table 3 shows a random selec-tion of the results produced by the system.Generated HeadlinesFirst Palestinian airlines flight depart Gaza?s airportJerusalem/ suicide bombers targeted market Friday setting blastsU.S.
Senate outcome apparently rests small undecided voters.Brussels April 30 European parliament approved Thursday joincurrency mechanismHong Kong strong winds Sunday killing 150 / Philippines leav-ing hundreds thousands homelessChileans wish forget years politics repressionTable 3: System-generated headlines.
A headlinecan be concatenated from several phrases, sepa-rated by ?/?s5.2   EvaluationIdeally, the evaluation should show the system?sperformance on both content selection and gram-maticality.
However, it is hard to measure thelevel of grammaticality achieved by a systemcomputationally.
Similar to (Banko, et al, 2000),we restricted the evaluation to a quantitativeanalysis on content only.Our system was evaluated on previously unseenDUC2003 test data of 615 files.
For each file,headlines generated at various lengths were com-pared against i) the original headline, and ii) head-lines written by four DUC2003 human assessors.The performance metric was to count term over-laps between the generated headlines and the teststandards.Table 4 shows the human agreement and theperformance of the system comparing with thetwo test standards.
P and R are the precision andrecall scores.The system-generated headlines were also evalu-ated using the automatic summarization evalua-tion tool ROUGE (Recall-Oriented Understudyfor Gisting Evaluation) (Lin and Hovy,Figure 1: Surrounding bigrams for top-scoringwordsAllegations  of police  racism  and   brutalityhave   shaken this city that for decades hasprided itself on a progressive attitude towardcivil  rights    and a reputation for racialharmony.
The death of  two blacks   at   adrug   raid   that went awry, followed 10 dayslater by a scuffle between police and?Assessors?
GeneratedP R Length(words)P R9 0.1167 0.156612 0.1073 0.2092Original0.34290.233613 0.1075 0.22989 0.1482 0.135112 0.1365 0.1811Assessors?0.21860.218613 0.1368 0.1992Table 4: Results evaluated using unigram over-lap2003).
The ROUGE score is a measure of n-gramrecall between candidate headlines and a set ofreference headlines.
Its simplicity and reliabilityare gaining audience and becoming a standard forperforming automatic comparative summarizationevaluation.
Table 5 shows the ROUGE perform-ance results for generated headlines with length 12against headlines written by human assessors.6    Conclusion and Future WorkGenerating summaries with headline-length re-striction is hard because of the difficulty ofsqueezing a full text into a few words in a read-able fashion.
In practice, it often happens in orderto achieve the optimal informativeness, grammati-cal structure is overlooked, and vice versa.
In thispaper, we have described a system that was de-signed to use two methods, individually had ex-hibited exactly one of the two types of unbalances,and integrated them to yield content and gram-maticality.Structural abstraction at the POS level is shownto be helpful in our current experiment.
However,part-of-speech tags do not generalize well and failto model issues like subcategorization and otherlexical semantic effects.
This problem was seenfrom the fact that there are half as many templatesas the original headlines.
A more refined patternlanguage, for example taking into account namedentity types and verb clusters, will further improveperformance.
We intend to incorporate additionalnatural language processing tools to create a moresophisticated and richer hierarchical structure forheadline summarization.ReferencesMichele Banko, Vibhu Mittal, and Michael Wit-brock.
2000.
Headline generation based on sta-tistical translation.
In ACL-2000, pp.
318-325.Bonnie Dorr, David Zajic, and Richard Schwartz.2003.
Hedge trimmer: a parse-and-trim ap-proach to headline generation.
In Proceedingsof Workshop on Automatic  Summarization,2003.H.
P. Edmundson.
1969.
New methods in auto-matic extracting.
Journal of the ACM ,16(2):264?285.Chin-Yew Lin and Eduard Hovy.
2003.
Auto-matic evaluation of summaries using n-gramco-occurrence statistics.
In HLT-NAACL 2003,pp.150?157.Rong Lin and Alexander Hauptmann.
2001.
Head-line generation using a training corpus.
InCICLING 2000.Kishore Papineni, Salim Roukos, Todd Ward, andWei-Jin Zhu.
2001.
IBM research report Bleu: amethod for automatic evaluation of machinetranslation.
In IBM Research Division Techni-cal Report, RC22176 (W0109-22).David Zajic, Bonnie Dorr, and Richard Schwartz.2002.
Automatic headline generation for news-paper stories.
In Proceedings of the ACL-2002Workshop on Text Summarization.Human GeneratedUnigrams 0.292 0.169Bigrams 0.084 0.042Trigrams 0.030 0.0104-grams 0.012 0.002Table 5: Performance on ROUGE
