Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 1065?1072Manchester, August 2008An Integrated Probabilistic and Logic Approach to Encyclopedia RelationExtraction with Multiple Features?Xiaofeng YU Wai LAMInformation Systems LaboratoryDepartment of Systems Engineering & Engineering ManagementThe Chinese University of Hong KongShatin, N.T., Hong Kong{xfyu,wlam}@se.cuhk.edu.hkAbstractWe propose a new integrated approach based onMarkov logic networks (MLNs), an effective com-bination of probabilistic graphical models and first-order logic for statistical relational learning, to ex-tracting relations between entities in encyclopedicarticles from Wikipedia.
The MLNs model en-tity relations in a unified undirected graph col-lectively using multiple features, including contex-tual, morphological, syntactic, semantic as well asWikipedia characteristic features which can cap-ture the essential characteristics of relation extrac-tion task.
This model makes simultaneous statisti-cal judgments about the relations for a set of relatedentities.
More importantly, implicit relations canalso be identified easily.
Our experimental resultsshowed that, this integrated probabilistic and logicmodel significantly outperforms the current state-of-the-art probabilistic model, Conditional RandomFields (CRFs), for relation extraction from encyclo-pedic articles.1 IntroductionRelation extraction is a growing area of researchthat discovers various predefined semantic relations(e.g., visited, associate, and executive) between en-tity pairs in text.
As a subtask in Information Ex-traction (IE), this problem has generated much in-terest and has been formulated as part of MessageUnderstanding Conferences (MUC) and AutomaticContent Extraction (ACE) Evaluation.Reliably extracting relations between entities innatural-language documents is still a difficult, un-solved problem.
A large number of engineeredsystems were developed for identifying relationsof interest.
Recent approaches to this problem in-?The work described in this paper is substantially sup-ported by grants from the Research Grant Council of the HongKong Special Administrative Region, China (Project Nos:CUHK4193/04E and CUHK4128/07) and the Direct Grant ofthe Faculty of Engineering, CUHK (Project Codes: 2050363and 2050391).
This work is also affiliated with the Microsoft-CUHK Joint Laboratory for Human-centric Computing andInterface Technologies.?c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported license(http://creativecommons.org/licenses/by-nc-sa/3.0/).
Somerights reserved.clude statistical parsing (Miller et al, 2000), lo-gistic regression (Kambhatla, 2004), feature-basedmethods (Zhou et al, 2005; Toru et al, 2007),and kernel methods (Zelenko et al, 2003; Culottaand Sorensen, 2004; Bunescu and Mooney, 2005,2006).In text, this usually amounts to examining pairsof entities in a document and determining whethera relation exists between them.
In general, theabove approaches to relation extraction suffer fromthe following three difficulties: (1) enumeratingall pairs of entities, even when restricted to pairswithin a sentence, results in a low density of pos-itive relation examples, (2) these approaches as-sume that relations only exist within document, andclassify them independently without consideringdependencies between entities.
However, this as-sumption does not hold in practice, and ignoringdependencies between entities may lead to reducedperformance, and (3) implicit relations can hardlybe discovered in these models since they generallyexist in cross document and they are only impliedby the text.
And these are the sorts of relationson which current extraction models perform mostpoorly.In this paper we propose a new integrated ap-proach based on Markov logic networks (MLNs)to extracting relations between entities in Englishencyclopedic articles from Wikipedia.
We pre-dict only relations between the principal entity andeach mentioned secondary entity in Wikipedia ar-ticles.
By anchoring one argument of relationsto be the principal entity, we alleviate the diffi-culty of enumerating all pairs of entities in a doc-ument.
This approach can incorporate rich depen-dencies between entities by modeling entity rela-tions in a coherent undirected graph in a collectivemanner, and make simultaneous statistical judg-ments about the relations for a set of related enti-ties.
It can also exploit relational autocorrelation,a widely observed characteristic of relational data1065in which the value of a variable for one instance ishighly correlated with the value of the same vari-able on another instance.
We show how a vari-ety of well-engineered features can be easily andconcisely formulated as first-order logic and incor-porated into MLNs, and we show how implicit re-lations can be easily discovered in this modeling.We apply Gibbs sampling, a widely used Markovchain Monte Carlo (MCMC) algorithm, to performcollective inference in MLNs.
Experimental re-sults showed that this model yields substantiallybetter results on encyclopedia relation extractionover the current state-of-the-art probabilistic rela-tion extraction model, such as Conditional RandomFields (CRFs).2 WikipediaWikipedia1is the world?s largest free online ency-clopedia, representing the outcome of a continuouscollaborative effort of a large number of volunteercontributors.
Virtually any Internet user can cre-ate or edit a Wikipedia webpage, and this ?freedomof contribution?
has a positive impact on both thequantity (fast-growing number of articles) and thequality (potential mistakes are quickly correctedwithin the collaborative environment) of this onlineresource.
Currently Wikipedia has approximately9.25 million articles in more than 200 languages.We investigate the task of discovering seman-tic relations between entity pairs from Wikipedia?sEnglish encyclopedic articles.
The basic entry inWikipedia is an article, which mainly defines anddescribes an entity (also known as principal en-tity) or an event, and consists of a hypertext docu-ment with hyperlinks to other pages within or out-side Wikipedia.
This document mentions someother entities as secondary entities related to theprincipal entity (Culotta et al, 2006).
All theentities are hyper-linked within the text, and thetopic of an article usually defines the principal en-tity.
Moreover, Wikipedia has the category hier-archy structure which is used to classify articlesaccording to their content.
All these characteris-tics makeWikipedia an appropriate resource for thetask of relation extraction.
In this paper, we predictonly relations between the principal entity and eachmentioned secondary entity.An illustrative example of Wikipedia article isshown in Figure 2, where the principal entityAlbert Einstein is boxed and in italic font, and sec-1http://www.wikipedia.org/Albert EinsteinAlbert Einstein (March 14, 1879 - April 18, 1955) was a the-oretical physicist.
He was born in Germany.
His father wasHermann Einstein, a salesman and engineer, and his motherwas Pauline Einstein.
In 1880, the family moved to Munich.Albert attended a Catholic elementary school and finally hewas enrolled in the mathematics program at ETH Zurich.
Ein-stein received the Nobel Prize in Physics for his services toTheoretical Physics in 1921.Figure 1: An example of Wikipedia article for rela-tion extraction.
The principal entity is boxed and initalic font, and secondary entities are in italic font.ondary entities are in italic font.
Our goal is topredict what relation, if any, each secondary entityhas to the principal entity.
For example, there is ajob title relation between theoretical physicist andAlbert Einstein and a father relation between Her-mann Einstein and Albert Einstein , but no relationbetween salesman and Albert Einstein .3 Relation Extraction as SequenceLabeling: A Baseline ApproachNote that our goal is to extract relations betweenthe principal entity and each mentioned secondaryentity in Wikipedia?s English encyclopedic articles.This formulation allows us to view relation extrac-tion as a sequence labeling task such as part-of-speech tagging.
Motivated by this observation, wetherefore apply Conditional Random Fields (CRFs)(Lafferty et al, 2001), a probabilistic graphicalmodel that has been successfully employed on se-quence labeling tasks with state-of-the-art perfor-mance.
By using the CRF model, each secondaryentity?s label is its relation to the principal entity,and we can capture the dependency between ad-jacent labels.
For example, in the dataset it iscommon to see phrases such as ?
Albert Einstein(1879 - 1955) was born in Germany?
for whichthe labels birth year, death year, and birth placeoccur consecutively.
Sequence models are specifi-cally designed to handle these kinds of dependen-cies.
The modeling flexibility of CRFs permitsthe feature functions to be complex, arbitrary, non-independent, and overlapping features of the inputwithout requiring additional assumptions, allowingthe multiple features described in Section 5 to bedirectly exploited.
To avoid overfitting, we penal-ized the log-likelihood by the commonly used zero-mean Gaussian prior over the parameters.
Thisgives us a competitive baseline CRF model for re-lation extraction.10664 Markov Logic Networks for CollectiveRelation ExtractionMarkov logic networks (MLNs) conduct statisti-cal relational learning (SRL) by incorporating theexpressiveness of first-order logic into the flexibil-ity of probabilistic graphical models under a singlecoherent framework (Richardson and Domingos,2006).
An MLN consists of a set of weighted for-mulae and provides a way of softening first-orderlogic by making situations, in which not all for-mulae are satisfied, less likely but not impossible.More formally, the probability distribution of a par-ticular truth assignment x to X specified by theground Markov network ML,C2is given byP (X = x) =1Zexp(?wini(x ))=1Z?
?i(x{i})ni(x)(1)where X is the set of all propositions describinga world x (i.e.
all gliterals formed by groundingthe predicates with the constants in the domain),F is the set of all clauses in the MLN, wiis theweight associated with clause Fi?
F , ni(x) is thenumber of true groundings of Fiin x, x{i}is thetrue value of the atoms appearing in Fi, Z is thenormalizing partition function, ?iis a real-valuedpotential function and ?i(x{i})= ewi.MLNs model the relation extraction task in acollective manner and take into account the rela-tion types of related entities.
Note that this is dif-ferent from other relation extraction methods thatpredict relations independently without consider-ing the relationship between entities.
Attributes canbe represented in MLNs as predicates of the formA(x, v), where A is an attribute, x is an entity, andv is the value of A in x.
The relation is a desig-nated attribute C, representable by C(x, v), wherev is x?s relation.
The relations of different entitiesdepend on each other.
Classification is now simplythe problem of inferring the truth value of C(x, v)for all x and v of interest given all known A(x, v).In this collective modeling, the Markov blanket ofC(xi, v) includes other C(xj, v), even after condi-tioning on the known A(x, v).
Relations betweenentities are represented by predicates of the formR(xi, xj).2The graphical structure of ML,Cis that: there is an edgebetween two nodes of ML,Ciff the corresponding groundatoms appear together in at least one grounding of one first-order formula.4.1 Weight LearningGiven a relational database and a set of first-orderlogic, the weight of each clause can in principle belearned very efficiently by maximizing the pseudo-log-likelihood of this database on the closed worldassumption using the limited-memory BFGS algo-rithm (Liu and Nocedal, 1989).
These weights re-flect how often the clauses are actually observed inthe training data.To estimate the weights, we maximize the loga-rithm of the conditional likelihood of the trainingdata?
(xh,xo)?Tlog(p(Xh= xh|Xo= xo))(2)where Xhis a list of possible variables and xharethe corresponding values in the observation.
Xhcontains all variables referring to possible groundatoms of entity relations.
Xois the set of variablescorresponding to all possible instantiations of thepredicates.
T is the set of training observations(xh, xo).
For relation extraction, Equation 2 canbe rewritten asp(Xh= xh|Xo= xo) =?Entity pairs(p,q)p(Xe(p,q)= xe(p,q)|Xg(p,q)= xg(p,q))(3)where Xe(p,q)corresponds to the ground atoms,and Xg(p,q)is a list of all variables correspondingto predicates.With Equation 3, the conditional likelihood inEquation 2 simplifies to?
(xh,xo)?T?Entity pairs(p,q)log(p(xe(p,q)|xg(p,q))).
(4)where p(x|y) is the abbreviation for p(X = x|Y =y).
To calculate the conditional likelihood, we havep(xe(p,q)|xg(p,q))=p(xe(p,q), xg(p,q))p(1, xg(p, q))+ p(0, xg(p, q))(5)During MLN weight learning, each first-orderformula is converted to Conjunctive Normal Form(CNF).
The probabilities of all formulae collec-tively determine all weights, if we view themas empirical probabilities and learn the maximumlikelihood weights.
Conversely, the weights in alearned MLN can be viewed as collectively encod-ing the empirical formula probabilities.10674.2 InferenceIn order to perform inference over a given MLN,one needs to ground it into its correspondingMarkov network (Pearl, 1988).
A large numberof efficient inference techniques are applicable andthe most widely used approximate solution to prob-abilistic inference in MLNs is Markov chain MonteCarlo (MCMC) (Gilks et al, 1996).
One such al-gorithm to perform collective inference is calledGibbs sampling.
Gibbs sampling starts by assign-ing a truth value to each query gliteral (a groundliteral, i.e.
one that contains only ground terms).
Itthen proceeds in rounds to re-sample a value forgliteral X , given the truth values of its Markovblanket MBX(i.e.
the nodes with which it par-ticipates in ground clauses).5 Feature SetWe describe the features used in our model.
Thesefeatures have been shown to be very effective forrelation extraction.Contextual features: Bag-of-words consisting of4 words to the left and right of the target entity.Part-of-Speech: Part-of-speech tags are obtainedusing the Stanford POS Tagger3, which used richknowledge sources and features in a log-linearmodel.
POS tags with a window size of 4 aroundthe target entity are used.Morphological features: Such as whether the en-tity is capitalized or contains digits or punctuation,whether the entity ends in some suffixes such as-eer and -ician, etc.Syntactic features: Syntactic information can leadto significant improvements in extraction accuracy(e.g., Culotta and Sorensen (2004), Bunescu andMooney (2005)).
The POS-tagged corpus issubmitted to the Stanford Lexicalized DependencyParser4which generates a dependency parse treefor each sentence and assigns word positions toeach word.
This parser can also output grammati-cal relations (typed dependency).
The grammaticalrelations are of the form relation(reli, wi, wj),where reliis one of the fixed set of relationsassigned by the parser, and wiand wjare twowords.
The dependency paths, which contain therelevant terms describing the relations between theentity pairs, can be easily extracted.
We design aset of first-order formulae that captures some of themost important syntactic phenomena for relation3http://nlp.stanford.edu/software/tagger.shtml4http://nlp.stanford.edu/software/lex-parser.shtmlTable 1: Representative relation types and corre-sponding keywords.Relation Keywordsjob title secretary, writer, novelist, captain, cartoon-ist, actor, actress, physicist, mathematician,singer, naturalist, architect, musician, physi-cian, professor, journalist, banker, business-man, producer, philosopher, workervisited from, to, in, at, near, along, visitedassociate work for, along with, together with, performwith, work with, colleague, struck withmember of member of, serve in, serve at, serve with, se-lect to, campaign for, election to, involve in,captain with, play for, fellow of, enteropus sitcom, picture, film, teleplay, novel, essay,comedy, autobiography, show, movie, plot,drama, painting, book, cartoon, song, musiceducation university, academy, school, college, insti-tuteexecutive lead, head, leader, president, chairman, com-mittee, executive, officer, mayor, prince,chair, governorbirth place born in, born at, birthdeath place bury in, died in, died at, pass away, internationality American, English, Irish, French, Italian,Australian, Canadian, Jewish, Russianaward award, medal, fellowship, prize, pennant,scholarshipparticipant during, throughextraction.Entity features: Important entities are hyper-linked within the text, but they are not classified bytype.
Entity type is very helpful for relation extrac-tion.
For instance, the relation between a personand a location should be visited, birth place,death place, etc., but cannot be executive, founder,etc.
We identify named entities (person, locationand organization) by applying the Stanford NamedEntity Recognizer5, a CRF based sequence label-ing model coupled with well-engineered featuresincluding additional distributional similarity fea-tures.
The model is trained on data from CoNLL,MUC-6, MUC-7, and ACE, making it fairly robustin practice.
Types of other entities (e.g., date, year,and month) can be well classified by rule-basedapproach due to their relatively fixed forms.Keyword features: Some keywords providecrucial clues for relationships between entity pairs.Consider the following sentence:Bill Gates is the founder of the Microsoft Corpo-ration.If Bill Gates is the principal entity and Microsoftis the secondary entity, the keyword founder im-plies that there is a founder relation between them.Similarly, the executive relation may be implied by5http://nlp.stanford.edu/software/CRF-NER.shtml1068keywords lead, head, leader, president, chairman,executive officer, director, and administrator.Moreover, it is particularly interesting that someentities indicate their relation types to correspond-ing principal entities.
Entities containing keywordssuch as secretary, writer, novelist or actor show ajob title relation to their principal entities.
We ex-ploit tf-idf approach to co-occurrence (collocation)analysis for keyword extraction.
Tf-idf is used tomeasure the relevance of words with a windowsize of 8 to each relation between entity pairs.
Andthen we rank the relevance scores with respect toeach relation and choose keywords with scoreshigher than the user-defined threshold.Semantic features: Due to data sparseness, tf-idfmodel might be unsatisfactory to extract sufficientkeywords.
We employ WordNet (Fellbaum, 1998),an online lexical database, to extend and enricheach keyword candidate to its synonyms (synsets).For example, the keyword university for relationeducation is extended to the set {university,academy, college, institute}.
Table 1 shows somerepresentative relation types and keywords usingtf-idf method and semantic extension.Wikipedia characteristic features: Relationsonly exist between principal entities and secondaryentities.
There is no relation between any twoprincipal entities p, q or two secondary entities x, y.6 First-Order Logic RepresentationAll the features described in Section 5 can be eas-ily and concisely represented by first-order for-mulae, which are used during the MLN learning.First-order formulae are recursively constructedfrom atomic formulae using logical connectivesand quantifiers.
Atomic formulae are constructedusing constants, variables, functions, and predi-cates.
We give a couple of examples here.For contextual features, it is common to seetwo secondary entities x and y occur consecu-tively, accompanied by conjunctions such as ?and?or punctuation such as ?,?, then probably thetwo entities may have the same relation to theprincipal entity p. This can be written in first-order logic form as occur conse(x,y) ?same relation(x,y).
For morphologicalfeatures, suffixes such as -eer and -ician mayprobably show a job title relation to the princi-pal entity p. We therefore can easily write downthe logic person(p) ?
job suffix(x) ?job title(x,p) to capture this information.Entity features can be represented using somefirst-order formulae such as:person(p)?location(x) ?
visited(x,p) ?
birth place(x,p) ?
death place(x,p)person(p)?location(x) ?
!executive(x,p)?!founder(x,p).
The formula founder key(x,p) ?
founder relation(x,p)can be used for keyword features.
AndWikipedia characteristic features can be welland easily expressed by the logic principal(p)?
principal(q) ?
no relation(p,q)and secondary(x) ?
secondary(y) ?no relation(x,y).It is worth noticing that some features can becombined in first-order logic formulation.
For ex-ample, person(p) ?
organization(x) ?
founder key(x,p) ?
founder relation(x,p)means if there is a founder keyword betweena person and an organization, probably there is afounder relation between them.7 Implicit Relation ExtractionImplicit relations are those that do not have directcontextual evidence.
Implicit relations generallyexist in different paragraphs, or even across doc-uments.
They require additional knowledge to bedetected.
Notably, these are the sorts of relationsthat are likely to have significant impact on per-formance.
A system that can accurately discoverknowledge that is implied by the text will effec-tively provide access to the implications of a cor-pus.
Unfortunately, extracting implicit relations ischallenging even for current state-of-the-art rela-tion extraction models.We show that MLNs can enable this technol-ogy.
By employing the first-order logic formalism,the implicit relations can be easily discovered fromtext.
Since these formulae will not always hold,we would like to handle them probabilistically byestimating the confidence of each formula.
OneTable 2: Examples of first-order logic for implicitrelation extraction.wife(x,y)?
husband(y,x)father(x,y)?
son(y,x) ?
daughter(y,x)brother(x,y)?
brother(y,x) ?
sister(y,x)husband(x,y) ?
daughter(z,x)?
mother(y,z)father(x,y) ?
father(y,z)?
grandfather(x,z)founder(x,y) ?
superior(x,z)?
employer(z,y)associate(x,y) ?
member of(x,z)?
member of(y,z)executive(x,y) ?
member of(z,y)?
superior(x,z)1069of the benefits of the MLN probabilistic extractionmodel is that confidence estimates can be straight-forwardly obtained.Consider the following 2 sentences in Wikipediaarticles:1.
On November 4, 1842 Abraham Lincolnmarried Mary Todd.2.
Abraham Lincoln had a son named RobertTodd Lincoln and he was born in Springfield,Illinois on 1 August 1843.State-of-the-art extraction models may be able todetect the wife relation between Mary Todd andAbraham Lincoln , and the son relation betweenRobert Todd Lincoln and Abraham Lincoln suc-cessfully from local contextual clues.
However,in the descriptive article of Robert Todd Lincolnin Wikipedia, Robert Todd Lincoln becomes theprincipal entity, and the mother relation betweenMary Todd and Robert Todd Lincoln is only im-plied by the text and it is an implicit relation.First-order formalism allows the representation ofdeep and relational knowledge.
Using the logicwife(x,y) ?
son(z,y) ?
mother(x,z),the relational knowledge in the above example canbe easily captured to infer the implicit relation.These formulae are generally simple, and captureimportant knowledge for implicit relation extrac-tion.
Examples of first-order logic to infer implicitrelations are listed in Table 2.8 Experiments8.1 DataWe use the same dataset as in (Culotta et al, 2006)to conduct our experiments.
This dataset consistsof 1127 paragraphs from 441 pages from the on-line encyclopedia Wikipedia with 4701 relation in-stances and 53 relation types labeled.
Table 3shows the relation types and corresponding fre-quencies of this dataset.This dataset was split into training and testingsets (70%-30% split), attempting to separate the en-tities into connected components.
There are stilloccasional paths connecting entities in the trainingset to those in the testing set, and we believe thismethodology reflects a typical real-world scenario.8.2 Results and DiscussionWe design 38 first-order logic formulae (15 for-mulae are used for implicit relation extraction) toTable 3: Statistics of relation types and correspond-ing frequencies.Relation Frequency Relation Frequencyjob title 379 daughter 35visited 368 husband 33birth place 340 religion 32associate 326 influence 31birth year 287 underling 27member of 283 sister 20birth day 283 grandfather 20opus 267 ancestor 19death year 210 grandson 18death day 199 inventor 15education 185 cousin 13nationality 148 descendant 11executive 127 role 10employer 111 nephew 9death place 93 uncle 6award 86 supported person 6father 84 granddaughter 6participant 81 owns 4brother 71 great grandson 4son 68 aunt 4associate competition 58 supported idea 3wife 57 great grandfather 3superior 54 gpe competition 3mother 50 brother in law 2political affiliation 44 grandmother 1friend 43 discovered 1founder 43 Overall 4701construct the structure of MLNs.
Using the fea-tures described in Section 5, we train MLNs usinga Gaussian prior with zero mean and unit varianceon each weight to penalize the pseudo-likelihood,and with the weights initialized at the mode ofthe prior (zero).
The features specify a groundMarkov network (e.g., ground atoms) containingone feature for each possible grounding of a first-order formula.
Inference is performed for answer-ing the query predicates, given the evidence pred-icates and other relations that can be deterministi-cally derived.
We apply Gibbs sampling to predictrelations of entity pairs simultaneously.Table 4 presents the performance of our rela-tion extraction system based on MLNs comparedto CRFs for different types of relations.
We usethe same set of features for both MLNs and CRFs.For MLNs, all the features are represented usingfirst-order logic.
It shows that the MLN system per-forming collective relation prediction and integrat-ing implicit relation extraction yields substantiallybetter results, leading to an improvement of up to1.84% on the overall F-measure over the currentstate-of-the-art CRF model.
The improvement isstatistically significant (p < 0.05 with a 95% con-fidence interval) according to McNemar?s pairedtests.As shown in Table 4, the performance variesgreatly from different relation types.
Both of thetwo systems perform quite well on 4 relations:death day, death year, birth day, and birth year.1070Table 4: Comparative relation extraction performance.
Both CRFs and MLNs are tested on the same setof features in Section 5.CRFs MLNsRelation Precision Recall F?=1Precision Recall F?=1death day 100.00% 94.74% 97.30 98.85% 96.00% 97.40death year 98.21% 94.83% 96.49 98.14% 95.18% 96.64birth year 95.12% 95.12% 95.12 94.59% 95.68% 95.13birth day 93.90% 95.06% 94.48 93.20% 95.80% 94.48nationality 88.37% 95.00% 91.57 88.10% 95.02% 91.43birth place 86.81% 92.94% 89.77 87.78% 93.32% 90.47job title 87.07% 91.82% 89.38 87.63% 91.55% 89.55death place 89.47% 80.95% 85.00 91.66% 82.99% 87.11education 72.41% 89.36% 80.00 75.11% 90.22% 81.97father 70.97% 88.00% 78.57 71.88% 89.82% 79.85wife 72.22% 81.25% 76.47 72.30% 81.75% 76.74award 94.12% 61.54% 74.42 80.88% 66.49% 72.98mother 81.82% 64.29% 72.00 80.89% 69.33% 74.67political affiliation 100.00% 53.33% 69.57 85.66% 57.12% 68.54husband 66.67% 60.00% 63.16 67.39% 62.48% 64.84visited 66.29% 55.14% 60.20 66.70% 55.83% 60.78daughter 66.67% 54.55% 60.00 63.67% 59.00% 61.25founder 81.82% 47.37% 60.00 77.39% 52.63% 62.65member of 59.32% 49.30% 53.85 60.91% 51.66% 55.90executive 64.00% 44.44% 52.46 60.20% 48.48% 53.71superior 66.67% 42.11% 51.61 60.55% 44.23% 51.12brother 50.00% 46.67% 48.28 48.80% 48.57% 48.68opus 68.00% 33.33% 44.74 50.55% 44.75% 47.47son 50.00% 39.13% 43.90 49.30% 41.55% 45.09associate 42.28% 45.22% 43.70 40.77% 47.89% 44.04participant 41.67% 23.81% 30.30 31.98% 26.05% 28.71employer 46.67% 21.21% 29.17 47.78% 27.33% 34.77associate competition 23.08% 20.00% 21.43 24.38% 20.42% 22.22religion 100.00% 8.33% 15.38 15.55% 10.23% 12.34friend 0 0 0 50.38% 42.33% 46.01sister 0 0 0 34.66% 20.55% 25.80grandfather 0 0 0 23.74% 16.56% 19.51grandson 0 0 0 20.01% 13.39% 16.04cousin 0 0 0 22.00% 7.13% 10.77other types 0 0 0 0 0 0Overall 73.57% 64.20% 68.57 74.70% 66.58% 70.41Since these relations can be easily identified us-ing the distinct contextual evidence.
However,some relations (e.g., role, owns, etc.)
can hardlybe extracted.
One possible reason is the lack oftraining data (these relations occur rarely in thedataset).
Among all the 53 relation types in thedataset, MLNs successfully extract 34 relations,while CRFs can only detect 29.
For all the 34 rela-tions listed in Table 4, MLNs outperform CRFs on27 types of them.
It is particularly interesting thatMLNs can successfully predict relations friend, sis-ter, grandfather, grandson, and cousin, whereasCRFs cannot.
CRFs perform relation extractionsequentially without considering connections be-tween entities.
This may lead to the label incon-sistency problem.
For example, CRF sometimesfails to label the father relation between George H.W.
Bush and George W. Bush .
Implicit relationscan hardly be investigated in this sequence label-ing model.
These disadvantages limit the ability ofCRFs for relation extraction to a large extent.9 Related WorkOnly a few research work has attempted relationextraction from Wikipedia.
Culotta et al (2006)proposed a probabilistic model based on CRFsto integrate extraction and data mining tasks per-formed on biographical Wikipedia articles.
Rela-tion extraction was treated as a sequence labelingproblem and relational patterns were discovered toboost the performance.
However, this model ex-tracts relations without considering dependenciesbetween entities, and the best reported F-measure is67.91, which is significantly (by 2.5%) lower thanour MLN system when evaluated on the same train-ing and testing sets.
Nguyen et al (2007b,a) pro-posed a subtree mining approach to extracting rela-tions from Wikipedia by incorporating information1071from the Wikipedia structure and by the analysis ofWikipedia text.
In this approach, a syntactic treethat reflects the relation between a given entity pairwas built, and a tree-mining algorithm was used toidentify the basic elements of syntactic structure ofsentences for relations.
This approach mainly relieson syntactic structures to extract relations.
Syntac-tic structures are important for relation extraction,but insufficient to extract relations accurately.
Theobtained F-measure was only 37.76, which showsthat there is a large room for improving.
To thebest of our knowledge, our approach is the first at-tempt at using MLNs for relation extraction fromWikipedia which achieves state-of-the-art perfor-mance.We mention some other related work.
Bunescuand Mooney (2007) presented an approach to ex-tract relations from the Web using minimal super-vision.
Rosenfeld and Feldman (2007) presenteda method for improving semi-supervised relationextraction from the Web using corpus statistics onentities.
Our work is different from these researchwork.
We investigate supervised relation extractionfromWikipedia based on probabilistic and logic in-tegrated graphical models.10 ConclusionWe summarize the contribution of this paper.
First,we propose a new integrated model based onMLNs, which provide a natural and systematic wayby modeling entity relations in a coherent undi-rected graph collectively and integrating implicitrelation extraction easily, to extract relations in en-cyclopedic articles from Wikipedia.
Second, wedesign multiple features which can be conciselyformulated by first-order logic and exploit the col-lective inference algorithm (Gibbs sampling) topredict relations between entity pairs simultane-ously.
Third, our system achieved significantly bet-ter results compared to the current state-of-the-artprobabilistic model for relation extraction from en-cyclopedic articles.Having established this relation extractionmodel, our next step will be to evaluate it on largerdatasets, where we expect collective relation ex-traction and implicit relation discovery to be evenmore interesting.ReferencesRazvan C. Bunescu and Raymond J. Mooney.
A shortest pathdependency kernel for relation extraction.
In Proceedingsof HLT-EMNLP 2005, pages 724?731, Vancouver, BritishColumbia, Canada, 2005.Razvan C. Bunescu and Raymond J. Mooney.
Subsequencekernels for relation extraction.
In Y. Weiss, B. Sch?olkopf,and J. Platt, editors, Advances in Neural Information Pro-cessing Systems 18, pages 171?178.
MIT Press, Cam-bridge, MA, 2006.Razvan C. Bunescu and Raymond J. Mooney.
Learning toextract relations from the Web using minimal supervision.In Proceedings of ACL-07, pages 576?583, Prague, CzechRepublic, June 2007.Aron Culotta and Jeffrey Sorensen.
Dependency tree ker-nels for relation extraction.
In Proceedings of ACL-04,Barcelona, Spain, 2004.Aron Culotta, Andrew McCallum, and Jonathan Betz.
Inte-grating probabilistic extraction models and data mining todiscover relations and patterns in text.
In Proceedings ofHLT-NAACL 2006, pages 296?303, New York, 2006.Christiane Fellbaum, editor.
WordNet: An Electronic LexicalDatabase.
The MIT Press, 1998.W.R.
Gilks, S. Richardson, and D.J.
Spiegelhalter.
Markovchain Monte Carlo in practice.
Chapman and Hall, Lon-don, UK, 1996.Nanda Kambhatla.
Combining lexical, syntactic, and semanticfeatures with maximum entropy models for extracting rela-tions.
In Proceedings of ACL-04, Barcelona, Spain, 2004.John Lafferty, Andrew McCallum, and Fernando Pereira.Conditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proceedings ofICML-01, pages 282?289.
Morgan Kaufmann, San Fran-cisco, CA, 2001.Dong C. Liu and Jorge Nocedal.
On the limited memoryBFGS method for large scale optimization.
MathematicalProgramming, 45:503?528, 1989.Scott Miller, Heidi Fox, Lance Ramshaw, and RalphWeischedel.
A novel use of statistical parsing to extract in-formation from text.
In Proceedings of NAACL-2000, pages226?233, Seattle, Washington, 2000.Dat P. T. Nguyen, Yutaka Matsuo, and Mitsuru Ishizuka.
Re-lation extraction from Wikipedia using subtree mining.
InProceedings of AAAI-07, pages 1414?1420, Vancouver,British Columbia, Canada, 2007.Dat P. T. Nguyen, Yutaka Matsuo, and Mitsuru Ishizuka.
Sub-tree mining for relation extraction from Wikipedia.
In Pro-ceedings of HLT-NAACL 2007, pages 125?128, Rochester,New York, 2007.Judea Pearl.
Probabilistic reasoning in intelligent systems:Networks of plausible inference.
Morgan Kaufmann Pub-lishers Inc., San Francisco, CA, 1988.Matthew Richardson and Pedro Domingos.
Markov logic net-works.
Machine Learning, 62(1-2):107?136, 2006.Benjamin Rosenfeld and Ronen Feldman.
Using corpus statis-tics on entities to improve semi-supervised relation extrac-tion from the Web.
In Proceedings of ACL-07, pages 600?607, Prague, Czech Republic, June 2007.Hirano Toru, Matsuo Yoshihiro, and Kikui Genichiro.
Detect-ing semantic relations between named entities in text usingcontextual features.
In Proceedings of ACL-07, pages 157?160, Prague, Czech Republic, June 2007.Dmitry Zelenko, Chinatsu Aone, and Anthony Richardella.Kernel methods for relation extraction.
Journal of MachineLearning Research, 3:1083?1106, 2003.Guodong Zhou, Jian Su, Jie Zhang, andMin Zhang.
Exploringvarious knowledge in relation extraction.
In Proceedings ofACL-05, pages 427?434, Ann Arbor, Michigan, 2005.1072
