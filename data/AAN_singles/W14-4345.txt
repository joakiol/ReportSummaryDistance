Proceedings of the SIGDIAL 2014 Conference, pages 332?336,Philadelphia, U.S.A., 18-20 June 2014.c?2014 Association for Computational LinguisticsSequential Labeling for Tracking Dynamic Dialog StatesSeokhwan Kim, Rafael E. BanchsHuman Language Technology DepartmentInstitute for Infocomm ResearchSingapore 138632{kims,rembanchs}@i2r.a-star.edu.sgAbstractThis paper presents a sequential labelingapproach for tracking the dialog states forthe cases of goal changes in a dialog ses-sion.
The tracking models are trained us-ing linear-chain conditional random fieldswith the features obtained from the resultsof SLU.
The experimental results showthat our proposed approach can improvethe performances of the sub-tasks of thesecond dialog state tracking challenge.1 IntroductionA dialog manager is one of the key componentsof a dialog system, which aims at determining thesystem actions to generate appropriate responsesto users.
To make the system capable of conduct-ing a dialog in a more natural and effective man-ner, the dialog manager should take into accountnot only a given user utterance itself, but alsothe dialog state which represents various conver-sational situations obtained from the dialog ses-sion progress.
Dialog state tracking is a sub-taskof dialog management that analyzes and maintainsthis dialog state at each moment.
The major ob-stacle to dialog state tracking is that the inputs tothe tracker are likely to be noisy because of theerrors produced by automatic speech recognition(ASR) and spoken language understanding (SLU)processes which are required to be performed priorto the tracking.Thus, many researchers have focused on im-proving the robustness of dialog state trackersagainst ASR and SLU errors.
The simplest waysto tackle this problem have been based on hand-crafted rules mainly on the confidence scores ob-tained from ASR and SLUmodules (Nakano et al.,1999; Wang and Lemon, 2013).
However, theseapproaches have the limitation that building thequality rules manually is expensive and, what isworse, the confidence scores could be unreliableand inconsistent in some cases.The other direction of dialog state tracking ap-proaches have utilized statistical machine learn-ing techniques to obtain the distribution over a setof hypotheses.
Although the most widely studiedapproaches have been based on generative mod-els (Williams and Young, 2007; Williams, 2010;Young et al., 2010; Thomson and Young, 2010;Gas?ic?
and Young, 2011; Raux and Ma, 2011), re-cently, some researchers have reported that dis-criminative models (Bohus and Rudnicky, 2006;Lee, 2013; Zilka et al., 2013) achieved compara-ble, or even better, performances than generativemodels, especially in the tasks of the first dialogstate tracking challenge (DSTC) (Williams et al.,2013).This work focuses on the second phase ofDSTC (Henderson et al., 2014).
The major dif-ference of DSTC 2 from the previous challenge isthat user goals can be changed even in a single di-alog session.
This aspect can cause the limitationsof the previous approaches assuming the fixed usergoal for each session.
To solve this dynamic statetracking problem, we propose a sequential label-ing approach using linear-chain conditional ran-dom fields (CRFs) (Lafferty et al., 2001).
Thisapproach aims to improve the performances ofthe tracker in the case of goal changes by jointlyperforming prediction and segmentation of dialogstates.2 Problem DefinitionA dialog state defined in DSTC 2 consists of thefollowing three components: goals, method, andrequested slots.2.1 Goals TrackingGoals represent the constraint values which aretruly intended by a user at each moment.
Thesevalues can be represented by using a slot filling332UtteranceGoalsFood AreaS1Hello, How may I help you?U1I need a Persian restaurant in the south part oftown.Persian SouthS2What kind of food would you like?U2Persian.
Persian SouthS3I?m sorry but there is no restaurant serving persianfoodU3How about Portuguese food?
Portuguese SouthS4Peking restaurant is a nice place in the south oftown.U4Is that Portuguese?
Portuguese SouthS5Nandos is a nice place in the south of town servingtasty Portuguese food.U5Alright.
Whats the phone number?
Portuguese SouthS6The phone number of nandos is 01223 327908 .U6And the address?
Portuguese SouthS7Sure, nandos is on Cambridge Leisure Park CliftonWay.U7Thank you good bye.Figure 1: Examples of user goals tracking on adialog in the restaurant information domainover the following four categories: area, food,name, and price range.
Assuming the possiblevalue set for each slot is fixed, this task can beconsidered to be a problem of finding the distri-butions over these hypotheses.
While the previouschallenge aims at identifying a single fixed goalfor each session, the models for DSTC 2 shouldbe able to handle goal changes during a session,as shown in Figure 1.2.2 Method TrackingMethod tracking is performed by classifying theway of requesting information by a user into thefollowing four categories: ?by constraints?, ?by al-ternatives?, ?by name?, and ?finished?.
The prob-ability distribution over these four hypotheses iscomputed for each turn.
For example, a meth-ods sequence {byconstraints, byconstraints, byal-ternatives, byalternatives, byalternatives, byalter-natives, finished} can be obtained for the dialogsession in Figure 1.2.3 Requested Slots TrackingThe other component for dialog state tracking is tospecify the slots requested by a user.
The trackershould output the binary distributions with theprobabilities whether each slot is requested or not.Since the requestable slots are area, food, name,pricerange, addr, phone, postcode, and signature,eight different distributions are obtained at eachturn.
In the previous example dialog, ?phone?
and?addr?
are requested in the 5th and 6th turns re-spectively.
(a) Goal chain on the food slot(b) Method chain(c) Requested chain on the phone slotFigure 2: Examples of dialog state tracking as se-quential labeling with liner-chain CRFs3 MethodAlthough some discriminative approaches (Lee,2013; Zilka et al., 2013; Lee and Eskenazi, 2013;Ren et al., 2013) have successfully applied to thedialog state tracking tasks of DSTC 1 by explor-ing various features, they have limited ability toperform the DSTC 2 tasks, because the previousmodels trained based on the features mostly ex-tracted under the assumption that the user goal ina session is unchangeable.
To overcome this limi-tation, we propose a sequential labeling approachusing linear-chain CRFs for dynamic dialog statetracking.3.1 Sequential Labeling of Dialog StatesThe goal of sequential labeling is to produce themost probable label sequence y = {y1, ?
?
?
, yn}of a given input sequence x = {x1, ?
?
?
, xn},where n is the length of the input sequence, xi?X , X is the finite set of the input observation,yi?
Y , and Y is the set of output labels.
Theinput sequence for dialog state tracking at a giventurn t is defined as xt= {x1, ?
?
?
, xt}, where xidenotes the i-th turn in a given dialog session, thena tracker should be able to output a set of label se-quences for every sub-task.333For the goals and requested slots tasks, a la-bel sequence is assigned to each target slot, whichmeans the number of output sequences for thesesub-tasks are four and eight in total, respectively.On the other hand, only a single label sequence isdefined for the method tracking task.Due to discourse coherences in conversation,the same labels are likely to be located contigu-ously in a label sequence.
To detect the bound-aries of these label chunks, the BIO taggingscheme (Ramshaw and Marcus, 1999) is adoptedfor all the label sequences, which marks beginningof a chunk as ?B?, continuing of a chunk as ?I?, andoutside a chunk as ?O?.
Figure 2 shows the exam-ples of label sequences according to this schemefor the input dialog session in Figure 1.3.2 Linear Chain CRFsIn this work, all the sequential labeling tasks wereperformed by the tracking models trained usingfirst-order linear-chain CRFs.
Linear-chain CRFsare conditional probability distributions over thelabel sequences y conditioned on the input se-quence x, which are defined as follows:p (y|x) =1Z (x)n?t=1?
(yt, yt?1,x),?
(yt, yt?1,x) = ?1(yt,x) ?
?2(yt, yt?1),?1(yt,x) = exp(?k?kfk(yt,x)),?2(yt, yt?1) = exp(?k?kfk(yt, yt?1)),where Z(x) is the normalization function whichmakes that the distribution sums to 1, {fk} is a setof feature functions for observation and transition,and {?k} is a set of weight parameters which arelearnt from data.3.3 FeaturesTo train the tracking models, a set of feature func-tions were defined based on the n-best list of useractions obtained from the live SLU results at agiven turn and the system actions correspondingto the previous system output.The most fundamental information to capture auser?s intentions can be obtained from the SLU hy-potheses with ?inform?
action type.
For each ?in-form?
action in the n-best SLU results, a featurefunction is defined as follows:fi(inf, s, v) ={Si(inf, s, v), if inf(s, v) ?
UAi,0, otherwise,where Si(a, s, v) is the confidence score of thehypothesis (a, s, v) assigned by SLU for the i-thturn, a is the action type, s is the target slot, v isits value, and UAiis the n-best list of SLU results.Similarly, the actions with ?confirm?
and ?deny?types derive the corresponding feature functionsdefined as:fi(con, s, v) ={Si(con, s, v), if con(s, v) ?
UAi,0, otherwise,fi(den, s, v) ={Si(den, s, v), if den(s, v) ?
UAi,0, otherwise.In contrast with the above action types, both ?af-firm?
and ?negate?
don?t specify any target slot andvalue information on the SLU results.
The featurefunctions for these types are defined with (s, v)derived from the previous ?expl-conf?
and ?impl-conf?
system actions as follows:fi(aff, s, v) =????
?maxj(Sij(aff)) , if expl-conf(s, v) ?
SAi,or impl-conf(s, v) ?
SAi0, otherwise,fi(neg, s, v) =????
?maxj(Sij(neg)) , if expl-conf(s, v) ?
SAi,or impl-conf(s, v) ?
SAi0, otherwise,where SAiis the system actions at the i-th turn.The user actions with ?request?
and ?reqalts?could be able to play a crucial role to track therequested slots with the following functions:fi(req, s) ={Si(req, s), if req(s) ?
UAi,0, otherwise,fi(reqalts, s) ={Si(reqalts, s), if reqalts ?
UAi,0, otherwise.The other function is to indicate whether thesystem is able to provide the information on (s, v)using the ?canthelp?
actions as follows:fi(canthelp, s, v) ={1, if canthelp(s, v) ?
SAi,0, otherwise.334Dev set Test setAcc L2 ROC Acc L2 ROCJoint GoalsME 0.638 0.551 0.144 0.596 0.671 0.036CRF 0.644 0.545 0.103 0.601 0.649 0.064MethodME 0.839 0.260 0.398 0.877 0.204 0.397CRF 0.875 0.202 0.181 0.904 0.155 0.187Requested SlotsME 0.946 0.099 0.000 0.957 0.081 0.000CRF 0.942 0.107 0.000 0.960 0.073 0.000Table 1: Comparisons of dialog state tracking performances4 ExperimentTo demonstrate the effectiveness of our proposedsequential labeling approach for dialog state track-ing, we performed experiments on the DSTC 2dataset which consists of 3,235 dialog sessionson restaurant information domain which were col-lected using Amazon Mechanical Turk.
The re-sults of ASR and SLU are annotated for everyturn in the dataset, as well as the gold standardannotations are also provided for evaluation.
Weused this dataset following the original divisioninto training/development/test sets, which have1,612/506/1,117 sessions, respectively.Using this dataset, we trained two differenttypes of models: one is based on CRFs for our pro-posed sequential labeling approach; and the otheris a baseline using maximum entropy (ME) thatperforms the prediction for each individual turnseparately from others in a given session.
All themodels for both approaches were trained on thetraining set with the same feature functions de-fined in Section 3.3 using MALLET1toolkit.The trained models were used for predictinggoals, method, and requested slots of each turn inthe development and test sets, the results of whichwere then organized into a tracker output objectdefined as the input format to the evaluation scriptof DSTC 2.
Since we omitted the joint goals dis-tributions in the output, the evaluations on the jointgoals were performed on the independent combi-nations of the slot distributions.Among the various combinations of evaluationvariables listed in the results of the evaluationscript, the following three featured metrics wereselected to report the performances of the trackerin this paper: Accuracy, L2 norm, and ROC CA 5.All these metrics were computed for the predictedjoint goals, method and requested slots.1http://mallet.cs.umass.edu/Table 1 compares the performances of our pro-posed approach (CRF) and the baseline method(ME) for three sub-tasks on the development andtest sets.
The results indicate that our proposedsequential labeling approach achieved better per-formances than the baseline for most cases.
Es-pecially, CRF models produced better joint goalsand method predictions in terms of accuracy andL2 norm on both development and test sets.
Forthe requested slots task, our proposed approachfailed to generate better results than the baselineon the development set.
However, this situationwas reversed on the test set, which means our pro-posed approach achieved better performances onall three sub-tasks on the test set in two of the threeevaluation metrics.5 ConclusionsThis paper presented a sequential labeling ap-proach for dialog state tracking.
This approachaimed to solve the cases of goal changes usinglinear-chain CRFs.
Experimental results showthe merits of our proposed approach with the im-proved performances on all the sub-tasks of DSTC2 compared to the baseline which doesn?t considersequential aspects.However, these results are still not enough tobe competitive with the other participants in thechallenge.
One possible reason is that our trackerswere trained only on the very basic features in thiswork.
If we discover more advanced features thathelp to track the proper dialog states, they can raisethe overall performances further.The other direction of our future work is to inte-grate these dialog state trackers with our existingdialog systems which accept the 1-best results ofASR and SLU as they are, then to see their impactson the whole system level.335ReferencesDan Bohus and Alex Rudnicky.
2006.
A k-hypotheses+ other belief updating model.
In Proc.of the AAAI Workshop on Statistical and EmpiricalMethods in Spoken Dialogue Systems.Milica Gas?ic?
and Steve Young.
2011.
Effectivehandling of dialogue state in the hidden informa-tion state pomdp-based dialogue manager.
ACMTransactions on Speech and Language Processing(TSLP), 7(3):4.Matthew Henderson, Blaise Thomson, and JasonWilliams.
2014.
The second dialog state trackingchallenge.
In Proceedings of the SIGdial 2014 Con-ference, Baltimore, U.S.A., June.John Lafferty, Andrew McCallum, and Fernando CNPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.
In Proceedings of ICML, pages 282?289.Sungjin Lee and Maxine Eskenazi.
2013.
Recipe forbuilding robust spoken dialog state trackers: Dialogstate tracking challenge system description.
In Pro-ceedings of the SIGDIAL 2013 Conference, pages414?422.Sungjin Lee.
2013.
Structured discriminative modelfor dialog state tracking.
In Proceedings of the SIG-DIAL 2013 Conference, pages 442?451.Mikio Nakano, Noboru Miyazaki, Jun-ichi Hirasawa,Kohji Dohsaka, and Takeshi Kawabata.
1999.
Un-derstanding unsegmented user utterances in real-time spoken dialogue systems.
In Proceedings of the37th annual meeting of the Association for Compu-tational Linguistics on Computational Linguistics,pages 200?207.Lance A Ramshaw and Mitchell P Marcus.
1999.
Textchunking using transformation-based learning.
InNatural language processing using very large cor-pora, pages 157?176.
Springer.Antoine Raux and Yi Ma.
2011.
Efficient probabilistictracking of user goal and dialog history for spokendialog systems.
In Proceedings of INTERSPEECH,pages 801?804.Hang Ren,Weiqun Xu, Yan Zhang, and YonghongYan.2013.
Dialog state tracking using conditional ran-dom fields.
In Proceedings of the SIGDIAL 2013Conference, pages 457?461.Blaise Thomson and Steve Young.
2010.
Bayesianupdate of dialogue state: A pomdp framework forspoken dialogue systems.
Computer Speech & Lan-guage, 24(4):562?588.Zhuoran Wang and Oliver Lemon.
2013.
A simpleand generic belief tracking mechanism for the dia-log state tracking challenge: On the believability ofobserved information.
In Proceedings of the SIG-DIAL 2013 Conference, pages 423?432.Jason D Williams and Steve Young.
2007.
Partiallyobservable markov decision processes for spokendialog systems.
Computer Speech & Language,21(2):393?422.Jason Williams, Antoine Raux, Deepak Ramachan-dran, and Alan Black.
2013.
The dialog state track-ing challenge.
In Proceedings of the SIGDIAL 2013Conference, pages 404?413.Jason D Williams.
2010.
Incremental partition re-combination for efficient tracking of multiple dialogstates.
In Acoustics Speech and Signal Processing(ICASSP), 2010 IEEE International Conference on,pages 5382?5385.
IEEE.Steve Young, Milica Gas?ic?, Simon Keizer, Franc?oisMairesse, Jost Schatzmann, Blaise Thomson, andKai Yu.
2010.
The hidden information state model:A practical framework for pomdp-based spoken dia-logue management.
Computer Speech & Language,24(2):150?174.Lukas Zilka, David Marek, Matej Korvas, and Filip Ju-rcicek.
2013.
Comparison of bayesian discrimina-tive and generative models for dialogue state track-ing.
In Proceedings of the SIGDIAL 2013 Confer-ence, pages 452?456.336
