Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 104?108,Sydney, July 2006. c?2006 Association for Computational LinguisticsEmpirical Verification of Adjacency Pairs Using DialogueSegmentationT.
Daniel Midgley Shelly Harrison Cara MacNishDiscipline of Linguistics,University of Western Australia(dmidgley, shelley)@cyllene.uwa.edu.auSchool of Computer Science andSoftware Engineering,University of Western Australiacara@csse.uwa.edu.auAbstractA problem in dialogue research is that offinding and managing expectations.Adjacency pair theory has widespreadacceptance, but traditional classificationfeatures (in particular, ?previous-tag?type features) do not exploit thisinformation optimally.
We suggest amethod of dialogue segmentation thatverifies adjacency pairs and allows us touse dialogue-level information within theentire segment and not just the previousutterance.
We also use the ?2 test forstatistical significance as ?noisereduction?
to refine a list of pairs.Together, these methods can be used toextend expectation beyond the traditionalclassification features.1 IntroductionAdjacency pairs have had a long history indialogue research.
The pairs of question/answer,inform/backchannel, and others have been well-known ever since they were proposed by Sacksand Schegloff in 1973.
They have been used bydialogue researchers to assist in knowing ?whatcomes next?
in dialogue.Unfortunately, this dialogue information hasbeen difficult to leverage.
Most dialogue act(DA) classification research uses some kind ofdialogue history, but this usually takes the formof some kind of ?previous tag?
feature, perhapseven ?two-previous tag?.
Dialogue informationfrom three or more utterances previous is notnormally used because, in the words of oneresearcher, ?
[n]o benefit was found from usinghigher-order dialog grammars?
(Venkataramanet al 2002).
This could be due to the sparse dataproblem; more permutations means fewerrepetitions.Part of the problem, then, may lie in the waythe ?previous tag?
feature is used.
Consider thefollowing example from the Verbmobil-2 corpus(Verbmobil 2006)1:A: how does does Novemberfourteenth and fifteenth lookSUGGESTB: no REJECTHere, the second pair part occurs directly afterthe first pair part that occasioned it.
Butsometimes performance factors intervene as inthe following example, where B is engaging infloor-holding using a dialogue act annotated hereas DELIBERATE:A: so that maybe I if I need to if Ineed to order like a limo orsomethingSUGGESTB: <hes> let us see DELIBERATEB: the this is the <hes> wrongmonthDELIBERATEB: the third DELIBERATEB: let us see DELIBERATEB: I don't have anything scheduledthat morning and we areleaving at oneINFORMThe response (INFORM) finally comes, but theforgetful ?previous tag?
feature is now lookingfor what comes after DELIBERATE.What is needed is a way to not onlydetermine what is likely to happen next, but toretain that expectation over longer distanceswhen unfulfilled, until that expectation is nolonger needed.
Such information would conformmore closely to this description of aconversational game (but which could be appliedto any communicative subgoal):1For a full description of the Verbmobil speechacts, see Alexandersson 1997.104A conversational game is a sequence ofmoves starting with an initiation andencompassing all moves up until thatinitiation?s purpose is either fulfilled orabandoned.
(Carletta 1997, italics mine.
)2 Dialogue segmentationThis work grew out of related research intofinding expectations in dialogue, but we werealso interested in dialogue segmentation.Dialogues taken as a whole are very differentfrom each other, so segmentation is necessary toderive meaningful information about their parts.The question is, then, how best to segmentdialogues so as to reveal dialogue information orto facilitate some language task, such as DAclassification?Various schemes for dialogue segmentationhave been tried, including segmentation basedon fulfilment of expectation (Ludwig et al1998), and segmenting by propositionality(Midgley 2003).One answer to the question of how tosegment dialogue came from the pioneeringwork of Sacks and Schegloff (1973) article.A basic rule of adjacency pair operation is:given the recognizable production of a firstpair part, on its first possible completion itsspeaker should stop and a next speakershould start and produce a second pair partfrom the same pair type of which the first isrecognizably a member.
(p. 296, italicsmine.
)Thus, if a speaker stops speaking, it is likely thatsuch a handover has just taken place.
The lastutterance of a speaker?s turn, then, will be thepoint at which the first speaker has issued a firstpair part, and is now expecting a second pair partfrom the other speaker.
This suggests a naturalboundary.This approach was also suggested by Wright(1998), who used a ?most recent utterance byprevious speaker?
feature in her work on DAtagging.
This feature alone has boostedclassification accuracy by about 2% in ourpreliminary research, faring better than thetraditional ?previous tag?
feature used in muchDA tagging work.We collected a training corpus of 40English-speaking dialogues from theVerbmobil-2 corpus, totalling 5,170 utterances.We then segmented the dialogues into chunks,where a chunk included everything from the lastutterance of one speaker?s turn to the last-but-one utterance of the next speaker.3 Results of segmentationThis segmentation revealed some interestingpatterns.
When ranked by frequency, the mostcommon chunks bear a striking resemblance tothe adjacency pairs posited by Schegloff andSacks.Here are the 25 most common chunks in ourtraining corpus, with the number of times theyappeared.
The full list can be found at http://www.csse.uwa.edu.au/~fontor/research/chi/fullseg.txtSUGGEST:ACCEPT 176INFORM:FEEDBACK_POSITIVE 166FEEDBACK_POSITIVE:FEEDBACK_POSITIVE104FEEDBACK_POSITIVE:INFORM 97ACCEPT:FEEDBACK_POSITIVE 65FEEDBACK_POSITIVE:SUGGEST 60INFORM:INFORM 57REQUEST:INFORM 46INFORM:BACKCHANNEL 41INFORM:SUGGEST 40REQUEST_COMMENT:FEEDBACK_POSITIVE 40INIT:FEEDBACK_POSITIVE 35BYE:NONE 34ACCEPT:INFORM 32BYE:BYE 31REQUEST:FEEDBACK_POSITIVE 30POLITENESS_FORMULA:FEEDBACK_POSITIVE29REQUEST_CLARIFY:FEEDBACK_POSITIVE 28BACKCHANNEL:INFORM 28NOT_CLASSIFIABLE:INFORM 28REQUEST_SUGGEST:SUGGEST 28NONE:GREET 27SUGGEST:SUGGEST 27ACCEPT:SUGGEST 26SUGGEST:REQUEST_CLARIFY 26The data suggest a wide variety of languagebehaviour, including traditional adjacency pairs(e.g.
SUGGEST: ACCEPT), acknowledgement(INFORM: BACKCHANNEL), formalisedexchanges (POLITENESS_FORMULA:FEEDBACK_POSITIVE) offers and counter-offers (SUGGEST: SUGGEST), and it evenhints at negotiation subdialogues (SUGGEST:REQUEST_CLARIFY).However, there are some drawbacks to thislist.
Some of the items are not good examples ofadjacency pairs because the presence of the firstdoes not create an expectation for the secondhalf (e.g.
NOT_CLASSIFIABLE: INFORM).
In105some cases they appear backwards (ACCEPT:SUGGEST).
Legitimate pairs appear further downthe list than more-common bogus ones.
Forexample, SUGGEST: REJECT is a well-knownadjacency pair, but it does not appear on the listuntil after several less-worthy-seeming pairs.Keeping the less-intuitive chunks may help uswith classification, but it falls short of providingempirical verification for pairs.What we need, then, is some kind of noisereduction that will strain out spurious pairs andbring legitimate pairs closer to the top of the list.We use the well-known ?2 test for statisticalsignificance.4 The ?2 testThe ?2 test tells how the observed frequency ofan event compares with the expected frequency.For our purposes, it tells whether the observedfrequency of an event (in this case, one kind ofspeech act following a certain other act) can beattributed to random chance.
The test has beenused for such tasks as feature selection (Spitters2000) and translation pair identification (Churchand Gale 1991).The ?2 value for any two speech acts A and Bcan be calculated by counting the times that anutterance marked as tag A (or not) is followed byan utterance marked as tag B (or not), as inTable 1.Ui = A Ui ?
AUi+1 = B AB ?ABUi+1 ?
B A?B ?A?BTable 1.
Obtaining counts for ?2.These counts (as well as N, the total numberof utterances) are plugged into a variant of the ?2equation used for 2x2 tables, as in Sch?tze et al(1995).
?2=N(AB ?
?A?B - A?B ?
?AB)(AB + A?B)(AB + ?AB)(A?B + ?A?B)(?AB + ?A?B)We trained the ?2 method on the aforementionedchunks.
Rather than restrict our focus to onlyadjacent utterances, we allowed a match for pairA:B if B occurred anywhere within the chunkstarted by A.
By doing so, we hoped to reduceany acts that may have been interfering with theadjacency pairs, especially hesitation noises(usually classed as DELIBERATE) andabandoned utterances (NOT_CLASSIFIABLE).5 Results for ?2Here are the 25 pairs with the highest ?2 scores.With tail probability p = .0001, a ?2 value >10.83 is statistically significant.
The full list canbe found at http://www.csse.uwa.edu.au/~fontor/research/chi/fullchi.txt.NONE:GREET 1576.87BYE:NONE 949.89SUGGEST:ACCEPT 671.81BYE:BYE 488.60NONE:POLITENESS_FORMULA 300.46POLITENESS_FORMULA:POLITENESS_FORMULA 272.95GREET:GREET 260.69REQUEST_CLARIFY:CLARIFY 176.63CLARIFY:CLARIFY 165.76DEVIATE_SCENARIO: DEVIATE_SCENARIO159.45SUGGEST:FEEDBACK_POSITIVE 158.12COMMIT:COMMIT 154.46GREET:POLITENESS_FORMULA 111.19INFORM:FEEDBACK_POSITIVE 84.82REQUEST_SUGGEST:SUGGEST 83.17SUGGEST:REJECT 83.11THANK:THANK 76.25SUGGEST:EXPLAINED_REJECT 69.31POLITENESS_FORMULA:INIT 67.76NONE:INIT 59.97FEEDBACK_POSITIVE:ACCEPT 59.41DEFER:ACCEPT 56.07THANK:BYE 51.82POLITENESS_FORMULA:THANK 50.21POLITENESS_FORMULA:GREET 45.17Using ?2 normalises the list; low-frequency actslike REJECT and EXPLAINED_REJECT nowappear as a part of their respective pairs.These results give empirical justification forSacks and Schegloff?s adjacency pairs, andreveals more not mentioned elsewhere in theliterature, such as DEFER:ACCEPT.
As such, itgives a good idea of what kinds of speech actsare expected within a chunk.In addition, these results can be plotted into adirected acyclic graph (seen in Figure 1).
Thisgraph can be used as a sort of conversationalmap.6 Conclusions and Future WorkWe can draw some tentative conclusions fromthis work.
First of all, the dialogue segmentationcombined with the ?2 test for significance yieldsinformation about what is likely to happen, notjust for the next utterance, but somewhere in thenext chunk.
This will help to overcome thelimitations imposed by the traditional ?previous106tag?
feature.
We are working to implement thisinformation into a model where the expectationsinherent in a first pair part are retained when notimmediately fulfilled.
The expectations will alsodecay with time.Second, this approach provides empiricalevidence for adjacency pairs mentioned in theliterature on conversation analysis.
The noisereduction feature of the ?2 test gives more weightto legitimate adjacency pairs where they appearin the data.An intriguing possibility for the chunkeddata is that of chunk matching.
Nearest-neighbour algorithms are already used forclassification tasks (including DA tagging forindividual utterances), but once segmented, thedialogue chunks could be compared against eachother as a classification tool as in a nearest-neighbour algorithm.ReferencesJ.
Alexandersson, B. Buschbeck-Wolf, T.Fujinami, E. Maier, N. Reithinger, B.Schmitz, and M. Siegel.
1997.
Dialogue actsin Verbmobil-2.
Verbmobil Report 204.J.
Carletta, A. Isard, S. Isard, J. C. Kowtko, G.Doherty-Sneddon, and A. H. Anderson.1997.
The reliability of a dialogue structurecoding scheme.
Computational Linguistics,23(1):13--31.K.
W. Church and W. A. Gale.
1991.Concordances for parallel text.
InProceedings of the Seventh AnnualConference of the UW Centre for the NewOED and Text Research, pages 40?62,Oxford.D.
Midgley.
2003.
Discourse chunking: a toolfor dialogue act tagging.
In ACL-03Companion Volume to the Proceedings ofthe Conference, pages 58?63, Sapporo,Japan.E.
A. Schegloff.
and H. Sacks.
1973.
Opening upclosings.
Semiotica, 8(4):289?327.H.
Sch?tze, D. Hull, and J. Pedersen.
1995.
Acomparison of classifiers and documentrepresentations for the routing problem.
InProceedings of SIGIR ?95, pages 229?237.M.
Spitters.
2000.
?Comparing feature sets forlearning text categorization.?
In Proceedingsof RIAO 2000, April, 2000.A.
Venkataraman, A. Stolcke, E. Shriberg.Automatic dialog act labeling with minimalsupervision.
In Proceedings of the 9thAustralian International Conference onSpeech Science and Technology, Melbourne,Australia, 2002.Verbmobil.
2006.
?Verbmobil?
[online].Available <http://verbmobil.dfki.de/>.H.
Wright.
1998.
Automatic utterance typedetection using suprasegmental features.
InICSLP (International Conference on SpokenLanguage Processing) ?98.
Sydney,Australia.107Figure 1.
A directed acyclic graph using the ?2 data for the 40 highest pairs.
For any pair of connectednodes, the first node represents the last utterance in a speaker?s turn, and the second could be anyutterance in the other speaker?s turn.
The numbers are ?2 scores.
For illustrative purposes, higher ?2values are shown by bold lines.
The complete graph can be found at http://www.csse.uwa.edu.au/~fontor/research/chi/fullchart.jpg108
