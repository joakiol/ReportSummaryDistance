Name Origin Recognition Using Maximum Entropy Modeland Diverse FeaturesMin Zhang1, Chengjie Sun2, Haizhou Li1, Aiti Aw1, Chew Lim Tan3, Xiaolong Wang21Institute for InfocommResearch, Singapore{mzhang,hli,aaiti}@i2r.a-star.edu.sg2Harbin Institute ofTechnology, China{cjsun,wangxl}@insun.hit.edu.cn3National University ofSingapore, Singaporetancl@comp.nus.edu.sgAbstractName origin recognition is to identify thesource language of a personal or locationname.
Some early work used either rule-based or statistical methods with singleknowledge source.
In this paper, we cast thename origin recognition as a multi-classclassification problem and approach theproblem using Maximum Entropy method.In doing so, we investigate the use of differ-ent features, including phonetic rules, n-gram statistics and character position infor-mation for name origin recognition.
Ex-periments on a publicly available personalname database show that the proposed ap-proach achieves an overall accuracy of98.44% for names written in English and98.10% for names written in Chinese, whichare significantly and consistently better thanthose in reported work.1 IntroductionMany technical terms and proper names, such aspersonal, location and organization names, aretranslated from one language into another withapproximate phonetic equivalents.
The phonetictranslation practice is referred to as transliteration;conversely, the process of recovering a word in itsnative language from a transliteration is called asback-transliteration (Zhang et al 2004; Knightand Graehl, 1998).
For example, English name?Smith?
and ????
(Pinyin 1 : Shi-Mi-Si)?
in1 Hanyu Pinyin, or Pinyin in short, is the standard romaniza-tion system of Chinese.
In this paper, Pinyin is given next toChinese form a pair of transliteration and back-transliteration.
In many natural language process-ing tasks, such as machine translation and cross-lingual information retrieval, automatic nametransliteration has become an indispensable com-ponent.Name origin refers to the source language of aname where it originates from.
For example, theorigin of the English name ?Smith?
and its Chi-nese transliteration ????
(Shi-Mi-Si)?
is Eng-lish, while both ?Tokyo?
and ???
(Dong-Jing)?are of Japanese origin.
Following are examples ofdifferent origins of a collection of English-Chinesetransliterations.English: Richard-???
(Li-Cha-De)Hackensack-????
(Ha-Ken-Sa-Ke)Chinese: Wen JiaBao-???(Wen-Jia-Bao)ShenZhen???
(Shen-Zhen)Japanese: Matsumoto-??
(Song-Ben)Hokkaido-???
(Bei-Hai-Dao)Korean: Roh MooHyun-???(Lu-Wu-Xuan)Taejon-??
(Da-Tian)Vietnamese: Phan Van Khai-???(Pan-Wen-Kai)Hanoi-??
(He-Nei)In the case of machine transliteration, the nameorigins dictate the way we re-write a foreign word.For example, given a name written in English orChinese for which we do not have a translation inChinese characters in round brackets for ease of reading.56a English-Chinese dictionary, we first have to de-cide whether the name is of Chinese, Japanese,Korean or some European/English origins.
Thenwe follow the transliteration rules implied by theorigin of the source name.
Although all Englishpersonal names are rendered in 26 letters, theymay come from different romanization systems.Each romanization system has its own rewritingrules.
English name ?Smith?
could be directlytransliterated into Chinese as ????
(Shi-Mi-Si)?since it follows the English phonetic rules, whilethe Chinese translation of Japanese name ?Koi-zumi?
becomes ???(Xiao-Quan)?
following theJapanese phonetic rules.
The name origins areequally important in back-transliteration practice.Li et al (2007) incorporated name origin recogni-tion to improve the performance of personal nametransliteration.
Besides multilingual processing,the name origin also provides useful semantic in-formation (regional and language information) forcommon NLP tasks, such as co-reference resolu-tion and name entity recognition.Unfortunately, little attention has been given toname origin recognition (NOR) so far in the litera-ture.
In this paper, we are interested in two kindsof name origin recognition: the origin of nameswritten in English (ENOR) and the origin ofnames written in Chinese (CNOR).
For ENOR,the origins include English (Eng), Japanese (Jap),Chinese Mandarin Pinyin (Man) and Chinese Can-tonese Jyutping (Can).
For CNOR, they includethree origins: Chinese (Chi, for both Mandarin andCantonese), Japanese and English (refer to Latin-scripted language).Unlike previous work (Qu and Grefenstette,2004; Li et al, 2006; Li et al, 2007) where NORwas formulated with a generative model, we re-gard the NOR task as a classification problem.
Wefurther propose using a discriminative learningalgorithm (Maximum Entropy model: MaxEnt) tosolve the problem.
To draw direct comparison, weconduct experiments on the same personal namecorpora as that in the previous work by Li et al(2006).
We show that the MaxEnt method effec-tively incorporates diverse features and outper-forms previous methods consistently across all testcases.The rest of the paper is organized as follows: insection 2, we review the previous work.
Section 3elaborates our proposed approach and the features.Section 4 presents our experimental setup and re-ports our experimental results.
Finally, we con-clude the work in section 5.2 Related WorkMost of previous work focuses mainly on ENORalthough same methods can be extended to CNOR.We notice that there are two informative clues thatused in previous work in ENOR.
One is the lexicalstructure of a romanization system, for example,Hanyu Pinyin, Mandarin Wade-Giles, JapaneseHepbrun or Korean Yale, each has a finite set ofsyllable inventory (Li et al, 2006).
Another is thephonetic and phonotactic structure of a language,such as phonetic composition, syllable structure.For example, English has unique consonantclusters such as /str/ and /ks/ which Chinese,Japanese and Korean (CJK) do not have.Considering the NOR solutions by the use of thesetwo clues, we can roughly group them into twocategories: rule-based methods (for solutionsbased on lexical structures) and statistical methods(for solutions based on phonotactic structures).Rule-based MethodKuo and Yang (2004) proposed using a rule-based method to recognize different romanizationsystem for Chinese only.
The left-to-right longestmatch-based lexical segmentation was used toparse a test word.
The romanization system is con-firmed if it gives rise to a successful parse of thetest word.
This kind of approach (Qu and Grefen-stette, 2004) is suitable for romanization systemsthat have a finite set of discriminative syllable in-ventory, such as Pinyin for Chinese Mandarin.
Forthe general tasks of identifying the language originand romanization system, rule based approachsounds less attractive because not all languageshave a finite set of discriminative syllable inven-tory.Statistical Method1) N-gram Sum Method (SUM): Qu and Gre-fenstette (2004) proposed a NOR identifier using atrigram language model (Cavnar and Trenkle,1994) to distinguish personal names of three lan-guage origins, namely Chinese, Japanese and Eng-lish.
In their work, the training set includes 11,416Chinese name entries, 83,295 Japanese name en-tries and 88,000 English name entries.
However,the trigram is defined as the joint probabil-57ity 1 2( )i i ip c c c?
?
for 3-character 1 2i i ic c c?
?
rather thanthe commonly used conditional probabil-ity 1 2( | )i i ip c c c?
?
.
Therefore, the so-called trigramin Qu and Grefenstette (2004) is basically a sub-string unigram probability, which we refer to asthe n-gram (n-character) sum model (SUM) in thispaper.
Suppose that we have the unigram count1 2( )i i iC c c c?
?
for character substring 1 2i i ic c c?
?
, theunigram is then computed as:1 21 21 21 2,( )( )( )i i ii i ii i ii i ii c c cC c c cp c c cC c c c?
??
??
??
?= ?
(1)which is the count of character substring 1 2i i ic c c?
?normalized by the sum of all 3-character stringcounts in the name list for the language of interest.For origin recognition of Japanese names, thismethod works well with an accuracy of 92%.However, for English and Chinese, the results arefar behind with a reported accuracy of 87% and70% respectively.2) N-gram Perplexity Method (PP): Li et al(2006) proposed using n-gram character perplexitycPP  to identify the origin of a Latin-scripted name.Using bigram, the cPP is defined as:11 log ( | )2Nci i 1icp c cNcPP?=?
?=   (2)where cN is the total number of characters in thetest name, ic is the ith character in the test name.1( | )i ip c c ?
is the bigram probability which islearned from each name list respectively.
As afunction of model, cPP  measures how good themodel matches the test data.
Therefore, cPP can beused to measure how good a test name matches atraining set.
A test name is identified to belong toa language if the language model gives rise to theminimum perplexity.
Li et al (2006) shown thatthe PP method gives much better performancethan the SUM method.
This may be due to the factthat the PP measures the normalized conditionalprobability rather than the sum of joint probability.Thus, the PP method has a clearer mathematicalinterpretation than the SUM method.The statistical methods attempt to overcome theshortcoming of rule-based method, but they sufferfrom data sparseness, especially when dealingwith a large character set, such as in Chinese (ourexperiments will demonstrate this point empiri-cally).
In this paper, we propose using MaximumEntropy (MaxEnt) model as a general frameworkfor both ENOR and CNOR.
We explore and inte-grate multiple features into the discriminative clas-sifier and use a common dataset for benchmarking.Experimental results show that the MaxEnt modeleffectively incorporates diverse features to demon-strate competitive performance.3 MaxEnt Model and Features3.1 MaxEnt Model for NORThe principle of maximum entropy (MaxEnt)model is that given a collection of facts, choose amodel consistent with all the facts, but otherwiseas uniform as possible (Berger et al, 1996).
Max-Ent model is known to easily combine diverse fea-tures.
For this reason, it has been widely adoptedin many natural language processing tasks.
TheMaxEnt model is defined as:( , )11( | ) j iKf c xi jjp c xZ?== ?
(3)( , )1 1 1( | ) j iKN Nf c xi ji i jZ p c x ?= = == =?
??
(4)where ic is the outcome label, x is the given obser-vation, also referred to as an instance.
Z is a nor-malization factor.
N  is the number of outcomelabels, the number of language origins  in our case.1 2, , , Kf f fL are feature functions and1 2, , , K?
?
?L are the model parameters.
Each pa-rameter corresponds to exactly one feature and canbe viewed as a ?weight?
for the corresponding fea-ture.In the NOR task, c is the name origin label; x isa personal name, if is a feature function.
All fea-tures used in the MaxEnt model in this paper arebinary.
For example:1,    " "& (" ")( , )0,  jif c Eng x contains strf c xotherwise=?= ?
?In our implementation, we used Zhang?s maxi-mum entropy package2.3.2 FeaturesLet us use English name ?Smith?
to illustrate thefeatures that we define.
All characters in a name2 http://homepages.inf.ed.ac.uk/s0450736/maxent.html58are first converted into upper case for ENOR be-fore feature extraction.N-gram Features: N-gram features are de-signed to capture both phonetic and orthographicstructure information for ENOR and orthographicinformation only for CNOR.
This is motivated bythe facts that: 1) names written in English but fromnon-English origins follow different phonetic rulesfrom the English one; they also manifest differentcharacter usage in orthographic form; 2) nameswritten in Chinese follows the same pronunciationrules (Pinyin), but the usage of Chinese charactersis distinguishable between different language ori-gins as reported in Table 2 of (Li et al, 2007).The N-gram related features include:1) FUni: character unigram <S, M, I, T, H>2) FBi: character bigram <SM, MI, IT, TH>3) FTri: character trigram <SMI, MIT, ITH >Position Specific n-gram Features: We in-clude position information into the n-gram fea-tures.
This is mainly to differentiate surname fromgiven name in recognizing the origin of CJK per-sonal names written in Chinese.
For example, theposition specific n-gram features of a Chinesename ????(Wen-Jia-Bao)?
are as follows:1) FPUni: position specific unigram<0?
(Wen), 1?
(Jia), 2?
(Bao)>2) FPBi: position specific bigram<0??
(Wen-Jia), 1??
(Jia-Bao)>3) FPTri: position specific trigram<0???
(Wen-Jia-Bao)>Phonetic Rule-based Features: These featuresare inspired by the rule-based methods (Kuo andYang, 2004; Qu and Grefenstette, 2004) that checkwhether an English name is a sequence of sylla-bles of CJK languages in ENOR task.
We use thefollowing two features in ENOR task as well.1) FMan: a Boolean feature to indicatewhether a name is a sequence of ChineseMandarin Pinyin.2) FCan: a Boolean feature to indicate whethera name is a sequence of Cantonese Jyutping.Other Features:1) FLen: the number of Chinese characters in agiven name.
This feature is for CNOR only.The numbers of Chinese characters in per-sonal names vary with their origins.
For ex-ample, Chinese and Korean names usuallyconsist of 2 to 3 Chinese characters whileJapanese names can have up to 4 or 5 Chi-nese characters2) FFre: the frequency of n-gram in a givenname.
This feature is for ENOR only.
InCJK names, some consonants or vowelsusually repeat in a name as the result of theregular syllable structure.
For example, inthe Chinese name ?Zhang Wanxiang?, thebigram ?an?
appears three timesPlease note that the trigram and position spe-cific trigram features are not used in CNOR due toanticipated data sparseness in CNOR3.4 ExperimentsWe conduct the experiments to validate the effec-tiveness of the proposed method for both ENORand CNOR tasks.4.1 Experimental SettingOrigin #  entries Romanization SystemEng4 88,799 EnglishMan5 115,879 PinyinCan 115,739 JyutpingJap6 123,239 HepburnTable 1: DE: Latin-scripted personal name corpus forENOROrigin #  entriesEng7 37,644Chi8 29,795Jap9 33,897Table 2: DC: Personal name corpus written in Chinesecharacters for CNOR3 In the test set of CNOR, 1080 out of 2980 names of Chineseorigin do not consist of any bigrams learnt from training data,while 2888 out of 2980 names do not consist of any learnttrigrams.
This is not surprising as most of Chinese names onlyhave two or three Chinese characters and in our open testing,the train set is exclusive of all entries in the test set.4 http://www.census.gov/genealogy/names/5 http://technology.chtsai.org/namelist/6 http://www.csse.monash.edu.au/~jwb/enamdict_doc.html7 Xinhua News Agency (1992)8 http://www.ldc.upenn.edu LDC2005T349 www.cjk.org59Datasets: We prepare two data sets which are col-lected from publicly accessible sources: DE and DCfor the ENOR and CNOR experiment respectively.DE is the one used in (Li et al, 2006), consisting ofpersonal names of Japanese (Jap), Chinese (Man),Cantonese (Can) and English (Eng) origins.
DCconsists of personal names of Japanese (Jap), Chi-nese (Chi, including both Mandarin and Canton-ese) and English (Eng) origins.
Table 1 and Table2 list their details.
In the experiments, 90% of en-tries in Table 1 (DE) and Table 2 (DC) are ran-domly selected for training and the remaining 10%are kept for testing for each language origin.
Col-umns 2 and 3 in Tables 7 and 8 list the numbers ofentries in the training and test sets.Evaluation Methods: Accuracy is usually used toevaluate the recognition performance (Qu andGregory, 2004; Li et al, 2006; Li et al, 2007).However, as we know, the individual accuracyused before only reflects the performance of recalland does not give a whole picture about a multi-class classification task.
Instead, we use precision(P), recall (R) and F-measure (F) to evaluate theperformance of each origin.
In addition, an overallaccuracy (Acc) is also given to describe the wholeperformance.
The P, R, F and Acc are calculatedas following:##correctly recognized entries of the given originPentries recognized as the given origin by the system=##correctly recognized entries of the given originRentries of the given origin=2PRFP R=+##all correctly recognized entriesAccall entries=4.2 Experimental Results and AnalysisTable 3 reports the experimental results of ENOR.It shows that the MaxEnt approach achieves thebest result of 98.44% in overall accuracy whencombining all the diverse features as listed in Sub-section 3.2.
Table 3 also measures the contribu-tions of different features for ENOR by graduallyincorporating the feature set.
It shows that:1) All individual features are useful since theperformance increases consistently whenmore features are being introduced.2) Bigram feature presents the most informa-tive feature that gives rise to the highestperformance gain, while the trigram featurefurther boosts performance too.3) MaxEnt method can integrate the advan-tages of previous rule-based and statisticalmethods and easily integrate other features.FeaturesOriginP(%)R(%)FAcc(%)Eng 91.40 80.76 85.75Man 83.05 81.90 82.47Can 81.13 82.76 81.94FUniJap 87.31 94.11 90.5885.29Eng 97.54 91.10 94.21Man 97.51 98.10 97.81Can 97.68 98.05 97.86+FBiJap 94.62 98.24 96.3996.72Eng 97.71 93.79 95.71Man 98.94 99.37 99.16Can 99.12 99.19 99.15+FTriJap 96.19 98.52 97.3497.97Eng 97.53 94.64 96.06Man 99.21 99.43 99.32Can 99.41 99.24 99.33+FPUniJap 96.48 98.49 97.4798.16Eng 97.68 94.98 96.31Man 99.32 99.50 99.41Can 99.53 99.34 99.44+FPBiJap 96.59 98.52 97.5598.28Eng 97.62 94.97 96.27Man 99.34 99.58 99.46Can 99.63 99.37 99.50+FPTriJap 96.61 98.45 97.5298.30Eng 97.74 95.06 96.38Man 99.37 99.59 99.48Can 99.61 99.41 99.51+FFreJap 96.66 98.56 97.6098.35Eng 97.82 95.11 96.45Man 99.52 99.68 99.60Can 99.71 99.59 99.65+ FMan+ FCanJap 96.69 98.59 97.6398.44Table 3: Contribution of each feature for ENOR60Features Eng Jap Man CanFMan -0.357 0.069 0.072 -0.709FCan -0.424 -0.062 -0.775 0.066Table 4: Features weights in ENOR task.FeatureOriginP(%)R(%)FAcc(%)Eng 97.89 98.43 98.16Chi 95.80 95.03 95.42FUniJap 96.96 97.05 97.0096.97Eng 96.99 98.27 97.63Chi 96.86 92.11 94.43+FBiJap 95.04 97.73 96.3696.28Eng 97.35 98.38 97.86Chi 97.29 95.00 96.13+FLenJap 96.78 97.64 97.2197.14Eng 97.74 98.65 98.19Chi 97.65 96.34 96.99+FPUniJap 97.91 98.05 97.9897.77Eng 97.50 98.43 97.96Chi 97.61 96.04 96.82+FPBiJap 97.59 97.94 97.7697.56Eng 98.08 99.04 98.56Chi 97.57 96.88 97.22FUni+FLen+FPUni Jap 98.58 98.11 98.3498.10Table 5: Contribution of each feature for CNORTable 4 reports the feature weights of two fea-tures ?FMan?
and ?FCan?
with regard to differentorigins in ENOR task.
It shows that ?FCan?
haspositive weight only for origin ?Can?
while?FMan?
has positive weights for both origins?Man?
and ?Jap?, although the weight for ?Man?is higher.
This agrees with our observation that thetwo features favor origins ?Man?
or ?Can?.
Thefeature weights also reflect the fact that someJapanese names can be successfully parsed by theChinese Mandarin Pinyin system due to their simi-lar syllable structure.
For example, the Japanesename ?Tanaka Miho?
is also a sequence of Chi-nese Pinyin: ?Ta-na-ka Mi-ho?.Table 5 reports the contributions of differentfeatures in CNOR task by gradually incorporatingthe feature set.
It shows that:1) Unigram features are the most informative2) Bigram features degrade performance.
Thisis largely due to the data sparseness prob-lem as discussed in Section 3.2.3) FLen is also useful that confirms our intui-tion about name length.Finally the combination of the above three use-ful features achieves the best performance of98.10% in overall accuracy for CNOR as in thelast row of Table 5.In Tables 3 and 5, the effectiveness of each fea-ture may be affected by the order in which the fea-tures are incorporated, i.e., the features that areadded at a later stage may be underestimated.Thus, we conduct another experiment using "all-but-one" strategy to further examine the effective-ness of each kind of features.
Each time, one typeof the n-gram (n=1, 2, 3) features (including or-thographic n-gram, position-specific and n-gramfrequency features) is removed from the wholefeature set.
The results are shown in Table 6.FeaturesOriginP(%)R(%)FAcc(%)Eng 97.81 95.01 96.39Man 99.41 99.58 99.49Can 99.53 99.48 99.50w/oUni-gramJap 96.63 98.52 97.5798.34Eng 97.34 95.17 96.24Man 99.30 99.48 99.39Can 99.54 99.33 99.43w/o Bi-gramJap 96.73 98.32 97.5298.26Eng 97.57 94.10 95.80Man 98.98 99.23 99.10Can 99.20 99.08 99.14w/oTri-gramJap 96.06 98.42 97.2397.94Table 6: Effect of n-gram feature for ENORTable 6 reveals that removing trigram featuresaffects the performance most.
This suggests thattrigram features are much more effective forENOR than other two types of features.
It alsoshows that trigram features in ENOR does not suf-fer from the data sparseness issue.As observed in Table 5, in CNOR task, 93.96%61accuracy is obtained when removing unigram fea-tures, which is much lower than 98.10% when bi-gram features are removed.
This suggests that uni-gram features are very useful in CNOR, which ismainly due to the data sparseness problem thatbigram features may have encountered.4.3 Model Complexity and Data SparsenessTable 7 (ENOR) and Table 8 (CNOR) compareour MaxEnt model with the SUM model (Qu andGregory, 2004) and the PP model (Li et al, 2006).All the experiments are conducted on the samedata sets as described in section 4.1.
Tables 7 and8 show that the proposed MaxEnt model outper-forms other models.
The results are statisticallysignificant ( 2?
test with p<0.01) and consistentacross all tests.Model Complexity:We look into the complexity of the models andtheir effects.
Tables 7 and 8 summarize the overallaccuracy of three models.
Table 9 reports thenumbers of parameters in each of the models.
Weare especially interested in a comparison betweenthe MaxEnt and PP models because their perform-ance is close.
We observe that, using trigram fea-tures, the MaxEnt model has many more parame-ters than the PP model does.
Therefore, it is notsurprising if the MaxEnt model outperforms whenmore training data are available.
However, the ex-periment results also show that the MaxEnt modelconsistently outperforms the PP model even withthe same size of training data.
This is largely at-tributed to the fact that MaxEnt incorporates morerobust features than the PP model does, such asrule-based, length of names features.One also notices that PP clearly outperformsSUM by using the same number of parameters inENOR and shows comparable performance inCNOR tasks.
Note that SUM and PP are differentin two areas: one is the PP model employs wordlength normalization while SUM doesn?t; anotherthat the PP model uses n-gram conditional prob-ability while SUM uses n-character joint probabil-ity.
We believe that the improved performance ofPP model can be attributed to the effect of usageof conditional probability, rather than length nor-malization since length normalization does notchange the order of probabilities.Data Sparesness:We understand that we can only assess the ef-fectiveness of a feature when sufficient statistics isavailable.
In CNOR (see Table 8), we note that theChinese transliterations of English origin use only377 Chinese characters, so data sparseness is not abig issue.
Therefore, bigram SUM and bigram PPmethods easily achieve good performance for Eng-lish origin.
However, for Japanese origin (repre-sented by 1413 Chinese characters) and Chineseorigin (represented by 2319 Chinese characters),the data sparseness becomes acute and causes per-formance degradation in SUM and PP models.
Weare glad to find that MaxEnt still maintains a goodperformance benefiting from other robust features.Table 10 compares the overall accuracy of thethree methods using unigram and bigram featuresin CNOR task, respectively.
It shows that theMaxEnt method achieves best performance.
An-other interesting finding is that unigram featuresperform better than bigram features for PP andMaxEnt models, which shows that  data sparsenessremains an issue even for MaxEnt model.5 ConclusionWe propose using MaxEnt model to explore di-verse features for name origin recognition.
Ex-periment results show that our method is more ef-fective than previously reported methods.
Ourcontributions include:1) Cast the name origin recognition problem asa multi-class classification task and proposea MaxEnt solution to it;2) Explore and integrate diverse features forname origin recognition and propose themost effective feature sets for ENOR andfor CNORIn the future, we hope to integrate our nameorigin recognition method with a machine translit-eration engine to further improve transliterationperformance.
We also hope to study the issue ofname origin recognition in context of sentence anduse contextual words as additional features.ReferencesAdam L. Berger, Stephen A. Della Pietra and Vincent J.Della Pietra.
1996.
A Maximum Entropy Approachto Natural Language Processing.
Computational Lin-guistics.
22(1):39?71.William B. Cavnar and John M. Trenkle.
1994.
Ngrambased text categorization.
In 3rd Annual Symposium62on Document Analysis and Information Retrieval,275?282.Kevin Knight and Jonathan Graehl.
1998.
MachineTransliteration.
Computational Linguistics.
24(4),599-612.Jin-Shea Kuo and Ying-Kuei Yan.
2004.
GeneratingPaired Transliterated-Cognates Using Multiple Pro-nunciation Characteristics from Web Corpora.
PA-CLIC 18, December 8th-10th, Waseda University,Tokyo, Japan, 275?282.Haizhou Li, Shuanhu Bai and Jin-Shea Kuo.
2006.Transliteration.
Advances in Chinese Spoken Lan-guage Processing.
World Scientific Publishing Com-pany, USA, 341?364.Haizhou Li, Khe Chai Sim, Jin-Shea Kuo and MinghuiDong.
2007.
Semantic Transliteration of PersonalNames.
ACL-2007.
120?127.Xinhua News Agency.
1992.
Chinese Transliteration ofForeign Personal Names.
The Commercial PressYan Qu and Gregory Grefenstette.
2004.
Finding ideo-graphic representations of Japanese names written inLatin script via language identification and corpusvalidation.
ACL-2004.
183?190.Min Zhang, Jian Su and Haizhou Li.
2004.
Direct Or-thographical Mapping for Machine Translation.COLING-2004.
716-722.Trigram SUM Trigram PP MaxEnt Origin # trainingentries# testentries P (%) R(%) F P(%) R(%) F P(%) R(%) FEng 79,920 8,879 94.66 72.50 82.11 95.84 94.72 95.28 97.82 95.11 96.45Man 104,291 11,588 86.79 94.87 90.65 98.99 98.33 98.66 99.52 99.68 99.60Can 104,165 11,574 90.03 93.87 91.91 96.17 99.67 97.89 99.71 99.59 99.65Jap 110,951 12,324 89.17 92.84 90.96 98.20 96.29 97.24 96.69 98.59 97.63Overall Acc (%) 89.57 97.39 98.44Table 7: Benchmarking different methods in ENOR taskBigram SUM  Bigram PP  MaxEnt Origin # trainingentries# testentries P(%) R(%) F P(%) R(%) F P(%) R(%) FEng 37,644 3,765 95.94 98.65 97.28 97.58 97.61 97.60 98.08 99.04 98.56Chi 29,795 2,980 96.26 87.35 91.59 95.10 87.35 91.06 97.57 96.88 97.22Jap 33,897 3,390 93.01 97.67 95.28 90.94 97.43 94.07 98.58 98.11 98.34Overall Acc (%) 95.00 94.53 98.10Table 8: Benchmarking different methods in CNOR task# of parameters for ENOR # of parameters for CNORMethodsTrigram Unigram BigramMaxEnt  124,692 13,496  182,116PP 16,851 4,045 86,490SUM  16,851 4,045 86,490Table 9: Numbers of parameters used in different methodsSUM PP MaxEntUnigram Features 90.55 97.09 98.10Bigram Features 95.00 94.53 97.56Table 10: Overall accuracy using unigram and bigram features in CNOR task63
