PAUSE AS  A PHRASE DEMARCATOR FOR SPEECH AND LANGUAGE PROCESSINGJUNKO HOSAKA MARK SELIGMAN HARALD SINGERATR Interpreting Telephony Research LaboratoriesHika,ridai 2-2, Seika-cho, Sor~ku-gun, Kyoto 619-02, J ap ;mAbst ractIn spontaneous speech understanding a sophisticated in-tegration of speech recognition and language processingis espceially crucial.
However, the two modnles are tra-ditionally designed independently, with independent lin-guistie rules.
In Japanese spc.ech recognition the bun-sctsu phrase is the basic processing unit and in languageprocessing the sentence is the basic unit.
This differencehas made it impracticM to use a unique set of linguisticrules for both types of processing.
Further, spontaneousspeech contains unexpected utterances other than well-formed sentences, while lingnistic rules for both speechand language processing expect well-formed sentences.They therefore fail to process everyday spoken language.To bridge the gap between speech and language process-ing, we propose that pauses be treated as phrase demar-cators and that the interpausal phrase be the basic com-mon process ing unit.
And to treat the linguistic l)henoI~l-ena of spoken language properly, we survey relevant fea-tures in spontaneous speech data.
We then examine theeffect of integrating pausal and spontaneous speech phe-nomena into synt~tctic rules for speech recognition, using118 sentences.
Our experiments show that incorporat-ing pansal phenomena as purely syntactic onstraints de-grades recognition accuracy considerably, while the addi-tional degradation is minor if some filrther spontaneousspeech features are also incorporated.1 INTRODUCTIONA spontaneous speech understanding system acceptsnaturally spoken input and understands its meaning.hi such a system, speechprocessing and language pro-cessiug must be integrated in a sophisticated manner.Itowew:r, the integration is not straightforward, asthe two are stndied independently art(/ have differ-ent processing units.
Moreover, spontaneous speechcontains unexpected phenomena, such as hesitations,corrections and fragmentary expressions, which thusfar have not been treated in linguistic rules.The most significant concern in speech processingis raising the recognition accuracy.
For that purpose,applying linguistic information, e.g.
using stochasticmodels\[l l, syntactic rules\[2\], sen,antic intbrmation\[3\]and discourse plan@l\], is most promising.
In a recentJapanese speech translation system\[5\] b*lnselsu-basedsyntactic constraints are successfully applied in thespeech processing module\[6\] 1, However, rules repre-l A bunsetsu rouglfly corresponds to a phrase and is the nextlargest unit after the word.
The  nunfl)er of words in a phraseranges f rom I to 14, art(\] the mean numl)er is al)ont 317\].senting the same constraints cannot be used directlyin sentence-based language processing, where the pri-mary concern is to understand sentence meaning.
Inspeech recognition, a sequence of words forms a bun-selsu and a set of bunseisus then forms a sentence.In language processing, on the other hand, wherethe sentence is the basic processing unit, treating themain verh aud its complements i  usually the core ofprocessing.
For the sentence kaigi ni moshikomi taino desu ga, meauing 'I would like to apply for theconference,' the processing discrepancy is sketched inFigure 1:Speech Processingkaigi n, ~moshikomi\]~no desu gaLT I I.. ILanguage Processing\]moshikomi~ tai no dosu gaI I- 7 .~L  ..Figure 1: Structural DifferenceAlthough linguistic rules for speech recognition al-ways cope with uncertain l)honeme hypotheses, theystill expect well-fornmd speech input, and this is evenmore true of linguistic rules in language processing.In spontaneous peech, however, there are hesita-tions, corrections and incomplete utterances whichare uot treated in the conventional framework.In addressing spontaneous peech understanding,two main prohlems must be solved: the absence ofcommon processing components a~s sketched in Fig-ure 1, and our insufficient knowledge of spontaneousspeech features.
In this paper, we propose the pauseas a phrase demarcator and the interpausal phraseas the basic processing unit.
A phrase is natu-rally demarcated with pauses in spoken language andan interpausal phrase often functions as a meaningunit\[8\]\[9\], in spontaneous speech understanding wemust both accept naturally spoken input and under-stand its lneaning.
Use of the pause as a phrase de-marcator is advantageous for both of these purposes.Further, we investigate several frequent spontaneous987speech fleatures using spontaneous speech data\[10\].We then apply tile study to speech recognition.
Weexamine the effect of integrating into syntactic rulespausal phenomena and certain features of spoken lan-guage, using 118 test sentences.2 ANALYS IS  OF SPONTA-NEOUS D IALOGUES2.1 Spontaneous  D ia logue  DataAs sources of spontaneous data, we nse four Japanesedialogues concerning directions from Kyoto stationto either a conference center or a hotel, collectedin the Environment for Multi-Modal lnteraction\[10\].Speaker A is pre-trained to give the directions, men-tioning possible transportation, location and so forth.Two subjects seeking directions, Speaker B andSpeaker C, are given some keywords, such as thename and tim date of the conference.
They may usetelephone connections only, or may use a multimodalsetnp with onscreen graphics and video as well.
Ta-ble 1 shows how many words are used in tile dialoguesstudied:Table 1: Words in the CorporaSpeakers A ,BSpeakers A,CSubtotalTelephone Multimedia536 7141167 1124~7o3 1838Total 3541The corpora consists of 3541 words in total, andcontains 440 different words, it has 403 turn-takings,and thus roughly 403 sentences.In the multimedia setup, speakers use deictic ex-pressions uch as koko and kore meaning "here" and"this," respectively.
The dialogues also la~sted longerthan those in the telephone-only setup.
Itowever, wedid not find any further distinct differences betweenthe two setups.
We therefore analyse all of the dia-logues in tile same way.For our stndy, transcripts of the spontaneous di-alogues have been prepared, and these contain too>photogical tags and turn-taking information.
Pauseinformation within turns, i.e., breaths or silenceslonger than 400 miliseconds, is provided a~s well.2.2 Pause  as  a Phrase  DemarcatorIn Table 2 we illustrate the adequacy of the inter-pausal phrase as a processing unit with a series of di-rections to Kyoto station's Karasumachou exit.
3'heentire explanation consists of three turns separated byshort response syllables, snch as hat, that do not over-lap I,l~e xplanation.
That  is, the speaker paused dur-ing these responses.
We marked each turn with '/'URNat the end.
As a primary demarcator we used pausesand turns.
Thus either PAUSE or TURN appears in thesecond colunm.
Further demarcator candidates uchas the filled pauses anoo or Pete, the emphasis markerdesune and the response syllable hat when overlap-ping the explanation appear in the third eohmm asFILLED PAUSE, DESUNE and RESPONSE, respectively.A rough translation follows each interpausal phrase:Table 2: Phrase Demarcator~2 K ~@"QL2~: 6 PAUSE FILLED PAUSEi f  it is from here~ 6 PAUSEthis side?-)~t~>*&'-\[:2Z)~ O "C'N ~ ~ b~ PAUSE R, ESPONSEyou go up the stairsc c fo  a /~o-cN~-  TUaNyou cross here all the way~* PAUSEand~ ,~,-?'
I~ESPONSE- -  ~: J~ Y~JJ m PAUSEwhen you see the nezt stairs, this one, turn left, first~_ ~ 7-~" PAUSE DESUNEat this place like a crossroad which appears~'~cEf o~CT;~  ~ 5- TURNturn rigM"(" ,~ff IC '~ "o "% I~ Iz'~ X2 " PAUSEand yell t'~lrTz right-PC c a) N~-C-I~g ~ -C\]*.~ "~ ~- ~ PAUSE t~ESPONSEand lhen if  you go down the stairs hereyou come out of the karasumachou emilThe length of the processing unit plays an impe lrant role in speech recognition.
Table 2 shows thatalternative demarcator candidates such as FILLEDPAUSE and RESPONSE usually cooccur with pauses.In Table 2, for example, we find only one case whereRESPONSE does not eooecur with a pause.
Conse-quently, tile segments within turns bounded by thesealternative markers would not be much different fromthose bounded by pauses; in particular, they wouldnot be nan& shorter or longer.
Thus, at least wherelength is concerned, the combination of PAUSE andTURN seems appropriate and sufficient to mark outphrases.
With respect to language processing, Table2 shows that interpausal phrases are often adequateas translation units,  which suggests that such phrasesoften function as meaning units.Interpausal phrases typically end with a conjunc-tive postposition, such ms ya or keredomo; a postpo-sitional phrase; an interjection, such as hat or moshi-moshi; the genitive postposition no for adnominals;988all adnominal  conjugaL|oil for l l l ;  ;t coor(/itmJ.e cot@l-gation form; ~m?iliaries with senl;ence liua\[ conjuga-tiol: form; or a seut,enee final l)arl.icle, such as lea or"ll ?.2.3 Features  of  Spontaneous  D ia -loguesWe studied t, en features of Sl)Ont~mc.ous dialogueswhich are not, consid(,red iu grammars  for weal \['ormedsenl;ences\[6\]\[I 1\].
Table 3 shows the fi 'ah:res and t;hcirfrequem:ies:In Ex.
2 Speaker \]3 did not; finish whag he wm,i, edt.o say, but SpeMcer A m:derstood his iutent ion andinl;err:ll)ted his utterance, which is therefore fragumn-tary.
Speaker 11 continued but, before he could liaishSpeaker A finished for him.
So Speaker B's l:tge.ra:lceis again \]'r:tgn:el:l, a 'y.Ex.
3Speaker A: fu l :aeki  (lead'ter I, wo stopsSpeaker H: keagekeage5'peaker A: sou de,suthat 's  rightTabh'.
3: Feature and OccurrenceUs(: of dc,s~.ze :ff IUse of a~:oo 35 IFragmentary ul;term~ce 2:5 \]IJse of ec/o 1,5 IEnd o\[" tm'n with a PP 7 :POStl)osition drop 7 ',Question without ka 5 \]I ) isf luency: so ude.~'~n~, 51Apposit ion 1 IInversion 31We expected a very high frequency of the \[|{ledpauses a'0oo and celo f lmctioaiag as discoursemanagers\[I2\],  lloweve.r, Table 3 shows only a roodest frequency.
Iq~ol:ological varim, ions such as utb*ooal:d aTio for a11oo ;Hid etlov a:ld cello \['or 0el0 wereuot coltllted.
This may be why the \['requeucy off bed:cxpr(..ssions ix unexpectedly low.Some flai, ures shown in Table :1 are disc:,ssed inthe ('.X;-UI/I)Ie sets below.
Fe.al, ures it: focus ;~re iu boldtype:F ,x .
1soch.h'a ~Io ( lesmte noviba kava basu ga desunedele.masuthere is a bus fl'om that  bus s~,op"\]'he person giving dire.cdons off, e:: uses dm expres-sion desu~:e. The use o\[" dcsu'ne emphasiz(:s t,he pre-ceding utterance., typically the inlmediat.ely precedingmiMmal phrase.
In Ex.
I the first use emphasizessochira no and the second sl, resse.s ba.s.u yR.We deuol, e t, he person giving the directions asSp(,akcr A aud the person seeking the infornmtionas Speal:er B in Examples 2, and 3.Ex.
2Speaker lk  keagc no k i tanorl,h <ff keage.5'l;cakcv A: sou des'~lthat 's  rig}itSpeaker I~: ( legneh iexitSpeaker A: f~hzdcg'uchi dc,~'a ~tcil/s t l~e nord~ exit, okay?Speaker A is giving directions but before he hascompleted his ul, terancv Spealce.r B interrupts witl~the stat ion name.
SpeM:er A did not continue his\[h'sl, utterance and agreed wit\[: Speaker B. St)e.ake.rA's first utterance is a non:|hal  phrase, which is nevereomlJe.ted.. .
.
.
-4 1 - " 3 APP I , ICA\ ] ION OF  THEANALYS ISTo e?amine the l'easibility of integrat ing h:to syn-tactic rules both p:msal phenoutena nd the fi;ah:res0\[" SI)OIILI/:IOOIlS speech studied in Section 2, we pre-pared three, dil l 'trent sets of rules.
In all three s(%s,rules have bee.n exl)licitly u:oditied l;o represent lmUSgdphel:ot:wp.a.
The.
first set: Pause; contains only suchmodifications, while I,he other l;wo sets add olle additionai spont:meous 5mtut'e each: rule set Emphasisl>crmits l lse o\[" |,he ell:l)hasis marker deswnc el'Let anoun phrase, while rule set Turn  allows t)ostposidonalu(;i.erauccs at; t:he end o\[' a turn.
\a?e conducted pre.l iminary speech recoguitiou cxperiment, s with a pgLrserwhich uses linguist, ic constra ints  written ~us a CFC.
( .~Ol ls t ra l r l t ,  s 3.\] L ingu is t ic  ~ "To represem; ore' underlying linguistic eonstnf ints weadapted existiug synt;wt.ie rules developed for sl)eechrecognition\[6\].
Earl ier expcri luents using b'lutselsu-based sl)eech input  showed 70% sent, ence reeognidonaccuracy for tl:e top caudidat, e and 8,1% for d:c. top 5e:mdidates.The format for all of our synt, actic :':alex ix as fob-lows;(<CATI> <--> (<CAT2> <CAT3>))Nonterminals are surrounded by <>.
\ ] 'he aboverule indicates thal.
CATI  cons i s ts  o f  CAT2 a l :d  CAT3.We denote the categories in interpa::sa/ phrase rulesin lower-cruse and t, he categories in interpausal  phrase-based se:/gellee r l l ieS il: upper-case.In the rule set Pause  we prepared about d5l>hrases dmt can end will: a pause: postposi-tionaI phrases, COllj:lllCt, ive phrases, adnominM ver -ba l  phrases marked with a special conjugation form,989phrases that end with a conjunctive postposition, ad-nominal phrases with the genitive postposition no,and coordinate verbal phrases.
The first three rulesare as follows:(<pp-pau> <--> (<pp> <pause>))(<conj-pau> <--> (<conj> <pause>))(<vaux-mod-pau> <--> (<vaux-mod> <pause>))In the rule set Emphasis we prepared seven addi-tional rules for treating the emphasis marker desune,represented as follows:(<pp-pau> <--> (<pp> <emphasis> <pause>))(<pp-no-pau> <-->(<pp-no> <emphasis> <pause>))Methods for combining interpausal phrases to ob-tain an overall utterance meaning require furtherstudy.
At this stage we defined a sentence veryloosely.
It can be an interjection; an interjectionfollowed by a combination of interpausal phrases; orsimply a combination of interpausal phrases.
To al-low fragmentary ntterances, in the rule set Turn, wealso introduced a sentence consisting of a nominalphrase, which may contain adnominal phrases.
Com-plete sentences in Turn are defined as follows:(<SSS> <--> (<INTERJI>))(<SSS> <--> (<INTERJI> <SS>))(<SSS> <--> (<SS>))(<SSS> <--> (<M-NN>))Table 4 shows the size and phoneme perplexity ofthe three sets of rules:Table 4: Size and PerplexityPause Emphasis TurnRules 2326 2333 2327Words 751 752 751Perplexity 3.96 3.96 3.96A given phoneme string can belong to several cat-egories.
For instance, de can be a postposition ora copula conjugation form.
The number of differentphoneme strings is 503 for Pause  and Turn, and 504for Emphasis.3 .2  Speech  Recogn i t ion  Exper imentWe conducted a speech recognition experiment with118 test sentences concerning secretarial services foran international conference.
A professional broad-caster uttered the sentences without any special con-straints uch as pause placement.For our speech recognition parser, we used tIMM-LR\[14\], which is a combination of generalized LRparsing and Hidden Markov Models (HMM).
The sys-tem predicts phonemes by using an LR parsing tableand drives HMM phoneme verifiers to detect or ver-ify them without any intervening structure such as aphoneme lattice.
Linguistic rules for parsing can bewritten m CFG format.As mentioned in section 3.1, we explicitly definedrules that can end with pauses in linguistic con-straints.
According to the pause model, a pause canlast from 1 to 150 frames, where a frame lasts 9 reset.Examples (1) and (2) show the results of ItMM-Lit.
Japanese speech recognition 2.
(1) shows sampleresults of rule set Pause and (2) shows sample resultsof Turn.
The phoneme strings which were actuallypronounced are enclosed in I I:(i) I kaiginoaNnaishowaomo chide suka I(Do you have a conference invitation?).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.I : kaigi-no-P-aNnaisyo-o-omochi-desu-ka2 : kaigi-ni-P-aNnaisyo-o-omochi-desu-ka3 : kaigi-ga-P-aNnaisyo-o-omochi-desu-ka> 4: kaigi-no-P-aNnaisyo-wa-P-omoehi-desu-ka5 : kaigi-ni-P-aNnaisyo-wa-P-omochi-desu-ka(2) \ [ i i e \ [  (no).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.1 : imi-e2: igo-e> 3: iie4: ima-eS: kigeg-eIn the examples, the symbols >, -, N and P havespecial meaning: A correctly recognized phrase ismarked with >.
A word boundary is marked with -.A syllabic nasal is transcribed N. A pause is markedwith p.Example (1) shows typical recognition errors in-volving postpositions like no, m, ga, and o, which of-ten receive reduced pronunciation i  natural speech.The surounding context may aggravate the problem.IIere, for instance, topic marker wa is erroneously rec-ognized as object marker o in the environment; of pre-ceding and subsequent phoneme o.
The possible in-troduction of pauses at such junctures further compli-cates the recognition problem.
Analysis deeper thanCFG parsing will often be needed to filter unlikelycandidates.
Example (2) demonstrates the dangersof allowing postpositional phrases to end utterances.Here, all recognition candidates other than the thirdare inappropriate postpositional phrases.
To recog-nize the unlikelihood of such candidates, we will needfurther controls, such as discourse management.Our resulting sentence speech recognition accura-cies are shown in Table 5.
For instance, using rule setPause, the correct candidate was the highest rank-ing candidate 50.0 percent of the time, Rank 1, whilethe correct candidate was among the top ,5 candidates55.9 percent of the time, Rank 5.2The maximal amount of the whole beam width, called theglobal beam width, is set at 100, emd the maximM beau widthof each branch, the local beam width, is 12.990Table 5: Recognition t{ate (%)y-  T.o T 5o /,\[o.HI I < 4.2 i iI II iWith the underlying linguistic rules fl)r the threerule sets, earlier experiments had achieved 70% sen-I, ence speech l:ecognition accuracy for speech inputwith explicit p~mses at bunsets'u bonndaries.
Our best,present results tbr spontaneous speech are much moremodest: 50%.
'l'~d~le 5 shows that the introduction of the empha-sis marker des'uric did not affect processing: as seen inTable 4, rule set Emphasis has a slightly higher per-plexity than Pause, but we had ex~(:tly the same re-sues for the two.
On I;he other hand, the perplexitiesof Pause and Turn ~re identical, but the treattnent offragmentary utterances did decrease recognition ac-Clll:acy.4 CONCLUSION2'o treat spontaneous speech understauding we havetwo main problems: the absence of a common pro-ceasing unit gJ.lld insuflieieilt knowle.dge of spouta-rictus speech fcatarea.We have proposed pauses as i)hrase detYlarcatol'sand interpausM phrases as common processing unitsto allow integration of speech recognition and lan-guage processing in the processing of spontaneousspeech understand\[us.
We demonstrated the adwm-gages of processing based on iutcrpausaI phrases usingexamples taken from spontameous speech dialoguescontaining 3,541 words.
Using the same data, westudied certain features of spoken language, such astilled pauses and fragmentary utterances.
Based onthe study, we prepared three difDrent CFG rule se.tsfor preliminary speech recognition experiments.
Inall three sets, rules have been e?plicitly modified torepresent pausal phenomena.
Tiw.
first set eolltaiiisonly such modifications, while the other two sets acidtile addit, ional spontaneous feature each: rise of theemphasis marker desune after a noun phrase or post-positional utterances at the end of a turn.
For 118sel/tences, sel/tence reco~llitioll acctlracy \['or pause-based rules was considerably less than the accuracyobtidned in earlier buTiseisu-based tests using manda-tory pauses at b~tn.selslt boundaries; but flirt, her lossof accuracy caused by incorporating the spontaneousfeatures was minor.We believe that the loss of speech recognition ac-curacy for sentences een in our pause-based experiments is largely due to the difficulties of eombin-lug interpausaI phrase hypotheses.
Our r/lies cur-reiltly eombine interpausal phrases in a relatively un-constrained lllS.unerl tlsillg only weak syutactic COll-straiuts.
Based vn filrther study of the structureswhich precede and follow pauses or filled pauses, wehope t.o provide stronger syntactic onstraints in theftit'dre.5 ACKNOWLEDGEMENTSWc wish to thank \])r. Y. Yamazaki, President ofATR-ITL, 2'.
Morimoto, Ilead of Department 4, andmany of our \[TL colleagues for their generous upportslid ellcollragelilell t.References\[1\] Lee, K.-F. and Iton, \[\[.-W.(1988): "Large-VocMmMry Speaker-independent Continuous SpeechRecognition Using \[\]MM," Prec.
of ICASSP-88,pp.
123-126.\[2\] Ney, II,(\]987): "l)ymmfic t'rogrammlng SpeechRecognition Using a (\]ontexl.-Free Grammar," Proc.of IC, ASSP-87, pp.69-72.\[3\] Matsunaga, S., Sagayama, S., Honmia, S. and Furui,S.
(1990): "A Continuous Speech Recognition SystemBased on a Two-Level Grammm: Approach," Pro<:.
ofICASSP-90, pp.589-592.\[4\] Yamaok~h T. and lida, H.(19.90): "A Method to Pre-dict the Next Utterance \[)'sing it Four-layered PlanRecognition Model," Prec.
e\[ ECAL90, pp.726-731.\[5\] Morimoto, T., Takezawa, T., Yato, F., ct M.(1993):"AG'IUs Spec'ch G'ransb~tion System: ASUH A," Prec.of Eurospcech-93, Vol.2, pp.129\]-t294.\[6\] \[\[osaka, J., TMcezawa, T.(1992): "Construction ofcorpus-based syntactic rules for accurate speechrecognition," Prec.
of COtiNG-92, pi,.806-812.\[7\] Ehara., '1'., Ogura, IC, Mot\[mote, T. (1990): "ATRl)ia.logue \])atahase," Prec.
of ICSLI>-90, pp.
1093-1096.\[8\] Fodor, J., Bever, %(1965): "'Fhe psychological real-icy of linguistic segments," Journal of Verbal Learn-ing aud Behavior, pp.
4:414-420.\[9\] Sugito, M.(t988):"Pause and intonation in dis-course," Nihongo to nihongo kyouiku, Vol.2, pp.343-.363 (in Japanese).I,oken-Kim, K., Yato, F., et a1.
(1993): EMMI-ATR environment for multi-roods{ inter~Lction, q'T-IT-0081, A'\['R.llesak~h 3.
(1993): A (Iramlmtr for Japanese Genera-tion in l, he TUG Fr;tmework, TechnicaJ Report TIL1-0346, A'I'ILSadanobu, T., Takubo, Y.
(;1993): "The DiscourseM~nagement Function of Fillers -a ca.se of "eeto" and"ant(o)'>-, Prec.
of ISSD-93, pp.271-274.Hosaka, J., '\['akezawa, 'l'., Uratani, N.(1992): "An-alyzing Postposition \[)tops in Spoken Japanese,"Prec.
of l(3SLP-92, Vol.2, pp.1251q254.Kita, K., Kawabala, T., Saito, li.
(1989): "HMMContinuous Speech l{ecogniton UsiiIg Predictive LI{Parsing," Prec.
of ICASSP-89, pp.703-7\[)6.\[10\]\[1~\]\[12\]\[13\]\[14\]991
