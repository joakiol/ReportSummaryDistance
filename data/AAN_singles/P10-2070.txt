Proceedings of the ACL 2010 Conference Short Papers, pages 382?386,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsWrapping up a Summary:from Representation to GenerationJosef Steinberger and Marco Turchi andMijail Kabadjov and Ralf SteinbergerEC Joint Research Centre21027, Ispra (VA), Italy{Josef.Steinberger, Marco.Turchi,Mijail.Kabadjov, Ralf.Steinberger}@jrc.ec.europa.euNello CristianiniUniversity of Bristol,Bristol, BS8 1UB, UKnello@support-vector.netAbstractThe main focus of this work is to investi-gate robust ways for generating summariesfrom summary representations without re-curring to simple sentence extraction andaiming at more human-like summaries.This is motivated by empirical evidencefrom TAC 2009 data showing that humansummaries contain on average more andshorter sentences than the system sum-maries.
We report encouraging prelimi-nary results comparable to those attainedby participating systems at TAC 2009.1 IntroductionIn this paper we adopt the general frameworkfor summarization put forward by Spa?rck-Jones(1999) ?
which views summarization as a three-fold process: interpretation, transformation andgeneration ?
and attempt to provide a clean in-stantiation for each processing phase, with a par-ticular emphasis on the last, summary-generationphase often omitted or over-simplified in the main-stream work on summarization.The advantages of looking at the summarizationproblem in terms of distinct processing phases arenumerous.
It not only serves as a common groundfor comparing different systems and understand-ing better the underlying logic and assumptions,but it also provides a neat framework for devel-oping systems based on clean and extendable de-signs.
For instance, Gong and Liu (2002) pro-posed a method based on Latent Semantic Anal-ysis (LSA) and later J. Steinberger et al (2007)showed that solely by enhancing the first sourceinterpretation phase, one is already able to pro-duce better summaries.There has been limited work on the last sum-mary generation phase due to the fact that it isunarguably a very challenging problem.
The vastamount of approaches assume simple sentence se-lection, a type of extractive summarization, whereoften the summary representation and the endsummary are, indeed, conflated.The main focus of this work is, thus, to in-vestigate robust ways for generating summariesfrom summary representations without recurringto simple sentence extraction and aiming at morehuman-like summaries.
This decision is also mo-tivated by empirical evidence from TAC 2009 data(see table 1) showing that human summaries con-tain on average more and shorter sentences thanthe system summaries.
The intuition behind this isthat, by containing more sentences, a summary isable to capture more of the important content fromthe source.Our initial experimental results show that ourapproach is feasible, since it produces summaries,which when evaluated against the TAC 2009 data1yield ROUGE scores (Lin and Hovy, 2003) com-parable to the participating systems in the Sum-marization task at TAC 2009.
Taking into accountthat our approach is completely unsupervised andlanguage-independent, we find our preliminary re-sults encouraging.The remainder of the paper is organised as fol-lows: in the next section we briefly survey therelated work, in ?3 we describe our approach tosummarization, in ?4 we explain how we tacklethe generation step, in ?5 we present and discussour experimental results and towards the end weconclude and give pointers to future work.2 Related WorkThere is a large body of literature on summariza-tion (Hovy, 2005; Erkan and Radev, 2004; Kupiecet al, 1995).
The most closely related work to theapproach presented hereby is work on summariza-tion attempting to go beyond simple sentence ex-1http://www.nist.gov/tac/382traction and to a lesser degree work on sentencecompression.
We survey below work along theselines.Although our approach is related to sentencecompression (Knight and Marcu, 2002; Clarkeand Lapata, 2008), it is subtly different.
Firstly, wereduce the number of terms to be used in the sum-mary at a global level, not at a local per-sentencelevel.
Secondly, we directly exploit the resultingstructures from the SVD making the last genera-tion step fully aware of previous processing stages,as opposed to tackling the problem of sentencecompression in isolation.A similar approach to our sentence reconstruc-tion method has been developed by Quirk et al(2004) for paraphrase generation.
In their work,training and test sets contain sentence pairs thatare composed of two different proper English sen-tences and a paraphrase of a source sentence isgenerated by finding the optimal path through aparaphrases lattice.Finally, it is worth mentioning that we are awareof the ?capsule overview?
summaries proposed byBoguraev and Kennedy (1997) which is similar toour TSR (see below), however, as opposed to theiremphasis on a suitable browsing interface ratherthan producing a readable summary, we preciselyattempt the latter.3 Three-fold Summarization:Interpretation, Transformation andGenerationWe chose the LSA paradigm for summarization,since it provides a clear and direct instantiation ofSpa?rck-Jones?
three-stage framework.In LSA-based summarization the interpreta-tion phase takes the form of building a term-by-sentence matrix A = [A1, A2, .
.
.
, An], whereeach column Aj = [a1j , a2j , .
.
.
, anj ]T representsthe weighted term-frequency vector of sentence jin a given set of documents.
We adopt the sameweighting scheme as the one described in (Stein-berger et al, 2007), as well as their more generaldefinition of term entailing not only unigrams andbigrams, but also named entities.The transformation phase is done by applyingsingular value decomposition (SVD) to the initialterm-by-sentence matrix defined as A = U?V T .The generation phase is where our main contri-bution comes in.
At this point we depart from stan-dard LSA-based approaches and aim at produc-ing a succinct summary representation comprisedonly of salient terms ?
Term Summary Represen-tation (TSR).
Then this TSR is passed on to an-other module which attempts to produce completesentences.
The module for sentence reconstruc-tion is described in detail in section 4, in what fol-lows we explain the method for producing a TSR.3.1 Term Summary RepresentationTo explain how a term summary representation(TSR) is produced, we first need to define two con-cepts: salience score of a given term and saliencethreshold.
Salience score for each term in matrixA is given by the magnitude of the correspondingvector in the matrix resulting from the dot productof the matrix of left singular vectors with the diag-onal matrix of singular values.
More formally, letT = U ?
?
and then for each term i, the saliencescore is given by |~Ti|.
Salience threshold is equalto the salience score of the top kth term, when allterms are sorted in descending order on the basisof their salience scores and a cutoff is defined as apercentage (e.g., top 15%).
In other words, if thetotal number of terms is n, then 100?k/n must beequal to the percentage cutoff specified.The generation of a TSR is performed in twosteps.
First, an initial pool of sentences is selectedby using the same technique as in (Steinberger andJez?ek, 2009) which exploits the dot product of thediagonal matrix of singular values with the rightsingular vectors: ?
?
V T .2 This initial pool of sen-tences is the output of standard LSA approaches.Second, the terms from the source matrix A areidentified in the initial pool of sentences and thoseterms whose salience score is above the saliencethreshold are copied across to the TSR.
Thus, theTSR is formed by the most (globally) salient termsfrom each one of the sentences.
For example:?
Extracted Sentence: ?Irish Prime Minister BertieAhern admitted on Tuesday that he had held a series ofprivate one-on-one meetings on the Northern Irelandpeace process with Sinn Fein leader Gerry Adams, butdenied they had been secret in any way.??
TSR Sentence at 10%: ?Irish Prime MinisterBertie Ahern Tuesday had held one-on-one meetingsNorthern Ireland peace process Sinn Fein leader GerryAdams?32Due to space constraints, full details on that step areomitted here, see (Steinberger and Jez?ek, 2009).3The TSR sentence is stemmed just before feeding it tothe reconstruction module discussed in the next section.383Average Human System At 100% At 15% At 10% At 5% At 1%number of: Summaries SummariesSentences/summary 6.17 3.82 3.8 3.95 4.39 5.18 12.58Words/sentence 15.96 25.01 26.24 25.1 22.61 19.08 7.55Words/summary 98.46 95.59 99.59 99.25 99.18 98.86 94.96Table 1: Summary statistics on TAC?09 data (initial summaries).Metric LSAextract At 100% At 15% At 10% At 5% At 1%ROUGE-1 0.371 0.361 0.362 0.365 0.372 0.298ROUGE-2 0.096 0.08 0.081 0.083 0.083 0.083ROUGE-SU4 0.131 0.125 0.126 0.128 0.131 0.104Table 2: Summarization results on TAC?09 data (initial summaries).4 Noisy-channel model for sentencereconstructionThis section describes a probabilistic approach tothe reconstruction problem.
We adopt the noisy-channel framework that has been widely used in anumber of other NLP applications.
Our interpre-tation of the noisy channel consists of looking at astemmed string without stopwords and imaginingthat it was originally a long string and that some-one removed or stemmed some text from it.
In ourframework, reconstruction consists of identifyingthe original long string.To model our interpretation of the noisy chan-nel, we make use of one of the most popularclasses of SMT systems: the Phrase Based Model(PBM) (Zens et al, 2002; Och and Ney, 2001;Koehn et al, 2003).
It is an extension of the noisy-channel model and was introduced by Brown et al(1994), using phrases rather than words.
In PBM,a source sentence f is segmented into a sequenceof I phrases f I = [f1, f2, .
.
.
fI ] and the same isdone for the target sentence e, where the notion ofphrase is not related to any grammatical assump-tion; a phrase is an n-gram.
The best translationebest of f is obtained by:ebest = argmaxe p(e|f) = argmaxeI?i=1?(fi|ei)?
?d(ai ?
bi?1)?d|e|?i=1pLM (ei|e1 .
.
.
ei?1)?LMwhere ?
(fi|ei) is the probability of translatinga phrase ei into a phrase fi.
d(ai ?
bi?1) isthe distance-based reordering model that drivesthe system to penalize substantial reorderings ofwords during translation, while still allowing someflexibility.
In the reordering model, ai denotes thestart position of the source phrase that was trans-lated into the ith target phrase, and bi?1 denotesthe end position of the source phrase translatedinto the (i?1th) target phrase.
pLM (ei|e1 .
.
.
ei?1)is the language model probability that is based onthe Markov chain assumption.
It assigns a higherprobability to fluent/grammatical sentences.
?
?,?LM and ?d are used to give a different weight toeach element (for more details see (Koehn et al,2003)).In our reconstruction problem, the differencebetween the source and target sentences is not interms of languages, but in terms of forms.
In fact,our source sentence f is a stemmed sentence with-out stopwords, while the target sentence e is acomplete English sentence.
?Translate?
means toreconstruct the most probable sentence e given finserting new words and reproducing the inflectedsurface forms of the source words.4.1 Training of the modelIn Statistical Machine Translation, a PBM systemis trained using parallel sentences, where each sen-tence in a language is paired with another sentencein a different language and one is the translation ofthe other.In the reconstruction problem, we use a set, S1of 2,487,414 English sentences extracted from thenews.
This set is duplicated, S2, and for each sen-tence in S2, stopwords are removed and the re-maining words are stemmed using Porter?s stem-mer (Porter, 1980).
Our stopword list contains 488words.
Verbs are not included in this list, becausethey are relevant for the reconstruction task.
Tooptimize the lambda parameters, we select 2,000pairs as development set.384An example of training sentence pair is:?
Source Sentence: ?royal mail ha doubl profit 321million huge fall number letter post??
Target Sentence: ?royal mail has doubled its prof-its to 321 million despite a huge fall in the number ofletters being posted?In this work we use Moses (Koehn et al, 2007),a complete phrase-based translation toolkit foracademic purposes.
It provides all the state-of-the-art components needed to create a phrase-basedmachine translation system.
It contains differentmodules to preprocess data, train the LanguageModels and the Translation Models.5 Experimental ResultsFor our experiments we made use of the TAC2009 data which conveniently contains human-produced summaries against which we could eval-uate the output of our system (NIST, 2009).To begin our inquiry we carried out a phaseof exploratory data analysis, in which we mea-sured the average number of sentences per sum-mary, words per sentence and words per summaryin human vs. system summaries in the TAC 2009data.
Additionally, we also measured these statis-tics of summaries produced by our system at fivedifferent percentage cutoffs: 100%, 15%, 10%,5% and 1%.
4 The results from this explorationare summarised in table 1.
The most notable thingis that human summaries contain on average moreand shorter sentences than the system summaries(see 2nd and 3rd column from left to right).
Sec-ondly, we note that as the percentage cutoff de-creases (from 4th column rightwards) the charac-teristics of the summaries produced by our systemare increasingly more similar to those of the hu-man summaries.
In other words, within the 100-word window imposed by the TAC guidelines, oursystem is able to fit more (and hence shorter) sen-tences as we decrease the percentage cutoff.Summarization performance results are shownin table 2.
We used the standard ROUGE evalu-ation (Lin and Hovy, 2003) which has been alsoused for TAC.
We include the usual ROUGE met-rics: R1 is the maximum number of co-occurringunigrams, R2 is the maximum number of co-occurring bigrams and RSU4 is the skip bigrammeasure with the addition of unigrams as counting4Recall from section ?3 that the salience threshold is afunction of the percentage cutoff.unit.
The last five columns of table 2 (from left toright) correspond to summaries produced by oursystem at various percentage cutoffs.
The 2nd col-umn, LSAextract, corresponds to the performanceof our system at producing summaries by sentenceextraction only.5In the light of the above, the decrease in per-formance from column LSAextract to column ?At100%?
can be regarded as reconstruction error.6Then, as we decrease the percentage cutoff (from4th column rightwards) we are increasingly cover-ing more of the content comprised by the humansummaries (as far as the ROUGE metrics are ableto gauge this, of course).
In other words, the im-provement of content coverage makes up for thereconstruction error, and at 5% cutoff we alreadyobtain ROUGE scores comparable to LSAextract.This suggests that if we improve the quality of oursentence reconstruction we would potentially endup with a better performing system than a typicalLSA system based on sentence selection.
Hence,we find these results very encouraging.Finally, we admittedly note that by applying apercentage cutoff on the initial term set and furtherperforming the sentence reconstruction we gain incontent coverage, to a certain extent, on the ex-pense of sentence readability.6 ConclusionIn this paper we proposed a novel approach tosummary generation from summary representa-tion based on the LSA summarization frameworkand on a machine-translation-inspired techniquefor sentence reconstruction.Our preliminary results show that our approachis feasible, since it produces summaries which re-semble better human summaries in terms of the av-erage number of sentences per summary and yieldROUGE scores comparable to the participatingsystems in the Summarization task at TAC 2009.Bearing in mind that our approach is completelyunsupervised and language-independent, we findour results promising.In future work we plan on working towards im-proving the quality of our sentence reconstructionstep in order to produce better and more readablesentences.5These are, effectively, what we called initial pool of sen-tences in section 3, before the TSR generation.6The only difference between the two types of summariesis the reconstruction step, since we are including 100% of theterms.385ReferencesB.
Boguraev and C. Kennedy.
1997.
Salience-based content characterisation of text documents.
InI.
Mani, editor, Proceedings of the Workshop on In-telligent and Scalable Text Summarization at the An-nual Joint Meeting of the ACL/EACL, Madrid.P.
Brown, S. Della Pietra, V. Della Pietra, and R. Mer-cer.
1994.
The mathematic of statistical machinetranslation: Parameter estimation.
ComputationalLinguistics, 19(2):263?311.J.
Clarke and M. Lapata.
2008.
Global inference forsentence compression: An integer linear program-ming approach.
Journal of Artificial Intelligence Re-search, 31:273?318.G.
Erkan and D. Radev.
2004.
LexRank: Graph-basedcentrality as salience in text summarization.
Journalof Artificial Intelligence Research (JAIR).Y.
Gong and X. Liu.
2002.
Generic text summarizationusing relevance measure and latent semantic analy-sis.
In Proceedings of ACM SIGIR, New Orleans,US.E.
Hovy.
2005.
Automated text summarization.
InRuslan Mitkov, editor, The Oxford Handbook ofComputational Linguistics, pages 583?598.
OxfordUniversity Press, Oxford, UK.K.
Knight and D. Marcu.
2002.
Summarization be-yond sentence extraction: A probabilistic approachto sentence compression.
Artificial Intelligence,139(1):91?107.P.
Koehn, F. Och, and D. Marcu.
2003.
Statisticalphrase-based translation.
In Proceedings of NAACL?03, pages 48?54, Morristown, NJ, USA.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open source toolkitfor statistical machine translation.
In Proceedingsof ACL ?07, demonstration session.J.
Kupiec, J. Pedersen, and F. Chen.
1995.
A trainabledocument summarizer.
In Proceedings of the ACMSIGIR, pages 68?73, Seattle, Washington.C.
Lin and E. Hovy.
2003.
Automatic evaluation ofsummaries using n-gram co-occurrence statistics.
InProceedings of HLT-NAACL, Edmonton, Canada.NIST, editor.
2009.
Proceeding of the Text AnalysisConference, Gaithersburg, MD, November.F.
Och and H. Ney.
2001.
Discriminative trainingand maximum entropy models for statistical ma-chine translation.
In Proceedings of ACL ?02, pages295?302, Morristown, NJ, USA.M.
Porter.
1980.
An algorithm for suffix stripping.Program, 14(3):130?137.C.
Quirk, C. Brockett, and W. Dolan.
2004.
Monolin-gual machine translation for paraphrase generation.In Proceedings of EMNLP, volume 149.
Barcelona,Spain.K.
Spa?rck-Jones.
1999.
Automatic summarising: Fac-tors and directions.
In I. Mani and M. Maybury,editors, Advances in Automatic Text Summarization.MIT Press.J.
Steinberger and K. Jez?ek.
2009.
Update summariza-tion based on novel topic distribution.
In Proceed-ings of the 9th ACM DocEng, Munich, Germany.J.
Steinberger, M. Poesio, M. Kabadjov, and K. Jez?ek.2007.
Two uses of anaphora resolution in summa-rization.
Information Processing and Management,43(6):1663?1680.
Special Issue on Text Summari-sation (Donna Harman, ed.).R.
Zens, F. J. Och, and H. Ney.
2002.
Phrase-basedstatistical machine translation.
In Proceedings of KI?02, pages 18?32, London, UK.
Springer-Verlag.386
