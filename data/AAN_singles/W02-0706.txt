Architectures for speech-to-speech translationusing finite-state modelsFrancisco Casacuberta Enrique VidalDpt.
de Sistemes Informa`tics i Computacio?
&Institut Tecnolo`gic d?Informa`ticaUniversitat Polite`cnica de Vale`ncia46071 Vale`ncia, SPAIN.fcn@iti.upv.es, evidal@iti.upv.esJuan Miguel VilarDpt.
de Llenguatges i Sistemes Informa`ticsUniversitat Jaume ICastello?, SPAIN.jvilar@lsi.uji.esAbstractSpeech-to-speech translation can be ap-proached using finite state models andseveral ideas borrowed from automaticspeech recognition.
The models can beHidden Markov Models for the accous-tic part, language models for the sourcelanguage and finite state transducers forthe transfer between the source and targetlanguage.
A ?serial architecture?
woulduse the Hidden Markov and the languagemodels for recognizing input utteranceand the transducer for finding the transla-tion.
An ?integrated architecture?, on theother hand, would integrate all the mod-els in a single network where the searchprocess takes place.
The output of thissearch process is the target word sequenceassociated to the optimal path.
In botharchitectures, HMMs can be trained froma source-language speech corpus, and thetranslation model can be learned automat-ically from a parallel text training cor-pus.
The experiments presented here cor-respond to speech-input translations fromSpanish to English and from Italian to En-glish, in applications involving the inter-action (by telephone) of a customer withthe front-desk of a hotel.1 IntroductionPresent finite-state technology allows us to buildspeech-to-speech translation (ST) systems usingideas very similar to those of automatic speechrecognition (ASR).
In ASR the acoustic hiddenMarkov models (HMMs) can be integrated into thelanguage model, which is typically a finite-stategrammar (e.g.
a N-gram).
In ST the same HMMscan be integrated in a translation model which con-sists in a stochastic finite-state transducer (SFST).Thanks to this integration, the translation processcan be efficiently performed by searching for anoptimal path of states through the integrated net-work by using well-known optimization proceduressuch as (beam-search accelerated) Viterbi search.This ?integrated architecture?
can be compared withthe more conventional ?serial architecture?, wherethe HMMs, along with a suitable source languagemodel, are used as a front-end to recognize a se-quence of source-language words which is then pro-cessed by the translation model.
A related approachhas been proposed in (Bangalore and Ricardi, 2000;Bangalore and Ricardi, 2001).In any case, a pure pattern-recognition approachcan be followed to build the required systems.Acoustic models can be trained from a suffi-ciently large source-language speech training set,in the very same way as in speech recognition.On the other hand, using adequate learning algo-rithms (Casacuberta, 2000; Vilar, 2000), the trans-lation model can also be learned from a sufficientlylarge training set consisting of source-target paralleltext.In this paper, we comment the results obtained us-ing this approach in EUTRANS, a five-year joint ef-fort of four European institutions, partially fundedby the European Union.Association for Computational Linguistics.Algorithms and Systems, Philadelphia, July 2002, pp.
39-44.Proceedings of the Workshop on Speech-to-Speech Translation:2 Finite-state transducers and speechtranslationThe statistical framework allow us to formulate thespeech translation problem as follows: Let x be anacoustic representation of a given utterance; typi-cally a sequence of acoustic vectors or ?frames?.The translation of x into a target-language sentencecan be formulated as the search for a word se-quence, t?, from the target language such that:t?
= argmaxtPr(t|x).
(1)Conceptually, the translation can be viewed as atwo-step process (Ney, 1999; Ney et al, 2000):x ?
s ?
t,where s is a sequence of source-language wordswhich would match the observed acoustic sequencex and t is a target-language word sequence associ-ated with s. Consequently,Pr(t|x) =?sPr(t, s|x), (2)and, with the natural assumption that Pr(x|s, t) doesnot depend on the target sentence t,t?
= argmaxt(?sPr(s, t) ?
Pr(x|s)).
(3)Using a SFST as a model for Pr(s, t) and HMMsto model Pr(x|s), Eq.
3 is transformed in the opti-mization problem:t?
= argmaxt(?sPrT (s, t) ?
PrM(x|s)), (4)where PrT (s, t) is the probability supplied by theSFST and PrM(x|s) is the density value suppliedby the corresponding HMMs associated to s for theacoustic sequence x.2.1 Finite-state transducersA SFST, T , is a tuple ?Q,?,?, R, q0, F, P ?, whereQ is a finite set of states; q0 is the initial state; ?
and?
are finite sets of input symbols (source words) andoutput symbols (target words), respectively (???
=?
); R is a set of transitions of the form (q, a, ?, q?
)for q, q?
?
Q, a ?
?, ?
?
??
and1 P : R ?
IR+(transition probabilities) and F : Q ?
IR+ (final-state probabilities) are functions such that ?q ?
Q:F (q) +??
(a, ?, q?)
?
????
?Q :(q, a, ?, q?)
?
RP (q, a, ?, q?)
= 1.Fig.
1 shows a small fragment of a SFST for Spanishto English translation.A particular case of finite-state transducers areknown as subsequential transducers (SSTs).
Theseare finite-state transducers with the restriction of be-ing deterministic (if (q, a, ?, q), (q, a, ?
?, q?)
?
R,then ?
= ??
and q = q?).
SSTs also have outputstrings associated to the (final) states.
This can fitwell under the above formulation by simply addingan end-off-sentence marker to each input sentence.For a pair (s, t) ?
??
?
?
?, a translation form,?, is a sequence of transitions in a SFST T :?
: (q0, s1, ?t1, q1), (q1, s2, ?t2, q2),.
.
.
, (qI?1, sI , ?tI , qI),where ?tj denotes a substring of target words (theempty string for ?tj is also possible), such that?t1 ?t2 ... ?tI = t and I is the length of the source sen-tence s. The probability of ?
isPrT (?)
= F (qI) ?I?i=0P (qi?1, si, ?ti, qi).
(5)Finally, the probability of the pair (s, t) isPrT (s, t) =??
?d(s,t)PrT (?)
(6)?
max?
?d(s,t)PrT (?
), (7)where d(s, t) is the set of all translation forms forthe pair (s, t).These models have implicit source and target lan-guage models embedded in their definitions, whichare simply the marginal distributions of PrT .
Inpractice, the source (target) language model can beobtained by removing the target (source) words fromeach transition of the model.1By??
and??
we denote the sets of finite-length strings on?
and ?, respectively0 1una / a  (0.5)la / the (0.5)2habitaci?n / room (0.1)4habitaci?n / room (0.3)3habitaci?n / ?
(0.6)doble / with two beds (1)doble / double room (0.3)individual / single room (0.7)Figure 1: Example of SFST.
?
denotes the empty string.
The source sentence ?una habitacio?n doble?
canbe translated to either ?a double room?
or ?a room with two beds?.
The most probable translation is thefirst one with probability of 0.09.The structural (states and transitions) and theprobabilistic components of a SFST can be learnedautomatically from training pairs in a single processusing the MGTI technique (Casacuberta, 2000).
Al-ternatively, the structural component can be learnedusing the OMEGA technique (Vilar, 2000), whilethe probabilistic component is estimated in a secondstep using maximum likelihood or other possible cri-teria (Pico?
and Casacuberta, 2001).
One of the mainproblems that appear during the learning process isthe modelling of events that have not been seen inthe training set.
This problem can be confronted,in a similar way as in language modelling, by usingsmoothing techniques in the estimation process ofthe probabilistic components of the SFST (Llorens,2000).
Alternatively, smoothing can be applied inthe process of learning both components (Casacu-berta, 2000).2.2 Architectures for speech translationUsing Eq.
7 as a model for Pr(s, t) in Eq.
4,t?
= argmaxt(?smax?
?d(s,t)PrT (?)
?
PrM(x|s)),(8)For the computation of PrM(x|s) in Eq.
8, letb be an arbitrary segmentation of x into I acous-tic subsequences, each of which associated with asource word (therefore, I is the number of words ins).
Then:PrM(x|s) =?bI?i=1PrM(x?i|si), (9)where x?i is the i-th.
acoustic segment of b, and eachsource word si has an associated HMM that suppliesthe density value PrM(x?i|si).Finally, by substituting Eq.
5 and Eq.
9 into Eq.
8and approximating sums by maximisations:t?
= argmax?
?d(s,t),bI?i=1P (qi?1, si, t?i, qi) ?
PrM(x?i|si).
(10)Solving this maximisation yields (an approximationto) the most likely target-language sentence t?
for theobserved source-language acoustic sequence x.This computation can be accomplished using thewell known Viterbi algorithm.
It searches for an op-timal sequence of states in an integrated network (in-tegrated architecture) which is built by substitutingeach edge of the SFST by the corresponding HMMof the source word associated to the edge.This integration process is illustrated in Fig.
2.
Asmall SFST is presented in the first panel (a) of thisfigure.
In panel (b), the source words in each edgeare substituted by the corresponding phonetic tran-scription.
In panel (c) each phoneme is substitutedby the corresponding HMM of the phone.
Clearly,this direct integration approach often results in hugefinite-state networks.
Correspondingly, a straight-forward (dynamic-programming) search for an op-timal target sentence may require a prohibitivelyhigh computational effort.
Fortunately, this compu-tational cost can be dramatically reduced by meansof standard heuristic acceleration techniques such asbeam search.An alternative, which sacrifices optimality moredrastically, is to break the search down into twosteps, leading to a so-called ?serial architecture?.
Inthe first step a conventional source-language speechdecoding system (using just a source-language lan-guage model) is used to obtain a single (may be mul-tiple) hypothesis for the sequence of uttered words.In the second step, this text sequence is translatedinto a target-language sentence.0 1la / the 2maleta / ?3bolsa / ?
4azul / blue suitcaseazul / blue baga) Original FST.0 l / ?
1a / them / ?b / ?a / ?o / ?l / ?
e / ?
t / ?
2t / ?a / ?
a / ?
z / ?s / ?l / ?
s / ?3s / ?a / ?
a / ?
z / ?s / ?u / ?4l / blue suitcaseu / ?
l / blue bagb) Lexical expansion.0 l a 1   the   mba l etta2ao l ssa3azsu l4blue suitcasezsulblue bagc) Phonetic expansion.Figure 2: Example of the integration process of the lexical knowledge (figure b) and the phonetic knowledge(figure c) in a FST (figure a).
?
denotes the empty string in panels a and b.
In panel c, source symbols aretypeset in small fonts, target strings are typeset in large fonts and edges with no symbols denote emptytransitions.Using Pr(s, t) = Pr(t | s) ?
Pr(s) in Eq.
3 andapproximating the sum by the maximum, the opti-mization problem can be presented as(t?, s?)
= argmaxt,s(Pr(t|s) ?
Pr(s) ?
Pr(x|s)) ,(11)and the two-step approximation reduces tos?
?
argmaxs{Pr(s) ?
Pr(x|s)} , (12)t?
?
argmaxtPr(t|s?)
(13)= argmaxtPr(s?, t).
(14)In other words, the search for an optimal target-language sentence is now approximated as follows:1.
Word decoding of x.
A source-language sen-tence s?
is searched for using a source languagemodel, PrN (s), for Pr(s) and the correspond-ing HMMs, PrM(x|s), to model Pr(x|s):s?
?
argmaxs(PrN (s) ?
PrM(x|s)) .2.
Translation of s?.
A target-language sentence t?is searched for using a SFST, PrT (s?, t), as amodel of Pr(s?, t)t?
?
argmaxtPrT (s?, t).A better alternative for this crude ?two-step?
ap-proach is to use Pr(s, t) = Pr(s | t) ?Pr(t) in Eq.
3.Now, approximating the sum by the maximum, theoptimization problem can be presented as(t?, s?)
= argmaxt,s(Pr(s | t) ?
Pr(t) ?
Pr(x | s)) ,(15)and now the two-step approximation reduces tos?
?
argmaxs{Pr(s | t) ?
Pr(x | s)} , (16)t?
?
argmaxtPr(s?
| t) ?
Pr(t) (17)= argmaxtPr(s?, t).
(18)The main problem of this approach is the termt that appears in the first maximisation (Eq.
16).A possible solution is to follow an iterative proce-dure where t, that is used for computing s?, is theone obtained from argmaxt Pr(s?, t) in the previousiteration (Garc?
?a-Varea et al, 2000).
In this case,Pr(s | t) can be modelled by a source languagemodel that depends on a previously computed t?
:PrN ,t?(s).
In the first iteration no t?
is known, butPrN ,t?
(s) can be approximated by PrN (s).
Follow-ing this idea, the search can be formulated as:Initialization:Let PrN ,t(s) be approximated by a source lan-guage model PrN (s).while not convergence1.
Word decoding of x.
A source-language sen-tence s?
is searched for using a source lan-guage model that depends on the target sen-tence, PrN ,t?
(s), for Pr(s | t) (t?
is the t?
com-puted in the previous iteration) and the corre-sponding HMMs, PrM(x | s), to model Pr(x |s):s?
?
argmaxs(PrN ,t?
(s) ?
PrM(x | s)).2.
Translation of s?.
A target-language sentence t?is searched for using a SFST, PrT (s?, t), as amodel of Pr(s?, t)t?
?
argmaxtPrT (s?, t).end of whileThe first iteration corresponds to the sequential ar-chitecture proposed above.While this seems a promising idea, only verypreliminary experiments were carried out (Garc?
?a-Varea et al, 2000) and it has not been considered inthe experiments presented in the present paper.3 Experiments and resultsThree sets of speech-to-speech translation proto-types have been implemented for Spanish to Englishand for Italian to English.
In all of them, the appli-cation was the translation of queries, requests andcomplaints made by telephone to the front desk ofa hotel.
Three tasks of different degree of difficultyhave been considered.In the first one (EUTRANS-0), Spanish-to-Englishtranslation systems were learned from a big andwell controlled training corpus: about 170k differ-ent pairs (?
2M running words), with a lexicon ofabout 700 words.
In the second one (EUTRANS-I), also from Spanish to English, the systems werelearned from a random subset of 10k pairs (?
100krunning words) from the previous corpus; this wasestablished as a more realistic training corpus for thekind of application considered.
In the third and mostdifficult one, from Italian to English (EUTRANS-II),the systems were learned from a small training cor-pus that was obtained from a transcription of a spon-taneous speech corpus: about 3k pairs (?
60k run-ning words), with a lexicon of about 2,500 words.For the serial architecture, the speech decodingwas performed in a conventional way, using thesame acoustic models as with the integrated archi-tecture and trigrams of the source language models.For the integrated architecture, the speech decodingof an utterance is a sub-product of the translationprocess (the sequence of source words associated tothe optimal sequence of transitions that produces thesequence of target words).The acoustic models of phone units were trainedwith the HTK Toolkit (Woodland, 1997).
For theEUTRANS-0 and EUTRANS-I prototypes, a trainingspeech corpus of 57,000 Spanish running words wasused, while the EUTRANS-II Italian acoustic modelswere trained from another corpus of 52,000 runningwordsPerformance was assessed on the base of 336Spanish sentences in the case of EUTRANS-0and EUTRANS-I and 278 Italian sentences inEUTRANS-II.
In all the cases, the test sentences (aswell as the corresponding speakers) were differentfrom those appearing in the training data.For the easiest task, EUTRANS-0, (well controlledand a large training set), the best result was achievedwith an integrated architecture and a SFST obtainedwith the OMEGA learning technique.
A Transla-tion Word Error Rate of 7.6% was achieved, whilethe corresponding source-language speech decodingWord Error Rate was 8.4%.
Although these figuresmay seem strange (and they would certainly be inthe case of a serial architecture), they are in fact con-sistent with the fact that, in this task (corpus), the tar-get language exhibits a significantly lower perplex-ity than the source language.For the second, less easy task EUTRANS-I, (wellcontrolled task but a small training set), the bestresult was achieved with an integrated architectureand a SFST obtained with the MGTI learning tech-nique (10.5% of word error rate corresponding to thespeech decoding and 12.6% of translation word er-ror rate).For the most difficult task, EUTRANS-II (spon-taneous task and a small training set), the best resultwas achieved with a serial architecture and a SFSTobtained with the MGTI learning technique (22.1%of word error rate corresponding to the speech de-coding and 37.9% of translation word error rate).4 ConclusionsSeveral systems have been implemented for speech-to-speech translation based on SFSTs.
Some of themwere implemented for translation from Italian to En-glish and the others for translation from Spanish toEnglish.
All of them support all kinds of finite-statetranslation models and run on low-cost hardware.They are currently accessible through standard tele-phone lines with response times close to or betterthan real time.From the results presented, it appears that the in-tegrated architecture allows for the achievement ofbetter results than the results achieved with a serialarchitecture when enough training data is availableto train the SFST.
However, when the training datais insufficient, the results obtained by the serial ar-chitecture were better than the results obtained bythe integrated architecture.
This effect is possiblebecause the source language models for the exper-iments with the serial architecture were smoothedtrigrams.
In the case of sufficient training data, thesource language model associated to a SFST learntby the MGTI or OMEGA is better than trigrams(Section 2.1).
However, in the other case (not suf-ficient training data) these source languages wereworse than trigrams.
Consequently an importantdegradation is produced in the implicit decoding ofthe input utterance.AcknowledgmentsThe authors would like to thank the researchers thatparticipated in the EUTRANS project and have de-veloped the methodologies that are presented in thispaper.This work has been partially supported by the Eu-ropean Union under grant IT-LTR-OS-30268, by theproject TT2 in the ?IST, V Framework Programme?,and Spanish project TIC 2000-1599-C02-01.ReferencesS.
Bangalore and G. Ricardi.
2000.
Stochastic finite-state models for spoken language machine translation.In Workshop on Embeded Machine Translation Sys-tems.S.
Bangalore and G. Ricardi.
2001.
A finite-state ap-proach to machine translation.
In The Second Meetingof the North American Chapter of the Association forComputational Linguistics.F.
Casacuberta.
2000.
Inference of finite-state trans-ducers by using regular grammars and morphisms.In Grammatical Inference: Algorithms and Applica-tions, volume 1891 of Lecture Notes in Artificial Intel-ligence, pages 1?14.
Springer-Verlag.I.
Garc?
?a-Varea, A. Sanchis, and F. Casacuberta.
2000.A new approach to speech-input statistical translation.In Proceedings of the International Conference on Pat-tern Recognition (ICPR2000), volume 2, pages 907?910, Barcelona, Sept. IAPR, IEEE Press.D.
Llorens.
2000.
Suavizado de auto?matas y traduc-tores finitos estoca?sticos.
Ph.D. thesis, UniversitatPolite`cnica de Vale`ncia.H.
Ney, S. Nie?en, F. Och, H. Sawaf, C. Tillmann, andS.
Vogel.
2000.
Algorithms for statistical translationof spoken language.
IEEE Transactions on Speech andAudio Processing, 8(1):24?36.H.
Ney.
1999.
Speech translation: Coupling of recogni-tion and translation.
In Proceedins of the IEEE Inter-national Conference on Acoustic, Speech and SignalProcessing, pages 517?520, Phoenix, AR, March.D.
Pico?
and F. Casacuberta.
2001.
Some statistical-estimation methods for stochastic finite-state transduc-ers.
Machine Learning, 44:121?141.J.M.
Vilar.
2000.
Improve the learning of subsequen-tial transducers by using alignments and dictionaries.In Grammatical Inference: Algorithms and Applica-tions, volume 1891 of Lenture Notes in Artificial Intel-ligence, pages 298?312.
Springer-Verlag.S.
Young; J. Odell; D. Ollason; V. Valtchev; P. Wood-land.
1997.
The HTK Book (Version 2.1).
CambridgeUniversity Department and Entropic Research Labora-tories Inc.
