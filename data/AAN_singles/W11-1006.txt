Proceedings of SSST-5, Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 52?60,ACL HLT 2011, Portland, Oregon, USA, June 2011. c?2011 Association for Computational LinguisticsAn Evaluation and Possible Improvement Path for Current SMT Behavioron Ambiguous NounsEls Lefever1,2 and Ve?ronique Hoste1,2,31LT3, Language and Translation Technology Team, University College GhentGroot-Brittannie?laan 45, 9000 Gent, Belgium2Dept.
of Applied Mathematics and Computer Science, Ghent UniversityKrijgslaan 281 (S9), 9000 Gent, Belgium3Dept.
of Linguistics, Ghent UniversityBlandijnberg 2, 9000 Gent, BelgiumAbstractMistranslation of an ambiguous word can havea large impact on the understandability of agiven sentence.
In this article, we describea thorough evaluation of the translation qual-ity of ambiguous nouns in three different se-tups.
We compared two statistical MachineTranslation systems and one dedicated WordSense Disambiguation (WSD) system.
OurWSD system incorporates multilingual infor-mation and is independent from external lex-ical resources.
Word senses are derived auto-matically from word alignments on a parallelcorpus.
We show that the two WSD classifiersthat were built for these experiments (English?French and English?Dutch) outperform theSMT system that was trained on the same cor-pus.
This opens perspectives for the integra-tion of our multilingual WSD module in a sta-tistical Machine Translation framework, in or-der to improve the automated translation ofambiguous words, and by consequence makethe translation output more understandable.1 IntroductionWord Sense Disambiguation (WSD) is the NLPtask that consists in assigning a correct sense toan ambiguous word in a given context.
Tradition-ally, WSD relies on a predefined monolingual sense-inventory such as WordNet (Fellbaum, 1998) andWSD modules are trained on corpora, which aremanually tagged with senses from these inventories.A number of issues arise with these monolingual su-pervised approaches to WSD.
First of all, there is alack of large sense-inventories and sense-tagged cor-pora for languages other than English.
Furthermore,sense inventories such as WordNet contain very fine-grained sense distinctions that make the sense dis-ambiguation task very challenging (even for humanannotators), whereas very detailed sense distinctionsare often irrelevant for practical applications.
In ad-dition to this, there is a growing feeling in the com-munity that WSD should be used and evaluated inreal application such as Machine Translation (MT)or Information Retrieval (IR) (Agirre and Edmonds,2006).An important line of research consists in the de-velopment of dedicated WSD modules for MT.
In-stead of assigning a sense label from a monolin-gual sense-inventory to the ambiguous words, theWSD system has to predict a correct translation forthe ambiguous word in a given context.
In (Vick-rey et al, 2005), the problem was defined as a wordtranslation task.
The translation choices of ambigu-ous words are gathered from a parallel corpus bymeans of word alignment.
The authors reportedimprovements on two simplified translation tasks:word translation and blank filling.
The evaluationwas done on an English-French parallel corpus butis confronted with the important limitation of hav-ing only one valid translation (the aligned transla-tion in the parallel corpus) as a gold standard trans-lation.
Cabezas and Resnik (2005) tried to improvean SMT system by adding additional translations tothe phrase table, but were confronted with tuningproblems of this dedicated WSD feature.
Specia(2006) used an inductive logic programming-basedWSD system which was tested on seven ambigu-ous verbs in English-Portuguese translation.
The lat-ter systems already present promising results for theuse of WSD in MT, but really significant improve-ments in terms of general machine translation qual-52ity were for the first time obtained by Carpuat andWu (2007) and Chan et al (2007).
Both papersdescribe the integration of a dedicated WSD mod-ule in a Chinese-English statistical machine trans-lation framework and report statistically significantimprovements in terms of standard MT evaluationmetrics.Stroppa et al (2007) take a completely dif-ferent approach to perform some sort of implicitWord Sense Disambiguation in MT.
They introducecontext-information features that exploit source sim-ilarity, in addition to target similarity that is modeledby the language model, in an SMT framework.
Forthe estimation of these features that are very simi-lar to the typical WSD local context features (leftand right context words, Part-of-Speech of the focusphrase and context words), they use a memory-basedclassification framework.The work we present in this paper is differentfrom previous research in two aspects.
Firstly,we evaluate the performance of two state-of-the-artSMT systems and a dedicated WSD system on thetranslation of ambiguous words.
The comparison isdone against a manually constructed gold-standardfor two language pairs, viz.
English?French andEnglish?Dutch.
Although it is crucial to measure thegeneral translation quality after integrating a dedi-cated WSD module in the SMT system, we think it isequally interesting to conduct a dedicated evaluationof the translation quality on ambiguous nouns.
Stan-dard SMT evaluation metrics such as BLEU (Pap-ineni et al, 2002) or edit-distance metrics (e.g.
WordError Rate) measure the global overlap of the trans-lation with a reference, and are thus not very sen-sitive to WSD errors.
The mistranslation of an am-biguous word might be a subtle change compared tothe reference sentence, but it often drastically affectsthe global understanding of the sentence.Secondly, we explore the potential benefits of areal multilingual approach to WSD.
The idea to usetranslations from parallel corpora to distinguish be-tween word senses is based on the hypothesis thatdifferent meanings of a polysemous word are oftenlexicalized across languages (Resnik and Yarowsky,2000).
Many WSD studies have incorporated thiscross-lingual evidence idea and have successfullyapplied bilingual WSD classifiers (Gale and Church,1993; Ng et al, 2003; Diab and Resnik, 2002) orsystems that use a combination of existing Word-Nets with multilingual evidence (Tufis?
et al, 2004).Our WSD system is different in the sense that it isindependent from a predefined sense-inventory (itonly uses the parallel corpus at hand) and that itis truly multilingual as it incorporates informationfrom four other languages (French, Dutch, Span-ish, Italian and German depending on the target lan-guage of the classifier).
Although our classifiers arestill very preliminary in terms of the feature set andparameters that are used, we obtain interesting re-sults on our test sample of ambiguous nouns.
Wetherefore believe our system can have a real addedvalue for SMT, as it can easily be trained for differ-ent language pairs on exactly the same corpus whichis used to train the SMT system, which should makethe integration a lot easier.The remainder of this paper is organized as fol-lows.
Section 2 introduces the two machine transla-tion systems we evaluated, while section 3 describesthe feature construction and learning algorithm ofour multilingual WSD system.
Section 4 gives anoverview of the experimental setup and results.
Wefinally draw conclusions and present some future re-search in Section 5.2 Statistical Machine Translation SystemsFor our experiments, we analyzed the behaviorof two phrase-based statistical machine translation(SMT) systems on the translation of ambiguousnouns.
SMT generates translations on the basisof statistical models whose parameters are derivedfrom the analysis of sentence-aligned parallel textcorpora.
Phrase-based SMT is considered as thedominant paradigm in MT research today.
It com-bines a phrase translation model (which is based onthe noisy channel model) and a phrase-based de-coder in order to find the most probable translation eof a foreign sentence f (Koehn et al, 2003).
Usuallythe Bayes rule is used to reformulate this translationprobability:argmaxep(e|f) = argmaxep(f |e)p(e)This allows for a language model p(e) that guar-antees the fluency and grammatical correctness ofthe translation, and a separate translation modelp(f |e) that focusses on the quality of the transla-53tion.
Training of both the language model (on mono-lingual data) as well as the translation model (onbilingual text corpora) requires large amounts of textdata.Research has pointed out that adding more train-ing data, both for the translation as for the lan-guage models, results in better translation quality,(Callison-Burch et al, 2009).
Therefore it is impor-tant to notice that our comparison of the two SMTsystems is somewhat unfair, as we compared theMoses research system (that was trained on the Eu-roparl corpus) with the Google commercial systemthat is trained on a much larger data set.
It remainsan interesting exercise though, as we consider thecommercial system as the upper bound of how farcurrent SMT can get in case it has unlimited accessto text corpora and computational resources.2.1 MosesThe first statistical machine translation system weused is the off-the-shelf Moses toolkit (Koehn et al,2007).
As the Moses system is open-source, welldocumented, supported by a very lively users fo-rum and reaches state-of-the-art performance, it hasquickly been adopted by the community and highlystimulated development in the SMT field.
It also fea-tures factored translation models, which enable theintegration of linguistic and other information at theword level.
This makes Moses a good candidate toexperiment with for example a dedicated WSD mod-ule, that requires more enhanced linguistic informa-tion (such as lemmas and Part-of-Speech tags).We trained Moses for English?French and English?Dutch on a large subsection of the Europarl corpus(See Section 3 for more information on the corpus),and performed some standard cleaning.
Table 1 liststhe number of aligned sentences after cleaning thebilingual corpus, and the number of uni-, bi- and tri-grams that are comprised by the language model.2.2 GoogleIn order to gain insights in the upper bounds forcurrent SMT, we also analyzed the output of theGoogle Translate API1 for our set of ambiguousnouns.
Google Translate currently supports 57 lan-guages.
As both the amount of parallel and mono-1http://code.google.com/apis/language/translate/overview.htmlFrench DutchNumber of bilingual sentence pairs872.689 873.390Number of ngramsunigrams 103.027 173.700bigrams 1.940.925 2.544.554trigrams 2.054.906 1.951.992Table 1: Statistics resulting from the Moses trainingphaselingual training data as well as the computer powerare crucial for statistical MT, Google (that disposesof large computing clusters and a network of datacenters for Web search) has very valuable assets atits disposal for this task.
We can only speculateabout the amount of resources that Google uses totrain its translation engine.
Part of the training datacomes from transcripts of United Nations meetings(in six official languages) and those of the Euro-pean Parliament (Europarl corpus).
Google researchpapers report on a distributed infrastructure that isused to train on up to two trillion tokens, which re-sult in language models containing up to 300 billionngrams (Brants et al, 2007).3 ParaSenseThis section describes the ParaSense WSD system:a multilingual classification-based approach toWord Sense Disambiguation.
Instead of usinga predefined monolingual sense-inventory suchas WordNet, we use a language-independentframework where the word senses are derivedautomatically from word alignments on a parallelcorpus.
We used the sentence-aligned Europarlcorpus (Koehn, 2005) for the construction of ourWSD module.
The following six languages wereselected: English (our focus language), Dutch,French, German, Italian and Spanish.
We onlyconsidered the 1-1 sentence alignments betweenEnglish and the five other languages.
This way weobtained a six-lingual sentence-aligned subcorpusof Europarl, that contains 884.603 sentences perlanguage.
For our experiments we used the lexicalsample of twenty ambiguous nouns that was alsoused in the SemEval-2010 ?Cross-Lingual WordSense Disambiguation?
(CLWSD) task (Lefeverand Hoste, 2010b), which consists in assigning a54correct translation in five supported target languages(viz.
French, Italian, Spanish, German and Dutch)for an ambiguous focus word in a given context.In order to detect all relevant translationsfor the twenty ambiguous focus words, we ranGIZA++ (Och and Ney, 2003) with its default set-tings on our parallel corpus.
The obtained wordalignment output was then considered to be the clas-sification label for the training instances for a givenclassifier (e.g.
the French translation resulting fromthe word alignment is the label that is used to trainthe French classifier).
This way we obtained allclass labels (or oracle translations) for all traininginstances for our five classifiers (English as an inputlanguage and French, German, Dutch, Italian andSpanish as target languages).
For the experimentsdescribed in this paper, we focused on the English?French and English?Dutch classifiers.We created two experimental setups.
The firsttraining set contains the automatically generatedword alignment translations as labels.
A postpro-cessing step was applied on these translations in or-der to automatically filter leading and trailing deter-miners and prepositions from the GIZA++ output.For the creation of the second training set, we man-ually verified all word alignment correspondencesof the ambiguous words.
This second setup givesan idea of the upperbound performance in case theword alignment output could be further improved forour ambiguous nouns.3.1 ClassifierTo train our WSD classifiers, we used the memory-based learning (MBL) algorithms implemented inTIMBL (Daelemans and van den Bosch, 2005),which has successfully been deployed in previousWSD classification tasks (Hoste et al, 2002).
Weperformed very basic heuristic experiments to de-fine the parameter settings for the classifier, leadingto the selection of the Jeffrey Divergence distancemetric, Gain Ratio feature weighting and k = 7 asnumber of nearest neighbours.
In future work, weplan to use an optimized word-expert approach inwhich a genetic algorithm performs joint feature se-lection and parameter optimization per ambiguousword (Daelemans et al, 2003).3.2 Feature ConstructionFor the feature vector construction, we combine lo-cal context features that were extracted from the En-glish sentence and a set of binary bag-of-words fea-tures that were extracted from the aligned transla-tions in the four other languages (that are not thetarget language of the classifier).3.2.1 Local Context FeaturesWe extract the same set of local context featuresfrom both the English training and test instances.
AllEnglish sentences were preprocessed by means of amemory-based shallow parser (MBSP) (Daelemansand van den Bosch, 2005) that performs tokeniza-tion, Part-of-Speech tagging and text chunking.
Thepreprocessed English instances were used as inputto build a set of commonly used WSD features:?
features related to the focus word itself beingthe word form of the focus word, the lemma,Part-of-Speech and chunk information,?
local context features related to a window ofthree words preceding and following the focusword containing for each of these words theirfull form, lemma, Part-of-Speech and chunk in-formationThese local context features are to be consideredas a basic feature set.
The Senseval evaluation ex-ercises have shown that feeding additional informa-tion sources to the classifier results in better systemperformance (Agirre and Martinez, 2004).
In fu-ture experiments we plan to integrate a.o.
lemmainformation on the surrounding content words andsemantic analysis (e.g.
Singular Value Decomposi-tion (Gliozzo et al, 2005)) in order to detect latentcorrelations between terms.3.2.2 Translation FeaturesIn addition to the commonly deployed local con-text features, we also extracted a set of binary bag-of-words features from the aligned translations thatare not the target language of the classifier (e.g.for the French classifier, we extract bag-of-wordsfeatures from the Italian, Spanish, Dutch and Ger-man aligned translations).
We preprocessed allaligned translations by means of the Treetaggertool (Schmid, 1994) that outputs Part-of-Speech and55lemma information.
Per ambiguous focus word, alist of all content words (nouns, adjectives, adverbsand verbs) that occurred in the aligned translationsof the English sentences containing this word, wasextracted.
This resulted in one binary feature per se-lected content word per language.
For the construc-tion of the translation features for the training set,we used the Europarl aligned translations.As we do not dispose of similar aligned trans-lations for our test instances (where we only havethe English test sentences at our disposal), we hadto adopt a different strategy.
We decided to usethe Google Translate API to automatically generatetranslations for all English test instances in the fivetarget languages.
This automatic translation pro-cess can be done using whatever machine translationtool, but we chose the Google API because of itseasy integration.
Online machine translation toolshave already been used before to create artificialparallel corpora that were used for NLP tasks suchas for instance Named Entity Recognition (Shah etal., 2010).
Similarly, Navigli and Ponzetto (2010)used the Google Translate API to enrich BabelNet, awide-coverage multilingual semantic network, withlexical information for all languages.Once the automatic aligned translations were gen-erated, we preprocessed them in the same way as wedid for the aligned training translations.
In a nextstep, we again selected all content words from thesetranslations and constructed the binary bag-of-wordsfeatures.4 EvaluationTo evaluate the two machine translation systems aswell as the ParaSense system on their performanceon the lexical sample of twenty ambiguous words,we used the sense inventory and test set of the Sem-Eval Cross-Lingual Word Sense Disambiguationtask.
The sense inventory was built up on the ba-sis of the Europarl corpus: all retrieved translationsof a polysemous word were manually grouped intoclusters, which constitute different senses of thatgiven word.
The test instances were selected fromthe JRC-ACQUIS Multilingual Parallel Corpus2 andBNC3.
There were in total 50 test instances for each2http://wt.jrc.it/lt/Acquis/3http://www.natcorp.ox.ac.uk/of the twenty ambiguous words in the sample.
To la-bel the test data, native speakers assigned three validtranslations from the predefined clusters of Europarltranslations to each test instance.
A more detaileddescription of the construction of the data set canbe found in (Lefever and Hoste, 2010a).
As eval-uation metric, we used a straightforward accuracymeasure that divides the number of correct answersby the total amount of test instances.
As a baseline,we selected the most frequent lemmatized transla-tion that resulted from the automated word align-ment (GIZA++).The output of the ParaSense WSD module con-sists of a lemmatized translation of the ambiguousfocus word in the target language.
The output ofthe two statistical machine translation systems,however, is a translation of the full English inputsentence.
Therefore we manually selected thetranslation of the ambiguous focus word from thefull translation, and made sure the translation wasput in its base form (masculine singular form fornouns and adjectives, infinitive form for verbs).Table 2 lists the accuracy figures for the baseline,two flavors of the ParaSense system (with and with-out correction of the word alignment output), Mosesand Google for English?French and English?Dutch.A first conclusion is that all systems beat themost frequent sense baseline.
As expected, theGoogle system (where there was no limitation onthe training data) achieves the best results, but forFrench the considerable difference in training sizeonly leads to modest performance gains comparedto the ParaSense System.
Another interesting obser-vation is that the ParaSense system that uses manu-ally verified translation labels hardly beats the sys-tem that uses automatically generated class labels.This is promising as it makes the manual interven-tions on the data superfluous and leads to a fully au-tomatic system development process.Figure 1 illustrates the accuracy figures for Frenchfor all three systems (for the ParaSense system weused the flavor that incorporates the non-validatedtranslation labels) on all individual test words.The three curves follow a similar pattern, exceptfor some words where Moses (mood, scene, side) orboth Moses and ParaSense (figure) perform worse.As the curves show, some words (e.g.
coach, figure,56Figure 1: Accuracy figures per system for all 20 test wordsFrench DutchBaseline 63% 59%ParaSense systemNon Corrected 75% 68%word alignment labelsCorrected word 76% 68%alignment labelsSMT SystemsMoses 71% 63%Google 78% 74%Table 2: Accuracy figures averaged over all twenty testwordsmatch, range) are particularly hard to disambiguate,while others obtain very high scores (e.g.
letter, mis-sion, soil).
The almost perfect scores for the lattercan be explained by the fact that these words all havea very generic translation in French (respectively let-tre, mission, sol) that can be used for all senses ofthe word, although there might be more suited trans-lations for each of the senses depending on the con-text.
As the manual annotators could pick three goodtranslations for each test instance, the most generictranslation often figures between the gold standardtranslations.The low scores for some other words can often beexplained through the relationship with the numberof training instances (corresponding to the frequencyNumber of Number ofInstances Translationscoach 66 11education 4380 55execution 489 26figure 2298 167job 7531 184letter 1822 75match 109 21mission 1390 46mood 100 26paper 3650 94post 998 68pot 63 27range 1428 145rest 1739 80ring 143 46scene 284 50side 3533 261soil 287 16strain 134 40test 1368 92Table 3: Number of instances and classes for all twentytest words in Frenchof the word in the training corpus) and the ambigu-ity (number of translations) per word.
As is shownin Table 3, both for coach and match there are veryfew examples in the corpus, while figure and range57are very ambiguous (respectively 167 and 145 trans-lations to choose from).The main novelty of our ParaSense system lies inthe application of a multilingual approach to per-form WSD, as opposed to the more classical ap-proach that only uses monolingual local context fea-tures.
Consequently we also ran a set of additionalexperiments to examine the contribution of the dif-ferent translation features to the WSD performance.Table 4 shows the accuracy figures for French andDutch for a varying number of translation featuresincluding the other four languages: Italian, Span-ish, French and Dutch for the French classifier orFrench for the Dutch classifier.
The scores clearlyconfirm the validity of our hypothesis: the classifiersusing translation features are constantly better thanthe one that merely uses English local context fea-tures.
For French, the other two romance languagesseem to contribute most: the classifier that uses Ital-ian and Spanish bag-of-words features achieves thebest performance (75.50%), whereas the classifierthat incorporates German and Dutch translations ob-tains the worst scores (71.90%).
For Dutch, the in-terpretation of the scores is less straightforward: theItalian-German combination achieves the best result(69%), but the difference with the other classifiersthat use two romance languages (Italian-Spanish:67.70% and Italian-French: 67.20%) is less salientthan for French.
In order to draw final conclusionson the contribution of the different languages, weprobably first need to optimize our feature base andclassification parameters.
For the current experi-ments, we use very sparse bag-of-words features thatcan be optimized in different ways (e.g.
feature se-lection, reduction of the bag-of-words features byapplying semantic analysis such as Singular ValueDecomposition, etc.
).5 ConclusionWe presented a thorough evaluation of two statis-tical Machine Translation systems and one dedi-cated WSD system on a lexical sample of Englishambiguous nouns.
Our WSD system incorporatesboth monolingual local context features and bag-of-words features that are built from aligned trans-lations in four additional languages.
The best re-sults are obtained by Google, the SMT system thatFrench DutchBaseline 63.10 59.40All four translation featuresIt, Es, De, Nl/Fr 75.20 68.10Three translation featuresIt, Es, De 75.00 67.80Es, De, Nl/Fr 74.70 66.30It, De, Nl/Fr 75.20 68.20It, Es, Nl/Fr 75.30 67.90Average 75.05 67.55Two translation featuresEs, De 74.70 67.80It, De 75.10 69.00De, Nl/Fr 71.90 68.00It, Es 75.50 67.70Es, Nl/Fr 74.20 68.10It, Nl/Fr 75.30 67.20Average 74.45 67.96One translation featureDe 74.50 66.50Es 75.20 68.40It 74.90 66.70Nl/Fr 73.80 66.20Average 74.60 66.95No translation featuresNone 73.50 63.90Table 4: Accuracy figures for French and Dutch for avarying number of translation features including the otherfour languages viz.
Italian (It), Spanish (Es), German(De) and French (Fr) or Dutch (Nl)is built with no constraints on data size or compu-tational resources.
Although there is still a lot ofroom for improvement on the feature base and op-timization of the WSD classifiers, our results showthat the ParaSense system outperforms Moses that isbuilt with the same training corpus.We also noticed large differences among the testwords, often related to the number of training in-stances and the number of translations the classifier(or decoder) has to choose from.Additional experiments with the ParaSense sys-tem incorporating a number of varying translationsfeatures allow us to confirm the validity of our hy-pothesis.
The classifiers that use the multilingualbag-of-words features clearly outperform the clas-sifier that only uses local context features.In future work, we want to expand our feature setand apply a genetic algorithm to perform joint fea-ture selection, parameter optimization and instance58selection.
In addition, we will apply semantic anal-ysis tools (such as SVD or LSA) on our multilingualbag-of-words sets in order to detect latent semantictopics in the multilingual feature base.
Finally, wewant to evaluate to which extent the integration ofour WSD output helps the decoder to pick the cor-rect translation in a real SMT framework.ReferencesE.
Agirre and P. Edmonds, editors.
2006.
Word SenseDisambiguation.
Algorithms and Applications.
Text,Speech and Language Technology.
Springer, Dor-drecht.E.
Agirre and D. Martinez.
2004.
Smoothing and WordSense Disambiguation.
In Proceedings of EsTAL -Espan?a for Natural Language Processing, Alicante,Spain.Th.
Brants, A.C. Popat, P. Xu, F.J. Och, and J. Dean.2007.
Large Language Models in Machine Transla-tion.
In Proceedings of the 2007 Joint Conferenceon Empirical methods in Natural Language Process-ing and Computational Natural Language Learning,pages 858?867.C.
Cabezas and P. Resnik.
2005.
Using wsd tech-niques for lexical selection in statistical machine trans-lation.
Technical report, Institute for Advanced Com-puter Studies, University of Maryland.C.
Callison-Burch, Ph.
Koehn, Ch.
Monz, andJ.
Schroeder.
2009.
Findings of the 2009 Workshopon Statistical Machine Translation.
In Proceedings ofthe 4th EACL Workshop on Statistical Machine Trans-lation, pages 1?28, Athens, Greece.M.
Carpuat and D. Wu.
2007.
Improving statisticalmachine translation using word sense disambiguation.In Proceedings of the 2007 Joint Conference on Em-pirical Methods in Natural Language Processing andComputational Natural Language Learning (EMNLP-CoNLL), pages 61?72, Prague, Czech Republic.Y.S.
Chan, H.T.
Ng, and D. Chiang.
2007.
Word sensedisambiguation improves statistical machine transla-tion.
In Proceedings of the 45th Annual Meeting of theAssociation of Computational Linguistics, pages 33?40, Prague, Czech Republic.W.
Daelemans and A. van den Bosch.
2005.
Memory-based Language Processing.
Cambridge UniversityPress.W.
Daelemans, V. Hoste, F. De Meulder, and B. Naudts.2003.
Combined optimization of feature selection andalgorithm parameters in machine learning of language.Machine Learning, pages 84?95.M.
Diab and P. Resnik.
2002.
An Unsupervised Methodfor Word Sense Tagging Using Parallel Corpora.
InProceedings of ACL, pages 255?262.C.
Fellbaum.
1998.
WordNet: An Electronic LexicalDatabase.
MIT Press.W.A.
Gale and K.W.
Church.
1993.
A program for align-ing sentences in bilingual corpora.
ComputationalLinguistics, 19(1):75?102.A.M.
Gliozzo, C. Giuliano, and C. Strapparava.
2005.Domain Kernels for Word Sense Disambiguation.
In5943nd Annual Meeting of the Association for Computa-tional Linguistics.
(ACL-05).V.
Hoste, I. Hendrickx, W. Daelemans, and A. van denBosch.
2002.
Parameter Optimization for Machine-Learning of Word Sense Disambiguation.
NaturalLanguage Engineering, Special Issue on Word SenseDisambiguation Systems, 8:311?325.P.
Koehn, F.J. Och, and D. Marcu.
2003.
StatisticalPhrase-based translation.
In HLT-NAACL 2003: con-ference combining Human Language Technology con-ference series and the North American Chapter of theAssociation for Computational Linguistics conferenceseries, pages 48?54, Edmonton, Canada.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open Source Toolkit forStatistical Machine Translation.
In Proceedings of theACL 2007 Demo and Poster Sessions, pages 177?180,Prague, Czech Republic.P.
Koehn.
2005.
Europarl: a parallel corpus for statisti-cal machine translation.
In Tenth Machine TranslationSummit, pages 79?86, Phuket, Thailand.E.
Lefever and V. Hoste.
2010a.
Constructionof a Benchmark Data Set for Cross-Lingual WordSense Disambiguation.
In Nicoletta Calzolari, KhalidChoukri, Bente Maegaard, Joseph Mariani, Jan Odijk,Stelios Piperidis, and Daniel Tapias, editors, Proceed-ings of the seventh International Conference on Lan-guage Resources and Evaluation (LREC?10), Valletta,Malta, May.
European Language Resources Associa-tion (ELRA).E.
Lefever and V. Hoste.
2010b.
SemEval-2010 Task3: Cross-Lingual Word Sense Disambiguation.
InProceedings of the 5th International Workshop on Se-mantic Evaluation, ACL 2010, pages 15?20, Uppsala,Sweden.R.
Navigli and S.P.
Ponzetto.
2010.
BabelNet: Buildinga very large multilingual semantic network.
In Pro-ceedings of the 48th Annual Meeting of the Associ-ation for Computational Linguistics, pages 216?225,Uppsala, Sweden.H.T.
Ng, B. Wang, and Y.S.
Chan.
2003.
Exploiting par-allel texts for word sense disambiguation: An empiri-cal study.
In 41st Annual Meeting of the Associationfor Computational Linguistics (ACL), pages 455?462,Sapporo, Japan.F.
J. Och and H. Ney.
2003.
A systematic comparison ofvarious statistical alignment models.
ComputationalLinguistics, 29(1):19?51.K.
Papineni, S. Roukos, T. Ward, and Zhu W.-J.
2002.BLEU: a method for automatic evaluation of machinetranslation.
In Proceedings of the 40th Annual Meet-ing of the Association for Computational Linguistics.Ph.
Resnik and D. Yarowsky.
2000.
Distinguishing sys-tems and distinguishing senses: New evaluation meth-ods for word sense disambiguation.
Natural LanguageEngineering, 5(3):113?133.H.
Schmid.
1994.
Probabilistic part-of-speech taggingusing decision trees.
In Proceedings of the Interna-tional Conference on new methods in Language Pro-cessing, Manchester, UK.R.
Shah, B. Lin, A. Gershman, and R. Frederking.
2010.SYNERGY: A Named Entity Recognition System forResource-scarce Languages such as Swahili using On-line Machine Translation.
In Proceedings of theSecond Workshop on African Language Technology(AFLAT 2010), Valletta, Malt.L.
Specia.
2006.
A Hybrid Relational Approach forWSD - First Results.
In Proceedings of the COL-ING/ACL 2006 Student Research Workshop, pages 55?60, Sydney, Australia.N.
Stroppa, A. van den Bosch, and A.
Way.
2007.Exploiting source similarity for smt using context-informed features.
In Proceedings of the 11th Con-ference on Theoretical and Methodological Issues inMachine Translation (TMI 2007).D.
Tufis?, R. Ion, and N. Ide.
2004.
Fine-GrainedWord Sense Disambiguation Based on Parallel Cor-pora, Word Alignment, Word Clustering and AlignedWordnets.
In Proceedings of the 20th InternationalConference on Computational Linguistics (COLING2004), pages 1312?1318, Geneva, Switzerland, Au-gust.
Association for Computational Linguistics.D.
Vickrey, L. Biewald, M. Teyssier, and D. Koller.
2005.Word-sense disambiguation for machine translation.In Proceedings of EMNLP05, pages 771?778.60
