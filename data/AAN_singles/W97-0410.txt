Expanding the Domain of a Multi-l ingualSpeech-to-Speech Translation SystemAlon Lavie, Lori Levin, Puming Zhan, Maite Taboada, Donna Gates,Mirella Lapata, Cortis Clark, Matthew Broadhead, Alex WaibelInteractive Systems LaboratorySchool of Computer ScienceCarnegie Mellon University5000 Forbes Ave., Pittsburgh, PA 15213emai l  : l av ie~cs .cmu.eduAbstractJANUS is a multi-lingual speech-to-speech translationsystem, which has been designed to translate sponta-neous spoken language in a limited domain.
In thispaper, we describe our recent preliminary efforts to ex-pand the domain of coverage of the system from therather limited Appointment Scheduling domain, to themuch richer Travel Planning domain.
We compare thetwo domains in terms of out-of-vocabulary rates andlinguistic omplexity.
We discuss the challenges thatthese differences impose on our translation system andsome planned changes in the design of the system.
Ini-tial evaluations on Travel Planning data are also pre-sented.IntroductionSpoken language understanding systems have been rea-sonably successful in limited semantic domains I. Thelimited domains naturally constrain vocabulary andperplexity, making speech recognition tractable.
In ad-dition, the relatively small range of meanings that couldbe conveyed make parsing and understanding tractable.Now, with the increasing success of large vocabularycontinuous speech recognition (LVCSR), the challengeis to similarly scale up spoken language understanding.In this paper we describe our plans for extending theJANUS speech-to-speech translation system \[1\] \[2\] fromthe Appointment Scheduling domain to a broader do-main, Travel Planning, which has a rich sub-domainstructure, covering many topics.In the last three years, the JANUS project has beendeveloping a speech-to-speech translation system forthe Appointment Scheduling domain (two people set-ting up a time to meet with each other).
Although thedata we have been working with is spontaneous speech,the scheduling scenario naturally limits the vocabularyto about 3000 words in English and about 4000 words inSpanish and German, which have more inflection.
Sim-ilarly, the types of dialogues are naturally limited.
At Verbmobil, systems developed under the ATIS ini-tiative, and systems developed at SRI, A.T&T andMlT/Lincoln Lab are examples of such successful spokenlanguage understanding systems.67scheduling dialogue typically consists of opening reet-ings, followed by several rounds of negotiation on atime, followed by closings.
There is ambiguity, for ex-ample whether a number efers to a date or a time,but many potentially ambiguous sentences have onlyone possible meaning in the scheduling domain.
Todate, our translation system for the scheduling domainhas achieved performance l vels on unseen data of over80% acceptable translations on transcribed input, andover 70% acceptable translations on speech input recog-nized with a 75-90% word accuracy, depending on thelanguage.In addition to the scheduling domain, the JANUSspeech recognizer has also been trained and developedfor Switchboard, a broad domain LVCSR task.
We arenow planning to expand our domain of spoken languageunderstanding aswell.
The new domain, Travel Plan-ning, is still limited, but is significantly more complexthan the scheduling domain.
Travel Planning containsa number of semantic sub-domains -- for example, ac-commodation, events, transportation --  each of whichhas a number of sub-topics uch as time, location, andprice.
Travel planning also differs from scheduling inhaving more types of interactions.
Scheduling consistsalmost entirely of negotiation dialogues except for open-ings and closings.
The travel domain includes negoti-ations, information seeking, instruction giving, and di-alogues that accompany non-linguistic domain actionssuch as paying and reserving.
Furthermore, there ismore ambiguity in travel planning, especially becausethe same utterance can have different meanings in dif-ferent sub-domains.An important part of our approach to the travel plan-ning domain is a system of sub-domain parsing.
Eachsentence will be parsed in parallel by a number of sub-domain grammars, each of which is faster and less am-biguous than a large grammar would be.
Since the sub-grammars are separated from each other, the ambigui-ties between them will add and not multiply.
The con-tent of each sub-domain grammar will be determinedautomatically by running a comprehensive grammarover a corpus in which each sentence has a sub-domaintag.~.,~._~._.hin Source Lan~.
.
.
.~I Speech "ec?g nizer \]GLR Translation Moduler .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
I. f .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
: :" Morph Analyzer :.t-.P.,..
GLR" Parser,, f=  -- , ,.." Processor :.- ~ Feature Structure _,/&?~?.
.
.
?o?
,o?
.
???
, ??
,o????
?~aPhoenix Translation Module: Int~aua ~...Frame.Siot S ructure /S???o??o????
'No???"? '
??*?
.
.
.
.
.
~ ' t~ Phoenix Generator ":1Figure 1: The JANUS SystemIn the remaining sections, we summarize the JANUSapproach to spoken language translation, highlight hedifferences between the scheduling and travel planningdomains, present some preliminary results for the travelplanning domain, and summarize our plans for modi-fying the design of the system, in order to effectivelyhandle a variety of sub-domains.Rev iew of  our  approachA component diagram of our system for the Schedulingdomain can be seen in Figure 1.
The main system mod-ules are speech recognition, parsing, discourse process-ing, and generation.
Each module is language indepen-dent in the sense that it consists of a general processorthat can be loaded with language specific knowledgesources.
The translation system is based on an inter-lingua approach.
The source language input string isfirst analyzed by a parser, which produces a language-independent interlingua content representation.
Theinterlingua is then passed to a generation component,which produces an output string in the target language.In an attempt o achieve both robustness and transla-tion accuracy when faced with speech disfluencies andrecognition errors, we use two different parsing strate-gies: a GLFt parser designed to be more accurate, anda Phoenix parser designed to be more robust.
Detaileddescriptions of the system components appear in ourprevious publications \[1\] \[2\] \[3\] \[4\] \[5\] \[6\].68Speech translation in the JANUS system is guidedby the general principle that spoken utterances can beanalyzed and translated as a sequential collection of se-mantic dialogue units (SDUs), each of which roughlycorresponds to a speech-act.
SDUs are semantically co-herent pieces of information.
The interlingua represen-tation in our system was designed to capture meaningat the level of such SDUs.
Each semantic dialogue unitis analyzed into an interlingua representation.For both parsers, segmentation f an input utteranceinto SDUs is achieved in a two-stage process, partlyprior to and partly during parsing.
Pre-parsing seg-mentation relies on acoustic, lexical, syntactic, seman-tic, and statistical knowledge sources.
We use a statis-tical measure that attempts to capture the likelihoodof an SDU boundary between any two words of an ut-terance.
The measure is trained on hand-segmentedtranscriptions of dialogues.
Pro-parsing segmentationsubstantially reduces parsing time, increases parse ac-curacy, and reduces ambiguity.
Final segmentation intoSDUs is done during parse time, guided by the gram-mar rules.
The same statistical measure used to find themost likely SDU boundaries during pre-parsing segmen-tation is used to filter out unlikely segmentations duringparse time.For the scheduling domain, we have been using se-mantic grammars, in which the grammar ules de-fi,e semantic categories such as busy-free-phrase andschedu le -meet ing  in addition to syntactic categoriessuch as NP and VP.
There were several reasons for chos-ing semantic grammars.
First, the domain lends itselfwell to semantic grammars because there are many fixedexpressions and common expressions that are almostformulaic.
Breaking these down syntactically wouldbe an unnecessary complication.
Additionally, sponta-neous spoken language is often syntactically ill formed,yet semantically coherent.
Semantic grammars allowour robust parsers to extract the key concepts beingconveyed, even when the input is not completely gram-matical in a syntactic sense.
Furthermore, we wantedto achieve reasonable coverage of the domain in as shorta time as possible.
Our experience has been that, forlimited domains, 60% to 80% coverage can be achievedin a few months with semantic grammars.In order to assess the overall effectiveness of the trans-lation system, we developed a detailed end-to-end eval-uation procedure \[7\].
We evaluate the translation mod-ules on both transcribed and speech recognized input.The evaluation of transcribed input allows us to assesshow well our translation modules would function with"perfect" speech recognition.
Testing is performed ona set of unseen dialogues that were not used for devel-oping the translation modules or training the speechrecognizer.The translation of an utterance is manually evalu-ated by assigning it a grade or a set of grades basedon the number of SDUs in the utterance.
Each SDUis classified first as either relevant to the schedulingdomain (in-domain) or not relevant o the schedulingdomain (out-of-domain).
Each SDU is then assignedone of four grades for translation quality: (1) Perfect- a fluent translation with all information conveyed;(2) OK - all important information translated correctlybut some unimportant details missing, or the transla-tion is awkward; (3) Bad - unacceptable translation;(4) Recognition Error - unacceptable translation due toa speech recognition error.
These grades are used forboth in-domain and out-of-domain sentences.
However,if an out-of-domain sentence is automatically detectedas such by the parser and is not translated at all, it isgiven an "OK" grade.
The evaluations are performedby one or more independent graders.
When more thanone grader is used, the results are averaged together.Comparison of Travel and SchedulingDomainsIn this section we compare some characteristics of theEnglish Travel Domain (ETD) and the English Spon-taneous Scheduling Task (ESST).
The ETD and ESSTdatabases are not comparable in some ways - -  ETD hasbeen under development for less than one year whereasthe ESST database was collected over a three year pe-riod and is much larger.
Also, the ESST recording sce-nario was push-to-talk whereas the ETD recording set-up allows for cross talk.
However, it is possible to drawsome comparisons.
For example, speech recognition ap-69pears to indicate that the ETD domain has a higherout-of-vocabulary ate.
In addition, informal observa-tions of the grammar developers point out sources ofambiguity in ETD that do not exist in ESST.ESST data was collected by giving marked-up calen-dars to two speakers and asking them to schedule a twohour meeting at a time that was free on each of theircalendars.
This method allowed us to collect speechin a limited domain that was nevertheless pontaneous.Similarly, ETD data is collected in a simulated con-versation between a traveller and a travel agent.
Thespeaker playing the traveller is given a scenario such as"You are travelling with your wife and teenage daugh-ter to the Pittsburgh Arts Festival.
Book a hotel roomthat is conveniently located."
The speaker playing thetravel agent has information about hotels, transporta-tion, etc.
on which to base answers to the traveller'squestions.The current ETD database contains 2000 utterances(30 dialogues).
For both speech recognition and gram-mar development, we used 1292 utterances (20 dia-logues) as a training set and 368 utterances (5 dia-logues) as a test set.
The ESST speech recognitiontraining set contains over 40 hours speech data and iscomposed of 8277 utterances.
The testing set is com-posed of 612 utterances.
The ESST testing vocabularycontains 2900 words.
The current word error rate ofthe ESST recognizer is about 23%.Some differences in the ETD and ESST databases areattributable to the push-to-talk vs. cross-talk record-ing scenarios.
In push-to-talk dialogues, the partici-pants push a key when they start and finish speaking,and cannot  speak at the same time.
In cross-talk di-alogues, participants can speak freely and their speechcan overlap.
The average length of ESST push-to-talkutterances is 33.6 words.
ETD cross-talk utterancesaverage 14.6 words.
In addition, the noise rate (noise-tokens/total-tokens) is 25.3% for the ESST training set,and 15.23% for the travel domain training set.In spite of the differences in the size of the twodatabases, we can compare the out-of-vocabulary ratesin order to get some idea of the difference in vocabularysizes of the two domains.
The vocabulary size of theESST system is 2900 words, which includes all uniquewords in the ESST training set.
The ETD speech vo-cabulary was constructed by augmenting the ESST vo-cabulary with 312 new words that appeared in the ETDtraining set.
This results in a vocabulary of 3212 words.The ETD test set contains 272 out-of-vocabulary tokensout of a total of 2554 tokens.
Thus, the out-of-vocabu-lary rate for the ETD test set is 10.65%.
This compareswith out-of-vocabulary rates for ESST that have rangedbetween 1% to 4%.
We have also found noticeable lan-guage model perplexity differences between the ESSTand ETD domains.
However, these appear to be highlydependent on the method used for obtaining the lan-guage models, and did not seem to form a consistentpattern.There are also differences between ETD and ESSTwith respect o parsing and ambiguity.
For example, inthe scheduling domain, numbers could be either datesor times.
In the travel domain, a number like twelve.fifteen could be a time, price (twelve dollars and fifteencents or one thousand two hundred and fifteen dollars),room number, flight number, etc.
The increase in in-terpretations can be attributed to the larger number ofsub-domains.P re l iminary  Resu l ts  fo r  the  Trave lP lann ing  DomainSpeech  Recogn i t ionDue to the very limited amount of training data avail-able for the travel domain, we decided to attempt obuild a speech recognition system for ETD by a pro-cess of adapting the acoustic and language models ofour ESST recognition system.
To start off, we con-ducted a preliminary evaluation on the ETD test setusing the original ESST acoustic and language mod-els.
With this set-up, the average word error rate onthe ETD test set was 55%.
Next, we added the ETDtraining corpus to the ESST training corpus and usedthe merged corpus for language model training.
Withthis new language model, we obtained a 42% word er-ror rate.
We also tried to build the language model justbased on the ETD corpus, which was smoothed by in-terpolation with the ESST language model.
However,this resulted in only about 0.5% improvement.In the next stage, to allow for better training withvery limited amounts of data, we rebuilt the acousticmodels using just the PLP feature and signal energy.This dramatically reduced the codebook size and thedimension of the feature vectors.
With the new acousticmodels which were trained with ESST and ETD speechdata, we obtained a 37.5% word error rate.
Trainingthe acoustic models with Vocal Tract Normalization(VTLN) speaker normalization reduced the word er-ror rate even further to 35.8%.
We experimented withadapting the ESST acoustic models by using the ETDspeech as adaptation data, but both the MLLR andMAP adaptation methods did not reduce the word er-ror rate any further.There are three main reasons why the word error rateis much higher for ETD than ESST.
First, the out-of-vocabulary ate is significantly higher.
Second, be-cause the travel domain database is very small com-pared to the ESST database, the ESST data domi-nates the acoustic and language models.
Third, theETD data is cross-talk, which is generally more dis-fluent and contains more co-articulation.
(This wasdemonstrated with our Spanish Spontaneous Schedul-ing Task database, which contained both push-to-talkand cross-talk utterances.)
We expect significantlylarger amounts of training data to at least partiallyalleviate these problems resulting in significant perfor-mance gains.70We obtained the above results without using the ETDspeech data to train the acoustic models.
Consideringthat the travel speech data is only a very small portionof all the available English training data, we plan touse adaptation techniques to adapt the current ESSTacoustic models into models for the travel domain.Translation ComponentsIn addition to speech recognition, we have done somepreliminary development of our translation componentsfor ETD.
Since we currently have only English traveldata, we developed English analysis and generationgrammars for English-to-English translation (or para-phrase) using the Phoenix system.
On a test set ofsix unseen dialogues, we achieve about 45% acceptabletranslation of transcribed SDUs in the travel domain.
2A preliminary interlingua design for the travel do-main contains about 200 concepts arranged in an IS-Ahierarchy, semantic features to represent the meaningof closed class items, and a list of five basic speech actswhich each have several sub-types.
We have developedexperimental grammars that are compatible with theinterlingua design for English parsing (Phoenix), En-glish generation (Phoenix and GLR), German gener-ation (Phoenix), and Japanese generation (Phoenix).Mappers mediate between Phoenix tree structures andthe feature structures of the interlingua design.P lanned Mod i f i ca t ions  to  the  SystemDes ignWe believe that the main challenge that the TravelPlanning domain will impose on our translation systemis the problem of how to effectively deal with signifi-cantly greater levels of ambiguity.
We suspect hat thesingle semantic grammar approach, which we have beenfollowing for the scheduling domain, will not be feasiblefor the Travel domain.
Syntactically similar structuresthat correspond to different semantic oncepts usuallyrequire separate rules in a semantic grammar.
Thus,as the domain semantically expands, the size of the se-mantic grammar tends to substantially grow.
With thisgrowth, significant new ambiguities are introduced intothe grammar, and these tend to multiply.One method of dealing with this problem is by"breaking" the large travel domain into several seman-tic sub-domains.
Because ach of the sub-domains willbe semantically much more narrow, the correspondingsemantic grammars should be smaller and far less am-biguous, leading to faster parsing and more accurateanalysis.
Since the sub-grammars are separated fromeach other, the ambiguities between them will add andnot multiply.2The travel domain grammars have been under develop-ment for only a few months.
The scheduling domain gram-mars, which have been under development for three yearsachieve about 85% acceptable translations on unseen tran-scribed input.Travel domain dialogues, however, will often con-tain sub-dialogues and utterances from different sub-domains, and will likely shift between one sub-domainand another.
We thus envision modifying the design ofour translation system to facilitate dealing with multi-ple sub-domains simultaneously and/or in parallel.
Ut-terances will be first segmented into sub-utterances byasegmentation procedure.
We expect hat in most cases,each sub-utterance will not span multiple sub-domains.Each sub-utterance will then be parsed in parallel bya number of sub-domain grammars, each of which isfaster and less ambiguous than a large grammar wouldbe.
Because each sub-domain grammar should be ableto parse well only sentences that fall in its domain ofcoverage, we expect that in many cases it should berelatively easy to select which among the parses pro-duced by the different sub-domain grammars is mostappropriate and/or correct.
Sentences that are coveredwell by more than one grammar most likely indicatetrue semantic ambiguity (for example, as mentionedabove, an expression such as twelve fifteen, whichcan be interpreted as a time, flight number, room num-ber or price).
To aid in such cases, we plan on devel-oping a sub-domain/topic dentification and trackingcomponent that will be independent of the semanticgrammars.
This component will assist in disambiguat-ing among semantically ambiguous analyses using con-textual information, modeled via statistical and othermethods.The effectiveness of the sub-domain approach de-scribed above will most likely depend heavily onour ability to choose appropriate sub-domains.
Sub-domains hould be chosen to be semantically distinct, sothat sentences may be easily classified into sub-domainsby both humans and machine.
Our current sub-domainclassification has two dimensions.
The first distin-guishes between topics such as accommodation, trans-portation, restaurants, events and sights.
The seconddistinguishes between discussions about price, reserva-tions, location, time, participants, directions and gen-eral information.
We are in the process of experiment-ing with both possible classifications, and their com-binations.
We have constructed a simple sub-domainclassifier that is based on a naive-Bayesian approachand trained on the available ETD data.
Preliminarytests (on unseen data) indicate that the simple classi-fier correctly identifies ub-domains classified accordingto the first dimension about 65% of the time.
Whenthe second dimension set of sub-domain classificationsis used, the classifier correctly identifies 75% of the sub-domains.We would like to avoid having to manually constructthe different sub-domain grammars for several reasons.First, even if the various sub-domains are semanticallydistinct, multiple sub-domain grammars will likely con-tain some of the same rules.
Furthermore, since we ex-pect to experiment with various sub-domain classifica-tions, it would be useful to devise an automatic method71for dividing a large comprehensive grammar of the en-tire travel domain into sub-domain grammars.
We planto achieve this task by running a comprehensive gram-mar over a corpus in which each sentence is tagged withits corresponding sub-domain and correct parse.
Thegrammar ules that correspond to the correct parse arethen added to the appropriate sub-domain grammar.This approach is similar to one proposed by Raynerand Samuelsson \[8\] for tailoring a large grammar to agiven corpus.ConclusionsIn this paper we described our plans for extending theJANUS speech-to-speech translation system from theAppointment Scheduling domain to a broader domain,Travel Planning, which has a rich sub-domain struc-ture.
Our preliminary experiments with English traveldomain data indicate that it is characterized by higherout-of-vocabulary ates and greater levels of semanticcomplexity, compared with English scheduling domaindata.
In order to effectively deal with the significantlygreater levels of ambiguity, we plan to use a collection ofsub-domain grammars, which will in sum cover the en-tire travel planning domain.
Our system design will bemodified to facilitate working with multiple sub-domaingrammars in parallel.
The collection of appropriatesub-domains will be determined empirically.
Automaticpruning methods will be used to derive each of the sub-domain grammars from a manually constructed com-prehensive grammar.
We expect o complete an initialprototype implementation of the above methods andhave additional preliminary evaluations of their effec-tiveness by late summer 1997.AcknowledgementsThe work reported in this paper was funded in partby grants from ATR- Interpreting TelecommunicationsResearch Laboratories of Japan, the US Departmentof Defense, and the Verbmobil Project of the FederalRepublic of Germany.References\[1\] A. Lavie, D. Gates, M.
Gavald?, L. Mayfield,A.
Waibel, and L. Levin.
Multi-lingual transla-tion of spontaneously spoken language in a limiteddomain.
In Proceedings of the COLING, 1996.\[2\] Alon Lavie, Alex Waibel, Lori Levin, DonnaGates, Marsal Gavalda, Torsten Zeppenfeld, Pum-ing Zhan and Oren Glickman.
Translation of Con-versational Speech with JANUS-II, In Proceedingsof ICSLP-96, Philadelphia, USA, October 1996.\[3\] P. Zhan, K. Ries, M. Gavalda, D. Gates, A.Lavie and A. Waibel.
JANUS-II: Towards Sponta-neous Spanish Speech Recognition, Proceedings ofICSLP-96, Philadelphia, PA, October 1996\[4\] A. Lavie.
A Grammar Based Robust Parser ForSpontaneous Speech.
PhD thesis, School of Com-puter Science, Carnegie Mellon University, 1995.\[5\] L. Mayfield, M. Gavaldk, Y-H. Seo, B. Suhm.
W.Ward.
A. Waibel.
Parsing Real Input in JANUS: aConcept-Based Approach, In Proceedings of TMI95.\[6\] Y. Qu, C. P. Rose, B.
Di Eugenio.
Using DiscoursePredictions for Ambiguity Resolution, In Proceed-ings of COLING-96, Copenhagen, Denmark, Au-gust 1996.\[7\] D. Gates, A. Lavie, L. Levin, A. Waibel,M.
Gavaldk, L. Mayfield, M. Woszczyna andP.
Zhan.
End-to-end Evaluation in JANUS: aSpeech-to-speech Translation System, To appear inProceedings of ECAI Workshop on Dialogue Pro-cessing in Spoken Language Systems, Budapest,Hungary, August 1996.\[8\] M-S. Agn~, H. Alshawi, I. Bretan, D. Carter,K.
Ceder, M. Collins, R. Crouch, V. Digalakis,B.
Ekholm, B. Gamback, J. Kaja, J. Karlgren,B.
Lyberg, P. Price, S. Pulman, M. Rayner,C.
Samuelsson, and T. Svensson.
Spoken LanguageTranslator: First-Year Report.
Technical ReportCRC-043, SRI Cambridge, 1994.72
