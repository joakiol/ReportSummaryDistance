Paraphrase Acquisition for Information ExtractionYusuke ShinyamaDepartment of Computer ScienceNew York University715, Broadway, 7th Floor, NY, 10003yusuke@cs.nyu.eduSatoshi SekineDepartment of Computer ScienceNew York University715, Broadway, 7th Floor, NY, 10003sekine@cs.nyu.eduAbstractWe are trying to find paraphrases fromJapanese news articles which can be usedfor Information Extraction.
We focusedon the fact that a single event can be re-ported in more than one article in differ-ent ways.
However, certain kinds of nounphrases such as names, dates and numbersbehave as ?anchors?
which are unlikely tochange across articles.
Our key idea is toidentify these anchors among comparablearticles and extract portions of expressionswhich share the anchors.
This way wecan extract expressions which convey thesame information.
Obtained paraphrasesare generalized as templates and stored forfuture use.In this paper, first we describe our ba-sic idea of paraphrase acquisition.
Ourmethod is divided into roughly four steps,each of which is explained in turn.
Thenwe illustrate several issues which we en-counter in real texts.
To solve these prob-lems, we introduce two techniques: coref-erence resolution and structural restrictionof possible portions of expressions.
Fi-nally we discuss the experimental resultsand conclusions.1 IntroductionWe are trying to obtain paraphrases which can beused for Information Extraction (IE) systems.
IEsystems scan articles and retrieve specific informa-tion which is required for a certain domain definedin advance.
Currently, many IE tasks are performedby pattern matching.
For example, if the system re-ceives a sentence ?Two more people have died inHong Kong from SARS,?
and the system has a pat-tern ?NUMBER people die in LOCATION?
in its in-ventory, then the system can apply the pattern tothe sentence and fill the slots, and obtain informa-tion such as ?NUMBER = two more, LOCATION =Hong Kong?.
In most IE systems, the performanceof the system is dependent on these well-designedpatterns.In natural language sentences, a single event canbe expressed in many different ways.
So we needto prepare patterns for various kinds of expressionsused in articles.
We are interested in clusteringIE patterns which capture the same information.For example, a pattern such as ?LOCATION reportsNUMBER deaths?
can be used for the same purposeas the previous one, since this pattern could also cap-ture the casualties occurring in a certain location.Prior work to relate two IE patterns was reported by(Shinyama et al, 2002).
However, in this attemptonly limited forms of expressions could be obtained.Furthermore, the obtained paraphrases were limitedto existing IE patterns only.
We are interested in col-lecting various kinds of clues, including similar IEpatterns themselves, to connect two patterns.
In thispaper, we tried to obtain more varied paraphrases.Although our current method is intended for use inInformation Extraction, we think the same approachcan be applied to obtain paraphrases for other pur-poses, such as machine translation or text summa-rization.There have been several attempts to obtain para-phrases.
(Barzilay and McKeown, 2001) appliedtext alignment to parallel translations of a singletext and used a part-of-speech tagger to obtain para-phrases.
(Lin and Pantel, 2001) used mutual infor-mation of word distribution to calculate the simi-larity of expressions.
(Pang et al, 2003) also usedtext alignment and obtained a finite state automatonwhich generates paraphrases.
(Ravichandran andHovy, 2002) used pairs of questions and answersto obtain varied patterns which give the same an-swer.
Our approach is different from these works inthat we used comparable news articles as a source ofparaphrases and used Named Entity tagging and de-pendency analysis to extract corresponding expres-sions.2 Overall Procedure of ParaphraseAcquisitionOur main goal is to obtain pattern clusters for IE,which consist of sets of equivalent patterns captur-ing the same information.
So we tried to discoverparaphrases contained in Japanese news articles fora specific domain.
Our basic idea is to search newsarticles from the same day.
We focused on the factthat various newspapers describe a single event indifferent ways.
So if we can discover an eventwhich is reported in more then one newspaper, wecan hope these articles can be used as the source ofparaphrases.
For example, the following articles ap-peared in ?Health?
sections in different newspaperson Apr.
11:1.
?The government has announced that two morepeople have died in Hong Kong after contract-ing the SARS virus and 61 new cases of theillness have been detected.?
(Reuters, Apr.
11)2.
?Hong Kong reported two more deaths and 61fresh cases of SARS Friday as governmentsacross the world took tough steps to stop thekiller virus at their borders.?
(Channel NewsAsia, Apr.
11)In these articles, we can find several correspond-ing parts, such as ?NUMBER people have died inLOCATION?
and ?LOCATION reported NUMBERdeaths?.
Although their syntactic structures are dif-ferent, they still convey the same single fact.
Hereit is worth noting that even if a different expressionis used, some noun phrases such as ?Hong Kong?or ?two more?
are preserved across the two arti-cles.
We found that these words shared by the twosentences provide firm anchors for two different ex-pressions.
In particular, Named Entities (NEs) suchas names, locations, dates or numbers can be thefirmest anchors since they are indispensable to re-port an event and difficult to paraphrase.We tried to obtain paraphrases by using this prop-erty.
First we collect a set of comparable articleswhich reports the same event, and pull appropriateportions out of the sentences which share the sameanchors.
If we carefully choose appropriate portionsof the sentences, the extracted expressions will con-vey the same information; i.e.
they are paraphrases.After corresponding portions are obtained, we gen-eralize the expressions to templates of paraphraseswhich can be used in future.Our method is divided into four steps:1.
Find comparable sentences which report thesame event from different newspapers.2.
Identify anchors in the comparable sentences.3.
Extract corresponding portions from the sen-tences.4.
Generalize the obtained expressions to para-phrase templates.Figure 1 shows the overall procedure.
In the re-mainder of this section, we describe each step inturn.2.1 Find Comparable SentencesTo find comparable articles and sentences, we usedmethods developed for Topic Detection and Track-ing (Wayne, 1998).
The actual process is dividedinto two parts: article level matching and sentencelevel matching.
Currently we assume that a pairof paraphrases can be found in a single sentenceof each article and corresponding expressions don?trange across two or more sentences.
Article levelmatching is first required to narrow the search spaceand reduce erroneous matching of anchors.ArticleAArticleBSARS1SARS2Find comparablearticles andsentencesIdentifyanchorsExtractcorrspondingportions(Articles onthe same day)anchors paraphrases"NUMBERpeople diein LOCATION""LOCTIONreportsNUMBERdeaths"GeneralizeexpressionsFigure 1: The overall procedureBefore applying this technique, we first prepro-cessed the articles by stripping off the strings whichare not considered as sentences.
Then we used apart-of-speech tagger to obtain segmented words.
Inthe actual matching process we used a method de-scribed in (Papka et al, 1999) to find a set of com-parable articles.
Then we use a simple vector spacemodel for sentence matching.2.2 Identify AnchorsBefore extracting paraphrases, we find anchors incomparable sentences.
We used Extended NamedEntity tagging to identify anchors.
A Named Entitytagger identifies proper expressions such as names,locations and dates in sentences.
In addition to theseexpressions, an Extended Named Entity tagger iden-tifies some common nouns such as disease names ornumbers, that are also unlikely to change (Sekineet al, 2002).
For each corresponding pair of sen-tences, we apply the tagger and identify the samenoun phrases which appear in both sentences as an-chors.2.3 Extract Corresponding Sentence PortionsNow we identify appropriate boundaries of expres-sions which share the anchors identified in the pre-vious stage.
To avoid extracting non-grammaticalexpressions, we operate on syntactically structuredtext rather than sequences of words.
Dependencyanalysis is suitable for this purpose, since using de-pendency trees we can reconstruct grammaticallycorrect expressions from a spanning subtree whoseroot is a predicate.
Dependency analysis also allowsus to extract expressions which are subtrees but donot correspond to a single contiguous sequence ofwords.We applied a dependency analyzer to a pair ofcorresponding sentences and obtained tree structuresfor each sentence.
Each node of the tree is either apredicate such as a verb or an adjective, or an argu-ment such as a noun or a pronoun.
Each predicatecan take one or more arguments.
We generated allpossible combinations of subtrees from each depen-dency tree, and compared the anchors which are in-cluded in both subtrees.
After a pair of correspond-ing subtrees which share the anchors is found, thesubtree pair can be recognized as paraphrases.
In ac-tual experiments, we put some restrictions on thesesubtrees, which will be discussed later.
This waywe can obtain grammatically well-formed portionsof sentences (Figure 2).2.4 Generalize ExpressionsAfter corresponding portions are obtained, we gen-eralize the expressions to form usable templates ofparaphrases.
Actually this is already done by Ex-tended Named Entity tagging.
An Extended NamedEntity tagger classifies proper expressions into sev-eral categories.
This is similar to a part-of-speechtagger as it classifies words into several part-of-speech categories.
For example, ?Hong Kong?
istagged as a location name, and ?two more?
as anumber.
So an expression such as ?two more peo-ple die in Hong Kong?
is finally converted into theform ?NUMBER people die in LOCATION?
whereNUMBER and LOCATION are slots to fill in.
Thisway we obtain expressions which can be used as IEpatterns.the governmenthas announcedhave diedin Hong Kongtwo more peoplesubjectobjectinsubjectHong Kongreportedtwo more deathssubjectobjectpredicates predicatesparaphrasesLOCATION is included.NUMBER is included.anchorsFigure 2: Extracting portions of sentences3 Handling Problems in Real TextsIn the previous section we described our method forobtaining paraphrases in principle.
However thereare several issues in actual texts which pose difficul-ties for our method.The first one is in finding anchors which refer tothe same entity.
In actual articles, names are some-time referred to in a slightly different form.
For ex-ample, ?President Bush?
can also be referred to as?Mr.
Bush?.
Additionally, sometime it is referredto by a pronoun, such as ?he?.
Since our methodrelies on the fact that those anchors are preservedacross articles, anchors which appear in these var-ied forms may reduce the actual number of obtainedparaphrases.To handle this problem, we extended the notionof anchors to include not just Extended Named En-tities, but also pronouns and common nouns suchas ?the president?.
We used a simple corefer-ence resolver after Extended Named Entity tag-ging.
Currently this is done by simply assigningthe most recent antecedent to pronouns and findinga longest common subsequence (LCS) between twonoun groups.
Since it is possible to form a com-pound noun such as ?President-Bush?
in Japanese,we computed LCS for each character in the twonoun groups.
We used the following condition todecide whether two noun groups s1 and s2 are coref-erential:?
if 2 ?
min(|s1|, |s2|) ?
|LCS(s1, s2)|, thens1 and s2 are considered coreferential.Here |s| denotes the length of noun group s andLCS(s1, s2) is the LCS of two noun groups s1 ands2.The second problem is to extract appropriate por-tions as paraphrase expressions.
Since we use a treestructure to represent the expressions, finding com-mon subtrees may take an exponential number ofsteps.
For example, if a dependency tree in onearticle has one single predicate which has n argu-ments, the number of possible subtrees which canbe obtained from the tree is 2n.
So the matchingprocess between arbitrary combinations of subtreesmay grow exponentially with the length of the sen-tences.
Even worse, it can generate many combina-tions of sentence portions which don?t make sense asparaphrases.
For example, from the expression ?twomore people have died in Hong Kong?
and ?HongKong reported two more deaths?, we could extractexpressions ?in Hong Kong?
and ?Hong Kong re-ported?.
Although both of them share one anchor,this is not a correct paraphrase.
To avoid this sort oferror, we need to put some additional restrictions onthe expressions.
(Shinyama et al, 2002) used the frequency of ex-pressions to filter these incorrect pairs of expres-sions.
First the system obtained a set of IE patternsfrom corpora (Sudo and Sekine, 2001), and then cal-culated the score for each candidate paraphrase bycounting how many times that expression appears asan IE pattern in the whole corpus.
However, withthis method, obtainable expressions are limited toexisting IE patterns only.
Since we wanted to ob-tain a broader range of expressions not limited toIE patterns themselves, we tried to use other restric-tions which can be acquired independently of the IEsystem.We partly solve this problem by calculating theplausibility of each tree structure.
In Japanese sen-tences, the case of each argument which modifiesa predicate is represented by a case marker (post-position or joshi) which follows a noun phrase, justlike prepositions in English but in the opposite order.These arguments include subjects and objects thatare elucidated syntactically in English sentences.We collected frequent cases occurring with a spe-cific predicate in advance.
We applied this restric-tion when generating subtrees from a dependencytree by calculating a score for each predicate as fol-lows:Let an instance of predicate p have cases C ={c1, c2, ..., cn} and a function Np(I) be the numberof instances of p in the corpus whose cases are I ={c1, c2, ..., cm}.
We compute the score Sp(C) of theinstance:Sp(C) =?I?C Np(I)the number of instances of p in the corpus .Using this metric, a predicate which doesn?t havecases that it should usually have is given a lowerscore.
A subtree which includes a predicate whosescore is less than a certain threshold is filtered out.This way we can filter out expressions such as?Hong Kong reported?
in Japanese since it wouldlack an object case which normally the verb ?re-port?
should have.
Moreover, this greatly reducesthe number of possible combinations of subtrees.4 ExperimentsWe used Japanese news articles for this experi-ment.
First we collected articles for a specific do-main from two different newspapers (Mainichi andNikkei).
Then we used a Japanese part-of-speechtagger (Kurohashi and Nagao, 1998) and ExtendedNamed Entity tagger to process documents, and putthem into a Topic Detection and Tracking system.In this experiment, we used a modified version of aJapanese Extended Named Entity tagger (Uchimotoet al, 2000).
This tagger tags person names, orga-nization names, locations, dates, times and numbers.Article pairs:Obtained CorrectSystem 195 156(80%)Sentence pairs:(from top 20 article pairs)Obtained CorrectManual 93 93W/o coref.
55 41 (75%)W coref.
75 52 (69%)Paraphrase pairs:Obtained CorrectW/o coref.
or restriction 106 25 (24%)W/o coref., w restriction 32 18 (56%)W coref.
and restriction 37 23 (62%)Manual (in 5 hours) (100) (100)Table 1: Results in the murder cases domainSample 1:?
PERSON1 killed PERSON2.?
PERSON1 let PERSON2 die from loss of blood.Sample 2:?
PERSON1 shadowed PERSON2.?
PERSON1 kept his eyes on PERSON2.Figure 3: Sample correct paraphrases obtained(translated from Japanese)Sample 3:?
PERSON1 fled to LOCATION.?
PERSON1 fled and lay in ambush to LOCATION.Sample 4:?
PERSON1 cohabited with PERSON2.?
PERSON1 murdered in the room for cohabitationwith PERSON2.Figure 4: Sample incorrect paraphrases obtained(translated from Japanese)Next we applied a simple vector space method to ob-tain pairs of sentences which report the same event.After that, we used a simple coreference resolver toidentify anchors.
Finally we used a dependency an-alyzer (Kurohashi, 1998) to extract portions of sen-tences which share at least one anchor.In this experiment, we used a set of articles whichreports murder cases.
The results are shown in Ta-ble 1.
First, with Topic Detection and Tracking,there were 156 correct pairs of articles out of 193pairs obtained.
To simplify the evaluation process,we actually obtained paraphrases from the top 20pairs of articles which had the highest similarities.Obtained paraphrases were reviewed manually.
Weused the following criteria for judging the correct-ness of paraphrases:1.
They has to be describing the same event.2.
They should capture the same information if weuse them in an actual IE application.We tried several conditions to extract paraphrases.First we tried to extract paraphrases using neithercoreference resolution nor case restriction.
Then weapplied only the case restriction with the threshold0.3 < Sp(C), and observed the precision went upfrom 24% to 56%.
Furthermore, we added a sim-ple coreference resolution and the precision rose to62%.
We got 23 correct paraphrases.
We foundthat several interesting paraphrases are obtained.Some examples are shown in Figure 3 (correct para-phrases) and Figure 4 (incorrect paraphrases).It is hard to say how many paraphrases can be ul-timately obtained from these articles.
However, it isworth noting that after spending about 5 hours forthis corpus we obtained 100 paraphrases manually.5 DiscussionSome paraphrases were incorrectly obtained.
Therewere two major causes.
The first one was depen-dency analysis errors.
Since our method recognizesboundaries of expressions using dependency trees, ifsome predicates in a tree take extra arguments, thismay result in including extraneous portions of thesentence in the paraphrase.
For example, the predi-cate ?lay in ambush?
in Sample 3 should have takena different noun as its subject.
If so, the predicatedoesn?t share the anchors any more and could beeliminated.The second cause was the lack of recognizingcontexts.
In Sample 4, we observed that even if twoexpressions share multiple anchors, an obtained paircan be still incorrect.
We hope that this kind of errorcan be reduced by considering the contexts aroundexpressions more extensively.6 Future WorkWe hope to apply our approach further to ob-tain more varied paraphrases.
After a certainnumber of paraphrases are obtained, we can usethe obtained paraphrases as anchors to obtainadditional paraphrases.
For example, if we know?A dismantle B?
and ?A destroy B?
are para-phrases, we could apply them to ?U.N.
reportedIraq dismantling more missiles?
and ?U.N.
officialsays Iraq destroyed more Al-Samoud 2 missiles?,and obtain another pair of paraphrases ?X reports Y?and ?X says Y?.This approach can be extended in the other direc-tion.
Some entities can be referred to by completelydifferent names in certain situations, such as ?NorthKorea?
and ?Pyongyang?.
We are also planning toidentify these varied external forms of a single entityby applying previously obtained paraphrases.
Forexample, if we know ?A restarted B?
and ?A reac-tivated B?
as paraphrases, we could apply them to?North Korea restarted its nuclear facility?
and ?Py-ongyang has reactivated the atomic facility?.
Thisway we know ?North Korea?
and ?Pyongyang?
canrefer to the same entity in a certain context.In addition, we are planning to give some credi-bility score to anchors for improving accuracy.
Wefound that some anchors are less reliable than oth-ers even if they are considered as proper expres-sions.
For example, in most U.S. newspapers theword ?U.S.?
is used in much wider contexts thanword such as ?Thailand?
although both of them arecountry names.
So we want to give less credit tothese widely used names.We noticed that there are several issues in general-izing paraphrases.
Currently we simply label everyNamed Entity as a slot.
However expressions suchas ?the governor of LOCATION?
can take only a cer-tain kind of locations.
Also some paraphrases mightrequire a narrower context than others and are nottruly interchangeable.
For example, ?PERSON wassworn?
can be replaced with ?PERSON took office?,but not vice versa.7 ConclusionsIn this paper, we described a method to obtain para-phrases automatically from corpora.
Our key notionis to use comparable articles which report the sameevent on the same day.
Some noun phrases, espe-cially Extended Named Entities such as names, lo-cations and numbers, are preserved across articleseven if the event is reported using different expres-sions.
We used these noun phrases as anchors andextracted portions which share these anchors.
Thenwe generalized the obtained expressions as usableparaphrases.We adopted dependency trees as a format for ex-pressions which preserve syntactic constraints whenextracting paraphrases.
We generate possible sub-trees from dependency trees and find pairs whichshare the anchors.
However, simply generating allsubtrees ends up obtaining many inappropriate por-tions of sentences.
We tackled this problem by cal-culating a score which tells us how plausible ex-tracted candidates are.
We confirmed that it con-tributed to the overall accuracy.
This metric wasalso useful to trimming the search space for match-ing subtrees.
We used a simple coreference resolverto handle some additional anchors such as pronouns.AcknowledgmentsThis research is supported by the Defense AdvancedResearch Projects Agency as part of the Translin-gual Information Detection, Extraction and Sum-marization (TIDES) program, under Grant N66001-001-1-8917 from the Space and Naval Warfare Sys-tems Center San Diego, and by the National ScienceFoundation under Grant IIS-0081962.
This paperdoes not necessarily reflect the position or the pol-icy of the U.S. Government.ReferencesRegina Barzilay and Kathleen R. McKeown.
2001.
Ex-tracting Paraphrases from a Parallel Corpus.
In Pro-ceedings of the ACL/EACL.Sadao Kurohashi and Makoto Nagao, 1998.
JapaneseMorphological Analysis System JUMAN.
Kyoto Uni-versity, version 3.61 edition.Sadao Kurohashi, 1998.
Kurohashi-Nagao parser.
Ky-oto University, version 2.0 b6 edition.Dekang Lin and Patrick Pantel.
2001.
Discovery of In-ference Rules for Question Answering.
Natural Lan-guage Engineering, 7(4):343?360.Bo Pang, Kevin Knight, and Danial Marcu.
2003.Syntax-based Alignment of Multiple Translations: Ex-tracting Paraphrases and Generating New Sentences.In NAACL-HLT.Ron Papka, James Allen, and Victor Lavrenko.
1999.UMASS Approaches to Detection and Tracking atTDT2.
In DARPA: Broadcast News Workshop.Deepak Ravichandran and Eduard Hovy.
2002.
Learningsurface text patterns for a question answering system.In Proceedings of the 40th Annual Meeting of the As-sociation for Computational Linguistics (ACL).Satoshi Sekine, Kiyoshi sudo, and Chikashi Nobata.2002.
Extended Named Entity Hierarchy.
In Proceed-ings of the LREC.Yusuke Shinyama, Satoshi Sekine, Kiyoshi Sudo, andRalph Grishman.
2002.
Automatic Paraphrase Ac-quisition from News Articles.
In Proceedings of theSecond International Conference on Human LanguageTechnology Research.Kiyoshi Sudo and Satoshi Sekine.
2001.
Automatic Pat-tern Acquisition for Japanese Information Extraction.In Proceedings of the HLT.Kiyotaka Uchimoto, Masaki Murata, Qing Ma, HiromiOzaku, and Hitoshi Isahara.
2000.
Named Entity Ex-traction Based on A Maximum Entropy Model andTransformation Rules.
In Proceedings of the 38thAnnual Meeting of the Association for ComputationalLinguistics (ACL), pages 326?335.Charles L. Wayne.
1998.
Topic Detection & Tracking: ACase Study in Corpus Creation & Evaluation Method-ologies.
In Proceedings of the LREC.
