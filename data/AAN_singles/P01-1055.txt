Using Machine Learning to Maintain Rule-based Named-EntityRecognition and Classification SystemsGeorgios Petasis ?, Frantz Vichot ?, Francis Wolinski ?Georgios Paliouras ?, Vangelis Karkaletsis ?
and Constantine D. Spyropoulos ??
Institute of Informatics and Telecommunications,National Centre for Scientific Research ?Demokritos?,153 10 Ag.
Paraskevi, Athens, Greece?
Informatique-CDC4, rue Berthollet94114 Arcueil, France{petasis,paliourg,vangelis,costass}@iit.demokritos.gr{frantz.vichot, francis.wolinski}@caissedesdepots.frAbstractThis paper presents a method that as-sists in maintaining a rule-basednamed-entity recognition and classifi-cation system.
The underlying idea is touse a separate system, constructed withthe use of machine learning, to monitorthe performance of the rule-based sys-tem.
The training data for the secondsystem is generated with the use of therule-based system, thus avoiding theneed for manual tagging.
The dis-agreement of the two systems acts as asignal for updating the rule-based sys-tem.
The generality of the approach isillustrated by applying it to large cor-pora in two different languages: Greekand French.
The results are very en-couraging, showing that this alternativeuse of machine learning can assist sig-nificantly in the maintenance of rule-based systems.1 IntroductionMachine learning has recently been proposed asa promising solution to a major problem in lan-guage engineering: the construction of lexicalresources.
Most of the real-world language en-gineering systems make use of a variety of lexi-cal resources, in particular grammars and lexi-cons.
The use of general-purpose resources isineffective, since in most applications a special-ised vocabulary is used, which is not supportedby general-purpose lexicons and grammars.
Forthis reason, significant effort is currently putinto the construction of generic tools that canquickly adapt to a particular thematic domain.The adaptation of these tools mainly involvesthe adaptation of domain-specific semantic lexi-cal resources.Named-entity recognition and classification(NERC) is the identification of proper names intext and their classification as different types ofnamed entity (NE), e.g.
persons, organisations,locations, etc.
This is an important subtask inmost language engineering applications, in par-ticular information retrieval and extraction.
Thelexical resources that are typically included in aNERC system are a lexicon, in the form of gaz-etteer lists, and a grammar, responsible for rec-ognising the entities that are either not in thelexicon or appear in more than one gazetteerlists.
The manual adaptation of those two re-sources to a particular domain is time-consuming and in some cases impossible, due tothe lack of experts.
The exploitation of learningtechniques to support this adaptation task hasattracted the attention of researchers in languageengineering.However, the adaptation of lexical resourcesto a specific domain at a certain point in time isnot sufficient on its own.
The performance of aNERC system degrades over time (Vichot et al,1999; Wolinski et al, 2000) due to the introduc-tion of new NEs or the change in the meaning ofexisting ones.
We need to find ways that facili-tate the maintenance of rule-based NERC sys-tems.
This paper presents such a method, ex-ploiting machine learning in an innovative way.Our method controls rule-based NERC systemswith NERC systems constructed by a machinelearning algorithm.
The method comprises twostages: the training stage, during which a super-vised machine learning algorithm constructs anew system using data generated by the rule-based system, and the deployment stage, inwhich the results of the two systems are com-pared on new data and their disagreements areused as signals for change in the rule-based sys-tem.
Note that, unlike most applications of su-pervised machine learning, the training data forthe new system are not produced manually.In order to illustrate the generality of this ap-proach, we have tested it with two differentNERC systems, one for Greek and another onefor French.
The results are very encouraging andshow that machine learning techniques can beused for the maintenance of rule-based systems.Section 2 presents existing work on the do-main adaptation of NERC systems using ma-chine learning (ML) techniques.
Section 3 pre-sents the two rule-based NERC systems forGreek and French.
Section 4 explains ourmethod and Section 5 describes the two experi-ments and presents the evaluation results.
Fi-nally, Section 6 concludes and presents our fu-ture plans.2 Related WorkAs mentioned above, the exploitation of learningtechniques to support the domain adaptation ofNERC systems has recently attracted the atten-tion of several researchers.
Some of these ap-proaches are briefly discussed in this section.Nymble (Bikel et al, 1997) uses statisticallearning to acquire a Hidden Markov Model(HMM) that recognises NEs in text.
Nymble didparticularly well in the MUC-7 competition(DARPA, 1998), due mainly to the use of thecorrect features in the encoding of words, e.g.capitalisation, and the probabilistic modelling ofthe recognition system.Named-entity recognition in Alembic (Vilainand Day, 1996) uses the transformation-basedrule learning approach introduced in Brill?swork on part-of-speech tagging (Brill, 1993).
Animportant aspect of this approach is the fact thatthe system learns rules that can be freely inter-mixed with hand-engineered ones.The RoboTag system presented in (Bennettet al, 1997) constructs decision trees that clas-sify words as being start or end points of a par-ticular named-entity type.
A variant of this ap-proach was used in the system presented by theNew York University (NYU) in the MultilingualEntity Task (MET-2) of MUC-7 (Sekine, 1998).The system developed for Italian in ECRAN(Cuchiarelli et al, 1998), uses unsupervisedlearning to expand a manually constructed sys-tem and improve its performance.
The learningalgorithm tries to supplement the manually con-structed system by classifying recognised butunclassified NEs.
In (Petasis et al, 2000) themanually constructed system was replaced bythe supervised tree induction algorithm C4.5(Quinlan, 1993), reaching very good perform-ance on the MUC-6 corpora.The partially supervised multi-level boot-strapping approach presented in (Riloff andJones, 1999) induces a set of information extrac-tion patterns, which can be used to identify andclassify NEs.
The system starts by generatingexhaustively all candidate extraction patterns,using an earlier system called AutoSlog (Riloff,1993).
Given a small number of seed examplesof NEs, the most useful patterns for recognisingthe seed examples are selected and used to ex-pand the set of classified NEs.
The end result isa dictionary of NEs and the extraction patternsthat correspond to them.Our method follows an alternative innovativeapproach to the use of learning for NERC.
In-stead of using ML to construct a NERC systemthat will be used autonomously, the system con-structed by ML, according to our approach isused to monitor the performance of an existingrule-based NERC system.
In this manner, thenew system provides feedback on whether therule-based system under control has becomeobsolete and needs to be updated.
An importantadvantage of this approach is that no manualtagging of training data is needed, despite theuse of a supervised learning algorithm.Our method bears some similarities with sys-tems based on active learning (Thompson et al,1999).
According to this technique, multipleclassifiers performing the same task are used inorder to actively create training data, throughtheir disagreements.
Usually, this involves aniterative procedure.
First a few initial labelledexamples are used to train the classifiers andthen, unlabelled examples are presented to theclassifiers.
Examples that cause the classifiers todisagree are good candidates to retrain the clas-sifiers on.
The difference of active learning toour method is the use of a manually-constructedrule-based NERC system as the basic system.The ML method is used only to identify whenthe rule-based NERC system should be updated,but not for creating new training instances.
An-other approach, which bears some similarity toours, is presented in (Kushmerick, 1999) wherea heuristic algorithm is used to monitor the per-formance of web-page wrappers.3 Rule-based NERC SystemsA typical NERC system consists of a lexiconand a grammar.
The lexicon is a set of NEs thatare known beforehand and have been classifiedinto semantic classes.
The grammar is used torecognize and classify NEs that are not in thelexicon and to decide upon the final classes ofNEs in ambiguous cases.Manual construction of NERC systems is acomplicated and time-consuming process, evenfor experts.
The meaning of a single sentencemay vary a lot according to which category aNE is assigned to.
For example, the sentence?Express group intends to sell Le Point for 700MF?
indicates a sale of a newspaper company, if?Le Point?
is classified as an organisation.Whereas the following sentence, which isgrammatically identical to the previous one,?Compagnie des Signaux intends to sellTVM430 for 700 MF?
gives only a price for anindustrial product.In order for a NERC system to be able torecognise and categorise correctly NEs, both thelexicon and the grammar have to be validated onlarge corpora, testing their efficiency and theirrobustness.
However, this process does not en-sure that the performance of the developed sys-tem will remain steady over time.
Almost underall thematic domains, the introduction of newNEs or the change in the meaning of existingones can increase the error rate of the system.Our approach tries to identify such cases, facili-tating the maintenance of the NERC system.The following subsections briefly describethe Greek and French rule-based NERC systemsthat have been used in our experiments.3.1 The Greek NERC SystemThe Greek NERC system (Farmakiotou et al,2000) used for the purposes of this experimentforms part of a larger Greek information extrac-tion system, being developed in the context ofthe R&D project MITOS.1 The NERC compo-nent of this system mainly consists of threeprocessing stages: linguistic pre-processing, NEidentification and NE classification.
The linguis-tic pre-processing stage involves some basictasks: tokenisation, sentence splitting, part-of-speech tagging and stemming.
Once the text hasbeen annotated with part of speech tags, astemmer is used.
The aim of the stemmer is toreduce the size of the lexicon as well as the sizeand complexity of the NERC grammar.The NE identification stage involves the de-tection of their boundaries, i.e., the start and theend of all the possible spans of tokens that arelikely to belong to a NE.
Identification consistsof three sub-stages: initial delimitation, separa-tion and exclusion.
Initial delimitation involvesthe application of general patterns.
These pat-terns are combinations of a limited number ofwords, selected types of tokens (e.g.
tokens con-sisting of capital characters), special symbolsand punctuation marks.
At the separation sub-stage, possible NEs that are likely to containmore than one NE or a NE attached to a non-NE, are detected and attachment problems areresolved.
Finally, at the exclusion sub-stage twotypes of criteria are used for exclusion from thepossible NE list: the context of the phrase andbeing part of an exclusion list.
Suggestive con-text for exclusion consists of common namesthat refer to products, services or artifacts.
Theexclusion list includes capitalized abbreviationsof common nouns, financial terms, capitalizedperson titles, which are not ambiguous, andnouns commonly found in names of products,artifacts and services.Once the possible NEs have been identified,the classification stage begins.
Classificationinvolves three sub-stages: application of classi-fication rules, gazetteer-based classification, andpartial matching of classified named-entitieswith unclassified ones.
Classification rules takeinto account both internal and external evidence(McDonald, 1996), i.e., the words and symbolsthat comprise the possible name and the contextin which it occurs.
Gazetteer-based classifica-tion involves the look up of pre-stored lists ofknown proper names (gazetteers).
The gazet-teers contain stemmed forms and have beencompiled from Web sites and an annotated train-1 http://www.iit.demokritos.gr/skel/mitosing corpus.
The size of the gazetteers is rathersmall (3,059 names).
At the partial matchingsub-stage, classified names are matched againstunclassified ones aiming at the recognition ofthe truncated or variable forms of names.3.2 The French NERC SystemThe French NERC system has been imple-mented with the use of a rule-based inferenceengine (Wolinski et al, 1995).
It is based on alarge knowledge base (lexicon) including 8,000proper names that share 10,000 forms and con-sist of 11,000 words.
It has been used continu-ously since 1995 in several real-time documentfiltering applications (Wolinski et al, 2000).The uses of the NERC system in these applica-tions are the following:1.
Segmentation of NEs, in order to improvethe performance of the syntactic analyser, par-ticularly in the case of long proper names whichcontain grammatical markers (e.g.
prepositions,conjunctions, commas, full stops).2.
Recognition of known NEs in order to sup-ply precise information to a document filteringmodule.3.
Classification of NEs in order to feed adocument filtering module with informationdealing with the very nature of the NEs quotedin the documents.The NERC system tries to classify each NEin one of four different categories: association(non-commercial organisation), person, locationor company.For the classification of known entities, acrucial problem appears when several NEs sharea single form.
To deal with these cases, two setsof rules have been implemented:1.
Local context: For instance, ?Saint-Louis?may be interpreted in one of the following ways:the capital of Missouri, a French group in thefood production industry, a small industry ?lesCristalleries de Saint Louis?, a small town inFrance, a hospital in Paris, etc.
Exploration ofthe local context using the proper name mayenable, in certain cases, a choice to be madebetween these various interpretations.
If the textspeaks of ?St-Louis (Missouri)?, only the firstinterpretation should be adopted.
In order to dothis the knowledge base should contain informa-tion that ?Saint-Louis?
is in Missouri, and a ruleshould exist to interpret the affixing of a paren-thesis.2.
Global context: Abbreviated NEs and acro-nyms are much more frequent sources of ambi-guity and are almost always common to severalNEs.
In general, such ambiguous forms of NEsdo not occur on their own in news but almostalways together with non-ambiguous forms thatenable the ambiguity to be removed.
For in-stance, if the NEs ?Saint-Louis?
and ?H?pitalSaint-Louis?
appear in a single news item, theinterpretation corresponding to the hospital ismore likely to be the one that should be adopted.For unknown entities, three sets of rules havebeen implemented:1.
Prototypes: Many NEs are constructed ac-cording to some prototypes.
These can be cate-gorised using pattern matching rules.
Mr Andr?Blavier, Kyocera Corp, Cond?-sur-Huisne,Honda Motor, IBM-Asia, Bernard TapieFinance, Siam Nissan Automobile Co Ltd aregood examples of such prototypes.2.
Local context: Many single-word unknownNEs (some known NEs as well) may also becategorised using the local context.
For instance,the small sentences ?Peskine, director of thegroup?, ?the shareholders of Fibaly ?
or ?themayor of Gisenyi?
are used as categorisationrules.3.
Global context: After the first appearance ofa NE in full, its head (e.g.
family name, maincompany) is often used alone in the text insteadof the full name.
The company Kyocera Corp,for example, may be designated by the singleword Kyocera in the remainder of the text.
Foreach such unknown word, starting with a capitalletter, a special rule examines whether it appearsinside another NE in the text.4 Controlling a Rule-based System Us-ing Machine LearningMachine learning has been used successfully tocontrol a rule-based system that performs a dif-ferent task, namely document filtering (Wolinskiet al, 2000).
The learning method used in thatcase was a neural network (Stricker et al, 2001).In our present study, we control the rule-based NERC systems that have been presentedin section 3, with NERC systems constructed bythe C4.5 algorithm.
Our method comprises twostages: the training stage, during which C4.5constructs a new system using data generated bythe rule-based system, and the deployment stage,in which the results of the two systems are com-pared on new data and their disagreements areused as signals for change in the rule-based sys-tem.
This section describes the basic principlesof our control method.4.1 Control method: training stageThe training stage of our method consists of thefollowing processing steps (Figure 1):Running the rule-based NERC system on alarge training corpus (containing several thou-sands of NEs in our case).
The aim of this proc-ess is to recognise and classify the NEs in thecorpus.
The end product is a set of NEs, associ-ated with their class.Constructing a separate NERC system by ap-plying C4.5 on the data generated by the rule-based system.
In this process, the classified NEsare used as training data by C4.5, in order toconstruct the second NERC system (trainedNERC).
For each classified NE a training exam-ple (vector) is created, containing informationabout the part of speech and gazetteer tags of thefirst and the last two words of the NE, as well asthe two words preceding and the two followingthe NE.
It is important to note that, unlike otheruses of supervised machine learning methods,this approach does not require manual tagging oftraining data.TrainingCorpusRule-basedNERCTrainingDataC4.5 TrainedNERCFigure 1: Training stage.4.2 Control method: deployment stageIn the deployment stage, the two NERC systemsare compared on a new corpus to identify dis-agreements.
Despite the fact that the secondmethod is trained on data generated by the first,the different nature of the NERC system gener-ated by C4.5, i.e., a decision tree, leads to inter-esting disagreements between the two methods.The deployment stage consists of the followingprocessing steps (Figure 2):1.
Running the rule-based NERC system on anew corpus.
It should be stressed here that thedocuments in this corpus differ in some charac-teristic way from those in the training corpus.
Inour experiments the difference is chronological,i.e., the new corpus consists of recent news arti-cles.
The reason for adopting this approach isthat we are interested in the maintenance of arule-based system through time.
An alternativeapproach might be for the new corpus to be froma slightly different thematic domain.
In thatcase, the goal of the process would be the cus-tomisation of the rule-based system to a newdomain.2.
Running the trained NERC system on thesame corpus.3.
Comparing the results provided by both sys-tems to identify cases of disagreement.
The re-sult is a set of data where the two systems dis-agree: in our case, disagreements deal with thedifferent categories assigned by the NERC sys-tems to NEs (see Section 5 for detailed results).These cases are then provided to the languageengineer, who needs to evaluate them and de-cide on changes for the rule-based system.NewCorpusRule-basedNERCCases ofdisagreementIdentifydisagreementsTrainedNERCFigure 2: Deployment stage.5 ResultsIn order to evaluate the proposed method, twodifferent experiments were contacted, one foreach language.
The exact experimental settingsas well as the evaluation results are presented inthe following sections.5.1 Results for the Greek SystemFor the experiment regarding the Greek lan-guage, we used three NE classes: organisations,persons and locations.
For the purposes of theexperiment, two corpora of financial news wereused.2 The first corpus that was used for trainingpurposes, consisted of 5,000 news articles fromthe years 1996 and 1997, containing 10,010instances of NEs (1,885 persons, 1,781 loca-tions, 6,344 organisations).
The second corpus2 The corpora were provided by the Greek publishing com-pany Kapa-TEL.that was used for evaluation purposes consistedof 5,779 news from the years 1999 and 2000 andcontained 11,786 instances of NEs (1,137 per-sons, 810 locations, 9,839 organisations).5.1.1 Aggregate ResultsA good way to give an overview of the cases ofdisagreement of the two systems is through acontingency matrix, as shown in Table 1.
Therows of this table correspond to the classifica-tion of the rule-based system, while the columnsto the classification of the system constructed byC4.5.Table 1: Overview of the results for Greek.organisation.
person locationorganisation 9,906 250 32person 230 649 14location 24 6 675As we can see from Table 1, in 95% of the casesthe two systems are in agreement.
This means,that in order to update the rule-based NERCsystem, we have to examine only 5% of thecases, where the two systems disagree.
Examin-ing these cases gave us important insight regard-ing problems of the rule-based NERC system.Some examples are presented in the followingsections.5.2 Recognition problemsThe examination of cases in disagreement re-vealed some interesting problems regarding NErecognition.
These problems concern NEs thatthe rule-based system identified only partiallyand as a result classified them incorrectly.For example, in the stage of initial delimita-tion, the general patterns fail to identify NEs thatcontain numbers in their names, like the organi-sation ??????
2004?
(Athens 2004) represent-ing the organising committee of 2004 Olympics.In addition, during the separation phase someof the rules have not taken into account someinflexional endings, causing failures in separat-ing some NEs.
For example, in the phrase ??
??.??????????
?.
?????????
(the under-secretaryof Culture ?.
????????)
the recogniser failed toseparate the person name from its title, due tothe last accented character of the word ???????-????
?.Finally, we were able to locate several stop-words and update our exclusion list.
For in-stance, the phrase ????????
ISDN?
(ISDNlines) was recognised as an organisation (as theword ?????????
is a frequent constituent ofairline or shipping companies), but in reality thetext was referring to ISDN telephone lines.5.2.1 Classification problemsExcept from the problems identified in the rec-ognition phase, the examination of the cases ofdisagreement revealed various problems regard-ing mainly the classification grammar.
In fact,some of our classification rules were found to betoo general, leading to wrong classifications.For example, according to one of the rules, asequence of two words, starting with capitalletters, constitutes a person name if it is pre-ceded by a definite article and the endings ofthese two words belong in a specific set thatusually denote person names.
This rule causedthe classification of various non-NEs as persons,including ????
??????????
???????
(theOlympic Village).Another example of an overly general rule isa rule that classifies a sequence of abbreviationsor nouns starting with capital letter as an organi-sation, if this sequence is preceded by a commathat in turn is preceded by a NE already classi-fied as an organisation.
This rule caused theclassification of few person names as organisa-tions, such as ??
?????????
???
???????
?????-??
?, ?.?????????
(the director of NationalBank, ?.????????
).5.3 Results for the French SystemThe corpus used for the French experiment con-tained dispatches from the Agence France-Presse from April 1998 until January 2001.
Thethematic domain of the corpus was shareholdingevents.
This corpus contained six thousanddocuments, including 180,983 instances of NEswith the following distribution: companies(45%), locations (45%), persons (7%) and asso-ciations (non commercial organisations) (3%).For the purposes of this experiment, the corpuswas chronologically split in two parts.
The partcontaining the chronologically earlier messageswas used for training purposes while the secondpart, containing the most recent messages, wasused in order to evaluate our approach.
In thisexperiment, we mainly focused on four NEcategories, instead of the three categories usedfor the Greek experiment.
This differentiationoriginates in the fact that the French NERC sys-tem further categorises organisations into asso-ciations (non-profit organisations) and compa-nies.5.3.1 Aggregate ResultsThe contingency matrix giving an overview ofthe cases of disagreement of the two systems isshown in Table 2.
It appears that in 91% of thecases the two systems are in agreement.Table 2: Overview of the results for French.associat.
person location companyassociat.
808 6 31 618person 3 4,498 46 509location 11 51 6,870 2,526company 296 67 534 34,946Examining the disagreement cases gave us im-portant insight regarding problems of the rule-based system.
The following sections presentsome interesting examples.5.3.2 Recognition problemsSimilarly to the Greek experiment, the examina-tion of disagreements revealed some interestingproblems in the recognition of NEs.
For in-stance, ?Europe 1?
is a well-known French radiostation, also written sometimes as ?Europe Un?
(Europe One).
The rule-based system failed toidentify ?Europe Un?
and only identified?Europe?
as a location.
The source of the prob-lem is the lack of a mapping between fully writ-ten numbers and numerical figures.Another example is the phrase ?Le MansRe?, which is a shortened version of the com-pany name ?Les mutuelles du MansReassurance?
(a Reinsurance company).
Therule-based system recognised only ?Le Mans?
asa location, due to the well-known French city.What is needed here is an extension of the seg-mentation rules to include ?Re?
as a ?companydesignator?, such as ?Motor?, ?Bank?
or ?Tele-com?.5.3.3 Classification problemsMost of the classification problems that wereidentified concerned NEs already known to thesystem that meanwhile have acquired newmeanings.
For example, ?Ariane II rach?te?
(Ariane II buys) is classified as a person, due tothe word ?Ariane?
contained in the lexicon as aperson forename.
In reality, ?Ariane II?
is a newcompany that should also be included in thelexicon database.
Another example is ?Orange?already included in the lexicon as an old Frenchcity.
In the meanwhile, a new French companyhas been created having the same name, as inthe example ?Orange, valoris?e par les analys-tes?
(Orange, estimated by analysts).
Also in thiscase, the lexicon must be updated with a secondentry for this entity, categorised as a company.Besides lexicon omissions, some problemsregarding the classification grammar were alsorevealed.
First, overly general rules were identi-fied, such as the one that classifies entities start-ing from ?A?
and followed by numbers asFrench highway names.
This rule wrongly clas-sified the NE ?A3XX?
as a highway, while thetext was referring to an airplane model:?L?A3XX, un avion?
(The A3XX, an air plane).Our approach also succeeded in locatingwell-known NEs used in a new context.
Forexample, the rule-based NERC system recog-nises ?Taittinger?
as a company while the sys-tem learned by C4.5 disagrees with this classifi-cation in the sentence ?la famille Taittinger?
(thefamily Taittinger).
In this case, the grammarshould be updated with a rule saying that theword ?family?
in front of a proper name sug-gests a person name.6 ConclusionsIn this paper, we have proposed an alternativeuse of machine learning in named-entity recog-nition and classification.
Instead of constructingan autonomous NERC system, the system con-structed with the use of machine learning assistsin the maintenance of a rule-based NERC sys-tem.
An important feature of the approach is theuse of a supervised learning method, without theneed for manual tagging of training data.
Theproposed approach was evaluated with successfor two different languages: Greek and French.On-going work aims at reducing the numberof disagreements between the two systems downto those that are essential for the improvementof the system.
Currently, there are many caseswhere the two systems disagree, but the rule-based system is correct.Another extension that we are examining isto train a NERC system to not only classify, butalso recognise NEs.
We believe that this exten-sion will lead to the identification of more prob-lematic cases in the recognition phase.In conclusion, the method presented in thispaper proposes a simple and effective use ofmachine learning for the maintenance of rule-based systems.
The scope of this approach isclearly wider than that examined here, i.e.,named-entity recognition.AcknowledgementsThis research has been carried out thanks to theHellenic ?
French scientific cooperation projectADIET (PLATON no.
00521 TH).
It also usedresults of the Greek R&D project MITOS(EPET II ?
1.3 ?
102).ReferencesBennett S.W., Aone C. and Lovell C., 1997.
Learningto Tag Multilingual Texts through Observation.Proc.
of the Second Conference on EmpiricalMethods in NLP, pp.
109-116.Bikel D., Miller S., Schwartz R. and Weischedel R.,1997.
Nymble: a High-Performance LearningName-finder.
Proc.
of 5th Conference on Appliednatural Language Processing, Washington.Defense Advanced Research Projects Agency, 1998.Proc.
of the Seventh Message Understanding Con-ference (MUC-7), Morgan Kaufmann.Brill E., 1993.
A corpus-based approach to languagelearning.
PhD Dissertation, Univ.
of Pennsylvania.Cuchiarelli A., Luzi D., and Velardi P., 1998.
Auto-matic Semantic Tagging of Unknown ProperNames.
Proc.
of COLING-98, Montreal.Farmakiotou D., Karkaletsis V., Koutsias J., SigletosG., Spyropoulos C.D.
and Stamatopoulos P., 2000.Rule-based Named Entity Recognition for GreekFinancial Texts.
Proc.
of the Workshop on Compu-tational lexicography and Multimedia Dictionaries(COMLEX 2000), pp.
75-78.Kushmerick N., 1999.
Regression testing for wrappermaintenance.
Proc.
of National Conference on Ar-tificial Intelligence, pp.
74-79.McDonald D., 1996.
Internal and External Evidencein the Identification and Semantic Categorizationof Proper Names.
In B. Boguraev & J.
Pustejovski(eds.)
Corpus Processing for Lexical Acquisition,MIT Press, pp 21?39.Petasis G., Cucchiarelli A., Velardi P., Paliouras G.,Karkaletsis V., Spyropoulos C.D., 2000.
Automaticadaptation of Proper Noun Dictionaries throughcooperation of machine learning and probabilisticmethods.
Proc.
of ACM SIGIR-2000, Athens,Greece.Quinlan J. R., 1993.
C4.5: Programs for machinelearning.
Morgan-Kaufmann, San Mateo, CA.Riloff E., 1993.
Automatically Constructing a Dic-tionary for Information Extraction Tasks.
Proc.
ofthe National Conference on Artificial Intelligence,pp.
811-816.Riloff E. and Jones R., 1999.
Learning Dictionariesfor Information Extraction by Multi-Level Boot-strapping.
Proc.
of the National Conference on Ar-tificial Intelligence, pp.
474-479.Sekine, S., 1998.
NYU: Description of the JapaneseNE System used for MET-2.
Proc.
of the SeventhMessage Understanding Conference (MUC-7).Stricker M., Vichot F., Dreyfus G., Wolinski F.,2001.
Training Context-sensitive Neural Networkswith few Relevant Examples for TREC-9 Routing.In Text Retrieval Conference, TREC-9, NIST Spe-cial Publication, Gaithersburg, USA, to appear.Thompson C., Califf M., Mooney R., 1999.
ActiveLearning for Natural Language Parsing and Infor-mation Extraction.
Proc.
of the International Con-ference on Machine Learning, pp.
406-414.Vichot F., Wolinski F., Ferri H. C., Urbani D., 1999.Using Information Extraction for Knowledge En-tering, In Advances in Intelligent Systems - Con-cepts, Tools and Applications, S. G.
Tzafestas(Ed.
), Kluwer academic publishers, Dordrecht, TheNetherlands, pp.
191-200.Vilain M., and Day D., 1996.
Finite-state phraseparsing by rule sequences.
Proc.
of COLING-96,vol.
1, pp.
274-279.Wolinski F., Vichot F., Dillet B., 1995.
AutomaticProcessing of Proper Names in Texts.
In EuropeanChapter of the Association for Computer Linguis-tics, EACL, Dublin, Ireland, pp.23-30.Wolinski F., Vichot F., Stricker M., 2000.
UsingLearning-based Filters to Detect Rule-based Filter-ing Obsolescence.
In Recherche d?
InformationAssist?e par Ordinateur, RIAO, Paris, France,pp.1208-1220.
