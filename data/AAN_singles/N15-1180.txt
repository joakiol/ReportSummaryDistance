Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1569?1575,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsHow to Memorize a Random 60-Bit StringMarjan GhazvininejadInformation Sciences InstituteDepartment of Computer ScienceUniversity of Southern Californiaghazvini@isi.eduKevin KnightInformation Sciences InstituteDepartment of Computer ScienceUniversity of Southern Californiaknight@isi.eduAbstractUser-generated passwords tend to be memo-rable, but not secure.
A random, computer-generated 60-bit string is much more secure.However, users cannot memorize random 60-bit strings.
In this paper, we investigate meth-ods for converting arbitrary bit strings into En-glish word sequences (both prose and poetry),and we study their memorability and otherproperties.1 IntroductionPasswords chosen by users (e.g., ?Scarlet%2?)
areeasy to remember, but not secure (Florencio andHerley, 2007).
A more secure method is to use asystem-assigned 60-bit random password, such as0010100010100...00101001.
However, this string ishard to memorize.
In this paper, we convert suchstrings into English phrases, in order to improvetheir memorability, using natural language process-ing to select fluent passphrases.Our methods are inspired by an XKCD cartoon1that proposes to convert a randomly-chosen 44-bitpassword into a short, nonsensical sequence of En-glish words.
The proposed system divides the 44-bitpassword into four 11-bit chunks, and each chunkprovides an index into a 2048-word English dictio-nary.
XKCD?s example passphrase is correct horsebattery staple:1http://xkcd.com/93644-bit password English phrase--------------- --------------10101101010 -> correct10010110101 -> horse01010101010 -> battery10110101101 -> stapleThe four-word sequence is nonsense, but it is easierto memorize than the 44-bit string, and XKCD hy-pothesizes that users can improve memorability bybuilding an image or story around the four words.In this paper, we investigate other methods forconverting a system-generated bit string into a mem-orable sequence of English words.
Our methods pro-duce whole sentences, e.g.Fox news networks are seekingviews from downtown streets.as well as short poems, e.g.Diversity inside replied,Soprano finally reside.We also move to 60-bit passwords, for better secu-rity.
One source claims:As of 2011, available commercial prod-ucts claim the ability to test up to2,800,000,000 passwords a second on astandard desktop computer using a high-end graphics processor.2If this is correct, a 44-bit password would take onehour to crack, while a 60-bit password would take11.3 years.Our concrete task is as follows:2http://en.wikipedia.org/wiki/Password cracking1569Method Name AverageNumberof WordsAverageNumber ofCharactersAVG LMScoreCapacity Sample PasswordsXKCD 4 31.2 -62.42 1fees wesley inmate decentralizationphoto bros nan plainembarrass debating gaskell jennieFirst LetterMnemonic15 87.7 -61.20 2 ?
1051It makes me think of union pacific resourcesaid it looks like most commercial networks .Some companies keep their windows rolleddown so you don?t feel connected to anycommunity .Contains extreme violence and it was a matterof not only its second straight loss .All LetterMethod11.8 70.8 -58.83 3 ?
1056Parking and utilities have been searching for athird straight road win .It was the same girl and now a law professor inthe former east german town .I know a man who said he was chief of staffsin a real and deep conversation .FrequencyMethod9.7 55.5 -52.88 6 ?
1014Fox news networks are seeking views fromdowntown streets .The review found a silver tree throughdocuments and artifacts .These big questions are bothering me a bitstronger .Poetry 7.2 52.7 -73.15 106Joanna kissing verifiedsoprano finally resideDiversity inside repliedretreats or colors justifiedSurprise celebrity withoutthe dragging allison throughoutTable 1: Comparison of methods that convert system-assigned 60-bit strings into English word sequences.
Averageword lengths range from 4 (XKCD) to 15 (First Letter Mnemonic).
Average character lengths include spaces.
LMscore refers to the log probability assigned by a 5-gram English language model trained on the Gigaword corpus.Capacity tells how many English word sequences are available for an individual 60-bit input string.1570?
Input: A random, system-generated 60-bitpassword.?
Output: An English word sequence with twoproperties:?
It is memorable.?
We can deterministically recover the orig-inal input 60-bit string from it.This implies that we map 260distinct bit stringsinto 260distinct English sequences.
If a user memo-rizes the English word sequence supplied to them,then they have effectively memorized the 60-bitstring.2 Password Generation MethodsWe now describe our baseline password generationmethod, followed by four novel methods.
In Sec-tion 3 we experimentally test their memorability.2.1 XKCD BaselineOur baseline is a version of XKCD.
Instead of a2048-word dictionary, we use a 32,7868-word dic-tionary.
We assign each word a distinct 15-bit code.At runtime, we take a system-assigned 60-bitcode and split it into four 15-bit sequences.
We thensubstitute each 15-bit segment with its correspond-ing word.
By doing this, we convert a random 60-bitcode into a 4-word password.The first row of Table 1 shows three sampleXKCD passwords, along with other information,such as the average number of characters (includingspaces).2.2 First Letter MnemonicXKCD passwords are short but nonsensical, so wenow look into methods that instead create longer butfluent English sentences.
We might think to guaran-tee fluency by selecting sentences from an already-existing text corpus, but no corpus is large enough tocontain 260(?
1018) distinct sentences.
Therefore,we must be able to synthesize new English strings.In our first sentence generation method (First Let-ter Mnemonic), we store our input 60-bit code in thefirst letters of each word.
We divide the 60-bit codeinto 4-bit sections, e.g., ?0100-1101-1101-...?.
Every4-bit sequence type corresponds to an English letterBitSequenceMappedCharacterBitSequenceMappedCharacter0000 e 1000 r,x0001 t 1001 d,j0010 a 1010 l,k0011 o 1011 c,v0100 i 1100 u,b0101 n 1101 m,p0110 s,z 1110 w,y0111 h,q 1111 f,gTable 2: Mapping function between 4-bit sequences andEnglish letters in the First Letter Mnemonic method.or two, per Table 2.
We build a word-confusion net-work (or ?sausage lattice?)
by replacing each 4-bitcode with all English words that start with a corre-sponding letter, e.g.
:0100 1101 1111 ... 0011---- ---- ---- ----income my frog ... octopusis miner feast ... ofinner priest gratuitous ... oregon... ... ...
...This yields about 1074paths, some good (is myfrog.
.
. )
and some bad (income miner feast.
.
.
).To select the most fluent path, we train a 5-gramlanguage model with the SRILM toolkit (Stolcke,2002) on the English Gigaword corpus.3SRILMalso includes functionality for extracting the bestpath from a confusion network.Table 1 shows sample sentences generated by themethod.
Perhaps surprisingly, even though the sen-tences are much longer than XKCD (15 words ver-sus 4 words), the n-gram language model (LM)score is a bit better.
The sentences are locally flu-ent, but not perfectly grammatical.We can easily reconstruct the original 60-bit codeby extracting the first letter of each word and apply-ing the Table 2 mapping in reverse.2.3 All Letter MethodMost of the characters in the previous methods seem?wasted?, as only the word-initial letters bear in-formation relevant to reconstructing the original 60-3https://catalog.ldc.upenn.edu/LDC2011T071571Bit Sequence Mapped Characters0 e, o, i, h, r, c, u, f, g, b, v, x ,q1 t, a, n, s, d, l, m, w, y, p, k, j, zTable 3: Mapping function between bits and Englishcharacters in the All Letter Method.bit string.
Our next technique (All Letter Method)non-deterministically translates every bit into an En-glish letter, per Table 3.
Additionally, we non-deterministically introduce a space (or not) betweeneach pair of letters.This yields 4 ?
1084possible output strings per in-put, 3 ?1056of which consist of legal English words.From those 3 ?
1056strings, we choose the one thatyields the best word 5-gram score.It is not immediately clear how to process a letter-based lattice with a word-based language model.
Wesolve this search problem by casting it as one of ma-chine translation from bit-strings to English.
We cre-ate a phrase translation table by pairing each Englishword with a corresponding ?bit phrase?, using Ta-ble 3 in reverse.
Sample entries include:din ||| 1 0 1through ||| 1 0 0 0 0 0 0yields ||| 1 0 0 1 1 1We then use the Moses machine translation toolkit(Koehn et al, 2007) to search for the 1-best transla-tion of our input 60-bit string, using the phrase tableand a 5-gram English LM, disallowing re-ordering.Table 1 shows that these sentences are shorterthan the mnemonic method (11.8 words versus 15words), without losing fluency.Given a generated English sequence, we can de-terministically reconstruct the original 60-bit inputstring, using the above phrase table in reverse.2.4 Frequency MethodSentence passwords from the previous method con-tain 70.8 characters on average (including spaces).Classic studies by Shannon (1951) and others esti-mate that printed English may ultimately be com-pressible to about one bit per character.
This im-plies we might be able to produce shorter output (60characters, including space) while maintaining nor-mal English fluency.Our next technique (Frequency Method) modifiesthe phrase table by assigning short bit codes to fre-quent words, and long bit codes to infrequent words.For example:din ||| 0 1 1 0 1 0 1 0 0through ||| 1 1 1 1yields ||| 0 1 0 1 1 1 0 1Note that the word din is now mapped to a 9-bitsequence rather than a 3-bit sequence.
More pre-cisely, we map each word to a random bit sequenceof length bmax(1,??
?
log P(word) + ?)c.
Bychanging variables ?
and ?
we can vary betweensmooth but long sentences (?
= 1 and ?
= 0) toXKCD-style phrases (?
= 0 and ?
= 15).Table 1 shows example sentences we obtain with?
= 2.5 and ?
= ?2.5, yielding sentences of 9.7words on average.2.5 PoetryIn ancient times, people recorded long, historicalepics using poetry, to enhance memorability.
We fol-low this idea by turning each system-assigned 60-bitstring into a short, distinct English poem.
Our for-mat is the rhyming iambic tetrameter couplet:?
The poem contains two lines of eight syllableseach.?
Lines are in iambic meter, i.e., their syllableshave the stress pattern 01010101, where 0 rep-resents an unstressed syllable, and 1 representsa stressed syllable.
We also allow 01010100, toallow a line to end in a word like Angela.?
The two lines end in a pair of rhyming words.Words rhyme if their phoneme sequencesmatch from the final stressed vowel onwards.We obtain stress patterns and phoneme se-quences from the CMU pronunciation dictio-nary.4Monosyllabic words cause trouble, because theirstress often depends on context (Greene et al, 2010).For example, eighth is stressed in eighth street, butnot in eighth avenue.
This makes it hard to guar-antee that automatically-generated lines will scan asintended.
We therefore eject all monosyllabic words4http://www.speech.cs.cmu.edu/cgi-bin/cmudict1572from the vocabulary, except for six unstressed ones(a, an, and, the, of, or).Here is a sample poem password:The le-gen-da-ry Ja-pan-ese?
?
?
?
?
?
?
?Sub-si-di-ar-ies ov-er-seas?
?
?
?
?
?
?
?Meter and rhyme constraints make it difficult touse the Moses machine translation toolkit to searchfor fluent output, as we did above; the decoder statemust be augmented with additional short- and long-distance information (Genzel et al, 2010).Instead, we build a large finite-state acceptor(FSA) with a path for each legal poem.
In each path,the second line of the poem is reversed, so that wecan enforce rhyming locally.The details of our FSA construction are as fol-lows.
First, we create a finite-state transducer (FST)that maps each input English word onto four se-quences that capture its essential properties, e.g.
:create -> 0 1create -> 0 1 EY-Tcreate -> 1r 0rcreate -> EY-T 1r 0rHere, EY-T represents the rhyme-class of wordslike create and debate.
The r indicates a stress pat-tern in the right-to-left direction.We then compose this FST with an FSA that onlyaccepts sequences of the form:0 1 0 1 0 1 0 1 X X 1r 0r 1r 0r 1r 0r 1r 0rwhere X and X are identical rhyme classes (e.g., EY-T and EY-T).It remains to map an arbitrary 60-bit string ontoa path in the FSA.
Let k be the integer representa-tion of the 60-bit string.
If the FSA contains exactly260paths, we can easily select the kth path usingthe following method.
At each node N of the FSA,we store the total number of paths from N to thefinal state?this takes linear time if we visit statesin reverse topological order.
We then traverse theFSA deterministically from the start state, using k toguide the path selection.Our FSA actually contains 279paths, far morethan the required 260.
We can say that the informa-tion capacity of the English rhyming iambic tetram-eter couplet is 79 bits!
Some are very good:Sophisticated potentatesmisrepresenting Emirates.The supervisor notifiedthe transportation nationwide.Afghanistan, Afghanistan,Afghanistan, and Pakistan.while others are very bad:The shirley emmy plebiscitecomplete suppressed unlike inviteThe shirley emmy plebiscitecomplaints suppressed unlike inviteThe shirley emmy plebiscitecomplaint suppressed unlike inviteFortunately, because our FSA contains over a mil-lion times the required 260paths, we can avoid thesebad outputs.
For any particular 60-bit string, wehave a million poems to choose from, and we out-put only the best one.More precisely, given a 60-bit input string k, weextract not only the kth FSA path, but also thek + i ?
260paths, with i ranging from 1 to 999,999.We explicitly list out these paths, reversing the sec-ond half of each, and score them with our 5-gramLM.
We output the poem with the 1-best LM score.Table 1 shows sample outputs.To reconstruct the original 60-bit string k, we firstfind the FSA path corresponding to the user-recalledEnglish string (with second half reversed).
We usedepth-first search to find this path.
Once we have thepath, it is easy to determine which numbered pathit is, lexicographically speaking, using the node-labeling scheme above to recover k.3 ExperimentsWe designed two experiments to compare our meth-ods.The first experiment tests the memorability ofpasswords.
We asked participants to memorize apassword from a randomly selected method5and re-call it two days later.
To give more options to users,5In all experiments, we omit the First Letter Mnemonic, dueto its low performance in early tests.1573Method Participants Recalls CorrectRecallsXKCD 16 12 58.3%All LetterMethod15 9 33.3%FrequencyMethod15 10 40.0%Poetry 16 13 61.5%Table 4: Memorability of passwords generated by ourmethods.
?Recalls?
indicates how many participants re-turned to type their memorized English sequences, and?Correct Recalls?
tells how many sequences were accu-rately remembered.Method Name User preferenceXKCD 5%All Letter Method 39%Frequency Method 37%Poetry 19%Table 5: User preferences among passwords generated byour methods.we let them select from the 10-best passwords ac-cording to the LM score for a given 60-bit code.Note that this flexibility is not available for XKCD,which produces only one password per code.62 users participated in this experiment, 44 re-turned to recall the password, and 22 successfullyrecalled the complete password.
Table 4 shows thatthe Poetry and XKCD methods yield passwords thatare easiest to remember.In the second experiment, we present a separateset of users with passwords from each of the fourmethods.
We ask which they would prefer to use,without requiring any memorization.
Table 5 showsthat users prefer sentences over poetry, and poetryover XKCD.4 AnalysisTable 4 shows that the Poetry and XKCD methodsyield passwords that are easiest to memorize.
Com-plete sentences generated by the All Letter and Fre-quency Methods are harder to memorize.
At thesame time Table 5 shows that people like the sen-tences better than XKCD, so it seems that they over-estimate their ability to memorize a sentence of 10-12 words.
Here are typical mistakes (S = system-generated, R = as recalled by user):(S) Still looking for ruben sierra couldbe in central michigan(R) I am still looking for ruben sierrain central michigan(S) That we were required to go tocollege more than action movies(R) We are required to go tocollege more than action movies(S) No dressing allowed under canon lawin the youth group(R) No dresses allowed under canon lawfor youth groupsUsers remember the gist of a sentence very well,but have trouble reproducing the exact wording.Post-experiment interview reveal this to be partlyan effect of overconfidence.
Users put little mentalwork into memorizing sentences, beyond choosingamong the 10-best alternatives presented to them.By contrast, they put much more work into mem-orizing an XKCD phrase, actively building a mentalimage or story to connect the four otherwise unre-lated words.5 Future DirectionsActually, we can often automatically determine thata user-recalled sequence is wrong.
For example,when we go to reconstruct the 60-bit input stringfrom a user-recalled sequence, we may find that weget a 62-bit string instead.
We can then automati-cally prod the user into trying again, but we find thatthis is not effective in practice.
An intriguing di-rection is to do automatic error-correction, i.e., takethe user-recalled sequence and find the closest matchamong the 260English sequences producible by themethod.
Of course, it is a challenge to do this with1-best outputs of an MT system that uses heuristicbeam search, and we must also ensure that securityis maintained.We may also investigate new ways to re-rank n-best lists.
Language model scoring is a good start,but we may prefer vivid, concrete, or other typesof words, or we may use text data associated withthe user (papers, emails) for secure yet personalizedpassword generation.15746 Related WorkGasser (1975), Crawford and Aycock (2008), andShay et al (2012) describe systems that producemeaningless but pronounceable passwords, such as?tufritvi?
.
However, their systems can only assign?
230distinct passwords.Jeyaraman and Topkara (2005) suggest generat-ing a random sequence of characters, and findinga mnemonic for it in a text corpus.
A limited cor-pus means they again have a small space of system-assigned passwords.
We propose a similar method inSection 2.2, but we automatically synthesize a newmnemonic word sequence.Kurzban (1985) and Shay et al (2012) use amethod similar to XKCD with small dictionaries.This leads to longer nonsense sequences that can bedifficult to remember.7 ConclusionWe introduced several methods for generating se-cure passwords in the form of English word se-quences.
We learned that long sentences are seem-ingly easy to remember, but actually hard to repro-duce, and we also learned that our poetry methodproduced relatively short, memorable passwordsthat are liked by users.AcknowledgmentsWe would like to thank James Bedell, Aliya Deri,Tomer Levinboim, Jonathan May, Nima Pour-damghani and the anonymous reviewers for theirvery helpful comments.
This work was supportedin part by DARPA contract FA-8750-13-2-0045.ReferencesHeather Crawford and John Aycock.
2008.
Kwyjibo: au-tomatic domain name generation.
Software: Practiceand Experience, 38(14):1561?1567.Dinei Florencio and Cormac Herley.
2007.
A large-scale study of web password habits.
In Proceedings ofthe 16th international conference on World Wide Web,pages 657?666.
ACM.Morrie Gasser.
1975.
A random word generator forpronounceable passwords.
Technical report, Elec-tronic Systems Division, Air Force Systems Com-mand, USAF.Dmitriy Genzel, Jakob Uszkoreit, and Franz Och.
2010.Poetic statistical machine translation: rhyme and me-ter.
In Proceedings of the 2010 Conference on Empir-ical Methods in Natural Language Processing, pages158?166.
Association for Computational Linguistics.Erica Greene, Tugba Bodrumlu, and Kevin Knight.
2010.Automatic analysis of rhythmic poetry with applica-tions to generation and translation.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, pages 524?533.
Association forComputational Linguistics.Sundararaman Jeyaraman and Umut Topkara.
2005.Have your cake and eat it too?infusing usability intotext-password based authentication systems.
In Pro-ceedings of ACSAC.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, et al 2007.
Moses: Open source toolkit for sta-tistical machine translation.
In Proceedings of the 45thAnnual Meeting of the ACL, Demo and Poster Ses-sions, pages 177?180.
Association for ComputationalLinguistics.Stanley A Kurzban.
1985.
Easily rememberedpassphrases: a better approach.
ACM SIGSAC Review,3(2-4):10?21.Claude E. Shannon.
1951.
Prediction and entropyof printed English.
Bell System Technical Journal,30(1):50?64.Richard Shay, Patrick Gage Kelley, Saranga Koman-duri, Michelle L Mazurek, Blase Ur, Timothy Vidas,Lujo Bauer, Nicolas Christin, and Lorrie Faith Cranor.2012.
Correct horse battery staple: Exploring the us-ability of system-assigned passphrases.
In Proceed-ings of the Eighth Symposium on Usable Privacy andSecurity, page 7.
ACM.Andreas Stolcke.
2002.
SRILM-an extensible languagemodeling toolkit.
In INTERSPEECH, pages 901?904.1575
