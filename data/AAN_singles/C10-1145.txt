Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1290?1298,Beijing, August 2010Entity Linking LeveragingAutomatically Generated AnnotationWei Zhang?
Jian Su?
Chew Lim Tan?
Wen Ting Wang?
?School of ComputingNational University of Singapore{z-wei, tancl}@comp.nus.edu.sg?
Institute for Infocomm Research{sujian, wwang}@i2r.a-star.edu.sgAbstractEntity linking refers entity mentions in adocument to their representations in aknowledge base (KB).
In this paper, wepropose to use additional informationsources from Wikipedia to find morename variations for entity linking task.
Inaddition, as manually creating a trainingcorpus for entity linking is labor-intensive and costly, we present a novelmethod to automatically generate a largescale corpus annotation for ambiguousmentions leveraging on their unambi-guous synonyms in the document collec-tion.
Then, a binary classifier is trainedto filter out KB entities that are not simi-lar to current mentions.
This classifiernot only can effectively reduce the am-biguities to the existing entities in KB,but also be very useful to highlight thenew entities to KB for the further popu-lation.
Furthermore, we also leverage onthe Wikipedia documents to provide ad-ditional information which is not availa-ble in our generated corpus through adomain adaption approach which pro-vides further performance improve-ments.
The experiment results show thatour proposed method outperforms thestate-of-the-art approaches.1 IntroductionThe named entity (NE) ambiguation has raisedserious problems in many areas, including webpeople search, knowledge base population(KBP), and information extraction, because anentity (such as Abbott Laboratories, a diversifiedpharmaceuticals health care company) can bereferred to by multiple mentions (e.g.
?ABT?
and?Abbott?
), and a mention (e.g.
?Abbott?)
can beshared by different entities (e.g.
Abbott Texas: acity in United States; Bud Abbott, an Americanactor; and Abbott Laboratories, a diversifiedpharmaceutical health care company).Both Web People Search (WePS) task (Artileset al 2007) and Global Entity Detection & Rec-ognition task (GEDR) in Automatic Content Ex-traction 2008 (ACE08) disambiguate entity men-tions by clustering documents with these men-tions.
Each cluster then represents a unique enti-ty.
Recently entity linking has been proposed inthis field.
However, it is quite different from theprevious tasks.Given a knowledge base, a document collec-tion, entity linking task as defined by KBP-091(McNamee and Dang, 2009) is to determine foreach name string and the document it appears,which knowledge base entity is being referred to,or if the entity is a new entity which is notpresent in the reference KB.Compared with GEDR and WePS, entity link-ing has a given entity list (i.e.
the reference KB)to which we disambiguate the entity mentions.Moreover, in document collection, there are newentities which are not present in KB and can beused for further population.
In fact, new entitieswith or without the names in KB cover morethan half of testing instances.1 http://apl.jhu.edu/~paulmac/kbp.html1290Entity linking has been explored by several re-searchers.
Without any training data available,most of the previous work ranks the similaritybetween ambiguous mention and candidate enti-ties through Vector Space Model (VSM).
Sincethey always choose the entity with the highestrank as the answer, the ranking approaches hard-ly detect a situation where there may be a newentity that is not present in KB.
It is also difficultto combine bag of words (BOW) with other fea-tures.
For example, to capture the ?category?information, the method of Cucerzan (2007) in-volves a complicated optimization issue and theapproach has to be simplified for feasible com-putation, which compromises the accuracy.
Be-sides unsupervised methods, some supervisedapproaches (Agirre et al 2009, Li et al 2009 andMcNamee et al 2009) also have been proposedrecently for entity linking.
However, the super-vised approaches for this problem require largeamount of training instances.
But manuallycreating a corpus is labor-intensive and costly.In this paper, we explore how to solve the enti-ty linking problem.
We present a novel methodthat can automatically generate a large scalecorpus for ambiguous mentions leveraging ontheir unambiguous synonyms in the documentcollection.
A binary classifier based on SupportVector Machine (SVM) is trained to filter outsome candidate entities that are not similar toambiguous mentions.
This classifier can effec-tively reduce the ambiguities to the existing enti-ties in KB, and it is very useful to highlight thenew entities to KB for the further population.We also leverage on the Wikipedia documents toprovide additional information which is notavailable in our generated corpus through a do-main adaption approach which provides furtherperformance improvements.
Besides, more in-formation sources for finding more variationsalso contribute to the overall 22.9% accuracyimprovements on KBP-09 test data over baseline.The remainder of the paper is organized as fol-lows.
Section 2 reviews related work for entitylinking.
In Section 3 we detail our algorithm in-cluding name variation and entity disambigua-tion.
Section 4 describes the experimental setupand results.
Finally, Section 5 concludes the pa-per.2 Related WorkThe crucial component of entity linking is thedisambiguation process.
Raphael et al (2007)report a disambiguation algorithm for geography.The algorithm ranks the candidates based on themanually assigned popularity scores in KB.
Theclass with higher popularity will be assignedhigher score.
It causes that the rank of entitieswould never change, such as Lancaster (Califor-nia) would always have a higher rank than Lan-caster (UK) for any mentions.
However, as thepopularity scores for the classes change overtime, it is difficult to accurately assign dynamicpopularity scores.
Cucerzan (2007) proposes adisambiguation approach based on vector spacemodel for linking ambiguous mention in a doc-ument with one entity in Wikipedia.
The ap-proach ranks the candidates and chooses the ent-ity with maximum agreement between the con-textual information extracted from Wikipediaand the context of a document, as well as theagreement among the category tags associatedwith the candidate entities.
Nguyen and Cao(2008) refer the mentions in a document to KIM(Popov et al 2004) KB.
KIM KB is populatedwith over 40,000 named entities.
They representa mention and candidates as vectors of their con-textual noun phrase and co-occurring NEs, andthen the similarity is determined by the commonterms of the vectors and their associated weights.For linking mentions in news articles with a Wi-kipedia-derived KB (KBP-09 data set), Varma etal.
(2009) rank the entity candidates using asearch engine.
Han and Zhao (2009) rank thecandidates based on BOW and Wikipedia se-mantic knowledge similarity.All the related work above rank the candidatesbased on the similarity between ambiguous men-tion and candidate entities.
However, the rankingapproach hardly detects the new entity which isnot present in KB.Some supervised approaches also have beenproposed.
Li et al (2009) and McNamee et al(2009) train their models on a small manuallycreated data set containing only 1,615 examples.But entity linking requires large training data.Agirre et al (2009) use Wikipedia to constructtheir training data by utilizing Inter-Wikipedialinks and the surrounding snippets of text.
How-ever, their training data is created from a1291different domain which does not work well inthe targeted news article domain.3 ApproachIn this section we describe our two-stage ap-proach for entity linking: name variation andentity disambiguation.
The first stage finds vari-ations for every entity in the KB and generatesan entity candidate set for a given query.
Thesecond stage is entity disambiguation, whichlinks an entity mention with the real world entityit refers to.3.1 Name VariationThe aim for Name Variation is to build aKnowledge Repository of entities that containsvast amount of world knowledge of entities likename variations, acronyms, confusable names,spelling variations, nick names etc.
We useWikipedia to build our knowledge repositorysince Wikipedia is the largest encyclopedia inthe world and surpasses other knowledge basesin its coverage of concepts and up-to-datecontent.
We obtain useful information fromWikipedia by the tool named Java WikipediaLibrary 2  (Zesch et al 2008), which allows toaccess all information contained in Wikipedia.Cucerzan (2007) extracts the name variationsof an entity by leveraging four knowledgesources in Wikipedia: ?entity pages?, ?disam-biguation pages?
?redirect pages?
and ?anchortext?.Entity page in Wikipedia is uniquely identifiedby its title ?
a sequence of words, with the firstword always capitalized.
The title of Entity Pagerepresents an unambiguous name variation forthe entity.
A redirect page in Wikipedia is an aidto navigation.
When a page in Wikipedia is redi-rected, it means that those set of pages are refer-ring to the same entity.
They often indicate syn-onym terms, but also can be abbreviations, morescientific or more common terms, frequentmisspellings or alternative spellings etc.
Disam-biguation pages are created only for ambiguousmentions which denote two or more entities inWikipedia, typically followed by the word ?dis-ambiguation?
and containing a list of referencesto pages for entities that share the same name.This is more useful in extracting the abbrevia-2 http://www.ukp.tu-darmstadt.de/software/JWPLtions of entities, other possible names for an ent-ity etc.
Besides, both outlinks and inlinks in Wi-kipedia are associated with anchor texts thatrepresent name variations for the entities.Using these four sources above, we extractedname variations for every entity in KB to formthe Knowledge Repository as Cucerzan?s (2007)method.
For example, the variation set for entityE0272065 in KB is {Abbott Laboratories, Ab-bott Nutrition, Abbott ?}.
Finally, we can gen-erate the entity candidate set for a given queryusing the Knowledge Repository.
For example,for the query containing ?Abbott?, the entitycandidate set retrieved is {E0272065, E0064214?
}.From our observation, for some queries the re-trieved candidate set is empty.
If the entity forthe query is a new entity, not present in KB,empty candidate set is correct.
Otherwise, wefail to identify the mention in the query as a var-iation, commonly because the mention is a miss-pelling or infrequently used name.
So we pro-pose to use two more sources ?Did You Mean?and ?Wikipedia Search Engine?
when Cucerzan(2007) algorithm returns empty candidate set.Our experiment results show that both proposedknowledge sources are effective for entity link-ing.
This contributes to a performance improve-ment on the final entity linking accuracy.Did You Mean: The ?did you mean?
featureof Wikipedia can provide one suggestion formisspellings of entities.
This feature can help tocorrect the misspellings.
For example, ?AbbotNutrition?
can be corrected to ?Abbott Nutri-tion?.Wikipedia Search Engine: This key wordbased search engine can return a list of relevantentity pages of Wikipedia.
This feature is moreuseful in extracting infrequently used name.Algorithm 1 below presents the approach togenerate the entity candidate set over the createdKnowledge Repository.
RefE(s) is the entity setindexed by mention s retrieved from KnowledgeRepository.
In Step 8, we use the longest com-mon subsequence algorithm to measure the simi-larity between strings s and the title of the entitypage with highest rank.
More details about long-est common subsequence algorithm can befound in Cormen et al (2001).1292Algorithm 1 Candidate Set GenerationInput: mention s;1: if RefE(s) is empty2:        s?
?Wikipedia?did youmean?Suggestion3:        If s?
is not NULL4:             s ?
s?5:        else6:            EntityPageList ?
WikipediaSearchEngine(s)7:            EntityPage?FirstPage of EntityPageList8:            Sim=Similarity(s,EntityPage.title)9:            if Sim > Threshold10:   s?
EntityPage.title11:          end if12: end if13: end ifOutput: RefE(s);3.2 Entity DisambiguationThe disambiguation component is to link themention in query with the entity it refers to incandidate set.
If the entity to which the mentionrefers is a new entity which is not present in KB,nil will be returned.
In this Section, we will de-scribe the method for automatic data creation,domain adaptation from Wikipedia data, and oursupervised learning approach as well.3.2.1 Automatic Data CreationThe basic idea is to take a document with an un-ambiguous reference to an entity E1 and replac-ing it with a phrase which may refer to E1, E2 orothers.Observation: Some full names for the entitiesin the world are unambiguous.
This phenomenonalso appears in the given document collection ofentity linking.
The mention ?Abbott Laborato-ries?
appearing at multiple locations in the doc-ument collection refers to the same entity ?apharmaceuticals health care company?
in KB.From this observation, our method takes intoaccount the mentions in the Knowledge Reposi-tory associated with only one entity and we treatthese mentions as unambiguous name.
Let ustake Abbott Laboratories-{E0272065} in theKnowledge Repository as an example.
We firstuse an index and search tool to find the docu-ments with unambiguous mentions.
Such as, themention ?Abbott Laboratories?
occurs in docu-ment LDC2009T13 and LDC2007T07 in thedocument collection.
The chosen text indexingand searching tool is the well-known ApacheLucene information retrieval open-source li-brary3.Next, to validate the consistency of NE typebetween entities in KB and in document,   werun the retrieved documents through a NamedEntity Recognizer, to tag the named entities inthe documents.
Then we link the document tothe entity in KB if the document contains anamed entity whose name exactly matches withthe unambiguous mention and type (i.e.
Person,Organization and Geo-Political Entity) exactlymatches with the type of entity in KB.
In thisexample, after Named Entity Recognition, ?Ab-bott Laboratories?
in document LDC2009T13 istagged as an Organization which is consistentwith the entity type of E0272065 in KB.
We linkthe ?Abbott Laboratories?
occurring inLDC2009T13 with entity E0272065.Finally, we replace the mention in the selecteddocuments with the ambiguous synonyms.
Forexample, we replace the mention ?Abbott La-boratories?
in document LDC2009T13 with?Abbott?
where Abbott-{E0064214,E0272065?}
is an entry in Knowledge Reposi-tory.
?Abbott?
is ambiguous, because it is refer-ring not only to E0272065, but also to E0064214in Knowledge Repository.
Then, we can get twoinstances for the created data set as Figure 1,where one is positive and the other is negative.Figure 1: An instance of the data setHowever, from our studies, we realize somelimitations on our training data.
For example, asshown in Figure 1, the negative instance forE0272065 and the positive instance for3 http://lucene.apache.org(Abbott, LDC2009T13)  E0272065    +(Abbott, LDC2009T13)  E0064214    -?+   refer to  -  not refer to1293E0064214 are not in our created data set.However, those instances exist in the currentdocument collection.
We do not retrieve themsince there is no unambiguous mention forE0064214 in the document collection.To reduce the effect of this problem, we pro-pose to use the Wikipedia data as well, sinceWikipedia data has training examples for all theentities in KB.
Articles in Wikipedia often con-tain mentions of entities that already have a cor-responding article, and at least the first occur-rence of the mentions of an entity in a Wikipediaarticle must be linked to its corresponding Wiki-pedia article, if such an article exists.
Therefore,if the mention is ambiguous, the hyperlink isdisambiguating it.
Next, we will describe how toincorporate Wikipedia data.Incorporating Wikipedia Data.
The docu-ment collection for entity linking is commonlyfrom other domains, but not Wikipedia.
To ben-efit from Wikipedia data, we introduce a domainadaption approach (Daum?
III, 2007) which issuitable for this work since we have enough?target?
domain data.
The approach is to aug-ment the feature vectors of the instances.
Denoteby X the input space, and by Y the output space,in this case, X is the space of the real vectors????
for the instances in data set and Y= {+1,-1}is the label.
Ds is the Wikipedia domain datasetand Dt is our automatically created data set.Suppose for simplicity that X=RF for some F > 0(RF is the space of F-dimensions).
The aug-mented input space will be defined by ??
=R3F.Then, define mappings ?s, ?t : X ?
??
for map-ping the Wikipedia and our created data set re-spectively.
These are defined as follows:?????
??
?????
?????
?
??????
??
???????
????
?Where 0=<0,0,?,0> ?RF is the zero vector.
Weuse the simple linear kernel in our experiments.However, the following kernelized version canhelp us to gain some insight into the method.
Kdenotes the dot product of two vectors.K(x,x?
)=< ?
(x), ?
(x?)>.
When the domain isthe same, we get: ?????
???
??
?????
?????
???
?????
?????
?
?????
???
.
When they arefrom different domains, we get: ?????
???
???????
?????
??
????
???.
Putting this togeth-er, we have:??
?
??????
?????????????????
????????
?????
?This is an intuitively pleasing result.
Looselyspeaking, this means that data points from ourcreated data set have twice as much influence asWikipedia points when making predictionsabout test data from document collection.3.2.2 The Disambiguation FrameworkTo disambiguate a mention in document collec-tion, the ranking method is to rank the entities incandidate set based on the similarity score.
Inour work, we transform the ranking problem intoa classification problem: deciding whether amention refers to an entity on an SVM classifier.If there are 2 or more than 2 candidate entitiesthat are assigned positive label by the binaryclassifier, we will use the baseline system (ex-plained in Section 4.2) to rank the candidatesand the entity with the highest rank will be cho-sen.In the learning framework, the training or test-ing instance is formed by (query, entity) pair.For Wikipedia data, (query, entity) is positive ifthere is a hyperlink from the article containingthe mention in query to the entity, otherwise(query, entity) is negative.
Our automaticallycreated data has been assigned labels in Section3.2.1.
Based on the training instances, a binaryclassifier is generated by using particular learn-ing algorithm.
During disambiguation, (query,entity) is presented to the classifier which thenreturns a class label.Each (query, entity) pair is represented by thefeature vector using different features and simi-larity metrics.
We chose the following threeclasses of features as they represent a wide rangeof information - lexical features, word-categorypair, NE type - that have been proved to be ef-fective in previous works and tasks.
We nowdiscuss the three categories of features used inour framework in details.Lexical features.
For Bag of Words feature inWeb People Search, Artiles et al (2009) illu-strated that noun phrase and n-grams longer than2 were not effective in comparison with token-based features and using bi-grams gives the best1294results only reaching recall 0.7.
Thus, we usetoken-based features.
The similarity metric wechoose is cosine (using standard tf.idf weight-ing).
Furthermore, we also take into account theco-occurring NEs and represent it in the form oftoken-based features.
Then, the single cosinesimilarity feature is based on Co-occurring NEsand Bag of Words.Word Category Pair.
Bunescu (2007) dem-onstrated that word-category pairs extractedfrom the document and Wikipedia article are agood signal for disambiguation.
Thus we alsoconsider word-category pairs as a feature class,i.e., all (w,c) where w is a word from Bag ofWords of document and c is a category to whichcandidate entity belongs.NE Type.
This feature is a single binary fea-ture to guarantee that the type of entity in docu-ment (i.e.
Person, Geo-Political Entity and Or-ganization) is consistent with the type of entityin KB.4 Experiments and Discussions4.1 Experimental SetupIn our study, we use KBP-09 knowledge baseand document collection for entity linking.
In thecurrent setting of KBP-09 Data, the KB has beengenerated automatically from Wikipedia.
TheKB contains 818,741 different entities.
The doc-ument collection is mainly composed of news-wire text from different press agencies.
The col-lection contains 1.3 million documents that spanfrom 1994 to the end of 2008.
The test data has3904 queries across three named entity types:Person, Geo-Political Entity and Organization.Each query contains a document with an ambi-guous mention.Wikipedia data can be obtained easily fromthe website4 for free research use.
It is availablein the form of database dumps that are releasedperiodically.
In order to leverage various infor-mation mentioned in Section 3.1 to derive namevariations, make use of the links in Wikipedia togenerate our training corpus and get word cate-gory information for the disambiguation, we fur-ther get Wikipedia data directly from the website.The version we used in our experiments was re-leased on Sep. 02, 2009.
The automatically4 http://download.wikipedia.orgcreated corpus (around 10K) was used as thetraining data, and 30K training instances asso-ciated with the entities in our corpus was derivedfrom Wikipedia.For pre-processing, we perform sentenceboundary detection and Chunking derived fromStanford parser (Klein and Manning, 2003),Named Entity Recognition using a SVM basedsystem trained and tested on ACE 2005 with92.5(P) 84.3(R) 88.2(F), and coreference resolu-tion using a SVM based coreference resolvertrained and tested on ACE 2005 with 79.5%(P),66.7%(R) and 72.5%(F).We select SVM as the classifier used in thispaper since SVM can represent the stat-of-the-art machine learning algorithm.
In our imple-mentation, we use the binary SVMLight devel-oped by Joachims (1999).
The classifier istrained with default learning parameters.We adopt the measure used in KBP-09 to eva-luate the performance of entity linking.
Thismeasure is micro-averaged accuracy: the numberof correct link divided by the total number ofqueries.4.2 Baseline SystemsWe build the baseline using the ranking ap-proach which ranks the candidates based on si-milarity between mention and candidate entities.The entity with the highest rank is chosen.
Bagof words and co-occurring NEs are representedin the form of token-based feature vectors.
Thentf.idf is employed to calculate similarity betweenfeature vectors.To make the baseline system with token-based features state-of-the-art, we conduct a se-ries of experiments.
Table 1 lists the perfor-mances of our token-based ranking systems.
Inour experiment, local tokens are text segmentsgenerated by a text window centered on themention.
We set the window size to 55, which isthe value that was observed to give optimumperformance for the disambiguation problem(Gooi and Allan, 2004).
Full tokens and NE areall the tokens and named entities co-occurring inthe text respectively.
We notice that tokens ofthe full text as well as the co-occurring namedentity produce the best baseline performance,which we use for the further experiment.1295Micro-averagedAccuracylocal tokens 60.0local tokens + NE 60.6full tokens + NE 61.9Table 1: Results of the ranking methods4.3 Experiment and ResultAs discussed in Section 3.1, we exploit twomore knowledge sources in Wikipedia: ?did youmean?
(DYM) and ?Wikipedia search engine?
(SE) for name variation step.
We conduct someexperiments to compare our name variation me-thod using Algorithm 1 in Section 3.1 with thename variation method of Cucerzan (2007).
Ta-ble 2 shows the comparison results of differentname variation methods for entity linking.
Theexperiments results show that, in entity linkingtask, our name variation method outperforms themethod of Cucerzan (2007) for both entity dis-ambiguation methods.Name VariationApproachesRankingMethodOur Disambig-uation MethodCucerzan(2007)60.9 82.2+DYM+SE 61.9 83.8Table 2: Entity Linking Result for two namevariation approaches.
Column 1 used the base-line method for entity disambiguation step.
Col-umn 2 used our proposed entity disambiguationmethod.Table 3 compares the performance of differentmethods for entity linking on the KBP-09 testdata.
Row 1 is the result for baseline system.Row 2 and Row 3 show the results training onWikipedia data and our automatically data re-spectively.
Row 4 is the result training on bothWikipedia and our created data using the domainadaptation method mentioned in Section 3.2.1.
Itshows that our method trained on the automati-cally generated data alone significantly outper-forms baseline.
Compared Row 3 with Row 2,our created data set serves better at training theclassifier than Wikipedia data.
This is due to thereason that Wikipedia is a different domain fromnewswire domain.
By comparing Row 4 withRow 3, we find that by using the domain adapta-tion method in Section 3.2.1, our method forentity linking can be further improved by 1.5%.Likely, this is because of the limitation of theauto-generated corpus as discussed in Section3.2.1.
In another hand, Wikipedia can comple-ment the missing information with the auto-generated corpus.
So combining Wikipedia datawith our generated data can achieve better result.Compared with baseline system using Cucerzan(2007) name variation method in Table 2, in to-tal our proposed method achieves a significant22.9% improvement.Micro-averaged Accu-racyBaseline 61.9Wiki 79.9Created Data 82.3Wiki?
Created Data 83.8Table 3: Micro-averaged Accuracy for EntityLinkingTo test the effectiveness of our method todeal with new entities not present in KB and ex-isting entities in KB respectively, we conductsome experiments to compare with Baseline.Table 4 shows the performances of entity linkingsystems for existing entities (non-NIL) in KBand new entity (NIL) which is not present in KB.We can see that the binary classifier not onlyeffectively reduces the ambiguities to the exist-ing entities in KB, but also is very useful tohighlight the new entities to KB for the furtherpopulation.
Note that, in baseline system, all thenew entities are found by the empty candidateset of name variation process, while the disam-biguation component has no contribution.
How-ever, our approach finds the new entities not on-ly by the empty candidate set, but also leverag-ing on disambiguation component which alsocontributes to the performance improvement.non-NIL NILBaseline 72.6  52.4Wiki?
CreatedData79.2 87.8Table 4: Entity Linking on Existing and NewEntities1296Finally, we also compare our method with thetop 5 systems in KBP-09.
Among them,Siel_093 (Varma et al 2009) and NLPR_KBP1(Han and Zhao 2009) use similarity ranking ap-proach; Stanford_UBC2 (Agirre et al 2009),QUANTA1 (Li et al 2009) and hltcoe1 (McNa-mee et al 2009) use supervised approach.
Fromthe results shown in Figure 2, we observe thatour method outperforms all the top 5 systemsand the baseline system of KBP-09.
Specifically,our method achieves better result than both simi-larity ranking approaches.
This is due to the li-mitations of the ranking approach which havebeen discussed in Section 2.
We also observethat our method gets a 5% improvement overStanford_UBC2.
This is because they collecttheir training data from Wikipedia which is adifferent domain from document collection ofentity linking, news articles in this case; whileour automatic data generation method can createa data set from the same domain as the docu-ment collection.
Our system also outperformsQUANTA1 and hltcoe1 because they train theirmodel on a small manually created data set(1,615 examples), while our method can auto-matically generate a much larger data set.Figure 2: A comparison with KBP09 systems5 ConclusionThe purpose of this paper is to explore howto leverage the automatically generated largescale annotation for entity linking.
Traditionally,without any training data available, the solutionis to rank the candidates based on similarity.However, it is difficult for the ranking approachto detect a new entity that is not present in KB,and it is also difficult to combine different fea-tures.
In this paper, we create a large corpus forentity linking by an automatic method.
A binaryclassifier is then trained to filter out KB entitiesthat are not similar to current mentions.
We fur-ther leverage on the Wikipedia documents toprovide other information which is not availablein our generated corpus through a domain adap-tion approach.
Furthermore, new informationsources for finding more variations also contri-bute to the overall 22.9% accuracy improve-ments on KBP-09 test data over baseline.ReferencesE.
Agirre et al Stanford-UBC at TAC-KBP.
In Pro-ceedings of Test Analysis Conference 2009 (TAC09).J.
Artiles, J. Gonzalo, and S. Sekine.
2007.
The se-meval-2007 web evaluation: Establishing abenchmark for the web people search task.
In Pro-ceeding of the Fourth International Work-shop onSemantic Evaluations (SemEval-2007).J.
Artiles, E. Amigo and J. Gonzalo.
2009.
The roleof named entities in Web People Search.
In pro-ceeding of the 47th Annual Meeting of the Associa-tion for Computational Linguistics.R.
Bunescu.
2007.
Learning for information extrac-tion from named entity recognition and disambig-uation to relation extraction.
Ph.D thesis, Universi-ty of Texas at Austin, 2007.T.
H. Cormen, et al 2001.
Introduction To Algo-rithms (Second Edition).
The MIT Press, Page350-355.S.
Cucerzan.
2007.
Large-Scale Named Entity Dis-ambiguation Based on Wikipedia Data.
EmpiricalMethods in Natural Language Processing, June28-30, 2007.H.
Daum?
III.
2007.
Frustratingly easy domain adap-tation.
In Proceedings of the 45th Annual Meetingof the Association of Computational Linguistics .C.
H. Gooi and J. Allan.
2004.
Cross-document core-ference on a large scale corpus.
In proceedings ofHuman Language Technology Conference NorthAmerican Association for Computational Linguis-tics Annual Meeting, Boston, MA.X.
Han and J. Zhao.
NLPR_KBP in TAC 2009 KBPTrack: A Two-Stage Method to Entity Linking.
InProceedings of Test Analysis Conference 2009(TAC 09).0.8380.82170.80330.79840.78840.76720.5710.50.550.60.650.70.750.80.850.91297T.
Joachims.
1999.
Making large-scale SVM learningpractical.
In Advances in Kernel Methods - Sup-port Vector Learning.
MIT Press.D.
Klein and C. D. Manning.
2003.
Fast Exact Infe-rence with a Factored Model for Natural LanguageParsing.
In Advances in Neural InformationProcessing Systems 15 (NIPS 2002), Cambridge,MA: MIT Press, pp.
3-10.F.
LI et al THU QUANTA at TAC 2009 KBP andRTE Track.
In Proceedings of Test Analysis Con-ference 2009 (TAC 09).P.
McNamee and H. T. Dang.
2009.
Overview of theTAC 2009 Knowledge Base Population Track.
InProceedings of Test Analysis Conference 2009(TAC 09).P.
McNamee et al HLTCOE Approaches to Know-ledge Base Population at TAC 2009.
In Proceed-ings of Test Analysis Conference 2009 (TAC 09).H.
T. Nguyen and T. H. Cao.
2008.
Named EntityDisambiguation on an Ontology Enriched by Wi-kipedia.
2008 IEEE International Conference onResearch, Innovation and Vision for the Future inComputing & Communication Technologies.B.
Popov et al 2004.
KIM - a Semantic Platform forInformation Extraction and Retrieval.
In Journalof Natural Language Engineering, Vol.
10, Issue3-4, Sep 2004, pp.
375-392, Cambridge UniversityPress.V.
Raphael, K. Joachim and M. Wolfgang, 2007.Towards ontology-based disambiguation of geo-graphical identifiers.
In Proceeding of the 16thWWW workshop on I3: Identity, Identifiers, Identi-fications, 2007.V.
Varma et al 2009.
IIIT Hyderabad at TAC 2009.In Proceedings of Test Analysis Conference 2009(TAC 09).T.
Zesch, C. Muller and I. Gurevych.
2008.
Extrac-tiong Lexical Semantic Knowledge from Wikipe-dia and Wiktionary.
In Proceedings of the Confe-rence on Language Resources and Evaluation(LREC), 2008.1298
