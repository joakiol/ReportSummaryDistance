Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 314?321,The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational LinguisticsUser-adaptive Coordination of Agent Communicative Behaviorin Spoken DialogueKohji DohsakaNTT Communication Science LaboratoriesNTT Corporation2-4, Hikaridai, Seika-cho,Kyoto 619-0237, JapanAtsushi KanemotoGraduate School ofInformation Science and TechnologyOsaka University, 1-1, Yamadaoka,Suita, Osaka 565-0871, JapanRyuichiro HigashinakaNTT Cyber Space LaboratoriesNTT Corporation1-1, Hikarinooka, Yokosuka,Kanagawa 239-0847, JapanYasuhiro Minami and Eisaku MaedaNTT Communication Science LaboratoriesNTT Corporation2-4, Hikaridai, Seika-cho,Kyoto 619-0237, Japan{dohsaka,minami,maeda}@cslab.kecl.ntt.co.jphigashinaka.ryuichiro@lab.ntt.co.jpAbstractIn this paper, which addresses smooth spo-ken interaction between human users andconversational agents, we present an ex-perimental study that evaluates a methodfor user-adaptive coordination of agentcommunicative behavior.
Our methodadapts the pause duration preceding agentutterances and the agent gaze duration toreduce the discomfort perceived by indi-vidual users during interaction.
The exper-imental results showed a statistically sig-nificant tendency: the duration of the agentpause and the gaze converged during inter-action with the method.
The method alsosignificantly improved the perceived rele-vance of the agent communicative behav-ior.1 IntroductionConversational agents have been studied as an ef-fective human-computer interface for such pur-poses as training decision-making in team ac-tivities (Traum and Rickel, 2002), learning sup-port (Johnson et al, 2002), museum guides (Koppet al, 2005), and community facilitators (Zhenget al, 2005; Fujie et al, 2009).
They will playa crucial role in establishing a society where hu-mans and robots collaborate through natural in-teraction.
However, agents cannot produce theirintended effects when the smooth flow of interac-tion is disturbed.
To fully exploit the promise ofagents, we need to achieve smooth interaction be-tween human users and agents.Although various types of modalities have beenused in human-computer interfaces, speech hasdrawn a great deal of interest because it is one ofthe most pervasive communication methods in ourdaily lives and we usually perform it without anyspecial effort (Nass and Brave, 2005).
In this pa-per, we are interested in smooth spoken dialoguesbetween users and agents.A spoken dialogue is a joint activity amongparticipants (Clark, 1996).
For such a joint ac-tivity to be smooth and successful, participantsneed to coordinate their communicative behav-iors in various ways.
In human dialogues, par-ticipants agree on lexical choices to refer to ob-jects (Brennan and Clark, 1996) and coordinateeye gaze (Richardson and Dale, 2005) and whoseturn it is to speak (Sacks et al, 1974).
Theybecome more similar to their partners as the di-alogue proceeds in many aspects such as pitch,speech rate, and pause structure (Burgoon et al,1995; Hayashi et al, 2009).
Such coordinationserves to make conversation flow easily and intel-ligibly (Garrod and Pickering, 2004).The coordination of communicative behaviorsalso plays a crucial role in smooth human-agentinteraction.
Previous work addressed human be-havior adaptation to agents (Oviatt et al, 2004),agent behavior adaptation to human partners (Mit-sunaga et al, 2005; Tapus and Mataric?, 2007), andthe mutual adaptation of human and agent behav-ior (Breazeal, 2003).In this paper, which addresses smooth spokeninteraction between human users and agents, wefocus on the adaptation of agent communicativebehavior to individual users in spoken dialogues314with flexible turn-taking.
We present a methodfor user-adaptive coordination of agent commu-nicative behavior to reduce the discomfort per-ceived by individual users during the interactionand show experimental results that evaluate howthe method influences agent communicative be-havior and improves its relevance as perceived byusers.
For evaluation purposes, we used a quiz-style multi-party spoken dialogue system (Minamiet al, 2007; Dohsaka et al, 2009).
A quiz-styledialogue is a kind of thought-evoking dialoguethat can stir user thinking and activate communi-cation (Higashinaka et al, 2007a; Dohsaka et al,2009).
This characteristic is expected to be ad-vantageous for evaluation experiments since it en-courages involvement in the dialogue.Our method adapts agent communicative be-havior based on policy gradient reinforcementlearning (Sutton et al, 2000; Kohl and Stone,2004).
The policy gradient method has beenused for robot communicative behavior adapta-tion (Mitsunaga et al, 2005; Tapus and Mataric?,2007).
However, both studies dealt with scenario-based interaction in which a user and a robot actedwith predetermined timing.
In contrast, we focuson spoken dialogues in which users and agents canspeak with more flexible timing.
In addition, weallow for two- and three-party interactions amonga user and two agents.
It remains unclear whetherthe policy gradient method can successfully adaptagent communicative behavior to a user in two-or three-party spoken dialogues with flexible turn-taking.
Although this paper focuses on agent be-havior adaptation to human users, we believe thatour investigation of the agent behavior adaptationmechanism in flexible spoken interaction will con-tribute to conversational interfaces where humanusers and agents can mutually adapt their commu-nicative behaviors.As agent communicative behavior to beadapted, this paper focuses on the pause durationpreceding agent utterances and the agent gaze du-ration.
In conversation, the participant pause du-ration is influenced by partners, and the coordina-tion of pause structure leads to smooth communi-cation (Burgoon et al, 1995; Hayashi et al, 2009).Without pause structure coordination, undesiredspeech overlaps or utterance collisions are likelyto occur between users and agents, which may dis-turb smooth communication.
Funakoshi et al pro-posed a method to prevent undesired speech over-laps in human-robot speech interactions by usinga robot?s subtle expressions produced by a blink-ing LED attached to its chest (Funakoshi et al,2008).
In their method, a blinking light notifiesusers about such internal states of the robot as pro-cessing or busy and helps users identify the robotpause structures; however we are concerned withthe adaptation of robot pause structures to users.Gaze coordination is causally related to thesuccess of communication (Richardson and Dale,2005), and the amount of gaze influences conver-sational turn-taking (Vertegaal and Ding, 2002).The relevant control of agent gaze duration isthus essential to the smooth flow of conversation.Moreover, since the amount of gaze is related tospecific interpersonal attitudes among participantsand is also subject to such individual differences aspersonalities (Argyle and Cook, 1976), agent gazeduration must be adapted to individual users.In the following, Section 2 describes our quiz-style multi-party spoken dialogue system.
Sec-tion 3 shows our method for the user-adaptive co-ordination of agent communicative behavior.
Sec-tion 4 explains the experiment, and Section 5 de-scribes its results.
Section 6 concludes our paper.2 Quiz-Style Spoken Dialogue SystemTo evaluate a method for agent communicativebehavior adaptation, we used a quiz-style multi-party spoken dialogue system based on a quiz-style two-party spoken dialogue system (Minamiet al, 2007) and extended it to performmulti-partyinteraction (Dohsaka et al, 2009).In this system, a human user and one or twoagents interact.
The two agents include a quiz-master and a peer.
The quizmaster agent createsa ?Who is this??
quiz about a famous personand presents hints one by one to the user and thepeer agent, who participates in the interaction andguesses the correct answer in the same way thatthe user does.The hints are automatically created from thebiographical facts of people in Wikipedia1 andranked based on the difficulty of solving thequizzes experienced by users (Higashinaka et al,2007b).
Since users must consider the hints to of-fer reasonable answers, the system can stimulatetheir thinking and encourage them to engage in theinteraction (Higashinaka et al, 2007a).
In addi-tion, the peer agent?s presence and the agent?s em-pathic expressions improve user satisfaction and1http://ja.wikipedia.org/315Figure 1: User interacting with two agents usingthe quiz-style spoken dialogue systemincrease user utterances (Dohsaka et al, 2009).Figure 1 shows a human user interacting withthe two agents, both of whom are physically em-bodied robots.
The system utilizes an extremelylarge vocabulary with continuous speech recogni-tion (Hori et al, 2007).
Agent utterances are pro-duced by speech synthesis.
The agents can gaze atother participants by directing their faces to them.At each point of the dialogue, the system choosesthe next speaker and its utterance based on thedialogue state that the system maintains, the pre-conditions of the individual utterances, and a fewturn-taking rules (Dohsaka et al, 2009).
The agentpause and gaze durations are controlled based onthe adaptation method described in Section 3.A sample dialogue among a user and two agentsis depicted in Figure 2.
Master is the quizmasteragent, and Peer is the peer agent.
The agent ut-terances are classified as either spontaneous or re-sponsive.
Spontaneous utterances are those madeafter an agent takes his turn in an unforced man-ner, and responsive utterances are responses to theother?s utterances.
In the sample dialogue, sponidentifies spontaneous and res identifies respon-sive utterances.Quizmaster agent Master makes spontaneousutterances such as presenting hints (lines 1 and 5),indicating the quiz difficulty, and addressing lis-teners.
It also makes such responsive utterancesas evaluating the other?s answers (lines 3, 9, and11).
Peer agent Peer makes such spontaneous ut-terances as showing its own difficulty (line 4), giv-ing an answer (line 8), giving feedback when itsown or the other?s answer is right (line 12), andaddressing listeners.
It also makes such responsiveutterances as showing empathy to the user (line 7).3 Method for Agent CommunicativeBehavior AdaptationWe apply policy gradient reinforcement learn-ing (Sutton et al, 2000; Kohl and Stone, 2004)1 Master Who is this?
First hint.
He gradu-ated from the University of Tokyo.
(hint/spon)2 User Yoshida Shigeru?
(answer/spon)3 Master No, not even close!
He?s not apolitician.
(evaluation/res)4 Peer I don?t know.
Very difficult.
(show difficulty/spon)5 Master It?s time for the second hint: He?sa novelist and a scholar of Britishliterature.
(hint/spon)6 User Oh, I think I know it but I can?t re-member his name.
That?s so frus-trating.
(show difficulty/spon)7 Peer Difficult for me, too.
(show empathy/res)8 Peer Haruki Murakami?
(answer/spon)9 Master Close!
You are half right, becausehe is a novelist.
(evaluation/res)10 User Natsume Soseki?
(answer/spon)11 Master That?s right.
Wonderful.
(evaluation/res)12 Peer Good job.
(feedback/spon)Figure 2: Sample dialogue between user and twoagents: quizmaster Master and peer Peer.
Sponidentifies spontaneous and res identifies respon-sive utterances.to the user-adaptive coordination of agent com-municative behavior.
A policy gradient methodis a reinforcement learning (RL) approach that di-rectly optimizes a parameterized policy by gradi-ent ascent based on the gradient of the expectedreward with respect to the policy parameters.
Al-though RL methods have recently been applied tooptimizing dialogue management in spoken dia-logue systems (Williams and Young, 2007; Mi-nami et al, 2009), these previous studies utilizedRL methods based on the value-function estima-tion.
The policy gradient method is an alterna-tive approach to RL that has the following mer-its.
It can handle continuous and large actionspaces (Kimura and Kobayashi, 1998) and is usu-ally assured to converge to a locally optimal pol-icy in such action spaces (Sutton et al, 2000).Moreover, it does not need to explicitly estimatethe value function, and it is incremental, requiringonly a constant amount of computation per learn-ing step (Kimura and Kobayashi, 1998).Due to these advantages, the policy gradientmethod is suitable for adapting agent communica-tive behavior to a user during interaction, because316(1) ?
= [?j ]?
initial policy (policy parametervector of size n)(2) ?
= [?j ]?
step size vector of size n(3) ?
?
overall scalar step size(4) maxA?
0 (greatest absolute value ofreward ever observed in adaptation process)(5) while dialogue continues(6) for i = 1 to T(7) for j = 1 to n(8) rj ?
random choice from {?1, 0, 1}(9) Rij ?
?j + ?j ?
rj(Ri is T random perturbations of?
)(10) for i = 1 to T(11) Perform a hint dialogue based onpolicyRi, and evaluate reward(12) for j = 1 to n(13) Avg+?,j ?
average reward for all Riwith positive perturbation in parameter ?j(14) Avg0,j ?
average reward for all Riwith zero perturbation in parameter ?j(15) Avg?
?,j ?
average reward for all Riwith negative perturbation in parameter ?j(16) if (Avg0,j > Avg+?,j andAvg0,j > Avg?
?,j)(17) aj ?
0(18) else(19) aj ?
Avg+?,j ?Avg?
?,j(20) ?j(aj ?
aj|A| ?
?j ?
?
)(21) maxC ?
maximum of absolute value ofreward in current adaptation cycle(22) if (maxC > maxA)(23) maxA?
maxC (update maxA)(24) else(25) A?
A ?
maxCmaxA(26) ??
?+AFigure 3: Pseudocode for user-adaptive coordina-tion of agent communicative behaviorit can naturally incorporate such continuous pa-rameters as pause and gaze duration and incremen-tally adapt agent behavior.
In fact, the policy gra-dient method has been successfully used for robotbehavior adaptation (Mitsunaga et al, 2005; Tapusand Mataric?, 2007).
In this paper, we apply thismethod to agent communicative behavior adapta-tion in spoken dialogues with flexible turn-taking.Figure 3 shows our method for the user-adaptivecoordination of agent communicative behavior.This method is a modification of an algorithm pre-sented by Kohl and Stone (2004) in that the gra-dient is adjusted based on the maximum absolutevalue of the reward obtained during each adapta-tion cycle.The agent communicative behaviors are deter-mined based on a policy that is represented as vec-tor?
(= [?j ]) of n policy parameters.
In the quiz-style dialogues, the behavior of both the quizmas-ter and peer agents is controlled based on the samepolicy parameters.
The method adapts the behav-ior of both agents to individual users by adaptingthe policy parameters.
In this experiment, we usedthe following four parameters (n = 4):?
pre-spontaneous-utterance pause duration?spon: duration of pauses preceding agentspontaneous utterances?
pre-responsive-utterance pause duration?res: duration of pauses preceding agentresponsive utterances?
gaze duration ?gaze: duration of agent?s di-recting its face to the other while it is speak-ing or listening?
hint interval ?hint: interval of presenting quizhintsAs shown above, we used two types of pauseduration since the relevant pause duration can bedependent on dialogue acts (Itoh et al, 2009).
Al-though our main concern is the pause and gaze du-ration, we examined the hint interval as a parame-ter particular to quiz-style dialogues.To adapt the policy parameters to individualusers, we first generate T random perturbations[R1, .
.
.
,RT ] of current policy ?
by randomlyadding ?j , 0,?
?j to each parameter ?j of ?
inlines 6 to 9, where ?j is a step size set for eachparameter.
In the experiment, we set T to 10.
Thestep sizes of the parameters used in the experimentwill be shown later in Table 1.Dialogue per hint (a hint dialogue) is then per-formed based on each perturbation policyRi, andthe reward for each hint dialogue is obtained inlines 10 to 11.
All agent behaviors in a hint di-alogue are determined based on the same pertur-bation policy.
As we will explain in Section 4, inthe experiment, we regarded the magnitude of dis-comfort perceived by users during a hint dialogueas a negative reward.
Users signified discomfortby pressing buttons on the controller held in theirhands.
After performing hint dialogues for all TperturbationsRi, gradientA(= [aj ]) is computedin lines 12 to 19.
The gradient is normalized by317Parameters ?spon(sec.)?res(sec.)?gaze(sec.)?hint(sec.
)Initial value 4.96 0.53 3.04 27.7Step size 0.50 0.20 0.30 2.5Table 1: Initial values and step sizes of policy pa-rameters: ?spon (pre-spontaneous-utterance pauseduration), ?res (pre-responsive-utterance pauseduration), ?gaze (gaze duration), and ?hint (hintinterval)overall scalar step size ?
and individual step size?j for each parameter in line 20.
Overall scalarstep size ?
is used to adjust the adaptation speed,which we set to 1.0.Next we get the maximum maxC of the abso-lute value of the reward in the current adaptationcycle.
As in lines 21 to 25, the gradient is ad-justed based on the ratio of maxC to the greatestabsolute value maxA of reward ever observed inthe overall adaptation process.
Finally, the currentpolicy parameters are updated using the gradientin line 26.This is an adaptation cycle.
By iterating it, theagent communicative behavior is adapted to re-duce the discomfort perceived by each user.4 ExperimentWe recruited and paid 32 Japanese adults (16males and 16 females) for their participation.
Themean ages of the male and female groups were33.2 and 36.8, respectively.
They were dividedinto two groups: two-party dialogues (user andquizmaster) and three-party dialogues (user, quiz-master, and peer).
In each group, the numbers ofmales and females were identical.For this experiment, we used a quiz-style spo-ken dialogue system.
We chose the quiz sub-jects in advance and divided them into sets of fiveso that the difficulty level was approximately thesame in all sets.
For this purpose, we made sev-eral sets of five people of approximately identicalPageRank TM scores based on Wikipedia?s hyper-link structure.The users first rehearsed the dialogues for a setof five quizzes to familiarize themselves with thesystem.
After practicing, they performed the dia-logues to evaluate the adaptation method and tooka break per five-quiz set.
The presentation orderof the quiz sets was permutated to prevent ordereffect.
For each user, the dialogues continued un-til the user received 150 hints.
The adaptationmethod was applied during the interaction, and thepolicy parameters were updated per 10 hint dia-logues.
As a result, the parameters were updated15 times through the dialogues.
It took about twohours for each user to complete all dialogues.The policy parameters were updated based onthe magnitude of discomfort perceived by users.In this experiment, users were told to concentrateon the discomfort caused by agent pause and gazeduration and signified it by pressing buttons onthe controller held in their hands at three levels ofmagnitude: ?3?, ?2?, and ?1?.
The sum of discom-fort obtained during a hint dialogue was normal-ized with respect to the hint dialogue length, andthe normalized values were regarded as negativerewards.
Ideally we should estimate user discom-fort from such user behaviors as pause structureand eye gaze.
However, as the first step toward thatgoal, in this experiment we adopted this setting inwhich users directly signified their discomfort bypressing buttons.Table 1 shows the initial values and the stepsizes of the policy parameters used in the exper-iment.
To obtain the relevant initial values, weconducted a preparatory experiment in which tenother participants performed quiz-style dialoguesunder the same conditions as this experiment.
Theinitial values in this experiment were set to theaveraged final values of the policy parameters inthe preparatory experiment.
The step sizes weredetermined as approximately one-tenth of the ini-tial values except for the pre-responsive-utterancepause, for which the step size was set to 200 msecbased on the limits of human perception.Before and after the adaptation, the users filledout the following questionnaire items (7-point Lik-ert scale) to evaluate the relevance of agent pauseand gaze duration:?
Did you feel that the pause duration preced-ing the agent utterances was relevant??
Did you feel that the agent gaze duration wasrelevant while the agents were speaking orlistening to you?5 Results5.1 Convergence of policy parametersThe policy parameters were updated based on theadaptation method during the user-agent interac-tion.
Figure 4 exemplifies how the policy param-eter values changed during the adaptation cycleswith a user engaged in the two-party dialogue.31833.544.555.50 2 4 6 8 10 12 14(a) Pre-spontaneous-utt.
pause duration (sec.
)22.533.540 2 4 6 8 10 12 14(c) Gazeduration (sec.
)0.450.50.550.60.650 2 4 6 8 10 12 142022242628300 2 4 6 8 10 12 14(b) Pre-responsive-utt.
pause duration (sec.
)(d) Hint interval (sec.
)Figure 4: Change of policy parameter values dur-ing adaptation cycles with a user engaged in two-party dialogue.
Horizontal axis shows adaptationcycles and vertical axis shows parameter values.00.040.080.12 First-phase RAC Last-phase RACTwo-party dialoguep=0.029 *p=0.0071 **p=0.041 * N.S.
?spon ?res ?gaze ?hint00.040.080.12First-phase RAC Last-phase RACThree-party dialoguep=0.038 *p<0.001 ***p=0.016 *?spon ?res ?gaze ?hintp=0.011 *Figure 5: For each policy parameter, average andstandard error of first- and last-phase RACs (rela-tive amount of change in parameter values)Table 2 shows the statistics of the final valuesof the policy parameters at the end of the adapta-tion process.
Since the initial values were appro-priately determined based on the preparatory ex-periment, the final value averages were not greatlydifferent from the initial values.
However, judgingfrom the maximum, minimum, and standard devi-ations, the final values reflected individual users.If the adaptation method works successfully, thepolicy parameter values should converge duringthe user-agent interaction.
From this viewpoint,we examined the relative amount of change in thepolicy parameters (RAC).
Given parameter valuepk?1 at (k ?
1)-th adaptation cycle and param-eter value pk at k-th cycle, RAC is defined asTwo-party dialoguesParameters ?spon(sec.)?res(sec.)?gaze(sec.)?hint(sec.
)Average 5.04 0.62 3.10 25.8Min 3.90 0.39 2.40 19.5Max 6.17 1.18 3.69 31.2Sd.
0.72 0.21 0.36 2.7Three-party dialoguesParameters ?spon(sec.)?res(sec.)?gaze(sec.)?hint(sec.
)Average 4.86 0.62 3.15 27.4Min 4.07 0.35 2.52 22.0Max 5.54 0.90 3.58 32.7Sd.
0.44 0.18 0.27 2.5Table 2: Statistics of final values of policy param-eters: ?spon (pre-spontaneous-utterance pause du-ration), ?res (pre-responsive-utterance pause dura-tion), ?gaze (gaze duration), and ?hint (hint inter-val)|pk?pk?1|pk?1 .For each policy parameter, we compared theRAC averages in the first and in the last three adap-tation cycles: the first-phase RAC and the last-phase RAC.
As shown in Figure 5, the last-phaseRAC tends to be smaller than the first-phase RAC.The Kolmogorov-Smirnov test showed that the as-sumption of normality (p > 0.2) was met for eachgroup.
By applying the paired Welch?s t-test, asshown in Figure 5, we found that the last-phaseRAC is significantly smaller than the first-phaseRAC except for the hint interval in the two-partydialogues.
This shows that the agent pause andgaze duration converged during the interaction inboth the two- and three-party dialogues.The hint interval is unlikely to converge, prob-ably because it is a longer period than the pauseand gaze duration and is subject to various factors.Moreover, it greatly depends on user interest.5.2 User evaluationsFigure 6 shows the subjective user evaluations ofthe relevance of agent pause and gaze duration be-fore and after the adaptation.
Each user evaluationwas measured by a Likert question.
The rating ofa single Likert question is an ordinal measure, andwe generally cannot apply a parametric statisticaltest to an ordinal measure.
Therefore we used anonparametric test, the Wilcoxon signed-rank test,to compare user evaluations before and after the3191234567Pause Gaze Pause GazeBefore Adaptation After AdaptationTwo-party dialogue Three-party dialoguep=0.014 * p=0.0051 ** p=0.015 * p=0.021 *Figure 6: Average and standard error of user eval-uations of relevance of agent pause and gaze dura-tion before and after adaptationadaptation.
The F-test for the homogeneity of vari-ances (p > 0.1) showed that the data satisfied thestatistical test assumption.We found that in both the two- and three-partydialogues, the relevance of the agent pause andgaze duration significantly improved during thetwo-hour adaptation process (p < 0.01 for gazeduration in the two-party dialogues, p < 0.05 forother cases).
The p-values are shown in Figure 6.No significant differences between gender werefound.These results on the convergence of policyparameters and user evaluations show that thepolicy-gradient-based method can adapt agentcommunicative behavior to individual users inspoken dialogues with flexible turn-taking.6 ConclusionIn this paper, addressing smooth spoken inter-action between human users and conversationalagents, we presented a method for user-adaptivecoordination of agent communicative behaviorand experimentally evaluated how it can adaptagent behavior to individual users in spoken dia-logues with flexible turn-taking.
The method co-ordinates agent pause and gaze duration based onpolicy gradient reinforcement learning to reducethe discomfort perceived by individual users dur-ing interaction.
We experimentally evaluated themethod in a setting where the users performedtwo- and three-party quiz-style dialogues and sig-nified their discomfort by pressing buttons held intheir hands.
Our experimental results showed astatistically significant tendency: the agent pauseand gaze duration converged during interactionwith the method in both two- or three-party dia-logues.
The method also significantly improvedthe perceived relevance of the agent communica-tive behavior in both two- and three-party di-alogues.
These results indicate that in spokendialogues with flexible turn-taking, the policy-gradient-based method can adapt agent commu-nicative behavior to individual users.Many directions for future work remain.
First,we will analyze how users adapt their communica-tive behaviors with our method.
Second, we needto automatically estimate user discomfort or sat-isfaction based on such user behaviors as pausestructure, prosody, eye gaze, and body posture.Third, we will extend the adaptation method toregulate agent behavior based on dialogue states,since one limitation of the current method is itsinability to recognize them.
Fourth, we are inter-ested in the adaptation of additional higher-levelactions like the relevant choice of dialogue topicsbased on the level of user interest.AcknowledgmentsThis work was partially supported by a Grant-in-Aid for Scientific Research on Innovative Areas,?Founding a creative society via collaboration be-tween humans and robots?
(21118004), from theMinistry of Education, Culture, Sports, Scienceand Technology (MEXT), Japan.ReferencesMichael Argyle and Mark Cook.
1976.
Gaze and Mu-tual Gaze.
Cambridge University Press.Cynthia Breazeal.
2003.
Regulation and entrainmentfor human-robot interaction.
International Journalof Experimental Robotics, 21(10-11):883?902.Susan E. Brennan and Herbert H. Clark.
1996.
Con-ceptual pacts and lexical choice in conversation.Journal of Experimental Psychology: Learning,Memory, and Cognition, 22:1482?1493.Judee K. Burgoon, Lesa A. Stern, and Leesa Dillman.1995.
Interpersonal Adaptation: Dyadic InteractionPatterns.
Cambridge University Press.Herbert H. Clark.
1996.
Using Language.
CambridgeUniversity Press.Kohji Dohsaka, Ryota Asai, Ryuichiro Higashinaka,Yasuhiro Minami, and Eisaku Maeda.
2009.
Effectsof conversational agents on human communicationin thought-evoking multi-party dialogues.
In Proc.of SIGDIAL 2009, pages 217?224.Shinya Fujie, Yoichi Matsuyama, Hikaru Taniyama,and Tetsunori Kobayashi.
2009.
Conversation robotparticipating in and activating a group communica-tion.
In Proc.
of Interspeech 2009, pages 264?267.320Kotaro Funakoshi, Kazuki Kobayashi, Mikio Nakano,Seiji Yamada, Yasuhiko Kitamura, and Hiroshi Tsu-jino.
2008.
Smoothing human-robot speech interac-tions by using a blinking-light as subtle expression.In Proc.
of ICMI 2008, pages 293?296.Simon Garrod and Martin J. Pickering.
2004.
Why isconversation so easy?
Trends in Cognitive Sciences,8:8?11.Takanori Hayashi, Shohei Kato, and Hidenori Itoh.2009.
A synchronous model of mental rhythm usingparalanguage for communication robots.
In LectureNotes in Computer Science (PRIMA 2009), volume5925, pages 376?388.Ryuichiro Higashinaka, Kohji Dohsaka, ShigeakiAmano, and Hideki Isozaki.
2007a.
Effects of quiz-style information presentation on user understand-ing.
In Proc.
of Interspeech 2007, pages 2725?2728.Ryuichiro Higashinaka, Kohji Dohsaka, and HidekiIsozaki.
2007b.
Learning to rank definitions to gen-erate quizzes for interactive information presenta-tion.
In Proc.
of ACL 2007 (Poster Presentation),pages 117?120.Takaaki Hori, Chiori Hori, Yasuhiro Minami, and At-sushi Nakamura.
2007.
Efficient WFST-based one-pass decoding with on-the-fly hypothesis rescoringin extremely large vocabulary continuous speechrecognition.
IEEE Transactions on Audio, Speechand Language Processing, 15:1352?1365.Toshihiko Itoh, Norihide Kitaoka, and RyotaNishimura.
2009.
Subjective experiments oninfluence of response timing in spoken dialogues.In Proc.
of Interspeech 2009, pages 1835?1838.W.
Lewis Johnson, Jeff W. Rickel, and James C. Lester.2002.
Animated pedagogical aqgents: face-to-faceinteraction in interactive learning environments.
In-ternational Journal of Artificial Intelligence in Edu-cation, 11:47?78.Hajime Kimura and Shigenobu Kobayashi.
1998.
Re-inforcement learning for continuous action usingstochastic gradient ascent.
In Proc.
of the 5th Inter-national Conference on Intelligent Autonomous Sys-tems, pages 288?295.Nate Kohl and Peter Stone.
2004.
Policy gradient rein-forcement learning for fast quadrupedal locomotion.In Proc.
of ICRA 2004, volume 3, pages 2619?2624.Stefan Kopp, Lars Gesellensetter, Nicole C. Kra?mer,and Ipke Wachsmuth.
2005.
A conversational agentas museum guide: design and evaluation of a real-world application.
In Lecture Notes in ComputerScience (IVA 2009), volume 3661, pages 329?343.Yasuhiro Minami, Minako Sawaki, Kohji Dohsaka,Ryuichiro Higashinaka, Kentaro Ishizuka, HidekiIsozaki, Tatsushi Matsubayashi, Masato Miyoshi,Atsushi Nakamura, Takanobu Oba, Hiroshi Sawada,Takeshi Yamada, and Eisaku Maeda.
2007.
TheWorld of Mushrooms: human-computer interactionprototype systems for ambient intelligence.
In Proc.of ICMI 2007, pages 366?373.Yasuhiro Minami, Akira Mori, Ryuichiro Higashinaka,Kohji Dohsaka, and Eisaku Maeda.
2009.
Dialoguecontrol algorithm for ambient intelligence based onpartially observable Markov decision processes.
InProc.
of IWSDS 2009.Noriaki Mitsunaga, Christian Smith, Takayuki Kanda,Hiroshi Isiguro, and Norihiro Hagita.
2005.Human-robot interaction based on policy gradientreinforcement learning.
In Proc.
of IROS 2005,pages 1594?1601.Clifford Nass and Scott Brave.
2005.
Wired forSpeech: How Voice Activates and Advances theHuman-Computer Relationship.
The MIT Press.Sharon Oviatt, Courtney Darves, and Rachel Coulston.2004.
Toward adaptive conversational interfaces:modeling speech convergence with animated per-sonas.
ACM Transactions on Computer-Human In-teraction, 11(3):300?328.Daniel C. Richardson and Rick Dale.
2005.
Look-ing to understand: the coupling between speakers?and listeners?
eye movements and its relationshipto discourse comprehension.
Cognitive Science,29:1045?1060.Harvey Sacks, Emanuel A. Schegloff, and Gail Jeffer-son.
1974.
A simplest systematics for the orga-nization of turn-taking in conversation.
Language,50:696?735.Richard S. Sutton, David McAllester, Satinder Singh,and Yishay Mansour.
2000.
Policy gradient meth-ods for reinforcement learning with function approx-imation.
In Advances in Neural Information Pro-cessing Systems, volume 12, pages 1057?1063.Adriana Tapus and Maja J. Mataric?.
2007.
Hands-offtherapist robot behavior adaptation to user person-ality for post-stroke rehabilitation therapy.
In Proc.of 2007 IEEE International Conference on Roboticsand Automation, pages 1547?1553.David Traum and Jeff Rickel.
2002.
Embodied agentsfor multi-party dialogue in immersive virtual worlds.In Proc.
of AAMAS 2002, pages 766?773.Roel Vertegaal and Yaping Ding.
2002.
Explainingeffects of eye gaze on mediated group conversations:amount or synchronization.
In Proc.
of CSCW 2002,pages 41?48.Jason D. Williams and Steve Young.
2007.
Par-tially observable Markov decision processes for spo-ken dialog systems.
Computer & Speech Language,21(2):393?422.Jun Zheng, Xiang Yuan, and Yam San Chee.
2005.Designing multiparty interaction support in Elva, anembodied tour guide.
In Proc.
of AAMAS 2005,pages 929?936.321
