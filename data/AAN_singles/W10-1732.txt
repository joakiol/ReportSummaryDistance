Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 212?215,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsHierarchical Phrase-Based MT at the Charles Universityfor the WMT 2010 Shared TaskDaniel ZemanCharles University in Prague, Institute of Formal and Applied Linguistics (?FAL)Univerzita Karlova v Praze, ?stav form?ln?
a aplikovan?
lingvistiky (?FAL)Malostransk?
n?m?st?
25, Praha, CZ-11800, Czechiazeman@ufal.mff.cuni.czAbstractWe describe our experiments with hier-archical phrase-based machine translationfor WMT 2010 Shared Task.
We providea detailed description of our configurationand data so the results are replicable.
ForEnglish-to-Czech translation, we experi-ment with several datasets of various sizesand with various preprocessing sequences.For the other 7 translation directions, wejust present the baseline results.1 IntroductionCzech is a language with rich morphology (bothinflectional and derivational) and relatively freeword order.
In fact, the predicate-argument struc-ture, often encoded by fixed word order in English,is usually captured by inflection (especially thesystem of 7 grammatical cases) in Czech.
Whilethe free word order of Czech is a problem whentranslating to English (the text should be parsedfirst in order to determine the syntactic functionsand the English word order), generating correct in-flectional affixes is indeed a challenge for English-to-Czech systems.
Furthermore, the multitudeof possible Czech word forms (at least order ofmagnitude higher than in English) makes the datasparseness problem really severe, hindering bothdirections.There are numerous ways how these issuescould be addressed.
For instance, parsing andsyntax-aware reordering of the source-languagesentences can help with the word order differ-ences (same goal could be achieved by a reorder-ing model or a synchronous context-free grammarin a hierarchical system).
Factored translation, asecondary language model of morphological tagsor even a morphological generator are some of thepossible solutions to the poor-to-rich translation is-sues.Our submission to the shared task should revealwhere a pure hierarchical system stands in this jun-gle and what of the above mentioned ideas matchthe phenomena the system suffers from.
Althoughour primary focus lies on English-to-Czech trans-lation, we also report the accuracy of the samesystem on moderately-sized corpora for the otherthree languages and seven translation directions.2 The Translation SystemOur translation system belongs to the hierarchi-cal phrase-based class (Chiang, 2007), i.e.
phrasepairs with nonterminals (rules of a synchronouscontext-free grammar) are extracted from sym-metrized word alignments and subsequently usedby the decoder.
We use Joshua, a Java-based open-source implementation of the hierarchical decoder(Li et al, 2009), release 1.1.1Word alignment was computed using the firstthree steps of the train-factored-phrase-model.perl script packed with Moses2 (Koehn etal., 2007).
This includes the usual combination ofword clustering using mkcls3 (Och, 1999), two-way word alignment using GIZA++4 (Och andNey, 2003), and alignment symmetrization usingthe grow-diag-final-and heuristic (Koehn et al,2003).For language modeling we use the SRILMtoolkit5 (Stolcke, 2002) with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen andGoodman, 1998).We use the Z-MERT implementation of mini-mum error rate training (Zaidan, 2009).
The fol-lowing settings have been used for Joshua and Z-MERT:1http://sourceforge.net/projects/joshua/2http://www.statmt.org/moses/3http://fjoch.com/mkcls.html4http://fjoch.com/GIZA++.html5http://www-speech.sri.com/projects/srilm/212?
Grammar extraction:--maxPhraseLength=5?
Decoding: span_limit=10 fuzz1=0.1fuzz2=0.1 max_n_items=30 rela-tive_threshold=10.0 max_n_rules=50rule_relative_threshold=10.0?
N-best decoding: use_unique_nbest=trueuse_tree_nbest=falseadd_combined_cost=true top_n=300?
Z-MERT: -m BLEU 4 closest -maxIt 5-ipi 203 Data and Pre-processing Pipeline3.1 Baseline ExperimentsWe applied our system to all eight language pairs.However, for all but one we ran only a baseline ex-periment.
From the data point of view the baselineexperiments were even more constrained than theorganizers of the shared task suggested.
We did notuse the Europarl corpus, we only used the NewsCommentary corpus6 for training.
The target sideof the News Commentary corpus was also the onlysource to train the language model.
Table 1 showsthe size of the corpus.Corpus SentPairs Tokens xx Tokens encs-en 94,742 2,077,947 2,327,656de-en 100,269 2,524,909 2,484,445es-en 98,598 2,742,935 2,472,860fr-en 84,624 2,595,165 2,137,407Table 1: Number of sentence pairs and tokens forevery language pair in the News Commentary cor-pus.
Unlike the organizers of the shared task, westick with the standard ISO 639 language codes: cs= Czech, de = German, en = English, es = Spanish,fr = French.Note that in some cases the grammar extractionalgorithm in Joshua fails if the training corpus con-tains sentences that are too long.
Removing sen-tences of 100 or more tokens (per advice by Joshuadevelopers) effectively healed all failures.
Unfor-tunately, for the baseline corpora the loss of train-ing material was still considerable and resulted indrop of BLEU score, though usually insignificant.76Available for download at http://www.statmt.org/wmt10/translation-task.html using the link ?Parallelcorpus training data?.7Table 1 and Table 2 present statistics before removing thelong sentences.The News Test 2008 data set (2051 sentencesin each language) was used as development datafor MERT.
BLEU scores reported in this paperwere computed on the News Test 2009 set (2525sentences each language).
The official scores onNews Test 2010 are given only in the main WMT2010 paper.Only lowercased data were used for the baselineexperiments.3.2 English-to-CzechA separate set of experiments has been conductedfor the English-to-Czech direction and larger datawere used.
We used CzEng 0.9 (Bojar and?abokrtsk?, 2009)8 as our main parallel corpus.Following CzEng authors?
request, we did not usesections 8* and 9* reserved for evaluation pur-poses.As the baseline training dataset (?Small?
in thefollowing) only the news section of CzEng wasused.
For large-scale experiments (?Large?
in thefollowing), we used all CzEng together with theEMEA corpus9 (Tiedemann, 2009).10As our monolingual data we use the mono-lingual data provided by WMT10 organizers forCzech.
Table 2 shows the sizes of these corpora.Corpus SentPairs Tokens cs Tokens enSmall 126,144 2,645,665 2,883,893Large 7,543,152 79,057,403 89,018,033Mono 13,042,040 210,507,305Table 2: Number of sentences and tokens in theCzech-English corpora.Again, the official WMT 201011 developmentset (News Test 2008, 2051 sentences each lan-guage) and test set (News Test 2009, 2525 sen-tences each language) are used forMERT and eval-uation, respectively.
The official scores on NewsTest 2010 are given only in the main WMT 2010paper.We use a slightly modified tokenization rulescompared to CzEng export format.
Most notably,we normalize English abbreviated negation andauxiliary verbs (?couldn?t?
?
?could not?)
and8http://ufal.mff.cuni.cz/czeng/9http://urd.let.rug.nl/tiedeman/OPUS/EMEA.php10Unfortunately, the EMEA corpus is badly tokenized onthe Czech side with fractional numbers split into several to-kens (e.g.
?3, 14?).
We attempted to reconstruct the originaldetokenized form using a small set of regular expressions.11http://www.statmt.org/wmt10213attempt at normalizing quotation marks to distin-guish between opening and closing one followingproper typesetting rules.The rest of our pre-processing pipeline matchesthe processing employed in CzEng (Bojar and?abokrtsk?, 2009).12 We use ?supervised truecas-ing?, meaning that we cast the case of the lemmato the form, relying on our morphological analyz-ers and taggers to identify proper names, all otherwords are lowercased.4 ExperimentsAll BLEU scores were computed directly byJoshua on the News Test 2009 set.
Note thatthey differ from what the official evaluation scriptwould report, due to different tokenization.4.1 Baseline ExperimentsThe set of baseline experiments with all translationdirections involved running the system on lower-cased News Commentary corpora.
Word align-ments were computed on 4-character stems (in-cluding the en-cs and cs-en directions).
A trigramlanguage model was trained on the target side ofthe parallel corpus.Direction BLEUen-cs 0.0905en-de 0.1114cs-en 0.1471de-en 0.1617en-es 0.1966en-fr 0.2001fr-en 0.2020es-en 0.2025Table 3: Lowercased BLEU scores of the baselineexperiments on News Test 2009 data.4.2 English-to-CzechThe extended (non-baseline) English-to-Czech ex-periments were trained on larger parallel andmonolingual data, described in Section 3.2.
Notethat the dataset denoted as ?Small?
still falls intothe constrained task because it only uses CzEng0.9 and the WMT 2010 monolingual data.12Due to the subsequent processing, incl.
parsing, the tok-enization of English follows PennTreebenk style.
The ratherunfortunate convention of treating hyphenated words as sin-gle tokens increases our out-of-vocabulary rate.Word alignments were computed on lemmatizedversion of the parallel corpus.
Hexagram languagemodel was trained on the monolingual data.
True-cased data were used for training, as describedabove; the BLEU scores of these experiments inTable 4 are computed on truecased system output.Setup BLEUBaseline 0.0905Small 0.1012Large 0.1300Table 4: BLEU scores (lowercased baseline, true-cased rest) of the English-to-Czech experiments,including the baseline experiment with NewsCommentary, mentioned earlier.As for the official evaluation on News Test2010, we used the Small setup as our primary sub-mission, and the Large setup as secondary despiteits better results.
The reason was that it was notclear whether the experiment would be finished intime for the official evaluation.13An interesting perspective on the three en-csmodels is provided by the feature weights opti-mized duringMERT.We can see in Table 5 that thesmall and relatively weak baseline LM is trustedless than the most influential translation featurewhile for large parallel data and even much largerLM the weights are distributed more evenly.Setup LM Pt0 Pt1 Pt2 WPBaseline 1.0 1.55 0.51 0.63 ?2.63Small 1.0 1.03 0.72 ?0.09 ?0.34Large 1.0 0.98 0.97 ?0.02 ?0.82Table 5: Feature weights are relative to the weightof LM , the score by the language model.
Thenthere are the three translation features: Pt0 =P (e|f), Pt1 = Plex(f |e) and Pt2 = Plex(e|f).WP is the word penalty.4.3 EfficiencyThe machines on which the experiments were con-ducted are 64bit Intel Xeon dual core 2.8 GHzCPUs with 32 GB RAM.Word alignment of each baseline corpus tookabout 1 hour, time needed for data preprocessing13In fact, it was not finished in time.
Due to a failure ofa MERT run, we used feature weights from the primary sub-mission for the secondary one, too.214and training of the language model was negligible.Grammar extraction took about four hours but itcould be parallelized.
For decoding the test datawere split into 20 chunks that were processed inparallel.
OneMERT iteration, including decoding,took from 30 minutes to 1 hour.Training the large en-cs models requires morecareful engineering.
The grammar extraction eas-ily consumes over 20 GB memory so it is impor-tant to make sure Java really has access to it.
Weparallelized the extraction in the same way as wehad done with the decoding; even so, about 5 hourswere needed to complete the extraction.
The de-coder now must use the SWIG-linked SRILM li-brary because Java-based languagemodeling is tooslow and memory-consuming.
Otherwise, the de-coding times are comparable to the baseline exper-iments.5 ConclusionWe have described the hierarchical phrase-basedSMT system we used for the WMT 2010 sharedtask.
For English-to-Czech translation, we dis-cussed experiments with large data from the pointof view of both the translation accuracy and effi-ciency.This has been our first attempt to switch to hier-archical SMT and we have not gone too far beyondjust putting together the infrastructure and apply-ing it to the available data.
Nevertheless, our en-csexperiments not only confirm that more data helps;in the Small and Large setup, the data was not onlylarger than in Baseline, it also underwent a morerefined preprocessing.
In particular, we took ad-vantage of the Czeng corpus being lemmatized toproduce better word alignment; also, the truecas-ing technique helped to better target named enti-ties.AcknowledgementsThe work on this project was supported by thegrant MSM0021620838 by the Czech Ministry ofEducation.ReferencesOnd?ej Bojar and Zden?k ?abokrtsk?.
2009.
Czeng0.9: Large parallel treebank with rich annotation.The Prague Bulletin of Mathematical Linguistics,92:63?83.Stanley F. Chen and Joshua Goodman.
1998.
An em-pirical study of smoothing techniques for languagemodeling.
In Technical report TR-10-98, ComputerScience Group, Harvard, MA, USA, August.
Har-vard University.David Chiang.
2007.
Hierarchical Phrase-Based Translation.
Computational Linguistics,33(2):201?228.Reinhard Kneser and Hermann Ney.
1995.
Im-proved backing-off for m-gram language modeling.In Proceedings of the IEEE International Confer-ence on Acoustics, Speech and Signal Processing,pages 181?184, Los Alamitos, California, USA.IEEE Computer Society Press.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
InNAACL ?03: Proceedings of the 2003 Conferenceof the North American Chapter of the Associationfor Computational Linguistics on Human LanguageTechnology, pages 48?54, Morristown, NJ, USA.Association for Computational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ond?ej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: OpenSource Toolkit for Statistical Machine Translation.In Proceedings of the 45th Annual Meeting of theAssociation for Computational Linguistics Compan-ion Volume Proceedings of the Demo and Poster Ses-sions, pages 177?180, Praha, Czechia, June.
Associ-ation for Computational Linguistics.Zhifei Li, Chris Callison-Burch, Sanjeev Khudanpur,and Wren Thornton.
2009.
Decoding in Joshua:Open Source, Parsing-Based Machine Translation.The Prague Bulletin of Mathematical Linguistics,91:47?56, 1.Franz Josef Och andHermannNey.
2003.
A systematiccomparison of various statistical alignment models.Computational Linguistics, 29(1):19?51.Franz Josef Och.
1999.
An efficient method for deter-mining bilingual word classes.
In Proceedings of theNinth Conference of the European Chapter of the As-sociation for Computational Linguistics (EACL?99),pages 71?76, Bergen, Norway, June.
Association forComputational Linguistics.Andreas Stolcke.
2002.
Srilm ?
an extensible languagemodeling toolkit.
In Proceedings of InternationalConference on Spoken Language Processing, Den-ver, Colorado, USA.J?rg Tiedemann.
2009.
News from opus ?
a collectionof multilingual parallel corpora with tools and inter-faces.
InRecent Advances in Natural Language Pro-cessing (vol.
V), pages 237?248.
John Benjamins.Omar F. Zaidan.
2009.
Z-mert: A fully configurableopen source tool for minimum error rate training ofmachine translation systems.
The Prague Bulletin ofMathematical Linguistics, 91:79?88.215
