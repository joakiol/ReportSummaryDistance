Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 350?353,Prague, June 2007. c?2007 Association for Computational LinguisticsUBC-UMB: Combining unsupervised and supervised systems for all-wordsWSDDavid Martinez,Timothy BaldwinLT Group, CSSEUniversity of MelbourneVictoria 3010 Australia{davidm,tim}@csse.unimelb.edu.auEneko Agirre, Oier Lopez de LacalleIXA NLP GroupUniv.
of the Basque CountryDonostia, Basque Country{e.agirre,jibloleo}@ehu.esAbstractThis paper describes the joint submissionof two systems to the all-words WSD sub-task of SemEval-2007 task 17.
The maingoal of this work was to build a competitiveunsupervised system by combining hetero-geneous algorithms.
As a secondary goal,we explored the integration of unsupervisedpredictions into a supervised system by dif-ferent means.1 IntroductionThis paper describes the joint submission of two sys-tems to the all-words WSD subtask of SemEval-2007 task 17.
The systems were developed by theUniversity of the Basque Country (UBC), and theUniversity of Melbourne (UMB).
The main goal ofthis work was to build a competitive unsupervisedsystem by combining heterogeneous algorithms.
Asa secondary goal, we explored the integration ofthis method into a supervised system by differentmeans.
Thus, this paper describes both the unsu-pervised system (UBC-UMB-1), and the combinedsupervised system (UBC-UMB-2) submitted to theall-words task.Our motivation in building unsupervised systemscomes from the difficulty of creating hand-taggeddata for all words and all languages, which is col-loquially known as the knowledge acquisition bot-tleneck.
There have also been promising results inrecent work on the combination of unsupervised ap-proaches that suggest the gap with respect to super-vised systems is narrowing (Brody et al, 2006).The remainder of the paper is organized as fol-lows.
First we describe the disambiguation algo-rithms in Section 2.
Next, the development exper-iments are presented in Section 3, and our final sub-missions and results in Section 4.
Finally, we sum-marize our conclusions in Section 5.2 AlgorithmsIn this section, we will describe the standalone algo-rithms (three unsupervised and one supervised) andthe combination schemes we explored.
The unsu-pervised methods are based on different intuitionsfor disambiguation (topical features, local context,and WordNet relations), which is a desirable charac-teristic for combining algorithms.2.1 Topic Signatures (TS)Topic signatures (Agirre and de Lacalle, 2004) arelists of words related to a particular sense.
They canbe built from a variety of sources, and be used di-rectly to perform WSD.
Cuadros and Rigau (2006)present a detailed evaluation of topic signatures builtfrom a variety of knowledge sources.
In this workwe built those coming from the following:?
the relations in the Multilingual Central Repos-itory (TS-MCR)?
the relations in the Extended WordNet (TS-XWN)In order to apply this resource for WSD, we sim-ply measured the word-overlap between the targetcontext and each of the senses of the target word.The sense with highest overlap is chosen as the cor-rect sense.3502.2 Relatives in Context (RIC)This is an unsupervised method presented in Mar-tinez et al (2006).
This algorithm makes use ofthe WordNet relatives of the target word for disam-biguation.
The process is carried out in these steps:(i) obtain a set of close relatives from WordNet foreach sense (the relatives can be polysemous); (ii) foreach test instance define all possible word sequencesthat include the target word; (iii) for each word se-quence, substitute the target word with each relativeand query a web search engine; (iv) rank queries ac-cording to the following factors: length of the query,distance of the relative to the target word, and num-ber of hits; and (v) select the sense associated withthe highest ranked query.The intuition behind this system is that we canfind related words that can be substituted for the tar-get word in a given context, which are indicative ofits sense.
The close relatives that can form morecommon phrases from the target context determinethe target sense.2.3 Relative Number (RNB)This heuristic has been motivated as a way of identi-fying rare senses of a word.
An important disadvan-tage of unsupervised systems is that rare senses canbe over-represented in the models, while supervisedsystems are able to discard them because they haveaccess to token-level word sense distributions.This simple algorithm relies on the number ofclose relatives found in WordNet for each sense ofthe word.
The senses are ranked according to thenumber of synonyms, direct hypernyms, and di-rect hyponyms they have in WordNet.
The highestranked sense is taken to be the most important for thetarget word, and all occurrences of the target wordare tagged with that sense.2.4 k-Nearest Neighbours (kNN)As our supervised system, we relied on kNN.
This isa memory-based learning method where the neigh-bours are the k most similar contexts, represented byfeature vectors (~ci) of the test vector (~f ).
The sim-ilarity among instances is measured by the cosineof their vectors.
The test instance is labeled with thesense that obtains the maximum sum of the weightedvotes of the k most similar contexts.
Each vote isweighted depending on its (neighbour) position inthe ordered rank, with the closest being first.
Equa-tion 1 formalizes kNN, where Ci corresponds to thesense label of the i-th closest neighbour.arg maxSj=k?i=1{1i if Ci = Sj0 otherwise (1)The UBC group used a combination of kNN clas-sifiers trained over a large set of features, and en-hanced this method using Singular Value Decompo-sition (SVD) for their supervised submission (UBC-ALM) to the lexical-sample and all-words subtasks(Agirre and Lopez de Lacalle, 2007).
However, weonly used the basic implementation in this work, dueto time constraints.2.5 Combination of systemsWe explored two approaches to combine the stan-dalone systems.
The first consisted simply of addingup the normalized weights that each system wouldgive to each sense.
We tested this voting approachboth for the unsupervised and supervised settings.The second method could only be applied in com-bination with the supervised kNN system.
Theidea was to include the unsupervised predictions asweighted features for the supervised system.
We re-fer to this method as ?stacking?, and it has been pre-viously used to integrate heterogeneous knowledgesources for WSD (Stevenson and Wilks, 2001).3 Development experimentsWe tested the single algorithms and their combina-tion over both Semcor and the training distributionof the SemEval-2007 lexical-sample subtask of task17 (S07LS for short).
The goal of these experimentswas to obtain an estimate of the expected perfor-mance, and submit the most promising configura-tion.
We present first the tests on the unsupervisedsetting, and then the supervised setting.
It is im-portant to note that the hand-tagged corpora was notused to fine-tune the parameters of the unsupervisedalgorithms.3.1 Unsupervised systemsFor the first evaluation of our unsupervised systems,we relied on Semcor, and tagged 43,063 instancesof the 329 word types occurring in SemEval-2007351System RecallRNB 30.6TS-MCR 57.5TS-XWN 47.0TS-MCR & TS-XWN 57.3RBN & TS-MCR & TS-XWN 53.6Table 1: Evaluation of standalone and combinedunsupervised systems over 43,063 instances fromSemcorSystem RecallTS-MCR 60.1TS-XWN 54.3TS-MCR & TS-XWN 61.1TS-MCR & TS-XWN & RIC* 61.2Table 2: Evaluation of standalone and combinedunsupervised systems over 8,518 instances fromS07LS trainingall-words.
Due to time constraints, we were not ableto test the RIC algorithm on this dataset.
The re-sults are shown in Table 1.
We can see that the RNBheuristic performs poorly, and that the best configu-ration consists of applying the single TS-MCR algo-rithm.
From this experiment, we decided to removethe RNB heuristic and focus on the topic signaturesand RIC.We also used S07LS for extra experiments inthe unsupervised setting.
From the training part ofthe S07LS dataset, we extracted 8,518 instances ofwords also occurring in SemEval-2007 all-words.As S07LS used senses from OntoNotes, we reliedon the mapping provided by the task organisers tolink them to WordNet senses.
We left RNB out ofthis experiment due to its low performance in Sem-cor, and regarding RIC, we only evaluated a sampleof 68 instances.
Results are shown in Table 2.
Thebest scores are achieved when combining both setsof topic signatures.
The few cases that have beendisambiguated with RIC improve the overall perfor-mance slightly.3.2 Combined systemWe could not rely on Semcor in the supervised set-ting (we used it for training), and therefore tried touse as much data as possible from the training com-ponent of S07LS, wherein all the instances avail-able (22,281) were disambiguated.
We tested firstSystem RecallkNN 87.4kNN & TS-MCR 86.8kNN & TS-XWN 86.4kNN & TS-MCR & TS-XWN 86.0Table 3: Evaluation of voting supervised systems in22,281 instances from S07LS trainingSystem RecallkNN 71.7kNN & TS-MCR & TS-XWN 71.8Table 4: Evaluation of ?stacking?
the unsupervisedsystems on kNN over 8,518 instances from S07LStrainingthe voting combination by adding the normalizedweights from the output of each system.
Due totime constraints we only evaluated the combinationof kNN with TS-MCR and TS-XWN.
Results areshown in Table 3, where we can see that combin-ing the unsupervised systems with voting hurts theperformance of the kNN method.Finally, we applied the second combination ap-proach, consisting of including the predictions of theunsupervised systems as features for kNN (?stack-ing?).
We performed this experiment on the trainingpart of S07LS, but only for the 8,518 instances ofthe words occurring on the all-words dataset.
Theresults of this experiment are given in Table 4.
Weobserved a slight improvement in this case.4 Final systemsFor our final submissions, we chose the combination?TS-MCR& TS-XWN&RIC?
for the unsupervisedsystem (UBC-UMB-1), and the combination ?kNN& TS-MCR & TS-XWN?
via ?stacking?
for our su-pervised system (UBC-UMB-2).
The results of allthe systems are given in Table 5.We can see that our unsupervised system ranked10th.
Unfortunately, we do not know at the time ofwriting which other systems are unsupervised, andtherefore are unable to compare to other unsuper-vised systems.Our ?stacking?
supervised system performsslightly lower than the kNN supervised systems byUBC-ALM (which ranks 7th), showing that our sys-tem was not able to profit from information from352System Precision Recall1.
0.537 0.5372.
0.527 0.5273.
0.524 0.5244.
0.522 0.4865.
0.518 0.5186.
0.514 0.5147.
0.493 0.4928.
UBC-UMB-2 0.485 0.4849.
0.420 0.42010.
UBC-UMB-1 0.362 0.36211.
0.355 0.35512.
0.337 0.33713.
0.298 0.29814.
0.120 0.118Table 5: Official results for all systems in task #17of SemEval-2007.
Our systems are shown in bold.UBC-UMB-1 stands for TS-MCR & TS-XWN &RIC, and UBC-UMB-2 for kNN & TS-MCR & TS-XWN.System Precision RecallTS-MCR 36.7 36.5TS-XWN 33.1 32.9RIC 30.6 30.4TS-MCR & TS-XWN 37.5 37.3TS-MCR & TS-XWN & RIC 36.2 36.2Table 6: Our unsupervised systems in the SemEval-2007 all words test datathe unsupervised systems.
However, we cannot at-tribute the decrease only to the unsupervised fea-tures, as the kNN implementations were different(UBC-ALM relied on SVD).After the gold-standard data was released, wewere able to test the contribution of each of the un-supervised systems in the ensemble, as well as twoadditional combinations.
The results are given inTable 6.
We can see that TS-MCR is the best per-forming method, confirming our development ex-periments (cf.
Tables 1 and 2).
In contrast, in-cluding RIC decreased the performance by 0.7 per-cent points, and had we used only TS-MCR and TS-XWN our results would have been better.5 ConclusionsIn this submission we combined heterogeneous un-supervised algorithms to obtain competitive perfor-mance without relying on training data.
However,due to time constraints, we were only able to submita preliminary system, and some of the unsupervisedmethods were not properly developed and tested.For future work we plan to properly test thesemethods, and deploy other unsupervised algorithms.We also plan to explore more sophisticated combina-tion strategies, using meta-learning to try to predictwhich features of each word make a certain WSDsystem succeed (or fail).AcknowledgementsThe first and second authors were supported by Aus-tralian Research Council grant no.
DP0663879.
Wewant to thank German Rigau from the University ofthe Basque Country for kindly providing access tothe MCR.ReferencesEneko Agirre and Oier Lopez de Lacalle.
2004.
Pub-licly available topic signatures for all WordNet nom-inal senses.
In Proceedings of the 4rd InternationalConference on Language Resources and Evaluations(LREC), pages 1123?6, Lisbon, Portugal.Eneko Agirre and Oier Lopez de Lacalle.
2007.
UBC-ALM: Lexical-Sample and All-Words tasks.
InProceedings of SemEval-2007 (forthcoming), Prague,Czech Republic.Samuel Brody, Roberto Navigli, and Mirella Lapata.2006.
Ensemble methods for unsupervised WSD.
InProceedings of the 21st International Conference onComputational Linguistics and the 44th annual meet-ing of the ACL, pages 97?104, Sydney, Australia.Montse Cuadros and German Rigau.
2006.
Quality as-sessment of large scale knowledge resources.
In Pro-ceedings of the International Conference on EmpiricalMethods in Natural Language Processing (EMNLP-06), pages 534?41, Sydney, Australia.David Martinez, Eneko Agirre, and Xinglong Wang.2006.
Word relatives in context for word sense dis-ambiguation.
In Proceedings of the 2006 AustralasianLanguage Technology Workshop, pages 42?50, Syd-ney, Australia.Mark Stevenson and YorickWilks.
2001.
The interactionof knowledge sources in word sense disambiguation.Computational Linguistics, 27(3):321?49.353
