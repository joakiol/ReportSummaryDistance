Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 141?144,Suntec, Singapore, 4 August 2009.c?2009 ACL and AFNLPAsynchronous Binarization for Synchronous GrammarsJohn DeNero, Adam Pauls, and Dan KleinComputer Science DivisionUniversity of California, Berkeley{denero, adpauls, klein}@cs.berkeley.eduAbstractBinarization of n-ary rules is critical for the effi-ciency of syntactic machine translation decoding.Because the target side of a rule will generallyreorder the source side, it is complex (and some-times impossible) to find synchronous rule bina-rizations.
However, we show that synchronousbinarizations are not necessary in a two-stage de-coder.
Instead, the grammar can be binarized oneway for the parsing stage, then rebinarized in adifferent way for the reranking stage.
Each indi-vidual binarization considers only one monolin-gual projection of the grammar, entirely avoid-ing the constraints of synchronous binarizationand allowing binarizations that are separately op-timized for each stage.
Compared to n-ary for-est reranking, even simple target-side binariza-tion schemes improve overall decoding accuracy.1 IntroductionSyntactic machine translation decoders searchover a space of synchronous derivations, scoringthem according to both a weighted synchronousgrammar and an n-gram language model.
Therewrites of the synchronous translation gram-mar are typically flat, n-ary rules.
Past workhas synchronously binarized such rules for effi-ciency (Zhang et al, 2006; Huang et al, 2008).Unfortunately, because source and target ordersdiffer, synchronous binarizations can be highlyconstrained and sometimes impossible to find.Recent work has explored two-stage decoding,which explicitly decouples decoding into a sourceparsing stage and a target language model inte-gration stage (Huang and Chiang, 2007).
Be-cause translation grammars continue to increasein size and complexity, both decoding stages re-quire efficient approaches (DeNero et al, 2009).In this paper, we show how two-stage decodingenables independent binarizations for each stage.The source-side binarization guarantees cubic-time construction of a derivation forest, while anentirely different target-side binarization leads toefficient forest reranking with a language model.Binarizing a synchronous grammar twice inde-pendently has two principal advantages over syn-chronous binarization.
First, each binarization canbe fully tailored to its decoding stage, optimiz-ing the efficiency of both parsing and languagemodel reranking.
Second, the ITG constraint onnon-terminal reordering patterns is circumvented,allowing the efficient application of synchronousrules that do not have a synchronous binarization.The primary contribution of this paper is to es-tablish that binarization of synchronous grammarsneed not be constrained by cross-lingual reorder-ing patterns.
We also demonstrate that even sim-ple target-side binarization schemes improve thesearch accuracy of forest reranking with a lan-guage model, relative to n-ary forest reranking.2 Asynchronous BinarizationTwo-stage decoding consists of parsing and lan-guage model integration.
The parsing stage buildsa pruned forest of derivations scored by the trans-lation grammar only.
In the second stage, this for-est is reranked by an n-gram language model.
Wererank derivations with cube growing, a lazy beamsearch algorithm (Huang and Chiang, 2007).In this paper, we focus on syntactic translationwith tree-transducer rules (Galley et al, 2006).These synchronous rules allow multiple adjacentnon-terminals and place no restrictions on rule sizeor lexicalization.
Two example unlexicalized rulesappear in Figure 1, along with aligned and parsedtraining sentences that would have licensed them.2.1 Constructing Translation ForestsThe parsing stage builds a forest of derivations byparsing with the source-side projection of the syn-chronous grammar.
Each forest node Pijcom-pactly encodes all parse derivations rooted bygrammar symbol P and spanning the source sen-tence from positions i to j.
Each derivation of Pijis rooted by a rule with non-terminals that each141?PRP1NN2VBD3PP4PRP1VBD3PP4NN2S ?yo    ayer    com?
en casaI       ate     at home   yesterdayPRP  VBD       PP           NNS(a)(b)PRP1NN2VBD3PP4PRP1VBD3PP4NN2S ?yo    ayer    com?
en casaI       ate     at home   yesterdayPRP  VBD       PP           NNSyo    ayer    com?
en casaI       ate   yesterday   at homePRP  VBD       NN           PPSPRP1NN2VBD3PP4PRP1VBD3NN2PP4S ?Figure 1: Two unlexicalized transducer rules (top) andaligned, parsed training sentences from which they could beextracted (bottom).
The internal structure of English parseshas been omitted, as it is irrelevant to our decoding problem.anchor to some child nodeC(t)k`, where the symbolC(t)is the tth child in the source side of the rule,and i ?
k < ` ?
j.We build this forest with a CKY-style algorithm.For each span (i, j) from small to large, and eachsymbol P , we iterate over all ways of building anode Pij, first considering all grammar rules withparent symbol P and then, for each rule, consider-ing all ways of anchoring its non-terminals to ex-isting forest nodes.
Because we do not incorporatea language model in this stage, we need only oper-ate over the source-side projection of the grammar.Of course, the number of possible anchoringsfor a rule is exponential in the number of non-terminals it contains.
The purpose of binarizationduring the parsing pass is to make this exponentialalgorithm polynomial by reducing rule branchingto at most two non-terminals.
Binarization reducesalgorithmic complexity by eliminating redundantwork: the shared substructures of n-ary rules arescored only once, cached, and reused.
Caching isalso commonplace in Early-style parsers that im-plicitly binarize when applying n-ary rules.While any binarization of the source side willgive a cubic-time algorithm, the particulars of agrammar transformation can affect parsing speedsubstantially.
For instance, DeNero et al (2009)describe normal forms particularly suited to trans-ducer grammars, demonstrating that well-chosenbinarizations admit cubic-time parsing algorithmswhile introducing very few intermediate grammarsymbols.
Binarization choice can also improvemonolingual parsing efficiency (Song et al, 2008).The parsing stage of our decoder proceedsby first converting the source-side projection ofthe translation grammar into lexical normal form(DeNero et al, 2009), which allows each rule tobe applied to any span in linear time, then build-ing a binary-branching translation forest, as shownin Figure 2(a).
The intermediate nodes introducedduring this transformation do not have a target-side projection or interpretation.
They only existfor the sake of source-side parsing efficiency.2.2 Collapsing BinarizationTo facilitate a change in binarization, we transformthe translation forest into n-ary form.
In the n-aryforest, each hyperedge corresponds to an originalgrammar rule, and all nodes correspond to originalgrammar symbols, rather than those introducedduring binarizaiton.
Transforming the entire for-est to n-ary form is intractable, however, becausethe number of hyperedges would be exponential inn.
Instead, we include only the top k n-ary back-traces for each forest node.
These backtraces canbe enumerated efficiently from the binary forest.Figure 2(b) illustrates the result.For efficiency, we follow DeNero et al (2009)in pruning low-scoring nodes in the n-ary for-est under the weighted translation grammar.
Weuse a max-marginal threshold to prune unlikelynodes, which can be computed through a max-sum semiring variant of inside-outside (Goodman,1996; Petrov and Klein, 2007).Forest reranking with a language model can beperformed over this n-ary forest using the cubegrowing algorithm of Huang and Chiang (2007).Cube growing lazily builds k-best lists of deriva-tions at each node in the forest by filling a node-specific priority queue upon request from the par-ent.
N -ary forest reranking serves as our baseline.2.3 Reranking with Target-Side BinarizationZhang et al (2006) demonstrate that rerankingover binarized derivations improves search accu-racy by better exploring the space of translationswithin the strict confines of beam search.
Binariz-ing the forest during reranking permits pairs of ad-jacent non-terminals in the target-side projectionof rules to be rescored at intermediate forest nodes.This target-side binarization can be performed on-the-fly: when a node Pijis queried for its k-bestlist, we binarize its n-ary backtraces.Suppose Pijcan be constructed from a rule rwith target-side projectionP ?
`0C1`1C2`2.
.
.
Cn`nwhere C1, .
.
.
, Cnare non-terminal symbols thatare each anchored to a nodeC(i)klin the forest, and`iare (possibly empty) sequences of lexical items.142yo ayer com?
en casaSPRP+NN+VBDPRP+NNPRP NN VBD PPyo ayer com?
en casaSPRP NN VBD PPyo ayer com?
en casaSPRP NN VBD PPPRP+VBD+NNPRP+VBD?I ate?
[[PRP1NN2]VBD3]  PP4PRP1VBD3NN2PP4S ?PRP1NN2VBD3PP4PRP1VBD3NN2PP4S ?PRP1NN2VBD3PP4[[PRP1VBD3]    NN2]  PP4S ?
[[PRP1NN2]VBD3]  PP4PRP1VBD3PP4NN2S ?PRP1NN2VBD3PP4PRP1VBD3PP4NN2S ?PRP1NN2VBD3PP4[[PRP1VBD3]    PP4]  NN2S ?
(a) Parsing stage binarization (b) Collapsed n-ary forest (c) Reranking stage binarizationPRP+VBD+PPFigure 2: A translation forest as it evolves during two-stage decoding, along with two n-ary rules in the forest that are rebi-narized.
(a) A source-binarized forest constructed while parsing the source sentence with the translation grammar.
(b) A flatn-ary forest constructed by collapsing out the source-side binarization.
(c) A target-binarized forest containing two derivationsof the root symbol?the second is dashed for clarity.
Both derivations share the node PRP+VBD, which will contain a singlek-best list of translations during language model reranking.
One such translation of PRP+VBD is shown: ?I ate?.We apply a simple left-branching binarization tor, though in principle any binarization is possible.We construct a new symbol B and two new rules:r1: B ?
`0C1`1C2`2r2: P ?
B C3`3.
.
.
Cn`nThese rules are also anchored to forest nodes.
AnyCiremains anchored to the same node as it was inthe n-ary forest.
For the new symbol B, we intro-duce a new forest nodeB that does not correspondto any particular span of the source sentence.
Welikewise transform the resulting r2until all ruleshave at most two non-terminal items.
The originalrule r from the n-ary forest is replaced by binaryrules.
Figure 2(c) illustrates the rebinarized forest.Language model reranking treats the newly in-troduced forest nodeB as any other node: buildinga k-best derivation list by combining derivationsfrom C(1)and C(2)using rule r1.
These deriva-tions are made available to the parent of B, whichmay be another introduced node (if more binariza-tion were required) or the original root Pij.Crucially, the ordering of non-terminals in thesource-side projection of r does not play a rolein this binarization process.
The intermediatenodes B may comprise translations of discontigu-ous parts of the source sentence, as long as thoseparts are contained within the span (i, j).2.4 Reusing Intermediate NodesThe binarization we describe transforms the for-est on a rule-by-rule basis.
We must consider in-dividual rules because they may contain differentlexical items and non-terminal orderings.
How-ever, two different rules that can build a node oftenshare some substructures.
For instance, the tworules in Figure 2 both begin with PRP followed byVBD.
In addition, these symbols are anchored tothe same source-side spans.
Thus, binarizing bothrules yields the same intermediate forest node B.In the case where two intermediate nodes sharethe same intermediate rule anchored to the sameforest nodes, they can be shared.
That is, we needonly generate one k-best list of derivations, thenuse it in derivations rooted by both rules.
Sharingderivation lists in this way provides an additionaladvantage of binarization over n-ary forest rerank-ing.
Not only do we assess language model penal-ties over smaller partial derivations, but repeatedlanguage model evaluations are cached and reusedacross rules with common substructure.3 ExperimentsThe utility of binarization for parsing is wellknown, and plays an important role in the effi-ciency of the parsing stage of decoding (DeNero etal., 2009).
The benefit of binarization for language143Forest Reranked BLEU Model ScoreN -ary baseline 58.2 41,543Left-branching binary 58.5 41,556Table 1: Reranking a binarized forest improves BLEU by 0.3and model score by 13 relative to an n-ary forest baseline byreducing search errors during forest rescoring.model reranking has also been established, bothfor synchronous binarization (Zhang et al, 2006)and for target-only binarization (Huang, 2007).
Inour experiment, we evaluate the benefit of target-side forest re-binarization in the two-stage decoderof DeNero et al (2009), relative to reranking n-aryforests directly.We translated 300 NIST 2005 Arabic sentencesto English with a large grammar learned from a220 million word bitext, using rules with up to 6non-terminals.
We used a trigram language modeltrained on the English side of this bitext.
Modelparameters were tuned withMERT.
Beam size waslimited to 200 derivations per forest node.Table 1 shows a modest increase in modeland BLEU score from left-branching binarizationduring language model reranking.
We used thesame pruned n-ary forest from an identical parsingstage in both conditions.
Binarization did increasereranking time by 25% because more k-best listsare constructed.
However, reusing intermediateedges during reranking binarization reduced bina-rized reranking time by 37%.
We found that onaverage, intermediate nodes introduced in the for-est are used in 4.5 different rules, which accountsfor the speed increase.4 DiscussionAsynchronous binarization in two-stage decodingallows us to select an appropriate grammar trans-formation for each language.
The source trans-formation can optimize specifically for the parsingstage of translation, while the target-side binariza-tion can optimize for the reranking stage.Synchronous binarization is of course a way toget the benefits of binarizing both grammar pro-jections; it is a special case of asynchronous bi-narization.
However, synchronous binarization isconstrained by the non-terminal reordering, lim-iting the possible binarization options.
For in-stance, none of the binarization choices used inFigure 2 on either side would be possible in asynchronous binarization.
There are rules, thoughrare, that cannot be binarized synchronously at all(Wu, 1997), but can be incorporated in two-stagedecoding with asynchronous binarization.On the source side, these limited binarizationoptions may, for example, prevent a binarizationthat minimizes intermediate symbols (DeNero etal., 2009).
On the target side, the speed of for-est reranking depends upon the degree of reuseof intermediate k-best lists, which in turn dependsupon the manner in which the target-side grammarprojection is binarized.
Limiting options may pre-vent a binarization that allows intermediate nodesto be maximally reused.
In future work, we lookforward to evaluating the wide array of forest bi-narization strategies that are enabled by our asyn-chronous approach.ReferencesJohn DeNero, Mohit Bansal, Adam Pauls, and Dan Klein.2009.
Efficient parsing for transducer grammars.
In Pro-ceedings of the Annual Conference of the North AmericanAssociation for Computational Linguistics.Michel Galley, Jonathan Graehl, Kevin Knight, DanielMarcu, Steve DeNeefe, Wei Wang, and Ignacio Thayer.2006.
Scalable inference and training of context-rich syn-tactic translation models.
In Proceedings of the AnnualConference of the Association for Computational Linguis-tics.Joshua Goodman.
1996.
Parsing algorithms and metrics.
InProceedings of the Annual Meeting of the Association forComputational Linguistics.Liang Huang and David Chiang.
2007.
Forest rescoring:Faster decoding with integrated language models.
In Pro-ceedings of the Annual Conference of the Association forComputational Linguistics.Liang Huang, Hao Zhang, Daniel Gildea, and Kevin Knight.2008.
Binarization of synchronous context-free gram-mars.
Computational Linguistics.Liang Huang.
2007.
Binarization, synchronous binarization,and target-side binarization.
In Proceedings of the HLT-NAACL Workshop on Syntax and Structure in StatisticalTranslation (SSST).Slav Petrov and Dan Klein.
2007.
Improved inference for un-lexicalized parsing.
In Proceedings of the North AmericanChapter of the Association for Computational Linguistics.Xinying Song, Shilin Ding, and Chin-Yew Lin.
2008.
Betterbinarization for the CKY parsing.
In Proceedings of theConference on Empirical Methods in Natural LanguageProcessing.Dekai Wu.
1997.
Stochastic inversion transduction gram-mars and bilingual parsing of parallel corpora.
Computa-tional Linguistics, 23:377?404.Hao Zhang, Liang Huang, Daniel Gildea, and Kevin Knight.2006.
Synchronous binarization for machine translation.In Proceedings of the North American Chapter of the As-sociation for Computational Linguistics.144
