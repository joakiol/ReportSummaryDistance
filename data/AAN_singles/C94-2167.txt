A METHODOLOGY FOR AUTOMATIC  TERM RECOGNIT IONSoph ia  Anan ladouDepartment of Computing~ Manchester Metropolitan UniversityJohn Dalton Building, Chester Street, Manchester, UK, M1 5GD1 INTRODUCTIONThe topic of automatic term recognition (ATR)is of great interest especially with the growth ofNLP systems, which are passing from the develop-ment stage to the application stage.
The applicationof NLP technology involves customlsing systems to-wards specific needs, particularly in specialised o-mains (sublanguages) which form the main target ofthe technology~ There is thus an urgent need for highquality, large scale collections of terminologies (withassociated linguistic information) for use in NLP sys-tem dictionaries.The existence of coherently built terminologiesleads to better performance for many interestingapplications: translation, technical writing (in themother tongue or in a foreign language), multilin-gual (multimedial) document production, classify-ing, indexing, archiving and retrieving docmnents(monolingual and multilingual), extracting, reorga-nizing and reformulating knowledge represented intextual form (Iteid,U.
and McNaught 1991).Given the amount of specialised texts that needto be processed in efforts to discover (potential)terms, keep track of the life-cycle of terms, etc., it isof interest o consider the design of (semi)automaticaids.
A term recognition tool would be a great aid tospecial exicographers.
It is only an aid~ however, ifit incorporates linguistic and terminological knowl-edge such that it makes largely accurate proposals.It is with the design of such a tool that we have beenparticularly concerned and we report below on var-ious aspects with which we have had success.
Wedo not claim to have solved the term recognitionproblem.
As we shall see, there are many differentkinds of term formations each of which calls for dif-ferent techniques and different knowledge: our workhas concentrated on a subset of these.2 TERMSThe main characteristic of terms is that theyare monoreferential to a very great degree: a termtypically refers to a specific concept in a partic-ular subject field.
Subject field knowledge is con-veyed via naturally occurring sublanguages whichdemonstrate r strictions on the lexical, syntactic andsemantic levels.
Each sublanguage has its own setof concepts and a terminologist will structure theseinto a system organised according to relationshipsholding between concepts (generic, partitive, causal,etc.).
Terms are therefore the linguistic realisation ofthe concepts of special communication and are or-ganised into systems of terms which ideally reflectthe associated conceptual system.Terms differ from general language words primar-ily by their nature of reference.
Nevertheless, it is notalways an easy task to divide terms from words.
Theterminologist is often faced with cases where syn-onymy, homonymy or polysemy could be said to beplaying a role.
Also, the same wordform can refer todifferent concepts in different sublanguages, and beused differently in general language.In elaborating a terminology, we typically em-ploy texts and a set of tools (e.g.
KWIC, inverseKWIC, etc.)
which will facilitate the tasks of iden-tifying which words, phrases, acronyms, etc., of thecorpus are functioning as terms with respect o theconceptual system of the subject field and of relatingthem appropriately via relationships and definitions.One important aspect in terminology is the creationof new terms (term formation) in response to a newconcept - this may be by, say, an engineer (monolin-gually) or a translator (where a target equivalent ismissing).Term formation follows certain guidelines (pro-cedures) which vary in sophistication depending onthe subject domain.
Some domains how evidence ofmandatory adherence to strict term formation.
Oth-ers may permit wide choice within recognized limits.We view term formation in our research from an an-alytical viewpoint, i.e.
we investigate the linguisticform of known terms in order to identify productivemeans of forming terms, which is necessary in orderto be able to recognize new terms~3 A METHODOLOGY FOR AUTO-MATIC  TERM RECOGNIT IONWe investigated the relevance of other disciplinesto automatic term recognition, such as InformationScience - especially techniques of automatic index-ing.
We concluded that non-linguistic based tech-niques (statistical nd probability based ones), while~034providing gross means of characterizing texts andmeasuring the beilaviour and content-bearing poten-tial of words, are not refined enough for our purposes.In Terminology we are interested as much in word-forms occurring with high frequency as in rare onesor those of the middle frequencies.
We are interestedin all units that may be acting as terms in a col-lection of texts.
IIowever, we do not deny the useflllrole of such techniques.
They have their place in thatthey may usefully complement o her techniques.We chose to concentrate on potential contribu-tions of Linguistics, especially from lexical morphol-ogy, and were interested in developing methodologiesfor term recognition that apply theoretically moti-vated ideas about term formation.
Theoretical Lin-guistics deals exclusively with general language wordstructure.
We designed an integrated model of wordand term structure based on the results of an analysisof Immunology terms in the sublanguage of Medicine(for English) and on models to he found in the liter-ature on general language (Se\]kirk, 1982; Mohanan,1986).Medical terminology relies heavily on Greek(mainly) and Latin neoclassical elements for the cre-ation of terms such as 'erythroeyte' and 'angioneu-rotie'.
In the literature of theoretical Linguisticsthere are no satisfactory accounts of the neoclassicalvocabulary and no formal motivated classification ofneoclassical wordforms exists.
In Terminology, mostaccounts of term structure remain at an unformaliseddescriptive level and this is particularly true for dis-cussions of neoclassical vocabularies.The reason for this overall ack of formal descrip-tion of neoclassical elements appears to be due totheir occupying a peripheral or ambiguous place inmost analyses of word and term formation in En-glish.
We found this to be unsatisfactory for the fol-lowing reason: it is anomalous to conceive of Englishword formation as being somehow separated fromterm formation, especially as terms constitute themajority of English words.
Therefore, we strove toset up an integrated model of word and term struc-ture which would, importantly, account adequatelyfor the neoclassical component.The word structure of English can be said to com-prise 3 category types, i.e.
Word, Root and Affix(Selkirk, 1982) 1However, there is great confusion in the literatureas to the morphological status of Greek and Latinneoclassical forms, i.e.
whether they are roots, af-fixes or even both.
Models which describe them asaffixes allow the generation of forms such as *af-ffx+a{fix.
Many models, including the unformalisedones of conventional dictionaries, charaeterise neo-classical elements vaguely as 'combining elements',1Selkirk is cited here only as a reference point:  we shal ldevelop our own model  as shall  be seen.which suggests ome kind of extra-morphologicM sta-tus (or wastebasket s atus).
Such forms thus appar-ently defy attempts to provide an integrated accountin terms of the accepted morphological categories.In our approach, we introduced a fourth categorytype comb, to help handle the neoclassical word-stock of English.
This does not, in itself, resolvethe problem of how to (sub)classify neoclassical el-ements: we will address this aspect below in detail.Firstly, though, we discuss our concomitant adop-tion of a level ordered approach to the morphologicalanalysis of English words and terms.Level ordering places strong constraints on thecooccurrence ororder of classes of affix and hence is apowerful mechanism in helping to identify whether awordform is well-formed or not, whether a wordformmay be segmented in a particular way or not, etc.Numerous models incorporating level ordering havebeen proposed in morphology and morphophonology.There is debate on how many levels should be iden-tiffed and what the relationships between levels are.Level ordering has its critics also.
We do not enterinto these debates here, however we have found, inexperiments over the years, that level ordering is ofgreat use in a computational morphology environ-ment, as has been recently also suggested by (Sproat,1992) who, like us, has also found that there is a gainin grouping rules according to Level.There is nevertheless broad agreement that, inEnglish, Level 1 and Level 2 are affixational levelsdealing with latinate morphology (Class I affixation)and native morphology (Class II affixation), respec-tively.
Level 1 feeds Level 2, therefore native affixa-tion must he attached outside latinate morphology.There is less agreement about the relationship be-tween Class II affixation and native compoundingand whether one needs to identify a separate na-tive compounding level.
For various reasons we donot have space to go into here, we choose to recog-nize a distinct native compounding Level 3.
More-over, we importantly recognize a Level 0, which isreserved for non-native (i.e.
neoclassical) compound-ing.
In other words, compounding purely involvingneoclassical elements must be completed before af-fixation takes place.Thus, the four distinct levels of our model are:1.
Non-native compounding (neoclassical com-pounding)2.
Class I affixation3.
Class II affixation4.
Native compoundingEach level has two characteristics: it is cyclic andoptional.
Cyclicity accounts for recursive structures,i.e.
we might find forms such as the following:1035prefix-II + word + suffix-I + sufflx-I ~'where Level 1 rules apply twice before Level 2 ones.To apply our model, we used the Edinburgh Cam-bridge Morphological Analyser and Dictionary Sys-tem (Ritchie, et al 1992), a component of the lgatu-ral Language Toolkit developed for the UK Alvey ITProgramme.
This offers a Koskeniemmi-type anal-yser (here restricted to handling morphographemicpt,enomena) and a general purpose unification basedanalyser which allows the morphologist to expressher knowledge via feature bundles of attribute-valuepairs in a context-flee grammar framework.Our model is instantiated in our computationalwordform grammar as follows.
The analysis trategyused by the wordform grammar parser is that of abottom up chart parser.
Each rule in our grammaris marked for level or levels.
Lexical entries are alsomarked for level.
Thus, a Class I suffix like 'ous' asin 'glorious' is marked for Level 1.
Monomorphemicnon-affix native lexical entries are also marked bydefault for Level 1.
Thus, if we have the wordform'glorious', then, in a computational environment,string segmentation, morphographemic rule applica-tion and dictionary look-up will yield:glory((cat noun)(level l.)) andous ((cat suffix)(leve\] 1))These two representations are added to the datastructure (a chart).
Rules with Level 1 as their do-main may now apply, as the basic condition for theiractivation is present in the chart.
They will matchwith these representations and yield:glory + ous ((cat adjective)(level 1))which is still a Level 1 object.
This is added to thechart and no further rules apply.
This representa-tion may now be generated as a word of English.
AsLevels are optional, in this case the rules associatedwith higher Levels do not apply.
If we take an nn-derived monomorphemie native wordform, this canbe seen conceptually as passing through Levels 1-3,with vacuous rule application.
All such wordformsare marked as Level 1 in the dictionary, thus will notbe considered, as is correct, by Level 0 rules.
Thefact that an object is marked for some Level doesnot block it at that Level: it merely indicates thatthis is the first Level at which rules may apply -recall that we do not know, in bottom-up analysis,wbetber e.g.
we are dealing with an underived form,until we have finished the analysis, thus we must al-low for underived forms to potentially combine withaffixes or participate in compounding.Besides the use of four levels in our morpholog-ical analysis, we additionally introduced a diacriticfeature which explicitly marks degrees of boundnessfor neoclassical roots.
Analysis of a corpus of Im-munology texts, by various (semi-)automatic meth-ods, produced classifications of neoclassical elements2I~ II correspond to Class I afflxation and Class II affixa-tion, respectively.into roots and affixes.
Neoclassical roots make upour new category comb and display three degrees ofboundness: totally free (e.g.
cyst), partially bound(e.g.
myel- or -myel) and totally bound (e.g.
ten) a,Totally bound forms cannot appear on their own andcannot appear in compound final root position with-out being suffixed.
Partially bound forms cannot ap-pear on their own, but can stand in compound finalroot position without suffixation.
Totally free formscan appear in any position, suffixed or not, and canstand on their own.
All neoclassical roots are markedin the dictionary with level information level  0 anda value for the boundness feature 4.
Those neoclassi-cal elements that we have classed as affixes are dealtwith largely at Level 1~In addition to level ordering and boundness in-formation, other characteristics of our implementa-tion are the use of morphosyntactic head, featurevalue percolation and rela~ivised head (Di Sciullo andWilliams, 1987).
The important issue for us was todetermine whether a wordform is a general anguageword or a potential tenn.
In our system, we demon-strafed how this could be achieved for affixed forms,neoclassical compounds and certain types of nativecompound.
We labelled certain suffixes as typicallyterm forming suffixes on the basis of a sublanguagecorpus analysis, attaching the feature value (word-type  te rm)  to their dictionary entry (each affix hasits own lexical entry).
We can then ensure that a suf-fix with this feature percolates its value to the mothernode.
We used only two wordtype values in our sys-tem: te rm and word.
Besides employing the notionsof head and perco la t ion  from Lexicalist Morphol-ogy, we also used the notion of re la t iv i zed  head.This refinement of the notion of head helped us per-colate the relevant information in cases where themorpheme bearing tbe label (wordtype  te rm)  wasnot in syntactic head position according to the Right-band Itead Rule.Our wordfonn grammar rules generate the fol-lowing word and term forms involving sufllxation(note: prefixation is similar to suffixation thus is notshown): term -4 word + term_suffixterm --~ term-{- term_suffixword -4 word -{- word suffixterm .-* term -{- word_suffix,Compounding operates in a similar fashion:term -~ term + wordterm -+ term -I- termterm --~ word -F termword -~ word -F word.Our use of a unification based word grammar3 We could have worked with three types of comb, howeverwe prefer our current solution as it appears more flexible andexpressive tous.4We only use two wlues for bound, however bonndness iinterpreted by a combination of bound and level values togive us our 3-way distinction.1036then allowed features associated with known termi-nological elements to be attached to overall word-forms, thus characterising them as potential termsfor later assessment by the terminologist.
The no-tion of ~erminoIogical head of a wordform is impor-tant in this respect: this refers to the element of acomplex wordform which confers term-hood on thewhole wordform, which may not be the same as themorphosyntactic head.As yet, we are only capable of determining termi-nological status for an mlknown word, or wordformcontaining an unknown morpheme, if it contains aknown terminological e ement (revealed by prior co lpus analysis and coded appropriately in tile dictio-nary).
For known morphemes there is no problem.By using notions of Level Ordering, we can fltrther-more impose strong constraints on the form a word(or term) may take.
Thus, we can filter and rejectas nonwords or nonterms wordforms where all anal-ysis without Level Ordering might postulate a validwordfonn of English.We provide an anMysis of a potential term in thefollowing.Pmal represen-tationleukaemiaanalysis: 1(((bound-) compound-) (level 1) (wordtype term)(category noun))\]" This is the final representation which postulatesthat the word 'leukaemia' is a noun, term, Level 1,non compound lexical unit.L0-to-M-by-n-.or-a(b-suffixingT rule name(((compound-) (wordtype term) (bound -) (level 0)(category comb))representation of lexical entry a dataENTRY(leuk ((category conrb) (level O) (bound -) (wor&ypeterm) (compound-)) )1 lexical entry a(((wordtype term) (hound-) (tie q-) (level l) (makesnoun) (suffixes comb) (category suffix))I representation of lexical entry b dataENTRY(q aemia ((category suillx) (suffixes (noun verb ad-jective adverb comb))(t ie I) (bo,md-)  (level 1)(wordtype term) (makes noun)) )))\[ lexieal entry bRelevant rule(L0-to-Ll.-by-n-or-adj-suffixing((category monn-or-adj) (wordtype term) (level 1)(compound-) (bound 4)q"((category n-v-adj-~dv-comh)(lovel O)(bound '9),((category .~umx)(sumxes _n-v-adj-adv-comb)(makesnonn-or-adj) (level l)))We have simplified tl, is example somewhat \~rexposition: in tile EdCam system, a dictionary end.try contains fields other than the two shown here(the orthographic form followed by associated mor-phosyntactic information).
Underline denotes a fea-ture variahle, whose name indicates the set of possi-ble values taken by the feature.
All Level 0 object, s1,ave terminological status in our corpus thus we maysafely mark wordtype directly on the mother.
Thefeature suffixes is used as a subcategorisation framewhose value must unify with that of the affixed ob-ject.
The feature makes indicates what category theaffix turns the object it attaches to into.
Tlm valueof this feature is the one that is percolated, via uniGcation of variable values, to the mother node, to giveit its category specification.
Subcategorisation a dmakes information is stored in the morphosyntaxtleld of an afflx's lexical entry.
Our suffixing rulesare basicMly all of this form with variants to takecare of suffixation at different Levels.
There are sev-eral rules that take care of mapping between Levels 0and I as in the above example.
With prefixes, whichare typically not category changing, we have a three-way unification.
The use of the eompomM featureis used at two levels, the neoclassical level and thenative level.
Compounds are assigned one syntacticparse only, a left branching one, to avoid problemswith overgeneration ~A top-level filter takes care of allowing only word~forms that are potential terms to be passed out as re-suits: ((category _any-cat)(bound-) (level _1-2-o>3)(wordtype term)).
Note that no Level 0 objects canhe so output a.nd that each object must be unbound,have a major lexical category (not suffix, pref ix orcomb) and t)e of wordtype term.4 CONCLUI ) ING REMARKSWe }lave implemented a computational morpho-logical grammar and lexicon that instanl;iates tileabovementioned 4 level ordered morphology of En-glish cal)at31e of handling both neoclassica.1 con>pmmding and other complex and simple wordformsm a theoreticMly s~tisfactory manner, and fllrther-more demonstrating that application of theoreticMlymotivated lingnistic knowledge nhances term recog-nition.
The identification of this new level is an orig-inM contribution to morphological theory and, forthe first time, allows neoclassical elements to be in-tegrated in a theoretically satisfactory and elegantway in a model of term and word structure.Term formation is only one of tile factors involvedin term recognition.
Our research has focussed on'~It should he noticed that (compound t)  is serving twopurposes in this analysis: a) as a strategic value I:o preventmultiple syntactic analyses of a compound and b) to mark anobject, as a compounded form.
Several features of our grammarare inspired by the simple grammar provided with the EdCamsystem, however we llave substantially altered and added toghi-~ featnreset and ruleset.1037morphosyntactie aspects of term formation insofaras these appear to be more tractable than others,which we have also identified in the course of ourresearch.Our work has focussed recently on the develop-ment of tools for sublanguage linguistic analysis toaid the process of word classification: e.g.
to effectinversion of KWIC indexes and to apply techniquesof gradual approximation to discover semantic ollo-cations between words (Sekine et.al, 1992a, 1992b).Future work will further investigate the appli-cation of such tools to automatic term recognitionand will examine how techniques and research re-sults from the various fields given above in section3 can be applied to other aspects of term formationand thus term recognition.5 REFERENCESDi Sciullo, A.M.,and Williams, E.(1987).
On the Def-inition of Word.
Linguistic Inquiry Monograph 14,The MIT Press, Cambridge, Ma.Heid, U., and McNaught, J.
(1991).
EUROTRA-7Study: Feasibility and Project Definition Study onthe Reusability of Lexical and Terminological Re-sources in Computerised Applications.
Final Report.Submitted to DGXIII-B, CEC, Luxembourg.Mohanan, K.P., (1986).
The Theory of LexicalPhonology.
Reidel, Dordrecht.Ritchie, G.D., Russell, G.J., Black, A.W.
and Pul-man, S.G. (1992).
Computational Morphology.
TheMIT Press, Cambridge, Ma.Sekine, S., Carroll, J.J., Ananiadou, S., and Tsujii,J.
(1992a) Automatic Learning for Semantic Collo-cation.
Proceedings of Third Conference on AppliedNLP, Trento, Italy, pp.
104-110.Sekine S., Ananiadou, S., Carroll, J.J. and Tsujii, J.(1992b).
Linguistic Knowledge Generator.
Proceed-ings of lSth Coling, vol.If, pp.560-566.Selkirk, E., (1982).
The Syntax of Words.
LinguisticInquiry Monograph 7, MIT Press.
Ca.
Mass.Sproat, R., (1992).
Morphology and Computation.The MIT Press, Cambridge, Ma.1038
