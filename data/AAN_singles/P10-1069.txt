Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 671?677,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsTemporal information processing of a new language:fast porting with minimal resourcesFrancisco Costa and Anto?nio BrancoUniversidade de LisboaAbstractWe describe the semi-automatic adapta-tion of a TimeML annotated corpus fromEnglish to Portuguese, a language forwhich TimeML annotated data was notavailable yet.
In order to validate thisadaptation, we use the obtained data toreplicate some results in the literature thatused the original English data.
The factthat comparable results are obtained indi-cates that our approach can be used suc-cessfully to rapidly create semantically an-notated resources for new languages.1 IntroductionTemporal information processing is a topic of nat-ural language processing boosted by recent eval-uation campaigns like TERN2004,1 TempEval-1(Verhagen et al, 2007) and the forthcomingTempEval-22 (Pustejovsky and Verhagen, 2009).For instance, in the TempEval-1 competition, threetasks were proposed: a) identifying the temporalrelation (such as overlap, before or after) hold-ing between events and temporal entities such asdates, times and temporal durations denoted by ex-pressions (i.e.
temporal expressions) occurring inthe same sentence; b) identifying the temporal re-lation holding between events expressed in a doc-ument and its creation time; c) identifying the tem-poral relation between the main events expressedby two adjacent sentences.Supervised machine learning approaches arepervasive in the tasks of temporal information pro-cessing.
Even when the best performing sys-tems in these competitions are symbolic, there aremachine learning solutions with results close totheir performance.
In TempEval-1, where therewere statistical and rule-based systems, almost1http://timex2.mitre.org2http://www.timeml.org/tempeval2all systems achieved quite similar results.
In theTERN2004 competition (aimed at identifying andnormalizing temporal expressions), a symbolicsystem performed best, but since then machinelearning solutions, such as (Ahn et al, 2007), haveappeared that obtain similar results.These evaluations made available sets of anno-tated data for English and other languages, usedfor training and evaluation.
One natural questionto ask is whether it is feasible to adapt the trainingand test data made available in these competitionsto other languages, for which no such data still ex-ist.
Since the annotations are largely of a seman-tic nature, not many changes need to be done inthe annotations once the textual material is trans-lated.
In essence, this would be a fast way to createtemporal information processing systems for lan-guages for which there are no annotated data yet.In this paper, we report on an experimentthat consisted in adapting the English data ofTempEval-1 to Portuguese.
The results of ma-chine learning algorithms over the data thus ob-tained are compared to those reported for the En-glish TempEval-1 competition.
Since the resultsare quite similar, this permits to conclude thatsuch an approach can rapidly generate relevant andcomparable data and is useful when porting tem-poral information processing solutions to new lan-guages.The advantages of adapting an existing corpusinstead of annotating text from scratch are: i)potentially less time consuming, if it is faster totranslate the original text than it is to annotatenew text (this can be the case if the annotationsare semantic and complex); b) the annotations canbe transposed without substantial modifications,which is the case if they are semantic in nature;c) less man power required: text annotation re-quires multiple annotators in order to guaranteethe quality of the annotation tags, translation ofthe markables and transposition of the annotations671in principle do not; d) the data obtained are com-parable to the original data in all respects exceptfor language: genre, domain, size, style, annota-tion decisions, etc., which allows for research tobe conducted with a derived corpus that is compa-rable to research using the original corpus.
Thereis of course the caveat that the adaptation processcan introduce errors.This paper proceeds as follows.
In Section 2,we provide a quick overview of the TimeML an-notations in the TempEval-1 data.
In Section 3,it is described how the data were adapted to Por-tuguese.
Section 4 contains a brief quantitativecomparison of the two corpora.
In Section 5, theresults of replicating one of the approaches presentin the TempEval-1 challenge with the Portuguesedata are presented.
We conclude this paper in Sec-tion 6.2 Brief Description of the AnnotationsFigure 1 contains an example of a document fromthe TempEval-1 corpus, which is similar to theTimeBank corpus (Pustejovsky et al, 2003).In this corpus, event terms are tagged with<EVENT>.
The relevant attributes are tense,aspect, class, polarity, pos, stem.
Thestem is the term?s lemma, and pos is its part-of-speech.
Grammatical tense and aspect are encodedin the features tense and aspect.
The attributepolarity takes the value NEG if the event termis in a negative syntactic context, and POS other-wise.
The attribute class contains several lev-els of information.
It makes a distinction betweenterms that denote actions of speaking, which takethe value REPORTING and those that do not.For these, it distinguishes between states (valueSTATE) and non-states (value OCCURRENCE),and it also encodes whether they create an in-tensional context (value I STATE for states andvalue I ACTION for non-states).Temporal expressions (timexes) are inside<TIMEX3> elements.
The most important fea-tures for these elements are value, type andmod.
The timex?s value encodes a normal-ized representation of this temporal entity, itstype can be e.g.
DATE, TIME or DURATION.The mod attribute is optional.
It is used for ex-pressions like early this year, which are anno-tated with mod="START".
As can be seen inFigure 1 there are other attributes for timexesthat encode whether it is the document?s creationtime (functionInDocument) and whether itsvalue can be determined from the expressionalone or requires other sources of information(temporalFunction and anchorTimeID).The <TLINK> elements encode temporal re-lations.
The attribute relType represents thetype of relation, the feature eventID is a ref-erence to the first argument of the relation.The second argument is given by the attributerelatedToTime (if it is a time interval or du-ration) or relatedToEvent (if it is anotherevent; this is for task C).
The task feature is thename of the TempEval-1 task to which this tempo-ral relation pertains.3 Data AdaptationWe cleaned all TimeML markup in theTempEval-1 data and the result was fed tothe Google Translator Toolkit.3 This tool com-bines machine translation with a translationmemory.
A human translator corrected theproposed translations manually.After that, we had the three collections of docu-ments (the TimeML data, the English unannotateddata and the Portuguese unannotated data) alignedby paragraphs (we just kept the line breaks fromthe original collection in the other collections).
Inthis way, for each paragraph in the Portuguese datawe know all the corresponding TimeML tags inthe original English paragraph.We tried using machine translation software (weused GIZA++ (Och and Ney, 2003)) to performword alignment on the unannotated texts, whichwould have enabled us to transpose the TimeMLannotations automatically.
However, word align-ment algorithms have suboptimal accuracy, so theresults would have to be checked manually.
There-fore we abandoned this idea, and instead we sim-ply placed the different TimeML markup in thecorrect positions manually.
This is possible sincethe TempEval-1 corpus is not very large.
A smallscript was developed to place all relevant TimeMLmarkup at the end of each paragraph in the Por-tuguese text, and then each tag was manually repo-sitioned.
Note that the <TLINK> elements alwaysoccur at the end of each document, each in a sep-arate line: therefore they do not need to be reposi-tioned.During this manual repositioning of the anno-tations, some attributes were also changed man-3http://translate.google.com/toolkit672<?xml version="1.0" ?><TempEval>ABC<TIMEX3 tid="t52" type="DATE" value="1998-01-14" temporalFunction="false"functionInDocument="CREATION_TIME">19980114</TIMEX3>.1830.0611NEWS STORY<s>In Washington <TIMEX3 tid="t53" type="DATE" value="1998-01-14" temporalFunction="true"functionInDocument="NONE" anchorTimeID="t52">today</TIMEX3>, the Federal Aviation Administration <EVENTeid="e1" class="OCCURRENCE" stem="release" aspect="NONE" tense="PAST" polarity="POS" pos="VERB">released</EVENT> air traffic control tapes from <TIMEX3 tid="t54" type="TIME" value="1998-XX-XXTNI"temporalFunction="true" functionInDocument="NONE" anchorTimeID="t52">the night</TIMEX3> the TWA Flighteight hundred <EVENT eid="e2" class="OCCURRENCE" stem="go" aspect="NONE" tense="PAST" polarity="POS"pos="VERB">went</EVENT>down.</s>...<TLINK lid="l1" relType="BEFORE" eventID="e2" relatedToTime="t53" task="A"/><TLINK lid="l2" relType="OVERLAP" eventID="e2" relatedToTime="t54" task="A"/><TLINK lid="l4" relType="BEFORE" eventID="e2" relatedToTime="t52" task="B"/>...</TempEval>Figure 1: Extract of a document contained in the training data of the first TempEval-1ually.
In particular, the attributes stem, tenseand aspect of <EVENT> elements are languagespecific and needed to be adapted.
Sometimes, thepos attribute also needs to be changed, since e.g.a verb in English can be translated as a noun inPortuguese.
The attribute class of the same kindof elements can be different, too, because naturalsounding translations are sometimes not literal.3.1 Annotation DecisionsWhen porting the TimeML annotations from En-glish to Portuguese, a few decisions had to bemade.
For illustration purposes, Figure 2 containsthe Portuguese equivalent of the extract presentedin Figure 1.For <TIMEX3> elements, the issue is that if thetemporal expression to be annotated is a preposi-tional phrase, the preposition should not be insidethe <TIMEX3> tags according to the TimeMLspecification.
In the case of Portuguese, this raisesthe question of whether to leave contractions ofprepositions with determiners outside these tags(in the English data the preposition is outside andthe determiner is inside).4 We chose to leave themoutside, as can be seen in that Figure.
In this ex-ample the prepositional phrase from the night/danoite is annotated with the English noun phrasethe night inside the <TIMEX3> element, but thePortuguese version only contains the noun noiteinside those tags.For <EVENT> elements, some of the attributesare adapted.
The value of the attribute stem is4The fact that prepositions are placed outside of temporalexpressions seems odd at first, but this is because in the orig-inal TimeBank, from which the TempEval data were derived,they are tagged as <SIGNAL>s.
The TempEval-1 data doesnot contain <SIGNAL> elements, however.obviously different in Portuguese.
The attributesaspect and tense have a different set ofpossible values in the Portuguese data, simplybecause the morphology of the two languagesis different.
In the example in Figure 1 thevalue PPI for the attribute tense stands forprete?rito perfeito do indicativo.
We chose toinclude mood information in the tense attributebecause the different tenses of the indicative andthe subjunctive moods do not line up perfectlyas there are more tenses for the indicative thanfor the subjunctive.
For the aspect attribute,which encodes grammatical aspect, we onlyuse the values NONE and PROGRESSIVE,leaving out the values PERFECTIVE andPERFECTIVE PROGRESSIVE, as in Portuguesethere is no easy match between perfective aspectand grammatical categories.The attributes of <TIMEX3> elements carryover to the Portuguese corpus unchanged, and the<TLINK> elements are taken verbatim from theoriginal documents.4 Data DescriptionThe original English data for TempEval-1 arebased on the TimeBank data, and they are splitinto one dataset for training and development andanother dataset for evaluation.
The full data are or-ganized in 182 documents (162 documents in thetraining data and another 20 in the test data).
Eachdocument is a news report from television broad-casts or newspapers.
A large amount of the doc-uments (123 in the training set and 12 in the testdata) are taken from a 1989 issue of the Wall StreetJournal.The training data comprise 162 documents with673<?xml version="1.0" encoding="UTF-8" ?><TempEval>ABC<TIMEX3 tid="t52" type="DATE" value="1998-01-14" temporalFunction="false"functionInDocument="CREATION_TIME">19980114</TIMEX3>.1830.1611REPORTAGEM<s>Em Washington, <TIMEX3 tid="t53" type="DATE" value="1998-01-14" temporalFunction="true"functionInDocument="NONE" anchorTimeID="t52">hoje</TIMEX3>, a Federal Aviation Administration <EVENTeid="e1" class="OCCURRENCE" stem="publicar" aspect="NONE" tense="PPI" polarity="POS" pos="VERB">publicou</EVENT> gravaoes do controlo de trfego areo da <TIMEX3 tid="t54" type="TIME" value="1998-XX-XXTNI"temporalFunction="true" functionInDocument="NONE" anchorTimeID="t52">noite</TIMEX3> em que o voo TWA800<EVENT eid="e2" class="OCCURRENCE" stem="cair" aspect="NONE" tense="PPI" polarity="POS" pos="VERB">caiu</EVENT>.</s>...<TLINK lid="l1" relType="BEFORE" eventID="e2" relatedToTime="t53" task="A"/><TLINK lid="l2" relType="OVERLAP" eventID="e2" relatedToTime="t54" task="A"/><TLINK lid="l4" relType="BEFORE" eventID="e2" relatedToTime="t52" task="B"/>...</TempEval>Figure 2: Extract of a document contained in the Portuguese data2,236 sentences (i.e.
2236 <s> elements) and52,740 words.
It contains 6799 <EVENT> el-ements, 1,244 <TIMEX3> elements and 5,790<TLINK> elements.
Note that not all the eventsare included here: the ones expressed by wordsthat occur less than 20 times in TimeBank wereremoved from the TempEval-1 data.The test dataset contains 376 sentences and8,107 words.
The number of <EVENT> elementsis 1,103; there are 165 <TIMEX3>s and 758<TLINK>s.The Portuguese data of course contain the same(translated) documents.
The training dataset has2,280 sentences and 60,781 words.
The test datacontains 351 sentences and 8,920 words.5 Comparing the two DatasetsOne of the systems participating in theTempEval-1 competition, the USFD system(Hepple et al, 2007), implemented a verystraightforward solution: it simply trained classi-fiers with Weka (Witten and Frank, 2005), usingas attributes information that was readily availablein the data and did not require any extra naturallanguage processing (for all tasks, the attributerelType of <TLINK> elements is unknown andmust be discovered, but all the other informationis given).The authors?
objectives were to see ?whether a?lite?
approach of this kind could yield reasonableperformance, before pursuing possibilities that re-lied on ?deeper?
NLP analysis methods?, ?whichof the features would contribute positively to sys-tem performance?
and ?if any [machine learning]approach was better suited to the TempEval tasksthan any other?.
In spite of its simplicity, they ob-tained results quite close to the best systems.For us, the results of (Hepple et al, 2007) are in-teresting as they allow for a straightforward evalu-ation of our adaptation efforts, since the same ma-chine learning implementations can be used withthe Portuguese data, and then compared to theirresults.The differences in the data are mostly due tolanguage.
Since the languages are different, thedistribution of the values of several attributes aredifferent.
For instance, we included both tenseand mood information in the tense attribute of<EVENT>s, as mentioned in Section 3.1, so in-stead of seven possible values for this attribute, thePortuguese data contains more values, which cancause more data sparseness.
Other attributes af-fected by language differences are aspect, pos,and class, which were also possibly changedduring the adaptation process.One important difference between the Englishand the Portuguese data originates from the factthat events with a frequency lower than 20 wereremoved from the English TempEval-1 data.
Sincethere is not a 1 to 1 relation between English eventterms and Portuguese event terms, we do not havethe guarantee that all event terms in the Portuguesedata have a frequency of at least 20 occurrences inthe entire corpus.5The work of (Hepple et al, 2007) reports onboth cross-validation results for various classifiersover the training data and evaluation results on thetraining data, for the English dataset.
We we will5In fact, out of 1,649 different stems for event terms in thePortuguese training data, only 45 occur at least 20 times.674TaskAttribute A B CEVENT-aspect !
!
!EVENT-polarity !
!
?EVENT-POS !
!
!EVENT-stem !
?
?EVENT-string ?
?
?EVENT-class ?
!
!EVENT-tense ?
!
!ORDER-adjacent !
N/A N/AORDER-event-first !
N/A N/AORDER-event-between ?
N/A N/AORDER-timex-between ?
N/A N/ATIMEX3-mod !
?
N/ATIMEX3-type !
?
N/ATable 1: Features used for the English TempEval-1tasks.
N/A means the feature was not applicable tothe task,!means the feature was used by the bestperforming classifier for the task, and ?
means itwas not used by that classifier.
From (Hepple etal., 2007).be comparing their results to ours.Our purpose with this comparison is to validatethe corpus adaptation.
Similar results would notnecessarily indicate the quality of the adapted cor-pus.
After all, a word-by-word translation wouldproduce data that would yield similar results, butit would also be a very poor translation, and there-fore the resulting corpus would not be very inter-esting.
The quality of the translation is not at stakehere, since it was manually revised.
But similarresults would indicate that the obtained data arecomparable to the original data, and that they aresimilarly useful to tackle the problem for whichthe original data were collected.
This would con-firm our hypothesis that adapting an existing cor-pus can be an effective way to obtain new data fora different language.5.1 Results for EnglishThe attributes employed for English by (Hepple etal., 2007) are summarized in Table 1.
The class isthe attribute relType of <TLINK> elements.The EVENT features are taken from <EVENT>elements.
The EVENT-string attribute is thecharacter data inside the element.
The other at-tributes correspond to the feature of <EVENT>with the same name.
The TIMEX3 featuresTaskAlgorithm A B Cbaseline 49.8 62.1 42.0lazy.KStar 58.2 76.7 54.0rules.DecisionTable 53.3 79.0 52.9functions.SMO 55.1 78.1 55.5rules.JRip 50.7 78.6 53.4bayes.NaiveBayes 56.3 76.2 50.7Table 2: Performance of several machine learn-ing algorithms on the English TempEval-1 train-ing data, with cross-validation.
The best resultfor each task is in boldface.
From (Hepple et al,2007).also correspond to attributes of the relevant<TIMEX3> element.
The ORDER features areboolean and computed as follows:?
ORDER-event-first is whether the<EVENT> element occurs in the text beforethe <TIMEX3> element;?
ORDER-event-between is whether an<EVENT> element occurs in the text betweenthe two temporal entities being ordered;?
ORDER-timex-between is the same, butfor temporal expressions;?
ORDER-adjacent is whether bothORDER-event-between and ORDER-timex-between are false (but othertextual data may occur between the twoentities).Cross-validation over the training data pro-duced the results in Table 2.
The base-line used is the majority class baseline, asgiven by Weka?s rules.ZeroR implemen-tation.
The lazy.KStar algorithm is anearest-neighbor classifier that uses an entropy-based measure to compute instance similarity.Weka?s rules.DecisionTable algorithm as-signs to an unknown instance the majority classof the training examples that have the sameattribute values as that instance that is be-ing classified.
functions.SMO is an imple-mentation of Support Vector Machines (SVM),rules.JRip is the RIPPER algorithm, andbayes.NaiveBayes is a Naive Bayes classi-fier.675TaskAlgorithm A B Cbaseline 49.8 62.1 42.0lazy.KStar 57.4 77.7 53.3rules.DecisionTable 54.2 78.1 51.6functions.SMO 55.5 79.3 56.8rules.JRip 52.1 77.6 52.1bayes.NaiveBayes 56.0 78.2 53.5trees.J48 55.6 79.0 59.3Table 3: Performance of several machine learn-ing algorithms on the Portuguese data for theTempEval-1 tasks.
The best result for each taskis in boldface.5.2 AttributesWe created a small script to convert the XML an-notated files into CSV files, that can be read byWeka.
In this process, we included the same at-tributes as the USFD authors used for English.For task C, (Hepple et al, 2007) are not veryclear whether the EVENT attributes used were re-lated to just one of the two events being temporallyrelated.
In any case, we used two of each of theEVENT attributes, one for each event in the tempo-ral relation to be determined.
So, for instance, anextra attribute EVENT2-tense is where the tenseof the second event in the temporal relation is kept.5.3 ResultsThe majority class baselines produce the sameresults as for English.
This was expected: theclass distribution is the same in the two datasets,since the <TLINK> elements were copied to theadapted corpus without any changes.For the sake of comparison, we used the sameclassifiers as (Hepple et al, 2007), and we used theattributes that they found to work best for English(presented above in Table 1).
The results for thePortuguese dataset are in Table 3, using 10-foldcross-validation on the training data.We also present the results for Weka?s imple-mentation of the C4.5 algorithm, to induce deci-sion trees.
The motivation to run this algorithmover these data is that decision trees are humanreadable and make it easy to inspect what deci-sions the classifier is making.
This is also true ofrules.JRip.
The results for the decision treesare in this table, too.The results obtained are almost identical to theresults for the original dataset in English.
The bestperforming classifier for task A is the same as forEnglish.
For task B, Weka?s functions.SMOproduced better results with the Portuguese datathan rules.DecisionTable, the best per-forming classifier with the English data for thistask.
In task C, the SVM algorithm was also thebest performing algorithm among those that werealso tried on the English data, but decision treesproduced even better results here.For English, the best performing classifier foreach task on the training data, according to Ta-ble 2, was used for evaluation on the test data: theresults showed a 59% F-measure for task A, 73%for task B, and 54% for task C.Similarly, we also evaluated the best algorithmfor each task (according to Table 3) with the Por-tuguese test data, after training it on the entiretraining dataset.
The results are: in task A thelazy.KStar classifier scored 58.6%, and theSVM classifier scored 75.5% in task B and 59.4%in task C, with trees.J48 scoring 61% in thistask.The results on the test data are also fairly similarfor the two languages/datasets.We inspected the decision trees and rule setsproduced by trees.J48 and rules.JRip, inorder to see what the classifiers are doing.Task B is probably the easiest task to check thisway, because we expect grammatical tense to behighly predictive of the temporal order between anevent and the document?s creation time.And, indeed, the top of the tree induced bytrees.J48 is quite interesting:eTense = PI: OVERLAP (388.0/95.0)eTense = PPI: BEFORE (1051.0/41.0)Here, eTense is the EVENT-tense attributeof <EVENT> elements, PI stands for present in-dicative, and PPI is past indicative (prete?rito per-feito do indicativo).
In general, one sees pasttenses associated with the BEFORE class and fu-ture tenses associated with the AFTER class (in-cluding the conditional forms of verbs).
Infini-tives are mostly associated with the AFTER class,and present subjunctive forms with AFTER andOVERLAP.
Figure 3 shows the rule set induced bythe RIPPER algorithm.The classifiers for the other tasks are more dif-ficult to inspect.
For instance, in task A, the eventterm and the temporal expression that denote theentities that are to be ordered may not even be di-rectly syntactically related.
Therefore, it is hard to676(eClass = OCCURRENCE) and ( eTense = INF) and ( ePolarity = POS) => lRelType= AFTER(183.0/77.0)( eTense = FI) => lRelType= AFTER (55.0/10.0)(eClass = OCCURRENCE) and ( eTense = IR-PI+INF) => lRelType= AFTER (26.0/4.0)(eClass = OCCURRENCE) and ( eTense = PC) => lRelType= AFTER (15.0/3.0)(eClass = OCCURRENCE) and ( eTense = C) => lRelType= AFTER (17.0/2.0)( eTense = PI) => lRelType= OVERLAP (388.0/95.0)(eClass = ASPECTUAL) and ( eTense = PC) => lRelType= OVERLAP (9.0/2.0)=> lRelType= BEFORE (1863.0/373.0)Figure 3: rules.JRip classifier induced for task B. INF stands for infinitive, FI is future indicative,IR-PI+INF is an infinitive form following a present indicative form of the verb ir (to go), PC is presentsubjunctive, C is conditional, PI is present indicative.see how interesting the inferred rules are, becausewe do not know what would be interesting in thisscenario.
In any case, the top of the induced treefor task A is:oAdjacent = True: OVERLAP (554.0/128.0)Here, oAdjacent is the ORDER-adjacentattribute.
Assuming this attribute is an indicationthat the event term and the temporal expression arerelated syntactically, it is interesting to see that thetypical temporal relation between the two entitiesin this case is an OVERLAP relation.
The rest ofthe tree is much more ad-hoc, making frequent useof the stem attribute of <EVENT> elements, sug-gesting the classifier is memorizing the data.Task C, where two events are to be ordered, pro-duced more complicated classifiers.
Generally theinduced rules and the tree paths compare the tenseand the class of the two event terms, showing someexpected heuristics (such as, if the tense of the firstevent is future and the tense of the second eventis past, assign AFTER).
But there are also manyseveral rules for which we do not have clear intu-itions.6 DiscussionIn this paper, we described the semi-automaticadaptation of a TimeML annotated corpus fromEnglish to Portuguese, a language for whichTimeML annotated data was not available yet.Because most of the TimeML annotations aresemantic in nature, they can be transposed to atranslation of the original corpus, with few adap-tations being required.In order to validate this adaptation, we used theobtained data to replicate some results in the liter-ature that used the original English data.The results for the Portuguese data are very sim-ilar to the ones for English.
This indicates that ourapproach to adapt existing annotated data to a dif-ferent language is fruitful.ReferencesDavid Ahn, Joris van Rantwijk, and Maarten de Ri-jke.
2007.
A cascaded machine learning approachto interpreting temporal expressions.
In HumanLanguage Technologies 2007: The Conference ofthe North American Chapter of the Association forComputational Linguistics; Proceedings of the MainConference, pages 420?427, Rochester, New York,April.
Association for Computational Linguistics.Mark Hepple, Andrea Setzer, and Rob Gaizauskas.2007.
USFD: Preliminary exploration of fea-tures and classifiers for the TempEval-2007 tasks.In Proceedings of SemEval-2007, pages 484?487,Prague, Czech Republic.
Association for Computa-tional Linguistics.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.James Pustejovsky and Marc Verhagen.
2009.Semeval-2010 task 13: evaluating events, time ex-pressions, and temporal relations (tempeval-2).
InProceedings of the Workshop on Semantic Evalua-tions: Recent Achievements and Future Directions,pages 112?116, Boulder, Colorado.
Association forComputational Linguistics.James Pustejovsky, Patrick Hanks, Roser Saur?
?, An-drew See, Robert Gaizauskas, Andrea Setzer,Dragomir Radev, Beth Sundheim, David Day, LisaFerro, and Marcia Lazo.
2003.
The TIMEBANKcorpus.
In Proceedings of Corpus Linguistics 2003,pages 647?656.M.
Verhagen, R. Gaizauskas, F. Schilder, M. Hepple,and J. Pustejovsky.
2007.
SemEval-2007 Task 15:TempEval temporal relation identification.
In Pro-ceedings of SemEval-2007.Ian H. Witten and Eibe Frank.
2005.
Data Mining:Practical Machine Learning Tools and Techniqueswith Java Implementations.
Morgan Kaufmann, SanFrancisco.
second edition.677
