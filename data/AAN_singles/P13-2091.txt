Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 511?515,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsJoint Modeling of News Reader?s and Comment Writer?s Emotions?Huanhuan Liu?
Shoushan Li??
*  Guodong Zhou?
Chu-Ren Huang?
Peifeng Li?
?Natural Language Processing LabSoochow University, China{huanhuanliu.suda,shoushan.li,churenhuang}@gmail.com?Department of CBSthe Hong Kong Polytechnic University{gdzhou,pfli}@suda.edu.cnAbstractEmotion classification can be generally donefrom both the writer?s and reader?sperspectives.
In this study, we find that twofoundational tasks in emotion classification,i.e., reader?s emotion classification on thenews and writer?s emotion classification onthe comments, are strongly related to eachother in terms of coarse-grained emotioncategories, i.e., negative and positive.
On thebasis, we propose a respective way to jointlymodel these two tasks.
In particular, a co-training algorithm is proposed to improvesemi-supervised learning of the two tasks.Experimental evaluation shows theeffectiveness of our joint modelingapproach.
*1 IntroductionEmotion classification aims to predict the emo-tion categories (e.g., happy, angry, or sad) of agiven text (Quan and Ren, 2009; Das and Ban-dyopadhyay, 2009).
With the rapid growth ofcomputer mediated communication applications,such as social websites and miro-blogs, the re-search on emotion classification has been attract-ing more and more attentions recently from thenatural language processing (NLP) community(Chen et al, 2010; Purver and Battersby, 2012).In general, a single text may possess two kindsof emotions, writer?s emotion and reader?s emo-tion, where the former concerns the emotion ex-pressed by the writer when writing the text andthe latter concerns the emotion expressed by areader after reading the text.
For example, con-sider two short texts drawn from a news and cor-responding comments, as shown in Figure 1.
On* *  Corresponding authorone hand, for the news text, while its writer justobjectively reports the news and thus does notexpress his emotion in the text, a reader couldyield sad or worried emotion.
On the other hand,for the comment text, its writer clearly expresseshis sad emotion while the emotion of a readerafter reading the comments is not clear (Somemay feel sorry but others might feel careless).News:Today's Japan earthquake could be2011 quake aftershock.
?
?News Writer?s emotion: NoneNews Reader?s emotion: sad, worriedComments:(1) I hope everything is ok, so sad.
I still cannot forget last year.
(2) My father-in-law got to experience thisquake... what a suffering.Comment Writer?s emotion: sadComment Reader?s emotion: UnknownFigure 1: An example of writer?s and reader?semotions on a news and its commentsAccordingly, emotion classification can begrouped into two categories: reader?s emotionand writer?s emotion classifications.
Althoughboth emotion classification tasks have beenwidely studied in recent years, they are alwaysconsidered independently and treated separately.However, news and their corresponding com-ments often appear simultaneously.
For example,in many news websites, it is popular to see anews followed by many comments.
In this case,because the writers of the comments are a part ofthe readers of the news, the writer?s emotions onthe comments are exactly certain reflection of thereader?s emotions on the news.
That is, thecomment writer?s emotions and the news read-er?s emotions are strongly related.
For example,511in Figure 1, the comment writer?s emotion ?sad?is among the news reader?s emotions.Above observation motivates joint modelingof news reader?s and comment writer?s emotions.In this study, we systematically investigate therelationship between the news reader?s emotionsand the comment writer?s emotions.
Specifically,we manually analyze their agreement in a corpuscollected from a news website.
It is interesting tofind that such agreement only applies to coarse-grained emotion categories (i.e., positive andnegative) with a high probability and does notapply to fine-grained emotion categories (e.g.,happy, angry, and sad).
This motivates our jointmodeling in terms of the coarse-grained emotioncategories.
Specifically, we consider the newstext and the comment text as two different viewsof expressing either the news reader?s or com-ment writer?s emotions.
Given the two views, aco-training algorithm is proposed to performsemi-supervised emotion classification so thatthe information in the unlabeled data can be ex-ploited to improve the classification performance.2 Related Work2.1 Comment Writer?s Emotion Classifica-tionComment writer?s emotion classification hasbeen a hot research topic in NLP during the lastdecade (Pang et al, 2002; Turney, 2002; Alm etal., 2005; Wilson et al, 2009) and previous stud-ies can be mainly grouped into two categories:coarse-grained and fine-grained emotion classifi-cation.Coarse-grained emotion classification, alsocalled sentiment classification, concerns onlytwo emotion categories, such as like or dislikeand positive or negative (Pang and Lee, 2008;Liu, 2012).
This kind of emotion classificationhas attracted much attention since the pioneerwork by Pang et al (2002) in the NLP communi-ty due to its wide applications (Cui et al, 2006;Riloff et al, 2006; Dasgupta and Ng, 2009; Li etal., 2010; Li et al, 2011).In comparison, fine-grained emotion classifi-cation aims to classify a text into multiple emo-tion categories, such as happy, angry, and sad.One main group of related studies on this task isabout emotion resource construction, such asemotion lexicon building (Xu et al, 2010;Volkova et al, 2012) and sentence-level or doc-ument-level corpus construction (Quan and Ren,2009; Das and Bandyopadhyay, 2009).
Besides,all the related studies focus on supervised learn-ing (Alm et al, 2005; Aman and Szpakowicz,2008; Chen et al, 2010; Purver and Battersby,2012; Moshfeghi et al, 2011), and so far, wehave not seen any studies on semi-supervisedlearning on fine-grained emotion classification.2.2 News Reader?s Emotion ClassificationWhile comment writer?s emotion classificationhas been extensively studied, there are only afew studies on news reader?s emotion classifica-tion from the NLP and related communities.Lin et al (2007) first describe the task of read-er?s emotion classification on the news articlesand then employ some standard machine learningapproaches to train a classifier for determiningthe reader?s emotion towards a news.
Their fur-ther study, Lin et al (2008) exploit more featuresand achieve a higher performance.Unlike all the studies mentioned above, ourstudy is the first attempt on exploring the rela-tionship between comment writer?s emotionclassification and news reader?s emotion classifi-cation.3 Relationship between News Reader?sand Comment Writer?s EmotionsTo investigate the relationship between newsreader?s and comment writer?s emotions, we col-lect a corpus of Chinese news articles and theircorresponding comments from Yahoo!
KimoNews (http://tw.news.yahoo.com), where eachnews article is voted with emotion tags fromeight categories: happy, sad, angry, meaningless,boring, heartwarming, worried, and useful.These emotion tags on each news are selected bythe readers of the news.
Note that because thecategories of ?useful?
and ?meaningless?
are notreal emotion categories, we ignore them in ourstudy.
Same as previous studies of Lin et al(2007) and Lin et al (2008), we consider thevoted emotions as reader?s emotions on the news,i.e., the news reader?s emotions.
We only selectthe news articles with a dominant emotion (pos-sessing more than 50% votes) in our data.
Be-sides, as we attempt to consider the commentwriter?s emotions, the news articles without anycomments are filtered.As a result, we obtain a corpus of 3495 newsarticles together with their comments and thenumbers of the articles of happy, sad, angry,boring, heartwarming, and worried are 1405,230, 1673, 75, 92 and 20 respectively.
Forcoarse-grained categories, happy and heartwarm-ing are merged into the positive category while512sad, angry, boring and worried are merged intothe negative category.Besides the tags of the reader?s emotions, eachnews article is followed by some comments,which can be seen as a reflection of the writer?semotions (Averagely, each news is followed by15 comments).
In order to know the exact rela-tionship between these two kinds of emotions,we select 20 news from each category and asktwo human annotators, named A and B, to manu-ally annotate the writer?s emotion (single-label)according to the comments of each news.
Table 1reports the agreement on annotators and emo-tions, measured with Cohen?s kappa (?)
value(Cohen, 1960).?
Value(Fine-grainedemotions)?
Value(Coarse-grainedemotions)Annotators 0.566 0.742Emotions 0.504 0.756Table 1: Agreement on annotators and emotionsAgreement between two annotators: Theannotation agreement between the two annota-tors is 0.566 on the fine-grained emotion catego-ries and 0.742 on the coarse-grained emotioncategories.Agreement between news reader?s andcomment writer?s emotions: We compare thenews reader?s emotion (automatically extractedfrom the web page) and the comment writer?semotion (manually annotated by annotator A).The annotation agreement between the two kindsof emotions is 0.504 on the fine-grained emotioncategories and 0.756 on the coarse-grained emo-tion categories.
From the results, we can see thatthe agreement on the fine-grained emotions is abit low while the agreement between the coarse-grained emotions, i.e., positive and negative, isvery high.
We find that although some fine-grained emotions of the comments are not con-sistent with the dominant emotion of the news,they belong to the same coarse-grained category.In a word, the agreement between news read-er?s and comment writer?s emotions on thecoarse-grained emotions is very high, even high-er than the agreement between the two annota-tors (0.754 vs. 0.742).In the following, we focus on the coarse-grained emotions in emotion classification.4 Joint Modeling of News Reader?s andComment Writer?s EmotionsGiven the importance of both news reader?s andcomment writer?s emotion classification as de-scribed in Introduction and the close relationshipbetween news reader?s and comment writer?semotions as described in last section, we system-atically explore their joint modeling on the twokinds of emotion classification.In semi-supervised learning, the unlabeled da-ta is exploited to improve the models with asmall amount of the labeled data.
In our ap-proach, we consider the news text and the com-ment text as two different views to express thenews or comment emotion and build the twoclassifiersNC  and CC .
Given the two-view clas-sifiers, we perform co-training for semi-supervised emotion classification, as shown inFigure 2, on both news reader?s and commentwriter?s emotion classification.Input:NewsL  the labeled data on the newsCommentL the labeled data  on the commentsNewsU the unlabeled data  on the newsCommentU  the labeled data  on the commentsOutput:NewsL New labeled data on the newsCommentL  New labeled data on the commentsProcedure:Loop for N iterations untilNewsU ??
or CommentU ??(1).
Learn classifierNC  with NewsL(2).
UseNC  to label the samples from NewsU(3).
Choose1n  positive and 1n negative news 1Nmost confidently predicted byNC(4).
Choose corresponding comments1M (thecomments of the news in1N )(5).
Learn classifierCC  with CommentL(6).
UseCC  to label the samples from CommentU(7).
Choose2n  positive and 2n negative comments2M  most confidently predicted by CC(8).
Choose corresponding comments2N (the newsof the comments in2M )(9).1 2News NewsL L N N?
?
?1 2Comment CommentL L M M?
?
?
(10).1 2News NewsU U N N?
?
?1 2Comment CommentU U M M?
?
?Figure 2: Co-training algorithm for semi-supervised emotion classification5135 Experimentation5.1 Experimental SettingsData Setting: The data set includes 3495 newsarticles (1572 positive and 1923 negative) andtheir comments as described in Section 3.
Alt-hough the emotions of the comments are not giv-en in the website, we just set their coarse-grainedemotion categories the same as the emotions oftheir source news due to their close relationship,as described in Section 3.
To make the data bal-anced, we randomly select 1500 positive and1500 negative news with their comments for theempirical study.
Among them, we randomly se-lect 400 news with their comments as the testdata.Features: Each news or comment text is treat-ed as a bag-of-words and transformed into a bi-nary vector encoding the presence or absence ofword unigrams.Classification algorithm: the maximum en-tropy (ME) classifier implemented with the pub-lic tool, Mallet Toolkits*.5.2 Experimental ResultsNews reader?s emotion classifier: The classifiertrained with the news text.Comment writer?s emotion classifier: Theclassifier trained with the comment text.Figure 3 demonstrates the performances of thenews reader?s and comment writer?s emotionclassifiers trained with the 10 and 50 initial la-beled samples plus automatically labeled datafrom co-training.
Here, in each iteration, we pick2 positive and 2 negative most confident samples,i.e,1 2 2n n?
?
.
From this figure, we can see thatour co-training algorithm is very effective: usingonly 10 labeled samples in each categoryachieves a very promising performance on eithernews reader?s or comment writer?s emotion clas-sification.
Especially, the performance when us-ing only 10 labeled samples is comparable to thatwhen using more than 1200 labeled samples onsupervised learning of comment writer?s emotionclassification.For comparison, we also implement a self-training algorithm for the news reader?s andcomment writer?s emotion classifiers, each ofwhich automatically labels the samples from theunlabeled data independently.
For news reader?semotion classification, the performances of self-training are 0.783 and 0.79 when 10 and 50 ini-* http://mallet.cs.umass.edu/tial labeled samples are used.
For comment writ-er?s emotion classification, the performances ofself-training are 0.505 and 0.508.
These resultsare much lower than the performances of our co-training approach, especially on the commentwriter?s emotion classification i.e., 0.505 and0.508 vs. 0.783 and 0.805.10 Initial Labeled Samples0.50.60.70.80 400 800 1200 1600 2000 2400Size of the added unlabeled dataAccuracy50 Initial Labeled Samples0.650.70.750.80.850.90 400 800 1200 1600 2000 2400Size of the added unlabeled data dataAccuracyThe news reader's emotionclassifier (Co-training)The comment writer's emotionclassifier (Co-training)Figure 3: Performances of the news reader?s andcomment writer?s emotion classifiers using theco-training algorithm6 ConclusionIn this paper, we focus on two popular emotionclassification tasks, i.e., reader?s emotion classi-fication on the news and writer?s emotion classi-fication on the comments.
From the data analysis,we find that the news reader?s and commentwriter?s emotions are highly consistent to eachother in terms of the coarse-grained emotion cat-egories, positive and negative.
On the basis, wepropose a co-training approach to perform semi-supervised learning on the two tasks.
Evaluationshows that the co-training approach is so effec-tive that using only 10 labeled samples achievesnice performances on both news reader?s andcomment writer?s emotion classification.514AcknowledgmentsThis research work has been partially supportedby two NSFC grants, No.61003155, andNo.61273320, one National High-tech Researchand Development Program of ChinaNo.2012AA011102, one General Research Fund(GRF) sponsored by the Research Grants Coun-cil of Hong Kong No.543810, the NSF grant ofZhejiang Province No.Z1110551, and one pro-ject supported by Zhejiang Provin-cial NaturalScience Foundation of China, No.Y13F020030.ReferencesAlm C., D. Roth and R. Sproat.
2005.
Emotions fromText: Machine Learning for Text-based EmotionPrediction.
In Proceedings of EMNLP-05, pp.579-586.Aman S. and S. Szpakowicz.
2008.
Using Roget?sThesaurus for Fine-grained Emotion Recognition.In Proceedings of IJCNLP-08, pp.312-318.Chen Y., S. Lee, S. Li and C. Huang.
2010.
EmotionCause Detection with Linguistic Constructions.
InProceeding of COLING-10, pp.179-187.Cohen J.
1960.
A Coefficient of Agreement for Nom-inal Scales.
Educational and Psychological Meas-urement, 20(1):37?46.Cui H., V. Mittal and M. Datar.
2006.
ComparativeExperiments on Sentiment Classification forOnline Product Comments.
In Proceedings ofAAAI-06, pp.1265-1270.Das D. and S. Bandyopadhyay.
2009.
Word to Sen-tence Level Emotion Tagging for Bengali Blogs.
InProceedings of ACL-09, pp.149-152.Dasgupta S. and V. Ng.
2009.
Mine the Easy, Classifythe Hard: A Semi-Supervised Approach to Auto-matic Sentiment Classification.
In Proceedings ofACL-IJCNLP-09,  pp.701-709, 2009.Duin R. 2002.
The Combining Classifier: To Train OrNot To Train?
In Proceedings of 16th InternationalConference on Pattern Recognition (ICPR-02).Fumera G. and F. Roli.
2005.
A Theoretical and Ex-perimental Analysis of Linear Combiners for Mul-tiple Classifier Systems.
IEEE Trans.
PAMI, vol.27,pp.942?956, 2005.Li S., Z. Wang, G. Zhou and S. Lee.
2011.
Semi-supervised Learning for Imbalanced SentimentClassification.
In Proceeding of IJCAI-11,  pp.826-1831.Li S., C. Huang, G. Zhou and S. Lee.
2010.
Employ-ing Personal/Impersonal Views in Supervised andSemi-supervised Sentiment Classification.
In Pro-ceedings of ACL-10,  pp.414-423.Lin K., C. Yang and H. Chen.
2007.
What Emotionsdo News Articles Trigger in Their Readers?
InProceeding of SIGIR-07, poster, pp.733-734.Lin K., C. Yang and H. Chen.
2008.
Emotion Classi-fication of Online News Articles from the Reader?sPerspective.
In Proceeding of the InternationalConference on Web Intelligence and IntelligentAgent Technology, pp.220-226.Liu B.
2012.
Sentiment Analysis and Opinion Mining(Introduction and Survey).
Morgan & ClaypoolPublishers, May 2012.Kittler J., M. Hatef, R. Duin, and J. Matas.
1998.
OnCombining Classifiers.
IEEE Trans.
PAMI, vol.20,pp.226-239, 1998Moshfeghi Y., B. Piwowarski and J. Jose.
2011.
Han-dling Data Sparsity in Collaborative Filtering usingEmotion and Semantic Based Features.
In Proceed-ings of SIGIR-11, pp.625-634.Pang B. and L. Lee.
2008.
Opinion Mining andSentiment Analysis: Foundations and Trends.Information Retrieval, vol.2(12), 1-135.Pang B., L. Lee and S. Vaithyanathan.
2002.
Thumbsup?
Sentiment Classification using MachineLearning Techniques.
In Proceedings of EMNLP-02, pp.79-86.Purver M. and S. Battersby.
2012.
Experimentingwith Distant Supervision for Emotion Classifica-tion.
In Proceedings of EACL-12, pp.482-491.Quan C. and F. Ren.
2009.
Construction of a BlogEmotion Corpus for Chinese Emotional ExpressionAnalysis.
In Proceedings of EMNLP-09, pp.1446-1454.Riloff E., S. Patwardhan and J. Wiebe.
2006.
FeatureSubsumption for Opinion Analysis.
In Proceedingsof EMNLP-06, pp.440-448.Turney P. 2002.
Thumbs up or Thumbs down?Semantic Orientation Applied to UnsupervisedClassification of comments.
In Proceedings ofACL-02, pp.417-424.Vilalta R. and Y. Drissi.
2002.
A Perspective Viewand Survey of Meta-learning.
Artificial IntelligenceReview, 18(2): 77?95.Volkova S., W. Dolan and T. Wilson.
2012.
CLex: ALexicon for Exploring Color, Concept and Emo-tion Associations in Language.
In Proceedings ofEACL-12, pp.306-314.Wilson T., J. Wiebe, and P. Hoffmann.
2009.Recognizing Contextual Polarity: An Explorationof Features for Phrase-Level Sentiment Analysis.Computational Linguistics, vol.35(3), pp.399-433.Xu G., X. Meng and H. Wang.
2010.
Build ChineseEmotion Lexicons Using A Graph-basedAlgorithm and Multiple Resources.
In Proceedingof COLING-10, pp.1209-1217.515
