APPROXIMATING AN INTERL INGUAIN  A PR INCIPLED WAYEduard Hovy I and Sergei Nirenburg 21) Information Sciences Institute 2) Center for Machine Translation4676 Admiralty Way Carnegie Mellon UniversityMarina del Rey, CA 90292-6695 Pittsburgh, PA 15213ABSTRACTWe address the problem of constructing in a principled wayan ontology of terms to be used in an interlingua for ma-chine translation.
Given our belief that the a true language-neutral ontology of terms can only be approached asymp-totically, the construction method outlined involves a step-wise folding in of one language at a time.
This is effectedin three steps: first building for each language a taxonomyof the linguistic generalizations required to analyze and gen-erate that language, then organizing the domain entities interms of that taxonomy, and finally merging the result withthe existing interlingua ontology in a well-defined way.
Thismethodology is based not on intuitive grounds about whatis and is not 'true' about the world, which is a question oflanguage-independence, but instead on practical concerns,namely what information the analysis and generation pro-grams require in order to perform their tasks, a question oflanguage-neutrality.
After each merging is complete, the re-sulting taxonomy contains, declaratively and explicitly rep-resented, those distinctions required to control the analysisand generation of the linguistic phenomena.
The paper isbased on current work of the PANGLOSS MT project.1.
InterlinguasThis paper presents a method of constructing in a prin-cipled way an ontology of terms to be used as a sourceof terms in an interlingua for machine translation.
Themethod involves taxonomizing relevant linguistic phe-nomena in each language and merging the resulting tax-onomy with the interlingua ontology to produce an on-tology that explicitly records the phenomena that mustbe handled by any parser or generator and is neutralwith respect o the languages handled by the system.1.1.
What is an Interlingua?In interlingual machine translation, the representationalpower of the interlingua is central to the success of thetranslation.
By interlingua we mean a notation usedin MT systems to represent the propositional and prag-matic meaning of input texts; an interlingua text thatrepresents the meaning of a source language text is pro-duced by computational analysis, and is then used asinput to a generation module which realizes this mean-ing in a target language text.An interlingua consists of the following three parts:a collection of terms: the elements that representindividual meanings (of lexical items, pragmatic as-pects, etc.
); this collection is organized in a multiplyinterconnected semantic network;notation: the syntax to which well-formed interlin-gua texts conform;substrate: the knowledge representation system inwhich interlingua texts are instantiated and whichprovided the infrastructure for reasoning with theknowledge ncoded in interlingua texts.The term network can be thought of as a conceptual lex-icon of basic meaning distinctions that represent entitiesin the world.
While it is not feasible to produce a com-plete model of the world, it is possible to produce a well-formed subset in which each term's definition containsenough features to differentiate it from all other termsin the subworld.
A good taxonomization enables thesharing and inheritance of properties and facilitates def-initional brevity and expressive power.
Any given self-contained subworld includes a set of terms which it canshare with other subworlds.
These are to be found athigher levels of the network, closer to its root node.
Itis customary to call a subnetwork of terms that are ex-pected to be present in most (if not all) subworlds anontology, while the rest of a particular subworld is oftencalled a domain model.
Though the boundary betweenan ontology and a set of domain models is rather diffi-cult to establish in the abstract, in practice, for any givenset of domain models, it is straightforward to detect theshared higher levels.The main purpose of an ontology and a domain modelin MT is to support lexical-semantic analysis and gen-eration.
The open-class lexical units of a language havetheir meanings explained using terms from the ontologyand the domain model.
Connections are made in thelexicons for each particular language.
(For a detaileddescription of one such interlingua-ontology-lexicon com-bination see \[15, 13, 4\]).2611.2.
Language Independence vs.Language Neutral ityBy definition, an interlingua is language-independentand depicts the world directly, not through the mediumof a natural anguage.
Of course, particular interlinguasvary in their quality and utility.
The two major proper-ties of an interlingua which influence its quality are itsexpressive power (that is, the ability to support a dif-ferent structure for each of a set of ambiguous naturallanguage xpressions) and its capability to scale up with-out a major overhaul of its syntax (a point which relatesdirectly to the task of term acquisition).In theory, interlingua is language-independent.
That is,all the languages handled are pairwise independent withrespect o the interlingua, and the interlingua containsno "traces" of particular semantic distinctions predomi-nant in a particular language or group of languages.
Thedegree of language independence attained by an interlin-gua in reality is a matter of judgment.The feasibility of language-independent representationshas been debated many times.
Since interlinguas areby definition language-independent, the debate revolvesabout the degree of overlap with language-specific knowl-edge and the status of such overlap.
This debate is inter-esting but not practically relevant in the area of MT.
Afully language-independent o ology is a worthy ideal.Since the acquisition-related tasks of selection, defini-tion, and taxonomization of terms for an ontology anddomain model are always performed by people, they arealways open to being influenced by the distinctions madein the acquirers' languages as well as their "folk" modelsof the world.
1However, our approach to the problem of interlingua con-struction is more practical.
We are concerned with thematter of constructing an interlingua that is language-neutral, i.e., one that enables analyzers and generatorsto operate optimally in a machine translation system.Under this approach it is still possible to maintain thecentral architectural tenet of interlingual MT systems - -that it is possible to translate from a text to its interlin-gua text without regard to any eventual target language,and to translate from the interlingua text to a targetwithout regard to the original source language.We focus in this paper on the ontology, leaving asidequestions of notation and substrate.
Given the complex-1 Consider, for example, the problem of representing colors: howmany are there, and how are they organized?
Even the basic dis-tinction into the three primary colors so natural to any westerneris unlikely to occur to the Daui people of New Guinea, who haveonly two color terms (mill = dark-cool; mola = light-warm) andhave proven difficulty in learning names for nonfocM colors \[16\].ity of the ontology construction task, we believe thatany given ontology will inevitably be closer to some lan-guages than to others, both in the terms selected andtheir connections.
We don't consider this to be a prob-lem, as we would be able to augment he ontology anddomain model as necessary whenever new domain mod-els and new languages are added to the system.What we do consider a problem is the lack of a generallyestablished well-defined method for constructing ontolo-gies.
Most ontologies and domain models to date havebeen assembled based primarily on introspection, andoften reflect the idiosyncrasies of the builders more thanthe requirements of the application (such as MT).
Lack-ing well-founded guiding principles, the ontology builderis working in the dark.
In this paper, we suggest hata better methodology uses data-oriented methods andlinguistic knowledge to guide introspection.2.
A Method of Ontology Construct ion2.1.
Basic Criterion of TaxonomizationRecognizing that we cannot build a satisfactorilylanguage-neutral ontology directly, we formulate an in-cremental procedure that, we believe, allows the acquirerto approach an optimal ontology asymptotically.To develop the methodology we seek theoretically moti-vated answers to the following basic questions underlyingontology construction:?
What terms must be included in the ontology??
How should the terms be organized in it??
What level of detail should it reach??
How closely can the ontology terms parallel the par-ticular words and phrases of any single language?In answering these questions, we exploit the fact that theontology is inevitably going to be more or less language-specific to further our overall goal: a powerful interlin-gual MT system.
The "closer" the ontology is to thesource and target languages, the easier the process ofontology term acquisition and organization, and the lesswork the parser and generator have to do to bridge thegap between interlingua texts and source and target lan-guage texts.
To find the point of "minimal distance"from all source and target languages, weighted as dis-cussed in Section 2.5, we formulate the:Basic c r i te r ion  under ly ing  te rmino logyc reat ion  and  taxonomizat ion :  The ontologymust be just sufficiently powerful to representthe distinctions required to analyze the sourcelanguages and generate the target languages inthe given domains.262To define the distinctions needed to support each lan-guage, we start with a list of linguistic phenomena to becovered in it.
This information can be extracted from asufficiently rich grammar of the language.
For example,for English the fact that nouns pattern into mass andcount, the fact that adjectives and adverbs pattern dif-ferently than do verbs, or the fact that many differentforms of possession (to have an arm, to have a spouse,to have a car) are expressed similarly.
We then createa taxonomy of these linguistic abstractions, guided bytheir interrelationships.
This taxonomy would, for theseexamples, contain nodes for UncountableObj and Count-ableObj under Obj to help handle nouns, nodes Qualityand Process as high-level taxonomic organizers of adjec-tival/adverbial modifiers and verbal actions, and Gen-eralizedPossession as a high-level organizational pointfor the various types of possession.
Any proposed termis accepted in the taxonomy only if it captures a dis-tinct linguistic phenomenon of the language not oth-erwise handled.
We end up with a "general" taxon-omy of abstract entities that capture useful groupingsof processing-oriented f atures.Having established such a taxonomy, we then list all theentities that appear in the domain being addressed bythe MT system (objects, actions, states, relations, plans,scripts (action chains), etc.).
What we are after is a tax-onomization of these entities in such as way as to facil-itate MT.
Of course, the simplest scheme is no taxono-mization at all: a list of the domain entities without anyhigher-level organizing entities.
Then however each en-tity must contain enough information by itself to enablesuccessful manipulation by the analyzer and generator(for example, Company must be explicitly annotated asbeing a SociaiOrg, if this fact is used by analyzer and/orgenerator).
A better solution is to group entities withthe same features together and define nodes that repre-sent generalizations.
But which generalizations?
We ar-gue that most useful are those generalizations that playa role in the processing, analysis and generation (thosethat serve some differentiating function in the construc-tion of an analysis or a clause) - -  exactly those containedin the taxonomy of linguistic phenomena.
This taxon-omy partitions the entities of the domain in ways whichfacilitate their treatment by the system.
~Thus, we use the linguistically inspired taxonomy as on-2It must be understood that we are not stating that one must(or even can) perform exhaustive decomposition f all the facetsof meaning of a concept to place it in the ontology.
The basiccriterion argues that just enough must be represented to enablethe generation of the languages in question.
Thus for example wedo not need a term Pink for Pale Red unless the domain is suchthat there are implicative ffects to saying "pale red" instead of"pink" (the former being a noncentral meaning in some contexts;see \[12\] and \[8\], p. 115).tology under which to categorize all the domain terms(though this is not the only way to employ the language-oriented taxonomy as a guide, it is the most straightfor-ward).
By such a taxonomization, each domain term islocated so as to inherit precisely the representational dis-tinctions required to support its generation in the targetlanguage.
Such taxonomies are fairly common in sym-bolically based NLP systems; see for example the onesused in JANUS (BBN) \[7\], LILOG (IBM Germany) \[11\],and Naive Semantics \[5\].We call the resulting taxonomy, which consists of a lin-guistically inspired ontology and a domain-oriented do-main model, the Language Base (LB) of the language.Since the resulting knowledge base is language-based,it is not necessarily best suited to support specializedforms of reasoning such as naive physics, legal reasoning,etc.
But since our intention is MT, this poses no prob-lem.
An example of the abstractions that can be used ashigh-level organization for English is the Penman UpperModel \[2\], a taxonomy that has been used to support hegeneration of English text in several domains.2 .2 .
Toward  Language Neut ra l i tyIt will be noted that the example terms employed aboveare semantic rather than syntactic (e.g., Process ratherthan Verb).
Where obvious semantic orrelates for syn-tactic generalizations exist, the strategy is to employthem, for they are more likely to appear also in the LBsof other languages.
However, the result is still (at best)a mixture of semantic and purely syntactic generaliza-tions, including generalizations for phenomena withoutany obvious semantic basis; for example, in English, thehct  that verbs like "fill" and "spray" pattern similarly:"he filled the cart with hay" and "he sprayed the wallwith paint" can be similarly transformed to "he used hayto fill the cart" and "he used paint to spray the wall".Using abstractions from any particular language meansgiving up the basic goal of language neutrality.
Since,however, we expect that any ontology is going to beslanted toward some language(s) more than others, weare willing to accommodate such "syntactic pollution"as long as it does not hamper MT.
We next outlinea method of progressively making a taxonomy morelanguage-neutral to the point where all troublesome syn-tactic terms are removed.
This process involves mergingthe LB for a second language with the LB for the firstto form a hybrid taxonomy (also called a polylingua in\[9\]), which we call the Ontology Base (OB), and then re-peating the process for additional languages, accordingto the following procedure:1.
Construct he LB taxonomy for language 1.
This isthe ontology base (OB).2632.
For each subsequent language,(eL) construct he LB for its phenomena;(b) merge it with the existing OB, starting fromthe topmost entity and proceeding downward,as described in Section 2.3, ensuring that thelower-level, domain-specific, OB terms remainproperly taxonomized.The merging process can be considerably simplified ifduring construction of the LB for a new language (step2(a)), the classes of the existing OB are used as a guidewhenever various taxonomizations are possible.From the languages we have examined, the followingtrend is apparent: the upper regions (ontologies) of theLBs are identical or nearly so.
Differences occur in themiddle regions, since they reflect language-particular in-formation; the degree of cross-LB commensurability de-pends roughly on the closeness of the grammars.
Thelower regions are essentially identical for fairly inter-national domains such as banking, science, technology,etc.
- -  after all, however something like Metal is treatedin the language, its descendants Gold, Silver, etc., aretreated similarly and thus taxonomize together similarly.As discussed in \[17\] and \[10\], conceptual systems (ofwhich OBs and LBs are an example) can be commen-surate in several different ways.
Lakoff lists five typesof commensurability of two conceptual systems (p. 322):translation (a sentence-by-sentence translation preserv-ing truth conditions is possible), understanding (a per-son can understand both alternatives), use (the sameconcepts are used the same ways), framing (situationsare "framed" the same way and there is a one-one cor-respondence between the systems, frame by frame), andorganization (when the same concept occurs in both, itis organized the same way relative to others that occurin both).
Lakoff provides ome examples: the systems ofaspect in English and Hopi are commensurate by transla-tion (since Whorf did translate sentences from one to theother) but not by use, since as Whorf's examples makeclear (pp.
57-64), the "same" concepts for time are usedvery differently; the systems of Spatial Location in En-glish and Mixtec are commensurate by translation butnot by organization \[3\], since for example sentences ex-pressing the English meaning "on" translate to widelydifferent Mixtec expressions depending on the shape ofthe lower object, among other things.2.3.
Merging OntologiesGiven the OB and an LB for a new language, we startthe merging process from the topmost item(s) of the hi-erarchies.
Usually, since the "meaning" of each itemis captured by its interrelationships and ancestry, it isinstructive to consider groups of closely related items si-multaneously.
The merging process involves one of threealternative operations for each item in the LB:Ident i ty :  the LB item is identical to a correspondingitem of the OB; they represent he same phenomenon,such as DecomposableObj.
In this case, no further workis required beyond a name change to the OB item name.Identity may be difficult to determine for non-semanticitems (one reason we suggest using semantic items whenpossible), or even occasionally for semantic ones, whentheir subordinate items differ.
We discuss this point laterin this section.
However, in practise, identity of OB andLB items is common for related languages, especially inthe more abstract (higher) regions and more domain-specific (lower) regions of the OB.Extens ion :  the LB item is more specific than the ap-propriate OB item(s); that is, it straightforwardly sub-categorizes some OB item(s).
In this case, the OB isgrown by including the LB item as a child of the OBitem.
For example, if the OB were initially constructedfrom English, its system of honorifics would probablycontain only two items, one for FormalSuperordinate andthe other for EqualOrSubordinate; a Japanese LB wouldcause this system to be fleshed out to include a moreelaborate substructure along the lines described in \[1\].Cross-elassl f icat ion:  the LB item represents aspectsof more than one OB items.
This is the case the newlanguage partitions the phenomenon under considera-tion in a different way to the previous language(s) stud-ied.
Typically, several parallel LB items represent onepartitioning of the phenomenon and several OB itemsrepresent a different partitioning.
In this case, two al-ternative strategies can be followed.
The first is to enterthe LB items into the OB as a parallel but distinct tax-onomization of the phenomenon, and all their descen-dants must be added as well, unless items representingthe same descendants are already in the OB, in whichcase these items must be linked up also to the appro-priate LB item(s).
The second strategy is to create thecross-product of the two sets of items.
For example, ifthe OB partitions Objs into UncountableObj (mass) andCountableObj (count) types, and the new language parti-tions Objs into (say) TaiiSkinnyObj and OtherObj types,and neither LB class is a proper subset of either OBone, then four new items must be formed: Countable-TallSkinnyObj, Uncountable-TallSkinnyObj, Countable-OtherObj, and Uncountable-OtherObj.
Every item sub-ordinate to either item in both LB and OB must then bereclassified with respect o the new cross-product i ems.One difficult case arises when the same item is tax-onomized in the LB and OB under mutually exclusive264items.
For example, the domain concept Sand may beclassified as UncountableObj in one and CountableObjin the other.
In this case, the respective LB and OBitems UncountableObj and CountableObj must be differ-entiated as, for example, UncountableObjl and Count-ableObjl and UncountableObj2 and CountableObj2, thecross-product taken, and any subordinate items reclas-sifted.
Though this may become a combinatorially ex-pensive operation in principle, in practise we find it sel-dom occurs in our domain; furthermore, the fact that allthree our current LBs for English contain fewer than 200non-domain tems (see Section 3), and we do not expectsignificantly arger LBs to be necessary.2.4.
Funct iona l  Grounds  for  Onto logyA certain amount of leeway exists in the constructionof the LB.
This leeway should be used wisely, since, asmentioned above, similarity with the existing OB cansignificantly simplify the merging process.
For best re-sults, linguistic phenomena should be modeled accord-ing to their underlying functional reasons.
Functionaldistinctions often have different syntactic expressions indifferent languages; it is therefore important o repre-sent in the interlingua the function and not the form(for example, the rule "passive translates to passive" ig-nores the reason why passive was used in the original andcannot ensure an appropriate target expression).
Un-derstanding the true source of variations and creating inthe ontology appropriate means for representing them isof central importance.2.5.
T radeof fs  in Onto logy  ContentThe ontology construction method outlined here pro-duces a set of terms explicitly defined to represent allthe pertinent linguistic phenomena ofeach language be-ing covered.
For practical purpose, however, this proce-dure may introduce more complexity than savings in thecase where some phenomenon carries meaning only inone of the languages being handled.
If for example onlyone language differentiated Number into Single, Dual,and Multiple (as Arabic and Hebrew do) while all theothers just differentiated Single from Multiple, the Dualoption can be removed and handled only by the Arabicand Hebrew generators, who in the case of Multiple haveto determine (somehow) whether the entity in questionis dual or not, or whether they should simply gener-ate an alternative locution.
For any particular language,the more specifically attuned the LB upper regions areto specific forms of expression, the more syntacticallyoriented information enters the ontology.
As a result,though LB construction for that language is simplified,its merging with the OB is made more complex, as is sub-sequent merging of the OB with other LBs.
In addition,analysis of other languages i complicated, since infor-mation must be sought hat may not be present in thesource text.
To top it all, this information is totally ir-relevant when translation occurs to languages other thanthe complexifying culprit.Easily recognized uring step 2(b) of the merging pro-cess of LB and OB by the lack of comparable items in theOB, such unique LB phenomena c n be omitted from theInterlingua, ignored during analysis, and incorporatedduring a pre-realization phase in generation, either byusing default values, preselected settings, or by turningto a human (in-editor or post-editor) for help.
The rela-tive costs of incorporating such phenomena into the LBversus leaving them out and handling them when neededdepend on the following:?
the complexity of the phenomenon (which is pro-portional to the number of LB items required torepresent i ),?
ease of handling it by default or circumvention,?
the frequency of translation i to the language(s) ex-hibiting the phenomena.When LB items are swallowed into specific language pro-cessors, a record of the removal of the phenomena shouldbe left in the OB at the appropriate point(s) in the tax-onomy.
Such a record will be encountered during lateraddition of other languages, enabling arguments to bemade for the reintroduction f the phenomenon i to theOB itself if appropriate.In this manner, the Interlingua may be more or lesslanguage-neutral, requiring correspondingly more workto generate the more distant ones.
Its optimal position-ing requires a careful analysis of the tradeoffs involved.3.
Cur rent  WorkWe recently began constructing an Interlingua for thePANGLOSS machine translation system, using the termi-nologies developed by the three partners, namely a setof ontologies and domain models developed at the Cen-ter for Machine Translation at CMU, using the ONTOSacquisition interface \[14\], IR, the Intermediate Repre-sentation terminology used at the Computing ResearchLaboratory of New Mexico State University \[6\], and theUpper Model developed for the Penman language gen-erator at USC/ISI \[2\].
Both CMT's TAMERLAN andIR have already been used to support Interlingual ma-chine translation of several languages, while variants ofthe Upper Model suited for German, Japanese, and Chi-nese are under construction at GMD/IPSI (Germany)and the University of Sydney (Australia).265As expected, except for names, we found little disagree-ment among the three ontologies in their upper regions(while the IR is not explicitly taxonomized into an on-tology, this can be done without problem).
The mostrecent ontology from CMU contains approximately 185items, IR approximately 150, and the Penman UpperModel approximately 190 (the latter two contain onlylinguistic generalizations, no domain entities).4.
ConclusionIn this paper we addressed the problem of constructingin a principled way one of the three components ofan In-terlingua for machine translation: the ontology of termswhich are used in the Interlingua notation to capture themeaning of the source text and govern the generation ofthe target text.
The methodology described is basednot on intuitive grounds about what is and is not 'true'about the world, which is a matter for philosophers andconcerns the question of language-independence, but isbased instead on more practical concerns, namely whatinformation the analysis and generation programs re-quire in order to perform their tasks.Given our belief that the a true language-neutral on-tology of terms can only be approached asymptotically,the method we outline for constructing the ontology in-volves a stepwise folding in of one language at a time.Any "syntactic pollution" present in an LB will either bemerged into the ontology and stand explicitly as some-thing other language analyzers and generators have tohandle or it will be swallowed in the analyzer and gener-ator for the specific language as a clearly identified itemthat requires special treatment.
In either case, an ex-plicit and declarative representation of the distinctionsrequired to control the analysis and generation of thelanguages handled results.Though (depending on the nature of the analysis andgeneration procedures) a taxonomy of this kind need notalways resemble what most people intuitively think ofwhen they talk about an interlingua ontology, we claimthis is a moot point, since what we and they are after isa practical construct hat can be used effectively in anMT system, and the method of construction outlined inthis paper is a way of achieving one.References1.
Bateman, J.A.
1988.
Aspects of Clause Politeness inJapanese: An Extended Inquiry Semantics Treatment.In Proceedings of the ~6th Annual Conference of theACL, Buffalo (147-154).2.
Bateman, J.A., Kasper, R.T., Moore, J.D.
and Whit-ney, R.A. 1989.
A General Organization of Knowledgefor Natural Language Processing: The Penman UpperModel.
Unpublished research report, USC/InformationSciences Institute, Marina del Rey.3.
Brugman, C. 1983.
The Use of Bady-Part Terms asLocatives in Chalcatongo Mixtec.
In Report no.
4 ofthe Survey of California and Other Indian Languages,University of California at Berkeley (235-290).4.
Carlson, L. and Nirenburg, S. 1990.
World Modeling forNLP.
Technical Report no.
CMU-CMT-90-121, CarnegieMellon University, Pittsburgh.5.
Dahlgren, K., McDowell, J., and Stabler, E.P.
1990.Knowledge Representation for Commonsense Reasoningwith Text.
Computational Linguistics 15 (149-170).6.
Farwell, D. 1990.
Description of the Intermedia Rep-resentation System for the CRL Multilingual MachineTranslation System.
Unpublished ocument, Comput-ing Research Laboratory, New Mexico State University,Las Cruces.7.
Hinrichs, E.W., Ayuso, D.M., Scha, R. 1987.
The Syn-tax and Semantics of the JANUS Semantic InterpretationLanguage.
In Research and Development in Natural Lan-guage Understanding asPart o\] the Strategic ComputingProgram.
Annual Technical Report no.
6552, BBN Lab-oratories, Cambridge.8.
Jackendoff, R. 1985.
Semantics and Cognition.
Cam-bridge: MIT Press.9.
Kay, M., Gawron, J.M., and Norvig, P. 1991.
Verbmo-bil: A Translation System for Face-to-Face Dialog.
CSLIStudy.10.
Lakoff, G. 1987.
Women, Fire, and Dangerous Things.Chicago: University of Chicago Press.11.
Lang, E. 1991.
The LmoG Ontology from a LinguisticPoint of View.
In O. Herzog and C-R. Rollinger (eds),Text Understanding in LILOG.
Berlin: Springer (464-480).12.
McCawley, J.D.
1978.
Conversation Implicature and theLexicon.
In P. Cole, ed.
Syntax and Semantics vol.
9.New York: Academic Press (245-259).13.
Meyer, I., Onyshkevych, B., and Carlson, L. 1990.
Lex-icographic Principles and Design for Knowledge-BasedMachine Translation.
Technical Report no.
CMU-CMT-90-118.
Carnegie Mellon University, Pittsburgh.14.
Monarch, I.
1989.
ONTOS Reference Manual.
TechnicalMemo, Center for Machine Translation.
Carnegie MellonUniversity, Pittsburgh.15.
Nirenburg, S. and Defrise, C. 1992.
Application-Oriented Computational Semantics.
In R. Johnson andM.
Rosner (eds.
), Computational Linguistics and FormalSemantics.
Cambridge: Cambridge University Press.16.
Rosch, E. 1973.
Natural Categories.
Cognitive Psychol-ogy 4 (328-350).17.
Whorf, B.L.
1956.
Language, Thought, and Reality: Se-lected writings o/ Benjamin Lee Whorl, ed.
John B. Car-roll, Cambridge: MIT Press.266
