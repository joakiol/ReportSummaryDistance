Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics ?
Student Research Workshop, pages 119?125,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsSuggestion Mining from Opinionated TextSapna NegiInsight Centre for Data AnalyticsNational University of Ireland, Galwaysapna.negi@insight-centre.orgAbstractIn addition to the positive and negativesentiments expressed by speakers, opin-ions on the web also convey suggestions.Such text comprise of advice, recommen-dations and tips on a variety of pointsof interest.
We propose that suggestionscan be extracted from the available opin-ionated text and put to several use cases.The problem has been identified only re-cently as a viable task, and there is alot of scope for research in the directionof problem definition, datasets, and meth-ods.
From an abstract view, standard al-gorithms for tasks like sentence classifi-cation and keyphrase extraction appear tobe usable for suggestion mining.
How-ever, initial experiments reveal that thereis a need for new methods, or variations inthe existing ones for addressing the prob-lem specific challenges.
We present a re-search proposal which divides the prob-lem into three main research questions; wewalk through them, presenting our analy-sis, results, and future directions.1 IntroductionOnline text is becoming an increasingly popularsource to acquire public opinions towards entitieslike persons, products, services, brands, events,social debates etc.
State of the art opinion miningsystems primarily utilise this plethora of opinionsto provide summary of positive and negative sen-timents towards entities or topics.
We stress thatopinions also encompass suggestions, tips, and ad-vice, which are often explicitly sought by stake-holders.
We collaboratively refer to this kind ofinformation as suggestions.
Suggestions about avariety of topics of interest may be found on opin-ion platforms like reviews, blogs, social media,and discussion forums.
These suggestions, oncedetected and extracted, could be exploited in nu-merous ways.
In the case of commercial entities,suggestions present among the reviews can con-vey ideas for improvements to the brand owners,or tips and advice to customers.Suggestion extraction can also be employedfor the summarisation of dedicated suggestion fo-rums1.
People often provide the context in suchposts, which gets repetitive over a large number ofposts.
Suggestion mining methods can identify theexact textual unit in the post where a suggestion isconveyed.Table 1 provides examples of suggestions foundin opinion mining datasets.
In our previous work(Negi and Buitelaar, 2015b), we showed that sug-gestions do not always possess a particular senti-ment polarity.
Thus the detection of suggestionsin the text goes beyond the scope of sentiment po-larity detection, while complements its use casesat the same time.In the recent past, suggestions have gained theattention of the research community.
However,most of the related work so far performs a binaryclassification of sentences into suggestions or non-suggestions, where suggestions are defined as thesentences which propose improvements in a re-viewed entity (Brun and Hagege, 2013; Ramanandet al, 2010; Dong et al, 2013).
These studies an-notated datasets accordingly and developed sys-tems for the detection of only these type of sug-gestions; and performed an in-domain evaluationof the classifier models on these datasets.We emphasise that in addition to the classi-fication tasks performed earlier, there are a lotmore aspects associated with the problem, includ-ing a well-formed and consistent problem defini-1https://feedly.uservoice.com/forums/192636-suggestions/category/64071-mobile119tion.
We divide the study of suggestion mininginto three guiding aspects or research questions:1) Definition of suggestions in the context of sug-gestion mining, 2) Their automatic detection fromopinionated text, and 3) Their representation andsummarisation.A comprehensive research on suggestion min-ing demands the problem specific adaptation andintegration of common NLP tasks, like text classi-fication, keyphrase extraction, sequence labelling,text similarity etc.
Last but not least, recentprogress in the adaptation of deep learning basedmethods for NLP tasks opens up various possibil-ities to employ them for suggestion mining.2 Research ProblemA broad statement of our research problem wouldbe, mining expressions of suggestions from opin-ionated text.
There are several aspects of the prob-lem which can lead to a number of research ques-tions.
We identify three broad research questionswhich are the guiding map for our PhD research.?
Research Question 1 (RQ1): How do we definesuggestions in suggestion mining??
Research Question 2 (RQ2): How do we detectsuggestions in a given text ??
Research Question 3 (RQ3): How can sugges-tions be represented and summarised ?The following sections will give a more detaileddescription of these aspects, including the prelim-inary results, challenges, and future directions.3 Research MethodologyIn this section we address each of the researchquestions, our findings so far, and the future di-rections.3.1 RQ1: Suggestion DefinitionThe first sense of suggestion as listed in the ox-ford dictionary is, an idea or plan put forwardfor consideration, and the listed synonyms areproposal, proposition, recommendation, advice,counsel, hint, tip, clue etc.
This definition, how-ever needs to be defined on a more fine grainedlevel, in order to perform manual and automaticlabelling of a text as an expression of suggestion.There have been variations in the definitionof suggestions targeted by the related works,which renders the system performances fromsome of the works incomparable to the others.We identify three parameters which can lead usto a well-formed task definition of suggestionsfor suggestion mining task: What is the unit ofa suggestion, who is the intended receiver, andwhether the suggestion is expressed explicitly ornot.Unit: Currently, we consider sentence as aunit of suggestion, which is in-line with relatedworks.
However, it was observed that somesentences tend to be very long, where suggestionmarkers are present in only one of the constituentclauses.
For example: When we booked the roomthe description on the website said it came witha separate seating area, despite raising the issuewith reception we were basically told this was notso , I guess someone needs to amend the web-site.
In this sentence, although the full sentenceprovides context, the suggestion is identifiablefrom the last clause.
It is common to witnesssuch non-uniform choice of punctuation in onlinecontent.
Considering this, we intend to buildclassification models which can identify the exactclause/phrase where a suggestion is expressed,despite of individual instances being sentences.Receiver: Different applications of suggestionmining may target different kinds of suggestions,which can differ on the basis of intended receiver.For example, in domains like online reviews, thereare two types of intended receivers, brand owners,and fellow customers.
Therefore, suggestionsneed to be defined on the basis of the intendedreceivers.How is a suggestion expressed: The firstround of suggestion labelling performed by usresulted in a very low inter-annotator agreement,i.e.
a kappa score of 0.4 - 0.5.
It was observed thatgiven a layman definition of suggestions, humansdo not distinguish between explicit and implicitforms of suggestions, since they can inherentlyinfer suggestions from their implicit forms.Figure 1 illustrates the two forms.
Specifically,in the case of domains like reviews, annotatorsmostly disagreed on whether the implicit onesare suggestions or not.
We define an explicitsuggestion as the text which directly proposes,recommends, or advices an action or an entity;whereas the implicit ones provide the information120Figure 1: Implicit and explicit forms of sugges-tionsfrom which the suggested action or entity can beinferred.
In remainder of the paper, we refer toexplicit suggestions as suggestions.We observe that certain linguistic propertiesconsistently mark suggestions across differentdatasets (Table 1).
One such phenomenon is im-perative and subjunctive mood (Negi and Buite-laar, 2015a; Negi and Buitelaar, 2015b).
Thepresence of these properties makes it more likely,but does not guarantee a text to be a suggestion.Another linguistic property is speech act (Searle,1969).
Speech act is a well studied area of com-putational linguistics, and several typologies forspeech acts exist in literature, some of which con-sider suggestions as a speech act (Zhang et al,2011).3.2 RQ2: Suggestion DetectionThe problem of suggestion detection in a bigdataset of opinions can be defined as a sentenceclassification problem: Given a set S of sentences{s1,s2,s3,...,sn}, predict a label lifor each sen-tence in S, where li?
{suggestion, non sugges-tion}.The task of suggestion detection rests on the hy-pothesis that a large amount of opinionated textabout a given entity or topic is likely to containsuggestions which could be useful to the stake-holders for that entity or topic.
This hypothesishas been proven to be true when sentences fromreviews and tweets about commercial entities weremanually labeled (Table 1).
Also, the survey pre-sented by Asher et al (2009) shows that althoughin a low proportion, opinionated texts do containexpressions of advice and recommendations.The required datasets for suggestion basedsentence classification task are a set of sen-tences which are labelled as suggestion andnon-suggestion, where the labeled suggestionsshould be explicitly expressed.Existing Datasets: Some datasets on sug-gestions for product improvement are unavailabledue to their industrial ownership.
To the bestof our knowledge, only the below mentioneddatasets are publicly available from the previousstudies:1) Tweet dataset about Microsoft phones: com-prises of labeled tweets which give suggestionsabout product improvement (Dong et al, 2013).Due to the short nature of tweets, suggestions arelabeled at the tweet level, rather than the sentencelevel.2) Travel advice dataset: comprises of sentencesfrom discussion threads labeled as advice (Wicak-sono and Myaeng, 2013).
We observe that thestatements of facts (implicit suggestions/advice)are also tagged as advice in this dataset, forexample, The temperature may reach upto 40degrees in summer.
Therefore, we re-labeledthe dataset with the annotation guidelines forexplicit suggestions, which reduced the numberof positive instances from 2192 to 1314.Table 2 lists the statistics of these datasets.Introduced Datasets: In our previous work(Negi and Buitelaar, 2015b), we prepared twodatasets from hotel and electronics reviews(Table 2) where suggestions targeted to thefellow customers are labeled.
Similar to theexisting Microsoft tweets dataset, the number ofsuggestions are very low in these datasets.
Asstated previously, we also formulate annotationguidelines for the explicit expression of sugges-tions, which led to a kappa score of upto 0.86 asthe inter-annotator agreement.
In another work(Negi et al, 2016), we further identify possibledomains and collection methods, which are likelyto provide suggestion rich datasets for trainingstatistical classifiers.1) Customer posts from a publicly accessiblesuggestion forums for the products Feedly mobileapp2, and Windows App studio3.
We crawled2https://feedly.uservoice.com/forums/192636-suggestions3https://wpdev.uservoice.com/forums/110705-universal-windows-platform121Source, En-tity/TopicSentence Intended Re-ceiverSentiment Linguistic PropertiesReviews, Electron-icsI would recommend doing the upgrade to be sure youhave the best chance at trouble free operation.Customer Neutral Subjunctive, Imperative,lexical clue: recommendReviews, Electron-icsMy one recommendation to creative is to get some mar-keting people to work on the names of these thingsBrand owner Negative Imperative, lexical clue:recommendationReviews, Hotels Be sure to specify a room at the back of the hotel.
Customer Neutral ImperativeTweets, WindowsPhoneDear Microsoft, release a new zune with your wp7 launchon the 11th.
It would be smartBrand owner Neutral Imperative, subjunctiveDiscussion thread,TravelIf you do book your own airfare, be sure you don?t haveproblems if Insight has to cancel the tour or reschedule itThread partici-pantsNeutral Conditional, imperativeTable 1: Examples of similar linguistic properties in suggestions from different domains, about differententities and topics, and intended for different receiversthe suggestion for improvement posts for theseproducts, and labeled only a subset of them dueto the annotation costs.
Although all the postsare about suggestions, they also comprise ofexplanatory and informative sentences aroundthe suggestion sentences.
With the availabilityof more annotation resources, this dataset can beeasily extended.2) We also prepared a new tweet dataset, wherethe tweets are first collected using the hashtagssuggestion, advice, recommendation, warning,which appeared as top unigram features in ourSVM based classification experiments.
Thissampling method increased the likelihood of thepresence of suggestion tweets as compared to theMicrosoft tweets dataset.Table 2 details all the currently available datasetsincluding the old and the new ones.Sentence Classification: Conventional textclassification approaches, including, rule basedclassifiers, and SVM based classifiers have beenpreviously used for this task.
We employ thesetwo approaches on all the available datasets asbaselines.
In addition to the in-domain trainingand evaluation of statistical classifiers, we alsoperform a cross-domain training and evaluation.The reason for performing a cross domain trainingexperiment is that the suggestions possess similarlinguistic properties irrespective of the domain(Table 1).
Since, it is expensive to prepare dedi-cated training dataset for each domain or use case,we aim for domain independent classificationmodels.We performed a first of its kind study of theemployability of neural network architectures likeLong Short Term Memory (LSTM), and Convo-lutional Neural Nets (CNN) for suggestion detec-tion.
The F-scores for positive class are shownin Table 2.
A neural network based approachseems to be promising compared to the baselineapproaches, specifically in the case of domain in-dependent training.
Our intuition is that the abilityof word embeddings to capture semantic and syn-tactic knowledge, as well as the ability of LSTMto capture word dependencies are the contributingfactors to this.There is a lot of scope for improvement in thecurrent results.
One challenge is that the sen-tences are often longer, whereas the suggestionis present only as a phrase or clause.
Therefore,a future direction is to explore sequential classi-fication approaches in this regard, where we cantag sentences at the word level, and train the clas-sifiers to predict binary labels corresponding towhether a word is a part of suggestion or not.For example, My 1 recommendation 1 is 1 to 1wait 1 on 1 buying 1 one 1 from 1 this 1 com-pany 1 as 0 they 0 will 0 surely 0 get 0 sent 0 a 0message 0 of 0 many 0 returned 0 dvd 0 play-ers 0 after 0 christmas 0.
LSTM NNs have alsobeen proven to be a good choice for sequence la-belling tasks (Huang et al, 2015).3.3 Suggestion Representation andSummarisationIn order to apply suggestion mining to real lifeapplications, a more structured representation ofsuggestions might be required.
After the extrac-tion of suggestion sentences from large datasets,there should be a way to cluster suggestions, linkthem to relevant topics and entities, and sum-marise them.
One way of achieving this is to fur-ther extract information from these sentences, asshown in Table 3.We start with the task of extracting the cen-tral phrase from a suggestion, which either cor-responds to a recommended entity or a suggestedaction.
As a first step in this direction, we experi-mented with keyphrase extraction.
Keyphrase ex-traction has been mainly used for the detection oftopical information, and is therefore noun-based122Dataset IntendedreceiverNo.
of sugges-tionsF1 scoreRules SVM LSTM CNNIn-domain EvaluationHotel Reviews Customers 448 / 7534 0.285 0.543 0.639 0.578Electronics reviews Customers 324 / 3782 0.340 0.640 0.672 0.612Travel advice Thread partici-pants1314 / 5183 0.342 0.566 0.617 0.586Tweets (Microsoft) Brand owner 238 / 3000 0.325 0.616 0.550 0.441New Tweets Public 1126 / 4099 0.266 0.632 0.645 0.661Suggestion Forum Brand owners 1428 / 5724 0.605 0.712 0.727 0.713Cross-domain EvaluationTraining Dataset Test Dataset No.
of sugges-tions (training)F1 scoreRules SVM LSTM CNNSugg-Forum Hotel 1428 / 5724 0.285 0.211 0.452 0.363Sugg-Forum Electronics 1428 / 5724 0.340 0.180 0.516 0.393Sugg-Forum Travel advice 1428 / 5724 0.342 0.273 0.323 0.453Sugg-Forum + Travel advice Hotel 2742 / 10907 0.285 0.306 0.345 0.393Sugg-Forum + Travel advice Electronics 2742 / 10907 0.340 0.259 0.503 0.456New Tweets MicrosoftTweets1126 / 4099 0.325 0.117 0.161 0.122Table 2: Results of suggestion detection across datasets, using different methodsFull suggestion text Entity Beneficiary KeyphraseIf you do end up here, be sure to specifya room at the back of the hotelRoom Customer Specify a room at theback of the hotelIf you are here, I recommend a TrabisafariTrabi Safari Customer Trabi SafariChair upholstry seriously needs to becleanedChair/ChairupholstryBrandownerchair upholstry need tobe cleanedTable 3: Aimed information extraction from suggestions(Hasan and Ng, 2014).
As Table 3 shows, we alsoneed to detect verb based keyphrases in the caseof advice or action based suggestions, however anoun based keyphrase would work in the case ofsuggestions which recommend an entity.In the Table 4, we show the examples ofkeyphrases extracted using TextRank (Mihalceaand Tarau, 2004) algorithm on 3 different re-view datasets, i.e.
ebook reader, camera, and ho-tel.
TextRank and almost all of the keyphraseextraction algorithms rely on the occurrenceand co-occurrence of candidate keyphrases (nounphrases) in a given corpus.
We ran TextRankon the reviews and obtained a set of keyphrase.Table 4 shows whether the central phrases con-tained in a suggestion from the dataset were de-tected as a keyphrase by the algorithm or not.In the case of suggestion for improvement i.e.sentence 1, TextRank is able to capture relevantnoun keyphrases.
This can be attributed to a largenumber of sentences in the corpus which mentionprice, which is an important aspect of the reviewedentity.
However, in the case of suggestions whichare addressed to the other customers, reviewers of-ten speak about aspects which do not appear fre-quently in reviews.
This can be observed in sen-tence 2 and 3, where the keyphrase were not de-tected.We plan to include keyphrase annotations tothe sequence labels mentioned in section 3.2, inorder to identify the suggestions as well as thekeyphrases within those suggestions at the sametime.After the representation of suggestions in theproposed format, we plan to use the methods fortext similarity and relatedness in order to clustersimilar suggestions.Suggestions ExtractedkeyphraseDesiredkeyphraseLook around and compareprice...the price of the Nookvaries widely between stores.Price compare priceI suggest that you purchase ad-ditional memorynone purchase addi-tional memoryWould recommend the KohiNoor indian around the corner,book in advance as it is smalland well used by locals.none Kohi Noor In-dian, book inadvanceTable 4: Sample results from keyphrase extractionusing the textRank algorithm4 Related WorkTo the best of our knowledge, all of the relatedwork so far focussed on research question 2, i.e.detection of suggestions in a given text.
In recentyears, only a limited number of experiments have123been performed in this regard, all of which framethe task as a sentence classification task.Suggestion Detection: Ramanand et al (2010)and Brun et al (2013) employed manually craftedlinguistic rules to identify suggestions for productimprovement.
Dong et al (2013) performed clas-sification of given tweets about Microsoft Win-dows?
phone as suggestions for improvement ornot.
Wicaksono et al (Wicaksono and Myaeng,2013) detected advice containing sentences fromtravel related discussion threads.
They employedsequential classifiers, based on Hidden MarkovModel, and Conditional Random Fields.
Most ofthe datasets are not available, and annotations forthe available datasets are ambiguous with no de-tailed definition of what is considered as a sugges-tion or advice.Text Classification using deep learning: Recentadvances in the application of Neural Networks(NNs) to NLP tasks demonstrate their effective-ness in some of the text classification problems,like sentiment classification, pos tagging, and se-mantic categorisation.
Long Short Term Mem-ory NNs (Graves, 2012), and Convolutional NNs(Kim, 2014) are the two most popular neural net-work architectures in this regard.
An end to endcombination of CNN and LSTM (Zhou et al,2015) has also shown improved results for senti-ment analysis.5 ConclusionIn this work we presented a research plan on sug-gestion mining.
The problem in itself introducesa novel information mining task.
Several usefuldatasets have already been released, with more tocome.
The related work in this direction is verylimited, and has so far focussed on only one aspectof the problem.
Our proposal proposes researchcontributions in three research aspects/questions,and presents initial results and analysis.Since suggestions tend to exhibit similar lin-guistic structure, irrespective of topics and in-tended receiver of the suggestions, there is a scopeof learning domain independent models for sug-gestion detection.
Therefore, we test the discussedapproaches both in a domain-independent settingas well, in order to test the domain-independenceof models learnt in these approaches.
Neural net-works in general outperformed the results on ex-isting test datasets, in both domain dependent andindependent training.
In light of these findings,building neural network based classification archi-tectures for intra-domain feature learning can bean interesting future direction for us.The results also point towards the challengesand complexity of the task of suggestion mining.Building word level suggestion tagged datasetsseems to be a promising direction in this regard,which can simultaneously address the tasks of sug-gestion detection and as keyphrase extraction forsuggestion mining.Our research findings and datasets can alsobe employed to similar problems, like classifica-tion of speech acts, summarisation, verb basedkeyphrase extraction, and cross domain classifica-tion model learning.AcknowledgementsThis work has been funded by the EuropeanUnions Horizon 2020 programme under grantagreement No 644632 MixedEmotions, and theScience Foundation Ireland under Grant NumberSFI/12/RC/2289 (Insight Center).References[Asher et al2009] Nicholas Asher, Farah Benamara,and Yannick Mathieu.
2009.
Appraisal of Opin-ion Expressions in Discourse.
Lingvistic Investiga-tiones, 31.2:279?292.
[Brun and Hagege2013] C. Brun and C. Hagege.
2013.Suggestion mining: Detecting suggestions for im-provements in users comments.
In Proceedings of14th International Conference on Intelligent TextProcessing and Computational Linguistics.
[Dong et al2013] Li Dong, Furu Wei, Yajuan Duan, Xi-aohua Liu, Ming Zhou, and Ke Xu.
2013.
The au-tomated acquisition of suggestions from tweets.
InMarie desJardins and Michael L. Littman, editors,AAAI.
AAAI Press.
[Graves2012] Alex Graves.
2012.
Supervised se-quence labelling.
In Supervised Sequence La-belling with Recurrent Neural Networks, pages 5?13.
Springer Berlin Heidelberg.
[Hasan and Ng2014] Kazi Saidul Hasan and VincentNg.
2014.
Automatic keyphrase extraction: A sur-vey of the state of the art.
In Proceedings of the52nd Annual Meeting of the Association for Compu-tational Linguistics (Volume 1: Long Papers), pages1262?1273, Baltimore, Maryland, June.
Associationfor Computational Linguistics.
[Huang et al2015] Zhiheng Huang, Wei Xu, and KaiYu.
2015.
Bidirectional LSTM-CRF models for se-quence tagging.
CoRR, abs/1508.01991.124[Kim2014] Yoon Kim.
2014.
Convolutional neuralnetworks for sentence classification.
arXiv preprintarXiv:1408.5882.
[Mihalcea and Tarau2004] R. Mihalcea and P. Tarau.2004.
TextRank: Bringing order into texts.
In Pro-ceedings of EMNLP-04and the 2004 Conference onEmpirical Methods in Natural Language Process-ing, July.
[Negi and Buitelaar2015a] Sapna Negi and Paul Buite-laar.
2015a.
Curse or boon?
presence of subjunctivemood in opinionated text.
In Proceedings of the 11thInternational Conference on Computational Seman-tics, pages 101?106, London, UK, April.
Associa-tion for Computational Linguistics.
[Negi and Buitelaar2015b] Sapna Negi and Paul Buite-laar.
2015b.
Towards the extraction of customer-to-customer suggestions from reviews.
In Proceed-ings of the 2015 Conference on Empirical Methodsin Natural Language Processing, pages 2159?2167,Lisbon, Portugal, September.
Association for Com-putational Linguistics.
[Negi et al2016] Sapna Negi, Kartik Asooja, ShubhamMehrotra, and Paul Buitelaar.
2016.
A distant su-pervision approach to semantic role labeling.
InProceedings of the Fifth Joint Conference on Lexi-cal and Computational Semantics, Berlin, Germany,August.
Association for Computational Linguistics.
[Ramanand et al2010] J Ramanand, Krishna Bhavsar,and Niranjan Pedanekar.
2010.
Wishful thinking -finding suggestions and ?buy?
wishes from productreviews.
In Proceedings of the NAACL HLT 2010Workshop on Computational Approaches to Analy-sis and Generation of Emotion in Text, pages 54?61,Los Angeles, CA, June.
Association for Computa-tional Linguistics.
[Searle1969] John R. Searle.
1969.
Speech Acts: AnEssay in the Philosophy of Language.
CambridgeUniversity Press, Cambridge, London.
[Wicaksono and Myaeng2013] Alfan Farizki Wicak-sono and Sung-Hyon Myaeng.
2013.
Automaticextraction of advice-revealing sentences foradvicemining from online forums.
In K-CAP, pages 97?104.
ACM.
[Zhang et al2011] Renxian Zhang, Dehong Gao, andWenjie Li.
2011.
What are tweeters doing: Recog-nizing speech acts in twitter.
In Analyzing Microtext,volume WS-11-05 of AAAI Workshops.
AAAI.
[Zhou et al2015] Chunting Zhou, Chonglin Sun,Zhiyuan Liu, and Francis C. M. Lau.
2015.
AC-LSTM neural network for text classification.CoRR, abs/1511.08630.125
