Proceedings of the ACL 2007 Student Research Workshop, pages 49?54,Prague, June 2007. c?2007 Association for Computational LinguisticsLogistic Online Learning Methods and Their Application toIncremental Dependency ParsingRichard JohanssonDepartment of Computer ScienceLund UniversityLund, Swedenrichard@cs.lth.seAbstractWe investigate a family of update methodsfor online machine learning algorithms forcost-sensitive multiclass and structured clas-sification problems.
The update rules arebased on multinomial logistic models.
Themost interesting question for such an ap-proach is how to integrate the cost functioninto the learning paradigm.
We propose anumber of solutions to this problem.To demonstrate the applicability of the al-gorithms, we evaluated them on a numberof classification tasks related to incrementaldependency parsing.
These tasks were con-ventional multiclass classification, hiearchi-cal classification, and a structured classifica-tion task: complete labeled dependency treeprediction.
The performance figures of thelogistic algorithms range from slightly lowerto slightly higher than margin-based onlinealgorithms.1 IntroductionNatural language consists of complex structures,such as sequences of phonemes, parse trees, and dis-course or temporal graphs.
Researchers in NLP havestarted to realize that this complexity should be re-flected in their statistical models.
This intuition hasspurred a growing interest of related research in themachine learning community, which in turn has ledto improved results in a wide range of applicationsin NLP, including sequence labeling (Lafferty et al,2001; Taskar et al, 2006), constituent and depen-dency parsing (Collins and Duffy, 2002; McDon-ald et al, 2005), and logical form extraction (Zettle-moyer and Collins, 2005).Machine learning research for structured prob-lems have generally used margin-based formula-tions.
These include global batch methods such asMax-margin Markov Networks (M3N) (Taskar et al,2006) and SVMstruct (Tsochantaridis et al, 2005)as well as online methods such as Margin InfusedRelaxed Algorithm (MIRA) (Crammer and Singer,2003) and the Online Passive-Aggressive Algorithm(OPA) (Crammer et al, 2006).
Although the batchmethods are formulated very elegantly, they do notseem to scale well to the large training sets prevalentin NLP contexts.
The online methods on the otherhand, although less theoretically appealing, can han-dle realistically sized data sets.In this work, we investigate whether logisticonline learning performs as well as margin-basedmethods.
Logistic models are easily extended to us-ing kernels; that this is theoretically well-justifiedwas shown by Zhu and Hastie (2005), who alsomade an elegant argument that margin-based meth-ods are in fact related to regularized logistic models.For batch learning, there exist several learning algo-rithms in a logistic framework for conventional mul-ticlass classification but few for structured problems.Prediction of complex structures is conventionallytreated as a cost-sensitive multiclass classificationproblem, although special care has to be taken tohandle the large space of possible outputs.
The in-tegration of the cost function into the logistic frame-work leads to two distinct (although related) updatemethods: the Scaled Prior Variance (SPV) and theMinimum Expected Cost (MEC) updates.Apart from its use in structured prediction, cost-sensitive classification is useful for hierachical clas-sification, which we briefly consider here in an ex-periment.
This type of classification has useful ap-49plications in NLP.
Apart from the obvious use inclassification of concepts in an ontology, it is alsouseful for prediction of complex morphological ornamed-entity tags.
Cost-sensitive learning is alsorequired in the SEARN algorithm (Daum?
III et al,2006), which is a method to decompose the predic-tion problem of a complex structure into a sequenceof actions, and train the search in the space of actionsequences to maximize global performance.2 AlgorithmWe model the learning problem as finding a discrim-inant function F that assigns a score to each possibleoutput y given an input x.
Classification in this set-ting is done by finding the y?
that maximizes F (x, y).In this work, we consider linear discriminants of thefollowing form:F (x, y) = ?w,?
(x, y)?Here, ?
(x, y) is a numeric feature representation ofthe pair (x, y) and w a vector of feature weights.Learning in this case is equivalent to assigning ap-propriate weights in the vector w.In the online learning framework, the weight vec-tor is constructed incrementally.
Algorithm 1 showsthe general form of the algorithm.
It proceeds anumber of times through the training set.
In eachstep, it computes an update to the weight vectorbased on the current example.
The resulting weightvector tends to be overfit to the last few examples;one way to reduce overfitting is to use the averageof all successive weight vectors as the result of thetraining (Freund and Schapire, 1999).Algorithm 1 General form of online algorithmsinput Training set T = {(xt, yt)}Tt=1Number of iterations Nfor n in 1..Nfor (xt, yt) in TCompute update vector ?w for (xt, yt)w ?
w + ?wreturn waverageFollowing earlier online learning methods such asthe Perceptron, we assume that in each update step,we adjust the weight vector by incrementally addingfeature vectors.
For stability, we impose the con-straint that the sum of the updates in each step shouldbe zero.
We assume that the possible output valuesare {yi}mi=0 and, for convenience, that y0 is the cor-rect value.
This leads to the following ansatz:?w =m?j=1?j(?
(x, y0)??
(x, yj))Here, ?j defines how much F is shifted to favor y0instead of yj .
This is also the approach (implicitly)used by other algorithms such as MIRA and OPA.The following two subsections present two waysof creating the weight update ?w, differing in howthe cost function is integrated into the model.
Bothare based on a multinomial logistic framework,where we model the probability of the class y beingassigned to an input x using a ?soft-max?
functionas follows:P (y|x) = eF (x,y)?mj=0 eF (x,yj)2.1 Scaled Prior Variance ApproachThe first update method, Scaled Prior Variance(SPV), directly uses the probability of the correctoutput.
It uses a maximum a posteriori approach,where the cost function is used by the prior.Na?vely, the update could be done by maximizingthe likelihood with respect to ?
in each step.
How-ever, this would lead to overfitting ?
in the case ofseparability, a maximum does not even exist.
Wethus introduce a regularizing prior that penalizeslarge values of?.
We introduce variance-controllinghyperparameters sj for each ?j , and with a Gaussianprior we obtain (disregarding constants) the follow-ing log posterior:L(?)
=m?j=1?j(K00 ?Kj0)?m?j=1sj?2j?
logm?k=0efk+Pmj=1 ?j(K0k?Kjk)where Kij = ??
(x, yi),?
(x, yj)?
and fk =F (x, yk) (i.e.
the output before w is updated).As usual, the feature vectors occur only in innerproducts, allowing us to use kernels if appropriate.50We could have used any prior; however, in prac-tice we will require it to be log-concave to avoidsuboptimal local maxima.
A Laplacian prior (i.e.?
?mj=1 sj|?j |) will also be considered in this work?
the discontinuity of its gradient at the origin seemsto pose no problem in practice.Costs are incorporated into the model by as-sociating them to the prior variances.
We triedtwo variants of variance scaling.
In the first case,we let the variance be directly proportional to thecost (C-SPV):sj =?c(yj)where ?
is a tradeoff parameter controlling the rel-ative weight of the prior with respect to the likeli-hood.
Intuitively, this model allows the algorithmmore freedom to adjust an ?j associated with a yjwith a high cost.In the second case, inspired by margin-basedlearning we instead scaled the variance by the loss,i.e.
the scoring error plus the cost (L-SPV):sj =?max(0, fj ?
f0) + c(yj)Here, the intuition is instead that the algorithm isallowed more freedom for ?dangerous?
outputs thatare ranked high but have high costs.2.2 Minimum Expected Cost ApproachIn the second approach to integrating the cost func-tion, the Minimum Expected Cost (MEC) update,the method seeks to minimize the expected cost ineach step.
Once again using the soft-max probabil-ity, we get the following expectation of the cost:E(c(y)|x) =m?k=0c(yk)P (yk|x)=?mk=0 c(yk)efk+Pmj=1 ?j(K0k?Kjk)?mk=0 efk+Pmj=1 ?j(K0k?Kjk)This quantity is easily minimized in the same wayas the SPV posterior was maximized, althoughwe had to add a constant 1 to the expectation toavoid numerical instability.
To avoid overfitting, weadded a quadratic regularizer ?
?mj=1 ?2j to log(1 +E(c(y)|x)) just like the prior in the SPV method,although this regularizer does not have an interpre-tation as a prior.The MEC update is closely related to SPV: forcost-insensitive classification (i.e.
the cost of everymisclassified instance is 1), the expectation is equalto one minus the likelihood in the SPV model.2.3 Handling Complex Prediction ProblemsThe algorithm can thus be used for any cost-sensitive classification problem.
This class of prob-lems includes prediction of complex structures suchas trees or graphs.
However, for those problems theset of possible outputs is typically very large.
Twobroad categories of solutions to this problem havebeen common in literature, both of which rely onthe structure of the domain:?
Subset selection: instead of working with thecomplete range of outputs, only an ?interest-ing?
subset is used, for instance by repeatedlyfinding the most violated constraints (Tsochan-taridis et al, 2005) or by using N -best search(McDonald et al, 2005).?
Decomposition: the inherent structure of theproblem is used to factorize the optimiza-tion problem.
Examples include Markov de-compositions in M3N (Taskar et al, 2006)and dependency-based factorization for MIRA(McDonald et al, 2005).In principle, both methods could be used in ourframework.
In this work, we use subset selec-tion since it is easy to implement for many do-mains (in the form of an N -best search) and al-lows a looser coupling between the domain and thelearning algorithm.2.4 Implementation IssuesSince we typically work with only a few variables ineach iteration, maximizing the log posterior or mini-mizing the expectation is easy (assuming, of course,that we chose a log-concave prior).
We used gra-dient ascent and did not try to use more sophisti-cated optimization procedures like BFGS or New-ton?s method.
Typically, only a few iterations wereneeded to reach the optimum.
The running time ofthe update step is almost identical to that of MIRA,which solves a small quadratic program in each step,but longer than for the Perceptron algorithm or OPA.51Actions Parser actions ConditionsInitialize (nil,W, ?
)Terminate (S, nil, A)Left-arc (n|S, n?|I,A)?
(S, n?|I,A ?
{(n?, n)}) ??n??(n?
?, n) ?
ARight-arc (n|S, n?|I,A)?
(n?|n|S, I,A ?
{(n, n?)})
??n??(n?
?, n?)
?
AReduce (n|S, I,A)?
(S, I,A) ?n?
(n?, n) ?
AShift (S, n|I,A)?
(n|S, I,A)Table 1: Nivre?s parser transitions where W is the initial word list; I , the current input word list; A, thegraph of dependencies; and S, the stack.
(n?, n) denotes a dependency relations between n?
and n, where n?is the head and n the dependent.3 ExperimentsTo compare the logistic online algorithms againstother learning algorithms, we performed a set of ex-periments in incremental dependency parsing usingthe Nivre algorithm (Nivre, 2003).The algorithm is a variant of the shift?reduce al-gorithm and creates a projective and acyclic graph.As with the regular shift?reduce, it uses a stack Sand a list of input words W , and builds the parsetree incrementally using a set of parsing actions (seeTable 1).
However, instead of finding constituents,it builds a set of arcs representing the graph of de-pendencies.
It can be shown that every projectivedependency graph can be produced by a sequenceof parser actions, and that the worst-case number ofactions is linear with respect to the number of wordsin the sentence.3.1 Multiclass ClassificationIn the first experiment, we trained multiclass clas-sifiers to choose an action in a given parser state(see (Nivre, 2003) for a description of the featureset).
We stress that this is true multiclass classifica-tion rather than a decomposed method (such as one-versus-all or pairwise binarization).As a training set, we randomly selected 50,000instances of state?action pairs generated for adependency-converted version of Penn Treebank.This training set contained 22 types of actions (suchas SHIFT, REDUCE, LEFT-ARC(SUBJECT), andRIGHT-ARC(OBJECT).
The test set was also ran-domly selected and contained 10,000 instances.We trained classifiers using the logistic updates(C-SPV, L-SPV, and MEC) with Gaussian andLaplacian priors.
Additionally, we trained OPAand MIRA classifiers, as well as an Additive Ultra-conservative (AU) classifier (Crammer and Singer,2003), a variant of the Perceptron.For all algorithms, we tried to find the best val-ues of the respective regularization parameter usingcross-validation.
All training algorithms iterated fivetimes through the training set and used an expandedquadratic kernel.Table 2 shows the classification error for all algo-rithms.
As can be seen, the performance was lowerfor the logistic algorithms, although the differencewas slight.
Both the logistic (MEC and SPV) andthe margin-based classifiers (OPA and MIRA) out-performed the AU classifier.Method Test errorMIRA 6.05%OPA 6.17%C-SPV, Laplace 6.20%MEC, Laplace 6.21%C-SPV, Gauss 6.22%MEC, Gauss 6.23%L-SPV, Laplace 6.25%L-SPV, Gauss 6.26%AU 6.39%Table 2: Multiclass classification results.3.2 Hierarchical ClassificationIn the second experiment, we used the same train-ing and test set, but considered the selection of theparsing action as a hierarchical classficiation task,i.e.
the predicted value has a main type (SHIFT,REDUCE, LEFT-ARC, and RIGHT-ARC) and possi-bly also a subtype (such as LEFT-ARC(SUBJECT) or52RIGHT-ARC(OBJECT)).To predict the class in this experiment, we usedthe same feature function but a new cost function:the cost of misclassification was 1 for an incorrectparsing action, and 0.5 if the action was correct butthe arc label incorrect.We used the same experimental setup as in themulticlass experiment.
Table 3 shows the averagecost on the test set for all algorithms.
Here, theMEC update outperformed the margin-based onesby a negligible difference.
We did not use AU inthis experiment since it does not optimize for cost.Method Average costMEC, Gauss 0.0573MEC, Laplace 0.0576OPA 0.0577C-SPV, Gauss 0.0582C-SPV, Laplace 0.0587MIRA 0.0590L-SPV, Gauss 0.0590L-SPV, Laplace 0.0632Table 3: Hierarchical classification results.3.3 Prediction of Complex StructuresFinally, we made an experiment in prediction of de-pendency trees.
We created a global model wherethe discriminant function was trained to assign highscores to the correct parse tree.
A similar model waspreviously used by McDonald et al (2005), with thedifference that we here represent the parse tree asa sequence of actions in the incremental algorithmrather than using the dependency links directly.For a sentence x and a parse tree y, we definedthe feature representation by finding the sequence((S1, I1) , a1) , ((S2, I2) , a2) .
.
.
of states and theircorresponding actions, and creating a feature vectorfor each state/action pair.
The discriminant functionwas thus written??
(x, y),w?
=?i??
((Si, Ii) , ai),w?where ?
is the feature function from the previoustwo experiments, which assigns a feature vector to astate (Si, Ii) and the action ai taken in that state.The cost function was defined as the sum of linkcosts, where the link cost was 0 for a correct depen-dency link with a correct label, 0.5 for a correct linkwith an incorrect label, and 1 for an incorrect link.Since the history-based feature set used in theparsing algorithm makes it impossible to use inde-pendence to factorize the scoring function, an exactsearch to find the best-scoring action sequence is notpossible.
We used a beam search of width 2 in thisexperiment.We trained models on a 5000-word subset of theBasque Treebank (Aduriz et al, 2003) and evalu-ated them on a 8000-word subset of the same cor-pus.
As before, we used an expanded quadratic ker-nel, and all algorithms iterated five times through thetraining set.Table 4 shows the results of this experiment.
Weshow labeled accuracy instead of cost for ease of in-terpretation.
Here, the loss-based SPV outperformedMethod Labeled AccuracyL-SPV, Gauss 66.24MIRA 66.19MEC, Gauss 65.99C-SPV, Gauss 65.84OPA 65.45MEC, Laplace 64.81C-SPV, Laplace 64.73L-SPV, Laplace 64.50Table 4: Results for dependency tree prediction.MIRA, and two other logistic updates also outper-formed OPA.
The differences between the first fourscores are however not statistically significant.
In-terestingly, all updates with Laplacian prior resultedin low performance.
The reason for this may be thatLaplacian priors tend to promote sparse solutions(see Krishnapuram et al (2005), inter alia), and thatthis sparsity is detrimental for this highly lexicalizedfeature set.4 Conclusion and Future WorkThis paper presented new update methods for onlinemachine learning algorithms.
The update methodsare based on a multinomial logistic model.
Theirperformance is on par with other state-of-the-art on-line learning algorithms for cost-sensitive problems.53We investigated two main approaches to integrat-ing the cost function into the logistic model.
In thefirst method, the cost was linked to the prior vari-ances, while in the second method, the update rulesets the weights to minimize the expected cost.
Wetried a few different priors.
Which update methodand which prior was the best varied between exper-iments.
For instance, the update where the priorvariances were scaled by the costs was the best-performing in the multiclass experiment but theworst-performing in the dependency tree predictionexperiment.In the SPV update, the cost was incorporated intothe MAP model in a rather ad-hoc fashion.
Al-though this seems to work well, we would like toinvestigate this further and possibly devise a cost-based prior that is both theoretically well-groundedand performs well in practice.To achieve a good classification performance us-ing the updates presented in this article, there is aconsiderable need for cross-validation to find thebest value for the regularization parameter.
This istrue for most other classification methods as well,including SVM, MIRA, and OPA.
There has beensome work on machine learning methods where thisparameter is tuned automatically (Tipping, 2001),and a possible extension to our work could be toadapt those models to the multinomial and cost-sensitive setting.We applied the learning models to three problemsin incremental dependency parsing, the last of whichbeing prediction of full labeled dependency trees.Our system can be seen as a unification of the twobest-performing parsers presented at the CoNLL-XShared Task (Buchholz and Marsi, 2006).ReferencesItzair Aduriz, Maria Jesus Aranzabe, Jose Mari Arriola,Aitziber Atutxa, Arantza Diaz de Ilarraza, AitzpeaGarmendia, and Maite Oronoz.
2003.
Constructionof a Basque dependency treebank.
In Proceedings ofthe TLT, pages 201?204.Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-Xshared task on multilingual dependency parsing.
InProceedings of the CoNLL-X.Michael Collins and Nigel Duffy.
2002.
New rankingalgorithms for parsing and tagging: Kernels over dis-crete structures, and the voted perceptron.
In Proceed-ings of the ACL.Koby Crammer and Yoram Singer.
2003.
Ultraconserva-tive online algorithms for multiclass problems.
Jour-nal of Machine Learning Research, 2003(3):951?991.Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Schwartz, and Yoram Singer.
2006.
Online passive-aggressive algorithms.
Journal of Machine LearningResearch, 2006(7):551?585.Hal Daum?
III, John Langford, and Daniel Marcu.
2006.Search-based structured prediction.
Submitted.Yoav Freund and Robert E. Schapire.
1999.
Large mar-gin classification using the perceptron algorithm.
Ma-chine Learning, 37(3):277?296.Balaji Krishnapuram, Lawrence Carin, M?rio A. T.Figueiredo, and Alexander J. Hartemink.
2005.Sparse multinomial logistic regression: Fast algo-rithms and generalization bounds.
IEEE Transactionson Pattern Analysis and Machine Intelligence, 27(6).John Lafferty, Andrew McCallum, and Fernando Pereira.2001.
Conditional random fields: Probabilistic mod-els for segmenting and labeling sequence data.
In Pro-ceedings of the 18th International Conference on Ma-chine Learning.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic?.
2005.
Non-projective dependency pars-ing using spanning tree algorithms.
In Proceedingsof HLT-EMNLP-2005.Joakim Nivre.
2003.
An efficient algorithm for projec-tive dependency parsing.
In Proceedings of the 8th In-ternational Workshop on Parsing Technologies (IWPT03), pages 149?160, Nancy, France, 23-25 April.Ben Taskar, Carlos Guestrin, Vassil Chatalbashev, andDaphne Koller.
2006.
Max-margin Markov networks.Journal of Machine Learning Research, to appear.Michael E. Tipping.
2001.
Sparse Bayesian learningand the relevance vector machine.
Journal of MachineLearning Research, 1:211 ?
244.Iannis Tsochantaridis, Thorsten Joachims, Thomas Hof-mann, and Yasemin Altun.
2005.
Large margin meth-ods for structured and interdependent output variables.Journal of Machine Learning Research, 6(Sep):1453?1484.Luke S. Zettlemoyer and Michael Collins.
2005.
Learn-ing to map sentences to logical form: Structured clas-sification with probabilistic categorial grammars.
InProceedings of UAI 2005.Ji Zhu and Trevor Hastie.
2005.
Kernel logistic regres-sion and the import vector machine.
Journal of Com-putational and Graphical Statistics, 14(1):185?205.54
