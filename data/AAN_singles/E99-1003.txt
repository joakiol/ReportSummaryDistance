!Proceedings of EACL '99TERM EXTRACTION + TERM CLUSTERING:An Integrated Platform for Computer-Aided TerminologyDidier BourigaultERSS, UMR 5610 CNRSMaison de la Recherche5 all4es Antonio Machado31058 Toulouse cedex, FRANCEdidier ,  bourigault @wanadoo.
f rChristian JacqueminLIMSI-CNRSBP 13391403 ORSAYFRANCEj acquemin@limsi, frAbstractA novel technique for automatic the-saurus construction is proposed.
It isbased on the complementary use of twotools: (1) a Term Extraction tool thatacquires term candidates from taggedcorpora through a shallow grammar ofnoun phrases, and (2) a Term Cluster-ing tool that groups syntactic variants(insertions).
Experiments performed oncorpora in three technical domains yieldclusters of term candidates with preci-sion rates between 93% and 98%.1 Computat iona l  Termino logyIn the domain of corpus-based terminology twotypes of tools are currently developed: toolsfor automatic term extraction (Bourigault, 1993;Justeson and Katz, 1995; Daille, 1996; Brun,1998) and tools for automatic thesaurus construc-tion (Grefenstette, 1994).
These tools are ex-pected to be complementary in the sense thatthe links and clusters proposed in automatic the-saurus construction can be exploited for structur-ing the term candidates produced by the auto-matic term extractors.
In fact, complementarityis difficult because term extractors provide mainlymulti-word terms, while tools for automatic the-saurus construction yield clusters of single-wordterms.On the one hand, term extractors focus onmulti-word terms for ontological motivations:single-word terms are too polysemous and toogeneric and it is therefore necessary to providethe user with multi-word terms that representfiner concepts in a domain.
The counterpart ofthis focus is that automatic term extractors yieldimportant volumes of data that require structur-ing through a postprocessor.
On the other hand,tools for automatic thesaurus construction focuson single-word terms for practical reasons.
Sincethey cluster terms through statistical measuresof context similarities, these tools exploit recur-ring situations.
Since single-word terms denotebroader concepts than multi-word terms, they ap-pear more frequently in corpora and are thereforemore appropriate for statistical clustering.The contribution of this paper is to proposean integrated platform for computer-aided termextraction and structuring that results from thecombination of LEXTER, a Term Extraction tool(Bouriganlt et al, 1996), and FASTR 1, a TermNormalization tool (Jacquemin et al, 1997).2 Components of the Platform forComputer-Aided TerminologyThe platform for computer-aided terminology isorganized as a chain of four modules and the cor-responding flowchart is given by Figure 1.
Themodules are:POS tagging First the corpus is processed bySylex, a Part-of-Speech tagger.
Each word isunambiguously tagged and receives a singlelemma.Term Ext ract ion  LEXTER, the term extrac-tion tool acquires term candidates from thetagged corpus.
In a first step, LEXTER ex-ploits the part-of-speech categories for ex-tracting maximal-length noun phrases.
It re-lies on makers of frontiers together with ashallow grammar of noun phrases.
In a sec-ond step, LEXTER recursively decomposesthese maximal-length noun phrases into twosyntactic onstituents (Head and Expansion).Term Cluster ing The term clustering toolgroups the term candidates produced at the* FA  STR can be downloadedwww.
limsi, fr/Individu/j acquemi/FASTK.from15Proceedings of EACL '99Raw corpusP-O-Ssy/exTagging ~ \]IL,emmatizcd and tagged corpusTerm ExtractionLEXTERINetwork of term candidatesTerm ClusteringFASTRJ Expert\[ Interlace IStructured ~rminology ~dal~Figure 1: Overview of the platform for computer-aided terminologypreceding step through a self-indexing proce-dure followed by a graph-based classification.This task is basically performed by FASTR,a term normalizer, that has been adapted tothe task at hand.~F- : !e t ion  The last step of thesaurus construc-tion is the validation of automatically ex-tracted clusters of term candidates by a ter-minologist and a domain expert.
The vali-dation is performed through a data-base in-terface.
The links are automatically updatedthrough the entire base and a structured the-saurus is progressively constructed.The following sections provide more detailsabout the components and evaluate the qualityof the terms thus extracted.3 Term Ext ract ion3.1 Term Ext ract ion  for the  FrenchLanguageTerm extraction tools perform statistical or/andsyntactical analysis of text corpora in special-ized technical or scientific domains.
Term can-didates correspond to sequences of words (mostof the time noun phrases) that are likely to beterminological units.
These candidates are ulti-mately validated as entries by a terminologist incharge of building a thesaurus.
LEXTER, theterm extractor, is applied to the French language.Since French is a Romance language, the syntac-tic structure of terms and compounds i very sim-ilar to the structure of non-compound and non-terminological noun phrases.
For instance, inFrench, terms can contain prepositional phraseswith determiners such as: paroiNoun deprep /'Deturet~reNoun (ureteral wall).
Because of this simi-larity, the detection of terms and their variants inFrench is more difficult than in the English lan-guage.The input of our term extraction tool is an un-ambiguously tagged corpus.
The extraction pro-cess is composed of two main steps: Splitting andParsing.3.2 Spl i t t ingThe techniques of shallow parsing implementedin the Splitting module detect morpho-syntacticalpatterns that cannot be parts of terminologicalnoun phrases and that are therefore likely to in-dicate noun phrases boundaries.
Splitting tech-niques are used in other shallow parsers such as(Grefenstette, 1992).
In the case of LEXTER, thenoun phrases which are isolated by splitting arenot intermediary data; they are not used by anyother automatic module in order to index or clas-sify documents.
The extracted noun phrases areterm candidates which are proposed to the user.In such a situation, splitting must be performedwith high precision.In order to process correctly some problem-atic splittings, such as coordinations, attribu-tive past participles and sequences preposition+ determiner, the system acquires and usescorpus-based selection restrictions of adjectivesand nouns (Bourigault et al, 1996).For example, in order to disambiguate PP-attachments, the system possesses a corpus-based list of adjectives which accept a preposi-tional argument built with the preposition h (at).These selectional restrictions are acquired throughCorpus-Based Endogenous Learning (CBEL) asfollows: During a first pass, all the adjectives in apredicative position followed by the preposition hare collected.
During a second pass, each time asplitting rule has eliminated a sequence beginningwith the preposition el, the preceding adjective isdiscarded from the list.
Empirical analyses con-firm the validity of this procedure.
More complexprocedures of CBEL are implemented into LEX-TER in order to acquire nouns sub-categorizingthe preposition h or the preposition sur (on), ad-jectives sub-categorizing the preposition de (of),past participles ub-categorizing the prepositionde (of), etc.Ultimately, the Splitting module produces a setof text sequences, mostly noun phrases, which we16Proceedings of EACL '99refer to as Maximal-Length Noun Phrases (hence-forth MLNP).3.3 Pars ingThe Parsing module recursively decomposes themaximal-length noun phrases into two syntac-tic constituents: a constituent in head-position(e.g.
bronchial cell in the noun phrase cylindri-cal bronchial cell, and cell in the noun phrasebronchial cell), and a constituent in expansion po-sition (e.g.
cylindrical in the noun phrase cylin-drical bronchial cell, and bronchial in the nounphrase bronchial cell).
The Parsing module ex-ploits rules in order to extract wo subgroups fromeach MLNP, one in head-position and the otherone in expansion position.
Most of MLNP se-quences are ambiguous.
Two (or more) binarydecompositions compete, corresponding to severalpossibilities of prepositional phrase or adjectiveattachment.
The disambiguation is performed bya corpus-based method which relies on endoge-nous learning procedures (Bouriganlt, 1993; Rat-naparkhi, 1998).
An example of such a procedureis given in Figure 2.3.4 Network  of  term candidatesThe sub-groups generated by the Parsing module,together with the maximal-length noun phrasesextracted by the Splitting module, are the termcandidates produced by the Term extraction tool.This set of term candidates is represented as anetwork: each multi-word term candidate is con-nected to its head constituent and to its expansionconstituent by syntactic decomposition links.
Anexcerpt of a network of term candidates i givenin Figure 3.
Vertical and horizontal links are syn-tactic decomposition links produced by the TermExtraction tool.
The oblique link is a syntacticvariation link added by the Term Clustering tool.The building of the network is especially im-portant for the purpose of term acquisition.
Theaverage number of multi-word term candidates i8,000 for a 100,000 word corpus.
The feedbackof several experiments in which our Term Extrac-tion tool was used shows that the more structuredthe set of term candidates i , the more efficientlythe validation task is performed.
For example,the structuring through syntactic decompositionallows the system to underscore lists of terms thatshare the same term either in head position or inexpansion position.
Such paradigmatic series arefrequent in term banks, and initiating the valida-tion task by analyzing such lists appears to be avery efficient validation strategy.This paper proposes a novel technique for en-riching the network of term candidates throughcellN 3"0bronchial cell1A2N 3 l\[ Expansion link~ l cylindrical bronchial cellcylindrical ell- IAIN 3Expansion linkbronchialA2I::>-cyf i~calAt1:>.-Figure 3: Excerpt of a network of term candidates.the addition of syntactic variation links to syntac-tic decomposition links.4 Term C lus ter ing4.1 Adapt ing  a Normal i za t ion  Too lTerm normalization is a procedure used in au-tomatic indexing for conflating various term oc-currences into unique canonical forms.
More orless linguistically-oriented techniques are used inthe literature for this task.
Basic proceduressuch as (Dillon and Gray, 1983) rely on functionword deletion, stemming, and alphabetical wordreordering.
For example, the index library cat-alogs is transformed into catalog librar throughsuch simplification techniques.In the platform presented in this paper, termnormalization is performed by FASTR, a shal-low transformational parser which uses linguisticknowledge about the possible morpho-syntactictransformations of canonical terms (Jacquemin etal., 1997).
Through this technique syntacticallyand morphologically-related occurrences, uch asstabilisation de prix (price stabilization) and sta-biliser leurs prix (stabilize their prices), are con-tinted.Term variant extraction in FASTR differs frompreceding works such as (Evans et al, 1991) be-cause it relies on a shallow syntactic analysis ofterm variations instead of window-based measuresof term overlaps.
In (Sparck Jones and Tait, 1984)a knowledge-intensive technique is proposed forextracting term variations.
This approach hashowever never been applied to large scale term ex-traction because it is based on a full semantic anal-ysis of sentences.
Our approach is more realisticbecause it does not involve large-scale knowledge-intensive interpretation of texts that is known tobe unrealistic.Our approach to the clustering of term can-17Proceedings of EACL '99Parsing ruleNoun1 Prep Noun2 Adj -~Parse (1)Head: NoumExp.
: Nouns AdjHead: NounsExp.
: AdjParse (2)Head: Noun1 Prep NounsHead: Noun1Exp.
: NounsExp.
: AdjDisambiguation procedure:Look in the corpus for non ambiguous occurrences of the sub-groups:(a) Noun2 Adj (b) Noun1 Adj (c) Noun1 Prep Noun2Then choose:if the sub-group (a) has been found, then choose Parse (1)else if the sub-groups (b) or (c) have been found, then choose Parse (2)else choose Parse (1)Figure 2: An ambiguous parsing rule and associated isambiguation proceduredidates is to group the output of LEXTER, byconflating term candidates with other term can-didates instead of confiating corpus occurrenceswith controlled terms.
Our technique can be seenas a kind of self-indexing in which term candidatesare indexed by themselves through FASTR, forthe purpose of conflating candidates that are vari-ants of each other.
Thus, the term candidate cel-lule bronchique cylindrique (cylindrical bronchialcell) is a variant of the other candidate cellulecylindrique (cylindrical cell) because an adjecti-val modifier is inserted in the first term.
Throughthe self-indexing procedure these two candidatesbelong to the same cluster.4.2 Types  of  Syntactic Variation RulesBecause of this original framework, specific vari-ations patterns were designed in order to captureinter-term variations.
In this study, we restrictourselves to syntactic variations and ignore mor-phological modifications.
The variations patternscan be classified into the following two families:Internal insertion of modifiers The insertionof one or more modifiers inside a noun phrasestructure.
For instance the following trans-formation NAInsAj:Noun1 Adj2--+ Noun1 ((Adv ?
Adj) 1-3 Adv ?)
Adj2describes the insertion of one to three adjec-tival modifiers inside a Noun-Adjective struc-ture in French.
Through this transforma-tion, the term candidate cellule bronchiquecylindrique (cylindrical bronchial cell) is rec-ognized as a variant of the term candidatecellule cylindrique (cylindrical cell).
Otherinternal modifications account for adverbialand prepositional modifiers.Preposi t ion switch 8?
determiner insertionIn French, terms, compounds, and nounphrases have comparable structures: gen-erally a head noun followed by adjectivalor prepositional modifiers.
Such terms mayvary through lexical changes without signif-icant structural modifications.
For exampleNPNSynt:Noun1 PreI~2 Nouns--4 Noun1 ((Prep Det?)
?)
Noun3accounts for preposition suppressions uchas fibre de collaggne/fibre collaggne (colla-gen fiber), additions of determiners, and/orpreposition switches such as rev~tement desurface / rev~tement en surface (surface coat-ing).The complete rule set is shown in Table 1.
Eachtransformation given in the first column conflatesthe term structure given in the second column andthe term structure given in the third column.4.3 ClusteringThe output of FASTR is a set of links betweenpairs of term candidates in which the target can-didate is a variant of the source candidate.
Inorder to facilitate the validation of links by the ex-pert, this output is converted into clusters of termcandidates.
The syntactic variation links can beconsidered as the edges of an undirected graphwhose nodes are the term candidates.
A node nlrepresenting a term tl is connected to a node n2representing t2 if and only if there is a transfor-mation T such that T(tl) = t2 or T(t2) = tl ?Each connected subgraph Gi of G is considered asa cluster of term candidates likely to correspondto similar concepts.
(A connected subgraph Gi is18Proceedings of EACL '99Table 1: Syntactic variation rules exploited by the Term Clustering tool.Ident.
Base term VariantNAInsAv Noun1 Adj2NAInsAj Noum Adj2NAInsN Noun1 Adj2Noun, ((Adv ?
Adj) 0-s Adv) Adj2Noun1 ((Adv ?
Adj) 1-3 Adv ?)
AdjeNoun1 ((Adv ?
hdj) ?
(Prep ?
Det ?
(Adv ?
Adj) ?
Noun) (Adv ?
Adj) ?
Adv ?)
Adj2ANInsAv Adjl Noun2 (Adv) Adjl Noun2NPNSyntNPNInsAjNPNInsNNoun1 Prep2 Noun3Noun1 Prep2 Noun3Noun1 Prep2 Noun3Nounl ((Prep Det?)
?)
Noun3Noun1 ((Adv ?
Adj) ?-3 Prep Det ?
(Adv ?
Adj)0-3 ) NounsNoun, ((Adv ?
Adj) ?-3 (Prep Det?)
?
(Adv ?
Adj) ?-s Noun(Adv ?
Adj) ?-3 (Prep Det?)
?
(Adv ?
Adj)0-3 ) Noun3NPDNSyntNPDNInsAjNPDNInsNNoun, Prep2 Det4 NounsNoun, Prep2 Det4 Noun3Noun, Prep2 Det4 Noun3Noun, ((Prep Det?)
?)
NounsNOunl ((Adv ?
Adj) ?-3 Prep Det ?
(Adv ?
Adj)0-3 ) Noun3Noun1 ((Adv ?
Adj) ?-3 (Prep Det?)
?
(Adv ?
Adj) ?-3 Noun(Adv ?
Adj) ?-3 (Prep Det?)
?
(Adv ?
Adj)0-3 ) Noun3nucl~ole souvent pro~minent nucl~ole c ntral pro~minentt 3e" '~ nsAv NAInsAj.~'~ t2nucldole pro t~~vt4nucldole parfois pro~rainentFigure 4: A sample 4-term cluster.such that for every pair of nodes (nl,n2) in Gi,there exists a path from nl to n2.
)For example, tl =nucldole prodminent (promi-nent nucleolus), t2 =nucldole central prodminent(prominent central nucleolus), t3 =nucldole sou-vent prodminent (frequently prominent nucleo-lus), and t4 =nucl~ole parfois prodminent (some-times prominent nucleolus) are four term candi-dates that build a star-shaped 4-word cluster il-lustrated by Figure 4.
Each edge is labelled withthe syntactic transformation T that maps one ofthe nodes to the other.5 ExperimentsExperiments were made on three different corporadescribed in Table 2.
The first two lines of Table 2report the size of the corpora and the numberof term candidates extracted by LEXTER fromthese corpora.
The third and fourth lines showthe number of links between term candidates ex-tracted by FASTR and the number of connectedsubgraphs corresponding to these links.
Finally,the last two lines report statistics on the size of theclusters and the ratio of term candidates that be-Table 3: Frequencies of syntactic variations.\[Menel.\] \[Brouss.\] \[DER\]NAInsAv 21% 30% 1%NAInsAj 33% 25% 5%NAInsN 23% 21% 13%ANInsAv 3% 3% 0%NPNSynt  2% 2% 18%NPNInsAj 6% 11% 8%NPNInsN 1% 2% 11%NPDNSynt 1% 2% 22%NPDNInsAj  8% 2% 11%NPDNInsN 2% 2% 11%Total 100% 100% 100%long to one of the subgraphs produced by the clus-tering algorithm.
Although the variation rules im-plemented in the Term Structuring tool are ratherrestrictive (only syntactic insertion has been takeninto account), the number of links added to thenetwork of term candidates i noticeably high.
Anaverage rate of 10% of multi-word term candidatesproduced by LEXTER belong to one of the clus-ters resulting from the recognition of term variantsby FASTR.Frequencies of syntactic variations are reportedin Table 3.
A screen-shot showing the type ofvalidation that is proposed to the expert is givenby Figure 5.6 Expert EvaluationEvaluation was performed by three experts, one ineach domain represented by each corpus.
Theseexperts had already been involved in the con-19Proceedings of EACL '99Table 2: The three corpora exploited in the experiments.\[Broussals\] \[DER\] \[Menelas\]Domain anatomy pathology nuclear engineering coronarian diseasesType of documents medical reports technical reports medical filesNumber of words 40,000Number of multi-word term 3,439candidatesNumber of variation links 240Number of clusters 168Maximal size of the clusters 10Number of term candidates 438 (12.7%)belonging to one cluster230,000 110,00014,037 10,155785 634556 44813 131,349 (9.6%) 1,173 (11.6%)Figure 5: The expert interface for cluster validation20Proceedings of EACL '99struction of terminological products through theanalysis of the three corpora used in our ex-periments: an ontology for a case-memory sys-tem dedicated to the diagnosis upport ~n pathol-ogy (\[Broussais\]), a semantic dictionary for theMenelas Natural Language Understanding sys-tem (\[Menelas\]), and a structured thesaurus for acomputer-assisted t chnical writing tool (\[DER\]).The precision rates are very satisfactory (from93% to 98% corresponding to error rates of 7% and2% given in the last line of Table 4), and show thatthe proposed method must be considered as animportant progress in corpus-based terminology.Only few links are judged as conceptually irrele-vant by the experts.
For example, image d'emboletumorale (image of a tumorous embolus) is notconsidered as a correct variant of image tumorale(image of a tumor) because the first occurrencerefers to an embolus while the second one refersto a tumor.The experts were required to assess the pro-posed links and, in case of positive reply, theywere required to provide a judgment about theactual conceptual relation between the connectedterms.
Although they performed the validation in-dependently, the three experts have proposed verysimilar types of conceptual relations between termcandidates connected by syntactic variation links.At a coarse-grained level, they proposed the samethree types of conceptual relations:Synonymy Both connected terms are consid-ered as equivalent by the expert: emboletumorale (tumorous embolus) / embole vascu-laire tumorale (vascular tumorous embolus).The preceding example corresponds to a fre-quent situation of elliptic synonymy: the no-tion of integrated metonymy (Kleiber, 1989).In the medical domain, it is a common knowl-edge that an embole tumorale is an embolevasculaire tumorale, as everyone knows thatsunflower oil is a synonym of sunflower seedoil.Gener ic /spec i f i c  re lat ion One of the twoterms denotes a concept that is finer thanthe other one: cellule dpithdliale cylindrique(cylindrical epithelial cell) is a specific typeof cellule cylindrique (cylindrical cell).A t t r ibut ive  re lat ion As in the preceding case,there is a non-synonymous semantic relationbetween the two terms.
One of them denotesa concept richer than the other one because itcarries an additional attributes: a noyau vo-lumineux irrdgulier (large irregular nucleus)is a noyau irrdgulier (irregular nucleus) thatis additionally volumineux (large).7 Future  WorkThis study shows that the clustering of term can-didates through term normalization is a powerfultechnique for enriching the network of term can-didates produced by a Term Extraction tool suchas LEXTER.In our approach, term normalization is per-formed through the conflation of specific termvariants.
We have focused on syntactic vari-ants that involve structural modifications (mainlymodifier insertions).
As reported in (Jacquemin,1999), morphological nd semantic variations aretwo other important families of term variationswhich can also be extracted by FASTR.
They willbe accounted for in order to enhance the numberof clustered term candidates.
It is our purpose tofocus on these two types of variants in the nearfuture.AcknowledgementThe authors would like to thank the expertsfor their comments and their evaluations ofour results: Pierre Zweigenbaum (AP/HP) on\[Menelas\], Christel Le Bozec and Marie-ChristineJanlent (AP/HP) on \[Broussais\], and HenryBoccon-Gibod (DER-EDF) on \[DER\].
We are alsograteful to Henry Boccon-Gibod (DER-EDF) forhis support o this work.
This work was partiallyfunded by l~lectriciti@ de France.Re ferencesDidier Bourigault, Isabelle Gonzalez-Mullier, andC@cile Gros.
1996.
Lexter, a natural anguageprocessing tool for terminology extraction.
InSeventh EURALEX International Congress onLexicography (EURALEX96), Part II, pages771-779.Didier Bouriganlt.
1993.
An endogeneous corpus-based method for structural noun phrase disam-biguation.
In Proceedings, 6th Conference of theEuropean Chapter of the Association for Com-putational Linguistics (EA CL '93), pages 81-86,Utrecht.Caroline Brun.
1998.
Terminology finite-statepreprocessing for computational lfg.
In Proceed-ings, 36th Annual Meeting of the Associationfor Computational Linguistics and 17th Inter-national Conference on Computational Linguis-tics (COLING-ACL'98), pages 196-200, Mon-treal.21Proceedings of EACL '99Table 4: Results of the validation.\[Broussais\] \[Menelas\] \[DER\]Number of variation links proposed by the system 240 634 785Number of variation links validated by the expert 240 227 344Types of conceptual relation given by the expertsynonymy 44 (18%) 14 (,6%) 136 (40%)generic/specific 96 (40%) 147 (6.5%) 121 (35%)attributive 96 (40%) 61 (2'7%) 62 (18%)non relevant 4 (2%) 5 (2%) 25 (7%)B6atrice Daille.
1996.
Study and implementa-tion of combined techniques for automatic ex-traction of terminology.
In Judith L. Klavansand Philip Resnik, editors, The Balancing Act:Combining Symbolic and Statistical Approachesto Language, pages 49-66.
MIT Press, Cam-bridge, MA.Martin Dillon and Ann S. Gray.
1983.
FASIT:A fully automatic syntactically based indexingsystem.
Journal of the American Society forInformation Science, 34(2):99-108.David A. Evans, Kimberly Ginther-Webster,Mary Hart, Robert G. Lefferts, and Ira A.Monarch.
1991.
Automatic indexing using se-lective NLP and first-order thesauri.
In Pro-ceedings, Intelligent Multimedia InformationRetrieval Systems and Management (RIA 0'91),pages 624-643, Barcelona.Gregory Grefenstette.
1992.
A knowledge-poortechnique for knowledge xtraction from largecorpora.
In Proceedings, 15th Annual Inter-national A CM SIGIR Conference on Researchand Development in Information Retrieval (SI-GIR '92), Copenhagen.Gregory Grefenstette.
1994.
Explorations inAutomatic Thesaurus Discovery.
Kluwer Aca-demic Publisher, Boston, MA.Christian Jacquemin, Judith L. Klavans, and Eve-lyne Tzoukermann.
1997.
Expansion of multi-word terms for indexing and retrieval usingmorphology and syntax.
In Proceedings, 35thAnnual Meeting of the Association for Compu-tational Linguistics and 8th Conference of theEuropean Chapter of the Association for Com-putational Linguistics (ACL - EACL'97), pages24-31, Madrid.Christian Jacquemin.
1999.
Syntagmatic andparadigmatic representations of term varia-tion.
In Proceedings, 37th Annual Meeting ofthe Association for Computational Linguistics(ACL'99), University of Maryland.John S. Justeson and Slava M. Katz.
1995.
Tech-nical terminology: some linguistic propertiesand an algorithm for identification i  text.
Nat-ural Language Engineering, 1(1):9-27.George Kleiber.
1989.
Paul est bronzd versus lapeau de paul est bronzde.
Contre une approcher6f~rentielle analytique.
In Harro Stammerjo-harm, editor, Proceedings, Ire colloque interna-tional de linguistique slavo-romane, pages 109-134, Tiibingen.
Gunter Narr Verlag.
Reprintedin Nominales, A. Colin, Paris, 1995.Adwait Ratnaparkhi.
1998.
Statistical modelsfor unsupervised prepositional phrase attach-ment.
In Proceedings, 36th Annual Meeting ofthe Association for Computational Linguisticsand 17th International Conference on Compu-tational Linguistics (COLING-ACL'98), pages1079-1085, Montreal.Karen Sparck Jones and John I. Tait.
1984.
Auto-matic search term variant generation.
Journalof Documentation, 40(1):50-66.22
