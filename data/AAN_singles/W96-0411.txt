Best-First Surface RealizationStephan Busemann*DFKI  GmbHStuhlsatzenhausweg 3D-66123 Saarbriickenemaih busemann@dfki ,  un i - sb ,  deAbst rac tCurrent work in surface realization concen-trates on the use of general, abstract algo-rithms that interpret large, reversible gram-mars.
Only little attention has been paidso far to the many small and simple appli-cations that require coverage of a small sub-language at different degrees of sophistica-tion.
The system TG/2 described in this pa-per can be smoothly integrated with deep gen-eration processes, it integrates canned text,templates, and context-free rules into a sin-gle formalism, it allows for both textual andtabular output, and it can be parameterizedaccording to linguistic preferences.
These fea-tures are based on suitably restricted produc-tion system techniques and on a generic back-tracking regime.1 Mot ivat ionCurrent work in surface realization concen-trates on the use of general, abstract algo-rithms that interpret declaratively defined,non-directional grammars.
It is claimed thatthis way, a grammar can be reused for parsing*This work has been supported by a grant fromThe Federal Ministry for Research and Technology(FKZ ITW 9402).
I am grateful to Michael Wein,who implemented the interpreter,  and to Jan  Alexan-dersson for influential work on a previous version ofthe system.
Finally, I wish to thank  two anonymousreviewers for useful suggestions.
All errors containedin this paper are my own.and generation, or a generator can interpretdifferent grammars (e.g.
in machine transla-tion).
A prominent example for this typeof abstract algorithm is semantic-head-drivengeneration \[Shieber et al, 1990\] that has beenused with HPSG, CUG, DCG and several oth-er formalisms.In practice, this type of surface realizationhas several drawbacks.
First, many existinggrammars have been developed with parsingas the primary type of processing in mind.Adapting their semantics layer to a genera-tion algorithm, and thus achieving reversibil-ity, can turn out to be a difficult enterprise\[Russell et al, 1990\].
Second, many linguisti-cally motivated grammars do not cover com-mon means of information presentation, suchas filling in a table, bulletized lists, or semi-frozen formulae used for greetings in letters.Finally, the grammar-based logical form rep-resentation hardly serves as a suitable inter-face to deep generation processes.
Grammar-based semantics is, to a large extent, a com-positional reflex of the syntactic structure andhence corresponds too closely to the surfaceform to be generated.
As a consequence, on-ly little attention has been paid to interfacingthis type of realizers adequately to deep gen-eration processes, e.g.
by allowing the latterto influence the order of results of the former.The system TG/2, which is presented inthis contribution, overcomes many flaws ofgrammar-based surface realization systemsthat arise in concrete applications.
In par-ticular, TG/2101?
can be smoothly integrated with 'deep'generation processes,?
integrates canned text, templates, andcontext-free rules into a single formalism,?
allows for both textual and tabular out-put,?
efficiently reuses generated substrings foradditional solutions, and?
can be parameterized according to lin-guistic properties (regarding style, gram-mar, fine-grained rhetorics etc.
).TG/2 is based on restricted production sys-tem techniques that preserve modularity ofprocessing and linguistic knowledge, hencemaking the system transparent and reusablefor various applications.
Production systemshave been used both for modeling humanthought (e.g.
\[Newell, 1973\]) and for the con-struction of knowledge-based xpert systems(e.g.
\[Shortliffe, 1976\]).
In spite of the modu-larity gained by separating the rule basis fromthe interpreter, production systems have dis-appeared from the focus of current researchbecause of their limited transparency ausedby various types of side effects.
In particu-lar, side effects could modify the data base insuch a way that other rules become applicable\[Davis and King, 1977\].However, precondition-action pairs can beused in a more restricted way, preservingtransparency by disallowing side effects thataffect the database.
In TG/2 preconditionsare tests over the database contents (the gen-erator's input structure), and actions typical-ly lead to a new subset of rules the applicabil-itv of which would be tested on some selectedportion of the database.
By constraining theeffects of production rules in such a way, thedisadvantages of early production systems areavoided.
At the same time, considerable flex-ibility is maintained with regard to linguisticknowledge used.
A production rule may?
involve a direct mapping to surface forms(canned text),?
require to fill in some missing portionfrom a surface text (template), or?
induce the application of other rules(classical grammar rules)Early template-based generation methodshave correctly been criticized for beeing tooinflexible to account adequately for the com-municative and rhetorical demands of manyapplications.
On the other hand, templateshave been successfully used when these de-mands could be hard-wired into the rules.
InTG/2 the rule writer can choose her degreeof abstraction according to the task at hand.She can freely intermix all kinds of rules.The rest of the paper is organized as fol-lows.
TG/2 assumes as its input a predicate-argument structure, but does not require anyparticular format.
Rather, a separate transla-tion step is included that translates the out-put of feeding components into expressionsof the Generator Interface Language (GIL)(Section 2).
In Section 3 the formalism TGL(Template Generation Language) for produc-tion rules is introduced.
The properties ofTGL allow for efficient generation of all pos-sible solutions in any order.
The TGL inter-preter and its generic backtracking regime arepresented in Section 4.
It is used to param-eterize TG/2 by inducing an order in whichthe solutions are generated (Section 5).Figure 1 gives an overview of the systemand its components.2 The Generation InterfaceLanguage (GIL)Although the level of logical form is consid-ered a good candidate for an interface to sur-face realization, practice shows that notation-al idosyncrasies can pose severe translationproblems.
TG/2 has an internal language,GIL, that corresponds to an extended pred-icate argument structure.
GIL is the basis forthe precondition test predicates and the se-lector functions of TGL.
Any input to TG/2102Input structuretranslationG IL-Structuref G Substructurestack i -t ~ GILN E i = m  mT Jo mRTGL Production Rulesl~l EZ3 I---I r--11EE3 I'--I r~lmm~mmummmm m m m m- -  m m m m m mTGL E?
test rules?
select a rule?
apply the ruleOutput StringNGINEFigure 1: Overview of the system TG/2.is first translated into GIL before being pro-cessed.
It is of considerable practical benefitto keep the rule basis as independent as possi-ble from external conditions (such as changesto the output specification of the feeding sys-tem).GIL is designed to be a target languagesuited for deep generation processes.
Similaraims have been pursued with the developmentof the Sentence Plan Language (SPL) \[Kasperand V'hitney, 1989\] that is used in a variety ofgeneration systems.
Like SPL, GIL assumesonly little grammatical information.
GIL canrepresent DAG-like feature structures.
Fig-ure 2 contains a sample GIL expression.
Theexample shows the major language lements:?
The top level consists of a speech actpredicate and arguments for author, ad-dressee and theme (the speechact prop-er).?
Discourse objects can be assigned uniqueconstants (I.D) that denote SETs of dis-course objects.?
SMOOD expresses entence modalities in-103\[(PRED request)(HEARER \[(ID refo365) (SET < nussbaum >)\])(SPEAKER \[(ID refo752) (SET < digisec >)\])(THEME \[(SMOOD \[(TOPIC #i) (MODALITY unmarked) (TIME pres)\])(PRED meet)(DREF \[(ID refo610) (SET < meetl >)\])(ARGS < #1= \[(ROLE agent)(CARD single)(CONTENT \[(DREF \[(ID refo621) (SET < zweig >)\])(QFORCE noquant)(PRED humname)(NAME \[(TITLE \"Prof.\")(SURNAME \"Zweig\")(SORT female)\])\])\],\[(ROLE patient)(CARD single)(CONTENT \[(DREF \[(ID refo365) (SET < nussbaum >)\])(QFORCE iota)(PRED object)\])\] >)(TIME-ADJ \[(ROLE on) (CONTENT \[(WEEKDAY 5)\])\])\])\]Figure 2: A sample GIL input structure (Prof. Zweig will Sic am Freitag treffen \[Prof. Zweigwants to meet you on Friday\].
< and > are list delimiters; # denotes coreferences.cluding sentence type, time, a specifica-tion of which constituents to topicalize ina German declarative sentence, etc.?
The predicate argument structure is re-flected by corresponding features: ARGScontains a list of arguments.?
Different sorts of free temporal and localadjuncts can be specified by correspond-ing features.
In Figure 2, a temporal ad-junct is represented under TIME-ADJ.?
Arguments and, in part, adjuncts arespecified for their role, for cardinal-ity, for quantificational force (underC0NTENT.QFORCE), and further detailssuch as name strings and natural gender.?
Temporal adjuncts relate to some context(e.g.
tomorrow) or are indexical (e.g.
onWednesday, February 7, 1996).
All com-mon combinations in German are cov-ered.3 The Template GenerationLanguage (TGL)TGL defines a general format for expressingproduction rules as precondition-action pairs(cf.
Figure 3).
A TGL rule is applicable if itspreconditions are met.
A TGL rule is suc-cessfully applied, if the action part has beenexecuted without failure.
Failure to apply aTGL rule signals that the rule does not coverthe portion of the input structure submittedto it.Figure 4 shows a sample TGL rule.
It cor-responds to an infinitival VP covering a directobject, an optional temporal adjunct, an op-tional expression for a duration (such as foran hour), an optional local adjunct (such asat the DFKI  building) , and the infinite verbform.
Given the input GIL structure of Fig-ure 2, the VP Sic am Freitag treffen \[to meetyou on Friday\] could be genorated from thisrule.
Among the optional constituents, onlythe temporal adjunct would find appropriate104<rule><tgl-rule><category><template>::= (DEFPRODUCTION <string> <tgl-rule>)::= (:PRECOND (:CAT <category>:TEST (<lisp-code>+)):ACTIONS (:TEMPLATE <template>+{:SIDE-EFFECTS <lisp-code>}{:CONSTRAINT <feature-equation>+}))::= TXT I S l VP I NP J PP \] PPdur \] INF J ADJ \] ...::= (:RULE <category> <lisp-code>) \](:0PTRULE <category> <lisp-code>) I(:FUN <lisp-code>) I<string>Figure 3: An excerpt of TGL Syntax.material in the GIL input structure (underTHEME.
TIME-ADJ).Every TGL rule has a unique name, denot-ed by the initial string.
This name is used forexpressing preferences on alternative rules (cf.Section 5).Category i  The categories can be defined asin a context-free grammar.
Correspond-ingly, categories are used for rule selec-tion (see below).
They ensure that aset of TGL rules possesses a context-freebackbone.Test: The Lisp code under : TEST is a booleanpredicate (usually about properties of theportion of input structure under investi-gation or about the state of some mem-ory).
In the sample rule, an argument isrequired that fills the patient role.Template :  Actions under :TEMPLATE 1 in-clude the selection of other rules ( : RULE,: 0PTRULE), executing a function (:FUN),or returning an ASCII string as a (par-tial) result.When selecting other rules by virtue ofa category, a Lisp function is called that1The notion of template is preserved for histori-cal reasons: the predecessor system TG/1 was strictlytemplate-based,identifies the relevant portion of the in-put structure for which a candidate rulemust pass its associated tests.
In Fig-ure 4, the first action selects all rules withcategory NP; the relevant substructure isthe argument filling the patient role (cf.the second element of the ARGS list in Fig-ure 2).
If there is no such substructuresan error is signalled 2 unless an 0PTRULEslot (for "optional rule") was executed.In this case, processing continues with-out results from that slot.Functions must return an ASCII string.They are mostly used for word inflection;otherwise, for German every inflection-al variant would have to be encoded as arule.
TG/2  uses the morphological inflec-tion component MORPHIX \[Finkler andNeumann, 1988\].Side effects: The Lisp code under: SIDE-EFFECTS is a function whose valueis ignored.
It accounts for non-local de-pendencies between substructures, uchas updates of a discourse memory.
Notethat these effects can be traced and un-done in the case of backtracking.2In the case at hand, the grammar writer preferredto ensure availability of the substructure by virtue ofthe test predicate.105(defproduction "VPinf with temp/loc adjuncts"(:PRECOND (:CAT VP:TEST ((role-filler-p 'patient))):ACTIONS (:TEMPLATE (:RULE NP (role-filler 'patient))(:0PTRULE PP (temp-adjunct))(:0PTRULE PPdur (temp-duration))(:0PTRULE PP (lot-adjunct))(:RULE INF (theme)):CONSTRAINTS (CASE (NP) :VAL 'akk))))Figure 4: A sample production rule for a VP with an infinitive verb form placed at the end.Constraints:  Agreement relations are en-coded into the rules by virtue of a PATRstyle \[Shieber et al, 1983\] feature per-colation mechanism.
The rules can beannotated by equations that either as-sert equality of a feature's value at twoor more constituents or introduce a fea-ture value at a constituent.
Attempt-ing to overwrite a feature specificationyields an error.
In Figure 4, the right-hand side constituent NP is assigned ac-cusative case.
Any of these effects aresubject to backtracking.Using TGL, small task- and domain-specificgrammars can be written quickly.
For in-stance, in the domain of appointment schedul-ing the system COSMA \[Busemann et al,1994\] has to accept, reject, modify, or re-fine suggested meeting dates via email.
Thesublanguage ncoded in TGL only needs afew speech acts, about twenty sentential tem-plates, and a complete account of Germandate expressions.
Moreover, formal as wellas informal opening and closing phrases foremails are covered.Larger grammars may become difficult tomaintain unless special care is taken by thegrammar writer to preserve a global struc-ture of rules, both by defining suitable cat-egories and by documenting the rules.
TGLrules are presently written using a text editor.A specialized TGL grammar editor could im-prove the development and the organization ofgrammars considerably.
Syntactic orrectnessis checked at compile-time by an LR-Parsergenerated by Zebu \[Laubsch, 1992\] on the ba-sis of a BNF syntax for TGL.4 An interpreter withgeneric backtrackingTG/2 has a simple interpretation proce-dure that corresponds to the classical three-step evaluation cycle in production systems(matching, conflict resolution, firing) \[Davisand King, 1977\].
The algorithm receives aGIL structure as its input and uses a distin-guished category, TXT, to start from.1.
Match ing :  Select all rules carrying thecurrent category.
Execute the tests foreach of these rules on the input structureand add those passing their test to theconflict set.2.
Conf l ict  reso lut ion:  Select an elementfrom the conflict set.3.
F i r ing:  Execute its side effect code (ifany).
Evaluate its constraints (if any).For each action part, read the catego-ry, determine the substructure of the in-put by evaluating the associated func-tion, and goto 1.The processing strategy is top-down anddepth-first.
The set of actions is fired from106B1/32B2~ \[pre context ego post contextst ~\ -- {s2i\[1 _< i _< Isll} s3.v2.ss.51.v1.83 ~?
= {s4jll _< j _< IB21} ssst.Vl.sa's5j = {s6kll _< k < IB2,1}where 84j -~- 85j'V21 "87j87j "88Figure 5: Table of Backtrack Points: B2 is encountered outside of the ego of Bt.
B2~ isencountered inside the ego of B2.left to right.
Failure of executing some actioncauses the rule to be backtracked.The interpreter yields all solutions thegrammar can generate.
It attempts to gener-ate and output a first solution, producing pos-sible alternatives only on external demand.Any alternative is based on backtracking atleast one rule.
Backtrack points correspondto conflict sets containing more than one ele-ment.Backtracking may turn out to be inefficientif it involves recomputation of previously gen-erated substrings.
In TG/2  this effort is re-duced considerably because it is only neces-sary to recompute the part licensed by thenewly selected rule.
What has been generat-ed before or after it remains constant (modulosome word forms that need to agree with newmaterial) and can thus be reused for subse-quent solutions.
This is possible due to thedesign properties of TGL: rules cannot irre-vocably influence other parts of the solution.In particular, the context-free backbone im-plicit in any solution and the restrictions toside effects mentioned above keep the struc-tural effects of TGL rules local.In the sequel, technical aspects of the back-tracking regime are discussed.
Let us as-sume that the interpreter compute a back-track point.
Let us call the sequence of stringsgenerated by previous actions its pre-context,the set of string sequences generated from theelements of the conflict set its ego, and the se-quence of strings generated from subsequentactions its post-context.
For every ego, thepre- or the post context may be empty.Each time a backtrack point is encounteredduring processing, an entry into a global tableis made by specifying its pre-context (which isalready known due to the left-to-right process-ing), a variable for the ego (which will collectthe sequences of strings generated by the el-ements of the conflict set), and a variable forthe post-context (which is unknown so far).
aFigure 5 shows the state of a sample tablecomprising three backtrack points after all so-lutions have been computed.
The ego vari-able is shown using indices running over theelements of the respective conflict sets.
Theoperator '.'
denotes concatenation of stringswith strings or sets of strings, delivering allpossible combinations.After the first solution has been found (i.e.Sl"S21 '83"851 "861"871 "S8), every ego set containsone element.
The post contexts for all back-track points can be entered into the table.The next solution is generated by selectinganyone of the backtrack points and adding anew element o the ego set.
At the same time.all other entries of the table are updated, andthe set of additional solutions can be read offstraightforwardly from the entry of the back-track point just processed.
Assume, for in-stance, that B21 generates a second solution.thus causing V2~ to have two elements.
Wethen get Sl'S21"83"851"862"871"88.
Now assumethat Bi also generates a second solution.
This3In fact, it is preterminal rather than terminal ele-ments that are stored in the table in order to accountfor modified constraints.
This can be neglected in thepresent discussion, but will be taken up again below.107directly yields two more solutions since thepost context of B1 includes, via 84j, the twoelements of V21.This way only the alternative lements of aconflict set have to be expanded from scratch.All other material can be reused.
This ishighly efficient for backtrack points introduc-ing "cheap" alternatives (e.g.
different word-ings).
Since the ego must be recomputed fromscratch, much less is gained with backtrackpoints occurring at a higher level (e.g.
activevs.
passive sentence).
In order to avoid hav-ing to recompute successfully generated par-tial results within the ego, such results arestored during processing together with thepart of the input structure and the currentcategory.
They can be reused when passingan applicability test that requires the storedcategory and input structure to be identicalto the current ones.The backtracking approach described isbased on the assumption that any constraintsintroduced for some ego can be undone andrecomputed on the basis of rules generatingan alternative go.
Clearly, features instanti-ated for some ego may have effects onto thepre- or post-context.
If an agreement featurereceives a different value during backtrackingand it relates to material outside the ego, in-flectional processes for that material must becomputed again.
These cases can be detectedby maintaining a trace of all constraint ac-tions.
The recomputation is rendered possi-ble by adding, in addition to storing terminalstrings in the table, the underlying calls to theinflection component as well.5 Parameter i za t ionParameterization of TG/2  is based on spec-ifying the way how the generic backtrackingregime should operate.
It can be influencedwith regard to?
the element in the conflict set to be pro-cessed next, and?
the backtrack point to be processed next.Both possibilities taken together allow a sys-tem that feeds TG/2  to specify linguistic cri-teria of preferred solutions to be generatedfirst.The criteria are defined in terms of rulenames, and a criterion is fulfilled if some cor-responding rule is successfully applied.
Wecall such a rule c-rule.
TG/2 implementsa simple strategy that processes those back-track points first that have conflict sets con-taining c-rules, and preferrably choses a c-rulefrom a conflict set.
When applied incremen-tally, this procedure yields all solutions fulfill-ing (some of) the criteria first.It would be desirable to see the solution ful-filling most criteria first.
However, incremen-tal application enforces decisions to be takenlocally for each conflict set.
Any c-rule chosenmay be the last one in a derivation, whereaschosing a non-c-rule may open up further op-portunities of chosing c-rules.
These limitsare due to a lack of look-ahead information:it is not known in general which decisions willhave to be taken until all solutions have beengenerated.
4 Clearly, sacrificing incrementali-ty is not what should be desired although itmay be acceptable for some applications.
Thedrawbacks include a loss of efficiency and run-time.
This leaves us with two possible direc-tions that can lead to improved results.Ana lyz ing  dependenc ies  of criteria:The solution fulfilling most criteria is gener-ated first if sets of mutually independent cri-teria are applied: fulfilling one criterion mustnot exclude the applicability of another one.unless two criteria correspond to rules of thesame conflict set.
In this case, they must allowfor the the application of the same subset ofcriteria.
If these conditions are met, chosing ac-rule from every conflict set, if possible, willlead to a globally best solution first.
There is,however, the practical problem that the con-ditions on the criteria can only be fulfilled by4Note that this conclusion does not depend on theprocessing strategy chosen.108analyzing, and possibly modifying, the TGLgrammar used.
This contradicts the idea ofhaving the user specify her preferences inde-pendent of TG/2 properties.Learning dependencies of criteria:Missing look-ahead information could be ac-quired automatically by exploiting the deriva-tional history of previously generated texts.For every applied rule, the set of c-rules ap-plied later in the current subtree of a deriva-tion is stored.
From this information, we canderive off-line for any set of criteria which c-rules have applied in the corpus and how of-ten each c-rule has applied within a deriva-tion.
Computing such information from thecontext-free backbone of TGL grammars in-stead would be less effective since it neglectsthe drastic filtering effects of preconditions.However.
checking the grammar this way in-dicates which c-rules will not appear in somesubtree.During processing, TG/2 can then judgethe global impact of chosing the locally bestc-rule and decide to fulfill or violate a cri-terion.
The success of this method dependson how well the derivation under constructionfits with the sample data.
The more examplesthe system observes, the more reliable will beits decisions.The latter approach is in fact independenton how the criteria influence each other.
Inaddition, it can be extended to cope withweighted criteria.
A weight is specified by theuser (e.g.
a feeding system) and expresses therelative importance of the criterion being ful-filled in a solution.
TG/2 would give prefer-ence to derivations leading to the maximumglobal weight.
The global weight of a solutionis the sum of the c-rule weights, each dividedby the number of times the c-rule occurs.However, different GIL structures may, fora TGL rule, lead to different sets of follow-upc-rules.
This causes the decision to be non-deterministic unless the reasons for the dif-ference are learned and applied to the caseat hand.
We must leave it to future researchto identify ard apply suitable learning algo-rithms to solving this problem.Criteria have been implemented for choos-ing a language, for chosing between active andpassive sentences, for preferring paratacticalover hypotactical style, and for choice of for-mal vs. informal wordings.
Additional usescould include some rhetorical structuring (e.g.order of nucleus and satellites in RST-basedanalyses \[Mann and Thompson.
1988\]).The approach presented offers a technicalframework that allows a deep generation pro-cess to abstract away from many idiosyn-crasies of linguistic knowledge by virtue ofmeaningful weighting functions.
Ideally, thesefunctions must implement a theory of howmutual dependencies of criteria should bedealt with.
For instance, lexical choice andconstituent order constraints may suggest heuse of passive voice (cf.
e.g.
\[Danlos, 1987\]).
Itis a yet open question whether such a theorycan be encoded by weights.
However, for somesets of preferences, this approach as provento be sufficient and very useful.6 Conc lus ionIn this contribution, we have introducedTG/2, a production-rule based surface gen-erator that can be parameterized to generatethe best solutions first.
The rules are encodedin TGL, a language that allows the definitionof canned text items, templates, and context-free rules within the same formalism.
TGLrules can, and should, be written with gen-eration in mind, i.e.
the goal of reversibilityof grammars pursued with many constraint-based approaches has been sacrificed.
This isjustified because of the limited usefulness oflarge reversible grammars for generation.TGL is particularly well suited for the de-scription of limited sublanguages specific tothe domains and the tasks at hand.
Par-tial reuse of such descriptions depends onwhether the grammar writer keeps general.reusable definitions independent from the spe-cific, non-reusable parts of the grammar.
For109instance, time and date descriptions encod-ed for the COSMA domain can be reused inother TG/2 applications.
On the other hand,TGL sublanguage grammars can be devel-oped using existing resources.
For instance,suitable fragments of context-free grammarstranslated into TGL could be augmented bythe domain and task specific properties need-ed.
Practical experience must show whetherthis approach saves effort.The system is fully implemented in AllegroCommon Lisp and runs on different platforms(SUN workstations, PC, Macintosh).
Com-puting the first solution of average-length sen-tences (10-20 words) takes between one andthree seconds on a SUN SS 20.
TG/2 is beingused in the domain of appointment schedulingwithin DFKI's COSMA system.
In the nearfuture, the system will be used within an NL-based information kiosk, where informationabout environmental data must be providedin both German and French language, includ-ing tabular presentations if measurements ofseveral substances are involved.References\[Busemann et al, 1994\] S. Busemann, S. Oe-pen, E. Hinkelman, G. Neumann, andH.
Uszkoreit.
COSMA-multi-participantNL interaction for appointment scheduling.Research Report RR-94-34, DFKI, Saar-brficken, 1994.\[Danlos, 1987\] L. Danlos.
The Linguistic Ba-sis of Text Generation.
Cambridge Univer-sity Press, Cambridge, 1987.\[Davis and King, 1977\] R. Davis and J. King.An overview of production systems.
InE.
W. Elcock and D. Michie.
editors, Ma-chine Intelligence 8, pages 300-332.
EllisHorwood, Chichester, 1977.\[Finkler and Neumann, 1988\] W. Finkler andG.
Neumann.
Morphix: A fast realizatiopof a classification-based approach to mor-phology.
In H. Trost, editor, Proc.
der4.
dJsterreichischen Artificial-IntelligenceTagung, pages 11-19, Berlin, August 1988.Springer.\[Kasper and Whitney, 1989\] R. Kasper andR.
Whitney.
SPL: A sentence plan languagefor text generation.
Technical report, USC-ISI.
Marina del Rey, 1989.\[Laubsch, 1992\] J. Laubsch.
Zebu: A Toolfor Specifying Reversible LALR(1) Parsers.Technical Report HPL-92-147.
Hewlett-Packard Labs, Palo Alto, CA, July 1992.\[Mann and Thompson, 1988\] W. C. Mannand S. A. Thompson.
Rhetorical structuretheory: Toward a functional theory of textorganization.
Text, 8(3):243-281.
1988.\[Newell, 1973\] A. Newell.
Production sys-tems: Models of control structures.
InW.
G. Chase, editor, Visual Informa-tion Processing, pages 463-526.
AcademicPress, New York, 1973.\[Russell et al, 1990\] G. Russell.
S. Warwick,and J. Carroll.
Asymmetry in parsingand generating with unification grammars:Case studies from ELU.
In Proc.
28th A CL,pages 205-211., Pittsburgh, 1990.\[Shieber et al, 1983\] S. Shieber, H. Uszko-reit, F. Pereira, J. Robinson, and M. Tyson.The formalism and implementation ofPATR-II.
In B. J. Grosz and M. E. Stick-el, editors, Research on Interactive Acqui-sition and Use of Knowledge, pages 39-79.AI Center, SRI International, Menlo Park.CA, 1983.\[Shieber et al, 1990\] S. Shieber, G. vanNoord, R. C. Moore, and F. Pereira.
Asemantic-head-driven g eration algorithmfor unification-based formalisms.
Compu-tational Linguistics, 16(1):30-42, 1990.\[Shortliffe, 1976\] E. H. Shortliffe.
Computer-based Medical Consultations: MYCIN.
El-sevier, New York, 1976.110
