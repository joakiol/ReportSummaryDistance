Proceedings of ACL-08: HLT, pages 568?576,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsAutomatic Syllabification with Structured SVMsfor Letter-To-Phoneme ConversionSusan Bartlett?
Grzegorz Kondrak?
Colin Cherry?
?Department of Computing Science ?Microsoft ResearchUniversity of Alberta One Microsoft WayEdmonton, AB, T6G 2E8, Canada Redmond, WA, 98052{susan,kondrak}@cs.ualberta.ca colinc@microsoft.comAbstractWe present the first English syllabificationsystem to improve the accuracy of letter-to-phoneme conversion.
We propose a novel dis-criminative approach to automatic syllabifica-tion based on structured SVMs.
In comparisonwith a state-of-the-art syllabification system,we reduce the syllabification word error ratefor English by 33%.
Our approach also per-forms well on other languages, comparing fa-vorably with published results on German andDutch.1 IntroductionPronouncing an unfamiliar word is a task that is of-ten accomplished by breaking the word down intosmaller components.
Even small children learn-ing to read are taught to pronounce a word by?sounding out?
its parts.
Thus, it is not surprisingthat Letter-to-Phoneme (L2P) systems, which con-vert orthographic forms of words into sequences ofphonemes, can benefit from subdividing the inputword into smaller parts, such as syllables or mor-phemes.
Marchand and Damper (2007) report thatincorporating oracle syllable boundary informationimproves the accuracy of their L2P system, but theyfail to emulate that result with any of their automaticsyllabification methods.
Demberg et al (2007), onthe other hand, find that morphological segmenta-tion boosts L2P performance in German, but not inEnglish.
To our knowledge, no previous Englishorthographic syllabification system has been ableto actually improve performance on the larger L2Pproblem.In this paper, we focus on the task of automaticorthographic syllabification, with the explicit goalof improving L2P accuracy.
A syllable is a subdi-vision of a word, typically consisting of a vowel,called the nucleus, and the consonants preceding andfollowing the vowel, called the onset and the coda,respectively.
Although in the strict linguistic sensesyllables are phonological rather than orthographicentities, our L2P objective constrains the input to or-thographic forms.
Syllabification of phonemic rep-resentation is in fact an easier task, which we plan toaddress in a separate publication.Orthographic syllabification is sometimes re-ferred to as hyphenation.
Many dictionaries pro-vide hyphenation information for orthographic wordforms.
These hyphenation schemes are related to,and influenced by, phonemic syllabification.
Theyserve two purposes: to indicate where words maybe broken for end-of-line divisions, and to assist thedictionary reader with correct pronunciation (Gove,1993).
Although these purposes are not always con-sistent with our objective, we show that we can im-prove L2P conversion by taking advantage of theavailable hyphenation data.
In addition, automatichyphenation is a legitimate task by itself, whichcould be utilized in word editors or in synthesizingnew trade names from several concepts.We present a discriminative approach to ortho-graphic syllabification.
We formulate syllabifica-tion as a tagging problem, and learn a discriminativetagger from labeled data using a structured supportvector machine (SVM) (Tsochantaridis et al, 2004).With this approach, we reduce the error rate for En-glish by 33%, relative to the best existing system.Moreover, we are also able to improve a state-of-the-art L2P system by incorporating our syllabificationmodels.
Our method is not language specific; whenapplied to German and Dutch, our performance is568comparable with the best existing systems in thoselanguages, even though our system has been devel-oped and tuned on English only.The paper is structured as follows.
After dis-cussing previous computational approaches to theproblem (Section 2), we introduce structured SVMs(Section 3), and outline how we apply them to ortho-graphic syllabification (Section 4).
We present ourexperiments and results for the syllabification taskin Section 5.
In Section 6, we apply our syllabifica-tion models to the L2P task.
Section 7 concludes.2 Related WorkAutomatic preprocessing of words is desirable be-cause the productive nature of language ensures thatno finite lexicon will contain all words.
Marchandet al (2007) show that rule-based methods are rela-tively ineffective for orthographic syllabification inEnglish.
On the other hand, few data-driven syllabi-fication systems currently exist.Demberg (2006) uses a fourth-order HiddenMarkov Model to tackle orthographic syllabificationin German.
When added to her L2P system, Dem-berg?s orthographic syllabification model effects aone percent absolute improvement in L2P word ac-curacy.Bouma (2002) explores syllabification in Dutch.He begins with finite state transducers, which es-sentially implement a general preference for onsets.Subsequently, he uses transformation-based learningto automatically extract rules that improve his sys-tem.
Bouma?s best system, trained on some 250Kexamples, achieves 98.17% word accuracy.
Daele-mans and van den Bosch (1992) implement a back-propagation network for Dutch orthography, but findit is outperformed by less complex look-up table ap-proaches.Marchand and Damper (2007) investigate the im-pact of syllabification on the L2P problem in En-glish.
Their Syllabification by Analogy (SbA) algo-rithm is a data-driven, lazy learning approach.
Foreach input word, SbA finds the most similar sub-strings in a lexicon of syllabified words and thenapplies these dictionary syllabifications to the inputword.
Marchand and Damper report 78.1% word ac-curacy on the NETtalk dataset, which is not goodenough to improve their L2P system.Chen (2003) uses an n-gram model and Viterbidecoder as a syllabifier, and then applies it as a pre-processing step in his maximum-entropy-based En-glish L2P system.
He finds that the syllabificationpre-processing produces no gains over his baselinesystem.Marchand et al (2007) conduct a more systematicstudy of existing syllabification approaches.
Theyexamine syllabification in both the pronunciationand orthographic domains, comparing their ownSbA algorithm with several instance-based learningapproaches (Daelemans et al, 1997; van den Bosch,1997) and rule-based implementations.
They findthat SbA universally outperforms these other ap-proaches by quite a wide margin.Syllabification of phonemes, rather than letters,has also been investigated (Mu?ller, 2001; Pearsonet al, 2000; Schmid et al, 2007).
In this paper, ourfocus is on orthographic forms.
However, as withour approach, some previous work in the phoneticdomain has formulated syllabification as a taggingproblem.3 Structured SVMsA structured support vector machine (SVM) is alarge-margin training method that can learn to pre-dict structured outputs, such as tag sequences orparse trees, instead of performing binary classifi-cation (Tsochantaridis et al, 2004).
We employ astructured SVM that predicts tag sequences, calledan SVM Hidden Markov Model, or SVM-HMM.This approach can be considered an HMM becausethe Viterbi algorithm is used to find the highest scor-ing tag sequence for a given observation sequence.The scoring model employs a Markov assumption:each tag?s score is modified only by the tag that camebefore it.
This approach can be considered an SVMbecause the model parameters are trained discrimi-natively to separate correct tag sequences from in-correct ones by as large a margin as possible.
Incontrast to generative HMMs, the learning processrequires labeled training data.There are a number of good reasons to apply thestructured SVM formalism to this problem.
We getthe benefit of discriminative training, not availablein a generative HMM.
Furthermore, we can use anarbitrary feature representation that does not require569any conditional independence assumptions.
Unlikea traditional SVM, the structured SVM considerscomplete tag sequences during training, instead ofbreaking each sequence into a number of traininginstances.Training a structured SVM can be viewed as amulti-class classification problem.
Each training in-stance xi is labeled with a correct tag sequence yidrawn from a set of possible tag sequences Yi.
Asis typical of discriminative approaches, we create afeature vector ?
(x, y) to represent a candidate y andits relationship to the input x.
The learner?s task isto weight the features using a vector w so that thecorrect tag sequence receives more weight than thecompeting, incorrect sequences:?i?y?Yi,y 6=yi [?
(xi, yi) ?
w > ?
(xi, y) ?
w] (1)Given a trained weight vector w, the SVM tags newinstances xi according to:argmaxy?Yi [?
(xi, y) ?
w] (2)A structured SVM finds a w that satisfies Equation 1,and separates the correct taggings by as large a mar-gin as possible.
The argmax in Equation 2 is con-ducted using the Viterbi algorithm.Equation 1 is a simplification.
In practice, a struc-tured distance term is added to the inequality inEquation 1 so that the required margin is larger fortag sequences that diverge further from the correctsequence.
Also, slack variables are employed to al-low a trade-off between training accuracy and thecomplexity of w, via a tunable cost parameter.For most structured problems, the set of negativesequences in Yi is exponential in the length of xi,and the constraints in Equation 1 cannot be explicitlyenumerated.
The structured SVM solves this prob-lem with an iterative online approach:1.
Collect the most damaging incorrect sequencey according to the current w.2.
Add y to a growing set Y?i of incorrect se-quences.3.
Find a w that satisfies Equation 1, using the par-tial Y?i sets in place of Yi.4.
Go to next training example, loop to step 1.This iterative process is explained in far more detailin (Tsochantaridis et al, 2004).4 Syllabification with Structured SVMsIn this paper we apply structured SVMs to the syl-labification problem.
Specifically, we formulatesyllabification as a tagging problem and apply theSVM-HMM software package1 (Altun et al, 2003).We use a linear kernel, and tune the SVM?s cost pa-rameter on a development set.
The feature represen-tation ?
consists of emission features, which pairan aspect of x with a single tag from y, and transi-tion features, which count tag pairs occurring in y.With SVM-HMM, the crux of the task is to createa tag scheme and feature set that produce good re-sults.
In this section, we discuss several differentapproaches to tagging for the syllabification task.Subsequently, we outline our emission feature rep-resentation.
While developing our tagging schemesand feature representation, we used a developmentset of 5K words held out from our CELEX trainingdata.
All results reported in this section are on thatset.4.1 Annotation MethodsWe have employed two different approaches to tag-ging in this research.
Positional tags capture wherea letter occurs within a syllable; Structural tags ex-press the role each letter is playing within the sylla-ble.Positional TagsThe NB tag scheme simply labels every letteras either being at a syllable boundary (B), or not(N).
Thus, the word im-mor-al-ly is tagged ?N B NN B N B N N?, indicating a syllable boundary af-ter each B tag.
This binary classification approachto tagging is implicit in several previous imple-mentations (Daelemans and van den Bosch, 1992;Bouma, 2002), and has been done explicitly in boththe orthographic (Demberg, 2006) and phoneme do-mains (van den Bosch, 1997).A weakness of NB tags is that they encode noknowledge about the length of a syllable.
Intuitively,we expect the length of a syllable to be valuable in-formation ?
most syllables in English contain fewerthan four characters.
We introduce a tagging schemethat sequentially numbers the N tags to impart infor-mation about syllable length.
Under the Numbered1http://svmlight.joachims.org/svm struct.html570NB tag scheme, im-mor-al-ly is annotated as ?N1 BN1 N2 B N1 B N1 N2?.
With this tag set, we haveeffectively introduced a bias in favor of shorter syl-lables: tags like N6, N7.
.
.
are comparatively rare, sothe learner will postulate them only when the evi-dence is particularly compelling.Structural TagsNumbered NB tags are more informative thanstandard NB tags.
However, neither annotation sys-tem can represent the internal structure of the sylla-ble.
This has advantages: tags can be automaticallygenerated from a list of syllabified words withouteven a passing familiarity with the language.
How-ever, a more informative annotation, tied to phono-tactics, ought to improve accuracy.
Krenn (1997)proposes the ONC tag scheme, in which phonemesof a syllable are tagged as an onset, nucleus, or coda.Given these ONC tags, syllable boundaries can eas-ily be generated by applying simple regular expres-sions.Unfortunately, it is not as straightforward to gen-erate ONC-tagged training data in the orthographicdomain, even with syllabified training data.
Silentletters are problematic, and some letters can behavedifferently depending on their context (in English,consonants such as m, y, and l can act as vowels incertain situations).
Thus, it is difficult to generateONC tags for orthographic forms without at least acursory knowledge of the language and its princi-ples.For English, tagging the syllabified training setwith ONC tags is performed by the following sim-ple algorithm.
In the first stage, all letters from theset {a, e, i, o, u} are marked as vowels, while the re-maining letters are marked as consonants.
Next, weexamine all the instances of the letter y.
If a y is bothpreceded and followed by a consonant, we mark thatinstance as a vowel rather than a consonant.
In thesecond stage, the first group of consecutive vowelsin each syllable is tagged as nucleus.
All letters pre-ceding the nucleus are then tagged as onset, whileall letters following the nucleus are tagged as coda.Our development set experiments suggested thatnumbering ONC tags increases their performance.Under the Numbered ONC tag scheme, the single-syllable word stealth is labeled ?O1 O2 N1 N2 C1C2 C3?.A disadvantage of Numbered ONC tags is that,unlike positional tags, they do not represent sylla-ble breaks explicitly.
Within the ONC framework,we need the conjunction of two tags (such as an N1tag followed by an O1 tag) to represent the divisionbetween syllables.
This drawback can be overcomeby combining ONC tags and NB tags in a hybridBreak ONC tag scheme.
Using Break ONC tags,the word lev-i-ty is annotated as ?O N CB NB O N?.The ?NB?
tag indicates a letter is both part of thenucleus and before a syllable break, while the ?N?tag represents a letter that is part of a nucleus butin the middle of a syllable.
In this way, we get thebest of both worlds: tags that encapsulate informa-tion about syllable structure, while also representingsyllable breaks explicitly with a single tag.4.2 Emission FeaturesSVM-HMM predicts a tag for each letter in a word,so emission features use aspects of the input to helppredict the correct tag for a specific letter.
Considerthe tag for the letter o in the word immorally.
Witha traditional HMM, we consider only that it is ano being emitted, and assess potential tags based onthat single letter.
The SVM framework is less re-strictive: we can include o as an emission feature,but we can also include features indicating that thepreceding and following letters are m and r respec-tively.
In fact, there is no reason to confine ourselvesto only one character on either side of the focus let-ter.After experimenting with the development set, wedecided to include in our feature set a window ofeleven characters around the focus character, fiveon either side.
Figure 1 shows that performancegains level off at this point.
Special beginning- andend-of-word characters are appended to words sothat every letter has five characters before and af-ter.
We also experimented with asymmetric contextwindows, representing more characters after the fo-cus letter than before, but we found that symmetriccontext windows perform better.Because our learner is effectively a linear classi-fier, we need to explicitly represent any importantconjunctions of features.
For example, the bigrambl frequently occurs within a single English sylla-ble, while the bigram lb generally straddles two syl-lables.
Similarly, a fourgram like tion very often571Figure 1: Word accuracy as a function of the window sizearound the focus character, using unigram features on thedevelopment set.forms a syllable in and of itself.
Thus, in additionto the single-letter features outlined above, we alsoinclude in our representation any bigrams, trigrams,four-grams, and five-grams that fit inside our con-text window.
As is apparent from Figure 2, we seea substantial improvement by adding bigrams to ourfeature set.
Higher-order n-grams produce increas-ingly smaller gains.Figure 2: Word accuracy as a function of maximum n-gram size on the development set.In addition to these primary n-gram features,we experimented with linguistically-derived fea-tures.
Intuitively, basic linguistic knowledge, suchas whether a letter is a consonant or a vowel, shouldbe helpful in determining syllabification.
However,our experiments suggested that including featureslike these has no significant effect on performance.We believe that this is caused by the ability of theSVM to learn such generalizations from the n-gramfeatures alone.5 Syllabification ExperimentsIn this section, we will discuss the results of our bestemission feature set (five-gram features with a con-text window of eleven letters) on held-out unseentest sets.
We explore several different languages anddatasets, and perform a brief error analysis.5.1 DatasetsDatasets are especially important in syllabificationtasks.
Dictionaries sometimes disagree on the syl-labification of certain words, which makes a goldstandard difficult to obtain.
Thus, any reported ac-curacy is only with respect to a given set of data.In this paper, we report the results of experi-ments on two datasets: CELEX and NETtalk.
Wefocus mainly on CELEX, which has been devel-oped over a period of years by linguists in theNetherlands.
CELEX contains English, German,and Dutch words, and their orthographic syllabifi-cations.
We removed all duplicates and multiple-word entries for our experiments.
The NETtalk dic-tionary was originally developed with the L2P taskin mind.
The syllabification data in NETtalk wascreated manually in the phoneme domain, and thenmapped directly to the letter domain.NETtalk and CELEX do not provide the samesyllabification for every word.
There are numer-ous instances where the two datasets differ in a per-fectly reasonable manner (e.g.
for-ging in NETtalkvs.
forg-ing in CELEX).
However, we argue thatNETtalk is a vastly inferior dataset.
On a sample of50 words, NETtalk agrees with Merriam-Webster?ssyllabifications in only 54% of instances, whileCELEX agrees in 94% of cases.
Moreover, NETtalkis riddled with truly bizarre syllabifications, such asbe-aver, dis-hcloth and som-ething.
These syllabifi-cations make generalization very hard, and are likelyto complicate the L2P task we ultimately want toaccomplish.
Because previous work in English pri-marily used NETtalk, we report our results on bothdatasets.
Nevertheless, we believe NETtalk is un-suitable for building a syllabification model, and thatresults on CELEX are much more indicative of theefficacy of our (or any other) approach.At 20K words, NETtalk is much smaller thanCELEX.
For NETtalk, we randomly divide the datainto 13K training examples and 7K test words.
We572randomly select a comparably-sized training set forour CELEX experiments (14K), but test on a muchlarger, 25K set.
Recall that 5K training exampleswere held out as a development set.5.2 ResultsWe report the results using two metrics.
Word ac-curacy (WA) measures how many words match thegold standard.
Syllable break error rate (SBER) cap-tures the incorrect tags that cause an error in syl-labification.
Word accuracy is the more demand-ing metric.
We compare our system to Syllabifica-tion by Analogy (SbA), the best existing system forEnglish (Marchand and Damper, 2007).
For bothCELEX and NETtalk, SbA was trained and testedwith the same data as our structured SVM approach.Data Set Method WA SBERCELEXNB tags 86.66 2.69Numbered NB 89.45 2.51Numbered ONC 89.86 2.50Break ONC 89.99 2.42SbA 84.97 3.96NETtalk Numbered NB 81.75 5.01SbA 75.56 7.73Table 1: Syllabification performance in terms of word ac-curacy and syllable break error percentage.Table 1 presents the word accuracy and syllablebreak error rate achieved by each of our tag sets onboth the CELEX and NETtalk datasets.
Of our fourtag sets, NB tags perform noticeably worse.
This isan important result because it demonstrates that it isnot sufficient to simply model a syllable?s bound-aries; we must also model a syllable?s length orstructure to achieve the best results.
Given the simi-larity in word accuracy scores, it is difficult to drawdefinitive conclusions about the remaining three tagssets, but it does appear that there is an advantage tomodeling syllable structure, as both ONC tag setsscore better than the best NB set.All variations of our system outperform SbA onboth datasets.
Overall, our best tag set lowers the er-ror rate by one-third, relative to SbA?s performance.Note that we employ only numbered NB tags forthe NETtalk test; we could not apply structural tagschemes to the NETtalk training data because of itsbizarre syllabification choices.Our higher level of accuracy is also achieved moreefficiently.
Once a model is learned, our systemcan syllabify 25K words in about a minute, whileSbA requires several hours (Marchand, 2007).
SVMtraining times vary depending on the tag set anddataset used, and the number of training examples.On 14K CELEX examples with the ONC tag set,our model trained in about an hour, on a single-processor P4 3.4GHz processor.
Training time is,of course, a one-time cost.
This makes our approachmuch more attractive for inclusion in an actual L2Psystem.Figure 3 shows our method?s learning curve.
Evensmall amounts of data produce adequate perfor-mance ?
with only 2K training examples, word ac-curacy is already over 75%.
Using a 60K trainingset and testing on a held-out 5K set, we see wordaccuracies climb to 95.65%.Figure 3: Word accuracy as function of the size of thetraining data.5.3 Error AnalysisWe believe that the reason for the relatively low per-formance of unnumbered NB tags is the weakness ofthe signal coming from NB emission features.
Withthe exception of q and x, every letter can take oneither an N tag or a B tag with almost equal proba-bility.
This is not the case with Numbered NB tags.Vowels are much more likely to have N2 or N3 tags(because they so often appear in the middle of asyllable), while consonants take on N1 labels withgreater probability.The numbered NB and ONC systems make manyof the same errors, on words that we might expect to573cause difficulty.
In particular, both suffer from be-ing unaware of compound nouns and morphologicalphenomena.
All three systems, for example, incor-rectly syllabify hold-o-ver as hol-dov-er.
This kindof error is caused by a lack of knowledge of the com-ponent words.
The three systems also display trou-ble handling consecutive vowels, as when co-ad-ju-tors is syllabified incorrectly as coad-ju-tors.
Vowelpairs such as oa are not handled consistently in En-glish, and the SVM has trouble predicting the excep-tions.5.4 Other LanguagesWe take advantage of the language-independence ofNumbered NB tags to apply our method to other lan-guages.
Without even a cursory knowledge of Ger-man or Dutch, we have applied our approach to thesetwo languages.# Data Points Dutch German?
50K 98.20 98.81?
250K 99.45 99.78Table 2: Syllabification performance in terms of word ac-curacy percentage.We have randomly selected two training sets fromthe German and Dutch portions of CELEX.
Oursmaller model is trained on ?
50K words, while ourlarger model is trained on ?
250K.
Table 2 showsour performance on a 30K test set held out from bothtraining sets.
Results from both the small and largemodels are very good indeed.Our performance on these language sets is clearlybetter than our best score for English (compare at95% with a comparable amount of training data).Syllabification is a more regular process in Germanand Dutch than it is in English, which allows oursystem to score higher on those languages.Our method?s word accuracy compares favor-ably with other methods.
Bouma?s finite state ap-proach for Dutch achieves 96.49% word accuracyusing 50K training points, while we achieve 98.20%.With a larger model, trained on about 250K words,Bouma achieves 98.17% word accuracy, against our99.45%.
Demberg (2006) reports that her HMMapproach for German scores 97.87% word accu-racy, using a 90/10 training/test split on the CELEXdataset.
On the same set, Demberg et al (2007) ob-tain 99.28% word accuracy by applying the systemof Schmid et al (2007).
Our score using a similarsplit is 99.78%.Note that none of these scores are directly com-parable, because we did not use the same train-testsplits as our competitors, just similar amounts oftraining and test data.
Furthermore, when assem-bling random train-test splits, it is quite possiblethat words sharing the same lemma will appear inboth the training and test sets.
This makes the prob-lem much easier with large training sets, where thechance of this sort of overlap becomes high.
There-fore, any large data results may be slightly inflatedas a prediction of actual out-of-dictionary perfor-mance.6 L2P PerformanceAs we stated from the outset, one of our primary mo-tivations for exploring orthographic syllabification isthe improvements it can produce in L2P systems.To explore this, we tested our model in conjunc-tion with a recent L2P system that has been shownto predict phonemes with state-of-the-art word ac-curacy (Jiampojamarn et al, 2007).
Using a modelderived from training data, this L2P system first di-vides a word into letter chunks, each containing oneor two letters.
A local classifier then predicts a num-ber of likely phonemes for each chunk, with confi-dence values.
A phoneme-sequence Markov modelis then used to select the most likely sequence fromthe phonemes proposed by the local classifier.Syllabification English Dutch GermanNone 84.67 91.56 90.18Numbered NB 85.55 92.60 90.59Break ONC 85.59 N/A N/ADictionary 86.29 93.03 90.57Table 3: Word accuracy percentage on the letter-to-phoneme task with and without the syllabification infor-mation.To measure the improvement syllabification caneffect on the L2P task, the L2P system was trainedwith syllabified, rather than unsyllabified words.Otherwise, the execution of the L2P system remainsunchanged.
Data for this experiment is again drawn574from the CELEX dictionary.
In Table 3, we re-port the average word accuracy achieved by the L2Psystem using 10-fold cross-validation.
We reportL2P performance without any syllabification infor-mation, with perfect dictionary syllabification, andwith our small learned models of syllabification.L2P performance with dictionary syllabification rep-resents an approximate upper bound on the contribu-tions of our system.Our syllabification model improves L2P perfor-mance.
In English, perfect syllabification producesa relative error reduction of 10.6%, and our modelcaptures over half of the possible improvement, re-ducing the error rate by 6.0%.
To our knowledge,this is the first time a syllabification model has im-proved L2P performance in English.
Previous workincludes Marchand and Damper (2007)?s experi-ments with SbA and the L2P problem on NETtalk.Although perfect syllabification reduces their L2Prelative error rate by 18%, they find that their learnedmodel actually increases the error rate.
Chen (2003)achieved word accuracy of 91.7% for his L2P sys-tem, testing on a different dictionary (Pronlex) witha much larger training set.
He does not report wordaccuracy for his syllabification model.
However, hisbaseline L2P system is not improved by adding asyllabification model.For Dutch, perfect syllabification reduces the rela-tive L2P error rate by 17.5%; we realize over 70% ofthe available improvement with our syllabificationmodel, reducing the relative error rate by 12.4%.In German, perfect syllabification produces onlya small reduction of 3.9% in the relative error rate.Experiments show that our learned model actuallyproduces a slightly higher reduction in the relativeerror rate.
This anomaly may be due to errors orinconsistencies in the dictionary syllabifications thatare not replicated in the model output.
Previously,Demberg (2006) generated statistically significantL2P improvements in German by adding syllabifi-cation pre-processing.
However, our improvementsare coming at a much higher baseline level of wordaccuracy ?
90% versus only 75%.Our results also provide some evidence that syl-labification preprocessing may be more beneficialto L2P than morphological preprocessing.
Dem-berg et al (2007) report that oracle morphologicalannotation produces a relative error rate reductionof 3.6%.
We achieve a larger decrease at a higherlevel of accuracy, using an automatic pre-processingtechnique.
This may be because orthographic syl-labifications already capture important facts about aword?s morphology.7 ConclusionWe have applied structured SVMs to the syllabifi-cation problem, clearly outperforming existing sys-tems.
In English, we have demonstrated a 33% rela-tive reduction in error rate with respect to the state ofthe art.
We used this improved syllabification to in-crease the letter-to-phoneme accuracy of an existingL2P system, producing a system with 85.5% wordaccuracy, and recovering more than half of the po-tential improvement available from perfect syllab-ification.
This is the first time automatic syllabi-fication has been shown to improve English L2P.Furthermore, we have demonstrated the language-independence of our system by producing compet-itive orthographic syllabification solutions for bothDutch and German, achieving word syllabificationaccuracies of 98% and 99% respectively.
Theselearned syllabification models also improve accu-racy for German and Dutch letter-to-phoneme con-version.In future work on this task, we plan to exploreadding morphological features to the SVM, in an ef-fort to overcome errors in compound words and in-flectional forms.
We would like to experiment withperforming L2P and syllabification jointly, ratherthan using syllabification as a pre-processing stepfor L2P.
We are also working on applying ourmethod to phonetic syllabification.AcknowledgementsMany thanks to Sittichai Jiampojamarn for his helpwith the L2P experiments, and to Yannick Marchandfor providing the SbA results.This research was supported by the Natural Sci-ences and Engineering Research Council of Canadaand the Alberta Informatics Circle of Research Ex-cellence.ReferencesYasemin Altun, Ioannis Tsochantaridis, and ThomasHofmann.
2003.
Hidden Markov support vector ma-575chines.
Proceedings of the 20th International Confer-ence on Machine Learning (ICML), pages 3?10.Susan Bartlett.
2007.
Discriminative approach to auto-matic syllabification.
Master?s thesis, Department ofComputing Science, University of Alberta.Gosse Bouma.
2002.
Finite state methods for hyphen-ation.
Natural Language Engineering, 1:1?16.Stanley Chen.
2003.
Conditional and joint models forgrapheme-to-phoneme conversion.
Proceedings of the8th European Conference on Speech Communicationand Technology (Eurospeech).Walter Daelemans and Antal van den Bosch.
1992.Generalization performance of backpropagation learn-ing on a syllabification task.
Proceedings of the 3rdTwente Workshop on Language Technology, pages 27?38.Walter Daelemans, Antal van den Bosch, and Ton Wei-jters.
1997.
IGTree: Using trees for compression andclassification in lazy learning algorithms.
Artificial In-telligence Review, pages 407?423.Vera Demberg, Helmust Schmid, and Gregor Mo?hler.2007.
Phonological constraints and morphologicalpreprocessing for grapheme-to-phoneme conversion.Proceedings of the 45th Annual Meeting of the Associ-ation of Computational Linguistics (ACL).Vera Demberg.
2006.
Letter-to-phoneme conversion fora German text-to-speech system.
Master?s thesis, Uni-versity of Stuttgart.Philip Babcock Gove, editor.
1993.
Webster?s Third NewInternational Dictionary of the English Language,Unabridged.
Merriam-Webster Inc.Sittichai Jiampojamarn, Grzegorz Kondrak, and TarekSherif.
2007.
Applying many-to-many alignmentsand hidden Markov models to letter-to-phoneme con-version.
Proceedings of the Human Language Tech-nology Conference of the North American Chapterof the Association of Computational Linguistics HLT-NAACL, pages 372?379.Brigitte Krenn.
1997.
Tagging syllables.
Proceedings ofEurospeech, pages 991?994.Yannick Marchand and Robert Damper.
2007.
Can syl-labification improve pronunciation by analogy of En-glish?
Natural Language Engineering, 13(1):1?24.Yannick Marchand, Connie Adsett, and Robert Damper.2007.
Evaluation of automatic syllabification algo-rithms for English.
In Proceedings of the 6th Inter-national Speech Communication Association (ISCA)Workshop on Speech Synthesis.Yannick Marchand.
2007.
Personal correspondence.Karin Mu?ller.
2001.
Automatic detection of syllableboundaries combining the advantages of treebank andbracketed corpora training.
Proceedings on the 39thMeeting of the Association for Computational Linguis-tics (ACL), pages 410?417.Steve Pearson, Roland Kuhn, Steven Fincke, and NickKibre.
2000.
Automatic methods for lexical stress as-signment and syllabification.
In Proceedings of the 6thInternational Conference on Spoken Language Pro-cessing (ICSLP), pages 423?426.Helmut Schmid, Bernd Mo?bius, and Julia Weidenkaff.2007.
Tagging syllable boundaries with joint N-grammodels.
Proceedings of Interspeech.Ioannis Tsochantaridis, Thomas Hofmann, ThorstenJoachims, and Yasemin Altun.
2004.
Support vec-tor machine learning for interdependent and structuredoutput spaces.
Proceedings of the 21st InternationalConference on Machine Learning (ICML), pages 823?830.Antal van den Bosch.
1997.
Learning to pronouncewritten words: a study in inductive language learning.Ph.D.
thesis, Universiteit Maastricht.576
