Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 88?97,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsSimple, Robust and (almost) Unsupervised Generation of PolarityLexicons for Multiple LanguagesI?naki San Vicente, Rodrigo Agerri, German RigauIXA NLP GroupUniversity of the Basque Country (UPV/EHU)Donostia-San Sebasti?an{inaki.sanvicente,rodrigo.agerri,german.rigau}@ehu.esAbstractThis paper presents a simple, robust and(almost) unsupervised dictionary-basedmethod, qwn-ppv (Q-WordNet as Person-alized PageRanking Vector) to automati-cally generate polarity lexicons.
We showthat qwn-ppv outperforms other automat-ically generated lexicons for the four ex-trinsic evaluations presented here.
It alsoshows very competitive and robust resultswith respect to manually annotated ones.Results suggest that no single lexicon isbest for every task and dataset and thatthe intrinsic evaluation of polarity lexiconsis not a good performance indicator ona Sentiment Analysis task.
The qwn-ppvmethod allows to easily create quality po-larity lexicons whenever no domain-basedannotated corpora are available for a givenlanguage.1 IntroductionOpinion Mining and Sentiment Analysis are im-portant for determining opinions about commer-cial products, on companies reputation manage-ment, brand monitoring, or to track attitudes bymining social media, etc.
Given the explosion ofinformation produced and shared via the Internet,it is not possible to keep up with the constant flowof new information by manual methods.Sentiment Analysis often relies on the availabil-ity of words and phrases annotated according tothe positive or negative connotations they convey.
?Beautiful?, ?wonderful?, and ?amazing?
are exam-ples of positive words whereas ?bad?, ?awful?, and?poor?
are examples of negatives.The creation of lists of sentiment words hasgenerally been performed by means of manual-,dictionary- and corpus-based methods.
Manuallycollecting such lists of polarity annotated words islabor intensive and time consuming, and is thususually combined with automated approaches asthe final check to correct mistakes.
However,there are well known lexicons which have beenfully (Stone et al., 1966; Taboada et al., 2010) orat least partially manually created (Hu and Liu,2004; Riloff and Wiebe, 2003).Dictionary-based methods rely on some dictio-nary or lexical knowledge base (LKB) such asWordNet (Fellbaum and Miller, 1998) that con-tain synonyms and antonyms for each word.
Asimple technique in this approach is to start withsome sentiment words as seeds which are thenused to perform some iterative propagation on theLKB (Hu and Liu, 2004; Strapparava and Vali-tutti, 2004; Kim and Hovy, 2004; Takamura et al.,2005; Turney and Littman, 2003; Mohammad etal., 2009; Agerri and Garc?
?a-Serrano, 2010; Bac-cianella et al., 2010).Corpus-based methods have usually been ap-plied to obtain domain-specific polarity lexicons:they have been created by either starting from aseed list of known words and trying to find otherrelated words in a corpus or by attempting to di-rectly adapt a given lexicon to a new one usinga domain-specific corpus (Hatzivassiloglou andMcKeown, 1997; Turney and Littman, 2003; Dinget al., 2008; Choi and Cardie, 2009; Mihalcea etal., 2007).
One particular issue arising from cor-pus methods is that for a given domain the sameword can be positive in one context but negativein another.
This is also a problem shared by man-ual and dictionary-based methods, and that is whyqwn-ppv also produces synset-based lexicons forapproaches on Sentiment Analysis at sense level.This paper presents a simple, robust and(almost) unsupervised dictionary-based method,QWordNet-PPV (QWordNet by PersonalizedPageRank Vector) to automatically generatepolarity lexicons based on propagating someautomatically created seeds using a Personalized88PageRank algorithm (Agirre et al., 2014; Agirreand Soroa, 2009) over a LKB projected into agraph.
We see qwn-ppv as an effective method-ology to easily create polarity lexicons for anylanguage for which a WordNet is available.This paper empirically shows that: (i) qwn-ppvoutperforms other automatically generated lexi-cons (e.g.
SentiWordNet 3.0, MSOL) on the 4extrinsic evaluations presented here; it also dis-plays competitive and robust results also with re-spect to manually annotated lexicons; (ii) no singlepolarity lexicon is fit for every Sentiment Analy-sis task; depending on the text data and the taskitself, one lexicon will perform better than oth-ers; (iii) if required, qwn-ppv efficently generatesmany lexicons on demand, depending on the taskon which they will be used; (iv) intrinsic evalua-tion is not appropriate to judge whether a polar-ity lexicon is fit for a given Sentiment Analysis(SA) task because good correlation with respect toa gold-standard does not correspond with correla-tion with respect to a SA task; (v) it is easily ap-plicable to create qwn-ppv(s) for other languages,and we demonstrate it here by creating many po-larity lexicons not only for English but also forSpanish; (vi) the method works at both word andsense levels and it only requires the availabilityof a LKB or dictionary; finally, (vii) a dictionary-based method like qwn-ppv allows to easily cre-ate quality polarity lexicons whenever no domain-based annotated reviews are available for a givenlanguage.
After all, there usually is available adictionary for a given language; for example, theOpen Multilingual WordNet site lists WordNetsfor up to 57 languages (Bond and Foster, 2013).Although there has been previous work usinggraph methods for obtaining lexicons via propa-gation, the qwn-ppv method to combine the seedgeneration and the Personalized PageRank prop-agation is novel.
Furthermore, it is considerablesimpler and obtains better and easier to reproduceresults than previous automatic approaches (Esuliand Sebastiani, 2007; Mohammad et al., 2009;Rao and Ravichandran, 2009).Next section reviews previous related work, tak-ing special interest on those that are currentlyavailable for evaluation purposes.
Section 3 de-scribes the qwn-ppv method to automatically gen-erate lexicons.
The resulting lexical resources areevaluated in section 4.
We finish with some con-cluding remarks and future work in section 5.2 Related WorkThere is a large amount of work on SentimentAnalysis and Opinion Mining, and good com-prehensive overviews are already available (Pangand Lee, 2008; Liu, 2012), so we will reviewthe most representative and closest to the presentwork.
This means that we will not be review-ing corpus-based approaches but rather those con-structed manually or upon a dictionary or LKB.We will in turn use the approaches here reviewedfor comparison with qwn-ppv in section 4.The most popular manually-built polarity lexi-con is part of the General Inquirer (Stone et al.,1966), and consists of 1915 words labelled as?positive?
and 2291 as ?negative?.
Taboada et al.
(2010) manually created their lexicons annotatingthe polarity of 6232 words on a scale of 5 to -5.Liu et al., starting with Hu and Liu (2004), havealong the years collected a manually corrected po-larity lexicon which is formed by 4818 negativeand 2041 positive words.
Another manually cor-rected lexicon (Riloff and Wiebe, 2003) is the oneused by the Opinion Finder system (Wilson et al.,2005) and contains 4903 negatively and 2718 pos-itively annotated words respectively.Among the automatically built lexicons, Turneyand Littman (2003) proposed a minimally super-vised algorithm to calculate the polarity of a worddepending on whether it co-ocurred more with apreviously collected small set of positive wordsrather than with a set of negative ones.
Agerri andGarc?
?a Serrano presented a very simple methodto extract the polarity information starting fromthe quality synset in WordNet (Agerri and Garc?
?a-Serrano, 2010).
Mohammad et al.
(2009) de-veloped a method in which they first identify (bymeans of affixes rules) a set of positive/negativewords which act as seeds, then used a Roget-likethesaurus to mark the synonymous words for eachpolarity type and to generalize from the seeds.They produce several lexicons the best of which,MSOL(ASL and GI) contains 51K and 76K en-tries respectively and uses the full General Inquireras seeds.
They performed both intrinsic and ex-trinsic evaluations using the MPQA 1.1 corpus.Finally, there are two approaches that are some-what closer to us, because they are based on Word-Net and graph-based methods.
SentiWordNet 3.0(Baccianella et al., 2010) is built in 4 steps: (i)they select the synsets of 14 paradigmatic pos-itive and negative words used as seeds (Turney89and Littman, 2003).
These seeds are then it-eratively extended following the construction ofWordNet-Affect (Strapparava and Valitutti, 2004).
(ii) They train 7 supervised classifiers with thesynsets?
glosses which are used to assign polar-ity and objectivity scores to WordNet senses.
(iii)In SentiWordNet 3.0 (Esuli and Sebastiani, 2007)they take the output of the supervised classifiersas input to applying PageRank to WordNet 3.0?sgraph.
(iv) They intrinsically evaluate it with re-spect to MicroWnOp-3.0 using the p-normalizedKendall ?
distance (Baccianella et al., 2010).
Raoand Ravichandran (2009) apply different semi-supervised graph algorithms (Mincuts, Random-ized Mincuts and Label Propagation) to a set ofseeds constructed from the General Inquirer.
Theyevaluate the generated lexicons intrinsically takingthe General Inquirer as the gold standard for thosewords that had a match in the generated lexicons.In this paper, we describe two methods to au-tomatically generate seeds either by followingAgerri and Garc?
?a-Serrano (2010) or using Tur-ney and Littman?s (2003) seeds.
The automati-cally obtained seeds are then fed into a Person-alized PageRank algorithm which is applied overa WordNet projected on a graph.
This method isfully automatic, simple and unsupervised as it onlyrelies on the availability of a LKB.3 Generating qwn-ppvThe overall procedure of our approach consists oftwo steps: (1) automatically creates a set of seedsby iterating over a LKB (e.g.
a WordNet) rela-tions; and (2) uses the seeds to initialize contextsto propagate over the LKB graph using a Personal-ized Pagerank algorithm.
The result is qwn-ppv(s):Q-WordNets as Personalized PageRanking Vec-tors.3.1 Seed GenerationWe generate seeds by means of two different auto-matic procedures.1.
AG: We start at the quality synset of WordNetand iterate over WordNet relations followingthe original Q-WordNet method described inAgerri and Garc?
?a Serrano (2010).2.
TL: We take a short manually created listof 14 positive and negative words (Turneyand Littman, 2003) and iterate over Word-Net using five relations: antonymy, similarity,derived-from, pertains-to and also-see.The AG method starts the propagation fromthe attributes of the quality synset in WordNet.There are five noun quality senses in WordNet,two of which contain attribute relations (to adjec-tives).
From the quality1nsynset the attribute re-lation takes us to positive1a, negative1a, good1aandbad1a; quality2nleads to the attributes superior1aandinferior2a.
The following step is to iterate throughevery WordNet relation collecting (i.e., annotat-ing) those synsets that are accessible from theseeds.
Both AG and TL methods to generate seedsrely on a number of relations to obtain a more bal-anced POS distribution in the output synsets.
Theoutput of both methods is a list of (assumed to be)positive and negative synsets.
Depending on thenumber of iterations performed a different numberof seeds to feed UKB is obtained.
Seed numbersvary from 100 hundred to 10K synsets.
Both seedcreation methods can be applied to any WordNet,not only Princeton WordNet, as we show in sec-tion 4.3.2 PPV generationThe second and last step to generate qwn-ppv(s)consists of propagating over a WordNet graph toobtain a Personalized PageRanking Vector (PPV),one for each polarity.
This step requires:1.
A LKB projected over a graph.2.
A Personalized PageRanking algorithmwhich is applied over the graph.3.
Seeds to create contexts to start the propaga-tion, either words or synsets.Several undirected graphs based on WordNet3.0 as represented by the MCR 3.0 (Agirre etal., 2012) have been created for the experimenta-tion, which correspond to 4 main sets: (G1) twographs consisting of every synset linked by thesynonymy and antonymy relations; (G2) a graphwith the nodes linked by every relation, includ-ing glosses; (G3) a graph consisting of the synsetslinked by every relation except those that arelinked by antonymy; finally, (G4) a graph consist-ing of the nodes related by every relation exceptthe antonymy and gloss relations.Using the (G1) graphs, we propagate from theseeds over each type of graph (synonymy andantonymy) to obtain two rankings per polarity.90Synset Level Word levelPositives Negatives Positives NegativesLexicon size P R F P R F size P R F P R FAutomatically createdMSOL(ASL-GI)* 32706 .65 .45 .53 .58 .76 .66 76400 .70 .49 .58 .61 .79 .69QWN 15508 .69 .53 .60 .62 .76 .68 11693 .64 .53 .58 .60 .70 .65SWN 27854 .73 .57 .64 .65 .79 .71 38346 .70 .55 .62 .63 .77 .69QWN-PPV-AG(s03 G1/w01 G1) 2589 .77 .63 .69 .69 .81 .74 5119 .68 .77 .72 .73 .64 .68QWN-PPV-TL(s04 G1/w01 G1) 5010 .76 .66 .70 .70 .79 .74 4644 .68 .71 .69 .70 .67 .68(Semi-) Manually createdGI* 2791 .74 .57 .64 .65 .80 .72 3376 .79 .64 .71 .70 .83 .76OF* 4640 .77 .61 .68 .68 .81 .74 6860 .82 .71 .76 .74 .84 .79Liu* 4127 .81 .63 .71 .70 .85 .76 6786 .85 .74 .79 .77 .87 .82SO-CAL* 4212 .75 .57 .64 .65 .81 .72 6226 .82 .70 .76 .74 .85 .79Table 1: Evaluation of lexicons at document level using Bespalov?s Corpus.The graphs created in (G2), (G3) and (G4) areused to obtain two ranks, one for each polarity bypropagating from the seeds.
In all four cases thedifferent polarity rankings have to be combined inorder to obtain a final polarity lexicon: the polar-ity score pol(s) of a given synset s is computedby adding its scores in the positive rankings andsubtracting its scores in the negative rankings.
Ifpol(s) > 0 then s is included in the final lexiconas positive.
If pol(s) < 0 then s is included in thefinal lexicon as negative.
We assume that synsetswith null polarity scores have no polarity and con-sequently they are excluded from the final lexicon.The Personalized PageRanking propagation isperformed starting from both synsets and wordsand using both AG and TL styles of seed gen-eration, as explained in section 3.1.
Combin-ing the various possibilities will produce at least6 different lexicons for each iteration, dependingon which decisions are taken about which graph,seeds and word/synset to create the qwn-ppv(s).
Infact, the experiments produced hundreds of lexi-cons, according to the different iterations for seedgeneration1, but we will only refer to those thatobtain the best results in the extrinsic evaluations.With respect to the algorithm to propagate overthe WordNet graph from the automatically createdseeds, we use a Personalized PageRank algorithm(Agirre et al., 2014; Agirre and Soroa, 2009).
Thefamous PageRank (Brin and Page, 1998) algo-rithm is a method to produce a rank from the ver-tices in a graph according to their relative struc-tural importance.
PageRank has also been viewedas the result of a Random Walk process, where thefinal rank of a given node represents the probabil-ity of a random walk over the graph which ends onthat same node.
Thus, if we take the created Word-1The total time to generate the final 352 QWN-PPV prop-agations amounted to around two hours of processing time ina standard PC.Net graph G with N vertices v1, .
.
.
, vnand diasbeing the outdegree of node i, plus a N ?N tran-sition probability matrix M where Mji= 1/diif a link from i to j exists and 0 otherwise, thencalculating the PageRank vector over a graph Gamounts to solve the following equation (1):Pr = cMPr + (1?
c)v (1)In the traditional PageRank, vector v is a uni-form normalized vector whose elements values areall 1/N , which means that all nodes in the graphare assigned the same probabilities in case of arandom walk.
Personalizing the PageRank algo-rithm in this case means that it is possible to makevector v non-uniform and assign stronger proba-bilities to certain nodes, which would make thealgorithm to propagate the initial importance ofthose nodes to their vicinity.
Following Agirre etal.
(2014), in our approach this translates into ini-tializing vector v with those senses obtained by theseed generation methods described above in sec-tion 3.1.
Thus, the initialization of vector v us-ing the seeds allows the Personalized propagationto assign greater importance to those synsets inthe graph identified as being positive and negative,which resuls in a PPV with the weigths skewed to-wards those nodes initialized/personalized as pos-itive and negative.4 EvaluationPrevious approaches have provided intrinsic eval-uation (Mohammad et al., 2009; Rao andRavichandran, 2009; Baccianella et al., 2010) us-ing manually annotated resources such as the Gen-eral Inquirer (Stone et al., 1966) as gold stan-dard.
To facilitate comparison, we also providesuch evaluation in section 4.3.
Nevertheless, andas demonstrated by the results of the extrinsic eval-uations, we believe that polarity lexicons should91Synset Level Word levelPositives Negatives Positives NegativesLexicon size P R F P R F size P R F P R FAutomatically createdMSOL(ASL-GI)* 32706 .56 .37 .44 .76 .87 .81 76400 .67 .5 .57 .80 .89 .85QWN 15508 .63 .22 .33 .73 .94 .83 11693 .58 .22 .31 .73 .93 .82SWN 27854 .57 .33 .42 .75 .89 .81 38346 .55 .55 .55 .80 .8 .80QWN-PPV-AG (w10 G3/s09 G4) 117485 .60 .63 .62 .83 .82 .83 144883 .65 .50 .57 .80 .88 .84QWN-PPV-TL (s05 G4) 114698 .61 .58 .59 .82 .83 .83 144883 .66 .53 .59 .81 .88 .84(Semi-) Manually createdGI* 2791 .70 .32 .44 .76 .94 .84 3376 .71 .56 .62 .82 .90 .86OF* 4640 .67 .37 .48 .77 .92 .84 6860 .75 .68 .71 .87 .90 .88Liu* 4127 .67 .33 .44 .76 .93 .83 6786 .78 .45 .57 .79 .94 .86SO-CAL* 4212 .69 .3 .42 .75 .94 .84 6226 .73 .53 .61 .81 .91 .86Table 2: Evaluation of lexicons using averaged ratio on the MPQA 1.2testCorpus.in general be evaluated extrinsically.
After all,any polarity lexicon is as good as the results ob-tained by using it for a particular Sentiment Anal-ysis task.Our goal is to evaluate the polarity lexiconssimplifying the evaluation parameters to avoid asmany external influences as possible on the re-sults.
We compare our work with most of thelexicons reviewed in section 2, both at synsetand word level, both manually and automaticallygenerated: General Inquirer (GI), Opinion Finder(OF), Liu, Taboada et al.
?s (SO-CAL), Agerriand Garc?
?a-Serrano (2010) (QWN), Mohammadet al?s, (MSOL(ASL-GI)) and SentiWordNet 3.0(SWN).
The results presented in section 4.2 showthat extrinsic evaluation is more meaningful to de-termine the adequacy of a polarity lexicon for aspecific Sentiment Analysis task.4.1 Datasets and Evaluation SystemThree different corpora were used: Bespalov etal.
?s (2011) and MPQA (Riloff and Wiebe, 2003)for English, and HOpinion2in Spanish.
In addi-tion, we divided the corpus into two subsets (75%development and 25% test) for applying our ratiosystem for the phrase polarity task too.
Note thatthe development set is only used to set up the po-larity classification task, and that the generation ofqwn-ppv lexicons is unsupervised.For Spanish we tried to reproduce the Englishsettings with Bespalov?s corpus.
Thus, both devel-opment and test sets were created from the HOpin-ion corpus.
As it contains a much higher propor-tion of positive reviews, we created also subsetswhich contain a balanced number of positive andnegative reviews to allow for a more meaningfulcomparison than that of table 6.
Table 3 shows thenumber of documents per polarity for Bespalov?s,2http://clic.ub.edu/corpus/hopinionMPQA 1.2 and HOpinion.Corpus POS docs NEG docs TotalBespalovdev23,112 23,112 46,227Bespalovtest10,557 10,557 21,115MPQA 1.2dev2,315 5,260 7,575MPQA 1.2test771 1,753 2,524MPQA 1.2total3,086 7,013 10,099HOpinion Balanceddev1,582 1,582 3,164HOpinion Balancedtest528 528 1,056HOpiniondev9,236 1,582 10,818HOpiniontest3,120 528 3,648Table 3: Number of positive and negative docu-ments in train and test sets.We report results of 4 extrinsic evaluations ortasks, three of them based on a simple ratio av-erage system, inspired by Turney (2002), and an-other one based on Mohammad et al.
(2009).
Wefirst implemented a simple average ratio classifierwhich computes the average ratio of the polaritywords found in document d:polarity(d) =?w?dpol(w)|d|(2)where, for each polarity, pol(w) is 1 if w is in-cluded in the polarity lexicon and 0 otherwise.Documents that reach a certain threshold are clas-sified as positive, and otherwise as negative.
Tosetup an evaluation enviroment as fair as possi-ble for every lexicon, the threshold is optimised bymaximising accuracy over the development data.Second, we implemented a phrase polarity taskidentification as described by Mohammad et al.(2009).
Their method consists of: (i) if any ofthe words in the target phrase is contained in thenegative lexicon, then the polarity is negative; (ii)if none of the words are negative, and at least oneword is in the positive lexicon, then is positive;(iii) the rest are not tagged.We chose this very simple polarity estimatorsbecause our aim was to minimize the role other92Synset Level Word levelPositives Negatives Positives NegativesLexicon size P R F P R F size P R F P R FAutomatically createdMSOL(ASL-GI)* 32706 .52 .48 .50 .85 .62 .71 76400 .68 .56 .62 .82 .86 .84QWN 15508 .50 .36 .42 .84 .32 .46 11693 .45 .49 .47 .78 .51 .61SWN 27854 .50 .45 .47 .85 .48 .61 38346 .49 .52 .50 .78 .68 .73QWN-PPV-AG (s09 G3/w02 G3) 117485 .59 .67 .63 .85 .78 .82 147194 .64 .64 .64 .84 .83 .83QWN-PPV-TL (w02 G3/s06 G3) 117485 .59 .57 .58 .82 .81 .81 147194 .63 .67 .65 .85 .81 .83(Semi-) Manually createdGI* 2791 .60 .40 .47 .91 .38 .54 3376 .70 .60 .65 .93 .52 .67OF* 4640 .63 .42 .50 .93 .46 .62 6860 .75 .71 .73 .95 .66 .78Liu* 4127 .65 .36 .47 .94 .45 .60 6786 .78 .49 .60 .97 .61 .75SO-CAL* 4212 .65 .37 .47 .92 .45 .60 6226 .73 .57 .64 .96 .59 .73Table 4: Evaluation of lexicons at phrase level using Mohammad et al.
?s (2009) method on MPQA1.2totalCorpus.aspects play in the evaluation and focus on how,other things being equal, polarity lexicons performin a Sentiment Analysis task.
The average ratiois used to present results of tables 1 and 2 (withBespalov corpus), and 5 and 6 (with HOpinion),whereas Mohammad et al.
?s is used to report re-sults in table 4.
Mohammad et al.
?s (2009) testsetbased on MPQA 1.1 is smaller, but both MPQA1.1 and 1.2 are hugely skewed towards negativepolarity (30% positive vs. 70% negative).All datasets were POS tagged and WordSense Disambiguated using FreeLing (Padr?o andStanilovsky, 2012; Agirre and Soroa, 2009).
Hav-ing word sense annotated datasets gives us the op-portunity to evaluate the lexicons both at word andsense levels.
For the evaluation of those lexiconsthat are synset-based, such as qwn-ppv and Sen-tiWordNet 3.0, we convert them from senses towords by taking every word or variant containedin each of their senses.
Moreover, if a lemma ap-pears as a variant in several synsets the most fre-quent polarity is assigned to that lemma.With respect to lexicons at word level, we takethe most frequent sense according to WordNet 3.0for each of their positive and negative words.
Notethat the latter conversion, for synset based evalua-tion, is mostly done to show that the evaluation atsynset level is harder independently of the qualityof the lexicon evaluated.4.2 ResultsAlthough tables 1, 2 and 4 also present re-sults at synset level, it should be noted that theonly polarity lexicons available to us for com-parison at synset level were Q-WordNet (Agerriand Garc?
?a-Serrano, 2010) and SentiWordNet 3.0(Baccianella et al., 2010).
QWN-PPV-AG refersto the lexicon generated starting from AG?s seeds,and QWN-PPV-TL using TL?s seeds as describedin section 3.1.
Henceforth, we will use qwn-ppv torefer to the overall method presented in this paper,regardless of the seeds used.For every qwn-ppv result reported in this sec-tion, we have used every graph described in sec-tion 3.2.
The configuration of each qwn-ppv in theresults specifies which seed iteration is used as theinitialization of the Personalized PageRank algo-rithm, and on which graph.
Thus, QWN-PPV-TL(s05 G4) in table 2 means that the 5th iteration ofsynset seeds was used to propagate over graph G4.If the configuration were (w05 G4) it would havemeant ?the 5th iteration of word seeds were usedto propagate over graph G4?.
The simplicity ofour approach allows us to generate many lexiconssimply by projecting a LKB over different graphs.The lexicons marked with an asterisk denotethose that have been converted from word tosenses using the most frequent sense of WordNet3.0.
We would like to stress again that the purposeof such word to synset conversion is to show thatSA tasks at synset level are harder than at wordlevel.
In addition, it should also be noted that inthe case of SO-CAL (Taboada et al., 2010), wehave reduced what is a graded lexicon with scoresranging from 5 to -5 into a binary one.Table 1 shows that (at least partially) manuallybuilt lexicons obtain the best results on this eval-uation.
It also shows that qwn-ppv clearly out-performs any other automatically built lexicons.Moreover, manually built lexicons suffer from theevaluation at synset level, obtaining most of themlower scores than qwn-ppv, although Liu?s (Huand Liu, 2004) still obtains the best results.
In anycase, for an unsupervised procedure, qwn-ppv lex-icons obtain very competitive results with respectto manually created lexicons and is the best amongthe automatic methods.
It should also be noted thatthe best results of qwn-ppv are obtained with graph93G1 and with very few seed iterations.Table 2 again sees the manually built lexi-cons performing better although overall the dif-ferences are lower with respect to automaticallybuilt lexicons.
Among these, qwn-ppv again ob-tains the best results, both at synset and wordlevel, although in the latter the differences withMSOL(ASL-GI) are not large.
Finally, table 4shows that qwn-ppv again outperforms other auto-matic approaches and is closer to those have been(partially at least) manually built.
In both MPQAevaluations the best graph overall to propagate theseeds is G3 because this type of task favours highrecall.Positives NegativesLexicon size P R F P R FAutomatically createdSWN 27854 .87 .99 .93 .70 .16 .27QWN-PPV-AG(wrd01 G1)3306 .86 .00 .92 .67 .01 .02QWN-PPV-TL(s04 G1)5010 .89 .96 .93 .58 .30 .39Table 5: Evaluation of Spanish lexicons using thefull HOpinion corpus at synset level.We report results on the Spanish HOpinion cor-pus in tables 5 and 6.
Mihalcea(f) is a manu-ally revised lexicon based on the automaticallybuilt Mihalcea(m) (P?erez-Rosas et al., 2012).
Elh-Polar (Saralegi and San Vicente, 2013) is semi-automatically built and manually corrected.
SO-CAL is built manually.
SWN and QWN-PPV havebeen built via the MCR 3.0?s ILI by applying thesynset to word conversion previously described onthe Spanish dictionary of the MCR.
The results forSpanish at word level in table 6 show the sametrend as for English: qwn-ppv is the best of theautomatic approaches and it obtains competitivealthough not as good as the best of the manuallycreated lexicons (ElhPolar).
Due to the dispro-portionate number of positive reviews, the resultsfor the negative polarity are not useful to draw anymeaningful conclusions.
Thus, we also performedan evaluation with HOpinion Balanced set as listedin table 3.The results with a balanced HOpinion, notshown due to lack of space, also confirm the pre-vious trend: qwn-ppv outperforms other automaticapproaches but is still worse than the best of themanually created ones (ElhPolar).Positives NegativesLexicon size P R F P R FAutomatically createdMihalcea(m) 2496 .86 .00 .92 .00 .00 .00SWN 9712 .88 .97 .92 .55 .19 .28QWN-PPV-AG(s11 G1)1926 .89 .97 .93 .59 .26 .36QWN-PPV-TL(s03 G1)939 .89 .98 .93 .71 .26 .38(Semi-) Manually createdElhPolar 4673 .94 .94 .94 .64 .64 .64Mihalcea(f) 1347 .91 .96 .93 .61 .41 .49SO-CAL 4664 .92 .96 .94 .70 .51 .59Table 6: Evaluation of Spanish lexicons using thefull HOpinion corpus at word level.4.3 Intrinsic evaluationTo facilitate intrinsic comparison with previousapproaches, we evaluate our automatically gener-ated lexicons against GI.
For each qwn-ppv lex-icon shown in previous extrinsic evaluations, wecompute the intersection between the lexicon andGI, and evaluate the words in that intersection.
Ta-ble 7 shows results for the best-performing QWN-PPV lexicons (both using AG and TL seeds) inthe extrinsic evaluations at word level of tables 1(first two rows), 2 (rows 3 and 4) and 4 (rows 5and 6).
We can see that QWN-PPV lexicons sys-tematically outperform SWN in number of correctentries.
QWN-PPV-TL lexicons obtain 75.04%of correctness on average.
The best performinglexicon contains up to 81.07% of correct entries.Note that we did not compare the results withMSOL(ASL-GI) because it contains the GI.Lexicon ?
wrt.
GI Acc.
Pos NegSWN 2,755 .74 .76 .73QWN-PPV-AG (w01 G1) 849 .71 .68 .75QWN-PPV-TL (w01 G1) 713 .78 .80 .76QWN-PPV-AG (s09 G4) 3,328 .75 .75 .77QWN-PPV-TL (s05 G4) 3,333 .80 .84 .77QWN-PPV-AG (w02 G3) 3,340 .74 .71 .77QWN-PPV-TL (s06 G3) 3,340 .77 .79 .77Table 7: Accuracy QWN-PPV lexicons and SWNwith respect to the GI lexicon.4.4 DiscussionQWN-PPV lexicons obtain the best results amongthe evaluations for English and Spanish.
Further-more, across tasks and datasets qwn-ppv providesa more consistent and robust behaviour than mostof the manually-built lexicons apart from OF.
Theresults also show that for a task requiring high94recall the larger graphs, e.g.
G3, are preferable,whereas for a more balanced dataset and documentlevel task smaller G1 graphs perform better.These are good results considering that ourmethod to generate qwn-ppv is simpler, more ro-bust and adaptable than previous automatic ap-proaches.
Furthermore, although also based ona Personalized PageRank application, it is muchsimpler than SentiWordNet 3.0, consistently out-performed by qwn-ppv on every evaluation anddataset.
The main differences with respect to Sen-tiWordNet?s approach are the following: (i) theseed generation and training of 7 supervised clas-sifiers corresponds in qwn-ppv to only one simplestep, namely, the automatic generation of seedsas explained in section 3.1; (ii) the generationof qwn-ppv only requires a LKB?s graph for thePersonalized PageRank propagation, no disam-biguated glosses; (iii) the graph they use to dothe propagation also depends on disambiguatedglosses, not readily available for any language.The fact that qwn-ppv is based on alreadyavailable WordNets projected onto simple graphsis crucial for the robustness and adaptability ofthe qwn-ppv method across evaluation tasks anddatasets: Our method can quickly create, over dif-ferent graphs, many lexicons of diffent sizes whichcan then be evaluated on a particular polarity clas-sification task and dataset.
Hence the differentconfigurations of the qwn-ppv lexicons, becausefor some tasks a G3 graph with more AG/TL seediterations will obtain better recall and viceversa.This is confirmed by the results: the tasks usingMPQA seem to clearly benefit from high recallwhereas the Bespalov?s corpus has overall, morebalanced scores.
This could also be due to the sizeof Bespalov?s corpus, almost 10 times larger thanMPQA 1.2.The experiments to generate Spanish lexiconsconfirm the trend showed by the English evalua-tions: Lexicons generated by qwn-ppv consistenlyoutperform other automatic approaches, althoughsome manual lexicon is better on a given task anddataset (usually a different one).
Nonetheless theSpanish evaluation shows that our method is alsorobust across languages as it gets quite close tothe manually corrected lexicon of Mihalcea(full)(P?erez-Rosas et al., 2012).The results also confirm that no single lexicon isthe most appropriate for any SA task or dataset anddomain.
In this sense, the adaptability of qwn-ppvis a desirable feature for lexicons to be employedin SA tasks: the unsupervised qwn-ppv methodonly relies on the availability of a LKB to buildhundreds of polarity lexicons which can then beevaluated on a given task and dataset to choose thebest fit.
If not annotated evaluation set is avail-able, G3-based propagations provide the best re-call whereas the G1-based lexicons are less noisy.Finally, we believe that the results reported herepoint out to the fact that intrinsic evaluations arenot meaningful to judge the adequacy a polaritylexicon for a specific SA task.5 Concluding RemarksThis paper presents an unsupervised dictionary-based method qwn-ppv to automatically generatepolarity lexicons.
Although simpler than similarautomatic approaches, it still obtains better resultson the four extrinsic evaluations presented.
Be-cause it only depends on the availability of a LKB,we believe that this method can be valuable to gen-erate on-demand polarity lexicons for a given lan-guage when not sufficient annotated data is avail-able.
We demonstrate the adaptability of our ap-proach by producing good performance polaritylexicons for different evaluation scenarios and formore than one language.Further work includes investigating differentgraph projections of WordNet relations to do thepropagation as well as exploiting synset weights.We also plan to investigate the use of annotatedcorpora to generate lexicons at word level to tryand close the gap with those that have been (atleast partially) manually annotated.The qwn-ppv lexicons and graphs used in thispaper are publicly available (under CC-BY li-cense): http://adimen.si.ehu.es/web/qwn-ppv.
Theqwn-ppv tool to automatically generate polaritylexicons given a WordNet in any language willsoon be available in the aforementioned URL.AcknowledgementsThis work has been supported by the OpeNER FP7project under Grant No.
296451, the FP7 News-Reader project, Grant No.
316404 and by theSpanish MICINN project SKATER under GrantNo.
TIN2012-38584-C06-01.95ReferencesR.
Agerri and A.
Garc??a-Serrano.
2010.
Q-WordNet:extracting polarity from WordNet senses.
In SeventhConference on International Language Resourcesand Evaluation, Malta.
Retrieved May, volume 25,page 2010.Eneko Agirre and Aitor Soroa.
2009.
Personalizingpagerank for word sense disambiguation.
In Pro-ceedings of the 12th Conference of the EuropeanChapter of the Association for Computational Lin-guistics (EACL-2009), Athens, Greece.Aitor Gonz?alez Agirre, Egoitz Laparra, German Rigau,and Basque Country Donostia.
2012.
Multilin-gual central repository version 3.0: upgrading a verylarge lexical knowledge base.
In GWC 2012 6th In-ternational Global Wordnet Conference, page 118.Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa.2014.
Random walks for knowledge-based wordsense disambiguation.
Computational Linguistics,(Early Access).S.
Baccianella, A. Esuli, and F. Sebastiani.
2010.
Sen-tiWordNet 3.0: An enhanced lexical resource forsentiment analysis and opinion mining.
In Seventhconference on International Language Resourcesand Evaluation (LREC-2010), Malta., volume 25.Dmitriy Bespalov, Bing Bai, Yanjun Qi, and Ali Shok-oufandeh.
2011.
Sentiment classification based onsupervised latent n-gram analysis.
In Proceedings ofthe 20th ACM international conference on Informa-tion and knowledge management, pages 375?382.Francis Bond and Ryan Foster.
2013.
Linking and ex-tending an open multilingual wordnet.
In 51st An-nual Meeting of the Association for ComputationalLinguistics: ACL-2013.Sergey Brin and Lawrence Page.
1998.
Theanatomy of a large-scale hypertextual web searchengine.
Computer networks and ISDN systems,30(1):107117.Y.
Choi and C. Cardie.
2009.
Adapting a polarity lexi-con using integer linear programming for domain-specific sentiment classification.
In Proceedingsof the 2009 Conference on Empirical Methods inNatural Language Processing: Volume 2-Volume 2,pages 590?598.X.
Ding, B. Liu, and P. S. Yu.
2008.
A holistic lexicon-based approach to opinion mining.
In Proceedingsof the international conference on Web search andweb data mining, pages 231?240.Andrea Esuli and Fabrizio Sebastiani.
2007.
Pager-anking wordnet synsets: An application to opinionmining.
In Proceedings of the 45th Annual Meet-ing of the Association of Computational Linguistics,pages 424?431, Prague, Czech Republic, June.
As-sociation for Computational Linguistics.C.
Fellbaum and G. Miller, editors.
1998.
Wordnet:An Electronic Lexical Database.
MIT Press, Cam-bridge (MA).V.
Hatzivassiloglou and K. R McKeown.
1997.
Pre-dicting the semantic orientation of adjectives.
InProceedings of the eighth conference on Europeanchapter of the Association for Computational Lin-guistics, pages 174?181.M.
Hu and B. Liu.
2004.
Mining and summariz-ing customer reviews.
In Proceedings of the tenthACM SIGKDD international conference on Knowl-edge discovery and data mining, pages 168?177.Soo-Min Kim and Eduard Hovy.
2004.
Determiningthe sentiment of opinions.
In Proceedings of Coling2004, pages 1367?1373, Geneva, Switzerland, Aug23?Aug 27.
COLING.Bing Liu.
2012.
Sentiment analysis and opinion min-ing.
Synthesis Lectures on Human Language Tech-nologies, 5(1):1?167.R.
Mihalcea, C. Banea, and J. Wiebe.
2007.
Learningmultilingual subjective language via cross-lingualprojections.
In Annual Meeting of the Associa-tion for Computational Linguistics, volume 45, page976.S.
Mohammad, C. Dunne, and B. Dorr.
2009.
Gen-erating high-coverage semantic orientation lexiconsfrom overtly marked words and a thesaurus.
InProceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing: Volume2-Volume 2, pages 599?608.Llu?
?s Padr?o and Evgeny Stanilovsky.
2012.
Freeling3.0: Towards wider multilinguality.
In Proceedingsof the Language Resources and Evaluation Confer-ence (LREC 2012), Istanbul, Turkey, May.
ELRA.B.
Pang and L. Lee.
2008.
Opinion mining and senti-ment analysis.
Foundations and Trends in Informa-tion Retrieval, 2(1-2):1?135.Ver?onica P?erez-Rosas, Carmen Banea, and Rada Mi-halcea.
2012.
Learning sentiment lexicons in span-ish.
In LREC, pages 3077?3081.D.
Rao and D. Ravichandran.
2009.
Semi-supervisedpolarity lexicon induction.
In Proceedings of the12th Conference of the European Chapter of the As-sociation for Computational Linguistics, pages 675?682.E.
Riloff and J. Wiebe.
2003.
Learning extraction pat-terns for subjective expressions.
In Proceedings ofthe International Conference on Empirical Methodsin Natural Language Processing (EMNLP?03).Xabier Saralegi and I?naki San Vicente.
2013.
Elhuyarat TASS2013.
In XXIX Congreso de la Sociedad Es-paola de Procesamiento de lenguaje natural, Work-shop on Sentiment Analysis at SEPLN (TASS2013),pages 143?150, Madrid.96P.
Stone, D. Dunphy, M. Smith, and D. Ogilvie.
1966.The General Inquirer: A Computer Approach toContent Analysis.
Cambridge (MA): MIT Press.Carlo Strapparava and Alessandro Valitutti.
2004.Wordnet-affect: an affective extension of wordnet.In Proceedings of the 4th International Conferenceon Languages Resources and Evaluation (LREC2004), pages 1083?1086, Lisbon, May.M.
Taboada, J. Brooke, M. Tofiloski, K. Voll, andM.
Stede.
2010.
Lexicon-based methods for sen-timent analysis.
Computational Linguistics, (EarlyAccess):141.Hiroya Takamura, Takashi Inui, and Manabu Okumura.2005.
Extracting semantic orientations of words us-ing spin model.
In Proceedings of the 43rd AnnualMeeting of the Association for Computational Lin-guistics (ACL?05), page 133140, Ann Arbor, Michi-gan, June.
Association for Computational Linguis-tics.P.
Turney and M. Littman.
2003.
Measuring praise andcriticism: Inference of semantic oreintation from as-sociation.
ACM Transaction on Information Sys-tems, 21(4):315?346.P.D.
Turney.
2002.
Thumbs up or thumbs down?
: se-mantic orientation applied to unsupervised classifi-cation of reviews.
In Proceedings of the 40th AnnualMeeting on Association for Computational Linguis-tics, page 417424.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-level sentiment analysis.
In Proceedings of the con-ference on Human Language Technology and Em-pirical Methods in Natural Language Processing,page 347354.97
