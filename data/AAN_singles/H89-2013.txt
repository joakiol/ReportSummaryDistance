Enhanced Good-Turing and Cat.Cal:Two New Methodsfor Estimating Probabilitiesof English Bigrams(abbreviated version)Kenneth W. ChurchWilliam A. GaleAT&T Bell LaboratoriesAbstractFor many pattern recognition applications including speech recognition and optical character recognition,prior models of language are used to disambiguate otherwise qually probable outputs.
It is commonpractice to use tables of probabilities of single words, pairs of words, and triples of words (n-grams) as aprior model.
Our research is directed to 'backing-off' methods, that is, methods that build an (n+l)-gram model from an n-gram model.In principle, n-gram probabilities can be estimated from a large sample of text, by counting the numberof occurrences of each n-gram of interest and dividing by the size of the training sample.
Unfortunately,this simple method, known as the "maximum likelihood estimator" (MLE), is unsuitable because n-grams which do not occur in the training text are assigned zero probability.
In addition, the MLE doesnot distinguish among bigrams with the same frequency.We study two alternative methods for estimating the frequency of a given bigram in a test corpus, givena training corpus.
The first method is an enhanced version of the method due to Good and Turing(Good, 1953).
Under the modest assumption that the distribution of each bigram is binomial, Goodprovided a theoretical result hat increases estimation accuracy.
The second method assumes even less,merely that training and test corpora are generated by the same process.
We refer to this purelyempirical method as the Categorize-Calibrate (orCat-Cal) method.We emphasize three points about hese methods.
First, by using a second predictor of the probability inaddition to the observed frequency, it is possible to estimate different probabilities for bigrams with thesame frequency.
We refer to this use of a second predictor as "enhancement."
With enhancement, wefind 1200 significantly different probabilities (with a range of five orders of magnitude) for the group ofbigrams not observed in the training text; the MLE method would not be able to distinguish any one ofthese bigrams from any other.
Second, both methods provide (estimated) variances for the errors inestimating the n-gram probabilities.
Third, the variances are used in a refined testing method thatenables us to study small differences between methods.
We find that Cat-Cal should be used whencounts are very small, and otherwise, GT is the method of choice.1.
MaterialsOur corpus was selected from articles distributed by the Associated Press (AP) during 1988.
Someportions of the year were lost.
The remainder was processed automatically b  Riley and Liberman toremove nearly identical articles.
There remained N = 4.4x107 words in the corpus, with a vocabularyof V = 400,653.
When we speak of "words," we use a common term to hide a number of processingdecisions.
Roughly, a word is a string of characters delimited by white space.
For instance, The andthe are different words, and so are need and needs.
In addition, punctuation such as period and commaare treated as "words".
Additional tokens are inserted automatically to delimit sentences, paragraphsand discourses.
In the future we hope to use a more balanced sample of general English.
However, forthe purpose of testing methods, a large sample is desirable; the the AP corpus is considerably larger thanalternatives such as the Brown Corpus.
The vocabulary size is also considerably larger than the 5000word vocabulary reported in (N~das, 1984).82We split the 1988 AP wire into two halves by assigning bigrams beginning with even numbered wordsto one sample, those beginning with odd numbered words to the other.
It is important that we made thissplit by taking every other bigram.
We have found that spliting the corpus into two half-year periods,for example, generates two quite different samples, which complicates matters considerably.
Since ouraim is to study methods, we have adopted this extreme measure in order to construct two very similarsamples.Our goal is to develop a methodology for extending an n-gram model to an (n+l)-gram model.
Weregard the model for unigrams as completely fixed before beginning to study bigrams.
This includesspecifying V, the vocabulary, and e(p(x)), an estimate of the probability of each word.
We alsosuppose that variances of the estimates are known.
Likewise, we would regard a bigram model as fixedbefore studying a trigram model.2.
Estimation MethodsLet r* be the adjusted frequency for a type observed r times.
Then p, the probability of the type, isestimated by r*/N.
In order to satisfy the constraint ~p= 1, the adjusted frequencies must satisfyr* = N. Two such methods will be considered at length: the Good-Turing Method (GT) and theCategorize-Calibrate M thod (CC).These methods are considerably better than the Maximum Likelihood Estimator (MLE): r* = r. Themain problem with MLE is that bigrams will be assigned zero probability if they didn't happen to occurin the training sample.
Moreover, there are large errors when the counts are small (e.g., less than 20).In addition, the MLE fails to distinguish among bigrams with the same count.
In our application thereare billions of bigrams with a count of zero, some of which are much more likely than others.
Theirprobability is neither zero nor identical.2.1 The Basic Good-Turing and Cat-Cal MethodsWe use the adjective basic to distinguish these methods from the enhanced methods that will bediscussed in the next section.
The main difference is that basic methods treat bigrams at atomic objectswith no internal structure; enhanced methods will "back-off" and use the unigram model whenappropriate.The Good-Turing method has been used very successfully by IBM speech recognition group (Niidas,1984; Nitdas, 1985; Katz, 1987).
The key insight suggested by Turing and developed by Good (1953),is the use of Nr, the number of bigrams which occur r times.
We may refer to N,.
as the frequency offrequency r. The GT estimate is r* = (r+I)N,.+i/N~ and it has a variance of r*( l+(r+l)*-r*).In practice it is necessary to use smoothed estimates of N~ instead of raw observations, especially whenN~ is small.
(Smoothing will not be discussed in this paper in order to save space.
)The following table illustrates a use of the basic GT estimate (BGT).
(This example was selected sothat the Nr's are large enough that smoothing is not too important.
)83r (=MLE) N,  BGT r* BGT o 20 1.605x1011 .28x10 -5 1.85x10 -51 2,053,146 0.446 0.8082 458,136 1.26 2.493 191,809 2.24 4.504 107,522 3.25 6.315 69,883 4.19 8.476 48,809 5.21 10.47 36,345 6.21 12.98 28,201 7.289 22,821The adjusted frequencies, r*, can be compared to the raw frequencies, r; they have the same order, anddo not differ greatly.
The GT method assigns some probability to bigrams which have not been seen,suggesting that we should act as if we had seen each of them 0.0000128 times instead of zero times.
Inorder to compensate for moving 160 billion bigrams from 0 to 0.0000128, some other bigrams must beadjusted ownwards.
In this case, all bigrams with r > 0 will be adjusted ownwards.Notice that the calculation of r* for r = 0 depends on No, the number of bigrams that we have notseen.
We can calculate No because V is provided by the the unigram model.
(This marks a greatdifference in our application of the Good-Turing formula from many applications in population biology,where inferences about he population size are the desideratum.)
The total universe of bigrams that wewish to know about has size V2=l.6xl011.
No is the difference between V2 and the number of distinctbigrams seen, ~Nr .
Note that No=V 2 since V 2 > N O > V2-N and N << V 2.
In other words,r>0most bigrams have not been seen.
In our experience, the problem only gets worse as we look at largercorpora because V 2 tends to grow faster than N.GT improves on MLE by making use of more information, namely {Nr}.
CC gathers even moreinformation.
The training text is divided into two halves.
Categorize ach bigram, b, by its observedfrequency r l (b) in the first part of the text.
Denote the number of distinct bigrams in the category byNr = ~ 1.
Calibrate the category by counting all occurrences of all the bigrams in the categoryblrl(b)=rin the second part of the text, C, ~- ~ r2(b), where the r2(b) is the observed frequency of thebJrt(b)=rbigram, b, in the second half.
The adjusted frequency is then: r* = Cr/N,.
The only assumptionbehind this method is that both samples are generated by the same process.
This assumption is weakerthan the binomial assumption of GT.
We refer to this method as the basic Cat-Cal method (BCC); thenext section will consider an enhanced version that makes use of the bigrams' internal structure.Basic Cat-Cai Methodr N,.
Cr BCC r* repeat BGT r*0 1.605x10 ll 2,046,125 1.27x10 -5 1.27x10 -5 1.28x10 -a1 2,053,146 919,645 0.448 0.448 0.4462 458,136 577,518 1.26 1.26 1.263 191 ,809  431,839 2.25 2.25 2.244 107 ,522  347,424 3.23 3.22 3.255 69,883 293,953 4.22 4.23 4.196 48,809 257,141 5.20 5.22 5.217 36,345 223,574 6.20 6.19 6.218 28,201 205,171 7.22 7.25 7.28The adjusted frequencies for the BCC can be compared to the adjusted frequencies for the BGT as wellas to the MLE.
The differences between the BCC and the BGT are limited to the third significant84figure, while the differences of either from the MLE are in the first significant figure.The fifth column of the table, labeled repeat, contains the results of repeating the basic Cat-Cal methodafter exchanging the texts used for categorization and calibration.
The differences are again limited tothe third significant figure, showing that BCC agrees well with our standard.
We originally establishedthe Cat-Cal method as a standard against which to compare other methods.
However, we came torealize that it could itself be used as a practical method.
Thus Cat-Cal plays two roles: standard andpotential method.The CC method can be extended to compute variances as illustrated below.
Note that the variancescomputed by the CC method agree closely with those computed by GT.2.2Variancesr Nr Cr 2 BCCff 2 G Ta20 1.605X1011 2,980,905 1.85X10 -5 1.85X10 ->1 2,053,146 2,069,343 0.808 0.8082 458,136 1,865,654 2.48 2.493 191 ,809  1,831,325 4.48 4.504 107 ,522  1,805,150 6.36 6.315 69,883 1,827,811 8.41 8.476 48,809 1,858,543 10.5 10.47 36,345 1,832,738 12.4 12.98 28,201 1,898,443 14.5The Enhanced MethodsA key suggestion of this work is the introduction of a second predictor of frequency of observation inaddition to an observed frequency; accounting for the second predictor constitutes what we call anenhanced method.
We study an enhanced Good-Turing method and an enhanced Cat-Cal method.
Bothenhanced methods allow us to differentiate among the many bigrams which have not been seen.
Wewill show that about 1200 significantly different probabilities can be estimated for bigrams not seen inthe training text.A possible second predictor for bigrams is the following: j i i  = N e(p(x)) e(p(y)), where e(p(x)) ande(p(y)) are the unigram model's estimates of the probability of the first and second word in the bigram.j i i  is an acronym for "joint if independent".
We refer to values of j i i  as "Unigram Estimates (UE)"when we compare them to other estimates uch as MLE or GT.
In many of the following plots, we/ /group bigrams into approximately 35 bins using the binning rule: j = \[31oglojii I.I_ .JOther second predictors are possible.
We do not know what makes one variable better than another forgrouping.
A necessary property of the grouping variable is that it be possible to count the number oftypes included in each group, because we need to know No.
We hypothesize that if one variablepredicts r better than another, then it will make a better grouping variable.
It is useful for smoothingthat j i i  is a continuous variable.3.
Qualitative EvaluationWe find that the both GT and CC estimates agree very well with the standard estimates over the entirerange of data that we can test.
The smallest frequency observations are the most critical.
The followingfigure shows the results for r = 1.
Five predicted frequencies are shown in this and following figures:(1) the standard, S, shown by points, (2) the maximum likelihood estimate, MLE, shown by long dashes,(3) the unigram estimate, UE, shown by long dashes, (4) the enhanced Cat-Cal estimate, CC, shown bya solid line, and (5) the enhanced Good-Turing estimate, GT, shown by short dashes.
These estimatesare plotted against he logarithm of the unigram estimator, jii.
Note that CC and GT agree closely withthe standard.
They are quite distinct from either the MLE or UE but lie approximately between thesetwo primary estimators.85Enhanced Good-Turing and Cat-Cal Agree with the Standard for r=lUE/I I I !-6 -4 -2 0IoglO jiiStandard  *I I2 4Enhanced Good-Turing and Cat-Cal Agree with the Standard for r=0iAv0c0.9/r/ Standard */U E / // /  / / /// /// /I I I I I I-6 -4 -2 0 2 4IoglO jiiFor frequency zero, the range of CC and GT is about five orders of magnitude, four orders of magnitudelarger than for any other frequency.
Over this range, both GT and CC agree well with the standardestimates.
At the resolution shown, there is no visible difference between the three estimates for mostof the range.86Enhanced Good-Turing and Cat-Cal Agree with the Standard for Small r- r=2 ,~ ?
.
~ -~ ; .
.
.
.
.
(1) II"O  IIr=11 J-- !
-4  -2  0 2r a m - -N"R.c~,r=5"I I I I I g4 "4 '2 0 | 4N- I8q" l  I~- .
t  t I!
!/i i i i |-6 -4 -2 0 2=,8 ,=r = 8~~.
'IIIm i ~ i i i?
-6 -4 -2 0 2 4= 17 i "IIIIIIII /i = i i i?
4 4 -2 0 2I I4I og lO  jiiNote that r* depends more on jii when r is small; the slope of r* is very steep for r = 0, and prettyflat for r = 17.
This means that UE is more important when r is small.
We will return to this whenwe consider the number of significantly different probabilities.4.
Quantitative EvaluationIt is natural to evaluate methods with a t-score tjr = ( r ' j ,  - r~r)/C~y~, where r ' j r  is an estimateproduced by one of the proposed methods for bin j and frequency r, r~ is the standard for the same jrcell, and c~j, is the standard eviation for the same jr cell.
We use the GT method to estimate thestandard eviation because it appears to match the CC variance while being less noisy and defined inmore cells.We have some expectations about these t-scores.
A perfect predictor would give an RMS t-score ofabout one, because the variance of one standard observation is used as the denominator.
We find thatGT is nearly perfect with RMS t-scores very close to one except for small r. In contrast, CC is notperfect anywhere because both the categorization a d the calibration samples have the assumed variance.However, when r is very small, it appears that the binomial assumption is inappropriate, andconsequently, the the more empirical, though imperfect, CC method is preferable.The two plots below show the RMS t-value averaged within each jii bin.
The solid lines compare CCwith the standard; the short dashed lines compare GT with the standard.
The best performancetheoretically possible is an RMS error of one, shown by a long dashed line in each panel.
GTapproaches this ideal quickly, though CC is preferable at very small frequencies.
The CC values in the87upper panel are adjusted for sample size to be comparable toGT values.Comparison of the Enhanced Good-Turing and Cat-Cal MethodsCat-Cal is better for small r and worse for large r?O1oO _= m.t/J qif)o.o~GTGT0 10 20 30 40frequency (r)0 10 20 30 40frequency (r)The following plot shows that MLE does not reach ideal performance within the range shown.Moreover, for frequencies less than about 40, MI.E is substantially worse than GT.
Over the smallestten frequencies the MI.E has RMS t-values ranging from five to thirty times those of enhanced G(x3d-Turing estimates.Comparison of the Enhanced Good-Turing and MLE MethodsGood-Turing is better, especially when r is smallItI\6tTfrequency (r)5.
How Many Significantly Different Probabilities?In this section we show that estimates in adjacent j i i bins differ quite significantly.
This implies thatinterpolation is justified, and leads to an estimate of the equivalent number of significantly differentestimates.For each jii, let fj, denote a frequency estimated for bigrams in the jan bin and frequency r. Let ~j, be88variance of fir.
The following figure investigates the t-scoret=  ()S,--/O-,r) /for the particularly important case of r = 0.
The solid line shows the t-statistics for CC; the shortdashed line shows the GT differences.
Long dashed lines are drawn at conventional significance levelsof +_ 1.65.
These differences are highly significant, indicating that interpolation between the observedvalues is justified.
We estimate the equivalent number of significantly different values by taking thesum of all the t-statistics and dividing by 1.65.
For r = 0, the equivalent number of significantlydifferent values is 1245.About 1200 Significantly Different Probabilities for r = 0?6 -4 -2 0 2 4Io910 jllThe following figure shows the equivalent number of significant differences as a function of frequency.The dashed lines are drawn at log101 and 1og102.
While the number of significantly different valuesfalls rapidly with increasing r, it remains above two through r = 40, and continues to be greater thanone even through frequency 100.
This range encompasses the majority of bigram tokens and indicatesthe value of a second predictor for practical applications, indicating that enhancement is of considerablevalue for practical applications.Equivalent Number of Significantly Different Probabilitieswe can distinguish bigrams with the same frequency very well for small frequencies8ii !
it 1 tn  ?
tn  ? "
* .
.
.~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
~ .~ .
.
.
.
.
.
.
"_'_'.'::_"'_-.
:':7_-:'_'::::::_0 20 40 60 80 10Cfrequency Or)6.
ConclusionsThis paper has proposed two specific methods for backing-off bigrarn probability estimates to unigramprobabilities: the enhanced Good-Turing method, and the Cat-Cal method.
Three important points inthis paper have extended the strength of these methods over previous methods:89?
the use of a second predictor (e.g., jii) to exploit the structure of n-grams, the distinguishing featurebetween the enhanced Good-Turing method and the basic Good-Turing method.?
the estimation of variances for the bigram probabilities, which allows building significance tests forvarious practical applications, and in particular allows?
the use of refined testing methods that can show important qualitative differences even thoughquantitative differences may be small.The use of a second predictor is the basis on which we distinguish the enhanced Good-Turing method(GT) proposed here from the basic Good-Turing method and the enhanced Cat-Cal (CC) from a basicCat-Cal.
If we had not introduced a second predictor, all bigrams that were observed once would beconsidered equally likely, and all bigrams that were observed twice would also be considered equallylikely, and so on.
This is extremely undesirable.
Note that there are a large number of bigrams thathave been seen just once (2,053,146 in a training corpus of 22 million words); we do not want to modelall of them as equally probable.
Much worse, there are a very large number of bigrams that have notbeen seen (160 billion bigrams in the same training corpus of 22 million words); we really do not wantto model all of them as equally probable.
By introducing the second predictor jii as we did, we wereable to make much finer distinctions within groups of bigrams with the same number of observations r.In particular, for bigrams not seen in the training corpus, we have about 1200 significantly differentestimates.It would be interesting to consider other variables besides jii.
One might consider, for example, thenumber of letters in the bigram.
Katz (1987) proposes an alternative variable: the first word of the n-gram.
Any variable that is not completely correlated with r would be of some use.
jii has someadvantages; it makes it possible to summarize the data so concisely that the relevant structure can beobserved in a simple plot.
Moreover, jii has a natural order and is continuous, o the number of binscan be adjusted for accuracy.
In contrast, selecting the first word of the n-gram prescribes the numberof bins.The second point, the calculation of variances, is often not discussed in the literature on using theGood-Turing model for language modeling.
Variances are necessary to make statements about thestatistical significance of differences between observed and predicted frequencies.
In other work(Church, Gale, Hanks, and Hindle, 1989), we have used variances to distinguish unusual n-grams fromchance.The third point we want to emphasize, the use of relined tests for differences in methods, is discussed insection 4.
Four methods, MLE, UE, CC, and GT, were compared to the standard, t-scores werecalculated for the differences between the standard and a proposed method and aggregate results acrossjii.
We find that the GT method rapidly approaches ideal performance, though it is outperformed byCCwhen r is very small, presumably because the binomial assumption is apparently not quite satisfied forsmall frequencies.There are many ways that the language model presented could be improved.
We have said very littleabout he unigram model; in fact, the unigram model was estimated with the MLE method.
One couldapply the methodology developed here to improve greatly on this.
One could also obtain muchimproved estimates by starting with a better sample; the 1988 AP corpus is not a balanced sample ofgeneral English.
This paper is primarily concerned with developing methods and evaluation procedures;in future work, we hope to use these results to construct better language models.ReferencesChurch, K, Gale, W., Hanks, P., Hindle, D., (1989) "Parsing, Word Associations and TypicalPredicate-Argument Relations," International Workshop on Parsing Technologies, CMU, August.Good, I.J., (1953), "The population frequencies of species and the estimation of population parameters,"Biometrika, v. 40, pp.
237-264.90Kahan, S., Pavlidis, T., and Baird, H., (1987), "On the Recognition of Printed Characters of any Fontor Size," IEEE Transactions PAMI, pp.
274-287, March, 1987.Katz, S. M., (1987), "Estimation of probabilities from sparse data for the language model component ofa speech recognizer," IEEE Transactions on Acoustics, Speech, and Signal Processing, v. ASSP-35, pp.400-401.Nhdas, A., (1984), "Estimation of probabilities in the language model of the IBM speech recognitionsystem," IEEE Transactions on Acoustics, Speech, and Signal Processing, v. ASSP-32 pp.
859-861.Nhdas, A., (1985), "On Turing's formula for word probabilities," IEEE Transactions on Acoustics,Speech, and Signal Processing, v. ASSP-32 pp.
859-861.91
