CATCHING THE CHESHIRE CATChrister JohanssonDept.
of Linguistics, Lund University, Swedenemail: Christer.Johansson @ling.lu.seABSTRACTFinding useful phrases is important in applica-tions like information retriewd, and text-to-speech systems.
One of the currently mostused statistics is the mutual information ratio.This paper compares the mutual informationratio and a measure that takes temporal order-ing into account.
Using this lnodified measure,some local syntactic constraints as well asphrases am captured.INTRODUCTIONIn Alice's Adventures in Wonderland by LewisCarrel many of Alice's friends have names thatconsists of two words, for example: the MarchHare, the Mock Turtle, and the Cheshire Cat.
'\['he individual words in these combinations, ifwe ignore capitalisation, might be quite com-mon.Individual words usually mean differentthings when they am free.
l:or example, in "TheMarch against Apartheid", and "The MarchI tare", "march" means totally different hings.There is obviously a strong link between "the"and "march", but the link between "march" and"hare" is definitely stronger, at least in Lt;wisCarrol's text.The goal of this paper is to propose a statisticthat measures the strength ol7 such glue betweenwords in a sampled text.
Finding tile names {)17Alice's friends can be done by searching for twoadjacent words with initial capit~d letters.
()no use of statistical associations could he tofind translatable concepts and phrases, thatmight be expressed with a different number ofwords in another language.
Another possiblyinteresting use of statistical associations i topredict whether words constitute new or giveninformation in speech.
It has been proposed(e.g.
Horne& Johansson, 1993) that the stressof words in speech is highly dependent on theinformational content of the word.
Also, statisti-cal associations are not incompatible with thefirst stages of the "hypothesis space" proposedby Processability Theory (personal communica-tion with Manfred Pienemann of SydneyUniversity, see also Meisel & al., 1981).There are different methods of calculatingstatistical associations.
Yang & Chute (1992)showed that a linear least square mapping ofnatural anguage to canonical terms is both fea-sible, and a way of detecting synonyms.
Theirmethod oes not seem to detect dependencies inthe order of words however.
To do this we needa measure that is sensitive to the order betweenwords.
In this paper we will use a variant ofmutual infi)rmation that derives from Shannon'stheory of information.
(as discussed in e.g.,Salton & McGill, 1983)Definit ions and assumptionsThe definition of a word in a meaninglul way is\[:ar from easy, but a working definition, fortechnical purposes, is to assume that a wordequals a string of letters.
These 'words' are sep-arated by non-letters.
The case of letters is ig-nored, i.e.
converted into lower case.
For ex-ample: "there's" are two 'words': "there" and~IS".A collocation consists of a word and theword that immediate@ follows.
Index I will re-fer to the first word and 2 to the second word.Index 12 will refer to word 1 followed byword2, and similarly for 2 I.Another assumption is that natural anguageis morn predictive in the (left-to-right) emporalorder, than in tile reversed order.
This is moti-wtted by the simple obserwttion that speechcomes into the system through the ears serially.For example: consider the French phrase "unben viu hlanc" (Lit.
"a good wine white").
"Ben" can (relatively often) be followed by"vin", but usually not "vin" by "ben".
Thesame kind of link exists between "vin" and"bhmc", but not between "blanc" and "vin".This linking affects the intonation of Frenchphrases, and also that intonation supports thesekinds of links.
Note, that this is not an explana-.tion of either intonation or syntax: we mosllikely have to consider massive interaction be-.tween different modalities of language.1021Deriving the measureThe mutual information ratio, g, provides arough estimation on the glue between words.
Itmeasures, roughly, how much more common acollocation is in a text than can be accounted forby chance.
This measure does not assume anyordering between the words making up a collo-cation, in the sense that the g-measure of\[wl.
.
.w2\] and \[w2.. .wl\]  are calculated as ifthey were unrelated collocations.The mutual information ratio (in Steier &Belew, 1991) is expressed:,Formula 1: The mutual information ratiowhere 'p' defines the probability function,p(\[wl .
.
.w2\])  is read as "the probability offinding word w2 after word wl".Adjusting for order between wordsWe have experimented with the difference inmutual information, ag, between the two differ-ent orderings of two words making up a collo-cation.
The results indicate that zxg capturessome of the local constraints in a sampled text.6g can be expressed:A~t=I (P(\[Wl...W2\])I , (P(\[W2...W~I=>, / ,= t o g 2 / - -  - - /Formula 2: The diffcmnce in mutualinlblrnationwhere F(\[wx...Wy\]) denotes the frequency ofwhich Wx and Wy co-occur in the sample.F(wx) is the frequency of word Wx.
Note thatthe size of the sample cancels in this equation.Note also that this measure is not sensitive to theindividual probabilities of the words.A problem is when them is no F(\[w2...wl\]).In these cases, we have chosen to arbitrarily setF(\[w2...Wl\]) to0.1, with the justification that ifthe sample was ten times larger we might havefound at least one such pair.MATERIALThe material is Alice's Adventures inWonderhmd by Lewis Carrol, available in elec-tronic format via email from the GutenbergProject.
The text contains 27332 words ofwhich 2576 are unique, making up a total of14509 unique word pairs.
Alice in Wonderlandwas chosen because it is a well-known text, itcontains ome phrases that we know are in there(e.g.
March Hare), and it contains a sufficientnumber of words, and variations of words, tobe interesting for the experiment.
Studies couldbe done for other collections of texts, e.g.medical abstracts.
As morn documents ate avail-able, comparisons between documents can bedone (Steier & Belew, 1991).
This experimentonly contains within comparisons of phrases forone specific text.METHODFor each of the unique words in the text the fie-quencies of all immediately following wordswere collected.
In this text, no filtering of thetext was performed.
Some initial experimentswere performed, with a stoplist, to removefunction words and some other common words(see Fox, 1992, for details).
Some simplestemming was also tried, e.g.
removing 's' and'ed' from the end of words.
Stemming may leadto difficulties in distinguishing compounds fromnoun-verb complexes.
It is not clear if the prosof using stemming outweighs the cons, conse-quently we decided to work with the raw text.Stoplists and stemming might be more importantwhen the ordinary g-measure is used.RESULTSThe collocations were ordered ifferently by thetwo measures.
The g was sensitive to individualfrequencies, and favoured very low fi'equencycollocations.
The Ag was sensitive to the order-ing of the words, and favoured high frequencycollocations that only occmred in one order.
Thequality of the diffemnt measures can be seen bycomparing the top and last ten collocationsbetween the measures.
Table 1.1 and 2.1 referto Ag, and Table 1.2 and 2.2 refer to g. The Ncolumn tells the rank-number of the collocation.Note that the frequencies of the individualwords, F1 and F2, are not used to compute Ag,they are only provided for compa~%on with theg-measure.Note that the numerical values of the g-mea-sure and the Ag-measure cannot be directlycompared since they measure slightly differentphenomena.1022Tab le  1.1: The topN- I  wo'  _._.
!rsaid-> (he -1 \]~(}~2 ioT> (h~3 ~ in->a .
{).92 }4 an{f> the 9_.7(} !_5  in-> tile _9.641_ 6 to-> Ihe 9.4317 don->l 9.25 l8 as-> she 9.25_\]_ { )  a-> little 9.20110  she-> had 9.2()\[ten collocations by Ag1,'1 y~_ l ,  lZ l l , ) lA_ 462 .f~2~ _2!01 {J __\[3696321 97\]_0 \]_ 3691 .6421 801_0 ~6322__ 1281, "A', t2 A_55~_178L 2~1o Ials gives a measure of local  links betweenwords.
As can be seen from Tab le  1.1, Abtcaptures local constraints: that prepositions amusually fol lowed by a noun phrase, that 'and'usual ly  is used as a noun co-ord inator(indicated by the high value for 'and->the').Mitjushin (1992) has proposed similar links on ahigher syntactic level, using a rule-based ap-proach.
We have del iberately tried to awfidtalking about word-classes ince it is misleadingat this level of analysis.
However, we get manyexamples of good representatives for word-classes that form collocations.Table  1.2: Thc top tell collocations by ~tN word pair b t 1," !
F2  _ le 12___l w{?~den->spadcs .
.
.
.
14.7 / ~ 1 _ 1_2 vari{~u~r_>Drctextss .__14.7 & I ._ luncommonly->lat .___4 _t3~->t{}il~e?
.5 littere{l->audibl~___.6 link li~>sl~_ecd~7 tide-> rises_ 8 lalt->cuslard_9 s l cam-~c __?10 ~d~->{h 'essed14 .7  1__ I _ I14.7 I .
I 114.7 1 1 1144.Z C 1 _ r14.7 1 l 1_14.j_ & t L_t4.j Z J _ !The f lavour of the collocations that bt ratehighly is different.
As can be seen from Tab le1.2, low individual frequencies result in a highg-value, even if the collocation is unique.
Thisgives an illusion of a semantic relation, which isdue to the fact that low frequency words arcusually high in content.
The g-measure is usefulwhen we are interested in the correlation be-tween words within and between documents(Steier & Belew, 1991).
This notion could beexpanded up{}n to incorporate correlation be-tween any two words in general, and it seemsto work well for the g-measure (Wettler andRapp, 1989).The last ten col locations.
Ag is sensitive todeviation from an expected ordering in tilesample.
The negative valued link between thesewords makes a phrase boundary between thetwo words probable.'
Fab le  2 .1:  The last ten collocations by A~14500 catcq~illar-> -4.70 28 \[ 1642 I / 26 I__  Ihe_14501 mouse->the14502 s->it14503 s->that14504 dormouse->the14505 q ucen->lhc14L506 she->alld14507 was->shc14508 m->i14509!
was->it-4.~1~ 201/~.~ 56 \[-5.09 20t 3t51 x4 L-5.13 40 16421 1 \] 35 I__-5.177 75 16421 2 72 I_578 552-5.86 63 545 I 1 I 5N \[The g-measure, in contrast, gives some col-locations that are intuitively unlikely phrasesconsisting of high frequency words.
In the caseof "the-> the" there exists 1641 pairs that speakagainst hat pairing, but it is hard to explain thisin terms of local syntactic constraints.
Thenegative scores seems to capture possible typo-graphic errors.Tab le  2.2:  The last ten collocations by btN word pair g___ 1," 1 __.1~2 1?1214500 she-> of -3.37 552 513 114501 to-> and -3.54 729 872 214502 a->i -3.66 632 545 114503 and->of -4.03 872 513 114504 i->and -4.12 545 872 114505 she->mld -4.14 552 872 1145(16 to->to -4.28 729 729 114507 mid-> ~ld -4.80 872 872 114508 i->lhe -5.03 545 r642 114509 Ihc->lhe -6.62 '642 !642 1Par t i c le  verbsParticle verbs are hard to rank high for the~t-measure, because the individual fl'cquenciesof the particles are usually devastatingly high,~md the fl'equency of the main verb in pm'ticleverb constructions are usually higher than av-crage.
The Abt are, in gencral, good at findingsuch combinations if the order between thetwo words is fixed ('Fable 3.1).1023Table 3.1: Some verb + particle (or negation)word pair Np.
NAg rt Art1did->not 3961 33 6.39 8.13~/scemcd->to 6818 54 4.80 7.64must->be 4038 58 6.32 7.57looked->at 5211 72 5.61 7.41Finding thematic phrasesBut what about finding Alice's friends' ?
Doesthe art find the phrases that the text is about (~thematic phrases)?
To test this we chose some ofthe names of Alice's friends (Table 3.2).We found that the rank number that Ag deliv-ers is higher than the rank number for the rt-measure for all the checked friends.
This is dueto the frequency effects discussed above.Table 3.2: Alice's Friendsword pair ~_  NAg gmock->turtle 1517 12 8.86~march->hare 1003 28 9.65white->rabbit 1637 47 8.62chesl~ke ->cat 1360 473 9.04~ueen 8519 831 4,00the->donnouse 8841 832 3.868463 2954 4.03What is lostThere am obviously good phrases that grates higher than zXg.
These usually consists oftwo words that are uncommon in the sample.Some idioms are of this kind.
The at* needs tofind more examples of collocations with theexact ordering between the consti-tuents orate the collocation high ( Table 3.3).Table 3.3: Some collocationswith Ng < Nagword pair Nbt NAbt rt Artycr->honour 172 705 12.7 5.32young->lady 230 1073 12.4 4.91guinea->pigs 398 645 11.6 5.32rose->tree 459 1114 11.3 4.91fast->asleep 460 1115 11.3 4.91note->book 462 2501 11 3 4.32 /raving->mad 597 2500 ~ 4.32cheshire->cats 1925 4468 \[ 8.23 \[ 3.32Adding memoryWe have also done some experiments withadding memory to the method.
A 'memory'could, for example, extend 10 words after eachword.
All words following within a distanceequal to the size of the memory were collected.Adding a memory allowed the model to detectshared information of words that was furtherapart (for example "pack of card~" or "boots andshoes".The memory introduced false collocations:e.g., "grammar-> mouse".
The context was:"Alice thought hi,~" lnust be the right way ofspeaking to a mouse: she had never done such athing before, but she remembered having seen inher brother~ Latin Grammar, ',4 mouse--eramouse--to a mouse--a mouse--O mouse\]'"This context gave up to 5 collocations for"grammar" followed by "mouse", and thereforerated "grammar-> mouse" very high.Otherwise, words that happened to be near aword without being statistically related to theword were usually rated low.
The g gave clearlybetter esults on finding related phrases than thezXg, with the model with the 'memory'.With the memory, the Abt ordered the pairscloser to the original raw-frequency ordering themore 'memory' was present.
The experimentwith the memory was useful because it showedthat this was not worth doing for aj.t, but likelyworth doing for g.CONCLUSIONSPossible usefulnessThe higher sensitivity to local constraints inthe temporal ordering could be used in a parserfor finding local phrases.
This might also haveits implications for language acquisition.
It couldbe tested if language learners make mistakes thatcould be explained by the statistical connectivitybetween words.
Further research is needed onhow the measure of connectivity behaves onphrase boundaries.Areas where phrase finding could be usefulinclude: text-to-speech (phrase intonation), ma-chine translation (translation of compounds),and in information retrieval: phrase transfo~xna-tion of high frequency terms into medium fie-quency telxns with a better discrimination value(Salton & McGill, 1983).CharacteristicsThe rt-measure is good at estimating lobalcorrelations in a document or collection of doc-uments (Wettler & Rapp, 1989).
This could beused for capturing contextual and pragmaticconstraints in a text.
Other methods exist that aregood, perhaps even better, at capturing forexample synonymy.1024Linear least square mapping (Yang & Chute1992) is one method that has shown to bcpromis ing on captur ing very good mappingsbetween, in their case, symptoms and diagnosis.The same technique could be used for mapping atext to its abstract.
The draw-back of thesemethods is their inherent parallel structure whichmakes it hard to account for the ordering thatnatm'al language requires.The Ag-measure, on the other hand, is a localmeasure, that seems to capture dependencies inthe temporal ordering of the language.
It is hardto draw any def in i te conc lus ions from theanalysis of only one text, but we have seen howthe two proposed measures react 1o the fre-quencies of indiv idual  words, as well  as thefrequencies of word pairs.
Taking into accountthe abi l i ty o1' Abt to find dependencies in thetemporal ordering, we think it is a more relevautmeasure than I-t for several  aspects of naturallanguage processing, but not all.AcknowledgementsThanks to the people at my department: es-pecial ly Barbara Gawronska.Shannon, C. E., 1951, Prediction mid l';ntropy ofPrinted English, Bell Systems TechnicalJournal, Vol.
30, No.
1, Janumy 1951, pp.
50~65.
(quoted in Salton & MeGilI)Sitter, A. M. & Belcw, R. K., 1991, l:';xportingphrases: A statistical analysis of topical an-guage.
In Casey, R. & Crofl, B., (l';ds.
), 2ndSymposium on Document Analysis andlnJormation RetriewtLWettler, M. & Rapp, R., 1989, A connectionistSystem to Simulate I,exical Decisions in\[nlbrmation Retrieval, In: Pl'cilcr & al.
(F, ds,),Connectionism in Perspective, North-I lollandYang, Y.
& Chute (2.
G., 1992, A Linem' I,eastSqum'cs l;it Method for Inlormation Retrievalflom Natural Language Texts, Proceedings ofthe ./iJteenth International Con/erence onConqmtational Linguistics, pp.
447-453Yarowsky, I)., 1992, Word-Sense l)ismnbiguationUsing Statistical Models of Roger's CategoriesTrained on I.arge Coq)ora, Proceedings of theJi/teenth International CoR/?erence onComputational Linguistics, pp.
454-460Project Gutenberg, Illinois Benedictine College,send the message: "send gutenberg catalog" to'almanac @ oes.
otwl.
edu ' lor more inlbrmation.Canol, I,.
Alice's Adventures in Wonderland, TheMillennium l:ulerum l'~(lition 2.9REFERENCESBelow, R. K., 1989, Adaptive inlormation re-trieval: Using a connectionist reprcsentalion toreUicve and learn about doctlments, hi: l'roc.SIGIR 1989, pp.
I 1-20, C~unbridge, MA.Fox, C., 1992, l.exical Analysis and Stoplists, Ill:l:rakes, W. B., & Baeza-Yates, R., hfformationRetrieval, Prentice Ilall, NJ.llorne, M. & Johansson, C., 1991, l,cxicalStructure and accenting inEnglish and Swedishrcslrictcd texts.
Working l'apers (Dept.
ofLing., U. of Lurid, Sweden)38: 97-114.Ilornc, M. & Johansson, C., 1993,Computational tracking of 'new' vs. 'given' in-formation: implications lor synthesis of into-nation, In: (}ranstr(hn, B.
& Nard, 1..
(l';ds.
)Nordic Prosody VI - papers l?om a sympo-sium, Ahnquist & Wikscll International,S|ockhohn, Sweden.Meiscl, J., Clahsen, 11., alld Pienemann, M.,1981, On determining developmental stages insecond language acquisition.
Studies in SecondLanguage Acquisilion 3, 2, pp.
109-135.Mitjushin, L. 1992, lligh Probabilily SyntacticLinks, Proceedings o~ tile fifteenthInternational Conference on ComputationalLinguistics, pp.
930-934.Salt(m, (\]., & McGill M. J., 1983, IntroductionIo Modern h!formation Retriewtl, McGraw-I illComputer Science Series1025Information Retrieval& Extraction
