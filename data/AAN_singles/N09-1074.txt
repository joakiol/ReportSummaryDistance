Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 656?664,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsImproved Syntactic Models for Parsing Speech with Repairs?Tim MillerDepartment of Computer Science and EngineeringUniversity of Minnesota, Twin Citiestmill@cs.umn.eduAbstractThis paper introduces three new syntacticmodels for representing speech with repairs.These models are developed to test the intu-ition that the erroneous parts of speech repairs(reparanda) are not generated or recognized assuch while occurring, but only after they havebeen corrected.
Thus, they are designed tominimize the differences in grammar rule ap-plications between fluent and disfluent speechcontaining similar structure.
The three modelsconsidered in this paper are also designed toisolate the mechanism of impact, by systemat-ically exploring different variables.1 IntroductionRecent work in recognition of speech with repairshas shown that syntactic cues to speech repair canimprove both overall parsing accuracy and detectionof repaired sections (Hale et al, 2006; Miller andSchuler, 2008; Johnson and Charniak, 2004).
Thesetechniques work by explictly modeling the structureof speech repair, specifically the tendency of repairsto follow unfinished constituents of the same cate-gory.
This is the essence of what was termed thewell-formedness rule by Willem Levelt (1983) in hispsycholinguistic studies of repair.The work presented here uses the same motiva-tions as those cited above (to be described in moredetail below), in that it attempts to model the syn-tactic structure relating unfinished erroneous con-?This research was supported by NSF CAREER award0447685.
The views expressed are not necessarily endorsed bythe sponsors.stituents to the repair of those constituents.
How-ever, this work attempts to improve on those mod-els by focusing on the generative process used by aspeaker in creating the repair.
This is done first byeschewing any labels representing the presence ofan erroneous constituent while processing the text.This modeling representation reflects the intuitionthat speakers do not intend to generate erroneousspeech ?
they intend their speech to be fluent, ora correction to an error, and can stop very quicklywhen an error is noticed.
This corresponds to Lev-elt?s Main Interruption Rule, which states that aspeaker will ?Stop the flow of speech immediatelyupon detecting the occasion of repair.?
Rather thanattempting to recognize a special syntactic categorycalled EDITED during the processing phase, thiswork introduces the REPAIRED category to signalthe ending of a repaired section only.The second part of the modeling framework isthe use of a right-corner transform on training data,which converts phrase-structure trees into heavilyleft-branching structures.
This transformation hasbeen shown to represent the structure of unfinishedconstituents like those seen in speech repair in a nat-ural way, leading to improved detection of speechrepair (Miller and Schuler, 2008).Combining these two modeling techniques in abottom-up parsing framework results in a parsingarchitecture that is a reasonable approximation tothe sequential processing that must be done by thehuman speech processor when recognizing spokenlanguage with repairs.
This parser also recognizessentences containing speech repair with better accu-racy than the previous models on which it is based.656Therefore, these syntactic models hold promise forintegration into systems for processing of streamingspeech.1.1 Speech Repair TerminologyA speech repair occurs when a speaker decides tointerrupt the flow of speech and restart part or allof an utterance.
Typically speech repair structure(Shriberg, 1994) is considered to contain a reparan-dum, or the part of the utterance to be replaced, andan alteration, which is meant to replace the reparan-dum section.
There are also frequently editing terms(for example, ?uh?
and ?um?)
between the reparan-dum and alteration, which may be used to signal therepair, or to indicate that the speaker is thinking, orjust to maintain control of the dialogue.1.2 Related WorkThis work is related to that of Hale et al(2006) inthat it attempts to model the syntactic structure ofspeech repair.
In that paper speech repair detec-tion accuracy was increased by explicitly account-ing for the relation between reparanda category andalteration category.
This was done by so-called?daughter annotation,?
which expanded the set ofEDITED categories by appending the category be-low the EDITED label to the end of the EDITEDlabel ?
for example, a noun phrase (NP) reparandawould be of type EDITED-NP.
In addition, this ap-proach made edit detection easier by propagating the-UNF label attached to the rightmost unfinished con-stituent up to the EDITED label.
These two changesin combination allow the parser to better recognizewhen a reparandum has occurred, and to make sib-lings of reparanda and alterations with the same ba-sic category label.Another model of speech repair that explicitlymodels the structure of speech repair is that of John-son and Charniak (2004).
That model has a differ-ent approach than the context-free parsing approachdone in the present work.
Instead, they run a tree-adjoining grammar (TAG) parser which traces theoverlapping words and part-of-speech tags that oc-cur in the reparandum and alteration of a speech re-pair.
This approach is highly accurate at detectingspeech repairs, and allows for downstream process-ing of cleaned up text to be largely free of speechrepair, but due to its TAG component it may presentdifficulties incorporating into an architecture thatoperates on streaming text or speech.This work is also similar in aim to a component ofthe parsing and language modeling work of Roarkand Johnson (1999), which used right-binarizationin order to delay decision-making about constituentsas much as possible.
For example, the ruleNP ?
DT NNmight be right-binarized as two rules:NP ?
DT NP -DTandNP -DT ?
NNThe result of this binarization is that when predictingthe noun phrase (NP) rule, a top-down parser is de-laying making any commitments about the categoryfollowing the determiner (DT).
This delay in predic-tion means that the parser does not need to makeany predictions about whether the next word willbe, e.g., a common noun (NN), plural noun (NNS),or proper noun (NNP), until it sees the actual nextword.Similarly, the model presented in this work aimsto delay the decision to create a speech repair asmuch as possible.
This is done here by eliminatingthe EDITED category (representing a reparandum)during processing, replacing it with a REPAIREDcategory which represents the alteration of a speechrepair, and by eliminating implicit cues about repairhappening before a decision to repair should be nec-essary.Finally, this work is most directly related to thatof Miller and Schuler (2008).
In that work, the au-thors used a right-corner transform to turn standardphrase-structure trees into highly left-branchingtrees with sub-tree category labels representing in-complete but in-progress constituent structure.
Thatstructure was shown to have desirable properties inthe representation of repair in syntax trees, and thiswork leverages that insight, while attempting to im-prove the input representation such that the right-corner representation does not require the parser tomake any assumptions or decisions earlier than nec-essary.6572 Syntactic ModelThis section will first describe the default represen-tation scheme for speech repair in the Switchboardcorpus and the standard representation after applica-tion of a right-corner transform, and then describewhy there are shortcomings in both of these repre-sentations.
Descriptions of several alternative mod-els follow, with an explanation of how each of themis meant to address the shortcomings seen in previ-ous representations.
These models are then evalu-ated in Section 3.2.1 Standard Repair AnnotationThe standard representation of speech repair in theSwitchboard corpus makes use of one new categorylabel (EDITED), to represent a reparandum, and anew dash-tag (-UNF), representing the lowest unfin-ished constituent in a phrase.
An example tree withboth EDITED and -UNF tags is shown in Figure 1.SBARWHNP-2DTthatSEDITEDSNP-SBJPRPyouVP-UNFMDcouldNP-SBJPRPyouVPMDcouldVPVBusePP-PRPINforNPNNlandfillFigure 1: A fragment of a standard phrase-structure treefrom the development set, containing both an EDITEDconstituent and an -UNF tag.This sentence contains a restarted sentence (S)constituent, in which the speaker started by saying?you could?, then decided to restart the phrase, inthis case without changing the first two words.
Oneimportant thing to notice is that the EDITED labelcontains no information about the structure beneathit.
As a result, a parser trained on this default anno-tation has no information about the attempted con-stituent type, which, in the case of restarts would ob-viously be beneficial.
As described above, the workby Hale et al using daughter annotation was meantto overcome this shortcoming.Another shortcoming of this annotation schemeto consider is that the EDITED tag is not meaning-ful with respect to constituent structure.
Attempt-ing to learn from this structure, for example a prob-abilistic context-free grammar, will result in the rulethat a sentence (S) consists of a reparandum, a nounphrase, and a verb phrase, which is an odd way ofthinking about both constituent structure and mean-ing.
A more intuitive understanding might be that asentence may consist of a noun phrase followed by averb phrase, and during the production of that rule,an interruption may occur which causes the rule torestart.2.2 Right-Corner TransformThe work described above by Miller and Schuler(2008) uses a right-corner transform.
This transformturns right-branching structure into left-branchingstructure, using category labels that use a ?slash?
no-tation ?/?
to represent an incomplete constituent oftype ?
?looking for?
a constituent of type ?
in orderto complete itself.
Figure 2 shows the right-cornertransformed tree from above.This transform first requires that trees be bina-rized.
This binarization is done in a similar way toJohnson (1998) and Klein and Manning (2003).Rewrite rules for the right-corner transform are asfollows, first flattening right-branching structure:1A1?1 A2?2 A3a3?A1A1/A2?1A2/A3?2A3a3(1)A1?1 A2A2/A3?2.
.
.?A1A1/A2?1A2/A3?2.
.
.
(2)then replacing it with left-branching structure:1Here, all Ai denote nonterminal symbols, and ?i denotesubtrees ; the notation A1:?0 indicates a subtree ?0 with la-bel A1; and all rewrites are applied recursively, from leaves toroot.
In trees containing repairs, the symbol ET represents anynumber of editing terms and the sub-structure within them.658SS/NPS/PPS/VPS/VPS/SS/S?
?
?
WHNPthatEDITED-SS/VPNPyouVP-UNFcouldNPyouMDcouldVBuseINforNPlandfillFigure 2: Right-corner transformed tree fragment.A1A1/A2:?1 A2/A3?2?3 .
.
.
?A1A1/A3A1/ A2:?1 ?2?3 .
.
.
(3)This representation has interesting properties,which work well for speech repair.
First, the left-branching structure of a repair results in reparandathat only require one special repair rule application,at the last word in the reparandum.
Second, the ex-plicit representation of incomplete constituents al-lows many reparanda to seamlessly integrate withthe rest of the parse tree, with the EDITED labelessentially acting as an instruction to the parser tomaintain the current position in the unfinished con-stituent.
This subtle second point is illustrated in thetree in Figure 2.
After the EDITED section is de-tected, it combines with a category label S/S to formanother sub-tree with category label S/S, essentiallyacting as a null op in a state machine looking to com-plete a phrase of type S.This representation also contains problems, how-ever.
First, note that the (bottom-up) parser uses oneset of rules to combine the reparandum with the cur-rent state of the recognition, and another set of ruleswhen combining the alteration with the previous in-put.
While it is a benefit of this approach that bothrule sets are made up of fluent speech rules, theirway of combining nonetheless requires an early pre-monition of the repair to occur.
If anything, the re-pair should require special rule applications, but inthis representation it is still the case that the reparan-dum looks different and the alteration looks ?nor-mal.
?A better model of repair from a recognition per-spective would recognize the reparandum as flu-ent, since they are recognized as such in real time,and then, when noticing the repeated words, declarethese new words to be a repair section, and retroac-tively declare the original start of the phrase to bea reparandum.
It is this conception of a recognitionmodel that forms part of the basis for a new syntacticmodel of speech repair in Section 2.3.A second problem with this representation is ev-ident in certain multi-word repairs such as the onein Figure 2 that require an extra right branch off ofthe main left branching structure of the tree.
As aresult, a multi-word reparandum structure requiresan extra unary rule application at the left-corner ofthe sub-tree, in this case S/VP, relative to the inlinestructure of the fluent version of that phrase.
Thisextra rule will often be nearly deterministic, but insome cases it may not be, which would result essen-tially in a penalty for starting speech repairs.
Thismay act to discourage short repairs and incentivizelonger reparanda, across which the penalty wouldbe amortized.
This incentive is exactly backwards,since reparanda tend to be quite short.The next section will show how the two issuesmentioned above can be resolved by making mod-659ifications to the original structure of trees containingrepairs.2.3 Modified Repair AnnotationThe main model introduced in this paper works byturning the original repair into a right-branchingstructure as much as possible.
As a result, theright-corner transformed representation has very flatstructure, and, unlike the standard right-corner trans-formed representation described above, does not re-quire a second level of depth in the tree with differ-ent rule applications.
This can also be an importantconsideration for speech, since there are parsers thatcan operate in asymptotically linear time by usingbounded stacks, and flat tree structure minimizes theamount of stack space required.This model works by using an ?interruption?model for the way a repair begins.
The interrup-tion model works on restarted constituents, by mov-ing the repaired constituent (the alteration) to bethe right-most child of the original EDITED con-stituent.
The EDITED label is then removed, anda new REPAIRED label is added.
This of coursemakes the detection of EDITED sections possibleonly retrospectively, by noting a REPAIRED sectionof a certain syntactic category, and tracing back inthe tree to find the closest ancestor of the same cate-gory.This can be illustrated schematically by the fol-lowing rewrite rule:A0EDITEDA1?0 A2?1ET.
.
.A1:?2?A0A1?0 A2?1 REPAIRED-A1ET.
.
.A1:?2(4)Figure 3 shows how the example tree from Fig-ure 1 looks when transformed in this manner.
Theresult of these transformations may appear odd, butit is important to note that it is merely an intermedi-ate stage between the ?standard?
representation withan EDITED label, representing the post-recognitionunderstanding of the sentence, and the right-cornerrepresentation in which recognition actually occurs.This right-corner representation can be seen in Fig-ure 2.3.This representation is notable in that it looks ex-actly the same after the first word of the repair(?you?)
as the later incarnation of the same word inthe alteration.
After the second word (?could?
), therepair is initiated, and here a repair rule is initiated.It should be noted, however, that strictly speakingthe only reason the REPAIRED category needs toexist is to keep track of edits for the purpose of eval-uating the parser.
It serves only a processing pur-pose, telling the parser to reset what it is looking forin the incoming word stream.WHSBARWHNPDTthatSNPPRPyouVPMDcouldREPAIRED-SSNPPRPyouVPMDcouldVPVBusePPINforNPNNlandfillFigure 3: REPAIRED-INT transformationThe next model attempts to examine the im-pact of two different factors in the REPAIRED-INTrepresentation above.
That representation had theside effect of creating special rules off of the alter-ation (REPAIRED) node, and it is difficult to as-sign praise or blame to the performance results ofthat model without distinguishing the main modi-fication from the side effects.
This can be recti-fied by proposing another model that similarly elim-inates the EDITED label for reparanda, and usesa new label REPAIRED for the alteration, but that660SS/NPS/PPS/VPS/VPS/REPAIRED-SS/VPS/SWHNPthatNPyouMDcouldNPyouMDcouldVBuseINforNPlandfillFigure 4: REPAIRED-INT + right-corner transformationdoes not satisfy the desire to have reparanda occurinline using the ?normal?
rule combinations.
Thismodel does, however, still have special rules thatthe REPAIRED label will generate.
Thus, if thismodel performs equally well (or equally as poorly)as REPAIRED-INT, then it is likely due to the modelpicking up strong signals about an alteration ruleset.
This modification involves rewriting the origi-nal phrase structure tree as follows:A0EDITEDA1:?0ET.
.
.A1:?1 ?A0A1A1:?0 ET.
.
.REPAIRED-A1A1:?1(5)A tree with this annotation scheme can be seen inFigure 5, and its right-corner counterpart is shownin Figure 6.The final modification to examine acts effectivelyas another control to the previous two annotationschemes.
The two modifications above are essen-tially performing two operations, first acting to bina-rize speech repairs by lumping a category of type Xwith a category of type EDITED-X, and then explic-itly marking the repair but not the reparandum.
Thismodification tests whether simply adding an extralayer of structure can improve performance while re-taining the standard speech repair annotation includ-ing the EDITED category label.
This modificationwill be denoted EDITED-BIN.EDITED-BIN trees are created using the follow-ing rewrite rule:WHSBARWHNPDTthatSSNPPRPyouVP-UNFMDcouldREPAIRED-SNPPRPyouVPMDcouldVPVBusePPINforNPNNlandfillFigure 5: REPAIRED-BIN transformationSS/NPS/PPS/VPS/VPS/REPAIRED-SS/SWHNPthatSS/VPNPyouVP-UNFcouldNPyouMDcouldVBuseINforNPlandfillFigure 6: REPAIRED-BIN + right-corner transformationA0EDITEDA1:?0ET.
.
.A1:?1 ?A0A1EDITED-A1A1:?0ET.
.
.A1:?1(6)After this transform, the tree would look identicalto the REPAIRED-BIN tree in Figure 5, except thenode labeled ?REPAIRED-S?
is labeled ?S?, and itsleft sibling is labeled ?EDITED-S?
instead of ?S.
?An EDITED-BIN tree after right-corner transforma-tions is shown in Figure 7.
This explicit binariza-tion of speech repairs may be effective in its ownright, because without it, a ?brute force?
binariza-tion must be done to format the tree before apply-ing the right-corner transform, and that process in-661volves joining chains of categories with underscoresinto right-branching super-categories.
This processcan result in reparanda categories in unpredictableplaces in the middle of lengthy super-categories,making data sparse and less reliable.SS/NPS/PPS/VPS/VPS/SS/SWHNPthatEDITED-SS/VPNPyouVP-UNFcouldNPyouMDcouldVBuseINforNPlandfillFigure 7: EDITED-BIN + right-corner transformation3 EvaluationThe evaluation of this model was performed using aprobabilistic CYK parser2.
This parser operates ina bottom-up fashion, building up constituent struc-ture from the words it is given as input.
This parsingarchitecture is a good match for the structure gen-erated by the right-corner transform because it doesnot need to consider any categories related to speechrepair until the repaired section has been completed.Moreover, the structure of the trees means that theparser is also building up structure from left to right.That mode of operation is useful for any modelwhich purports to be potentially extensible to speechrecognition or to model the human speech proces-sor.
In contrast, top-down parsers require exhaustivesearches, meaning that they need to explore interpre-tations containing disfluency, even in the absence ofsyntactic cues for its existence.These experiments used the Switchboard corpus(Godfrey et al, 1992), a syntactically-annotated cor-pus of spontaneous dialogues between human inter-locutors.
This corpus is annotated for phrase struc-ture in much the same way as the Penn Treebank2The specific parser used is the Stanford parser described inKlein and Manning(2003), but run in ?vanilla PCFG?
mode.Wall Street Journal corpus, with the addition of sev-eral speech-specific categories as described in Sec-tion 2.1.
For training, trees in sections 2 and 3 ofthis corpus were transformed as described in Sec-tion 2, and rule probabilities were estimated in theusual way.
For testing, trees in section 4, subsec-tions 0 and 1, were used.
Data from the tail end ofsection 4 (subsections 3 and 4) was used during de-velopment of this work.Before doing any training or testing, all trees inthe data set were stripped of punctuation, emptycategories, typos, all categories representing repairstructure, and partial words ?
anything that wouldbe difficult or impossible to obtain reliably witha speech recognizer.
A baseline parser was thentrained and tested using the split described above,achieving standard results as seen in the table be-low.
For a fair comparison to the evaluation in Haleet al (2006), the parser was given part-of-speechtags along with each word as input.
The structureobtained by the parser was then in the right-cornerformat.
For standardized scoring, the right-cornertransform, binarization, and augmented repair anno-tation were undone, so that comparison was doneagainst the nearly pristine test corpus.
Several testconfigurations were then evaluated, and comparedto three baseline approaches.The two metrics used here are the standard Parse-val F-measure, and Edit-finding F. The first takes theF-score of labeled precision and recall of the non-terminals in a hypothesized tree relative to the goldstandard tree.
The second measure marks words inthe gold standard as edited if they are dominated bya node labeled EDITED, and measures the F-scoreof the hypothesized edited words relative to the goldstandard (recall in this case is percentage of actualedited words that were hypothesized as edited, andprecision is percentage of hypothesized edited wordsthat were actually edited).The first three lines in the table refer to baselineapproaches to compare against.
?Plain?
refers to aconfiguration with no modifications other than theremoval of repair cues.
The next result shown is areproducton of the results from Hale et al (2006)(described in section 1.2)3.
The next line (?Standard3The present work compares to the standard CYK parsingresult from that paper, and not the result from a heavily opti-mized parser using lexicalization.662Right Corner?)
is a reproduction of the results fromMiller and Schuler (2008).The following three lines contain the three ex-perimental configurations.
First, the configurationdenoted EDITED-BIN refers to the simple bina-rized speech repair described in Section 2.3 (Equa-tion 6).
REPAIRED-BIN refers to the binarizedspeech repair in which the labels are basically re-versed from EDITED-BIN (Equation 5).
Finally,REPAIRED-INT refers to the speech repair typewhere the REPAIRED category may be a child ofa non-identity category, representing an interruptionof the outermost desired constituent (Equation 4).System Configuration Parseval-F Edited-FBaseline 71.03 17.9Hale et al 68.47??
37.9?
?Standard Right Corner 71.21??
30.6?
?EDITED-BIN 69.77??
??
38.9??
?
?REPAIRED-BIN 71.37?
31.6??
?
?REPAIRED-INT 71.77??
39.2??
?
?Table 1: Table of parsing results.
Star (?)
indicates sig-nificance relative to the ?Standard Right Corner?
baseline(p < 0.05), dagger (?)
indicates significance relative tothe ?Baseline?
labeled result (p < 0.05).
Double star anddagger indicate highly significant results (p < 0.001).Significance results were obtained by perform-ing a two-tailed paired Student?s t-test on both theParseval-F and Edit-F per-sentence results.
Thismethodology is not perfect, since it fails to accountfor the ease of recognition of very short sentences(which are common in a speech corpus like Switch-board), and thus slightly underweights performanceon longer sentences.
This is also the explanationfor the odd effect where the ?REPAIRED-BIN?
and?REPAIRED-INT?
results achieve significance overthe ?Standard Right Corner?
result, but not over the?Baseline?
result.
However, the simplest alternative?
weighting each sentence by its length ?
is probablyworse, since it makes the distributions being com-pared in the t-test broadly distributed collections ofunlike objects, and thus hard to interpret meaning-fully.These results show a statistically significant im-provement over previous work in overall parsing ac-curacy, and obvious (as well as statistically signif-icant) gains in accuracy recognizing edited words(reparanda) with a parser.
The REPAIRED-INTapproach, which makes repair structure even morehighly left-branching than the standard right-cornertransform, proved to be the most accurate approach.The superior performance according to the EDIT-F metric by REPAIRED-INT over REPAIRED-BINsuggests that the improvement of REPAIRED-INTover a baseline is not due simply to a new category.The EDITED-BIN approach, while lowering overallaccuracy slightly, does almost as well on EDITED-Fas REPAIRED-INT, despite having a very differentrepresentation of repair.
This suggests that there areelements of repair that this modification recognizesthat the others do not.
This possibility will be ex-plored in future work.Another note of interest regards the recovery ofreparanda in the REPAIRED-INT case.
As men-tioned in Section 2.3, the EDITED section can befound by tracing upwards in the tree from a RE-PAIRED node of a certain type, to find an non-repaired ancestor of the same type.
This makes anassumption that repairs are always maximally local,which probably does not hurt accuracy, since mostrepairs actually are quite short.
However, this as-sumption is obviously not true in the general case,since in Figure 3 for example, the repair could traceall the way back to the S label at the root of the treein the case of a restarted sentence.
It is even possiblethat this implicit incentive to short repairs is respon-sible for some of the accuracy gains by discountinglong repairs.
In any case, future work will attempt tomaintain the motivation behind the REPAIRED-INTmodification while relaxing hard assumptions aboutrepair distance.4 ConclusionThis paper introduced three potential syntactic rep-resentations for speech with repairs, based on theidea that errors are not recognized as such until acorrection is begun.
The main result is a new rep-resentation, REPAIRED-INT, which, when trans-formed via the right-corner transform, makes a veryattractive model for speech with repairs.
This rep-resentation leads to a parser that improves on otherparsing approaches in both overall parsing accu-racy and accuracy recognizing words that have beenedited.663ReferencesJohn J. Godfrey, Edward C. Holliman, and Jane Mc-Daniel.
1992.
Switchboard: Telephone speech corpusfor research and development.
In Proc.
ICASSP, pages517?520.John Hale, Izhak Shafran, Lisa Yung, Bonnie Dorr, MaryHarper, Anna Krasnyanskaya, Matthew Lease, YangLiu, Brian Roark, Matthew Snover, and Robin Stew-art.
2006.
PCFGs with syntactic and prosodic indica-tors of speech repairs.
In Proceedings of the 45th An-nual Conference of the Association for ComputationalLinguistics (COLING-ACL).Mark Johnson and Eugene Charniak.
2004.
A tag-basednoisy channel model of speech repairs.
In Proceed-ings of the 42nd Annual Meeting of the Associationfor Computational Linguistics (ACL ?04), pages 33?39, Barcelona, Spain.Mark Johnson.
1998.
PCFG models of linguistic treerepresentation.
Computational Linguistics, 24:613?632.Dan Klein and Christopher D. Manning.
2003.
Accu-rate unlexicalized parsing.
In Proceedings of the 41stAnnual Meeting of the Association for ComputationalLinguistics, pages 423?430.Willem J.M.
Levelt.
1983.
Monitoring and self-repair inspeech.
Cognition, 14:41?104.Tim Miller and William Schuler.
2008.
A unified syn-tactic model for parsing fluent and disfluent speech.
InProceedings of the 46th Annual Meeting of the Associ-ation for Computational Linguistics (ACL ?08).Brian Roark and Mark Johnson.
1999.
Efficient proba-bilistic top-down and left-corner parsing.
In Proceed-ings of the 37th Annual Meeting of the Association forComputational Linguistics (ACL 99).Elizabeth Shriberg.
1994.
Preliminaries to a Theory ofSpeech Disfluencies.
Ph.D. thesis, University of Cali-fornia at Berkeley.664
