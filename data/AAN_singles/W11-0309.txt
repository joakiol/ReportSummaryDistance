Proceedings of the Fifteenth Conference on Computational Natural Language Learning, pages 68?77,Portland, Oregon, USA, 23?24 June 2011. c?2011 Association for Computational LinguisticsSubword and spatiotemporal models for identifying actionable informationin Haitian KreyolRobert MunroDepartment of LinguisticsStanford UniversityStanford, CA, 94305rmunro@stanford.eduAbstractCrisis-affected populations are often able tomaintain digital communications but in asudden-onset crisis any aid organizations willhave the least free resources to process suchcommunications.
Information that aid agen-cies can actually act on, ?actionable?
informa-tion, will be sparse so there is great poten-tial to (semi)automatically identify actionablecommunications.
However, there are hurdlesas the languages spoken will often be under-resourced, have orthographic variation, andthe precise definition of ?actionable?
will beresponse-specific and evolving.
We presenta novel system that addresses this, drawingon 40,000 emergency text messages sent inHaiti following the January 12, 2010 earth-quake, predominantly in Haitian Kreyol.
Weshow that keyword/ngram-based models us-ing streaming MaxEnt achieve up to F=0.21accuracy.
Further, we find current state-of-the-art subword models increase this substan-tially to F=0.33 accuracy, while modeling thespatial, temporal, topic and source contexts ofthe messages can increase this to a very ac-curate F=0.86 over direct text messages andF=0.90-0.97 over social media, making it a vi-able strategy for message prioritization.1 IntroductionThe recent proliferation of cellphone technologieshas resulted in rapid increases in the volume of in-formation coming out of crisis-affected regions.
Inthe wake of the January 12, 2010 earthquake inHaiti local emergency response services were inop-erable but 70-80% of cell-towers were quickly re-stored.
With 83%/67% of men/women possessinga cellphone, the nation remained largely connected.People within Haiti were texting, calling and inter-acting with social media, but aid agencies were notequipped to process so much information.
This isbecause in any sudden onset crisis, this flood of in-formation out of the region coincides with crisis-response organizations already working at capacityas they move in.
The problem definition is clear:how can we filter this information to identify action-able intelligence to support relief efforts?The solution is complicated.
There may befew resources for the language(s) of the crisis-affected population and the ratio of actionable tonon-actionable information will often be very large,especially when reported through social-media andother non-official channels.
In the absence of ex-isting electronic resources models must be built on-the-fly and account for substantial spelling varia-tions.
The definition of what constitutes action-able intelligence will often be context-specific andchanging, too.
In the data used here ?actionable?changed quickly from Search and Rescue to anymedical emergency and then to include clusters ofrequests for food and water.
The models will there-fore need to be time-sensitive or otherwise adaptive.The system presented here attempts to addressthese problems, finding that the accurate identifica-tion of actionable information can be achieved withsubword models, the automatic identification of top-ics (categories), and spatiotemporal clustering, allwithin a streaming architecture.
It is evaluated us-ing 40,811 emergency text messages sent in Haitifollowing the January 12, 2010 earthquake.682 Evaluation dataThree sets of short-messages are used, all from be-tween January 12 and May 12, 2010:1.
Mission 4636.
40,811 text-messages sent to afree number, ?4636?, in Haiti.2.
Radio Station.
7,528 text-messages sent to aHaitian radio station.3.
Twitter.
63,195 Haiti-related tweets.The Mission 4636 messages were translated, ge-olocated and categorized by a volunteer onlinecrowdsourced workforce, predominantly from theHaitian diaspora, and by paid workers within Haiti(Munro, 2010).
English-speaking crisis-mappersidentified actionable messages and refined the coor-dinates and categories.
The categories are a standardset of UN-defined emergency categories with someadditions (48 total).
The definition of an ?actionable?message was defined by the main responders to themessages, the US Coast Guard and the US Marinesworking with Southern Command, and included anymessages with an identifiable location that containeda request for medical assistance, Search and Rescue,water-shortages, clusters of requests for food in ar-eas not known to aid workers, security, and reportsof unaccompanied minors.The radio station and Twitter messages are notstructured or geolocated.
They are used here as po-tential false-positives in a needle-in-a-haystack sce-nario where the majority of messages are irrelevant.A recent Red Cross survey (2010) found that nearlyhalf the respondents would use social media to re-port emergencies, so this is a realistic scenario.3 Streaming modelsSupervised streaming-models attempt to classify anincoming stream of unlabeled items by building uptraining-data on past items (Aggarwal, 2006; Hul-ten et al, 2001; Babcock et al, 2002).
The mod-els are often time-sensitive with training data eitherweighted towards or exclusively consisting of morerecently seem items, especially in the context of con-cept drift or bounded memory (Zhang et al, 2008).There is a penalty for applying GOLD labels topast items for training: either only a subset can belabeled or there is a time-delay.
When only a subsetcan be labeled the scenario is similar to that of activelearning (Cohn et al, 1996; Tong and Koller, 2002).When there is a delay not all past items are imme-diately available, meaning that short-term conceptdrifts might not be adapted to.
In both cases, accu-racy is continually evaluated over incoming items.Here, the time-delay penalty was used for all Mis-sion 4636 messages as it is closer to the actual sce-nario where each potential emergency message is ul-timately read by a person but with potential delaysfrom sudden bursts and backlogs.The messages were divided into 100 temporallyordered sets.
Each set belongs to one epoch i inthe streaming architecture, R, such that Ri is eval-uated on R0, .
.
.
, Ri?1 (R1 is evaluated on a modeltrained on R0; R2 is evaluated on a model trainedon {R0, R1}; R3 is evaluated on a model trained on{R0, R1, R2}, etc.).
The accuracy is therefore cal-culated over R1, .
.
.
, R99 (all but the first set).The results here report a system using a MaxEntlearning algorithm with Quasi-Newton optimizationand a convergence tolerance of 10?4.
Changing pa-rameter settings or swapping out the learning algo-rithm with linear and quadratic kernel SVMs madelittle difference in accuracy (see discussion of othermodels below).4 Features (F )G : Words and ngrams.W : Subword patterns (extended definition below).P : Source of the message (phone number).T : Time received.C : Categories (c0,...,47).L : Location (longitude and latitude).L?
: Has-location (there is an identifiable locationwithin the message).G, W , P and T were calculated directly from themessages.
C and L?
were predicted using indepen-dent streaming models and L was clustered throughtiling (see below).4.1 Hierarchical streaming models forhas-location (L?)
and category (C)The SMS protocol does not encode locations or cate-gories.
The streaming model was extended to a two-level hierarchical architecture so that we could use(predicted) locations and categories as features.69Nou tigwav,nou pa gen manje nou pa gen kay.
m.?We are Petit Goave, we don?t have food, we don?t have a house.
Thanks.Actionable -72.86537, 18.43264 1/22/2010 16:59 2a.
Food Shortage, 2b.
Water shortageLopital Sacre-Coeur ki nan vil Milot, 14 km nan sid vil Okap, pre pou li resevwa moun malad e l?apmande pou moun ki malad yo ale la.
?Sacre-Coeur Hospital which located in this village Milot 14 km south of Oakp is ready to receive thosewho are injured.
Therefore, we are asking those who are sick to report to that hospital.
?Actionable -72.21272, 19.60869 2/13/2010 22:33 4a.
Health servicesMwen se [FIRST NAME] [LAST NAME] depi jeremi mwen ta renmen jwenm travay.
?My name is [FIRST NAME] [LAST NAME], I?m in Jeremi and I would like to find work.
?Not Actionable -74.1179, 18.6423 1/22/2010 18:29 5.
OtherRue Casseus no 9 gen yon sant kap bay swen ak moun ki blese e moun ki brile.
?Street Casseus no 9, there is a center that helps people that are wounded or burnt.
?Actionable -72.32857,18.53019 1/19/2010 11:21 4a.
Health servicesPaket moun delmas 32 ki forme organisation kap mache pran manje sou non pep yo ankesel lakay?People in Delmas 32 formed an association that takes food in the name of everyone in the neighborhood?Not Actionable -72.30815,18.54414 2/4/2010 1:21 5.
OtherTable 1: Examples of messages, with translation, actionable flag, location, timestamp and categories.
The final twowere a consistent false negative and false positive respectively.
The former likely because of sparsity - places offeringservices were rare - and the latter because reports of possible corruption were not, unfortunately, considered actionable.A set S, of 49 base streaming models predictedthe has-location, L?, feature and categories, c0,...,47.That is, unlike the main model, R, which predictsthe ?Actionable?/?Not Actionable?
division, eachmodel S predicts either the existence of a locationwithin the text or binary per-category membership.The predictions for each message were added to thefinal model as feature confidence values per-label.This is richer than simply using the best-guess labelsfor each model S and it was clear in early processingthat confidence features produced consistently moreaccurate final models than binary predicted labels.In fact, using model confidence features for L?
ac-tually outperforms an oracle binary has-location fea-ture, O(L?)
(see results).The same G, W , P and T features were used forthe S and R models.As the final model R requires the outputs from Sfor training, and S are themselves predictive models,the L?
and C features are not included until the sec-ond training epoch R1.
In the context of machine-learning for sudden onset humanitarian informationprocessing any delay could be significant.
One sim-ple solution is starting with smaller epoch sizes.4.2 Subword featuresA typical former creole, Haitian Kreyol has verysimple morphology but the text message-languageproduces many compounds and reductions (?myfamily?
: fanmi mwen, fanmwen, fanmi m, fanmi?m,fanmim?, fanmim), so it requires segmentation.There is also substantial variation due to lack ofspelling conventions, geographic variation, varyingliteracy, more-or-less French spellings for cognates,and character sets/accents (?thank you?
: mesi, me?si,me?ci meci, merci).
See Table 2 for further examplesand common subword patterns that were discoveredacross very different surface forms.The approach here builds on the earlier work ofMunro and Manning (2010), adapted from Gold-water et al (2009), where unsupervised methodswere used to segment and phonologically normalizethe words.
For example, the process might turn allvariants of ?thank you?
into ?mesi?
and all variantsof ?my family?
into ?fan mwen?.
This regulariza-tion allows a model to generalize over the different70Abbrev.
Full Form Pattern Meanings?on se yon sVn is aave`n ave`knou VvVn with usrelem rele mwen relem call mewap ouap uVp you aremap mwen ap map I will bezanmim zanmi mwen zanmim my friendlavel lave li lavel to wash (it)Table 2: Abbreviations and full forms of words, showingsubstantial variation but common subword patterns andcharacter alternations (V=any vowel).forms even in the event of singleton word variants.Here we incorporated the segmentation into the su-pervised learning task rather than model the phono-logical/orthographic variation as a pre-learning nor-malization step, as in Munro and Manning.
A setof candidate segmentations and normalizations wereadded to our final model as features representingboth the pre and post-normalization, allowing themodel to arrive at the optimal training weights be-tween the unnormalized/unsegmented and normal-ized/segmented variants.This meant that rather than optimizing the sub-word segmentation according to a Gaussian priorover unlabeled data we optimized the segmentationaccording to the predictive ability of a given seg-mentation per model.
This is further from the lin-guistic reality of the segments than our earlier ap-proach but the richer feature space led to an increasein accuracy in all test cases here.The subword models were only applied to theoriginal messages.
The English translations werenot included among the features as it is not realis-tic to assume manual translation of every messagebefore the less labor-intensive task of identifying ac-tionable items.4.3 Oracle featuresWhile the SMS protocol does not encode thegeographical origin of the message, other proto-cols/systems do, especially those used by smart-phones.
Similarly, cell-tower granularity of loca-tions might be available, phone numbers might be apriori associated with locations, or locations couldbe formalized within the text using methods like?Tweak the Tweet?
(Starbird and Stamberger, 2010).Therefore, it is reasonable to also simulate a scenariowhere the messages come pre-geocoded.
We com-pared our results to models also containing the ora-cle longitude and latitude of the messages, O(L) (noattempt was made to predict L, the precise longitudeand latitude - a challenging but interesting task) andthe oracle existence of a location O(L?
).It is less likely that messages come pre-categorized but oracle features for the categorieswere also evaluated to compare the performance formodels containing the predictive categories to onescontaining the actual categories, O(c0,...,47).4.4 Spatial clusteringIn addition to identifying locations, we also used thelatitude and longitude to geographically cluster mes-sages.
This was to capture two phenomena:1.
Hot spots: some areas were in greater need ofaid than others.2.
Clustered food requests: the definition of ?ac-tionable?
extended to clustered requests forfood, but not requests from lone individuals.Figure 1 shows a Port-au-Prince (Po?toprens)neighborhood with incident reports from the textmessages.
The x, y axes (latitude, longitude) showthe clusters given by the Ushahidi map and the z axisshows the temporal distribution of messages over atwo month period.
Both the spatial and temporaldistributions clearly show a high frequency of bothclusters and outliers.The most accurate clustering divided the mes-sages by longitude and latitude into tiles approxi-mating 100m2, 1km2 and 10km2.
At each gran-ularity, tiling was repeated with an offset by halfon each dimension to partially smooth the arbitrari-ness of tile boundaries.
This resulted in each geo-located messages being a member of 12 tiles in to-tal, which were included as 12 features L. We werenot able to find an unsupervised spatial clustering al-gorithm that improved the results beyond this brute-force method of multiple tiles at different granulari-ties (see discussion of other models tested below).4.5 Temporal modeling and discountingIt is common to calculate a discounting functionover training epochs in streaming models (Aggar-71Figure 1: Map of a Port-au-Prince neighborhood with in-cident reports from text messages, with spatial clusters onthe latitudinal and longitudinal axes and temporal distri-butions on the time axis, showing both spatial and tem-poral clustering, with frequent outliers.wal, 2006; Hulten et al, 2001; Babcock et al, 2002).We used a slightly different method here wherethe time-stamp feature, T , performs this function,arriving at the relative probability for a given timeperiod t in the final model, R (Zhang et al, 2008).It has several advantages over a simple weighteddiscounting function.
First, t is calculated incre-mentally, not per training epoch, meaning that theweight ?
for t is calculated until the most recentlyseen items.
Second, it frees T to cluster accord-ing to temporal divisions other than the (arbitrary)divisions of training epochs.
Finally, it allows un-constrained weights for different temporal clusters,permitting the final distribution of weights over dif-ferent ts to define complex and possibly nonmono-tonic discounting functions.
Modeling time as a fea-ture rather than a discounting function also madeit simpler to combine temporal and spatial cluster-ing.
The feature T consisted of multiple bucketsof time-stamps per message and also composite fea-tures with the O(L) tiles when present.4.6 Other models testedSeveral other machine-learning methods were testedbut ultimately not reported here.Intuitively, SVMs with non-linear kernels couldmore accurately model geographic divisions inthe latitude and longitude dimensions and dis-cover different combinations of features like has-location=true and category=emergency.
However,we were not able to find a combination of kernelsand parameter settings that demonstrated this.
It ispossible that we could not avoid over-fitting or thatthe composite features had already sufficiently cap-tured the combinations.Munro and Manning (2010) also found gains us-ing supervised LDA (Ramage et al, 2009), whichhas also previously been used for disaster responseclustering (Kireyev et al, 2009).
We implementedsupervised LDA and unsupervised LDA topic mod-els, but they showed modest improvements over thebaseline model only.
We presume that this is be-cause when we add the predicted categories fromour (supervised) category learning task, they alreadycontained enough information about topic divisions.We looked at several methods for spatio-temporalclustering including cliques (Zhang et al, 2004), k-means (Wagstaff et al, 2001), and targeted low fre-quency clusters (Huang et al, 2003).
The change inaccuracy was negligible but the exploration of meth-ods was by no means exhaustive.
One exceptionwas using nearest-neighbor spatiotemporal cluster-ing, however the gains were predominantly repeatedmessages from the same person and thus alreadycaptured by the source feature, P .Several systems have been built by humanitar-ian organizations for filtering/prioritizing messages,mostly keyword and memory-based.
All are cur-rently less accurate than the baseline system hereand their predicted outputs gave no gains as features.The SwiftRiver system built on NLTK library (Birdet al, 2009) was the most promising, only underper-forming the baseline by F=0.01.5 ResultsThe results in Table 3 show that a combination ofstreaming models with subword models improvesthe accuracy of identifying actionable messages.
Allincreases in accuracy are significant relative to thebaseline.The temporal feature, T , alone gives F=0.045 in-crease in accuracy indicating that there is substantialconcept drift and an adaptive model is necessary foraccurate classification.The subword models, W , increase the gain to0.119 showing that despite Kreyol being a morpho-logically simple language the variation in spellingsand compounds is significant.72Model Precision Recall F-value F-GainWords/Ngrams (G) 0.622 0.124 0.207 n/aTemporal feature (G,T ) 0.716 0.153 0.252 0.045Subwords and Source (G,T,W,P ) 0.548 0.233 0.326 0.119Categories (predicted: G,T,C, P ) 0.464 0.240 0.316 0.109Location (predicted: G,T,L?, P ) 0.572 0.212 0.310 0.103Categories (oracle: G,T,O(C), P ) 0.565 0.225 0.322 0.115Location (oracle: G,T,O(L?
), P ) 0.746 0.168 0.274 0.067Spatial clusters (L) 0.896 0.653 0.756 0.549All non-oracle and spatial clusters 0.872 0.840 0.855 0.648Pre-filtered spatial clusters 0.613 0.328 0.428 0.221Radio station 0.961 0.854 0.904 n/aTwitter 0.950 0.989 0.969 n/aTable 3: The final results for the different models.
The first three and Location (oracle) contain only single streamingmodels.
The others use a hierarchical streaming model combining features with the outputs from the base streamingmodelsS.
The model combining all features is the most accurate at F=0.855, 0.648 above the baseline model optimizedover words and word sequences (ngrams).
The Pre-filtered spatial clusters contains the same architecture/features asthe most accurate model, but with those messages not containing an identifiable location (and therefore automaticallynon-actionable) stripped from the training and test data.
The final Radio station and Twitter models used the messagessent to a radio station and Twitter as the non-actionable items, using the same training model as All non-oracle andspatial clusters.5.1 Oracle vs predicted outputsComparing the oracle values and predicted outputsfrom the categories and the identification of mes-sages containing locations, O(C), O(L?
), C, L?, wesee that the predictive model for categories onlyslightly underperforms the oracle, but the predictivemodel for locations outperforms the oracle model.We suspect that this is because the predictions areprobabilities, not binary indicators of the existenceof a location.
Therefore, the richer real-valuedfeature space led to greater information for the fi-nal model despite any predictive errors in this basemodel.
Another reason can be clearly seen in theprecision, 0.746 for the O(L) model, one of thehighest precision-to-recall ratios.
The final modelis clearly giving too much weight to the existenceof a location as a predictor of an actionable la-bel.
Smoothing O(L) makes little difference as itis a high-frequency binary feature, but the greaterrange of probability values in L are necessarily moresparse and therefore more de-weighted by smooth-ing.Identifying locations is one area that could be ex-panded on greatly.
Initial experiments with named-entity recognition were abandoned when it was clearthat the data was too sparse and too different fromexisting data sets, but perhaps text-message-specificnamed-entity recognition methods could lead toeven more accurate results for identifying locations.5.2 Spatial clusteringBy adding spatial clusters we get the greatest leap inaccuracy: F=0.756, a substantial F=0.549 over thebaseline.
This is strong evidence in favor of extend-ing text-only messaging to location-aware messag-ing.
As with the prediction of locations, it is likelythat methods for spatial clustering other than brute-force bucketing could lead to more accurate results,but as stated earlier we were not able to identify any.Combining the base streaming model outputswith all features leads to the most accurate model.
Itis expected that this would produce the best results,but at F=0.855 we have a very significant gain overany of the models implementing only single-streamlearning, or without the full feature space.735.3 Pre-filteringSomewhat counterintuitively, pre-filtering messageswithout known locations (in both training and testdata) decreased the accuracy to F=0.428.
Oracle fil-tering of true-negative test items will not change re-call and can only increase precision, so clearly thereis ?signal?
in the ?noise?
here.
Analysis of the mes-sages showed that many non-actionable messageswere not related to emergencies at all (general ques-tions, requests for work, etc), as were many mes-sages without identifiable locations.
That is, peoplewho tended to not send actionable information alsotended to not include locations.
Because of this cor-relation, the content of messages without locationsbecomes useful information for the model.A careful analysis of the training models con-firms this: the word and subword features for non-actionable messages with no locations had non-zeroweights.
Pre-filtering them therefore resulted in animpoverished training set.It is standard practice in the humanitarian indus-try to pre-filter messages that are easily identifiedas non-actionable (for obvious reasons: it reducesthe manual processing), which is what occurred inHaiti - only about 5% of messages were treated as?actionable?
candidates.
The results here indicatethat if manual processing is extended to automatedor semi-automated processing this strategy needs tochange, with all potential training items included inthe models.5.4 Comparison to non-emergency messagesFor the social media scenarios where we combinedthe actionable test items with the messages sent toa radio station and Twitter the accuracy was highestof all.
This is a promising result for seeking action-able information in non-traditional sources.
The ra-dio station is particularly promising as almost all themessages where in Haitian Kreyol and spoke aboutthe same locations as the 4636 messages.While the Twitter messages were extremely ac-curate at F=0.969, the majority of the tweets werein English or French from people outside of Haiti,so this model was at least in part about languageidentification, a much simpler task and less novelfrom a research perspective.
Nonetheless, while atleast part of the accuracy is easily explained this wasthe most sparse test set with only 0.025% actionableitems, so the application scenario is very promising.5.5 PrioritizationApplying ROC analysis, the methods here couldspeed up the prioritization of actionable messagesby a factor of 10 to 1 based on content alone.
Thatis, on average an actionable message falls within the90th percentile for probability of being actionable.By including spatial clustering this becomes the 98thpercentile.
There is great potential for improvementsbut the methods reported here could already be usedto efficiently prioritize the triage of the most impor-tant messages within a semi-automated system.6 Related Work6.1 trillion text messages were sent in 2010 - morethan emails and social network communicationscombined (ITU, 2010), especially in areas of greatlinguistic diversity (Maffi, 2005).
This easily makesit the least well-studied method for digital commu-nication relative to the amount digital informationbeing generated.The lack of research is probably due to obstaclesin obtaining data.
By contrast Twitter?s API has ledto much recent research, primarily in sentiment anal-ysis (O?Connor et al, 2010; Alexander Pak, 2010;Sriram et al, 2010) and unsupervised event detec-tion (Petrovic?
et al, 2010).
The task of identifyingsentiment is different to filtering actionable intelli-gence, we were not training on tweets, and Twitter-language is reportedly different from text-message-language (Krishnamurthy et al, 2008).
However,there are similarities relating to problems of mes-sage brevity and the ability to extend the feature-space.
For example, Sriram et al (2010) also foundthat modeling the source of a message improved ac-curacy.
Eisenstein et al (Eisenstein et al, 2010)show promising results in identifying an author?sgeographic location from micro-blogs, but the lo-cations are course-grained and rely on a substantialmessage history per-source.In recent work with medical text messages in theChichewa language, we compared the accuracy ofrule-based and unsupervised phonological normal-ization and morphological segmentation when ap-plied to a classification task over medical labels,74showing substantial gains from subword models(Munro and Manning, 2010).A cluster of earlier work looked at SMS-SPAM inEnglish (Healy et al, 2005; Hidalgo et al, 2006;Cormack et al, 2007) and Beaufort et al (2010)used a similar preprocessing method for normaliz-ing text-messages in French, combining rule-basedmodels with a finite-state framework.
The accuracywas calculated relative to BLEU scores for ?correct?French, not as a classification task.Machine-translation into a more well-spoken lan-guage can extend the potential workforce.
Earlyresults are promising (Lewis, 2010) but still leavesome latency in deployment.For streaming architectures, Zhang et al (2008)proposed a similar method for calculating per epochweights as an alternative to a discounting functionwith significant gains.
Wang et al (2007) alsolooked at multiple parallel streams of text from dif-ferent newspapers reporting the same events but wecouldn?t apply their method here as there were fewinstances of the same pairs of people independentlyreporting two distinct events.
The two-tiered archi-tecture used here is similar to a hierarchical model,the main difference being epoch-based retrainingand the temporal offset of the base models feed-ing into the final one.
Joint learning over hierarchi-cal models has been successful in NLP (Finkel andManning, 2010) but to our best knowledge no onehas published work on joint learning over hierarchi-cal streaming models, in NLP or otherwise.7 ConclusionsFrom models optimized over words and ngramsto one including temporal clustering and subwordmodels the accuracy rises from F=0.207 to F=0.326.Clearly, the words that someone has chosen to ex-press a message is just one small aspect of thecontext in which that message is understood andby combining different learning models with richerfeatures we can prioritize actionable reports withsome accuracy.
With spatial clustering this rises toF=0.885, indicating that geographic location was thesingle most important factor for prioritizing action-able messages.These results are only a first step as there is greatpotential for research identifying more accurate andefficient learning paradigms.
A growing number ofour communications are real-time text with frequentspelling variants and a spatial component (tweets,location-based ?check-ins?, instant messaging, etc)so there will be increasingly more data available inan increasing variety of languages.It is easy to imagine many humanitarian applica-tions for classifying text-messages with spatiotem-poral information.
Social development organiza-tions are already using text messaging to supporthealth (Leach-Lemens, 2009), banking (Peevers etal., 2008), access to market information (Jagun et al,2008), literacy (Isbrandt, 2009), and there is the po-tential to aid many of them.
Even more importantly,this work can contribute to information processingstrategies in future crises.
Had a system like the onepresented here been in place for Haiti then the iden-tification of actionable messages could have beenexpedited considerably and a greater volume pro-cessed.
I coordinated the Mission 4636 volunteerswho were translating and mapping the messages inreal-time, so this research is partially motivated bythe need to see what I could have done better, with aview to being better prepared for future crises.The results for social media are especially promis-ing.
In total, the tweets contained 1,178,444 words- the size of approximately 10 novels - but if therewas just one real emergency among them, there wasa 97% chance it would rise to the top when orderedby actionable confidence.AcknowledgmentsWith thanks to the volunteers of Mission 4636.Their work translating, categorizing and mappingcommunications showed the humanitarian commu-nity the benefits of crowdsourcing/microtasking andis now also helping us prepare for higher-volumesemi-automated systems.
Thanks also to the volun-teers and workers of Samasource/FATEM in Haiti,Ushahidi Haiti in Boston, and to the engineers atCrowdFlower and Ushahidi who built the platformswe used for translation and mapping.This work was supported by a Stanford Grad-uate Fellowship and owes thanks to collaborativework and conversations with Chris Manning andcolleagues in the Stanford NLP Research Group.75ReferencesCharu C. Aggarwal.
2006.
Data Streams: Mod-els and Algorithms (Advances in Database Systems).Springer-Verlag, New York.Patrick Paroubek Alexander Pak.
2010.
Twitter as a cor-pus for sentiment analysis and opinion mining.
In Pro-ceeding of the 2010 International Conference on Lan-guage Resources and Evaluation (LREC 2010).Brian Babcock, Shivnath Babu, Mayur Datar, RajeevMotwani, and Jennifer Widom.
2002.
Models andissues in data stream systems.
In Proceedings of thetwenty-first ACM SIGMOD-SIGACT-SIGART sympo-sium on Principles of database systems, pages 1?16.ACM.Richard Beaufort, Sophie Roekhaut, Louise-Ame?lieCougnon, and Ce?drick Fairon.
2010.
A hybridrule/model-based finite-state framework for normaliz-ing sms messages.
In Proceedings of the 48th AnnualMeeting of the Association for Computational Linguis-tics ACL 2010.BSteven Bird, Ewan Klein, and Edward Loper.
2009.Natural language processing with Python.
Oreilly &Associates Inc.David A. Cohn, Zoubin Ghahramani, and Michael Jor-dan.
1996.
Active learning with statistical models.Arxiv preprint cs/9603104.Gordon V. Cormack, Jose?
Mara Go?mez Hidalgo, and En-rique Puertas Sa?nz.
2007.
Feature engineering formobile (SMS) spam filtering.
In The 30th annual in-ternational ACM SIGIR conference on research anddevelopment in information retrieval.The American Red Cross.
2010.
Social media in disas-ters and emergencies.
Presentation.Jacob Eisenstein, Brendan O?Connor, Noah A. Smith,and Eric P. Xing.
2010.
A latent variable model for ge-ographic lexical variation.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP 2010).Jenny Rose Finkel and Christopher D. Manning.
2010.Hierarchical joint learning: Improving joint parsingand named entity recognition with non-jointly labeleddata.
In Annual Conference of the Association forComputational Linguistics (ACL 2010).Sharon Goldwater, Thomas L. Griffiths, and Mark John-son.
2009.
A bayesian framework for word segmen-tation: Exploring the effects of context.
Cognition,112(1):21?54.Matt Healy, Sarah Jane Delany, and Anton Zamolotskikh.2005.
An assessment of case-based reasoning forShort Text Message Classification.
In The 16th IrishConference on Artificial Intelligence & Cognitive Sci-ence.Jose?
Mara Go?mez Hidalgo, Guillermo Cajigas Bringas,Enrique Puertas Sa?nz, and Francisco Carrero Garca.2006.
Content based SMS spam filtering.
In ACMsymposium on Document engineering.Yan Huang, Hui Xiong, Shashi Shekhar, and Jian Pei.2003.
Mining confident co-location rules without asupport threshold.
In Proceedings of the 2003 ACMsymposium on Applied computing.Geoff Hulten, Laurie Spencer, and Pedro Domingos.2001.
Mining time-changing data streams.
In Pro-ceedings of the seventh ACM SIGKDD internationalconference on Knowledge discovery and data mining.ACM.Scott Isbrandt.
2009.
Cell Phones in West Africa: im-proving literacy and agricultural market informationsystems in Niger.
White paper: Projet Alphabe?tisationde Base par Cellulaire.ITU.
2010.
The world in 2010: ICT facts and figures.International Telecommunication Union.Abi Jagun, Richard Heeks, and Jason Whalley.
2008.The impact of mobile telephony on developing countrymicro-enterprise: A Nigerian case study.
InformationTechnologies and International Development, 4.Kirill Kireyev, Leysia Palen, and Kenneth M. Ander-son.
2009.
Applications of topics models to analy-sis of disaster-related Twitter data.
In Proceedings ofthe NIPS Workshop on Applications for Topic Models:Text and Beyond.Balachander Krishnamurthy, Phillipa Gill, and MartinArlitt.
2008.
A few chirps about Twitter.
In Proceed-ings of the first workshop on Online social networks,New York.Carole Leach-Lemens.
2009.
Using mobile phones inHIV care and prevention.
HIV and AIDS Treatment inPractice, 137.Will Lewis.
2010.
Haitian Creole: How to Build andShip an MT Engine from Scratch in 4 days, 17 hours,& 30 minutes.
In 14th Annual Conference of the Eu-ropean Association for Machine Translation.Luisa Maffi.
2005.
Linguistic, cultural, and biologicaldiversity.
Annual Review of Anthropology, 34:599?617.Robert Munro and Christopher D. Manning.
2010.
Sub-word variation in text message classification.
In Pro-ceedings of the Annual Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics (NAACL 2010).Robert Munro.
2010.
Crowdsourced translation foremergency response in Haiti: the global collaborationof local knowledge.
In AMTA Workshop on Collabo-rative Crowdsourcing for Translation.Brendan O?Connor, Ramnath Balasubramanyan,Bryan R. Routledge, and Noah A. Smith.
2010.76From tweets to polls: Linking text sentiment to publicopinion time series.
In Proceedings of the FourthInternational AAAI Conference on Weblogs and SocialMedia.Gareth Peevers, Gary Douglas, and Mervyn A. Jack.2008.
A usability comparison of three alternative mes-sage formats for an SMS banking service.
Interna-tional Journal of Human-Computer Studies, 66.Sasa Petrovic?, Miles Osborne, and Victor Lavrenko.2010.
Streaming first story detection with applicationto twitter.
In Proceedings of the Annual Conferenceof the North American Chapter of the Association forComputational Linguistics (NAACL 2010).Daniel Ramage, David Hall, Ramesh Nallapati, andChristopher D. Manning.
2009.
Labeled LDA: Asupervised topic model for credit attribution in multi-labeled corpora.
In Proceedings of the 2009 Confer-ence on Empirical Methods in Natural Language Pro-cessing, Singapore.Bharath Sriram, Dave Fuhry, Engin Demir, Hakan Fer-hatosmanoglu, and Murat Demirbas.
2010.
Short textclassification in twitter to improve information filter-ing.
In Proceeding of the 33rd international ACM SI-GIR conference on research and development in infor-mation retrieval.Kate Starbird and Jeannie Stamberger.
2010.
Tweak theTweet: Leveraging Microblogging Proliferation with aPrescriptive Syntax to Support Citizen Reporting.
InProceedings of the 7th International ISCRAM Confer-ence.Simon Tong and Daphne Koller.
2002.
Support vec-tor machine active learning with applications to textclassification.
The Journal of Machine Learning Re-search, 2:45?66.Kiri Wagstaff, Claire Cardie, Seth Rogers, and StefanSchr?odl.
2001.
Constrained k-means clustering withbackground knowledge.
In Proceedings of the Eigh-teenth International Conference on Machine Learning,volume 577, page 584.
Citeseer.Xuanhui Wang, Cheng Xiang Zhai, Xiao Hu, and RichardSproat.
2007.
Mining correlated bursty topic pat-terns from coordinated text streams.
In Proceedingsof the 13th ACM SIGKDD international conference onKnowledge discovery and data mining.Xin Zhang, Nikos Mamoulis, David W. Cheung, and Yu-tao Shou.
2004.
Fast mining of spatial collocations.In Proceedings of the tenth ACM SIGKDD interna-tional conference on Knowledge discovery and datamining, pages 384?393.
ACM.Peng Zhang, Xingquan Zhu, and Yong Shi.
2008.
Cate-gorizing and mining concept drifting data streams.
InProceedings of the 14th ACM SIGKDD internationalconference on Knowledge discovery and data mining.77
