Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 100?105,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsSemEval-2010 Task 9: The Interpretation of Noun CompoundsUsing Paraphrasing Verbs and PrepositionsCristina ButnariuUniversity College Dublinioana.butnariu@ucd.ieSu Nam KimUniversity of Melbournenkim@csse.unimelb.edu.auPreslav NakovNational University of Singaporenakov@comp.nus.edu.sgDiarmuid O?
Se?aghdhaUniversity of Cambridgedo242@cam.ac.ukStan SzpakowiczUniversity of OttawaPolish Academy of Sciencesszpak@site.uottawa.caTony VealeUniversity College Dublintony.veale@ucd.ieAbstractWe present a brief overview of the mainchallenges in understanding the semantics ofnoun compounds and consider some knownmethods.
We introduce a new task to bepart of SemEval-2010: the interpretation ofnoun compounds using paraphrasing verbsand prepositions.
The task is meant to providea standard testbed for future research on nouncompound semantics.
It should also promoteparaphrase-based approaches to the problem,which can benefit many NLP applications.1 IntroductionNoun compounds (NCs) ?
sequences of two or morenouns acting as a single noun,1 e.g., colon cancertumor suppressor protein ?
are abundant in Englishand pose a major challenge to the automatic anal-ysis of written text.
Baldwin and Tanaka (2004)calculated that 3.9% and 2.6% of the tokens inthe Reuters corpus and the British National Corpus(BNC), respectively, are part of a noun compound.Compounding is also an extremely productive pro-cess in English.
The frequency spectrum of com-pound types follows a Zipfian or power-law distribu-tion (O?
Se?aghdha, 2008), so in practice many com-pound tokens encountered belong to a ?long tail?of low-frequency types.
For example, over half ofthe two-noun NC types in the BNC occur just once(Lapata and Lascarides, 2003).
Even for relativelyfrequent NCs that occur ten or more times in theBNC, static English dictionaries give only 27% cov-erage (Tanaka and Baldwin, 2003).
Taken together,1We follow the definition in (Downing, 1977).the factors of high frequency and high productiv-ity mean that achieving robust NC interpretation isan important goal for broad-coverage semantic pro-cessing.
NCs provide a concise means of evoking arelationship between two or more nouns, and natu-ral language processing (NLP) systems that do nottry to recover these implicit relations from NCs areeffectively discarding valuable semantic informa-tion.
Broad coverage should therefore be achievedby post-hoc interpretation rather than pre-hoc enu-meration, since it is impossible to build a lexicon ofall NCs likely to be encountered.The challenges presented by NCs and their se-mantics have generated significant ongoing interestin NC interpretation in the NLP community.
Repre-sentative publications include (Butnariu and Veale,2008; Girju, 2007; Kim and Baldwin, 2006; Nakov,2008b; Nastase and Szpakowicz, 2003; O?
Se?aghdhaand Copestake, 2007).
Applications that have beensuggested include Question Answering, MachineTranslation, Information Retrieval and InformationExtraction.
For example, a question-answering sys-tem may need to determine whether headaches in-duced by caffeine withdrawal is a good paraphrasefor caffeine headaches when answering questionsabout the causes of headaches, while an informationextraction system may need to decide whether caf-feine withdrawal headache and caffeine headacherefer to the same concept when used in the samedocument.
Similarly, a machine translation systemfacing the unknown NC WTO Geneva headquartersmight benefit from the ability to paraphrase it asGeneva headquarters of the WTO or as WTO head-quarters located in Geneva.
Given a query like can-100cer treatment, an information retrieval system coulduse suitable paraphrasing verbs like relieve and pre-vent for page ranking and query refinement.In this paper, we introduce a new task, which willbe part of the SemEval-2010 competition: NC inter-pretation using paraphrasing verbs and prepositions.The task is intended to provide a standard testbedfor future research on noun compound semantics.We also hope that it will promote paraphrase-basedapproaches to the problem, which can benefit manyNLP applications.The remainder of the paper is organized as fol-lows: Section 2 presents a brief overview of theexisting approaches to NC semantic interpretationand introduces the one we will adopt for SemEval-2010 Task 9; Section 3 provides a general descrip-tion of the task, the data collection, and the evalua-tion methodology; Section 4 offers a conclusion.2 Models of Relational Semantics in NCs2.1 Inventory-Based SemanticsThe prevalent view in theoretical and computationallinguistics holds that the semantic relations that im-plicitly link the nouns of an NC can be adequatelyenumerated via a small inventory of abstract re-lational categories.
In this view, mountain hut,field mouse and village feast all express ?locationin space?, while the relation implicit in history bookand nativity play can be characterized as ?topicality?or ?aboutness?.
A sample of some of the most influ-ential relation inventories appears in Table 1.Levi (1978) proposes that complex nominals ?a general concept grouping together nominal com-pounds (e.g., peanut butter), nominalizations (e.g.,dream analysis) and non-predicative noun phrases(e.g., electric shock) ?
are derived through the com-plementary processes of recoverable predicate dele-tion and nominalization; each process is associatedwith its own inventory of semantic categories.
Table1 lists the categories for the former.Warren (1978) posits a hierarchical classifica-tion scheme derived from a large-scale corpus studyof NCs.
The top-level relations in her hierar-chy are listed in Table 1, while the next levelsubdivides CONSTITUTE into SOURCE-RESULT,RESULT-SOURCE and COPULA; COPULA is thenfurther subdivided at two additional levels.In computational linguistics, popular invento-ries of semantic relations have been proposed byNastase and Szpakowicz (2003) and Girju et al(2005), among others.
The former groups 30 fine-grained relations into five coarse-grained super-categories, while the latter is a flat list of 21 re-lations.
Both schemes are intended to be suit-able for broad-coverage analysis of text.
For spe-cialized applications, however, it is often usefulto use domain-specific relations.
For example,Rosario and Hearst (2001) propose 18 abstract rela-tions for interpreting NCs in biomedical text, e.g.,DEFECT, MATERIAL, PERSON AFFILIATED,ATTRIBUTE OF CLINICAL STUDY.Inventory-based analyses offer significant advan-tages.
Abstract relations such as ?location?
and ?pos-session?
capture valuable generalizations about NCsemantics in a parsimonious framework.
Unlikeparaphrase-based analyses (Section 2.2), they arenot tied to specific lexical items, which may them-selves be semantically ambiguous.
They also lendthemselves particularly well to automatic interpreta-tion methods based on multi-class classification.On the other hand, relation inventories have beencriticized on a number of fronts, most influentiallyby Downing (1977).
She argues that the great vari-ety of NC relations makes listing them all impos-sible; creative NCs like plate length (?what yourhair is when it drags in your food?)
are intuitivelycompositional, but cannot be assigned to any stan-dard inventory category.
A second criticism is thatrestricted inventories are too impoverished a repre-sentation scheme for NC semantics, e.g., headachepills and sleeping pills would both be analyzed asFOR in Levi?s classification, but express very differ-ent (indeed, contrary) relationships.
Downing writes(p. 826): ?These interpretations are at best reducibleto underlying relationships.
.
.
, but only with the lossof much of the semantic material considered by sub-jects to be relevant or essential to the definitions.
?A further drawback associated with sets of abstractrelations is that it is difficult to identify the ?correct?inventory or to decide whether one proposed classi-fication scheme should be favored over another.2.2 Interpretation Using Verbal ParaphrasesAn alternative approach to NC interpretation asso-ciates each compound with an explanatory para-101Author(s) Relation InventoryLevi (1978) CAUSE, HAVE, MAKE, USE, BE, IN, FOR, FROM, ABOUTWarren (1978) POSSESSION, LOCATION, PURPOSE, ACTIVITY-ACTOR, RESEMBLANCE, CONSTITUTENastase and CAUSALITY (cause, effect, detraction, purpose),Szpakowicz PARTICIPANT (agent, beneficiary, instrument, object property,(2003) object, part, possessor, property, product, source, whole, stative),QUALITY (container, content, equative, material, measure, topic, type),SPATIAL (direction, location at, location from, location),TEMPORALITY (frequency, time at, time through)Girju et al (2005) POSSESSION, ATTRIBUTE-HOLDER, AGENT, TEMPORAL, PART-WHOLE, IS-A, CAUSE,MAKE/PRODUCE, INSTRUMENT, LOCATION/SPACE, PURPOSE, SOURCE, TOPIC, MANNER,MEANS, THEME, ACCOMPANIMENT, EXPERIENCER, RECIPIENT, MEASURE, RESULTLauer (1995) OF, FOR, IN, AT, ON, FROM, WITH, ABOUTTable 1: Previously proposed inventories of semantic relations for noun compound interpretation.
The first two comefrom linguistic theories; the rest have been proposed in computational linguistics.phrase.
Thus, cheese knife and kitchen knife can beexpanded as a knife for cutting cheese and a knifeused in a kitchen, respectively.
In the paraphrase-based paradigm, semantic relations need not comefrom a small set; it is possible to have many sub-tle distinctions afforded by the vocabulary of theparaphrasing language (in our case, English).
Thisparadigm avoids the problems of coverage and rep-resentational poverty, which Downing (1977) ob-served in inventory-based approaches.
It also re-flects cognitive-linguistic theories of NC semantics,in which compounds are held to express underlyingevent frames and whose constituents are held to de-note event participants (Ryder, 1994).Lauer (1995) associates NC semantics withprepositional paraphrases.
As Lauer only consid-ers a handful of prepositions (about, at, for,from, in, of, on, with), his model is es-sentially inventory-based.
On the other hand, noun-preposition co-occurrences can easily be identifiedin a corpus, so an automatic interpretation can beimplemented through simple unsupervised methods.The disadvantage of this approach is the absence of aone-to-one mapping from prepositions to meanings;prepositions can be ambiguous (of indicates manydifferent relations) or synonymous (at, in and onall express ?location?).
This concern arises with allparaphrasing models, but it is exacerbated by the re-stricted nature of prepositions.
Furthermore, manyNCs cannot be paraphrased adequately with prepo-sitions, e.g., woman driver, honey bee.A richer, more flexible paraphrasing model is af-forded by the use of verbs.
In such a model, a honeybee is a bee that produces honey, a sleeping pillis a pill that induces sleeping and a headache pillis a pill that relieves headaches.
In some previouscomputational work on NC interpretation, manuallyconstructed dictionaries provided typical activitiesor functions associated with nouns (Finin, 1980; Is-abelle, 1984; Johnston and Busa, 1996).
It is, how-ever, impractical to build large structured lexiconsfor broad-coverage systems; these methods can onlybe applied to specialized domains.
On the otherhand, we expect that the ready availability of largetext corpora should facilitate the automatic miningof rich paraphrase information.The SemEval-2010 task we present here builds onthe work of Nakov (Nakov and Hearst, 2006; Nakov,2007; Nakov, 2008b), where NCs are paraphrasedby combinations of verbs and prepositions.
Giventhe problem of synonymy, we do not provide a sin-gle correct paraphrase for a given NC but a prob-ability distribution over a range of candidates.
Forexample, highly probable paraphrases for chocolatebar are bar made of chocolate and bar that tasteslike chocolate, while bar that eats chocolate is veryunlikely.
As described in Section 3.3, a set of gold-standard paraphrase distributions can be constructedby collating responses from a large number of hu-man subjects.In this framework, the task of interpretation be-comes one of identifying the most likely paraphrasesfor an NC.
Nakov (2008b) and Butnariu and Veale(2008) have demonstrated that paraphrasing infor-mation can be collected from corpora in an un-supervised fashion; we expect that participants in102SemEval-2010 Task 9 will further develop suitabletechniques for this problem.
Paraphrases of this kindhave been shown to be useful in applications such asmachine translation (Nakov, 2008a) and as an inter-mediate step in inventory-based classification of ab-stract relations (Kim and Baldwin, 2006; Nakov andHearst, 2008).
Progress in paraphrasing is thereforelikely to have follow-on benefits in many areas.3 Task DescriptionThe description of the task we present below is pre-liminary.
We invite the interested reader to visit theofficial Website of SemEval-2010 Task 9, where up-to-date information will be published; there is also adiscussion group and a mailing list.23.1 Preliminary StudyIn a preliminary study, we asked 25-30 human sub-jects to paraphrase 250 noun-noun compounds us-ing suitable paraphrasing verbs.
This is the Levi-250 dataset (Levi, 1978); see (Nakov, 2008b) for de-tails.3 The most popular paraphrases tend to be quiteapt, while some less frequent choices are question-able.
For example, for chocolate bar we obtainedthe following paraphrases (the number of subjectswho proposed each one is shown in parentheses):contain (17); be made of (16); be madefrom (10); taste like (7); be composedof (7); consist of (5); be (3); have (2);smell of (2); be manufactured from (2);be formed from (2); melt into (2); serve(1); sell (1); incorporate (1); be made with(1); be comprised of (1); be constitutedby (1); be solidified from (1); be flavoredwith (1); store (1); be flavored with (1); becreated from (1); taste of (1)3.2 ObjectiveWe propose a task in which participating systemsmust estimate the quality of paraphrases for a testset of NCs.
A list of verb/preposition paraphraseswill be provided for each NC, and for each list aparticipating system will be asked to provide aptness2Please follow the Task #9 link at the SemEval-2010 home-page http://semeval2.fbk.eu3This dataset is available from http://sourceforge.net/projects/multiword/scores that correlate well (in terms of frequency dis-tribution) with the human judgments collated fromour test subjects.3.3 DatasetsTrial/Development Data.
As trial/developmentdata, we will release the previously collected para-phrase sets for the Levi-250 dataset (after furtherreview and cleaning).
This dataset consists of 250noun-noun compounds, each paraphrased by 25-30human subjects (Nakov, 2008b).Test Data.
The test data will consist of approx-imately 300 NCs, each accompanied by a set ofparaphrasing verbs and prepositions.
Following themethodology of Nakov (2008b), we will use theAmazon Mechanical Turk Web service4 to recruithuman subjects.
This service offers an inexpensiveway to recruit subjects for tasks that require humanintelligence, and provides an API which allows acomputer program to easily run tasks and collatethe responses from human subjects.
The MechanicalTurk is becoming a popular means to elicit and col-lect linguistic intuitions for NLP research; see Snowet al (2008) for an overview and a discussion of is-sues that arise.We intend to recruit 100 annotators for each NC,and we will require each annotator to paraphraseat least five NCs.
Annotators will be given clearinstructions and will be asked to produce one ormore paraphrases for a given NC.
To help us filterout subjects with an insufficient grasp of English oran insufficient interest in the task, annotators willbe asked to complete a short and simple multiple-choice pretest on NC comprehension before pro-ceeding to the paraphrasing step.Post-processing.
We will manually check thetrial/development data and the test data.
Dependingon the quality of the paraphrases, we may decide todrop the least frequent verbs.License.
All data will be released under the Cre-ative Commons Attribution 3.0 Unported license5.3.4 EvaluationSingle-NC Scores.
For each NC, we will comparehuman scores (our gold standard) with those pro-posed by each participating system.
We have con-4http://www.mturk.com5http://creativecommons.org/licenses/by/3.0/103sidered three scores: (1) Pearson?s correlation, (2)cosine similarity, and (3) Spearman?s rank correla-tion.Pearson?s correlation coefficient is a standardmeasure of the correlation strength between two dis-tributions; it can be calculated as follows:?
= E(XY ) ?
E(X)E(Y )?E(X2) ?
[E(X)]2?E(Y 2) ?
[E(Y )]2(1)where X = (x1, .
.
.
, xn) and Y = (y1, .
.
.
, yn) arevectors of numerical scores for each paraphrase pro-vided by the humans and the competing systems, re-spectively, n is the number of paraphrases to score,and E(X) is the expectation of X .Cosine correlation coefficient is another popu-lar alternative and was used by Nakov and Hearst(2008); it can be seen as an uncentered version ofPearson?s correlation coefficient:?
= X.Y?X?
?Y ?
(2)Spearman?s rank correlation coefficient is suit-able for comparing rankings of sets of items; it isa special case of Pearson?s correlation, derived byconsidering rank indices (1,2,. .
. )
as item scores .
Itis defined as follows:?
= n?xiyi ?
(?xi)(?
yi)?n?x2i ?
(?xi)2?n?
y2i ?
(?
yi)2(3)One problem with using Spearman?s rank coef-ficient for the current task is the assumption thatswapping any two ranks has the same effect.
Theoften-skewed nature of paraphrase frequency distri-butions means that swapping some ranks is intu-itively less ?wrong?
than swapping others.
Consider,for example, the following list of human-proposedparaphrasing verbs for child actor, which is given inNakov (2007):be (22); look like (4); portray (3); start as(1); include (1); play (1); have (1); involve(1); act like (1); star as (1); work as (1);mimic (1); pass as (1); resemble (1); beclassified as (1); substitute for (1); qualifyas (1); act as (1)Clearly, a system that swaps the positions forbe (22) and look like (4) for child actor willhave made a significant error, while swapping con-tain (17) and be made of (16) for chocolate bar (seeSection 3.1) would be less inappropriate.
However,Spearman?s coefficient treats both alterations iden-tically since it only looks at ranks; thus, we do notplan to use it for official evaluation, though it maybe useful for post-hoc analysis.Final Score.
A participating system?s final scorewill be the average of the scores it achieves over alltest examples.Scoring Tool.
We will provide an automatic eval-uation tool that participants can use when train-ing/tuning/testing their systems.
We will use thesame tool for the official evaluation.4 ConclusionWe have presented a noun compound paraphrasingtask that will run as part of SemEval-2010.
The goalof the task is to promote and explore the feasibilityof paraphrase-based methods for compound inter-pretation.
We believe paraphrasing holds some keyadvantages over more traditional inventory-basedapproaches, such as the ability of paraphrases to rep-resent fine-grained and overlapping meanings, andthe utility of the resulting paraphrases for other ap-plications such as Question Answering, InformationExtraction/Retrieval and Machine Translation.The proposed paraphrasing task is predicated ontwo important assumptions: first, that paraphrasingvia a combination of verbs and prepositions pro-vides a powerful framework for representing and in-terpreting the meaning of compositional nonlexical-ized noun compounds; and second, that humans canagree amongst themselves about what constitutes agood paraphrase for any given NC.
As researchers inthis area and as proponents of this task, we believethat both assumptions are valid, but if the analysisof the task were to raise doubts about either assump-tion (e.g., by showing poor agreement amongst hu-man annotators), then this in itself would be a mean-ingful and successful output of the task.
As such,we anticipate that the task and its associated datasetwill inspire further research, both on the theory anddevelopment of paraphrase-based compound inter-pretation and on its practical applications.104ReferencesTimothy Baldwin and Takaaki Tanaka.
2004.
Transla-tion by machine of compound nominals: Getting itright.
In Proceedings of the ACL 2004 Workshop onMultiword Expressions: Integrating Processing, pages24?31.Cristina Butnariu and Tony Veale.
2008.
A concept-centered approach to noun-compound interpretation.In Proceedings of the 22nd International Conferenceon Computational Linguistics (COLING 2008), pages81?88.Pamela Downing.
1977.
On the creation and use of En-glish compound nouns.
Language, 53(4):810?842.Timothy Finin.
1980.
The Semantic Interpretation ofCompound Nominals.
Ph.D. Dissertation, Universityof Illinois, Urbana, Illinois.Roxana Girju, Dan Moldovan, Marta Tatu, and DanielAntohe.
2005.
On the semantics of noun compounds.Journal of Computer Speech and Language - SpecialIssue on Multiword Expressions, 4(19):479?496.Roxana Girju.
2007.
Improving the interpretation ofnoun phrases with cross-linguistic information.
InProceedings of the 45th Annual Meeting of the Associ-ation of Computational Linguistics (ACL 2007), pages568?575.Pierre Isabelle.
1984.
Another look at nominal com-pounds.
In Proceedings of the 10th International Con-ference on Computational Linguistics, pages 509?516.Michael Johnston and Frederica Busa.
1996.
Qualiastructure and the compositional interpretation of com-pounds.
In Proceedings of the ACL 1996 Workshop onBreadth and Depth of Semantic Lexicons, pages 77?88.Su Nam Kim and Timothy Baldwin.
2006.
Interpret-ing semantic relations in noun compounds via verbsemantics.
In Proceedings of the 45th Annual Meet-ing of the Association of Computational Linguistics(COLING/ACL 2006) Main Conference Poster Ses-sions, pages 491?498.Mirella Lapata and Alex Lascarides.
2003.
Detectingnovel compounds: the role of distributional evidence.In Proceedings of the 10th conference of the Europeanchapter of the Association for Computational Linguis-tics (EACL 2003), pages 235?242.Mark Lauer.
1995.
Designing Statistical LanguageLearners: Experiments on Noun Compounds.
Ph.D.thesis, Dept.
of Computing, Macquarie University,Australia.Judith Levi.
1978.
The Syntax and Semantics of ComplexNominals.
Academic Press, New York.Preslav Nakov andMarti A. Hearst.
2006.
Using verbs tocharacterize noun-noun relations.
In LNCS vol.
4183:Proceedings of the 12th international conference onArtificial Intelligence: Methodology, Systems and Ap-plications (AIMSA 2006), pages 233?244.
Springer.Preslav Nakov and Marti A. Hearst.
2008.
Solving re-lational similarity problems using the web as a cor-pus.
In Proceedings of the 46th Annual Meeting of theAssociation of Computational Linguistics (ACL 2008),pages 452?460.Preslav Nakov.
2007.
Using the Web as an ImplicitTraining Set: Application to Noun Compound Syntaxand Semantics.
Ph.D. thesis, EECS Department, Uni-versity of California, Berkeley, UCB/EECS-2007-173.Preslav Nakov.
2008a.
Improved statistical machinetranslation using monolingual paraphrases.
In Pro-ceedings of the 18th European Conference on ArtificialIntelligence (ECAI?2008), pages 338?342.Preslav Nakov.
2008b.
Noun compound interpretationusing paraphrasing verbs: Feasibility study.
In LNAIvol.
5253: Proceedings of the 13th international con-ference on Artificial Intelligence: Methodology, Sys-tems and Applications (AIMSA 2008), pages 103?117.Springer.Vivi Nastase and Stan Szpakowicz.
2003.
Exploringnoun-modifier semantic relations.
In Proceedings ofthe 5th International Workshop on Computational Se-mantics, pages 285?301.Diarmuid O?
Se?aghdha and Ann Copestake.
2007.
Co-occurrence contexts for noun compound interpreta-tion.
In Proceedings of the Workshop on A BroaderPerspective on Multiword Expressions, pages 57?64.Diarmuid O?
Se?aghdha.
2008.
Learning Compound NounSemantics.
Ph.D. thesis, University of Cambridge.Barbara Rosario and Marti Hearst.
2001.
Classify-ing the semantic relations in noun compounds via adomain-specific lexical hierarchy.
In Proceedings ofthe 2001 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP 2005), pages 82?90.Mary Ellen Ryder.
1994.
Ordered Chaos: The Interpre-tation of English Noun-Noun Compounds.
Universityof California Press, Berkeley, CA.Rion Snow, Brendan O?Connor, Daniel Jurafsky, and An-drew Ng.
2008.
Cheap and fast ?
but is it good?evaluating non-expert annotations for natural languagetasks.
In Proceedings of the 2008 Conference onEmpirical Methods in Natural Language Processing(EMNLP 2008), pages 254?263.Takaaki Tanaka and Timothy Baldwin.
2003.
Noun-noun compound machine translation: a feasibilitystudy on shallow processing.
In Proceedings of theACL 2003 workshop on Multiword expressions, pages17?24.Beatrice Warren.
1978.
Semantic patterns of noun-nouncompounds.
In Gothenburg Studies in English 41,Goteburg, Acta Universtatis Gothoburgensis.105
