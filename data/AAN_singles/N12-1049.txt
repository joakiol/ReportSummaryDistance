2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 446?455,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsParsing Time: Learning to Interpret Time ExpressionsGabor AngeliStanford UniversityStanford, CA 94305angeli@stanford.eduChristopher D. ManningStanford UniversityStanford, CA 94305manning@stanford.eduDaniel JurafskyStanford UniversityStanford, CA 94305jurafsky@stanford.eduAbstractWe present a probabilistic approach for learn-ing to interpret temporal phrases given only acorpus of utterances and the times they ref-erence.
While most approaches to the taskhave used regular expressions and similar lin-ear pattern interpretation rules, the possibil-ity of phrasal embedding and modification intime expressions motivates our use of a com-positional grammar of time expressions.
Thisgrammar is used to construct a latent parsewhich evaluates to the time the phrase wouldrepresent, as a logical parse might evaluate toa concrete entity.
In this way, we can employa loosely supervised EM-style bootstrappingapproach to learn these latent parses whilecapturing both syntactic uncertainty and prag-matic ambiguity in a probabilistic framework.We achieve an accuracy of 72% on an adaptedTempEval-2 task ?
comparable to state of theart systems.1 IntroductionTemporal resolution is the task of mapping froma textual phrase describing a potentially complextime, date, or duration to a normalized (grounded)temporal representation.
For example, possiblycomplex phrases such as the week before last areoften more useful in their grounded form ?
e.g.,January 1 - January 7.The dominant approach to this problem in previ-ous work has been to use rule-based methods, gen-erally a combination of regular-expression matchingfollowed by hand-written interpretation functions.In general, it is appealing to learn the interpre-tation of temporal expressions, rather than hand-building systems.
Moreover, complex hierarchicaltemporal expressions, such as the Tuesday beforelast or the third Wednesday of each month, and am-biguous expressions, such as last Friday, are diffi-cult to handle using deterministic rules and wouldbenefit from a recursive and probabilistic phrasestructure representation.
Therefore, we attempt tolearn a temporal interpretation system where tempo-ral phrases are parsed by a grammar, but this gram-mar and its semantic interpretation rules are latent,with only the input phrase and its grounded interpre-tation given to the learning system.Employing probabilistic techniques allows us tocapture ambiguity in temporal phrases in two impor-tant respects.
In part, it captures syntactic ambigu-ity ?
e.g., last Friday the 13th bracketing as either[last Friday] [the 13th], or last [Friday the 13th].This also includes examples of lexical ambiguity ?e.g., two meanings of last in last week of Novemberversus last week.
In addition, temporal expressionsoften carry a pragmatic ambiguity.
For instance, aspeaker may refer to either the next or previous Fri-day when he utters Friday on a Sunday.
Similarly,next week can refer to either the coming week or theweek thereafter.Probabilistic systems furthermore allow propaga-tion of uncertainty to higher-level components ?
forexample recognizing that May could have a num-ber of non-temporal meanings and allowing a sys-tem with a broader contextual scope to make the fi-nal judgment.
We implement a CRF to detect tem-poral expressions, and show our model?s ability toact as a component in such a system.We describe our temporal representation, fol-lowed by the learning algorithm; we conclude withexperimental results showing our approach to becompetitive with state of the art systems.4462 Related WorkOur approach draws inspiration from a large body ofwork on parsing expressions into a logical form.
Thelatent parse parallels the formal semantics in previ-ous work, e.g., Montague semantics.
Like these rep-resentations, a parse ?
in conjunction with the refer-ence time ?
defines a set of matching entities, in thiscase the grounded time.
The matching times can bethought of as analogous to the entities in a logicalmodel which satisfy a given expression.Supervised approaches to logical parsing promi-nently include Zelle and Mooney (1996), Zettle-moyer and Collins (2005), Kate et al (2005), Zettle-moyer and Collins (2007), inter alia.
For exam-ple, Zettlemoyer and Collins (2007) learn a mappingfrom textual queries to a logical form.
This logicalform importantly contains all the predicates and en-tities used in their parse.
We loosen the supervisionrequired in these systems by allowing the parse to beentirely latent; the annotation of the grounded timeneither defines, nor gives any direct cues about theelements of the parse, since many parses evaluate tothe same grounding.
To demonstrate, the groundingfor a week ago could be described by specifying amonth and day, or as a week ago, or as last x ?
sub-stituting today?s day of the week for x.
Each of thesecorrespond to a completely different parse.Recent work by Clarke et al (2010) and Liang etal.
(2011) similarly relax supervision to require onlyannotated answers rather than full logical forms.
Forexample, Liang et al (2011) constructs a latent parsesimilar in structure to a dependency grammar, butrepresenting a logical form.
Our proposed lexi-cal entries and grammar combination rules can bethought of as paralleling the lexical entries and pred-icates, and the implicit combination rules respec-tively in this framework.
Rather than querying froma finite database, however, our system must com-pare temporal expression within an infinite timeline.Furthermore, our system is run using neither lexicalcues nor intelligent initialization.Related work on interpreting temporal expres-sions has focused on constructing hand-crafted in-terpretation rules (Mani and Wilson, 2000; Saqueteet al, 2003; Puscasu, 2004; Grover et al, 2010).
Ofthese, HeidelTime (Stro?tgen and Gertz, 2010) andSUTime (Chang and Manning, 2012) provide par-ticularly strong competition.Recent probabilistic approaches to temporal reso-lution include UzZaman and Allen (2010), who em-ploy a parser to produce deep logical forms, in con-junction with a CRF classifier.
In a similar vein,Kolomiyets and Moens (2010) employ a maximumentropy classifier to detect the location and temporaltype of expressions; the grounding is then done viadeterministic rules.3 RepresentationWe define a compositional representation of time;a type system is described in Section 3.1 while thegrammar is outlined in Section 3.2 and described indetail in Sections 3.3 and 3.4.3.1 Temporal Expression TypesWe represent temporal expressions as either aRange, Sequence, or Duration.
We describe these,the Function type, and the miscellaneous Numberand Nil types below:Range [and Instant] A period between two dates(or times).
This includes entities such as Today,1987, or Now.
We denote a range by the variabler.
We maintain a consistent interval-based theory oftime (Allen, 1981) and represent instants as intervalswith zero span.Sequence A sequence of Ranges, not necessarilyoccurring at regular intervals.
This includes enti-ties such as Friday, November 27th, or lastFriday.
A Sequence is a tuple of three elementss = (rs,?s, ?s):1. rs(i): The ith element of a sequence, of typeRange.
In the case of the sequence Friday,rs(0) corresponds to the Friday in the currentweek; rs(1) is the Friday in the following week,etc.2.
?s: The distance between two elements in thesequence ?
approximated if this distance is notconstant.
In the case of Friday, this distancewould be a week.3.
?s: The containing unit of an element of a se-quence.
For example, ?Friday would be theRange corresponding to the current week.
Thesequence index i ?
Z, from rs(i), is defined447relative to rs(0) ?
the element in the same con-taining unit as the reference time.We define the reference time t (Reichenbach,1947) to be the instant relative to which times areevaluated.
For the TempEval-2 corpus, we approxi-mate this as the publication time of the article.
Whilethis is conflating Reichenbach?s reference time withspeech time, it is a useful approximation.To contrast with Ranges, a Sequence can rep-resent a number of grounded times.
Nonetheless,pragmatically, not all of these are given equal weight?
an utterance of last Friday may mean either of theprevious two Fridays, but is unlikely to ground toanything else.
We represent this ambiguity by defin-ing a distribution over the elements of the Sequence.While this could be any distribution, we chose to ap-proximate it as a Gaussian.In order to allow sharing parameters between anysequence, we define the domain in terms of the indexof the sequence rather than of a constant unit of time(e.g., seconds).
To illustrate, the distribution overApril would have a much larger variance than thedistribution over Sunday, were the domains fixed.The probability of the ith element of a sequence thusdepends on the beginning of the range rs(i), the ref-erence time t, and the distance between elements ofthe sequence ?s.
We summarize this in the equationbelow, with learned parameters ?
and ?
:Pt(i) =?
0.5?=?0.5N?,?(rs(i)?
t?s+ ?
)(1)Figure 1 shows an example of such a distribution;importantly, note that moving the reference time be-tween two elements dynamically changes the prob-ability assigned to each.Duration A period of time.
This includes entitieslike Week, Month, and 7 days.
We denote a du-ration with the variable d.We define a special case of the Duration type torepresent approximate durations, identified by theircanonical unit (week, month, etc).
These are usedto represent expressions such as a few years or somedays.Function A function of arity less than or equal totwo representing some general modification to one-211/13-111/20-0.3t?s112/4212/11Reference timeP (11/20) = ?
?0.5?1.5 f(x)011/27ffffFigure 1: An illustration of a temporal distribution, e.g.,Sunday.
The reference time is labeled as time t betweenNov 20 and Nov 27; the probability that this sequenceis referring to Nov 20 is the integral of the marked area.The domain of the graph are the indices of the sequence;the distribution is overlaid with mean at the (normalized)reference time t/?s; in our case ?s is a week.
Notethat the probability of an index changes depending on theexact location of the reference time.of the above types.
This captures semantic entitiessuch as those implied in last x, the third x [of y],or x days ago.
The particular functions and theirapplication are enumerated in Table 2.Other Types Two other types bear auxiliary rolesin representing temporal expressions, though theyare not directly temporal concepts.
In the grammar,these appear as preterminals only.The first of these types is Number ?
denotinga number without any temporal meaning attached.This comes into play representing expressions suchas 2 weeks.
The other is the Nil type ?
denotingterms which are not directly contributing to the se-mantic meaning of the expression.
This is intendedfor words such as a or the, which serve as cues with-out bearing temporal content themselves.
The Niltype is lexicalized with the word it generates.Omitted Phenomena The representation de-scribed is a simplification of the complexities oftime.
Notably, a body of work has focused onreasoning about events or states relative to temporalexpressions.
Moens and Steedman (1988) describestemporal expressions relating to changes of state;Condoravdi (2010) explores NPI licensing intemporal expressions.
Broader context is also not448Rangef(Duration) : RangecatRightnextDurationNumberNumn?1002DurationDaydays(a)catRight(t, 2D )catRight(t,?
)next2DNum(2)21Ddays(b)Figure 2: The grammar ?
(a) describes the CFG parse ofthe temporal types.
Words are tagged with their nontermi-nal entry, above which only the types of the expressionsare maintained; (b) describes the corresponding combi-nation of the temporal instances.
The parse in (b) is de-terministic given the grammar combination rules in (a).directly modeled, but rather left to systems in whichthe model would be embedded.
Furthermore, vaguetimes (e.g., in the 90?s) represent a notable chunkof temporal expressions uttered.
In contrast, NLPevaluations have generally not handled such vaguetime expressions.3.2 Grammar FormalismOur approach builds on the assumption that naturallanguage descriptions of time are compositional innature.
Each word attached to a temporal phrase isusually compositionally modifying the meaning ofthe phrase.
To demonstrate, we consider the expres-sion the week before last week.
We can construct ameaning by applying the modifier last to week ?
cre-ating the previous week; and then applying before toweek and last week.We construct a paradigm for parsing temporalphrases consisting of a standard PCFG over tempo-ral types with each parse rule defining a function toapply to the child nodes, or the word being gener-ated.
At the root of the tree, we recursively applythe functions in the parse tree to obtain a final tem-poral value.
One can view this formalism as a rule-to-rule translation (Bach, 1976; Allen, 1995, p. 263),or a constrained Synchronous PCFG (Yamada andKnight, 2001).Our approach contrasts with common approaches,such as CCG grammars (Steedman, 2000; Bos etal., 2004; Kwiatkowski et al, 2011), giving us moreflexibility in the composition rules.
Figure 2 showsan example of the grammar.Formally, we define our temporal grammarG = (?, S,V,W,R, ?).
The alphabet ?
and startsymbol S retain their usual interpretations.
We de-fine a set V to be the set of types, as described inSection 3.1 ?
these act as our nonterminals.
For eachv ?
V we define an (infinite) set Wv correspondingto the possible instances of type v. Concretely, ifv = Sequence, our set Wv ?
W could contain el-ements corresponding to Friday, last Friday, Nov.27th, etc.
Each node in the tree defines a pair (v, w)such that w ?
Wv, with combination rules definedover v and function applications performed on w.A rule R ?
R is defined as a pairR =(vi ?
vjvk, f : (Wvj ,Wvk)?Wvi).
Thefirst term is our conventional PCFG rule over thetypes V .
The second term defines the function toapply to the values returned recursively by the childnodes.
Note that this definition is trivially adaptedfor the case of unary rules.The last term in our grammar formalism denotesthe rule probabilities ?.
In line with the usual in-terpretation, this defines a probability of applying aparticular rule r ?
R. Importantly, note that thedistribution over possible groundings of a temporalexpression are not included in the grammar formal-ism.
The learning of these probabilities is detailedin Section 4.3.3 PreterminalsWe define a set of preterminals, specifying theireventual type, as well as the temporal instance it pro-duces when its function is evaluated on the word itgenerates (e.g., f(day) = Day).
A distinction ismade in our description between entities with con-tent roles versus entities with a functional role.The first ?
consisting of Ranges, Sequences, andDurations ?
are listed in Table 1.
A total of 62 suchpreterminals are defined in the implemented system,corresponding to primitive entities often appearingin newswire, although this list is easily adaptable to449Function Description Signature(s)shiftLeft Shift a Range or Sequence left by a Duration f : S,D?
S; f : R,D?
RshiftRight Shift a Range or Sequence right by a Duration f : S,D?
S; f : R,D?
RshrinkBegin Take the first Duration of a Range/Sequence f : S,D?
S; f : R,D?
RshrinkEnd Take the last Duration of a Range/Sequence f : S,D?
S; f : R,D?
RcatLeft Take Duration units after the end of a Range f : R,D?
RcatRight Take Duration units before the start of a Range f : R,D?
RmoveLeft1 Move the origin of a sequence left by 1 f : S?
SmoveRight1 Move the origin of a sequence right by 1 f : S?
Snth x of y Take the nth Sequence in y (Day of Week, etc) f : Number?
Sapproximate Make a Duration approximate f : D?
DTable 2: The functional preterminals of the grammar; R, S, and D denote Ranges Sequences and Durations respec-tively.
The name, a brief description, and the type signature of the function (as used in parsing) are given.
Describedin more detail in Section 3.4, the functions are most easily interpreted as operations on either an interval or sequence.Type InstancesRange Past, Future, Yesterday,Tomorrow, Today, Reference,Year(n), Century(n)Sequence Friday, January, .
.
.DayOfMonth, DayOfWeek, .
.
.EveryDay, EveryWeek, .
.
.Duration Second, Minute, Hour,Day, Week, Month, Quarter,Year, Decade, CenturyTable 1: The content-bearing preterminals of the gram-mar, arranged by their types.
Note that the Sequencetype contains more elements than enumerated here; how-ever, only a few of each characteristic type are shown herefor brevity.fit other domains.
It should be noted that the expres-sions, represented in Typewriter, have no a pri-ori association with words, denoted by italics; thiscorrespondence must be learned.
Furthermore, enti-ties which are subject to interpretation ?
for exampleQuarter or Season ?
are given a concrete inter-pretation.
The nth quarter is defined by evenly split-ting a year into four; the seasons are defined in thesame way but with winter beginning in December.The functional entities are described in Table 2,and correspond to the Function type.
The majorityof these mirror generic operations on intervals on atimeline, or manipulations of a sequence.
Notably,like intervals, times can be moved (3 weeks ago) ortheir size changed (the first two days of the month),or a new interval can be started from one of the end-points (the last 2 days).
Additionally, a sequence canbe modified by shifting its origin (last Friday), ortaking the nth element of the sequence within somebound (fourth Sunday in November).The lexical entry for the Nil type is tagged with theword it generates, producing entries such as Nil(a),Nil(November), etc.
The lexical entry for the Num-ber type is parameterized by the order of magnitudeand ordinality of the number; e.g., 27th becomesNumber(101,ordinal).3.4 Combination RulesAs mentioned earlier, our grammar defines bothcombination rules over types (in V) as well as amethod for combining temporal instances (in Wv ?W).
This method is either a function application ofone of the functions in Table 2, a function which isimplicit in the text (intersection and multiplication),or an identity operation (for Nils).
These cases aredetailed below:?
Function application, e.g., last week.
We apply(or partially apply) a function to an argumenton either the left or the right: f(x, y)x or xf(x, y).
Furthermore, for functions of arity 2taking a Range as an argument, we define a ruletreating it as a unary function with the referencetime taking the place of the second argument.?
Intersecting two ranges or sequences, e.g.,450Input (w,t) ( Last Friday the 13 th , May 16 2011 )LatentparseRmoveLeft1( FRI ) ?
13thmoveLeft1( FRI )moveLeft1(?
)lastFRIfriday13thNilthethe13th13thOutput ??
May 13 2011Figure 3: An overview of the system architecture.
Notethat the parse is latent ?
that is, it is not annotated in thetraining data.November 27th.
The intersect function treatsboth arguments as intervals, and will return aninterval (Range or Sequence) corresponding tothe overlap between the two.1?
Multiplying a Number with a Duration, e.g., 5weeks.?
Combining a non-Nil and Nil element with nochange to the temporal expression, e.g., a week.The lexicalization of the Nil type allows thealgorithm to take hints from these supportingwords.We proceed to describe learning the parameters ofthis grammar.4 LearningWe present a system architecture, described in Fig-ure 3.
We detail the inference procedure in Sec-tion 4.1 and training in Section 4.2.4.1 InferenceTo provide a list of candidate expressions with theirassociated probabilities, we employ a k-best CKYparser.
Specifically, we implement Algorithm 3 de-scribed in Huang and Chiang (2005), providing anO(Gn3k log k) algorithm with respect to the gram-mar size G, phrase length n, and beam size k. Weset the beam size to 2000.1In the case of complex sequences (e.g., Friday the 13th) anA?
search is performed to find overlapping ranges in the twosequences; the origin rs(0) is updated to refer to the closestsuch match to the reference time.Revisiting the notion of pragmatic ambiguity, ina sense the most semantically complete output ofthe system would be a distribution ?
an utterance ofFriday would give a distribution over Fridays ratherthan a best guess of its grounding.
However, it is of-ten advantageous to ground to a concrete expressionwith a corresponding probability.
The CKY k-bestbeam and the temporal distribution ?
capturing syn-tactic and pragmatic ambiguity ?
can be combined toprovide a Viterbi decoding, as well as its associatedprobability.We define the probability of a syntactic parsey making use of rules R ?
R as P (y) =P (w1, .
.
.
wn;R) =?i?j,k?R P (j, k | i).
As de-scribed in Section 3.1, we define the probability ofa grounding relative to reference time t and a par-ticular syntactic interpretation Pt(i|y).
The prod-uct of these two terms provides the probability ofa grounded temporal interpretation; we can obtain aViterbi decoding by maximizing this joint probabil-ity:Pt(i, y) = P (y)?
Pt(i|y) (2)This provides us with a framework for obtaininggrounded times from a temporal phrase ?
in line withthe annotations provided during training time.4.2 TrainingWe present an EM-style bootstrapping approach totraining the parameters of our grammar jointly withthe parameters of our Gaussian temporal distribu-tion.Our TimEM algorithm for learning the parame-ters for the grammar (?
), jointly with the temporaldistribution (?
and ?)
is given in Algorithm 1.
Theinputs to the algorithm are the initial parameters ?,?, and ?, and a set of training instances D. Further-more, the algorithm makes use of a Dirichlet prior ?on the grammar parameters ?, as well as a Gaussianprior N on the mean of the temporal distribution ?.The algorithm outputs the final parameters ?
?, ?
?and ?
?.Each training instance is a tuple consisting ofthe words in the temporal phrase w, the annotatedgrounded time ?
?, and the reference time of the ut-terance t. The input phrase is tokenized accordingto Penn Treebank guidelines, except we additionally451Algorithm 1: TimEMInput: Initial parameters ?, ?, ?
; dataD = {(w, ?
?, t)}; Dirichlet prior ?,Gaussian prior NOutput: Optimal parameters ?
?, ?
?, ?
?while not converged do1(M?
?, M??,?)
:= E-Step (D,?,?,?
)2(?, ?, ?)
:= M-Step (M?
?, M??,?
)3end4return (?s, ?, ?
)5begin E-Step(D,?,?,?)6M??
= []; M??,?
= []7for (w, ?
?, t) ?
D do8m??
= []; m??,?
= []9for y ?
k-bestCKY(w, ?)
do10if p = P?,?(??
| y, t) > 0 then11m??
+= (y, p); m??,?
+= (i, p)12end13end14M?
+= normalize(m??)15M??,?
+= normalize(m??,?
)16end17return M?18end19begin M-Step(M??,M??,?)20??
:= bayesianPosterior(M?
?, ?)21??
:= mlePosterior(M??,?)22??
:= bayesianPosterior(M?
?,?, ?
?, N )23return (?
?, ?
?, ??
)24end25split on the characters ?-?
and ?/,?
which often de-limit a boundary between temporal entities.
Beyondthis preprocessing, no language-specific informationabout the meanings of the words are introduced, in-cluding syntactic parses, POS tags, etc.The algorithm operates similarly to the EM algo-rithms used for grammar induction (Klein and Man-ning, 2004; Carroll and Charniak, 1992).
How-ever, unlike grammar induction, we are allowed acertain amount of supervision by requiring that thepredicted temporal expression match the annotation.Our expected statistics are therefore more accuratelyour normalized expected counts of valid parses.Note that in conventional grammar induction, theexpected sufficient statistics can be gathered analyt-ically from reading off the chart scores of a parse.This does not work in our case for two reasons.
Inpart, we would like to incorporate the probabilityof the temporal grounding in our feedback probabil-ity.
Additionally, we are only using parses which arevalid candidates ?
that is, the parses which ground tothe correct time ??
?
which we cannot establish untilthe entire expression is parsed.
The expected statis-tics are thus computed non-analytically via a beamon both the possible parses (line 10) and the pos-sible temporal groundings of a given interpretation(line 11).The particular EM updates are the standard up-dates for multinomial and Gaussian distributionsgiven fully observed data.
In the multinomial case,our (unnormalized) parameter updates, with Dirich-let prior ?, are:?
?mn|l = ?+?(y,p)?M??
?vjk|i?y1(vjk|i = vmn|l)p (3)In the Gaussian case, the parameter update for ?is the maximum likelihood update; while the updatefor ?
incorporates a Bayesian prior N (?0, ?0):??
=????1?(i,p)?M??,?p?(i,p)?M??,?(i?
??
)2 ?
p (4)??
=?
?2?0 + ?20?(i,p)?M??,?
i ?
p?
?2 + ?20?(i,p)?M??,?
p(5)As the parameters improve, the parser more effi-ciently prunes incorrect parses and the beam incor-porates valid parses for longer and longer phrases.For instance, in the first iteration the model mustlearn the meaning of both words in last Friday; oncethe parser learns the meaning of one of them ?
e.g.,Friday appears elsewhere in the corpus ?
subsequentiterations focus on proposing candidate meaningsfor last.
In this way, a progressively larger percent-age of the data is available to be learned from at eachiteration.5 EvaluationWe evaluate our model against current state-of-theart systems for temporal resolution on the English452Train TestSystem Type Value Type ValueGUTime 0.72 0.46 0.80 0.42SUTime 0.85 0.69 0.94 0.71HeidelTime 0.80 0.67 0.85 0.71OurSystem 0.90 0.72 0.88 0.72Table 3: TempEval-2 Attribute scores for our system andthree previous systems.
The scores are calculated us-ing gold extents, forcing a guessed interpretation for eachparse.portion of the TempEval-2 Task A dataset (Verhagenet al, 2010).5.1 DatasetThe TempEval-2 dataset is relatively small, contain-ing 162 documents and 1052 temporal phrases in thetraining set and an additional 20 documents and 156phrases in the evaluation set.
Each temporal phrasewas annotated as a TIMEX32 tag around an adver-bial or prepositional phrase5.2 ResultsIn the TempEval-2 A Task, system performance isevaluated on detection and resolution of expressions.Since we perform only the second of these, we eval-uate our system assuming gold detection.Similarly, the original TempEval-2 scoringscheme gave a precision and recall for detection,and an accuracy for only the temporal expressionsattempted.
Since our system is able to produce aguess for every expression, we produce a precision-recall curve on which competing systems are plotted(see Figure 4).
Note that the downward slope of thecurve indicates that the probabilities returned by thesystem are indicative of its confidence ?
the prob-ability of a parse correlates with the probability ofthat parse being correct.Additionally, and perhaps more accurately, wecompare to previous system scores when con-strained to make a prediction on every example; ifno guess is made, the output is considered incorrect.This in general yields lower results, as the systemis not allowed to abstain on expressions it does not2See http://www.timeml.org for details on theTimeML format and TIMEX3 tag.00.20.40.60.810  0.2  0.4  0.6  0.8  1Value accuracyExtent recallHeidelTime1HeidelTime2SUTimeOurSystemFigure 4: A precision-recall curve for our system, com-pared to prior work.
The data points are obtained by set-ting a threshold minimum probability at which to guessa time creating different extent recall values.
The curvefalls below HeidelTime1 and SUTime in part from lackof context, and in part since our system was not trainedto optimize this curve.recognize.
Results are summarized in Table 3.We compare to three previous rule-based sys-tems.
GUTime (Mani and Wilson, 2000) presents anolder but widely used baseline.3 More recently, SU-Time (Chang and Manning, 2012) provides a muchstronger comparison.
We also compare to Heidel-Time (Stro?tgen and Gertz, 2010), which representsthe state-of-the-art system at the TempEval-2 task.5.3 DetectionOne of the advantages of our model is that it can pro-vide candidate groundings for any expression.
Weexplore this ability by building a detection model tofind candidate temporal expressions, which we thenground.
The detection model is implemented as aConditional Random Field (Lafferty et al, 2001),with features over the morphology and context.
Par-ticularly, we define the following features:?
The word and lemma within 2 of the currentword.?
The word shape4 and part of speech of the cur-rent word.3Due to discrepancies in output formats, the output ofGUTime was heuristically patched and manually checked toconform to the expected format.4Word shape is calculated by mapping each character to oneof uppercase, lowercase, number, or punctuation.
The first fourcharacters are mapped verbatim; subsequent sequences of sim-ilar characters are collapsed.453Extent AttributeSystem P R F1 Typ ValGUTime 0.89 0.79 0.84 0.95 0.68SUTime 0.88 0.96 0.92 0.96 0.82HeidelTime1 0.90 0.82 0.86 0.96 0.85HeidelTime2 0.82 0.91 0.86 0.92 0.77OurSystem 0.89 0.84 0.86 0.91 0.72Table 4: TempEval-2 Extent scores for our system andthree previous systems.
Note that the attribute scores arenow relatively low compared to previous work; unlikerule-based approaches, our model can guess a temporalinterpretation for any phrase, meaning that a good pro-portion of the phrases not detected would have been in-terpreted correctly.?
Whether the current word is a number, alongwith its ordinality and order of magnitude?
Prefixes and suffixes up to length 5, along withtheir word shape.We summarize our results in Table 4, noting thatthe performance indicates that the CRF and interpre-tation model find somewhat different phrases hard todetect and interpret respectively.
Many errors madein detection are attributable to the small size of thetraining corpus (63,000 tokens).5.4 DiscussionOur system performs well above the GUTime base-line and is competitive with both of the more recentsystems.
In part, this is from more sophisticatedmodeling of syntactic ambiguity: e.g., the past fewweeks has a clause the past ?
which, alone, shouldbe parsed as PAST ?
yet the system correctly dis-prefers incorporating this interpretation and returnsthe approximate duration 1 week.
Furthermore,we often capture cases of pragmatic ambiguity ?
forexample, empirically, August tends to refers to theprevious August when mentioned in February.Compared to rule-based systems, we attributemost errors the system makes to either data spar-sity or missing lexical primitives.
For example ?illustrating sparsity ?
we have trouble recognizingNov.
as corresponding to November (e.g., Nov. 13),since the publication time of the articles happen tooften be near November and we prefer tagging theword as Nil (analogous to the 13th).
Missing lexi-cal primitives, in turn, include tags for 1990s, or half(in minute and a half ); as well as missing functions,such as or (in weeks or months).Remaining errors can be attributed to causes suchas providing the wrong Viterbi grounding to theevaluation script (e.g., last rather than this Friday),differences in annotation (e.g., 24 hours is markedwrong against a day), or missing context (e.g., thepublication time is not the true reference time),among others.6 ConclusionWe present a new approach to resolving temporal ex-pressions, based on synchronous parsing of a fixedgrammar with learned parameters and a composi-tional representation of time.
The system allowsfor output which captures uncertainty both with re-spect to the syntactic structure of the phrase and thepragmatic ambiguity of temporal utterances.
Wealso note that the approach is theoretically betteradapted for phrases more complex than those foundin TempEval-2.Furthermore, the system makes very fewlanguage-specific assumptions, and the algorithmcould be adapted to domains beyond temporalresolution.
We hope to improve detection andexplore system performance on multilingual andcomplex datasets in future work.Acknowledgements The authors would like to thank ValentinSpitkovsky, David McClosky, and Angel Chang for valuablediscussion and insights.
We gratefully acknowledge the supportof the Defense Advanced Research Projects Agency (DARPA)Machine Reading Program under Air Force Research Labora-tory (AFRL) prime contract no.
FA8750-09-C-0181.
Any opin-ions, findings, and conclusions or recommendations expressedin this material are those of the authors and do not necessarilyreflect the view of DARPA, AFRL, or the US government.ReferencesJames F. Allen.
1981.
An interval-based representa-tion of temporal knowledge.
In Proceedings of the7th international joint conference on Artificial intelli-gence, pages 221?226, San Francisco, CA, USA.
Mor-gan Kaufmann Publishers Inc.James Allen.
1995.
Natural Language Understanding.Benjamin/Cummings, Redwood City, CA.454E.
Bach.
1976.
An extension of classical transforma-tional grammar.
In Problems of Linguistic Metatheory(Proceedings of the 1976 Conference), Michigan StateUniversity.Johan Bos, Stephen Clark, Mark Steedman, James R.Curran, and Julia Hockenmaier.
2004.
Wide-coveragesemantic representations from a CCG parser.
InProceedings of Coling, pages 1240?1246, Geneva,Switzerland.
COLING.Glenn Carroll and Eugene Charniak.
1992.
Two experi-ments on learning probabilistic dependency grammarsfrom corpora.
Technical report, Providence, RI, USA.Angel Chang and Chris Manning.
2012.
SUTIME: alibrary for recognizing and normalizing time expres-sions.
In Language Resources and Evaluation.James Clarke, Dan Goldwasser, Ming-Wei Chang, andDan Roth.
2010.
Driving semantic parsing from theworld?s response.
In CoNLL, pages 18?27, Uppsala,Sweden.Cleo Condoravdi.
2010.
NPI licensing in temporalclauses.
Natural Language and Linguistic Theory,28:877?910.Claire Grover, Richard Tobin, Beatrice Alex, and KateByrne.
2010.
Edinburgh-LTG: TempEval-2 systemdescription.
In Proceedings of the 5th InternationalWorkshop on Semantic Evaluation, Sem-Eval, pages333?336.Liang Huang and David Chiang.
2005.
Better k-bestparsing.
In Proceedings of the Ninth InternationalWorkshop on Parsing Technology, Parsing, pages 53?64.Rohit J. Kate, Yuk Wah Wong, and Raymond J. Mooney.2005.
Learning to transform natural to formal lan-guages.
In AAAI, pages 1062?1068, Pittsburgh, PA.Dan Klein and Christopher D. Manning.
2004.
Corpus-based induction of syntactic structure: models of de-pendency and constituency.
In ACL.Oleksandr Kolomiyets and Marie-Francine Moens.
2010.KUL: recognition and normalization of temporal ex-pressions.
In Proceedings of the 5th InternationalWorkshop on Semantic Evaluation, Sem-Eval ?10,pages 325?328.Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwa-ter, and Mark Steedman.
2011.
Lexical generalizationin CCG grammar induction for semantic parsing.
InEMNLP, pages 1512?1523, Edinburgh, Scotland, UK.J.
Lafferty, A. McCallum, and F Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In InternationalConference on Machine Learning (ICML).P.
Liang, M. I. Jordan, and D. Klein.
2011.
Learningdependency-based compositional semantics.
In ACL.Inderjeet Mani and George Wilson.
2000.
Robust tem-poral processing of news.
In ACL, pages 69?76, HongKong.Marc Moens and Mark Steedman.
1988.
Temporal on-tology and temporal reference.
Computational Lin-guistics, 14:15?28.G.
Puscasu.
2004.
A framework for temporal resolution.In LREC, pages 1901?1904.Hans Reichenbach.
1947.
Elements of Symbolic Logic.Macmillan, New York.E.
Saquete, R. Muoz, and P. Martnez-Barco.
2003.Terseo: Temporal expression resolution system ap-plied to event ordering.
In Text, Speech and Dialogue,pages 220?228.Mark Steedman.
2000.
The syntactic process.
MITPress, Cambridge, MA, USA.Jannik Stro?tgen and Michael Gertz.
2010.
Heideltime:High quality rule-based extraction and normalizationof temporal expressions.
In Proceedings of the 5th In-ternational Workshop on Semantic Evaluation, Sem-Eval, pages 321?324.Naushad UzZaman and James F. Allen.
2010.
TRIPSand TRIOS system for TempEval-2: Extracting tem-poral information from text.
In Proceedings of the 5thInternational Workshop on Semantic Evaluation, Sem-Eval, pages 276?283.Marc Verhagen, Roser Sauri, Tommaso Caselli, andJames Pustejovsky.
2010.
Semeval-2010 task 13:TempEval-2.
In Proceedings of the 5th InternationalWorkshop on Semantic Evaluation, pages 57?62, Up-psala, Sweden.Kenji Yamada and Kevin Knight.
2001.
A syntax-basedstatistical translation model.
In ACL, pages 523?530.John M. Zelle and Raymond J. Mooney.
1996.
Learn-ing to parse database queries using inductive logic pro-gramming.
In AAAI/IAAI, pages 1050?1055, Portland,OR.Luke S. Zettlemoyer and Michael Collins.
2005.
Learn-ing to map sentences to logical form: Structured clas-sification with probabilistic categorial grammars.
InUAI, pages 658?666.
AUAI Press.Luke S. Zettlemoyer and Michael Collins.
2007.
On-line learning of relaxed CCG grammars for parsing tological form.
In EMNLP-CoNLL, pages 678?687.455
