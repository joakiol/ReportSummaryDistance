Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 154?159,Baltimore, Maryland, USA.
June 27, 2014.c?2014 Association for Computational LinguisticsA Conceptual Framework for Inferring ImplicaturesJanyce WiebeDepartment of Computer ScienceUniversity of Pittsburghwiebe@cs.pitt.eduLingjia DengIntelligent Systems ProgramUniversity of Pittsburghlid29@pitt.eduAbstractWhile previous sentiment analysis re-search has concentrated on the interpreta-tion of explicitly stated opinions and atti-tudes, this work addresses a type of opin-ion implicature (i.e., opinion-oriented de-fault inference) in real-world text.
Thiswork describes a rule-based conceptualframework for representing and analyzingopinion implicatures.
In the course of un-derstanding implicatures, the system rec-ognizes implicit sentiments (and beliefs)toward various events and entities in thesentence, often of mixed polarities; thus,it produces a richer interpretation than istypical in opinion analysis.1 IntroductionThis paper is a brief introduction to a frameworkwe have developed for sentiment inference (Wiebeand Deng, 2014).
Overall, the goal of this work isto make progress toward a deeper automatic inter-pretation of opinionated language by developingcomputational models for the representation andinterpretation of opinion implicature (i.e., opinion-oriented default inference) in language.
In thispaper, we feature a rule-based implementation ofa conceptual framework for opinion implicatures,specifically implicatures that arise in the presenceof explicit sentiments, and events that positively ornegatively affect entities (goodFor/badFor events).To eliminate interference introduced by the noisyoutput of automatic NLP components, the sys-tem takes as input manually annotated explicit-sentiment and event information, and makes in-ferences based on that input information.
Thus,the purpose of this work is to provide a conceptualunderstanding of (a type of) opinion implicature,to provide a blueprint for realizing fully automaticsystems in the future.Below, we give terminology, overview the rule-based system, and then present the rule schemas.Finally, via discussion of an example from theMPQA opinion-annotated corpus (Wiebe et al.,2005)1, we illustrate the potential of the frame-work for recognizing implicit sentiments andwriter-level sentiments that are not anchored onclear sentiment words, and for capturing inter-dependencies among explicit and implicit senti-ments.We have developed a graph-based computa-tional model implementing some rules introducedbelow (Deng and Wiebe, 2014).
Moreover, in on-going work, we have proposed an optimizationframework to jointly extract and resolve the inputambiguities.2 TerminologyThe building blocks of our opinion implicatureframework are subjectivity, inferred private states,and benefactive/malefactive events and states.Subjectivity.
Following (Wiebe et al., 2005;Wiebe, 1994), subjectivity is defined as the ex-pression of private states in language, where pri-vate states are mental and emotional states such asspeculations, sentiments, and beliefs (Quirk et al.,1985).
Subjective expressions (i.e., opinions) havesources (or holders): the entity or entities whoseprivate states are being expressed.
Again follow-ing (Wiebe et al., 2005; Wiebe, 1994), a privatestate is an attitude held by a source toward (op-tionally) a target.
Sentiment and belief are typesof attitudes.
Subjectivity is the linguistic expres-sion of private states.
Subjectivity is a pragmaticnotion: as the sentence is interpreted in context,a private state is attributed to a source in that con-text (Banfield, 1982).
By sentiment expressionor explicit sentiment, we mean a subjective ex-pression where the attitude type of the expressed1Available at http://mpqa.cs.pitt.edu154private state is sentiment.There are many types of linguistic clues thatcontribute to recognizing subjective expressions(Wiebe, 1994).
In the clearest case, some wordsenses give rise to subjectivity whenever they areused in discourse (Wiebe and Mihalcea, 2006).Other clues are not as definitive.
For example, re-searchers in NLP have begun to develop lexiconsof connotations (Feng et al., 2011), i.e., words as-sociated with polarities out of context (e.g., warhas negative connotation and sunshine has positiveconnotation (Feng et al., 2013)).
However, wordsmay be used in context with polarities opposite totheir connotations, as in Ghenghis Kan likes war.Inferred Private States and Opinion Implica-tures.
We address private states inferred fromother private states, where the attitude type of bothis sentiment.
Inference is initiated by explicit sen-timent subjectivity.
We borrow the term implica-ture from linguistics, specifically generalized con-versational implicature.
Grice (1967; 1989) intro-duced the notion to account for how more can bepragmatically communicated than what is strictlysaid - what is implicated vs. what is said (Doranet al., 2012).
Generalized conversational implica-tures are cancellable, or defeasible.Analogously, we can treat subjectivity as partof what is said,2and the private-state inferenceswe address to be part of what is implicated.Opinion implicatures are default inferences thatmay not go through in context.Benefactive/Malefactive Events and States.This work addresses sentiments toward, in gen-eral, states and events which positively or nega-tively affect entities.
Various lexical items andsemantic roles evoke such situations.
We adoptone clear case in this work (Deng et al., 2013):?agent, event, object?
triples, where event nega-tively (badFor) or positively (goodFor) affects theobject.
An event that is goodFor or badFor is agfbf event.
Note that we have annotated a corpuswith gfbf information and the speaker?s sentimenttoward the agents and objects of gfbf events (Denget al., 2013).32While the focus in the literature on what is said is se-mantics, Grice and people later working on the topic ac-knowledge that what is said must include pragmatics such asco-reference and indexical resolution (Doran et al., 2012),and subjectivity arises from deixis (Bruder and Wiebe, 1995;Stein and Wright, 1995).
However, as long as what is said isconceived of as only truth evaluable propositions, then it isnot exactly the notion for our setting.3Available at http://mpqa.cs.pitt.edu3 OverviewIn this section, we give an overview of the rule-based system to provide an intuitive big picture ofwhat it can infer, instead of elaborating specificrules, which will be introduced in Section 4.The system includes default inference ruleswhich apply if there is no evidence to the contrary.It requires as input explicit sentiment and gfbf in-formation (plus any evidence that is contrary to theinferences).
The data structure of the input and theoutput are described in Section 3.1.
The rules areapplied repeatedly until no new conclusions can bedrawn.
If a rule matches a sentiment or event thatis the target of a private state, the nesting struc-ture is preserved when generating the conclusions.We say that inference is carried out in private statespaces, introduced in Section 3.2.
Finally in Sec-tion 3.3, an example is provided to illustrate whatthe system is able to infer.3.1 Data StructureThe system builds a graphical representation ofwhat it knows and infers about the meaning ofa sentence.
A detailed knowledge representationscheme is presented in (Wiebe and Deng, 2014).Below is an example from the MPQA corpus.Ex(1) [He] is therefore planning to trig-ger [wars] here and there to revive [theflagging arms industry].There are two gfbf events in this sentence: ?He,trigger, wars?
and ?He, revive, arms industry?.
Thesystem builds these nodes as input (as printed bythe system):8 writer positive believesTrue4 He revive flagging arms industry6 writer positive believesTrue1 He trigger warsThe system?s printout does not show all thestructure of a node.
Consider node 8.
It has asource edge to the node representing the writer,and a target edge to node 4, which in turn has anagent edge to the node representing He and a ob-ject edge to the node representing flagging armsindustry.
The nodes also have attributes whichrecord, e.g., what type of node it is (node 8 is aprivateState and node 4 is a gfbf), polarity (if rele-vant), etc.The graph is directed.
For example, node 4 isa child of 8.
A specification for the input is thateach root node must be a sentiment or believesTrue155node whose source is the writer.
Inference pro-ceeds by matching rules to the graph built so farand, when a rule successfully fires, adding nodesto the graph.3.2 Private State SpacesThe approach adopted here follows work on rea-soning in belief spaces and belief ascription in nat-ural language (Martins and Shapiro, 1983; Rapa-port, 1986; Slator and Wilks, 1987).
Other thanprivate states of the writer, all propositions andevents must be the target of some private state.
Inthe simplest case, the writer believes the proposi-tion or event he/she describes in the document, sothe proposition or event is nested under a writerpositive believesTrue node.We want to carry out inferences within privatestate spaces so that, for example, from S positivebelievesTrue P, & P =?
Q, the system may in-fer S positive believesTrue Q.
However, we areworking with sentiment, not only belief as in ear-lier work, and we want to allow, as appropriate,these types of inferences: from S sentiment to-ward P, & P =?Q, infer S sentiment toward Q.For example, if I?m upset my computer is infectedwith a virus, then I?m also upset with the conse-quences (e.g., that my files may be corrupted).A private state space is defined by a path wherethe root is a believesTrue or sentiment node whosesource is the writer, and each node on the path is abelievesTrue or sentiment node.
Two paths definethe same private state space if, at each correspond-ing position, they have the same attitude type, po-larity, and source.
P is in a private state space if Pis the target of the rightmost node on a path defin-ing that space.3.3 An ExampleNow we have introduced the data structure and theprivate state spaces, let?s see the potential conclu-sions which the system can infer before we go intothe detailed rules in the next section.Ex(2) However, it appears as if [the in-ternational community (IC)] is tolerat-ing [the Israeli] campaign of suppres-sion against [the Palestinians].The input nodes are the following.writer negative sentimentIC positive sentimentIsraeli suppression PalestiniansThe gfbf event ?Israeli, suppression,Palestinians?
is a badFor event.
Accordingto the writer, the IC is positive toward the eventin the sense that they tolerate (i.e., protect) it.However and appears as if are clues that thewriter is negative toward IC?s positive sentiment.Given these input annotations, the following arethe sentiments inferred by the system just towardthe entities in the sentence; note that many of thesentiments are nested in private state spaces.writer positive sentimentPalestinianswriter negative sentimentIsraelwriter negative sentimentICwriter positive believesTrueIsrael negative sentimentPalestinianswriter positive believesTrueIC negative sentimentPalestinianswriter positive believesTrueIC positive sentimentIsraelwriter positive believesTrueIC positive believesTrueIsrael negative sentimentPalestiniansNote that for the sentiments between two enti-ties other than the writer (e.g., Israel negative to-ward Palestinians), they are nested under a writerpositive believesTrue node.
This shows why weneed private state spaces.
The writer expresseshis/her opinion that the sentiment from Israel to-ward Palestinians is negative, which may not betrue outside the scope of this single document.4 RulesRules include preconditions and conclusions.They may also include assumptions (Hobbs et al.,1993).
For example, suppose a rule would suc-cessfully fire if an entity S believes P. If the entityS is not the writer but we know that the writer be-lieves P, and there is no evidence to the contrary(i.e.
there is no evidence showing that the entityS doesn?t believe P), then we?ll assume that S be-lieves it as well, if a rule ?asks us to?.Thus, our rules are conceptually of the form:P1, ..., P j : A1, .., Ak/Q1, ..., Qmwhere the P s are preconditions, the As are as-sumptions, and the Qs are conclusions.
For the Qsto be concluded, the P s must already hold; there156must be a basis for assuming each A; and theremust be no evidence against any of the As or Qs.Assumptions are indicated using the term ?As-sume?, as in rule 10, which infers sentiment fromconnotation:rule10:(Assume Writer positive ...believesTrue) A gfbf T &T?s anchor is in connotation lexicon =?Writer sentiment toward TThe first line contains an assumption, the sec-ond line contains a precondition, and the third con-tains a conclusion.rule8:S positive believesTrue A gfbf T &S sentiment toward T =?S sentiment toward A gfbf TFor example, applying rule 8 to ?The bill wouldcurb skyrocketing health care costs,?
from thewriter?s (S?s) negative sentiment toward the costs(T) expressed by skyrocketing, we can infer thewriter is positive toward the event ?bill, curb,costs?
(A gfbf T) because it would decrease thecosts.Note that, in rule 8, the inference is (senti-ment toward object) =?
(sentiment toward event).Rules 1 and 2 infer in the opposite direction.rule1:S sentiment toward A gfbf T =?S sentiment toward idea of A gfbf Trule2:S sentiment toward idea of A gfbf T =?S sentiment toward TFor rule 1, why ?ideaOf A gfbf T??
Because thepurview of this work is making inferences aboutattitudes, not about events themselves.
Conceptu-ally, ideaOf coerces an event into an idea, raisingit into the realm of private-state spaces.
Reasoningabout the ideas of events avoids the classificationof whether the events are realis (i.e., whether theydid/will happen).Rule 9 infers sentiment toward the agent in agfbf event.rule9:S sentiment toward A gfbf T &A is a thing &(Assume S positive believesTrue ...substantial) A gfbf T =?S sentiment toward ABy default, the system infers the event is in-tentional and that the agent is positive toward theevent; if there is evidence against either, the infer-ence should be blocked.rule6:A gfbf T, where A is animate =?A intended A gfbf Trule7:S intended S gfbf T =?S positive sentiment towardideaOf S gfbf TSo far, the preconditions have included only onesentiment.
Rule 3 applies when there are nestedsentiments, i.e., sentiments toward sentiments.rule3.1:S1 sentiment towardS2 sentiment toward Z =?S1 agrees/disagrees with S2 thatisGood/isBad Z &S1 sentiment toward Zrule3.2:S1 sentiment towardS2 pos/neg believesTrue substantial Z=?S1 agrees/disagrees with S2 thatisTrue/isFalse Z &S1 pos/neg believesTrue substantial Zrule3.3:S1 sentiment towardS2 pos/neg believesShould Z =?S1 agrees/disagrees with S2 thatshould/shouldNot Z &S1 pos/neg believesShould ZAmong the subcases of rule 3, one shared con-clusion is S1 agrees/disagrees with S2 *, which de-pends on the sentiment from S1 toward S2.
Thereason there are subcases is because the attitudetypes of S2 are various, which determine the in-ferred attitude type of S1.By rule 3, given the sentiment between S1 andS2, we can infer whether S1 and S2 agree.
Simi-larly, we can infer in the opposite direction, as rule4 shows.rule4:S1 agrees/disagrees with S2 that*=?S1 sentiment toward S2Two other rules are given in (Wiebe and Deng,2014).5 Inferences for An Example fromMPQA CorpusThis section returns to the example from theMPQA corpus in Section 3.1, illustrating some in-teresting inference chains and conclusions.Recall that the input for Ex(1) in Section 3.1 is:8 writer positive believesTrue4 He revive flagging arms industry6 writer positive believesTrue1 He trigger wars157The first inference is from connotation to sen-timent since the word war is in the connotationlexicon.rule10:(Assume Writer positive ...believesTrue) A gfbf T &T?s anchor is in connotation lexicon =?Writer sentiment toward TAssumptions:6 writer positive believesTrue1 He trigger warsrule10 =?
Infer:17 writer negative sentiment2 warsFrom the writer?s negative sentiment towardwars, the system infers a negative sentiment to-ward trigger wars, since triggering wars is good-For them:rule8:S positive believesTrue A gfbf T &S sentiment toward T =?S sentiment toward A gfbf TPreconditions:6 writer positive believesTrue1 He trigger wars17 writer negative sentiment2 warsrule8 =?
Infer:28 writer negative sentiment1 He trigger warsOn the other hand, since the agent, He, is ani-mate and there is no evidence to the contrary, thesystem infers that the triggering event is inten-tional, and that He is positive toward the idea ofhis performing the event:rule6 =?
Infer:38 writer negative sentiment20 He positive intends1 He trigger warsrule7 =?
Infer:41 writer negative sentiment25 He positive sentiment26 ideaOf1 He trigger warsContinuing with inference, since the writer hasa negative sentiment toward the agent?s positivesentiment, the system infers that the writer dis-agrees with him (rule 3) and thus that the writeris negative toward him (rule 4):rule3.1:S1 sentiment towardS2 sentiment toward Z =?S1 agrees/disagrees with S2 thatisGood/isBad Z &S1 sentiment toward ZPreconditions:41 writer negative sentiment25 He positive sentiment26 ideaOf1 He trigger warsrule3.1 =?
Infer:50 writer disagrees with He that49 isGood26 ideaOf1 He trigger wars30 writer negative sentiment26 ideaOf1 He trigger warsThen rule 4 works on node 50 and infers:rule4 =?
Infer:55 writer negative sentiment3 HeIn addition to the sentiment related to the wars,we have also drawn several conclusions of senti-ment toward the arms industry.
For example, oneof the output nodes related to the arms industry is:32 writer positive believesTrue31 He positive sentiment5 flagging arms industryThe MPQA annotators marked the writer?s neg-ative sentiment, choosing the long spans therefore.
.
.
industry and therefore planning .
.
.
here andthere as attitude and expressive subjective elementspans, respectively.
They were not able to pinpointany clear sentiment phrases.
A machine learningsystem trained on such examples would have diffi-culty recognizing the sentiments.
The system, re-lying on the negative connotation of war and thegfbf information in the sentence, is ultimately ableto infer several sentiments, including the writer?snegative sentiment toward the trigger event.6 ConclusionsWhile previous sentiment analysis research hasconcentrated on the interpretation of explicitlystated opinions and attitudes, this work addressesopinion implicature (i.e., opinion-oriented defaultinference) in real-world text.
This paper describeda rule-based framework for representing andanalyzing opinion implicatures which we hopewill contribute to deeper automatic interpretationof subjective language.
In the course of under-standing implicatures, the system recognizesimplicit sentiments (and beliefs) toward variousevents and entities in the sentence, often of mixedpolarities; thus, it produces a richer interpretationthan is typical in opinion analysis.Acknowledgements.
This work was supportedin part by DARPA-BAA-12-47 DEFT grant#12475008 and National Science Foundationgrant #IIS-0916046.
We would like to thank theanonymous reviewers for their feedback.158ReferencesAnn Banfield.
1982.
Unspeakable Sentences.
Rout-ledge and Kegan Paul, Boston.G.
Bruder and J. Wiebe.
1995.
Recognizing subjec-tivity and identifying subjective characters in third-person fictional narrative.
In Judy Duchan, GailBruder, and Lynne Hewitt, editors, Deixis in Nar-rative: A Cognitive Science Perspective.
LawrenceErlbaum Associates.Lingjia Deng and Janyce Wiebe.
2014.
Sentimentpropagation via implicature constraints.
In Meetingof the European Chapter of the Association for Com-putational Linguistics (EACL-2014).Lingjia Deng, Yoonjung Choi, and Janyce Wiebe.2013.
Benefactive/malefactive event and writer at-titude annotation.
In Proceedings of the 51st AnnualMeeting of the Association for Computational Lin-guistics (Volume 2: Short Papers), pages 120?125,Sofia, Bulgaria, August.
Association for Computa-tional Linguistics.Ryan Doran, Gregory Ward, Meredith Larson, YaronMcNabb, and Rachel E. Baker.
2012.
A novelexperimental paradigm for distinguishing between?what is said?
and ?what is implicated?.
Language,88(1):124?154.Song Feng, Ritwik Bose, and Yejin Choi.
2011.
Learn-ing general connotation of words using graph-basedalgorithms.
In Proceedings of the 2011 Confer-ence on Empirical Methods in Natural LanguageProcessing, pages 1092?1103, Edinburgh, Scotland,UK., July.
Association for Computational Linguis-tics.Song Feng, Jun Seok Kang, Polina Kuznetsova, andYejin Choi.
2013.
Connotation lexicon: A dashof sentiment beneath the surface meaning.
In Pro-ceedings of the 51st Annual Meeting of the Associa-tion for Computational Linguistics (Volume 1: LongPapers), pages 1774?1784, Sofia, Bulgaria, August.Association for Computational Linguistics.Herbert Paul Grice.
1967.
Logic and conversation.The William James lectures.H Paul Grice.
1989.
Studies in the Way of Words.
Har-vard University Press.Jerry R. Hobbs, Mark E. Stickel, Douglas E. Appelt,and Paul Martin.
1993.
Interpretation as abduction.Artificial Intelligence, 63(1-2):69?142, October.Jo?ao Martins and Stuart C. Shapiro.
1983.
Reasoningin multiple belief spaces.
In IJCAI.Randolph Quirk, Sidney Greenbaum, Geoffry Leech,and Jan Svartvik.
1985.
A Comprehensive Gram-mar of the English Language.
Longman, New York.William J. Rapaport.
1986.
Logical foundations forbelief representation.
Cognitive Science, 10(4):371?422.Brian M. Slator and Yorick Wilks.
1987.
Towards se-mantic structures from dictionary entries.
TechnicalReport MCCS-87-96, Computing Research Labora-tory, NMSU.Dieter Stein and Susan Wright, editors.
1995.
Sub-jectivity and Subjectivisation.
Cambridge Univer-sity Press, Cambridge.Janyce Wiebe and Lingjia Deng.
2014.
An account ofopinion implicatures.
arXiv:1404.6491v1 [cs.CL].Janyce Wiebe and Rada Mihalcea.
2006.
Word senseand subjectivity.
In Proceedings of the 21st Interna-tional Conference on Computational Linguistics and44th Annual Meeting of the Association for Com-putational Linguistics, pages 1065?1072, Sydney,Australia, July.
Association for Computational Lin-guistics.Janyce Wiebe, Theresa Wilson, and Claire Cardie.2005.
Annotating expressions of opinions and emo-tions in language.
Language Resources and Eval-uation (formerly Computers and the Humanities),39(2/3):164?210.Janyce Wiebe.
1994.
Tracking point of view in narra-tive.
Computational Linguistics, 20(2):233?287.159
