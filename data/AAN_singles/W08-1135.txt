USP-EACH Frequency-based Greedy Attribute Selection forReferring Expressions GenerationDiego Jesus de Lucena Ivandr?
ParaboniEscola de Artes, Ci?ncias e Humanidades Escola de Artes, Ci?ncias e HumanidadesUniversity of S?o Paulo ?
USP University of S?o Paulo ?
USPAv.
Arlindo Bettio, 1000 - S?o Paulo, Brazil Av.
Arlindo Bettio, 1000 - S?o Paulo, Brazildiego.si@usp.br ivandre@usp.brAbstractBoth greedy and domain-oriented REG algo-rithms have significant strengths but tend toperform poorly according to humanlikenesscriteria as measured by, e.g., Dice scores.
Inthis work we describe an attempt to combineboth perspectives into a single attribute selec-tion strategy to be used as part of the Dale &Reiter Incremental algorithm in the REGChallenge 2008, and the results in both Furni-ture and People domains.1 IntroductionMinimality and Humanlikeness in REG are oftenconflicting goals.
Greedy algorithms tend to favourshorter descriptions, but in doing so their outputmay look unnatural.
On the other hand, domain-oriented algorithms that arguably favour more?human-like?
strategies (e.g., selecting the mosttypical attributes first) pay little or no attention tominimality, and as a result the generated descrip-tions may become overly long or clumsy.Which strategy might a human speaker favour?In this work we describe an algorithm that disre-gards minimality entirely and attempts to select?typical?
attributes based on two simple assump-tions: first, when facing a complex context with alarge number of objects, an attempt to compute theprecise attribute capable of ruling out the largestpossible number of distractors is not only hard(from the computational point of view), but alsoless natural than simply using typical (e.g., fre-quent) attributes.
On the other hand, as the numberof distractors decreases, it may become graduallyclearer for the speaker which attributes are mosthelpful to achieve uniqueness, up to the point inwhich she may naturally switch to a ?greedy?
strat-egy and finalize the description.
These assump-tions are implemented as an attribute selectionstrategy to be used with the Incremental algorithm(Dale & Reiter, 1995) described below.2 System DescriptionWe take a simple view of humanlikeness in whichthe list of preferred attributes is sorted by relativefrequency1 as seen in the training data.
The result-ing list P is the centre piece of the following attrib-ute selection strategy:(1) select all attributes whose relative frequencyfalls above a trainable threshold value t  (in ourexperiments t is estimated to be 0.8 for bothFurniture and People domains.
)(2) if the resulting description uniquely describesthe target object, then finalizes.
(3) if not, starting from the most frequent attributein P, search exhaustively for an attribute gsuch that g, if selected, would rule out all re-maining distractors in the context.1 This contrasts the work in Kelleher (2007), which takes intoaccount absolute counts seen in the training data.219(4) if such attribute g exists, then g is selected andthe algorithm finalizes.
(5)  if not, select the most frequent attribute f thatcan rule out at least one distractor, and repeatsteps (3-5).The selection of attribute g stands for the greedycomponent of our approach, whilst the initial at-tributes in step 1 and the attribute f account for our?humanlikeness as frequency?
assumption.
Theoverall effect attempted is the following:- Highly frequent attributes are always selected.In our tests this means that the attributes typeand colour were always included in Furnituredescriptions, and type was always included inPeople descriptions (in both cases this is so re-gardless of discriminatory power.)
As a result,we can only produce minimal descriptions bychance.- In a complex situation of reference (in whichmany attributes may rule out many distractors,but more than one will be required to achieveuniqueness) the algorithm simply selects themost frequent attributes, perhaps not unlike ahuman speaker who has to single out the targetobject but who does not have the time or re-sources to come up with the ?best?
attributestraight away.- As the number of distractors decreases, a sin-gle attribute capable of ruling out all distrac-tors will eventually emerge, forcing thealgorithm to switch to a greedy strategy and fi-nalize.
Once again, this might be just whathumans do when  a suitable (i.e., economical)attribute becomes sufficiently salient and alldistractors in the context can be ruled out atonce.3 ResultsBelow we summarize our results for Task 1 (At-tribute Selection) and also for Task 3 (AttributeSelection and Surface Realisation combined) forthe REG 2008 development data set (80 instancesfor Furniture and 68 instances for People.)
As ex-pected, our algorithm is heavily penalized in theMinimality criteria but performs reasonably well inHumanlikeness (Dice and MASI.)
if compared tothe systems presented in the previous GRE Chal-lenge.Overall Furniture PeopleMean SD Mean SD Mean SDDice 0.75 0.25 0.82 0.22 0.66 0.26MASI 0.53 0.39 0.62 0.39 0.42 0.35Accuracy 0.37 0.48 0.49 0.50 0.24 0.43Uniqueness 1.00 - 1.00 - 1.00 -Minimality - - - - - -String-edit distance 6.70 3.09 6.13 3.28 7.38 2.72String-accuracy 0.02 0.14 0.04 0.19 - -Figure 1.
Attribute Selection and Surface Realisation resultsAcknowledgmentsThis work has been supported by CNPq-Brazil(484015/2007-9) and FAPESP (2006/03941-7).ReferencesDale, Robert and Ehud Reiter.
1995.
Computationalinterpretations of the Gricean maxims in the genera-tion of referring expressions.
Cognitive Science (19).Kelleher, J.D.
(2007) DIT - Frequency Based Incre-mental Attribute Selection for GRE.
MT Summit XIWorkshop Using Corpora for Natural LanguageGeneration: Language Generation and MachineTranslation, pp.
90-91.220
