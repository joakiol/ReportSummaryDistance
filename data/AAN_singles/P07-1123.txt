Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 976?983,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsLearning Multilingual Subjective Language via Cross-Lingual ProjectionsRada Mihalcea and Carmen BaneaDepartment of Computer ScienceUniversity of North Texasrada@cs.unt.edu, carmenb@unt.eduJanyce WiebeDepartment of Computer ScienceUniversity of Pittsburghwiebe@cs.pitt.eduAbstractThis paper explores methods for generatingsubjectivity analysis resources in a new lan-guage by leveraging on the tools and re-sources available in English.
Given a bridgebetween English and the selected target lan-guage (e.g., a bilingual dictionary or a par-allel corpus), the methods can be used torapidly create tools for subjectivity analysisin the new language.1 IntroductionThere is growing interest in the automatic extractionof opinions, emotions, and sentiments in text (sub-jectivity), to provide tools and support for variousnatural language processing applications.
Most ofthe research to date has focused on English, whichis mainly explained by the availability of resourcesfor subjectivity analysis, such as lexicons and man-ually labeled corpora.In this paper, we investigate methods to auto-matically generate resources for subjectivity analy-sis for a new target language by leveraging on theresources and tools available for English, which inmany cases took years of work to complete.
Specif-ically, through experiments with cross-lingual pro-jection of subjectivity, we seek answers to the fol-lowing questions.First, can we derive a subjectivity lexicon for anew language using an existing English subjectivitylexicon and a bilingual dictionary?
Second, can wederive subjectivity-annotated corpora in a new lan-guage using existing subjectivity analysis tools forEnglish and a parallel corpus?
Finally, third, can webuild tools for subjectivity analysis for a new targetlanguage by relying on these automatically gener-ated resources?We focus our experiments on Romanian, selectedas a representative of the large number of languagesthat have only limited text processing resources de-veloped to date.
Note that, although we work withRomanian, the methods described are applicable toany other language, as in these experiments we (pur-posely) do not use any language-specific knowledgeof the target language.
Given a bridge between En-glish and the selected target language (e.g., a bilin-gual dictionary or a parallel corpus), the methodscan be applied to other languages as well.After providing motivations, we present two ap-proaches to developing sentence-level subjectivityclassifiers for a new target language.
The first uses asubjectivity lexicon translated from an English one.The second uses an English subjectivity classifierand a parallel corpus to create target-language train-ing data for developing a statistical classifier.2 MotivationAutomatic subjectivity analysis methods have beenused in a wide variety of text processing applica-tions, such as tracking sentiment timelines in on-line forums and news (Lloyd et al, 2005; Baloget al, 2006), review classification (Turney, 2002;Pang et al, 2002), mining opinions from productreviews (Hu and Liu, 2004), automatic expressivetext-to-speech synthesis (Alm et al, 2005), text se-mantic analysis (Wiebe and Mihalcea, 2006; Esuliand Sebastiani, 2006), and question answering (Yuand Hatzivassiloglou, 2003).976While much recent work in subjectivity analysisfocuses on sentiment (a type of subjectivity, namelypositive and negative emotions, evaluations, andjudgments), we opt to focus on recognizing subjec-tivity in general, for two reasons.First, even when sentiment is the desired focus,researchers in sentiment analysis have shown thata two-stage approach is often beneficial, in whichsubjective instances are distinguished from objec-tive ones, and then the subjective instances are fur-ther classified according to polarity (Yu and Hatzi-vassiloglou, 2003; Pang and Lee, 2004; Wilson etal., 2005; Kim and Hovy, 2006).
In fact, the prob-lem of distinguishing subjective versus objective in-stances has often proved to be more difficult thansubsequent polarity classification, so improvementsin subjectivity classification promise to positivelyimpact sentiment classification.
This is reported instudies of manual annotation of phrases (Takamuraet al, 2006), recognizing contextual polarity of ex-pressions (Wilson et al, 2005), and sentiment tag-ging of words and word senses (Andreevskaia andBergler, 2006; Esuli and Sebastiani, 2006).Second, an NLP application may seek a widerange of types of subjectivity attributed to a per-son, such as their motivations, thoughts, and specu-lations, in addition to their positive and negative sen-timents.
For instance, the opinion tracking systemLydia (Lloyd et al, 2005) gives separate ratings forsubjectivity and sentiment.
These can be detectedwith subjectivity analysis but not by a method fo-cused only on sentiment.There is world-wide interest in text analysis appli-cations.
While work on subjectivity analysis in otherlanguages is growing (e.g., Japanese data are used in(Takamura et al, 2006; Kanayama and Nasukawa,2006), Chinese data are used in (Hu et al, 2005),and German data are used in (Kim and Hovy, 2006)),much of the work in subjectivity analysis has beenapplied to English data.
Creating corpora and lexicalresources for a new language is very time consum-ing.
In general, we would like to leverage resourcesalready developed for one language to more rapidlycreate subjectivity analysis tools for a new one.
Thismotivates our exploration and use of cross-linguallexicon translations and annotation projections.Most if not all work on subjectivity analysis hasbeen carried out in a monolingual framework.
Weare not aware of multi-lingual work in subjectivityanalysis such as that proposed here, in which subjec-tivity analysis resources developed for one languageare used to support developing resources in another.3 A Lexicon-Based ApproachMany subjectivity and sentiment analysis tools relyon manually or semi-automatically constructed lex-icons (Yu and Hatzivassiloglou, 2003; Riloff andWiebe, 2003; Kim and Hovy, 2006).
Given the suc-cess of such techniques, the first approach we taketo generating a target-language subjectivity classi-fier is to create a subjectivity lexicon by translatingan existing source language lexicon, and then builda classifier that relies on the resulting lexicon.Below, we describe the translation process anddiscuss the results of an annotation study to assessthe quality of the translated lexicon.
We then de-scribe and evaluate a lexicon-based target-languageclassifier.3.1 Translating a Subjectivity LexiconThe subjectivity lexicon we use is from Opinion-Finder (Wiebe and Riloff, 2005), an English sub-jectivity analysis system which, among other things,classifies sentences as subjective or objective.
Thelexicon was compiled from manually developed re-sources augmented with entries learned from cor-pora.
It contains 6,856 unique entries, out of which990 are multi-word expressions.
The entries in thelexicon have been labeled for part of speech, and forreliability ?
those that appear most often in subjec-tive contexts are strong clues of subjectivity, whilethose that appear less often, but still more often thanexpected by chance, are labeled weak.To perform the translation, we use two bilingualdictionaries.
The first is an authoritative English-Romanian dictionary, consisting of 41,500 entries,1which we use as the main translation resource for thelexicon translation.
The second dictionary, drawnfrom the Universal Dictionary download site (UDP,2007) consists of 4,500 entries written largely byWeb volunteer contributors, and thus is not errorfree.
We use this dictionary only for those entriesthat do not appear in the main dictionary.1Unique English entries, each with multiple Romaniantranslations.977There were several challenges encountered in thetranslation process.
First, although the English sub-jectivity lexicon contains inflected words, we mustuse the lemmatized form in order to be able to trans-late the entries using the bilingual dictionary.
How-ever, words may lose their subjective meaning oncelemmatized.
For instance, the inflected form ofmemories becomes memory.
Once translated intoRomanian (as memorie), its main meaning is ob-jective, referring to the power of retaining informa-tion as in Iron supplements may improve a woman?smemory.Second, neither the lexicon nor the bilingual dic-tionary provides information on the sense of the in-dividual entries, and therefore the translation has torely on the most probable sense in the target lan-guage.
Fortunately, the bilingual dictionary lists thetranslations in reverse order of their usage frequen-cies.
Nonetheless, the ambiguity of the words andthe translations still seems to represent an impor-tant source of error.
Moreover, the lexicon some-times includes identical entries expressed throughdifferent parts of speech, e.g., grudge has two sepa-rate entries, for its noun and verb roles, respectively.On the other hand, the bilingual dictionary does notmake this distinction, and therefore we have againto rely on the ?most frequent?
heuristic captured bythe translation order in the bilingual dictionary.Finally, the lexicon includes a significant number(990) of multi-word expressions that pose transla-tion difficulties, sometimes because their meaningis idiomatic, and sometimes because the multi-wordexpression is not listed in the bilingual dictionaryand the translation of the entire phrase is difficultto reconstruct from the translations of the individualwords.
To address this problem, when a translationis not found in the dictionary, we create one usinga word-by-word approach.
These translations arethen validated by enforcing that they occur at leastthree times on the Web, using counts collected fromthe AltaVista search engine.
The multi-word expres-sions that are not validated in this process are dis-carded, reducing the number of expressions from aninitial set of 990 to a final set of 264.The final subjectivity lexicon in Romanian con-tains 4,983 entries.
Table 1 shows examples of en-tries in the Romanian lexicon, together with theircorresponding original English form.
The tableRomanian English attributes?
?nfrumuset?a beautifying strong, verbnotabil notable weak, adjplin de regret full of regrets strong, adjsclav slaves weak, nounTable 1: Examples of entries in the Romanian sub-jectivity lexiconalso shows the reliability of the expression (weak orstrong) and the part of speech ?
attributes that areprovided in the English subjectivity lexicon.Manual Evaluation.We want to assess the quality of the translated lexi-con, and compare it to the quality of the original En-glish lexicon.
The English subjectivity lexicon wasevaluated in (Wiebe and Riloff, 2005) against a cor-pus of English-language news articles manually an-notated for subjectivity (the MPQA corpus (Wiebe etal., 2005)).
According to this evaluation, 85% of theinstances of the clues marked as strong and 71.5% ofthe clues marked as weak are in subjective sentencesin the MPQA corpus.Since there is no comparable Romanian corpus,an alternate way to judge the subjectivity of a Ro-manian lexicon entry is needed.Two native speakers of Romanian annotated thesubjectivity of 150 randomly selected entries.
Eachannotator independently read approximately 100 ex-amples of each drawn from the Web, including alarge number from news sources.
The subjectivityof a word was consequently judged in the contextswhere it most frequently appears, accounting for itsmost frequent meanings on the Web.The tagset used for the annotations consists ofS(ubjective), O(bjective), and B(oth).
A W(rong) la-bel is also used to indicate a wrong translation.
Table2 shows the contingency table for the two annota-tors?
judgments on this data.S O B W TotalS 53 6 9 0 68O 1 27 1 0 29B 5 3 18 0 26W 0 0 0 27 27Total 59 36 28 27 150Table 2: Agreement on 150 entries in the RomanianlexiconWithout counting the wrong translations, theagreement is measured at 0.80, with a Kappa ?
=9780.70, which indicates consistent agreement.
Afterthe disagreements were reconciled through discus-sions, the final set of 123 correctly translated entriesdoes include 49.6% (61) subjective entries, but fully23.6% (29) were found in the study to have primar-ily objective uses (the other 26.8% are mixed).Thus, this study suggests that the Romanian sub-jectivity clues derived through translation are less re-liable than the original set of English clues.
In sev-eral cases, the subjectivity is lost in the translation,mainly due to word ambiguity in either the sourceor target language, or both.
For instance, the wordfragile correctly translates into Romanian as fragil,yet this word is frequently used to refer to breakableobjects, and it loses its subjective meaning of del-icate.
Other words, such as one-sided, completelylose subjectivity once translated, as it becomes inRomanian cu o singura latura?, meaning with onlyone side (as of objects).Interestingly, the reliability of clues in the Englishlexicon seems to help preserve subjectivity.
Out ofthe 77 entries marked as strong, 11 were judged to beobjective in Romanian (14.3%), compared to 14 ob-jective Romanian entries obtained from the 36 weakEnglish clues (39.0%).3.2 Rule-based Subjectivity Classifier Using aSubjectivity LexiconStarting with the Romanian lexicon, we developeda lexical classifier similar to the one introduced by(Riloff and Wiebe, 2003).
At the core of this methodis a high-precision subjectivity and objectivity clas-sifier that can label large amounts of raw text usingonly a subjectivity lexicon.
Their method is furtherimproved with a bootstrapping process that learnsextraction patterns.
In our experiments, however, weapply only the rule-based classification step, sincethe extraction step cannot be implemented withouttools for syntactic parsing and information extrac-tion not available in Romanian.The classifier relies on three main heuristics to la-bel subjective and objective sentences: (1) if twoor more strong subjective expressions occur in thesame sentence, the sentence is labeled Subjective;(2) if no strong subjective expressions occur in asentence, and at most two weak subjective expres-sions occur in the previous, current, and next sen-tence combined, then the sentence is labeled Objec-tive; (3) otherwise, if none of the previous rules ap-ply, the sentence is labeled Unknown.The quality of the classifier was evaluated on aRomanian gold-standard corpus annotated for sub-jectivity.
Two native Romanian speakers (Ro1 andRo2) manually annotated the subjectivity of the sen-tences of five randomly selected documents (504sentences) from the Romanian side of an English-Romanian parallel corpus, according to the anno-tation scheme in (Wiebe et al, 2005).
Agreementbetween annotators was measured, and then theirdifferences were adjudicated.
The baseline on thisdata set is 54.16%, which can be obtained by as-signing a default Subjective label to all sentences.
(More information about the corpus and annotationsare given in Section 4 below, where agreement be-tween English and Romanian aligned sentences isalso assessed.
)As mentioned earlier, due to the lexicon projec-tion process that is performed via a bilingual dictio-nary, the entries in our Romanian subjectivity lex-icon are in a lemmatized form.
Consequently, wealso lemmatize the gold-standard corpus, to allowfor the identification of matches with the lexicon.For this purpose, we use the Romanian lemmatizerdeveloped by Ion and Tufis?
(Ion, 2007), which hasan estimated accuracy of 98%.2Table 3 shows the results of the rule-based classi-fier.
We show the precision, recall, and F-measureindependently measured for the subjective, objec-tive, and all sentences.
We also evaluated a vari-ation of the rule-based classifier that labels a sen-tence as objective if there are at most three weak ex-pressions in the previous, current, and next sentencecombined, which raises the recall of the objectiveclassifier.
Our attempts to increase the recall of thesubjective classifier all resulted in significant loss inprecision, and thus we kept the original heuristic.In its original English implementation, this sys-tem was proposed as being high-precision but lowcoverage.
Evaluated on the MPQA corpus, it hassubjective precision of 90.4, subjective recall of34.2, objective precision of 82.4, and objective re-call of 30.7; overall, precision is 86.7 and recall is32.6 (Wiebe and Riloff, 2005).
We see a similar be-havior on Romanian for subjective sentences.
Thesubjective precision is good, albeit at the cost of low2Dan Tufis?, personal communication.979Measure Subjective Objective Allsubj = at least two strong; obj = at most two weakPrecision 80.00 56.50 62.59Recall 20.51 48.91 33.53F-measure 32.64 52.52 43.66subj = at least two strong; obj = at most three weakPrecision 80.00 56.85 61.94Recall 20.51 61.03 39.08F-measure 32.64 58.86 47.93Table 3: Evaluation of the rule-based classifierrecall, and thus the classifier could be used to har-vest subjective sentences from unlabeled Romaniandata (e.g., for a subsequent bootstrapping process).The system is not very effective for objective classi-fication, however.
Recall that the objective classifierrelies on the weak subjectivity clues, for which thetransfer of subjectivity in the translation process wasparticularly low.4 A Corpus-Based ApproachGiven the low number of subjective entries found inthe automatically generated lexicon and the subse-quent low recall of the lexical classifier, we decidedto also explore a second, corpus-based approach.This approach builds a subjectivity-annotated cor-pus for the target language through projection, andthen trains a statistical classifier on the resultingcorpus (numerous statistical classifiers have beentrained for subjectivity or sentiment classification,e.g., (Pang et al, 2002; Yu and Hatzivassiloglou,2003)).
The hypothesis is that we can eliminatesome of the ambiguities (and consequent loss of sub-jectivity) observed during the lexicon translation byaccounting for the context of the ambiguous words,which is possible in a corpus-based approach.
Ad-ditionally, we also hope to improve the recall of theclassifier, by addressing those cases not covered bythe lexicon-based approach.In the experiments reported in this section, weuse a parallel corpus consisting of 107 documentsfrom the SemCor corpus (Miller et al, 1993) andtheir manual translations into Romanian.3 The cor-pus consists of roughly 11,000 sentences, with ap-proximately 250,000 tokens on each side.
It is a bal-anced corpus covering a number of topics in sports,politics, fashion, education, and others.3The translation was carried out by a Romanian nativespeaker, student in a department of ?Foreign Languages andTranslations?
in Romania.Below, we begin with a manual annotation studyto assess the quality of annotation and preservationof subjectivity in translation.
We then describe theautomatic construction of a target-language trainingset, and evaluate a classifier trained on that data.Annotation Study.We start by performing an agreement study meantto determine the extent to which subjectivity is pre-served by the cross-lingual projections.
In the study,three annotators ?
one native English speaker (En)and two native Romanian speakers (Ro1 and Ro2) ?first trained on 3 randomly selected documents (331sentences).
They then independently annotated thesubjectivity of the sentences of two randomly se-lected documents from the parallel corpus, account-ing for 173 aligned sentence pairs.
The annotatorshad access exclusively to the version of the sen-tences in their language, to avoid any bias that couldbe introduced by seeing the translation in the otherlanguage.Note that the Romanian annotations (after all dif-ferences between the Romanian annotators were ad-judicated) of all 331 + 173 sentences make up thegold standard corpus used in the experiments re-ported in Sections 3.2 and 4.1.Before presenting the results of the annotationstudy, we give some examples.
The following areEnglish subjective sentences and their Romaniantranslations (the subjective elements are shown inbold).
[en] The desire to give Broglio as many starts aspossible.
[ro] Dorint?a de a-i da lui Broglio ca?t mai multestarturi posibile.
[en] Suppose he did lie beside Lenin, would it bepermanent ?
[ro] Sa?
presupunem ca?
ar fi as?ezat ala?turi de Lenin,oare va fi pentru totdeauna?The following are examples of objective parallelsentences.
[en]The Pirates have a 9-6 record this year and theRedbirds are 7-9.
[ro] Pirat?ii au un palmares de 9 la 6 anul acesta siPa?sa?rile Ros?ii au 7 la 9.
[en] One of the obstacles to the easy control of a2-year old child is a lack of verbal communication.
[ro] Unul dintre obstacolele ?
?n controlarea unuicopil de 2 ani este lipsa comunica?rii verbale.980The annotators were trained using the MPQAannotation guidelines (Wiebe et al, 2005).
Thetagset consists of S(ubjective), O(bjective) andU(ncertain).
For the U tags, a class was also given;OU means, for instance, that the annotator is uncer-tain but she is leaning toward O.
Table 4 shows thepairwise agreement figures and the Kappa (?)
calcu-lated for the three annotators.
The table also showsthe agreement when the borderline uncertain casesare removed.all sentences Uncertain removedpair agree ?
agree ?
(%) removedRo1 & Ro2 0.83 0.67 0.89 0.77 23En & Ro1 0.77 0.54 0.86 0.73 26En & Ro2 0.78 0.55 0.91 0.82 20Table 4: Agreement on the data set of 173 sentences.Annotations performed by three annotators: one na-tive English speaker (En) and two native Romanianspeakers (Ro1 and Ro2)When all the sentences are included, the agree-ment between the two Romanian annotators is mea-sured at 0.83 (?
= 0.67).
If we remove the border-line cases where at least one annotator?s tag is Un-certain, the agreement rises to 0.89 with ?
= 0.77.These figures are somewhat lower than the agree-ment observed during previous subjectivity anno-tation studies conducted on English (Wiebe et al,2005) (the annotators were more extensively trainedin those studies), but they nonetheless indicate con-sistent agreement.Interestingly, when the agreement is conductedcross-lingually between an English and a Romanianannotator, the agreement figures, although some-what lower, are comparable.
In fact, once theUncertain tags are removed, the monolingual andcross-lingual agreement and ?
values become al-most equal, which suggests that in most cases thesentence-level subjectivity is preserved.The disagreements were reconciled first betweenthe labels assigned by the two Romanian annotators,followed by a reconciliation between the resultingRomanian ?gold-standard?
labels and the labels as-signed by the English annotator.
In most cases, thedisagreement across the two languages was foundto be due to a difference of opinion about the sen-tence subjectivity, similar to the differences encoun-tered in monolingual annotations.
However, thereare cases where the differences are due to the sub-jectivity being lost in the translation.
Sometimes,this is due to several possible interpretations for thetranslated sentence.
For instance, the following sen-tence:[en] They honored the battling Billikens last night.
[ro] Ei i-au celebrat pe Billikens seara trecuta?.is marked as Subjective in English (in context, theEnglish annotator interpreted honored as referringto praises of the Billikens).
However, the Romaniantranslation of honored is celebrat which, while cor-rect as a translation, has the more frequent interpre-tation of having a party.
The two Romanian annota-tors chose this interpretation, which correspondinglylead them to mark the sentence as Objective.In other cases, in particular when the subjectivityis due to figures of speech such as irony, the trans-lation sometimes misses the ironic aspects.
For in-stance, the translation of egghead was not perceivedas ironic by the Romanian annotators, and conse-quently the following sentence labeled Subjective inEnglish is annotated as Objective in Romanian.
[en] I have lived for many years in a Connecti-cut commuting town with a high percentage of [...]business executives of egghead tastes.
[ro] Am tra?it mult?i ani ?
?ntr-un oras?
din apropiere deConnecticut ce avea o mare proport?ie de [...] oa-meni de afaceri cu gusturi intelectuale.4.1 Translating a Subjectivity-AnnotatedCorpus and Creating a Machine LearningSubjectivity ClassifierTo further validate the corpus-based projection ofsubjectivity, we developed a subjectivity classifiertrained on Romanian subjectivity-annotated corporaobtained via cross-lingual projections.Ideally, one would generate an annotated Roma-nian corpus by translating English documents man-ually annotated for subjectivity such as the MPQAcorpus.
Unfortunately, the manual translation of thiscorpus would be prohibitively expensive, both time-wise and financially.
The other alternative ?
auto-matic machine translation ?
has not yet reached alevel that would enable the generation of a high-quality translated corpus.
We therefore decided touse a different approach where we automaticallyannotate the English side of an existing English-Romanian corpus, and subsequently project the an-notations onto the Romanian side of the parallel cor-981Precision Recall F-measurehigh-precision 86.7 32.6 47.4high-coverage 79.4 70.6 74.7Table 5: Precision, recall, and F-measure for thetwo OpinionFinder classifiers, as measured on theMPQA corpus.pus across the sentence-level alignments available inthe corpus.For the automatic subjectivity annotations, wegenerated two sets of the English-side annotations,one using the high-precision classifier and one usingthe high-coverage classifier available in the Opinion-Finder tool.
The high-precision classifier in Opin-ionFinder uses the clues of the subjectivity lexiconto harvest subjective and objective sentences froma large amount of unannotated text; this data is thenused to automatically identify a set of extraction pat-terns, which are then used iteratively to identify alarger set of subjective and objective sentences.In addition, in OpinionFinder, the high-precisionclassifier is used to produce an English labeled dataset for training, which is used to generate its NaiveBayes high-coverage subjectivity classifier.
Table5 shows the performance of the two classifiers onthe MPQA corpus as reported in (Wiebe and Riloff,2005).
Note that 55% of the sentences in the MPQAcorpus are subjective ?
which represents the baselinefor this data set.The two OpinionFinder classifiers are used to la-bel the training corpus.
After removing the 504 testsentences, we are left with 10,628 sentences thatare automatically annotated for subjectivity.
Table6 shows the number of subjective and objective sen-tences obtained with each classifier.Classifier Subjective Objective Allhigh-precision 1,629 2,334 3,963high-coverage 5,050 5,578 10,628Table 6: Subjective and objective training sentencesautomatically annotated with OpinionFinder.Next, the OpinionFinder annotations are pro-jected onto the Romanian training sentences, whichare then used to develop a probabilistic classifier forthe automatic labeling of subjectivity in Romaniansentences.Similar to, e.g., (Pang et al, 2002), we use aNaive Bayes algorithm trained on word features co-occurring with the subjective and the objective clas-sifications.
We assume word independence, and weuse a 0.3 cut-off for feature selection.
While re-cent work has also considered more complex syn-tactic features, we are not able to generate such fea-tures for Romanian as they require tools currentlynot available for this language.We create two classifiers, one trained on eachdata set.
The quality of the classifiers is evaluatedon the 504-sentence Romanian gold-standard corpusdescribed above.
Recall that the baseline on this dataset is 54.16%, the percentage of sentences in the cor-pus that are subjective.
Table 7 shows the results.Subjective Objective Allprojection source: OF high-precision classifierPrecision 65.02 69.62 64.48Recall 82.41 47.61 64.48F-measure 72.68 56.54 64.68projection source: OF high-coverage classifierPrecision 66.66 70.17 67.85Recall 81.31 52.17 67.85F-measure 72.68 56.54 67.85Table 7: Evaluation of the machine learning classi-fier using training data obtained via projections fromdata automatically labeled by OpinionFinder (OF).Our best classifier has an F-measure of 67.85,and is obtained by training on projections fromthe high-coverage OpinionFinder annotations.
Al-though smaller than the 74.70 F-measure obtainedby the English high-coverage classifier (see Ta-ble 5), the result appears remarkable given that nolanguage-specific Romanian information was used.The overall results obtained with the machinelearning approach are considerably higher thanthose obtained from the rule-based classifier (exceptfor the precision of the subjective sentences).
Thisis most likely due to the lexicon translation process,which as mentioned in the agreement study in Sec-tion 3.1, leads to ambiguity and loss of subjectivity.Instead, the corpus-based translations seem to betteraccount for the ambiguity of the words, and the sub-jectivity is generally preserved in the sentence trans-lations.5 ConclusionsIn this paper, we described two approaches to gener-ating resources for subjectivity annotations for a new982language, by leveraging on resources and tools avail-able for English.
The first approach builds a targetlanguage subjectivity lexicon by translating an exist-ing English lexicon using a bilingual dictionary.
Thesecond generates a subjectivity-annotated corpus ina target language by projecting annotations from anautomatically annotated English corpus.These resources were validated in two ways.First, we carried out annotation studies measuringthe extent to which subjectivity is preserved acrosslanguages in each of the two resources.
These stud-ies show that only a relatively small fraction of theentries in the lexicon preserve their subjectivity inthe translation, mainly due to the ambiguity in boththe source and the target languages.
This is con-sistent with observations made in previous workthat subjectivity is a property associated not withwords, but with word meanings (Wiebe and Mihal-cea, 2006).
In contrast, the sentence-level subjectiv-ity was found to be more reliably preserved acrosslanguages, with cross-lingual inter-annotator agree-ments comparable to the monolingual ones.Second, we validated the two automatically gen-erated subjectivity resources by using them to builda tool for subjectivity analysis in the target language.Specifically, we developed two classifiers: a rule-based classifier that relies on the subjectivity lexi-con described in Section 3.1, and a machine learn-ing classifier trained on the subjectivity-annotatedcorpus described in Section 4.1.
While the highestprecision for the subjective classification is obtainedwith the rule-based classifier, the overall best resultof 67.85 F-measure is due to the machine learningapproach.
This result is consistent with the anno-tation studies, showing that the corpus projectionspreserve subjectivity more reliably than the lexicontranslations.Finally, neither one of the classifiers relies onlanguage-specific information, but rather on knowl-edge obtained through projections from English.
Asimilar method can therefore be used to derive toolsfor subjectivity analysis in other languages.ReferencesAlina Andreevskaia and Sabine Bergler.
Mining wordnet forfuzzy sentiment: Sentiment tag extraction from WordNetglosses.
In Proceedings of EACL 2006.Cecilia Ovesdotter Alm, Dan Roth, and Richard Sproat.
2005.Emotions from text: Machine learning for text-based emo-tion prediction.
In Proceedings of HLT/EMNLP 2005.Krisztian Balog, Gilad Mishne, and Maarten de Rijke.
2006.Why are they excited?
identifying and explaining spikes inblog mood levels.
In EACL-2006.Andrea Esuli and Fabrizio Sebastiani.
2006.
Determining termsubjectivity and term orientation for opinion mining.
In Pro-ceedings the EACL 2006.Minqing Hu and Bing Liu.
2004.
Mining and summarizingcustomer reviews.
In Proceedings of ACM SIGKDD.Yi Hu, Jianyong Duan, Xiaoming Chen, Bingzhen Pei, andRuzhan Lu.
2005.
A new method for sentiment classifi-cation in text retrieval.
In Proceedings of IJCNLP.Radu Ion.
2007.
Methods for automatic semantic disambigua-tion.
Applications to English and Romanian.
Ph.D. thesis,The Romanian Academy, RACAI.Hiroshi Kanayama and Tetsuya Nasukawa.
2006.
Fully auto-matic lexicon expansion for domain-oriented sentiment anal-ysis.
In Proceedings of EMNLP 2006.Soo-Min Kim and Eduard Hovy.
2006.
Identifying and ana-lyzing judgment opinions.
In Proceedings of HLT/NAACL2006.Levon Lloyd, Dimitrios Kechagias, and Steven Skiena.
2005.Lydia: A system for large-scale news analysis.
In Proceed-ings of SPIRE 2005.George Miller, Claudia Leacock, Tangee Randee, and RossBunker.
1993.
A semantic concordance.
In Proceedingsof the DARPA Workshop on Human Language Technology.Bo Pang and Lillian Lee.
2004.
A sentimental education: Sen-timent analysis using subjectivity summarization based onminimum cuts.
In Proceedings of ACL 2004.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002.Thumbs up?
Sentiment classification using machine learningtechniques.
In Proceedings of EMNLP 2002.Ellen Riloff and Janyce Wiebe.
2003.
Learning extraction pat-terns for subjective expressions.
In Proceedings of EMNLP2003.Hiroya Takamura, Takashi Inui, and Manabu Okumura.
2006.Latent variable models for semantic orientations of phrases.In Proceedings of EACL 2006.Peter Turney.
2002.
Thumbs up or thumbs down?
Semanticorientation applied to unsupervised classification of reviews.In Proceedings of ACL 2002.Universal Dictionary.
2007.
Available atwww.dicts.info/uddl.php.Janyce Wiebe and Rada Mihalcea.
2006.
Word sense and sub-jectivity.
In Proceedings of COLING-ACL 2006.Janyce Wiebe and Ellen Riloff.
2005.
Creating subjectiveand objective sentence classifiers from unannotated texts.
InProceedings of CICLing 2005 (invited paper).
Available atwww.cs.pitt.edu/mpqarequest.Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005.Annotating expressions of opinions and emotions in lan-guage.
Language Resources and Evaluation, 39(2/3):164?210.
Available at www.cs.pitt.edu/mpqa.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005.Recognizing contextual polarity in phrase-level sentimentanalysis.
In Proceedings of HLT/EMNLP 2005.Hong Yu and Vasileios Hatzivassiloglou.
2003.
Towards an-swering opinion questions: Separating facts from opinionsand identifying the polarity of opinion sentences.
In Pro-ceedings of EMNLP 2003.983
