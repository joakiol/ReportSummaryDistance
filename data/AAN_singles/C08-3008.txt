Coling 2008: Companion volume ?
Posters and Demonstrations, pages 173?176Manchester, August 2008Entailment-based Question Answeringfor Structured DataBogdan Sacaleanu?, Constantin Orasan?, Christian Spurk?, ShiyanOu?, Oscar Ferrandez?, Milen Kouylekov?
and Matteo Negri?
?LT-Lab, DFKI GmbH / Saarbr?cken, Germany?RIILP, University of Wolverhampton / Wolverhampton, UK?Fondazione Bruno Kessler (FBK) / Trento, Italy?University of Alicante / Alicante, SpainAbstractThis paper describes a Question Answer-ing system which retrieves answers fromstructured data regarding cinemas andmovies.
The system represents the firstprototype of a multilingual and multi-modal QA system for the domain of tour-ism.
Based on specially designed domainontology and using Textual Entailment asa means for semantic inference, the sys-tem can be used in both monolingual andcross-language settings with slight ad-justments for new input languages.1 IntroductionQuestion Answering over structured data hasbeen traditionally addressed through a deepanalysis of the question in order to reconstruct alogical form, which is then translated in the querylanguage of the target data (Androutsopoulos etal, 1995, Popescu et al 2003).
This approach im-plies a complex mapping between linguistic ob-jects (e.g.
lexical items, syntactic structures) andagainst data objects (e.g.
concepts and relationsin a knowledge base).
Unfortunately, such amapping requires extensive manual work, whichin many cases represents a bottleneck preventingthe realization of large scale and portable naturallanguage interfaces to structured data.This paper presents the first prototype of aquestion answering system which can answerquestions in several languages about movies andcinema using a multilingual ontology and textual?
2008.
Licensed under the Creative Commons Attri-bution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.entailment.
The remainder of the paper is struc-tured as follows: Section 2 presents the conceptof entailment-based question answering; Section3 describes our prototype which implements thisconcept; A brief evaluation is presented in Sec-tion 4, followed by conclusions in Section 5.2 Entailment-based QARecently Textual Entailment (TE) has been pro-posed as a unifying framework for applied se-mantics (Dagan and Glickman, 2004), where theneed for an explicit representation of a mappingbetween linguistic objects and data objects canbe, at least partially, bypassed through the defini-tion of semantic inferences at a textual level.
Inthis framework, a text (T) is said to entail a hy-pothesis (H) if the meaning of H can be derivedfrom the meaning of T.On the basis of the TE framework, the QAproblem can be recast as an entailment problem,where the text (T) is the question (or its affirma-tive version) and the hypothesis (H) is a rela-tional answer pattern, which is associated to in-structions for retrieving the answer to the inputquestion.
In this framework, given a question Qand a set of relational answer patterns P, a QAsystem needs to select those patterns in P that areentailed by Q.
Instructions associated to answerpatterns may be viewed as high precision proce-dures for answer extraction, which are dependenton the specific source which is asked for.
In caseof QA over structured data, instructions could bequeries to a database; whilst in case of QA on theWeb, an instruction could be the URL of a Webpage containing the answer to a question or someform of IR query to a search engine.Therefore, the underlying idea of an entail-ment-based QA system is to match the user?s re-quest to a set of predefined question patterns inorder to get some kind of analysis for the request.173As an example consider the question ?Wherecan I watch the movie ?Dreamgirls?
next Satur-day??
and the predefined question patterns:?
Which movies are currently running in[CINEMA]?
 EAT = [MOVIE]?
Where can I watch the movie [MOVIE]on [WEEKDAY]?
 EAT = [CINEMA]?
Where can I see [MOVIE]? EAT = [CINEMA]In the example, each of the patterns containsplaceholders for relevant named entities and hasan expected answer type (EAT) associated withit.
The entailment-based QA system should re-turn that pattern (2) is entailed by the questionand as a result the retrieval instructions associ-ated to it will be used to answer the question.3 Description of systemOur question answering system implements theconcept of entailment-based question answeringdescribed in the previous section.
The overallstructure of our system is presented in Figure 1.Given a question asked by a user of the systemin a known location, the QA planner forwards itto the Instance Annotator in order to find anyconcepts that might be related to the targeteddomain (i.e.
cinema, city, movie).
The result isthen analyzed by the Relation Matcher, which onthe basis of entailment can either select the mostappropriate interpretation of the question and im-plicitly its associated procedure of answering thequestion, or decide that the user request is out-of-coverage if no such interpretation is available.The cross-linguality of our system and, to acertain extent, the interaction between its compo-nents is ensured by a domain ontology which isused for all four languages involved in the pro-ject: English, German, Italian and Spanish, andits modules (Ou et al, 2008).
Concepts from theontology are used to annotate the user questionsas well as data from which the answer is ex-tracted.
In the current stage of the project, theanswers are contained in databases obtained fromcontent provides or built from structured webpages.
As a result, the information in the databasetables was annotated with concepts from the on-tology and then converted into an RDF graph toFigure 1.
System Architecture174facilitate retrieval using SPARQL query lan-guage (Prud'hommeaux and Seaborne, 2006).Question patterns corresponding to one or severalontological relations were produced after ques-tions for users were collected and used in the en-tailment module.
The question patterns used bythe system are very similar to those presented inthe previous section and contain placeholders forthe actual entities that are expected to appear in aquestion.The SPARQL query associated with a patternselected for a user question is used to retrieve theanswers from the knowledge base and prepare forpresentation.
Given that our system is not limitedto returning only textual information, furtherprocessing can be applied to the retrieved data.For example, for proximity questions the list ofanswers consists of cinema names and their GPS-coordinates, which are used by the Answer Sort-ing component to reorder the list of answers onthe basis of their distance to the user?s location.Besides presenting the possible answers to agiven question, the system can offer additionalinformation based on the answer?s type:?
a map for answers that are locationnames,?
a route description for answers that arecinema names,?
a video-trailer for answers that are movienames and?
an image for answers that are personnames.Due to the fact that a common semantics isshared by all four languages by way of a domainontology, the system can be used not only in amonolingual setting, but also in a cross-languagesetting.
This corresponds to a user-scenariowhere a tourist asks for information in their ownlanguage in a foreign location (i.e.
Englishspeaker in Italy).
The only difference betweenmonolingual and cross-language scenarios is thatin the cross-language setting, the QA Core sub-system (Figure 1) selects a Find Entailed Rela-tion component according to the user input?s lan-guage.
This is due to the entailment algorithmsthat tend to use language specific resources inorder to attain high accuracy results of matchingthe user request with one of the lexicalized rela-tions (patterns).
It is only the entailment compo-nent that has to be provided in order to adapt thesystem to new input languages, once the lexical-ized relations have been translated either manualor automatically.Both the Instance Annotator and the AnswerRetriever are language independent, but locationdependent (Figure 2).
The Answer Retriever de-pends on the location since it is querying datafound at that place (i.e.
Italy), while the InstanceAnnotator looks up instances of the data in theuser?s question (i.e.
annotates an English ques-tion).
They are language independent since theyare working with data abstractions like SPARQLqueries (Answer Retriever) or work at characterlevel and do not consider language specific as-pects, like words, in their look-up process (In-stance Annotator).The current version of the system1 is designedaccording to the SOA (Service Oriented Archi-tecture) and is implemented as point-to-point in-tegrated web services.
Any of the system?s com-ponents can be substituted by alternative imple-mentations with no need for further changes aslong as the functionality remains the same.1http://attila.dfki.uni-sb.de:8282/ QallMe_Proto-type_WEB_Update/faces/Page6.jspFigure 2.
Cross-language Setting1754 EvaluationA preliminary evaluation of the first prototypewas carried out on randomly selected questionsfrom a benchmark specifically designed for theproject.
This benchmark was developed to con-tain questions about various aspects from thedomain of tourism and for this reason we filteredout questions not relevant to cinema or movies.The evaluation of the system did not assesswhether it can extract the correct answer.
Instead,it measured to what extent the system can selectthe right SPARQL pattern.
The explanation forthis can be found in the fact that once a correctquestion pattern is selected, the extraction of theanswer requires only retrieval of the answer fromthe database.
Moreover, it should be pointed outthat the main purpose of this preliminary evalua-tion was to test the interaction between compo-nents and indicate potential problems, and it wasless about their performances.Table 1 summarises the results of the evalua-tion.
The number of questions used in the evalua-tion is different from one language to another.This can be explained by the fact that for eachlanguage a number of questions (in general 500)was randomly selected from the benchmark andonly the ones which referred to cinema or movieswere selected.
The column Questions indicatesthe number of questions assessed.
The Correctcolumn indicates for how many questions a cor-rect SPARQL was generated.
The Wrong columncorresponds to the number of questions where awrong or incomplete SPARQL was generated.This number also includes cases where noSPARQL was generated due to lack of corre-sponding answer pattern.Questions Correct WrongEnglish 167 74 (44.31%) 93 (55.68%)German 214 120 (56.04%) 94 (43.92%)Spanish 58 50 (86.20%) 8 (13.79%)Italian 99 46 (46.46%) 53 (53.53%)Table 1: Evaluation resultsAs can be seen, the results are very differentfrom one language to another.
This can be ex-plained by the fact that different entailment en-gines are used for each language.
In addition,even though the benchmark was built using acommon set of guidelines, the complexity ofquestions varies from one language to another.For this reason, for some questions it is more dif-ficult to find the correct pattern than for others.Analysis of the results revealed that one of theeasiest ways to improve the performance of thesystem is to increase the number of patterns.
Cur-rently the average number of patterns per lan-guage is 42.
Improvement of the entailment en-gines is another direction which needs to be pur-sued.
Most of the partners involved in the projecthave more powerful entailment engines thanthose integrated in the prototype which wereranked highly in RTE competitions.
Unfortu-nately, many of these engines cannot be used di-rectly in our system due to their slow speed.
Oursystem is supposed to give users results in realtime which imposes some constraints on theamount of processing that can be done.5 ConclusionsThis paper presented the first prototype of anentailment-based QA system, which can answerquestions about movies and cinema.
The use of adomain ontology ensures that the system is cross-language and can be extended to new languageswith slight adjustments at the entailment engine.The system is implemented as a set of web ser-vices and along a Service Oriented Architecture.6 AcknowledgementsThis work is supported by the EU-funded pro-ject QALL-ME (FP6 IST-033860).ReferencesAndroutsopoulos, I. and G.D. Ritchie and P. Thanisch.1995.
Natural Language Interfaces to Databases --An Introduction, Journal of Natural Language En-gineering, vol.1, no.1, Cambridge University Press.Popescu Ana-Marie, Oren Etzioni, and Henry Kautz.2003.
Towards a theory of natural language inter-faces to databases.
In Proceedings of the confer-ence on Intelligent User Interfaces.Dagan Ido and Oren Glickman.
2004.
Probabilistictextual entailment: Generic applied modeling oflanguage variability.
In PASCAL Workshop onLearning Methods for Text Understanding andMining, Grenoble.Ou Shiyan, Viktor Pekar, Constantin Orasan, Chris-tian Spurk, Matteo Negri.
2008.
Development andalignment of a domain-specific ontology for ques-tion answering.
In Proceedings of the 6th Edition ofthe Language Resources and Evaluation Confer-ence (LREC-08).Prud'hommeaux Eric, Andy Seaborne (eds.).
2006.SPARQL Query Language for RDF.
RDF Data Ac-cess Working Group.176
