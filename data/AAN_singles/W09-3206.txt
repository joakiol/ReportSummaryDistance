Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing, ACL-IJCNLP 2009, pages 41?49,Suntec, Singapore, 7 August 2009.c?2009 ACL and AFNLPWikiWalk: Random walks on Wikipedia for Semantic RelatednessEric Yeh, Daniel Ramage,Christopher D. ManningComputer Science Department,Stanford UniversityStanford, CA, USA{yeh1,dramage,manning}@cs.stanford.eduEneko Agirre, Aitor SoroaIxa TaldeaUniversity of the Basque CountryDonostia, Basque Country{e.agirre,a.soroa}@ehu.esAbstractComputing semantic relatedness of naturallanguage texts is a key component of taskssuch as information retrieval and sum-marization, and often depends on knowl-edge of a broad range of real-world con-cepts and relationships.
We address thisknowledge integration issue by comput-ing semantic relatedness using person-alized PageRank (random walks) on agraph derived from Wikipedia.
This pa-per evaluates methods for building thegraph, including link selection strategies,and two methods for representing inputtexts as distributions over the graph nodes:one based on a dictionary lookup, theother based on Explicit Semantic Analy-sis.
We evaluate our techniques on stan-dard word relatedness and text similaritydatasets, finding that they capture similar-ity information complementary to existingWikipedia-based relatedness measures, re-sulting in small improvements on a state-of-the-art measure.1 IntroductionMany problems in NLP call for numerical mea-sures of semantic relatedness, including documentsummarization, information retrieval, and textualentailment.
Often, measuring the relatedness ofwords or text passages requires world knowledgeabout entities and concepts that are beyond thescope of any single word in the document.
Con-sider, for instance, the following pair:1.
Emancipation Proclamation2.
Gettysburg AddressTo correctly assess that these examples are re-lated requires knowledge of the United States CivilWar found neither in the examples themselves norin traditional lexical resources such as WordNet(Fellbaum, 1998).
Fortunately, a massive collabo-ratively constructed knowledge resource is avail-able that has specific articles dedicated to both.Wikipedia is an online encyclopedia containingaround one million articles on a wide variety oftopics maintained by over one hundred thousandvolunteer editors with quality comparable to thatof traditional encyclopedias.Recent work has shown that Wikipedia can beused as the basis of successful measures of se-mantic relatedness between words or text pas-sages (Strube and Ponzetto, 2006; Gabrilovich andMarkovitch, 2007; Milne and Witten, 2008).
Themost successful measure, Explicit Semantic Anal-ysis (ESA) (Gabrilovich and Markovitch, 2007),treats each article as its own dimension in a vec-tor space.
Texts are compared by first projectingthem into the space of Wikipedia articles and thencomparing the resulting vectors.In addition to article text, Wikipedia stores agreat deal of information about the relationshipsbetween the articles in the form of hyperlinks, infoboxes, and category pages.
Despite a long his-tory of research demonstrating the effectivenessof incorporating link information into relatednessmeasures based on the WordNet graph (Budanit-sky and Hirst, 2006), previous work on Wikipediahas made limited use of this relationship infor-mation, using only category links (Bunescu andPasca, 2006) or just the actual links in a page(Gabrilovich and Markovitch, 2007; Milne andWitten, 2008).In this work, we combine previous approachesby converting Wikipedia into a graph, mapping in-put texts into the graph, and performing randomwalks based on Personalized PageRank (Haveli-wala, 2002) to obtain stationary distributions thatcharacterize each text.
Semantic relatedness be-tween two texts is computed by comparing theirdistributions.
In contrast to previous work, weexplore the use of all these link types when con-41structing the Wikipedia graph, the intuition beingthese links, or some combination of them, con-tain additional information that would allow a gainover methods that use only just the article text.
Wealso discuss two methods for performing the initialmapping of input texts to the graph, using tech-niques from previous studies that utilized Word-Net graphs and Wikipedia article text.We find that performance is signficantly af-fected by the strategy used to initialize the graphwalk, as well as the links selected when con-structing the Wikipedia graph.
Our best systemcombines an ESA-initialized vector with randomwalks, improving on state-of-the-art results overthe (Lee et al, 2005) dataset.
An analysis ofthe output demonstrates that, while the gains aresmall, the random walk adds complementary re-latedness information not present in the page text.2 PreliminariesA wide range of different methods, from corpus-based distributional similarity methods, such asLatent Semantic Analysis (Landauer et al, 1998),to knowledge-based ones that employ structuredsources such as WordNet,1have been developedto score semantic relatedness and similarity.
Wenow review two leading techniques which we useas starting points for our approach: those that per-form random walks over WordNet?s graph struc-ture, and those that utilize Wikipedia as an under-lying data source.2.1 Random Graph Walks for SemanticRelatednessSome of the best performing WordNet-based al-gorithms for computing semantic relatedness arebased on the popular Personalized PageRank al-gorithm (Hughes and Ramage, 2007; Agirre andSoroa, 2009).
These approaches start by takingWordNet as a graph of concepts G = (V,E) witha set of vertices V derived from WordNet synsetsand a set of edges E representing relations be-tween synsets.
Both algorithms can be viewedas random walk processes that postulate the ex-istence of a particle that randomly traverses thegraph, but at any time may jump, or teleport, toa new vertex with a given teleport probability.
Instandard PageRank (Brin and Page, 1998), this tar-get is chosen uniformly, whereas for Personalized1See (Budanitsky and Hirst, 2006) for a survey.PageRank it is chosen from a nonuniform distribu-tion of nodes, specified by a teleport vector.The final weight of node i represents the propor-tion of time the random particle spends visiting itafter a sufficiently long time, and corresponds tothat node?s structural importance in the graph.
Be-cause the resulting vector is the stationary distri-bution of a Markov chain, it is unique for a par-ticular walk formulation.
As the teleport vectoris nonuniform, the stationary distribution will bebiased towards specific parts of the graph.
In thecase of (Hughes and Ramage, 2007) and (Agirreand Soroa, 2009), the teleport vector is used to re-flect the input texts to be compared, by biasing thestationary distribution towards the neighborhoodof each word?s mapping.The computation of relatedness for a word paircan be summarized in three steps: First, each inputword is mapped with to its respective synsets inthe graph, creating its teleport vector.
In the casewords with multiple synsets (senses), the synsetsare weighted uniformly.
Personalized PageRank isthen executed to compute the stationary distribu-tion for each word, using their respective teleportvectors.
Finally, the stationary distributions foreach word pair are scored with a measure of vectorsimilarity, such as cosine similarity.
The methodto compute relatedness for text pairs is analogous,with the only difference being in the first step allwords are considered, and thus the stationary dis-tribution is biased towards all synsets of the wordsin the text.2.2 Wikipedia as a Semantic ResourceRecent Wikipedia-based lexical semantic related-ness approaches have been found to outperformmeasures based on the WordNet graph.
Two suchmethods stand out: Wikipedia Link-based Mea-sure (WLM) (Milne and Witten, 2008), and Ex-plicit Semantic Analysis (ESA) (Gabrilovich andMarkovitch, 2007).WLM uses the anchors found in the body ofWikipedia articles, treating them as links to otherarticles.
Each article is represented by a list ofits incoming and outgoing links.
For word relat-edness, the set of articles are first identified bymatching the word to the text in the anchors, andthe score is derived using several weighting strate-gies applied to the overlap score of the articles?links.
WLM does not make further use of the linkgraph, nor does it attempt to differentiate the links.42In contrast to WLM, Explicit Semantic Analy-sis (ESA) is a vector space comparison algorithmthat does not use the link structure, relying solelyon the Wikipedia article text.
Unlike Latent Se-mantic Analysis (LSA), the underlying conceptspace is not computationally derived, but is insteadbased on Wikipedia articles.
For a candidate text,each dimension in its ESA vector corresponds toa Wikipedia article, with the score being the sim-ilarity of the text with the article text, subject toTF-IDF weighting.
The relatedness of two textsis computed as the cosine similarity of their ESAvectors.Although ESA reports the best results to dateon both the WordSim-353 dataset as well as theLee sentence similarity dataset, it does not utilizethe link structure, which motivated a combined ap-proach as follows.2.3 A Combined ApproachIn this work, we base our random walk algorithmsafter the ones described in (Hughes and Ramage,2007) and (Agirre et al, 2009), but use Wikipedia-based methods to construct the graph.
As in previ-ous studies, we obtain a relatedness score betweena pair of texts by performing random walks overa graph to compute a stationary distribution foreach text.
For our evaluations, the score is simplythe cosine similarity between the distributions.
Inthe following sections, we describe how we builtgraphs from Wikipedia, and how input texts areinitially mapped into these structures.3 Building a Wikipedia GraphIn order to obtain the graph structure of Wikipedia,we simply treat the articles as vertices, andthe links between articles as the edges.
Thereare several sources of pre-processed Wikipediadumps which could be used to extract the arti-cles and links between articles, including DBpe-dia (Auer et al, 2008), which provides a rela-tional database representation of Wikipedia, andWikipedia-Miner2, which produces similar infor-mation from Wikipedia dumps directly.
In thiswork we used a combination of Wikipedia-Minerand custom processing scripts.
The dump used inthis work is from mid 2008.As in (Milne and Witten, 2008), anchors inWikipedia articles are used to define links between2http://wikipedia-miner.sourceforge.netarticles.
Because of different distributional proper-ties, we explicitly distinguish three types of links,in order to explore their impact on the graph walk.Infobox links are anchors found in the infoboxsection of Wikipedia articles.
Article in-foboxes, when present, often enumeratedefining attributes and characteristics for thatarticle?s topic.Categorical links reference articles whose titlesbelong in the Wiki namespace ?Category,?as well as those with titles beginning with?List of.?
These pages are often just lists ofanchors to other articles, which may be use-ful for capturing categorical information thatroughly contains a mixture of hyponymy andmeronymy relations between articles.Content links are those that are not already clas-sified as infobox nor categorical, and are in-tended to represent the set of miscellaneousanchors found solely in the article body.These may include links already found in thecategorical and infobox categories.Links can be further factored out according togenerality, a concept introduced in (Gabrilovichand Markovitch, 2009).
We say that one articleis more general than another when the number ofinlinks is larger.
Although only a rough heuris-tic, the intuition is that articles on general top-ics will receive many links, whereas specific ar-ticles will receive fewer.
We will use +k notationfor links which point to more general articles, i.e.,where the difference in generality between sources and target t is #inlink(t)/#inlink(s) ?
k.We will use ?k for links to less general articles,i.e., #inlink(s)/#inlink(t) ?
k. Finally weuse =k when the generality is in the same orderof magnitude, i.e., when the link is neither +knor ?k.
The original notion of generality from(Gabrilovich and Markovitch, 2009) restricts con-sideration to only more general articles by one or-der of magnitude (+10), without reference to thelink types introduced above.Given the size of the Wikipedia graph, we ex-plored further methods inspired by (Gabrilovichand Markovitch, 2009) to make the graph smaller.We discarded articles with fewer than 2,000 non-stop words and articles with fewer than 5 outgoingand incoming links.
We will refer to the complete43graph as full and to this reduced graph as reduced.34 Initializing a Wikipedia Graph WalkIn order to apply Personalized PageRank to agiven passage of text or word, we need to con-struct a custom teleport vector, representing theinitial distribution of mass over the article nodes.In this section we introduce two such methods,one based on constructing a direct mapping fromindividual words to Wikipedia articles (which wecall dictionary-based initialization), and the otherbased directly on the results of ESA.
We will seeeach technique in turn.4.1 Dictionary based initializationGiven a target word, we would like to defineits teleport vector using the set of articles inWikipedia to which the word refers.
This is analo-gous to a dictionary, where an entry lists the set ofmeanings pertaining to the entry.We explored several methods for building sucha dictionary.
The first method constructed the dic-tionary using the article title directly, while alsoincluding redirection pages and disambiguationpages for additional ways to refer to the article.
Inaddition, we can use the anchor text to refer to arti-cles, and we turned to Wikipedia-Miner to extractthis information.
Anchors are indeed a rich sourceof information, as they help to relate similar wordsto Wikipedia articles.
For instance, links to pageMonk are created by using textual anchors such aslama, brothers, monastery, etc.
As a result, thedictionary entries for those words will have a linkto the Monk page.
This information turned out tobe very valuable, so all experiments have been car-ried out using anchors.An additional difficulty was that any of thesemethods yielded dictionaries where the entriescould refer to tens, even hundreds of articles.
Inmost of the cases we could see that relevant arti-cles were followed by a long tail of loosely relatedarticles.
We tried two methods to prune the dic-tionary.
The first, coarse, method was to eliminateall articles whose title contains a space.
The mo-tivation was that our lexical semantic relatednessdatasets (cf.
Section 5) do not contain multiwordentries (e.g., United States).
In the second method,we pruned articles from the dictionary which ac-3In order to keep category and infobox links, the 2,000non-stop word filter was not applied to categories and lists ofpages.GraphsGraph # Vertices # EdgesFull 2,483,041 49,602,752Reduced 1,002,411 30,939,288DictionariesDictionary # Entries Avg.
Articlesall 6,660,315 1.311% 6,660,306 1.121% noent 1,058,471 1.04Table 1: Graph and dictionary sizes.
Avg.
Articlescolumn details the average number of articles perentry.counted for less than 1% or 10% of the occur-rences of that anchor word, as suggested by (Milneand Witten, 2008).In short, for this method of initialization, we ex-plored the use of the following variants: all, all ar-ticles are introduced in the dictionary; noent, arti-cles with space characters are omitted; 1% (10%),anchors that account for less than 1% (10%) of thetotal number of anchors for that entry are omitted.We did not use stemming.
If a target word has nomatching Wikipedia article in the dictionary, thenit is ignored.Table 1 shows the numbers for some graph anddictionary versions.
Although the average numberof articles per entry in the dictionary might seemlow, it is actually quite high for the words in thedatasets: for MC it?s 5.92, and for wordsim353 it?s42.14.
If we keep the articles accounting for 10%of all occurrences, the numbers drops drasticallyto 1.85 and 1.64 respectively.As we will see in the results section, smallergraphs and dictionaries are able to attain higherresults, but at the cost of losing information forsome words.
That is, we observed that some fac-tored, smaller graphs contained less noise, but thatmeant that some articles and words are isolated inthe graph, and therefore we are not able to com-pute relatedness for them.
As a solution, we de-vised an alternative way to initialize the randomwalk.
Instead of initializing it according to the ar-ticles in the dictionary, we initialized it with thevector weights returned by ESA, as explained inthe next section.444.2 Initialization with ESAIn addition to the dictionary based approach, wealso explored the use of ESA to construct the tele-port vector.
In contrast to dictionary initialization,ESA uses the text of the article body instead of an-chor text or the article titles.
Because ESA mapsquery text to a weighted vector of Wikipedia arti-cles, it can be naturally adapted as a teleport vectorfor a random walk with a simple L1normaliza-tion.
We used Apache Lucene4to implement bothESA?s repository of Wikipedia articles, and to re-turn vectors for queries.
Each article is indexed asits own document, with page text preprocessed tostrip out Wiki markup.Although we followed the steps outlined in(Gabrilovich and Markovitch, 2007), we had toadd an extension to the algorithm: for a returnvector from ESA, we order the articles by score,and retain only the scores for the top-n articles,setting the scores of the remaining articles to 0.Without this modification, our performance resultswere will below the reported numbers, but with acutoff at 625 (determined by a basic grid search),we obtained a correlation of 0.76 on the Lee sen-tence similarity dataset, over the previously pub-lished score of 0.72.4.3 Teleport ProbabilityFor this work, we used a value of 0.15 as the prob-ability of returning to the teleport distribution atany given step.
The walk terminates when the vec-tor converges with an L1error of 0.0001 (circa 30iterations).
Some preliminary experiments on a re-lated Word Sense Disambiguation task indicatedthat in this context, our algorithm is quite robust tothese values, and we did not optimize them.
How-ever, we will discuss using different return param-eters in Section 6.1.5 ExperimentsIn this section, we compare the two methods ofinitialization as well as several types of edges.
Fora set of pairs, system performance is evaluated byhow well the generated scores correlate with thegold scores.
Gold scores for each pair are the av-erage of human judgments for that pair.
In order tocompare against previous results obtained on thedatasets, we use the Spearman correlation coeffi-cient on the Miller Charles (MC) and WordSim-353 word-pair datasets, and the Pearson correla-4http://lucene.apache.orgDictionary Graph MCall full 0.3691% full 0.6101%, noent full 0.565 (0.824)1% reduced 0.5631% reduced +2 0.5301% reduced +4 0.6011% reduced +8 0.5121% reduced +10 0.491 (0.522)10% full 0.604 (0.750)10% reduced 0.605 (0.751)10% reduced +2 0.491 (0.540)10% reduced +4 0.476 (0.519)10% reduced +8 0.474 (0.506)10% reduced +10 0.430 (0.484)WordNet 0.90 / 0.89WLM 0.70ESA 0.72Table 2: Spearman correlation on the MC datasetwith dictionary-based initialization.
Refer to Sec-tion 3 for explanation of dictionary and graphbuilding methods.
Between parenthesis, resultsexcluding pairs which had a word with an emptydictionary entry.tion coefficient on the (Lee et al, 2005) document-pair dataset.5.1 Dictionary-based InitializationGiven the smaller size of the MC dataset, weexplored the effect of the different variants tobuild the graph and dictionary on this dataset.Some selected results are shown in Table 2, along-side those of related work, where we used Word-Net for (Hughes and Ramage, 2007) and (Agirreet al, 2009) (separated by ?/?
in the results),WLM for (Milne and Witten, 2008) and ESA for(Gabrilovich and Markovitch, 2007).We can observe that using the full graph anddictionaries yields very low results.
Reducing thedictionary (removing articles with less than 1% or10% of the total occurrences) produces higher re-sults, but reducing the graph does not provide anyimprovement.
On a closer look, we realized thatpruning the dictionary to 10% or removing multi-words (noent) caused some words to not get anylink to articles (e.g., magician).
If we evaluateonly over pairs where both words get a Personal-ized PageRank vector, the results raise up to 0.751and 0.824, respectively, placing our method close45Dictionary Graph WordSim-3531% full 0.4491%, noent full 0.440 (0.634)1% reduced 0.485WordNet 0.55 / 0.66WLM 0.69ESA 0.75WikiRelate 0.50Table 3: Spearman correlation on the WordSim-353 dataset with dictionary-based initialization.Refer to Section 3 for explanation of dictionaryand graph building methods.
Between parenthe-sis, results excluding pairs which had a word withan empty dictionary entry.Dictionary Graph (Lee et al, 2005)1%, noent Full 0.3081% Reduced +4 0.269ESA 0.72Table 4: Pearson correlation on (Lee et al, 2005)with dictionary-based initialization.
Refer to Sec-tion 3 for explanation of dictionary and graphbuilding methods.to the best results on the MC dataset.
This cameat the cost of not being able to judge the related-ness of 3 and 5 pairs, respectively.
We think thatremoving multiwords (noent) is probably too dras-tic, but the positive effect is congruent with (Milneand Witten, 2008), who suggested that the cover-age of certain words in Wikipedia is not adequate.The results in Table 3 show the Spearman cor-relation for some selected runs over the WordSim-353 dataset.
Again we see that a restrictive dic-tionary allows for better results on the pairs whichdo get a dictionary entry, up to 0.63.
WikiRelaterefers to the results in (Strube and Ponzetto, 2006).We only tested a few combinations over (Lee etal., 2005), with results given in Table 4.
These arewell below state-of-the-art, and show that initial-izing the random walk with all words in the doc-ument does not characterize the documents well,resulting in low correlation.5.2 ESA-based initializationWhile the results using a dictionary based ap-proach were encouraging, they did not come closeto the state-of-the-art results achieved by ESA.Here, we explore combining ESA and randomMethod Text SimESA@625 0.766ESA@625+Walk All 0.556ESA@625+Walk Categories 0.410ESA@625+Walk Content 0.536ESA@625+Walk Infobox 0.710Table 5: Pearson correlation on the (Lee et al,2005) dataset when walking on various types oflinks.
Note that walking tends to hurt performanceoverall, with Infobox links by far the least harm-ful.walks, by using ESA to initialize the teleport vec-tor.
Following section 4.2, we used a top-n cutoffof 625.Table 5 displays the results of our ESA im-plementation followed by a walk from that ESAdistribution.
Walking on any link type actuallydepresses performance below the baseline ESAvalue, although the Infobox links seem the leastharmful.However, as mentioned in Section 3, links be-tween articles represent many different types ofrelationships beyond the few well-defined linkspresent in lexical resources like WordNet.
Thisalso extends to where the link is found, and the ar-ticle it is pointing to.
As such, not all links are cre-ated equal, and we expect that some types of linksat different levels of generality will perform bet-ter or worse than others.
Table 6 presents a sam-ple grid search across the category links choosingmore general, less general, or similar generality atseveral factors of k, showing that there is a consis-tent pattern across multiple link types.
Note thatthe best value indeed improves upon the score ofthe ESA distribution, albeit modestly.We performed a similar analysis across all linktypes and found that the best link types were Cat-egory links at +6 and Infobox links at =2.
Intu-itively, these link types make sense: for seman-tic relatedness, it seem reasonable to expect moregeneral pages within the same category to help.And for Infobox links, much rarer and much morecommon pages can both introduce their own kindof noise.
While the improvement from each typeof edge walk is small, they are additive?the bestresults on the sentence similarity dataset was fromwalking across both link types.
Our final Pearsoncorrelation coefficient of .772 is to our knowledgethe highest number reported in the literature, al-46Generality of Category links+k -k =kk = 2 0.760 0.685 0.462k = 4 0.766 0.699 0.356k = 6 0.771 0.729 0.334k = 8 0.768 0.729 0.352k = 10 0.768 0.720 0.352Table 6: Pearson correlation on the (Lee et al,2005) with random walks over only a subset ofthe edges in the Category link information (scores.410 when taking all edges).
Note that factoringthe graph by link generality can be very helpful tothe walk.Method Text SimESA@625 0.766ESA@625+Walk Cat@+6 0.770ESA@625+Walk Cat@+6 Inf@=2 0.772Bag of words (Lee et al, 2005) 0.5LDA (Lee et al, 2005) 0.60ESA* 0.72Table 7: Pearson correlation on the (Lee et al,2005) dataset for our best sytems compared to pre-viously reported numbers.
ESA* is the score forraw ESA as reported number in (Gabrilovich andMarkovitch, 2007).beit only a small improvement over our ESA@625score.Despite the results obtained for text similarity,the best settings found for the Lee dataset did nottranslate to consistent improvements over the ESAbaseline for Spearman rank correlation on the lex-ical similarity datasets.
While our scores on theMC dataset of 30 word pairs did improve with thewalk in roughly the same way as in Lee, no suchimprovements were found on the larger WordSim-353 data.
On WordSim-353, our implementa-tion of ESA scored 0.709 (versus Gabrilovich?sreported ESA score of 0.75), and our walk onCat@+6 showing no gain or loss.
In contrast tothe text similarity dataset, Infobox links were nolonger helpful, bringing the correlation down to.699.
We believe this is because Infobox linkshelped the most with entities, which are very rarein the WordSim-353 data, but are more commonin the Lee dataset.6 DiscussionOur results suggest that even with a simpledictionary-based approach, the graph of Wikipedialinks can act as an effective resource for comput-ing semantic relatedness.
However, the dictio-nary approach alone was unable to reach the re-sults of state-of-the-art models using Wikipedia(Gabrilovich and Markovitch, 2007; Milne andWitten, 2008) or using the same technique onWordNet (Hughes and Ramage, 2007; Agirreet al, 2009).
Thus, it seems that the text ofWikipedia provides a stronger signal than the linkstructure.
However, a pruned dictionary can im-prove the results of the dictionary based initial-ization, which indicates that some links are in-formative for semantic relatedness while othersare not.
The careful pruning, disambiguation andweighting functions presented in (Milne and Wit-ten, 2008) are directions for future work.The use of WordNet as a graph provided ex-cellent results (Hughes and Ramage, 2007), closeto those of ESA.
In contrast with our dictionary-based initialization on Wikipedia, no pruning ofdictionary or graph seem necessary to obtain highresults with WordNet.
One straightforward expla-nation is that Wikipedia is a noisy source of linkinformation.
In fact, both ESA and (Milne andWitten, 2008) use ad-hoc pruning strategies in or-der to obtain good results.6.1 ESA and Walk ComparisonBy using ESA to generate the teleport distribu-tion, we were able to introduce small gains us-ing the random walk.
Because these gains weresmall, it is plausible that the walk introduces onlymodest changes from the initial ESA teleport dis-tributions.
To evaluate this, we examined the dif-ferences between the vector returned by ESA anddistribution over the equivalent nodes in the graphafter performing a random walk starting with thatESA vector.For this analysis, we took all of the text entriesused in this study, and generated two distributionsover the Wikipedia graph, one using ESA@625,the other the result of performing a random walkstarting at ESA@625.
We generated a list of theconcept nodes for both distributions, sorted in de-creasing order by their associated scores.
Start-ing from the beginning of both lists, we thencounted the number of matched nodes until theydisagreed on ordering, giving a simple view of47Walk Type Avg Std MaxMC Cat@+6 12.1 7.73 35Cat@+6 Inf@=2 5.39 5.81 20WordSim Cat@+6 12.0 10.6 70Cat@+6 Inf@=2 5.74 7.78 54Lee Cat@+6 28.3 89.7 625Cat@+6 Inf@=2 4.24 14.8 103Table 8: Statistics for first concept match length,by run and walk type.how the walk perturbed the strongest factors in thegraphs.
We performed this for both the best per-forming walk models (ESA@625+Walk Cat@+6and ESA@625+Walk Cat@+6 Inf@=2) againstESA@625.
Results are given in Table 8.As expected, adding edges to the random walkincreases the amount of change from the graph,as initialized by ESA.
A cursory examination ofthe distributions also revealed a number of outlierswith extremely high match lengths: these werelikely due to the fact that the selected edge typeswere already extremely specialized.
Thus for anumber of concept nodes, it is likely they did nothave any outbound edges at all.Having established that the random walk doesindeed have an impact on the ESA vectors, thenext question is if changes via graph walk areconsistently helpful.
To answer this, we com-pared the performance of the walk on the (Lee etal., 2005) dataset for probabilities at selected val-ues, using the best link pruned Wikipedia graph(ESA@625+Walk Cat@+6 Inf@=2), and using allof the available edges in the graph for compari-son.
Here, a lower probability means the distribu-tion spreads out further into the graph, comparedto higher values, where the distribution varies onlyslightly from the ESA vector.
Results are given inTable 9.
Performance for the pruned graph im-proves as the return probability decreases, withlarger changes introduced by the graph walk re-sulting in better scores, whereas using all availablelinks decreases performance.
This reinforces thenotion that Wikipedia links are indeed noisy, butthat within a selected edge subset, making use ofall information via the random walk indeed resultsin gains.7 ConclusionThis paper has demonstrated that performing ran-dom walks with Personalized PageRank over theProb Corr (Pruned) Corr (All)0.01 0.772 0.2460.10 0.773 0.5000.15 0.772 0.5560.30 0.771 0.6820.45 0.769 0.7370.60 0.767 0.7580.90 0.766 0.7660.99 0.766 0.766Table 9: Return probability vs. correlation, on tex-tual similarity data (Lee et al, 2005).Wikipedia graph is a feasible and potentially fruit-ful means of computing semantic relatedness forwords and texts.
We have explored two methods ofinitializing the teleport vector: a dictionary-basedmethod and a method based on ESA, the cur-rent state-of-the-art technique.
Our results showthe importance of pruning the dictionary, and forWikipedia link structure, the importance of bothcategorizing by anchor type and comparative gen-erality.
We report small improvements over thestate-of-the-art on (Lee et al, 2005) using ESA asa teleport vector and a limited set of links fromWikipedia category pages and infoboxes.In future work, we plan to explore new waysto construct nodes, edges, and dictionary entrieswhen constructing the Wikipedia graph and dic-tionary.
We believe that finer grained methods ofgraph construction promise to improve the valueof the Wikipedia link structure.
We also plan tofurther investigate the differences between Word-Net and Wikipedia and how these may be com-bined, from the perspective of graph and randomwalk techniques.
A public distribution of softwareused for these experiments will also be made avail-able.5AcknowledgementsThe authors would like to thank Michael D. Leeand Brandon Pincombe for access to their textualsimilarity dataset, and the reviewers for their help-ful comments.
Eneko Agirre performed part ofthe work while visiting Stanford, thanks to a grantfrom the Science Ministry of Spain.5Please see http://nlp.stanford.edu/software and http://ixa2.si.ehu.es/ukb48ReferencesE.
Agirre and A. Soroa.
2009.
Personalizing pager-ank for word sense disambiguation.
In Proceedingsof 14th Conference of the European Chapter of theAssociation for Computational Linguistics, Athens,Greece.E.
Agirre, E. Alfonseca, K. Hall, J. Kravalova,M.
Pasc?a, and A. Soroa.
2009.
A study on similarityand relatedness using distributional and WordNet-based approaches.
In Proceedings of the NorthAmerican Chapter of the Association for Computa-tional Linguistics - Human Language Technologies,Boulder, USA.S Auer, C Bizer, G Kobilarov, J Lehmann, R Cyganiak,and Z Ives.
2008.
Dbpedia: A nucleus for a webof open data.
In Proceedings of 6th InternationalSemantic Web Conference, 2nd Asian Semantic WebConference (ISWC+ASWC 2007), pages 722?735.S.
Brin and L. Page.
1998.
The anatomy of a large-scale hypertextual web search engine.
ComputerNetworks and ISDN Systems, 30(1-7).A.
Budanitsky and G. Hirst.
2006.
EvaluatingWordNet-based measures of lexical semantic relat-edness.
Computational Linguistics, 32(1):13?47.R.
C. Bunescu and M. Pasca.
2006.
Using encyclo-pedic knowledge for named entity disambiguation.In Proceedings of 11th Conference of the EuropeanChapter of the Association for Computational Lin-guistics.C.
Fellbaum.
1998.
WordNet: An electronic lexicaldatabase.
MIT Press.E.
Gabrilovich and S. Markovitch.
2007.
Computingsemantic relatedness using Wikipedia-based explicitsemantic analysis.
In Proceedings of the 20th Inter-national Joint Conference on Artificial Intelligence(IJCAI-07).E.
Gabrilovich and S. Markovitch.
2009.
Wikipedia-based semantic interpretation.
Journal of ArtificialIntelligence Research, 34:443?498.T.
H. Haveliwala.
2002.
Topic-sensitive pagerank.
InWWW ?02, pages 517?526, New York, NY, USA.ACM.T.
Hughes and D. Ramage.
2007.
Lexical semantic re-latedness with random graph walks.
In Proceedingsof EMNLP-CoNLL, pages 581?589.T.
K. Landauer, P. W. Foltz, and D. Laham.
1998.
Anintroduction to latent semantic analysis.
DiscourseProcesses, 25(2-3):259?284.M.
D. Lee, B. Pincombe, and M. Welsh.
2005.
An em-pirical evaluation of models of text document sim-ilarity.
In Proceedings of the 27th Annual Confer-ence of the Cognitive Science Society, pages 1254?1259, Mahwah, NJ.
Erlbaum.D.
Milne and I.H.
Witten.
2008.
An effective, low-cost measure of semantic relatedness obtained fromWikipedia links.
In Proceedings of the first AAAIWorkshop on Wikipedia and Artifical Intellegence(WIKIAI?08), Chicago, I.L.M.
Strube and S.P.
Ponzetto.
2006.
Wikirelate!
com-puting semantic relatedness using Wikipedia.
InProceedings of the 21st National Conference on Ar-tificial Intelligence, pages 1419?1424.49
