Splittability of Bilexical Context-FreeGrammars is UndecidableMark-Jan Nederhof?University of St. AndrewsGiorgio Satta?
?University of PaduaBilexical context-free grammars (2-LCFGs) have proved to be accurate models for statisticalnatural language parsing.
Existing dynamic programming algorithms used to parse sentencesunder these models have running time of O(|w|4), where w is the input string.A 2-LCFG is splittable if the left arguments of a lexical head are always independentof the right arguments, and vice versa.
When a 2-LCFGs is splittable, parsing time can beasymptotically improved to O(|w|3).
Testing this property is therefore of central interest toparsing efficiency.
In this article, however, we show the negative result that splittability of2-LCFGs is undecidable.1.
IntroductionBilexical context-free grammars, or 2-LCFGs for short, are specialized context-freegrammars where each nonterminal is associated with a terminal symbol representing alexical element of the language of interest.
Furthermore, no more than two symbols canbe used in the right-hand side of a rule, and the terminal symbol associated with the left-hand side of a rule must also occur on the right-hand side.
In this way, 2-LCFGs are ableto specify syntactic constraints as well as lexically specific preferences that influencethe combination of predicates with their arguments or modifiers.
Models based on2-LCFGs have therefore been of central interest in statistical natural language parsing, asthey allow selection of high-quality parse trees.
One can in fact see 2-LCFGs as abstractmodels of the head automata of Alshawi (1996), the probabilistic projective dependencygrammars of Eisner (1996), and the head-driven statistical models of Charniak (2001)and Collins (2003).Parsing algorithms based on 2-LCFGs can be very efficient.
In the general case,existing dynamic programming algorithms have running time of O(|w|4), where w isthe input string.
(In this article we disregard complexity factors that depend on theinput grammar, which we will consider to be constants.)
In cases in which, for each(lexical) head, the two processes of generating its left and right arguments are, to some?
School of Computer Science, University of St. Andrews, North Haugh, St. Andrews, Fife, KY16 9SX,Scotland.
E-mail: markjan.nederhof@gmail.com.??
Department of Information Engineering, University of Padua, via Gradenigo 6/A, I-35131 Padova, Italy.E-mail: satta@dei.unipd.it.Submission received: 8 September 2010; revised submission received: 21 January 2011; accepted forpublication: 17 April 2011.?
2011 Association for Computational LinguisticsComputational Linguistics Volume 37, Number 4extent, independent one of the other, parsing based on 2-LCFGs can be asymptoticallyimproved to O(|w|3).
The reader is referred to Eisner and Satta (1999) for a detailedpresentation of these computational results.In the literature, this condition on independence between left and right argumentsof each head has been called splittability (Eisner 1997; Eisner and Satta 1999).
Testingfor splittability on an input 2-LCFG is therefore of central interest to parsing efficiency.The computability of this test has never been investigated, however.In this article splittability is defined for 2-LCFGs in terms of equivalence to anothergrammar in which independence between left and right arguments of each head isensured by a simple syntactic restriction.
This restriction is called split form.
Informally,a 2-LCFG is in split form if it can be factorized into individual subgrammars, one foreach head, and each subgrammar produces the left and the right arguments of its headthrough two derivation processes, one happening strictly after the other.One may believe that a necessary and sufficient condition for splittability is that a2-LCFG does not allow recursive structures that alternately generate left (L) and right(R) arguments of some head a.
These structures could well result in subderivationsproducing sequences of the form LnaRn, for any n ?
0, which would appear to precludethe application of the O(|w|3) algorithm.This situation, however, does not mean in general that the grammar is not splittable.Although a subset of the rules in a grammar may generate structures such as those justdiscussed, there may be additional rules that make the observed dependencies betweenleft and right arguments irrelevant.
In fact, splittability of a 2-LCFG is undecidable, aswill be shown in this article.Our result is based on the fact that it is undecidable whether a linear context-freegrammar with a center marker (to be defined later) generates a regular language.
Thisfact is originally proved in this article, and does not follow from the weaker result stat-ing the undecidability of regularity of (general) linear context-free languages, which iswell known in the formal language literature (Hopcroft and Ullman 1979, exercise 8.10a,page 214) and which is originally due to Hunt III and Rosenkrantz (1974).The remaining part of this article is organized as follows.
In Section 2 we presentsome preliminary background, and in Section 3 we define 2-LCFGs and the notionof splittability.
In Section 4 we prove the main result of this article, and draw someconclusions in Section 5.2.
PreliminariesIn this article we assume the reader is familiar with the notions of context-free grammar,Turing machine, and undecidability (see, e.g., Hopcroft and Ullman 1979).
We brieflysummarize the adopted notation now.A context-free grammar (CFG) is a 4-tuple G = (?, N, S, R), where ?
is a finite setof terminals, N is a finite set of nonterminals, disjoint from ?
and including the startsymbol S, and R is a finite set of rules.
Each rule has the form A ?
?, where A ?
N and?
?
(?
?N)?.
A CFG is called linear if each rule A ?
?
has at most one nonterminal inthe right-hand side ?.We associate with G a binary relation called rewrite and denoted by the symbol?G, defined such that ?A??
?G ????
if A ?
?
is a rule in R and ?,??
?
(?
?N)?.
Wedrop subscript G from ?G whenever it is understood from the context.
The reflexiveand transitive closure of?
is denoted as??.
The language generated by G is definedas L(G) = {w ?
??
|S ??
w}.868Nederhof and Satta Splittability of 2-LCFGsWe now introduce a special class of CFGs that will play a central role in the proofsin this article.
Assume a distinguished symbol # ?
?, which we will refer to as a centermarker.
The class of linear CFGs with center marker #, or lin-CFG(#) for short, is theclass of CFGs in which each rule either has the form A ?
# or the form A ?
uBv,where A,B ?
N and u, v ?
(?
\ {#})?, where symbol ?\?
denotes set difference.
Wesay a grammar in lin-CFG(#) is in binary form if the total length of u and v in rulesA ?
uBv is at most 1.
It is not difficult to see that there is a language-preservingtransformation of grammars in lin-CFG(#) to binary form, as suggested by the followingexample.Example 1Let ?
= {a, b, #}.
One member of lin-CFG(#) is the CFG G defined by the rules:S ?
a S a,S ?
a S b,S ?
b S a,S ?
b S b,S ?
#.For this grammar, strings in L(G) have the form u#v, with u ?
(?
\ {#})?
and v ?
(?
\{#})?
having the same length.A rule such as S ?
aSb can be replaced by a pair of rules in binary form, for exampleS ?
aA and A ?
Sb, where A is a new nonterminal.3.
Bilexical CFGs and SplittabilityWe start this section with the definition of 2-LCFG, which is based on Eisner andSatta (1999).
Let ND be a finite alphabet whose symbols will be called delexicalizednonterminals.
We combine ND with a set ?
of terminal symbols as follows:ND(?)
= {A[a] |A ?
ND, a ?
?
}.A bilexical context-free grammar is a CFG G = (?, ND(?)
?
{S}, S, R).
Every rule in Rhas one of the following five forms: S ?
A[a]; A[a]?
B[b] C[a]; A[a]?
B[a] C[c]; A[a]?
B[a]; A[a]?
a.The nonterminal occurrences C[a] and B[a] in the second and third rules, respectively,and the nonterminal occurrence B[a] in the fourth rule will be referred to as head childoccurrences.
Notice that the head child of a rule is always associated with the sameterminal as the left-hand-side nonterminal.
The nonterminal occurrence A[a] in thefirst rule, and the nonterminal occurrences B[b] and C[c] in the second and third rules,respectively, will be referred to as maximal projection occurrences.
Observe how in a869Computational Linguistics Volume 37, Number 4parse tree generated by a 2-LCFG, each occurrence of a lexical element (represented asa terminal symbol) is also part of several head child occurrences of nonterminals aboveit, up to some unique maximal projection occurrence.
We assume that the head childoccurrence in a rule is always marked within the rule itself, in order to disambiguatecases in which the head child and the maximal projection share the same terminal (a = bin the second rule or a = c in the third).1Let G = (?, N, S, R) be a 2-LCFG and choose some A[a] ?
N that occurs as maximalprojection in some rule in R. We now define a grammar G(A[a]) = (?
(A[a]), N(A[a]), A[a],R(A[a]) ) in lin-CFG(a).
The main idea here is that G(A[a]) captures all descending paths inparse trees of G from any maximal projection occurrence of A[a] down to a, treating themaximal projection occurrences of G?s nonterminals to the left and right of these pathsas terminal symbols of G(A[a]).
Each such maximal projection nonterminal B[b], whentreated as a terminal, will be denoted as B[b].
The start symbol is A[a] and the rule setR(A[a]) is specified as follows: D[a]?
B[b] C[a] is in R(A[a]) for each rule D[a]?
B[b] C[a] in R; D[a]?
B[a] C[c] is in R(A[a]) for each rule D[a]?
B[a] C[c] in R; D[a]?
B[a] is in R(A[a]) for each rule D[a]?
B[a] in R; D[a]?
a is in R(A[a]) for each rule D[a]?
a in R.Grammar G(A[a]) might contain useless rules, that is, rules that never appear in a deriva-tion of a string of the generated language, but this is irrelevant to the development ofthe results in this article.We now introduce an equivalence relation on 2-LCFGs, which will be used laterin the definition of splittability.
As we will see, our equivalence relation is strongerthan the usual weak equivalence between grammars, where the latter only requiresthat the languages generated by two grammars be the same.
In addition to weakequivalence, we demand that two 2-LCFGs establish the same predicate?argumentdependencies between lexical elements in the generated sentences, as will be explainedhere.Definition 1Two 2-LCFGs G1 and G2 are d-equivalent if the following conditions are all satisfied:1.
G1 and G2 have the same set of nonterminals that occur as maximalprojections;2.
G1 and G2 have the same rules rewriting the start symbol, that is, the rulesof the form S ?
A[a]; and3.
for each nonterminal A[a] that occurs as a maximal projection in G1 andG2, the grammars G(A[a])1 and G(A[a])2 generate the same languages.Lemma 1If two 2-LCFGs G1 and G2 are d-equivalent, then L(G1) = L(G2).1 One way to formalize this marking is to have a separate subset of delexicalized nonterminals that are partof each maximal projection occurrence and never a part of any head child occurrence.870Nederhof and Satta Splittability of 2-LCFGsProofWe show the stronger statement that, for each maximal projection occurrence A[a] fromG1 and G2 (item 1 in Definition 1) and for each w ?
?
?, we have A[a]?
?G1 w if and onlyif A[a]?
?G2 w. The statement of the lemma easily follows from item 2 in Definition 1.
Weproceed by induction on |w|.Assume |w| = 1, w = a.
If A[a]?
?G1 a, then A[a]??G(A[a])1a.
From item 3 in Defini-tion 1 we also have A[a]?
?G(A[a])2a and hence A[a]?
?G2 a.
The converse statement isshown similarly.Assume now |w| > 1.
If A[a]?
?G1 w, there must be a ?head-driven?
derivationrewriting maximal projection occurrence A[a] into a through a chain of head childnonterminal occurrences.
More precisely, we can write:A[a] ?
?G1 B1[b1] ?
?
?Bl[bl]aC1[c1] ?
?
?Cr[cr]?
?G1 uaC1[c1] ?
?
?Cr[cr]?
?G1 uav = w (1)with l, r ?
0, l+ r > 0 (because |w| > 1), and the indicated occurrence of a in uav isgenerated fromA[a] through a chain of rule applications always rewriting the head childof the previous rule and generating the maximal projection occurrences Bi[bi], 1 ?
i ?
l,and Cj[cj], 1 ?
j ?
r.Due to Equation (1) we have A[a]?
?G(A[a])1B1[b1] ?
?
?Bl[bl]aC1[c1] ?
?
?Cr[cr] and fromitem 3 in Definition 1 we have A[a]?
?G(A[a])2B1[b1] ?
?
?Bl[bl]aC1[c1] ?
?
?Cr[cr].
We thus con-clude that A[a]?
?G2 B1[b1] ?
?
?Bl[bl]aC1[c1] ?
?
?Cr[cr].From Equation (1) we can also see that there must be strings ui, 1 ?
i ?
l and vj,1 ?
j ?
r, such that Bi[bi]?
?G1 ui and Cj[bj]?
?G1vj, where u1 ?
?
?
ul = u and v1 ?
?
?
vr = v.Because each Bi[bi] and each Cj[cj] is a maximal projection occurrence, we can apply theinductive hypothesis and conclude that Bi[bi]?
?G2 ui and Cj[bj]?
?G2vj, 1 ?
i ?
l and1 ?
j ?
r.Putting together all of this, we have A[a]?
?G2 u1 ?
?
?
ulav1 ?
?
?
vr = w. With a similarargument we can show that A[a]?
?G2 w implies A[a]??G1w.
Besides enforcing the weak equivalence between two 2-LCFGs, the d-equivalencerelation guarantees that the grammars establish the same dependencies between pairsof lexical elements in the generated sentences.
To explain this, we borrow subsequentlythe notion of dependency structure from dependency grammars.Let G be a 2-LCFG and let t be a parse tree assigned by G to a string w ?
?
?.We can associate with t a dependency structure, by considering all rule occurrencesin t that link two lexical elements from w. For each rule occurrence A[a]?
B[b] C[a]in t, a link is constructed from the corresponding occurrence of b in w to the corre-sponding occurrence of a.
Similarly, a rule occurrence A[a]?
B[a] C[c] gives rise toa link from the corresponding occurrence of c to the corresponding occurrence of a.Notice that a dependency structure abstracts away from some topological aspects ofthe parse trees.
For example, two rules A[a]?
B[a] C[c] and B[a]?
D[d] E[a] could giverise to the same dependency structures as the two rules A[a]?
D[d] F[a] and F[a]?E[a] C[c].It is not difficult to see that if two 2-LCFGs G1 and G2 are d-equivalent, then the setsof dependency structures they assign to strings in the common language (via the set ofparse trees as sketched above) are identical.871Computational Linguistics Volume 37, Number 4Example 2Consider the 2-LCFG G1 defined by the rules:S ?
A[a], A[a] ?
a,A[a] ?
B[b] A[a], B[b] ?
b,A[a] ?
C[c] A[a], C[c] ?
c,A[a] ?
A[a] D[d], D[d] ?
d,A[a] ?
A[a] E[e], E[e] ?
e;and the 2-LCFG G2 defined by the rules:S ?
A[a], A?
[a] ?
a,A[a] ?
B[b] A[a], B[b] ?
b,A[a] ?
C[c] A[a], C[c] ?
c,A[a] ?
A?
[a], D[d] ?
d,A?
[a] ?
A?
[a] D[d], E[e] ?
e,A?
[a] ?
A?
[a] E[e].G1 and G2 are d-equivalent, and thus generate the same language by Lemma 1.
Thislanguage consists of all strings of the form uav, where u ?
{b, c}?
and v ?
{d, e}?.
Fur-thermore, the set of dependency structures associated by G1 and G2 to any of the stringsthey can generate are the same.
Figure 1 shows one instance of such a correspondence.Note that in addition to the tree in Figure 1(a), there are two more trees generated bygrammar G1 that correspond to the dependency structure in Figure 1(c).Figure 1Two parse trees for the string bcad under grammars G1 (a) and G2 (b) from Example 2.
Both treescorrespond to the same associated dependency structure (c).872Nederhof and Satta Splittability of 2-LCFGsWe conclude this section with the definition of splittability, which is central to thisarticle.
We first introduce a special form for 2-LCFGs, which we call split form.
Theintuition is that a 2-LCFG is in split form if, for each maximal projection nonterminaloccurrence A[a], all arguments on the left are generated first, followed by the generationof all arguments on the right.Definition 2A 2-LCFG G = (?,ND(?)
?
{S}, S, R) is in split form if, for each maximal projectionoccurrence of a nonterminal A[a] ?
ND(?
), the nonterminals in G(A[a]) can be dividedinto two disjoint sets N(A[a])land N(A[a])r , such that A[a] ?
N(A[a])land all of the followingconditions are satisfied:1. if D[a]?
B[b] C[a] in R(A[a]), then D[a],C[a] ?
N(A[a])l;2. if D[a]?
B[a] C[c] in R(A[a]), then D[a],B[a] ?
N(A[a])r ;3. if D[a]?
B[a] in R(A[a]), then D[a] ?
N(A[a])lor B[a] ?
N(A[a])r ; and4.
if D[a]?
a in R(A[a]), then D[a] ?
N(A[a])r .Note that the left arguments of A[a] are generated via the nonterminals in N(A[a])l,and the right arguments are generated via nonterminals in N(A[a])r .
Furthermore, inthe top?down generation of the arguments we can switch from nonterminals in N(A[a])lto nonterminals in N(A[a])r only once, through a rule of the form D[a]?
B[a] such thatD[a] ?
N(A[a])land B[a] ?
N(A[a])r , as stated by the third item in Definition 2.
Gram-mar G2 from Example 2 is in split form, with N(A[a])l= {A[a]} and N(A[a])r = {A?
[a]}.The importance of 2-LCFGs in split form is that they allow parsing in time O(|w|3),which is independent of the size of G assumingND is fixed.
This contrasts with the timecomplexity O(|w|4) for arbitrary 2-LCFGs.We say a 2-LCFG G1 is splittable if there is a 2-LCFG G2 in split form such thatG1 and G2 are d-equivalent.
Grammar G1 from Example 2 is splittable, because it isd-equivalent to grammar G2 in the same example, and the latter is in split form.Example 3Consider the 2-LCFG defined by the following rules:S ?
A[a], A[a] ?
a,A[a] ?
B[b] A?
[a], B[b] ?
b,A?
[a] ?
A[a] C[c], C[c] ?
c.Note that there is an equal number of arguments on either side of the head a.
No 2-LCFGin split form can achieve this dependency, and therefore this grammar is not splittable.We can now formally prove that if a 2-LCFG is splittable, then the left arguments ofeach head are independent of its right arguments, and vice versa, in the sense that onlya finite amount of information can be passed between the two sides.Theorem 1Let G be a 2-LCFG.
G is splittable if and only if, for each maximal projection occurrenceA[a] from G, the lin-CFG(a) G(A[a]) generates a regular language.873Computational Linguistics Volume 37, Number 4ProofIf G is splittable, then there exists a split 2-LCFG Gs such that G and Gs are d-equivalent.Let A[a] be a nonterminal of Gs that occurs as maximal projection, and consider thelin-CFG(a) G(A[a])s , whose nonterminals are partitioned into sets N(A[a])land N(A[a])r as inDefinition 2.
It is not difficult to see that L(G(A[a])s ) is a regular language.
This regularlanguage is the finite union of the languages:L(B[a],C[a]) = {uav |A[a]??
uB[a]?
uC[a]??
uav},for all possible distinct choices of rules of the form B[a]?
C[a] from G(A[a])s withB[a] ?
N(A[a])land C[a] ?
N(A[a])r .
For each such choice, the set of strings u is clearlyregular, as it is generated by a right-linear subgrammar.
Similarly, the set of strings vis regular.
Because G and Gs are d-equivalent, it follows that each G(A[a]) generates aregular language as well.Conversely, assume that for each maximal projection occurrence A[a] from Gwe have that G(A[a]) generates a regular language.
Then we can construct an alternativegrammar in lin-CFG(a) generating the same language as G(A[a]), but now in split form.To this end, assume a finite automatonM accepting L(G(A[a]) ) with a finite setQ of statesand a transition relation ?.
For each transition q1a?
q2 of M, we can construct right-linear rules corresponding to transitions occurring on paths from the initial state of Mto state q1, and left-linear rules corresponding to transitions occurring on paths fromstate q2 to any final state ofM.Concretely, for each transition qB[b]?
q?
such that q1 is reachable from q?, we constructrule q[a]?
B[b] q?
[a], and for each transition qB[b]?
q?
such that q is reachable from q2, weconstruct rule q?[a]?
q[a] B[b].
We also construct ruleA[a]?
q0[a], where q0 is the initialstate of M, and the rule q2[a]?
a.
For each final state qf of M that is reachable from q2we furthermore construct the rule q1[a]?
qf [a].
The resulting grammar generates thestrings that are accepted by M by computations that traverse the transition q1a?
q2.Each transition q1a?
q2 gives rise to one such grammar.We can now take the disjoint union of such grammars for all transitions q1a?
q2,taking different copies of automaton states q in nonterminals q[A] for each combi-nation of q1 and q2.
The result is a grammar generating all strings accepted by M.Nonterminals q[a] are defined to be in N(A[a])lor in N(A[a])r depending on whether a stateq1 in a transition q1a?
q2 is reachable from q or whether q is reachable from a state q2 in atransition q1a?
q2.
NaturallyA[a] is taken to be inN(A[a])l. The requirements on split formare now clearly satisfied.
4.
Undecidability ResultsThis section presents the main results of this article.
We start with some basic notionsfrom computability theory and with the adopted notation for Turing machines.We use single-tape, single-head, deterministic Turing machines.
A configuration ofa Turing machine M is a string over some alphabet ?, encoding the current contentof the tape along with the position of the head on the tape and the current state.
Inthe initial configuration, the tape contains the input to the Turing machine, the headis placed at the start of the tape, and the machine is in its (unique) initial state.
Anaccepting configuration is any configuration ofM of which the current state belongs toa distinguished set of accepting states.
An accepting computation of M is a sequenceof configurations of M starting with an initial configuration and ending with a final874Nederhof and Satta Splittability of 2-LCFGsconfiguration, and such that consecutive configurations are related by a valid move ofthe machine.
Without loss of generality, we assume that any accepting computation hasan odd number of moves, and at least three.For a given string w, we write ?w to denote the mirror image of w. Consider a Turingmachine M whose configurations are defined over some alphabet ?, and assume twofresh symbols $ and # not in ?.
Following the notation of Bordihn, Holzer, and Kutrib(2005), we encode accepting computations ofM as strings of the form:w0$w2$ .
.
.
$w2k#w?2k+1$ .
.
.
$?w3$?w1 (2)Here, w0, .
.
.
, w2k+1 are configurations ofM, with w0 an initial configuration and w2k+1an accepting configuration.
Furthermore, for each i with 0 ?
i ?
2k, configuration wi isrelated to configuration wi+1 by a valid move ofM.
We define VALC(M) to be the setof all valid computations ofM, represented as before.
We say that a string u is acceptedbyM if u occurs in an initial configuration w0 in some computation in VALC(M).
Thelanguage L(M) is defined to be the set of all strings accepted byM.We rely on the following result (Hopcroft and Ullman 1979, page 189):Lemma 2For a Turing machineM, it is undecidable whether the language L(M) is finite.We also need the following result, which is essentially the same as a result reportedby Hopcroft and Ullman (1979, Lemma 8.8, page 204).
We provide a complete proofhere because we need to adapt the result to our special encoding of valid computa-tions, which is somewhat different from that used by Hopcroft and Ullman (1979), andbecause Hopcroft and Ullman only report a sketch of the proof.Lemma 3For a Turing machineM, the language VALC(M) is context-free if and only if L(M) isfinite.ProofIf L(M) is finite, then VALC(M) is also finite (because M is deterministic).
HenceVALC(M) is a context-free language.If L(M) is an infinite language, we need to show that VALC(M) cannot be a context-free language.
To this end, we use the version of Ogden?s lemma presented by Hopcroftand Ullman (1979, page 129).
This lemma states that if L is a context-free language, thereexists a constant n such that, if we arbitrarilymark n ormore distinct positions in a stringin L, then we can write that string as uvwxy in such a way that v and x together includeat least one marked position, vwx includes at most n marked positions, and uviwxiy isin L for any i ?
0.Assume now that VALC(M) is a CFL.
Because L(M) is an infinite language,the length of its strings can be arbitrarily large.
Therefore there must be a string inVALC(M) of the form:?
= w0$w2$ .
.
.
$w2k#w?2k+1$ .
.
.
$?w3$?w1,with w2 having length greater than n. This is so because the initial configuration w0,representing the input string, can be chosen with arbitrarily large length, and only two875Computational Linguistics Volume 37, Number 4moves ofM have been applied to obtain w2 from w0.
Let us mark all positions of ?
thatfall within w2.Now let ?
= uvwxy be a factorization satisfying Ogden?s lemma.
If v or x containone or more occurrences of the symbol $, we can pump such a string in ?
and obtain anew string which is not a valid computation, which is a contradiction.
More precisely,assume that v contains exactly one occurrence of $, and write v = v?$v??.
If we choosei = 3 in Ogden?s lemma, we obtain a new string with two instances of configuration v?
?v?in it.
This would imply a loop in the computation of a deterministic Turing machine,and therefore the resulting string cannot be an accepting computation.
Using similararguments, we can conclude that neither v nor x contains an occurrence of symbol $.Because v and x together must include at least one marked position, we can distin-guish two (not necessarily distinct) cases.
In the first case, v is entirely included in thestring w2.
This means that we can pump w2 to a new configuration of arbitrarily largelength, without pumping w0.
But this is a contradiction, because w0 and w2 are only twomoves apart.
In the second case, x is entirely included in the string w2.
Similarly to thefirst case, we can pump w2 to a new configuration of arbitrarily large length, withoutpumping w1, but this is also a contradiction because the two configurations are relatedby a single move.
Therefore VALC(M) cannot be a CFL.
We now define the set of invalid computations ofM, written INVALC(M), as:INVALC(M) = ((?
?
{$})?
?
{#} ?
(?
?
{$})?)
\ VALC(M) (3)We deviate from Bordihn, Holzer, and Kutrib (2005) in that we only consider thosestrings in the complement of VALC(M) that contain exactly one occurrence of #.
Be-cause all the operations that need to be applied to obtain INVALC(M) from VALC(M),or vice versa, preserve regular languages, it follows that VALC(M) is a regular languageif and only if INVALC(M) is a regular language.The following result relates the language INVALC(M) to the class lin-CFG(#), thatis, the linear context-free grammars with center marker #, introduced in Section 2.
Ourproof differs somewhat from proofs of similar statements inHopcroft andUllman (1979)for general linear CFGs, in that the center marker has a prominent role in the grammar,and the construction must ensure that # occurs exactly once.Lemma 4Given a Turing machine M, one can effectively construct a grammar in lin-CFG(#)generating INVALC(M).ProofIntuitively, our grammar is the union of several subgrammars, which generate,respectively: a set of strings of the form (2) in which the wi can be arbitrary strings over?, except that w0 must not be an initial configuration, similarly, a set of strings of the form (2) in which w2k+1 must not be a finalconfiguration, a set of strings of the form (2) in which for some i, w2i+1 must not be thesuccessor of w2i,876Nederhof and Satta Splittability of 2-LCFGs a set of strings of the form (2) in which for some i, w2i must not be thesuccessor of w2i?1, a set of strings of the form:u1$ .
.
.
$uk#v1$ .
.
.
$vmwhere ui ?
??
(1 ?
i ?
k), vj ?
??
(1 ?
j ?
m) and k < m, a set of strings of the form:u1$ .
.
.
$uk#v1$ .
.
.
$vmwhere ui ?
??
(1 ?
i ?
k), vj ?
??
(1 ?
j ?
m) and m < k.It is straightforward to construct each of these subgrammars as linear grammars withcenter marker #, similarly to proofs from Hopcroft and Ullman (1979, pages 203 and215).
The statement of the theorem then follows from the fact that the class lin-CFG(#)is closed under (finite) union.
We now show that it is undecidable whether a linear context-free grammar witha center marker generates a regular language.
This result is stronger than a similarresult stating the undecidability of regularity for general linear context-free languages,originally obtained by Hunt III and Rosenkrantz (1974) and also reported by HopcroftandUllman (1979, Exercise 8.10a, page 214), in that our languages have an explicit centermarker that unambiguously splits the string into two parts.
Here we report a directproof of the result for linear context-free grammars with a center marker, whereas thesimilar result for general linear context-free grammars is indirectly obtained by HuntIII and Rosenkrantz (1974, Corollary 2.7(5) and discussion at page 66) through sufficientconditions for the undecidability of a family of general predicates.Theorem 2It is undecidable whether a grammar in lin-CFG(#) generates a regular language.ProofLet M be a Turing machine.
We start by claiming that L(M) is finite if and only ifINVALC(M) is regular.
To show this, assume first that L(M) is finite.
Because ourTuring machines are deterministic, VALC(M) is also finite, and therefore regular.
FromEquation (3), it follows that INVALC(M) is regular as well.
Conversely, if INVALC(M)is regular, then so is VALC(M).
This means that VALC(M) is context-free and, byLemma 3, that L(M) is finite.Suppose now that it is decidable whether a grammar in lin-CFG(#) generates aregular language.
Following Lemma 4, we can effectively construct a grammar in lin-CFG(#) generating INVALC(M).
Under our assumption, we can now decide whetherINVALC(M) is regular and hence, by our claim, whether L(M) is finite.
This contradictsLemma 2.
Hence, it must be undecidable whether a grammar in lin-CFG(#) generates aregular language.
877Computational Linguistics Volume 37, Number 4Example 4Consider the (unambiguous) grammar that is defined by the rules:S ?
A |B |CA ?
aAa | bAb | aAb | bAa | #B ?
aB | bB | aA | bAC ?
Ca |Cb |Aa |AbDespite rules such as A ?
aAa and A ?
bAb, which by themselves may appear to makethe language non-regular, the generated language is in fact {a, b}?#{a, b}?.We now return to bilexical context-free grammars.
In Section 3 we have constructedgrammars G(A[a]) out of a 2-LCFG G, for each nonterminal A[a] that occurs as maximalprojection in rules from G. We then characterized splittability of G, in Theorem 1, interms of the regularity of the languages generated by each G(A[a]).
Note that each G(A[a])is in lin-CFG(a).
In order to obtain the main result of this article, we only need to lookat a very simple type of 2-LCFG in which we can identify a given linear context-freegrammar with a center marker.Theorem 3Splittability of bilexical CFGs is undecidable.ProofWe show that the existence of an algorithm for deciding whether a 2-LCFG is splittablewould imply an algorithm for deciding whether any grammar in lin-CFG(#) generatesa regular language, contrary to Theorem 2.Let G1 be a grammar in lin-CFG(#).
Without any loss of generality, we assume that: G1 is in binary form; the start symbol of G1 has the form S[#]; each nonterminal symbol of G1 has the form A[#], for some A; and each terminal symbol of G1 is either # or a symbol of the form B[b], forsome B and some b.From G1 we construct a 2-LCFG G2 as follows.
The start symbol of G2 is S?, and G2has a single rule S?
?
S[#] expanding the start symbol.
Each rule from G1 is copied tobe a rule of G2, after replacing each terminal symbol B[b] by a nonterminal B[b].
Theremaining rules are of the form B[b]?
b for each terminal symbol B[b] of G1.It is easy to see that G(S[#])2 = G1.
We also observe that, for each nonterminal B[b] ofG2, grammar G(B[b])2 generates the regular language {b}.
From Theorem 1 it then followsthat G2 is splittable if and only if G1 is regular.
5.
DiscussionSplittability of 2-LCFGs is of central importance to the processing efficiency of severalmodels that are currently being used in statistical natural language parsing, as discussedin the Introduction.
The notion of splittability has been originally introduced by Eisner(1997) and Eisner and Satta (1999) for the closely related formalism of head automatongrammars.
In this article we gave an equivalent definition for 2-LCFGs, through thenotion of d-equivalence, and we showed that splittability of 2-LCFGs is undecidable.878Nederhof and Satta Splittability of 2-LCFGsThe result immediately carries over to head automaton grammars, through the standardmapping defined by Eisner and Satta (1999).Our result is based on a characterization of the notion of splittability (theorem 1) interms of a factorization of a bilexical CFG into linear context-free grammars with centermarkers, and on the regularity of these linear grammars.
The same characterization hasbeen claimed by Eisner and Satta (1999) relative to head automaton grammars, withouta formal proof.
Central to our result is a proof showing the undecidability of regularityfor linear context-free grammars with center markers (Theorem 2).
This strengthens analready known result stating the undecidability of regularity for general linear context-free languages.The main implication of our results is that mechanical analysis of a 2-LCFG will notsuffice to determine whether the grammar is splittable or not.
There are trivial sufficientconditions for splittability, as for example requiring that the grammar is already in thesplit form of definition 2.
Also, if G(B[b]) has a single nonterminal, for each B[b] thatoccurs as maximal projection in a 2-LCFG G, then G is trivially splittable.
It is an openproblem whether splittability is decidable in case the number of nonterminals in eachG(B[b]) is bounded by some constant larger than one.
The proof techniques presented inthis article do not seem to lend themselves to extension of our undecidability results inthis direction.
Other interesting sufficient conditions for splittability are not known.To obtain a more general setting, one might depart from 2-LCFGs and considerChomsky normal form context-free grammars where each binary rule classifies its twononterminals into functor (or predicate projection) and argument.
Also in this case, onecan pose the question of whether the two processes of generating the left and the rightarguments of each predicate are independent one of the other.
The results reported inthis article can be extended to show undecidability of this question as well.AcknowledgmentsWe are indebted to the anonymous reviewersfor many detailed and helpful comments.Among other things, the terminology hasbeen improved relative to the first versionof this article.
This we owe to a valuablesuggestion from one of the reviewers.ReferencesAlshawi, H. 1996.
Head automata andbilingual tiling: Translation with minimalrepresentations.
In 34th Annual Meeting ofthe Association for Computational Linguistics,Proceedings of the Conference, pages 167?176,Santa Cruz, CA.Bordihn, H., M. Holzer, and M. Kutrib.2005.
Some non-semi-decidabilityproblems for linear and deterministiccontext-free languages.
In Implementationand Application of Automata: 9thInternational Conference, pages 68?79,Kingston.Charniak, E. 2001.
Immediate-head parsingfor language models.
In 39th AnnualMeeting and 10th Conference of the EuropeanChapter of the Association for ComputationalLinguistics, Proceedings of the Conference,pages 116?123, Toulouse.Collins, M. 2003.
Head-driven statisticalmodels for natural language parsing.Computational Linguistics, 29(4):589?637.Eisner, J.
1996.
Three new probabilisticmodels for dependency parsing: Anexploration.
In The 16th InternationalConference on Computational Linguistics,volume 1, pages 340?345, Copenhagen.Eisner, J.
1997.
Bilexical grammars anda cubic-time probabilistic parser.In International Workshop on ParsingTechnologies, pages 54?65, Cambridge, MA.Eisner, J. and G. Satta.
1999.
Efficient parsingfor bilexical context-free grammars andhead automaton grammars.
In 37th AnnualMeeting of the Association for ComputationalLinguistics, Proceedings of the Conference,pages 457?464, College Park, MD.Hopcroft, J. E. and J. D. Ullman.
1979.Introduction to Automata Theory, Languages,and Computation.
Addison-Wesley,Reading, MA.Hunt III, H. B. and D. J. Rosenkrantz.
1974.Computational parallels between theregular and context-free languages.In Conference Record of the Sixth AnnualACM Symposium on Theory of Computing,pages 64?74, Seattle, WA.879
