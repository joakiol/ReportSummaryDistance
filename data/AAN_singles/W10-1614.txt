Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas,pages 100?108, Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsAutomated Detection of Language Issues Affecting Accuracy, Ambiguityand Verifiability in Software Requirements Written in Natural LanguageAllan Berrocal Rojas, Gabriela Barrantes SliesarievaEscuela de Ciencias de la Computacio?n e Informa?ticaUniversidad de Costa Rica, San Jose?, Costa Rica{allan.berrocal,gabriela.barrantes}@ecci.ucr.ac.crAbstractMost embedded systems for the avionics in-dustry are considered safety critical systems;as a result, strict software development stan-dards exist to ensure critical software is builtwith the highest quality possible.
One of suchstandards, DO-178B, establishes a numberof properties that software requirements mustsatisfy including: accuracy, non-ambiguityand verifiability.
From a language perspec-tive, it is possible to automate the analysis ofsoftware requirements to determine whetheror not they satisfy some quality properties.This work suggests a bounded definition forthree properties (accuracy, non-ambiguity andverifiability) considering the main character-istics that software requirements must exhibitto satisfy those objectives.
A software proto-type that combines natural language process-ing (NLP) techniques and specialized dictio-naries was built to examine software require-ments written in English with the goal of iden-tifying whether or not they satisfy the de-sired properties.
Preliminary results are pre-sented showing how the tool effectively iden-tifies critical issues that are normally ignoredby human reviewers.1 IntroductionSoftware requirements play a critical role in thesoftware life cycle.
It has been observed thatpoorly written software requirements often lead toweak and unpredictable software applications (Wil-son et al, 1997).
Besides, the cost of fixing er-rors increases exponentially throughout the differ-ent phases of software development (Galin, 2004;Leffingwell and Widrig, 2003).
In other words, it isless expensive to fix an error in the software require-ments phase than it is to fix the same error duringthe integration or verification phase.Embedded systems for the avionics industry aredeveloped following particularly rigorous restric-tions due to strict safety and availability constraintsthat need to be satisfied during air or ground op-erations.
DO-178B (RTCA, 1992) is a recognizedstandard for development of safety critical embed-ded systems.
It is widely used by software certi-fication authorities such as FAA (Federal AviationAssociation), and it establishes some guidelines andquality objectives for each phase of a software devel-opment effort.
In particular, the standard estates thatsoftware requirements must be accurate, verifiable,and non-ambiguous.1.1 Software QualityMilicic suggests that software quality can be under-stood as conformity with a given specification (Mili-cic et al, 2005).
This definition is in total agree-ment with DO-178B, which requires that software isdesigned, built, and tested following approved stan-dards for each phase of the development cycle.Extrapolating the previous definition, one can ar-gue that quality of software requirements can be un-derstood as the degree to which software require-ments also comply with a given specification.
Inother words, in order to produce high quality soft-ware requirements, one needs to ensure that theysatisfy the criteria established in a software require-ments standard.In the case of software requirements written innatural language (NL), some of the criteria canbe addressed from a linguistic perspective, observ-ing certain types of language constructs and lan-guage usage in general that may represent violationsagainst desired quality criteria in a standard.1001.2 Overview of Research GoalsThe overall objective of this research was to identifysome of the linguistic elements that one can observeto determine whether or not software requirementswritten in natural language1 comply with three spe-cific properties established by DO-178B: accuracy,verifiability and non-ambiguity.
Those linguistic el-ements can be seen as rules in an expert system, sothat requirements are said to be compliant with theirquality objectives when they satisfy all rules.
Theyare said to be non-compliant with their quality ob-jectives when rules are not satisfied.In this research, linguistic elements were identi-fied and independently validated by professionals inthe field of software verification.
Later on, a soft-ware prototype capable of examining a list of re-quirements was built to automatically detect whenrequirements do not satisfy a given rule.The main contribution of this research is that itprovides a quantitative evaluation of the target re-quirements.
More specifically, based on the num-ber of satisfied and non satisfied rules, the proto-type scores each requirement in a 1 to 10 scale.
Thetool also provides additional information (qualitativeanalysis) to the user indicating the root of the prob-lem when a given rule is not satisfied, as well as pos-sible ways to fix the issue.1.3 JustificationThe author?s experience in the field of requirementsverification suggests that the task of reviewing a setof requirements for compliance with properties suchas accuracy, verifiability and non-ambiguity is a nontrivial task.
This is particularly true when the re-viewer lacks the proper training and tools.
Some ofthe known difficulties for this process are:?
It requires linguistic (e.g.
grammar, semantics)and technical knowledge from a reviewer.?
There is no warranty that two or more review-ers will produce the same findings for the sameinput (mostly due to the informal nature of NL).?
The process is error prone since reviewers be-come fatigued after some time.1This research assumes requirements are written in English.?
The process is time consuming, which directlyaffects budget and schedule performance.Having a tool that partially automates the pro-cess of reviewing software requirements may rep-resent significant improvements in the overall soft-ware life cycle process.
Even when current devel-opments in computational linguistics do not providea complete solution for the problem at hand, a par-tial approach is still valuable producing numerousadvantages such as:?
Linguistic and technical knowledge is inputinto the system in a cumulative manner, reduc-ing dependency on highly qualified personnel.?
Results are reproducible for any given set of in-puts, reducing inconsistencies while adding re-liability to the results.?
Review time is significantly reduced.2 Related WorkSignificant work has been done in the area of soft-ware requirements analysis.
Lami (Lami et al,2004) classifies these efforts in three groups.
A firstgroup consists of preventive techniques that needto be applied during the process of writing require-ments.
Those techniques normally trigger checkliststhat are enforced by a person with no support fromtools, see for instance (Firesmith, 2003).
Anothergroup consists of restrictive techniques that limit thedegree of language freedom when writing require-ments.
One example in this group is Fuchs (Fuchset al, 1998) who introduces ACE (Attempto Con-trolled English), a restricted subset of English witha restricted grammar and domain specific vocabu-lary.
Requirements can be written in natural lan-guage with enough expressive power.
They are latertranslated into first order predicate logic to be pro-cessed formally by a computer program.The last group of efforts consists of analytic tech-niques that perform automated analysis of require-ments once they have been produced.
The follow-ing are two relevant projects in this group.
Wilson(Wilson et al, 1997) developed a tool named ARMthat performs automated analysis of a requirementsdocument.
The tool focuses on lexical analysis todetect specific keywords such as vague adverbs and101vague adjectives that are not desired.
Different fromour work, ARM also checks that the document it-self complies with a specific format.
Then, Lami(Lami et al, 2004) described a systematic methodfor automated analysis of requirements detecting de-ficiencies such as ambiguity, inconsistencies, and in-completeness.
A tool named QuARS implementsthe suggested methodology and appears to be a goodcontribution in this area 2.3 Theoretical FrameworkThis section provides a basic explanation of someconcepts that are commonly used in the field of soft-ware verification.
Emphasis will be made on con-cepts related to the software engineering field inan attempt to set the grounds for the investigation.Other linguistic related concepts will be mentionedalong the paper assuming the reader has basic under-standing of them.3.1 Software Life CycleA Software Life Cycle Model or Software Develop-ment Model consists of a group of concepts and wellcoordinated methodologies that guide the softwaredevelopment process from beginning to end (Galin,2004).
The classic software life cycle model (a.k.a.the waterfall model) consists of linear sequence ofactivities or phases that take place during a softwaredevelopment effort.In the Requirements elicitation phase, a detaileddescription of what the software shall do is pro-duced.
Although there are various methods, a natu-ral language description in the form of a list of state-ments is widely used to produce requirements.A software requirement is a condition or charac-teristic that a system must possess to satisfy a con-tract, a standard, a formal specification or other ap-plicable regulation (IEEE, 1990).In simple words, a software requirement explainshow the system should behave or react given a spe-cific set of inputs and initial conditions.
While nottrue for all software applications, in the avionics in-dustry, all software functionalities are required to befully deterministic.
This means that the system mustbehave exactly the same all the time for a given set2The author has not been able to use QuARS yet.of inputs and initial conditions.
This is why correct-ness of requirements is so critical.The following section briefly comments on threeof the properties that requirements must satisfy tomeet quality objectives.
Although there are manysuch properties, we focus on three whose detectionis partially automated in this research.3.2 Quality Properties for SoftwareRequirementsTo meet quality objectives, software requirementmust be accurate, non-ambiguous and verifiable.This section provides a brief explanation of theseterms in the context of software verification.
Ad-ditionally, it describes the main language elementsused in this research to automatically detect whensoftware requirements do not satisfy a given prop-erty.3.2.1 AmbiguityA word or phrase is said to be ambiguous whenit has more than one possible meaning causing con-fusion or uncertainty.
Similarly, software require-ments are said to be ambiguous when they admitmore than one possible interpretation.
An ambigu-ous requirement is notably incompatible with thegoal of producing deterministic software.Berry (Berry, 2003) distinguishes six major formsof ambiguity in software requirements: lexical, syn-tactical, semantic, pragmatic, vagueness and lan-guage error.
In this research, we focused on lexi-cal, syntactic, vagueness, and language errors sincethis group covers common deficiencies that show inrequirements.One form of syntactical ambiguity occurs whenrequirements fail to group logical conditions (e.g.AND, OR) with appropriate punctuation marks orexplicit parenthesis.
In the following example, forinstance, it is not clear what the conditions are forthe system to enter into normal mode: ?The systemshall enter Normal mode when SDI field on label 227equals 2 or SSM in label 268 equals 3 and WOW is trueor AIR is false.
?Vague adverbs usually modifying nouns (such as:acceptable, high, low, fast, in/sufficient, normal,similar and many others) also create ambiguous re-quirements like the following: ?The system shall allowthe operator to adjust volume to an acceptable level.
?102Finally, non deterministic constructs such asand/or, any, not limited to also create ambiguity inrequirements, such as the following case: ?The sys-tem shall display altitude and/or temperature at the bot-tom line of the screen.
?3.2.2 AccuracyIn a requirement, accuracy refers to how conciseand precise a requirement is specified.
Accuracyshould be present not only in the content but alsoin the structure of a requirement.In terms of structure, a requirement must clearlydistinguish between at least two parts: condition andaction.
A requirement with a clear action and nocondition opens a possibility to think that the spec-ified action is permanent (which is rarely the case).On the other hand, by definition, there can not exista requirement with no action.For instance, the following requirement is inaccu-rate: ?The system shall clear the DMA shared space,?since no one knows when the action must occur.In terms of content, a requirement must includeclear and detailed information about the conditionand the action that is being described.
Accurate re-quirements also include explicit units for physicalvalues as well as tolerances and thresholds for nu-merical computations.For instance, the following requirement is inaccu-rate ?The system shall send ARINC label 251 every 50ms,?
but adding a tolerance value solves the issue asin ?The system shall send ARINC label 251 every 50 ms+/- 5ms.
?Non deterministic adverbs usually modifyingverbs (such as: continually, periodically, regularlyand others) also create inaccurate requirements likethe following: ?The system shall periodically performCBITE.
?Finally, there are a number of general verbs thatshould be avoided in requirements since they cre-ate inaccurate descriptions.
Some of these verbs are:process, monitor, support, check among others.
Forinstance, it is not clear to see the software action thatthis requirement implies: ?The system shall monitor re-sponses from the slave processor.
?3.2.3 VerifiabilityA requirement is said to be verifiable if it is pos-sible to create and execute a test to demonstrate thatthe software behaves exactly as specified in the re-quirement.Sometimes a test can not be executed primarilybecause of hardware or test equipment limitations.In other cases, conflicts or inconsistencies betweenrequirements are revealed which prevent a test frombeing performed.
However, another group of re-quirements become non verifiable due to languageusage errors.For instance, by definition requirements are meantto describe actions that the system shall perform.
Inthat sense, a requirement must not describe anythingthat the system shall not perform.
To illustrate, arequirement such as the following is non verifiable:?The system shall not enter INTERACTIVE mode whenWOW is false.?
The reason is that a tester can notexpect any specific system action during a test forthis requirement.Furthermore, requirements using the adverbs al-ways and never are also non-verifiable since a testfor them would require infinite time.
Similarly, theterm only must be used correctly when modifyingthe main action (verb) of the requirement.
For ex-ample, the requirement ?The system shall only displayinvalid data in red color?
implies that the only ac-tion this system performs is ?display invalid data inred color.?
The intended meaning is probably ?Thesystem shall display only invalid data in red color.
?Finally, some requirements contain verbs that im-ply actions that a software application can not per-form; instead, these are usually human-specific tasksthat are incorrectly assigned to software.
Some ofthese verbs are: determine, ignore, consider, anal-yse and others.
One example of wrong usage is ?Thesystem shall consider fault history during CBITE.
?As mentioned in section 1.2, one objective was toprovide a quantitative evaluation of a set of require-ments against three properties: accuracy, ambigu-ity and verifiability.
With that goal in mind, section4.1 introduces some of the formulations that will beused to perform the evaluation of the requirementsagainst the selected properties.4 Research FoundationTo accomplish the general objectives described insection 1.2, section 4.1 introduces a semi-formalnomenclature used to express the various situations103when a requirement either satisfies or violates anyof the desired properties.
This nomenclature is valu-able for it allows to represent various situationsin a symbolic and summarized way.
Section 4.2describes the process followed to select the crite-ria against which the software requirements will beevaluated for quality.4.1 Proposing General NomenclatureWe will use the term element to refer to individuallinguistics elements or rules as mentioned in section1.2.
Similarly, the term attribute refers to qualityproperties: accuracy, ambiguity and verifiability.To represent the attribute ambiguity, we define theset ?
= {?1, ?2, ..., ?k} with k ?
N?1 whereeach ?i is an element that reveals a non compliancefor the attribute of ambiguity by a given requirement.For instance, let?s assume ?1 = ?A requirement mustnot use vague or general adverbs to describe an ac-tion,?
then, if we apply ?1 to the requirement R1 =?The system shall allow the operator to adjust vol-ume to an acceptable level,?
we conclude that R1 isambiguous since the adverb ?acceptable?
is vague.In that case we say that R1 does not satisfy ?1.For accuracy we define ?
= {?1, ?2, ..., ?r}with r ?
N?1, and for verifiability we define?
= {?1, ?2, ..., ?s} with s ?
N?1 in an analo-gous way.
Summarizing, we define:X1 = ?
, X2 = ?
, X3 = ?where Xi = {?1, ?2, ..., ?n} and each ?i is anelement that tells us if a requirement does not satisfya specific attribute.We propose the following notation to representsituations where requirements fail to satisfy an el-ement.?
When a requirement Re meets the restrictionimposed by an element ?k, we say that Resatisfies ?k, and we write Re ?
?k.?
When a requirement Re does not meet the re-striction imposed by an element ?k, we say thatRe does not satisfy ?k, and we write Re ?
?k.?
When the restriction imposed by an element ?kis not applicable for a requirement Re, we saythat ?k is not applicable for Re and we writeRe ?
?kNotice how the expressions Re ?
?k , Re ?
?kand Re ?
?k can be seen as logical predicates for abinary relation.
For instance, we could read the firstexpression as ?
(Re, ?k) or SATISFIES(Re, ?k) .However, computing the degree in which a re-quirement satisfies an attribute is not a binary rela-tion.
For instance, a requirement can meet some re-strictions and not others; besides, some restrictionsare more critical than others.For a more objective evaluation, a scale from 0to 10 is proposed.
Each element ?1, ?2, ..., ?n inXi is assigned a value or score so that the scoresfor all elements in an attribute add up to 10 andscore(?i) = p , p ?
R+10 (where R+10 = [0, 10]).Values are assigned depending on the criticality andtype of error revealed by each element.
Summariz-ing:|Xi|?j=1score(?j) = 10where ?j ?
Xi and Xi ?
{?,?,?
}(1)Now, in order to evaluate a requirement Re in re-gards to an attribute, we define ?
: (R) ?
R+10:?
(Re, Xi) = [10??j,Re?
?jscore(?j)] =[?j,Re?
?jscore(?j)] where ?j ?
Xi(2)Notice how we write ?
using either predicatedoes not satisfy?
or satisfies?.
In both cases, whenan element is not applicable ?
to a requirement, weassume that the requirement satisfies such element.To understand the meaning of ?, suppose thatx = ?(Re,?)
is the score a requirement Re getswhen it is evaluated against a given attribute, let?ssay accuracy.?
When x = 10 we say that Re satisfies ?
and wewrite Re ?
?.
Re is accurate, since it meets allthe restrictions imposed by each element in ?.?
When x = 0 we say that Re does not satisfy ?and we write Re?0?.
Re is not accurate, sinceit does not meet any of the restrictions imposedby elements in ?.104?
When 0 < x < 10 we say that Redoes not satisfy ?
with a degree x and we writeRe?x ?.
Re meets some of the restrictions im-posed by elements in ?
but not all.
In this case,the closer x is to 10, the better the requirementwill be3.Finally, to get a requirement?s overall scoreagainst all three attributes, we define a function?
: (R) ?
R+10 as follows:?
(Rk) =?3i=1 ?
(Rk, Xi)3 where Xi ?
{?,?,?}(3)?
is the arithmetic mean of the scores a require-ment gets against each attribute hXi in (2).
Theoverall score is a measure of a requirement?s qual-ity, and it could be used potentially to estimate costsin a software project.To understand ?
suppose x = ?
(Rk) is the scorea requirement Rk gets when it is evaluated againstall three attributes (ambiguity, accuracy and verifia-bility) using all elements in {?,?,?}.?
When x = 10, we say that Rk is accurate, ver-ifiable and non-ambiguous sinceRk ?Xi ?Xi ?
{?,?,?}.?
When x = 0 we say that Rk is inaccurate, non-verifiable and ambiguous sinceRk ?Xi ?Xi ?
{?,?,?}.?
When 0 < x < 10, we say that Rk is ei-ther inaccurate, non-verifiable or ambiguoussince it does not satisfy at least one element in{?,?,?}.
In this case, ?
provides more infor-mation about the weakness detected in Rk.The value of the suggested notation comes fromthe fact that we can now produce quantitative evalu-ations of requirements, as opposed to common qual-itative evaluations.
The following sections brieflydescribe a bottom up process we followed to selectevaluation criteria for the prototype that was built.3We will use either notation ?
or ?x to indicate that a re-quirement does not satisfy an attribute and the degree x is notrelevant.4.2 Selecting Criteria for EvaluationThe process of selecting the elements for each at-tribute was conducted in a series of steps that aresummarized below.
The objective of our approachwas to provide a selection of elements that satis-fied three main goals.
The first goal was to haverepresentative and useful selection within the fieldof software verification.
The second goal was thatthe selection could be independently validated by agroup of professionals in the field.
And finally, thethird goal was that the selection of elements refersto weaknesses that can be automatically detected bya software.The following is a summary of the process thatwas followed to select the criteria to evaluate re-quirements.1.
A list of elements was first suggested by theauthor based on relevant literature and his ownexperience in software verification for embed-ded systems.
The list contained 19 elements(10 for accuracy, 5 for ambiguity and 4 for ver-ifiability).2.
Five elements were filtered out as they werenot candidates to be automated.
Feasible can-didates were those that could be automated us-ing techniques such as parsing, tagging, regularexpressions, and specialized dictionaries likeWordNet (Miller, 1993) and VerbNet (Kipper,2005).
The list ended with 6 elements in accu-racy, 4 in ambiguity and 4 in verifiability.3.
The author suggested an initial value or scorefor each element in the list.4.
Both the element selection and the value distri-bution were independently validated by a groupof three professionals with demonstrable expe-rience in software verification4.5.
A numerical model was prepared based on theproposed approach described in section 4.1.This is already a contribution since the evalu-ation of the requirements could be done manu-ally in case no tool had been created.4Although these individuals are not language experts, sincethey have valuable experience in requirements verification, theirfeedback was considered a valid complement in this research.1056.
A software prototype was written for a tool thatis capable of examining a list of requirementsapplying equations 2 and 3 in section 4.1.Section 5 briefly describes the capabilities of theprototype tool that was developed.5 Automated EvaluationThis section provides a brief description of the soft-ware prototype.
A more in depth description wouldbe ideal; however, due to space limitations we willfocus on two items only.
First, an overview of thetool?s architecture and technologies involved (sec-tion 5.1).
Second, a description of the outputs thistool produces (section 5.2).5.1 Building the PrototypeOur prototype tool receives the name of SRR-Director from Software Requirements Reviewer Di-rector.
This prototype was built using open sourcesoftware and tools that are freely available for re-search.
Our goal was to integrate several of theseavailable resources into a single piece of softwarethat helped us solving the problem we are studying.Perl5 was used as the main language for the soft-ware and Awk6 was used as an independent tool tocheck some of the results while developing the tool.Input requirements normally exist in various formatssuch as MS Word7, MS Excel8, structured XML, orplain text files.
We provide a tool that can be config-ured to read those inputs converting them into XMLdocuments that follow a normalized structure whichbasically separates requirements identifiers from theactual text of the requirement.The three main techniques used during automatedinspection of the requirements were the following:Lexical Analysis: this is a common and simpletechnique that is based on regular expressions.
Perl?sengine for regular expressions was particularly use-ful in this task.
This type of analysis allows identifi-cation of key words or phrase structures that revealspecific types of weaknesses in requirements.This technique helped identifying issues of allthree types.
For ambiguity it allowed to locate5http://www.perl.org6http://www.gnu.org/software/gawk/7http://office.microsoft.com/word8http://office.microsoft.com/excelvague adverbs and non deterministic language con-structs; for accuracy, we detected tolerance issues,non deterministic adverbs and general verbs.
Fi-nally, to check for verifiability this technique wasused to capture negative requirements, infinite re-quirements, and wrong usage of the term only.Syntactic Analysis: consists of parsing the re-quirements to transform language statements intotheir grammatical constituents which enables otherspecific analysis such as ambiguity analysis.
Thisprocess was performed using a parser made avail-able by Eugine Charniak and Brown University(Charniak et al, 2006).
In this case, the CLAIRgroup at University of Michigan made available aPerl wrapper for the Charniak parser(CLAIR, 2009).Studying the syntax tree produced by the parser, itwas possible to identify accuracy issues such as re-quirements without explicit condition statements (orcondition blocks).
Also, studying the output of theparser along with lexical analysis of the requirementreveals cases of ambiguity when logical conditionsare not stated clearly.Dictionaries: two great resources were also in-corporated in this research to support our analy-sis: WordNet (Miller, 1993) and VerbNet (Kipper,2005).
Both of this tools can also be accessed fromPerl via wrappers and provide useful informationabout words and verbs that were used to ensure someconditions were valid while we perform the analysisof the requirements.Dictionaries allow identification of human spe-cific verbs and ambiguous verbs.
In this case, theparser makes it possible to capture the main verb fora requirement, and further queries into dictionariescomplete the task.
VerbNet provides a mechanismto classify requirements according to their degree ofambiguity.
This mechanism may be too stringentfor flagging ambiguous verbs sometimes.
There areverbs tagged as ambiguous in VerbNet, but they havea fairly well known and shared meaning in the do-main of software engineering such as: set, shut-down, turnoff, send, receive among others.SRR-Director runs from a command line and itis currently controlled using a number of argumentsand switches.
Even when this is still a prototypetool, our experiments show that the tool is very effi-cient capturing weaknesses in the requirements witha marginal error rate (< 5%) for the rules included106in the current version of the tool.
More importantly,the tool is able to examine hundreds of requirementsin a matter of minutes when the same work takeshours or even days for a human reviewer.5.2 Using the ReportsIn the current prototype version, the tool producesseven types of reports that provide information forthree types of users:Quality engineers: two reports show general in-formation about the quality of the requirements thatwere analysed.
Quality engineers are interested inthe overall percentage of requirements compliancewith the quality objectives, and they don?t need de-tails on the types of failures.Requirements engineers: four reports are avail-able for the largest audience of users who are actu-ally interested in learning the details about the typesof failures identified in the requirements.
Not onlyare the engineers notified of the weaknesses but alsothey are provided with suggestions on how to fix theissues.
The evaluation they receive is not only qual-itative but also quantitative since they can see thescore for individual requirements against each of thethree properties being studied.Software engineers: this is a miscellaneous re-port that provides performance information whichmay later help software engineers while tuning cer-tain processes in the tool.6 Experiments and ResultsExperiments were performed using sample require-ments from three distinct and real word applicationsin embedded systems.
Test data was selected froma pool of reserved requirements that were not usedduring development of the tool.Four groups of 20 requirements each were se-lected and given to three experienced professionalsin the field of software verification.
The subjectswere asked to identify weaknesses in the require-ments using their own criteria.
They were asked toclassify ill requirements as inaccurate, ambiguousor non-verifiable when applicable.
The same groupswere input to the prototype for evaluation, and re-sults were compared.As it was mentioned before, the tool recognizesall deficiencies described by a rule or element witha low error rate (< 5%).
We believe this is mostlydue to the fact that ?in this initial phase of the tool?rules are not complex, and can indeed be automatedwithout using complex techniques.One interesting result was that a high degree ofdiscrepancies and disagreement between the subjectreviewers was observed .
On average, the three re-viewers agreed only in 14% of their evaluations, andonly in 62% of the cases there was agreement be-tween at least two reviewers.
These unexpected dis-crepancies certainly make it difficult to compare thetool?s results with the reviewer?s results to identifyareas of agreement or disagreement.A more in depth analysis of the results suggeststhat human beings may perform erratically when itcomes to reviewing requirements that contain thetypes of errors we are looking for.
Some of theweaknesses we want to uncover are rather subtleand, as we argued before (section 1.3), require agood level of language and technical knowledge aswell as a detail oriented attitude.
People are alsoaffected by external factors such as fatigue that neg-atively affects the quality of their work.7 ConclusionsThe results of this research show that it is actuallypossible to automate the review process of softwarerequirements identifying valuable sources of defi-ciencies that otherwise make requirements inaccu-rate, ambiguous or non-verifiable.Besides, there are resources freely available forresearch that can be integrated into more specifictools to solve a variety of problems.
Specialized dic-tionaries, stand alone tools, such as parsers, and ageneral purpose scripting language (Perl) were com-bined in order to create the tool prototype.Finally, a simple but rather useful nomenclatureto represent different scenarios that occur during re-quirements verification was proposed.
This con-tribution allows us to provide a quantitative anal-ysis of the requirements as opposed to traditionalqualitative-only analyses.8 Collaboration OpportunitiesThis section answers two specific questions to de-scribe possible collaboration opportunities betweeninvestigators doing research on similar topics.1078.1 How can this work benefit other researchprojects?This research was focused on three properties ap-plicable to software requirements for aerospace sys-tems.
However, it would be ideal to apply similartechniques to examine other types of properties thatare crucial in similarly critical application domainssuch as finance, transportation, medicine and com-munications.In this work, inputs are text documents with nat-ural language text in the form of software require-ments.
Those inputs are preprocessed and convertedinto simpler representations that basically consist ofsentences.
Those sentences at the end are the maininput for the tool that performs the automated qual-ity analysis.Researchers wishing to learn more about thiswork are strongly encouraged to contact the authorto share ideas on this topic and benefit from one an-other.
We believe it is possible to reuse part of theapproach to build similar tools to analyse require-ments in languages other than English.8.2 What are some resources and expertise theauthor lacks?One of the main difficulties the author faced is theabsence of collaboration between researchers inter-ested in similar topics.
This work has been producedmostly in isolation as part of academic research in amasters program.Being able to share ideas with working groupseither academic or industry sponsored would be agreat channel to improve research scope and pro-duce more significant results.
For the nature of thisresearch, a mixed team of linguists and software en-gineers would presumably improve the quality of thework.On the one hand, linguists would provide valu-able knowledge that would help identifying addi-tional language structures that represent symptomsof weaknesses in requirements.
On the other hand,software engineers would be closer to requirementsengineers and could contribute with implementationdetails so that new rules are added to the system.ReferencesWilson, W. and Rosenberg, L. and Hyatt, L. 1997.
Auto-mated Analysis of Requirement Specifications.
Nine-teenth International Conference on Software Engineer-ing (ICSE-97), Boston, MA.Galin, D. 2004.
Software Quality Assurance From theoryto implementation.
Pearson Education Ltd.Leffingwell, D. and Widrig, D. 2003.
Managing Soft-ware Requirements, 2nd Ed.
Addison-Wesley.RTCA/EUROCAE.
1992.
DO-178 Software Consider-ations for Airborne Systems and Equipment Certifica-tion.
RTCA, Inc., Washington, DC.Drazen, M. and Berander, P. and Damm, L. and Eriksson,J.
and Gorschek, T. and Henningsson, K. and Jonsson,P.
and Kagstrom, S. and Martensson, F. and Ronkko,K.
and Tomaszewski, P. .
2005.
Software quality at-tributes and trade-offs, Software Quality Models andPhilosophies.
Blekinge Institute of Technology.IEEE Standards Board.
1990.
IEEE Standard Glossaryof Software Engineering Terminology, Std 610.12-1990.Berry, D. and Kamsties, E. and Krieger, M. .
2003.
FromContract Drafting to Software Specification: Linguis-tic Sources of Ambiguity.Miller, G. and Beckwith, R. and Fellbaum, C. and Gross,D.
and Miller, K.. 1993.
Introduction to WordNet: AnOnline Lexical Database.
Cognitive Science Labora-tory, Princeton University.Kipper, K.. 2005.
VerbNet: A broad-coverage, compre-hensive verb lexicon.
Computer and Information Sci-ence, University of Pennsylvania.Lami, G. and Gnesi, S. and Fabbrini, F. and Fusani, M.and Trentanni, G. .
1997.
An Automatic Tool for theAnalysis of Natural Language Requirements.
C.N.R.Information Science and Technology Institute, PisaItaly.McClosky, D. and Charniak, E. and Johnson, M.. 2006.Reranking and Self-Training for Parser Adaptation.21st International Conference on Computational Lin-guistics.CLAIR official website.
2009.
URL http://belobog.si.umich.edu/clair/clair/downloads.html.
Visited on March 12, 2009.Fuchs, N. and Schwertel, U. and Schwitter, D.. 1998.Attempto Controlled English Not Just Another LogicSpecification Language.
Eighth International Work-shop on Logic-based Program Synthesis and Transfor-mation LOPSTR?98, Manchester, UK.Firesmith, D.. 2003.
Specifying Good Requirements.Journal of Object Technology, ETH Zurich.108
