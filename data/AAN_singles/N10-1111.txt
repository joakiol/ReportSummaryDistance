Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 729?732,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsConstraint-Driven Rank-Based Learning for Information ExtractionSameer Singh Limin Yao Sebastian Riedel Andrew McCallumDept.
of Computer ScienceUniversity of MassachusettsAmherst MA 01003{sameer,lmyao,riedel,mccallum}@cs.umass.eduAbstractMost learning algorithms for undirectedgraphical models require complete inferenceover at least one instance before parameter up-dates can be made.
SampleRank is a rank-based learning framework that alleviates thisproblem by updating the parameters during in-ference.
Most semi-supervised learning algo-rithms also perform full inference on at leastone instance before each parameter update.We extend SampleRank to semi-supervisedlearning in order to circumvent this compu-tational bottleneck.
Different approaches toincorporate unlabeled data and prior knowl-edge into this framework are explored.
Whenevaluated on a standard information extractiondataset, our method significantly outperformsthe supervised method, and matches results ofa competing state-of-the-art semi-supervisedlearning approach.1 IntroductionMost supervised learning algorithms for undirectedgraphical models require full inference over thedataset (e.g., gradient descent), small subsets of thedataset (e.g., stochastic gradient descent), or at leasta single instance (e.g., perceptron, Collins (2002))before parameter updates are made.
Often this is themain computational bottleneck during training.SampleRank (Wick et al, 2009) is a rank-basedlearning framework that alleviates this problem byperforming parameter updates within inference.
Ev-ery pair of samples generated during inference isranked according to the model and the ground truth,and the parameters are updated when the rankingsdisagree.
SampleRank has enabled efficient learn-ing for massive information extraction tasks (Culottaet al, 2007; Singh et al, 2009).The problem of requiring a complete inference it-eration before parameters are updated also exists inthe semi-supervised learning scenario.
Here the sit-uation is often considerably worse since inferencehas to be applied to potentially very large unlabeleddatasets.
Most semi-supervised learning algorithmsrely on marginals (GE, Mann and McCallum, 2008)or MAP assignments (CODL, Chang et al, 2007).Calculating these is computationally inexpensive formany simple tasks (such as classification and re-gression).
However, marginal and MAP inferencetends to be expensive for complex structured pre-diction models (such as the joint information extrac-tion models of Singh et al (2009)), making semi-supervised learning intractable.In this work we employ a fast rank-based learningalgorithm for semi-supervised learning to circum-vent the inference bottleneck.
The ranking functionis extended to capture both the preference expressedby the labeled data, and the preference of the domainexpert when the labels are not available.
This allowsus to perform SampleRank as is, without sacrificingits scalability, which is crucial for future large scaleapplications of semi-supervised learning.We applied our method to a standard informationextraction dataset used for semi-supervised learning.Empirically we demonstrate improvements over thesupervised model, and closely match the results of acompeting state-of-the-art semi-supervised learner.2 BackgroundConditional random fields (Lafferty et al, 2001) areundirected graphical models represented as factor729graphs.
A factor graph G = {?i} defines a prob-ability distribution over assignments y to a set ofoutput variables, conditioned on an observation x.A factor ?i computes the inner product betweenthe vector of sufficient statistics f(xi,yi) and pa-rameters ?.
Let Z(x) be the data-dependent par-tition function used for normalization.
The proba-bility distribution defined by the graph is:p(y|x,?)
=1Z(x)??i?Ge?
?f(xi,yi)2.1 Rank-Based LearningSampleRank (Wick et al, 2009) is a rank-basedlearning framework for that performs parameter up-dates within MCMC inference.
Every pair of con-secutive samples in the MCMC chain is ranked ac-cording to the model and the ground truth, and theparameters are updated when the rankings disagree.This allows the learner to acquire more supervisionper sample, and has led to efficient training of mod-els for which inference is very expensive (Singhet al, 2009).SampleRank considers two ranking functions: (1)the unnormalized conditional probability (modelranking), and (2) a truth function F(y) (objectiveranking) which is defined as ?L(y,yL), the neg-ative loss between the possible assignment y andthe true assignment yL.
The truth function can takedifferent forms, such as tokenwise accuracy or F1-measure with respect to some labeled data.In order to learn the parameters for which modelrankings are consistent with objective rankings,SampleRank performs the following update for eachconsecutive pair of samples ya and yb of the MCMCchain.
Let ?
be the learning rate, and ?
=f(xi,yai )?
f(xi,ybi ), then ?
is updated as follows:?+????????
if p(ya|x)p(yb|x) < 1 ?
F(ya) > F(yb)???
if p(ya|x)p(yb|x) > 1 ?
F(ya) < F(yb)0 otherwise.This update is usually fast: in order to calculatethe required model ratio, only factors that touchchanged variables have to be taken into account.SampleRank has been incorporated into the FAC-TORIE toolkit for probabilistic programming withimperatively-defined factor graphs (McCallum et al,2009).3 Semi-Supervised Rank-Based LearningTo apply SampleRank to the semi-supervised set-ting, we need to specify the truth function F overboth labeled and unlabeled data.
For labeled dataYL, we can use the true labels.
These are not avail-able for unlabeled data YU , and we present alterna-tive ways of defining a truth function FU : YU ?
<for this case.3.1 Self-TrainingSelf-training, which uses predictions as truth, fits di-rectly into our SampleRank framework.
After per-forming SampleRank on training data (using FL),MAP inference is performed on the unlabeled data.The prediction y?U is used as the ground truth forthe unlabeled data.
Thus the self-training objectivefunction Fs over the unlabeled data can be definedas Fs(y) = ?L(y, y?U ).3.2 Encoding ConstraintsConstraint-driven semi-supervised learning usesconstraints to incorporate external domain knowl-edge when labels are missing (Chang et al, 2007;Mann and McCallum, 2008; Bellare et al, 2009).Constraints prefer certain label configurations overothers.
For example, one constraint may be that oc-currences of the word ?California?
are preferred tohave the label ?location?.We can encode constraints directly into the objec-tive function FU .
Let a constraint i be specified as?pi, ci?, where ci(y) denotes whether assignment ysatisfies the constraint i (+1), violates it (?1), or theconstraint does not apply (0), and pi is the constraintstrength.
Then the objective function is:Fc(y) =?ipici(y)3.3 Incorporating Model PredictionsWhen the objective function Fc is used, every pre-diction on unlabeled data is ranked only according tothe constraints, and thus the model is trained to sat-isfy all the constraints.
This is a problem when theconstraints prefer a wrong solution while the modelfavors the correct solution, resulting in SampleR-ank updating the model away from the true solution.To avoid this, the ranking function needs to balancepreferences of the constraints and the current model.730One option is to incorporate the self-training ob-jective function Fs.
A new objective function thatcombines self-training with constraints can be de-fined as:Fsc(y) = Fs(y) + ?sFc(y)= ?L(y, y?U ) + ?s?ipici(y)This objective function has at least two limita-tions.
First, self-training involves a complete infer-ence step to obtain y?U .
Second, the model mighthave low confidence in its prediction (this is the casewhen the underlying marginals are almost uniform),but the self-training objective des not take this intoaccount.
Hence, we also propose an objective func-tion that incorporates the model score directly, i.e.Fmc(y) = log p(y|x,?)
+ logZ(x) + ?mFc(y)=??i?
?
f(xi,yi) + ?m?ipici(y)This objective does not require inference, and alsotakes into account model confidence.In both objective functions Fsc and Fmc, ?
con-trols the relative contribution of the constraint pref-erences to the objective function.
With higher ?,SampleRank will make updates that never try to vi-olate constraints, while with low ?, SampleRanktrusts the model more.
?
corresponds to constraintsatisfaction weights ?
used in (Chang et al, 2007).4 Related WorkChang et al propose constraint-driven learn-ing (CODL, Chang et al, 2007) which can be in-terpreted as a variation of self-training: Instancesare selected for supervision based not only on themodel?s prediction, but also on their consistencywith a set of user-defined constraints.
By directly in-corporating the model score and the constraints (asinFmc in Section 3.3) we follow the same approach,but avoid the expensive ?Top-K?
inference step.Generalized expectation criterion (GE, Mann andMcCallum, 2008) and Alternating Projections (AP,Bellare et al, 2009) encode preferences by speci-fying constraints on feature expectations, which re-quire expensive inference.
Although AP can use on-line training, it still involves full inference over eachinstance.
Furthermore, these methods only supportconstraints that factorize according to the model.Li (2009) incorporates prior knowledge into con-ditional random fields as variables.
They require fullinference during learning, restricting the applicationto simple models.
Furthermore, higher-order con-straints are specified using large cliques in the graph,which slow down inference.
Our approach directlyincorporates these constraints into the ranking func-tion, with no impact on inference time.5 ExperimentsWe carried out experiments on the Cora citationdataset.
The task is to segment each citation intodifferent fields, such as ?author?
and ?title?.
We use300 instances as training data, 100 instances as de-velopment data, and 100 instances as test data.
Someinstances from the training data are selected as la-beled instances, and the remaining data (includingdevelopment) as unlabeled.
We use the same token-label constraints as Chang et al (2007).We use the objective functions defined in Sec-tion 3, specifically self-training (Self:Fs), directconstraints (Cons:Fc), the combination of the two(Self+Cons:Fsc), and combination of the modelscore and the constraints (Model+Cons:Fmc).
Weset pi = 1.0, ?
= 1.0, ?s = 10, and ?m = 0.0001.Average token accuracy for 5 runs is reported andcompared with CODL1 in Table 1.
We also reportsupervised results from (Chang et al, 2007) andSampleRank.
All of our methods show vast im-provement over the supervised method for smallertraining sizes, but this difference decreases as thetraining size increases.
When the complete trainingdata is used, additional unlabeled data hurts our per-formance.
This is not observed in CODL since theyuse more unlabeled data, which may also explaintheir slightly higher accuracy.
Note that Self+Consperforms better than Self or Cons individually.Model+Cons also performs competitively, andmay potentially outperform other methods if a bet-ter ?m is chosen.
Note, however, that ?m is muchharder to tune than ?s since ?m weighs the contri-bution of the unnormalized model score, the range1We report inference without constraints results fromCODL.
Their results that incorporated constraints were higher,but we do not implement this alternative due to the difficulty inbalancing the model score and constraint weights.731Method 5 10 15 20 25 300Sup.
(CODL) 55.1 64.6 68.7 70.1 72.7 86.1SampleRank 66.5 74.6 75.6 77.6 79.5 90.7CODL 71 76.7 79.4 79.4 82 88.2Self 67.6 75.1 75.8 78.6 80.4 88Cons 67.2 75.3 77.5 78.6 79.4 88.3Self+Cons 71.3 77 77.5 79.5 81.1 87.4Model+Cons 69.8 75.4 75.7 79.3 79.3 90.6Table 1: Tokenwise Accuracy: for different methods as we vary the size of the labeled dataof which depends on many different factors such asproperties of the data, the learning rate, number ofsamples, proposal function, etc.
For self+cons (?s),the ranges of the predictions and constraint penaltiesare fixed and known, making the task simpler.Self training takes 90 minutes to run on average,while Self+Cons and Model+Cons need 100 min-utes.
Since the Cons method skips the inferencestep over unlabeled data, it takes only 30 minutesto run.
As the size of the model and unlabeled dataset grows, this saving will become more significant.Running time of CODL was not reported.6 ConclusionThis work extends the rank-based learning frame-work to semi-supervised learning.
By integratingthe two paradigms, we retain the computational effi-ciency provided by parameter updates within infer-ence, while utilizing unlabeled data and prior knowl-edge.
We demonstrate accuracy improvements on areal-word information extraction dataset.We believe that the method will be of greater ben-efit to learning in complex factor graphs such asjoint models over multiple extraction tasks.
In futurework we will investigate our approach in such set-tings.
Additionally, various sensitivity, convergence,and robustness properties of the method need to beanalyzed.AcknowledgmentsThis work was supported in part by the Center for In-telligent Information Retrieval, in part by SRI Inter-national subcontract #27-001338 and ARFL primecontract #FA8750-09-C-0181, and in part by TheCentral Intelligence Agency, the National Secu-rity Agency and National Science Foundation underNSF grant #IIS-0326249.
Any opinions, findingsand conclusions or recommendations expressed inthis material are the authors?
and do not necessarilyreflect those of the sponsor.ReferencesKedar Bellare, Gregory Druck, and Andrew McCallum.Alternating projections for learning with expectationconstraints.
In UAI, 2009.Mingwei Chang, Lev Ratinov, and Dan Roth.
Guidingsemi-supervision with constraint-driven learning.
InACL, 2007.Michael Collins.
Discriminative training methods forhidden markov models: Theory and experiments withperceptron algorithm.
In ACL, 2002.Aron Culotta, Michael Wick, and Andrew McCallum.First-order probabilistic models for coreference reso-lution.
In NAACL/HLT, 2007.John Lafferty, Andrew McCallum, and Fernando Pereira.Conditional random fields: probabilistic models forsegmenting and labeling sequence data.
In ICML,2001.Xiao Li.
On the use of virtual evidence in conditionalrandom fields.
In EMNLP, 2009.Gideon S. Mann and Andrew McCallum.
Generalized ex-pectation criteria for semi-supervised learning of con-ditional random fields.
In ACL, 2008.Andrew McCallum, Karl Schultz, and Sameer Singh.FACTORIE: probabilistic programming via impera-tively defined factor graphs.
In NIPS, 2009.Sameer Singh, Karl Schultz, and Andrew McCallum.Bi-directional joint inference for entity resolutionand segmentation using imperatively-defined factorgraphs.
In ECML/PKDD, 2009.Michael Wick, Khashayar Rohanimanesh, Aron Culotta,and Andrew McCallum.
SampleRank: Learning pref-erences from atomic gradients.
In NIPS Workshop onAdvances in Ranking, 2009.732
