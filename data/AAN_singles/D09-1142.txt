Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1368?1377,Singapore, 6-7 August 2009. c?2009 ACL and AFNLPWhat?s in a name?
In some languages, grammatical genderVivi NastaseEML Research gGmbHHeidelberg, Germanynastase@eml-research.deMarius PopescuDepartment of Mathematics and Computer ScienceUniversity of Bucharest, Bucharest, Romaniampopescu@phobos.cs.unibuc.roAbstractThis paper presents an investigation of therelation between words and their gender intwo gendered languages: German and Ro-manian.
Gender is an issue that has longpreoccupied linguists and baffled languagelearners.
We verify the hypothesis thatgender is dictated by the general soundpatterns of a language, and that it goesbeyond suffixes or word endings.
Exper-imental results on German and Romaniannouns show strong support for this hypoth-esis, as gender prediction can be done withhigh accuracy based on the form of thewords.1 IntroductionFor speakers of a language whose nouns have nogender (such as modern English), making the leapto a language that does (such as German), doesnot come easy.
With no or few rules or heuris-tics to guide him, the language learner will try todraw on the ?obvious?
parallel between grammat-ical and natural gender, and will be immediatelybaffled to learn that girl ?
Ma?dchen ?
is neuter inGerman.
Furthermore, one may refer to the sameobject using words with different gender: car canbe called (das) Auto (neuter) or (der) Wagen (mas-culine).
Imagine that after hard work, the speakerhas mastered gender in German, and now wishesto proceed with a Romance language, for exampleItalian or Spanish.
He is now confronted with thetask of relearning to assign gender in these newlanguages, made more complex by the fact thatgender does not match across languages: e.g.
sun?
feminine in German (die Sonne), but masculinein Spanish (el sol), Italian (il sole) and French (lesoleil); moon ?
masculine in German (der Mond),but feminine in Spanish (la luna), Italian (la luna)and French (la lune).
Gender doesn?t even matchwithin a single language family: travel ?
mascu-line in Spanish (el viage) and Italian (il viaggio),but feminine in Portuguese (a viagem).Grammatical gender groups nouns in a lan-guage into distinct classes.
There are languageswhose nouns are grouped into more or less thanthree classes.
English for example has none, andmakes no distinction based on gender, althoughOld English did have three genders and sometraces remain (e.g.
blonde, blond).Linguists assume several sources for gender: (i)a first set of nouns which have natural gender andwhich have associated matching grammatical gen-der; (ii) nouns that resemble (somehow) the nounsin the first set, and acquire their grammatical gen-der through this resemblance.
Italian and Roma-nian, for example, have strong and reliable phono-logical correlates (Vigliocco et al, 2004b, for Ital-ian).
(Doca, 2000, for Romanian).
In Romanianthe majority of feminine nouns end in a?
or e. Somerules exists for German as well (Schumann, 2006),for example nouns ending in -ta?t, -ung, -e, -enz,-ur, -keit, -in tend to be feminine.
Also, whenspecific morphological processes apply, there arerules that dictate the gender of the newly formedword.
This process explains why Frau (woman) isfeminine in German, while Fra?ulein (little woman,miss) is neuter ?
Fra?ulein = Frau + lein.
The ex-isting rules have exceptions, and there are numer-ous nouns in the language which are not derived,and such suffixes do not apply.Words are names used to refer to concepts.
Thefact that the same concept can be referred to usingnames that have different gender ?
as is the casefor car in German ?
indicates that at least in somecases, grammatical gender is in the name and notthe concept.
We test this hypothesis ?
that the gen-der of a noun is in its word form, and that this goesbeyond word endings ?
using noun gender datafor German and Romanian.
Both Romanian andGerman have 3 genders: masculine, feminine and1368neuter.
The models built using machine learningalgorithms classify test nouns into gender classesbased on their form with high accuracy.
These re-sults support the hypothesis that in gendered lan-guages, the word form is a strong clue for gender.This supplements the situation when some con-cepts have natural gender that matches their gram-matical gender: it allows for an explanation wherethere is no such match, either directly perceived,or induced through literary devices.The present research has both theoretical andpractical benefits.
From a theoretical point ofview, it contributes to research on phonology andgender, in particular in going a step further in un-derstating the link between the two.
From a practi-cal perspective, such a connection between genderand sounds could be exploited in advertising, inparticular in product naming, to build names thatfit a product, and which are appealing to the de-sired customers.
Studies have shown that espe-cially in the absence of meaning, the form of aword can be used to generate specific associationsand stimulate the imagination of prospective cus-tomers (Sells and Gonzales, 2003; Bedgley, 2002;Botton et al, 2002).2 GenderWhat is the origin of grammatical gender and howdoes it relate to natural gender?
Opinions are split.Historically, there were two main, opposite, views:(i) there is a semantic explanation, and naturalgender motivated the category (ii) the relationshipbetween natural and grammatical gender is arbi-trary.Grimm (1890) considered that grammaticalgender is an extension of natural gender broughton by imagination.
Each gender is associatedwith particular adjectives or other attributes, and insome cases (such as for sun and moon) the assign-ment of gender is based on personification.
Brug-mann (1889) and Bloomfield (1933) took the po-sition that the mapping of nouns into genders isarbitrary, and other phenomena ?
such as deriva-tions, personification ?
are secondary to the estab-lished agreement.
Support for this second viewcomes also from language acquisition: childrenwho learn a gendered language do not have a nat-ural gender attribute that they try to match ontothe newly acquired words, but learn these in a sep-arate process.
Any match or mapping betweennatural and grammatical gender is done after thenatural gender ?feature?
is acquired itself.
Ki-larski (2007) presents a more detailed overviewof currents and ideas about the origin of gender.Unterbeck (1999) contains a collection of papersthat investigate grammatical gender in several lan-guages, aspects of gender acquisition and its rela-tion with grammatical number and agreement.There may be several reasons for the polemicbetween these two sides.
One may come from thecategorization process, the other from the relationbetween word form and its meaning.
Let us takethem each in turn, and see how they influencedgender.Grammatical gender separates the nouns in alanguage into disjoint classes.
As such, it is a cat-egorization process.
The traditional ?
classical ?theory of categorization and concepts viewed cat-egories and concepts as defined in terms of a setof common properties that all its members shouldshare.
Recent theories of concepts have changed,and view concepts (and categories) not necessar-ily as ?monolithic?
and defined through rules, butrather as clusters of members that may resembleeach other along different dimensions (Margolisand Laurence, 1999).In most linguistic circles, the principle of ar-bitrariness of the association between form andmeaning, formalized by de Saussure (1916) hasbeen largely taken for granted.
It seems however,that it is hard to accept such an arbitrary relation,as there have always been contestants of this prin-ciple, some more categorical than others (Jakob-son, 1937; Jespersen, 1922; Firth, 1951).
It is pos-sible that the correlation we perceive between theword form and the meaning is something that hasarisen after the word was coined in a language, be-ing the result of what Firth called ?phonetic habit?through ?an attunement of the nervous system?,and that we have come to prefer, or select, cer-tain word forms as more appropriate to the con-cept they name ?
?There is no denying that thereare words which we feel instinctively to be ade-quate to express the ideas they stand for.
... Soundsymbolism, we may say, makes some words morefit to survive?
(Jespersen, 1922).These two principles relate to the discussionon gender in the following manner: First of all,the categories determined by grammatical gen-der need not be homogeneous, and their mem-bers need not all respect the same member-ship criterion.
This frees us from imposing amatching between natural and grammatical gen-der where no such relation is obvious or pos-1369sible through literary devices (personification,metaphor, metonymy).
Nouns belonging to thesame gender category may resemble each otherbecause of semantic considerations, lexical deriva-tions, internal structure, perceived associationsand so on.
Second, the fact that we allow for thepossibility that the surface form of a word mayencode certain word characteristics or attributes,allows us to hypothesize that there is a surface,phonological, similarity between words groupedwithin the same gender category, that can supple-ment other resemblance criteria in the gender cat-egory (Zubin and Ko?pcke, 1986).Zubin and Ko?pcke (1981), Zubin and Ko?pcke(1986) have studied the relation between seman-tic characteristics and word form with respect togender for German nouns.
Their study was mo-tivated by two observations: Zipf (1935) showedthat word length is inversely correlated with fre-quency of usage, and Brown (1958) proposed thatin choosing a name for a given object we are morelikely to use a term corresponding to a ?basic?level concept.
For example, chair, dog, applewould correspond to the basic level, while furni-ture, animal, fruit and recliner, collie, braeburnapple correspond to a more general or a morespecific level, respectively.
Their study of gen-der relative to these levels have shown that basiclevel terms have masculine, feminine, and rarelyneuter genders, while the more undifferentiatedcategories at the superordinate level are almost ex-clusively neuter.In psycholinguistic research, Friederici and Ja-cobsen (1999) adopt the position that a lexicalentry consists of two levels: form and seman-tic and grammatical properties to study the influ-ence of gender priming ?
both from a form andsemantic perspective ?
on language comprehen-sion.
Vigliocco et al (2004a) study gender prim-ing for German word production.
While this re-search studies the influence of the word form onthe production of nouns with the same or differentgrammatical gender, there is no study of the rela-tion between word forms and their correspondinggender.In recent studies we have found on the rela-tion between word form and its associated gender,the only phonological component of a word thatis considered indicative is the ending.
Spalek etal.
(2008) experiment on French nouns, and testwhether a noun?s ending is a strong clue for gen-der for native speakers of French.
Vigliocco et al(2004b) test cognitive aspects of grammatical gen-der of Italian nouns referring to animals.Cucerzan and Yarowsky (2003) present a boot-strapping process to predict gender for nouns incontext.
They show that context gives accurateclues to gender (in particular through determiners,quantifiers, adjectives), but when the context is notuseful, the algorithm can fall back successfully onthe word form.
Cucerzan and Yarowsky modelthe word form for predicting gender using suffixtrie models.
When a new word is encountered, theword is mapped onto the trie starting from the lastletter, and it is assigned the gender that has thehighest probability based on the path it matches inthe trie.
In context nouns appear with various in-flections ?
for number and case in particular.
Suchmorphological derivations are gender specific, andas such are strong indicators for gender.The hypothesis tested here is that gender comesfrom the general sound of the language, and is dis-tributed throughout the word.
For this, the dataused should not contain nouns with ?tell tale?
in-flections.
The data will therefore consist of nounsin the singular form, nominative case.
Some nounsare derived from verbs, adverbs or adjectives, orother nouns through morphological derivations.These derivations are regular and are identifiablethrough a rather small number of regular suffixes.These suffixes (when they are indicative of gen-der) and word endings will be used as baselinesto compare the accuracy of prediction on the fullword with the ending fragment.3 DataWe test our gender-language sounds connectionthrough two languages from different languagefamilies.
German will be the representative of theGermanic languages, and Romanian for the Ro-mance ones.
We first collect data in the two lan-guages, and then represent them through variousfeatures ?
letters, pronunciation, phonetic features.3.1 Noun collectionsGerman data For German we collect nouns andtheir grammatical gender from a German-Englishdictionary, part of the BEOLINGUS multi-lingualdictionary1.
In the first step we collected the Ger-man nouns and their gender from this dictionary.In step 2, we filter out compounds.
The reasonfor this step is that a German noun compound will1http://dict.tu-chemnitz.de/1370have the gender of its head, regardless of its nom-inal modifiers.
For the lack of a freely availabletool to detect and split noun compounds, we resortto the following algorithm:1. initialize the list of nouns LNto the emptylist;2. take each noun n in the dictionary D, and(a) if ?ni?
LNsuch that n is an end sub-string of ni, then add n to LNand re-move nifrom LN;(b) if ?ni?
LNsuch that niis a end sub-string of n, skip n;Essentially, we remove from the data all nounsthat include another noun as the end part (whichis the head position in German noun compounds).This does not filter examples that have suffixesadded to form the feminine version of a masculinenoun, for example: (der) Lehrer ?
(die) Lehrerin(teacher).
The suffixes are used in one of the base-lines for comparison with our learning method.We obtain noun pronunciation information fromthe Bavarian Archive for Speech Signals2.
We fil-ter again our list LNto keep nouns for which wehave pronunciation information.
This allows us tocompare the learning results when letter or pro-nunciation information is used.After collecting the nouns and their pronunci-ation, we map the pronunciation onto lower levelphonetic features, following the IPA encoding ofsounds for the German language.
The mappingbetween sounds and IPA features was manuallyencoded following IPA tables.Romanian data We extract singular nomina-tive forms of nouns from the Romanian lexicaldatabase (Barbu, 2008).
The resource containsthe proper word spelling, including diacritics andspecial characters.
Because of this and the factthat there is a straightforward mapping betweenspelling and pronunciation in Romanian, we canuse the entire data extracted from the dictionaryin our experiments, without special pronunciationdictionaries.
Following the example for the Ger-man language, we encode each sound throughlower level phonological features using IPA guide-lines.As in Italian, in Romanian there are strongphonological cues for nouns, especially those hav-ing the feminine gender: they end in a?
and e.2http://www.phonetik.uni-muenchen.de/Bas/To determine whether the connection between aword form and gender goes beyond this superfi-cial rule, we generate a dataset in which the nounsare stripped of their final letter, and their represen-tation is built based on this reduced form.Table 1 shows the data collected and the distri-bution in the three classes.German Romanianmasc.
565 32.64% 7338 15.14%fem.
665 38.42% 27187 56.08%neut.
501 28.94% 13952 28.78%total 1731 48477Table 1: Data statisticsBecause for Romanian the dataset is ratherlarge, we can afford to perform undersamplingto balance our classes, and have a more straight-forward evaluation.
We generate a perfectly bal-anced dataset by undersampling the feminine andthe neuter classes down to the level of the mascu-line class.
We work then with a dataset of 22014instances, equally distributed among the three gen-ders.3.2 Data representationFor each word in our collections we produce threetypes of representation: letters, phonemes andphonological features.
Table 2 shows examplesfor each of these representations.
The letter andphoneme representations are self-explanatory.
Weobtain the pronunciation corresponding to eachword from a pronunciation dictionary, as men-tioned in Section 3.1, which maps a word onto asequence of phonemes (phones).
For Romanianwe have no such resource, but me make withoutsince in most part the pronunciation matches theletter representation3.Germanletter abend (m) a b e n dphoneme a: b @ n dRomanianletter seara?
(f) s e a r a?Table 2: Data representation in terms of letters andphonemes for the German and Romanian forms ofthe word evening.
For Romanian, the letter andphoneme representation is the same.3The exceptions are the diphthongs and a few groups ofletters: ce, ci, che, chi, oa, and the letter x.1371Phonemes, the building blocks of the phoneticrepresentation, can be further described in termsof phonological features ?
?configurations?
ofthe vocal tract (e.g tongue and lips position),and acoustic characteristics (e.g.
manner ofair flow).
We use IPA standards for mappingphones in German and Romanian onto thesephonological features.
We manually constructa map between phones and features, and thenautomatically binarize this representation anduse it to generate a representation for eachphone in each word in the data.
For the wordabend (de) / seara (ro) (evening) in Figure 2, thephonological feature representation for German is:00001000000010000100000000010001000100000000000010000000000010000000010000000001000110000001000000100000000000001000000100000000000010000000,with the feature base:< alveolar, approximant, back, bilabial, cen-tral, close, closemid, consonant, fricative, front,glottal, labiodental, long, mid, nasal, nearclose,nearopen, open, openmid, palatal, plosive,postalveolar, rounded, short, unrounded, uvular,velar, vowel >.For Romanian, the phonological feature baseis:< accented, affricate, approximant, back, bi-labial, central, close, consonant, dental, fricative,front, glottal, labiodental, mid, nasal, open,plosive, postalveolar, rounded, trill, unrounded,velar, voiced, voiceless, vowel >,and the phonological feature representationof the word changes accordingly.4 Kernel Methods and String KernelsOur hypothesis that the gender is in the name isequivalent to proposing that there are sequences ofletters/sounds/phonological features that are morecommon among nouns that share the same genderor that can distinguish between nouns under differ-ent genders.
To determine whether that is the case,we use a string kernel, which for a given string (se-quence) generates a representation that consists ofall its substrings of length less than a parameter l.The words are represented as strings with bound-aries marked with a special character (?#?).
Thehigh dimensional representation generated by thestring kernel is used to find a hyperplane that sep-arates instances of different classes.
In this sectionwe present in detail the kernel we use.Kernel-based learning algorithms work by em-bedding the data into a feature space (a Hilbertspace), and searching for linear relations in thatspace.
The embedding is performed implicitly,that is by specifying the inner product betweeneach pair of points rather than by giving their co-ordinates explicitly.Given an input set X (the space of examples),and an embedding vector space F (feature space),let ?
: X ?
F be an embedding map called fea-ture map.A kernel is a function k, such that for all x, z ?X , k(x, z) =< ?
(x), ?
(z) >, where < ., .
>denotes the inner product in F .In the case of binary classification problems,kernel-based learning algorithms look for a dis-criminant function, a function that assigns +1 toexamples belonging to one class and ?1 to exam-ples belonging to the other class.
This functionwill be a linear function in the space F , that meansit will have the form:f(x) = sign(< w, ?
(x) > +b),for some weight vector w. The kernel can beexploited whenever the weight vector can be ex-pressed as a linear combination of the trainingpoints,n?i=1?i?
(xi), implying that f can be ex-pressed as follows:f(x) = sign(n?i=1?ik(xi, x) + b).Various kernel methods differ in the way inwhich they find the vector w (or equivalently thevector ?).
Support Vector Machines (SVM) try tofind the vector w that define the hyperplane thatmaximum separate the images in F of the train-ing examples belonging to the two classes.
Math-ematically SVMs choose the w and b that satisfythe following optimization criterion:minw,b1nn?i=1[1?
yi(< w, ?
(xi) > +b)]++ ?||w||2where yiis the label (+1/?1) of the training ex-ample xi, ?
a regularization parameter and [x]+=max(x, 0).1372Kernel Ridge Regression (KRR) selects the vec-tor w that simultaneously has small empirical er-ror and small norm in Reproducing Kernel HilbertSpace generated by kernel k. The resulting mini-mization problem is:minw1nn?i=1(yi?
< w, ?
(xi) >)2+ ?||w||2where again yiis the label (+1/?1) of the trainingexample xi, and ?
a regularization parameter.
De-tails about SVM and KRR can be found in (Taylorand Cristianini, 2004).
What is important is thatabove optimization problems are solved in such away that the coordinates of the embedded pointsare not needed, only their pairwise inner productswhich in turn are given by the kernel function k.SVM and KRR produce binary classifiers andgender classification is a multi-class classificationproblem.
There are a lot of approaches for com-bining binary classifiers to solve multi-class prob-lems.
We used one-vs-all scheme.
For argumentsin favor of one-vs-all see (Rifkin and Klautau,2004).The kernel function offers to the kernel methodsthe power to naturally handle input data that arenot in the form of numerical vectors, for examplestrings.
The kernel function captures the intuitivenotion of similarity between objects in a specificdomain and can be any function defined on therespective domain that is symmetric and positivedefinite.
For strings, a lot of such kernel functionsexist with many applications in computational bi-ology and computational linguistics (Taylor andCristianini, 2004).Perhaps one of the most natural ways to mea-sure the similarity of two strings is to count howmany substrings of length p the two strings havein common.
This give rise to the p-spectrum ker-nel.
Formally, for two strings over an alphabet ?,s, t ?
?
?, the p-spectrum kernel is defined as:kp(s, t) =?v?
?pnumv(s)numv(t)where numv(s) is the number of occurrences ofstring v as a substring in s 4 The feature map de-fined by this kernel associate to each string a vec-tor of dimension |?|p containing the histogram offrequencies of all its substrings of length p. Taking4Note that the notion of substring requires contiguity.
See(Taylor and Cristianini, 2004) for discussion about the am-biguity between the terms ?substring?
and ?subsequence?across different traditions: biology, computer science.into account all substrings of length less than p itwill be obtained a kernel that is called the blendedspectrum kernel:kp1(s, t) =p?q=1kq(s, t)The blended spectrum kernel will be the ker-nel that we will use in conjunction with SVM andKRR.
More precisely we will use a normalizedversion of the kernel to allow a fair comparisonof strings of different length:?kp1(s, t) =kp1(s, t)?kp1(s, s)kp1(t, t)5 Experiments and ResultsWe performed 10-fold cross-validation learningexperiments with kernel ridge regression and thestring kernel (KRR-SK) presented in Section 4.We used several baselines to compare the resultsof the experiments against:BL-R Gender is assigned following the distribu-tion of genders in the data.BL-M Gender is assigned following the majorityclass (only for German, for Romanian we usebalanced data).BL-S Gender is assigned based on suffix-genderrelation found in the literature.
We use thefollowing mappings:?
German (Schumann, 2006):feminine -ade, -age, -anz, -e, -ei, -enz,-ette, -heit, -keit, -ik, -in, -ine, -ion, -itis, -ive, -schaft, -ta?t, -tur, -ung, -ur;masculine -ant, -er, -ich, -ismus, -ling;neuter -chen, -ist, -lein, -ment, -nis, -o,-tel, -um.In our data set the most dominant gen-der is feminine, therefore we assign thisgender to all nouns that do not matchany of the previous suffixes.
Table 4shows a few suffixes for each gender,and an example noun.?
Romanian: in Romanian the word end-ing is a strong clue for gender, especiallyfor feminine nouns: the vast majorityend in either -e or -a?
(Doca, 2000).
Wedesign a heuristic that assigns the gen-der ?preferred?
by the last letter ?
the1373Method Accuracy masc.
F-score fem.
F-score neut.
F-scoreGermanBL-R 33.79BL-M 38.42BL-S 51.35 40.83 62.42 26.69KRR-SK 72.36 ?
3 64.88 ?
5 84.34 ?
4 64.44 ?
7KRR-SKnoWB66.91 58.77 79.19 58.26RomanianBL-R 33.3BL-S 74.38 60.65 97.96 63.93KRR-SK 78.83 ?
0.8 68.74 ?
0.9 98.05 ?
0.2 69.38 ?
2KRR-SK no last letter 65.73 ?
0.6 56.11 ?
1 85.00 ?
0.5 55.05 ?
1KRR-SKnoWB77.36 67.54 96.75 67.39Table 3: 10-fold cross-validation results ?
accuracy and f-scores percentages (?
variation over the 10runs) ?
for gender learning using string kernelsGermangender suffix examplefem.
-e Ecke (corner)-heit Freiheit (freedom)-ie Komo?die (comedy)masc.
-er Fahrer (driver)-ich Rettich (radish)-ling Fru?hling (spring - season)neut.
-chen Ma?dchen (girl)-nis Versta?ndnis (understanding)-o Auto (car)Table 4: Gender assigning rules and examples forGermanmajority gender of all nouns ending inthe respective letter ?
based on analy-sis of our data.
In Table 5 we includesome of the letter endings with an exam-ple noun, and a percentage that showsthe precision of the ending in classify-ing the noun in the gender indicated inthe table.The results of our experiments are presentedin Table 3, in terms of overall accuracy, and f-score for each gender.
The performance presentedcorresponds to the letter-based representation ofwords.
It is interesting to note that this represen-tation performed overall better than the phonemeor phonological feature-based ones.
An explana-Romaniangender ending example Prec.fem.
-a?
masa?
(table) 98.04-e pa?ine (bread) 97.89masc.
-g sociolog (sociologist) 72.77-r nor (cloud) 66.89-n domn (gentleman) 58.45neut.
-m algoritm (algorithm) 90.95-s vers (verse) 66.97-t eveniment (event) 51.02Table 5: Word-ending precision on classifyinggender and examples for Romaniantion may be that in both the languages we consid-ered, there is an (almost) one-to-one mapping be-tween letters and their pronunciation, making thusthe pronunciation-based representation unneces-sary.
As such, the letter level captures the interest-ing commonalities, without the need to go downto the phoneme-level.We performed experiments for Romanian whenthe last letter of the word is removed.
The reasonfor this batch of experiments is to further test thehypothesis that gender is more deeply encoded in aword form than just the word ending.
For both lan-guages we observe statistically significant higherperformance than all baselines.
For Romanian,the last letter heuristic gives a very high baseline,confirming that Romanian has strong phonologi-cal cues for gender in the ending.
Had the wordending been the only clue to the word?s gender,13740204060801000  5  10  15  20  25# of letters considered from endRomanianclassification accuracyword length percentages30354045505560657075800  1  2  3  4  5  6  7accuracy# of letters cut from endRomanianword without last lettersbaseline0204060801000  2  4  6  8  10  12  14  16  18  20# of letters considered from endGermanclassification accuracyword length percentages3540455055606570750  1  2  3  4  5  6accuracy# of letters cut from endGermanword without last lettersbaselineFigure 1: Gender prediction based on the last N letters, and based on the word minus the last N lettersonce it is removed the performance on recogniz-ing gender should be close to the random assign-ment.
This is not the case, and the improvementover the random baseline is 32% points.
It is inter-esting to notice that when cutting off the last letterthe class for which the gender assignment heuris-tic was clearest ?
the feminine class with -a?
and-e endings ?
the performance remains very high ?85% F-score.To further test where the gender indicators arelocated, we performed two more sets of experi-ments: (i) classify words in their correspondinggender class using the word minus the last N let-ters; (ii) classify words based on the last N let-ters.
The results of these experiments in terms ofaccuracy are presented in Figure 1.
When con-sidering only the last N letters the performance ishigh for both German and Romanian, as expectedif the gender indicators are concentrated at the endof the word.
It is interesting though to notice theresults of classification based on the word withoutthe last N letters.
The prediction accuracy mono-tonically decreases, but remains above the base-line until more than 6 letters are cut.
Because asletters are cut some words completely disappear,the baseline changes accordingly.
94.07% of thewords have a length of at most 12 letters in theRomanian dataset, and 96.07% in the German one.Because gender prediction can be done with accu-racy higher than the random baseline even after 6letters are cut from the ending of the word indicatethat for more than 94% of the words considered,gender clues are spread over more than the secondhalf of the word.
Again, we remind the reader thatthe word forms are in nominative case, with nocase or number inflections (which are strong indi-cators of gender in both Romanian and German).Except for lines KRR ?
SKnoWB, the resultsin Table 3 are obtained through experiments con-ducted on words containing word boundary mark-ers, as indicated in Section 4.
Because of thesemarkers, word starting or word ending substringsare distinct from all the others, and informationabout their position in the original word is thuspreserved.
To further explore the idea that genderindicators are not located only in word endings,we ran classification experiments for German andRomanian when the word representation does notcontain word boundary markers.
This means thatthe substrings generated by the string kernel have1375no position information.
The results of these ex-periments are presented in rows KRR?SKnoWBin Table 3.
The accuracy is slightly lower than thebest results obtained when word boundaries aremarked and the entire word form is used.
How-ever, they are well above all the baselines consid-ered, without no information about word endings.For both German and Romanian, the gender thatwas learned best was feminine.
For German partof this effect is due to the fact that the feminineclass is more numerous in the data.
For Roma-nian the data was perfectly balanced, so there is nosuch bias.
Neuter and masculine nouns have lowerlearning performance.
For Romanian, a contri-bution to this effect is the fact that neuter nounsbehave as masculine nouns in their singular form(take the same articles, inflections, derivations),but as feminine in the plural, and our data consistsof nouns in singular form.
It would seem that froman orthographic point of view, neuter and mascu-line nouns are closer to each other than to femininenouns.From the reviewed related work, the one thatuses the word form to determine gender isCucerzan and Yarowsky (2003) for Romanian.There are two important differences with respectto the approach presented here.
First, they con-sider words in context, which are inflected fornumber and case.
Number and case inflectionsare reflected in suffixes that are gender specific.The words considered here are in singular form,nominative case ?
as such, with no inflections.Second, Cucerzan and Yarowsky consider twoclasses: feminine vs. masculine and neuter.
Mas-culine and neuter nouns are harder to distinguish,as in singular form neuter nouns behave like mas-culine nouns in Romanian.
While the datasets andword forms used by Cucerzan and Yarowsky aredifferent than the one used here, the reader maybe curious how well the word form distinguishesbetween feminine and the other two classes inthe experimental set-up used here.
On the full5Romanian dataset described in Section 3, a twoclass classification gives 99.17% accuracy.
Whenpredicting gender for all words in their dataset,Cucerzan and Yarowsky obtain 98.25% accuracy.6 ConclusionWhen a speaker of a genderless language tries tolearn a language with grammatical gender, it is5By ?full?
we mean the dataset before balancing theclasses 48,477 instances (see Table 1).very tempting to try to assign grammatical gen-der based on perceived or guessed natural gendertypes.
This does not work out well, and it onlyserves to confuse the learner even more, when hefinds out that nouns expressing concepts with clearfeminine or masculine natural gender will have theopposite or a neutral grammatical gender, or thatone concept can be referred to through names thathave different grammatical genders.
Going withthe flow of the language seems to be a better idea,and allow the sound of a word to dictate the gen-der.In this paper we have investigated the hypothe-sis that gender is encoded in the word form, andthis encoding is more than just the word endingsas it is commonly believed.
The results obtainedshow that gender assignment based on word formanalysis can be done with high accuracy ?
72.36%for German, and 78.83% for Romanian.
Existinggender assignment rules based on word endingshave lower accuracy.
We have further strength-ened the point by conducting experiments on Ro-manian nouns without tell-tale word endings.
Theaccuracy remains high, with remarkably high per-formance in terms of F-score for the feminineclass (85%).
This leads us to believe that gen-der information is somehow redundantly coded ina word.
We plan to look closer at cases wherewe obtain different predictions based on the wordending and the full form of the word, and useboosting to learn weights for classifiers based ondifferent parts of the word to see whether we canfurther improve the results.As we have underlined before, word form simi-larity between words under the same gender is onecriterion for gender assignment.
It would be in-teresting to verify whether gender recognition canbe boosted by using lexical resources that capturethe semantics of the words, such as WordNets orknowledge extracted from Wikipedia, and verifywhether similarities from a semantic point of vieware also responsible for gender assignments in var-ious languages.ReferencesAna-Maria Barbu.
2008.
Romanian lexical databases: Inflected and syllabic forms dictionar-ies.
In Proceedings of the Sixth InternationalLanguage Resources and Evaluation (LREC?08).http://www.lrec-conf.org/proceedings/lrec2008/.Sharon Bedgley.
2002.
Strawberry isno blackberry: Building brands us-1376ing sound.
http://online.wsj.com/article/0,,SB1030310730179474675.djm,00.html.Leonard Bloomfield.
1933.
Language.
Holt, Reinhart& Winston, New York.Marcel Botton, Jean-Jack Cegarra, and Beatrice Fer-rari.
2002.
Il nome della marca: creazione e strate-gia di naming, 3rd edition.
Guerini e Associati.Roger Brown.
1958.
Words and Things.
The FreePress, New York.Karl Brugmann.
1889.
Das Nominalgeschlechtin den indogermanischen Sprachen.
In Inter-nationale Zeitschrift fu?r allgemenine Sprachwis-senschaft, pages 100?109.S.
Cucerzan and D. Yarowsky.
2003.
Minimally super-vised induction of grammatical gender.
In Proceed-ings of HLT-NAACL 2003, pages 40?47.Ferdinand de Saussure.
1916.
Cours de linguistiquege?ne?rale.
Harrassowitz, Wiesbaden.Gheorghe Doca Doca.
2000.
Romanian language.
Vol.II: Morpho-Syntactic and Lexical Structures.
ArsDocendi, Bucharest, Romania.John Rupert Firth.
1951.
Modes and meaning.
InPapers in linguistics 1934-1951.
Oxford UniversityPress, London.Angela Friederici and Thomas Jacobsen.
1999.
Pro-cessing grammatical gender during language com-prehension.
Journal of Psychological Research,28(5):467?484.Jacob Grimm.
1890.
Deutsche Grammatik.Roman Jakobson.
1937.
Lectures on Sound and Mean-ing.
MIT Press, Cambridge, MA.Otto Jespersen.
1922.
Language - its Nature, Devel-opment and Origin.
George Allen & Unwim Ltd.,London.Marcin Kilarski.
2007.
On grammatical gender as anarbitrary and redundant category.
In Douglas Kil-bee, editor, History of Linguistics 2005: Selected pa-pers from the 10th International Conference on theHistory of Language Sciences (ICHOLS X), pages24?36.
John Benjamins, Amsterdam.Eric Margolis and Stephen Laurence, editors.
1999.Concepts: Core Readings.
MIT Press.Ryan Rifkin and Aldebaro Klautau.
2004.
In de-fense of one-vs-all classification.
Journal of Ma-chine Learning Research, 5(January):101?141.Johannes Schumann.
2006.
Mittelstufe Deutsch.
MaxHueber Verlag.Peter Sells and Sierra Gonzales.2003.
The language of advertising.http://www.stanford.edu/class/linguist34/; inparticular unit 8: ?/Unit 08/blackberry.htm.Katharina Spalek, Julie Franck, Herbert Schriefers, andUlrich Frauenfelder.
2008.
Phonological regulari-ties and grammatical gender retrieval in spoken wordrecognition and word production.
Journal of Psy-cholinguistic Research, 37(6):419?442.John S. Taylor and Nello Cristianini.
2004.
KernelMethods for Pattern Analysis.
Cambridge Univer-sity Press, New York, NY, USA.Barbara Unterbeck, editor.
1999.
Gender in Grammarand Cognition.
Approaches to Gender.
Trends inLinguistics.
Studies and Monographs.
124.
Moutonde Gruyter.Gabriela Vigliocco, David Vinson, Peter Indefrey,Willem Levelt, and Frauke Hellwig.
2004a.
Role ofgrammatical gender and semantics in german wordproduction.
Journal of Experimental Psychology:Learning, Memory and Cognition, 30(2):483?497.Gabriela Vigliocco, David Vinson, and Federica Pa-ganelli.
2004b.
Grammatical gender and meaning.In Proc.
of the 26th Meeting of the Cognitive ScienceSociety.George Zipf.
1935.
The Psychobiology of Language.Addison-Wesley.David Zubin and Klaus-Michael Ko?pcke.
1981.
Gen-der: A less than arbitrary grammatical category.
InR.
Hendrick, C. Masek, and M. F. Miller, editors,Papers from the seventh regional meeting, pages439?449.
Chicago Linguistic Society, Chicago.David Zubin and Klaus-Michael Ko?pcke.
1986.
Gen-der and folk taxonomy: The indexical relation be-tween grammatical and lexical categorization.
InC. Craig, editor, Noun classes and categorization,pages 139?180.
Benjamins, Philadelphia.1377
