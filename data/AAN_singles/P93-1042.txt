HOW DO WE COUNT?THE PROBLEM OF TAGGING PHRASAL VERBS IN PARTSNava A. ShakedThe  Graduate  School  and  Un ivers i ty  CenterThe  C i ty  Un ivers i ty  of New York33 West  42nd St reet .
New York,  NY  10036nava@nynexst .comABSTRACTThis paper examines the current performance of thestochastic tagger PARTS (Church 88) in handling phrasalverbs, describes a problem that arises from the statis-tical model used, and suggests a way to improve thetagger's performance.
The solution involves a changein the definition of what counts as a word for the pur-pose of tagging phrasal verbs.1.
INTRODUCTIONStatistical taggers are commonly used to preprocessnatural anguage.
Operations like parsing, informationretrieval, machine translation, and so on, are facilitatedby having as input a text tagged with a part of speechlabel for each lexical item.
In order to be useful, a tag-ger must be accurate as well as efficient.
The claimamong researchers advocating the use of statistics forNLP (e.g.
Marcus et al 92) is that taggers are routinelycorrect about 95% of the time.
The 5% error rate is notperceived as a problem mainly because human taggersdisagree or make mistakes at approximately the samerate.
On the other hand, even a 5% error rate can causea much higher rate of mistakes later in processing ifthe mistake falls on a key element hat is crucial to thecorrect analysis of the whole sentence.
One exampleis the phrasal verb construction (e.g.
gun down, backoff).
An error in tagging this two element sequence willcause the analysis of the entire sentence to be faulty.An analysis of the errors made by the stochastic tag-ger PARTS (Church 88) reveals that phrasal verbs doindeed constitute a problem for the model.2.
PHRASAL  VERBSThe basic assumption underlying the stochastic pro-cess is the notion of independence.
Words are definedas units separated by spaces and then undergo statis-tical approximations.
As a result the elements of aphrasal verb are treated as two individual words, eachwith its own lexical probability (i.e.
the probability ofobserving part of speech i given word j).
An interestingpattern emerges when we examine the errors involvingphrasal verbs.
A phrasal verb such as sum up will betagged by PARTS as noun + preposition instead ofverb + particle.
This error influences the tagging ofother words in the sentence as well.
One typical erroris found in infinitive constructions, where a phrase liketo gun down is tagged as INTO NOUN IN (a prepo-sitional 'to' followed by a noun followed by anotherpreposition).
Words like gun, back, and sum, in iso-lation, have a very high probability of being nouns a.sopposed to verbs, which results in the misclassificationdescribed above.
However, when these words are fol-lowed by a particle, they are usually verbs, and in theinfinitive construction, always verbs.2.1.
THE HYPOTHESISTile error appears to follow froln the operation of thestochastic process itself.
In a trigram model the proba-bility of each word is calculated by taking into consider-ation two elements: the lexical probability (probabilityof the word bearing a certain tag) and the contextualprobability (probability of a word bearing a certain taggiven two previous parts of speech).
As a result, if anelement has a very high lexical probability of being anoun (gun is a noun in 99 out of 102 occurrences in theBrown Corpus), it will not only influence but will ac-tually override the contextual probability, which mightsuggest a different assignment.
In the case of to gundown the ambiguity of to is enhanced by the ambiguityof gun, and a mistake in tagging gun will automaticallylead to an incorrect agging of to as a preposition.It follows that the tagger should perform poorly on289phrasal verbs in those cases where the ambiguous el-ement occurs much more frequenty as a noun (or anyother element hat is not a verb).The tagger will expe-rience fewer problems handling this construction whenthe ambiguous element is a verb in the vast majority ofinstances.
If this is true, the model should be changedto take into consideration the dependency between theverb and the particle in order to optimize the perfor-mance of the tagger.3.
THE EXPERIMENT3.1.
DATAThe first step in testing this hypothesis was to evalu-ate the current performance of PARTS in handling thephrasal verb construction.
To do this a set of 94 pairsof Verb+Particle/Preposition was chosen to representa range of dominant frequencies from overwhelminglynoun to overwhelmingly verb.
20 example sentenceswere randomly selected for each pair using an on-linecorpus called MODERN, which is a collection of severalcorpora (Brown, WSJ, AP88-92, HANSE, HAROW,WAVER, DOE, NSF, TREEBANK, and DISS) total-ing more than 400 million words.
These sentences werefirst tagged manually to provide a baseline and thentagged automatically using PARTS.
The a priori op-tion of assuming only a verbal tag for all the pairs inquestion was also explored in order to test if this simplesolution will be appropriate in all cases.
The accuracyof the 3 tagging approaches was evaluated.3.2.
RESULTSTable 2 presents a sample of the pairs examined in tilefirst column, PARTS performance for each pair in tilesecond, and the results of assuming a verbal tag in thethird.
(The "choice" colunm is explained below.
)The average performance of PARTS for this task is89%, which is lower than the general average perfor-mance of the tagger as claimed in Church 88.
Yet wenotice that simply assigning a verbal tag to all pairs ac-tually degrades performance because in some cases thecontent word is a.lmost always a noun rather than averb.
For example, a phrasal verb like box in generallyappears with an intervening object (to box somethingin), and thus when box and in are adjacent (except forthose rare cases involving heavy NP shift) box is a noun.Thus we see that there is a need to distinguish be-tween the cases where the two element sequence shouldbe considered as one word for the purpose of assign-iug the Lexical Probability (i.e.,phrasal verb) and caseswhere we have a Noun + Preposition combination wherePARTS' analyses will be preferred.
The "choice" inPHRASAL IMP.VERBFREQ.
DIST.
(BROWN)date-from 1.00 dateflesh-out 0.59 fleshbottle-up 0.55 bottlehand-over 0.35 handnarrow-down 0.23 narrowclose-down 0.22 closedrive-off 0.22 drivecry-out 0.21 cryaverage-out 0.20 averagehead-for 0.18 headend-up 0.16 endaccount-for 0.15 accountdouble-up 0.14 doubleback-off 0.13 backcool-off 0.13 coolclear-out 0.12 clearcahn-down 0.10 cMmNN/98 VB/6NN/53 VB/1NN/77 VB/1NN/411 VB/8JJ/61 NN/1 VB/1J J/81 NN/16QL/1 RB/95 VB/40NN/49 VB/46NN/31 VB/19J J/64 NN/60 VB/6J J /4 NN/404 VB/14NN/359 VB/41NN/89 VB/28JJ/37 NN/ l l  RB/4VB/6J J/27 NN/177 RB/720VB/26J J/49 NN/3RB/1 VB/SJ J/197 NN/1RB/10 VB/15JJ/22 NN/8 VB/7Table 1: 10% or more improvement for elements of nonverbal frequency.Table 2 shows that allowing a choice between PARTS'analysis and one verbal tag to the phrase by taking thehigher performance score, improves the performance ofPARTS from 89% to 96% for this task, and reduces theerrors in other constructions involving phrasal verbs.When is this alternative needed?
In the cases wherePARTS had 10% or more errors, most of the verbs oc-cur lnuch more often as nouns or adjectives.
This con-firms my hypothesis that PARTS will have a problemsolving the N/V ambiguity in cases where the lexicalprobability of the word points to a noun.
These arethe very cases that should be treated as one unit inthe system.
The lexical probability should be assignedto the pair as a whole rather than considering the twoelements eparately.
Table 1 lists the cases where tag-ging improves 10% or more when PARTS is given theadditional choice of assigning a verbal tag to the wholeexpression.
Frequency distributions of these tokens intile Brown Corpus are presented as well, which reflectwhy statistical probabilities err in these cases.
In or-der to tag these expressions correctly, we will have tocapture additional information about the pair which isnot available froln tile PARTS statistical model.290pairs parts all verb choiceaccount-for 0.84 1 1aim-at 0.90 0.30 0.90average-out 0.7 0.9 0.9back-off 0.86 1 1balance-out 0.92 0.84 0.92bargain-for 0.87 0.58 0.87block-in 0.97 0.02 0.97book-in 1 0 1bottle-up 0.36 0.90 0.90bottom-out 0.8 0.85 0.85box-in 1 0.02 1break-away 1 1 1call-back 0.96 0.84 0.96calm-down 0.85 0.95 0.95care-for 0.9 0.48 0.93cash-in 0.95 0.25 0.95change-into 0.85 0.89 0.89check-in 0.96 0.48 0.96clear-out 0.87 1 1close-down 0.77 1 1contract-in 1 0.02 1cool-off 0.86 1 1credit-with 1 0 1cry-out 0.79 1 1date-from 0 1 1deal-with 0.96 0.92 0.96demand-of 1 0.04 1double-up 0.80 0.95 0.95end-up 0.83 1 1fall-in 0.92 0.29 0.92feel-for 0.93 0.33 0.93flesh-out 0.41 1 1flow-from 0.94 0.42 0.94fool-around 0.91 1 1force-upon 0.84 0.61 0.84gun-down 0.60 0.62 0.62hand-over 0.65 1 1head-for 0.63 0.81 0.81heat-up 0.94 1 1hold-down 0.92 1 1lead-on 1 0.07 1let-down 0.57 0.57 0.57live-for 0.91 1 1move-in 0.96 0.60 0.96narrow-down 0.77 1 1part-with 0.79 0.43 0,79phone-in 0.91 0,12 0.91TOTAL AVERAGE 0.89 0,79 0.96Table 2: A Sample of Performance Evaluation4.
CONCLUSION:  L INGUIST ICINTUIT IONSThis paper shows that for some cases of phrasal verbsit is not enough to rely on lexical probability alone: Wemust take into consideration the dependency betweenthe verb and the particle in order to improve the per-formance of the tagger.The relationship between verbsand particles is deeply rooted in Linguistics.
Smith(1943) introduced the term phrasal verb, arguing thatit should be regarded as a type of idiom because the el-ements behave as a unit.
He claimed that phrasal verbsexpress a single concept hat often has a one word coun-terpart in other languages, yet does not always havecompositional meaning.
Some particles are syntacti-cally more adverbial in nature and some more preposi-tional, but it is generally agreed that the phrasal verbconstitutes a kind of integral functional unit.
Perhapslinguistic knowledge can help solve the tagging problemdescribed here and force a redefinition of the bound-aries of phrasal verbs.
For now we can redefine theword boundaries for the problematic ases that PARTSdoesn't handle well.
Future research should concen-trate on the linguistic characteristics of this problem-atic construction to determine if there are other caseswhere the current assumption that one word equals oneunit interferes with successful processing.5.
ACKNOWLEDGEMENTI wish to thank my committee members Virginia Teller,Judith Klavans and John Moyne for their helpful com-ments and support.
I am also indebted to Ken Churchand Don Hindle for their guidance and help all along.6.
REFERENCESK.
W. Church.
A Stochastic Parts Program and NounPhrase Parser for Unrestricted Text.
Proc.
Conf.
onApplied Natural Language Processing, 136-143, 1988.K.
W. Church, & R. Mercer.
Introduction to the Spe-cial Issue on Computational Linguistics Using LargeCorpora.
To appear in Computational Linguistics, 1993.C.
Le raux.
On The Interface of Morphology & Syntax.Evidence from Verb-Particle Combinations in Afi-ican.SPIL 18.
November 1988.
MA Thesis.M.
Marcus, B. Santorini & D. Magerman.
First stepstowards an annotated atabase of American English.Dept.
of Computer and Information Science, Universityof Pennsylvania, 1992.
MS.L.
P. Smith.
Words ~" Idioms: Studies in The EnglishLanguage.
5th ed.
London, 1943.291
