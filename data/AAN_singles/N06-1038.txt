Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 296?303,New York, June 2006. c?2006 Association for Computational LinguisticsIntegrating Probabilistic Extraction Models and Data Miningto Discover Relations and Patterns in TextAron CulottaUniversity of MassachusettsAmherst, MA 01003culotta@cs.umass.eduAndrew McCallumUniversity of MassachusettsAmherst, MA 01003mccallum@cs.umass.eduJonathan BetzGoogle, Inc.New York, NY 10018jtb@google.comAbstractIn order for relation extraction systemsto obtain human-level performance, theymust be able to incorporate relational pat-terns inherent in the data (for example,that one?s sister is likely one?s mother?sdaughter, or that children are likely toattend the same college as their par-ents).
Hand-coding such knowledge canbe time-consuming and inadequate.
Addi-tionally, there may exist many interesting,unknown relational patterns that both im-prove extraction performance and provideinsight into text.
We describe a probabilis-tic extraction model that provides mutualbenefits to both ?top-down?
relational pat-tern discovery and ?bottom-up?
relationextraction.1 IntroductionConsider these four sentences:1.
George W. Bush?s father is George H. W. Bush.2.
George H.W.
Bush?s sister is Nancy Bush Ellis.3.
Nancy Bush Ellis?s son is John Prescott Ellis.4.
John Prescott Ellis analyzed George W. Bush?scampaign.We would like to build an automated system toextract the set of relations shown in Figure 1.cousinNancy Ellis BushsiblingGeorge HW BushGeorge W BushsonJohn Prescott EllissonFigure 1: Bush family treeState of the art extraction algorithms may be ableto detect the son and sibling relations from local lan-guage clues.
However, the cousin relation is onlyimplied by the text and requires additional knowl-edge to be extracted.
Specifically, the system re-quires knowledge of familial relation patterns.One could imagine a system that accepts suchrules as input (e.g.
cousin = father?s sister?s son)and applies them to extract implicit relations.
How-ever, exhaustively enumerating all possible rules canbe tedious and incomplete.
More importantly, manyrelational patterns unknown a priori may both im-prove extraction accuracy and uncover informativetrends in the data (e.g.
that children often adopt thereligion of their parents).
Indeed, the goal of datamining is to learn such patterns from database reg-ularities.
Since these patterns will not always hold,we would like to handle them probabilistically.We propose an integrated supervised machinelearning method that learns both contextual and re-lational patterns to extract relations.
In particular,we construct a linear-chain conditional random field(Lafferty et al, 2001; Sutton and McCallum, 2006)to extract relations from biographical texts while si-multaneously discovering interesting relational pat-terns that improve extraction performance.2962 Related WorkThis work can be viewed as a step toward the in-tegration of information extraction and data miningtechnology, a direction of growing interest.
Nahmand Mooney (2000) present a system that mines as-sociation rules from a database constructed from au-tomatically extracted data, then applies these learnedrules to improve data field recall without revisitingthe text.
Our work attempts to more tightly inte-grate the extraction and mining tasks by learningrelational patterns that can be included probabilis-tically into extraction to improve its accuracy; also,our work focuses on mining from relational graphs,rather than single-table databases.McCallum and Jensen (2003) argue the theoreti-cal benefits of an integrated probabilistic model forextraction and mining, but do not construct such asystem.
Our work is a step in the direction of theirproposal, using an inference procedure based on aclosed-loop iteration between extraction and rela-tional pattern discovery.Most other work in this area mines raw text, ratherthan a database automatically populated via extrac-tion (Hearst, 1999; Craven et al, 1998).This work can also be viewed as part of a trendto perform joint inference across multiple languageprocessing tasks (Miller et al, 2000; Roth and tauYih, 2002; Sutton and McCallum, 2004).Finally, using relational paths between entities isalso examined in (Richards and Mooney, 1992) toescape local maxima in a first-order learning system.3 Relation Extraction as SequenceLabelingRelation extraction is the task of discovering seman-tic connections between entities.
In text, this usu-ally amounts to examining pairs of entities in a doc-ument and determining (from local language cues)whether a relation exists between them.
Commonapproaches to this problem include pattern match-ing (Brin, 1998; Agichtein and Gravano, 2000),kernel methods (Zelenko et al, 2003; Culotta andSorensen, 2004; Bunescu and Mooney, 2006), lo-gistic regression (Kambhatla, 2004), and augmentedparsing (Miller et al, 2000).The pairwise classification approach of kernelmethods and logistic regression is commonly a two-phase method: first the entities in a document areidentified, then a relation type is predicted for eachpair of entities.
This approach presents at leasttwo difficulties: (1) enumerating all pairs of enti-ties, even when restricted to pairs within a sentence,results in a low density of positive relation exam-ples; and (2) errors in the entity recognition phasecan propagate to errors in the relation classificationstage.
As an example of the latter difficulty, if a per-son is mislabeled as a company, then the relationclassifier will be unsuccessful in finding a brotherrelation, despite local evidence.We avoid these difficulties by restricting our in-vestigation to biographical texts, e.g.
encyclopediaarticles.
A biographical text mostly discusses oneentity, which we refer to as the principal entity.
Werefer to other mentioned entities as secondary enti-ties.
For each secondary entity, our goal is to predictwhat relation, if any, it has to the principal entity.This formulation allows us to treat relation ex-traction as a sequence labeling task such as named-entity recognition or part-of-speech tagging, and wecan now apply models that have been successful onthose tasks.
By anchoring one argument of relationsto be the principal entity, we alleviate the difficultyof enumerating all pairs of entities in a document.By converting to a sequence labeling task, we foldthe entity recognition step into the relation extrac-tion task.
There is no initial pass to label each entityas a person or company.
Instead, an entity?s label isits relation to the principal entity.
Below is an exam-ple of a labeled article:George W. BushGeorge is the son of George H. W. Bush?
??
?fatherand Barbara Bush?
??
?mother.Additionally, by using a sequence model we cancapture the dependence between adjacent labels.
Forexample, in our data it is common to see phrasessuch as ?son of the Republican president George H.W.
Bush?
for which the labels politicalParty, jobTi-tle, and father occur consecutively.
Sequence mod-els are specifically designed to handle these kindsof dependencies.
We now discuss the details of ourextraction model.2973.1 Conditional Random FieldsWe build a model to extract relations using linear-chain conditional random fields (CRFs) (Laffertyet al, 2001; Sutton and McCallum, 2006).
CRFsare undirected graphical models (i.e.
Markov net-works) that are discriminatively-trained to maximizethe conditional probability of a set of output vari-ables y given a set of input variables x.
This condi-tional distribution has the formp?
(y|x) =1Zx?c?C?c(yc,xc; ?)
(1)where ?
are potential functions parameterized by ?and Zx =?y?c?C ?
(yc,xc) is a normalizationfactor.
Assuming ?c factorizes as a log-linear com-bination of arbitrary features computed over cliquec, then ?c(yc,xc; ?)
= exp (?k ?kfk(yc,xc)),where f is a set of arbitrary feature functions overthe input, each of which has an associate modelparameter ?k.
Parameters ?
= {?k} are a setof real-valued weights typically estimated from la-beled training data by maximizing the data likeli-hood function using gradient ascent.In these experiments, we make a first-orderMarkov assumption on the dependencies among y,resulting in a linear-chain CRF.4 Relational PatternsThe modeling flexibility of CRFs permits the fea-ture functions to be complex, overlapping features ofthe input without requiring additional assumptionson their inter-dependencies.
In addition to commonlanguage features (e.g.
neighboring words and syn-tactic information), in this work we explore featuresthat cull relational patterns from a database of enti-ties.As described in the introductory example (Figure1), context alone is often insufficient to extract re-lations.
Even in simpler examples, it may be thecase that modeling relational patterns can improveextraction accuracy.To capture this evidence, we compute featuresfrom a database to indicate relational connectionsbetween entities, similar to the relational path-finding performed in Richards and Mooney (1992).Imagine that the four sentence example about theBush family is included in a training set, and the en-cousinfather sonX YsiblingFigure 2: A feature template for the cousin relation.tities are labeled with their correct relations.
In thiscase, the cousin relation in sentence 4 would also belabeled.
From this data, we can create a relationaldatabase that contains the relations in Figure 1.Assume sentence 4 comes from a biography aboutJohn Ellis.
We calculate a feature for the entityGeorge W. Bush that indicates the path from JohnEllis to George W. Bush in the database, annotat-ing each edge in the path with its relation label; i.e.father-sibling-son.
By abstracting away the actualentity names, we have created a cousin template fea-ture, as shown in Figure 2.By adding these relational paths as features tothe model, we can learn interesting relational pat-terns that may have low precision (e.g.
?people arelikely to be friends with their classmates?)
withouthampering extraction performance.
This is in con-trast to the system described in Nahm and Mooney(2000), in which patterns are induced from a noisydatabase and then applied directly to extraction.
Inour system, since each learned path has an associ-ated weight, it is simply another piece of evidenceto help the extractor.
Low precision patterns mayhave lower weights than high precision patterns, butthey will still influence the extractor.A nice property of this approach is that examin-ing highly weighted patterns can provide insight intoregularities of the data.4.1 Feature InductionDuring CRF training, weights are learned for eachrelational pattern.
Patterns that increase extractionperformance will receive higher weights, while pat-terns that have little effect on performance will re-ceive low weights.We can explore the space of possible conjunctionsof these patterns using feature induction for CRFs,as described in McCallum (2003).
Search throughthe large space of possible conjunctions is guided298by adding features that are estimated to increase thelikelihood function most.When feature induction is used with relationalpatterns, we can view this as a type of data mining,in which patterns are created based on their influ-ence on an extraction model.
This is similar to workby Dehaspe (1997), where inductive logic program-ming is embedded as a feature induction techniquefor a maximum entropy classifier.
Our work restrictsinduced features to conjunctions of base features,rather than using first-order clauses.
However, thepatterns we learn are based on information extractedfrom natural language.4.2 Iterative Database ConstructionThe top-down knowledge provided by data min-ing algorithms has the potential to improve the per-formance of information extraction systems.
Con-versely, bottom-up knowledge generated by ex-traction systems can be used to populate a largedatabase, from which more top-down knowledgecan be discovered.
By carefully communicating theuncertainty between these systems, we hope to iter-atively expand a knowledge base, while minimizingfallacious inferences.In this work, the top-down knowledge consists ofrelational patterns describing the database path be-tween entities in text.
The uncertainty of this knowl-edge is handled by associating a real-valued CRFweight with each pattern, which increases when thepattern is predictive of other relations.
Thus, the ex-traction model can adapt to noise in these patterns.Since we also desire to extract relations betweenentities that appear in text but not in the database, wefirst populate the database with relations extractedby a CRF that does not use relational patterns.
Wethen do further extraction with a CRF that incorpo-rates the relational patterns found in this automati-cally generated database.
In this manner, we create aclosed-loop system that alternates between bottom-up extraction and top-down pattern discovery.
Thisapproach can be viewed as a type of alternating opti-mization, with analogies to formal methods such asexpectation-maximization.The uncertainty in the bottom-up extraction stepis handled by estimating the confidence of each ex-traction and pruning the database to remove en-tries with low confidence.
One of the benefits ofa probabilistic extraction model is that confidenceestimates can be straight-forwardly obtained.
Cu-lotta and McCallum (2004) describe the constrainedforward-backward algorithm to efficiently estimatethe conditional probability that a segment of text iscorrectly extracted by a CRF.Using this algorithm, we associate a confidencevalue with each relation extracted by the CRF.
Thisconfidence value is then used to limit the noiseintroduced by incorrect extractions.
This differsfrom Nahm and Mooney (2000) and Mooney andBunescu (2005), in which standard decision tree rulelearners are applied to the unfiltered output of ex-traction.4.3 Extracting Implicit RelationsAn implicit relation is one that does not have directcontextual evidence, for example the cousin relationin our initial example.
Implicit relations generallyrequire some background knowledge to be detected,such as relational patterns (e.g.
rules about familialrelations).
These are the sorts of relations on whichcurrent extraction models perform most poorly.Notably, these are exactly the sorts of relationsthat are likely to have the biggest impact on informa-tion access.
A system that can accurately discoverknowledge that is only implied by the text will dra-matically increase the amount of information a usercan uncover, effectively providing access to the im-plications of a corpus.We argue that integrating top-down and bottom-up knowledge discovery algorithms discussed inSection 4.2 can enable this technology.
By per-forming pattern discovery in conjunction with infor-mation extraction, we can collate facts from multi-ple sources to infer new relations.
This is an ex-ample of cross-document fusion or cross-documentinformation extraction, a growing area of researchtransforming raw extractions into usable knowledgebases (Mann and Yarowsky, 2005; Masterson andKushmerik, 2003).5 Experiments5.1 DataWe sampled 1127 paragraphs from 271 articles fromthe online encyclopediaWikipedia1 and labeled a to-1http://www.wikipedia.org299George W. BushDick CheneyunderlingYaleeducationRepublicanpartyPresidentjobTitleGeorge H. W. BushsonunderlingHarken Energyexecutiveeducation partyjobTitlePrescott BushsoneducationBill ClintonrivalBob DolerivaleducationDemocratpartyjobTitleHillary ClintonhusbandeducationpartyHalliburtonexecutiveeducationPres Medal of FreedomawardpartyNelson RockefellerawardElizabeth DolewifeWWIIparticipantawardpartypartyMartin Luther King, Jr.awardFigure 3: An example of the connectivity of the entities in the data.birthday birth year death daydeath year nationality visitedbirth place death place religionjob title member of cousinfriend discovered educationemployer associate opusparticipant influence awardbrother wife supported ideaexecutive of political party supported personfounder son fatherrival underling superiorrole inventor husbandgrandfather sister brother-in-lawnephew mother daughtergranddaughter grandson great-grandsongrandmother rival organization owner ofuncle descendant ancestorgreat-grandfather auntTable 1: The set of labeled relations.tal of 4701 relation instances.
In addition to a largeset of person-to-person relations, we also includedlinks between people and organizations, as well asbiographical facts such as birthday and jobTitle.
Inall, there are 53 labels in the training data (Table 1).We sample articles that result in a high densityof interesting relations by choosing, for example, acollection of related family members and associates.Figure 3 shows a small example of the type of con-nections in the data.
We then split the data into train-ing and testing sets (70-30 split), attempting to sep-arate the entities into connected components.
Forexample, all Bush family members were placed inthe training set, while all Kennedy family memberswere placed in the testing set.
While there are stilloccasional paths connecting entities in the trainingset to those in the test set, we believe this method-ology reflects a typical real-world scenario in whichwe would like to extend an existing database to adifferent, but slightly related, domain.The structure of the Wikipedia articles somewhatsimplifies the extraction task, since important enti-ties are hyper-linked within the text.
This providesan automated way to detect entities in the text, al-though these entities are not classified by type.
Thisalso allows us to easily construct database queries,since we can reason at the entity level, rather thanthe token level.
(Although, see Sarawagi and Cohen(2004) for extensions of CRFs that model the en-tity length distribution.)
The results we report hereare constrained to predict relations only for hyper-linked entities.
Note that despite this property, westill desire to use a sequence model to capture thedependencies between adjacent labels.We use the MALLET CRF implementation (Mc-Callum, 2002) with the default regularization pa-rameters.Based on initial experiments, we restrict relationalpath features to length two or three.
Paths of lengthone will learn trivial paths and can lead to over-fitting.
Paths longer than three can increase compu-tational costs without adding much new information.In addition to the relational pattern features de-scribed in Section 4, the list of local features in-cludes context words (such as the token identitywithin a 6 word window of the target token), lexi-cons (such as whether a token appears in a list ofcities, people, or companies), regular expressions(such as whether the token is capitalized or containsdigits or punctuation), part-of-speech (predicted bya CRF that was trained separately for part of speechtagging), prefix/suffix (such as whether a word endsin -ed or begins with ch-), and offset conjunctions(combinations of adjacent features within a windowof size six).300ME CRF0 CRFr CRFr0.9 CRFr0.5 CRFt CRFt0.5F1 .5489 .5995 .6100 .6008 .6136 .6791 .6363P .6475 .7019 .6799 .7177 .7095 .7553 .7343R .4763 .5232 .5531 .5166 .5406 .6169 .5614Table 2: Results comparing the relative benefits of using relational patterns in extraction.5.2 Extraction ResultsWe evaluate performance by calculating the preci-sion (P) and recall (R) of extracted relations, as wellas the F1 measure, which is the harmonic mean ofprecision and recall.CRF0 is the conditional random field constructedwithout relational features.
Results for CRF0 aredisplayed in the second column of Table 2.
ME isa maximum entropy classifier trained on the samefeature set as CRF0.
The difference between thesetwo models is that CRF0 models the dependence ofrelations that appear consecutively in the text.
Thesuperior performance of CRF0 suggests that this de-pendence is important to capture.The remaining models incorporate the relationalpatterns described in Section 4.
We compare threedifferent confidence thresholds for the constructionof the initial testing database, as described in Sec-tion 4.2.
CRFr uses no threshold, while CRFr0.9andCRFr0.5 restrict the database to extractions withconfidence greater than 0.9 and 0.5, respectively.As shown by comparing CRF0 and CRFr in Ta-ble 2, the relational features constructed from thedatabase with no confidence threshold provides aconsiderable boost in recall (reducing error by 7%),at the cost of a decrease in precision.
Here we seethe effect of making fallacious inferences on a noisydatabase.In column four, we see the opposite effect forthe overly conservative threshold of CRFr0.9.
Here,precision improves slightly over CRF0, and consid-erably over CRFr (12% error reduction), but this isaccompanied by a drop in recall (8% reduction).Finally, in column five, a confidence of 0.5 resultsin the best F1 measure (a 3.5% error reduction overCRF0).
CRFr0.5 also obtains better recall and preci-sion than CRF0, reducing recall error by 3.6%, pre-cision error by 2.5%.Comparing the performance on different relationtypes, we find that the biggest increase from CRF0to CRFr0.5 is on the memberOf relation, for whichthe F1 score improves from 0.4211 to 0.6093.
Weconjecture that the reason for this is that the patternsmost useful for thememberOf label contain relationsthat are well-detected by the first-pass CRF.
Also,the local language context seems inadequate to prop-erly extract this relation, given the low performanceof CRF0.To better gauge how much relational pattern fea-tures are affected by errors in the database, we runtwo additional experiments for which the relationalfeatures are fixed to be correct.
That is, imagine thatwe construct a database from the true labeling of thetesting data, and create the relational pattern featuresfrom this database.
Note that this does not trivializethe problem, since there are no relational path fea-tures of length one (e.g., if X is the wife of Y, therewill be no feature indicating this).We construct two experiments under this scheme,one where the entire test database is used (CRFt),and another where only half the relations are in-cluded in the test database, selected uniformly atrandom (CRFt0.5).Column six shows the improvements enabled byusing the complete testing database.
More inter-estingly, column seven shows that even with onlyhalf the database accurately known, performanceimproves considerably over both CRF and CRFr0.5.A realistic scenario for CRFt0.5 is a semi-automatedsystem, in which a partially-filled database is used tobootstrap extraction.5.3 Mining ResultsComparing the impact of discovered patterns on ex-traction is a way to objectively measure mining per-formance.
We now give a brief subjective evaluationof the learned patterns.
By examining relational pat-terns with high weights for a particular label, we canglean some regularities from our dataset.
Examplesof such patterns are in Table 3.301Relation Relational Path Featuremother father ?
wifecousin mother ?
husband ?
nephewfriend education ?
studenteducation father ?
educationboss boss ?
sonmemberOf grandfather ?
memberOfrival politicalParty ?
member ?
rivalTable 3: Examples of highly weighted relational pat-terns.From the familial relations in our training data, weare able to discover many equivalences for mothers,cousins, grandfathers, and husbands.
In addition tothese high precision patterns, the system also gener-ates interesting, low precision patterns.
Row 3-7 ofTable 3 can be summarized by the following gener-alizations: friends tend to be classmates; children ofalumni often attend the same school as their parents;a boss?
child often becomes the boss; grandchildrenare often members of the same organizations as theirgrandparents; and rivals of a person from one polit-ical party are often rivals of other members of thesame political party.
While many of these patternsreflect the high concentration of political entities andfamilial relations in our training database, many willhave applicability across domains.5.4 Implicit RelationsIt is difficult to measure system performance on im-plicit relations, since our labeled data does not dis-tinguish between explicit and implicit relations.
Ad-ditionally, accurately labeling all implicit relationsis challenging even for a human annotator.We perform a simple exploratory analysis to de-termine how relational patterns can help discoverimplicit relations.
We construct a small set of syn-thetic sentences for which CRF0 successfully ex-tracts relations using contextual features.
We thenadd sentences with slightly more ambiguous lan-guage and measure whether CRFr can overcome thisambiguity using relational pattern features.For example, we create an article about an en-tity named ?Bob Smith?
that includes the sentences?His brother, Bill Smith, was a biologist?
and ?Hiscompanion, Bill Smith, was a biologist.?
CRF0 suc-cessfully returns the brother relation in the first sen-tence, but not the second.
After a fact is added tothe database that says Bob and Bill have a brother incommon named John, CRFr is able to correctly labelthe second sentence in spite of the ambiguous word?companion,?
because CRF0 has a highly-weightedrelational pattern feature for brother.Similar behavior is observed for low precisionpatterns like ?associates tend to win the sameawards.?
A synthetic article for the entity ?TomJones?
contains the sentences ?He was awarded thePulitzer Prize in 1998?
and ?Tom got the PulitzerPrize in 1998.?
Because CRF0 is highly-reliant onthe presence of the verb ?awarded?
or ?won?
to indi-cate a prize fact, it fails to label the second sentencecorrectly.
After the database is augmented to includethe fact that Tom?s associate Jill received the PulitzerPrize, CRFr labels the second sentence correctly.However, we also observed that CRFr still re-quires some contextual clues to extract implicit re-lations.
For example, if the Tom Jones article in-stead contains the sentence ?The Pulitzer Prize wasawarded to him in 1998,?
neither CRF labels theprize fact correctly, since this passive constructionis rarely seen in the training data.We conclude from this brief analysis that rela-tional patterns used by CRFr can help extract im-plicit relations when (1) the database contains ac-curate relational information, and (2) the sentencecontains limited contextual clues.
Since relationalpatterns are treated only as additional features byCRFr, they are generally not powerful enough toovercome a complete absence of contextual clues.From this perspective, relational patterns can be seenas enhancing the signal from contextual clues.
Thisdiffers from deterministically applying learned rulesindependent of context, which may boost recall atthe cost of precision.6 Conclusions and Future WorkWe have shown that integrating pattern discoverywith relation extraction can lead to improved per-formance on each task.In the future, we wish to explore extending thismethods to larger datasets, where we expect rela-tional patterns to be even more interesting.
Also,we plan to improve upon iterative database construc-tion by performing joint inference among distant302relations in an article.
Inference in these highly-connected models will likely require approximatemethods.
Additionally, we wish to focus on extract-ing implicit relations, dealing more formally withthe precision-recall trade-off inherent in applyingnoisy rules to improve extraction.7 AcknowledgmentsThanks to the Google internship program, and to Charles Suttonfor providing the CRF POS tagger.
This work was supported inpart by the Center for Intelligent Information Retrieval, in partby U.S. Government contract #NBCH040171 through a sub-contract with BBNT Solutions LLC, in part by The Central In-telligence Agency, the National Security Agency and NationalScience Foundation under NSF grant #IIS-0326249, and in partby the Defense Advanced Research Projects Agency (DARPA),through the Department of the Interior, NBC, Acquisition Ser-vices Division, under contract number NBCHD030010.
Anyopinions, findings and conclusions or recommendations ex-pressed in this material are the author(s) and do not necessarilyreflect those of the sponsor.ReferencesEugene Agichtein and Luis Gravano.
2000.
Snowball: Extract-ing relations from large plain-text collections.
In Proceed-ings of the Fifth ACM International Conference on DigitalLibraries.Sergey Brin.
1998.
Extracting patterns and relations from theworld wide web.
In WebDB Workshop at 6th InternationalConference on Extending Database Technology.Razvan Bunescu and Raymond Mooney.
2006.
Subsequencekernels for relation extraction.
In Y. Weiss, B. Scho?lkopf,and J. Platt, editors, Advances in Neural Information Pro-cessing Systems 18.
MIT Press, Cambridge, MA.Mark Craven, Dan DiPasquo, Dayne Freitag, Andrew K. Mc-Callum, Tom M. Mitchell, Kamal Nigam, and Sea?n Slattery.1998.
Learning to extract symbolic knowledge from theWorld Wide Web.
In Proceedings of AAAI-98, 15th Confer-ence of the American Association for Artificial Intelligence,pages 509?516, Madison, US.
AAAI Press, Menlo Park, US.Aron Culotta and Andrew McCallum.
2004.
Confidence es-timation for information extraction.
In Human LangaugeTechnology Conference (HLT 2004), Boston, MA.Aron Culotta and Jeffrey Sorensen.
2004.
Dependency treekernels for relation extraction.
In ACL.L.
Dehaspe.
1997.
Maximum entropy modeling with clausalconstraints.
In Proceedings of the Seventh InternationalWorkshop on Inductive Logic Programming, pages 109?125,Prague, Czech Republic.M.
Hearst.
1999.
Untangling text data mining.
In 37th AnnualMeeting of the Association for Computational Linguistics.Nanda Kambhatla.
2004.
Combining lexical, syntactic, and se-mantic features with maximum entropy models for extract-ing relations.
In ACL.John Lafferty, Andrew McCallum, and Fernando Pereira.
2001.Conditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proc.
18th Interna-tional Conf.
on Machine Learning, pages 282?289.
MorganKaufmann, San Francisco, CA.Gideon Mann and David Yarowsky.
2005.
Multi-field informa-tion extraction and cross-document fusion.
In ACL.D.
Masterson and N. Kushmerik.
2003.
Information extractionfrom multi-document threads.
In ECML-2003: Workshop onAdaptive Text Extraction and Mining, pages 34?41.Andrew McCallum and David Jensen.
2003.
A note on theunification of information extraction and data mining us-ing conditional-probability, relational models.
In IJCAI03Workshop on Learning Statistical Models from RelationalData.Andrew McCallum.
2002.
Mallet: A machine learning forlanguage toolkit.
http://mallet.cs.umass.edu.Andrew McCallum.
2003.
Efficiently inducing features of con-ditional random fields.
In Nineteenth Conference on Uncer-tainty in Artificial Intelligence (UAI03).Scott Miller, Heidi Fox, Lance A. Ramshaw, and RalphWeischedel.
2000.
A novel use of statistical parsing to ex-tract information from text.
In ANLP.Raymond J. Mooney and Razvan Bunescu.
2005.
Miningknowledge from text using information extraction.
SigKDDExplorations on Text Mining and Natural Language Process-ing.Un Yong Nahm and Raymond J. Mooney.
2000.
A mutuallybeneficial integration of data mining and information extrac-tion.
In AAAI/IAAI.Bradley L. Richards and Raymond J. Mooney.
1992.
Learningrelations by pathfinding.
In Proceedings of the Tenth Na-tional Conference on Artificial Intelligence (AAAI-92), pages50?55, San Jose, CA.Dan Roth and Wen tau Yih.
2002.
Probabilistic reasoning forentity and relation recognition.
In COLING.Sunita Sarawagi and William W. Cohen.
2004.
Semi-markovconditional random fields for information extraction.
InNIPS 04.Charles Sutton and Andrew McCallum.
2004.
Dynamic condi-tional random fields: Factorized probabilistic models for la-beling and segmenting sequence data.
In Proceedings of theTwenty-First International Conference on Machine Learning(ICML).Charles Sutton and Andrew McCallum.
2006.
An introductionto conditional random fields for relational learning.
In LiseGetoor and Ben Taskar, editors, Introduction to StatisticalRelational Learning.
MIT Press.
To appear.Dmitry Zelenko, Chinatsu Aone, and Anthony Richardella.2003.
Kernel methods for relation extraction.
Journal ofMachine Learning Research, 3:1083?1106.303
