Weakly Supervised Learning for Cross-document Person NameDisambiguation Supported by Information ExtractionCheng Niu, Wei Li, and Rohini K. SrihariCymfony Inc.600 Essjay Road, Williamsville, NY 14221, USA.
{cniu, wei, rohini}@cymfony.comAbstractIt is fairly common that different people areassociated with the same name.
In trackingperson entities in a large document pool, it isimportant to determine whether multiplementions of the same name across documentsrefer to the same entity or not.
Previousapproach to this problem involves measuringcontext similarity only based on co-occurringwords.
This paper presents a new algorithmusing information extraction support inaddition to co-occurring words.
A learningscheme with minimal supervision is developedwithin the Bayesian framework.
Maximumentropy modeling is then used to represent theprobability distribution of context similaritiesbased on heterogeneous features.
Statisticalannealing is applied to derive the final entitycoreference chains by globally fitting thepairwise context similarities.
Benchmarkingshows that our new approach significantlyoutperforms the existing algorithm by 25percentage points in overall F-measure.1 IntroductionCross document name disambiguation isrequired for various tasks of knowledge discoveryfrom textual documents, such as entity tracking,link discovery, information fusion and eventtracking.
This task is part of the co-reference task:if two mentions of the same name refer to same(different) entities, by definition, they should(should not) be co-referenced.
As far as names areconcerned, co-reference consists of two sub-tasks:(i) name disambiguation to handle the problem ofdifferent entities happening to use the same name;(ii) alias association to handle the problem of thesame entity using multiple names (aliases).Message Understanding Conference (MUC)community has established within-document co-reference standards [MUC-7 1998].
Comparedwith within-document name disambiguation whichcan leverage highly reliable discourse heuristicssuch as one sense per discourse [Gale et al1992],cross-document name disambiguation is a muchharder problem.Among major categories of named entities (NEs,which in this paper refer to entity names, excludingthe MUC time and numerical NEs), company andproduct names are often trademarked or uniquelyregistered, and hence less subject to nameambiguity.
This paper focuses on cross-documentdisambiguation of person names.Previous research for cross-document namedisambiguation applies vector space model (VSM)for context similarity, only using co-occurringwords [Bagga & Baldwin 1998].
A pre-definedthreshold decides whether two context vectors aredifferent enough to represent two different entities.This approach faces two challenges: i) it is difficultto incorporate natural language processing (NLP)results in the VSM framework; 1 ii) the algorithmfocuses on the local pairwise context similarity,and neglects the global correlation in the data: thismay cause inconsistent results, and hurts theperformance.This paper presents a new algorithm thataddresses these problems.
A learning scheme withminimal supervision is developed within theBayesian framework.
Maximum entropy modelingis then used to represent the probabilitydistribution of context similarities based onheterogeneous features covering both co-occurringwords and natural language information extraction(IE) results.
Statistical annealing is used to derivethe final entity co-reference chains by globallyfitting the pairwise context similarities.Both the previous algorithm and our newalgorithm are implemented, benchmarked and1 Based on our experiment, only using co-occurringwords often cannot fulfill the name disambiguation task.For example, the above algorithm identifies thementions of Bill Clinton as referring to two differentpersons, one represents his role as U. S. president, andthe other is strongly associated with the scandal,although in both mention clusters, Bill Clinton has beenmentioned as U.S. president.
Proper namedisambiguation calls for NLP/IE support which mayhave extracted the key person?s identificationinformation from the textual documents.compared.
Significant performance enhancementup to 25 percentage points in overall F-measure isobserved with the new approach.
The generality ofthis algorithm ensures that this approach is alsoapplicable to other categories of NEs.The remaining part of the paper is structured asfollows.
Section 2 presents the algorithm designand task definition.
The name disambiguationalgorithm is described in Sections 3, 4 and 5,corresponding to the three key aspects of thealgorithm, i.e.
minimally supervised learningscheme, maximum entropy modeling andannealing-based optimization.
Benchmarks areshown in Section 6, followed by Conclusion inSection 7.2 Task Definition and Algorithm DesignGiven n  name mentions, we first introduce thefollowing symbols.
iC  refers to the context of thei -th mention.
iP  refers to the entity for the i -thmention.
iName  refers to the name string of the i-th mention.
jiCS ,  refers to the context similaritybetween the i -th mention and the j -th mention,which is a subset of the predefined contextsimilarity features.
?f  refers to the?
-thpredefined context similarity feature.
So jiCS ,takes the form of { }?f .The name disambiguation task is defined as hardclustering of the multiple mentions of the samename.
Its final solution is represented as { }MK ,where K refers to the number of distinct entities,and M represents the many-to-one mapping (frommentions to a cluster) such that( ) K].
[1,j n],[1,i j,iM ?
?=One way of combining natural language IEresults with traditional co-occurring words is todesign a new context representation scheme andthen define the context similarity measure based onthe new scheme.
The challenge to this approachlies in the lack of a proper weighting scheme forthese high-dimensional heterogeneous features.
Inour research, the algorithm directly models thepairwise context similarity.For any given context pair, a set of predefinedcontext similarity features are defined.
Then with nmentions of a same name, 2)1( ?nn  contextsimilarities [ ] [ )( )ijniCS ji ,1,,1 , ??
arecomputed.
The name disambiguation task isformulated as searching for { }MK ,  whichmaximizes the following conditional probability:{ }( ) [ ] [ )( )ijniCSMK ji ,1,,1       }{,Pr , ?
?Based on Bayesian Equity, this is equivalent tomaximizing the following joint probability{ }( ) [ ] [ )( ){ }( ) { }( ){ }( ) { }( )MKMKCSMKMKCSijniCSMKijNijijiji,Pr,Pr,Pr,}{Pr,1,,1       }{,,Pr1,1,1,,,??==?=??(1)Eq.
(1) contains a prior probability distributionof name disambiguation { }( )MK ,Pr .
Becausethere is no prior knowledge available about whatsolution is preferred, it is reasonable to take anequal distribution as the prior probabilitydistribution.
So the name disambiguation isequivalent to searching for { }MK ,  whichmaximizes Expression (2).
{ }( )?
?==1,1,1, ,PrijNiji MKCS      (2)where{ }( ) ( ) ( ) ( )( )?=== otherwise ,PrjMiM if ,Pr,Pr,,,jijijijiji PPCSPPCSMKCS(3)To learn the conditional probabilities ( )jiji PPCS =|Pr ,  and ( )jiji PPCS ?|Pr ,  in Eq.
(3), we use a machine learning scheme which onlyrequires minimal supervision.
Within this scheme,maximum entropy modeling is used to combineheterogeneous context features.
With the learnedconditional probabilities in Eq.
(3), for a given{ }MK ,  candidate, we can compute the conditionalprobability of Expression (2).
In the final step,optimization is performed to search for { }MK ,that maximizes the value of Expression (2).To summarize, there are three key elements inthis learning scheme: (i) the use of automaticallyconstructed corpora to estimate conditionalprobabilities of Eq.
(3); (ii) maximum entropymodeling for combining heterogeneous contextsimilarity features; and (iii) statistical annealing foroptimization.3 Learning Using Automatically ConstructedCorporaThis section presents our machine learningscheme to estimate the conditional probabilities ( )jiji PPCS =|Pr ,  and ( )jiji PPCS ?|Pr ,  in Eq.(3).
Considering jiCS ,  is in the form of { }?f , were-formulate the two conditional probabilities as{ }( )ji PPf =|Pr ?
and { }( )ji PPf ?|Pr ?
.The learning scheme makes use of automaticallyconstructed large corpora.
The rationale isillustrated in the figure below.
The symbol +represents a positive instance, namely, a mentionpair that refers to the same entity.
The symbol ?represents a negative instance, i.e.
a mention pairthat refers to different entities.Corpus I  Corpus II+++++---++++++         ----------------------+-----+++--+++++           --+------------------++++++++++--++           --------------+------+++++++---++++         -----------------------+++----++++++++         --------+-------------As shown in the figure, two training corpora areautomatically constructed.
Corpus I containsmention pairs of the same names; these are themost frequently mentioned names in the documentpool.
It is observed that frequently mentionedperson names in the news domain are fairlyunambiguous, hence enabling the corpus to containmainly positive instances.2 Corpus II containsmention pairs of different person names, thesepairs overwhelmingly correspond to negativeinstances (with statistically negligible exceptions).Thus, typical patterns of negative instances can belearned from Corpus II.
We use these patterns tofilter away the negative instances in Corpus I. Thepurified Corpus I can then be used to learn patternsfor positive instances.
The algorithm is formulatedas follows.Following the observation that different namesusually refer to different entities, it is safe to deriveEq.
(4).
( ) ( )2121 }{Pr}{Pr namenamefPPf ?=?
??
(4)For ( )21}{Pr PPf =?
, we can derive thefollowing relation (Eq.
5):2 Based on our data analysis, there is no observabledifference in linguistic expressions involving frequentlymentioned vs. occasionally occurring person names.Therefore, the use of frequently mentioned names in thecorpus construction process does not affect theeffectiveness of the learned model to be applicable to allthe person names in general.
( )( )[( )]( )[( )( )]21212121212121Pr1*}{PrPr*}{Pr}{PrnamenamePPPPfnamenamePPPPfnamenamef==??+=====???
(5)So ( )21}{Pr PPf =?
can be determined if( ))()(}{Pr 21 PnamePnamef =?
,( ))()(}{Pr 21 PnamePnamef ??
, and( ))()(Pr 2121 PnamePnamePP ==  are all known.By using Corpus I and Corpus II to estimate theabove three probabilities, we achieve Eq.
(6.1) andEq.
(6.2)( )21}{Pr PPf =?
( ) ( ) ( )XXff ?
?=1*}{Pr}{Pr maxEntIImaxEntI ??
.
(6.1)( ) })({Pr}{Pr maxEntII21 ??
fPPf =?
(6.2)where ( )}{Pr maxEntI ?f  denotes the maximumentropy model of ( ))()(}{Pr 21 PnamePnamef =?using Corpus I,  ( )}{Pr maxEntII ?f  denotes themaximum entropy model of( ))()(}{Pr 21 PnamePnamef ??
using Corpus II,and X  stands for the Maximum LikelihoodEstimation (MLE) of( ))()(Pr 2121 PnamePnamePP ==  using Corpus I.Maximum entropy modeling is used here due to itsstrength of combining heterogeneous features.It is worth noting that ( )}{Pr maxEntI ?f  and( )}{Pr maxEntII ?f  can be automatically computedusing Corpus I and Corpus II.
Only X requiresmanual truthing.
Because X is contextindependent, the required truthing is very limited(in our experiment, only 100 truthed mention pairswere used).
The details of corpus construction andtruthing will be presented in the next section.4 Maximum Entropy ModelingThis section presents the definition of contextsimilarity features }{ ?f , and how to estimate themaximum entropy model of  ( )}{Pr maxEntI ?f  and( )}{Pr maxEntII ?f .First, we describe how Corpus I and Corpus IIare constructed.
Before the person namedisambiguation learning starts, a large pool oftextual documents are processed by an IE engineInfoXtract [Srihari et al2003].
The InfoXtractengine contains a named entity tagger, an aliasingmodule, a parser and an entity relationshipextractor.
In our experiments, we used ~350,000AP and WSJ news articles (a total of ~170 millionwords) from the TIPSTER collection.
All thedocuments and the IE results are stored into an IERepository.
The top 5,000 most frequentlymentioned multi-token person names are retrievedfrom the repository.
For each name, all thecontexts are retrieved while the context is definedas containing three categories of features:(i)     The surface string sequence centering arounda key person name (or its aliases as identifiedby the aliasing module) within a predefinedwindow size equal to 50tokens to both sides of the key name.
(ii)  The automatically tagged entity names cooccurring with the key name (or its aliases)within the same predefined window as in (i).
(iii) The automatically extracted relationshipsassociated with the key name (or its aliases).The relationships being utilized are listedbelow:Age, Where-from, Affiliation, Position,Leader-of, Owner-of, Has-Boss, Boss-of,Spouse-of, Has-Parent, Parent-of, Has-Teacher, Teacher-of, Sibling-of, Friend-of,Colleague-of, Associated-Entity, Title,Address, Birth-Place, Birth-Time, Death-Time, Education, Degree, Descriptor,Modifier, Phone, Email, Fax.A recent manual benchmarking of the InfoXtractrelationship extraction in the news domain is 86%precision and 67% recall (75% F-measure).To construct Corpus I, a person name israndomly selected from the list of the top 5,000frequently mentioned multi-token names.
For eachselected name, a pair of contexts are extracted, andinserted into Corpus I.
This process repeats until10,000 pairs of contexts are selected.It is observed that, in the news domain, the topfrequently occurring multi-token names are highlyunambiguous.
For example, Bill Clintonexclusively stands for the previous U.S. presidentalthough in real life, although many other peoplemay also share this name.
Based on manuallychecking 100 sample pairs in Corpus I, we have( ) 95.0Pr 21 ?== PPX I , which means for the 100sample pairs mentioning the same person name,only 5 pairs are found to refer to different personentities.
Note that the value of X?1  represents theestimation of the noise in Corpus I, which is usedin Eq (6.1) to correct the bias caused by the noisein the corpus.To construct Corpus II, two person names arerandomly selected from the same name list.
Then acontext for each of the two names is extracted, andthis context pair is inserted into Corpus II.
Thisprocess repeats until 10,000 pairs of contexts areselected.Based on the above three categories of contextfeatures, four context similarity features aredefined:(1)  VSM-based context similarity using co-occurring wordsThe surface string sequence centering around thekey name is represented as a vector, and the word iin context j is weighted as follows.
)(log*),(),( idfDjitfjiweight =   (7)where ),( jitf is the frequency of word i in thej-th surface string sequence; D is the number ofdocuments in the pool; and )(idf  is the number ofdocuments containing the word i.
Then, the cosineof the angle between the two resulting vectors isused as the context similarity measure.
(2) Co-occurring NE SimilarityThe latent semantic analysis (LSA) [Deerwesteret al1990] is used to compute the co-occurring NEsimilarities.
LSA is a technique to uncover theunderlining semantics based on co-occurrencedata.
The first step of LSA is to construct word-vs.-document co-occurrence table.
We use 100,000documents from the TIPSTER corpus, and selectthe following types of top n most frequentlymentioned words as base words:top 20,000 common nounstop 10,000 verbstop 10,000 adjectivestop 2,000 adverbstop 10,000 person namestop 15,000 organization namestop 6,000 location namestop 5,000 product namesThen, a word-vs.-document co-occurrence tableMatrix  is built so that)(log*),( idfDjitfMatrixij = .
The second step ofLSA is to perform singular value decomposition(SVD) on the co-occurrence matrix.
SVD yieldsthe following Matrix  decomposition:TDSTMatrix 000=    (8)where T  and D are orthogonal matrices (the rowvector is called singular vectors), and S  is adiagonal matrix with the diagonal elements (calledsingular values) sorted decreasingly.The key idea of LSA is to reduce noise orinsignificant association patterns by filtering theinsignificant components uncovered by SVD.
Thisis done by keeping only top k singular values.
Inour experiment, k is set to 200, following thepractice reported in [Deerwester et al 1990] and[Landauer & Dumais, 1997].
This procedure yieldsthe following approximation to the co-occurrencematrix:TTSDMatrix ?
(9)where S  is attained from 0S by deleting non-top kelements,  and T ( D ) is obtained from 0T ( 0D ) bydeleting the corresponding columns.It is believed that the approximate matrix is moreproper to induce underlining semantics than theoriginal one.
In the framework of LSA, the co-occurring NE similarities are computed as follows:suppose the first context in the pair contains NEs{ }it0 , and the second context in the pair containsNEs { }it1 .
Then the similarity is computed as =iiiititititiTwTwTwTwS10101010 where iw0 and iw1 areterm weights defined in Eq (7).
(3) Relationship SimilarityWe define four different similarity values basedon entity relationship sharing: (i) sharing nocommon relationships, (ii) relationship conflictsonly, (iii) relationship with consistence andconflicts, and (iv) relationship with consistenceonly.
The  consistency checking between extractedrelationships is supported by the InfoXtractnumber normalization and time normalization aswell as entity aliasing procudures.
(4) Detailed Relationship SimilarityFor each  relationship type, four differentsimilarity values are defined based on sharing ofthat specific relationship i: (i) no sharing ofrelationship i, (ii) conflicts for relationship i, (iii)consistence and conflicts for relationship i, and(iv) consistence for relationship i.To facilitate the maximum entropy modeling inthe later stage, the values of the first and secondcategories of similarity measures are discretizedinto integers.
The number of integers being usedmay impact the final performance of the system.
Ifthe number is too small, significant informationmay be lost during the discretization process.
Onthe other hand, if the number is too large, thetraining data may become too sparse.
We trained aconditional maximum entropy model todisambiguate context pairs between Corpus I andCorpus II.
The performance of this model is usedto select the optimal number of integers.
There isno significant  performance change when theinteger number is within the range of [5,30], with12 as the optimal number.Now the context similarity for a context pair is avector of similarity features, e.g.
{VSM_Similairty_equal_to_2,NE_Similarity_equal_to_1,Relationship_Conflicts_only,No_Sharing_for_Age,Conflict_for_Affiliation}.Besides the four categories of basic contextsimilarity features defined above, we defineinduced context similarity features by combiningbasic context similarity features using the logicalAND operator.
With induced features, the contextsimilarity vector in the previous example isrepresented as{VSM_Similairty_equal_to_2,NE_Similarity_equal_to_1,Relationship_Conflicts_only,No_Sharing_for_Age,Conflict_for_Affiliation,[VSM_Similairty_equal_to_2 andNE_Similarity_equal_to_1],[VSM_Similairty=2 andRelationship_Conflicts_only],??
[VSM_Similairty_equal_to_2 andNE_Similarity_equal_to_1 andRelationship_Conflicts_only andNo_Sharing_for_Age andConflict_for_Affiliation]}.The induced features provide direct and fine-grained information, but suffer from less samplingspace.
Combining basic features and inducedfeatures under a smoothing scheme, maximumentropy modeling may achieve optimalperformance.Now the maximum entropy modeling can beformulated as follows: given a pairwise contextsimilarity vector }{ ?f  the probability of }{ ?f isgiven as( ){ }??=?
?fffwZf1}{Pr maxEnt   (10)where Z is the normalization factor, fw  is theweight associated with feature f .
The IterativeScaling algorithm combined with Monte Carlosimulation [Pietra, Pietra & Lafferty 1995] is usedto train the weights in this generative model.Unlike the commonly used conditional maximumentropy modeling which approximates the featureconfiguration space as the training corpus[Ratnaparkhi 1998], Monte Carlo techniques arerequired in the generative modeling to simulate thepossible feature configurations.
The exponentialprior smoothing scheme [Goodman 2003] isadopted.
The same training procedure is performedusing Corpus I and Corpus II to estimate( )}{Pr maxEntI if  and ( )}{Pr maxEntII if  respectively.5 Annealing-based OptimizationWith the maximum entropy modeling presentedin the last section, for a given namedisambiguation candidate solution{ }MK , , we cancompute the conditional probability of Expression(2).
Statistical annealing [Neal 1993]-basedoptimization is used to search for { }MK ,  whichmaximizes Expression (2).The optimization process consists of two steps.First, a local optimal solution{ }0, MK is computedby a greedy algorithm.
Then by setting { }0, MK asthe initial state, statistical annealing is applied tosearch for the global optimal solution.Given n  same name mentions, assuming theinput of 2)1( ?nn  probabilities ( )jiji PPCS =,Prand 2)1( ?nn  probabilities ( )jiji PPCS ?,Pr , thegreedy algorithm performs as follows:1.
Set the initial state { }MK , as nK = ,and [ ]n1,i  ,)( ?= iiM ;2.
Sort ( )jiji PPCS =,Pr  in decreasingorder;3.
Scan the sorted probabilities one by one.If the current probability is  ( )jiji PPCS =,Pr , )(  )( jMiM ?
, andthere exist no such l  and m that( ) ( ) ( ) ( )jMmMiMlM == ,and ( ) ( )mlmljiji PPCSPPCS ?<= ,, PrPrthen update { }MK ,  by merging cluster)(iM and )( jM .4.
Output { }MK ,  as a local optimal solution.Using the output { }0, MK of the greedyalgorithm as the initial state, the statisticalannealing is described using the following pseudo-code:Set { } { }0,, MKMK = ;for( 1.01?*;??
;??
final0 =<= ){iterate pre-defined number of times{set { } { }MKMK ,, 1 = ;update { }1, MK  by randomly changingthe  number of clusters K and thecontent of   each cluster.set{ }( ){ }( )??
?==?===1,1,1,1,1,11,,Pr,PrijNijiijNijiMKCSMKCSxif(x>=1){set { } { }1,, MKMK =}else{set { } { }1,, MKMK =  with probability?x .
}if{ }( ){ }( ) 1,Pr,Pr1,1,10,1,1,1,>??
?==?==ijNijiijNijiMKCSMKCSset { } { }MKMK ,, 0 =}}output { }0, MK  as the optimal state.6 BenchmarkingTo evaluate the effectiveness of our newalgorithm, we implemented the previous algorithmdescribed in [Bagga & Baldwin 1998] as ourbaseline.
The threshold is selected as 0.19 byoptimizing the pairwise disambiguation accuracyusing the 80 truthed mention pairs of ?JohnSmith?.
To clearly benchmark the performanceenhancement from IE support, we alsoimplemented a system using the same weaklysupervised learning scheme but only VSM-basedsimilarity as the pairwise context similaritymeasure.
We benchmarked the three systems forcomparison.
The following three scoring measuresare implemented.
(1) Precision (P):=iNP i  ofcluster  output   in the  mentions of #i  ofcluster  output   in the  mentionscorrect   of #1(2) Recall (R):=iNP i  ofcluster  key    in  the  mentions of #i   ofcluster  output    in  the  mentionscorrect   of #1(3) F-measure (F):RPRPF+=*2The name co-reference precision and recall usedhere is adopted from the B_CUBED scoringscheme used in [Bagga & Baldwin 1998], which isbelieved to be an appropriate benchmarkingstandard for this task.Traditional benchmarking requires manuallydividing person name mentions into clusters,which is labor intensive and difficult to scale up.
Inour experiments, an automatic corpus constructionscheme is used in order to perform large-scaletesting for reliable benchmarks.The intuition is that in the general news domain,some multi-token names associated with massmedia celebrities is highly unambiguous.
Forexample, ?Bill Gates?, ?Bill Clinton?, etc.mentioned in the news almost always refer tounique entities.
Therefore, we can retrieve contextsof these unambiguous names, and mix themtogether.
The name disambiguation algorithmshould recognize mentions of the same name.
Thecapability of recognizing mentions of anunambiguous name is equivalent to the capabilityof disambiguating ambiguous names.For the purpose of benchmarking, weautomatically construct eight testing datasets(Testing Corpus I), listed in Table 1.Table 1.
Constructed Testing Corpus I# of Mentions NameSet 1a Set 1bMikhail S. Gorbachev 20 50Dick Cheney 20 10Dalai Lama 20 10Bill Clinton 20 10Set 2a Set 2bBob Dole 20 50Hun Sen 20 10Javier Perez de Cuellar 20 10Kim Young Sam 20 10Set 3a Set 3bJiang Qing 20 10Ingrid Bergman 20 10Margaret Thatcher 20 50Aung San Suu Kyi 20 10Set 4a Set 4bBill Gates 20 10Jiang Zemin 20 10Boris Yeltsin 20 50Kim Il Sung 20 10Table 2.
Testing Corpus I BenchmarkingP R F P R FSet 1a Set 1bBaseline 0.79 0.37 0.58 0.78 0.34 0.56VSMOnly 0.86 0.33 0.60 0.78 0.23 0.51Full 0.98 0.75 0.86 0.90 0.79 0.85Set 2a Set 2bBaseline 0.82 0.58 0.70 0.94 0.50 0.72VSMOnly 0.90 0.54 0.72 0.98 0.45 0.71Full 0.93 0.84 0.88 1.00 0.93 0.96Set 3a Set 3bBaseline 0.84 0.69 0.77 0.80 0.34 0.57VSMOnly 0.95 0.72 0.83 0.93 0.29 0.61Full 0.95 0.86 0.90 0.98 0.57 0.77Set 4a Set 4bBaseline 0.88 0.74 0.81 0.80 0.49 0.64VSMOnly 0.93 0.77 0.85 0.88 0.42 0.65Full 0.95 0.93 0.94 0.98 0.84 0.91Overall P R FBaseline 0.83 0.51 0.63VSMOnly 0.90 0.47 0.69Full 0.96 0.82 0.88Table 2 shows the benchmarks for each dataset,using the three measures just defined.
The newalgorithm when only using VSM-based similarity(VSMOnly) outperforms the existing algorithm(Baseline) by 5%.
The new algorithm using the fullcontext similarity measures including IE features(Full) significantly outperforms the existingalgorithm (Baseline) in every test:  the overall F-measure jumps from 64% to 88%, with 25percentage point enhancement.
This performancebreakthrough is mainly due to the additionalsupport from IE, in addition to the optimizationmethod used in our algorithm.We have also manually truthed an additionaltesting corpus of two datasets containing mentionsassociated with the same name (Testing Corpus II).Truthed Dataset 5a contains 25 mentions of PeterSutherland and Truthed Dataset 5b contains 68mentions of John Smith.
John Smith is a highlyambiguous name.
With its 68 mentions, theyrepresent totally 29 different entities.
On the otherhand, all the mentions of Peter Sutherland arefound to refer to the same person.
The benchmarkusing this corpus is shown below.Table 3.
Testing Corpus II BenchmarkingP R F P R FSet 5a Set 5bBaseline 0.96 0.92 0.94 0.62 0.57 0.60VSMOnly 0.96 0.92 0.94 0.75 0.51 0.63Full 1.00 0.92 0.96 0.90 0.81 0.85Based on these benchmarks, using eithermanually truthed corpora or automaticallyconstructed corpora, using either ambiguouscorpora or unambiguous corpora, our algorithmconsistently and significantly outperforms theexisting algorithm.
In particular, our systemachieves a very high precision (0.96 precision).This shows the effective use of IE results whichprovide much more fine-grained evidence than co-occurring words.
It is interesting to note that therecall enhancement is greater than the precisionenhancement (0.31 recall enhancement vs. 0.13precision enhancement).
This demonstrates thecomplementary nature between evidence from theco-occurring words and the evidence carried by IEresults.
The system recall can be further improvedonce the recall of the currently precision-orientedIE engine is enhanced over time.7 ConclusionWe have presented a new person namedisambiguation algorithm which demonstrates asuccessful use of natural language IE support inperformance enhancement.
Our algorithm isbenchmarked to outperform the previous algorithmby 25 percentage points in overall F-measure,where the effective use of IE contributes to 20percentage points.
The core of this algorithm is alearning system trained on automaticallyconstructed large corpora, only requiring minimalsupervision in estimating a context-independentprobability.8 AcknowledgementsThis work was partly supported by a grant fromthe Air Force Research Laboratory?s InformationDirectorate (AFRL/IF), Rome, NY, under contractF30602-03-C-0170.
The authors wish to thankCarrie Pine of AFRL for supporting and reviewingthis work.ReferencesBagga, A., and B. Baldwin.
1998.
Entity-BasedCross-Document Coreferencing Using theVector Space Model.
In Proceedings ofCOLING-ACL'98.Deerwester, S., S. T. Dumais, G. W. Furnas, T. K.Landauer, and R. Harshman.
1990.
Indexing byLatent Semantic Analysis.
In Journal of theAmerican Society of Information ScienceGale, W., K. Church, and D. Yarowsky.
1992.One Sense Per Discourse.
In Proceedings of the4th DARPA Speech and Natural LanguageWorkshop.Goodman, J.
2003.
Exponential Priors forMaximum Entropy Models.Landauer, T. K., & Dumais, S. T. 1997.
A solutionto Plato's problem: The Latent SemanticAnalysis theory of the acquisition, induction, andrepresentation of knowledge.
PsychologicalReview, 104, 211-240, 1997.MUC-7.
1998.
Proceedings of the SeventhMessage Understanding Conference.Neal, R. M. 1993.
Probabilistic Inference UsingMarkov Chain Monte Carlo Methods.
TechnicalReport, Univ.
of Toronto.Pietra, S. D., V. D. Pietra, and J. Lafferty.
1995.Inducing Features Of Random Fields.
In IEEETransactions on Pattern Analysis and MachineIntelligence.Srihari, R. K., W. Li, C. Niu and T. Cornell.InfoXtract: An Information Discovery EngineSupported by New Levels of InformationExtraction.
In Proceeding of HLT-NAACL 2003Workshop on Software Engineering andArchitecture of Language Technology Systems,Edmonton, Canada.
