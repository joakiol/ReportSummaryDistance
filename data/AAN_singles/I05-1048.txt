R. Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
542 ?
552, 2005.?
Springer-Verlag Berlin Heidelberg 2005A Lexicon-Constrained Character Model for ChineseMorphological AnalysisYao Meng, Hao Yu, and Fumihito NishinoFujitsu R&D Center Co., Ltd, Room B1003, Eagle Run Plaza, No.
26 Xiaoyun Road,Chaoyang District, Bejing, 100016, P. R. China{Mengyao, Yu, Nishino}@frdc.fujitsu.comAbstract.
This paper proposes a lexicon-constrained character model that com-bines both word and character features to solve complicated issues in Chinesemorphological analysis.
A Chinese character-based model constrained by alexicon is built to acquire word building rules.
Each character in a Chinese sen-tence is assigned a tag by the proposed model.
The word segmentation and part-of-speech tagging results are then generated based on the character tags.
Theproposed method solves such problems as unknown word identification, datasparseness, and estimation bias in an integrated, unified framework.
Preliminaryexperiments indicate that the proposed method outperforms the best SIGHANword segmentation systems in the open track on 3 out of the 4 test corpora.
Ad-ditionally, our method can be conveniently integrated with any other Chinesemorphological systems as a post-processing module leading to significant im-provement in performance.1   IntroductionChinese morphological analysis is a fundamental problem that has been studied ex-tensively [1], [2], [3], [4], [5], [6], [7], [8].
Researchers make use of word or characterfeatures to cope with this problem.
However, neither of them seems completely satis-factory.In general, a simple word-based approach can achieve about 90% accuracy forsegmentation with a medium-size dictionary.
However, since no dictionary includesevery Chinese word, the unknown word (or Out Of Vocabulary, OOV) problem [9],[10] can severely affect the performance of word-based approaches.
Furthermore,word-based models have an estimation bias when faced with segmentation candidateswith different numbers of words.
For example, in the standard hidden Markov model,the best result, ?=?==niiiiiTTtttptwpWTpT111* )...|()|(maxarg)|( maxarg , is related to the number ofthe words in the segmentation candidates.
As such, a candidate with fewer words ispreferred over those with more words in the selection process.
Therefore, most word-based models are likely to fail when a combinational ambiguity1 sequence is separatedinto multiple words.1A typical segmentation ambiguity, it refers to a situation in which the same Chinese sequencemay be one word or several words in different contexts.A Lexicon-Constrained Character Model for Chinese Morphological Analysis 543Compared with Chinese words, Chinese characters are relatively less unambigu-ous.
The Chinese character set is very limited.
Therefore, unknown characters occurrarely in a sentence.
The grammatical advantages of characters have inspired re-searchers to adopt character features in Chinese morphology and parsing [5], [6], [11],[12].
However, it is difficult to incorporate necessary word features, such as the formof a Chinese word and its fixed part-of-speech tags, in most character-based ap-proaches.
For this reason, character-based approaches have not achieved satisfactoryperformance in large-scale open tests.In this paper, we propose a lexicon-constrained character model to combine themerits of both approaches.
We explore how to capture the Chinese word buildingrules using a statistical method, which reflects the regularities in the word formationprocess.
First, a character hidden Markov method assigns the candidate tags to eachcharacter.
Next, a large-size word list combined with linguistic information is used tofilter out erroneous candidates.
Finally, segmentation and part-of-speech tagging forthe sentence are provided based on the character tags.The proposed model solves the problems of unknown word detection, word seg-mentation and part-of-speech tagging using both word and character features.
Addi-tionally, our module is a post-processing module, which can be coupled to any exist-ing Chinese morphological system; and it can readily recall some of the unknownwords omitted by the system, and as a result, significantly improves the overall per-formance.
Evaluations of the proposed system on SIGHAN open test sets indicate thatour method outperforms the best bakeoff results on 3 test sets, and ranks 2nd in the 4thtest set [9].2   A Lexicon-Constrained Character Model for ChineseMorphology2.1   An Elementary Model to Describe Chinese Word Building RulesIt is recognized that there are some regularities in the process of forming words fromChinese characters.
This in general can be captured by word building rules.
In thispaper, we explore a statistical model to acquire such rules.
The following are somedefinitions used in the proposed model.[Def.
1] character position featureWe use four notations to denote the position of a character in a Chinese word.
?F?means the first character of the word, ?L?
the last character, ?M?
is a character withinit and ?S?
the word itself.[Def.
2] character tag setIt is the product of the set of character position features and the set of part-of-speech tags.Character tag set ={xy| setwordx  POS ?
, },,,{ LMFSy ?
}, where, x denotes onepart-of-speech (POS) tag and y a character position feature.
Together they are used todefine the rules of Chinese word formation.[Def.
3] character taggingGiven a Chinese sentence; character tagging is the process for assigning a charactertag to each character in the sentence.544 Y. Meng, H. Yu, and F. NishinoWord building rules are acquired based on the relation between the character andthe corresponding character tag.
Word segmentation and part-of-speech tagging canbe achieved easily based on the result of character tagging.
For example, a characterwith ?xS?
is a single character word with the part-of-speech tag ?x?
; a character se-quence starting with ?xF?
and ending with ?xL?
is a multiple character word with thepart-of-speech tag ?x?.The elementary model adopts the character bi-gram hidden Markov model.
In hid-den Markov model, given the sentence,nn ccccs 121 ...: ?
, and character tagging resultnn xyxyxyxyt 121 ...: ?
, the probability of result t of s is estimated as:?=??
?=niiiiii xycpxyxyxypstp,112 )|() |()|(  (1)The best character tagging result for the sentences is given by equation (2):?=??
?=niiiiiitxycpxyxyxypt,112* )|()|(maxarg  (2)We used the People's Daily Corpus of 1998 [13] to train this model.
Also weadopted a 100,000-word dictionary listing all valid part-of-speech tags for each Chi-nese word in the training phase to solve the data sparseness problem.
The training dataare converted into character tagging data through the following steps: a single charac-ter word with ?x?
is converted into the character marked with tag ?xS?
; a two-characterword with ?x?
is converted into a first character with ?xF?
and a second character with?xL?
; a word with more than two characters with ?x?
are converted into a first characterwith ?xF?, middle characters with ?xM?
and last character with ?xL?.
We adopt the POStag set from the People's Daily Corpus, which consists of 46 tags.
Taking into accountof the four position features, the final character tag set is comprised of 184 tags.The emitted probability and transition probability of the model are estimated by themaximum likelihood method.
The emitted probability is counted by the training Cor-pus and the dictionary, where the Chinese words in the dictionary are counted onetime.
The transition probability is trained from the training Corpus only.2.2   An Improved Character-Based Model Using Lexicon ConstraintsWe tested the above model based on the SIGHAN open test set [9].
The average pre-cision for word segmentation was more than 88%.
This means that most of the wordbuilding rules in Chinese have been obtained by the elementary model.
However, theperformance was relatively inferior to other word segmentation systems.
It indicatedthat the model needed more features to learn word building rules.
In error analysis, wefound that the elementary model was so flexible that it produced many pseudo-wordsand invalid part-of-speech tags.
In practice, a Chinese word is a stable sequence ofChinese characters, whose formation and part-of-speech tags are fixed by long-termusage.
It seemed that only character position and meaning cannot describe a wordbuilding rule effectively.We also observed that word segmentation systems based on a simple dictionarymatching algorithm and a few linguistic rules could achieve about 90% accuracy [14].This suggested that a lexicon may have contribution to word building rules.
Thus, wetried to incorporate a lexicon to the model to improve the performance.A Lexicon-Constrained Character Model for Chinese Morphological Analysis 545The major errors in the elementary model were pseudo words and invalid part-of-speech (POS) tags.
We proposed two constraints based on the lexicon to deal withthese errors:1.
If a possible word produced from the elementary model is in the word-dictionary, the character tag of the characters forming this word should beconsistent with the part-of-speech tag of the word in the dictionary.2.
If a possible word produced is not in the dictionary, it must include one ormore single characters, and none of which may be subsumed by any word inthe dictionary in the current context.The first constraint eliminates invalid character tags.
For example, the character??
?
has six character tags: ?aF?
(first in adjective) , ?dF?
(first in adverb), ?nF?
(firstin noun), ?nrF?
(first in person name), ?tF?
(first in time), and ?vF?
(first in verb).
Thecharacter ???
has five character tags: ?dL?, ?nL?, ?nrL?, ?tL?, and ?vL?.
The combina-tion of the two characters produces the possible word ???
?, which includes fivepossible word part-of-speech tags: ?d?, ?n?, ?nr?, ?t?, and ?v?
based on these charactertags.
But ????
is a word in the dictionary, which only has two valid part-of-speechtags, namely, ?time?
and ?person name?.
Obviously, the part-of-speech tags: ?d?, ?n?and ?v?
of ????
are invalid.
Accordingly, the tags ?aF?, ?dF?, ?nF?
, ?vF?
on ???
andthe tags ?dL?, ?nL?, ?vL?
on ???
are also invalid.
So they should be pruned from thecandidates of the character tagging.The second constraint prunes pseudo words in the elementary model.
Many studiesin dictionary-based segmentation treat unknown words as sequences of single charac-ters [1], [14].
The second constraint ensures that the new word produced by the ele-mentary model must have one or more ?unattached?
single characters (not subsumedby any other words).
For example, the sequence ??????
(program error) willcombine the pseudo word ????
because of the tag ?nF?
on ???
and the tag ?nL?
on???.
The second constraint will prune ????
since ????
(program) and ????
(error) are already in the dictionary and there is no ?unattached?
single character in it.Accordingly, the tag ?nF?
on ???
and the tag ?nL?
on ???
will be deleted from thecandidates of character tagging.The following experiments show the lexicon-based constraints are very effective ineliminating error cases.
The elementary model faces an average of 9.3 character tagsfor each character.
The constraints will prune 70% of these error tags from it.
As aresult, the performance of character tagging is improved.It is worth noting that the lexicon in the elementary model cannot distort the prob-ability of the character tagging results in the model.
The pruned cases are invalidcases which cannot occur in the training data because all the words and POS tags inthe training data are valid.
Thus, the model built from the training data is not affectedby the pruning process.2.3   Case StudyIn this subsection, we illustrate the advantages of the proposed method for Chinesemorphology with an example.546 Y. Meng, H. Yu, and F. NishinoExample: ??????????????
(Xiaoming will analyze the program errors tomorrow).Where, ????
is an unknown word (person name), and the sequence ????
is acombinational ambiguity (either ????
(put up with) or ??
?+ ???
(will)).
Here ishow our approach works.Step 1: List all the character tags for each character.
Figure 1 shows the charactertags in the sequence ??????
.
?aF dF nF nrF nM nrM nsM qM vM aL dL vL aS?aF dF nF nrF vF tF nM lM tM aL dL nrL aS?aF dF nF nrF vF tF nM lM tM aL dL nrL aS?nF tF nrM dL nL nrL tL vLFig.
1.
Candidates for the sequence ?????
?In this step we are able to find possible unknown words based on character positionfeatures.
For example, the character tags in ??????
combine four possible un-known words: ???
?, ????
?, ?????
, and ?????
?.Step 2: Prune the invalid candidates using constraints.The first constraint prunes some invalid character tags.
For example, ????
can beeither an adverb (d) or a personal name (nr); ????
is a time (t) word.
The other part-of-speech tags of these two words will be deleted.
With the second constraint, we candelete ?????
because ????
and ????
are words in the dictionary.
However, ????
, ????
?, and ??????
will be kept because ???
is a ?unattached?
singlecharacter.
The remaining candidates are shown in figure 2.?aF dF nF nrF nM nrM nsM qM vM aL dL vL aS?dF  nrF   nM lM tM    aS?tF nM lM tM  dL nrL aS?nF tF nrM   nrL tLFig.
2.
Remaining Candidates for the sequence ?????
?Step 3: Choose the best character tagging result based on the proposed characterhidden Markov model.The best character tagging result is chosen using equation 2 in Section 2.1.
Theambiguities in segmentation and word POS tagging are solved in the character tag-ging process.Consider the combinational ambiguity ????
in the following 2 candidates:Candidate 1: ??
?/nr ?
?/t ?/d ?/d ?
?/n ?
?/n ?
?/v ?
?/v?Candidate 2: ??
?/nr ?
?/t ?
?/v ?
?/n ?
?/n ?
?/v ?
?/v?A Lexicon-Constrained Character Model for Chinese Morphological Analysis 547In word-based linear model, the erroneous candidate 2 will be prior to the correctcandidate 1 since the model counts 9 nodes in candidate 1 but 8 nodes in candidate 2.However, there is no such bias in the character model because the number of charac-ters does not change.
The combinational ambiguity ????
will be denoted as ??/dS?/dS?
or ?
?/vF ?/vL?.
The number of nodes in all candidates of character tagging isthe same.At last, the correct result ?
?/nrF ?/nrL ?/tF ?/tL ?/dS ?/dS?/nF ?/nL ?/nF?/nL ?/vF ?/vL ?/vF ?/vL?
is selected, and the corresponding morphological resultis: ??
?/nr ?
?/t ?/d ?/d ?
?/n ?
?/n ??
/v ?
?/v ?.The above steps show the proposed approach solves the various issues related toChinese morphology by a concise character tagging process where word building isrevealed.3   Experiments and DiscussionWe evaluated the proposed character method using the SIGHAN Backoff data, i.e.
theone-month People's Daily Corpus of 1998, and the first version of Penn Chinese Tree-bank [15].
We compared our approach against two state-of-the-art systems: one isbased on a bi-gram word segmentation model [7], and the other based on a word-based hidden Markov model [3].
For simplicity, we only considered three kinds ofunknown words (personal name, location name, and organization name) in the allmethods.The same corpus and word-dictionary were used to train the above three systems.The training data set was the 5-month People's Daily Corpus of 1998, which con-tained approximately 6,300,000 words and 46 word part-of-speech tags.
The systemdictionary contained 100,000 words and the valid part-of-speech tag(s) of each word.On average, there were 1.3 part-of-speech tags for a word in the dictionary.In the following, chr-HMM refers to the proposed elementary model; chr-HMM+Dic refers to the character model improved by integrating linguistic informa-tion.
W-Bigram is the word-based bi-gram system, and W-HMM is the word-basedhidden Markov system.3.1   Morphological Experimental ResultsWe examined the performance of our model in comparison against W-Bigram and W-HMM.
Table 1 compares the segmentation performance of our model against that ofother models.
Table 2 shows the accuracy in unknown word identification.
Table 3illustrates the performance of the part-of-speech tagging.
The experiments in Table 1and Table 2 were examined using the SIGHAN open test corpora.
The experiments inTable 3 were performed again on the one-month People's Daily Corpus (PD corpus)and 4,000 sentences in the Penn Chinese Treebank (Penn CTB).
We only examined 4major word categories in the Penn Chinese Treebank due to inconsistency in the part-of-speech tag sets between the two corpora.
The 4 major word categories were: noun(shown as NN, NR in Penn CTB; n, nr, ns, nz in PD corpus), verb (VV in Penn CTB;v, vd, vn in PD corpus), adjective (JJ in Penn CTB; a, ad, an in PD corpus) and adverb(AD in Penn CTB; d in PD corpus).548 Y. Meng, H. Yu, and F. NishinoSegmentation and word POS tagging performance is measured in precision (P%),recall (R%) and F-score (F).
Unknown words (NW) are those words not found in ourword-dictionary, which include named entities and other new words.
The unknownword rate (NW-Rate), the precision on unknown words (NW-Precision) and recall ontotal unknown words (NW-Recall) are given by:NW-Rate= identifiedNW  of  #  totalrdsunknown wo of  #NW-Precision = identifiedNW  of # totalrdsunknown wo  validof #NW-Recall = data in testingNW  of # totalrdunknown wo  validof #Table 1 shows that the above three systems achieve similar performances on thePK testing corpus.
All of them were trained by the People's Daily corpus.
For thisreason, their performances were similar when the testing data had similar styles.
Butfor other texts, the proposed character model performed much better than the word-based models in both recall and precision.
This indicated that our approach performedbetter for unseen data.Table 2 shows that our method for unknown word identification also outperformsthe word-based method.
We notice that word-based approaches and character-basedapproaches have similar precision on unknown word identification, however word-based approaches have much lower recall than character-based ones.
The main reasonfor this is that word-based systems focus only on unknown words with proper wordstructures, but cannot recognize newly generated words, rare words, and other newwords unlisted in the dictionary.
A very high proportion of these types of unknownword in the SIGHAN testing data affects the recall of the word-based methods onunknown words.
The experiments reveal that our method could effectively identify allkinds of new words.
This is because our model has defined word building rules for allkinds of words.Without a widely recognized testing standard, it is very hard to evaluate the per-formance on part-of-speech tagging.
The results in Penn Chinese Treebank was betterthan that in the People's Daily Corpus since we examined all 42 POS tags in the Peo-ple's Daily Corpus, but we only tested four major POS tags in Penn Chinese Tree-bank.
Our approach is better than the word-based method for two test data sets.
How-ever, we could not conclude that our method was superior to the word-based methodbecause of the limited testing approaches and testing data.
A thorough empirical com-parison among different approaches should be investigated in the future.Table 1.
Comparison of word segmentation based on SIGHAN open test setsPK CTB HK ASR%/ P% F R%/ P% F R%/ P% F R%/ P% FChr-HMM 91.9/91.8 91.8 86.9/87.3 87.1 87.7/86.7 87.2 89.9/89.1 89.5Chr-HMM+Dic 95.9/96.7 96.3 92.7/93.5 93.1 91.1/91.9 91.5 92.3/93.9 93.1W-Bigram 94.7/95.4 95.1 87.4/86.8 87.1 88.7/83.7 86.3 87.9/85.1 86.5W-HMM 94.6/95.1 94.9 88.6/89.2 88.9 90.7/89.1 89.9 90.7/87.2 89.0Rank 1 in SIG 96.3/95.6 96.0 91.6/90.7 91.2 95.8/95.4 95.6 91.5/89.4 90.5Rank 2 in SIG 96.3/94.3 95.3 91.1/89.1 90.1 90.9/86.3 88.6 89.2/85.3 87.3A Lexicon-Constrained Character Model for Chinese Morphological Analysis 549Table 2.
Accuracy of unknown word identification for SIGHAN open test setsPK CTB HK ASChr-HMM UWR% P% R% UWR% P% R% UWR% P% R% UWR% P% R%Chr-HMM+Dic 2.3 56.2 54.8 10.4 68.8 64.4 9.7 61.4 58.4 8 65.4 62.9W-Bigram 2.3 54.7 53.6 10.4 53.9 23.8 9.7 53.0 29.6 8 64.6 35.3W-HMM 2.3 58.1 51.3 10.4 68.3 37.2 9.7 62.3 40.7 8 68.4 41.1Table 3.
Comparison of word part-of-speech taggingPeople Daily Penn CTBP% R% F-score P% R% F-scoreChr-HMM 82.4% 82.5% 82.5 89.7% 88.5% 89.1Chr-HMM+Dic 89.3 87.8 88.6 92.5 91.5 92.0W-HMM 86.2% 85.4% 85.7 91.1% 90.8% 91.0From Table 1 and Table 3, we notice that chr-HMM achieved 88% accuracy inword segmentation and 80% in part-of-speech tagging without a word-dictionary.Chr-HMM is a state-of-the-art Chinese morphology system without a word-dictionary.
Its performance is comparable to some dictionary-based approaches (e.g.,forward-maximum).
This result indicates that our model has effectively captured mostof the Chinese word building rules.The results also show that chr-HMM+Dic outperformed the best SIGHAN wordsegmentation system on 3 out of the 4 SIGHAN open track test corpora, and achievedtop 2 in the case of HK testing corpus.3.2   Incorporation with Other SystemsThe advantage of the proposed model is proficiency in describing word building rulesand since many existing NLP application systems are weak in identifying new words,it is intuitive to integrate our model to existing systems and serves as a post-processing subsystem.
In this subsection, we show how existing word segmentationsystems could be improved using chr-HMM.Given a segmentation result, we assume that unidentified new words may be a se-quence of unattached characters.
That is, all multiple-character words in the givenresult are considered correct, while single words, which might include unidentifiednew words will be rechecked by the chr-HMM.
The entire process involves 3 steps:1.
Only character tags that are consistent with the position of the character in theword are listed for multi-character words.2.
The unattached characters are tagged with all possible character tags.
In thisway, the original segmentation result is converted into a group of charactertagging candidates.3.
We then input these character tagging candidates into the chr-HMM to selectthe best one.550 Y. Meng, H. Yu, and F. NishinoConsider an original result:??
[?
?
?
?
?]
??
[?
? ]
(Jordan bounced back strongly from thebottom yesterday)The parts in brackets are the sequence of single characters where the new wordsmay appear.
The chr-HMM will list all possible character tags for these ?unattached?characters.
The parts outside the brackets are multiple-character words identified bythe original system.
They are assumed correct and maintain also positional informa-tion.
Only the character tags, which are consistent with the positions of the characterin the word are listed.
The character tagging candidates for the above sample is givenin Figure 3:?
?
?vL ?
nL nsL ?tL vL nM nrL vM?
nL lM nsF nLnM ?nrF nrL tL nM vF nrF nM vF vL vF vLnF nL nL aM pS nF vF nF nL aF nLaF aL tS tS dS nS nS aF aL aS vS?
?
?
?
?
?
?
?
?
?
?Fig.
3.
Character tagging candidates for recheckingChr-HMM is then applied to the character tagging candidates and the best charac-ter tagging selected based on the probability of the candidates is output as the result.In this example, the result is: ???
(Jordan) ??
(yesterday) ?
(from) ??
(earth)??
(strongly) ??
(bound)?.
The three missing new words in the original systemare identified by this post-processing subsystem.We re-assigned the word segmentation results for all participants who have givenpermission to release data from the SIGHAN site (available for download fromhttp://www.sighan.org/bakeoff2003 ).
Table 4 enlists the performance of SIGHANopen test with and without chr-HMM.
The participant numbers correspond to the siteslisted in [9].Table 4.
Comparison of results with and without chr-HMMCorpus Site  R% P% FAS 03 Before After89.290.885.392.087.291.401 Before After88.790.187.691.888.190.903 Before After85.386.480.687.882.987.1 CTB10 Before After91.191.089.193.590.192.3HK 03 Before After90.989.486.391.088.690.203 Before After94.194.491.195.392.594.9 PK10 Before After96.395.695.697.795.996.7A Lexicon-Constrained Character Model for Chinese Morphological Analysis 551From Table 4, it is obvious that word segmentation precision increases signifi-cantly, and at the same time, the corresponding recall remains the same or slightlydeclined.
This implies that the chr-HMM retains the correct words by the originalsystem and concurrently decreases significantly its errors.4   Related WorkAlthough character features are very important in Chinese morphology, research incharacter-based approach is unpopular.
Chooi-Ling Goh et al [16], Jianfeng Gao etal.
[8] and Huaping Zhang [3] adopted character information to handle unknownwords; X. Luo [11], Yao Meng [12] and Shengfen Luo [17] each presented character-based parsing models for Chinese parsing or new-word extraction.
T. Nakagawa usedword-level information and character-level information for word segmentation [6].Hwee Tou Ng et al [5] investigated word-based and character-based approaches andproposed a maximum entropy character-based POS analyzer.
Although the charactertags proposed in this paper are essentially similar to some of the previous work men-tioned above, here our focus is to integrate various word features with the character-based model in such a way that the probability of the model is undistorted.
The pro-posed model is effective in acquiring word building rules.
To our knowledge, ourwork is the first character-based approach, which outperforms the word-based ap-proaches for SIGHAN open test.
Also, our approach is versatile and can be easilyintegrated with existing morphological systems to achieve improved performance.5   Conclusion and Future WorksA lexicon-constrained character model is proposed to capture word building rulesusing word features and character features.
The combination of word and characterfeatures improves the performance of word segmentation and part-of-speech tagging.The proposed model can solve complicated issues in Chinese morphological analysis.The Chinese morphological analysis is generalized into a process of specific charactertagging and word filtering.
A lexicon supervises the character-based model to elimi-nate invalid character tagging candidates.Our system outperformed the best SIGHAN word segmentation system in 3 out ofthe 4 SIGHAN open test sets.
To our knowledge, our work is the first character-basedapproach, which performs better than word-based approaches for SIGHAN open test.In addition, the proposed method is versatile and can be easily integrated to any exist-ing Chinese morphological system as a post-processing subsystem leading to en-hanced performance.In this paper, we focused on word features in character-based mode, and adoptedHMM as the statistical model to identify the rules.
Other statistical models, such asmaximum entropy, boosting, support vector machine, etc., may also be suitable forthis application.
They are worth investigating.
The data sparseness problem is practi-cally non-existent in the character-based model for the Chinese character set is lim-ited.
However, odd characters are occasionally found in Chinese personal or placenames.
Some rules using named entity identification technique may help smoothen552 Y. Meng, H. Yu, and F. Nishinothis.
In a broader view, the word building rules proposed in our model is simpleenough for linguistic studies to better understand for example formation of Chinesewords or even the Chinese language itself.References1.
Andi Wu.
Chinese Word Segmentation in MSR-NLP.
In Proc.
of SIGHAN Workshop,Sapporo, Japan, (2003) 127-1752.
GuoDong Zhou and Jian Su.
A Chinese Efficient Analyzer Integrating Word Segmenta-tion, Part-Of-Speech Tagging, Partial Parsing and Full Parsing.
In Proc.
Of SIGHANWorkshop, Sapporo, Japan, (2003) 78-833.
Huaping Zhang, Hong-Kui Yu et al.
HHMM-based Chinese Lexical Analyzer ICTCLAS.In Proc.
Of SIGHAN Workshop, Sapporo, Japan, (2003) 184-1874.
Nianwen Xue and Libin Shen.
Chinese Word Segmentation as LMR Tagging.
In Proc.
OfSIGHAN Workshop, Sapporo, Japan, (2003) 176-1795.
Hwee Tou Ng, Low, Jin Kiat.
Chinese Part-of-Speech Tagging: One-at-a-Time or All-at-Once?
Word-Based or Character-Based?
In Proc.
of EMNLP, Barcelona, Spain, (2004)277-2846.
Tetsuji Nakagawa.
Chinese and Japanese Word Segmentation Using Word-level andCharacter-level Information, In Proc.
of the 20th COLING, Geneva, Switzerland, (2004)466-4727.
Guohong Fu and Kang-Kwong Luke.
A Two-stage Statistical Word Segmentation Systemfor Chinese.
In Proc.
Of SIGHAN Workshop, Sapporo, Japan, (2003) 156-1578.
Jianfeng Gao, Andi Wu, Chang-Ning Huang et al Adaptive Chinese Word Segmentation.In Proc.
of 42nd ACL.
Barcelona, Spain, (2004) 462-4699.
Richard Sproat and Thomas Emerson.
The First International Chinese Word SegmentationBakeoff.
In Proc.
Of SIGHAN Workshop, Sapporo, Japan, (2003) 133-14310.
X. Luo.
A Maximum Entropy Chinese Character-based Parser.
In Proc.
of EMNLP.
Sap-poro, Japan, (2003) 192-19911.
Honglan Jin, Kam-Fai Wong, ?A Chinese Dictionary Construction Algorithm for Informa-tion Retrieval?, ACM Transactions on Asian Language Information Processing, 1(4):281-296, Dec. 2002.12.
Yao Meng, Hao Yu and Fumihito Nishino.
2004.
Chinese New Word Identification Basedon Character Parsing Model.
In Proc.
of 1st  IJCNLP, Hainan, China, (2004) 489-49613.
Shiwen Yu, Huiming Duan, etal.
?????????????????.
?????
?v(5), (2002) 49-64, 58-6514.
Maosong Sun and Benjamin K. T?
Sou.
Ambiguity Resolution in Chinese Word Segmenta-tion.
In Proc.
of 10th Pacific Asia Conference on Language, Information & Computation,(1995) 121-12615.
Nianwen Xue, Fu-Dong Chiou and Martha Palmer.
Building a Large-scale AnnotatedChinese Corpus.
In Proc.
of the 19th COLING.
Taibei, Taiwan, (2002)16.
Chooi-Ling GOH, Masayuki Asahara, Yuji Matsumoto.
Chinese Unknown Word Identifi-cation Using Character-based Tagging and Chunking.
In Proc.
of the 41st ACL, Interac-tive Poster/Demo Sessions, Sapporo, Japan, (2003) 197-20017.
Shengfen Luo, Maosong Sun.
2003, Two-character Chinese Word Extraction Based onHybrid of Internal and Contextual Measure, In Proc.
of the 2nd SIGHAN Workshop, Sap-poro, Japan, (2003) 20-30
