A.
Generic Template to evaluate integrated componentsin spoken dialogue systemsGavin E Churcher and Eric S Atwell and Clive SouterCentre for Computer Analysis of Language And Speech (CCALAS)Artificial Intelligence Division, School of Computer StudiesThe University of Leeds, LEEDS LS2 9JT, Yorkshire, Englandgavin~scs.leeds.ac.uk anderic~scs.leeds.ac.uk andcs@scs.leeds.ac.ukWWW: http://agora.leeds.ac.uk/amalgam/Abstract enough to be employed in the commercial marketWe present a generic template for spokendialogue systems integrating speech recog-nition and synthesis with 'higher-level' nat-ural language dialogue modelling compo-nents.
The generic model is abstractedfrom a number of real application sys-tems targetted at very different domains.Our research aim in developing this generictemplate is to investigate a new approachto the evaluation of Dialogue ManagementSystems.
Rather than attempting to mea-sure accuracy/speed of output, we proposeprinciples for the evaluation of the underly-ing theoretical linguistic model of DialogueManagement in a given system, in termsof how well it fits our generic template forDialogue Management Systems.
This isa measure of 'genericness' or 'application-independence' of a given system, which canbe used to moderate accuracy/speed scoresin comparisons ofvery unlike DMSs servingdifferent domains.
This relates to (but isorthogonal to) Dialogue Management Sys-tems evaluation in terms of naturalnessand like measurable metrics (eg Dybkjaeret al1995, Vilnat 1996, EAGLES 1994,Fraser 1995); it follows more closely emerg-ing qualitative evaluation techniques forNL grammatical parsing schemes (Leech etal 1996, Atwell 1996).KEYWORDS: evaluation, comparisons, genericmodel, standards.1 BackgroundDialogue management systems, particularly thosewhich replace a graphical user interface with a spo-ken language one, have become increasingly popu-lar.
Speech recognition isgradually becoming robustplace, and because of this many companies are real-ising the value of a spoken interface to their prod-ucts and services.
The research community pro-7"vides a number of methodologies to the represen-tation of dialogue and its implementation  a com-puter.
Correspondingly, there are a number of de-sign methodologies for building such a system.
De-spite there many differences, every one contains acommon process: an evaluative cycle.
Evaluating adialogue management system is a difficult and oftensubjective xperience.
Whilst it is possible to objec-tively measure recognition performance, valuationof a dialogue is not as straightforward.
Even thosesystems which exhibit appalling speech recognitionperformance can nevertheless lead to "successful" di-alogues.2 Quantitative and qualitativeevaluationThere are two approaches to evaluating a dialoguemanagement system: to use a qualitative or a quan-titative measure.
A qualitative valuation wouldrely on the user's opinion of the system.
Dybkjaeret al(1995) conducted interviews after each sessionand asked whether the dialogue seemed natural andpleasant.
Such a subjective valuation is fraughtwith problems.
For example, the user may learn af-ter the first attempt how to address the system andwhich words to use or avoid.
Subsequent evaluationsof the same system may then vary even though thesystem has not changed.
Some users may find thesystem difficult to use whilst other will find it effort-less.
"Pleasantness" differs from person to person,too.
As Vilnat (1996) argues, there is no clear con-sensus of what comprises a good dialogue.
Whenasking the user, the designer has to make sure thatthe user is representative of the end user in terms ofbackground and frequency of use.
Because of theseproblems, many researchers have tried to provide ameans of objectively evaluating a system.The two methodologies for quantitative valua-tion, black and glass box, are concerned with inputand output behaviour and the behaviour of each ofthe components in the system, respectively.
Glassbox evaluation can rely on a comparison betweenthe output of a component and a retrospective r f-erence.
By directly comparing the two it is possibleto measure the accuracy of that component.
Theblack box approach, on the other hand, cannot usethis method to evaluate a dialogue since there is no"correct" dialogue to compare it with.
Despite this,objective valuation of the dialogue is necessary inorder to compare the performance of different sys-tems.
Initial efforts have been made to standardisethis (for example in EAGLES, see Fraser 1995a) butremain work in progress.3 Common components  in p ract i ca lD ia logue  Management  SystemsOur recent survey of a number of dialogue man-agement systems has led us to identify those fea-tures and components which occur in many of thesystems.
By examining a range of successful sys-tems, from flight information services (Fraser 1995b)and appointment scheduling in Verbmobil (Alexan-der and Reithinger 1995, Maier 1996, Alexandersson1996) to theatre ticket booking (Hulstijn et al 1996)and virtual space navigation (Nugues et al 1996), atemplate for a generic dialogue management systemhas been drafted.
A number of features are incor-porated, including a pragmatics interpreter dealingwith discourse phenomena such as anaphoric resolu-tion and ellipsis, a model of the task structure andhow it relates to the dialogue structure, a model ofconversation incorporating an interaction strategyand a recovery strategy, and a semantic interpreterwhich resolves the full interpretation of an utterancein light of its context.
This generic template canbe used in the design of future dialogue manage-ment systems, highlighting important features andthe mechanisms required to implement them.
Thetemplate also provides an application-independentmethod for assessing systems according to the fea-tures they exhibit.4 Advantages  o f  qua l i ta t iveassessment  aga ins t  a s tandardSpeech And Language Technology researchers areused to thinking of evaluation in terms of speedand accuracy of system outputs, for example 'suc-cess rate' of a speech recogniser or syntactic parserin analysing a standard test corpus.
However, 'Din-10logue Management' is a high-level linguistic conceptwhich cannot be measured so straightforwardly forseveral reasons:- existing DMSs are very domain-specific, and weneed to compare dialogue systems across domains;so it makes no sense to look for a common standard'test corpus';- the boundary between 'good' and 'bad' dialogueis very ill-defined, so it makes little sense to try toassess against a target 'correct output', or even bysubjective assessment of 'pleasantness' of output;- the structure of dialogue (and hence a DMS) iscomplex, multi-level, and non-algorithmic, making asingle overall 'evaluation metric' meaningless with-out consideration of component behaviours;- we need to evaluate the integrated system holis-tically, as opposed to measuring speed or accuracyof individual components;- alternative dialogue systems use a wide range ofalternative component technologies; only by fittingthese against a generic template can we discrimi-nate between superficial and substantive differencesin component assumptions and functionalities.There is a useful analogy with evaluation of NLparsers; typically, rival parsers are compared bymeasuring speed (sentences-per-minute) and/or ac-curacy (e.g.
percentage of sentences parsed) - e.g.
(Sutcliffe t al 1996).
However, rival parsing schemesinclude varying 'levels' of syntactic information, asshown in EAGLES recommendations (Leech et al1995).
Atwell (1996) proposes an orthogonal eval-uation of parsing schemes against the generic EA-GLES 'template' of syntactic levels, so that a givenparser speed/accuracy measure should be moder-ated by a 'genericness' weight; for example, the EN-GCG parser (Voutilainen and Jarvinen 1996) is veryfast and accurate BUT its underlying parsing schemeinstantiates only a small subset of the EAGLES'template', which moderates an overall 'score'.
Inmuch the same way, we propose that very unlike ri-val DMSs can be meaningfully compared by assess-ing how well they match our generic template fordialogue management architecture, and using this'genericness' score to temper any measures of speed,accuracy, naturalness, etc.Consider (Churcher et al1997), which included afirst attempt at an outline of a generic spoken lan-guage system.
The model includes generic modulesfor syntactic, semantic, and speech act constraints;these constraints are integrated into spoken input in-terpretation to compensate for limitations in speechrecognition components.
The model constitutes atemplate tool for designing integrated systems; itspecifies the standard components and how they fittogether.
As is the predicament of any generic sys-tem it is necessarily vague and since it attempts tocombine components found in a variety of individualmodels, it may not fit all systems, if any in particu-lar.In our survey, we studied how this generic modelmapped onto a range of existing real systems, bylooking at the representation formats for the vari-ous linguistic features in the dialogue managementschemes; as with grammatical analysis schemes,there is a need for a theory-neutral 'interlingua' stan-dard dialogue representation scheme (Atwell 1996).5 Features  o f  Natura l  D ia logue'Naturalness' in dialogue is difficult to define, butby examining phenomena which occur in human tohuman dialogue we can begin to draw some fea-tures which contribute to its definition.
The pro-posed model in (Churcher et al97) reflects this toa certain extent by incorporating components forphenomena such as anaphora nd ellipsis whilst ab-stracting away from those components which are do-main specific, such as the model of task/dialoguestructure.
To begin with, seven such features aredescribed below.A: AnaphoraAnaphora frequently occurs in dialogue.
This formof deixis is applied to words which can only be inter-preted in the given context of the dialogue.
Thereare a number of different forms of anaphora includ-ing personal pronouns (" I", "you", "he/she/it" etc.
),spatial anaphora ("there", "that" etc.)
and tempo-ral anaphora ("then").
Expressions relative to thecurrent context often need to be interpreted into anabsolute or canonical form.
This form of anaphoraincludes expressions such as "next week" and "thenext entry" which can only be resolved in relation toa previous expression.
By incorporating anaphora,speaker can reduce redundancy and economise theirspeech.B: EllipsisEllipsis commonly occurs in a sentence where forreasons of economy, style or emphasis, part of thestructure is omitted.
The missing structure can berecovered from the context of the dialogue and nor-mally the previous entences.
Without modellingellipsis, dialogue can appear far from natural.C: Recovery strategyAlthough misunderstandings often occur in conver-sations, speakers have the ability to recover fromthese and other deviations in communication.
Taleb(1996) presents an analysis of the type of commu-nicative deviations which can occur in conversationand categorises them into content and role devia-tions.
The inadequacies of speech recognition tech-nology introduces additional potential deviations.
Adialogue management system must be able to re-cover from any deviations which occur.
Seldomin human to human conversation does the dialogue'break down'.D: Interaction strategyAt any stage in a dialogue, one participant has theinitiative of the conversation.
In everyday conversa-tion, it is possible for either participant to take theinitiative at any stage.
Turning to dialogue man-agement, he interaction strategy is important whendefining the naturalness of the system.
System-orientated question and answer systems where thesystem has the initiative throughout the dialogueare the simplest to model since the user is explicitlyconstrained in their response.
The greater freedomthe user has to control the dialogue, the more com-plicated this modelling strategy becomes.
Where theuser has the initiative throughout the dialogue suchas in command and control applications, the user hasgreater expressibility and freedom of choice.
Themost difficult dialogues to model are those wherethe initiative can be taken be either the system orthe user at various points in the dialogue.
As notedby Eckert (1996), mixed initiative systems involvedialogues which approach the intricacies of conver-sational turn-taking, utilising strategies which deter-mine when, for example, the system can take the ini-tiative away from the user.
For systems using speechrecognition, the ability to confirm or clarify giveninformation is essential, hence system-orientated ormixed initiative should exist.E: Functional perplexityTo a lesser extent, the range of tasks that can beperformed by a particular dialogue is important.
Inhuman to human conversations, for example, an ut-terance can perform more than one illocutionary orspeech act.
In an analogous way, a dialogue caninclude more than one task, whether it is to booktickets for a performance, or to enquire about flighttimes.
Looking to individual utterances, the greaterthe number of acts which can be performed, themore complex (or perplex) the language model be-comes.
In everyday conversation, humans are adeptat marking topic boundaries and changes.
For appli-cations where more than one task is to be performedin a single dialogue, the dialogue manager needs to11be able to identify when the user switches from onetask to another.
Functional perplexity is a measureof the density of the topic changes in a single di-alogue and is accordingly difficult to calculate.
Asimpler measure is to count the number of semanti-cally distinct tasks a user can perform.F: Language perplexityThe ability to express oneself as one wishes and stillbe understood is an important factor which con-tributes to naturalness in dialogue.
This does notnecessarily entail a very large vocabulary since cor-pus studies and similar language elicitation exer-cises can provide a relatively small, core vocabulary.The user's freedom of expression is implicitly relatedto the initiative strategy employed by the dialoguemanager.
For example, when the system has theinitiative, the user's language can be explicitly con-strained.
In contrast a system which allows the userto take the initiative has less control of the user'slanguage.
Again, as with functional perplexity, theperplexity of a language in this sense is difficult tomeasure but it is helpful to look to the extent thatthe system attempts to constrain the user's languagefor performing a task.
The level of constraint shouldnot be measured when the system is recovering fromdeviations in the dialogue, since focussing the usermay be necessary for recovering from the deviationin as few steps as possible.G: Over-informativenessThere are two inter-pretations of over-informativeness, system and userorientated, system orientated over-informativenessallows the dialogue manager to present more infor-mation to the user than was actually explicitly re-quested.
User orientated over-informativeness is animportant feature to have and is directly related tothe degree of freedom of expression.
In natural dia-logue, a speaker can provide more information thanis actually requested.
Humans are able to take thisadditional information into consideration or ignoreit depending on how relevant it is to the conversa-tion.
The information may have been volunteered inanticipation of a future request for information andas a result a dialogue manager which ignores it willnot appear very natural.
As an example, considerthe following dialogue between the system and userwhere the user responds with a reply which is over-informative:User: I'd like to make an appointment.System: Who would you like to make an appoint-ment with?User: John Smith at 2pm.6 A QuestionnaireWhilst each of the above features are important, itis not obvious which are more important to 'natural-ness' than others.
Turning to the research commu-nity we asked those who had designed systems incor-porating dialogue management for their experiencesand opinions.
The questionnaire asked the commu-nity to rank the features according to how importantthey thought hey were to their particular dialoguemanager and to comment on each one.
Given thetime constraints, it was not possible to ask moredetailed questions about each feature, although therespondents were encouraged to give examples.Table 1 shows the six systems detailed, table 2 asummary of the importance of the features to eachsystem.
The results range from 1 - the most im-portant to 7 - the least important; the ratings wereallowed to be tied.Table 1 :6  DMSs\[1\] Daimler-Benz Generic DMS (Heisterkamp1993, Heisterkamp and McGlashan 1996,Regel-Brietzm~nn et al (forthcoming))\[2\] LINLIN (Ahrenberg et al 1990,Jonsson 1993, 1996)\[3\] EVAR German Train-Timetable SpokenDialogue Information System (Eckertet al 1993, Boros et al 1996)\[4\] VERBMOBIL dialogue component(Alexandersson et al 1996,1997)\[5\] The Slovenian Dialog System for AirFlight Inquiries (Ipsic et al 1997,Pepelnjak et al 1996)\[6\] SAPLEN - Sistema Automatico dePedidos en Lenguaje Natural(Lopez-Cozar(forthcoming))Table 2: Features ranked in 6 DMSsFeature A B C D E F GE l i  2 1 1 2 3 2 2\ [2 \ ]  2 1 1 2 2 2 2\ [3 \ ]  2 1 1 1 3 1 1\ [4 \ ]  1 1 1 6 - 2 -\ [5 \ ]  - 3 6 6 5 3 2\ [6 \ ]  3 5 5 5 5., ,5 ,5Men 2 .0  2 .0  2 .5  3 .7  3 .6  2 .5  2 .412Note that where '-' occurs, the feature was notranked, and so is omitted from the mean.
It is inter-esting to note that different respondents interpretedthe ranking differently.
Whilst some understood thepoints system to indicate the order of importance ofeach feature, others, such as \[6\] considered the pointsto be an indication of how important the feature wasto their system.By taking the mean of the scores, the features canbe ordered as follows, most important first:A: Anaphora == B: EllipsisG: Over-informativenessC: Recovery strategy == F: Language perplexityE: Functional perplexityD: Interaction strategy7 Comments  on  approach  takenThe initial, tentative ranking of features indicatesthat anaphora and ellipsis are important, whilstfunctional perplexity and interaction strategy areleast important.
Given that the systems urveyedperformed just one or two tasks, it is not surprisingthat functional perplexity is not ranked highly.
Thelow ranking of the interaction strategy reflects theapplication of the system.
For example, system \[4\],Verbmobil, regarded the interaction strategy to beof low importance since it is a minimally intrusivesystem which facilitates the dialogue between twohumans.What is made clear is that we need to conduct fur-ther research into explicitly quantifying each featurefor this approach to be worthwhile.
Whilst featuressuch as over-informativeness are either present ornot, others are finer grained; the interaction strat-egy can be system-orientated, user-orientated or acombination of both.
Language perplexity, in thesense meant here, needs to be quantified, too, beforeit can be considered a useful feature.
In retrospect,the ranking of each feature needs to be made consis-tent.8 Conclusion~ecent echnological dvances are bringing spokendialogue systems closer to markets, to real applica-tions.
As the focus of this research field shifts fromacademic study to commercial reality, we feel it isimportant o maintain a theoretical underpinning:a generic model for independent qualitative assess-ment and comparison of practical Interactive SpokenDialogue Systems.
We invite practical systems de-velopers to help us assess their products against hisgeneric template, allowing us in turn to maintainand refine the theoretical generic model to keep stepwith practical developments.The list of features can be used in two ways: toevaluate the 'genericness' ofa dialogue manager, andto ascertain whether a dialogue manager is suitableto a particular application.
In choosing between ri-val Dialogue Managment Systems, it is not sensibleto try to use a simple metric of accuracy or natural-ness applicable across all applications.
Different ap-plications require different DMS features.
Prospec-tive users hoping to re-use a DMS should first decidewhat they want from one; if they can frame their re-quirements in terms of our generic template, theycan eliminate candidate systems which do not focuson the required features.ReferencesL.
Ahrenberg, A. Jhnsson and N. Dahlb~ick, "Dis-course Representation and Discourse Managementfor Natural Language Interfaces", in Proceedings ofthe 2nd Nordic Conference on Text Comprehensionin Man and Machine, T~iby, Sweden.
1990.J.
Alexandersson and N. Reithinger, "Designingthe dialogue component in a speech translation sys-tem - a corpus-based approach", in Andernach et hi.(eds.)
1995.J.
Alexandersson, "Some ideas for the automaticacquisition of dialogue structure", in Luperfoy et al1996.J.
Alexandersson, N. Reithinger and E. Maier,"Insights into the Dialogue Processing of Verbmo-bil", in Proceedings of the Fifth Conference onApplied Natural Language Processing, ANLP '97,Washington, DC.
1997.E.
Atwell, "Comparative evaluation of grammati-cal annotation models", in: Sutcliffe et al 1996.G.
Churcher, E. Atwell, C. Souter, "DialogueManagement Systems: a survey and overview", Re-search Report 97.06, School of Computer Studies,Leeds University, 1997.M.
Boros, W. Eckert, F. Fallwitz, G. Hanrieder,G.
Goerz, H. Niemann, "Towards UnderstandingSpontaneous Speech: Word Accuracy vs. ConceptAccuracy", in Proceedings of the 4th InternationalConference on Spoken Language Processing (ICSLP-96), Philadelphia, 1996.H.
Dybkjeer, L. Dybkjeer, N. O. Bernsen, "De-sign, formalization and evaluation of spoke languagedialogue", in J.
A. Andernach, S. P. van de Burgtand G. F. van der Hoeven (eds), "Corpus-based Ap-proaches to Dialogue Modelling", Proceedings of the9th Twente Workshop on Language Technology ,University of Twente, Enschede, Netherlands.
1995.13W.
Eckert, T. Kuhn, N. Niemann, S. Rieck, A.Scheuer, E. G. Schukat-Talamazzini, "A Spoken Di-alogue System for German Intercity Train TimetableInquiries", in Proceedings of Eurospeech '93, BerlinW.
Eckert, "Understanding of Spontaneous Utter-ances in Human- Machine-Dialog", in Luperfoy et al1996.N.
Fraser, "Quality Standards for Spoken Dia-logue Systems: a report on progress in EAGLES",in Dalsgaard et al (1995), pp 157-160.
1995.N.
Fraser, "Messy data, what can we learn fromit?
", in Andernach et al (eds.)
1995.P.
tteisterkamp, "Ambiguity and uncertainty inspoken dialogue", in Proceedings of Eurospeech '93,Berlin, 1993.P.
IIeisterkamp and S. McGlashan, "Units of di-alogue management: an example", in Proceedingsof the 4th International Conference on Spoken Lan-guage Processing (ICSLP-96), Philadelphia, 1996.J.
Hulstijn, R. Steetskamp, If.
ter Doest, S. vande Burgt and A. Nijholt, "Topics in SCIIISMA Di-alogues", in Luperfoy et al 1996.I.
Ipsic, F. Mihelic, K. Pepelnjak, J. Gros, S. Do-brisek, N. Pavesic, E. Noth, "The Solvian DialogSystem for Air Flight Inquiries", in Proceedings ofthe 2nd SQEL Workshop on Multi-Lingual Informa-tion Retrieval Dialogs, Pilsen, 1997.A.
JSnsson, "Dialogue Actions for Natural Lan-guage Interfaces", in Proceedings of IJCAI-95,MontrEal, Canada, 1995.A.
JSnsson, "A Model for Dialogue Managementfor Human Computer Interaction", in Proceedingsof ISSD'96, Philadelphia, 1996.G.
N. Leech, R. Barnett, P. Kahrel, "EAGLESFinal Report and Guidelines for the Syntactic An-notation of Corpora", (EAGLES Document EAG-TCWG-SASG), Pisa.
Italy.
1995R.
Lopez-Cozr, P. Garcia, J. Diaz and A. J. Ru-bio, "A voice activated ialogue system for fast-foodrestaurant applications", Proceedings ofEurospeech'97, Rhodes.
(forthcoming)S. Luperfoy, A. Nijholt and G. Veldhuijzen vanZanten (eds.
), "Dialogue Management in NaturalLanguage Systems", Proceedings ofthe 11th TwenteWorkshop on Language Technology , University ofTwente, Enschede, Netherlands.
1996.E.
Maier, "Context construction as subtask of di-alogue processing - the VEKBMOBIL case", in Lu-perfoy et al 1996.P.
Nugues, C. Godereaux, P. El Guedj and F. Re-volta, "A conversational agent o navigate in virtualworlds", in Luperfoy et al 1996.K.
Pepelnjak, F. Mihelic, N. Pavesic, "SemanticDecomposition f Sentences in the System Support-ing Flight Services", in Journal of Computing andInformation Technology (CIT), Vol.
4, No.
1, Za-greb, 1996.P.
Regel-Brietzmann et al, "ACCESS - Auto-mated Call CEnter through Speech understandingSystem.
A description of an advanced application.Proceedings of Eurospeech '97, Rhodes.
(forthcom-ing)M. Schillo, "Working while Driving: Corpus basedlanguage modelling of a natural English Voice-UserInterface to the in-car Personal Assistant", MScThesis, School of Computer Studies, Leeds Univer-sity, 1996.M.
Schillo, E. Atwell, C. Souter, T. Denson, "Lan-guage modelling for the in-car personal assistant",in C. Moghrabi (ed), "Proceedings of NLP+IA'96:International Conference on Natural Language Pro-cessing and Industrial Applications", Universite deMoncton, Canada, 1996.R.
Sutcliffe, If.
D. Koch, and A. McElligott(editors), Industrial Parsing of Software Manuals,Rodopi.
1996L.
Taleb, "Communicative Deviation in FinalizedInformative Dialogue Management", in Luperfoy etal.
1996.A.
Vilnat, "Which processes to manage human-machine dialogue?
", in Luperfoy et al 1996.A.
Voutilainen, T. Jarvinen, "Using English Con-straint Grammar to Analyse a Software Manual Cor-pus", in Sutcliffe et al 1996.Append ix  1: Quest ionna i re  onFeatures  o f  Natura l  D ia logueBelow are listed 7 generic features of natural dia-logue.
Please state whether your system deals withthese features: insert your answer after the asteriskAlso, please RANK the features in order of impor-tance to your system: 1 - most important, 7 - least,entries can be tied.
Please insert your ranking in thesquare brackets \[\].P lease  name your  sys tem:  *Please give one or two References (publ ishedpapers,  URLs, tech reports)  to cite, givingfur ther  detai ls  o f  your  sys tem:  *Does your system deal with:Anaphora?
\[ \] YES / NO: *- Which types?
For example: Personal pronouns,relative xpressions... - If you have time, some briefexamples.14Ell ipsis?
\[ \] YES / NO: *- If you have time, some brief examples.Recovery  St ra tegy?
\[ \] Please comment :  *- What types of errors can the system detect and re-cover from?
Can the system identify and cope witherrors arising from speech recognition, domain am-biguity etc?
See example below for more.In teract ion  S t ra tegy?
\[ \] SYSTEM / USER/ M IXED IN IT IAT IVE  *- Does the DMS force the system to take the initia-tive all of the time by prompting the user for input,or must the user take the initiative all of the time(eg.
command and control applications)?
Or doesthe DMS allow the user and the system to take theinitiative when required, hence allowing mixed ini-tiative?Funct iona l  Perp lex i ty?
\[ \] P lease comment :- How many separate functions can the user get thesystem to perform in a dialogue?
A function is a taskor a general goal.
For example, a theatre booking/reservation system provides two functions which canbe performed in one dialogue: theatre booking andticket reservation.Language Perp lex i ty?
\[ \] P lease comment :  *- Does the system strictly constrain the user's lan-guage, perhaps by explicit prompting of what theuser can say?
Or is a user free to use any languagethey wish for the task, and the system will attemptto cope with it?Over - in format lveness?
\[ \]YES / NO *- Does the system cope with users' over-informativesentences?
If a user provides more information thanis strictly asked for, how does the system react?Any  Other  Comments :  *- - -  END OF QUESTIONNAIRE====== START OF EXAMPLE - - _An example:P lease name your  system:  *The In-car Personal AssistantPlease give one or two References (publ ishedpapers ,  URLs ,  tech reports )  to cite, g iv ingfu r ther  detai ls  of  your  system: *Michael Schillo, "Working while Driving: Corpusbased language modelling of a natural English Voice-User Interface to the in-car Personal Assistant",MSc Thesis, School of Computer Studies, Leeds Uni-versity, 1996.Michael Schillo, Eric Atwell, Clive Sourer, TonyDenson, "Language modelling for the in-car personalassistant", in Chadia Moghrabi (ed), "Proceedings ofNLP+IA '96: International Conference on NaturalLanguage Processing and Industrial Applications",Universite de Moncton, Canada, 1996.Does your  sys tem deal  with:Anaphora?
\[ 3 \] *YESCan cope with the following anaphora:- personal pronouns (eg.
'he', 'she', 'it' etc)- relative expressions (eg.
'next Tuesday', 'tomor-row ')- other types (eg.
'that' referring to a diary entry-d 'delete that entry')Ell ipsis?
\[ 3 \] *YESFor example, when using the diary the user can ask:User: When is my nezt appointment?The system responds with:System: Today at 2pro with Mr SmithThe user can then use ellipsis to ask:User: And tomorrow?Recovery  S t ra tegy?
\[ 1 \] P lease comment :  *System deals with two types of error occurring:.
errors relating to speech recognition (misrecogni-tion, speech ambiguity(eg.
~ohn' and 'tom' with sim-ilar confidence values), and low confidence in recog-nised speech leading to confirmation/clarification- conflicts arising between the domain model andthe user's request, for example, the user may askthe system: User: Delete the appointment with MrSmith when there is no such appointment.I n te ract ion  S t ra tegy?
\[ 2 \] *MIXEDIN IT IAT IVEThe user has the initiative until the system needsto elicit or clarify something.
For example, the usercan ask the system to call somebody, but if the personis misrecognised then the system takes the initiativeto elicit this.Funct iona l  Perp lex i ty?
\[ 2 \] P leasecomment :  *The system can perform any of 13 separate func-tions, including:Telephone:make a callDiary: add an appointment;retrieve an appointment;retrieve all appointments between certain times;15delete an appointment;etc.Language Perp lex i ty?
\[ 1 \] P lease comment :The user is free to ezpress his/herself as seen fit,since the user initially has the initiative and is notprompted what to say by the system.Over - in fo rmat iveness?
\[ 6 \] *YESThe user can give more information in a sentencethan is actually asked for.
For example, the follow-ing dialogue shows a user making an appointment,and providing information related to but inappropri-ate to the prompt:User: Make an appointment.System: Who do you want to make an appoint-ment with?User: Mr Smith at 2pm today.System: The appoi.ntment has been made.Any Other  Comments :  *NOTE that these answers are not for a real, imple-mented system, but for the DMS we assumed wouldunderly the simulation experiments.- - -  END OF EXAMPLE- - -16
