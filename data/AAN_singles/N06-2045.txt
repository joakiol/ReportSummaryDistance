Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 177?180,New York, June 2006. c?2006 Association for Computational LinguisticsLycos Retriever: An Information Fusion EngineBrian UlicnyVersatile Information Systems, Inc.5 Mountainview DriveFramingham, MA 01701 USAbulicny@vistology.comAbstractThis paper describes the Lycos Retrieversystem, a deployed system for automati-cally generating coherent topical summa-ries of popular web query topics.1 IntroductionLycos Retriever1 is something new on the Web: apatent-pending information fusion engine.
That is,unlike a search engine, rather than returning rankeddocuments links in response to a query, Lycos Re-triever categorizes and disambiguates topics, col-lects documents on the Web relevant to thedisambiguated sense of that topic, extracts para-graphs and images from these documents and ar-ranges these into a coherent summary report orbackground briefing on the topic at something likethe level of the first draft of a Wikipedia2 article.These topical pages are then arranged into abrowsable hierarchy that allows users to find re-lated topics by browsing as well as searching.2 MotivationsThe presentation of search results as ranked lists ofdocument links has become so ingrained that it ishard now to imagine alternatives to it.
Other inter-faces, such as graphical maps or visualizations,have not been widely adopted.
Question-answeringinterfaces on the Web have not had a high adoption1 http://www.lycos.com/retriever.html.
Work on Retrieverwas done while author was employed at Lycos.2 http://www.wikipedia.orgrate, either: it is hard to get users to venture beyondthe 2.5 word queries they are accustomed to, and ifquestion-answering results are not reliably betterthan keyword search, users quickly return to key-word queries.
Many user queries specify nothingmore than a topic anyway.But why treat common queries exactly likeunique queries?
For common queries we knowthat incentives for ranking highly have led to tech-niques for artificially inflating a site?s ranking atthe expense of useful information.
So the user hasmany useless results to sift through.
Furthermore,users are responsive to filtered information, as theupsurge in popularity of Wikipedia and An-swers.com demonstrate.Retriever responds to these motivations byautomatically generating a narrative summary thatanswers, ?What do I need to know about thistopic??
for the most popular topics on the Web.33 Lycos Retriever pagesFigure 1 shows a sample Retriever page for thetopic ?Mario Lemieux?.4   The topic is indicated atthe upper left.
Below it is a category assigned tothe topic, in this case Sports > Hockey > IceHockey > National Hockey League > Lemieux,Mario.
The main body of the page is a set of para-graphs beginning with a biographical paragraphcomplete with Lemieux?s birth date, height, weightand position extracted from Nationmaster.com,followed by paragraphs outlining his career from3 See (Liu, 2003) for a similarly motivated system.4 For other categories, see e.g.
King Kong (1933):http://www.lycos.com/info/king-kong-1933.html,Zoloft: http://www.lycos.com/info/zoloft.html,Public-Key Cryptography: http://www.lycos.com/info/public-key-cryptography.html ,Lyme Disease: http://www.lycos.com/info/lyme-disease.html,Reggaeton: http://www.lycos.com/info/reggaeton.html177other sources.
The source for each extract is indi-cated in shortened form in the left margin of thepage; mousing over the shortened URL reveals thefull title and URL.
Associated images are thumb-nailed alongside the extracted paragraphs.Running down the right side of the page underMore About is a set of subtopics.
Each subtopic isa link to a page (or pages) with paragraphs aboutthe topic (Lemieux) with respect to such subtopicsas Games, Seasons, Pittsburgh Penguins, WayneGretzky, and others, including the unpromisingsubtopic ice.4 Topic SelectionAn initial run of about 60K topics was initiated inDecember, 2005; this run yielded approximately30K Retriever topic pages, each of which can havemultiple display pages.
Retriever topics that hadfewer than three paragraphs or which were catego-rized as pornographic were automatically deleted.The biggest source of topic candidates was Lycos?sown query logs.
A diverse set of topics was chosenin order to see which types of topics generated thebest Retriever pages.5 Topic Categorization & DisambiguationAfter a topic was input to the system, the Retrieversystem assigned it a category using a na?ve Bayesclassifier built on a spidered DMOZ5 hierarchy.Various heuristics were implemented to make thereturned set of categories uniform in length anddepth, up-to-date, and readable.Once the categorizer assigned a set of cate-gories to a topic, a disambiguator module deter-mined whether the assigned categories could beassigned to a single thing using a set of disambigu-ating features learned from the DMOZ data itself.For example, for the topic ?Saturn?, the assignedcategories included ?Science/Astronomy?, ?Recrea-tion/Autos?
and ?Computers/Video Games?
(SegaSaturn).
The disambiguator detected the presenceof feature pairs in these that indicated more thanone topic.
Therefore, it clustered the assignedcategories into groups for the car-, astronomy- andvideo-game-senses of the topic and assigned eachgroup a discriminative term which was used to dis-ambiguate the topic: Saturn (Auto), Saturn (SolarSystem), Saturn (Video Game).
Retriever returnedpages only for topics that were believed to be dis-ambiguated according to DMOZ.
If no categories5 http://www.dmoz.comFigure 1 Retriever Topic Page "Mario Lemieux"178were identified via DMOZ, a default Other cate-gory was assigned unless the system guessed thatthe topic was a personal name, based on its com-ponents.The live system assigns non-default categorieswith 86.5% precision; a revised algorithm achieved93.0% precision, both based on an evaluation of982 topics.
However, our precision on identifyingunambiguous topics with DMOZ was only 83%.Still, this compares well with the 75% precisionachieved on by the best-performing system on asimilar task in the 2005 KDD Cup (Shen 2005).6 Document RetrievalAfter a topic was categorized and disambiguated,the disambiguated topic was used to identify up to1000 documents from Lycos?
search provider.
Forambiguous topics various terms were added as op-tional ?boost?
terms, while terms from other sensesof the ambiguous topic categories were prohibited.Other query optimization techniques were used toget the most focused document set, with non-English and obscene pages filtered out7 Passage ExtractionEach URL for the topic was then fetched.
AnHTML parser converted the document into a se-quence of contiguous text blocks.
At this point,contiguous text passages were identified as beingpotentially interesting if they contained an expres-sion of the topic in the first sentence.When a passage was identified as beingpotentially interesting, it was then fully parsed tosee if an expression denoting the topic was theDiscourse Topic of the passage.
Discourse Topicis an under-theorized notion in linguistic theory:not all linguists agree that the notion of DiscourseTopic is required in discourse analysis at all (cf.Asher, 2004).
For our purposes, however, we for-mulated a set of patterns for identifying DiscourseTopics on the basis of the output of the CMU LinkParser6 the system uses.Paradigmatically, we counted ordinarysubjects of the first sentence of a passage as ex-pressive of the Discourse Topic.
So, if we foundan expression of the topic there, either in full orreduced form, we took that as an instance of thetopic appearing as Discourse Topic in that passage6 http://www.link.cs.cmu.edu/link/and ranked that passage highly.
Of course, not allDiscourse Topics are expressed as subjects, and thesystem recognized this.A crucial aspect of this functionality is toidentify how different sorts of topics can be ex-pressed in a sentence.
To give a simple illustra-tion, if the system believes that a topic has beencategorized as a personal name, then it acceptedreduced forms of the name as expressions of thetopic (e.g.
?Lindsay?
and ?Lohan?
can both be ex-pressions of the topic ?Lindsay Lohan?
in certaincontexts); but it does not accept reduced forms inall cases.Paragraphs were verified to contain a se-quence of sentences by parsing the rest of the con-tiguous text.
The verb associated with theDiscourse Topic of the paragraph was recorded forfuture use in assembling the topic report.
Variousfilters for length, keyword density, exophoric ex-pressions, spam and obscenity were employed.
Ascore of the intrinsic informativeness of the para-graph was then assigned, making use of such met-rics as the length of the paragraph, the number ofunique NPs, the type of verb associated with theDiscourse Topic, and other factors.Images were thumbnailed and associated withthe extracted paragraph on the basis of matchingtext in the image filename, alt-text or descriptionelements of the tag as well as the size and prox-imity of the image to the paragraph at hand.
Wedid not analyze the image itself.8 Subtopic Selection and Report AssemblyOnce the system had an array of extracted para-graphs, ranked by their intrinsic properties, we be-gan constructing the topic report by populating aninitial ?overview?
portion of the report with someof the best-scoring paragraphs overall.First, Retriever eliminated duplicate andnear-duplicate paragraphs using a spread-activationalgorithm.Next the system applied question-answering methodology to order the remainingparagraphs into a useful overview of the topic:first, we found the best two paragraphs that saywhat the topic is, by finding the best paragraphswhere the topic is the Discourse Topic of the para-graph and the associated verb is a copula or cop-ula-like (e.g.
be known as).
Then, in a similar way,we found the best few paragraphs that said what179attributes the topic has.
Then, a few paragraphsthat said what the topic does, followed by a fewparagraphs that said what happens to the topic(how it is used, things it has undergone, and so on).The remaining paragraphs were then clus-tered into subtopics by looking at the most frequentNPs they contain, with two exceptions.
First, su-perstrings of the topic were favored as subtopics inorder to discover complex nominals in which thetopic appears.
Secondly, non-reduced forms ofpersonal names were required as subtopics, even ifa reduced form was more frequent.Similar heuristics were used to order para-graphs within the subtopic sections of the topicreport as in the overview section.Additional constraints were applied to staywithin the boundaries of fair use of potentiallycopyrighted material, limiting the amount of con-tiguous text from any one source.Topic reports were set to be refreshed by thesystem five days after they were generated in orderto reflect any new developments.In an evaluation of 642 paragraphs, 88.8% wererelevant to the topic; 83.4% relevant to the topic ascategorized.
For images, 85.5% of 83 images wererelevant, using a revised algorithm, not the livesystem.
Of 1861 subtopic paragraphs, 88.5% ofparagraphs were relevant to the assigned topic andsubtopic.9 DiscussionOf the over 30K topical reports generated by Re-triever thus far, some of the reports generatedturned out surprisingly well, while many turned outpoorly.
In general, since we paid no attention totemporal ordering of paragraphs, topics that werehighly temporal did poorly, since we would typi-cally arrange paragraphs with no regard for eventprecedence.There are many things that remained to bedone with Retriever, including extracting para-graphs from non-HTML documents, auto-hyperlinking topics within Retriever pages (as inWikipedia), finding more up-to-date sources forcategorization, and verticalizing Retriever pagegeneration for different types of topics (e.g.
treat-ing movies differently than people and both differ-ently than diseases).
Unfortunately, the projectwas essentially discontinued in February, 2006.10 Related WorkAlthough there have been previous systems thatlearned to identify and summarize web documentson a particular topic (Allen et al 1996) withoutattempting to fuse them into a narrative structure,we are not aware of any project that attempts togenerate coherent, narrative topical summaries byparagraph extraction and ordering.
Much recentwork focuses on multi-article summarization ofnews by sentence extraction and ordering (see forexample, Columbia?s well-known Newsblasterproject and Michigan?s NewsInEssence project).The latest DUC competition similarly emphasizedsentence-level fusion of multi-document summa-ries from news text (DUC, 2005).
One exception isthe ArteQuaKt project (Kim et al 2002), a proto-type system for generating artist biographies fromextracted passages and facts found on the Webaimed at different levels of readers (e.g.
gradeschool versus university students).
The Artequaktsystem was to use extracted text both as found andas generated from facts in a logical representation.It is not clear how far the ArteQuaKt project pro-gressed.Less legitimately, more and more ?spamblogs?
repackage snippets from search results or inother ways appropriate text from original sourcesinto pages they populate with pay-per-click adver-tising.
Retriever differs from such schemes in fil-tering out low value content and by makingobscure sources visible.ReferencesAllen, Brad et al 1996.
WebCompass: an agent-based meta-search and metadata discovery tool for the Web.
SIGIR ?96.Asher,Nicholas.
2004.
Discourse Topic, Theoretical Linguis-tics.
30:2-3DUC.
2005  DUC Workshop.
Vancouver, BCKim, Sanghee et al 2002.
Artequakt: Generating Talored Bi-ographies from Automatically Annotated Fragments fromthe Web.
In Proceedings of Workshop on Semantic Author-ing, Annotation & Knowledge Markup (SAAKM?02).pp.
1-6, Lyon, France.Liu, Bing, et al 2003.
Mining Topic-Specific Concepts andDefinitions on the Web.
Proceedings of the Twelfth Inter-national World Wide Web Conference (WWW-2003),Shen, Dou et al Q2C@UST: Our Winning Solution to QueryClassification in KDDCUP 2005.
ACM KDD Explora-tions.
Vol 7, no.
2.
December 2005.180
