Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 1601?1611, Dublin, Ireland, August 23-29 2014.Word Sense Induction Using Lexical Chain based Hypergraph ModelTao Qian1,3, Donghong Ji*1, Mingyao Zhang2, Chong Teng1, and Congling Xia1(1) Computer School, Wuhan University, Wuhan, China?2?College of Foreign Languages and Literature, Wuhan University, Wuhan, China(3) College of Computer Science and Technology, Hubei University ofScience and Technology,XianNing, China{taoqian, dhji, myzhang, tengchong, clxia}@whu.edu.cnAbstractWord Sense Induction is a task of automatically finding word senses from large scale texts.
It is general-ly considered as an unsupervised clustering problem.
This paper introduces a hypergraph model inwhich nodes represent instances of contexts where a target word occurs and hyperedges represent high-er-order semantic relatedness among instances.
A lexical chain based method is used for discovering thehyperedges, and hypergraph clustering methods are used for finding word senses among the context in-stances.
Experiments show that this model outperforms other methods in supervised evaluation andachieves comparable performance with other methods in unsupervised evaluation.1 IntroductionWord sense induction (WSI) aims to automatically find senses of a given target word (Yarowsky,1995) from large scale texts.
Compared with existing manual word sense resources, WSI techniquesuse clustering algorithms to determine the possible senses for a word.Word sense induction is generally considered as an unsupervised clustering problem.
The input forthe clustering algorithm is context instances of a target word, represented by word bags or co-occurrence vectors, and the output is a grouping of these instances into classes, each corresponding toan induced sense.Traditional methods in WSI tend to adopt the vector space model, in which the context of each in-stance of a target word is represented as a vector of features based on frequency statistics and proba-bility distributions, e.g., first-order or second-order vector (Sch?tze, 1998; Purandare and Pedersen,2004; Cruys et al., 2011).
These vectors are clustered and the resulting clusters represent the inducedsenses.
Another family of employed approach is graph-based methods (Widdows and Dorow, 2002;V?ronis, 2004; Agirre et al., 2006; Klapaftis and Manandhar, 2007; Di Marco and Navigli, 2011; Hopeand Keller, 2013), which have been recently explored successfully to some extent.
Graph-based me-thods are considering the notion of a co-occurrence graph, assuming a binary relatedness between co-occurring words.One of the key challenges in WSI is learning the higher-order semantic relatedness among multiplecontext instances.
Previous approaches (Klapaftis and Manandhar.
2007; Bordag, 2006) for WSI areused to construct higher-order relatedness by counting co-occurrence frequency or collocation of muti-words, regardless of global semantic similarity.Lexical chain (Morris and Hirst, 1991) is defined as a sequence of semantically related words in textand provides important clues about the text structure and topic.
It can be viewed as a global counter-part of the measures of semantic similarity (Navigli, 2009).
For example, Figure 1 gives three contextinstances containing Apple.
* Corresponding author E-mail: dhji@whu.edu.cn.This work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings foo-ter are added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/1601Figure 1.
Context instances of AppleObviously, four Apples in Figure 1 all refer to the Apple Company.
We can directly group three in-stances by the lexical chain: iPod-iTunes-hardware and software product-Inc.
This lexical chainrepresents a higher-order semantic relatedness among the three instances.In this paper, we propose a hypergraph model from a global perspective, in which nodes representinstances of contexts where a target word occurs and hyperedges denote higher-order semantic rela-tedness among instances.
A lexical chain based method is used for identifying the hyperedges.
Thismethod for lexical chain extraction is a knowledge-free method based on LDA topic model (Remusand Biemann, 2013).The remainder of this paper is structured as follows.
Section 2 presents an overview of the relatedwork.
Section 3 describes our model in details.
Section 4 provides a quantitative evaluation and com-parison with other algorithms in the SemEval-2013 word sense induction task.
Finally, section 5 drawsconclusions and lays out some future research directions.2 Related Work2.1 Word sense inductionA number of diverse approaches to WSI have been proposed so far.
Context features are oftenrepresented in a variety of forms such as co-occurrence of words within phrases (Pantel and Lin, 2002;Dorow and Widdows, 2003), parts of speeches (Purandare and Pedersen, 2004), and grammatical rela-tions (Pantel and Lin, 2002; Dorow and Widdows, 2003).
The size of the context window also varies,such as two words before and after the target word, the sentence or even larger paragraph within whichcontains the target word.Most of the work in WSI is the vector space model, such as context-based vector algorithm(Sch?tze, 1998; Ide et al., 2001; Van de Cruys et al., 2011), substitute-based vector algorithm (Yatbazet al., 2012; Baskaya et al., 2013).
In this model, the context of each instance of a target word isrepresented as a vector of features based on frequency statistics or probability distributions (e.g., first-order or second-order vector).
These vectors are clustered by various algorithms and the resulting clus-ters represent the induced senses.Another family of employed approach is graph-based methods, which have been successfully ap-plied in the sense induction task with some better results achieved.
In this framework words arerepresented as nodes in the graph and vertices are drawn between the target word and its co-occurrences.
The co-occurrences between words can be obtained on the basis of grammatical (Wid-dows and Dorow, 2002) or collocational relations (V?ronis, 2004).
Senses are induced by identifyinghighly dense sub-graphs (hubs) in the co-occurrence graph.Klapaftis (2007) uses hypergraph model for WSI, in which co-occurrences of two or more wordsare represented by using weighted hyperedges.
This model fully exploits the existence of collocationsor terms consisting of more than two words.
In fact, the method converts the sense induction problemto the clustering of the contextual words, and the result relies on local word co-occurrence frequency.Our hypergraph model is constructed from a global perspective, where the whole context instance isregarded as a node.WSI evaluation also is an important issue in WSI tasks.
Previous WSI evaluations in SemEval(Agirre and Soroa, 2007; Manandhar et al., 2010) have approached sense induction in terms of findingthe single most salient sense of a target word given its context.
However, as shown in Erk and McCar-thy (2009), multiple senses of the target word may be perceived by readers from different angles and agraded notion of sense labeling may be considered as the most appropriate.
The SemEval-2013 WSIevaluation is designed to explore the possibility of finding all perceived senses of a target word in asingle context instance.
Our model is evaluated and verified on the SemEval-2013 WSI task.16022.2 Lexical chain extractionThe Lexical chain method is an important technique in natural language processing.
A lexical chain isa sequence of semantic related words in text and provides important clues about the text structure andtopic.
It has formed a theoretically well-founded building block in a lot of applications, such as wordsense disambiguation (Manabu and Takeo, 1994), malapropism detection and correction (Hirst and St-Onge, 1998), summarization (Barzilay et al., 1997), topic tracking (Carthy, 2004), text segmentation(Stokes et al., 2004), and others.There are mainly two approaches for lexical chain extraction.
One focuses on the use of knowledgeresources like WordNet (Hirst and St-Onge, 1998) or thesauri (Morris and Hirst, 1991) as backgroundinformation in order to quantify semantic relations between words.
A major disadvantage of this strat-egy is that it relies on the resource, which has a direct impact on the quality of lexical chains.
Anotherapproach is based on statistical methods (Remus and Biemann, 2013).
In this paper, we follow Remusand Biemann (2013) to automatically extract lexical chain by using LDA topic model.3  Hypergraph modelIn general, lexical chain based hypergraph model contains the following steps:i) Automatically extracting lexical chains based on topic model;ii) Constructing hypergraph with lexical chains;iii) Inducing word sense by hypergraph clustering.3.1 Lexical chain extractionThe extraction technique of lexical chains is based on LDA topic model.
LDA topic model (Blei et al.,2003) is a probabilistic model of text generation designed for revealing some hidden structure in largedata collections.
The key idea is that each document can be represented as a probability distributionover a fixed set of topics where each topic can be represented as a probability distribution over words.We use LDA topic model for estimating the semantic closeness of lexical terms, and explore a way ofutilizing LDA?s topic information in constructing lexical chains automatically.
In our model, docu-ment is replaced with context instance of a target word.We adopt the idea of interpreting lexical chains as topics and placing all word tokens that share thesame topic into the same chain.
Lexical chains are usually extracted from the same paragraph or text,whose topic distributions are identical.
However, in our experiment the context instances of a targetword for WSI are derived from different articles, whose topic distributions are varied.
Therefore bothlexical and contextual topics are modeled.
After training the LDA model, we use the information ofthe per-document topic distribution ?d= p(z|d), the per-topic word distribution?w=p(w|z) and thesampling topic of a word zw.The key work lies in how to assign a word to a topic in training LDA model.
Since single samplesof topics per word may exhibit a large variance (Riedl and Biemann, 2012), we sample several timesand use the mode (most frequently assigned) topic ID per word as the topic assignment.Algorithm 1. lexical chains extraction algorithmInput: training set D of target word, hyper-parameters of LDA model;  semantic threshold ?.Output: lexical chain set S1  ?,?,Z          LDA (D)2  for each topic z3     lc =""                 //  lc denotes a lexical chain4     for each doc d5         for each word w in doc d6             if ( zw = z  and p(w,d|z) > ?
)7                lc.add (w)8   S.add (lc)9   return S1603The extraction algorithm is shown in algorithm 1.
In order to improve the quality of identified lexi-cal chains, a threshold ?
is set to filter those invalid words whose generating probability of samplingtopics in the document is lower than ?.
( , | ) ( | ) ( | )p w d z p z d p w z ??
>                 (1) The threshold ?
is essential for the quality of lexical chains, which directly impacts on the performanceof the model.
Detailed analysis for the threshold ?
will be given in section 4.5.3.2 Hypergraph creationA hypergraph H = (V, E) is a generalization of a graph whose edge can connect more than two vertices.Just as graphs represent many kinds of information in mathematical and computer science problems,hypergraphs also arise in important practical problems, including circuit layout, boolean satisfiability,numerical linear algebra, complex network and article co-citation, etc.Figure 2 shows an example of hypergraph creation in our model.
We represent each context in-stance as a vertex and connect those context instances with a lexical chain across them by a hyperedge.A hyperedge weight equals to the weight of the corresponding lexical chain, defined as follows:( | d ) (w | )( ) (2)| |ii iw Cp z p zw e C?=?where lexical chain C corresponds to hyperedge e, |C| is the number of words in C, and z is the sam-pling topic of C.3.3 Hypergraph clusteringFor hypergraph clustering, the hypergraph is usually transformed into induced graph.
There are twotransformation strategies: one is vertex expansions (2006; Zhou et al., 2006), i.e., clique expansion orstar expansion, in which a hyperedge is transformed into a clique; the other is called hyperedge expan-sion (Pu and Faltings, 2012) based on a network flow technique, in which hyperedges are projectedback to vertices through the adjacency information between hyperedges and vertices.Hypergraph clustering algorithm can be divided into two classes: one is based on minimal norma-lized cut, and the other is based on maximal density.
We use three general hypergraph clustering algo-rithms to identify the context instance clusters.
The three algorithms are simply shown in figure 3 anddescribed as the follows.1) Normalized Hypergraph Cut (NHC)1604The NHC algorithm (Zhou et al., 2006) is a typical approach based on vertex expansion.
The objec-tive is to obtain a partition in which the connection among the vertices in the same cluster is densewhile the connection between two clusters is sparse.
The main steps include transforming the hyper-graph into an induced graph first, and then adopting the normalized Laplacian to spectral partitioning.2) Hyperedge Expansion Clustering (HEC)Some works (e.g., Shashua et al., 2006; Bulo and Pelillo, 2012) have shown that the pairwise affini-ty relations after the projection to the induced graph would introduce information loss, and workingdirectly on the hypergraph could produce better performance.The hyperedge expansion works as follows.
It constructs a directed graph G = (V, E) that includestwo vertices e+ and e- for each hyperedge e in the original hypergraph.
Note that the vertices in G cor-respond to the hyperedges, but not the vertices in the original hypergraph.
A directed edge is placedfrom e+ to e- with weight w(e) where w is the weighting function in the hypergraph.
For every pair ofoverlapping hyperedges e1 and e2, two directed edges 1 2(e ,e )?
+  and 2 1(e ,e )?
+  are added to G with weightsw(e2) and w(e1).
After hypergraph expansion, it adopts spectral method for clustering.3) SchypeThe Schype (Michoel and Nachtergaele, 2012) is a maximal density cluster algorithm.
According tothe generalization of the Perron-Frobenius theorem, there exists a unique, positive vector, called thedominant eigenvector, over the set of vertices of the hypergraph, which produces a maximal densitysub-graph with linear time.
The procedure is as follow:i) Finding maximal density sub-graph by computing the dominant eigenvector.ii) Removing all vertices and hyperedges of the sub-graph from hypergraph.iii) Repeating above steps until no vertex in hypergraph occurs.This algorithm tends to generate many fine-grained clusters.
We follow Tan and Kumar (2006) tomerge clusters using two measures: cohesion and separation.
The cohesion of a cluster Ci is defined as:,#( | , )(C ) | C |i ix C y Ciie x y ecohesion ?
??=?
(3)where #( | , )e x y e?
is the number of hyperedges containing nodes x and y in C and |Ci| is the number ofvertices in Ci.
Separation between two clusters Ci, Cj is defined as:,#( | , )(C ,C ) 1 ( )| C | | C |i jx C y Ci ji je x y eseparation ?
?
?= ???
(4)1605We merge cluster pairs with high cohesion and low separation.
The intuition is that context in-stances in such pairs will maintain a relatively high degree of semantic similarity.
High cohesion isdefined as greater than average cohesion of all clusters.
Low separation is defined as a reciprocal rela-tionship between two clusters: if a cluster Ci has the lowest separations to a cluster Cj and Cj has thelowest separation to Ci, then the two (high cohesion) clusters are merged.
This merging process is ite-rated until it converges.4 Experiment and Evaluation4.1 DatasetOur WSI evaluation is based on the dataset provided by the SemEval-2013 shared 13th task.
Test datawas drawn from the Open American National Corpus (OANC) (Ide and Suderman, 2004) across a va-riety of genres and from both the spoken and written portions of the corpus.
It consists of 4,806 in-stances of 50 target words: 20 verbs, 20 nouns and 10 adjectives.
Due to the unsupervised nature of thetask, participants were not provided with sense-labeled training data.
However, WSI systems wereprovided with the ukWac corpus (Baroni et al., 2009) to use in inducing senses.
Additionally, we usedthe SemEval-2013 lexical trial data sets as development sets to tune parameters.4.2 Implementation detailsThe training data is extracted from uKWac corpus.
For each target word, we extracted 10K contextinstances, and each instance is a sentence window containing the target word.
Additionally, we ran-domly selected 10K sentences as common auxiliary corpus, including none of the target word.
Thetraining data are tagged with POS tags and lemmatized with TreeTagger (Schmid, 1994).
Removingstop words, nouns are taken as features.
Meanwhile, we also removed words that co-occur with thetarget of word less than 50 times over the whole ukWac data.The training data in the model contains 20K instances: 10K instances of target word, 10K auxiliaryinstances.
Specifically, we used the JGibbLDA1 framework for topic model estimation and inference,and examined the following LDA parameters: number of topics K, dirichlet hyperparameters for doc-ument-topic distribution ?
and topic-term distribution ?.
We tested combinations in the rangesK=1000?1500?2000,  ?=5/K..50/K and ?=0.001..0.1.
The highest performance of the WSI systemwas found for K = 2000, ?
=0.025, ?
= 0.001.
Similar to tuning the dirichlet hyperparameters of LDA,the best parameter ?
in lexical chain extraction is 0.0001 in the ranges ?
=0.01.. 0.000001.We adopt the three clustering algorithms to cluster hypergraph2.
The number of clusters is set as 10for NHC and HEC, while Schype algorithm generates the number of the clusters (but requiring theedge-vertex ratio to be pre-defined), whose average number of senses is 31.8 after clusters are merged.Additionally, For Schype algorithm, we used the default values of parameters, except that the ?min-clustscore?
parameter, a minimal score to output a cluster, being tuned to 0.1.The sense inventory acquired from the induction step can be used for disambiguation of individualinstances.
Each sense is represented as a vector, whose element is a word and the value of element isco-occurrence frequency with target word in the training set.
Each test instance is also represented as avector.
The similarity between the instance and the induced sense is computed by using cosine func-tion.
For each test instance, it is compared with each sense separately, and finally the sense is selectedif the cosine value is greater than a certain threshold ?.
In experiment, ?
is 0.04 for NHC and HEC,and is 0.1 for schype.4.3 Evaluation measuresEvaluation in the SemEval-2013 WSI task can be divided into two categories:1.
A traditional WSD task for unsupervised WSD and WSI systems,2.
A clustering comparison setting that evaluates the similarity of the sense inventories for WSI sys-tems.1 http://sourceforge.net/projects/jgibblda/2  The Hypergraph Analysis Toolbox (HAT) for NHC and HEC: http://lia.epfl.ch/index.php/research/relational-learningand the Schype?s code: http://www.roslin.ed.ac.uk/tom-michoel/software/1606In the first evaluation, we adopt a WSD task with three objectives: (1) detecting which senses areapplicable, (2) ranking senses by their applicability, and (3) measuring agreement in applicability rat-ings with human annotators.
Each objective uses a specific measurement:i):  Jaccard Index: given two sets of sense labels for an instance, X and Y, the Jaccard Index is usedto measure the agreement: X YX Y??.
The Jaccard Index is maximized when X and Y use identical labels,and is minimized when the sets of sense labels are disjoint.ii):  Positionally-weighted Kendall?s ?
similarity: for graded sense evaluation, we consider an rank-ing scoring based on Kumar and Vassilvitskii(2010), which weights the penalty of reordering the low-er positions less than the penalty of reordering the first ranks.iii):  Weighted Normalized Discounted Cumulative Gain (WNDCG): NDCG (Moffat and Zobel,2008) normally compares the rankings of two lists.
It is extended to weighting the DCG by consider-ing the relative difference in the two weights.Because the induced senses will likely vary in number and nature between systems, the WSD evalu-ation has to incorporate a sense alignment step, in which it performs by splitting the test in-stances intotwo sets: a mapping set and an evaluation set.
The optimal mapping from induced senses to gold-standard senses is learned from the mapping set, and the sense alignment is used to map the predic-tions of the WSI system to pre-defined senses for the evaluation set.
The particular split we use to cal-culate WSD effectiveness in this paper is 80%/20% (mapping/test), averaged across 5 random splits.In the clustering evaluation, similarity between participant?s clusters and the gold standard clustersis measured by way of two metrics.i): Fuzzy Normalised Mutual information (NMI): it extends the method of (Lancichinetti et al., 2009)to compute NMI between overlapping clusters.
Fuzzy NMI captures the alignment of the two clustersindependent of the cluster sizes and therefore serves as an effective measure of the ability of an ap-proach to accurately model rare senses.ii): Fuzzy B-Cubed: it adapts the overlapping B-Cubed measured defined in Amigo et al.
(2009) tothe fuzzy clustering setting, and provides an item-based evaluation that is sensitive to the cluster sizeskew and effectively captures the expected performance of the system on a dataset where the clusterdistribution would be equivalent.4.4 ResultsWe compared our models with four baselines and three benchmark systems from the SemEval-2013task.
Four baselines are described as follows.?
Baseline MFS ?
most frequent sense baseline, assigning all test instances to the MFS in thetest data (regardless of what applicability rating it was given).?
One sense ?
labels each instance with the same induced sense.?
One sense per instance (1clinst) ?
labels each instance with its own induced.?
Baseline Random-n ?
randomly assigns each test instance to one of n randomly selected in-duced senses, where n is the number of senses for the target word in WordNet 3.1.Three benchmark systems as the following are those which achieved better results in the originalSemEval-2013 task.?
AI-KU is based on a lexical substitution method.?
UoS uses dependency-parsed features from the corpus, which are then clustered into senses us-ing the MaxMax algorithm (Hope and Keller, 2013).?
Unimelb is a non-parameter topic model which uses a Hierarchical Dirichlet Process (Teh et al.,2006) to automatically infer the number of senses from contextual and positional features.4.4.1 Supervised evaluationIn the supervised evaluation, the automatically induced clusters are mapped to gold standard senses,using one part of the test set.
The obtained mapping is used to label the other part of test set with goldstandard tags, which means that the methods are evaluated in a standard WSD task.
In experiment, wefollow the 80/20 setup: 80% for mapping and 20% for test.Table 1 shows the results of our systems on test data using all instances (including verbs, nouns andadjectives) for the WSD evaluation.
As in previous WSD tasks, the MFS baseline on Jaccard Indexmeasures is quite competitive, outperforming all systems in detecting which senses are applicable.1607System JI-F1 WKT-F1WNDCG-F1NHC 0.325 0.692 0.375HEC 0.327 0.693 0.376Schype 0.376 0.753 0.345AI-KU  0.244 0.642 0.332UNIMELB 0.213 0.62 0.371UoS 0.232 0.625 0.374MFS 0.455 0.465 0.339One sense 0.192 0.609 0.2881c1inst 0.0 0.095 0.0Random-n 0.29 0.638 0.286Table 1.
The supervised results over the SemEv-al-2013 dataset.System FNMI FBCNHC 0.046  0.406HEC 0.037  0.400Schype 0.042  0.377AI-KU 0.039 0.451UNIMELB 0.056 0.459UoS 0.045 0.448MFS - -One sense 0 0.6321c1inst 0.071 0Random-n 0.016 0.245Table 2.
The unsupervised results over the Se-mEval-2013 dataset.However, most systems in this task were able to outperform the MFS baseline in ranking senses andquantifying their applicability.On the other hand, it also indicates that our three systems achieve better or comparable scores Andthe Schype gets the highest scores in detecting senses and ranking senses over all systems.4.4.2 Unsupervised evaluationUnsupervised evaluation aims to measure the similarity of the induced sense inventories for WSI sys-tems.
Unlike supervised metrics, it avoids potential loss of sense information since this setting doesnot require any sense mapping procedure to convert induced senses to WordNet senses.Table 2 shows the performance of our systems, benchmarks and baselines.
It shows that the NMI-measure is biased towards the one sense per instance baseline and the FBC-measure one sense base-line.
However, systems are capable of performing well in both the Fuzzy NMI and Fuzzy B-Cubedmeasures, thereby avoiding the extreme performance of either baseline.
Generally, the performance ofour model gets balanced scores.4.5 DiscussionTopic models, such as LDA and HDP (Brody and Lapata, 2009; Lau et al., 2012), have been success-fully adopted for WSI, in which one topic is viewed as one sense.
Our work is motivated by lexicalchain that represents the intrinsic semantic relatedness among context instances on the viewpoint oflinguistics.
Topic model is used to find lexical chains which are interpreted as topics.
We have com-pared the Unimelb (Lau et al., 2013), a HDP topic model, with our model in the experiments.
Addi-tionally, we also follow Lau et al.
(2012) to train a LDA model with a fixed number of topics based onour training data for WSI3.
Table 3 shows the supervised result compared to the Schype.These experiments show promising performance for our model, which captures richer semantic re-latedness by using lexical chains.
Lexical chains play a key role for the performance of our model.Intuitively, when lexical chains are too long, the higher-order relatedness would be mixed with somenoises, while when lexical chains are too short, some higher-order relatedness will be missed.
In orderto verify the effectiveness of lexical chains, we tune the parameter ?
in lexical chain extraction proce-dure and the results are shown in Figure 4.Another issue is the impact of POS labels of word for WSI task.
The test data in SemeVal-2013WSI task contain nouns, verbs and adjectives.
We also test the performance based on different POSlabels.
Table 4 gives the supervised evaluation performance of our three systems on adjectives, verbsand nouns respectively.
We found that the performance for adjectives in sense detection is the best,verbs followed and nouns worst, whereas it?s reversed in sense ranking.
The probable interpretation is3 The LDA model parameters are set as follows: K=10, ?
=0.025, ?
= 0.001.1608Figure 4.
Performance analysis on Jaccard indexmeasure for different threshold parameter ?
inlexical chains extraction procedure.Type LDAK=10 SchypeJI-F1 0.318 0.376WKT-F1 0.692 0.753WNDCG-F1 0.334 0.345Table 3.
The supervised results over the SemEv-al-2013 dataset between LDAk=10 and Schype forWSI.NHC HEC SchypePOS JI WKT WNDCG JI WKT WNDCG JI WKT WNDCGnouns 0.306  0.697  0.370  0.313 0.702 0.367  0.363 0.767  0.246verbs 0.336  0.686  0.374  0.336 0.690 0.380  0.384 0.749  0.245adjs 0.347  0.697  0.396  0.342 0.678 0.390  0.394 0.733  0.248Table 4.
The supervised performance of three algorithms respectively on nouns, verbs and adjectives.that adjective?s average sense number is the lowest, and the sense granularity is greater than verbs andnouns over the test data4.5 Conclusions and future workIn this paper, we present a hypergraph model in which a node represents an instance and a hyperedgerepresents higher-order semantic relatedness among instances.
Compared with other strategies basedon binary local comparison, the model captures complex semantic relatedness among the instancesfrom a global perspective.The evaluation results indicate that our model outperforms or reaches competitive performancecomparable to other systems for the SemEval-2013 word sense induction task.
Additionally, the expe-riments also show that both sense number and sense granularity of a target word affect the perfor-mance of WSI.For future work, we would like to explore better ways to extract and evaluate lexical chain for WSItask.
In addition, for the three clustering algorithms, they generally require the number of clusters oredge-vertex ratio to be pre-defined, so we will seek more effective hypergraph clustering algorithms toautomatically determine the parameters.
Finally, the hypergraph model proposed in this work is notspecific to the sense induction task, and can be adapted for other applications, such as document clas-sification and clustering, information retrieval, etc.AcknowledgementsThis work is supported by the National Natural Science Foundation of China (No.
61173062, 61373108,61133012), the major program of the National Social Science Foundation of China (No.
11&ZD189), and theHigh Performance Computing Center of Computer School, Wuhan University.ReferenceEneko Agirre and Aitor Soroa.
2007.
SemEval-2007 task 02: Evaluating word sense induction and discrimina-tion systems.
In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 7?12.Eneko Agirre, David Martnez, Oier L?pez de Lacalle, and Aitor Soroa.
2006.
Two graph-based algorithms forstate-of-the-art WSD.
In Proceedings of the 2006 Conference on Empirical Methods in Natural Language4 In the test data, the average number of senses of nouns, verbs, adjectives respectively is 7.15, 6.85, 5.9 respectively.1609Processing, pages 585?593.Enrique Amig?, Julio Gonzalo, Javier Artiles, and Felisa Verdejo.
2009.
A comparison of extrinsic clusteringevaluation metrics based on formal constraints.
Information retrieval, 12(4):461?486.Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and Eros Zanchetta.
2009.
The wacky wide web: a collec-tion of very large linguistically processed web-crawled corpora.
Language resources and evaluation,43(3):209?226.Regina Barzilay, Michael Elhadad, et al.
1997.
Using lexical chains for text summarization.
In Proceedings ofthe ACL workshop on Intelligent scalable text summarization, volume 17, pages 10?17.Osman Baskaya, Enis Sert, Volkan Cirik, and Deniz Yuret.
2013.
AI-kU: Using substitute vectors and co-occurrence modeling for word sense induction and disambiguation.
In Proceedings of SemEval-2013.David M Blei, Andrew Y Ng, and Michael I Jordan.
2003.
Latent dirichlet allocation.
the Journal of Machinelearning research, 3:993?1022.Samuel Brody and Mirella Lapata.
2009.
Bayesian word sense induction.
In Proceedings of the 12th Conferenceof the European Chapter of the Association for Computational Linguistics.Stefan Bordag.
2006.
Word sense induction: Triplet-based clustering and automatic evaluation.
In Proceedingsof the 11th Conference of the European Chapter of the Association for Computational LinguisticsJoe Carthy.
2004.
Lexical chains versus keywords for topic tracking.
In Computational Linguistics and Intelli-gent Text Processing, pages 507?510.Antonio Di Marco and Roberto Navigli.
2011.
Clustering web search results with maximum spanning trees.
InAI* IA 2011: Artificial Intelligence Around Man and Beyond, pages 201?212.Beate Dorow and Dominic Widdows.
2003.
Discovering corpus-specific word senses.
In Proceedings of thetenth Conference on European chapter of the Association for Computational Linguistics-Volume 2, pages 79?82.Katrin Erk, Diana McCarthy, and Nicholas Gaylord.
2009.
Investigations on word senses and word usages.
InProceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International JointConference on Natural Language Processing of the AFNLP: Volume 1-Volume 1, pages 10?18.Graeme Hirst and David St-Onge.
1998.
Lexical chains as representations of context for the detection and cor-rection of malapropisms.
WordNet: An electronic lexical database, 305:305?332.David Hope and Bill Keller.
2013.
Maxmax: a graph-based soft clustering algorithm applied to word sense in-duction.
In Computational Linguistics and Intelligent Text Processing, pages 368?381.Nancy Ide and Keith Suderman.
2004.
The american national corpus first release.
In LREC.Nancy Ide, Tomaz Erjavec, and Dan Tufis.
2001.
Automatic sense tagging using parallel corpora.
In NLPRS,pages 83?90.David Jurgens and Ioannis Klapaftis.
2013.
SemEval-2013 Task 13: Word Sense Induction for Graded and Non-Graded Senses.
In Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval2013).Ioannis P Klapaftis and Suresh Manandhar.
2007.
Uoy: a hypergraph model for word sense induction & disam-biguation.
In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 414?417.Andrea Lancichinetti, Santo Fortunato, and J?nos Kert?sz.
2009.
Detecting the overlapping and hierarchicalcommunity structure in complex networks.
New Journal of Physics, 11(3):033015.Jey Han Lau, Paul Cook, and Timothy Baldwin.
2013. unimelb: Topic Modelling-based Word Sense Induction.In Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013).Jey Han Lau, Paul Cook and Diana McCarthy, David Newman and Timothy Baldwin.
2012.
Word sense induc-tion for novel sense detection.
In Proceedings of the 13th Conference of the European Chapter of the Associa-tion for Computational Linguistics.Okumura Manabu and Honda Takeo.
1994.
Word sense disambiguation and text segmentation based on lexicalcohesion.
In Proceedings of the 15th conference on Computational linguistics-Volume 2, pages 755?761.Suresh Manandhar, Ioannis P Klapaftis, Dmitriy Dligach, and Sameer S Pradhan.
2010.
SemEval-2010 task 14:Word sense induction & disambiguation.
In Proceedings of the 5th International Workshop on Semantic1610Evaluation, pages 63?68.Tom Michoel and Bruno Nachtergaele.
2012.
Alignment and integration of complex networks by hypergraph-based spectral clustering.
Physical Review E, 86(5):056111.Alistair Moffat and Justin Zobel.
2008.
Rank-biased precision for measurement of retrieval effectiveness.
ACMTransactions on Information Systems (TOIS), 27(1):2.Jane Morris and Graeme Hirst.
1991.
Lexical cohesion computed by thesaural relations as an indicator of thestructure of text.
Computational linguistics, 17(1):21?48.Roberto Navigli.
2009.
Word sense disambiguation: A survey.
ACM Computing Surveys (CSUR),41(2):10.Michael Steinbach Pang-Ning Tan and Vipin Kumar.
2006.
Introduction to Data Mining.
Pearson Addison Wes-ley.Patrick Pantel and Dekang Lin.
2002.
Discovering word senses from text.
In Proceedings of the eighth ACMSIGKDD, pages 613?619.Li Pu and Boi Faltings.
2012.
Hypergraph learning with hyperedge expansion.
In Machine Learning and Know-ledge Discovery in Databases, pages 410?425.Amruta Purandare and Ted Pedersen.
2004.
Word sense discrimination by clustering contexts in vector and simi-larity spaces.
In Proceedings of the Conference on Computational Natural Language Learning, pages 41?48.Boston.Kumar, Ravi and Vassilvitskii, Sergei.
2010.
Generalized distances between rankings.
In Proceedings of the 19thinternational conference on World wide web, pages 571-580.Steffen Remus and Chris Biemann.
2013.
Three knowledge-free methods for automatic lexical chain extraction.In Proceedings of the 2013 Conference of the North American Chapter of the Association for ComputationalLinguistics: Human Language Technologies, pages 989?999, Atlanta, Georgia, June.Martin Riedl and Chris Biemann.
2012.
Sweeping through the topic space: bad luck?
roll again!
In Proceedingsof the Joint Workshop on Unsupervised and Semi-Supervised Learning in NLP, pages 19?27.Samuel Rota Bulo and Marcello Pelillo.
2012.
A game-theoretic approach to hypergraph clustering.Helmut Schmid.
1994.
Probabilistic part-of-speech tagging using decision trees.
In Proceedings of internationalconference on new methods in language processing, volume 12, pages 44?49.Hinrich Sch?tze.
1998.
Automatic word sense discrimination.
Computational linguistics, 24(1):97?123.Amnon Shashua, Ron Zass, and Tamir Hazan.
2006.
Multi-way clustering using super-symmetric non-negativetensor factorization.
In Computer Vision?ECCV 2006, pages 595?608.Nicola Stokes, Joe Carthy, and Alan F Smeaton.
2004.
Select: a lexical cohesion based news story segmentationsystem.
AI Communications, 17(1):3?12.Yee Whye Teh, Michael I Jordan, Matthew J Beal, and David M Blei.
2006.
Hierarchical dirichlet processes.Journal of the american statistical association, 101(476).Tim Van de Cruys, Marianna Apidianaki, et al.
2011.
Latent semantic word sense induction and disambiguation.In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Lan-guage Technologies (ACL/HLT), pages 1476?1485.Jean V?ronis.
2004.
Hyperlex: lexical cartography for information retrieval.
Computer Speech & Language,18(3):223?252.Dominic Widdows and Beate Dorow.
2002.
A graph model for unsupervised lexical acquisition.
In Proceedingsof the 19th International Conference on Computational linguistics-Volume 1, pages 1?7.David Yarowsky.
1995.
Unsupervised word sense disambiguation rivaling supervised methods.
In Proceedingsof the 33rd annual meeting on Association for Computational Linguistics, pages 189?196.Mehmet Ali Yatbaz, Enis Sert, and Deniz Yuret.
2012.
Learning syntactic categories using paradigmatic repre-sentations of word context.
In Proceedings of the 2012 Joint Conference on Empirical Methods in NaturalLanguage Processing and Computational Natural Language Learning, pages 940?951.Dengyong Zhou, Jiayuan Huang, and Bernhard Sch?lkopf.
2006.
Learning with hypergraphs: Clustering, classi-fication, and embedding.
In Advances in Neural Information Processing Systems, pages 1601?1608.1611
