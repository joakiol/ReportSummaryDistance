Speech Graffiti vs. Natural Language: Assessing the User ExperienceStefanie Tomko and Roni RosenfeldLanguage Technologies Institute, School of Computer ScienceCarnegie Mellon University5000 Forbes Ave., Pittsburgh PA 15213{stef, roni}@cs.cmu.eduAbstractSpeech-based interfaces have great potentialbut are hampered by problems related to spo-ken language such as variability, noise andambiguity.
Speech Graffiti was designed toaddress these issues via a structured, universalinterface protocol for interacting with simplemachines.
Since Speech Graffiti requires thatusers speak to the system in a certain way, wewere interested in how users might respond tosuch a system when compared with a naturallanguage system.
We conducted a user studyand found that 74% of users preferred theSpeech Graffiti system to a natural languageinterface in the same domain.
User satisfac-tion scores were higher for Speech Graffitiand task completion rates were roughly equal.1 IntroductionMany problems still exist in the design of speech-basedinterfaces.
Noisy environments and linguistic variabilitymake interpretation of already uncertain input evenmore difficult, resulting in errors that must be handledeffectively.
What if many of these issues could be re-duced by asking users to interact with speech-basedsystems in a structured way?
Would they learn the in-teraction protocol?
Would they prefer a more efficientyet structured interaction to one that was more natural,but perhaps less efficient?One approach to structuring interaction is throughdirected-dialog systems.
These generally work well fornovice users, but they can be too meandering for expertusers who know exactly what they want from the sys-tem.
Specialized command-and-control languages givemore power to the user, but they can be difficult fornovices and require learning a new language for eachnew application encountered.Speech Graffiti is a structured interaction protocolthat is designed to be universal.
Common input struc-tures, output patterns and keywords are used for allSpeech Graffiti applications, and once users are familiarwith these for any single application, they can navigatetheir way through any other Speech Graffiti application.Fig.
1 shows a sample Speech Graffiti dialogUser interactions with Speech Graffiti (independentof other speech interfaces) have previously been as-sessed in Rosenfeld et al (2000).
Here we consider ahead-to-head comparison: given the chance to interactwith both types of interfaces, which would peoplechoose?
What differences might be observed in per-formance or user satisfaction?1.1 Related workAlthough much research has been conducted on thedesign of natural language spoken dialog systems, farless research has been done on more standardizedspeech interfaces.
Several studies have previously foundthat users are able to interact successfully usingconstrained or subset languages (e.g.
Guindon &Shuldberg, 1987; Ringle & Halstead-Nussloch, 1989;Sidner & Forlines, 2002).
As far as we know, no studieshave been done comparing constrained, ?universal?languages and natural language interfaces directly as wehave done in this study.
General information about theSpeech Graffiti project and its motivation can be foundin Rosenfeld et al (2001).User: Theater is the Manor.
Title is Tuck Everlasting.System: THE CINEMAGIC MANOR THEATRE, TUCK EVERLASTING.Options.SHOW TIME, DAY, GENRE, {?
}.What are the show times?2 MATCHES: 1:25, 5:30.Start over.STARTING OVER.Area is Monroeville.MONROEVILLE.What are the theaters?SHOWCASE CINEMAS PITTSBURGH EAST.Theater is Showcase Cinemas Pittsburgh East.SHOWCASE CINEMAS PITTSBURGH EAST.What are the titles?11 MATCHES, BLUE CRUSH, ABANDON, BROWN SUGAR, {?
}.Genre is comedy.COMEDY.Where am I?AREA IS MONROEVILLE, THEATER IS SHOWCASE CINEMAS PITTSBURGHEAST, WHAT ARE THE TITLES?, GENRE IS COMEDY.What are the titles?5 MATCHES, MY BIG FAT GREEK WEDDING, BROWN SUGAR,JONAH - A VEGGIETALES MOVIE, {?
}.Figure 1.
Sample Speech Graffiti interaction.2 MethodWe conducted a within-subjects user study in whichparticipants attempted a series of queries to a movieinformation database with either a Speech Graffiti inter-face (SG-ML) or a natural language interface (NL-ML).Participants repeated the process with the other systemafter completing their initial tasks and an evaluationquestionnaire.
System presentation order was balanced.2.1 ParticipantsTwenty-three users (12 female, 11 male) accessed thesystems via telephone in our lab.
Most were under-graduate students from Carnegie Mellon University,resulting in a limited range of ages represented.
Nonehad any prior experience with either of the two moviesystems or interfaces, and all users were native speakersof American English.
About half the users had computerscience and/or engineering (CSE) backgrounds, andsimilarly about half reported that they did computerprogramming ?fairly often?
or ?very frequently.
?2.2 TrainingUsers learned Speech Graffiti concepts prior to use dur-ing a brief, self-paced, web-based tutorial session.Speech Graffiti training sessions were balanced betweentutorials using examples from the MovieLine and tutori-als using examples from a database that provided simu-lated flight arrival, departure, and gate information.Regardless of training domain, most users spent ten tofifteen minutes on the Speech Graffiti tutorial.A side effect of the Speech Graffiti-specific trainingis that in addition to teaching users the concepts of thelanguage, it also familiarizes users with the more gen-eral task of speaking to a computer over the phone.
Tobalance this effect for users of the natural language sys-tem, which is otherwise intended to be a walk-up-and-use interface, participants engaged in a brief NL ?fa-miliarization session?
in which they were simply in-structed to call the system and try it out.
To match thein-domain/out-of-domain variable used in the SG tutori-als, half of the NL familiarization sessions used the NLMovieLine and half used MIT?s Jupiter natural lan-guage weather information system (Zue et al, 2000).Users typically spent about five minutes exploring theNL systems during the familiarization session.2.3 TasksAfter having completed the training session for a spe-cific system, each user was asked to call that system andattempt a set of tasks (e.g.
?list what?s playing at theSquirrel Hill Theater,?
?find out & write down what theratings are for the movies showing at the Oaks Thea-ter?).
Participant compensation included task comple-tion bonuses to encourage users to attempt each task inearnest.
Regardless of which system they were workingwith, all users were given the same eight tasks for theirfirst interactions and a different set of eight tasks fortheir second system interactions.2.4 EvaluationAfter interacting with a system, each participant wasasked to complete a user satisfaction questionnaire scor-ing 34 subjective-response items on a 7-point Likertscale.
This questionnaire was based on the SubjectiveAssessment of Speech System Interfaces (SASSI) pro-ject (Hone & Graham, 2001), which sorts a number ofsubjective user satisfaction statements (such as ?I al-ways knew what to say to the system?
and ?the systemmakes few errors?)
into six relevant factors: systemresponse accuracy, habitability, cognitive demand, an-noyance, likeability and speed.
User satisfaction scoreswere calculated for each factor and overall by averagingthe responses to the appropriate component statements.1In addition to the Likert scale items, users were alsoasked a few comparison questions, such as ?which ofthe two systems did you prefer?
?For objective comparison of the two interfaces, wemeasured overall task completion, time- and turns-to-completion, and word- and understanding-error rates.3 Results3.1 Subjective assessmentsSeventeen out of 23 participants preferred Speech Graf-fiti to the natural language interface.
User assessmentswere significantly higher for Speech Graffiti overall andfor each of the six subjective factors, as shown in Fig.
2(REML analysis: system response accuracy F=13.8,p<0.01; likeability F=6.8, p<0.02; cognitive demandF=5.7, p<0.03; annoyance F=4.3, p<0.05; habitabilityF=7.7, p<0.02; speed F=34.7, p<0.01; overall F=11.2,p<0.01).
All of the mean SG-ML scores except for an-noyance and habitability are positive (i.e.
> 4), while theNL-ML did not generate positive mean ratings in anycategory.
For individual users, all those and only thosewho stated they preferred the NL-ML to the SG-MLgave the NL-ML higher overall subjective ratings.Although users with CSE/programming back-grounds tended to give the SG-ML higher user satisfac-tion ratings than non-CSE/programming participants,the differences were not significant.
Training domainlikewise had no significant effect on user satisfaction.1  Some component statements are reversal itemswhose values were converted for analysis, so that highscores in all categories are considered good.3.2 Objective assessmentsTask completion.
Task completion did not differ sig-nificantly for the two interfaces.
In total, just over twothirds of the tasks were successfully completed witheach system: 67.4% for the NL-ML and 67.9% for theSG-ML.
The average participant completed 5.2 taskswith the NL-ML and 5.4 tasks with the SG-ML.
As withuser satisfaction, users with CSE or programming back-ground generally completed more tasks in the SG-MLsystem than non-CSE/programming users, but again thedifference was not significant.
Training domain had nosignificant effect on task completion for either system.To account for incomplete tasks when comparingthe interfaces, we ordered the task completion measures(times or turn counts) for each system, leaving all in-completes at the end of the list as if they had been com-pleted in ?infinite time,?
and compared the medians.Time-to-completion.
For completed tasks, the aver-age time users spent on each SG-ML task was lowerthan for the NL-ML system, though not significantly:67.9 versus 71.3 seconds.
Considering incomplete tasks,the SG-ML performed better than the NL-ML, with amedian time of 81.5 seconds, compared to 103 seconds.Turns-to-completion.
For completed tasks, the av-erage number of turns users took for each SG-ML taskwas significantly higher than for the NL-ML sys-tem:8.2 versus 3.8 (F=26.4, p<0.01).
Considering incom-plete tasks, the median SG-ML turns-to-completion ratewas twice that of the NL-ML: 10 versus 5.Word-error rate.
The SG-ML had an overall word-error rate (WER) of 35.1%, compared to 51.2% for theNL-ML.
When calculated for each user, WER rangedfrom 7.8% to 71.2% (mean 35.0%, median 30.0%) forthe SG-ML and from 31.2% to 78.6% (mean 50.3%,median 48.9%) for the NL-ML.
The six users with thehighest SG-ML WER were the same ones who preferredthe NL-ML system, and four of them were also the onlyusers in the study whose NL-ML error rate was lowerthan their SG-ML error rate.
This suggests, not surpris-ingly, that WER is strongly related to user preference.To further explore this correlation, we plotted WERagainst users?
overall subjective assessments of eachsystem, with the results shown in Fig.
3.
There is a sig-nificant, moderate correlation between WER and usersatisfaction for Speech Graffiti (r=-0.66, p<0.01), but nosimilar correlation for the NL-ML system (r=0.26).Understanding error.
Word-error rate may not bethe most useful measure of system performance formany spoken dialogue systems.
Because of grammarredundancies, systems are often able to ?understand?
anutterance correctly even when some individual wordsare misrecognized.
Understanding error rate (UER) maytherefore provide a more accurate picture of the errorrate that a user experiences.
For this analysis, we onlymade a preliminary attempt at assessing UER.
Theseerror rates were hand-scored, and as such represent anapproximation of actual UER.
For both systems, wecalculated UER based on an entire user utterance ratherthan individual concepts in that utterance.SG-ML UER for each user ranged from 2.9% to65.5% (mean 26.6%, median 21.1%).
The averagechange per user from WER to understanding-error forthe SG-ML interface was ?29.2%.The NL-ML understanding-error rates differed littlefrom the NL-ML WER rates.
UER per user ranged from31.4% to 80.0% (mean 50.7%, median 48.5%).
Theaverage change per user from NL-ML WER was +0.8%.Figure 2.
Mean user satisfaction for systemresponse accuracy, likeability, cognitive demand,annoyance, habitability, speed and overall.1234567syst.resp.acc.like.
cog.dmd.ann.
hab.
speed overallNL SGFigure 3.
Word-error rate vs. overall usersatisfaction for Speech Graffiti and naturallanguage MovieLines.12345670 20 40 60 80SG word-error rate12345670 20 40 60 80NL word-error rate4 DiscussionOverall, we found that Speech Graffiti performedfavorably compared to the natural language interface.Speech Graffiti generated significantly higher usersatisfaction scores, and task completion rates and timeswere similar.The higher turns-to-completion rate for SpeechGraffiti is not necessarily problematic.
The phrasal na-ture of Speech Graffiti syntax seems to encourage usersto input single phrases; we suspect that in a longitudinalstudy, we would find single-utterance command use inSG-ML increasing as users became more familiar withthe system.
Furthermore, because the SG-ML splits longoutput lists into smaller chunks, a user often has to ex-plicitly issue a request to hear more items in a list, add-ing at least one more turn to the interaction.
Thus thereexists a trade-off between turn-wise efficiency and re-duced cognitive load.
Because of the reasonable resultsshown for the SG-ML in user satisfaction and comple-tion time, we view this as a reasonable trade-off.It is possible that if lower word-error rates can beachieved, Speech Graffiti would become unnecessary.This may be true for consistent, extremely low word-error rates, but such rates do not appear to be attainablein the near term.
Furthermore, the correlations in Fig.
3suggest that as WER decreases, users become more sat-isfied with the SG interface but that this is not necessar-ily true for the NL interface.
Consider also the effect ofunderstanding error.
UER is the key to good systemperformance since even if the system has correctly de-coded a word string, it must still match that string withthe appropriate concepts in order to perform the desiredaction.
Although WER may be reduced via improvedlanguage and acoustic models, matching input to under-standing in NL systems is usually a labor-intensive anddomain-specific task.
In contrast, the structured natureof Speech Graffiti significantly reduces the need forsuch intensive concept mapping.Future work.
For Speech Graffiti, scores forhabitability (represented by statements like ?I alwaysknew what to say to the system?)
were typically thelowest of any of the six user satisfaction factors,suggesting that this is a prime area for further work.In this regard, it is instructive to consider the ex-perience of the six users who preferred the NL interface.Overall, they accounted for the six highest SG-MLword- and understanding-error rates and the six lowestSG-ML task completion rates: clearly not a positiveexperience.
An additional measure of habitability isgrammaticality: how often do users speak within theSpeech Graffiti grammar?
The six NL-ML-preferringusers also had low grammaticality rates (Tomko &Rosenfeld, 2004).
These users have become a motivatorof future work: what can be done to make the interfacework for them and others like them?
(Future studies willfocus on a broader population of adults.)
How can wehelp users who are having severe difficulties with aninterface learn how to use it better and faster?
Toimprove the habitability of Speech Graffiti, we plan toexplore allowing more natural language-esqueinteraction while retaining an application-portablestructure.
We also plan to refine Speech Graffiti?sruntime help facilities in order to assist users moreeffectively in saying the right thing at the right time.In addition to these core interface goals, we plan toextend the functionality of Speech Graffiti beyondinformation access to support the creation, deletion andmodification of information in a database.AcknowledgementsThis work was supported by an NDSEG Fellowship,Pittsburgh Digital Greenhouse and Grant N66001-99-1-8905 from the Space & Naval Warfare Systems Center.The information in this publication does not necessarilyreflect the position or the policy of the US Governmentand no official endorsement should be inferred.ReferencesGuindon, R. & Shuldberg, K. 1987.
Grammatical andungrammatical structures in user-adviser dialogues:evidence for sufficiency of restricted languages innatural language interfaces to advisory systems.
InProc.
of the Annual Meeting of the ACL, pp.
41-44.Hone, K. & Graham, R. 2001.
Subjective Assessment ofSpeech-System Interface Usability.
In Proceedings ofEurospeech, Aalborg, Denmark.Ringle, M.D.
& Halstead-Nussloch, R. 1989.
Shapinguser input: a strategy for natural language design.
In-teracting with Computers 1(3):227-244Rosenfeld, R., Zhu, X., Toth, A., Shriver, S., Lenzo, K.& Black, A.
2000.
Towards a Universal Speech Inter-face.
In Proceedings of ISCLP, Beijing, China.Rosenfeld, R., Olsen, D. & Rudnicky, A.
2001.
Uni-versal Speech Interfaces.
Interactions, 8(6):34-44.Sidner, C. & Forlines, C. 2002.
Subset Languages forConversing with Collaborative Interface Agents.
InProc.
of ICSLP, Denver CO, pp.
281-284.Tomko, S. & Rosenfeld, R. 2004.
Speech Graffiti habi-tability: what do users really say?
To appear in Pro-ceedings of SIGDIAL.Zue, V., Seneff, S., Glass, J.R., Polifroni, J., Pao, C.,Hazen, T.J. & Hetherington, L. 2000.
JUPITER: ATelephone-Based Conversational Interface forWeather Information, IEEE Transactions on Speechand Audio Processing, 8(1): 85 ?96.
