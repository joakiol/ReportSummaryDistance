Proceedings of the Fourteenth Conference on Computational Natural Language Learning: Shared Task, pages 78?83,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsExploiting Rich Features for Detecting Hedges and Their ScopeXinxin Li, Jianping Shen, Xiang Gao, Xuan WangHarbin Institute of Technology Shenzhen Graduate SchoolShenzhen, Guangdong, China{lixxin2, jpshen2008}@gmail.com,sky0306201@163.com, wangxuan@insun.hit.edu.cnAbstractThis paper describes our system aboutdetecting hedges and their scope in naturallanguage texts for our participation in CoNLL-2010 shared tasks.
We formalize these twotasks as sequence labeling problems, andimplement them using conditional randomfields (CRFs) model.
In the first task, we use agreedy forward procedure to select features forthe classifier.
These features include part-of-speech tag, word form, lemma, chunk tag oftokens in the sentence.
In the second task, oursystem exploits rich syntactic features aboutdependency structures and phrase structures,which achieves a better performance than onlyusing the flat sequence features.
Our systemachieves the third score in biological data setfor the first task, and achieves 0.5265 F1 scorefor the second task.1 IntroductionIn recent years, a fair amount of approaches havebeen developed on detecting speculative andnegative information from biomedical andnatural language texts, for its benefit to theapplications like information extraction.
Theseapproaches evolve from hand-crafted rule-basedapproaches, which use regular expressions tomatch the sentences or its grammatical parsing,such as NegEx (Chapman et al, 2001),Negfinder (Mutalik et al, 2001), andNegExpander (Aronow et al, 1999), to machinelearning approaches, including semi-supervisedmethods (Medlock and Briscoe, 2007; Szarvas,2008), and supervised methods (Morante andDaelemans, 2009).In this paper, we describe the machinelearning system submitted to CoNLL-2010Shared task (Farkas et al, 2010).
Our systemformalizes these two tasks as consecutivesequence labeling problems, and learns theclassifiers using conditional random fieldsapproach.
In the first task, a model is trained toidentify the hedge cues in sentences, and in thesecond task, another model is used to find thecorresponding scope for each hedge cuegenerated in the first task.
Our system followsthe study of Morante and Daelemans (2009), butapplies more refined feature selection.
In the firsttask, we use a greedy forward procedure to selectfeatures for the classifier.
In the second task, weexploit rich syntactic information to improve theperformance of the model, from dependencystructures and phrase structures.
A rule-basedpost processing procedure is used to eliminatethe errors brought by the classifier for each task.The remainder of the paper is organized asfollows.
In section 2, we briefly describe the taskand the details of our system, including how toselect features for the hedge cue detectionsystem, and how to find the corresponding scopefor each hedge cue.
The experimental results arediscussed in section 3.
In section 4 we putforward some conclusion.2 System DescriptionWe model these two tasks for identifying thehedge cues and finding their scope as twoconsecutive sequence labeling problems, such aschunking, segmentation and named entityrecognition, and train the classifiers usingconditional random fields approach (Lafferty etal., 2001).
For each task, a post-processingprocedure is used to refine the results from theclassifier.In the first task, we detect the hedge cue byclassifying the tokens of a sentence as being atthe beginning of, inside or outside of the hedgesignal.
In the second task, we find the scope of ahedge cue by classifying the tokens of a sentenceas being the first one of, the last one or neither ofthe scope.A sentence from biological full articles dataset omitting the id number is shown below inFigure 1.
In this sentence, there is only onehedge cue, the phrase ?raises an interestingquestion?, and its corresponding scope is thesequence from token ?raises?
to token ?acid?.78<sentence>This <xcope><cue>raises aninteresting question</cue>: "Is there a 23rdamino acid</xcope>?
".</sentence>Figure 1: A sentence with hedge cue and scopeannotation in biological full articles data set2.1 Hedge detectionSince hedge cues usually consist of one or moretokens, we predict the tokens in BIOrepresentation, whether the token is the firsttoken of a hedge cue (B-cue), inside a hedge cue(I-cue), or outside of the hedge cue (O-cue).
Forthe sentence in Figure 1, token ?raises?
isdenoted as B-cue, tokens ?an interestingquestion?
all as I-cue, and the other tokens in thesentence as O-cue.The classifier is trained using conditionalrandom fields (Lafferty et al, 2001), whichcombines the benefits of conditional models withthe global normalization of random field models,and avoid the label bias problem that exists inmaximum entropy Markov models (MEMMs).The CRF model we use is implemented asCRF++ 0.51 1 .
The parameters of the CRFclassifier are set as defaults.We use a greedy forward procedure to select abetter feature sets for the classifier according tothe evaluation results in the development set.
Wefirst start from a basic feature set, and then addeach feature outside the basic set and removeeach feature inside the basic set one by one tocheck the effectiveness of each feature by theperformance change in the development set.
Thisprocedure is repeated until no feature is added orremoved or the performance is not improved.The selected features are listed below:?
Cn (n=-2,-1, 0, 1, 2)?
CnCn+1 (n=-1,0)?
Cn-1CnCn+1 (n=-1,0,1)?
Cn-2Cn-1CnCn+1  (n=0,1)Where C denote features of each token,including FORM, LEMMA, and POS (in Table1), C0 represents the feature of current token andCn(C-n) represents the feature of the token npositions to the right (left) of current token.CnCn+1 denote the combination of Cn and Cn+1.
Soare Cn-1CnCn+1 and Cn-2Cn-1CnCn+1.1http://crfpp.sourceforge.net/FeatureNameDescriptionFORM Word form or punctuation symbol.LEMMA Lemma or stem of word form.POS Part-of-speech tag of the token.CHUNK Chunk tag of the token, e.g.
B_NP,B_ SBAR, and I_NP.TCHUNK Chunk type of the token, e.g.
NP.Table 1: Description of features of each tokenAlthough our system is based on token, chunkfeatures are also important.
Analyzing thetraining data set, it is shown that if one token in achunk is in the hedge cue, the other tokens in thechunk are usually in the same hedge cue.
Thechunk feature can provide more information forthe multiword hedge cues.
The LEMMA, POS,and CHUNK of each token used in our systemare determined using GENIA tagger (Tsuruoka etal., 2005).The selected CHUNK features in our systemare listed as follows:?
Cn (n=-3, -2,-1, 0, 1, 2, 3 )?
CnCn+1 (n=-3, -2,-1, 0, 1, 2, 3 )?
Cn-1CnCn+1  (n=-2,-1,0,1,-2)?
Cn-2Cn-1CnCn+1 (n=-1,0,1,2)We can obtain the preliminary results usingthe CRF model-based classifier, but there aresome missed or incorrectly classified hedge cueswhich can be recognized by rule-based patterns.Through statistical analysis on the training anddevelopment data sets, we obtain some effectiverules for post processing, including:?
If the first token of a NP chunk tag isannotated as I-cue, the whole NP chunk isin the hedge cues.?
If the B-VP chunk tag of a token isfollowed by a B-SBAR chunk tag, thetoken is annotated as B-cue.?
If token ?that?
follows token ?indicate?and the POS of token ?that?
is IN, thechunk tag of token ?that?
is B-SBAR, thenthe ?indicate?
will be annotated with B-cue and ?that?
will be annotated with I-cue.?
If token ?indicate?
is followed by token?an?
or token ?a?, then the token?indicate?
is annotated as B-cue.792.2 Scope findingIn this task, we train a classifier to predictwhether each token in the sentence is in thescope by classifying them as the first one (F-scope), the last one (L-scope), or neither(NONE) of the scope, which is the same asMorante and Daelemans (2009).
For the sentencein Figure 1, token ?raises?
is denoted as F-scope,token ?acid?
as L-scope, and the other tokens inthe sentence as NONE.After the classification, a post processingprocedure is used to match the scope to eachhedge, guaranteeing that each hedge has only onecorresponding scope sequence, and must beinside its scope sequence.
There is no crossbetween different scope sequences, but inclusionis allowed.
The hedges are selected from the firsttask.The classifier is also implemented usingconditional random fields model, and theparameters of the CRF classifier are set asdefaults.
We first build a set of baseline sequencefeatures for the classifier, some borrowed fromMorante and Daelemans (2009).
The selectedbaseline sequence features are:?
Of the token in focus: FORM, POS,LEMMA, CHUNK, TCHUNK,combination of FORM and POS; POS,LEMMA, CHUNK, TCHUNK of twotokens to the left and three tokens to theright; first word, last word, chain ofFORM, POS of two chunks to the left andtwo chunks to the right; All combinationof POS in the window of length less than 3;All combination of CHUNK in thewindow of length 2.?
Of the left closest hedge: chain of theFORM, POS, LEMMA, CHUNK, andTCHUNK; All combination of POS andFORM in the window of length 2.?
Of the right closest hedge: chain of theFORM, POS, LEMMA, CHUNK, andTCHUNK; All combination of POS andFORM in the window of length 2.?
Of the tokens between the left closesthedge and the token in focus: chain ofFORM, POS, LEMMA, CHUNK andTCHUNK; the number.?
Of the tokens between the right closesthedge and the token in focus: chain ofFORM, POS, LEMMA, CHUNK andTCHUNK; the number.?
Others: the number of hedge cues in thesentence; the sequence relation betweenthe token in focus and hedge cues (LEFT,RIGHT, MIDDLE, IN, NULL)Besides the sequence features listed above,syntactic features between the token in focus andhedge cues are explored in our classifier.
Huangand Low (2007) notes that structure informationstored in parse trees helps identifying the scopeof negative hedge cues, and Szarvas (2008)points out that the scope of a keyword can bedetermined on the basic of syntax.
Thus webelieve that a highly accurate extraction ofsyntactic structure would be beneficial for thistask.For sentences in the dataset, their dependencystructures are extracted using GENIADependency parser (Sagae and Tsujii, 2007), andphrase structure using Brown self-trainedbiomedical parser (McClosky, 2009).
Figure 2shows the corresponding dependency tree andFigure 3 shows the corresponding phrasestructure tree for the sentence in Figure 1.
In thefollowing part in the section, we will illustratethese syntactic features and give examples fortheir value.
We take the token ?acid?
as the tokenin focus, to determine whether it is classified asF-scope, L-scope or NONE.Figure 2: Dependency tree of the sentence inFigure 1For the token ?acid?
in the dependency treesin Figure 2, its father node is the token ?there?,and the dependency relation between these twotoken is ?NMOD?.Dependency features between the token infocus and the left closest hedge cue are:?
Dependency relation of the token infocus to its father, left closest hedge to its80father and the dependency relation pair:NOMD, ROOT, ROOT+NMOD.?
Chain of POS: ->VBZ<-VBZ<-EX<-NN?
Chain of POS without consecutiveredundant POS: ->VBZ <-EX<-NN?
POS of their nearest co-father: VBZ?
Whether it is a linear relation (self, up ,down, no): up?
Kinship (grandfather, grandson, father,son, brother, self, no): no.?
The number of tokens in the chain: 4Similar features are extracted for dependencyrelation between the token in focus and its rightclosest hedge cue.
There is no right hedge cue fortoken ?acid?.
Thus these features are set as?NULL?.This raises an interesting question :  " Is there a 23rd amino acid ? "
.DT VBZ DT JJ NN : NN VBZ RB DT NN NN NN .
RB .NP NP NP ADVP NPVPSNPADVPNPVPSSFigure 3: Phrase structure tree of the sentence inFigure 1Phrase structure features between the token infocus and its left closest hedge cue are:?
Chain of syntactic categories: VBZ->VP<- NP <-NP <-S<-VP <-NP<-NN?
syntactic categories without consecutiveredundant ones: VBZ->VP<-NP<-S<-VP<- NP<-NN?
Syntactic category of their nearest co-father: VP?
The number of syntactic categories in thechain: 8The phrase structure features between thetoken in focus and the nearest right hedge cue aresimilar, setting as ?NULL?.Scope finding requires each hedge cue hasonly one corresponding scope.
A hedge-scopepair is true positive only if the hedge cue and itscorresponding scope are correctly identified.
Weperform the post processing procedure insequence:?
For each hedge cue from the beginningto the end of the sentence, find its leftclosest F-scope which has not beenidentified by other hedge cues, andidentify it as its F-scope.?
For each hedge cue from the end to thebeginning of the sentence, find its rightclosest L-scope which has not beenidentified by other hedge cues, andidentify it as its L-scope.?
For each hedge: If both its F-scope and L-scope isidentified, then done; If only its F-scope is identified, thenits L-scope is set as L-scope of thelast hedge cue in the sentence if itexists or according to the dictionarywhich we build with training dataset; If only its L-scope is identified, thenits F-scope is set as its first token; If none of its F-scope and L-scope isidentified, then discard the hedgecue.3 Overall ResultsIn this section we will present our experimentalresults for these two tasks.
In the first task, thechief evaluation is carried on sentence level:whether a sentence contains hedge/weasel cue ornot.
Our system compares the performance ofdifferent machine learning algorithm, CRF andSVM-HMM on hedge cue detection.
A postprocessing procedure is used to increase therecall measure for our system.In the second task, three experiments areperformed.
The first experiment is used tovalidate the benefit of dependency features andphrase structure features for scope finding.
Thesecond experiment is designed to evaluate theeffect of abstract dataset on full article dataset.These two experiments are all performed usinggold hedge cues.
The performance of our scopefinding system with predicted hedge cues ispresented in the third experiment.813.1 Hedge detectionThe first experiment is used to compare twomachine learning algorithms, SVM-HMM andCRF.
We train the classifiers on abstract and fullarticles data sets.
The results of the classifier onevaluation data set are shown in Table 2.Model Precision Recall F1SVM-HMM 88.71 81.52 84.96CRF 90.4 81.01 85.45Table 2: Results of hedge cues detection usingCRF and SVM-HMMFrom Table 1, it is shown that CRF modeloutperforms SVM-HMM model in bothprecision and recall measure.
The results areobtained without post processing.
Theexperimental result with post processing isshown in Table 3.Feature Precision Recall F1Without Postprocessing90.4 81.01 85.45Postprocessing90.1 82.05 85.89Table 3: Result of biological evaluation data setwithout/with post processingBy post processing, some mislabeled orincorrectly classified hedge cues can berecognized, especially the recall of the I-cueimproved largely, from 55.26% to 68.51%.Though the precision is a little lower, the F1measure increases 0.44%.3.2 Scope findingTo measure the benefit of syntactic features onscope finding task, we perform the experimentwith different features on abstract data set, ofwhich we split two-thirds as training data, andthe other one third as testing data.
The results arepresented in Table 4.We take the classifier with sequence featuresas baseline classifier.
From Table 4, it is shownthat adding dependency features achieves aslightly better performance than the baselineclassifier, and adding phrase structure featuresimprove much better, about 1.2% F1-score.
Theclassifier with all syntactic features achieves thebest F1-score, 2.19% higher than baselineclassifier.
However, in later experiment onevaluation dataset after the shared task, weobserved that dependency features actuallyharmed the performance for full articles dataset.Feature set Precision Recall F1Sequence(Baseline)82.20 81.61 81.90Sequence +Dependency82.28 82.09 82.19Sequence+ Phrase structure83.14 83.04 83.09All 84.19 83.99 84.09Table 4: Results of scope finding system withdifferent feature sets on abstract data setThree experiments are designed to evaluatethe benefit of abstract dataset for full articlesdataset.
The first one is performed on full articlesdata set, of which we split two-thirds for training,and the other one third for testing.
The secondexperiment is trained on abstract data set, andevaluated on full articles data set.
In the thirdexperiment, we take abstract data set and onethird of full articles as training data, and evaluateon the remaining full articles data set.
The resultsare shown below in Table 5.TrainingdataTestingdataPrec.
Recall F1Part Art.
Part Art.
53.14 51.80 52.46Abs.
Full Art.
54.32 54.64 54.48Mix Part Art.
59.59 59.74 59.66Table 5: Results of scope finding system withgold-standard hedge cuesResults in Table 5 reveal that more abstractand full article dataset are added to the classifieras training data, better performance the systemachieve.
Thus we use the combination of abstractand full articles as training data for the finalevaluation.Table 6 presents the results of our scopefinding system with or without dependencyfeatures, using both gold-standard hedge cuesand predicated hedge cues generated by ourhedge cue finding system.Comparing the results in Table 4, 5, and 6, weobserve that the performance of scope findingclassifier on full article dataset is much lowerthan on abstract dataset, and dependency featuresare beneficial for the abstract dataset, but uselessfor full article dataset.
We ascribe thisphenomenon to the lack of enough full articlestraining data and the different properties of82abstract and full articles data sets.
Deep researchis expected to continue.HedgecuesDep.featuresPrec.
Recall F1with 57.42 47.92 52.24Predictedwithout 58.13 48.11 52.65with 59.43 58.28 58.85Goldstandardwithout 60.20 58.86 59.52Table 6: Results of scope finding systemwith/without dependency features using bothgold-standard and predicated hedge cues4 ConclusionIn this paper, we describe a machine learningsystem for detecting hedges and their scope innatural language texts.
These two tasks areformalized as sequence labeling problems, andimplemented using conditional random fieldsapproach.
We use a greedy forward procedure toselect features for the classifier, and exploit richsyntactic features to achieve a better performance.In the in-domain evaluation, our system achievesthe third score in biological data set for the firsttask, and achieves 0.5265 F1 score for the secondtask.AcknowledgmentsThe authors would like to thank Buzhou Tang foruseful discussions of the paper.
This work issupported by the National High-tech R&DProgram of China (863 Program, No.2007AA01Z194).ReferencesDavid B. Aronow, Fangfang Feng, and W. BruceCroft.
1999.
Ad Hoc Classification of RadiologyReports.
Journal of the American MedicalInformatics Association, 6(5):393?411.Wendy W. Chapman, Will Bridewell, Paul Hanbury,Gregory F. Cooper, and Bruce G. Buchanan.
2001.A Simple Algorithm for Identifying NegatedFindings and Diseases in Discharge Summaries.Journal of Biomedical Informatics, 34:301?310.Rich?rd Farkas, Veronika Vincze, Gy?rgy M?ra,J?nos Csirik, and Gy?rgy Szarvas.
2010.
TheCoNLL-2010 Shared Task: Learning to DetectHedges and their Scope in Natural Language Text.In Proceedings of the Fourteenth Conferenceon Computational Natural Language Learning(CoNLL-2010): Shared Task, pages 1?12.Yang Huang, and Henry J. Lowe.
2007.
A novelhybrid approach to automated negation detection inclinical radiology reports.
Journal of theAmerican Medical Informatics Association,14(3):304?311.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional random fields:Probabilistic models for segmenting and labelingsequence data.
In Proceedings of the EighteenthInternational Conference on MachineLearning, pages 282?289.David McClosky.
2009.
Any Domain Parsing:Automatic Domain Adaptation for NaturalLanguage Parsing.
Ph.D. thesis, Department ofComputer Science, Brown University.Ben Medlock, and Ted Briscoe.
2007.
Weaklysupervised learning for hedge classification inscientific literature.
In Proc.
of ACL 2007, pages992?999.Roser Morante, and Walter Daelemans.
2009.Learning the scope of hedge cues in biomedicaltexts.
In Proceedings of the Workshop onBioNLP, pages 28?36.Pradeep G. Mutalik, Aniruddha Deshpande, andPrakash M. Nadkarni.
2001.
Use of general-purpose negation detection to augment conceptindexing of medical documents: a quantitativestudy using the UMLS.
Journal of the AmericanMedical Informatics Association, 8(6):598?609.Kenji Sagae, and Jun?ichi Tsujii.
2007.
Dependencyparsing and domain adaptation with LR modelsand parser ensembles.
In Proceedings of theCoNLL-2007 Shared Task, pages 82?94Gy?rgy Szarvas.
2008.
Hedge classification inbiomedical texts with a weakly supervisedselection of keywords.
In Proc.
of ACL 2008,pages 281?289, Columbus, Ohio, USA.
ACL.Gy?rgy Szarvas, Veronika Vincze, Rich?rd Farkas,and J?nos Csirik.
2008.
The BioScope corpus:annotation for negation, uncertainty and their scopein biomedical texts.
In Proc.
of BioNLP 2008,pages 38?45, Columbus, Ohio.
ACL.Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim,Tomoko Ohta, John McNaught, Sophia Ananiadou,and Jun'ichi Tsujii.
2005.
Developing a RobustPart-of-Speech Tagger for Biomedical Text.Advances in Informatics - 10th PanhellenicConference on Informatics, LNCS 3746, pages382?392.83
