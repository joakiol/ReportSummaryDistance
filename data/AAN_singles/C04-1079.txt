Generating Overview Summaries of Ongoing Email Thread DiscussionsStephen WanDepartment of ComputingMacquarie UniversitySydney NSW 2109swan@ics.mq.edu.auKathy McKeownColumbia UniversityDepartment of Computer Science1214 Amsterdam AvenueNY - 10027-7003, USAkathy@cs.columbia.eduAbstractThe tedious task of responding to a backlog ofemail is one which is familiar to many researchers.As a subset of email management, we address theproblem of constructing a summary of emaildiscussions.
Specifically, we examine ongoingdiscussions which will ultimately culminate in aconsensus in a decision-making process.
Oursummary provides a snapshot of the current state-of-affairs of the discussion and facilitates a speedyresponse from the user, who might be thebottleneck in some matter being resolved.
Wepresent a method which uses the structure of thethread dialogue and word vector techniques todetermine which sentence in the thread should beextracted as the main issue.
Our solutionsuccessfully identifies the sentence containing theissue of the thread being discussed, potentiallymore informative than subject line.1 IntroductionImagine the chore of sifting through youroverflowing email inbox after an extended periodaway from the office.
The discovery that some ofthese emails form part of a larger decision-makingdiscussion only heightens the sense of urgency andstress.
Such a discussion may require an urgentresponse and a user?s lack of contribution may be abottleneck in some matter being resolved.
Such ascenario is seems quite familiar and intuitively, onewould expect that better solutions to presenting thecontents of the email inbox might be useful infacilitating a timely reply to a missed emaildiscussion.One such solution might be a summary of thatvery email discussion.
However, it would be muchmore useful if the summary did not just tell theuser what the thread is about.
Such informationmight be easily obtained from the subject line, or ifnot, a conventional off-the-shelf summarizer mightprovide the gist of the thread quite easily.However, in contrast to a conventional sentenceextraction summary in Figure 1, the ideal summaryought to provide sufficient information about thecurrent state-of-affairs of the discussion, in order tominimize any further delay in the matter beingresolved.
Specifically, this might include adescription of the matter being discussed and theresponses received so far.
An example of such asummary is presented in Figure 2.
In this example,it is not sufficient to know that a plaque is beingdesigned.
Crucially, the wording of the plaque isunder discussion and requires feedback from thethread participants.
It is not difficult to appreciatethe usefulness of such a summary to avoid writingresponses to older, and hence irrelevant, emails.Accordingly, we envisage that the resultingsummary to be not just indicative of the threadcontent but informative Borko (1975).1.
Here's the plaque info.2.
http://www.affordableawards.com/plaques/ordecon.htm3.
I like the plaque, and aside for exchangingDana's name for "Sally Slater" and ACM for"Ladies Auxiliary", the wording is nice.4.
We just need to contact the plaque folks andask what format they need for the logo.Figure 1.
Example summary from a conventionalsentence extraction summarizerIssue: Let me know if you agree or disagreew/choice of plaque and (especially) wording.Response 1: I like the plaque, and aside forexchanging Dana's name for "Sally Slater"and ACM for "Ladies Auxiliary", thewording is nice.Response 2: I prefer Christy's wording to theplaque original.Figure 2.
Example summary from our systemWe present a novel approach which identifiesthe main issue within the email and finds theresponses to that issue within subsequent emails.Our approach uses a combination of traditionalvector space techniques and Singular ValueDecomposition (SVD).
We rely on the premisethat the participants of the discussion haveimplicitly determined which sentence from theinitiating email of the thread is most important andthat we can see evidence of this inherent in thecontent of their respective replies.In the remainder of the paper, we providebackground on email usage and our observationsof discussion thread structure in Section 2 tosupport our basic premise.
Section 3 provides adescription of related work in the area.
To date,use of dialogue structure has mostly been limitedto finding question-answer pairs in order to extractthe pairing as a whole for the sake of coherence.We present a more formal description of theproblem we are addressing and our algorithms forissue in Section 4.
Section 5 outlines our handlingof response extraction.
In Section 6, we present apreliminary evaluation we have conducted alongwith the results.
Finally we end with concludingremarks in Section 7.2 Background: Email Threads2.1 Email Discussions supporting a Decision-Making ProcessThe focus of this paper is on email discussionssupporting a group decision-making process.
Incontrast to studies on individual email usage (foran overview see: Ducheneaut and Bellotti, 2001),this research area has been less explored.Occasionally, such discussions end with an onlinevote.
However, Ducheneaut and Belotti do notethat voting is relatively infrequent and our ownexperience with our email corpora tends to supportthis.In general, we expect that these threads containsupporting discussions, and the actual decisionmight occur outside of the email medium, forexample in a board meeting.
What we hope toobserve is that, for some issue discussed, candidatesolutions and responses highlighting the pros andcons of a solution are introduced via email.Decision-making discussion threads occurfrequently enough in environments which dependon professional usage of email.
In the corpus weexamined, 40% of the threads were decision-making discussions.2.2 Constraints on and Choice of a Corpus ofEmail DiscussionsTo collect a corpus of these threads, we placed afew constraints on the mailing list archives wefound online.To begin with, we focused on threads frommailing lists that were set up to supportorganization activities as these often involvedecision-making processes.
As we are alsointerested in examining the role of dialogue, werequired access to the email thread structure fromwhich we can infer a basic dialogue structure.We chose to use the archives of the ColumbiaUniversity ACM Student Chapter Committee asthis group has organized several events and usedemail as their primary mode of communicationoutside of meetings.
For practical reasons, it wasrelatively straightforward to obtain the necessarypermissions to use the data, something that mightbe more difficult for other archives.
Possiblealternative corpora might be the mailing lists oforganizing committees, for example that of aconference organizing committee or a steeringgroup.
Project-based mailing lists might also bepotentially used, especially if the groupparticipants have sufficient shared background toengage in discussions.2.3 Observations on Thread StructureThe Columbia University ACM Student ChapterCommittee was made up of about 10 people.
Uponinitial examination of the data, we found that wecould classify the threads of email according to itspurpose.
The set of group tasks facilitated by theemail correspondence were: decision-making,information provision, requests for action andsocial conversation.However, it is natural for the group to engage inmultiple tasks.
Thus, we use the term ?task shift?to refer to adjacent segments of the thread(comprised of emails) which reflect distinct groupgoals.
In the corpus we use, we observe that thesetasks usually occur sequentially.
In some cases, asingle email proposes more than one issue fordiscussion, and subsequent responses address eachof these in turn.Intuitively, it makes sense to create a summaryfor a single task.
Accordingly, we have designedour algorithm to accept only dialogue structuresaddressing a single group task.
If discussionsinvoke short clarification questions, these shouldnot be treated differently if the task remains thesame.
One supporting reason for this is thesyntactic variation with which participants expressdisagreement.
We have observed thatdisagreement is often expressed as a clarificationquestion, or as a question which offers analternative suggestion.3 Related WorkTo date, email thread summarization has notbeen explored in any great depth within the NaturalLanguage Processing (NLP) research community.Research on thread summarization has includedsome work on using dialogue structure for emailsummarization.
Nenkova et al (2003) advocatethe use of overview sentences similar to ours.They extract sentences based on the presence ofsubject line key words.
However, should thesubject line not reflect the content of the thread,our method has the potential to extract the truediscussion issue since it based on the responses ofother participants.Lam et al (2002) use the context of thepreceding thread to provide backgroundinformation for email summaries.
However, theynote that even after appropriate preprocessing ofemail text, simply concatenating preceding contextcan lead to long summaries.
In contrast, instead ofextracting email texts verbatim, we extract singlesentences from particular emails in the thread.
As aresult, our summaries tend to be much shorter.Murakoshi et al (1999) describe an approachwhich extracts question-answer pairs from anemail thread.
Extraction is based on the use ofpattern-based information extraction methods.
Thesummary thus provides the question-answer pairintact, thereby improving the coherence.
Question-answer summaries would presumably be suited todiscussions which support an informationprovision task, a complementary task to the one weexamine.Rambow et al (2004) apply sentence extractiontechniques to the thread to construct a genericsummary.
Though not specifically using dialoguestructure, one feature used marks if a sentence is aquestion or not.Work has also been done on more accuratelyconstructing the dialogue structure.
Newman andBlitzer (2003) focus on clustering relatednewsgroup messages into dialogue segments.
Thesegments are then linked using email headerinformation to form a hierarchical structure.
Theirsummary is simply the first sentence from eachsegment.
We envisage dialogue structuresummaries showing an overview of topics wouldbe combined with approaches such as ours whichprovide summaries of segments.We also note the existing work that explores thesummarization of speech transcripts.
Speech is avery different mode of communication.
Anoverview of the differences between asynchronousand synchronous modes of communication isprovided by Clark (1991) and Simpson-Young etal.
(2000).
Alexandersson et al (2000) note that inspeech there is a tendency not to repeat sharedconversation context.
They use the precedingdialogue structure, modeled using DialogueRepresentation Theory, to provide additionalellipsed information.
It is unclear how such anapproach might apply to an email corpus which hasthe potential to cover a broader set of domains.More recently, Zechner and Lavie (2001)identify question-answer dialogue segments inorder to extract the pair as a whole.Hillard et al (2003) have also produced a systemwhich generates summaries of speech discussionssupporting a decision-making process.
Their workdiffers from ours in that they focus on categorizingthe polarity of responses in order to summarizeconsensus.4 Issue DetectionTo make the problem more manageable wemake the following assumptions about the types ofthreads that our algorithm will handle.
To beginwith, we assume that the threads have beencorrectly constructed and classified as discussionssupporting decision-making.
Needless to say, thefirst assumption is a little unrealistic given thatthread construction is a difficult problem.
Forexample, it is not uncommon to receive emailswith recycled subject lines simply because replyingto an email is often more convenient than typing inan address.The other assumptions we make have to do withthe dialogue structure of the threads.
The first isthat the issue being discussed (usually a statementdescribing the matter to be decided) is to be foundin the first email.
The second is that the emailthread doesn?t shift task, nor does it containmultiple issues.The first assumption is based on what we haveobserved to be normal behavior.
Exceptions to thisrule are broken threads and cases where theparticipants have responded to a forwarded email.In the first case, this can be seen as an error inthread construction and identification.
In suchcases however, even in such a thread, the firstemail usually contains a reference to the issue athand, although it may be an impoverishedparaphrase.
Our algorithm extracts theseparaphrases in lieu of the original wording.
Caseswhere participants have responded to a forwardedemail are not common.
For such threads, weattempt to extract the sentence participants respondto.
However, again, this may not be the bestformulation of the issue.Secondly, we assume that a text segmentationalgorithm (for examples see Hearst?s ?Text-Tiling?algorithm 1997, Choi et al 2000) has alreadysegmented the threads according to shifts in task.Operationally, our detection of shifts in task wouldthen be based on corresponding changes invocabulary used.4.1 The AlgorithmOur summarization approach is to extract a set ofsentences consisting of one issue, and thecorresponding responses ?
one per participant.Our sentence extraction mechanisms borrow frominformation retrieval methods which represent textas weighted term frequency vectors (for anoverview see: Salton and McGill, 1983).In Figure 3, we present the general framework ofthe algorithm.
In this framework we divide thethread into two parts, the initiating email and thereplies.
We create a comparison vector thatrepresents what the replies are about.
We canconstruct variations of this framework by changingthe way we build our comparison vector.
The aimis to compare each sentence to the comparisonvector for the replies.
Thus, we build separatevector representations, called candidate vectors, foreach sentence in the first email.
Using the cosinesimilarity metric to compare candidate vectors withthe comparison vector, we rank the sentences ofthe first email.
Conceptually, the highest rankedsentence will be the one that is closest in content tothe replies and this is extracted as the issue of thediscussion.1.
Separate thread into issue_email  and replies2.
Create ?comparison vector?
V representing replies3.
For each sentence s in issue_email3.1 Construct vector representation S for sentence s3.2   Compare V and S using cosine similarity4.
Rank sentences according to their cosine similarityscores5.
Extract top ranking sentenceFigure 3.
Framework for extracting discussionIssues.We now discuss the four methods for buildingthe comparison vector.
These are:1.
The Centroid method2.
The SVD Centroid method.3.
The SVD Key Sentence method4.
Combinations of methods: Oracles4.1.1 The Centroid MethodIn the Centroid method, we first build a term bysentence (t ?
s) matrix, A, from the reply emails.In this matrix, rows represent sentences andcolumns represent unique words found in thethread.
Thus, the cells of a row store the termfrequencies of words in a particular sentence.From this matrix, we form a centroid to representthe content of the replies.
This is a matter ofsumming each row vector and normalizing by thenumber of rows.
This centroid is then what we useas our comparison vector.4.1.2 The SVD Centroid MethodOur interpretation of the SVD results is based onthat of Gong and Liu (1999) and Hoffman (1999).Gong and Liu use SVD for text segmentation andsummarization purposes.
Hoffman describes theresults of SVD within a probabilistic framework.For a more complete summary of our interpretationof the SVD analysis see Wan et al (2003).To begin with, we construct the matrix A as inthe Centroid Method.
The matrix A provides arepresentation of each sentence in wdimensionality, where w is the size of thevocabulary of the thread.
The SVD analysis1 is theproduct of three matrices U, S and V transpose.
Inthe following equation, dimensionality is indicatedby the subscripts.SVD(At ?
s) = Ut ?
r Sr ?
r(Vs ?
r) trConceptually, the analysis essentially maps thesentences into a smaller dimensionality r, whichwe interpret as the main ?concepts?
that arediscussed in the sentences.
These dimensions, orconcepts, are automatically identified by the SVDanalysis on the basis of similarities of co-occurrences.
The rows of V matrix represent thesentences of the first email, and each row vectordescribes how a given sentence relates to thediscovered concepts.
Importantly, the number ofdiscovered concepts is less than or equal to thevocabulary of the thread in question.
If it is lessthan the vocabulary size, then the SVD analysishas been able to combine several related terms intoa single concept.
Conceptually, this corresponds tofinding word associations between synonymsthough in general, this association may notconserve part-of-speech.
In contrast to the valuesof the A matrix which are always positive (sincethey are based on frequencies), the values of eachcell in the V matrix can be negative.
Thisrepresents the degree to which the sentence relatesto a particular concept.
We build a centroid fromthe V matrix to form our comparison vector.4.1.3 The SVD Key Sentence MethodThe SVD Key Sentence Method is similar to thepreceding method.
We build the matrix A, applythe SVD analysis and obtain the matrix V.   Insteadof constructing a vector which represents all of thereplies, we choose one sentence from the repliesthat is most representative of the thread content.This is done by selecting the most importantconcept and finding the sentence that contains themost words related to it.
The SVD analysis bydefault sorts the concepts according to degree towhich sentences are associated with it.
By thisdefinition, the most important sentence is1We use the SVD function in the JAMA Java MatrixPackage (http://math.nist.gov/javanumerics/jama/) tocompute the analysis.represented by the values in the first column of thematrix V.  We then take the maximum of thiscolumn vector and note its row index, r, whichdenotes a sentence.
We use the rth  row vector ofthe V matrix as the comparison vector.In both the SVD Centroid method and the SVDKey Sentence method, the comparison vector has adifferent dimensionality than the candidate vectors.To perform the comparison, we must map thecandidate vectors into this new dimensionality.This is done by pre-multiplying each candidatevector with the result of the matrix multiplication:Utranspose ?
S.  Both of the matrices involved areobtained from the SVD analysis.4.1.4 Combinations of methods: OraclesSince we have three alternatives for constructingthe comparison vector we consider the possibilityof combining the approaches.
In Wan et al (2003)we showed that using a combination of traditionalTF?IDF approaches and SVD approaches wasuseful given that SVD provided additionalinformation about word associations.
Similarly,our two SVD methods provide complementaryinformation.
The vector computed by the SVDcentroid method provides information about thereplies and accounts for word associations such assynonyms.
However, like the centroid method,this vector will include all topics discussed in thereplies, even small digressions.
In contrast, theSVD Key sentence is potentially better at ignoringthese digressions by focusing on a single concept.We present three heuristic oracles whichessentially re-rank the candidate issue sentencesidentified by each of the three methods.
Re-ranking is based on a voting mechanism.
The rulesfor three oracles are presented in Figures 4 and 5.1.
If a majority exists return it2.
If tie then:retrieve the lowest index number i,where i    13.
If all methods return different answers, thenchoose Centroid Method?s answerFigure 4.
Oracle 1 heuristic rulesThe oracle in Figure 4 attempts to choose thebest sentence, retrieving a single sentence.
Rule 2attempts to encode the intuition that the issuesentence is likely to occur early in the email,however, not usually at the top of the email.Finally, we use the Centroid Method as a defaultbecause it is less prone to errors arising from lowvocabulary sizes found in shorter threads.
Forsuch threads, we found that SVD approaches tendnot to perform so well.The second oracle again relies on a majorityvote.
However, it relaxes the constraint of justreturning a single sentence if the majority is thefirst sentence of the email.
Since we tend not tofind issue sentences in at the very top of emails, wereturn all possible issue sentences in rule 1.1.
If a majority exists then return it;UNLESS i = 1 in which case, return allchoices2.
If tie then retrieve the lowest index number i,where i    13.
If all methods return different answers, thenchoose Centroid Method?s answerFigure 5.
Oracle 2 heuristic rulesFinally, as a baseline, the third oracle returns allthe possible issue sentences identified by all of thecontributing methods.5 Extracting the Responses to the IssueTo extract the responses to the issue, we simplytake the first sentence of the replies of eachresponding participant.
We make sure to onlyextract one response per participant.An alternative solution analogous to that of issuedetection was also considered.
In this solution, weapplied the issue detection algorithm to the replyemail in question.
However, it turns out that mostof the tagged responses occurred at the start ofeach reply email and a more complex approachwas unnecessary and potentially introduced moreerrors.6 Evaluation of Issue Detection Algorithms6.1 The Test DataThe test data used was a portion of the ColumbiaACM Student Chapter corpus.
This corpusincluded a total of 300 threads which wereconstructed using message-ID information foundin the header.
On average, there were 190 wordsper thread and 6.9 sentences in the first email.Threads longer than two emails2 werecategorized manually.
We identified discussionsthat supported a decision-making process.
Forthese, we manually annotated the issue of thethread and the responses to the issue.
Although wedo not currently use this information, we alsoclassified the responses as being either inagreement or disagreement.
According to theassumptions listed in Section 4, we discarded thosethreads in which the issue was not found in the firstemail.
In total, we identified 37 discussion2Longer threads offered a great chance of identifyinga discussion.threads, each of which forms a test case.
A manualannotation of the discussion issues was done byfollowing the instruction: Select the sentence fromthe first email that subsequent emails areresponding to.?
These annotated issue sentencesformed our gold standard.Our approach was designed to operate on thenew textual contributions of each participant.Thus, the emails underwent a limitedpreprocessing stage.
Email headers, automaticallyembedded ?reply context?
text and static signatureswere ignored.6.2 Evaluation Framework and ResultsThe evaluation was designed to test if ourmethods which use dialogue structure improvesentence extraction results.
We used the recall-precision metric to compare the results of a systemwith the manually annotated gold standard.
Intotal, we tested 6 variations of our issue detectionalgorithms.
These included the Centroid method,the SVD Centroid method and the SVD KeySentence method and the 3 oracles.For each test case, the approach being tested wasused to extract one or more sentencescorresponding to the issue of the discussion, whichwas then compared to the gold standard.
Thebaseline used was the first n sentences of the firstemail as a summary, where n ranged from 1 to 3sentences.The recall-precision results of the evaluation arepresented in Table 1.
On average, the chance ofcorrectly choosing the correct sentence randomlyin a test set was 21.9%.We used an ANOVA to test whether there wasan overall effect between the various methods forrecall and precision.
We rejected the nullhypothesis, that is, the choice of method doesaffect recall and precision (?=0.05, dfnumerator= 8,dfdenoinator= 324).To determine if our techniques were statisticallysignificant compared to the baselines, we ran pair-wise two-tailed student t-tests to compare the threemethods and the first oracle to the n=1 baselinesince these all returned a single sentence.
Theresults are presented in Table 2.
Similarly, Table3 shows the t-test comparisons for the oracle andoracle baseline against the n=3 baseline.Except for the SVD Key Sentence method, allthe methods were significantly better than the n=1baseline.
However, a useful recall score was onlyobtained using the oracle methods.
Whencomparing the oracle methods which returnedmore than one sentence against the n=3 baseline,we found no significant difference in recall.However, when comparing precision performancewe found that the difference between the precisionof Centroid method and the three oracles weresignificantly different compared to the baseline.Method Ave.Recall % Ave. Prec.
&Centroid 62.2 62.2SVD Centroid 48.6 48.6SVD Key Sent 37.8 37.8Oracle 1 62.2 62.2Oracle 2 70.3 62.7Oracle Baseline 83.8 45.1Baseline n=1 24.3 24.3Baseline n=2 48.6 24.3Baseline n=3 64.0 21.6Table 1.
Average recall and precision values foreach method.Method Prob(Recall)  Prob(Prec.
)Centroid 0.0016 0.0016SVD Centroid 0.0187 0.0187SVD Key Sent 0.1601 0.1601Oracle 1 0.0004 0.0004Table 2.
Pair-wise t-test scores comparing eachmethod to the n=1 baseline (df = 36).
The valuesshow the probability of the obtained t value.Method Prob(Recall)  Prob(Prec.
)Oracle 2 0.5998 0.0001Oracle Baseline 0.1686 0.0108Table 3.
Pair-wise t-test scores comparing eachmethod to the n=3 baseline (df = 36).
The valuesshow the probability of the obtained t value.The recall and precision statistics for theCentroid method was the most impressive of thethree methods proposed, far outperforming thebaseline.
The results of comparisons involving theoracles, which combine the three methods, showedimproved performance, suggesting that suchtechniques might potentially be useful in an emailthread summary.
Whilst there was little differencebetween the recall values of the three oracles andthe baselines, the benefit of using a more involvedapproach such as ours is demonstrated clearly bythe gain in precision performance which willimpact the usefulness of such a summary.
It isalso interesting to note that the performance of theoracles was achieved by simply using simple ruleswithout any corpus training.7 Conclusion and Future WorkThe methods described in this paper would formpart of a larger email thread summarizer able toidentify task boundaries and then initiate theappropriate summarization strategy for that task.We have addressed the sub-problem ofsummarizing the decision-making processes whichhave been supported by discussions over email.Despite the preliminary nature of our investigation,our findings are encouraging and lend support tothe view that a combination of simple word vectorapproaches with singular value decompositionapproaches do well at extracting discussion issues.Such methods, even with only a simple notiondialogue structure achieve a useful level of recalland precision.
We would like to conduct extrinsicexperiments to test our assumptions about theusefulness of these summaries.
Furtherinvestigations will also focus on examine issues ofscalability, with regard to group size, and domainindependence.
We would also like to investigatehow issue detection might be integrated with amore complete solution to email threadsummarization.8 AcknowledgementsThe research described in this paper waspartially supported by a grant provided throughNSF's Knowledge Discovery and DisseminationProgram.
We would like to thank the NLP groupsof Columbia University, Macquarie University andCSIRO for feedback received on this work.ReferencesJ.
Alexandersson, P. Poller, M. Kipp, and R. Engel.2000.
Multilingual Summary Generation in aSpeech-To-Speech Translation System forMultilingual Dialogues.
In Proc.
of INLG-2000,Mitzpe Ramon, Israel.B.
Simpson-Young, N. Ozkan, C.Paris, C. Chung,J.
Brook, K. Yap.
2000 Video Messaging:Addressing the Characteristics of the Medium.
Inthe Proceedings of the Euromedia 2000Conference.
Antwerp, May 2000.Borko, H., and Bernier, C. 1975 AbstractingConcepts and Methods.
New York: AcademicPress.F.Y.Y.
Choi.
2000 Advances in domainindependent linear text segmentation.
In theProc.
of the North American Chapter of theAssociation.
for Comp.
Linguistics, pp.
26-33.Clark, H.H.
and S.E Brennan.
1991.
Grounding inCommunication?
In Readings in Groupware andComputer-Supported Collaborative Work, R.M.Baeker, ed.
Morgan Kaufmann, California, 222-223.Nicolas Ducheneaut, Victoria Bellotti 2001.
E-mailas habitat: an exploration of embedded personalinformation management, interactions.
inCommunications of the ACM v.8 n.5, p.30-38.Dustin Hillard, Mari Ostendorf, and ElizabethShriberg 2003.
Detection Of Agreement vs.Disagreement In Meetings: Training WithUnlabeled Data.
in the Proc.
HLT-NAACLConference, Edmonton, Canada, May 2003.Gong Y., and Liu, X.
2001.
Generic TextSummarization Using Relevance Measure andLatent Semantic Analysis.
In the ProceedingsSIGIR 2001: pages 19-25.M.
Hearst.
1994.
Multi-paragraph segmentation ofexpository text.
In the Proc.
of the 2nd AnnualMeeting of the Association for ComputationalLinguistics, Las Cruces, NM.Hiroyuki Murakoshi, Akira Shimazu, and KoichiroOchimizu.
1999.
Construction of DeliberationStructure in Email Communication.
InProceedings of the Pacific Association forComputational Linguistics (PACLING'99), pages16--28, Aug.T.
Hofmann.
1999.
Probabilistic latent semanticanalysis, in the Proceedings of the FifteenthConference on Uncertainty in ArtificialIntelligence, Morgan Kaufmann Publishers, SanFrancisco, CA, pp.
289-296.Lam, Derek and Rohall, Steven L. and Schmandt,Chris and Stern, Mia K. 2002.
Exploiting E-mailStructure to Improve Summarization.
TechnicalPaper at IBM Watson Research Center #20-02Ani Nenkova and Amit Bagga.
2003.
Facilitatingemail thread access by extractive summarygeneration.
In Proceedings of RANLP, Bulgaria.Newman and Blitzer, Paula Newman and JohnBlitzer.
2002.
Summarizing ArchivedDiscussions: a Beginning.
In the Proceeding ofIntelligent User Interfaces.G.
Salton and M. J. McGill.
1983.
Introduction tomodern information retrieval, McGraw-Hill,New York.Owen Rambow, Lokesh Shrestha, John Chen andChristy Laurdisen.
2004.
Summarizing EmailThreads.
In the Proc.
of HLT-NAACL 2004:Short Papers.Stephen Wan, Mark Dras, C?cile Paris, RobertDale.
2003.
Using Thematic Information inStatistical Headline Generation.
In theProceedings of the Workshop on MultilingualSummarization and Question Answering at ACL2003, July 11, Sapporo, JapanK.
Zechner and A. Lavie.
2001 Increasing thecoherence of spoken dialogue summaries bycross-speaker information linking.
InProceedings of the NAACL-01 Workshop onAutomatic Summarization, Pittsburgh, PA, June,2001.
