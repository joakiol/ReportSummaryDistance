Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 1?8,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsImprovements in unsupervised co-occurrence based parsingChristian Ha?nigDaimler AGResearch and Technology89081 Ulm, Germanychristian.haenig@daimler.comAbstractThis paper presents an algorithm for unsu-pervised co-occurrence based parsing thatimproves and extends existing approaches.The proposed algorithm induces a context-free grammar of the language in questionin an iterative manner.
The resulting struc-ture of a sentence will be given as a hier-archical arrangement of constituents.
Al-though this algorithm does not use any apriori knowledge about the language, itis able to detect heads, modifiers and aphrase type?s different compound compo-sition possibilities.
For evaluation pur-poses, the algorithm is applied to manuallyannotated part-of-speech tags (POS tags)as well as to word classes induced by anunsupervised part-of-speech tagger.1 IntroductionWith the growing amount of textual data availablein the Internet, unsupervised methods for naturallanguage processing gain a considerable amountof interest.
Due to the very special usage of lan-guage, supervised methods trained on high qualitycorpora (e. g. containing newspaper texts) do notachieve comparable accuracy when being appliedto data from fora or blogs.
Huge annotated corporaconsisting of sentences extracted from the Internetbarely exist until now.Consequential a lot of effort has been put intounsupervised grammar induction during the lastyears and results and performance of unsuper-vised parsers improved steadily.
Klein and Man-ning (2002)?s constituent context model (CCM)obtains 51.2% f-score on ATIS part-of-speechstrings.
The same model achieves 71.1% on WallStreet Journal corpus sentences with length ofat most 10 POS tags.
In (Klein and Manning,2004) an approach combining constituency anddependency models yields 77.6% f-score.
Bod(2006)?s all-subtree approach ?
known as Data-Oriented Parsing (DOP) ?
reports 82.9% forUML-DOP.
Seginer (2007)?s common cover linksmodel (CCL) does not need any prior tagging andis applied on word strings directly.
The f-scorefor English is 75.9%, and for German (NEGRA10)59% is achieved.
Ha?nig et al (2008) present a co-occurrence based constituent detection algorithmwhich is applied to word forms, too (unsupervisedPOS tags are induced using unsuPOS, see (Bie-mann, 2006)).
An f-score of 63.4% is reported forGerman data.In this paper, we want to present a new unsu-pervised co-occurrence based grammar inductionmodel based on Ha?nig et al (2008).
In the fol-lowing section, we give a short introduction to thebase algorithm unsuParse.
Afterwards, we presentimprovements to this algorithm.
In the final sec-tion, we evaluate the proposed model against ex-isting ones and discuss the results.2 Co-occurrence based parsingIt has been shown in (Ha?nig et al, 2008) thatstatistical methods like calculating significant co-occurrences and context clustering are applicableto grammar induction from raw text.
The underly-ing assumption states that each word prefers a cer-tain position within a phrase.
Two particular casesare of special interest: a word?s occurrence at thebeginning of a sentence and a word?s occurrence atthe end of a sentence.
Those positions obviouslyare constituent borders and can be easily used toextract syntactic knowledge.
One possibility is todiscover constituents employing constituency tests(see (Adger, 2003)), whereby these two cases canbe used to express and use one of them in a formalway: the movement test.Three neighbourhood co-occurrences expressthe aforementioned observations:1?
Value a denotes the significance of word Astanding at the last position of a sentence(where $ is an imaginary word to mark a sen-tences?
end).a = sig (A, $) (1)?
Contrary, variable b denotes the significanceof a word B being observed at the beginningof a sentence (where ?
is an imaginary wordto mark the beginning of a sentence).b = sig (?
, B) (2)?
Additionally, a third value is necessary to rep-resent the statistical significance of the neigh-bourhood co-occurrence containing word Aand B.c = sig (A,B) (3)To compute those significance values for a corpus,the log-likelihood measure (see (Dunning, 1993))is applied using corpus size n, term frequenciesnA and nB (for the words A and B) and frequencynAB of the co-occurrence of A and B.To detect constituent borders between twowords, a separation value sepAB can be definedas:sepAB =ac ?bc =a ?
bc2 (4)If word A occurs more significantly at the end ofa sentence as in front of B, then ac > 1.
Addi-tionally, b is larger than c if B is observed moresignificantly at the beginning of a sentence as af-ter A and bc will be > 1.
In this case sepAB is> 1 and obviously, a constituent border would besituated between A and B.The basic approach to create parse trees fromseparation values between two adjacent words isto consecutively merge the two subtrees contain-ing the words with the smallest separation valuebetween them ?
starting with each word in a sep-arate subtree.
In order to avoid data sparsenessproblems, co-occurrences and separation valuesare primarily calculated on part-of-speech tags.However, word co-occurrences will be used to pre-serve word form specific dependencies.In this paper, we want to present unsuParse+?
an extension of this co-occurrence based ap-proach.
The first extension is the distinction be-tween endocentric and exocentric elements whichintroduces the detection of heads along with theirmodifiers (see section 2.2).
Furthermore, learningof recursive constructions is facilitated.
Secondly,we will consider discontiguous dependencies andpresent a possibility to detect rare constructionslike complex noun phrases (see section 2.3).
Asthird enhancement, we employ a simple cluster-ing algorithm to induced phrases in order to detectconstituents holding identical syntactic functions.Those phrases will be labeled the same way in-stead of by different phrase numbers (see section2.4).First, we will start with the detection of con-stituent candidates.2.1 Detection of constituent bordersInstead of using sepAB to detect constituent bor-ders we use neighbourhood co-occurrence signif-icances on account of an experiment in (Ha?nig etal., 2008) showing that the pure significance valuec is sufficient.Furthermore, we do not restrict the detectionof phrases to bigrams and allow the detection ofarbitrary n-grams.
The motivation behind this isbasically caused by coordinating conjunctions forwhich discussions on the correct1 structure areraised.
While Chomsky (1965) argues in favor ofsymmetric multiple-branching coordinating con-structions (see Figure 1), recent discussions in thecontext of unification grammars (especially head-driven phrase structure grammar (see (Pollard andSag, 1994)) prefer asymmetric endocentric con-structions (see (Kayne, 1995) and (Sag, 2002)).The corresponding structure can be seen in Figure2.
Nevertheless, a symmetric construction con-taining two heads seems to be more appropriate forsome languages (e. g. German, see (Lang, 2002)).NPNNS CC NNScats and dogsFigure 1: Symmetriccoordinating conjunc-tionConJNNS Conj?cats CC NNSand dogsFigure 2: Asymmetriccoordinating conjunc-tion1correct meaning considered to be correct2Thus, the presented algorithm is able to dealwith phrases containing any number of com-pounds.As in (Ha?nig et al, 2008), phrases will belearned in an iterative manner (see details in sec-tion 2.5).
Within each iteration, the n-gram Pyielding the highest significance is considered tobe the best candidate for being a valid constituent.P = [p0 .
.
.
pn?1] (5)The preferred position of part-of-speech tags ismaintained as we define pref (A) for every POStag A.
This value is initialized as the ratio of twoparticular significances as in Equ.
6:pref (A) = sig (?
, A)sig (A, $) (6)Analogous to sepAB (see section 2) pref (A) is> 1 if POS tag A prefers the first position withina phrase and vice versa.Before a phrase candidate is used to create anew grammar rule, its validity has to be checked.Using the assumption that every word prefers acertain position within a constituent leads us tocheck the first word of a phrase candidate for pre-ferring the first position and the last word for fa-voring the last one.But there are at least two exceptions: coordi-nating conjunctions and compound nouns.
Thoseconstructions (e. g. cats/NNS and/CC dogs/NNS,dog/NN house/NN) usually start and end with thesame phrase respectively POS tag.
This wouldlead to wrong validation results, because NNSor NN do prefer the last position within a con-stituent and should not occur at the beginning.
Asboth constructions are endocentric, they prefer thehead?s position within the superordinating phraseand thus, their existence does not stand in contrastto the assumption made about preferred positions.Formally, we get the following proposition:valid (P )?
p0 = pn?1 ?pref (p0) ?
?
?
pref (pn?1) ?1?
(7)An uncertainty factor is introduced by ?, as someparts-of-speech tend to not appear at the bordersof a sentence although they prefer a certain posi-tion within constituents.
Some examples (given inTable 1) of the 5 most frequent English2 and Ger-2Penn Tree Tagset, see (Marcus et al, 1993)man3 parts-of-speech will demonstrate this effect.English GermanNN 0.08 NN 0.30IN 31.45 ART 242.48NNP 1.39 APPR 143.62DT 84.19 ADJA 5.06NNS 0.31 NE 1.11Table 1: Values of pref (POS) for the 5 most fre-quent parts-of-speech of English and GermanIn both languages proper nouns (NNP resp.
NE)occur slightly more often at the beginning of a sen-tence than at its end, although proper nouns pre-fer ?
like normal nouns ?
the last position of aphrase.
To account for this effect, pref (A) will beiteratively adapted to the observations of learnedgrammar rules as given in Equ.
8:pref (p0)?1?
?
pref (p0)pref (pn?1)?
?
?
pref (pn?1)(8)Due to iterative learning of rules, we can useknowledge obtained during a previous itera-tion.
Every rule contains reinforcing informationabout the preferred position of a part-of-speech.pref (A) is adapted by a factor ?
(with 0 < ?
< 1)for the corresponding parts-of-speech and it willconverge to its preferred position.In later iterations, significances of phrase can-didates do not differ considerably from each otherand thus, the order of phrase candidates is not veryreliable anymore.
Consequently, parts-of-speechoccur at non-preferred positions more often andtrustworthy knowledge (in form of pref (A))about the preferred positions of parts-of-speech isvery helpful to avoid those phrase candidates frombeing validated.We want to give one example for English: ad-jectives (JJ).
Before the first iteration, pref (JJ)is initialized with 1.046 which means that JJ hasno preferred position.
The most significant rulescontaining JJ are JJ NN, JJ NNS and JJ NNP?
supporting a preference of the first positionwithin a constituent.
An iterative adaption ofpref (JJ) will represent this observation and dis-approve constituents ending with JJ (like DT JJ orIN JJ) in upcoming iterations.3Stuttgart-Tu?bingen Tagset, see (Thielen et al, 1999)3After having detected a new and valid con-stituent, we can use context similarity and otherstatistical methods to learn more about its be-haviour and inner construction.2.2 Classification into endocentric andexocentric constructionsEndocentric constructions contain a head ?
ormore than one in symmetric coordinate construc-tions ?
which is syntactically identical to the en-docentric compound.
Additionally, at least oneoptional element subordinating to the head is con-tained in the construction.
An exocentric con-struction on the other hand does not contain anyhead element which is syntactically identical to thewhole construction.The following example sentences will demon-strate the distinction of these two types.
Sentence(a) contains a determiner phrase (DP: a new car)which has a noun phrase embedded (NP: new car).The NP can be replaced by its head as in sentence(b) and thus is regarded to be endocentric.
The DPis exocentric ?
it can neither be replaced by thedeterminer (sentence (c)) nor by the NP (sentence(d)) without losing its syntactical correctness.
(a) I buy a new car.
(b) I buy a car.
(c) * I buy a.
(d) * I buy new car.Detection of endocentric constructions yieldsvaluable information about the language in ques-tion.
It is possible to detect heads along with theirmodifiers without any a priori knowledge.
Fur-thermore, detection of optional modifiers reducesthe complexity of sentences and thus, facilitateslearning of high precision rules.Without classification into endocentric and exo-centric constructions, two rules (P#1?
JJ NNand P#2 ?
JJ P#1 would be necessary toparse the phrase first civil settlement as given inFigure 3.
Using knowledge about subordinatingelements achieves the same result (see Figure 4)with one rule (NN ?
JJ NN ).
Addition-ally, data-sparseness problems are circumventedas no rare occurrences like JJ .
.
.
JJ NN needto be contained in the training corpus to eventu-ally parse those phrases.Following the definition of endocentricity, aphrase containing a head and an optional elementP#2JJ P#1first JJ NNcivil settlementFigure 3: Structurewithout knowledgeabout endocentricityNNJJ NNfirst JJ NNcivil settlementFigure 4: Structureusing knowledgeabout endocentricityshould be equally distributed ?
in respect to itscontext ?
as the head.
Consequentially, a phraseis considered to be endocentric, if it contains anelement showing high context similarity (see Equ.9).endocentric (P )?
?i : sim (context (P ) , context (pi)) ?
?
(9)The global context context (P ) of a phrase orPOS tag P is the sum of all local contexts of Pwithin the training corpus.
We use the two leftand right neighbours including the aforementionedmarkers for the beginning and the end of a sen-tence if necessary.
We apply the Cosine Measureto calculate the similarity between the two con-texts and in case of passing a defined threshold ?,the phrase is considered to be endocentric.
See Ta-ble 2 for some examples (?
= 0.9).NNS ?
JJ NNSNN ?
JJ NNNNP ?
NNP CC NNPNN ?
NN CC NNVBZ ?
RB VBZTable 2: Examples of endocentric constructions2.3 Discontiguous dependenciesAdditionally to endocentric constructions contain-ing a head and a modifier, some parts-of-speechlike articles and possessive pronouns do not occurwithout a noun or noun phrase.
While those parts-of-speech are grouped together as determiners(DT) in the Penn Tree Tagset, for other tagsets andlanguages they might be distributed among multi-ple classes (as in the German Stuttgart?Tu?bingen4Tagset among ART, PPOSAT, PIAT .
.
.).
To de-tect such strong dependencies, we propose a sim-ple test measuring the relative score of observingtwo words A and B together within a maximumrange n.depn (A,B) =?nd=0 freq (A,B, d)min (freq (A) , freq (B))(10)Equ.
10 formally describes the relative scorewhere freq (A,B, d) denotes the frequency of Aand B occurring together with exactly d othertokens between them.
If depn (A,B) passes athreshold ?
(0.9 for our experiments), then thedependency between A and B is allowed to oc-cur discontiguously.
Including these dependen-cies facilitates the parsing of rare and insignificantphrases like adjectival phrases.NPART AP NNDer mit zwei FestplattenausgestatteteComputerThe with two disksequippedcomputerFigure 5: Adjectival PhraseIn the example given in Figure 5, the discon-tiguous dependency between articles (ART) andnormal nouns (NN) can be applied to two possi-ble word pairs.
On the one hand, there is Der .
.
.Festplatten (The .
.
.
disks), the other possibility isDer .
.
.
Computer (The .
.
.
computer).
We choosethe pair achieving the highest neighbourhood co-occurrence significance.
Regarding our example,it is quite obvious that Computer is the noun tochoose as Der and Computer show grammaticalagreement while this is not the case for Festplat-ten.
Consequently, the significance of Der Com-puter is much higher than the one of Der Festplat-ten.
Although articles and other parts-of-speechare not unambiguous regarding gender, numberand case for all languages, this approach can re-solve some of those cases for certain languages.2.4 Phrase ClusteringOne objection to unsupervised parsing is the factthat phrases belonging to the same phrase type arenot labeled the same way.
And of course, withoutany prior knowledge, induced phrases will neverbe labeled NP, PP or like any other known phrasetype.
This complicates the application of any fur-ther algorithms relying on that knowledge.
Never-theless, it is possible to cluster syntactic identicalphrases into one class.As in section 2.2, similarity between two globalcontexts is calculated.
If the similarity of phrase P(the one being tested) and Q (see most similar one,see Equ.
11) exceeds a threshold ?, then phrase Pis considered to have the same phrase type as Q(see Equ.
12).
In this case, P will be labeled bythe label of Q and thus, is treated like Q.Q = arg maxq ?
phrasessim (context (P ) , context (q))(11)Type (P ) = Type (Q)?
sim (P,Q) ?
?
(12)As it can be seen in Table 3 (?
= 0.9), cluster-ing finds syntactic similar phrases and facilitatesiterative learning as rules can be learned for eachphrase type and not for each composition.P#1 ?
DT JJ NNP#1 ?
DT NNP#1 ?
PRP$ NNSP#2 ?
IN P#1P#2 ?
IN NNP#2 ?
IN NNSTable 3: Results of phrase clustering2.5 Iterative learningLearning rules is realized as an iterative process.A flow chart of the proposed process is given inFigure 6.First, an empty parser model is initialized.
Atthe beginning of an iteration all rules are appliedto transform the corpus.
Resulting structures formthe data which is used for the next iteration.
Thesentence in Figure 7 will be transformed by al-ready induced rules.After application of rule NN ?
JJ NN , theoptional element JJ is removed (see Fig.
8).The next rule (P#1 ?
DT NN ) reduces thecomplexity of the sentence and from now on, fur-ther rules will be created on those parts-of-speechand phrases (see Fig.
9).Learning will be aborted after one of the follow-ing three conditions becomes true:5BeginInitializationApplication of induced rulesAbortlearning?
EndDetection ofnew phrase candidateValid?Endocentric?
Create a rulelabeled by its headDiscontinuity testSimilar toexistingphrase type?Create a rulelabeled byexisting phrase typeCreate a rulelabeled by a new unique labelYesNoYesNoNoYesYesNoFigure 6: Flow chartof the proposed learning process1.
The algorithm reaches the maximum numberof rules.2.
The last phrase candidate is not considered tobe significant enough.
A threshold in relationto the highest significance can be set up.3.
All sentences contained in the training corpusare reduced to one phrase.Afterwards, the most significant n-gram passingthe validity test will be regarded as a phrase.
In thefollowing steps, the label of the new phrase will bedetermined.
Either it is labeled by its head (in caseof an endocentric construction) or by a syntacticidentical phrase type that has been learned before.If neither is the case, it gets a new unique label.Afterwards, the next iteration is triggered.SDT JJ NN VBZ $ CDThe minimum unit is $ 100Figure 7: ExampleSDT NN VBZ $ CDThe is $ 100Figure 8: Example after application of ruleNN ?
JJ NNSP#1 VBZ $ CDis $ 100Figure 9: Example after additional application ofrule P#1 ?
DT NN3 EvaluationTo evaluate unsuParse+ against unsuParse andother unsupervised parsing algorithms, we applythe same experimental setup as in (Klein, 2005),(Bod, 2006) and (Ha?nig et al, 2008).
For Germanpunctuation and empty element tags are removedfrom the NEGRA corpus (see (Skut et al, 1998)).Afterwards, all sentences containing more than 10elements are dismissed.
The resulting corpus is re-ferred to as NEGRA10 (2175 sentences).
To takemore complex sentences into account, we also pre-pared a corpus containing sentences to a maximumlength of 40 elements (NEGRA40).We present results for both ?
POS tags andword strings.
As most unsupervised parsing mod-els (except (Seginer, 2007)), we apply the hand-annotated data of the NEGRA corpus.
Addition-ally, we used an unsupervised part-of-speech tag-ger (see (Biemann, 2006)) to tag the NEGRA cor-pus to be able to present a complete unsupervisedparsing process relying on word strings only.
Weapplied the model de40M which has been created6on a corpus containing 40 million sentences andcontains 510 word classes.To compare the performance of different pars-ing algorithms, we used the Unlabeled BracketsMeasure as in (Klein and Manning, 2002) and(Klein and Manning, 2004).
Additionally to un-labeled precision UP and unlabeled recall UR, theunlabeled f-score UF is defined as:UF = 2 ?
UP ?
URUP + UR (13)The baseline algorithm is based on neighbour-hood co-occurrences.
First, a parse tree is ini-tialized and all tokens of a sentence are added asleaves.
Afterwards, the two adjacent nodes con-taining the POS tags with the highest neighbour-hood co-occurrence significance are merged con-secutively until a binary tree has been created.Results for NEGRA10 are given in Table 4. un-suParse+ improves the performance of unsuParsein both categories: supervised and unsupervisedannotated POS tags.
While recall is improved sig-nificantly for hand-annotated data, just a slight im-provement is achieved for word strings.
Especiallyclustering of phrases leads to the increased recallas rules do not need to be learned for every possi-ble compound composition of a given phrase typeas they are already covered by the phrase typeitself.
Models based on unsuParse achieve thehighest precision among all models.
This is notvery surprising as most of the other models (ex-cept Common Cover Links) generate binary parsesachieving a higher recall.
Nevertheless, unsu-Parse+ yields comparable results and obtains thehighest f-score for German data.Parsing Model UP UR UFBaseline (POS tags) 35.5 66.0 46.2CCM 48.1 85.5 61.6DMV + CCM 49.6 89.7 63.9U-DOP 51.2 90.5 65.4UML-DOP ?
?
67.0U-DOP* ?
?
63.8unsuParse (POS tags) 76.9 53.9 63.4unsuParse+ (POS tags) 71.1 67.9 69.5Baseline (words) 23.6 43.9 30.7Common Cover Links 51.0 69.8 59.0unsuParse (words) 61.2 59.1 60.2unsuParse+ (words) 63.1 60.4 61.7Table 4: UP, UR and UF for NEGRA10Performance drops for more complex sentences(see Table 5).
As for short sentences, the recall ofour approach is in the same order as for the base-line.
However, precision is increased by a factorof two in comparison to the baseline, which is alsosimilar to short sentences.Parsing Model UP UR UFBaseline (POS tags) 24.8 49.3 33.0unsuParse+ (POS tags) 55.3 51.4 53.3Table 5: UP, UR and UF for NEGRA40Table 6 shows the most frequently over- andunder-proposed phrases for NEGRA10.
Noun andprepositional phrases are often over-proposed dueto a flat representation within the NEGRA corpus.The most frequently under-proposed phrase NENE is learned and classified as endocentric con-struction (NE ?
NE NE).
Due to the removal ofpunctuation, proper nouns which naturally wouldbe separated by e. g. commas will be representedby one flat phrase without deeper analysis of theinner structure.
This includes some underproposi-tions which will not occur while parsing sentencescontaining punctuation.Overproposed UnderproposedART NN 369 NE NE 42CARD NN 111 NN NE 35ADV ADV 103 ART NN NE 27ADJA NN 99 ADV ART NN 24APPR ART NN 93 APPR PPER 23Table 6: Most frequently over- and under-proposed constituents4 Conclusions and further workIn this paper, we presented an improved model forco-occurrence based parsing.
This model createshigh accuracy parses employing a constituent de-tection algorithm yielding competitive results.
Al-though no a priori knowledge about the languagein question is taken into account, it is possible todetect heads, modifiers and different phrase types.Especially noun phrases and prepositional phrasesare clustered into their respective classes.
For fur-ther processing like relation extraction, precise re-sults for the aforementioned phrase types are es-sential and provided by this algorithm in an unsu-pervised manner.Our future work will include the investigation ofunsupervised methods for dependency identifica-7tion between verbs and their arguments.
Further-more, the inclusion of further constituency testslike substitution and deletion could provide addi-tional certainty for constituent candidates.ReferencesDavid Adger.
2003.
Core Syntax: A Minimalist Ap-proach.
Oxford University Press.Chris Biemann.
2006.
Unsupervised part-of-speechtagging employing efficient graph clustering.
InProceedings of the COLING/ACL-06 Student Re-search Workshop, Sydney, Australia.Rens Bod.
2006.
An all-subtrees approach to un-supervised parsing.
In ACL-44: Proceedings ofthe 21st International Conference on ComputationalLinguistics and the 44th annual meeting of the Asso-ciation for Computational Linguistics.Noam Chomsky.
1965.
Aspects of the Theory of Syn-tax.
MIT Press, Cambridge, Massachusetts.Ted Dunning.
1993.
Accurate methods for the statis-tics of surprise and coincidence.
ComputationalLinguistics, 19(1):61?74.Christian Ha?nig, Stefan Bordag, and Uwe Quasthoff.2008.
Unsuparse: Unsupervised parsing with un-supervised part of speech tagging.
In Proceedingsof the Sixth International Language Resources andEvaluation (LREC?08).Richard S. Kayne.
1995.
The Antisymmetry of Syntax.MIT Press.Dan Klein and Christopher D. Manning.
2002.
Agenerative constituent-context model for improvedgrammar induction.
In ACL ?02: Proceedings of the40th Annual Meeting on Association for Computa-tional Linguistics.Dan Klein and Christopher D. Manning.
2004.Corpus-based induction of syntactic structure: mod-els of dependency and constituency.
In ACL ?04:Proceedings of the 42nd Annual Meeting on Associ-ation for Computational Linguistics.Dan Klein.
2005.
The Unsupervised Learning of Natu-ral Language Structure.
Ph.D. thesis, Stanford Uni-versity.Ewald Lang.
2002.
Die Wortart ?Konjunktion?.
InLexikologie.
Lexicology.
Ein Internationales Hand-buch zur Natur und Struktur von Wo?rtern undWortscha?tzen, pages 634?641.
de Gruyter.M.
Marcus, B. Santorini, and M. A. Marcinkiewicz.1993.
Building a large annotated corpus of en-glish: The penn treebank.
Computational Linguis-tics, 19(2):313?330.Carl Pollard and Ivan A.
Sag.
1994.
Head-DrivenPhrase Structure Grammar.
University Of ChicagoPress.Ivan Sag.
2002.
Coordination and underspecification.In roceedings of the Ninth International Conferenceon Head-Driven Phrase Structure Grammar.Yoav Seginer.
2007.
Fast unsupervised incrementalparsing.
In Proceedings of the 45th Annual Meetingof the Association of Computational Linguistics.Wojciech Skut, Thorsten Brants, Brigitte Krenn, andHans Uszkoreit.
1998.
A linguistically interpretedcorpus of german newspaper text.
In ESSLLI-98Workshop on Recent Advances in Corpus Annota-tion.C.
Thielen, A. Schiller, S. Teufel, and C. Sto?ckert.1999.
Guidelines fu?r das Tagging deutscher Tex-tkorpora mit STTS.
Technical report, University ofStuttgart and University of Tu?bingen.8
