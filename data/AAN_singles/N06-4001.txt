Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume, pages 253?256,New York City, June 2006. c?2006 Association for Computational LinguisticsInfoMagnets: Making Sense of Corpus DataJaime Arguello Carolyn Ros?Language Technologies Institute Language Technologies InstituteCarnegie Mellon University Carnegie Mellon UniversityPittsburgh, PA 15216 Pittsburgh, PA 15216jarguell@andrew.cmu.edu cprose@cs.cmu.eduAbstractWe introduce a new interactive corpusexploration tool called InfoMagnets.
In-foMagnets aims at making exploratorycorpus analysis accessible to researcherswho are not experts in text mining.
Asevidence of its usefulness and usability, ithas been used successfully in a researchcontext to uncover relationships betweenlanguage and behavioral patterns in twodistinct domains: tutorial dialogue(Kumar et al, submitted) and on-linecommunities (Arguello et al, 2006).
Asan educational tool, it has been used aspart of a unit on protocol analysis in anEducational Research Methods course.1 IntroductionExploring large text corpora can be a dauntingprospect.
This is especially the case for behavioralresearchers who have a vested interest in the latentpatterns present in text, but are less interested incomputational models of text-representation (e.g.the vector-space model) or unsupervised pattern-learning (e.g.
clustering).
Our goal is to providethis technology to the broader community of learn-ing scientists and other behavioral researchers whocollect and code corpus data as an important partof their research.
To date none of the tools that arecommonly used in the behavioral research com-munity, such as HyperResearch, MacShapa, orNvivo, which are used to support their corpusanalysis efforts, make use of technology more ad-vanced than simplistic word counting approaches.With InfoMagnets, we are working towards bridg-ing the gap between the text-mining communityand the corpus-based behavioral research commu-nity.
The purpose of our demonstration is to makethe language technologies community more awareof opportunities for applications of language tech-nologies to support corpus oriented behavioral re-search.Figure 1: InfoMagnets ScreenshotInfoMagnet?s novelty is two-fold: First, it pro-vides an intuitive visual metaphor that allows theuser to get a sense of their data and organize it foreasy retrieval later.
This is important during thesense making stage of corpus analysis work justbefore formal coding scheme development begins.Secondly, it allows the user to interact with cluster-ing technology, and thus influence its behavior, ineffect introducing human knowledge into the clus-tering process.
Because of this give and take be-tween the clustering technology and the human253influence, the tool is able to achieve an organiza-tion of textual units that is not just optimal from analgorithmic stand-point, but also optimal for theuser?s unique purpose, which non-interactive clus-tering algorithms are not in general capable ofachieving.Using visual metaphors to convey to the userproximity and relations between documents andautomatically generated clusters is not a new tech-nique (Chalmers and Chitson, 1992; Dubin, 1995;Wise et al, 1995; Leuski and Allan, 2000; Ras-mussen and Karypis, 2004).
InfoMagnet?s noveltycomes from giving the user more control over theultimate clustering organization.
The user is able toincrementally influence the formation and reor-ganization of cluster centroids and immediately seethe effect on the text-to-cluster assignment.
Thus,the user can explore the corpus in more effectiveand meaningful ways.In what follows, we more concretely elaborateon InfoMagnet?s functionality and technical de-tails.
We then motivate its usability and usefulnesswith a real case study.2 FunctionalityExploring a textual corpus in search of interest-ing topical patterns that correlate with externallyobservable variables is a non-trivial task.
Take asan example the task of characterizing the processby which students and tutors negotiate with oneanother over a chat interface as they navigate in-structional materials together in an on-line explora-tory learning environment.
A sensible approach isto segment all dialogue transcripts into topic-oriented segments and then group the segments bytopic similarity.
If done manually, this is a chal-lenging task in two respects.
First, to segment eachdialogue the analyst must rely on their knowledgeof the domain to locate where the focus of the dia-logue shifts from one topic to the next.
This, ofcourse, requires the analyst to know what to lookfor and to remain consistent throughout the wholeset of dialogues.
More importantly, it introducesinto the topic analysis a primacy bias.
The analystmay miss important dialogue digressions simplybecause they are not expected based on observa-tions from the first few dialogues viewed in detail.InfoMagnets addresses these issues by offeringusers a constant bird?s eye view of their data.
SeeFigure 1.As input, InfoMagnets accepts a corpus of tex-tual documents.
As an option to the user, the docu-ments can be automatically fragmented intotopically-coherent segments (referred to also asdocuments from here on), which then become theatomic textual unit1.
The documents (or topic seg-ments) are automatically clustered into an initialorganization that the user then incrementally ad-justs through the interface.
Figure 1 shows the ini-tial document-to-topic assignment thatInfoMagnets produces as a starting point for theuser.
The large circles represent InfoMagnets, ortopic oriented cluster centroids, and the smallercircles represent documents.
An InfoMagnet canbe thought of as a set of words representative of atopic concept.
The similarity between the vectorrepresentation of the words in a document and thatof the words in an InfoMagnet translate into attrac-tion in the two-dimensional InfoMagnet space.This semantic similarity is computed using LatentSemantic Analysis (LSA) (Landauer et al,  1998).Thus, a document appears closest to the InfoMag-net that best represents its topic.A document that appears equidistant to two In-foMagnets shares its content equally between thetwo represented topics.
Topics with lots of docu-ments nearby are popular topics.
InfoMagnets withonly a few documents nearby represent infrequenttopics.
Should the user decide to remove an In-foMagnet, any document with some level of attrac-tion to that InfoMagnet will animate and repositionitself based on the topics still represented by theremaining InfoMagnets.
At all times, the In-foMagnets interface offers the analyst a bird?s eyeview of the entire corpus as it is being analyzedand organized.Given the automatically-generated initial topicrepresentation, the user typically starts by brows-ing the different InfoMagnets and documents.
Us-ing a magnifying cross-hair lens, the user can viewthe contents of a document on the top pane.
Asnoted above, each InfoMagnet represents a topicconcept through a collection of words (from thecorpus) that convey that concept.
Selecting the In-foMagnet displays this list of words on the leftpane.
The list is shown in descending order of im-portance with respect to that topic.
By browsingeach InfoMagnet?s list of words and browsing1 Due to lack of space, we do not focus on our topic-segmentation algorithm.
We intend to discuss this in the demo.254nearby documents, the user can start recognizingtopics represented in the InfoMagnet space and canstart labeling those InfoMagnets.InfoMagnets with only a few neighboringdocuments can be removed.
Likewise, InfoMag-nets attracting too many topically-unrelated docu-ments can be split into multiple topics.
The usercan do this semi-automatically (by requesting asplit, and allowing the algorithm to determinewhere the best split is) or by manually selecting aset of terms from the InfoMagnet?s word list andcreating a new InfoMagnet using those words torepresent the new InfoMagnet?s topic.
If the userfinds words in an InfoMagnet?s word list that lacktopical relevance, the user can remove them fromInfoMagnet?s word list or from all the InfoMag-nets?
word lists at once.Users may also choose to manually assign a seg-ment to a topic by ?snapping?
that document to anInfoMagnet.
?Snapping?
is a way of overriding theattraction between the document and other In-foMagnets.
By ?snapping?
a document to an In-foMagnet, the relationship between the ?snapped?document and the associated InfoMagnet remainsconstant, regardless of any changes made to theInfoMagnet space subsequently.If a user would like to remove the influence of asubset of the corpus from the behavior of the tool,the user may select an InfoMagnet and all thedocuments close to it and place them in the ?quar-antine?
area of the interface.
When placed in thequarantine, as when ?snapped?, a document?s as-signment remains unchanged.
This feature is usedto free screen space for the user.If the user opts for segmenting each input dis-course and working with topic segments ratherthan whole documents, an alternative interface al-lows the user to quickly browse through the corpussequentially (Figure 2).
By switching between thisview and the bird?s eye view, the user is able to seewhere each segment fits sequentially into the largercontext of the discourse it was extracted from.
Theuser can also use the sequential interface for mak-ing minor adjustments to topic segment boundariesand topic assignments where necessary.
Once theuser is satisfied with the topic representation in thespace and the assignments of all documents tothose topics, the tool can automatically generate anXML file, where all documents are tagged withtheir corresponding topic labels.Figure 2.
InfoMagnet?s alternative sequential view3 ImplementationAs mentioned previously, InfoMagnets uses La-tent Semantic Analysis (LSA) to relate documentsto InfoMagnets.
LSA is a dimensionality reductiontechnique that can be used to compute the semanticsimilarity between text spans of arbitrary size.
Fora more technical overview of LSA, we direct thereader to (Landauer et al, 1998).The LSA space is constructed using the corpusthat the user desires to organize, possibly aug-mented with some general purpose text (such asnewsgroup data) to introduce more domain-generalterm associations.
The parameters used in buildingthe space are set by the user during pre-processing,so that the space is consistent with the semanticgranularity the user is interested in capturing.Because documents (or topic-segments) tend tocover more than one relevant topic, our clusteringapproach is based on what are determined heuristi-cally to be the most important terms in the corpus,and not on whole documents.
This higher granular-ity allows us to more precisely capture the topicsdiscussed in the corpus by not imposing the as-sumption that documents are about a single topic.First, all terms that occur less than n times and inless than m documents are removed from consid-eration2.
Then, the remaining terms are clusteredvia average-link clustering, using their LSA-basedvector representations and using cosine-correlationas a vector similarity measure.
Our clustering algo-rithm combines top-down clustering (Bisecting K-Means) and bottom-up clustering (AgglomerativeClustering) (Steinbach et al, 2000).
This hybrid2 n and m are parameters set by the user.255clustering approach leverages the speed of bisect-ing K-means and the greedy search of agglomera-tive clustering, thus achieving a nice effectivenessversus efficiency balance.Cluster centroids (InfoMagnets) and documents(or topic segments) are all treated as bag-of-words.Their vector-space representation is the sum of theLSA vectors of their constituent terms.
When theuser changes the topic-representation by removingor adding a term to an InfoMagnet, a new LSAvector is obtained by projecting the new bag-of-words onto the LSA space and re-computing thecosine correlation between all documents and thenew topic.4 An Example of UseInfoMagnets was designed for easy usability byboth computational linguistics and non-technicalusers.
It has been successfully used by social psy-chologists working on on-line communities re-search as well as learning science researchersstudying tutorial dialogue interactions (which wediscuss in some detail here).Using InfoMagnets, a thermodynamics domainexpert constructed a topic analysis of a corpus ofhuman tutoring dialogues collected during class-room study focusing on thermodynamics instruc-tion (Ros?
et al, 2005).
Altogether each student?sprotocol was divided into between 10 and 25 seg-ments such that the entire corpus was divided intoapproximately 379 topic segments altogether.
Us-ing InfoMagnets, the domain expert identified 15distinct topics such that each student covered be-tween 4 and 11 of these topics either once or mul-tiple times throughout their interaction.The topic analysis of the corpus gives us a wayof quickly getting a sense of how tutors dividedtheir instructional time between different topics ofconversation.
Based on this topic analysis of thehuman-tutoring corpus, the domain expert de-signed 12 dialogues, which were then implementedusing a dialogue authoring environment calledTuTalk (Gweon et al, 2005).
In a recent very suc-cessful classroom evaluation, we observed the in-structional effectiveness of these implementedtutorial dialogue agents, as measured by pre andpost tests.AcknowledgmentsThis work was funded by Office of Naval Re-search, Cognitive and Neural Science Division,grant number N00014-05-1-0043.ReferencesJaime Arguello, Brian S. Butler, Lisa Joyce, RobertKraut, Kimberly S. Ling, Carolyn Rose and XiaoqingWang (2006).
Talk to Me: Foundations of SuccessfulIndividual-Group Interactions in Online Communi-ties.
To appear in Proceedings of CHI: Human Fac-tors in Computing.Matthew Chalmers and Paul Chitson (1992).
Bead: Ex-plorations in Information Visualization.
In Proceed-ings of ACM SIGIR,  330-337David Dubin (1995).
Document Analysis for Visualiza-tion.
In Proceedings of ACM SIGIR, 199-204.Gahgene Gweon, Jaime Arguello, Carol Pai, ReganCarey, Zachary Zaiss, and Carolyn Ros?
(2005).Towards a Prototyping Tool for Behavior OrientedAuthoring of Conversational Interfaces, Proceedingsof the ACL Workshop on Educational Applications ofNLP.Rohit Kumar, Carolyn Ros?, Vincent Aleven, Ana Igle-sias, Allen Robinson (submitted).
Evaluating the Ef-fectiveness of Tutorial Dialogue Instruction in anExploratory Learning Context, Submitted to ITS ?06Thomas Landauer, Peter W. Foltz, and Darrell Laham(1998).
Introduction to Latent Semantic Analysis.Discourse Processes, 25, 259-284.Anton Leuski and James Allan (2002).
Lighthouse:Showing the Way to Relevant Information.
In Pro-ceedings of the IEEE InfoVis  2000Matt Rasmussen and George Karypis (2004).
gCLUTO:An Interactive Clustering, Visualization, and Analy-sis System.
Technical Report # 04-021Carolyn Ros?, Vincent Aleven, Regan Carey, AllenRobinson, and Chih Wu (2005).
A First Evaluationof the Instructional Value of Negotiable ProblemSolving Goals on the Exploratory Learning Contin-uum, Proceedings of AI in Education ?05Michael Steinbach, George Karypis, and Vipin Kuma(2000).
A comparison of document clustering tech-niques.
In KDD Workshop on Text Mining.James A.
Wise, James J. Thomas, Kelly Pennock, DavidLantrip, Marc Pottier, and Anne Schur (1995).
Visu-alizing the Non-Visual: Spatial Analysis and Interac-tion with Information from Text Documents.
InProceedings of IEEE InfoVis ?95, 51-58.256
