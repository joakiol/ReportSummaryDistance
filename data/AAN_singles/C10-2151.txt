Coling 2010: Poster Volume, pages 1318?1326,Beijing, August 2010Search with Synonyms: Problems and SolutionsXing Wei, Fuchun Peng, Huishin Tseng, Yumao Lu, Xuerui Wang, Benoit DumoulinYahoo!
Labs	{xwei,fuchun,huihui,yumaol,xuerui,benoitd}@yahoo-inc.comAbstractSearch with synonyms is a challengingproblem for Web search, as it can eas-ily cause intent drifting.
In this paper,we propose a practical solution to this is-sue, based on co-clicked query analysis,i.e., analyzing queries leading to clickingthe same documents.
Evaluation resultson Web search queries show that syn-onyms obtained from this approach con-siderably outperform the thesaurus basedsynonyms, such as WordNet, in terms ofkeeping search intent.1 IntroductionSynonym discovery has been an active topic in avariety of language processing tasks (Baroni andBisi, 2004; Fellbaum, 1998; Lin, 1998; Pereiraet al, 1993; Sanchez and Moreno, 2005; Turney,2001).
However, due to the difficulties of syn-onym judgment (either automatically or manu-ally) and the uncertainty of applying synonymsto specific applications, it is still unclear howsynonyms can help Web scale search task.
Previ-ous work in Information Retrieval (IR) has beenfocusing mainly on related words (Bai et al,2005; Wei and Croft, 2006; Riezler et al, 2008).But Web scale data handling needs to be preciseand thus synonyms are more appropriate than re-lated words for introducing less noise and alle-viating the efficiency concern of query expan-sion.
In this paper, we explore both manually-built thesaurus and automatic synonym discov-ery, and apply a three-stage evaluation by sep-arating synonym accuracy from relevance judg-ment and user experience impact.The main difficulties of discovering synonymsfor Web search are the following:1.
Synonym discovery is context sensitive.Although there are quite a few manually builtthesauri available to provide high quality syn-onyms (Fellbaum, 1998), most of these syn-onyms have the same or nearly the same mean-ing only in some senses.
If we simply replacethem in search queries in all occurrences, it isvery easy to trigger search intent drifting.
Thus,Web search needs to understand different sensesencountered in different contexts.
For example,?baby?
and ?infant?
are treated as synonyms inmany thesauri, but ?Santa Baby?
has nothing todo with ?infant?.
?Santa Baby?
is a song title,and the meaning of ?baby?
in this entity is dif-ferent than the usual meaning of ?infant?.2.
Context can not only limit the use of syn-onyms, but also broaden the traditional definitionof synonyms.
For instance, ?dress?
and ?attire?sometimes have nearly the same meaning, eventhough they are not associated with the same en-try in many thesauri; ?free?
and ?download?
arefar from synonyms in traditional definition, but?free cd rewriter?
may carry the same query in-tent as ?download cd rewriter?.3.
There are many new synonyms devel-oped from the Web over time.
?Mp3?
and?mpeg3?
were not synonyms twenty years ago;?snp newspaper?
and ?snp online?
carry thesame query intent only after snponline.com waspublished.
Manually editing synonym list is pro-hibitively expensive.
Thus, we need an auto-matic synonym discovery system that can learnfrom huge amount of data and update the dictio-nary frequently.1318In summary, synonym discovery for Websearch is different from traditional thesaurusmining; it needs to be context sensitive and needsto be updated timely.
To address these prob-lems, we conduct context based synonym dis-covery from co-clicked queries, i.e., queries thatshare similar document click distribution.
Toshow the effectiveness of our synonym discov-ery method on Web search, we use several met-rics to demonstrate significant improvements:(1) synonym discovery accuracy that measureshow well it keeps the same search intent; (2)relevance impact measured by Discounted Cu-mulative Gain (DCG) (Jarvelin and Kekalainen.,2002); and (3) user experience impact measuredby online experiment.The rest of the paper is organized as follows.In Section 2, we first discuss related work anddifferentiate our work from existing work.
Thenwe present the details of our synonym discov-ery approach in Section 3.
In Section 4 we showour query rewriting strategy to include synonymsin Web search.
We conduct experiments on ran-domly sampled Web search queries and run thethree-stage evaluation in Section 5 and analyzethe results in Section 6.
WordNet based syn-onym reformulation and a current commercialsearch engine are the baselines for the three-stage evaluation respectively.
Finally we con-clude the paper in Section 7.2 Related WorksAutomatically discovering synonyms from largecorpora and dictionaries has been popular top-ics in natural language processing (Sanchez andMoreno, 2005; Senellart and Blondel, 2003; Tur-ney, 2001; Blondel and Senellart, 2002; van derPlas and Tiedemann, 2006), and hence, there hasbeen a fair amount of work in calculating wordsimilarity (Porzel and Malaka, 2004; Richardsonet al, 1998; Strube and Ponzetto, 2006; Bolle-gala et al, 2007) for the purpose of discoveringsynonyms, such as information gain on ontology(Resnik, 1995) and distributional similarity (Lin,1998; Lin et al, 2003).
However, the definitionof synonym is application dependent and mostof the work has been applied to a specific task(Turney, 2001) or restricted in one domain (Ba-roni and Bisi, 2004).
Synonyms extracted us-ing these traditional approaches cannot be easilyadopted in Web search where keeping search in-tent is critical.Our work is also related to semantic matchingin IR: manual techniques such as using hand-crafted thesauri and automatic techniques suchas query expansion and clustering all attempts toprovide a solution, with varying degrees of suc-cess (Jones, 1971; van Rijsbergen, 1979; Deer-wester et al, 1990; Liu and Croft, 2004; Baiet al, 2005; Wei and Croft, 2006; Cao et al,2007).
These works focus mainly on adding inloosely semantically related words to expand lit-eral term matching.
But related words may betoo coarse for Web search considering the mas-sive data available.3 Synonym Discovery based onCo-clicked QueriesIn this section, we discuss our approach to syn-onym discovery based on co-clicked queries inWeb search in detail.3.1 Co-clicked Query ClusteringClustering has been extensively studied in manyapplications, including query clustering (Wen etal., 2002).
One of the most successful tech-niques for clustering is based on distributionalclustering (Lin, 1998; Pereira et al, 1993).
Weadopt a similar approach to our co-clicked queryclustering.
Each query is associated with a setof clicked documents, which in turn associatedwith the number of views and clicks.
We thencompute the distance between a pair of queriesby calculating the Jensen-Shannon(JS) diver-gence (Lin, 1991) between their clicked URLdistributions.
We start with that every queryis a separate cluster, and merge clusters greed-ily.
After clusters are generated, pairs of querieswithin the same cluster can be considered asco-clicked/related queries with a similarity scorecomputed from their JS divergence.Sim(qk|ql) = DJS(qk||ql) (1)13193.2 Query Pair AlignmentTo make sure that words are replacement foreach other in the co-clicked queries, we alignwords in the co-clicked query pairs that havethe same length (number of terms), and havethe same terms for all positions except one.This is a simplification for complicated aligningprocesses.
Previous work on machine transla-tion (Brown et al, 1993) can be used when com-plete alignment is needed for modeling.
How-ever, as we have tremendous amount of co-clicked query data, our restricted version ofalignment is sufficient to obtain a reasonablenumber of synonyms.
In addition, this restrictedapproach eliminates much noise introduced inthose complicated aligning processes.3.2.1 Synonym Discovery from Co-clickedQuery PairSynonyms discovered from co-clicked querieshave two aspects of word meaning: (1) gen-eral meaning in language and (2) specific mean-ing in the query.
These two aspects are related.For example, if two words are more likely tocarry the same meaning in general, then they aremore likely to carry the same meaning in spe-cific queries; on the other hand, if two words of-ten carry the same meaning in a variety of spe-cific queries, then we tend to believe that the twowords are synonyms in general language.
How-ever, neither of these two aspects can cover theother.
Synonyms in general language may notbe used to replace each other in a specific query.For example, ?sea?
and ?ocean?
have nearly thesame meaning in language, but in the specificquery ?sea boss boat?, ?sea?
and ?ocean?
cannotbe treated as synonyms because ?sea boss?
is abrand; also, in the specific query ?women?s wed-ding attire?, ?dress?
can be viewed as a synonymto ?attire?, but in general language, these twowords are not synonyms.
Therefore, whethertwo words are synonyms or not for a specificquery is a synthesis judgment based on both ofgeneral meaning and specific context.We develop a three-step process for synonymdiscovery based on co-clicked queries, consider-ing the above two aspects.Step 1: Get al synonym candidates for wordwi in general meaning.In this step, we would like to get al syn-onym candidates for a word.
This step corre-sponds to Aspect (1) to catch the general mean-ing of words in language.
We consider all theco-clicked queries with the word and sum overthem, as in Eq.
2P (wj |wi) =?k simk(wi ?
wj)?wj?k sim(wi ?
wj)(2)where simk(wi ?
wj) represents the similarityscore (see Section 3.1) of a query qk that alignswi to wj .
So intuitively, we aggregate scores ofall query pairs that align wi to wj , and normalizeit to a probability over the vocabulary.Step 2: Get synonyms for word wi in queryqk.In this step, we would like to get synonyms fora word in a specific query.
We define the prob-ability of reformulating wi with wj for query qkas the similarity score shown in Eq.
3.P (wj |wi, qk) = simk(wi ?
wj) (3)Step 3: Combine the above two steps.Now we have two sets of estimates for the syn-onym probability, which is used to reformulatewi with wj .
One set of values are based on gen-eral language information and another set of val-ues are based on specific queries.
We apply threecombination approaches to integrate the two setsof values for a final decision of synonym dis-covery: (1) two independent thresholds for eachprobability, (2) linear combination with a coeffi-cient, and (3) linear combination in log scale asin Eq.
4, with ?
as a mixture coefficient.Pqk(wj |wi) ?
?
log P (wj |wi)+(1 ?
?)
log P (wj |wi, qk) (4)In experiments we found that there is no sig-nificant difference with the results from differentcombination methods by finely tuned parametersetting.3.2.2 Concept based SynonymsThe simple word alignment strategy we usedcan only get the synonym mapping from single1320term to single term.
But there are a lot of phrase-to-phrase, term-to-phrase, or phrase-to-term syn-onym mappings in language, such as ?babe inarms?
to ?infant?, and ?nyc?
to ?new york city?.We perform query segmentation on queries toidentify concept units from queries based onan unsupervised segmentation model (Tan andPeng, 2008).
Each unit is a single word or sev-eral consecutive words that represent a meaning-ful concept.4 Synonym Handling in Web SearchThe automatic synonym discovery methods de-scribed in Section 3 generate synonym pairs foreach query.
A simple and straightforward wayto use the synonym pairs would be ?equalizing?them in search, just like the ?OR?
function inmost commercial search engines.Another method would be to re-train thewhole ranking system using the synonym fea-ture, but it is expensive and requires a large sizetraining set.
We consider this to be future work.Besides general equalization in all cases, wealso apply a restriction, specially, on whether ornot to allow synonyms to participate in documentselection.
For the consideration of efficiency,most Web search engines has a document selec-tion step to pre-select a subset of documents forfull ranking.
For the general equalization, thesynonym pair is treated as the same even in thedocument selection round; in a conservative vari-ation, we only use the original word for docu-ment selection but use the synonyms in the sec-ond phase finer ranking.5 ExperimentsIn this section, we present the experimental re-sults for our approaches with some in-depth dis-cussion.5.1 Evaluation MetricsWe have several metrics to evaluate the synonymdiscovery system for Web search queries.
Theycorresponds to the three stages during the systemdevelopment.
Each of them measures a differentaspect.Stage 1: accuracy.
Because we are more in-terested in the application of reformulating Websearch queries, our guideline to the editorialjudgment focuses on the query intent change andcontext-based synonyms.
For example, ?trans-porters?
and ?movers?
are good synonyms inthe context of ?boat?
because ?boat transporters?and ?boat movers?
keep the same search intent,but ?ocean?
is not a good synonym to ?sea?
inthe query of ?sea boss boats?
because ?sea boss?is a brand name and ?ocean boss?
does not re-fer to the same brand.
Results are measured withaccuracy by the number of discovered synonyms(which reflects coverage).Stage 2: relevance.
To evaluate the effec-tiveness of our semantic features we use DCG,a widely-used metric for measuring Web searchrelevance.Stage 3: user experience.
In addition to thesearch relevance, we also evaluate the practicaluser experience after logging all the user searchbehaviors during a two-week online experiment.Web CTR: the Web click through rate (Sher-man and Deighton, 2001; Lee et al, 2005) is de-fined asCTR = number of clickstotal page views,where a page view (PV) is one result page that asearch engine returns for a query.Abandon rate: the percentage of queries thatare abandoned by user neither clicking a resultnor issuing a query refinement.5.2 DataA period of Web search query log with clickedURLs are used to generate co-clicked query set.After word alignment that extracts the co-clickedquery pairs with same number of units and withonly one different unit, we obtain 12.1M unseg-mented query pairs and 11.9M segmented querypairs.Since we run a three-stage evaluation, thereare three independent evaluation set respectively:1. accuracy test set.
For the evaluation of syn-onym discovery accuracy, we randomly sampled42K queries from two weeks of query log, and1321evaluate the effectiveness of our synonym dis-covery model with these queries.
To test the syn-onym discovery model built on the segmenteddata, we segment the queries before using themas evaluation set.2.
relevance test set.
To evaluate the relevanceimpact by the synonym discovery approach, werun experiments on another two weeks of querylog and randomly sampled 1000 queries from theaffected queries (queries that have differences inthe top 5 results after synonym handling).3. user experience test set.
The user experi-ence test is conducted online with a commercialsearch engine.5.3 Results of Synonym DiscoveryAccuracyHere we present the results of WordNet the-saurus based query synonym discovery, co-clicked based term-to-term query synonym dis-covery, and co-click concept based query syn-onym discovery.5.3.1 Thesaurus-based SynonymReplacementThe WordNet thesaurus-based synonym re-placement is a baseline here.
For any word thathas synonyms in the thesaurus, thesaurus-basedsynonym replacement will rewrite the word withsynonyms from the thesaurus.Although thesaurus often provides clean in-formation, synonym replacement based on the-saurus does not consider query context and in-troduces too many errors and noise.
Our exper-iments show that only 46% of the discoveredsynonyms are correct synonyms in query.
Theaccuracy is too low to be used for Web searchqueries.5.3.2 Co-clicked Query-based ContextSynonym DiscoveryHere we present the results from our approachbased on co-clicked query data (in this sectionthe queries are all original queries without seg-mentation).
Figure 1 shows the accuracy of syn-onyms by the number of discovered synonyms.By applying different thresholds as cut-off linesto Eq.
4, we get different numbers of synonymsfrom the same test set.
As we can see, looseningthe threshold can give us more synonym pairs,but it could hurt the accuracy.Figure 1: Accuracy versus number of synonymswith term based synonym discoveryFigure 1 demonstrates how accuracy changeswith the number of synonyms.
Y-axis repre-sents the percentage of correctly discovered syn-onyms, and X-axis represents the number ofdiscovered synonyms, including both of correctones and wrong ones.
The three different linesrepresents three different parameter settings ofmixture weights (?
in Eq.
4, which is 0.2, 0.3,or 0.4 in the figure).
The figure shows accuracydrops by increasing the number of synonyms.More synonym pairs lead to lower accuracy.From Figure 1 we can see: Firstly, threecurves with different thresholds almost over-lap, which means the effectiveness of synonymdiscovery is not very sensitive to the mixtureweight.
Secondly, accuracy is monotonically de-creasing as more synonyms are detected.
Bygetting more synonyms, the accuracy decreasesfrom 100% to less than 80% (we are not in-terested in accuracies lower than 80% due tothe high precision requirement of Web searchtasks, so the graph contains only high-accuracyresults).
This trend also confirms the effective-ness of our approach (the accuracy for a randomapproach would be a constant).5.3.3 Concept based Context SynonymDiscoveryWe present results from our model based onsegmented co-clicked query data in this section.1322Original Query New Query with Synonyms IntentExamples of thesaurus-based based synonym replacementbasement window wells drainage basement window wells drainbillabong boardshorts sale billabong boardshorts sales event samebigger stronger faster documentary larger stronger faster documentaryyahoo hayseedmaryland judiciary case search maryland judiciary pillowcase search differentfree cell phone number lookup free cell earpiece number lookupExamples of term-to-term synonym discoveryairlines jobs airlines careersarea code finder area code search sameacai berry acai fruitacai berry acai juiceace hardware differentcrest toothpaste coupon crest whitestrips couponExamples of concept based synonym discoveryae american eagle outfittersapartments for rent apartment rentals samearizona time zone arizona timecortrust bank credit card cortrust bank mastercarddavid beckham beckham differentdodge caliber dodgeTable 1: Examples of query synonym discovery: the first section is thesaurus based, second sec-tion is co-clicked data based term-to-term synonym discovery, and the last section is concept basedsynonym discovery.The modeling part is the same as the one forSection 5.3.2, and the only difference is thatthe data were segmented.
We have shown inSection 5.3.2 that the mixture weight is not ancrucial factor within a reasonable range, so wepresent only the result with one mixture weightin Figure 2.
As in Section 5.3.2, the figure showsthat the accuracy of synonym discovery is sensi-tive to the threshold.
It confirms that our modelis effective and setting threshold to Eq.
4 is a fea-sible and sound way to discover not only singleterm synonyms but also phrase synonyms.Figure 2: Accuracy versus number of synonymswith concept based synonym discoveryTable 1 shows some anecdotal examples ofquery synonyms with the thesaurus-based syn-onym replacement, context sensitive synonymdiscovery, and concept based context sensitivesynonym discovery.
In contrast, the upper partof each section shows positive examples (queryintents remain the same after synonym replace-ment) and the lower part shows negative ex-amples (query intents change after synonym re-placement).5.4 Results of Relevance ImpactWe run relevance test on 1000 randomly sampledaffected queries.
With the automatic synonymdiscovery approach we apply our synonym han-dling method described in Section 4.
Results ofDCG improvements by different thresholds andsynonym handling settings are presented in Ta-ble 2.
Thresholds are selected empirically fromthe accuracy test in Section 5.3 (we run a smallsize relevance test on the accuracy test set andset the range of thresholds based on that).
Notethat in our relevance experiments we use term-to-term synonym pairs only.
For the relevanceimpact of concept-based synonym discovery, wewould like to study it in our future work.1323From Table 2 we can see that the automaticsynonym discovery approach we presented sig-nificantly improves search relevance on varioussettings, which confirms the effectiveness of oursynonym discovery for Web search queries.
Weconjecture that avoiding synonym in documentselection is of help.
This is because precision ismore important to Web search than recall for thehuge amount of data available on the Web.Relevance impact with synonym handlingdoc-selectionthreshold1 threshold2 participation DCG0.8 0.02 no +1.7%0.8 0.02 yes +1.3%0.8 0.05 no +1.8%0.8 0.05 yes +1.4%Table 2: Relevance impact with synonym han-dling by different parameter settings.
?Thresh-old1?
is the threshold for context-based similar-ity score?Eq.
3; ?threshold2?
is the thresholdfor general case similarity score?Eq.
2; ?doc-selection participation?
refers to whether or notlet synonym handling participate in documentselection.
All improvements are statistically sig-nificant by Wilcox significance test.5.5 Results of User Experience ImpactIn addition to the relevance impact, we also eval-uated the practical user experience impact byCTR and abandon rate (defined in Section 5.1)through a two-week online run.
Results showthat the synonym discovery method presented inthis paper improves Web CTR by 2%, and de-creases abandon rate by 11.4%.
All changesare statistically significant, which indicates syn-onyms are indeed beneficial to user experience.6 Discussion and Error AnalysisFrom Table 1, we can see that our approach cancatch not only traditional synonyms, which arethe synonyms that can be found in manually-built thesaurus, but also context-based syn-onyms, which may not be treated as synonymsin a standard dictionary or thesaurus.
There area variety of synonyms our approach discovered:1.
Synonyms that are not considered as syn-onyms in traditional thesaurus, such as ?berry?and ?fruit?
in the context of ?acai?.
?acai berry?and ?acai fruit?
refer to the same fruit.2.
Synonyms that have different part-of-speech features than the corresponding originalwords, such as ?finder?
and ?search?.
Userssearching ?area code finder?
and users search-ing ?area code search?
are looking for the samecontent.
In the context of Web search queries,part-of-speech is not an important factor as mostqueries are not grammatically perfect.3.
Synonyms that show up in recent concepts,such as ?webmail?
and ?email?
in the contextof ?cox?.
The new concept of ?webmail?
or?email?
has not been added to many thesauri yet.4.
Synonyms not limited by length, such as?crossword puzzles?
and ?crossword?, ?homesfor sale?
and ?real estate?.
The segmenterhelps our system discover synonyms in variouslengths.With these many variations, the synonyms dis-covered by our approach are not the ?synonyms?in the traditional meaning.
They are context sen-sitive, Web data oriented and search effectivesynonyms.
These synonyms are discovered bythe statistical model we presented and based onWeb search queries and clicked data.However, the click data themselves contain ahuge amount of noise.
Although they can re-flect the users?
intents in some big picture, inmany specific cases synonyms discovered fromco-clicked data are biased by the click noise.
Inour application?Web search query reformula-tion with synonyms, accuracy is the most im-portant thing and thus we are interested in er-ror analysis.
The errors that our model makesin synonym discovery are mainly caused by thefollowing reasons:(1) There are some concepts well acceptedsuch as ?cnn?
means ?news?
and ?amtrak?means ?train?.
And users searching ?news?
tendto click CNN Web site; users searching ?train?tend to click Amtrak Web site.
With our model,?cnn?
and ?news?, ?amtrak?
and ?train?
are dis-covered to be synonyms, which may hurt thesearch of ?news?
or ?train?
in general meaning.1324(2) Same clicks by different intents.
Althoughclicking on same documents generally indicatessame search intent, different intents could re-sult in same or similar clicks, too.
For exam-ple, the queries of ?antique style wedding rings?and ?antique style engagement rings?
carry dif-ferent intents, but very usually, these two differ-ent intents lead to the clicks on the same Website.
?Booster seats?
and ?car seats?, ?brightonhandbags?
and ?brighton shoes?
are other twoexamples in the same case.
For these examples,clicking on Web URLs are not precise enoughto reflect the subtle difference of language con-cepts.
(3) Bias from dominant user intents.
Mostpeople searching ?apartment?
are looking for anapartment to rent.
So ?apartment for rent?
and?apartment?
have similar clicked URLs.
Butthese two are not synonyms in language.
In thesecases, popular user intents dominate and bias themeaning of language, which causes problems.
?Airline baggage restrictions?
and ?airline travelrestrictions?
is another example.
(4) Antonyms.
Many context-based synonymdiscovery methods suffer from the antonymproblem, because antonyms can have very simi-lar contexts.
In our model, the problem has beenreduced by integrating clicked-URLs.
But still,there are some examples, such as ?spyware?
and?antispyware?, resulting in similar clicks.
Tolearn how to ?protect a Web site?, a user oftenneeds to learn what are the main methods to ?at-tack a Web site?, and these different-intent pairslead to the same clicks because different intentsdo not have to mean different interests in manyspecific cases.Although these problems are not common, butwhen they happen, they cause a bad user searchexperience.
We believe a solution to these prob-lems might need more advanced linguistic anal-ysis.7 ConclusionsIn this paper, we have developed a synonym dis-covery approach based on co-clicked query data,and improved search relevance and user experi-ence significantly based on the approach.For future work, we are investigating moresynonym handling methods to further improvethe synonym discovery accuracy, and to handlethe discovered synonyms in more ways than justthe query side.ReferencesBai, J., D. Song, P. Bruza, J.Y.
Nie, and G. Cao.2005.
Query Expansion using Term Relationshipsin Language Models for Information Retrieval.
InProceedings of the ACM 14th Conference on In-formation and Knowledge Management.Baroni, M. and S. Bisi.
2004.
Using CooccurrenceStatistics and the Web to Discover Synonyms in aTechnical Language.
In LREC.Blondel, V. and P. Senellart.
2002.
Automatic Ex-traction of Synonyms in a Dictionary.
In Proc.
ofthe SIAM Workshop on Text Mining.Bollegala, D., Y. Matsuo, and M. Ishizuka.
2007.Measuring Semantic Similarity betweenWords us-ing Web Search Engines.
In Proceedings of the16th international conference on World Wide Web(WWW).Brown, P. F., S. A. Della Pietra, V. J. Della Pietra, andR.
L. Mercer.
1993.
The Mathematics of Statis-tical Machine Translation: Parameter Estimation.Computational Linguistics, 19(2):263.Cao, G., J.Y.
Nie, and J. Bai.
2007.
Using MarkovChains to Exploit Word Relationships in Informa-tion Retrieval.
In Proceedings of the 8th Confer-ence on Large-Scale Semantic Access to Content.Deerwester, S., S. T. Dumais, G. W. Furnas, T. K.Landauer, and R. Harshman.
1990.
Indexing byLatent Semantic Analysis.
Journal of the Amer-ican Society for Information Science, 41(6):391?407.Fellbaum, C., editor.
1998.
WordNet: An ElectronicLexical Database.
MIT Press, Cambridge, Mass.Jarvelin, K. and J. Kekalainen.
2002.
CumulatedGain-Based Evaluation Evaluation of IR Tech-niques.
ACM TOIS, 20:422?446.Jones, K. S., 1971.
Automatic Keyword Classificationfor Information Retrieval.
London: Butterworths.Lee, Uichin, Zhenyu Liu, and Junghoo Cho.
2005.Automatic Identification of User Goals in WebSearch.
In In the World-Wide Web Conference(WWW).1325Lin, D., S. Zhao, L. Qin, and M. Zhou.
2003.
Iden-tifying Synonyms among Distributionally SimilarWords.
In Proceedings of International Joint Con-ference on Artificial Intelligence (IJCAI).Lin, J.
1991.
Divergence measures based on theshannon entropy.
IEEE Transactions on Informa-tion Theory, 37(1):145?151.Lin, D. 1998.
Automatic Retrieval and Clustering ofSimilar Words.
In Proceedings of COLING/ACL-98, pages 768?774.Liu, X. and B. Croft.
2004.
Cluster-based Retrievalusing LanguageModels.
In Proceedings of SIGIR.Pereira, F., N. Tishby, and L. Lee.
1993.
Distribu-tional Clustering of English Words.
In Proceed-ings of ACL, pages 183 ?
190.Porzel, R. and R. Malaka.
2004.
A Task-based Ap-proach for Ontology Evaluation.
In ECAI Work-shop on Ontology Learning and Population.Resnik, P. 1995.
Using Information Content to Eval-uate Semantic Similarity in a Taxonomy.
In Pro-ceedings of IJCAI-95, pages 448 ?
453.Richardson, S., W. Dolan, and L. Vanderwende.1998.
MindNet: Acquiring and Structuring Se-mantic Information from Text.
In 36th Annualmeeting of the Association for Computational Lin-guistics.Riezler, Stefan, Yi Liu, and Alexander Vasserman.2008.
Translating Queries into Snippets for Im-proved Query Expansion.
In Proceedings of the22nd International Conference on ComputationalLinguistics (COLING?08).Sanchez, D. and A. Moreno.
2005.
Automatic Dis-covery of Synonyms and Lexicalizations from theWeb.
In Proceedings of the 8th Catalan Confer-ence on Artificial Intelligence.Senellart, P. and V. D. Blondel.
2003.
AutomaticDiscovery of Similar Words.
In Berry, M., editor,A Comprehensive Survey of Text Mining.
Springer-Verlag, New York.Sherman, L. and J. Deighton.
2001.
Banner ad-vertising: Measuring effectiveness and optimiz-ing placement.
Journal of Interactive Marketing,15(2):60?64.Strube, M. and S. P. Ponzetto.
2006.
WikiRe-late!
Computing Semantic Relatedness UsingWikipedia.
In Proceedings of AAAI.Tan, B. and F. Peng.
2008.
Unsupervised Query Seg-mentation using Generative Language Models andWikipedia.
In Proceedings of the 17th Interna-tional World Wide Web Conference (WWW), pages347?356.Turney, P. 2001.
Mining the Web for Synonyms:PMI-IR versus LSA on TOEFL.
In Proceedingsof the Twelfth European Conference on MachineLearning.van der Plas, Lonneke and Jorg Tiedemann.
2006.Finding Synonyms using Automatic Word Align-ment and Measures of Distributional Similarity.In Proceedings of the COLING/ACL 2006, pages866?873.van Rijsbergen, C.J., 1979.
Information Retrieval.London: Butterworths.Wei, X. and W. B. Croft.
2006.
LDA-based Doc-ument Models for Ad-hoc Retrieval.
In Proceed-ings of SIGIR, pages 178?185.Wen, J.R., J.Y.
Nie, and H.J.
Zhang.
2002.
QueryClustering Using User Logs.
ACM Transactionson Information Systems, 20(1):59?81.1326
