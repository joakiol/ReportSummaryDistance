Proceedings of ACL-08: HLT, pages 28?36,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsThe Tradeoffs Between Open and Traditional Relation ExtractionMichele Banko and Oren EtzioniTuring CenterUniversity of WashingtonComputer Science and EngineeringBox 352350Seattle, WA 98195, USAbanko,etzioni@cs.washington.eduAbstractTraditional Information Extraction (IE) takesa relation name and hand-tagged examples ofthat relation as input.
Open IE is a relation-independent extraction paradigm that is tai-lored to massive and heterogeneous corporasuch as theWeb.
An Open IE system extracts adiverse set of relational tuples from text with-out any relation-specific input.
How is OpenIE possible?
We analyze a sample of Englishsentences to demonstrate that numerous rela-tionships are expressed using a compact setof relation-independent lexico-syntactic pat-terns, which can be learned by an Open IE sys-tem.What are the tradeoffs between Open IE andtraditional IE?
We consider this question inthe context of two tasks.
First, when thenumber of relations is massive, and the rela-tions themselves are not pre-specified, we ar-gue that Open IE is necessary.
We then presenta new model for Open IE called O-CRF andshow that it achieves increased precision andnearly double the recall than the model em-ployed by TEXTRUNNER, the previous state-of-the-art Open IE system.
Second, when thenumber of target relations is small, and theirnames are known in advance, we show thatO-CRF is able to match the precision of a tra-ditional extraction system, though at substan-tially lower recall.
Finally, we show how tocombine the two types of systems into a hy-brid that achieves higher precision than a tra-ditional extractor, with comparable recall.1 IntroductionRelation Extraction (RE) is the task of recognizingthe assertion of a particular relationship between twoor more entities in text.
Typically, the target relation(e.g., seminar location) is given to the RE system asinput along with hand-crafted extraction patterns orpatterns learned from hand-labeled training exam-ples (Brin, 1998; Riloff and Jones, 1999; Agichteinand Gravano, 2000).
Such inputs are specific to thetarget relation.
Shifting to a new relation requires aperson to manually create new extraction patterns orspecify new training examples.
This manual laborscales linearly with the number of target relations.In 2007, we introduced a new approach to theRE task, called Open Information Extraction (OpenIE), which scales RE to the Web.
An Open IE sys-tem extracts a diverse set of relational tuples withoutrequiring any relation-specific human input.
OpenIE?s extraction process is linear in the number ofdocuments in the corpus, and constant in the num-ber of relations.
Open IE is ideally suited to corporasuch as the Web, where the target relations are notknown in advance, and their number is massive.The relationship between standard RE systemsand the new Open IE paradigm is analogous to therelationship between lexicalized and unlexicalizedparsers.
Statistical parsers are usually lexicalized(i.e.
they make parsing decisions based on n-gramstatistics computed for specific lexemes).
However,Klein and Manning (2003) showed that unlexical-ized parsers are more accurate than previously be-lieved, and can be learned in an unsupervised man-ner.
Klein and Manning analyze the tradeoffs be-28tween the two approaches to parsing and argue thatstate-of-the-art parsing will benefit from employingboth approaches in concert.
In this paper, we exam-ine the tradeoffs between relation-specific (?lexical-ized?)
extraction and relation-independent (?unlexi-calized?)
extraction and reach an analogous conclu-sion.Is it, in fact, possible to learn relation-independentextraction patterns?
What do they look like?
We firstconsider the task of open extraction, in which thegoal is to extract relationships from text when theirnumber is large and identity unknown.
We then con-sider the targeted extraction task, in which the goalis to locate instances of a known relation.
How doesthe precision and recall of Open IE compare withthat of relation-specific extraction?
Is it possible tocombine Open IE with a ?lexicalized?
RE systemto improve performance?
This paper addresses thequestions raised above and makes the following con-tributions:?
We present O-CRF, a new Open IE system thatuses Conditional Random Fields, and demon-strate its ability to extract a variety of rela-tions with a precision of 88.3% and recall of45.2%.
We compare O-CRF to O-NB, the ex-traction model previously used by TEXTRUN-NER (Banko et al, 2007), a state-of-the-artOpen IE system.
We show that O-CRF achievesa relative gain in F-measure of 63% over O-NB.?
We provide a corpus-based characterization ofhow binary relationships are expressed in En-glish to demonstrate that learning a relation-independent extractor is feasible, at least for theEnglish language.?
In the targeted extraction case, we compare theperformance of O-CRF to a traditional RE sys-tem and find that without any relation-specificinput, O-CRF obtains the same precision withlower recall compared to a lexicalized extractortrained using hundreds, and sometimes thou-sands, of labeled examples per relation.?
We present H-CRF, an ensemble-based extrac-tor that learns to combine the output of thelexicalized and unlexicalized RE systems andachieves a 10% relative increase in precisionwith comparable recall over traditional RE.The remainder of this paper is organized as fol-lows.
Section 2 assesses the promise of relation-independent extraction for the English language bycharacterizing how a sample of relations is ex-pressed in text.
Section 3 describes O-CRF, a newOpen IE system, as well as R1-CRF, a standard REsystem; a hybrid RE system is then presented in Sec-tion 4.
Section 5 reports on our experimental results.Section 6 considers related work, which is then fol-lowed by a discussion of future work.2 The Nature of Relations in EnglishHow are relationships expressed in English sen-tences?
In this section, we show that many rela-tionships are consistently expressed using a com-pact set of relation-independent lexico-syntactic pat-terns, and quantify their frequency based on a sam-ple of 500 sentences selected at random from an IEtraining corpus developed by (Bunescu andMooney,2007).1 This observation helps to explain the suc-cess of open relation extraction, which learns arelation-independent extraction model as describedin Section 3.1.Previous work has noted that distinguished re-lations, such as hypernymy (is-a) and meronymy(part-whole), are often expressed using a small num-ber of lexico-syntactic patterns (Hearst, 1992).
Themanual identification of these patterns inspired abody of work in which this initial set of extractionpatterns is used to seed a bootstrapping process thatautomatically acquires additional patterns for is-a orpart-whole relations (Etzioni et al, 2005; Snow etal., 2005; Girju et al, 2006), It is quite natural thento consider whether the same can be done for all bi-nary relationships.To characterize how binary relationships are ex-pressed, one of the authors of this paper carefullystudied the labeled relation instances and produceda lexico-syntactic pattern that captured the relationfor each instance.
Interestingly, we found that 95%of the patterns could be grouped into the categorieslisted in Table 1.
Note, however, that the patternsshown in Table 1 are greatly simplified by omittingthe exact conditions under which they will reliablyproduce a correct extraction.
For instance, whilemany relationships are indicated strictly by a verb,1For simplicity, we restrict our study to binary relationships.29SimplifiedRelative Lexico-SyntacticFrequency Category Pattern37.8 Verb E1 Verb E2X established Y22.8 Noun+Prep E1 NP Prep E2X settlement with Y16.0 Verb+Prep E1 Verb Prep E2X moved to Y9.4 Infinitive E1 to Verb E2X plans to acquire Y5.2 Modifier E1 Verb E2 NounX is Y winner1.8 Coordinaten E1 (and|,|-|:) E2 NPX-Y deal1.0 Coordinatev E1 (and|,) E2 VerbX , Y merge0.8 Appositive E1 NP (:|,)?
E2X hometown : YTable 1: Taxonomy of Binary Relationships: Nearly 95%of 500 randomly selected sentences belongs to one of theeight categories above.detailed contextual cues are required to determine,exactly which, if any, verb observed in the contextof two entities is indicative of a relationship betweenthem.
In the next section, we show how we can use aConditional Random Field, a model that can be de-scribed as a finite state machine with weighted tran-sitions, to learn a model of how binary relationshipsare expressed in English.3 Relation ExtractionGiven a relation name, labeled examples of the re-lation, and a corpus, traditional Relation Extraction(RE) systems output instances of the given relationfound in the corpus.
In the open extraction task, re-lation names are not known in advance.
The soleinput to an Open IE system is a corpus, along witha small set of relation-independent heuristics, whichare used to learn a general model of extraction forall relations at once.The task of open extraction is notably more diffi-cult than the traditional formulation of RE for sev-eral reasons.
First, traditional RE systems do notattempt to extract the text that signifies a relation ina sentence, since the relation name is given.
In con-trast, an Open IE system has to locate both the set ofentities believed to participate in a relation, and thesalient textual cues that indicate the relation amongthem.
Knowledge extracted by an open system takesthe form of relational tuples (r, e1, .
.
.
, en) that con-tain two or more entities e1, .
.
.
, en, and r, the nameof the relationship among them.
For example, fromthe sentence, ?Microsoft is headquartered in beau-tiful Redmond?, we expect to extract (is headquar-tered in, Microsoft, Redmond).
Moreover, followingextraction, the system must identify exactly whichrelation strings r correspond to a general relation ofinterest.
To ensure high-levels of coverage on a per-relation basis, we need, for example to deduce that?
?s headquarters in?, ?is headquartered in?
and ?isbased in?
are different ways of expressing HEAD-QUARTERS(X,Y).Second, a relation-independent extraction processmakes it difficult to leverage the full set of featurestypically used when performing extraction one re-lation at a time.
For instance, the presence of thewords company and headquarters will be useful indetecting instances of the HEADQUARTERS(X,Y)relation, but are not useful features for identifyingrelations in general.
Finally, RE systems typicallyuse named-entity types as a guide (e.g., the secondargument to HEADQUARTERS should be a LOCA-TION).
In Open IE, the relations are not known inadvance, and neither are their argument types.The unique nature of the open extraction task hasled us to develop O-CRF, an open extraction sys-tem that uses the power of graphical models to iden-tify relations in text.
The remainder of this sectiondescribes O-CRF, and compares it to the extractionmodel employed by TEXTRUNNER, the first OpenIE system (Banko et al, 2007).
We then describeR1-CRF, a RE system that can be applied in a typi-cal one-relation-at-a-time setting.3.1 Open Extraction with Conditional RandomFieldsTEXTRUNNER initially treated Open IE as a clas-sification problem, using a Naive Bayes classifier topredict whether heuristically-chosen tokens betweentwo entities indicated a relationship or not.
For theremainder of this paper, we refer to this model asO-NB.
Whereas classifiers predict the label of a sin-gle variable, graphical models model multiple, in-30K a f k aE N T O E N TO E N T B 	 R E L I 	 R E L, P ra g u ea wr i ter b o r n i nFigure 1: Relation Extraction as Sequence Labeling: ACRF is used to identify the relationship, born in, betweenKafka and Pragueterdependent variables.
Conditional Random Fields(CRFs) (Lafferty et al, 2001), are undirected graphi-cal models trained to maximize the conditional prob-ability of a finite set of labels Y given a set of inputobservations X .
By making a first-order Markov as-sumption about the dependencies among the outputvariables Y , and arranging variables sequentially ina linear chain, RE can be treated as a sequence la-beling problem.
Linear-chain CRFs have been ap-plied to a variety of sequential text processing tasksincluding named-entity recognition, part-of-speechtagging, word segmentation, semantic role identifi-cation, and recently relation extraction (Culotta etal., 2006).3.1.1 TrainingAs with O-NB, O-CRF?s training process is self-supervised.
O-CRF applies a handful of relation-independent heuristics to the PennTreebank and ob-tains a set of labeled examples in the form of rela-tional tuples.
The heuristics were designed to cap-ture dependencies typically obtained via syntacticparsing and semantic role labelling.
For example,a heuristic used to identify positive examples is theextraction of noun phrases participating in a subject-verb-object relationship, e.g., ?<Einstein> received<the Nobel Prize> in 1921.?
An example of aheuristic that locates negative examples is the ex-traction of objects that cross the boundary of an ad-verbial clause, e.g.
?He studied <Einstein?s work>when visiting <Germany>.
?The resulting set of labeled examples are de-scribed using features that can be extracted withoutsyntactic or semantic analysis and used to train aCRF, a sequence model that learns to identify spansof tokens believed to indicate explicit mentions ofrelationships between entities.O-CRF first applies a phrase chunker to each doc-ument, and treats the identified noun phrases as can-didate entities for extraction.
Each pair of enti-ties appearing no more than a maximum number ofwords apart and their surrounding context are con-sidered as possible evidence for RE.
The entity pairserves to anchor each end of a linear-chain CRF, andboth entities in the pair are assigned a fixed label ofENT.
Tokens in the surrounding context are treatedas possible textual cues that indicate a relation, andcan be assigned one of the following labels: B-REL,indicating the start of a relation, I-REL, indicatingthe continuation of a predicted relation, or O, indi-cating the token is not believed to be part of an ex-plicit relationship.
An illustration is given in Fig-ure 1.The set of features used by O-CRF is largelysimilar to those used by O-NB and other state-of-the-art relation extraction systems, They in-clude part-of-speech tags (predicted using a sepa-rately trained maximum-entropy model), regular ex-pressions (e.g.detecting capitalization, punctuation,etc.
), context words, and conjunctions of featuresoccurring in adjacent positions within six words tothe left and six words to the right of the currentword.
A unique aspect of O-CRF is that O-CRFuses context words belonging only to closed classes(e.g.
prepositions and determiners) but not functionwords such as verbs or nouns.
Thus, unlike most REsystems, O-CRF does not try to recognize semanticclasses of entities.O-CRF has a number of limitations, most of whichare shared with other systems that perform extrac-tion from natural language text.
First, O-CRF onlyextracts relations that are explicitly mentioned inthe text; implicit relationships that could inferredfrom the text would need to be inferred from O-CRF extractions.
Second, O-CRF focuses on rela-tionships that are primarily word-based, and not in-dicated solely from punctuation or document-levelfeatures.
Finally, relations must occur between en-tity names within the same sentence.O-CRF was built using the CRF implementationprovided by MALLET (McCallum, 2002), as wellas part-of-speech tagging and phrase-chunking toolsavailable from OPENNLP.22http://opennlp.sourceforge.net313.1.2 ExtractionGiven an input corpus, O-CRF makes a single passover the data, and performs entity identification us-ing a phrase chunker.
The CRF is then used to labelinstances relations for each possible entity pair, sub-ject to the constraints mentioned previously.Following extraction, O-CRF applies the RE-SOLVER algorithm (Yates and Etzioni, 2007) to findrelation synonyms, the various ways in which a re-lation is expressed in text.
RESOLVER uses a prob-abilistic model to predict if two strings refer to thesame item, based on relational features, in an unsu-pervised manner.
In Section 5.2 we report that RE-SOLVER boosts the recall of O-CRF by 50%.3.2 Relation-Specific ExtractionTo compare the behavior of open, or ?unlexicalized,?extraction to relation-specific, or ?lexicalized?
ex-traction, we developed a CRF-based extractor underthe traditional RE paradigm.
We refer to this systemas R1-CRF.Although the graphical structure of R1-CRF is thesame as O-CRF R1-CRF differs in a few ways.
Agiven relation R is specified a priori, and R1-CRF istrained from hand-labeled positive and negative in-stances of R. The extractor is also permitted to useall lexical features, and is not restricted to closed-class words as is O-CRF.
Since R is known in ad-vance, if R1-CRF outputs a tuple at extraction time,the tuple is believed to be an instance of R.4 Hybrid Relation ExtractionSince O-CRF and R1-CRF have complementaryviews of the extraction process, it is natural to won-der whether they can be combined to produce amore powerful extractor.
In many machine learn-ing settings, the use of an ensemble of diverse clas-sifiers during prediction has been observed to yieldhigher levels of performance compared to individ-ual algorithms.
We now describe an ensemble-basedor hybrid approach to RE that leverages the differ-ent views offered by open, self-supervised extractionin O-CRF, and lexicalized, supervised extraction inR1-CRF.4.1 StackingStacked generalization, or stacking, (Wolpert,1992), is an ensemble-based framework in which thegoal is learn a meta-classifier from the output of sev-eral base-level classifiers.
The training set used totrain the meta-classifier is generated using a leave-one-out procedure: for each base-level algorithm, aclassifier is trained from all but one training exampleand then used to generate a prediction for the left-out example.
The meta-classifier is trained using thepredictions of the base-level classifiers as features,and the true label as given by the training data.Previous studies (Ting and Witten, 1999; Zenkoand Dzeroski, 2002; Sigletos et al, 2005) haveshown that the probabilities of each class value asestimated by each base-level algorithm are effectivefeatures when training meta-learners.
Stacking wasshown to be consistently more effective than voting,another popular ensemble-based method in whichthe outputs of the base-classifiers are combined ei-ther through majority vote or by taking the classvalue with the highest average probability.4.2 Stacked Relation ExtractionWe used the stacking methodology to build anensemble-based extractor, referred to as H-CRF.Treating the output of an O-CRF and R1-CRF asblack boxes, H-CRF learns to predict which, if any,tokens found between a pair of entities (e1, e2), in-dicates a relationship.
Due to the sequential natureof our RE task, H-CRF employs a CRF as the meta-learner, as opposed to a decision tree or regression-based classifier.H-CRF uses the probability distribution over theset of possible labels according to each O-CRF andR1-CRF as features.
To obtain the probability ateach position of a linear-chain CRF, the constrainedforward-backward technique described in (CulottaandMcCallum, 2004) is used.
H-CRF also computesthe Monge Elkan distance (Monge and Elkan, 1996)between the relations predicted by O-CRF and R1-CRF and includes the result in the feature set.
Anadditional meta-feature utilized by H-CRF indicateswhether either or both base extractors return ?no re-lation?
for a given pair of entities.
In addition tothese numeric features, H-CRF uses a subset of thebase features used by O-CRF and R1-CRF.
At each32O-CRF O-NBCategory P R F1 P R F1Verb 93.9 65.1 76.9 100 38.6 55.7Noun+Prep 89.1 36.0 51.3 100 9.7 55.7Verb+Prep 95.2 50.0 65.6 95.2 25.3 40.0Infinitive 95.7 46.8 62.9 100 25.5 40.6Other 0 0 0 0 0 0All 88.3 45.2 59.8 86.6 23.2 36.6Table 2: Open Extraction by Relation Category.
O-CRFoutperforms O-NB, obtaining nearly double its recall andincreased precision.
O-CRF?s gains are partly due to itslower false positive rate for relationships categorized as?Other.
?given position i between e1 and e2, the presence ofthe word observed at i as a feature, as well as thepresence of the part-of-speech-tag at i.5 Experimental ResultsThe following experiments demonstrate the benefitsof Open IE for two tasks: open extraction and tar-geted extraction.Section 5.1, assesses the ability of O-CRF to lo-cate instances of relationships when the number ofrelationships is large and their identity is unknown.We show that without any relation-specific input, O-CRF extracts binary relationships with high precisionand a recall that nearly doubles that of O-NB.Sections 5.2 and 5.3 compare O-CRF to tradi-tional and hybrid RE when the goal is to locate in-stances of a small set of known target relations.
Wefind that while single-relation extraction, as embod-ied by R1-CRF, achieves comparatively higher lev-els of recall, it takes hundreds, and sometimes thou-sands, of labeled examples per relation, for R1-CRF to approach the precision obtained by O-CRF,which is self-trained without any relation-specificinput.
We also show that the combination of unlex-icalized, open extraction in O-CRF and lexicalized,supervised extraction in R1-CRF improves precisionand F-measure compared to a standalone RE system.5.1 Open ExtractionThis section contrasts the performance of O-CRFwith that of O-NB on an Open IE task, and showsthat O-CRF achieves both double the recall and in-creased precision relative to O-NB.
For this exper-iment, we used the set of 500 sentences3 describedin Section 2.
Both IE systems were designed andtrained prior to the examination of the sample sen-tences; thus the results on this sentence sample pro-vide a fair measurement of their performance.While the TEXTRUNNER system was previouslyfound to extract over 7.5 million tuples from a cor-pus of 9 million Web pages, these experiments arethe first to assess its true recall over a known set ofrelational tuples.
As reported in Table 2, O-CRF ex-tracts relational tuples with a precision of 88.3% anda recall of 45.2%.
O-CRF achieves a relative gainin F1 of 63.4% over the O-NB model employed byTEXTRUNNER, which obtains a precision of 86.6%and a recall of 23.2%.
The recall of O-CRF nearlydoubles that of O-NB.O-CRF is able to extract instances of the fourmost frequently observed relation types ?
Verb,Noun+Prep, Verb+Prep and Infinitive.
Three of thefour remaining types ?
Modifier, Coordinaten andCoordinatev ?
which comprise only 8% of the sam-ple, are not handled due to simplifying assumptionsmade by both O-CRF and O-NB that tokens indicat-ing a relation occur between entity mentions in thesentence.5.2 O-CRF vs. R1-CRF ExtractionTo compare performance of the extractors when asmall set of target relationships is known in ad-vance, we used labeled data for four different re-lations ?
corporate acquisitions, birthplaces, inven-tors of products and award winners.
The first twodatasets were collected from the Web, and madeavailable by Bunescu and Mooney (2007).
To aug-ment the size of our corpus, we used the same tech-nique to collect data for two additional relations, andmanually labelled positive and negative instances byhand over all collections.
For each of the four re-lations in our collection, we trained R1-CRF fromlabeled training data, and ran each of R1-CRF andO-CRF over the respective test sets, and comparedthe precision and recall of all tuples output by eachsystem.Table 3 shows that from the start, O-CRF achievesa high level of precision ?
75.0% ?
without any3Available at http://www.cs.washington.edu/research/knowitall/hlt-naacl08-data.txt33O-CRF R1-CRFRelation P R P R Train ExAcquisition 75.6 19.5 67.6 69.2 3042Birthplace 90.6 31.1 92.3 64.4 1853InventorOf 88.0 17.5 81.3 50.8 682WonAward 62.5 15.3 73.6 52.8 354All 75.0 18.4 73.9 58.4 5930Table 3: Precision (P) and Recall (R) of O-CRF and R1-CRF.O-CRF R1-CRFRelation P R P R Train ExAcquisition 75.6 19.5 67.6 69.2 3042?Birthplace 90.6 31.1 92.3 53.3 600InventorOf 88.0 17.5 81.3 50.8 682?WonAward 62.5 15.3 65.4 61.1 50All 75.0 18.4 70.17 60.7 >4374Table 4: For 4 relations, a minimum of 4374 hand-taggedexamples is needed for R1-CRF to approximately matchthe precision of O-CRF for each relation.
A ???
indicatesthe use of all available training data; in these cases, R1-CRF was unable to match the precision of O-CRF.relation-specific data.
Using labeled training data,the R1-CRF system achieves a slightly lower preci-sion of 73.9%.Exactly how many training examples per relationdoes it take R1-CRF to achieve a comparable levelof precision?
We varied the number of training ex-amples given to R1-CRF, and found that in 3 out of4 cases it takes hundreds, if not thousands of labeledexamples for R1-CRF to achieve acceptable levelsof precision.
In two cases ?
acquisitions and inven-tions ?
R1-CRF is unable to match the precision ofO-CRF, even with many labeled examples.
Table 4summarizes these findings.Using labeled data, R1-CRF obtains a recall of58.4%, compared to O-CRF, whose recall is 18.4%.A large number of false negatives on the part of O-CRF can be attributed to its lack of lexical features,which are often crucial when part-of-speech taggingerrors are present.
For instance, in the sentence, ?Ya-hoo To Acquire Inktomi?, ?Acquire?
is mistaken fora proper noun, and sufficient evidence of the exis-tence of a relationship is absent.
The lexicalized R1-CRF extractor is able to recover from this error; thepresence of the word ?Acquire?
is enough to recog-R1-CRF HybridRelation P R F1 P R F1Acquisition 67.6 69.2 68.4 76.0 67.5 71.5Birthplace 93.6 64.4 76.3 96.5 62.2 75.6InventorOf 81.3 50.8 62.5 87.5 52.5 65.6WonAward 73.6 52.8 61.5 75.0 50.0 60.0All 73.9 58.4 65.2 79.2 56.9 66.2Table 5: A hybrid extractor that uses O-CRF improvesprecision for all relations, at a small cost to recall.nize the positive instance, despite the incorrect part-of-speech tag.Another source of recall issues facing O-CRF isits ability to discover synonyms for a given relation.We found that while RESOLVER improves the rela-tive recall of O-CRF by nearly 50%, O-CRF locatesfewer synonyms per relation compared to its lexical-ized counterpart.
With RESOLVER, O-CRF finds anaverage of 6.5 synonyms per relation compared toR1-CRF?s 16.25.In light of our findings, the relative tradeoffs ofopen versus traditional RE are as follows.
Open IEautomatically offers a high level of precision withoutrequiring manual labor per relation, at the expenseof recall.
When relationships in a corpus are notknown, or their number is massive, Open IE is es-sential for RE.When higher levels of recall are desir-able for a small set of target relations, traditional REis more appropriate.
However, in this case, one mustbe willing to undertake the cost of acquiring labeledtraining data for each relation, either via a computa-tional procedure such as bootstrapped learning or bythe use of human annotators.5.3 Hybrid ExtractionIn this section, we explore the performance of H-CRF, an ensemble-based extractor that learns to per-form RE for a set of known relations based on theindividual behaviors of O-CRF and R1-CRF.As shown in Table 5, the use of O-CRF as partof H-CRF, improves precision from 73.9% to 79.2%with only a slight decrease in recall.
Overall, F1improved from 65.2% to 66.2%.One disadvantage of a stacking-based hybrid sys-tem is that labeled training data is still required.
Inthe future, we would like to explore the developmentof hybrid systems that leverage Open IE methods,34like O-CRF, to reduce the number of training exam-ples required per relation.6 Related WorkTEXTRUNNER, the first Open IE system, is partof a body of work that reflects a growing inter-est in avoiding relation-specificity during extrac-tion.
Sekine (2006) developed a paradigm for ?on-demand information extraction?
in order to reducethe amount of effort involved when porting IE sys-tems to new domains.
Shinyama and Sekine?s ?pre-emptive?
IE system (2006) discovers relationshipsfrom sets of related news articles.Until recently, most work in RE has been carriedout on a per-relation basis.
Typically, RE is framedas a binary classification problem: Given a sentenceS and a relation R, does S assert R between twoentities in S?
Representative approaches include(Zelenko et al, 2003) and (Bunescu and Mooney,2005), which use support-vector machines fittedwith language-oriented kernels to classify pairs ofentities.
Roth and Yih (2004) also described aclassification-based framework in which they jointlylearn to identify named entities and relations.Culotta et al (2006) used a CRF for RE, yettheir task differs greatly from open extraction.
REwas performed from biographical text in which thetopic of each document was known.
For every en-tity found in the document, their goal was to pre-dict what relation, if any, it had relative to the pagetopic, from a set of given relations.
Under these re-strictions, RE became an instance of entity labeling,where the label assigned to an entity (e.g.
Father) isits relation to the topic of the article.Others have also found the stacking framework toyield benefits for IE.
Freitag (2000) used linear re-gression to model the relationship between the con-fidence of several inductive learning algorithms andthe probability that a prediction is correct.
Overthree different document collections, the combinedmethod yielded improvements over the best individ-ual learner for all but one relation.
The efficacy ofensemble-based methods for extraction was furtherinvestigated by (Sigletos et al, 2005), who experi-mented with combining the outputs of a rule-basedlearner, a Hidden Markov Model and a wrapper-induction algorithm in five different domains.
Of avariety ensemble-based methods, stacking proved toconsistently outperform the best base-level system,obtaining more precise results at the cost of some-what lower recall.
(Feldman et al, 2005) demon-strated that a hybrid extractor composed of a statis-tical and knowledge-based models outperform eitherin isolation.7 Conclusions and Future WorkOur experiments have demonstrated the promise ofrelation-independent extraction using the Open IEparadigm.
We have shown that binary relationshipscan be categorized using a compact set of lexico-syntactic patterns, and presented O-CRF, a CRF-based Open IE system that can extract different re-lationships with a precision of 88.3% and a recall of45.2%4.
Open IE is essential when the number ofrelationships of interest is massive or unknown.Traditional IE is more appropriate for targeted ex-traction when the number of relations of interest issmall and one is willing to incur the cost of acquir-ing labeled training data.
Compared to traditionalIE, the recall of our Open IE system is admittedlylower.
However, in a targeted extraction scenario,Open IE can still be used to reduce the number ofhand-labeled examples.
As Table 4 shows, numer-ous hand-labeled examples (ranging from 50 for onerelation to over 3,000 for another) are necessary tomatch the precision of O-CRF.In the future, O-CRF?s recall may be improvedby enhancements to its ability to locate the variousways in which a given relation is expressed.
We alsoplan to explore the capacity of Open IE to automati-cally provide labeled training data, when traditionalrelation extraction is a more appropriate choice.AcknowledgmentsThis research was supported in part by NSF grantsIIS-0535284 and IIS-0312988, ONR grant N00014-08-1-0431 as well as gifts from Google, and carriedout at the University of Washington?s Turing Center.Doug Downey, Stephen Soderland and Dan Weldprovided helpful comments on previous drafts.4The TEXTRUNNER Open IE system now indexes extrac-tions found by O-CRF from millions of Web pages, and is lo-cated at http://www.cs.washington.edu/research/textrunner35ReferencesE.
Agichtein and L. Gravano.
2000.
Snowball: Ex-tracting relations from large plain-text collections.
InProcs.
of the Fifth ACM International Conference onDigital Libraries.M.
Banko, M. Cararella, S. Soderland, M. Broadhead,and O. Etzioni.
2007.
Open information extractionfrom the web.
In Procs.
of IJCAI.S.
Brin.
1998.
Extracting Patterns and Relations from theWorldWideWeb.
InWebDBWorkshop at 6th Interna-tional Conference on Extending Database Technology,EDBT?98, pages 172?183, Valencia, Spain.R.
Bunescu and R. Mooney.
2005.
Subsequence kernelsfor relation extraction.
In In Procs.
of Neural Informa-tion Processing Systems.R.
Bunescu and R. Mooney.
2007.
Learning to extractrelations from the web using minimal supervision.
InProc.
of ACL.A.
Culotta and A. McCallum.
2004.
Confidence es-timation for information extraction.
In Procs ofHLT/NAACL.A.
Culotta, A. McCallum, and J. Betz.
2006.
Integrat-ing probabilistic extraction models and data miningto discover relations and patterns in text.
In Procs ofHLT/NAACL, pages 296?303.P.
Domingos.
1996.
Unifying instance-based and rule-based induction.
Machine Learning, 24(2):141?168.O.
Etzioni, M. Cafarella, D. Downey, S. Kok, A. Popescu,T.
Shaked, S. Soderland, D. Weld, and A. Yates.2005.
Unsupervised named-entity extraction from theweb: An experimental study.
Artificial Intelligence,165(1):91?134.R.
Feldman, B. Rosenfeld, and M. Fresko.
2005.
Teg - ahybrid approach to information extraction.
Knowledgeand Information Systems, 9(1):1?18.D.
Freitag.
2000.
Machine learning for informationextraction in informal domains.
Machine Learning,39(2-3):169?202.R.
Girju, A. Badulescu, and D. Moldovan.
2006.
Au-tomatic discovery of part-whole relations.
Computa-tional Linguistics, 32(1).M.
Hearst.
1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Procs.
of the 14th In-ternational Conference on Computational Linguistics,pages 539?545.D.
Klein and C. Manning.
2003.
Accurate unlexicalizedparsing.
In ACL.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Procs.
ofICML.A.
McCallum.
2002.
Mallet: A machine learning forlanguage toolkit.
http://mallet.cs.umass.edu.A.
E. Monge and C. P. Elkan.
1996.
The field matchingproblem: Algorithms and applications.
In Procs.
ofKDD.E.
Riloff and R. Jones.
1999.
Learning Dictionaries forInformation Extraction by Multi-level Boot-strapping.In Procs.
of AAAI-99, pages 1044?1049.D.
Roth and W. Yih.
2004.
A linear progamming formu-lation for global inference in natural language tasks.In Procs.
of CoNLL.S.
Sekine.
2006.
On-demand information extraction.
InProc.
of COLING.Y.
Shinyama and S. Sekine.
2006.
Preemptive informa-tion extraction using unrestricted relation discovery.In Proc.
of the HLT-NAACL.G.
Sigletos, G. Paliouras, C. D. Spyropoulos, andM.
Hat-zopoulos.
2005.
Combining infomation extractionsystems using voting and stacked generalization.
Jour-nal of Machine Learning Research, 6:1751,1782.R.
Snow, D. Jurafsky, and A. Ng.
2005.
Learning syn-tactic patterns for automatic hypernym discovery.
InAdvances in Neural Information Processing Systems17.
MIT Press.K.M.
Ting and I. H. Witten.
1999.
Issues in stacked gen-eralization.
Artificial Intelligence Research, 10:271?289.D.
Wolpert.
1992.
Stacked generalization.
Neural Net-works, 5(2):241?260.A.
Yates and O. Etzioni.
2007.
Unsupervised resolu-tion of objects and relations on the web.
In Procs ofNAACL/HLT.D.
Zelenko, C. Aone, and A. Richardella.
2003.
Kernelmethods for relation extraction.
JMLR, 3:1083?1106.B.
Zenko and S. Dzeroski.
2002.
Stacking with an ex-tended set of meta-level attributes and mlr.
In Proc.
ofECML.36
