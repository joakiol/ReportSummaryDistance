Harvesting Re-usable High-level Rulesfor Expository Dialogue GenerationSvetlana StoyanchevCentre for Research in ComputingThe Open UniversityWalton Hall, Milton Keynes, UKs.stoyanchev@open.ac.ukPaul PiwekCentre for Research in ComputingThe Open UniversityWalton Hall, Milton Keynes, UKp.piwek@open.ac.ukAbstractThis paper proposes a method for extract-ing high-level rules for expository dialoguegeneration.
The rules are extracted from di-alogues that have been authored by expertdialogue writers.
We examine the rules thatcan be extracted by this method, focusing onwhether different dialogues and authors ex-hibit different dialogue styles.1 IntroductionIn the past decade, a new area of Natural LanguageGeneration (NLG) has emerged: the automated gen-eration of expository dialogue, also often referred toas scripted, authored or fictive dialogue.
Research inthis area began with the seminal study by Andre?
etal.
(2000), which explored generation of dialoguesbetween a virtual car buyer and seller from technicaldata on a car.
This strand of work was developed fur-ther in the NECA project (van Deemter et al, 2008)and has since been extended to other domains, in-cluding explanation of medical histories (Williamset al, 2007), patient information leaflets (Piwek etal., 2007) and Wall Street Journal articles (Hernaultet al, 2008).Systems for generating expository dialogue haveexplored different inputs (databases, knowledge rep-resentations and text), generation methods (e.g.,rule versus constraint-based approaches) and out-puts (from dialogue scripts in text form to audio andcomputer-animated dialogue).
A common trait of allthese systems is, however, that at some point in thegeneration process, they produce a dialogue script, atext file which specifies what the interlocutors say,possibly enriched with mark-up for dialogue acts,speech and gestures ?
see, e.g., Piwek et al (2002).These systems are different from conventional dia-logue systems in that the system does not engage ina dialogue with the user; rather, the system generatesa dialogue between two or more fictitious charac-ters for the user/audience to view and learn from.
Inother words, the dialogue is used to deliver informa-tion to the user or audience, rather than between theinterlocutors.
Piwek (2008) discusses several empir-ical studies that identify benefits of the use of expos-itory dialogue for education and persuasion.In this paper, we take a step towards addressingtwo shortcomings of the work so far.
Firstly, allthe work cited has relied on hand-crafted resources(typically rules) for creating the dialogue.
With theresources being created by non-expert dialogue au-thors (e.g., academic researchers), generated dia-logues based on these resources may not be optimal;for instance, Williams et al (2007) found that gener-ated dialogues can be too information-dense, requir-ing conversational padding.
Secondly, the resourcesfor creating dialogue are tied to a specific domain,making it hard to redeploy a system in new domains.We propose to address the first issue by automat-ically creating dialogue generation resources from acorpus of dialogues written by known effective dia-logue authors.
This fits in with a trend in dialoguemodelling and generation to create resources fromempirical data (Oh and Rudnicky, 2002; DeVault etal., 2008; Henderson et al, 2008; Belz and Kow,2009).The second issue is addressed by specifying di-alogue generation rules at a level of detail that ab-stracts over the particulars of the domain and fits inwith existing NLG architectures.
The reference ar-chitecture of Reiter and Dale (2000) identifies threeprincipal NLG tasks: Document Planning (DP),Microplanning and Realisation.
DP is primarilynon-linguistic: it concerns selection of informationand organization of this information into a coherentwhole.
The latter is achieved by making sure thatthe information is tied together by Rhetorical Rela-tions such as Contrast, Elaboration and Explanation,in other words, it is part of a Rhetorical Structure.We propose that dialogue generation rules interfacewith Rhetorical Structure and map to a Sequence ofDialogue Acts.Interestingly, the interface between DP and Mi-croplanning has also been identified as a place wheredecisions and preferences regarding style take an ef-fect (McDonald and Pustejovsky, 1985).
A ques-tion that we explore in this paper is whether dialoguestyles exist at the highly abstract level we focus onin this paper.
We concentrate on style in the sense of?
[t]he manner of expression characteristic of a par-ticular writer?1.The remainder of this paper is set up as follows.In Section 2, we introduce the corpus that we use toextract dialogue generation resources.
Section 3 ex-amines the dialogues in the corpus for prima facieevidence for stylistic differences between authors atthe dialogue level.
In Section 4, we describe our ap-proach to extracting high-level dialogue generationrules from the corpus.
Next, in Section 5 we anal-yse the resulting rules, looking for further evidenceof different dialogue styles.
We also compare therules that were harvested from our corpus with hand-crafted rules in terms of content and variety.
Finally,Section 6 contains our conclusions and a discussionof avenues for further research.2 A Parallel Monologue-Dialogue CorpusThe current work makes use of a corpus of human-authored dialogues, the CODA corpus.2 In total, thiscorpus consist of about 800 dialogue turns.
This1From definition 13.a.
of the Oxford English Dictionary athttp://dictionary.oed.com2Further information on the construction of this cor-pus can be found in the annotation manual at comput-ing.open.ac.uk/coda/AnnotationManual.pdf.paper is based on three dialogues from the cor-pus: George Berkeley?s ?Dialogues between Hylasand Philonous?
(extract of 172 turns), Mark Twain?s?What is man??
(extract of 445 turns) and Yuri Gure-vich?s ?Evolving Algebras?
(extract of 89 turns).Berkeley?s dialogue is one of the classics of philoso-phy, arguing for the, at first sight, extravagant claimthat ?there is no such thing as material substance inthe world?.
Twain, according to the EncyclopaediaBritannica ?one of America?s best and most belovedwriters?, takes on the concept of free will.
Gure-vich?s dialogue deals with the mathematical conceptof evolving algebras.
Of these dialogues, Twain isby a large margin the longest (over 800 turns in total)and the only one which is aimed specifically at thegeneral public, rather than an academic/specialistaudience.For each of the dialogues, the corpus also con-tains human-authored monologue which expressesthe same content as the dialogue.
Monologue anddialogue are aligned through mappings from mono-logue snippets to dialogue spans.
As a result, theCODA corpus is a parallel monologue-dialogue cor-pus.
Both the monologue and dialogue come withannotations: the monologue with Rhetorical Struc-ture Theory (RST) relations (Mann and Thompson,1988; Carlson and Marcu, 2001) and the dialogueside with an adaptation of existing Dialogue Act an-notation schemes (Carletta et al, 1997; Core andAllen, 1997).
Table 2 contains an overview of theseRST relations and Dialogue Act labels.3 Dialogue AnalysisIn this section we examine whether there is primafacie evidence for differences in style between thethree dialogues.
Whereas existing work in NLG onstyle has focused on lexical and syntactic choice,see Reiter and Williams (2008), here we focus onhigher-level characteristics of the dialogues, in par-ticular, proportion of turns with multiple dialogueacts, frequencies of dialogue act bigrams, and rela-tion between dialogue acts and speaker roles.An important reason for determining whetherthere are different styles involved, is that this hasimplications for how we use the corpus to createexpository dialogue generation resources.
If differ-ent dialogues employ different styles, we need to beRST relations Dialogue ActsEnablement, Cause, Evaluation (Subjective, Inferred),Comment, Attribution, Condition-Hypothetical, Contrast,Comparison, Summary, Manner-means, Topic-Comment(Problem-Solution, Statement-Response, Question-Answer, Rhetorical Question) Background, Temporal,Elaboration/Explanation, (Additional, General-Specific,Example, Object-attribute, Definition, Evidence, Reason),Same-unitExplain, Info-Request (Init-Factoid-InfoReq, Init-YN-InfoReq, Init-Complex-InfReq), Init-Request-Clarify, Response-Answer (Resp-Answer-Yes/No, and Resp-Answer-Factoid), Resp-Agree, Resp-ContradictTable 1: RST relations and Dialogue Acts used in the CODA corpus.
Annotators used the fine-grainedcategories in italics that are listed in brackets.
For the current study, we rely, however, on the higher-levelcategories that preceed the fine-grained categories and which combine several of them.careful with creating resources which combine datafrom different dialogues.
Merging such data, if any-thing, may lead to the generation of dialogues whichexhibit features from several possibly incompatiblestyles.
Since our aim is specifically to generate dia-logues that emulate the masters of dialogue author-ing, it is then probably better to create resourcesbased on data from a single master or dialogue.3.1 Multi-act TurnsOne of the characteristics of dialogue is the paceand the amount of information presented in eachof the speaker?s turns.
In a fast-paced dialogueturns are concise containing a single dialogue act.Such dialogues of the form A:Init B:Response A:InitB:Response ... are known as ?pingpong?
dialogue.Twain?s ?What is man??
dialogue starts in this fash-ion (O.M.
= Old Man; Y.M = Young Man):O.M.
What are the materials ofwhich a steam-engine is made?Y.M.
Iron, steel, brass, white-metal,and so on.O.M.
Where are these found?Y.M In the rocks.O.M.
In a pure state?Y.M.
No?in ores.. .
.One character serves as the initiator and the otherreplies with a response.
With turns that contain morethan one dialogue, henceforth multi-act turns, thispattern can be broken:O.M.
.
.
.And you not only did not make thatAuthor Twain Gurevich BerkeleyMulti-act 34% 43% 24%Layman/Expert 45%/55% 36%/64% 51%/49%Table 2: Proportion of multi-act utterances and theirdistribution between Layman and Expertmachinery yourself, but you have NOTEVEN ANY COMMAND OVER IT.Y.M.
This is too much.You think I could have formed noopinion but that one?O.M.
Spontaneously?
No.
And .
.
.Multi-act turns are turns comprised of multiple dia-logue acts, such as the Young Man?s in the exam-ple above, where a Resp-Contradict (?This is toomuch.?)
is followed by an Init-YN-Request (?Youthink I could have formed no opinion but that one??
).The dialogue pace may vary throughout a dia-logue.
We, however, find that overall proportionsof multi-act turns and their distribution between ex-pert and layman vary between the authors (see Ta-ble 2).
Gurevich?s dialogue has the highest propor-tion (43%) of multi-act turns and majority of themare attributed to the expert.
Only 24% of Berkeley?sdialogue turns consist of multiple dialogue acts andthey are evenly split between the expert and the lay-man.
Gurevich?s dialogue is the type of dialoguewhere an expert gives a lesson to a layman whilein Berkeley?s dialogue one character often comple-ments ideas of the other character making it difficultto determine which of the characters is an expert.The amount of multi-act turns seems to be one ofthe stylistic choices made by a dialogue author.3.2 Dialogue DiversityFigure 1: Bigram coverage for the 1-st to 4th mostfrequent bigrams.Dialogues are essentially a sequence of turns,where each turn consists of one or more dialogueacts.
For our measure of dialogue diversity we focuson two-turn sequences (i.e., turn bigrams), where aturn is identified by the sequence of dialogue acts itcontains.We define bigram coverage for i as the percent-age that the top i most frequent bigrams contributeto all bigrams in the corpus.
Diversity of the dia-logue is inversely related to the dialogue coverage.In a dialogue with minimal diversity, the same turn,consisting of one or more dialogue acts, is repeatedthroughout the dialogue.
The turn bigram consistingof two such turns has 100% bigram coverage.Figure 1 shows the coverage for 1 ?
i ?
4 foreach author in the corpus.3 Out of the three authors,Twain?s dialogues are the most diverse where the top4 bigrams constitute only 15% of all bigrams.
InGurevich?s dialogues the four most frequent bigramsconstitute 25% and in Berkeley 40%.Note that for all three authors the dialogue cov-erage for the 4 most frequent bigrams is quite lowindicating high variability in bigrams used.
Toachieve such variability in automatically generateddialogues we need a large number of distinct gener-ation rules.3This range was chosen for illustration purposes.
Bigramcoverage can be compared for any i ?total number of distinctbigrams.3.3 Dialogue Acts and Speaker RolesOne of the most frequent bigrams for all three au-thors was, not unexpectedly, the sequence:A: InfoRequestB: Response-AnswerThere is, however, a difference in the roles of speak-ers A and B.
In all dialogues, one of the speakerstook on the expert role and the other the layman role.For the aforementioned bigram, both in Berkeley?sand Gurevich?s dialogues the layman typically ini-tiates the request for information and the expert re-sponds (and often goes on to explain the response inGurevich?s dialogue):Q: Is it difficult to define basictransition rules in full generality?A: No.
Here is the definition.?
Any local function update is a rule.. .
.
(From Gurevich?s dialogue)In contrast, in Twain?s dialogues the roles are typ-ically reversed: the expert asks and the layman re-sponds:O.M.
Then the impulse which moves youto submit to the tax is not ALLcompassion, charity, benevolence?Y.M.
Well?perhaps not.Both techniques allow the author to convey a par-ticular piece of information, but each giving rise itsvery own dialogue style.4 Approach to Rule ExtractionComparing statistics for individual dialogues givesus some idea about whether different styles are in-volved.
The true test for whether different styles areinvolved is, however, whether for the same contentdifferent realizations are generated.
Unfortunately,for our three dialogues the content is different to be-gin with.
The parallel corpus allows us, however, toget around this problem.
From the parallel corpuswe can extract rules which map RST structures todialogue act sequences.
The Lefthand Side (LHS)of a rule represents a particular rhetorical structurefound in the monologue side, whereas the Right-hand Side (RHS) of the rule represents the dialogueact sequence with which it is aligned in the corpus.Such rules can be compared between the differentdialogues: in particular, we can examine whether thesame LHS gives rise to similar or different RHSs.4.1 Comparison with previous workHernault et al (2008) manually construct surface-level rules mapping monologue to dialogue.Surface-level rules execute text-to-text conversionoperating directly on the input string.
In our ap-proach, we separate the conversion into two stages.A first stage converts RST structures to DialogueAct sequences.
A second stage, which is beyondthe scope of this paper, converts Dialogue Act se-quences to text.A further difference between the current approachand Hernault et al?s is that the LHS of our rulescan match nested RST structures.
This covers, whatwe call, simple rules (involving a single RST re-lation, e.g., Contrast(X,Y)) and complex rules (in-volving 2 or more nested RST relations, e.g., Con-trast(Condition(X,Y),Z)).
Hernault et al only allowfor simple rules.
A detailed comparison between ourapproach and that of Hernault et al, using the attri-bution rule as an example, can be found in Section5.3.id DA turns0 Init-YN-InfoReqIs your mind a part of your PHYSI-CAL equipment ?0 Resp-Answer-NoNo.1 Explain It is independent of it ; it is spiritual2 Init-YN-InfoReqBeing spiritual, it cannot be af-fected by physical influences?2 Resp-Answer-NoNo.3 Init-YN-InfoReqDoes the mind remain sober withthe body is drunk ?- decorative Well?3 Resp-Answer-NoNo.Table 3: Example of annotated dialogue (from MarkTwain?s ?What is man??
).4.2 Rule Extraction AlgorithmTable 3 and Figure 2 show annotated dialogue (au-thored by Twain) and its annotated monologue trans-lation.
Each terminal node of the RST structurecorresponds to a part of a monologue snippet.
Allnodes with the same id correspond to a completeConditionAttributionid=2Contrastid=0id=1Being spiritual,by phisical influences.nucid=3Let?s for a minuteassume thatExplanationit can not be affectedyour mind is not partid=0of your physical equipment, it is spiritual.that it is independent of it,However,the mind    does notremain soberwhen the bodyis drunk.nucnucFigure 2: RST structure for the translation of dia-logue in Table 3span rule0-0 Attribution(0, 0)0-1 Attribution( Explanation(0, 1))2-3 Contrast(2, 3)0-3 Condition (Attribution( Ex-plain(0, 1)), Contrast(2, 3))Table 4: RST sub-structures: LHS of monologue-to-dialogue mapping rulessnippet and are linked to the dialogue act(s) with thesame ids.
The relation between monologue snippetsand dialogue act segments is one-to-many.
In otherwords, one snippet (e.g.
snippets with id=0, id=2)can be expressed by multiple dialogue act segments.Rules are extracted as follows: For each (auto-matically extracted) sub-structure of the RST struc-tures on the monologue side, a rule is created (seeTable 4).
Two constraints restrict extraction of sub-structures: 1) spans of the structure?s terminal nodesmust be consecutive and 2) none of the ids of theterminal nodes are shared with a node outside thesub-structure.For example, Explanation(0, 1) is not extractedbecause the node with id=0 appears also under theAttribution relation which is not a part of this sub-structure.Additionally, rules are generated by removing arelation and its satellite node and moving a nucleusnode one level up.
Attribution(0, 0) was extractedfrom a tree that had the Explanation relation and itssatellite child 1 pruned.
This operation relies on thevalidity of the following principle for RST (Marcu,1997): ?If a relation holds between two textual spansof the tree structure of a text, that relation also holdsbetween the most important units of the constituentsubspans.
?The RST sub-structure is the LHS of a rule anddialogue act sequences are the RHS of a rule.5 Results: Analysis of the RulesIn this section we describe the rules collected fromthe corpus.
We compare the rules collected from thedialogues of different authors.
We also compare therules constructed manually in previous work withthe rules collected from the corpus, specifically forthe attribution relation.5.1 Rule Statisticsrelation Twain Gurev Berk allsimple 31 (33) 29 (38) 25 (26) 81 (97)complex 19 26 16 61 (61)null 15 (22) 9 (18) 9 (27) 25 (67)total 65 64 50 167# turns 85 78 96 259Table 5: Numbers of extracted distinct structuralrules (total occurrences are parenthesized)relation Twain Gurevich Berkleyattribution 15% 2% 12%contrast 18% 9% 17%expl/elab 34% 47% 26%eval 9% 6% 21%other 24% 36% 24%total 100% 100% 100%Table 6: Proportions of relations expressed as rulesrelation Twain Gurevich Berkleyoverall 2.4 1.9 2.9contrast 2.3 2 2.6elab/expl 2.7 1.7 3.3eval 2 2 2.5Table 7: Average number of turns in simple rulesSimple rules are the rules with one RST relation inthe LHS.
Complex rules are the rules with multipleRST relations in the LHS.
In Table 4, rules for theLHS 0-0 and 2-3 are simple while the rules for 0-1and 0-3 are complex.
Null rules are the rules with noRST relation in the LHS.From our sample of 259 translated and annotateddialogue turns from the corpus, we extracted 81 sim-ple, 61 complex, and 25 null rules (null rules involveno RST structure and are discussed below).
Table 5shows the number of distinct rules per author.4 Inparentheses we show the number of actual (not nec-essarily distinct) rule occurrences in corpus.
Themajority of simple rules in the corpus (65 out of 81)occur only once.5 This shows that the dialogue au-thors use a variety of dialogue act sequences whenpresenting their arguments in dialogue.To compare dialogue styles we compare the rulesacross the dialogues of different authors.
Table 6shows the proportions of relation types in each au-thor?s dialogues that are mapped to a dialogue struc-ture and produce a mapping rule.6 Not all relationsin monologue are mapped to a dialogue structure.For example, Explain moves may contain multipleclauses that are presented by a single character inthe same turn.
We find differences in distributionsof relation types mapped to dialogue between thethree authors (Fisher?s exact test p<.01).
Berkeley?sdialogues produce more mapping rules with Eval-uation and less with Explanation/Elaboration rela-tions than the other two authors.
Gurevich?s di-alogues produce less mapping rules with Attribu-tion and Contrast relations than the other two au-thors.
This difference between distributions of re-lation types mapped to dialogue has an importantimplication for dialogue generation.
Dialogue gen-eration programs may vary the style of a dialogueby choosing which discourse relations of the mono-logue are mapped to dialogue turns.Another relevant property of a rule is the numberof turns in the RHS of the rule.
Number of turns in arule shows how many times the dialogue charactersswitch to present information of the monologue cor-responding to the LHS of the rule.
The average num-bers of turns in the RHS of all rules of the Twain,Gurevich, and Berkeley dialogues are 2.4, 1.9, 2.9respectively (see Table 7).
They are all pairwise sig-nificantly different (t-test p < .05) ranking the au-4Two rules are distinct if either their LHS (relation in mono-logue) or RHSs (sequence of dialogue acts) are different.565=81-(97-81)6This includes simple and complex rulesthors in the order Gurevich < Twain < Berkeleyaccording to the number of turns in the RHS of therule.
Similar ranking also appears as a trend for in-dividual relations suggesting that this is the effect ofthe author?s style rather than the relations (the dis-tribution of relation types is different across the au-thors).
This suggests that dialogue generation mayaffect the style of automatically generated dialogueby selectively choosing rules with longer (or shorter)RHS.5.2 Null RuleA null rule is a rule where a sequence of dialogueturns between two characters corresponds with a textsegment with no rhetorical relation.
A text segmentwithout a rhetorical relation corresponds to a leafnode in the RST structure.
A null rule typically cre-ates a dialogue fragment consisting of a yes/no ques-tion (Init-YN-Info-Req) followed by yes/no answer,or a complex information request (e.g.
What is youropinion on X?)
followed by an Explain dialogue act,or a presentation of an argument (Explain dialogueact) followed by a response that signals agreement(Resp-Agree).
Null rules create more interactivity inthe dialogue.The monologue segment corresponding to theLHS of a null rule may be in a rhetorical relationwith another segment, such that the LHS of the nullrule is embedded into another rule.
Table 8 shows anexample of a null rule embedded in a contrast rule.Turns 1 - 3 correspond to the RHS of the Null ruleand 1 - 4 correspond to the RHS of the Contrast rule.Null rules can be used to turn information intodialogue, even when there is no RST relation.
Forexample, we may want to convey the piece of in-formation A,B,C,D,E in that order, with rel1(A,B)and rel2(D,E).
Whereas a simple rule may apply torelations and turn them into dialogue, C is left un-touched.
However, a null rule can be applied to C, toalso turn its presentation into a dialogue exchange.5.3 Case Study: the Attribution RuleIn this section we present a comparison of manu-ally created rules for the RST attribution relation andrules extracted from the CODA corpus.Hernault et al manually construct two surface-level rules for the Attribution (S,N)7 relation (see7N is a nucleus phrase that carries main information and S isTable 9).
In the Dialogue Act column we showthe dialogue act representation of the correspond-ing surface-level rules.
The first rule converts attri-bution relation into a Complex-Info-Request by theLayman followed with the Explain by the Expert.The second rule converts the attribution relation intoExplain by the Expert, Factoid-Info-Request by theLayman and Factoid-Response by Expert.
In bothrules, the Expert is the one providing information(N) to the Layman and information is presented inExplain dialogue actTable 10 shows six attribution rules we collectedfrom phrases with attribution relation in the corpus(Twain1-4,Berkeley1,Gurevich)8.
We notice severaldifferences with the manually constructed rules:?
The variety of dialogue act sequences: eachRHS of the rule (or dialogue act sequence) isdifferent.?
Main information (N) can be presented byeither the expert (Twain1, Twain2, Twain3,Berkeley1) or by the layman (Twain4, Gure-vich1).?
Main information (N) can be presented indifferent dialogue acts: Explain dialogue act(Twain1, Twain4, Berkeley), YN-Info-Request(Twain2, Twain3), or Complex-Info-Request(Gurevich).?
Contextual information is part of the rule andmay be used when choosing which rule to ap-ply.6 Conclusions and Further WorkIn this paper, we have introduced a new approach tocreating resources for automatically generating ex-pository dialogue.
The approach is based on ex-tracting high-level rules from RST relations to Di-alogue Act sequences using a parallel Monologue-Dialogue corpus.
The approach results in rules thatare reusable across applications and based on knownexpert dialogue authors.After examining differences between the dia-logues in the corpus in order to obtain prima facieevidence for differences in style, we conducted adetailed evaluation of the rules that were extracteda satellite phrase that contains the entity to whom N is attributed8These are all the rules for attribution RST relation from 50annotated turns for each authorTurn Speaker Dialogue act DialogueContrast rule.
Segment with contrast relation:[He never does anything for any one else?s comfort , spiritual or physical.]
[EXCEPT ON THOSE DISTINCT TERMS?
that it shall FIRST secure HIS OWN spiritual comfort ].Null rule.
Segment without rhetorical relation:He never does anything for any one else?s comfort , spiritual or physical1 Layman decorative Come!2 Expert Init-YN-Request He never does anything for any one else ?
s comfort , spiritual or physical ?3 Expert Resp-Answer-No No4 Expert Explain EXCEPT ON THOSE DISTINCT TERMS ?
that it shall FIRST secure HISOWN spiritual comfort .Table 8: Contrast rule example containing null rule from Twain dialogue.Rule 1Speaker Surface-level Rule Dialogue act Example DialogueLayman What did + GetSubject(S+N) + Getmain-VerbLemma(S+N)Complex-Info-Request What did S say?Expert AddifNotPresentIn(N, That) + N Explain NRule 2Expert RemoveIfPresentIn(N, That) + N Explain NLayman Who GetMainVerb(N) that?
Factoid-Info-Req Who said that?Expert GetSubjectFromSentence(S+N) Factoid-Response S didTable 9: Manually created rules for Attribution(S,N) relation (Hernault et al, 2008)from the corpus.
We extracted 167 distinct rules anddiscussed the three types of rules: null, simple andcomplex (depending on the number of RST relationin the LHS: 0, 1 or more).We found differences between authors in severalrespects, specifically:?
number of turns per simple rule?
number of dialogue acts per simple rule?
combination of speaker roles and dialogue actsA detailed comparison between our automaticallyextracted attribution rule and the hand-crafted rulesused by Hernault et al showed up a number ofdifferences.
Apart from the fact that the corpusyielded many more rules than the two manually cre-ated ones, there were differences in which interlocu-tor presented particular information and which dia-logue acts were being used.The current work has focussed on high-level map-ping rules which can be used both for generationfrom databases and knowledge representations andalso for generation from text.
In future work, wewill focus on mapping text (in monologue form) todialogue.
For this we need to combine the high-level rules with rules for paraphrasing the text in themonologue with text for the dialogue acts that ex-press the same information in dialogue form.
Forautomatically extracting these surface level map-pings we will draw on the approach to learning para-phrases from a corpus that is described in Barzilayand McKeown (2001).
An important component ofour future effort will be to evaluate whether automat-ically generating dialogues from naturally-occurringmonologues, following the approach described here,results in dialogues that are fluent and coherent andpreserve the information from the input monologue.AcknowledgementsWe would like to thank the anonymous reviewersof INLG2010 for their helpful comments and ourcolleagues in the Open University?s NLG groupfor stimulating discussions on the content of thispaper.
The research reported in this paper wascarried out as part of the CODA project (CO-herent Dialogue Automatically generated fromtext; see http://computing.open.ac.uk/coda/)which is funded by the UK Engineering andPhysical Sciences Research Council under grantEP/G/020981/1.ReferencesE.
Andre?, T. Rist, S. van Mulken, M. Klesen, andS.
Baldes.
2000.
The automated design of believabledialogues for animated presentation teams.
In Em-Speaker Dialogue act DialogueTwain1 I will put that law into words, keep it in your mind: FROM HIS CRADLE TO HIS GRAVE A MAN NEVER DOES...Satellite of SummaryLayman Init-YN-InfoReq Will you put that law into words?Expert Resp-Answer-Yes Yes.Expert Resp-Explain This is the law, keep it in your mind.
FROM HIS CRADLE TO HIS GRAVE AMAN NEVER DOES...Twain2 I can not imagine that there is some other way of looking at it.
Satellite of ExplanationExpert Init-Complex-InfoReq /clarify What makes you think that?Layman decorative Pray what else could I think?Expert Init-YN-InfoReq Do you imagine that there is some other way of looking at it?Twain3 One cannot doubt that he felt well.Satellite of Evaluation-ConclusionExpert Init-YN-InfoReq He felt well?Layman Resp-Answer-Yes One cannot doubt it.Twain4 As I said a minute ago Hamilton fought that duel to get PUBLIC approval.
Nucleus of ExplanationLayman Init-Explain/contradict A minute ago you said Hamilton fought that duel to get PUBLIC approval.Resp-Agree Resp-Agree I did.Berkeley1 You can not conceive a vehement sensation to be without pain or pleasure.Expert Init-Explain Again, try in your thoughts, Hylas, if you can conceive a vehement sensation tobe without pain or pleasure.Layman Resp-Contradict You can not.Gurevich I will explain what static algebras are exactly.
Nucleus of Statement-responseLayman Init-Complex-InfoReq Please explain to me what static algebras are exactly.Expert Resp-Agree Gladly.Table 10: Attribution Examples.
Satellite is italicised.bodied Conversational Agents, pages 220?255.
MITPress, Cambridge, Mass.R.
Barzilay and K. McKeown.
2001.
Extracting Para-phrases from a Parallel Corpus.
In Proceedings of theACL, Toulouse, France.A.
Belz and E. Kow.
2009.
System Building Cost vs.Output Quality in Data-to-Text Generation.
In Pro-ceedings of the 12th European Workshop on NaturalLanguage Generation (ENLG?09), Athens, Greece.J.
Carletta, A. Isard, and J. C. Kowtko.
1997.
The relia-bility of a dialogue structure coding scheme.
Compu-tational Linguistics, 23:13?31.L.
Carlson and D. Marcu.
2001.
Discourse taggingreference manual.
Technical Report ISI-TR-545, ISI,September.M.
Core and J. Allen.
1997.
Coding dialogs with thedamsl annotation scheme.
In Working Notes: AAAIFall Symposium on Communicative Action in Humansand Machine.D.
DeVault, D. Traum, and R. Artstein.
2008.
MakingGrammar-Based Generation Easier to Deploy in Dia-logue Systems.
In Procs SIGdial 2008, Ohio, June.E.Reiter and S. Williams.
2008.
Three approaches togenerating texts in different styles.
In Proceedings ofthe Symposium on Style in text: creative generationand identification of authorship.J.
Henderson, O.
Lemon, and K. Georgila.
2008.
Hy-brid Reinforcement / Supervised Learning of DialoguePolicies from Fixed Datasets.
Computational Linguis-tics, 34(4):487?511.H.
Hernault, P. Piwek, H. Prendinger, and M. Ishizuka.2008.
Generating dialogues for virtual agents usingnested textual coherence relations.
In IVA08: 8th In-ternational Conference on Intelligent Virtual Agents.William C. Mann and Sandra A. Thompson.
1988.Rhetorical structure theory: Toward a functional the-ory of text organization.
Text, 8(3):243?281.D.
Marcu.
1997.
From Discourse Structures toText Summaries.
In The Proceedings of theACL?97/EACL?97 Workshop on Intelligent ScalableText Summarization, pages 82?88, Madrid, Spain.D.
McDonald and J. Pustejovsky.
1985.
A computationaltheory of prose style for natural language generation.In Proceedings of the second conference on Europeanchapter of the Association for Computational Linguis-tics, pages 187?193, Geneva, Switzerland.A.
Oh and A. Rudnicky.
2002.
Stochastic natural lan-guage generation for spoken dialog.
Computer Speechand Language, 16(3/4):387?407.P.
Piwek, B. Krenn, M. Schroeder, M. Grice, S. Bau-mann, and H. Pirker.
2002.
RRL: A Rich Repre-sentation Language for the Description of Agent Be-haviour in NECA.
In Proceedings of the AAMAS work-shop ?Embodied conversational agents - let?s specifyand evaluate them!
?, Bologna, Italy, July.P.
Piwek, H. Hernault, H. Prendinger, and M. Ishizuka.2007.
T2D: Generating Dialogues between VirtualAgents Automatically from Text.
In Intelligent VirtualAgents, LNAI 4722, pages 161?174.
Springer Verlag.P.
Piwek.
2008.
Presenting Arguments as Fictive Dia-logue.
In Proceedings of 8th Workshop on Computa-tional Models of Natural Argument (CMNA08), Patras,Greece, July.
ISBN 978-960-6843-12-9.E.
Reiter and R. Dale.
2000.
Building Natural Lan-guage Generation Systems.
Cambridge UniversityPress, Cambridge.K.
van Deemter, B. Krenn, P. Piwek, M. Klesen,M.
Schroeder, and S. Baumann.
2008.
Fully gener-ated scripted dialogue for embodied agents.
ArtificialIntelligence Journal, 172(10):1219?1244.S.
Williams, P. Piwek, and R. Power.
2007.
Generat-ing Monologue and Dialogue to Present PersonalisedMedical Information to Patients.
In Procs ENLG2007, pages 167?170, Schloss Dagstuhl, Germany.
