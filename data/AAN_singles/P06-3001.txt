Proceedings of the COLING/ACL 2006 Student Research Workshop, pages 1?6,Sydney, July 2006. c?2006 Association for Computational LinguisticsA Flexible Approach to Natural Language Generation for DisabledChildrenPradipta BiswasSchool of Information TechnologyIndian Institute of Technology, Kharagpur 721302  INDIApbiswas@sit.iitkgp.ernet.inAbstractNatural Language Generation (NLG) is away to automatically realize a correct ex-pression in response to a communicativegoal.
This technology is mainly exploredin the fields of machine translation, re-port generation, dialog system etc.
In thispaper we have explored the NLG tech-nique for another novel application-assisting disabled children to take part inconversation.
The limited physical abilityand mental maturity of our intended usersmade the NLG approach different fromothers.
We have taken a flexible ap-proach where main emphasis is given onflexibility and usability of the system.The evaluation results show this tech-nique can increase the communicationrate of users during a conversation.1 Introduction?Natural Language Generation?
also known as?Automated Discourse Generation?
or simply?Text Generation?, is a branch of computationallinguistics, which deals with automatic genera-tion of text in natural human language by themachine.
It can be conceptualized as a processleading from a high level communicative goal toa sequence of communicative acts that accom-plish this communicative goal (Rambow et.
al.,2001).
Based on input representation, any NLGtechnique can be broadly classified into twoparadigms viz.
Template based Approach andPlan based approach.
The template-based ap-proach does not need large linguistic knowledgeresource but it cannot provide the expressivenessor flexibility needed for many real domains(Langkilde and Knight, 1998).
In (Deemter et.al., 1999), it has been tried to prove with the ex-ample of a system (D2S: Direct to Speech) thatboth of the approaches are equally powerful andtheoretically well founded.
The D2S system usesa tree structured template organization that re-sembles Tag Adjoining Grammar (TAG) struc-ture.
The template-based approach that has beentaken in the system, enables the basic languagegeneration algorithms application independentand language independent.
At the final stage oflanguage generation it checks the compatibilityof the sentence structure with the current contextand validates the result with Chomsky?s bindingtheory.
For this reason it is claimed to be as wellfounded as any plan-based approach.
As anotherpractical example of NLG technique, we canconsider the IBM MASTOR system (Liu et.
al.,2003).
It is used as speech-to-speech translatorbetween English and Mandarin Chinese.
TheNLG part of this system uses trigram languagemodel for selecting appropriate inflectional formfor target language generation.When NLG (or NLP) technology is ap-plied in assistive technology, the focus is shiftedto increase communication rate rather than in-creasing the efficiency of input representation.As for example, CHAT (Alm, 1992) software isan attempt to develop a predictive conversationmodel to achieve higher communication rate dur-ing conversation.
This software predicts differentsentences depending on situation and mood ofthe user.
The user is free to change the situationor mood with a few keystrokes.
In ?Compan-sion?
project (McCoy, 1997), a novel approachwas taken to enhance the communication rate.The system takes telegraphic message as inputand automatically produces grammatically cor-rect sentences as output based on NLP tech-niques.
The KOMBE Project (Pasero, 1994) triesto enhance the communication rate in a differentway.
It predicts a sentence or a set of sentence bytaking sequence of words from users.
The San-yog project (Sanyog, 2006)(Banerjee, 2005) ini-tiates a dialog with the users to take differentportions (eg.
Subject, verb, predicate etc.)
of asentence and automatically constructs a gram-matically correct sentence based on NLG tech-niques.12 The Proposed ApproachThe present system is intended to be used bychildren with severe speech and motor-impairment.
It will cater those children who canunderstand different parts of a sentence (like sub-ject, object, verb etc.)
but do not have the compe-tence to construct a grammatically correct sen-tence by properly arranging words.
The intendedaudience offers both advantages and challengesto our NLG technique.
The advantage is we canlimit the extent of sentence types that have to begenerated.
But the challenges overwhelm thisadvantage.
The main challenges identified so farcan be summarized as follows. Simplicity in interacting with user due tolimited mental maturity level of users Flexibility in taking input Generating sentences with minimumnumber of keystrokes due to the limitedphysical ability of the users Generating the most appropriate sen-tence in the first chance since we do nothave any scope to provide users a set ofsentences and ask them to choose onefrom the set.In the next few sections the NLG techniqueadopted in our system will be discussed in de-tails.
Due to limited vocabulary and educationlevel of our intended users, our NLG techniquewill generate only simple active voice sentences.The challenges are also tried to be addressed indeveloping the NLG technique.Generally an NLG system can be divided intothree modules viz.
Text Planning, MicroPlanningand Realization.
In (Callaway and Lester, 1995),the first two modules are squeezed into a plan-ning module and results only two subtasks in anNLG system.
Generally in all the approaches ofNLG, the process starts with different parts of asentence and each of these parts can be desig-nated as a template.
After getting values for thesetemplates the templates are arranged in a speci-fied order to form an intermediate representationof a sentence.
Finally the intermediate represen-tation undergoes through a process viz.
Surfacerealization to form a grammatically correct andfluent sentence.
Thus any NLG technique can bebroadly divided into two parts Templates fill up Surface realizationNow each of these two steps for our system willbe discussed in details.2.1 Templates fill upWe defined templates for our system based onthematic roles and Parts of Speech of words.
Wetagged each sentence of our corpus (the corpus isdiscussed in section 4.1) and based on thistagged corpus, we have classified the templatesin two classes.
One class contains the high fre-quency templates i.e.
templates that are con-tained in most of the sentences.
Examples of thisclass of templates include subject, verb, objectetc.
The other class contains rest of the tem-plates.
Let us consider the first class of templatesare designated by set A={a1,a2,a3,a4?.}
andother class is set B={b1,b2,b3,b4,????..
}.Our intention is to offer simplicity and flexibilityto user during filling up the templates.
So eachtemplate is associated with an easy to understandphrase likeSubject=> WhoVerb=> ActionObject=> WhatDestination=>To WhereSource=>From Where??
?..etc.To achieve the flexibility, we show all the tem-plates in set A to user in the first screen (thescreenshot is given in fig.
1, however the screenwill not look as clumsy as it is shown becausesome of the options remain hidden by default andappear only on users?
request).
The user is free tochoose any template from set A to start sentenceconstruction and is also free to choose any se-quence during filling up values for set A. Thesystem will be a free order natural language gen-erator i.e.
user can give input to the system usingany order; the system will not impose any par-ticular order on the user (as imposed by the San-yog Project).
Now if the user is to search for allthe templates needed for his/her sentence, thenboth the number of keystrokes and cognitive loadon user will increase.
So with each template ofset A we defined a sequence of templates takingtemplates from both set A and set B.
Let userchooses template ak.
Now after filling up tem-plate ak, user will be prompted with a sequenceof templates like ak1, ak2, ak3, bk1, bk2, bk3,etc.
to fill up.
Again the actual sequence that willbe prompted to user will depend on the input thatis already given by user.
So the final sequenceshown to the user will be a subset of the prede-fined sequence.
Let us clear the concept with anexample.
Say a user fills up the template <Desti-nation>.
Now s/he will be requested to give val-ues for template like <Source>, <Conveyance>,<Time>, <Subject> etc, excluding those which2are already filled up.
As the example shows, theuser needs not to search for all templates as wellas s/he needs not to fill up a template more thanonce.
This strategy gives sentence compositionwith minimum number of keystrokes in most ofthe cases.2.2 Surface RealizationIt consists of following steps Setting verb form according to the tensegiven by user Setting Sense Setting Mood Phrase ordering to reflect users intentionEach of these steps is described next.The verb form will be modified according to theperson and number of the subject and the tensechoice given by the user.The sense will decide the type of the sentence i.e.whether it is affirmative, negative, interrogativeor optative.
For negative sense, appropriate nega-tive word (e.g.
No, not, do not) will be insertedbefore the verb.
The relative position of the or-der of the subject and verb will be altered foroptative and interrogative sentences.The mood choice changes the main verb of thesentence to special verbs like need, must etc.
Ittries to reflect the mood of the user during sen-tence composition.Finally the templates are grouped to constitutedifferent phrases.
These phrases are ordered ac-cording to the order of the input given by theuser.
This step is further elaborated in section3.2.3 A Case StudyIn this section a procedural overview of the pre-sent system will be described.
The automaticlanguage generation mechanism of the presentsystem uses the following stepsTaking Input from UsersThe user has to give input to the system using theform shown in fig.
1.
As shown in the form theuser can select any property (like tense, mood orsense) or template at any order.
The user can se-lect tense, mood or sentence type by clicking onappropriate option button.
The user can give in-put for the template by answering to the follow-ing questions?
Action?
Who?
Whom?
With Whom?
What?
From Where?
To Where?
Vehicle Used ?
?etc.After selecting a thematic role, a second formwill come as shown in Fig.
2.
From the formshown at Fig 2, the user can select as manywords as they want.
Even if they want they cantype a word (e.g.
his /her own name).
The punc-tuations and conjunction will automatically beinserted.Fig.
1: Screenshot of dialog based interfaceFig.
2: Screenshot of word selection interfaceTemplate fill-upAfter giving all the input the user asks the systemto generate the sentence by clicking on ?generatesentence?
Button.
The system is incorporatedwith several template organizations and a default3template organization.
Examples of some ofthese template organizations are as follows?
SUBJECT VERB?
SUBJECT VERB INANIMATE OBJECT?
SUBJECT VERB ANIMATE OBJECT?
SUBJECT VERB WITH COAGENT?
SUBJECT VERB INANIMATE OBJECTWITH COAGENT?
SUBJECT VERB INANIMATE OBJECTWITH INSTRUMENT?
SUBJECT VERB SOURCE DESTINA-TION BY CONVEYANCE?
SUBJECT VERB SOURCE DESTINA-TION WITH COAGENTThe system select one such template organizationbased on user input and generates the intermedi-ate sentence representation.Verb modification according to tenseThe intermediate sentence is a simple presenttense sentence.
According to the user chosentense, the verb of the intermediate sentence getmodified at this step.
If no verb is specified, ap-propriate auxiliary verb will be inserted.Changing Sentence TypeUp to now the sentence remain as an affirmativesentence.
According to the user chosen sense thesentence gets modified in this step.
E.g.
Forquestion, the verb comes in front, for negativesentence not, do not, did not or does not is in-serted appropriately.Inserting Modal VerbsFinally the users chosen modal verbs like must,can or need are inserted into the sentence.
Forsome modal verbs (like can or need) the systemalso changes the form of the verb (like can orcould).3.1 Example of Sentence Generation usingOur ApproachLet us consider some example of language gen-eration using our system.Example 1Let the user wants to tell, ?I am going to schoolwith father?Step 1: The user inputs will beWho => ITo Where => schoolWith Whom => fatherMain Action => goTense => Present ContinuousStep 2: Template Organization SelectionBased on user input the following template or-ganization will be selectedSUBJECT VERB DESTINATION WITH CO-AGENTStep 3: Verb Modification according to tenseSince the selected tense is present continuousand subject is first person singular number, so?go?
will be changed to ?am going?.Step 4: In this case there is no change of the sen-tence due to step 4.Step 5: There is no change of the sentence due tostep 5.So the final output will be ?I am going to schoolwith father?.
It is same as the user intended sen-tence.Example 2Let the user wants to tell, ?You must eat it?Step 1: The user inputs will beWho => YouMain Action => eatWhat => itMood => mustTense => Present SimpleStep 2: Template Organization SelectionBased on user input the following template or-ganization will be selectedSUBJECT VERB INANIMATE OBJECTStep 3: Verb Modification according to tenseSince the tense is present simple so there will beno change in verb.Step 4: In this case there is no change of the sen-tence due to step 4.Step 5: The modal verb will be inserted beforethe verbSo the final output will be ?You must eat it?Example 3Let the user wants to tell, ?How are you?Step 1: The user inputs will beWho => YouSense => QuestionWh-word => HowTense => Present SimpleStep 2: Template Organization SelectionThere is no appropriate template for this input.Hence the default template organization will bechosen.Step 3: Verb Modification according to tense4Since no action is specified, the auxiliary verbwill be selected as the main verb.
Here the sub-ject is second person and tense is present simple,so the verb selected is ?are?.Step 4: Since the selected sentence type is?Question?, so the verb will come in front of thesentence.
Again, since a Wh-word has been se-lected, it will come in front of the verb.
A ques-tion mark will automatically be appended at theend of the sentence.Step 5: There is no change of the sentence due tostep 5.So the final output will be ?How are you?
?3.2 Phase ordering to reflect users?
inten-tionAn important part of any NLG system is prag-matics that can be defined as the reference to theinterlocutors and context in communication(Hovy, 1990).
In (Hovy, 1990), a system viz.PAULINE has been described that is capable ofgenerating different texts for the same communi-cative goals based on pragmatics.
In PAULINE,the pragmatics has been represented by rhetoricalgoals.
The rhetorical goals defined several situa-tions that dictate all the phases like topic collec-tion, topic organization and realization.
Inspiredfrom the example of PAULINE the present sys-tem has also tried to reflect users?
intention dur-ing sentence realization.
Here the problem is thelimited amount of input for making any judiciousjudgment.
The input to the system is only a se-quence of words with correspondence to a seriesof questions.
A common finding is that we ut-tered the most important concept in a sentenceearlier than other parts of the sentence.
So wehave tried to get the users?
intention from theorder of input given by user based on the beliefthat the user will fill up the slots in order of theirimportance according to his/her mood at thattime.
We have associated a counter with eachtemplate.
The counter value is taken from aglobal clock that is updated with each word se-lection by the user.
Each sentence is divided intoseveral phrases before realization.
Now eachphrase constitute of several templates.
For exam-ple let S be a sentence.
Now S can be dividedinto phrases like P1, P2, P3?..
Again eachphrase Pi can be divided into several templateslike T1, T2, T3?.Based on the counter value ofeach template, we have calculated the rank ofeach phrase as the minimum counter value of itsconstituent templates i.e.Rank(Pi)=Minimum(Counter(Tj)) for all j in PiNow before sentence realization the phrases areordered according to their rank.
Each of thesephrase orders produces a separate sentence.
Asfor example let the communication goal is ?I goto school from home with my father?.
If the inputsequence is (my father -> I -> go -> school ->home), the generated sentence will be ?With myfather I go from home to School?.
Again if theinput sequence is (school -> home -> I -> go ->my father), then the generated sentence will be?From home to school I go with my father.
?Thus for the same communicative goal, thesystem produces different sentences based onorder of input given by user.4 EvaluationThe main goal of our system is to develop acommunication aid for disabled children.
So theperformance metrics concentrated on measuringthe communication rate that has little importancefrom NLG point of view.
To evaluate our systemfrom NLG point of view we emphasize on theexpressiveness and ease of use of the system.The expressiveness is measured by the percent-age of sentences that was intended by user andalso successfully generated by our system.
Theease of use is measured by the average numberof inputs needed to generate each sentence.4.1 Measuring ExpressivenessTo know the type of sentences used by our in-tended users during conversation, first we ana-lyzed the communication boards used by dis-abled children.
Then we took part in some actualconversations with some spastic children in aCerebral Palsy institute.
Finally we interviewedtheir teachers and communication partners.Based on our research, we developed a list ofaround 1000 sentences that covers all types ofsentences used during conversation.
This list isused as a corpus in both development andevaluation stage of our system.
During develop-ment the corpus is used to get the necessary tem-plates and for classification of templates (refersec.
2.1).
After development, we tested the scopeof our system by generating some sentences thatwere exactly not in our corpus, but occurred insome sample conversations of the intended users.In 96% cases, the system is successful to gener-ate the intended sentence.
After analyzing therest 4% of sentence, we have identified followingproblems at the current implementation stage.5 The system cannot handle gerunds as ob-ject to preposition.
(e.g.
He ruins hiseyes by reading small letters). The system is yet not capable to generatecorrect sentence with an introductory?It?.
(e.g.
It is summer).
In these situa-tions the sentence is correctly generatedwhen ?It?
is given as an agent, which isnot intended.4.2 Measuring ease of useTo calculate the performance of the system, wemeasured the number of inputs given by user forgenerating sentence.
The input consists of words,tense choice, mood option and sense choicegiven by user.
Next we plot the number of inputsw.r.t.
the number of words for each sentence.Fig.
3 shows the plot.
It can be observed from theplot that as the number of words increases (i.e.for longer sentences), the ratio of number of in-puts to number of words decreases.
So effortfrom users?
side will not vary remarkably withsentence length.
The overall communication rateis found to be 5.52 words/min (27.44 charac-ters/min) that is better than (Stephanidis, 2003).Additionally it is also observed that the commu-nication rate is increasing with longer conversa-tions.5 ConclusionThe present paper discusses a flexible ap-proach for natural language generation for dis-abled children.
A user can start a sentence gen-eration from any part of a sentence.
The inherentsentence plan will guide him to realize a gram-matically correct sentence with minimum num-ber of keystrokes.
The present system respectsthe pragmatics of a conversation by reorderingdifferent parts of a sentence following users?
in-tention.
The system is evaluated both from ex-pressiveness and performance point of views.Initial evaluation results show this approach canincrease the communication rate of intended us-ers during conversation.AcknowledgementThe author is grateful to Media Lab AsiaLaboratory of IIT Kharagpur and Indian Instituteof Cerebral Palsy, Kolkata for exchanging ideasand providing resources for the present work.NLG Performance010200 10 20 30Number of WordsNumber ofInputsFig.
3: Line graph for performance meas-urement of the systemReferencesAlm N., Arnott J. L., Newell A. F. 1992, Prediction andConversational Momentum in an Augmentative Com-munication System, Communications of the ACM, vol.55, No.
5, May 1992Banerjee A.
2005, A Natural Language Generation Frame-work for an Interlingua-based Machine Translation Sys-tem,  MS Thesis, IIT KharagpurCallaway Charles B., Lester James C. 1995, Robust NaturalLanguage Generation from Large-Scale KnowledgeBases, Proceedings of the Fourth Bar-Ilan Symposiumon FoundationsHovy E. H. 1990, Pragmatics and Natural Language Gen-eration, Artificial Inteligence 43(1990): 153-197Liu Fu-Hua,Liang Gao Gu,Yuqing, Picheny Michael 2003,Use of Statistical N_Gram Models in Natural LanguageGeneration for Machine translation, Proceedings of IEEEInternational Conference on Acoustics, Speech, and Sig-nal Processing, 2003.
Vol 1 : 636 639Langkilde Irene, Knight Kevin 1998, Generation that Ex-ploits Corpus-Based Statistical Knowledge, Annualmeeting-association for computational linguistics: 704-710Deemter Kees van et.
al.
1999, Plan-Based vs. template-based NLG: a false opposition?, Becker and Busemann(1999)McCoy K. 1997 , ?Simple NLP Techniques for ExpandingTelegraphic Sentences?
Natural Language Processing forCommunication Aids,1997Rambow Owen, Bangalore Srinivas, Walker Marilyn2001,Natural Language Generation in Dialog System,Proceedings of the first international conference on Hu-man language technology research HLT '01Pasero Robert, Nathalie Richardet and Paul Sabatier;?Guided Sentences Composition for Disabled People?
;Proceedings of the fourth conference on Applied naturallanguage processing October 1994Project SANYOG Available at:http://www.mla.iitkgp.ernet.in/projects/sanyog.htmStephanidis, C. et.
al., ?Designing Human Computer Inter-faces for Quadriplegic People?,  ACM Transactions onComputer-Human Interaction, pp 87-118, Vol.
10, No.
2,June 20036
