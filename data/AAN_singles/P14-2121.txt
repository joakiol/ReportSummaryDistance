Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 745?751,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsMeasuring metaphoricityJonathan DunnDepartment of Computer Science / Illinois Institute of Technologyjonathan.edwin.dunn@gmail.comAbstractThis paper presents the firstcomputationally-derived scalar mea-surement of metaphoricity.
Each inputsentence is given a value between 0and 1 which represents how metaphoricthat sentence is.
This measure achievesa correlation of 0.450 (Pearson?s R, p<0.01) with an experimental measure ofmetaphoricity involving human partici-pants.
While far from perfect, this scalarmeasure of metaphoricity allows differentthresholds for metaphoricity so thatmetaphor identification can be fitted forspecific tasks and datasets.
When reducedto a binary classification evaluation usingthe VU Amsterdam Metaphor Corpus,the system achieves an F-Measure of0.608, slightly lower than the comparablebinary classification system?s 0.638 andcompetitive with existing approaches.1 IntroductionMetaphor is a cognitive phenomenon (Lakoff &Johnson, 1980, 1999) which has a significant im-pact on human reasoning abilities (Casasanto &Jasmin, 2012; Johansson Falk & Gibbs, 2012)and which, as a result, commonly appears in lan-guage in the form of metaphoric expressions (e.g.,Deignan, 2005).
The most comprehensive non-computational study of metaphoric expressions inlarge corpora (Steen, et al, 2010) found that upto 18.5% of words in the British National Cor-pus were used metaphorically.
This means thatmetaphorically used words not only have very dif-ferent interpretations than literally used words, butthey are also common enough to pose a significantchallenge for computational linguistics.Starting with Wilks (1978), the problem ofmetaphor has been approached as an identifica-tion task: first identify or detect metaphoric ex-pressions and then (1) prevent them from inter-fering with computational treatments of literal ex-pressions and (2) use them to gain additional in-sight about a text (e.g., Carbonell, 1980; Neuman& Nave, 2009).
The identification or detectiontask has been approached as a binary classificationproblem: for a given unit of language (e.g., word,phrase, sentence) decide whether it is metaphoricor non-metaphoric.
Wilks (1978) used selectionalrestrictions for this purpose; Mason (2004) usedhand-crafted knowledge resources to detect sim-ilar selectional mismatches; another approach isto detect selectional mismatches using statisticallycreated resources (e.g., Shutova, et al 2013;Shutova & Sun, 2013).
A second general approachto the binary classification problem has been to usemismatches in properties like abstractness (Gandy,et al, 2013; Assaf, et al, 2013; Tsvetkov, et al,2013; Turney, et al, 2011), semantic similarity(Li & Sporleder, 2010; Sporleder & Li, 2010),and domain membership (Dunn, 2013a, 2013b) toidentify metaphoric units of language.
A third ap-proach has been to use forms of topic modellingto identify linguistic units which represent both ametaphoric topic and a literal topic (Strzalkowski,2013; Bracewell, et al 2013; Mohler, et al, 2013).The single constant across all of these ap-proaches is that the task is viewed as a binary clas-sification problem of distinguishing metaphoriclanguage from non-metaphoric language.
Thisbinary distinction assumes a clear boundary be-tween the two; in other words, it assumes thatmetaphoricity is a discrete property.
However,three strands of theoretical research show thatmetaphoricity is not a discrete property.
First,psycholinguistic studies of metaphor processingshow that there is no difference between the pro-cessing of metaphoric and non-metaphoric lan-guage (Coulson & Matlock, 2001; Gibbs, 2002;Evans, 2010).
The most plausible interpretation745of this psycholinguistic evidence is that most lin-guistic units fall somewhere between metaphoricand literal, so that metaphoricity is a scalar valuewhich influences processing gradually (and is dif-ficult to uncover because of related factors likesalience; Giora, 2002).
Second, linguistic stud-ies of metaphor have found that the metaphoric-ity of a linguistic unit can be predicted givencertain factors (Dunn, 2011, 2013c).
Third, thehigh frequency of metaphorically used languageimplies that it is hard to set a boundary beyondwhich a word is used metaphorically.
In otherwords, it seems clear that 18.5% of the BNC is nothighly metaphoric, but rather is the sort of slightlymetaphoric language that speakers are not con-sciously aware of because it is used so frequently.This paper introduces a system for produc-ing a scalar measurement of metaphoricity whichplaces sentences anywhere between 0 (literal) and1 (highly metaphoric).
The goal is to produce acomputationally derived measurement that mod-els the gradient nature of metaphoricity, with theresult that metaphors which are clearly and con-sciously seen as metaphors score closer to 1 andmetaphors which are not realized by speakers tobe metaphoric score further from 1.
This scalarmeasurement approach has two advantages: (1) itadheres more closely to the current theoretical un-derstanding of metaphor, thus being more cogni-tively accurate; (2) it allows applications to controlthe threshold of metaphoricity when identifyingmetaphor, thus allowing the treatment of metaphorto be optimized for a given task.2 Measuring Gradient MetaphoricityAn experiment was conducted to set a standard forevaluating scalar measurements of metaphoricity.A corpus of 60 sentences of varying metaphoric-ity, drawn equally from four top-level domains(PHYSICAL, MENTAL, SOCIAL, and ABSTRACT),was created using the Corpus of ContemporaryAmerican English.
Each domain was representedby five verbs and each verb by three sentences:one literal, one slightly metaphoric, and one verymetaphoric (as judged by the author).The selection of various domains, verbs, andhypothesized metaphoricity levels helps to controlfor other factors, like abstractness, which might beonly indirectly related to metaphoricity.
It also en-sures that the experiment covers a wide-range ofmetaphors.
It should be noted that the purposeof the experiment is not to (1) test a three-waydistinction between metaphoricity levels (which issimply used to ensure a representative selectionof metaphors) or (2) test the author?s intuitionsof metaphoricity.
Rather, the purpose is to havea representative selection of metaphors rated formetaphoricity against which to test scalar mea-surements of metaphoricity.Three survey tasks were used.
The firsttested speakers?
ability to consistently separatemetaphoric and non-metaphoric sentences.
Partic-ipants were given a sentence and asked to iden-tify it as ?Literal?
or ?Metaphoric.?
The secondtask tested speakers?
ability to consistently labela given sentence as ?Not Metaphoric?, ?SlightlyMetaphoric?, and ?Very Metaphoric.?
The addi-tional label was added in order to provide partic-ipants with a middle ground between metaphoricand literal.
The third task tested speakers?
abilityto consistently rank three sentences according totheir metaphoricity.
In order to ensure comparabil-ity, each set of three sentences contained a literal, aslightly metaphoric, and a very metaphoric use ofa single verb (e.g., three uses of ?butcher?).
Thepurpose of this task was to allow participants todirectly compare different uses of the same verb.The surveys were conducted using the Mechan-icalTurk platform.
Each participant took a particu-lar survey only once and the sentences to be ratedwere drawn randomly from the corpus.
Partici-pants were given eight questions for the identifica-tion and labeling tasks and four questions for theranking task.
This was done in order to keep thesurvey short and prevent participants from losinginterest.
All participants were asked if they had at-tended a primary or elementary school conductedin English in order to ensure consistent languageability.
Further, a test question was positioned partway through the survey to ensure that participantsread the prompts correctly.
Only answers valid ac-cording to these two tests are considered in the fol-lowing results.
Each task had 100 unique partici-pants who gave valid answers, for a total of 300participants.
Participants did not see any domaininformation for the sentence prompts.For the first task, the binary identification task,the metaphoricity of a sentence was computed bytaking the percentage of participants who iden-tified it as metaphoric.
Thus, if all participantsagreed that a sentence was metaphoric, then it re-ceives a 1, while if half of the participants agreed,746then it receives a 0.5.
The idea here is that highmetaphoricity is consciously available to partici-pants, so that the more agreement there is aboutmetaphor the more the participants are aware ofthe sentence?s metaphoricity and thus the higherits metaphoricity value should be.
The results ofthis first experiment are summarized in Table 1with the mean, standard deviation, and range ofthe metaphoricity measurements.
The results arestrong on the low end of the scale, with everydomain having sentences with either 0 values orclose to 0 values.
The high end is more problem-atic, with the highest values in each domain be-ing below 0.9.
This is a result of not having per-fect agreement across all participants.
However,in spite of this, the measure makes a good distinc-tion between utterances.
For example, it assignsthe metaphoricity value of 0.833 to the sentencein (1), but a metaphoricity value of only 0.153 tothe sentence in (2).
This reflects a distinction inmetaphoricity, although the extreme top and bot-tom of the scale are problematic.
(1) ?A lady on high heels clacked along, the typemy mother says invests all of her brainpower in herlooks.?
(2) ?The banks and the corporations in Americatoday have lots of money that they can invest rightnow.
?Domain Mean Std.
Dev.
RangeAbstract 0.373 0.282 0.065?0.833Mental 0.289 0.278 0.000?0.888Physical 0.417 0.331 0.000?0.846Social 0.389 0.351 0.000?0.812All 0.367 0.316 0.000?0.888Table 1: Metaphoricity by identification.The second experiment asks participants tolabel metaphoricity, this time including a dis-tinction between slightly metaphoric and highlymetaphoric sentences.
The purpose of this is notto test a three-way distinction in metaphoricityvalues, but rather to improve the scale by mov-ing intermediate sentences out of the Literal orMetaphoric categories.
The metaphoricity valuesfor this experiment were calculated in the sameway: the percentage of participants who rated asentence as highly metaphoric.
Thus, this mea-surement also is based on the idea that moreparticipants will be consciously aware of highlymetaphoric sentences, with a third category avail-able to allow an extra distinction to be made.
Thismeasurement, summarized in Table 2, is more ac-curate at the lower end of the scale, with manysentences receiving a 0 because participants wereable to choose a category other than metaphoric.At the same time, the values tend to be furtherfrom 1 at the upper end of the scale.
The sentencein (2) above, for example, received a 0; however,the sentence in (1) above received only a 0.571,which, while high given the range of values, is stillfar from 1.
Thus, while the measurement makesdistinctions at the top of the scale, it does not ap-proach 1.Domain Mean Std.
Dev.
RangeAbstract 0.170 0.165 0.000?0.571Mental 0.096 0.119 0.000?0.455Physical 0.220 0.248 0.000?0.778Social 0.258 0.281 0.000?0.769All 0.186 0.222 0.000?0.778Table 2: Metaphoricity by labelling.The third task gathered ordering information bypresenting participants with three sentences, all ofwhich contained the same main verb.
The par-ticipants were asked to order the sentences fromthe least metaphoric to the most metaphoric.
Thepurpose of this experiment was to give partici-pants context in the form of other uses of a givenverb against which to make their judgments.
Themetaphoricity value was computed by taking thepercentage of participants who identified a sen-tence as the most metaphoric of the three givensentences.
This measurement, shown in Table 3,has similar averages across domains, unlike theprevious measurements.
It tends to be better thanthe previous measures on the upper bound, likelybecause of the contextual comparison it allows.However, because sentences with the same mainverb were forced into a three-way ordering, par-ticipants could not, for example, label two of thesentences as equally metaphoric.
Thus, it is possi-ble that some of this advantage on the upper boundis a result of the task itself.Given these three experiments for measuringthe metaphoricity of sentences, Table 4 shows thecorrelations between each measure using Pear-son?s R. Each correlation is significant at the 0.01level (2-tailed).
The highest correlation is betweenthe first and second tasks, at 0.819.
The lowestis between the first and third (which differ in the747Domain Mean Std.
Dev.
RangeAbstract 0.333 0.211 0.056?0.773Mental 0.331 0.175 0.071?0.632Physical 0.331 0.235 0.050?0.941Social 0.327 0.280 0.050?0.783All 0.331 0.227 0.050?0.941Table 3: Metaphoricity by ordering.number of distinctions allowed) at 0.699.
How-ever, this is still a high correlation.Task Identify Label OrderIdentify ?
0.819 0.699Label 0.819 ?
0.702Order 0.699 0.702 ?Table 4: Correlation between measurements.This section has put forward a robust series ofscalar measurements of metaphoricity.
Each ex-periment had 100 participants and operationalizedthe task of rating metaphoricity in different waysacross a representative section of domains, verbs,and metaphoricity levels.
The resulting highly cor-related measures show that we have a good stan-dard of metaphoricity against which to evaluatecomputational models which produce scalar mea-surements of metaphoricity.
The next section in-troduces such a system.3 Description of the SystemWe approach the problem by starting with an exist-ing binary identification system and converting itto a scalar system.
In principle any of the property-based systems listed above could be converted inthis way.
We have chosen to start with the do-main interaction system (Dunn, 2013a, 2013b),which performed competitively in an evaluationwith other systems (Dunn, 2013b).
The originalsystem uses the properties of domain-membershipand event-status of concepts to identify metaphorsat the sentence-level using a logistic regressionclassifier.
The scalar version of the system willhave to evaluate the features in a different way.The first step is to increase the robustness of thesystem?s representation of sentences by adding ad-ditional properties.
We split the original system?sdomain membership feature into two: the domainof a word?s referent and the domain of a word?ssense.
The idea is to capture cases like MINISTER,in which a physical object (a human) is defined byits social role (being a minister).
The event-statusproperty is unchanged.Several additional properties are added; theseproperties were not used in the original system.First, animacy-status allows a distinction to bemade between inanimate objects like rocks andstones and animate or human objects.
Second,the fact-status property allows a distinction to bemade between objects which exist as such in-dependently of humans (e.g., rocks and stones)and those which exist to some degree dependenton human consciousness (e.g., laws and ideas).Third, the function-status property allows a dis-tinction to be made between objects which en-code a function (e.g., a screwdriver is specificallyan object meant to turn screws) and those whichdo not encode a function (e.g., rocks are simplyobjects).
A finer distinction within the function-status property distinguishes social functions (e.g.,laws) from physical-use functions (e.g., screw-drivers).Following the original system, these propertiesare taken from a knowledge-base and used to cre-ate feature vectors.
The text is first processed us-ing Apache OpenNLP for tokenization, named en-tity recognition, and part of speech tagging.
Mor-pha (Minnen, et al, 2001) is used for lemmati-zation.
At this point word sense disambiguationis performed using SenseRelate (Pedersen & Kol-hatkar, 2009), mapping the lexical words to thecorresponding WordNet senses.
These WordNetsenses are first mapped to SynSets and then to con-cepts in the SUMO ontology, using existing map-pings (Niles & Pease, 2001, 2003).Thus, each sentence is represented by the SUMOconcepts which it contains and each concept isrepresented by its six concept properties.
The fea-tures used are computed as follows: First, the rela-tive frequency of each value of each concept prop-erty in the sentence is determined; Second, thenumber of instances of the most common value foreach property is determined, as well as the numberof instances of all other values (both relativized tothe number of concepts present in the sentence).Third, the number of types of values for each con-cept property is determined, relative to the numberof possible types.
This gives a total of 41 featuresfor each sentence.These features were computed for each ofthe sentences used in the experiments and then748the correlation between the features and themetaphoricity measurements were computed us-ing Pearson?s R. Those features which had a sig-nificant positive relationship with the experimen-tal results, shown in Table 5, were added to-gether to create a rough computational measure ofmetaphoricity and then converted so that they fallbetween 0 and 1.
The resulting computationally-derived measure correlates significantly with eachof the experiments: 0.450, 0.416, and 0.337.Properties ValuesDomain of the Referent MentalDomain of the Referent Other / ConceptsEvent-Status StateAnimacy-Status UndeterminedAnimacy-Status Other / ConceptsFact-Status PhysicalFunction-Status NoneDomain of the Referent Types / PossibleEvent-Status Types / PossibleAnimacy-Status Types / PossibleFunction-Status (negative) Types / PossibleTable 5: Predictive features.4 EvaluationA scalar measurement of metaphoricity allowsthe threshold for metaphor in metaphor identifi-cation tasks to be fitted for specific purposes anddatasets.
The scalar system was evaluated on theVU Amsterdam Metaphor Corpus (Steen, et al,2010) which consists of 200,000 words from theBritish National Corpus divided into four gen-res (academic, news, fiction, and spoken; per-formance on the spoken genre was not evaluatedfor this task because it consists of many shortfragmentary utterances) and manually annotatedfor metaphor by five raters.
Previous evaluationsusing this corpus (Dunn, 2013b) concluded thatprepositions annotated as metaphoric in the cor-pus should not be considered metaphoric for com-putational purposes.
Thus, metaphorically usedprepositions have been untagged as metaphoric.Further, we have also untagged the ambiguouslymetaphoric sentences.
Sentences with an insuffi-ciently robust conceptual representation were re-moved (e.g., fragments).
The evaluation datasetthus consists of 6,893 sentences, distributed asshown in Table 6.For the purposes of this evaluation, the thresh-Subset Literal Metaphor TotalAcademic 759 1,550 2,309Fiction 1,215 1,389 2,604News 366 1,614 1,980Total 2,340 4,553 6,893Table 6: Size of evaluation dataset in sentences.old for metaphor was set independently for eachgenre and tied to the number of sentences con-taining metaphorically used words, as rated bythe annotators of the corpus.
Thus, for the num-ber x of metaphors in the genre, the x sentenceswith the top metaphoricity values were identifiedas metaphoric.
This illustrates the flexibility ofsuch a scalar approach to metaphor identification.The baseline results are taken from a binary classi-fication evaluation of the corpus using the full setof 41 features produced by the system and eval-uated using the logistic regression algorithm with100-fold cross-validation.System Subset Prec.
Recall F-Meas.Scalar Acad.
0.578 0.686 0.578Binary Acad.
0.649 0.682 0.623Scalar News 0.712 0.822 0.712Binary News 0.750 0.812 0.748Scalar Fict.
0.554 0.582 0.554Binary Fict.
0.632 0.633 0.630Scalar All 0.608 0.703 0.608Binary All 0.663 0.685 0.638Table 7: Evaluation results.The binary classification system, with access tothe full range of features, out-performs the scalarmeasurement in most cases.
It is important to note,however, that the binary classification system re-quires labelled training data and is restricted to asingle threshold of metaphoricity, in this case thethreshold embedded in the corpus by the raters.The scalar system, however, was trained only onthe experimental data and was not influenced bythe evaluation corpus (except, of course, that ithad access to the number of metaphoric sentencesin the dataset, which is a parameter and not partof the model itself).
Further, it can be appliedto any English text without the need for labelledtraining data.
Thus, the scalar approach performscompetitively on a binary task (0.608 vs. 0.638F-Measure) but can also produce scalar identifica-tions, which binary systems cannot produce.749ReferencesAssaf, D., Neuman, Y., Cohen, Y., Argamon, S.,Howard, N., Last, M., Koppel, M. 2013.
Why ?darkthoughts?
aren?t really dark: A novel algorithm formetaphor identification.
2013 IEEE Symposium onComputational Intelligence, Cognitive Algorithms,Mind, and Brain: 60?65.
Institute of Electrical andElectronics Engineers.Bracewell, D. B., Tomlinson, M. T., Mohler, M. 2013.Determining the Conceptual Space of MetaphoricExpressions.
Proceedings of the 14th InternationalConference on Computational Linguistics and Intel-ligent Text Processing, Volume I: 487?500.
Berlin,Heidelberg: Springer-Verlag.Carbonell, J.
1980.
Metaphor - A Key to ExtensibleSemantic Analysis.
Proceedings of the 18th Meet-ing of the Association for Computational Linguis-tics: 17?21.
Association for Computational Linguis-tics.Casasanto, D., Jasmin, K. 2012.
The Hands of Time:Temporal gestures in English speakers.
CognitiveLinguistics, 23(4): 643?674.Coulson, S., Matlock, T. 2001.
Metaphor and thespace structuring model.
Metaphor & Symbol,16(3), 295-316.Deignan, A.
2005.
Metaphor and Corpus Linguistics.Amsterdam: John Benjamins.Dunn, J.
2011.
Gradient Semantic Intuitions ofMetaphoric Expressions.
Metaphor & Symbol,26(1), 53-67.Dunn, J.
2013a.
Evaluating the premises and results offour metaphor identification systems.
Proceedingsof the 14th International Conference on Computa-tional Linguistics and Intelligent Text Processing,Volume I: 471-486.
Berlin, Heidelberg: Springer-Verlag.Dunn, J.
2013b.
What metaphor identification systemscan tell us about metaphor-in-language.
Proceed-ings of the First Workshop on Metaphor in NLP: 1-10.
Association for Computational Linguistics.Dunn, J.
2013c.
How linguistic structure influencesand helps to predict metaphoric meaning.
CognitiveLinguistics, 24(1), 33-66.Evans, V. 2010.
Figurative language understanding inLCCM Theory.
Cognitive Linguistics, 21(4), 601-662.Gandy, L., Allan, N., Atallah, M., Frieder, O., Howard,N., Kanareykin, S., Argamon, S. 2013.
AutomaticIdentification of Conceptual Metaphors With Lim-ited Knowledge.
Proceedings of the 27th Confer-ence on Artificial Intelligence: 328?334.
Associa-tion for the Advancement of Artificial Intelligence.Gibbs Jr., R. W. 2002.
A new look at literal meaning inunderstanding what is said and implicated.
Journalof Pragmatics, 34(4), 457-486.Giora, R. 2002.
Literal vs. figurative language: Dif-ferent or equal?
Journal of Pragmatics, 34(4), 487-506.Johansson Falck, M., Gibbs, Jr., R. W. 2012.
Embod-ied motivations for metaphorical meanings.
Cogni-tive Linguistics, 23(2): 251?272.Lakoff, G., Johnson, M. 1980.
Metaphors we live by.Chicago: University Of Chicago Press.Lakoff, G., Johnson, M. 1999.
Philosophy in theflesh: The embodied mind and its challenge to west-ern thought.
Chicago: University Of Chicago Press.Li, L., Sporleder, C. 2010a.
Linguistic Cues for Distin-guishing Literal and Non-literal Usages.
Proceed-ings of the 23rd International Conference on Com-putational Linguistics: Posters: 683-691.
Associa-tion for Computational Linguistics.Li, L., Sporleder, C. 2010b.
Using Gaussian Mix-ture Models to Detect Figurative Language in Con-text.
Human Language Technologies: The 2010 An-nual Conference of the North American Chapter ofthe Association for Computational Linguistics: 297?300.
Association for Computational Linguistics.Mason, Z.
2004.
CorMet: A Computational, Corpus-Based Conventional Metaphor Extraction System.Computational Linguistics, 30(1), 23-44.Minnen, G., Carroll, J., Pearce, D. 2001.
Appliedmorphological processing of English.
Natural Lan-guage Engineering, 7(3), 207-223.Mohler, M., Bracewell, D., Tomlinson, M., Hinote,D.
2013.
Semantic Signatures for Example-BasedLinguistic Metaphor Detection.
Proceedings of theFirst Workshop on Metaphor in NLP: 27-35.
Asso-ciation for Computational Linguistics.Neuman, Y., Nave, O.
2009.
Metaphor-based meaningexcavation.
Information Sciences, 179, 2719-2728.Niles, I., Pease, A.
2001.
Towards a standard upperontology.
Proceedings of the International Confer-ence on Formal Ontology in Information Systems:2-9.
Association for Computing Machinery.Niles, I., Pease, A.
2003.
Linking lexicons and on-tologies: Mapping WordNet to the Suggested UpperMerged Ontology.
Proceedings of the 2003 Inter-national Conference on Information and KnowledgeEngineering: 412-416.
World Congress in Com-puter Science, Computer Engineering, and AppliedComputing.Pedersen, T., Kolhatkar, V. 2009.
Word-Net::SenseRelate::AllWords - A broad coverageword sense tagger that maximimizes semantic re-latedness.
Proceedings of Human Language Tech-nologies: The 2009 Annual Conference of the North750American Chapter of the Association for Computa-tional Linguistics, Companion Volume: Demonstra-tion Session: 17-20.
Association for ComputationalLinguistics.Shutova, E., Sun, L. 2013.
Unsupervised MetaphorIdentification using Hierarchical Graph Factoriza-tion Clustering.
Proceedings of Human LanguageTechnologies: The 2013 Annual Conference of theNorth American Chapter of the Association forComputational Linguistics: 978-988.
Associationfor Computational Linguistics.Shutova, E., Teufel, S., Korhonen, A.
2013.
Statis-tical Metaphor Processing.
Computational Linguis-tics, 39(2), 301-353.Steen, G. J., Dorst, A. G., Herrmann, J.
B., Kaal, A. A.,Krennmayr, T. 2010.
Metaphor in usage.
CognitiveLinguistics, 21(4), 765-796.Strzalkowski, T., Broadwell, G. A., Taylor, S., Feld-man, L., Shaikh, S., Liu, T., Elliot, K. 2013.
RobustExtraction of Metaphor from Novel Data.
Proceed-ings of the First Workshop on Metaphor in NLP: 67-76.
Association for Computational Linguistics.Tsvetkov, Y., Mukomel, E., Gershman, A.
2013.Cross-Lingual Metaphor Detection Using CommonSemantic Features.
Proceedings of the First Work-shop on Metaphor in NLP: 45-51.
Association forComputational Linguistics.Turney, P. D., Neuman, Y., Assaf, D., Cohen, Y.2011.
Literal and Metaphorical Sense Identifica-tion Through Concrete and Abstract Context.
Pro-ceedings of the Conference on Empirical Methodsin Natural Language Processing: 680-690.
Associ-ation for Computational Linguistics.Wilks, Y.
1978.
Making preferences more active.
Ar-tificial Intelligence, 11(3), 197-223.751
