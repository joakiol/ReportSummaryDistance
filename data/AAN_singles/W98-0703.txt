IIIiIiIIIIIIIIIII!IWord Sense Disambiguat ion based on Semantic DensityRada Mihalcea and Dan I. MoldovanDepartment of Computer Science and EngineeringSouthern Methodist UniversityDallas, Texas, 75275-0122{rada,moldovan}@seas.smu.eduAbstractThis paper presents a Word Sense Disambiguation method based on the idea of semantic densitybetween words.
The disambiguation is done in the context of WordNet.
The Internet is used as araw corpora to provide statistical information for word associations.
A metric is introduced andused to measure the semantic density and to rank all possible combinations of the senses of twowords.
This method provides a precision of 58% in indicating the correct sense for both words atthe same time.
The precision increases as we consider more choices: 70% for top two ranked and7'3% for top three ranked.1 In t roduct ionWord Sense Disambiguation (WSD) is an open prob-lem in Natural Language Processing.
Its solutionimpacts other tasks uch as discourse, reference reso-lution, coherence, inference and others.
WSD meth-ods can be broadly classified into three types:1.
WSD that make use of the information pro-vided by machine readable dictionaries (Cowieet a1.1992), (Miller et a1.1994), (Agirre andRigau, 1995), (Li et a1.1995), (McRoy, 1992);2.
WSD that use information gathered from train-ing on a corpus that has already been semanti-cally disambiguated (supervised training meth-ods) (Gale, Church et al, 1992), (Ng and Lee,1996};3.
WSD that use information gathered fromraw corpora (unsupervised training methods)(Yarowsky 1995) (Resnik 1997).There are also hybrid methods that combine sev-eral sources of knowledge such as lexicon informa-tion, heuristics, collocations and others (McRoy,1992) (Bruce and Wiebe, 1994) (Ng and Lee, 1996)(Rigau, Asterias et al, 1997).Statistical methods produce high accuracy resultsfor small number of preselected words.
A lack ofwidely available semantically tagged corpora almostexcludes upervised learning methods.
On the otherhand, the disambiguation using unsupervised meth-ods has the disadvantage that the senses are not welldefined.
To our knowledge, none of the statisticalmethods disambiguate adjectives or adverbs o far.One approach to WSD is to determine the concep-tual distance between words, that is to measure thesemantic loseness of the words within a semanticnetwork.
Essentially.
it is the length of the short-est path connecting the concepts (Rada et a1.1989),(Rigau.
Asterias et al, 1997).
By measuring theconceptual distance between words, it is possible todetermine the likelihood of word sense associations.For example, the method proposed in (Li et a1.1995)tries to determine the possible sense of a noun asso-ciated with a verb using WordNet and a large text.Based on other occurrences of the verb or semanti-cally related verbs in the text, the possible objectis determined by measuring the semantic similaritybetween the noun objects.Methods that do not need large corpora are usu-ally based exclusively on MRD.
A proposal in thissense has been made in (Agirre and Rigau, 1995):they measure the conceptual density between ouns,by using WordNet, but the method proposed in theirpaper cannot be applied to measuring a concep-tual distance between a verb and a noun, as no di-rect links are provided in MRDs between the nounsand verbs hierarchies.
A WordNet-based methodfor measuring the semantic similarity between ounswas also proposed in (Richardson et ai., 1994).
Theirmethod consists of using hierarchical concept graphsconstructed from WordNet data files, and a semanticsimilarity formula.
Still, the method does not pro-vide a link between different part-of-speech words.2 Our  approachThe approach described in this paper is based on theidea of semantic density.
This can be measured bythe number of common words that are within a se-mantic distance of two or more words.
The closer thesemantic relationship between two words the higherthe semantic density between them.
The way it isdefined here.
the semantic density works well in thecase of uniform MRD.
In reality there are gaps in theknowledge representations and the semantic densitycan provide only an estimation of the actual seman-tic relatedness between words.We introduce the semantic density because it is16IIIIIIIIIIIIIIIIIIIrelatively easy to measure it on a MRD like Word-Net.
This is done by counting the number of con-cepts two words have in common.
A metric is intro-duced in this sense which when applied to all possiblecombinations of the senses of two or more words itranks them.Another idea of this paper is to use the Internetas a raw corpora.
Thus we have two sources of in-formation: (1) the Internet for gathering statisticsand (2) WordNet for measuring semantic density.As will be shown below, a ranking of words sensesresults from each of these two sources.
The issuenow is how to combine these two rankings in orderto provide an overall ranking.
One possibility is touse them in parallel and the other one is to use themserially.
We have tried both and the serial approachprovided better results.
Thus, for a verb - noun pair,the WSD method consists of two Algorithms, thefirst one ranks the noun senses, of which we retainonly the best two senses; and a second Algorithmtakes the output produced by the first Algorithmand ranks the pairs of verb - noun senses.
Exten-sions of this method to other pairs than verb - nounare discussed, and larger windows of more than twowords are considered.An essential aspect of the WSD method presentedhere is that we provide a raking of possible asso-ciations between words instead of a binary yes/nodecision for each possible sense combination.
Thisallows for a controllable precision as other modulesmay be able to distinguish later the correct senseassociation from such a small pool.WordNet is a fine grain MRD and this makes itmore difficult to pinpoint he correct sense combina-tion since there are many to choose from and manyare semantically close.
For applications such as ma-chine translation, fine grain disambiguation workswell but for information extraction and some otherapplications this is an overkill, and some senses maybe lumped together.A simple sentence or question can usually bebriefly described by an action and an object; forexample, the main idea from the sentence He hasto investigate all the reports can be described bythe action-object pair investigate-report.
Even thephrase may" be ambiguous by having a poor context,still the results of a search or interface based on sucha sentence can be improved if the possible associa-tions between the senses of the verb and the nounare determined.In WordNet (Miller 1990), the gloss of a verbsynset provides a noun-context for that verb, i.e.
thepossible nouns occurring in the context of that par-ticular verb.
The glosses are used here in the sameway a corpus is used.173 Rank ing  the  poss ib le  senses  o fthe  nounIn order to improve the precision of determining theconceptual density between a verb and a noun, thesenses of the noun should be ranked, such as to in-dicate with a reasonable accuracy the first possiblesenses that it might have.The approach we considered for this task is the useof unsupervised statistical methods on large texts.The larger the collection of texts, the bigger is theprobability to provide an accurate ranking of senses.As the biggest number of texts electronically stored- and thus favoring an automatic processing - is con-tained on the Web, we thought of using the Internetas a source of corpora for ranking the senses of thewords.This first step of our method takes into consid-eration verb-noun pairs V - N, and it creates pairsin which the verb remains constant, i.e.
V, and thenoun is replaced by the words in its similarity lists.Using WordNet, a similarity list is created for eachsense of the noun.
and it contains: the words fromthe noun synset and the words from the noun hy-pernym synset.Algor i thm 1Input: untagged verb - noun pairOutput: ranking of noun sensesProcedure:1.
Form a similarity list for  each noun sense.Consider, for example, that the noun N hasm senses.
This means that N appears in msimilarity lists,(Nt ,  ,Vt(t), .W(2) ..... :Vl{ kt ))(N  2 ' N ~(~), ,V2(2) .
.
.
.
.
:V 2(.2) )(N', .V r~l), N "(~) ..... N "~ k" ))where ,V l, N "~ ..... N"  represent the differentsenses of :V, and ,V i(') represents the synonymnumber s of the sense N i of the noun N asdefined in WordNet.2.
Form verb - noun pairs.
The pairs that may beformed are:(V - N l , V - N 1(11, V - N 1(2) ..... V - N l{~t) )(V  - N 2, V - N 2(~), V - N 2~) ,  .
.
.
,  V - N 2(k2) )(V - N ' ,  V - N =(~), V - N "(2) ..... V - N " (k ' )  ).
Search the \[nternet and rank senses.
A searchperformed on the Internet for each of thesegroups will indicate a ranking over the possi-ble senses of the noun N.In our experiments we used (AhaVista) sinceit is one of the most powerful search enginescurrently available.IIIiII.I!IIIiIIIIIIIVerb NounSenseof nounin SemCorrescind action 6set-aside resolution 7reject amendment  1allow legislator 1a*k person 1endorse support 8expend fund 1provide increase 2defeat  person 1wa i t  te rm 2receive vote 1revi~e law 2expect resignation 3comment .on  topic 2hold " meeting: 1remedy problem 2place burden 4award fee 1award compensat ion Iprotect court 1l Hits provided by AltaVista for V-N IResult9 49 o i o i 2 27 1 \[ o 1S 0 75 7 0 0 17 2 248 1172 I15628 0 1912 0 1101 162 31 13 361 3 0 134 4846 123 1110189 5268 4429 1543 0 2340 0 428 ,,j i 20 27321 1 0 762 11271 0 0 406 62 1224 2829 648 640 37 397 0 112 0 554 11801 5517 1205 128 8 1164 20 69 2227 3107 345 266 12327 2031 12842 3271 21 1284 222 126 22574 3120 360 540 916 722 433 2Table 1: A sampleUsing the operators provided by AltaVista, theverb-noun groups derived above can be ex-pressed in two query-forms:of the result we obtained in ranking the noun senses using the Internet(a) ("V* N 1."
OR "V* N I(1)*" OR "V* N ~(2)*"OR ... OR "V* N i(k')*')(b) ((V* NEAR N 1.)
OR (V* NEAR N ~(1)*) OR(V* NEAR N i(2)*) OR ... OR (V* NEARN'(~,)*))where the asterisk (*) is used as a wildcard indi-cating that we want to find all words containinga match for the specified pattern of letters.Using one of these queries, we can get the num-ber of hits for each sense i of the noun and thisprovides a ranking of the m senses of the nounas they relate with the verb V.We tested this method for 80 verb-noun pairs ex-tracted from SemCor 1.5 of the Brown corpus, iUsing query form (a) as an input to the search en-gine, we obtained an accuracy of 83% in providing aranking over the noun senses, such as the sense in-dicated in SemCor was one of the first two senses inthis classification.
\[n Table 1, we present a sampleof the results we obtained.
The column Result  inthis table presents the ranking over the noun senses:a I in this column means that the sense indicated inSemCor was also indicated by our method: 2 meansthat the sense indicated in SemCor was in top two ofthe sense ranking provided by our method; similarly,3 or 4 indicates that the sense of the noun, as spec-ified in :~emCor, was in the top three, respectivelyfour, of 1;his sense ranking.We u.,ed also the query form (b), but the resultswe obtained have been proved to be similar; usingthe operator NEAR,  a bigger number of hits is re-ported, but the sense ranking remains the same.It is i:ateresting to observe that even we are cre-ating queries starting with a verb-noun pair, it isITh~: verb-noun pairs have been extracted from thefile br-aO:.not guaranteed that the search on the web will iden-tify only words linked by such a lexical relation.
Webased our idea on the fact that: (1) the noun directlyfollowing a verb is highly probable to be an objectof the verb (as in the expression "Verb* Noun*")and (2) for our method, we are actually interestedin determining possible senses of a verb and a nounthat can share a common context.4 Determin ing  the  conceptua ldens i ty  between verbs  and  nounsA measure of the relatedness between words canbe a knowledge source for several decisions in theNLP applications.
The conceptual density betweenverbs and nouns seems difficult to determine, with-out large corpora or a without a machine-readabledictionary having semantic links between verbs andnouns.
Such semantic links can be traced howeverif we consider the glosses for the verbs, which areproviding a possible context of a verb.A lgor i thm 2Input: untagged verb - noun pair and a ranking ofnoun senses (as determined by Algorithm 1)Output: sense tagged verb - noun pairProcedure:1.
Given a verb-noun pair V - N, determine allthe possible senses for the verb and the noun,by using WordNet.
Let us denote them by< vl, v2 ..... t,~ > and < nt, n2 ..... nl > respec-tively.2.
Using the method described in section 3, thesenses of the noun are ranked.
Only the firsttwo possible senses indicated by this step willbe considered.3.
For each possible pair Vi  - -  n), the conceptualdensity is computed as follows:18(a) extract all the glosses from the sub-hierarchy including vi (the rationale ofthe method used to determine these sub-hierarchies i explained below)(b) Determine the nouns from these glosses.These constitute the noun-context of theverb.
All these nouns are stored togetherwith the level of the associated verb withinthe sub-hierarchy of vi.
(c) Determine the nouns from the sub-hierarchy including ni.
(d) Determine the number Cij of commonconcepts between the nouns obtained at(b) and the nouns obtained at (c).4.
The most suitable combinations between thesenses of the verb and the noun vi - nj  are theones that provide the biggest values for Cij.In order to determine the sub-hierarchies thatshould be used for vl and nj, we used statisticsprovided by SemCor, a sense tagged version of theBrown corpus (Francis and Kucera, 1967) (Miller,Leacock et al, 1993), containing 250,000 words.Each word (noun, verb, adjective, adverb) is in-eluded in a synset within a hierarchy.
The tops ofthese hierarchies denominate the class of the word.The sense in SemCor for a word W is indicated bythe class C of the word W, and the sense of the wordwithin the class C. For example, the SemCor entry:<el cndfdone pos=PIN l e~ma=invest igat ion  gnsn=llexsn= 1 : 09 :  O0 : : > invest  igat  ion</e f>indicates:word: investigationpart of speech: common ounsense in WordNet: 1A statistic measure performed on SemCor, indi-cates the following probabilities for the sense of aword within a class:~ PsrtJ Of Number Of ~ within a cla, ss.
the probability I speech wordl in to have ~en~e number: SemCor 0 I x I 2 \[ 3 I 4 I s. .
.
.
4L799 13% j ,%j.
j.
\]verb  27,637 60% 14% 5% 12% 3% 2%Table 2: The probabilities for the sense of a word withina classAs shown in Table 2, the class of the noun in-dicates with a probability of 85% a correct sense 1within that class.Thus, for this algorithm, we consider for a nounthe hierarchy including the noun (if the class of thenoun ni is C', then the method considers all thenouns from the class C).This does not work for the verbs, as the probabil-ity to indicate a correct sense knowing the class ismuch smaller (only 60%).
For this reason, and basedon the experiments we computed, the sub-hierarchy19including a verb vi is determined as follows: (i) con-sider the hypernym hi of the verb oi and (ii) considerthe hierarchy having hi as top.It is necessary to consider a bigger hierarchy thenjust the one provided by synonyms and direct hy-ponyms, since providing accuracy in a metric com-putation needs large corpora.
As we replaced thecorpora with the glosses, better results are achievedif more glosses are considered.
Still, we do not haveto enlarge too much the context, in order not to missthe correct answers.Conceptua l  Dens i ty  Met r i cFor determining the conceptual density between anoun ni and a verb vj,  the algorithm considers:?
the list of nouns sv~ associated with the glossesof the verbs within the hierarchy determined byhi: (svk,w~),  where:- hj is the hypernym of vj- w~ is the level in this hierarchy?
the list of nouns snt within the class of ni :(snt)The common words between these two lists( svk ,wk)  and (snt) will produce a list of commonconcepts with the associated weights cdij < w~ >.The conceptual density between rli and vj is givenby the formula:Icd.,l(1) C'/j = log(desci)where:?
Icdijl is the number of common concepts be-tween the hierarchies of ni and uj?
w~ are the weights associated with the nounsfrom the noun-context of the verb vj?
desci is the total number of words within thehierarchy of noun nlAs the nouns with a big hierarchy tend to indicatea big value for Icdijl, the weighted sum of commonconcepts has to be normalized in respect with thedimension of the noun hierarchy.
This is estimatedas the logarithm of the total number of descendantsin the hierarchy (i.e.
Io9(desci)) .We also took into consideration other metrics,like:(2) The number of common concepts between thenoun and verb hierarchies, without consideringthe weights.
(3) A weighted summation of the common conceptsbetween the noun and verb hierarchies, as in-dicated in (1), but without a normalization irapport with the noun hierarchy.III!IIIIIIII!iIWe considered also the metrics indicated in(Agirre and Rigau, 1995).
But after running theprogram on several examples, the formula indicatedin (1) provided the best results.A possible improvement o the metric (1) is toconsider the weights for the levels in the noun hier-archy, in addition to the levels in the verb hierarchy.5 An  exampleConsider as example of a verb-noun pair the phraserevise lau?.
The verb revise has two possible sensesin WordNet 1.5:Sense 1revise, make revisions ingloss: (revise a thesis, for example)=~ rewrite, write differently, alter by writinggloss: ("The student rewrote his thesis")Sense 2re tool, revise=~ reorganize, shake up, organize anThe noun law has 7 possible sensesSense 1law, jurisprudencegloss: (the collection of rules imposed by authority; ~civilizationpresupposes respect for the law")collection, aggregation, accumulation, assemblagegloss: (several things grouped together)Sense 2lawgloss: (one of a set of rules governing a particular activity or alegal document setting forth such a rule; "there is a law againstkidnapping" )~, rule, prescriptgloss: (prescribed guide for conduct or action)=~ legal document, legal instrument, ofl~icial docu-ment, instrumentSense 3law, natural awgloss: (a rule or body of rules ofconduct inherent in human natureand essential to or binding upon human society)=~ concept, conceptiongloss: (an abstract or general idea inferred or derivedfrom specific instances)Sense 4law, law of naturegloss: (a generalization based on recurring facts or events (inscience or mathematics etc): "the laws of thermodynamics)concept, conceptiongloss: (an abstract or general idea inferred or derivedfrom specific instances)Sense 5jurisprudence, law, legal philosophygloss: (the branch of philosophy concerned with the law)philosophygloss: (the rational investigation of questions aboutexistence and knowledge and ethics)Sense 6police, police force, constabulary, lawgloss: (the force or policemen and officer~; "the law came lookingfor him" }=~ force, personnelgloss: (group of people willing to obey orders}Sense Tlaw.
practice of lawgloss: Ithe learned profession that is mastered by graduate studyin a law school and that is responsible for the judicial system; "hestudied law at Yale")20:*.
learned professiongloss: (one of the three professions traditionally be-lieved to require advanced \[earning and high princi-ples)We searched on lnternet, using AltaVista, for allpossible pairs V-N that may be created using re-vise and the words from the similarity lists of law.Over the seven possible senses for this noun, the firststep of our method indicated the following ranking(we indicate the number of hits between parenthe-sis):law#e(2829), !aw#3(648), law#4(640), law#6(397),1aw#1(224), 1aw#5(37), taw#7(0).
Thus, only thesense # and #3 of the noun law are eligible to beused for the next algorithm.For each of the two senses of the verb, we deter-mined the noun-context, including the nouns fromthe glosses in the sub-hierarchy of the verb, and theassociated weights.For each of the two possible senses of the noun, wedetermined the nouns from the class of each sense.In Table 3, we present: (1) the values obtained forthe combinations of different senses, i.e.
the numberof common concepts between the verb and noun hi-erarchies- \[cdq\[ (columns 2-3); (2) the summationsof the weights associated with each noun within thenoun-context of the verb vj (columns 4-5); (3) thetotal number of nouns within the hierarchy of eachsense hi, i.e.
desci (columns 6-7); (4) the conceptualdensity Cq for each pair ni - vj, derived using theformula presented above (columns 8-9).~ edl, l\[ 3 weights des?, C, 1 4 5 6 7 8 9n2 n3 n2 n3 n2 n3 n2 n3V\["~, 5 4 2.06 2 975 |265 0.30 O.
28r-6-1 0 0 0 0 975 1265 0 0Table 3: Values used in computing the conceptual den-sity and the conceptual density C,jIn this table:- vi indicates the sense number i of verb revise- ni indicates the sense number i of noun lawThe biggest value for conceptual density is givenby vt - n2:revise~l/2 -1aw~2/5 Cll = 0.30This combination of verb-noun senses 2 appears inSemCor, file br-a01.6 Tests  aga ins t  SemCorWe tested this method by using verb-noun pairsfrom SemCor.
A randomly selected sample from theentire table with 80 pairs is presented in Table 4.For each pair verb-noun, we indicate the sense ofthe verb (column B).
the sense of the noun (col-umn C), as they result from SemCor; the total num-ber of possible senses for both the verb (column D)2The notation #iln means ense i out of n possible.IIIIIIIIIIIIIIIIIiIthese cases, the NEAR operator should be usedfor the first step of this algorithm).2.
The number of words considered at a time canbe increased, from two to three, four or evenmore words.7 ConclusionIn this paper, we have presented a method for WSDthat is based on measuring the conceptual densitybetween words using WordNet.
The metric proposedmay be further improved by considering the weightsfor verbs as well as for nouns.
The senses of thewords are ranked, and an user may select the firstchoice or the first few choices, depending upon theapplication.
We have also proposed to use the Inter-net as a source of statistics on a raw corpora.The method extends well to considering morethan two words at a time, and also for all parts ofspeech covered by WordNet.It is difficult to compare the precision obtained bythis method with other methods, since we considerhere the collective meaning of two or more words,while most of other methods consider one word ata time.
However, an estimation can be done by ex-tracting the square root of the accuracy for a pairof verb-noun words; and that is 76.15% for the firstchoice, 83.66% for the first two choices and 85.44%for the first three choices.
Since the disambiguationprecision for nouns is usually higher than for verbs,those numbers provide only an average.ReferencesDigital Equipment Corporation.
AltaVista HomePage.
URL:http://www.altavista.digital.com.E.
Agirre and G. Rigau, A Proposal for Word SenseDisambiguation using Conceptual Distance, Pro-ceedings of the Ist International Conference onRecent Advances in Natural Language Process-ing, Velingrad, 1995R.
Bruce and J. Wiebe, Word Sense Disambigua-tion using Decomposable Models, Proceedingsof the 32nd Annual Meeting of the Associationfor Computational Linguistics (ACL-94), 139-146,LasCruces, NM, June 1994.J.
Cowie, L. Guthrie and J. Guthrie, Lexical disam-biguation using simulated annealing.
Proceedingsof the Fifth International Conference on Compu-tational Linguistics COLING-92, !57-161, 1992.Francis and H. Kucera, Computational Analisysof present-day American English, Providence, RI:Brown University Press, 1967W.
Gale, K. Church and D. Yarowsky, One Senseper Discourse, Proceedings ofthe DARPA Speechand Natural Language Workshop, Harriman, NewYork.
1992.S.22X.
Li, S. Szpakowicz and S. Matwin.
A WordNet-based algorithm for word semantic sense disam-biguation.
Proceedings of the 14th InternationalJoint Conference on Artificial Intelligence IJCAI-95, Montreal, Canada, 1995.S.
McRoy, Using multiple Knowledge Sources forWord Sense Disambiguation, Computational Lin-Ouistics, 18(1):1-30, 1992.G.A.
Miller, WordNet: An on-line lexical database.International Journal of Lexicography, 3(4):235-312, 1990.G.A.
Miller, C. Leacock, T. Randee and R. Bunker,A Semantic Concordance.
Proceedings of the 3rdDARPA Workshop on Human Language Technol-ogy, 303-308, Plainsboro, New Jersey, 1993G.A.
Miller, M. Chodorow, S. Landes, C. Leacockand R.G.
Thomas, Using a semantic oncordancefor sense identification.
Proceedings of the ARPAHuman Language Technology Workshop, 240-243,1994.H.T.
Ng and H.B.
Lee, Integrating Multiple Knowl-edge Sources to Disambiguate Word Sense: AnExamplar-Based Approach, Proceedings of the34th Annual Meeting of the Association for Com-putational Linguistics (ACL-96), Santa Cruz,1996.R.
Rada, H. Mill, E. Bickell and M. Blettner.
Devel-opment and Application of a Metric on SemanticNets.
IEEE Transactions on Systems, Man andCybernetics, vol.
19, pp 17-30, Jan/Feb 1989.P.
Resnik, Selectional Preference and Sense Disam-biguation, Proceedings of ACL Siglex Workshopon Tagging Text with Lexical Semantics, Why,What and How?, Washington, April 4-5, 1997.P.
Resnik and D. Yarowsky, A Perspective on WordSense Disambiguation Methods and Their Eval-uation.
Proceedings of ACL Siglex Workshop onTagging Text with Lexical Semantics, Why, Whatand How?, Washington, April 4-5.
1997.R.
Richardson, A.F.
Smeaton and J. Murphy, Us-ing WordNet as a Knowledge Base for Measur-ing Semantic Similarity between Words, Techni-cal Report, Working paper CA-1294, School ofComputer Applications, Dublin City University.Dublin, Ireland, 1994.G.
Rigau, J. Atserias and E. Agirre.
Combining Un-supervised Lexical Knowledge Methods for WordSense Disambiguation.
Computational Linguis-tics/9704007, 1997.D.
Yarowsky.
Unsupervised Word Sense Disam-biguation rivaling Supervised Methods.
Proceed-ings of the 33rd Association of ComputationalLinguistics, 1995.IIIIiI!IiIIIIIIIlIIConstructing Bayesian Networks from WordNet for Word-SenseDisambiguation: Representational and Processing Issues *J anyce  Wiebe  and Tom O'Hara  Rebecca  BruceDepartment of Computer  Science and Department of Computer  ScienceComputing Research Laboratory  University of North Carolina at Ashevil leNew Mexico State University Asheville, NC 28804-3299Las Cruces, NM 88003 bruce@cs .unca .eduw iebe ,  tomohara~cs .nmsu.eduAbst rac tThis paper describes a probabilistic model that isformed from the integration of an analytical andempirical component.
The analytical componentis a Bayesian network derived from WordNet, andthe empirical component is composed of compatibleprobabilistic models formulated from tagged train-ing data.
The components are integrated in a for-real, uniform framework based on the semantics ofcausal dependence.
The paper explores various rep-resentational issues that must be addressed whenformulating a Bayesian network representation oflexical iaformation such as that expressed in Word-Net.
These issues are essential to the design of such anetwork and they have not been previously explored.We describe two choices for the representation flexical items and two choices for the representationlexical relations.
The effect of each combination ofchoices on evidence propagation in the network isdiscussed.1 Int roduct ionThere is a long tradition in AI of resolving interde-pendent lexical ambiguities through spreading acti-vation, from QuiUian's (1968) seminal work on se-mantic networks, through Hirst's work (1988) onPolaroid words, to more recent work by Voorhees(1993) and Veronis and Ide (1990) on large-scaledisambiguation.
This research investigates a proba-bilistic realization of spreading activation to resolveinterdependent word-sense ambiguities.
The coreidea is to exploit belief propagation in Bayesian net-works: Words are mapped to nodes, lexical relationsare mapped to edges, and evidence is propagatedfrom word senses to other related word senses.The lexical relations are derived from an exist-ing knowledge source, because this information can-not be automatically extracted from training datawith existing techniques.
The knowledge source weuse is the WordNet ~-a hierarchy, i.e., the hyper-nym/h~onym taxonomy (Miller, 1990).
Althoughthis hierarchy was developed for other purposes, it" This research wa~ supported in part by the Office of NavalResearch under grant number N00014-95-1-0776.has been frequently applied to word-sense disam-bignation (Resnik, 1995; Sussna, 1993).
In thiswork, we investigate various approaches to con-structing a Bayesian network representation of the~-a hierarchy for use in word-sense disambigua-tion.
As this work continues, other relations suchas part/whole and entailment relations will also beincluded in the network.Another contribution of our work is a novel pro-posal for integrating symbolic and statistical infor-mation for the purpose of performing NLP  tasks.Statistical approaches to word-sense disambiguationhave had the most success to date, when evaluatedon unseen test data.
The "analytical" Bayesian net-work component of our method is actually built ontop of "empirical" probabilistic classifiers inducedstatistically from training data.
In particular, anempirical classifier is induced for each word in thecurrent sentence to be disambiguated (i.e., for eachtarget word).
Each empirical classifier is developedindependently of the empirical classifiers for othertarget words.
A Bayesian network is constructedfrom the segment of the WordNet is-a hierarchythat is connected to the target words.
The resultsof the empirical classifiers axe fed as evidence intothe Bayesian network, thus initiating belief propa-gation.
All of the information is represented in aformal, uniform framework: a probabilistic modelembodying conditional independence relationshipsamong the variables that form the joint distribu-tion.
Conditional independence relationships sim-plify the formulation of ~he joint distribu~.ion makingit possible to work with a large number of variables.Further, models that characterize conditional inde-pendence relationships have desirable computationalproperties (e.g., see the discussion on decomposablemodels in (Pearl, 1988)).
These properties form thebasis of the evidence propagation scheme used forBayesian networks discussed in Section 7.
We alsomake use of these properties in formulating the em-pirical classifiers as described in (Bruce and Wiebe,1994).
Bayesian networks are a very rich and com-plex representational framework.
They support easyintegration of diverse information sources and form23IIIIiIIiIIIiithe basis for much of the current work on reasoningunder uncertainty (Pearl, 1988).This paper explores the representational issuesthat must be addressed when mapping the lexical in-formation in WordNet to a Bayesian etwork.
Theimplications of the various choices are analyzed indepth.
In section 2, we introduce the basic con-cepts and illustrate them with an example in sec-tion 3, which also includes a brief description of theempirical component.
The Bayesian etwork repre-sentations of lexical items and lexical relations arediscussed in sections 4 and 5, respectively.
In sec-tion 6, we describe the integration of the empiricalcomponent into the Bayesian etwork The process ofsense disambiguation is described in section 7.
Sec-tion 8 discusses related work followed by conclusionsin section 9.2 Bayesian Networks: BackgroundBayesian etworks model dependencies among nodesthrough the use of conditional probabilities.
Specif-ically, ff a node (Cause2) is considered as acause for another node (Syrnptoml), then thesecond node is defined relative to the first (i.e.,P(SymptomllCause2)).
Some nodes don't have as-sociated causes, so they are just defined via un-conditional probabilities (e.g., P(Cause2)).
Takentogether; the set of all the conditional and un-conditional probabilities determine a joint distri-bution for all the nodes being modeled (e.g.,P( Symptoml .... , SymptomN, Cause l, ...CauseM) ).Such global distributions are usually difficult to as-sess directly; hence, the Bayesian etwork provides aconvenient formalism for specifying the same distri-bution via local distributions, under conditional in-dependence assumptions.
Furthermore.
without heconditional independence relations, the full joint dis-tribution for cases with hundreds of senses would beinfeasible to process--the independence assumptionsare key.
Pearl (1988) presents an in-depth coverageof the theory of Bayesian etworks and provides anetficient algorithm for evaluating them.In a Bayesian approach to statistical inference, wedistinguish between prior and posterior probabili-ties.
Prior probabilities express the beliefs that wehold about the likelihood of events prior to beinggiven any evidence, posterior probabilities expressour beliefs in the likelihood of events given all theevidence that is currently known.
Thus, the poste-rior probability of an event changes as new evidenceis learned.
The conditional and unconditional prob-abilities mentioned above are the prior probabilities.The posterior probabilities are calculated using theBayesian etwork propagation algorithm each timenew evidence is added.
We discuss propagation ingreater detail in Section 7.
Intuitively, the posteriorprobability of a node, say the node GATHERING~I24(switching to a word-sense disambiguation example),is a combination of the beliefs received from its chil-dren and the beliefs received from its parents.
Oncea node has calculated its own belief, it calculatesoutgoing messages to send to its parents and to itschildren, which enable them, in turn, to calculatetheir posterior probabilities.
In this way informa-tion is propagated throughout the network.3 An Ex_~mpleIn this section, we illustrate how a simple Bayesiannetwork can be constructed to model the interde-pendencies among words.
This identifies the basicsteps in the overall process and helps to motivatethe representational issues discussed later.Suppose that the words "community" and "town"appear in a single sentence, and that their cor-rect senses in that context are COMMUNITY,1 andTOWN~2, respectively.
Our task is to assign the cor-rect word senses to both of them, considering infor-mation automatically derived from the corpus andgathered individually for each word, as well as in-formation derived from the WordNet /s-a hierarchyand represented in a Bayesian etwork.
The basicstrategy is to add the corpus-derived information tothe Bayesian network representations of "commu-nity" and "town," in such a way that it initiatespropagation.Let us consider this process in more detail.
Thewords "community" and "town" have the followingsenses in WordNet:community:1. people living in a particular local area2.
an association of people with similarinterests3.
common ownership4.
the body of people in a learned occupationtown:1. an urban area with a fixed boundary thatis smaller than a city2.
the people living in a municipality smallerthan a city3.
an administrative division of a countyThese senses are represented assets of synonyms, orslmsets.
In the/s-a hierarchy, each synset is linked toits hypernym, i.e., the synset representing its concep-tual parent.
For example, the synset correspondingto{occupation, vocation, occupational group}is the hypernym of the synset corresponding to{profession, community}.A new Bayesian network is created for each sen-tence.
It includes all of the synsets for the tar-get words in the sentence, together with all of the!!|IIIIi!
!synsets reachable from them in the WordNet/s-a hi-erarchy.
Extracting this information from WordNetis straightforward.Figure 1 illustrates one way that the Bayesian et-work for the example sentence containing "town"and "community" can be constructed.
In this rep-resentation, each word sense is mapped to a node inthe network, and there is an edge from X to Y iffword sense X is a hypernym (i.e., a superordinate)of word sense Y (please ignore the octagonal nodesat the bottom for now).
Notice that the relationbetween COMMUNITY#1 and TOWN#2 is mediatedby GATHERINGS1, a type of GROUP#I.
Our goal isfor the contextual evidence provided by the empir-ical classifiers to propagate along this path in sucha way that the correct senses of the target wordsreinforce one another.After the topology of the network has been es-tablished, the conditional probability tables requiredfor each node must be defined.
As will be discussedlater in section 5, we can make independence as-sumptions that make estimating the necessary prob-abilities more easier.Next, an empirical classifier is developed for eachambiguous word, in this case, "town" and "commu-nity".
Each classifier defines a probability distribu-tion describing the likelihood of each sense of the tar-geted word given the automatically derived featuresof the context.
An example of the type of featureused is the part-of-speech of the word to the right;see (Bruce and Wiebe, 1994) for the other ones weuse.The distributions determined by the empiricalclassifiers are added as evidence to the Bayesian net-work, initiating belief propagation.
Once the net-work reaches equilibrium, the posterior probabilitiesof the nodes for "town" and Ucomrnunity" determinethe senses assigned to each ambiguous word.4 Representing Lexical Items: Whatdoes a Node mean?There are two basic approaches to representingWordNet synsets in a Bayesian network.
Since thelexical relations are among synsets and not words,a natural approach is to represent the synsets asnodes.
Alternatively, one node could be used to rep-resent all senses of a word.4.1 The One Node Per Word  ApproachWhen nodes correspond to words, the possible val-ues for each node are senseO through senseN, whereN is the number of WordNet synsets representingsenses of the target word.
SenseO represents thecomposite of all other meanings, i.e., of all meaningsthat are not represented by WordNet synsets.
Fig-ure 2 shows the graph for the Bayesian network whenword nodes are used for the relations.
It also illus-25trates the use of logical links, which are describedin the next section.
This involves more than just achange in link direction.4.2 The One Node Per  Sense ApproachFigure 1 illustrates the approach in which eachsyuset (each sense) is mapped to a node.
An impor-tant advantage ofusing the node per sense approachis that it facilitates handling dependencies amongthe senses of a word.
In the node per word approach,single node cycles are produced when modeling thedependencies of words that have a meaning that isdefined in terms of other meanings for that sameword.A disadvantage of this approach is that modelingmutual exclusion among the senses of a single wordbecomes more di$cult.
The most straightforwardapproach modeling mutual exclusion is to create adependency from each sense node to a separate nodewith a CPT enforcing mutual exclusion.
But sincethe table must have 2 ~v entries, this approach be-comes impractical for words with a large number ofsenses.
To get around this problem, two levels ofmutual-exclusion dependencies could be introduced:one at which mutual exclusion among small groupsof senses is enforced, and another enforcing mutualexclusion of the groups.5 Representing Lexical Relations:What  does an edge mean?Here, we address issues concerning the representa-tion of WordNet /s-a relationships as causal depen-dencies.
The two primary issues to be addressedare: (1) expressing the Hypernym/Hyponym rela-tionship as a causal dependency, and (2) quantifyingthe causal dependencies with conditional probabilitydistributions.5.1 Hypernym-4Hyponym RepresentationsThe Hypernym -4 Hyponym Representation was il-lustrated above in section 3: there is an edge fromnode X to node Y iff X represents a hypernym ofnode Y in the WordNet/s-a hierarchy.
Consider thenode per sense representation (see figure 1).
Sup-pose Hyper is a synset that is a hypernym of synsetsHypol... Hypok.
Then, the relevant part of theBayesian etwork expresses the following:Hyper -4 Hypot v .
.
.
V HypokAs such, we are making a closed world assumption.If, for example, there is a synset ANIMAL#I withthree hyponyms DoG#l, CAT#l, and MOUSE#l,we are assuming that these three are the only kindsof ANIMAL#1'S there are.When using this link representation with either ofthe node per sense or the node per word representa-tions, the roots of the network are the most superor-dinate synsets reachable from the target words, andIII1i!IIIIFigure I: Sense per node Bayesian network with hypernym--+hyponym linksthe target words are typically (but not necessarily)the leafs of the network.We now turn to defining the CPT.
We discuss thiswith respect to the node per sense representation (infigure 1) because it is easier to discuss and similarconditional probabilities must be defined under thenode per word representation.To define the CPT  for each child node in theBayesian network, where each child node corre-sponds to a hyponym node in WordNet, we assignthe conditional probability P(hyponymlhypernym)to be inversely proportional to the number of chil-dren that the hypernym has.
For instance, MU-NICIPALITY#I has two children in WordNet, sowe assign the following conditional probability forTOWN#I given this hypernym.P(town#1 \[ municipality#i)municipa~.ty# 1 P(town#1)F 0.000 +T 0.500work, we will consider using frequency of occurrenceinformation in tagged training data to define theseCPTs.For the root nodes, which represent the most su-perordinate concepts, prior probabilities must bespecified.
With no evidence to the contrary, uniformprior distributions are assigned to the root nodes;the empirical classifiers are relied upon to providecontextual support (through the leafs of the net-work).5.2 Hyponym-+Hypernym RepresentationsUnder the Hyponyrn ~ Hypernym Representation,there is an edge from node X to node Y iff X rep-resents a hyponym of node Y in the WordNet /s-ahierarchy.
Consider the node per sense representa-tion (see figure 2).
The Bayesian network representsthe following:(Hypoi  = si -+ Hyper j  = s i )A .
.
.
^ (Hypo .
= s .
-+ Hyper .
,  = sin)In so doing we are: (I) considering each hyponymof a given hypernym to be equally likely, and (2)maintaining the closed world assumption by requir-ing that these conditional probabilities sum to one.In all CPTs, we add a small positive probabilityto all zero probability values in order to allow therealization of all possible configurations of node val-ues (e.g., to handle inconsistent evidence).
In futureUnder the semantics of the WordNet /s-a hierar-chy, all instances of a hyponym are instances of itshypernym.
So, a typical CPT  for this representationis as follows:P(municipality# 1 \[ town#l)town P (municipality# I)F 0 .0+~T 1.0 -26!!I!!!I!!!
!II!suppo~_townassociation ) ( ownership ) ( occupationpossession ) ( body ) / / ( urban_areaFigure 2: Word per node Bayesian network with hyponym~hypernyrn linksNote that this case is not illustrated in the graphsshown: these only cover two of the four main possi-bilities.Interestingly, in this representation, the rootnodes represent the target words.
Thus, the rootnodes are the sites where evidence from the empiricalclassifiers is added to then network.
In the absenceof this evidence, these nodes take on their prior prob-abilities.
As above, we assign uniform distributionsas the priors.
Recall that, in the case of multipleparents, CPTs must specify the conditional distri-bution of the child node given the values of all of itsparent nodes.
The issues involved in working withmultiple parent nodes are discussed below.5.3 CPT  Entries when Multiple Parents:Causal IndependenceIf a node has multiple parents, say n parents, thenspecifying all of the entries in the CPT  for thatnode can be prohibitive.
If no additional indepen-dence assumptions are made regarding the inter-actions among the parent nodes, then the numberof probabilities that must be specified is exponen-tial in n, and probabilistic inference is made corre-spondingly more complex (Heckerman and Breese,1994).
To overcome this problem, the noisy-ORmodel (Pearl, 1988) is often adopted.
Under thismodel, certain independence assumptions are maderegarding the interactions among the parent nodes,with the effect that the number of probabilities thatmust be specified is linear in n. Basically, one needonly specify the conditional probabilities of the childand each parent individually.As presented in (Pearl, 1988), the noisy-OR modelassumes that all of the variables axe binary.
Heck-erman and Breese (1994) present a generalization ofthe noisy-OR model, causa/independence.
In thismodel, the parents are assumed to be independentcauses for the child.
This allows us to formulatea CPT from the specification of only the followingconditional probabilities: P(clpi j) ,  where c rangesover the values of the child, and Pij ranges over thevalues of parent Pi.
These values are combined viathe constraints of the model to produce the CPT forthe child node.We assign the probabilities using a causal inde-pendence model which specializes to the noisy-ORmodel when applied to binary nodes.
First considerthat the inclusive-or connective can be viewed asoutputting a true value iff none of the inputs is false:output = -,((-,vt) ^ - "  ^ (-,v,,))where each vi is a logical-valued input variable.
Theextension to the case where probabilities are associ-ated with each input is relatively straightforward:ch i td= -,((-,vl) ^ - - -A  (--vn))P(childlV1 = vl,.
.
.
,  V~ = v,,) =1.0 - H(1.0 - P(chi ldlvi)) ,  Vv~vl = T.When extending to the general case; the relationshipbetween the value of the child node and the valuesof its parent nodes is not necessarily defined by a27IiI1IiIIIiIIiIIIIIItruth function.
But, the probabilities are assignedanalogously:P(Chi ld  = clV1 = vl,..., V,  = vn) =1.0 - 1"I(1.0 - P(chi ld = clVi = vi))V~P(ch i ld  = clVi = vl) > ~.In their work on plan recognition, Charniak andGoldman (1993) use the noisy-OR model, specifi-cally for representing the dependencies of observedactions on the potential plans that could explainthem.6 I n tegrat ing  Empi r i ca l  andAna ly t i ca l  In fo rmat ion :  V i r tua lEv idence NodesDue to space limitations, we consider just onemethod for integrating the empirical and analyti-cal components.
In this technique, support from theempirical classifiers i added to the Bayesian etworkusing virtual evidence nodes (Pearl, 1988).
The usualway to add evidence to a Bayesian etwork is to in-stantiate a node to a particular value (called "damp-ing'); the influence of this evidence is then propa-gated through the network.
However, that methodis not appropriate for our task, because we do notknow the sense of any word (so there is no node inthe Bayesian etwork that can be initially instanti-ated).
Virtual evidence nodes provide a way to spec-ify uncertain evidence, in the form of a distributionover node values (i.e., the probability of each nodevalue).
They are represented bythe octagonal nodesin figures I and 2.
There is one for each of the targetwords to be disambiguated.
These nodes representthe support for each sense that was derived from thecorpus by the empirical component.
Each virtual ev-idence node is implemented asa binary-valued nodewhose parent is the node for which evidence isbeingprovided.
The evidence distribution determines theconditional probability table.7 Edge  D i rec t ion  and  Be l ie fP ropagat ionThere is a very important implication of the choicebetween the hyperuym ~ hyponym and the hy-ponym ~ hypernym representations.
In a Bayesiannetwork, suppose that evidence is added to a node(either by clamping or by virtual evidence nodes).This evidence will propagate to its ancestors in theBayesian network, and also to the children ofits ancestors.
For example, in figure 1, evidenceintroduced at node SUPPORT_COMMUNITY will prop-agate, among other places, back to COMMUNITY~I ,back to GATHERING~:I, and then down to MUNIC-IPALITY,2, and so on.
Thus, this representation,hypernym ~ hyponym, supports the kind of propa-gation described in this paper.On the other hand, consider the hyponym ~ hy-pern.vm representations (figures I and 2).
In these28r sensecommunity# 1gathering#lmunicipality#2town#2community#4body#2location#lmunicipality#ltown#lbefore after.20 .70.55 .87.25 .33.25 .33.20 .I0.20 .10.50 .67.25 .33.25 .33Table 1: Propagation w/hyponym--+hypernym linksrepresentations, the targeted words are the roots ofthe Bayesian etwork, so the evidence isadded to theroots of the network.
This evidence will not prop-agate from, say, COMMUNITY#1 tO TOWN#2 in fig-ure 1.
Information propagates between such nodesonly if evidence were added to their mutualdescendents.
As Pearl says, "evidence gatheredat a particular node does not influence any of itsspouses until their common child gathers diagnosticsupport" ((Pearl, 1988), p. 182).
Thus, if evidenceis only added at the virtual evidence nodes in figure2, evidence will not propagate from COMMUNITY=ItO MUNICIPALITY=2 (SO it will not propagate furtherto TOWN=2).
The corresponding odes are spouses,but their child (GATHERING) has not received iag-nostic support, by which Pearl means evidence prop-agated from below.However, there are many other possibilities foradding evidence to the network, under which de-sired propagation would occur.
Thus, our discus-sion of the hyponym -~ hypernym representations isnot just a cautionary tale.
For example, one mightuse Yarowsky's (1992) unsupervised method for as-signing words to thesaural categories to add evi-dence to a node representing a superordinate con-cept in the WordNet i~-a hierarchy.
(Virtual evi-dence nodes could be used for this purl:ose too.)
Inthe hyponym ~ hypernym representations, this su-perordinate concept (say GATHERING~ i. or SOCIAL-GROUP#l) is a descendent of the nodes repre-senting the targeted words.
It would thus providethe needed diagnostic support to enable propaga-tion from one target word to another.
Note that thehyponym ~ hypernym representation is conceptu-ally appealing, since its semantics i based directlyon the semantics of the WordNet ia-a hierarchy.As an illustration, consider applying sample evi-dence of (.70, .10, .10, .10) for the senses of "com-munity" (with no evidence for town).
Table 1 showsthe posterior probabilities before and after applyingthis evidence.As can be seen, the high evidence for COMMU-IiIIIIIIIIIiIiIsensecommunity#lgathering#1municipality#2.
town#2community#4body#2location#lmunicipality#ltown#lbefore after.054 .562.126 .631.063 .312.060 .290.020 .030.064 .296.500 .500.068 .063.053 .050Table 2: Propagation w/hyperuym~hyponym linksNITY~I increases the support for the hypernymGATHERINGS1 (as well as for the other ancestorsin the same path not shown).
However, no supportis reaching MUNICIPALITY,2.If the hyperuym -~ hyponym representation isused instead (as in figure 1), an appropriate propa-gation does take place.
The propagation occurs intwo phases.
First, the high evidence for COMMU-NITY~ 1 is propagated "upstream" to the hypernymnode.
Then, the increased support for this synset ispropagated "downstream" to increase the likelihoodof the value for the appropriate sense of "town".
Ta-ble 2 shows the posterior probabilities in this case.7.1 Attenuation of Spreading ActivationAn important aspect of spreading activation ap-proaches is that the strength of the evidence beingpropagated is attenuated the further the evidencespreads from the original source.
Traditional spread-ing activation schemes have used various heuristicsto model this attenuation, often incorporating a dis-tance factor in terms of number of links.
By usingprobabilistic propagation, we can account for bothlength of path and fan-out at the nodes along thepath (i.e., how many children they have).
The lengthof the path is taken into account by the propaga-tion algorithm.
Intuitively, when a node calculatesits posterior distribution, it calculates a distribu-tion taking into account all possibilities (e.g., gather-ing#1=l, municipality#2=1; gathering#l=1, mu-nicipality#2=0; and so on).
As the evidence is dis-persed among the various possibilities at subsequentnodes, the evidence for any single possibility tendsto decrease.
This is so for either edge direction.8 Compar i son  to Re la ted  WorkSpreading activation schemes have been commonin various forms, starting with Quillian's (Quillian,1968) work on semantic memory.
QuiUian usedspreading activation to identify paths between con-cepts for the purpose of comparison and contrast.To construct the semantic networks, dictionary def-29initions were manually encoded in the form a graph:Hirst (1988) also used spreading activation to per-form word-sense disambiguation.
The approach re-lies on the identification of paths between interde-pendent word meanings.
To avoid extraneous con-nections, constraints were introduced; for instance,a limit on path length was introduced, and/s-a linkswere normally not traversed in reverse direction.Furthermore, heuristics were used to give preferenceto shorter paths and to avoid connections throughnodes with many out-going arcs.There have been several approaches that have re-lied upon word-overlap in dictionary definitions toresolve word-sense ambiguities in context, startingwith (Lesk, 1986).
Cowie et al (1992) extend theidea by using simulated annealing to optimize a con-figuration of word senses simultaneously in terms ofdegree of word overlap.Veronis and Ide (1990) developed a neural networkmodel to overcome the limitation of addressing onlypairwise dependencies in word-overlap approaches.Using dictionary, definitions, they constructed a net-work containing links from each word node to thenodes for each of its senses and finks from each ofthe sense nodes to the nodes of the words used inthe definition.Sussna (1993) produces a semantic network basedon several different WordNet relations.
His disam-biguation method minimizes the pairwise distanceamong senses via a weighting scheme that accountsfor both fan-out and depth in the hierarchy.
Of theapproaches we have surveyed, his is most similar toour analytical component.Voorhees (1993) describes an unsupervised ap-proach that exploits the WordNet hypernym taxon-omy.
In particular, the hierarchy for a given wordis automatically partitioned so that the words oc-curring in the synsets of a partition (or hood) onlyoccur with one of the senses for the word.
Disam-biguation is based on the selecting the hood whichhas the highest estimated relative frequency for thecontext relative to training text.Resnik (1995) also describes an unsupervised ap-proach that is based on estimating synset frequen-cies.
As with Voorhees, the estimated frequency of asynset is based on the frequency of the word plus thefrequencies of all its descendant synsets in a largecorpus.
Therefore, the top-level synsets have thehighest frequencies and thus the highest estimatedfrequency of occurrence.
For each pair of nouns fromthe text to be disambiguated, the most-in\[ormative-subsumer is determined by finding the common an-cestor with the highest information content, whereinformation content is inversely related to frequency.Then each noun is disambiguated by selecting thesynset hat receives the most support (i.e., informa-tion content) from the all of the most-informative-IIIIIiIIIiIIiIsubsumers.Eizirik et al (1993) also describe a Bayesian et-work model for word-sense disambiguation, whichincludes syntactic disambiguation as well as lexicalinformation.
However, their networks are not auto-matically constructed.9 Conc lus ionThis paper explores various representational issuesthat must be addressed when formulating a Bayesiannetwork representation f lexical information suchas is expressed in WordNet.
We describe twochoices for the representation f lexical items andtwo choices for the representation lexical relations.The effects on evidence propagation i the networkis aho discussed.Re ferencesBruce, R., and Wiebe, J.
(1994), "Word-sensedisambiguation using decomposable models", inProc.
of the 32nd Annual Meeting of the Associa-tion for Computational Linguistics (ACL-9~), pp139-146.Charniak, E., and R. Goldman (1993), "A BayesianModel of Plan Recognition", Artificial Intelligence64:53-79.Cowie, J., J. Guthrie, and L. Guthrie (1992), "Lexi-cal Disambiguation Using Simulated Annealing",Proc.
COLING-92, pp.
359-365.Eisirik, L. , V. Barbosa, and S. Mendes (1993),"A Bayesian-Network Approach to Lexical Dis-ambiguation", Cognitive Science, 17:257-283.Heckerman, D. and J. Breese (1994), "Causal In-dependence for Probability Assessment and Infer-ence Using Bayesian Networks", Technical ReportMSR-TR-94-08, Microsoft Research, (Revised Oc-tober, 1995).Hirst, G. (1988), "Resolving Lexical AmbiguityComputationaUy with Spreading Activation andPolaroid Words", in Lexical Ambiguity Resolution,S.
Small, G. Cottrell, and M. Tanenhaus (eds),San Mate), CA: Morgan Kaufinann Publishers,pp.
73-107.Lesk, M. (1986), "Automatic Sense DisambiguationUsing Machine Readable Dictionaries: How toTell a Pine Cone from an Ice Cream Cone", inProc.
SIGDOC, Toronto.Miller, G., (1990), "WordNet: An On-line LexicalDatabase", International Journal of Lexicography?
3 (4 ) .Pearl, J.
(1988), Probabilistic Reasoning m Intel-ligent Systems, San Marco, CA: Morgan Kauf-mann.Quillian, M.(1968), "Semantic Memory", in Seman-tic Information and Processing, M. Minsky, ed.,Cambridge, MA: MIT Press.30Resnik, P. (1995), "Disambiguating Noun Group-ings with Respect o WordNet Senses", in Proc.Third Workshop on Very Large Corpora, Cam-bridge, MA, June 1995.Sussna, M. (1993), "Word Sense Disambiguationfor Free-text Indexing Using a Massive SemanticNetwork", in Proc.
Second International Confer-ence on Information and Knowledge Management(CIKM-93), Arlington, Virginia.Veronis, J., and N. Ide (1990), "Word Sense Disam-biguation with Very Large Neural Networks Ex-tracted from Machine Readable Dictionaries", inProc.
COLING-90, Helsinld, August 1990.Voorhees, E. (1993) "Using Word.Net to Disam-biguate Word Senses for Text Retrieval", in Proc.16th Annual A CM SIGIR Conference on Researchand Development in Information Retrieval, Pitts-burgh, pp.
171-180.Yarowsky, D. (1992), "Word-Sense DisambiguationUsing Statistical Models of Roget's CategoriesTrained on Large Corpora", in Proc.
COLING-92, Nantes, Aug 23-28, pp.
454-460.
