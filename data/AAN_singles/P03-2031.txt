Automatic Acquisition of Named Entity Tagged Corpus from World WideWebJoohui AnDept.
of CSEPOSTECHPohang, Korea 790-784minnie@postech.ac.krSeungwoo LeeDept.
of CSEPOSTECHPohang, Korea 790-784pinesnow@postech.ac.krGary Geunbae LeeDept.
of CSEPOSTECHPohang, Korea 790-784gblee@postech.ac.krAbstractIn this paper, we present a method thatautomatically constructs a Named En-tity (NE) tagged corpus from the webto be used for learning of Named En-tity Recognition systems.
We use an NElist and an web search engine to col-lect web documents which contain theNE instances.
The documents are refinedthrough sentence separation and text re-finement procedures and NE instances arefinally tagged with the appropriate NE cat-egories.
Our experiments demonstratesthat the suggested method can acquireenough NE tagged corpus equally usefulto the manually tagged one without anyhuman intervention.1 IntroductionCurrent trend in Named Entity Recognition (NER) isto apply machine learning approach, which is moreattractive because it is trainable and adaptable, andsubsequently the porting of a machine learning sys-tem to another domain is much easier than that of arule-based one.
Various supervised learning meth-ods for Named Entity (NE) tasks were successfullyapplied and have shown reasonably satisfiable per-formance.
((Zhou and Su, 2002)(Borthwick et al,1998)(Sassano and Utsuro, 2000)) However, mostof these systems heavily rely on a tagged corpus fortraining.
For a machine learning approach, a largecorpus is required to circumvent the data sparsenessproblem, but the dilemma is that the costs requiredto annotate a large training corpus are non-trivial.In this paper, we suggest a method that automati-cally constructs an NE tagged corpus from the webto be used for learning of NER systems.
We use anNE list and an web search engine to collect web doc-uments which contain the NE instances.
The doc-uments are refined through the sentence separationand text refinement procedures and NE instances arefinally annotated with the appropriate NE categories.This automatically tagged corpus may have lowerquality than the manually tagged ones but its sizecan be almost infinitely increased without any hu-man efforts.
To verify the usefulness of the con-structed NE tagged corpus, we apply it to a learn-ing of NER system and compare the results with themanually tagged corpus.2 Automatic Acquisition of an NE TaggedCorpusWe only focus on the three major NE categories (i.e.,person, organization and location) because othersare relatively easier to recognize and these three cat-egories actually suffer from the shortage of an NEtagged corpus.Various linguistic information is already held incommon in written form on the web and its quantityis recently increasing to an almost unlimited extent.The web can be regarded as an infinite language re-source which contains various NE instances with di-verse contexts.
It is the key idea that automaticallymarks such NE instances with appropriate categorylabels using pre-compiled NE lists.
However, thereshould be some general and language-specific con-Web documentsW1W2W3?URL1URL2URL3?Web search engineWeb robotSentence separatorTextrefinementS1S2S3?1.html2.html?1.ans2.ans?NE list Web page URLSeparated sentencesRefined sentencesNE taggenerationS1(t)S2(t)S3(t)?NE taggedcorpusFigure 1: Automatic generation of NE tagged corpusfrom the websiderations in this marking process because of theword ambiguity and boundary ambiguity of NE in-stances.
To overcome these ambiguities, the auto-matic generation process of NE tagged corpus con-sists of four steps.
The process first collects webdocuments using a web search engine fed with theNE entries and secondly segments them into sen-tences.
Next, each sentence is refined and filteredout by several heuristics.
An NE instance in eachsentence is finally tagged with an appropriate NEcategory label.
Figure 1 explains the entire proce-dure to automatically generate NE tagged corpus.2.1 Collecting Web DocumentsIt is not appropriate for our purpose to randomly col-lect documents from the web.
This is because not allweb documents actually contain some NE instancesand we also do not have the list of all NE instancesoccurring in the web documents.
We need to col-lect the web documents which necessarily containat least one NE instance and also should know itscategory to automatically annotate it.
This can beaccomplished by using a web search engine queriedwith pre-compiled NE list.As queries to a search engine, we used the listof Korean Named Entities composed of 937 per-son names, 1,000 locations and 1,050 organizations.Using a Part-of-Speech dictionary, we removed am-biguous entries which are not proper nouns in othercontexts to reduce errors of automatic annotation.For example, ?E?
(kyunggi, Kyunggi/business con-ditions/a game)?
is filtered out because it means a lo-cation (proper noun) in one context, but also meansbusiness conditions or a game (common noun) inother contexts.
By submitting the NE entries asqueries to a search engine1, we obtained the max-imum 500 of URL?s for each entry.
Then, a webrobot visits the web sites in the URL list and fetchesthe corresponding web documents.2.2 Splitting into SentencesFeatures used in the most NER systems can be clas-sified into two groups according to the distance froma target NE instance.
The one includes internal fea-tures of NE itself and context features within a smallword window or sentence boundary and the other in-cludes name alias and co-reference information be-yond a sentence boundary.
In fact, it is not easy toextract name alias and co-reference information di-rectly from manually tagged NE corpus and needsadditional knowledge or resources.
This leads us tofocus on automatic annotation in sentence level, notdocument level.
Therefore, in this step, we split thetexts of the collected documents into sentences by(Shim et al, 2002) and remove sentences withouttarget NE instances.2.3 Refining the Web TextsThe collected web documents may include texts ac-tually matched by mistake, because most web searchengines for Korean use n-gram, especially, bi-grammatching.
This leads us to refine the sentences to ex-clude these erroneous matches.
Sentence refinementis accomplished by three different processes: sep-aration of functional words, segmentation of com-pound nouns, and verification of the usefulness ofthe extracted sentences.An NE is often concatenated with more than onejosa, a Korean functional word, to compose aKorean word.
Therefore we need to separate thefunctional words from an NE instance to detect theboundary of the NE instance and this is achievedby a part-of-speech tagger, POSTAG, which candetect unknown words (Lee et al, 2002).
Theseparation of functional words gives us anotherbenefit that we can resolve the ambiguities betweenan NE and a common noun plus functional words1We used Empas (http://www.empas.com)Person Location OrganizationTraining Automatic 29,042 37,480 2,271Manual 1,014 724 1,338Test Manual 102 72 193Table 1: Corpus description (number of NE?s) (Au-tomatic: Automatically annotated corpus, Manual:Manually annotated corpusand filter out erroneous matches.
For example,?E??(kyunggi-do)?
can be interpreted aseither ?E??
(Kyunggi Province)?
or ?E?+?
(agame also)?
according to its context.
We can removethe sentence containing the latter case.A josa-separated Korean word can be a com-pound noun which only contains a target NE as asubstring.
This requires us to segment the compoundnoun into several correct single nouns to match withthe target NE.
If the segmented single nouns are notmatched with a target NE, the sentence can be fil-tered out.
For example, we try to search for an NEentry, ???
(Fin.KL, a Korean singer group)?
andmay actually retrieve sentences including ?????
(surfing club)?.
The compound noun, ?????
?,can be divided into ???(surfing)?
and ???
(club)?by a compound-noun segmenting method (Yun etal., 1997).
Since both ????
and ????
are notmatched with our target NE, ???
?, we can deletethe sentences.
Although a sentence has a correct tar-get NE, if it does not have context information, it isnot useful as an NE tagged corpus.
We also removedsuch sentences.2.4 Generating an NE tagged corpusThe sentences selected by the refining process ex-plained in previous section are finally annotated withthe NE label.
We acquired the NE tagged corpus in-cluding 68,793 NE instances through this automaticannotation process.
We can annotate only one NEinstance per sentence but almost infinitely increasethe size of the corpus because the web provides un-limited data and our process is fully automatic.3 Experimental Results3.1 Usefulness of the Automatically TaggedCorpusFor effectiveness of the learning, both the size andthe accuracy of the training corpus are important.Training corpus Precision Recall F-measureSeeds only 84.13 42.91 63.52Manual 80.21 86.11 83.16Automatic 81.45 85.41 83.43Manual + Automatic 82.03 85.94 83.99Table 2: Performance of the decision list learningGenerally, the accuracy of automatically created NEtagged corpus is worse than that of hand-made cor-pus.
Therefore, it is important to examine the useful-ness of our automatically tagged corpus comparedto the manual corpus.
We separately trained the de-cision list learning features using the automaticallyannotated corpus and hand-made one, and comparedthe performances.
Table 1 shows the details of thecorpus used in our experiments.2Through the results in Table 2, we can verify thatthe performance with the automatic corpus is supe-rior to that with only the seeds and comparable tothat with the manual corpus.Moreover, the domainof the manual training corpus is same with that ofthe test corpus, i.e., news and novels, while the do-main of the automatic corpus is unlimited as in theweb.
This indicates that the performance with theautomatic corpus should be regarded as much higherthan that with the manual corpus because the per-formance generally gets worse when we apply thelearned system to different domains from the trainedones.
Also, the automatic corpus is pretty much self-contained since the performance does not gain muchthough we use both the manual corpus and the auto-matic corpus for training.3.2 Size of the Automatically Tagged CorpusAs another experiment, we tried to investigate howlarge automatic corpus we should generate to get thesatisfiable performance.
We measured the perfor-mance according to the size of the automatic cor-pus.
We carried out the experiment with the deci-sion list learning method and the result is shown inTable 3.
Here, 5% actually corresponds to the size ofthe manual corpus.
When we trained with that sizeof the automatic corpus, the performance was verylow compared to the performance of the manual cor-pus.
The reason is that the automatic corpus is com-2We used the manual corpus used in Seon et al (2001) astraining and test data.Corpus size (words) Precision Recall F-measure90,000 (5%) 72.43 6.94 39.69448,000 (25%) 73.17 41.66 57.42902,000 (50%) 75.32 61.53 68.431,370,000 (75%) 78.23 77.19 77.711,800,000 (100%) 81.45 85.41 83.43Table 3: Performance according to the corpus sizeCorpus size (words) Precision Recall F-measure700,000 79.41 81.82 80.621,000,000 82.86 85.29 84.081,200,000 83.81 86.27 85.041,300,000 83.81 86.27 85.04Table 4: Saturation point of the performance for?person?
categoryposed of the sentences searched with fewer namedentities and therefore has less lexical and contextualinformation than the same size of the manual cor-pus.
However, the automatic generation has a bigmerit that the size of the corpus can be increased al-most infinitely without much cost.
From Table 3,we can see that the performance is improved as thesize of the automatic corpus gets increased.
As aresult, the NER system trained with the whole au-tomatic corpus outperforms the NER system trainedwith the manual corpus.We also conducted an experiment to examine thesaturation point of the performance according to thesize of the automatic corpus.
This experiment wasfocused on only ?person?
category and the result isshown in Table 4.
In the case of ?person?
category,we can see that the performance does not increaseany more when the corpus size exceeds 1.2 millionwords.4 ConclusionsIn this paper, we presented a method that automat-ically generates an NE tagged corpus using enor-mous web documents.
We use an internet search en-gine with an NE list to collect web documents whichmay contain the NE instances.
The web documentsare segmented into sentences and refined throughsentence separation and text refinement procedures.The sentences are finally tagged with the NE cat-egories.
We experimentally demonstrated that thesuggested method could acquire enough NE taggedcorpus equally useful to the manual corpus withoutany human intervention.
In the future, we plan to ap-ply more sophisticated natural language processingschemes for automatic generation of more accurateNE tagged corpus.AcknowledgementsThis research was supported by BK21 program ofKorea Ministry of Education and MOCIE strategicmid-term funding through ITEP.ReferencesAndrew Borthwick, John Sterling, Eugene Agichtein,and Ralph Grishman.
1998.
Exploiting DiverseKnowledge Sources via Maximum Entropy in NamedEntity Recognition.
In Proceedings of the Sixth Work-shop on Very Large Corpora, pages 152?160, NewBrunswick, New Jersey.
Association for Computa-tional Linguistics.Gary Geunbae Lee, Jeongwon Cha, and Jong-HyeokLee.
2002.
Syllable Pattern-based Unknown Mor-pheme Segmentation and Estimation for Hybrid Part-Of-Speech Tagging of Korean.
Computational Lin-guistics, 28(1):53?70.Manabu Sassano and Takehito Utsuro.
2000.
NamedEntity Chunking Techniques in Supervised Learningfor Japanese Named Entity Recognition.
In Proceed-ings of the 18th International Conference on Compu-tational Linguistics (COLING 2000), pages 705?711,Germany.Choong-Nyoung Seon, Youngjoong Ko, Jeong-SeokKim, and Jungyun Seo.
2001.
Named Entity Recog-nition using Machine Learning Methods and Pattern-Selection Rules.
In Proceedings of the Sixth NaturalLanguage Processing Pacific Rim Symposium, pages229?236, Tokyo, Japan.Junhyeok Shim, Dongseok Kim, Jeongwon Cha,Gary Geunbae Lee, and Jungyun Seo.
2002.
Multi-strategic Integrated Web Document Pre-processing forSentence and Word Boundary Detection.
InformationProcessing and Management, 38(4):509?527.Bo-Hyun Yun, Min-Jeung Cho, and Hae-Chang Rim.1997.
Segmenting Korean Compound Nouns usingStatistical Information and a Preference Rule.
Jour-nal of Korean Information Science Society, 24(8):900?909.GuoDong Zhou and Jian Su.
2002.
Named EntityRecognition using an HMM-based Chunk Tagger.
InProceedings of the 40th Annual Meeting of the As-sociation for Computational Linguistics (ACL), pages473?480, Philadelphia, USA.
