Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 1468?1476, Dublin, Ireland, August 23-29 2014.Single Document Keyphrase Extraction Using Label InformationSumit NegiIBM ResearchDelhi, Indiasumitneg@in.ibm.comAbstractKeyphrases have found wide ranging application in NLP and IR tasks such as document sum-marization, indexing, labeling, clustering and classification.
In this paper we pose the problemof extracting label specific keyphrases from a document which has document level metadata as-sociated with it namely labels or tags (i.e.
multi-labeled document).
Unlike other, supervisedor unsupervised, methods for keyphrase extraction our proposed methods utilizes both the doc-ument?s text and label information for the task of extracting label specific keyphrases.
We pro-pose two models for this purpose both of which model the problem of extracting label specifickeyphrases as a random walk on the document?s text graph.
We evaluate and report the qualityof the extracted keyphrases on a popular multi-label text corpus.1 IntroductionThe use of graphs to model and solve various problems arising in Natural Language Processing havelately become very popular.
Graph theoretical methods or graph based approaches have been success-fully applied for a varied set of NLP tasks such as Word Sense Disambiguation, Text Summarization,Topic detection etc.
One of the earliest and most prominent work in this area has been the TextRank (Mi-halcea and Tarau, 2004) method - an unsupervised graph-based ranking model for extracting keyphrasesand ?key?
sentences from natural language text.
This unsupervised method extracts prominent terms,phrases and sentences from text.
The TextRank models the text as a graph where, depending on the endapplication, text units of various sizes and characteristics can be added as vertices e.g.
open class words,collocations, sentences etc.
Similarly, based on the application, connections can be drawn between thesevertices e.g.
lexical or semantic relation, contextual overlap etc.
To identify ?central?
or ?key?
text unitsin this text graph, TextRank runs the PageRank algorithm on this constructed graph.
The ranking oververtices (text units), which indicates their centrality and importance, is obtained by finding the stationarydistribution of the random walk on the text graph.In this paper, we consider the problem of extracting label specific keyphrases from a document whichhas document level metadata associated with it namely labels (i.e.
multi-labeled document).
To elabo-rate, consider a document as shown in Figure 1.
This document has been assigned to two categories asindicated by the labels ?Air Pollution?
and ?Plant Physiology?.
Running TextRank on this article yieldstop ranked key-phrases such as ?calibrated instrument?, ?polluting gases?, ?industrial development?etc.
These keyphrases, though central to the article, are not specific to any of the labels that have beenassigned to the article.
For instance, one would associate keyphrases such as ?carbon monoxide ?, ?airpollutants?
to be more relevant to the ?Air Pollution?
label and keyphrases such as ?stomatal movement?,?cell defense?
to be more closely associated with the ?Plant Physiology?
label.
The objective of this pa-per is to explore extensions to TextRank for extracting label-specific keyphrases from a multi-labeleddocument.
Such label-specific keyphrases can be useful for a number of practical applications namely:highlighting such terms within the body of a document could provide a label-specific (topic-focussed)view of the document thus facilitating fast browsing and reading of the document, such key terms couldalso be useful for generating topic-driven or label-specific summaries and in multifaceted search.This work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/1468Figure 1: Label specific keyphrases (best viewed in color).
Note that there could be keyphrases that arecommon to both labels.
Due to space restrictions only a snippet of the document is shown.The rest of the paper is organized as following.
We discuss related work and provide an overviewof our approach in Section 2.
Details of the proposed method is discussed in Section 3 followed byevaluation in Section 4.
Future work and conclusion is presented in Section 5.2 Related WorkThe methods for keyphrase (or keyword) extraction can be roughly categorized into either unsupervisedor supervised.
Unsupervised methods usually involve assigning a saliency score to each candidate phraseby considering various features.
Popular work in this area include the use of point-wise KL-divergencebetween multiple language models for scoring both phrase-ness and informativeness of candidate phrases(Tomokiyo and Hurst, 2003), use of TF-IDF weighting (A. Hulth, 2003) etc.
Supervised machine learn-ing algorithms have been proposed to classify a candidate phrase into either keyphrase or not usingfeatures such as the frequency of occurrence, POS information, and location of the phrase in the docu-ment.
All the above methods only make use the document text for generating keyphrases and cannot beused (as-is) for generating label-specific keyphrases.One possible method for extracting label-specific keyphrases from a document could be based onpost-processing the output of the TextRank algorithm in the following way (1) Identify a set of labelspecific features fcandl(unigram terms) that are strongly correlated with the label.
This could be doneby applying feature selection methods (Forman, 2003), (Forman, 2003) on a multi-label text corpus (wediscuss this step in more detail in a later section).
For instance, fcandair_pollution={?pollutant?,?gases?,...
}(2) Run the TextRank algorithm on the document d to generate a list of keyphrases keyphrased(3) Filterthe resultant list keyphrasedbased on lexical or semantic match with the label specific features fcandltogenerate keyphraseldor label-l specific keyphrase for document d.This approach suffers from the following limitations (a) The keyphrase list generated in Step (2) i.e.keyphrasedmight be dominated by keyphrases which have little to do with label l. Post processingthis list (Step 3) using fcandlmight result in only very few keyphrases in keyphraseld.
(b) The labelspecific features fcandl, which are derived from corpus level statistics1, might not be the best indicator ofthe keyphrase-ness of a term in the document.
(c) Moreover, consider a scenario where a document isassociated with more than one label.
Consider the previous example where the document is associatedwith two labels ?Air Pollution?
and ?Plant Physiology?.
When extracting keyphrases specific to thelabel/category ?Air Pollution?
from document d one would expect that the extracted keyphrases arecloser to the Air Pollution label/category and distant from other labels associated with document d i.e.
?Plant Physiology?.
It is not evident how this can be modeled in this approach.
In this paper we proposean approach that models the problem of finding label-specific keyphrases in a document as a randomwalk on the document?s text-graph.
Two approaches are proposed namely PTR: Personalized TextRankand TRDMS: TextRank using Ranking on Data Manifolds with Sinks.1Using feature selection methods1469PTR: Personalized TextRank : In this setting the PageRank algorithm, which is the underpinning ofthe TextRank keyphrase extraction algorithm, is replaced with the personalized page rank (Haveliwala,2002) algorithm.
By using the label specific features fcandlas the personalization vector we are able tobias the walk on the underlying text graph towards terms relevant to the label.
We discuss this approachin more detail in Section 3.3.
Even though using a label specific transport or personalization vectorhelps bias the walk towards terms specific to that label, terms relevant to labels other than l continue toinfluence the walk.
The Personalized TextRank method offers no elegant solution which would penalizeterms unrelated to l while simultaneously preferring terms relevant to label l.To achieve both these goals in one model we propose the TRDMS: TextRank using Ranking on DataManifolds with Sinks approach.
We model the problem of identifying label specific keyphrases in a givendocument as a random walk over the document?s weighted text graph with sink and query nodes2.
Rank-ing on data manifolds was first proposed by (Zhou et al., 2004) and has been used for multi-documentsummarization (Wan et al., 2007), image retrieval (He et al., 2004) etc.
An intuitive description of theranking algorithm is described as follows.
A weighted network is constructed first, where nodes rep-resent all the data and query points, and an edge is put between two nodes if they are ?close?.
Querynodes are then initialized with a positive ranking score, while the nodes to be ranked are assigned a zeroinitial score.
All the nodes, except the sink nodes, then propagate their ranking scores to their neighborvia the weighted network.
The propagation process is repeated until a global state is achieved, and allthe nodes except the query nodes are ranked according to their final scores.
Manifold ranking giveshigh rank to nodes that are close to the query nodes on the manifold (relevance) and that have strongcentrality (importance).
Sink nodes, whose ranking is fixed to the minimum (zero) during the rankingprocess, do not spread any ranking score to their neighbors thus penalizing the nodes that are connectedto them.
To use this method for extracting label-(l) specific keyphrases , fcandlare modeled as querynodes while features associated with labels other than l are modeled as sink nodes.
This approach isinspired by the work done by (Cheng et al., 2011) for query recommendation and update summarization.Section 3.4 discusses this method in more detail.
To summarize, to the best of our knowledge we arethe first to propose the problem of extracting label specific keyphrases from a multi-labeled document.Our modifications to TextRank for achieving this task are novel.
Moreover, our idea of of using Rankingon Data Manifolds on the document-level text graphs for extracting label specific keyphrases is a newcontribution.3 Generating Label Specific Keyphrases3.1 NotationIn this section we introduce notations which we use throughout the paper.
Let D represent a multi-labeldocument corpus and = be the set of all possible labels which could be associated with documents in D.A document from this corpus is denoted by d and the set of labels associated with document d is denotedby `, where d ?D and `?=.
The text graph for document d is denoted byGdandM denotes the numberof vertices inGd.
We describe how this text graph is constructed in Section 3.2.
Features specific to labell, which are extracted from the corpus D, are represented as fcandl, where l ?
=.
Section 3.5 describeshow these label specific features are extracted from a multi-label document corpus.3.2 Building the Text GraphFor a given document d the text graph Gdis built in the following way.
All open-class, unigram tokensoccurring in d are treated as vertices.
Two vertices are connected if their corresponding lexical unitsco-occur within a window of maximum N words, where N is set to 10 for all our experiments.
As in-dicated by (Mihalcea and Tarau, 2004) co-occurrence links express relations between syntactic elementsand represent cohesion indicators for a given text.
Note that the methods described in Section 3.3 andSection 3.4 provide a score/rank for each vertex (unigram term) in the graph.
To generate keyphrases (n-grams) from these candidate terms the following post-processing is performed on the top ranked terms.Vertices are sorted in reverse order of their score and the top K vertices in the ranking are retained2Nodes correspond to terms in a text graph1470Figure 2: (a) Label specific features fcandl(b) Personalized TextRank - walk biased towards terms relatedto fcandplant_physiology(shown in red color).
(c) TextRank using Ranking on Data Manifold with Sinks: walkbiased towards terms related to fcandplant_physiology, while simultaneously penalizing terms that are relatedto fcandair_pollution.
The sink points, which are shown in black color, are vertices whose ranking scores arefixed at the minimum score (zero in our case) during the ranking process.
Hence, the sink points willnever spread any ranking score to their neighbors.
Arrows indicate diffusion of ranking scores (Figurebest viewed in color)for post-processing.
Let this ranked list be represented as <TK>.
During post-processing, all terms se-lected as potential keywords are marked in the text, and sequence of adjacent keywords are collapsedinto a multi-word keyphrase.
For example, in the text calibrated instruments are used to measure, ifthe unigram terms calibrated and instruments are selected as potential/candidate terms by the PTR orTRDMS method, since they are adjacent they are collapsed into one single keyphrase ?calibrated in-struments?.
This heuristic is implemented as a function which is referred as kphrasegen(<TK>,d).
Thisfunction takes as input the ranked term list <TK> and the document text d and returns the collapsed setof keyphrases.
A similar approach was adopted in the TextRank (Mihalcea and Tarau, 2004) work.3.3 PTR: Personalized TextRankFor extracting label-l specific keyphrases from document d we modify the TextRank (Mihalcea andTarau, 2004) algorithm.
We replace the PageRank algorithm used in the TextRank method with the Per-sonalized Page Rank (Haveliwala, 2002) algorithm.
PageRank gives a stationary distribution of a randomwalk which, at each step, with a certain probability  jumps to a random node, and with probability 1-follows a randomly chosen outgoing edge from the current node.
More formally, let Gddenotes the textgraph of document d with M vertices where didenotes the out degree of node wi, then p = Lp + (1-)v.Where p is the page rank vector, L is a M ?M transition probability matrix with Lji=1di.
In the pagerank equation v is a stochastic normalized vector whose element values are all1M.
This assigns equalprobabilities to all nodes in the graph in case of random jumps.
In the personalized page rank formulationthe vector v can be non-uniform and can assign stronger probabilities to certain kind of nodes effectivelybiasing the PageRank vector.
In the PTR approach v is modeled to capture the evidence that is availablefor label l in document d. Doing so biases the walk towards terms that are more specific to label l in thedocument.
This is achieved by considering vertices (terms) that are common between the label l featurevector i.e.
fcandland the text graph for document d i.e.
Gd.
More precisely, for a label l associated witha document d, let Vlddenote the intersection of the set Vdwith fcandl, i.e.
Vld= Vd?
fcandl, where Vddenote the vertex set for the text graph Gd3and l ?
`.
In this way Vldindicates the evidence we havefor label l in the text graph Gd.
To illustrate this point consider Figure 2.
The label specific features forlabel Plant Physiology is shown in Figure 2 (a) denoted as fcandplant?physiology.
The term colored in red3Gdis the text graph built for document d using the method outlined in Section 3.2.1471indicates the term that is common between fcandplant?physiologyand Gdi.e.
Vplant?physiologydHaving identified the nodes (Vld) which should be allocated stronger probabilities in v the next stepis to devise a mechanism to determine these probabilities.
We experiment with four approaches.
In thefirst approach, referred to as seed_nodes_only, we allocate all the probability mass in v uniformly tothe nodes in Vld, all other nodes i.e.
nodes 6?
Vldare assigned zero probability.
In the second approach, re-ferred to as the seed_and_eta approach, we keep aside a small fraction ?
of the probability mass, whichis distributed uniformly to all the nodes 6?
Vld, the rest of the probability mass i.e.
1-?4is uniformly dis-tributed to all nodes ?
Vld.
The third approach, referred to as non_uniform_seed_only, is similar to theseed_nodes_only approach except that in this case the probability mass in v is not allocated uniformlyto the nodes in Vld.
Probability mass is allocated to the nodes in proportion to their importance, as indi-cated by the weights allocated to the feature in fcandlby the feature selection method used.
As we discussin Section 3.5 the feature selection methods, which are used for generating label specific feature fcandl,compute weights for individual features in fcandl.
These weights (e.g mutual information score, t-score)indicate the strength of association between the feature and the label.
In the non_uniform_seed_onlyapproach we allocate probability mass to nodes in Vldin proportion to their feature weights.
Finally, inthe non_uniform_eta approach we distribute the probability mass i.e.
1-?
amongst the Vldin propor-tion to their feature weights.
The left probability mass of ?
is distributed uniformly amongst other nodes6?
Vld.
Performance of these different configurations are evaluated in Section 4.1.One shortcoming of the PTR approach is that it does not provides a clean mechanism to integratefeatures from labels other than l which are associated with the document d. The motivation of doing sois to on one hand bias the walk on the text graph towards terms in fcandlwhile simultaneously penal-izing terms which are in Fcand= ?k 6=l and k?`fcandk5.
As shown in Figure 2 (b) not incorporating thisinformation results in a leakage of scores (indicated using arrows) to nodes not relevant to label l (e.g.gases, sulphur etc) .
In the next section we describe the TRDMS or TextRank using Ranking on DataManifold with Sinks approach which allows us to simultaneously consider both fcandland Fcandin thesame model.3.4 TRDMS: TextRank using Ranking on Data Manifold with SinksAlgorithm 1: Algorithm for generating label-l specific keyphrases for document dData: Document d, label-l specific unigram features fcandl, unigram features for label categories other than lrepresented as Fcand= ?k 6=land k?`fcandkResult: label-l specific keyphrases from document d1.
Build a Text Graph Gdfor document d as discussed in Section 3.2.
Let wiindicate the vertices in Gd;2.
Construct an affinity matrix A, where Aij= sim(wi,wj) if there is an edge linking wi, wjin Gd.
sim(wi,wj)indicates similarity between vertices wi, wj;3.
Symmetrically, normalize A as S = D?1/2AD?1/2.
D is a diagonal matrix matrix with its (i,i)-element equalto the sum of the i-th row A;4. while (!converge(p)) doIterate p(t+ 1) = ?SIp(t) + (1-?
)y ;/* where 0 <?
<1 and I is an indicator diagonal matrix with it?s (i,i)-element equal to 0 if wi?
V?ldand 1otherwise.*/end5.
Sort the vertices wq?
Vqin descending order of their scores p[q].
Let this ranked list be represented as<TK>;6. kphraseld= kphrasegen(<TK>,d) , where kphraseldis the label-l specific keyphrase list for document d;7. return kphraseld;In this section we describe the TextRank using Ranking on Data Manifold with Sinks approach thatallows us to simultaneously consider both fcandland Fcandwhen extracting label l specific keyphrasesfrom document?s d text graph.
For ease of exposition we repeat a few notations and introduce some newones.
Let Vddenote the vertex set for the text graph Gd.
Vertices for the text graph Gdare representedby wiwhere i ?
[1..M], M is the number of vertices i.e.
M=|Vd|.
As introduce earlier, Vlddenotes the4Please note v is a stochastic normalized vector whose elements sum to 1.
In our experiments we set ?=0.25Where ` indicates the label set associated with document d1472intersection of the set Vdwith fcandl, i.e.
Vld= Vd?
fcandl.
Vldindicates the evidence we have for label lin the text graphGd, where l ?
`.
These vertices are also referred to as query nodes in the ranking on datamanifold literature.
Let V?lddenote the intersection of the set Vdwith Fcand, where Fcand= ?k 6=l and k?`fcandki.e.
all the unigram features associated with label categories other than l6.
These vertices are alsoreferred to as sink nodes in the ranking on data manifold literature.
All other vertices are indicated byVqd, where Vqd= Vd\ (V?ld?
Vld) denote the set of points to be ranked.
Let p:V ?< denote the rankingfunction which assigns a ranking score pito each vertex wiin Gd.
One can view p as a vector i.e.
p =[p1,....,pM].
A binary vector y = [y1,....,yM] is defined in which yi= 1 if wi?
Vldotherwise yi= 0.Algorithm 1 gives a detailed outline of the TRDMS method.
This algorithm is based on the algorithmproposed by (Cheng et al., 2011) for ranking on data manifold with sink points.
To generate label-lspecific keyphrase for document d the algorithm considers document d, label-l specific unigram featuresfcandl, and unigram features for labels other than l represented as Fcand.
It begins by first building a textgraph Gd.
After this an affinity matrix A is constructed.
This is shown in Step 2.
The affinity matrixA, which captures the similarity between vertices (terms in the text graph) wiand wj, is built usingWordNet.
We use the popular WordNet::Similarity (Pedersen et al., 2004) package which measures thesemantic similarity and relatedness between a pairs of concepts.
After symmetrically normalizing A(Step 3) and initializing the query and sink nodes the scores are propagated till convergence (Step 4).The routine converge(p) checks for convergence by comparing the value of p between two consecutiveiterations.
If there is little or no change in p the routine return true.
To generate n-gram keyphraseswe follow the approach described in Section 3.2.
In Step 6 of Algorithm 1 the kphrasegen7routine isinvoked.
In order to choose top-k, label-l specific keyphrases for document d one can select the first kelements of the kphraseldlist.3.5 Generating label specific features from a multi-label corpusAs discussed in previous sections the label specific features fcandlplay an important role in the overallranking process.
When searching for label-l specific keyphrases, the unigram features fcandlhelps biasthe walk on the document?s text graph towards terms that are relevant and central to label l. We alsosaw that by considering Fcandi.e.
unigram features belonging to label categories other than l8as sinknodes prevents leakage of the ranking score to terms not relevant or central to l. We show throughexperiments in Section 4 that this improves the quality of label-l specific keyphrases extracted fromdocument d. In order to generate label specific features from a multi-label corpus D we adopt theproblem transformation approach commonly used in multi-label learning.
In this approach the multi-label corpus D is transformed into | = | single-label data sets, where = is the set of labels associatedwith corpus D. Post this transformation any single-label feature selection method can be used to extractlabel l specific features from these single-label data sets.
For our setup we experiment with unigramfeatures selected using mutual information and chi-squared based feature selection methods.4 ExperimentIn order to assess the quality of the label-specific keyphrases generated by our system we conduct amanual evaluation of the generated output.
Details of this evaluation are provided in Section 4.1.
Forour experiments we use a subset of the multi-label corpus EUR-Lex9.
The EUR-Lex text collection isa collection of documents about European Union law.
It contains many different types of documents,including treaties, legislation, case-law and legislative proposals, which are labeled with EUROVOCdescriptors.
A document in this data-set could be associated with multiple EUROVOC descriptors10.
Thedata set that was downloaded contained 16k documents documents and 3,993 EUROVOC descriptors.6We do not assume that fcandl?
Fcand= ?7Details of this routine are provided in Section 3.28In cases where the document is associated with more than one label or category9http://www.ke.tu-darmstadt.de/resources/eurlex10We treat these as labels1473Method PrecisionavgRecallavgF-measureavgTPPbaseline0.163 0.194 0.177PTRseed_nodes_only0.169 0.213 0.188PTRseed_and_eta0.199 0.223 0.210PTRnon_uniform_seed_only0.203 0.231 0.216PTRnon_uniform_eta0.237 0.257 0.247TRDMS 0.397 0.387 0.392Table 1: Keyphrase Extraction ResultsWe removed labels that were under represented11in this data set.
We refer to this data set as the EUR?Lexfiltereddata set.
We randomly selected 100 documents from the EUR ?
Lexfiltereddata set.
Twocriteria were considered when selecting these documents (a) Each document should be associated withat least 2 but not more than 3 labels (b) The size of the evidence set i.e.
|Vld| where Vld= Vd?
flcandisat least 10% of |Vd|, where Vdrepresents the vertex set of the text graph associated with d. The resultingdata set is referred to as the EUR ?
Lexkeyphrasefiltereddata set.
The reason for enforcing these two criteriais the following.
Ensuring that a document in EUR ?
Lexkeyphrasefilteredhas at least 2 labels allows us toexperiment with sink nodes i.e.
Fcand.
As we discuss in Section 4.1 for each label associated with adocument, a human evaluator was asked to generates a label specific list of keyphrases.
For example,if a document is associated with 3 labels, three label specific keyphrase list had to be generated by thehuman evaluator.
Allowing documents with more than 3 labels makes this process tedious.
The reasonfor putting restriction (b) when building the EUR ?
Lexkeyphrasefilteredis explained in Section 4.1.1.
Forgenerating label-l specific features we use the approach described in Section 3.5.
For our experimentsmutual information based feature selection method was used with a feature size of 250 i.e.
|fcandl| =250.4.1 Label-specific Keyphrase EvaluationTwo graduate students were asked to manually extract label-specific keyphrases for each document in theEUR ?
Lexkeyphrasefiltereddata set.
At most 10 keyphrases could be assigned to each document-label pair.This results in a total of 1721 keyphrases.
The Kappa statistics for measuring inter-agreement among theannotation was 0.81.
Any annotation conflicts between the two subjects was resolved by a third graduatestudent.
For evaluation, the automatically extracted label-specific keyphrases for a given document werecompared with the manually extracted/annotated keyphrases.
Before comparing the keyphrase, the wordsin the keyphrase were converted to their corresponding base form using word stemming.
We calculatethree evaluation metrics namely Precision, Recall and F-measure for each document-label pair.
Precision(P) =countcorrectcountsystem, Recall (R) =countcorrectcounthumanand F-measure (F) =2PRP+R, where countcorrectis the totalnumber of correct keyphrases extracted by our method, countsystemis the total number of automaticallyextracted keyphrases and counthumanis the total number of keyphrases labeled by the human annotators.These metrics are calculated for each document-label pair in the EUR?Lexkeyphrasefiltereddata set and thenaveraged to obtain Precisionavg, Recallavgand F ?measureavg.
These results are shown in Table 1We compare the performance of our system against the TextRank with Post-Processing: TPPbaselinebaseline which was explained in Section 2.
Briefly, in this setup to identify label-l specific keyphrases indocument d, we run TextRank on document d and filter the generated keyphrase list based on fcandli.e.label l specific features.
In all setups the document text graph is built in the same fashion i.e.
N = 10and co-occurrence relationship is used to draw edges between nodes in the text graph.
For generating theaffinity matrix A, which is used in the TRDMS method, the res semantic similarity method is used12.
Toreiterate, when generating label-l specific keyphrases for document d the PTR method only uses fcandl,whereas the TRDMS method uses both fcandl(as query nodes) and Fcand= ?k 6=l and k?`fcandk(where11Any label which occurred less than 10% times in the data set was removed.
The documents associated with these labelswere also removed from the data set12We experimented with other semantic similarity measures such as lin and jcn.
The res measure gave us the best results1474` is the set of labels associated with document d) i.e.
all the unigram features associated with label cat-egories other than l (as sink nodes).
One can observe from Table 1 that for PTR the non_uniform_etaconfiguration gives the best result.
Overall the TRDMS approach significantly outperforms all PTR con-figurations and our baseline.
This validates our belief that one can significantly improve the quality ofextracted keyphrase by not only considering label-l specific features i.e.
fcandlbut also features associ-ated with label categories other than l. When we analyzed the performance of TRDMS at the documentlevel we observed that the keyphrase extraction metrics for documents which had strongly correlated la-bels e.g.
?tariff_quota?
and ?import_license?
was 9-11% lower than the reported average scores.
On thecontrary, keyphrase extraction metrics for documents which had labels that had no or weak correlatione.g.
?aid_contract?
and ?import_license?
was 3-5% higher than the reported average scores.
One reasonfor this could be the substantial overlap between fcandland Fcandfor highly correlated labels.
This largeoverlap results in the query nodes being considered as sink nodes which negatively impacts the scorepropagation in the underlying text graph.Figure 3: Impact of evidence set size on F-measure ( best viewed in color)4.1.1 Impact of evidence set size (|Vld|) on keyphrase generation resultsTo recap, elements in set Vldindicate the evidence we have for label l in the text graph of document di.e.
Gd.
In order to investigate how the size of the evidence set i.e.
|Vld| impacts the performance of oursystem the following simulation was carried out.
In different setups we randomly drop out elements fromVldso that the size of the resulting evidence set ranges from 2% to 10% of |Vd|, where |Vd| represents thevertex set size of text graph Gd.
We plot the impact this has on the F-measure in Figure 3.
One observesthat when the evidence set size is in the range 2-4% the gains over the TPPbaselinebaseline (0.177) arelow to modest.
As the evidence set size increases the gains over the baseline increases substantially.5 Conclusion and Future WorkIn this paper we presented the problem of extracting label specific keyphrases from a document.
Wepose the problem of extracting such keyphrases from a document as a random walk on a document?stext graph.
The methods proposed in this paper utilizes the label specific features, which are stronglyassociated with the label, to bias the walk towards terms that are more relevant to the label.
We showthrough experiments that when generating label-l specific keyphrases it helps to consider both label-lspecific features and features associated with labels other than l. As future work we would like to furtherassess the quality of the generated keyphrases by using these keyphrases for generating topic (or label)focused document summaries.1475ReferencesTakashi Tomokiyo and Matthew Hurst.
2003.
A language model approach to keyphrase extraction.
Proceedingsof the ACL 2003 workshop on Multiword expressions: analysis, acquisition and treatment.A.
Hulth.
2003.
Improved Automatic Keyword Extraction Given More Linguistic Knowledge.
Proceedings of theConference on Empirical Methods in Natural Language Processing.Yutaka Matsuo and Mitsuru Ishizuka.
2004.
Keyword Extraction from a Single Document using Word Co-occurrence Statistical Information.
International Journal on Artificial Intelligence Tools.Peter D. Turney.
2000.
Learning Algorithms for Keyphrase Extraction.
Information Retrieval.Eibe Frank and W. Gordon Paynter and Ian H. Witten and Carl Gutwin and Craig G. Nevill-Manning.
1999.Domain-Specific Keyphrase Extraction.
IJCAI ?99: Proceedings of the Sixteenth International Joint Conferenceon Artificial Intelligence.Peter D. Turney.
2003.
Coherent Keyphrase Extraction via Web Mining.
IJCAI ?03: Proceedings of the SixteenthInternational Joint Conference on Artificial Intelligence.Min Song and Il-Yeol Song and Xiaohua Hu.
2003.
KPSpotter: a flexible information gain-based keyphraseextraction system.
Fifth International Workshop on Web Information and Data Management.Olena Medelyan and Ian H. Witten.
2006.
Thesaurus based automatic keyphrase indexing.
JCDL ?06: Proceed-ings of the 6th ACM/IEEE-CS joint conference on Digital libraries.George Forman.
2003.
An Extensive Empirical Study of Feature Selection Metrics for Text Classification.
TheJournal of Machine Learning Research.George Forman.
2004.
A pitfall and solution in multi-class feature selection for text classification.
InternationalConference on Machine Learning.Rada Mihalcea and Paul Tarau.
2004.
TextRank: Bringing Order into Texts.
Proceedings of EMNLP-04 and the2004 Conference on Empirical Methods in Natural Language Processing.Rada Mihalcea, Paul Tarau and Elizabeth Figa.
2004.
PageRank on Semantic Networks, with Application to WordSense Disambiguation.
COLING.Rada Mihalcea, Paul Tarau and Elizabeth Figa.
2004.
PageRank on Semantic Networks, with Application to WordSense Disambiguation.
COLING.Dengyong Zhou and Jason Weston and Arthur Gretton and Olivier Bousquet and Bernhard Sch?u?lkopf.
2004.Ranking on Data Manifolds.
Advances in Neural Information Processing Systems.Ted Pedersen and Siddharth Patwardhan and Jason Michelizzi.
2004.
WordNet::Similarity: Measuring the Relat-edness of Concepts.
Association for Computational Linguistics.Rada Mihalcea and Paul Tarau.
2005.
A language independent algorithm for single and multiple documentsummarization.
In Proceedings of IJCNLP?
?A?Z2005.Xiaojun Wan.
2007.
TimedTextRank: adding the temporal dimension to multi-document summarization.
SIGIR.Taher H. Haveliwala.
2002.
Topic-sensitive PageRank.
Proceedings of the Eleventh International World WideWeb Conference.Xue-Qi Cheng and Pan Du and Jiafeng Guo and Xiaofei Zhu and Yixin Chen.
2011.
Ranking on Data Manifoldwith Sink Points.
IEEE Transactions on Knowledge and Data Engineering.Jingrui He and Mingjing Li and Hong-Jiang Zhang and Hanghang Tong and Changshu Zhang.
2004.
Manifold-ranking Based Image Retrieval.
Proceedings of the 12th Annual ACM International Conference on Multimedia.Xiaojun Wan and Jianwu Yang and Jianguo Xiao.
2007.
Manifold-Ranking Based Topic-Focused Multi-DocumentSummarization.
IJCAI.1476
