Proceedings of the NAACL HLT 2010 Workshop on Semantic Search, pages 27?35,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsA Graph-Based Semi-Supervised Learning for Question Semantic LabelingAsli CelikyilmazComputer Science DivisionUniversity of California, Berkeleyasli@berkeley.eduDilek Hakkani-TurInternational Computer Science InstituteBerkeley, CAdilek@icsi.berkeley.eduAbstractWe investigate a graph-based semi-supervisedlearning approach for labeling semantic com-ponents of questions such as topic, focus,event, etc., for question understanding task.We focus on graph construction to handlelearning with dense/sparse graphs and presentRelaxed Linear Neighborhoods method, inwhich each node is linearly constructed fromvarying sizes of its neighbors based on thedensity/sparsity of its surrounding.
With thenew graph representation, we show perfor-mance improvements on syntactic and realdatasets, primarily due to the use of unlabeleddata and relaxed graph construction.1 IntroductionOne of the important steps in Question Answering(QA) is question understanding to identify semanticcomponents of questions.
In this paper, we inves-tigate question understanding based on a machinelearning approach to discover semantic components(Table 1).An important issue in information extraction fromtext is that one often deals with insufficient la-beled data and large number of unlabeled data,which have led to improvements in semi-supervisedlearning (SSL) methods, e.g., (Belkin and Niyogi.,2002b), (Zhou et al, 2004).
Recently, graph basedSSL methods have gained interest (Alexandrescuand Kirchhoff, 2007), (Goldberg and Zhu, 2009).These methods create graphs whose vertices corre-spond to labeled and unlabeled data, while the edgeweights encode the similarity between each pair ofdata points.
Classification is performed using thesegraphs by scoring unlabeled points in such a wayWhat?
??
?otherfilm?
??
?focusintroduced?
??
?eventJar Jar Binks?
??
?topic?Semantic Components & Named-Entitiy Typestopic: ?Jar?
(Begin-Topic); ?Jar?
(In-Topic) ;?Binks?
(In-Topic)(HUMAN:Individual)focus: ?film?
(Begin-Focus) (DESCRIPTION:Definition)action / event: ?introduced?
(Begin-Event)expected answer-type: ENTITY:creativeTable 1: Question Analysis - Semantic Components of asample question from TREC QA task.that instances connected by large weights are givensimilar labels.
Such methods can perform well whenno parametric information about distribution of datais available and when data is characterized by an un-derlying manifold structure.In this paper, we present a semantic componentlabeling module for our QA system using a newgraph-based SSL to benefit from unlabeled ques-tions.
One of the issues affecting the performanceof graph-based methods (Maier and Luxburg, 2008)is that there is no reliable approach for model se-lection when there are too few labeled points (Zhouet al, 2004).
Such issues have only recently cameinto focus (Wang and Zhang, 2006).
This is some-what surprising because graph construction is afundamental step.
Rather than proposing yet an-other learning algorithm, we focus on graph con-struction for our labeling task, which suffers frominsufficient graph sparsification methods.
Suchproblems are caused by fixed neighborhood assign-ments in k-nearest neighbor approaches, treatingsparse and denser regions of data equally or usingimproper threshold assumptions in -neighborhood27graphs, yielding disconnected components or sub-graphs or isolated singleton vertices.
We proposea Relaxed Linear Neighborhood (RLN) method toovercome fixed k or  assumptions.
RLN approx-imates the entire graph by a series of overlappedlinear neighborhood patches, where neighborhoodN (xi) of any node xi is captured dynamically basedon the density/sparsity of its surrounding.
Moreover,RLN exploits degree of neighborhood during re-construction method rather than fixed assignments,which does not get affected by outliers, producing amore robust graph, demonstrated in Experiment #1.We present our question semantic componentmodel in section 3 with the following contributions:(1) a new graph construction method for SSL,which relaxes neighborhood assumptions yieldingrobust graphs as defined in section 5,(2) a new inference approach to enable learningfrom unlabeled data as defined in section 6.The experiments in section 7 yield performance im-provement in comparison to other labeling methodson different datasets.
Finally we draw conclusions.2 Related Work on Question AnalysisAn important step in question analysis is extractingsemantic components like answer type, focus, event,etc.
The ?answer-type?
is a quantity that a questionis seeking.
A question ?topic?
usually represents ma-jor context/constraint of a question (?Jar Jar Binks?in Table 1).
A question ?focus?
(e.g., film) denotes acertain aspect (or descriptive feature) of a question?topic?.
To extract topic-focus from questions, (Ha-jicova et al, 1993) used rule-based approaches viadependency parser structures.
(Burger, 2006) im-plemented parsers and a mixture of rule-based andlearning methods to extract different salient featuressuch as question type, event, entities, etc.
(Chai andJin, 2004) explored semantic units based on theirdiscourse relations via rule-based systems.In (Duan et al, 2008) a language model is pre-sented to extract semantic components from ques-tions.
Similarly, (Fan et al, 2008)?s semantic chunkannotation uses conditional random fields (CRF)(Lafferty et al, 2001) to annotate semantic chunksof questions in Chinese.
Our work aparts fromthese studies in that we use a graph-based SSLmethod to extract semantic components from unla-beled questions.
Graph-based methods are suitablefor labeling tasks because when two lexical unitsin different questions are close in the intrinsic ge-ometry of question forms, their semantic compo-nents (labels) will be similar to each other.
Labelsvary smoothly along the geodesics, i.e., manifoldassumption, which plays an essential role in SSL(Belkin et al, 2006).This paper presents a new graph construction toimprove performance of an important module of QAwhen labeled data is sparse.
We compare our re-sults with other graph construction methods.
Next,we present the dataset construction for our semanticcomponent labeling model before we introduce thenew graph construction and inference for SSL.3 Semantic Component LabelingEach word (token) in a question is associated witha label among a pre-determined list of semantictags.
A question i is defined as a sequence of in-put units (words/tokens) xi = (x1i, ..., xT i) ?
X Twhich are tagged with a sequence of class labels,yi = (y1i, ..., yT i) ?
YT , semantic components.The task is to learn classifier F that, given a newsequence xnew, predicts a sequence of class labelsynew = F(xnew).
Among different semantic com-ponent types presented in previous studies, we giveeach token a MUC style semantic label from a list of11 labels.
(1) O: other;(2) BT:begin-topic;(3) IT:in-topic(4) BF:begin-focus;(5) IF:in-focus(6) BE:begin-event;(7) IE:in-event(8) BCL:begin-clause(9) ICL:in-clause(10) BC:begin-complement(11) IC:in-complementMore labels can be appended if necessary.
The firsttoken of a component gets ?begin?
prefix and con-secutive words are given ?in?
prefix, e.g., Jar (begin-topic), Jar (in-topic), Binks (in-topic) in Table 1.In graph-based SSL methods, a graph is con-structed G = ?V, E?, where V = X is a vertex set,E is an edge set, associated with each edge eij rep-28resents a relation between xi and xj .
The task is toassign a label (out of 11 possible labels) to each to-ken of a question i, xti, t = 1, ..., T , T is the maxnumber of tokens in a given query.
We introducea set of nodes for each token (xti), each represent-ing a binary relation between that token and one ofpossible tags (yti).
A binary relation represents anagreement between a given token and assigned label,so our SSL classifier predicts the probability of truerelation between token and assigned label.
Thus,for each token, we introduce 11 different nodes us-ing yk ?
{O,BT,IT,BF,IF,BC,IC,BE,IE,BCL,ICL}.There will be 11 label probability assignments ob-tained from each of the 11 corresponding nodes.
Forlabeled questions, intuitively, only one node per to-ken is introduced to the graph for known(true) to-ken/label relations.
We find the best question labelsequence via Viterbi algorithm (Forney, 1973).3.1 Feature Extraction For Labeling TaskThe following pre-processing modules are built forfeature extraction prior to graph construction.3.1.1 Pre-Processing For Feature ExtractionPhrase Analysis(PA): Using basic syntactic anal-ysis (shallow parsing), the PA module re-buildsphrases from linguistic structures such as noun-phrases (NN), basic prepositional phrases (PP) orverb groups (VG).
Using Stanford dependencyparser (Klein and Manning, 2003), (Marneffe et al,2006), which produces 48 different grammatical re-lations, PA module re-constructs the phrases.
Forexample for the question in Table 1, dependencyparser generates two relations:?
nn(Binks-3, Jar-1) and nn(Binks-3, Jar-2),PA reveals ?Jar Jar Binks?
as a noun phrase re-constructing the nn:noun compound modifier.
Wealso extract part of speech tags of questions via de-pendency parser to be used for feature extraction.Question Dependency Relations (QDR): Usingshallow semantics, we decode underlying Stanforddependency trees (Marneffe et al, 2006) that em-body linguistic relationships such as head-subject(H-S), head-modifier (complement) (H-M), head-object (H-O), etc.
For example: ?How did Troopsenter the area last Friday??
is chunked as:?
Head (H): enter ?
Object (O): area?
Subject (S): Troops ?Modifier (M): last FridayLater, the feature functions (FF) are extracted basedon generalized rules such as S and O?s are usuallyconsidered topic/focus, H is usually an event, etc.3.1.2 Features for Token-Label PairsEach node vi in a graph G represents a relation ofany token(word) i, xti to its label yti, denoted as afeature vector xti ?
<d.
A list of feature functionsare formed to construct multi-dimensional trainingexamples.
We extract mainly first and second orderfeatures to identify token-label relations, as follows:Lexicon Features (LF): These features are overwords and their labels along with information aboutwords such as POS tags, etc.
A sample first orderlexicon feature, z(yt, x1:T , t):z ={1 if yt =(BE/IE) and POSxt=VB0 otherwise(1)is set to 1, if its assigned label yt is of event type(BE/IE) and word?s POS tag is VB(verb) (suchtoken-label assignment would be correct).
A simi-lar feature is set to 1 if a word has ?VB?
as its POStag and it is a copula word, so it?s correct label canonly be ?O:other?.
Nodes satisfying only this con-straint and have a relation to ?O?
label get the valueof ?1?.
Similar binary features are: if the word is aWH type (query word), if its POS tag is an article, ifits POS tag is NN(P)(noun), IN, etc.Compound Features (CF): These features ex-ploit semantic compound information obtained fromour PA and QDR modules, in which noun-phrasesare labeled as focus/topics, or verb-phrases as event.For instance, if a token is part of a semantic com-pound, e.g., subject, identified via our QDR mod-ule, then for any of the 11 nodes generated for thistoken, if token-label is other than ?O(Other)?, thensuch feature would be 1, and 0 otherwise.
Similarly,if a word is part of a noun-phrase, then a node havinga relation to any of the labels other than ?O/BE/IE?would be given the value 1, and 0 otherwise Weeliminate inclusion of some nodes with certain la-bels such as words with ?NN?
tags are not usuallyconsidered events.Probability Feature Functions (PFF): We cal-culate word unigram and bigram frequencies fromtraining samples to extract label conditional prob-abilities given a word, e.g., P(BT??IBM?
), P(O-BE?
?Who founded?).
When no match is found in29unigram and bigram label conditional probability ta-bles for testing cases, we use unigram and bigramlabel probabilities given the POS tag of that word,e.g., P(BT?NNP), P(O-BE??WP-VBD?).
We ex-tract 11 different features for each word correspond-ing to each possible label to form the probability fea-tures from unigram frequencies, max.
of 11X11 fea-tures for bigram frequencies, where some bigramsare never seen in training dataset.Second-Order Features (SOF): Such featuresdenote relation between a token, tag and tag?1, e.g.,:z ={1 if yt?1 =BT, yt =IT and POSxt=NN0 otherwise(2)which indicates if previous label is a start of a topictag (BT) and current POS tag is NN, then a nodewith a relation to label ?In-Topic (IT)?
would yieldvalue ?1?.
For any given token, one should introduce112 different nodes to represent a single property.
Inexperiments we found that only a limited number ofsecond order nodes are feasible.4 Graph Construction for SSLLet XL = {x1, ..., xl} be labeled question tokenswith associated labels YL = {y1, ..., yl}T and XU ={x1, ..., xu} be unlabeled tokens, X = XL ?
XU .A weighted symmetric adjacency matrix W isformed in two steps with edges E in G whereWij ?<nxn, and non-zero elements represent the edgeweight between vi and vj .
Firstly, similarity be-tween each pair of nodes is obtained by a measureto create a full affinity matrix, A ?
<nxn, using akernel function, Aij = k(xi, xj) as weight measure(Zhou et al, 2004) wij ?
<n?n:wij = exp(?
?xi ?
xj?
/2?2)(3)Secondly, based on chosen graph sparsificationmethod, a sparse affinity matrix is obtained by re-moving edges that do not convey with neighborhoodassumption.
Usually a k-nearest neighbor (kNN) or neighbor (N) methods are used for sparsification.Graph formation is crucial in graph based SSLsince sparsity ensures that the predicted model re-mains efficient and robust to noise, e.g., especiallyin text processing noise is inevitable.
N graphs pro-vide weaker performance than the k-nearest neigh-borhood graphs (Jebara et al, 2009).
In addition,the issue with kNN sparsification of graph is that thenumber of neighbors is fixed at the start, which maycause fault neighborhood assumptions even whenneighbors are far apart.
Additionally, kernel simi-larity functions may not rate edge weights becausethey might be useful locally but not quite efficientwhen nodes are far apart.
Next, we present RelaxedLinear Neighborhoods to address these issues.5 Relaxed Linear Neighborhoods (RLN)Instead of measuring pairwise relations (3), we useneighborhood information to construct G. Whenbuilding a sparse affinity matrix, we re-constructeach node using a linear combination of its neigh-bors, similar to Locally Linear Embedding (Roweisand Saul, 2000) and Linear Neighborhoods (Wangand Zhang, 2006), and minimize:min?i ||xi ?
?j:xj?N (xi)wijxj ||2 (4)where N (xi) is neighborhood of xi, and wij is thedegree of contribution of xj to xi.
In (4) each nodecan be optimally reconstructed using a linear combi-nation of its neighborhood (Roweis and Saul, 2000).However, having fixed k neighbors at start of thealgorithm can effect generalization of classifier andcan also cause confusion on different manifolds.We present novel RLN method to reconstructeach object (node) by using dynamic neighborhoodinformation, as opposed to fixed k neighbors of(Wang and Zhang, 2006).
RLN approximates entiregraph by a series of overlapped linear neighborhoodpatches, where neighborhood N (xi) of a node xi iscaptured dynamically via its neighbor?s density.Boundary Detection: Instead of finding fixed kneighbors of each node xi (Wang and Zhang, 2006),RLN captures boundary of each node B(xi) basedon neighborhood information and pins each nodewithin this boundary as its neighbors.
We defineweightW matrix using a measure like (3) as a firstpass sparsification.
We identify neighbors for eachnode xi ?
X and save information in boundary ma-trix, B. kNN recovers its k neighbors using a simi-larity function, e.g., a kernel distance function, andinstantiates via:Nxi;k(xj) ={1 d(xi, xj1) < d(xi, xj2)0 otherwise}(5)30Figure 1: Neighborhood Boundary.
Having same numberof neighbors (n=15), boundaries of x1 and x2 are similarbased on kNN (e.g., k=15), but dissimilar based on N .Similarly, with the N approach the neighbors areinstantiated when they are at most  far away:Nxi;(xj) ={1 d(xi, xj) < 0 otherwise}(6)Both methods have limitations when sparsity or den-sity is to concern.
For sparse regions, if we restrictdefinition to k neighbors, thenN (xi) would containdissimilar points.
Similarly, improper threshold val-ues could result in disconnected components or sub-graphs or isolated singleton vertices.
-radius wouldnot define a graph because not every neighborhoodradius would have the same density (see Fig.
1).Neighborhoods of two points (x1, x2) are different,although they contain same number of nodes.We can use both kNN and NN approaches todefine the neighborhood between any xi and xj as:Nxi;k,(xj) ={1 |N(xi)| > kNxi;k(xj) otherwise}(7)|N(xi)| denotes cardinality of -neighbors of xi,and Nxi;k(xj) ?
{0, 1} according to (5).
Thus ifthere are enough number of nodes in the  vicinity(> k), then the boundary is identified.
Otherwisewe use kNN .
Boundary set of any xi is defined as:B(xi) ={xj=1..n ?
X??
?INxi;k,(xj)=1}(8)Relaxed Boundary Detection: Adjusting bound-aries based on a neighborhood radius and densitymight cause some problems.
Specifically, if denseregions (clusters) exist and parameters are set largefor sparse datasets, e.g., k and , then neighborhoodsets would include more (and even noisy) nodesthan necessary.
Similarly, for low density regionsif parameters are set for dense neighborhoods, weakneighborhood bonds will be formed to re-constructvia linear neighborhoods.
An algorithm that canhandle a wide range of change interval would beadvantageous.
It should also include informationprovided by neighboring nodes closest to the corre-sponding node, which can take neighborhood rela-tion into consideration more sensitively.
Thus weextend neighborhood definition in (7) and (8) ac-counting for sensitivity of points with varying dis-tances to neighbor points based on parameter k > 0:Nxi(xj) = max {(1?
k (d(xi, xj)/dmax)) , 0}(9)dmax = maxxi,xj?X d(xi, xj)d(xi, xj) =?
?mp=1(xip ?
xjp)2(10)In (10) m is the max.
feature vector dimension ofany xi, k plays a role in determining neighborhoodradius, such that it could be adjusted as follows:1?
k (/dmax) = 0?
k = dmax/ (11)The new boundary set of any given xi includes:B(xi) = {xj=1..n ?
X |Nxi(xj) ?
[0, 1]} (12)In the experiments, we tested our RLN approach(9), 0 < Nxi(xj) < 1 for boundary detection, incomparison to the static neighborhood assignmentswhere the number of neighbors, k is fixed.
(3) Graph Formation: Instead of measuring pair-wise relations as in (3), we use neighborhood in-formation to represent G. In an analogical man-ner to (Roweis and Saul, 2000), (Wang and Zhang,2006), for graph sparcification, for our Relaxed Lin-ear Neighborhood, we re-construct each node usinga linear combination of its dynamic neighbors:minw?i??
?xi ??j:xj?B(xi)Nxi(xj)wijxj???2s.t.
?j wij = 1, wij ?
0(13)where 0 < Nxi(xj) < 1 is the degree of neighbor-hood to boundary set B(xi) andwij is degree of con-tribution of xj to xi, to be predicted.
ANxi(xj) = 0means no edge link.
To prevent negative weights,and satisfy their normalization to unity, we used aconstraint in (13) for RLN.Edge weights of G are found using above relaxedboundary assumption, and relaxed neighborhood31method.
A sparse relaxed weight matrix (W?
)ij =w?ij is formed representing different number of con-nected edges for every node, which are weighted ac-cording to their neighborhood density.
Since wij isconstructed via linear combination of varying num-ber of neighbors of each node, W?
is used as the edgeweights of G. Next we form a regularization frame-work in place of label propagation (LP).6 Regularization and InferenceGiven a set of token-label assignments X ={x1, ..., xl, xl+1, ..., xn}, and binary labels of first lpoints, Y = {y1, ..., yl, 0, .., 0}, the goal is to predictif the label assignment of any token of a given testquestion is true or false.
Let F denote set of clas-sifying functions defined on X , and ?f ?
F a realvalue fi to every point xi is assigned.
At each it-eration, any given data point exploits a part of labelinformation from its neighbors, which is determinedby RLN.
Thus, predicted label of a node xi at t+1:f t+1i = ?yi + (1?
?
)?j Nxi(xj)wijftj (14)where xj ?
Bxi, 0< ?
<1 sets a portion of la-bel information that xi gets from its local neighbors,ft = (f t1, ft2, ..., ftn) is the prediction label vector atiteration t and f0 = y.
We can re-state (14) as:ft+1 = ?yi + (1?
?
)W?ft (15)Each node?s label is updated via (15) until conver-gence, which might be at t ?
?.
In place of LP,we can develop a regularization framework (Zhou etal., 2004) to learn f. In graph-based SSL, a functionover a graph is estimated to satisfy two conditions:(i) close to the observed labels , and (ii) be smoothon the whole graph via following loss function:argminQ(f) =?ni=1 (fi ?
yi)2+?
?ni,j=1?j:xj?B(xi) ?xi(xj) ?fi, fj?
(16)where ?xi(xj) = Nxi(xj)w?ij .
Setting gradient ofloss function Q(f) to zero, we obtain:?fQ(f) = 2(Y?
f)+?[(I??)+(I??
)T ]f (17)Relaxed weight matrix W?
is normalized accordingto constraint in (13), so as degree matrix, D =?j W?ij , and graph Laplacian, i.e., L = (D?
?W?)/D?
= I ?
W?
.
Since f is a function on the man-ifold and the graph is discretized form of a manifold(Belkin and Niyogi, 2002a), f can also be regardedas the discrete form of f , which is equivalent at thenodes of graph.
So the second term of (16) yields:[(I?W?)+(I?W?
)T ]f ?
2Lf ?
[(I?W?
)]f (18)Hence optimum f?
is obtained by new form ofderivative in (17) after replacing (18):f?
= (1?
?
)(I ?
?W?
)?1Y (19)Most graph-based SSLs are transductive, i.e., noteasily expendable to new testing points.
In (Delal-leau et al, 2005) an induction scheme is proposed toclassify a new point xTe byf?
(xTe) =?i?L?U W?xifi/?i?L?U W?xi (20)Thus, we use induction, where we can, to avoid re-construction of the graph for new test points.7 Experiments and DiscussionsIn the next, we evaluate the performance of the pro-posed RLN in comparison to the other methods onsyntactic and real datasets.Exp.
1.
Graph Construction Performance:Here we use a similar syntactic data in (Jebara etal., 2009) shown in Fig.2.a, which contains twoclusters of dissimilar densities and shapes.
Weinvestigate three graph construction methods, lin-ear k-neighborhoods of (Roweis and Saul, 2000) inFig.2.b, b-matching(Jebara et al, 2009) in Fig.2.cand RLN of this work in Fig.2.d using a dataset of300 points with binary output values.
b-matchingpermits a given datum to select k neighboring pointsbut also ensures that exactly k points selects givendatum as their neighbor.In each graph construction method Gaussian ker-nel distance is used.
Experiments are run 50 timeswhere at each fold only 2 labeled samples from op-posite classes are used to predict the rest.
The exper-iments are repeated for different k, b and  values.
InFig.
2, average of trials is shown when k, b are 10and  >0.5.
We also used the N approach but it didnot show any improvement over kNN approach.32Figure 2: Graph Construction Experiments.
(a) Syntactic data.
(b) linear k-neighborhood (c) b-matching (d) RLN.In Fig.
2.d, RLN can separate two classesmore efficiently than the rest.
Compared to the b-matching approach, RLN clearly improves the ro-bustness.
There are more links between clusters inother graph methods than RLN, which shows thatRLN can separate two classes much efficiently.
Alsosince dynamic number of edges are constructed withRLN, unnecessary links are avoided, but for the restof the graph methods there are edges between faraway nodes (shown with arrows).
In the rest of theexperiments, we use b-matching for benchmark as itis the closest approach to the proposed RLN.Exp.
2.
Semantic Component Recognition:We demonstrate the performance of the new RLNwith two sets of experiments for sequence labelingof question recognition task.
As a first step in un-derstanding semantic components of questions, weasked two annotators to annotate a random subsam-ple of 4000 TREC factoid and description questionsobtained from tasks of 1999-2006.
There are 11predefined semantic categories (section 3), close to280K labeled tokens.
Annotators are told that eachquestion must have one topic and zero or one focusand event, zero or more of the rest of the compo-nents.
Inter-tagger agreement is ?
= 0.68, whichdenotes a considerable agreement.We trained models on 3500 random set of ques-tions and reserved the rest of 500 for testing the per-formance.
We applied pre-processing and featureselection of section 3 to compile labeled and unla-beled training and labeled testing datasets.
At train-ing time, we performed manual iterative parameteroptimization based on prediction accuracy to findthe best parameter sets, i.e., k = {3, 5, 10, 20, 50}, ?
{0, 1}, distance = {linear, gaussion}.We use the average loss (L?)
per sequence (query)other topic focus event rest# Samples 1997 1142 525 264 217CRF 0.935 0.903 0.823 0.894 0.198b-matching 0.871 0.900 0.711 0.847 0.174RLN 0.911 0.910 0.761 0.834 0.180Table 2: Chunking accuracy on testing data.
?other?=O,?topic?=BT+IT, ?focus?
= BF+IF, ?event?= ?BE+IE?,?rest?= rest of the labels, i.e., IE, BC, IC, BCL, ICL.to evaluate the semantic chunking performance:L?
= 1N?Ni=1[1Li?Lij=1 I ((y?i)j 6= (yi)j)](21)where y?
and y are predicted and actual sequence re-spectively; N is the number of test examples; Li isthe length of ith sequence; I is the 0-1 loss function.
(1) Chunking Performance: Here, we investigatethe accuracy of our models on individual componentprediction.
We use CRF, b-matching and our RLNto learn models from labeled training data and eval-uate performance on testing dataset.
For RLN andb-matching we use training as labeled and testing asunlabeled dataset in transductive way to predict to-ken labels.
The testing results are shown in Table 2for different group of components.
The accuracy for?topic?
and ?focus?
components are relatively highcompared to other components.
Most of the errorson the ?rest?
labels are due to confusion with ?topic?or ?focus?.
On some components, i.e., topic, other,RLN performed significantly better than b-matchingbased on t-test statistics (at 95% confidence).
Nostatistical significance between CRF and RLN is ob-served indicating that RLN?s good performance onindividual label scoring, as it shows that RLN canbe used efficiently for sequence labeling.
(2) Question Labeling Performance.
Having33Labeled CRF SSL sCRF b-match RLN1% 0.240 0.235 0.223 0.233 0.2205% 0.222 0.218 0.215 0.203 0.18910% 0.170 0.219 0.186 0.194 0.18025% 0.173 0.196 0.175 0.174 0.17050% 0.160 0.158 0.147 0.156 0.15875% 0.140 0.163 0.138 0.160 0.155100% 0.120 0.170 0.123 0.155 0.149Table 3: Test Data Average Loss on graph constructionwith RLN, b-matching, standard SSL with kNN as wellas CRF, CRF with Self Learning (sCRF).demonstrated that RLN is an alternative methodto the standard sequence learning methods forthe question labeling task, next we evaluate persequence (question) performance, rather than in-dividual label performance using unlabeled data.Firstly, we randomly select subset of labeled train-ing dataset, XiL ?
XL with different sample sizes,niL = 5% ?
nL, 10% ?
nL, 25% ?
nL, 50% ?
nL,75% ?
nL, 100% ?
nL, where nL is the size of XL.Thus, instead of fixing the number of labeled recordsand varying the number of unlabeled points, we pro-pose to fix the percentage of unlabeled points intraining dataset.
We hypothetically use unselectedpart of the labeled dataset as unlabeled data at eachrandom selection.
We compare the result of RLN toother graph based methods including standard SSL(Zhu et al, 2003) using kNN, and b-matching.
Wealso build a CRF model using the same featuresas RLN except the output information, which CRFlearns through probabilistic structure.
In addition,we implemente self training for CRF (sCRF), mostcommonly known SSL method, by adding most con-fident (x, f(x)) unlabeled data back to the data andrepeat the process 10 times.
Table 3 reports averageloss of question recognition tasks on testing datasetusing these methods.When the number of labeled data is small (niL <25%nL), RLN has better performance compared tothe rest (an average of 7% improvement).
The SSLand sCRF performance is slightly better than CRF atthis stage.
As expected, as the percentage of labeledpoints in training is increased, the CRF outperformsthe rest of the models.
However, observing no sta-tistical significance between CRF, b-matching and# Unlabeled tokens 25K 50K 75K 100KAverage Loss 0.150 0.146 0.141 0.139Table 4: Average Loss Results for RLN graph based SSLas unlabeled tokens is increased.RLN up to 25-50% labeled points indicates RLNsperformance on unlabeled datasets.
Thus, for se-quence labeling, the RLN can be a better alternativeto known sequence labeling methods, when manualannotation of the entire dataset is not feasible.Exp.
3.
Unlabeled Data Performance: Herewe evaluate the effect of the size of unlabeled dataon the performance of RLN by gradually increas-ing the size of unlabeled questions.
The assump-tion is that as more unlabeled data is used, the modelwould have additional spatial information about to-ken neighbors that would help to improve its gener-alization performance.
We used the questions fromthe Question and Answer pair dataset distributed byLinguistic Data Consortium for the DARPA GALEproject (LDC catalog number: LDC2008E16).
Wecompiled 10K questions, consisting of 100K tokens.Although the error reduction is small (Table 4),the empirical results indicate that unlabeled data canhave positive effect on the performance of the RLNmethod.
As we introduce more unlabeled data, theRLN performance is increased, which indicates thatthere is a lot to discover from unlabeled questions.8 ConclusionsIn this paper, we presented a graph-based semi-supervised learning method with a new graph con-struction.
Our new graph construction relaxes theneighborhood assumptions yielding robust graphswhen the labeled data is sparse, in comparison toprevious methods, which set rigid boundaries.
Thenew algorithm is particularly appealing to questionsemantic component recognition task, namely ques-tion understanding, in that in this task we usuallydeal with very few labeled data and considerablylarger unlabeled data.
Experiments on question se-mantic component recognition show that our semi-supervised graph-based method can improve perfor-mance by up to 7-10% compared to well-known se-quence labeling methods, especially when there aremore unlabeled data than the labeled data.34ReferencesA.
Alexandrescu and K. Kirchhoff.
2007.
Data-drivengraph construction for semi-supervised graph-basedlearning in nlp.
In Proc.
of HLT 2007.M.
Belkin and P. Niyogi.
2002a.
Laplacian eigenmapsand spectral techniques for embedding and clustering.In Advances in Neural Information Processing Sys-tems.M.
Belkin and P. Niyogi.
2002b.
Using manifold struc-ture for partially labeled classification.
In Proc.
ofNIPS 2002.M.
Belkin, P. Niyogi, and V. Sindhwani.
2006.
A ge-ometric framework for learning from examples.
InJournal of Machine Learning Research.J.
D. Burger.
2006.
Mitre?s qanda at trec-15.
In Proc.
ofthe TREC-2006.J.Y.
Chai and R. Jin.
2004.
Discourse structure forcontext question answering.
In Proc.
of HLT-NAACL2004.O.
Delalleau, Y. Bengio, and N.L.
Roux.
2005.
Efficientnon-parametric function induction in semi-supervisedlearning.
In Proc.
of AISTAT-2005.H.
Duan, Cao Y, C.Y.
Lin, and Y. Yu.
2008.
Searchingquestions by identifying question topic and questionfocus.
In Proc.
of ACL-08.S.
Fan, Y. Zhang, W.W.Y.
Ng, Xuan Wang, and X. Wang.2008.
Semantic chunk annotation for complex ques-tions using conditional random field.
In Coling 2008:Proc.
of Workshop on Knowledge and Reasoning forAnswering Questions.GD.
Forney.
1973.
The viterbi algorithm.
In Proc.
ofIEEE 61(3), pages 269?278.A.
Goldberg and X. Zhu.
2009.
Keepin?
it real: Semi-supervised learning with realistic tuning.
In Proc.of NAACL-09 Workshop on Semi-Supervised Learningfor NLP.E.
Hajicova, P. Sgall, and H. Skoumalova.
1993.
Iden-tifying topic and focus by an automatic procedure.
InProc.
of the EACL-1993.T.
Jebara, J. Wang, and S.F.
Chang.
2009.
Graph con-struction and b-matching for semi-supervised learning.In Proc.
of ICML-09.Dan Klein and Christopher D. Manning.
2003.
Accu-rate unlexicalized parsing.
In Proceedings of the 41stMeeting of the ACL-2003, pages 423?430.J.D.
Lafferty, A. McCallum, and F. Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proc.
of 18thInternational Conf.
on Machine Learning (ICML?01).M.
Maier and U.V.
Luxburg.
2008.
Influence of graphconstruction on graph-based clustering measures.
InProc.
of Neural Infor.
Proc.
Sys.
(NIPS 2008).M.-C.D.
Marneffe, B. MacCartney, and C.D.
Manning.2006.
Generating typed-dependency parsers fromphrase structure parsers.
In In LREC2006.S.T.
Roweis and L.K.
Saul.
2000.
Nonlinear dimension-ality reduction by locally embedding.
In Science, vol-ume 290, pages 2323?2326.F.
Wang and C. Zhang.
2006.
Label propagation throughlinear neighborhoods.
In Proc.
of the ICML-2006.Dengyong Zhou, Olivier Bousquet, Thomas N. Lal, Ja-son Weston, and Bernhard Scho?lkopf.
2004.
Learningwith local and global consistency.
Advances in NeuralInformation Processing Systems, 16:321?328.Xiaojin Zhu, John Lafferty, and Zoubin Ghahramani.2003.
Semi-supervised learning: From GaussianFields to Gaussian processes.
Technical Report CMU-CS-03-175, Carnegie Mellon University, Pittsburgh.35
