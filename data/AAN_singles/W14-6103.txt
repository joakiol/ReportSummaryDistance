First Joint Workshop on Statistical Parsing of Morphologically Rich Languagesand Syntactic Analysis of Non-Canonical Languages, pages 26?38 Dublin, Ireland, August 23-29 2014.Improving the parsing of French coordination through annotationstandards and targeted featuresAssaf UrieliCLLE-ERSSUniversite?
de Toulouseassaf.urieli@univ-tlse2.frJoliciel InformatiqueFoix, Franceassaf@joli-ciel.comAbstractIn the present study we explore various methods for improving the transition-based parsing ofcoordinated structures in French.
Features targeting syntactic parallelism in coordinated struc-tures are used as additional features when training the statistical model, but also as an efficientmeans to find and correct annotation errors in training corpora.
In terms of annotation, we com-pare four different annotations for coordinated structures, demonstrate the importance of globallyunambiguous annotation for punctuation, and discuss the decision process of a transition-basedparser for coordination, explaining why certain annotations consistently out-perform others.
Wecompare the gains provided by different annotation standards, by targeted features, and by usinga wider beam.
Our best configuration gives a 37.28% reduction in the coordination error rate,when compared to the baseline SPMRL test corpus for French after manual corrections.1 IntroductionCoordinated structures (CS) are recognised as one of the main difficulties for automatic syntax parsers.They are particularly challenging for transition-based parsers, which operate sequentially from sentencestart to end: indeed, even for a simple coordinated structure, it is virtually impossible to determine thefirst conjunct of the structure without examining the rest of the sentence.
Consider the following threesentences, identical in French up to the coordinating conjunction:Example 1.1 - J?ai mange?
une pomme rouge et mu?re.
(I ate a red and ripe apple)- J?ai mange?
une pomme rouge et une orange.
(I ate a red apple and an orange)- J?ai mange?
une pomme rouge et Georges a bu du the?.
(I ate a red apple and George drank some tea)In the above cases, selecting the correct conjuncts is simply a matter of examining the parts-of-speechimmediately following the coordinating conjunction, except in the last case, where we have to decidewhether or not George gets eaten.
Nevertheless, nothing preceding the conjunction can help us make thedecision.
Often the situation is more complex, with adjuncts intervening between the conjunction andsecond conjunct, not to mention cases such as various forms of ellipsis, CSs with 3 or more conjuncts,and modifiers shared by two or more conjuncts.In this article, after reviewing related work (section 2) and introducing CS annotation and transition-based parsing (section 3) and our data set and software (section 4), we follow a chronological outline interms of our own research.
In a previous study (Urieli, 2014) we successfully applied knowledge-richtargeted features to the pos-tagging of ambiguous functional words.
In the present study we turn to pars-ing (section 5.1), and attempt to apply knowledge-rich targeted features for coordination to the SPMRL2013 dependency corpus for French (Seddah et al., 2013).
Although the results are not fully satisfactory,we discover while tuning the features that they can be very useful for pinpointing and correcting manyof the coordination errors in the training and evaluation corpora (section 5.2).
Also, while exploring thereason behind failure to coordinate correctly, we note that the way in which coordination is annotated inthe corpus is responsible for a sizable proportion of errors.
We then attempt automatic transformationsThis work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings footerare added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/.26of this annotation and compare results for six different annotations (section 5.3).
Finally, we combineannotation schemes with targeted features and a wider beam to find the maximal gain that can be attained(section 5.4).2 Related workSeveral studies have explored the annotation standards for coordination in English.
However, the originalPenn Treebank annotates only a subset of simple coordinated structures implicitly by grouping the itemstogether in a single phrase.
Maier et al.
(2012) present an annotation scheme for Penn Treebank coordi-nation which includes punctuation, critical in the case of constituency treebanks.
They then (Maier andKu?bler, 2013) train a classifier to attempt to recognise coordinating vs. non-coordinating commas, andachieve an f-score of 89.22 for the coordinating (difficult) class.
Many of the phenomena they are tryingto disambiguate in the constituency treebank by annotating punctuation are disambiguated in dependencytreebanks more simply by using an appropriate set of dependency labels, e.g.
in the case of apposition vs.coordination.
In the present study, we thus take a somewhat opposite approach by removing annotationfrom punctuation in the dependency treebank context, in order to concentrate the decision-process on theconjuncts themselves.Ivanova et al.
(2013) measure performance for English using three different annotations for coordi-nation, all of which are covered by the present study.
With respect to annotation, they come to similarconclusions for English to ours for French, but concentrate on the lowest-accuracy conjunction-headedapproach, as it is proned by the grammar-based parser in which they specialize.Popel et al.
(2013) perform a survey of many different dependency annotations for coordination, anddevelop a tool for lossless transformation between these annotations.
They also describe in detail thevarious difficulties involved in annotating coordination, including the role of punctuation.Schwartz et al.
(2012) compare the ?learnability?
of various possible annotations for 6 structures inEnglish, including coordination, where learnability is defined both by the annotation giving the highestattachment accuracy, and by the annotation which attains a target accuracy with the fewest trainingexamples.
They compare 2 possible annotations for coordination, and find, as we do, that using one ofthe conjuncts as head is far more learnable than using the conjunction as the head, across a variety ofparsers.
However, since the Penn Treebank does not annotate coordinated structures with more than 2conjuncts, they explore fewer annotation possibilites than in the present study.Tsarfaty et al.
(2011) raise a similar question of evaluating parsers trained on different annotation stan-dards, including for coordination, but take a radically different approach.
They convert all annotations todirectly comparable generalised functional trees, and find that apparent major differences in performanceare considerably attenuated or disappear when considered in such a light.
It would be interesting to applytheir method to our different annotations for French data, and see to what extent it affects results.In terms of annotation standards, the present study extends previous work by (a) applying similarexperiments to French and consolidating certain conclusions, while concentrating on the case of 3 ormore conjuncts, (b) highlighting the importance of a systematic annotation for punctuation, which isonly possible when punctuation is not explicitly used to indicate coordination, and (c) comparing gainsfrom annotation changes to those made by the addition of targeted coordination features or using a widerbeam.In terms of specific targeted features for coordination, Hogan (2007) achieves statistically signifi-cant improvements in noun phrase (NP) coordination in English, in the context of a history-based con-stituency parser, by introducing features for NP head semantic similarity.
Shimbo and Hara (2007)leave out semantics, and instead use features incorporating the syntactic ?edit-distance?
between com-peting structures.
Both studies apply to consitituency parsers with a higher complexity than our lineartransition-based parser.Other studies have attempted introducing generic ?rich?
features without specifically aiming at par-allelism in coordination.
Ku?bler et al.
(2009) propose a method whereby the n-best PCFG parses arereranked, in order to improve the parsing of coordination in German.
Their features are generic, but cancover the full parse trees since they are applied in reranking rather than during parsing.
Our study differs27Je vois Jean , Paul et Marieobjcoorddep coordcoorddep coordFigure 1: French SPMRL annotation for coordinationfrom theirs by applying the features during the first parsing pass of a linear-complexity transition-basedparser, rather than requiring a large beam of n-best solutions at the outset.Zhang and Nivre (2011; 2012) have shown the usefulness of generic ?rich?
features such as the valency(number of dependents) of a given token, the distance between two tokens, a list of current uniquemodifier labels for a token, and features looking at various characteristics a token?s second order governor(its governor?s governor).
They find that these features are particularly useful for global-learning basedparsers with a very high beam width (64)?this however comes with certain practical disadvantages,since parsing speed is linearly correlated to beam width, and analysing with a beam of 64 takes 64 timesas long.
In our study, we do not explore beam widths beyond 5 and do not apply global learning, andshow nevertheless that highly specific targeted features give considerable gain even in such a context.In terms of French, De la Clergerie (2014) introduces rich symbolic features into statistical transition-based parsing indirectly, by parsing each sentence first using FRMG, a TAG parser, and injecting fea-tures based on the FRMG parse into the transition-based parser.
He attains excellent results for French(LAS=90.25 for the SPMRL test corpus with guessed pos-tags).
However, given the need to parsewith a TAG parser, this system is not directly comparable to linear-time transition-based parsing.3 Annotations and analysis mechanismsLet us consider the following sentence containing a 3-conjunct coordinated structure:Example 3.1 Je vois Jean, Paul et Marie.
(I see John, Paul and Mary)Figure 1 shows the French SPMRL dependency annotation for this sentence: all conjuncts are gov-erned by the first conjunct via the preceding comma or conjunction.The next question is: how is such an annotation parsed?
In this study we concentrate purely ontransition-based parsing (Ku?bler et al., 2009).
Parsing is thus defined as a series of transitions leadingfrom one parse configuration to the next, where a parse configuration is defined as follows:?
?
: a stack, or ordered sequence of tokens which have been partially processed?
?
: a buffer, or ordered sequence of tokens which have not yet been processed?
?
: a set of dependency arcs of the form label(governor, dependent) that have already been added?
?
: a sequence of transitions allowing us to reach the current configuration from an initial oneWe will use ?0 to indicate the token currently on top of the stack, and ?1..n for tokens deeper in thestack.
Similarly, ?0 indicates the next token to be processed on the buffer, and ?1..n for tokens fartherdown the buffer.
Parsing begins with root artefact on the stack and all other tokens on the buffer.
Parsingends when the buffer is empty.
Our study uses the arc-eager transition system (Nivre, 2008), whichdefines the four transitions shown in table 1 for moving from one configuration to the next.It is well known that transition-based parsers tend to favour short-distance dependencies over longerdistance ones (McDonald and Nivre, 2007; Candito et al., 2010), since they will always compare twocloser tokens before comparing two tokens which are farther away, and the decision regarding the twocloser tokens is taken independently given the information available at this point.
Thus, a closer tokenis never directly compared to a token farther away when making an attachment decision.
This tendencycan be somewhat curtailed by applying a beam search (Urieli and Tanguy, 2013).28transition effect preconditionleft-arclabel Create the dependency arclabel(?0,?0) and pop the stackThe reverse dependencyany(?0,?0) does not exist, and?0 is not the root noderight-arclabel Create the dependency arclabel(?0,?0), and push the head of thebuffer to the top of the stackreduce Pop the top of the stack The top-of-stack has a governorshift Push the head of the buffer to the topof the stackTable 1: The arc-eager transition system for shift-reduce dependency parsingNow, as already seen in example 1.1, forward-looking features are required to correctly identify thefirst conjunct by guessing the second conjunct.
Table 2 shows the exact sequence of transitions requiredfor parsing the 3rd example sentence from example 1.1, from the moment when we first encounter thecoordinating conjunction on the buffer to the moment when the CS itself has been fully parsed.
Difficultdecisions are shown in bold.
Among these, the reduce transitions on lines n+1 and n+2 both require usto look farther down the buffer to guess the most likely second conjunct, since we can only reduce whenthere are no more dependents to be attached.
The shift transitions on lines n+4 and n+5 are simpler,since we already know that the first conjunct is a verb.
Still, we have to recognise that the second verb iscomposite, which is governed by convention by the past participle rather than the helper verb.transition stack buffer dependenciesaddedn root, mange?,pomme, rougeet, Georges, a, bu,du, the?n+1 reduce root, mange?,pommeet, Georges, a, bu,du, the?n+2 reduce root, mange?
et, Georges, a, bu,du, the?n+3 right-arccoord root, mange?, et Georges, a, bu, du,the?coord(mange?,et)n+4 shift root, mange?, et,Georgesa, bu, du, the?n+5 shift root, mange?, et,Georges, abu, du, the?n+6 left-arcaux tps root, mange?, et,Georgesbu, du, the?
aux tps(bu, a)n+7 left-arcsuj root, mange?, et bu, du, the?
suj(bu, Georges)n+8 right-arcdep coordroot, mange?, et, bu du, the?
dep coord(et, bu)Table 2: Arc-eager transition sequence for coordination, with difficult decisions in boldThe case of a CS with 3 or more conjuncts is even more complicated, since it requires lookaheadfeatures for the first two conjuncts, looking farther ahead than in the case of the 2-conjuct CS.
In allcases, correctly guessing the final conjunct ahead of time is critical information to correctly annotatingthe coordination.294 Data and software4.1 TalismaneAll of the experiments in this study use the Talismane parser1.
Talismane (Urieli, 2013) is an NLP toolkitincluding a sentence detector, tokeniser, pos-tagger and transition-based parser.
All four modules use astatistical supervised machine learning approach, and it is possible to apply a beam search to the lastthree modules, as well as defining sophisticated features and rules using an expressive feature definitionsyntax.
For all experiments in the present study, we used a linear SVM model with C = 0.25 and = 0.01.
We applied a cutoff of 5, so that a feature has to appear at least 5 times in the training corpusto be considered.4.2 French TreebankThe original input for this study is the dependency annotation for the French section of SPMRL (Seddahet al., 2013), itself derived from the French Treebank (Abeille?
et al., 2003), via an automatic conversionof constituency structures to dependencies.
We use the train (14,759 sentences, 412,879 tokens), dev(1,235 sentences, 36,272 tokens) and test (2,541 sentences, 69,922 tokens) divisions of this corpusas defined for SPMRL.
All of our studies use the gold pos-tags from the treebank, in order to make anabstraction of pos-tagger errors and concentrate on parsing.
The baseline LAS excluding punctuation is89.57% (dev) and 89.45% (test).
The baseline f-score for coordinated structures, calculated as thef-score for all individual coordination arcs, is 84.35% (dev) and 85.16% (test).4.3 Initial error classificationWe began this study by analysing coordination errors performed by Talismane in the dev corpus.
Out of240 errors analysed, 24% were annotation errors (of which over 60% were correctly annotated by Talis-mane), 14% were artefacts of the annotation scheme (the 2nd and 3rd conjunct were directly coordinatedby Talismane unlike the original annotation), and 30% were errors where Talismane coordinated twodifferent pos-tags, whereas the correct coordination involved the same pos-tag.
If we group this togetherwith other cases of simple parallelism (e.g.
cases where Talismane coordinated different prepositionsinstead of the same prepostion), this climbs up to 38%.
The remaining 24% covered various difficultcases, including elliptical coordinations.
Only 12% involved cases where semantics were required tomake the correct choice.The cases where the mildly rich French morphology might help us are very rare: only three casesamong the dev corpus errors.
In the examples below and elsewhere in this article, the guessed conjunctsare shown in italics (non-italics for the English translation), the correct conjuncts are underlined, and theconjunction is shown in bold.
In the first example, the feminine demonstrative pronoun celle indicatesthat we are coordinating with the feminine noun pre?sidence rather than with M. Michel Albert:Example 4.1 [.
.
. ]
on avait parle?
de la pre?sidence des AGF a` la place de M. Michel Albert ou de celledu GAN occupe?e par M. Franc?ois Heilbronner.
(.
.
.
they spoke of the presidency of the AGFs instead ofMr Michel Albert or of that of the GAN occupied by Mr Franc?ois Heilbronner.
)In the second case, the masculine past participle rejete?
should coordinate with the masculine pastparticiple opte?
rather than the feminine faite:Example 4.2 Le conseil d?administration [.
.
. ]
a opte?
pour la proposition de reprise faite par Bongrainet rejete?
celle de Besnier.
(The board of directors chose the takeover proposal made by Bongrain andrejected the one made by Besnier.
)In the final example, a plural adjective re?pe?titifs is coordinated with a plural adjectival past participleconstruits, rather than a previous morphologically unadorned past participle de?couvert in a conjugatedconstruction:Example 4.3 [.
.
. ]
les Europe?ens ont de?couvert/VPP l?immensite?
du stock japonais : [.
.
. ]
sce?nariosre?pe?titifs/ADJ mais habilement construits/VPP [.
.
. ]
(the Europeans discovered the immensity of theJapanese stock: repetitive and skillfully constructed scenarios.
.
.
)1http://redac.univ-tlse2.fr/applications/talismane.html30Because of the rarity of such cases, we decided not to include morpholigical features in our experi-ments.5 Experiments5.1 Initial experiment with targeted featuresWe first decided to target the 38% of errors relating to simple parallelism (e.g.
parallelism errors relatedto mismatched pos-tags or prepositions, rather than semantics).Because of the importance of identifying a second conjunct before identifying the first one, we firstconstructed the following targeted feature:?
Second conjunct identification: attempts to correctly identify the second conjunct.
Since allsubsequent features depend on this second conjunct feature, it was critical to attain high accuracy.Also, since the feature is a component of features used to select the first conjunct, it can only makeuse of information available when a first conjunct candidate is at ?0 and the conjunction at ?0 (steps1, 2 and 3 in table 2): critically, it tries to guess the second conjunct with no knowledge of thecorrect first conjunct.The most difficult cases for this feature are verbs, since both coordinated verbs need to be outside ofsubordinate, relative or comment phrases.
Comment phrases, particularly numerous in journalistic text,and marked only by punctuation, word order, and lexical choices, are the most difficult to recognise.
Thefollowing list shows examples of sentences with two conjugated verbs (in italics), and with the conjunctsunderlined.1.
Verb coordination: Il s?agit ici d?un jour normal de la semaine et un inventaire scrupuleux exigeraitque l?on prenne e?galement en compte l?offre accrue du mercredi.
(We are dealing here with a normalweekday, and a scupulous inventory would require us to take into account the increased offer onWednesdays.)2.
Verb coordination: Les chiffres parlent d?eux-me?mes : les Japonais occupent 30 % du marche?ame?ricain et leurs exportations repre?sentent pre`s de 75 % du de?ficit commercial global annuel.
(The numbers speak for themselves: the Japanese occupy 30% of the American market and theirexports represent almost 75% of the annual global commercial deficit.)3.
Comment phrase: A Lourdes, nous signale notre correspondant Jean-Jacques Rollat, la venue etla circulation des pe`lerins ont e?te?
tre`s perturbe?es.
(At Lourdes, signals our correspondent Jean-Jacques Rollat, the arrival and circulation of pilgrims was considerably disrupted.)4.
Relative clause: Les e?missions d?e?veil qui ont fait la richesse des cha?
?nes de service public entre1975 et 1985 ont toutes disparu.
(The discovery programmes which constituted the richness ofpublic channels between 1975 and 1985 have all disappeared.
)We tested this feature on the training corpus, by applying it whenever a conjunction was found in?0, and seeing how often it correctly guessed ?true?
when the token in ?0 was the second conjunct, and?false?
when the token in ?0 was not the second conjunct, while ignoring knowledge of the first conjunct.The accuracy for the ?true?
result is 99.07%, and for the ?false?
result is 94.54%.We then used this feature to construct various features attempting to recognise parallelism in CS withinthe framework of transition-based parsing.
Most of these features compare the item currently at the top-of-stack to the second conjunct guess, and check to see if there is a better candidate deeper in the stack.The following features were used:?
Pos-tag mismatch: if the first conjunct candidate at the top-of-stack has a different pos-tag fromthe second conjunct guess, does a candidate with the same pos-tag exist deeper on the stack??
Mismatched prepositions: if the first candidate at the top-of-stack and the second conjunct guessare two different prepositions, does the same preposition exist deeper on the stack?31?
Pos-tag match: if the first conjunct candidate at the top-of-stack is the same pos-tag as the secondconjunct guess, are there any other candidates with this pos-tag deeper on the stack??
3 conjunct parallelism: when two tokens of the same pos-tag, separated by a comma, are beingcompared, is the second token followed by a coordinating conjunction and then a third token withthe same pos-tag as the first two?
We allow for various intervening modifiers depending on thepos-tag being considered.?
Parentheses: is the first conjunct candidate at the top-of-stack inside parentheses and the secondconjunct guess outside of them?When we first attempted to apply these features to our dev (and test) corpora, our f-score forcoordination (coord and dep coord combined) improved from 84.34% to 85.52% (85.16% to 86.97%for test), giving a fairly modest error reduction of 7.54% (12.20% for test).
In terms of significance,McNemar?s test gives a p-value < 0.001 for coordination label changes in both dev and test.Now, there are of course cases in the training corpus with valid non-parallel structures, such as thefollowing coordination between an adjective and prepositional phrase:Example 5.1 Au mieux, la reprise sera lente/ADJ et de/P faible ampleur.
(At best, the recovery will beslow and of limited extent.
)These, however, are few and far in between when compared to the very large number of errors concern-ing clear pos-tag parallelism.
We will examine some errors introduced by applying targeted parallelismfeatures to non-parallel CSs in our final error analysis found in section 5.4.5.2 Improvements through manual correctionThe targeted feature definition involved several iterations in which features were projected onto the train-ing corpus, and any unexpected results were analysed.
Among the unexpected results were a very largenumber of annotation errors.
Given that 24% of the original errors in the dev corpus were annotation er-rors, and our efficient method for pinpointing and correcting such errors by projecting targeted features,we decided to apply these targeted manual corrections to the entire SPMRL French corpus (train, devand test).Specifically, these manual corrections involved:?
Fixing any coordination where the dependent preceded the governor (impossible in the originalannotation standard)?
Reviewing and standardizing all cases of ni.
.
.
ni.
.
.
(neither.
.
.
nor.
.
. )
and soit.
.
.
soit.
.
.
(ei-ther.
.
.
or.
.
.
).?
Projecting the above targeted features onto the corpus via Talismane, and correcting any items wherethe feature yielded unexpected results.The total corrections are 1,488 for train (out of 21,061 coordination relations = 7.07%), 106 for dev(out of 1,743 coordination relations = 6.08%) and 274 for test (out of 3,420 coordination relations =8.01%).
Multi-word expressions (MWEs) were left as is, except on rare cases where a modifier insidethe MWE was coordinated to a modifier outside of it.dev base dev fix test base test fixtrain base 84.34 85.08 85.16 85.54train fix 83.99 85.75 84.99 86.75Table 3: Coordination f-score after targeted manual error correctionTable 3 shows the coordination f-score with and without targeted error correction in both training andevaluation.
Fixing errors in the training corpus is only useful when equivalent errors are fixed in the32Je vois Jean , Paul et Marieobjcoorddep coordcoorddep coord(a) 1st-conjunct headed (1H)Je vois Jean , Paul et Mariecoordcoordobjcoord(b) Conjunction headed (CH)Je vois Jean , Paul et Marieobjcoorddep coordcoorddep coord(c) Previous conjunct headed (PH)Je vois Jean , Paul et Marieobjcoord coorddep coord(d) Previous conjunct headed 2 (PH2)Figure 2: Different annotations for coordinationevaluation corpora.
If we consider the corrected evaluation corpora only, fixing errors in the trainingcorpus gives an f-score error reduction of 4.49% for dev (8.37% for test).The remainder of this study uses the manually corrected corpora as a baseline.
Although this is notsatisfying in terms of comparisons with other studies, we found ourselves constrained to do so becauseour automatic conversions from one annotation scheme to another required a clean and consistent anno-tation to begin with.
In order to simplify comparisons, we have generated a difference file to apply to theoriginal SPMRL corpus, available upon request.5.3 Comparing annotation schemesAs seen in section 4.3, over 14% of the initial errors were artefacts of the annotation scheme for aCS with more than 2 conjuncts, where Talismane systematically attached the conjunct to the previousconjunct, whereas the original annotation scheme systematically attaches it to the first conjunct.
Indeed,the previous conjunct attachment is more natural for transition-based parsers: since the comma is a highlyambiguous indicator for coordination, the coordination is often missed between the first and secondconjuncts, and the first conjunct is reduced.
By the time the parser reaches the coordinating conjunction,only the second conjunct is left on the stack.
This suggested that changing the CS annotation schemecould lead to considerable improvements.We therefore decided to experiment with four different equivalent CS annotation schemes, as shown infigure 2.
Subfigure 2a gives the original 1H (1st conjunct headed) annotation used in the SPMRL 2013dependency corpus for French.
The first conjunct always heads the CS, and governs the coordinatingcommas and conjunction with a coord label, which in turn govern the remaining conjuncts with adep coord label.
Subfigure 2b shows the CH (conjunction headed) annotation, used by a wide varietyof grammars: the conjunction governs all of the conjuncts with a coord label.
Subfigure 2c shows thePH (previous conjunct headed) annotation, in which each conjunct governs the following coordinator(whether a comma or a conjunction) with the coord label, and the coordinator governs the followingconjunct with the dep coord label.
Finally, subfigure 2d shows the PH2 annotation, in which we skipthe comma, so that conjuncts separated by a comma are directly governed by the previous conjunct usingthe coord label.
In the case of a simple CS with 2 conjuncts, the PH and PH2 annotations are identicalto the 1H annotation.Notice that there is no loss of information between these four annotations, so that round-trip conver-sions can restore the original annotation.
Post-positioned shared modifiers (e.g.
?Jean, Paul et MarieDupont?, where all three are members of the Dupont family) can be indicated by having the conjunc-tion govern the shared modifier in the CH annotation, and having the 1st conjunct govern it in the otherannotations.
This annotation becomes non-projective (i.e.
involves crossed dependency arcs) in 1H, PHand PH2 when the modifier applies to the objects of a prepositional phrase coordination, e.g.
?Je parle33de Jean, de Paul, et de Marie Dupont?
(?I?m talking about John, Paul and Marie Dupont?).
Since weuse a projective parser in the present study, we change the governor to the final conjunct when requiredto avoid non-projectivity, thus losing some information.
The 1H, PH and PH2 have no simple way ofdistinguishing ante-positioned shared modifiers from modifiers of the first conjunct, e.g.
?Chers Jean,Paul et Marie?
(?Dear John, Paul and Mary?).
Moreover, none of these annotation schemes provide aclear solution for elliptical coordinations, e.g.
?J?ai vu Jean et Paul hier, et Marie aujourd?hui?
(?I sawJohn and Paul yesterday, and Mary today?
).Another possibility for annotation was suggested by detailed analysis of the actual transition sequencesfor the first 20 coordination errors, revealing two cases in which, if a comma followed the first conjunct,the first conjunct was erroneously reduced.
This suggested that having to take a decision when the commawas found at ?0 led to errors which could be eliminated if the comma were immediately attached and onlyused as a feature for further decisions.
Now, if we look at the French Treebank annotation for punctuationoutside of coordinated structures, the label is always ponct, but the choice of the punctuation?s governorseems fairly arbitrary.
Parser confidence is thus very low for punctuation attachment decisions, and asa result, when applying a beam search, the beam is often filled with alternative arbitrary punctuationattachment decisions instead of true syntactic ambiguities.
We therefore decided to experiment as wellwith attaching punctuation systematically to the previous non-punctation token (or to the root artefactwhen punctuation opens the sentence), except in the case of coordinating commas for the 1H and PHannotations.
Indeed, for the CH and PH2 schemes, we were forced to apply this punctuation ?fix?in order to avoid generating a large number of non-projective punctuation arcs when transforming thecorpus.
In these latter two annotations, where coordinated commas are not used to annotate the CS,applying a punctuation fix results in systematic annotation for all punctuation in the corpus, thus resultingin a systematic application of the right-arcponct and reduce transitions.We thus make the hypothesis that transition-based parsers will favour those annotations which relyon shorter-distance dependencies, specifically PH and PH2.
Our second hypothesis is that systematicannotation for commas (PH2) helps improve annotation by removing a needless source of ambiguity.Scheme: 1H 1H+P CH+P PH PH+P PH2+PDevCoord f-score 85.75 85.60 73.20 86.68 86.96 89.21Coord prec.
99.55 99.55 98.88 99.49 99.49 99.41Coord recall 75.31 75.09 58.11 76.79 77.24 80.91LAS no punct.
89.69 89.69 87.44 89.74 89.82 90.11UAS no punct.
91.71 91.64 89.39 91.74 91.78 92.02LAS 87.34 91.00 89.13 87.38 91.11 91.45UAS 89.10 92.69 90.81 89.12 92.82 93.10TestCoord f-score 86.75 86.94 73.09 88.20 88.44 90.29Coord prec.
99.70 99.52 99.38 99.75 99.50 99.71Coord recall 76.78 77.18 57.80 79.04 79.59 82.50LAS no punct.
89.63 89.81 87.19 89.76 89.94 90.16UAS no punct.
91.63 91.79 89.17 91.75 91.94 92.13LAS 87.19 91.12 88.93 87.29 91.24 91.49UAS 88.93 92.85 90.64 89.01 92.98 93.20Table 4: Comparing CS annotationTable 4 shows results for the six annotation schemes (where +P indicates the punctuation fix was ap-plied): 1H, 1H+P, CH+P, PH, PH+P, PH2+P.
All results are after targeted manual correction.
For ease ofcomparison with previous studies, we show LAS and UAS both with and without punctuation.
Unsur-prisingly, in the schemes without the punctuation fix, hence with arbitrary attachment for punctuation,we systematically lose 2% when we include punctuation in the LAS/UAS, whereas in the schemes with34the punctuation fix we systematically gain over 1%.In the coordination results, we include both the coord and dep coord labels, since differentschemes have different proportions for these.
Precision is very high because of the strong markersfor coordination.
Recall is much lower, because of the difficulty of finding the first conjunct.
Theconjunction-headed scheme CH+P is a clear loser in transition-based parsing?hardly a surprising re-sult, since it requires far more lookahead features.
All of the previous-conjunct headed schemes (PH,PH+P, PH2+P) outperform the first-conjunct headed schemes (1H, 1H+P) by over 1.5% when it comesto the coordination f-score, which validates our hypothesis based on the analysis of errors in section4.3.
Finally, the clear winner is the PH2+P scheme, where all attachment ambiguity is transposed frompunctuation to the conjuncts, with 2.0% gain in coordination f-score with respect to the PH+P scheme.The coordination f-score error reduction between the original 1H scheme and PH2+P is 24.28% for dev(26.72% for test).
In terms of statistical significance for both the dev and test corpora (McNemar?stest applied to identifying individual conjuncts), the differences between 1H, 1H+P, PH and PH+P arenot significant (p-value > 0.05).
The differences between any other schema and CH+P or PH2+P arehighly significant (p-value < 0.001).5.4 Combining with targeted featuresIn our final experiment, we combine the PH2+P annotation scheme with the targeted features presentedin section 5.1, to see to what extent the gains are cumulative.
We also test at different beam widths to seehow much additional gain can be had at higher beams.Beam: Beam 1 Beam 2 Beam 5Scheme: 1H PH2+P 1H PH2+P 1H PH2+PFeatures: ?
+ ?
+ ?
+ -?
+ ?
+ ?
+DevCoord f-score 85.8 86.4 89.2 90.0 87.0 87.2 90.3 90.5 87.2 87.4 90.8 90.7Coord prec.
99.6 99.4 99.4 99.4 99.6 99.5 99.5 99.5 99.4 99.4 99.6 99.5Coord recall 75.3 76.3 80.9 82.2 77.2 77.5 82.7 83.0 77.6 78.0 83.3 83.4LAS no pnct 89.7 89.7 90.1 90.3 90.2 90.3 90.5 90.6 90.4 90.4 90.7 90.7UAS no pnct 91.7 91.8 92.0 92.2 92.2 92.3 92.5 92.6 92.4 92.5 92.6 92.7LAS 87.3 87.4 91.5 91.6 88.0 88.1 91.8 91.9 88.2 88.3 91.9 92.0UAS 89.1 89.2 93.1 93.2 89.8 89.9 93.5 93.6 90.0 90.1 93.6 93.7TestCoord f-score 86.8 88.5 90.3 91.3 87.8 89.3 90.5 91.6 88.6 89.6 90.6 91.7Coord prec.
99.7 99.6 99.7 99.7 99.8 99.7 99.6 99.6 99.8 99.6 99.6 99.6Coord recall 76.8 79.5 82.5 84.3 78.4 80.9 83.0 84.8 79.6 81.5 83.1 85.0LAS no pnct 89.6 89.9 90.2 90.3 90.3 90.4 90.6 90.7 90.5 90.6 90.6 90.8UAS no pnct 91.6 91.9 92.1 92.2 92.2 92.4 92.5 92.6 92.5 92.6 92.6 92.7LAS 87.2 87.4 91.5 91.6 88.0 88.2 91.8 92.0 88.4 88.4 91.9 92.0UAS 88.9 89.2 93.2 93.3 89.7 89.9 93.5 93.6 90.0 90.1 93.6 93.7Table 5: Combining annotation schemes and targeted features at different beam widthsTable 5 shows the results at beams 1, 2 and 5, for the original scheme 1H and the best scheme PH2+P,and with (+) or without (?)
targeted features.
Gains are clearly centered on coordination recall.
Table 6shows the same information in terms of f-score error reduction with respect to the baseline configuration(1H annotation, baseline features, beam 1), with a maximal reduction of 35.09% for the dev corpus, and37.28% for test.
The three parameters tested are to a large extend cumulative.
Individually, changingthe annotation standard gives the most gain, followed by targeted features and then increasing the beamsize to 2.
In terms of statistical significance for the test corpus (McNemar?s test applied to identifyingindividual conjuncts), all combinations are significant (p-value < 0.05) except for: PH2+P/?/1-2 toPH2+P/?/5; PH2+P/+/2 to PH2+P/+/5; and a few other combinations going from 1H/+ to PH2+P/?.35None Features Scheme BothDev: base f-score = 85.75Beam 1 0.00 4.28 24.28 29.89Beam 2 8.49 9.82 32.14 33.40Beam 5 9.82 11.44 35.09 34.95Test: base f-score = 86.75Beam 1 0.00 12.91 26.72 34.64Beam 2 8.15 19.02 28.53 36.83Beam 5 13.58 21.81 28.98 37.28Table 6: Coordination f-score error reduction with respect to 1H, baseline features, beam 1In terms of time performance, these changes have a vastly different cost.
All tests were run on an IntelXeon E3-1245 V2 machine, with a 3.4GHz clock speed, 4 cores, 8 threads, and 8 Mb cache, running theUbuntu 12.04.2 LTS 64-bit operating system.
The baseline setup takes 171 seconds to parse the testcorpus (+133 seconds to load the model and lexicon), giving about 400 tokens/second.
Changing theschema from 1H to PH2+P speeds up analysis slightly (?0.93).
Changing the beam width results in alinear increase in time, ?2 for a beam of 2, and ?5 for a beam of 5.
Finally, targeted features result in a?22 increase in time.We also performed a detailed error analysis for dev corpus, on the remaining errors in the PH2+Pcorpus with targeted features at beam 1.
Although the number of erroneous coordinations analysed hasreduced from 241 to 151, the percentage of errors relating to simple parallelism (pos-tag mismatch,preposition mismatch, etc.)
remains stable, down from 38% to 36%.
Annotation errors are reduced from24% to 11%.
Artefacts of the annotation scheme in which conjuncts are attached to the first or secondconjunct are reduced from 15% to 5%.
Finally, the complicated cases have climbed significantly, withellipses climbing from 5% to 13% and cases where only semantics can help us decide climbing from12% to 23%.
The latter results indicates that introducing semantic resources might be worthwhile for theremaining errors.There are a few cases of CSs coordinating unlike categories, where the new features introduced errors.We have a two cases of true non-parallelism, as in the following case, where an adjectival past participleis coordinated with a prepositional phrase:Example 5.2 [.
.
. ]
celle d?/P une part significative des programmes et des productions re?alise?es/VPPou en cours de/P re?alisation.
(.
.
.
that of a significant part of programs and productions that are alreadyfinished or currently being prepared.
)We have a similar valid case of a non-parallel copula coordinating an adjective with a pronoun :Example 5.3 Ce n?est/V pas force?ment la plus e?conomiquement souhaitable/ADJ, mais celle/PRO quifera le moins de vagues, compte tenu de l?agitation dans les campagnes, entendait/V-on [.
.
. ]
(It?s notnecessarily the most economically desirable, but the one which will make the least waves, given therestlessness in the countryside, we were told.
.
.
)The remaining cases are related to spelling errors in the original text, or to tokenisation and pos-tagerrors in the gold pos-tags.
For example, in the following case, the journalist misspelt the second baisser(to lower) as an infinitive verb whereas it should have been the homophone past participle baisse?
:Example 5.4 Quant au dollar lui-me?me, il a monte?/V quand on croyait qu?il allait baisser/VINF [.
.
. ]
etbaisser/VINF derechef quand le marche?
commenc?ait a` se convaincre.
.
.
(As for the dollar itself, it rosewhen we thought it would lower, and lower[ed] once again when the market started to convince itself.
.
.
)A second case involves the MWE conforme?ment aux (in conformance with), which should probablybe marked as a single preposition rather than ADV+P:Example 5.5 Dans le cas des/P ce?re?ales, et conforme?ment/ADV aux/P orientations souhaite?es par lesorganisations professionnelles [.
.
. ]
(In the case of cereals, and in conformance with the desires ofprofessional organisations, .
.
.
)36Similar cases involve the pos-tagging of ge?ne?raux as a noun (generals in an army) rather than anadjective (general):Example 5.6 [.
.
. ]
a` l?ensemble des pre?sidents/NC des conseils re?gionaux/ADJ et ge?ne?raux/NC.
(.
.
.
toall of the presidents of regional and general councils.
)6 Conclusions and perspectivesIn the present study, we attempted to improve the parsing of coordinated structures in French throughchanges to the annotation scheme and the application of targeted features.
Both methods were successful,with annotation scheme changes reducing the test corpus coordination f-score error rate by 26.72%,targeted features reducing it by 12.91%, and the two combined reducing it by 34.64% (36.83% at beam2, 37.28% at beam 5).However, the application of targeted features comes at a considerable practical cost in terms of timeperformance (?22 increase in time).
This is partly due to the fact that features are described in configu-ration files using a declarative syntax, so that certain operations (e.g.
looking forward in the buffer) arerepeated thousands of times.
Indeed, forward-looking features do not rely on partial parsing information,and could even be cached for any given token for the entire sentence parse, across parse configurations.If features were programmed and compiled, this could be made far more efficient, but we would lose theadvantage of external configuration files.In addition, we introduced a method for efficiently correcting training corpus errors through the pro-jection of targeted features, a method which could be extremely useful for corpus constructors.
Finally,we highlighted the usefulness of removing all ambiguity from the annotation of punctuation.In a future study, we would need to test these methods with guessed pos-tags rather than gold pos-tagsin order to check their sensitivity to pos-tag errors.
It would also be interesting to apply our methodsto other languages, and to include targeted semantic features based on semantic resources automaticallyconstructed using semi-supervised methods.
For languages with a richer morphology than French, itmight well be worthwhile to introduce features based on morphological parallelism as well.
Finally,various methods would have to be explored for improving the time performance of targeted features, ifpossible without losing the configurability and flexibility of declarative feature files.AcknowledgementsI would like to thank the anonymous reviewers for their in-depth reading and many helpful suggestions.ReferencesAnne Abeille?, Lionel Cle?ment, and Franc?ois Toussenel.
2003.
Building a treebank for French.
In Anne Abeille?,editor, Treebanks.
Kluwer.Marie Candito, Joakim Nivre, Pascal Denis, and Enrique Henestroza Anguiano.
2010.
Benchmarking of statis-tical dependency parsers for french.
In Proceedings of the 23rd International Conference on ComputationalLinguistics: Posters, pages 108?116.
Association for Computational Linguistics.Deirdre Hogan.
2007.
Coordinate noun phrase disambiguation in a generative parsing model.
In Annual Meeting- Association for Computational Linguistics, volume 45, page 680.Angelina Ivanova, Stephan Oepen, and Lilja ?vrelid.
2013.
Survey on parsing three dependency representationsfor english.
ACL 2013, page 31.Sandra Ku?bler, Ryan McDonald, and Joakim Nivre.
2009.
Dependency parsing.
Morgan & Claypool Publishers.Sandra Ku?bler, Wolfgang Maier, Erhard Hinrichs, and Eva Klett.
2009.
Parsing coordinations.
In Proceedings ofthe 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 406?414.Association for Computational Linguistics.Wolfgang Maier and Sandra Ku?bler.
2013.
Are all commas equal?
detecting coordination in the penn treebank.In The Twelfth Workshop on Treebanks and Linguistic Theories (TLT12), page 121.37Wolfgang Maier, Erhard Hinrichs, Sandra Ku?bler, and Julia Krivanek.
2012.
Annotating coordination in thepenn treebank.
In Proceedings of the Sixth Linguistic Annotation Workshop, pages 166?174.
Association forComputational Linguistics.Ryan T McDonald and Joakim Nivre.
2007.
Characterizing the errors of data-driven dependency parsing models.In EMNLP-CoNLL, pages 122?131.Joakim Nivre.
2008.
Algorithms for deterministic incremental dependency parsing.
Computational Linguistics,34(4):513?553.Martin Popel, David Marecek, Jan S?tepa?nek, Daniel Zeman, and Zdene?k Z?abokrtsky`.
2013.
Coordination struc-tures in dependency treebanks.
In Proceedings of the 51st Annual Meeting of the Association for ComputationalLinguistics.E?ric Villemonte de la Clergerie.
2014.
Jouer avec des analyseurs syntaxiques.
In Actes de la 21e confe?rence surle Traitement Automatique des Langues Naturelles (TALN?2014), pages 67?78, Marseille, France.Roy Schwartz, Omri Abend, and Ari Rappoport.
2012.
Learnability-based syntactic annotation design.
In COL-ING, pages 2405?2422.Djame?
Seddah, Reut Tsarfaty, Sandra Ku?bler, Marie Candito, Jinho Choi, Richa?rd Farkas, Jennifer Foster, IakesGoenaga, Koldo Gojenola, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier,Joakim Nivre, Adam Przepiorkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, MarcinWolin?ski, Alina Wro?blewska, and Eric Villemonte de la Cle?rgerie.
2013.
Overview of the spmrl 2013 sharedtask: A cross-framework evaluation of parsing morphologically rich languages.
In Proceedings of the 4thWorkshop on Statistical Parsing of Morphologically Rich Languages: Shared Task, Seattle, WA.Masashi Shimbo and Kazuo Hara.
2007.
A discriminative learning model for coordinate conjunctions.
In EMNLP-CoNLL, pages 610?619.Reut Tsarfaty, Joakim Nivre, and Evelina Andersson.
2011.
Evaluating dependency parsing: robust and heuristics-free cross-nnotation evaluation.
In Proceedings of the Conference on Empirical Methods in Natural LanguageProcessing, pages 385?396.
Association for Computational Linguistics.Assaf Urieli and Ludovic Tanguy.
2013.
L?apport du faisceau dans l?analyse syntaxique en de?pendances par tran-sitions : e?tudes de cas avec l?analyseur Talismane.
In Actes de la 20e confe?rence sur le Traitement Automatiquedes Langues Naturelles (TALN?2013), pages 188?201, Les Sables d?Olonne, France.Assaf Urieli.
2013.
Robust French syntax analysis: reconciling statistical methods and linguistic knowledge inthe Talismane toolkit.
Ph.D. thesis, Universite?
de Toulouse II le Mirail.Assaf Urieli.
2014.
Ame?liorer l?e?tiquetage de ?que?
par les descripteurs cible?s et les re`gles.
In Actes de la21e confe?rence sur le Traitement Automatique des Langues Naturelles (TALN?2014), pages 56?66, Marseille,France.Yue Zhang and Joakim Nivre.
2011.
Transition-based dependency parsing with rich non-local features.
In ACL(Short Papers), pages 188?193.Yue Zhang and Joakim Nivre.
2012.
Analyzing the effect of global learning and beam-search on transition-baseddependency parsing.
In COLING (Posters), pages 1391?1400.38
