Efficient Collaborative Discourse: A Theory and Its ImplementationAlan W. Biermann, Curry I. Guinn, D. Richard Hipp, Ronnie W. SmithComputer Science DepartmentDuke UniversityDurham, NC 27706ABSTRACTAn architecture for voice dialogue machines i described with em-phasis on the problem solving and high level decision making mech-anisms.
The architecture provides facilities for generating voiceinteractions aimed at cooperative human-machine problem solving.It assumes that the dialogue will consist of a series of local self-consistent subdialogues ach aimed at subgoals related to the overalltask.
The discourse may consist of a set of such subdiaiogues withjumps from one subdialogue tothe other in a search for a success-ful conclusion.
The architecture maintains auser model to assurethat interactions properly account for the level of competence of theuser, and it includes an ability for the machine to take the initiativeor yield the initiative to the user.
It uses expectation from the di-alogue processor to aid in the correction of errors from the speechrecognizer.1.
Supporting the Voice TechnologiesDialogue theory is the implementing science for the voicetechnologies.
The many successes in voice recognition andgeneration will have value only to the extent hat they be-come incorporated into practical systems that deliver serviceto users.
This paper eports on a dialogue system design thatattempts o implement a variety of behaviors that we believe tobe necessary for efficient human-machine interaction.
Thesebehaviors include:1.
Collaborative problem-solving: The system must havethe ability for the machine to problem-solve and collab-orate with the human user in the process.
Specifically,the machine must be able to formulate queries to the userand process responses that will enable progress towardthe goal.2.
Subdialogue processing: It must be able to participate inlocally coherent subdialognes to solve subgoals and tojump in possibly unpredictable ways from subdialogue tosubdialogue in an aggressive s arch for the most effectivepath to success.
Such jumps may emanate from thesystem's own processing strategy or they may be initiatedby the user and tracked through plan recognition by thesystem.3.
User modeling: It needs to maintain a user model thatenables it to formulate queries appropriate to the user..and that will inhibit outputs that will not be helpful.Variable initiative: The machine must be able to take theinitiative and lead the interaction at places where it hasinformation implying that it can do this effectively.
Italso needs to be able to yield the initiative completely orin part at times when data is available indicating that itshould o so.
It needs to be able to negotiate with the userto either take or release the initiative when appropriate.The use of expectation: It needs to be able to use theexpectation implicit in the dialogue to support the voicerecognition stage in error correction.2.
A Dialogue System ArchitectureDespite the variety of the target behaviors and their seemingstructural disjoinmess, an architecture has been found thatsupports them all in a relatively uniform and natural way\[1, 2, 3, 4\].
The design is based on the model of a Prologprocessor but includes a variety of special capabilities to ad-dress the needs of this application.
This section will describethe fundamental theory of the system and the next sectionwill describe its performance in a series of tests with humansubjects.The basic operation of the architecture is illustrated in Fig-ure 1 where problem-solving is to achieve top level goal G.Prolog-style theorem proving proceeds in the usual way andff G can be proven from available information there will beno interaction with the user.
However, if information is notsufficient o allow completion of the proof, the system canattempt to provide "missing axioms" through interaction withthe user.
In the figure, this process is illustrated in the subtreeC where P has been proven from an existing assertion butQ is not known.
Then the system may be able to resort o avoice interaction with the user to discover Q.
Thus the archi-tecture organizes interactions with the user to directly supportthe theorem proving process.
This organization gives thedialogue the task-oriented coherent (\[5\]) organization that isneeded for effective cooperative problem-solving.
It providesthe intentional structure described by Grosz and Sidner\[6\].The example continues with the illustrated rule177G~ 0  B 0 unsolved goal ?
solved goalP ~Q~NN Missing axiom; interact with user.userknows(V) voieeinteraction(observe, V)I us~rknows(V)howtoobserve(V)Figure 1: The theorem proving tree associated with a voicedialogue.V :- userknows(V), voiceinteracfion(observe,V)which is also shown in Figure 1.
Specifically, it asserts thatif, according to the user model\[7, 8, 9, 10\], the user knowsV, then a voice interaction could be initiated to try to obtainthat information.
Our approach effectively enables V to unifywith any goal to enable the interaction.
This could yield anexchange between computer and user of the typeC: Is the switch on?U: Yes.But the situation might not be as simple as a single questionand answer.
It may be that the user does not know how toobserve Q but could be told.
This is illustrated by the rulesuserknows(V) :- howtoobserve(V)howtoobserve(V) : - .
.
.which could lead to a lengthy interaction involving locatingother objects, carrying out actions, and making other obser-vations.
Thus a series of voice interactions could ensue withthe goal of eventually observing Q.
The set of all interac-tions aimed at the completion of a given goal is defined bythis project o be a subdialogue.
Notice that the subdialogueaccounts at every step for the user's knowledge through in-vocation of the user modeling assertions.
The dialogue asksonly questions that the user model indicates are appropriateand explains concepts either extensively, briefly, or not at alldepending on the assertions contained in the model.
Subdia-logues by one name or another have been studied by a varietyof authors \[11, 12, 13, 14\].The system allows for the possibility of unpredictable jumpsfrom one subdialogue toanother.
In the above xample, theuser might be locally uncooperative and respond as follows:C: Is the switch up?U: B is true.Here we assume that B is an assertion related to anothersubgoal on the theorem proving tree as shown in Figure 1.
Theuser may initiate such a change in subdialogue in an attemptto pursue another path to the global goal.
Here the machinefirst must track the user's intention (in a process called "planrecognition" \[15, 16, 17, 18, 19\]) and then evaluate whether tofollow the move or not.
This decision is based upon the currentlevel of the initiative of the system as described below.
If thesystem follows the user's initiative, it will apply its internaltheorem proving system to the subgoal E and pursue voiceinteractions related to it.
If it rejects the user's indicated path,it will simply store the received fact and reaffirm its own path:C: Is the switch up?The system may also abandon a subdialogue for reasons of itsown.
For example, processing during the dialogue could yieldthe unexpected result hat the current path is no longer likelyto yield an efficient path to the global goal.
Then the systemcould abruptly drop a line of interactions and jump to a newsubgoal which is momentarily evaluated as more attractive.Efficient dialogue often requires regular changes of initia-tive depending on which participant currently has the keyinformation\[20, 21, 22, 23\].
When a subject is opened whereone participant is knowledgeable and the other is not, that par-ticipant should lead the interaction to its completion and theother should be supportive and respond cooperatively.
Ourproject implements four levels of initiative, directive, sugges-five, declarative, and passive.
These levels result in, respec-tively, uncompromising control on the part of the machine,control but only at a weaker level, the yielding of control tothe user but with a willingness to make assertions about heproblem-solving process, and quiet acceptance of the user'sinitiative.
The level of initiative sets the strength at which themachine will prefer its own best evaluated solution path whenit selects the subdialogue tobe followed.
The initiative levelalso adjusts the assertiveness of the spoken outputs and mayaffect he way inputs are processed.
(See \[1\]).Expectation at each point in a dialogue is derived from theproof tree and other dialogue information in a manner simi-lar to that explained by Young\[24\].
Concepts that would beappropriate in the context of the current local interaction are"unparsed" into expected syntactic inputs and voice recogni-tion is biased to receive one of these xpected inputs.
If therecognition phase fails to achieve a good match with a local178expectation, comparisons are made to nonlocal expectations atincreasing distances from the local context until an acceptablematch is found or an error message is reported.
Recognitionof a nonlocal expectation amounts to the discovery that theuser is following adifferent path; this is a process called "planrecognition" in the literature.
If the system is following theuser initiative at this point, it may shift its theorem provingefforts to that subtree and cooperate with the user.3.
The  Imp lementat ionThe major system developed by this project is known as "TheCircuit Fix-It Shoppe" \[1, 25\].
It is implemented with adomain modeller to guide the process of debugging an elec-tric circuit and to present appropriate subgoals for possibleexamination.
A complex dialogue controller overviews theprocessing of decisions related to which subgoal to select andlevel of initiative issues.The coding has been done primarily in Quintus Prolog on aSun 4 workstation.
The parser is coded in C and uses a nearestneighbor algorithm to find the best match between the errorprone recognition system output and the set of expected in-puts.
The speech recognizer isa Verbex 6000 user-dependentconnected speech recognizer running on an IBM PC, and thevocabulary is currently 125 words.
Users are required to be-gin each utterance with the word "verbie" and end with theword "over.
"The implemented domain processor is loaded with a modelof a particular experimental circuit hat was constructed on aRadio Shack 160-in-OneElectronic Project Kit.
The model iscomplete enough to do any problem of the circuit hat involvesmissing wires.
For example, if the system is asked to debugthe circuit with no wires at all, it will systematically discoverevery missing wire and ask the user to install it.Speech output is done by a DECtalk DTC01 text-to-speechconverter.4.
Experimental ResultsThe system was tested with human subjects olving missingwire problems.
Subjects were trained to use the system andgiven some guidance on acceptable sentence syntax.
Theywere required to register their pronunciation fall of the vo-cabulary words and they spoke 239 sentences to train therecognizer on coarticulation.
They were provided with a listof vocabulary words and charts on a poster board suggest-ing implemented syntax.
They were told not to address theexperimenter during the test but the experimenter had a setof eleven standard messages that he or she would give to thesubject under certain specified conditions.
These includedsuch things as "The system is ready for your next utterance"or "Please restrict your utterances toone sentence."
On twolater days, subjects were given up to ten problems per session,one session with the machine at the strongest initiative leveland one at a moderately passive level.A transcript of one such dialogue follows here.
This inter-action was in moderately passive mode so the system tendsto suggest rather than demand action.
The user inserted twomissing wires during the interaction and made two changes insubdialogue (marked as * *) that were each correctly trackedby the system.
The total time of the interaction was 160seconds.C: This is the circuit fix it shop.
How may I help you?U: RS 111 is not working.C: I am familiar with that circuit.C: The LED is supposed to be displaying alternately flashingone and seven.U: The LED is off.C: The power is on when the switch is up.U: The switch is up.C: The switch is connecting tothe battery when there is a wirebetween connector one one one and connector one two zero.U: LED is displaying one and seven.
**C: Is the one on the LED flashing?U: No.C: Is the seven on the LED flashing?U: No.C: There is supposed to be a wire between connector threezero and connector seven zero.U: RS l l l  is working.
**C: Glad to have been of assistance.
Good-bye.Eight subjects attempted 141 dialogues, 75 with the machinein mildly passive mode and 66 with it in directive mode.
Theaverage problem completion time in the two modes was 270.6seconds and 511.3 seconds respectively.
The longer sessionsin the directive mode were because the system required theuser to pedantically go through every step of a debuggingprocedure while in the more passive mode, the user couldoften jump to the correct subgoal and solve it quite quickly.The average number of utterances spoken per dialogue was10.7 and 27.6, respectively.
The experimenter needed to giveerror messages to the subject about one every six sentenceswith the machine in passive mode and one every eighteensentences in directive mode.
This indicates that with thegreater freedom allowed by the more passive mode, subjectstended to get into more difficulty using the system.
The exactsentence recognition rate by the Verbex machine in the twomodes was 44.3 and 53.1 percents, respectively.
These werecorrected to 75.3 and 85.0 respectively by the expectation-based nearest neighbor error correction system.5.
Current ResearchOur newest dialogue algorithm by Guinn\[3\] features a set ofreal numbers on the proof tree paths that are continuously179updated to reflect estimates of the nearness to a solution.The algorithm follows paths using a best first strategy, andit includes automatic mechanisms tochange mode, negotiateinitiatiw.~,, and other efficiency improving behaviors.
Thisalgorithm has not been incorporated into the voice interactivesystem and is instead being tested separately.This algorithm allows a more complicated interaction tooccurinvolving negotiation ff the machine and user differ on whoshould control the initiative.
Suppose the machine adamantlydemands its own path (Is the switch up?)
and the user isequally as uncompromising and demands information relatedto the E subgoal as shown in Figure 1.
With Guinn's trategythe system negotiates with the user to try to convince the userto follow its path.
Specifically, it presents the user with partof the proof tree leading to the goal to show the user howquickly the goal can be achieved.
For example, in the case ofFigure 1, it might assertC: If the switch is up, then since P is true, then Cwill be true; consequently G will be true.Alternatively, the user could present his or her own path to thegoal in a negotiation and conceivably convince the system tolower its evaluation of its own path.This newer theory of initiative bases subdialogne decisionson a real number and biases the number with an initiativeparameter which can take on any value between 0 and 1.
Inthis system, the level of initiative is defined over a continuousrange rather than a discrete set of initiative values.Tests on the newer diologne algorithm have been in machine-to-machine problem-solving sessions.
The methodology hasbeen to randomly distribute facts about a murder mystery be-tween the two participants and then observe the conversationsthat lead to a solution of the mystery.
The transmitted infor-mation between the participants is in the form of Prolog-stylepredicates since the machines gain nothing through a transla-tion to natural language.
Detailed results have been extremelyencouraging and will be given later.
For example, in one testinvolving 85 dialogues, the average number of interactions re-quired to solve the problems was 123 without he negotiationfeature described above and 103 with it.6.
Comparisons with Other Dialogue SystemsThe system that most resembles the one we describe here is theMINDS system of Young et al \[26\].
Their system maintainsand AND-OR tree much like our Prolog tree and engagesin dialogue similarly to try to achieve subgoals.
It similarlyuses expectations generated by subgoals and enhanced by au~rr model to predict incoming utterances for the purpose oferror correction.
The resulting system demonstrated dramaticimprovements.
For example, the effective perplexity in onetest was reduced from 242.4 to 18.3 using dialogue levelconstraints while word recognition accuracy was increasedfrom 82.1 percent to 97.0.
We employ Prolog-style rules forthe knowledge base and the associated proofs for directingthe goal-oriented behavior.
This leads to the "missing axiomtheory" we describe above and some rather simple methodsfor handling the user model, multiple subdialogues, variableinitiative, negotiation and a variety of other features.Another dialogue system, by Allen et al (\[27\]), uses a black-board architecture to store representations of sentence pro-cessing and dialogue structures.
Processing is done by aseries of subroutines that function at the syntactic, semantic,and dialogue levels.
This system models detailed interactionsbetween the sentence and dialogue levels that are beyondanything we attempt but does not support problem-solving,variable initiative and voice interactions a we do.A third interesting project has produced the TINA system\[28\].This system uses probabilistic networks to parse token se-quences provided by a speech recognition system, SUMMITby Zue et al \[29\].
The networks and their probabilities arecreated automatically from grammatical rules and text sam-pies input by the designer.
Their main utifity is to provideexpectation for error correction as we do in our system.
How-ever, their expectation is primarily syntax-based while oursuses structure from all levels, subdialogue (or focus-based),semantic and syntactic.
Their semantics i built directly intothe parse trees which is translated into SQL for access to adatabase.
Our system is task-oriented, emphasizes problem-solving, and employs auser model to assure ffectiveness ofthe interaction.References1.
R.W.
Smith, D.R.
Hipp and A.W.
Biermann.
A Dialog ControlAlgorithm and its Performance.
Proc.
of the Third Conf.
onApplied Natural Language Processing, Trento, Italy, 1992.2.
D.R.
Hipp.
A New Technique for Parsing Ill-formed Spo-ken Natural-language Dialog.
Ph.D. thesis.
Duke University,Durham, North Carolina.
1992.3.
C.I.
Guinn.
Ph.D. thesis.
Duke University.
Durham, NorthCarolina.
To appear.
1993.4.
R.W.
Smith.
A Computational Model of Expectation-DrivenMixed.Initiative Dialog Processing.
Ph.D. thesis, Duke Uni-versity, Durham, North Carolina, 1991.5.
J.R. Hobbs.
"Coherence and eoreferenee."
Cognitive Science3:67-90, 1979.6.
BJ.
Grosz and C.L.
Sidner.
Attentions, intentions, and thestructure of discourse.
ComputationalLinguistics, 12(3):175-204, 1986.7.
A. Kobsa and W. Wahlster, editors.
Special Issue on UserModeling.
MIT Press, Cambridge, Mass., September 1988.
Aspecial issue of Computational Linguistics.8.
R. Cohen and M. Jones.
Incorporating user models into ex-pert systems for educational diagnosis.
In A. Kobsa andW.
Wahlster, editors, User Models in Dialog Systems, pages313-333.
Springer-Verlag, New York, 1989.1809.
T.W.
Finin.
GUMS: A general user modeling shell.
InA.
Kobsa and W. Wahlster, editors, User Models in DialogSystems, pages 411-430.
Springer-Verlag, New York, 1989.10.
S. Carberry.
Modeling the user's plans and goals.
Computa-tional Linguistics, 14(3):23-37, 1988.11.
B.J.
Grosz.
Discourse analysis.
In D.E.
Walker, editor, Under.standing Spoken Language, pages 235-268.
North-Holland,New York, 1978.12.
C. Linde and J. Goguen.
Suructure of planning discourse.
J.SocialBiol.
Struet.
pages 1:219-251, 1978.13.
L. PolanyiandR.
Scha.
Ontherecursivestmctureofdiscourse.In Connectedness in Sentence, Discourse and Text, ed.
by K.Ehlich and H. van Riemsdijk.
Tilburg University.
pages 141-178, 1983.14.
R. Reichman.
Getting Computers to Talk Like You and Me.M1T Press, Cambridge, Mass., 1985.15.
J.E Allen.
Recognizing intentions fTom naturallanguage utter-ances.
In M. Brady and R.C.
Berwick, editors, ComputationalModels of Discourse, pages 107-166.
MIT Press, Cambridge,Mass., 1983.16.
H.A.
Kautz.
A formal theory of plan recognition and its im-plementation, in Reasoning about Plans, ed.
by J.F.
Allen,H.A.
Kantz, R.N.
Pelavin" and J.D.
Tenenberg.
San Mateo,California: Morgan Kaufmann" pages 69-125, 1991.17.
D.L Litman and J.F.
Allen.
A plan recognition model forsubdialogues inconversations.
Cognitive Science, 11(2):163-200, 1987.18.
M.E.
Pollack.
A model of plan inference that distinguishesbetween the beliefs of actors and observers.
In Proceedingsofthe 24th AnnuaI Meeting of the Association for ComputationalLinguistics, pages 207-214, 1986.19.
S. Carberty.
Plan Recognition i Natural Language Dialogue.MIT Press, Cambridge, Mass., 1990.20.
H. Kitano and C. Van Ess-Dykema.
Toward a plan-basedunderstanding model for mixed-initiative dialogues.
In Pro-ceedings of the 29th Annual Meeting of the Association forComputational Linguistics, pages 25-32,1991.21.
D.G.
Novick.
Control of Mixed-Initiative Discourse ThroughMeta-Locutionary Acts: A Computational Model.
PhD thesis,University of Oregon, 1988.22.
M. Walker and S Whittaker.
Mixed initiative in dialogue: Aninvestigation i to discourse segmentation.
In Proceedings ofthe 2 8th Annual Meeting of the Association for ComputationalLinguistics, pages 70--78, 1990.23.
S. Whittaker and P. Stenton.
Cues and control in expert-clientdialogues.
In Proceedings of the 2 6th Annual Meeting of the As-sociation for Computational Linguistics, pages 123-130,1988.24.
S.R.
Young.
Use of dialogue, pragmafics and semantics toenhance speech recognition.
Speech Communication, 9:551-564, 1990.25.
D.R.
Hipp and R.W.
Smith.
A Demonstration f the "Cir-cuit Fix-It Shoppe'.
Twelve minute video tape, Department ofComputer Science, Duke University, Durham, North Carolina.1991.26.
S.R.
Young, A.G. Hauptmann, W.H.
Ward, E.T.
Smith, andP.
Werner.
High level knowledge sources in usable speechrecognition systems.
Communications ofthe ACM, pages 183-194, February 1989.27.
J. Allen, S. Guez, L. HoebeL E. Hinkelman" K. Jackson, A. Ky-burg, and D. Traum.
The discourse system project.
TechnicalReport 317, University of Rochester, November 1989.28.
S. Seneff.
TINA: A Natural Language System for SpokenLanguageApplicafions.
ComputationalLinguistics, 18(1):61-86, 1992.29.
V. ZueJ.
Glass,M.
Philiips and S. Seneff.
The MIT SAUMMITspeech recognition system: a program report.
Proceedings,DARPA Speech and Natural Language Workshop, Philadelphia,pages 21-23, 1989.AcknowledgmentThis research was supported by National Science Foundationgrant number NSF-IRI-88-03802 and by Duke University.181
