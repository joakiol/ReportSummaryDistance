Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 681?692,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsUnsupervised Induction of Cross-lingual Semantic RelationsMike LewisSchool of InformaticsUniversity of EdinburghEdinburgh, EH8 9AB, UKmike.lewis@ed.ac.ukMark SteedmanSchool of InformaticsUniversity of EdinburghEdinburgh, EH8 9AB, UKsteedman@inf.ed.ac.ukAbstractCreating a language-independent meaningrepresentation would benefit many cross-lingual NLP tasks.
We introduce the first un-supervised approach to this problem, learn-ing clusters of semantically equivalent Englishand French relations between referring expres-sions, based on their named-entity argumentsin large monolingual corpora.
The clusterscan be used as language-independent semanticrelations, by mapping clustered expressionsin different languages onto the same relation.Our approach needs no parallel text for train-ing, but outperforms a baseline that uses ma-chine translation on a cross-lingual questionanswering task.
We also show how to use thesemantics to improve the accuracy of machinetranslation, by using it in a simple reranker.1 IntroductionIdentifying a language-independent semantics is amajor long term goal of computational linguistics,and is interesting both theoretically and for practicalapplications.
It assumes that semantically equiva-lent sentences in any language can be mapped ontoa common meaning representation.
Such a repre-sentation would be of great utility for tasks suchas translation, relation extraction, summarization,question answering, and information retrieval.
Re-gardless of whether it is even possible to create sucha semantics, we show that an incomplete version canbe useful for downstream tasks.Semantic machine translation aims to map asource language to a language-independent meaningrepresentation, and then generate the target languagetranslation from this.
It is hoped this would allevi-ate the difficulties of simpler models when translat-ing between languages with very different word or-dering and syntax (Vauquois, 1968).
Despite manyattempts to define interlingual representations (Mi-tamura et al 1991; Beale et al 1995; Banarescu etal., 2013), state-of-the-art machine translation stilluses phrase-based models (Koehn et al 2007).
Themajor obstacle to defining interlinguas has been de-vising a meaning representation that is language-independent, but capable of expressing the limitlessnumber of meanings that natural languages can ex-press (Dorr et al 2004).Our approach avoids this problem by utilizing themethods of distributional semantics.
Recent workhas shown that paraphrases of expressions can belearned by clustering those with similar arguments(Poon and Domingos, 2009; Yao et al 2011; Lewisand Steedman, 2013)?for example learning that Xwrote Y and X is the author of Y are equivalent ifthey appear in a corpus with similar (X, Y) argument-pairs such as {(Shakespeare, Macbeth), (Dickens,Oliver Twist)}.
We extend this to the multilingualcase, aiming to also map the French equivalents Xa e?crit Y and Y est un roman de X on to the samecluster as the English paraphrases.
Conceptually,we treat a foreign expression as a paraphrase of anEnglish expression.
The cluster identifier can beused as a predicate in a logical form, suggesting thatthe fundamental predicates of an interlingua can belearnt in an unsupervised manner via clustering.In this paper we focus on learning binary relationsbetween named entities.
This problem is much sim-pler than attempting complete interlingual semantic681interpretation, but the approach could be general-ized.
This class of expressions has proved extremelyuseful in the monolingual case, with direct applica-tions for question answering and relation extraction(Poon and Domingos, 2009; Mintz et al 2009), andwe demonstrate how to use them to improve ma-chine translation.
It is important to be able to ex-tract knowledge across languages, as many facts willnot be expressed in all languages?either due to less-complete encyclopedias being available in some lan-guages, or facts being most relevant to a single coun-try.In contrast to most previous work on machinetranslation and cross-lingual clustering, our methodrequires no parallel text (see Section 8 for discussionof some exceptions).
It instead exploits an alignmentbetween named-entities in different languages.
Thelimited size of parallel corpora is a significant bot-tleneck for machine translation (Resnik and Smith,2003), whereas our approach can be used on muchlarger monolingual corpora.
This means it is poten-tially useful for language-pairs where little paralleltext is available, for domain adaptation, or for semi-supervised approaches.2 Basic ApproachOur work builds on clustering-based approaches tomonolingual distributional semantics, aiming to cre-ate clusters of semantically equivalent predicates,based on their arguments in a corpus.
In each lan-guage, we first map each sentence in a large mono-lingual corpus onto a simple logical form, by ex-tracting binary predicates between named entities.Then, we cluster predicates both within and betweenlanguages into those with similar arguments.When parsing a new sentence, instead of usingthe monolingual predicate, we use the cluster identi-fier as a language-independent semantic relation, asshown in Figure 1.
The resulting logical form can beused for inference in question answering.Unlike traditional approaches to translation, thisdoes not require parallel text?but it does imposesome additional constraints on language resources.Our approach requires:?
A large amount of factual text, as we rely onthe same facts being expressed in different lan-guages.
We use Wikipedia, which contains ar-ticles in 250 languages, including 121 with atleast 10,000 articles.1 Other domains, such asNewswire, may also be effective.?
A method for extracting binary relations fromsentences.
This is straightforward from depen-dency parses, which are available for many lan-guages.
It is also possible without a parser,with some language-specific work (Fader et al2011).
We describe our approach in Section 3.?
A method for linking entities in the trainingdata to some canonical representation.
Mc-Namee et al(2011) report good results on thistask in 21 languages.
We describe our methodfor this in Section 4.1.3 Predicate ExtractionOur method relies on extracting binary predicatesbetween entities from sentences.
Various represen-tations have been suggested for binary predicates,such as Reverb patterns (Fader et al 2011), de-pendency paths (Lin and Pantel, 2001; Yao et al2011), and binarized predicate-argument relationsderived from a CCG-parse (Lewis and Steedman,2013).
Our approach is formalism-independent, andis compatible with any method of expressing binarypredicates.We choose the CCG-based parser of Lewis andSteedman (2013) for several reasons.
It out-puts a logical form derived automatically fromthe CCG-parse, containing predicates such as:writearg0,arg1(shakespeare,macbeth).
By using theclose relationship between the CCG syntax and se-mantics, it is able to generalize over many seman-tically equivalent syntactic constructions (such aspassives, conjunctions and relative clauses), mean-ing we can map both Shakespeare wrote Macbethand Macbeth was written by Shakespeare to thesame logical form.
Using a dependency-based rep-resentation, these would have different predicates,which would need to be clustered later.
CCG alsohas a well developed theory of operator semantics(Steedman, 2012), so is able to represent semanticoperators such as quantifiers, negation and tense?understanding these is crucial to high performanceon question answering or translation tasks.
As in1As of June 2013.682Shakespeare wrote MacbethShakespeare wrote MacbethNP (S\NP)/NP NP>S\NP<Swritearg0:PER,arg1:BOOK(william shakespeare,macbeth)relation43(william shakespeare, macbeth)Shakespeare a e?crit MacbethShakespearesubjamode?crit Macbethobje?criresub j:PER,ob j:BOOK(william shakespeare,macbeth)CCG ParseInitial Semantic AnalysisLookup predicatein clusteringDependency ParseInitial Semantic AnalysisFigure 1: Example showing how our system can map sentences in different languages to the same meaning represen-tation, assuming we have clustered the equivalent predicates writearg0:PER,arg1:BOOK and e?criresub j:PER,ob j:BOOK.Lewis and Steedman (2013), clusters derived fromthe output from the parser can be integrated into thelexicon, allowing us to build logical forms whichcapture both operator and lexical semantics.Accurate CCG syntactic parsers are currentlyonly available for English, whereas dependencytreebanks and parsers exist for many languages(Buchholz and Marsi, 2006).
Consequently, forFrench we use the dependency path representation,which captures the nodes and edges connecting twonamed entities in a dependency parse.
The extrac-tion of these paths is language-independent, anddoes not depend on the dependency grammar used,which means our approach could be adapted to newlanguages with minimal work.4 Entity Semantics4.1 Entity LinkingAs discussed, our approach assumes that semanti-cally similar predicates will have similar argumententities.
This requires us to be able to identify core-ferring entities across languages during training.
Inthe monolingual case, it suffices to represent entitiesby the string used in the sentence.
This is inadequatein the multilingual case, as many entities may be re-ferred to by different names in different languages?for example the United States translates as les E?tats-Unis in French and die Vereinigte Staaten in Ger-man.
This problem is worsened by the ambiguity ofnamed-entity strings?for example, in the context ofa sports article, United States may refer specificallyto a team, rather than a country.Recent work on multilingual named-entity link-ing (McNamee et al 2011) shows how to linknamed entities in multiple languages onto EnglishWikipedia articles, which can be used as uniqueidentifiers for entities.
This means that we couldgain the information we need from unrestrictedtext.
However, as we use Wikipedia itself forour training corpora, we can bootstrap entity infor-mation directly from its markup.
Wikipedia con-tains cross-language links, e.g.
between the UnitedStates articles in different languages, allowing usto determine the equivalence of entities in differ-683ent languages.
Wikipedia links also help us au-tomatically disambiguate entities to a given arti-cle.
For unlinked named-entity mentions, we per-form some simple heuristic co-reference?based onword-overlap with previously mentioned entities inthe document, whether the mention name is the ti-tle of a Wikipedia article, or whether the mentionname is a Freebase (Bollacker et al 2008) alias ofan entity.
We emphasise that this does not mean ourapproach is only applicable to the Wikipedia corpus.4.2 Entity TypingIt has become standard in clustering approaches todistributional semantics to assign types to predicatesbefore clustering, and only cluster predicates withthe same type (Schoenmackers et al 2010; Berantet al 2011; Yao et al 2012).
This is useful forresolving ambiguity?for example the phrase bornin may express a place-of-birth or date-of-birth rela-tion depending on whether its second argument hasa LOC or DAT type.
Ambiguous expressions maytranslate differently in other languages?for exam-ple, the two interpretations of was born in translatein French as est ne?
a` and est ne?
en respectively.
Thetype of a predicate is determined by the type of itsarguments, and predicates with different types aretreated as distinct.Lewis and Steedman (2013) induce an unsuper-vised model of entity types using Latent DirichletAllocation (Blei et al 2003), based on selectionalpreferences of verbs and argument-taking nouns.When applied cross-linguistically, we found thistechnique tended to create language-specific topics.Instead, we exploit the fact that many Wikipedia en-tities are linked to the Freebase database, which hasa detailed manually-built type-schema.
This meansfor a Wikipedia entity, we can look up its set of typesin Freebase.2 We use the simplified type-set of 112types created by Ling and Weld (2012).
Where en-tities have multiple types (for example, Shakespeareis both an author and a person), we create a separaterelation for each type.2Named entities not present in Freebase are ignored duringtraining.5 Relation ClusteringPredicates are clustered into those which are seman-tically equivalent, based on their argument-pairs ina corpus.
The initial semantic analysis is run overthe corpora, and for each predicate we build a vectorcontaining counts for each of its argument-pairs (wedivide these counts by the overall frequency of anargument-pair in the corpus, so that rarer argument-pairs are more significant).
These vectors are usedto compute similarity between predicates.First, we run the clustering algorithm on each lan-guage independently, and then we attempt to find analignment between the clusters.
Duc et al(2011)and Ta?ckstro?m et al(2012) use similar two-step ap-proaches.
Running the clustering on both languagessimultaneously was found to produce many clustersonly containing predicates from a single language.This appears to be because even if predicates in twodifferent languages are truth-conditionally equiva-lent, the language biases the sample of entity-pairsfound in a corpus.
For example, the French verbe?crire may contain more French author/book pairsthan the English equivalent write.
This differencecan make the verbs appear to represent differentpredicates to the clustering algorithm.
Our two-stepapproach also means that advances in monolingualclustering should directly lead to improved cross-lingual clusters.5.1 Monolingual ClusteringFollowing Lewis and Steedman (2013), we use theChinese Whispers algorithm (Biemann, 2006) formonolingual clustering?summarized in Algorithm1.
The algorithm is non-parametric, meaning thatthe number of relation clusters is induced from thedata, and highly scalable.
We create a separate graphfor each type of predicate in each language?forexample, predicates between types AUTHOR andBOOK in French (so only predicates with the sametype will be clustered).
We create one node per pred-icate in the graph, and edges represent the distribu-tional similarity between the predicates.The distributional similarity between a pair ofpredicates is calculated as the cosine-similarity oftheir argument pair vectors in the corpus.
Manymore sophisticated approaches to determining sim-ilarity have been proposed (Kotlerman et al 2010;684Weisman et al 2012), and future work should ex-plore these.
We prune nodes with less than 25 oc-currences, edges of weight less than 0.05, and a shortlist of stop predicates.
We find many of our Frenchdependency paths do not have a clear semantic inter-pretation, so add the requirement that dependencypaths contain at least one content word, contain atmost 5 edges, and that one of the dependencies con-nected to the root is subject, object or the Frenchpreposition de.Data: Set of predicates PResult: A cluster assignment rp for all p ?
P?p ?
P : rp??
unique cluster identifier;while not converged dorandomize order of Pfor p ?
P dorp??
argmaxr?p?
1r=rp?
sim(p, p?
)endendAlgorithm 1: Chinese Whispers algorithm, usedfor monolingual predicate clustering.
sim(p, p?)
isthe distributional similarity between p and p?, and1r=r?
is 1 iff r=r?
and 0 otherwise5.2 Cross-lingual Cluster AlignmentWe use a simple greedy procedure to find an align-ment between the monolingual clusters in differentlanguages.
First, the entity-pair vectors for eachpredicate in a relation cluster are merged.
Then,the cosine similarity between entity-pair vectors forclusters in different languages is calculated?webase this only on argument-pairs that occur in bothlanguages, to reduce the potential bias of some en-tities being more relevant to one language.
Clus-ters are then greedily aligned, in order of their sim-ilarity, as in Algorithm 2 (pruning similarities lessthan 0.01).
This means that clusters are aligned withtheir most similar foreign cluster.
We only attemptto align clusters with the same argument types.6 Cross Lingual Question AnsweringExperimentsWe evaluate our system on English and French, us-ing Wikipedia for corpora.
The English corpus isPOS-tagged and CCG-parsed with the C&C toolsData: Sets of monolingual relation clusters RL1and RL2Result: An alignment between the monolingualclusters AA??
{};while RL1 6= {}?RL2 6= {} do(r1,r2)??
argmax(r1,r2)?RL1?RL2sim(r1,r2);A??
A?{(r1,r2)};RL1??
RL1/{r1};RL2??
RL2/{r2};endAlgorithm 2: Cluster alignment algorithmEnglish FrenchX invades Y X envahit Yinvasion de Y par XX orbits Y X est un satellite de YX est une lune de YX is a skyscraper in Y X est un gratte-ciel de YX is a novel by Y X est un roman de YX joins Y X adhe`re a` YX is a member of Y X entre dans YX rejoint YTable 1: Some example cross-lingual clusters.
Predicatesare given in a human-readable form, and predicate typesare suppressed.
(Clark and Curran, 2004).
The French corpus istagged with MElt (Denis et al 2009) and parsedwith MaltParser (Nivre et al 2007), trained on theFrench Treebank (Candito et al 2010).
Wikipediamarkup is filtered using Wikiprep (Gabrilovich andMarkovitch, 2007)?replacing internal links withthe name of their target article, to help entity link-ing.
Some example clusters learnt by our model areshown in Table 1.
We find that the cross-lingualclusters typically contain more French expressionsthan English, possibly due to the differing sizes ofthe corpora?adjusting the parameters in Section 5results in larger clusters, but introduces noise.6.1 Experimental SetupWe evaluate our system on a cross-lingual questionanswering task, similar to monolingual QA evalua-tions by Poon and Domingos (2009) and Lewis and685Steedman (2013).
A question is asked in languageL, and is answered by the system from a corpus oflanguage L?.
Human annotators are shown the ques-tion, answer entity, and the sentence that providedthe answer, and are then asked whether the answeris a reasonable conclusion based on the sentence.Whilst this task is much easier than full translation,it is both a practical application for our approach,and a reasonably direct extrinsic evaluation for ourcross-lingual clusters.Following Poon and Domingos (2009) and Lewisand Steedman (2013), the question dataset is auto-matically generated from the corpus.
This approachhas the advantage of evaluating on expressions inproportion to their corpus frequency, so understand-ing frequent expressions is more important than rareones.
We then sample 1000 questions for each lan-guage, by extracting binary relations matching cer-tain patterns (Xnsub j?
verbdob j?
Y, Xnsub j?
verbpob j?
Y orXnsub j?
bedob j?
nounpob j?
Y), and removing one of thearguments.
For example, from the sentence Obamalives in Washington we create the questions X livesin Washington?, and Obama lives in X?.3 Answersare judged by fluent bilingual humans, and do nothave to match the entity that originally instantiatedX.
Multiple answers can be returned for the samequestion.Our system attempts this task by mapping boththe question and candidate answer sentences (whichwill be in a different language to the question) onto a logical form using the clusters, and determin-ing whether they express the same relation.
Thistests the ability of our approach to cluster expres-sions into those which are semantically equivalentbetween languages.
It is possible for entities to havemultiple types (see Section 4.2), and answers areranked by the number of types in which the entail-ment relation is predicted to hold.3Questions are given in a declarative form, to make the taskssimpler for the machine translation baseline.
We found themachine translation performed poorly on questions such asWhat is Obama the president of?, as inverted word-orders andlong-range dependencies are difficult to handle with re-orderingmodels and language models (though are straightforward tohandle for a CCG system (Clark et al 2004)).
We find thatmachine translation performs much better on declarative equiv-alents, such as: Obama is the president of X.6.2 BaselineOur baseline makes use of the Moses machine trans-lation system (Koehn et al 2007), and is similarto previous approaches to cross-lingual question an-swering such as Ahn et al(2004).
We train a Mosesmodel on the Europarl corpus (Koehn, 2005).
First,the question is translated from language L to L?,taking the 50-best translations.
As the questionsare typically shorter than corpus sentences, this issubstantially easier for the machine-translation thantranslating the corpus.
These are then parsed, andpatterns are extracted (as in Section 3).
We alsomanually supply a translation of the named-entityin the question (based on the Freebase entity nametranslation), to avoid penalizing the translation sys-tem for failing to translate named-entities that havenot been seen in its training data.
These patternsare then used to find answers to the questions.
An-swers are ranked by the score of the best translationthat produced the pattern.
Figure 2 illustrates thispipeline.The choice of languages is very favourable tothe machine-translation system, English and Frenchhave similar word-order, and there is a large amountof parallel text available (Koehn and Monz, 2006).Our system works with any word-order, and does notrequire parallel text for training, so we would expectbetter performance relative to machine-translationon other language pairs.
Future work will experi-ment with more diverse languages.
The sentences tobe translated are also very short, reducing the poten-tial for error.6.3 ResultsResults are shown in Table 3, based on a sampleof 100 answers from the output of each of the sys-tems.
Unsurprisingly, the machine-translation hashigh accuracy on this task, given the choice of lan-guages and the short queries.
Pleasingly, our clustersachieve similar accuracy, with much greater recall,with no usage of parallel text.Examining the results, we see that the distribu-tion of answers is highly skewed for all systems,with many answers to a smaller number of ques-tions (multiple answers can be returned to the samequestion).
This is due to the Zipfian nature of lan-guage, the difficulty of the task (which is far from686Question AnswerX dies in Moscow Sergue??
Guerassimov meurt d?une crise cardiaque le mardi26 novembre 1985 a` MoscouGermany invades X .
.
.
depuis l?invasion de la Pologne par l?Allemagne et l?URSSX wins the FA Cup Portsmouth FC remporte la FA Challenge Cup en s?imposant enfinale face a` Wolverhampton Wanderers FCX is a band from Finland Yearning est un groupe Finlande de doom metal atmosphe?riqueX vit en France Dewi Sukarno .
.
.
has lived in different countries includingSwitzerland, France and the United StatesX bat Kurt Angle Anderson defeated Kurt Angle and Abyss to advance to the finalsX est une ville de Kirghizistan Il?chibay is a village in the Issyk Kul Province of KyrgyzstanTable 2: Example questions correctly answered using our clusters, with the answer entity highlighted in bold.Obama lives in XObama habite a` XObamasubjhabiteprepa`pobjXhabitesub j,a`(barack obama, X)Machine TranslationSyntactic ParseSemantic AnalysisFigure 2: Pipeline used by baseline system for answeringFrench questions.
The pattern extracted from the trans-lated sentence is used to search for answers in an Englishcorpus.English?
French Answers CorrectBaseline 269 86%Clusters (best 270) 270 100%Clusters (all) 1032 72%French?
English Answers CorrectBaseline 274 85%Clusters (all) 401 93%Table 3: Results on wide-coverage Question Answer-ing task.
Best-N results are shown to illustrate the ac-curacy of our cluster-based system at the same rank asthe baseline.
It is not possible to give a recall figure, asthe total number of correct answers in the corpus is un-known.
English?
French results are from the full FrenchWikipedia corpus, whereas French?
English results arefrom a 10% sample.solved in the monolingual case), and the possibil-ity that questions may have no answers in the for-eign corpus.
This is particuarly true for the cluster-ing approach?although the clustering system findsmore answers with the English corpus, the baselinesystem answers slightly more unique questions (57vs 66).
The 1032 answers found by the clustersin the French corpus came from just 56 questions(compared to 29 unique questions answered by thebaseline).
This suggests that the translations foundby the clustering can be more useful than those ofMoses on this task?for example, it may find anequivalence between a rare French term and a com-mon related English term, where machine transla-tion may only find a more literal translation.Despite this, we see the clusters have learnt to687paraphrase a variety of relations between languageswith high accuracy, suggesting that there is muchpotential for the use of unsupervised clusters incross-lingual semantic applications.
Some examplesanswers are given in Table 2.
Most of the errors arecaused by a small number of questions.7 Translation Reranking ExperimentsUltimately, we would like to be able to translateusing semantic parsing with cross-lingual clusters.As a step towards this, we investigated whether wecould rerank the output of a machine translation sys-tem, on the basis of whether the semantic parse ofthe source sentence is consistent with that of candi-date translations.We sample French sentences where we can pro-duce a semantic parse (i.e.
we can extract a predicatebetween named entities that maps to a cross-lingualcluster).
These sentences are translated to Englishusing Moses, taking the 50-best list, and semanticparses are produced for each of these.
If the seman-tic parse for the 1-best translation does not match thesource semantic parse, we take the parse from the50-best list that most closely matches it?otherwisewe discard the sentence from our evaluation, as oursemantics agrees with the machine-translation.To ensure that the evaluation focuses on the clus-ters, we try to exclude several other factors thatmight affect the results.
The coverage of our CCGparsing and semantic analysis drops significantly onnoisy translated sentences, and potentially acts as alanguage model by failing to produce any semanticparse on ungrammatical output sentences.
We there-fore only consider sentences where we can producea semantic parse for the 1-best machine translationoutput.
We also try to avoid penalizing the machine-translation system for failing to translate named en-tities correctly, so we do not attempt to rerank sen-tences where the entities from the source sentenceare not present in the 1-best translation.Human annotators were shown the source sen-tence, the 1-best translation, and the translation cho-sen by the reranker (the translations were shown ina random order).
To focus the evaluation on the se-mantic relations we are modelling, we ask the anno-tators which sentence best preserves the meaning be-tween the named entities that have different relationsPercentage oftranslations preferred1-best Moses translation 5%Cluster-based Reranker 39%No preference 56%Table 5: Human preference judgements for the transla-tion reranking experiment, based on a sample of 87 sen-tences.
Results show the percentage of sentences forwhich the annotators preferred the original translation,the reranked translation, or neither.
As discussed in thetext, results where annotators had no preference were typ-ically due to syntactic parse errors.in the semantic parse.
This avoids our system beingpenalized for choosing a translation that is worse inaspects other than the relations it is modelling.
Anexample is shown in Table 4.
The data was anno-tated jointly by two fluent bilingual speakers, whoreported high agreement on this task.Results are shown in Table 5, and are highly en-couraging, with the original Moses output being pre-ferred to the reranked translation in only 5% of caseswhere our model makes a positive prediction.Inspecting the results, we see that many of thecases where the annotators had no preference werecaused by syntactic parse errors.
For example, ifthe 1-best translation is correct, but a prepositionalphrase is incorrectly attached, it will appear to havean incorrect semantics.
A similar translation in the50-best list may be correctly parsed, and conse-quently selected by our reranker.
However, a humanwill have no preference between these translations.Incorporating K-Best parsing into our pipeline mayhelp mitigate against such cases.This preliminary experiment suggests that there ispotential for future improvements in machine trans-lation using cross-lingual distributional semantics.The system only attempts to rerank a very smallproportion of sentences, but we believe the cover-age could be greatly improved by including relationsbetween common nouns (rather than just named-entities)?future work should explore this.8 Related WorkOur work builds on recent progress in monolingualdistributional semantics (Poon and Domingos, 2009;Yao et al 2011; Lewis and Steedman, 2013) by688Source Le Princess Elizabeth arrive a` Dunkerque le 3 aou?t 1999Machine translation 1-best Le Princess Elizabeth is to manage to Dunkirk on 3 August 1999Reranked translation The Princess Elizabeth arrives at Dunkirk on 3 August 1999Table 4: Example sentence that is reranked by our clusters.
Human evaluators were asked which translation bestpreserved the meaning between Princess Elizabeth and Dunkirk.clustering typed predicates into those which are se-mantically equivalent.
We also show how to boot-strap semantic information about entities from theWikipedia markup, and believe this makes it an in-teresting corpus for future work on monolingual dis-tributional semantics.Cross-language Latent Relational Analysis (Ducet al 2011) is perhaps the most similar previouswork to ours, which moves the work of Turney(2005) into a multilingual setting.
Duc et al(2011)aim to compute, for example, that the ?latent rela-tion?
between (Obama, US) in an English corpus issimilar to that between (Cameron, UK) in a foreigncorpus.
This is solved by finding all textual patternsbetween the two entity-pairs, and computing theiroverall similarity.
Like us, they compute similaritybetween expressions in different languages based onnamed-entity arguments and clustering (unlike us,they also rely on machine translation for comput-ing similarity).
A key difference is that their sys-tem aims to understand the overall relation betweenan entity-pair based on many observations, whereasour approach attempts to understand each sentenceindividually (as is required for tasks such as transla-tion).Various recent papers have explored the rela-tionship between translation and monolingual para-phrases ?for example Bannard and Callison-Burch(2005) create paraphrases by pivoting through a for-eign translation, and Callison-Burch et al(2006)show that including monolingual paraphrases im-proves the quality of translation by reducing spar-sity.
The success of these approaches depends on themany-to-many relationship between equivalent ex-pressions in different languages.
Our approach aimsto model this relationship explicitly by clustering allequivalent paraphrases in different languages.Current state-of-the-art machine translation sys-tems circumvent the problem of full semantic in-terpretation, by using phrase-based models learntfrom large parallel corpora (Brown et al 1993).
Al-though this approach has been very successful, it hassignificant limitations?for example, when translat-ing between languages with very different word-orders (Birch et al 2009), or with little parallel text.Semantic machine translation aims to map thesource language to an interlingual semantic rep-resentation, and then generate the target languagesentence from this.
Jones et al(2012) show howthis can be done on a small dataset using hyper-edge replacement grammars.
A major obstacle tothis is designing a suitable meaning representation,which involves choosing a set of primitive conceptswhich are abstract enough to be capable of express-ing meaning in any language (Dorr et al 2004).A recent proposal for this is the Abstract MeaningRepresentation (Banarescu et al 2013), which usesEnglish verbs as a set of predicates.
This is a less ab-stract form of semantic interpretation than our pro-posal, as semantically equivalent paraphrases maybe given a different representation.
Such an ap-proach also relies on annotating large amounts oftext with the semantic representation?whereas ourunsupervised approach offers a way to build such aninterlingua using only a method for extracting pred-icates from sentences.Whilst almost all recent work on machine-translation has relied on parallel text, there havebeen several interesting approaches that do not.Rapp (1999) learns to translate words based on smallseed bilingual dictionary.
Klementiev et al(2012a)exploit a variety of interesting indirect sources ofinformation to learn a lexicon?for example as-suming that equivalent Wikipedia articles in differ-ent languages will use semantically similar words.The Polylingual Topic Model (Mimno et al 2009)makes use of similar intuitions.
Whilst we exploitequivalent Wikipedia articles for entity linking, wedo not require aligned articles.
Incorporating suchtechniques into our model would be a natural next689step, allowing us to learn a more complete lexicon.To our knowledge, ours is the first approach to learnto translate semantic relations, rather than words andphrases.Several other recent papers have learnt cross-lingual word clusters, and used these to improvecross-lingual tasks such as document-classification(Klementiev et al 2012b), parsing (Ta?ckstro?m etal., 2012) and semantic role labelling (Kozhevnikovand Titov, 2013) in resource-poor languages.
Cross-lingual word clusters are learnt by aligning mono-lingual clusters on the basis of parallel text?inlanguage-pairs where parallel text is available, thisoffers an interesting complement to our method ofclustering based on named entities.9 Conclusions and Future WorkWe have demonstated that our previous work onmonolingual distributional semantics can simply beextended to learn a language-independent semanticsof relations from unlabelled text, and that this se-mantics is powerful enough to aid applications suchas question answering and translation reranking.There is much potential for future extensions toaddress the limitations of the process described here.As we use a flat clustering of relations, we areonly able to model synonyms and not hypernyms.More sophisticated clustering techniques, such asthose used by Berant et al(2011), seem to offera way to address this.
Our system clusters rela-tions with similar named-entity arguments, but thismeans it does not cluster relations whose argumentsare rarely named entities.
However, using cross-lingual clusters of common nouns, such as thosefrom Ta?ckstro?m et al(2012), it should be possible tocluster relations that take semantically similar com-mon noun arguments.
Embedding cluster-identifiersin a logical form allows us to also model logical op-erators, such as negation and quantifiers, which mayhelp to improve the translation of these.
It wouldalso be interesting to experiment with more diverselanguages types.AcknowledgementsWe thank the anonymous reviewers for their helpfulcomments, and Eva Hasler for help training Moses.This work was funded by ERC Advanced Fellow-ship 249520 GRAMPLUS and IP EC-FP7-270273Xperience.ReferencesKisuh Ahn, Beatrix Alex, Johan Bos, Tiphaine Dalmas,Jochen L Leidner, and Matthew B Smillie.
2004.Cross-lingual question answering with QED.
In Work-ing Notes, CLEF Cross-Language Evaluation Forum,pages 335?342.Laura Banarescu, Claire Bonial, Shu Cai, MadalinaGeorgescu, Kira Griffitt, Ulf Hermjakob, KevinKnight, Philipp Koehn, Martha Palmer, and NathanSchneider.
2013.
Abstract Meaning Representationfor sembanking.
In Proceedings of the 7th LinguisticAnnotation Workshop and Interoperability with Dis-course, Sofia, Bulgaria, August.
Association for Com-putational Linguistics.Colin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In Proceed-ings of the 43rd Annual Meeting of the Association forComputational Linguistics (ACL?05), pages 597?604,Ann Arbor, Michigan, June.
Association for Compu-tational Linguistics.Stephen Beale, Sergei Nirenburg, and Kavi Mahesh.1995.
Semantic analysis in the Mikrokosmos machinetranslation project.
In Proceedings of the 2nd Sym-posium on Natural Language Processing, pages 297?307.Jonathan Berant, Ido Dagan, and Jacob Goldberger.2011.
Global learning of typed entailment rules.
InProceedings of the 49th Annual Meeting of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies - Volume 1, HLT ?11, pages 610?619.
Association for Computational Linguistics.C.
Biemann.
2006.
Chinese whispers: an efficient graphclustering algorithm and its application to natural lan-guage processing problems.
In Proceedings of theFirst Workshop on Graph Based Methods for NaturalLanguage Processing, pages 73?80.
Association forComputational Linguistics.Alexandra Birch, Phil Blunsom, and Miles Osborne.2009.
A Quantitative Analysis of Reordering Phenom-ena.
In Proceedings of the Fourth Workshop on Sta-tistical Machine Translation, pages 197?205, Athens,Greece, March.
Association for Computational Lin-guistics.D.M.
Blei, A.Y.
Ng, and M.I.
Jordan.
2003.
Latentdirichlet alcation.
the Journal of machine Learningresearch, 3:993?1022.Kurt Bollacker, Colin Evans, Praveen Paritosh, TimSturge, and Jamie Taylor.
2008.
Freebase: a col-laboratively created graph database for structuring hu-690man knowledge.
In Proceedings of the 2008 ACMSIGMOD international conference on Management ofdata, SIGMOD ?08, pages 1247?1250, New York, NY,USA.
ACM.Peter F. Brown, Vincent J. Della Pietra, Stephen A. DellaPietra, and Robert L. Mercer.
1993.
The mathemat-ics of statistical machine translation: parameter esti-mation.
Comput.
Linguist., 19(2):263?311, June.Sabine Buchholz and Erwin Marsi.
2006.
Conll-x sharedtask on multilingual dependency parsing.
In Proceed-ings of the Tenth Conference on Computational Nat-ural Language Learning, pages 149?164.
Associationfor Computational Linguistics.Chris Callison-Burch, Philipp Koehn, and Miles Os-borne.
2006.
Improved statistical machine transla-tion using paraphrases.
In Proceedings of the HumanLanguage Technology Conference of the NAACL, MainConference, pages 17?24, New York City, USA, June.Association for Computational Linguistics.Marie Candito, Beno?
?t Crabbe?, Pascal Denis, et al2010.Statistical french dependency parsing: treebank con-version and first results.
In Proceedings of the SeventhInternational Conference on Language Resources andEvaluation (LREC 2010), pages 1840?1847.Stephen Clark and James R. Curran.
2004.
Parsing theWSJ using CCG and log-linear models.
In Proceed-ings of the 42nd Annual Meeting on Association forComputational Linguistics, ACL ?04.
Association forComputational Linguistics.S.
Clark, M. Steedman, and J.R. Curran.
2004.
Object-extraction and question-parsing using CCG.
In Pro-ceedings of the EMNLP Conference, pages 111?118.Pascal Denis, Beno?
?t Sagot, et al2009.
Coupling anannotated corpus and a morphosyntactic lexicon forstate-of-the-art pos tagging with less human effort.
InPACLIC, pages 110?119.Bonnie J Dorr, Eduard H Hovy, and Lori S Levin.
2004.Machine translation: Interlingual methods.Nguyen Tuan Duc, Danushka Bollegala, and MitsuruIshizuka.
2011.
Cross-language latent relationalsearch: Mapping knowledge across languages.
Asso-ciation for the Advancement of Artificial Intelligence,pages 1237?1242.Anthony Fader, Stephen Soderland, and Oren Etzioni.2011.
Identifying relations for open informationextraction.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing,EMNLP ?11, pages 1535?1545.
Association for Com-putational Linguistics.Evgeniy Gabrilovich and Shaul Markovitch.
2007.
Com-puting semantic relatedness using wikipedia-based ex-plicit semantic analysis.
In IJCAI, volume 7, pages1606?1611.Bevan Jones, Jacob Andreas, Daniel Bauer, Karl MoritzHermann, and Kevin Knight.
2012.
Semantics-based machine translation with hyperedge replacementgrammars.
Proc.
COLING, 2012.Alexandre Klementiev, Ann Irvine, Chris Callison-Burch, and David Yarowsky.
2012a.
Toward statis-tical machine translation without parallel corpora.
InProceedings of the 13th Conference of the EuropeanChapter of the Association for Computational Linguis-tics, EACL ?12, pages 130?140.
Association for Com-putational Linguistics.Alexandre Klementiev, Ivan Titov, and Binod Bhattarai.2012b.
Inducing crosslingual distributed representa-tions of words.
In Proceedings of the InternationalConference on Computational Linguistics (COLING),Bombay, India, December.Philipp Koehn and Christof Monz.
2006.
Manual and au-tomatic evaluation of machine translation between Eu-ropean languages.
In Proceedings on the Workshop onStatistical Machine Translation, pages 102?121, NewYork City, June.
Association for Computational Lin-guistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondr?ej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: open sourcetoolkit for statistical machine translation.
In Proceed-ings of the 45th Annual Meeting of the ACL on Inter-active Poster and Demonstration Sessions, ACL ?07,pages 177?180.
Association for Computational Lin-guistics.Philipp Koehn.
2005.
Europarl: A parallel corpus for sta-tistical machine translation.
In MT summit, volume 5.Lili Kotlerman, Ido Dagan, Idan Szpektor, and MaayanZhitomirsky-geffet.
2010.
Directional distributionalsimilarity for lexical inference.
Nat.
Lang.
Eng.,16(4):359?389, October.Mikhail Kozhevnikov and Ivan Titov.
2013.
Crosslin-gual transfer of semantic role models.
In To Appear inProceedings of the 51th Annual Meeting of the Asso-ciation for Computational Linguistics, Sofia, Bulgaria,August.
Association for Computational Linguistics.Mike Lewis and Mark Steedman.
2013.
Combined Dis-tributional and Logical Semantics.
Transactions ofthe Association for Computational Linguistics, 1:179?192.Dekang Lin and Patrick Pantel.
2001.
DIRT - Discoveryof Inference Rules from Text.
In In Proceedings of theACM SIGKDD Conference on Knowledge Discoveryand Data Mining, pages 323?328.Xiao Ling and Daniel S Weld.
2012.
Fine-grained entityrecognition.
In Proceedings of the 26th Conference onArtificial Intelligence (AAAI).691Paul McNamee, James Mayfield, Dawn Lawrie, Dou-glas W Oard, and David Doermann.
2011.
Cross-language entity linking.
Proc.
IJCNLP2011.David Mimno, Hanna M Wallach, Jason Naradowsky,David A Smith, and Andrew McCallum.
2009.Polylingual topic models.
In Proceedings of the 2009Conference on Empirical Methods in Natural Lan-guage Processing: Volume 2-Volume 2, pages 880?889.
Association for Computational Linguistics.M.
Mintz, S. Bills, R. Snow, and D. Jurafsky.
2009.
Dis-tant supervision for relation extraction without labeleddata.
In Proceedings of the Joint Conference of the47th Annual Meeting of the ACL and the 4th Interna-tional Joint Conference on Natural Language Process-ing of the AFNLP: Volume 2-Volume 2, pages 1003?1011.
Association for Computational Linguistics.Teruko Mitamura, Eric H Nyberg, and Jaime G Car-bonell.
1991.
An efficient interlingua translation sys-tem for multi-lingual document production.Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev,Gu?lsen Eryigit, Sandra Ku?bler, Svetoslav Marinov,and Erwin Marsi.
2007.
Maltparser: A language-independent system for data-driven dependency pars-ing.
Natural Language Engineering, 13(2):95?135.Hoifung Poon and Pedro Domingos.
2009.
Unsuper-vised semantic parsing.
In Proceedings of the 2009Conference on Empirical Methods in Natural Lan-guage Processing: Volume 1 - Volume 1, EMNLP ?09,pages 1?10.
Association for Computational Linguis-tics.Reinhard Rapp.
1999.
Automatic identification of wordtranslations from unrelated english and german cor-pora.
In Proceedings of the 37th annual meeting of theAssociation for Computational Linguistics on Compu-tational Linguistics, ACL ?99, pages 519?526.
Asso-ciation for Computational Linguistics.Philip Resnik and Noah A Smith.
2003.
The webas a parallel corpus.
Computational Linguistics,29(3):349?380.Stefan Schoenmackers, Oren Etzioni, Daniel S. Weld,and Jesse Davis.
2010.
Learning first-order hornclauses from web text.
In Proceedings of the 2010Conference on Empirical Methods in Natural Lan-guage Processing, EMNLP ?10, pages 1088?1098.Association for Computational Linguistics.Mark Steedman.
2012.
Taking Scope: The Natural Se-mantics of Quantifiers.
MIT Press.Oscar Ta?ckstro?m, Ryan McDonald, and Jakob Uszkoreit.2012.
Cross-lingual word clusters for direct transfer oflinguistic structure.
In Proceedings of the 2012 Con-ference of the North American Chapter of the Associa-tion for Computational Linguistics: Human LanguageTechnologies, NAACL HLT ?12, pages 477?487.
As-sociation for Computational Linguistics.Peter D. Turney.
2005.
Measuring semantic similarityby latent relational analysis.
In Proceedings of the19th international joint conference on Artificial intel-ligence, IJCAI?05, pages 1136?1141, San Francisco,CA, USA.
Morgan Kaufmann Publishers Inc.Bernard Vauquois.
1968.
A survey of formal grammarsand algorithms for recognition and transformation inmachine translation.
In IFIP Congress, volume 68,pages 254?260.Hila Weisman, Jonathan Berant, Idan Szpektor, andIdo Dagan.
2012.
Learning verb inference rulesfrom linguistically-motivated evidence.
In Proceed-ings of the 2012 Joint Conference on Empirical Meth-ods in Natural Language Processing and Computa-tional Natural Language Learning, EMNLP-CoNLL?12, pages 194?204.
Association for ComputationalLinguistics.Limin Yao, Aria Haghighi, Sebastian Riedel, and AndrewMcCallum.
2011.
Structured relation discovery usinggenerative models.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing, EMNLP ?11, pages 1456?1466.
Association forComputational Linguistics.Limin Yao, Sebastian Riedel, and Andrew McCallum.2012.
Unsupervised relation discovery with sense dis-ambiguation.
In ACL (1), pages 712?720.692
