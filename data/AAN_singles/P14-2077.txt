Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 470?475,Baltimore, Maryland, USA, June 23-25 2014. c?2014 Association for Computational LinguisticsIdentifying Real-Life Complex Task Names with Task-Intrinsic Enti-ties from MicroblogsTing-Xuan Wang* and Kun-Yu Tsai and Wen-Hsiang LuNational Cheng Kung UniversityTainan, Taiwan{P78981320,P76014460,whlu}@mail.ncku.edu.twAbstractRecently, users who search on the web aretargeting to more complex tasks due to theexplosive growth of web usage.
To accom-plish a complex task, users may need to ob-tain information of various entities.
For ex-ample, a user who wants to travel to Beijing,should book a flight, reserve a hotel room,and survey a Beijing map.
A complex taskthus needs to submit several queries in orderto seeking each of entities.
Understandingcomplex tasks can allow a search engine tosuggest related entities and help users explic-itly assign their ongoing tasks.1 IntroductionThe requirement of searching for complex tasksdramatically increases in current web search.Users not always search for single informationneed (Liao et al, 2012).
To accomplish a real-life complex task, users usually need to obtainvarious information of distinct entities on theweb.
In this paper, we define the necessary enti-ties for a complex task as task-intrinsic entities.For example, a complex task ?travel to Beijing?has at least three task-intrinsic entities, includinga flight ticket, hotel room, and maps.
Therefore,users need submit several queries in order to seekall of the necessary entities.
However, conven-tional search engines are careless of latent com-plex tasks behind a search query.
Users are guid-ed to search for each task-intrinsic entity one byone to accomplish their complex task inefficient-ly.Figure 1 shows a complex task consisting of atask name ?travel to Beijing?
and several task-intrinsic entities.
A task name is composed of atask event and a task topic.
The task event trig-gers users to perform exploratory or comparativesearch behaviors such as ?prepareFigure 1.
The structure of a complex task withtask-intrinsic entities and related queries.something?, ?buy something?
or ?travel tosomewhere?.
The task topic is the subject of in-terest in the complex task.
Task-intrinsic entitiesare intrinsically demanded by the complex task.The three queries ?Beijing flight ticket?, ?Beijinghotel?, and ?Beijing map?
are driven by the in-formation need of each of task-intrinsic entitieswith topic ?Beijing?
and event ?travel?
for thehidden complex task ?travel to Beijing?.According to our observation, users may de-scribe details of a complex task to be done oralready completed via microblogs, e.g., Twitteror Weibo1.
Microblogs are a miniature version oftraditional weblogs.
In recent years, many userspost and share their life details with others onmicroblogs every day.
Due to the post lengthlimitation (only 140 characters in case of Weibo),users tend to only describe key points.
Table 1shows an example of a microblog.
We can findthat the user, who has an ongoing complex task?????
(travel to Beijing)?, mentioned twotask-intrinsic entities ???
(flight ticket)?
and???
(hotel)?.In this work, we address the problem of how tohelp users efficiently accomplish a complex taskwhen submitting a single query or multiple que-ries.1 Weibo: http://weibo.com470Chinese?????????????????????????????~???
!English TranslationI have already booked a flight today, and I onlyhave to find a hotel.
I?m about to travel toBeijing next week - good anticipation!Table 1.
A microblog post from Weibomentioning an ongoing complex task?????
(travel to Beijing)?We divide the problem into the following threemajor sub-problems.1.
Find task-intrinsic entities for the complextask.2.
Generate a task name for the complex task.3.
Suggest proper search results covering alldesired entities for the complex task.The above three problems are very importantbut non-trivial to solve.
In this preliminary work,we only focus on first two sub-problems.
Weproposed an entity-driven complex task model(ECTM) to automatically generate complex tasknames and related task-intrinsic entities.
Toevaluate our proposed ECTM, we conducted ex-periments on a large dataset of real-world querylogs.
The experimental results show that ourECTM is able to identify a comprehensive com-plex task name with the task-intrinsic entities andhelp users accomplish the complex task with lesseffort.2 Related WorkRecent studies show that about 75% of searchsessions searching for complex tasks (Feild andAllan, 2013).
To help users deal with their com-plex search tasks, researchers devoted their ef-forts to understand and identify complex tasksfrom search sessions.
Boldi et al (2002) pro-posed a graph-based approach to dividing a long-term search session into search tasks.
Guo andAgichtein (2010) made the attempt to investigatethe hierarchical structure of a complex task witha series of search actions based on search ses-sions.
Cui et al (2011) proposed random walkbased methods to discover search tasks fromsearch sessions.
Kotov et al (2011) noticed that amulti-goal task may require a user to issue a se-ries of queries, spanning a long period of timeand multiple search sessions.
Thus, they ad-dressed the problem of modeling and analyzingcomplex cross-session search tasks.
Lucchese etal.
(2011) tried to identify task-based sessions inquery logs by semantic-based features extractedfrom Wiktionary and Wikipedia to overcomelack of semantic information.
Ji et al (2011)proposed a graph-based regularization algorithmto predict popular search tasks and simultaneous-ly classify queries and web pages by buildingtwo content-based classifiers.
White et al (2013)improved the traditional personalization methodsfor search-result re-ranking by exploiting similartasks from other users to re-rank search results.Wang et al (2013) addressed the problem of ex-tracting cross session tasks and proposed a taskpartition algorithm based on several pairwisesimilarity features.
Raman et al (2013) investi-gated intrinsic diversity (ID) for a search taskand proposed a re-ranking algorithm according tothe ID tasks.A complex task consists of several sub-tasks,and each sub-task goal may be composed of asequence of search queries.
Therefore, modelingthe sub-tasks is necessary for identifying a com-plex task.
Klinkner (2008) proposed a classifica-tion-based method to divide a single search ses-sion into tasks and sub-tasks based on the fourtypes of features, including time, word, query logsequence, and web search.
Lin et al (2012) de-fined a search goal as an action-entity pair andutilized web trigram to generate fine-grainedsearch goals.
Agichetin et al (2012) conducted acomprehensive analysis of search tasks and clas-sified them based on several aspects, such as in-tent, motivation, complexity, work-or-fun, time-sensitive, and continued-or-not.
Jones andYamamoto et al (2012) proposed an approach tomining sub-tasks for a task using query cluster-ing based on bid phrases provided by advertisers.The most important difference between our workand previous works is that we further try to gen-erate task names with related task-intrinsic enti-ties.
To the best of our knowledge, there is noexisting approach to utilizing microblogs in deal-ing with task identification and generating hu-man-interpretable names.3 Entity-driven Complex Task Model3.1 Problem FormulationGiven a query  , we aim to identify the complextask for the query.
Since the single query is notable to describe a complex task.
Our proposedECTM model introduces an expanded query setfor helping identify the task  .
Thus,  ( | )can be formulated as follows:( | )  ?
(  | ) ( |    )              (1)Since the expanded query set   always contain471the input query  , the Equation (1) can thus beapproximated as:( | )  ?
(  | ) ( |  )  ,            (2)where  (  | )  is the query expansion model.For  ( |  ) we utilize a set of microblog postsfor identifying the complex task   and obtainthe following equation:( |  )  ?
( |  ) ( |    ) .
(3)For  ( |    ) in Equation (3), the query setcan be omitted since the microblog post setcontains  .
The Equation (3) can thus be modi-fied as follows:( |  )  ?
( |  ) ( | ) .
(4)Finally, the ECTM can be obtained as follows:( | )  ?
(  | ) ?
( |  ) ( | )   ,  (5)where  (  | )  is the query expansion model,( |  )  is microblog retrieval model, and( | ) is task identification model.
In the fol-lowing section, we will describe the three modelsin detail respectively.3.2 Query Expansion ModelIn fact, only using a single query is insufficientto identify the latent complex task.
We thus try toextract task-coherent queries from search ses-sions.
According to our observation, users maypersistently search for the same complex task ina period of time.
However, users may also simul-taneously interleave search for multiple differenttasks (MacKay and Watters, 2008; Liu and Bel-kin, 2010).
Therefore, identifying task-coherentqueries from search sessions is an important is-sue.
We perform the following processes in orderto extract task-coherent queries.Given a query log and an input query  , wefirst separate queries in the log into search ses-sions with the time gap of 30 minutes.
We ex-tract search sessions containing the input queryand thus obtain a set of sessions   .
To extracttask-coherent queries   from the session set   ,we employ log-linear model (LLM) with the fol-lowing three useful features:Average Query Frequency: In most cases, thefrequency of queries can reflect their importance.To avoid a long session resulting in high queryfrequency, we calculate the normalized queryfrequency as:(  )|   |?
(    )| |,     (6)where     (    ) is the frequency of the queryin session  ,     is the sessions containing   ,| |  is the number of queries in session  , and|   | is the number of sessions containing queryin the set    .Session Coverage: The queries occurring in sev-eral sessions are possible candidates in terms oftask-coherence.
In order to favor queries occur-ring in many sessions, we use average sessionfrequency, which can be calculated as follows:(  )     (|   ||  |),         (7)where |  | is the number of sessions containingthe input query   in the set   , |   | is the num-ber of sessions containing query    in the set    ,and    ( ) is the exponential function.Average Query Distance: Since queries whichclose to the input query in a search session mayhave high task-coherence for the latent complextask.
We thus use normal distribution to estimatethe task-coherence for each query:(  )?,           (8)where   is standard deviation (is empirically set0.2 in this work),   is the average number ofqueries between    and input query   in sessions.We employ log-linear model to calculate theprobability of each candidate task-coherent querybased on the features described above:(    )(?
(  )| |)(  ),              (9)where   is the set of all candidate queries in thesession set   , | | is the number of used featurefunctions   (  ),  is the set of weighting pa-rameters    of feature functions, and  (  ) is anormalizing factor set to the value  (  )?
(?
(  )| |)     .3.3 Microblog Retrieval ModelSince the task names are not always observablein the expanded query set  , we thus need fur-ther expanding    by retrieving microblog posts.The basic idea is that a microblog post contain-ing all queries in    may also contain the taskname (see the example in Table 1).
In fact, thequeries in the query set    usually consist of atopic name and a task-intrinsic entity.
For exam-ple a query ?????
(Beijing flight ticket)?contains a topic ???(Beijing)?
and an entity???
(flight ticket)?.
Therefore, we first try toextract task-intrinsic entities from the query setby extracting all common nouns in each ofqueries.
We can thus obtain a list of task-intrinsic472entities    ordered by the occurrence frequencyof each entity.
Since a microblog post may onlycontain a part of entities for a complex task, wegenerate pseudo queries based on all subsets con-taining two or three entities from top-n entities of.
Finally, we use all generated pseudo queriesto retrieve microblog posts.3.4 Task Identification ModelTo identify a suitable task name from retrievedmicroblog posts, there are two steps in this mod-el, including candidate task name extraction andcorrect task name determination.Candidate Task Name ExtractionFor each retrieved microblog post, we first ex-tract all bigrams and trigrams which match thePOS (part of speech) patterns listed in Table 2.According to our observation, the POS of a tasktopic is usually a proper noun (  ) and the POSof a task event is usually a transitive verb (  ) +common noun (  ) or an intransitive verb (  ).On the other hand, a task topic may be the mostimportant term in related search sessions  .
Morespecifically, the term with the POS of propernoun and the highest occurrence count in the  .We thus consider the term as a candidate topic(notated as <T>) and adopt two related task POSpatterns, i.e.,    + <T> +   and <T> +   .Topic POS Event POS Task POS Pattern+       +    ++<T>+       + <T> +<T>+Table 2.
Adopted POS patterns for extractingcandidate task names from microblog posts.Correct Task Name DeterminationDifferent from long-text documents (e.g.,webpages), microblog posts are relatively shortand hard to find features based on special sec-tions in content (e.g., anchor text, title, or blocks).Therefore, we use five efficient features pro-posed by Zeng et al (2004) to extract complextask names from short-text snippets, such as mi-croblog post or search-result snippets.
The fea-tures proposed by Zeng et al including TFIDF,phrase length, intra-cluster similarity, cluster en-tropy, and phrase independence.
Furthermore, inthis work, we plus two practical features taskname coverage (the percentage of microblogposts containing the candidate task name) andchi-square score (Manning, 1999).Based on the set of extracted candidate tasknames    for the input query  , we also utilizedLLM to select the potential task names with thehighest likelihood.
The LLM for identifyingcomplex task names is given as follows:(   )(?
( )| |)(  ),              (10)where   is the set of weighting parameters    offeature functions   ( ), | | is the number of fea-ture functions   ( ),  (  ) is a normalizing fac-tor set to ?
(?
( )| |)    .4 Experiments4.1 DataWe use a one-month query logs from the Sogousearch engine, which contains 21,422,773 rec-ords and 3,163,170 distinct queries.
Each recordcontains user ID, query, clicked URL, userclicked order for the query, and the search-resultrank of the clicked URL.
We group query rec-ords into sessions according to user ID.
Since acomplex search task may take a long time to ac-complish, we used one week as the time gap tosplit sessions, and finally obtained 264,360 ses-sions.
For microblogs, we collected the top 50posts for each pseudo query from Weibo.To evaluate the performance of our proposedECTM model, we manually selected 30 testingqueries from sessions which are searching forcomplex tasks.
For each query, we employ threeannotators to label complex task names.
Threeannotators independently annotated 30 queries.We further examined the labeled results, and uni-fied the similar task names.
For instances, ?????
(travel to Beijing)?
and ?????
(trip toBeijing)?
were be unified to ?????
(travel toBeijing)?.
Table 3 shows an example of testingquery with labeled task name and task-intrinsicentities.QueryLabeledTask NameLabeled Task-Intrinsic EntitiesChinese?????
?????
?, ?
?, ???
?, ??
?English TranslationBeijingtravelagencytravel toBeijingmap, weather,hotel ,flight tick-ets, scheduleTable 3.
An example query ??????
(Beijing travel agency)?
with labeled taskname and task-intrinsic entities.4734.2 Compared MethodsWe compare our approach with the state-of-theart phrase extraction approach from short-textsnippet (e.g., microblog posts or search resultsnippets):?
Cluster_Q_RS (baseline): The method isproposed by Zeng et al (2004), which try toidentify important phrases from search resultsnippets.
They proposed five features includ-ing TFIDF, phrase length, intra-cluster simi-larity, cluster entropy, and phrase independ-ence.?
Cluster_EQ_RS: Since the above methodonly aim to identify important phrases from asingle query, the result should be not fair forthe problem addressed in this work.
We try toenhance Cluster_Q_RS using expandedsearch-result snippets proposed in this work.?
ECTM_RS: This method further use our sug-gested POS patterns for extracting candidatetask names and use all features proposed inSection 3.4.2.?
ECTM_MB: The only difference betweenthis method and the above method is that themethod try to identify task names from mi-croblog posts.4.3 Parameter SelectionThe weights of feature functions are learned byfive-fold cross-validation based on our labeleddata.
We use the same weights for the all of fol-lowing experiments.
Furthermore, determiningthe number of task-intrinsic entities used in gen-erating pseudo queries is most critical in thiswork.
We show the top n average coverage rateand average precision of extracted entities forour 30 testing queries in Figure 2.Figure 2.
The precision and coverage rate of topn entities used in our microblog retrieval modelWe found that using top 5 task-intrinsic entitiescan achieve the best results.
Therefore, for eachquery, we will generate 20 (i.e.,) pseudoqueries and we retrieved top 10 microblog postsfor each pseudo queries (totally 200 posts foreach testing query).4.4 Results of Task Name IdentificationWe use average top   inclusion rate as the met-rics.
For a set of queries, its top   inclusion rateis defined as the percentage of the query setwhose correct task names occur in the firstidentified task names.
The overall results areshown in Table 4.
We can see that ourECTM_MB outperform other methods.
TheECTM_MB can identify correct task nameswithin the first three recommendations.
Unsur-prisingly, Cluster_Q_RS achieved worst inclu-sion rate.
The reason is that Cluster _Q_RS try tofind comprehensive complex task name based onsearch results from only a single query.
Most oftask names suggested by Cluster_Q_RS are sim-ple task names i.e., the sub-tasks for the latentcomplex task, such as ?????
(book flighttickets)?.
For ECTM_RS, which is a variation ofCluster_EQ_RS, it achieved slightly better per-formance by adding the restrictions of POS pat-terns for extracting candidate task names.
Sincesome identified task names in Cluster_EQ_RSmay not semantically suitable, ECTM_RS?s ap-proach can efficiently deal with this problem.Furthermore, we also found that using search-result snippets may generate worse task namesthan using microblog posts.
According to ourinvestigating on the two types of the short-text-snippet resources, the search-result snippets arevery diverse and task-extrinsic while microblogposts are task-coherent in describing real-lifetasks.Top kinclusion rateTop1 Top3 Top5 Top10Cluster_Q_RS 0.28 0.33 0.37 0.47Cluster_EQ_RS 0.40 0.43 0.50 0.73ECTM_RS 0.43 0.43 0.57 0.83ECTM_MB 0.87 1 1 1Table 4.
The results of compared methods5 ConclusionIn this work, we proposed an entity-driven com-plex task model (ECTM), which addressed theproblem of improving user experience whensearching for a complex task.
Experimental re-sults show that ECTM efficiently identifies com-plex tasks with various task-intrinsic entities.Nevertheless, there are still some problems thatneed to be solved.
In the future, we will try toinvestigate ranking algorithms for developing anovel complex-task-based search engine, whichcan deal with queries based on complex tasks inreal life.474ReferencesAgichtein, E., White, R. W., Dumais, S. T., and Ben-nett, P. N. Search, Interrupted: Understanding andPredicting Search Task Continuation.
In Proc.
ofSIGIR, 2012.Boldi, P., Bonchi, F., Castillo, C., Donato, D., Gionis,A., and Vigna, S. The Query-Flow Graph: Modeland Applications.
In Proc.
of CIKM, 2008.Cui, J., Liu, H., Yan, J., Ji L., Jin R., He, J., Gu, Y.,Chen, Z., and Du, X. Multi-view Random WalkFramework for Search Task Discovery from Click-through Log.
In Proc.
of CIKM, 2011.Feild, H. and Allan, J. Task-Aware Query Recom-mendation.
In Proc.
of SIGIR, 2013.Guo, Q. and Agichtein, E. Ready to Buy or JustBrowsing?
Detecting Web Searcher Goals from In-teraction Data.
In Proc.
of SIGIR, 2010.Ji, M., Yan, J., Gu, S., Han, J., He, X., Zhang, W. V.,and Chen, Z.
Learning Search Tasks in Queries andWeb Pages via Graph Regularization.
In Proc.
ofSIGIR, 2011.Jones, R., and Klinkner, K. Beyond the SessionTimeout: Automatic Hierarchical Segmentation ofSearch Topics in Query Logs.
In Proc.
of CIKM,2008.Kotov, A., Bennett, P. N., White, R. W., Dumais, S.T., and Teevan, J.
Modeling and Analysis of Cross-Session Search Tasks.
In Proc.
of SIGIR, 2011.Liao, Z., Song, Y., He, L.-W., and Huang, Y. Evaluat-ing the Effectiveness of Search Task Trails.
InProc.
of WWW, 2012.Lin, T., Pantel, P., Gamon, M., Kannan, A., and Fux-man, A.
Active Objects: Actions for Entity-CentricSearch.
In Proc.
of WWW, 2012.Liu, J. and Belkin, N. J. Personalizing InformationRetrieval for Multi-Session Tasks: The Roles ofTask Stage and Task Type.
In Proc.
of SIGIR, 2010.Lucchese, C., Orlando, S., Perego, R., Silvestri, F.,and Tolomei, G. Identifying Task-based Sessionsin Search Engine Query Logs.
In Proc.
of WSDM,2011.MacKay, B. and Watters, C. Exploring Multi-SessionWeb Tasks.
In Proc.
of CHI, 2008.Manning, C. D., Sch?tze, H. Foundations of Statisti-cal Natural Language Processing.
The MIT Press.Cambridge, US, 1999.Raman, K., Bennett, P. N., and Collins-Thompson, K.Toward Whole-Session Relevance: Exploring In-trinsic Diversity in Web Search.
In Proc.
of SIGIR,2013.Wang, H., Song, Y., Chang, M.-W., He, X., White, R.W., and Chu, W. Learning to Extract Cross-Session Search Tasks.
In Proc.
of WWW, 2013.White, R. W., Chu, W., Hassan, A., He, X., Song, Y.,and Wang, H. Enhancing Personalized Search byMining and Modeling Task Behavior.
In Proc.
ofWWW, 2013.Yamamoto, T., Sakai, T., Iwata, M., Yu, C., Wen, J.-R., and Tanaka, K. The Wisdom of Advertisers:Mining Subgoals via Query Clustering.
In Proc.
ofCIKM, 2012.Zeng, H.-J., He, Q.-C., Chen, Z., Ma, W.-Y., and Ma,J.
Learning to Cluster Web Search Results.
In Proc.of SIGIR, 2004.475
