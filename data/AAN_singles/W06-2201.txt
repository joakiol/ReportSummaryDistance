Learning Effective Surface Text Patternsfor Information ExtractionGijs Geleijnse and Jan KorstPhilips Research LaboratoriesProf.
Holstlaan 4, 5656 AA Eindhoven, The Netherlands{gijs.geleijnse,jan.korst}@philips.comAbstractWe present a novel method to identify ef-fective surface text patterns using an inter-net search engine.
Precision is only oneof the criteria to identify the most effec-tive patterns among the candidates found.Another aspect is frequency of occurrence.Also, a pattern has to relate diverse in-stances if it expresses a non-functional re-lation.
The learned surface text patternsare applied in an ontology population al-gorithm, which not only learns new in-stances of classes but also new instance-pairs of relations.
We present some ?rstexperiments with these methods.1 IntroductionRavichandran and Hovy (2002) present a methodto automatically learn surface text patterns ex-pressing relations between instances of classes us-ing a search engine.
Their method, based ona training set, identi?es natural language surfacetext patterns that express some relation betweentwo instances.
For example, ?was born in?
provedto be a precise pattern expressing the relation be-tween instances Mozart (of class ?person?)
and1756 (of class ?year?
).We address the issue of learning surface textpatterns, since we observed two drawbacks ofRavichandran and Hovy?s work with respect to theapplication of such patterns in a general informa-tion extraction setting.The ?rst drawback is that Ravichandran andHovy focus on the use of such surface text patternsto answer so-called factoid questions (Voorhees,2004).
They use the assumption that each instanceis related by R to exactly one other instance ofsome class.
In a general information extractionsetting, we cannot assume that all relations arefunctional.The second drawback is that the criterion for se-lecting patterns, precision, is not the only issue fora pattern to be effective.
We call a pattern effec-tive, if it links many different instance-pairs in theexcerpts found with a search engine.We use an ontology to model the informationdomain we are interested in.
Our goal is to pop-ulate an ontology with the information extracted.In an ontology, instances of one class can be re-lated by some relation R to multiple instances ofsome other class.
For example, we can identifythe classes ?movie?
and ?actor?
and the ?acts in?-relation, which is a many-to-many relation.
Ingeneral, multiple actors star in a single movie anda single actor stars in multiple movies.In this paper we present a domain-independentmethod to learn effective surface text patterns rep-resenting relations.
Since not all patterns foundare highly usable, we formulate criteria to selectthe most effective ones.
We show how such pat-terns can be used to populate an ontology.The identi?cation of effective patterns is impor-tant, since we want to perform as few queries toa search engine as possible to limit the use of itsservices.This paper is organized as follows.
After de?n-ing the problem (Section 2) and discussing relatedwork (Section 3), we present an algorithm to learneffective surface text patterns in Section 4.
We dis-cuss the application of this method in an ontologypopulation algorithm in Section 5.
In Section 6,we present some of our early experiments.
Sec-tions 7 and 8 handle conclusions and future work.12 Problem descriptionWe consider two classes cq and ca and the corre-sponding non-empty sets of instances Iq and Ia.Elements in the sets Iq and Ia are instances of cqand ca respectively, and are known to us before-hand.
However, the sets I do not have to be com-plete, i.e.
not all possible instances of the corre-sponding class have to be in the set I .Moreover, we consider some rela-tion R between these classes and give anon-empty training set of instance-pairsTR = {(x, y) | x ?
Iq ?
y ?
Ia}, whichare instance-pairs that are known to be R-related.Problem: Given the classes cq and ca, the setsof instances Iq and Ia, a relation R and a setof R-related instance-pairs TR, learn effectivesurface text patterns that express the relation R.Say, for example, we consider the classes ?au-thor?
and ?book title?
and the relation ?has written?.We assume that we know some related instance-pairs , e.g.
(?Leo Tolstoy?, ?War and Peace?)
and(?Gu?nter Grass?, ?Die Blechtrommel?).
We thenwant to ?nd natural language phrases that relateauthors to the titles of the books they wrote.
Thus,if we query a pattern in combination with the nameof an author (e.g.
?Umberto Eco wrote?
), we wantthe search results of this query to contain the booksby this author.The population of an ontology can be seen asa generalization of a question-answering setting.Unlike question-answering, we are interested in?nding all possible instance-pairs, not only thepairs with one ?xed instance (e.g.
all ?author?-?book?
pairs instead of only the pairs containinga ?xed author).
Functional relations in an ontol-ogy correspond to factoid questions, e.g.
the pop-ulation of the classes ?person?
and ?country?
andthe ?was born in?-relation.
Non-functional rela-tions can be used to identify answers to list ques-tions, for example ?name all books written byLouis-Ferdinand Ce?line?
or ?which countries bor-der Germany?
?.3 Related workBrin identi?es the use of patterns in the discoveryof relations on the web (Brin, 1998).
He describesa website-dependent approach to identify hyper-text patterns that express some relation.
For eachweb site, such patterns are learned and exploredto identify instances that are similarly related.
In(Agichtein and Gravano, 2000), such a system iscombined with a named-entity recognizer.In (Craven et al, 2000) an ontology is popu-lated by crawling a website.
Based on tagged webpages from other sites, rules are learned to extractinformation from the website.Research on named-entity recognition was ad-dressed in the nineties at the Message Understand-ing Conferences (Chinchor, 1998) and is contin-ued for example in (Zhou and Su, 2002).Automated part of speech tagging (Brill, 1992)is a useful technique in term extraction (Frantziet al, 2000), a domain closely related to named-entity recognition.
Here, terms are extractedwith a prede?ned part-of-speech structure, e.g.
anadjective-noun combination.
In (Nenadic?
et al,2002), methods are discussed to extract informa-tion from natural language texts with the use ofboth part of speech tags and hyponym patterns.As referred to in the introduction, Ravichandranand Hovy (2002) present a method to identify sur-face text patterns using a web search engine.
Theyextract patterns expressing functional relations ina factoid question answering setting.
Selection ofthe extracted patterns is based on the precision ofthe patterns.
For example, if the pattern ?was bornin?
is identi?ed as a pattern for the pair (?Mozart?,?Salzburg?
), they compute precision as the num-ber of excerpts containing ?Mozart was born inSalzburg?
divided by the number of excerpts with?Mozart was born in?.Information extraction and ontologies creationare two closely related ?elds.
For reliable informa-tion extraction, we need background information,e.g.
an ontology.
On the other hand, we need in-formation extraction to generate broad and highlyusable ontologies.
An overview on ontology learn-ing from text can be found in (Buitelaar et al,2005).Early work (Hearst, 1998), describes the extrac-tion of text patterns expressing WordNet-relations(such as hyponym relations) from some corpus.This work focusses merely on the identi?cation ofsuch text patterns (i.e.
phrases containing both in-stances of some related pair).
Patterns found bymultiple pairs are suggested to be usable patterns.KnowItAll is a hybrid named-entity extractionsystem (Etzioni et al, 2005) that ?nds lists of in-stances of some class from the web using a searchengine.
It combines Hearst patterns and learned2patterns for instances of some class to identify andextract named-entities.
Moreover, it uses adaptivewrapper algorithms (Crescenzi and Mecca, 2004)to extract information from html markup such astables.Cimiano and Staab descibe a method to usea search engine to verify a hypothesis relation(2004).
For example, if we are interested in the ?isa?
or hyponym relation and we have a candidate in-stance pair (?river?, ?Nile?)
for this relation, we canuse a search engine to query phrases expressingthis relation (e.g.
?rivers such as the Nile?).
Thenumber of hits to such queries can then be used asa measure to determine the validity of the hypoth-esis.In (Geleijnse and Korst, 2005), a method is de-scribed to populate an ontology with the use ofqueried text patterns.
The algorithm presented ex-tracts instances from search results after havingsubmitted a combination of an instance and a pat-tern as a query to a search engine.
The extractedinstances from the retrieved excerpts can there-after be used to formulate new queries ?
and thusidentify and extract other instances.4 The algorithmWe present an algorithm to learn surface text pat-terns for relations.
We use GoogleTM to retrievesuch patterns.The algorithm makes use of a training set TRof instance-pairs that are R-related.
This trainingset should be chosen such the instance-pairs aretypical for relation R.We ?rst discover how relation R is expressedin natural language texts on the web (Section 4.1).In Section 4.2 we address the problem of select-ing effective patterns from the total set of patternsfound.4.1 Identifying relation patternsWe ?rst generate a list of surface text patterns withthe use of the following algorithm.
For evaluationpurposes, we also compute the frequency of eachpattern found.- Step 1: Formulate queries using an instance-pair (x, y) ?
TR.
Since we are interested inphrases within sentences rather than in key-words or expressions in telegram style thatoften appear in titles of webpages, we usethe allintext: option.
This gives us onlysearch results with the queried expression inthe bodies of the documents rather than in thetitles.
We query both allintext:" x *y " and allintext:" y * x ".
The *is a regular expression operator accepted byGoogle.
It is a placeholder for zero or morewords.- Step 2: Send the queries to Google and col-lect the excerpts of the at most 1,000 pages itreturns for each query.- Step 3: Extract all phrases matching thequeried expressions and replace both x andy by the names of their classes.- Step 4: Remove all phrases that are notwithin one sentence.- Step 5: Normalize all phrases by removingall mark-up that is ignored by Google.
SinceGoogle is case-insensitive and ignores punc-tuation, double spaces and the like, we trans-late all phrases found to a normal form: thesimplest expression that we can query thatleads to the document retrieved.- Step 6: Update the frequencies of all normal-ized phrases found.- Step 7: Repeat the procedure for any un-queried pair (x?, y?)
?
TR.We now have generated a list with relation pat-terns and their frequencies within the retrievedGoogle excerpts.4.2 Selecting relation patternsFrom the list of relation patterns found, we are in-terested in the most effective ones.We are not only interested in the most preciseones.
For example, the retrieved pattern ?fo?dd 30mars 1853 i?
proved to a 100% precise patternexpressing the relation between a person (?Vin-cent van Gogh?)
and his place of birth (?Zun-dert?).
Clearly, this rare phrase is unsuited to mineinstance-pairs of this relation in general.
On theother hand, high frequency of some pattern is noguarantee for effectiveness either.
The frequentlyoccurring pattern ?was born in London?
(foundwhen querying for Thomas Bayes * England)is well-suited to be used to ?nd London-born per-sons, but in general the pattern is unsuited ?
sincetoo narrow ?
to express the relation between a per-son and his or her country of origin.3Taking these observations into account, we for-mulate three criteria for selecting effective relationpatterns.1.
The patterns should frequently occur on theweb, to increase the probability of getting anyresults when querying the pattern in combi-nation with an instance.2.
The pattern should be precise.
When wequery a pattern in combination with an in-stance in Iq, we want to have many searchresults containing instances from ca.3.
If relation R is not functional, the patternshould be wide-spread, i.e.
among the searchresults when querying a combination of thepattern and an instance in Iq there must be asmany distinct R-related instances from ca aspossible.To measure these criteria, we use the followingscoring functions for relation patterns s.1.
ffreq(s) = ?number of occurrences of s inthe excerpts as found by the algorithm de-scribed in the previous subsection?2.
fprec(s) =?x?I?qP (s,x)|I?q | , wherefor instances x ?
I ?q, I ?q ?
Iq , we calculateP (s, x) as follows.P (s, x) = FI(s,x)FO(s,x)andFI(s, x) = the number of Google excerptsafter querying s in combination with xcontaining instances of ca.FO(s, x) = the total number of excerptsfound (at most 1,000).3. fspr(s) =?x?I?q B(s, x), whereB(s, x) = the number of distinct instancesof class ca found after querying pattern s incombination with x.The larger we choose the testset, the subsetI ?q of Iq, the more reliable the measures for pre-cision and spreading.
However, the number ofGoogle queries increases with the number of pat-terns found for each instance we add to I ?q.We ?nally calculate the score of the patterns bymultiplying the individual scores:score(s) = ffreq(s) ?
fprec(s) ?
fspr(s)For ef?ciency reasons, we only compute thescores of the patterns with the highest frequencies.The problem remains how to recognize a (pos-sible multi-word) instance in the Google excerpts.For an ontology alignment setting ?
where the setsIa and Iq are not to be expanded ?
these problemsare trivial: we determine whether t ?
Ia is accom-panied by the queried expression.
For a settingwhere the instances of ca are not all known (e.g.it is not likely that we have a complete list of allbooks written in the world), we solve this problemin two stages.
First we identify rules per class toextract candidate instances.
Thereafter we use anadditional Google query to verify if a candidate isindeed an instance of class ca.Identifying a candidate instanceThe identi?cation of multi-word terms is an is-sue of research on its own.
However, in this settingwe can allow ourselves to use less elaborate tech-niques to identify candidate instances.
We can doso, since we additionally perform a check on eachextracted term.
So, per class we create rules toidentify candidate instances with a focus on highrecall.
In our current experiments we thus use verysimple term recognition rules, based on regular ex-pressions.
For example, we identify a candidateinstance of class ?person?
if the queried expressionis accompanied by two or three capitalized words.Identifying an instance-class relationWe are interested in the question whether someextracted term t is an instance of class ca.
For ex-ample, given the term ?The Godfather?, does thisterm belong to the class ?movie??
The instance-class relation can be viewed of as a hyponym re-lation.
We therefore verify the hypothesis of t be-ing an instance of ca by Googling hyponym rela-tion patterns.
We use a ?xed set H of commonpatterns expressing the hyponym relation (Hearst,1992; Cimiano and Staab, 2004), see Table 1.
Forthe class names, we use plurals.We use these patterns in the following accep-tance functionacceptcq(t) := (?p?Hh(p, cq, t) ?
n),4"cq including t and""cq for example t and""cq like t and""cq such as t and"Table 1: Hearst patterns for instance-class relation.where h(p, cq, t) is the number of Google hits forquery with pattern p combined with term t and theplural form of the class name cq.
The thresholdn has to be chosen beforehand.
We can do so, bycalculating the sum of Google hits for queries withknown instances of the class.
Based on these ?g-ures, a threshold can be chosen e.g.
the minimumof these sums.Note that term t is both preceded and followedby a ?xed phrase in the queries.
We do so, toguarantee that t is indeed the full term we are in-terested in.
For example, if we had extracted theterm ?Los?
instead of ?Los Angeles?
as a Califor-nian City, we would falsely identify ?Los?
as a Cal-ifornian City, when we do not let ?Los?
follow bythe ?xed expression and.
The number of Googlehits for some expression x is at least the numberof Google hits when querying the same expressionfollowed by some expression y.If we identify a term t as being an instance ofclass ca, we can add this term to the set Ia.
How-ever, we cannot relate t to an instance in Iq, sincethe pattern used to ?nd t has not proven to be effec-tive yet (e.g.
the pattern could express a differentrelation between one of the instance-pairs in thetraining set).We reduce the amount of Google queries by us-ing a list of terms found that do not belong to ca.Terms that occur multiple times in the excerptscan then be checked only once.
Moreover, we usethe OR-clause to combine the individual queriesinto one.
We then check if the number of hitsto this query exceeds the threshold.
The amountof Google queries in this phase thus equals theamount of distinct terms extracted.5 The use of surface text patterns ininformation extractionHaving a method to identify relation patterns, wenow focus on utilizing these patterns in informa-tion extraction from texts found by a search en-gine.
We use an ontology to represent the infor-mation extracted.Suppose we have an ontology O with classes(c1, c2, ...) and corresponding instance sets(I1, I2, ..).
On these classes, relations R(i,j)1are de?ned, with i and j the index number ofthe classes.
The non-empty sets T(i,j) containthe training set of instance-pairs of the relationsR(i,j).Per instance, we maintain a list of expressionsthat already have been used as a query.
Initially,these are empty.The ?rst step of the algorithm is to learn surfacetext patterns for each relation in O.The following steps of the algorithm are per-formed until either some stop criterion is reached,or no more new instances and instance-pairs canbe found.- Step 1: Select a relation R(i,j), and an in-stance v from either Ii or Ij such that thereexists at least one pattern expressing R(i,j)we have not yet queried in combination withv.- Step 2: Construct queries using the patternswith v and send these queries to Google.- Step 3: Extract instances from the excerpts.- Step 4: Add the newly found instances tothe corresponding instance set and add theinstance-pairs found (thus with v) to T(i,j).- Step 5: If there exists an instance that we canuse to formulate new queries, then repeat theprocedure.Else, learn new patterns using the extractedinstance-pairs and then repeat the procedure.Note that instances of class cx learned using thealgorithm applied on relation R(x,y) can be usedas input for the algorithm applied to some relationR(x,z) to populate the sets Iz and T(x,z).6 ExperimentsIn this section, we discuss two experiments that wehave conducted.
The ?rst experiment involves theidenti?cation of effective hyponym patterns.
Thesecond experiment is an illustration of the applica-tion of learned surface text patterns in informationextraction.1Assuming one relation per pair of classes.
We can useanother index k in R(i,j,k) to distinct multiple relations be-tween ci and cj .56.1 Learning effective hyponym patternsWe are interested whether the effective surface textpatterns are indeed intuitive formulations of somerelation R. As a test-case, we compute the mosteffective patterns for the hyponym relation using atest set with names of all countries.Our experiment was set up as follows.
We col-lected the complete list of countries in the worldfrom the CIA World Factbook2.
Let Iq be this setof countries, and let Ia be the set { ?countries?,?country?
}.
The set TR consists of all pairs (a,?countries?)
and (a, ?country?)
, for a ?
Ia.
Weapply the surface text pattern learning algorithmon this set TR.The algorithm identi?ed almost 40,000 patterns.We computed fspr and fprec for the 1,000 mostfrequently found patterns.
In table 2, we give the25 most effective patterns found by the algorithm.We consider the patterns in boldface true hyponympatterns.
Focussing on these patterns, we observetwo groups: ?is a?
and Hearst-like patterns.pattern freq prec spr(countries) like 645 0.66 134(countries) such as 537 0.54 126is a small (country) 142 0.69 110(country) code for 342 0.36 84(country) map of 345 0.34 78(countries) including 430 0.21 93is the only (country) 138 0.55 102is a (country) 339 0.22 99(country) ?ag of 251 0.63 46and other (countries) 279 0.34 72and neighboring (countries) 164 0.43 92(country) name republic of 83 0.93 76(country) book of 59 0.77 118is a poor (country) 63 0.73 106is the ?rst (country) 53 0.70 112(countries) except 146 0.37 76(country) code for calling 157 0.95 26is an independent (country) 62 0.55 114and surrounding (countries) 84 0.40 107is one of the poorest (countries) 61 0.75 78and several other (countries) 65 0.59 90among other (countries) 84 0.38 97is a sovereign (country) 48 0.69 89or any other (countries) 87 0.58 58(countries) namely 58 0.44 109Table 2: Learned hyponym patterns and theirscores.The Hearst-patterns ?like?
and ?such as?
show tobe the most effective.
This observation is useful,when we want to minimize the amount of queriesfor hyponym patterns.Expressions of properties that hold for each2http://www.cia.gov/cia/publications/factbookcountry and only for countries, for example the ex-istence of a country code for dialing, are not triv-ially identi?ed manually but are useful and reliablepatterns.The combination of ?is a?, ?is an?
or ?is the?
withan adjective is a common pattern, occurring 2,400times in the list.
In future work, we plan to identifysuch adjectives in Google excerpts using a Part ofSpeech tagger (Brill, 1992).6.2 Applying learned patterns in informationextractionThe Text Retrieval Conference (TREC) questionanswering track in 2004 contains list question,for example ?Who are Nirvana?s band members??
(Voorhees, 2004).
We illustrate the use of our on-tology population algorithm in the context of suchlist-question answering with a small case-study.Note that we do not consider the processing of thequestion itself in this research.Inspired by one of the questions (?What coun-tries is Burger King located in??
), we are interestedin populating an ontology with restaurants and thecountries in which they operate.
We identify theclasses ?country?
and ?restaurant?
and the relation?located in?
between the classes.We hand the algorithm the instances of ?coun-try?, as well as two instances of ?restaurant?
: ?Mc-Donald?s?
and ?KFC?.
Moreover, we add threeinstance-pairs of the relation to the algorithm.
Weuse these pairs and a subset I ?country of size eightto compute a ranked list of the patterns.
We ex-tract terms consisting of one up to four capital-ized words.
In this test we set the threshold forthe number of Google results for the queries withthe extracted terms to 50.
After a small test withnames of international restaurant branches, thisseemed an appropriate threshold.The algorithm learned, besides a ranked list of170 surface text patterns (Table 3), a list of 54 in-stances of restaurant (Table 4).
Among these in-stances are indeed the names of large internationalchains, Burger King being one of them.
Lessexpected are the names of geographic locationsand names of famous cuisines such as ?Chinese?and ?French?.
The last category of false instancesfound that have not be ?ltered out, are a number ofvery common words (e.g.
?It?
and ?There?
).We populate the ontology with relations foundbetween Burger King and instances from countryusing the 20 most effective patterns.6pattern prec spr freqca restaurants of cq 0.24 15 21ca restaurants in cq 0.07 19 9ca hamburger chain that occupiesvillages throughout modern day cq 1.0 1 7ca restaurant in cq 0.06 16 6ca restaurants in the cq 0.13 16 2ca hamburger restaurant in southern cq 1.0 1 4Table 3: Top learned patterns for the restaurant-country (ca - cq) relation.Chinese Bank Outback SteakhouseDenny?s Pizza Hut Kentucky Fried ChickenSubway Taco Bell ContinentalHolywood Wendy?s Long John Silver?sHOTEL OR This Burger KingJapanese West Keg SteakhouseYou BP OutbackWorld Brazil San FranciscoLeo Victoria New YorkThese Lyons StarbucksFELIX Roy California Pizza KitchenMarks Cities EmperorFriendly Harvest FridayNew York Vienna MontanaLouis XV Greens Red LobsterGood It ThereThat Mark Dunkin DonutsItalia French Tim HortonsTable 4: Learned instances for restaurant.The algorithm returned 69 instance-pairs withcountries related to ?Burger King?.
On the BurgerKing website3 a list of the 65 countries can befound in which the hamburger chain operates.
Ofthese 65 countries, we identi?ed 55.
This impliesthat our results have a precision of 5569 = 80% andrecall of 5565 = 85%.
Many of the falsely relatedcountries ?
mostly in eastern Europe ?
are loca-tions where Burger King is said to have plans toexpand its empire.7 ConclusionsWe have presented a novel approach to identifyuseful surface text patterns for information extrac-tion using an internet search engine.
We arguedthat the selection of patterns has to be based oneffectiveness: a pattern has to occur frequently, ithas to be precise and has to be wide-spread if itrepresents a non-functional relation.These criteria are combined in a scoring func-tion which we use to select the most effective pat-terns.3http://www.whopper.comThe method presented can be used for arbitraryrelations, thus also relations that link an instanceto multiple other instances.
These patterns can beused in information extraction.
We combine pat-terns with an instance and offer such an expressionas a query to a search engine.
From the excerptsretrieved, we extract instances and simultaneouslyinstance-pairs.Learning surface text patterns is ef?cient withrespect to the number of queries if we know allinstances of the classes concerned.
The ?rst partof the algorithm is linear to the size of the trainingset.
Furthermore, we select the n most frequentpatterns and perform |I ?q| ?
n queries to computethe score of these n patterns.However, for a setting where I ?a is incomplete,we have to perform a check for each unique termidenti?ed as a candidate instance in the excerptsfound by the |I ?q| ?
n queries.
The number ofqueries, one for each extracted unique candidateinstance, thus fully depends on the rules that areused to identify a candidate instance.We apply the learned patterns in an ontologypopulation algorithm.
We combine the learnedhigh quality relation patterns with an instance ina query.
In this way we can perform a range of ef-fective queries to ?nd instances of some class andsimultaneously ?nd instance-pairs of the relation.A ?rst experiment, the identi?cation of hy-ponym patterns, showed that the patterns identi-?ed indeed intuitively re?ect the relation consid-ered.
Moreover, we have generated a ranked listof hyponym patterns.
The experiment with therestaurant ontology illustrated that a small train-ing set suf?ces to learn effective patterns and pop-ulate an ontology with good precision and recall.The algorithm performs well with respect to re-call of the instances found: many big internationalrestaurant branches were found.
The identi?cationof the instances however is open to improvement,since the additional check does not ?lter out allfalsely identi?ed candidate instances.8 Future workCurrently we check whether an extracted term isindeed an instance of some class by querying hy-ponym patterns.
However, if we ?nd two in-stances related by some surface text pattern, we al-ways accept these instances as instance pair.
Thus,if we both ?nd ?Mozart was born in Germany?and ?Mozart was born in Austria?, both extracted7instance-pairs are added to our ontology.
Wethus need some post-processing to remove falselyfound instance-pairs.
When we know that a re-lation is functional, we can select the most fre-quently occurring instance-pair.Moreover, the process of identifying an instancein a text needs further research especially sincethe method to identify instance-class relations byquerying hyponym patterns is not ?awless.The challenge thus lies in the area of improvingthe precision of the output of the ontology pop-ulation algorithm.
With additional ?ltering tech-niques and more elaborated identi?cation tech-niques we expect to be able to improve the pre-cision of the output.
We plan to research checkfunctions based on enumerations of candidate in-stances with known instances of the class.
For ex-ample, the enumeration ?KFC, Chinese and Mc-Donald?s?
is not found by Google, where ?KFC,Burger King and McDonald?s?
gives 31 hits.Our experiment with the extraction of hyponympatterns, suggests a ranking of Hearst-patternsbased on the effectiveness.
Knowledge on the ef-fectiveness of each of the Hearst-patterns can beutilized to minimize the amount of queries.Finally we will investigate ways to compare ourmethods with other systems in a TREC like settingwith the web as a corpus.AcknowledgmentsWe thank our colleagues Bart Bakker and DraganSekulovski and the anonymous reviewers for theiruseful comments on earlier versions of this paper.ReferencesE.
Agichtein and L. Gravano.
2000.
Snowball: Ex-tracting relations from large plain-text collections.In Proceedings of the Fifth ACM International Con-ference on Digital Libraries.E.
Brill.
1992.
A simple rule-based part-of-speechtagger.
In Proceedings of the third Conference onApplied Natural Language Processing (ANLP?92),pages 152?155, Trento, Italy.S.
Brin.
1998.
Extracting patterns and relations fromthe world wide web.
In WebDB Workshop at sixthInternational Conference on Extending DatabaseTechnology (EDBT?98).P.
Buitelaar, P. Cimiano, and B. Magnini, editors.2005.
Ontology Learning from Text: Methods, Eval-uation and Applications, volume 123 of Frontiers inArti?cial Intelligence and Applications.
IOS Press.N.
A. Chinchor, editor.
1998.
Proceedings of the Sev-enth Message Understanding Conference (MUC-7).Morgan Kaufmann, Fairfax, Virginia.P.
Cimiano and S. Staab.
2004.
Learning by googling.SIGKDD Explorations Newsletter, 6(2):24?33.M.
Craven, D. DiPasquo, D. Freitag, A. McCallum,T.
Mitchell, K. Nigam, and S. Slattery.
2000.
Learn-ing to construct knowledge bases from the WorldWide Web.
Arti?cial Intelligence, 118:69?113.V.
Crescenzi and G. Mecca.
2004.
Automatic infor-mation extraction from large websites.
Journal ofthe ACM, 51(5):731?779.O.
Etzioni, M. J. Cafarella, D., A. Popescu, T. Shaked,S.
Soderland, D. S. Weld, and A. Yates.
2005.
Un-supervised named-entity extraction from the web:An experimental study.
Arti?cial Intelligence,165(1):91?134.K.
Frantzi, S. Ananiado, and H. Mima.
2000.
Au-tomatic recognition of multi-word terms: the c-value/nc-value method.
International Journal onDigital Libraries, 3:115?130.G.
Geleijnse and J. Korst.
2005.
Automatic ontologypopulation by googling.
In Proceedings of the Sev-enteenth Belgium-Netherlands Conference on Arti-?cial Intelligence (BNAIC 2005), pages 120 ?
126,Brussels, Belgium.M.
Hearst.
1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Proceedings of the14th conference on Computational linguistics, pages539?545, Morristown, NJ, USA.M.
Hearst.
1998.
Automated discovery of wordnetrelations.
In Christiane Fellbaum, editor, WordNet:An Electronic Lexical Database.
MIT Press, Cam-bridge, MA.G.
Nenadic?, I.
Spasic?, and S. Ananiadou.
2002.
Au-tomatic discovery of term similarities using patternmining.
In Proceedings of the second internationalworkshop on Computational Terminology (CompuT-erm?02), Taipei, Taiwan.D.
Ravichandran and E. Hovy.
2002.
Learning surfacetext patterns for a question answering system.
InProceedings of the 40th Annual Meeting of the Asso-ciation for Computational Linguistics (ACL 2002),pages 41?47, Philadelphia, PA.E.
Voorhees.
2004.
Overview of the trec 2004 ques-tion answering track.
In Proceedings of the 13thText Retrieval Conference (TREC 2004), Gaithers-burg, Maryland.G.
Zhou and J. Su.
2002.
Named entity recognitionusing an hmm-based chunk tagger.
In Proceedingsof the 40th Annual Meeting of the Association forComputational Linguistics (ACL 2002), pages 473 ?480, Philadelphia, PA.8
