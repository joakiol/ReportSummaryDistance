A Pipeline Approach to Chinese Personal NameDisambiguationYang Song, Zhengyan He, Chen Chen, Houfeng WangKey Laboratory of Computational Linguistics (Peking University)Ministry of Education,China{ysong, hezhengyan, chenchen, wanghf}@pku.edu.cnAbstractIn this paper, we describe our sys-tem for Chinese personal name dis-ambiguation task in the first CIPS-SIGHAN joint conference on ChineseLanguage Processing(CLP2010).
Weuse a pipeline approach, in which pre-processing, unrelated documents dis-carding, Chinese personal name exten-sion and document clustering are per-formed separately.
Chinese personalname extension is the most importantpart of the system.
It uses two addi-tional dictionaries to extract full per-sonal names in Chinese text.
And thendocument clustering is performed un-der different personal names.
Exper-imental results show that our systemcan achieve good performances.1 IntroductionPersonal name search is one of the most im-portant tasks for search engines.
When a per-sonal name query is given to a search engine,a list of related documents will be shown.
Butnot all of the returned documents refer to thesame person whom users want to find.
For ex-ample, the query name ?jordan?
is submittedto a search engine, we can get a lot of doc-uments containing ?jordan?.
Some of themmay refer to the computer scientist, othersperhaps refer to the basketball player.
ForEnglish, there have been three Web PeopleSearch (WePS1) evaluation campaigns on per-sonal name disambiguation.
But for Chinese,1http://nlp.uned.es/weps/this is the first time.
It encounters more chal-lenge for Chinese personal name disambigua-tion.
There are no word boundary in Chinesetext, so it becomes difficult to recognize thefull personal names from Chinese text.
For ex-ample, a query name ????
is given, but thefull personal name from some documents maybe an extension of ???
?, like ?????
or????
?, and so on.
Meanwhile, ????
canalso be a common Chinese word.
So we needto discard those documents which are not ref-ered to any person related to the given queryname.To solve the above-mentioned problem, weexplore a pipeline approach to Chinese per-sonal name disambiguation.
The overview ofour system is illustrated in Figure 1.
We splitthis task into four parts: preprocessing, unre-lated documents discarding, Chinese personalname extension and document clustering.
Inpreprocessing and unrelated documents dis-carding, we use word segmentation and part-of-speech tagging tools to process the givendataset and documents are discarded whenthe given query name is not tagged as a per-sonal name or part of a personal name.
Afterthat we perform personal name extension inthe documents for a given query name.
Whenthe query name has only two characters.
Weextend it to the left or right for one character.For example, we can extend ????
to ?????
or ?????.
The purpose of extendingthe query name is to obtain the full personalname.
In this way, we can get a lot of full per-sonal names for a given query name from thedocuments.
And then document clusteringFigure 1: Overview of the Systemis performed under different personal names.HAC (Hierarchical Agglomerative Clustering)is selected here.
We represent documents withbag of words and solve the problem in vectorspace model, nouns, verbs, bigrams of nounsor verbs and named entities are selected asfeatures.
The feature weight value takes 0 or1.
In HAC, we use group-average link methodas the distance measure and consine similar-ity as the similarity computing measure.
Thestopping criteria is dependent on a thresholdwhich is obtained from training data.
Our sys-tem produces pretty good results in the finalevaluation.The remainder of this paper is organized asfollows.
Section 2 introduces related work.Section 3 gives a detailed description aboutour pipeline approach.
It includes preprocess-ing, unrelated documents discarding, Chinesepersonal name extension and document clus-tering.
Section 4 presents the experimentalresults.
The conclusions are given in Section5.2 Related WorkSeveral important studies have tried tosolve the task introduced in the previous sec-tion.
Most of them treated it as an cluster-ing problem.
Bagga & Baldwin (1998) firstselected tokens from local context as featuresto perform intra-document coreference resolu-tion.
Mann & Yarowsky (2003) extracted lo-cal biographical information as features.
Niuet al (2004) used relation extraction resultsin addition to local context features and get aperfect results.
Al-Kamha and Embley (2004)clustered search results with feature set in-cluding attributes, links and page similarities.In recent years, this problem has attracteda great deal of attention from many researchinstitutes.
Ying Chen et al (2009) used aWeb 1T 5-gram corpus released by Googleto extract additional features for clustering.Masaki Ikeda et al (2009) proposed a two-stage clustering algorithm to improve the lowrecall values.
In the first stage, some reliablefeatures (like named entities) are used to con-nect documents about the same person.
Af-ter that, the connected documents (documentcluster) are used as a source from which newfeatures (compound keyword features) are ex-tracted.
These new features are used in thesecond stage to make additional connectionsbetween documents.
Their approach is to im-prove clusters step by step, where each steprefines clusters conservatively.
Han & Zhao(2009) presented a system named CASIANEDto disambiguate personal names based on pro-fessional categorization.
They first catego-rize different personal name appearances intoa real world professional taxonomy, and thenthe personal name appearances are clusteredinto a single cluster.
Chen Chen et al (2009)explored a novel feature weight computingmethod in clustering.
It is based on the point-wise mutual information between the ambigu-ous name and features.
In their paper, theyalso develop a trade-off point based clusterstopping criteria which find the trade-off pointbetween intra-cluster compactness and inter-cluster separation.Our approach is based on Chinese per-sonal name extension.
We recognize the fullpersonal names in Chinese text and performdocument clustering under different personalnames.3 MethodologyIn this section, we will explain preprocess-ing, unrelated documents discarding, Chinesepersonal name extension and document clus-tering in order.3.1 PreprocessingWe use ltp-service2 to process the given Chi-nese personal name disambiguation dataset(a detailed introduction to it will be givenin section 4).
Training data in the datasetcontains 32 query names.
There are 100-300documents under every query name.
All thedocuments are collected from Xinhua NewsAgency.
They contain the exact same stringas query names.
Ltp-service is a web ser-vice interface for LTP3(Language TechnologyPlatform).
LTP has integrated many Chineseprocessing modules, including word segmen-tation, part-of-speech tagging, named entityrecognition, word sense disambiguation, andso on.
Jun Lang et al (2006) give a detailedintroduction to LTP.
Here we only use LTPto generate word segmentation, part-of-speechtagging and named entity recognition resultsfor the given dataset.3.2 Unrelated documents discardingUnder every query name, there are 100-300documents.
But not all of them are really re-lated.
For example, ????
is a query name intraining data.
In corresponding documents,some are refered to real personal names like????
or ?????.
But others may be a sub-string of an expression such as ????????.
These documents are needed to be fil-tered out.
We use the preprocessing tool LTPto slove this problem.
LTP can do word seg-mentation and part-of-speech tagging for us.For each document under a given query name,if the query name in the document is tagged asa personal name or part of some extended per-sonal name, the document will be marked asundiscarded, otherwise the document will bediscarded.
Generally speaking, for the queryname containing three characters, we don?tneed to discard any of the corresponding doc-uments.
But in practice, we find that for somequery names, LTP always gives the invariable2http://code.google.com/p/ltp-service/3http://ir.hit.edu.cn/ltp/part-of-speech.
For example, no matter whatthe context of ????
is, it is always taggedas a geographic name.
So we use another pre-processing tool ICTCLAS4.
Only when bothof them mark one document as discarded, wediscard the corresponding document.3.3 Chinese personal name extensionAfter discarding unrelated documents, weneed to recognize the full Chinese personalnames.
We hypothesize that the full Chinesepersonal name has not more than three char-acters (We don?t consider the compound sur-names here).
So the query names containingonly two Chinese characters are considered toextend.
In our approach, we use two Chinesepersonal names dictionaries.
One is a sur-name dictionary containing 423 one-characterentries.
We use it to do left extend for thequery name.
For example, the query nameis ????
and its left character in a docu-ment is ??
?, we will extend it to full per-sonal name ?????.
The other is a non-ending Chinese character dictionary contain-ing 64 characters which could not occur at theend of personal names.
It is constructed by apersonal title dictionary.
We use every title?sfirst character and some other special charac-ters (such as numbers or punctuations) to con-stuct the dictionary.
Some manual work hasalso been done to filter a few incorrect charac-ters.
Several examples of the two dictionariesare shown in Table 1.Through the analysis of Xinhua News arti-cles, we also find that nearly half of the docu-ments under given query name actually referto the reporters.
And they often appear inthe first or last brackets in the body of cor-responding document.
For example, ?(??????????)?
is a sentence containingquery name ????.
We use some simple butefficient rules to get full personal names forthis case.3.4 Document clusteringFor every query name, we can get a list offull peronal names.
For example, when the4http://ictclas.org/Table 1: Several Examples of the two DictionariesDictionaries ExamplesSurnames ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?...Non-ending Chinese characters ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?...query name is ???
?, we can get the per-sonal names like ????
?, ????
?, ????
?, ?????.
And then document clusteringis performed under different personal names.3.4.1 FeaturesWe use bag of words to represent docu-ments.
Some representative words need to bechosen as features.
LTP can give us POS tag-ging and NER results.
We select all the nouns,verbs and named entities which appear in thesame paragraph with given query name as fea-tures.
Meanwhile, the bigrams of nouns orverbs are also selected.
We take 0 or 1 forfeature weight value.
0 represents that thefeature doesn?t appear in corresponding para-graphs, and 1 represents just the opposite.
Wefind that this weighting scheme is more effec-tive than TFIDF.3.4.2 ClusteringAll features are represented in vector spacemodel.
Every document is modeled as a ver-tex in the vector space.
So every documentcan be seen as a feature vector.
Before cluster-ing, the similarity between documents is com-puted by cosine value of the angle betweenfeature vectors.
We use HAC to do documentclustering.
It is a bottom-up algorithm whichtreats each document as a singleton cluster atthe outset and then successively merges (oragglomerates) pairs of clusters until all clus-ters have been merged into a single clusterthat contains all documents.
From our ex-perience, single link and group-average linkmethod seem to work better than completelink one.
We use group-average link methodin the final submission.
The stopping criteriais a difficult problem for clustering.
Here weuse a threshold for terminating condition.
Soit is not necessary to determine the numberof clusters beforehand.
We select a thresholdwhich produces the best performance in train-ing data.4 Experimental ResultsThe dataset for Chinese personal name dis-ambiguation task contains training data andtesting data.
The training data contains32 query names.
Every query name foldercontains 100-300 news articles.
Given thequery name, all the documents are retrivedby character-based matching from a collectionof Xinhua news documents in a time span offourteen years.
The testing data contains 25query names.
Two threshold values as termi-nating conditions are obtained from trainingdata.
They are 0.4 and 0.5.
For evaluation,we use P-IP score and B-cubed score (Baggaand Baldwin, 1998).
Table 2 & Table 3 showthe official evaluation results.Table 2: Official Results for P-IP scoreThreshold P-IPP IP F score0.4 88.32 94.9 91.150.5 91.3 91.77 91.18Table 3: Official Results for B-Cubed scoreThreshold B-CubedPrecision Recall F score0.4 83.68 92.23 86.940.5 87.87 87.49 86.84Besides the formal evaluation, the organizeralso provide a diagnosis test designed to ex-plore the relationship between Chinese wordsegmentation and personal name disambigua-tion.
That means the query names in thedocuments are segmented correctly by manualwork.
Table 4 & Table 5 show the diagnosisresults.Table 4: Diagnosis Results for P-IP scoreThreshold P-IPP IP F score0.4 89.01 95.83 91.960.5 91.85 92.68 91.96Table 5: Diagnosis Results for B-Cubed scoreThreshold B-CubedPrecision Recall F score0.4 84.53 93.42 87.960.5 88.59 88.59 87.8The official results show that our methodperforms pretty good.
The diagnosis resultsshow that correct word segmentation can im-prove the evaluation results.
But the improve-ment is rather limited.
That is mainly becauseChinese personal name extension is done wellin our approach.
So the diagnosis results don?tgain much profit from query names?
correctsegmentation.5 ConclusionsWe describe our framework in this paper.First, we use LTP to do preprocessing for orig-inal dataset which comes from Xinhua newsarticles.
LTP can produce good results forChinese text processing.
And then we usetwo additional dictionaries(one is Chinese sur-name dictionary, the other is Non-ending Chi-nese character dictionary) to do Chinese per-sonal name extension.
After that we performdocument clustering under different personalnames.
Official evaluation results show thatour method can achieve good performances.In the future, we will attempt to use otherfeatures to represent corresponding persons inthe documents.
We will also investigate auto-matic terminating condition.6 AcknowledgmentsThis research is supported by NationalNatural Science Foundation of Chinese(No.60973053) and Research Fund for theDoctoral Program of Higher Education ofChina (No.20090001110047).ReferencesJ.
Artiles, J. Gonzalo, and S. Sekine.
2009.
WePS2 evaluation campaign: overview of the web peo-ple search clustering task.
In 2nd Web PeopleSearch Evaluation Workshop(WePS 2009), 18thWWW Conference.Bagga and B. Baldwin.
1998.
Entity-basedcross-document coreferencing using the vectorspace model.
In Proceedings of 17th Interna-tional Conference on Computational Linguis-tics, 79?85.Mann G. and D. Yarowsky.
2003.
Unsupervisedpersonal name disambiguation.
In Proceedingsof CoNLL-2003, 33?40, Edmonton, Canada.C.
Niu, W. Li, and R. K. Srihari.
2004.
WeaklySupervised Learning for Cross-document PersonName Disambiguation Supported by Informa-tion Extraction.
In Proceedings of ACL 2004.Al-Kamha.
R. and D. W. Embley.
2004.
Group-ing search-engine returned citations for person-name queries.
In Proceedings of WIDM 2004,96-103, Washington, DC, USA.Ying Chen, Sophia Yat Mei Lee, and Chu-RenHuang.
2009.
PolyUHK:A Robust InformationExtraction System for Web Personal Names.In 2nd Web People Search Evaluation Work-shop(WePS 2009), 18th WWW Conference.Masaki Ikeda, Shingo Ono, Issei Sato, MinoruYoshida, and Hiroshi Nakagawa.
2009.
PersonName Disambiguation on the Web by Two-StageClustering.
In 2nd Web People Search Evalua-tion Workshop(WePS 2009), 18th WWW Con-ference.Xianpei Han and Jun Zhao.
2009.
CASIANED:Web Personal Name Disambiguation Based onProfessional Categorization.
In 2nd Web PeopleSearch Evaluation Workshop(WePS 2009), 18thWWW Conference.Chen Chen, Junfeng Hu, and Houfeng Wang.2009.
Clustering technique in multi-documentpersonal name disambiguation.
In Proceed-ings of the ACL-IJCNLP 2009 Student ResearchWorkshop, pages 88?95.Jun Lang, Ting Liu, Huipeng Zhang and Sheng Li.2006.
LTP: Language Technology Platform.
InProceedings of SWCL 2006.Bagga, Amit and B. Baldwin.
1998.
Algorithmsfor scoring co-reference chains.
In Proceedingsof the First International Conference on Lan-guage Resources and Evaluation Workshop onLinguistic co-reference.
