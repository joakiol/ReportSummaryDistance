RESOLVING LEX ICAL  AMBIGUITY  IN  ADETERMIN IST IC  PARSERRober t  Mi lneIntelligent Applications10 Charlotte SquareEdinburgh EH2 4DR ScotlandLexical ambiguity and especially part-of-speech ambiguity is the source of much non-determinism inparsing.
As a result, the resolution of lexical ambiguity presents deterministic parsing with a major test.If deterministic parsing is to be viable, it must be shown that lexical ambiguity can be resolved easilydeterministically.
In this paper, it is shown that Marcus's "diagnostics" can be handled without anymechanisms beyond what is required to parse grammatical sentences and reject ungrammaticalsentences.
It is also shown that many other classes of ambiguity can be easily resolved as well.1 INTRODUCTIONLexical ambiguity, and especially part-of-speech ambigu-ity, is the source of much non-determinism in parsing.As a result, the resolution of lexical ambiguity presentsdeterministic parsing (Marcus 1980) with a major test.
Ifdeterministic parsing is to be viable, it should be shownthat lexical ambiguity can be resolved deterministicallyfor many situations in which people do not have trouble.In this paper, it is shown that Marcus's "diagnostics" canbe handled without any mechanisms beyond what isrequired to parse grammatical sentences and rejectungrammatical sentences and that many other classes ofambiguity can be easily resolved as well.
This result ispossible because of the constraints on English from wordorder and number agreement.Although many high-level constituents can be"moved" in English, the lower-level structure of someconstituents is relatively fixed.
For example, after adeterminer, one expects a noun rather than a verb.
Inthis paper we also wish to ask, "How might this low-levelfixed order assist in the resolution of ambiguity?"
Wewill not give a definite answer to this question, but willsee that it is extremely useful in the resolution of ambigu-ity.The examples of ambiguity shown in this paper seemto cause no apparent problems to a person reading them.That is, all of these examples read easily and certainly donot exhibit the garden path effect, except, of course, theexamples that are intended to be difficult.
If a parser isto be psychologically plausible, then it is desirable that ithandle these examples in such a way as to explain whypeople have no apparent difficulty with most sentences,despite the inherent ambiguity in them.In parsing English, one of the major causes of non-determinism is part-of-speech ambiguity.
If a word canbe two parts of speech, then a non-deterministic parsermay have to explore both possibilities.
If one claims tobe able to parse English deterministically, then the reso-lution of part-of-speech ambiguity is a very importantarea.It should be noted that a non-deterministic parser doesnot need to tackle the problem of local part-of-speechambiguity.
If it should make an error, then it can back-track and correct it.
Alternatively, it could maintain allpossible parses at once and throw some of them away.In deterministic parsing we are not allowed to use eitherbacktracking or parallelism.
Although this problem hasbeen investigated for many non-deterministic parsers, ithas not been the critical problem that it is for determinis-tic parsing.
To handle ambiguity deterministically, wemust never make an error.
As a result, our methods ofdisambiguation must be reliable.
We will see that manycases of ambiguity can be resolved using standard tech-niques that have been applied to non-deterministicparsers.If it is possible to handle all the examples of localambiguity presented here, with no additional mechanism,device or feature than is needed for ordinary sentenceparsing, then our goal above can be considered met.
One.Copyright1986 bythe Association for Computational Linguistics.
Permission tocopy without fee all or part of this material isgranted provided thatthe copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page.
To copyotherwise, or to republish, requires a fee and/or specific permission.0362-613X/86/010001-12503.00Computational Linguistics, Volume 12, Number 1, January-March 1986 1Robert Milne Resolving Lexical Ambiguity in a Deterministic Parserpossible explanation for the fact that people do notnotice local ambiguities may be that there is no specialmechanism needed for them, so that nothing differingfrom normal parsing is necessary.Conversely, if it is necessary to add special mech-anisms and routines to the parser just to handle theseexamples of ambiguity, then this will not explain howpeople can understand these examples o well and it canbe considered a weakness in the model.To say part-of-speech ambiguity can be handleddeterministically but with the use of special mechanismswould be no surprise and not very important.
To say onecan handle part-of-speech ambiguity deterministicallywith no special mechanisms i a more significant claim.In this paper it is indeed suggested that many cases ofpart-of-speech ambiguity can be handled by the parserwith no special mechanisms.This paper is a summary of a section of the author'sPh.D.
thesis (Milne 1983) with the same title anddescribes work done at the University of Edinburgh.That thesis presents ROBIE, a deterministic parser that isable to resolve lexical ambiguities and that is fully imple-mented in PROLOG.
ROBIE has two lookahead buffersand does not use Marcus's Attention Shift mechanism.This means that ROBIE scans the current token and onemore of lookahead.
PARSIFAL scanned the currenttoken and two lookahead cells.
In this paper, only localambiguities are addressed, that is, ambiguities that can beresolved within the sentence.
Global ambiguities, whichrequire context to resolve, are not discussed.
For thispaper, it is assumed that the reader is familiar with deter-ministic parsing and no other understanding of specificparsing mechanisms i  assumed.In the rest of this paper, we look at lexical ambiguityfrom simple examples to more complex ones.
We startwith how words are defined within the parser to beambiguous and how the morphology can be used toresolve ambiguities.
Next we look at how word orderand finally various types of agreement can be used toresolve most remaining ambiguities.2 SYNTACTIC CONTEXT2.1 WORD DATA STRUCTURESAs a first approach to handling ambiguity, it was asked," I f  we construct a compound lexical entry for each wordcomposed of the features of each part of speech the wordcan have and make no alterations to the grammar, howwide a coverage of examples will we get?
"This approach was used by Winograd (1972) and wasfound to be very effective for the following reason.
Eachword has all the possible relevant features for it.
There-fore, the test will succeed for each possible part of speechwith which a word can be used.
In this way, all applica-ble rules will match.
It may be that often only one rulewill match, or that the first rule tried is the correct rule.The question is, how often will the rule that matches bethe correct rule?All words in ROBIE are defined in the syntacticdictionaries.
Each word has a compound lexical entryincorporating all the features for all the possible parts ofspeech the word could have.
This is exactly as was doneby Winograd (1972).
For example, block is defined as anoun and a verb, can is defined as a noun, auxiliary verb,and verb, and hit is defined as a noun and a verb.
Thefeatures for each of these parts of speech are kept in thedictionary and, when the word is looked up, they arereturned as a single ordered list of features.
Thesefeatures are sub-grouped according to the part of speechthey are associated with.
Hence, when the word block islooked up, the result returned is both the noun and theverb definition.
In this way, all possibilities are returned.In the English language, most words can have severalparts of speech.
This fact must be reflected in a parser ofEnglish and we do this with the multiple meanings above.When the parser has enough information to decide whichis the correct part of speech, it ignores (removes) theother possibilities.
In this way, we have not built struc-ture that is later thrown away.
Although some may arguethat this is a form of parallelism, it seems necessary sinceit reflects the inherent parallelism of language.2.2 MORPHOLOGYThe first part of the disambiguation process takes placein the morphology.
When ROBIE identifies a word thathas a morphological ending, the morphology must adjustthe features of the word.
For example, when blocked isidentified, the feature "ed" must be added to the list offeatures for block.
At the same time, a portion of thedisambiguation takes place.
If block is defined as both anoun and a verb, then blocked is not a noun.
Themorphology causes some features to be added, such as"ed, past" and some features to be removed such as"tenseless."
As features that are no longer applicable areremoved, so also are parts of speech and their associatedfeatures that are no longer applicable.
For blocked, thefeatures "noun, ns, n3p" will be removed and thefeatures "adjective, ed, past" will be added.The morphology will identify words such as adverbs,adjectives, and verbs in a similar way.
The morphologyused is very similar to that of Winograd (1972) and ofDewar, Bratley, and Thorne (1969); the part-of-speechadditions and deletions are taken from Marcus (1980).Although this technique may seem obvious, it is includedto point out that a majority of the occurrences of part-of-speech ambiguity can be resolved or reduced on the basisof the morphology alone.2.3 DISAMBIGUATIONNow that we have allowed words to have multiple partsof speech and the morphology can be used to trim someof the ambiguity, we need a simple technique for disam-biguating words to a single part of speech.
Again, refer-ring to Occam's Razor, what is preferable is a simple andgeneral technique for all types of disambiguation.2 Computational Linguistics, Volume 12, Number 1, January-March 1986Robert Milne Resolving Lexical Ambiguity ina Deterministic ParserIn ROBIE each rule matches the features of one or twobuffer cells.
(The word buffer will be used interchangea-bly with cell.
That is, buffer and cell are the sameconcept.)
If the word block is in the first buffer cell, thena pattern \[noun\] or a pattern \[verb\] will match.
Thesepatterns do not relate to the other possible definitions ofa word.
If a rule pattern has matched on the feature"noun" in the first buffer cell, then ROBIE assumes thatthis word is a noun.
It would then be appropriate todisambiguate the word as a noun.
This is exactly as inWinograd (1972).In a non-deterministic parser, it is not essential to findthe correct rule first.
If the parser uns an incorrect rule,the parser may backtrack and change the categoryassignment.
But in a deterministic parser, there willnever be any backtracking, and this solution cannot beused.Since ROBIE does not backtrack, disambiguating theword when the pattern matches will always result in thesame disambiguation as if the word were disambiguatedin the grammar rule.
Once a rule runs assuming a buffercontains a certain part of speech, it must be used as suchin the parser.
The general disambiguation scheme is: if afull pattern matches a word as a certain part of speech,then it is disambiguated asthat part of speech.The compound lexical entries and pattern-matchingdisambiguation alone will handle many examples ofambiguity.
In the rest of this paper we see just what thiscan do for us.2.4 AN EXAMPLEGiven the above mechanisms - multiple definition anddisambiguation by the pattern matching, let us see how afew simple examples are handled.
Consider:(1) The falling block needs painting.We will look only at the words falling and block in thisexample.
The word falling is defined as a verb and anadjective in the dictionary and block is defined as a nounand a verb.While parsing this example, after the word the hasinitiated an NP and been attached to it as a determiner,the rules to parse adjectives are activated.
The ruleADJECTIVE has the pattern \[adj\], and matches the wordfalling.
Falling is then attached and disambiguated as anadjective.
Recognition of falling as a verb does notoccur.
As there are no more adjectives, ROBIE will acti-vate the rules to parse the headnoun.
(ROBIE's grammarassumes that all words between the first noun and thehead noun of an NP are nouns; see section 2.6.)
The ruleNOUN with the pattern \[noun\] will match on the wordblock, and it will be attached as a noun.
Hence block willalso be disambiguated without the verb use being consid-ered by ROBIE.Other ambiguities inside the noun phrase will behandled in a similar way.
This approach will usuallycover the situation of singular head nouns,verb/adjective ambiguity and many other pre-nominalambiguities.
This works because the noun phrase has avery strict word order.
When an ambiguous word isfound, only one of its meanings will be appropriate to theword order of the noun phrase at that point.
Thisapproach can be thought of as an extension of the basicapproach of the Harvard Predictive Analyzer (Kuno1965).This strategy will also often disambiguate main verbs.For example, consider the following sentences:(2) Tom hit Mary.
(3) Tom will hit Mary.
(4) The will gave the money to Mary.In (2), hit is the main verb.
In the dictionary, hit isalso defined as a noun, (as in card playing).
The parserwill attach Tom as the subject of the sentence and thenactivate the rules for the main verb.
Since hit has thefeature "verb", it will match that rule and be attachedand disambiguated asa verb.
Again, other possible partsof speech are not considered.The word will could be a noun or a modal as sentences(3) and (4) demonstrate.
In (3), will cannot be part ofthe headnoun with Tom, so the NP will be finished asabove.
The rules for the auxiliary will then be activatedand the word will then matches the pattern \[modal\] andis attached to the AUX.In (4), the word will is used as a noun.
Since itfollows the determiner, the rules for nouns will be acti-vated.
The word will then matches the pattern \[noun\]and attaches to the NP as a noun.The same approach will also disambiguate stop and runin the following sentence.
Since stop is sentence initialand can be a tenseless verb, the rule IMPERATIVE willmatch, and it will be disambiguated asa verb.
The wordrun, which can be a noun or a verb, will be handled aswill in (4).
(5) Stop the run.2.5 THE WORD TONOW let us consider a more difficult example, the wordto.
To is defined as an auxiliary verb and a preposition inROBIE, as illustrated by these sentences:(6) I want to kiss you.
(7) I will go to the show with you.In (6), to is the infinitive auxiliary, while in (7) to is apreposition.
This analysis is based on that of Marcus(1980:118).
Our two buffer cell lookahead is sufficientto disambiguate hese examples.The buffer patterns for the above sentences are:\[to&tenseless\] -~ embedded VP\[to&ngstart\] -~ PPBy looking at the following word, to can be disambigu-ated.
In (7), the word the cannot be a tenseless verb, sothe first pattern does not match.
In (6), the second buff-Computational Linguistics, Volume 12, Number 1, January-March 1986 3Robert Milne Resolving Lexical Ambiguity in a Deterministic Parserer does not have the feature "ngstart", so the rule doesn'tmatch.However, the above patterns will accept ungrammat-ical sentences.
To reject ungrammatical sentences, wecan use verb subcategorisation as a supplement to theabove rules.
One cannot say:(8) *I want to the school with you.
(9) *I will hit to wash you.In English, only certain verbs can take infinitivecomplements.
To can only be used as an auxiliary verbstarting a VP when the verb can take an infinitivecomplement.
Hence, by activating the rules to handle theVP usage only when the infinitive is allowed, the problemis partly reduced.
Also by classifying the verb for PPswith the preposition to, the problem is simplified.
This ismerely taking advantage of subcategorisation i  verbphrases.
Taking advantage of this subcategorisationgreatly reduces, but does not eliminate, the possibleconflict.We have seen what to do if the verb will only accept atoPP or a VP.
The final difficult situation arises whenev-er the following three conditions are true:?
the verb will accept a toPP and a toVP,?
the item in the second buffer has the features"tenseless" and "ngstart" and,?
the toPP is a required modifier of the verb.Although this situation rarely arises, the above rule willmake the wrong decision if the ambiguous word is beingused as a noun.
In this situation, ROBIE will make thewrong decision, and has no capability to better decide.By default, the principles of Right Association and Mini-mal Attachment apply as discussed in Frazier and Fodor(1978).A free text analysis done on a cover story in TIMEmagazine (1978) resulted in 55 occurrences of the wordto.
The two rules mentioned above in conjunction withverb subcategorisation gave the correct interpretation ofall of these.
These rules were also checked on theMECHO corpus (Milne 1983) and the ASHOK corpus(Martin, Church, and Patil 1981).
There were noviolations of these rules in either of these.2.6 ADJECTIVE/NOUN AND NOUN/NOUN AMBIGUITYAdjective/noun ambiguity is beyond the present scope ofthis research and is handled in a simple-minded way.
Ifthe word following the ambiguous adjective/noun wordcan be a noun, then the ambiguous word is used as anadjective.
In other words, all conflicts are resolved infavour of the adjective usage.
This problem arises inthese examples:(10) The plane is inclined at an angle of 30 degreesabove the horizontal.
(11) A block rests on a smooth horizontal table.In (10), horizontal is a noun, while in (11), it is anadjective.
The above algorithm handles these cases.This approach takes advantage of the lookahead of thedeterministic parser.
A word should be used as an adjec-tive if the following word can be an adjective or a noun.However, this approach would fail on examples uch as:(12) The old can get in for half price.
(13) The large student residence blocks my view.2.7 WHY DO THESE TECHNIQUES WORK?In this section we have seen many examples of the reso-lution of ambiguity.
To handle these examples, we mere-ly constructed a compound lexical entry for each word,composed of the features of each part of speech the wordcould be and allowed the pattern matching to performthe disambiguation.
This technique has been used byWinograd (1972).
Why does this work so well?English has a fairly strict structural order for all theexamples presented here.
Because of this, in each exam-ple we have seen, the use of the word as a different partof speech would be ungrammatical.
Although these tech-niques have been used for non-deterministic parsers,their effectiveness has not been investigated for a deter-ministic parser.Most ambiguities are not recognised by peoplebecause only one of the alternatives i grammatical.
Inmany situations, when fixed constituent structure is takeninto account, other uses of an ambiguous word are notpossible and probably not even recognised.
Since fixedconstituent structure rules out most alternatives, we havebeen able to handle the examples in this paper withoutany special mechanisms.
In the introduction to thispaper, it was stated that a clean and simple method ofhandling ambiguity was desired.
I feel that this goal hasbeen met for these examples.3 THE ROLE OF AGREEMENT IN HANDLING AMBIGUITYUsing the simple techniques presented in the lastsections, we can handle many cases of part-of-speechambiguity, but there are many examples we cannotresolve.
For example, the second of each pair ofsentences below would be disambiguated incorrectly.
(14) I know that boy is bad.
(15) I know that boys are bad.
(16) What boy did it?
(17) What boys do is not my business.
(18) The trash can be smelly.
(19) The trash can was smelly.Many people wonder what role person/number codesand the relatively rigid constituent structure in the verbgroup play in English.
In this section, we will exploretheir role by attempting to answer the question, "Whatuse is the fixed structure of the verb group andperson/number codes?
"4 Computational Linguistics, Volume 12, Number 1, January-March 1986Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser3.1 UNGRAMMATICAL SENTENCESBefore we proceed, let us look at an assumption Marcusmade in his parser, that it would be given only grammat-ical sentences.
This assumption makes life easy forsomeone writing a grammar, since there is no need toworry about grammatical checking.
Hence no provisionwas made for ungrammatical sentences and the originalparser accepted such examples as:(20) *A blocks are red.
(21) *The boy hit the girl the boy the girl.
(22) *Are the boy run?This simplification causes no problems in mostsentences, but can lead to trouble in more difficult exam-ples.
If the parser's grammar is loosely formulatedbecause it assumes it will be given grammatical examplesonly, then ungrammatical sentences may be accepted.
Ifthe syntactic analysis accepts ungrammatical sentences asgrammatical, then it is making an error.
Using grammat-ical constraints actually helps parsing efficiency anddisambiguation.
In the next sections we look at theconsequences of this assumption as well as those ofrejecting ungrammatical sentences.3.2 SUBJECT/VERB AGREEMENTWe know that the verb group has a complicated but rela-tively fixed constituent structure.
Although verbals havemany forms, they must be mixed in a certain rigid order.We also know that the first finite verbal element mustagree with the subject in person and number.
That is,one cannot say:(23) *The boy are run.
(24) *The boy will had been run.
(25) *The boys had are red.etc.While Marcus's parser enforced these observations tosome extent, he did not follow them throughout hisparser.
We want to enforce this agreement throughoutROBIE.
Checking the finite or main verb, to be sure thatit agrees in number with the subject, will lead to therejection of the above examples.
This was done byadding the agreement requirement into the pattern foreach relevant rule as will be explained later.Buffers 1 and 2 must agree before a rule relating thesubject and verb can match.
This check looks at thenumber code of the NP and the person/number code ofthe verb and checks whether they agree.
The routine forsubject/verb agreement is very general and is used by allthe subject/verb rules.
The routine can only check thegrammatical features of the buffers.3.3 MARCUS'S DIAGNOSTICSMarcus (1980) did handle some part-of-speech ambigui-ties.
The words to, what, which, that, and have could allbe used as several parts of speech.
For each of thesewords he also used a Diagnostic rule.
These Diagnosticrules matched when the word they were to diagnosearrived in the first buffer position and the appropriatepackets were active.
Each diagnostic would examine thefeatures of the three buffers cells and the contents of theActive Node Stack.
Once the diagnostic decided whichpart of speech the word was being used as, it eitheradded the appropriate features, or explicitly ran a gram-mar rule.
Marcus did not give each word a compoundlexical entry as we have done here.Most of the grammar ules in his parser were simpleand elegant, but the diagnostics tended to be verycomplex and contained many conditionals.
In some casesthey also seemed rather ad hoc and did not meet the goalof a simple, elegant method of handling ambiguity.For example, consider the THAT-DIAGNOSTIC:\[that\]\[np\] -* in the Packet CPOOL (Clause pool of rules)"If there is no determiner of secondand there is not a qp of secondand the nbar of 2nd is none of massn,npland 2nd is not-modifiablethen attach as detelse if c is nbarthen label 1 st pronoun, relative pronounelse label 1st complementiser.
"(Marcus 1980:291)Notice that if the word that were to be used as a deter-miner, then it would be attached after the NP was built!This is his primary rule for disambiguating the word that.Marcus's parser also had three other rules to handledifferent cases.It seems that these rules did not "elegantly capturegeneralisations" as did the rest of his parser.
I considerthese rules undesirable and feel that they should becorrected to comply with my criteria for simple andelegant techniques in resolving ambiguity.
I wanted amethod that used no special mechanism, or routine, otherthan that needed to parse grammatical sentences.
Thesediagnostics are certainly special mechanisms and do notmeet this goal.
Can we cover the same examples in amore simple and principled way?In this section, we look at each of these diagnostics inturn and show how they have been replaced in the newermodel.
We also look at a few other examples of ambigui-ty which Marcus did not handle, but are related to ourdiscussion here.3.4 HANDLING THE WORD TOThe handling of to by Marcus's diagnostic can bereplaced by the method outlined in Section 2.5.
Thismethod was motivated to handle grammatical sentencesand meets our criterion for a simple approach.3.5 HANDLING WHATAND WHICHFor both what and which, the ambiguity lies between arelative pronoun and a determiner.
The following exam-ples show various uses of both words:Computational Linguistics, Volume 12, Number 1, January-March 1986 5Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser(26) Which boy wants a fish?
det(27) Which boys want fish?
det(28) The river which I saw has many fish.
tel.
pron.
(29) What boy wants a fish?
det(30) What boys want is fish.
tel.
pron.There is some debate about the part of speech to beassigned the word which.
Some linguists consider it to bea quantifier (Chomsky 1965), while others consider it tobe a determiner (Akmajian and Heny 1975, Chapter 8).We shall adopt the determiner analysis, making the prob-lems for what and which similar.To determine the correct part of speech for these twowords, Marcus (1980:286) used the following diagnos-tics:\[which\] -~ in the packet CPOOL"If the NP above Current Node is not modifiedthen label 1st pronoun, relative pronounelse label 1st quant,ngstart,ns,wh,npl.
"\[what\]\[t\] -*- in the packet NPOOL"If 2nd is ngstart and 2nd is not detthen label 1st det,ns,npl,n3p,wh;activate parse detelse label 1st pronoun,relpron,wh.
"These diagnostics would make the word in question arelative pronoun if it occurred after a headnoun, or adeterminer if the word occurred at the start of a possiblenoun phrase.If we follow the approach in the last section, and giveeach word a compound lexical entry composed of thedeterminer and relative pronoun features, we find thatthese words are always made determiners unless theyoccur immediately after a headnoun.
In other words, thewhich examples are all parsed correctly, but (30) isparsed incorrectly.
This happens because the determinerrule will always try to match before the rule for WH ques-tions can take effect.
This simple step gives the correctanalysis if the ambiguous word is to be a determiner, butwill still err on (30).The rule to parse a relative pronoun and start a rela-tive clause is active only after the headnoun has beenfound.
At this time, the rule for determiners is notactive.
Therefore, if the word what or which is presentafter a headnoun, the only rule that can match is the ruleto use it as a relative pronoun, and it will be used as arelative pronoun.
We have resolved the simple case ofwhat as a relative pronoun using only the simple tech-niques of the last section.
For these sentences(31) What block is red?
(32) Which boy hit her?
(33) Which is the right one?ROBIE produces the correct analysis, but still errs on(30).
This error is because what is being used as a rela-tive pronoun but does not follow a headnoun.
Withoutany additional changes to the parser, we get two things.Firstly, if the word occurs after the headnoun, then theNP-COMPLETE packet rules are active, and it will be arelative pronoun.
In fact, since relative clauses can occuronly after the end of an NP, this correctly resolves therelative pronoun uses.
If the word occurs at the start ofan NP, then it will be made a determiner.This approach as exactly the same effect and cover-age as did Marcus's diagnostics, but we have not neededany special rules to implement i .
It will now provide thecorrect interpretation for which, but will make someerrors for the word what.
Marcus's what-diagnostic willtreat what as a determiner whenever the item in thesecond buffer could start a NP.
This is usually correct,but what will be treated as a determiner in all of thefollowing:(34) What boys want is fish.
(35) What blocks the road?
(36) What climbs trees?
(37) What boys did you see?
(38) What blocks are in the road?
(39) What climbs did you do?In this paper, we are adopting the following analysisfor WH clefts such as (34).
The initial WH word, what isa relative pronoun and attached as the WH-COMP of thesubject S node.
The subject is the phrase What boyswant.
The main verb of the sentence is is and thecomplement fish.
The exact details are not important,only that the word what or which is a not determiner atthe start of a WH cleft.In sentences (34-36), the word what is not used as adeterminer.
In the analysis we are using, it is a relativepronoun and is used as the WH-COMP for the S. Insentences (37-39), the word what is used as a determiner.Marcus (1980:286) admits that this diagnostic producesthe incorrect result in this case.
His diagnostic will makewhat a determiner in all of these examples, as will myanalysis.One can also see that each of the above pairs is a pairof potential garden path sentences.
For each pair, thetwo buffers contain the same words.
Hence our two-buf-fer lookahead is not sufficient o choose the correct usageof the word what.
Using only two or three buffers, thereis no way to make what a relative pronoun when theheadnoun is plural but a determiner when it is singularfor all arbitrary sentences.With regard to the Semantic Checking Hypothesis(Milne 1982) then, it is suggested that this decision isbased on non-syntactic information.
I believe that into-nation is critical in these examples.
Unfortunately thereis insufficient experimental evidence to determine forcertain whether this is true.
Finally, the problem of whatand which as sentence initials, with no noun in the secondbuffer seems to arise very rarely.
I have found no exam-ples of this problem in free text analysis.The current parser (ROBIE) cannot obtain the extrainformation provided by intonation to help resolve thiscase.
As a result it follows Mareus's diagnostic andmakes what a determiner in each of the above cases.6 Computational Linguistics, Volume 12, Number 1, January-March 1986Robert Milne Resolving Lexieal Ambiguity in a Deterministic ParserThis is because what is defined as a determiner that canagree with either a singular noun or a plural noun, as itwas in Marcus's parser.3.6 HANDLING THATIn ROBIE, that is defined as a singular determiner, apronoun, a relative pronoun, and a complementiser.Marcus had four diagnostics to handle the word that.
Wehave seen one of these at the start of this section.
In thissub-section we see how these four diagnostics can bereplaced in a simple way.
Let us consider how to handlethe uses of that one at a time.Firstly, as a determiner.
The following sentences illus-trate the problem in identifying this usage.
(40) I know that boy should do it.
(41) I know that boys should do it.Marcus assumed that PARSIFAL would be given onlygrammatical sentences to parse.
If determiner/numberagreement is not given to a parser, then it will, incorrect-ly, make that a determiner in (41), producing the wronganalysis.
The way to prevent his is to enforce numberagreement in the rule DETERMINER by insisting that thedeterminer agree with the noun in number.
The deter-miner usage will be grammatical only when the headnounhas the same number.
If we make this a condition for therule to match, then that will not be made a determiner in(41) and ROBIE will get the correct parse.For this case, the agreement check would make surethat one of the following patterns match:\[det,ns\] \[noun,ns\]\[det,npl\] \[noun,npl\]The above two cases are handled properly becausenumber agreement blocks the interpretation of the (41)as a determiner.
This approach leads to the correct pref-erence, when there is an ambiguity and accounts for thedifficulty in (42) versus (43):(42) That deer ate everything in my garden surprisedme.
(43) That deer ate everything in my garden last night.The second experiment in Milne (1983), showed that(42) is a garden path sentence, while (43) is not.
In bothsentences, it is believed the subject uses the word that asa determiner.
Deer is both singular and plural, so it fitsthe above rule.
In (42), that must be used as a complem-entiser to make the sentence grammatical.
The approachoutlined above will use that as a determiner in an ambig-uous case such as this.These two simple techniques, word order and agree-ment, are sufficient to handle all the examples we havejust presented.
In addition, free text analysis has shownno violations to this approach (Milne 1983).
These tech-niques provide the same coverage as Marcus's diagnostic,with the added bonus that the determiner is attachedbefore the NP is built.That can only be a complementiser when a that S- isexpected.
Hence the rules using that to start an embed-ded sentence are only activated when the verb has thefeature THAT-COMP.
The rules in THAT-COMP will firewhen that is followed by something that can start an NP.This ensures that the S- will have a subject and meansthat that will be taken as a pronoun in the followingsentences:(44) I know that hit Mary.
(45) I know that will be true.but it will be taken as a complementiser in thesesentences:(46) I know that boys are mean.
(47) I know that Tom will hit Mary.It seems that, unless the S- has a subject, the pronounuse of that is preferred.
Otherwise one would have acomplementiser followed by a trace, rather than aunmarked complementiser, followed by a pronoun.
Thisrule provides more complete coverage than Marcus'sdiagnostic since it examines the second buffer.The rule to handle pronouns in general is of low prior-ity and will only fire after all other uses have failed tomatch.
That is treated in the same way.That will be identified as a relative pronoun only if itoccurs after a headnoun and the packet NP-COMPLETEis active.
This situation will be handled in the samemanner as the usual relative clause rules and will thencover:(48) I know the boy that you saw.
(49) I know the boy that hit you.The most difficult case for that is when the verb issubcategorised:VNPS-That is, it can take an NP subject, followed by a that S-.For these examples, ROBIE may have to decide if theseries of words following that is a relative clause or anembedded sentence.In the following sentences, the lookahead would haveto be more than three buffers.
(Brackets indicate wordsin the buffers.
The last word is the disambiguatingword.
)(50) I told the girl \[that\]\[the\]\[boy\] hit the story(51) I told the girl \[that\]\[the\]\[boy\] will kiss herIt can be seen that in these sentences the disambiguat-ing word is outside our three buffers.
How do peoplehandle these, and what should our parser do?
In Milne(1983) it was shown that when the syntax could notresolve the ambiguity with its two-buffer lookahead, thedecision of which interpretation to use might be madeusing non-syntactic nformation.
It was also stated that ifcontext can affect the interpretation of the sentence, thennon-syntactic information is being used to select theComputational Linguistics, Volume 12, Number 1, January-March 1986 7Robert Milne Resolving Lexical Ambiguity in a Deterministic Parserinterpretation.
The reader can experiment for himselfand see that context does affect the interpretation ofthese sentences.
Therefore it is predicted that non-syn-tactic information is being used to interpret thesesentences, and that this problem should be resolved noton a semantic basis but on a non-syntactic one.This explains why some of these examples cause diffi-culty and others do not.
The psychological evidencefrom cases using that is scant, and I feel no conclusionscan be reached here.
My theory predicts that contextwill strongly affect these examples and, if they arestrongly biased to the incorrect reading, a garden pathshould result.One well-known example in this area is (52):(52) I told the girl that I liked the story.
(53) I told the girl whom I liked the story.
(54) I told the girl the story that I liked.These examples were tested in Milne (1983).
The resultssuggested that (52) was read faster than the other twoexamples.
Many of the subjects were questionedinformally after the experiment about their interpretationof the sentence.
All reported only one meaning; the S-reading.
None of the subjects aid that they noticed therelative clause reading, hence the result.
The experimenthowever, was not designed formally to distinguish these.To handle the examples we have seen in this section,Marcus had four diagnostics, one of which was verycomplicated.
I have just shown how to handle all fourcases of that without any special rules, merely substitut-ing enforced agreement and rejecting ungrammaticalsentences.3.7 HANDLING THE WORD HA VELet us now look at the elimination of Marcus'sHAVE-DIAGNOSTIC in relation to the use of agreementwe have been discussing in this section.
The problemwith have is illustrated by the following sentences:(55) Have the students take the exam.
(56) Have the students taken the exam?In these, we must decide if have is an auxiliary verb or amain verb and whether the sentence is a yes-no questionor an imperative.
The sentences have the same initialstring until the final morpheme on take.
To handle thiscase, Marcus (1980:211) used this rule:"RULE HAVE-DIAG PRIORITY:5 IN SS-START\[have,tenseless\]\[np\]\[t\] -~If 2nd is ns,n3p or 3rd is tenselessthen run imperative next elseIf 3rd is not verbthen run yes-no-question nextelse if not sure, assume it's a y/n-q and run yes-no-question ext".
"This rule seems to be necessary in order to distinguishbetween the question and the imperative.
If one tries toascertain exactly what occurs, the apparent complexity isrevealed.
Note also that Marcus's rule defaults to a yes-no question twice in this diagnostic.
The followingsentences illustrate the distinction this rule makes.
(57) Have the boy take the exam.
(58) Have the boy taken the exam.
(59) Have the boys take the exam.
(60) Have the boys taken the exam?It can be seen that YES-NO QUESTION should runonly when the NP following is plural and the verb has"en" (i.e., taken).
\[Only (60) has a plural noun, the boys,and the verb taken.\] This can also be understood as: thesentence is an imperative if the item in the 2nd buffer isnot plural and the verb is tenseless.
Thus, the first threeexamples above are Imperatives because ither the noun(boy) is singular (57 and 58) or the verb is tenseless (59).The second part of the rule takes care of the fact that thethird buffer must contain a verb for the imperative, asthis would be the main verb of the embedded sententialobject.Let us 10ok more closely at the reason why only (60)is a question.
Firstly, if the sentence is a yes-no question,then aux-inversion must occur.
When this happens, Havewill be adjacent o the verb that was in the third buffer.In order for ROBIE to continue, the verb must have an"en" ending, or have and the next verb will not agree inaspect.
This is the basis for discrimination in the earlierexamples (57-60).Secondly, in (57) and (58), the noun phrases aresingular and both sentences are imperatives.
Had thesentence been a yes-no question, have would need toagree with the subject, which must then be plural.Hence, in effect, Marcus's rule checks for numberagreement between the subject and verb, and checks thatthe fixed order of the verb group is obeyed.
Let us nowlook at other situations where this is necessary.PARSIFAL would accept he following ungrammaticalstrings:(61) *Are the boy running?
(62) *Has the boys run?
(63) *Has the boy kissing?
(64) *Has the boy kiss?For a yes-no question, the inverted auxiliary mustagree with the verb after it has been inverted.
To stopthese ungrammatical constructions, we must enforce verbagreement.
The pattern for the rule YES-NO QUESTIONshould be:\[auxverb\]\[np\]\[verb\], agree(auxverb,verb),agree(verb,np).This constraint enforces agreement of the verb andauxiliary verb and the subject and verb.
Again this checkis based only on the linguistic features of the buffers.Such a constraint effectively blocks the ungrammaticalconstructions.
(The parser will fail if the auxiliary hasbeen inverted, since the auxiliary will not be parsed.
)Also the subject NP must agree with the auxiliary verb,so we can also add "agree(auxverb,np)" to the rule, as8 Computational Linguistics, Volume 12, Number 1, January-March 1986Robert Milne Resolving Lexical Ambiguity in a Deterministic Parserwe did with the HAVE-DIAGNOSTIC!
So, by correctingthe yes-no question rule, the HAVE-DIAGNOSTIC isredundant.In this section we have seen that Marcus'sHAVE-DIAGNOSTIC can be replaced by merely exploit-ing agreement.
It should be pointed out that althoughthis approach has the same coverage as Marcus's diag-nostic, it is wrong in some cases.
Milne (1983) has a fulldiscussion.3.8 PLURAL HEAD NOUNSThere is a class of ambiguities that can be resolved mere-ly by enforcing subject/verb agreement.
In this section,we see an example from the class of words with thefeatures noun, verb, final-s (plural).
If we have twowords that can be a plural noun or a singular verb, wecan enumerate four cases.
Let us look at these possibil-ities and see that these cases can be disambiguated bysimple rules using subject/verb agreement.
The follow-ing examples illustrate all the possibilities:(65) The soup pot cover handle screw is red.
(66) The soup pot cover handles crew tightly.
(67) *The soup pot cover handles crews tightly.
{68} The soup pot cover handle screws tightly.
{69} The soup pot cover handle screws are red.Each of the words pot, cover, handle, and screw can beeither a noun or a verb.
The "end of constituent" prob-lem is to find out which word is used as the verb andwhich words make up the complex headnoun.
The possi-ble distributions of the morpheme "s" among two wordsgives us four cases.
We deal with each of these in turn.Case 1: In (65) each noun is singular.
For this case allambiguous words must be nouns and part of the head-noun.
Due to subject/verb agreement, a singular nounmust match a 3rd person singular (v3s) verb, i.e, onewithout the letter "s".
This case excludes that possibilitysince none of the words have an "s" at the end.
Hencethey must all be nouns.Case 2: In (66) handles is a plural noun and each wordbefore it must be a noun.
When a singular noun/verbword follows handles, the word (screw) must be a verband handles is the last of the headnouns.
It is not possi-ble to use handles in this situation as a verb, and screw asa noun because of subject/verb agreement.Case 3: The examples in this case have two consec-utive plural nouns as in (67), where both words havenoun/verb ambiguity.
(Do not confuse plural "s" withpossessive "'s").When the first plural is a noun, then the second onecan be a verb only if it is part of a different constituent.Examples of this are the following.
(Sentences beginningwith "?"
are considered grammatical but unacceptable tomost readers.
)(70) ?The soup pot machine handles crews easily.
(71) The soup pot machine handles crew easily.
(72) Which years do you have costs figures for?
(73) Do you have a count of the number of salesrequests and the number of requests filled?\[(72) and (73) are from Martin, Church, and Patil(1981).\]Because there is a non-plural headnoun followed by aplural headnoun, this case is really a subset of Case 4.
Ingeneral, the problems and issues for Case 4 dominate theresolution of this ambiguity.Case 4: Sentences (68) and (69) both have the sameword initial string until after screws, but in (68) screws isa verb while in (69) screws is part of the headnoun.
Inthis situation, where the final word in a series is plural,each word before it must be a noun.
The word itself canbe either a noun or a verb, depending on what follows.These can be recognised as a pair of potential gardenpath sentences, as discussed in Milne (1982).
Therefore,this is the case to which the Semantic Checking Hypoth-esis applies and the predictions of Milne (1982) apply.In that paper, the idea of potential garden pathsentences is presented.
These are sentences that may ormay not lead to a garden path.
Each garden pathsentence has a partner, which is similar but not a gardenpath.
It is proposed that the decision as to how toresolve the ambiguity that may lead to a garden pathshould be made by semantics and not by syntax.
Thistheory is called the Semantic Checking Hypothesis.
Forfull details see Milne (1983).In this section, we have looked at resolving a simplecase of noun/verb ambiguity.
In order to resolve thisambiguity, it was necessary merely to exploit agreementbetween the subject and verb in number and person.Due to number and subject verb agreement, thesefacts have a linguistic base.
They rely on the fact that afinal "s" marks a plural noun but a singular verb.
If theverb is v3s (verb agrees with a 3rd person, singularnoun, as with the "s"), then the subject of the verb mustbe singular, or else the sentence is ungrammatical.
Thisis why all the words before the v3s word must be nouns.If any of these words were used as a verb, then subject-verb agreement would be violated.
This is why (67) isungrammatical.
If the verb is v-3s (agrees with anynoun phrase except 3rd person, singular i.e., no "s"),then the subject cannot be singular.
(65) has no pluralsubject and so cannot have a v-3s verb.
In (66) handlesprovides a plural subject, so screw, which is v-3s, canagree.3.9 NOUN/MODAL AMBIGUITYWe now consider noun/modal ambiguity as demon-strated by can and will.
Both can be either a noun or amodal (i.e., could, should, would, can, will, might, etc.
):(74) The trash can was taken out.
(75) The trash can be taken out.
(76) The paper will was destroyed.
(77) The paper will be destroyed.Computational Linguistics, Volume 12, Number 1, January-March 1986 9Robert Milne Resolving Lexical Ambiguity ina Deterministic ParserEach of these words is entered in the dictionary bothas a noun and a modal.
Due to agreement requirements,the modal/noun word can only be grammatically used asa modal if the word following it is a tenseless verb, i.e.,the pattern:\[modal\]\[tenseless\] -~ modal usageapplies.
Handling noun/modal ambiguity can be quiteeasy; when the noun modal word appears in the firstbuffer one merely has to look at the contents of thesecond buffer to see if it contains a tenseless verb.
Thiscan be complicated, though, if the auxiliary is inverted orthe sentence is an imperative.
The following examplesshow how this can arise:(78) Let the paper will be read.
(79) Will the paper can be re-used?In sentence (78) the fragment Let the paper impliesthat will can only be used as a noun, as the sentencealready has one tensed verb.
In the parser, thenoun/modal word is first encountered inside the NPpackets and the parser must decide whether to use theword as part of the headnoun or to leave it in the bufferto be used as a modal verb.
These rules do not knowwhether a verb has been found previously.
Hence, notall information from the sentence is used.
If all the infor-mation is available at the time the noun/modal ambiguityis being resolved, these sentences would be unambiguousand people would have no trouble reading them.Subjects were asked to read the above examples in thesecond experiment presented in Milne (1982).
Theresults showed convincingly that they are potentialgarden paths.
Many naive readers had considerablymore difficulty with them than with their more straight-forward counterparts.
This was predicted for reasonsexplained below.This result seems surprising.
If the subjects used allinformation available at the time the noun/modal  wordwas encountered, then they should have had no troublewith these sentences.
The fact that these are gardenpaths indicates that the readers did not use all the infor-mation available to them.
Notice also that the ambiguitycan be reformulated as: "Do we have the end of a nounphrase, or a complex headnoun?
"We have already seen a case where people do notseem to use all the information available to them.
InMilne (1983), several end-of-NP problems werepresented that could lead to a garden path.
In each ofthese, it was shown that the ambiguity was resolved onthe basis of non-syntactic nformation, without regard tothe following words in the sentence.
In other words, wesaw that the reader did not use all the information avail-able.
There is one crucial difference though.
In theprevious cases, non-syntactic information was usedbecause the syntactic processor with its limited lookaheadwas sometimes unable to choose the correct alternative.In this case, the information ecessary has already beenabsorbed by the parser.This suggests that the choice of alternatives i madelocally inside the NP parsing rules, without regard toinformation about the type of sentence being parsed.
Inother words, the two-buffer pattern applies regardless ofthe rest of the sentence.
This assumes that anoun/modal word followed by a tenseless verb is beingused as a modal.
This is similar to Fodor, Bever, andGarrett's (1974) old canonical sentoid strategy: abottom-up analysis that took every N-V combination as anew S. Let us look at why this might be true in theparser.When the parser starts to parse a NP, it creates a newNP node and pushes it to the bottom item of the ActiveNode Stack.
This operation makes the NP node theCurrent Active Node and parsing of the old CurrentActive Node is suspended.
If the parser is parsing an Snode, for example at the start of the sentence, then workon this node will be suspended until the NP node hasbeen completed and dropped into the buffer.In ROBIE, unlike PARSIFAL, the pattern matcher forthe grammar ules is allowed only to inspect the gram-matical features of the two buffers.
This means that theparser is unable to examine the contents of the ActiveNode Stack and, hence, the information that a tensedverb has already been found is unavailable to the NPparsing rules.
This then suggests that the ambiguity willbe resolved on the basis of local information only.It should be pointed out that although ROBIE does notexamine the Active Node Stack, the current packetreflects its contents.
For example, if the parser is parsingthe major S node, the packet SS-VP will be active, but ifthe parser is parsing an embedded S node, the packetEmbedded-S will be active.
This information can beconsidered to provide local context to the parsing rules.This is the same as in PARSIFAL.This ambiguity is an end-of-NP problem and thechoice of alternatives i made on the basis of limited andlocal information.
This suggests that non-syntactic nfor-mation may be used to resolve the ambiguity.
There isone further possibility.
The semantic hoice mechanismis attempting to find the end of an NP.
So far it hasasked the question, "Can this item be part of the NP?
"However, the end-of-NP problem can be reformulated as,"Is it better to use this as part of the NP, or'as the start ofthe verb group?"
It is conceivable that the end of NPmechanism uses will as the start of the verb group in themajority of occurrences, hence leading to the apparentmodal preference in these examples:(80) The trash can hit the wall.
(81) The paper will hit the table.Due to lack of data, it is not clear exactly what people doin this situation and this would seem to provide an inter-esting area for further investigation.10 Computational Linguistics, Volume 12, Number 1, January-March 1986Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser3.10 WHAT ABOUT HERAnother problem is the word her, which can be used as apronoun or as a possessive pronoun.
Note that we cansay:(82) Tom kissed her.
(83) Tom kissed her sister.Clearly in (82) her is a pronoun and in (83) her is apossessive determiner.
When multiple part-of-speechdefinitions were added to ROBIE and the simple disam-biguation method used, ROBIE always made her a posses-sive determiner.This difficulty arose in Marcus's parser because therule to start a NP was ordered before the rule to parse apronoun.
These rules were copied directly into ROBIE'sgrammar.
Since the word her has both the features"ngstart" and "pronoun", it could match both rules.Unfortunately, as Marcus's rules were stated, it alwaysmatched the NP starting rule, and hence was used as adeterminer by the parser.
This indicates one problemthat can arise in the writing of a parser grammar.To handle possessive determiners, PARSIFAL andROBIE have a rule with the pattern:\[poss__np\]This rule will match a possessive pronoun after it hasbeen made into an NP.
It will also match any possessiveNP, such as: the boy's or the boy's mother's.
The rule thenadds the feature "determiner" to the NP, making it eligi-ble for the NP starting rule.
By degrading the possessiveNPs to determiners, both parsers easily handle examplesof left branching such as:(84) The boy's mother's brother is his uncle.Another problem arose in (82) because the possessiveNP rule was not sufficiently constrained.
It is possible touse her as a determiner only where the next word can bepart of a noun phrase with that determiner.
To enforcethis, the second buffer is checked to be certain that itscontents will take the determiner.
Using this approach,her in (82) would not be converted to a possessive deter-miner.
The rule DETERMINER can run only if the nextitem will "take a determiner".This check is made by the syntactic category of thefollowing word, rather than by a specially markedfeature.
This check could be done by having a list of allthe possible categories as the pattern of the second buff-er.
As an implementation detail, this is in the form of anagreement check, merely to simplify this rule and to showits generality.The only remaining problem occurs when the verb cantake one or more objects and the item after the word hercan be either the second object, or an NP with her as adeterminer.
For example:(85) I took her grapes.
(86) He saw her duck.
(87) I gave her food for the dog.The examples presented above are all examples ofglobal ambiguity, which is discussed in more detail inMilne (1983).
In these cases the check of "Will-the nextword take a determiner?
", may or may not lead to thewrong analysis.
This problem also interacts with thetop-down component of verb phrase parsing and thesemantic restrictions presented by it.The conflict between the determiner and possessiveusage can be modelled as a conflict of rule priorities.
Ifthe possessive use is preferred, then this rule shouldmatch first.
Conversely, if the object use is preferred,then the object rule should match first.
Any error inreading these examples would be due to one rule havingpriority over the other, when the reverse should be thecase.
Finally, notice that with no help from either into-nation or context, either analysis is possible.
That is,there is not enough information in the sentence to deter-mine a unique interpretation.We have now shown how to replace all the diagnosticsMarcus used.
In doing this, we enforced number andverb agreement on the rules before they could run.
Thiswas motivated to reject ungrammatical items, rather thanfor the handling of ambiguity.
While there are still a fewproblems due to global ambiguity, the approach reportedhere has the same coverage as Marcus's diagnostics, andprovides a better explanation of why people have troubleon certain sentences.4 POSSIBLE USES FOR AGREEMENT IN ENGLISHIn this paper, we have seen several occurrences of ambi-guity, for each of which we have found a parallel situ-ation that could lead to acceptance of ungrammaticalsentences by ROBIE.
We then used person/numbercodes or the fixed structure of the verb group to blockthese unacceptable readings.
Most of our ambiguityproblems were also handled by this method.
Althoughthis has been used before with non-deterministic parsers,it was not obvious that it would provide enough informa-tion to enable deterministic parsing.Once person/number codes are taken into account,the number of potential ambiguous readings is dramat-ically reduced.
In many cases, only one of the ambiguouspossibilities was grammatical.
It should be noted thatthere are a few difficult cases which we have not hadtime to describe in this paper; these are discussed indetail in Milne (1983).Marcus had a few rules to resolve part of speech ambi-guity, but they were ad hoc.
We have seen that we canreplace these rules very simply by merely exploitingagreement.In the introduction, it was stated that handling lexicalambiguity was a major test for deterministic parsing.
Inthis paper we have seen that many cases of ambiguity can?
be resolved in a simple way.
This is possible because ofthe constraints imposed by number agreement and wordorder.
In fact, many cases of the seemingly difficultComputational Linguistics, Volume 12, Number 1, January-March 1986 11Robert Milne Resolving Lexical Ambiguity in a Deterministic Parserp rob lem of lexical ambigui ty  turn out - to  be easilyreso lved in a determinist ic  parser,  since the determinist icparser  uses more  in format ion  to make  decisions.REFERENCESAkmajian, A. and Heny, F. 1975 An Introduction tothe Principles ofTransformational Syntax.
MIT Press, Cambridge, Massachusetts.Chomsky, Noam 1965 Aspects of the Theory of Syntax.
MIT Press,Cambridge, Massachusetts.Dewar, H.; Bratley, P.; and Thorne, J.
1969 A Program for theSyntactic Analysis of English Sentences.
Communications f theACM 12(8).Fodor, Jerry; Bever, T.; and Garrett, M. 1974 The Psychology ofLanguage.
McGraw-Hill, New York, New York.Fodor, Janet and Frazier, Lynn 1978 The Sausage Machine: A NewTwo-Stage Parsing Mode.
Cognition 6: 291-325.Kuno, S. 1965 The Predictive Analyzer and a Path Elimination Tech-nique.
Communications f the ACM 8(10).Marcus, Mitchell 1980 A Theory of Syntactic Recognition for NaturalLanguage.
MIT Press, Cambridge, Massachusetts.Martin, William; Church, K; and Patil, R. 1981 Preliminary Analysisof a Breadth-First Parsing Algorithm: Theoretical nd ExperimentalResults.
MIT AI Lab.
Presented at Modeling Human Parsing Strat-egies Symposium, Austin, Texas.Milne, Robert 1982 Predicting Garden Path Sentences, CognitiveScience 6: 349-373.Milne, Robert 1983 Resolving Lexical Ambiguity in a DeterministicParser.
D.Phil.
Dissertation, University of Edinburgh, Edinburgh,Scotland.TIME 9 January 1978 Good Ole Burt; Cool-eyed Clint.Winograd, Terry 1972 Understanding Natural Language.
AcademicPress, New York, New York.12 Computational Linguistics, Volume 12, Number 1, January-March 1986
