Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 321?324,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsTowards Cross-Lingual Textual EntailmentYashar Mehdad1,2, Matteo Negri1, Marcello Federico1FBK-Irst1, University of Trento2Trento, Italy{mehdad,negri,federico}@fbk.euAbstractThis paper investigates cross-lingual textualentailment as a semantic relation between twotext portions in different languages, and pro-poses a prospective research direction.
Weargue that cross-lingual textual entailment(CLTE) can be a core technology for sev-eral cross-lingual NLP applications and tasks.Through preliminary experiments, we aim atproving the feasibility of the task, and provid-ing a reliable baseline.
We also introduce newapplications for CLTE that will be explored infuture work.1 IntroductionTextual Entailment (TE) (Dagan and Glickman,2004) has been proposed as a generic framework formodeling language variability.
Given two texts Tand H, the task consists in deciding if the meaningof H can be inferred from the meaning of T. So far,TE has been only applied in a monolingual setting,where both texts are assumed to be written in thesame language.
In this work, we propose and inves-tigate a cross-lingual extension of TE, where we as-sume that T and H are written in different languages.The great potential of integrating (monolingual)TE recognition components into NLP architectureshas been reported in several works, such as ques-tion answering (Harabagiu and Hickl, 2006), infor-mation retrieval (Clinchant et al, 2006), informa-tion extraction (Romano et al, 2006), and documentsummarization (Lloret et al, 2008).To the best of our knowledge, mainly due tothe absence of cross-lingual TE (CLTE) recognitioncomponents, similar improvements have not beenachieved yet in any cross-lingual application.
Asa matter of fact, despite the great deal of attentionthat TE has received in recent years (also witnessedby five editions of the Recognizing Textual Entail-ment Challenge1), interest for cross-lingual exten-sions has not been in the mainstream of TE research,which until now has been mainly focused on the En-glish language.Nevertheless, the strong interest towards cross-lingual NLP applications (both from the market andresearch perspectives, as demonstrated by success-ful evaluation campaigns such as CLEF2) is, to ourview, a good reason to start investigating CLTE, aswell.
Along such direction, research can now ben-efit from recent advances in other fields, especiallymachine translation (MT), and the availability of: i)large amounts of parallel and comparable corpora inmany languages, ii) open source software to com-pute word-alignments from parallel corpora, and iii)open source software to set-up strong MT baselinesystems.
We strongly believe that all these resourcescan potentially help in developing inference mecha-nisms on multilingual data.Building on these considerations, this paper aimsto put the basis for future research on the cross-lingual Textual Entailment task, in order to allowfor semantic inference across languages in differentNLP tasks.
Among these, as a long-term goal, weplan to adopt CLTE to support the alignment of textportions that express the same meaning in differentlanguages.
As a possible application scenario, CLTE1http://pascallin.ecs.soton.ac.uk/Challenges/RTE/2www.clef-campaign.org/321can be used to address content merging tasks in tidymultilingual environments, such as commercial Websites, digital libraries, or user generated content col-lections.
Within such framework, as it will be dis-cussed in the last section of this paper, CLTE com-ponents can be used for automatic content synchro-nization in a concurrent, collaborative, and multilin-gual editing setting, e.g.
Wikipedia.2 Cross Lingual Textual EntailmentAdapting the definition of TE we define CLTE asa relation between two natural language portions indifferent languages, namely a text T (e.g.
in En-glish), and a hypothesis H (e.g.
in French), thatholds if a human after reading T would infer that His most likely true, or otherwise stated, the meaningof H can be entailed (inferred) from T .We can see two main orthogonal directions for ap-proaching CLTE: i) simply bring CLTE back to themonolingual case by translating H into the languageof T, or vice-versa; ii) try to embed cross-lingualprocessing techniques inside the TE recognition pro-cess.
In the following, we briefly overview and mo-tivate each approach.Basic approaches.
The simplest approach is toadd a MT component to the front-end of an existingTE engine.
For instance, let the French hypothesisH be translated into English and then run the TE en-gine on T and the translation of H. There are sev-eral good reasons to follow this divide-and-conquerapproach, as well as some drawbacks.
Decouplingthe cross-lingual and the entailment components re-sults in a simple and modular architecture that, ac-cording to well known software engineering princi-ples, results easier to develop, debug, and maintain.Moreover, a decoupled CLTE architecture would al-low for easy extensions to other languages as it justrequires extra MT systems.
Along the same idea ofpivoting through English, in fact, the same TE sys-tem can be employed to perform CLTE between anylanguage pair, once MT is available from each lan-guage into English.
A drawback of the decoupledapproach is that as MT is still far from being perfect,translation errors are propagated to the TE engineand might likely affect performance.
To cope withthis issue, we explored the alternative approach ofapplying TE on a list of n-best translations providedby the MT engine, and take a final decision based onsome system combination criterion.
This latter ap-proach potentially reduces the impact of translationerrors, but might significantly increase the computa-tional requirements of CLTE.Advanced approaches.
The idea is to move to-wards a cross-lingual TE approach that takes advan-tage of a tighter integration of MT and TE algo-rithms and techniques.
This could result in methodsfor recognizing TE across languages without trans-lating the texts and, in principle, with a lower com-plexity.
When dealing with phrase-based statisticalMT (Koehn et al, 2007), a possible approach is toextract information from the phrase-table to enrichthe inference and entailment rules which could beused in a distance based entailment system.
As anexample the entailment relations between the Frenchphrase ?ordinateur portable?
and the English phrase?laptop?, or between the German phrase ?europaeis-chen union?
and the English word ?Europe?
couldbe captured from parallel corpora through statisticalphrase-based MT approaches.There are several implications that make this ap-proach interesting.
First of all, we believe that re-search on CLTE can employ inference mechanismsand semantic knowledge sources to augment exist-ing MT methods, leading to improvements in thetranslation quality (e.g.
(Pado?
et al, 2009)).
Inaddition, the acquired rules could as well enrichthe available multilingual resources and dictionariessuch as MultiWordNet3.3 Feasibility studiesThe main purpose of our preliminary experiments isto verify the feasibility of CLTE, as well as settingbaseline results to be further improved over time.
Tothis aim, we started by adopting the basic approachpreviously discussed.
In particular, starting from anEnglish/French corpus of T-H pairs, we automati-cally translated each H fragment from French intoEnglish.Our decisions build on several motivations.
Firstof all, the reason for setting English and Frenchas a first language pair for experiments is to relyon higher quality translation models, and largeramounts of parallel data for future improvements.3http://multiwordnet.fbk.eu/322Second, the reason for translating the hypotheses isthat, according to the notion of TE, they are usuallyshorter, less detailed, and barely complex in terms ofsyntax and concepts with respect to the texts.
Thismakes them easier to translate preserving the origi-nal meaning.
Finally, from an application-orientedperspective, working with English Ts seems morepromising due the richness of English data available(e.g.
in terms of language variability, and more de-tailed elaboration of concepts).
This increases theprobability to discover entailment relations with Hsin other languages.In order to create a realistic and standard setting,we took advantage of the available RTE data, select-ing the RTE3 development set and manually trans-lating the hypotheses into French.
Since the man-ual translation requires trained translators, and dueto time and logistics constraints, we obtained 520translated hypotheses (randomly selected from theentire RTE3 development set) which built our bi-lingual entailment corpus for evaluation.In the initial step, following our basic approach,we translated the French hypotheses to English us-ing Google4 and Moses5.
We trained a phrase-base translation model using Europarl6 and NewsCommentary parallel corpora in Moses, applying a6-gram language model trained on the New YorkTimes portion of the English Gigaword corpus7.As a TE engine , we used the EDITS8 package(Edit Distance Textual Entailment Suite).
This sys-tem is an open source software package based onedit distance algorithms, which computes the T-Hdistance as the cost of the edit operations (i.e.
in-sertion, deletion and substitution) that are necessaryto transform T into H. By defining the edit distancealgorithm and a cost scheme (i.e.
which defines thecosts of each edit operation), this package is able tolearn a distance model over a set of training pairs,which is used to decide if an entailment relationholds over each test pair.In order to obtain a monolingual TE model, wetrained and tuned (Mehdad, 2009) our model on theRTE3 test set, to reduce the overfitting bias, since4http://translate.google.com5http://www.statmt.org/moses/6http://www.statmt.org/europarl/7http://www.ldc.upenn.edu8http://edits.fbk.eu/our original data was created over the RTE3 devel-opment set.
Moreover, we used a set of lexical en-tailment rules extracted from Wikipedia and Word-Net, as described in (Mehdad et al, 2009).
To be-gin with, we used this model to classify the cre-ated cross-lingual entailment corpus in three differ-ent settings: 1) hypotheses translated by Google, 2)hypotheses translated by Moses (1st best), and 3) theoriginal RTE3 monolingual English pairs.Results reported in Table 1 show that usingGoogle as a translator, in comparison with the orig-inal manually-created data, does not cause any dropin performance.
This confirms that merely trans-lating the hypothesis using a very good translationmodel (Google) is a feasible and promising direc-tion for CLTE.
Knowing that Google has one of thebest French-English translation models, the down-trend of results using Moses translator, in contrastwith Google, is not out of our expectation.
Tryingto bridge this gap brings us to the next round ofexperiments, where we extracted the n-best trans-Orig.
Google Moses Moses Moses1st best 30 best > 0.4Acc.
63.48 63.48 61.37 62.90 62.90Table 1: Results comparison over 520 test pairs.lations produced by Moses, to have a richer lexicalvariability, beneficial for improving the TE recogni-tion.
The graph in Figure 1 shows an incrementalimprovement when the n-best translated hypothesesare used.
Besides that, trying to reach a more mono-tonic distribution of the results, we normalized theranking score (from 0 to 1) given by Moses, and ineach step we chose the first n results over a normal-ized score.
In this way, having the hypotheses withthe score of above 0.4, we achieved the highest accu-racy of 62.9%.
This is exactly equal to adopting the30-best hypotheses translated by Moses.
Using thismethod, we could improve the performance up to1.5% above the 1st best results, achieving almost thesame level of performance obtained with Google.4 A possible application scenarioAmong the many possible applications, the task ofmanaging textual information in multiple languagesrepresents an ideal application scenario for CLTE.Along such direction, our long-term goal is to use323Figure 1: Accuracy gained by n-best Moses translations.CLTE components in the task of synchronizing thecontent of documents about the same topic (e.g.Wikipedia articles), written in different languages.Currently, multilingual Wikis rely on users to manu-ally translate different Wiki pages on the same sub-ject.
This is not only a time-consuming procedurebut also the source of many inconsistencies, as usersupdate the different language versions separately,and every update would require translators to com-pare the different language versions and synchronizethe updates.
Our goal is to automate this processby integrating MT and CLTE in a two-step processwhere: i) CLTE is used to identify text portions thatshould ?migrate?
from one page to the other, and ii)MT is used to actually translate these portions in theappropriate target language.The adoption of entailment-based techniques toaddress the multilingual content synchronizationtask looks promising, as several issues inherent tosuch task can be formalized as TE-related problems.Given two pages (P1 and P2), these issues includeidentifying (and then properly managing):1.
Text portions in P1 and P2 that express exactlythe same meaning (bi-directional entailment, or se-mantic equivalence) and which should not migrateacross pages;2.
Text portions in P1 that are more specific thanportions of P2 (unidirectional entailment betweenP2 and P1 or vice-versa) and should replace them;3.
Text portions in P1 describing facts that are notpresent in P2, and which should be added in P2 orvice-versa (the ?unknown?
cases in RTE parlance);4.
Meaning discrepancies between text portionsin P1 and text portions in P2 (?contradictions?
inRTE parlance).5 ConclusionThis paper presented a preliminary investigation to-wards cross-lingual Textual Entailment, focusing onpossible research directions and alternative method-ologies.
Baseline results have been provided todemonstrate the potentialities of a simple approachthat integrates MT and monolingual TE compo-nents.
Overall, our work sets a novel frameworkfor further studies and experiments to improve cross-lingual NLP tasks.
In particular, CLTE can be scaledto more complex problems, such as cross-lingualcontent merging and synchronization.AcknowledgmentsThis work has been partially supported by the EC-funded project CoSyne (FP7-ICT-4-24853)ReferencesS.
Clinchant, C. Goutte, and E. Gaussier.
2006.
Lex-ical entailment for information retrieval.
In Proc.ECIR?06.I.
Dagan and O. Glickman.
2004.
Probabilistic tex-tual entailment: Generic applied modeling of languagevariability.
Proc.
of the PASCAL Workshop of Learn-ing Methods for Text Understanding and Mining.S.
Harabagiu and A. Hickl.
2006.
Methods for using tex-tual entailment in open-domain question answering.In Proc.
COLING/ACL 2006.P.
Koehn et al 2007.
Moses: Open source toolkit forstatistical machine translation.
In Proc.
ACL07 Demoand Poster Sessions.E.
Lloret, O?.
Ferra?ndez, R. Mun?oz, and M. Palomar.2008.
A text summarization approach under the in-fluence of textual entailment.
In Proc.
NLPCS 2008.Y.
Mehdad, M. Negri, E. Cabrio, M. Kouylekov, andB.
Magnini.
2009.
Edits: An open source frameworkfor recognizing textual entailment.
In Proc.
TAC 2009.To appear.Yashar Mehdad.
2009.
Automatic cost estimation fortree edit distance using particle swarm optimization.In Proc.
ACL ?09.S.
Pado?, M. Galley, D. Jurafsky, and C. D. Manning.2009.
Textual entailment features for machine trans-lation evaluation.
In Proc.
StatMT ?09.L.
Romano, M. Kouylekov, I. Szpektor, I. Dagan, andA.
Lavelli.
2006.
Investigating a generic paraphrase-based approach for relation extraction.
In Proc.
EACL2006.324
