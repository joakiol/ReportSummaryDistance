Proceedings of the Linguistic Annotation Workshop, pages 191?196,Prague, June 2007. c?2007 Association for Computational LinguisticsPanel Session: Discourse AnnotationManfred StedeDept.
of LinguisticsUniversity of Potsdamstede@ling.uni-potsdam.deJanyce WiebeDept.
of Computer ScienceUniversity of Pittsburghwiebe@cs.pitt.eduEva Hajic?ova?Faculty of Math.
and PhysicsCharles Universityhajicova@ufal.ms.mff.cuni.czBrian ReeseDept.
of LinguisticsUniv.
of Texas at Austinbjreese@mail.utexas.eduSimone TeufelComputer LaboratoryUniv.
of Cambridgesht25@cl.cam.ukBonnie WebberSchool of InformaticsUniv.
of Edinburghbonnie@inf.ed.ac.ukTheresa WilsonDept.
of Comp.
ScienceUniv.
of Pittsburghtwilson@cs.pitt.edu1 IntroductionThe classical ?success story?
of corpus annotationare the various syntax treebanks that provide struc-tural analyses of sentences and have enabled re-searchers to develop a range of new and highly suc-cessful data-oriented approaches to sentence pars-ing.
In recent years, however, a number of corporahave been constructed that provide annotations onthe discourse level, i.e.
information that reaches be-yond the sentence boundaries.
Phenomena that havebeen annotated include coreference links, the scopeof connectives, and coherence relations.
Many ofthese are phenomena on whose handling there isnot a general agreement in the research community,and therefore the question of ?recycling?
corpora byother people and for other purposes is often diffi-cult.
(To some extent, this is due to the fact that dis-course annotation deals ?only?
with surface reflec-tions of underlying, abstract objects.)
At the sametime, the efforts needed for building high-qualitydiscourse corpora are considerable, and thus oneshould be careful in deciding how to invest those ef-forts.
One aspect of providing added-value with an-notation projects is that of shared corpora: If a vari-ety of annotation efforts is executed on the same pri-mary data, the series of annotation levels can yieldinsights that the creators of the individual levels hadnot explicitly planned for.
A clear case is the rela-tionship between coherence relations and connectiveuse: When both levels are marked individually andwith independent annotation guidelines, then after-wards the correlations between coherence relations,cue usage (and possibly other factors, if annotated)can be studied systematically.
This conception ofmulti-level annotation presupposes, of course, thatthe technical problems of setting annotation levelsin correspondence to one another be resolved.The panel on discourse annotation is organizedby Manfred Stede and Janyce Wiebe.
It aims atsurveying the scene of discourse corpora, exploringchances for synergy, and identifying desiderata forfuture corpus creation projects.
In preparation forthe panel, the participants have provided the follow-ing short descriptions of the various copora in whoseconstruction they have been involved.2 Prague Dependency Treebank(Eva Hajic?ova?, Prague)One of the maxims of the work on the Prague De-pendency Treebank is that one should not overlook,disregard and thus lose what the sentence structureoffers when one attempts to analyze the structure ofdiscourse, thus moving from ?the trees?
to ?the for-est?.
Therefore, we emphasize that discourse anno-tation should make use of every possible detail theannotation of the component parts of the discourse,namely the sentences, puts at our disposal.
Thisis, of course, not only true for the surface shape ofthe sentence (i.e., the surface means of expression),but (and most importantly) for the underlying repre-sentation of sentences.
The panel contribution willintroduce the (multilayered) annotation scenario ofthe Prague Dependency Treebank and illustrate thepoint using some of the particular features of the un-derlying structure of sentences that can be made useof in planning the scenario of discourse ?treebanks?.1913 SDRT in Newspaper Text(Brian Reese, Austin)We are currently working under the auspices ofan NSF grant to build and train a discourse parserand codependent anaphora resolution program totest discourse theories empirically.
The training re-quires the construction of a corpus annotated withdiscourse structure and coreference information.
Sofar, we have annotated the MUC61 corpus for dis-course structure and are in the process of annotatingthe ACE22 corpus; both corpora are already anno-tated for coreference.
One of the goals of the projectis to investigate whether using the right frontier con-straint improves the system?s performance in resolv-ing anaphors.
Here we detail some experiences wehave had with the discourse annotation process.An implementation of the extant SDRT (Asher andLascarides, 2003) glue logic for building discoursestructures is insufficient to deal with open domaintext, and we cannot envision an extended versionat the present time able to deal with the problem.Thus, we have opted for a machine learning basedapproach to discourse parsing based on superficialfeatures, like BNL.
To build an implementation totest these ideas, we have had to devise a corpus oftexts annotated for discourse structure in SDRT.Each of the 60 texts in the MUC6 corpus, and now18 of the news stories in ACE2, were annotated bytwo people familiar with SDRT.
The annotators thenconferred and agreed upon a gold standard.
Ourannotation effort took the hierarchical structure ofSDRT seriously and built graphs in which the nodesare discourse units and the arcs represent discourserelations between the units.
The units could either besimple (elementary discourse units: EDUs) or theycould be complex.
We assumed that in principle theunits were recursively generated and could have anarbitrary though finite degree of complexity.4 Potsdam Commentary Corpus(Manfred Stede, Potsdam)Construction of the Potsdam Commentary Corpus(PCC) began in 2003 and is still ongoing.
It is a1The Message Understanding Conference, www-nlpir.nist.gov/related projects/muc/.2The Automated Content Extraction program,www.nist.gov/speech/tests/ace/.genre-specific corpus of German newspaper com-mentaries, taken from the daily papers Ma?rkischeAllgemeine Zeitung and Tagesspiegel.
One centralaim is to provide a tool for studying mechanismsof argumentation and how they are reflected on thelinguistic surface.
The corpus on the one hand is acollection of ?raw?
data, which is used for genre-oriented statistical explorations.
On the other hand,we have identified two sub-corpora that are subjectto a rich multi-level annotation (MLA).The PCC176 (Stede, 2004) is a sub-corpus thatis available upon request for research purposes.
Itconsists of 176 relatively short commentaries (12-15 sentences), with 33.000 tokens in total.
Thesentences have been PoS-tagged automatically (andmanually checked); sentence syntax was anno-tated semi-automatically using the TIGER scheme(Brants et al, 2002) and Annotate3 tool.
In addition,we annotated coreference (PoCos (Krasavina andChiarcos, 2007)) and rhetorical structure accordingto RST (Mann and Thompson, 1988).
Our anno-tation software architecture consists of a variety ofstandard, external tools that can be used effectivelyfor the different annotation types.
Their XML outputis then automatically converted to a generic format(PAULA, (Dipper, 2005)), which is read into the lin-guistic database ANNIS (Dipper et al, 2004), wherethe annotations are aligned, so that the data can beviewed and queried across annotation levels.The PCC10 is a sub-corpus of 10 commentariesthat serves as ?testbed?
for further developing theannotation levels.
On the one hand, we are apply-ing recent guidelines on annotation of informationstructure (Go?tze et al, 2007).
On the other hand,based on experiences with the RST annotation, weare replacing the rhetorical trees with a set of dis-tinct, simpler annotation layers: thematic structure,conjunctive relations (Martin, 1992), and argumen-tation structure (Freeman, 1991); these are comple-mented by the other levels mentioned above for thePCC176.
The primary motivation for this step is thehigh degree of arbitrariness that annotators reportedwhen producing the RST trees (see (Stede, 2007)).By separating the thematic from the intentional in-formation, and accounting for the surface-oriented3www.coli.uni-saarland.de/projects/sfb378/negra-corpus/annotate.html192conjunctive relations (which are similar to what isannotated in the PDTB, see Section 6), we hope to?
make annotation easier: handling several ?sim-ple?
levels individually should be more effec-tive than a single, very complex annotationstep;?
end up with less ambiguity in the annotations,since the reasons for specific decisions can bemade explicit (by annotations on ?simpler?
lev-els);?
be more explicit than a single tree can be: if adiscourse fulfills, for example, a function bothfor thematic development and for the writer?sintention, they can both be accounted for;?
provide the central information that a ?tradi-tional?
rhetorical tree conveys, without loosingessential information.5 AZ Corpus(Simone Teufel, Cambridge)The Argumentative Zoning (AZ) annotation scheme(Teufel, 2000; Teufel and Moens, 2002) is con-cerned with marking argumentation steps in scien-tific articles.
One example for an argumentation stepis the description of the research goal, another anovert comparison of the authors?
work with rival ap-proaches.
In our scheme, these argumentation stepshave to be associated with text spans (sentences orsequences of sentences).
AZ?Annotation is the la-belling of each sentence in the text with one of theselabels (7 in the original scheme in (Teufel, 2000)).The AZ labels are seen as relations holding betweenthe meanings of these spans, and the rhetorical actof the entire paper.
(Teufel et al, 1999) reports oninterannotator agreement studies with this scheme.There is a strong interrelationship between the ar-gumentation in a paper, and the citations writers useto support their argument.
Therefore, a part of thecomputational linguistics corpus has a second layerof annotation, called CFC (Teufel et al, 2006) orCitation Function Classification.
CFC?
annotationrecords for each citation which rhetorical function itplays in the argument.
This is following the spirit ofresearch in citation content analysis (e.g., (Moravc-sik and Murugesan, 1975)).
An example for a ci-tation function would be ?motivate that the methodused is sound?.
The annotation scheme contains12 functions, clustered into ?superiority?, ?neutralcomparison/contrast?, ?praise or usage?
and ?neu-tral?.One type of research we hope to do in the futureis to study the relationship between these rhetori-cal phonemena with more traditional discourse phe-nomena, e.g.
anaphoric expressions.The CmpLg/ACL Anthology corpora consist of320/9000 papers in computational linguistics.
Theyare partially annotated with AZ and CFC markup.
Asubcorpus of 80 parallelly annotated papers (AZ andCFF) can be obtained from us for research (12000sentences, 1756 citations).
We are currently port-ing both schemes to chemistry in the frameworkof the EPSRC-sponsored project SciBorg.
In thecourse of this work a larger, more general AZ an-notation scheme was developed.
The SciBorg effortwill result in an AZ/CFC?annotated chemistry cor-pus available to the community in 2009.In terms of challenges, the most time-consumingaspects of creating this annotated corpus were for-mat conversions on the corpora, and cyclic adapta-tions of scheme and guidelines.
Another problem isthe simplification of annotating only full sentences;sometimes, annotators would rather mark a clauseor sometimes even just an NP.
However, we foundthese cases to be relatively rare.6 Penn Discourse Treebank(Bonnie Webber, Edinburgh)The Penn Discourse TreeBank (Miltsakaki et al,2004; Prasad et al, 2004; Webber, 2005) anno-tates discourse relations over the Wall Street Jour-nal corpus (Marcus et al, 1993), in terms of dis-course connectives and their arguments.
Followingthe approach towards discourse structure in (Webberet al, 2003), the PDTB takes a lexicalized approach,treating discourse connectives as the anchors of therelations and thus as discourse-level predicates tak-ing two Abstract Objects as their arguments.
An-notated are the text spans that give rise to these ar-guments.
There are primarily two types of connec-tives in the PDTB: explicit and implicit, the latterbeing inserted between adjacent paragraph-internalsentence pairs not related by an explicit connective.193Also annotated in the PDTB is the attribution ofeach discourse relation and of its arguments (Dineshet al, 2005; Prasad et al, 2007).
(Attribution itselfis not considered a discourse relation.)
A prelimi-nary version of the PDTB was released in April 2006(PDTB-Group, 2006), and is available for downloadat http://www.seas.upenn.edu/?pdtb.
This release only hasimplicit connectives annotated in three sections ofthe corpus.
The annotation of all implicit connec-tives, along with a hierarchical semantic classifica-tion of all connectives (Miltsakaki et al, 2005), willappear in the final release of the PDTB in August2007.Here I want to mention three of the challenges wehave faced in developing the PDTB:(I) Words and phrases that can function as con-nectives can also serve other roles.
(Eg, when can bea relative pronoun, as well as a subordinating con-junction.)
It has been difficult to identify all andonly those cases where a token functions as a dis-course connective, and in many cases, the syntacticanalysis in the Penn TreeBank (Marcus et al, 1993)provides no help.
For example, is as though always asubordinating conjunction (and hence a connective)or do some tokens simply head a manner adverbial(eg, seems as though .
.
.
versus seems more rushedas though .
.
.
)?
Is also sometimes a discourse con-nective relating two abstract objects and other times,an adverb that presupposes that a particular propertyholds of some other entity?
If so, when one andwhen the other?
In the PDTB, annotation has erredon the side of false positives.
(II) In annotating implicit connectives, we discov-ered systematic non-lexical indicators of discourserelations.
In English, these include cases of markedsyntax (eg, Had I known the Queen would be here,I would have dressed better.)
and cases of sentence-initial PPs and adjuncts with anaphoric or deicticNPs such as at the other end of the spectrum, addingto that speculation.
These cases labelled ALTLEX,for ?alternative lexicalisation?
have not been anno-tated as connectives in the PDTB because they arefully productive (ie, not members of a more eas-ily annotated closed set of tokens).
They compriseabout 1% of the cases the annotators have consid-ered.
Future discourse annotation will benefit fromfurther specifying the types of these cases.
(III) The way in which spans are annotated as ar-guments to connectives also raises a challenge.
First,because the PDTB annotates both structural andanaphoric connectives (Webber et al, 2003), a spancan serve as argument to >1 connective.
Secondly,unlike in the RST corpus (Carlson et al, 2003) or theDiscourse GraphBank (Wolf and Gibson, 2005), dis-course segments are not separately annotated, withannotators then identifying what discourse relationshold between them.
Instead, in annotating argu-ments, PDTB annotators have selected the minimalclausal text span needed to interpret the relation.This could comprise an embedded, subordinate orcoordinate clause, an entire sentence, or a (possi-bly disjoint) sequence of sentences.
As a result,there are fairly complex patterns of spans within andacross sentences that serve as arguments to differ-ent connectives, and there are parts of sentences thatdon?t appear within the span of any connective, ex-plicit or implicit.
The result is that the PDTB pro-vides only a partial but complexly-patterned coverof the corpus.
Understanding what?s going on andwhat it implies for discourse structure (and possiblysyntactic structure as well) is a challenge we?re cur-rently trying to address (Lee et al, 2006).7 MPQA Opinion Corpus(Theresa Wilson, Pittsburgh)Our opinion annotation scheme (Wiebe et al, 2005)is centered on the notion of private state, a gen-eral term that covers opinions, beliefs, thoughts, sen-timents, emotions, intentions and evaluations.
AsQuirk et al (1985) define it, a private state is a statethat is not open to objective observation or verifica-tion.
We can further view private states in terms oftheir functional components ?
as states of experi-encers holding attitudes, optionally toward targets.For example, for the private state expressed in thesentence John hates Mary, the experiencer is John,the attitude is hate, and the target is Mary.We create private state frames for three main typesof private state expressions (subjective expressions)in text:?
explicit mentions of private states, such as?fears?
in ?The U.S. fears a spill-over??
speech events expressing private states, such as?said?
in ?The report is full of absurdities,?194Xirao-Nima said.?
expressive subjective elements, such as ?full ofabsurdities?
in the sentence just above.Frames include the source (experiencer) of theprivate state, the target, and various properties suchas polarity (positive, negative, or neutral) and inten-sity (high, medium, or low).
Sources are nested.
Forexample, for the sentence ?China criticized the U.S.report?s criticism of China?s human rights record?,the source is ?writer, China, U.S.
report?, reflectingthe facts that the writer wrote the sentence and theU.S.
report?s criticism is the target of China?s criti-cism.
It is common for multiple frames to be createdfor a single clause, reflecting various levels of nest-ing and the type of subjective expression.The annotation scheme has been applied to acorpus, called the ?Multi-Perspective Question An-swering (MPQA) Corpus,?
reflecting its origins inthe 2002 NRRC Workshop on Multi-PerspectiveQuestion Answering (MPQA) (Wiebe et al, 2003)sponsored by ARDA AQUAINT (it is also called?OpinionBank?).
It contains 535 documents and atotal of 11,114 sentences.
The articles in the cor-pus are from 187 different foreign and U.S. newssources, dating from June 2001 to May 2002.
Pleasesee (Wiebe et al, 2005) and Theresa Wilson?s forth-coming PhD dissertation for further information, in-cluding the results of inter-coder agreement studies.ReferencesNicholas Asher and Alex Lascarides.
2003.
Logicsof Conversation.
Cambridge University Press, Cam-bridge.Sabine Brants, Stefanie Dipper, Silvia Hansen, WolfgangLezius, and George Smith.
2002.
The TIGER tree-bank.
In Proceedings of the Workshop on Treebanksand Linguistic Theories, Sozopol.Lynn Carlson, Daniel Marcu, and Mary Ellen Okurowski.2003.
Building a discourse-tagged corpus in theframework of rhetorical structure theory.
In J. vanKuppevelt & R. Smith, editor, Current Directions inDiscourse and Dialogue.
Kluwer, New York.Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, RashmiPrasad, Aravind Joshi, and Bonnie Webber.
2005.
At-tribution and the (non-)alignment of syntactic and dis-course arguments of connectives.
In ACL Workshopon Frontiers in Corpus Annotation, Ann Arbor MI.Stefanie Dipper, Michael Go?tze, Manfred Stede, and Till-mann Wegst.
2004.
Annis: A linguistic database forexploring information structure.
In InterdisciplinaryStudies on Information Structure, ISIS Working papersof the SFB 632 (1), pages 245?279.Stefanie Dipper.
2005.
XML-based stand-off represen-tation and exploitation of multi-level linguistic annota-tion.
In Rainer Eckstein and Robert Tolksdorf, editors,Proceedings of Berliner XML Tage, pages 39?50.James B. Freeman.
1991.
Dialectics and theMacrostructure of Argument.
Foris, Berlin.Michael Go?tze, Cornelia Endriss, Stefan Hinterwimmer,Ines Fiedler, Svetlana Petrova, Anne Schwarz, StavrosSkopeteas, Ruben Stoel, and Thomas Weskott.
2007.Information structure.
In Information structure incross-linguistic corpora: annotation guidelines formorphology, syntax, semantics, and information struc-ture, volume 7 of ISIS Working papers of the SFB 632,pages 145?187.Olga Krasavina and Christian Chiarcos.
2007.
PotsdamCoreference Scheme.
In this volume.Alan Lee, Rashmi Prasad, Aravind Joshi, Nikhil Dinesh,and Bonnie Webber.
2006.
Complexity of dependen-cies in discourse.
In Proc.
5th Workshop on Treebanksand Linguistic Theory (TLT?06), Prague.William Mann and Sandra Thompson.
1988.
Rhetoricalstructure theory: Towards a functional theory of textorganization.
TEXT, 8:243?281.Mitchell Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large scale anno-tated corpus of English: The Penn TreeBank.
Compu-tational Linguistics, 19:313?330.James R. Martin.
1992.
English text: system and struc-ture.
John Benjamins, Philadelphia/Amsterdam.Eleni Miltsakaki, Rashmi Prasad, Aravind Joshi, andBonnie Webber.
2004.
Annotating discourse connec-tives and their arguments.
In NAACL/HLT Workshopon Frontiers in Corpus Annotation, Boston.Eleni Miltsakaki, Nikhil Dinesh, Rashmi Prasad, Ar-avind Joshi, and Bonnie Webber.
2005.
Experimentson sense annotation and sense disambiguation of dis-course connectives.
In 4t Workshop on Treebanks andLinguistic Theory (TLT?05), Barcelona, Spain.Michael J. Moravcsik and Poovanalingan Murugesan.1975.
Some results on the function and quality of ci-tations.
Soc.
Stud.
Sci., 5:88?91.The PDTB-Group.
2006.
The Penn Discourse TreeBank1.0 annotation manual.
Technical Report IRCS 06-01,University of Pennsylvania.195Rashmi Prasad, Eleni Miltsakaki, Aravind Joshi, andBonnie Webber.
2004.
Annotation and data miningof the Penn Discourse TreeBank.
In ACL Workshopon Discourse Annotation, Barcelona, Spain, July.Rashmi Prasad, Nikhil Dinesh, Alan Lee, Aravind Joshi,and Bonnie Webber.
2007.
Attribution and its annota-tion in the Penn Discourse TreeBank.
TAL (TraitementAutomatique des Langues.Randolph Quirk, Sidney Greenbaum, Geoffry Leech, andJan Svartvik.
1985.
A Comprehensive Grammar of theEnglish Language.
Longman, New York.Manfred Stede.
2004.
The Potsdam commentary corpus.In Proceedings of the ACL Workshop on Discourse An-notation, pages 96?102, Barcelona.Manfred Stede.
2007.
RST revisited: disentangling nu-clearity.
In Cathrine Fabricius-Hansen and WiebkeRamm, editors, ?Subordination?
versus ?coordination?in sentence and text ?
from a cross-linguistic perspec-tive.
John Benjamins, Amsterdam.
(to appear).Simone Teufel and Marc Moens.
2002.
Summaris-ing scientific articles ?
experiments with relevanceand rhetorical status.
Computational Linguistics,28(4):409?446.Simone Teufel, Jean Carletta, and Marc Moens.
1999.An annotation scheme for discourse-level argumenta-tion in research articles.
In Proceedings of the 9th Eu-ropean Conference of the ACL (EACL-99), pages 110?117, Bergen, Norway.Simone Teufel, Advaith Siddharthan, and Dan Tidhar.2006.
An annotation scheme for citation function.
InProceedings of SIGDIAL-06, Sydney, Australia.Simone Teufel.
2000.
Argumentative Zoning: Infor-mation Extraction from Scientific Text.
Ph.D. thesis,School of Cognitive Science, University of Edinburgh,Edinburgh, UK.Bonnie Webber, Matthew Stone, Aravind Joshi, and Al-istair Knott.
2003.
Anaphora and discourse structure.Computational Linguistics, 29:545?587.Bonnie Webber.
2005.
A short introduction to the PennDiscourse TreeBank.
In Copenhagen Working Papersin Language and Speech Processing.Janyce Wiebe, Eric Breck, Chris Buckley, Claire Cardie,Paul Davis, Bruce Fraser, Diane Litman, David Pierce,Ellen Riloff, Theresa Wilson, David Day, and MarkMaybury.
2003.
Recognizing and organizing opinionsexpressed in the world press.
In Working Notes of theAAAI Spring Symposium in New Directions in Ques-tion Answering, pages 12?19, Palo Alto, California.Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005.Annotating expressions of opinions and emotionsin language.
Language Resources and Evaluation,39(2/3):164?210.Florian Wolf and Edward Gibson.
2005.
Representingdiscourse coherence: A corpus-based study.
Compu-tational Linguistics, 31:249?287.196
