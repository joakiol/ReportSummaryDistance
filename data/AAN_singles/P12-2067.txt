Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 344?348,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsExploiting Latent Information to Predict Diffusions of Novel Topics onSocial NetworksTsung-Ting Kuo1*, San-Chuan Hung1, Wei-Shih Lin1, Nanyun Peng1, Shou-De Lin1,Wei-Fen Lin21Graduate Institute of Networking and Multimedia, National Taiwan University, Taiwan2MobiApps Corporation, Taiwan*d97944007@csie.ntu.edu.twAbstractThis paper brings a marriage of two seemlyunrelated topics, natural languageprocessing (NLP) and social networkanalysis (SNA).
We propose a new task inSNA which is to predict the diffusion of anew topic, and design a learning-basedframework to solve this problem.
Weexploit the latent semantic informationamong users, topics, and social connectionsas features for prediction.
Our framework isevaluated on real data collected from publicdomain.
The experiments show 16% AUCimprovement over baseline methods.
Thesource code and dataset are available athttp://www.csie.ntu.edu.tw/~d97944007/diffusion/1 BackgroundThe diffusion of information on social networkshas been studied for decades.
Generally, theproposed strategies can be categorized into twocategories, model-driven and data-driven.
Themodel-driven strategies, such as independentcascade model (Kempe et al, 2003), rely oncertain manually crafted, usually intuitive, modelsto fit the diffusion data without using diffusionhistory.
The data-driven strategies usually utilizelearning-based approaches to predict the futurepropagation given historical records of prediction(Fei et al, 2011; Galuba et al, 2010; Petrovic et al,2011).
Data-driven strategies usually performbetter than model-driven approaches because thepast diffusion behavior is used during learning(Galuba et al, 2010).Recently, researchers started to exploit contentinformation in data-driven diffusion models (Fei etal., 2011; Petrovic et al, 2011; Zhu et al, 2011).However, most of the data-driven approachesassume that in order to train a model and predictthe future diffusion of a topic, it is required toobtain historical records about how this topic haspropagated in a social network (Petrovic et al,2011; Zhu et al, 2011).
We argue that suchassumption does not always hold in the real-worldscenario, and being able to forecast the propagationof novel or unseen topics is more valuable inpractice.
For example, a company would like toknow which users are more likely to be the sourceof ?viva voce?
of a newly released product foradvertising purpose.
A political party might wantto estimate the potential degree of responses of ahalf-baked policy before deciding to bring it up topublic.
To achieve such goal, it is required topredict the future propagation behavior of a topiceven before any actual diffusion happens on thistopic (i.e., no historical propagation data of thistopic are available).
Lin et al also propose an ideaaiming at predicting the inference of implicitdiffusions for novel topics (Lin et al, 2011).
Themain difference between their work and ours is thatthey focus on implicit diffusions, whose data areusually not available.
Consequently, they need torely on a model-driven approach instead of a data-driven approach.
On the other hand, our workfocuses on the prediction of explicit diffusionbehaviors.
Despite the fact that no diffusion data ofnovel topics is available, we can still design a data-driven approach taking advantage of some explicitdiffusion data of known topics.
Our experimentsshow that being able to utilize such information iscritical for diffusion prediction.2 The Novel-Topic Diffusion ModelWe start by assuming an existing social network G= (V, E), where V is the set of nodes (or user) v,and E is the set of link e. The set of topics is344denoted as T. Among them, some are considered asnovel topics (denoted as N), while the rest (R) areused as the training records.
We are also given aset of diffusion records D = {d | d = (src, dest, t)},where src is the source node (or diffusion source),dest is the destination node, and t is the topic of thediffusion that belongs to R but not N. We assumethat diffusions cannot occur between nodes withoutdirect social connection; any diffusion pair impliesthe existence of a link e = (src, dest ?)
E. Finally,we assume there are sets of keywords or tags thatrelevant to each topic (including existing and noveltopics).
Note that the set of keywords for noveltopics should be seen in that of existing topics.From these sets of keywords, we construct a topic-word matrix TW = (P(wordj | topici))i,j of which theelements stand for the conditional probabilities thata word appears in the text of a certain topic.Similarly, we also construct a user-word matrixUW= (P(wordj | useri))i,j from these sets ofkeywords.
Given the above information, the goal isto predict whether a given link is active (i.e.,belongs to a diffusion link) for topics in N.2.1 The FrameworkThe main challenge of this problem lays in that thepast diffusion behaviors of new topics are missing.To address this challenge, we propose a superviseddiffusion discovery framework that exploits thelatent semantic information among users, topics,and their explicit / implicit interactions.
Intuitively,four kinds of information are useful for prediction:?
Topic information: Intuitively, knowing thesignatures of a topic (e.g., is it about politics?
)is critical to the success of the prediction.?
User information: The information of a usersuch as the personality (e.g., whether this useris aggressive or passive) is generally useful.?
User-topic interaction: Understanding the users'preference on certain topics can improve thequality of prediction.?
Global information: We include some globalfeatures (e.g., topology info) of social network.Below we will describe how these four kinds ofinformation can be modeled in our framework.2.2 Topic InformationWe extract hidden topic category information tomodel topic signature.
In particular, we exploit theLatent Dirichlet Allocation (LDA) method (Blei etal., 2003), which is a widely used topic modelingtechnique, to decompose the topic-word matrix TWinto hidden topic categories:TW = TH * HW, where TH is a topic-hidden matrix, HW is hidden-word matrix, and h is the manually-chosenparameter to determine the size of hidden topiccategories.
TH indicates the distribution of eachtopic to hidden topic categories, and HW indicatesthe distribution of each lexical term to hidden topiccategories.
Note that TW and TH include bothexisting and novel topics.
We utilize THt,*, the rowvector of the topic-hidden matrix TH for a topic t,as a feature set.
In brief, we apply LDA to extractthe topic-hidden vector THt,* to model topicsignature (TG) for both existing and novel topics.Topic information can be further exploited.
Topredict whether a novel topic will be propagatedthrough a link, we can first enumerate the existingtopics that have been propagated through this link.For each such topic, we can calculate its similaritywith the new topic based on the hidden vectorsgenerated above (e.g., using cosine similaritybetween feature vectors).
Then, we sum up thesimilarity values as a new feature: topic similarity(TS).
For example, a link has previouslypropagated two topics for a total of three times{ACL, KDD, ACL}, and we would like to knowwhether a new topic, EMNLP, will propagatethrough this link.
We can use the topic-hiddenvector to generate the similarity values betweenEMNLP and the other topics (e.g., {0.6, 0.4, 0.6}),and then sum them up (1.6) as the value of TS.2.3 User InformationSimilar to topic information, we extract latentpersonal information to model user signature (theusers are anonymized already).
We apply LDA onthe user-word matrix UW:UW = UM * MW, where UM is the user-hidden matrix, MW is thehidden-word matrix, and m is the manually-chosensize of hidden user categories.
UM indicates thedistribution of each user to the hidden usercategories (e.g., age).
We then use UMu,*, the rowvector of UM for the user u, as a feature set.
Inbrief, we apply LDA to extract the user-hiddenvector UMu,* for both source and destination nodesof a link to model user signature (UG).3452.4 User-Topic InteractionModeling user-topic interaction turns out to benon-trivial.
It is not useful to exploit latentsemantic analysis directly on the user-topic matrixUR = UQ * QR , where UR represents how manytimes each user is diffused for existing topic R (R?T), because UR does not contain information ofnovel topics, and neither do UQ and QR.
Given nopropagation record about novel topics, we proposea method that allows us to still extract implicituser-topic information.
First, we extract from thematrix TH (described in Section 2.2) a subset RHthat contains only information about existing topics.Next we apply left division to derive another user-hidden matrix UH:UH = (RH \ URT)T = ((RHT RH)-1 RHT URT)TUsing left division, we generate the UH matrixusing existing topic information.
Finally, weexploit UHu,*, the row vector of the user-hiddenmatrix UH for the user u, as a feature set.Note that novel topics were included in theprocess of learning the hidden topic categories onRH; therefore the features learned here doimplicitly utilize some latent information of noveltopics, which is not the case for UM.
Experimentsconfirm the superiority of our approach.Furthermore, our approach ensures that the hiddencategories in topic-hidden and user-hiddenmatrices are identical.
Intuitively, our methoddirectly models the user?s preference to topics?signature (e.g., how capable is this user topropagate topics in politics category?).
In contrast,the UM mentioned in Section 2.3 represents theusers?
signature (e.g., aggressiveness) and hasnothing to do with their opinions on a topic.
Inshort, we obtain the user-hidden probability vectorUHu,* as a feature set, which models userpreferences to latent categories (UPLC).2.5 Global FeaturesGiven a candidate link, we can extract globalsocial features such as in-degree (ID) and out-degree (OD).
We tried other features such asPageRank values but found them not useful.Moreover, we extract the number of distinct topics(NDT) for a link as a feature.
The intuition behindthis is that the more distinct topics a user hasdiffused to another, the more likely the diffusionwill happen for novel topics.2.6 Complexity AnalysisThe complexity to produce each feature is as below:(1) Topic information: O(I * |T| * h * Bt) for LDAusing Gibbs sampling, where I is # of theiterations in sampling, |T| is # of topics, and Btis the average # of tokens in a topic.
(2) User information: O(I * |V| * m * Bu) , where |V| is # of users, and Bu is the average # oftokens for a user.
(3) User-topic interaction: the time complexity isO(h3 + h2 * |T| + h * |T| * |V|).
(4) Global features: O(|D|), where |D| is # ofdiffusions.3 ExperimentsFor evaluation, we try to use the diffusion recordsof old topics to predict whether a diffusion linkexists between two nodes given a new topic.3.1 Dataset and Evaluation MetricWe first identify 100 most popular topic (e.g.,earthquake) from the Plurk micro-blog sitebetween 01/2011 and 05/2011.
Plurk is a popularmicro-blog service in Asia with more than 5million users (Kuo et al, 2011).
We manuallyseparate the 100 topics into 7 groups.
We usetopic-wise 4-fold cross validation to evaluate ourmethod, because there are only 100 availabletopics.
For each group, we select 3/4 of the topicsas training and 1/4 as validation.The positive diffusion records are generatedbased on the post-response behavior.
That is, if aperson x posts a message containing one of theselected topic t, and later there is a person yresponding to this message, we consider adiffusion of t has occurred from x to y (i.e., (x, y, t)is a positive instance).
Our dataset contains a totalof 1,642,894 positive instances out of 100 distincttopics; the largest and smallest topic contains303,424 and 2,166 diffusions, respectively.
Also,the same amount of negative instances for eachtopic (totally 1,642,894) is sampled for binaryclassification (similar to the setup in KDD Cup2011 Track 2).
The negative links of a topic t aresampled randomly based on the absence ofresponses for that given topic.The underlying social network is created usingthe post-response behavior as well.
We assumethere is an acquaintance link between x and y if and346only if x has responded to y (or vice versa) on atleast one topic.
Eventually we generated a socialnetwork of 163,034 nodes and 382,878 links.Furthermore, the sets of keywords for each topicare required to create the TW and UW matrices forlatent topic analysis; we simply extract the contentof posts and responses for each topic to create bothmatrices.
We set the hidden category number h = m= 7, which is equal to the number of topic groups.We use area under ROC curve (AUC) toevaluate our proposed framework (Davis andGoadrich, 2006); we rank the testing instancesbased on their likelihood of being positive, andcompare it with the ground truth to compute AUC.3.2 Implementation and BaselineAfter trying many classifiers and obtaining similarresults for all of them, we report only results fromLIBLINEAR with c=0.0001 (Fan et al, 2008) dueto space limitation.
We remove stop-words, useSCWS (Hightman, 2012) for tokenization, andMALLET (McCallum, 2002) and GibbsLDA++(Phan and Nguyen, 2007) for LDA.There are three baseline models we compare theresult with.
First, we simply use the total numberof existing diffusions among all topics betweentwo nodes as the single feature for prediction.Second, we exploit the independent cascadingmodel (Kempe et al, 2003), and utilize thenormalized total number of diffusions as thepropagation probability of each link.
Third, we trythe heat diffusion model (Ma et al, 2008), setinitial heat proportional to out-degree, and tune thediffusion time parameter until the best results areobtained.
Note that we did not compare with anydata-driven approaches, as we have not identifiedone that can predict diffusion of novel topics.3.3 ResultsThe result of each model is shown in Table 1.
Allexcept two features outperform the baseline.
Thebest single feature is TS.
Note that UPLC performsbetter than UG, which verifies our hypothesis thatmaintaining the same hidden features acrossdifferent LDA models is better.
We further conductexperiments to evaluate different combinations offeatures (Table 2), and found that the best one (TS+ ID + NDT) results in about 16% improvementover the baseline, and outperforms the combinationof all features.
As stated in (Witten et al, 2011),adding useless features may cause the performanceof classifiers to deteriorate.
Intuitively, TS capturesboth latent topic and historical diffusioninformation, while ID and NDT providecomplementary social characteristics of users.Table 1: Single-feature results.Table 2: Feature combination results.4 ConclusionsThe main contributions of this paper are as below:1.
We propose a novel task of predicting thediffusion of unseen topics, which has wideapplications in real-world.2.
Compared to the traditional model-driven orcontent-independent data-driven works ondiffusion analysis, our solution demonstrateshow one can bring together ideas from twodifferent but promising areas, NLP and SNA,to solve a challenging problem.3.
Promising experiment result (74% in AUC)not only demonstrates the usefulness of theproposed models, but also indicates thatpredicting diffusion of unseen topics withouthistorical diffusion data is feasible.AcknowledgmentsThis work was also supported by National ScienceCouncil, National Taiwan University and IntelCorporation under Grants NSC 100-2911-I-002-001,and 101R7501.Method Feature AUCBaselineExisting Diffusion 58.25%Independent Cascade 51.53%Heat Diffusion 56.08%LearningTopic Signature (TG) 50.80%Topic Similarity (TS) 69.93%User Signature (UG) 56.59%User Preferences toLatent Categories (UPLC) 61.33%In-degree (ID) 65.55%Out-degree (OD) 59.73%Number of Distinct Topics (NDT) 55.42%Method Feature AUCBaseline Existing Diffusion 58.25%LearningALL 65.06%TS + UPLC + ID + NDT 67.67%TS + UPLC + ID 64.80%TS + UPLC + NDT 66.01%TS + ID + NDT 73.95%UPLC + ID + NDT 67.24%347ReferencesDavid M. Blei, Andrew Y. Ng & Michael I. Jordan.2003.
Latent dirichlet alocation.
J. Mach.
Learn.Res., 3.993-1022.Jesse Davis & Mark Goadrich.
2006.
The relationshipbetween Precision-Recall and ROC curves.Proceedings of the 23rd international conference onMachine learning, Pittsburgh, Pennsylvania.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang & Chih-Jen Lin.
2008.
LIBLINEAR: ALibrary for Large Linear Classification.
J. Mach.Learn.
Res., 9.1871-74.Hongliang Fei, Ruoyi Jiang, Yuhao Yang, Bo Luo &Jun Huan.
2011.
Content based social behaviorprediction: a multi-task learning approach.Proceedings of the 20th ACM internationalconference on Information and knowledgemanagement, Glasgow, Scotland, UK.Wojciech Galuba, Karl Aberer, Dipanjan Chakraborty,Zoran Despotovic & Wolfgang Kellerer.
2010.Outtweeting the twitterers - predicting informationcascades in microblogs.
Proceedings of the 3rdconference on Online social networks, Boston, MA.Hightman.
2012.
Simple Chinese Words Segmentation(SCWS).David Kempe, Jon Kleinberg & Eva Tardos.
2003.Maximizing the spread of influence through a socialnetwork.
Proceedings of the ninth ACM SIGKDDinternational conference on Knowledge discoveryand data mining, Washington, D.C.Tsung-Ting Kuo, San-Chuan Hung, Wei-Shih Lin,Shou-De Lin, Ting-Chun Peng & Chia-Chun Shih.2011.
Assessing the Quality of Diffusion ModelsUsing Real-World Social Network Data.
Conferenceon Technologies and Applications of ArtificialIntelligence, 2011.C.X.
Lin, Q.Z.
Mei, Y.L.
Jiang, J.W.
Han & S.X.
Qi.2011.
Inferring the Diffusion and Evolution ofTopics in Social Communities.
Proceedings of theIEEE International Conference on Data Mining,2011.Hao Ma, Haixuan Yang, Michael R. Lyu & Irwin King.2008.
Mining social networks using heat diffusionprocesses for marketing candidates selection.Proceeding of the 17th ACM conference onInformation and knowledge management, NapaValley, California, USA.Andrew Kachites McCallum.
2002.
MALLET: AMachine Learning for Language Toolkit.Sasa Petrovic, Miles Osborne & Victor Lavrenko.
2011.RT to Win!
Predicting Message Propagation inTwitter.
International AAAI Conference on Weblogsand Social Media, 2011.Xuan-Hieu Phan & Cam-Tu Nguyen.
2007.GibbsLDA++: A C/C++ implementation of latentDirichlet alocation (LDA).Ian H. Witten, Eibe Frank & Mark A.
Hall.
2011.
DataMining: Practical machine learning tools andtechniques.
San Francisco: Morgan KaufmannPublishers Inc.Jiang Zhu, Fei Xiong, Dongzhen Piao, Yun Liu & YingZhang.
2011.
Statistically Modeling theEffectiveness of Disaster Information in SocialMedia.
Proceedings of the 2011 IEEE GlobalHumanitarian Technology Conference.348
