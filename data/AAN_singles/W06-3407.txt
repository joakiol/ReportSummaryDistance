Proceedings of the Analyzing Conversations in Text and Speech (ACTS) Workshop at HLT-NAACL 2006, pages 42?49,New York City, New York, June 2006. c?2006 Association for Computational LinguisticsTopic Segmentation of DialogueJaime Arguello Carolyn Ros?Language Technologies Institute Language Technologies InstituteCarnegie Mellon University Carnegie Mellon UniversityPittsburgh, PA 15217 Pittsburgh, PA 15217jarguell@andrew.cmu.edu cprose@cs.cmu.eduAbstractWe introduce a novel topic segmentationapproach that combines evidence of topicshifts from lexical cohesion with linguisticevidence such as syntactically distinct fea-tures of segment initial and final contribu-tions.
Our evaluation shows that this hy-brid approach outperforms state-of-the-artalgorithms even when applied to looselystructured, spontaneous dialogue.
Furtheranalysis reveals that using dialogue ex-changes versus dialogue contributions im-proves topic segmentation quality.1 IntroductionIn this paper we explore the problem of topicsegmentation of dialogue.
Use of topic-based mod-els of dialogue has played a role in informationretrieval (Oard et al, 2004), information extraction(Baufaden, 2001), and summarization (Zechner,2001), just to name a few applications.
However,most previous work on automatic topic segmenta-tion has focused primarily on segmentation of ex-pository text.
This paper presents a survey of thestate-of-the-art in topic segmentation technology.Using the definition of topic segment from (Pas-sonneau and Litman, 1993) applied to two differentdialogue corpora, we present an evaluation includ-ing a detailed error analysis, illustrating why ap-proaches designed for expository text do not gen-eralize well to dialogue.We first demonstrate a significant advantage ofour hybrid, supervised learning approach calledMuseli, a multi-source evidence integration ap-proach, over competing algorithms.
We then ex-tend the basic Museli algorithm by introducing anintermediate level of analysis based on Sinclair andCoulthard?s notion of a dialogue exchange (Sin-clair and Coulthard, 1975).
We show that both ourbaseline and Museli approaches obtain a signifi-cant improvement when using perfect, hand-labeled dialogue exchanges, typically in the orderof 2-3 contributions, as the atomic discourse unit incomparison to using the contribution as the unit ofanalysis.
We further evaluate our success towardsautomatic classification of exchange boundariesusing the same Museli framework.2 Defining TopicIn the most general sense, the challenge of topicsegmentation can be construed as the task of find-ing locations in the discourse where the focusshifts from one topic to another.
Thus, it is not pos-sible to address topic segmentation of dialoguewithout first addressing the question of what a?topic?
is.
We began with the goal of adopting adefinition of topic that meets three criteria.
First, itshould be reproducible by human annotators.
Sec-ond, it should not rely heavily on domain-specificknowledge or knowledge of the task structure.
Fi-nally, it should be grounded in generally acceptedprinciples of discourse structure.The last point addresses a subtle, but important,criterion necessary to adequately serve down-stream applications using our dialogue segmenta-tion.
Topic analysis of dialogue concerns itselfmainly with thematic content.
However, bounda-ries should be placed in locations that are naturalturning points in the discourse.
Shifts in topicshould be readily recognizable from surface char-acteristics of the language.With these goals in mind, we adopted a defini-tion of ?topic?
that builds upon Passonneau andLitman?s seminal work on segmentation of mono-logue (Passonneau and Litman, 1993).
They foundthat human annotators can successfully accomplisha flat monologue segmentation using an informalnotion of speaker intention.42Dialogue is inherently hierarchical in structure.However, a flat segmentation model is an adequateapproximation.
Passonneau and Litman?s pilotstudies confirmed previously published results(Rotondo, 1984) that human annotators cannot re-liably agree on a hierarchical segmentation ofmonologue.
Using a stack-based hierarchicalmodel of discourse, Flammia (1998) found that90% of all information-bearing dialogue turns re-ferred to the discourse purpose at the top of thestack.We adopt a flat model of topic segmentationbased on discourse segment purpose, where a shiftin topic corresponds to a shift in purpose that isacknowledged and acted upon by both conversa-tional participants.
We place topic boundaries oncontributions that introduce a speaker?s intention toshift the purpose of the discourse, while ignoringexpressed intentions to shift discourse purposesthat are not taken up by the other participant.
Weadopt the dialogue contribution as the basic unit ofanalysis, refraining from placing topic boundarieswithin a contribution.
This decision is analogous toHearst?s (Hearst, 1994, 1997) decision to shift theTextTiling induced boundaries to their nearest ref-erence paragraph boundary.We evaluated the reproducibility of our notionof topic segment boundaries by assessing inter-coder reliability over 10% of the corpus (see Sec-tion 5.1).
Three annotators were given a 10 pagecoding manual with explanation of our informaldefinition of shared discourse segment purpose aswell as examples of segmented dialogues.
Pair-wise inter-coder agreement was above 0.7 for allpairs of annotators.3 Previous WorkExisting topic segmentation approaches can beloosely classified into two types: (1) lexical cohe-sion models, and (2) content-oriented models.
Theunderlying assumption in lexical cohesion modelsis that a shift in term distribution signals a shift intopic (Halliday and Hassan, 1976).
The best knownalgorithm based on this idea is TextTiling (Hearst,1997).
In TextTiling, a sliding window is passedover the vector-space representation of the text.
Ateach position, the cosine correlation between theupper and lower regions of the sliding window iscompared with that of the peak cosine correlationvalues to the left and right of the window.
A seg-ment boundary is predicted when the magnitude ofthe difference exceeds a threshold.One drawback to relying on term co-occurrenceto signal topic continuity is that synonyms or re-lated terms are treated as thematically-unrelated.One proposed solution to this problem is LatentSemantic Analysis (LSA) (Landauer and Dumais,1997).
Two LSA-based algorithms for segmenta-tion are described in (Foltz, 1998) and (Olney andCai, 2005).
Foltz?s approach differs fromTextTiling mainly in its use of an LSA-based vec-tor space model.
Olney and Cai address a problemnot addressed by TextTiling or Foltz?s approach,which is that cohesion is not just a function of therepetition of thematically-related terms, but also afunction of the presentation of new information inreference to information already presented.
Theirorthonormal basis approach allows for segmenta-tion based on relevance and informativity.Content-oriented models, such as (Barzilay andLee, 2004), rely on the re-occurrence of patterns oftopics over multiple realizations of thematicallysimilar discourses, such as a series of newspaperarticles about similar events.
Their approach util-izes a hidden Markov model where states corre-spond to topics and state transition probabilitiescorrespond to topic shifts.
To obtain the desirednumber of topics (states), text spans of uniformlength (individual contributions, in our case) areclustered.
Then, state emission probabilities areinduced using smoothed cluster-specific languagemodels.
Transition probabilities are induced byconsidering the proportion of documents in whicha contribution assigned to the source cluster (state)immediately precedes a contribution assigned tothe target cluster (state).
Following an EM-likeapproach, contributions are reassigned to statesuntil the algorithm converges.4 Overview of Museli ApproachWe cast the segmentation problem as a binaryclassification problem where each contribution isclassified as NEW_TOPIC if it introduces a newtopic and SAME_TOPIC otherwise.
In our hybridMuseli approach, we combined lexical cohesionwith features that have the potential to capturesomething about the linguistic style that marksshifts in topic.
Table 1 lists our features.43Feature DescriptionLexicalCohesionCosine correlation of adjacentregions in the discourse.
Termvectors of adjacent regions arestemmed and stopwords are re-moved.Word-unigramUnigrams in previous and cur-rent contributionsWord-bigram Bigrams in previous and currentcontributionsPunctuation Punctuation of previous and cur-rent contributions.Part-of-Speech (POS)BigramPOS-Bigrams in previous andcurrent contributions.TimeDifferenceTime difference between previ-ous and current contribution,normalized by:(X ?
MIN)/ (MAX ?
MIN),where X corresponds to this timedifference and MIN & MAX arewith respect to the whole corpus.ContentContributionBinary-valued, is there a non-stopword term in the currentcontribution?ContributionLengthNumber of words in the currentcontribution, normalized by:(X ?
MIN) / (MAX ?
MIN).PreviousAgent1Binary-valued, was the speakerof the previous contribution thestudent or the tutor?Table 1.
Museli Features.We found that using a Na?ve Bayes classifierwith an attribute selection wrapper using the chi-square test for ranking attributes performed betterthan other state-of-the-art machine learning algo-rithms on our task, perhaps because of the evi-dence integration oriented nature of the problem.We conducted our evaluation using 10-fold cross-validation, being careful not to include instancesfrom the same dialogue in both the training andtest sets on any fold to avoid biasing the trainedmodel with idiosyncratic communicative patternsassociated with individual dialogue participants.To capitalize on differences in conversationalbehavior between participants assigned to different1  The current contribution?s agent is implicit in the fact thatwe learn separate models for each agent-role (student & tutor).roles in the conversation (i.e., student and tutor),we learn separate models for each role.
This deci-sion is motivated by observations that participantswith different speaker-roles, each with differentgoals in the conversation, introduce topics with adifferent frequency, introduce different types oftopics, and may introduce topics in a different stylethat displays their status in the conversation.
Forinstance, a tutor may be more likely to introducenew topics with a contribution that ends with animperative.
A student may be more likely to intro-duce new topics with a contribution that ends witha wh-question.
Dissimilar agent-roles also occur inother domains such as Travel Agent and Customerin flight booking scenarios.Using the complete set of features enumeratedabove, we perform feature selection on the trainingdata for each fold of the cross-validation sepa-rately, training a model with the top 1000 features,and applying that trained model to the test data.Examples of high ranking features output by ourchi-squared feature selection wrapper confirm ourintuition that initial and final contributions of asegment are marked differently.
Moreover, thehighest ranked features are different for our twospeaker-roles.
Some features highly-correlatedwith student-initiated segments are am_trying,should, what_is, and PUNCT_question, which re-late to student questions and requests for informa-tion.
Some features highly-correlated with tutor-initiated segments include ok_lets, do, see_what,and BEGIN_VERB (the POS of the first word inthe contribution is VERB), which characterize im-peratives, and features such as now, next, and first,which characterize instructional task ordering.5 EvaluationWe evaluate Museli in comparison to the bestperforming state-of-the-art approaches, demon-strating that our hybrid Museli approach out-performs all of these approaches on two differentdialogue corpora by a statistically significant mar-gin (p < .01), in one case reducing the probabilityof error, as measured by Pk (Beeferman et al,1999), to about 10%.5.1 Experimental CorporaWe used two different dialogue corpora from theeducational domain for our evaluation.
Both cor-pora constitute of dialogues between a student and44a tutor (speakers with asymmetric roles) and bothwere collected via chat software.
The first corpus,which we call the Olney & Cai corpus, is a set ofdialogues selected randomly from the same corpusOlney and Cai obtained their corpus from (Olneyand Cai, 2005).
The dialogues discuss problemsrelated to Newton?s Three Laws of Motion.
Thesecond corpus, the Thermo corpus, is a locally col-lected corpus of thermodynamics tutoring dia-logues, in which tutor-student pairs work togetherto solve an optimization task.
Table 2 shows cor-pus statistics from both corpora.Olney & CaiCorpusThermoCorpus#Dialogues 42 22Conts./Dialogue 195.40 217.90Conts./Topic 24.00 13.31Topics/Dialogue 8.14 16.36Words/Cont.
28.63 5.12Student Conts.
4113 1431Tutor Conts.
4094 3363Table 2.
Evaluation Corpora StatisticsBoth corpora seem adequate for attempting toharness systematic differences in how speakerswith asymmetric roles may initiate or close topicsegments.
The Thermo corpus is particularly ap-propriate for addressing the research question ofhow to automatically segment natural, spontaneousdialogue.
The exploratory task is more looselystructured than many task-oriented domains inves-tigated in the dialogue community, such as flightreservation or meeting scheduling.
Students caninterrupt with questions and tutors can digress inany way they feel may benefit the completion ofthe task.
In the Olney and Cai corpus, the same 10physics problems are addressed in each session andthe interaction is almost exclusively a tutor initia-tion followed by student response, evident from thenearly equal number of student and tutor contribu-tions.5.2 Baseline ApproachesWe evaluate Museli against the following fouralgorithms: (1) Olney and Cai (Ortho), (2) Barzilayand Lee (B&L), (3) TextTiling (TT), and (4) Foltz.As opposed to the other baseline algorithms,(Olney and Cai, 2005) applied their orthonormalbasis approach specifically to dialogue, and priorto this work, report the highest numbers for topicsegmentation of dialogue.
Barzilay and Lee?s ap-proach is the state of the art in modeling topicshifts in monologue text.
Our application of B&Lto dialogue attempts to harness any existing andrecognizable redundancy in topic-flow across ourdialogues for the purpose of topic segmentation.We chose TextTiling for its seminal contributionto monologue segmentation.
TextTiling and Foltzconsider lexical cohesion as their only evidence oftopic shifts.
Applying these approaches to dialoguesegmentation sheds light on how term distributionin dialogue differs from that of expository mono-logue text (e.g.
news articles).
The Foltz and Orthoapproaches require a trained LSA space, which weprepared the same way as described in (Olney andCai, 2005).
Any parameter tuning for approachesother than our Museli was computed over the en-tire test set, giving baseline algorithms the maxi-mum advantage.In addition to these approaches, we includesegmentation results from three degenerate ap-proaches: (1) classifying all contributions asNEW_TOPIC (ALL), (2) classifying no contribu-tions as NEW_TOPIC (NONE), and (3) classifyingcontributions as NEW_TOPIC at uniform intervals(EVEN), separated by the average reference topiclength (see Table 2).As a means for comparison, we adopt twoevaluation metrics: Pk and f-measure.
An extensiveargument in support of Pk?s robustness (if k is setto ?
the average reference topic length) is pre-sented in (Beeferman, et al 1999).
Pk measures theprobability of misclassifying two contributions adistance of k contributions apart, where the classi-fication question is are the two contributions partof the same topic segment or not?
Pk is the likeli-hood of misclassifying two contributions, thuslower Pk values are preferred over higher ones.
Itequally captures the effect of false-negatives andfalse-positives and favors predictions that that arecloser to the reference boundaries.
F-measure pun-ishes false positives equally, regardless of theirdistance to reference boundaries.5.3 ResultsTable 3 shows our evaluation results.
Note thatlower values of Pk are preferred over higher ones.The opposite is true of F-measure.
In both cor-pora, the Museli approach performed significantlybetter than all other approaches (p < .01).45Olney and CaiCorpusThermo CorpusPk F Pk FNONE 0.4897 -- 0.4900 --ALL 0.5180 -- 0.5100 --EVEN 0.5117 -- 0.5131 --TT 0.6240 0.1475 0.5353 0.1614B&L 0.6351 0.1747 0.5086 0.1512Foltz 0.3270 0.3492 0.5058 0.1180Ortho 0.2754 0.6012 0.4898 0.2111Museli 0.1051 0.8013 0.4043 0.3693Table 3.
Results on both corpora5.4 Error AnalysisResults for all approaches are better on the Ol-ney and Cai corpus than the Thermo corpus.
TheThermo corpus differs profoundly from the Olneyand Cai corpus in ways that very likely influencedthe performance.
For instance, in the Thermo cor-pus each dialogue contribution is on average 5words long, whereas in the Olney and Cai corpuseach dialogue contribution contains an average of28 words.
Thus, the vector space representation ofthe dialogue contributions is more sparse in theThermo corpus, which makes shifts in lexical co-herence less reliable as topic shift indicators.In terms of Pk, TextTiling (TT) performed worsethan the degenerate algorithms.
TextTiling meas-ures the term overlap between adjacent regions inthe discourse.
However, dialogue contributions areoften terse or even contentless.
This producesmany islands of contribution-sequences for whichthe local lexical coherence is zero.
TextTilingwrongly classifies all of these as starts of new top-ics.
A heuristic improvement to prevent TextTilingfrom placing topic boundaries at every point alonga sequence of contributions failed to produce a sta-tistically significant improvement.The Foltz and the Ortho approaches rely on LSAto provide strategic semantic generalizations capa-ble of detecting shifts in topic.
Following (Olneyand Cai, 2005), we built our LSA space using dia-logue contributions as the atomic text unit.
In cor-pora such as the Thermo corpus, however, this maynot be effective due to the brevity of contributions.Barzilay and Lee?s algorithm (B&L) did notgeneralize well to either dialogue corpus.
One rea-son could be that probabilistic methods, such astheir approach, require that reference topics havesignificantly different language models, which wasnot true in either of our evaluation corpora.
Wealso noticed a number of instances in the dialoguecorpora where participants referred to informationfrom previous topic segments, which consequentlymay have blurred the distinction between the lan-guage models assigned to different topics.6 Dialogue ExchangesAlthough results are reliably better than ourbaseline algorithms in both corpora, there is muchroom for improvement, especially in the morespontaneous Thermo corpus.
We believe that animprovement can come from a multi-layer segmen-tation approach, where a first pass segments a dia-logue into dialogue exchanges and a second classi-fier assigns topic shifts based on exchange initialcontributions.
Dialogue is hierarchical in nature.Topic and topic shift comprise only one of themany lenses through which dialogue behaves inseemingly structured ways.
Thus, it seems logicalthat exploiting more fine-grained sub-parts of dia-logue than our definition of topic might help us dobetter at predicting shifts in topic.
One such sub-part of dialogue is the notion of dialogue exchange,typically between 2-3 contributions.Stubbs (1983) motivates the definition of an ex-change with the following observation.
In theory,there is no limit to the number of possible re-sponses to the clause ?Is Harry at home??.
How-ever, constraints are imposed on the interpretationof the contribution that follows it: yes or no.
Such aconstraint is central to the concept of a dialogueexchange.
Informally, an exchange is made froman initiation, for which the possibilities are open-ended, followed by dialogue contributions that arepre-classified and thus increasingly restricted.
Acontribution is part of the next exchange when theconstraint on its communicative act is lifted.Sinclair and Coulthard (1975) introduce a moreformal definition of exchange with their Initiative-Response-Feedback or IRF structure.
An initiationproduces a response and a response happens asdirect consequence to an initiation.
Feedbackserves to close an exchange.
Sinclair and Coulthardposit that if exchanges constitute the minimal unitof interaction, IRF is a primary structure of interac-tive discourse in general.To measure the benefits of exchange boundariesin detecting topic shift in dialogue, we coded theThermo corpus with exchanges following Sinclair46and Coulthard?s IRF structure.
The coder who la-beled dialogue exchanges had no knowledge of ourdefinition of topic or our intention to do topic-analyses of the corpus.
Any correlation betweenexchange boundaries and topic boundaries is not abias introduced during the hand-labeling process.7 Topic Segmentation with ExchangesIn our corpus, as we believe is true in domain-general dialogue, knowledge of an exchange-boundary increases the probability of a topic-boundary significantly.
One way to quantify thisrelation is with the following observation.
In ourexperimental Thermo corpus, there are 4794 dia-logue contributions, 360 topic shifts, and 1074 ex-change shifts.
Using maximum likelihood estima-tion, the likelihood of being correct if we say that arandomly chosen contribution is a topic shift is0.075 (# topic shifts / # contributions).
However,the likelihood of being correct if we have priorknowledge that an exchange-shift also occurs inthat contribution is 0.25.
Thus, knowledge that thecontribution introduces a new exchange increasesour confidence that it also introduces a new topic.More importantly, the probability that a contribu-tion does not mark a topic shift, given that it doesnot mark an exchange-shift, is 0.98.
Thus, ex-changes show great promise in narrowing thesearch-space of tentative topic shifts.In addition to possibly narrowing the space oftentative topic-boundaries, exchanges are helpfulin that they provide more coarse-grain buildingblocks for segmentation algorithms that rely onterm-distribution as a proxy for dialogue coher-ence, such as TextTiling (Hearst, 1994, 1997), theFoltz algorithm (Foltz, 1998), Orthonormal Basis(Olney and Cai, 2005), and Barzilay and Lee?scontent modeling approach (Barzilay and Lee,2004).
At the heart of all these approaches is theassumption that a change in term distribution sig-nals a shift in topic.
When applied to dialogue, themajor weakness of these approaches is that contri-butions are often times contentless: terse and ab-sent of thematically meaningful terms.
Thus, amore coarse-grained discourse unit is needed.8 Barzilay and Lee with ExchangesBarzilay and Lee (2004) offer an attractiveframe work for constructing a context-specificHidden Markov Model (HMM) of topic drift.
Inour initial evaluation, we used dialogue contribu-tions as the atomic discourse unit.
Using contribu-tions, our application of Barzilay and Lee?s algo-rithm for segmenting dialogue fails at least in partbecause the model learns states that are not the-matically meaningful, but instead relate to othersystematic phenomena in dialogue, such as fixedexpressions and discourse cues.
Figure 1 shows thecluster (state) size distribution in terms of the per-centage of the total discourse units (exchanges vs.contributions) in the Thermo corpus assigned toeach cluster.
In the horizontal axis, clusters (states)are sorted by size from largest to smallest.% of Total Discourse Units per Cluster(clusters sorted by size, largest-to-smallest)0%10%20%30%40%50%60%70%80%1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16Cluster Rank%ofDiscourseUnitsinClusterCONTRIBUTIONS EXCHANGESFigure 1.
Exchanges produce a more evenly dis-tributed cluster size distribution.The largest cluster contains 70% of all contribu-tions in the corpus.
The second largest cluster onlygenerates 10% of the contributions.
In contrast,when using exchanges as the atomic unit, the clus-ter size distribution is less skewed and correspondsmore closely to a topic analysis performed by adomain expert.
In this analysis, the number of de-sired cluster (states), which is an input to the algo-rithm, was set to 16, the same number identified ina domain expert?s analysis of the Thermo corpus.Examples of such topics include high-level onessuch as greeting, setup initialization, and generalthermo concepts, as well as task-specific ones likesensitivity analysis and regeneration.A closer examination of the clusters (states) con-firms our intuition that systematic topic-independent phenomena in dialogue, coupled withthe terse nature of contributions in spontaneousdialogue, leads to an overly skewed cluster sizedistribution.
Examining the terms with the highestemission probabilities, the largest states contain47topical terms like cycle, efficiency, increase, qual-ity, plot, and turbine intermixed with terms likethink, you, right, make, yeah, fine, and ok. Also thesets of topical terms in these larger states do notseem coherent with respect to the expert inducedtopics.
This suggests that thematically ambiguousfixed expressions blur the distinction between thedifferent topic-centered language models, produc-ing an overly heavy-tailed cluster size distribution.One might argue that a possible solution to thisproblem would be to remove these fixed expres-sions as part of pre-processing.
However, that re-quires knowledge of the particular domain andknowledge of the interaction style characteristic tothe context.
We believe that a more robust solutionis to use exchanges as the atomic unit of discourse.9 Evaluation with ExchangesTo show the value of dialogue exchanges intopic segmentation, in this section we re-formulateour problem from classifying contributions intoNEW_TOPIC and SAME_TOPIC to classifyingexchange initial contributions into NEW_TOPICand SAME_TOPIC.
For all algorithms, we con-sider only predictions that coincide with hand-coded exchange initial contributions.
We showthat, except for our own Museli approach, usingexchange boundaries improves segmentation qual-ity across all algorithms (p < .05) when comparedto their respective counterparts that ignore ex-changes.
Using exchanges gives the Museli ap-proach a significant advantage based on F-measure(p < .05), but only a marginally significant advan-tage based on Pk.
These results confirm our intui-tion that what gives our Museli approach an advan-tage over baseline algorithms is its ability to har-ness the lexical, syntactic, and phrasal cues thatmark shifts in topic.
Given that shift-in-topic corre-lates highly with shift-in-exchange, these featuresare discriminatory in both respects.Of the degenerate strategies in section 5.2, onlyALL lends itself to our reformulation of the topicsegmentation problem.
For the ALL heuristic, weclassify all exchange initial contributions intoNEW_TOPIC.
This degenerate heuristic aloneproduces better results than all algorithms classify-ing utterances (Table 4).
In our implementation ofTextTiling (TT) with exchanges, we only considerpredictions on contributions that coincide with ex-change initial contributions, while ignoring predic-tions made on contributions that do not introduce anew exchange.
Consistent with our evaluationmethodology from Section 5, we optimized thewindow size using the entire corpus and found anoptimal window size of 13 contributions.
Withoutexchanges, the optimal window size was 6 contri-butions.
The higher optimal window-size hints tothe possibility that by using exchange initial con-tributions an approach based on lexical cohesionmay broaden its horizon without losing precision.Thermo Corpus(Contributions)Thermo Corpus(Exchanges)Pk F Pk FNONE 0.4900 -- N/A --ALL 0.5100 -- 0.4398 0.3809EVEN 0.5132 -- N/A --TT 0.5353 0.1614 0.4328 0.3031B&L 0.5086 0.1512 0.3817 0.3840Foltz 0.5058 0.1180 0.4242 0.3296Ortho 0.4898 0.2111 0.4398 0.3813Museli 0.4043 0.3693 0.3737 0.3897Table 4.
Results using perfect exchange boundariesIn this version of B&L, we use exchanges tobuild the initial clusters (states) and the finalHMM.
B&L with exchanges significantly im-proves over B&L with contributions, in terms ofboth Pk and F-measure (p < .005) and significantlyimproves over our ALL heuristic (where all ex-change initial contributions introduce a new topic)in terms of Pk (p < .0005).
Thus, its use of ex-changes goes beyond merely narrowing the spaceof possible NEW_TOPIC contributions: it alsouses these more coarse-grained discourse units tobuild a more thematically-motivated topic model.Foltz?s and Olney and Cai?s (Ortho) approachboth use an LSA space trained on the dialoguecorpus.
Instead of training the LSA space with in-dividual contributions, we train the LSA space us-ing exchanges.
We hope that by training the spacewith more contentful text units LSA might capturemore topically-meaningful semantic relations.
Inaddition, only exchange initial contributions whereused for the logistic regression training phase.Thus, we aim to learn the regression equation thatbest discriminates between exchange initial contri-butions that introduce a topic and those that do not.Both Foltz and Ortho improve over their non ex-change counterparts, but neither improves over theALL heuristic by a significant margin.48For Museli with exchanges, we tried both train-ing the model using only exchange initial contribu-tions, and applying our previous model to only ex-change initial contributions.
Training our modelsusing only exchange initial contributions producedslightly worse results.
We believe that the reduc-tion of the amount of training data prevents ourmodels from learning good generalizations.
Thus,we trained our models using contributions (as inSection 5) and consider predictions only on ex-change initial contributions.
The Museli approachoffers a significant advantage over TT in terms ofPk and F-measure.
Using perfect-exchanges, it isnot significantly better than Barzilay and Lee.
It issignificantly better than Foltz?s approach based onF-measure and significantly better than Olney andCai based on Pk (p < .05).These experiments used hand coded exchangeboundaries.
We also evaluated our ability toautomatically predict exchange boundaries.
On theThermo corpus, Museli was able to predict ex-change boundaries with precision = 0.48, recall =0.62, f-measure = 0.53, and Pk = 0.14.10 Conclusions and Current DirectionsIn this paper we addressed the problem of auto-matic topic segmentation of spontaneous dialogue.We demonstrated with an empirical evaluation thatstate-of-the-art approaches fail on spontaneous dia-logue because term distribution alone fails to pro-vide adequate evidence of topic shifts in dialogue.We have presented a supervised learning algo-rithm for topic segmentation of dialogue calledMuseli that combines linguistic features signaling acontribution?s function with local context indica-tors.
Our evaluation on two distinct corpora showsa significant improvement over the state-of-the-artalgorithms.
We have also demonstrated that a sig-nificant improvement in performance of state-of-the-art approaches to topic segmentation can beachieved when dialogue exchanges, rather thancontributions, are used as the basic unit of dis-course.
We demonstrated promising results inautomatically identifying exchange boundaries.AcknowledgmentsThis work was funded by Office of Naval Re-search, Cognitive and Neural Science Division;grant number N00014-05-1-0043.ReferencesRegina Barzilay and Lillian Lee.
2004.
Catching thedrift: Probabilistic Content Models, with Applica-tions to Generation and Summarization.
In Proceed-ings of HLT-NAACL, 113 - 120.Doug Beeferman, Adam Berger, John D. Lafferty.
1999.Statistical Models for Text Segmentation.
MachineLearning, 34 (1-3): 177-210.Narj?s Boufaden, Guy Lapalme, Yoshua Bengio.
2001.Topic Segmentation: A first stage to Dialog-based In-formation Extraction.
In Proceedings of NLPRS.Giovanni Flammia.
1998.
Discourse Segmentation ofSpoken Dialogue, PhD Thesis.
Massachusetts Insti-tute of Technology.Peter Foltz, Walter Kintsch, and Thomas Landauer.1998.
The measurement of textual cohesion withLSA.
Discourse Processes, 25, 285-307.Michael Halliday and Ruqaiya Hasan.
1976.
Cohesionin English.
London: Longman.Marti Hearst.
1997.
TextTiling: Segmenting Text intoMulti-Paragragh Subtopic Passages.
ComputationalLinguistics, 23(1), 33 ?
64.Thomas Landauer and Susan Dumais.
A Solution toPlato?s Problem: The Latent Semantic Analysis ofAcquisition, Induction, and Representation ofKnowledge.
Psychological Review, 104, 221-240.Douglas Oard, Bhuvana Ramabhadran, and SamuelGustman.
2004.
Building an Information RetrievalTest Collection for Spontaneous ConversationalSpeech.
In Proceedings of SIGIR.Andrew Olney and Zhiqiang Cai.
2005.
An Orthonor-mal Basis for Topic Segmentation of Tutorial Dia-logue.
In Proceedings of HLT/EMNLP.
971-978.Rebecca Passonneau and Diane Litman.
1993.
Inten-tion-Based Segmentation: Human Reliability andCorrelation with Linguistic Cues.
In Proceedings ofACL, 148 ?
155.John Rotondo, 1984, Clustering Analysis of SubjectPartitions of Text.
Discourse Processes, 7:69-88John Sinclair and Malcolm Coulthard.
1975.
Towardsan Analysis of Discourse: the English Used byTeachers and Pupils.
Oxford University Press.Michael Stubbs.
1983.
Discourse Analysis.
A Sociolin-guistic Analysis of Natural Language.
Basil Black-well.Klaus Zechner.
2001.
Automatic Summarization of Spo-ken Dialogues in Unrestricted Domains.
Ph.D. The-sis.
Carnegie Mellon University.49
