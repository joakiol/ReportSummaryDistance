Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 73?78,Baltimore, Maryland USA, June 23-24, 2014.c?2014 Association for Computational LinguisticsA Rule-Augmented Statistical Phrase-based Translation SystemCong Duy Vu Hoang?, AiTi Aw?and Nhung T. H.
Nguyen??
?Human Language Technology Dept.Institute for Infocomm Research (I2R), A*STAR, Singapore{cdvhoang, aaiti}@i2r.a-star.edu.sg?School of Information ScienceJapan Advanced Institute of Science and Technology (JAIST), Japannthnhung@jaist.ac.jpAbstractInteractive or Incremental Statistical Ma-chine Translation (IMT) aims to provide amechanism that allows the statistical mod-els involved in the translation process to beincrementally updated and improved.
Thesource of knowledge normally comes fromusers who either post-edit the entire trans-lation or just provide the translations forwrongly translated domain-specific termi-nologies.
Most of the existing work onIMT uses batch learning paradigm whichdoes not allow translation systems to makeuse of the new input instantaneously.
Weintroduce an adaptive MT framework witha Rule Definition Language (RDL) forusers to amend MT results through trans-lation rules or patterns.
Experimental re-sults show that our system acknowledgesuser feedback via RDL which improvesthe translations of the baseline system onthree test sets for Vietnamese to Englishtranslation.1 IntroductionIn current Statistical Machine Translation (SMT)framework, users are often seen as passive con-tributors to MT performance.
Even if there is acollaboration between the users and the system, itis carried out in a batch learning paradigm (Ortiz-Martinez et al., 2010), where the training of theSMT system and the collaborative process are car-ried out in different stages.
To increase the produc-tivity of the whole translation process, one has toincorporate human correction activities within thetranslation process.
Barrachina et al.
(2009) pro-posed an iterative process in which the translatoractivity is used by the system to compute its best?Work done during an internship at I2R, A*STAR.
(or n-best) translation suffix hypotheses to com-plete the prefix.
Ortiz-Martinez et al.
(2011) pro-posed an IMT framework that includes stochas-tic error-correction models in its statistical formal-ization to address the prefix coverage problemsin Barrachina et al.
(2009).
Gonzalez-Rubio etal.
(2013) proposed a similar approach with a spe-cific error-correction model based on a statisticalinterpretation of the Levenshtein distance (Leven-shtein, 1966).
On the other hand, Ortiz-Martinezet al.
(2010) presented an IMT system that is ableto learn from user feedback by incrementally up-dating the statistical models used by the system.The key aspect of this proposed system is the useof HMM-based alignment models trained by an in-cremental EM algorithm.Here, we present a system similar to Ortiz-Martinez et al.
(2010).
Instead of updating thetranslation model given a new sentence pair, weprovide a framework for users to describe trans-lation rules using a Rule Definition Language(RDL).
Our RDL borrows the concept of the rule-based method that allows users to control thetranslation output by writing rules using their lin-guistic and domain knowledge.
Although statis-tical methods pre-dominate the machine transla-tion research currently, rule-based methods arestill promising in improving the translation qual-ity.
This approach is especially useful for lowresource languages where large training corpusis not always available.
The advantage of rule-based methods is that they can well handle par-ticular linguistic phenomena which are peculiar tolanguages and domains.
For example, the TCHMT system at IWSLT 2008 (Wang et al., 2008)used dictionary and hand-crafted rules (e.g.
regu-lar expression) to process NEs.
Their experimentsshowed that handling NE separately (e.g., personname, location name, date, time, digit) results intranslation quality improvement.In this paper, we present an adaptive and in-73Figure 1: The proposed rule-augmented SMTframework.teractive MT system that allows users to correctthe translation and integrate the adaptation intothe next translation cycle.
Our experiments showthat the system is specifically effective in han-dling translation errors related to out of vocabularywords (OOVs), language expressions, name enti-ties (NEs), abbreviations, terminologies, idioms,etc.
which cannot be easily addressed in the ab-sence of in-domain parallel data.2 System OverviewFigure 1 shows the translation and interactive pro-cess of our system.
The system is trained with abatch of parallel texts to create a baseline model.Users improve the translation by adding RDLrules to change or correct the unsatisfactory trans-lation.
New RDL rules are tested in a workingenvironment before uploading to the productionenvironment where they would be used by subse-quent translation requests.In our system, RDL Management checks, vali-dates and indexes the translation rules.
The Rule-Augmented Decoder has two components: (1) theRDL Matcher to find applicable RDL rules for agiven source text to create dynamic translation hy-potheses; and (2) the Augmented Decoder to pro-duce the final consensus translation using both dy-namic hypotheses and static hypotheses from thebaseline model.3 Rule Definition Language (RDL)The Rule Definition Language (RDL) comprises aRDL grammar, a RDL parser and a RDL matchingalgorithm.3.1 RDL GrammarOur RDL grammar is represented with a Backus-Naur Form (BNF)s syntax.
The major feature ofNode Type DescriptionToken Any string of characters in the definedbasic processing unit of the language.String A constant string of characters.Identifier A term represents a pre-defined role(e.g.
integer, date, sequence, .
.
.
).Meta-node A term executes a specific function(e.g.
casing, selection/option, con-nection).Context cue A term describes source context?s ex-istence.Function A term executes a pre-defined task.Table 1: A brief description of RDL nodes.Figure 2: An Example of RDL Rule.RDL grammar is the support of pre-defined identi-fiers and meta-operators which go beyond the nor-mal framework of regular expression.
We alsoincluded a set of pre-defined functions to furtherconstraint the application and realization of therules.
This framework allows us to incorporatesemantic information into the rule definition andderive translation hypotheses using both semanticand lexical information.
A RDL rule is identifiedby a unique rule ID and five constituents, includ-ing Source pattern, rule Condition, Target transla-tion, Reordering rule and user ConFidence.
Thesource pattern and target translation can be con-structed using different combination of node typesas described in Table 1.
The rules can be furtherconditioned by using some pre-defined functionsand the system allows users to reorder the transla-tion of the target node.
Figure 2 gives an exampleof a RDL rule where identifier @Num is used.3.2 RDL Parsing and IndexingThe RDL Parser checks the syntax of the rulesbefore indexing and storing them into the ruledatabase.
We utilize the compiler generator (WoBet al., 2003) to generate a RDL template parser andthen embed all semantic parsing components intothe template to form our RDL Parser.As rule matching is performed during transla-tion, searching of the relevant rules have to be veryfast and efficient.
We employed the modified ver-sion of an inverted index scheme (Zobel and Mof-fat, 2006) for our rule indexing.
The algorithm is74Figure 3: A linked item chain for a rule source(@a @b [c] [?d e?]
[?f g h?]
(?i?
| ?j k?
)).represented in Algorithm 1.Data: ruleID & srcPatnResult: idxTbl// To build data structure ?
Forward StepdoForward(srcPatn, linkedItmChain);// To create index table ?
Backward StepdoBackward(linkedItmChain, ruleID, idxTbl);Algorithm 1: Algorithm for RDL rule indexing.The main idea of the rule indexing algorithm isto index all string-based nodes in the source pat-tern of the RDL rule.
Each node is representedusing 3-tuple.
They are ruleID, number of nodesin source pattern and all plausible positions of thenode during rule matching.
The indexing is car-ried out via a Forward Step and Backward Step.The Forward Step builds a linked item chain whichtraverses all possible position transitions from onenode to another as illustrated in Figure 3.
Note thatS and E are the Start and End Node.
The link indi-cates the order of transition from a node to another.The numbers refer to the possible positions of anitem in source.
The Backward Step starts at theend of the source pattern; traverses back the linkto index each node using the 3-tuple constructedin the Forward Step.
This data structure allows usto retrieve, add or update RDL rules efficiently andincrementally without re-indexing.3.3 RDL Matching AlgorithmEach word in the source string will be matchedagainst the index table to retrieve relevant RDLrules during decoding.
The aim is to retrieve allRDL rules in which the word is used as part ofthe context in the source pattern.
We sort all therules based on the word positions recorded dur-ing indexing, match their source patterns againstthe input string within the given span, check theconditions and generate the hypotheses if the rulesfulfill all the constraints.4 Rule-Augmented DecoderThe rule-augmented decoder integrates the dy-namic hypotheses generated during rule match-ing with the baseline hypotheses during decoding.Given a sentence f from a source language F, thefundamental equation of SMT (Brown et al., 1993)to translate it into a target sentence e of a targetlanguage E is stated in Equation 1.ebest= argmaxePr(e|f)= argmaxePr(f |e)Pr(e)= argmaxeN?n=1?nhn(e, f)(1)Here, Pr(f |e) is approximated by a translationmodel that represents the correlation between thesource and the target sentence and Pr(e) is ap-proximated by a language model presenting thewell-formedness of the candidate translation e.Most of the SMT systems follow a log-linear ap-proach (Och and Ney, 2002), where direct mod-elling of the posterior probabilityPr(f |e) of Equa-tion 1 is used.
The decoder searches for the besttranslation given a set of model hm(e, f) by max-imizing the log-linear feature score (Och and Ney,2004) as in Equation 1.For each hypothesis generated by the RDL rule,an appropriate feature vector score is needed to en-sure that it will not disturb the probability distribu-tion of each model and contributes to hypothesisselection process of SMT decoder.4.1 Model Score EstimationThe aim of the RDL implementation is to addressthe translation of language-specific expressions(such as date-time, number, title, etc.)
and do-main-specific terminologies.
Sometimes, transla-tion rules and bilingual phrases can be easily ob-served and obtained from experienced translatorsor linguists.
However, it is difficult to estimate theprobability of the RDL rules manually to reflectthe correct word or phrase distribution in real data.Many approaches have been proposed to solve theOOV problem and estimate word translation prob-abilities without using parallel data.
Koehn etal.
(2000) estimated word translation probabilitiesfrom unrelated monolingual corpora using the EMalgorithm.
Habash et al.
(2008) presented differ-ent techniques to extend the phrase table for on-line handling of OOV.
In their approach, the ex-tended phrases are added to the baseline phrase75table with a default weight.
Arora et al.
(2008)extended the phrase table by adding new phrasetranslations for all source language words that donot have a single-word entry in the original phrase-table, but appear in the context of larger phrases.They adjusted the probabilities of each entry in theextended phase table.We performed different experiments to estimatethe lexical translation feature vector for each dy-namic hypothesis generated by our RDL rules.
Weobtain the best performance by estimating the fea-ture vector score using the baseline phrase tablethrough context approximation.
For each hypoth-esis generated by the RDL rule, we retrieve en-tries from the phrase table which have at least onesimilar word with the source of the generated hy-pothesis.
We sort the entries based on the sim-ilarities between the generated and retrieved hy-potheses using both source and target phrase.
Themedium score of the sorted list is assigned to thegenerated hypothesis.5 System FeaturesThe main features of our system are (1) the flexi-bilities provided to the user to create different lev-els of translation rules, from simple one-to-onebilingual phrases to complex generalization rulesfor capturing the translation of specific linguis-tic phenomena; and (2) the ability to validate andmanage translation rules online and incrementally.5.1 RDL Rule ManagementOur system framework is language independentand has been implemented on a Vietnamese to En-glish translation project.
Figure 4 shows the RDLManagement Screen where a user can add, mod-ify or delete a translation rule using RDL.
A RDLrule can be created using nodes.
Each node canbe defined using string or system predefined meta-identifiers with or without meta-operators as de-scribed in Table 1.
Based on the node type selectedby the user, the system further restricts the user toappropriate conditions and translation functions.The user can define the order of the translation out-put of each node and at the same time, inform thesystem whether to use a specific RDL exclusivelyduring decoding, in which any phrases from thebaseline phrase table overlapping with that spanwill be ignored1.
The system also provides an edi-1Similar to Moses XML markup exclusive featurehttp://www.statmt.org/moses/?n=Moses.Figure 4: RDL Management screen with identi-fiers & meta-functions supported.tor for expert users to code the rules using the RDLcontrolled language.
Each rule is validated by theRDL parser (discussed in section 3.2), which willdisplay errors or warning messages when an in-valid syntax is encountered.5.2 RDL Rule ValidationOur decoder manages two types of phrase table.One is the static phrase-table obtained throughthe SMT training in parallel texts; the other isthe dynamic table that comprises of the hypothe-ses generated on-the-fly during RDL rule match-ing.
To ensure only fully tested rules are used inthe production environment, the system supportstwo types of dynamic phrase table.
The work-ing phrase-table holds the latest updates made bythe users.
The users can test the translation withthese latest modifications using a specific transla-tion protocol.
When users are satisfied with thesemodifications, they can perform an operation toupload the RDL rules to the production phrase-table, where the RDLs are used for all translationAdvancedFeatures#ntoc976Named Entity Category Number of RulesDate-time 120Measurement 92Title 13Designation 12Number 19Terminology 178Location 13Organization 48Total 495Table 2: Statistics of created RDL rules forVietnamese-to-English NE Translation.requests.
Uploaded rules can be deleted, modifiedand tested again in the working environment be-fore updated to the production environment.
Fig-ure 5b and Figure 5c show the differences in trans-lation output before and after applied the RDL rulein Figure 5a.6 A Case Study for Vietnamese?EnglishTranslationWe performed an experiment using the proposedRDL framework for a Vietnamese to Englishtranslation system.
As named entity (NE) con-tributes to most of the OOV occurrences and im-pacts the system performance for out-of-domaintest data in our system, we studied the NE usagein a large Vietnamese monolingual corpus com-prising 50M words to extract RDL rules.
We cre-ated RDL rules for 8 popular NE types includingtitle, designation, date-time, measurement, loca-tion, organization, number and terminology.
Wemade use of a list of anchor words for each NEcategory and compiled our RDL rules based onthese anchor words.
As a result, we compiled atotal of 495 rules for 8 categories and it took about3 months for the rule creation.
Table 2 shows thecoverage of our compiled rules.6.1 Experiment & ResultsOur experiments were performed on a training setof about 875K parallel sentences extracted fromweb news and revised by native linguists over 2years.
The corpus has 401K and 225K unique En-glish and Vietnamese tokens.
We developed 1008and 2548 parallel sentences, each with 4 refer-ences, for development and testing, respectively.All the reference sentences are created and revisedby different native linguists at different times.
Wealso trained a very large English language modelusing data from Gigaword, Europarl and EnglishFigure 5: Translation Demo with RDL rules.Data Set nS nT nMRTrainFull (VN) 875,579 28,251,775 627,125TrainFull (EN) 875,579 20,191,526 -Test1 (VN) 1009 34,717 737Test1 (4 refs) (EN) 1009 ?25,713 -Test2 (VN) 1033 29,546 603Test2 (4 refs) (EN) 1033 ?22,717 -Test3 (VN) 506 16,817 344Test3 (4 refs) (EN) 506 ?12,601 -Dev (VN) 1008 34,803 -Dev (4 refs) (EN) 1008 ?25,631 -Table 3: Statistics of Vietnamese-to-English paral-lel data.
nS, nT, and nMR are number of sentencepairs and tokens, and count of matched rules, re-spectively.web texts of Vietnamese authors to validate theimpact of RDL rules on large-scale and domain-rich corpus.
The experimental results show thatcreated RDL rules improve the translation perfor-mance on all 3 test sets.
Table 3 and Table 4 showrespective data statistics and results of our evalua-tion.
More specifically, the BLEU scores increase3%, 3.6% and 1.4% on the three sets, respectively.7 ConclusionWe have presented a system that provides a con-trol language (Kuhn, 2013) specialized for MT forusers to create translation rules.
Our RDL differsfrom Moses?s XML mark-up in that it offers fea-77Data Set System BLEU NIST METEORSet 1 Baseline 39.21 9.2323 37.81+RDL (all) 39.51 9.2658 37.98Set 2 Baseline 40.25 9.5174 38.24+RDL (all) 40.61 9.6092 38.84Set 3 Baseline 36.77 8.6953 37.65+RDL (all) 36.91 8.7062 37.69Table 4: Experimental results with RDL rules.tures that go beyond the popular regular expres-sion framework.
Without restricting the mark-upon the source text, we allow multiple translationsto be specified for the same span or overlappingspan.Our experimental results show that RDLrules improve the overall performance of theVietnamese-to-English translation system.
Theframework will be tested for other language pairs(e.g.
Chinese-to-English, Malay-to-English) inthe near future.
We also plan to explore advancedmethods to identify and score ?good?
dynamichypotheses on-the-fly and integrate them into cur-rent SMT translation system (Simard and Foster,2013).AcknowledgmentsWe would like to thank the reviewers of the paperfor their helpful comments.ReferencesPaul M. Sumita E. Arora, K. 2008.
Translationof unknown words in phrase-based statistical ma-chine translation for languages of rich morphol-ogy.
In In Proceedings of the Workshop on SpokenLanguage Technologies for Under-Resourced Lan-guages, SLTU 2008.Sergio Barrachina, Oliver Bender, Francisco Casacu-berta, Jorge Civera, Elsa Cubel, Shahram Khadivi,Antonio Lagarda, Hermann Ney, Jes?us Tom?as, En-rique Vidal, and Juan-Miguel Vilar.
2009.
Sta-tistical approaches to computer-assisted translation.Comput.
Linguist., 35(1):3?28, March.Peter F. Brown, Vincent J. Della Pietra, StephenA.
Della Pietra, and Robert L. Mercer.
1993.
Themathematics of statistical machine translation: Pa-rameter estimation.
Comput.
Linguist., 19(2):263?311, June.Jes?us Gonz?alez-Rubio, Daniel Ort?
?z-Martinez, Jos?e-Miguel Bened?
?, and Francisco Casacuberta.
2013.Interactive machine translation using hierarchicaltranslation models.
In Proceedings of the 2013 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 244?254, Seattle, Washington,USA, October.Nizar Habash.
2008.
Four techniques for online han-dling of out-of-vocabulary words in arabic-englishstatistical machine translation.
In Proceedings ofACL: Short Papers, HLT-Short ?08, pages 57?60,Stroudsburg, PA, USA.Philipp Koehn and Kevin Knight.
2000.
Estimatingword translation probabilities from unrelated mono-lingual corpora using the em algorithm.
In Proceed-ings of the Seventeenth National Conference on Ar-tificial Intelligence and Twelfth Conference on Inno-vative Applications of Artificial Intelligence, pages711?715.
AAAI Press.Tobias Kuhn.
2013.
A survey and classification of con-trolled natural languages.
Computational Linguis-tics.VI Levenshtein.
1966.
Binary codes capable of cor-recting deletions, insertions and reversals.
SovietPhysics Doklady, 10:707.Franz Josef Och and Hermann Ney.
2002.
Discrim-inative training and maximum entropy models forstatistical machine translation.
In In Proceedings ofACL, pages 295?302, Stroudsburg, PA, USA.Franz Josef Och and Hermann Ney.
2004.
The align-ment template approach to statistical machine trans-lation.
Comput.
Linguist., 30(4):417?449, Decem-ber.Daniel Ortiz-Martinez, Ismael Garcia-Varea, and Fran-cisco Casacuberta.
2010.
Online learning for inter-active statistical machine translation.
In In Proceed-ings of NAACL, HLT ?10, pages 546?554, Strouds-burg, PA, USA.Daniel Ortiz-Mart?
?nez, Luis A. Leiva, Vicent Alabau,Ismael Garc?
?a-Varea, and Francisco Casacuberta.2011.
An interactive machine translation systemwith online learning.
In In Proceedings of ACL:Systems Demonstrations, HLT ?11, pages 68?73,Stroudsburg, PA, USA.Michel Simard and George Foster.
2013.
Pepr: Post-edit propagation using phrase-based statistical ma-chine translation.
Proceedings of the XIV MachineTranslation Summit, pages 191?198.Haifeng Wang, Hua Wu, Xiaoguang Hu, Zhanyi Liu,Jianfeng Li, Dengjun Ren, and Zhengyu Niu.
2008.The tch machine translation system for iwslt 2008.In In Proceedings of IWSLT 2008, Hawaii, USA.Albrecht WoB, Markus Loberbauer, and HanspeterMossenbock.
2003.
Ll(1) conflict resolution in arecursive descent compiler generator.
In ModularProgramming Languages, volume 2789 of LectureNotes in Computer Science, pages 192?201.Justin Zobel and Alistair Moffat.
2006.
Inverted filesfor text search engines.
ACM Comput.
Surv., 38,July.78
