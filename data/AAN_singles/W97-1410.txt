Exploiting Image Descriptions for the GenerationExpressionsof ReferringKnut  Har tmann*  Jochen  SchSpp t1 In t roduct ionIntelligent multimedia representation systems(e.g.
(Wahlster et al, 1993), (Andre et al, 1996),(Feiner and McKeown, 1993)) have to select ap-propriate expressions in different modes (texts,graphics and animations) and to coordinate them1.
For both tasks, an explicit representation f thecontent of the multimodal expressions is required.An important aspect of the media coordination isto ensure the cohesion of the resulting multimodalpresentation.One way to tie the expressions in the differentmodes together is to generate referring expres-sions using co-referential relations between textand graphics.
In order to construct appropriatereferring expressions for the displayed objects inthe graphics, one has to choose what attributes ofthe objects could be used for constructing an un-ambiguous linguistic realization.
Most of the algo-rithms proposed by other researchers (e.g.
(Daleand Reiter, 1995)) use information on the typeof the object and perceptually recoguisable at-tributes like colour or shape.
Some systems ex-ploit additional information as descriptors such asthe information on complex objects and their com-ponents (IDAS (Reiter et al, 1995)) or the spatialinclusion relation (KAMP (Appelt, 1985)).
How-ever, other kinds of descriptors, uch as informa-tion on the relative location of a component withrespect o another, have not been used yet.In this paper, we propose an algorithm to com-pute a set of components for sides of complex ob-*Otto-yon- Guericke-Universit~it Magdeburg,Institut fiir Informations- und Kommunikationssys-teme, P.O.Box 41 20, D-39016 Magdeburg, GermanyEmail: hartmann~iik.cs.uni-magdeburg.det software design & management GmbH & Co.KG, Thomas-Dehler-Str.
27, D-81737 Mfinchen, Ger-many, Email: jochen.schoepp~sdm.detin (Bordegoni et al, 1996) the tasks of intelligentmultimedia representation systems are discussed in auniform terminology.jects, that are so characteristic as to enable theaddressee to identify the side on which they arelocated.
Based on this information, referring ex-pressions can be generated that exploit informa-tion on relative location of the components of acomplex object.This paper is organised as follows: In section 2,we describe how the content of a computer gener-ated graphics is represented and propose an algo-rithm to compute a set of so-called characteristiccomponent.
The result of our algorithm can beapplied to the generation of referring expressions,as described in section 3.
In section 4, we discussour results by comparing our algorithm with otherreference algorithms.
Section 5 gives a short sum-mary and describes future work.2 Descr ib ing  the  content  o fp ic turesIn this section we describe how we represent thecontent of graphics by an enumeration of the de-picted objects and propose an algorithm to com-pute the characteristic components for a side of acomplex object.
Furthermore, we show the resultsof the algorithm by applying it to an example.2.1 Image descriptionsIn order to describe the content of pictures we enu-merate the visible objects of the picture, the visi-ble sides in the depicted objects, the componentsof complex objects, and the sides on which thecomponents are located.
We refer to this struc-ture as the image description.
This information isencoded in the knowledge representation formal-ism LOOM, a KL-ONE (Brachman and Schmolze,1985) descendent.
The knowledge base also con-tains a linguistically motivated concept hierarchy,the upper model (Bateman, 1990), which is usedfor the multilingual text generation system PEN-MAN (Penman, 1989), that we employ in our sys-tem.73 K. Hartmann and J. Sch6ppAttributes of objects such as their size, colourand the relative position of a component withrespect to other components are obtained frominference processes in other knowledge sourcessuch as the geometric model and the illuminationmodel.
Both representations can be combined byidentical identifiers for the blocks in the geomet-ric model and the corresponding instances in theknowledge base 2.2.2 character i s t i c  omponentsHumans typically refer to the sides of objects withlexemes like front side, bottom side, top side etc.These lexemes refer to directions within a systemof coordinates with two possible origins, eitherwithin the object itself (the intrinsic interpreta-tion) or within the addressee of the generated pre-sentation (the deictic interpretation).
In the pre-sented work we use the intrinsic interpretation.The sides of an object can be characterised by acombination of components unique to them.
Con-fronted with a picture, humans can easily tellwhich intrinsic sides of the presented object arevisible and which sides are hidden by identifyingexactly this characteristic combination of compo-nents.
We call those combinations of componentsthe characteristic components of this side.Take, for instance, the front side of the toasterdepicted in figure 1: This side can be identifiedunambiguously, because the user can identify con-trol devices like the roast intensity selector or theelevating pushbutton, and hence this side can bereferred to as "front side" in the subsequent dis-course.
Similarly, the top side of the toaster canbe identified by recognising the bread slot or themounted rolls support.In the following, we assume that all compo-nents of complex objects are identifiable and dis-tinguishable, which implies that their colour dif-fers from their background, the illumination isperfect, etc.
If this assumption is violated, wecannot rely on referring successfully to unidenti-fiable components of complex objects.
Given thisassumption, we can define a straightforward pro-cedure to compute the characteristic components.Figure 2 presents the formal criterion for a setof components o be characteristic components ofa given side s. The variable ,S denotes a set ofother sides of the given object.
Note, that s isnot a member of 8.
To simplify the definition'snotation, we introduce the set O,~ of componentswhich are located on the side si.
The basic idea2As objects in the geometric model are associatedto instances in the knowledge base, we use the termsobject and instance synonymously.d.,,.~.7t -  b- -aa roast intensity selectorb elevating pushbuttonc crumb drawerd mounted rolls supporte cable take-up reelf stop buttonFigure 1: A complex object with some labelledcomponents (Instructions for Use of the ToasterSiemens TT  621)underlying this definition is to ensure that the setC is a distinctive characterisation f the side s withrespect o the set S of other sides under the equiv-alence relation indistinguishable.In our model, we assume that one cannot dis-tinguish instances of the same concept, becausewe assume that the type attribute has a higherdiscriminating value than other attributes uch asits colour or location.
So we define the relationind is t ingu ishab le (o l ,  o2) to be true iff the in-stances ol and o2 belong to the same direct super-concept, and false otherwise.
A simple implicationof the characteristic component criterion is, thatif one is able to distinguish arbitrary componentsC8~S _{ C I 08 = {pl is-located-on(p, s)} AdCO,  A-~3s' \[ s' E S h0, ,  = {p' l is-located-on(p', s )} A( C/=-indistinguishable C_0.,/_-_indistinguishable ) \] }Figure 2: The characteristic component criterionExploiting Image Descriptions for the Generation of Referring Expressions 7559, := {p \[ is-located-on(p, s)}?
:=0Candidates := PowerSet(O,)whi le (Candidates # 0) doCandidate := member(Candidates)check := t ruefor si in S do59s, : :  {p \[ is-located-on(p, si)}if  ( Candidate/ .
.
.
.
.
.
.
.
.
.
C " --lnOlstlngulsnaDle --Os~/---indistinguishable )then check := falsefiodi f  (check = true)then C := C U CandidateflCandidates := Candidates \ { Candidate}odre turn  CFigure 3: The algorithm to compute the charac-teristic component setformation which components are located on whichsides of the complex objects, the system can rea-son about the visible components and the charac-teristic components of the intrinsic sides.2.3 An  exampleConsider the following example: Given a complexobject, we denote the sides of the object with siand the set of all the sides 81, .
.
.
,  S 6 with ,5.
Withaj, bj, cj, dj, and ej we denote instances of theconcepts A, B, C, D and E respectively.side components  c(s i ,3\  {si})81 al,  bl {}82 a2,c2 {}83 b3, C3 { }84 C4 (}s5 ds, e5 {{ds}, {es}, {ds, es}}S6 as, b6, c6 { {a6, b6, c6 } }Figure 4: A complex object and some componentswhich are located on its intrinsic sides.
Columnone denotes the sides of the object, the secondcolumn displays the range of the is-located-onrelation, and the third column depicts the resultof our algorithm.01 and 02 (i.e.
ind is t ingu ishab le(Ol ,  02) is falsefor arbitrary components 01 and 02), every com-ponent is a characteristic component for the sideon which it is located.However, it might not be sufficient o discrim-inate between instances of different concepts, be-cause the differentiation, which leads to the defini-tion of subconcepts for a common superconcept,reflects assumptions on the shared knowledge ofthe intended user group.
Different user groupsmight not agree on the distinctions drawn in theknowledge base and thus make finer or coarser dis-tinctions between objects.
Nevertheless, as usermodelling is not the focus of this work, we do notinvestigate this topic.The algorithm in figure 3 computes the char-acteristic omponents for a given side s using thecriterion above.
First, the powerset of the com-ponents which are located on side s, is computedand afterwards it is checked for each member ofthis powerset whether the characteristic compo-nent criterion is fulfilled.
There can be none, oneor several sets of characteristic components for agiven side of a complex object.
We can furtherconstrain our definition by adding a minimalitycondition.Using the model described in section 2.1 wehave developed a simple formalism to describe thevisible sides of the object.
Together with the in-If we apply the characteristic component al-gorithm to the example given in figure 4, theset of characteristic omponents of side s5 is{{ds}, {es}, {ds,es}}.
This implies that the ad-dressee can identify the side s5 when either recog-nising an instance of the concept D or an instanceof the concept E. There exist two minimal setsof characteristic components with respect o thisside.
The set of characteristic components of sides6 is {{as, b6,cs}}, which implies that the sidess can be identified only when recognising an in-stance of concepts A, B and C. The addresseehas to identify an instance of each concept, be-cause combinations of instances of two of theseconcepts can be found on the sides sl, s2 and s3.In contrast o the sides s~ and s6, the sides sl,s2, s3 and s4 cannot be identified by exploitingthe knowledge regarding which components are lo-cated on these sides, as instances of the conceptsA, B and C are located on side s6.3 Generation of referringexpressionsIn (Dale and Reiter, 1995, p. 259) it is assumedthat "a referring expression contains two kinds ofinformation: nav igat ion  and discrimination.Each descriptor used in a referring expressionplays one of these two roles.
Navigational, or76 K. Hartmann and J. SchSppat tent ion -d i rec t ing  information, is intended tobring the referent in the hearer's focus of atten-tion \[while\] discriminating information is intendedto distinguish the intended referent from other ob-jects in the hearer's focus of attention".
In the fol-lowing, we show how we compute navigational nddiscriminating descriptions of a given intended ref-erent, especially a component of a complex object,using the results of our characteristic componentalgorithm.As shown in example 4, the characteristic com-ponent algorithm computes ets of characteristiccomponents for the intrinsic sides of a given com-plex object.
Assuming that the system wants torefer to a component of the complex object, theintended referent can be an element of a unary set,of a non-unary set or it can be no element of a setof characteristic components at all.
We will anal-yse all these cases in turn.
Where the intended ref-erent belongs to several characteristic componentsets, the system selects one, preferring the small-est set, in order to generate referring expressionswhich employ a minimal number of descriptors.Case  1: The  in tended referent  is a un iquecharacter i s t i c  component .
Figure 1 shows thefront side, the top side and the right side of atoaster.
The elevating pushbutton and the roastintensity selector are both elements of a unaryset of characteristic components for the front side.Hence, one can refer unambiguously to these com-ponents in an associated text, because the ad-dressee can unambiguously distinguish these com-ponents from all components which are located onthe other sides of the depicted toaster and henceno navigational description is necessary.Press the spray button.Figure 5: An example for a missing co-referentialcoordination between text and graphics (AndrE,1995, page 80)However, the characteristic omponent algo-rithm considers only the components which arelocated on other sides, but not the componentswhich are located on the same side.
For the gen-eration of referring expressions, the intended ref-erent has also to be distinguished from the othercomponents on the same side of the complex ob-ject.
Figure 5, for instance, shows a detail ofan iron with two buttons on the top side.
Ac-cording to the characteristic component algorithmboth buttons represent unique characteristic com-ponents for the top side of the depicted electriciron, and hence no navigational description is gen-erated.Nevertheless, we still have to provide discrimi-nating descriptions for the intended referent withrespect o the set of the components of the sametype on that side.
As the colour and the shapeof both buttons in example 5 do not differ, wehave to exploit information on the relative loca-tion, which enables us to generate a sentence like"Press the left button, which is the spray button".This establishes a co-referential connection be-tween the referent of the nominal phrase "thespray button" and the left button on the top side,which can be exploited in the subsequent dia-logue.
In contrast o that, an augmentation ofthe depicted graphics with an arrow is proposedby (Andre, 1995, page 81) in order to establishthis co-reference.Case  2: The  in tended re ferent  is not  aun ique  character i s t i c  component ,  but  an el-ement  o f  a set  o f  character i s t i c  components .Since the set of characteristic components enablesthe hearer to infer on which side these compo-nents are located, no further navigational infor-mation is needed, if all components of that setare mentioned in the referring expression.
For theconstruction of the referring expression, we com-pute a set of discriminating descriptions for theintended referent with respect o the other com-ponents in the set of characteristic components C'(formally C' is the set difference of the set of char-acteristic omponents C and the intended referent{r}).
These discriminating descriptions of the in-tended referent should be perceptually recognis-able, like its colour, shape or the relative locationwith respect o the other components in C' andcan be retrieved from the illumination model orthe geometric model.If we use the relative location of the intendedreferent with respect o all the components in C'for generating the referring expression, no furthernavigational information eeds to be included, asthe intended referent ogether with C' specifies aExploiting Image Descriptions for the Generation of Referring Expressions 77set of characteristic components and all the com-ponents of this characteristic component set arementioned in the referring expression.In example 4, the component a6 on side s8 is in-cluded in the set {a6, b6, ~ } of characteristic com-ponents.
To enable the addressee to distinguishthe intended referent a6 from b6 and c6, we haveto provide further descriptors.
Thus, we have tosearch for perceptually recognisable attributes ofa6 like its colour, shape - -  or its relative locationwith respect o b6 and c6.Case 3: The intended referent is not anelement of a characterist ic component  setat all.
Navigational information indicating onwhich side the intended referent is located has tobe included.
In addition, we have to provide dis-criminating descriptions for the intended referentthat distinguish it from all the other componentswhich are located on this side.
This set of discrim-inating descriptions can be computed by a tradi-tional reference algorithm.
If the system intendsto refer to the component al of side sl in exam-ple 4, it would insert the name of the side sl asnavigational information and the set of attributeswhich distinguishes al from bl.4 D iscuss ionIn previous work to generate referring expressionsseveral algorithms were proposed (Dale and Re-iter, 1995), (Horacek, 1996).
The main goal ofthese algorithms i to compute a referring expres-sion for a given referent, which enables the hearerto distinguish it from all other objects in thehearer's focus of attention, the contrast et.
Daleand Reiter proposed a number of algorithms thatdiffer in their computational complexity.
Since thetask of finding the minimal set of descriptors iNP-hard 3, a number of heuristics are used, whichapproximate he minimal set.The computation of the referring expressionsin our approach is done in a two-stage process:First, we use only the type information to findthe characteristic components of the sides whichcan be used for the generation of navigational de-scriptors.
In a second step, classical reference al-gorithms compute the discriminating informationfor the intended referent with a reduced contrastset using perceptually recoguisable attributes likecolour, shape and relative location of componentswith respect to other components.The proposed characteristic component algo-rithm computes a set of descriptors which enable3The problem can be transformed into the problemto find the minimal size set cover, which is proven tobe NP-haxd (Garey and Johnson, 1979).the addressee to identify a side of a given complexobject in contrast o the set of the other sidesof the given object.
For the characteristic com-ponent algorithm, while the intended referent isthe given side of the object, the other sides ofthe object can be considered as the contrast setin Dale & Reiter's terms.
In contrast o (Daleand Reiter, 1995) where at most one descriptorset is computed which distinguishes the referentfrom all other objects in the contrast set, our algo-rithm computes all minimal descriptor sets.
Thealgorithm is far more expensive than classical ref-erence algorithms, because we calculate all min-imal distinguishing descriptions of the given sideusing only the type attribute.
On the other hand,this enables us to use sources other than the part-whole relation (IDAS (Reiter et al, 1995)) or thespatial inclusion relation (KAMP (Appelt, 1985))for the generation of the navigational part of thereferring expression.The set of characteristic components containsno negative expressions.
Negative expressionswould enable us to compute characteristic compo-nents of sides, for which the proposed algorithmcomputes an empty set of characteristic compo-nents.
On the other hand, that would force us togenerate r ferring expressions which contain state-ments about components hat are not located onthe same side as the intended component.
Wethink that statements of this kind would confusethe addressee.This proposed work incorporates propositionaland analogue representation as suggested by (Ha-bel et al, 1995).
Within the VisDok-project (visu-alization in technical documentation), wedecidedto combine geometric information and informa-tion gained from the illumination model with apropositional representation f the type of the ob-jects in a knowledge base.A first prototypical system for the generation ofmultimodal multilingual documentation for tech-nical devices within an interactive setting has beenrealised.
We employ separate processes for therendering of predefined pictures and animations,and text generation.
Our algorithm enables us tominimise the time-consuming communication be-tween separate processes in order to generate re-ferring expressions, as the procedure described insection 3 relies only partly on perceptually recog-nisable attributes of objects like colour, shapeand relative location while employing the typeattribute, which is explicitly represented in theknowledge base.78 K. Hartrnann and J. SchSpp5 Summary  and  fu ture  workIn this paper, we have presented a combinedpropositional and analogue representation f theobjects displayed in graphics and animations.
Wepropose an algorithm based on this representa-tion, which computes a set of characteristic com-ponents for a given complex object.
The informa-tion on the characteristic components of the in-trinsic sides of the given complex object is usedto generate referring expressions of both kinds,navigational and discriminating descriptions thatestablish co-referential relation between text andgraphics.We plan to combine the approach presented inthis work with the results of the Hyper-Renderer(Emhardt and Strothotte, 1992), which stores in-formation about visible objects and their texture.This information is computed as a side effect ofthe rendering algorithm and can be used in ourframework.
Especially for complex objects, theis-located-on relation can be computed auto-matically and serves as the input data for our al-gorithm.6 AcknowledgementThe authors want to thank Brigitte Grote, lanPitt, BjSrn HSfiing and Oliver Brandt for dis-cussing the ideas presented in this paper and acareful reading.ReferencesElisabeth Andrd, Jochen Miiller, and ThomasPost.
1996.
The PPP Persona: A MultipurposeAnimated Presentation Agent.
In Advanced Vi-sual Interfaces, pages 245-247.
ACM Press.Elisabeth Andrd.
1995.
Ein planbasierter Ansatzzur Generierung multimedialer PrSsentationen.infix Verlag.Douglas E. Appelt.
1985.
Planning EnglishSentences.
Cambridge University Press, Cam-bridge, UK.John A. Bateman.
1990.
Upper Modeling: Or-ganizing Knowledge for Natural Language Pro-cessing.
In 5th International Workshop onNatural Language Generation, 3-6 June 1990,Pittsburgh, PA.M.
Bordegoni, G. Faconti, T. Post, S. Ruggieri,P.
Trahanias, and M. Wilson.
1996.
Intelli-gent Multimedia Presentation Systems: A Pro-posal for a Reference Model.
In J.-P. Cour-tiat, M. Diaz, and P. Sdnac, editors, MultimediaModeling: Towards the Information Superhigh-way, pages 3-20.
World Scientific, Singapore.Ronald J. Brachman and J. Schmolze.
1985.
AnOverview of the K1-ONE Knowledge Represen-tation System.
Cognitive Science, 9(2):171-216.Robert Dale and Ehud Reiter.
1995.
Computa-tional Interpretations of the Gricean Maxims inthe Generation of Referring Expressions.
Cog-nitive Science, 19(2):233-263.Jiirgen Emhardt and Thomas Strothotte.
1992.Hyper-Rendering.
In Proc.
of the Graphics In-terfaces 'gP, pages 37-43, Vancouver, Canada,May 13-15.Steve K. Feiner and Kathleen R. McKeown.
1993.Automating the Generation of CoordinatedMultimedia Explanations.
In M. T. Maybury,editor, Intelligent Multimedia Interfaces, pages117-138.
AAAI Press, Menlo Park, CA.W.
Garey and D. Johnson.
1979.
Computers andIntractability: A Guide to the Theory of NP-Completeness.
W. H. Freeman, San Fransisco.Christopher Habel, Simone Pribbenow, and Ge-offrey Simmons.
1995.
Partonomies and De-pictions: A Hybrid Approach.
In B. Chan-drasekaran J. Glasgow, H. Narayanan, editor,Diagrammatic Reasoning: Computational andCognitive Perspectives.
AAAI/MIT Press.Helmut Horacek.
1996.
A new Algorithm forGenerating Referential Descriptions.
In Wolf-gang Wahlster, editor, Proceedings of the 1PthEuropean Conference on Artificial Intelligence(ECAI'96), pages 577-581, Budapest, Hungary,August 11-19.
John Wiley & Sons LTD., Chich-ester, New York, Bribane, Toronto, Singuapure.Penman Project.
1989.
PENMAN Documenta-tion: the Primer, the User Guide, the Refer-ence Manual, and the Nigel Manual.
Techni-cal report, USC/Information Sciences Institute,Marina del Rey, California.Ehud Reiter, Chris Mellish, and John Levine.1995.
Automatic Generation of Technical Doc-umentation.
Applied Artificial Intelligence,9:259-287.Wolfgang Wahlster, Elisabeth AndrE, WolfgangFinkler, Hans-Jfirgen Profitlich, and ThomasPOst.
1993.
Plan-based Integration of NaturalLanguage and Graphics Generation.
ArtificialIntelligence, 63:387-427.
