Text Chunking using Transformation-Based LearningLance A. RamshawDept.
of Computer ScienceBowdoin CollegeBrunswick, ME 04011 USAramshaw@polar, bowdoin, eduMitchell P. MarcusComputer and Information Science Dept.University of PennsylvaniaPhiladelphia, PA 19104-6389 USAmit ch?linc, cis.
upenn, eduAbstractEric Brill introduced transformation-based learning and showed that it can do part-of-speech tagging with fairly high accuracy.
The same method can be applied at a higherlevel of textual interpretation for locating chunks in the tagged text, including non-recursive"baseNP" chunks.
For this purpose, it is convenient to view chunking as a tagging problemby encoding the chunk structure in new tags attached to each word.
In automatic tests usingTreebank-derived data, this technique achieved recall and precision rates of roughly 92% forbaseNP chunks and 88% for somewhat more complex chunks that partition the sentence.
Someinteresting adaptations to the transformation-based learning approach are also suggested bythis application.1 IntroductionText chunking involves dividing sentences into nonoverlapping segments on the basis of fairlysuperficial analysis.
Abney (1991) has proposed this as a useful and relatively tractable precursorto full parsing, since it provides a foundation for further levels of analysis including verb-argumentidentification, while still allowing more complex attachment decisions to be postponed to a laterphase.
Since chunking includes identifying the non-recursive portions of noun phrases, it can alsobe useful for other purposes including index term generation.Most efforts at superficially extracting segments from sentences have focused on identifyinglow-level noun groups, either using hand-built grammars and finite state techniques or usingstatistical models like HMMs trained from corpora.
In this paper, we target a somewhat higherlevel of chunk structure using Brill's (1993b) transformation-based learning mechanism, in whicha sequence of transformational ru es is learned from a corpus; this sequence iteratively improvesupon a baseline model for some interpretive feature of the text.
This technique has previouslybeen used not only for part-of-speech tagging (Brill, 1994), but also for prepositional phraseattachment disambiguation (Brill and Resnik, 1994), and assigning unlabeled binary-branchingtree structure to sentences (Brill, 1993a).
Because transformation-based learning uses pattern-action rules based on selected features of the local context, it is helpful for the values beingpredicted to also be encoded locally.
In the text-chunking application, encoding the predictedchunk structure in tags attached to the words, rather than as brackets between words, avoidsmany of the difficulties with unbalanced bracketings that would result if such local rules wereallowed to insert or alter inter-word brackets directly.In this study, training and test sets marked with two different ypes of chunk structure werederived algorithmically from the parsed data in the Penn Treebank corpus of Wall Street Journal82text (Marcus et al, 1994).
The source texts were then run through Brill's part-of-speech tagger(Brill, 1993c), and, as a baseline heuristic, chunk structure tags were assigned to each wordbased on its part-of-speech tag.
Rules were then automatically earned that updated these chunkstructure tags based on neighboring words and their part-of-speech and chunk tags.
Applyingtransformation-based learning to text chunking turns out to be different in interesting ways fromits use for part-of-speech tagging.
The much smaller tagset calls for a different organization ofthe computation, and the fact that part-of-speech assignments a well as word identities are fixedsuggests different optimizations.2 Text ChunkingAbney (1991) has proposed text chunking as a useful preliminary step to parsing.
His chunks areinspired in part by psychological studies of Gee and Grosjean (1983) that link pause durations inreading and naive sentence diagraming to text groupings that they called C-phrases, which veryroughly correspond to breaking the string after each syntactic head that is a content word.
Ab-ney's other motivation for chunking is procedural, based on the hypothesis that the identificationof chunks can be done fairly dependably by finite state methods, postponing the decisions thatrequire higher-level analysis to a parsing phase that chooses how to combine the chunks.2.1 Ex is t ing  Chunk  Ident i f i ca t ion  Techn iquesExisting efforts at identifying chunks in text have been focused primarily on low-level noun groupidentification, frequently as a step in deriving index terms, motivated in part by the limitedcoverage of present broad-scale parsers when dealing with unrestricted text.
Some researchershave applied grammar-based methods, combining lexical data with finite state or other grammarconstraints, while others have worked on inducing statistical models either directly from thewords or from automatically assigned part-of-speech classes.On the grammar-based side, Bourigault (1992) describes a system for extracting "termino-logical noun phrases" from French text.
This system first uses heuristics to find "maximal lengthnoun phrases", and then uses a grammar to extract "terminological units."
For example, fromthe maximal NP le disque dur de la station de travail it extracts the two terminological phrasesdisque dur, and station de travail.
Bourigault claims that the grammar can parse "around 95%of the maximal length noun phrases" in a test corpus into possible terminological phrases, whichthen require manual validation.
However, because its goal is terminological phrases, it appearsthat this system ignores NP chunk-initial determiners and other initial prenominal modifiers,somewhat simplifying the parsing task.Voutilalnen (1993), in his impressive NPtool system, uses an approach that is in some wayssimilar to the one used here, in that he adds to his part-of-speech tags a new kind of tag that showschunk structure; the chunk tag "@>N", for example, is used for determiners and premodifiers,both of which group with the following noun head.
He uses a lexicon that lists all the possiblechunk tags for each word combined with hand-built constraint grammar patterns.
These patternseliminate impossible readings to identify a somewhat idiosyncratic kind of target noun groupthat does not include initial determiners but does include postmodifying prepositional phrases(including determiners).
Voutilainen claims recall rates of 98.5% or better with precision of 95%or better.
However, the sample NPtool analysis given in the appendix of (Voutilainen, 1993),appears to be less accurate than claimed in general, with 5 apparent mistakes (and one unresolvedambiguity) out of the 32 NP chunks in that sample, as listed in Table 1.
These putative rrors,83combined with the claimed high performance, suggest that NPtool's definition of NP chunk i.s alsotuned for extracting terminological phrases, and thus excludes many kinds of NP premodifiers,again simplifying the chunking task.NPtool parse Apparent correct parseless \[time\] \[less time\]the other hand the \[other hand\]many \[advantages\] \[many advantages\]\[b!nary addressing\] \[binary addressing andand \[instruction formats\] instruction formats\]a purely \[binary computer\] a \[purely binary computer\]Table 1: Apparent errors made by Voutilainen's NPtoolKupiec (1993) also briefly mentions the use of finite state NP recognizers for both Englishand French to prepare the input for a program that identified the correspondences between NPsin bilingual corpora, but he does not directly discuss their performance.Using statistical methods, Church's Parts program (1988), in addition to identifying partsof speech, also inserted brackets identifying core NPs.
These brackets were placed using astatistical model trained on Brown corpus material in which NP brackets had been insertedsemi-automatically.
In the small test sample shown, this system achieved 98% recall for correctbrackets.
At about the same time, Ejerhed (1988), working with Church, performed comparisonsbetween finite state methods and Church's stochastic models for identifying both non-recursiveclauses and non-recursive NPs in English text.
In those comparisons, the stochastic methodsoutperformed the hand built finite-state models, with claimed accuracies of 93.5% (clauses) and98.6% (NPs) for the statistical models compared to to 87% (clauses) and 97.8% (NPs) for thefinite-state methods.Running Church's program on test material, however, reveals that the definition of NP em-bodied in Church's program is quite simplified in that it does not include, for example, structuresor words conjoined within NP by either explicit conjunctions like "and" and "or", or implicitlyby commas.
Church's chunker thus assigns the following NP chunk structures:\[a Skokie\], \[hi.\] , \[subsidiary\]\[newer\], [big-selling prescriptions drugs\]\[the inefficiency\] , \[waste\] and \[lack\] of \[coordination\]\[Kidder\], \[Peabody\] ~ \[Co\]It is difficult to compare performance figures between studies; the definitions of the targetchunks and the evaluation methodologies differ widely and are frequently incompletely specified.All of the cited performance figures above also appear to derive from manual checks by theinvestigators of the system's predicted output, and it is hard to estimate the impact of thesystem's uggested chunking on the judge's determination.
We believe that the work reportedhere is the first study which has attempted to find NP chunks subject only to the limitation thatthe structures recognized o not include recursively embedded NPs, and which has measuredperformance by automatic omparison with a preparsed corpus.842.2 Der iv ing  Chunks  f rom Treebank  ParsesWe performed experiments using two different chunk structure targets, one that tried to bracketnon-recursive "baseNPs" and one that partitioned sentences into non-overlapping N-type andV-type chunks, loosely following Abney's model.
Training and test materials with chunk tagsencoding each of these kinds of structure were derived automatically from the parsed Wall StreetJournal text in the Penn Treebank (Marcus et al, i994).
While this automatic derivation processintroduced a small percentage of errors of its own, it was the only practical way both to providethe amount of training data required and to aJlow for fully-automatic testing.The goal of the "baseNP" chunks was to identify essentially the initial portions of non-recursive noun phrases up to the head, including determiners but not including postmodifyingprepositional phrases or clauses.
These chunks were extracted from the Treebank parses, basicallyby selecting NPs that contained no nested NPs 1.
The handling of conjunction followed that ofthe Treebank annotators as to whether to show separate baseNPs or a single baseNP spanningthe conjunction 2.
Possessives were treated as a special case, viewing the possessive marker as thefirst word of a new baseNP, thus flattening the recursive structure in a useful way.
The followingsentences give examples of this baseNP chunk structure:During \[N the third quarter N\] , IN Compaq N\] purchased \[N a former WangLaboratories manufacturing facility N\] in \[N Sterling N\], \[N Scotland N\], which willbe used for IN international service and repair operations N\] ?\[N The government N\] has \[N other agencies and instruments N\] for pursuing\[N these other objectives N\] ?Even IN Mao Tse-tung N\] \[N's China/v\] began in \[N 1949 N\] with \[N apartnership N\] between \[N the communists N\] and \[N a number N\] of IN smaller ,non-communist parties N\] ?The chunks in the partitioning chunk experiments were somewhat closer to Abney's model,where the prepositions in prepositional phrases are included with the object NP up to the headin a single N-type chunk.
This created substantial additional ambiguity for the system, whichhad to distinguish prepositions from particles.
The handling of conjunction again follows theTreebank parse with nominal conjuncts parsed in the Treebank as a single NP forming a singleN chunk, while those parsed as conjoined NPs become separate chunks, with any coordinatingconjunctions attached like prepositions to the following N chunk.The portions of the text not involved in N-type chunks were grouped as chunks termed V-type, though these "V" chunks included many elements that were not verbal, including adjectivephrases.
The internal structure of these V-type chunks loosely followed the Treebank parse,though V chunks often group together elements that were sisters in the underlying parse tree.Again, the possessive marker was viewed as initiating a new N-type chunk.
The following sen-tences are annotated with these partitioning N and V chunks:\[N Some bankers N\] \[v are reporting v\] \[N more inquiries than usual N\] IN aboutCDs N\] \[N since Friday N\] ?1This heuristic fails in some cases.
For example, Treebank uses the label NAG for some NPs functioning aspremodifiers, like "Bank of England" in "Robin Leigh-Pemberton, Bank of England governor, conceded.."; in suchcases, "governor" is not included in any b~eNP chunk.2Non-constituent NP conjunction, which Treebank labels NX, is another example that still causes problems.85I Training CorpusRule TemplatesCorrect AnswersI Learned Rule SequenceBaseline System \]~ Derive~d Sc?re I !e I Candidate Rules Cu nt Corpus~1 Select Rule \] ?Apply RuleIFigure 1: Transformation-Based Learning\[N Eastern Airlines N\] \[N ' creditors N\] \[V have begun exploring v\] \[N alternativeapproaches N\] \[N to a Chapter 11 reorganization N\] \[Y because v\] \[g they Y\]\[Y areunhappy v\] \[g with the carrier N\] \ [g ' s  latest proposal N\] ?\[N Indexing N\] \[N for the most part N\] \[v has involved simply buying v\] \[w and thenholding v\] \[Y stocks N\] \[Y in the correct mix N\] \[Y to mirror V\] \[g a stock marketbarometer g\] ?These two kinds of chunk structure derived from the Treebank data were encoded as chunktags attached to each word and provided the targets for the transformation-based l arning.3 The Transformation-based Learning ParadigmAs shown in Fig.
1, transformation-based l arning starts with a supervised training corpus thatspecifies the correct values for some linguistic feature of interest, a baseline heuristic for predictinginitial values for that feature, and a set of rule templates that determine a space of possibletransformational rules.
The patterns of the learned rules match to particular combinations offeatures in the neighborhood surrounding a word, and their action is to change the system'scurrent guess as to the feature for that word.To learn a model, one first applies the baseline heuristic to produce initial hypotheses foreach site in the training corpus.
At each site where this baseline prediction is not correct, thetemplates are then used to form instantiated candidate rules with patterns that test selectedfeatures in the neighborhood of the word and actions that correct the currently incorrect tagassignment.
This process eventually identifies all the rule candidates generated by that templateset that would have a positive effect on the current ag assignments anywhere in the corpus.Those candidate rules are then tested against the rest of corpus, to identify at how manylocations they would cause negative changes.
One of those rules whose net score (positive changesminus negative changes) is maximal is then selected, applied to the corpus, and also writtenout as the first rule in the learned sequence.
This entire learning process is then repeatedon the transformed corpus: deriving candidate rules, scoring them, and selecting one with themaximal positive effect.
This process is iterated, leading to an ordered sequence of rules, withrules discovered first ordered before those discovered later.
The predictions of the model on new86itext are determined by beginning with the baseline heuristic prediction and then applying eachrule in the learned rule sequence in turn.4 Transformational Text ChunkingThis section discusses how text chunking can be encoded as a tagging problem that can beconveniently addressed using transformational learning.
We also note some related adaptationsin the procedure for learning rules that improve its performance, taking advantage of ways inwhich this task differs from the learning of part-of-speech tags.4.1 Encoding ChoicesApplying transformational learning to text chunking requires that the system's current hypothesesabout chunk structure be represented in a way that can be matched against he pattern parts ofrules.
One way to do this would be to have patterns match tree fragments and actions modifytree geometries, as in Brill's transformational parser (1993a).
In this work, we have found itconvenient to do so by encoding the chunking using an additional set of tags, so that each wordcarries both a part-of-speech tag and also a "chunk tag" from which the chunk structure can bederived.In the baseNP experiments aimed at non-recursive NP structures, we use the chunk tag set( I ,  G, B}, where words marked I are inside some baseNP, those marked O are outside, and the Btag is used to mark the left most item of a baseNP which immediately follows another baseNP.In these tests, punctuation marks were tagged in the same way as words.In the experiments hat partitioned text into N and V chunks, we use the chunk tag set {BN,N, BV, V, P), where BN marks the first word and N the succeeding words in an N-type groupwhile BY and Y play the same role for V-type groups.
Punctuation marks, which are ignored inAbney's chunk grammar, but which the Treebank data treats as normal lexical items with theirown part-of-speech tags, are unambiguously assigned the chunk tag P. Items tagged P are allowedto appear within N or V chunks; they are irrelevant as far as chunk boundaries are concerned,but they are still available to be matched against as elements of the left hand sides of rules.Encoding chunk structure with tags attached to words rather than non-recursive bracketmarkers inserted between words has the advantage that it limits the dependence b tween differentelements of the encoded representation.
While brackets must be correctly paired in order to derivea chunk structure, it is easy to define a mapping that can produce a valid chunk structure fromany sequence of chunk tags; the few hard cases that arise can be handled completely locally.
Forexample, in the baseNP tag set, whenever a B tag immediately follows an 0, it must be treatedas an I, and, in the partitioning chunk tag set, wherever a V tag immediately follows an N tagwithout any intervening BV, it must be treated as a BV.4.2 Base l ine  SystemTransformational learning begins with some initial "baseline" prediction, which here means abasehne assignment of chunk tags to words.
Reasonable suggestions for baseline heuristics aftera text has been tagged for part-of-speech might include assigning to each word the chunk tagthat it carried most frequently in the training set, or assigning each part-of-speech tag the chunktag that was most frequently associated with that part-of-speech tag in the training.
We testedboth approaches, and the baseline heuristic using part-of-speech tags turned out to do better, so87it was the one used in our experiments.
The part-of-speech tags used by this baseline heuristic,and then later also matched against by transformational ru e patterns, were derived by runningthe raw texts in a prepass through Brill's transformational part-of-speech tagger (Brill, 1993c).4.3 Rule TemplatesIn transformational learning, the space of candidate rules to be searched is defined by a set ofrule templates that each specify a small number of particular feature sets as the relevant factorsthat a rule's left-hand-side pattern should examine, for example, the part-of-speech tag of theword two to the left combined with the actual word one to the left.
In the preliminary scan of thecorpus for each learning pass, it is these templates that are applied to each location whose currenttag is not correct, generating a candidate rule that would apply at least at that one location,matching those factors and correcting the chunk tag assignment.When this approach is applied to part-of-speech tagging, the possible sources of evidence fortemplates involve the identities of words within a neighborhood ofsome appropriate size and theircurrent part-of-speech tag assignments.
In the text chunking application, the tags being assignedare chunk structure tags, while the part-of-speech tags are a fixed part of the environment, likethe lexical identities of the words themselves.
This additional class of available information causesa significant increase in the number of reasonable templates if templates for a wide range of thepossible combinations of evidence are desired.
The distributed version of Brill's tagger (Brill,1993c) makes use of 26 templates, involving various mixes of word and part-of-speech tests onneighboring words.
Our tests were performed using 100 templates; these included almost all ofBrill's combinations, and extended them to include references to chunk tags as well as to wordsand part-of-speech tags.The set of 100 rule templates used here was built from repetitions of 10 basic patterns, shownon the left side of Table 2 as they apply to words.
The same 10 patterns can also be used to matchagainst part-of-speech tags, encoded as P0, P - l ,  etc.
(In other tests, we have explored mixedtemplates, that match against both word and part-of-speech values, but no mixed templates wereused in these experiments.)
These 20 word and part-of-speech patterns were then combined witheach of the 5 different chunk tag patterns hown on the right side of the table.
The cross productof the 20 word and part-of-speechpatterns withthe 5 chunk tag patterns determined the full setof 100 templates used.PatternWoW-1W1W- l ,  W0Wo, WlW-l, WlW_~, W-1W1, W2W-1,-2,-3W1,2,3Word Patterns Tag PatternsMeaning Pattern Meaningcurrent wordword 1 to leftword 1 to rightcurrent word and word to leftcurrent word and word to rightword to left and word to righttwo words to lefttwo words to rightword 1 or 2 or 3 to leftword 1 or 2 or 3 to rightT0T- l ,  ToTo, T1T-2, T-1T1, T2current agcurrent ag and tag to leftcurrent ag and tag to righttwo tags to lefttwo tags to rightTable 2: Patterns used in Templates885 Algorithm Design IssuesThe large increase in the number of rule templates in the text chunking application when com-pared to part-of-speech tagging pushed the training process against he available limits in termsof both space and time, particularly when combined with the desire to work with the largestpossible training sets.
Various optimizations proved to be crucial to make the tests describedfeasible.5.1 Organ izat ion  of  the  Computat ionOne change in the algorithm is related to the smaller size of the tag set.
In Brill's tagger (Brill,1993c), an initial calculation in each pass computes the confusion matrix for the current tagassignments and sorts the entries of that \[old-tag x new-tag\] matrix, so that candidate rules canthen be processed in decreasing order of the maximum possible benefit for any rule changing,say, old tag I to new tag J.
The search for the best-scoring rule can then be halted when a cellof the confusion matrix is reached whose maximum possible benefit is less than the net benefitof some rule already encountered.The power of that approach is dependent on the fact that the confusion matrix for part-of-speech tagging partitions the space of candidate rules into a relatively large number of classes,so that one is likely to be able to exclude a reasonably large portion of the search space.
In achunk tagging application, with only 3 or 4 tags in the effective tagset, this approach based onthe confusion matrix offers much less benefit.However, even though the confusion matrix does not usefully subdivide the space of possiblerules when the tag set is this small, it is still possible to apply a similar optimization by sortingthe entire list of candidate rules on the basis of their positive scores, and then processing thecandidate rules (which means determining their negative scores and thus their net scores) in orderof decreasing positive scores.
By keeping track of the rule with maximum benefit seen so far, onecan be certain of having found one of the globally best rules when one reaches candidate rules inthe sorted list whose positive score is not greater than the net score of the best rule so far.5.2 Index ing  Sta t i c  Ru le  E lementsIn earlier work on transformational part-of-speech tagging (Ramshaw and Marcus, 1994), wenoted that it is possible to greatly speed up the learning process by constructing a full, bidirec-tional index linking each candidate rule to those locations in the corpus at which it applies andeach location in the corpus to those candidate rules that apply there.
Such an index allows theprocess of applying rules to be performed without having to search through the corpus.
Unfortu-nately, such complete indexing proved to be too costly in terms of physical memory to be feasiblein this application.However, it is possible to construct a limited index that lists for each candidate rule thoselocations in the corpus at which the static portions of its left-hand-side pattern match.
Becausethis index involves only the stable word identity and part-of-speech tag values, it does not requireupdating; thus it can be stored more compactly, and it is also not necessary to maintain backpointers from corpus locations to the applicable rules.
This kind of partial static index proved tobe a significant advantage in the portion of the program where candidate rules with relatively highpositive scores are being tested to determine their negative scores, since it avoids the necessityof testing such rules against every location in the corpus.89Training Recall Error Red.
Precision Error Red.
Corr.
Tag Error Red.Baseline 81.9% 78.2% 94.5%50K 90.4% 47.2% 89.8% 53.1% 96.9% 44.4%100K 91.8% 54.8% 91.3% 60.0% 97.2% 49.6%200K 92.3% 57.4% 91.8% 62.4% 97.4% 53.4%Table 3: BaseNP Chunk ResultsTraining Recall Error Red.
Precision Error Red.
Corr.
Tag Error Red.Baseline 60.0% 47.8% 78.0%50K 86.6% 66.6% 85.8% 72.8% 94.4% 74.4%100K 88.2% 70.4% 87.4% 75.8% 95.0% 77.3%200K 88.5% 71.1% 87.7% 76.5% 95.3% 78.5%Table 4: Partitioning Chunk Results5.3 Heur i s t i c  D isab l ing  of  Un l ike ly  Ru lesWe also investigated a new heuristic to speed up the computation: After each pass, we disable allrules whose positive score is significantly lower than the net score of the best rule for the currentpass.
A disabled rule is then reenabled whenever enough other changes have been made to thecorpus that it seems possible that the score of that rule might have changed enough to bring itback into contention for the top place.
This is done by adding some fraction of the changes madein each pass to the positive scores of the disabled rules, and reenabling rules whose adjustedpositive scores came within a threshold of the net score of the successful rule on some pass.Note that this heuristic technique introduces ome risk of missing the actual best rule in apass, due to its being incorrectly disabled at the time.
However, empirical comparisons betweenruns with and without rule disabling suggest that conservative use of this technique can producean order of magnitude speedup while imposing only a very slight cost in terms of suboptimalityof the resulting learned rule sequence.6 Resu l tsThe automatic derivation of training and testing data from the Treebank analyses allowed forfully automatic scoring, though the scores are naturally subject to any remaining systematicerrors in the data derivation process as well as to bona fide parsing errors in the Treebank source.Table 3 shows the results for the baseNP tests, and Table 4 shows the results for the partitioningchunks task.
Since training set size has a significant effect on the results, values are shown forthree different raining set sizes.
(The test set in all cases was 50K words.
Training runs werehalted after the first 500 rules; rules learned after that point affect relatively few locations in thetraining set and have only a very slight effect for good or ill on test set performance.
)The first line in each table gives the performance of the baseline system, which assigned abaseNP or chunk tag to each word on the basis of the POS tag assigned in the.prepass.
Perfor-mance is stated in terms of recall (percentage of correct chunks found) and precision (percentageof chunks found that are correct), where both ends of a chunk had to match exactly for it tobe counted.
The raw percentage of correct chunk tags is also given for each run, and for eachperformance measure, the relative error reduction compared to the baseline is listed.
The par-90titioning chunks do appear to be somewhat harder to predict than baseNP chunks.
The highererror reduction for the former is partly due to the fact that the part-of-speech basehne for thattask is much lower.6.1 Analysis of In i t ia l  Ru lesTo give a sense of the kinds of rules being learned, the first 10 rules from the 200K baseNP runare shown in Table 5.
It is worth glossing the rules, since one of the advantages of transformation-based learning is exactly that the resulting model is easily interpretable.
In the first of the baseNPrules, adjectives (with part-of-speech tag J J) that are currently tagged I but that are followedby words tagged 0 have their tags changed to 0.
In Rule 2, determiners that are preceded by twowords both tagged I have their own tag changed to B, marking the beginning of a baseNP thathappens to directly follow another.
(Since the tag B is only used when baseNPs abut, the basehnesystem tags determiners a  I.)
Rule 3 takes words which immediately follow determiners taggedI that in turn follow something tagged 0 and changes their tag to also be I.
Rules 4-6 are similarto Rule 2, marking the initial words of baseNPs that directly follow another baseNP.
Rule 7marks conjunctions (with part-of-speech tag CC) as I if they follow an I and precede a noun,since such conjunctions are more likely to be embedded in a single baseNP than to separate twobaseNPs, and Rules 8 and 9 do the same.
(The word "&" in rule 8 comes mostly from companynames in the Wall St. Journal source data.)
Finally, Rule 10 picks up cases hke "including aboutfour million shares" where "about" is used as a quantifier rather than preposition.Pass1.
I2.3.4.
I5.
I6.
I7.
08.
09.
010.
0Old Tag Context New TagTable 5:T1 = 0, P0 = JJT_:= I, T_I= I, Po=DTT-2 = 0, T_i = I, P-1 = DTT-1 = I, P0=WDTT-1 = I, P0 = PRPT-1 = I, Wo = whoT-1 = I, P0 = CC, P I= NNT i= I ,  W0=&T-1 = I, P0 = CC, P1 = NNST-1 = 0, W0 = about0BIBBBIIIIFirst Ten Basenp Chunk RulesA similar list of the first ten rules for the chunk task can be seen in Table 6.
To gloss a fewof these, in the first rule here, determiners (with part-of-speech tag DT), which usually begin Nchunks and thus are assigned the baseline tag BN, have their chunk tags changed to hl if they followa word whose tag is also BN.
In Rule 2, sites currently tagged N but which fall at the beginningof a sentence have their tags switched to BN.
(The dummy tag Z and word ZZZ indicate that thelocations one to the left are beyond the sentence boundaries.)
Rule 3 changes N to BN after acomma (which is tagged P), and in Rule 4, locations tagged BN are switched to BV if the followinglocation is tagged V and has the part-of-speech tag VB.91Pass1.
BN2.
N3.
N4.
BN5.
N6.
N7.
BV8.
V9.
BV10.
BNOld Tag Context New TagT-1  = BN, P0 = DTT-1 =Z, W-1 = ZZZT-1  = P, P -1  = ~,~T1 =V, P1 = VBT-1 = BV, P-1,-2,-3 = VBDP-1 = VBT-1 = V, P-1,-2,-3 = RBT-1 = N, P-1 , -2 , -3  = NNT-1 = BV, P1,2,3 = VBT-1 = BN, Po = PRP$NBNBNBVBNBNVBVVNTable 6: First Ten Partitioning Chunk Rules6.2  Cont r ibut ion  of  Lex ica l  TemplatesThe fact that this system includes lexical rule templates that refer to actual words sets it apartfrom approaches that rely only on part-of-speech tags to predict chunk structure.
To explore howmuch difference in performance those lexical rule templates make, we repeated the above test runsomitting templates that refer to specific words.
The results for these runs, in Tables 7 and 8, sug-gest that the lexical rules improve performance on the baseNP chunk task by about 1% (roughly5% of the overall error reduction) and on the partitioning chunk task by about 5% (roughly10% of the error reduction).
Thus lexical rules appear to be making a limited contribution indetermining baseNP chunks, but a more significant one for the partitioning chunks.Training Recall Error Red.
Precision Error Red.
Corr.
Tag Error Red.Baseline 81.9% 78.2% 94.5%50K 89.6% 42.7% 88.9% 49.2% 96.6% 38.8%100K 90.6% 48.4% 89.9% 53.7% 96.9% 44.4%200K 90.7% 48.7% 90.5% 56.3% 97.0% 46.0%Table 7: BaseNP Chunk Results Without Lexical TemplatesTraining Recall Error Red.
Precision Error Red.
Corr.
Tag Error Red.Baseline 60.0% 47.8% 78.0%50K 81.8% 54.5% 81.4% 64.4% 92.4% 65.4%100K 82.9% 57.2% 83.0% 67.3% 92.9% 67.9%200K i 83.6% 58.9% 83.5% 68.4% 93.9% 72.2%Table 8: Partitioning Chunk Results Without Lexical Templates6.3 F requent  E r ror  C lassesA rough hand categorization of a sample of the errors from a baseNP run indicates that manyfall into classes that are understandably difficult for any process using only local word and part-of-speech patterns to resolve.
The most frequent single confusion involved words tagged VBGand VBN, whose baseline prediction given their part-of-speech tag was 0, but which also occur92frequently inside baseNPs.
The system did discover some rules that allowed it to fix certain classesof VBG and VBN mistaggings, for example, rules that retagged VBNs as I when they precededan NN or NNS tagged I.
However, many also remained unresolved, and many of those appear tobe cases that would require more than local word and part-of-speech patterns to resolve.The second most common class of errors involved conjunctions, which, combined with theformer class, make up half of all the errors in the sample.
The Treebank tags the words "and"and frequently "," with the part-of-speech tag CC, which the baseline system again predictedwould fall most often outside of a baseNP 3.
However, the Treebank parses do also frequentlyclassify conjunctions of Ns or NPs as a single baseNP, and again there appear to be insufficientclues in the word and tag contexts for the current system to make the distinction.
Frequently, infact, the actual choice of structure assigned by the Treebank annotators seemed largely dependenton semantic indications unavailable to the transformational learner.7 Future DirectionsWe are planning to explore several different paths that might increase the system's power todistinguish the linguistic ontexts in which particular changes would be useful.
One such directionis to expand the template set by adding templates that are sensitive to the chunk structure.
Forexample, instead of referring to the word two to the left, a rule pattern could refer to the firstword in the current chunk, or the last word of the previous chunk.
Another direction would beto enrich the vocabulary of chunk tags, so that they could be used during the learning process toencode contextual features for use by later rules in the sequence.We would also like to explore applying these same kinds of techniques to building largerscale structures, in which larger units are assembled or predicate/argument structures derived bycombining chunks.
One interesting direction here would be to explore the use of chunk structuretags that encode a form of dependency grammar, where the tag "N+2" might mean that thecurrent word is to be taken as partof  the unit headed by the N two words to the right.8 ConclusionsBy representing text chunking as a kind of tagging problem, it becomes possible to easily applytransformation-based learning.
We have shown that this approach is able to automatically inducea chunking model from supervised training that achieves recall and precision of 92% for baseNPchunks and 88% for partitioning N and V chunks.
Such chunking models provide a useful andfeasible next step in textual interpretation that goes beyond part-of-speech tagging, and thatserve as a foundation both for larger-scale grouping and for direct extraction of subunits hkeindex terms.
In addition, some variations in the transformation-based learning algorithm aresuggested by this application that may also be useful in other settings.AcknowledgmentsWe would like to thank Eric Brill for making his system widely available, and Ted Briscoe andDavid Yarowsky for helpful comments, including the suggestion to test the system's performancewithout lexical rule templates.aNote that this is one of the cases where Church's chunker allows eparate NP fragments ocount as chunks.93ReferencesAbney, Steven.
1991.
Parsing by chunks.
In Berwick, Abney, and Tenny, editors, Principle-BasedParsing.
Kluwer Academic Publishers.Bourigault, D. 1992.
Surface grammatical analysis for the extraction of terminological nounphrases.
In Proceedings of the Fifteenth International Conference on Computational Linguis-tics, pages 977-981.Brill, Eric.
1993a.
Automatic grammar induction and parsing free text: A transformation-basedapproach.
In Proceedings of the DARPA Speech and Natural Language Workshop, 1993, pages237-242.Brill, Eric.
1993b.
A Corpus-Based Approach to Language Learning.
Ph.D. thesis, University ofPennsylvania.Brill, Eric.
1993c.
Rule based tagger, version 1.14.
Available from ftp.cs.jhu.edu in the directory/pub/bril l/programs/.Brill, Eric.
1994.
Some advances in transformation-based part of speech tagging.
In Proceed-ings of the Twelfth National Conference on Artificial Intelligence, pages 722-727.
(cmp-lg/9406010).BriU, Eric and Philip Resnik.
1994.
A rule-based approach to prepositional attachment dis-ambiguation.
In Proceedings of the Sixteenth International Conference on ComputationalLinguistics.
(cmp-lg/9410026).Church, Kenneth.
1988.
A stochastic parts program and noun phrase parser for unrestrictedtext.
In Second Conference on Applied Natural Language Processing.
ACL.Ejerhed, Eva I.
1988.
Finding clauses in unrestricted text by finitary and stochastic methods.In Second Conference on Applied Natural Language Processing, pages 219-227.
ACL.Gee, James Paul and Francois Grosjean.
1983.
Performance structures: A psycholinguistic andlinguistic appraisal.
Cognitive Psychology, 15:411-458.Kupiec, Julian.
1993.
An algorithm for finding noun phrase correspondences in bilingual corpora.In Proceedings of the 31st Annual Meeting of the ACL, pages 17-22.Marcus, Mitchell, Grace Kim, Mary Ann Marcinkiewicz, Robert MacIntyre, Ann Bies, MarkFerguson, Karen Katz, and Britta Schasberger.
1994.
The Penn Treebank: A revised corpusdesign for extracting predicate argument structure.
In Human Language Technology, ARPAMarch 1994 Workshop.
Morgan Kaumann.Ramshaw, Lance A. and Mitchell P. Marcus.
1994.
Exploring the statistical derivation of trans-formational rule sequences for part-of-speech tagging.
In Proceedings of the ACL BalancingAct Workshop on Combining Symbolic and Statistical Approaches to Language, pages 86-95.
(cmp-lg/9406011).Voutilainen, Atro.
1993.
NPTool, a detector of English noun phrases.
In Proceedings of theWorkshop on Very Large Corpora, pages 48-57.
ACL, June.
(cmp-lg/9502010).94
