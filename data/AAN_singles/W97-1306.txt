High Precision CoreferenceCogNIAC :with Limited KnowledgeResourcesand LinguisticBreck Baldwin3401 Walnut St.IRCS Suite 400-aPhiladelphia, PA, USA 19104breck@ linc.cis.upenn.eduAbstract "This paper presents a high precision pronounresolution system that is capable of greater than90% precision with 60% and better recall forsome pronouns.
It is suggested that the system isresolving a sub-set of anaphors that do notrequire general world knowledge or sophisticatedlinguistic processing for successful resolution.The system does this by being very sensitive toambiguity, and only resolving pronouns whenvery high confidence rules have been satisfied.The system is capable of 'noticing' ambiguitybecause it requires that there be a uniqueantecedent within a salience ranking, and thesalience rankings are not total orders, i.e.
two ormore antecedents can be equally salient.
Giventhe nature of the systems rules, it is very likelythat they are largely domain independent and thatthey reflect processing strategies used by humansfor general language comprehension.
The systemhas been evaluated in two distinct experimentswhich support the overall validity of theapproach.1 Introduction:Pronoun resolution is one of the 'classic'computational linguistics problems.
It is also widelyconsidered to be inherently an 'A.I.
complete' task--meaning that resolution of pronouns requires full worldknowledge and inference.
CogNIAC is a pronounresolution engine designed around the assumption thatthere is a sub-class of anaphora that does not requiregeneral purpose reasoning.
The kinds of informationCogNIAC does require includes: sentence detection,part-of-speech tagging, simple noun phrase recognition,basic semantic category information like, gender,number, and in one configuration, partial parse trees.What distinguishes CogNIAC from algorithms thatuse similar sorts of information is that it will notresolve a pronoun in circumstances of ambiguity.Crucially, ambiguity is a function of how muchknowledge an understander has.
Since CogNIAC doesnot have as rich a representation f world knowledge ashumans, it finds much more ambiguity in texts thanhumans do.2 A path to high precisionpronominal resolution-- avoidguesswork in ambiguouscontexts:It is probably safe to say that few referringpronouns are conveyed without the speaker/writerhaving an antecedent in mind.
Ambiguity occurs whenthe perceiver cannot recover from the context whatconveyer has in mind.
I have found myself utteringpronouns which the hearer has no chance of recoveringthe antecedent to because they are not attending to thesame part of the external environment, "He sure looksfamiliar", or in text I am so focused on the context ofwhat I am writing that use a pronoun to refer to ahighly salient concept for me, but the antecedent maycompletely evade a reader without my familiarity withthe topic.
Of course it is  possible to explicitly leavethe reader hanging as in, "Earl and Dave were workingtogether when suddenly he fell into the threshingmachine.
"Humans, unlike most coreference algorithms, noticesuch cases of ambiguity and can then ask forclarification or at least grumble about how we cannotclimb into the writers head to figure out what theymeant.
But in that grumble we have articulated theessence of the problem--we don't have sufficientknowledge to satisfy ourselves that an antecedent hasbeen found.Pronoun resolution systems have extremely limitedknowledge sources, they cannot access a fraction ofhuman common sense knowledge.
To appreciate thisconsider the following text with grammatical tagsreplacing words with pronouns and names left in place:The city council VERBGROUP the women NP CCthey VB NNMariana VBD PP Sarah TO VB herself PP DT AJDNNWithout lexical knowledge a human attempting toresolve the pronouns is in much the knowledgeimpoverished position of the typical coreference38algorithm.
It is no surprise that texts with so littleinformation provided in them tend to be moreambiguous than the texts in fleshed out form.
Theconclusion to draw from this example is that thelimiting factor in CogNIAC is knowledge sources, notan artificial restriction on domains or kinds ofcoreference.
This point will be resumed in thediscussion section when what the consequences of fullerknowledge sources would be on CogNIAC.2.1 Using limited world knowledgeto find possible antecedents:For noun phrase anaphora, gathering semanticallypossible antecedents amounts to running all the nounphrases in a text through various databases for numberand gender, and perhaps then a classifier that determineswhether a noun phrase is a company, person or place 1.This set of candidate antecedents rarely has more than 5members when some reasonable ocality constraints areadhered to, and this set alost always contains theactual antecedent.
The remainder of the coreferenceresolution process amounts to picking the right entityfrom this set.For the kinds of data considered here (narratives andnewspaper articles) there is a rarely a need for generalworld knowledge in assembling the initial set ofpossible antecedents for pronouns.
This does notaddress the issue of inferred antecedents, event reference,discourse deixis and many other sorts of referringphenomenon which clearly requi~e the use of worldknowledge but are beyond the scope of this work.
As ithappens, recognizing the possible antecedents of thesepronouns is within the capabilities of currentknowledge sources.Better knowledge sources could be used to reduce thespace of possible antecedents.
For example the wellknown \[Winograd 1972\] alternation:The city council refused to give the womena permit because they {feared/advocated}violence.There are two semantically possible antecedents tothey: The city council, and the women.
The problem ispicking the correct one.
Dependent on verb choice, theystrongly prefers one antecedent to the other.
Capturingthis generalization requires a sophisticated theory ofverb meaning as relates to pronoun resolution.Speaking anecdotally, these kinds of resolutions happenquite often in text.
CogNIAC recognizes knowledgeintensive coreference and does not attempt o resolvesuch instances.2.2 Using limited linguisticresources to find coreference:1 The named entity task at MUC-6 used a similarclassification task and the best system performance was96% precision/97% recall.Fortunately not all instances of pronominalanaphora require world knowledge for successfulresolution.
In lieu of full world knowledge, CogNIACuses regularities of English usage in an attempt omimic strategies used by humans when resolvingpronouns.
For example, the syntax of a sentence highlyconstrains a reflexive pronoun's antecedent.
Also ifthere is just one possible antecedent in entire the priordiscourse, then that entity is nearly always the correctantecedent.
CogNIAC consists of a set of suchobservations implemented in Perl.CogNIAC has been used with a range of linguisticresources, ranging from scenarios where almost nolinguistic processing of the text is done at all to partialparse trees being provided.
At the very least, there mustbe sufficient linguistic resources to recognize pronounsin the text and the space of candidate antecedents mustbe identified.
For the first experiment the text has beenpart of speech tagged and basal noun phrases have beenidentified with '\[\]' (i.e.
noun phrases that have nonested noun phrases) as shown below:\[ Mariana/NNP \] motioned/VBD for/IN \[Sarah/NNP \] to/TO seat/VB \[ herself/PRP \]on/IN \[ a/DT twoseater/NN lounge/NN \]In addition, finite clauses were identified (by hand forexperiment 1) and various regular expressions are usedto identify subjects, objects and what verbs take asarguments for the purposes of coreference r strictions.With this level of linguistic annotation, nearly all theparts of CogNIAC can be used to resolve pronouns.The core rules of CogNIAC are given below, withtheir performance on training data provided (200pronouns of narrative text).
In addition, examples wherethe rules successfully apply have been provided formost of the rules with the relevant anaphors andantecedents in boldface.
The term 'possible antecedents'refers to the set of entities from the discourse that arecompatible with an anaphor's gender, number andcoreference restrictions (i.e.
non-reflexive pronounscannot corefer with the other arguments of itsverb/preposition etc.
).1) Unique in Discourse:  If there is asingle possible antecedent i in the read-inportion of the entire discourse, then pick i asthe antecedent: 8 correct, and 0 incorrect.2) Ref lex ive :  Pick nearest possibleantecedent in read-in portion of currentsentence if the anaphor is a reflexivepronoun: 16 correct, and I incorrect.Mafiana motioned for Sarah to seatherself on a two-seater lounge.3) Unique in Current  + Pr ior:  If thereis a single possible antecedent i in the priorsentence and the read-in portion of the current39sentence, then pick i as the antecedent: 114correct, and 2 incorrect.Rupert  Murdock's News Corp. confirmedhis interest in buying back the ailing NewYork Post.
But analysts said that if bewinds up bidding for the paper .....4) Possessive Pro: If the anaphor is apossessive pronoun and there is a single exactstring match i of the possessive in the priorsentence, then pick i as the antecedent: 4correct, and 1 incorrect.After he was dry, Joe carefully laid out thedamp towel in front of his locker.
Traviswent over to his locker,  took out a toweland started to dry off.5) Unique Current Sentence: If there isa single possible antecedent in the read-inportion of the current sentence, then pick i asthe antecedent: 21 correct, and 1 incorrect.Like a large bear, he sat motionlessly in thelounge in one of the faded armchairs,watching Constantin.
After a weekConstantin tired of rreading the old novelsin the bottom shelf of the bookcase--somewhere among the gray well thumbedpages he had hoped to find a message fromone of his predecessors .....6) Unique Subject/ Subject Pronoun:If the subject of the prior sentence contains asingle possible antecedent i, and the anaphoris the subject of the current sentence, thenpick i as the antecedent: 11 correct, and 0incorrect.Besides, if he provoked Malek, uncertaintieswere introduced, of which there were alreadyfar too many.
He noticed the supervisorenter the lounge ...The method of resolving pronouns withinCogNIAC works as follows: Pronouns are resolvedleft-to-right in the text.
For each pronoun, the rules areapplied in the presented order.
For a given rule, if anantecedent is found, then the appropriate annotations aremade to the text and no more rules are tried for thatpronoun, otherwise the next rule is tried.
If no rulesresolve the pronoun, then it is left unresolved.These rules are individually are high precision rules,and collectively they add up to reasonable recall.
Theprecision is 97% (121/125) and the recall is 60%(121/201) for 198 pronouns of training data.3 Evaluation:3.1 Compar ison to Hobbs' Na iveA lgor i thm:The Naive Algorithm \[Hobbs 1976\] works byspecifying a total order on noun phrases in the priordiscourse and comparing each noun phrase against theselectional restrictions (i.e.
gender, number) of theanaphor, and taking the antecedent tobe the first one tosatisfy them.
Thespecif ication of the orderingconstitutes a traversal order of the syntax tree of theanaphors clause and from there to embedding clausesand prior clauses.The Winograd sentences, with either verb, wouldyield the following ordering of possible antecedents:The city council > the womenThe algorithm would resolve they to The citycouncil.
This is incorrect on one choice of verb, but thealgorithm does not integrate the verb information intothe salience ranking.In comparison, none of the six rules of CogNIACwould resolve the pronoun.
Rules have been tried thatresolved a subject pronoun of a nested clause with thesubject of the dominating clause, but no configurationhas been found that yielded sufficient precision 2.Consequently, they is not resolveff.The naive algorithm has some interestingproperties.
First it models relative salience as relativedepth in a search space.
For two candidate antecedents aand b, if a is encountered before b in the search space,then a is more salient than b.
Second, the relativesaliency of all candidate antecedents i totally ordered,that is, for any two candidate antecedents a and b ,  a ismore salient han b xor b is more salient han a.2 In experiment 2,discussed below, the rule 'subjectsame clause' would resolve they to the city council, butit was added to the MUC-6 system without testing, andhas shown itself to not be a high precision rule.40CogNIAC shares several features of the NaiveAlgorithm:?
Both use basic selectional restrictions to findsemantically acceptable potential antecedents.?
Both use highly syntactic generalizations toresolve anaphors, and do not attempt o domore sophisticated semantic processing.But they also differ in significant ways:?
CogNIAC is not committed to totally orderingall potential antecedents, the Naive Algorithmis.?
CogNIAC is sensitive to ambiguity, i.e.circumstances of many possible antecedents,and will not resolve pronouns in such cases.The Naive Algorithm has no means of notingambiguity and will resolve a pronoun as longas there is at least one possible antecedent.Perhaps the most convincing reason to endorsepartially ordered salience rankings is that saliencedistinctions fade as the discourse moves on.Earl was working with Ted the other day.
Hefell into the threshing machine.Earl was working with Ted the other day.All of the sudden, the cows started making aruckus.
The noise was unbelievable.
He fellinto the threshing machine.In the first example 'He' takes 'Earl' as antecedent,which is what rule 6, Unique Subject/Subject Pronoun,would resolve the pronoun to.
However in the secondexample, the use of 'He' is ambiguous--a distinctionthat existed before is now gone.
The Naive Algorithmwould still maintain a salience distinction between'Earl' and 'Ted', where CogNIAC has no rule thatmakes a salience distinction between subject and objectof a sentence which has two intervening sentences.
Theclosest rule would be Unique in Discourse, rule 1,which does not yield a unique antecedent.3.2 Performance:CogNIAC has been evaluated in two differentcontexts.
The goal of the first experiment was toestablish relative performance of CogNIAC to Hobbs'Naive Algorithm--a convenient benchmark that allowsindirect comparison to other algorithms.
The secondexperiment reports results on Wall Street Journal data.3.2.1 Experiment 1:The chosen domain for comparison with Hobbs'Naive Algorithm was narrative texts about two personsof the same gender told from a third person perspective.The motivation for this data was that we wanted tomaximize the ambiguity of resolving pronouns.
Onlysingular third person pronouns were considered.
Thetext was pre-processed with a part-of-speech tagger overwhich basal noun phrases were delimited and finiteclauses and their relative nesting were identified bymachine.
This pre-processing was subjected to handcorrection in order to make comparison with Hobbs' asfair as possible since that was an entirely hand executedalgorithm, but CogNIAC was otherwise machine runand scored.
Errors were not chained, i.e.
in left-to-rightprocessing of the text, earlier mistakes were correctedbefore processing the next noun phrase.Since the Naive Algorithm resolves all pronouns,two lower precision rules were added to rules 1-6) forcomparisons sake.
The rules are:7) Cb-P ick ing3:  If there is a Cb i in thecurrent finite clause that is also a candidateantecedent, then pick i as the antecedent.8) Pick Most Recent:  Pick the mostrecent potential antecedent in the text.The last two rules are lower precision than the firstsix, but perform well enough to merit their inclusionin a 'resolve all pronouns' configuration.
Rule 7performed reasonably well with 77% precision intraining (10/13 correct for 201 pronouns), and rule 8performed with 65% precision in training (44/63correct).
The first six rules each had a precision ofgreater than 90% for the training data with theexception of rule 4 which had a precision of 80% for 5resolutions.
The summary performance of the NaiveAlgorithm and CogNIAC (including all 8 rules) for thefirst 100 or so pronouns in three narrative texts are:Naive Alg.235 (78.8%):CogNIAC ~'resolve all232 (77.9%)Results for 298 third persontwo same gender people.CogNIACHigh Prec.190/206 (92%) P190/298 (64%) R9ronouns in text aboutSince both the Naive Algorithm and the resolve allpronouns configuration of CogNIAC are required toresolve all pronouns, precision and recall figures are notappropriate.
Instead % correct figures are given.
Thehigh precision version of CogNIAC is reported withrecall (number correct/number of instances ofcoreference) and precision (number correct/number ofguesses) measures.The conclusion to draw from these results is: ifforced to commit to all anaphors, CogNIAC performscomparably to the Naive Algorithm.
Lappin and Leass3 Rule 7 is based on the primitives of CenteringTheory (Grosz, Joshi and Weinstein '86).
The Cb of anutterance is the highest ranked NP (Ranking being:Subject > All other NPs) from the prior finite clauserealized anaphorically in the current finite clause.
Pleasesee Baldwin '95 for a full discussion of the details ofthe rule.411994 correctly resolved 86% of 360 pronouns incomputer manuals.
Lapin and Leass run Hobbs'algorithm on the their data and the Naive Algorithm iscorrect 82% of the time--4% worse.
This allowsindirect comparison with CogNIAC, with thesuggestive conclusion that the resolve all pronounsconfiguration of CogNIAC, like the Naive Algorithm,is at least in the ballpark of more modern approaches 4.The breakdown of the individual rules is as follows:Rule Recall Precisionl)Uniq in Discourse2) Reflexive3) Uniq Curr + Prior4) Possessive Pro5) Uniq Curr Sentence5) Uniq Subj/Subj Pre7) Cb-Picking8) Pick Most Recent11% (32/298)3% (10/298)35% (104/298)1% (2/298)fi% (18/298)~% (24/298)~% (13/298)10%(29/298)100% (32/32)100% (10/10)96% (104/I 10)100% (2/2)gl% (18/22)\]0% (24/30)~2% (13/31)~8% (29/61)Performance of individual rules in Experiment 1.Note the high precision of rules 1 - 6).
Recall =#correct/#actual, Precision = #correct/#guessedFar more interesting to consider is the performanceof the high precision rules 1 through 6.
The first fourrules perform quite well at 96% precision (148/154) and50% recall (148/298).
Adding in rules 5 and 6 resolvesa total of 190 pronouns correctly, with only 16mistakes, a precision of 92% and recall of 64%.
Thiscontrasts trongly with the resolve-all-pronouns re ultsof 78%.
The last two rules, 7 and 8 performed quitebadly on the test data.
Despite their poor performance,CogNIAC still remained comparable to the NaiveAlgorithm.3.2.2 Experiment 2-- Allpronouns in MUC-6 evaluation:CogNIAC was used as the pronoun component inthe University Pennsylvania's coreference entry 5 in theMUC-6 evaluation.
Pronominal anaphora constitutes17% of coreference annotations in the evaluation dataused.
The remaining instances of anaphora includedcommon noun anaphora and coreferent instances ofproper nouns.
As a result being part of a larger system,changes were made to CogNIAC to make it fit in betterwith the other components of the overall system inaddition to adding rules that were specialized for thenew kinds of pronominal anaphora.
These changesinclude:4 This is not to say that RAP was not anadvancement of the state of the art.
A significant aspectof that research is that both RAP and the NaiveAlgorithm were machine executed--the NaiveAlgorithm was not machine executed in either theHobbs 76 paper or in the evaluation in this work.5 Please see Baldwin et al'96 for performancestatistics and a bit more detail about he entire system.?
Processing quoted speech in a limited fashion(Quoted Speech).?
Addition of a rule that searched back for aunique antecedent through the text at first 3sentences back, 8 sentences back, 12 sentencesback and so on (Search Back).?
Addition of a partial parser \[Collins 1996\] todetermine what a finite clause is.?
A new pattern was added which selected thesubject of the immediately surrounding clause(Subject Same Clause).?
Addition of a pleonastic-it detector whichfiltered uses of it that were not pronominal.?
Disabling of several rules because they did notappear to be appropriate for the domain; 4, 7and 8.A total of thirty articles were used in the formalevaluation, of which I chose the first fifteen for closeranalysis.
The remaining fifteen were retained for futureevaluations.
The performance of CogNIAC was asfollows:I All Pronouns I Recall (for pros) 75% (85/114) I Precision (73%) 85/116 IThe precision (73%) is quite a bit worse than thatencountered in the narrative.
The performance of theindividual rules was quite different from the narrativetexts, as shown in the table below:RuleQuoted Speech1) Uniq in Discourse3) Uniq Curr + PriorSearch Back2) Reflexive5) Uniq Curr SentenceSubject Same ClauseRecall (pros)11% (13/114)4% (5/114)50% (57/114)1% (1/114)0% (0/114)4% (5/114)4% (4/114)Precision(87%) 13/15(100%) 5/5(72%) 57/79(33%) 1/30/0(70%) 5/7(57%) 4/7The results for CogNIAC for all pronouns in thefirst 15 articles of the MUC-6 evaluation.Upon closer examination approximately 75% of theerrors were due to factors outside the scope of theCogNIAC pronominal resolution component.
Softwareproblems accounted for 20% of the incorrect cases,another 30% were due to semantic errors likemisclassification of a noun phrase into person orcompany, singular/plural etc.
The remaining errorswere due to incorrect noun phrase identification, failureto recognize pleonastic-it or other cases where there isno instance of an antecedent.
However, 25% of theerrors were due directly to the rules of CogNIAC beingplain wrong.4 D iscuss ion :CogNIAC is both an engineering effort and adifferent approach to information processing in variableknowledge contexts.
Each point is addressed in turn.424.1 The utility of high precisioncoreference:A question raised by a reviewer asked whether therewas any use for high precision coreference given that itis not resolving as much correference as other methods.In the first experiment, he high precision version ofCogNIAC correctly resolved 62% of the pronouns ascompared to the resolve all pronouns version whichresolved 79% of them--a 27% loss of overall recall.The answer to this question quite naturally dependson the application coreference is being used in.
Someexamples follow.Information RetrievalInformation retrieval is characterized asa process bywhich a query is used to retrieve relevant documentsfrom a text database.
Queries are typically naturallanguage based or Boolean expressions.
Documents areretrieved and ranked for relevance using various stringmatching techniques with query terms in a documentand the highest scoring documents are presented to theuser first.The role that coreference resolution might play ininformation retrieval is that retrieval algorithms that a)count the number of matches to a query term in adocument, or b) count the proximity of matches toquery terms, would benefit by noticing alternativerealizations of the terms like 'he' in place 'GeorgeBush'.In such an application, high precision coreferencewould be more useful than high recall coreference ifthe information retrieval engine was returning toomany irrelevant documents but getting a reasonablenumber of relevant documents.
The coreference wouldonly help the scores of presumably relevant documents,but at the expense of missing some relevantdocuments.
A higher recall, lower precision algorithmwould potentially add more irrelevant documents.Coherence CheckingA direct application of the "ambiguity noticing"ability of CogNIAC is in checking the coherence ofpronoun use in text for children and English as a secondlanguage learners.
Ambiguous pronoun use is asubstantial problem for beginning writers and languagelearners.
CogNIAC could scan texts as they are beingwritten and evaluate whether there was sufficientsyntactic support from the context to resolve thepronoun--if not, then the user could be notified of apotentially ambiguous use.
It is not clear thatCogNIAC's current levels of performance ould supportsuch an application, but it is a promising application.Information ExtractionInformation extraction amounts to filling intemplate like data structures from free text.
Typicallythe patterns which are used to fill the templates arehand built.
The latest MUC-6 evaluation involvedmanagement changes at companies.
A major problemin information extraction is the fact that the desiredinformation can be spread over many sentences in thetext and coreference resolution is essential to relaterelevant sentences to the correct individuals, companiesetc.
The MUC-6 correference task was developed withthe idea that it would aid information extractiontechnologies.The consequences for an incorrectly resolvedpronoun can be devastating tothe final template fillingtask--one runs the risk of conflating information aboutone individual with another.
High precision coreferenceappears to be a natural candidate for such applications.4.2 The methodology behindCogNIACCogNIAC effectively circumscribes those caseswhere coreference an be done with high confidence andthose cases that require greater world knowledge, buthow might CogNIAC be a part of a more knowledgerich coreference application?CogNIAC as a set of seven or so high precisionrules would act as an effective filter on what a moreknowledge rich application would have to resolve.
Butthe essential component behind CogNIAC is not therules themselves, but the control structure of behind itscoreference r solution algorithm.
This control structurecould control general inference techniques as well.An interesting way to look at CogNIAC is as asearch procedure.
The Naive Algorithm can be oversimplified as depth first search over parse trees.
Depthfirst search is also a perfectly reasonable controlstructure for an inference engine-- as it is withPROLOG.
The search structure of CogNIAC could becharacterized as parallel iterative deepening withsolutions being accepted only if a unique solution isfound to the depth of the parallel search.
But there isnot enough room in this paper to explore the generalproperties of CogNIAC's search and evaluationstrategy.Another angle on CogNIAC's role with morerobust knowledge sources is to note that the recalllimitations of CogNIAC for the class of pronouns/dataconsidered are due to insufficient filtering mechanismson candidate antecedents.
There is not a need to expandthe space of candidate antecedents with additionalknowledge, but rather eliminate semantically plausibleantecedents with constraints from verb knowledge andother sources of constraints currently not available tothe system.However, there are classes of coreference that requirestrong knowledge representation to assemble the initialset of candidate antecedents.
This includes the realm ofinferred definites "I went to the house and opened thedoor" and synonymy between definite common nounsas in "the tax' and 'the levy.434.3 The possibility of perfectcoreferenceHobbs 1976 ultimately rejects the Naive Algorithmas a stand-alone solution to the pronoun resolutionproblem.
In that rejection he states:The naive algorithm does not work.
Anyonecan think of examples where it fails.
Inthese cases it not only fails; it gives noindication that it has failed and offers nohelp in finding the real antecedent.Hobbs then articulates a vision of what theappropriate chnology is, which entails inference overan encoding of world knowledge.
But is worldknowledge inherent in resolving all pronouns as Hobbsskepticism seems to convey?It has not been clear up to this point whether anyanaphora can be resolved with high confidence giventhat there are clear examples which can only be resolvedwith sophisticated world knowledge, e.g.
the Winogradcity council sentences.
But the results from the first andsecond experiments demonstrate hat it is possible tohave respectable r call with very high precision (greaterthan 90%) for some kinds of pronominal resolution.However, good performance does not necessarily falsifyHobbs' skepticism.The high precision component of CogNIAC stillmakes mistakes, 8-9% error for the first experiment--itis harder to evaluate the second experiment.
If it werethe case that integration of world knowledge wouldhave prevented those errors, then Hobbs' skepticismstill holds since CogNIAC has only minimized the roleof world knowledge, not eliminated it.
In looking at themistakes made in the second experiment, here were noexamples that appea_ed to be beyond the scope offurther improving the syntactic rules or expanding thebasic categorization of noun phrases into person,company or place.
For the data considered so far, theredoes appear to be a class of anaphors that can bereliably recognized and resolved with non-knowledgeintensive techniques.
Whether this holds in generalremains an open question, but it is a central designassumption behind the system.A more satisfying answer to Hobbs' skepticism iscontained in the earlier suggestive conjecture that worldknowledge facilitates anaphora by eliminatingambiguity.
This claim can be advanced to say thatworld knowledge comes into play in those cases ofanaphora that do not fall under the purview of rules 1through 7 and their refinements.
If this is correct, thenthe introduction of better world knowledge sources willhelp in the recall of the system rather than theprecision.Ultimately, the utility of CogNIAC is a function ofhow it performs.
The high precision rules of CogNIACperformed very well, greater than 90% precision withgood recall for the first experiment.
In the secondexperiment, components other than the rules ofCogNIAC began to degrade the performance of thesystem unduly.
But there is promise in the highprecision core of CogNIAC across varied domains.5 The future of CogNIAC:CogNIAC is currently the common noun andpronoun resolution component of the University ofPennsylvania's coreference resolution software andgeneral NLP software (Camp).
This paper does notaddress the common noun coreference aspects of thesystem but there are some interesting parallels withpronominal coreference.
Some changes planned includethe following sorts of coreference:The processing of split antecedents,John called Mary.
They went to a movie.This class of coreference is quite challenging becausethe plural anaphor 'they' must be able to collect a setof antecedents from the prior discourse--but how farshould it look back, and once it has found twoantecedents, should it continue to look for more?Event reference is a class of coreference that willalso prove to be quite challenging.
For example:The computer won the match.
It was a greattriumph.The antecedent to 'It' could be any of 'The computer','the match' or the event of winning.
The space ofambiguity will certainly grow substantially whenevents are considered as candidate antecedents.Currently the system uses no verb semantics to tryand constrain possible coreference.
While the Winogradsentences are too difficult for current robust lexicalsemantic systems, simpler generalizations about whatcan fill an argument are possible, consider:The price of aluminum rose today due tolarge purchases by ALCOA Inc.
It claimedthat it was not trying to corner the market.Since 'It' is an argument o 'claimed' , a verb thatrequires that its subject be animate, we can eliminate'The price of aluminum' and 'today' fromconsideration, leaving 'ALCOA Inc.' as the solesingular antecedent from the prior sentence.
Work hasbeen done along these lines by Dagan '90.6 Acknowledgments:I would like to thank my advisors Ellen Prince andAravind Joshi for their support.
Also the comments oftwo anonymous reviewers proved quite helpful.447 References:\[Baldwin 1995\]Baldwin, B., "CogNIAC: A discourse processingengine", University of Pennsylvania, Department ofComputer and Information Science, Ph.D. dissertation.\[Baldwin et al 1995\]Baldwin, B., Reynar, J., Collins, M., Eisner, J.,Ratnaparkhi, A., Rosenzweig, J. Sarkar, A., Srinivas(1995), "University of Pennsylvania: Description of theUniversity of Pennsylvania system used for MUC-6",Proceedings of Sixth Message UnderstandingConference, November 1995.\[Collins 1996\]Collins, M., "A New Statistical Parser based onBigram Lexical Dependencies", Proceedings of the 34thAnnual Meeting of the Association for ComputationalLinguistics, June, 1996.\[Carter 1986\]Carter, D. (1986), "Common Sense Inference in aFocus-Guided Anaphor Resolver", Journal ofSemantics, 4.\[Chinehor and Sundhiem 1994\]Chinchor, N., Sundheim, B.
(1994) "CoreferenceTask Definition vl.l", supporting documentation forMUC-6 coreference task.\[Dagan 1990\]Dagan, I., Itai, A., (1990) A Statistical Filter forResolving Pronoun References, Proceedings of 7thIsraeli Symposium on Artificial Intelligence andComputer Vision.\[Grosz, Joshi and Weinstein 1986\]Grosz, B. J, Joshi, A. K., and Weinstein, S. (1986)"Towards a Computational Theory of DiscourseInterpretation" Ms.\[Hobbs 1976\]Hobbs, J.
(1976) "Pronoun Resolution", ResearchReport #76-1, City College, City University of NewYork.\[Hobbs 1977\]Hobbs, J.
(1977) "38 Examples of ElusiveAntecedents from Published Texts", Research Report#77-2, City College, City University of New York.\[Kennedy 1996\]C. Kennedy, B. Boguraev, "Anaphora for everyone:pronominal anaphora resolution without a parser.
"Proceedings of the 16th International Conference onComputational Linguistics COLING'96, Copenhagen,Denmark, 5-9 August 1996\[Lappin and Leass 1994\]Lappin, S., Leass, H. (1994) "An Algorithm forPronominal Anaphora Resolution", ComputationalLinguistics.\[Mitkov 1997\]Mitkov R., "Pronoun resolution: the practicalalternative", In S. Botley, T. McEnery (Eds) "DiscourseAnaphora and Anaphor Resolution".
UniversityCollege London Press, 1997\[Sidner 1986\]Sidner, C. L. (1986) "Focusing in theComprehension of Definite Anaphora", Readings inNatural Language Processing, eds Grosz, Jones,Webber.
Morgan Kaufman, Los Altos CA.\[Winograd 1972\]Winograd, T. 1972, "Understanding NaturalLanguage", New York: Academic Press.45
