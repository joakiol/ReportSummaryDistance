USER MODELS AND DISCOURSE MODELS:UNITED THEY STAND .
.
.Alfred KobsaSFB 314: AI-Knowledge-Based SystemsDepartment of Computer ScienceUniversity of Saarbriicken, W. GermanyOpinions on the relationship between discourse models(DMs) and user models (UMs) are obviously influencedby preassumptions about their respective contents.
Asfar as DMs are concerned, two divergent views havebeen expressed in the discussion published here:I.
The DM contains only representations of theobjects mentioned so far in the discourse (i.e., amentioned-object memory--see Schuster, thisissue).
The term "object" will be used here in thebroad sense of Schuster, thus also denotingevents, properties, etc.2.
The DM contains in additiona.
a representation of the purpose underlyingthe segments of the dialog (i.e.
a dialogpurpose--see Grosz Sidner 1986, Chin, thisissue).b.
an attentional structure, which is a subset ofthe representations mentioned in (1) contain-ing the currently focused objects which areordered in a focus stack (Cohen, this issue;Chin, this issue, who requires only that theuser must be familiar with these objects).Less disagreement seems to exist about he componentsof a UM.
Generally, it is regarded as containing explicitrepresentations of the system's assumptions about allrelevant aspects of the user, i.e., assumptions about his/her "objective situation" (e.g., marital status, numberof children), as well as about his/her prior knowledge,goals, plans and false beliefs with respect o the domainof discourse.
In order to meet Wahlster's personnel-database counterexample, it must be further requiredthat the user model be separable by the system from therest of the system's knowledge.To discuss the relationship between DMs and UMs,a general belief, goal, and plan maintenance system(BGP-MS) will be presented here, the purpose of whichis to store and update the beliefs, goals, and plans ofboth the system and an arbitrary number of otheragents, including the system's current user.
Specificsubcomponents and subfunctions of this system hope-fully capture the general consensus on what constitutesa discourse model and a user model, respectively.However, we will see that these subcomponents arestrongly interwoven and that--apart from a few rarelyoccurring exceptions--the DM is part of the UM at leastat the level of content.
The question arises then, ofcourse, whether it makes sense to separate these no-tions conceptually.The belief, goal, and plan maintenance system out-lined here is being implemented (in a somewhat simpli-fied form) in XTRA, a natural language access ystem toexpert systems (Allgayer et al 1988).
A previous imple-mentation was VIE-DPM (Kobsa 1985a,b).
In theknowledge base of BGP-MS, the representation f thevarious types of (nested) beliefs and goals (Kobsa 1988)is separated into a number of hierarchically orderedpartitions (see Figure 1).
If it is shared knowledgebetween S and U that U possesses certain beliefs(knowledge), then this knowledge or these beliefs arerepresented in MB(UB).
1 MB(UW) contains those goalsand plans of the user, MB(SB) those beliefs of thesystem, and MB(SW) those goals of the system forwhich the same holds true.
"Private" beliefs of thesystem about he domain of discourse / about the user'sbeliefs / about the user's beliefs about the system'sgoals are represented in SB, SBUB, and SBUBSW,respectively.
MB contains the mutual beliefs (knowl-edge) with respect o the domain, and MW the mutualgoals and plans of S and U.
The arrows between thepartitions denote inheritance relationships.In the partitions of BGP-MS, the content of the individ-ual beliefs, goals, and plans can be expressed througharbitrary representational structures (e.g., a KL-ONE-like representation asused in XTRA).
Various markersfor non-belief and uncertainty can be added: For in-stance, in SBUB it can be expressed, among otherCopyright 1988 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material is granted providedthat the copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page.
Tocopy otherwise, or to republish, requires a fee and/or specific permission.0362-613X/88/0100e-e$ 03.00Computational Linguistics, Volume 14, Number 3, September 1988 91Affred Kohsa User Models and Discourse Models: United they stand.. .MWtSB..................... i ............................ i\[ iit\[ J sso B IIqlBFigure 1.
Hierarchical belief, goal and plan representationin BGP-MS.things, that S is uncertain whether (or does not believethat) U knows some fact; and in MB(UB), that S isuncertain (or does not believe) that a belief of the useris mutually known.Where are the user model and the discourse modellocated in this architecture?
The UM part of BGP-MSconsists of all partitions except SB and SW, plus allrepresentations i  SB (and probably SW) in which anindividual constant occurs denoting the user (the rest ofSB corresponds to Sparck Jones's world model).
TheDM cannot be so easily identified.
In the followingsections I will discuss how the different functions of adiscourse model as outlined above can be fulfilled bythe proposed architecture.1.
THE MENTIONED OBJECT MEMORYWhen an object is mentioned during the discourse, thenmutual knowledge about its existence is usually estab-lished.
Thus a representation of the object can beentered into MB (implying, for instance, that S can nowuse definite NPs to refer to these objects).
Finer dis-tinctions in what is now known can also be expressed:to take Chin's example, if S mentions a name unknownto U (i.e., the relationship between the name and itsbearer is contained in SB only), then the existence of aperson with this name can be entered into MB.
InMB(UB) it can be represented that U does not know,and in bAB_(SB) that S does know the bearer of thisname.All of the mentioned partitions are part of the usermodel.
One might argue that the above architecture maycompletely cover the mentioned object memory func-tion in an NL dialog system.
However, three kinds ofinformation are lost thereby (this defect also seems toapply partly to Schuster's model).a.
The information that objects have been explicitlymentioned in the discourse:MB contains not only those objects which wereexplicitly mentioned in the discourse (and whichare therefore mutually known by all dialog partic-ipants), but also representations of those objectswhose existence is mutually known due to stereo-types (Rich 1988) or to inferences from the dis-course.
Sometimes, however, the system shouldpossess information about whether or not someobject had been explicitly mentioned, for examplein order to increase coherency in its own dialogcontributions ("As I/you said before.
.
.  ")
or topoint out inconsistencies in dialog contributions ofthe user ("But previously ou sa id .
.
. "
) .b.
Information about he sequence (and thus recency)of objects' mention:This information is very important in NL systems,since the choice of various forms of anaphoradepends on the degree of recency.c.
hlformation about he linguistic structure of dialogcontributions:Sometimes the system should also possess infor-mation about the wording or the syntactic struc-ture of the user's and the system's previous dialogcontributions (i.e., information on how objectshave been mentioned).
This information can beexploited by the system for reiterating a descrip-tion in its own dialog contributions or for avoidingreiteration, for instance.In XTRA, two additional knowledge bases have beenintroduced which serve the above-mentioned functions,among others: the FSS knowledge base and the so-called Linguistic Dialog Memory.
The FSS (Allgayerand Reddig 1986) represents the functional semanticstructure of both the user's and the system's dialogcontributions.
FSS contents can also be linked to thelinguistic surface forms (NPs, PPs, etc.)
which causedtheir creation (in the case of user input) or became theirlinguistic realizations (in the case of system dialogcontributions).
The dialog memory, among other things,records the objects that have been mentioned during thediscourse, and, in its dialog sequence part, the sequenceof the objects' mention.In general, all system knowledge about what objectshave been mentioned in the on-going discourse, in what92 Computational Linguistics, Volume 14, Number 3, September 1988Alfred Kobsa User Models and Discourse Models: United they s tand .
.
.order they were mentioned, and how they were de-scribed (i.e.
all parts of the dialog memory) are regardedas being part of MB, and hence part of the user model.This is necessarily so, since, by definition, MB containsall knowledge that is shared by system and user.
Andonly if knowledge about the previous discourse isshared between both participants can it be safely em-ployed in the generation of dialog contributions.
(Forexample, an anaphor generated by the system willprobably fail to fulfill its referential function if only thesystem, but not the user, believes that its intendedreferent has been mentioned just recently.
Hence thesystem should check whether its records in the dialogsequence memory are shared by the user.
)In cases of communicative failure, however, thereexists system discourse knowledge that is not shared bythe user, and thus not part of MB and the user model.
Insuch cases, entries are made into SB instead, andthereby form part of the system's knowledge only.
Forinstance, when S assumes that U does not rememberwhat has been said (see Wahlster's hastily-presented-names example), the FSS descriptions and the repre-sentations of their referents in the dialog memory can beentered in SB instead of MB, and thus do not form partof the user model.
In addition, however, all sorts ofuncertain assumptions about what the user has or hasnot, in fact, kept in mind can be expressed in SBUB orMB(UB), i.e., in the user model.
(For example, thesystem can note in the user model that the user probablyremembered the first two but not the subsequentnames.)
For simplicity, however, neither of the de-scribed cases of communicative failure is dealt with inXTRA, and for implementational reasons the FSS partof MB forms a separate partition.2A.
THE DIALOG PURPOSEHere the problem arises in research on NL dialogsystems as to whether or not one should regard theintentional structure of individual utterances (Cohen,this issue) or dialog segments (Grosz Sidner 1986) asbeing independent of the dialog setting and the dialogparticipants.
To put it in a more provocative way, dodialog constituents or dialog participants have an inten-tional structure?
In my view, the essence of problem-solving dialog lies in the recognition of the dialogparticipants' goals and plans, and in the construction ofmutually known goals and plans.
Dialog contributionsof the dialog partner serve as a more-or-less helpful aidin this process (Pollack et al (1982) present transcriptsin which dialog contributions ofclients with misconcep-tions even impair the recognition of their actual goals).Apart from that, no intentional character pertains todialog constituents that is independent of the dialog andsituational context and of the current (beliefs about)goals and plans.In the BGP-MS philosophy, (beliefs about) goals andplans are contained in those partitions whose labelsinclude a W. A user's dialog contribution is first repre-sented by FSS structures in MB.
If user plans or goalscan be inferred by S, they are represented in MB(UW),or in MW if there is mutual knowledge that they havebeen accepted by S. Conversely, when S graduallycommunicates it  plans or goals to U, the correspondingrepresentation structures are transferred from SW toMB(SW), and finally hopefully to MW.
Thus any sort ofintentional structure is part of the user model.2B.
THE ATTENTIONAL STRUCTUREI agree with Chin (this issue) that the attentional struc-ture is also not a context-independent characteristic ofdiscourse (although Chin's notion of attentional struc-ture seems to be broader than mine).
Only mutuallyknown objects can be in focus.
In XTRA, focus isexpressed by focus values in the dialog memory which,logically, can only be applied to representation struc-tures in MB and MW and therefore form part of the usermodel.SUMMARYThe above discussion demonstrates that the function ofa UM and of all mentioned DM components can becompletely fulfilled by the outlined belief~ goal, and planmaintenance system.
I cannot deal here in detail withthe question of whether this is also the case for othercomponents that have been proposed for a DM, forexample, the structuring of the dialog into dialog seg-ments (Grosz Sidner 1986), a context space grammar(Reichman 1981), or rhetorical predicates (schemata;McKeown 1982).
With respect o the analyzed compo-nents, we have seen that the discourse model almostcompletely overlaps with the user model at the level ofcontent.
Only if the user does not fully catch thesystem's dialog contributions are entries in the DMcreated which do not form part of the UM (see, forinstance, Wahlster's example, this issue).
But at aprocedural level as well, only a few processes can befound which operate xclusively on that part of the usermodel that is identical with the discourse model, orupon the remaining parts of the user model.This large degree to which the DM is included in theUM, however, is not surprising: Discourse models areultimately based on linguistic onventions.
In order forthe linguistic, intentional, attentional, etc., structure ofthe previous discourse to be exploited for future dialogcontributions, conventions about what the structure of aparticular ongoing dialog actually is must exist.
Knowl-edge about convention is mutual knowledge, however,(Lewis 1969, Schiffer 1972), and thus part of MB.
Thesame holds true for the above-mentioned a ditionalcomponents of the DM that could not be dealt with inthis paper.
And, by the way, it also holds true for thegrammar the system employs (but see the opposingviews of Morik and Wahlster, this issue).
If the systemdid not assume that its assumptions about he syntacticstructure of language (as expressed in its grammar) beComputational Linguistics, Volume 14, Number 3, September 1988 93Alfred Kobsa "Jser Models and Discourse Models: United they s tand.
.
.shared by the user, it could not justifiably use it in theanalysis and generation of dialog contributions withoutrisking miscommunication.
And there definitely existswork in user modeling (e.g., Schuster I985, Kilbury1986, Lehman CarboneU 1988), which is concerned withthe recognition of those parts of a user's idiosyncraticgrammar that deviate from the mutually shared kernelgrammar.
Of course, an entry in MB never means thatthe system assumes that the user "has the same struc-ture in his/her mind" (e.g., ATNs, KL-ONE,  or LISP),but only that these structures are functionally equiva-lent reconstructions of the user's competence.Does the large degree of inclusion of discourse mod-els in user models at the level of content imply that thenotion of discourse model is superflous?
As was pointedout by Morik (this issue), extensionally overlappingnotions may still prove useful if their intension high-lights different aspects of a system.
For example, in theabove architecture, such a concept might characterizean orthogonal substructure and denote, for instance,entries in different partitions with specific origin orfunction.
The above as well as Morik's and partlyWahlster's discussions demonstrate, however, that it isvery hard to find such differential criteria for DMs.
Itherefore suspect that a happy fate of that kind willmore probably apply to notions such as mentionedobject memory or discourse sequence memory than tothe vague notion of discourse model.ACKNOWLEDGEMENTThis research was supported by the German Science Foundation i  itsSpecial Collaborative Programme on AI and Knowledge-Based Sys-tems (SFB 314).
I am indebted to Carola Reddig and NorbertReithinger for their comments on an earlier version of this paper.REFERENCESAllgayer, J. and Reddig, C. 1986 Processing Descriptions ContainingWords and Gestures: A System Architecture.
In Rollinger, C. R.and Horn, W.
(eds.)
GWA1-86 und 2.
Osterreichische Artificial-lntelligence-Tagung.
Springer, Verlag, Berlin--New York.Allgayer, J.; Harbusch, K.; Kobsa, A.; Reddig, C.; Reithinger, N.;Schm~.uks, D. 1988 XTRA: A Natural-Language Access System toExpert Systems.
Technical Report, SFB 314: AI-Knowledge-Based Systems, Department ofComputer Science, University ofSaarbrficken, W. Germany.Kilbury, J.
1986 Language Variation, Parsing, and the Modelling ofUser's Language Variations.
In Proceedings of the 7th EuropeanConference on Artificial Intelligence, Brighton, England: 29-32.Kobsa, A. I985a Benutzermodellierung in Dialogsystemen.
Springer-Verlag, Berlin--New York.Kobsa, A.
1985b Using Situation Descriptions and Russellian Atti-tudes for Representing Beliefs and Wants.
In Proceedings oftheInternational Joint Conference on Artificial Intelligence, LosAngeles, CA: 513-515.Kobsa, A.
1988 A Taxonomy of Beliefs and Goals for User Models inDialog Systems.
In Kobsa, A. and Wahlster, W.
(eds.
), UserModels in Dialog Systems.
Springer-Verlag, Berlin--New York.Lehman, J. F. and Carbonell, J. G. 1988 Learning the User's Lan-guage: A Step Towards Automated Creation of User Models.
InKobsa, A. and Wahlster, W.
(eds.
), User Models in DialogSystems.
Springer-Verlag, Berlin--New York.Lewis, D. K. 1969 Convention: A Philosophical Study.
HarvardUniversity Press, Cambridge, MA.McKeown, K. R. 1982 Generating Natural Language Responses toQuestions about Database Structure.
TR MS-CIS-82-5, Depart-ment of Computer and Information Science, University of Penn-sylvania, Philadelphia, PA.Pollack, M.E.
; Hirschberg, J.; and Webber, B.
1982 User Participa-tion in the Reasoning Process of Expert Systems.
MS CIS-82-9,Department of Computer and Information Science, University ofPennsylvania, Philadelphia, PA.Reichman, R. 1981 Plain Speaking: A Theory and Grammar ofSpontaneous Discourse.
Report No.
4681, Bolt, Beranek andNewman, Cambridge, MA.Rich, E. 1988 Stereotypes and User Modeling.
In Kobsa, A. andWahlster, W.
(eds.
), User Models in Dialog Systems.
Springer-Verlag, Berlin--New York.Schiffer, S. R. 1972 Meaning.
Clarendon Press, Oxford, England.Schuster, E. 1985 Grammars as User Models.
In Proceedings oftheInternational Joint Conference on Artificial Intelligence, IJCAI-85, Los Angeles, CA: 20-22.NOTEThe abbreviations are mnemonic: read "system believes" for"SB", "system wants" for "SW", "user believes" for "UB","'mutual belief" for "MB", etc.94 Computational Linguistics, Volume 14, Number 3, September 1988
