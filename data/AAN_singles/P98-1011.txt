Evaluating a Focus-Based Approach to Anaphora Resolution*Sa l iha  Azzam,  Kev in  Humphreys  and Rober t  Ga izauskas{s. azzam, k. humphreys,  r .
ga izauskas}?dcs ,  she f .
ac.
ukDepartment  of Computer  Science, University of SheffieldRegent Court, Portobel lo RoadSheffield S1 4DP UKAbst rac tWe present an approach to anaphora resolutionbased on a focusing algorithm, and implementedwithin an existing MUC (Message Understand-ing Conference) Information Extraction system,allowing quantitative valuation against a sub-stantial corpus of annotated real-world texts.Extensions to the basic focusing mechanism canbe easily tested, resulting in refinements o themechanism and resolution rules.
Results showthat the focusing algorithm is highly sensitiveto the quality of syntactic-semantic analyses,when compared to a simpler heuristic-based ap-proach.1 In t roduct ionAnaphora resolution is still present as a signi-ficant linguistic problem, both theoretically andpractically, and interest has recently been re-newed with the introduction of a quantitativeevaluation regime as part of the Message Under-standing Conference (MUC) evaluations of In-formation Extraction (IE) systems (Grishmanand Sundheim, 1996).
This has made it pos-sible to evaluate different (implementable) the-oretical approaches against sizable corpora ofreal-world texts, rather than the small collec-tions of artificial examples typically discussedin the literature.This paper describes an evaluation of a focus-based approach to pronoun resolution (not ana-phora in general), based on an extension ofSidner's algorithm (Sidner, 1981) proposed in(Azzam, 1996), with further refinements fromdevelopment on real-world texts.
The approach* This work was carried out in the context of the EUAVENTINUS project (Thumair, 1996), which aims todevelop a multilingual IE system for drug enforcement,and including alanguage-independent coreference mech-anism (Azzam et al, 1998).is implemented within the general coreferencemechanism provided by the LaSIE (Large ScaleInformation Extraction) system (Gaizauskas etal., 1995) and (Humphreys et al, 1998), Shef-field University's entry in the MUC-6 and 7evaluations.2 Focus  in Anaphora  Reso lu t ionThe term focus, along with its many relationssuch as theme, topic, center, etc., reflects an in-tuitive notion that utterances in discourse areusually 'about' something.
This notion has beenput to use in accounts of numerous linguisticphenomena, but it has rarely been given a firmenough definition to allow its use to be evalu-ated.
For anaphora resolution, however, stem-ming from Sidner's work, focus has been givenan algorithmic definition and a set of rules for itsapplication.
Sidner's approach is based on theclaim that anaphora generally refer to the cur-rent discourse focus, and so modelling changesin focus through a discourse will allow the iden-tification of antecedents.The algorithm makes use of several focus re-gisters to represent the current state of a dis-course: CF, the current focus; AFL, the altern-ate focus list, containing other candidate foci;and FS, the focus stack.
A parallel structure tothe CF, AF the actor focus, is also set to dealwith agentive pronouns.
The algorithm updatesthese registers after each sentence, confirming orrejecting the current focus.
A set of Interpret-ation Rules (IRs) applies whenever an anaphoris encountered, proposing potential antecedentsfrom the registers, from which one is chosen us-ing other criteria: syntactic, semantic, inferen-tial, etc.742.1 Evaluating Focus-Based ApproachesSidner's algorithmic account, although not ex-haustively specified, has lead to the implement-ation of focus-based approaches to anaphoraresolution in several systems, e.g.
PIE (Lin,1995).
However, evaluation of the approach asmainly consisted of manual analyses of smallsets of problematic cases mentioned in the liter-ature.
Precise evaluation over sizable corpora ofreal-world texts has only recently become pos-sible, through the resources provided as part ofthe MUC evaluations.3 Core ference  in LaS IEThe LaSIE system (Gaizauskas et al, 1995)and (Humphreys et al, 1998), has been de-signed as a general purpose IE system whichcan conform to the MUC task specifications fornamed entity identification, coreference r solu-tion, IE template lement and relation identific-ation, and the construction of scenario-specificIE templates.
The system is basically a pipelinearchitecture consisting of tokenisation, sentencesplitting, part-of-speech tagging, morphologicalstemming, list lookup, parsing with semantic in-terpretation, proper name matching, and dis-course interpretation.
The latter stage con-structs a discourse model, based on a predefineddomain model, using the, often partial, se-mantic analyses upplied by the parser.The domain model represents a hierarchy ofdomain-relevant concept nodes, together withassociated properties.
It is expressed in the XIformalism (Gaizauskas, 1995) which provides abasic inheritance mechanism for property valuesand the ability to represent multiple classificat-ory dimensions in the hierarchy.
Instances ofconcepts mentioned in a text are added to thedomain model, populating it to become a text-,or discourse-, specific model.Coreference resolution is carried out by at-tempting to merge each newly added instance,including pronouns, with instances alreadypresent in the model.
The basic mechanismis to examine, for each new-old pair of in-stances: semantic type consistency/similarityin the concept hierarchy; attribute value con-sistency/similarity, and a set of heuristic rules,some specific to pronouns, which can act to ruleout a proposed merge.
These rules can referto various lexical, syntactic, semantic, and po-sitional information about instances.
The in-tegration of the focus-based approach replacesthe heuristic rules for pronouns, and representsthe use of LaSIE as an evaluation platform formore theoretically motivated algorithms.
It ispossible to extend the approach to include def-inite NPs but, at present, the existing rules areretained for non-pronominal naphora in theMUC coreference task: proper names, definitenoun phrases and bare nouns.4 Imp lement ing  Focus-BasedPronoun Reso lut ion  in LaS IEOur implementation makes use of the algorithmproposed in (Azzam, 1996), where elementaryevents (EEs, effectively simple clauses) are usedas basic processing units, rather than sentences.Updating the focus registers and the applicationof interpretation rules (IRs) for pronoun resolu-tion then takes place after each EE, permittingintrasentential references3 In addition, an ini-tial 'expected focus' is determined based on thefirst EE in a text, providing a potential ante-cedent for any pronoun within the first EE.Development of the algorithm using real-world texts resulted in various further refine-ments to the algorithm, in both the IRs and therules for updating the focus registers.
The fol-lowing sections describe the two rules sets sep-arately, though they are highly interrelated inboth development and processing.4.1 Updat ing  the FocusThe algorithm includes two new focus registers,in addition to those mentioned in section 2:AFS, the actor focus stack, used to record pre-vious AF (actor focus) values and so allow aseparate set of IRs for agent pronouns (animateverb subjects); and Intra-AFL, the intrasenten-tial alternate focus list, used to record candidatefoci from the current EE only.In the space available here, the algorithmis best described through an example showingthe use of the registers.
This example is takenfrom a New York Times article in the MUC-7training corpus on aircraft crashes:1An important limitation of Sidner's algorithm, notedin (Azzam, 1996), is that the focus registers are onlyupdated after each sentence.
Thus antecedents proposedfor an anaphor in the current sentence will always befrom the previous entence or before and intrasententialreferences axe impossible.75State Police said witnesses told them the pro-peller was not turning as the plane descendedquickly toward the highway in Wareham nearExit 2.
It hit a tree.EE- I :  State Police said te l l _eventAn 'expected focus' algorithm applies toinitialise the registers as follows:CF (current focus) = te l l _eventAF (actor focus) = State PoliceIntra-AFL remains empty because EE-1contains no other candidate foci.
No otherregisters are affected by the expected focus.No pronouns occur in EE-1 and so no IRs apply.EE-2: witnesses told themThe Intra-AFL is first initialised with all(non-pronominal) candidate foci in the EE:Intra-AFL = witnessesThe IRs are then applied to the first pronoun,them, and, in this case, propose the current AF,State Police, as the antecedent.
The Intra-AFLis immediately updated to add the antecedent:Intra-AFL = State Police, witnessesEE-2 has a pronoun in 'thematic' position,'theme' being either the object of a transitiveverb, or the subject of an intransitive or thecopula (following (Gruber, 1976)).
Its ante-cedent herefore becomes the new CF, with theprevious value moving to the FS.
EE-2 has an'agent', where this is an animate verb subject(again as in (Gruber, 1976)), and this becomesthe new AF.
Because the old AF is now theCF, it is not added to the AFS as it wouldbe otherwise.
After each EE the Intra-AFL isadded to the current AFL, excluding the CF.The state after EE-2 is then:CF = State Police AF  = witnessesFS = te l l _event  AFL = witnessesEE-3: the propeller was not turningThe Intra-AFL is reinitialised with candidatefoci from this EE:Intra-AFL = propellerNo pronouns occur in EE-3 and so no IRsapply.
The 'theme', propeller here becauseof the copula, becomes the new CF and theold one is added to the FS.
The AF remainsunchanged as the current EE lacks an agent:CF = propellerAF  = witnessesFS = State Police, te l l _eventAFL = propeller, witnessesEE-4: the plane descendedIntra-AFL = the planeCF = the plane (theme)AF = witnesses (unchanged)FS = propeller, State Police, te l l _eventAFL = the plane, propeller, witnessesIn the current algorithm the AFL is reset atthis point, because EE-4 ends the sentence.EE-5: it hit a treeIntra-AFL = a treeThe IRs resolve the pronoun it with the CF:CF = the plane (unchanged)AF = witnesses (unchanged)FS = propeller, State Police, te l l _eventAFL = a tree4.2 In terpretat ion  Ru lesPronouns are divided into three classes, eachwith a distinct set of IRs proposing antecedents:Persona l  p ronouns  act ing  as agents  (an-imate  sub jec ts ) :  (e.g.
he in Shotz said heknew the pilots) AF  proposed initially, then an-imate members of AFL.Non-agent  pronouns :  (e.g.
them in EE-2above and it in EE-5) CF proposed initially,then members of the AFL and FS.Possess ive,  rec ip roca l  and  ref lex ive pro-nouns  (PRRs) :  (e.g.
their in the brothershad left and were on their way home) Ante-cedents proposed from the Intra-AFL, allowingintra-EE references.Antecedents proposed by the IRs are accep-ted or rejected based on their semantic type andfeature compatibility, using the semantic andattribute value similarity scores of LaSIE's ex-isting coreference mechanism.5 Eva luat ion  w i th  the  MUC CorporaAs part of MUC (Grishman and Sundheim,1996), coreference resolution was evaluated asa sub-task of information extraction, which in-volved negotiating a definition of coreference r -lations that could be reliably evaluated.
The fi-nal definition included only 'identity' relationsbetween text strings: proper nouns, commonnouns and pronouns.
Other possible corefer-ence relations, such as 'part-whole', and non-text strings (zero anaphora) were excluded.76The definition was used to manually annot-ate several corpora of newswire texts, usingSGML markup to indicate relations betweentext strings.
Automatically annotated texts,produced by systems using the same markupscheme, were then compared with the manuallyannotated versions, using scoring software madeavailable to MUC participants, based on (Vilainet al, 1995).The scoring software calculates the stand-ard Information Retrieval metrics of 'recall' and'precision', 2 together with an overall f-measure.The following section presents the results ob-tained using the corpora and scorer providedfor MUC-7 training (60 texts, average 581 wordsper text, 19 words per sentence) and evaluation(20 texts, average 605 words per text, 20 wordsper sentence), the latter provided for the formalMUC-7 run and kept blind during development.6 Resu l tsThe MUC scorer does not distinguish betweendifferent classes of anaphora (pronouns, definitenoun phrases, bare nouns, and proper nouns),but baseline figures can be established by run-ning the LaSIE system with no attempt madeto resolve any pronouns:Corpus Recall Precision fTraining: 42.47.
73.67.
52.67.Evaluation: 44.77.
73 .97 .
55.77.LaSIE with the simple pronoun resolutionheuristics of the non-focus-based mechanismachieves the following:Corpus Recall Precision fTraining: 58 .27 .
71.37.
64.17.Evaluation : 56.07.
70.27.
62.37.showing that more than three quarters of theestimated 20% of pronoun coreferences in thecorpora are correctly resolved with only a minorloss of precision.LaSIE with the focus-based algorithmachieves the following:~Recall is a measure of how many correct (i.e.
manu-ally annotated) coreferences a system found, and preci-sion is a measure of how many coreferences that the sys-tem proposed were actually correct.
For example, with100 manually annotated coreference r lations in a corpusand a system that proposes 75, of which 50 are correct,recall is then 50/100 or 50% and precision is 50/75 or66.7%.Corpus Recall Precision fTraining: 55 .47 .
70.37.
61.97.Evaluation: 53.37.
69 .77 .
60.47.which, while demonstrating that the focus-based algorithm is applicable to real-world text,does question whether the more complex al-gorithm has any real advantage over LaSIE'soriginal simple approach.The lower performance of the focus-based al-gorithm is mainly due to an increased relianceon the accuracy and completeness of the gram-matical structure identified by the parser.
Forexample, the resolution of a pronoun will beskipped altogether if its role as a verb argu-ment is missed by the parser.
Partial parseswill also affect the identification of EE bound-aries, on which the focus update rules depend.For example, if the parser fails to attach a pre-positional phrase containing an antecedent, itwill then be missed from the focus registers andso the IRs (see (Azzam, 1995)).
The simpleLaSIE approach, however, will be unaffected inthis case.Recall is also lost due to the more restrictedproposal of candidate antecedents in the focus-based approach.
The simple LaSIE approachproposes antecedents from each preceding para-graph until one is accepted, while the focus-based approach suggests a single fixed set.From a theoretical point of view, manyinteresting issues appear with a large set ofexamples, discussed here only briefly becauseof lack of space.
Firstly, the fundamentalassumption of the focus-based approach, thatthe focus is favoured as an antecedent, doesnot always apply.
For example:In June, a few weeks before the crash ofTWA Flight 800, leaders of several MiddleEastern terrorist organizations met in Te-heran to plan terrorist acts.
Among themwas the PFL of Palestine, an organization thathas been linked to airplane bombings in the past.Here, the pronoun them corefers with organiz-ations rather than the focus leaders.
Additionalinformation will be required to override the fun-damental assumption.Another significant question is when sentencefocus changes.
In our algorithm, focus changeswhen there is no reference (pronominal orotherwise) to the current focus in the current77EE.
In the example used in section 4.1, thiscauses the focus at the end of the first sentenceto be that of the last EE in that sentence,thus allowing the pronoun it in the subsequentsentence to be correctly resolved with the plane.However in the example below, the focus ofthe first EE (the writ) is the antecedent of thepronoun it in the subsequent sentence, ratherthan the focus from the last EE (the ...flight):The writ is for "damages" of seven pas-sengers who died when the Airbus A310 flightcrashed.
It claims the deaths were caused bynegligence.Updating focus after the complete sentence,rather than each EE, would propose the cor-rect antecedent in this case.
However neitherstrategy has a significant overall advantage inour evaluations on the MUC corpora.Another important factor is the priorities ofthe Interpretation Rules.
For example, when apersonal pronoun can corefer with both CF andAF, IRs select the CF first in our algorithm.However, this priority is not fixed, being basedonly on the corpora used so far, which raises thepossibility of automatically acquiring IR prior-ities through training on other corpora.7 Conc lus ionA focus-based approach to pronoun resolutionhas been implemented within the LaSIE IE sys-tem and evaluated on real-world texts.
The res-ults show no significant preformance increaseover a simpler heuristic-based approach.
Themain limitation of the focus-based approach isits reliance on a robust syntactic/semantic ana-lysis to find the focus on which all the IRsdepend.
Examining performance on the real-world data also raises questions about the the-oretical assumptions of focus-based approaches,in particular whether focus is always a favouredantecedent, or whether this depends, to someextent, on discourse style.Analysing the differences in the results of thefocus- and non-focus-based approaches, doesshow that the focus-based rules are commonlyrequired when the simple syntactic and se-mantic rules propose a set of equivalent ante-cedents and can only select, say, the closest ar-bitrarily.
A combined approach is therefore sug-gested, but whether this would be more effect-ive than further refining the resolution rules ofthe focus-based approach, or improving parseresults and adding more detailed semantic on-straints, remains an open question.Re ferencesS.
Azzam, K. Humphreys, and R. Gaizauskas.1998.
Coreference resolution in a multilin-gual information extraction system.
In Pro-ceedings of the First Language Resources andEvaluation Conference (LREC).
LinguisticCoreference Workshop.S.
Azzam.
1995.
Anaphors, PPs and Disam-biguation Process for conceptual analysis.
InProceedings of l~th IJCALS.
Azzam.
1996.
Resolving anaphors in embed-ded sentences.
In Proceedings of 34th ACL.R.
Gaizauskas, T. Wakao, K Humphreys,H.
Cunningham, and Y. Wilks.
1995.
De-scription of the LaSIE system.
In Pro-ceedings of MUC-6, pages 207-220.
MorganKaufmann.R.
Gaizauskas.
1995.
XI: A KnowledgeRepresentation Language Based on Cross-Classification and Inheritance.
Technical Re-port CS-95-24, University of Sheffield.R.
Grishman and B. Sundheim.
1996.
Mes-sage Understanding Conference - 6: A briefhistory.
In Proceedings of 16th IJCAI, pages466-471.J.S.
Gruber.
1976.
Lexical structures in syntaxand semantics.
North-Holland.K.
Humphreys, R. Gaizauskas, S. Azzam,C.
Huyck, B. Mitchell, H. Cunningham, andY.
Wilks.
1998.
Description of the LaSIE-IIsystem.
In Proceedings of MUC-7.
Forthcom-ing.D.
Lin.
1995.
Description of the PIE System.
InProceedings of MUC-6, pages 113-126.
Mor-gan Kaufmann.C.
Sidner.
1981.
Focusing for interpretationof pronouns.
American Journal of Computa-tional Linguistics, 7:217-231.G.
Thurmair.
1996.
AVENTINUS System Ar-chitecture.
AVENTINUS project report LE1-2238.M.
Vilain, J. Burger, J. Aberdeen, D. Connolly,and L. Hirschman.
1995.
A model-theoreticcoreference scoring scheme.
In Proceedings ofMUC-6, pages 45-52.
Morgan Kaufmann.78
