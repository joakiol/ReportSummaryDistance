Proceedings of the 3rd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, pages 70?78,Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational LinguisticsPrior versus Contextual Emotion of a Word in a SentenceDiman GhaziEECS, University of Ottawadghaz038@uottawa.caDiana InkpenEECS, University of Ottawadiana@eecs.uottawa.caStan SzpakowiczEECS, University of Ottawa &ICS, Polish Academy of Sciencesszpak@eecs.uottawa.caAbstractA set of words labelled with their prior emo-tion is an obvious place to start on the auto-matic discovery of the emotion of a sentence,but it is clear that context must also be con-sidered.
No simple function of the labels onthe individual words may capture the overallemotion of the sentence; words are interre-lated and they mutually influence their affect-related interpretation.
We present a methodwhich enables us to take the contextual emo-tion of a word and the syntactic structure of thesentence into account to classify sentences byemotion classes.
We show that this promisingmethod outperforms both a method based ona Bag-of-Words representation and a systembased only on the prior emotions of words.The goal of this work is to distinguish auto-matically between prior and contextual emo-tion, with a focus on exploring features impor-tant for this task.1 IntroductionRecognition, interpretation and representation of af-fect have been investigated by researchers in thefield of affective computing (Picard 1997).
Theyconsider a wide range of modalities such as affect inspeech, facial display, posture and physiological ac-tivity.
It is only recently that there has been a grow-ing interest in automatic identification and extractionof sentiment, opinions and emotions in text.Sentiment analysis is the task of identifying posi-tive and negative opinions, emotions and evaluations(Wilson, Wiebe, and Hoffmann, 2005).
Most of thecurrent work in sentiment analysis has focused ondetermining the presence of sentiment in the giventext, and on determining its polarity ?
the positive ornegative orientation.
The applications of sentimentanalysis range from classifying positive and nega-tive movie reviews (Pang, Lee, and Vaithyanathan,2002; Turney, 2002) to opinion question-answering(Yu and Hatzivassiloglou, 2003; Stoyanov, Cardie,and Wiebe, 2005).
The analysis of sentiment must,however, go beyond differentiating positive fromnegative emotions to give a systematic account ofthe qualitative differences among individual emo-tion (Ortony, Collins, and Clore, 1988).In this work, we deal with assigning fine-grainedemotion classes to sentences in text.
It might seemthat these two tasks are strongly tied, but the higherlevel of classification in emotion recognition taskand the presence of certain degrees of similaritiesbetween some emotion labels make categorizationinto distinct emotion classes more challenging anddifficult.
Particularly notable in this regard are twoclasses, anger and disgust, which human annotatorsoften find hard to distinguish (Aman and Szpakow-icz, 2007).
In order to recognize and analyze affectin written text ?
seldom explicitly marked for emo-tions ?
NLP researchers have come up with a varietyof techniques, including the use of machine learn-ing, rule-based methods and the lexical approach(Neviarouskaya, Prendinger, and Ishizuka, 2011).There has been previous work using statisticalmethods and supervised machine learning applied tocorpus-based features, mainly unigrams, combinedwith lexical features (Alm, Roth, and Sproat, 2005;Aman and Szpakowicz, 2007; Katz, Singleton, andWicentowski, 2007).
The weakness of such methods70is that they neglect negation, syntactic relations andsemantic dependencies.
They also require large (an-notated) corpora for meaningful statistics and goodperformance.
Processing may take time, and anno-tation effort is inevitably high.
Rule-based meth-ods (Chaumartin, 2007; Neviarouskaya, Prendinger,and Ishizuka, 2011) require manual creation of rules.That is an expensive process with weak guaran-tee of consistency and coverage, and likely verytask-dependent; the set of rules of rule-based af-fect analysis task (Neviarouskaya, Prendinger, andIshizuka, 2011) can differ drastically from what un-derlies other tasks such as rule-based part-of-speechtagger, discourse parsers, word sense disambigua-tion and machine translation.The study of emotions in lexical semantics wasthe theme of a SemEval 2007 task (Strapparava andMihalcea, 2007), carried out in an unsupervised set-ting (Strapparava and Mihalcea, 2008; Chaumartin,2007; Kozareva et al, 2007; Katz, Singleton, andWicentowski, 2007).
The participants were encour-aged to work with WordNet-Affect (Strapparava andValitutti, 2004) and SentiWordNet (Esuli and Sebas-tiani, 2006).
Word-level analysis, however, will notsuffice when affect is expressed by phrases which re-quire complex phrase- and sentence-level analyses:words are interrelated and they mutually influencetheir affect-related interpretation.
On the other hand,words can have more than one sense, and they canonly be disambiguated in context.
Consequently, theemotion conveyed by a word in a sentence can differdrastically from the emotion of the word on its own.For example, according to the WordNet-Affect lex-icon, the word ?afraid?
is listed in the ?fear?
cate-gory, but in the sentence ?I am afraid it is going torain.?
the word ?afraid?
does not convey fear.We refer to the emotion listed for a word in anemotion lexicon as the word?s prior emotion.
Aword?s contextual emotion is the emotion of the sen-tence in which that word appears, taking the contextinto account.Our method combines several way of tackling theproblem.
First, we find keywords listed in WordNet-Affect and select the sentences which include emo-tional words from that lexicon.
Next, we study thesyntactic structure and semantic relations in the textsurrounding the emotional word.
We explore fea-tures important in emotion recognition, and we con-happi- sad- anger dis- sur- fear totalness ness gust prise398 201 252 53 71 141 1116Table 1: The distribution of labels in the WordNet-Affect Lexicon.sider their effect on the emotion expressed by thesentence.
Finally, we use machine learning to clas-sify the sentences, represented by the chosen fea-tures, by their contextual emotion.We categorize sentences into six basic emotionsdefined by Ekman (1992); that has been the choiceof most of previous related work.
These emotionsare happiness, sadness, fear, anger, disgust and sur-prise.
There also may, naturally, be no emotion in asentence; that is tagged as neutral/non-emotional.We evaluate our results by comparing our methodapplied to our set of features with Support Vec-tor Machine (SVM) applied to Bag-of-Words, whichwas found to give the best performance among su-pervised methods (Yang and Liu, 1999; Pang, Lee,and Vaithyanathan, 2002; Aman and Szpakowicz,2007; Ghazi, Inkpen, and Szpakowicz, 2010).
Weshow that our method is promising and that it out-performs both a system which works only with prioremotions of words, ignoring context, and a systemwhich applies SVM to Bag-of-Words.Section 2 of this paper describes the dataset andresources used.
Section 3 discusses the featureswhich we use for recognizing contextual emotion.Experiments and results are presented in Section 4.In Section 5, we conclude and discuss future work.2 Dataset and ResourcesSupervised statistical methods typically requiretraining data and test data, manually annotatedwith respect to each language-processing task to belearned.
In this section, we explain the dataset andlexicons used in our experiments.WordNet-Affect Lexicon (Strapparava and Vali-tutti, 2004).
The first resource we require is anemotional lexicon, a set of words which indicatethe presence of a particular emotion.
In our exper-iments, we use WordNet-Affect, which contains sixlists of words corresponding to the six basic emo-tion categories.
It is the result of assigning a variety71Neutral Negative Positive Both6.9% 59.7% 31.1% 0.3%Table 2: The distribution of labels in the Prior-PolarityLexicon.of affect labels to each synset in WordNet.
Table 1shows the distribution of words in WordNet-Affect.Prior-Polarity Lexicon (Wilson, Wiebe, andHoffmann, 2009).
The prior-polarity subjectivitylexicon contains over 8000 subjectivity clues col-lected from a number of sources.
To create thislexicon, the authors began with the list of subjec-tivity clues extracted by Riloff (2003).
The listwas expanded using a dictionary and a thesaurus,and adding positive and negative word lists fromthe General Inquirer.1 Words are grouped intostrong subjective and weak subjective clues; Table 2presents the distribution of their polarity.Intensifier Lexicon (Neviarouskaya, Prendinger,and Ishizuka, 2010).
It is a list of 112 modifiers (ad-verbs).
Two annotators gave coefficients for inten-sity degree ?
strengthening or weakening, from 0.0to 2.0 ?
and the result was averaged.Emotion Dataset (Aman and Szpakowicz,2007).
The main consideration in the selection ofdata for emotional classification task is that the datashould be rich in emotion expressions.
That is whywe chose for our experiments a corpus of blog sen-tences annotated with emotion labels, discussed byAman and Szpakowicz (2007).
Each sentence istagged by its dominant emotion, or as non-emotionalif it does not include any emotion.
The annotation isbased on Ekman?s six emotions at the sentence level.The dataset contains 4090 annotated sentences, 68%of which were marked as non-emotional.
The highlyunbalanced dataset with non-emotional sentences asby far the largest class, and merely 3% in the fearand surprise classes, prompted us to remove 2000 ofthe non-emotional sentences.
We lowered the num-ber of non-emotional sentences to 38% of all thesentences, and thus reduced the imbalance.
Table 3shows the details of the chosen dataset.1www.wjh.harvard.edu/?inquirer/hp sd ag dg sr fr ne total536 173 179 172 115 115 800 2090Table 3: The distribution of labels in Aman?s modifieddataset.
The labels are happiness, sadness, anger, dis-gust, surprise, fear, no emotion.3 FeaturesThe features used in our experiments were motivatedboth by the literature (Wilson, Wiebe, and Hoff-mann, 2009; Choi et al, 2005) and by the explo-ration of contextual emotion of words in the anno-tated data.
All of the features are counted based onthe emotional word from the lexicon which occurs inthe sentence.
For ease of description, we group thefeatures into four distinct sets: emotion-word fea-tures, part-of-speech features, sentence features anddependency-tree features.Emotion-word features.
This set of features arebased on the emotion-word itself.?
The emotion of a word according to WordNet-Affect (Strapparava and Valitutti, 2004).?
The polarity of a word according to the prior-polarity lexicon (Wilson, Wiebe, and Hoff-mann, 2009).?
The presence of a word in a small list of modi-fiers (Neviarouskaya, Prendinger, and Ishizuka,2010).Part-of-speech features.
Based on the Stanfordtagger?s output (Toutanova et al, 2003), every wordin a sentence gets one of the Penn Treebank tags.?
The part-of-speech of the emotional word it-self, both according to the emotion lexicon andStanford tagger.?
The POS of neighbouring words in the samesentence.
We choose a window of [-2,2], as itis usually suggested by the literature (Choi etal., 2005).Sentence features.
For now we only consider thenumber of words in the sentence.Dependency-tree features.
For each emotionalword, we create features based on the parse tree andits dependencies produced by the Stanford parser(Marneffe, Maccartney, and Manning, 2006).
The72dependencies are all binary relations: a grammati-cal relation holds between a governor (head) and adependent (modifier).According to Mohammad and Turney (2010),2adverbs and adjectives are some of the mostemotion-inspiring terms.
This is not surprising con-sidering that they are used to qualify a noun or averb; therefore to keep the number of features small,among all the 52 different type of dependencies, weonly chose the negation, adverb and adjective modi-fier dependencies.After parsing the sentence and getting the de-pendencies, we count the following dependency-treeBoolean features for the emotional word.?
Whether the word is in a ?neg?
dependency(negation modifier): true when there is a nega-tion word which modifies the emotional word.?
Whether the word is in a ?amod?
dependency(adjectival modifier): true if the emotionalword is (i) a noun modified by an adjective or(ii) an adjective modifying a noun.?
Whether the word is in a ?advmod?
depen-dency (adverbial modifier): true if the emo-tional word (i) is a non-clausal adverb or adver-bial phrase which serves to modify the meaningof a word, or (ii) has been modified by an ad-verb.We also have several modification features basedon the dependency tree.
These Boolean features cap-ture different types of relationships involving the cueword.3 We list the feature name and the condition onthe cue word w which makes the feature true.?
Modifies-positive: w modifies a positive wordfrom the prior-polarity lexicon.?
Modifies-negative: w modifies a negative wordfrom the prior-polarity lexicon.?
Modified-by-positive: w is the head of the de-pendency, which is modified by a positive wordfrom the prior-polarity lexicon.?
Modified-by-negative: w is the head of thedependency, which is modified by a negativeword from the prior-polarity lexicon.2In their paper, they also explain how they created an emo-tion lexicon by crowd-sourcing, but ?
to the best of our knowl-edge ?
it is not publicly available yet.3The terms ?emotional word?
and ?cue word?
are used in-terchangeably.hp sd ag dg sr fr ne totalpart 1 196 64 64 63 36 52 150 625part 2 51 18 22 18 9 14 26 158part 1+ 247 82 86 81 45 66 176 783part 2Table 4: The distribution of labels in the portions ofAman?s dataset used in our experiments, named part 1,part 2 and part 1+part 2.
The labels are happiness, sad-ness, anger, disgust, surprise, fear, no emotion.?
Modifies-intensifier-strengthen: w modifies astrengthening intensifier from the intensifierlexicon.?
Modifies-intensifier-weaken: w modifies aweakening intensifier from the intensifier lex-icon.?
Modified-by-intensifier-strengthen: w is thehead of the dependency, which is modified bya strengthening intensifier from the intensifierlexicon.?
Modified-by-intensifier-weaken: w is the headof the dependency, which is modified by aweakening intensifier from the intensifiers lex-icon.4 ExperimentsIn the experiments, we use the emotion dataset pre-sented in Section 2.
Our main consideration is toclassify a sentence based on the contextual emotionof the words (known as emotional in the lexicon).That is why in the dataset we only choose sentenceswhich contain at least one emotional word accord-ing to WordNet-Affect.
As a result, the number ofsentences chosen from the dataset will decrease to783 sentences, 625 of which contain only one emo-tional word and 158 sentences which contain morethan one emotional word.
Their details are shown inTable 4.Next, we represent the data with the features pre-sented in Section 3.
Those features, however, weredefined for each emotional word based on their con-text, so we will proceed differently for sentenceswith one emotional word and sentences with morethan one emotional word.?
In sentences with one emotional word, we as-sume the contextual emotion of the emotional73word is the same as the emotion assigned to thesentence by the human annotators; therefore allthe 625 sentences with one emotional word arerepresented with the set of features presentedin Section 3 and the sentence?s emotion will beconsidered as their contextual emotion.?
For sentences with more than one emotionalword, the emotion of the sentence depends onall emotional words and their syntactic and se-mantic relations.
We have 158 sentences whereno emotion can be assigned to the contextualemotion of their emotional words, and all weknow is the dominant emotion of the sentence.We will, therefore, have two different sets of ex-periments.
For the first set of sentences, the data areall annotated, so we will take a supervised approach.For the second set of sentences, we combine super-vised and unsupervised learning.
We train a clas-sifier on the first set of data and we use the modelto classify the emotional words into their contextualemotion in the second set of data.
Finally, we pro-pose an unsupervised method to combine the con-textual emotion of all the emotional words in a sen-tence and calculate the emotion of the sentence.For evaluation, we report precision, recall, F-measure and accuracy to compare the results.
Wealso define two baselines for each set of experimentsto compare our results with.
The experiments arepresented in the next two subsections.4.1 Experiments on sentences with oneemotional wordIn these experiments, we explain first the baselinesand then the results of our experiments on the sen-tences with only one emotional word.BaselineWe develop two baseline systems to assess the dif-ficulty of our task.
The first baseline labels the sen-tences the same as the most frequent class?s emo-tion, which is a typical baseline in machine learningtasks (Aman and Szpakowicz, 2007; Alm, Roth, andSproat, 2005).
This baseline will result in 31% ac-curacy.The second baseline labels the emotion of the sen-tence the same as the prior emotion of the only emo-tional word in the sentence.
The accuracy of thisPrecision Recall FSVM +Bag-of-WordsHappiness 0.59 0.67 0.63Sadness 0.38 0.45 0.41Anger 0.40 0.31 0.35Surprise 0.41 0.33 0.37Disgust 0.51 0.43 0.47Fear 0.55 0.50 0.52Non-emo 0.49 0.48 0.48Accuracy 50.72%SVM+ ourfeaturesHappiness 0.68 0.78 0.73Sadness 0.49 0.58 0.53Anger 0.66 0.48 0.56Surprise 0.61 0.31 0.41Disgust 0.43 0.38 0.40Fear 0.67 0.63 0.65Non-emo 0.51 0.53 0.52Accuracy 58.88%LogisticRegres-sion + ourfeaturesHappiness 0.78 0.82 0.80Sadness 0.53 0.64 0.58Anger 0.69 0.62 0.66Surprise 0.89 0.47 0.62Disgust 0.81 0.41 0.55Fear 0.71 0.71 0.71Non-emo 0.53 0.64 0.58Accuracy 66.88%Table 5: Classification experiments on the dataset withone emotional word in each sentence.
Each experimentis marked by the method and the feature set.experiment is 51%, remarkably higher than the firstbaseline?s accuracy.
The second baseline is particu-larly designed to address the emotion of the sentenceonly based on the prior emotion of the emotionalwords; therefore it will allow us to assess the dif-ference between the emotion of the sentence basedon the prior emotion of the words in the sentenceversus the case when we consider the context and itseffect on the emotion of the sentence.Learning ExperimentsIn this part, we use two classification algorithms,Support Vector Machines (SVM) and Logistic Re-gression (LR), and two different set of features,the set of features from Section 3 and Bag-of-Words (unigram).
Unigram models have beenwidely used in text classification and shown to pro-vide good results in sentiment classification tasks.In general, SVM has long been a method ofchoice for sentiment recognition in text.
SVM has74been shown to give good performance in text clas-sification experiments as it scales well to the largenumbers of features (Yang and Liu, 1999; Pang, Lee,and Vaithyanathan, 2002; Aman and Szpakowicz,2007).
For the classification, we use the SMO al-gorithm (Platt, 1998) from Weka (Hall et al, 2009),setting 10-fold cross validation as a testing option.We compare applying SMO to two sets of features,(i) Bag-of-Words, which are binary features defin-ing whether a unigram exists in a sentence and (ii)our set of features.
In our experiments we use uni-grams from the corpus, selected using feature selec-tion methods from Weka.We also compare those two results with the thirdexperiment: apply SimpleLogistic (Sumner, Frank,and Hall, 2005) from Weka to our set of features,again setting 10-fold cross validation as a testing op-tion.
Logistic regression is a discriminative prob-abilistic classification model which operates overreal-valued vector inputs.
It is relatively slow to traincompared to the other classifiers.
It also requires ex-tensive tuning in the form of feature selection andimplementation to achieve state-of-the-art classifica-tion performance.
Logistic regression models withlarge numbers of features and limited amounts oftraining data are highly prone to over-fitting (Alias-i, 2008).
Besides, logistic regression is really slowand it is known to only work on data representedby a small set of features.
That is why we do notapply SimpleLogistic to Bag-of-Words features.
Onthe other hand, the number of our features is rela-tively low, so we find logistic regression to be a goodchoice of classifier for our representation method.The classification results are shown in Table 5.We note consistent improvement.
The results ofboth experiments using our set of features signifi-cantly outperform (on the basis of a paired t-test,p=0.005) both the baselines and SVM applied toBag-of-Words features.
We get the best result, how-ever, by applying logistic regression to our featureset.
The number of our features and the nature ofthe features we introduce make them an appropriatechoice of data representation for logistic regressionmethods.4.2 Experiments on sentences with more thanone emotional wordIn these experiments, we combine supervised andunsupervised learning.
We train a classifier on thefirst set of data, which is annotated, and we use themodel to classify the emotional words in the sec-ond group of sentences.
We propose an unsuper-vised method to combine the contextual emotion ofthe emotional words and calculate the emotion of thesentence.BaselineWe develop two baseline systems.
The first base-line labels all the sentences the same: as the emo-tion of the most frequent class, giving 32% accu-racy.
The second baseline labels the emotion of thesentence the same as the most frequently occurringprior-emotion of the emotional words in the sen-tence.
In the case of a tie, we randomly pick oneof the emotions.
The accuracy of this experimentis 45%.
Again, as a second baseline we choose abaseline that is based on the prior emotion of theemotional words so that we can compare it with theresults based on contextual emotion of the emotionalwords in the sentence.Learning ExperimentsFor sentences with more than one emotionalword, we represent each emotional word and its con-text by the set of features explained in section 3.
Wedo not have the contextual emotion label for eachemotional word, so we cannot train the classifier onthese data.
Consequently, we train the classifier onthe part of the dataset which only includes sentenceswith one emotional word.
In these sentences, eachemotional word is labeled with their contextual emo-tion ?
the same as the sentence?s emotion.Once we have the classifier model, we get theprobability distribution of emotional classes for eachemotional word (calculated by the logistic regres-sion function learned from the annotated data).
Weadd up the probabilities of each class for all emo-tional words.
Finally, we select the class with themaximum probability.
The result, shown in Table 6,is compared using supervised learning, SVM, withBag-of-Words features, explained in previous sec-tion, with setting 10-fold cross validation as a testing75Precision Recall FSVM +Bag-of-WordsHappiness 0.52 0.60 0.54Sadness 0.35 0.33 0.34Anger 0.30 0.27 0.29Surprise 0.14 0.11 0.12Disgust 0.30 0.17 0.21Fear 0.44 0.29 0.35Non-emo 0.23 0.35 0.28Accuracy 36.71%LogisticRegres-sion +unsu-pervised+ ourfeaturesHappiness 0.63 0.71 0.67Sadness 0.67 0.44 0.53Anger 0.50 0.41 0.45Surprise 1.00 0.22 0.36Disgust 0.80 0.22 0.34Fear 0.60 0.64 0.62Non-emo 0.37 0.69 0.48Accuracy 54.43%Table 6: Classification experiments on the dataset withmore than one emotional word in each sentence.
Eachexperiment is marked by the method and the feature set.option.4By comparing the results in Table 6, we can seethat the result of learning applied to our set of fea-tures significantly outperforms (on the basis of apaired t-test, p=0.005) both baselines and the resultof SVM algorithm applied to Bag-of-Words features.4.3 DiscussionWe cannot directly compare our results with the pre-vious results achieved by Aman and Szpakowicz(2007), because the datasets differ.
F-measure, pre-cision and recall for each class are reported on thewhole dataset, but we only used part of that dataset.To show how hard this task is, and to see where westand, the best result from (Aman and Szpakowicz,2007) is shown in Table 7.In our experiments, we showed that our approachand our features significantly outperform the base-lines and the SVM result applied to Bag-of-Words.For the final conclusion, we add one more compar-ison.
As we can see from Table 6, the accuracyresult of applying SVM to Bag-of-Words is reallylow.
Because supervised methods scale well on largedatasets, one reason could be the size of the data weuse in this experiment; therefore we try to compare4Since SVM does not return a distribution probability, wecannot apply SVM to our features in this set of experiments.Precision Recall FHappiness 0.813 0.698 0.751Sadness 0.605 0.416 0.493Anger 0.650 0.436 0.522Surprise 0.723 0.409 0.522Disgust 0.672 0.488 0.566Fear 0.868 0.513 0.645Non-emo 0.587 0.625 0.605Table 7: Aman?s best result on the dataset explained inSection 2.the results of the two experiments on all 758 sen-tences with at least one emotional word.For this comparison, we apply SVM with Bag-of-Words features to all of 758 sentences and we getan accuracy of 55.17%.
Considering our featuresand methodology, we cannot apply logistic regres-sion with our features to the whole dataset; thereforewe calculate its accuracy by counting the percent-age of correctly classified instances in both parts ofthe dataset, used in the two experiments, and we getan accuracy of 64.36%.
We also compare the re-sults with the baselines.
The first baseline, whichis the percentage of most frequent class (happinessin this case), results in 31.5% accuracy.
The secondbaseline based on the prior emotion of the emotionalwords results in 50.13% accuracy.
It is notable thatthe result of applying LR to our set of features isstill significantly better than the result of applyingSVM to Bag-of-Words and both baselines; this sup-ports our earlier conclusion.
It is hard to comparethe results mentioned thus far, so we have combinedall the results in Figure 1, which displays the accu-racy obtained by each experiment.We also looked into our results and assessed thecases where the contextual emotion is different fromthe prior emotion of the emotional word.
Considerthe sentence ?Joe said it does not happen that oftenso it does not bother him.?
Based on the emotionlexicon, the word ?bother?
is classified as angry; sois the emotion of the sentence if we only considerthe prior emotion of words.
In our set of features,however, we consider the negation in the sentence,so the sentence is classified as non-emotional ratherthan angry.
Another interesting sentence is the rathersimple ?You look like her I guess.?
Based on the lex-icon, the word ?like?
is in the happy category, while76Figure 1: The comparison of accuracy results of all ex-periments for sentences with one emotional word (part1), sentences with more than one emotional words (part2), and sentences with at least one emotional word (part1+part 2).the sentence is non-emotional.
In this case, the part-of-speech features play an important role and theycatch the fact that ?like" is not a verb here; it doesnot convey a happy emotion and the sentence is clas-sified as non-emotional.We also analyzed the errors, and we found somecommon errors due to:?
complex sentences or unstructured sentenceswhich will cause the parser to fail or return in-correct data, resulting in incorrect dependency-tree information;?
limited coverage of the emotion lexicon.These are some of the issues which we would liketo address in our future work.5 Conclusion and Future DirectionsThe focus of this study was a comparison of prioremotion of a word with its contextual emotion, andtheir effect on the emotion expressed by the sen-tence.
We also studied features important in recog-nizing contextual emotion.
We experimented witha wide variety of linguistically-motivated features,and we evaluated the performance of these fea-tures using logistic regression.
We showed thatour approach and features significantly outperformthe baseline and the SVM result applied to Bag-of-Words.Even though the features we presented did quitewell on the chosen dataset, in the future we wouldlike to show the robustness of these features by ap-plying them to different datasets.Another direction for future work will be to ex-pand our emotion lexicon using existing techniquesfor automatically acquiring the prior emotion ofwords.
Based on the number of instances in eachemotion class, we noticed there is a tight relationbetween the number of words in each emotion listin the emotion lexicon and the number of sentencesthat are derived for each emotion class.
It followsthat a larger lexicon will have a greater coverage ofemotional expressions.Last but not least, one of the weaknesses of ourapproach was the fact that we could not use all theinstances in the dataset.
Again, the main reason wasthe low coverage of the emotion lexicon that wasused.
The other reason was the limitation of ourmethod: we had to only choose the sentences thathave one or more emotional words.
As future work,we would like to relax the restriction by using theroot of the sentence (based on the dependency treeresult) as a cue word rather than the emotional wordfrom the lexicon.
So, for sentences with no emo-tional word, we can calculate all the features regard-ing the root word rather than the emotional word.ReferencesAlias-i.
2008.
Lingpipe 4.1.0., October.Alm, Cecilia Ovesdotter, Dan Roth, and Richard Sproat.2005.
Emotions from Text: Machine Learning forText-based Emotion Prediction.
In HLT/EMNLP.Aman, Saima and Stan Szpakowicz.
2007.
Identifyingexpressions of emotion in text.
In Proc.
10th Inter-national Conf.
Text, Speech and Dialogue, pages 196?205.
Springer-Verlag.Chaumartin, Fran?ois-Regis.
2007.
UPAR7: aknowledge-based system for headline sentiment tag-ging.
In Proc.
4th International Workshop on Seman-tic Evaluations, SemEval ?07, pages 422?425.Choi, Yejin, Claire Cardie, Ellen Riloff, and SiddharthPatwardhan.
2005.
Identifying sources of opinionswith conditional random fields and extraction patterns.In Proc.
Human Language Technology and EmpiricalMethods in Natural Language Processing, HLT ?05,pages 355?362.Ekman, Paul.
1992.
An argument for basic emotions.Cognition & Emotion, 6(3):169?200.Esuli, Andrea and Fabrizio Sebastiani.
2006.
SENTI-WORDNET: A Publicly Available Lexical Resource77for Opinion Mining.
In Proc.
5th Conf.
on LanguageResources and Evaluation LREC 2006, pages 417?422.Ghazi, Diman, Diana Inkpen, and Stan Szpakowicz.2010.
Hierarchical approach to emotion recognitionand classification in texts.
In Canadian Conference onAI, pages 40?50.Hall, Mark, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA data mining software: an update.SIGKDD Explor.
Newsl., 11:10?18, November.Katz, Phil, Matthew Singleton, and Richard Wicen-towski.
2007.
SWAT-MP: the SemEval-2007 systemsfor task 5 and task 14.
In Proc.
4th International Work-shop on Semantic Evaluations, SemEval ?07, pages308?313.Kozareva, Zornitsa, Borja Navarro, Sonia V?zquez, andAndr?s Montoyo.
2007.
UA-ZBSA: a headline emo-tion classification through web information.
In Proc.4th International Workshop on Semantic Evaluations,SemEval ?07, pages 334?337.Marneffe, Marie-Catherine De, Bill Maccartney, andChristopher D. Manning.
2006.
Generating typed de-pendency parses from phrase structure parses.
In Proc.LREC 2006.Mohammad, Saif M. and Peter D. Turney.
2010.
Emo-tions evoked by common words and phrases: usingmechanical turk to create an emotion lexicon.
In Proc.NAACL HLT 2010 Workshop on Computational Ap-proaches to Analysis and Generation of Emotion inText, CAAGET ?10, pages 26?34.Neviarouskaya, Alena, Helmut Prendinger, and MitsuruIshizuka.
2010.
AM: textual attitude analysis model.In Proc.
NAACL HLT 2010 Workshop on Computa-tional Approaches to Analysis and Generation of Emo-tion in Text, pages 80?88.Neviarouskaya, Alena, Helmut Prendinger, and MitsuruIshizuka.
2011.
Affect Analysis Model: novel rule-based approach to affect sensing from text.
NaturalLanguage Engineering, 17(1):95?135.Ortony, Andrew, Allan Collins, and Gerald L. Clore.1988.
The cognitive structure of emotions.
CambridgeUniversity Press.Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: sentiment classification using ma-chine learning techniques.
In Proc.
ACL-02 confer-ence on Empirical methods in natural language pro-cessing - Volume 10, EMNLP ?02, pages 79?86.Platt, John C. 1998.
Sequential Minimal Optimization:A Fast Algorithm for Training Support Vector Ma-chines.Riloff, Ellen.
2003.
Learning extraction patterns for sub-jective expressions.
In Proc.
2003 Conf.
on EmpiricalMethods in Natural Language Processing, pages 105?112.Stoyanov, Veselin, Claire Cardie, and Janyce Wiebe.2005.
Multi-perspective question answering using theopqa corpus.
In Proc.
Conference on Human Lan-guage Technology and Empirical Methods in NaturalLanguage Processing, HLT ?05, pages 923?930.Strapparava, Carlo and Rada Mihalcea.
2007.
SemEval-2007 Task 14: Affective Text.
In Proc.
Fourth Interna-tional Workshop on Semantic Evaluations (SemEval-2007), pages 70?74, Prague, Czech Republic, June.Strapparava, Carlo and Rada Mihalcea.
2008.
Learningto identify emotions in text.
In Proc.
2008 ACM sym-posium on Applied computing, SAC ?08, pages 1556?1560.Strapparava, Carlo and Alessandro Valitutti.
2004.WordNet-Affect: an Affective Extension of Word-Net.
In Proc.
4th International Conf.
on LanguageResources and Evaluation, pages 1083?1086.Sumner, Marc, Eibe Frank, and Mark A.
Hall.
2005.Speeding Up Logistic Model Tree Induction.
In Proc.9th European Conference on Principles and Practiceof Knowledge Discovery in Databases, pages 675?683.Toutanova, Kristina, Dan Klein, Christopher D. Man-ning, and Yoram Singer.
2003.
Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network.In Proc.
HLT-NAACL, pages 252?259.Turney, Peter D. 2002.
Thumbs up or thumbs down?
:semantic orientation applied to unsupervised classifi-cation of reviews.
In Proc.
40th Annual Meeting onAssociation for Computational Linguistics, ACL ?02,pages 417?424.Wilson, Theresa, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-levelsentiment analysis.
In Proc.
HLT-EMNLP, pages 347?354.Wilson, Theresa, Janyce Wiebe, and Paul Hoffmann.2009.
Recognizing Contextual Polarity: An Explo-ration of Features for Phrase-Level Sentiment Analy-sis.
Computational Linguistics, 35(3):399?433.Yang, Yiming and Xin Liu.
1999.
A re-examinationof text categorization methods.
In Proc.
22nd an-nual international ACM SIGIR conference on Re-search and development in information retrieval, SI-GIR ?99, pages 42?49.Yu, Hong and Vasileios Hatzivassiloglou.
2003.
To-wards answering opinion questions: separating factsfrom opinions and identifying the polarity of opin-ion sentences.
In Proc.
2003 conference on Empiricalmethods in natural language processing, EMNLP ?03,pages 129?136.78
