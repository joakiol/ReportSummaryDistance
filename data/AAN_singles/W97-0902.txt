Developing a new grammar checker for Englishas a second languageCornelia Tschichold, Franck Bodmer, Etienne Cornu, Franqois Grosjean,Lysiane Grosjean, Natalie Ktibler, Nicolas Lrwy & Corinne TschumiLaboratoire de traitement du langage t de la paroleUniversit6 de Neuch~tel, Avenue du Premier-Mars 26CH - 2000 Neuch~telAbstractIn this paper we describe the prototype ofa new grammar checker specifically gearedto the needs of French speakers writing inEnglish.
Most commerc ia l  g rammarcheckers on the market oday are meant o beused by native speakers of a language whohave good intuitions about their ownlanguage competence.
Non-native speakersof a language, however, have different intu-itions and are very easily confused by falsealarms, i.e.
error messages given by thegrammar checker when there is in fact noerror in the text.
In our project aimed atdeveloping a complete writing tool for thenon-native speaker, we concentrated onbuilding a grammar checker that keeps therate of over-flagging down and on deve-loping a user-friendly writing environmentwhich contains, among other things, a seriesof on-line helps.
The grammar checkingcomponent, which is the focus of this paper,uses island processing (or chunking) ratherthan a full parse.
This approach is both rapidand appropriate when a text contains manyerrors.
We explain how we use automata toidentify mult i -word units, detect errors(which we first isolated in a corpus oferrors) and interact with the user.
We endwith a short evaluation of our prototype andcompare it to three currently avai lablecommercial grammar checkers.I Introduct ionMany word-processing systems todayinclude grammar checkers which can beused to locate various grammatical problemsin a text.
These tools are clearly aimed atnative speakers even if they can be of somehelp to non-nat ive speakers as well.However, non-native speakers make moreerrors than native speakers and their errorsare quite different (Corder 1981).
Becauseof this, they require grammar checkersdesigned for their specific needs (Granger &Meunier 1994).The prototype we have developed isaimed at French native speakers writing inEnglish.
From the very start, we worked onthe idea that our prototype would be com-mercialized.
In order to find out users' realneeds, we first conducted a survey amongpotential users and experts in the field con-cerning such issues as coverage and theinterface.
In addition, we studied whicherrors needed to be dealt with.
To do this,we integrated the information on errorsfound in published lists of typical learnererrors, e.g.
Fitikides (1963), with our owncorpus of errors obtained from English textswritten by French native speakers.
Some27'000 words of text produced over 2'800errors, which were classified and sorted.
Wehave used this corpus to decide which errorsto concentrate on and to evaluate the correc-tion procedures developed.
The followingtwo tables give the percentages of errorsfound in our corpus, broken down by themajor categories, followed by the subcate-gories pertaining to the verb.Error type percentagespelling & pronunciation 10.3 %adjectives 5.3 %adverbs 4.4 %nouns 19.6 %verbs 24.5 %word combinations 8.3 %sentence 27.6 %Table 1: Percentage of errors bymajor categoriesError type percentagemorphology 1.2 %agreement 1.4 %tenses 8.8 %lexicon 8.0 %phrase following the verb 5 .1%Table 2: Percentage of verb er rors  bysubcategoriesThe prototype includes a set of writingaids, a problem word highlighter and agrammar checker.
The writing aids includetwo monolingual and a bilingual dictionary(simulated), a verb conjugator, a smal ltranslating module for certain fixed expres-sions, and a comprehens ive  on- l inegrammar.
The problem word highlighter isused to show all the potential lexical errorsin a text.
While we hoped that the grammarchecker would cover as many different ypesof errors as possible, it quickly became clearthat certain errors could not be handled satis-factorily with the checker, e.g.
using library(based on French librairie) instead of book-store in a sentence like I need to go to thelibrary in order to buy a present for myfather.
Instead of flagging every instance oflibrary in a text, something other grammarcheckers often do, we developed the prob-lem word highlighter.
It allows the user toview all the problematic words at one glanceand it offers help, i.e.
explanations andexamples for each word, on request.Potential errors such as false friends, con-fusions, foreign loans, etc.
are tackled bythe highlighter.
The heart of the prototype isthe grammar checker, which we describebelow.
Further details about the writing aidscan be found in Tschumi et al (1996).2 The  grammar  checkerTexts written by non-native speakers aremore difficult to parse than texts written bynative speakers because of the number andtypes of errors they contain.
It is doubtfulwhether a complete parse of a sentence con-raining these kinds of errors can be achievedwith today's technology (Thurmair 1990).To get around this, we chose an approachusing island processing.
Such a method,similar to the chunking approach describedin Abney (1991), makes it possible to extractfrom the text most of the information eededto detect errors without wasting time andresources on trying to parse an ungram-matical sentence fully.
Chunking can be seenas an intermediary step between tagging andparsing, but it can also be used to get aroundthe problem of a full parse when dealingwith ill-formed text.Once the grammar checker has beenactived, the text which is to be checked goesthrough a number of stages.
It is first seg-mented into sentences and words.
The indi-vidual words are then looked up in thedictionary, which is an extract of CELEX(see Burnage 1990).
It includes all thewords that occur in our corpus of texts, withall their possible readings.
For example, theword the is listed in our dictionary as adeterminer and as an adverb; table has anentry both as a noun and as a verb.
In thissense, our dictionary is not a simplified andscaled-down version of a full dictionary, butsimply a shorter version.
In the next stage,an algorithm based on neural networks (seeBodmer 1994)disambiguates all wordswhich belong to more than one syntacticcategory.
Furthermore, some mult i -wordunits are identified and labeled with a singlesyntactic category, e.g.
a lot of(PRON) I.After this stage, island parsing can begin.
Afirst step consists in identifying simple nounphrases.
On the basis of these NPs, prepro-eessing automata ssemble complex nounphrases and assign features to them when-ever possible.
In a second step, other pre-processing automata identify the verb groupand assign tense, voice and aspect featuresto it.
Finally, in a third step, error detectionautomata re run, some of which involveinteracting with the user.
Each of these threesteps will be described below.3 The preprocessing stageThe noun phrase parser identifies implenon- recurs ive  noun phrases such asDet+Adj+N or N+N.
The method used forthis process involves an algorithm of thetype described in Church (1988) which wastrained on a manually marked part of ourcorpus.
The module is thus geared to theparticular type of second language text thechecker needs to deal with.
The resulting in-formation is passed on to a preprocessingmodule consisting of a number of automatagroups.
The automata used here (as well asin subsequent modules) are finite-stateautomata similar to those described in Allen(1987) or Silberztein (1993).
This type ofautomata is well-known for its efficiencyand versatility.In the preprocessing module, a first set ofautomata scan the text for noun phrases,identify the head of each NP and assign thefeatures for  person and number to it.
Othersets of automata then mark temporal nounphrases, e.g.
this past week or six monthsago.
In a similar fashion, some prepositionalphrases are given specific features if theydenote time or place, e.g.
during that period,at the office.
Still within the same prepro-cessing module, some recursive NPs arethen assembled into more complex NPs,e.g.
the arrival of the first group.
Finally,human NPs are identified and given a specialfeature.
This is illustrated in the followingautomaton:Automaton 1<NP @\[CAT = N, +HUMAN\](NP_TYPE => NP_HUM) >Every automaton starts by looking for itsanchor, an arc marked by "@" (not neces-sarily the first arc in the automaton).
Theabove automaton first looks for a noun(inside a noun phrase) which occurs in thelist of nouns denoting human beings.
If itfinds one, it puts the value NP_HUMAN inthe register called NP TYPE, a registerwhich is associated with the NP as a whole.The second group of preprocessingautomata deals with the verb group.Periphrastic verb forms are analyzed fortense, aspect, and phase, and the resultstored in registers.
The content of theseregisters can later be called upon by thedetection automata.
After these two prepro-cessing stages, the error detection automatacan begin their work.4 Er ror  detectionOnce important islands in the sentencehave been identified, it becomes much easierto write detection automata which look forspecific types of errors.
Because no overallparse is attempted, error detection has to relyon wel l -descr ibed contexts.
Such anapproach, which reduces overflagging, alsohas the advantage of describing errorsprecisely.
Errors can thus not only be iden-tified but can also be explained to the user.Suggestions can also be made as to howerrors can be corrected.One of the detection automata that makeuse of the NPs which have been previouslyidentified is the automaton used for certaincases of subject-noun agreement (e.g.
*Henever eat cucumber sandwiches):l This part of speech corresponds toCELEX's use of'PRON'.Automaton 2<NP (PERS_NP = P3,NBR_NP = SING)>\[CAT = ADV\]* I@\[CAT = V, TNS = PRES, MORPH ~ P3\]This automaton (simplif ied here) firstlooks for the content of its last arc, a verbwhich is not in the third person singularform of the present ense.
From there it pro-ceeds leftwards.
The arc before the an-choring arc optionally matches an adverb.The next arc, the second from the top,matches an NP which has been found tohave the features third person singular.
If thewhole of this detection automaton succeeds,a message appears which suggests that theverb be changed to the third person singularform.5 User interactionIt is sometimes possible to detect an errorwithout being completely sure about itsidentity or how to correct it.
To deal withsome of these cases, we have developed aninteractive mode where the user is asked foradditional information on the problem inquestion.
The first step is to detect thestructure where there might be an error.Here again, the preprocessing automata reput to use.
For example, the fo l low ingautomaton looks for the erroneous order ofconst i tuents in a sentence containing atransitive verb (as in *We saw on the planetall the little Martians).Automaton 3@ \[CAT = V, +TRANS\]<PP (PP_TYPE = PP_TIME IPP_TYPE = PP_PLACE)><NP (NP_TYPE ~ NP_TIME)>If this automaton finds a sequence thatcontains a transitive verb fol lowed by aprepositional phrase with either the featurePP T IME or PP PLACE and that ends in anoun phrase which does not have the featureNP_TIME, then the fol lowing question isput to the user:"La srquence "all the little Martians" est-elle l'objet direct du verbe "saw"?
"("Is the sequence "all the little Martians"the direct object of the verb "saw"?
")If the user presses on the Yes-button, areordering of the predicate is suggested so asto give V - NP - PP (this can be done auto-matically).
If the No-button is pressed, athank-you message appears instead and thechecker moves on to the next error.Interaction is also used in cases whereone of two possible corrections needs to bechosen.
If a French native speaker writes*the more great, it is not clear whether s/heintended to use a comparative or a super-lative.
This can be determined by interactingwith the user and an appropriate correctioncan then be proposed if need be.Whi le developing the automata whichinclude interaction, we took great care not toask too much of the user.
So far we haveused less than ten different question patternsand the vocabulary has been restricted toterminology famil iar to potential users.
Inaddition we only ask one question per inter-action.Interacting with the user can thus be avaluable device during error detection if it isused with caution.
Too many interactions,especially if they do not lead to actual errorcorrection, can be annoying.
They shouldtherefore be restricted to cases where there isa fair chance of detecting an error and shouldnot be used to flag problematic lexical itemssuch as all the tokens of the word library in atext.6 Eva luat ionIn a first evaluation using the approachdescribed in Tschichold (1994), we com-pared our prototype to three commercia lgrammar checkers: Correct Grammar forMacintosh (version 2.0 of the monol ingualEngl ish grammar checker developed byLifetree Software and Houghton Mifflin),Grammatik for Macintosh (the English for10MeasureError detectionError overflaggingPrototype14.5%43.5%CorrectGrammar10.5%74%Grammatik12.5%75%WinProof34%76%Table 3.
Error detection and error overflagging scores for the prototype andthree commercial grammar checkersFrench users 4.2 version of the ReferenceSoftware grammar checker) and WinProoffor PC (version 4.0 of Lexpertise LinguisticSoftware's English grammar checker forFrench speakers).
While the overall per-centage of correctly detected errors is stillrather low for all of the tested checkers,Table 3 clearly shows that our prototypedoes the best at keeping the overflaggingdown while doing relatively well on realerrors.
2A more extensive valuation can befound in Cornu et al (forthcoming).Another way of evaluating our prototypeis to see how closely it follows the guide-lines for an efficient EFL/ESL grammarchecker proposed by Granger & Meunier(1994).
They describe four different criteriawhich should apply to grammar checkersused by non-natives.
According to them, agood second language grammar checkershould:?
be based on authentic learner errors:This first criterion is met with the errorcorpus we collected to help us identify thetypes of errors that need to be dealt with.?
have a core program and bilingual 'add-on' components:The general island processing approachwe have adopted can be employed both formonol ingual  and bi l ingual  g rammarcheckers.
Full parse approaches, however,2 The error detection scores hown here are ratherlow compared to those of other evaluations (e.g.Bolt 1992, Granger & Meunier 1994).
This can beexplained by the fact that most of the test items usedcame from real texts produced by non-nativespeakers and were not specifically written by theevaluator to test a particular system.
Real textscontain many iexical and semantic errors whichcannot be corrected with today's grammar checkers.are not as easy to use on non-native speakertexts which contain many errors.
'Add-on'components will include the kinds of writingaids we have integrated into the prototype.?
be customizable:The grammar checker can be customizedby turning on or off certain groups ofautomata relating to grammatical reas suchas "subject-verb agreement" or "tense".?
indicate what it can and cannot do:This variable is dealt with both in flyerssent around and in the checker's manual.
Asour prototype is not yet commercialized, thislast criterion does yet apply here.7 Conc lud ing  remarksIn this paper we have presented theprototype of a second language writing toolfor French speakers writing in English.
It ismade up of a set of writing aids, a problemword highlighter and a grammar checker.Two characteristics of the checker make itparticularly interesting.
First, overflaggingis reduced.
This is done by moving certainsemantic problems to the problem wordhighlighter, gearing the automata to specificerrors and interacting with the user fromtime to time.
Second, the use of island pro-cessing has kept processing time down to alevel that is acceptable to users.Because we have designed a prototypewith the view to commercializing it, scalingup can be achieved quite easily.
The dictio-nary already contains all word classesneeded and we do not expect the disam-biguation stage to become less efficientwhen a larger dictionary is used.
In addi-tion, the error processing technology that weIIhave implemented allows for all componentsto be expanded without degrading thequality.
Commercial development willinvolve increasing the size of the dictionary,adding automata to cover a wider range oferrors, finishing some of the writing aidsand integrating the completed product, i.e.the writing tool, into existing word pro-cessors.As for the reusability of various compo-nents of our grammar checker for otherlanguage pairs, we believe that many of theerrors in English are also made by speakersof other languages, particularly otherRomance languages.
Thus many of ourautomata could probably be reused as such.Ho~'ever, the writing aids and the problemword highlighter would obviously need tobe adapted to the user's first language.AcknowledgementsThe work presented here was part of aproject funded by the Swiss Committee forthe Encouragement of Scientific Research(CERS/KWF 20.54.2).ReferencesSteven Abney.
1991.
Parsing by chunks.
InR.
Berwick, S. Abney & C.
Tenny(Eds.)
Principle-Based Parsing.Dordrecht: Kluwer.Franck Bodmer.
1994.
DELENE: undrsambigufsateur lexical neuronal pourtextes en langue seconde.
TRANEL(Travaux neuchfitelois de linguistique),21: 247-263.Philip Bolt.
1992.
An evaluation of gram-mar-checking programs as self-:helpinglearning aids for learners of English as aforeign language.
CALL; 5:49-91.Gavin Burnage.
1990.
CELEX - A Guidefor Users.
Centre for LexicalInformation, University of Nijmegen,The Netherlands.Kenneth Church.
1988.
A stochastic partsprogram and noun phrase parser for un-restricted text.
Proceedings of theSecond Conference on Applied NaturalLanguage Processing.
Austin, Texas.Pit S. Corder.
1981.
Error Analysis andInterlanguage.
Oxford: OxfordUniversity Press.Etienne Cornu, N. Ktibler, F. Bodmer, F.Grosjean, L. Grosjean, N. Lrwy, C.Tschichold & C.
Tschumi.(forthcoming).
Prototype of a secondlanguage writing tool for Frenchspeakers writing in English.
NaturalLanguage Engineering.T.J.
Fitikides.
1963.
Common Mistakes inEnglish.
Harlow: Longman.Sylviane Granger & F. Meunier.
1994.Towards a grammar checker for learnersof English.
In U. Fries, G. Tottie & P.Schneider (eds.
), Creating and UsingEnglish Language Corpora.
Amsterdam:Rodopi.Max Silberztein.
1993.
Dictionnaires elec-troniques et analyse automatique detextes.
Paris: Masson.Georg Thurmair.
1990.
Parsing for gram-mar and style checking.
COLING,90:365-370.Cornelia Tschichold.
1994.
Evaluatingsecond language grammarcheckers.TRANEL (Travauxneuchfitelois de linguistique ), 21: 195-204.Corinne Tschumi, F. Bodmer, E. Cornu, F.Grosjean, L. Grosjean, N. Ktibler, N.Lrwy & C. Tschichold.
1996.
Un logi-ciel qui aide h la correction en anglais.Les langues modernes, 4:28-41.Terry Winograd.
1983.
Language as aCognitive Process: Syntax, Reading,Mass.
: Addison-Wesley.12
