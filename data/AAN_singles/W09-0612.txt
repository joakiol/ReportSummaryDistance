Proceedings of the 12th European Workshop on Natural Language Generation, pages 82?89,Athens, Greece, 30 ?
31 March 2009. c?2009 Association for Computational LinguisticsAn Alignment-capable Microplanner for Natural Language GenerationHendrik Buschmeier, Kirsten Bergmann and Stefan KoppSociable Agents Group, CITEC, Bielefeld UniversityPO-Box 10 01 31, 33501 Bielefeld, Germany{hbuschme, kbergman, skopp}@TechFak.Uni-Bielefeld.DEAbstractAlignment of interlocutors is a well knownpsycholinguistic phenomenon of great rel-evance for dialogue systems in general andnatural language generation in particular.In this paper, we present the alignment-capable microplanner SPUD prime.
Us-ing a priming-based model of interactivealignment, it is flexible enough to modelthe alignment behaviour of human speak-ers to a high degree.
This will allow forfurther investigation of which parametersare important to model alignment and howthe human?computer interaction changeswhen the computer aligns to its users.1 IntroductionA well known phenomenon in dialogue situationsis alignment of the interlocutors.
An illustrativeexample is given by Levelt and Kelter (1982), whotelephoned shops and either asked the question?What time does your shop close??
or the ques-tion ?At what time does your shop close??.
Theanswers were likely to mirror the form of the ques-tion.
When asked ?At what .
.
.
?
?, answers tendedto begin with the preposition ?at?
(e.g., ?At fiveo?clock.?).
Conversely, when asked ?What .
.
.
?
?,answers tended to begin without the preposition(e.g., ?Five o?clock.?).
Similar alignment phenom-ena can be observed in many aspects of speech pro-duction inter alia in syntactic and lexical choice.Pickering and Garrod (2004) present the inter-active alignment model bringing together all align-ment phenomena of speech processing in dialogue.According to this model, human language com-prehension and production are greatly facilitatedby alignment of the interlocutors during conversa-tion.
The process of alignment is explained throughmutual priming of the interlocutors?
linguistic rep-resentations.
Thus, it is automatic, efficient, andnon-conscious.
A stronger claim of the authors isthat alignment ?
in combination with routines anda dialogue lexicon ?
is a prerequisite for fluentspeech production in humans.Alignment effects also occur in human?com-puter interaction.
Brennan (1991) and Braniganet al (in press) present evidence that syntacticstructures and lexical items used by a computerare subsequently adopted by users.
For this reason,alignment is an important concept for natural lan-guage human?computer interaction in general, andfor dialogue systems with natural language gener-ation in particular.
Integrating ideas from the in-teractive alignment model into the microplanningcomponent of natural language generation systemsshould be beneficial for several reasons.
First, mi-croplanning may become more efficient since thesubsets of rules or lexical items in the dialoguelexicon that have been used before can be prefer-entially searched.
Second, due to self-alignment,the output of the system can become more con-sistent and therefore easier to understand for theuser.
Finally, mutual alignment of user and dia-logue system might make the conversation itselfmore natural and, presumably, cognitively morelightweight for the user.In this paper we present a computational modelfor parts of the interactive alignment model thatare particularly important in the context of naturallanguage generation.
We describe how this modelhas been incorporated into the existing SPUD litesystem (Stone et al, 2003; Stone, 2002) to yieldthe alignment-capable microplanner SPUD prime.In Section 2 we describe previous approaches tointegrate alignment into natural language genera-tion.
In Sections 3 and 4, we present our priming-based model of alignment and its implementationin SPUD prime.
In Section 5, we describe resultsof an evaluation on a corpus of task-oriented dia-logue, and in Section 6 we conclude our work anddescribe possible future directions.822 Related WorkComputational modelling is an important method-ology for evaluating and testing psycholinguistictheories.
Thus, it is certainly not a new idea toimplement the interactive alignment model compu-tationally.
Indeed, a call for ?explicit computationalmodels?
is made as early as in the open peer com-mentary on Pickering and Garrod?s (2004) paper.Brockmann et al (2005) and Isard et al (2006)present a ?massive over-generation?
approach tomodelling alignment and individuality in naturallanguage generation.
Their system generates ahuge number of alternative sentences ?
up to3000 ?
and evaluates each of these sentences witha trigram model consisting of two parts: a defaultlanguage model computed from a large corpus anda cache model which is calculated from the user?slast utterance.
The default language model is lin-early interpolated with the cache model, whose in-fluence on the resulting combined language modelis determined by a weighting factor ?
?
[0,1] thatcontrols the amount of alignment the system exhib-its.Purver et al (2006) take a more formal approach.They use an implementation of the Dynamic Syn-tax formalism, which uses the same representationsand mechanisms for parsing as well as for genera-tion of natural language, and extend it with a modelof context.
In their model, context consists of twodistinct representations: a record of the semantictrees generated and parsed so far and a record ofthe transformation actions used for the constructionof these semantic trees.
Re-use of semantic treesand actions is used to model many dialogue phe-nomena in Dynamic Syntax and can also explainalignment.
Thus, the authors declare alignment tobe a corollary of context re-use.
In particular, re-useof actions is assumed to have a considerable influ-ence on alignment in natural language generation.Instead of looking through the complete lexiconeach time a lexical item is chosen, this kind of lex-ical search is only necessary if no action ?
whichconstructed the same meaning in the given con-text before ?
exists in the record.
If such an actionexists, it can simply be re-used, which obviouslyleads to alignment.A completely different approach to alignmentin natural language generation is presented by deJong et al (2008), whose goal is to make a vir-tual museum guide more believable by aligningto the user?s level of politeness and formality.
Inorder to achieve this, the virtual guide analyses sev-eral features of the user?s utterance and generates areply with the same level of politeness and formal-ity.
According to the authors, lexical and syntacticalignment occur automatically because the lexicalitems and syntactic constructions to choose fromare constrained by the linguistic style adopted.Finally, Bateman (2006) advocates another pro-posal according to which alignment in dialogue ispredictable for it is an inherently social activity.Following the social-semiotic view of language,Bateman suggests to model alignment as arisingfrom register and microregister.
More specifically,in his opinion priming of a linguistic representationis comparable with pre-selecting a microregisterthat must be considered when generating an utter-ance in a particular social context.The approaches presented above primarily focuson the linguistic aspects of alignment in naturallanguage generation.
The work of Brockmann etal.
(2005) and Isard et al (2006) concentrates onthe surface form of language, Bateman (2006) seesalignment arising from social-semiotic aspects, andPurver et al (2006) are primarily interested in fit-ting alignment into a formal linguistic framework.In this paper we adopt a more psycholinguistic andcognitive stance on alignment.
Pickering and Gar-rod (2004) propose that low-level priming is thebasic mechanism underlying interactive alignment.Here, we propose that computational modelling ofthese priming mechanisms also opens up an inter-esting and new perspective for alignment in naturallanguage generation.3 A Priming-based Model of AlignmentWe are interested here in those parts of the inter-active alignment model that are most relevant formicroplanning in natural language generation andit is out of our scope to model all the facets anddetails of direct/repetition priming in the alignmentof linguistic representations.
For instance, exacttiming effects are likely to be not even relevant as,in an actual system, it does not matter how manymilliseconds faster the retrieval of a primed lexicalitem is in contrast to the retrieval of an item thatis not primed.
For this reason we adopt an ideal-ised view, in which priming of linguistic structuresresults from two basic activation mechanisms:Temporary activation This kind of activationshould increase abruptly and then decreaseslowly over time until it reaches zero again.83Permanent activation This kind of activationshould increase by a certain quantity and thenmaintain the new level.These two mechanisms of priming are in ac-cordance with empirical findings.
Branigan et al(1999) present evidence for rapid decay of activa-tion of primed syntactic structures, whereas Bockand Griffin (2000) report evidence for their long(er)term activation.
In any case, Reitter (2008) foundboth types of priming in his analysis of severalcorpora, with temporary activation being the moreimportant one.
The assumption that both mechan-isms play a role in dialogue is also supported byBrennan and Clark (1996) whose terminology willbe followed in this paper: temporary priming willbe called ?recency of use effects?
and permanentpriming will be called ?frequency of use effects?.Reitter (2008) assumes the repetition probabilityof primed syntactic structures to depend logarith-mically on the distance between priming and usage.Here, recency of use effects are modelled by amore general exponential decay function, modifiedto meet the needs for modelling activation decay ofprimed structures:ta(?r) = exp(??r?1?
), (1)?r ?
N+; ?
> 0; ta ?
[0,1]ta(?r) is the temporary activation value of a lin-guistic structure depending on the distance ?rbetween the current time T and the time r at whichthe structure was primed.
The slope of the functionis determined by the parameter ?
.
Additionally, thefunction is shifted right in order to yield an activa-tion value of 1 for ?r = 1.
This shift is due to theassumption of discrete time steps with a minimaldistance of 1.
A plot of ta(?r) with different valuesfor ?
is given in Figure 1a.Using exponential decay to model temporary ac-tivation appears to be a sensible choice that is oftenused to model natural processes.
The advantage ofthis model of temporary activation lies in its flexib-ility.
By changing the slope parameter ?
, differentempirical findings as well as variation among hu-mans can be modelled easily.Next, a mathematical model for frequency of useeffects is needed.
To prevent that frequency effectslead to an ever increasing activation value, a max-imum activation level exists.
This is also found inReitter?s (2008) corpus studies, which indicate that00.20.40.60.811  3  5  7  9  11  13  15TemporaryActivationta(?r)Recency Distance  ?r(a)?
= 12481600.20.40.60.811  3  5  7  9  11  13  15Permanent Activationpa(f)Frequency Counter f(b)?
= 124816Figure 1: Plots of the mathematical functions thatmodel recency and frequency effects.
Plot (a) dis-plays temporary activation depending on the re-cency of priming.
Plot (b) shows permanent activ-ation depending on the frequency count.
Both areshown for different values of the slope parameter?
respectively ?
.the frequency effect is inversely connected to therecency effect.
Here, we model recency effects witha general exponential saturation function, modifiedto meet the requirements for modelling permanentactivation of linguistic structures:pa( f ) = 1?
exp(?f ?1?
), (2)f ?
N+; ?
> 0; pa ?
[0,1]The most important point to note here is that thepermanent activation value pa( f ) is not a functionof time but a function of the frequency-counter fattached to each linguistic structure.
Whenever astructure is primed, its counter is increased by thevalue of 1.
Again, the slope of the function is de-termined by the parameter ?
and the function is84shifted right in order to get an activation value of0 for f = 1.
A plot of equation (2) with differentslope parameters is given in Figure 1b.
Similar tothe advantages of the model of temporary activa-tion, this model for frequency effects is very flex-ible so that different empirical findings and humanindividuality can be expressed easily.Now, both priming models need to be combinedfor a model of alignment.
We opted for a weightedlinear combination of temporary and permanentactivation:ca(?r, f ) = ?
?
ta(?r)+(1??)
?
pa( f ), (3)0?
?
?
1; ca ?
[0,1]Different values of ?
allow different forms of align-ment.
With a value of ?
= 0.5 recency and fre-quency effects are equally important, with a valueof ?
= 1 alignment depends on recency only, andwith a value of ?
= 0 alignment is governed solelyby frequency.
Being able to adjust the influenceof the different sorts of priming on alignment iscrucial as it has not yet been empirically determ-ined to what extent recency and frequency of useaffect alignment (in Section 5.2 we will exploit thisflexibility for matching empircial data).In contrast to the models of alignment presentedin Section 2, the computational alignment modelpresented here will not only consider alignmentbetween the interlocutors (interpersonal- or other-alignment), but also alignment to oneself (intra-personal- or self-alignment).
Pickering et al (2003)present results from three experiments which sug-gest self-alignment to be even more important thanother-alignment.
In our model, self-alignment isaccounted for with the same priming-based mech-anisms.
To this end, four counters are attached toeach linguistic structure:?
?rs: recency of use by the system itself?
?ro: recency of use by the interlocutor?
fs: frequency of use by the system itself?
fo: frequency of use by the interlocutorThe overall activation value of the structure isa linear combination of the combined activationvalue ca(?rs, fs) and the combined activation valueca(?ro, fo) from equation (3):act(?rs, fs,?ro, fo) =?
?
(?
?
ca(?rs, fs)+(1??)
?
ca(?ro, fo)),(4)0?
?
,?
?
1; act ?
[0,1]Again, by changing the factor ?
, smooth interpola-tion between pure self-alignment (?
= 1) and pureother-alignment (?
= 0) is possible, which can ac-count for different empirical findings or humanindividual differences.
Furthermore, the strengthof alignment is modelled with a scaling factor ?
,which determines whether alignment is consideredduring generation (?
> 0) or not (?
= 0).4 The Alignment-capable MicroplannerSPUD primeThe previously described priming-based model ofalignment has been implemented by extendingthe integrated microplanning system SPUD lite(Stone, 2002).
SPUD lite is a lightweight Prologre-implementation of the SPUD microplanning sys-tem (Stone et al, 2003) based on the context-freetree rewriting grammar formalism TAGLET.
Notonly the microplanner itself, but also the linguisticstructures (the initial TAGLET trees) are represen-ted as Prolog clauses.SPUD lite carries out the different microplan-ning tasks (lexical choice, syntactic choice, refer-ring expression generation and aggregation) at onceby treating microplanning as a search problem.
Dur-ing generation it tries to find an utterance which isin accordance with the constraints set by its input(a grammar, a knowledge base and a query).
This isdone by searching the search space spanned by thelinguistic grammar rules and the knowledge baseuntil a goal state is found.
Non-goal search statesare preliminary utterances that are extended by onelinguistic structure in each step until a syntacticallycomplete utterance is found which conveys all thespecified communicative goals.
Since this searchspace is large even for relatively small grammars,a heuristic greedy search strategy is utilised.Our alignment-capable microplanner SPUDprime extends SPUD lite in several ways.
First, wealtered the predicate for the initial TAGLET treesby adding a unique identifier ID as well as countersfor self/other-recency/frequency values (rs, fs, roand fo; see Section 3).
The activation value of aninitial tree is then calculated with equation (4).Furthermore, we have created a mechanism thatenables SPUD lite to change the recency and fre-quency information attached to the initial trees on-line during generation.
This is done in three stepswith the help of Prolog?s meta-programming cap-abilities: Firstly, the clause of a tree is retrieved85from the knowledge base.
Secondly, it is retrac-ted from the knowledge base.
Finally, the clauseis (re-)asserted in the knowledge base with up-dated recency and frequency information.
As awelcome side effect of this procedure, primed ini-tial trees are moved to the top of the knowledgebase and ?
since Prolog evaluates clauses and factsin the order of their appearance in the knowledgebase ?
they can be accessed earlier than unprimedinitial trees or initial trees that were primed longerago.
Thus, in SPUD prime recency of priming dir-ectly influences the access of linguistic structures.Most importantly, the activation values of the ini-tial trees are considered during generation.
Thus, inaddition to the evaluation measures used by SPUDlite?s heuristic state evaluation function, the meanactivation valueact(S) =?Ni=1 actti(?rsti , fsti ,?roti , foti )Nof the N initial trees {t1, .
.
.
, tN} of a given searchstate S is taken into account as a further evaluationmeasure.
Hence, when SPUD prime evaluates (oth-erwise equal) successor search states, the one withthe highest mean activation value is chosen as thenext current state.5 EvaluationIn order to find out whether our priming-basedalignment model and its implementation work asintended, we evaluated SPUD prime on a corpusthat was collected in an experiment designed toinvestigate the alignment behaviour of humans ina controlled fashion (Wei?
et al, 2008).
The partof the corpus that we used consists of eight recor-ded and transcribed dialogues between two inter-locutors that play the ?Jigsaw Map Game?, a taskin which different objects have to be placed cor-rectly on a table.
Speakers take turns in explainingeach other where to place the next object in re-lation to the objects that are already on the table.Each speaker has to learn a set of name?object rela-tions before the game, such that both use the samenames for all but three objects.
Due to this precon-dition, both speakers use the same lexical referringexpressions for most objects and the speaker?s lex-ical alignment behaviour for the differently namedobjects can be observed easily.In our evaluation, we concentrate on the gener-ation of nouns by simulating the uses of the threedifferently learned nouns in the eight dialoguesfrom the perspective of all sixteen interlocutors.In each test, SPUD prime plays the role of oneof the speakers talking to a simulated interlocutorwho behaves exactly as in the real experiment.With this test setup we examined, first, how wellSPUD prime can model the alignment behaviourof a real speaker in a real dialogue context and,second, whether our model is flexible enough toconsistently emulate different speakers with differ-ent alignment behaviour.In order to find the best model (i.e., the bestparameter set {?,?
,?,?})
for each speaker, wesimulated all tests with all parameter combinationsand counted the number of mismatches betweenour model?s choice and the real speaker?s choice.To make this exhaustive search possible, we limitthe set of values for the parameters ?
and ?
to{1,2,4,6,8,10,14,18,24,30} and the set of valuesfor the parameters ?
and ?
to {0,0.1,0.2, ...,1},resulting in a total of 112?102 = 12100 differentparameter sets.
Since we want to investigate align-ment, ?
is constantly set to 1.5.1 An Illustrative ExampleTo illustrate our evaluation method, we first presentand discuss the simulation of one particular dia-logue (from the Jigsaw Map Game corpus) fromthe perspective of participant (A).
Before the exper-iment started, both interlocutors learned the name?object relations ?Raute?
(rhombus), ?Ring?
(ring),?Schraube?
(bolt) and ?Wu?rfel?
(cube), additionallyparticipant (A) learned ?Spielfigur?
(token), ?Ball?
(sphere) and ?Block?
(cuboid) and participant (B)learned ?Ma?nnchen?
(token), ?Kugel?
(sphere) and?Klotz?
(cuboid).
In our simulation, we focus on theuse of the differently learned names (the targets)and not on the other names (non-targets).
Table 1shows the sequence of target nouns as they oc-curred in the real dialogue (non-targets omitted).For each parameter set {?,?
,?,?}
the dialogueis simulated in the following way:?
When participant (A) used a referring non-target noun in the dialogue, self-priming ofthe corresponding rule(s) in SPUD prime?sknowledge base is simulated (i.e., the recencyand frequency counters are increased).?
When participant (A) used a referring targetnoun in the dialogue, SPUD prime is queriedto generate a noun for the target object.
Thenit is noted whether the noun actually generated86B: der Klotz 14 A: der Klotz1 A: die Spielfigur 15 A: die Kugel2 A: der Klotz 16 A: der KlotzB: das Ma?nnchen B: der KlotzB: der Klotz B: die Kugel3 A: die Spielfigur B: der KlotzB: das Ma?nnchen 17 A: der Klotz4 A: das Ma?nnchen B: das Ma?nnchen5 A: das Ma?nnchen B: der Klotz6 A: das Ma?nnchen 18 A: das Ma?nnchen7 A: das Ma?nnchen 19 A: der Klotz8 A: das Ma?nnchen B: das Ma?nnchenB: das Ma?nnchen 20 A: der Ball9 A: das Ma?nnchen 21 A: das Ma?nnchen10 A: der Ball B: der BallB: der Ball B: das Ma?nnchen11 A: der Ball 22 A: die Kugel12 A: der Ball 23 A: der BallB: die Kugel B: der KlotzB: das Ma?nnchen 24 A: der Ball13 A: der Ball B: der KlotzB: die Kugel 25 A: der KlotzTable 1: Sequence of referring target nouns used byparticipants (A) and (B) in our example dialogue.is the noun used in the actual dialogue (match)or not (mismatch).?
When participant (B) used a referring noun(target or non-target), priming of the corres-ponding rule(s) in SPUD prime?s knowledgebase is simulated.The evaluation measure for a specific parameterset is the number of mismatches it produces whensimulating a dialogue.
Thus the parameter set (orrather sets) which produce the least number of mis-matches are the ones that best model the particularspeaker under consideration.
For participant (A)of our example dialogue the distribution of para-meter sets p producing m mismatches is shown inTable 2.
Four parameter sets produce only two mis-matches (in phrase 15 and 22; cf.
Table 1) and thusour priming-based alignment model can accountfor 92% of the target nouns produced by speaker(A).
However, it must be noted that these two mis-matches occur at points in the dialogue where thealignment behaviour of (A) is not straightforward.At target noun 15, both interlocutors have alreadyused the name ?Ball?
and then both switch to ?Ku-gel?.
The mismatch at target 22 is a special case: (A)used ?Kugel?
and immediately corrected himself to?Ball?, the name he learned prior to the experiment.It seems as if the task instruction, to use the learnednouns, suddenly became prevalent.m 0 1 2 3 4 5# p 0 0 4 833 3777 2248m 6 7 8 9 10 .
.
.# p 3204 1105 478 148 294 0Table 2: Number of parameter sets p leading to mmismatches for participant (A) in dialogue 7.5.2 Simulation ResultsTo evaluate our alignment-capable microplanner,we simulated the noun production for each of theinterlocutors from the experiment.
One dialoguehas been excluded from the data analysis as thedialogue partners used nouns that none of them hadlearned in the priming phase.
For each of the re-maining 14 interlocutors we varied the parameters?
, ?
, ?
and ?
as described above to identify thoseparameter set(s) which result in the least numberof mismatches.Each interlocutor produced between 18 and 32target nouns (N=14, M=23.071, SD=3.936).
Oursimulation runs contain between 0 and 19 mis-matches overall (N=169400, M=6.35, SD=3.398).The minimal number of mismatches for eachspeaker simulation ranges between 0 and 6 (N=14,M=2.286, SD=1.684).
That is, our model can sim-ulate a mean of 89.9% of all target nouns (N=14,M=.899, Min=.667, Max=1.000, SD=.082), whichis an improvement of 24.6% on the baseline con-dition (alignment switched off), where 65.3% ofthe target nouns are generated correctly (N=14,M=.653, Min=.360, Max=1.000, SD=.071).
Asalready illustrated in Section 5.1, mismatches typic-ally occur at points in the dialogue where the align-ment behaviour of the interlocutor is not straight-forward.As displayed in Table 3 the parameter assign-ments resulting in least mismatches differ consid-erably from speaker to speaker.
However, there aresome remarkable trends to be observed in the data.As concerns the parameter ?
, which determinesthe combination of self- and other-alignment, themajority of values are in the upper range of theinterval [0,1].
For 8 of 14 speakers the mean isabove 0.7 with relatively low standard deviations.Only for one speaker (P13) the mean ?
is below0.3.
Thus, the parameter values indicate a consider-able tendency toward self-alignment in contrast toother-alignment.For the parameter ?
that interpolates betweenrecency and frequency effects of priming, the res-87?
?
?
?m # p M SD M SD M SD M SDP13 2 4 3.0 1.155 19.5 9.14 .1 .0 .3 .0P14 1 72 5.53 1.52 14.32 9.61 .819 .040 .901 .108P17 1 200 1.66 .823 12.94 9.529 .353 .169 .955 .069P18 3 2445 15.37 8.758 10.98 9.76 .597 .211 .706 .236P19 0 4321 11.81 9.492 11.01 8.929 .824 .148 .387 .291P20 2 8 1.0 .0 15.75 9.285 .737 .052 .388 .146P23 6 987 6.85 6.681 12.08 9.354 .331 .374 .4 .33P24 3 256 12.95 9.703 13.63 8.937 .537 .201 .468 .298P39 5 1 1.0 .0 2.0 .0 .9 .0 .8 .0P40 0 3504 12.08 9.33 10.30 8.753 .843 .147 .343 .282P41 2 609 11.37 8.475 15.34 8.921 .770 .106 .655 .213P42 3 30 6.0 1.486 17.53 9.016 .783 .059 .760 .122P47 2 326 13.75 7.794 13.53 9.508 .772 .095 .816 .166P48 2 2478 12.87 9.545 10.74 8.538 .764 .175 .166 .148Table 3: Mean parameter values for those simulation runs which result in a minimal number of mismatchesfor each speaker.ults are less revealing.
For two speaker simulations(P13 and P48) the mean ?
is 0.3 or lower, for an-other four speaker simulations the mean ?
is above0.7.
That is, our model produces good matching be-haviour in adopting different alignment strategies,depending either primarily on frequency or recency,respectively.
All other simulations, however, arecharacterised by a mean ?
in the medium rangealong with a relatively high standard deviation.6 ConclusionIn this paper, we introduced a priming-based modelof alignment which focusses more on the psycho-linguistic aspects of interactive alignment and mod-els recency and frequency of use effects ?
as pro-posed by Reitter (2008) and Brennan and Clark(1996) ?
as well as the difference between intraper-sonal and interpersonal alignment (Pickering et al,2003; Pickering and Garrod, 2004).
The presentedmodel is fully parameterisable and can account fordifferent empirical findings and ?personalities?.
Ithas been implemented in the SPUD prime micro-planner which activates linguistic rules by changingits knowledge base on-line and considers the ac-tivation values of those rules used in constructingthe current utterance by using their mean activationvalue as an additional feature in its state evaluationfunction.We evaluated our alignment model and its im-plementation in SPUD prime on a corpus of task-oriented dialogue collected in an experimentalsetup especially designed for alignment research.The results of this evaluation show that our priming-based model of alignment is flexible enough to sim-ulate the alignment behaviour of different humanspeakers (generating target nouns) in the experi-mental setting.
It should be noted, however, thatour model tries to give a purely mechanistic ex-planation of lexical and syntactic choice and thatit, therefore, cannot explain alignment phenomenathat are due to social factors (e.g., politeness, rela-tionship, etc.
), audience design or cases, in which aspeaker consciously decides whether to align or not(e.g., whether to use a word or its synonym).
Whilethe evaluation has shown that our model can repro-duce human alignment behaviour to a high degree,it remains to be investigated which influence eachparameter exerts and how exactly the parametersvary across individual speakers.Nevertheless, the development of the alignment-capable microplanner is only one step in the dir-ection of an intuitive natural language human?computer interaction system.
In order to reach thisgoal, the next step is to combine SPUD prime witha natural language understanding system, whichshould ideally work with the same linguistic rep-resentations so that the linguistic structures usedby the interlocutor could be primed automatically.This work is underway.Furthermore, user studies should be carriedout in order to evaluate SPUD prime in a moresophisticated way.
Branigan et al (in press) foundthat human?computer alignment was even strongerthan human?human alignment.
But how wouldthe alignment behaviour of human interlocutorschange if the computer they are speaking to alsoaligns to them?
Further, would integration of analignment-capable dialogue system into a computerinterface make the interaction more natural?
Andwould an embodied conversational agent appear88more resonant and more sociable (Kopp, 2008) ifit aligned to users during conversation?
The workpresented here provides a starting point for theinvestigation of these questions.Acknowledgements ?
This research is supportedby the Deutsche Forschungsgemeinschaft (DFG) inthe Center of Excellence in ?Cognitive InteractionTechnology?
(CITEC) as well as in the Collabor-ative Research Center 673 ?Alignment in Commu-nication?.
We also thank Petra Wei?
for makingthe ?Jigsaw Map Game?
corpus available and threeanonymous reviewers for their helpful comments.ReferencesJohn A. Bateman.
2006.
A social-semiotic view ofinteractive alignment and its computational instanti-ation: A brief position statement and proposal.
InKerstin Fischer, editor, How People Talk to Com-puters, Robots and Other Artificial CommunicationPartners, SFB/TR 8 Report No.
010-09/2006, pages157?170, Bremen, Germany.J.
Kathryn Bock and Zenzi M. Griffin.
2000.
The per-sistence of structural priming: Transient activationor implicit learning?
Journal of Experimental Psy-chology: General, 129(2):177?192.Holly P. Branigan, Martin J. Pickering, and Alexan-dra A. Cleland.
1999.
Syntactic priming in writtenproduction: Evidence for rapid decay.
PsychonomicBulletin & Review, 6(4):635?640.Holly P. Branigan, Martin J. Pickering, Jamie Pearson,and Janet F. McLean.
in press.
Linguistic alignmentbetween people and computers.
Journal of Pragmat-ics.Susan E. Brennan and Herbert H. Clark.
1996.Conceptual pacts and lexical choice in conversa-tion.
Journal of Experimental Psychology: Learn-ing, Memory, and Cognition, 22(6):1482?1493.Susan E. Brennan.
1991.
Conversation with andthrough computers.
User Modeling and User-Adapt-ed Interaction, 1(1):67?86.Carsten Brockmann, Amy Isard, Jon Oberlander, andMichael White.
2005.
Modelling alignment for af-fective dialogue.
In Proc.
of the Workshop on Adapt-ing the Interaction Style to Affective Factors at the10th Int.
Conf.
on User Modeling.Markus A. de Jong, Marie?t Theune, and Dennis Hofs.2008.
Politeness and alignment in dialogues witha virtual guide.
In Proc.
of the 7th Int.
Conf.
onAutonomous Agents and Multiagent Systems, pages207?214.Amy Isard, Carsten Brockmann, and Jon Oberlander.2006.
Individuality and alignment in generated dia-logues.
In Proc.
of the 4th Int.
Natural LanguageGeneration Conf., pages 25?32.Stefan Kopp.
2008.
From communicators to reson-ators ?
Making embodied conversational agents so-ciable.
In Proc.
of the Speech and Face to FaceCommunication Workshop in Memory of ChristianBeno?
?t, pages 34?36.Willem J. M. Levelt and Stephanie Kelter.
1982.
Sur-face form and memory in question answering.
Cog-nitive Psychology, 14(1):78?106.Martin J. Pickering and Simon Garrod.
2004.
Towarda mechanistic psychology of dialogue.
Behavioraland Brain Sciences, 27(2):169?226.Martin J. Pickering, Holly P. Branigan, and Janet F.McLean.
2003.
Dialogue structure and the activ-ation of syntactic information.
In Proc.
of the 9thAnnual Conf.
on Architectures and Mechanisms forLanguage Processing, page 126.Matthew Purver, Ronnie Cann, and Ruth Kempson.2006.
Grammars as parsers: Meeting the dialoguechallenge.
Research on Language and Computation,4(2?3):289?326.David Reitter.
2008.
Context Effects in Language Pro-duction: Models of Syntactic Priming in DialogueCorpora.
Ph.D. thesis, University of Edinburgh.Matthew Stone, Christine Doran, Bonnie Webber, To-nia Bleam, and Martha Palmer.
2003.
Microplan-ning with communicative intentions: The SPUD sys-tem.
Computational Intelligence, 19(4):311?381.Matthew Stone.
2002.
Lexicalized grammar 101.
InProc.
of the ACL-02 Workshop on Effective Toolsand Methodologies for Teaching Natural LanguageProcessing and Computational Linguistics, pages77?84.Petra Wei?, Thies Pfeiffer, Gesche Schaffranietz, andGert Rickheit.
2008.
Coordination in dialog: Align-ment of object naming in the Jigsaw Map Game.
InProc.
of the 8th Annual Conf.
of the Cognitive Sci-ence Society of Germany, pages 4?20.89
