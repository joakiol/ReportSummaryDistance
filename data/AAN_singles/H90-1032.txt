Session 7: Speech Recognition IMitch Weintraub, ChairSRI International333 Ravenswood AveEK 180Menlo Park, CA 94025This session presented a number of interesting papers ona wide range of topics concerning speech recognition: twopapers on noise robust signal processing algorithms, onepaper on approaches tolarge vocabulary continuous speechrecognition, two papers on algorithms for reducing com-putation time, one paper on adding new words to thevocabulary, and one paper on theoretical issues concerningvocabulary independent recognition.The first paper, presented by Harvey Silverman,presented an algorithm for talker location using a linearmicrophone array.
He advocated an algorithm calledStochastic Region Contraction for nonlinear optimizationproblems, and claimed it was very successful inmicrophone array work.
Results were presented for deter-mining the location of a single talker using a cross-correlation hyperbolic-fit algorithm.
In the discussion fol-lowing the paper, the issue of how to evaluate microphonearrays was raised, and it was suggested that improvementto speech recognition accuracy be used as the e valuationmetric.In the second paper, presented by Alehandro Acero, anew algorithm for joint noise suppression and spectral-tiltcompensation was presented.
The algorithm uses the EMalgorithm for finding the ML solution using incompletedata (channel and noise characteristics).
Recognition rateswere presented for a number of simultaneous recordingsusing different microphone pairs.
During the discussion,he explained that although some microphone characteristicsare sensitive to the relative location of the talker, this isdealt with by reestimating the transfer function indepen-dently for each utterance.In the third paper, presented by Laurence Gillick ofDragon, described their Phoneme-in-Context (PIC) model-ing approach for large-vocabulary continuous speechrecognition.
He described how each PIC is made up from 1to 6 "phonemic segments," with a maximum of 2000phonemic segments used to consguct all 30,000 PIC's.
Healso said that stress and duration were an important part ofeach PIC.
The discussion focused on how many PIC'swere necessary for modeling eneral English, and how thePIC differs from the commonly used triphone: the maindifference being that Dragon uses Bayesian smoothing.The fourth paper was also from Dragon and focused ontheir rapid match algorithm.
Laurence Gillick explainedthat the signal processing consists of 3 smooth flamesspaced over a 240 millisecond window, and was used tofind collections of words whose beginnings are acousticallysimilar.
Each of the features are assumed independentLaplacian distributions, and a special clustering algorithmis used for clustering the probability distributions to reducecomputation time.
There was some discussion of how thisalgorithm compared to IBM's fast match, but not enoughdetails were known about either system to make a detailedcomparison possible.The fifth paper, presented by Vasilios Digalakis,focused on fast search algorithms for use in the stochasticsegment model (SSM).
He presented a new algorithm forjoint segmentation a d recognition usin g a variant of thesplit and merge algorithm.
They reported phone recog-nition results on the TIMIT corpus using context independ-ent SSM techniques that are similar to other reportedcontext-dependent results.
They were able to significantlyreduce the computation of the SSM; however the resultingsplit and merge algorithm required over 100 iterations inprocessing each sentence.
The discussion focused on theirplans to extend this work to word and sentence r cognitiontasks, and whether there was an agre ed upon conventionfor training/testing sets and scoring algorithms using theTIMIT corpus (apparently not).
It was suggested that NISTdefine a standard for training and testing using this corpus.The sixth paper, presented by Michael Picheny,described IBM's approach to adding new words to the dic-tionary.
The problem was formulated in a probabilisticframework, where the goal is to find the baseform string tomaximize the probability given the language model andacoustic observations of that word.
He summarized theirapproach to using decision trees for generating spelling-to-sound rules, and the difficulty of generating consistentbaseforms.
The discussion focused on the need for thisapproach (versus a large dictionary), and how users of theTangora system pronounce words strangely, especiallyproper names.
He also stressed the need for baseforms sothat these words could be incorporated into the fast matchalgorithm.The seventh and last paper presented in this session waspresented by Doug Paul.
He described how the traininglanguage models affects the acoustic models used byspeech recognizers, and how this bias is illustrated by theuse of corrective training with one language model and149testing with a different language model.
He pointed outthat current resource management (RM) corpus is a verypoor source of acoustic information for porting to newvocabularies, as illustrated by the CMU experiments onvocabulary independence.
He then presented a proposalfor a new corpus of read speech based on the ACL/DCIcorpus.
Part of the discussion focused on the ability todevelop language models from small task-related data sets,rather than from large non-task related texts.
The otherpart of the discussion focused on understanding what theperplexity of RM task is.150
