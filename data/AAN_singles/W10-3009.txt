Proceedings of the Fourteenth Conference on Computational Natural Language Learning: Shared Task, pages 64?69,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsHedge Detection Using the RelHunter Approach?Eraldo R. Fernandes?
and Carlos E. M. Crestana?
and Ruy L.
Milidiu?
?Departamento de Informa?tica, PUC-RioRio de Janeiro, Brazil{efernandes, ccrestana, milidiu}@inf.puc-rio.brAbstractRelHunter is a Machine Learning basedmethod for the extraction of structured in-formation from text.
Here, we apply Rel-Hunter to the Hedge Detection task, pro-posed as the CoNLL-2010 Shared Task1.RelHunter?s key design idea is to modelthe target structures as a relation over enti-ties.
The method decomposes the originaltask into three subtasks: (i) Entity Iden-tification; (ii) Candidate Relation Gener-ation; and (iii) Relation Recognition.
Inthe Hedge Detection task, we define threetypes of entities: cue chunk, start scopetoken and end scope token.
Hence, theEntity Identification subtask is further de-composed into three token classificationsubtasks, one for each entity type.
Inthe Candidate Relation Generation sub-task, we apply a simple procedure to gen-erate a ternary candidate relation.
Each in-stance in this relation represents a hedgecandidate composed by a cue chunk, astart scope token and an end scope to-ken.
For the Relation Recognition sub-task, we use a binary classifier to discrim-inate between true and false candidates.The four classifiers are trained with theEntropy Guided Transformation Learningalgorithm.
When compared to the otherhedge detection systems of the CoNLLshared task, our scheme shows a competi-tive performance.
The F -score of our sys-tem is 54.05 on the evaluation corpus.?
This work is partially funded by CNPq and FAPERJgrants 557.128/2009-9 and E-26/170028/2008.?
Holds a CNPq doctoral fellowship and has financialsupport from IFG, Brazil.
?Holds a CAPES doctoral fellowship.
?Holds a CNPq research fellowship.1Closed Task 2: detection of hedge cues and their scopes.1 IntroductionHedges are linguistic devices that indicate un-certain or unreliable information within a text.The detection of hedge structures is important formany applications that extract facts from textualdata.
The CoNLL-2010 Shared Task (Farkas etal., 2010) is dedicated to hedge detection.A hedge structure consists of a cue and a scope.In Figure 1, we present a sentence with two hedgeinstances.
The hedge cues are highlighted andtheir scopes are delimited by brackets.
The hedgecue comprises one or more keywords that indi-cate uncertainty.
The hedge scope is the uncertainstatement which is hedged by the cue.
The scopealways includes the corresponding cue.
[ They indicate that [ the demonstrationis possible in this context ] and there is acorrelation ]Figure 1: Sentence with two hedge instances.Over the last two decades, several Computa-tional Linguistic problems have been successfullymodeled as local token classification tasks (Brill,1995; Milidiu?
et al, 2009).
Nevertheless, theharder problems consist in identifying complexstructures within a text.
These structures comprisemany tokens and show non local token dependen-cies.Phrase chunking (Sang and Buchholz, 2000) isa task that involves structure recognition.
Pun-yakanok and Roth decompose this task intofour subtasks, that are sequentially solved (Pun-yakanok and Roth, 2001).
They use HiddenMarkov Models for the first three subtasks.
Theyfind out that task decomposition improves theoverall token classification modeling.Clause identification (Sang and De?jean, 2001)is another task that requires structure recognition.As clauses may embed other clauses, these struc-64tures involve stronger dependencies than phrasechunks.
Carreras et al propose an approach thatextends Punyakanok and Roth?s previous work(Carreras et al, 2002).
Their system comprisescomplex methods for training and extraction, inorder to exploit the specific dependency aspects ofclause structures.Phrase Recognition is a general type of task thatincludes both phrase chunking and clause iden-tification.
Carreras et al propose the Filtering-Ranking Perceptron (FRP) system for this generaltask (Carreras et al, 2005).
The FRP task model-ing is strongly related to previous proposals (Pun-yakanok and Roth, 2001; Carreras et al, 2002).However, it simultaneously learns to solve threesubtasks.
FRP is very effective, although compu-tationally expensive at both training and predictiontime.
Currently, FRP provides the best performingclause identification system.In Morante and Daelemans (2009), the hedgedetection task is solved as two consecutive classi-fication tasks.
The first one consists of classify-ing the tokens of a sentence as hedge cues usingthe IOB tagging style.
The second task consists ofclassifying tokens of a sentence as being the startof a hedge scope, the end of one, or neither.
Theresult of those two tasks is combined using a set ofsix rules to solve the hedge detection task.Here, we describe RelHunter, a new methodfor the extraction of structured information fromtext.
Additionally, we apply it to the Hedge Detec-tion task.
RelHunter extends the modeling strat-egy used both in Carreras et al (2005) and Pun-yakanok et al (2001).
Other applications of thismethod are presented in Fernandes at al.
(2009b;2010).The remainder of this text is organized as fol-lows.
In Section 2, we present an overview of theRelHunter method.
The modeling approach forthe Hedge Detection task is presented in Sections3 and 4.
The experimental findings are depictedand discussed in Section 5.
Finally, in Section 6,we present our final remarks.2 RelHunter OverviewThe central idea of RelHunter is to model the tar-get structures as a relation over entities.
To learnhow to extract this relation from text, RelHunteruses two additional schemes: task decompositionand interdependent classification.We decompose the original task into three sub-tasks: (i) Entity Identification; (ii) Candidate Re-lation Generation; and (iii) Relation Recognition.In Figure 2, we illustrate the application of Rel-Hunter to hedge detection.
We use the sentenceintroduced by Figure 1.Entity Identification is a local subtask, in whichsimple entities are detected without any concernabout the structures they belong to.
The outcomeof this subtask is the entity set.
For instance, forhedge detection, we identify three types of enti-ties: hedge cues, tokens that start a scope and to-kens that end a scope.The second subtask is performed by a simpleprocedure that generates the candidate relationover the entity set.
This relation includes true andfalse candidates.
This procedure considers do-main specific knowledge to avoid the generationof all possible candidates.
In the hedge detectiontask, we define the candidate relation as the setof entity triples that comprise a hedge cue, a startscope token and an end scope token, such that thestart token does not occur after the end token andthe hedge cue occurs between the start and the endtokens.The Relation Recognition subtask is a binaryclassification problem.
In this subtask, we dis-criminate between true and false candidates.
Theoutput relation produced in this subtask containsthe identified hedge instances.3 Hedge Detection using RelHunterIn this section, we detail the RelHunter methodand describe its application to hedge detection.3.1 Entity IdentificationWe consider three specific entity types: cue chunk,start scope token, and end scope token.
We divideentity identification into three token classificationtasks, one for each entity type.
Thus, we use theoriginal corpus to train three classifiers.The cue chunk subtask is approached as a to-ken classification problem by using the IOB tag-ging style.
The token tag is defined as follows: I,when it is inside a hedge cue; O, when it is outsidea hedge cue; and B, when it begins a hedge cueimmediately after a distinct cue.
As the baselineclassifier, we use the Cue Dictionary proposed inMorante and Daelemans (2009), classifying eachoccurrence of those words as a cue.The start scope and end scope subtasks aremodeled as binary token classification problems.65Figure 2: Diagram of the RelHunter method.As the baseline classifier for the start scope sub-task, we assign the first token of each hedge cue asthe start of a scope.We have two baseline classifiers for the endscope subtask: END and END-X.
The END sys-tem classifies as an end token the second to thelast token of each sentence that contains a cue.Due to the frequent occurrence of parenthesizedclauses at the end of sentences in full articles, theEND-X system extends the END system with anadditional operation.
It reassigns an end scope tag,from a close parentheses token, to the token beforeits corresponding open parentheses.3.2 Candidate Relation GenerationWe define as the candidate hedge relation the setof entity triples that comprise a hedge cue, a startscope token and an end scope token, such that thestart token does not occur after the end token andthe hedge cue occurs between the start and the endtokens.3.3 Relation RecognitionWe train a binary classifier to discriminate be-tween positive and negative candidates within thecandidate relation.
This classifier is trained on therelation dataset, which is built by a general pro-cedure.
This dataset contains an entry for eachcandidate.
For each candidate, we generate twofeature sets: local features and global features.The local features include local informationabout each candidate entity, namely: cue chunk,start scope token and end scope token.
These fea-tures are retrieved from the original corpus.
Forthe start and end tokens, we use all their features inthe original corpus.
For the cue chunk, we use thefeatures of the rightmost token within the chunk.The global features follow Carreras et al(2002).
These features are generated by consid-ering the whole sentence where the candidate liesin.
They inform about the occurrence of relevantelements within sentence fragments.
We consideras relevant elements the three entity types and ver-bal chunks.For each candidate entity, we consider threefragments.
The first one contains all the tokens be-fore the entity.
The second, all the entity tokens,and the third all the tokens after the entity.
Simi-larly, for the whole candidate, we have three morefragments: one containing all the tokens before thecandidate, another containing all the candidate to-kens, and the third one containing all the tokensafter the candidate.
Thus, there are 12 fragmentsfor each candidate, three for each entity plus threefor the whole candidate.For each relevant element and fragment, wegenerate two global features in the relation dataset:a flag indicating the occurrence of the elementwithin the fragment and a counter showing its fre-quency.The relation dataset has km local features and6r(k + 1) global features, where k is the relationcardinality (number of entities), m is the numberof features in the original corpus, and r is the num-ber of relevant elements.Our current RelHunter implementation uses theEntropy Guided Transformation Learning (ETL)as its learning engine (Milidiu?
et al, 2008; dosSantos and Milidiu?, 2009).
For instance, we trainfour ETL based classifiers: one for each EntityIdentification subtask and one for the RelationRecognition subtask.
In the next section, we de-scribe an important issue explored by the ETL al-gorithm.664 Interdependent ClassificationThe input to the Relation Recognition subtask isthe candidate relation, i.e., a set of hedge candi-dates.
The corresponding classifier must discrim-inate positive from negative candidates.
However,identifying one candidate as positive implies thatsome other candidates must be negatives.
This in-volves a special modeling issue: interdependentclassification.
The learning engine may explorethese dependencies, when building the classifierfor this subtask.Interdependent classification is usually assumedfor neighboring examples.
When the learningmodel adopts a Markovian Property, then theneighborhood is given by a context window.
Thisis the case for Markovian Fields such as HiddenMarkov Models.
Another model that also exploresinterdependent examples is ETL.ETL is a very attractive modeling tool and hasbeen applied to several classification tasks (Mi-lidiu?
et al, 2008; dos Santos and Milidiu?, 2009;Fernandes et al, 2009a; Fernandes et al, 2010).ETL uses an annotated corpus, where the corre-sponding class is attached to each example.
Thecorpus is partitioned into segments.
Each segmentis a sequence of examples.
Examples within thesame segment are considered dependent.
Con-versely, examples within different segments areconsidered independent.
Moreover, an exampleclassification depends only on the features of theexamples from its corresponding context window.Hence, to apply ETL we need to provide threemodeling ingredients: segment definition, exam-ple ordering within a segment and the context win-dow size.
Given that, classification dependenciesare explored by the ETL classifier.
Hence, Rel-Hunter uses ETL as its learning engine.We include in the same segment the hedge can-didates that have the same cue and start scope to-kens.
Within a segment, we order the candidatesby the order of the end token in the original cor-pus.
We use a context window of 7 candidates,i.e., three candidates before the current, the currentcandidate and three candidates after the current.5 Experimental ResultsWe use the corpus provided in the CoNLL-2010Shared Task to train and evaluate our hedge de-tection system.
We add the following annota-tion to the corpus: word stems, part-of-speechtags, phrase chunks, and clause annotations.
Wordstems have been generated by the Porter stemmer(Porter, 1980).
The additional annotation has beengenerated by ETL based systems (dos Santos andMilidiu?, 2009; Fernandes et al, 2009b; Milidiu?
etal., 2008).The CoNLL corpus is based on the BioScopecorpus (Vincze et al, 2008).
Since it contains doc-uments of two different kinds ?
paper abstracts andfull papers ?
we split it into two subcorpora.
Thefirst subcorpus is called ABST and contains all thepaper abstracts.
The second is called FULL andcontains all the full papers.We have two experimental setups: Developmentand Evaluation.
In the Development Setup, we useABST as the training corpus and FULL as the de-velopment corpus.
This is a conservative decisionsince the CoNLL Evaluation Corpus is comprisedonly of full articles.
In the Evaluation Setup, weuse the union of ABST and FULL as the train-ing corpus and report the performance over theCoNLL Evaluation Corpus.5.1 DevelopmentHere, we report the development setup experimen-tal findings.
In Table 1, we show the performanceof the three baseline classifiers.
The start and endclassifiers are evaluated with golden standard cuechunks.
All results are obtained with the END-Xbaseline system, except when explicitly stated.Task Precision Recall F-scoreCue 51.96 51.65 51.80Start scope 72.01 72.22 72.11End scope 65.90 58.97 62.24Table 1: Development performance of the threeBaseline Classifiers.In Table 2, we report the performance of thethree entity identification ETL classifiers.
Again,the start and end classifiers are evaluated withgolden standard cue chunks.
These results indi-cate that the end scope subtask is the hardest one.Indeed, our ETL classifier is not able to improvethe baseline classifier performance.
The last ta-ble line shows the performance of the RelHuntermethod on the target task ?
hedge detection.5.2 EvaluationHere, we report the evaluation setup findings.
InTable 3, we show the performance of the three67Task Precision Recall F-scoreCue 81.23 73.20 77.01Start scope 91.81 72.37 80.94End scope 65.90 58.97 62.24Hedge 53.49 34.43 41.89Table 2: Development performance of the threeentity identification ETL classifiers and the Rel-Hunter method to hedge detection.baseline classifiers.
The start and end classifiersare evaluated with golden standard cue chunks.Task Precision Recall F-scoreCue 45.12 60.02 51.52Start scope 75.51 75.73 75.62End scope 81.01 72.56 76.55Table 3: Evaluation performance of the threeBaseline Classifiers.In Table 4, we report the performance of thethree entity identification ETL classifiers.
Again,the start and end classifiers are evaluated withgolden standard cue chunks.
The last table lineshows the performance of the RelHunter methodon the target task ?
hedge detection.Task Precision Recall F-scoreCue 78.73 77.05 77.88Start scope 89.21 77.86 83.15End scope 81.01 72.56 76.55Hedge 57.84 50.73 54.05Table 4: Evaluation performance of the threeentity identification ETL classifiers and the Rel-Hunter method to hedge detection.In Table 5, we report the Hedge Detection per-formances when using END and END-X, as thebaseline classifier for the end scope subtask.
Theuse of END-X improves the overall system F -score by more than ten twelve.In Table 6, we report the Final Results of theCoNLL-2010 Shared Task ?
Closed Task 2.
Forthe sake of comparison, we also include the per-formance of the RelHunter system with END-X,that has been developed and tested after the com-End scope Precision Recall F-scoreEND 45.96 38.04 41.63END-X 57.84 50.73 54.05Table 5: Evaluation performance of the RelHuntersystem when using END and END-X.petition end.
The version with the END baselineholds rank 7 at the competition.Official System P R FRank1 Morante 59.62 55.18 57.322 Rei 56.74 54.60 55.653 Velldal 56.71 54.02 55.33- RelHunter 57.84 50.73 54.054 Li 57.42 47.92 52.245 Zhou 45.32 43.56 44.426 Zhang 45.94 42.69 44.257 Fernandes 45.96 38.04 41.638 Vlachos 41.18 35.91 38.379 Zhao 34.78 41.05 37.6610 Tang 34.49 31.85 33.1211 Ji 21.87 17.23 19.2712 Ta?ckstro?m 02.27 02.03 02.15Table 6: Evaluation performance of the CoNLL-2010 systems and the RelHunter method with theEND-X end scope classifier.6 ConclusionWe propose RelHunter, a new machine learningbased method for the extraction of structured in-formation from text.
RelHunter consists in model-ing the target structures as a relation over entities.To learn how to extract this relation from text, Rel-Hunter uses two main schemes: task decomposi-tion and interdependent classification.RelHunter decomposes the identification of en-tities into several but simple token classificationsubtasks.
Additionally, the method generates acandidate relation over the identified entities anddiscriminates between true and false candidateswithin this relation.RelHunter uses the Entropy Guided Transfor-mation Learning algorithm as its learning engine.As Hidden Markov Models, ETL is able to con-sider interdependent examples.
RelHunter ex-68ploits this powerful feature in order to tackle de-pendencies among the hedge candidates.RelHunter is easily applied to many complexComputational Linguistic problems.
We show itseffectiveness by applying it to hedge detection.Other successful applications of this method arepresented in Fernandes et al (2009b; 2010).RelHunter explores the dependency among lin-guistic structures by using a powerful feature ofthe ETL algorithm.
Nevertheless, this featureis restricted to sequentially organized examples,since ETL has been initially proposed for tokenclassification problems.
Linguistic structures in-volve topologies that are frequently more complexthan that.
The ETL algorithm may be extended toconsider more complex topologies.
We conjecturethat it is possible to consider quite general topolo-gies.
This would contribute to the construction ofbetter solutions to many Computational Linguistictasks.AcknowledgmentsThe authors thank Evelin Amorim and EduardoMotta for coding dataset normalization proceduresthat are very handy for Hedge Detection.ReferencesEric Brill.
1995.
Transformation-based error-drivenlearning and natural language processing: a casestudy in part-of-speech tagging.
Computational Lin-guistics, 21(4):543?565.Xavier Carreras, Llu?
?s Ma`rquez, Vasin Punyakanok,and Dan Roth.
2002.
Learning and inference forclause identification.
In Proceedings of the Thir-teenth European Conference on Machine Learning,pages 35?47.Xavier Carreras, Llu?
?s Ma`rquez, and Jorge Castro.2005.
Filtering-ranking perceptron learning for par-tial parsing.
Machine Learning, 60(1?3):41?71.C?
?cero N. dos Santos and Ruy L.
Milidiu?, 2009.
Foun-dations of Computational Intelligence, Volume 1:Learning and Approximation, volume 201 of Stud-ies in Computational Intelligence, chapter EntropyGuided Transformation Learning, pages 159?184.Springer.Richa?rd Farkas, Veronika Vincze, Gyo?rgy Mo?ra, Ja?nosCsirik, and Gyo?rgy Szarvas.
2010.
The CoNLL-2010 Shared Task: Learning to Detect Hedges andtheir Scope in Natural Language Text.
In Proceed-ings of the Fourteenth Conference on ComputationalNatural Language Learning (CoNLL-2010): SharedTask, pages 1?12, Uppsala, Sweden, July.
Associa-tion for Computational Linguistics.Eraldo R. Fernandes, C?
?cero N. dos Santos, and Ruy L.Milidiu?.
2009a.
Portuguese language processingservice.
In Proceedings of the Web in Ibero-AmericaAlternate Track of the 18th World Wide Web Confer-ence (WWW?2009), Madrid.Eraldo R. Fernandes, Bernardo A. Pires, C?
?cero N. dosSantos, and Ruy L. Milidiu?.
2009b.
Clause identifi-cation using entropy guided transformation learning.In Proceedings of the 7th Brazilian Symposium in In-formation and Human Language Technology (STIL),Sa?o Carlos, Brazil.Eraldo R. Fernandes, Bernardo A. Pires, C?
?cero N.dos Santos, and Ruy L. Milidiu?.
2010.
A ma-chine learning approach to Portuguese clause iden-tification.
In Proceedings of the Nineth Interna-tional Conference on Computational Processing ofthe Portuguese Language (PROPOR), volume 6001of Lecture Notes in Artificial Intelligence, pages 55?64, Porto Alegre, Brazil.
Springer.Ruy L.
Milidiu?, C?
?cero N. dos Santos, and Julio C.Duarte.
2008.
Phrase chunking using entropyguided transformation learning.
In Proceedings ofACL-08: HLT, pages 647?655, Columbus, USA.Association for Computational Linguistics.Ruy L.
Milidiu?, C?
?cero N. dos Santos, and CarlosE.
M. Crestana.
2009.
A token classification ap-proach to dependency parsing.
In Proceedings ofthe 7th Brazilian Symposium in Information and Hu-man Language Technology (STIL?2009), Sa?o Carlos,Brazil.Roser Morante and Walter Daelemans.
2009.
Learn-ing the scope of hedge cues in biomedical texts.
InProceedings of the BioNLP 2009 Workshop, pages28?36, Boulder, USA, June.
Association for Com-putational Linguistics.Martin F. Porter.
1980.
An algorithm for suffix strip-ping.
Program, 14(3):130?137.Vasin Punyakanok and Dan Roth.
2001.
The use ofclassifiers in sequential inference.
In Proceedings ofthe Conference on Advances in Neural InformationProcessing Systems (NIPS), pages 995?1001.
MITPress.Erik F. Tjong Kim Sang and Sabine Buchholz.2000.
Introduction to the CoNLL-2000 shared task:Chunking.
In Proceedings of CoNLL-2000 andLLL-2000, Lisbon, Portugal.Erik F. T. K. Sang and Herve?
De?jean.
2001.
Introduc-tion to the CoNLL-2001 shared task: Clause identifi-cation.
In Proceedings of Fifth Conference on Com-putational Natural Language Learning, Toulouse,France.Veronika Vincze, Gyo?rgy Szarvas, Richa?rd Farkas,Gyo?rgy Mo?ra, and Ja?nos Csirik.
2008.
The Bio-Scope corpus: biomedical texts annotated for uncer-tainty, negation and their scopes.
BMC Bioinformat-ics, 9 (Suppl 11):S9.69
