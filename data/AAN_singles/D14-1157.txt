Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1481?1486,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsStaying on Topic:An Indicator of Power in Political DebatesVinodkumar PrabhakaranDept.
of Computer ScienceColumbia UniversityNew York, NY, USAvinod@cs.columbia.eduAshima AroraDept.
of Computer ScienceColumbia UniversityNew York, NY, USAaa3470@columbia.eduOwen RambowCCLSColumbia UniversityNew York, NY, USArambow@ccls.columbia.eduAbstractWe study the topic dynamics of interac-tions in political debates using the 2012Republican presidential primary debatesas data.
We show that the tendency ofcandidates to shift topics changes over thecourse of the election campaign, and that itis correlated with their relative power.
Wealso show that our topic shift features helppredict candidates?
relative rankings.1 IntroductionThe field of computational social sciences has cre-ated many interesting applications for natural lan-guage processing in recent years.
One of the areaswhere NLP techniques have shown great promiseis in the analysis of political speech.
For example,researchers have applied NLP techniques to polit-ical texts for a variety of tasks such as predictingvoting patterns (Thomas et al., 2006), identifyingmarkers of persuasion (Guerini et al., 2008), cap-turing cues that signal charisma (Rosenberg andHirschberg, 2009), and detecting ideological po-sitions (Sim et al., 2013).
Our work also analyzespolitical speech, more specifically, presidential de-bates.
The contribution of this paper is to showthat the topic shifting tendency of a presidentialcandidate changes over the course of the electioncampaign, and that it is correlated with his or herrelative power.
We also show that this insight canhelp computational systems that predict the candi-dates?
relative rankings based on their interactionsin the debates.2 MotivationThe motivation for this paper stems from priorwork done by the first author in collaborationwith other researchers (Prabhakaran et al., 2013a;Prabhakaran et al., 2013b).
Prabhakaran et al.
(2013a) introduced the notion of power in the do-main of presidential debates, and Prabhakaran etal.
(2013b) followed it up with an automatic powerranker system based on interactions within the de-bates.
The power that a candidate had at a cer-tain point in the election campaign was modeledbased on his or her recent poll standings: in elec-tions, popularity is power.
Those studies analyzedthe 2012 Republican presidential primary debatesand found that a candidate?s power at the time ofa debate correlates with the structure of interac-tions within the debate (e.g., turn frequency andinterruption patterns).
Another finding was thatthe candidates?
power correlates with the distribu-tion of topics they speak about in the debates: can-didates with more power spoke significantly moreabout certain topics (e.g., economy) and less aboutcertain other topics (e.g., energy).
However, thesefindings relate to the specific election cycle thatwas analyzed and will not carry over to politicaldebates in general.A further dimension with relevance beyond aspecific election campaign is how topics evolveduring the course of an interaction (e.g., who at-tempts to shift topics).
In (Prabhakaran et al.,2014), we explored this dimension and found thatcandidates with higher power introduce signifi-cantly more topics in the debates, but attempt toshift topics significantly less often while respond-ing to a moderator.
We used the basic LDA topicmodeling method (with a filter for substantivity ofturns) to assign topics to turns, which were thenused to detect shifts in topics.
However, segment-ing interactions into coherent topic segments is anactive area of research and a variety of topic mod-eling approaches have been proposed for that pur-pose.
In this paper, we explore the utility of onesuch topic modeling approach to tackle this prob-lem.While most of the early approaches for topicsegmenting in interactions have focused on the1481content of the contribution, Nguyen et al.
(2012)introduced a system called Speaker Identity forTopic Segmentation (SITS) which also takes intoaccount the topic shifting tendencies of the partic-ipants of the conversation.
In later work, Nguyenet al.
(2013) demonstrated the SITS system?s util-ity in detecting influencers in Crossfire debatesand Wikipedia discussions.
They also applied theSITS system to the domain of political debates.However they were able to perform only a qual-itative analysis of its utility in the debates domainsince the debates data did not have influence an-notations.
In this paper, we use the SITS systemto assign topics to turns and perform a quantita-tive analysis of how the topic shift features calcu-lated using the SITS system relate to the notion ofpower as captured by (Prabhakaran et al., 2013a).The SITS system associates each debate partic-ipant with a constant scalar value that captures hisor her tendency to shift topics.
However, sincewe want to investigate how each candidate?s topicshifting tendency relates to his or her changingpower over the course of the campaign, we intro-duce a variation of the SITS analysis in which werepresent a different ?persona?
for each candidatein each debate.
Once equipped with this notionof ?persona?, we find that the topic shifting ten-dency of a candidate does indeed show a great dealof fluctuation during the election campaign period.We also find that this fluctuation in topic shiftingtendencies is significantly correlated with the can-didates?
power.As an additional contribution of this paper, wedemonstrate the utility of our topic shift featuresextracted using both types of SITS-based anal-yses in improving the performance of the auto-matic power ranker system presented in (Prab-hakaran et al., 2013b).
We also investigated theutility of topic shifting features described in (Prab-hakaran et al., 2014) extracted using LDA basedtopic modeling.
However, they did not improvethe performance of the ranker, and hence we donot discuss them in detail in this paper.3 DataWe use the presidential debates corpus released byPrabhakaran et al.
(2013a), which contains manualtranscripts of 20 debates held between May 2011and February 2012 as part of the 2012 Republicanpresidential primaries.
The corpus also captureseach candidate?s power at the time of each debate,computed based on their relative standing in re-cent public polls.
The poll numbers capture howsuccessful candidates are in convincing the elec-torate of their candidature, which in turn affectstheir confidence within the debates.
These debatesserve as a rich domain to explore manifestationsof power since they are a medium through whichcandidates pursue and maintain power over othercandidates.
Prabhakaran et al.
(2013b) offers a de-tailed description of how the relative standings innational and state-level polls from various sourcesare aggregated to obtain candidates?
power.The transcripts are originally obtained from TheAmerican Presidency Project, where each turn ofthe conversation is manually demarcated and theirspeakers identified.
The turns in the corpus arepreprocessed using the Stanford CoreNLP pack-age to perform basic NLP steps such as tokeniza-tion, sentence segmentation, parts-of-speech tag-ging and lemmatization.4 Modeling Topic ShiftsTopic segmentation, the task of segmenting inter-actions into coherent topic segments, is an impor-tant step in analyzing interactions.
In additionto its primary purpose, topic segmentation alsoidentifies the speaker turn where the conversationchanged from one topic to another, i.e., where thetopic shifted, which may shed light on the char-acteristics of the speaker who changed the topic.We use the SITS approach proposed by (Nguyenet al., 2012) to detect topic shifts.
We also proposea different way of using SITS to obtain an analysisof our corpus, which we call SITSvar.
We discussboth in turn, and then provide a discussion.4.1 Segmentation using SITSMost computational approaches towards auto-matic topic segmentation have focused mainly onthe content of the contribution without taking intoaccount the social aspects or speaker character-istics.
Different discourse participants may havedifferent tendencies to introduce or shift topics ininteractions.
In order to address this shortcom-ing, Nguyen et al.
(2012) proposed a new topicsegmentation model called Speaker Identity forTopic Segmentation (SITS), in which they explic-itly model the individual?s tendency to introducenew topics.Like traditional topic modeling approaches, theSITS system also considers each turn to be a14820?0.1?0.2?0.3?0.4?0.5?0.6?6/13/11?8/11/11?
9/5/11?9/7/11?9/12/11?9/22/11?10/11/11?10/18/11?11/9/11?11/12/11?11/22/11?12/10/11?12/15/11?1/7/12?1/8/12?1/16/12?1/19/12?1/23/12?1/26/12?2/22/12?Topic?Shi?
?Tendency,?PI(x_d)?Date?of?Debate?BACHMANN?CAIN?GINGRICH?HUNTSMAN?PAUL?PERRY?ROMNEY?SANTORUM?Figure 1: SITSvarTopic shift tendency values across debatesbag of words generated from a mixture of top-ics.
These topics themselves are multinomial dis-tributions over terms.
In order to account for thetopic shifts that happen during the course of an in-teraction, they introduce a binary latent variableld;tcalled the topic shift to indicate whether thespeaker changed the topic or not in conversationd at turn t. To capture the individual speaker?stopic shifting tendency, they introduced anotherlatent variable called topic shift tendency (pix) ofspeaker x.
The pixvalue represents the propensityof speaker x to perform a topic shift.4.2 Segmentation using SITSvarWithin the SITS formulation, the topic shiftingtendency of an individual (pix) is considered a con-stant across conversations.
While an individualmay have an inherent propensity to shift topics ornot, we argue that the topic shifting tendency heor she displays can vary based on the social set-tings in which he or she interacts and his or herstatus within those settings.
In other words, thesame discourse participant may behave differentlyin different social situations and at different pointsin time.
This is especially relevant in the contextof our dataset, where the debates happen over aperiod of 10 months, and the power and statusof each candidate in the election campaign varygreatly within that time period.We propose a variant of SITS which takes thisissue into account.
We consider each candi-date to have a different ?persona?
in each debate.To accomplish this, we create new identities foreach candidate x for each debate d, denoted byx d. For example, ?ROMNEY 08-11-2011?
de-notes the persona of the candidate ROMNEY inthe debate held on 08-11-2011.
Running the SITSsystem using this formulation, we obtain differentpix dvalues for candidate x for different debates,capturing different topic shift tendencies of x.4.3 ExecutionWe perform both the SITS and SITSvaranalyseson the 20 debates in our corpus.
We used the non-parametric version of SITS for both runs, since itsystemically estimates the number of topics in thedata.
We set the maximum number of iterationsat 5000, sample lag at 100 and initial number oftopics at 25.
We refer the reader to (Nguyen et al.,2013) for details on these parameters.For each candidate, we calculate the mean andstandard deviation of the topic shift tendency(pix d) of his or her personas across all debateshe or she participated in.
We then average thesemeans and standard deviations, and obtain an av-erage mean of 0.14 and an average standard devia-tion of 0.09.
This shows that the topic shift tenden-cies of candidates vary by a considerable amountacross debates.
Figure 1 shows the pix dvalue fluc-tuating across different debates.5 Analysis of Topic Shift FeaturesNguyen et al.
(2013) used the SITS analysis as ameans to model influence in multi party conver-sations.
They propose two features to detect in-fluencers: Total Topic Shifts (TTS) and WeightedTopic Shifts (WTS).
TTS(x, d) captures the ex-pected number of topic shifts the individual xmakes in conversation d. This expectation is cal-culated through the empirical average of samples1483Feature Set Feature CorrelationTopShTotal Topic Shifts (TTS) 0.12Weighted Topic Shifts (WTS) 0.16TopShvarTotal Topic Shifts (TTSvar) 0.12Weighted Topic Shifts (WTSvar) 0.15Topic Shift Tendency (PIvar) -0.27Table 1: Pearson Correlations for Topical Featuresboldface denotes statistical significance (p < 0.05)from the Gibbs sampler, after a burn-in period.
Werefer the reader to (Nguyen et al., 2013) for moredetails on how this value is computed.
WTS(x, d)is the value of TTS(x, d) weighted by 1?
pix.
Theintuition here is that a topic shift by a speaker withlow topic shift tendency must be weighted higherthan that by a speaker with a high topic shift ten-dency.
We use these two features as well, and de-note the set of these two features as TopSh.We also extract the TTS and WTS features us-ing our SITSvarvariation of topic segmentationanalysis and denote them as TTSvarand WTSvarrespectively.
In addition, we also use a featurePIvar(x, d) which is the pix dvalue obtained by theSITSvarfor candidate x in debate d. It captures thetopic shifting tendency of candidate x in debate d.(We do not include the SITS pixvalue in our corre-lation analysis since it is constant across debates.
)We denote the set of these three features obtainedfrom the SITSvarrun as TopShvar.Table 1 shows the Pearson?s product correla-tion between each topical feature and candidate?spower.
We obtain a highly significant (p = 0.002)negative correlation between topic shift tendencyof a candidate (PI) and his/her power.
In otherwords, the variation in the topic shifting tenden-cies is significantly correlated with the candidates?recent poll standings.
Candidates who are higherup in the polls tend to stay on topic while thecandidates with less power attempt to shift top-ics more often.
This is in line with our previousfindings from (Prabhakaran et al., 2014) that can-didates with higher power attempt to shift topicsless often than others when responding to moder-ators.
It is also in line with the findings by Prab-hakaran et al.
(2013a) that candidates with higherpower tend not to interrupt others.
On the otherhand, we did not obtain any significant correlationfor the features proposed by Nguyen et al.
(2013).6 Topic Shift Features in Power RankerIn this section, we investigate the utility of theSITS and SITSvarbased topic shift features de-scribed above in the problem of automaticallyranking the participants of debates based on theirpower.
Prabhakaran et al.
(2013b) define the prob-lem as follows: given a debate d with a set of par-ticipants Cd= {x1, x2, ...xn} and correspondingpower indices P (xi) for 1 < i < n, find a rankingfunction r : Cd?
{1...n} such that for all 1 <i, j < n, r(xi) > r(xj) ??
P (xi) > P (xj).For our experiments, we use the SVMrankbasedsupervised learned power ranker presented in thatwork to estimate this ranking function.As we do in (Prabhakaran et al., 2013b), wehere report Kendall?s Tau and Normalized Dis-counted Cumulative Gain values (NDCG andNDCG@3) on 5-fold cross validation (at the de-bate level).
All three metrics are based on thenumber of rank inversions between original andpredicted ranking.
While Tau treats all rank in-versions equal, NDCG and NDCG@3 penalizethe inversions happening in the top of the rankedlist more than those happening in the bottom.NDCG@3 focuses only on the top 3 positions inthe ranked list.We use the best performing feature set of (Prab-hakaran et al., 2013b) as the baseline (BL), whichcontains three features: Words Deviation (WD),Question Deviation (QD) and Mention Percent-age (MP).
WD and QD capture the deviation ofpercentage of words spoken by the candidate andquestions addressed to the candidate from the ex-pected fair share of those measures in the particu-lar debate.
The fair share for debate d is 1/|Cd|?the percentage each candidate would have gottenfor each feature if it was equally distributed.
Thisdeviation measure is used instead of the raw per-1484Kendall?s Tau NDCG NDCG@3BL 0.55 0.962 0.932TopSh 0.36 0.907 0.830TopShvar0.39 0.919 0.847BL + TopSh 0.59 0.967 0.929BL + TopShvar0.60 0.970 0.937BL + TopSh + TopShvar0.59 0.968 0.934Table 2: Power Ranker results using topic shift features on 5-fold cross validationBL: Baseline system (Prabhakaran et al., 2013b)NDCG: Normalized Discounted Cumulative Gaincentage in order to handle the fact that the percent-age values are dependent on the number of partic-ipants in a debate, which varied from 9 to 4.
MPcaptures the percentage of mentions of the candi-date within a debate.Table 2 shows the results obtained using thebaseline features (BL) as well as combinations ofTopSh and TopShvarfeatures.
The baseline sys-tem obtained a Kendall Tau of 0.55, NDCG of0.962 and NDCG@3 of 0.932.
The topic shiftfeatures by themselves performed much worse,with TopShvarposting marginally better resultsthan TopSh.
Combining the topic shift and base-line features increases performance considerably.TopShvarobtained better performance than TopShacross the board.
BL + TopShvarposted the over-all best system obtaining a Tau of 0.60, NDCGof 0.970, and NDCG@3 of 0.937.
These resultsdemonstrates the utility of topic shift features inthe power ranking problem, especially using theSITSvarformulation.
We also experimented withall subsets of TopSh and TopShvar; the best resultswere obtained using all features in each set.7 Related WorkStudies in sociolinguistics (e.g., (Ng et al., 1993;Ng et al., 1995; Reid and Ng, 2000)) have longestablished that dialog structure in interactions re-lates to power and influence.
Researchers in theNLP community have studied power and influencein various genres of interactions, such as organiza-tional email threads (Bramsen et al., 2011; Gilbert,2012; Prabhakaran and Rambow, 2013; Prab-hakaran and Rambow, 2014), online discussion fo-rums (Danescu-Niculescu-Mizil et al., 2012; Bi-ran et al., 2012) and online chat dialogs (Strza-lkowski et al., 2012).
The correlates analyzed inthese studies range from word and phrase patterns,to derivatives of such patterns such as linguisticcoordination, to deeper dialogic features such asargumentation and dialog acts.
Our work differsfrom these studies in that we study the correlatesof power in topic dynamics.
Furthermore, we an-alyze spoken interactions.8 ConclusionIn this paper, we studied how topic shift patternsin the 2012 Republican presidential debates corre-late with the power of candidates.
We proposed analternate formulation of the SITS topic segmenta-tion system that captures fluctuations in each can-didate?s topic shifting tendencies, which we foundto be correlated with their power.
We also showedthat features based on topic shift improve the pre-diction of the relative rankings of candidates.
Infuture work, we will explore a model that cap-tures individuals?
inherent topic shift propensities,while also capturing their fluctuations due to so-cial factors.AcknowledgmentsThis paper is based upon work supported by theDARPA DEFT Program.
The views expressed arethose of the authors and do not reflect the officialpolicy or position of the Department of Defense orthe U.S. Government.
We also thank the anony-mous reviewers for their constructive feedback.1485ReferencesOr Biran, Sara Rosenthal, Jacob Andreas, KathleenMcKeown, and Owen Rambow.
2012.
Detectinginfluencers in written online conversations.
In Pro-ceedings of the Second Workshop on Language inSocial Media, pages 37?45, Montr?eal, Canada, June.Association for Computational Linguistics.Philip Bramsen, Martha Escobar-Molano, Ami Patel,and Rafael Alonso.
2011.
Extracting social powerrelationships from natural language.
In Proceedingsof the 49th Annual Meeting of the Association forComputational Linguistics: Human Language Tech-nologies, pages 773?782, Portland, Oregon, USA,June.
Association for Computational Linguistics.Cristian Danescu-Niculescu-Mizil, Lillian Lee,Bo Pang, and Jon Kleinberg.
2012.
Echoes ofpower: language effects and power differences insocial interaction.
In Proceedings of the 21st in-ternational conference on World Wide Web, WWW?12, New York, NY, USA.
ACM.Eric Gilbert.
2012.
Phrases that signal workplace hier-archy.
In Proceedings of the ACM 2012 conferenceon Computer Supported Cooperative Work, CSCW?12, pages 1037?1046, New York, NY, USA.
ACM.Marco Guerini, Carlo Strapparava, and Oliviero Stock.2008.
Corps: A corpus of tagged political speechesfor persuasive communication processing.
Journalof Information Technology & Politics, 5(1):19?32.Sik Hung Ng, Dean Bell, and Mark Brooke.
1993.Gaining turns and achieving high in influence rank-ing in small conversational groups.
British Journalof Social Psychology, pages 32, 265?275.Sik Hung Ng, Mark Brooke, and Michael Dunne.1995.
Interruption and in influence in discussiongroups.
Journal of Language and Social Psychol-ogy, pages 14(4),369?381.Viet-An Nguyen, Jordan Boyd-Graber, and PhilipResnik.
2012.
Sits: A hierarchical nonparametricmodel using speaker identity for topic segmentationin multiparty conversations.
In Proceedings of the50th Annual Meeting of the Association for Com-putational Linguistics (Volume 1: Long Papers),pages 78?87, Jeju Island, Korea, July.
Associationfor Computational Linguistics.Viet-An Nguyen, Jordan Boyd-Graber, Philip Resnik,Deborah A. Cai, Jennifer E. Midberry, and YuanxinWang.
2013.
Modeling topic control to detect in-fluence in conversations using nonparametric topicmodels.
Machine Learning, pages 1?41.Vinodkumar Prabhakaran and Owen Rambow.
2013.Written dialog and social power: Manifestations ofdifferent types of power in dialog behavior.
In Pro-ceedings of the IJCNLP, pages 216?224, Nagoya,Japan, October.
Asian Federation of Natural Lan-guage Processing.Vinodkumar Prabhakaran and Owen Rambow.
2014.Predicting power relations between participants inwritten dialog from a single thread.
In Proceed-ings of the 52nd Annual Meeting of the Associationfor Computational Linguistics (Volume 2: Short Pa-pers), pages 339?344, Baltimore, Maryland, June.Association for Computational Linguistics.Vinodkumar Prabhakaran, Ajita John, and Dor?ee D.Seligmann.
2013a.
Power dynamics in spoken in-teractions: a case study on 2012 republican primarydebates.
In Proceedings of the 22nd internationalconference on World Wide Web companion, pages99?100.
International World Wide Web ConferencesSteering Committee.Vinodkumar Prabhakaran, Ajita John, and Dor?ee D.Seligmann.
2013b.
Who had the upper hand?
rank-ing participants of interactions based on their rela-tive power.
In Proceedings of the IJCNLP, pages365?373, Nagoya, Japan, October.
Asian Federationof Natural Language Processing.Vinodkumar Prabhakaran, Ashima Arora, and OwenRambow.
2014.
Power of confidence: How pollscores impact topic dynamics in political debates.In Proceedings of the ACL 2014 Workshop on Lan-guage Technologies and Computational Social Sci-ence, page 49, Baltimore, MD, USA, June.
Associa-tion for Computational Linguistics.Scott A. Reid and Sik Hung Ng.
2000.
Conversation asa resource for in influence: evidence for prototypicalarguments and social identification processes.
Euro-pean Journal of Social Psych., pages 30, 83?100.Andrew Rosenberg and Julia Hirschberg.
2009.Charisma perception from text and speech.
SpeechCommunication, 51(7):640?655.Yanchuan Sim, Brice D. L. Acree, Justin H. Gross, andNoah A. Smith.
2013.
Measuring ideological pro-portions in political speeches.
In Proceedings of the2013 Conference on EMNLP, pages 91?101, Seattle,Washington, USA, October.
Association for Compu-tational Linguistics.Tomek Strzalkowski, Samira Shaikh, Ting Liu,George Aaron Broadwell, Jenny Stromer-Galley,Sarah Taylor, Umit Boz, Veena Ravishankar, andXiaoai Ren.
2012.
Modeling leadership and influ-ence in multi-party online discourse.
In Proceedingsof COLING, pages 2535?2552, Mumbai, India, De-cember.
The COLING 2012 Organizing Committee.Matt Thomas, Bo Pang, and Lillian Lee.
2006.
Get outthe vote: Determining support or opposition fromcongressional floor-debate transcripts.
In Proceed-ings of the 2006 Conference on Empirical Methodsin Natural Language Processing, pages 327?335,Sydney, Australia, July.
Association for Computa-tional Linguistics.1486
