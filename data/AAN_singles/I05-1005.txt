Corpus-Based Analysis of Japanese RelativeClause ConstructionsTakeshi Abekawa1 and Manabu Okumura21 Interdisciplinary Graduate School of Science and Engineering,Tokyo Institute of Technology, Japanabekawa@lr.pi.titech.ac.jp2 Precision and Intelligence Laboratory,Tokyo Institute of Technology, Japanoku@pi.titech.ac.jpAbstract.
Japanese relative clause constructions (RCC?s) are defined asbeing the NP?s of structure ?S NP?, noting the lack of a relative pronounor any other explicit form of noun-clause demarcation.
Japanese relativeclause modification should be classified into at least two major semantictypes: case-slot gapping and head restrictive.
However, these types forrelative clause modification cannot apparently be distinguished.
In thispaper we propose a method of identifying a RCC?s type with a machinelearning technique.
The features used in our approach are not only rep-resenting RCC?s characteristics, but also automatically obtained fromlarge corpora.
The results we obtained from evaluation revealed that ourmethod outperformed the traditional case frame-based method, and thefeatures that we presented were effective in identifying RCC?s types.1 IntroductionJapanese relative clause constructions (RCC?s) are defined as being the NP?s ofstructure ?S NP?, noting the lack of a relative pronoun or any other explicit formof noun-clause demarcation[1].
Japanese relative clause constructions should beclassified into at least two major semantic types: case-slot gapping and headrestrictive.
However, these types for relative clause constructions cannot appar-ently be distinguished.Given the types of Japanese relative clause constructions and a corpus ofJapanese relative clause construction instances, we present a machine learningbased approach to classifying RCC?s.
We present a set of lexical and semanticfeatures that characterize RCC?s, and integrate them as a classifier to determineRCC types.
We use decision tree learning as the machine learning algorithm.Distinguishing case-slot gapping and head restrictive relative clauses, or re-solving the semantic relationship between the relative clause and its head nounhas several application domains, such as machine translation from Japanese[5].It also has a place in text understanding tasks, such as splitting a long sentenceinto multiple shorter sentences, and removing less important clauses to shortena sentence[6].R.
Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
46?57, 2005.c?
Springer-Verlag Berlin Heidelberg 2005Corpus-Based Analysis of Japanese Relative Clause Constructions 47Previously, relative clauses had been analyzed with rule-based methods thatutilized case frames[5,2].
Using hand-crafted rules and knowledge creates severalproblems: the high cost of constructing them, and lower scalability and coverage.Recently, due to the availability of very large corpora, corpus-based and ma-chine learning-based approaches have been actively investigated[7].
Cooccurrenceinformation between nouns and verbs can be calculated from the syntacticallyparsed corpus, and this information can be used preferentially instead of hand-crafted case frames to determine whether a noun can be the filler of a case-slotof a verb[7,11].However, merely using the cooccurrence information between nouns andverbs instead of case frames cannot provide a good solution to the analysis ofJapanese relative clauses.
Clauses with high occurrence probability of the mainverb and the head noun can sometimes be head restrictive.
Moreover, just be-cause the head noun can be the filler of a case-slot of the verb does not alwaysmean that the clause as case-slot gapping.
We have to rely on several differ-ent clues in order to realize accurate classification.
Therefore, in this paper wepresent eight features are effective in classifying case-slot gapping and head re-strictive relative clauses.
Most of the features can be automatically acquired bystatistically analyzing a corpus as explained in section 4.In section 2 we first describe the nature of Japanese RCC?s, and in section3 we outline previous work on the analysis of Japanese relative clauses.
In sec-tion 4 we explain the features that we present in this paper, and in section 5we explain the machine learning-based classifier, which uses the features in sec-tion 4.
In section 6 we describe the evaluation of the system and discuss theexperimental results.2 Japanese Relative Clause ConstructionsJapanese relative clause constructions have the structure ?S NP?, and constitutea noun phrase as a whole.
We will term the modifying S the ?relative clause?, themodified NP the ?head NP?, and the overall NP a ?relative clause construction?or RCC[2].
Example RCCs are:RCC should be classified into at least two major semantic types: case-slot gap-ping and head restrictive.
With case-slot gapping RCC?s (also called ?inner?(a)????
??
?saury grill man?the mani who ?i grills a saury?(b)???
?????
?
?everyone know information?the informationi which everyone knows ?i?(c)????
??
?
?saury grill smell?the smell of saury grilled?48 T. Abekawa and M. Okumurarelative clauses[14]), the head NP can be considered to have been gapped from acase slot subcategorized by the main verb of the relative clause.
Head restrictiveRCC?s (also called ?outer?
relative clause[14]) occur when the relative clause mod-ifies the head NP.
In (a), the head NP ??
(man) can be the subject of the main verbof the relative clause, and in (b), the head NP ??
(information) can be object ofthe main verb.
These RCC type are ?inner?
relative clauses.
In (c) the head NP ??
(smell) cannot fill the gap in the relative clause, and RCC type is ?outer?.The inherent difficulty in determining the type of RCC derives from the factthat these two types of RCC are syntactically identical.
Even if the relative clausehas case-slot gapping, the type of that clause is not always ?inner?, because inJapanese the main verb of the relative clause has often zero pronoun.
We thushave to disambiguate the individual RCC instances.3 Related WorkPrevious work on analyzing Japanese relative clauses has used case frames asuseful information.
They have first tried to find the case frame for the main verbof the relative clause and embedded the nouns in the clause into its case-slots.The head noun is then tried to be embedded into the remaining case-slot in thecase frame.
To determine whether a relative clause instance is ?outer?
clause,they have beforehand constructed a dictionary of the nouns that can be modi-fied by ?outer?
clause, such as ??
(purpose), or ??(opinion).
In one approach[5],the instance is determined to be ?outer?
clause, if the head noun is includedin the dictionary, regardless of the main verb of the relative clause.
In anotherapproach[12], the instance is determined to be ?outer?, if the head noun cannotbe embedded into a case-slot and the head noun is included in the dictionary.Recently, cooccurrence information between verbs and nouns has been usedin analysis.
Kawahara and Kurohashi[7] automatically extracted case framesfrom very large corpora, and used the case frames to analyze Japanese relativeclauses.
However, they judged the instances as ?outer?
clauses, only if case-slotfilling did not succeed.Murata[11] presented a statistical method of classifying whether the relativeclause is an ?inner?
or an ?outer?
clause.
However this method cannot correctlyclassify ?outer?
relative clause which had high cooccurrence probability of themain verbs and the head nouns.4 Feature Set to Classify RCC TypeIn this section, we present eight features that can be considered to be effectivein classifying ?inner?
and ?outer?
relative clauses.1.
Degree of possibility where the head noun can be modified by the?outer?
relative clause (degree of ?outerness?
).In Japanese, there are two ways of modification between verbs and nouns: nounsmodify verbs by filling a case-slot (noun ?
verb), and verbs modify nouns inCorpus-Based Analysis of Japanese Relative Clause Constructions 49Table 1.
Comparison of the number of cooccurring verbsrelative clauses case-slotsnoun freq.
verb No.
freq.
verb No.
(intent) 8,732 941 14,216 677(fact) 5,454 1,448 7,301 754(preparation) 2,268 428 2,720 74(people) 6,681 1,367 10,026 1,998(city) 1,172 449 3,688 857(television) 2,740 707 30,627 2,228relative clauses (verb ?
noun).
Some pairs of a verb and a noun can cooccuronly in RCC, and cannot cooccur by filling a case-slot of the verb.
For example,Therefore, we can measure the likelihood that the noun will be modified by?outer?
relative clauses, by calculating the difference in the frequency distributionof verbs cooccurring in relative clauses against the frequency distribution of verbscooccurring in the case-slot relation (If the difference is larger, the probabilitythat the noun can be modified by the ?outer?
relative clause becomes larger).We calculate the likelihood as J(Pk(v|n), Pm(v|n)), the Jensen-Shannon dis-tance between the cooccurrence probability where nouns fill the case-slots ofverbs(Pk(v|n)) and the cooccurrence probability where verbs cooccur with nounsin relative clauses(Pm(v|n)).
Given two probability distributions p,q, the Jensen-Shannon distance is defined by the following formula[9]:J(p, q) =12[D(p||p + q2) + D(q||p + q2)].
(1)D(p||q) is the Kullback-Leibler distance and defined by the following formula[3]:D(p||q) =?ipi logpiqi.
(2)noun ????
(preparation) and verb ????
(run) can cooccur with each other asthe main verb of a relative clause and its head noun, as in ??????
(prepara-tion for running), though the noun cannot fill any case-slots of the verb, as in *???????
(*preparation runs).
For nouns, some verbs only cooccur in relativeclauses, and a number of such verbs tend to be modified by ?outer?
clauses.Table 1 shows the occurrence frequency of sample nouns and the number oftheir cooccurring verbs in the relative clauses or in the case-slot relations.
Fornouns that do not tend to be modified by ?outer?
clauses, such as ????(people),????
(city), and ?????
(television), the ratio between the frequency and thenumber of verbs is almost the same between the relative clause and case-slotcases.
On the contrary, for nouns that tend to be modified by ?outer?
clauses,such as ????
(intent), ????
(fact), and ????
(preparation), the number ofverbs is much bigger in relation to clause cases, although the frequency is smaller.The reason may be, as previously explained, that some verbs cooccur with thenouns that tend to be modified by the ?outer?
clause only in relative clauseconstructions.50 T. Abekawa and M. OkumuraTable 2.
?outerness?
of example nounsWe use the Jensen-Shannon distance rather than the Kullback-Leibler distance,because the former is symmetric and has stability in various sizes of probabilitydistribution experimentally.
Pk(v|n) and Pm(v|n) are calculated as follows:Pk(v|n) =fk(n, v)fk(n), (3)Pm(v|n) =fm(n, v)fm(n), (4)where fk(n, v) is the cooccurrence frequency where noun n fills a case-slots ofverb v, and fk(n) is the frequency of the noun that occurs in the case-slotof verbs.
Similarly, fm(n, v) and fm(n) are the frequencies for relative clauseconstructions.
Table 2 shows the ?outerness?
of sample nouns.
The values of thenouns that are often modified by ?outer?
clauses are higher than those of thenouns which tend to be modified by ?inner?
clauses.2.
Cooccurrence information between head noun and main verb ofrelative clause.For a relative clause instance to be an ?inner?
clause, the head noun has to filla case-slot of the main verb of the relative clause.
Consider the following twoexamples:Whether a noun can fill a case-slot of a verb has been traditionally determinedusing case frames.
However, we use the cooccurrence information between thehead noun and the main verb.
In this paper, the cooccurrence between nouns andverbs is measured by mutual information.
Taking into account the informationon case particles, mutual information is calculated with the following formula:I(n, k; v) = logp(n, k, v)p(n, k)p(v), (5)noun ??
??
??
??
??
???
(intent) (fact) (preparation) (people) (city) (television)J(Pk, Pm) 0.546 0.360 0.616 0.160 0.155 0.159(a) ????
?resonate sound?the soundi that ?i resonates?(b)????
?destruct sound?the destruction sound?In (a), ???
(sound) can be the subject (???
case) of the main verb ??????(resonate).
On the contrary, in (b) ???
cannot fill any case-slots of the mainverb ??????
(destruct) and can be considered to be modified by the ?outer?relative clause.
Therefore, if the head noun can fill a case-slot of the main verb,the relation can be more plausibly assessed as ?inner?.Corpus-Based Analysis of Japanese Relative Clause Constructions 513.
Which case-slots are already filled for main verb by nouns in relativeclause.As previously explained, if the head noun can fill the case-slot of the main verb ofthe relative clause, the RCC instance can be judged as an ?inner?
clause.
However,if the case-slot that the head noun can fill is already filled by the noun in therelative clause, and hence unavailable for case-slot gapping, the rule cannot beapplied.
Consider, for example, the following two cases:Taking the situation into account, if a noun in the relative clause fills a case-slot of the main verb, the mutual information for the case-slot is set to a verysmall value Mmin.4.
Whether the head noun is modified by modifiers other than therelative clause (other modifier).Previous work on analyzing Japanese relative clauses has taking into accountonly the head noun, and has not taking into account modifiers other than therelative clause.
Consider the following two examples:where p(n, k) is the probability that noun n will cooccur with case particle kand p(n, k, v) is the cooccurrence probability for noun n, case particle k and verbv, and p(v) is the occurrence probability for verb v. The following seven caseparticles were taken into account: (???,???,???,???,???,??
?, and ????
).This is because only these case-slots can, in fact, be gapped to the head noun toconstruct the relative clause.(a)?????
?hear story?the storyi that (someone) heard ?i?(b)???
?????
?Japanese comic story hear story?the story that (someone) heard a Japanese comic story?In (a), since ???
(story) can fill the object (???
case) case-slot of the main verb????
(hear), the relation can be judged as ?inner?.
However, in (b), since theobject (???
case) case-slot of the main verb ????
is already filled by the noun????
(Japanese comic story), and ???
cannot fill any case-slot, the instanceis judged as ?outer?.(a)??
??
?
?him talk purpose?the purpose that (someone) talk (something) to him?
?the purposei that (someone) talk ?i to him?(b)??
??
???
?
?him talk trip purpose?the purpose of the trip i that (I) talk ?i to him?
(a) has two interpretations.
The first interpretation is that ????
(purpose) donot fill the remaining case-slots of the main verb ????
(talk) and can be con-52 T. Abekawa and M. OkumuraIf the head noun is modified by modifiers other than the relative clause, suchas adjectives, compound nouns, and ?AB?
(B of A), the relative clause type tendsto be ?inner?.
The function of ?outer?
relative clause describes the content of thehead noun.
If the head noun is modified by a modifier, the relative clause neednot describe it.
Therefore, the type of relative clause tends to be ?inner?.To implement the idea, we define a feature ?other modifier?.
If the headnoun is modified by any modifiers other than the relative clause, its value is 1,otherwise, 03.5.
Whether head noun tends to be modifiedAs for the nouns which tend to be modified by ?outer?
relative clauses, the relativeclauses describe the content of the head nouns.
It is difficult to understand theirmeaning without any modification.
Therefore we calculate the percentage towhat degree nouns are modified by any modifier in large corpora.
Table 3 showsthe percentage for example nouns.Table 3.
Percentage of modification3 In the experiment, we use syntactic annotated corpus.
Therefore, other modifierelements are already identified.sidered to be modified by the ?outer?
relative clause.
The second interpretationis that ????
can be the direct object(???
case) of the main verb ????
andcan be considered to be modified by the ?inner?
relative clause.
On the contrary,(b) has only the interpretation of ?inner?.??
??
???
?
Average of(intention) (field) (television) (he) all nouns0.983 0.973 0.287 0.155 0.460The percentages of nouns ????
(intention) and ????
(field), which tend tobe modified by ?outer?
relative clause, are close to 1, that is to say, such nounsmust have any modification.
We consider, the higher this percentage, the higherthe possibility that the noun is modified by ?outer?
relative clause.6.
Percentage where ?????
is inserted between relative clause andhead nouns?????
is a function expression that is sometimes inserted between relativeclauses and head nouns.
Table 4 shows the percentage where ?????
cooccurswith example nouns.??
?
??
??
Average of(opinion) (rumor) (place) (people) all nouns0.335 0.246 0.007 0.008 0.007Table 4.
The percentage of ?????
cooccurring with nounCorpus-Based Analysis of Japanese Relative Clause Constructions 537.
Whether head noun tends to be modified by past-tensed relativeclauses(tense information)Table 5.
Tense of main verb and distribution of inner/outerTo implement this idea, we first calculated deviations in the distribution oftense for the relative clauses.
The percentage of past-tense main verbs in allrelative clauses, Rpast, and the average for all the nouns were calculated.
Table6 shows the results for sample nouns.Table 6.
Percentage of past-tense main verbs4 In Japanese, there are just two tense surface markers: present and past.
Therefore,future tense is indicated by the present tense on the surface.The percentages of nouns ????
(opinion) and ???
(rumor), which tend tobe modified by ?outer?
relative clause, are higher than the average.
We consider,the higher this percentage, the higher possibility that the noun is modified by?outer?
relative clause.Some nouns tend to be modified by past-tense relative clauses, and otherstend to be modified by those in the present tense.
Consider, for example, thefollowing two nouns: ????
(plan) and ????
(memory).
Both nouns are con-sidered to imply the concept of time (future or past) 4 .??
??
(plan) (memory)tense inner outer inner outerpresent 6 89 12 0past 5 0 5 83For each of the two nouns ????
(plan) and ????
(memory), we examined100 relative clause instances that had the noun as the head noun (Table 5).Ifthe head noun implies the concept of time, the tense of the main verb of therelative clause tends to coincide with this concept.
Furthermore, note that thetense of the main verb of ?outer?
relative clauses is the same as the time conceptof the head noun.
From this, if the noun tends to be modified by a specific-tenserelative clause, the relative clause tends to be ?outer?, and if the tense of themain verb contradicts the time concept of the head noun (tense of frequentlymodified relative clauses), the relative clause should be determined as ?inner?.??
??
??
??
Average of(plan) (memory) (place) (people) all nouns0.032 0.958 0.333 0.422 0.322For a head noun which does not imply the concept of time (????
(place) and????
(people)), the percentage is near average.
On the contrary, ????
(plan)and ????
(memory) which imply the concept of time have an extreme value.54 T. Abekawa and M. OkumuraTaking into account the actual tense of the relative clause instances, wecalculated the following score:Vpast{Rpast ?
AV Gpast in case of present tenseAV Gpast ?
Rpast in case of past tense(6)For a head noun not implying the concept of time, in either tense of the mainverb, the score is rather low, and a decision on inner/outer might not be af-fected by the score.
For a head noun implying the concept of time, the ab-solute value of the score is rather large, and if the tense of the main verb isthe same as the time concept, the score becomes negative; otherwise the scorebecomes positive.8.
Whether main verb has a sense of ?exclusion?The last feature is for identifying exceptional ?outer?
relative clause.
Considerthe following two examples:5 Machine Learning Based Classifier for RCC TypeWe integrated the eight features in described the last section and used the ma-chine learning approach to determine the RCC type.
We used C5.0[13] as themachine learning algorithm.C5.0 is a decision-tree based classification system that has been used in nat-ural language processing, such as text classification, chunking, text summariza-tion, and ellipsis resolution[10].
C5.0 takes a set of training instances with afeature vector and correct type as input, and induces a classifier which charac-terizes the given feature space.Since we use only eight features, we think even the state of the art machinelearning method like SVM would yield almost the same accuracy as decision-tree.Furthermore decision-tree are more easily interpreted by human than SVMs.(a)???
??
????
?Japan except Asian countries?Asian countries except Japan?(b)????
???
?
?injured people except passenger?the passenger except injured people?These examples are ?outer?
relative clauses, and this RCC type is identified bythe main verb which has sense of exclusion.
There are a few verbs which indicatethe RCC type by itself.
Therefore, we defined a feature ?excluding verb?.
If themain verb contains a character ???
(which has sense of exclusion), the featureis set to 1, otherwise, 0.Corpus-Based Analysis of Japanese Relative Clause Constructions 556 Evaluation6.1 ExperimentCooccurrence and other statistical information used in this work were calculatedfrom the corpus of a collection of twenty-two years of newspaper articles.
Thecorpus was parsed with KNP[8], which is a rule-based Japanese syntactic parser.The cooccurrence information we obtained was as follows: the number of fk(n, v)was about 60.8 million, and the number of fm(n, v) was about 12.4 million.The data used in the evaluation was a set of RCC instances randomly ex-tracted from the EDR corpus[4] which had syntactically analyzed.
Then, a label,whether the relative clause is ?inner?
or ?outer?, was manually annotated.
Thestatistics on the data are shown in Table 7.
Evaluation with C5.0 was carriedout by way of 5-fold cross validation.Table 7.
Statistics on evaluation dataTotal Inner Outer749 580 169Table 8.
Experimental resultsInner Outeraccuracy precision recall precision recallBaseline 0.774 0.774 1.000 - -Cooccurrence information only 0.787 0.836 0.906 0.520 0.366Case frame 0.830 0.868 0.921 0.657 0.521Our approach 0.902 0.931 0.942 0.794 0.762Fig.
1.
Generated decision tree...excluding verb = 1: outer(exceptinal type) (22/2):.excluding verb = 0::..outerness <= 0.212: inner (444/6)outerness > 0.212::..other modifier = 1: inner (84/17)other modifier = 0::..cooccurrence("?"
case) > -9.10: inner (28/4)cooccurrence("?"
case) <= -9.10::..percentage of "???"
> 0.027: outer (105/14)percentage of "???"
<= 0.027::..percentage of modified <= 0.735: inner (25/2)percentage of modified > 0.735::..cooccurrence("?"
case) <= -13.1:outer (31/5)cooccurrence("?"
case) > -13.1:inner (10/2)56 T. Abekawa and M. OkumuraThe baseline we used determines all instances as ?inner?
relative clauses.
Wealso compared our approach with the traditional method with case frames, anda method that uses only cooccurrence information (features 2 and 3 in section 4.An evaluation measure is an accuracy, which is defined as the number of correctlyidentified RCCs divided by the number of all RCCs.
And for inner/outer relativeclauses, precision and recall are calculated.Precision =#number of correctly identified relative clauses#number of inner/outer attempted by systemRecall =#number of correctly identified relative clauses#number of inner/outer relative clausesThe results are shown in Table 8.
The generated decision tree from all instancesis shown in Figure 1.
The last values on each line, for example ?22/2?
and ?444/6?,indicated ?number of applied examples / number of misclassification?.6.2 DiscussionAccuracy of our approach is higher than that of the traditional approach.
Ourapproach works well especially for identifying ?outer?
relative clause.
Further-more, using only cooccurrence information could not yield better performancefor ?outer?
relative clause.
Therefore, we conclude that the features in our ap-proach can effectively identify the ?outer?
relative clause.Figure 1 shows that the most contributive feature except ?excluding verb?is the degree of ?outerness?.
This feature can classify many instances with highaccuracy (98.6%=438/444).
If the degree of ?outerness?
is smaller than certainthreshold, RCC type is ?inner?
with high probability.The second contributing feature is the ?other modifier?.
If modifiers otherthan the relative clause exist, RCC type is ?inner?.
However, the accuracy of thisfeature is not so good compared with other features.We unfortunately could not find the ?tense information?
in our decision tree.We consider the reason to be that nouns which imply the concept of time arevery few, and there might be no instances which contain them.7 ConclusionsIn this paper, we presented eight lexical and semantic features that characterizedRCC, and we integrated them using machine learning approach to determine theRCC type.Evaluation proved that our approach outperformed the traditional caseframe-based method, and the features that we presented were effective in classi-fying types into ?inner?
and ?outer?
relative clauses.After identification of ?inner?
clauses, case identification will be necessary forsemantic analysis.
This will be considered in future work.Corpus-Based Analysis of Japanese Relative Clause Constructions 57References1.
Baldwin, T., Tokunaga, T. and Tanaka, H.: The parameter-based analysis ofJapanese relative clause constructions.
In IPSJ SIGNote on Natural Language 134-8 (1999) 55-622.
Baldwin, T.: Making Sense of Japanese Relative Clause Constructions.
In Proceed-ings of the Second Workshop on Text Meaning and Interpretation (2004) 49-56.3.
Dagan, I., Lee, L. and Pereira, F.: Similarity-based models of word cooccurrenceprobabilities.
Machine Learning 34 (1999) 65-814.
EDR.
: EDR electronic dictionary technical guide.
Technical Report TR045,Japanese Electronic Dictionary Research Institute Ltd (1995)5.
Ikehara, S., Shirai, S., Yokoo, A. and Nakaiwa, H.: Toward an MT system with-out pre-editing effect of new methods in ALT-J/E .
In Proceedings of the ThirdMachine Translation Summit (1991)6.
Ishizako, T., Kataoka, A., Masuyama, S., Yamamoto, K. and Nakagawa, S.: Re-duction of overlapping expressions using dependency relations.
Natural LanguageProcessing 7(4) (2000) 119-142.
(in Japanese)7.
Kawahara, D. and Kurohashi, S.: Fertilization of case frame dictionary for robustJapanese case analysis.
In Proceedings of the 19th International Conference onComputational Linguistics (2002) 425-4318.
Kurohashi, S. and Nagao, M.: Kn parser: Japanese dependency/case structure ana-lyzer.
In Proceeding of the International Workshop on Sharable Natural LanguageResources (1994) 48-559.
Lin, J.: Divergence measures based on the shannon entropy.
IEEE TRANSAC-TIONS ON INFORMATION THEORY.
37(1) (1991) 145-15110.
Manning, C. and Schutze, H.: Foundations of Statistical Natural Language Pro-cessing.
MIT Press (1999)11.
Murata, M.: Extraction of negative examples based on positive examples automaticdetection of mis-spelled Japanese expressions and relative clauses that do not havecase relations with their heads .
In IPSJ SIGNote on Natural Language 144-15(2001) 105-112.
(in Japanese)12.
Narita, H.: Parsing Japanese clauses modifying nominals.
In IPSJ SIGNote onNatural Language 99-11 (1994) 79-86.
(in Japanese)13.
Quinlan, J.: C4.5: Programs for Machine Learning.
Morgan Kaufmann (1993)14.
Teramura, H.: Rentai-shuushoku no shintakusu to imi.
No.1-4.
Nihongo Nihon-bunka 4-7 (1975-1978) (in Japanese)
