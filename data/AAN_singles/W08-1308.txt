Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 51?58Manchester, August 2008?Deep?
Grammatical Relations for Semantic InterpretationMark McConville and Myroslava O. DzikovskaInstitute for Communicating and Collaborative SystemsSchool of Informatics, University of EdinburghInformatics Forum, 10 Crichton Street, Edinburgh, EH8 9AB, Scotland{Mark.McConville,M.Dzikovska}@ed.ac.ukAbstractIn this paper, we evaluate five distinct sys-tems of labelled grammatical dependencyagainst the kind of input we require for se-mantic interpretation, in particular for thedeep semantic interpreter underlying a tu-torial dialogue system.
We focus on thefollowing linguistic phenomena: passive,control and raising, noun modifiers, andmeaningful vs. non-meaningful preposi-tions.
We conclude that no one systemprovides all the features that we require,although each such feature is containedwithin at least one of the competing sys-tems.1 IntroductionThe aim of the work reported in this paper is toevaluate the extent to which proposed systems ofgrammatical relations (GRs) reflect the kinds ofdeep linguistic knowledge required for semanticinterpretation, in particular for deriving semanticrepresentations suitable for domain reasoning indialogue systems.Grammatical relations either produced by or ex-tracted from the output of wide-coverage syntacticparsers are currently used as input to shallow se-mantic parsers, which identify semantic relationsthat exist between predicators (typically verbs) andtheir dependents (Gildea and Jurafsky, 2002; Erkand Pad?o, 2006).
Predicate-argument structureidentified in this way can then be used in tasks likeinformation extraction (Surdeanu et al, 2003) andquestion answering (Kaisser and Webber, 2007).c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.However, wide-coverage stochastic parsers areonly rarely used in dialogue systems.
Tradi-tionally, interpretation modules of dialogue sys-tems utilise specialised parsers and semantic in-terpreters handcrafted to a small domain (Seneff,1992; Chang et al, 2002), or wide coverage deepparsers (Allen et al, 2007; Jordan et al, 2006;Wolska and Kruijff-Korbayov?a, 2003; Callaway etal., 2007; Kay et al, 1994).
Unlike in informationretrieval and question answering tasks, the systemoften needs to be connected to a knowledge basewhich represents the state of the world, and mustbe able to convert user utterances into knowledgebase queries.
In addition to identifying predicate-argument relationships, such systems need to sup-port a variety of tasks, for example resolution ofpronouns and anaphors, and interpreting negation,quantification, tense and modality.While deep parsers produce precise seman-tic representations appropriate for such reason-ing, they suffer from robustness problems.
Wide-coverage dependency parsers could potentiallyprovide a more robust alternative, provided thattheir output is easy to convert into semantic rep-resentations for reasoning.Section 2 introduces the kind of deep linguis-tic processing application which motivates our ap-proach to grammatical relations.
Section 3 de-fines some underlying principles behind the kindof ?deep?
GR systemwe have in mind.
The remain-der of the paper discusses a number of linguisticphenomena in detail, and evaluates how well vari-ous systems of GR representation from the depen-dency parsing literature capture the kind of linguis-tic insights required for interface with reasoning?passive (section 4), raising and control (section 5),noun modification (section 6) and syntactic versussemantic prepositions (section 7).512 MotivationAs an example application that requires deep pars-ing consider a tutorial dialogue system that inter-prets students?
answers to factual questions (e.g.Which bulbs will be lit in this circuit?)
as wellas explanation questions (e.g.
Explain your rea-soning!).
It has been argued previously (Wolskaand Kruijff-Korbayov?a, 2004; Ros?e et al, 2003)that tutorial dialogue systems require deep under-standing of student explanations, which can havesignificantly more complex structure than databasequeries in the information-seeking domain.
In ourapplication, if a student is asked for an explana-tion, his or her input has to be passed through thedomain knowledge base to verify its factual cor-rectness, and a separate process verifies that allrelations mentioned in the explanation are correctand relevant.
For example, imagine that the stu-dent says the following:(1) The bulbs in circuits 1 and 3 will be litbecause they are in closed paths with thebatteries.Here, the system has to verify two things: (a) thatthe facts are correct (bulbs in circuits 1 and 3 willbe lit, and each of those bulbs is in a closed pathwith a battery); and (b) that the reason is valid ?being in a closed path with a battery is a necessaryand sufficient condition for a bulb to be lit.This task is particularly interesting because itcombines characteristics of deep and shallow inter-pretation tasks.
On the one hand, the fact-checkingmechanism requires a connection to the database.Thus, both pronouns and definite noun phrasesneed to be resolved to the objects they represent inthe knowledge base, and first-order logic formulasrepresenting utterance content need to be checkedagainst the system knowledge.
This task is simi-lar to natural language interfaces to databases, orknowledge acquisition interfaces that convert lan-guage into knowledge base statements (Yeh et al,2005).
On the other hand, with respect to rea-son checking, human tutors have indicated thatthey would accept an answer simply if a studentproduces the key concepts and relations betweenthem, even if the answer is not strictly logicallyequivalent to the ideal answer (Dzikovska et al,2008).
Human tutors tend to be especially lenientif a student is asked a generic question, like Whatis the definition of voltage?, which does not referto specific objects in the knowledge base.
Thus, asimpler matching mechanism is used to check thereasons, making this task more similar to an infor-mation retrieval task requiring shallower process-ing, i.e.
that the predicate-argument relations areretrieved correctly (though negation still remainsimportant).Thus, while a specific task is used to motivateour evaluation, the conclusions would be applica-ble to a variety of systems, including both deep andshallow semantic interpreters.For the purposes of this evaluation, we discussfeatures of grammatical representation relevant totwo subtasks critical for the system: (a) identify-ing predicate-argument structure; and (b) resolvinganaphora.The extraction of predicate-argument relationsis a common requirement for both shallow anddeep semantic tasks.
For example, for the stu-dent input in example (1) we may expect some-thing like:1(2) (LightBulb b1) (LightBulb b2)(lit b1 true) (lit b2 true)(Path P3) (closed P3 true)(contains P3 b1) (Path P4)(closed P4 true) (contains P4 b2)Resolving anaphora, on the other hand, is par-ticularly important for the kind of deep seman-tic processing used in dialogue systems.
Implicitin the above representation is the fact that thedefinite noun phrase the bulbs in circuits 1 and3 was resolved to domain constants b1 and b3,and indefinite references to paths were replaced bySkolem constants P3 and P4.
The reference reso-lution process requires detailed knowledge of nounphrase structure, including information about re-strictive modification, and this is the second focusof our evaluation.Ideally, we would like a dependency parser toproduce grammatical relations that can be con-verted into such semantic representations withminimal effort, thus minimising the number of spe-cific rules used to convert individual relations.
Wediscuss the principles underlying such representa-tions in more detail in the next section.1We used a simplified representation of quantifiers that as-sumes no scope ambiguity and uses skolem constants to rep-resent existential quantification.
This is sufficient for our par-ticular application.
In general, a more sophisticated quantifierrepresentation would be necessary, for example that proposedin Copestake et al (2005) or Bos and Oka (2002), but weleave the relevant evaluation for future work.523 Deep grammatical relationsWe formulated four principles for deep grammati-cal relations representation.Firstly, grammatical relations should, wheneverpossible, reflect relations between the predicators(i.e.
content words as opposed to function words)in a sentence.
In addition, the same relation shouldcorrespond to the same role assignment.
For exam-ple, the deep GRs in passive constructions shouldbe the same as those in the active equivalents(see section 4), and the analysis of a control verbconstruction like John persuaded Mary to danceshould make it clear that there is a ?subject?
GRfrom dance to Mary similar to that in the impliedsentence Mary danced (see section 5).Secondly, a GR should, whenever possible, ap-pear only if there is a an explicit selectional restric-tion link between the words.
For example, in araising verb construction like John expects Mary todance, there should be noGR from the raising verbexpects to its object Mary (see section 5).
Also,where a preposition functions strictly as a syntac-tic role marker, as in the construction John relieson Mary, it should have no place in the GR anal-ysis; rather there should be a direct link from theverb to the embedded noun phrase (see section 7).Thirdly, the GRs should preserve evidence ofsyntactic modification to enable reference resolu-tion.
To understand why this is important, take thefollowing two examples:(3) The lit bulb is in a closed path.The bulb in a closed path is lit.From a pure predicate-argument structure perspec-tive, these two sentences share exactly the samedeep GRs:2(4) ext(lit,bulb)ext(in-closed-path,bulb)However, from the perspective of reference resolu-tion, the two sentences are very different.
For thefirst example, this process involves first finding thelit bulb and then verifying that it is in a closed path,whereas for the second we need to find the bulb ina closed path and verify that it is lit.
This differ-ence can be captured by assigning the followingadditional deep GRs to the first example:2The representation is simplified for reasons of exposition.The GRs should be interpreted as follows: ext denotes theexternal argument of an adjective or preposition, ncmod anon-clausal restrictive modifier, and det the determiner of anoun.
(5) det(bulb,the)ncmod(bulb,lit)And the following GRs are added to the analysisof the second example:(6) det(bulb,the)ncmod(bulb,in-closed-path)Now the two analyses are formally distinct: (a) thefirst is rooted at predicate in a closed path and thesecond at lit; and (b) the definite external argumentthe bulb takes scope over the modifier lit in the firstbut over in a closed path in the second.
Noun mod-ification is discussed in section 6.Finally, the set of grammatical relations shouldmake it easy to identify and separate out con-structions which are largely dependent on seman-tic/world knowledge, such as N-N modification, sothat separate models and evaluations can be con-ducted as necessary.4 PassiveThe shared task dataset contains numerous passiveparticiples, most of which can be classified into thefollowing four groups depending on how the par-ticiple is used: (a) complement of passive auxiliarye.g.
Tax induction is activated by the RelA subunit;(b) complement of raising verb e.g.
The adminis-tration doesn?t seem moved by the arguments; (c)nominal postmodifier e.g.
the genes involved in T-cell growth; and (d) nominal premodifier e.g.
theproposed rules.In all these cases, our system for deep gram-matical relation annotation requires: (a) thatthere is a relation from the passive partici-ple to the deep object; and (b) that this rela-tion be the same as in the corresponding ac-tive declarative construction, so that predicate-argument structure can be straightforwardly de-rived.
Thus, for example, the analysis of Tax in-duction is activated by the RelA subunit will con-tain the GR dobj(activated,induction),and that of the proposed rules will includedobj(proposed,rules), where dobj is therelation between a transitive verb and its (deep) di-rect object.We evaluated five GR-based output formats ac-cording to these two features.
The results are pre-sented in Table 1, where for each representationformat (the rows) and each usage class of pas-sive participles (the columns), we provide the GRwhich goes from the participle to its deep object,53complement of complement of nominal nominalpassive auxiliary raising verb postmodifier premodifier activeHPSG ARG2 (of verb arg12)RASP ncsubj:obj dobjCCGBank Spss\NP N/N S\NP/[NP]Stanford nsubjpass - dobjPARC subj - objTable 1: Representation of deep objects in passive and activeif such a GR exists.3The five GR representationscompared are:HPSG predicate-argument structures extractedfrom the University of Tokyo HPSG Treebank(Miyao, 2006)RASP grammatical relations as output by theRASP parser (Briscoe et al, 2006)CCGBank predicate-argument dependencies ex-tracted from CCGBank (Hockenmaier andSteedman, 2007)Stanford grammatical relations output by theStanford Parser (de Marneffe et al, 2006)PARC dependency structures used in the annota-tion of DepBank (King et al, 2003)The first four columns in Table 1 represent, foreach of the four uses of passive participles listedabove, the grammatical relation, if any, which typ-ically joins a passive participle to its deep object.The rightmost column presents the label used forthis relation in equivalent active clauses.
Adjacentcolumns have been collapsed where the same GRis used for both uses.
The ideal system would havethe same GR listed in each of the five columns.The grammatical relations used in the Stan-ford, PARC and RASP systems are atomic labelslike subj, obj etc, although the latter systemdoes allow for a limited range of composite GRslike ncsubj:obj (a non-clausal surface subjectwhich realises a deep object).
In the HPSG sys-tem, verbal subjects and objects are representedas ARG1 and ARG2 respectively of strict transi-tive verb type verb arg12.
Finally, the GRs as-sumed in CCGBank consist of a lexical category(e.g.
the strict transitive verb category S\NP/NP)with one argument emphasised.
I assume the3The relations presented for HPSG and CCG are those forpassive participle of strict transitive verbs.following notational convenience for those cate-gories which contain specify more than one argu-ment ?
the emphasised argument is surroundedby square brackets.
Thus, subject and object of astrict transitive verb are denoted S\[NP]/NP andS\NP/[NP] respectively.With respect to Table 1, note that: (a) in theCCGbank dependency representation, althoughprenominal passive participles are linked to theirdeep object (i.e.
the modified noun), this relationis just one of generic noun premodification (i.e.N/N) and is thus irrelevant to the kind of predicate-argument relation we are interested in; (b) in thePARC and Stanford dependency representations,there is no GR from noun-modifying passive par-ticiples to their deep objects, just generic modifica-tion relations in the opposite direction; and (c) inPARC, passive participles are themselves markedas being passive, thus allowing a subsequent inter-pretation module to normalise the deep grammati-cal relations if desired.If we are interested in a system of deep gram-matical role annotation which allows for the rep-resentation of normalised GRs for passive partici-ples in all their uses, then the HPSG Treebank for-mat is more appropriate than the other schemes,since it uniformly uses deep GRs for both ac-tive and passive verb constructions.
The RASPrepresentation comes a close second, only requir-ing a small amount of postprocessing to convertncsubj:obj relations into dobj ones.
In addi-tion, both the CCGBank and the Stanford notationdistinguish two kinds of surface subject ?
thosewhich realise deep subjects, and those which re-alise passivised deep objects.5 ControlThe shared task dataset contains a number of in-finitives or participles which are dependents ofnon-auxiliary verbs or adjectives (rather than be-ing nounmodifiers for example).
Most of these can54complements adjuncts raisingHPSG 3 3 5RASP 3 3 5CCGbank 3 3 5Stanford 3 5 3PARC 5 5 5Table 2: Representation of controlled subjects andraisingbe partitioned into the following three classes: (a)complements of subject control verbs e.g.
The ac-cumulation of nuclear c-Rel acts to inhibit its owncontinued production; (b) complements of subjectraising verbs e.g.
The administration seems movedby arguments that .
.
.
; and (c) subject controlledadjuncts e.g.
Alex de Castro has stopped by to slipsix cards to the Great Man Himself.In all these cases, our deep grammatical role an-notation requires that there be a subject relation(or an object relation in the case of a passive par-ticiple) from the infinitive/participle to the surfacesubject (or surface object in the case of object con-trol) of the controlling verb/adjective.
For exam-ple, the analysis of Tax acts indirectly by induc-ing the action of various host transcription fac-tors will contain both the GRs sbj(acts,Tax)and sbj(inducing,Tax).
In addition, we alsowant to distinguish ?raising?
verbs and adjectivesfrom control structures.
Thus, in the analysis ofThe administration seems moved by argumentsthat .
.
.
, we want a (deep) object relation frommoved to administration, but we don?t want anyrelation from seems to administration.We again evaluated the various GR-based outputformats according to these features.
The results arepresented in Table 2, where for each representationformat (the rows) we determine: (a) whether a verbwith an understood subject which is a complementof the matrix verb is linked directly to its relevantsubject (column 1); (b) whether a verb with an un-derstood subject which is a controlled adjunct ofthe matrix verb is linked directly to its relevantsubject (column 2); and (c) whether raising verbsare non-linked to their surface subjects (column3).
Note that the Stanford dependency represen-tation is the only format which distinguishes be-tween raising and control.
This distinction is madeboth structurally and in terms of the name assignedto the relevant dependent ?
controlled subjectsare distinguished from all other subjects (includ-ing raised ones) by having the label xsubj ratherthan just nsubj.4The ideal GR representation format would havea tick in each of the three columns in Table 2.
It isclear that no single representation covers all of ourdesiderata for a deep grammatical relation treat-ment of control/raising, but each feature we requireis provided by at least one format.6 Nominal modifiersThe dataset contains numerous prenominal modi-fiers5, subdivided into the following three groups:(a) attributive adjectives e.g.
a few notable excep-tions; (b) verb participles e.g.
the proposed rules;and (c) nouns e.g.
a car salesman.In order to ensure an adequate representation ofbasic predicate-argument structure, our system ofdeep grammatical annotation first of all requiresthat, from each prenominal adjective or verb, thereis an appropriate relation to the modified noun, ofthe same type as in the corresponding predicativeusage.
For example, assuming that He proposedthe rules has a direct object relation from proposedto rules, the same relation should occur in the anal-ysis of the proposed rules.
Similarly, if The excep-tions are notable is analysed as having an externalargument relation from notable to exceptions, thenthe same should happen in the case of a few no-table exceptions.
However, this does not appear tohold for prenominal nouns, since the relation be-tween the two is not simply one of predication ?a car salesman is not a salesman who ?is?
a car,but rather a salesman who is ?associated?
with carsin some way.
Thus we would not want the samerelation to be used here.6Secondly, in order to ensure a straightforwardinterface with reference resolution, we need amodification relation going in the opposite direc-4We have judged that CCGBank does not make the rele-vant distinction between raising and control verbs based onthe dependency representations contained in the shared taskdataset.
For example, for the example sentence The adminis-tration seemmoved by the fact that .
.
.
, a CCG subject relationis specified from the raising verb seem to its surface subjectadministration.5We focus on prenominal modifiers in order to keep theexposition simple.
Similar remarks are valid for postnominalrestrictive modifiers as well.6Presumably the same goes for attributive adjectiveswhich lack corresponding predicative uses, e.g.
the formerpresident.55tion, from the modified noun to each (restrictive)modifier, as argued in section 2.
Thus, a completeGR representation of a noun phrase like notableexceptions would be cyclical, for example:(7) ext(notable,exceptions)ncmod(exceptions,notable)We evaluated the various GR-based output formatsaccording to these desiderata.
The results are pre-sented in Table 3.
For each annotation scheme (therows), we first present the relation (if any) whichgoes from the modified noun to each kind of pre-modifier (adjective, verb participle and noun re-spectively).7Themiddle three columns contain therelation (if any) which goes to the noun from eachkind of modifier.
Finally, the last three columnsgive the corresponding predicative relation used inthe annotation scheme, for example in construc-tions like The exceptions are notable, He proposedthe rules, or Herbie is a car.
Where it is un-clear whether a particular format encodes the re-lation between a predicative noun and its subject,we mark this as ???
in the last column.Ideally, what we want is a representation where:(a) there is a GR in all nine columns (with the pos-sible exception of the ?noun modifier to noun?
one(column 6)); (b) the corresponding relations in themiddle and righthand sections are identical, exceptfor ?noun modifier to noun?
(column 6) and ?pred-icative noun?
(the last column) which should bedistinct, since the relation between a noun modifierand its head noun is not simply one of predication.It is clear that no one representation is perfect,though every feature we require is present in atleast one representation system.
Note in particu-lar that the HPSG, PARC and Stanford systems areacyclic ?
the former only has ?modifier to noun?links, while the latter two only have ?noun to mod-ifier?
ones.
The RASP format is cyclic, at least forprenominal participles ?
in the proposed rules,there is a modifier relation from rules to proposed,as well as a deep object relation from proposed torules, the same relation that would be found in thecorresponding predicative the rules were proposed.Note finally that the PARC and Stanford repre-sentations distinguish between prenominal adjec-tives and nouns, in terms of the name of the rele-vant modifier GR.
This corresponds well with our7Note that the N/N links in the CCG representation actu-ally go from the modifier to the noun.
However, they havebeen included in the set of ?noun to modifier?
relations sincethey are formally modifier categories (i.e.
of the form X/X).preference for a GR system where we can evalu-ate modules of N-N disambiguation (e.g.
luxurycar salesman) in isolation from other aspects ofprenominal structure.7 PrepositionsAll five grammatical relations formats treat prepo-sition phrases in pretty much the same way: (a)there is a GR link from the head of which the PPis a complement or modifier to the preposition it-self (the HPSG representation has this link goingin the opposite direction for PP modifiers, but theprinciple is the same); and (b) there is a link fromthe preposition to its complement NP.
For example,the noun phrase experts in Congress is annotated asfollows:(8) ncmod(experts,in)dobj(in,Congress)The only PPs which have been handled differentlyare agentive by-PPs of passive participles, whichare either normalised or treated using a special,construction-specific GR.Note however that all prepositions are not equalwhen it comes down to representing the predicate-argument structure of a sentence.
In a nutshell,some prepositions are predicators (e.g.
expertsin Congress) whereas others are simply syntacticrole markers (e.g.
a workout of the Suns).
Ide-ally, we would want a GR system which marksthis distinction, for example by annotating pred-icator prepositions as lexical heads and ignoringrole-marking prepositions altogether.
The onlyGR scheme which attempts to make this distinc-tion is the PARC system, which has a ptype fea-ture for every preposition with two possible val-ues, semantic and non-semantic.
However,this does not appear to have been annotated consis-tently in the PARC dataset ?
the only examples ofnon-semantic prepositions are agentive by-PPs ofpassive participles.8 ConclusionWe have proposed a set of principles for devel-oping a grammatical relation annotation systemfor use with both shallow and deep semantic in-terpretation systems, in particular a tutorial dia-logue system.
We then evaluated five different GRschemes from the dependency parsing literaturebased on how well they handle a number of ?deep?syntactic phenomena implied by these principles,56noun to modifier modifier to noun predicativeA V N A V N A V NRASP ncmod - ncsubj etc - - ncsubj etc -HPSG - a arg1 v arg1 etc n arg1 a arg1 v arg1 etc n arg1CCG N/N - N/N - S\NP etc - Sadj\NP S\NP etc ?PARC adjunct mod - subj subj ?Stanf amod nn - nsubj nsubj ?Table 3: Representation of prenominal modifiersi.e.
passive, control and raising, noun modifica-tion, and meaningful vs. non-meaningful prepo-sitions.
We conclude that none of the proposedGR annotation schemes contains everything we re-quire for deep semantic processing, although eachof the features/distinctions we included in our listof desiderata is provided by at least one system.Many of the deep syntactic phenomena dis-cussed here are known issues for shallow seman-tic tasks like semantic role labelling.
For exam-ple, passive constructions are a recognised sourceof noise in semantic role labelling systems (Gildeaand Jurafsky, 2002), and resolving controlled sub-jects provides more data for training models of se-lectional restrictions, which are known to be usefulfeatures for role labelling.
More generally, Chenand Rambow (2003) demonstrate that a focus on?deep?
syntactic features results in a more accuratestochastic semantic role labeller than using surfaceinformation alone.Note also that the deep grammatical role rep-resentation proposed here is meant to be ?theory-neutral?, in the sense that it was not influenced byany one of the competing grammar formalisms tothe exclusion of the others.
Indeed, it should bea straightforward task to write a grammar usingeither the HPSG, LFG, CCG or RASP-style un-derlying formalism which can produce an outputrepresentation consisting of deep relations, con-structed in a purely compositional manner.
Indeed,the syntactic phenomena discussed in this paperare those which form the basis of numerous in-troductory textbooks on English generative syntax(Haegeman, 1994; Sag and Wasow, 1999; Bres-nan, 2000).
In addition, the phenomena whichform the basis of the analysis in this paper wereamong those which had been the focus of a sig-nificant amount of attention in the developmentof the semantic interpretation system underlyingour domain-independent tutorial dialogue system.Other issues which were considered, but for whichwe lack space to discuss in detail include: (a) ex-pletive pronouns should be ignored, i.e.
the subjectpronouns in ?impersonal?
verb constructions like Itis raining or It?s great that John loves Mary shouldnot be seen as the target of deep grammatical re-lations; (b) unbounded dependencies should be re-solved, i.e.
in the relative clause the woman Billthinks John loves there should be an object relationbetween the embedded verb loves and its extractedobject woman; (c) restrictive and non-restrictivemodification (including apposition) should be dis-tinguished, since the latter is not relevant for refer-ence resolution; and (d) certain subsentential con-junctions need to be compiled out (for exampleslike electronic, computer and building products).Finally, we recognise that, in many cases, it ispossible to transform parser representations intoour desired format.
For example, if the parser out-put tells us that a given verb form is a passiveparticiple, we can use this information to remapthe surface relations, thus retrieving the underlyingpredicate-argument structure.
However, we pre-fer a system where this kind of post-processingis not needed.
Reasons for this include the in-creased potential for error in a system relying onpost-processing rules, as well as the need to haveboth detailed documentation for how each parseroutput format handles particular constructions, aswell as a comprehensive mapping schema betweenrepresentations.
Having a community standard forGR-based parser output is an essential element offuture parsing technology, and to be practicallyuseful in a range of semantic interpretation tasks,this standard should involve ?deep?
syntactic dis-tinctions of the kind discussed in this paper.9 AcknowledgementsThe work reported here was supported by grantsN00014-08-1-0179 and N00014-08-1-0043 fromthe Office of Naval Research.57ReferencesAllen, James, Myroslava Dzikovska, Mehdi Manshadi,and Mary Swift.
2007.
Deep linguistic processingfor spoken dialogue systems.
In Proceedings of theACL?07 Workshop on Deep Linguistic Processing.Bos, Johan and Tetsushi Oka.
2002.
An inference-based approach to dialogue system design.
In Pro-ceedings of COLING?02.Bresnan, Joan.
2000.
Lexical-Functional Syntax.
BasilBlackwell.Briscoe, Ted, John Carroll, and Rebecca Watson.
2006.The second release of the RASP system.
In Pro-ceedings of the COLING/ACL?06 Interactive Presen-tation Sessions.Callaway, Charles B., Myroslava Dzikovska, ElaineFarrow, Manuel Marques-Pita, Colin Matheson, andJohanna D. Moore.
2007.
The Beetle and BeeDifftutoring systems.
In Proceedings of SLaTE?07.Chang, N., J. Feldman, R. Porzel, and K. Sanders.2002.
Scaling cognitive linguistics: Formalismsfor language understanding.
In Proceedings ofScaNaLU?02.Chen, John and Owen Rambow.
2003.
Use of deeplinguistic features for the recognition and labeling ofsemantic arguments.
In Proceedings of EMNLP?03.Copestake, Ann, Dan Flickinger, Carl Pollard, andIvan A.
Sag.
2005.
Minimal Recursion Semantics:An Introduction.
Research on Language and Com-putation, 3:281?332.de Marneffe, Marie-Catherine, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProceedings of LREC?06.Dzikovska, Myroslava O., Gwendolyn E. Campbell,Charles B. Callaway, Natalie B. Steinhauser, ElaineFarrow, Johanna D. Moore, Leslie A. Butler, andColin Matheson.
2008.
Diagnosing natural lan-guage answers to support adaptive tutoring.
In Pro-ceedings of FLAIRS?08 special track on IntelligentTutoring Systems.Erk, Katrin and Sebastian Pad?o.
2006.
SHAL-MANESER - a toolchain for shallow semantic pars-ing.
In Proceedings of LREC?06.Gildea, Daniel and Daniel Jurafsky.
2002.
Automaticlabeling of semantic roles.
Computational Linguis-tics, 28(3).Haegeman, Liliane.
1994.
Introduction to Governmentand Binding Theory.
Basil Blackwell, 2nd editionedition.Hockenmaier, Julia and Mark Steedman.
2007.
CCG-bank: a corpus of CCG derivations and dependencystructures extracted from the Penn Treebank.
Com-putational Linguistics, 33(3).Jordan, Pamela, Maxim Makatchev, Umarani Pap-puswamy, Kurt VanLehn, and Patricia Albacete.2006.
A natural language tutorial dialogue systemfor physics.
In Proceedings of FLAIRS?06.Kaisser, Michael and Bonnie Webber.
2007.
Questionanswering based on semantic roles.
In Proceedingsof the ACL?07 Workshop on Deep Linguistic Pro-cessing.Kay, Martin, Jean Mark Gawron, and Peter Norvig.1994.
Verbmobil: A Translation System for Face-To-Face Dialog.
CSLI Press, Stanford, CA.King, Tracy Holloway, Richard Crouch, Stefan Rie-zler, Mary Dalrymple, and Ronald M. Kaplan.
2003.The PARC 700 dependency bank.
In Proceedings ofEACL?03.Miyao, Yusuke.
2006.
From Linguistic Theory to Syn-tactic Analysis: Corpus-Oriented Grammar Devel-opment and Feature Forest Model.
Ph.D. thesis, Uni-versity of Tokyo.Ros?e, C. P., D. Bhembe, S. Siler, R. Srivastava, andK.
VanLehn.
2003.
The role of why questions in ef-fective human tutoring.
In Proceedings of AIED?03.Sag, Ivan A. and Thomas Wasow.
1999.
Syntactic The-ory: A Formal Introduction.
CSLI.Seneff, Stephanie.
1992.
TINA: A natural languagesystem for spoken language applications.
Computa-tional Linguistics, 18(1).Surdeanu, Mihai, Sanda M. Harabagiu, John Williams,and Paul Aarseth.
2003.
Using predicate-argumentstructures for information extraction.
In Proceedingsof ACL?03.Wolska, Magdalena and Ivana Kruijff-Korbayov?a.2003.
Issues in the interpretation of input in mathe-matical dialogs.
In Duchier, Denys, editor, Prospectsand advances in the syntax/semantics interface.Lorraine-Saarland Workshop Series proceedings.Wolska, Magdalena and Ivana Kruijff-Korbayov?a.2004.
Analysis of mixed natural and symbolic lan-guage input in mathematical dialogs.
In Proceedingsof ACL?04.Yeh, Peter Z., Bruce Porter, and Ken Barker.
2005.Matching utterances to rich knowledge structures toacquire a model of the speaker?s goal.
In Proceed-ings of K-CAP?05.58
