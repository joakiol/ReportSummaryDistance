Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 332?336,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsWhich Tumblr Post Should I Read Next?Zornitsa KozarevaYahoo!701 First AvenueSunnyvale, CA 94089zornitsa@kozareva.comMakoto YamadaInstitute of Chemical ResearchKyoto UniversityGokasho, Uji, 611-0011, Japanmyamada@kuicr.kyoto-u.ac.jpAbstractMicroblogging sites have emerged as ma-jor platforms for bloggers to create andconsume posts as well as to follow otherbloggers and get informed of their updates.Due to the large number of users, and thehuge amount of posts they create, it be-comes extremely difficult to identify rel-evant and interesting blog posts.In this paper, we propose a novel con-vex collective matrix completion (CCMC)method that effectively utilizes user-itemmatrix and incorporates additional user ac-tivity and topic-based signals to recom-mend relevant content.
The key advantageof CCMC over existing methods is that itcan obtain a globally optimal solution andcan easily scale to large-scale matrices us-ing Hazan?s algorithm.
To the best of ourknowledge, this is the first work which ap-plies and studies CCMC as a recommen-dation method in social media.
We con-duct a large scale study and show signif-icant improvement over existing state-of-the-art approaches.1 IntroductionThe usage of social media sites has significantlyincreased over the years.
Every minute people up-load thousands of new videos on YouTube, writeblogs on Tumblr1, take pictures on Flickr and In-stagram, and send messages on Twitter and Face-book.
This has lead to an information overloadthat makes it hard for people to search and dis-cover relevant information.Social media sites have attempted to mitigatethis problem by allowing users to follow, or sub-scribe to updates from specific users.
However, as1www.tumblr.comthe number of followers grows over time, the in-formation overload problem returns.
One possiblesolution to this problem is the usage of recommen-dation systems, which can display to users itemsand followers that are related to their interests andpast activities.Over time recommender methods have signifi-cantly evolved.
By observing the history of user-item interactions, the systems learn the prefer-ences of the users and use this information to ac-curately filter through vast amount of items andallowing the user to quickly discover new, inter-esting and relevant items such as movies, clothes,books and posts.
There is a substantial bodyof work on building recommendation systems fordiscovering new items, following people in socialmedia platforms, predicting what people like (Pu-rushotham et al, 2012; Chua et al, 2013; Kim etal., 2013).
However, these models either do notconsider the characteristics of user-item adoptionbehaviors or cannot scale to the magnitude of data.It is important to note that the problem of rec-ommending blog posts differs from the traditionalcollaborative filtering settings, such as the Net-flix rating prediction problem in two main as-pects.
First, the interactions between the usersand blogs are binary in the form of follows andthere is no explicit rating information availableabout the user?s preference.
The follow informa-tion can be represented as an unidirectional un-weighted graph and popular proximity measuresbased on the structural properties of the graph havebeen applied to the problem (Yin et al, 2011).Second, the blog recommendation inherently hasricher side information additional to the conven-tional user-item matrix (i.e.
follower graph).In Tumblr, text data includes a lot of informa-tion, since posts have no limitation in length, com-pared to other microblogging sites such as Twit-ter.
While such user generated content charac-332terizes various blogs, user activity is a more di-rect and informative signal of user preference asusers can explicitly express their interests by lik-ing and reblogging a post.
This implies that userswho liked or reblogged the same posts are likelyto follow similar blogs.
The challenge is how tocombine multiple sources of information (text andactivity) at the same time.
For the purpose, wepropose a novel convex collective matrix comple-tion (CCMC) social media recommender model,which can scale to million by million matrix usingHazan?s algorithm (Gunasekar et al, 2015).Our contributions are as follows:?
We propose a novel CCMC based Tumblr blogpost recommendation model.?
We represent users and blogs with an exten-sive set of side information sources such as theuser/blog activity and text/tags.?
We conduct extensive experimental evaluationson Tumblr data and show that our approach sig-nificantly outperforms existing methods.2 Convex Collective Matrix CompletionIn this section, we formulate the Tumblr blog postrecommendation task as collective matrix factor-ization problem and we describe our large-scaleconvect collective matrix completion method withHazan?s algorithm (Gunasekar et al, 2015).2.1 Model DescriptionLetX1?
{0, 1}nr1?nc1denote the user-blog (fol-lower) matrix, where nr1is the number of usersand nc1is the number of blogs.
In this matrix,if the user i likes blog j, the (i, j)th element isset to 1.
In addition to the user-blog matrix, wehave other auxiliary matrices denoted by X2?Rnr2?nc2and X3?
Rnr3?nc3.
For example, ifwe have an user activity matrix, we can use it asX2, where nr2= nr1and nc2is the number ofactivities.
Moreover, if we have the content infor-mation of articles, we can use them as X3.
In thiscase, nc1= nc3is the number of blogs, and nr3isthe number of topics in LDA.
Note that, X1tendsto be a sparse matrix, while X2and X3tend to bedenser matrices.
The final goal is to factorize X1with the help of the auxiliary matrices X2and/orX3.
First, we form a large matrix M by concate-nating all matrices [Xv]Vv=1and then factorizingM together with the regularizations.In this paper, we adopt a convex approach(Bouchard et al, 2013; Gunasekar et al, 2015).For example, for V = 3 , the matrix M is givenasM =?????
X1X2?X>1?
?
X3X>2?
?
??
X>3?
?????.
(1)This framework is called convex collective ma-trix completion (CMC) (Singh and Gordon, 2008).The key advantage of the CCMC approach is thatthe sparse user-blog matrix X1is factorized pre-cisely with the help of the dense matrices X2and/or X3.
Moreover, it has been recently shownthat the sample complexity of the CCMC algo-rithm can be smaller than that of the simple matrixfactorization approach (i.e., only factorize X1)(Gunasekar et al, 2015).
Finally, the CCMCmethod can easily incorporate multiple sources ofinformation.
Over time if Tumblr provides newsignals or if we decide to incorporate new features,CCMC can easily adopt them.
Therefore, we be-lieve that CCMC is very suitable for solving theTumblr recommendation task.2.2 CCMC-Hazan AlgorithmOne of the key challenges of CCMC for Tum-blr data is the scalability, since Tumblr has morethan million users and hundred millions of blogposts.
The original CCMC approach adopts Sin-gular Value Thresholding (SVT) to solve the prob-lem, and it works for small scale problems.
How-ever, SVT needs to solve N ?
N dimensionaleigenvalue decomposition on each iteration, andthus it is not feasible to deal directly with theTumblr data.
Recently, Gunasekar et al pro-posed an Atomic norm minimization algorithm forCCMC (Gunasekar et al, 2015) using the approx-imate SDP solver of Hazan (Hazan, 2008; Jaggiand Sulovsky, 2010).
The optimization problem isgiven asminZ0V?v=1?P?v(Xv?
Pv(Z))?2Fs.t.
tr(Z) ?
?, (2)where ?X?Fis the Frobenius norm of matrix X ,P?v, which extracts the elements in the set, ?visthe set of non-zero indexes ofXv, Pv(Z) = Zv?Rnrv?ncv, and ?
?
0 is a regularization parameter.The Hazan?s algorithm for CMF is summarized inAlgorithm 1.333Algorithm 1 CCMC with Hazan?s Algorithm of(2)Parameters: T (Number of iterations)Rescale loss:?f?
(Z) =?v?P?v(Xv?
Pv(?Z))?2FInitialize Z(1)for all t = 1, 2 .
.
.
, T =4doCompute u(t) = approxEV(???f?
(Z(t)), 1t2)2?t:=22+tZ(t+1) = Z(t) + ?tu(t)u(t)>end forreturn [Pv(Z(T ))]Vv=1The advantage of CCMC-Hazan is that it needsto compute only a top eigenvector on each itera-tion.
Practically, on each iteration t in Algorithm1, we just need to compute an1t2-approximatelargest eigenvalue of the sparse matrix with |?|non-zero elements, which needs O(|?|t) compu-tation using Lanczos algorithm.
On the otherhand, the original CCMC algorithms adopt Sin-gular Value Thresholding (SVT) method, whichconverges much faster than CCMC-Hazan.
How-ever, the SVT approach has to compute all eigen-values in each iteration.
Thus, CCMC-Hazan ismore suited for large-scale dataset than CCMC-SVT.
The details of CMC with Hazan?s algorithm,please refer to (Gunasekar et al, 2015).3 Task DefinitionWe define our task as given a set of users and theirTumblr post adoption behavior over a period oftime, the goal is to build a model that can discoverand recommend relevant Tumblr posts to the users.3.1 Evaluation Setup and DataWe set up our Tumblr post evaluation frameworkby considering the posting or reblogging of anitem j by a user i as an adopted item, and other-wise as unadopted.
We present each user with topk items sorted by their predicted adoption scoreand evaluate how many of the recommended items(posts) were actually adopted by the users.For our post recommendation study, we usedTumblr data from July until September.
We usedthe data from July to August for training, andtested on the data from September.
This experi-mental set up simulates A/B testing.From the derived data, we sampled 15, 000 ac-tive users and 35, 000 posts resulting in 5 millionuser-item adoptions for training and 8.6 millionuser-item adoptions for testing.2approxEV(X, )computes the approximate top eigenvector of X upto  error.In post recommendation our CCMC-Hazanmethod uses an user-item matrix X1?
{0, 1}15000?35000and an item-topic matrix X2?R35000?1000.
To learn the topics we use LatentDirichlet Allocation (LDA) (Blei et al, 2003).
Werepresent a document as a collection of post de-scription, captions and hashtags.
We use 1000topics for our experiments.
Figure 1 shows someexamples of the learned topics from the Tumblrposts.Figure 1: LDA.3.2 Evaluation MetricsTo evaluate the performance of our collaborativematrix factorization approach for Tumblr post rec-ommendation, we calculate precision (P), recall(R) and normalized discounted cumulative gain(nDCG) for top-k recommended posts.-P@k as the fraction of adopted items byeach user in top-k items in the list.
We aveageprecision@k across all users.-R@k as the fraction of adopted items that aresuccessfully discovered in top-k ranked list outof all adopted items by each user.
We averagerecall@k across all users.-nDCG@k computes the weighted score ofadopted items based on the position in the top-klist.
We average nDCG@k of all users.We set k to 10 since recommending too manyposts is unrealistic.
While nDCG@k uses the po-sition of correct answer in the top-k ranked list,it does not penalize for unadopted posts or miss-ing adopted posts in the top-k ranked list.
There-fore, to judge the performance of the algorithms,one has to consider all three metrics together.
In-tuitively a good performing model is the one thathas high P@k, R@k and nDCG@k.3.3 Comparison Against State-of-art ModelsIn addition to evaluating the performance of ouralgorithm on Tumblr post recommendation, we334also conducted a comparative study against exist-ing state-of-the-art models.Item-based3The item-based model recommendsitems that are similar to what the users have al-ready adopted (Karypis, 2001).
The model doesnot use textual information and only uses adopteditems to compute the similarity between the items.The similarity metric is the Tanimoto Coefficient,which is used to handle binary ratings.User-based The user-based model recommendsitems that are adopted by other users with simi-lar taste (Herlocker et al, 1999).
The model doesnot use textual information and only uses adopteditems to compute the similarity between the users.Similar to the item-based recommendation, we usethe Tanimoto Coefficient.
We choose top k itemsusing k-Nearest Neighbor of similar users.MC4Alternating least squares (ALS) is ma-trix completion (MC) based collaborative filter-ing model, which was originally introduced tomodel user-movie rating prediction using mean-square loss function with weighted ?
regulariza-tion (Zhou et al, 2008).
The model does not usetextual information or signals for adopted items.PMC5Probabilistic Matrix Completion(Salakhutdinov and Mnih, 2008) is a proba-bilistic linear model with Gaussian observationnoise that handles very large data sets and isrobust to sparse user-item matrix.
Similar toMC, PMC models the user-item adoption as theproduct of two K-dimensional lower-rank userand item hidden variables.
The model does notuse textual information, but unlike the previousmethods it uses information on unadopted items.CF Collaborative Filtering model with softmaxfunction (Guadagni and Little, 1983; Manski,1975; McFadden, 1974) captures the adoption andun-adoption behavior of users on items in socialmedia.
The model does not use textual informa-tion, but it uses signals on unadopted items.
CFallows us to study the gain of performance in postrecommendation when softmax function is usedinstead of the objective functions used in MC andPMC.CTR Collaborative Topic Regression (Wang andBlei, 2011) was originally introduced to recom-mend scientific articles.
It combines collabora-tive filtering PMC and probabilistic topic model-3https://mahout.apache.org4www.graphlab.org5http://www.cs.cmu.edu/ chongw/citeulike/Method PRC@10 RCL@20 AUCItem-based 0.24 0.08 0.42User-based 0.32 0.11 0.51MC 0.31 0.11 0.52PMC 0.35 0.12 0.55CF 0.36 0.13 0.56CTR 0.39 0.14 0.59CCMC-Hazan 0.41 0.16 0.61Table 1: Tumblr Post Recommendation Resultsing LDA.
It captures two K-dimensional lower-rank user and item hidden variables from user-itemadoption matrix and the content of the items.
Thismodel uses textual information and signal for un-adopted items.3.4 ResultsTable 1 shows the obtained results of the proposedCCMC-Hazan method against the remaining rec-ommendation models.
The simple user and itembased recommendations have the lowest perfor-mance.
This shows that for accurate post rec-ommendation using direct post and user informa-tion is insufficient and one needs stronger contextdriven signals.
This is shown in the performanceof the CF and CTR methods, which model contextinformation with LDA and perform better than therest of the models.However, when we compare the performanceof our collaborative matrix completion method,we can see that the rest of the models have sig-nificantly lower performance.
The main reasonsare due to the dense information of CCMC-Hazanmethod and the fact that our method optimizes aconvex function whereas the MC, CF and CTFmodels can get stuck in local optima.4 ConclusionsRecommending blog posts is one of the majortasks for user engagement and revenue generationin online microblogging sites such as Tumblr.
Inthis paper, we propose a convex collective matrixcompletion based recommendation method thateffectively utilizes the user-item matrix as wellas rich side information from users and/or items.We evaluate the proposed method on real-worlddataset collected from Tumblr.
Extensive exper-iments demonstrate the effectiveness of the pro-posed method in comparison to existing state-of-the-art approaches.335AcknowledgementWe would like to thank the anonymous review-ers for their valuable feedback and grant MEXTKAKENHI #16K16114.ReferencesDavid Blei, Andrew Ng, and Michael Jordan.
2003.Latent dirichlet alocation.
The Journal of MachineLearning Research, 3:993?1022.Guillaume Bouchard, Shengbo Guo, and Dawei Yin.2013.
Convex collective matrix factorization.
InAISTATS.Freddy Chong Tat Chua, Hady W. Lauw, and Ee-PengLim.
2013.
Generative models for item adoptionsusing social correlation.
IEEE Trans.
on Knowl.
andData Eng., 25:2036?2048.Peter M Guadagni and John DC Little.
1983.
A logitmodel of brand choice calibrated on scanner data.Marketing science, 2(3):203?238.Suriya Gunasekar, Makoto Yamada, Dawei Yin, andYi Chang.
2015.
Consistent collective matrix com-pletion under joint low rank structure.
In AISTATS.Elad Hazan, 2008.
Sparse Approximate Solutions toSemidefinite Programs, pages 306?316.
SpringerBerlin Heidelberg.Jonathan L. Herlocker, Joseph A. Konstan,Al Borchers, and John Riedl.
1999.
An algo-rithmic framework for performing collaborativefiltering.
In SIGIR.Martin Jaggi and Marek Sulovsky.
2010.
A simplealgorithm for nuclear norm regularized problems.
InICML.George Karypis.
2001.
Evaluation of item-based top-nrecommendation algorithms.
In CIKM.Jihie Kim, Jaebong Yoo, Ho Lim, Huida Qiu, ZornitsaKozareva, and Aram Galstyan.
2013.
Sentimentprediction using collaborative filtering.
In ICWSM.Charles F Manski.
1975.
Maximum score estimationof the stochastic utility model of choice.
Journal ofEconometrics, 3(3):205?228.Daniel McFadden.
1974.
Conditional logit analysis ofqualitative choice behavior.
In Frontiers in Econo-metrics, pages 105?142.Sanjay Purushotham, Yan Liu, and C.-C. Jay Kuo.2012.
Collaborative topic regression with socialmatrix factorization for recommendation systems.CoRR.Ruslan Salakhutdinov and Andriy Mnih.
2008.Bayesian probabilistic matrix factorization usingmarkov chain monte carlo.
In ICML.Ajit P. Singh and Geoffrey J. Gordon.
2008.
Relationallearning via collective matrix factorization.
In KDD.Chong Wang and David M. Blei.
2011.
Collaborativetopic modeling for recommending scientific articles.In KDD.Dawei Yin, Liangjie Hong, and Brian D Davison.2011.
Structural link analysis and prediction in mi-croblogs.
In CIKM.Yunhong Zhou, Dennis Wilkinson, Robert Schreiber,and Rong Pan.
2008.
Large-scale parallel collabo-rative filtering for the netflix prize.
In AAIM.336
