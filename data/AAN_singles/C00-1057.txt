Robust Segmentation of Japanese Text into a Lattice for ParsingGary Kaemarcik, Chris Brockett, Hisami SuzukiM icrosofl ResearchOne Microsoft WayRedmond WA, 98052 USA{ garykac,chrisbkt, hisamis }@in i croso ft.comAbstractWe describe a segmentation component thatutilizes minimal syntactic knowledge to produce alattice of word candidates for a broad coverageJapanese NL parser.
The segmenter is a finitestate morphological nalyzer and text normalizerdesigned to handle the orthographic variationscharacteristic of written Japanese, includingalternate spellings, script variation, vowelextensions and word-internal parentheticalmaterial.
This architecture differs from con-ventional Japanese wordbreakers in that it doesnot attempt to simultaneously attack the problemsof identifying segmentation candidates andchoosing the most probable analysis.
To minimizeduplication of effort between components and togive the segmenter greater fi'eedom to addressorthography issues, the task of choosing the bestanalysis is handled by the parser, which has accessto a much richer set of linguistic information.
Bymaximizing recall in the segmenter and allowing aprecision of 34.7%, our parser currently achieves abreaking accuracy of ~97% over a wide variety ofcorpora.IntroductionThe task of segmenting Japanese text into wordunits (or other units such as bunsetsu (phrases))has been discussed at great length in Japanese NLliterature (\[Kurohashi98\], \[Fuchi98\], \[Nagata94\],et al).
Japanese does not typically have spacesbetween words, which means that a parser mustfirst have the input string broken into usable unitsbefore it can analyze a sentence.
Moreover, avariety of issues complicate this operation, mostnotably that potential word candidate records mayoverlap (causing ambiguities for the parser) orthere may be gaps where no suitable record isfound (causing a broken span).These difficulties are commonly addressed usingeither heuristics or statistical methods to create amodel for identifying the best (or n-best) sequenceof records for a given input string.
This istypically done using a connective-cost model(\[Hisamitsu90\]), which is either maintainedlaboriously by hand, or trained on large corpora.Both of these approaches uffer fiom problems.Handcrafted heuristics may become a maintenancequagmire, and as \[Kurohashi98\] suggests in hisdiscussion of the JUMAN scgmenter, statisticalmodels may become increasingly fi'agile as thesystem grows and eventually reach a point whereside effects rule out fiwther improvements.
Thesparse data problem commonly encountered instatistical methods is exacerbated in Japanese bywidespread orthographic variation (see ?3).Our system addresses these pitfalls by assigningcompletely separate roles to the segmeuter and theparser to allow each to delve deeper into thecomplexities inherent in its tasks.Other NL systems (\[Kitani93\], \[Ktu'ohashi98\])have separated the segmentation and parsingcomponents.
However, these dual-level systemsare prone to duplication of effort since mauysegmentation ambiguities cannot be resolvedwithout invoking higher-level syntactic orsemantic knowledge.
Our system avoids thisduplication by relaxing the requirement that thesegmenter identify the best path (or even n-bestpaths) through the lattice of possible records.
Thesegmenter is responsible only for ensuring that acorrect set of records is present in its output.
It isthe filnction of the parsing component to select hebest analysis from this lattice.
With tiffs model,our system achieves roughly 97% recall/precision(see \[Suzuki00\] for more details).1 System OverviewFigure shows a simple block diagram of ourNatural Language Understanding system forJapanese, the goal of which is to robustly producesyntactic and logical forms that allow automatic390Word Segmentationl{\[ Dcrivational .,\sscmhl~ ISyntactic Analysis \]\[ \[,ogical Form \],0 ( )rthograph.vl.exiconSyntaxI.cxicon%Figure 1: Block diagram of Japanese NL systemextraction of semantic relationships (see\[Richardson98\]) and support other lirlguisticprojects like information retrieval, NL interfacesand dialog systems, auto-.summarization andmachine translation.The segmenter is the frst level of' processing.
Thisis a finite-state morphological nalyzer esponsiblefor generating all possible word candidates into aword lattice.
It has a custom lexicon (auto:matically derived from the main lexicon to ensureconsistency) that is designed to facilitate theidentification of orfllographic variants.Records representing words and morphemes arehanded off by the segmenter to the derivationalassembly component, which uses syntax-like rulesto generate additional derived forms that are thenused by the parser to create syntax trees and logicalforms.
Many of the techniques here are similar towhat we use in our Chinese NI., system (see\[Wu98\] for more details).The parser (described exterisively in \[Jensen93\])generates syntactic representatioris arm logicalforms.
This is a bottomoup chart parser withbinary rnles within the Augnmnted PhraseStructure Grammar formalism.
The grammar rulesare language--specific while the core engine isshared among 7 languages (Chinese, Japanese,Korean, English, French, German, Spanish).
TheJapanese parser is described in \[Suzuki00\].2 Recall vs?
PrecisionIn this architecture, data is fed forward from oneCOlnponent to the next; hence, it is crucial that thebase components (like the segmenter) generate aminimal number of omission errors.Since segmentation errors may affect subsequentcomponents, it is convenient to divide these errorsinto two types: recoverable and non-recoverable.A ram-recoverable error is one that prevents thesyntax (or any downstream) component fromarriving at a correct analysis (e.g., a missingrecord).
A recoverable rror is one that does notinterfere with the operation of followingcomponents.
An example of the latter is theinchision of an extra record.
This extra recorddoes not (theoretically) prevent the parser fromdoing its lob (although in practice it may since iteonsun les  resot l rces) .Using standard definitions of recall (R) andprecision (P):*~ Jr R - Seg~,,,.,.,.,., p = Seg~,,,.,.~.~.,7bg,,,,,/ &g,,,,,,iwhere Segcor~ec t and .<,egmxal are the number q/" "'cotwect"and total number o/'segments returned by the segmentet;and "\['agto~a I is the total Jlttmber of "correct" segmentsfi'om a tagged corpus,we can see that recall measures non-recoverableerrors and precision measures recoverable rrors.Since our goal is to create a robust NL system, itbehooves us to maximize recall (i.e., make veryfew non-recoverable errors) in open text whilekeeping precision high enough that the extrarecords (recoverable errors) do not interfere withthe parsing component.Achieving near-100% recall might initially seem tobe a relatively straightforward task given asufficiently large lexicon - simply return everypossible record that is found in the input string, inpractice, tile mixture of scripts and flexibleorthography rules of Japanese (in addition to theinevitable non-lexicalized words) make the task ofidentifying potential lexical boundaries aninteresting problem in its own right.3 Japanese Orthographic VariationOver tile centuries, Japanese has evolved acomplex writing system that gives tile writer agreat deal of flexibility when composing text.Four scripts are in common use (kanji, hiragana,katakana and roman), and can co-occur withinlexical entries (as shown ill Table 1).Some mixed-script entries could be handled assyntactic ompounds, for example, ID ~a---1-" /atdii kaado="ID card'7 could be derived fl'om1DNotJN + 79-- I ~ NOUN.
tlowever, many such itemsare preferably treated as lexical entries because391i!i \[~ ~ ' \[atarashii ,: "'new "\]Kanji-I l iragana I~LII~J \[ho~(vtnn'ui = "'mammal"\]~ 7/" "7 :./\[haburashi -~ "'toothbrush "\].
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.K'}n.!i-<~!P!\]!!
...................... E ( !S  ' !
t ( !Z .
/~( :GS tm! '
i  t?
::c:(';S's:vstet!
* :'1 ........12 ) J \[lmtmL, atsu - "December"/Kallji-Synlbol v ,{'~ \ [gcmma sen = "'~amma rays "\].i-3 1" 4" t/ \[otoim - "'toilet "'\]Mixed kana............................. \[ -/")3 hl~?!,,!!
?
.
;;(9 c?f~,,,~/5' ;7/ ...........II3 )-~ - -  b" \[aidtt kaado = "lP card"\]Kana-Alpha ..t .y-t~ .>"-5;-V - -RNA \[messe~gaa RA'A =................................................................. T ie~t~:s~'~lxe~ ~U.:I.
'7 ..................................7, J- U 2/-)'- ~) 2, 90 \[suloronchiumu 90 -"'Strontiunt 90 "\]Kana-Symbol I~ 2_ 7~ 40 ?
\[hoeru yonjuu do = "'roaring............................................................................ fo t : !
!~, , ; .7  .........................................................~i~ b ~" ~, \[keshigomu - "'eraser "1a >,I- 21" ~ e/ ~) ~: \[artiSt kentauri set :Other mixed"'Alpha Centauri "\]\[.
~: ~ \[togaki = "'stage directions"\]Table 1: Mixed-script lexical entriesthey have non-compositional syntactic or semanticattributes.In addition, many Japanese verbs and adjectives(and words derived from them) have a variety ofaccepted spellings associated with okurigana,optional characters representing inflectionalendings.
For example, the present ense of e)j b ~;?
;~- (kiriotosu = "to prune ") can be written as anyof: ~)Ji:~~J --, ~;)J b .."?,:t, ?
:JJTf; & ,~, ~JJb.~s&~-, ~ ~:; ~s ~ Ior even ~ ~) ~'g ~ 4-, -~ 9 7~;-~-.Matters become even more complex when onescript is substituted for another at the word or sub-word level.
This can occur for a var iety o freasons: to replace a rare or d i f f i cu l t  ka@ (.~?~\[rachi= "kMnap"\] instead of f,):~); to highlight aword in a sentence ( ~ >" t2 -h, o ~_ *) \[hennakakkou = "strange appearance '7); or to indicate aparticular, often technical, sense (7 Y o -c \[watatte="crossing over"\] instead of iA~o-c, to emphasizethe domain-specific sense of "connecting 2groups" in Go literature).More colloquial writing allows for a variety ofcontracted tbrms like ~ t~j~.\-~  ~ t~ + !=t \[ore~tacha = ore-tachi + wa = "we'" + TOPIC\] andphonological inutations as in ~d.~:--~- = -d'4 \ [dee-su ~ desu = "is "\].This is only a sampling of the orthographic issuespresent in Japanese.
Many of these variations poseserious sparse-data problems, and lexicalization ofall variants is clearly out of the questioi1.II.\]'~., ~lJ < .
.~  lt,l~L~l~;'~q ?gJ \[H/ikc,kkoku "'everyrepeat moment "'\]characters Ill ~ ~., e L I~, .~ HI :!
:~ til-!~ U ~ ' \[kaigaishu"'diligent "'\]distribution of  t: " '>" v~- ~ t:":#v\]- \[huleo "vMeo"\] voicina nl,qrkshalt\vidth &lhllwidthcompositesymbolsF M b2J~" ~ FM )/ZJ~ \[I"M housml ~ "FMbroadcast "'\];~ (i'?"
~U, "-~ 5" 4, "V <e" :>, 2, \[daivaguramu :"'diagram 'J;~; "-~ .
.
.
.
.
L" 2/ 1- \[paasento =: "percent :;\]r tz  , .
.
.
/~ ,  .
"'incorporated 'i\]N\] ~ 2 8 FI \[n!jmthactH niciu = "28 'j' day of themonth "\]Table 2: Character type normalizations4 Segmenter DesignGiven the broad long-term goals for' the overallsystem, we address the issues of recall/precisionand orthographic variation by narrowly definingthe responsibilities of the segmenter as:(i) Maximize recall(2) Normalize word variants4.1 Maxinf fze RecallMaximal recall is imperative, Any recall mistakelnade in the segmenter prevents the parser fromreaching a successful analysis.
Since the parser inour NL system is designed to handle ambiguousinput in the fbrm of a word lattice of potentiallyoverlapping records, we can accept lower precisionif that is what is necessary to achieve high recall?Conversely, high precision is specifically not agoal for the segmenter.
While desirable, highprecision may be at odds with the primary goal ofmaximizing recall.
Note that the lower bound forprecision is constrained by the lexicon.4?2 Normal ize word variantsGiven tile extensive amount of orthographicvariability present in Japanese, some form ofnormalization into a canonical form is a pre-requisite for any higher-.order linguistic processing.The segmenter performs two basic kinds ofnomlalization: \[,emmatization f inflected formsand Orthographic Norlnalization.392,~kur ieana .
.
.
.
n),: g.).
z~ -+ i,J,: ~- ~),~ :~ \[lhkmuk~ :: "drafty"/  ;5'./~ <% J)-tJ- ; '3_ \[11i1:i:;5,.,7~-\]\[ ~", ,.
,,,,.. ~ ' >\]-~J-'"o kammwaseru = 7o.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
~ !o{ ~ c!i ~s /./!,a!!{,6!
: ::e ,!:e!l?
!el<, 71 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
engage (gear.w i'a ml l .~ ' l lmor i  - "'~111 non-s tandard  tA'ct) ::~ "~ ~-0~ \]'- \[onnanoko :: "gir l"/  .;.'/.
<) ~, l) \[ ~u:<;'~-\]\[ ~ [:~-).
{,.
~') \] estimate "'script +~:t , - t  - "+ 0 :4  7, :~ \[d,s'uko : "d i sco" /  I I )  ) :2  I" \ [ l i ' , ;4 -  l l l \ ]) :<fi4 - - i :DZ i D: a/ih, kaado2:" lDc iml  '"?
D, I\] "+ " "~ Jl \[tkka,4etsu :: "one month" /  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.9:0  var iants  kagi tahako "'smf/'f --I, I!
:~ " \['~\] \[ktl.~'uml~aseki = "Kasunli~aseki "\]numera ls  fi~r 5 i\[i~ .+ ti\]!i~ \[gorm : "'Olympics "\]kalt j i  1 ),, ~ ")v \[hitori : "one person"/:t.; i Z - -  ~ ,t~, k.  ~ -~J { 2 b ' ~5 /~ \[oniisan = "'oldervovcelextens ions  brother "'\]-7 -,- 4' \]" 4 "+ 7 -," 4" I" \[/'aito 'ftght "'\]'Y - /  4- ~- 9 "../-i~ i<.
( ~- 9 "-./\[batorm - "'vloti~F7ka lakana-)" 9 :E- - -  Iv ..+ 9 ~ .
O ?
:E- --" F' \ [aramoode "'h la v ari all Is too& "'\]IPL~(!rt)2_ ~ + ll~),t 2.
".
'~ \[haeru = "'to shine "7in l ine yomi  ~ ~_lt(f:l: ~o ~I> ") )\]~(i "+l/'~ ~t JL?\[ \[hachuuruiD,3 '/, < :~' II~';L D ', ~ II:t:~'i 0:: 'J "< -~ I toDac~'o"/g;'~; V, 1-{{:/~ D;\]\[!i,~:l '  '1 na~ai "'a long visit"Table 4: Orthography latticeslexical entry.
Examples are given in "fable 3.
Twocases of special interest are okurigana and inlineyomi/kanji normalizations.
The okurigananormalization expands shortened forms into fullyspecified forms (i.e., fornls with all optional.................................
7"~'!~t!
?C'\] ..................................................................................... characters present).
Tile yomi/kanji handling takesin l ine kanj i  l Yo (N)~: i i l2d  -'~ tgs ~ft~ \[~essh~rul =: "'rodent"/Table 3: Script normalizations4.Z 1 LemmatizationLEMMATIZATION iri Japanese is the same as thatfor any language with inflected forms - a lemma,or dictionary form, is returned along with theinflection attributes.
So, a form like ~:~-7~ \[tabeta= "ate "J would retum a lemma of f,~ ~<~; \[taberu ="'eat"\] along with a PAST attribute.Contracted forms are expanded and lemmatizedindividually, so that f,~ ~<-<o ~:~ .> o ?= \[tabe~tecchatta = "has ectten and gone'7 is returned as:f~  ~-Z.
7 0 G\[-RUND -F (, x < GERUND -F L. +E ") PASr\ [taberu: "eat" + iku--++go" F s \ ]T imaz l=.
.
iSpE(7\ [ . '
\ ] .4..2.2 Orthographic Normalizatio,,ORTIIOGRAPttlC NORMALIZATION smoothes outorthographic variations o that words are returnedin a standardized form.
This facilitates lexicallookup and allows tile system to map the variantrepresentations to a single lexicon entry.We distinguish two classes of orqthographicnormalization: character type normalization andscript normalization.CI IARAC' IER  TYPE  NORMAI .
IZAT ION takes tilevarious representations allowed by the Unicodespecification and converts them into a singleconsistent form.
Table 2 summarizes this class ofnormalization.SCR.
I I ' T  NORMAI,IZAI'ION rewrites the word so thatit conforms to tile script and :~pelling used in theinfixed parenthetical material and normalizes it out(after using the parenthetical infommtion to verifysegmentation accuracy).5 Lexicon StructuresSeveral special lexicon structures were developedto support hese features.
Tile most significant isan orthography lattice* that concisely encapsulatesall orthographic variants for each lexicon entry andimplicitly specifies the normalized form.
This hasthe advantage of compactness and facilitateslexicon maintenance since lexicographic inform-ation is stored in one location.The orthography lattice stores kana inforrnationabout each kanji or group of kanji in a word.
Forexample, the lattice far the verb Y~:-<~D \[taberu ="eat'7 is \[~:#_\]-<~, because the first character(ta) can be written as either kanji 5~ or kana 1=.
Aricher lattice is needed for entries with okuriganavariants~ like LJJ 0 i'~:~ 4 \[kiriotosu = "'to prune "\]cited earlier: commas separate each okuriganagrouping.
The lattice for kiriotosu is \[OJ:~, 0 \]\[i"#:~,  E \]~j-.
Table 4 contains more lattice examples.Enabling all possible variants can proliferaterecords and confiise the analyzer (see \[Kurohashi94\]).
We therefore suppress pathological variantsthat cause confusion with more common wordsand constructions.
For example, f:L-t,q- \[n~gai = "along visit'7 never occurs as I.~ ~' since this isambiguous with the highly fi'equent adjective ~-~v,/nasal - "l<mg'7.
Likewise, a word like !t' Not to be confiised with the word lattice, which is theset of records passed fi'om the segmenter tothe parser.393\[nihon = ",Aq)an "7 is constrained to inhibit invalidvariants like 124< which cause confusion with: {cI'OSl' + # NOUN \ [ t I i : : I ' .
- tRT IC I .
I : "  + /1on  = "book  " \ ] .We default to enabling all possible orthographiesfor each ennT and disable only those that arerequired.
This saves US from having to update thelexicon whenever we encounter a novelorthographic variant since the lattice anticipates allpossible variants.6 Unknown WordsUnknown words pose a significant recall problemin languages that don't place spaces betweenwords.
The inability to identify a word in the inputstream of characters can cause neighboring wordsto be misidentified.We have divided this problem space into sixcategories: variants of lexical entries (e.g.,okurigana variations, vowel extensions, et al);non-lexiealized proper nouns; derived forms;foreign Ioanwords; mimetics; and typographicalerrors.
This allows us to devise focused heuristicsto attack each class of unfound words.The first category, variants of lexical entries, hasbeen addressed through the script normalizationsdiscussed earlier.Non-lexicalized proper nouns and derived words,which account for the vast majority of unfoundwords, are handled in the derivational assemblycomponent.
This is where compounds like -: ~ >ix ~':, ffuransugo = "French (language)"\] areassembled from their base components ;1 5~ J x\[furansu : "France "\] and at~ \[go = "language "J.Unknown foreign Ioanwords are identified by asimple maximal-katakana heuristic that returns thelongest run of katakana characters.
Despite itssimplicity, this algorithm appears to work quitereliably when used in conjunction with the othermechanisms in our system.Mimetic words in Japanese tend to follow simpleABAB or ABCABC patterns in hiragana orkatakana, so we look for these patterns andpropose them as adverb records.The last category, typographical errors, remainsmostly the subject for future work.
Currently, weonly address basic : (kanji) ~-~ -: (katakana) andi-, (hiragana) +~ : ' -  (katakana) substitutions.50%40%30%20%"10%0%15 25 35 45 55 65 75 85 95 105 115- - -~ Japanese  =-~t-=Chinese \]?
.
.
.
.
.
72 .27_~_z z zs?
27 ~ 7 ~Lz77 ~z ~25z ~ 2 7~ .
.
.
.
.
.
.
.Figure 2: Worst-case segmenter precision (y-axis) versussentence length (x-axis - in characters)7 Eva|uationOur goal is to improve the parser coverage byimproving the recall in the segmenter.
Evaluationof this component is appropriately conducted in thecontext of its impact on the entire system,Z 1 Parser EvaluationRunning on top of our segmenter, our currentparsing system reports ~71% coverage + (i.e, inputstrings for which a complete and acceptablesentential parse is obtained), and -,97% accuracyfor POS labeled breaking accuracy?
A fulldescription of these results is given in \[Suzuki00\].Z 2 Segmenter EvaluatkmThree criteria are relevant to segmenter per-formance: recall precision and speed.Z Z 1 RecallAnalysis of a randonlly chosen set of taggedsentences gives a recall of 99.91%.
This result isnot surprising since maxindzing recall was aprinlary focus of our efforts.The breakdown of the recall errors is as follows:missing proper nouns = 47%, missing nouns =15%.. missing verbs/adjs = 15%, orthographicidiosyncrasies = 15%, archaic inflections = 8%.It is worth noting that for derived forms (those thatTested on a 15,000 sentence blind, balanced corpus.See \[SuzuldO0\] fordetails.3943000 \ [ i2000 I1<':> ,# ,~, ?> e <# ~,~, e e @,, ,+>,e,eFigure 3: Characters/second (y~axis) vs. sentencelength (x-axis) for se~<ginenter alone (upper curve)and our NL system as a whole (lower curve)are tiandled in the derivational assembly corn-.ponent), tim segmenter is considered correct aslong as it produces the necessary base recordsneeded to build the derived fom-t.ZZ2 PrecisionSince we focused our effbrts on maximizing recall,,a valid concern is the impact of the extra recordson the parser, that is, the effect of lower segmenterprecision oll the system as a whole.Figure 2 shows the baselirie segrnenter precisionplotted against sentence length using the 3888tagged sentences ~: For compaiison~ data forChinese ~is included.
These are baseline vahles inthe sense they represent the riumber of recordslooked up in the lexicon without application of ariyheuristics to suppress invalid records.
Thus, thesemnnbers represent worst--case segmenter p ecision.The baseline precisior, for the Japariese segmenteraverages 24.8%, whicl-i means that a parser wouldneed to discard 3 records for each record it used inthe final parse.
TMs value stays fairly constant asthe sentence length increases.
The baselineprecision for Chir, ese averages 37.1%.
Thedisparity between the Japanese and Chinese worst-case scenario is believed to reflect the greaterambiguity inherent in the Japanese v<'riting system,owing to orthographic w~riation and the use of asyllabic script.++ The " <,<," o .~ t<%~,% was obtained by usin,,the results of theparser on untagged sentences.39112 sentences tagged in a sirnilar fashion using ourChinese NI,P system.100%70% "-:-: 5 ~ ::.::~::,~::-5..
,'i ,': ~ -"r.'-~,'~7,:'s~'-,.
: ~ :  .~ ~ ::,~ x;K< ~50%40% ~ ~ - .
---..-~30% :::::::::::::::::::::::::::::::::::::::::::::::::::::::20% :::i:!)?i:~:~)}ii!:i\]::{i)~:,x::i!illii.:i!:'-.~!!~\]:!21{7-i\[.g{:!:'7:7:~::?.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
,~< ............10% !::::::ii'::::ii!i'ii{f!}{ii'.".
'::iii::::ii0% ~'~S 215 25 35 45 55 65 75 85 95 105 115 125 135\ [BSegmenter  \ [ \ ]Lex ica l  E IDer iv  BOther  El ParserFigure 4: Percentage oftime spent in each component (y-axis) vs. sentence l ngth x-axis)Using conservative pruning heuristics, we are ableto bring the precision tip to 34.7% withoutaffecting parser recall.
Primarily, these heuristicswork by suppressing the hiragana form of shorkambiguous words (like ~ \[ki="tree, air, .slJirit,season, record, yellow,... '7, which is normallywritten using kanji to identify the intended sense).Z2..3 SpeedAnother concern with lower precision values has todo with performance measured in terms of speed.Figure 3 summarizes characters-per.-second per-formance of the segmentation component and ourNL system as a whole (irmluding the segmentationcomponent).
As expected, the system takes moretime for longer senterlces.
Crucially, however, thesystem slowdowri s shown to be roughly linear,Figure 4 shows how nluch time is spent in eachcomponent during sentence analysis.
As the sen-tence length increases, lexical lookup+ derivationalmorphology and '+other" stay approximately con-starit while the percentage of time spent in theparsing component increases.Table 5 compares parse time performance fortagged and untagged sentences.
This tableqnantifies the potential speed improvement that theparser could realize if the segmenter precision wasimproved.
Cohunn A provides baseline lexicallookup and parsing times based on untagged input.Note that segmenter time is not given this tablebecause it would not be comparable to tile hypotheticalsegmenters devised for columns P, and C.395ALexical processing 7.66 sParsing 3.480 sOther 4.
95 sTotal 25.336 sOverallPercent LexicalImprovement I'arsingOtherB c2.5 0 s 2.324 s8.865 s 7.
79 s3.620 s 3.5 9 s4.995 s 3.022 s40.82% 48.60%67.24% 69.66%34.24% 46.74%3.7 % 6.
%Table 5: Summary of performance (speed)experiment where untagged input (A) is comparedwith space-broken i put (B) and space-broken i putwith POS tags (C).Columns B and C give timings based on a(hypothetical) segmenter that correctly identifiesall word botmdaries (B) and one that identifies allword boundaries and POS (C) 1'I".
C represents thebest-case parser performance since it assumesperfect precision and recall in the segmenter.
Thebottom portion of Table ,5 restates theseimprovements a percentages.This table suggests that adding conservativepruning to enhance segmenter precision mayimprove overall system performance.
It alsoprovides a metric for evaluating the impact ofheuristic rule candidates.
The parse-timeimprovemeuts from a rule candidate can beweighed against the cost of implementing thisadditional code to determine the overall benefit othe entire system.8 FuturePlanued near-term enhancements include addingcontext-sensitive h uristic rules to the segmenter asappropriate.
In addition to the speed gainsquantified in Table 5, these heuristics can also beexpected to improve parser coverage by reducingresource requiremeuts.Other areas for improvement are unfotmd wordmodels, particularly typographical error detection,and addressing the issue of probabilities as theyapply to orthographic variants.
Additionally, weare experimenting with various lexicon formats tomore efficiently support Japanese.tt For the hypothetical segmenters, our segmenter wasmodified to return only the records consistent with atagged input set.9 ConclusionThe complexities involved in segmenting Japanesetext make it beneficial to treat this taskindependently from parsing.
These separate tasksare each simplified, thcilitating the processing of awider range of phenomenon specific to theirrespective domains.
The gains in robustnessgreatly outweigh the impact on parser performancecaused by the additional records.
Our parsingresults demonstrate that this compartmentalizedapproach works well, with overall parse timesincreasing linearly with sentence length.10 References\[Fuchi98\] Fuchi,T., Takagi,S., "JapaneseMorphological Analyzer using Word Co-occurrence",ACL/COLING 98, pp409-4 3, 998.\[Hisamitsu90\] Hisamitsu,T., Nitta, Y.,Morphological Analyis by Minimum Connective-CostMethod", SIGNLC 90-8, IEICE pp 7-24, 990 (inJapanese).\[Jensen93\] Jensen,K., Heidorn,G., Richardson,S,(eds.)
"Natural Language Processing: The PLNLPApproach", Kluwer, Boston, 993.\[Kitani93\] Kitani,T., Mitamura,T., "A JapanesePreprocessor for Syntactic and Semantic Parsing", 9 thConference on AI in Applications, pp86-92, 993.\[Kurohashi94\] Kurohashi,S., Nakamura,Y.,Matsumoto,Y., Nagao,M., "hnprovements of JapaneseMorphological Analyzer JUMAN", SNLR, pp22-28,994.\[Kurohashi98\] Kurohashi,S., Nagao,M., "Building aJapanese Parsed Corpus while hnproving the ParsingSystem", First LREC Proceedings, pp7 9-724, 998.\[Nagata94\] Nagata,M., "A Stochastic JapaneseMorphological Analyzer Using a Forward-DPBackward-A* N-Best Search Algorithm", COL1NG,pp20-207, 994.\[Richardson98\] Richardson,S.D., Dolan,W.B.,Vanderwende,L., "MindNet: Acquiring and StructuringSemantic Information from Text", COLING/ACL 98,pp 098- 02, 998.\[Suzuki00\] Suzuki,H., Brockett,C., Kacmarcik,G.,"Using a broad-coverage parser for word-breaking inJapanese", COLING 2000.\[Wu98\] Wu,A., Zixin,J., "Word Segmentation inSentence Analysis", Microsoft Technical Report MSR-TR-99- 0, 999.396
