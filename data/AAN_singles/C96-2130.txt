Learning Part-of-Speech Guessing Rules from Lexicon:Extension to Non-Concatenat ive Operations*Andre i  M ikheevHCRC Language Techno logy  GroupUn ivers i ty  of Ed inburgh2 Buccleuch PlaceEdinburgh EH8 9LW, Scotland, UK: Andrei.
Mikheev@ed.
ac.
ukAbstractOne of the problems in part-of-speechtagging of real-word texts is that ofunknown to the lexicon words.
In(Mikheev, 1996), a technique for fullyunsupervised statistical acquisition ofrules which guess possible parts-of-speech for unknown words was proposed.One of the over-simplification assumedby this learning technique was the acqui-sition of morphological rules which obeyonly simple coneatenative r gularities ofthe main word with an affix.
In this pa-per we extend this technique to the non-concatenative cases of suffixation and as-sess the gain in the performance.1 Introduct ionPart-of-speech (pos) taggers are programs whichassign a single pos-tag to a word-token, providedthat, it is known what parts-of-speech t is wordcan take on in principle.
In order to do that tag-gers are supplied with a lexicon that lists possiblel'os-tags for words which were seen at the trainingphase.
Naturally, when tagging real-word texts,one can expect to encounter words which werenot seen at the training phase and hence not in-cluded into the lexicon.
This is where word-Posguessers take their place - they employ the analy-sis of word features, e.g.
word leading and trailingcharacters to figure out its possible pos categories.Currently, most of the taggers are supplied witha word-guessing component for dealing with un-known words.
The most popular guessing strat-egy is so-called "ending guessing" when a possibleset, of pos-tags for a word is guessed solely on thebasis of its trailing characters.
An example of suchguesser is the guesser supplied with the Xerox tag-ger (Kupiec, 1992).
A similar approach was takengome of the research reported here was funded aspart of EPSRC project IED4/1/5808 "Integrated Lan-guage Database".in (Weischedel et al, 1993) where an unknownword was guessed given the probabilities for anunknown word to be of a particular pos, its cap-italisation feature and its ending.
In (Brill, 1995)a system of rules which uses both ending-guessingand more morphologically motivated rules is de-scribed.
Best of these methods were reported toachieve 82-85% of tagging accuracy on unknownwords, e.g.
(Brill, 1995; Weischedel et al, 1993).In (Mikheev, 1996) a cascading word-Posguesser is described.
It applies first morpho-logical prefix and suffix guessing rules and thenending-guessing rules.
This guesser is reported toachieve higher guessing accuracy than quoted be-fore which in average was about by 8-9% betterthan that of the Xerox guesser and by 6-7% bet-ter than that of Brill's guesser, reaching 87-92%tagging accuracy on unknown words.There are two kinds of word-guessing rules em-ployed by the cascading uesser: morphologicalrules and ending guessing rules.
Morphologicalword-guessing rules describe how one word can beguessed given that another word is known.
In En-glish, as in many other languages, morphologicalword formation is realised by affixation: prefixa-tion and suffixation, so there are two kinds of mor-phological rules: suffix rules (A '~) - rules whichare applied to the tail of a word, and prefix rules(AP)  - -  rnles which are applied to the beginningof a word.
For example, the prefix rule:AP : \[u, (VBD VBN) (JJ)lsays that if segmenting the prefix "un" from anunknown word results in a word which is foundin the lexicon as a past verb and participle (VBDVBN), we conclude that the unknown word is anadjective (J J).
This rule works, for instance, forwords \[developed -+undeveloped\].
An example of asuffix rule is:A ~ : \[ed (NN VB) (JJ VBD VBN)\]This rule says that if by stripping the suffix "ed"from an unknown word we produce a word withthe pos-class noun/verb (NN VB), the unknownword is of the class adjective/past-verb/participle(JJ VBD VBN).
This rule works, for instance, for770word l)airs \[book -+booked\], \[water -+watered\], etc.Unlike morphological guessing rules, ending-guessing rules do not require the main form of anunknown word to be listed in the lexicon.
Theserules guess a pos-c.lass for a word .just Oil the ba-sis of its ending characters and without looking upit'~ st;era in the lexicon.
For example, an ending-guessing ruleAe: \ [ ing-- -  (aa NN VBG)\]says that if a word ends with "ing" it; canbe an adjective, a noun or a gerund.
Unlikea morphological rule, this rule does not ask to(:hock whether the snbstring preceeding the "ing"-ending is a word with a particular pos-tag.Not surt)risingly, morphoh)gical guessing rulesare more accurate than ending-guessing rules linttheir lexical coverage is more restricted, i.e.
dmyare able to cover less unknown words.
Sine('.
theyal-( ~.
illore, accurate, in the cascading uesser theywere al)plied before the ending-guessing rules andimproved the pre, cision of the guessings by about5?./0.
This, actually, resulted in about 2% higheraccuracy of tagging on unknown words.Although in general the performance of the cas-cading guesser was detected to be only 6% worsethan a general-language lexicon lookup, one of theover-simt)lifications a sumed at the extraction ofi;he mort)hological rules was that they obey onlysimI)le con(:atenative r gularities:book ?
~book-}-ed; take --+take-l-n; play -4playqoing.No atteml)tS were made to model non-concatenadve cases which are quite eoinmon inEnglish, as for instance:try - ,tries; reduce-+reducing; advise-~advisable.So we thought hat the incorporation of a set ofguessing rule, s which call capture morphok)gicalword dependencies with letter alterations houldext;end the lexieal coverage of tile morphoh)gicalrules and hence might contribute to the overallguessing accuracy.In the rest of the paper first, we will I)rieflyoutline the unsupervised statistical learning tech-nique proposed in (Mikheev, 1996), then we pro-pose a modification which will allow for the incor-poration of the learning of non-concatenative mor-t)hological rules, and finally, wc will ewfluate andassess the contribution of the non-concatenativesutfix morphological rules to the overall taggingav, curaey on unknown words using the cascadingguesser .2 The Learn ing Parad igmThe major topic in the development of worthpos guessers is the strategy which is to beused f()r dm acquisition of the guessing rules.Brill (Brill, 1995) outlines a transformation-basedlearner which learns guessing rules from a pre-tagged training corpus.
A statistical-based suffixlearnex is presented in (Schmid, 1994).
From al)re-tagged training corpus it constructs the suf-fix tree where every sutfix is associated with itsinformation measure.The learning technique employed in the in-duction of tile rules of the cascading guesser(Mikheev, 1996) does not require specially pre-pared training data and employs fully tmsuper-vised statistical learning from the lexicon suppliedwith the tagger and word-ti'equeneies obtainedfrom a raw corpus.
The learning is implementedas a two-staged process with fe.edback.
First, set-dng certain parameters a set of guessing rules isacquired, th(m it is evaluated and the results ofevaluation are used for re.-acquisition of a bette.rtuued rule-set.
As it has been already said, thislearning technktue t)roved to be very successful,but did not attempt at the acquisition of word-guessing rules which do not obey simple concate-nations of a main word with some prefix.
Ilere wepresent an e, xte, nsion to accommodate such cases.2.1 Rule Extraction PhaseIn the initial learning technique (Mikheev, 1996)which ac(:ounted only tbr sitnl)le concatenativeregularities a guessing rule was seen as a triph',:A = (S, I ,  H,) whereS is the affix itself;I is the l'os-elass of words which should belooked llI) in the lexicon as main forms;R is the pos-elass which is assigned to unknownwords if the rule is satisfied.IIere we extend this structure to handle cases ofthe mutation in the last n letters of tile main word(words of/-c lass),  as, for instance, in the case oftry -?tries, wtlen the letter "y" is changed to "i" be-fore the suffix.
To accommodate such alterationswe included an additional mutation dement (M)into tile rule structure.
This element keeps the,segment o be added to the main word.
So theapplication of a guessing rule can be described as:unknown-word - 5' + M : I -}H,i.e.
fl'om an unknown word we strip the affix S,add the nlutative segment M, lookup tile pro-duced string in the lexicon and if it is of (:lassI we conclude that the unknown word is of classH,.
For examt)le: the suttix rule A~:\[ S ~-~ ied I~--- (NN, VB) R~--~ ( J J  VBD VBN) M=y\ ]or in shor t  lied (NN VB) ( J J  VBD VBN) y\]says that if there is an unknown word which endswith "led", we should strip this ending and ap-pend to the remaining part the string "y".
Ifthen we find this word in the lexicon as (NN VB)(noun/verb), we conclude that the guessed word isof category (JZ VBD VBN) (adjective, past verb orparticiple).
This rule, for example, will work forword pairs like ,pecify - spec i f ied  o r  deny  - denied.Next, we modified the V operator which was771used for the extraction of morphological guessingrules.
We augmented this operator with the indexn which specifies the length of the mutative nd-ing of the main word.
Thus when the index n is0 the result of the application of the V0 operatorwill be a morphological rule without alterations.The V1 operator will extract the rules with thealterations in the last letter of tile main word, asin the example above.
The V operator is appliedto a pair of words from the lexicon.
First it seg-ments the last n characters of the shorter wordand stores this in the M element of the rule.
Thenit tries to segment an affix by subtracting theshorter word without the mutative ending fromthe longer word.
If the subtraction results in annon-empty string it creates a morphological ruleby storing the pos-class of the shorter word as the/-class, the pos-class of the longer word as the R-(:lass and the segmented affix itself.
For example:\[booked ( J J  VBD VBN)\] Vo \[book (NN VB)\] --)A s : \[ed (NN VB) (JZ VBD VBN) .... \]\[advisable ( J J  VBD VBN)\] ~1 \[advise (NN VB)\] --~A ~ : \[able (NN VB) ( J J  VBD VBN) "e"\]The V operator is applied to all possiblelexicon-entry pairs and if a rule produced by suchan application has already been extracted fromanother pair, its frequency count (f) is incre-mented.
Thus sets of morphological guessing rulestogether with their calculated frequencies are pro-duced.
Next, from these sets of guessing ruleswe need to cut out infrequent rules which mightbias the further learning process.
To do that weeliminate all the rules with the frequency f lessthan a certain threshold 0:.
Such filtering reducesthe rule-sets more than tenfold and does not leaveclearly coincidental cases among the rules.2 .2  Ru le  Scor ing  PhaseOf course, not all acquired rules are equally goodas plausible guesses about word-classes.
So, forew~ry acquired rule we need to estimate whetherit is an effective rule which is worth retaining inthe final rule-set.
To perform such estimationwe take one-by-one ach rule from the rule-setsproduced at the rule extraction phase, take eachword-token from the corpus and guess its POS-setusing the rule if the rule is applicable to the word.For example, if a guessing rule strips a pro'titularsuffix and a current word from the corpus does nothave such suffix we classify these word and ruleas incompatible and the rule as not applicable tothat word.
If the rule is applicable to the word weperform lookup in the lexicon and then comparethe result of the guess with the information listedin the lexicon.
If the guessed pos-set is the sameas the Pos-set stated in the lexicon, we count it assuccess, otherwise it is failure.
Then for each rule:usually we set this threshold quite low: 2-4.we calculate its score as explained in (Mikheev,1996) using the scoring function as follows:.
~ / t  1 score i  =/3 i  - 1.65 * V '~, t~ + log(ISd))where /3 is the proportion of all positive out-comes (x) of the rule application to the total num-ber of compatible to the rule words (n), and ISlis the length of the affix.
We also smooth/3 so asnot to have zeros in positive or negative outcomeprobabilities:/3 = n+l  "Setting the threshold Os at a certain level letsonly the rules whose score is higher than thethreshold to be included into the final rule-sets.The method for setting up the threshold is basedon empirical evaluations of the rule-sets and is de-scribed in Section 2.3.2 .3  Set t ing  the  Thresho ldThe task of assigning a set of pos-tags to a par-ticular word is actually quite similar to the taskof document categorisation where a documentshould be assigned with a set of descriptors whichrepresent its contents.
The performance of suchassignment can be measured in:reca l l  - the percentage of pos-tags which theguesser assigned correctly to a word;prec is ion  - the percentage of POS-tags tileguesser assigned correctly over the total numberof pos-tags it assigned to the word;coverage  - tile proportion of words which theguesser was able to classify, but not necessarilycorrectly.There are two types of test-data in use at thisstage.
First, we measure the performance of aguessing rule-set against the actual lexicon: ev-ery word from the lexicon, except for closed-classwords and words shorter than five characters, isguessed by the rule-sets and the results are com-pared with the information the word has in thelexicon.
In the second experiment we measurethe performance of the guessing rule-sets againstthe training corpus.
For every word we mea-sure its metrics exactly as in the previous exper-iment.
Then we multiply these measures by thecorpus frequency of this particular word and av-erage them.
Thus the most fi'equent words havethe greatest influence on the final measures.To extract he best-scoring rule-sets for each ac-quired set of rules we produce several final rule-sets setting the threshold 0, at different values.For each produced rule-set we record tile threemetrics (precision, recall and coverage) and choosethe sets with the best aggregate measures.3 Learning ExperimentOne of the most important issues in the inductionof guessing rule-sets is the choice of right data fortraining.
In our approach, guessing rules are ex-772-GuessingStrategy-Suffix (S6o)SutIix with alt.
(Aso)S60-I-As0Aso +S(~oEnding (E75)Srm+E75$6o +As0 +E75As0+S60+ET~LexiconPrecision Recall Coverage0.920476 0.959087 0.3738510.964433 0.97194 0.1934040.925782 0.959568 0.44950.928376 0.959457 0.44950.666328 0.94023 0.977410.728449 0.941157 0.97894710.739347 0.941548 0.9791810.740538 0.941497 0.979181CorpusPrecision Recall Coverage0.978246 0.973537 0.297850.996292 0.991106 0.1874780.981375 0.977098 0.3705380.981844 0.977165 0.3705380.755653 0.951342 0.9588520.798186 0.947714 0.9610470.805789 0.948022 0.9610470.805965 0.948051 0.961047Table l.: Results of the cascading application of the rule-sets over the training lexicon and trainingcorpus.
As0 - suffixes with alterations cored over 80 points, $60 - suffixes without alterations coredover 60 points, ET~ - ending-guessing rule-set scored over 75 points.tracted from the lexicon and the actual corpus fre~qnencies of word-usage then allow for discrinfina-tion between rules which are no longer productive(but haw'~ left their imprint on the basic lexicon)and rules that are productive in real-life texts.Thus the major factor ill the learning process isthe lexicon - it should be as general as possible(list all possible Poss for a word) and as large aspossible, since guessing rules are meant o capturegeneral anguage regularities.
The correspondingcorpus should include most of the words fi'om thelexicon and be large enough to obtain reliable es-timates of word-frequency distribution.We performed a rule-induction experiment us-ing the lexicon and word-frequencies derivedfrom the Brown Corpus (Prancis&Kucera, 1982).There are a number of reasons tbr choosing tileBrown Corpus data for training.
The most im-portant ones are that the Brown Corpus providesa model of general multi-domain language use,so general language regularities carl be inducedh'om it;, and second, many taggers come with datatrained on the.
Brown Corpus which is useflll forcomparison and evaluation.
This, however, hy nomeans restricts the described technique to that orany other tag-set, lexicon or corpus.
Moreover,despite the fact that tile training is performedon a particular lexicon and a particular corpus,the obtained guessing rules suppose to be domainand corpus independent and the only training-dependent, feature is the tag-set in use.Using the technique described above and thelexicon derived frora the Brown Corpus we ex-tracted prefix morphological rules (no alter-ations), suffix morphological rules without alter-ations and ending guessing rules, exactly as it wasdone in (Mikheev, 1996).
Then we extracted suf-fix morphological rules with alterations ill the lastletter (V1), which was a new rule-set for the cas-cading guesser.
Quite interestingly apart froln tileexpected suffix rules with alterations as:\[ S= led 1= (NN, VB) R= (JJ VBD VBN) M=y\]which can handle pairs like deny -+denied, thisrule-set was populated with "second-order" uleswhich describe dependencies between secondaryfornls of words.
For instance, the rule\[ S= ion I=  (NNS VBZ) R= (NN) M=8\]says if by deleting the suffix "ion" from a wordand adding "s" to the end of the result of thisdeletion we produce a word which is listed in thelexicon as a plural noun and 3-rd form of a verb(NNS VBZ) the unknown word is a noun (NN).This rule, for instance, is applicable to word pairs:affects -+affection, asserts -+assertion, etc.Table 1 presents ome results of a comparativestudy of the cascading application of the new rule-set against he standard rule-sets of the cascadingguesser.
Tim first part of Table 1 shows tile bestobtained scores for the standard suffix rules (S)and suffix rules with ~flterations in the last let-ter (A).
Wtmn we applied the two suffix rule-setscascadingly their joint lexical coverage increasedby about 7-8% (from 37% to 45% on the lexiconand fl'om 30% to 37% on the corpus) while pre-cision and recall remained at tile sanle high level.This was quite an encouraging result which, a('-tually, agreed with our prediction.
Then we mea-sured whether suffix rules with alterations (A) addany improveulent if they are used in conjunctionwith the ending-guessing rules.
Like in the previ-ous experiment we measured the precision, recalland coverage both on tim lexicon and on tile cor-pus.
The second part of Table 1 shows that sim-ple concatenative suffix rules ($60) improved theprecision of the guessing when they were appliedbefore the ending-guessing rules (E75) by about5%.
Then we cascadingly applied the suffix ruleswith alterations (As0) whictl caused further im-provement in precision by about 1%.After obtaining the optimal rule-sets we per-formed tile same experiments on a word-samplewhich was not included into the training lexiconand corpus.
We gathered about three thousandwords from tile lexicon devcloped for tile Wall773Total Unkn.Score ScoreLexicon GuessingstrategyPull standard: P+S+E)hfll with new: P+A+S+ESmall standard: P+S+ESmall with new: P+A+S+ETotal Unkn.
Totalwords words mistag.5,970 3475,970 3475,970 2,215 3325,970 2,215 311Unkn.mistag.292 33292 3330928895.1%95.1%94.44%94.79%90.5%90.5%86.05%87.00%Table 2: Results of tagging a text using the standard Prefix+Suffix+Ending cascading uesser and theguesser with the additional rule-set of suffixes-with-Alterations.
For each of these cascading uesserstwo tagging experiments were performed: the tagger was equipped with the flfll Brown Corpus lexiconand with the small lexicon of closed-class and short words (5,465 entries).Street Journal corpus 2 and collected frequenciesof these words in this corpus.
At this test-sampleevaluation we obtained similar metrics apart fromthe (:overage which dropped by about 7% for bothkinds of sutfix rules.
This, actually, did not comeas a surprise, since many main tbrms required bythe suffix rules were missing in the lexicon.4 Eva luat ionThe direct performance measures of the rule-setsgave us the grounds for the comparison and se-lection of the best performing uessing rule-sets.The task of unknown word guessing is, however, asubtask of the overall part-of-speech tagging pro-cess.
Thus we are mostly interested in how theadvantage of one rule-set over another will affectthe tagging performance.
So, we performed an in-dependent evaluation of the lint)act of the wordguessing sets on tagging accuracy.
In this evalu-ation we used the cascading application of prefixrules, suffix rules and ending-guessing rules as de-scribed in (Mikheev, 1996).
We measured whetherthe addition of the suffix rules with alterationsincreases the accuracy of tagging in comparisonwith the standard rule-sets.
In this experiment weused a tagger which was a c++ re-implementationof the LISP implemented HMM Xerox tagger de-scribed in (Kupiec, 1992) trained on the BrownCorpus.
For words which failed to be guessed bytile guessing rules we applied the standard methodof classifying them as common nouns (NN) if theyare not capitalised inside a sentence and propernouns (NP) otherwise.In the evaluation of tagging accuracy on un-known words we payed attention to two metrics.First we measure the accuracy of tagging solelyon unknown words:UnkownSeore = CorrectlyTa,q,qcdUnkownWordsTota lUnknownWordsThis metric gives us the exact measure of howthe tagger has done when equipped with differentguessing rule-sets.
In this case, however, we donot account for the known words which were mis-tagged because of the unknown ones.
To put a9these words were not listed in the training lexiconperspective on that aspect we measure the overalltagging performance:TotaIScore = C?r rect lyTaggedW?rdsTota IWordsTo perform such evaluation we tagged severaltexts of different origins, except ones from theBrown Corpus.
These texts were not seen at thetraining phase which means that neither the tag-ger nor the guesser had been trained on these textsand they naturally had words unknown to the lex-icon.
For each text we performed two tagging ex-periments.
In tile first experiment we tagged thetext with the full-fledged Brown Corpus lexiconand hence had only those unknown words whichnaturally occur in this text.
In the second ex-periment we tagged the same text with the lexi-con which contained only closed-class a and short 4words.
This small lexicon contained only 5,456entries out of 53,015 entries of the original BrownCorpus lexicon.
All other words were consideredas unknown and had to be guessed by the guesser.In both experiments we ineasured tagging accu-racy when tagging with the guesser equipped withthe standard Prefix+Suffix+Ending rule-sets andwith the additional rule-set of suffixes with alter-ations in the last letter.Table 2 presents ome results of a typical ex-ample of such experiments.
There we tagged atext of 5,970 words.
This text was detected tohave 347 unknown to the Brown Corpus lexiconwords and as it can be seen the additional rule-set did not cause any improvement to the taggingaccuracy.
Then we tagged tile same text usingthe small lexicon.
Out of 5,970 words of the text,2,215 were unknown to the small lexicon.
Herewe noticed that the additional rule-set improvedtile tagging accuracy on unknown words for about1%: there were 21 more word-tokens tagged cor-rectly because of the additional rule-set.
Amongthese words were: "classified", "applied", "tries","tried", "merging", "subjective", etc.aarticles, prepositions, conjunctions, etc.4shorter than 5 characters7745 Discussion and ConclusionThe target; of the research reI)orted in this pa-1)er was to incorporate the learning of morl)holog-ical word-t'os guessing rules which (lo not ol)eysimI)le (:oncatenations of main words with affixesinto the learning paradigm proposed in (Mikheev,1996).
~l.k) do that we extended the data stru(:-tures and the algorithlns for the guessing-rule ap-1)li(:ation to handle the mutations in the last nletters of the main words.
Thus siml)le concate-native rules naturally became a sul)set of the mu-tative rules they can 1)e seen as mutative ruleswith the zero inutation, i.e.
when the M elementof the rule is empty.
Simple.
con(:atenative rules,however, are not necessarily regular morphologicalrules and quite often they capture other non-linearmorphological dependen(:ies.
For instance, con-sonant doubling is naturally cal)tured by the a ffixes themselves and obey siml)le concatenations,as, fl)r exalnI)le, describes the suffix rule A~':\[ S = gang l= (NN VI I)  1~: = (JJ NN VB( ; )  M~---""\]This rule.
for examl)le , will work fl)r word pairslike t,~g - tagg ing  OF d ig - d igg ing.
Not() that  herewe don't speei\[y the prerequisites for the stem-word to have one syllable and end with the sameconsonant as in the beginifing of the affix.
Ourtask here is not to provide a t)recise morpholog-ical deserii)tion of English 1)ut rather to SUl)t)ortcomputationally effective pos-guessings, by elll-1)loying some, morphological information.
So, in-st;cad of using a prol)er morphological t)ro(:essor,we adopted an engineering at)preach which is ar-gued tbr in (Mikheev&Liubushkina, 1995).
Thereis, of course, ilothing wrong with morphologicalprocessors perse, but it is hardly feasit)le to re-train them fully automatically for new tag-setsor to induce, new rules.
Our shallow Ix~('hniqueon the contrary allows to in(hlce such rules com-pletely automat;ically and ensure that these ruleswill have enough discriminative f atures for robustguessings.
In fact, we abandoned the notion ofmorpheme attd are dealing with word segments re-gardless of whether they are, "proper" morphemesor nol;.
So, for example, in the rule above "ging"is (:onsidered as a suffix which ill i)rincil)le is notright: the suffix is "ing" and "g" is the dubbed(:onsonant.
Clearly, such nuan(:es are impossibleto lem'n autolnati(:ally without specially l)reparedtraining data, which is denied by the techniquein use.
On the other hand it is not clear thatthis fine-grained information will contribute to thetask of morphological guessing.
The simplicity ofthe l)rol)osed shallow morphology, however, en-sures flflly automatic acquisition of such rules andthe emi)iri(:al evahlation presenl;ed in section 2.3('()ntirmed that they are just right for the task:1)recision ;rod recall of such rules were measuredili the  ra i lge  o f  96-99%.The other aim of the research tel)erred herewas to assess whether nou-concatenative morpho-logical rules will improve the overall performanceof the cascading uesser.
As it was measured in(Mikheev, 1996) simple concatenative prefix andsutlix morphological rules iInproved the overalli)recision of the cascading uesser 1)y about 5%,which resulted in 2% higher a(:curacy of taggingon mlknown words.
The additional rule-set of stir kfix rules with one, letter mutation caused soilleflirt, her improvement.
The precision of the guess-ing increased by al)out 1% and the tagging ac-cura(:y on a very large set of unknown words in-creased l)y at)out 1%.
in (:onchlsion we (:tin saythat although the ending-guessing rules, whichare nmeh simpler than morphological rules, canhandle words with affixes longer than two chara(>ters almost equally well, in the fi'amework of pos-tagging even a fl'action of per(:ent is an importantimi)rovement.
Therefore the (:ontribution of themorphological rules is wflual)le and ne(:essary forI;he robust t'os-tagging of real-world texts.ReferencesE.
Brill 1995.
'l'ransformation-l)ased error-drivenlearning and Natural Language t)roeessing: acase study in part-ot~speeeh tagging.
In Com-putational Linguistics 21(4)W. Fran(:is and 1I.
Kucera 1982.
FrequencyAnalysis of English Usage.
Houghton Mitflin,Boston.3.
Kupiec 1992. l/,obust Part-of-Speech TaggingUsing a lIidden Markov Model.
in Uomputer,qpeech and LanguageA.
Mikhe<;v and L. Liubushkina 1995.
Russianm<)rphology: An engineering approach.
In Nat-u'ynl Language Engineering, 1(3)A. Mikheev 1996.
Unsupervised Lem:ning of\?ord-C~tegory Guessing Rules.
In l'rocecdingsof the .
?~th Anr~atal Meeting of the As.~ocicttionfor Computational Linguistics (AUL-96), SantaCruz, USA.\[t. Schmid 1994.
Part of Speech Tagging withNeural Networks.
In P~vcecdinqs of the lSth In-ter'national Cot@fence on Cornputatior~,al Lin-guistics (COLING-9~), Kyoto, Japan.R.
Weischedel, M. Meteer, R. Schwartz,L.
Ramshaw and J. Pahnucci 1993.
Copingwith ambiguity and unknown words throught)rol)at)ilistic models.
In Computational Lin-.quistic,% w)l 19/2775
