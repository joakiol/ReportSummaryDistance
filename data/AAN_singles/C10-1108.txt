Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 958?966,Beijing, August 2010Computing EM-based Alignments of Routes and Route Directions as aBasis for Natural Language GenerationMichael Roth and Anette FrankDepartment of Computational LinguisticsHeidelberg University{mroth,frank}@cl.uni-heidelberg.deAbstractRoute directions are natural language(NL) statements that specify, for a givennavigational task and an automaticallycomputed route representation, a se-quence of actions to be followed by theuser to reach his or her goal.
A corpus-based approach to generate route direc-tions involves (i) the selection of elementsalong the route that need to be mentioned,and (ii) the induction of a mapping fromroute elements to linguistic structures thatcan be used as a basis for NL generation.This paper presents an Expectation-Maxi-mization (EM) based algorithm that alignsgeographical route representations withsemantically annotated NL directions, asa basis for the above tasks.
We formu-late one basic and two extended models,the latter capturing special properties ofthe route direction task.
Although ourcurrent data set is small, both extendedmodels achieve better results than the sim-ple model and a random baseline.
Thebest results are achieved by a combinationof both extensions, which outperform therandom baseline and the simple model bymore than an order of magnitude.1 IntroductionThe purpose of route directions is to inform a per-son, who is typically not familiar with his cur-rent environment, of how to get to a designatedgoal.
Generating such directions poses difficul-ties on various conceptual levels such as planningthe route, selecting landmarks (i.e., recognizablebuildings or structures) and splitting the task intoappropriate single instructions of how to navigatealong the route using the selected landmarks asreference points.Previously developed natural language genera-tion (NLG) systems make use of simple heuristicsfor the task of content selection for route direc-tions (Dale et al, 2005; Roth and Frank, 2009).In our work, we aim for a corpus-based approachthat can be flexibly modeled after natural, human-produced directions for varying subtasks (e.g., in-door vs. outdoor navigation), and that facilitatesmultilingual extensions.
By employing salientlandmarks and allowing for variation in NL real-ization, such a system is expected to generate nat-ural sounding directions that are easier to memo-rize and easier to follow than directions given bya classical route planner or navigation system.NLG for route directions crucially differs fromother generation tasks such as document summa-rization (Mani, 2001) in that the selection and or-dering of input structures for language generationis heavily situation-dependent, i.e., dependent onthe specific properties of a given route to be fol-lowed.In line with a corpus-based NLG approach, wepropose to automatically align geographical routerepresentations as produced by a route plannerwith an annotated corpus of NL directions givenby humans for the respective routes.
The inducedalignments will (i) serve to identify which ele-ments of a route to select for verbalization, and (ii)deliver correspondences between route segmentsand linguistic input structures that can be used asa basis for statistical NL generation.
We investi-958gate a minimally supervised method for inducingsuch alignments to ensure maximal flexibility foradaptations to different scenarios.The remainder of this paper is structured as fol-lows: In Section 2 we discuss related work.
Sec-tion 3 introduces the task, and the representationformats and resources we use.
Section 4 intro-duces a basic Expectation-Maximization modeland two extensions for the alignment task.
Sec-tion 5 outlines the experiments and presents theevaluation results.
In Section 6 we conclude anddiscuss future work.2 Related WorkVarious aspects of route directions have been sub-ject of research in computational linguistics, rang-ing from instructional dialogues in MapTask (An-derson et al, 1991) to recent work on learningto follow route directions (Vogel and Jurafsky,2010).
However, little work has been done ongenerating NL directions based on data from Geo-graphical Information Systems (Dale et al, 2005;Roth and Frank, 2009).NLG systems are typically realized as pipelinearchitectures (Reiter and Dale, 2000).
As a firststep, they compute a set of messages that rep-resent the information to be conveyed to a user,given a specific communicative task (Content Se-lection).
Selecting appropriate content for a taskcan be defined heuristically, by manually craftedrules or by learning content selection rules auto-matically from corpus data.
Previous work byDale et al (2005) and Roth and Frank (2009)on generating NL directions used hand-craftedheuristics.
Duboue and McKeown (2003) werethe first to model content selection as a machinelearning task, in which selection rules are inducedfrom pairs of human-written text and associatedsets of database entries.
They induce baseline se-lection rules from exact matches of NL expres-sions with database entries; in addition, class-based rules are computed by matching databaseentry types against NL expressions, using statis-tical co-occurrence clusters.
Barzilay and Lapata(2005) incorporate the interplay between multipleevents and entities when learning content selec-tion rules using a special link function.Recent work by Liang et al (2009) focuses onmodeling grounded language, by aligning real-world representations with NL text that referencescorresponding world states.
They show how agenerative model can be used to segment text intoutterances and to identify relevant facts with min-imal supervision.
Both tasks are handled jointlyin a unified framework by training a hierarchicalsemi-Markov model on pairs of text and worldstates, thereby modeling sequencing effects in thepresentation of facts.
While their work is not pri-marily concerned with NLG, the learned corre-spondences and their probabilities could be ap-plied to induce content selection rules and lin-guistic mappings in a NLG task.
The approach isshown to be effective in scenarios typical for NLGsettings (weather forecasts, RoboCup sportscast-ing, NFL recaps) that differ in the amount of avail-able data, length of textual descriptions, and den-sity of alignments.In the following, we will adapt ideas from theirEM-based approach to align (segments of) routerepresentations and NL route directions in a min-imally supervised manner.
We will investigate in-creasingly refined models that are tailored to thenature of our task and underlying representations.In particular, we extend their approach by exploit-ing semantic markup in the NL direction corpus.3 Aligning Routes and DirectionsIn this work we explore the possibility of usingan implementation of the EM algorithm (Demp-ster et al, 1977) to learn correspondences between(segments of) the geographical representation ofa route and linguistic instructions of how to fol-low this route in order to arrive at a designatedgoal.
We are specifically interested in identifyingwhich parts of a route are realized in natural lan-guage and which kinds of semantic constructionsare used to express them.As a data source for inducing such correspon-dences we use a parallel corpus of route repre-sentations and corresponding route directions thatwere collected in a controlled experiment for nav-igation in an urban street network (cf.
Schuldeset al (2009)).
For the alignment task, the routeswere compiled to a specification format that hasbeen realized in an internal version of an onlineroute planner.
Figure 1 displays the route rep-959Figure 1: A (partial) route representation of the route segment displayed on the right.resentation for a small route segment (a junctionconnecting ?Hauptstra?e?
and ?Leyergasse?).
Thecorresponding part of a NL route direction is dis-played in Figure 2.
The route representation andthe NL direction share some common concepts:For example, both contain references to a land-mark called ?Sudpfanne?
(marked as [1]) and astreet named ?Leyergasse?
(marked as [2]).
Usingpairs of route representations and directions, weaim to automatically induce alignments betweensuch correspondences.
In the following we de-scribe our data in more detail.3.1 Route Representation FormatThe route representation format we use (illus-trated in Figure 1) is an extended version ofthe OpenGIS Location Service (OpenLS) Imple-mentation Standards, a set of XML-based rep-resentations specified by the Open GeospatialConsortium1.
Previous approaches on extend-ing the latter with landmarks in an interopera-1http://www.opengeospatial.org/standards/isble way have been presented by Neis and Zipf(2008).
The representation format of our datahas been developed in close collaboration with re-searchers from Geoinformatics at Heidelberg Uni-versity2 and adopts ideas previously proposed inthe Cognitive OpenLS specification by Hansen etal.
(2006).
The resulting specification will be im-plemented in an extended (internal) version of theonline route planner OpenRouteService.org.Our work revolves around two kinds of ele-ments in this format: so-called maneuvers, i.e., el-ements that describe a decision point including therequired action and the following route segment,and landmarks that occur along the route.
For thealignment task we focus on the following types ofattributes that are part of the XML specification,specified here as Attribute (Element):directionOfTurn (Maneuver) ?
the direction ofmovement for the current maneuver, i.e.,?left?, ?right?
or ?straight?2Chair of GIScience, Alexander Zipf,http://www.geog.uni-heidelberg.de/lehrstuehle/gis/960Figure 2: Directions for the route segment displayed in Figure 1 annotated with frame-semantic markupand alignment information.
The directions translate to ?You start walking from Hauptstra?e towardsGaststa?tte Sudpfanne, then you turn right onto Leyergasse?junctionType (Maneuver) ?
the type of junctionat the current maneuver, e.g., ?intersection?,?crossing?name (JunctionCategory) ?
the name of thejunction at the current maneuver, e.g.,?Hauptstra?e/Leyergasse?name (NextSegment) ?
the name of the street ofthe next route segment, e.g., ?Hauptstra?e?streetName (RouteBranch) ?
the street name ofa branch along which the route continues,e.g., ?Leyergasse?streetName (NoRouteBranch) ?
the street nameof a branch that is not part of the route, e.g.,?Kisselgasse?name (Landmark) ?
the name of a landmark,e.g., ?Hotel Sudpfanne?spatialRelation (UsedLandmark) ?
the spatialrelation between a landmark and the currentmaneuver, e.g., ?left?, ?right?, ?before?3.2 A Parallel Corpus of Route DirectionsThe corpus of route directions used in this workis a subset of the data collected by Schuldes et al(2009) in a desk-based experiment.
To elicit NLroute directions, subjects were shown a web appli-cation that guided them along a route by means ofa 2D animation.
Subsequently they had to writeNL route directions in German for the shownroutes.
The subjects were allowed to use all infor-mation displayed by the web application: namedplaces, buildings, bridges and street names, etc.The resulting directions were POS-tagged withTreeTagger (Schmid, 1997), dependency-parsedwith XLE (Maxwell and Kaplan, 1993), and man-ually revised.
Additionally, we annotated frame-semantic markup (Fillmore et al, 2003) and goldstandard alignments to the route representation us-ing the SALTO annotation tool (Burchardt et al,2006).Frame semantic markup.
The texts are an-notated with an inventory of 4 frames relevantfor directions (SELF MOTION, PERCEPTION, BE-ING LOCATED, LOCATIVE RELATION), with se-mantic roles (frame elements) such as DIREC-TION, GOAL, PATH, LOCATION.
Figure 2 il-lustrates a typical example for the use of theSELF MOTION frame, once with the elementsSOURCE and DIRECTION, and once with the el-ements DIRECTION and GOAL.
Our alignmentmodel uses the frame semantic annotation asstructuring information.Gold standard alignments.
For evaluation weconstructed gold alignments.
We asked two an-notators to align text parts with correspondingattributes in the respective route representation3.The information about corresponding attributeswas added to a single word by manually insert-3The alignments have not been double annotated, henceno measure for inter-annotator agreement can be provided.961#S #W #FE #aligned FEavg.
per direction 8 98 28 14 (50%)overall 412 5298 1519 750Table 1: Corpus statistics: number of sentences(S), words (W), frame elements (FE) and align-ments.#attributes #aligned attr.avg.
per route 115 14 (12%)overall 921Table 2: Corpus statistics: total number and per-centage of relevant attribute alignments.ing XPATH expressions that unambiguously referto the aligned attribute in the route representationformat.
For learning the alignment model, the an-notations were spread to all words in the span ofthe respective frame element.Corpus statistics.
We made use of a corpus of54 NL directions collected for 8 routes in an urbanstreet network.
Tables 1 and 2 give some statis-tics about the number of words (W) and frameelements (FE) in the parallel corpus.
Comparingthe total number of relevant attributes (as listed inSection 3.1) and attributes annotated in the goldalignments (aligned attr.)
we note that only 12%are actually mentioned in NL directions.
Thus itis necessary to select the most salient attributes toavoid the generation of overly redundant text.4 Alignment ModelFor the induction of alignments between (parts of)route structures and semantic representations, weadopt ideas from the models presented in Liang etal.
(2009) (cf.
Section 2).We start from a basic frame alignment model.It specifies a conditional probability distributionp(f |a) for the alignment to a frame element f oftype ft (e.g., source, goal, direction) in the frame-semantic annotation layer given an attribute a oftype at (e.g., streetName, directionOfTurn) in theroute representation format.
Note that this modeldoes not take into account the actual value av ofthe attribute a nor the words that are annotated aspart of f .
We assume that the frame annotationrepresents a reliable segmentation for this align-ment.
This allows us to omit modeling segmenta-tion explicitly.As extensions to the basic frame alignmentmodel, we specify two further models that cap-ture properties that are specific to the task of di-rection alignment.
As route directions are typi-cally presented in a linear order with respect tothe route, we incorporate an additional distancemodel ?
in our alignment.
We further accountfor word choice within a frame element as an ad-ditional factor.
The word choice model p(w|a)will exploit attribute type and value informationin the route representations that are reflected inword choice in the linguistic instructions.
Bothextensions are inspired by and share similaritieswith models that have been successfully appliedin work on text alignment for the task of machinetranslation (Vogel et al, 1996; Tiedemann, 2003).Our full model is a distribution over frame el-ements f and words w that factorizes the threeabove mentioned parts under the assumption ofindependence between each component and eachattribute:p(f, w|a) = p(f |a)?
(dist(f, a)) p(w|a) (1)The individual models are described in moredetail in the following subsections.4.1 Frame Alignment ModelThis basic frame alignment model specifies theprobabilities p(f |a) for aligning an attribute a oftype at (i.e., one of the types listed in Section 3.1)to a frame element f labeled as type ft. Thisalignment model is initialized as a uniform distri-bution over f and trained using a straight-forwardimplementation of the EM algorithm, followingthe well-known IBM Model 1 for alignment inmachine translation (Brown et al, 1993).
The ex-pectation step (E-step) computes expected countsgiven occurrences of ft and at under the assump-tion that all alignments are independent 1:1 corre-spondences:count(ft, at) =?
{?f ?,a?
?|f ?t=ft?a?t=at} p(f?|a?)?
{?f ?,y?|f ?t=ft} p(f?|y)(2)The probabilities are re-estimated to maximizethe overall alignment probability by normalizing962the estimated counts (M-step):p(f |a) = count(ft, at)?x count(xt, at)(3)4.2 Distance ModelWe hypothesize that the order of route directionstends to be consistent with the order of maneuversencoded by the route representation.
We includethis information in our alignment model by defin-ing a distance measure dist(f, a) between the rel-ative position of a frame element f in the text andthe relative position of an attribute a in the routerepresentation.
The probabilities are specified inform of a distance distribution ?
(i) over normal-ized distances i ?
[0 : 1] and learned during EMtraining.
The weights are initialized as a uniformdistribution and re-estimated in each M-step bynormalizing the estimated counts:?
(i) =?
{?x,y?| dist(x,y)=i} count(x, y)?{?x,y?}
count(x, y)(4)4.3 Word Choice ModelWe define a word choice model for word us-age within a frame element.
This additional fac-tor is necessary to distinguish between variousoccurrences of the same type of frame elementwith different surface realizations.
For exam-ple, assuming that the frame alignment modelcorrectly aligns directionOfTurn attributes to aframe element of type DIRECTION, the wordchoice model will provide an additional weightfor the alignment between the value of an attribute(e.g., ?left?)
and the corresponding words withinthe frame element (e.g., ?links?).
Similarly tothe word choice model within fields in (Lianget al, 2009), our model specifies a distributionover words given the attribute a.
Depending onwhether the attribute is typed for strings or cate-gorial values, two different distributions are used.String Attributes.
For string attributes, we de-termine a weighting factor based on the longestcommon subsequence ratio (LCSR).
The reasonfor using this measure is that we want to allow forspelling variants and the use of synonymous com-mon nouns in the description of landmarks andstreet names (e.g., ?Main St.?
vs. ?Main Street?,?Texas Steakhouse?
vs. ?Texas Restaurant?).
Theweighting factor pstr(w|a) for an alignment pair?f, a?
is a constant in the E-step and is calculatedas the LCSR of the considered attribute value avand the content words w = cw(f) in an anno-tated frame element f divided by the sum over theLCSR values of all alignment candidates for a:pstr(w|a) =LCSR(av, w)?x LCSR(av, cw(x))(5)Categorial Attributes.
We define categorial at-tributes as attributes that can only take a finiteand prescribed set of values.
For these we donot expect to find matching strings in NL direc-tions as the attribute values are defined indepen-dently of the language in use (e.g., values for di-rectionOfTurn are ?left?, ?right?
and ?straight?.However, the directions in our data set are in Ger-man, thus containing the lexemes ?links?, ?rechts?und ?geradeaus?
instead).
As the set of values{av ?
Dat} for a categorial attribute type at isfinite, we can define and train probability distri-butions over words for each of them during EMtraining.
The models are initialized as uniformdistributions and are used as a weighting factorin the E-Step.
We re-calculate the parameters ofa distribution pcat(w|a) in each EM iteration bynormalizing the estimated counts during M-step:pcat(w|a) =count(av, w)?x count(av, x)(6)5 Experiments and Results5.1 SettingWe test the performance of different combinationsof these EM-based models on our data, startingfrom a simple baseline model (EM), combinedwith the distance (EM+dst) and word choicemodels (EM+wrd) and finally the full model(Full).
We perform additional experiments to ex-amine the impact of different corpus sizes and analignment threshold (+thld).EM is a baseline model that consists of a simpleEM implementation for aligning attributesand frame elements (equation (3)).EM+dst consists of the simple EM model and theadditional distance factor (equation (4)).963Model P (+thld) R (+thld) F1 (+thld)Random 2.7 (2.7) 3.9 (3.9) 3.2 (3.2)EM 2.0 (3.6) 2.9 (3.7) 2.34 (3.6)EM+dst 7.3 (11.6) 10.8 (11.7) 8.7 (11.6)EM+wrd 26.8 (36.3) 39.5 (35.5) 32.0 (35.9)Full 28.9 (38.9) 42.5 (37.9) 34.4 (38.4)Table 3: Precision (P), Recall (R) and F1 measureresults with and without threshold (+thld) on thealignment task (all numbers in percentages).EM+wrd consists of the simple EM model withthe word choice model (equations (5) and(6), respectively).Full is the full alignment model including dis-tance and word choice as described in Sec-tion 4 (cf.
equation (1)).We use the data set described in Section 3.
Thepredictions made by the different models are eval-uated against the gold standard alignments (cf.
Ta-bles 1 and 2).
We run a total number of 30 iter-ations4 of EM training on the complete data setto learn the parameters of the probability distri-butions.
From the set of all possible 1-to-1 align-ments, we select the most probable alignments ac-cording to the model in a way that no attribute andno frame element is aligned twice.5.2 ResultsWe measure precision as the number of predictedalignments also annotated in the gold standard di-vided by the total number of alignments generatedby our model.
Recall is measured as the numberof correctly predicted alignments divided by thetotal number of alignment annotations.
As base-lines we consider a random baseline (obtainedfrom the average results measured over 1,000 ran-dom alignment runs) and the simple EM model.The results in Table 3 show that the simpleEM model performs below the random baseline.The individual extended models achieve signifi-cant improvement over the simple model and therandom baseline.
While the distance model has asmaller impact, the influence of the word choice4This number was determined by experiments as a gen-eral heuristics.# directions Precison Recall F11 28.94% 42.31% 34.38%2 29.04% 41.90% 34.31%3 29.01% 42.18% 34.38%4 28.75% 41.81% 34.07%5 29.36% 42.69% 34.79%6 30.18% 43.91% 35.77%Table 4: Average results when using only a spe-cific number of directions for each route with themodel Full (-thld).model is considerable.
Applying the full modelyields further performance gains.
We note that forall models recall is higher compared to precision.One of the reasons for this phenomenon may bethat the EM-based models align as many attributesas possible to frame elements in the route direc-tions.
In our gold standard, however, only around12% of all relevant attributes correspond to frameelements in the route directions (cf.
Section 3.2).We estimate this quota from a part of the corpusand use it as an alignment threshold, i.e., for eval-uation we select the best alignments proposed bythe models, until we reach the threshold.
With thiswe achieve a F1 measure of 38.40% in a 6-foldcross validation test.
This represents an improve-ment of 3.97 points and considerably boosts preci-sion, yielding overall balanced precision (38.90%)and recall (37.92%).A general problem of the current setup is thesmall amount of available data.
With a total of 54route directions, the data consists of 6 to 8 direc-tions for each route.
We compute a learning curveby using only exactly 1 to 6 directions per route toexamine whether performance improves with in-creasing data size.
The results are computed asan average over multiple runs with different datapartitions (see Table 4).
The results indicate smallbut consistent improvements with increasing datasizes, however, the differences are minimal.
Thuswe are not able to conclude at this point whetherperformance increases are possible with the addi-tion of more data.5.3 Error AnalysisIn an error analysis on the results of the full model,we found that 363 out of 784 (46%) misalign-964ments are related to attributes not aligned in ourgold standard.
This is due to the fact that notall relevant attributes are realized in natural lan-guage directions.
By addressing this problem inthe model Full+threshold, we are able to reducethese errors, as evidenced by a gain of almost 10points in precision and 4 points in F1 measure.We further observe that the word choice modeldoes not correctly reflect the distribution of cat-egorial attributes in the parallel corpus.
In thedata, we observe that humans often aggregatemultiple occurrences of the same attribute valueinto one single utterance.
An example of such aphenomenon can be seen with the attribute type?directionOfTurn?
: Even though ?straight?
is themost common value for this attribute, it is only re-alized in directions in 33 (5%) cases (comparedto 65% and 47% for ?left?
and ?right?
respec-tively).
While our EM implementation maximizesthe likelihood for all alignment probabilities basedon expected counts, many pairs are not ?
or notfrequently ?
found in the corpus.
This results inthe model often choosing incorrect alignments forcategorial attributes and makes up for 23% of themisaligned attributes in total.We found that further 5% of the attributes aremisaligned with frame elements containing pro-nouns that actually refer to a different attribute.As our word choice model does not account forthe use of anaphora, none of the affected frameelements are aligned correctly.
Given the genreof our corpus, integrating simple heuristics to re-solve anaphora (e.g., binding to the closest pre-ceding mention) could solve this problem for themajority of the cases.6 ConclusionWe presented a weakly supervised method foraligning route representations and natural lan-guage directions on the basis of parallel corporausing EM-based learning.
Our models adopt ideasfrom Liang et al (2009) with special adaptationsto the current application scenario.
As a majordifference to their work, we make use of frame-semantic annotations on the NL side as a basis forsegmentation.While we can show that the extended mod-els significantly outperform a simple EM-basedmodel, the overall results are still moderate.
Wecannot draw a direct comparison to the results pre-sented in Liang et al (2009) due to the differentscenarios and data sets.
However, the corpus theyused for the NFL recaps scenario is the closest toours in terms of available data size and percentageof aligned records (in our case attributes).
For thiskind of corpus, they achieve an F1 score of 39.9%with the model that is closest to ours (Model 2?
).Their model achieves higher performance for sce-narios with more available data and a higher per-centage of alignments.
Thus we expect that ourmodel benefits from additional data sets, whichwe plan to gather in web-based settings.Still, we do not expect to achieve near to per-fect alignments due to speaker variation, a factorwe also observe in the current data.
As our ul-timate goal is to generate NL instructions fromgiven route representations, we can neverthelessmake use of imperfectly aligned data for the com-pilation of high-confidence rules to compute se-mantic input structures for NLG.
Following previ-ous work by Barzilay and Lee (2002), we can alsoexploit the fact that our data consists of multipledirections for each route to identify alternative re-alization patterns for the same route segments.
Inaddition, (semi-)supervised models could be usedto assess the gain we may achieve in comparisonto the minimally supervised setting.However, we still see potential for improv-ing our current models by integrating refinementsbased on the observations outlined above: Miss-ing alignment targets on the linguistic side ?
es-pecially due to anaphora, elliptical or aggregatingconstructions ?
constitute the main error source.We aim to capture these phenomena within thelinguistic markup in order to provide hidden align-ment targets.
Also, our current model only consid-ers frame elements as alignment targets.
This canbe extended to include their verbal predicates.Acknowledgements: This work is supported bythe DFG-financed innovation fund FRONTIER aspart of the Excellence Initiative at Heidelberg Uni-versity (ZUK 49/1).
We thank Michael Bauer andPascal Neis for the specification of the route repre-sentation format and Carina Silberer and JonathanGeiger for annotation.965ReferencesAnderson, Anne H., Miles Bader, Ellen Gurman Bard,Elizabeth Boyle, Gwyneth Doherty, Simon Garrod,Stephen Isard, Jacqueline Kowtko, Jan McAllister,Jim Miller, Catherine Sotillo, Henry Thompson, andRegina Weinert.
1991.
The HCRC Map Task cor-pus.
Language and Speech, 34(4):351?366.Barzilay, Regina and Mirella Lapata.
2005.
Collectivecontent selection for concept-to-text-generation.
InProceedings of the Human Language TechnologyConference and the 2005 Conference on EmpiricalMethods in Natural Language Processing, Vancou-ver, B.C., Canada, 6?8 October 2005, pages 331?338.Barzilay, Regina and Lillian Lee.
2002.
Bootstrappinglexical choice via multiple-sequence alignment.
InProceedings of the 2002 Conference on EmpiricalMethods in Natural Language Processing, Philadel-phia, Penn., 6?7 July 2002, pages 164?171.Brown, Peter F., Vincent J. Della Pietra, StephanA.
Della Pietra, and Robert L. Mercer.
1993.The mathematics of statistical machine translation:Parameter estimation.
Computational Linguistics,19:263?311.Burchardt, Aljoscha, Katrin Erk, Anette Frank, AndreaKowalski, and Sebastian Pado.
2006.
SALTO: Aversatile multi-level annotation tool.
In Proceedingsof the 5th International Conference on LanguageResources and Evaluation, Genoa, Italy, 22?28 May2006, pages 517?520.Dale, Robert, Sabine Geldof, and Jean-Philippe Prost.2005.
Using natural language generation in auto-matic route description.
Journal of Research andPractice in Information Technology, 37(1):89?106.Dempster, Arthur P., Nan M. Laird, and Donald B.Rubin.
1977.
Maximum likelihood from incom-plete data via the EM algorithm.
Journal of theRoyal Statistics Society, Series B (Methodological),39(1):1?38.Duboue, Pablo A. and Kathleen R. McKeown.
2003.Statistical acquisition of content selection rules.
InProceedings of the 2003 Conference on EmpiricalMethods in Natural Language Processing, Sapporo,Japan, 11?12 July 2003, pages 121?128.Fillmore, Charles J., Christopher R. Johnson, andMiriam R.L.
Petruck.
2003.
Background toFrameNet.
International Journal of Lexicography,16(3):235?250.Hansen, Stefan, Kai-Florian Richter, and AlexanderKlippel.
2006.
Landmarks in OpenLS: A datastructure for cognitive ergonomic route directions.In Proceedings of the 4th International Conferenceon Geographic Information Science, Mu?nster, Ger-many, 20-23 September 2006.Liang, Percy, Michael Jordan, and Dan Klein.
2009.Learning semantic correspondences with less super-vision.
In Proceedings of ACL-IJCNLP 2009, pages91?99, August.Mani, Inderjeet.
2001.
Automatic Summarization.John Benjamins, Amsterdam, Philadelphia.Maxwell, John T. and Ronald M. Kaplan.
1993.The interface between phrasal and functional con-straints.
Computational Linguistics, 19(4):571?590.Neis, Pascal and Alexander Zipf.
2008.
Extending theOGC OpenLS route service to 3D for an interoper-able realisation of 3D focus maps with landmarks.Journal of Location Based Services, 2(2):153?174.Reiter, Ehud and Robert Dale.
2000.
Building NaturalLanguage Generation Systems.
Cambridge, U.K.:Cambridge University Press.Roth, Michael and Anette Frank.
2009.
A NLG-basedApplication for Walking Directions.
In CompanionVolume to the Proceedings of the Joint Conferenceof the 47th Annual Meeting of the Association forComputational Linguistics and the 4th InternationalJoint Conference on Natural Language Processing,Singapore, 2?7 August 2009, pages 37?40.Schmid, Helmut.
1997.
Probabilistic Part-of-Speechtagging using decision trees.
In Jones, Daniel andHarold Somers, editors, New Methods in LanguageProcessing, pages 154?164.
London, U.K.: UCLPress.Schuldes, Stephanie, Michael Roth, Anette Frank, andMichael Strube.
2009.
Creating an annotated cor-pus for generating walking directions.
In Proceed-ings of the ACL-IJCNLP 2009 Workshop on Lan-guage Generation and Summarisation, Singapore,6 August 2009, pages 72?76.Tiedemann, Jo?rg.
2003.
Combining Clues for WordAlignment.
In Proceedings of the 10th Confer-ence of the European Chapter of the Association forComputational Linguistics (EACL), pages 339?346,Budapest, Hungary.Vogel, Adam and Dan Jurafsky.
2010.
Learning toFollow Navigational Directions.
In Proceedings ofACL-2010, Uppsala, Sweden.Vogel, Stephan, Hermann Ney, and Christoph Till-mann.
1996.
HMM-based Word Alignment in Sta-tistical Translation.
In Proceedings of the 16h Inter-national Conference on Computational Linguistics(COLING), pages 836?841, Copenhagen, Denmark.966
