Chinese Word Segmentation and Named Entity Recognition Based onConditional Random FieldsXinnian MaoFrance Telecom R&D Center (Beijing), Bei-jing, 100080, P.R.Chinaxinnian.mao@orange-ftgroup.comSaike HeUniversity of Posts and Telecommunications,Beijing, 100876, P.R.ChinaSencheng BaoUniversity of Posts and Telecommunications,Beijing, 100876, P.R.ChinaYuan Dong1,21France Telecom R&D Center (Beijing),Beijing, 100080, P.R.China2University of Posts and Telecommunica-tions, Beijing, 100876, P.R.Chinayuan.dong@orange-ftgroup.comHaila WangFrance Telecom R&D Center (Beijing), Bei-jing, 100080, P.R.Chinahaila.wang@orange-ftgroup.comAbstractChinese word segmentation (CWS), namedentity recognition (NER) and part-of-speech tagging is the lexical processing inChinese language.
This paper describes thework on these tasks done by France Tele-com Team (Beijing) at the fourth Interna-tional Chinese Language Processing Bake-off.
In particular, we employ ConditionalRandom Fields with different features forthese tasks.
In order to improve NER rela-tively low recall; we exploit non-local fea-tures and alleviate class imbalanced distri-bution on NER dataset to enhance the re-call and keep its relatively high precision.Some other post-processing measures suchas consistency checking and transforma-tion-based error-driven learning are used toimprove word segmentation performance.Our systems participated in most CWS andPOS tagging evaluations and all the NERtracks.
As a result, our NER systemachieves the first ranks on MSRA opentrack and MSRA/CityU closed track.
OurCWS system achieves the first rank onCityU open track, which means that oursystems achieve state-of-the-art perform-ance on Chinese lexical processing.1 IntroductionDifferent from most European languages, there isno space to mark word boundary between Chinesecharacters, so Chinese word segmentation (CWS)is the first step for Chinese language processing.From another point that there is no capitalizationinformation to indicate entity boundary, whichmakes Chinese named entity recognition (NER)more difficult than European languages.
And part-of-speech tagging (POS tagging) provides valuableinformation for deep language processing such asparsing, semantic role labeling and etc.
This paperpresents recent research progress on CWS, NERand POS tagging done by France Telecom Team(Beijing).
Recently, Conditional Random Fields1(CRFs) (Lafferty et al, 2001) have been success-fully employed in various natural language proc-essing tasks and achieve the state-of-the-art per-formance, in our system, we use it as the basicframework and incorporate some other post-processing measures for CWS, NER and POS tag-ging tasks.2 Chinese Named Entity RecognitionNER is always limited by its lower recall due tothe imbalanced distribution where the NONE classdominates the entity classes.
Classifiers built onsuch dataset typically have a higher precision and alower recall and tend to overproduce the NONE1 We use the CRF++ V4.5 software fromhttp://chasen.org/~taku/software/CRF++/90Sixth SIGHAN Workshop on Chinese Language Processingclass (Kambhatla, 2006).
Taking SIGHAN Bakeoff2006 (Levow, 2006) as an example, the recall islower about 5% than the precision for each submit-ted system on MSRA and CityU closed track.
If wecould improve NER recall but keep its relativelyhigh precision, the overall F-measure will be im-proved as a result.
We design two kinds of effec-tive features: 0/1 features and non-local features toachieve this objective.
Our final systems utilizethese features together with the local features toperform NER task.2.1 Local FeaturesThe local features are character-based and are in-stantiated from the following temples:Unigram: Cn (n=-2,-1, 0, 1, 2).Bigram: CnCn+1 (n=-2,-1, 0, 1) and C-1C1.Where C0 is the current character, C1 the nextcharacter, C2 the second character after C0, C-1 thecharacter preceding C0, and C-2 the second charac-ter before C0.2.2 0/1 FeaturesIn order to alleviate the imbalanced class distribu-tion, we assign 1 to all the characters which arelabeled as entity and 0 to all the characters whichare labeled as NONE in training data.
In such way,the class distribution can be alleviated greatly, tak-ing Bakeoff 2006 MSRA NER training data forexample, if we label the corpus with 10 classes, theclass distribution is 0.81(B-PER):1.70(B-LOC):0.95(B-ORG):0.81(I-PER):0.88(I-LOC):2.87(I-ORG):0.76(E-PER):1.42(E-LOC):0.94(E-ORG):88.86(NONE), if wechange the label scheme to 2 labels (0/1), the classdistribution is 11.14 (entity):88.86(NONE).
Wetrain the 0/1 CRFs tagger using the local featuresalone.
For the 0/1 features, during the trainingstage, they are assigned with 2-fold cross valida-tion, and during the testing stage, they are assignedwith the 0/1 tagger.2.3 Non-local FeaturesMost empirical approaches including CRFs cur-rently employed in NER task make decision onlyon local context for extract inference, which isbased on the data independent assumption.
Butoften this assumption does not hold because non-local dependencies are prevalent in natural lan-guage (including the NER task).
How to utilize thenon-local dependencies is a key issue in NER task.Up to now, few researches have been devoted tothis issue; existing works mainly focus on usingthe non-local information for improving NER labelconsistency (Krishnan and Manning, 2006).
Thereare two methods to use non-local information.
Oneis to add additional edges to graphical model struc-ture to represent the distant dependencies and theother is to encode the non-locality with non-localfeatures.
In the first approach, heuristic rules areused to find the dependencies (Bunescu andMooney, 2004) or penalties for label inconsistencyare required to handset ad-hoc (Finkel et al, 2005).Furthermore, high computational cost is spent forapproximate inference.
In order to establish thelong dependencies easily and overcome the disad-vantage of the approximate inference, Krishnanand Manning (2006) propose a two-stage approachusing CRFs framework with extract inference.They represent the non-locality with non-local fea-tures, and extract them from the output of the firststage CRF with local context alone; then they in-corporate the non-local features into the secondCRF.
But the features in this approach are onlyused to improve label consistency in Europeanlanguages.
Similar with their work encoding thenon-local information with non-local feature, andwe also exploit the non-local features under two-stage architecture.
Different from their features areactivated on the recognized entities coming fromthe first CRF, the non-local features we design areused to recall more missed entities which are seenin the training data or unseen entities but some oftheir occurrences being recognized correctly in thefirst stage, so our non-local features are activatedon the raw character sequence.Different NER in European languages, whereentity semantic classification is more difficultcompared with boundary detection, in Chinese, thesituation is opposite.
So we encode different use-ful information for Chinese NER two subtasks:entity boundary detection and entity semantic clas-sification.
Three kinds of non-local features aredesigned; they are fired on the token sequences ifthey are matched with certain entity in the entitylist in forward maximum matching (FMM) way.Token-position features (NF1): These refer tothe position information (start, middle and last)assigned to the token sequence which is matchedwith the entity list exactly.
These features enableus to capture the dependencies between the identi-cal candidate entities and their boundaries.91Sixth SIGHAN Workshop on Chinese Language ProcessingEntity-majority features (NF2): These refer tothe majority label assigned to the token sequencewhich is matched with the entity list exactly.
Thesefeatures enable us to capture the dependencies be-tween the identical entities and their classes, sothat the same candidate entities of different occur-rences can be recalled favorably, and their labelconsistencies can be considered too.Token-position & entity-majority features(NF3): These features capture non-local informa-tion from NF1 and NF2 simultaneously.
They takeinto account the entity boundary and semanticclass information at the same time.Figure 1 shows the flow of using non-local fea-tures under CRFs framework in two-stage architec-ture.
The first CRF is trained with local featuresalone, and then we test the testing data with thefirst CRF and get the entities plus their type fromthe output.
The second CRF utilizes the 0/1 fea-tures and the non-local features derived from theentity list which is merged by the output of the firstCRF from the testing data and the entities extracteddirectly from the training data.
We compare thethree kinds of non-local features on MSRA andCityU closed track in SIGHAN 2006 and we findthat the NF3 is the best (Mao etc, 2007).
So weonly incorporate the NF3 into our final NER sys-tem.Figure 1.
The flow using non-local featuresin two-stage architecture2.4 ResultsWe employ BIOE1 label scheme for the NER taskbecause we found it performs better than IOB2 onBakeoff 2006 (Levow, 2006) NER MSRA andCityU corpora.
Table 1 presents the official resultson the MSRA and CityU corpus.
The F-measureon MSRA open track is so high just because thetesting data in Bakeoff 2007 is part of its Bakeoff2006 training dataset and we utilize this corpus fortraining the final CRFs classifier.
The F-measureon CityU open track is not much superior to itsclosed track because we only use its Bakeoff 2006corpus to train the 0/1 CRFs, but not use the Bake-off 2006 corpus to train final classifier.Run ID  F-Score  Run ID  F-Scorecityu_c  84.99 cityu_o  87.92msra_c  92.81 msra_o 99.88Table 1: The official results on NERclosed(c) tracks and open(o) tracks3 Chinese Word SegmentationType FeatureUnigram Cn (n=-2,-1, 0, 1, 2).Bigram CnCn+1 (n=-2,-1,0, 1)Jump C-1C1Punc Pu (C0)Date, Digit, Letter T-1T0T1Table 2: The features used in our CWS systemsTable 2 lists the features we used in our CWS sys-tems.
After the raw corpus is processed by CRFs,two other post-processing measures are performed.We utilize transformation-based error-driven learn-ing (TBL)2 to further improve CWS and performconsistency checking among different occurrencesof a particular character sequence.
For TBL, weuse the template defined in (He et al).
Our CWSsystem participate almost all the tracks and table 3lists the official results.Run ID F-Score Run ID F-Scorecityu_c_a 94.43 cityu_o_a 96.97cityu_c_b error (94.31) cityu_o_b 96.86ckip_c_a 93.17 ckip_o_a 93.25ckip_c_b 93.06 ckip_o_b 93.64ctb_c_a 94.86 ctb_o_a 97.93ctb_c_b 94.74 ctb_o_b 97.28ncc_c_a 92.99 sxu_c_a 95.46ncc_c_b 92.89 sxu_c_b 95.17Table 3: The official results on CWS closed(c)tracks and open(o) tracksIn the table 3, run (a) means that we only per-form consistency checking; run (b) means that2 We use the TBL software fromhttp://nlp.cs.jhu.edu/~rflorian/fntbl/index.html92Sixth SIGHAN Workshop on Chinese Language ProcessingTBL is performed after consistency checking isdone.
We make a mistake on cityu_c_b because werename cityu_c_a as cityu_c_b, so the two resultsare the same, after we correct the mistake andscore again; we achieve an F-measure of 94.31%.In the closed tracks, we first train initial CRFswith 3-fold cross-validation; then we test the train-ing data (three parts) with the three trained CRFs,we train the TBL learner on the training data com-pared it with the testing result from the initialCRFs.
The consistency checking is inspired by (Ngand Low, 2004).
Table 4 lists the corpus used totrain the CRFs and TBL learner in the open tracks.CRFs  TBLCityU 2005,2006,2007 2003CKIP 2007 2006CTB 2006,2007 2007Table 4.
Corpora used to train the CRFs classi-fier and the TBL learnerIn the open track, we collect the consistency listfrom all its correspondent Bakeoff corpora, thegazetteer extract from People Daily 2000 and idi-oms, slang from GKB.
From the table 3 in theclosed test, we can confirm that TBL may not im-prove CWS performance, while in most cases, per-formance will surely draw back.
The reason lies inthe fact that the learning capability of CRFs is su-perior to that of TBL, if they are trained with thesame corpus, TBL may modify some correctly tagsby CRFs.
This can be seen from Table 3 that re-sults without TBL (in run (a)) are almost superiorto that with TBL (in run (b)).4 Part-of-speech TaggingFor POS tagging task, apart from the local featuressame as used in NER, two other features are de-signed to improve the performance.?
Ambiguous part-of-speech: this feature istrue when the word has more than 2 kindsof part-of-speech.?
Major part-of-speech: The feature is as-signed as the major part-of-speech for anyword.
We do not assign the value to thenew words.Table 5 shows the performance in the closedtracks.
Because we only used the simple featuresand do not process the unknown word specially,our performance is not satisfactory.Run ID F-Score Run ID F-Scorecityu_c 87.93 ctb_c 92.03ckip_c 87.93 ncc_c 91.72ctb_c 92.03Table 5: The official results on POS tagging inclosed tracksReferencesR.
Bunescu and R. J. Mooney.
2004.
Collective Infor-mation Extraction with Relational Markov Networks.In Proceedings of the 42nd ACL, 439?446.J.
Finkel, T. Grenager, and C. D. Manning.
2005.
Incor-porating Non-local Information into Information Ex-traction Systems by Gibbs Sampling.
In Proceedingsof the 42nd ACL, 363?370.Nan He, Xinnian Mao, Yuan Dong, Haila Wang, 2007.Transformation-based Error-driven Learning as Post-processing for Chinese Word Segmentation, In Pro-ceedings of the 7th International Conference on Chi-nese Computing, 46-51, Wuhan, China.N.
Kambhatla.
2006.
Minority Vote: At-Least-N VotingImproves Recall for Extracting Relations.
In Pro-ceeding of the 44th ACL, 460?466.V.
Krishnan and C. D Manning.
2006.
An EffectiveTwo-Stage Model for Exploiting Non-Local Depend-encies in Named Entity Recognition.
In Proceedingsof the 44th ACL, 1121?1128.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Condi-tional Random Fields: Probabilistic Models for Seg-menting and Labeling Sequence Data.
In Proceed-ings of the 18th ICML, 282?289, San Francisco, CA.G.
Levow.
2006.
The Third International Chinese Lan-guage Processing Bakeoff: Word Segmentation andNamed Entity Recognition.
In Proceedings ofSIGHAN-2006, 108-117.
Sydney, Australia.Xinnian Mao, Xu Wei, Yuan Dong, Saike He and HailaWang, 2007.
Using Non-local Features to ImproveNamed Entity Recognition Recall, In Proceedings ofthe 21th Pacific Asia Conference on Language, In-formation and Computation, 303-310, Seoul, Korea.Hwee Tou Ng, Jin Kiat Low, 2004.
Chinese Part-of-Speech Tagging: One-at-a-Time or All at Once?Word-based or Character based?
In Proceedings ofthe Conference on Empirical Methods in NaturalLanguage Processing, Spain.93Sixth SIGHAN Workshop on Chinese Language Processing
