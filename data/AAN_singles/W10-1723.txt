Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 161?166,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsThe LIG machine translation system for WMT 2010Marion Potet, Laurent Besacier and Herve?
BlanchonLIG Laboratory, GETALP TeamUniversity Joseph Fourier, Grenoble, France.Marion.Potet@imag.frLaurent.Besacier@imag.frHerve.Blanchon@imag.frAbstractThis paper describes the system submit-ted by the Laboratory of Informatics ofGrenoble (LIG) for the fifth Workshopon Statistical Machine Translation.
Weparticipated to the news shared transla-tion task for the French-English languagepair.
We investigated differents techniquesto simply deal with Out-Of-Vocabularywords in a statistical phrase-based ma-chine translation system and analyze theirimpact on translation quality.
The finalsubmission is a combination between astandard phrase-based system using theMoses decoder, with appropriate setupsand pre-processing, and a lemmatized sys-tem to deal with Out-Of-Vocabulary con-jugated verbs.1 IntroductionWe participated, for the first time, to the sharednews translation task of the fifth Workshop on Ma-chine Translation (WMT 2010) for the French-English language pair.
The submission wasperformed using a standard phrase-based trans-lation system with appropriate setups and pre-processings in order to deal with system?s un-known words.
Indeed, as shown in (Carpuat,2009), (Habash, 2008) and (Niessen, 2004), han-dling Ou-of-Vocabulary words with techniqueslike lemmatization, phrase table extension or mor-phological pre-processing is a way to improvetranslation quality.
After a short presentation ofour baseline system setups we discuss the effectof Out-Of-Vocabulary words in the system and in-troduce some ideas we chose to implement.
In thelast part, we evaluate their impact on translationquality using automatic and human evaluations.2 Baseline System Setup2.1 Used ResourcesWe used the provided Europarl and News par-allel corpora (total 1,638,440 sentences) to trainthe translation model and the News monolin-gual corpora (48,653,884 sentences) to train thelanguage model.
The 2008 News test corpora(news-test2008; 2,028 sentences) was used to tunethe produced system and last year?s test corpora(news-test2009; 3,027 sentences) was used forevaluation purposes.
These corpora will be ref-ered to as Dev and Test later in the paper.
As pre-processing steps, we applied the PERL scripts pro-vided with the corpora to lowercase and tokenisethe data.2.2 Language modelingThe target language model is a standard n-gramlanguage model trained using the SRI languagemodeling toolkit (Stocke, 2002) on the newsmonolingual corpus.
The smoothing technique weapplied is the modified Kneser-Ney discountingwith interpolation.2.3 Translation modelingThe translation model was trained using the par-allel corpus described earlier (Europarl+News).First, the corpus was word aligned and then, thepairs of source and corresponding target phraseswere extracted from the word-aligned bilingualtraining corpus using the scripts provided withthe Moses decoder (Koehn et al, 2007).
The re-sult is a phrase-table containing all the alignedphrases.
This phrase-table, produced by the trans-lation modeling, is used to extract several transla-tions models.
In our experiment we used thirteenstandard translation models: six distortion models,a lexicon word-based and a phrase-based transla-tion model for both direction, and a phrase, wordand distortion penalty.1612.4 Tuning and decodingFor the decoding (i.e.
translation of the testset), the system uses a log-linear combination ofthe previous target language model and the thir-teen translation models extracted from the phrase-table.
As the system can be beforehand tuned byadjusting log-linear combination weights on a de-velopement corpus, we used the Minimum ErrorRate Training (MERT) method, by (Och, 2003).3 Ways of Improvements3.1 Discussion about Out-Of-Vocabularywords in PBMT systemsPhrase-based statistical machine translation(PBMT) use phrases as units in the translationprocess.
A phrase is a sequence of n consecutivewords known by the system.
During the training,these phrases are automaticaly learned and eachsource phrase is mapped with its correspondingtarget phrase.
Throughout test set decoding, aword not being part of this vocabulary list islabeled as ?Out-Of-Vocabulary?
(OOV) and, as itdoesn?t appear in the translation table, the systemis unable to translate it.
During the decoding,Out-Of-Vocabulary words lead to ?broken?phrases and degrade translation quality.
For thesereasons, we present some techniques to handleOut-Of-Vocabulary words in a PBMT system andcombine these techniques before evaluating them.In a preliminary study, we automatically ex-tracted and manually analyzed OOVs of a 1000sentences sample extracted from the test cor-pus (news-test2009).
There were altogether 487OOVs tokens wich include 64.34% proper nounsand words in foreign languages, 17.62% commonnouns, 15.16% conjugated verbs, 1.84% errors insource corpus and 1.02% numbers.
Note that, asour system is configured to copy systematicallythe OOVs in the produced translated sentence, therewriting of proper nouns and words in foreignlanguage is straightforward in that case.
However,we still have to deal with common nouns and con-jugated verbs.Initial sentence:?Cela ne marchera pas?
souligna-t-il par la suite.Normalised sentence:?Cela ne marchera pas?
il souligna par la suiteFigure 1: Normalisation of the euphonious ?t?3.2 Term expansion with dictionaryThe first idea is to expand the vocabulary size,more specifically minimizing Out-Of-Vocabularycommon nouns adding a French-English dictio-nary during the training process.
In our experi-ment, we used a free dictionnary made availableby the Wiktionary1 collaborative project (wichaims to produce free-content multilingual dictio-naries).
The provided dictionnary, containing15,200 entries, is added to the bilingual trainingcorpus before phrase-table extraction.3.3 Lemmatization of the French sourceverbsTo avoid Out-Of-Vocabulary conjugated verbs oneidea is to lemmatize verbs in the source train-ing and test corpus to train a so-called lemma-tized system.
We used the freely available Frenchlemmatiser LIA TAGG (Be?chet, 2001).
But, ap-plying lemmatization leads to a loss of informa-tion (tense, person, number) which may affectdeeply the translation quality.
Thus, we decidedto use the lematized system only when OOV verbsare present in the source sentence to be trans-lated.
Consequently, we differentiate two kindsof sentences: -sentences containing at least oneOOV conjugated verb, and - sentences which donot have any conjugated verb (these latter sen-tences obviously don?t need any lemmatization!
).Thereby, we decided to build a combined trans-lation system which call the lemmatized systemonly when the source sentence contains at leastone Out-Of-Vocabulary conjugated verb (other-wise, the sentence will be translated by the stan-dard system).
To detect sentences with Out-Of-Vocabulary conjugated verb we translate each sen-tence with both systems (lemmatized and stan-dard), count OOV and use the lemmatized transla-tion only if it contains less OOV than the standardtranslation.
For example, a translation containingk Out-Of-Vocabulary conjugated verbs and n oth-ers Out-Of-Vocabulary words (in total k+n OOV)with the standard system, contains, most probably,only n Out-Of-Vocabulary words with the lemma-tised system because the conjugated verbs will belemmatized, recognized and translated by the sys-tem.1http://wiki.webz.cz/dict/1623.4 Normalization of a special French formWe observed, in the French source corpra, a spe-cial French form which generates almost alwaysOut-Of-Vocabulary words in the English transla-tion.
The special French form, named euphonious?t?, consists of adding the letter ?t?
between a verb(ended by ?a?, ?e?
or ?c?)
and a personal pronounand, then, inverse them in order to facilitate theprononciation.
The sequence is represented by:verb-t-pronoun like annonca-t-elle, arrive-t-il, a-t-on, etc.
This form concerns 1.75% of the Frenchsentences in the test corpus whereas these accountfor 0.66% and 0.78% respetively in the trainingand the developement corpora.
The normalizedproposed form, illustrated below in figure 1, con-tains the subject pronoun (in first posistion) andthe verb (in the second position).
This change hasno influence on the French source sentence and ac-cordingly on the correctness and fluency of the En-glish translation.3.5 Adaptation of the language modelFinally, for each system, we decided to apply dif-ferent language models and to look at those whoperfom well.
In addition to the 5-gram languagemodel, we trained and tested 3-gram and 4-gramlanguage models with two different kinds of vo-cabularies : - the first one (conventional, refered toas n-gram in table 3) contains an open-vocabularyextracted from the monolingual English trainingdata, and - the second one (refered to as n-gram-vocab in table 3) contains a closed-vocabulary ex-tracted from the English part of the bilingual train-ing data.
In both cases, language model probabil-ities are trained from the monolingual LM train-ing data but, in the second case, the lexicon is re-stricted to the one of the phrase-table.4 Experimental resultsIn the automatic evaluation, the reported evalu-ation metric is the BLEU score (Papineni et al,2002) computed by MTEval version 13a.
The re-sults are reported in table 1.
Note that in our ex-periments, according to the resampling method of(Koehn, 2004), there are significative variations(improvement or deterioration), with 95% cer-tainty, only if the difference between two BLEUscores represent, at least, 0.33 points.
To completethis automatic evaluation, we performed a humananalysis of the systems outputs.4.1 Standard systems4.1.1 Term expansion with dictionaryRegarding the results of automatic evaluation (ta-ble 1, system (2)), adding the dictionary do notleads to a significant improvement.
The OOVrate and system perplexity are reduced but, ignor-ing the tuned system which presents lower per-formance, the BLEU score decreases significatlyon the test set.
The BLEU score of the systemaugmented with the dictionary is 24.50 whereasthe baseline one is 24.94.
So we can concludethat there is not a meaningfull positive contribu-tion, probably because the size of the dictionaryis very small regarding the bilingual training cor-pus.
We found out very few Out-Of-Vocabularywords of the standard system recognized by thesystem with the dictionary, see figure 2 for exam-ple (among them : coupon, cafard, blonde, retar-dataire, me?dicaments, pamplemousse, etc.).
But,as the dictionnary is very small, most OOV com-mon words like ho?tesse and clignotant are still un-known.
Regarding the output sentences, we notethat there are very few differences and the qualityis equivalent.
The dictionary used is to small toextend the system?s vocabulary and most of wordsstill Out-Of-Vocabulary are conjugated verbs andunrecognized forms.Baseline system:A cafard fled before the danger, but if he felt fear?System with dictionary:A blues fled before the danger, but if he felt fear?Figure 2: Example of sentence with an OOV com-mon noun4.1.2 Normalisation of special French formConsidering the BLEU score, the normalization ofFrench euphonious ?t?
have, apparently, very fewrepercussion on the translation result (table 1, sys-tem (3)) but the human analysis indicates that, inour context, the normalisation of euphonious ?t?brings a clear improvement as seen in example 3.Consequently, this preprocessing is kept in the fi-nal system.4.1.3 TuningWe can see in table 1 that the usual tuning withMinimum Error Rate Training algorithm deterio-rates systematically performance scores on the testset, for all systems.
This can be explained by the163System OOVs ppl Dev score Test score(1) Baseline 2.32% 207 29.72 (19.93) 23.77 (24.94)(2) + dictionary 2.30% 204 30.01 (23.92) 24.32 (24.50)(3) + normalization 2.31% 204 30.07 (19.90) 23.99 (24.98)(4) + normalization + Dev data 2.30% 204 / (/) / (25,05)Table 1: Standard systems BLEU scores with tuning (without tuning)/ LM 5-gramBaseline system:?It will not work?
souligna-t-il afterwards.System with normalisation:?It will not work?
he stressed afterwards.Figure 3: Example of sentence with a ?verb-t-pronoun?
formgap between the developement and test corpora (iethe Dev set may be not representative of the Testset).
So, even if it is recommanded in the standardprocess, we do not tune our system (we use the de-fault weights proposed by the Moses decoder) andadd the developement corpus to train it.
In thiscase, the training set contains 1,640,468 sentences(the initial 1,638,440 sentences and the 2,028 sen-tences of the developement set).
This slightly im-proves the system (from 24.98, the BLEU scoreraise to 25,05 after adding the developpement setto the training).4.2 Lemmatised systemsResults of lemmatised systems are reported on ta-ble 2.
First, we can notice that, in this particularcase, the tuning (with MERT method) is manda-tory to adapt the weights of the log linear model.Our analysis of the tuned weight of the lemma-tised system shows that, in particular, the wordpenalty model has a very low weight (this favoursshort sentences) and the lexical word-based trans-lation models have a very low weight (no use ofthe lexical translation probability).
We also no-tice that the lemmatization leads to a real drop-offof OOV rate (fall from 2.32% for the baseline, to2.23% for the lemmatized system) and perplexity(fall from 207 for the baseline, to 178 for the lem-matized system).
We can observe a clear decreaseof the performance with the lemmatized system(BLEU score of 20.50) compared with a non-lemmatized one (BLEU score of 24.94).
This canbe significatively improved applying euphonious?t?
normalization to the source data (BLEU scoreof 22.14).
Almost all French OOV conjugatedverbs with the standard system were recognizedby the lemmatized one (trierait, joues, testaient,immerge?e, e?conomiseraient, baisserait, pre?pares,etc.)
but the small decrease of the translation qual-ity can be explained, among other things, by sev-eral tense errors.
See illustration in figure 4.
So,we conclude that the systematic normalization ofFrench verbs, as a pre-process, reduce the Out-Of-Vocabulary conjugated verbs but decrease slighlythe final translation quality.
The use of such a sys-tem is helpfull especially when the sentence con-tains conjugated verbs (see example 5).4.3 Adaptation of the language modelWe applied five differents language models (3-gram and 4-gram language models with selectedvocabulary or not and a 5-gram language model)to the four standard systems and the two lemma-tised one.
The results, reported in table 3, showthat BLEU score can be significantly different de-pending on the language model used.
For exam-ple, the fifth system (5) obtained a BLEU score of21.48 with a 3-gram language model and a BLEUscore of 22.84 with a 4-gram language model.
Wecan also notice that five out of our six systems out-perform using a language model with selected vo-cabulary (n-gram-vocab).
One possible explana-tion is that with LM using selected vocabulary (n-gram-vocab), there is no loss of probability massfor english words not present in the translation ta-ble.4.4 Final combined systemConsidering the previous observations, we believethat the best choice is to apply the lemmatizedsystem only if necessary i.e.
only if the sentencecontains OOV conjugated verbs, otherwise, a stan-dard system should be used.
We consider system(4), with 4-gram-vocab language model (selectedvocabulary) without tuning, as the best standardsystem and system (6), with 3-gram-vocab lan-guage model (selected vocabulary) not tuned ei-ther, as the best lemmatized system.
The final164System OOVs ppl Dev score Test score(5) lemmatization 2.23% 178 20.97 (8.57) 20.50 (8.56)(6) lemmatization + normalization 2.18% 175 27.81 (9.20) 22.14 (10.82)Table 2: Lemmatised systems BLEU scores with tuning (without tuning)/ LM 5-gramBaseline system: You will be limited by the absence of exit for headphones.Lemmatised system: You are limited by the lack of exit for ordinary headphones.reference: You will be limited by the absence of output on ordinary headphones.Figure 4: Example of sentences without OOV verbssystem translations are those of the lemmatizedsystem (6) when we translate sentences with oneor more Out-Of-Vocabulary conjugated verbs andthose of the un-lemmatized system (4) otherwise.Around 6% of test set sentences were translatedby the lemmatized system.
Considering the resultsreported in table 4, the combined system?s BLEUscore is comparable to the standard one (25.11against 25.17).System Test score sentences(4) Standard sys.
25.17 94 %(6) Lemmatised sys.
22.89 6%(7) Combined 25.11 100 %Table 4: Combined system?s results and % trans-lated sentences by each system5 Human evaluationWe compared two data set.
The first set (selectedsent.)
contains 301 sentences selected from testdata by the combined system (7) to be translatedby the lemmatized system (6) whereas the secondset (random sent.)
contains 301 sentences ran-domly picked up.
The latter is our control data set.We compared for both groups the translation hy-pothesis given by the lemmatized system and thestandard one.We performed a subjective evaluation with theNIST five points scales to measure fluency and ad-equacy of each sentences through SECtra w inter-face (Huynh et al, 2009).We involved a total of 6volunteers judges (3 for each set).
We evaluatedthe inter-annotator agreement using a generalizedversion of Kappa.
The results show a slight to fairagreement according (Landis, 1977).The evaluation results, detailled in table 5 and 6,showed that both fluency and adequacy were im-proved using our combined system.
Indeed, for arandom input (random sent.
), the lemmatized sys-tem lowers the translations quality (fluency andadequacy are degraded for, respectively, 35.8%and 37.5% of the sentences), while it improvesthe quality for sentences selected by the combinedsystem (for ?selected sent.
?, fluency and adequacyare improved or stable for 81% of the sentences).Adequacy selected sent.
random sent.
(6) ?
(4) 81% 62.4%(6) < (4) 18.9% 37.5%Table 5: Subjective evaluation of sentences ade-quacy ((6) lemmatized system - (4) standard sys-tem)Fluency selected sent.
random sent.
(6) ?
(4) 81% 64.1%(6)<(4) 18.9% 35.8%Table 6: Subjective evaluation of sentences flu-ency ((6) lemmatized system - (4) standard sys-tem)6 Conclusion and DiscussionWe have described the system used for our sub-mission to the WMT?10 shared translation task forthe French-English language pair.We propose dsome very simple techniques toimprove rapidely a statistical machine translation.Those techniques particularly aim at handlingOut-Of-Vocabulary words in statistical phrase-based machine translation and lead an improvedfluency in translation results.
The submited sys-tem (see section 4.4) is a combination between astandard system and a lemmatized system with ap-propriate setup.165Baseline system: At the end of trade, the stock market in the negative bascula.Lemmatised system: At the end of trade, the stock market exchange stumbled into the negative.Baseline system: You can choose conseillera.Lemmatised system: We would advise you, how to choose.Figure 5: Example of sentences with OOV conjugated verbsSystem 3-gram 3-gram-vocab 4-gram 4-gram-vocab 5-gram(1) 24.60 24.95 24.94 25.11 24.94(2) 25.14 25.17 24.50 23.49 24.50(3) 24.88 25.00 24.98 25.15 24.98(4) 24.92 24.99 25.05 25.17 25.05(5) 21.48 19.48 22.84 20.18 20.50(6) 22.60 22.89 22.14 22.24 22.14Table 3: Systems?s results on test set with differents language modelsThis system evaluation showed a positive influ-ence on translation quality, indeed, while the im-provements on automatic metrics are small, man-ual inspection suggests a significant improvementsof translation fluency and adequacy.In future work, we plan to investigate and de-velop more sophisticated methods to deal withOut-Of-Vocabulary words, still relying on the an-alyze of our system output.
We believe, for ex-ample, that an appropriate way to use the dictio-nary, a sensible pre-processings of French sourcetexts (in particular normalization of some specificFrench forms) and a factorial lemmatization withthe tense information can highly reduce OOV rateand improve translation quality.ReferencesPhilipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-dra Constantin, Evan Herbst.
2007.
Moses: OpenSource Toolkit for Statistical Machine Translation.Annual Meeting of the Association for Computa-tional Linguistics (ACL).
Prague, Czech Republic.Papineni K., Roukos S., Ward T., and Zhu W.J.
2002.BLEU: a method for automatic evaluation of ma-chine translation.
ACL-2002: 40th Annual meetingof the Association for Computational Linguistics,pp.
311?318.
Philadelphia, Pennsylvania, USA.Andreas Stolcke.
2002.
SRILM - An Extensible Lan-guage Modeling Toolkit.
International Conferenceon Spoken Language Processing, Vol.
2, pp 901?904.
Denver, Colorado, USA.Frederic Be?chet.
2001.
LIA TAGG.
http://old.lia.univ-avignon.fr/chercheurs/bechet/download fred.html.Franz Josef Och.
2003.
Minimum error rate train-ing for statistical machine translation.
Annual Meet-ing of the Association for Computational Linguistics(ACL).
Sapporo, July.Philipp Koehn.
2004.
Statistical significance testsfor machine translation evaluation.
conference onEmpirical Methods in Natural Language Processing(EMNLP), pp 388?395.
Barcelona, Spain.Marine Carpuat.
2009.
Toward Using Morphology inFrench-English Phrase-based SMT.
Workshop onMachine Translation in European Association forComputational Linguistics (EACL-WMT), pp 150?154.
Athens, Greece.Sonja Niessen and Hermann Ney.
2004.
StatisticalMachine Translation with Scarce Resources UsingMorpho-syntactic Information.
Computational Lin-guistics, vol.
30, pp 181?204.Nizar Habash.
2008.
Four techniques for OnlineHandling of Out-Of-Vocabulary Words in Arabic-English Statistical Machine Translation.
HumanLanguage Technology Workshop in Association forComputational Linguistics, (ACL-HTL), pp 57?60.Columbus, Ohio, USA.Landis J. R. and Koch G. G.. 1977.
The Measurementof Observer Agreement for Categorical Data.
Bio-metrics, vol.
33, pp.
159?174.Herve?
Blanchon, Christian Boitet and Cong-PhapHuynh.
2009.
A Web Service Enabling Grad-able Post-edition of Pre-translations Produced byExisting Translation Tools: Practical Use to ProvideHigh-quality Translation of an Online Encyclopedia.MT Summit XII, Beyond Translation Memories: NewTools for Translators Workshop, pp 20?27.
Ottawa,Canada.166
