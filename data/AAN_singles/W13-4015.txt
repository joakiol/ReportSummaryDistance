Proceedings of the SIGDIAL 2013 Conference, pages 107?111,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsPatterns of Importance Variation in Spoken DialogNigel G. WardUniversity of Texas at El PasoEl Paso, Texas, 79968 USAnigelward@acm.orgKaren A. Richart-RuizUniversity of Texas at El PasoEl Paso, Texas, 79968 USAkarichart@miners.utep.eduAbstractSome things people say are more impor-tant, and some less so.
Importance variesfrom moment to moment in spoken dialog,and contextual prosodic features and pat-terns signal this.
A simple linear regres-sion model over such features gave esti-mates that correlated well, 0.83, with hu-man importance judgments.1 Importance in Language and DialogNot everything people say to each other is equallyimportant, for example many ums and uhs have al-most no significance, in comparison to those con-tent words or nuances that are critical in one wayor another.Many language processing applications need todetect what is important in the input stream, in-cluding dialog systems and systems for summa-rization, information retrieval, information extrac-tion, and so on.
Today this is primarily doneusing task-specific heuristics, such as discardingstopwords, giving more weight to low frequencywords, or favoring utterances with high averagepitch.
In this paper, however, we explore a gen-eral, task-independent notion of importance, tak-ing a dialog perspective.Section 2 explains our empirical approach.
Sec-tions 3 and 4 explore the individual prosodic fea-tures and longer prosodic patterns that dialog par-ticipants use to signal to each other what is impor-tant and unimportant.
Section 5 describes predic-tive models that use this information to automat-ically estimate importance and Section 6 summa-rizes the significance and future work needed.2 Annotating ImportanceNo standard definition of importance is useful fordescribing what happens, moment-by-moment, inspoken dialog.
The closest contender would beentropy, as defined in information theory.
Fortext we can measure the difficulty of guessing let-ters or words, as a measure of their unpredictabil-ity and thus informativeness (Shannon, 1951), butthis is indirect, time-consuming, and impossibleto apply to non-symbolic aspects of language.
Wecan also measure the value of certain information,such as prosody, for improving the accuracy ofpredictions, but again this is indirect and time-consuming (Ward and Walker, 2009).We therefore chose to do an empirical study.
Wehired a student to annotate importance.
Wantingto capture her naive judgments, atheoretically, wedid not precisely define importance for her.
In-stead we discussed the concept briefly, noting thatimportance may be judged: not just by contentbut also by value for directing the future courseof the dialog, not just from the speaker?s perspec-tive but also from the listener?s, and not just fromthe words said but also from how they were said.The labeling tool used enabled the annotator tonavigate back and forth in the dialogs, listen to thespeakers together in stereo or independently, de-limit regions of any desired size including wordsand word fragments, and ascribe to each region animportance value.
While importance is continu-ous, for convenience we used the whole numbersfrom 0 to 5, with 5 indicating highest importance,4 typical importance, 3 somewhat less importance,2 and 1 even less, and 0 silence.
To have a varietyof speakers, topics, and speaking styles, the mate-rial was from the Switchboard corpus (Godfrey etal., 1992).107Figure 1: Importance versus Time, in milliseconds.
Rectangular line: Annotator judgments; Jagged line:Predictions (discussed below).
The words are all by one speaker, horizontally positioned by approximateoccurrence.In total, she labeled both tracks of just over 100minutes of dialog.
There was diversity in labels,supporting our belief that importance is not mono-tone: the largest fraction of non-zero-labeled re-gions, covering 38% of the total time, was at level4, but there were also 20% at level 3 and 37% atlevel 5.
In general importance was variable, onaverage staying at the same level for only 1.5 sec-onds.
Figure 1 illustrates.In parallel, the second author labeled 17 min-utes of the same dialogs1.
The agreement in termsof Kappa was .80 (?very good?)
across all cate-gories, and .67 (?good?)
excluding the zero-levellabels, which were mostly for silent regions andthus easy to agree on.
In terms ofWeighted Kappa,appropriate here since the labels are ordered (andthus, for example, a 1-point difference mattersmuch less than a 5-point difference), the agree-ment levels were .92 and .71, for all and for thezero-excluding sets, respectively.
The differenceswere mainly due to minor variations in boundaryplacement, missing labels for small quiet soundssuch as inbreaths and quiet overlapping backchan-nels, and different ratings of repeated words, andof backchannels (Ward and Richart-Ruiz, 2013).3 Correlating Prosodic FactorsFirst we briefly examined lexical correlates of im-portance, by examining the average importanceof words in this corpus (Ward and Richart-Ruiz,2013).
To summarize some key findings: Less fre-quent words tend to have higher average per-wordimportance, however ratings vary widely, depend-ing on context.
Some words have effects at a dis-tance, for example, because tends to indicate that1All labels are freely available athttp://www.cs.utep.edu/nigel/importance/whatever is said one second later will be impor-tant.
The interlocutor?s words can also be infor-mative, for example oh and uh-huh tend to indi-cate that whatever the interlocutor said one secondago was important.
The ?words?
with the mostextreme average importance ?
notably uh-huh,um-hum, um and laughter ?
are fillers, backchan-nels and other vocalizations of types which canbe detected well from the prosodic and inter-actional contexts (Neiberg and Gustafson, 2011;Truong and van Leeuwen, 2007).
Thus a word-based model of importance would be challengingto build and might not have much value.
We there-fore turned our attention to prosody.While prosody-importance connections havenot been considered directly, several studies havefound correlations between prosodic features andvarious importance-related constructs, such aspredictability, involvement, engagement, activa-tion, newness, and interest (Bell et al 2009; Yuet al 2004; Batliner et al 2011; Roehr and Bau-mann, 2010; Oertel et al 2011; Hsiao et al 2012;Kahn and Arnold, 2012; Kawahara et al 2010).However these studies have all been limited to spe-cific features, functions, or hypotheses.
Our aimsbeing instead exploratory, we looked for features,from among a broad inventory, which correlatewith importance, as it occurs in a broad variety ofcontexts.Our feature inventory included features of 8classes: four basic types ?
volume, pitch height,pitch range, and speaking-rate ?
each computedfor both participants: the speaker and the inter-locutor.
Within each class, features were com-puted over windows of various widths and at var-ious offsets, for a total of 78 features (Ward andRichart-Ruiz, 2013).108The speaker features correlating most stronglywith importance were volume and speaking rate.Although the very strongest correlations were withvolume slightly in the past, volume both beforeand after the current moment was strongly cor-related over all windows, with one exception.Speaker pitch height, in contrast, correlated neg-atively with importance across all windows, con-trary to what is often seen in monolog data.The interlocutor features correlating moststrongly with importance were again volume andspeaking rate, but only over windows close to thepoint of interest, perhaps due to co-constructionor supportive back-channeling; over more distantwindows, both past and future, these correlate neg-atively.
Interlocutor pitch range correlated nega-tively over all windows.4 Correlating Dialog-Activity PatternsThus we find that some prosodic features have dif-ferent effects depending on their offset from theframe of interest.
Perhaps prosody is not justmarking importance vaguely somewhere in thearea, but more precisely indicating important andunimportant moments.To explore this we used Principal ComponentsAnalysis (PCA), as described in detail in (Wardand Vega, 2012).
In short, this method findspatterns of prosodic features which co-occur fre-quently in the data, and so provides an unsuper-vised way to discover the latent structure underly-ing the observed regularities.
We correlated the di-mensions resulting with PCA with the importancevalues.
Many dimensions had significant correla-tions, indicating that importance relates to manyprosodic structures and contexts.
Each dimensionhad two characteristic patterns, one correspondingto high values on that dimension and one to lowvalues.
We were able to interpret most of these interms of dialog activities (Ward and Vega, 2012).Tending to be more important was: speech inthe middle of other speech (dimension 1), ratherthan words snuck in while the other has the floor;simultaneous speech (dimension 2), understand-ably as such times tended to be high in involve-ment and/or backchannels; times of encounteringand resolving turn conflicts (dimension 7), morethan places where the participants were support-ively interleaving turns, which in this corpus weregenerally more phatic than contentful; crisp turnends (dimension 8), rather than slow repetitiousmodel correlation m.a.e.m5pTree decision tree .38 1.21neural network .66 1.20simple linear regression .79 .89linear regression .83 .75ditto, past-only features .83 .79Table 1: Prediction Quality in terms of correlationand mean absolute error, for various learning algo-rithms.wind-downs; ?upgraded assessments,?
in which aspeaker agrees emphatically with an assessmentmade by the other (dimension 6); and times whenspeakers were solicitous, rather than controlling(dimension 19).
Dimension 6 is interesting inthat it matches an interaction pattern described asan exemplar of prosodic co-construction (Ogden,2012).
Dimension 19 was one of those underlyingthe exception noted above: the negative correla-tion between importance and speaker volume overthe window from 0?50 milliseconds after the pointof prediction.
Upon examination, low volume atthis offset often occurred when seeking agreementand during quiet filled pauses in the vicinity ofhigh-content words.5 Predictive ModelsWe next set out to build predictive models, for tworeasons: to judge whether the features discussedabove are adequate for building useful models, andto determine what additional factors would be re-quired in a more complete model.The task is, given a timepoint in a track in a dia-log, to predict the importance of what the speakeris saying at that moment.
Our performance met-rics were the mean absolute error and the correla-tion coefficient, computed over all frames; thus apredictor is better to the extent that its predictionsare close to and correlate highly with the annota-tor?s labels, including the implicit zero labels inregions of silence or noise.We built models using four algorithms in Weka.All models performed poorly on dialogs for whichthere was cross-track bleeding or other noise.
Asthese are artifacts of this corpus and would not berelevant for most applications, our main evaluationused only the five tracks with good audio quality.These all had different speakers.
We did five-foldcross-validation on this; Table 1 gives the results.Linear regression was best, by both measures and109past future all?400 ?200 0speaker .55 .64 .66 .59 .70interloc.
.37 .43 .43 .37 .47both .62 .70 .71 .65 .74Table 2: Model Quality, in terms of R2, as a func-tion of the features used.across every fold, and this was consistent for allthe other training and test sets tried.To compare the performance of this predictor tohuman performance, we also trained a model us-ing 5 tracks to predict performance over two testtracks, a total of 224495 test datapoints, whichthe second judge also had annotated.
Over thesethe predictor did almost as well as second judgein correlation (.88 versus .92), but not so well interms of mean absolute error (.75 versus .31).Analyzing the errors, we noted several types ofcause (Ward and Richart-Ruiz, 2013).
First, per-formance varied widely across tracks, with meanabsolute errors from .55 to .97, even though all thefeatures were speaker-normalized.
The high valuewas for a speaker who was an outlier in two re-spects: the only female among four males, and theonly East-Coast speaker among four Texans.
Thusresults might be improved by separately model-ing different genders and dialects.
Second, predic-tions were often off in situations like those wherethe two human judges disagreed.
Third, most ofthe errors were due to feature-set issues: robust-ness, poor loudness features, and not enough fine-grained features.
Fourth, our prosodic-feature-only model did very poorly at distinguishing be-tween the highest importance levels, 4 and 5, butwas otherwise generally good.Table 2 shows how performance varies with thefeatures used; here quality is measured using sim-ply the R2 of a linear regression over all the data.Performance is lower with only the left-contextfeatures, as would be required for real-time appli-cations, but not drastically so; as seen also in thelast line of Table 1.
Performance is only slightlylower when predicting slightly in advance, withoutusing any features closere than 200 ms prior to theprediction point, but notably worse 400 ms before.Features of the interlocutor?s behavior are helpful,partially why explaining dialog can be easier tounderstand than monolog (Branigan et al 2011).6 Broader Significance and Future WorkSperber and Wilson argue that ?attention andthought processes .
.
.
automatically turn toward in-formation that seems relevant: that is, capable ofyielding cognitive effects?
(Sperber and Wilson,1987).
This paper has identified some of the cuesthat systems can use to ?automatically turn to-ward?
the most important parts of the input stream.Overall, these findings show that task-independentimportance can be identified fairly reliably, andthat it can be predicted fairly well using simpleprosodic features and a simple model.
Signifi-cantly, we find that importance is frequently notsignaled or determined by one participant alone,but is often truly a dialog phenomenon.
We seethree main directions for future work:First, there is ample scope to build better modelsof importance, not only by pursuing the prosodic-feature improvements noted above, but in exam-ining lexical, semantic, rhetorical-structure anddialog-structure correlates of importance.Second, one could work to put our pretheoreti-cal notion of importance on a firmer footing, per-haps by relating it to entropy, or to the time courseof the psychological processes involved in retriev-ing, creating, managing, and packaging informa-tion into speech; or to the design and timing ofdialog contributions so as not to overload the lis-tener?s processing capacity.Third, there are applications.
For example, adialog system needing to definitely convey someinformation to the user could use an appropriateprosodic lead-in to signal it properly, doing an in-teractional dance (Gratch et al 2007; Brennan etal., 2010) to prepare the recipient to be maximallyreceptive at the moment when the critical wordis said.
Another potential application is in voicecodecs, as used in telecommunications.
Today?scodecs treat all speech as equally valuable.
In-stead we would like to transmit more importantwords and sounds at higher quality, and less im-portant ones at lower quality, thereby increasingperceived call quality without increasing the aver-age datarate, of course while properly consideringall perceptual factors (Voran and Catellier, 2013).AcknowledgmentsThis work was supported in part by the NSF un-der projects IIS-0914868 and CNS-0837556.
Wethank Timo Baumann, Alejandro Vega, ShreyasKarkhedkar, Gabriela Almeida and David Novick.110ReferencesAnton Batliner, Stefan Steidl, Bjorn Schuller, et al2011.
Whodunnit: Searching for the most importantfeature types signalling emotion-related user statesin speech.
Computer Speech and Language, 25:4?28.Alan Bell, Jason M. Brenier, Michelle Gregory, Cyn-thia Girand, and Dan Jurafsky.
2009.
Predictabilityeffects on durations of content and function wordsin conversational English.
Journal of Memory andLanguage, 60:92?111.Holly P. Branigan, C.M.
Catchpole, andM.J.
Pickering.2011.
What makes dialogues easy to understand?Language and Cognitive Processes, 26:1667?1686.Susan E. Brennan, Alexia Galati, and Anna K. Kuhlen.2010.
Two minds, one dialog: Coordinating speak-ing and understanding.
In Brian H. Ross, editor, ThePsychology of Learning and Motivation, volume 53,pages 301?344.
Elsevier.John J. Godfrey, Edward C. Holliman, and Jane Mc-Daniel.
1992.
Switchboard: Telephone speech cor-pus for research and development.
In Proceedingsof ICASSP, pages 517?520.Jonathan Gratch, Ning Wang, Jillian Gerten, EdwardFast, and Robin Duffy.
2007.
Creating rapport withvirtual agents.
In Intelligent Virtual Agents, pages125?138.
Springer.Joey Chiao-yin Hsiao, Wan-rong Jih, and Jane Yung-jen Hsu.
2012.
Recognizing continuous social en-gagement level in dyadic conversation by using turn-taking and speech emotion patterns.
In Activity Con-text Representation Workshop at AAAI.Jason M. Kahn and Jennifer E. Arnold.
2012.A processing-centered look at the contribution ofgivenness to durational reduction.
Journal of Mem-ory and Language, 67:311?325.Tatsuya Kawahara, K.Sumi, Z.Q.
Chang, andK.Takanashi.
2010.
Detection of hot spots in posterconversations based on reactive tokens of audience.In Interspeech, pages 3042?3045.Daniel Neiberg and Joakim Gustafson.
2011.
A dualchannel coupled decoder for fillers and feedback.
InInterspeech 2011, pages 3097?3100.Catharine Oertel, Stefan Scherer, and Nick Campbell.2011.
On the use of multimodal cues for the predic-tion of degrees of involvment in spontaneous con-versation.
In Interspeech.Richard Ogden.
2012.
Prosodies in conversation.
InOliver Niebuhr, editor, Understanding Prosody: Therole of context, function, and communication, pages201?217.
De Gruyter.Christine Tanja Roehr and Stefan Baumann.
2010.Prosodic marking of information status in German.In Speech Prosody Conference.Claude E. Shannon.
1951.
Prediction and entropyof printed English.
Bell System Technical Journal,30:50?64.Dan Sperber and Deirdre Wilson.
1987.
Pre?cis of Rel-evance: Communication and cognition.
Behavioraland Brain Sciences, 10(04):697?710.Khiet P. Truong and David A. van Leeuwen.
2007.
Au-tomatic discrimination between laughter and speech.Speech Communication, 49:144?158.Stephen D. Voran and Andrew A. Catellier.
2013.When should a speech coding quality increase be al-lowed within a talk-spurt?
In IEEE ICASSP.Nigel G. Ward and Karen A. Richart-Ruiz.
2013.
Lex-ical and prosodic indicators of importance in spokendialog.
Technical Report UTEP-CS-13-41, Univer-sity of Texas at El Paso, Department of ComputerScience.Nigel G. Ward and Alejandro Vega.
2012.
A bottom-up exploration of the dimensions of dialog state inspoken interaction.
In 13th Annual SIGdial Meetingon Discourse and Dialogue.Nigel G. Ward and Benjamin H. Walker.
2009.
Esti-mating the potential of signal and interlocutor-trackinformation for language modeling.
In Interspeech,pages 160?163.Chen Yu, Paul M. Aoki, and Alison Woodruff.
2004.Detecting user engagement in everyday conversa-tions.
In Interspeech, pages 1329?1332.111
