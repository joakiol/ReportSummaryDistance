c?
2002 Association for Computational LinguisticsSquibs and DiscussionsHuman Variation and Lexical ChoiceEhud Reiter?
Somayajulu Sripada?University of Aberdeen University of AberdeenMuch natural language processing research implicitly assumes that word meanings are fixed ina language community, but in fact there is good evidence that different people probably associateslightly different meanings with words.
We summarize some evidence for this claim from theliterature and from an ongoing research project, and discuss its implications for natural languagegeneration, especially for lexical choice, that is, choosing appropriate words for a generated text.1.
IntroductionA major task in natural language generation (NLG) is lexical choice, that is, choosinglexemes (words) to communicate to the reader the information selected by the system?scontent determination module.
From a semantic perspective lexical choice algorithmsare based on models of word meanings, which state when a word can and cannot beused; of course, lexical choice algorithms may also consider syntactic constraints andpragmatic features when choosing words.Such models assume that it is possible to specify what a particular word means toa particular user.
However, both the cognitive science literature and recent experimentscarried out in the SUMTIME project at the University of Aberdeen, of which the currentauthors are a part, suggest that this may be difficult to do because of variations amongpeople, that is, because the same word may mean different things to different people.More precisely, although people may agree at a rough level about what a word means,they may disagree about its precise definition, and in particular, to what objects orevents a word can be applied.
This means that it may be impossible even in principleto specify precise word meanings for texts with multiple readers, and indeed for textswith a single reader, unless the system has access to an extremely detailed user model.A corpus study in our project also showed that there were differences in which wordsindividuals used (in the sense that some words were used only by a subset of theauthors) and also in how words were orthographically realized (spelled).This suggests that it may be risky for NLG systems (and indeed human authors) todepend for communicative success on the human reader?s interpreting words exactlyas the system intends.
This in turn suggests that perhaps NLG systems should becautious in using very detailed lexical models and also that it may be useful to addsome redundancy to texts in case the reader does not interpret a word as expected.This is especially true in applications in which each user reads only one generated text;if users read many generated texts, then perhaps over time they will learn about andadapt to the NLG system?s lexical usage.
Human variability also needs to be takeninto account by natural language processing (NLP) researchers performing corporaanalyses; such analyses should not assume that everyone uses identical rules whenmaking linguistic decisions.?
Department of Computing Science, University of Aberdeen, Aberdeen AB24 3UE, UK.
E-mail:ereiter@csd.abdn.ac.uk?
Department of Computing Science, University of Aberdeen, Aberdeen AB24 3UE, UK.
E-mail:ssripada@csd.abdn.ac.uk546Computational Linguistics Volume 28, Number 42.
Evidence for Human Lexical Variation2.1 Previous ResearchLinguists have acknowledged that people may associate different meanings with thesame word.
Nunberg (1978, page 81), for example, writes:There is considerable variation among speakers in beliefs about whatdoes and does not constitute a member of the category.
.
.
.
Take jazz.
Imay believe that the category includes ragtime, but not blues; you maybelieve the exact opposite.
After all, we will have been exposed to avery different set of exemplars.
And absent a commonly accepted au-thority, we must construct our own theories of categories, most prob-ably in the light of varying degrees of musical sophistication.Many modern theories of mental categorization (Rosch 1978; Smith and Medin 1981)assume that mental categories are represented by prototypes or exemplars.
Therefore,if different people are exposed to different category prototypes and exemplars, theyare likely to have different rules for evaluating category membership.Parikh (1994) made a similar point and backed it up with some simple experimen-tation.
For example, he showed squares from the Munsell chart to participants andasked them to characterize the squares as red or blue; different individuals character-ized the squares in different ways.
In another experiment he showed that differencesremained even if participants were allowed to associate fuzzy-logic-type truth valueswith statements.In the psychological community, Malt et al (1999) investigated what names par-ticipants gave to real-world objects.
For example, these researchers wished to knowwhether participants would describe a pump-top hand lotion dispenser as a bottle or acontainer.
They were primarily interested in variations across linguistic communities,but they also discovered that even within a linguistic community there were differ-ences in how participants named objects.
They state (page 242) that only 2 of the 60objects in their study were given the same name by all of their 76 native-English-speaker participants.In the lexicographic community, field-workers for the Dictionary of American Re-gional English (DARE) (Cassidy and Hall 1996) asked a representative set of Americansto respond to fill-in-the-blank questionnaires.
The responses they received revealedsubstantial differences among participants.
For example, there were 228 different re-sponses to question B12, When the wind begins to increase, you say it?s , the mostcommon of which were getting windy and blowing up; and 201 different responses toquestion B13, When the wind begins to decrease, you say it?s , the most common ofwhich were calming down and dying down.2.2 SUMTIME ProjectThe SUMTIME project at the University of Aberdeen is researching techniques for gen-erating summaries of time-series data.1 Much of the project focuses on content deter-mination (see, for example, Sripada et al [2001]), but it is also examining lexical choicealgorithms for time-series summaries, which is where the work described in this ar-ticle originated.
To date, SUMTIME has primarily focused on two domains, weatherforecasts and summaries of gas turbine sensors, although we have recently started1 See ?http://www.csd.abdn.ac.uk/research/sumtime?
for general information about SUMTIME.547Reiter and Sripada Human Variation and Lexical Choicework in a third domain as well, summaries of sensor readings in neonatal intensivecare units.2.2.1 Gas Turbine Domain.
In order to develop a lexicon for describing patterns ingas turbine sensor data, we asked two experts to write short descriptions of 38 signalfragments.
(A signal fragment is an interval of a single time-series data channel.)
Thedescriptors were small, with an average size of 8.3 words.
In no case did the expertsproduce exactly the same descriptor for a fragment.
Many of the differences simplyreflected usage of different words to express the same underlying concept; for example,one expert typically used rise to describe what the other expert called increase.
In othercases the differences reflected different levels of detail.
For example, one fragment wasdescribed by expert A as Generally steady with a slow rising trend.
Lots of noise and a fewsmall noise steps, whereas expert B used the shorter phrase Rising trend, with noise.
Bothexperts also had personal vocabulary; for example, the terms bathtub and dome wereused only by expert A, whereas the terms square wave and transient were used only byexpert B.Most importantly from the perspective of this article, there were cases in which thedifferences between the experts reflected a difference in the meanings associated withwords.
For example, both experts used the word oscillation.
Six signals were describedby both experts as oscillations, but two signals, including the one shown in Figure 1,were described as oscillations only by expert B.
We do not have enough examplesto solidly support hypotheses about why the experts agreed on application of theterm oscillation to some signals and disagreed on its application to others, but oneexplanation that seems to fit the available data is that the experts agreed on applyingthe term to signals that were very similar to a sine wave (which presumably is theprototype [Rosch 1978] of an oscillation), but sometimes disagreed on its applicationto signals that were less similar to a sine wave, such as Figure 1.2.2.2 Meteorology Domain.
In the meteorology domain we accumulated and ana-lyzed a corpus of 1,099 human-written weather forecasts for offshore oil rigs, togetherwith the data files (produced by a numerical weather simulation) that the forecastersexamined when writing the forecasts.
The forecasts were written by five different fore-casters.
A short extract from a typical forecast is shown in Figure 2; this text describeschanges in wind speed and direction predicted to occur two days after the forecastwas issued.
An extract from the corresponding data file is shown in Table 1; it de-scribes the predicted wind speed and direction from the numerical weather simulationat three-hourly intervals.As in the gas turbine domain, our corpus analysis showed that individual fore-casters had idiosyncratic vocabulary that only they used.
For example, one forecasterused the verb freshening to indicate a moderate increase in wind speed from a lowor moderate initial value, but no other forecaster used this verb.
There were alsoFigure 1Signal fragment (gas turbine exhaust temperature): Is this an oscillation?548Computational Linguistics Volume 28, Number 4FORECAST 00-24 GMT, WEDNESDAY, 04-Oct 2000WIND(10M): WSW 20-24 BACKING SSW 10-14 BY MIDDAY THENVEERING SW 24-28 BY EVENINGFigure 2Wind (at 10m) extract from five-day weather forecast issued on October 2, 2000.differences in orthography.
For example, some forecasters lexicalized the four basicdirections as N, E, S, and W, whereas others used the lexicalizations N?LY, E?LY, S?LY,and W?LY.We performed a number of semantic analyses to determine when different fore-casters used different words; these invariably showed differences between authors.For example, we attempted to infer the meaning of time phrases such as by evening bysearching for the first data file record that matched the corresponding wind descriptor.The forecast in Figure 2, for example, says that the wind will change to SSW 10?14at the time suggested by BY MIDDAY.
In the corresponding data shown in Table 1,the first entry with a direction of SSW and a speed in the 10?14 range is 1200; hencein this example the time phrase by midday is associated with the time 1200.
A similaranalysis suggests that in this example the time phrase by evening is associated with thetime 0000 (on 5-10-00).We repeated this procedure for every forecast in our corpus and statistically an-alyzed the results to determine how individual forecasters used time phrases.
Moredetails about the analysis procedure are given by Reiter and Sripada (2002).
As re-ported in that paper, the forecasters seemed to agree on the meaning of some timephrases; for example, all forecasters predominantly used by midday to mean 1200.They disagreed, however, on the use of other terms, including by evening.
The use ofby evening is shown in Table 2; in particular, whereas forecaster F3 (the author of thetext in Figure 2) most often used this phrase to mean 0000, forecasters F1 and F4 mostoften used this phrase to mean 1800.
The differences between forecasters in their usageof by evening are significant at p < .001 under both a chi-squared test (which treatstime as a categorical variable) and a one-way analysis of variance (which comparesthe mean time for each forecaster; for this test we recoded the hour 0 as 24).2.2.3 Knows Java Experiment.
Some colleagues pointed out to us that meteorologyin particular was a domain with an established sublanguage and usage conventions,whose words might correspond to technical terms, and wondered what would hap-Table 1Wind (at 10m) extract from October 2, 2000, data file (output of numerical weather model).Day Hour Wind Direction Wind Speed4-10-00 0 WSW 224-10-00 3 WSW 204-10-00 6 SW 164-10-00 9 SW 144-10-00 12 SSW 124-10-00 15 SSW 184-10-00 18 SSW 224-10-00 21 SSW 245-10-00 0 SW 26549Reiter and Sripada Human Variation and Lexical ChoiceTable 2How often by evening was used to refer to each time, for each forecaster (mode in boldfacefont).Hour F1 F2 F3 F4 F5 Total0 5 35 1 3 443 1 16 1 19 012 1 115 5 2 3 1018 19 3 1 22 4 4921 7 5 22 3 6 43Total 31 14 61 29 14 149pen in a domain in which there was no established sublanguage and technical termi-nology.
We therefore performed a small experiment at the University of Aberdeenin which we asked 21 postgraduate students and academic staff members to fillout a questionnaire asking which of the following individuals they would regard asknowing Java:2?
A cannot program in Java, but knows that Java is a popularprogramming language.?
B cannot write a Java program from scratch, but can make very simplechanges to an existing Java program (such as changing a string constantthat specifies a URL).?
C can use a tool such as JBuilder to write a very simple Java program,but cannot use control flow constructs such as while loops.?
D can write Java programs that use while loops, arrays, and the Javaclass libraries, but only within one class; she cannot write a program thatconsists of several classes.?
E can create complex Java programs and classes, but needs tooccasionally refer to documentation for details of the Java language andclass libraries.Respondents could tick Yes, Unsure, or No.
All 21 respondents ticked No for A and Yesfor E. They disagreed about whether B, C, and D could be considered to know Java; 3ticked Yes for B, 5 ticked Yes for C, and 13 ticked Yes for D. In other words, even amongthis relatively homogeneous group, there was considerable disagreement over whatthe phrase knows Java meant in terms of actual knowledge of the Java programminglanguage.2 The questionnaire in fact contained a sixth item: ?F can create complex Java libraries and almost neverneeds to refer to documentation because she has memorised most of it.?
However, a few participantswere unsure whether create complex Java libraries meant programming or meant assembling compiledobject files into a single archive file using a tool such as tar or jartool, so we dropped F from our study.550Computational Linguistics Volume 28, Number 43.
Implications for Natural Language Generation3.1 Lexical ChoiceThe previous section has argued that people in many cases do associate differentmeanings with lexemes and phrases such as oscillation, by evening, and knows; and thatsome words, such as bathtub and freshening, are used only by a subset of authors in aparticular domain.
What impact does this have on lexical choice?In applications in which users read only one generated text, it may be necessaryto restrict lexeme definitions to those that we expect all users to share.
Indeed, essen-tially this advice was given to us by a domain expert in an earlier project on generatingpersonalized smoking-cessation letters (Reiter, Robertson, and Osman 2000).
In appli-cations in which users read many generated texts over a period of time, however, anargument could be made for using a richer vocabulary and set of lexeme definitionsand expecting users to adapt to and learn the system?s vocabulary and usage over thecourse of time; it may be appropriate to add ?redundant?
information to texts (sec-tion 3.2) while the user is still learning the system?s lexical usage.
This strategy hassome risks, but if successful, can lead to short and less awkward texts.
Consistency isessential if this strategy is followed; the system should not, for example, sometimesuse by evening to mean 1800 and sometimes use by evening to mean 0000.We are not aware of previous research in lexical choice that focuses on dealingwith differences in the meanings that different human readers associate with words.Perhaps the closest research strand is that which investigates tailoring word choice andphrasing according to the expertise of the user (Bateman and Paris 1989; Reiter 1991;McKeown, Robin, and Tanenblatt 1993).
For example, the Coordinated MultimediaExplanation Testbed (COMET) (McKeown, Robin, and Tanenblatt 1993) could generateCheck the polarity for skilled users and Make sure the plus on the battery lines up with theplus on the battery compartment for unskilled users.
General reviews of previous lexicalchoice research in NLG are given by Stede (1995) and Wanner (1996); Zukerman andLitman (2001) review research in user modeling and NLP.In the linguistic community, Parikh (1994) has suggested that utility theory beapplied to word choice.
In other words, if we know (1) the probability of a word?sbeing correctly interpreted or misinterpreted and (2) the benefit to the user of correctinterpretation and the cost of misinterpretation, then we can compute an overall utilityto the user of using the word.
This seems like an interesting theoretical model, but inpractice (at least in the applications we have looked at), whereas it may be just aboutpossible to get data on the likelihood of correct interpretation of a word, it is probablyimpossible to calculate the cost of misinterpretation, because we do not have accuratetask models that specify exactly how the user will use the generated texts (and ourdomain experts have told us that it is probably impossible to construct such models).3.1.1 Near Synonyms.
A related problem is choosing between near synonyms, thatis, words with similar meanings: for example, choosing between easing and decreasingwhen describing changes in wind speed, or saw-tooth transient and shark-tooth transientwhen describing gas turbine signals.
The most in-depth examination of choosing be-tween near synonyms was undertaken by Edmonds (1999), who essentially suggestedusing rules based on lexicographic work such as Webster?s New Dictionary of Synonyms(Gove 1984).Edmonds was working on machine translation, not generating texts from nonlin-guistic data, and hence was looking at larger differences than the ones with whichwe are concerned.
Indeed, dictionaries do not in general give definitions at the levelof detail required by SUMTIME; for example, we are not aware of any dictionary that551Reiter and Sripada Human Variation and Lexical Choicedefines oscillation in enough detail to specify whether it is appropriate to describe thesignal in Figure 1 as an oscillation.
We also have some doubts, however, as to whetherthe definitions given in synonym dictionaries such as Gove (1984) do indeed accu-rately represent how all members of a language community use near synonyms.
Forexample, when describing synonyms and near synonyms of error, Gove (page 298)states that faux pas is ?most frequently applied to a mistake in etiquette.?
This seemsto be a fair match to DARE?s fieldwork question (see section 2.1) JJ41, An embarrassingmistake: Last night she made an awful , and indeed DARE (volume 2, page 372)states that faux pas was a frequent response to this question.
DARE adds, however,that faux pas was less often used in the South Midland region of the United States (thestates of Kentucky and Tennessee and some adjacent regions of neighboring states)and also was less often used by people who lacked a college education.
So althoughfaux pas might be a good lexicalization of a ?mistake in etiquette?
for most Americans,it might not be appropriate for all Americans; and, for example, if an NLG systemknew that its user was a non-college-educated man from Kentucky, then perhaps itshould consider using another word for this concept.3.2 RedundancyAnother implication of human variation in word usage is that if there is a chance thatpeople may not interpret words as expected, it may be useful for an NLG system toinclude extra information in the texts it generates, beyond what is needed if users couldbe expected to interpret words exactly as the system intended.
Indeed, unexpectedword interpretations could perhaps be considered to be a type of ?semantic?
noise;and as with all noise, redundancy in the signal (text) can help the reader recover theintended meaning.For example, the referring-expression generation model of Dale and Reiter (1995)selects attributes to identify referents based on the assumption that the hearer willinterpret the attributes as the system expects.
Assume, for instance, that there aretwo books in focus, B1 and B2, and the system?s knowledge base records that B1 hascolor red and B2 has color blue.
Then, according to Dale and Reiter, the red book is adistinguishing description that uniquely identifies B1.Parikh, however, has shown that people can in fact disagree about which objectsare red and which are blue; if this is the case, then it is possible that the hearer will notin fact be able to identify B1 as the referent after hearing the red book.
To guard againstthis eventuality, it might be useful to add additional information about a differentattribute to the referring expression; for example, if B1 is 100 pages and B2 is 1,000pages, the system could generate the thin red book.
This is longer than the red book andthus perhaps may take longer to utter and comprehend, but its redundancy providesprotection against unexpected lexical interpretations.3.3 Corpus AnalysisA final point is that differences between individuals should perhaps be consideredin general by people performing corpus analyses to derive rules for NLG systems(Reiter and Sripada 2002).
To take one randomly chosen example, Hardt and Rambow(2001) suggest a set of rules for deciding on verb phrase (VP) ellipsis that are basedon machine learning techniques applied to the Penn Treebank corpus.
These achievea 35% reduction in error rate against a baseline rule.
They do not consider variationin author, and we wonder if a considerable amount of the remaining error is due toindividual variation in deciding when to ellide a VP.
It would be interesting to performa similar analysis with author specified as one of the features given to the machinelearning algorithm and see whether this improved performance.552Computational Linguistics Volume 28, Number 44.
Natural Language Generation versus Human-Written TextsTo finish on a more positive note, human variation may potentially be an opportunityfor NLG systems, because they can guarantee consistency.
In the weather-forecastingdomain we examined, for example, users receive texts written by all five forecasters,which means that they may have problems reliably interpreting phrases such as byevening; an NLG system, in contrast, could be programmed always to use this phraseconsistently.
An NLG system could also be programmed to avoid idiosyncratic termswith which users might not be familiar (bathtub, for example) and not to use terms incases in which people disagree about their applicability (e.g., oscillation for Figure 1).Our corpus analyses and discussions with domain experts suggest that it is not alwayseasy for human writers to follow such consistency rules, especially if they have limitedamounts of time.Psychologists believe that interaction is a key aspect of the process of humansagreeing on word usage (Garrod and Anderson 1987).
Perhaps a small group of peoplewho constantly communicate with each other over a long time period (presumably thecircumstances under which language evolved) will agree on word meanings.
But in themodern world it is common for human writers to write documents for people whomthey have never met or with whom they have never otherwise interacted, which mayreduce the effectiveness of the natural interaction mechanism for agreeing on wordmeanings.In summary, dealing with lexical variation among human readers is a challengefor NLG systems and will undoubtably require a considerable amount of thought,research, and data collection.
But if NLG systems can do a good job of this, theymight end up producing superior texts to many human writers, which would greatlyenhance the appeal of NLG technology.AcknowledgmentsOur thanks to the many individuals whohave discussed this work with us (not all ofwhom agree with our analysis!
), includingRegina Barzilay, Ann Copestake, RobertDale, Phil Edmonds, Jim Hunter, AdamKilgarriff, Owen Rambow, Graeme Ritchie,Rosemary Stevenson, Sandra Williams, andJin Yu.
We are also grateful to theanonymous reviewers for their helpfulcomments.
Special thanks to DARE editorJoan Hall for providing us with the DAREfieldwork data.
Last but certainly not least,this work would not have been possiblewithout the help of our industrialcollaborators at Intelligent Applications andWNI/Oceanroutes.
This work wassupported by the UK Engineering andPhysical Sciences Research Council(EPSRC), under grant GR/M76681.ReferencesBateman, John and Cecile Paris.
1989.Phrasing a text in terms the user canunderstand.
In Proceedings of the 11thInternational Joint Conference on ArtificialIntelligence (IJCAI-89), volume 2,pages 1511?1517.Cassidy, Frederick and Joan Hall, editors.1996.
Dictionary of American RegionalEnglish.
Belknap.Dale, Robert and Ehud Reiter.
1995.Computational interpretations of theGricean maxims in the generation ofreferring expressions.
Cognitive Science,19:233?263.Edmonds, Philip.
1999.
SemanticRepresentations of Near-Synonyms forAutomatic Lexical Choice.
Ph.D. thesis,Computer Science Department,University of Toronto, Toronto.Garrod, Simon and Anthony Anderson.1987.
Saying what you mean in dialogue:A study in conceptual and semanticco-ordination.
Cognition, 27:181?218.Gove, Philip, editor.
1984.
Webster?s NewDictionary of Synonyms.
Merriam-Webster.Hardt, Daniel and Owen Rambow.
2001.Generation of VP-ellipsis: A corpus-basedapproach.
In Proceedings of the 39th Meetingof the Association for Computation Linguistics(ACL-01), pages 282?289.Malt, Barbara, Steven Sloman, SilviaGennari, Meiyi Shi, and Yuan Wang.
1999.Knowing versus naming: Similarity and553Reiter and Sripada Human Variation and Lexical Choicethe linguistic categorization of artifacts.Journal of Memory and Language, 40:230?262.McKeown, Kathleen, Jacques Robin, andMichael Tanenblatt.
1993.
Tailoring lexicalchoice to the user?s vocabulary inmultimedia explanation generation.
InProceedings of 31st Annual Meeting of theAssociation for Computational Linguistics(ACL93), pages 226?234.Nunberg, Geoffrey.
1978.
The Pragmatics ofReference.
University of IndianaLinguistics Club, Bloomington.Parikh, Rohit.
1994.
Vagueness and utility:The semantics of common nouns.Linguistics and Philosophy, 17:521?535.Reiter, Ehud.
1991.
A new model of lexicalchoice for nouns.
ComputationalIntelligence, 7(4):240?251.Reiter, Ehud, Roma Robertson, and LieslOsman.
2000.
Knowledge acquisition fornatural language generation.
InProceedings of the First InternationalConference on Natural Language Generation,pages 217?215.Reiter, Ehud and Somayajulu Sripada.
2002.Should corpora texts be gold standardsfor NLG?
In Proceedings of the SecondInternational Conference on Natural LanguageGeneration, pages 97?104.Rosch, Eleanor.
1978.
Principles ofcategorization.
In E. Rosch and B. Lloyd,editors, Cognition and Categorization.Lawrence Erlbaum, Hillsdale, NJ,pages 27?48.Smith, Edward and Douglas Medin.
1981.Categories and Concepts.
HarvardUniversity Press, Cambridge.Sripada, Somayajulu, Ehud Reiter, JimHunter, and Jin Yu.
2001.
A two-stagemodel for content determination.
InProceedings of ENLGW-2001, pages 3?10.Stede, Manfred.
1995.
Lexicalization innatural language generation: A survey.Artificial Intelligence Review, 8:309?336.Wanner, Leo.
1996.
Lexical choice in textgeneration and machine translation.Machine Translation, 11:3?35.Zukerman, Ingrid and Diane Litman.
2001.Natural language processing and usermodeling: Synergies and limitations.
UserModeling and User-Adapted Interaction,11:129?158.
