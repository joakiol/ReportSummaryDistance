A THEORY OF LEXICAL ACCESS IN SPEECH PRODUCTIONWillem J.M.
LeveltMax Planck Institute for PsycholinguisticsP.O.
Box 310, 6500 AH Nijmegen, The Netherlandspim@mpi.nlABSTRACTThe generation of words in speech involves anumber of processing stages.
There is, first, astage of conceptual preparation; this isfollowed by stages of lexical selection,phonological encoding, phonetic encodingand articulation.
In addition, the speakermonitors the output and, if necessary, self-corrects.
Major parts of the theory have beencomputer modelled.
The paper concentrateson experimental reaction time evidence insupport of the theory.Central to the skill of speaking is ourability to select words that appropriatelyexpress our intentions, to retrieve theirsyntactic and phonological properties and tocompute the ultimate articulatory shape ofthese words in the context of the utterance asa whole (2).In the multi-stage theory of wordproduction (3) the first stage, conceptualpreparation, involves activating a lexicalconcept, given the intention.
In picturenaming, for instance, there is no "hard-wired"link between the object depicted and theultimate referential expression.
The sameobject can be veridically referred to by amultitude of different erms.
The mediatingprocess here is called perspective taking.
Itsoutput is a lexical concept, i.e., a concept forwhich there is a word in the speaker's mentallexicon, in the computational model, lexicalconcepts figure in a semantic, spreading-activation etwork.The lexical concept is input to aprocess called lexical selection.
Lexicatconcepts pread their information to lemmasin the mental exicon.
Lemmas are syntacticwords.
The probability that a lemma isselected within a minimal time interval is itsrelative activation (following Luce"s choicerule).
From this hazard rate expected retrievaltimes can be computed for variousexperimental conditions.
These predictionsfind solid experimental support (5).
A select-ed lemma spreads its activation to the word'sphonological code.
The speed of accessingthis code is word-frequency dependent (1).During phonological encoding thesegmental nd metrical features of the word'sphonological code are "spelled out".
Themetrical structures of adjacent words may getcombined to compute larger-size metricalunits, so-called phonological words.
Thespelled-out segments are incrementally("from left to right") attached to the metricalframe, on the fly creating the phonologicalword's syllabification.In phonetic encoding an articulatorygesture is computed for each phonologicalsyllable as it comes available.
This processprobably involves a ,syllabary, a store of high-frequent syllabic gestures (4).
Articulationcan be initiated as soon as all of a word'ssyllabic gestures have been prepared.A speaker self-monitors conceptualpreparation, acoustic output, but also anintermediary level of representation, namelythe syllabified phonological word (2, 6).REFERENCES1.
Jescheniak, J.
& Levelt, W.J.M.
(1994).
Wordfrequency effects in production.
Journal ofFxperimental Psychology LMC, 824-843.2.
Levelt, W.J.M.
(1989).
Speaking: From intention toarticulation.
Cambridge, MA: MIT Press.3.
Levelt, W.J.M.
(1994).
On the skill of speaking: Howdo we access words?
ICSLP 94, 2253-2258.4.
Levelt, W.J.M.
& Wheeldon.
L. (1994).
Do speakershave access to a mental syllabary?
Cognition, 50, 239-269.5.
Roelofs, A.
(1992).
A spreading activation theory oflemma retrieval in speaking.
Cognition, 42, 107-142.6.
Wheeldon, L. & Levelt, W.J.M.
(1995).
Monitoringthe time course of phonological encoding.
Journal ofMemory and Language, 34, 311-334.
