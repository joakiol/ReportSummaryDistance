Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages, pages 86?90,Seattle, Washington, USA, 18 October 2013. c?2013 Association for Computational LinguisticsSPMRL?13 Shared Task System:The CADIM Arabic Dependency ParserYuval MartonMicrosoft CorporationCity Center PlazaBellevue, WA, USANizar Habash, Owen RambowCCLSColumbia UniversityNew York, NY, USAcadim@ccls.columbia.eduSarah AlkuhlaniCS DepartmentColumbia UniversityNew York, NY, USAAbstractWe describe the submission from theColumbia Arabic & Dialect Modelinggroup (CADIM) for the Shared Task atthe Fourth Workshop on Statistical Pars-ing of Morphologically Rich Languages(SPMRL?2013).
We participate in theArabic Dependency parsing task for pre-dicted POS tags and features.
Our systemis based on Marton et al(2013).1 IntroductionIn this paper, we discuss the system that theColumbia Arabic & Dialect Modeling group(CADIM) submitted to the 2013 Shared Task onParsing Morphologically Rich Languages (Seddahet al 2013).
We used a system for Arabic depen-dency parsing which we had previously developed,but retrained it on the training data splits used in thistask.
We only participated in the Arabic dependencyparsing track, and in it, only optimized for predicted(non-gold) POS tags and features.We first summarize our previous work (Sec-tion 2).
We then discuss our submission and the re-sults (Section 3).2 ApproachIn this section, we summarize Marton et al(2013).We first present some background information onArabic morphology and then discuss our method-ology and main results.
We present our best per-forming set of features, which we also use in ourSPMRL?2013 submission.2.1 BackgroundMorphology interacts with syntax in two ways:agreement and assignment.
In agreement, there iscoordination between the morphological features oftwo words in a sentence based on their syntacticconfiguration (e.g., subject-verb or noun-adjectiveagreement in GENDER and/or NUMBER).
In as-signment, specific morphological feature values areassigned in certain syntactic configurations (e.g.,CASE assignment for the subject or direct object ofa verb).The choice of optimal linguistic features fora parser depends on three factors: relevance,redundancy and accuracy.
A feature has rel-evance if it is useful in making an attach-ment (or labeling) decision.
A particular fea-ture may or may not be relevant to parsing.For example, the GENDER feature may helpparse the Arabic phrase?YKYm.?'@/YKYm.?'@?PAJ??
@ H. AK.bAb AlsyArh?
Aljdyd/Aljdydh?1 ?door the-car the-newmasc.sg/fem.sg [lit.]?
using syntactic agreement:if the-new is masculine (Aljdyd YKYm.?
'@), it should at-tach to the masculine door (bAb H.
AK.
), resulting inthe meaning ?the car?s new door?
; if the-new is fem-inine (Aljdydh??YKYm.?
'@), it should attach to the femi-nine the-car (AlsyArh??PAJ??
@), resulting in ?the doorof the new car?.
In contrast, the ASPECT feature does1Arabic orthographic transliteration is presented in the HSBscheme (Habash et al 2007): (in alphabetical order)@ H.H H h. h p XXP 	P ?
?
??
??
????
?
?
??
?
?
?A b t ?
j H x d ?
r z s ?
S D T D?
?
?
f q k l m n h w yand the additional letters: ?
Z, ?
@, A?
@, A?@, w??
', y?
Z?
', h??, ?
?.86not constrain any syntactic decision.2 Even if rele-vant, a feature may not necessarily contribute to op-timal performance since it may be redundant withother features that surpass it in relevance.
For ex-ample, the DET and STATE features alone both helpparsing because they help identify the idafa con-struction (the modificiation of a nominal by a gen-itive noun phrase), but they are redundant with eachother and the DET feature is more helpful since italso helps with adjectival modification of nouns.
Fi-nally, the accuracy of automatically predicting thefeature values (ratio of correct predictions out of allpredictions) of course affects the value of a featureon unseen text.
Even if relevant and non-redundant,a feature may be hard to predict with sufficient ac-curacy by current technology, in which case it willbe of little or no help for parsing, even if helpfulwhen its gold values are provided.
The CASE fea-ture is very relevant and not redundant, but it cannotbe predicted with high accuracy and overall it is notuseful.Different languages vary with respect to whichfeatures may be most helpful given various tradeoffsamong these three factors.
It has been shown pre-viously that if the relevant morphological featuresin assignment configurations can be recognized wellenough, then they contribute to parsing accuracy.For example, modeling CASE in Czech improvesCzech parsing (Collins et al 1999): CASE is rele-vant, not redundant, and can be predicted with suf-ficient accuracy.
However, it had been more diffi-cult showing that agreement morphology helps pars-ing, with negative results for dependency parsing inseveral languages (Nivre et al 2008; Eryigit et al2008; Nivre, 2009).
In contrast to these negative re-sults, Marton et al(2013) showed positive resultsfor using agreement morphology for Arabic.2.2 MethodologyIn Marton et al(2013), we investigated morphologi-cal features for dependency parsing of Modern Stan-dard Arabic (MSA).
The goal was to find a set of rel-evant, accurate and non-redundant features.
We usedboth the MaltParser (Nivre, 2008) and the Easy-First2For more information on Arabic morphology in the con-text of natural language processing see Habash (2010).
For adetailed analysis of morpho-syntactic agreement, see Alkuhlaniand Habash (2011).Parser (Goldberg and Elhadad, 2010).
Since theEasy-First Parser performed better, we use it in allexperiments reported in this paper.For MSA, the space of possible morphologicalfeatures is quite large.
We determined which mor-phological features help by performing a searchthrough the feature space.
In order to do this, weseparated part-of-speech (POS) from the morpho-logical features.
We defined a core set of 12 POSfeatures, and then explored combinations of mor-phological features in addition to this POS tagset.This core set of POS tags is similar to those pro-posed in cross-lingual work (Rambow et al 2006;Petrov et al 2012).
We performed this search inde-pendently for Gold input features and predicted in-put features.
We used our MADA+TOKAN system(Habash and Rambow, 2005; Habash et al 2009;Habash et al 2012) for the prediction.
As the Easy-First Parser predicts links separately before labels,we first optimized for unlabeled attachment score,and then optimized the Easy-First Parser labeler forlabel score.As had been found in previous results, assignmentfeatures, specifically CASE and STATE, are veryhelpful in MSA.
However, in MSA this is true onlyunder gold conditions: since CASE is rarely explicitin the typically undiacritized written MSA, it has adismal accuracy rate, which makes it useless whenused in machine-predicted (real, non-gold) condi-tion.
In contrast with previous results, we showedthat agreement features are quite helpful in both goldand predicted conditions.
This is likely a result ofMSA having a rich agreement system, covering bothverb-subject and noun-adjective relations.Additionally, almost all work to date in MSAmorphological analysis and part-of-speech (POS)tagging has concentrated on the morphemic form ofthe words.
However, often the functional morphol-ogy (which is relevant to agreement, and relates tothe meaning of the word) is at odds with the ?sur-face?
(form-based) morphology; a well-known ex-ample of this are the ?broken?
(irregular) pluralsof nominals, which often have singular-form mor-phemes but are in fact plurals and show plural agree-ment if the referent is rational.
In Marton et al(2013), we showed that by modeling the functionalmorphology rather than the form-based morphology,we obtain a further increase in parsing performance87Feature Type Feature ExplanationPart-of-speech CORE12 12 tags for core parts-of-speech: verb, noun, adjective, adverb,proper noun, pronoun, preposition, conjunction, relative pronoun,particle, abbreviation, and punctuationInflectional features DET Presence of the determiner morpheme ?
@ AlPERSON 1st, 2nd, or 3rdFN*N Functional number: singular, dual, pluralFN*G Functional gender: masculine or feminineLexical features FN*R Rationality: rational, irrational, ambiguous, unknown or N/ALMM Undiacritized lemmaTable 1: Features used in the CADIM submission with the Easy-First Parser (Goldberg and Elhadad, 2010).Training Set Test Set LAS UAS LaS5K (SPMRL?2013) dev ?
70 81.7 84.7 92.7All (SPMRL?2013) dev ?
70 84.8 87.4 94.2Marton et al(2013) test (old split) ?
70 81.7 84.6 92.85K (SPMRL?2013) dev 81.1 84.2 92.7All (SPMRL?2013) dev 84.0 86.6 94.15K (SPMRL?2013) test 80.5 83.5 92.7All (SPMRL?2013) test 83.2 85.8 93.9Marton et al(2013) test (old split) 81.0 84.0 92.7Table 2: Results of our system on Shared Task test data, Gold Tokenization, Predicted Morphological Tags; and forreference also on the data splits used in our previous work (Marton et al 2013); ??
70?
refers to the test sentenceswith 70 or fewer words.Training Set Test Set Labeled Tedeval Score Unlabeled Tedeval Score5K (SPMRL?2013) test ?
70 86.4 89.9All (SPMRL?2013) test ?
70 87.8 90.8Table 3: Results of our system on on Shared Task test data, Predicted Tokenization, Predicted Morphological Tags;??
70?
refers to the test sentences with 70 or fewer words(again, both when using gold and when using pre-dicted POS and morphological features).We also showed that for parsing with predictedPOS and morphological features, training on a com-bination of gold and predicted POS and morpholog-ical feature values outperforms the alternative train-ing scenarios.2.3 Best Performing Feature SetThe best performing set of features on non-gold in-put, obtained in Marton et al(2013), are shown inTable 1.
The features are clustered into three types.?
First is part-of-speech, represented using a?core?
12-tag set.?
Second are the inflectional morphological fea-tures: determiner clitic, person and functionalgender and number.?
Third are the rationality (humanness) feature,which participates in morphosyntactic agree-ment in Arabic (Alkuhlani and Habash, 2011),and a form of the lemma, which abstract overall inflectional morphology.For the training corpus, we use a combination ofthe gold and predicted features.883 Our Submission3.1 Data PreparationThe data split used in the shared task is differentfrom the data split we used in (Marton et al 2013),so we retrained our models on the new splits (Diabet al 2013).
The data released for the Shared Taskshowed inconsistent availability of lemmas acrossgold and predicted input, so we used the ALMORanalyzer (Habash, 2007) with the SAMA databases(Graff et al 2009) to determine a lemma given theword form and the provided (gold or predicted) POStags.
In addition to the lemmas, the ALMOR an-alyzer also provides morphological features in thefeature-value representation our approach requires.Finally, we ran our existing converter (Alkuhlaniand Habash, 2012) over this representation to obtainfunctional number and gender, as well as the ratio-nality feature.3 For simplicity reasons, we used theMLE:W2+CATiB model (Alkuhlani and Habash,2012), which was the best performing model on seenwords, as opposed to the combination system thatused a syntactic component with better results onunseen words.
We did not perform Alif or Ya nor-malization on the data.We trained two models: one on 5,000 sentencesof training data and one on the entire training data.3.2 ResultsOur performance in the Shared Task for Arabic De-pendency, Gold Tokenization, Predicted Tags, isshown in Table 2.
Our performance in the SharedTask for Arabic Dependency, Predicted Tokeniza-tion, Predicted Tags, is shown in Table 3.
Forpredicted tokenization, only the IMS/Szeged sys-tem which uses system combination (Run 2) out-performed our parser on all measures; our parserperformed better than all other single-parser sys-tems.
For gold tokenization, our system is the sec-ond best single-parser system after the IMS/Szegedsingle system (Run 1).
For gold tokenization andpredicted morphology (Table 2), we also give theperformance reported in our previous work (Mar-ton et al 2013).
The increase over the previously3The functional feature generator of (Alkuhlani and Habash,2012) was trained on a different training set from the parser, butthe functional feature generator was not trained on any of thetest corpus for the Shared Task.reported work may simply be due to the differentsplit for training and test, but it may also be dueto improvements to the functional feature prediction(Alkuhlani and Habash, 2012), and the predictedfeatures provided by the Shared Task organizers.ReferencesSarah Alkuhlani and Nizar Habash.
2011.
A corpus formodeling morpho-syntactic agreement in Arabic: gen-der, number and rationality.
In Proceedings of the 49thAnnual Meeting of the Association for ComputationalLinguistics (ACL), Portland, Oregon, USA.Sarah Alkuhlani and Nizar Habash.
2012.
Identifyingbroken plurals, irregular gender, and rationality in Ara-bic text.
In Proceedings of the 13th Conference ofthe European Chapter of the Association for Compu-tational Linguistics, pages 675?685.
Association forComputational Linguistics.Michael Collins, Jan Hajic, Lance Ramshaw, andChristoph Tillmann.
1999.
A statistical parser forCzech.
In Proceedings of the 37th Annual Meeting ofthe Association for Computational Linguistics (ACL),pages 505?512, College Park, Maryland, USA, June.Mona Diab, Nizar Habash, Owen Rambow, and RyanRoth.
2013.
LDC Arabic Treebanks and AssociatedCorpora: Data Divisions Manual.
Technical ReportCCLS-13-02, Center for Computational Learning Sys-tems, Columbia University.G?lsen Eryigit, Joakim Nivre, and Kemal Oflazer.
2008.Dependency parsing of Turkish.
Computational Lin-guistics, 34(3):357?389.Yoav Goldberg and Michael Elhadad.
2010.
An effi-cient algorithm for easy-first non-directional depen-dency parsing.
In Proceedings of Human LanguageTechnology (HLT): the North American Chapter of theAssociation for Computational Linguistics (NAACL),pages 742?750, Los Angeles, California.David Graff, Mohamed Maamouri, Basma Bouziri,Sondos Krouna, Seth Kulick, and Tim Buckwal-ter.
2009.
Standard Arabic Morphological Analyzer(SAMA) Version 3.1.
Linguistic Data ConsortiumLDC2009E73.Nizar Habash and Owen Rambow.
2005.
Arabic Tok-enization, Part-of-Speech Tagging and MorphologicalDisambiguation in One Fell Swoop.
In Proceedings ofthe 43rd Annual Meeting of the Association for Com-putational Linguistics (ACL), pages 573?580, Ann Ar-bor, Michigan.Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.2007.
On Arabic Transliteration.
In A. van den Bosch89and A. Soudi, editors, Arabic Computational Mor-phology: Knowledge-based and Empirical Methods.Springer.Nizar Habash, Owen Rambow, and Ryan Roth.
2009.MADA+TOKAN: A toolkit for Arabic tokenization,diacritization, morphological disambiguation, POStagging, stemming and lemmatization.
In KhalidChoukri and Bente Maegaard, editors, Proceedings ofthe Second International Conference on Arabic Lan-guage Resources and Tools.
The MEDAR Consortium,April.Nizar Habash, Owen Rambow, and Ryan Roth.
2012.MADA+TOKAN Manual.
Technical report, Techni-cal Report CCLS-12-01, Columbia University.Nizar Habash.
2007.
Arabic Morphological Representa-tions for Machine Translation.
In Antal van den Boschand Abdelhadi Soudi, editors, Arabic ComputationalMorphology: Knowledge-based and Empirical Meth-ods.
Kluwer/Springer.Nizar Habash.
2010.
Introduction to Arabic NaturalLanguage Processing.
Morgan & Claypool Publish-ers.Yuval Marton, Nizar Habash, and Owen Rambow.
2013.Dependency parsing of Modern Standard Arabic withlexical and inflectional features.
Computational Lin-guistics, 39(1).Joakim Nivre, Igor M. Boguslavsky, and Leonid K.Iomdin.
2008.
Parsing the SynTagRus Treebank ofRussian.
In Proceedings of the 22nd InternationalConference on Computational Linguistics (COLING),pages 641?648.Joakim Nivre.
2008.
Algorithms for Deterministic Incre-mental Dependency Parsing.
Computational Linguis-tics, 34(4).Joakim Nivre.
2009.
Parsing Indian languages withMaltParser.
In Proceedings of the ICON09 NLP ToolsContest: Indian Language Dependency Parsing, pages12?18.Slav Petrov, Dipanjan Das, and Ryan McDonald.
2012.A universal part-of-speech tagset.
In Proceedings ofthe Conference on Language Resources and Evalua-tion (LREC), May.Owen Rambow, Bonnie Dorr, David Farwell, RebeccaGreen, Nizar Habash, Stephen Helmreich, EduardHovy, Lori Levin, Keith J. Miller, Teruko Mitamura,Florence Reeder, and Siddharthan Advaith.
2006.
Par-allel syntactic annotation of multiple languages.
InProceedings of the Fifth Conference on Language Re-sources and Evaluation (LREC), Genoa, Italy.Djam?
Seddah, Reut Tsarfaty, Sandra K?bler, Marie Can-dito, Jinho Choi, Rich?rd Farkas, Jennifer Foster, IakesGoenaga, Koldo Gojenola, Yoav Goldberg, SpenceGreen, Nizar Habash, Marco Kuhlmann, WolfgangMaier, Joakim Nivre, Adam Przepiorkowski, RyanRoth, Wolfgang Seeker, Yannick Versley, VeronikaVincze, Marcin Wolin?ski, Alina Wr?blewska, and EricVillemonte de la Cl?rgerie.
2013.
Overview of thespmrl 2013 shared task: A cross-framework evalua-tion of parsing morphologically rich languages.
InProceedings of the 4th Workshop on Statistical Pars-ing of Morphologically Rich Languages: Shared Task,Seattle, WA.90
