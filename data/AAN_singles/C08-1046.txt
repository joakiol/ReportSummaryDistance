Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 361?368Manchester, August 2008Japanese Dependency Parsing Using a Tournament ModelMasakazu Iwatate and Masayuki Asahara and Yuji MatsumotoNara Institute of Science and Technology, Japan8916-5, Takayama, Ikoma, Nara, Japan, 630-0192{masakazu-i, masayu-a, matsu}@is.naist.jpAbstractIn Japanese dependency parsing, Kudo?srelative preference-based method (Kudoand Matsumoto, 2005) outperforms bothdeterministic and probabilistic CKY-basedparsing methods.
In Kudo?s method, foreach dependent word (or chunk) a log-linear model estimates relative preferenceof all other candidate words (or chunks) forbeing as its head.
This cannot be consid-ered in the deterministic parsing methods.We propose an algorithm based on a tour-nament model, in which the relative pref-erences are directly modeled by one-on-one games in a step-ladder tournament.
Inan evaluation experiment with Kyoto TextCorpus Version 4.0, the proposed methodoutperforms previous approaches, includ-ing the relative preference-based method.1 IntroductionThe shared tasks of multi-lingual dependency pars-ing took place at CoNLL-2006 (Buchholz andMarsi, 2006) and CoNLL-2007 (Nivre et al,2007).
Many language-independent parsing al-gorithms were proposed there.
The algorithmsneed to adapt to various dependency structureconstraints according to target languages: projec-tive vs. non-projective, head-initial vs. head-final,and single-rooted vs. multi-rooted.
Eisner (1996)proposed a CKY-like O(n3) algorithm.
Yamadaand Matsumoto (2003) proposed a shift-reduce-like O(n2) deterministic algorithm.
Nivre et al(2003; 2004) also proposed a shift-reduce-likec?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.???hito-da.
(man .)???
?yomanai(doesn?t read)?
?hon-wo(books)(a)  ?He is a man who doesn?t read books.??????yomanai.
(doesn?t read .)??hon-wo(books)?
?kare-wa(He)(b)  ?He doesn?t read books.??
?kare-wa(He)Figure 1: Examples of Japanese sentences.O(n) deterministic algorithm for projective lan-guages.
The model is enhanced for non-projectivelanguages by Nivre and Nilsson (2005).
McDon-ald et al (2005) proposed a method based onsearch of maximum spanning trees employing theChu-Liu-Edmonds algorithm (hereafter ?CLE al-gorithm?)
(Chu and Liu, 1965; Edmonds, 1967).Most Japanese dependency parsers are based onbunsetsu units, which are similar concept to En-glish base phrases.
The constraints in Japanesedependency structure are stronger than those inother languages.
Japanese dependency structureshave the following constraints: head-final, single-head, single-rooted, connected, acyclic and projec-tive.
Figure 1 shows examples of Japanese sen-tences and their dependency structures.
Each boxrepresents a bunsetsu.
A dependency relation isrepresented by an edge from a dependent to itshead.
Though sentence (a) is similar to sentence(b), the syntactic structures of these two are differ-ent, especially because ?kare-wa?
directly dependson ?yomanai?
in (b) but not in (a).In dependency parsing of Japanese, determin-istic algorithms outperform probabilistic CKYmethods.
Kudo and Matsumoto (2002) applied the361cascaded chunking algorithm (hereafter ?CC al-gorithm?)
to Japanese dependency parsing.
Ya-mada?s method (Yamada and Matsumoto, 2003)employed a similar algorithm.
Sassano (2004)proposed a linear-order shift-reduce-like algorithm(hereafter ?SR algorithm?
), which is similar toNivre?s algorithm (Nivre, 2003).
These determin-istic algorithms are biased to select nearer candi-date heads since they examine the candidates se-quentially, and once they find a plausible one theynever consider further candidates.We experimented the CLE algorithm withJapanese dependency parsing, and found that theCLE algorithm is comparable to or in some casespoorer than the deterministic algorithms in our ex-periments.
Actually, the CLE algorithm is not suit-able for some of the constraints in Japanese depen-dency structures: head-final and projective.
First,head-final means that dependency relation alwaysgoes from left to right.
Second, since the CLE al-gorithm may produce non-projective dependencytrees, we need to conduct projectivity check in thealgorithm.Kudo and Matsumoto (2005) proposed a rela-tive preference-based method (hereafter ?relativepreference method?).
They defined the parsingalgorithm as series of selection steps of the mostlikely head for each bunsetsu out of all candidates.The method has so far achieved the highest ac-curacy in the experiments with Kyoto Text Cor-pus Version 3.0 data 1, since other deterministicmethods do not consider relative preference amongcandidate heads but solely consider whether thefocused-on pair of bunsetsu?s is in a dependencyrelation or not.We propose a model that takes a bunsetsu andtwo candidate heads into consideration and se-lects the better candidate head out of those two.This step is repeated in a step ladder tournamentto get the best candidate head (hereafter we callthis model as a ?tournament model?).
The tour-nament model was first introduced by Iida et al(2003) for coreference resolution.
We applied thismodel to selecting the most plausible candidatehead for each bunsetsu except for the sentence finalone.Section 2 describes the tournament model com-paring with previous research.
Section 3 describes1Note: Sassano?s SR algorithm is the highest by exper-iment with the smaller data Kyoto Text Corpus Version 2.0Relative preference method and SR algorithm are not com-pared directly with the same data.???hito-da.
(man .)??hon-wo(books)?
?kare-wa(He)Focused-ondependent Its candidate headsThe most likely candidate head???
?yomanai(doesn?t read)Figure 2: Example of a tournament.how the tournament model is applied to Japanesedependency parsing.
Section 4 shows the resultsof evaluation experiments.
Section 5 shows ourcurrent and future work, and Section 6 gives con-clusions of this research.2 Tournament ModelThe tournament model was first introduced byIida et al (2003) for coreference resolution.
Themodel chooses the most likely candidate in a step-ladder tournament, that is a sequence of one-on-one games between candidate referents for a givenanaphoric expression.
In each game, the winner ischosen by a binary classifier such as SVMs.We applied the tournament model to Japanesedependency parsing taking into considerationJapanese constraints.
The projective constraint iseasily met.
When selecting candidate heads for thefocused-on dependent, we only consider those can-didates that introduce no crossing dependency.Figure 2 illustrates a tournament.
The focused-on dependent bunsetsu is ?kare-wa?, and the can-didate heads are the three bunsetsu?s on the right-hand side: ?hon-wo?, ?yomanai?
and ?hito-da?.The first game is ?hon-wo?
vs. ?yomanai?.
Thenthe next game is the winner of the first game vs.?hito-da?.
The winner of the second game (i.e.,?hito-da?)
is chosen as the most likely candidateof the dependent, ?kare-wa?.In the tournament model, the most likely head ofa given bunsetsu is determined by a series of one-on-one games in a tournament.
Below, we presentthe advantages of the tournament model by com-parison with the previous methods.2.1 Scope of Feature ViewsThe CC algorithm and SR algorithm consider onlya pair of bunsetsu?s ?
a dependent and its candidate362head ?
in the parsing action determination (here-after ?2-tuple model?).
The same 2-tuple may ormay not have a dependency relation when they ap-pear in different context.
For example, both (a)and (b) in Figure 1 include the two bunsetsu?s,?kare-wa?
and ?yomanai?
; in (b) they have a de-pendency relation, but not in (a).
The 2-tuple mod-els and relative preference method cannot discrim-inate between these two patterns without consider-ing contextual features 2.
The tournament modelcan be regarded as a ?3-tuple model,?
which con-siders three bunsetsu?s ?
a dependent and two can-didate heads.
The discriminative performance ofthe 3-tuple model is greater than the 2-tuple mod-els, since it directly compares two candidate headsand selects the one that is more plausible than theother candidate.
Consider Figure 1 again.
In (a),?kare-wa?
does not depend on ?yomanai?
becausethere is another bunsetsu ?hito-da?
which is a moreplausible head.
2-tuple models may use this infor-mation as a contextual feature, but the effect is in-direct.
On the other hand, the tournament modeldirectly compares these candidates and always se-lects the better one.
The situation becomes crucialwhen the true head appears outside of the contextwindow of the current candidate.
2-tuple modelshave to select the head without consulting such in-formation.
The advantage of the tournament modelis its capability of deferring the decision by al-ways keeping the current best candidate head.
Onthe other hand, a disadvantage of the tournamentmodel is its space and time complexity.
The size offeatures is larger since they come from three bun-setsu?s.
The size of training instances is also larger.2.2 Relative Position in a SentenceWe name the two candidate heads in the 3-tuplemodel as ?the nearer candidate head?
and ?the far-ther candidate head.?
The dependent, the nearercandidate head and the farther candidate head ap-pear in this order in Japanese sentences.
The orderdefines the relative position of the contextual fea-tures.
The distance between the dependent and acandidate head is another feature to represent therelative position.
In previous research, the distancehas been represented by feature buckets, such as 1,2-5, or 6+.
While for some dependents and theirheads whether the distance is 1 or not is impor-tant, absolute distance is not so important since2Contextual features are features neither in the dependentnor in the candidate head(s).Japanese is a free-order language.
Relative posi-tions are more informative since some dependentstend to appear closer to other dependents, suchas objects that tend to appear closer to predicatescompared with other complements.
The tourna-ment model represents both the distance and rela-tive position as features.The deterministic algorithms are biased to selectnearer candidate heads.
As most dependent andhead pairs appear within a close window, this ten-dency does not cause many errors; deterministicalgorithms are weak at finding correct heads thatappear in a long distance as pointed out in Kudoand Matsumoto (2005).2.3 Relative PreferencesWhat the dependency parsers try to learn is rela-tive preference of bunsetsu dependency, i.e., howa dependent selects its head among others.
Therelative preference method (Kudo and Matsumoto,2005) learns the relative preferences among thecandidate heads by a discriminative framework.The relative preferences are learned with the log-linear model so as to give larger probability tothe correct dependent-head pair over any othercandidates.
McDonald?s method (2005) with theCLE algorithm learns the relative preferences bya perceptron algorithm ?
MIRA (Crammer andSinger, 2003), so that the correct dependent-headlink receives a higher score.
The tournamentmodel learns which candidate is more likely to bethe head between two candidates in a one-on-onegame in a tournament.
Therefore, all of those pars-ing algorithms try to learn the way to give the high-est preference to the correct dependent-head pairamong all possibilities though in different settings.While the relative preference method and Mc-Donald?s method consider all candidate heads in-dependently in a discriminative model, the tour-nament model evaluates which candidate is morelikely to be the head between the latest winner andthe new candidate.
The latest winner has alreadydefeated all of the preceding candidates.
If thenew candidate beats the latest winner, it becomesthe new winner, meaning that it is the most pre-ferred candidate among others so far considered.Through this way of comparison with the runner-up candidates, the tournament model uses richerinformation in learning relative preferences thanthe models in which all candidates are indepen-dently considered.363// N: # of bunsetsu?s in input sentence// true_head[j]: bunsetsu j?s head at// training data// gen(j,i1,i2,LEFT): generate// an example where bunsetsu j is// dependent of i1// gen(j,i1,i2,RIGHT): generate// an example where bunsetsu j is// dependent of i2for j = 1 to N-1 doh = true_head[j];for i = j+1 to h-1 dogen(j,i,h,RIGHT);for i = h+1 to N dogen(j,h,i,LEFT);end-for;Figure 3: Pseudo code of training example gener-ation procedure.3 Proposed Algorithm3.1 Training Example Generation AlgorithmAs shown in Figure 3, for each dependent, we gen-erate pairs of the correct head and all other candi-date heads.
On the example generation, the proce-dure does not take into account the projective con-straint; all bunsetsu?s on the right-hand side of thefocused-on dependent are candidate heads.Table 1 shows all examples generated from twosentences shown in Figure 1.
2-tuple models gen-erate training examples formed as (dependent, can-didate).
So, from the sentences of Figure 1, it gen-erates opposite classes to the pair (kare-wa, hito-da).
On the other hand, the examples generated bythe tournament model do not contain such incon-sistency.3.2 Parsing AlgorithmThe tournament model has quite wide freeness inthe parsing steps.
We introduce one of the tour-nament algorithms, in which the dependents arepicked from right to left; and the games of the tour-nament are performed from left to right.
This pars-ing algorithm takes into account the projective andhead-final constraints.This algorithm is shown in Figure 4.
The over-all parsing process moves from right to left.
Onselecting the head for a dependent all of the bun-setsu?s to the right of the dependent have alreadybeen decided.
In Figure 4, the array ?head?stores the parsed results and ensures that only non-crossing candidate heads are taken into considera-tion.// N: # of bunsetsu?s in// input sentence// head[]: (analyzed-) head of bunsetsu// classify(j,i1,i2): ask SVM// which candidate (i1 or i2) is// more likely for head of j.// return LEFT if i1 wins.// return RIGHT if i2 wins.head[] = {2,3,...,N-1,N,EOS};for j = N-1 downto 1 doh = j+1;i = head[h];while i != EOS doif classify(j,h,i)==RIGHTthen h = i;i = head[i];end-while;head[j] = h;end-for;Figure 4: Pseudo code of parsing algorithm.Note that the structure of the tournament has lit-tle effect on the results (< 0.1) in our preliminaryexperiments.
We tried 2 ?
2 options: the depen-dents are picked from right to left or from left toright; and the games of the tournament are per-formed from right to left or from left to right.
Wechoose the most natural combination for Japanesedependency parsing, which is easy to implement.4 Experiment4.1 SettingsWe implemented the tournament model, the CC al-gorithm (Kudo and Matsumoto, 2002), SR algo-rithm (Sassano, 2004) and CLE algorithm (Mc-Donald et al, 2005) with SVM classifiers.
Weevaluated dependency accuracy and sentence accu-racy using Kyoto Text Corpus Version 4.0, which iscomposed by newspaper articles.
Dependency ac-curacy is the percentage of correct dependenciesout of all dependency relations.
Sentence accuracyis the percentage of sentences in which all depen-dencies are determined correctly.
Dependency ac-curacy is calculated excluding the rightmost bun-setsu of each sentence.
3 Sentences that consist ofone bunsetsu are not used in our experiments.We use January 1st to 8th (7,587 sentences) forthe training data.
We use January 9th (1,213 sen-tences), 10th (1,479 sentences) and 15th (1,179sentences) for the test data.
We use TinySVM 4as a binary classifier.
Cubic polynomial kernel is3Most research such as Kudo?s (2005) uses this criteria.4http://chasen.org/?taku/software/TinySVM/364Sentence Focused-on dependent Left(Nearer) candidate Right(Farther) candidate Class label(a) kare-wa hon-wo hito-da.
RIGHT(a) kare-wa yomanai hito-da.
RIGHT(a) hon-wo yomanai hito-da.
LEFT(b) kare-wa hon-wo yomanai.
RIGHTTable 1: Generated examples from sentences in Figure 1.used for the kernel function.
Cost of constraint vi-olation is 1.0.
These SVM settings are the sameas previous research (Kudo and Matsumoto, 2002;Sassano, 2004).
All experiments were performedon Dual Core Xeon 3GHz x 2 Linux machines.4.2 FeaturesHere we describe features used in our experiments.Note that for the tournament model, features cor-responding to candidates are created for each ofthe nearer and farther candidates.
We define theinformation of a word as the following features:lexical forms, coarse-grained POS tags, full POStags and inflected forms.
We also define the infor-mation of a bunsetsu as word information for eachof syuji and gokei.
Syuji is the head content wordof the bunsetsu, defined as the rightmost contentword.
Gokei is the representative function word ofthe bunsetsu, defined as the rightmost functionalword.Existence of punctuations or brackets, whetherthe bunsetsu is the first bunsetsu in the sentence,and whether it is the final bunsetsu in the sentenceare also members of information of a bunsetsu.Standard features are the following: Informa-tion of the dependent and the candidate heads, dis-tance between the dependent and the candidateheads (1, 2-5 or 6+ bunsetsu?s), all punctuations,brackets and all particles between the dependentand the candidate heads.Additional features are the following: All caseparticles in the dependent and the candidate heads,information of the leftmost word in the candidateheads, and the lexical form of the neighboring bun-setsu to the right of the candidate heads.Case particle features are the following: Allcase particles appearing in the candidates?
depen-dent.
These features are intended to take into con-sideration the correlation between the case parti-cles in the dependent of a head.
When the head isa verb, it has a similar effect of learning case frameinformation.Standard and additional features are introducedby Sassano (2004).
The case particle feature isnewly introduced in this paper.
Features corre-sponding to the already-determined dependencyrelation are called dynamic features, and the othercontextual features are called static features.
Stan-dard and additional features are static features,and case particle features are dynamic features.Whether a dynamic feature is available for a pars-ing algorithm depends on the parsing order of thealgorithm.4.3 Parsing AccuracyThe parsing accuracies of our model and previ-ous models are summarized in Table 2.
Note that,since the CLE algorithm is non-deterministic anddynamic features are not available for this algo-rithm, we use only a standard and additional fea-ture set instead of an all feature set.
By McNemartest (p < 0.01) on the dependency accuracy, thetournament model significantly outperforms mostof other methods except for the SR algorithm onJanuary 10th data with all features (p = 0.083)and the CC algorithm on January 10th data withall features (p = 0.099).
The difference betweenthe tournament models with all features and withthe standard feature only is significant except foron January 9th data (p = 0.25).The highest dependency accuracy reported forJanuary 9th of Kyoto Text Corpus Version 2.0 is89.56% by Sassano(2004)?s SR algorithm.
5Since we don?t have the outputs of Sassano?s ex-periments, we cannot do a McNemar test betweenthe tournament model and Sassano?s results.
Ourmodel outperforms Sassano?s results by the depen-dency accuracy, but the difference between thesetwo is not significant by prop test (p = 0.097).When we add the additional and case particlefeatures, the improvement of our model is less thanthat of other algorithms.
This is interpreted thatour model can consider richer contextual informa-5This accuracy in Sassano (2004) is not for Kyoto TextCorpus Version 4.0 but Version 2.0 The feature set of Sas-sano?s experiment is also different from our experiment.365Method Features Jan. 9th Jan.10th Jan. 15thTournament Standard feature only 89.89/49.63 89.63/48.34 89.40/49.70All features 90.09/49.71 90.11/49.02 90.35/52.59SR algorithm Standard feature only 88.18/45.92 88.80/44.76 88.03/47.24(Sassano, 2004) All features 89.22/47.90 89.79/47.87 89.55/49.79CC algorithm Standard feature only 88.17/45.92 88.80/44.76 88.00/47.24(Kudo and Matsumoto, 2002) All features 89.22/47.90 89.80/47.94 89.53/49.79CLE algorithm Standard feature only 88.64/45.34 88.16/43.14 88.07/45.21(McDonald et al, 2005) Standard and Additional 89.21/46.83 89.05/45.03 88.90/48.43Table 2: Dependency and sentence accuracy [%] using 7,587 sentences as training data.tion within the algorithm itself than other models.This result also shows that the accuracies of theSR algorithm and CC algorithm are comparablewhen using the same features.
However, this doesnot mean that their substantial power is compara-ble because the parsing order limits the availabledynamic features.4.4 Parsing SpeedParsing time and the size of the training exam-ples are shown in Table 3.
All features wereused.
The column ?# Step?
represents the numberof SVM classification steps in parsing all the testdata.
Time complexity of the tournament modeland CC algorithm are O(n2) and that of the SR al-gorithm is O(n).
The tournament model needs 1.7times more SVM classification steps and is 4 timesslower than the SR algorithm.
The reason for thisdifference in steps (x1.7) and time (x4) is the num-ber of training examples and features in the SVMclassification.4.5 Comparison to Relative PreferenceMethodWe performed another experiment under the samesettings as Kudo?s (2005) to compare the tourna-ment model and relative preference method.
Thecorpus is Kyoto Text Corpus Version 3.0 sinceKudo and Matsumoto (2005) used this corpus.Training data is articles from January 1st to 11thand editorials from January to August (24,263 sen-tences).
Test data is articles from January 14thto 17th and editorials from October to December(9,287 sentences).
We did not perform parameterengineering by development data, although Kudoand Matsumoto (2005) performed it.
The criteriafor dependency accuracy are the same as the exper-iments above.
However, the criteria for sentenceaccuracy in this section include all sentences, evenif the length is one as Kudo and Matsumoto (2005)did.The results are shown in Table 4.
Note thatKudo and Matsumoto (2005) and our feature setsare different.
Only the CC Algorithm is tested withboth feature sets.
Our feature set looks better thanKudo?s.
By McNemar test (p < 0.01) on the de-pendency accuracy, the tournament model outper-forms both the SR and CC algorithms significantly.Since we don?t have the outputs of relative prefer-ence methods, we cannot do a McNemar test be-tween the tournament model and the relative pref-erence methods.
By prop test (p < 0.01) on thedependency accuracy, our model significantly out-performs the relative preference method of Kudoand Matsumoto (2005).
Though our model outper-forms the ?combination?
model of Kudo and Mat-sumoto (2005) by the dependency accuracy, thedifference between these two is not significant byprop test (p = 0.014).
6Note that, a log-linear model is used in Kudo?sexperiment.
The log-linear model has shortertraining time than SVM.
The log-linear model re-quires feature combination engineering by hand,while SVMs automatically consider the featurecombination by the use of polynomial kernels.5 Discussion and Future WorkIn our error analysis, many errors are observed incoordination structures.
Sassano (2004) reportedthat introduction of features of coordinated bun-6The ?combination?
model is the combination of the CCalgorithm and relative preference method.
In Kudo?s exper-iment, whereas the relative preference method outperformsthe CC algorithm for long-distance relations, it is reversed forshort-distance relations.
They determined the optimal combi-nation (the threshold set at bunsetsu length 3) using the devel-opment set.
In our experiment, the tournament model outper-forms the CC and SR algorithms for relations of all lengths.Therefore, the tournament model doesn?t need such ad hoccombination.366Method # Step Time[s] # Example # FeatureTournament 26396 371 374579 56165SR algorithm (Sassano, 2004) 15641 80 94669 37183CC algorithm (Kudo and Matsumoto, 2002) 18922 99 112759 37183Table 3: Parsing time and the size of the training examples.Method Features Dep.
Acc.
Sentence Acc.Tournament All 91.96 57.44SR algorithm (Sassano, 2004) All 91.48 55.67CC algorithm (Kudo and Matsumoto, 2002) All 91.47 55.65Combination ?
CC and Relative preference Kudo?s (2005) 91.66 56.30Relative preference (Kudo and Matsumoto, 2005) Kudo?s (2005) 91.37 56.00CC algorithm (Kudo and Matsumoto, 2002) Kudo?s (2005) 91.23 55.59Table 4: Dependency and sentence accuracy [%] using 24,263 sentences as training data with all features:comparison with Kudo(2005)?s experiments.setsu improves accuracy.
In Kyoto Text CorpusVersion 4.0, coordination and apposition are anno-tated with different types of dependency relation.We did not use this information in parsing.
A sim-ple extension is to include those dependency types.Another extension is to employ a coordination ana-lyzer as a separate process as proposed by Shimboand Hara (2007).Incorporating co-occurrence information willalso improve the parsing accuracy.
One usage ofsuch information is verb-noun co-occurrence in-formation that would represent selectional prefer-ence for case-frame information.
Abekawa andOkumura (2006) proposed a reranking methodof k-best dependency analyzer outputs using co-occurrence information.
We have already devel-oped a method to output k-best dependency trees.One of our future works is to test the rerankingmethod using co-occurrence information on the k-best dependency trees.Multilingual parsing is another goal.
Japaneseis a strict head-final language.
However, most lan-guages do not have such constraint.
A differentparsing algorithm should be employed for otherless constrained languages so as to relax this con-straint.
A simple solution is to introduce a discrim-ination model according to whether the head is onthe left-hand-side or on the right-hand-side of a de-pendent.
Existence of projective constraint doesnot matter for the tournament model.
The tourna-ment model can be extended to relax the projec-tive constraint.
The preliminary results for Englishare shown in our CoNLL Shared Task 2008 report(Watanabe et al, 2008).
The unlabeled syntac-tic dependency accuracy of 90.73% for WSJ datashows that the model is also effective in other (notstrictly head final, non-projective) languages.
Inparsing word sequences, O(n2) time complexitybecomes a serious problem compared to parsingbunsetsu sequences.
Since a bunsetsu is a basephrase in Japanese, the number of bunsetsu?s ismuch less than the number of words.
One solutionis to perform base phrase chunking in advance andto apply dependency parsing on the base phrase se-quences.A reviewer pointed out similarities between ourmodel and RankSVM.
RankSVM compares pairsof elements to find out relative ordering betweenelements.
Our tournament model is a special casewhere two elements are compared, but with a spe-cific viewpoint of a focused dependent.6 ConclusionsWe proposed a Japanese dependency parsing al-gorithm using the tournament model.
The tour-nament model is a 3-tuple bunsetsu model andimproves discriminative performance of selectingcorrect head compared with the conventional 2-tuple models.
The most likely candidate head isselected by one-on-one games in the step-laddertournament.
The proposed model considers therelative position between the nearer and farthercandidates.
The model also considers all candi-date heads, which are not considered in determin-istic parsing algorithms.
The tournament modelis robust for the free-order language.
The accu-367racy of our model significantly outperforms thatof the previous methods in most experiment set-tings.
Even though the problem of parsing speedremains, our research showed that consideringtwo or more candidate heads simultaneously canachieve more accurate parsing.ReferencesAbekawa, Takeshi and Manabu Okumura.
2006.Japanese Dependency Parsing Using Co-occurrenceInformation and a Combination of Case Elements.In Proceedings of the 21st International Confer-ence on Computational Linguistics and 44th AnnualMeeting of the Association for Computational Lin-guistics (COLING-ACL 2006), pages 833?840.Buchholz, Sabine and Erwin Marsi.
2006.
CoNLL-X Shared Task on Multilingual Dependency Parsing.In CoNLL-2006: Proceedings of the Tenth Confer-ence on Computational Natural Language Learning,pages 149?164.Chu, Yoeng-Jin and Tseng-Hong Liu.
1965.
On theshortest arborescence of a directed graph.
ScienceSinica, 14:1396?1400.Crammer, Koby and Yoram Singer.
2003.
Ultraconser-vative Online Algorithms for Multiclass Problems.Journal of Machine Learning Research, 3:951?991.Edmonds, Jack.
1967.
Optimum branchings.
Jour-nal of Research of the Natural Bureau of Standards,71B:233?240.Eisner, Jason M. 1996.
Three New Probabilistic Mod-els for Dependency Parsing: An Exploration.
InCOLING-96: Proceedings of the 16th Conference onComputational Linguistics - Volume 1, pages 340?345.Iida, Ryu, Kentaro Inui, Hiroya Takamura, and YujiMatsumoto.
2003.
Incorporating Contextual Cuesin Trainable Models for Coreference Resolution.
InEACL Workshop ?The Computational Treatment ofAnaphora?.Kudo, Taku and Yuji Matsumoto.
2002.
Japanese De-pendency Analysis Using Cascaded Chunking.
InCoNLL-2002: Proceedings of the Sixth Conferenceon Computational Language Learning, pages 1?7.Kudo, Taku and Yuji Matsumoto.
2005.
Japanese De-pendency Parsing Using Relative Preference of De-pendency (in Japanese).
Information Processing So-ciety of Japan, Journal, 46(4):1082?1092.McDonald, Ryan, Koby Crammer, and FernandoPereira.
2005.
Online Large-Margin Training ofDependency Parsers.
In ACL-2005: Proceedings of43rd Annual Meeting of the Association for Compu-tational Linguistics, pages 523?530.Nivre, Joakim and Jens Nilsson.
2005.
Psuedo-Projective Dependency Parsing.
In ACL-2005: Pro-ceedings of 43rd Annual Meeting of the Associationfor Computational Linguistics, pages 99?106.Nivre, Joakim and Mario Scholz.
2004.
DeterministicDependency Parsing of English Text.
In COLING-2004: Proceedings of the 20th International Confer-ence on Computational Linguistics, pages 64?70.Nivre, Joakim, Johan Hall, Sandra Ku?bler, Ryan Mc-Donald, Jens Nilsson, Sebastian Riedel, and DenizYuret.
2007.
The CoNLL 2007 Shared Task on De-pendency Parsing.
In CoNLL-2007: Proceedings ofthe CoNLL Shared Task Session of EMNLP-CoNLL-2007, pages 915?932.Nivre, Joakim.
2003.
An Efficient Algorithm for Pro-jective Dependency Parsing.
In IWPT-2003: 8th In-ternational Workshop on Parsing Technology, pages149?160.Sassano, Manabu.
2004.
Linear-Time DependencyAnalysis for Japanese.
In COLING-2004: Proceed-ings of the 20th International Conference on Com-putational Linguistics, pages 8?14.Shimbo, Masashi and Kazuo Hara.
2007.
A Discrimi-native Learning Model for Coordinate Conjunctions.In Proceedings of the 2007 Joint Conference onEmpirical Methods in Natural Language Process-ing and Computational Natural Language Learning(EMNLP-CoNLL), pages 610?619.Watanabe, Yotaro, Masakazu Iwatate, Masayuki Asa-hara, and Yuji Matsumoto.
2008.
A Pipeline Ap-proach for Syntactic and Semantic Dependency Pars-ing.
In Proceedings of the Twelfth Conference onComputational Natural Language Learning (To Ap-pear).Yamada, Hiroyasu and Yuji Matsumoto.
2003.
Statis-tical Dependency Analysis with Support Vector Ma-chines.
In IWPT-2003: 8th International Workshopon Parsing Technology, pages 195?206.368
