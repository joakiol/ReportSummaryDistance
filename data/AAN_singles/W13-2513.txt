Proceedings of the 6th Workshop on Building and Using Comparable Corpora, pages 105?111,Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational LinguisticsComparing Multilingual Comparable Articles Based On OpinionsMotaz Saad David Langlois Kamel Sma?
?liSpeech Group, LORIAINRIA, Villers-le`s-Nancy, F-54600, FranceUniversite?
de Lorraine, LORIA, UMR 7503, Villers-le`s-Nancy, F-54600, FranceCNRS, LORIA, UMR 7503, Villers-le`s-Nancy, F-54600, France{firstName.lastName}@loria.frAbstractMultilingual sentiment analysis attracts in-creased attention as the massive growthof multilingual web contents.
This con-ducts to study opinions across differentlanguages by comparing the underlyingmessages written by different people hav-ing different opinions.
In this paper, wepropose Sentiment based ComparabilityMeasures (SCM) to compare opinions inmultilingual comparable articles withouttranslating source/target into the same lan-guage.
This will allow media trackers(journalists) to automatically detect publicopinion split across huge multilingual webcontents.
To develop SCM, we need eitherto get or to build parallel sentiment cor-pora.
Because this kind of corpora are notavailable, we decided to build them.
Forthat, we propose a new method to automat-ically label parallel corpora with sentimentclasses.
Then we use the extracted parallelsentiment corpora to develop multilingualsentiment analysis system.
Experimentalresults show that, the proposed measurecan capture differences in terms of opin-ions.
The results also show that compara-ble articles variate in their objectivity andpositivity.1 IntroductionWe can distinguish two kinds of sentiments anal-ysis depending on monolingual or multilingual ar-ticles.In the following, as in (Pang and Lee, 2008), theterms Sentiment Analysis (SA) and Opinion Min-ing (OM) are used as synonyms.
Mining opinionsis to identify the subjectivity and/or the polarity ofa given text at article or sentence level.
Subjectiv-ity identification is to classify the text into subjec-tive or objective, while polarity identification is toclassify the text into negative or positive.Popular methods for monolingual sentimentanalysis are based on lexicon and corpus.
Lexi-con based methods use string matching techniquesbetween texts and annotated lexicons.
The mostcommon sentiment lexicons for English languageare WordNet-Affect (Valitutti, 2004) and Senti-WordNet (Esuli and Sebastiani, 2006), which areextensions of WordNet.
Additionally, SenticNet(Cambria et al 2010) is a knowledge-base ex-tension of aforementioned lexicons.
On the otherhand, corpus based approach is popular for sen-timent analysis (Pang and Lee, 2008).
It usescorpora and machine learning algorithms to buildsentiment classification systems.
For example,Pang et alused polarity (Pang et al 2002) andsubjectivity (Pang and Lee, 2004) English cor-pora to train machine learning algorithms to buildsentiment classifiers.
These resources have beenadapted to other languages by many researchersas we will see in the following.Multilingual sentiments analysis becomes a re-ality because of the massive growth of multilin-gual web contents.
In this case, sentiment analy-sis identifies sentiments across multiple languagesinstead of one language.
This can be done bycreating sentiment resources for new languagesby translating existing English resources (lexi-cons/corpora) into the target language, or by trans-lating target text into English, then pass the trans-lated text to English models for sentiment analysis(Rushdi-Saleh et al 2011; Bautin et al 2008; De-necke, 2008; Ghorbel, 2012).
However, (Brookeet al 2009) reported that creating new resourcesto build sentiment models from scratch works bet-ter than using the approach based on machinetranslation.As we see in the previous discussion, works onmultilingual sentiment analysis just try to iden-tify sentiments across multiple languages.
How-105ever, it is worthy to compare opinions about agiven topic in several languages, not just to iden-tify these opinions.
If people from different cul-tures wrote an article about political/societal top-ics, they may judge these topics differently ac-cording to their cultures.
In fact, detecting dis-agreement of opinions in multiple languages is apromising research area.
So, our goal is to en-able media trackers (journalists) to automaticallydetect the split of public opinions about a giventopic across multiple languages.
To the best of ourknowledge, there are no work in the literature thatserve our goal, therefore, we propose to developautomatic measures that compare opinions in mul-tilingual comparable articles.
These comparabil-ity measures will be the core of our goal which isbuilding multilingual automatic journalist reviewsystem.For that, we propose a Sentiment based Com-parability Measures (SCM) which identify senti-ments, score them and compare them across mul-tilingual documents.
Therefore, we need to iden-tify and score sentiments in multiple languages.Namely, SCM needs a multilingual sentimentanalysis system to identify and score sentiments.To build this system, we need parallel sentimentcorpora from different topics.
Unfortunately, wedo not have such corpora, we only have Englishsentiment corpus.
So, we propose in Section 2 anew method to build parallel sentiment corpora.We start from English sentiment corpora (moviereviews domain), then use it to build sentimentclassifier for English language and then label anew parallel English/target corpora which is dif-ferent from the movie one.
In section 3, we use theobtained parallel sentiment corpora to build a mul-tilingual sentiment analysis system which is usedto develop SCM, then we use SCM to comparemultilingual comparable articles in terms of opin-ions.
The advantage of this idea is that we do notneed to translate corpora/lexicons to analyse mul-tilingual text.The rest of this article is organized as fol-lows, Section 2 describes our method to build par-allel sentiment corpora, Section 3 presents ourproposed sentiment based comparability measures(SCM) and experimental results conducted on cor-pora.
Finally, we state the conclusions.2 Sentiment Corpora ExtractionAs we introduced earlier, we need parallel cor-pora to build the sentiment comparability measure.Therefore, we present in this section a methodto annotate parallel corpora with sentiment la-bels.
This method can be applied on any En-glish/target language pairs.
In this work, we la-bel English/Arabic parallel sentences.
The idea isto use an English sentiment classifier to label eachEnglish sentence in the new parallel corpora, thenwe can assign the same label to the target (Ara-bic) sentence, because sentences are parallel andconvey the same opinions.The widely used approach to build a classifieris to build a Naive Bayes model using n-gramslinguistic features (Pang et al 2002; Dave et al2003; Pang and Lee, 2004; Kim and Hovy, 2004;Cui et al 2006; Tan et al 2009).
So, we use thismethod on bigrams extracted from English sen-timent corpora of movie reviews.
These corporaare manually labelled with subjectivity and polar-ity labels.
Each review in the collection is rep-resented as a vector composed of bigram occur-rences.
Then, each vector is feed to Naive Bayesclassifier with corresponding class label for train-ing.
Naive Bayes classifies the vector to the high-est probable class.
Our objective in this paper is tocompare opinions, this is why we used this tradi-tional method for building the sentiment classifier.The parallel corpora, that we annotate, covervariant topics (newspapers, UN resolutions, andtranscribed talks), and are available in many lan-guages.
The newspapers are collection of parallelarticles from AFP, ANN, ASB, and provided byLDC1.
UN corpora2 is a collection of United Na-tions General Assembly Resolutions.
Transcribedtalks are collection of multilingual transcriptionsfrom TED provided by WIT33.Figure 1 illustrates our method and Table 1 de-scribes corpora denoted in the figure.
The men-tioned corpora are: senti-corp, parallel, and new-senti-corp. senti-corp represents the monolingual(English) manually labelled, parallel representsparallel corpora in variant topics, and new-senti-corp represents the extracted corpora.
Corporasizes are presented in Tables 2 and 3.
Table 2presents the number of reviews of senti-corp with1LDC - Linguistic Data Consortium: ldc.upenn.edu2Corpora of the United Nations: uncorpora.org3WIT3 Web Inventory of Transcribed and TranslatedTalks wit3.fbk.eu106respect to sentiment classes, and Table 3 presentsthe number of sentences of parallel corpora.Table 1: Corpora descriptionCorpora Descriptionsenti-corpMonolingual manuallylabelled sentiment corpus(polarity or subjectivity)senti-corp-p1Part 1 of senti-corp (90%):used to build classificationmodels which are used forlabelling tasksenti-corp-p2Part 2 of senti-corp (10%):This is the (test corpus)which is used to test theextracted corporaparallel Multilingual parallel corporaparallel-p1Part 1 of the parallel corpora(90%): to be labelledautomaticallyparallel-p2Part 2 of the parallel corpora(10%): to be used to evaluateSCMnew-senti-corpMultilingual automaticallylabelled sentiment corpusTable 2: Senti-corp size (number of reviews)Class senti-corp-p1 senti-corp-p2subjective 4500 500objective 4500 500negative 900 100positive 900 100Table 3: Parallel Corpora sizeCorpus # of sentencesparallel-p1 364Kparallel-p2 40KThe following steps describe the method wepropose:1.
Split senti-corp into two parts: senti-corp-p1is 90%, and senti-corp-p2 is 10%.2.
Use senti-corp-p1 to train a Naive Bayesclassifier to build a monolingual sentimentmodel.3.
Split the parallel corpora into two parts:parallel-p1 is 90%, and parallel-p2 is 10%.4.
Using the sentiment classification model ob-tained in step 2, classify and label Englishsentences of parallel-p1 and assign the samesentiment class to the corresponding Arabicsentences.5.
Refine and filter sentences which are labelledin step 4.
The filtering process keeps onlysentences that have high sentiment score.Then, we obtain new-senti-corp which isArabic/English parallel sentiment labelledcorpora in different domains.6.
Use the English part of new-senti-corp whichis obtained in step 5 to train a Naive Bayesclassifier.7.
Evaluate the classifier built in step 6 on senti-corp-p2.
If the classification accuracy is ac-cepted, then continues, otherwise, try othercorpora and/or models.This method is independent of the the sentimentclass labels.
So, it can be applied for subjectivityor polarity corpus.Tables 4 and 5 present the experimental resultsof steps 4 and 5 of the Figure 1.
Table 4 showsthe statistical information of sentiment scores ofthe labelled corpora, where Rate is the class labeldistribution (percentage) with respect to the wholedataset.
?, ?, Min, and Max are the mean, stan-dard deviation, minimum, and maximum valuesof sentiment scores respectively.
For subjectiv-ity labels, 54% and 46% of sentences are labelledas subjective and objective respectively.
For po-larity labels, 58% and 42% of sentences are la-belled as negative and positive respectively.
Table5 presents the frequency table of intervals of sen-timent scores of the labelled sentences.
We cansee from Table 5 that most of sentences have highsentiment scores (from 0.9 to 1.0).
To extract highquality labelled sentences, we keep only sentenceswith score greater than 0.8.In order to evaluate the quality of the extractedcorpora (step 7 in Figure 1), we need first to build asentiment classifier based on this corpora and thenevaluate the accuracy of this classifier.
The detailof this process is given bellow:1.
Train a Naive Bayes classifier on the parallelsentiment corpora new-senti-corp.2.
Test the obtained classifiers on the manuallylabelled corpus senti-corp-p2.107Figure 1: Approach for parallel sentiment corpora extraction and evaluationTable 4: Sentiment classes statistics for labelled sentences scores of parallel-p1 corporaLabel Count Rate ?
?
Min Maxsubjective 231,180 54% 0.93 0.11 0.60 1.00objective 197,981 46% 0.93 0.11 0.60 1.00negative 219,070 58% 0.84 0.12 0.60 0.99positive 159,396 42% 0.83 0.12 0.60 1.0Table 5: Frequency table of sentiment scores intervals of labelled sentences of parallel-p1 corporaLabel [0.6,0.7) [0.7,0.8) [0.8,0.9) [0.9,1]subjective 6.1% 9.0% 11.9% 73.0%objective 6.8% 8.1% 10.8% 74.3%negative 17.7% 18.0% 21.6% 42.7%positive 20.4% 20.8% 21.7% 37.2%In the following, senti-corp-p2 is the test cor-pus.
The evaluation is presented in Table 6.The metrics include classification accuracy, andF-measures.
F-neg, F-pos, F-sub, and F-obj arethe F-measures for negative, positive, subjective,and objective classes respectively.
For subjectiv-108Table 6: Evaluation of extracted corpus (step 7)Subjectivity PolarityAccuracy 0.765 Accuracy 0.720F-sub 0.717 F-neg 0.754F-obj 0.799 F-pos 0.674ity test, the classifier achieved 76.5% of accuracyand an average of 75.8% of f-measure.
For polar-ity test, the classifier leads to 72% of accuracy andan average of 71% of F-measure.We wanted to compare these results with oth-ers works in sentiment classification, but unfortu-nately the used corpora are not the same.
Anyway,these results are only indicative for us, because ourobjective is not to propose a new method for auto-matic sentiment classification, but to build a senti-ment based comparability measure.Now, we obtained English/Arabic parallel sen-timent corpora in multiple topics.
We use thesecorpora to develop sentiment based comparabilitymeasures that will be described in the next section.Notice that at the beginning the only avail-able sentiment corpus was a collection of moviereviews in English language, with the proposedmethod, we got multilingual sentiment corporaof different topics.
Furthermore, using thismethod, one can obtain sentiment corpus forunder-resourced languages.
The advantage of theparallel corpora is to build sentiment classifiersthat can be used to develop sentiment based com-parability measures.3 Sentiment Based ComparabilityMeasuresAs we stated in the introduction, there are no workin the literature that serve our goal, which is tocompare multilingual articles in terms opinions.Therefore, we propose to develop automatic mea-sures that compare opinions in multilingual com-parable articles.In the previous section, we built a parallel sen-timent corpora where both source and its corre-sponding sentence have the same sentiment label.In this section, we compare multilingual compa-rable articles in terms of sentiments.
Obviously,in this case we do not have the same sentiment la-bels since articles are comparable and not parallel.So, we develop Sentiment based ComparabilityMeasures (SCM) which measure the differencesof opinions in multilingual corpora.
For that, weuse the achieved parallel sentiment corpora new-senti-corp to build multilingual sentiment analysissystems, using the same method as in Section 2.The idea is to identify and score sentiments inthe source and target comparable articles and pro-vide these information to SCM to compare theiropinions.
In the following, we describe how tocompute SCM for comparable articles based onaverage score of all sentences.We use formula 1 which is derived from NaiveBayes to compute opinion score and assign thecorresponding label:classify(S) = argmaxcP (c)n?k=1P (fk|c) (1)where S is a sentence, fk are the features of S,c ?
{o, o?}
for subjectivity and c ?
{p, p?}
for po-larity, where o is objective, o?
is subjective, p ispositive, p?
is negative.An article may contain some sentences belong-ing to the subjective class, and others belongingto the objective class (idem for positive and nega-tive).
So, for a given pair of comparable articles,SCM has three parameters dx, dy, c, where dx, dyare the source and the target articles respectively,and c is the class label.
This score is calculated asfollows:SCM(dx, dy, c) =???????
?C(Sx)=cP (Sx|c)Nx?
?C(Sy)=cP (Sy|c)Ny???????
(2)Where Sx ?
dx, Sy ?
dy, and?C(Sx)=cP (Sx|c)and?C(Sy)=cP (Sy|c) are the sum of probabilitiesfor all source and target sentences respectively thatbelong to class c. Nx and Ny are the number ofsource and target sentences respectively that be-long to the class c. Formally speaking, for a givenpair of documents dx, dy, we have four measures:SCM(dx, dy, o), SCM(dx, dy, o?)
for subjectiv-ity, and SCM(dx, dy, p), SCM(dx, dy, p?)
for po-larity.In our experiments, we calculate SCM for pairof articles in parallel and comparable corpora.Calculating SCM for parallel corpora could bevery surprising, but we did it in order to showthat for this kind of corpora, the proposed measureshould be better than the one achieved for compa-rable corpora.109Table 7: Comparable corpora informationAFEWC eNewsEnglish Arabic English ArabicArticles 40290 40290 34442 34442Sentences 4.8M 1.2M 744K 622KAverage #sentences/article 119 30 21 17Average #words/article 2266 548 198 161Words 91.3M 22M 6.8M 5.5MVocabulary 2.8M 1.5M 232K 373KTable 8: Average Sentiment Based Comparability Measures (SCM)Corpora SCM(dx, dy, o?)
SCM(dx, dy, o) SCM(dx, dy, p?)
SCM(dx, dy, p)parallel-p2AFP 0.02 0.02 0.1 0.12ANN 0.05 0.06 0.1 0.1ASB 0.07 0.1 0.12 0.14TED 0.06 0.06 0.08 0.07UN 0.05 0.02 0.07 0.08ComparableENews 0.07 0.15 0.11 0.15AFEWC 0.11 0.19 0.11 0.16The comparable corpora that we use for ourexperiments are AFEWC and eNews which werecollected and aligned at article level (Saad et al2013).
Each pair of comparable articles is relatedto the same topic.
AFEWC corpus is collectedfrom Wikipedia and eNews is collected from Eu-ronews website.
Table 7 presents the number ofarticles, sentences, average sentences per article,average words per article, words, and vocabularyof these corpora.Table 8 presents the experimental results ofSCM computed using formula 2.
SCM is com-puted for the source and target articles for par-allel corpora parallel-p2 and comparable corpora(AFEWC and eNews).
We note that SCM for AFP,ANN, ASB, TED, and UN corpora are small be-cause they are parallel.
This shows that the pro-posed measure is well adapted to capture the sim-ilarity between parallel articles.
Indeed, they havethe same sentiments.
On the other hand, SCM be-come larger for comparable corpora, because theconcerned articles do not necessary have the samesentiments.
The only exception to what have beenclaimed is that the subjectivity SCM for eNewscomparable corpora is similar to the one of ASBwhich is parallel corpora.
In contrast, the objec-tivity SCM is larger (0.15) for eNews, that meanspair of articles in eNews corpora have similar sub-jective but different objective sentiments.
In otherwords, source and target are considered similar interms of subjectivity but different in terms of ob-jectivity (idem for negative and positive).
Con-sequently, comparable articles do not necessaryhave the same opinions.
Additionally, we notethat the SCM for AFEWC corpora are the largestin comparison to the others, this is maybe becauseWikipedia has been written by many different con-tributors from different cultures.4 ConclusionsWe presented a new method for comparing mul-tilingual sentiments through comparable articleswithout the need of translating source/target arti-cles into the same language.
Our results showedthat it is possible now for media trackers to au-tomatically detect difference in public opinionsacross huge multilingual web contents.
The re-sults showed that the comparable articles variatein their objectivity and positivity.
To develop oursystem, we required parallel sentiment corpora.So, we presented in this paper an original methodto build parallel sentiment corpora.
We startedfrom an English movie corpus annotated in termsof sentiments, we trained NB classier to classifyan English text concerning topics different frommovie, and then we deduced the sentiment labelsof the the corresponding target parallel text by as-signing the same labels.
This method is interest-110ing because it allows us to produce several parallelsentiment corpora concerning different topics.
Webuilt SCM using these parallel sentiment corpora,then, SCM identifies sentiments, scores them andcompares them across multilingual documents.
Inthe future works, we will elaborate our journalistreview system by developing a multilingual com-parability measure that can handle semantics andintegrate it with the sentiment based measure.ReferencesM.
Bautin, L. Vijayarenu, and S. Skiena.
2008.
Inter-national sentiment analysis for news and blogs.
InProceedings of the International Conference on We-blogs and Social Media (ICWSM).J.
Brooke, M. Tofiloski, and M. Taboada.
2009.
Cross-linguistic sentiment analysis: From english to span-ish.
In International Conference RANLP, pages 50?54.E.
Cambria, R. Speer, C. Havasi, and A. Hussain.2010.
Senticnet: A publicly available semantic re-source for opinion mining.
Artificial Intelligence,pages 14?18.H.
Cui, V. Mittal, and M. Datar.
2006.
Compara-tive experiments on sentiment classification for on-line product reviews.
In proceedings of the 21st na-tional conference on Artificial intelligence - Volume2, AAAI?06, pages 1265?1270.
AAAI Press.K.
Dave, S. Lawrence, and D. M. Pennock.
2003.Mining the peanut gallery: opinion extraction andsemantic classification of product reviews.
In Pro-ceedings of the 12th international conference onWorld Wide Web, WWW ?03, pages 519?528, NewYork, NY, USA.
ACM.K.
Denecke.
2008.
Using sentiwordnet for multilin-gual sentiment analysis.
In Data Engineering Work-shop, 2008.
ICDEW 2008.
IEEE 24th InternationalConference on, pages 507?512.A.
Esuli and F. Sebastiani.
2006.
Sentiwordnet: Apublicly available lexical resource for opinion min-ing.
In In Proceedings of the 5th Conference on Lan-guage Resources and Evaluation, pages 417?422.H.
Ghorbel.
2012.
Experiments in cross-lingual sen-timent analysis in discussion forums.
In K. Aberer,A.
Flache, W. Jager, L. Liu, J. Tang, and C. Guret,editors, Social Informatics, volume 7710 of Lec-ture Notes in Computer Science, pages 138?151.Springer Berlin Heidelberg.S.-M. Kim and E. Hovy.
2004.
Determining the senti-ment of opinions.
In Proceedings of the 20th inter-national conference on Computational Linguistics,COLING ?04, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.B.
Pang and L. Lee.
2004.
A sentimental educa-tion: Sentiment analysis using subjectivity summa-rization based on minimum cuts.
In Proceedings ofthe 42nd Annual Meeting on Association for Compu-tational Linguistics, page 271.
Association for Com-putational Linguistics.B.
Pang and L. Lee.
2008.
Opinion mining and sen-timent analysis.
Found.
Trends Inf.
Retr., 2(1-2):1?135, January.B.
Pang, L. Lee, and S. Vaithyanathan.
2002.
Thumbsup?
: sentiment classification using machine learn-ing techniques.
In Proceedings of the ACL-02 con-ference on Empirical methods in natural languageprocessing-Volume 10, pages 79?86.
Association forComputational Linguistics.M.
Rushdi-Saleh, M. T.
Mart?
?n-Valdivia, L. A. Uren?aLo?pez, and J. M. Perea-Ortega.
2011.
Bilingualexperiments with an arabic-english corpus for opin-ion mining.
In Proceedings of the InternationalConference Recent Advances in Natural LanguageProcessing 2011, pages 740?745, Hissar, Bulgaria,September.
RANLP 2011 Organising Committee.M.
Saad, D. Langlois, and K.
Sma??li.
2013.
Extract-ing comparable articles from wikipedia and measur-ing their comparabilities.
In V International Confer-ence on Corpus Linguistics.
University of Alicante,Spain.S.
Tan, X. Cheng, Y. Wang, and H. Xu.
2009.
Adapt-ing naive bayes to domain adaptation for sentimentanalysis.
In Advances in Information Retrieval,pages 337?349.
Springer.R.
Valitutti.
2004.
Wordnet-affect: an affective exten-sion of wordnet.
In In Proceedings of the 4th In-ternational Conference on Language Resources andEvaluation, pages 1083?1086.111
