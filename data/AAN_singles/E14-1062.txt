Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 588?597,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsType-Supervised Domain Adaptation for Joint Segmentation andPOS-TaggingMeishan Zhang?, Yue Zhang?, Wanxiang Che?, Ting Liu??
?Research Center for Social Computing and Information RetrievalHarbin Institute of Technology, China{mszhang, car, tliu}@ir.hit.edu.cn?Singapore University of Technology and Designyue zhang@sutd.edu.sgAbstractWe report an empirical investigation ontype-supervised domain adaptation forjoint Chinese word segmentation andPOS-tagging, making use of domain-specific tag dictionaries and only un-labeled target domain data to improvetarget-domain accuracies, given a set ofannotated source domain sentences.
Pre-vious work on POS-tagging of other lan-guages showed that type-supervision canbe a competitive alternative to token-supervision, while semi-supervised tech-niques such as label propagation areimportant to the effectiveness of type-supervision.
We report similar findingsusing a novel approach for joint Chinesesegmentation and POS-tagging, under across-domain setting.
With the help of un-labeled sentences and a lexicon of 3,000words, we obtain 33% error reduction intarget-domain tagging.
In addition, com-bined type- and token-supervision can leadto improved cost-effectiveness.1 IntroductionWith accuracies of over 97%, POS-tagging ofWSJ can be treated as a solved problem (Man-ning, 2011).
However, performance is still wellbelow satisfactory for many other languages anddomains (Petrov et al., 2012; Christodoulopouloset al., 2010).
There has been a line of research onusing a tag-dictionary for POS-tagging (Merialdo,1994; Toutanova and Johnson, 2007; Ravi andKnight, 2009; Garrette and Baldridge, 2012).
Theidea is compelling: on the one hand, a list of lex-icons is often available for special domains, suchas bio-informatics; on the other hand, compiling a?Corresponding author.lexicon of word-tag pairs appears to be less time-consuming than annotating full sentences.However, success in type-supervised POS-tagging turns out to depend on several subtle fac-tors.
For example, recent research has found thatthe quality of the tag-dictionary is crucial to thesuccess of such methods (Banko and Moore, 2004;Goldberg et al., 2008; Garrette and Baldridge,2012).
Banko and Moore (2004) found that theaccuracies can drop from 96% to 77% when ahand-crafted tag dictionary is replaced with a rawtag dictionary gleaned from data, without any hu-man intervention.
These facts indicate that carefulconsiderations need to be given for effective type-supervision.
In addition, significant manual workmight be required to ensure the quality of lexicons.To compare type- and token-supervised tagging,Garrette and Baldridge (2013) performed a set ofexperiments by conducting each type of annota-tion for two hours.
They showed that for low-resource languages, a tag-dictionary can be rea-sonably effective if label propagation (Talukdarand Crammer, 2009) and model minimizations(Ravi and Knight, 2009) are applied to expand andfilter the lexicons.
Similar findings were reportedin Garrette et al.
(2013).Do the above findings carry over to the Chi-nese language?
In this paper, we perform anempirical study on the effects of tag-dictionariesfor domain adaptation of Chinese POS-tagging.We aim to answer the following research ques-tions: (a) Is domain adaptation feasible with onlya target-domain lexicon?
(b) Can we further im-prove type-supervised domain adaptation usingunlabeled target-domain sentences?
(c) Is craft-ing a tag dictionary for domain adaptation moreeffective than manually annotating target domainsentences, given similar efforts?Our investigations are performed under twoChinese-specific settings.
First, unlike low-resource languages, large amounts of annotation588are available for Chinese.
For example, the Chi-nese Treebank (CTB) (Xue et al., 2005) containsover 50,000 manually tagged news sentences.Hence rather than studying purely type-supervisedPOS-tagging, we make use of CTB as the sourcedomain, and study domain adaptation to the Inter-net literature.Second, one uniqueness of Chinese POS-tagging, in contrast to the POS-tagging of alpha-betical languages, is that word segmentation canbe performed jointly to avoid error propagation(Ng and Low, 2004; Zhang and Clark, 2008; Kru-engkrai et al., 2009; Zhang and Clark, 2010).
Weadopt this approach for a strong baseline.
Previousstudies showed that unsupervised domain adap-tation can give moderate improvements (Liu andZhang, 2012).
We show that accuracies can bemuch more significantly improved by using target-domain knowledge in the form of lexicons.Both token-supervised and type-supervised do-main adaptation rely on a set of source-domainannotations; while the former makes additionaluse of a small set of target annotations, the lat-ter leverages a target-domain lexicon.
We takea feature-based method, analogous to that ofDaume III (2007), which tunes domain-dependentversions of features using domain-specific data.Our method tunes a set of lexicon-based features,so that domain-dependent models are derived frominserting domain-specific lexicons.The conceptually simple method worked highlyeffectively on a test set of 1,394 sentences fromthe Internet novel ?Zhuxian?.
Combined withthe use of unlabeled data, a tag lexicon of 3,000words gave a 33% error reduction when com-pared with a strong baseline system trained usingCTB data.
We observe that joint use of type- andtoken-supervised domain adaptation is more cost-effective than pure type- or token-supervision.With 10 hours of annotation, the best error reduc-tion reaches 47%, with F-score increasing from80.81% to 89.84%.2 BaselineWe take as the baseline system a discriminativejoint segmentation and tagging model, proposedby Zhang and Clark (2010), together with simpleself-training (Liu and Zhang, 2012).
While thebaseline discriminative model gives state-of-the-art joint segmentation and tagging accuracies onCTB data, the baseline self-training makes use ofunlabeled target domain data to find improved tar-get domain accuracies over bare CTB training.2.1 The Baseline Discriminative ChinesePOS-Tagging ModelThe baseline discriminative model performssegmentation and POS-tagging simultaneously.Given an input sentence c1?
?
?
cn(cirefers to theith character in the sentence), it operates incre-mentally, from left to right.
At each step, the cur-rent character can either be appended to the lastword of the existing partial output, or seperated asthe start of a new word with tag p. A beam is usedto maintain the N-best partial results at each stepduring decoding.
At step i (0 ?
i < n), eachitem in the beam corresponds to a segmentationand POS-tagging hypothesis for the first i?1 char-acters, with the last word being associated with aPOS, but marked as incomplete.
When the nextcharacter ciis processed, it is combined with allthe partial results from the beam to generate newpartial results, using two types of actions: (1) Ap-pend, which appends cito the last (partial) wordin a partial result; (2) Separate(p), which makesthe last word in the partial result as completed andadds cias a new partial word with a POS tag p.Partial results in the beam are scored globallyover all actions used to build them, so that the N-best can be put back to the agenda for the next step.For each action, features are extracted differently.We use the features from Zhang and Clark (2010).Discriminative learning with early-update (Collinsand Roark, 2004; Zhang and Clark, 2011) is usedto train the model with beam-search.2.2 Baseline Unsupervised Adaptation bySelf-TrainingA simple unsupervised approach for POS-taggingwith unlabeled data is EM.
For a generative modelsuch as HMM, EM can locally maximize the like-lihood of training data.
Given a good start, EMcan result in a competitive HMM tagging model(Goldberg et al., 2008).For discriminative models with source-domaintraining examples, an initial model can be trainedusing the source-domain data, and self-trainingcan be applied to find a locally-optimized modelusing raw target domain sentences.
The trainingprocess is sometimes associated with the EM al-gorithm.
Liu and Zhang (2012) used perplexitiesof character trigrams to order unlabeled sentences,and applied self-training to achieve a 6.3% error589CommonLexiconSourceLexiconSourceCorpusTrainingModelTargetSentencesTargetLexiconCommonLexiconTaggingTaggingResultsTraining TaggingFigure 1: Architecture of our lexicon-based model for domain adaptation.reduction on target-domain data when comparedwith source domain training.
Their method is sim-ple to implement, and we take it as our baseline.3 Type-Supervised Domain AdaptationTo give a formal definition of the domain adap-tation tasks, we denote by Csa set of anno-tated source-domain sentences, Cta set of anno-tated target-domain sentences, and Ltan anno-tated target-domain lexicon.
The form of Ltis alist of target-domain words, each associated witha set of POS tags.
Token-supervised domain adap-tation is the task of making use of Csand Cttoimprove target-domain performances, while type-supervised domain adaptation is to make use of Csand Ltinstead for the same purpose.As described in the introduction, type-supervised domain adaptation is useful whenannotated sentences are absent, but lexicons areavailable.
In addition, it is an interesting questionwhich type of annotation is more cost-effectivewhen neither is available.
We empirically com-pare the two approaches by proposing a novelmethod for type-supervised domain adaptation ofa discriminate tagging model, showing that it canbe a favourable choice in practical situation.In particular, we split Chinese words intodomain-independent and domain-specific cate-gories, and define unlexicalized features fordomain-specific words.
We train lexicalizeddomain-independent and unlexicalized domain-specific features using the source domain anno-tated sentences and a source-domain lexicon, andthen apply the resulting model to the target do-main by replacing the source-domain lexicon witha target domain lexicon.
Combined with unsu-pervised learning with unlabeled target-domainof sentences, the conceptually simple methodworked highly effectively.
Following Garrette andBaldridge (2013), we address practical questionson type-supervised domain adaptation by compar-ison with token-supervised methods under similarhuman annotation efforts.3.1 System ArchitectureOur method is based on the intuition that domain-specific words of certain types (e.g.
proper names)can behave similarly across domains.
For exam-ple, consider the source-domain sentence ???
?|NR (Jiang Zemin) ?
?|AD (afterwards) ?
?|VV (visit) ?
?|NR (Shanghai AutomobilesCorp.)?
and the target-domain sentence ??
?|NR (Biyao) ?
?|AD (afterwards) ?
?|VV(arrive) ??
?|NR (the Bamboo Mountains)?.????
(Jiang Zemin)?
and ???
(Biyao)?
areperson names in the two domains, respectively,whereas ???
(Shanghai Automobiles Corp.)?and ????
(the Bamboo Mountains)?
are loca-tion names in the two domains, respectively.
If thefour words are simply treated as domain-specificnouns, the two sentences both have the pattern??domain-NR?
AD VV ?domain-NR?
?, and hencesource domain training data can be useful in train-ing the distributions of the lexicon-based featuresfor both domains.Further, we assume that the syntax structuresand the usage of function words do not vary sig-nificantly across domains.
For example, verbs, ad-jectives or proper nouns can be different from do-main to domain, but the subject-verb-object sen-tence structure does not change.
In addition, theusage of closed-set function words remains sta-ble across different domains.
In the CTB tagset,closed-set POS tags are the vast majority.
Underthis assumption, we introduce a set of unlexical-ized features into the discriminative model, in or-der to capture the distributions of domain-specificdictionary words.
Unlexicalized features trainedfor source domain words can carry over to the tar-get domain.
The overall architecture of our sys-590Action Lexicon Feature templatesSeparate in-lex(w?1), l(w?1) ?
in-lex(w?1),in-lex(w?1, t?1), l(w?1) ?
in-lex(w?1, t?1)Table 1: Dictionary features of the type-supervised model, where w?1and t?1denote thelast word and POS tag of a partial result, re-spectively; l(w) denotes the length of the wordw; in-lex(w, t) denotes whether the word-tag pair(w, t) is in the lexicon.tem is shown in Figure 1, where lexicons can betreated as ?plugins?
to the model for different do-mains, and one model trained from the source do-main can be applied to many different target do-mains, as long as a lexicon is available.The method can be the most effectivewhen there is a significant amount of domain-independent words in the data, which provide richlexicalized contexts for estimating unlexicalizedfeatures for domain-specific words.
For scientificdomains (e.g.
the biomedical domain) whichshare a significant proportion of common wordswith the news domain, and have most domainspecific words being nouns (e.g.
????
(dia-betes)?
), the method can be the most effective.We choose a comparatively difficult domain pair(e.g.
modern news v.s.
ancient style novel),for which the use of many word types are quitedifferent.
Results on this data can be relativelymore indicative of the usefulness of the method.3.2 Lexicon-Based FeaturesTable 1 shows the set of new unlexicalized fea-tures for the domain-specific lexicons.
In additionto words and POS tags, length information is alsoencoded in the features, to capture different dis-tributions of different word sizes.
For example,a one-character word in the dictionary might notbe identified as confidently using the lexicon as athree-character word in the dictionary.To acquire a domain-specific lexicon for thesource domain, we use HowNet (Dong andDong, 2006) to classify CTB words into domain-independent and domain-specific categories.
Con-sisting of semantic information for nearly 100,000common Chinese words, HowNet can serve as aresource of domain-independent Chinese words.We choose out of all words in the source domaintraining data those that also occur in HowNet fordomain-independent words, and out of the remain-ing words those that occur more than 3 times forwords specific to the source domain.
We assumethat the domain-independent lexicon applies to alltarget domains also.
For some target domains,we can obtain domain-specific terminologies eas-ily from the Internet.
However, this can be a verysmall portion depending on the domain.
Thus, itmay still be necessary to obtain new lexicons bymanual annotation.3.3 Lexicon and Self-TrainingThe lexicon-based features can be combined withunsupervised learning to further improve target-domain accuracies.
We apply self-training on topof the lexicon-based features in the following way:we train a lexicon-based model M using a lexi-con Lsof the source domain, and then apply Mtogether with a target-domain lexicon Ltto auto-matically label a set of target domain sentences.We combine the automatically labeled target sen-tences with the source-domain training data to ob-tain an extended set of training data, and train afinal model Mself, using the lexicon Lsand Ltforsource- and target-domain data, respectively.Different numbers of target domain sentencescan be used for self-training.
Liu and Zhang(2012) showed that an increased amount of tar-get sentences do not constantly lead to improveddevelopment accuracies.
They use character per-plexity to order target domain sentences, takingthe top K sentences for self-training.
They eval-uate the optimal development accuracies using arange of different Kvalues, and select the best Kfor a final model.
This method gave better resultsthan using sentences in the internet novel in theiroriginal order (Liu and Zhang, 2012).
We followthis method in ranking target domain sentences.4 Experiments4.1 SettingWe use annotated sentences from the CTB5 forsource-domain training, splitting the corpus intotraining, development and test sections in the sameway as previous work (Kruengkrai et al., 2009;Zhang and Clark, 2010; Sun, 2011).Following Liu and Zhang (2012), we use thefree Internet novel ?Zhuxian?
(henceforth referredto as ZX; also known as ?Jade dynasty?)
as our tar-get domain data.
The writing style of the novel isin the literature genre, with the style of Ming andQing novels, very different from news in CTB.
Ex-591CTB sentences ZX sentences??????????
??????????????????????
(Qiaoshi meets the Russian delegates.)
(The world was big.
It held everything.
There were fascinating??????????????
landscapes.
There were haunting ghosts.
)(Lipeng stressed on speeding the reform of official regulations.)
????????????????????????????
(No time left.
Let me call out Zhuxian, the ancient sword.
)(Chinese chemistry industry increases the pace of opening up.)
???????????????
(There came suddenlya gust of wind, out of which was laughters and magic flashes.
)Table 2: Example sentences from CTB and ZX to illustrate the differences between news and novel.Data Set Chap.
IDs # sents # wordsCTB5Train 1-270, 400-931, 10,086 493,9301001-1151Devel 301-325 350 6,821Test 271-300 348 8,008ZXTrain 6.6-6.10, 2,373 67,6487.6-7.10, 19Devel 6.1-6.5 788 20,393Test 7.1-7.5 1,394 34,355Table 3: Corpus statistics.ample sentences from the two corpora are shownin Table 2.
Liu and Zhang (2012) manually anno-tated 385 sentences as development and test data,which we download from their website.1Thesedata follow the same annotation guidelines as theChinese Treebank (Xue et al., 2000).To gain more reliable statistics in our results,we extend their annotation work to a total 4,555sentences, covering the sections 6, 7 and 19 of thenovel.
The annotation work is based on the auto-matically labeled sentences by our baseline modeltrained with CTB5 corpus.
It took an experiencednative speaker 80 hours, about one minute on av-erage to annotate one sentence.
We use chapters1-5 of section 6 as the development data, chap-ters 1-5 of section 7 as the test data, and the re-maining data for target-domain training,2in orderto compare type-supervised methods with token-supervised methods.
Under permission from theauthor of the novel, we release our annotation forfuture reference.
Statistics of both the source andthe target domain data are shown in Table 3.
Therest of the novel is treated as unlabeled sentences,used for type-annotation and self-training.We perform the standard evaluation, using F-scores for both the segmentation accuracy and the1http://faculty.sutd.edu.sg/?yue zhang/emnlp12yang.zip2We only use part of the training sentences in our experi-ments, and the remaining can be used for further research.overall segmentation and POS tagging accuracy.4.2 Baseline PerformancesThe baseline discriminative model can achievestate-of-the-art performances on the CTB5, witha 97.62% segmentation accuracy and a 93.85% onoverall segmentation and tagging accuracy.
Usingthe CTB model, the performance on ZX drops sig-nificantly, to a 87.71% segmentation accuracy anda 80.81% overall accuracy.
Applying self-training,the segmentation and overall F-scores can be im-proved to 88.62% and 81.94% respectively.4.3 Development ExperimentsIn this section, we study type-supervised domainadaptation by conducting a series of experimentson the development data, addressing the follow-ing questions.
First, what is the influence of tag-dictionaries through lexicon-based features?
Sec-ond, what is the effect of type-supervised domainadaptation in contrast to token-supervised domainadaptation under the same annotation cost?
Third,what is the interaction between tag-dictionary andself-training?
Finally, what is the combined effectof type- and token-supervised domain adaptation?4.3.1 The Influence of The Tag DictionaryWe investigate the effects of two different tag dic-tionaries.
The first dictionary contains names ofcharacters (e.g.
??
(Guili)) and artifacts (e.g.swords such as??
(Dragonslayer)) in the novel,which are obtained from an Internet Encyclope-dia,3and requires little human effort.
We ex-tracted 159 words from this page, verified them,and put them into a tag dictionary.
We associateevery word in this tag dictionary with the POS?NR (proper noun)?, and name the lexicon by NR.The second dictionary was constructed man-ually, by first employing our baseline tagger totag the unlabeled ZX sentences automatically,3http://baike.baidu.com/view/18277.htm592ModelTarget-DomainCostSupervised +Self-TrainingResources SEG POS SEG POS ERBaseline ?
0 89.77 82.92 90.35 83.95 6.03Type-SupervisionNR(T) 0 89.84 83.91 91.18 85.22 8.143K(T) 5h 91.93 86.53 92.86 87.67 8.46ORACLE(T) ?
93.10 88.87 94.00 89.91 9.34Token-Supervision300(S) 5h 92.59 86.86 93.33 87.85 7.53600(S) 10h 93.19 88.13 93.81 89.01 7.41900(S) 15h 93.53 88.53 94.15 89.33 6.97Combined 3K(T) + 300(S) 10h 93.49 88.54 94.00 89.21 5.85Type- and Token-Supervision 3K(T) + 600(S) 15h 93.98 89.27 94.61 89.87 5.59Table 4: Development test results, where Cost denotes the cost of type- or token-annotation measuredby person hours, ER denotes the error reductions of overall performances brought by self-training, Tdenotes type-annotation and S denotes token-annotation.and then randomly selecting the words that arenot domain-independent for an experienced nativespeaker to annotate.
To facilitate comparison withtoken-supervision, we spent about 5 person hoursin annotating 3,000 word-tag pairs, at about thesame cost as annotating 300 sentences.
Finally weconjoined the 3,000 word-tag pairs with the NRlexicon, and name the resulting lexicon by 3K.For the target domain, we mark the words fromboth NR and 3K as the domain-specific lexicons.In all experiments, we use the same domain-independent lexicon, which is extracted from thesource domain training data by HowNet matching.The accuracies are shown in Table 4, wherethe NR lexicon improved the overall F-scoreslightly over the baseline, and the larger lexicon3K brought more significant improvements.
Theseexperiments agree with the intuition that the sizeand the coverage of the tag dictionary is impor-tant to the accuracies.
To understand the extent towhich a lexicon can improve the accuracies, weperform an oracle test, in which lexicons in thegold-standard test outputs are included in the dic-tionary.
The accuracy is 88.87%.4.3.2 Comparing Type-Supervised andToken-Supervised Domain AdaptationTable 4 shows that the accuracy improvement by3,000 annotated word-tag pairs (86.53%) is closeto that by 300 annotated sentences (86.86%).
Thissuggest that using our method, type-superviseddomain adaptation can be a competitive choice tothe token-supervised methods.The fact that the token-supervised model givesslightly better results than our type-annotationmethod under similar efforts can probably be ex-0.6 0.7 0.8 0.9 10.60.70.80.91Token-Supervision with 300(S)Type-Supervisionwith3K(T)Figure 2: Sentence accuracy comparisons fortype- and token-supervision with equal cost.plained by the nature of domain differences.
Textsin the Internet novel are different with CTB newsin not only the vocabulary, but also POS n-gramdistributions.
The latter cannot be transferred fromthe source-domain training data directly.
Textsfrom domains such as modern-style novels andscientific articles might have more similar POSdistributions to the CTB data, and can potentiallybenefit more from pure lexicons.
We leave the ver-ification of this intuition to future work.4.3.3 Making Use of Unlabeled SentencesBoth type- and token-supervised domain adapta-tion methods can be further improved via unla-beled target sentences.
We apply self-training toboth methods, and find improved results across theboard in Table 4.
The results indicate that unla-beled data is useful in further improving both type-and token-supervised domain adaptation.593Interestingly, the effects of the two methodson self-training are slightly different.
The er-ror reduction by self-training improves from 6.0%(baseline) to averaged 7.3% and 8.6% for token-and type-supervised adaptation, respectively.
Thebetter effect for the type-supervised method mayresult from comparatively more uniform cover-age of the lexicon on sentences, since the target-domain lexicon is annotated by selecting wordsfrom much more than 300 sentences.4.3.4 Combined Model of Type- andToken-SupervisionFigure 2 shows the F-scores of each developmenttest sentence by type- and token-supervised do-main adaptation with 5 person hours, respectively.It indicates that the two methods make differenttypes of errors, and can potentially be used jointlyfor better improvements.
We conduct a set of ex-periments as shown in Table 4, finding that thecombined type- and token-supervised model withlexicon 3K and 300 labeled sentences achievesan overall accuracy of 88.54%, exceeding the ac-curacies of both the type-supervised model withlexicon 3K and the token-supervised model with300 labeled sentences.
Similar observation canbe found for the combined model with lexicon 3Kand 600 labeled sentences.
If combined with self-training, the same fact can be observed.More interestingly, the combined model alsoexceeds pure type- and token-supervised mod-els with the same annotation cost.
For exam-ple, the combined model with 3K and 300 la-beled sentences gives a better accuracy than thetoken-supervised model with 600 sentences, withor without self-training.
Similar observations holdbetween the combined model with 3K and 600 la-beled sentences and the token-supervised modelwith 900 sentences.
The results suggest that themost cost-effective approach for domain adapta-tion can be combined type- and token-supervision:after annotating a set of raw sentences, one couldstop to annotate some words, rather than continu-ing sentence annotation.4.4 Final ResultsTable 5 shows the final results on test corpuswithin ten person hours?
annotation.
With five per-son hours (lexicon 3K), the type-supervised modelgave an error reduction of 32.99% compared withthe baseline.
The best result was obtained by thecombined type- and token-supervised model, withSEG POS ER TimeBaseline 87.71 80.81 0.00 0Baseline+Self-Training 88.62 81.94 5.89 0Type-SupervisionNR(T) 88.34 82.54 9.02 0NR(T)+ Self-Training 89.52 83.93 16.26 03K(T) 91.11 86.04 27.25 5h3K(T)+Self-Training 92.11 87.14 32.99 5hToken-Supervision300(S) 92.44 86.87 31.58 5h300(S)+Self-Training 93.24 87.48 34.76 5h600(S) 93.09 88.05 37.73 10h600(S)+Self-Training 93.77 88.78 41.53 10hCombined Type- and Token-Supervision3K(T)+300(S) 93.27 89.03 42.83 10h3K(T)+300(S)+Self-Training 93.98 89.84 47.06 10hTable 5: Final results on test set within ten per-son hours?
annotation, where ER denotes the over-all error reductions compared with the baselinemodel, Time denotes the cost of type- or token-annotation measured by person hours, T denotestype-annotation and S denotes token-annotation.an error reduction of 47.06%, higher than that thetoken-supervised model with the same cost underthe same setting (the model of 600 labeled sen-tences with an error reduction of 41.53%).
Theresults confirm that the type-supervised modelis a competitive alternative for joint segmenta-tion and POS-tagging under the cross-domain set-ting.
Combined type- and token-supervised modelyields better results than single models.5 Related WorkAs mentioned in the introduction, tag dictionarieshave been applied to type-supervised POS taggingof English (Toutanova and Johnson, 2007; Gold-water and Griffiths, 2007; Ravi and Knight, 2009;Garrette and Baldridge, 2012), Hebrew (Goldberget al., 2008), Kinyarwanda and Malagasy (Gar-rette and Baldridge, 2013; Garrette et al., 2013),and other languages (T?ackstr?om et al., 2013).These methods assume that lexicon can be ob-tained by manual annotation or semi-supervisedlearning, and use the lexicon to induce tag se-quences on unlabeled sentences.
We study type-supervised Chinese POS-tagging, but under thesetting of domain adaptation.
The problem ishow to leverage a target domain lexicon and anavailable annotated resources in a different sourcedomain to improving POS-tagging.
Consistent594with Garrette et al.
(2013), we also find that thetype-supervised method is a competitive choice totoken-supervised adaptation.There has been a line of work on using graph-based label propagation to expand tag-lexicons forPOS-tagging (Subramanya et al., 2010; Das andPetrov, 2011).
Similar methods have been ap-plied to character-level Chinese tagging (Zeng etal., 2013).
We found that label propagation fromneither the source domain nor auto-labeled targetdomain sentences can improve domain adaptation.The main reason could be significant domain dif-ferences.
Due to space limitations, we omit thisnegative result in our experiments.With respect to domain adaptation, existingmethods can be classified into three categories.The first category does not explicitly model dif-ferences between the source and target domains,but use standard semi-supervised learning meth-ods with labeled source domain data and unla-beled target domain data (Dai et al., 2007; Rainaet al., 2007).
The baseline self-training ap-proach (Liu and Zhang, 2012) belongs to this cat-egory.
The second considers the differences in thetwo domains in terms of features (Blitzer et al.,2006; Daume III, 2007), classifying features intodomain-independent source domain and target do-main groups and training these types consistently.The third considers differences between the dis-tributions of instances in the two domains, treat-ing them differently (Jiang and Zhai, 2007).
Ourtype-supervised method is closer to the second cat-egory.
However, rather than splitting features intodomain-independent and domain-specific types,we use domain-specific dictionaries to capture do-main differences, and train a model on the sourcedomain only.
Our method can be treated as an ap-proach specific to the POS-tagging task.With respect to Chinese lexical analysis, lit-tle previous work has been reported on using atag dictionary to improve joint segmentation andPOS-tagging.
There has been work on using alexicon in improving segmentation in a Chineseanalysis pipeline.
Peng et al.
(2004) used fea-tures from a set of Chinese words and charactersto improve CRF-based segmentation; Low et al.
(2005) extracted features based on a Chinese lex-icon from Peking University to help a maximumsegmentor; Sun (2011) collected 12,992 idiomsfrom Chinese dictionaries, and used them for rule-based pre-segmentation; Hatori et al.
(2012) col-lected Chinese words from HowNet and the Chi-nese Wikipedia to enhance segmentation accura-cies of their joint dependency parsing systems.
Incomparison with their work, our lexicon containadditional POS information, and are used for wordsegmentation and POS-tagging simultaneously.
Inaddition, we separate domain-dependent lexiconsfor the source and target lexicons, and use a novelframework to perform domain adaptation.Wang et al.
(2011) collect word-tag statisticsfrom automatically labeled texts, and use them asfeatures to improve POS-tagging.
Their word-tagstatistics can be treated as a type of lexicon.
How-ever, their efforts differ from ours in several as-pects: (1) they focus on in-domain POS-tagging,while our concern is cross-domain tagging; (2)they study POS-tagging on segmented sentences,while we investigate joint segmentation and POS-tagging for Chinese; (3) their tag-dictionaries arenot tag-dictionaries literally, but statistics of word-tag associations.6 ConclusionsWe performed an empirical study on the use oftag-dictionaries for the domain adaptation of jointChinese segmentation and POS-tagging, showingthat type-supervised methods can be a compet-itive alternative to token-supervised methodsin cost-effectiveness.
In addition, combinationof the two methods gives the best cost-effect.Finally, we release our annotation of over 4,000sentences in the Internet literature domain on-line at http://faculty.sutd.edu.sg/?yue_zhang/eacl14meishan.zip as afree resource for Chinese POS-tagging.AcknowledgmentsWe thank the anonymous reviewers for their con-structive comments.
We gratefully acknowl-edge the support of the National Key BasicResearch Program (973 Program) of China viaGrant 2014CB340503 and the National NaturalScience Foundation of China (NSFC) via Grant61133012 and 61370164, the National Basic Re-search Program (973 Program) of China via Grant2014CB340503, the Singaporean Ministration ofEducation Tier 2 grant T2MOE201301 and SRGISTD 2012 038 from Singapore University ofTechnology and Design.595ReferencesMichele Banko and Robert C. Moore.
2004.
Part-of-speech tagging in context.
In COLING.John Blitzer, Ryan McDonald, and Fernando Pereira.2006.
Domain adaptation with structural correspon-dence learning.
In Proceedings of the 2006 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 120?128, Sydney, Australia, July.Association for Computational Linguistics.Christos Christodoulopoulos, Sharon Goldwater, andMark Steedman.
2010.
Two decades of unsu-pervised POS induction: How far have we come?In Proceedings of the 2010 Conference on Empiri-cal Methods in Natural Language Processing, pages575?584, Cambridge, MA, October.
Association forComputational Linguistics.Michael Collins and Brian Roark.
2004.
Incremen-tal parsing with the perceptron algorithm.
In Pro-ceedings of the 42nd Meeting of the Association forComputational Linguistics (ACL?04), Main Volume,pages 111?118, Barcelona, Spain, July.Wenyuan Dai, Gui-Rong Xue, Qiang Yang, and YongYu.
2007.
Transferring Naive Bayes Classifiers forText Classification.
In AAAI, pages 540?545.Dipanjan Das and Slav Petrov.
2011.
Unsuper-vised part-of-speech tagging with bilingual graph-based projections.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies, pages600?609, Portland, Oregon, USA, June.
Associationfor Computational Linguistics.Hal Daume III.
2007.
Frustratingly easy domain adap-tation.
In Proceedings of the 45th Annual Meeting ofthe Association of Computational Linguistics, pages256?263, Prague, Czech Republic, June.
Associa-tion for Computational Linguistics.Zhendong Dong and Qiang Dong.
2006.
Hownet Andthe Computation of Meaning.
World Scientific Pub-lishing Co., Inc., River Edge, NJ, USA.Dan Garrette and Jason Baldridge.
2012.
Type-supervised hidden markov models for part-of-speechtagging with incomplete tag dictionaries.
InEMNLP-CoNLL, pages 821?831.Dan Garrette and Jason Baldridge.
2013.
Learning apart-of-speech tagger from two hours of annotation.In Proceedings of the 2013 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,pages 138?147, Atlanta, Georgia, June.
Associationfor Computational Linguistics.Dan Garrette, Jason Mielens, and Jason Baldridge.2013.
Real-world semi-supervised learning of pos-taggers for low-resource languages.
In Proceed-ings of the 51st Annual Meeting of the Associationfor Computational Linguistics (Volume 1: Long Pa-pers), pages 583?592, Sofia, Bulgaria, August.
As-sociation for Computational Linguistics.Yoav Goldberg, Meni Adler, and Michael Elhadad.2008.
EM can find pretty good HMM POS-taggers(when given a good start).
In Proceedings of ACL-08: HLT, pages 746?754, Columbus, Ohio, June.Association for Computational Linguistics.Sharon Goldwater and Tom Griffiths.
2007.
A fullybayesian approach to unsupervised part-of-speechtagging.
In Proceedings of the 45th Annual Meet-ing of the Association of Computational Linguistics,pages 744?751, Prague, Czech Republic, June.
As-sociation for Computational Linguistics.Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, andJun?ichi Tsujii.
2012.
Incremental joint approachto word segmentation, pos tagging, and dependencyparsing in chinese.
In Proceedings of the 50th An-nual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers), pages 1045?1053, Jeju Island, Korea, July.
Association for Com-putational Linguistics.Canasai Kruengkrai, Kiyotaka Uchimoto, Jun?ichiKazama, Yiou Wang, Kentaro Torisawa, and HitoshiIsahara.
2009.
An error-driven word-character hy-brid model for joint chinese word segmentation andpos tagging.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL and the4th International Joint Conference on Natural Lan-guage Processing of the AFNLP, pages 513?521,Suntec, Singapore, August.
Association for Compu-tational Linguistics.Yang Liu and Yue Zhang.
2012.
Unsupervised domainadaptation for joint segmentation and POS-tagging.In Proceedings of COLING 2012: Posters, pages745?754, Mumbai, India, December.
The COLING2012 Organizing Committee.Jin Kiat Low, Hwee Tou Ng, and Wenyuan Guo.
2005.A maximum entropy approach to chinese word seg-mentation.
In Proceedings of the Fourth SIGHANWorkshop on Chinese Language Processing, pages161?164.Christopher D. Manning.
2011.
Part-of-speech tag-ging from 97% to 100%: is it time for some linguis-tics?
In Proceeding of CICLing?11.Bernard Merialdo.
1994.
Tagging english text witha probabilistic model.
Computational Linguistics,20(2).Hwee Tou Ng and Jin Kiat Low.
2004.
Chinese part-of-speech tagging: One-at-a-time or all-at-once?word-based or character-based?
In Dekang Lin andDekai Wu, editors, Proceedings of EMNLP 2004,pages 277?284, Barcelona, Spain, July.
Associationfor Computational Linguistics.596Fuchun Peng, Fangfang Feng, and Andrew McCallum.2004.
Chinese segmentation and new word detec-tion using conditional random fields.
In Proceedingsof Coling 2004, pages 562?568, Geneva, Switzer-land, Aug 23?Aug 27.
COLING.Slav Petrov, Dipanjan Das, and Ryan McDonald.
2012.A universal part-of-speech tagset.
In Proceedings ofLREC, May.Rajat Raina, Alexis Battle, Honglak Lee, BenjaminPacker, and Andrew Y. Ng.
2007.
Self-taught learn-ing: transfer learning from unlabeled data.
In ICML,pages 759?766.Sujith Ravi and Kevin Knight.
2009.
Minimizedmodels for unsupervised part-of-speech tagging.
InACL/IJCNLP, pages 504?512.Amarnag Subramanya, Slav Petrov, and FernandoPereira.
2010.
Efficient graph-based semi-supervised learning of structured tagging models.In Proceedings of the 2010 Conference on Empiri-cal Methods in Natural Language Processing, pages167?176, Cambridge, MA, October.
Association forComputational Linguistics.Weiwei Sun.
2011.
A stacked sub-word model forjoint chinese word segmentation and part-of-speechtagging.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguis-tics: Human Language Technologies, pages 1385?1394, Portland, Oregon, USA, June.
Association forComputational Linguistics.Oscar T?ackstr?om, Dipanjan Das, Slav Petrov, McDon-ald Ryan, and Joakim Nivre.
2013.
Token and typeconstraints for cross-lingual part-of-speech tagging.In Transactions of the ACL.
Association for Compu-tational Linguistics, March.Partha Pratim Talukdar and Koby Crammer.
2009.New regularized algorithms for transductive learn-ing.
In ECML/PKDD (2), pages 442?457.Kristina Toutanova and Mark Johnson.
2007.
Abayesian lda-based model for semi-supervised part-of-speech tagging.
In NIPS.Yiou Wang, Jun?ichi Kazama, Yoshimasa Tsuruoka,Wenliang Chen, Yujie Zhang, and Kentaro Tori-sawa.
2011.
Improving chinese word segmentationand pos tagging with semi-supervised methods usinglarge auto-analyzed data.
In Proceedings of 5th In-ternational Joint Conference on Natural LanguageProcessing, pages 309?317, Chiang Mai, Thailand,November.
Asian Federation of Natural LanguageProcessing.Nianwen Xue, Fei Xia, Shizhe Huang, and Tony Kroch.2000.
The bracketing guidelines for the chinesetreebank.
Technical report, University of Pennsyl-vania.Nianwen Xue, Fei Xia, Fu-Dong Chiou, and MarthaPalmer.
2005.
The penn chinese treebank: Phrasestructure annotation of a large corpus.
Natural Lan-guage Engineering, 11(2):207?238.Xiaodong Zeng, Derek F. Wong, Lidia S. Chao, and Is-abel Trancoso.
2013.
Graph-based semi-supervisedmodel for joint chinese word segmentation and part-of-speech tagging.
In Proceedings of the 51st An-nual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers), pages 770?779, Sofia, Bulgaria, August.
Association for Com-putational Linguistics.Yue Zhang and Stephen Clark.
2008.
Joint word seg-mentation and POS tagging using a single percep-tron.
In Proceedings of ACL-08: HLT, pages 888?896, Columbus, Ohio, June.
Association for Com-putational Linguistics.Yue Zhang and Stephen Clark.
2010.
A fast decoderfor joint word segmentation and POS-tagging usinga single discriminative model.
In Proceedings of the2010 Conference on Empirical Methods in NaturalLanguage Processing, pages 843?852, Cambridge,MA, October.
Association for Computational Lin-guistics.Yue Zhang and Stephen Clark.
2011.
Syntactic pro-cessing using the generalized perceptron and beamsearch.
Computational Linguistics, 37(1):105?151.597
