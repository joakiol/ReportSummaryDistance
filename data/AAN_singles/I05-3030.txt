Chinese Word Segmentation based on Mixing ModelWei Jiang          Jian Zhao          Yi Guan          Zhiming XuITNLP, Harbin Institute of Technology,  Heilongjiang Province, 150001 Chinajiangwei@insun.hit.edu.cnAbstractThis paper presents our recent work forparticipation in the Second Interna-tional Chinese Word SegmentationBakeoff.
According to difficulties, wedivide word segmentation into severalsub-tasks, which are solved by mixedlanguage models, so as to take advan-tage of each approach in addressingspecial problems.
The experiment indi-cated that this system achieved 96.7%and 97.2% in F-measure in PKU andMSR open test respectively.1 IntroductionWord is a logical semantic and syntactic unit innatural language.
So word segmentation is thefoundation of most Chinese NLP tasks.
Thoughmuch progress has been made in the last twodecades, there is no existing model that cansolve all the problems perfectly at present.
Sowe try to apply different language models tosolve each special sub-task, due to ?No FreeLunch Theorem?
and ?Ugly Duckling Theorem?.Our system participated in the Second Inter-national Chinese Word Segmentation Bakeoff(henceforce, the bakeoff) held in 2005.
Recently,we have done more work in dealing with threemain sub-tasks: (1) Segmentation disambigua-tion; (2) Named entities recognition; (3) Newwords1 detection.
We apply different approachsto solve above three problems, and all the mod-ules are integrated into a pragmatic system(ELUS).
Due to the limitation of available re-source, some kinds of features, e.g.
POS, havebeen erased in our participation system.
Thissegmenter will be briefly describled in this paper.1 New words refer to this kind of out-of ?vocabulary wordsthat are neither recognized named entities or factoid wordsnor morphological words.2 ELUS SegmenterAll the words are categorized into five types:Lexicon words (LW), Factoid words (FT), Mor-phologically derived words (MDW), Namedentities (NE), and New words (NW).
Accord-ingly, four main modules are included to iden-tify each kind of words, as shown in Figure 1.Class-based trigram model (Gao 2004) isadopted in the Basic Segmentation to convertthe sentence into a word sequence.
Let w = w1w2 ?wn be a word class sequence, then the mostlikely word class sequence w* in trigram is:?niiiiwwwwwwPn 112 )|(maxarg*21 w ,where let P(w0|w-2 w-1) be P(w0) and letP(w1|w-1 w0) be P(w1|w0).
And wi represents LWor a type of FT or MDW.
Viterbi algorithm isused to search the best candidate.
Absolutesmoothing algorithm is applied to overcome thedata sparseness.
Here, LW, FT and MDW areidendified (Zhao Yan 2005).
All the Factoidwords can be represented as regular expressions.As a result, the detection of factoid words can bearchieved by Finite State Machines.Figure 1 ELUS SegmenterFactoid DetectMorphology WordLexicon wordsStringResultNE RecognizationSentenceBasic SegmentationNW DetectionDisambiguation180Four kinds of Named entities are detected, i.e.Chinese person name, foreign person name, lo-cation name and orgnization name.
This is themost complicated module in ELUS.Three kinds of models are applied here.HMM model (one order) is described as:?niiiiiTTTTTPTWPn 11# )|()|(maxarg21 T ,where iT  represents the tag of current word,Viterbi algorithm is used to search the best path.Another model is Maximum Entropy (Zhao Jian2005, Hai Leong Chieu 2002).
Take Chineseperson name as example.
Firstly, we combineHMM and Maximum Entropy (ME) model tolable the person name tag, e.g.
?
?/CPB ?/CPI?/CPI?
(Tongmei Yao); Secondly, the taggedname is merged by combining ME Model andSupport Vector Machine (SVM) and some aidedrules, e.g.
merged into ??/???
in PKU test.Some complex features are added into MEmodel (described in Zhao Jian 2005), in addition,we also collect more than 110,000 person names,and acquire the statistic about common namecharacters, these kinds of features are also fusedinto the ME model to detect NE.
The other kindsof NE recognition adopt similar method, exceptfor individual features.New Words is another important kind ofOOV words, especially in closed test.
Take PKUtest as example, we collect NW suffixes, such as???(city),???(lamp).
Those usually constructnew words, e.g.
?????
(sighting lamp).A variance-based method is used to collectsuffixes.
And three points need to be consid-ered:(1) It is tail of many words;(2) It has largevariance in constructing word;(3) It is seldomused alone.
We acquire about 25 common suf-fixes in PKU training corpus by above method.We use Local Maximum Entropy model, e.g.???
/1 ?
/1?
(Huanggang city), i.e.
only thenearer characters are judged before the suffix???
(city).
By our approach, the training corpuscan be generated via given PKU corpus in thebakeoff.
The features come from the nearer con-text, besides, common single words and punc-tuations are not regarded as a part of New Word.The last module is Word Disambiugation.Word segmentation ambiguities are usually clas-sified into two classes: overlapping ambiguityand combination ambiguity.
By evaluatingELUS, the most segmentation errors are onesegmentation errors (about 95%).
i.e.
the twowords on both sides of current segmentationerrors are right.
These include LW ambiguitiesand FT ambiguities etc.
Here, we adopt Maxi-mum Entropy model.
The same as other mod-ules, it is defined over HhT in segmentationdisambiguation, where H is the set of possiblecontexts around target word that will be tagged,and T is the set of allowable tags.
Then themodel?s conditional probability is defined as?
?
Tt thpthphtp')',(),()|(, where?kjthfjjthp1),(),( DSPwhere h is current context and t is one of thepossible tags.
The ambiguous words are mainlycollected by evaluating our system.In NE module and Word Disambiguationmodule, we introduce rough rule features, whichare extracted by Rough Set (Wang Xiaolong2004), e.g.
???????
(display ability), ?????/??(only?
can just), ???+person+???
(the reporter+person+report).
Previous ex-periment had indicated word disambiguationcould achieve better performance by applyingRough Set.3 Performance and analysisThe performance of ELUS in the bakeoff is pre-sented in Table 1 and Table 2 respectively, interms of recall(R), precision(P) and F score inpercentages.Table 1 Closed test, in percentages (%)Closed R P F OOV Roov RivPKU 95.4 92.7 94.1 5.8 51.8 98.1MSR 97.3 94.5 95.9 2.6 32.3 99.1CITYU 93.4 86.5 89.8 7.4 24.8 98.9AS 94.3 89.5 91.8 4.3 13.7 97.9Table 2 Open test, in percentages (%)Open R P F OOV Roov RivPKU 96.8 96.6 96.7 5.8 82.6 97.7MSR 98.0 96.5 97.2 2.6 59.0 99.0CITYU 94.6 89.8 92.2 7.4 41.7 98.9AS 95.2 92.0 93.6 4.3 35.4 97.9Our system has good performance in termsof F-measure in simplified Chinese open test,including PKU and MSR open test.
In addition,181its IV word identification performance is re-markable, ranging from 97.7% to 99.1%, standsat the top or nearer the top in all the tests inwhich we have participated.
This good perform-ance owes to class-based trigram, absolutesmoothing and word disambiguation module andrough rules.There is almost the same IV performance be-tween open test and closed test in MSR, CITYUand AS respectively, because we adopt the sameLexicon between open test and closed test re-spectively.
While in open test of PKU, we adoptanother Lexicon that comes from six-monthcorpora of Peoples?
Daily (China) in 1998,which were also annotated by Peking University.The OOV word identification performanceseems uneven, compared with PKU, the othertests seem lower, due to the following reasons:(1) Because of our resource limitation, NEtraining resource is six-month corpora of Peo-ples?
Daily (China) in 1998, which came fromPeking University, and some newspapers andweb pages annotated by our laboratory;(2) We have no traditional Chinese corpus,so the NE training resource for CITYU and ASis acquired via converting above corpora.
Sincethese corpora are converted from simplifiedChinese, they are not well suitable to traditionalChinese corpora;(3) The different corpora have different crite-rions in NE detection, especially in locationname and organization name, e.g.
????/??/???
(Cuicun Town Xiangtang Hogpen) inPKU and ?????????
in MSR criterion.Even if our system recognizes the ????/?/?/???
as a orgnization name, we are not eas-ily to regard ???
?
as one word in PKU,since ????
isn?t a lexical word.
However inMSR, that is easy, because its criterion regardthe whole Orgnization as a word;(4) We need do more to comply with thesegmentation criterion, e.g.
?????
(outlier) inCITYU come from ????
+ ??
?, while thiskind of false segment is due to our bad under-standing to CITYU criterion.Though there are above problems, our sys-tem does well in regonization precision, sincewe adopt two steps in recognizing NE, especialin recognizing Chinese person name.
And fromthe result of evalution in the bakeoff, we need toimprove the NE recall in the future.In order to make our New words complywith the criterion, we conservatively use NewWord Detection module, in order to avoid hav-ing bad recognition result, since each corpus hasits own New Word criterion.4 Conclusion and Future workWe have briefly describled our system based onmixed models.
Different approachs are adoptedto solve each special sub-task, since there is ?NoFree Lunch Theorem?.
And mixed models areused in NE detection.
This sytem has a goodperformance in the simplified Chinese in thebakeoff.The future work is mainly concentrating ontwo directions: finding effective features anddelicately adjusting internal relations amongdifferent modules, in order to improve segmen-tation performance.ReferencesFu Fuohong.
2000.
Research on Statistical Methodsof Chinese Syntactic Disambiguation.
Ph.D. The-sis.
Harbin Institute of Technology, China.Hai Leong Chieu, Hwee Tou Ng.
Named Entity.Recognition: A Maximum Entropy Approach Us-ing Global.
Information.
Proceedings of the 19thInternational Conference.
on Computational Lin-guistics, 2002.Hua-Ping Zhang, Qun Liu etc.
2003.
Chinese LexicalAnalysis Using Hierarchical Hidden MarkovModel, Second SIGHAN workshop affiliated with4th ACL, Sapporo Japan, pp.63-70, July 2003.Jianfeng Gao, Mu Li et al 2004.
Chinese WordSegmentation: A Pragmatic Approach.
MSR-TR-2004-123, November 2004.Wang Xiaolong, Chen Qingcai, and Daniel S.Yeung.2004.
Mining PinYin-to-Character ConversionRules From Large-Scale Corpus: A Rough Set Ap-proach, IEEE TRANSACTION ON SYSTEMS,MAN.
AND CYBERNETICS-PARTB:CYBERNETICS.
VOL.
34, NO.2, APRIL.Zhao Jian, Wang Xiao-long et al 2005.
ComparingFeatures Combination with Features Fusion inChinese Named Entity Recognition.
ComputerApplication.
China.Zhao Yan.
2005.
Research on Chinese MorphemeAnalysis Based on Statistic Language Model.Ph.D.
Thesis.
Harbin Institute of Technology,China.182
