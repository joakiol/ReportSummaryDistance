Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 1?9,Gothenburg, Sweden, 26-27 April 2014.c?2014 Association for Computational LinguisticsBreaking Bad: Extraction of Verb-Particle Constructionsfrom a Parallel Subtitles CorpusAaron SmithDepartment of Linguistics and PhilologyUppsala UniversityBox 635, 75126 Uppsala, Swedenaaron.smith.4159@student.uu.seAbstractThe automatic extraction of verb-particleconstructions (VPCs) is of particular inter-est to the NLP community.
Previous stud-ies have shown that word alignment meth-ods can be used with parallel corpora tosuccessfully extract a range of multi-wordexpressions (MWEs).
In this paper thetechnique is applied to a new type of cor-pus, made up of a collection of subtitles ofmovies and television series, which is par-allel in English and Spanish.
Building onprevious research, it is shown that a preci-sion level of 94?
4.7% can be achieved inEnglish VPC extraction.
This high levelof precision is achieved despite the dif-ficulties of aligning and tagging subtitlesdata.
Moreover, many of the extractedVPCs are not present in online lexical re-sources, highlighting the benefits of usingthis unique corpus type, which contains alarge number of slang and other informalexpressions.
An added benefit of usingthe word alignment process is that trans-lations are also automatically extracted foreach VPC.
A precision rate of 75?8.5% isfound for the translations of English VPCsinto Spanish.
This study thus shows thatVPCs are a particularly good subset ofthe MWE spectrum to attack using wordalignment methods, and that subtitles dataprovide a range of interesting expressionsthat do not exist in other corpus types.1 IntroductionIn this paper, a method for the automatic extrac-tion of English verb-particle constructions (VPCs)from parallel corpora is described and assessed.The method builds on previous research, partic-ularly that of Caseli et al.
(2010), adapting theirapproach specifically to VPC extraction and ap-plying it to a different kind of corpus, based onsubtitles from popular movies and television se-ries, which is parallel in English and Spanish.
Theuse of a parallel corpus also allows translations ofVPCs to be obtained; an evaluation of the successrate of this process is also presented.The paper is structured in the following man-ner: Section 2 discusses previous research and in-troduces key terminology, Section 3 describes thecorpus and details the methodology and Section 4explains the evaluation process.
Results are thenpresented in Section 5, before discussion and fu-ture work in Section 6, and finally conclusions inSection 7.2 BackgroundAmongst the many factors that contribute to thedifficulty faced by NLP systems in processingmulti-word expressions (MWEs), their sheer mul-tifariousness is surely one of the most challenging.MWEs are combinations of simplex words thatdisplay idiosyncrasies in their syntax, semantics,or frequency (Caseli et al., 2010; Kim and Bald-win, 2010).
They include nominal compoundssuch as distance learning, phrasal verbs such asloosen up and rely on, idioms such as we?ll crossthat bridge when we come to it and collocationssuch as salt and pepper, as well as instances whichcannot so easily be classified such as by the by andad hoc (Copestake et al., 2010).
Due to their di-verse and often non-compositional nature, MWEsconstitute a big problem in many NLP tasks, frompart-of-speech (PoS) tagging to parsing to ma-chine translation (Chatterjee and Balyan, 2011,Constant et al., 2013).In this paper the focus is on VPCs, a subset ofphrasal verbs consisting of a verb and a particle,which, according to Villavicencio (2005), can beeither prepositional, as in hold on, adverbial, as inback away, adjectival, as in cut short, or verbal, as1in let be.
The definitions of phrasal verbs, VPCsand prepositional verbs are often confusing, withseveral competing terminologies.
Greenbaum andQuirk (1990), for example, use a different systemthan that defined here: they use the term multi-word verbs where this study uses phrasal verbs,and phrasal verbs for those which are called VPCshere.
In their system phrasal verbs are thus, alongwith prepositional verbs, a subset of multi-wordverbs.
The confusion between the different cate-gories is often heightened by the fact that VPCsand prepositional verbs can be tricky to distin-guish.
The terminology used in this paper followsthat of Villavicencio (2005): VPCs and preposi-tional verbs are a subset of the broader category ofphrasal verbs.The two most fundamental MWE-related tasksin NLP can be classified as identification and ex-traction.
Identification, in the context of VPCs, isdescribed in Kim and Baldwin (2010) as ?the de-tection of individual VPC token instances in cor-pus data?, while in extraction ?the objective is toarrive at an inventory of VPCs types/lexical itemsbased on analysis of token instances in corpusdata?.
These tasks have relevance in different ap-plications: identification is important in any formof text processing, whereas extraction is importantfor the creation of lexical resources and for textgeneration.
Note that there is also a strong linkbetween the two: lexical resources listing MWEscan naturally be used to identify their instances ina text.In the present study the focus lies on VPC ex-traction: the goal is ultimately to create a list ofvalid VPCs.
It is not the case that every verb canbe combined with every possible particle ?
thiswould make our lives a lot easier (though per-haps less interesting).
Villavicencio (2005) dis-cusses the availability of VPCs in various lexi-cal resources, including dictionaries, corpora, andthe internet.
She finds 3156 distinct VPCs acrossthree electronic dictionaries, and extends that to-tal to 9745 via automatic extraction from BritishNational Corpus.
She goes on to use the seman-tic classification of verbs defined by Levin (1993)to create lists of candidate VPCs based on theirsemantic properties, before using the internet as agigantic corpus to attest them.
The conclusion isthat semantic classes are a good predictor of verbs?VPC productivity.The current study owes a large debt to the workof Caseli et al.
(2010).
They proposed a methodfor identifying MWEs in bilingual corpora as aby-product of the word alignment process.
More-over, their method was able to extract possibletranslations for the MWEs in question, thus pro-viding an efficient way to improve the coverageof bilingual lexical resources.
Zarriess and Kuhn(2009) had previously argued that MWE patternscould be identified from one-to-many alignmentsin bilingual corpora in conjunction with syntac-tic filters.
Caseli et al.
(2010) draw on a previousstudy by Villada Moir?on and Tiedemann (2006),who extract MWE candidates using associationmeasures and head dependence heuristics beforeusing alignment for ranking purposes.An interesting variation on the word alignmentextraction method was investigated by Liu (2011),who in fact use a monolingual corpus along withtechniques designed for bilingual word alignment.They create a replica of the monolingual corpus,and align each sentence to its exact copy.
Theythen adapt a word alignment algorithm (specifi-cally IBM model 3), adding the constraint that aword cannot be aligned to its copy in the paral-lel corpus.
This facilitates the extraction of col-locations, and the authors show that their methodelicits significant gains in both precision and re-call over its competitors.
A more recent attemptto use parallel corpora in the extraction of MWEswas made by Pichotta and DeNero (2013).
Theyfocused on English phrasal verbs, and devised amethod of combining information from transla-tions into many languages.
They conclude that us-ing information from multiple languages providesthe most effective overall system.A key finding of Caseli et al.
(2010) was thattheir method achieved its highest levels of preci-sion for phrasal verbs.
For this reason the presentstudy will focus specifically on VPCs, in a sensenarrowing the previous study to focus on part ofits most successful element.
Like that study, thiswork will also find and evaluate candidate transla-tions for each extracted English phrase.
The cor-pus used in that study was composed of articlesfrom a Brazilian scientific magazine.
Based onthe observation that VPCs are often less formalthan their non-VPC counterparts (consider for ex-ample The experiments back up the theory v. Theexperiments support the theory), the current workevaluates the methodology on a spoken text cor-pus, specifically subtitles from movies and televi-2sion series.
It is expected that this type of corpuswill have a high density of VPCs, and moreoverthat they will often be informal, slang, and evenprofanities that would not be found in most cor-pus types.
Indeed, the name of one of the mostsuccessful television series of recent times, Break-ing Bad, is a perfect example of a slang VPC thatwould not be found in most lexical resources.3 MethodologyThe methodology in this study, adapted from thatof Caseli et al.
(2010), consists of four stages:PoS tagging, extraction, filtering and grouping,which are explained in turn in Sections 3.1?3.4.The corpus used is the OpenSubtitles2012 cor-pus (Tiedemann, 2012), a collection of documentsfrom http://www.opensubtitles.org/, consisting ofsubtitles from movies and television series.
Asit based on user uploads there can be several setsof subtitles for the same movie, normally varyingonly slightly from each other.
The corpus is to-kenised, true-cased and sentence-aligned, and var-ious word alignments are also provided.
The sec-tion of the corpus used in this study, which is par-allel in English and Spanish, contains 39,826,013sentence pairs, with 342,833,112 English tokensand 299,880,802 Spanish tokens.3.1 PoS TaggingFirst of all, both the English and Spanish data arePoS tagged using TreeTagger (Schmid, 1994).
Anadvantage of TreeTagger is that as well as PoStags, it also provides lemma information for eachword, which will be useful later in identifying dif-ferent conjugations of the same VPCs.
Subtitles,being a form of spoken text, are inherently diffi-cult to tag; the overall accuracy of the TreeTaggeris likely to be low on this data type.
It should benoted however that PoS taggers generally have ahigh accuracy for verbs compared to other parts ofspeech.3.2 ExtractionUsing the aligned.grow-diag-final-andalignment file provided with the corpus, all wordalignments containing more than one word ineither language are extracted.
This alignment filehas been created by first word-aligning the paralleldata sets in both directions using GIZA++ (Ochand Ney, 2000), before merging them according tothe algorithm in Och and Ney (2003).
By varyingthe parameters to this algorithm to trade betweenprecision and recall, various other alignment fileshave also been produced and made available aspart of the OpenSubtitles2012 corpus.The first alignment from the raw extraction pro-cess (for illustration purposes ?
there is nothingparticularly special about this entry) is as follows:?ve/VHP/have got/VVN/get ///tengo/VLfin/tenerThe English ?ve got is aligned to the Spanish tengo(?I have?
), along with the respective PoS tags andlemmas.
In total there are 53,633,153 such align-ments in the corpus, many of which are repeti-tions.
Identical entries are counted and sorted, be-fore filtering is applied to find candidate VPCs.3.3 FilteringThis is achieved by looking for all instances wherethe first English word has a verb tag (any tag be-ginning with V), the second is a particle (indicatedby the tag RP), and the Spanish translation is alsoa verb.
A minimum frequency of five is also ef-fected; this is higher than the threshold of two ap-plied by Caseli et al.
(2010).
There are several rea-sons for this: the larger corpus size here, the factthat PoS tagging is expected to be less accurate onthis corpus, and the fact that some movies havemore than one set of subtitles, leading to some al-most identical sections in the corpus.
This filter-ing is rather strict: to make it through this stage aVPC must occur at least five times in the corpus inexactly the same conjugation with the same trans-lation.
Some genuine VPCs might therefore be fil-tered away at this stage; those that occur few timesand in different conjugations will be lost.
Thevalue of five was chosen early on in the study andleft unchanged, based on some initial observationsof lines that were repeated two or three times in thecorpus and taking into account the other factorsmentioned above.
This parameter can of coursebe adjusted to increase recall, with the expecteddamage to the precision score; a more detailed in-vestigation of this effect would be an interestingextension to the present study.The filtered list contains a total of 18186 entries,the first of which is:10900 come/VV/come on/RP/on ///vamos/VLfin/irThis looks promising so far: the English entrycome on is a valid VPC, and the Spanish transla-tion vamos (?let?s go?)
is a good translation.
There3is still more work to do, however, as at this stagethe list contains many instances of the same VPCsin different conjugations and with different trans-lations.
There are also, due to the fact that theoriginal corpus was in true case, some instances ofrepetitions of the same VPC with different casing.3.4 GroupingThe remaining data is lower-cased, before entriesare grouped based on their lemmas, adding to-gether the respective counts.
By doing this someinformation is lost: certain VPCs may only natu-rally appear in certain conjugations, or may havedifferent meanings depending on the conjugationthey appear in.
This therefore undoubtedly intro-duces some error into the evaluation process, butfor the purposes of simplification of analysis is acrucial step.Grouping reduces the list of VPC-translationpairs to 6833 entries, 37.6% of the number be-fore grouping.
This large reduction shows that theVPCs that occur many times in one conjugationtend to also appear in several other conjugations.The grouping process merges these to a single en-try, leading to the observed reduction.
Amongstthe remaining 6833 entries, there are 1424 uniqueEnglish VPCs.
The next challenge is to evaluatethe accuracy of the results.4 EvaluationThe evaluation of the extracted candidate VPCsand their translations is in three parts: first, anevaluation of whether the candidates are in factvalid English VPCs; secondly, whether they al-ready exist in certain online resources; and thirdlywhether the Spanish translations are valid.
Eval-uating all 6833 candidates is not feasible in thetime-frame of this study, thus the following ap-proach is taken: a random selection of 100 VPCcandidates is chosen from the list of 1424 VPCs,then for each of these candidates the highest prob-ability translation (that with the highest count inthe corpus) is found.4.1 Validity of VPC CandidatesThe 100 candidate VPCs are judged by a nativeEnglish speaker as either valid or not, followingthe definitions and rules set out in Chapter 16 ofGreenbaum and Quirk (1990) (note however theirdifferent terminology as mentioned in Section 2).One of the major difficulties in this evaluation isthat VPCs are productive; it can be difficult evenfor a native speaker to judge the validity of a VPCcandidate.
Consider for example the unusual VPCambulance off ; while this almost certainly wouldnot appear in any lexical resources, nor wouldhave been uttered or heard by the vast majority,native speaker intuition says that it could be usedas a VPC in the sense of ?carry away in an ambu-lance?.
This should therefore be judged valid inthe evaluation.
It is important to remember herethat one of the main reasons for using the subtitlescorpus in the first place is to find unusual VPCsnot usually found in other corpora types or lexicalresources; candidates cannot simply be ruled outbecause they have never been seen or heard beforeby the person doing the evaluation.
Ambulance offdoes actually appear in the corpus, in the sentenceA few of a certain Billy-boy?s friends were ambu-lanced off, though it is not part of the 100 candi-date VPCs evaluated in this study.At the evaluation stage, the aim is to judgewhether the candidate VPCs could in theoryvalidly be employed as VPCs, not to judgewhether they were in fact used as VPCs in the cor-pus.
The corpus itself was however a useful re-source for the judge; if a borderline VPC candi-date was clearly used at least once as a VPC in thecorpus, then it was judged valid.
Not all VPC can-didates were checked against the corpus however,as many could be judged valid without this step.It is worth noting that some genuine VPCs couldhave found themselves on the candidate list de-spite not actually having been employed as VPCsin the corpus, though this probably happens veryinfrequently.4.2 Existence in Current Lexical ResourcesOnce valid VPCs have been identified bythe judge from the list of 100 candidatesin the previous step, they are checkedagainst two online resources: Dictionary.com(http://dictionary.reference.com/) and The FreeDictionary (http://www.thefreedictionary.com/).Both these resources contain substantial quantitiesof MWEs; The Free Dictionary even has itsown ?idioms?
section containing many slangexpressions.
A VPC is considered to be alreadydocumented if it appears anywhere in either of thetwo dictionaries.44.3 Accuracy of TranslationsThe final stage of evaluation was carried out by anative Spanish speaker judge from Mexico with anear-native level of English.
The judge was askedto asses whether each of the Spanish translationcandidates could be employed as a translation ofthe English VPC in question.
The original cor-pus was used for reference purposes in a similarmanner to the evaluation of the VPC candidates:not every example was looked up but in borderlinecases it served as a useful reference.5 Results5.1 Validity of VPC CandidatesAmongst the 100 randomly selected VPC candi-dates, 94 were judged valid by a native speaker.The normal approximation gives a 95% confi-dence interval of 94?
4.7%.
In the original list of1424 candidates, the number of true VPCs is there-fore expected to lie in the range between 1272 and1405.
This precision rate is in line with the fig-ure of 88.94?97.30% stated in Table 9 of Caseliet al.
(2010).
Note however that the two figuresare not directly comparable; in their study theylooked at all combinations of verbs with particlesor prepositions, and judged whether they were trueMWEs.
Their analysis thus likely includes manyprepositional verbs as well as VPCs.
Rememberhere that only combinations of verbs with particleswere considered, and it was judged whether theywere true VPCs.
The current study shows howeverthat high levels of precision can be achieved in theextraction of phrasal verbs, even given a more dif-ficult corpus type.Amongst the VPC candidates judged valid, fourappeared in slightly unusual form in the list:teared up, brung down, fessed up and writ down.In all four cases the problem seems to stem fromthe lemmatiser: it fails to convert the past tenseteared to the infinitive tear (note that ?tear?
hastwo quite separate meanings with correspondingpronunciations ?
one with ?teared?
as past tenseand one with ?tore?
), it fails to recognise the di-alectal variation brung (instead of brought), it failsto recognise the slang verb fess (meaning ?con-fess?
), and it fails to recognise an old variationon the past tense of write, which was writ ratherthan wrote.
These mistakes of the lemmatiser arenot punished; there were marked valid as long asthey were genuine VPCs.
This reinforces a dif-ficulty of working with subtitle corpora: verbsmight be used in unusual forms which cause dif-ficulties for existing automatic text-analysis tools.It is of course also the reason why subtitles are infact so interesting as corpus material.It is illuminating to analyse why certain VPCcandidates were judged invalid; this can highlightproblems with the method, the evaluation, or eventhe corpus, which may help future studies.
Thesix VPC candidates in question are base on, boltout, bowl off, bury out, hide down and imprinton.
These false positives all contain valid verbs,but combined with the particle do not make validVPCs.
In several cases the confusion arises be-tween a preposition and a particle; it appears thetagger has incorrectly labelled the second token asa particle instead of a preposition in the cases baseon, bolt out, bury out and imprint on.
This seemsto occur particularly when the preposition occursat the very end of a sentence, for example in that?swhat these prices are based on, or when there isa two-word preposition such as in phrases like hebolted out of the room.
It is easy to see how thetagger could have interpreted these prepositionsas particles; very similar examples can be foundwhere we do indeed have a VPC, such as that wasa real mess up or he was shut out of the discus-sion (the particles ?up?
and ?out?
here appear inthe same positions as the prepositions in the previ-ous examples).
The candidate VPC hide down is asomewhat similar case, appearing in phrases suchas let?s hide down there.
The tagger incorrectlylabels ?down?
as a particle instead of an adverb.A clue that this is the wrong interpretation comesfrom the fact that when the phrase is spoken outloud the emphasis is placed on hide.The final false positive to be explained is bowloff.
This verb appears in the phrase they?d bowlyou off a cliff, which occurs no less than eleventimes in the corpus, each time aligned to a singleSpanish verb.
Here we see how a problem withthe corpus leads to errors in the final list of can-didates.
This appears to be a case where severalsets of subtitles exist for the same movie, and thetagger and aligner are making the same faulty de-cision each time they see this phrase, allowing theincorrect VPC to bypass the filters.
One possibleresolution to this problem could be to simply ex-clude all identical lines above a certain length fromthe corpus.
This is however somewhat unsatisfac-tory, as having multiple copies of the same subti-tles does provide some information; the fact that5several users have all chosen to transcribe a par-ticular section of a movie in a certain way shouldincrease our credence in the fact that it is bothvalid English and an accurate reflection of whatwas actually said.
Another option might thereforebe to alter the parameter determining the minimumnumber of times a particular alignment must occurto be included in the analysis.
A more thorough in-vestigation of the trade off between precision andrecall, which can be altered both by varying thisparameter and by invoking more or less strict wordalignment algorithms, could be the subject of afurther study.It is reasonable to ask the question as to why theaccuracy of VPC extraction is so high in compar-ison to other MWE types.
A possible reason forthis is that VPCs in one language, such as English,tend to be translated to a verb construction in an-other language, such as Spanish.
They can thussaid to be cross-linguistically consistent (althoughnot in the stronger sense that a VPC always trans-lates to a VPC ?
many languages indeed do nothave VPCs).
This is not true of all MWE types;in many cases complex constructions may be re-quired to translate a certain type of MWE fromone language to another.
Another contributing fac-tor may be that PoS taggers have good accuracyfor verbs compared to other PoS categories, whichmakes the filtering process more precise.5.2 Existence in Current Lexical ResourcesOne of the aims of this study was to show that sub-titles data contain interesting VPCs that are rarelyseen in other types of corpora, even those that con-tain a considerable number of idioms and slangexpressions.
Of the 94 validated VPCs from Sec-tion 5.1, 80 were found on either Dictionary.comor The Free Dictionary.
14 of the 100 randomly se-lected VPC candidates were thus valid previouslyundocumented VPCs (see Table 1), with a 95%confidence interval of 14 ?
6.8%.
This gives usbeam up make wholeclamber up reach overdance around shorten upgrab up single upgrill up spin uplift up storm offpoke up torch outTable 1: The 14 validated VPCs that do not appearin either of the online resources.a range of valid previously undocumented VPCsamongst the total 1424 extracted between 103 and296.Interestingly, nine of the 14 previously undocu-mented VPCs in the sample take the particle ?up?,suggesting that this type of VPC may be particu-larly under-represented in lexical resources.
Thisparticle often adds an aspectual meaning to theverb in question, rather than creating a completelynew idiomatic sense.
That is certainly the casewith several of the VPCs listed in Table 1; shortenup, grab up and grill up, for example, could bereplaced by shorten, grab and grill respectivelywithout a dramatic change in sense.
This particlemay therefore be somewhat more productive thanthe others observed in Table 1; whole, out, over,around, and off cannot be so freely added to verbsto make new VPCs.5.3 Accuracy of TranslationsThe translations of 75 of the 94 validated VPCsfrom Section 5.1 were judged valid by a nativeSpanish speaker.
This equates to a 95% confidenceinterval of 75 ?
8.5% of the original selection of100 VPC candidates that are valid and have cor-rect translations.
As with the original list of En-glish VPCs, there were some issues in the Spanishtranslations stemming from the lemmatiser.
Cer-tain verbs appeared in forms other than the infini-tive; as before these mistakes were not punished inthe evaluation.
The point here was not to judge thequality of the lemmatisation, which was primarilyused as a tool to simplify the evaluation.The precision rate of 75 ?
8.5% obtained inthis study is higher than the range 58.61?66.91%quoted in Caseli et al.
(2010), though there is asmall overlap of 0.41% (note that their range isbounded by the number of examples judged cor-rect by two judges and those judged correct byonly one of the judges, and is not a statistical con-fidence interval in the same sense).
Their analy-sis again differs somewhat here, however, as theyconsider translations of many different types ofMWE; they do not present an analysis of howthis figure breaks down with different MWE types.The results presented here suggest that high preci-sion rates can be achieved for VPC translations us-ing this alignment method.
Although the precisionis a little lower than for VPC extraction, it is stilllikely to be practically quite useful in the creationof bilingual lexical resources for NLP tasks.66 Discussion and Future WorkThe methodology described in this paper consistedof four stages ?
PoS tagging, extraction, filteringand grouping.
Analysis of false positive candidateVPCs extracted from the corpus demonstrated thatimprovements at various points along this pipelinecould be effected to boost the final results.
A com-mon error at the first stage was prepositions be-ing tagged as particles.
It was always likely thatPoS tagging on difficult data like subtitles wouldbe less than perfect, and for this reason it is notsurprising that errors of this nature arose.
Traininga PoS-tagger on labelled subtitles data, somethingwhich is not currently available, would be an ob-vious way to improve the accuracy here.An important factor at the extraction stage wasthat some sections of the corpus were essentiallyduplicates of each other, due to the fact that therecould be several user uploads of the same movie.This could lead to certain VPCs being validateddespite being very rare in reality.
A solution heremight be to try to remove duplicates from the cor-pus, and there are several conceivable ways of do-ing this.
One could impose a limit of one set ofsubtitles per movie, though this would require ac-cess to a version of the corpus with more informa-tion than that used in this study, and would raisethe question of which version to choose, bearingin mind that both the English and Spanish subtitlesmay have several versions.
A more brute methodwould be to directly remove duplicate lines fromthe corpus, that is to say all lines where both theEnglish and Spanish are identical in every respect.A preliminary study (not shown here) shows thatkeeping all other parameters equal, this reducesthe number of candidate VPC-translation pairsfrom 6833 to 3766 (a reduction of 45%), with a re-duction in the number of unique VPCs from 1424to 852 (a reduction of 40%).
One would of coursehope that the precision rate be higher amongst thecandidate VPCs, though given the large reductionof candidates, the overall number of valid VPCsextracted would surely be lower.
A lowering of thefrequency threshold might therefore be required inorder to extract more VPCs; a future study willlook into this trade-off.Another methodological choice made in thisstudy was the order in which various parts of themethodology were carried out: grouping came af-ter filtering in the four-stage process, but thesecould equally be switched.
A preliminary study(not shown here) shows that applying the groupingalgorithm before the frequency threshold increasesthe number of candidate VPCs to 12,945 (an in-crease of 89%), with 2052 unique VPCs (an in-crease of 44%).
However, there is a correspondingdecrease in precision from 94?4.7% to 85?7.0%(though the confidence intervals do overlap here).A more thorough investigation would be requiredto confirm this effect, and to test what happensto the number of previously undocumented VPCsand precision of translations.The frequency threshold was set to five in thiswork: each candidate VPC had to appear at leastfive times in the same conjugation to be accepted.This number was chosen at the beginning of thestudy and never altered; it is clear however thatit plays a big role in the final number of candi-date VPCs and the precision rate therein.
An in-teresting extension to this work would be to anal-yse the relationship between this threshold andprecision: at what frequency level does the pre-cision become acceptable?
This could be anal-ysed from both the point of view of VPC candi-dates and their translations: the level may not bethe same for both.
This would of course require alarge amount of empirical evaluation that may beexpensive and hard to carry out in practise.
Thehighest frequency translations for each of the ran-domly selected VPC candidates were evaluated inthis study; it would also be interesting to look atthe precision rate for all translations.
Caseli etal.
(2010) found that the range of accurate transla-tions reduced from 58.61?66.92% for the most fre-quent translations to 46.08?54.87% for all possi-ble translations across a larger spectrum of MWEs.The results presented in this study would bestronger if confirmed by other judges; the morethe better but ideally at least three.
It should beremembered however that the criteria for judgingwas whether the VPC candidate could in any cir-cumstance be used as a genuine VPC.
Only onepositive example is required to prove this for eachVPC candidate, and no number of negative ex-amples proves the reverse.
The difficulty for thejudge is therefore not really that he or she will ac-cidentally label an invalid candidate as valid, butthe opposite: sometimes it is simply difficult tothink up a valid phrase with the VPC in question,but once it appears in the mind of the judge he iscertain that it is valid.
The same can be true oftranslation: it may be difficult to think of a sense7of the English VPC in which the Spanish verb isvalid, even if that sense does exist.
The resultspresented here can thus be viewed as a minimum:the addition of further judges is unlikely to leadto a reduction in precision, but could lead to anincrease.
One area where further evaluation couldlead to less-impressive results is the number of un-documented VPCs.
Validated VPCs were checkedagainst two resources in this study: The Free Dic-tionary and Dictionary.com.
It would be interest-ing to do further tests against other resources, suchas the English Resource Grammar and Lexicon(www.delph-in.net/erg/).This study did not consider recall, choosing in-stead to focus on precision and a comparison ofextracted VPCs with existing resources.
It wouldhowever be useful for many applications to havean idea of the percentage of VPCs in the corpusthat end up in the final list, although a full analysiswould require a labelled subtitles corpus.
Caseliet al.
(2010) present a method to estimate recallwhen a labelled corpus is not available.
Gener-ally speaking however it can be assumed that thenormal inverse relation between precision and re-call holds here.
The exact dynamic of this rela-tion can be adjusted in the filtering process: byletting VPCs with lower frequency through recallis bound to increase, but at the same time reducethe high levels of precision as more false positivesend up in the final list.
The balance between pre-cision and recall can also be adjusted during thealignment process; the effect this would have onVPC extraction is unclear.
An evaluation of thiseffect could be carried out by re-running the studyusing each of the different alignment tables pro-vided with the OpenSubtitles corpus.Only one language pair was considered in thisstudy, namely English and Spanish.
Pichotta andDeNero (2013) have shown that combining infor-mation from many languages ?
albeit in conjunc-tion with a different extraction method ?
can im-prove VPC extraction accuracy.
One way to fur-ther increase the precision achieved via the align-ment methods in this study may be to use a sim-ilar combination technique.
The latest version ofthe OpenSubtitles corpus contains 59 different lan-guages, and this multitude of data could poten-tially be put to better use to obtain yet more VPCs.The choice of English and Spanish is also relevantvia the fact that English has VPCs while Span-ish does not ?
this may be an important factor.Whether better results could be obtained using twolanguages with VPCs, such as English and Ger-man, for example, is another interesting questionthat may be the subject of a follow up study.7 ConclusionsThis study has demonstrated that word alignmentmethods and a PoS tag based filter on a largeparallel subtitles corpus can be used to achievehigh precision extraction of VPCs and their trans-lations.
Despite the difficulties associated withthe corpus type, which hinder both the taggingand the word alignment processes, a precision of94 ?
4.7% was found for the extraction of validEnglish VPCs from a parallel corpus in Englishand Spanish.
14 ?
6.8% of the extracted VPCcandidates were both valid and previously undoc-umented in two large online resources, while sev-eral more appeared in unusual dialectal forms,highlighting the unique nature of the corpus type.Analysing the Spanish translations extracted alongwith the VPCs, 75 ?
8.5% were judged valid bya native Spanish speaker.
This represents a largeincrease in precision over similar previous stud-ies, highlighting the benefits of focusing on VPCsrather than a larger range of MWE types.AcknowledgementsThis work benefited greatly from discussions withmy fellow students on the Language Technol-ogy: Research and Development course at Upp-sala University.
I am particularly grateful to NinaSchottm?uller and Marie Dubremetz for their de-tailed suggestions, and our teacher Joakim Nivrefor his significant input to this paper.
I would alsolike to thank the three anonymous reviewers fortheir valuable feedback.ReferencesH.
M. Caseli, C. Ramisch, M. G. V. Nunes, and A.Villavicencio.
2010.
Alignment-based extractionof multiword expressions.
Language Resources &Evaluation, 44:59?77.N.
Chatterjee and R. Balyan.
2011.
Context Reso-lution of Verb Particle Constructions for English toHindi Translation.
25th Pacific Asia Conference onLanguage, Information and Computation, 140?149.M.
Constant and J.
Le Roux and A. Signone.
2013.Combining Compound Recognition and PCFG-LA8Parsing with Word Lattices and Conditional Ran-dom Fields.
In ACM Transactions on Speech andLanguage Processing, 10(3).A.
Copestake, F. Lambeau, A. Villavicencio, F. Bond,T.
Baldwin, I.
Sag, and D. Flickinger.
2002.
Multi-word expressions: linguistic precision and reusabil-ity.
In Proceedings of LREC, 1941?1947.C.
M. Darwin and L. S. Gray.
1999.
Going After thePhrasal Verb: An Alternative Approach to Classifi-cation.
TESOL Quarterly, 33(1).S.
Greenbaum and R. Quirk.
1990.
A Student?s Gram-mar of the English Language.
Pearson EducationLimited, Harlow, UK.S.
N. Kim and T. Baldwin.
2010.
How to pick out to-ken instances of English verb-particle constructions.Language Resources & Evaluation, 44:97?113.B.
Levin.
1993.
English Verb Classes and Alternations?
A Preliminary Investigation.
The Chicago Press.Z.
Liu, H. Wang, H. Wu, and S. Li.
2011.
Two-WordCollocation Extraction Using Monolingual WordAlignment Method.
In ACM Transactions on Intel-ligent Systems and Technology, 3(487?495).F.
J. Och and H. Ney.
2000.
Improved StatisticalAlignment Models.
In Proceedings of the 38th An-nual Meeting of the ACL, 440?447.F.
J. Och and H. Ney.
2003.
A Systematic Comparisonof Various Statistical Alignment Models.
Computa-tional Linguistics, 29(19?51).K.
Pichotta and J. DeNero.
2013.
Identifying PhrasalVerbs Using Many Bilingual Corpora.
In Proceed-ings of the 2013 Conference on Empirical Methodsin Natural Language Processing, 636?646.H.
Schmid.
1994.
Probabilistic Part-of-Speech Tag-ging Using Decision Trees.
In Proceedings of Inter-national Conference on New Methods in LanguageProcessing, Manchester, UK.J.
Tiedemann.
2012.
Parallel Data, Tools, and Inter-faces in OPUS.
In Proceedings of the 8th Interna-tional Conference on Language Resources and Eval-uation (LREC 2012), 2214?2218.B.
Villada Moir?on and J. Tiedemann.
2006.
Identify-ing Idiomatic Expressions using Automatic Word-Alignment.
In Proceedings of the Workshop onMulti-Word-Expressions in a Multilingual Context(EACL-2006), 33?40.A.
Villavicencio.
2005.
The availability of verb parti-cle constructions in lexical resources: How much isenough?
Computer Speech And Language, 19:415?432.S.
Zarriess and J. Kuhn.
2009.
Exploiting Trans-lational Correspondences for Pattern-IndependentMWE Identication.
In Proceedings of the Workshopon Multiword Expressions, Suntec, Singapore 23?309
