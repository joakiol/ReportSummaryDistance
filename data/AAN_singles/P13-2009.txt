Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 47?52,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsSemantic Parsing as Machine TranslationJacob AndreasComputer LaboratoryUniversity of Cambridgejda33@cam.ac.ukAndreas VlachosComputer LaboratoryUniversity of Cambridgeav308@cam.ac.ukStephen ClarkComputer LaboratoryUniversity of Cambridgesc609@cam.ac.ukAbstractSemantic parsing is the problem of de-riving a structured meaning representationfrom a natural language utterance.
Herewe approach it as a straightforward ma-chine translation task, and demonstratethat standard machine translation com-ponents can be adapted into a semanticparser.
In experiments on the multilingualGeoQuery corpus we find that our parseris competitive with the state of the art,and in some cases achieves higher accu-racy than recently proposed purpose-builtsystems.
These results support the use ofmachine translation methods as an infor-mative baseline in semantic parsing evalu-ations, and suggest that research in seman-tic parsing could benefit from advances inmachine translation.1 IntroductionSemantic parsing (SP) is the problem of trans-forming a natural language (NL) utterance intoa machine-interpretable meaning representation(MR).
It is well-studied in NLP, and a wide va-riety of methods have been proposed to tackleit, e.g.
rule-based (Popescu et al, 2003), super-vised (Zelle, 1995), unsupervised (Goldwasser etal., 2011), and response-based (Liang et al, 2011).At least superficially, SP is simply a machinetranslation (MT) task: we transform an NL ut-terance in one language into a statement of an-other (un-natural) meaning representation lan-guage (MRL).
Indeed, successful semantic parsersoften resemble MT systems in several impor-tant respects, including the use of word align-ment models as a starting point for rule extrac-tion (Wong and Mooney, 2006; Kwiatkowski etal., 2010) and the use of automata such as treetransducers (Jones et al, 2012) to encode the re-lationship between NL and MRL.The key difference between the two tasks is thatin SP, the target language (the MRL) has very dif-ferent properties to an NL.
In particular, MRs mustconform strictly to a particular structure so thatthey are machine-interpretable.
Contrast this withordinary MT, where varying degrees of wrongnessare tolerated by human readers (and evaluationmetrics).
To avoid producing malformed MRs, al-most all of the existing research on SP has focusedon developing models with richer structure thanthose commonly used for MT.In this work we attempt to determine how ac-curate a semantic parser we can build by treatingSP as a pure MT task, and describe pre- and post-processing steps which allow structure to be pre-served in the MT process.Our contributions are as follows: We developa semantic parser using off-the-shelf MT compo-nents, exploring phrase-based as well as hierarchi-cal models.
Experiments with four languages onthe popular GeoQuery corpus (Zelle, 1995) showthat our parser is competitve with the state-of-the-art, in some cases achieving higher accuracythan recently introduced purpose-built semanticparsers.
Our approach also appears to requiresubstantially less time to train than the two best-performing semantic parsers.
These results sup-port the use of MT methods as an informativebaseline in SP evaluations and show that researchin SP could benefit from research advances in MT.2 MT-based semantic parsingThe input is a corpus of NL utterances paired withMRs.
In order to learn a semantic parser usingMT we linearize the MRs, learn alignments be-tween the MRL and the NL, extract translationrules, and learn a language model for the MRL.We also specify a decoding procedure that will re-turn structured MRs for an utterance during pre-diction.47states bordering Texasstate(next to(state(stateid(texas))))?
STEM & LINEARIZEstate border texastate1 next to1 state1 stateid1 texas0?
ALIGNstate border texastate1 next to1 state1 stateid1 texas0?
EXTRACT (PHRASE)?
state , state1 ??
state border , state1 border1 ??
texa , state1 stateid1 texas0 ?...?
EXTRACT (HIER)[X] ?
?state , state1?
[X] ?
?state [X] texa ,state1 [X] state1 stateid1 texas0?...Figure 1: Illustration of preprocessing and rule ex-traction.Linearization We assume that the MRL isvariable-free (that is, the meaning representationfor each utterance is tree-shaped), noting that for-malisms with variables, like the ?-calculus, canbe mapped onto variable-free logical forms withcombinatory logics (Curry et al, 1980).In order to learn a semantic parser using MTwe begin by converting these MRs to a form moresimilar to NL.
To do so, we simply take a preordertraversal of every functional form, and label everyfunction with the number of arguments it takes.After translation, recovery of the function is easy:if the arity of every function in the MRL is known,then every traversal uniquely specifies its corre-sponding tree.
Using an example from GeoQuery,given an input function of the formanswer(population(city(cityid(?seattle?, ?wa?
))))we produce a ?decorated?
translation input of theformanswer1 population1 city1 cityid2 seattle0 wa0where each subscript indicates the symbol?s arity(constants, including strings, are treated as zero-argument functions).
Explicit argument numberlabeling serves two functions.
Most importantly,it eliminates any possible ambiguity from the treereconstruction which takes place during decod-ing: given any sequence of decorated MRL to-kens, we can always reconstruct the correspond-ing tree structure (if one exists).
Arity labeling ad-ditionally allows functions with variable numbersof arguments (e.g.
cityid, which in some trainingexamples is unary) to align with different naturallanguage strings depending on context.Alignment Following the linearization of theMRs, we find alignments between the MR tokensand the NL tokens using the IBM Model 4 (Brownet al, 1993).
Once the alignment algorithm isrun in both directions (NL to MRL, MRL to NL),we symmetrize the resulting alignments to obtaina consensus many-to-many alignment (Och andNey, 2000; Koehn et al, 2005).Rule extraction From the many-to-many align-ment we need to extract a translation rule ta-ble, consisting of corresponding phrases in NLand MRL.
We consider a phrase-based transla-tion model (Koehn et al, 2003) and a hierarchi-cal translation model (Chiang, 2005).
Rules forthe phrase-based model consist of pairs of alignedsource and target sequences, while hierarchicalrules are SCFG productions containing at mosttwo instances of a single nonterminal symbol.Note that both extraction algorithms can learnrules which a traditional tree-transducer-based ap-proach cannot?for example the right hand side[X] river1 all0 traverse1 [X]corresponding to the pair of disconnected treefragments:[X]traverseriver[X]all(where each X indicates a gap in the rule).Language modeling In addition to translationrules learned from a parallel corpus, MT systemsalso rely on an n-gram language model for the tar-get language, estimated from a (typically larger)monolingual corpus.
In the case of SP, such amonolingual corpus is rarely available, and we in-stead use the MRs available in the training data tolearn a language model of the MRL.
This informa-tion helps guide the decoder towards well-formed48structures; it encodes, for example, the preferencesof predicates of the MRL for certain arguments.Prediction Given a new NL utterance, we needto find the n best translations (i.e.
sequencesof decorated MRL tokens) that maximize theweighted sum of the translation score (the prob-abilities of the translations according to the ruletranslation table) and the language model score, aprocess usually referred to as decoding.
Standarddecoding procedures for MT produce an n-best listof all possible translations, but here we need torestrict ourselves to translations corresponding towell-formed MRs.
In principle this could be doneby re-writing the beam search algorithm used indecoding to immediately discard malformed MRs;for the experiments in this paper we simply filterthe regular n-best list until we find a well-formedMR.
This filtering can be done with time linear inthe length of the example by exploiting the argu-ment label numbers introduced during lineariza-tion.
Finally, we insert the brackets according tothe tree structure specified by the argument num-ber labels.3 Experimental setupDataset We conduct experiments on the Geo-Query data set.
The corpus consists of a set of880 natural-language questions about U.S. geog-raphy in four languages (English, German, Greekand Thai), and their representations in a variable-free MRL that can be executed against a Prologdatabase interface.
Initial experimentation wasdone using 10 fold cross-validation on the 600-sentence development set and the final evaluationon a held-out test set of 280 sentences.
All seman-tic parsers for GeoQuery we compare against alsomakes use of NP lists (Jones et al, 2012), whichcontain MRs for every noun phrase that appears inthe NL utterances of each language.
In our exper-iments, the NP list was included by appending allentries as extra training sentences to the end of thetraining corpus of each language with 50 times theweight of regular training examples, to ensure thatthey are learned as translation rules.Evaluation for each utterance is performed byexecuting both the predicted and the gold standardMRs against the database and obtaining their re-spective answers.
An MR is correct if it obtainsthe same answer as the gold standard MR, allow-ing for a fair comparison between systems usingdifferent learning paradigms.
Following Jones etal.
(2012) we report accuracy, i.e.
the percent-age of NL questions with correct answers, and F1,i.e.
the harmonic mean of precision (percentage ofcorrect answers obtained).Implementation In all experiments, we use theIBM Model 4 implementation from the GIZA++toolkit (Och and Ney, 2000) for alignment, andthe phrase-based and hierarchical models imple-mented in the Moses toolkit (Koehn et al, 2007)for rule extraction.
The best symmetrization algo-rithm, translation and language model weights foreach language are selected using cross-validationon the development set.
In the case of English andGerman, we also found that stemming (Bird et al,2009; Porter, 1980) was hepful in reducing datasparsity.4 ResultsWe first compare the results for the two translationrule extraction models, phrase-based and hierar-chical (?MT-phrase?
and ?MT-hier?
respectivelyin Table 1).
We find that the hierarchical modelperforms better in all languages apart from Greek,indicating that the long-range reorderings learnedby a hierarchical translation system are useful forthis task.
These benefits are most pronounced inthe case of Thai, likely due to the the language?scomparatively different word order.We also present results for both models with-out using the NP lists for training in Table 2.
Asexpected, the performances are almost uniformlylower, but the parser still produces correct outputfor the majority of examples.As discussed above, one important modifica-tion of the MT paradigm which allows us to pro-duce structured output is the addition of structure-checking to the beam search.
It is not evident,a priori, that this search procedure is guaran-teed to find any well-formed outputs in reasonabletime; to test the effect of this extra requirement onen de el thMT-phrase 75.3 68.8 70.4 53.0MT-phrase (-NP) 63.4 65.8 64.0 39.8MT-hier 80.5 68.9 69.1 70.4MT-hier (-NP) 62.5 69.9 62.9 62.1Table 2: GeoQuery accuracies with and withoutNPs.
Rows with (-NP) did not use the NP list.49English [en] German [de] Greek [el] Thai [th]Acc.
F1 Acc.
F1 Acc.
F1 Acc.
F1WASP 71.1 77.7 65.7 74.9 70.7 78.6 71.4 75.0UBL 82.1 82.1 75.0 75.0 73.6 73.7 66.4 66.4tsVB 79.3 79.3 74.6 74.6 75.4 75.4 78.2 78.2hybrid-tree 76.8 81.0 62.1 68.5 69.3 74.6 73.6 76.7MT-phrase 75.3 75.8 68.8 70.8 70.4 73.0 53.0 54.4MT-hier 80.5 81.8 68.9 71.8 69.1 72.3 70.4 70.7Table 1: Accuracy and F1 scores for the multilingual GeoQuery test set.
Results for other systems asreported by Jones et al (2012).the speed of SP, we investigate how many MRsthe decoder needs to generate before producingone which is well-formed.
In practice, increasingsearch depth in the n-best list from 1 to 50 resultsin a gain of no more than a percentage point ortwo, and we conclude that our filtering method isappropriate for the task.We also compare the MT-based semanticparsers to several recently published ones: WASP(Wong and Mooney, 2006), which like the hier-archical model described here learns a SCFG totranslate between NL and MRL; tsVB (Jones etal., 2012), which uses variational Bayesian infer-ence to learn weights for a tree transducer; UBL(Kwiatkowski et al, 2010), which learns a CCGlexicon with semantic annotations; and hybrid-tree (Lu et al, 2008), which learns a synchronousgenerative model over variable-free MRs and NLstrings.In the results shown in Table 1 we observe thaton English GeoQuery data, the hierarchical trans-lation model achieves scores competitive with thestate of the art, and in every language one of theMT systems achieves accuracy at least as good asa purpose-built semantic parser.We conclude with an informal test of trainingspeeds.
While differences in implementation andfactors like programming language choice makea direct comparison of times necessarily impre-cise, we note that the MT system takes less thanthree minutes to train on the GeoQuery corpus,while the publicly-available implementations oftsVB and UBL require roughly twenty minutes andfive hours respectively on a 2.1 GHz CPU.
Soin addition to competitive performance, the MT-based parser also appears to be considerably moreefficient at training time than other parsers in theliterature.5 Related WorkWASP, an early automatically-learned SP system,was strongly influenced by MT techniques.
Likethe present work, it uses GIZA++ alignments asa starting point for the rule extraction procedure,and algorithms reminiscent of those used in syn-tactic MT to extract rules.tsVB also uses a piece of standard MT ma-chinery, specifically tree transducers, which havebeen profitably employed for syntax-based ma-chine translation (Maletti, 2010).
In that work,however, the usual MT parameter-estimation tech-nique of simply counting the number of rule oc-currences does not improve scores, and the au-thors instead resort to a variational inference pro-cedure to acquire rule weights.
The present workis also the first we are aware of which uses phrase-based rather than tree-based machine translationtechniques to learn a semantic parser.
hybrid-tree(Lu et al, 2008) similarly describes a generativemodel over derivations of MRL trees.The remaining system discussed in this paper,UBL (Kwiatkowski et al, 2010), leverages the factthat the MRL does not simply encode trees, butrather ?-calculus expressions.
It employs resolu-tion procedures specific to the ?-calculus such assplitting and unification in order to generate ruletemplates.
Like other systems described, it usesGIZA alignments for initialization.
Other workwhich generalizes from variable-free meaning rep-resentations to ?-calculus expressions includes thenatural language generation procedure describedby Lu and Ng (2011).UBL, like an MT system (and unlike most of theother systems discussed in this section), extractsrules at multiple levels of granularity by means ofthis splitting and unification procedure.
hybrid-tree similarly benefits from the introduction of50multi-level rules composed from smaller rules, aprocess similar to the one used for creating phrasetables in a phrase-based MT system.6 DiscussionOur results validate the hypothesis that it is possi-ble to adapt an ordinary MT system into a work-ing semantic parser.
In spite of the compara-tive simplicity of the approach, it achieves scorescomparable to (and sometimes better than) manystate-of-the-art systems.
For this reason, we arguefor the use of a machine translation baseline as apoint of comparison for new methods.
The resultsalso demonstrate the usefulness of two techniqueswhich are crucial for successful MT, but which arenot widely used in semantic parsing.
The first isthe incorporation of a language model (or com-parable long-distance structure-scoring model) toassign scores to predicted parses independent ofthe transformation model.
The second is theuse of large, composed rules (rather than ruleswhich trigger on only one lexical item, or on treeportions of limited depth (Lu et al, 2008)) inorder to ?memorize?
frequently-occurring large-scale structures.7 ConclusionsWe have presented a semantic parser which usestechniques from machine translation to learn map-pings from natural language to variable-free mean-ing representations.
The parser performs com-parably to several recent purpose-built semanticparsers on the GeoQuery dataset, while trainingconsiderably faster than state-of-the-art systems.Our experiments demonstrate the usefulness ofseveral techniques which might be broadly appliedto other semantic parsers, and provides an infor-mative basis for future work.AcknowledgmentsJacob Andreas is supported by a Churchill Schol-arship.
Andreas Vlachos is funded by the Eu-ropean Community?s Seventh Framework Pro-gramme (FP7/2007-2013) under grant agree-ment no.
270019 (SPACEBOOK project www.spacebook-project.eu).ReferencesSteven Bird, Edward Loper, and Edward Klein.2009.
Natural Language Processing with Python.O?Reilly Media, Inc.Peter F. Brown, Vincent J. Della Pietra, StephenA.
Della Pietra, and Robert L. Mercer.
1993.The mathematics of statistical machine translation:parameter estimation.
Computational Linguistics,19(2):263?311.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of the 43rd Annual Meeting on Associationfor Computational Linguistics, pages 263?270, AnnArbor, Michigan.H.B.
Curry, J.R. Hindley, and J.P. Seldin.
1980.
ToH.B.
Curry: Essays on Combinatory Logic, LambdaCalculus, and Formalism.
Academic Press.Dan Goldwasser, Roi Reichart, James Clarke, and DanRoth.
2011.
Confidence driven unsupervised se-mantic parsing.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies, pages1486?1495, Portland, Oregon.Bevan K. Jones, Mark Johnson, and Sharon Goldwater.2012.
Semantic parsing with bayesian tree transduc-ers.
In Proceedings of the 50th Annual Meeting ofthe Association of Computational Linguistics, pages488?496, Jeju, Korea.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of the 2003 Human Language TechnologyConference of the North American Chapter of theAssociation for Computational Linguistics, pages48?54, Edmonton, Canada.Philipp Koehn, Amittai Axelrod, Alexandra Birch-Mayne, Chris Callison-Burch, Miles Osborne, andDavid Talbot.
2005.
Edinburgh System Descrip-tion for the 2005 IWSLT Speech Translation Evalu-ation.
In Proceedings of the International Workshopon Spoken Language Translation.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondr?ej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: opensource toolkit for statistical machine translation.
InProceedings of the 45th Annual Meeting of the As-sociation for Computational Linguistics CompanionVolume Proceedings of the Demo and Poster Ses-sions, pages 177?180, Prague, Czech Republic.Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwa-ter, and Mark Steedman.
2010.
Inducing proba-bilistic ccg grammars from logical form with higher-order unification.
In Proceedings of the 2010 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 1223?1233, Cambridge, Mas-sachusetts.Percy Liang, Michael Jordan, and Dan Klein.
2011.Learning dependency-based compositional seman-tics.
In Proceedings of the 49th Annual Meeting of51the Association for Computational Linguistics: Hu-man Language Technologies, pages 590?599, Port-land, Oregon.Wei Lu and Hwee Tou Ng.
2011.
A probabilisticforest-to-string model for language generation fromtyped lambda calculus expressions.
In Proceedingsof the Conference on Empirical Methods in Natu-ral Language Processing, EMNLP ?11, pages 1611?1622.
Association for Computational Linguistics.Wei Lu, Hwee Tou Ng, Wee Sun Lee, and Luke Zettle-moyer.
2008.
A generative model for parsing nat-ural language to meaning representations.
In Pro-ceedings of the 2008 Conference on Empirical Meth-ods in Natural Language Processing, pages 783?792, Edinburgh, UK.Andreas Maletti.
2010.
Survey: Tree transducersin machine translation.
In Proceedings of the 2ndWorkshop on Non-Classical Models for Automataand Applications, Jena, Germany.Franz Josef Och and Hermann Ney.
2000.
Improvedstatistical alignment models.
In Proceedings of the38th Annual Meeting of the Association for Com-putational Linguistics, pages 440?447, Hong Kong,China.Ana-Maria Popescu, Oren Etzioni, and Henry Kautz.2003.
Towards a theory of natural language inter-faces to databases.
In Proceedings of the 8th Inter-national Conference on Intelligent User Interfaces,pages 149?157, Santa Monica, CA.M.
Porter.
1980.
An algorithm for suffix stripping.Program, 14(3):130?137.Yuk Wah Wong and Raymond Mooney.
2006.
Learn-ing for semantic parsing with statistical machinetranslation.
In Proceedings of the 2006 Human Lan-guage Technology Conference of the North Amer-ican Chapter of the Association of ComputationalLinguistics, pages 439?446, New York.John M. Zelle.
1995.
Using Inductive Logic Program-ming to Automate the Construction of Natural Lan-guage Parsers.
Ph.D. thesis, Department of Com-puter Sciences, The University of Texas at Austin.52
