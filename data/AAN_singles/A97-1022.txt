A Prototype of a Grammar  Checker for Czech iTomtit, HolanDept.of Software and ComputerScience EducationCharles University, Prague,Czech Republicholan @ksvi.ms.mff.cuni.czVladislav Kubofilnst.of Formal and AppI.Ling.Charles University, Prague,Czech Republicvk@u fal.ms.mff.cuni.czMartin PlfitekDept.of Theoretical Comp.Sc.Charles University, Prague,Czech Republicplatek@kA:i.ms.mff.cuni.czAbst rac tThis paper describes the implementation f aprototype of a grammar based grammar checker forCzech and the basic ideas behind this implementation.The demo is implemented asan independent programcooperating with Microsoft Word.
The grammarchecker uses specialized grammar formalism whichgenerally enables to check errors in languages with avery high degree of word order freedom.IntroductionAutomatic grammar checking is one of the fieldsof natural anguage processing where simple means donot provide satisfactory results.
This statement is evenmore true with respect to grammar checking of theso-called free word order languages.
With the growingdegree of word order freedom the usability of simplepattern matching techniques decreases.
In languageswith such a high degree of word order freedom as inmost Slavic languages the set of syntactic errors thatmay be detected by means of simple pattern matchingmethods is almost negligible.
This is probably one ofthe reasons, why even though the famous paper \[CH83\]was written as long as 13 years ago, there are still veryfew articles about his topic, except papers like \[K94\] or\[M96\] which appeared only during the last three years.In the present paper we describe the basic ideasbehind an implementation f a prototype of a grammarchecker for Czech.
During the development of thisapplication we had to solve a number of problemsconcerning the theoretical background, to develop aformalism allowing efficient implementation a d ofcourse to create a grammar and define the structure ofthe lexical data.
The last but not least problem was toincorporate the prototype into an existing text editor.How does the system workIn order to demonstrate he function of the pivotimplementation f our system we decided to connect itto a commercially available text editor.
We intended tocreate a DLL library with the standard grammarchecking interface required by a particular text editor.This idea turned out to be unrealistic because thenecessary interface is among the classified insideinformation in most companies.
Fortunately there is thepossibility to use a concept of Dynamic Data Exchange(DDE) for the communication between programs in theMicrosoft Windows environment.
This type ofconnection is of course much slower than the intendedone, but for the purpose of this demonstration thedifference in speed is not so important.Our system can work with any text editor underWindows that contains a macro language supporting theDDE connection.
For the purpose of the pivotimplementation f the system we have chosen MicrosoftWord 6.0.
The grammar checker is implemented as anindependent Windows application (GRAMMAR.EXE)which runs on the background of the Word.
In order tobe able to use GRAMMAR.EXE, we had to create amacro Grammar, assigned to the Grammar Checkeritem in the Tools menu.
This macro selects a currentsentence, sends it to GRAMMAR.EXE via DDE,receives the result and indicates the type of the result othe user.
This activity is being performed for allsentences in the selection or for all sentences from theposition of the cursor till the end of document.
: 3+6ZVOLEN6HO-SKONEi/CASE_DISAGR IN THE FOBDOB\[-ZVOLEN6HO/CASE_DISAGR IN THE FOBDOB\[ - Z'VOLEN6HO/ERRCASE!ELENI~ - ZVOLEN{~HOIERRNUMIn~o,t: Is.or \] E.o,p.,,: ~ '~ ~ \[i l J147The user may get several types of messagesabout he correctness of  the text:a) The macro changes the color of  words in the textaccording to the type of the detected error - theunknown words are marked blue, the pairs of wordsinvolved in a syntactic error are marked red.b) The macro creates a message box with a warningeach time there is an undesired result of  grammarchecking - -  either there was no result or thesentence was too complicated.c) In case that the grammar checker identified andlocalized an error, it creates a message box with ashort description of  the error(s).Because the grammar checker is running as anindependent application, the user may also look at thecomplete results provided by it.
When a message boxcontaining an error message appears on the screen, theuser may switch to GRAMMAR and get an additionalinformation.
The main window of  GRAMMAR is ableto provide either the complete list of  errors, the statisticsconcerning for example the number of  differentsyntactic trees built during grammar checking or eventhe result in the form of a syntactic tree.
We do notsuppose that the last option is interesting for a typicaluser, but if we do have all this information, why shouldwe throw it out?-<.... ---.....obC~bi / j po ".I~  s viak /\o \./ -'- \???
j 7"oedmi / tfe?hprur~chThe architecture of the systemThe design of  the whole system is shown in theFig.
I.
The grammar checker is composed basically ofthree parts:I.Morphological and lexical analysisThis part is in fact an extended spelling checker.The input text is first checked for spelling errors, thenthe lexical and morphological nalysis creates data,which are combined with the information contained in aseparate syntactic dictionary.
It would of  course bepossible to use only one dictionary containingmorphosyntactic information about particular words(lemmas), but for the sake of an easier update ofinformation during the development of  the system wehave decided to keep morphemic and syntactic data inseparate files.Morphological / '~oel" l in ~"~ I ~ f ot~ t~dictionary jUSERn?n "JLJFig l:The architecture of the system2.Grammar checking (extended variant of syntacticparsing)This is the main part of  the system.
It tries toanalyze the input sentence.
There are three possibleresults of  the analysis:a) The analysis is successful and no syntacticinconsistencies were found (at this stage ofprocessing it is too early to use the term syntacticerror, because in our terminology the term error isreserved for something what is being announced tothe user after the evaluation) - -  in this case thesentence is considered to be correct and no messageis issued.b) The analysis is successful, but all results contain atleast one syntactic inconsistency.
In this case it isnecessary to pass the results to the evaluation phase.c) The analysis fails and (probably for the reason of theincompleteness of the grammar) it cannot sayanything about he input sentence.
In such a case noerror message is issued.
We do not use any partialresults for the evaluation of  the possible source of anerror.
Partial results are misleading, because it isoften the case that the error is buried somewhereinside the partial tree and tlo operations performedon partial trees can provide a correct error message.Besides that operations on (hundreds or thousands)148partial trees are very ineffective and they can alsoslow down substantially the processing of  the givensentence.3.EvaluationThis phase takes the results of the previous phasein the form of syntactic trees containing markersdescribing individual syntactic inconsistencies.
It triesto locate the source of  the error using an algorithm thatcompares available trees.
According to the settingsgiven by the user the evaluation phase issues warningsor error messages.The core of the system is the second, grammarchecking phase, therefore we will concentrate on thedescription of that phase.Process of grammar checkingThe design of  our system was motivated bya simple and natural idea - -  the grammar checkershould not spend too much time on simple correctsentences.
The composition of  a grammar checkingmodule tries to stick to this idea as much as possible.The processing of  an input sentence is divided intothree phases:a) Positive projectiveThis phase is in fact a standard parser - -  itchecks if it is possible to represent a given inputsentence by means of  a projective syntactic tree notcontaining any negative symbol (these symbolsrepresent the application of a grammar rule with relaxedconstraints or an error anticipating rule).
If the answer ispositive, the sentence is considered to be correct and noerror message is issued.As an example we may take the following simplesentence: "Karlova ~ena zal6vala kv~tiny."
(Word forword translation: Charles'\[fern.sing\] wifewateredtherefore its processing ends here.
The systemrecognizes the structure of this sentence in the followingway:LIEFT $ lENT I NELZALEUALAI<UET I NV " ,  / /KARL I~IAb) Positive nonprojective & negative projectiveThis phase tries to find a syntactic tree whicheither contains negative symbols or nonprojectiveconstructions.
A nonprojective subtree is a subtree withdiscontinuous coverage.
It is often the case - -  forexample in wh-sentences - -  that the sentence may beconsidered either syntactically incorrect ornonprojective - - see  examples in \[COL94\].
if such asyntactic tree exists, the evaluation phase tries to decideif there should be an error message, warning or nothing.Let us present a slightly modified sentence fromthe previous paragraph: "Karlovy ~ena zal6valakv~tiny."
(Word for word translation: Charles'\[fem.pl.\]wife watered flowers).
This sentence is ambiguous, it iseither correct and nonprojective (meaning: Womanwatered Charles' flowers) or incorrect (disagreement innumber between "Karlovy" and "~ena") and projective.Both results are achieved by this phase of  the grammarchecker:LEFT_.SEHTIHEL% ~ E U A L AZENA " .i.
/KI:IRL(3UYProjective reading contains an errorLEFT _$ EiNT 1 NELZAL.EU~AZ~NA KUET I ICY "KARI -OUYNonprojective r adingc) Negative nonprojectiveBoth nonprojective constructions and negativesymbols are allowed.
If this phase succeeds, theevaluation module issues a relevant error message orwarning.
In case that neither phase provides any result,no error message is issued.
In case that the user wants toknow which sentences were not analyzed properly, s/hemay obtain a warning.149Although this division into phases worked finefor short sentences (for the sentences not more than15 words long the first phase usually took about1 second on Pentium 75 MHz), long and complicatedsentences were unacceptably slow (even tens ofseconds).
These results turned our attention to theproblem how to speed up the processing of correctsentences even further.With the growing length of sentences the parsingwill be more complex with respect both to the length ofthe processing and to the number of resulting syntacticstructures.
Let us demonstrate he problem on a samplesentence from the corpus of Czech newspaper textsfrom the newspaper Lidov~ noviny.
Let us take thesentence:"KDS nep~edpokhidfi spoluprfici se stranou panaSladka a neni pravdou, ~.e ptedseda k~est'ansk37chdemokratfi pan Benda v telefonick6m rozhovoru sPetrem Pithartem prosazoval ing.
Dejmala do funkceministra ~ivotniho prost~edi.
"(Word for word translation: "CDP \[does\] notsuppose cooperation with party \[of\] Mister Slfidek and\[it\] isn't true, that chairman \[of\] Christian democratsMister Benda in telephone discussion with Petr Pithartenforced ing.
Dejmal to function \[of\] minister \[of\]environment.
")In this basic form of the sentence, which is anexact ranscription of the text from the corpus, theprocessing by the positive projective phase of ourparser takes 13,07s and it provides 26 different variantsof syntactic trees.
During the processing there were2272 items derived.
The testing of this sentence andalso of all the following ones was performed onPentium 75MHz with 16MB RAM.Such a relatively large number of variants iscaused by the fact that our syntactic analysis uses onlypurely syntactic means - we do not take into accounteither semantics or textual or sentential context.
That isthe reason why free modifiers at the end of our samplesentence create a great number of variants of syntacticstructures and thus make the processing longer andmore complicated.
In order to demonstrate his problemwe will take this sentence and modify it trying to findout what the main source of ineffectiveness of itsparsing is.If we look more closely at the number ofambiguities present with individual words, we noticethat the most ambiguous word is the word(abbreviation) "ing."
This word form is the same in allcases, genders and numbers.
If we substitute thisabbreviation by the full form of the word ("in~en~,ra"\[engineer - \[gem\]\]) weget the following results: thesentence is processed 8,95s, the number of variantsdecreases by four (22) and the number of derived itemsis, of course, also smaller (I 817).
The gain of speedwould be even greater would we have worked with anegative or a nonprojective variant of the parser.The next step is to delete further groups of wordsfrom the input sentence.
Among the suitable candidatesthere is, for example, the prepositional phrase "vtelefonickEm rozhovoru" (in \[the\] telephonediscussion).
This phrase can be easily checked forgrammatical correctness locally, because it has a clearleR and right borders (prepositions "v"and "s").
Herewe can easily solve the problem where the nominalgroup ends on the right hand side.
in general, we needto parse the whole sentence in order to get thisinformation, but in some specific cases we can rely onlyon the surface word order.After we had deleted this phrase, the processingtime went down to 8,79s, the same number of syntacticrepresentations as in the previous case was derived (22)and the number of items was slightly lower (1789).
Thisphrase is therefore certainly not the main source ofineffectiveness in parsing.
In order to speed up theprocessing even more we have to use another type ofsimplification.The first step of simplifying the original inputsentence represented almost 50% acceleration althoughit was only a cosmetic hange from an abbreviation toafull word form.
From the point of view of Iocalisation ofgrammatical inconsistencies we can proceed evenfarther - the group title+surname in fact represents onlyone item; if we remove titles preceding surnames we donot change syntactic structure of the sentence.
It islocally only a tiny bit simpler.
When we look moreclosely at the resulting syntactic representation f theprevious variants of the input sentence we may noticethat the word "in~en3~ra" \[engineer\[gen.\]\] figures(inadequately, of course, in this case) also as a right-hand attribute to the word "Pithartem\[instr.\]", as it isshown in the following screenshots (for the sake ofsimplicity we demonstrate only the relevant part ofderivation trees ).7 "??
\ PR3Eo Eo?
po.
\ \T ELEFON I CKEBBT REH \ II I NI S T RADEHOKRRTU?~/ \KR3EST3 ANSKV2CH DEJMALA Z31UOTN!
ZHO1 50F, nosoo._~ /  \ \ .
?EMOKRATU?/ /  PROSTR3EDI 2 KR3ES T3RNS KY2CH /Z31VOTNI 2HOPROSAO|L~/ ~ s ~-...I.Q.
-oo \ ~ /  oo,PR3EDSEDA PAN FUNKCEDEJMALAROZHOUOR~ITHARTEM/ /TELEFONICKEBBTREM MINISTRA DEMOKRATU?PROSTR3EDI2 KR3EST3ANSKV2CH /Z31UOTNI2HOLet us remove the word "in~en~,ra" from theinput sentence altogether.
This time the processing timeis only 3,74s, only 10 structures are created and 1021items are derived.
Another logical step is to remove allother first names and titles which are placedimmediately in front of their governing words.
Thosewords are "pana" \[mister \[gen.\]\], "pan" and "Petrem".The claim that the first two words are unambiguous isupported by the fact that the form of the word "p~in"\[mister\] is different in Czech in case the word is"independent" and in case it is used as a title (p~na vs.pana \[gen.,acc.\], pzin vs. pan\[nom.\]).
When we makethis change we get more than 50% shorter processingtime, namely 1,71 s, also the number of resultingstructures i a half of the original number (5) and only587 items are derived.
Another change we would like todemonstrate is the deletion of all other free modifiersthe result of which is a certain "backbone" of thesentence.After having carried out all deletions, we arriveat the following structure:"KDS nepfedpokl~id~i spolupr~ici a neni pravdou,~e Benda prosadil Dejmala.
"(Word for word translation: "CDP \[does\] not-suppose cooperation and \[it\] isn't true, that Bendaenforced Dejmal.
")The result of the processing is a unique structureand 141 items are derived in 0,22s.
The last variant ofthe input sentence will serve as a contrast to theprevious ones.
Let us take the last clause of thesentence, namely"P~edseda kPest'anskych demokratO pan Benda vtelefonick6m rozhovoru s Petrem Pithartem prosazovalin~en~ra Dejmala do funkce ministra ~.ivotnihoprost~edi.
"\["Chairman \[of\] Christian democrats MisterBenda in telephone discussion with Petr Pithartenforced ing.
Dejmal to function \[of\] minister \[of\]environment.
").If we take into account he results of the previousexamples we should not be surprised by the results.
Theprocessing time is 2,25s, I 0 structures were created and722 items were derived.This example and also other test data showedthat the main source of ineffectivity are clauses with abig number of free modifiers and adjuncts rather thancomplex sentences with many clauses.
These resultshave led us to a layered esign of grammar for positiveprojective parsing.
The core idea of this approach is thefollowing:Syntactic onstructions which even in free wordorder languages may be parsed locally (certainadjectival or prepositional phrases etc.)
should beparsed first in order to avoid their mutual unnecessary(from the point of view of grammar checking!)combinations.
This means that the grammar should bedivided into certain layers of rules (not necessarilydisjunctive), which will be applied one atter the other(in principle they may be applied even in cycles, butthis options is not used in our implementation).In the pivot version of our system we use thefollowing layers:I st layer: a metarule for processing titles andabbreviations preceding names2nd layer: a metarule from the first layer together withmetarules for processing prepositional ndadjectival phrases3rd layer: metarules from the previous layer togetherwith metarules filling the valency slots and othermetarules on the level of one clause4th layer: metarules from the previous layer togetherwith those processing of complex sentences5th layer: metarules for processing the left sentinel andthe right hand side sentential borderThe application of layers may slow down theprocessing of short sentences (it has a fixed cost ofopening the description file and consulting it duringparsing process), therefore it is applied only to151sentences longer than certain threshold (currently 15words).Another important point is, that the results ofparsing in layers provides only positive information (i.e.it is able to sort out sentences which are certainlycorrect, but the failure of parsing in layers does notnecessarily mean that the sentence is incorrect).
Thesame approach may not be used for error localizationand identification, although the cases when parsing inlayers fails on a correct sentence are quite rare.The imp lementat ionThe implementation of our system was to a bigextent influenced by the demand of effectiveness.
Forthis reason we had to abandon even feature structures asthe form of  the representation of  lexical data.
Our datastructure is a set of attribute-value pairs with the dataabout valency frames of particular words as the onlycomplex values (embedded attribute-value pairs).An example of the representation f the Czechwordform "informoval" (\[he\] informed) follows:i n fo rmova llex f :  in fo rmovatwc l :  vbsyntc l :  vv c l :  fu l lre f l :  0aspect :  p r ff rameset :( \[ ac tant :  ac t  case :  nom prep :  0\[ ac tant :  adr  case :  acc  prep :  0 \]\[ ac tant :  pat  case :  c lause  prep :\ ] )neg :  nov fo rm:  pastpgender :  ?
inan  , an im tnum:  sgEND\]z3eThe grammar of the system is composed ofmetarules representing whole sets of rules of thebackground formalism called Robust Free OrderDependency Grammar (RFODG).
The limited space ofthis paper does not allow to present the full descriptionof RFODG here.
The definition may be found forexample in \[TR96\].The RFODG provides a formal base for thedescription ofnonprojective and incorrect syntacticconstructions.
It introduces three measures by means ofwhich it is possible to classify the degree ofnonprojectivness and incorrectness of a particularsentence.
In this paper we would like to stress oneimportant feature of this formalism, namely theclassification of the set of symbols which are used byRFODG into three types:a) terminals and nonterminalsb) deletable and nondeletable symbolsc) positive and negative symbolsThe sets under a) have the usual meaning, thesets under b) serve for the classification of syntacticinconsistencies and the sets under c) serve for theirIocalisation.
The union of terminals and nonterminals iexactly the set of all symbols used by RFODG.
Thesame holds about he union of deletable andnondeletable symbols and also about he union ofpositive and negative symbols.
In other words, eachsymbol used by RFODG belongs to exactly one setfrom each pair of sets under a), b) and c).This classification therefore allows to handleru!es describing both correct and erroneous syntacticconstructions in a uniform way and to use a singlegrammar for the description of both types of syntacticconstructions.
Whenever a metarule describing syntacticinconsistency is used during the parsing process, anegative symbol is inserted into the tree createdaccording to the grammar.The metarules express a procedural descriptionof the process of checking the applicability of a givenmetarule to a particular pair of input items A and B (Astands to the left from B i n the input).
In case that aparticular rule may be applied to items A and B, a newitem X is created.
It is possible to change values of theresulting item X by means of an assignment operator :=?
The constraint relaxation technique is implemented inthe form of so called "soft constraints" - the constraintswith an operator ?
accompanied by an error marker maybe relaxed in phases b) and c) ("hard constraints" withan operator = may never be relaxed).The error anticipating rules are marked by akeyword NEGATIVE at the beginning of the rule andare applied only in phases b) and c).
The keywordPROJECTIVE indicates that the rule may be appliedonly in a projective way.An example of a (simplified) metarule desc,'ibingthe attachment of a nominal modifier in genitive casefrom the right hand side of the noun:PROJECT IVEIF  A .SYNTCL  = n THEN ELSEIF  A .SYNTCL  = prep2FA IL  ENDIFENDIFB .SYNTCL  = nB .case  = genA .R IGHTGEN = yesIF  A .T ITUL  : yes  THENTHEN ELSE152THENTHENIF  A .CASE = gen THENIF  A .GENDER = B.GENDERIF  A .NUM : B .NUMFA IL  ELSE  ENDIFELSE  ENDIFELSE  ENDIFELSE  ENDIFX : :AX .R IGHTGEN := noOKEND PThe interpretation of the grammar is performedby means of  a slightly modified CYK algorithm (adescription of this algorithm may be found for examplein \[$97\].
The grammar works with unambiguous inputdata (ambiguous words are represented as sets ofunambiguous items).
All partial parses from the firstphase are used in the phases b) and c).
For the purposeof testing and debugging the system we use full parsingeven in the first phase.Speeding up the  per fo rmanceIt is often the case that nondeterministic parsersthe author of the grammar has to prevent an unnecessarymultiplication of  results by means of"tricks" which arenot supported by the linguistic theory - -  let us take forexample the problem of subject - -  predicate - -  objectconstruction.
If we do not put any additional restrictionon the order of application of  rules then the rule fillingthe subcategorization slots for subject and object maybe applied in two ways, either first filling the slot for thesubject and then the object or vice versa.
Both wayscreate the same syntactic structure.In such a case it is necessary to apply someadditional constraints in the grammar - -  for examplethe restriction on the order of subcategorization (an itemto the left of  a verb should be processed first).
Thisapproach makes the grammar more complicated than itis necessary and it may also influence the quality ofresults (an error on the left hand side of  a verb may alsoprevent an attachment of the items fi'om the right handside of the verb).The interpreter of our grammar solves thesesituations itself.
Every time a new item is created, theinterpreter checks, if such an item with the samestructure and coverage already exists.
If yes, the newitem is deleted.This property of  the interpreter is used togetherwith other kinds of  pruning techniques in all phases ofgrammar checking.
In addition, there are also someother techniques used especially in phases b) and c).The work with unambiguous input symbols allows fastparsing in the phase a) (CYK is polynomial with respectto the length of  the input), but creates ome problems inthe context of  constraint relaxations used in subsequentphases.
For example, a typical error in "free wordorder'' languages i an error in agreement.
Let ussuppose that we have the following three input words(the actual exical value of  these words may beneglected):Preposition (accusative or locative) Adjective(animate or inanimate gender, genitive or accusativesing.)
Noun (animate, genitive or accusative sing.
)These words represent 2 + 4 + 2 = 8unambiguous items.
If we try to create a prepositionalphrase without constraint relaxation, we get oneresulting item PP(animate, accusative sing.).
On theother hand after the relaxation of  constraints there are16 items created.
One of them does not contain anysyntactic inconsistency, remaining 15 has one or twosyntactic inconsistencies.
In a nondeterministic parserall 16 variants are used in the subsequent parsing.
Thiscauses a combinatorial explosion of mostly incorrectresults.There are two ways how to solve this problem.The first possible solution is to relax the constraints incertain order (to apply a hierarchy on constraints).
Wehave chosen the other possible way, which prefers thesubtrees with minimal number of errors.
Every time anew branch or subtree is created, it is compared with theother branches or subtrees with the same structure andcoverage and if it contains more errors than thosealready existing, it is not parsed further.This technique substantially speeds up theprocessing of  rules with relaxed constraints, but it hasalso one rather unpleasant side effect: the syntacticinconsistencies may be suppressed and appear later in adifferent location.
This makes the task of  the evaluatingpart of  our system a bit more difficult, but neverthelessthe gain on effectivity not accompanied by the loss ofrecall justifies the use of this technique.ConclusionThe main purpose of the demo of our system isto demonstrate a method of grammar based grammarchecking of a "free word order" language.
The system isfar from being ready for commercial exploitation - themain obstacle is the size of  the syntactic dictionaryused.
Grammar based methods require a complexsyntactic information about words.
To build a syntacticdictionary of about 150 000 items is a task whichexceeds our current capacities with respect both tomanpower and funds.
It would be interesting to continuethe work on our system towards the development ofstatistical methods for this task.153References\[COL94\] V.Kubofi, M.Plfitek: A Grammar BasedApproach to Grammar Checking of Free Word OrderLanguages.
In: Proceedings ofCOLING'94, Kyoto1994, pp.
906-910\[TR96\] T.Holan, V.Kubofi, M.Plfitek: Formal ToolsSupporting Development ofa Grammar Checker,Technical Report No.9/96, Charles University, Prague,December 1996\[CH83\] J.Carbonell and P.Hayes: Recovery strategiesfor parsing extragrammatical language.
In: AmericanJournal of Computational Linguistics,1983 9(3-4)pp.123-146.\[K94\] Z.Kirschner: CZECKER - a Maquette Grammar-Checker for Czech.
In: The Prague Bulletin ofMathematical Linguistics 62, MFF UK Prague, 1994,pp.
5-30.\[M96\] L.Mitjushin: An Agreement Corrector forRussian.
In: Proceedings of COLING'96, Copenhagen1996, pp.
776-781\[$97\] Klaas Sikkel: Parsing Schemata - A Frameworkfor Specification and Analysis of Parsing Algorithms,Texts in Theoretical Computer Science - An EATCSSeries, ISBN 3-540-61650-0, Springer Verlag Berlin /Heidelberg / New York, 1997i The work was supported by the tollowing researchgrants: GA(~R 201/96/0195, RSS/H ESP No.
85/1995and JEP PECO 2824 ,,Language Technologies forSlavic Languages.
"154
