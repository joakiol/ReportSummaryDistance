COI~NG 82, J. Horeck~ (ed.
)North-Holland Publishing Company?
Academia, 1982NATURAL LANGUAGE INTERFACES USING LIMITED SEMANTIC INFORMATIONRalph Grishman, Lynette Sirschman*, and Carol FriedmanNew York UniversityNew York, NYIn order to analyze their input properly, naturallanguage interfaces require access todomain-speciflc semantic information.
However,design considerations for practical systems -- inparticular, the desire to construct interfaceswhich are readily portable to new domains --require us to limit and segregate thisdomain-specific information.
We consider here thepossibil ity of limiting ourselves to acharacterization of the structure of information ina domain.
This structure is captured in a domaininformation schema, which specifies the semanticclasses of the domain, the words and phrases whichbelong to these classes, and the predicate-argumentrelationships among members of these classes whichare meaningful in the domain.
We describe how thisschema is used by the various stages of two largenatural language processingsystems.The necessity of incorporating domain-specific semanticinformation into natural language processing systems is nowgenerally recognized.
The task we face as computational linguistslies in selecting this information, organizing it, and integratingit into a natural language processing system.In principle, no limit can be placed on the semantic knowledgeneeded for natural language analysis -- given essentially any fact,one can devise a natural language input which requires knowledge ofthat fact for its correct interpretation.
For the construction ofoperational systems, however, there are practical l imitations onour ability to collect and organize the domain-specific knowledgefor any substantial domain.
Rather than ignore such limitations,we should use them as a motivation for identifying manageablecomponents of this domaln-specific knowledge.
Such considerationsare especially important if we are aiming to construct _portablesystems -- systems which can be readily moved from one domain toanother.What properties should such a component have?
It should* be effective in providing the information needed to guidethe analysis of the input text;* have a ~ structure, to facilitate both the collectionof the information and its use in the language analysis procedures;* have a discoverv procedure -- a systematic way of collecting* Present affiliation: Research and Development Activity, Federaland Special Systems Group, Burroughs Corp., Paoli, PA.89R.G~SHMAN, L. HIRSCHMANandC.
FRIEDMAN6this information for a new domain.We suggest that a characterization of the structure ofinformation in a domain is such a semantic component.
We call thiscomponent a domain information schema (DIS).
A DIS specifies a setof semantic classes, the words and phrases which belong to theseclasses, and the predicate-argument relationships among members ofthese classes which are meaningful in this domain.
Some featuresof these relationships, such as functional dependencies betweensemantic classes, are also noted.This is not a novel assemblage of information.
The DIS isperhaps most similar to data base schemata which also seek toseparate a description of the structure of information in a domainfrom the specific facts about a domain.
In frame-based systems,this information is essentially captured by the top-level frames,although the delineation here between structural description andspecific facts is not as precise.
Semantic grammars embed much ofthe information of the DIS, although there it is mixed with generall inguistic knowledge.
Certain parsers (e.g., the RUS parser \[1\])also make use of aspects of information stored in a separatesemantic component.
Thus information similar to a DIS has beenused, at least implicitly, by other natural language systems;however, little research has been explicitly concerned with thetask of choosing a subset of the domain-specific information andevaluating it using criteria such as those mentioned above.
Wetherefore decided to address this question with respect to the DISin our recent research.To this end, we have recently modified portions of two largenatural language systems so that all domain-specific knowledge isisolated in a DIS.
One of these is a system for the informationformatting of natural language medical reports; the other, a"question-answering" system for data base retrieval using naturallanguage.
We shall report here on how information from the DIS isused in the various stages of analysis.
*THE SYSTEMSThe information formatting system \[2\] is designed to acceptnatural language text in some scientific or technical domain andmap the text into a domain-specific structure (an informationformat) which is suitable for subsequent retrieval operations.
Inessence, the format is a set of tables in which each category ofdomain information (for example, for hospital reports: laboratorytests, laboratory findings, diagnoses, treatments, etc.)
isassigned a separate column.
This formatting procedure has beensuccessfully applied to radiology reports and to hospital dischargesummaries.
The question-answering system \[3\] accepts naturallanguage queries regarding the data in the text and retrieves therequested information from the formatted data base.QBoth systems use the Linguistic String Pars~ and grammar \[4\]to obtain a parse and transformational decomposition of the inputsentence.
The grammar is an augmented context-free grammar writtenin Restriction Language \[5\].
In the formatting procedure, the* we have concurrently been investigating discovery procedures forDIS's; some of our early work in this area was r~ported in \[6\].NL INTERFACES USING LIMITED SEMANTIC INFORMATION 91decomposition tree is mapped into the information format; theformat then goes through a normalization component which fil ls inimplicit information and a component to analyze the time structureof the narrative.
For question answering, the decomposition treeis mapped into an extended predicate calculus formula; this isfollowed by anaphora resolution and translation of the formula intoa data base retrieval request.SELECTIONThe domain information schema is most directly reflected inthe syntax of the language, forming a sublanguage as described byHarris \[7\].
The semantic classes and relationships, as defined bythe DIS, are used to formulate sublanguage selectional constraints.These ~onstraints rule out incorrect syntactic analyses, many ofwhich are caused by structural ambiguity due to adjunct placementand conjunction, and by lexical ambiguity due to homographs.The selection mechanism is list driven to provide forportabil ity from one sublanguage to another.
These lists specifyfor each basic l inguistic relation, such as SUBJECT-VERB-OBJECT orHOST-ADJECTIVE, the patterns of word c lasseswh ich  are permissibleinthesublanguage.
Each basic l ingustic relation has many surfacerealizations for which selection must be checked.
TheSUBJECT-VERB-OBJECT relation, for instance, may appear indeclaratives and questions, in main and relative clauses, in activeand passive voice, in perfect and progressive forms, etc.
Thistask is greatly simplified, however, by the linguistic routines ofthe Restriction Language \[4,5\], which locate the elements of theparse tree bearing the underlying SUBJECT-VERB, VERB-OBJECT, andHOST-ADJUNCT relations.An example of how the DIS eliminates incorrect parses in themedical sublanguage can be seen in the sentence from a medical textBrother 18 also has heart disease, on cardiac meds.which has two analyses: one where "on cardiac meds" is an adjunctof "heart disease" and the other where it is an adjunct of"brother".
There is a HOST-ADJUNCT pattern for the classesFAMILY-MEMBER ON MEDICATION but not for DIAGNOSIS ON MEDICATION;thus only the second analysis has a pattern matching one  in theDIS.Matching the patterns is only one function of the selectionprocedure.
When a match is successful, those classes which matchthe pattern are recorded as "selected attributes" so that they maybe referenced at a further point in processing.
Once a pattern isestablished, the "selected attribute" classes are preferred to theoriginal ones.
Additional selectional constraints will refer tothe "selected attributes" of a word if it exists.
How thisprocedure aides in the disambiguation of homographs can be shownusing the homograph "discharge".
"Discharge" can be a medicaladministrative action (MED-VERB) as in "discharge from hospital" ora SIGN-SYMPTOM word as in "discharge from wound".
The phrase"discharge from hospital" will be successfully matched by thepattern MED-VERB FROM INSTITUTION; there is, in contrast, nopattern SIGN-SYMPTOM FROM INSTITUTION.
Thus in this phrase"discharge" is assigned a "selected attr ibute" MED-VERB and the92 R. GRISHMAN, L HIRSCHMAN and C. FRIEDMANSIGN-SYMPTOM class of "discharge" will be ignored.
This will heparticularly helpful in the information formatting stage, since themapping into the format is based primarily on a word's selectedsublanguage class.The selectional constraints are complicated by the fact thatthe class of a noun phrase is sometimes determined by the entirephrase and not by the head noun alone.
In some cases the class ofthe phrase is the class of one of its constituents.
For example,"stiff neck" has the same class as "stiff", which is a SIGN-SYMPTOMclass.
In other cases words from two classes combine to form aphrase with a different class.
In the medical domain, "temperatureof 103" is of the FINDING class because "temperature" is in theBODY-FUNCTION class and "103" is a quantifier.
This computation ofa phrasal attribute is called the "computed attribute"construction.
This attribute plays an important role ineliminating incorrect parses which arise with coordinateconjunction.
Noun phrase conjunction is restricted to phraseswhich are of the same or closely related classes.
In "Patient hadstiff neck and fever" there are two readings.
The reading in which"stiff" is the left adjunct of both "neck" and  "fever" iseliminated because "neck" and "fever" have different subclasses:"fever" is a SIGN-SYMPTOM word whereas "neck" is a BODY-PART word.However the phrase "stiff neck" has a SIGN-SYMPTOM "computedattribute" and is in the same class as "fever"~ therefore we doget the analysis where "fever" is conjoined to "stiff neck".
Amore detailed description of constraints on noun phrase conjunctionis described by Hirschman \[8\].FORMATTINGThe format itself can be viewed as a derivative of the DIS,obtained by merging several predicate-argument relations into asingle larger relation.
Because the formats, like thepredicate-argument relations, are based on the semantic classes ofthe DIS, the mapping from decomposition trees into formats can bedriven by a table of the correspondences between semantic classesand format columns.QUESTION-ANSWERINGThe predicate names used in the predicate calculusrepresentation within the question-answering system correspond tothe predicate-argument patterns of semantic classes in the DIS, sothe ~apping from decomposition trees to predicate calculusexpressions is also DIS-driven.
In addition, this mapping uses theinformation on functional dependencies recorded in the DIS:quantifier scoping is determined primarily by surface word orderand syntactic structure, but functional dependencies may takeprecedence.
For example, in the medical domain, because there is afunctional relation from "X-rays" to "patients" (each X-ray is ofone and only one patient), the phrase "the X-rays of the patients"is correctly analyzed with the quantifier over "patients" havingwider scope than the quantifier over "X-rays".The anaphora resolution component relies on the selectionmechanism described ear l ie r  (and hence on the DIS) to determinefrom context the possible semantic classes for the referent of anNL INTERFACES uSING LIMITED SEMANTIC INFORMATION 93anaphoric phrase; the antecedent search is then restricted tomembers of these classes.
In addition, the word classes are usedin distinguishing between definite and "one" anaphora (as definedby Webber \[9\]), and resolving "one" anaphora correctly \[10\].CONCLUSIONIn summary, the DIS has proven in these systems to be aneffective source of domaln-speclfic information.
Systemportability has been enhanced by using information of simplestructure which can be isolated from the lingulstic processingmechanisms.
At the same time, the simplicity of structure hasfacilitated the integration of this information into many stages o fthe analysis procedure.ACKNOWLEDGEMENTSThis research was supported in part by National ScienceFoundation grants MCS 80-02453 from the Division of Mathematicaland Computer Sciences and IST 81-15669 from the Division ofInformation Science and Technology; in part by National Library ofMedicine grant 1-R01-LM03933, awarded by the National InStitutes ofHealth, Department of Health and Human Services; and in part byOffice of Naval Research contract N00014-75-C-0571.REFERENCES\[i\] Bobrow, R.J. and Webber, B.L.
Knowledge Representation forSyntactic~Semantic Processing, First Annual Nat' IConf.
on~ Intelligence, 316-323, AAAI, Stanford, 1980.\[2\] Sager, N. Natural Language Information Formatting: TheAutomatic Conversion of Texts to a Structured Data Base.
InAdvances in E g ~  17 (M.C.
Yovlts, ed.
), 89-162 (AcademicPress, NY, 1978).\[3\] Grishman, R., and Hirschman, L. Question Answering fromNatural Language Medical Data Eases.
Artificial Intelliaence11 (1978), 25-43.\[4\] Sager, N. Natural ~ Information Processing(Addison-Wesley, 1981).\[5\] Sager, N., and Grlshman, R. The restriction language forcomputer grammars of natural language.
Comm.
ACM I~, 7 (July1975), 390-400.\[6\] Hirschman, L., Grishman, R., and Sager, N. Grammatically-BasedAutomatic word Class Formation.
~ Proceasinu andManaoement ii (1975), 39-57.\[7\] Harris, Z.
~ Structures of La~SI I~  (Interscience,New York, 1968).
k94 R. GRISHMAN, L. HIRSCHMAN and C. FRIEDMAN\[8\] Hirschman, L. Constraints on Noun Phrase Conjunction: aDomain-lndependenb Mechanism.
Proc.
COLING82 (this volume),\[9\] Webber, B.
~ Formal ~p~/~E~ to Discourge ~ (Garland,New York, 1979).\[10\] Grishman, R. Resolving Noun Phrase Anaphora.
Paper presentedat the Assn.
for Computational Linguistics meeting on"Computer Modeling of Linguistic Theory," New York, Dec. 28,1981.
