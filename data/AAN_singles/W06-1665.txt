Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 551?559,Sydney, July 2006. c?2006 Association for Computational LinguisticsContext-Dependent Term Relations for Information RetrievalJing Bai      Jian-Yun Nie     Guihong CaoDIRO, University of MontrealCP.
6128, succ.
Centre-ville, Montreal,Quebec H3C 3J7, Canada{baijing,nie,caogui}@iro.umontreal.caAbstractCo-occurrence analysis has been used todetermine related words or terms in manyNLP-related applications such as queryexpansion in Information Retrieval (IR).However, related words are usuallydetermined with respect to a single word,without relevant information for itsapplication context.
For example, the word?programming?
may be considered to bestrongly related to ?Java?, and appliedinappropriately to expand a query on ?Javatravel?.
To solve this problem, we proposeto add another context word in the relationto specify the appropriate context of therelation, leading to term relations of theform ?
(Java, travel) ?
Indonesia?.
Theextracted relations are used for queryexpansion in IR.
Our experiments onseveral TREC collections show that thisnew type of context-dependent relationsperforms much better than the traditionalco-occurrence relations.1.
IntroductionA query usually is a poor expression of aninformation need.
This is not only due to its shortlength (usually a few words), but also due to theinability of users to provide the best terms todescribe their information need.
At best, one canexpect that some, but not all, relevant terms areused in the query.
Query expansion thus aims toimprove query expression by adding relatedterms to the query.
However, the effect of queryexpansion is strongly determined by the termrelations used (Peat and Willett, 1991).
Forexample, even if ?programming?
is stronglyrelated to ?Java?, if this relation is used toexpand a query on ?Java travel?, the retrievalresult will likely deteriorate because theirrelevant term ?programming?
is introduced,leading to the retrieval of irrelevant documentsabout ?programming?.A number of attempts have been made to dealwith the problem of selecting appropriateexpansion terms.
For example, Wordnet has beenused in (Voorhees, 1994) to determine theexpansion terms.
However, the experiments didnot show improvement on retrieval effectiveness.Many experiments have been carried out usingassociative relations extracted from term co-occurrences; but they showed variable results(Peat and Willett, 1991).
In (Qiu and Frei, 1993),it is observed that one of the reasons is that onetried to determine expansion terms according toeach original query term separately, which mayintroduce much noise.
Therefore, they proposedto determine the expansion terms by summing upthe relations of a candidate expansion term toeach of the query terms.
In so doing, a candidateexpansion term is preferred if it has a strongrelationship with many of the query terms.However, it is still difficult to prevent theexpansion process from adding ?programming?to a query on ?Java travel?
because of its verystrong relation with ?Java?.The approach used in (Qiu and Frei, 1993)indeed tries to correct a handicap inherent in therelations: as term relations are created betweentwo single words such as ?Java ?programming?, no information is available tohelp determine the appropriate context to applyit.
The approach used in (Qiu and Frei, 1993) cansimply alleviate the problem without solving itradically.In this paper, we argue that the solution lies inthe relations themselves.
They have to containmore information to help determine theappropriate context to apply them.
We thuspropose a way to add some context informationinto the relations: we introduce an additionalword into the condition part of the relation, suchas ?
(Java, computer) ?
programming?, which551means ?programming?
is related to ?(Java,computer)?
together.
In so doing, we would beable to prevent from extracting and applying arelation such as ?
(Java, travel) ?programming?.In this paper, we will test the extractedrelations in query expansion for IR.
We choose toimplement query expansion within the languagemodeling (LM) framework because of itsflexibility and high performance.
Theexperiments on several TREC collections willshow that our query expansion approach canbring large improvements in retrievaleffectiveness.In the following sections, we will first reviewsome of the relevant approaches on queryexpansion and term relation extraction.
Then wewill describe our general IR models and theextraction of term relations.
The experimentalresults will be reported and finally someconclusions will be drawn.2.
Query Expansion and Term RelationsIt has been found that a key factor thatdetermines the effect of query expansion is theselection of appropriate expansion terms (Peatand Willett, 1991).
To determine expansionterms, one possible resource is thesauriconstructed manually, such as Wordnet.
Thesauricontain manually validated relations betweenterms, which can be used to suggest relatedterms.
(Voorhees, 1994) carried out a series ofexperiments on selecting related terms (e.g.synonyms, hyonyms, etc.)
from Wordnet.However, the experiments did not show that thiscan improve retrieval effectiveness.
Some of thereasons are as follows: Although Wordnetcontains many relations validated by humanexperts, the coverage is far from complete for thepurposes of IR: not only linguistically motivatedrelations, but also association relations, are usefulin IR.
Another problem is the lack of informationabout the appropriate context to apply relations.For example, Wordnet contains two synsets for?computer?, one for the sense of ?machine?
andanother for ?human expert?.
It is difficult toautomatically select the correct synset to expandthe word ?computer?
even if we know that thequery?s area is computer science.Another often used resource is associativerelations extracted from co-occurrences: twoterms that co-occur frequently are thought to beassociated to each other (Jing and Croft, 1994).However, co-occurrence relations are noisy:Frequently co-occurring terms are not necessarilyrelated.
On the other hand, they can also misstrue relations.
The most important problem is stillthat of ambiguity: when one term is associatedwith another, it may be related for one sense andnot for other possible senses.
It is then difficult todetermine when the relation applies.In most of the previous studies, relationsextracted are restricted between one word andanother.
This limitation makes the relationsambiguous, and their utilization in queryexpansion often introduces undesired terms.
Webelieve that the key to make a relation lessambiguous is to add some contextualinformation.In an attempt to select better expansion terms,(Qiu and Frei, 1993) proposed the followingapproach to select expansion terms: terms areselected according to their relation to the wholequery, which is calculated as the sum of theirrelations to each of the query terms.
Therefore, aterm that is related to several query terms will befavored.
In a similar vein, (Bai et al 2005) alsotry to determine the relationship of a word to agroup of words by combining its relationships toeach of the words in the group.
This can indeedselect better expansion terms.
The considerationof other query terms produces a weak contextualeffect.
However, this effect is limited due to thenature of the relations extracted, in which a termdepends on only one other term.
Much of thenoise in the sets will remain after selection.For a query composed of several words, whatwe would really like to have is a set of terms thatare related to all the words taken together (andnot separately).
By combining words in thecondition part such as ?
(Java, travel)?
or ?
(base,bat)?, each word will serve as a context to theother in order to constrain the related terms.
Inthese cases, we would expect that ?hotel?,?island?
or ?Indonesia?
would co-occur muchmore often with ?
(Java, travel)?
than?programming?, and ?ball?, ?catcher?
etc.
co-occur much more often with ?
(base, bat)?
than?animal?
or ?foundation?.One naturally would suggest that compoundterms can be used for this purpose.
However, formany queries, it is difficult to form a legitimatecompound term.
Even if we can detect oneoccurrence of a compound, we may miss othersthat use its variants.
For example, if ?Java travel?is used as a query, we will likely be able toconsider it as a compound term.
The samecompound (or its variant) would be difficult to552detect in a document talking about traveling toJava: the two words may appear at some distanceor not in some specific syntactic structure asrequired in (Lin, 1997).
This will lead to theproblem of mismatching between document andquery.In fact, compound terms are not the only wayto add contextual information to a word.
Byputting two words together (without forming acompound term), we usually obtain a moreprecise sense for each word.
For example, from?Java travel?, we can guess that the intendedmeaning is likely related to ?traveling to JavaIsland?.
People will not interpret thiscombination in the sense of ?Javaprogramming?.
In the same way, people wouldnot consider ?animal?
to be a related term to?base, bat?.
These examples show that in acombination of words, each word indeed servesto specify a context to interpret another word.
Itthen suggests the following approach: we canadjunct some additional word(s) in the conditionpart of a relation, such as ?
(Java, travel) ?Indonesia?, which means ?Indonesia?
is relatedto ?
(Java, travel)?
together.
It is expected thatone would not obtain ?
(Java, travel) ?programming?.Owing to the context effect explained above,we will call the relations with multiple words inthe condition part context-dependent relations.
Inorder to limit the computation complexity, wewill only consider adding one additional wordinto relations.The proposed approach follows the sameprinciple as (Yarowsky, 1995), which tried todetermine the appropriate word sense accordingto one relevant context word.
However, therequirement for query expansion is less thanword sense disambiguation: we do not need toknow the exact word sense to make expansion.We only need to determine the relevantexpansion terms.
Therefore, there is no need todetermine manually a set of seeds before thelearning process takes place.To some extent, the proposed approach is alsorelated to (Sch?tze and Pedersen, 1997), whichcalculate term similarity according to the wordsappearing in the same context, or to second-orderco-occurrences.
However, a key difference is that(Sch?tze and Pedersen, 1997) consider onlyseparate context words, while we considermultiple context words together.Once term relations are determined, they willbe used in query expansion.
The basic IR processwill be implemented in a language modelingframework.
This framework is chosen for itsflexibility to integrate term relations.
Indeed, theLM framework has proven to be capable ofintegrating term relations and query expansion(Bai et al, 2005; Berger and Lafferty, 1999; Zhaiand Lafferty, 2001).
However, none of the abovestudies has investigated the extraction of strongcontext-dependent relations from text collections.In the next section, we will describe thegeneral LM framework and our query expansionmodels.
Then the extraction of term relation willbe explained.3.
Context-Dependent Query Expansionin Language ModelsThe basic IR approach based on LM (Ponte andCroft, 1998) determines the score of relevance ofa document D by its probability to generate thequery Q.
By assuming independence betweenquery terms, we have:????
?=QwiQwiiiDwPDwPDQP )|(log)|()|(where )|( DwP i denotes the probability of a wordin the language model of the document D. As noambiguity will arise, we will use D to mean boththe language model of the document and thedocument itself (similarly for a query model anda query Q).Another score function is based on KL-divergence or cross entropy between thedocument model and the query model:?
?=VwiiiDwPQwPQDscore )|(log)|(),(where V is the vocabulary.
Although we haveboth document and query models in the aboveformulation, usually only the document model issmoothed, while the query model uses MaximumLikelihood Estimation (MLE) )|( QwP iML .
Thenwe have:?
?=QwiiMLiDwPQwPQDscore )|(log)|(),(However, it is obvious that a distance (KL-divergence) measured between a short query of afew words and a document cannot be precise.
Abetter expression would contain all the relatedterms.
The construction of a better queryexpression is the very motivation for queryexpansion in traditional IR systems.
It is the samein LM for IR: to create a better query expression(model) to be able to measure the distance to a553document in a more precise way.
The key tocreating the new model is the integration of termrelations.3.1 LM for Query ExpansionTerm relations have been used in several recentlanguage models in IR.
(Berger and Lafferty,1999) proposed a translation model that expandsthe document model.
The same approach can alsobe used to expand the query model.
Following(Berger and Lafferty, 1999), we arrive at the firstexpansion model as follows, which has also beenused in (Bai et al, 2005):Model 1: Context-independent queryexpansion model (CIQE)???
?==QqjMLjiRVqjiRiRjjQqPqwPQqwPQwP )|()|()|,()|(In this model, each original query term qj isexpanded by related terms wi.
The relationsbetween them are determined by )|( jiR qwP .
Wewill explain how this probability is defined inSection 3.2.
However, we can already see herethat wi is determined solely by one of the queryterm qj.
So, we call this model ?context-independent query expansion model?
(CIQE).The above expanded query model enables usto obtain new related expansion terms, to whichwe also have to add the original query.
This canbe obtained through the following smoothing:???+=QqjMLjiRiMLijQqPqwPQwPQwP)|()|()1()|()|(11??
(1)where 1?
is a smoothing parameter.However, if the query model is expanded onall the vocabulary (V), the query evaluation willbe very time consuming because the query andthe document have to be compared on every word(dimension).
In practice, we observe that only asmall number of terms have strong relations witha given term, and the terms having weak relationsusually are not truly related.
So we can limit theexpansion terms only to the strongly related ones.By doing this, we can also expect to filter outsome noise and considerably reduce the retrievaltime.Suppose that we have selected a set E ofstrong expansion terms.
Then we have:?????
?=QEwiiVwiiiiDwPQwPDwPQwPQDscore)|(log)|()|(log)|(),(This query expansion method uses the sameprinciple as (Qiu and Frei, 1993), but in a LMsetting: the selected expansion terms are thosethat are strongly related to all the query terms(this is what the summation means).
Theapproach used in (Bai et al, 2005) is slightlydifferent: A context vector is first built for eachword; then a context vector for a group of words(e.g.
a multi-word query) is composed from thecontext vectors of the words of the group; finallyrelated terms to the group of words aredetermined according to the similarity of theircontext vectors to that of the group.
This last stepuses second-order co-occurrences similarly to(Sch?tze and Pedersen, 1997).
In both (Qiu andFrei, 1993) and (Bai et al, 2005), the termsrelated to a group of words are determined fromtheir relations to each of the words in the group,while the latter relations are extracted separately.Irrelevant expansion terms can be retained.As we showed earlier, in many cases, whenone additional word is used with another word,the sense of each of them can usually be betterdetermined.
This additional word may besufficient to interpret correctly many multi-worduser queries.
Therefore, our goal is to extractstronger context-dependent relations of the form(qj qk) ?
wi, or to build a probabilityfunction )|( kjiR qqwP .
Once this function isdetermined, it can be integrated into a newlanguage model as follows.Model 2: Context-dependent query expansionmodel (CDQE)????
?=QqqkjkjiRVqqkjkjiRiRkjkjQqqPqqwPQqqPqqwPQwP,,)|()|()|()|()|(As )|( kjiR qqwP  is a relation with two terms ascondition, we will also call it a biterm relation.The name ?biterm?
is due to (Srikanth andSrihari, 2002), which means two terms co-occurring within some distance.
Similarly,)|( jiR qwP  will be called unigram relation.
Thecorresponding query models will be called bitermrelation model and unigram relation model.As in general LM, the biterm relation modelcan be smoothed with a unigram model.
Then wehave the following score function:???+=QqqkjkjiRiMLiRkjQqqPqqwPQwPQwP,22)|()|()1()|()|(??
(2)554where 2?
is another smoothing parameter.3.2 Extraction of Term RelationsThe key problem now is to obtain the relationswe need: )|( jiR wwP  and )|( kjiR wwwP .
For the firstprobability, as in many previous studies, weexploit term co-occurrences.
)|( jiR wwP  could bebuilt as a traditional bigram model.
However, thisis not a good approach for IR because two relatedterms do not necessarily co-occur side by side.They often appear at some distance.
Therefore,this model is indeed a biterm model (Srikanthand Srihari, 2002), i.e., we allow two terms beseparated within some distance.
We use thefollowing formula to determine this probability:?=lwjljijiRwwcwwcwwP),(),()|(where ),( ji wwc  is the frequency of co-occurrenceof the biterm ),( ji ww , i.e.
two terms in the samewindow of fixed size across the collection.
In ourcase, we set the window size at 10 (because thissize turned out to be reasonable in our pilotexperiments).For )|( kji wwwP , we further extend the bitermto triterm, and we use the frequency of co-occurrences of three terms ),,( kji wwwc  within thesame windows in the document collection:?=lwkjlkjikjiRwwwcwwwcwwwP),,(),,()|(The number of relations determined in thisway can be very large.
The upper bound for)|( ji wwP  and )|( kji wwwP  are respectivelyO(|V|2) and O(|V|3).
However, many relationshave very low probabilities and are often noise.As we only consider a subset of strong expansionterms, the relations with low probability arealmost never used.
Therefore, we set two filteringcriteria:?
The biterm in the condition of a relation shouldbe higher than a threshold (10 in our case);?
The probability of a relation should be higherthan another threshold (0.0001 in our case).?
One more filtering criterion is mutualinformation (MI), which reflects therelatedness of two terms in their combination),( kj ww .
To keep a relation )|( kji wwwP , werequire ),( kj ww  be a meaningful combination.We use the following pointwise MI (Churchand Hanks 1989):)()(),(log),(kjkjkjwPwPwwPwwMI =We only keep meaningful combinations suchthat 0),( >kj wwMI .By these filtering criteria, we are able toreduce considerably the number of biterms andtriterms.
For example, on a collection of about200MB, with a vocabulary size of about 148K,we selected only about 2.7M useful biterms andabout 137M triterms, which remain tractable.3.3 Probability of BitermsIn LM used in IR, each query term is attributedthe same weight.
This is equivalent to a uniformprobability distribution, i.e.
:Ui QQqP ||1)|( =where |Q|U is the number of unigrams in thequery.
In CIQE model, we use the same method.In CDQE, we also need to attribute aprobability )|( QqqP kj , to the biterm ),( kj qq .Several options are possible.Uniform probabilityThis simple approach distributes the probabilityuniformly among all biterms in the query, i.e.
:Bkj QQqqP ||1)|( =where BQ ||  is the number of biterms in Q.According to mutual informationIn a query, if two words are strongly associated,this also means that their association is moremeaningful to the query, thus should be weightedhigher.
Therefore, a natural way to assign aprobability to a biterm in the query is to usemutual information, which denotes the strengthof association between two words.
We use againthe pointwise mutual information MI(qj, qk).
If itis negative, we consider that the biterm is notmeaningful, and is ignored.
Therefore, we arriveat the following probability function:?
?=QqqmlkjkjmlqqMIqqMIQqqP)(),(),()|(where Qqq ml ?
)(  means all the meaningfulbiterms in the query.555Statistical parsingIn (Gao et al, 2002), a statistical parsingapproach is used to determine the bestcombination of translation words for a query.
Theapproach is similar to building a minimalspanning tree, which is also used in (Smeaton andVan Rijsbergen, 1983), to select the strongestterm relations that cover the whole query.
Thisapproach can also be used in our model todetermine the minimal set of the strongestbiterms that cover the query.In our experiments, we tested all the threeweighting schemas.
It turns out that the bestweighting is the one with MI.
Therefore, in thenext section, we will only report the results withthe second option.4.
Experimental EvaluationWe evaluate query expansion with differentrelations on four TREC collections, which aredescribed in Table 1.
All documents have beenprocessed in a standard manner: terms arestemmed using Porter stemmer and stopwords areremoved.
We only use titles of topics as queries,which contain 3.58 words per query on average.Table 1.
TREC collection statisticsColl.
Description Size (Mb) Vocab.
# Doc.
QueryAP Associated Press (1988-89) 491 196,933 164,597 51-100SJMSan JoseMercury News(1991)286 146,514 90,257 101-150WSJWall StreetJournal (1990-92)242 121,946 74,520 51-100In our experiments, the document modelremains the same while the query model changes.The document model uses the following Dirichletsmoothing:?
?++=UiMLii DCwPDwtfDwP ||)|(),()|(where ),( Dwtf i is the term frequency of wi in D,)|( CwP iML  is the collection model and ?
is theDirichlet prior, which is set at 1000 following(Zhai and Lafferty, 2001).There are two other smoothing parameters 1?
,and 2?
to be determined.
In our experiments, weuse a simple method to set them: the parametersare tuned empirically using a training collectioncontaining AP1989 documents and queries 101-150.
These preliminary tests suggest that the bestvalue of 1?
and 2?
(in Equations 1-2) arerelatively stable (we will show this later).
In theexperiments reported below, we will use 4.01 =?
,and 3.02 =?
.4.1 Experimental ResultsThe main experimental results are described inTable 2, which reports average precision withdifferent methods as well as the number ofrelevant documents retrieved.
UM is the basicunigram model without query expansion (i.e.
weuse MLE for the query model, while thedocument model is smoothed with Dirichletmethod).
CIQE is the context-independent queryexpansion model using unigram relations (Model1).
CDQE is the context-dependent queryexpansion model using biterm relations (Model2).
In the table, we also indicate whether theimprovement in average precision obtained isstatistically significant (t-test).Table 2.
Avg.
precision and RecallColl.#Rel.
UM CIQE CDQE0.2767 0.2902 (+5%*) 0.3383  (+22%**)[+17%**] AP 6101 3677 3897 40290.2017 0.2225 (+10%**) 0.2448 (+21%**)[+10%*] SJM 2559 1641 1761 18730.2373 0.2393 (+1%) 0.2710 (+14%**)[+13%*] WSJ 2172 1588 1626 1737* and ** indicate that the difference is statisticallysignificant according to t-test: * indicates p<0.05, **indicates p<0.01; (.)
is compared to UM and [.]
iscompared to CIQE.CIQE and CDQE vs. UMIt is interesting to observe that query expansion,either by CIQE or CDQE, consistentlyoutperforms the basic unigram model on all thecollections.
In all the cases except CIQE forWSJ, the improvements in average precision arestatistically significant.
At the same time, theincreases in the number of relevant documentsretrieved are also consistent with those in averageprecision.The improvement scales obtained with CIQEare relatively small: from 1% to 10%.
Thesecorrespond to the typical figure using thismethod.Comparing CIQE and CDQE, we can see thatcontext-dependent query expansion (CDQE)556always produces better effectiveness thancontext-independent expansion (CIQE).
Theimprovements range between 10% and 17%.
Allthe improvements obtained by CDQE arestatistically significant.
This result stronglysuggests that in general, the context-dependentterm relations identify better expansion termsthan context-independent unigram relations.
Thisconfirms our earlier hypothesis.Indeed, when we look at the expansionresults, we see that the expansion termssuggested by biterm relations are usually better.For example, the (stemmed) expansion terms forthe query ?insider trading?
suggestedrespectively by CIQE and CDQE are as follows:CIQE:  stock:0.0141 market:0.0113 US:0.0112year:0.0102 exchang:0.0101 trade:0.0092report:0.0082 price:0.0076 dollar:0.00711:0.0069 govern:0.0066 state:0.0065futur:0.0061 million:0.0061 dai:0.0060offici:0.0059 peopl:0.0059 york:0.0057issu:0.0057 ?CDQE:  secur:0.0161 charg:0.0158 stock:0.0137scandal:0.0128 boeski:0.0125 inform:0.0119street:0.0113 wall:0.0112 case:0.0106year:0.0090 million:0.0086 investig:0.0082exchang:0.0080 govern:0.0077 sec:0.0077drexel:0.0075 fraud:0.0071 law:0.0063ivan:0.0060 ?We can see that in general, the terms suggestedby CDQE are much more relevant.
In particular,it has been able to suggest ?boeski?
(Boesky)who is involved in an insider trading scandal.Several other terms are also highly relevant, suchas scandal, investing, sec, drexel, fraud, etc.The addition of these new terms does not onlyimprove recall.
Precision of top-rankeddocuments is also improved.
This can be seen inFigure 1 where we compare the full precision-recall curve for the AP collection for the threemodels.
We can see that at all the recall levels,the precision values always follow the followingorder: CDQE > UM.
The same observation isalso made on the other collections.
This showsthat the CDQE method does not increase recall tothe detriment of precision, but both of them.
Incontrast, CIQE increases precision at all but 0.0recall points: the precision at the 0.0 recall pointis 0.6565 for CIQE and 0.6699 for UM.
Thisshows that CIQE can slightly deteriorate the top-ranked few documents.Figure 1.
Comparison of three models on AP00.10.20.30.40.50.60.70.80 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1RecallPrecision CDQECIQEUMCDQE vs. Pseudo-relevance feedbackPseudo-relevance feedback is widely consideredto be an effective query expansion method.
Inmany previous experiments, it produced verygood results.
The mixture model (Zhai andLafferty, 2001) is a representative and effectivemethod to implement pseudo-relevance feedback:It uses a set of feedback documents to smooth theoriginal query model.
Compared to the mixturemodel, our CDQE method is also more effective:By manually tuning the parameters of the mixturemodel to their best, we obtained the averageprecisions of 0.3171, 0.2393 and 0.2565respectively for AP, SJM and WSJ collections.These values are lower than those obtained withCDQE, which has not been heavily tuned.For the same query ?insider trading?, the mixturemodel determines the following expansion terms:Mixture: stock:0.0259256 secur:0.0229553market:0.0157057 sec:0.013992inform:0.011658 firm:0.0110419exchang:0.0100346 law:0.00827076bill:0.007996 case:0.00764544profit:0.00672575 investor:0.00662856japan:0.00625859 compani:0.00609675commiss:0.0059618 foreign:0.00582441bank:0.00572947 investig:0.00572276We can see that some of these terms overlap withthose suggested by biterm relations.
However,interesting words such as boeski, drexel andscandal are not suggested.The above comparison shows that our methodoutperforms the state-of-the-art methods of queryexpansion developed so far.4.2 Effect of the Smoothing ParameterIn the previous experiments, we have fixed thesmoothing parameters.
In this series of tests, we557analyze the effect of this smoothing parameter onretrieval effectiveness.
The following figureshows the change of average precision (AvgP)using CDQE (Model 2) along with the change ofthe parameter 2?
(UM is equivalent to 12 =?
).Figure 2.
Effectiveness w.r.t.
2?0.150.20.250.30.350.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1LambdaAvg.P APWSJSJMWe can see that for all the three collections,the effectiveness is good when the parameter isset in the range of 0.1-0.5.
The best value fordifferent collections remains stable: 0.2-0.3.The effect of 1?
on Model 1 is slightlydifferent, but we observe the same trend.4.3 Number of Expansion TermsIn the previous tests, we limit the number ofexpansion terms to 80.
When different numbersof expansion terms are used, we obtain differenteffectiveness measures.
The following figureshows the variation of average precision (AvgP)with different numbers of expansion terms, usingCDQE method.Figure 3.
Effectiveness w.r.t.
#expansion terms0.150.200.250.300.3510 20 40 80 150 300No.
expansion termsAvg.P APWSJSJMWe can see that when more expansion termsare added, the effectiveness does not alwaysincrease.
In general, a number around 80 willproduce good results.
In some cases, even ifbetter effectiveness can be obtained with moreexpansion terms, the retrieval time is also longer.The number 80 seems to produce a goodcompromise between effectiveness and retrievalspeed: the retrieval time remains less than 1 sec.per query.4.4 Suitability of Relations AcrossCollectionsIn many real applications (e.g.
Web search), wedo not have a static document collection fromwhich relations can be extracted.
The question iswhether it is possible and beneficial to extractrelations from one text collection and use them toretrieve documents in another text collection.
Ourintuition is that this is possible because therelations (especially context-dependent relations)encode general knowledge, which can be appliedto a different collection.
In order to show this, weextracted term relations from each collection, andapplied them on other collections.
The followingtables show the effectiveness produced usingrespectively unigram and bi-term relations.Table 3.
Cross-utilization of relationsUnigram relation Biterm relationRel.Coll.
AP SJM WSJ AP SJM WSJAP 0.2902  0.2803  0.2793 0.3383 0.3057 0.2987SJM 0.2271 0.2225 0.2267 0.2424 0.2448 0.2453WSJ 0.2541  0.2445  0.2393 0.2816 0.2636 0.2710From this table, we can observe that relationsextracted from any collection are useful to somedegree: they all outperform UM (see Table 2).
Inparticular, the relations extracted from AP are thebest for almost all the collections.
This can beexplained by the larger size and wider coverageof the AP collection.
This suggests that we do notnecessarily need to extract term relations fromthe same text collection on which retrieval isperformed.
It is possible to extract relations froma large text collection, and apply them to othercollections.
This opens the door to the possibilityof constructing a general relation base for variousdocument collections.5.
Related WorkCo-occurrence analysis is a common method todetermine term relations.
The previous studieshave been limited to relations between twowords, which we called unigram relations.
Thisexpansion approach has been integrated both intraditional retrieval models (Jing and Croft,1994) and in LM (Berger and Lafferty 1999).
Aswe observed, this type of relation will introducemuch noise into the query, leading to unstableeffectiveness.Several other studies tried to filter out noiseexpansion (or translation) terms by consideringthe relations between them (Gao et al, 2002;558Jang et al 1999; Qiu and Frei, 1993; Bai et al2005).
However, this is insufficient to detect allthe noise.
The key issue is the ambiguity ofrelations due to the lack of context information inthe relations.
In this paper, we proposed a methodto add some context information into relations.
(Lin, 1997) also tries to solve word ambiguityby adding syntactic dependency as context.However, our approach does not requiredetermining syntactic dependency.
The principleof our approach is more similar to (Yarowsky,1995).
Compared to this latter, our approach isless demanding: we do not need to identifymanually the exact word senses and seed contextwords.
The process is fully automatic.
Thissimplification is made possible due to therequirement for IR: only in-context related wordsare required, but not the exact senses.Our work is also related to (Smadja andMcKeown, 1996), which tries to determine thetranslation of collocations.
Term combinations orbiterms we used can be viewed as collocations.Again, there is much less constraint for ourrelated terms than translations in (Smadja andMcKeown, 1996).6.
ConclusionsIn many NLP applications such as IR, we need todetermine relations between terms.
In mostprevious studies, one tries to determine therelated terms to one single term (word).
Thismakes the resulting relations ambiguous.Although several approaches have been proposedto remove afterwards some of the inappropriateterms, this only affects part of the noise, andmuch still remains.
In this paper, we argue thatthe solution to this problem lies in the addition ofcontext information in the relations betweenterms.
We proposed to add another word in thecondition of the relations so as to help constrainthe context of application.
Our experimentsconfirm that this addition of limited contextinformation can indeed improve the quality ofterm relations and query expansion in IR.In this paper, we only compared bitermrelations and unigram relations, the generalmethod can be extended to triterm relations ormore complex relations, provided that they canbe extracted efficiently.This paper only investigated the utilization ofcontext-dependent relations in IR.
These relationscan be applied in many other tasks, such asmachine translation, word sense disambiguation /discrimination, and so on.
These are someinteresting research work in the future.ReferencesBai, J., Song, D., Bruza, P., Nie, J. Y. and Cao, G.2005.
Query expansion using term relationships inlanguage models for information retrieval, ACMCIKM, pp.
688-695.Berger, A. and Lafferty, J.
1999.
Information retrievalas statistical translation.
ACM SIGIR, pp.
222-229.Church, K. W. and Hanks, P. 1989.
Word associationnorms, mutual information, and lexicography.
ACL,Vol.
16, pp.
22-29.Gao, J., Nie, J.Y., He, H, Chen, W., Zhou, M. 2002.Resolving query translation ambiguity using adecaying co-occurrence model and syntacticdependency relations.
ACM SIGIR, pp.
11-15.Jang, M. G., Myaeng, S. H., and Park, S. Y.
1999.Using mutual information to resolve querytranslation ambiguities and query term weighting.ACL, pp.
223-229.Jing, Y. and Croft, W.B.
1994.
An associationthesaurus for information retrieval.
RIAO, pp.
146-160.Lin, D. 1997.
Using syntactic dependency as localcontext to resolve word sense ambiguity, ACL, pp.64-71.Peat, H.J.
and Willett, P. 1991.
The limitations of termco-occurrence data for query expansion in documentretrieval systems.
JASIS, 42(5): 378-383.Ponte, J. and Croft, W.B.
1998.
A language modelingapproach to information retrieval.
ACM SIGIR, pp.275-281.Qiu, Y. and Frei, H.P.
1993.
Concept based queryexpansion.
ACM SIGIR, pp.160-169.Sch?tze, H. and Pedersen J.O.
1997.
A cooccurrence-based thesaurus and two applications to informationretrieval, Information Processing and Management,33(3): 307-318.Smeaton, A. F. and Van Rijsbergen, C. J.
1983.
Theretrieval effects of query expansion on a feedbackdocument retrieval system.
Computer Journal, 26(3):239-246.Smadja, F., McKeown, K.R., 1996.
Translatingcollocations for bilingual lexicons: A statisticalapproach, Computational Linguistics, 22(1): 1-38.Srikanth, M. and Srihari, R. 2002.
Biterm languagemodels for document retrieval.
ACM SIGIR, pp.
425-426Voorhees, E. 1994.
Query expansion using lexical-semantic relations.
ACM SIGIR, pp.
61-69.Yarowsky, D. 1995.
Unsupervised word sensedisambiguation rivaling supervised methods.
ACL,pp.
189-196.Zhai, C. and Lafferty, J.
2001.
Model-based feedbackin the language modeling approach to informationretrieval.
ACM SIGIR, pp.
403-410.559
