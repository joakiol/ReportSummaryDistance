Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 760?767,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsGuided Learning for Bidirectional Sequence ClassificationLibin ShenBBN TechnologiesCambridge, MA 02138, USAlshen@bbn.comGiorgio SattaDept.
of Inf.
Eng?g.University of PaduaI-35131 Padova, Italysatta@dei.unipd.itAravind K. JoshiDepartment of CISUniversity of PennsylvaniaPhiladelphia, PA 19104, USAjoshi@seas.upenn.eduAbstractIn this paper, we propose guided learning,a new learning framework for bidirectionalsequence classification.
The tasks of learn-ing the order of inference and training thelocal classifier are dynamically incorporatedinto a single Perceptron like learning algo-rithm.
We apply this novel learning algo-rithm to POS tagging.
It obtains an error rateof 2.67% on the standard PTB test set, whichrepresents 3.3% relative error reduction overthe previous best result on the same data set,while using fewer features.1 IntroductionMany NLP tasks can be modeled as a sequence clas-sification problem, such as POS tagging, chunking,and incremental parsing.
A traditional method tosolve this problem is to decompose the whole taskinto a set of individual tasks for each token in the in-put sequence, and solve these small tasks in a fixedorder, usually from left to right.
In this way, the out-put of the previous small tasks can be used as theinput of the later tasks.
HMM and MaxEnt MarkovModel are examples of this method.Lafferty et al (2001) showed that this approachsuffered from the so called label bias problem (Bot-tou, 1991).
They proposed Conditional RandomFields (CRF) as a general solution for sequence clas-sification.
CRF models a sequence as an undirectedgraph, which means that all the individual tasks aresolved simultaneously.
Taskar et al (2003) improvedthe CRF method by employing the large marginmethod to separate the gold standard sequence la-beling from incorrect labellings.
However, the com-plexity of quadratic programming for the large mar-gin approach prevented it from being used in largescale NLP tasks.Collins (2002) proposed a Perceptron like learn-ing algorithm to solve sequence classification in thetraditional left-to-right order.
This solution does notsuffer from the label bias problem.
Compared to theundirected methods, the Perceptron like algorithmis faster in training.
In this paper, we will improveupon Collins?
algorithm by introducing a bidirec-tional searching strategy, so as to effectively utilizemore context information at little extra cost.When a bidirectional strategy is used, the mainproblem is how to select the order of inference.
Tsu-ruoka and Tsujii (2005) proposed the easiest-first ap-proach which greatly reduced the computation com-plexity of inference while maintaining the accuracyon labeling.
However, the easiest-first approach onlyserves as a heuristic rule.
The order of inference isnot incorporated into the training of the MaxEnt clas-sifier for individual labeling.Here, we will propose a novel learning frame-work, namely guided learning, to integrate classifi-cation of individual tokens and inference order selec-tion into a single learning task.
We proposed a Per-ceptron like learning algorithm (Collins and Roark,2004; Daume?
III and Marcu, 2005) for guided learn-ing.
We apply this algorithm to POS tagging, a clas-sic sequence learning problem.
Our system reportsan error rate of 2.67% on the standard PTB test set,a relative 3.3% error reduction of the previous bestsystem (Toutanova et al, 2003) by using fewer fea-tures.
By using deterministic search, it obtains anerror rate of 2.73%, a 5.9% relative error reduction760over the previous best deterministic algorithm (Tsu-ruoka and Tsujii, 2005).The new POS tagger is similar to (Toutanova etal., 2003; Tsuruoka and Tsujii, 2005) in the waythat we employ context features.
We use a bidi-rectional search strategy (Woods, 1976; Satta andStock, 1994), and our algorithm is based on Percep-tron learning (Collins, 2002).
A unique contributionof our work is on the integration of individual clas-sification and inference order selection, which arelearned simultaneously.2 Guided Learning for BidirectionalLabelingWe first present an example of POS tagging to showthe idea of bidirectional labeling.
Then we presentthe inference algorithm and the learning algorithm.2.1 An Example of POS taggingSuppose that we have an input sentenceAgatha found that book interestingw1 w2 w3 w4 w5(Step 0)If we scan from left to right, we may find itdifficult to resolve the ambiguity of the label forthat, which could be either DT (determiner), orIN (preposition or subordinating conjunction) in thePenn Treebank.
However, if we resolve the labels forbook and interesting, it would be relatively easy tofigure out the correct label for that.Now, we show how bidirectional inference workson this sample.
Suppose we use beam search withwidth of 2, and we use a window of (-2, 2) for con-text features.For the first step, we enumerate hypotheses foreach word.
For example, found could have a labelVBN or VBD.
Suppose that at this point the mostfavorable action, out of the candidate hypotheses, isthe assignment of NN to book, according to the con-text features defined on words.
Then, we resolve thelabel for book first.
We maintain the top two hy-potheses as shown below.
Here, the second most fa-vorable label for book is VB.NNVBAgatha found that book interestingw1 w2 w3 w4 w5(Step 1)At the second step, assume the most favorable ac-tion is the assignment of label JJ to interesting inthe context of NN for book.
Then we maintain thetop two hypotheses for span book interesting asshown below.
The second most favorable label forinteresting is still JJ, but in the context of VB forbook.NN------JJVB------JJAgatha found that book interestingw1 w2 w3 w4 w5(Step 2)Then, suppose we are most confident for assigninglabels VBD and VBN to found, in that order.
We gettwo separated tagged spans as shown below.VBD NN------JJVBN VB------JJAgatha found that book interestingw1 w2 w3 w4 w5(Step 3)In the next step, suppose we are most confident forassigning label DT to that under the context of VBDon the left and NN-JJ on the right side, as shownbelow (second most favorable action, not discussedhere, is also displayed).
After tagging w3, two sep-arated spans merge into one, starting from found tointeresting.VBD---DT---NN------JJVBD---IN---NN------JJAgatha found that book interestingw1 w2 w3 w4 w5(Step 4)For the last step, we assign label NNP to Agatha,which could be an out-of-vocabulary word, under thecontext of VBD-DT on the right.NNP---VBD---DT---NN------JJNNP---VBD---IN---NN------JJAgatha found that book interestingw1 w2 w3 w4 w5(Step 5)This simple example has shown the advantage ofadopting a flexible search strategy.
However, it isstill unclear how we maintain the hypotheses, howwe keep candidates and accepted labels and spans,and how we employ dynamic programming.
We willanswer these questions in the formal definition of theinference algorithm in the next section.7612.2 Inference AlgorithmTerminology: Let the input sequence bew1w2 ?
?
?wn.
For each token wi, we are expectedto assign a label ti ?
T, with T the label set.A subsequence wi ?
?
?wj is called a span, and isdenoted [i, j].
Each span p considered by the al-gorithm is associated with one or more hypotheses,that is, sequences over T having the same length asp.
Part of the label sequence of each hypothesis isused as a context for labeling tokens outside the spanp.
For example, if a tri-gram model is adopted, weuse the two labels on the left boundary and the twolabels on the right boundary of the hypothesis for la-beling outside tokens.
The left two labels are calledthe left interface, and the right two labels are calledthe right interface.
Left and right interfaces haveonly one label in case of spans of length one.A pair s = (Ileft , Iright) with a left and a rightinterface is called a state.
We partition the hypothe-ses associated with span p into sets compatible withthe same state.
In practice, for span p, we use a ma-trix Mp indexed by states, so that Mp(s), s = (Ileft ,Iright), is the set of all hypotheses associated with pthat are compatible with Ileft and Iright .For a span p and a state s, we denote the associatedtop hypothesis ass.T = argmaxh?Mp(s)V (h),where V is the score of a hypothesis (defined in (1)below).
Similarly, we denote the top state for p asp.S = argmaxs: Mp(s) 6=?V (s.T ).Therefore, for each span p, we have a top hypothe-sis p.S.T , whose score is the highest among all thehypotheses for span p.Hypotheses are started and grown by means oflabeling actions.
For each hypothesis h associatedwith a span p we maintain its most recent labelingaction h.A, involving some token within p, as wellas the states h.SL and h.SR that have been used ascontext by such an action, if any.
Note that h.SL andh.SR refer to spans that are subsequences of p. Werecursively compute the score of h asV (h) = V (h.SL.T ) + V (h.SR.T ) + U(h.A), (1)Algorithm 1 Inference AlgorithmRequire: token sequence w1 ?
?
?wn;Require: beam width B;Require: weight vector w;1: Initialize P , the set of accepted spans;2: Initialize Q, the queue of candidate spans;3: repeat4: span p?
?
argmaxp?Q U(p.S.T.A);5: Update P with p?
;6: Update Q with p?
and P ;7: until (Q = ?
)where U is the score of an action.
In other words,the score of an hypothesis is the sum of the scoreof the most recent action h.A and the scores of thetop hypotheses of the context states.
The score ofan action h.A is computed through a linear functionwhose weight vector is w, asU(h.A) = w ?
f(h.A), (2)where f(h.A) is the feature vector of action h.A,which depends on h.SL and h.SR.Algorithm: Algorithm 1 is the inference algorithm.We are given the input sequence and two parame-ters, beam width B to determine the number of statesmaintained for each span, and weight vector w usedto compute the score of an action.We first initialize the set P of accepted spans withthe empty set.
Then we initialize the queue Q ofcandidate spans with span [i, i] for each token wi,and for each t ?
T assigned to wi we setM[i,i]((t, t)) = {i?
t},where i ?
t represents the hypothesis consisting ofa single action which assigns label t to wi.
This pro-vides the set of starting hypotheses.As for the example Agatha found that bookinteresting in the previous subsection, we have?
P = ??
Q = {[1, 1], [2, 2], [3, 3], [4, 4], [5, 5]}Suppose NN and VB are the two possible POS tagsfor w4 book.
We have?
M[4,4](NN, NN) = {h441 = 4?
NN}?
M[4,4](VB, VB) = {h442 = 4?
VB}The most recent action of hypothesis h441 is to as-sign NN to w4.
According to Equation (2), the score762of this action U(h441.A) depends on the features de-fined on the local context of action.
For example,f1001(h441.A) ={1 if t = NN ?
w?1 = that0 otherwise,where w?1 represents the left word.
It should benoted that, for all the features depending on theneighboring tags, the value is always 0, since thosetags are still unknown in the step of initialization.Since this operation does not depend on solved tags,we have V (h441) = U(h411.A), according to Equa-tion (1).The core of the algorithm repeatedly selects a can-didate span from Q, and uses it to update P and Q,until a span covering the whole sequence is added toP and Q becomes empty.
This is explained in detailbelow.At each step, we remove from Q the span p?
suchthat the action (not hypothesis) score of its top hy-pothesis, p?.S.T , is the highest.
This represents thelabeling action for the next move that we are mostconfident about.
Now we need to update P and Qwith the selected span p?.
We add p?
to P , and re-move from P the spans included in p?, if any.
LetS be the set of removed spans.
We remove from Qeach span which takes one of the spans in S as con-text, and replace it with a new candidate span takingp?
(and another accepted span) as context.
We alwaysmaintain B different states for each span.Back to the previous example, after Step 3 is com-pleted, w2 found, w4 book and w5 interestinghave been tagged and we have?
P = {[2, 2], [4, 5]}?
Q = {[1, 2], [2, 5]}There are two candidate spans in Q, each with its as-sociated hypotheses and most recent actions.
Morespecifically, we can either solve w1 based on the con-text hypotheses for [2, 2], resulting in span [1, 2], orelse solve w3 based on the context hypotheses in[2, 2] and [4, 5], resulting in span [2, 5].The top two states for span [2, 2] are?
M[2,2](VBD, VBD) = {h221 = 2?
VBD}?
M[2,2](VBN, VBN) = {h222 = 2?
VBN}and the top two states for span [4, 5] are?
M[4,5](NN-JJ, NN-JJ)= {h451 = (NN,NN)5?
JJ}?
M[4,5](VB-JJ, VB-JJ)= {h452 = (VB,VB)5?
JJ}Here (NN,NN)5 ?
JJ represents the hypothesiscoming from the action of assigning JJ to w5 underthe left context state of (NN,NN).
(VB,VB)5 ?
JJhas a similar meaning.1We first compute the hypotheses resulting from allpossible POS tag assignments to w3, under all possi-ble state combinations of the neighboring spans [2, 2]and [4, 5].
Suppose the highest score action consistsin the assignment of DT under the left context state(VBD, VBD) and the right context state (NN-JJ, NN-JJ).
We obtain hypothesis h251 = (VBD,VBD)3 ?DT(NN-JJ, NN-JJ) withV (h251) = V ((VBD,VBD).T ) +V ((NN-JJ,NN-JJ).T ) + U(h251.A)= V (h221) + V (h451) +w ?
f(h251.A)Here, features for action h251.A may depend onthe left tag VBD and right tags NN-JJ, which havebeen solved before.
More details of the feature func-tions are given in Section 4.2.
For example, we canhave features likef2002(h251.A) ={1 if t = DT ?
t+2 = JJ0 otherwise,We maintain the top two states with the highesthypothesis scores, if the beam width is set to two.We have?
M[2,5](VBD-DT, NN-JJ) = {h251 =(VBD,VBD)3?
DT(NN-JJ,NN-JJ)}?
M[2,5](VBD-IN, NN-JJ) = {h252 =(VBD,VBD)3?
IN(NN-JJ,NN-JJ)}Similarly, we compute the top hypotheses andstates for span [1, 2].
Suppose now the hypothesiswith the highest action score is h251.
Then we up-date P by adding [2, 5] and removing [2, 2] and [4, 5],which are covered by [2, 5].
We also update Q by re-moving [2, 5] and [1, 2],2 and add new candidate span[1, 5] resulting in?
P = {[2, 5]}?
Q = {[1, 5]}1It should be noted that, in these cases, each state con-tains only one hypothesis.
However, if the span is longer than4 words, there may exist multiple hypotheses for the samestate.
For example, hypotheses DT-NN-VBD-DT-JJ and DT-NN-VBN-DT-JJ have the same left interface DT-NN and rightinterface DT-JJ.2Span [1, 2] depends on [2, 2] and [2, 2] has been removedfrom P .
So it is no longer a valid candidate given the acceptedspans in P .763The algorithm is especially designed in such a waythat, at each step, some new span is added to P orelse some spans already present in P are extendedby some token(s).
Furthermore, no pair of overlap-ping spans is ever found in P , and the number ofpairs of overlapping spans that may be found in Q isalways bounded by a constant.
This means that thealgorithm performs at most n iterations, and its run-ning time is therefore O(B2n), that is, linear in thelength of the input sequence.2.3 Learning AlgorithmIn this section, we propose guided learning, a Per-ceptron like algorithm, to learn the weight vector w,as shown in Algorithm 2.
We use p?.G to representthe gold standard hypothesis on span p?.For each input sequence Xr and the gold standardsequence of labeling Yr, we first initialize P and Qas in the inference algorithm.
Then we select thespan for the next move as in Algorithm 1.
If p?.S.T ,the top hypothesis of the selected span p?, is com-patible with the gold standard, we update P and Qas in Algorithm 1.
Otherwise, we update the weightvector in the Perceptron style, by promoting the fea-tures of the gold standard action, and demoting thefeatures of the action of the top hypothesis.
Thenwe re-generate the queue Q with P and the updatedweight vector w. Specifically, we first remove all theelements in Q, and then generate hypotheses for allthe possible spans based on the context spans in P .Hypothesis scores and action scores are calculatedwith the updated weight vector w.A special aspect of Algorithm 2 is that we main-tain two scores: the score of the action represents theconfidence for the next move, and the score of thehypothesis represents the overall quality of a partialresult.
The selection for the next action directly de-pends on the score of the action, but not on the scoreof the hypothesis.
On the other hand, the score of thehypothesis is used to maintain top partial results foreach span.We briefly describe the soundness of the GuidedLearning Algorithm in terms of two aspects.
First,in Algorithm 2 weight update is activated wheneverthere exists an incorrect state s, the action score ofwhose top hypothesis s.T is higher than that of anystate in each span.
We demote this action and pro-mote the gold standard action on the same span.Algorithm 2 Guided Learning AlgorithmRequire: training sequence pairs {(Xr, Yr)}1?r?R;Require: beam width B and iterations I;1: w?
0;2: for (i?
1; i ?
I; i++) do3: for (r ?
1; r ?
R; r++) do4: Load sequence Xr and gold labeling Yr.5: Initialize P , the set of accepted spans6: Initialize Q, the queue of candidate spans;7: repeat8: p?
?
argmaxp?Q U(p.S.T.A);9: if (p?.S.T = p?.G) then10: Update P with p?
;11: Update Q with p?
and P ;12: else13: promote(w, f(p?.G.A));14: demote(w, f(p?.S.T.A));15: Re-generate Q with w and P ;16: end if17: until (Q = ?
)18: end for19: end forHowever, we do not automatically adopt the goldstandard action on this span.
Instead, in the nextstep, the top hypothesis of another span might be se-lected based on the score of action, which means thatit becomes the most favorable action according to theupdated weights.As a second aspect, if the action score of a goldstandard hypothesis is higher than that of any oth-ers, this hypothesis and the corresponding span areguaranteed to be selected at line 8 of Algorithm 2.The reason for this is that the scores of the contexthypotheses of a gold standard hypothesis must beno less than those of other hypotheses of the samespan.
This could be shown recursively with respectto Equation 1, because the context hypotheses of agold standard hypothesis are also compatible withthe gold standard.Furthermore, if we take(xi = f(p?.G.A)?
f(p?.S.T.A), yi = +1)as a positive sample, and(xj = f(p?.S.T.A)?
f(p?.G.A), yj = ?1)as a negative sample, the weight updates at lines 13764and 14 are a stochastic approximation of gradient de-scent that minimizes the squared errors of the mis-classified samples (Widrow and Hoff, 1960).
Whatis special with our learning algorithm is the strategyused to select samples for training.In general, this novel learning framework lies be-tween supervised learning and reinforcement learn-ing.
Guided learning is more difficult than super-vised learning, because we do not know the order ofinference.
The order is learned automatically, andpartial output is in turn used to train the local clas-sifier.
Therefore, the order of inference and the lo-cal classification are dynamically incorporated in thelearning phase.Guided learning is not as hard as reinforcementlearning.
At each local step in learning, we alwaysknow the undesirable labeling actions according tothe gold standard, although we do not know whichis the most desirable.
In this approach, we can eas-ily collect the automatically generated negative sam-ples, and use them in learning.
These negative sam-ples are exactly those we will face during inferencewith the current weight vector.In our experiments, we have used Averaged Per-ceptron (Collins, 2002; Freund and Schapire, 1999)and Perceptron with margin (Krauth and Me?zard,1987) to improve performance.3 Related WorksTsuruoka and Tsujii (2005) proposed a bidirectionalPOS tagger, in which the order of inference is han-dled with the easiest-first heuristic.
Gime?nez andMa`rquez (2004) combined the results of a left-to-right scan and a right-to-left scan.
In our model, theorder of inference is dynamically incorporated intothe training of the local classifier.Toutanova et al (2003) reported a POS taggerbased on cyclic dependency network.
In their work,the order of inference is fixed as from left to right.
Inthis approach, large beam width is required to main-tain the ambiguous hypotheses.
In our approach, wecan handle tokens that we are most confident aboutfirst, so that our system does not need a large beam.As shown in Section 4.2, even deterministic infer-ence shows rather good results.Our guided learning can be modeled as a searchalgorithm with Perceptron like learning (Daume?
IIIand Marcu, 2005).
However, as far as we know,Data Set Sections Sentences TokensTraining 0-18 38,219 912,344Develop 19-21 5,527 131,768Test 22-24 5,462 129,654Table 1: Data set splitsthe mechanism of bidirectional search with an on-line learning algorithm has not been investigated be-fore.
In (Daume?
III and Marcu, 2005), as wellas other similar works (Collins, 2002; Collins andRoark, 2004; Shen and Joshi, 2005), only left-to-right search was employed.
Our guided learning al-gorithm provides more flexibility in search with anautomatically learned order.
In addition, our treat-ment of the score of action and the score of hypoth-esis is unique (see discussion in Section 2.3).Furthermore, compared to the above works, ourguided learning algorithm is more aggressive onlearning.
In (Collins and Roark, 2004; Shen andJoshi, 2005), a search stops if there is no hypothe-sis compatible with the gold standard in the queueof candidates.
In (Daume?
III and Marcu, 2005), thesearch is resumed after some gold standard compat-ible hypotheses are inserted into a queue for futureexpansion, and the weights are updated correspond-ingly.
However, there is no guarantee that the up-dated weights assign a higher score to those insertedgold standard compatible hypotheses.
In our algo-rithm, the gold standard compatible hypotheses areused for weight update only.
As a result, after eachsentence is processed, the weight vector can usuallysuccessfully predict the gold standard parse.
There-fore our learning algorithm is aggressive on weightupdate.As far as this aspect is concerned, our algorithmis similar to the MIRA algorithm in (Crammer andSinger, 2003).
In MIRA, one always knows the cor-rect hypothesis.
In our case, we do not know thecorrect order of operations.
So we use our form ofweight update to implement aggressive learning.4 Experiments on POS Tagging4.1 SettingsWe apply our guided learning algorithm to POS tag-ging.
We carry out experiments on the standarddata set of the Penn Treebank (PTB) (Marcus et al,1994).
Following (Ratnaparkhi, 1996; Collins, 2002;Toutanova et al, 2003; Tsuruoka and Tsujii, 2005),765Feature Sets Templates Error%A Ratnaparkhi?s 3.05B A + [t0, t1], [t0, t?1, t1], [t0, t1, t2] 2.92C B + [t0, t?2], [t0, t2], [t0, t?2, w0], [t0, t?1, w0], [t0, t1, w0],[t0, t2, w0], [t0, t?2, t?1, w0], [t0, t?1, t1, w0], [t0, t1, t2, w0]2.84D C + [t0, w?1, w0], [t0, w1, w0] 2.78E D + [t0, X = prefix or suffix of w0], 4 < |X| ?
9 2.72Table 2: Experiments on the development data with beam width of 3we cut the PTB into the training, development andtest sets as shown in Table 1.
We use tools providedby CoNLL-2005 3 to extract POS tags from the mrgfiles of PTB.
So the data set is the same as previouswork.
We use the development set to select featuresand estimate the number of iterations in training.
Inour experiments, we enumerate all the POS tags foreach word instead of using a dictionary as in (Ratna-parkhi, 1996), since the size of the tag set is tractableand our learning algorithm is efficient enough.4.2 ResultsEffect of Features: We first run the experiments toevaluate the effect of features.
We use templates todefine features.
For this set of experiments, we setthe beam width B = 3 as a balance between speedand accuracy.
The guided learning algorithm usuallyconverges on the development data set in 4-8 itera-tions over the training data.Table 2 shows the error rate on the developmentset with different features.
We first use the same fea-ture set used in (Ratnaparkhi, 1996), which includesa set of prefix, suffix and lexical features, as wellas some bi-gram and tri-gram context features.
Fol-lowing (Collins, 2002), we do not distinguish rarewords.
On set A, Ratnaparkhi?s feature set, our sys-tem reports an error rate of 3.05% on the develop-ment data set.With set B, we include a few feature templateswhich are symmetric to those in Ratnaparkhi?s set,but are only available with bidirectional search.
Withset C, we add more bi-gram and tri-gram features.With set D, we include bi-lexical features.
With setE, we use prefixes and suffixes of length up to 9, as in(Toutanova et al, 2003; Tsuruoka and Tsujii, 2005).We obtain 2.72% of error rate.
We will use this fea-ture set on our final experiments on the test data.Effect of Search and Learning Strategies: For thesecond set of experiments, we evaluate the effect of3http://www.lsi.upc.es/?srlconll/soft.html, package srlconll-1.1.tgz.Search Aggressive?
Beam=1 Beam=3L-to-R Yes 2.94 2.82L-to-R No 3.24 2.75Bi-Dir Yes 2.84 2.72Bi-Dir No does not convergeTable 3: Experiments on the development datasearch methods, learning strategies, and beam width.We use feature set E for this set of experiments.
Ta-ble 3 shows the error rates on the development dataset with both left-to-right (L-to-R) and bidirectional(Bi-Dir) search methods.
We also tested both aggres-sive learning and non-aggressive learning strategieswith beam width of 1 and 3.First, with non-aggressive learning on bidirec-tional search, the error rate does not converge to acomparable number.
This is due to the fact that thesearch space is too large in bidirectional search, ifwe do not use aggressive learning to constrain thesamples for learning.With aggressive learning, the bidirectional ap-proach always shows advantages over left-to-rightsearch.
However, the gap is not large.
This isdue to the fact that the accuracy of POS taggingis very high.
As a result, we can always keep thegold-standard tags in the beam even with left-to-rightsearch in training.This can also explain why the performance of left-to-right search with non-aggressive learning is closeto bidirectional search if the beam is large enough.However, with beam width = 1, non-aggressivelearning over left-to-right search performs muchworse, because in this case it is more likely that thegold-standard tag is not in the beam.This set of experiments show that guided learn-ing is more preferable for tasks with higher ambi-guities.
In our recent work (Shen and Joshi, 2007),we have applied a variant of this algorithm to depen-dency parsing, and showed significant improvementover left-to-right non-aggressive learning strategy.Comparison: Table 4 shows the comparison withthe previous works on the PTB test sections.766System Beam Error%(Ratnaparkhi, 1996) 5 3.37(Tsuruoka and Tsujii, 2005) 1 2.90(Collins, 2002) - 2.89Guided Learning, feature B 3 2.85(Tsuruoka and Tsujii, 2005) all 2.85(Gime?nez and Ma`rquez, 2004) - 2.84(Toutanova et al, 2003) - 2.76Guided Learning, feature E 1 2.73Guided Learning, feature E 3 2.67Table 4: Comparison with the previous worksAccording to the experiments shown above, webuild our best system by using feature set E withbeam width B = 3.
The number of iterations onthe training data is estimated with respect to the de-velopment data.
We obtain an error rate of 2.67%on the test data.
With deterministic search, or beamwith B = 1, we obtain an error rate of 2.73%.Compared to previous best result on the same dataset, 2.76% by (Toutanova et al, 2003), our best re-sult shows a relative error reduction of 3.3%.
Thisresult is very promising, since we have not used anyspecially designed features in our experiments.
It isreported in (Toutanova et al, 2003) that a crude com-pany name detector was used to generate features,and it gave rise to significant improvement in per-formance.
However, it is difficult for us to duplicateexactly the same feature for the purpose of compari-son, although it is convenient to use features like thatin our framework.5 ConclusionsIn this paper, we propose guided learning, a newlearning framework for bidirectional sequence clas-sification.
The tasks of learning the order of infer-ence and training the local classifier are dynamicallyincorporated into a single Perceptron like algorithm.We apply this novel algorithm to POS tagging.
Itobtains an error rate of 2.67% on the standard PTBtest set, which represents 3.3% relative error reduc-tion over the previous best result (Toutanova et al,2003) on the same data set, while using fewer fea-tures.
By using deterministic search, it obtains anerror rate of 2.73%, a 5.9% relative error reductionover the previous best deterministic algorithm (Tsu-ruoka and Tsujii, 2005).
It should be noted that theerror rate is close to the inter-annotator discrepancyon PTB, the standard test set for POS tagging, there-fore it is very difficult to achieve improvement.ReferencesL.
Bottou.
1991.
Une approche the?orique de l?apprentissageconnexionniste: Applications a` la reconnaissance de la pa-role.
Ph.D. thesis, Universite?
de Paris XI.M.
Collins and B. Roark.
2004.
Incremental parsing with theperceptron algorithm.
In ACL-2004.M.
Collins.
2002.
Discriminative training methods for hiddenmarkov models: Theory and experiments with perceptron al-gorithms.
In EMNLP-2002.K.
Crammer and Y.
Singer.
2003.
Ultraconservative onlinealgorithms for multiclass problems.
Journal of MachineLearning Research, 3:951?991.H.
Daume?
III and D. Marcu.
2005.
Learning as search opti-mization: Approximate large margin methods for structuredprediction.
In ICML-2005.Y.
Freund and R. E. Schapire.
1999.
Large margin classifi-cation using the perceptron algorithm.
Machine Learning,37(3):277?296.J.
Gime?nez and L. Ma`rquez.
2004.
Svmtool: A general pos tag-ger generator based on support vector machines.
In LREC-2004.W.
Krauth and M. Me?zard.
1987.
Learning algorithms withoptimal stability in neural networks.
Journal of Physics A,20:745?752.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Conditionalrandom fields: Probabilistic models for segmentation and la-beling sequence data.
In ICML-2001.M.
P. Marcus, B. Santorini, and M. A. Marcinkiewicz.
1994.Building a large annotated corpus of English: The Penn Tree-bank.
Computational Linguistics, 19(2):313?330.A.
Ratnaparkhi.
1996.
A maximum entropy part-of-speech tag-ger.
In EMNLP-1996.G.
Satta and O.
Stock.
1994.
Bi-Directional Context-FreeGrammar Parsing for Natural Language Processing.
Artifi-cial Intelligence, 69(1-2).L.
Shen and A. K. Joshi.
2005.
Incremental LTAG Parsing.
InEMNLP-2005.L.
Shen and A. K. Joshi.
2007.
Bidirectional LTAG Depen-dency Parsing.
Technical Report 07-02, IRCS, UPenn.B.
Taskar, C. Guestrin, and D. Koller.
2003.
Max-marginmarkov networks.
In NIPS-2003.K.
Toutanova, D. Klein, C. Manning, and Y.
Singer.
2003.Feature-rich part-of-speech tagging with a cyclic dependencynetwork.
In NAACL-2003.Y.
Tsuruoka and J. Tsujii.
2005.
Bidirectional inferencewith the easiest-first strategy for tagging sequence data.
InEMNLP-2005.B.
Widrow and M. E. Hoff.
1960.
Adaptive switching circuits.IRE WESCON Convention Record, part 4.W.
Woods.
1976.
Parsers in speech understanding systems.Technical Report 3438, Vol.
4, 1?21, BBN Inc.767
