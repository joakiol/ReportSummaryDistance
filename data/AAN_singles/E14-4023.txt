Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 117?122,Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational LinguisticsComparing methods for deriving intensity scores for adjectivesJosef Ruppenhofer?, Michael Wiegand?, Jasper Brandes?
?Hildesheim UniversityHildesheim, Germany{ruppenho|brandesj}@uni-hildesheim.de?Saarland UniversitySaarbru?cken, Germanymichael.wiegand@lsv.uni-saarland.deAbstractWe compare several different corpus-based and lexicon-based methods for thescalar ordering of adjectives.
Amongthem, we examine for the first time a low-resource approach based on distinctive-collexeme analysis that just requires asmall predefined set of adverbial modi-fiers.
While previous work on adjective in-tensity mostly assumes one single scale forall adjectives, we group adjectives into dif-ferent scales which is more faithful to hu-man perception.
We also apply the meth-ods to both polar and non-polar adjectives,showing that not all methods are equallysuitable for both types of adjectives.1 IntroductionOrdering adjectives by strength (e.g.
good < great< excellent) is a task that has recently receivedmuch attention due to the central role of intensityclassification in sentiment analysis.
However, theneed to assess the relative strength of adjectivesalso applies to non-polar adjectives.
We are thusinterested in establishing prior or lexical intensityscores and rankings for arbitrary sets of adjectivesthat evoke the same scale.1 We do not address con-textualized intensity, i.e.
the fact that e.g.
negationand adverbs such as very or slightly impact the per-ceived intensity of adjectives.We work with four scales of adjectives (cf.
Ta-ble 1).
Our polar adjectives include 29 adjectivesreferring to quality and 18 adjectives relating tointelligence.
Our non-polar adjectives include 8dimensional adjectives denoting size and 22 de-noting duration.
The adjectives are taken, in part,from FrameNet?s (Baker et al., 1998) frames for1As there has been previous work on how to group adjec-tives into scales (Hatzivassiloglou and McKeown, 1993), weconsider this grouping as given.DESIRABILITY, MENTAL PROPERTY, SIZE andDURATION DESCRIPTION.
These scales are usedbecause they are prototypical and have multiplemembers on the positive and negative half-scales.We evaluate several corpus- and resource-basedmethods that have been used to assign intensityscores to adjectives.
We compare them to a newcorpus-based method that is robust and of lowcomplexity, and which directly uses informationrelated to degree modification of the adjectives tobe orderered.
It rests on the observation that ad-jectives with different types of intensities co-occurwith different types of adverbial modifiers.2POLAR ADJECTIVESIntelligence Adjs.
Intensity Levelbrilliant very high positiveingenious high positivebrainy, intelligent medium positivesmart low positivebright very low positivedaft very low negativefoolish low negativeinane lower medium negativedim upper medium negativedim-witted, dumb, mindless high negativebrainless, idiotic, imbecillic, moronic, stupid very high negativeQuality Adjs.
Intensity Levelexcellent, extraordinary, first-rate, great, outstand-ing, super, superb, superlative, tip-top, top-notchvery high positivegood high positivedecent upper medium positivefine, fair lower medium positiveokay, average low positiveso-so very low positivemediocre very low negativesecond-rate, substandard low negativeinferior lower medium negativebad, crappy, lousy, poor, third-rate medium negativerotten upper medium negativeawful high negativeshitty very high negativeDIMENSIONAL ADJECTIVESSize Adjs.
Intensity Levelcolossal, enormous, gargantuan, giant, gigantic, gi-normous, humongoushigh positivebig, huge, immense, large, oversize, oversized, vast medium positiveoutsize, outsized low positivediminutive, little, puny, small low negativetiny medium negativemicroscopic high negativeDuration Adjs.
Intensity Levellong high positivelengthy medium positiveextended low positivemomentaneous low negativebrief, fleeting, momentary medium negativeshort high negativeTable 1: Adjectives used grouped by human goldstandard intensity classes2The ratings we collected and our scripts are avail-able at www.uni-hildesheim.de/ruppenhofer/data/DISA_data.zip.1172 Data and resourcesTable 2 gives an overview of the different corporaand resources that we use to produce the differentscores and rankings that we want to compare.
Thecorpora and ratings will be discussed alongside theassociated experimental methods in ?4.1 and ?4.2.Corpora Tokens ReferenceBNC ?112 M (Burnard, 2007)LIU reviews ?1.06 B (Jindal and Liu, 2008)ukWaC ?2.25 B (Baroni et al., 2009)Resources Entries ReferenceAffective norms ?14 K (Warriner et al., 2013)SoCAL ?
6.5 K (Taboada et al., 2011)SentiStrength ?
2.5 K (Thelwall et al., 2010)Table 2: Corpora and resources used3 Gold standardWe collected human ratings for our four sets of ad-jectives.
All items were rated individually, in ran-domized order, under conditions that minimizedbias.
Participants were asked to use a horizontalslider, dragging it in the desired direction, repre-senting polarity, and releasing the mouse at the de-sired intensity, ranging from ?100 to +100 .Through Amazon Mechanical Turk (AMT), werecruited subjects with the following qualifica-tions: US residency, a HIT-approval rate of at least96% (following Akkaya et al.
(2010)), and 500prior completed HITs.
We collected 20 ratings foreach item but had to exclude some participants?answers as unusable, which reduced our sample to17 subjects for some items.
In the raw data, all ad-jectives had different mean ratings and their stan-dard deviations overlapped.
We therefore trans-formed the data into sets of equally strong adjec-tives as follows.
For a given pair of adjectives ofidentical polarity, we counted how many partici-pants rated adjective A more intense than adjectiveB; B more intense than A; or A as intense as B.Whenever a simple majority existed for one of thetwo unequal relations, we adopted that as our rela-tive ranking for the two adjectives.3 The resultingrankings (intensity levels) are shown in Table 1.4 MethodsOur methods to determine the intensity of adjec-tives are either corpus- or lexicon-based.3In our data, there was no need to break circular rankings,so we do not consider this issue here.4.1 Corpus-based methodsOur first method, distinctive-collexeme analysis(Collex) (Gries and Stefanowitsch, 2004) assumesthat adjectives with different types of intensitiesco-occur with different types of adverbial modi-fiers (Table 3).
End-of-scale modifiers such as ex-tremely or absolutely target adjectives with a par-tially or fully closed scale, such as brilliant or out-standing, which occupy extreme positions on theintensity scale.
?Normal?
degree modifiers suchas very or rather target adjectives with an openscale structure (in the sense of Kennedy and Mc-Nally (2005)), such as good or decent, which oc-cupy non-extreme positions.To determine an adjective?s preference for oneof the two constructions, the Fisher exact test(Pedersen, 1996) is used.
It makes no distribu-tional assumptions and does not require a min-imum sample size.
The direction in which ob-served values differ from expected ones indicates apreference for one construction over the other andthe p-values are taken as a measure of the prefer-ence strength.
Our hypothesis is that e.g.
an adjec-tive A with greater preference for the end-of-scaleconstruction than adjective B has a greater inher-ent intensity than B.
We ran distinctive-collexemeanalysis on both the ukWaC and the BNC.
We re-fer to the output as CollexukWaCand CollexBNC.Note that this kind of method has not yet been ex-amined for automatic intensity classification.end-of-scale ?normal?100%, fully, totally, absolutely,completely, perfectly, entirely,utterly, almost, partially, half,mostlyall, as, awfully, enough, extremely,fairly, highly, how, least, less, much,pretty, quite, rather, so, somewhat,sort of, terribly, too, very, wellTable 3: Domain independent degree modifiers (3most freq.
terms in the BNC; 3 most freq.
termsin the ukWaC)Another corpus-based method we consider em-ploys Mean star ratings (MeanStar) from prod-uct reviews as described by Rill et al.
(2012).
Un-like Collex, this method uses no linguistic prop-erties of the adjectives themselves.
Instead, it de-rives intensity from the star rating scores that re-viewers (manually) assign to reviews.
We counthow many instances of each adjective i (of the setof adjectives to classify) occur in review titles witha given star rating (score) Sjwithin a review cor-pus.
The intensity score is defined as the weightedmean of the star ratings SRi=?nj=1Sijn.Horn (1976) proposes pattern-based diagnos-118Pattern Any Int.
Qual.
Size Dur.X or even Y 4118 1 34 9 3X if not Y 3115 1 0 29 0be X but not Y 2815 0 74 3 1not only X but Y 1114 0 3 0 0X and in fact Y 45 0 0 0 0not X, let alone Y 4 0 0 0 0not Y, not even X 4 0 1 0 0Table 4: Phrasal patterns in the ukWaCtics for acquiring information about the scalarstructure of adjectives.
This was validated on ac-tual data by Sheinman and Tokunaga (2009).
Apattern such as not just/only X but Y implies that[Y] must always be stronger than [X] (as in It?snot just good but great.
).The pattern-based approach has a severe cover-age problem.
Table 4 shows the results for 7 com-mon phrasal patterns in the larger of our two cor-pora, the ukWaC.
The slots in the patterns are typ-ically not filled by adjectives from the same scale.For example, the most frequent pattern X or evenY has 4118 instances in the ukWaC.
Only 34 ofthese have quality adjectives in both slots.
Thoughde Melo and Bansal (2013) have shown that thecoverage problems can be overcome and state-of-the-art results obtained using web scale data in theform of Google n-grams, we still set aside thismethod here because of its great resource need.4.2 Manually compiled lexical resourcesIn addition to the corpus methods, we also con-sider some manually compiled resources.
We wantto know if the polarity and intensity information inthem can be used for ordering polar adjectives.One resource we consider are the affective rat-ings (elicited with AMT) for almost 14,000 En-glish words collected by Warriner et al.
(2013).They include scores of valence (unhappy tohappy), arousal (calm to aroused) and dominance(in control to controlled) for each word in the list.This scoring system follows the dimensional the-ory of emotion by Osgood et al.
(1957).
We willinterpret each of these dimensions as a separate in-tensity score, i.e.
WarV al, WarAroand WarDom.Beyond Warriner?s ratings, we consider the twopolarity lexicons SentiStrength (Thelwall et al.,2010) and SoCAL (Taboada et al., 2011) whichalso assign intensity scores to polar expressions.5 ExperimentsFor our evaluation, we compute the similarity be-tween the gold standard and every other rankingwe are interested in in terms of Spearman?s rankcorrelation coefficient (Spearman?s ?
).Polar DimensionalData set Intelligence Quality Duration SizeMeanStar 0.886 0.935 0.148 -0.058SoCAL 0.848 0.953 NA 0.776SentiStrength 0.874 0.880 NA NACollexukWaC0.837 0.806 0.732 0.808CollexukWaC?
0.845 0.753 0.732 0.940CollexBNC0.834 0.790 0.732 0.733CollexBNC?
0.705 0.643 0.834 0.700WarV al0.779 0.916 -0.632 -0.031WarAro0.504 -0.452 0.316 0.717WarDom0.790 0.891 0.632 0.285Table 5: Spearman rank correlations with the hu-man gold standard (?
: only the 3 most frequentmodifiers are used (see Table 3))5.1 Data transformationFor the word lists with numeric scores (MeanStar(?4.1); SentiStrength, SoCAL, WarV al, WarAroand WarDom(?4.2)) we did as follows: Adjectivesnot covered by the word lists were ignored.
Ad-jectives with equal scores were given tied ranks.For the experiments involving distinctivecollexeme analysis in our two corpora (?4.1) weproceeded as follows: The adjectives classifiedas distinctive for the end-of-scale modificationconstructions were put at the top and bottom ofthe ranking according to polarity; the greater thecollostructional strength for the adjective as de-noted by the p-value, the nearer it is placed to thetop or bottom of the ranking.
The adjectives thatare distinctive for the normal degree modificationconstruction are placed between those adjectivesdistinctive for the end-of-scale modificationconstruction, again taking polarity and collostruc-tional strength into account.
This time, the leastdistinctive lemmas for the normal modificationconstruction come to directly join up with theleast distinctive lemmas for the end-of-scaleconstruction.
In between the normal modifiers,we place adjectives that have no preference forone or the other construction, which may resultfrom non-occurrence in small data sets (see ?5.2).5.2 ResultsThe results of the pairwise correlations betweenthe human-elicited gold standard and the rankingsderived from various methods and resources areshown in Table 5.
For polar adjectives, most rank-ings correlate fairly well with human judgments.Warriner?s arousal list, however, performs poorlyon quality adjectives, whereas MeanStar and War-riner?s dominance and valence lists perform bet-ter on quality than on intelligence adjectives.
ForMeanStar, this does not come as a surprise as qual-ity adjectives are much more frequent in prod-119uct reviews than intelligence adjectives.
Overall,it seems that MeanStar most closely matches thehuman judgments that we elicited for the intel-ligence adjectives.
SentiStrength also produceshigh scores.
However, we do not have full confi-dence in that result since SentiStrength lacks manyof our adjectives, thus leading to a possibly highercorrelation than would have been achieved if ranks(scores) had been available for all adjectives.The picture is very different for the dimensional(non-polar) adjectives.
While Collex still givesvery good results, especially on the ukWaC, theMeanStar method and most Warriner lists producevery low positive or even negative correlations.This shows that estimating the intensity of non-polar adjectives from metadata or ratings elicitedin terms of affect is not useful.
It is much better toconsider their actual linguistic behavior in degreeconstructions, which Collex does.
SentiStrengthhas no coverage for size or duration adjectives.SoCAL covers 14 of the 22 size adjectives.Although it never gives the best result, Collexproduces stable results across both corpora andthe four scales.
It also requires the least humaneffort by far.
While all other rankings are pro-duced with the help of heavy human annotation(even MeanStar is completely dependent on manu-ally assigned review scores), one has only to spec-ify some domain-independent degree and end-of-scale modifiers.
Table 5 also shows that normallya larger set of modifiers is necessary: only consid-ering the 3 most frequent terms (Table 3) results ina notably reduced correlation.
As there is no con-sistent significant difference between CollexBNCand CollexukWaCeven though the ukWaC is 20times larger than the BNC (Table 2), we mayconclude that the smaller size of the BNC is al-ready sufficient.
This, however, raises the questionwhether even smaller amounts of data than the fullBNC could already produce a reasonable intensityranking.
Figure 1 plots the Spearman correlationfor our adjectives using various sizes of the BNCcorpus.4 It shows that further reducing the size ofthe corpus causes some deterioration, most signifi-cantly on the intelligence adjectives.
The counter-intuitive curve for duration adjectives is explainedas follows.
Collex produces ties in the middle ofthe scale when data is lacking (see ?5.1).
Becausethe smallest corpus slices contain no or very fewinstances and because the gold standard does in-4For each size, we average across 10 samples.0.60.650.70.750.80.850.90  20  40  60  80  100Spearman?srho% Size of BNCIntelligenceQualitySizeDurationFigure 1: Reducing the size of the BNCclude several ties, the results for duration adjec-tives are inflated initially, when data is lacking.6 Related workSentiment analysis on adjectives has been exten-sively explored in previous work, however, mostwork focussed on the extraction of subjective ad-jectives (Wiebe, 2000; Vegnaduzzo, 2004; Wie-gand et al., 2013) or on the detection of polar ori-entation (Hatzivassiloglou and McKeown, 1997;Kamps et al., 2004; Fahrni and Klenner, 2008).Intensity can be considered in two ways, as acontextual strength analysis (Wilson et al., 2004)or as an out-of-context analysis, as in this paper.Our main contribution is that we compare sev-eral classification methods that include a neweffective method based on distinctive-collexemeanalysis requiring hardly any human guidance andwhich moreover can solve the problem of intensityassignment for all, not only polar adjectives.7 ConclusionWe compared diverse corpus-based and lexicon-based methods for the intensity classification ofadjectives.
Among them, we examined for the firsttime an approach based on distinctive-collexemeanalysis.
It requires only a small predefined setof adverbial modifiers and relies only on infor-mation about individual adjectives rather than co-occurrences of adjectives within patterns.
As a re-sult, it can be used with far less data than e.g.
theGoogle n-grams provide.
Unlike the mean star ap-proach, it needs no extrinsic meta-data and it canhandle both polar and non-polar adjectives.
Ac-cordingly, it appears to be very promising for caseswhere only few resources are available and as asource of evidence to be used in hybrid methods.120AcknowledgmentsMichael Wiegand was funded by the German Fed-eral Ministry of Education and Research (BMBF)under grant no.
01IC12SO1X.
The authors wouldlike to thank Maite Taboada for providing her sen-timent lexicon (SoCAL) to be used for the experi-ments presented in this paper.ReferencesCem Akkaya, Alexander Conrad, Janyce Wiebe, andRada Mihalcea.
2010.
Amazon Mechanical Turkfor Subjectivity Word Sense Disambiguation.
InNAACL-HLT 2010 Workshop on Creating Speechand Language Data With Amazon?s MechanicalTurk, pages 195?203, Los Angeles, CA, USA.Collin F. Baker, Charles J. Fillmore, and John B.Lowe.
1998.
The Berkeley Framenet Project.In Proceedings of the International Conferenceon Computational Linguistics and Annual Meetingof the Association for Computational Linguistics(COLING/ACL), pages 86?90, Montre?al, Quebec,Canada.Marco Baroni, Silvia Bernardini, Adriano Ferraresi,and Eros Zanchetti.
2009.
The WaCky Wide Web:A Collection of Very Large Linguistically ProcessedWeb-Crawled Corpora.
Language Resources andEvaluation, 43(3):209?226.Lou Burnard, 2007.
Reference Guide for the BritishNational Corpus.
Research Technologies Serviceat Oxford University Computing Services, Oxford,UK.Gerard de Melo and Mohit Bansal.
2013.
Good, Great,Excellent: Global Inference of Semantic Intensities.Transactions of the Association for ComputationalLinguistics, 1:279?290.Angela Fahrni and Manfred Klenner.
2008.
Old Wineor Warm Beer: Target Specific Sentiment Analysisof Adjectives.
In Proceedings of the Symposium onAffective Language in Human and Machine, pages60?63, Aberdeen, Scotland, UK.Stefan Th.
Gries and Anatol Stefanowitsch.
2004.Extending collostructional analysis: a corpus-basedperspective on ?alternations?.
International Journalof Corpus Linguistics, 9(1):97?129.Vasileios Hatzivassiloglou and Kathleen McKeown.1993.
Towards the Automatic Identification of Ad-jectival Scales: Clustering Adjectives According toMeaning.
In Proceedings of the Annual Meetingof the Association for Computational Linguistics(ACL), pages 172?182, Columbus, OH, USA.Vasileios Hatzivassiloglou and Kathleen R. McKeown.1997.
Predicting the Semantic Orientation of Ad-jectives.
In Proceedings of the Conference on Euro-pean Chapter of the Association for ComputationalLinguistics (EACL), pages 174?181, Madrid, Spain.Laurence Robert Horn.
1976.
On the Semantic Prop-erties of Logical Operators in English.
Indiana Uni-versity Linguistics Club.Nitin Jindal and Bing Liu.
2008.
Opinion Spamand Analysis.
In Proceedings of the internationalconference on Web search and web data mining(WSDM), pages 219?230, Palo Alto, USA.Jaap Kamps, M.J. Marx, Robert J. Mokken, andMaarten De Rijke.
2004.
Using Wordnet to Mea-sure Semantic Orientations of Adjectives.
In Pro-ceedings of the Conference on Language Resourcesand Evaluation (LREC), pages 1115?1118, Lisbon,Portugal.Christopher Kennedy and Louise McNally.
2005.Scale Structure, Degree Modification, and theSemantics of Gradable Predicates.
Language,81(2):345?338.Charles E. Osgood, George Suci, and Percy Tannen-baum.
1957.
The Measurement of Meaning.
Uni-versity of Illinois Press.Ted Pedersen.
1996.
Fishing for exactness.
InProceedings of the South-Central SAS Users GroupConference, Austin, TX, USA.Sven Rill, Johannes Drescher, Dirk Reinel, JoergScheidt, Oliver Schuetz, Florian Wogenstein, andDaniel Simon.
2012.
A Generic Approach to Gen-erate Opinion Lists of Phrases for Opinion MiningApplications.
In Proceedings of the KDD-Workshopon Issues of Sentiment Discovery and Opinion Min-ing (WISDOM), Beijing, China.Vera Sheinman and Takenobu Tokunaga.
2009.
Ad-jScales: Differentiating between Similar Adjectivesfor Language Learners.
CSEDU, 1:229?235.Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-berly Voll, and Manfred Stede.
2011.
Lexicon-Based Methods for Sentiment Analysis.
Computa-tional Linguistics, 37(2):267 ?
307.Mike Thelwall, Kevan Buckley, Georgios Paltoglou,and Di Cai.
2010.
Sentiment Strength Detec-tion in Short Informal Text.
Journal of the Ameri-can Society for Information Science and Technology,61(12):2544?2558.Stefano Vegnaduzzo.
2004.
Acquisition of SubjectiveAdjectives with Limited Resources.
In Proceedingsof the AAAI Spring Symposium on Exploring Atti-tude and Affect in Text: Theories and Applications,Stanford, CA, USA.Amy Warriner, Victor Kuperman, and Marc Brysbaert.2013.
Norms of valence, arousal, and dominance for13,915 english lemmas.
Behavior Research Meth-ods, Online First:1?17.Janyce M. Wiebe.
2000.
Learning Subjective Adjec-tives from Corpora.
In Proceedings of the NationalConference on Artificial Intelligence (AAAI), pages735?740, Austin, TX, USA.121Michael Wiegand, Josef Ruppenhofer, and DietrichKlakow.
2013.
Predicative Adjectives: An Unsu-pervised Criterion to Extract Subjective Adjectives.In Proceedings of the Human Language TechnologyConference of the North American Chapter of theACL (HLT/NAACL), pages 534?539, Atlanta, GA,USA.Theresa Wilson, Janyce Wiebe, and Rebecca Hwa.2004.
Just how mad are you?
Finding strong andweak opinion clauses.
In Proceedings of the Na-tional Conference on Artificial Intelligence (AAAI),pages 761?767, San Jose, CA, USA.122
