Improving Pronoun Resolution by Incorporating CoreferentialInformation of CandidatesXiaofeng Yang??
Jian Su?
Guodong Zhou?
Chew Lim Tan?
?Institute for Infocomm Research21 Heng Mui Keng Terrace,Singapore, 119613{xiaofengy,sujian,zhougd}@i2r.a-star.edu.sg?
Department of Computer ScienceNational University of Singapore,Singapore, 117543{yangxiao,tancl}@comp.nus.edu.sgAbstractCoreferential information of a candidate, suchas the properties of its antecedents, is importantfor pronoun resolution because it reflects thesalience of the candidate in the local discourse.Such information, however, is usually ignored inprevious learning-based systems.
In this paperwe present a trainable model which incorporatescoreferential information of candidates into pro-noun resolution.
Preliminary experiments showthat our model will boost the resolution perfor-mance given the right antecedents of the can-didates.
We further discuss how to apply ourmodel in real resolution where the antecedentsof the candidate are found by a separate nounphrase resolution module.
The experimental re-sults show that our model still achieves betterperformance than the baseline.1 IntroductionIn recent years, supervised machine learning ap-proaches have been widely explored in refer-ence resolution and achieved considerable suc-cess (Ge et al, 1998; Soon et al, 2001; Ng andCardie, 2002; Strube and Muller, 2003; Yang etal., 2003).
Most learning-based pronoun res-olution systems determine the reference rela-tionship between an anaphor and its antecedentcandidate only from the properties of the pair.The knowledge about the context of anaphorand antecedent is nevertheless ignored.
How-ever, research in centering theory (Sidner, 1981;Grosz et al, 1983; Grosz et al, 1995; Tetreault,2001) has revealed that the local focusing (orcentering) also has a great effect on the pro-cessing of pronominal expressions.
The choicesof the antecedents of pronouns usually dependon the center of attention throughout the localdiscourse segment (Mitkov, 1999).To determine the salience of a candidatein the local context, we may need to checkthe coreferential information of the candidate,such as the existence and properties of its an-tecedents.
In fact, such information has beenused for pronoun resolution in many heuristic-based systems.
The S-List model (Strube,1998), for example, assumes that a co-referringcandidate is a hearer-old discourse entity andis preferred to other hearer-new candidates.In the algorithms based on the centering the-ory (Brennan et al, 1987; Grosz et al, 1995), ifa candidate and its antecedent are the backward-looking centers of two subsequent utterances re-spectively, the candidate would be the most pre-ferred since the CONTINUE transition is al-ways ranked higher than SHIFT or RETAIN.In this paper, we present a supervisedlearning-based pronoun resolution system whichincorporates coreferential information of candi-dates in a trainable model.
For each candi-date, we take into consideration the propertiesof its antecedents in terms of features (hence-forth backward features), and use the supervisedlearning method to explore their influences onpronoun resolution.
In the study, we start ourexploration on the capability of the model byapplying it in an ideal environment where theantecedents of the candidates are correctly iden-tified and the backward features are optimallyset.
The experiments on MUC-6 (1995) andMUC-7 (1998) corpora show that incorporatingcoreferential information of candidates booststhe system performance significantly.
Further,we apply our model in the real resolution wherethe antecedents of the candidates are providedby separate noun phrase resolution modules.The experimental results show that our modelstill outperforms the baseline, even with the lowrecall of the non-pronoun resolution module.The remaining of this paper is organized asfollows.
Section 2 discusses the importance ofthe coreferential information for candidate eval-uation.
Section 3 introduces the baseline learn-ing framework.
Section 4 presents and evaluatesthe learning model which uses backward fea-tures to capture coreferential information, whileSection 5 proposes how to apply the model inreal resolution.
Section 6 describes related re-search work.
Finally, conclusion is given in Sec-tion 7.2 The Impact of CoreferentialInformation on PronounResolutionIn pronoun resolution, the center of attentionthroughout the discourse segment is a very im-portant factor for antecedent selection (Mitkov,1999).
If a candidate is the focus (or center)of the local discourse, it would be selected asthe antecedent with a high possibility.
See thefollowing example,<s> Gitano1 has pulled off a clever illusion2with its3 advertising4.
<s><s> The campaign5 gives its6 clothes ayouthful and trendy image to lure consumersinto the store.
<s>Table 1: A text segment from MUC-6 data setIn the above text, the pronoun ?its6?
hasseveral antecedent candidates, i.e., ?Gitano1?,?a clever illusion2?, ?its3?, ?its advertising4?and ?The campaign5?.
Without looking back,?The campaign5?
would be probably selectedbecause of its syntactic role (Subject) and itsdistance to the anaphor.
However, given theknowledge that the company Gitano is the fo-cus of the local context and ?its3?
refers to?Gitano1?, it would be clear that the pronoun?its6?
should be resolved to ?its3?
and thus?Gitano1?, rather than other competitors.To determine whether a candidate is the ?fo-cus?
entity, we should check how the status (e.g.grammatical functions) of the entity alternatesin the local context.
Therefore, it is necessaryto track the NPs in the coreferential chain ofthe candidate.
For example, the syntactic roles(i.e., subject) of the antecedents of ?its3?
wouldindicate that ?its3?
refers to the most saliententity in the discourse segment.In our study, we keep the properties of the an-tecedents as features of the candidates, and usethe supervised learning method to explore theirinfluence on pronoun resolution.
Actually, todetermine the local focus, we only need to checkthe entities in a short discourse segment.
Thatis, for a candidate, the number of its adjacentantecedents to be checked is limited.
Therefore,we could evaluate the salience of a candidateby looking back only its closest antecedent in-stead of each element in its coreferential chain,with the assumption that the closest antecedentis able to provide sufficient information for theevaluation.3 The Baseline Learning FrameworkOur baseline system adopts the commonlearning-based framework employed in the sys-tem by Soon et al (2001).In the learning framework, each training ortesting instance takes the form of i{ana, candi},where ana is the possible anaphor and candi isits antecedent candidate1.
An instance is associ-ated with a feature vector to describe their rela-tionships.
As listed in Table 2, we only considerthose knowledge-poor and domain-independentfeatures which, although superficial, have beenproved efficient for pronoun resolution in manyprevious systems.During training, for each anaphor in a giventext, a positive instance is created by paringthe anaphor and its closest antecedent.
Also aset of negative instances is formed by paring theanaphor and each of the intervening candidates.Based on the training instances, a binary classi-fier is generated using C5.0 learning algorithm(Quinlan, 1993).
During resolution, each possi-ble anaphor ana, is paired in turn with each pre-ceding antecedent candidate, candi, from rightto left to form a testing instance.
This instanceis presented to the classifier, which will thenreturn a positive or negative result indicatingwhether or not they are co-referent.
The pro-cess terminates once an instance i{ana, candi}is labelled as positive, and ana will be resolvedto candi in that case.4 The Learning Model IncorporatingCoreferential InformationThe learning procedure in our model is similarto the above baseline method, except that foreach candidate, we take into consideration itsclosest antecedent, if possible.4.1 Instance StructureDuring both training and testing, we adopt thesame instance selection strategy as in the base-line model.
The only difference, however, is thestructure of the training or testing instances.Specifically, each instance in our model is com-posed of three elements like below:1In our study candidates are filtered by checking thegender, number and animacy agreements in advance.Features describing the candidate (candi)1. candi DefNp 1 if candi is a definite NP; else 02. candi DemoNP 1 if candi is an indefinite NP; else 03. candi Pron 1 if candi is a pronoun; else 04. candi ProperNP 1 if candi is a proper name; else 05. candi NE Type 1 if candi is an ?organization?
named-entity; 2 if ?person?, 3 ifother types, 0 if not a NE6.
candi Human the likelihood (0-100) that candi is a human entity (obtainedfrom WordNet)7. candi FirstNPInSent 1 if candi is the first NP in the sentence where it occurs8.
candi Nearest 1 if candi is the candidate nearest to the anaphor; else 09. candi SubjNP 1 if candi is the subject of the sentence it occurs; else 0Features describing the anaphor (ana):10. ana Reflexive 1 if ana is a reflexive pronoun; else 011. ana Type 1 if ana is a third-person pronoun (he, she,.
.
.
); 2 if a singleneuter pronoun (it,.
.
.
); 3 if a plural neuter pronoun (they,.
.
.
);4 if other typesFeatures describing the relationships between candi and ana:12.
SentDist Distance between candi and ana in sentences13.
ParaDist Distance between candi and ana in paragraphs14.
CollPattern 1 if candi has an identical collocation pattern with ana; else 0Table 2: Feature set for the baseline pronoun resolution systemi{ana, candi, ante-of-candi}where ana and candi, similar to the defini-tion in the baseline model, are the anaphor andone of its candidates, respectively.
The newadded element in the instance definition, ante-of-candi, is the possible closest antecedent ofcandi in its coreferential chain.
The ante-of-candi is set to NIL in the case when candi hasno antecedent.Consider the example in Table 1 again.
Forthe pronoun ?it6?, three training instances willbe generated, namely, i{its6, The compaign5,NIL}, i{its6, its advertising4, NIL}, andi{its6, its3, Gitano1}.4.2 Backward FeaturesIn addition to the features adopted in the base-line system, we introduce a set of backward fea-tures to describe the element ante-of-candi.
Theten features (15-24) are listed in Table 3 withtheir respective possible values.Like feature 1-9, features 15-22 describe thelexical, grammatical and semantic properties ofante-of-candi.
The inclusion of the two featuresApposition (23) and candi NoAntecedent (24) isinspired by the work of Strube (1998).
Thefeature Apposition marks whether or not candiand ante-of-candi occur in the same appositivestructure.
The underlying purpose of this fea-ture is to capture the pattern that proper namesare accompanied by an appositive.
The entitywith such a pattern may often be related to thehearers?
knowledge and has low preference.
Thefeature candi NoAntecedent marks whether ornot a candidate has a valid antecedent in thepreceding text.
As stipulated in Strube?s work,co-referring expressions belong to hearer-old en-tities and therefore have higher preference thanother candidates.
When the feature is assignedvalue 1, all the other backward features (15-23)are set to 0.4.3 Results and DiscussionsIn our study we used the standard MUC-6 and MUC-7 coreference corpora.
In eachdata set, 30 ?dry-run?
documents were anno-tated for training as well as 20-30 documentsfor testing.
The raw documents were prepro-cessed by a pipeline of automatic NLP com-ponents (e.g.
NP chunker, part-of-speech tag-ger, named-entity recognizer) to determine theboundary of the NPs, and to provide necessaryinformation for feature calculation.In an attempt to investigate the capability ofour model, we evaluated the model in an opti-mal environment where the closest antecedentof each candidate is correctly identified.
MUC-6 and MUC-7 can serve this purpose quite well;the annotated coreference information in thedata sets enables us to obtain the correct closestFeatures describing the antecedent of the candidate (ante-of-candi):15. ante-candi DefNp 1 if ante-of-candi is a definite NP; else 016. ante-candi IndefNp 1 if ante-of-candi is an indefinite NP; else 017. ante-candi Pron 1 if ante-of-candi is a pronoun; else 018. ante-candi Proper 1 if ante-of-candi is a proper name; else 019. ante-candi NE Type 1 if ante-of-candi is an ?organization?
named-entity; 2 if ?per-son?, 3 if other types, 0 if not a NE20.
ante-candi Human the likelihood (0-100) that ante-of-candi is a human entity21.
ante-candi FirstNPInSent 1 if ante-of-candi is the first NP in the sentence where it occurs22.
ante-candi SubjNP 1 if ante-of-candi is the subject of the sentence where it occursFeatures describing the relationships between the candidate (candi) and ante-of-candi :23.
Apposition 1 if ante-of-candi and candi are in an appositive structureFeatures describing the candidate (candi):24. candi NoAntecedent 1 if candi has no antecedent available; else 0Table 3: Backward features used to capture the coreferential information of a candidateantecedent for each candidate and accordinglygenerate the training and testing instances.
Inthe next section we will further discuss how toapply our model into the real resolution.Table 4 shows the performance of differentsystems for resolving the pronominal anaphors 2in MUC-6 and MUC-7.
Default learning param-eters for C5.0 were used throughout the exper-iments.
In this table we evaluated the perfor-mance based on two kinds of measurements:?
?Recall-and-Precision?
:Recall = #positive instances classified correctly#positive instancesPrecision = #positive instances classified correctly#instances classified as positiveThe above metrics evaluate the capabilityof the learned classifier in identifying posi-tive instances3.
F-measure is the harmonicmean of the two measurements.?
?Success?
:Success = #anaphors resolved correctly#total anaphorsThe metric4 directly reflects the pronounresolution capability.The first and second lines of Table 4 comparethe performance of the baseline system (Base-2The first and second person pronouns are discardedin our study.3The testing instances are collected in the same waysas the training instances.4In the experiments, an anaphor is considered cor-rectly resolved only if the found antecedent is in the samecoreferential chain of the anaphor.ante-candi_SubjNP = 1: 1 (49/5)ante-candi_SubjNP = 0::..candi_SubjNP = 1::..SentDist = 2: 0 (3): SentDist = 0:: :..candi_Human > 0: 1 (39/2): : candi_Human <= 0:: : :..candi_NoAntecedent = 0: 1 (8/3): : candi_NoAntecedent = 1: 0 (3): SentDist = 1:: :..ante-candi_Human <= 50 : 0 (4): ante-candi_Human > 50 : 1 (10/2):candi_SubjNP = 0::..candi_Pron = 1: 1 (32/7)candi_Pron = 0::..candi_NoAntecedent = 1::..candi_FirstNPInSent = 1: 1 (6/2): candi_FirstNPInSent = 0: ...candi_NoAntecedent = 0: ...Figure 1: Top portion of the decision treelearned on MUC-6 with the backward featuresline) and our system (Optimal), where DTpronand DTpron?opt are the classifiers learned inthe two systems, respectively.
The results in-dicate that our system outperforms the base-line system significantly.
Compared with Base-line, Optimal achieves gains in both recall (6.4%for MUC-6 and 4.1% for MUC-7) and precision(1.3% for MUC-6 and 9.0% for MUC-7).
ForSuccess, we also observe an apparent improve-ment by 4.7% (MUC-6) and 3.5% (MUC-7).Figure 1 shows the portion of the pruned deci-sion tree learned for MUC-6 data set.
It visual-izes the importance of the backward features forthe pronoun resolution on the data set.
FromTesting Backward feature MUC-6 MUC-7Experiments classifier assigner* R P F S R P F SBaseline DTpron NIL 77.2 83.4 80.2 70.0 71.9 68.6 70.2 59.0Optimal DTpron?opt (Annotated) 83.6 84.7 84.1 74.7 76.0 77.6 76.8 62.5RealResolve-1 DTpron?opt DTpron?opt 75.8 83.8 79.5 73.1 62.3 77.7 69.1 53.8RealResolve-2 DTpron?opt DTpron 75.8 83.8 79.5 73.1 63.0 77.9 69.7 54.9RealResolve-3 DT?pron DTpron 79.3 86.3 82.7 74.7 74.7 67.3 70.8 60.8RealResolve-4 DT?pron DT?pron 79.3 86.3 82.7 74.7 74.7 67.3 70.8 60.8Table 4: Results of different systems for pronoun resolution on MUC-6 and MUC-7(*Here we only list backward feature assigner for pronominal candidates.
In RealResolve-1 toRealResolve-4, the backward features for non-pronominal candidates are all found by DTnon?pron.
)the tree we could find that:1.)
Feature ante-candi SubjNP is of the mostimportance as the root feature of the tree.The decision tree would first examine thesyntactic role of a candidate?s antecedent,followed by that of the candidate.
Thisnicely proves our assumption that the prop-erties of the antecedents of the candidatesprovide very important information for thecandidate evaluation.2.)
Both features ante-candi SubjNP andcandi SubjNP rank top in the decision tree.That is, for the reference determination,the subject roles of the candidate?s referentwithin a discourse segment will be checkedin the first place.
This finding supports wellthe suggestion in centering theory that thegrammatical relations should be used as thekey criteria to rank forward-looking centersin the process of focus tracking (Brennanet al, 1987; Grosz et al, 1995).3.)
candi Pron and candi NoAntecedent areto be examined in the cases when thesubject-role checking fails, which confirmsthe hypothesis in the S-List model byStrube (1998) that co-refereing candidateswould have higher preference than othercandidates in the pronoun resolution.5 Applying the Model in RealResolutionIn Section 4 we explored the effectiveness ofthe backward feature for pronoun resolution.
Inthose experiments our model was tested in anideal environment where the closest antecedentof a candidate can be identified correctly whengenerating the feature vector.
However, duringreal resolution such coreferential information isnot available, and thus a separate module hasalgorithm PRON-RESOLVEinput:DTnon?pron: classifier for resolving non-pronounsDTpron: classifier for resolving pronounsbegin:M1..n:= the valid markables in the given docu-mentAnte[1..n] := 0for i = 1 to Nfor j = i - 1 downto 0if (Mi is a non-pron andDTnon?pron(i{Mi,Mj}) == + )or(Mi is a pron andDTpron(i{Mi,Mj , Ante[j]}) == +)thenAnte[i] := Mjbreakreturn AnteFigure 2: The pronoun resolution algorithm byincorporating coreferential information of can-didatesto be employed to obtain the closest antecedentfor a candidate.
We describe the algorithm inFigure 2.The algorithm takes as input two classifiers,one for the non-pronoun resolution and theother for pronoun resolution.
Given a testingdocument, the antecedent of each NP is identi-fied using one of these two classifiers, dependingon the type of NP.
Although a separate non-pronoun resolution module is required for thepronoun resolution task, this is usually not abig problem as these two modules are often in-tegrated in coreference resolution systems.
Wejust use the results of the one module to improvethe performance of the other.5.1 New Training and TestingProceduresFor a pronominal candidate, its antecedent canbe obtained by simply using DTpron?opt.
ForTraining Procedure:T1.
Train a non-pronoun resolution clas-sifier DTnon?pron and a pronoun resolutionclassifier DTpron, using the baseline learningframework (without backward features).T2.
Apply DTnon?pron and DTpron to iden-tify the antecedent of each non-pronominaland pronominal markable, respectively, in agiven document.T3.
Go through the document again.
Gen-erate instances with backward features as-signed using the antecedent information ob-tained in T2.T4.
Train a new pronoun resolution classifierDT?pron on the instances generated in T3.Testing Procedure:R1.
For each given document, do T2?T3.R2.
Resolve pronouns by applying DT?pron.Table 5: New training and testing proceduresa non-pronominal candidate, we built a non-pronoun resolution module to identify its an-tecedent.
The module is a duplicate of theNP coreference resolution system by Soon etal.
(2001)5 , which uses the similar learn-ing framework as described in Section 3.
Inthis way, we could do pronoun resolutionjust by running PRON-RESOLVE(DTnon?pron,DTpron?opt), where DTnon?pron is the classifierof the non-pronoun resolution module.One problem, however, is that DTpron?opt istrained on the instances whose backward fea-tures are correctly assigned.
During real resolu-tion, the antecedent of a candidate is found byDTnon?pron or DTpron?opt, and the backwardfeature values are not always correct.
Indeed,for most noun phrase resolution systems, therecall is not very high.
The antecedent some-times can not be found, or is not the closestone in the preceding coreferential chain.
Con-sequently, the classifier trained on the ?perfect?feature vectors would probably fail to outputanticipated results on the noisy data during realresolution.Thus we modify the training and testing pro-cedures of the system.
For both training andtesting instances, we assign the backward fea-ture values based on the results from separateNP resolution modules.
The detailed proce-dures are described in Table 5.5Details of the features can be found in Soon et al(2001)algorithm REFINE-CLASSIFIERbegin:DT1pron := DT?pronfor i = 1 to ?Use DTipron to update the antecedents ofpronominal candidates and the correspond-ing backward features;Train DTi+1pron based on the updated traininginstances;if DTi+1pron is not better than DTipron thenbreak;return DTipronFigure 3: The classifier refining algorithmThe idea behind our approach is to trainand test the pronoun resolution classifier oninstances with feature values set in a consis-tent way.
Here the purpose of DTpron andDTnon?pron is to provide backward feature val-ues for training and testing instances.
From thispoint of view, the two modules could be thoughtof as a preprocessing component of our pronounresolution system.5.2 Classifier RefiningIf the classifier DT?pron outperforms DTpronas expected, we can employ DT?pron in placeof DTpron to generate backward features forpronominal candidates, and then train a clas-sifier DT?
?pron based on the updated training in-stances.
Since DT?pron produces more correctfeature values than DTpron, we could expectthat DT?
?pron will not be worse, if not better,than DT?pron.
Such a process could be repeatedto refine the pronoun resolution classifier.
Thealgorithm is described in Figure 3.In algorithm REFINE-CLASSIFIER, the it-eration terminates when the new trained clas-sifier DTi+1pron provides no further improvementthan DTipron.
In this case, we can replaceDTi+1pron by DTipron during the i+1(th) testingprocedure.
That means, by simply runningPRON-RESOLVE(DTnon?pron,DTipron), we canuse for both backward feature computation andinstance classification tasks, rather than apply-ing DTpron and DT?pron subsequently.5.3 Results and DiscussionsIn the experiments we evaluated the perfor-mance of our model in real pronoun resolution.The performance of our model depends on theperformance of the non-pronoun resolution clas-sifier, DTnon?pron.
Hence we first examined thecoreference resolution capability of DTnon?pronbased on the standard scoring scheme by Vi-lain et al (1995).
For MUC-6, the module ob-tains 62.2% recall and 78.8% precision, while forMUC-7, it obtains 50.1% recall and 75.4% pre-cision.
The poor recall and comparatively highprecision reflect the capability of the state-of-the-art learning-based NP resolution systems.The third block of Table 4 summarizes theperformance of the classifier DTpron?opt in realresolution.
In the systems RealResolve-1 andRealResolve-2, the antecedents of pronominalcandidates are found by DTpron?opt and DTpronrespectively, while in both systems the an-tecedents of non-pronominal candidates are byDTnon?pron.
As shown in the table, comparedwith the Optimal where the backward featuresof testing instances are optimally assigned, therecall rates of two systems drop largely by 7.8%for MUC-6 and by about 14% for MUC-7.
Thescores of recall are even lower than those ofBaseline.
As a result, in comparison with Op-timal, we see the degrade of the F-measure andthe success rate, which confirms our hypothesisthat the classifier learned on perfect training in-stances would probably not perform well on thenoisy testing instances.The system RealResolve-3 listed in the fifthline of the table uses the classifier trainedand tested on instances whose backward fea-tures are assigned according to the results fromDTnon?pron and DTpron.
From the table we canfind that: (1) Compared with Baseline, the sys-tem produces gains in recall (2.1% for MUC-6and 2.8% for MUC-7) with no significant lossin precision.
Overall, we observe the increase inF-measure for both data sets.
If measured bySuccess, the improvement is more apparent by4.7% (MUC-6) and 1.8% (MUC-7).
(2) Com-pared with RealResolve-1(2), the performancedecrease of RealResolve-3 against Optimal isnot so large.
Especially for MUC-6, the systemobtains a success rate as high as Optimal.The above results show that our model canbe successfully applied in the real pronoun res-olution task, even given the low recall of thecurrent non-pronoun resolution module.
Thisshould be owed to the fact that for a candidate,its adjacent antecedents, even not the closestone, could give clues to reflect its salience inthe local discourse.
That is, the model prefers ahigh precision to a high recall, which copes wellwith the capability of the existing non-pronounresolution module.In our experiments we also tested the clas-sifier refining algorithm described in Figure 3.We found that for both MUC-6 and MUC-7data set, the algorithm terminated in the secondround.
The comparison of DT2pron and DT1pron(i.e.
DT?pron) showed that these two trees wereexactly the same.
The algorithm converges fastprobably because in the data set, most of theantecedent candidates are non-pronouns (89.1%for MUC-6 and 83.7% for MUC-7).
Conse-quently, the ratio of the training instances withbackward features changed may be not substan-tial enough to affect the classifier generation.Although the algorithm provided no furtherrefinement for DT?pron, we can use DT?pron, assuggested in Section 5.2, to calculate back-ward features and classify instances by runningPRON-RESOLVE(DTnon?pron, DT?pron).
Theresults of such a system, RealResolve-4, arelisted in the last line of Table 4.
For both MUC-6 and MUC-7, RealResolve-4 obtains exactlythe same performance as RealResolve-3.6 Related WorkTo our knowledge, our work is the first ef-fort that systematically explores the influence ofcoreferential information of candidates on pro-noun resolution in learning-based ways.
Iida etal.
(2003) also take into consideration the con-textual clues in their coreference resolution sys-tem, by using two features to reflect the rankingorder of a candidate in Salience Reference List(SRL).
However, similar to common centeringmodels, in their system the ranking of entitiesin SRL is also heuristic-based.The coreferential chain length of a candidate,or its variants such as occurrence frequency andTFIDF, has been used as a salience factor insome learning-based reference resolution sys-tems (Iida et al, 2003; Mitkov, 1998; Paul etal., 1999; Strube and Muller, 2003).
However,for an entity, the coreferential length only re-flects its global salience in the whole text(s), in-stead of the local salience in a discourse segmentwhich is nevertheless more informative for pro-noun resolution.
Moreover, during resolution,the found coreferential length of an entity is of-ten incomplete, and thus the obtained lengthvalue is usually inaccurate for the salience eval-uation.7 Conclusion and Future WorkIn this paper we have proposed a model whichincorporates coreferential information of candi-dates to improve pronoun resolution.
Whenevaluating a candidate, the model considers itsadjacent antecedent by describing its propertiesin terms of backward features.
We first exam-ined the effectiveness of the model by applyingit in an optimal environment where the clos-est antecedent of a candidate is obtained cor-rectly.
The experiments show that it booststhe success rate of the baseline system for bothMUC-6 (4.7%) and MUC-7 (3.5%).
Then weproposed how to apply our model in the real res-olution where the antecedent of a non-pronounis found by an additional non-pronoun resolu-tion module.
Our model can still produce Suc-cess improvement (4.7% for MUC-6 and 1.8%for MUC-7) against the baseline system, de-spite the low recall of the non-pronoun resolu-tion module.In the current work we restrict our study onlyto pronoun resolution.
In fact, the coreferentialinformation of candidates is expected to be alsohelpful for non-pronoun resolution.
We wouldlike to investigate the influence of the coreferen-tial factors on general NP reference resolution inour future work.ReferencesS.
Brennan, M. Friedman, and C. Pollard.1987.
A centering approach to pronouns.
InProceedings of the 25th Annual Meeting ofthe Association for Compuational Linguis-tics, pages 155?162.N.
Ge, J. Hale, and E. Charniak.
1998.
Astatistical approach to anaphora resolution.In Proceedings of the 6th Workshop on VeryLarge Corpora.B.
Grosz, A. Joshi, and S. Weinstein.
1983.Providing a unified account of definite nounphrases in discourse.
In Proceedings of the21st Annual meeting of the Association forComputational Linguistics, pages 44?50.B.
Grosz, A. Joshi, and S. Weinstein.
1995.Centering: a framework for modeling thelocal coherence of discourse.
ComputationalLinguistics, 21(2):203?225.R.
Iida, K. Inui, H. Takamura, and Y. Mat-sumoto.
2003.
Incorporating contextual cuesin trainable models for coreference resolu-tion.
In Proceedings of the 10th Confer-ence of EACL, Workshop ?The Computa-tional Treatment of Anaphora?.R.
Mitkov.
1998.
Robust pronoun resolutionwith limited knowledge.
In Proceedings of the17th Int.
Conference on Computational Lin-guistics, pages 869?875.R.
Mitkov.
1999.
Anaphora resolution: Thestate of the art.
Technical report, Universityof Wolverhampton.MUC-6.
1995.
Proceedings of the Sixth MessageUnderstanding Conference.
Morgan Kauf-mann Publishers, San Francisco, CA.MUC-7.
1998.
Proceedings of the SeventhMessage Understanding Conference.
MorganKaufmann Publishers, San Francisco, CA.V.
Ng and C. Cardie.
2002.
Improving machinelearning approaches to coreference resolution.In Proceedings of the 40th Annual Meeting ofthe Association for Computational Linguis-tics, pages 104?111, Philadelphia.M.
Paul, K. Yamamoto, and E. Sumita.
1999.Corpus-based anaphora resolution towardsantecedent preference.
In Proceedings ofthe 37th Annual Meeting of the Associa-tion for Computational Linguistics, Work-shop ?Coreference and It?s Applications?,pages 47?52.J.
R. Quinlan.
1993.
C4.5: Programs for ma-chine learning.
Morgan Kaufmann Publish-ers, San Francisco, CA.C.
Sidner.
1981.
Focusing for interpretationof pronouns.
American Journal of Computa-tional Linguistics, 7(4):217?231.W.
Soon, H. Ng, and D. Lim.
2001.
A ma-chine learning approach to coreference reso-lution of noun phrases.
Computational Lin-guistics, 27(4):521?544.M.
Strube and C. Muller.
2003.
A machinelearning approach to pronoun resolution inspoken dialogue.
In Proceedings of the 41stAnnual Meeting of the Association for Com-putational Linguistics, pages 168?175, Japan.M.
Strube.
1998.
Never look back: An alterna-tive to centering.
In Proceedings of the 17thInt.
Conference on Computational Linguis-tics and 36th Annual Meeting of ACL, pages1251?1257.J.
R. Tetreault.
2001.
A corpus-based eval-uation of centering and pronoun resolution.Computational Linguistics, 27(4):507?520.M.
Vilain, J. Burger, J. Aberdeen, D. Connolly,and L. Hirschman.
1995.
A model-theoreticcoreference scoring scheme.
In Proceedings ofthe Sixth Message understanding Conference(MUC-6), pages 45?52, San Francisco, CA.Morgan Kaufmann Publishers.X.
Yang, G. Zhou, J. Su, and C. Tan.2003.
Coreference resolution using competi-tion learning approach.
In Proceedings of the41st Annual Meeting of the Association forComputational Linguistics, Japan.
