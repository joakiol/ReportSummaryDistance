Integrating Natural Language Processing into E-learning ?A Case of CzechPavel Smrz?Faculty of Informatics, Masaryk University BrnoBotanicka?
68a, 602 00 Brno, Czech RepublicE-mail: smrz@fi.muni.czAbstractThe paper deals with the application of NLPtechnology in e-learning.
We report our re-search on intelligent platforms for computer-mediated education.
Some of the methods de-scribed in the paper have already taken part inthe end-user applications that are in everydayuse, others still wait for their implementation inthe form of software products.
The main mes-sage of the paper is that the language technol-ogy, even in the imperfect form of the currentstate of the art, can significantly enhance to-day?s computer-mediated teaching and learningactivities.
It is true especially for languages dif-ferent from English, where the adopted learningmanagement systems often do not support eventhe basic functionality of a language-orientedsearch and retrieval of learning objects.
As acase study, this paper demonstrates the appli-cation of the given ideas for e-learning materialsin Czech.1 IntroductionContemporary projects aiming at launchinglearning management systems (LMS) often fo-cus on the introduction of an existing softwaretool, rather than on an innovation by meansof the modern information technologies.
In ef-fect, there is almost no original research di-rected to the complex integration of e-learningsystems with the relevant IT such as assistivetechnologies (dialogue systems, speech recog-nition and synthesis .
.
.
), knowledge acquisi-tion and knowledge management systems, etc.Among others, the current LMS do not inte-grate the emerging natural language processing(NLP) applications.
The adopted learning man-agement systems often do not support even thebasic functionality of a language-oriented searchand retrieval of learning objects.Futhermore, the present-day LMS are not di-rectly linked to the wealth of relevant infor-mation and knowledge sources.
In the case ofthe higher education institutions, these sourcescould comprise standard libraries that provideat least an electronic catalogue of their sourcesnowadays, local digital libraries that are usu-ally freely available for academics from particu-lar institution, and the access to comprehensiveelectronic archives or digital libraries that areprovided by many publishers and other organi-zations on a commercial basis.
Companies oftenneglect valuable knowledge sources too.
For ex-ample, they should consider the integration oftheir knowledge bases in the form of recordedquestions and answers from the call centers.The current e-learning systems do not exploitthe potential of available high-level personaliza-tion techniques and adaptability of the form,the content and the access to the education.Most of them cannot play the role of a show-case for the modern teaching methods.This paper surveys several areas, where NLPtechniques and technologies can enhance educa-tional systems and applications.
Some of themexist in the form of prototypes only and havenot been applied in an end-user system yet.Others find their place in software tools thathave been implemented by our team.
They willbe briefly introduced in the paper.The range of LMS used or tested at MasarykUniversity, Brno, Czech Republic (MU) israther broad.
The most important ones are IL-IAS (http://www.ilias.uni-koeln.de/) andMOODLE (http://moodle.org).
Both sys-tems are developed and distributed under theterm of the GNU General Public License andprovide open platform appropriate for the inte-gration on NLP solutions.
The actual project atMU aims at unification of the used e-learningplatforms and their integration with the ad-ministrative information server of the univer-sity (Pavlovic et al, 2003).
Even though sep-arate systems would be more modular, easilymaintainable and extendable, we opt for the in-tegrated solution that will benefit from the per-manent technical support and personal assis-tence of the administrative information serverteam.
We strongly believe that NLP techniquesas a part of the e-learning system can help toopen doors to those faculties and departmentsthat have not discovered the world of computer-mediated education yet.The paper discusses also the incorporation oflanguage resources to support the learner duringhis/her interaction with an educational systemand to provide personalized learning.
We alsotackle the use of NLP technologies and resourcesto support the automatic assessment of learn-ers?
answers, especially those which are in freetext or restricted free text form.
Such assess-ment is useful to learners for controlling theirlearning progress (self-regulation), to teachersfor gathering information about learners andto systems for personalizing interaction.
Con-cept mapping is a knowledge elicitation tech-nique, which stimulates learners to articulateand synthesize their actual states of knowledgeduring the learning process.
We propose theuse of NLP in concept mapping systems in or-der to interactively support learners, who buildconcept maps and automate the process of theassessment of concept maps.
The availabil-ity of wordnet-like semantic networks result-ing from several projects such as EuroWord-Net (Vossen, 1998), BalkaNet (BWN, 2004),RussNet (Azarova, 2004), or broad-coverage on-tologies such as SUMO (SUMO, 2003) providea reasonable starting point for such an effort.The NLP applications in the area of e-learning can be divided according to various cri-teria.
They can be specific for synchronous orasynchronous mode of the course.
The mainfocus of the methods can be stressed to ad-dress e.g.
enhancements of the teaching ma-terial accessibility or the adaptability of LMS.Also the complexity of the needed NLP tech-niques can make the distinctions, whether themethods are already available and prepared tointegration into LMS or they need further de-velopment.
The availability of language re-sources or language technology (lingware) forthe particular language can make the differencetoo.
A related issue can be the portability ofa solution for other languages or other subjectarea, where subject-specific information cannotbe obtained fully automatically.
One can alsodivide the NLP applications in e-learning ac-cording to the NLP modules that are integrated,e.g.
a language-specific morphological moduleor named-entity analyzer could play a crucialrole.
As the educational process has two faces?
learning and teaching, the boarder-line canalso be drawn between the tools focusing on thestudents?
side and those intended for the courseauthors and teachers.The last mentioned aspect has been takeninto account in this paper.
It is organized asfollows: The next section discusses NLP tech-niques aimed at enhancements for the end-usersof e-learning systems ?
students looking for anappropriate e-learning material or those who al-ready enrolled in a course.
The third sectiontackles the support of authors and providers ofthe e-learning facilities that can take the ad-vantage of the language and text technologytoo.
Of course, the boundary between those twocases is not strict at all, so there are NLP toolsthat can help both types of LMS users.
Thefourth section then covers supplementary in-formation technologies such as multimedia andaudio- or video- recording of courses that can-not be classified as NLP per se but are stronglyrelated and, as our experience already shows,their integration should be at least coordinatedwith the employment language technology solu-tions.
The paper concludes with future direc-tions of our research.2 NLP Support of LMS End-users2.1 Basic MethodsSeveral standard NLP tools have been de-veloped recently in Natural Language Pro-cessing Laboratory, Faculty of Informatics(NLPlab FI MU) that are beneficial for manyareas.
E-learning is no exception in this respect.The most important module is morphologicalanalyzer AJKA (Sedlacek and Smrz, 2001) thatserves as a base for various related modules.The importance of the morphology for Czechcan be demonstrated by the history of the websearch engines in the Czech Republic.
Czech isa representative of Slavonic languages charac-terized by abundance of inflective morphologi-cal processes.
For example, nouns, adjectives,pronouns and numerals can be present in one of7 grammatical cases in Czech (nominative, gen-itive, dative, accusative, vocative, locative andinstrumental), three grammatical numbers (sin-gular, plural and dual), and three genders (mas-culine, feminine and neuter), in which masculineexists in two forms - animate and inanimate.The most popular Czech web portals startedwith the search engine provided by Google, butafter a short time they replaced it by special-ized language-aware systems developed usuallyin cooperation with Czech universities.The story shows that even generally recog-nized implementations can be outrivaled, if theyignore language-specific features.
It holds notonly for web environment but also for the e-learning.
Projects implementing LMS need tointegrate strong language support and go be-yond simple localization.A lot of e-learning material has been pro-duced in last years and the number grows asmany new courses are prepared in an electronicform nowadays.
One of the most important ap-plications of AJKA is therefore the system thatenables search in the available e-learning ma-terials.
As the document source language andthe encoding are not always specified explicitly,a text technology module ?
language guesserbased on the language samples in a particularencoding ?
has been also implemented and in-corporated into the e-learning search engine.Another language resource that proved to bevery useful in our experiments is the query ex-pansion module based on information from theCzech WordNet (Pala and Smrz, 2004).
Thecrucial point here is the improvement of the userinterface.
Users are able to search for all wordforms, synonyms, hypernyms and other seman-tically related words, exclude co-hyponyms, etc.They can also choose between orthographic, re-gional, style or register variants, words derivedfrom the term searched, verbs related by theaspect, etc.Of course, even a stemmer or a simple lem-matizer would suit the purpose of the searchengine.
However, the strength of the full mor-phological module becomes apparent when theincorporation of deeper analyses of texts is theissue.
We currently work on a module that willbe able to summarize the content of related doc-uments.
The immediate target of the tool is thesummarization of messages in course discussiongroups.
Sometimes, the students are very ac-tive (the discussion is occasionally off-topic) andeven a simple browsing through the discussionthreads from previous runs of a course couldpresent a tedious work.
The automatic extrac-tion of the most important points can signifi-cantly help newcomers.Recently, we have added automatic classifica-tion of e-learning materials into given categoriesor at least clustering if there are no pre-definedclasses.
Both ?
learners and authors can takeadvantage of these options but the role of self-learning is stressed in the current version.
Thefunction that proved to be most useful for e-learning content is searching for documents sim-ilar to a given course or an additional learn-ing material.
Inspired by the biggest dictionarypublishing servers, we will provide ?a new doc-ument for this day?
function and allow courseauthors to specify what should be the pool ofsearched documents.
As there is currently ane-learning project covering all our university,we strongly believe that such functionality willdraw a broad attention to the new methods ofteaching and learning.All the enhancements of the search for theadditional e-learning material mentioned aboveare also applicable in the search for appropri-ate courses.
The method based on the statis-tical tests known from the computational lin-guistics is provided which enables the automaticextraction of keywords that can be added tothose specified by course authors.
The availablenamed-entity and multiword-expression analyz-ers for Czech have found their place in this task.The summarization module is applicable heretoo as not all authors provide enough metadatato facilitate searching courses or relevant partsof them.
An automatically generated index aswell as glossary or a small encyclopedia from acomprehensive course enables non-linear pass-ing through the learning material, which be-comes a norm.Another technique that enables students toconcentrate on the selected parts of a courseis the matching of the course content to thestudent?s knowledge of a given topic.
Themethod applied to the matching is derived fromthe standard assessment procedure for languagelearners.
As the task for the first assignment,students are asked to write an essay coveringtheir current knowledge about the subject of thecourse.
The content of the document is com-pared with the sections (lectures) of the givencourse and the parts that are not covered suffi-ciently are presented for further study.The described approach can serve as thelaunching point for the LMS personalization.Some e-learning courses already contain specialmechanisms to offer a path through the teach-ing material adapted to the needs of particularuser.
Such an enhancement can improve theacceptance of the content by users that oftenface learning materials that are too in-depth insome parts and too sketchy in others.
Also,the speed of presentation of the teaching ma-terial can vary according to user needs.
Besidesthe above-mentioned assignment of essays, thesimple statistical technique has been adoptedthat automatically evaluates the match of stu-dents?
answers and determines knowledge lev-els of the students.
The solution is now readyto be applied generally to all e-learning coursesprovided by MU.
It can be generalized to allowsemi-automatic generation of tests for each partof the subject matter that would ?send?
stu-dents (back) to the parts they should go throughagain.The presented adaptive components, whichadjust the system to particular users, are notthe only ones that we thought about and thatare covered in our e-learning environment.
AsFI MU hosts centre Teiresias, which is responsi-ble for helping students with special needs fromall departments of MU (http://www.muni.cz/teiresias/), we focused also on the adaptationof LMS for disabled.
The activity of the centeris not limited to the electronic form of learningbut the context of the computer-mediated edu-cation fits its pursuance perfectly.
We currentlyplan the first e-learning course that would befully available both in Czech and in Brail forvisually impaired people.
The content differentfrom a plain text still presents a problem as it issometimes very difficult to find Brail equivalentsfor mathematical expressions or various symbolsand it is always an extremely time-consumingwork.We should also mention the role of the speechsynthesizer developed by our team that is avail-able for the needs of visually impaired partici-pants of the e-learning courses.
The users areable to help other students providing the pro-nunciation of the words, which is not correctlyderived from its orthographical representationby our automatic engine.2.2 Question Answering and ExerciseGenerationThe automatic question answering (QA) is an-other task where the morphological as well assurface syntactic analyses (Smrz and Horak,2000) play the crucial role.
We gain from our ex-perience with ?Encyclopedia Expert?
(Svoboda,2002), which is able to answer free questionsbased on the information extracted from anavailable Czech encyclopedia.
A set of semanticframes and corresponding syntactic structuresis defined that enables analysis of the most fre-quent question types.
The rest of queries areanswered by the full-text search and the iden-tification of the relevant part of the documentcontaining the answer.
Both cases are based onthe question-type analysis module determiningwhat information should be looked for.The employment of the same strategy inthe context of e-learning material is straight-forward.
The current system is able to ap-ply the mechanisms described above to answerquestions based on the content of a particularcourse.
The information about the part of thecourse, which contains the answer, can be alsoreturned.
The evaluation of the QA moduleshowed that the precision on queries that can beanswered just on the content of a given courseis pretty high.
Even for information not cov-ered by the pre-defined frames (answered by thefull-text search) it was about 87 percent (errorsare mainly due to the incorrect or incompleteanalysis by the morphological module ?
un-known words).
On the other hand, practicalassessment of the module showed that the de-scribed functionality has only a limited use forthe course participants.
Many students wouldneed and appreciate a search for answer in amuch broader range of relevant e-learning ma-terials.
Therefore, we are going to provide suchan option.
Of course, the number of errors canincrease in such a setting and it will be the re-sponsibility of the course author to check thefunction of the QA module on the sources heor she identified and to improve the results bymeans of additional linguistic resources neededin the analysis phase.The promising results of automatic QA ledus to the idea to engage similar NLP methodsthe other way around and automatically gen-erate questions and perhaps whole tests basedon the content of particular e-learning courses.It is usually easy to extract ?what is?
ques-tions or ask about a particular fact explicitlystated in the text.
Sometimes, the structureof the documents itself helps to identify theimportant knowledge; sometimes, the above-mentioned keyword extraction algorithm can beemployed.The tricky part of the process is thereforeto create a procedure that would be reliableenough for the automatic checking of answers.Again, the basic QA module is satisfactory forthe questions that expect factoid as the an-swer.
However, it is much more difficult toautomatically evaluate more elaborate answers.Although we are not able to present final re-sults for this part yet, the preliminary ones showthat the application of the same method as forthe comparison student essays with the contentcould provide at least a good approximation ofthe assessment that would be given by humanteachers.The weak point of the described automaticgenerator of exercises is its focus on the fac-tography and impossibility to verify that stu-dents really understand the content, that theygot the heart of the matter and are able to ap-ply the obtained knowledge.
Obviously, it is stillfar from today, when computers will be able tosubstitute human teachers in this respect.
Aninteresting step, that at least simulates such afunction and that is investigated by our currentexperiments, is the employment of standard on-tologies for this purpose.
The interest in on-tologies increased with the recognition of theirimportance for the Semantic Web.
The emerg-ing information systems need the definition ofcommon understanding for their application do-mains.
Even though ontologies are meant as ameans providing human knowledge to machines,they can be very useful for e-learning too.
Theformal specification of the concepts and rela-tions between them takes usually advantage ofthe new XML-family standards, RDF (Beckett,2003) and OWL (van Harmelen et al, 2003).The latter serves as a base for our recent re-search on the possibility to automatically gen-erate exercise questions asking for relations be-tween concepts given by an ontology.
As thenumber of available ontologies for various sub-ject domains will surely increase this directionof research has significant potential.2.3 Language LearningIn our work we pay a special attention to NLPmethods applied in the area of language learningand teaching.
The role of empirical data in theform of corpora ?
large collections of written orspoken language in the digital form ?
is gener-ally recognized in the computational linguistics.Corpora are crucial for language learning too.For example, the English courses taught at ourfaculty bear on BNC (the British National Cor-pus) and other available English corpora (e. g.Times Corpus).
The standard form of the vo-cabulary test is automatically generated whichlists concordances of a word that is deleted fromall the presented occurrences and students haveto fill the gap.Corpora are beneficial not only for generationof queries.
Students often use them as the pri-mary source to learn about the usage of a word.What complicates the process is the presence ofwords students are not familiar with.
Anotherdirection of our research that is currently un-der development is the effort to sort the concor-dance list according to the estimated complexityof words in them.
To be able to compute sucha measure efficiently even for extensive concor-dance lists, the evaluation is based on heuristicsthat take into account frequencies of the wordsin the contexts.New approach that will find its role in themodern computer-mediated language learningis the employment of the word sketch enginedescribed recently in (Kilgarriff et al, 2004).Word sketches are brief automatic corpus-basedsummaries of a word?s grammatical and colloca-tional behavior.
The sketch engine is a corpustool developed by our team which takes as inputa corpus of any language and a correspondinggrammar patterns and generates word sketchesfor the words of that language as its outputs.The most helpful feature of the system fromthe language e-learning point of view are notword sketches per se but the ability to auto-matically compare sketches generated for dif-ferent words.
It is crucial especially for seman-tically similar words, e.g.
for near synonymsor co-hyponyms.
Students are able to com-pare collocates and grammatical relations of thewords and the system can also automaticallygenerate tests checking whether learners knowthe difference between semantically close words.The word sketch engine also generates a the-saurus that can be directly used in inspectingthe knowledge of a particular semantic field.Correct answers are usually required to en-ter next levels of a course.
However, errors canplay a significant role too.
A special attentionhas been paid to the errors produced by stu-dents in project Czenglish.
It is a join project ofNLPlab FI MU and the Department of Englishat the Faculty of Arts.
The e-learning course isbased on popular book ?English or Czenglish?which is intended for students of English at theadvanced or the professional levels.
Studentsproduce translations of sentences presented bythe system.
If a translation does not match astored one, the correct answers are displayed.At the same time, the actual answer is com-pared with the examples of listed incorrect ones.If a match is found the explanation of the erroris presented.
Students may also indicate, thatthey still believe their translation is possible.The message is sent to the teacher that has todecide whether it should be added to the list ofcorrect answers.
Such a decision automaticallyaffects the assessment of the student?s test.3 NLP Techniques for Authors andTeachers3.1 Course PreparationThe quality of LMS raised enormously in lastdecades.
Students are able to work with e-learning applications that are much more user-friendly than some years ago.
However, simulta-neously with the quality increased the complex-ity of the systems for content providers.
To pre-pare a good course, teachers need to learn howto use the authoring system, how to determinethe possible passes through the material etc.The authoring systems are usually linked to par-ticular LMS.
At least a basic understanding ofthe technical stuff and e-learning standards be-hind the particular LMS is often required.
Ourexperience clearly shows that text and languagetechnology can significantly help the e-learningespecially in the phase of course preparation andis extremely beneficial for teachers.The context analysis and the evaluation ofthe similarity between a new e-learning con-tent and the existing courses can be employedto speed-up the process of course preparation.We currently prepare an expert system that willserve as an assistant for authors.
The systemcompares the provided content with the storedcourses and uses found similarities to proposestandard links (to additional materials, on-lineencyclopedias etc.)
It also groups the possibleactions to enable authors to perform many nec-essary actions at one-click.
It is advantageousespecially for providing metadata for the learn-ing objects that are understood as a must forall the future e-learning content.A course with a dense web of hyperlinks canturn to be a nightmare for maintainers in a dy-namic environment.
To keep track of all thelinks and relations between the e-learning con-tent, a new system called DEB has been de-signed and implemented by our team (Smrzand Povolny, 2003).
It is a client-server ap-plication that enables efficient storage and re-trieval of XML documents.
Also complex struc-tural and content queries can be defined.
Forexample, it is the main platform to host theabove-mentioned Czenglish project.
It guaran-tees that the whole content will stay consistentwhen linked information is changed.
The consis-tency checks are defined as XSLT sheets (Clark,1999) and the system reports any violation ofthe predefined constraints.The implemented mechanisms of XSLT trans-formations are powerful enough to be inte-grated in another important task of the cur-rent LMS ?
the support of open e-learningstandards.
All new learning objects developedat our faculty should be developed in sucha way to facilitate sharing and interchange.As the field of LMS is rather hot and manycommercial as well as public-domain systemsemerged recently, the newly produced learningobject should also reflect the possibility of aswitch between platforms without an informa-tion loss.
The currently developed authoringmodule defines XSLT transformations of theprimary document (DocBook-like (Walsh andMuellner, 1999)) format into LOM/SCORMcompliant forms.
It could help to put the plat-form independent standards into wide use.3.2 Course RunThe support to teachers during the run ofcourses is at least equally important as in thephase of the content preparation.
It is true es-pecially if a course has already run several timesand the feed-back from the previous runs shouldbe reflected in the actual one.
The current sys-tems usually ignore the possibility to reflect theexperience from the past years.
The students?answers, either correct or incorrect, are oftenthrown away or used just for elementary statisti-cal profiles.
One of the most valuable resourcesis frequently neglected.The results of our recent research revealthat the detailed analysis of the students?
out-puts offers an extremely useful material di-rectly applicable in the optimization of the e-learning content.
For example, special toolshave been developed for tagging and categoriz-ing the grammatical and stylistic errors in stu-dent essays (Pala et al, 2003).
Teachers markthe errors in the electronic documents.
Studentshave to correct them in the new version but alsoto record the original (incorrect) form and theerror type.
The files in the source format (usu-ally MS Word or LaTeX) are transformed intoan appropriate XML format.
A special form ofa learner corpus has been developed that servesas a base for focusing the teaching in a spe-cial course.
As a side effect, the created re-source is used to develop the Czech grammarchecker (Smrz and Horak, 1999) which will bethe first one based on the large empirical data.The attempts to make the assessment of stu-dent knowledge as objective as possible and toreduce the teacher?s work led to the spreadof multi-choice tests in last decades.
It is awell-known fact that this form of testing hasmany disadvantages too and that the focuson them can easily produce test-experts ratherthan people understanding the subject.
Thecurrent technology offers various means to im-plement intelligent tests and to escape the trapof multi-choice tests.
Our current research con-centrates on the integration of NLP techniquesinto the evaluation module of LMS.
The expe-rience shows that it is relatively easy to providesuch functionality for short answers in the formof phrases described by simple grammatical pat-terns.
The results of the first limited experi-ment are very promising as the method reducedthe number of answers that needed to be pro-cessed manually significantly (only 31 % of thecases remained for the manual check).
However,there are also many open questions concerningscaling-up the method of the answer patterns.The longer the answers are, the less matches be-tween the pre-defined applications are found.
Amore general solution of the analyzing mecha-nism in the form of a general grammar is ob-viously needed.
However, the available gram-mar for Czech is developed for a robust ana-lyzer so the ambiguity of the analysis tends tobe rather high.
Also it is much more difficultfor authors that do not specialize in the com-putational linguistics to define the acceptableforms of answers.
The assessment of open ques-tions is definitively one of the actual topics ofour research.Although the current state-of-the-art in NLPdoes not allow full computerization of the as-sessment of general tests, there are areas, wherethe technology can already take over the roletraditionally falling upon the teacher.
We haverecently implemented the automatic evaluationof programs in the Java programming course atFI MU and also the phrase-structure grammarsdeveloped by students of the ?Introduction tothe computational linguistics?.
Students areobliged to provide their assignments in the des-ignated form.
Pre-defined tests are applied toverify the correctness of the provided solutions.We are to provide a similar function for a gram-matical pre-checking of students?
essays.
Eventhough only a limited number of error types canbe identified automatically, the method can stillreduce a significant portion of the tedious teach-ers?
work.3.3 Additional FunctionsThe previous section discussed how the stan-dard NLP methods can help students to searchin the e-learning data.
The same techniquecan be integrated into the LMS authoring sub-system.
Especially, the tedious linking of theadditional course sources can be facilitated byNLP.
We have designed and implemented a sys-tem which automatically finds relevant articlesand papers available for the students of our fac-ulty or the university (digital libraries providedby ACM and Springer-Verlag), freely accessi-ble on the web (www.arxiv.gov, ResearchIndex)or that are at readers?
disposal at the facultylibraries.
The experience shows that the per-sonalization of the application interface is per-haps even more important for authors than forstudents.
Too complex environment can scareoff and discourage some authors, others call formore functions and more possibilities to deter-mine the behavior of the search engine.Many e-learning courses have been recentlycreated all over the world; many of them areavailable for the general public via Internet now.Most of the resources are written in English.
Itis sometimes impossible to take directly the for-eign version, at least a part of the content needsto be translated.
The NLP technology knownas translation memory finds its place here.
Themotivation of the application of the translationmemories is the same as in the common local-ization of software.
If the content of the e-course will be modified and a new version be-comes available, the ?memory?
of the tool willhelp to translate parts that remain the same orchanged in a limited extent only.
Our experi-ence of the localization based on DejaVu soft-ware (Dej, 2003) is rather positive as it enabledto ?upgrade?
our English-Czech translation injust a week.The last piece of software that will be men-tioned here is the experimental plagiarism iden-tifier.
Very simple methods comparing word n-grams showed to be efficient and precise enoughto identify plagiarism in cases where both theoriginal and the derived document are in onelanguage (Czech).
However, teachers often findessay that are word-for-word translations of anoriginal text.
A reliable automatic identificationof such cases is difficult as the n-gram methodscould not provide reasonable precision due tothe difference of the syntactical structures be-tween Czech and English.
This kind of checkingforms another direction of our future research.4 Web services and MultimediaSupport4.1 Service-Oriented Architecture forE-learningA typical LMS is constructed as a monolithicpiece of software or a set of tools fully integratedinto another system such as administrative in-formation system.
The first really open systemsable to communicate with the environment viaplatform-independent channels emerged in thearea of LMS only recently.
The long-term goalof our research is to provide NLP solutions forLMS via open technologies in the heterogeneoussystems.
The form of web services seems to beappropriate for the task.Generally speaking, our view is based on theidea of the service oriented architecture.
Thisemerging approach assumes that software ap-plications implement only functions specific fortheir tasks, while more general functions are im-plemented as services available on the net.If a method can be provided as a web ser-vice, it immediately evokes the idea of ?out-sourcing?.
A standard task in the prepara-tion of learning courses is the search for addi-tional material, its indexing and linking to theprimary course texts.
As has been presentedabove, NLP can offer supplementary functions,such as automatic question answering.
How-ever, as has been also shown, the preparation ofnecessary resources used in the analysis needsdetailed knowledge about the way a particu-lar NLP techniques work.
One reason for theoutsourcing lies therefore in the effort to en-able users to focus on the content of e-learningcourses only and to provide other services exter-nally (free of charge or on a commercial basis).To motivate the other reason, let us share theexperience of the processing large corpora.
Theabove-mentioned word sketch engine needs sev-eral hours to compute the necessary statistics ona 100,000-word corpus (BNC).
The implemen-tation takes advantage of the available powerfulPC workstations.
To process a 1-billion cor-pus in the same time, we would need a super-computer to perform the task.
However, such acomputer would be idle almost all the time inour laboratory.
It is much easier and cheaperto ?hire?
the computing power needed for theprocessing.Many modern NLP methods are based onlarge language corpora (hundreds thousands ofwords) and lexical databases (e.g.
PrincetonWordNet (Miller et al, 1990) contains morethan 200,000 lexical units and their relations).High-speed networks and Grid systems are veryimportant in this context as they enable totransfer the processing of resource-demandingtasks such as the creation of indices for largecollections of data to the available powerful sys-tems.
Such systems can moreover benefit fromthe analysis of various corpora.
Such tasks canbe fully outsourced without an allocation of owncapacity ?
in terms of efficiency as well as lan-guage resources.The described approach is one of the mostactual directions of the integration of NLP andthe Semantic Web.
It is studied at FI MU espe-cially as a part of the recently proposed projectcombining e-learning and the Grid technologies.We propose to integrate and evaluate servicesbased on the new specification WSRF (Web Ser-vice Resource Framework) that defines a unify-ing view at the web and Grid services.4.2 E-learning and Multimedia SupportThe modern e-learning courses are often supple-mented by a multimedia data.
It can range ofa simple recorded audio from the lecture to thefull video recording and its streaming with in-tegrated switching between the shots of the lec-turer and his/her presentation.
A recent topicwe are working on deals with the software toolsthat can facilitate the preparation of such ane-learning material.
One of the most impor-tant current issues is the research on the col-laboration between LMS and the developmentplatforms for multimedia applications (Author-ware (Aut, 2004) in our case).Processing and indexing the multimedia con-tent is another large issue.
We currently pre-pare a new methodology to link the presenta-tion with the lecture recording.
We also per-formed the first experiments aiming at the eval-uation of automatic linking of the presentationcontent to the recording by means of automaticspeech recognition.
The obtained unsatisfac-tory results influence the changes in the record-ing setting with the aim to improve the acousticquality of the recording.
We would like to definea universal methodology applicable also outsidethe university.The next priority of our research is the sharedteaching.
A pilot course with shared parts of se-lected lectures transmitted between two distantsites (Prague and Brno) will run in the nextsemester.
The experience with the teleconfer-encing will surely be a helpful for this task, espe-cially the verified camera tracking mechanisms.FI MU is also active in the field of streaming thelecture recordings via the high-speed networks.5 ConclusionsThe broader context of all the research de-scribed in the paper is given by the common e-learning strategy built by several leading univer-sities in the Czech Republic.
The initiative in-cludes the support for choosing LMS platform,study of the standards in the area, publishinggood practices for e-learning materials and thenew forms of education, etc.
The incorporationof NLP techniques to extend the functionalityof the current LMS becomes one of the primaryaction lines in the program.The experience gained by some faculties atMU as well as of other cooperating institu-tions demonstrates that preparation and pro-viding of the e-learning courses can generatesignificant profit.
It holds not only for commer-cial providers but also for the universities (dis-tant learning courses).
Moreover, the idea ofcomputer-mediated education is in accord withthe long-term aim to internationalize the uni-versities in the Czech Republic.
The describedNLP techniques and other modern approacheshelp to open the institutions to students fromall over the world.AcknowledgementsThis work was supported by Ministry of Edu-cation of the Czech Republic Research IntentsMSM6383917201 and CEZ:J07/98:143300003,Grant Agency of the Czech Republic GrantGACR 405/03/0913 and by EU project Balka-Net IST-2000-29388.References2004.
Macromedia Authorware 7, http://www.macromedia.com/software/authorware/.Irina V. Azarova.
2004.
RussNet ?
word-net for Russian.
http://www.phil.pu.ru/depts/12/RN/.2004.
Balkanet project website, http://www.ceid.upatras.gr/Balkanet/.Dave Beckett.
2003.
Rdf/xml syntax spec-ification.
http://www.w3.org/TR/2003/WD-rdf-syntax-grammar-20030123/.James Clark.
1999.
XSL Transformations(XSLT) Version 1.0.
(http://www.w3.org/TR/xslt).2003.
DejaVu translation memory and produc-tivity system, http://www.atril.com/.Adam Kilgarriff, Pavel Rychly, Pavel Smrz, andDavid Tugwell.
2004.
The sketch engine.
InProceedings of Euralex 2004.
(to be pub-lished).George Miller, Richard Beckwith, ChristianeFellbaum, Derek Gross, and Katherine Miller.1990.
Five papers on wordnet.
Technical Re-port CSL Report 43, Cognitive Science Lab-oratory, Princeton University.Karel Pala and Pavel Smrz.
2004.
BuildingCzech wordnet.
Romanian Journal of Infor-mation Science and Technology, Special Issueon BalkaNet.
(to be published).Karel Pala, Pavel Rychly, and Pavel Smrz.2003.
Text corpus with errors.
In Proceedingsof TSD 2003, Berlin.
Springer-Verlag.
Lec-ture Notes in Artificial Intelligence.Jan Pavlovic, Tomas Pitner, Pavel Smrz, andJiri Verner.
2003.
Customization of ILIASand its integration with the university infor-mation system.
In ILIAS 2003, Cologne, Ger-many.Radek Sedlacek and Pavel Smrz.
2001.
A newCzech morphological analyser ajka.
In Pro-ceedings of the TSD 2001, pages 100?107,Czech Republic.Pavel Smrz and Ales Horak.
1999.
Implementa-tion of efficient and portable parser for Czech.In Proceedings of TSD?99, pages 105?108,Berlin.
Springer-Verlag.
Lecture Notes in Ar-tificial Intelligence 1692.Pavel Smrz and Ales Horak.
2000.
Large scaleparsing of Czech.
In Proceedings of Efficiencyin Large-Scale Parsing Systems Workshop,COLING 2000, pages 43?50, Saarbrucken:Universitaet des Saarlandes.Pavel Smrz and Martin Povolny.
2003.
DEB -Dictionary Editing and Browsing.
In Proceed-ings of the EACL03 Workshop on LanguageTechnology and the Semantic Web: The 3rdWorkshop on NLP and XML (NLPXML-2003), pages 49?55, Budapest, Hungary.2003.
SUMO ?
Suggested Upper MergedOntology, http://ontology.teknowledge.com/.Zdenek Svoboda.
2002.
Znalec encyklope-die (encyclopedia expert).
Master?s thesis,Faculty of Informatics, Masaryk University,Brno.Frank van Harmelen, Jim Hendler Ian Hor-rocks, Deborah L. McGuinness, Peter F.Patel-Schneider, and Lynn Andrea Stein.2003.
OWL web ontology language reference.http://www.w3.org/TR/owl-ref/.Piek Vossen, editor.
1998.
EuroWordNet: AMultilingual Database with Lexical SemanticNetworks.
Kluwer Academic Publishers, Dor-drecht.Norman Walsh and Leonard Muellner.
1999.DocBook: The Definitive Guide.
O?Reilly.
