BioNLP 2007: Biological, translational, and clinical language processing, pages 49?56,Prague, June 2007. c?2007 Association for Computational LinguisticsMining a Lexicon of Technical Terms and Lay EquivalentsNoemie Elhadad and Komal SutariaComputer Science DepartmentThe City College of New YorkNew York, NY 10031noemie@cs.ccny.cuny.edu, kdsutaria@gmail.comAbstractWe present a corpus-driven method forbuilding a lexicon of semantically equiva-lent pairs of technical and lay medical terms.Using a parallel corpus of abstracts of clin-ical studies and corresponding news sto-ries written for a lay audience, we identifyterms which are good semantic equivalentsof technical terms for a lay audience.
Ourmethod relies on measures of association.Results show that, despite the small size ofour corpus, a promising number of pairs areidentified.1 IntroductionThe field of health literacy has garnered much at-tention recently.
Studies show that most docu-ments targeted at health consumers are ill-fitted tothe intended audience and its level of health liter-acy (Rudd et al, 1999; McCray, 2005).
While thereare many components involved in health literacy thatare specific to the reader (e.g., reading level and cul-tural background), we investigate what can be donefrom the standpoint of the text to adapt it to the liter-acy level of a given reader.
As such, we set ourselvesin the context of a text-to-text generation system,where a technical text is edited to be more compre-hensible to a lay reader.
An essential resource forsuch an editing tool is a lexicon of paraphrases, orsemantically equivalent terms.
In this paper, we in-vestigate a corpus-driven method for building sucha lexicon.
We focus on terms that are recognized bythe UMLS (UMLS, 1995), both for technical and laycandidate terms for equivalence.Because we have lay audiences in mind, our defi-nition of semantic equivalence must be broader thana notion of strict medical equivalence utilized bymedical experts.
Thus, while a medical dictionarylike UMLS assigns different concept unique identi-fiers (CUIs) to two particular terms, such as percu-taneous transluminal coronary angioplasty and an-gioplasty, these terms should be considered seman-tically equivalent for the purposes of lay readers.Besides enabling a text tailoring system to adapttechnical texts for a lay audience, a lexicon ofsemantically equivalent technical/lay terms wouldbenefit other tools as well.
For instance, the Con-sumer Health Vocabulary initiative1 is a comprehen-sive list of UMLS terms familiar to lay readers.
Ourlexicon could help augment the terms with equiva-lence links to technical terms.
While much researchof late has been devoted to identifying terms incom-prehensible to lay readers, such research has not es-tablished links between technical terms and equiva-lent lay terms beyond their CUI information (Zenget al, 2005; Elhadad, 2006).The key points of our approach are: (1) the useof combined measures of association to identifypairs of semantically equivalent terms, and (2) aknowledge-based heuristic which acts as a powerfulfilter for identifying semantically equivalent pairs.Our method does not rely on human labeling of se-mantically equivalent term pairs.
As such, it is un-supervised, and achieves results that are promisingconsidering the small size of the corpus from whichthe results are derived.This paper is organized as follows.
The next sec-tion describes our parallel corpus of paired techni-cal/lay documents.
The Methods section describesthe different measures of association we experi-mented with, how we combine them to leverage theircomplimentary strengths, and our semantic filter.The Results section reports the evaluation againstour gold standard and a discussion of our results.1http://www.consumerhealthvocab.org492 Data DescriptionBecause our ultimate goal is to learn, in a data-driven fashion, semantic equivalents of terms thatare too technical for lay readers, we can benefit fromhaving instances of texts which relay similar infor-mation but are conveyed in different styles.
Wecollect a corpus similar in structure to those usedin the field of statistical machine translation.
But,instead of having two collections in different lan-guages, we collect texts written for two different au-diences: medically trained readers (technical collec-tion) and health consumers (lay collection).The lay collection is composed of news storiesfrom the ReutersHealth E-line newsfeed2 summariz-ing research in the medical field.
Reuters journaliststake technical publications and report the main find-ings and methods and, on occasion, include inter-views with the authors of the scientific publication.The stories are targeted at a lay audience with a 12th-grade reading level.
Furthermore, every story in ourcollection contains a reference to the original scien-tific publication.
Thus, it is possible to gather theoriginal texts, which convey similar information butwere written for a technical audience.
The storiesdraw upon studies from reputable medical journals,such as Annals of Internal Medicine, New EnglandJournal of Medicine and Lancet.The technical collection in our corpus is com-posed of the original scientific articles correspond-ing to each news story in the lay collection.
Accord-ingly, the lay and technical collections contain thesame number of documents and are parallel at thedocument level.
That is, each technical documenthas a lay equivalent and vice-versa.
Because a laydocument is a summary of a technical article and is,hence, much shorter than the original scientific ar-ticle, we decided to include only the abstract of thetechnical document in our collection.
This way, thetechnical and lay documents are comparable in con-tent and length.
It should be noted, however, thatthe content in a technical/lay document pair is notparallel, but comparable (McEnery and Xiao, 2007):there is no natural sentence-to-sentence correspon-dence between the two texts.
This is to be expected:technical abstracts contain many technical details,while lay stories, to provide background, introduce2http://www.reutershealth.comWords SentencesMin Max Avg Min Max AvgTechnical 137 565 317 5 18 10Lay 187 1262 444 6 42 15Table 1: Statistics for the Technical and Lay collec-tions.
Each contains 367 documents.information entirely absent from abstracts.
In addi-tion, the lay stories drastically rearrange the order inwhich information is typically conveyed in technicalabstracts.
For these reasons, our corpus is not paral-lel at the sentence level and, thus, differs from otherbilingual parallel corpora used in machine transla-tion.To ensure that some significant number of termsappears with sufficient frequency in our corpus inorder to induce equivalent pairs automatically, wefocused on articles and stories in a single domain:cardiology.
We identified the original scientific ar-ticle manually, as the lay document only contains areference, not an actual link.
For this reason, only arelatively small amount of data could be collected:367 pairs of documents (see Table 1 for statistics).3 Methods3.1 Data ProcessingWe focus in this paper on finding term equiva-lents when both terms are recognized by the UMLS.Thus, our first step in processing our collections is toidentify terms as defined by the UMLS.
Both collec-tions are processed by our tool TermFinder (Teufeland Elhadad, 2002).
Sentences are identified and thetexts are tokenized and tagged with part-of-speechinformation.
Noun phrases are identified with a shal-low parser.
Next, terms are identified by looking upthe noun phrases in the meta-lexicon of UMLS foran exact match.
Terms are tagged with their con-cept unique identifier (CUI) and a semantic type,both provided by UMLS.
For our purposes, we onlyconsider a subset of all the terms listed in UMLS,based on their semantic type.
This is due to thefact that certain UMLS semantic types are unlikelyto yield technical terms in need of simplification.As such, terms belonging to semantic types suchas ?Activity,?
?Family Group?
or ?Behavior?
wereleft untagged.
Terms with semantic types such as?Disease or Syndrome?
or ?Therapeutic or Preven-50Correspondinglay doc.
containslay termCorresponding laydoc.
does not con-tain lay termTechnicaldoc.
containstech terma bTechnical doc.does not con-tain tech termc dTable 2: Contingency table for (tech term,lay term).tive Procedure,?
on the other hand, were consideredterms.
For instance, both the terms PTCA and percu-taneous transluminal coronary angioplasty have thesame CUI C0002997, as they are considered syn-onyms by UMLS.
The term balloon angioplasty hasthe CUI C0002996.
Both C0002997 and C0002996have the semantic type ?Therapeutic or PreventiveProcedure.
?3.2 Contingency TableWe call (tech term, lay term) a term pair, wheretech term is a term occurring in one or more tech-nical documents and lay term is a term presentin at least one of the corresponding lay docu-ments.3 For any such pair, we can compute acontingency table based on co-occurrence.
Ourdefinition of co-occurrence is slightly unusual:tech term and lay term co-occur in one documentpair if tech term appears at least once in the techni-cal document and lay term appears at least once inthe corresponding lay document.
Our unit of contentis document frequency for a CUI, i.e., the number ofdocuments in which a given CUI appears.
For in-stance, in our data, the contingency table for the termpair (MI, heart attack) shows the following counts:the document frequency of the CUI correspondingto MI in the technical collection is 98; the docu-ment frequency of the CUI corresponding to heartattack in the lay collection is 161.
Among these doc-uments, there are 84 technical/lay document pairs(out of the total of 367 paired documents) in whichthe CUI for MI occurs on the technical side and theCUI for heart attack occurs on the lay side.
Hence,the contingency table for this term pair is, following3This means that if tech term and lay term have no tech-nical/lay document in common, lay term is not considered apossible candidate for semantic equivalence for tech term.the notations of Table 2: a = 84, b = 98-84 = 14, c =161-84 = 77, and d = 367-98-161+84 = 192.At this stage of processing, lexical terms are ab-stracted by their CUIs.
We do this to maximize thepossible evidence that two terms co-occur.
For in-stance, the document frequency for MI in our tech-nical collection is 20, while the document frequencyfor its corresponding CUI is 98.
Section 3.7 de-scribes how we proceed from identifying equivalentterms at the CUI level to finding lexical equivalents.3.3 Gold StandardTo evaluate the validity of our approach, we col-lected all possible term pairs at the CUI level in ourcorpus (that is, all the term pairs for which a con-tingency table is computed).
We then whittled thisset down to those pairs where each CUI occurs inat least two documents.
This resulted in 2,454 pairsof CUIs.
We asked our medical expert, an internistin practice who interacts with patients on a daily ba-sis, to indicate for each pair whether the terms wereequivalent from a medical standpoint in the con-text of communicating with a patient.4 An opera-tional test for testing the equivalence of two terms iswhether he would use one term for the other whentalking to a patient.
We indicated to our expert thatthe terms should be equivalent out of context.
So,for instance, while the pair (myocardial infarction,complication) could be deemed equivalent in certainspecific contexts, these terms are not generally con-sidered equivalent.
Table 3 shows examples of pairsannotated as semantic equivalents for lay readers.5The list of terms contained only the actual lexicalterms and no information from the UMLS to avoidbiasing our expert.Out of the 2,454 CUI pairs provided to our medi-cal expert, 152 pairs were labeled as equivalent.
Outof the 152 pairs, only 8 (5.3%) had different seman-tic types.
Interestingly, 84 pairs (55.3%) had differ-ent CUIs.
This confirms our intuition that the notionof semantic equivalence for lay readers is looser thanfor medically knowledgeable readers.4While it is in some ways counterintuitive to rely on a tech-nical expert to identify lay semantic equivalents, this expertisehelps us validate equivalences from a medical standpoint.5In the table, DIGN stands for ?Diagnostic Procedure,?DISS for ?Disease or Symptom,?
FIND for ?Finding,?
andPATH for ?Pathological Finding.
?51Technical term Lay termmyocardial infarction | C0027051 | DISS heart attack | C0027051 | DISSSBP | C0428880 | DIGN systolic blood pressure | C0428880 | DIGNatrial fibrillation | C0004238 | PATH arrhythmia | C0003811 | PATHhypercholesterolemia | C0020443 | DISS high cholesterol | C0848569 | FINDmental stress | C0038443 | DISS stress | C0038435 | PATHTable 3: Examples from the gold standard of term pairs considered equivalent.3.4 Measures of AssociationGiven a term pair (tech term, lay term) and its cor-responding contingency table, we want to determinewhether lay term is a valid semantic equivalent oftech term from the standpoint of a lay reader.
Werely on three alternative measures of association in-troduced in the Statistics literature: the ?2 statis-tic, the ?
measure, and odds ratio.
All of thesemeasures are computed as a function of the contin-gency table, and do not rely on any human labelingfor equivalence.
Measures of association have beenused traditionally to identify collocations (Manningand Schu?tze, 1999).
Here we investigate their usefor building a lexicon.3.4.1 The ?2 StatisticThe standard chi-square statistic (?2) is usedto determine whether the deviation of observeddata from an expected event occurs solely bychance (Goodman and Kruskal, 1979).
Our nullhypothesis for this task is that the presence oflay term in a lay document is independent of thepresence of tech term in its correspondent techni-cal document.
Thus, any pair of terms for which the?2 is above the critical value at a given level of sig-nificance are considered semantic equivalents.
Oneimportant constraint for the measures to be valid isthat the observed data be large enough (more thanfive observations per cell in the contingency table).The ?2 statistic for our 2x2 contingency table,and with N being the total number of documentpairs, is calculated as follows:?2 = N(ad ?
bc)2(a + b)(a + c)(c + d)(b + d)Since ?2 is a true statistic, we can rely on criticalvalues to filter out pairs with low associative power.In our case, we set the significance level at .001(with a critical value for ?2 of 10.83).C0011847 ?
C0011847 SumC0011849 a = 13 b = 8 21?
C0011849 c = 40 d = 306 346Sum 53 314 367Table 4: Contingency table for (C0011849,C0011847).3.4.2 The ?
and ?
* MeasuresThe lambda measure (?)
assesses the extent towhich we can predict the presence of lay term in alay document by knowing whether the original tech-nical document contained tech term (Goodman andKruskal, 1979).
?
is an asymmetrical measure ofassociation.
Since a lay document is always writ-ten based on an original technical document, it isa plausible assumption that the presence of a spe-cific term in the technical document influenced thelexical choices of the author of the lay document.Thus, we consider the presence of tech term in atechnical document the antecedent to the presenceof lay term in the corresponding lay document, and,accordingly, operate in the setting of predicting thepresence of lay term.We present the intuition behind ?
in the contextof the following example.
Consider the contingencytable for the technical CUI C0011849 (diabetes mel-litus) and C0011847 (diabetes) in Table 4.
The taskis, given a random lay document, to predict which oftwo available categories it belongs to: either it con-tains the lay CUI (in our example, CUI C0011847for diabetes) or it does not.
There are two possi-ble cases: either (1) we do not have any knowl-edge about the original technical document, or (2)we know the original technical document and, there-fore, we know whether it contains the antecedent (inour example, CUI C0011849 for diabetes mellitus).Without any prior knowledge (case (1)), thesafest prediction we can make about the lay doc-ument is the category with the highest probabil-52ity.
The probability of error in case (1) is Perr1 =N?Max(a+c,b+d)N .In our example, the safest bet is ?
C0011847, witha raw count of 314 documents, and a probability oferror of Perr1 = 0.1444.If we have prior knowledge about the originaltechnical document (case (2)), then our safest pre-diction differs.
If we know that the technical doc-ument contains the CUI C0011849 (diabetes melli-tus), then our safest prediction is the category withthe highest probability: C0011847, with a raw countof 13 documents.
If, on the other hand, we knowthat the technical document does not contain theCUI C0011849, our safest prediction is the category?
C0011847, with a raw count of 306 documents.Thus, overall the probability of error in case (2) isPerr2 = N?
(Max(a,b)+Max(c,d))N .In our example, knowledge about the original tech-nical document lowers the probability of error toPerr2 = 0.1308.The ?
measure is defined as the relative decreasein probability of error in guessing the presence oflay term in a lay document ?
= Perr1?Perr2Perr1which, using our notation for contingency tables,can be expressed as?
= Max(a, b) + Max(c, d) ?
Max(a + c, b + d)N ?Max(a + c, b + d)In our example, ?
= 0.094. ?
ranges between 0and 1.
A value of 1 means that knowledge aboutthe presence of tech term in the original techni-cal document completely specifies the presence oflay term in its corresponding lay document.
A valueof 0 means that knowledge about the presence oftech term in the original technical document doesnot help in predicting whether lay term is present inits corresponding lay document.The ?
measure is not a test of significance like?2.
For instance, while two independent variablesnecessarily have a ?
of 0, the opposite is not neces-sarily true: it is possible for two dependent variablesto have a ?
of 0.
In our setting in particular, anycontingency table where a=b will provide a ?
of 0.Since ?
is computed as a function of maxima ofrows and columns, ?
can easily be biased toward theoriginal proportions in the antecedent.
In our exam-ple, for instance, a very large proportion of technicaldocuments has no occurrence of C0011849, diabetesmellitus (94.3% of the technical documents).
Butfor our purposes, such contingencies should not af-fect our measure of association, as the proportion oftechnical documents happening not to contain a par-ticular term is just an artificial consequence of cor-pus collection.
?
* is a variant of ?
also proposed byGoodman and Kruskal (1979) and is able to take thisfact into account.
It is computed using the same for-mula as ?, but the elements of the contingency tableare modified so that each category of the antecedentis equally likely.
In our case, this means: N*=1,a*=0.5a/N(a+b), b*=0.5b/N(a+b), c*=0.5c/N(c+d),and d*=0.5d/N(c+d).
Going back to our example ofdiabetes mellitus and diabetes, we now find ??
=0.324, which is much higher than the original ?
of0.094, and which indicates a strong association.We focus on ?
* as a measure of association forsemantic equivalence of term pairs.
Since ?
and ?
*are not true statistics, there is no significance levelwe can rely on to set a threshold for them.
Instead,we estimate an optimal threshold from the perfor-mance of ?
* on a development set.
The develop-ment set was obtained in the same manner as thegold standard and contains 50 term pairs.
This isa small number of pairs, but the term pairs in thedevelopment set were carefully chosen to containmostly semantically equivalent pairs.
In our experi-ments, the optimal value for ?
* was 0.3.
Thus, ?
* isused as a binary test for our purposes: tech term andlay term are considered semantically equivalent iftheir ?
* is above 0.3.3.4.3 Odds RatioOdds ratio is a measure of association that focuseson the extent to which one category in the contin-gency table affects another (Fleiss et al, 2003).
Forour contingency table, the odds ratio is expressed asfollows:OR = adbcFor instance, given the contingency table of Ta-ble 4, the odds ratio for the pair (diabetes mellitus,diabetes) is 12.43, which means that a lay docu-ment is 12.43 times more likely to contain the CUIC0011847, for diabetes, if its original technical doc-ument contains the term C0011849, for diabetesmellitus.53Like ?
*, odds ratio is not a true statistic and,therefore, does not have any critical value for sta-tistical significance.
We estimated the optimal valueof a threshold for OR based on the same develop-ment set described above.
The threshold for OR isset to 6.
Thus, OR is used as a binary test for ourpurposes: tech term and lay term are consideredsemantically equivalent if their OR is above 6.3.5 Combining the Measures of AssociationEach of the measures of association described aboveleverages different characteristics of the contingencytables, and similarly, each has its limitations.
Forinstance, ?2 cannot be computed when there arenot sufficient observations, and ?
* can equal 0, evenwhen there is a strong association between the twoterms.
We combine measures of association in thefollowing fashion: two terms are considered equiva-lent if at least one of the measures determined so.3.6 Semantic FilteringThe measures of association described above andtheir combination provide information solely basedon corpus-derived data.
Since all our counts arebased on co-occurrence, a measure of association byitself can encompass many types of semantic rela-tions.
For instance, the pair for (stroke, brain) testspositive with our three measures of association.
In-deed, there is a strong semantic association betweenthe two terms: strokes occur in the brain.
Theseterms, however, do not fit our definition of seman-tic equivalence.We rely on knowledge provided by the UMLS,namely semantic types, to help us filter equiv-alent types of associations among the candidateterm pairs.
One can assume that sharing semantictypes is a necessary condition for semantic equiva-lence.
Our semantic filter consists of testing whethertech term and lay term share the same semantictypes, as identified by our tool TermFinder.3.7 Lexical ChoiceSo far, term pairs are at the CUI level.
The measuresof association and the semantic filter provide a wayto identify candidates for semantic equivalence.
Westill have to figure out which particular lexical itemsamong the different lexical terms of a given CUI areappropriate for a lay reader.
For instance, the pair(C0027051, C0027051) is considered a good candi-date for semantic equivalence.
In the technical col-lection, the lexical terms contributing to the CUI areAMI, AMIs, MI, myocardial infarction, myocardialinfarct and myocardial necrosis.
In the lay collec-tion, however, the lexical terms contributing to thesame CUI are heart attack, heart attacks, and my-ocardial infarction.
Clearly, not all lexical items fora given CUI are appropriate for a lay reader.To select an appropriate lay lexical term, we relyon the term frequency of each lexical item in thelay collection (Elhadad, 2006).
In our example, thelexical term ?heart attack?
has the highest term fre-quency in the lay collection among all the variantswith the same CUI.
Thus, we chose it as a semanticequivalent of any lexical term of the CUI C0027051in the technical collection.If a technical term has several candidate semanticequivalents at the CUI level, the lexical lay term ischosen among all the lay terms.
For instance, (ad-verse effect, side effect) and (adverse effect, compli-cations) are two valid equivalents, but side effectshas a term frequency of 16 in our lay collection, andcomplications has a lay term frequency of 35.
Thus,complication is selected as the lay equivalent for ad-verse effect.4 ResultsWe report on the two steps of our system: (1) find-ing semantic equivalents at the CUI level, and (2)finding an appropriate lay lexical equivalent.Finding Semantic Equivalents at the CUI LevelTable 5 shows the precision, recall and F-measure(computed as the harmonic mean between precisionand recall) against our gold standard for the threealternative measures of association, including dif-ferent combinations of these, and also adding thesemantic filter.
In addition, we report results for acompetitive baseline based solely on CUI informa-tion, where tech term and lay term are consideredequivalent if they have the same CUI.The baseline is fairly competitive only becauseof its perfect precision (CUI in Table 5).
Its recall,however (44.7), indicates that building a lexicon oftechnical and lay equivalents based solely on CUIinformation would miss too many pairs within theUMLS.54Method P R F Method P R F Method P R Flam 40.8 20.4 27.2 chi,odds 20.6 78.3 32.6 CUI 100 44.7 61.8chi 38.7 23.7 29.4 chi,lam,odds 20.6 80.3 32.8 sem,odds 57.8 71.1 63.7sem,lam 76.3 19.1 30.5 sem,chi 81.8 23.7 36.7 sem,lam,odds 57.4 73.7 64.6odds 20.4 74.3 32 chi,lam 38.2 39.5 38.8 sem,chi,odds 58.5 75 65.7lam,odds 20.5 77 32.3 sem,chi,lam 79.5 38.2 51.6 sem,chi,lam,odds 57.9 77 66.1Table 5: Precision, Recall and F measures for different variants of the system.Relying on only one measure of association with-out any semantic filtering to determine semanticequivalents is not a good strategy: ?
* (lam in Ta-ble 5), ?2(chi) and OR (odds), by themselves, yieldthe worst F measures.
Interestingly, the measuresof association identify different equivalent pairs inthe pool of candidate pairs.
Thus, combining themincreases the coverage (or recall) of the system.For instance, ?
* by itself has a low recall of 20.4(lam).
When combined with OR, it improves the re-call from 74.3 (odds) to 77 (lam,odds); when com-bined with ?2, it improves the recall from 23.7 (chi)to 39.5 (chi,lam).
Combining the three measuresof association (chi,lam,odds) yields the best recall(80.3), confirming our hypothesis that the measuresare complementary and identify pairs with differentcharacteristics in our corpus.While combining measures of association im-proves recall, the semantic filter is very effective infiltering inaccurate pairs and, therefore, improvingprecision: ?
*, for instance, improves from a pre-cision of 40.8 (lam) to 76.3 (sem,lam) when thefilter is added, with very little change in recall.The best variant of our system in terms of F mea-sure is, not surprisingly, combining the three mea-sures of association and adding the semantic filter(sem,chi,lam,odds in Table 5).The results of these experiments are surprisinglygood, considering that the contingency tables arebuilt from a corpus of only 367 document pairs andrely on document frequency (not term frequency).These quantities are much smaller than those usedin machine translation, for instance.Finding Lay Lexical Equivalents We evaluateour strategy for finding an appropriate lay lexicalitem on the list of 152 term pairs identified by ourmedical expert as semantic equivalents.
Our strat-egy achieves an accuracy of 86.7%.5 Related WorkOur work belongs to the field of paraphrase identi-fication.
Much work has been done to build lexi-cons of semantically equivalent phrases.
In gener-ation systems, a lexicon is built manually (Robin,1994) or by relying on an electronic thesaurus likeWordNet (Langkilde and Knight, 1998) and settingconstraints on the type of accepted paraphrases (forinstance, accepting only synonyms as paraphrases,and not hypernyms).
Building paraphrase lexiconsfrom a corpus has also been investigated.
Jacqueminand colleagues (1997) identify morphological andsyntactic variants of technical terms.
Barzilay andMcKeown (2001) identify multi-word paraphrasesfrom a sentence-aligned corpus of monolingual par-allel texts.
One interesting finding of this work isthat the mined paraphrases were distributed acrossdifferent semantic links in WordNet: some para-phrases had a hypernym relation, while others weresynonyms, and others had no semantic links at all.The composition of our gold standard confirms thisfinding, since half of the semantically equivalentterms had different CUIs (see Table 3 for examplesof such pairs).If we consider technical and lay writing styles astwo sublanguages, it is easy to see an analogy be-tween our task and that of machine translation.
Iden-tifying translations for words or phrases has beendeeply investigated in the field of statistical machinetranslation.
The IBM models of word alignments arethe basis for most algorithms to date.
All of these areinstances of the EM algorithm (Expectation Maxi-mization) and rely on large corpora aligned at thesentence level.
We cannot apply an EM-based modelto our task since we have a very small corpus ofpaired technical/lay documents, and EM requireslarge amounts of data to achieve accurate results.Moreover, the technical and lay documents are notparallel, and thus, we do not have access to a sen-55tence alignment.
Of course, our task is easier thanthe one of machine translation, since we focus on?translating?
only technical terms, rather than everysingle word in a technical document.Gale and Church (1991) do not follow the EMmodel, but rather find French translations of Englishwords using a ?2-like measure of association.
Theircorpus is the parallel, sentence-aligned Hansard cor-pus.
Our method differs from theirs, as we do buildthe contingency table based on document frequen-cies.
Gale and Church employ sentence-level fre-quencies.
Our corpus is much smaller, and the sen-tences are not aligned (for comparison, we have367 document-pairs, while they have nearly 900,000sentence pairs).
Another difference between our ap-proach and theirs is our use of the semantic filterbased on UMLS.
We can afford to have such a filterbecause we focus on finding semantic equivalents ofUMLS terms only.6 Conclusions and Future WorkWe presented an unsupervised method for identi-fying pairs of semantically equivalent technical/layterms.
Such a lexicon would benefit research inhealth literacy.
In particular, it would benefit a sys-tem which automatically adapts a medical technicaltext to different levels of medical expertise.We collected a corpus of pairs of technical/laydocuments, where both documents convey similarinformation, but each is written for a different au-dience.
Based on this corpus, we designed a methodbased on three alternative measures of associationand a semantic filter derived from the UMLS.
Ourexperiments show that combining data-driven statis-tics and a knowledge-based filter provides the bestresults.Our method is concerned specifically with pairsof terms, as recognized from UMLS.
While UMLSprovides high coverage for technical terms, that isnot the case for lay terms.
In the future, we wouldlike to extend our investigation to pairs consistingof a technical term and any noun phrase which issufficiently frequent in our lay collection.
Findingsuch pairs would have the side effect of augmentingUMLS, a primarily technical resource, with minedlay terms.
One probable step towards this goal willbe to increase the size of our corpus of paired tech-nical and lay documents.ReferencesR.
Barzilay and K. McKeown.
2001.
Extracting para-phrases from a parallel corpus.
In Proc.
ACL?01, pages50?57.N.
Elhadad.
2006.
Comprehending technical texts:Predicting and defining unfamiliar terms.
In Proc.AMIA?06, pages 239?243.J.
Fleiss, B. Levin, and M.C.
Paik.
2003.
StatisticalMethods for Rates and Proportions.
Wiley.W.
Gale and K. Church.
1991.
Identifying word cor-respondences in parallel texts.
In Proc.
Speech andNatural Language Workshop, pages 152?157.L.
Goodman and W. Kruskal.
1979.
Measures of Associ-ation for Cross Classifications.
Springler Verlag.C.
Jacquemin, J. Klavans, and E. Tzoukermann.
1997.Expansion of multi-word terms for indexing and re-trieval using morphology and syntax.
In Proc.ACL?97, pages 24?31.I.
Langkilde and K. Knight.
1998.
Generation that ex-ploits corpus-based statistical knowledge.
In Proc.COLING-ACL?98, pages 704?710.C.
Manning and H. Schu?tze.
1999.
Foundations of Sta-tistical Natural Language Processing.
MIT Press.A.
McCray.
2005.
Promoting health literacy.
JAMA,12(2):152?163.A.
McEnery and Z. Xiao.
2007.
Parallel and comparablecorpora: What is happening?
In Incorporating Cor-pora.
The Linguist and the Translator.
Clevedon.National Library of Medicine, Bethesda,Maryland, 1995.
Unified Medical Lan-guage System (UMLS) Knowledge Sources.http://www.nlm.nih.gov/research/umls/.J.
Robin.
1994.
Revision-Based Generation of Natu-ral Language Summaries Providing Historical Back-ground.
Ph.D. thesis, Columbia University.R.
Rudd, B. Moeykens, and T. Colton.
1999.
Annual Re-view of Adult Learning and Literacy, chapter 5.
Healthand literacy: a review of medical and public health lit-erature.
Jossey Bass.S.
Teufel and N. Elhadad.
2002.
Collection and Lin-guistic Processing of a Large-scale Corpus of MedicalArticles.
In Proc.
LREC?02, pages 1214?1218.Q.
Zeng, E. Kim, J. Crowell, and T. Tse.
2005.
A textcorpora-based estimation of the familiarity of healthterminology.
In Proc.
ISBMDA?05, pages 184?192.56
