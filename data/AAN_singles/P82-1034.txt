DESIG~ DIMENSIONS FOR NON-NORMATIVE ONDERSTARDING SYSTEMSRobert J. BobrowMadelelne BatesBolt Beranek and Newman Inc.10 Moulton StreetCambridge, Massachusetts 02238I.
I n t roduct ionThis position paper is not based upon directexperience with the design and implementation of a"non-normative" natura l  language system, butra ther  draws upon our work on cascade \[11\]architectures for understanding systems in whichsyntactic, semantic and discourse processescooperate to determine the "best" interpretationof an utterance in a given discourse context.
TheRUS and PSI-KLONE systems \[I, 2, 3, 4, 5\], whichembody some of these principles, provide a strongframework for the development of non-normatlvesystems as illustrated by the work of Sondhelmerand Welschedel \[8, 9, 10\]and others.Here we pose a number of questions in order toclarify the theoretical and practical issuesinvolved in building "non-normatlve" naturallanguage systems.
We give brief indications ofthe range of plausible answers, in order tocharacterize the space of decisions that must bemade in deslgnlng such a system.
The firstquestions cover what is intended by the ill-defined term "non-normatlve system", beyond theimportant but vague desire for a "friendly andflexible" computer system.
The remainingquestions cover several of the architecturalissues involved in building such a system,including the categories of knowledge to berepresented in the system, the  staticmodularization of these knowledge sources, and thedynamic information and control flow among thesemodules.The way the system is to deal with ill-formedinput depends in a strong way on how much thesystem is expected to do with well-formed input.Ad hoc data base retrieval systems (a currentlyhot topic) pose different constraints than systemsthat are expected to enter into a substantlaldialogue with the user.
When the behavior of thesystem is severely limited even given perfectinput, the space of plausible inputs is alsolimited and the search for a reasonableinterpretation for ill-formed input can be madesubstantially easier by asking the user a fewwell-chosen questions.
In the dbms retrievaldomain, even partially processed input can be usedto suggest what information the user is interestedin, and provide the basis for a usefulclarification dialogue.What i s  the system expected to do with i l l -formed input?The system may be expected to understand theinput but not provide d i rec t  feedback on er rors(e.g.
by independently decldlng on the (mostplausible) interpretation of the input, or byquestioning the user about possible alternativeinterpretations).
Alternatively, the system mightprovide feedback about the probable source of itsdifficulty, e.g.
by pointing out the portion ofthe input which it could not handle (if it can belocalized), or by characterizing the type of errorthat occurred and describing general ways ofavoiding such errors in the future.2.
System performance goalsWhat are the overall performance objectives ofthe system?Marcus has argued \[7\] that the "well-formedness" constraints on natural langua6e makeit possible to parse utterances with minimal (orno) search.
2 The work we have done on the RU3system has convinced us that this is true and thatcascading semantic interpretatlon with syntacticanalysis can further improve the efficiency of theoverall system.
The question naturally arises asto whether the performance characteristics of thismodel must be abandoned when the input does notsatisfy the well-formedness constraints imposed bya competence model of language.
We believe thatit is possible to design natural language systemsthat can handle well-formed input efficiently andill-formed input effectively.3.
Arch i tec tura l  issuesIn order to design a fault-tolerant languageprocessing system, it is important to have a modelfor the component processes of the system, howthey interact in handling well-formed input, andhow each process is affected by the differenttypes of constraint vlolatlons occurring In 111-formed input.What categories of knowledge are needed tounderstand well-formed input, and how are theyused?Typically, a natural language understandlngsystem makes use of lexical and morphologicalknowledge (to categorize the syntactic andsemantic properties of input items), syntacticknowledge, semantic knowledge, and knowledge ofdiscourse phenomena (here we include issues ofellipsis, anaphora and focus, as well as plan153recognition ("why did he say this to me now?")
andrhetorical structure).
Of course, saying thatthese categories of knowledge are represented doesnot imply anything about the static(representational) or dynamic (processinteraction) modularizatlon of the resultingsystem.We will assume that the overall systemconsists of a set of component modules.
Onecommon decomposition has each category ofknowledge embodied in a separate component of theNLU system, although it is possible to fuse theknowledge of several categories into a singleprooeas.
Given this assumption, we must then askwhat control and information flow can be imposedon the interaction of the modules to achieve theoverall performance goals imposed on the system.In analyzing how violations of constraintsaffect the operation of various components, it isuseful to distinguish clearly between theinformation used w l th ina  component to compute itsoutput, and the structure and content of theinformation which it oasses on to othercomponents.
It is also important to determine howcritically the operation of the receivingcomponent depends on the presence, absence orinternal inconsistency of various features of theinter-component information flow.As an example, we will consider theinteraction between a ayntactic component (parser)and a semantic interpretation component.Typically, the semantic interpretation process iscomponential, building up the interpretation of aphrase in a lawful way from the interpretations ofits constituents.
Thus a primary goal for theparser is to determine the (syntactically)acceptable groupings of words and constituents (aconstituent structure tree, perhaps augmented bythe equivalent of traces to tie togethercomponents).
Unless such groupings can be made,there is nothing for the semantic interpreter andsubsequent components to operate on.
Somesyntactic features are used only within the parserto determine the acceptability of possibleconstituent groupings, and are not passed to thesemantic component (e.g.
some verbs take clausecomplements, and require the verb in thecomplement to be subjunctive, infinitive, etc.
).The normal output of the parser may alsospecify other properties of the input notimmediately available from thelexical/morphological analysis of individualwords, such as the syntactic number of nounphrases, and the case structure of clauses.Additionally, the parser may indicate thefunctional equivalent of "traces", showing howcertain constituents play multiple roles within ast,uc~ure, appearing as functional constituents ofmi~c than one separated phrase.
From the point ofview of semantics, however, the grouping operationis of primary importance, since it is difficult toreconstruct the intended grouping without makinguse of both local and global syntacticconstraints.
The other results of the parsingprocess are less essential.
Thus, for example,the case structure of clauses is often highlyconstrained by the semantic features of the verband the constituent noun phrases, and it ispossible to reconstruct it even with minimalsyntactic guidance (e.g.
"throw" "the bali" "theboy").How can each component fill its role in theovera l l  system when the  const ra in ts  andassumptions that  under l ie  i t s  design are v io la tedby i l l - fo rmed input?The distinction between the information usedwithin a component from the information which thatcomponent is required to provide to othercomponents is critical in designing processingstrategies for each component that allow it tofulfill its primary output goals when its inputviolates one or more well-formedness constraints.Often more than one source of information orconstraint may be available to determine theoutput of a component, and it is possible toproduce well-formed output based on the partial orconflicting internal information provided by Ill-formed input.
For example, in systems withfeedback between components, it is possible forthat feedback to make up for lack of informationor violation of constraints in the input, as whensemantic coherence between subject and verb issufficient to override the violation of thesyntactic number agreement constraint.
When theintegrity of the output of a component can bemaintained in the face of ill-formed input, othercomponents can be totally shielded from theeffects of that input.A clear specification of the interfacelanguage between components makes it possible tohave recovery procedures that radicallyrestructure or totally replace one componentwithout affecting the operation of othercomponents.
In general, the problem to be solvedby a non-normative language understander can beviewed as one of finding a "sufficiently goodexplanation" for an utterance in the givencontext.
~ A number of approaches to this problemcan be distinguished.
One approach attempts ~ocharacterize the class of error producingmechanisms (such as word transposition, mistypingof letters, morphological errors, resumptivepronouns, etc.).
Given such a characterization,recognition criteria for different classes oferrors, and procedures to invert the errorprocess, an "explanation" for an ill-formedutterance could be generated in the form of anintended well-formed utterance and a sequence oferror transformations.
The system would then tryto understand the hypothesized well-formedutterance.
While some "spelling corrector"algorithms use this approach, we know of noattempt to apply it to the full range ofsyntactic, semantic and pragmatic errors.
Webelieve that some strategies of this sort mightprove useful as components in a larger error-correcting system.A more thoroughly explored set of strategiesfor non-normative processing is based on theconcept of "constraint relaxation".
If acomponent can find no characterization of theutterance because it violates one or more154constraints, then it is necessary to relax suchconstraints.
A number of strategies have beenproposed for relaxing well-formedness constraintson input to permit components to derive well-structured output for both well-formed and ill-formed input:1. extend the notion of well-formed inputto include (the Common cases of) ill-formed input (e.g.
make the gr,m,~rhandle ill-formed input explicitly);2. allow certain specific constraints to beoverridden when no legal operationsucceeds;3. provide a process that can diagnosefailures and flexibly overrideconstraints.Somehow the "goodness" of an explanation mustbe related to the number and type of constraintswhich must be relaxed to allow that explanation.How good an explanation must be before it isaccepted is a matter of design choice.
Must itsimply be "good enough" (above some threshold), ormust it be guaranteed to be "the best posslble"explanation?
If it must be "the best possible",then one can either generate all possibleexplanations and compare them, or use somestrategy like the shortfall algorithm \[12\] thatguarantees the first explanation produced will beoptimal.While space prohibits discussion of theadvantages and disadvantages of each of thesestrategies, we would llke to present a number ofdesign dimensions along which they might beusefully compared.
We believe that choices onthese dimensions (made implicitly or explicitly)have a substantial effect on both the practicalperformance and theoretical interest of theresulting strategies.
These dimensions areexemplified by the following questions:o Does the component have an explicitinternal competence model that is clearlyseparated from its performancestrategles?
4o What information is used to determinewhich constraints to attempt to relax?Is the decision purely local (based onthe constraint and the words in theimmediate vicinity of the failure) or canthe overall properties of the utteranceand/or the discourse context enter intothe decision?o When is relaxation tried?
How arevarious alternatlves scheduled?
Is itpossible, for example, that a "parse"including the relaxation of a syntacticconstraint may be produced before a parsethat involves no such relaxation?o Does the technique permit incrementalfeedback between components, and is suchfeedback used in determining whichconstraints to relax?
5Non-syntactic ill-formednessWhile the overall framework mentioned aboveraises questions about errors that affectcomponents other than syntax, the discussioncenters primarily on syntactic ill-formedness.
Inthis we follow the trend in the field.
Perhapsbecause syntax is the most clearly understoodcomponent, we have a better idea as to how it cango wrong, while our models for semanticinterpretation and discourse processes are muchless complete.
Alternatively, it might besupposed that the parsing process as generallyperformed is the most fragile of the components,susceptible to disruption by the slightestviolation of syntactic constraints.
It may bethat more robust parslr~ strategies can be found.Without stating how the semantic componentmight relax its constraints, we might still pointout the parallel between constraint violation insyntax and such semantic phenomena as metaphor,personification and metonymy.
We believe that, asin the syntactic case, it will be useful todistinguish between the internal operation of thesemantic interpreter and the interface between itand discourse level processes.
It should also bepossible to make use of feedback from thediscourse component to overcome violations ofsemantic constraints.
In the context of a waitertalking to a cook about a customer complaint, thesentence "The hamburger is getting awfullyimpatient."
should be understood.q.
ConclusionsWe believe that it will be possible to designrobust systems without giving up many valuablefeatures of those systems which already work onwell-formed input.
In particular, we believe itwill be possible to build such systems on thebasis of competence models for various linguisticcomponents, which degrade gracefully and withoutthe use of ad hoc techniques such as patternmatching.One critical resource that is needed is awidely available, reasonably large corpus of "ill-formed input", exhibiting the variety of problemswhich must be faced by practical systems.
Thiscorpus should be sub-divlded by modallty, since itis known that spoken and typewritten interactionshave different characteristics.
The collectionsthat we know of are either limited in modality(e.g.
the work on speech errors by Fromkin \[6\]) orare not widely available (e.g.
unpublishedmaterial collected by Tony Kroch).
It would alsobe valuable if this material were analyzed interms of possible generative mechanisms, toprovide needed evidence for error recoverystrategies based on inversion of error generationprocesses.155Finally, we believe that many error recoveryproblems can be solved by using constraints fromone knowledge category to reduce the overallsensitivity of the system to errors in anothercategory.
To this end, work is clearly needed inthe area of control structures and cooperativeprocess architectures that allow both pipelinlngand feedback among components with vast lyd i f fe rent  in terna l  knowledge bases.1The preparat ion  of  th i s  paper was supported bythe Advanced Research Pro jec ts  Agency of  theDepartment of  Defense, and monitored by the Of f iceof  Naval Research under cont ract  NO001q-77-C-0378.2The parser designed by G. Ginsparg also hassimilar search characteristics, given grammaticalinput.3What constitutes "sufficiently good" depends,of course, on the overall goals of the system.~In almost any case, we believe, the informationavailable at the Interface between componentsshould be expressed primarily in terms of somecompetence model.REFERENCES1.
Bates, M., Bobrow, R. J. and Webber, B.L.Tools for Syntactic and Semantic Interpretation.BBN Report ~785, Bolt Beranek and Newman Inc.,1981.2.
Bates, M. and Bobrow, R. J.
The RUS ParsingSystem.
Bolt Beranek and Newman Inc.,forthcoming.3.
Bobrow, R. J.
The RUS System.
BBN Report3878, Bolt Beranek and Newman Inc., 1978.q.
Bobrow, R. J.
& Webber, B. L. PSI-KLONE -Parsing and Semantic Interpretation in the BBNNatural Language Understanding System.CSC3I/CSEIO Annual Conference, CSCSI/CSEIO, 1980.5.
Bobrow, R. J.
& Webber, B. L. KnowledgeRepresentation for Syntactic/Semantic Processing.Proceedings of The First Annual NationalConference on Artificial Intelligence, AmericanAssociation for Artificial Intelligence, 1980.6.
Fromkln, Victoria A.. J a n u a ~ ,  Seriesmalor.
Volume 77: Soeeoh Errors s s l ~Evidence.
Mouton, The Hague, 1973.7.
Marcus, M.. A Theory of S v n t a c t i c ~for Nstural LB?E~Ig~.
MIT Press, 1980.8.
Sondhelmer, N.K.
and Weisohedel, R.M.
A Rule-Based Approach to Ill-Formed Input.
Proo.
8thInt'l Conf.
on Computational Linguistics, Tokyo,Japan, October, 1980, pp.
46-54.9.
Welsohedel, Ralph M. and Black, John E. "IfThe Parser Fails."
Proceedln~s of the 18th AnnualMeetlnsof the ACL (June 1980).10.
Welschedel, Ralph and Sondhelmer, Norman.
AFramework for Processing Ill-Formed Input.Department of Computer and Information Sciences,University of Delaware, October, 1981.11.
Woods, W. A.
"Cascaded ATN Grammars."~.
E ~ L I ~ ~ ,  I (Jan.-Mar.1980).~Q12.
Woods, W. A.
"Optimal Search Strategies forSpeech Understanding Control.
"Intelli=ence 18, 3 (June 1982).156
