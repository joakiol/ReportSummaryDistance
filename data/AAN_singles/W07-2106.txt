Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 476?479,Prague, June 2007. c?2007 Association for Computational LinguisticsUofL: Word Sense Disambiguation Using Lexical CohesionYllias ChaliDepartment of Computer ScienceUniversity of LethbridgeLethbridge, Alberta, Canada, T1K 3M4chali@cs.uleth.caShafiq R. JotyDepartment of Computer ScienceUniversity of LethbridgeLethbridge, Alberta, Canada, T1K 3M4jotys@cs.uleth.caAbstractOne of the main challenges in the applica-tions (i.e.
: text summarization, question an-swering, information retrieval, etc.)
ofNatural Language Processing is to deter-mine which of the several senses of a wordis used in a given context.
The problem isphrased as ?Word Sense Disambiguation(WSD)?
in the NLP community.
This paperpresents the dictionary based disambigua-tion technique that adopts the assumptionof one sense per discourse in the context ofSemEval-2007 Task 7: ?Coarse-grainedEnglish all-words?.1 IntroductionCohesion can be defined as the way certain wordsor grammatical features of a sentence can connectit to its predecessors (and successors) in a text.
(Halliday and Hasan, 1976) defined cohesion as?the set of possibilities that exist in the languagefor making text hang together?.
Cohesion occurswhere the interpretation of some element in thediscourse is dependent on that of another.
For ex-ample, an understanding of the reference of a pro-noun (i.e.
: he, she, it, etc.)
requires to look back tosomething that has been said before.
Through thiscohesion relation, two text clauses are linked to-gether.Cohesion is achieved through the use in the textof semantically related terms, reference, ellipse andconjunctions (Barzilay and Elhadad, 1997).
Amongthe different cohesion-building devices, the mosteasily identifiable and the most frequent type islexical cohesion.
Lexical cohesion is created byusing semantically related words (repetitions,synonyms, hypernyms, hyponyms, meronyms andholonyms, glosses, etc.
)Our technique used WordNet (Miller, 1990) asthe knowledge source to find the semantic relationsamong the words in a text.
We assign weights tothe semantic relations.
The technique can be de-composed into two steps: (1) building a representa-tion of all possible senses of the words and (2) dis-ambiguating the words based on the highest score.The remainder of this paper is organized as fol-lows.
In the next section, we review previous work.In Section 3, we define the semantic relations andtheir weights.
Section 4 presents our two step pro-cedure for WSD.
We conclude with the evaluation.2 Previous WorkLexical Chaining is the process of connecting se-mantically related words, creating a set of chainsthat represent different threads of cohesion throughthe text (Galley and McKeown, 2003).
This inter-mediate representation of text has been used inmany natural language processing applications,including automatic summarization (Barzilay andElhadad, 1997; Silber and McCoy, 2003), informa-tion retrieval (Al-Halimi and Kazman, 1998), andintelligent spell checking (Hirst and St-Onge,1998).Morris and Hirst (1991) at first proposed a man-ual method for computing lexical chains and firstcomputational model of lexical chains was intro-duced by Hirst and St-Onge (1997).
This linear-time algorithm, however, suffers from inaccurateWSD, since their greedy strategy immediately dis-ambiguates a word as it is first encountered.
Later476research (Barzilay and Elhadad, 1997) significantlyalleviated this problem at the cost of a worse run-ning time (quadratic); computational inefficiency isdue to their processing of many possible combina-tions of word senses in the text in order to decidewhich assignment is the most likely.
Silber andMcCoy (2003) presented an efficient linear-timealgorithm to compute lexical chains, which modelsBarzilay?s approach, but nonetheless has inaccura-cies in WSD.More recently, Galley and McKeown (2003)suggested an efficient chaining method that sepa-rated WSD from the actual chaining.
It performsthe WSD before the construction of the chains.They showed that it could achieve more accuracythan the earlier ones.
Our method follows the simi-lar technique with some new semantic relations(i.e.
: gloss, holonym, meronym).3 Semantic RelationsWe used WordNet2.11 (Miller, 1990) and eXtendedWordNet (Moldovan and Mihalcea, 2001) as ourknowledge source to find the semantic relationsamong the words in a context.
We assigned aweight to each semantic relation.
The relations andtheir scores are summarized in the table 1.4 System OverviewThe global architecture of our system is shown inFigure 1.
Each of the modules of the system is de-scribed below.4.1 Context ProcessingContext-processing involves preprocessing the con-texts using several tools.
We have used the follow-ing tools:Extracting the main text: This module extractsthe context of the target word from the source xmldocument removing the unnecessary tags andmakes the context ready for further processing.Sentence Splitting, Text Stemming andChunking: This module splits the context into sen-tences, then stems out the words and chunks those.We used OAK systems 2  (Sekine, 2002) for thispurpose.1http://wordnet.princeton.edu/2http://nlp.cs.nyu.edu/oak/Candidate Words Extraction: This module ex-tracts the candidate words (for task 7: noun, verb,adjective and adverb) from the chunked text.4.2 All Sense RepresentationEach candidate word is expanded to all of itssenses.
We created a hash representation to identifyall possible word representations, motivated fromGalley and McKeown (2003).
Each word sense isinserted into the hash entry having the index valueequal to its synsetID.
For example, athlete and jockare inserted into the same hash entry (Figure 2).Figure 2.
Hash indexed by synsetIDOn insertion of the candidate sense into the hashwe check to see if there exists an entry into the in-dex value, with which the current word sense hasone of the above mentioned relations.
No disam-biguation is done at this point; the only purpose isto build a representation used in the next stage ofthe algorithm.
This representation can be shown asa disambiguation graph (Galley and McKeown,2003) where the nodes represent word instanceswith their WordNet senses and weighted edgesconnecting the senses of two different words repre-sent semantic relations (Figure: 3).Figure 3.
Partial Disambiguation graph, Bass hastwo senses, 1.
Food related 2.
Music instrumentrelated sense.
The instrument sense dominates overthe fish sense as it has more relations (score) withthe other words in the context.Athlete JockGymnast0967537810002518??
?Hypernym/HyponymBassInstrument sensesoundpropertyFood sensePitchFishgroundbass4774.3 Sense DisambiguationWe use the intermediate representation (disam-biguation graph) to perform the WSD.
We sum theweight of all edges leaving the nodes under theirdifferent senses.
The one sense with the highestscore is considered the most probable sense.
Forexample in fig: 3 Bass is connected with threewords: Pitch, ground bass and sound property byits instrument sense and with one word: Fish by itsFood sense.
For this specific example all the se-mantic relations are of Hyponym/Hypernym type(score 0.33).
So we get the score as in table 2.In case of tie between two or more senses, weselect the one sense that comes first in WordNet,since WordNet orders the senses of a word by de-creasing order of frequency.Sense Mne-monicScore Disambigu-ated Sense4928349 MusicalInstru-ment3*0.33=0.997672239 Fish orFood0.33Musical In-strument(4928349)Table 2.
Score of the senses of word ?Bass?Relation Definition Example WeightRepetition Same occurrences of the word Weather is great in Atlanta.
Florida ishaving a really bad weather.1Synonym Words belonging to the same syn-set in WordNetNot all criminals are outlaws.
1Hypernymand Hypo-nymY is a hypernym of X if X is a(kind of) Y AndX is a hyponym of Y if X is a (kindof) Y.Peter bought a computer.
It was a Dellmachine.0.33HolonymAndMeronymY is a holonym of X if X is a partof Y AndX is a meronym of Y if X is a partof YThe keyboard of this computer is notworking.0.33Gloss Definition and/or example sen-tences for a synset.Gloss of word ?dormitory?
is{a college or university building con-taining living quarters for students}0.33Table 1: The relations and their associated weightsFigure 1: Overview of WSD SystemContextProcessingSense Disam-biguationAll Sense Represen-tationDisambiguatedSenseCandidate wordsExtractionSource Con-textChunked Text4785 EvaluationIn SemEval-2007, we participated in Task 7:?Coarse-grained English all-words?.
The evalua-tion of our system is given below:Cases Precision Recall F1-measureAverage 0.52592 0.48744 0.50595Best 0.61408 0.59239 0.60304Worst 0.44375 0.41159 0.427076 ConclusionIn this paper, we presented briefly our WSD sys-tem in the context of SemEval 2007 Task 7.
Alongwith normal WordNet relations, our method alsoincluded additional relations such as repetition andgloss using semantically enhanced tool, eXtendedWordNet.
After disambiguation, the intermediaterepresentation (disambiguation graph) can be usedto build the lexical chains which in tern can be usedas an intermediate representation for other NLPapplications such as text summarization, questionanswering, text clustering.
This method (summingedge weights in selecting the right sense) of WSDbefore constructing the chain (Gallery and McKe-own, 2003) outperforms the earlier methods ofBarzilay and Elhadad (1997) and Silber andMcCoy (2003) but this method is highly dependenton the lexical cohesion among words in a context.So the length of context is an important factor forour system to achieve good performance.
For thetask the context given for a tagged word was not solarge to capture the semantic relations amongwords.
This may be the one of the reasons forwhich our system could not achieve one of the bestresults.ReferencesBarzilay, R. and Elhadad, M.  1997.
Using LexicalChains for Text Summarization.
In Proceedingsof the 35th Annual Meeting of the Associationfor Computational Linguistics and the 8th Euro-pean Chapter Meeting of the Association forComputational Linguistics, Workshop on Intel-ligent Scalable Test Summarization, pages 10-17, Madrid.Chali, Y. and Kolla, M. 2004.
Summarizationtechniques at DUC 2004.
In Proceedings of theDocument Understanding Conference, pages105 -111, Boston.
NIST.Galley, M. and McKeown, K. 2003.
ImprovingWord Sense Disambiguation in Lexical Chain-ing.
In Proceedings of the 18th InternationalJoint Conference on Artificial Intelligence(IJCAI?03), pages 1486-1488, Acapulco, Mex-ico.Halliday M. and Hasan R. 1976.
Cohesion in Eng-lish.
Longman, London.Harabagiu S. and Moldovan D. 1998.
WordNet:An Electronic Lexical Database, chapter Knowl-edge Processing on an Extended WordNet.
MITpress.Hirst G. and St-Onge D.  1997.
Lexical Chains asrepresentation of context for the detection andcorrection of malapropisms.
In Christiane Fell-baum, editor, WordNet: An Electronic LexicalDatabase and Some of its Applications.
MITPress, pages 305-332.Morris J. and Hirst.
G. 1991, Lexical CohesionComputed by Thesaural Relations as an Indica-tor of the Structure of Text .Computational Lin-guistics, 17(1):21-48.Silber H.G.
and McCoy K.F.
2002.
Efficiently Com-puted Lexical Chains As an Intermediate Representa-tion for Automatic Text Summarization.
Computa-tional Linguistics, 28(4):487-496.479
