Natural Language in Four Spatial InterfacesKenneth Wauchope, Stephanie Everet t ,  Denn is  Perzanowsk i ,  E la ine  MarshNavy Center  for Applied Research in Artificial Intell igenceNaval Research Laboratory,  Code 55124555 Overlook Avenue, S.W.Washington,  DC 20375-5337, USA\[wauchope \] severett \] dennisp I marsh\] ~aic.
nrl.
navy.
milAbst rac tWe describe our experiences building spo-ken language interfaces to four demon-stration applications all involving 2- or3-D spatial displays or gestural interac-tions: an air combat command and controlsimulation, an immersive VR tactical sce-nario viewer, a map-based air strike sim-ulation tool with cartographic database,and a speech/gesture controller for mobilerobots.1 IntroductionThe NAUTILUS natural language processor hasbeen under development a our facility since about1988.
During those years it has been used andtested in five different demonstration projects, fourof which we describe in some detail in this report: anair combat command and control simulation, an im-mersive VR tactical scenario viewer, a map-based airstrike simulation tool with cartographic database,and a speech/gesture controller for mobile robots.All four applications involve spatial displays or in-teractions, including 2D map-based graphical dis-plays (radar screen, geographic map), 3D perspec-tive scenes, and hand gesture input.2 NAUTILUSNAUTILUS is built around an early version of thePROTEUS chart parser from New York University'sCourant Institute (Grishman, 1986).
The three sub-sequent system components were developed at ourown facility.2.1 PROTEUSPROTEUS syntactic grammars consist primarily oftwo rule types: context-free rules written in BNF no-tation, and restriction rules written in a high-level8algorithmic language.
Each restriction rule is at-tached to a particular nonterminal in the right-handside of one or more context-free rules.
During pars-ing the restriction fires immediately after that non-terminal has been constructed, testing the subtreeat that point for well-formedness, or attaching anattribute value for use later on.
Nodes rejected by arestriction are not added to the active chart and sodo not contribute to the remainder of the parse.2.2 T INSELOne of the attributes composed by PROTEUS dur-ing parsing is an operator-operand regularized formintended to serve as the representation to whichsemantic selection and interpretation rules can beapplied.
The TINSEL semantic interpreter (Wau-chope, 1990) applies case-frame rules and selectionrestrictions to the PROTEUS regularized output.The interpreter can either he invoked post-parse (ap-plied top-down to each candidate sentential regu-larization) or interleaved with PROTEUS, testingeach individual clausal or noun phrase immediatelyupon construction.
In interleaved mode, if a node'sregularization does not pass the case-frame or se-lection criteria then the node is not added to thechart, which can prune the search space and reduceparsing time considerably.
If the node does pass se-lection, its regularization is augmented with the rel-evant semantic lass and role information, becomingan intermediate s mantic representation suitable forfurther processing such as reference resolution andquantifier scoping.The TINSEL interpreter is primarily model-driven, which is to say that the case frame behaviorof each predicate in the domain must be explicitlyencoded in a declarative semantic representation.
Asa result we have not attempted to incorporate anygeneralized case-frame rules into the interpreter it-self, so TINSEL is not bound to any particular the-ory of thematic relations, giving the system devel-oper maximum flexibility in devising useful semanticrepresentations.
TINSEL does contain some generalrules for handling noun phrases, however, such asautomatically attempting to interpret certain prepo-sitional phrases as implicit BE-verb relative clauses(the hammer on the table ~ the hammer which ison the table), etc.2.3 FOCALThe FOCAL (FOCus ALgorithm) reference resolu-tion module was developed by visiting MIT grad-uate student Gina-Anne Levow.
It resolves defi-nite, indefinite, and pronominal references as sub-sets of objects from a closed-world model developedfor each application.
Model objects have a TIN-SEL semantic lass attribute, permissable identify-ing specifiers (S.S. Loveboat, waypoint No.
2, NTDSicons), and a marker indicating if the object repre-sents a collection of unindividualized entities (maprings, aircraft trails).
FOCAL uses semantic lass,number, recency, and constituent order within thesentence when choosing antecedents for anaphoricreferences.
It assumes demonstratives (that fighter)to be anaphoric and attempts to resolve other def-inite references (the fighters) first as anaphoric andthen as universal.
Since none of our interfaces todate has involved declarative or hypothetical utter-ances, indefinite expressions (a fighter) are inter-preted strictly as closed-world references, i.e., oneof the known fighters.2.4 FUNTRANThe FUNTRAN (FUNctional TRANslator) moduletakes TINSEL and FOCAL output and constructsa quantified logical form suitable for evaluation inthe runtime environment to issue a command orquery to the target application.
The logical quan-tifiers and connectives (FORALL, EXISTS, NOT,AND, etc.)
have generic procedural definitions asLisp macros, so the system developer just needs todevelop a so-called Translation Function (TF) foreach of the TINSEL predicates in the domain.
TFsare Lisp functions (defuns) of the same name as thepredicate, taking keyword arguments correspondingto each of the predicate's emantic slots, and ex-changing appropriately coded information with thetarget application via so-called Interface Functions,described next.
FUNTRAN also composes implefragmentary English responses to database queriesbased on the results of the TF predicate valuation.2.5 Back End  Trans la torAt this point the generic NAUTILUS code endsand the system developer must hand-craft anapplication-specific interface layer between theTranslation Functions and the target.
The natureof that interface depends on whether NAUTILUSand the target are running in the same Lisp processor as separate Unix processes, possibly on differentmachines.
In one of our projects (InterLACE), thetarget application is just a Lisp program running inthe same process space as the NLP system, so theprimitive Interface Functions (IFs) for communicat-ing between the two are just Lisp function calls.
Intwo others (InterVR and InterROB), the target ap-plication runs on another Unix machine on the localnet, so the IFs on the NAUTILUS side must encodeand transmit message strings over an IPC socket toa corresponding decoder layer linked into the appli-cation.
In the fourth project (Eucalyptus) we de-veloped versions for both approaches, one where theapplication object code (compiled from C) is loadedinto Lisp and the IFs are foreign function calls, andthe other doing IPC message passing.2.6 Speech I /OFor speech input we use the Phonetic Engine(PE200) from Speech Systems Inc. with the speechrecognition software running on a Sun workstationto which the PE200 hardware is connected by a serialline.
Under various circumstances we have linked thesoftware in with either NAUTILUS or the applica-tion, or have run it as a separate process commu-nicating with NAUTILUS via an IPC socket.
Forspeech output, a DECtalk speech synthesizer is con-nected to the other Sun serial port and can be sentoutput from NAUTILUS either by Unix system callsor by writing data directly to the port.3 App l i ca t ion  Pro jec ts3.1 Euca lyptusNAUTILUS was first used in the Eucalyptus (Wau-chope, 1994) spoken language interface to theKOALAS Airborne Early Warning C2 simulation(Barrett and Aldrich, 1990).
The original KOALASinterface consisisted of a mouse-sensitive simulatedradar screen with a conventional graphical user in-terface composed of command pushbuttons, dialogboxes and scrolling display windows.
Our objec-tive in Eucalyptus was to make the same commandand data access functionality available via naturallanguage, integrated as much as possible with thegraphical interface to allow multimodal interactions.For example, a NL command to the system might re-sult in the display of the same dialog box used in thecorresponding GUI command, but with the dialog'sdata fields fully or partially filled from the NL input;9the user can then fill in any remaining empty fieldsand issue final acceptance either graphically or ver-bally.
To that end, the command-oriented InterfaceFunctions in Eucalyptus consist largely of calls tothe base functions underlying the KOALAS GUI.Eucalyptus also includes deictic reference, allow-ing the user to click on one or more radar blips orscreen locations while speaking verbal references likethis fighter or these CAP stations.
When a mouseclick occurs, NAUTILUS asks the application for theidentities of all the objects located at or near themouse vent, and then takes the subset of those ob-jects that match the semantics of the verbal phrase(which can be determined from predicate context aswell: for example the word here in Have fighter I re-fuel here necessarily refers to a tanker aircraft).
Toavoid the problems of time-correlating speech withgraphical input and distinguishing anaphora fromdeixis, we reserve the words this, these and herefor deictic reference and that, those and there foranaphoric reference, and allow no more than oneplural deictic reference per utterance.Database query is used both in answering explicitinterrogatives (Which fighters aren't holding CAPstation?)
as well as dereferencing qualified NPs(moving aircraft).
The system can also interpret NPsentence fragments as followup commands or queriesby substituting the NP into the semantically rele-vant slot of the prior utterance's logical form.As originally designed, FOCAL expected a closed-world model of all domain objects to be available atstartup time.
This had to be modified somewhat inEucalyptus ince the KOALAS world includes hy-pothetical objects (suspected threat aircraft) whichthe user and system can create and destroy at will.References to hypothetical entities are resolved byhaving FOCAL dynamically consult he applicationdatabase for the current object population at thetime the phrase was uttered.The core syntactic grammar of about 150 context-free rules and 50 restriction rules developed for Eu-calyptus has been re-used in all the other NAU-TILUS projects.
Each one has augmented it with afew dozen additional rules for handling application-specific constructs like station two sector one (Euca-lyptus), latitude forty degrees north longitude ninetyfive degrees west (InterVR), the town of Leipzig (In-terLACE), and thirty degrees left (InterROB).The Eucalyptus lexicon totals about 425 words,many of them unused morphological variants gen-erated automatically by the PROTEUS lexicalmacros; by comparison, the vocabulary for thespeech recognition front end is only 260 words.
To-tal input coverage is on the order of 100 million ut-terances, deliberately high to test the speech sys-tem's ability to detect a wide variety of noun phrasedeterminers.
Unlike the NAUTILUS grammar, thespeech grammar excludes iteration and recursion(such as compounding) to maintain a reasonablelevel of recognition accuracy.
An experimental d-dition of relative clauses to the speech grammarwas "productive" only in the linguistic sense, sincethe resulting exponential increase in grammar sizecaused recognition rates to drop to unacceptable lev-els.3.2 I n te rVRWe next used NAUTILUS in InterVR (Everett et al,1994), a spoken language controller for an immer-sive 3D or "Virtual Reality" tactical combat simula-tion viewer.
Here the emphasis was on the utility ofspeech I/O in an eyes- and hands-busy virtual envi-ronment.
Like Eucalyptus, InterVR supports com-mands, queries, complex reference and anaphora,and NP followups.
A non-immersive d sktop versionof the viewer allowed mouse selection of a platformand thus singular deictic reference (this helicopter),but the immersive display version did not include adataglove or other pointing device.
We did not havetime or resources to tackle the problem of resolvingreferents based on visual context (for example hav-ing that helicopter refer to the one nearest the centerof the user's field of view), but we are currently in-vestigating the interaction of vision and language inthe InterROB project, to be discussed shortly.The InterVR speech component has a vocabu-lary comparable in size to that of Eucalyptus buta more constrained input range (about 1 million ut-terances) mainly due to a less liberal variety of NPdeterminers.
The IPC code developed for Eucalyp-tus ported immediately to the new application, andNAUTILUS's modular architecture allowed speechmodeling, NLP knowledge base development andIF coding to be pursued independently b differentteam members with a minimum of coordination.3.3  In terLACEInterLACE (Wauchope, 1996) is an integrated nat-ural language interface and graphical map displayfor the Air Force's LACE land/air combat simu-lation system (Anken, 1989).
LACE includes alarge object-oriented cartographic database of mostof central Germany, containing a total of over 12,000objects such as towns, lakes, rivers, and railroads.Since the application is written in Common LISPand so can run in the same process environment asNAUTILUS, we dispensed with independently mod-eling FOCAL entities for the domain and just let the10LACE database objects serve as the extensions ofreferring expressions.
To avoid having to enter hun-dreds of foreign proper names into the PROTEUSlexicon, we modified the PROTEUS lexical taggerto assume that any input word might be a propername (applying that assumption only to non-Englishwords failed the first time we encountered the riverMain and the Czech towns of Most and As).
Deicticreference operates imilarly to Eucalyptus: a mouseclick can select a number of overlapping map objectsat once, to be resolved by an accompanying verbalreference; for example What's the population here?would resolve to a town object whereas Does thiscross the Elbe ?
might resolve to a road.The InterLACE domain necessitated extendingFUNTRAN to generate proper logical forms for spa-tial comparatives and superlatives (Is Wurzen closerthan Grimma?, the closest lake to Eilenburg) andimplicit and explicit reflexives (Do these roads cross\[each other\]?
), and also introduced irect address(Tank 1, head north) and iterative arguments to nav-igation commands (Head north on road E2 for 2 kmto Wurzen).
An experimental study of NL inputsfrom novice InterLACE users showed that of 822 in-puts, 14 contained typos or misspellings and 30 con-tained ungrammaticalities, for an illformedness rateof 5%.
Of the remaining 778 utterances NAUTILUSfailed to understand 23 (3%) due to incomplete cov-erage.Since the PE200's phonetic rules are for AmericanEnglish and (unlike PROTEUS) the module cannotbe tricked into recognizing unknown inputs as pos-sible proper names, a complete speech input com-ponent for InterLACE was impractical.
For demopurposes we opted to implement a 160-word speechinterface containing just fifty German proper names,few enough that the recognizer doesn't have toomuch trouble distinguishing them, for an input cov-erage of about 10 million utterances.
Similarly forspeech output we provided the same vocabulary toDECtalk along with phonetic transcriptions to pro-duce acceptable German pronunciations.3.4 In terROBInterROB is a new project exploring the integra-tion of spoken and gestural inputs to a pair of mo-bile robots with rangefinder vision capability.
Todate the system accepts commands only, using a66-word speech vocabulary with an input range ofabout 11,000 utterances.
The robots currently rec-ognize two types of gesture: distance (hands heldapart) and direction (wave left/right).
Since the sys-tem does not yet query information from the robots,deictic reference must currently be resolved on therobot side rather than (as in the systems describedearlier) by having NAUTILUS choose from a set ofcandidates provided by the application.
This meansthat phrases like that waypoint or the waypoint overthere must be assigned a special FOCAL extension(a pseudo-object alled a gesture-waypoint) which isnot one of the four actual waypoint objects in theclosed world, whereas with query capability NAU-TILUS might be able to obtain enough informationfrom the robot to determine which of the four actualwaypoints is being gestured toward.Another goal in InterROB is to go beyond theusual restriction of deictic reference to demonstra-tive or indexical references (that, here, there) andallow gestures to accompany any sort of definite orindefinite NP.
This could then be extended to in-clude extralinguistic context in general, such as in-terpreting the waypoint to mean the one the robot iscurrently facing, or my right to mean 90 degrees per-pendicular to the way the robot perceives the opera-tor to be facing.
We also plan to extend the roboticvision capabilities with additional hard/software toallow visual object recognition for lexical acquisition.ReferencesRalph Grishman.
1986.
PROTEUS parser referencemanual.
PROTEUS Project Memorandum #4,Department of Computer Science, Courant Insti-tute of Mathematical Sciences, New York Univer-sity, July.Kenneth Wauchope.
1994.
Eucalyptus: integrat-ing natural language input with a graphical userinterface.
NRL technical report NRL/FR/5510-94-9711, February.Chris Barrett and Charles P~ldrich.
1990.
Final re-port: KOALAS test planning tool concept demon-stration: users manual.
Los Alamos National Lab-oratory, Los Alamos, New Mexico.Craig S. Anken.
1989.
LACE: land air combat inERIC.
Rome Air Development Center RADC-TR-89-219, October.Kenneth Wauchope.
1990.
A tandem semantic in-terpreter for incremental parse selection.
NRLtechnical report 9288, September.Stephanie S. Everett, Kenneth Wauchope, andManuel A. P~rez.
1994.
A natural anguage inter-face for virtual reality systems.
NCARAI techni-cal report AIC-94-046.Kenneth Wauchope.
1996.
Multimodal interactionwith a map-based simulation system.
NCARAItechnical report AIC-96-019.11
