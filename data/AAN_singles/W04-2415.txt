Hierarchical Recognition of Propositional Arguments with PerceptronsXavier Carreras and Llu?
?s Ma`rquezTALP Research CentreTechnical University of Catalonia (UPC){carreras,lluism}@lsi.upc.esGrzegorz Chrupa?aGRIAL Research GroupUniversity of Barcelona (UB)grzegorz@pithekos.net1 IntroductionWe describe a system for the CoNLL-2004 Shared Taskon Semantic Role Labeling (Carreras and Ma`rquez,2004a).
The system implements a two-layer learning ar-chitecture to recognize arguments in a sentence and pre-dict the role they play in the propositions.
The explo-ration strategy visits possible arguments bottom-up, navi-gating through the clause hierarchy.
The learning compo-nents in the architecture are implemented as Perceptrons,and are trained simultaneously online, adapting their be-havior to the global target of the system.
The learn-ing algorithm follows the global strategy introduced in(Collins, 2002) and adapted in (Carreras and Ma`rquez,2004b) for partial parsing tasks.2 Semantic Role Labeling StrategyThe strategy for recognizing propositional arguments insentences is based on two main observations about argu-ment structure in the data.
The first observation is therelation of the arguments of a proposition with the chunkand clause hierarchy: a proposition places its argumentsin the clause directly containing the verb (local clause),or in one of the ancestor clauses.
Given a clause, we de-fine the sequence of top-most syntactic elements as thewords, chunks or clauses which are directly rooted at theclause.
Then, arguments are formed as subsequences oftop-most elements of a clause.
Finally, for local clausesarguments are found strictly to the left or to the right ofthe target verb, whereas for ancestor clauses argumentsare usually to the left of the verb.
This observation holdsfor most of the arguments in the data.
A general excep-tion are arguments of type V, which are found only in thelocal clause, starting at the position of the target verb.The second observation is that the arguments of allpropositions of a sentence do not cross their boundaries,and that arguments of a particular proposition are usuallyfound strictly within an argument of a higher level propo-sition.
Thus, the problem can be thought of as finding ahierarchy of arguments in which arguments are embed-ded inside others, and each argument is related to a num-ber of propositions of a sentence in a particular role.
If anargument is related to a certain verb, no other argumentlinking to the same verb can be found within it.The system presented in this paper translates these ob-servations into constraints which are enforced to hold ina solution, and guide the recognition strategy.
A limita-tion of the system is that it makes no attempt to recognizearguments which are split in many phrases.In what follows, x is a sentence, and xi is the i-th wordof the sentence.
We assume a mechanism to access theinput information of x (PoS tags, chunks and clauses),as well as the set of target verbs V , represented by theirposition.
A solution y ?
Y for a sentence x is a set ofarguments of the form (s, e)kv , where (s, e) represents anargument spanning from word xs to word xe, playing asemantic role k ?
K with a verb v ?
V .
Finally, [S,E]denotes a clause spanning from word xS to word sE .The SRL(x) function, predicting semantic roles of asentence x, implements the following strategy:1.
Initialize set of arguments, A, to empty.2.
Define the level of each clause as its distance to theroot clause.3.
Explore clauses bottom-up, i.e.
from deeper levelsto the root clause.
For a clause [S,E]:A := A ?
arg search(x, [S,E])4.
Return A2.1 Building Argument HierarchiesHere we describe the function arg search, which builds aset of arguments organized hierarchically, within a clause[S,E] of a sentence x.
The function makes use of twolearning-based components, defined here and describedbelow.
First, a filtering function F, which, given a can-didate argument, determines its plausible categories, orrejects it when no evidence for it being an argumentis found.
Second, a set of k-score functions, for eachk ?
K, which, given an argument, predict a score of plau-sibility for it being of role type k of a certain proposition.The function arg search searches for the argument hi-erarchy which optimizes a global score on the hierarchy.As in earlier works, we define the global score (?)
as thesummation of scores of each argument in the hierarchy.The function explores all possible arguments in the clauseformed by contiguous top-most elements, and selects thesubset which optimizes the global score function, forcinga hierarchy in which the arguments linked to the sameverb do not embed.Using dynamic programming, the function can becomputed in cubic time.
It considers fragments of top-most elements, which are visited bottom-up, incremen-tally in length, until the whole clause is explored.
Whileexploring, it maintains a two-dimensional matrix A ofpartial solutions: each position [s, e] contains the optimalargument hierarchy for the fragment from s to e. Finally,the solution is found at A[S,E].
For a fragment from s toe the algorithm is as follows:1.
A := A[s, r] ?
A[r+1, e] wherer := arg maxs?r<e ?
(A[s, r])+ ?
(A[r+1, e])2.
For each prop v ?
V :(a) K := F((s, e), v)(b) Compute k?
such thatk?
:= arg maxk?K k-score((s, e), v, x)Set ?
to the score of category k?.
(c) Set Av as the arguments in A linked to v.(d) If (?
(Av) < ?
)then A := A\Av ?
{(s, e)k?v }3.
A[s, e] := ANote that an argument is visited once, and that its scorecan be stored to efficiently compute the ?
global score.2.2 Start-End FilteringThe function F determines which categories in K areplausible for an argument (s, e) to relate to a verb v.This is done via start-end filters (FkS and FkE), one foreach type in K1.
They operate on words, independentlyof verbs, deciding whether a word is likely to start or endsome argument of role type k.The selection of categories is conditional to the relativelevel of the verb and the clause, and to the relative posi-tion of the verb and the argument.
The conditions are:?
v is local to the clause, and (v=s) and FVE(xe):K := {V}?
v is local, and (e<v ?
v<s):K := {k ?
K | FkS(xs) ?
FkE(xe)}1Actually, we share start-end filters for A0-A5 arguments.?
v is at deeper level, and (e<v):K := {k ?
K | k 6?K(v) ?
FkS(xs) ?
FkE(xe)}where K(v) is the set of categories already assignedto the verb in deeper clauses.?
Otherwise, K is set to empty.Note that setting K to empty has the effect of filter-ing out the argument for the proposition.
Note also thatStart-End classifications do not depend on the verb, thusthey can be performed once per candidate word, beforeentering the exploration of clauses.
Then, when visitinga clause, the Start-End filtering can be performed withstored predictions.3 Learning with PerceptronsIn this section we describe the learning components ofthe system, namely start, end and score functions, and thePerceptron-based algorithm to train them together online.Each function is implemented using a linear separator,hw : Rn ?
R, operating in a feature space defined bya feature extraction function, ?
: X ?
Rn, for someinstance space X .
The start-end functions (FkS and FkE)are formed by a prediction vector for each type, noted aswkS or wkE, and a shared representation function ?w whichmaps a word in context to a feature vector.
A predictionis computed as FkS(x) = wkS ?
?w(x), and similarly for theFkE, and the sign is taken as the binary classification.The score functions compute real-valued scores forarguments (s, e)v .
We implement these functions witha prediction vector wk for each type k ?
K, anda shared representation function ?a which maps anargument-verb pair to a feature vector.
The score pre-diction for a type k is then given by the expression:k-score((s, e), v, x) = wk ?
?a((s, e), v, x).3.1 Perceptron Learning AlgorithmWe describe a mistake-driven online algorithm to trainprediction vectors together.
The algorithm is essentiallythe same as the one introduced in (Collins, 2002).
Let Wbe the set of prediction vectors:?
Initialize: ?w?W w := 0?
For each epoch t := 1 .
.
.
T ,for each sentence-solution pair (x, y) in training:1. y?
= SRLW (x)2. learning feedback(W,x, y, y?)?
Return W3.2 Learning Feedback for Filtering-RankingWe now describe the learning feedback rule, introducedin earlier works (Carreras and Ma`rquez, 2004b).
We dif-ferentiate two kinds of global errors in order to give feed-back to the functions being learned: missed argumentsand over-predicted arguments.
In each case, we identifythe prediction vectors responsible for producing the in-correct argument and update them additively: vectors aremoved towards instances predicted too low, and movedaway from instances predicted too high.Let y?
be the gold set of arguments for a sentencex, and y?
those predicted by the SRL function.
LetgoldS(xi, k) and goldE(xi, k) be, respectively, the per-fect indicator functions for start and end boundaries ofarguments of type k. That is, they return 1 if word xistarts/ends some k-argument in y?
and -1 otherwise.
Thefeedback is as follows:?
Missed arguments: ?
(s, e)kv ?
y?\y?:1.
Update misclassified boundary words:if (wkS ?
?w(xs) ?
0) then wkS = wkS + ?w(xs)if (wkE ?
?w(xe) ?
0) then wkE = wkE +?w(xe)2.
Update score function, if applied:if (k ?
F ((s, e), v) thenwk = wk + ?a((s, e), v, x)?
Over-predicted arguments: ?
(s, e)kp ?
y?\y?:1.
Update score function:wk = wk ?
?a((s, e), v, x)2.
Update words misclassified as S or E:if (goldS(xs, k)=?1) then wkS = wkS?
?w(xs)if (goldE(xe, k)=?1) then wkE =wkE?
?w(xe)3.3 Kernel Perceptrons with Averaged PredictionsOur final architecture makes use of Voted Perceptrons(Freund and Schapire, 1999), which compute a predic-tion as an average of all vectors generated during train-ing.
Roughly, each vector contributes to the average pro-portionally to the number of correct positive training pre-dictions the vector has made.
Furthermore, a predictionvector can be expressed in dual form as a combination oftraining instances, which allows the use of kernel func-tions.
We use standard polynomial kernels of degree 2.4 FeaturesThe features of the system are extracted from three typesof elements: words, target verbs, and arguments.
Theyare formed making use of PoS tags, chunks and clausesof the sentence.
The functions ?w and ?a are definedin terms of a collection of feature extraction patterns,which are binarized in the functions: each extracted pat-tern forms a binary dimension indicating the existence ofthe pattern in a learning instance.Extraction on Words.
The list of features extractedfrom a word xi is the following:?
PoS tag.?
Form, if the PoS tag does not match with the Perlregexp /?(CD|FW|J|LS|N|POS|SYM|V)/.?
Chunk type, of the chunk containing the word.?
Binary-valued flags: (a) Its chunk is one-word ormulti-word; (b) Starts and/or ends, or is strictlywithin a chunk (3 flags); (c) Starts and/or endsclauses (2 flags); (d) Aligned with a target verb; and(e) First and/or last word of the sentence (2 flags).Given a word xi, the ?w function implements a ?3window, that is, it returns the features of the words xi+r,with ?3?r?+3, each with its relative position r.Extraction on Target Verbs.
Given a target verb v, weextract the following features from the word xv:?
Form, PoS tag, and target verb infinitive form.?
Voice : passive, if xv has PoS tag VBN, and either itschunk is not VP or xv is preceded by a form of ?tobe?
or ?to get?
within its chunk; otherwise active.?
Chunk type.?
Binary-valued flags: (a) Its chunk is multi-word ornot; and (b) Starts and/or ends clauses (2 flags).Extraction on Arguments.
The ?a function performsthe following feature extraction for an argument (s, e)linked to a verb v:?
Target verb features, of verb v.?
Word features, of words s?1, s, e, and e+1, eachanchored with its relative position.?
Distance of v to s and to e: for both pairs, a flagindicating if distance is {0, 1,?1, >1, <1}.?
PoS Sequence, of PoS tags from s to e: (a) n-gramsof size 2, 3 and 4; and (b) the complete PoS pattern,if it is less than 5 tags long.?
TOP sequence: tags of the top-most elements foundstrictly from s to e. The tag of a word is its PoS.
Thetag of a chunk is its type.
The tag of a clause is itstype (S) enriched as follows: if the PoS tag of thefirst word matches /?
(IN|W|TO)/ the tag is en-riched with the form of that word (e.g.
S-to); ifthat word is a verb, the tag is enriched with its PoS(e.g.
S-VBG); otherwise, it is just S. The follow-ing features are extracted: (a) n-grams of sizes 2, 3and 4; (b) The complete pattern, if it is less than 5tags long; and (c) Anchored tags of the first, second,penultimate and last elements.?
PATH sequence: tags of elements found betweenthe argument and the verb.
It is formed by a con-catenation of horizontal tags and vertical tags.
Thehorizontal tags correspond to the TOP sequence ofelements at the same level of the argument, from it tothe phrase containing the verb, both excluded.
Thevertical part is the list of tags of the phrases whichcontain the verb, from the phrase at the level of theargument to the verb.
The tags of the PATH se-quence are extracted as in the TOP sequence, withan additional mark indicating whether an element ishorizontal to the left or to the right of the argument,or vertical.
The following features are extracted: (a)n-grams of sizes 4 and 5; and (b) The complete pat-tern, if it is less than 5 tags long.?
Bag of Words: we consider the top-most elementsof the argument which are not clauses, and extractall nouns, adjectives and adverbs.
We then form aseparate bag for each category.?
Lexicalization: we extract the form of the head ofthe first top-most element of the argument, via com-mon head word rules; if the first element is a PPchunk, we also extract the head of the first NP found.5 Experiments and ResultsWe have build a system which implements the presentedarchitecture for recognizing arguments and their semanticroles.
The configuration of learning functions, related tothe roles in the CoNLL-2004 data, is set as follows :?
Five score functions for the A0?A4 types, and twoshared filtering functions FANS and FANE .?
For each of the 13 adjunct types (AM-*), a scorefunction and a pair of filtering functions.?
Three score functions for the R0?R2 types, and twofiltering functions FRS and FRE shared among them.?
For verbs, a score function and an end filter.We ran the learning algorithm on the training set (withpredicted input syntax) with a polynomial kernel of de-gree 2, for up to 8 epochs.
Table 1 presents the ob-tained results on the development set, either artificial orreal.
The second and third rows provide, respectively, theloss suffered because of errors in the filtering and scor-ing layer.
The filtering layer performs reasonably well,since 89.44% recall can be achieved on the top of it.However, the scoring functions clearly moderate the per-formance, since working with perfect start-end functionsonly achieve an F1 at 75.60.
Finally, table 2 presents finaldetailed results on the test set.Precision Recall F?=1g?FS, g?FE, g-score 99.92% 94.73% 97.26FS, FE, g?score 99.90% 89.44% 94.38g?FS, g?FE, score 85.12% 67.99% 75.60FS, FE, score 73.40% 63.70% 68.21Table 1: Overall results on the development set.
Func-tions with prefix g are gold functions, providing boundsof our performance.
The top row is the upper bound per-formance of our architecture.
The bottom row is the realperformance.Precision Recall F?=1Overall 71.81% 61.11% 66.03A0 81.83% 76.46% 79.05A1 68.73% 65.27% 66.96A2 59.41% 34.03% 43.28A3 58.18% 21.33% 31.22A4 72.97% 54.00% 62.07A5 0.00% 0.00% 0.00AM-ADV 54.50% 35.50% 43.00AM-CAU 58.33% 28.57% 38.36AM-DIR 64.71% 22.00% 32.84AM-DIS 64.06% 57.75% 60.74AM-EXT 100.00% 50.00% 66.67AM-LOC 35.62% 22.81% 27.81AM-MNR 50.89% 22.35% 31.06AM-MOD 97.57% 95.25% 96.40AM-NEG 90.23% 94.49% 92.31AM-PNC 36.11% 15.29% 21.49AM-PRD 0.00% 0.00% 0.00AM-TMP 61.86% 48.86% 54.60R-A0 78.85% 77.36% 78.10R-A1 64.29% 51.43% 57.14R-A2 100.00% 22.22% 36.36R-A3 0.00% 0.00% 0.00R-AM-LOC 0.00% 0.00% 0.00R-AM-MNR 0.00% 0.00% 0.00R-AM-PNC 0.00% 0.00% 0.00R-AM-TMP 0.00% 0.00% 0.00V 98.32% 98.24% 98.28Table 2: Results on the test setAcknowledgementsThis research is supported by the European Commission(Meaning, IST-2001-34460) and the Spanish Research Depart-ment (Aliado, TIC2002-04447-C02).
Xavier Carreras is sup-ported by a grant from the Catalan Research Department.ReferencesXavier Carreras and Llu?is Ma`rquez.
2004a.
Introduc-tion to the CoNLL-2004 Shared Task: Semantic RoleLabeling.
In Proceedings of CoNLL-2004.Xavier Carreras and Llu?is Ma`rquez.
2004b.
Onlinelearning via global feedback for phrase recognition.In Advances in Neural Information Processing Systems16.
MIT Press.M.
Collins.
2002.
Discriminative Training Methodsfor Hidden Markov Models: Theory and Experimentswith Perceptron Algorithms.
In Proceedings of theEMNLP?02.Y.
Freund and R. E. Schapire.
1999.
Large Margin Clas-sification Using the Perceptron Algorithm.
MachineLearning, 37(3):277?296.
