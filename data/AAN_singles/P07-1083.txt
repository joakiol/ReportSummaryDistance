Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 656?663,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsAlignment-Based Discriminative String SimilarityShane Bergsma and Grzegorz KondrakDepartment of Computing ScienceUniversity of AlbertaEdmonton, Alberta, Canada, T6G 2E8{bergsma,kondrak}@cs.ualberta.caAbstractA character-based measure of similarity isan important component of many natu-ral language processing systems, includingapproaches to transliteration, coreference,word alignment, spelling correction, and theidentification of cognates in related vocabu-laries.
We propose an alignment-based dis-criminative framework for string similarity.We gather features from substring pairs con-sistent with a character-based alignment ofthe two strings.
This approach achievesexceptional performance; on nine separatecognate identification experiments using sixlanguage pairs, we more than double the pre-cision of traditional orthographic measureslike Longest Common Subsequence Ratioand Dice?s Coefficient.
We also show strongimprovements over other recent discrimina-tive and heuristic similarity functions.1 IntroductionString similarity is often used as a means of quan-tifying the likelihood that two pairs of strings havethe same underlying meaning, based purely on thecharacter composition of the two words.
Strube etal.
(2002) use Edit Distance as a feature for de-termining if two words are coreferent.
Taskar etal.
(2005) use French-English common letter se-quences as a feature for discriminative word align-ment in bilingual texts.
Brill and Moore (2000) learnmisspelled-word to correctly-spelled-word similari-ties for spelling correction.
In each of these exam-ples, a similarity measure can make use of the recur-rent substring pairings that reliably occur betweenwords having the same meaning.Across natural languages, these recurrent sub-string correspondences are found in word pairsknown as cognates: words with a common formand meaning across languages.
Cognates arise ei-ther from words in a common ancestor language(e.g.
light/Licht, night/Nacht in English/German)or from foreign word borrowings (e.g.
trampo-line/toranporin in English/Japanese).
Knowledge ofcognates is useful for a number of applications, in-cluding sentence alignment (Melamed, 1999) andlearning translation lexicons (Mann and Yarowsky,2001; Koehn and Knight, 2002).We propose an alignment-based, discriminativeapproach to string similarity and evaluate this ap-proach on cognate identification.
Section 2 de-scribes previous approaches and their limitations.
InSection 3, we explain our technique for automati-cally creating a cognate-identification training set.
Anovel aspect of this set is the inclusion of competitivecounter-examples for learning.
Section 4 shows howdiscriminative features are created from a character-based, minimum-edit-distance alignment of a pairof strings.
In Section 5, we describe our bitext anddictionary-based experiments on six language pairs,including three based on non-Roman alphabets.
InSection 6, we show significant improvements overtraditional approaches, as well as significant gainsover more recent techniques by Ristad and Yiani-los (1998), Tiedemann (1999), Kondrak (2005), andKlementiev and Roth (2006).2 Related WorkString similarity is a fundamental concept in a va-riety of fields and hence a range of techniques656have been developed.
We focus on approachesthat have been applied to words, i.e., uninterruptedsequences of characters found in natural languagetext.
The most well-known measure of the simi-larity of two strings is the Edit Distance or Lev-enshtein Distance (Levenshtein, 1966): the numberof insertions, deletions and substitutions required totransform one string into another.
In our experi-ments, we use Normalized Edit Distance (NED):Edit Distance divided by the length of the longerword.
Other popular measures include Dice?s Coef-ficient (DICE) (Adamson and Boreham, 1974), andthe length-normalized measures Longest CommonSubsequence Ratio (LCSR) (Melamed, 1999), andLongest Common Prefix Ratio (PREFIX) (Kondrak,2005).
These baseline approaches have the impor-tant advantage of not requiring training data.
Wecan also include in the non-learning category Kon-drak (2005)?s Longest Common Subsequence For-mula (LCSF), a probabilistic measure designed tomitigate LCSR?s preference for shorter words.Although simple to use, the untrained measurescannot adapt to the specific spelling differences be-tween a pair of languages.
Researchers have there-fore investigated adaptive measures that are learnedfrom a set of known cognate pairs.
Ristad and Yiani-los (1998) developed a stochastic transducer versionof Edit Distance learned from unaligned string pairs.Mann and Yarowsky (2001) saw little improvementover Edit Distance when applying this transducer tocognates, even when filtering the transducer?s proba-bilities into different weight classes to better approx-imate Edit Distance.
Tiedemann (1999) used variousmeasures to learn the recurrent spelling changes be-tween English and Swedish, and used these changesto re-weight LCSR to identify more cognates, withmodest performance improvements.
Mulloni andPekar (2006) developed a similar technique to im-prove NED for English/German.Essentially, all these techniques improve on thebaseline approaches by using a set of positive (true)cognate pairs to re-weight the costs of edit op-erations or the score of sequence matches.
Ide-ally, we would prefer a more flexible approach thatcan learn positive or negative weights on substringpairings in order to better identify related strings.One system that can potentially provide this flexi-bility is a discriminative string-similarity approachto named-entity transliteration by Klementiev andRoth (2006).
Although not compared to other simi-larity measures in the original paper, we show thatthis discriminative technique can strongly outper-form traditional methods on cognate identification.Unlike many recent generative systems, the Kle-mentiev and Roth approach does not exploit theknown positions in the strings where the charactersmatch.
For example, Brill and Moore (2000) com-bine a character-based alignment with the Expec-tation Maximization (EM) algorithm to develop animproved probabilistic error model for spelling cor-rection.
Rappoport and Levent-Levi (2006) applythis approach to learn substring correspondences forcognates.
Zelenko and Aone (2006) recently showeda Klementiev and Roth (2006)-style discriminativeapproach to be superior to alignment-based genera-tive techniques for name transliteration.
Our worksuccessfully uses the alignment-based methodologyof the generative approaches to enhance the featureset for discriminative string similarity.3 The Cognate Identification TaskGiven two string lists, E and F , the task of cog-nate identification is to find all pairs of strings (e, f)that are cognate.
In other similarity-driven applica-tions, E and F could be misspelled and correctlyspelled words, or the orthographic and the phoneticrepresentation of words, etc.
The task remains tolink strings with common meaning in E and F us-ing only the string similarity measure.We can facilitate the application of string simi-larity to cognates by using a definition of cognationnot dependent on etymological analysis.
For ex-ample, Mann and Yarowsky (2001) define a wordpair (e, f) to be cognate if they are a translationpair (same meaning) and their Edit Distance is lessthan three (same form).
We adopt an improveddefinition (suggested by Melamed (1999) for theFrench-English Canadian Hansards) that does notover-propose shorter word pairs: (e, f) are cog-nate if they are translations and their LCSR ?0.58.
Note that this cutoff is somewhat conser-vative: the English/German cognates light/Licht(LCSR=0.8) are included, but not the cognateseight/acht (LCSR=0.4).If two words must have LCSR ?
0.58 to be cog-657Foreign Language F Words f ?
F Cognates Ef+ False Friends Ef?Japanese (Ro?maji) napukin napkin nanking, pumpkin, snacking, sneakingFrench abondamment abundantly abandonment, abatement, ... wondermentGerman prozyklische procyclical polished, prophylactic, prophylaxisTable 1: Foreign-English cognates and false friend training examples.nate, then for a given word f ?
F , we need onlyconsider as possible cognates the subset of words inE having an LCSR with f larger than 0.58, a set wecall Ef .
The portion of Ef with the same meaningas f , Ef+, are cognates, while the part with differ-ent meanings, Ef?, are not cognates.
The wordsEf?
with similar spelling but different meaning aresometimes called false friends.
The cognate identi-fication task is, for every word f ?
F , and a list ofsimilarly spelled words Ef , to distinguish the cog-nate subset Ef+ from the false friend set Ef?.To create training data for our learning ap-proaches, and to generate a high-quality labelled testset, we need to annotate some of the (f, ef ?
Ef )word pairs for whether or not the words share acommon meaning.
In Section 5, we explain ourtwo high-precision automatic annotation methods:checking if each pair of words (a) were aligned ina word-aligned bitext, or (b) were listed as transla-tion pairs in a bilingual dictionary.Table 1 provides some labelled examples withnon-empty cognate and false friend lists.
Note thatdespite these examples, this is not a ranking task:even in highly related languages, most words in Fhave empty Ef+ lists, and many have empty Ef?as well.
Thus one natural formulation for cognateidentification is a pairwise (and symmetric) cogna-tion classification that looks at each pair (f, ef ) sep-arately and individually makes a decision:+(napukin,napkin)?
(napukin,nanking)?
(napukin,pumpkin)In this formulation, the benefits of a discrimina-tive approach are clear: it must find substrings thatdistinguish cognate pairs from word pairs with oth-erwise similar form.
Klementiev and Roth (2006),although using a discriminative approach, do notprovide their infinite-attribute perceptron with com-petitive counter-examples.
They instead use translit-erations as positives and randomly-paired Englishand Russian words as negative examples.
In the fol-lowing section, we also improve on Klementiev andRoth (2006) by using a character-based string align-ment to focus the features for discrimination.4 Features for Discriminative SimilarityDiscriminative learning works by providing a train-ing set of labelled examples, each represented as aset of features, to a module that learns a classifier.
Inthe previous section we showed how labelled wordpairs can be collected.
We now address methods ofrepresenting these word pairs as sets of features use-ful for determining cognation.Consider the Ro?maji Japanese/English cognates:(sutoresu,stress).
The LCSR is 0.625.
Note that theLCSR of sutoresu with the English false friend sto-ries is higher: 0.75.
LCSR alone is too weak a fea-ture to pick out cognates.
We need to look at theactual character substrings.Klementiev and Roth (2006) generate features fora pair of words by splitting both words into all pos-sible substrings of up to size two:sutoresu ?
{ s, u, t, o, r, e, s, u, su, ut, to, ... su }stress ?
{ s, t, r, e, s, s, st, tr, re, es, ss }Then, a feature vector is built from all substring pairsfrom the two words such that the difference in posi-tions of the substrings is within one:{s-s, s-t, s-st, su-s, su-t, su-st, su-tr... r-s, r-s, r-es...}This feature vector provides the feature representa-tion used in supervised machine learning.This example also highlights the limitations of theKlementiev and Roth approach.
The learner can pro-vide weight to features like s-s or s-st at the begin-ning of the word, but because of the gradual accu-mulation of positional differences, the learner neversees the tor-tr and es-es correspondences that reallyhelp indicate the words are cognate.Our solution is to use the minimum-edit-distancealignment of the two strings as the basis for fea-ture extraction, rather than the positional correspon-dences.
We also include beginning-of-word (?)
andend-of-word ($) markers (referred to as boundary658markers) to highlight correspondences at those po-sitions.
The pair (sutoresu, stress) can be aligned:For the feature representation, we only extract sub-string pairs that are consistent with this alignment.1That is, the letters in our pairs can only be aligned toeach other and not to letters outside the pairing:{ ?-?,?s-?s, s-s, su-s, ut-t, t-t,... es-es, s-s, su-ss...}We define phrase pairs to be the pairs of substringsconsistent with the alignment.
A similar use of theterm ?phrase?
exists in machine translation, wherephrases are often pairs of word sequences consistentwith word-based alignments (Koehn et al, 2003).By limiting the substrings to only those pairsthat are consistent with the alignment, we gener-ate fewer, more-informative features.
Using moreprecise features allows a larger maximum substringsize L than is feasible with the positional approach.Larger substrings allow us to capture important re-curring deletions like the ?u?
in sut-st.Tiedemann (1999) and others have shown the im-portance of using the mismatching portions of cog-nate pairs to learn the recurrent spelling changes be-tween two languages.
In order to capture mismatch-ing segments longer than our maximum substringsize will allow, we include special features in ourrepresentation called mismatches.
Mismatches arephrases that span the entire sequence of unalignedcharacters between two pairs of aligned end char-acters (similar to the ?rules?
extracted by Mulloniand Pekar (2006)).
In the above example, su$-ss$is a mismatch with ?s?
and ?$?
as the aligned endcharacters.
Two sets of features are taken from eachmismatch, one that includes the beginning/endingaligned characters as context and one that does not.For example, for the endings of the French/Englishpair (e?conomique,economic), we include both thesubstring pairs ique$:ic$ and que:c as features.One consideration is whether substring featuresshould be binary presence/absence, or the count ofthe feature in the pair normalized by the length ofthe longer word.
We investigate both of these ap-1If the words are from different alphabets, we can get thealignment by mapping the letters to their closest Roman equiv-alent, or by using the EM algorithm to learn the edits (Ristadand Yianilos, 1998).proaches in our experiments.
Also, there is no rea-son not to include the scores of baseline approacheslike NED, LCSR, PREFIX or DICE as features inthe representation as well.
Features like the lengthsof the two words and the difference in lengths of thewords have also proved to be useful in preliminaryexperiments.
Semantic features like frequency simi-larity or contextual similarity might also be includedto help determine cognation between words that arenot present in a translation lexicon or bitext.5 ExperimentsSection 3 introduced two high-precision methods forgenerating labelled cognate pairs: using the wordalignments from a bilingual corpus or using the en-tries in a translation lexicon.
We investigate both ofthese methods in our experiments.
In each case, wegenerate sets of labelled word pairs for training, test-ing, and development.
The proportion of positive ex-amples in the bitext-labelled test sets range between1.4% and 1.8%, while ranging between 1.0% and1.6% for the dictionary data.2For the discriminative methods, we use a popu-lar Support Vector Machine (SVM) learning pack-age called SVMlight (Joachims, 1999).
SVMs aremaximum-margin classifiers that achieve good per-formance on a range of tasks.
In each case, welearn a linear kernel on the training set pairs andtune the parameter that trades-off training error andmargin on the development set.
We apply our classi-fier to the test set and score the pairs by their pos-itive distance from the SVM classification hyper-plane (also done by Bilenko and Mooney (2003)with their token-based SVM similarity measure).We also score the test sets using traditional ortho-graphic similarity measures PREFIX, DICE, LCSR,and NED, an average of these four, and Kondrak(2005)?s LCSF.
We also use the log of the edit prob-ability from the stochastic decoder of Ristad andYianilos (1998) (normalized by the length of thelonger word) and Tiedemann (1999)?s highest per-forming system (Approach #3).
Both use only thepositive examples in our training set.
Our evaluationmetric is 11-pt average precision on the score-sortedpair lists (also used by Kondrak and Sherif (2006)).2The cognate data sets used in our experiments are availableat http://www.cs.ualberta.ca/?bergsma/Cognates/6595.1 Bitext ExperimentsFor the bitext-based annotation, we use publicly-available word alignments from the Europarl corpus,automatically generated by GIZA++ for French-English (Fr), Spanish-English (Es) and German-English (De) (Koehn and Monz, 2006).
Initial clean-ing of these noisy word pairs is necessary.
We thusremove all pairs with numbers, punctuation, a capi-talized English word, and all words that occur fewerthan ten times.
We also remove many incorrectlyaligned words by filtering pairs where the pairwiseMutual Information between the words is less than7.5.
This processing leaves vocabulary sizes of 39Kfor French, 31K for Spanish, and 60K for German.Our labelled set is then generated from pairswith LCSR ?
0.58 (using the cutoff from Melamed(1999)).
Each labelled set entry is a triple of a) theforeign word f , b) the cognates Ef+ and c) the falsefriends Ef?.
For each language pair, we randomlytake 20K triples for training, 5K for developmentand 5K for testing.
Each triple is converted to a setof pairwise examples for learning and classification.5.2 Dictionary ExperimentsFor the dictionary-based cognate identification, weuse French, Spanish, German, Greek (Gr), Japanese(Jp), and Russian (Rs) to English translation pairsfrom the Freelang program.3 The latter three pairswere chosen so that we can evaluate on more distantlanguages that use non-Roman alphabets (althoughthe Ro?maji Japanese is Romanized by definition).We take 10K labelled-set triples for training, 2K fortesting and 2K for development.The baseline approaches and our definition ofcognation require comparison in a common alpha-bet.
Thus we use a simple context-free mapping toconvert every Russian and Greek character in theword pairs to their nearest Roman equivalent.
Wethen label a translation pair as cognate if the LCSRbetween the words?
Romanized representations isgreater than 0.58.
We also operate all of our com-parison systems on these Romanized pairs.6 ResultsWe were interested in whether our working defini-tion of cognation (translations and LCSR ?
0.58)3http://www.freelang.net/dictionary/Figure 1: LCSR histogram and polynomial trendlineof French-English dictionary pairs.System PrecKlementiev-Roth (KR) L?2 58.6KR L?2 (normalized, boundary markers) 62.9phrases L?2 61.0phrases L?3 65.1phrases L?3 + mismatches 65.6phrases L?3 + mismatches + NED 65.8Table 2: Bitext French-English development set cog-nate identification 11-pt average precision (%).reflects true etymological relatedness.
We looked atthe LCSR histogram for translation pairs in one ofour translation dictionaries (Figure 1).
The trendlinesuggests a bimodal distribution, with two distinctdistributions of translation pairs making up the dic-tionary: incidental letter agreement gives low LCSRfor the larger, non-cognate portion and high LCSRcharacterizes the likely cognates.
A threshold of0.58 captures most of the cognate distribution whileexcluding non-cognate pairs.
This hypothesis wasconfirmed by checking the LCSR values of a listof known French-English cognates (randomly col-lected from a dictionary for another project): 87.4%were above 0.58.
We also checked cognation on100 randomly-sampled, positively-labelled French-English pairs (i.e.
translated or aligned and havingLCSR ?
0.58) from both the dictionary and bitextdata.
100% of the dictionary pairs and 93% of thebitext pairs were cognate.Next, we investigate various configurations of thediscriminative systems on one of our cognate iden-tification development sets (Table 2).
The origi-nal Klementiev and Roth (2006) (KR) system can660Bitext DictionarySystem Fr Es De Fr Es De Gr Jp RsPREFIX 34.7 27.3 36.3 45.5 34.7 25.5 28.5 16.1 29.8DICE 33.7 28.2 33.5 44.3 33.7 21.3 30.6 20.1 33.6LCSR 34.0 28.7 28.5 48.3 36.5 18.4 30.2 24.2 36.6NED 36.5 31.9 32.3 50.1 40.3 23.3 33.9 28.2 41.4PREFIX+DICE+LCSR+NED 38.7 31.8 39.3 51.6 40.1 28.6 33.7 22.9 37.9Kondrak (2005): LCSF 29.8 28.9 29.1 39.9 36.6 25.0 30.5 33.4 45.5Ristad & Yanilos (1998) 37.7 32.5 34.6 56.1 46.9 36.9 38.0 52.7 51.8Tiedemann (1999) 38.8 33.0 34.7 55.3 49.0 24.9 37.6 33.9 45.8Klementiev & Roth (2006) 61.1 55.5 53.2 73.4 62.3 48.3 51.4 62.0 64.4Alignment-Based Discriminative 66.5 63.2 64.1 77.7 72.1 65.6 65.7 82.0 76.9Table 3: Bitext, Dictionary Foreign-to-English cognate identification 11-pt average precision (%).be improved by normalizing the feature count bythe longer string length and including the bound-ary markers.
This is therefore done with all thealignment-based approaches.
Also, because of theway its features are constructed, the KR systemis limited to a maximum substring length of two(L?2).
A maximum length of three (L?3) in the KRframework produces millions of features and pro-hibitive training times, while L?3 is computation-ally feasible in the phrasal case, and increases pre-cision by 4.1% over the phrases L?2 system.4 In-cluding mismatches results in another small boost inperformance (0.5%), while using an Edit Distancefeature again increases performance by a slight mar-gin (0.2%).
This ranking of configurations is consis-tent across all the bitext-based development sets; wetherefore take the configuration of the highest scor-ing system as our Alignment-Based Discriminativesystem for the remainder of this paper.We next compare the Alignment-Based Discrim-inative scorer to the various other implemented ap-proaches across the three bitext and six dictionary-based cognate identification test sets (Table 3).
Thetable highlights the top system among both thenon-adaptive and adaptive similarity scorers.5 In4Preliminary experiments using even longer phrases (be-yond L?3) currently produce a computationally prohibitivenumber of features for SVM learning.
Deploying current fea-ture selection techniques might enable the use of even more ex-pressive and powerful feature sets with longer phrase lengths.5Using the training data and the SVM to weight the com-ponents of the PREFIX+DICE+LCSR+NED scorer resulted innegligible improvements over the simple average on our devel-opment data.each language pair, the alignment-based discrimi-native approach outperforms all other approaches,but the KR system also shows strong gains overnon-adaptive techniques and their re-weighted ex-tensions.
This is in contrast to previous compar-isons which have only demonstrated minor improve-ments with adaptive over traditional similarity mea-sures (Kondrak and Sherif, 2006).We consistently found that the original KR perfor-mance could be surpassed by a system that normal-izes the KR feature count and adds boundary mark-ers.
Across all the test sets, this modification resultsin a 6% average gain in performance over baselineKR, but is still on average 5% below the Alignment-Based Discriminative technique, with a statisticallysignificantly difference on each of the nine sets.6Figure 2 shows the relationship between train-ing data size and performance in our bitext-basedFrench-English data.
Note again that the Tiedemannand Ristad & Yanilos systems only use the positiveexamples in the training data.
Our alignment-basedsimilarity function outperforms all the other systemsacross nearly the entire range of training data.
Notealso that the discriminative learning curves show nosigns of slowing down: performance grows logarith-mically from 1K to 846K word pairs.For insight into the power of our discrimina-tive approach, we provide some of our classifiers?highest and lowest-weighted features (Table 4).6Following Evert (2004), significance was computed usingFisher?s exact test (at p = 0.05) to compare the n-best word pairsfrom the scored test sets, where n was taken as the number ofpositive pairs in the set.66100.10.20.30.40.50.60.71000  10000  100000  1e+0611-pt AveragePrecisionNumber of training pairsNEDTiedemannRistad-YanilosKlementiev-RothAlignment-Based Discrim.Figure 2: Bitext French-English cognate identifica-tion learning curve.Lang.
Feat.
Wt.
ExampleFr (Bitext) e?es-ed +8.0 ve?rifie?es:verifiedJp (Dict.)
ru-l +5.9 penaruti:penaltyDe (Bitext) k-c +5.5 kreativ:creativeRs (Dict.)
irov- +4.9 motivirovat:motivateGr (Dict.)
f-ph +4.1 symfonia:symphonyGr (Dict.)
kos-c +3.3 anarchikos:anarchicGr (Dict.)
os$-y$ -2.5 anarchikos:anarchyJp (Dict.)
ou-ou -2.6 handoutai:handoutEs (Dict.)
-un -3.1 balance:unbalanceFr (Dict.)
er$-er$ -5.0 former:formerEs (Bitext) mos-s -5.1 toleramos:toleratesTable 4: Example features and weights for var-ious Alignment-Based Discriminative classifiers(Foreign-English, negative pairs in italics).Note the expected correspondences between foreignspellings and English (k-c, f-ph), but also featuresthat leverage derivational and inflectional morphol-ogy.
For example, Greek-English pairs with theadjective-ending correspondence kos-c, e.g.
anar-chikos:anarchic, are favoured, but pairs with the ad-jective ending in Greek and noun ending in English,os$-y$, are penalized; indeed, by our definition, an-archikos:anarchy is not cognate.
In a bitext, thefeature e?es-ed captures that feminine-plural inflec-tion of past tense verbs in French corresponds toregular past tense in English.
On the other hand,words ending in the Spanish first person plural verbsuffix -amos are rarely translated to English wordsending with the suffix -s, causing mos-s to be pe-Gr-En (Dict.)
Es-En (Bitext)alkali:alkali agenda:agendamakaroni:macaroni natural:naturaladrenalini:adrenaline ma?rgenes:marginsflamingko:flamingo hormonal:hormonalspasmodikos:spasmodic rado?n:radonamvrosia:ambrosia higie?nico:hygienicTable 5: Highest scored pairs by Alignment-BasedDiscriminative classifier (negative pairs in italics).nalized.
The ability to leverage negative features,learned from appropriate counter examples, is a keyinnovation of our discriminative framework.Table 5 gives the top pairs scored by our systemon two of the sets.
Notice that unlike traditional sim-ilarity measures that always score identical wordshigher than all other pairs, by virtue of our featureweighting, our discriminative classifier prefers somepairs with very characteristic spelling changes.We performed error analysis by looking at all thepairs our system scored quite confidently (highlypositive or highly negative similarity), but whichwere labelled oppositely.
Highly-scored false pos-itives arose equally from 1) actual cognates notlinked as translations in the data, 2) related wordswith diverged meanings, e.g.
the error in Table 5:makaroni in Greek actually means spaghetti in En-glish, and 3) the same word stem, a different partof speech (e.g.
the Greek/English adjective/nounsynonymos:synonym).
Meanwhile, inspection of thehighly-confident false negatives revealed some (of-ten erroneously-aligned in the bitext) positive pairswith incidental letter match (e.g.
the French/Englishrecettes:proceeds) that we would not actually deemto be cognate.
Thus the errors that our system makesare often either linguistically interesting or point outmistakes in our automatically-labelled bitext and (toa lesser extent) dictionary data.7 ConclusionThis is the first research to apply discriminativestring similarity to the task of cognate identification.We have introduced and successfully applied analignment-based framework for discriminative sim-ilarity that consistently demonstrates improved per-formance in both bitext and dictionary-based cog-662nate identification on six language pairs.
Our im-proved approach can be applied in any of the di-verse applications where traditional similarity mea-sures like Edit Distance and LCSR are prevalent.
Wehave also made available our cognate identificationdata sets, which will be of interest to general stringsimilarity researchers.Furthermore, we have provided a natural frame-work for future cognate identification research.
Pho-netic, semantic, or syntactic features could be in-cluded within our discriminative infrastructure to aidin the identification of cognates in text.
In particu-lar, we plan to investigate approaches that do not re-quire the bilingual dictionaries or bitexts to generatetraining data.
For example, researchers have auto-matically developed translation lexicons by seeingif words from each language have similar frequen-cies, contexts (Koehn and Knight, 2002), bursti-ness, inverse document frequencies, and date dis-tributions (Schafer and Yarowsky, 2002).
Semanticand string similarity might be learned jointly with aco-training or bootstrapping approach (Klementievand Roth, 2006).
We may also compare alignment-based discriminative string similarity with a morecomplex discriminative model that learns the align-ments as latent structure (McCallum et al, 2005).AcknowledgmentsWe gratefully acknowledge support from the Natu-ral Sciences and Engineering Research Council ofCanada, the Alberta Ingenuity Fund, and the AlbertaInformatics Circle of Research Excellence.ReferencesGeorge W. Adamson and Jillian Boreham.
1974.
The use ofan association measure based on character structure to iden-tify semantically related pairs of words and document titles.Information Storage and Retrieval, 10:253?260.Mikhail Bilenko and Raymond J. Mooney.
2003.
Adaptive du-plicate detection using learnable string similarity measures.In KDD, pages 39?48.Eric Brill and Robert Moore.
2000.
An improved error modelfor noisy channel spelling correction.
In ACL.
286?293.Stefan Evert.
2004.
Significance tests for the evaluation ofranking methods.
In COLING, pages 945?951.Thorsten Joachims.
1999.
Making large-scale Support VectorMachine learning practical.
In Advances in Kernel Methods:Support Vector Machines, pages 169?184.
MIT-Press.Alexandre Klementiev and Dan Roth.
2006.
Named entitytransliteration and discovery from multilingual comparablecorpora.
In HLT-NAACL, pages 82?88.Philipp Koehn and Kevin Knight.
2002.
Learning a transla-tion lexicon from monolingual corpora.
In ACL Workshopon Unsupervised Lexical Acquistion.Philipp Koehn and Christof Monz.
2006.
Manual and auto-matic evaluation of machine translation between Europeanlanguages.
In NAACL Workshop on Statistical MachineTranslation, pages 102?121.Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003.Statistical phrase-based translation.
In HLT-NAACL, pages127?133.Grzegorz Kondrak and Tarek Sherif.
2006.
Evaluation ofseveral phonetic similarity algorithms on the task of cog-nate identification.
In COLING-ACL Workshop on Linguis-tic Distances, pages 37?44.Grzegorz Kondrak.
2005.
Cognates and word alignment inbitexts.
In MT Summit X, pages 305?312.Vladimir I. Levenshtein.
1966.
Binary codes capable of cor-recting deletions, insertions, and reversals.
Soviet PhysicsDoklady, 10(8):707?710.Gideon S. Mann and David Yarowsky.
2001.
Multipath trans-lation lexicon induction via bridge languages.
In NAACL,pages 151?158.Andrew McCallum, Kedar Bellare, and Fernando Pereira.2005.
A conditional random field for discriminatively-trained finite-state string edit distance.
In UAI.
388?395.I.
Dan Melamed.
1999.
Bitext maps and alignment via patternrecognition.
Computational Linguistics, 25(1):107?130.Andrea Mulloni and Viktor Pekar.
2006.
Automatic detec-tion of orthographic cues for cognate recognition.
In LREC,pages 2387?2390.Ari Rappoport and Tsahi Levent-Levi.
2006.
Induction ofcross-language affix and letter sequence correspondence.
InEACL Workshop on Cross-Language Knowledge Induction.Eric Sven Ristad and Peter N. Yianilos.
1998.
Learning string-edit distance.
IEEE Transactions on Pattern Analysis andMachine Intelligence, 20(5):522?532.Charles Schafer and David Yarowsky.
2002.
Inducing transla-tion lexicons via diverse similarity measures and bridge lan-guages.
In CoNLL, pages 207?216.Michael Strube, Stefan Rapp, and Christoph Mu?ller.
2002.
Theinfluence of minimum edit distance on reference resolution.In EMNLP, pages 312?319.Ben Taskar, Simon Lacoste-Julien, and Dan Klein.
2005.
Adiscriminative matching approach to word alignment.
InHLT-EMNLP, pages 73?80.Jo?rg Tiedemann.
1999.
Automatic construction of weightedstring similarity measures.
In EMNLP-VLC, pages 213?219.Dmitry Zelenko and Chinatsu Aone.
2006.
Discriminativemethods for transliteration.
In EMNLP, pages 612?617.663
