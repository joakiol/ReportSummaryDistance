Proceedings of the 1st Workshop on South and Southeast Asian Natural Language Processing (WSSANLP), pages 17?25,the 23rd International Conference on Computational Linguistics (COLING), Beijing, August 2010Clause Identification and Classification in BengaliAniruddha Ghosh1 Amitava Das2 Sivaji Bandyopadhyay3Department of Computer Science and EngineeringJadavpur Universityarghyaonline@gmail.com1 amitava.santu@gmail.com2 si-vaji_cse_ju@yahoo.com3AbstractThis paper reports about the develop-ment of clause identification and classi-fication techniques for Bengali language.A syntactic rule based model has beenused to identify the clause boundary.
Forclause type identification a Conditionalrandom Field (CRF) based statisticalmodel has been used.
The clause identi-fication system and clause classificationsystem demonstrated 73% and 78% pre-cision values respectively.1 IntroductionThe clause identification is one of the shallowsemantic parsing tasks, which is important invarious NLP applications such as MachineTranslation, parallel corpora alignment, Informa-tion Extraction and speech applications.
Gram-matically a clause is a group of words having asubject and a predicate of its own, but formingpart of a sentence.
Clause boundary identifica-tion of natural language sentences poses consi-derable difficulties due to the ambiguous natureof natural languages.
Clause classification is aconvoluted task as natural language is generallysyntactically rich in formation of sentences orclauses.By the classical theory of Panini (Paul andStaal, 1969) a clause is the surface level basicsyntactic element which holds the basic depen-dent semantics (i.e.
lexical semantic have nodependency) to represent the overall meaning ofany sentence.
This syntactic to semantic deriva-tion proceeds through two intermediate stages:the level of karaka relations, which are compa-rable to the thematic role types and the level ofinflectional or derivational morphosyntax.Fillmore?s Case Grammar (Fillmore et.
al,2003), and much subsequent work, revived thePanini?s proposals in a modern setting.
A mainobjective of Case Grammar was to identify syn-tactic positions of semantic arguments that mayhave different realizations in syntax.In the year of 1996 Bharati et al (1996) de-fines the idea of Chunk or local word group forIndian languages.
After the successful imple-mentation of Shakti1 , the first publicly availableEnglish-Hindi machine translation system theidea of chunk became the most acceptable syn-tactic/semantic representation format for Indianlanguages, known as Shakti Standard Format(SSF).In 2009 Bali et al (2009) redefines the idea ofchunk and establishes that the idea of chunkingvaries with prosodic structure of a language.Boundary of chunk level is very ambiguous it-self and can differ by writer or speaker accord-ing to their thrust on semantic.Therefore it is evident that automatic clauseidentification for Indian languages needs moreresearch efforts.
In the present task, clauseboundary identification is attempted using theclassical theory of Panini and the Case Grammarapproach of Fillmore on the shallow parsed out-put in SSF structure.
It may be worth mentioningthat several basic linguistic tools in Indian lan-guages such as part of speech tagger, chunker,and shallow parser follow SSF2  as a standard.Previous research on clause identification wasdone mostly on the English language (Sang andDejean, 2001).
There have been limited effortson clause identification for Indian languages.One such effort is proposed in Ram and Devi,1http://shakti.iiit.ac.in/2http://ltrc.iiit.ac.in/MachineTrans/research/tb/shakti-analy-ssf.pdf17(2008) with statistical method.
The idea of ge-nerative grammar based on rule-based descrip-tions of syntactic structures introduced byChomsky (Chomsky, 1956) points out that everylanguage has its own peculiarities that cannot bedescribed by standard grammar.
Therefore a newconcept of generative grammar has been pro-posed by Chomsky.
Generative grammar can beidentified by statistical methods.
In the presenttask, conditional random field (CRF) 3  -basedmachine learning method has been used inclause type classification.
According to the bestof our knowledge this is the first effort to identi-fy and classify clauses in Bengali.The present system is divided into two parts.First, the clause identification task aims to iden-tify the start and the end boundaries of the claus-es in a sentence.
Second, Clause classificationsystem identifies the clause types.Analysis of corpus and standard grammar ofBengali revealed that clause boundary identifica-tion depends mostly on syntactic dependency.For this reason, the present clause boundaryidentification system is rule based in nature.Classification of clause is a semantic task anddepends on semantic properties of Bengali lan-guage.
Hence we follow the theory ofChomsky?s generative grammar to disambiguateamong possible clause types.
The present classi-fication system of clause is a statistics-basedapproach.
A conditional random field (CRF)based machine learning method has been used inthe clause classification task.
The output of therule based identification system is forwarded tothe machine learning model as input.The rest of the paper is organized as follows.In section 2 we elaborate the rule based clauseboundary identification.
The next section 3 de-scribes the implementation detail with all identi-fied features for the clause classification prob-lem.
Result section 4 reports about the accuracyof the hybrid system.
In error analysis sectionwe reported the limitations of the present sys-tem.
The conclusion is drawn in section 5 alongwith the future task direction.2 Resource AcquisitionBengali belongs to Indo-Aryan language family.A characteristic of Bengali is that it is under-3http://crf.sourceforge.net/resourced.
Language research for Bengali gotattention recently.
Resources like annotated cor-pus and linguistics tools for Bengali are veryrarely available in the public domain.2.1 CorpusWe used the NLP TOOLS CONTEST: ICON20094 dependency relation marked training data-set of 980 sentences for training of the presentsystem.
The data has been further annotated atthe clause level.
According to the standardgrammar there are two basic clause types such asPrincipal clause and Subordinate clause.
Subor-dinate clauses have three variations as Nounclause, Adjective clause and Adverbial clause.The tagset defined for the present task consistsof four tags as Principal clause (PC), Nounclause (NC), Adjective clause (AC) and Adver-bial clause (RC).
The annotation tool used forthe present task is Sanchay5.
The detailed statis-tics of the corpus are reported in Table 1.Train Dev TestNo of Sentences 980 150 100Table 1: Statistics of Bengali Corpus2.1.1 Annotation AgreementTwo annotators (Mr. X and Mr. Y) participatedin the present task.
Annotators were asked toidentify the clause boundaries as well as the typeof the identified clause.
The agreement of anno-tations among two annotators has been eva-luated.
The agreements of tag values at clauseboundary level and clause type levels are listedin Table 2.Boundary TypePercentage 76.54% 89.65%Table 2: Agreement of annotators at clauseboundary and type levelIt is observed from the Table 2 that clauseboundary identification task has lower agree-ment value.
A further analysis reveals that thereare almost 9% of cases where clause boundaryhas nested syntactic structure.
These types ofclause boundaries are difficult to identify.
Oneof such cases is Inquisitive semantic (Groenen-dijk, 2009) cases, ambiguous for human annota-4http://ltrc.iiit.ac.in/nlptools2009/5http://ltrc.iiit.ac.in/nlpai_contest07/Sanchay/18tors too.
It is better to illustrate with some spe-cific example.If John goes to the party,will Mary go as well?In an inquisitive semantics for a language ofpropositional logic the interpretation of disjunc-tion is the source of inquisitiveness.
Indicativeconditionals and conditional questions aretreated both syntactically and semantically.
Thesemantics comes with a new logical-pragmatically notion that judges and comparesthe compliance of responses to an initiative ininquisitive dialogue (Groenendijk, 2009).
Henceit is evident that these types of special casesneed special research attention.2.2 Shallow ParserShallow parser6 for Indian languages, developedunder a Government of India funded consortiumproject named Indian Language to Indian Lan-guage Machine Translation System (IL-ILMT),are now publicly available.
It is a well developedlinguistic tool and produce good credible analy-sis.
For the present task the linguistic analysis isdone by the tool and it gives output as prunedmorphological analysis at each word level, partof speech at each word level, chunk boundarywith type-casted chunk label, vibhakti computa-tion and chunk head identification.2.3 Dependency parserA dependency parser for Bengali has been usedas described in Ghosh et al (2009).
The depen-dency parser follows the tagset7  identified forIndian languages as a part of NLP TOOLSCONTEST 2009 as a part of ICON 2009.3 Rule-based Clause Boundary Identi-ficationAnalysis of a Bengali corpus and standardgrammar reveals that clause boundaries are di-rectly related to syntactic relations at sentencelevel.
The present system first identifies thenumber of verbs present in a sentence and sub-sequently finds out dependant chunks to eachverb.
The set of identified chunks that have rela-tion with a particular verb is considered as aclause.
But some clauses have nested syntactic6http://ltrc.iiit.ac.in/analyzer/bengali/7http://ltrc.iiit.ac.in/nlptools2009/CR/intro-husain.pdfformation, known as inquisitive semantic.
Theseclauses are difficult to identify by using onlysyntactic relations.
The present system has limi-tations on those inquisitive types of clauses.Bengali is a verb final language.
Most of theBengali sentences follow a Subject-Object-Verb(SOV) pattern.
In Bengali, subject can be miss-ing in a clause formation.
Missing subjects andmissing keywords lead to ambiguities in clauseboundary identification.
In sentences which donot follow the SOV pattern, chunks that appearafter the finite verb are not considered with thatclause.
For example:wAra AyZawana o parimANaxeKe buJawe asubiXA hayZa eipaWa hAwi geCe.After seeing the size andeffect, it is hard to under-stand that an elephant wentthrough this way.In the above example, there is hardly any clueto find beginning of subordinate clause.
To solvethis type of problem, capturing only the treestructure of a particular sentence has beentreated as the key factor to the goal of disambig-uation.
One way to capture the regularity ofchunks over different sentences is to learn a ge-nerative grammar that explains the structure ofthe chunks one finds.
These types of languageproperties make the clause identification prob-lem difficult.3.1 Karaka relationDependency parsing generates the inter chunkrelation and generates the tree structure.
The de-pendency parser as described in Section 2.3 usedas a supportive tool for the present problem.In the output of the dependency parsing sys-tems, most of the chunks have a dependencyrelation with the verb chunk.
These relations arecalled as karaka relation.
Using dependency re-lations, the chunks having dependency relationi.e.
karaka relation with same verb chunk aregrouped.
The set of chunks are the members of aclause.
Using this technique, identification ofchunk members of a certain clause becomes in-dependent of SOV patterns of sentences.
An ex-ample is shown in Figure 1.19Figure 1: Karaka Relations3.2 Compound verbsIn Bengali language a noun chunk with an infi-nite verb chunk or a finite verb chunk can form acompound verb.
An example is shown in Figure2.Figure 2: Compound VerbIn the above example, the noun chunk and theVGF chunk form a compound verb.
These twoconsecutive noun and verb chunks appearing ina sentence are merged to form a compound verb.These chunks are connected with a part-of rela-tion in Dependency Parsing.
The set of relatedchunks with these noun and verb chunks aremerged.3.3 Shasthi Relation (r6)In dependency parsing the genitive relation aremarked with shasthi (r6) relation.
The chunkwith shasthi (r6) (see the tagset of NLP ToolContest: ICON 2009) relation always has a rela-tion with the succeeding chunk.
An example isshown in Figure 3.In the example as mentioned in Figure 3, theword ?wadera?
(their) has a genitive relationwith the word in the next chunk ?manera?(ofmind).
These chunks are placed in a set.
It formsa set of two chunks members.
The system gene-rates two different types of set.
In one forms aset of members having relation with verbchunks.
Another set contains two noun chunkswith genitive relation.
Now the sets containingonly noun chunks with genitive relation does notform a clause.
Those sets are merged with the setcontaining verb chunk and having dependencyrelation with the noun chunks.
An example isshown in Figure 3.Figure 3: Shasthi RelationConsider ?
is set of all sets containing twochunk members connected with genitive marker.Consider ?
is a set of all sets consisting of re-lated chunks with a verb chunk.
?
is a element of?.
?
is a element of ?.
Now, If a set ?
which canhave common chunks from a ?
set then ?
set isassociated with the proper ?
set.
So, ?
?
?
?Null then ?
= ?
?
?.
If a set ?
which can havecommon chunks from two ?
sets which leads toambiguity of associability of the ?
set with theproper ?
set.
If ?
?
?
= verb chunk, then ?
setwill be associated with ?
set containing the verbchunk.
From the related set of chunk of verbchunks, system has identified the clauses in thesentence.
Afterwards, the clauses are markedwith the B-I-E (Beginning-Intermediate-End)notation.4 Case Grammar-Identification of Ka-raka relationsThe classical Sanskrit grammar Astadhyayi 8(?Eight Books?
), written by the Indian gramma-8http://en.wikipedia.org/wiki/P%C4%81%E1%B9%87ini20rian Panini sometime during 600 or 300 B.C.
(Robins, 1979), includes a sophisticated theoryof thematic structure that remains influential tilltoday.
Panini?s Sanskrit grammar is a system ofrules for converting semantic representations ofsentences into phonetic representations (Ki-parsky, 1969).
This derivation proceeds throughtwo intermediate stages: the level of karaka rela-tions, which are comparable to the thematic roletypes described above; and the level of morpho-syntax.Fillmore?s Case Grammar (Fillmore, 1968),and much subsequent work, revived the Panini?sproposals in a modern setting.
A main objectiveof Case Grammar was to identify semantic ar-gument positions that may have different realiza-tions in syntax.
Fillmore hypothesized ?a set ofuniversal, presumably innate, concepts whichidentify certain types of judgments human be-ings are capable of making about the events thatare going on around them?.
He posited the fol-lowing preliminary list of cases, noting howeverthat ?additional cases will surely be needed?.?
Agent: The typically animate perceivedinstigator of the action.?
Instrument: Inanimate force or objectcausally involved in the action or state.?
Dative: The animate being affected bythe state or action.?
Factitive: The object or being resultingfrom the action or state.?
Locative: The location or time-spatialorientation of the state or action.?
Objective: The semantically most neu-tral case, the concept should be limited tothings which are affected by the action orstate.The SSF specification handles this syntacticdependency by a coarse-grain tagset of Nomini-tive, Accusative, Genitive and Locative casemarkers.
Bengali shallow parser identifies thechunk heads as part of the chunk level analysis.Dependency parsing followed by a rule basedmodule has been developed to analyze the inter-chunk relationships depending upon each verbpresent in a sentence.
Described theoretical as-pect can well define the problem definition ofclause boundary identification but during prac-tical implementation of the solution we foundsome difficulties.
Bengali has explicit casemarkers and thus long distant chunk relations arepossible as valid grammatical formation.
As anexample:bAjAre yAoyZAra samayZa xeKAkare gela rAma.bAjAre yAoyZAra samayZa rAmaxeKA kare gela.rAma bAjAre yAoyZAra samayZaxeKA kare gela.Rama came to meet when hewas going to market.In the above example rAma could be placedanywhere and still all the three syntactic forma-tion are correct.
For these feature of Bengalimany dependency relation could be missed outlocated at far distance from the verb chunk in asentence.
Searching for uncountable numbers ofchunks have dependency relation with a particu-lar verb may have good idea theoretically but weprefer a checklist strategy to resolve the problemin practice.
At this level we decided to check allsemantic probable constituents by the definitionof universal, presumably innate, concepts list.We found this is a nice fall back strategy to iden-tify the clause boundary.
Separately rules arewritten as described below.4.1 AgentBengali is a verb final language.
Most of theBengali sentences follow a Subject-Object-Verb(SOV) pattern.
In Bengali, subject can be miss-ing in a clause formation.
Missing subjects andmissing keywords lead to ambiguities in clauseboundary identification.  	?Close the door.In the previous case system marks?/door?
as an ?Agent?
whereas the?Agent?
is ?you?
(2nd person singular number),silent here.We developed rules using case marker, Gend-er-Number-Person (GNP), morphological fea-ture and modality features to disambiguate these21types of phenomena.
These rules help to stopfalse hits by identifying no 2nd person phrasewas there in the example type sentences and em-power to identify proper phrases by locatingproper verb modality matching with the rightchunk.4.2 InstrumentInstrument identification is ambiguous for thesame type of case marker (nominative) taken byagent and instrument.
There is no ani-mate/inanimate information is available at syn-tactic level.	   ?The music of Shyam?s messme-rized me. ?The umbrella of Sumi.Bengali sentences follow a Subject-Object-Verb (SOV) pattern.
Positional information ishelpful to disambiguate between agent and in-strument roles.4.3 DativeGeneralBengali English Gloss/	//	...Morn-ing/evening/night/dawn?_////		...Oclock/time/hour/minute/second?//...Mon-day/Tuesday/Sunday?bn_aikaar/bn_aikaar /... Bengali months?!/	"#!
January/February?//... Day/month/year?/$/%... Longtime/moment?Relative&	'/%	... Before/After?	/	%	... Upcoming/SpecialCases(?
/*	...When rise/Whenstop?Table 3: Categories of Time ExpressionsTime expression identification has a differentaspect in NLP applications.
People generallystudied time expression to track event or anyother kind of IR task.
Time expressions could becategorized in two types as General and Rela-tive.In order to apply rule-based process we de-veloped a manually augmented list with pre de-fined categories as described in Table 3.
Stillthere are many difficulties to identify specialcases of relative time expressions.
As an exam-ple:+ (?
 & , -	?When moon rise we will startour journey.In the previous example the relative time ex-pression is ?(?
/when rise?
is tagged as infiniteverb (for Bengali tag level is VGNF).
Statisticsreveals that these special types of cases approx-imately are only 1.8-2% in overall corpus.These types of special cases are not handledby the present system.4.4 FactitiveThe particular role assignment is the most chal-lenging task as it separately known as argumentidentification.
To resolve this problem we need arelatively large corpus to learn fruitful featuresimilarities among argument structures.A manually generated list of causative post-positional words and pair wise conjuncts as re-ported in Table 4 has been prepared to identifyargument phrases in sentences.GeneralBengali English Gloss/	/	- ... Hence/Reason/ReasonRelative?_	 If_else?,_, If_elseTable 4: Categories of Causative Expressions4.5 LocativeRules have been written using a manually editedlist as described in Table 5.
Morphological loca-tive case marker feature have been successfullyused in identification of locative marker.
Thereis an ambiguity among Agent, Dative and Loca-tive case marker as they orthographically gene-rates same type of surface form (using common22suffixes as: 	?, 	? etc).
There is less differenceswe noticed among their syntactic dependencystructure throughout the corpus.
Positional in-formation helps in many cases to disambiguatethese cases. 	0 ?There is unemployment incountry side.A different type of problem we found whereverb plays locative role.
As an example:	 	?
	  	 		?Where people works there.Here ?
?
	  	/Where people works?should be identified as locative marker.
But thisis a verb chunk and leads difficulty.
Corpus sta-tistics reveals that this type of syntactic forma-tion is approximately 0.8-1.0% only and notbeen handled by the present system.Gen-eralBengali English Gloss	?/	/1 Morn-ing/evening/night/dawn?Rela-tive&	'/%	... Before/After?	/	%	... Front/BehindTable 5: Categories of Locative Expressions4.6 ObjectiveThe concept of objectivity is limited to things orhuman which are affected by the action or state.Statistical parser is a best way out for the presentproblem.
The karma karaka (k2) identified bythe dependency parser is simply the objectiveconstituent of any clause.5 Identification the Type of ClausesAfter marking of the clause boundaries, clausetypes are identified.
According to the clausestructure and functions in a sentence, clauses areclassified in to four types as principal clause,noun clause, adverbial clause and adjectiveclause.
To identify the clause types, a CRF basedstatistical approach has been adopted.5.1 Generative GrammarIn theoretical linguistics, generative grammarrefers to a particular approach to the study ofsyntax.
A generative grammar of a language at-tempts to give a set of rules that will correctlypredict which combinations of words will formgrammatical sentences.
Chomsky has arguedthat many of the properties of a generativegrammar arise from an "innate" universal gram-mar.
Proponents of generative grammar haveargued that most grammar is not the result ofcommunicative function and is not simplylearned from the environment.
Strongly moti-vated by Chomsky?s generative grammar weadopt the CRF based machine learning to learnthe properties of a language and apply the know-ledge to typecast clause classification as well.5.2 Conditional Random Fields (CRF)CRFs are undirected graphical models whichdefine a conditional distribution over a label se-quence given an observation sequence.
CRFusually trained based on input features.
Maxi-mum likelihood is being calculated on chosenfeatures for training.5.2.1 FeaturesThe vitality of using any machine learning ap-proach is in identification of proper feature set.Conditional Random Field (CRF) works on aconditional distribution over a label sequencegiven an observation sequence.
Hence CRF usedhere to statistically capture the prosodic structureof the language.
The features experimentallyfound useful are chosen as listed below.5.2.2 Chunk LabelAn n-gram chunk label window has been fixedto capture internal arrangement of any particularclause type.5.2.3 Chunk HeadsChunk head pattern is the vital clue to identifythe any clause pattern.5.2.4 WordIn the clause type identification task words playa crucial part as word carries the information ofthe clause type.From the input file in the SSF format, all themorphological information like root word, chunkheads are retrieved.
The clause type identifica-tion depends on the morphological informationalong with the position in the sentences and alsothe surrounding chunk labels.
Therefore the CRFbased statistical tool calculates the probability of23the morphological information along with thedependency relations of the previous three andnext three chunks.
For the present task a quad-gram technique is used as most of the sentenceshave around 10 chunks.The input file in the SSF format includesChunk labels and word.
The clause informationin the input files are in B-I-E format so that thebegin (B) / inside (I) / end (E) information for aclause are associated as a feature.
The chunkheads, words are identified from the training fileand noted as an input feature in the CRF basedsystem.
Each sentence is represented as a featurevector for the CRF machine learning task.
Theinput features associated with each word in thetraining set are the word, clause boundary tags,chunk tag and clause type tags.6 Error AnalysisDuring the development stage of the system wehad studied the various clause boundary labelingerrors committed by the system.
In the aboveexamples, the system faces ambiguity to derivethe rules for the identification of the clausemembers when a noun chunk acts as a nounmodifier of a clause.
In complex sentences, theverb chunk of the subordinate clause may havenoun modifier relation with the principal clause.As System forms the groups the chunks withdependency relation, system merges the subor-dinate clause with principal clause.
An exampleis shown in Figure 4.Figure 4: Shasthi Relation7 Experimental resultsSystem Precision RecallBoundary  73.12% 75.34%Classification  78.07% 78.92%Table 6: Performance of present SystemThe accuracy of the rule-based clause boundaryidentification system is 73.12% and 78.07% isthe accuracy clause type classification system asreported in Table 6.8 ConclusionThis paper reports about our works on clauseidentification and classification in Bengali lan-guage.
We have used the rule based system toidentify clause boundary and a statistical CRFbased model is used to decide the type of aclause.In future we would like to study different se-mantic relations which can regulate clause typeand boundary.24ReferencesA.
Ghosh, A. Das, P. Bhaskar, S. Bandyopadhyay.Dependency Parser for Bengali: the JU System atICON 2009, In NLP Tool Contest ICON 2009,December 14th-17th, 2009, Hyderabad.Akshar Bharati,  Vineet Chaitanya ,  Rajeev Sangal.Natural Language Processing A Paninian Perspec-tive.
Prentice Hall of India (1995).Charles J. Fillmore, Christopher R. Johnson, and Mi-riam R. L. Petruck.
2003.
Background to Frame-Net.
International Journal of Lexicography,16:235?250.Chomsky, Noam (1956).
"Three models for the de-scription of language".
IRE Transactions on In-formation Theory 2: 113?124.Erik F. Tjong kim sang and Herve Dejean Introduc-tion to CoNLL-2001 shared task: clause identifica-tion.Groenendijk, J.: (2009), ?Inquisitive Semantics: TwoPossibilities for Disjunction?.
In Lecture Notes inComputer Science.
ISBN- 978-3-642-00664-7.Volume- 5422/2009.
Berlin,  Heidelberg.
Pages-80-94.Kalika Bali, Monojit Choudhury, Diptesh Chatterjee,Arpit Maheswari, Sankalan Prasad.
Correlates be-tween Performance, Prosodic and Phrase Struc-tures in Bangla and Hindi: Insights from a Psycho-linguistic Experiment.
In Proceeding of ICON2009.
Hyderabad.
India.Kiparsky, Paul and J. F. Staal (1969).
?Syntactic andsemantic relations in Panini.?
Foundations of Lan-guage 5, 83-117.Robins, R. H. (1979).
A Short History of Linguistics(2nd Edition).
London: Longman.Vijay Sundar Ram.
R and Sobha Lalitha Devi, 2008Clause Boundary Identification Using ConditionalRandom Fields.25
