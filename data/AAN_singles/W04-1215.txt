Annotating Multiple Types of Biomedical Entities:A Single Word Classification ApproachChih Lee, Wen-Juan Hou and Hsin-Hsi ChenNatural Language Processing LaboratoryDepartment of Computer Science and Information EngineeringNational Taiwan University1 Roosevelt Road, Section 4, Taipei, Taiwan, 106{clee, wjhou}@nlg.csie.ntu.edu.tw, hh_chen@csie.ntu.edu.twAbstractNamed entity recognition is a fundamentaltask in biomedical data mining.
Multiple -classannotation is more challenging than single -class annotation.
In this paper, we took asingle word classification approach to dealingwith the multiple -class annotation problemusing Support Vector Machines (SVMs).Word attributes, results of existinggene/protein name taggers, context, and otherinformation are important features forclassification.
During training, the size oftraining data and the distribution of namedentities are considered.
The preliminaryresults showed that the approach might befeasible when more training data is used toalleviate the data imbalance problem.1 IntroductionThe volumn of on-line material in the biomedicalfield has been growing steadily for more than 20years.
Several attempts have been made to mineknowledge from biomedical documents, such asidentifying gene/protein names, recognizingprotein interactions, and capturing specificrelations in databases.
Among these, named entityrecognition is a fundamental step to mineknowledge from biological articles.Previous approaches on biological named entityextraction can be classified into two types ?
rule-based (Fukuda et al, 1998; Olsson et al, 2002;Tanabe and Wilbur, 2002) and corpus-based(Collier et al, 2000; Chang et al, 2004).
Yapex(Olsson et al, 2002) implemented some heuristicsteps described by Fukuda, et al, and appliedfilters and knowledge bases to remove false alarms.Syntactic information obtained from the parser wasincorporated as well.
GAPSCORE (Chang et al,2004) scored words on the basis of statisticalmodels that quantified their appearance,morphology and context.
The models includesNaive Bayes (Manning and Schutze, 1999),Maximum Entropy (Ratnaparkhi, 1998) andSupport Vector Machines (Burges, 1998).GAPSCORE also used Brill?s tagger (Brill, 1994)to get the POS tag to filter out some words that areclearly not gene or protein names.
Efforts havebeen made (Hou and Chen, 2002, 2003; Tsuruokaand Tsujii, 2003) to improve the performance.
Thenature of classification makes it possible tointegrate existing approaches by extracting goodfeatures from them.
Several works employingSVM classifier have been done (Kazama et al,2002; Lee et al, 2003; Takeuchi and Collier, 2003;Yamamoto et al, 2003), and will be discussedfurther in the rest of this paper.Collocation denotes two or more words havingstrong relationships (Manning and Schutze, 1999).Hou and Chen (2003) showed that protein/genecollocates are capable of assisting existingprotein/gene taggers.
In this paper, we addressedthis task as a multi-class classification problemwith SVMs and extended the idea of collocation togenerate features at word and pattern level in ourmethod.
Existing protein/gene recognizers wereused to perform feature extraction as well.The rest of this paper is organized as follows.The methods used in this study are introduced inSection 2.
The experimental results are shown anddiscussed in Section 3.
Finally, Section 4concludes the remarks and lists some future works.2 MethodsMost of the works in the past on recognizingnamed entities in the biomedical domain focusedon identifying a single type of entities like proteinand/or gene names.
It is obviously morechallenging to annotate multiple types of namedentities simultaneously.
Intuitively, one candevelop a specific recognizer for each type ofnamed entities, run the recognizers one by one toannotate all types of named entities, and merge theresults.
The problem results from the boundarydecision and the annotation conflicts.
Instead ofconstructing five individual recognizers, weregarded the multiple -class annotation as aclassification problem, and tried to learn a80classifier capable of identifying all the five types ofnamed entities.Before classification, we have to decide the unitof classification.
Since it is difficult to correctlymark the boundary of a name to be identified, thesimplest way is to consider an individual word asan instance and assign a type to it.
After the typeassignment, continuous words of the same typewill be marked as a complete named entity of thattype.
The feature extraction process will bedescribed in the following subsections.2.1 Feature ExtractionThe first step in classification is to extractinformative and useful features to represent aninstance to be classified.
In our work, one word isrepresented by the attributes carried per se, theattributes contributed by two surrounding words,and other contextual information.
The details areas follows.2.1.1 Word AttributesThe word ?attribute?
is sometimes usedinterchangeably with ?feature?, but in this articlethey denote two different concepts.
Features arethose used to represent a classification instance,and the information enclosed in the features is notnecessarily contributed by the word itself.Attributes are defined to be the information thatcan be derived from the word alone in this paper.The attributes assigned to each word are whetherit is part of a gene/protein name, whether it is partof a species name, whether it is part of a tissuename, whether it is a stop word, whether it is anumber, whether it is punctuation, and the part ofspeech of this word.
Instead of using a lexicon forgene/protein name annotation, we employed twogene/protein name taggers, Yapex andGAPSCORE, to do this job.
As for part of speechtagging, Brill?s part of speech tagger was adopted.2.1.2 Context Information PreparationContextual information has been shown helpful inannotating gene/protein names, and therefore twostrategies for extracting contextual information atdifferent levels are used.
One is the usual practiceat a word level, and the other is at a pattern level.Since the training data released in the beginningdoes not define the abstract boundary, we have toassume that sentences are independent of eachother, and the contextual information extractionwas thus limited to be within a sentence.For contextual information extraction at wordlevel (Hou and Chen, 2003), collocates along with4 statistics including frequency, the average andstandard error of distance between word and entityand t-test score, were extracted.
The frequencyand t-test score were normalized to [0, 1].
Fivelists of collocates were obtained for cell-line, cell-type, DNA, RNA, and protein, respectively.As for contextual information extraction atpattern level, we first gathered a list of wordsconstituting a specific type of named entities.Then a hierarchical clustering with cutoff thresholdwas performed on the words.
Edit distance wasadopted as the measure of dissimilarity (see Figure1).
Afterwards, common substrings were obtainedto form the list of patterns.
With a list of patternsat hand, we estimated the pattern distribution, theoccurrence frequencies at and around the currentposition, given the type of word at the currentposition.
Figure 2 showed an example of theestimated distribution.
The average KL-Divergence between any two distributions wascomputed to discriminate the power of each pattern.The formula is as follows:1 1,1 ( || )( 1)n ni ji j j iD p pn n = = ?- ?
?
, where pi and pjare the distributions of a pattern given the word atposition 0 being type i and j, respectively.Figure 1: Example of common substring extractionFigure 2: Pattern distributions given the type ofword at position 02.2 Constructing Training DataFor each word in a sentence, the attributes of theword and the two adjacent words are put into thefeature vector.
Then, the left five and the right fivewords are searched for previously extractedcollocates.
The 15 variables thus added are shownbelow.55, 0( | )ii iFreq w type=- ?
?55, 0_ ( | )ii it test score w type=- ?-?815, ,5, 0??
( | , )i iw type w typei if i m s=- ??
, where f is the pdf ofnormal distribution, type is one of the five types, widenotes the surrounding words,,?itypewm and,?itypews arethe maximum likelihood estimates of mean andstandard deviation for wi given the type.
Next, theleft three and right three words along with thecurrent word are searched for patterns, adding 6variables to the feature vector.33Prob ( | )wipi p Pi type=- ??
?
, where type is one of thesix types including ?O?,iwP is the set of patternsmatching wi, Prob p  denotes the pmf for pattern p.Finally, the type of the previous word is added tothe feature vector, mimicking the concept of astochastic model.2.3 ClassificationSupport Vector Machines classification with radialbasis kernel was adopted in this task, and thepackage LIBSVM ?
A Library for Support VectorMachines (Hsu et al, 2003) was used for trainingand prediction.
The penalty coefficient C inoptimization and gamma in kernel function weretuned using a script provided in this package.The constructed training data contains 492,551instances, which is too large for training.
Also, thetraining data is extremely unbalanced (see Table 1)and this is a known problem in SVMsclassification.
Therefore, we performed stratifiedsampling to form a smaller and balanced data setfor training.Type # of instances (words)cell-type 15,466DNA 25,307cell-line 11,217RNA 2,481protein 55,117O 382,963Table 1: Number of instances for each type3 Results and DiscussionSince there is a huge amount of training instancesand we do not have enough time to tune theparameters and train a model with all the traininginstances available, we first randomly selected onetenth and one fourth of the complete training data.The results, as we expected, showed that modeltrained with more instances performed better (seeTable 2).
However, we noticed that theperformances vary among the 6 types and one ofthe possible causes is the imbalance of trainingdata among classes (see Table 1).
Therefore wedecided to balance the training data.First, the training data was constructed tocomprise equal number of instances from eachclass.
However, it didn?t perform well and lots oftype ?O?
words were misclassified, indicating thatusing only less than 1% of type ?O?
traininginstances is not sufficient to train a good model.Thus two more models were trained to see if theperformance can be enhanced.
One model hasslightly more type ?O?
instances than the equallybalanced one, and the other model has the ratioamong classes being 4:8:4:1:8:16.
The resultsshowed increase in recall but drop in precision.Kazama et al (2002) addressed the dataimbalance problem and sped up the trainingprocess by splitting the type ?O?
instances into sub-classes using part-of-speech information.
However,we missed their work while we were doing thistask, and hence didn?t have the chance to use andextend this idea.After carefully examining the classificationresults, we found that many of the ?DNA?instances were classified as ?protein?
and many ofthe ?protein?
instances were classified as ?DNA?.For example, 904 out of 2,845 ?DNA?
instanceswere categorized as ?protein?
under ?model 1/4?.The reason may be that Yapex and GAPSCORE donot distinguish gene name from protein names.Even humans don?t do very well at this(Krauthammer et al, 2002).We originally planned to verify the contributionof each type of features.
For example, how muchnoise was introduced by using existing taggersinstead of lexicons.
This would have helped gainmore insights into the proposed features.4 Conclusion and Future workThis paper presented the preliminary results of ourstudy.
We introduced the use of existing taggersand presented a way to collect common substringsshared by entities.
Due to lack of time, the modelswere not well tuned against the two parameters ?
Cand gamma, influencing the capabilities of themodels.
Further, not all of the training instancesprovided were used to train the model, and it willbe interesting and worthwhile to investigate.
Howto deal with data imbalance is another importantissue.
By solving this problem, further evaluationof feature effectiveness would be facilitated.
Webelieve there is much left for our approach toimprove and it may perform better if more time isgiven.82ReferencesE.
Brill.
1994.
Some Advances in Transformation-Based Part of Speech Tagging.
Proceedings ofthe National Conference on ArtificialIntelligence.
AAAI Press; 722-727.C.
Burges.
1998.
A Tutorial on Support VectorMachines for Pattern Recognition.
Data Miningand Knowledge Discovery, 2: 121-167.J.T.
Chang, H. Schutze and R.B.
Altman.
2004.GAPSCORE: Finding Gene and Protein NamesOne Word at a Time.
Bioinformatics, 20(2): 216-225.N.
Collier, C. Nobata and J.I.
Tsujii.
2000.Extracting the Names of Genes and GeneProducts with a Hidden Markov Model.Proceedings of 18 th International Conference onComputational Linguistics, 201-207.K.
Fukuda, T. Tsunoda, A. Tamura and T. Takagi.1998.
Toward Information Extraction:Identifying Protein Names from BiologicalPapers.
Proceedings of Pacific Symposium onBiocomputing, 707-718.W.J.
Hou and H.H.
Chen 2002.
ExtractingBiological Keywords from Scientific Text.Proceedings of 13 th International Conference onGenome Informatics; 571-573.W.J.
Hou and H.H.
Chen.
2003.
EnhancingPerformance of Protein Name RecognizersUsing Collocation.
Proceedings of the ACL 2003Workshop on NLP in Biomedicine, 25-32.C.W.
Hsu, C.C Chang and C.J.
Lin.
2003.
APractical Guide to Support Vector Classification.http://www.csie.ntu.edu.tw/~cjlin/libsvm/index.html.J.
Kazama, T. Makino, Y. Ohta and J. Tsujii.
2002.Tuning Support Vector Machines for BiomedicalNamed Entity Recognition.
Proceedings of theACL 2002 workshop on NLP in the BiomedicalDomain , 1-8.M.
Krauthammer, P. Kra, I. Iossifov, S.M.
Gomez,G.
Hripcsak, V. Hatzivassiloglou, C. Friedmanand A. Rzhetsky.
2002.
Of truth and pathways:chasing bits of information through myriads ofarticles.
Bioinformatics, 18(sup.1):S249-S257.K.J.
Lee, Y.S.
Hwang and H.C. Rim.
2003.
Two-Phase Biomedical NE Recognition based onSVMs.
Proceedings of the ACL 2003 Workshopon NLP in Biomedicine, 33-40.C.D.
Manning and H. Schutze.
1999.
Foundationsof Statistical Natural Language Processing.
MITPress.F.
Olsson, G. Eriksson, K. Franzen, L. Asker and P.Liden.
2002.
Notions of Correctness whenEvaluating Protein Name Taggers.
Proceedingsof the 19th International Conference onComputational Linguistics, 765-771.A.
Ratnaparkrhi.
1998.
Maximum Entropy Modelsfor Natural Language Ambiguity Resolution.PhD Thesis, University of Pennsylvania.K.
Takeuchi and N. Collier.
2003.
Bio-MedicalEntity Extraction using Support VectorMachines.
Proceedings of the ACL 2003workshop on NLP in Biomedicine, 57-64.L.
Tanabe and W.J.
Wilbur.
2002.
Tagging Geneand Protein Names in Biomedical Text.Bioimformatics, 18(8) : 1124-1132.Y.
Tsuruoka and J. Tsujii.
2003.
BoostingPrecision and Recall of Dictionary-based ProteinName Recognition.
Proceedings of the ACL2003 Workshop on NLP in Biomedicine, 41-48.K.
Yamamoto, T. Kudo, A. Konagaya and Y.Matsumoto.
2003.
Protein Name Tagging forBiomedical Annotation in Text.
Proceedings ofthe ACL 2003 workshop on NLP in Biomedicine,65-72.Model 1/10 Model 1/4Recall Prec.
F-score Recall Prec.
F-score Recall Prec.
F-scoreFull (Object) 0.4756 0.4399 0.4571 0.5080 0.4759 0.4914Full (protein) 0.5846 0.4392 0.5016 0.6213 0.4614 0.5296Full (cell-line) 0.2420 0.2909 0.2642 0.2820 0.3341 0.3059Full (DNA) 0.2784 0.3249 0.2998 0.2888 0.4479 0.3512Full (cell-type) 0.3863 0.5752 0.4622 0.4196 0.6115 0.4977Full (RNA) 0.0085 0.1000 0.0156 0.0000 0.0000 0.0000Model balanced equally Model slightly more ?O?
Model 4:8:4:1:8:16Full (Object) 0.1480 0.0990 0.1186 0.1512 0.1002 0.1206 0.5036 0.3936 0.4419Full (protein) 0.1451 0.1533 0.1491 0.1458 0.1527 0.1492 0.5629 0.4280 0.4863Full (cell-line) 0.1580 0.0651 0.0922 0.2280 0.0319 0.0560 0.4060 0.2261 0.2904Full (DNA) 0.1326 0.0466 0.0690 0.1591 0.0582 0.0852 0.3759 0.2457 0.2972Full (cell-type) 0.1650 0.1375 0.1500 0.1494 0.1908 0.1676 0.4701 0.4900 0.4798Full (RNA) 0.0932 0.0067 0.0126 0.0169 0.0075 0.0104 0.0593 0.1148 0.0782Table 2: Performance of each model (only FULL is shown)83
