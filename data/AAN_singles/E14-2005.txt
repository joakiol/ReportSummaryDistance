Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 17?20,Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational LinguisticsRDRPOSTagger: A Ripple Down Rules-based Part-Of-Speech TaggerDat Quoc Nguyen1and Dai Quoc Nguyen1and Dang Duc Pham2and Son Bao Pham11Faculty of Information TechnologyUniversity of Engineering and TechnologyVietnam National University, Hanoi{datnq, dainq, sonpb}@vnu.edu.vn2L3S Research Center, Germanypham@L3S.deAbstractThis paper describes our robust, easy-to-use and language independent toolkitnamely RDRPOSTagger which employsan error-driven approach to automaticallyconstruct a Single Classification RippleDown Rules tree of transformation rulesfor POS tagging task.
During the demon-stration session, we will run the tagger ondata sets in 15 different languages.1 IntroductionAs one of the most important tasks in NaturalLanguage Processing, Part-of-speech (POS) tag-ging is to assign a tag representing its lexicalcategory to each word in a text.
Recently, POStaggers employing machine learning techniquesare still mainstream toolkits obtaining state-of-the-art performances1.
However, most of them aretime-consuming in learning process and require apowerful computer for possibly training machinelearning models.Turning to rule-based approaches, the mostwell-known method is proposed by Brill (1995).He proposed an approach to automatically learntransformation rules for the POS tagging problem.In the Brill?s tagger, a new selected rule is learnedon a context that is generated by all previous rules,where a following rule will modify the outputs ofall the preceding rules.
Hence, this procedure re-turns a difficulty to control the interactions amonga large number of rules.Our RDRPOSTagger is presented to overcomethe problems mentioned above.
The RDRPOSTag-ger exploits a failure-driven approach to auto-matically restructure transformation rules in theform of a Single Classification Ripple Down Rules(SCRDR) tree (Richards, 2009).
It accepts inter-actions between rules, but a rule only changes the1http://aclweb.org/aclwiki/index.php?title=POS_Tagging_(State_of_the_art)outputs of some previous rules in a controlled con-text.
All rules are structured in a SCRDR treewhich allows a new exception rule to be addedwhen the tree returns an incorrect classification.A specific description of our new RDRPOSTaggerapproach is detailed in (Nguyen et al., 2011).Packaged in a 0.6MB zip file, implementationsin Python and Java can be found at the tagger?swebsite http://rdrpostagger.sourceforge.net/.
Thefollowing items exhibit properties of the tagger:?
The RDRPOSTagger is easy to configure andtrain.
There are only two threshold parameters uti-lized to learn the rule-based model.
Besides, thetagger is very simple to use with standard inputand output, having clear usage and instructionsavailable on its website.?
The RDRPOSTagger is language independent.This POS tagging toolkit has been successfullyapplied to English and Vietnamese.
To train thetoolkit for other languages, users just provide alexicon of words and the most frequent associatedtags.
Moreover, it can be easily combined with ex-isting POS taggers to reach an even better result.?
The RDRPOSTagger obtains very competitiveaccuracies.
On Penn WSJ Treebank corpus (Mar-cus et al., 1993), taking WSJ sections 0-18 as thetraining set, the tagger achieves a competitive per-formance compared to other state-of-the-art En-glish POS taggers on the test set of WSJ sections22-24.
For Vietnamese, it outperforms all previ-ous machine learning-based POS tagging systemsto obtain an up-to-date highest result on the Viet-namese Treebank corpus (Nguyen et al., 2009).?
The RDRPOSTagger is fast.
For instance inEnglish, the time2taken to train the tagger onthe WSJ sections 0-18 is 40 minutes.
The taggingspeed on the test set of the WSJ sections 22-24 is2800 words/second accounted for the latest imple-mentation in Python whilst it is 92k words/second2Training and tagging times are computed on a Windows-7 OS computer of Core 2Duo 2.4GHz & 3GB of memory.17Figure 1: A part of our SCRDR tree for English POS tagging.for the implementation in Java.2 SCRDR methodologyA SCRDR tree (Richards, 2009) is a binary treewith two distinct types of edges.
These edges aretypically called except and if-not edges.
Associ-ated with each node in a tree is a rule.
A rule hasthe form: if ?
then ?
where ?
is called the condi-tion and ?
is referred to as the conclusion.Cases in SCRDR are evaluated by passing acase to the root of the tree.
At any node in thetree, if the condition of a node N ?s rule is satis-fied by the case, the case is passed on to the ex-ception child ofN using the except link if it exists.Otherwise, the case is passed on to the N ?s if-notchild.
The conclusion given by this process is theconclusion from the last node in the SCRDR treewhich fired (satisfied by the case).
To ensure thata conclusion is always given, the root node typi-cally contains a trivial condition which is alwayssatisfied.
This node is called the default node.A new node containing a new rule (i.e.
a new ex-ception rule) is added to an SCRDR tree when theevaluation process returns the wrong conclusion.The new node is attached to the last node in theevaluation path of the given case with the exceptlink if the last node is the fired one.
Otherwise, itis attached with the if-not link.For example with the SCRDR tree in the fig-ure 1, given a case ?as/IN investors/NNS an-ticipate/VB a/DT recovery/NN?
where ?antici-pate/VB?
is the current word and tag pair, the casesatisfies the conditions of the rules at nodes (0),(1) and (3), it then is passed to the node (6) (utiliz-ing except links).
As the case does not satisfy thecondition of the rule at node (6), it will be trans-ferred to node (7) using if-not link.
Since the casedoes not fulfill the conditions of the rules at nodes(7) and (8), we have the evaluation path (0)-(1)-(3)-(6)-(7)-(8) with fired node (3).
Therefore, thetag for ?anticipate?
is concluded as ?VBP?.Rule (1) - the rule at node (1) - is the exceptionrule3of the default rule (0).
As node (2) is the if-not child node of the node (1), the associated rule(2) is also an exception rule of the rule (0).
Simi-larly, both rules (3) and (4) are exception rules ofthe rule (1) whereas all rules (6), (7) and (8) areexception rules of the rule (3), and so on.
Thus,the exception structure of the SCRDR tree extendsto 4 levels: rules (1) and (2) at layer 1, rules (3),(4) and (5) at layer 2, rules (6), (7) and (8) at layer3, and rule (9) at layer 4.3 The RDRPOSTagger toolkitThe toolkit consists of four main compo-nents: Utility, Initial-tagger, SCRDR-learner andSCRDR-tagger.3.1 The UtilityThe major functions of this component are to eval-uate tagging performances (displaying accuracyresults), and to create a lexicon of words and themost frequent associated tags as well as to extractRaw corpus from an input golden training corpus.3.2 The Initial-taggerThe initial-tagger developed in the RDRPOSTag-ger toolkit is based on the lexicon which is gen-erated in the use of the Utility component to as-sign a tag for each word.
To deal with unknownwords, the initial-tagger utilizes several regular ex-pressions or heuristics for English and Vietnamesewhereas the most frequent tag in the training cor-pus is exploited to label unknown-words whenadapting to other languages.3.3 The SCRDR-learnerThe SCRDR-learner component uses a failure-driven method to automatically build a SCRDRtree of transformation rules.
Figure 3 describes thelearning process of the learner.3The default rule is the unique rule which is not an excep-tion rule of any other rule.
Every rule in layer n is an excep-tion rule of a rule in layer n?
1.18#12: if next1stTag == ?object.next1stTag?
then tag = ?correctTag?#14: if prev1stTag == ?object.prev1stTag?
then tag = ?correctTag?#18: if word == ?object.word?
&& next1stTag == ?object.next1stTag?
then tag = ?correctTag?Figure 2: Rule template examples.Figure 3: The diagram of the learning process of the learner.The Initialized corpus is returned by perform-ing the Initial-tagger on the Raw corpus.
By com-paring the initialized one with the Golden corpus,an Object-driven dictionary of pairs (Object, cor-rectTag) is produced in which Object captures the5-word window context covering the current wordand its tag in following format (previous 2ndword/ previous 2ndtag, previous 1stword / previous1sttag, word / currentTag, next 1stword / next 1sttag, next 2ndword / next 2ndtag) from the initial-ized corpus, and the correctTag is the correspond-ing tag of the current word in the golden corpus.There are 27 Rule templates applied for Rule se-lector which is to select the most suitable rulesto build the SCRDR tree.
Examples of the ruletemplates are shown in figure 2 where elementsin bold will be replaced by concrete values fromObjects in the object-driven dictionary to createconcrete rules.
The SCRDR tree of rules is initial-ized by building the default rule and all exceptionrules of the default one in form of if currentTag =?TAG?
then tag = ?TAG?
at the layer-1 exceptionstructure, for example rules (1) and (2) in the fig-ure 1, and the like.
The learning approach to con-struct new exception rules to the tree is as follows:?
At a node-F in the SCRDR tree, let SO bethe set of Objects from the object-driven dictio-nary, which those Objects are fired at the node-Fbut their initialized tags are incorrect (the current-Tag is not the correctTag associated).
It means thatnode-F gives wrong conclusions to all Objects inthe SO set.?
In order to select a new exception rule of therule at node-F from all concrete rules which aregenerated for all Objects in the SO set, the se-lected rule have to satisfy constraints: (i) The rulemust be unsatisfied by cases for which node-F hasalready given correct conclusions.
This constraintdoes not apply to node-F at layer-1 exception struc-ture.
(ii) The rule must associate to a highest scorevalue of subtracting B from A in comparison toother ones, where A and B are the numbers of theSO?s Objects which are correctly and incorrectlyconcluded by the rule respectively.
(iii) And thehighest value is not smaller than a given threshold.The SCRDR-learner applies two threshold pa-rameters: first threshold is to choose exceptionrules at the layer-2 exception structure (e.g rules(3), (4) and (5) in figure 1), and second thresholdis to select rules for higher exception layers.?
The process to add new exception rules is re-peated until there is no rule satisfying the con-straints above.
At each iteration, a new rule isadded to the current SCRDR tree to correct errorconclusions made by the tree.3.4 The SCRDR-taggerThe SCRDR-tagger component is to perform thePOS tagging on a raw text corpus where each lineis a sequence of words separated by white spacecharacters.
The component labels the text corpusby using the Initial-tagger.
It slides due to a left-to-right direction on a 5-word window context togenerate a corresponding Object for each initiallytagged word.
The Object is then classified by thelearned SCRDR tree model to produce final con-clusion tag of the word as illustrated in the exam-ple in the section 2.4 EvaluationThe RDRPOSTagger has already been success-fully applied to English and Vietnamese corpora.4.1 Results for EnglishExperiments for English employed the Penn WSJTreebank corpus to exploit the WSJ sections 0-18(38219 sentences) for training, the WSJ sections19-21 (5527 sentences) for validation and the WSJsections 22-24 (5462 sentences) for test.Using a lexicon created in the use of the train-19ing set, the Initial-tagger obtains an accuracy of93.51% on the test set.
By varying the thresholdson the validation set, we have found the most suit-able values4of 3 and 2 to be used for evaluatingthe RDRPOSTagger on the test set.
Those thresh-olds return a SCRDR tree model of 2319 rulesin a 4-level exception structure.
The training timeand tagging speed for those thresholds are men-tioned in the introduction section.
On the same testset, the RDRPOSTagger achieves a performance at96.49% against 96.46% accounted for the state-of-the-art POS tagger TnT (Brants, 2000).For another experiment, only in training pro-cess: 1-time occurrence words in training set areinitially tagged as out-of-dictionary words.
Witha learned tree model of 2418 rules, the taggerreaches an accuracy of 96.51% on the test set.Retraining the tagger utilizing another initialtagger5developed in the Brill?s tagger (Brill,1995) instead of the lexicon-based initial one,the RDRPOSTagger gains an accuracy result of96.57% which is slightly higher than the perfor-mance at 96.53% of the Brill?s.4.2 Results for VietnameseIn the first Evaluation Campaign6on VietnameseLanguage Processing, the POS tagging track pro-vided a golden training corpus of 28k sentences(631k words) collected from two sources of thenational VLSP project and the Vietnam Lexicog-raphy Center, and a raw test corpus of 2100 sen-tences (66k words).
The training process returneda SCRDR tree of 2896 rules7.
Obtaining a highestperformance on the test set, the RDRPOSTaggersurpassed all other participating systems.We also carry out POS tagging experiments onthe golden corpus of 28k sentences and on theVietnamese Treebank of 10k sentences (Nguyenet al., 2009) according to 5-fold cross-validationscheme8.
The average accuracy results are pre-sented in the table 1.
Achieving an accuracy of92.59% on the Vietnamese Treebank, the RDR-4The thresholds 3 and 2 are reused for all other experi-ments in English and Vietnamese.5The initial tagger gets a result of 93.58% on the test set.6http://uet.vnu.edu.vn/rivf2013/campaign.html7It took 100 minutes to construct the tree leading to tag-ging speeds of 1100 words/second and 45k words/second forthe implementations in Python and Java, respectively, on thecomputer of Core 2Duo 2.4GHz & 3GB of memory.8In each cross-validation run, one fold is selected as testset, 4 remaining folds are merged as training set.
The initialtagger exploits a lexicon generated from the training set.
Intraining process, 1-time occurrence words are initially labeledas out-of-lexicon words.Table 1: Accuracy results for VietnameseCorpus Initial-tagger RDRPOSTagger28k 91.18% 93.42%10k 90.59% 92.59%POSTagger outperforms previous Maximum En-tropy Model, Conditional Random Field and Sup-port Vector Machine-based POS tagging systems(Tran et al., 2009) on the same evaluation scheme.5 Demonstration and ConclusionIn addition to English and Vietnamese, in thedemonstration session, we will present promisingexperimental results and run the RDRPOSTaggerfor other languages including Bulgarian, Czech,Danish, Dutch, French, German, Hindi, Italian,Lao, Portuguese, Spanish, Swedish and Thai.
Wewill also let the audiences to contribute their owndata sets for retraining and testing the tagger.In this paper, we describe the rule-basedPOS tagging toolkit RDRPOSTagger to auto-matically construct transformation rules in formof the SCRDR exception structure.
We be-lieve that our robust, easy-to-use and language-independent toolkit RDRPOSTagger can be usefulfor NLP/CL-related tasks.ReferencesThorsten Brants.
2000.
TnT: a statistical part-of-speech tagger.
In Proc.
of 6th Applied Natural Lan-guage Processing Conference, pages 224?231.Eric Brill.
1995.
Transformation-based error-drivenlearning and natural language processing: a casestudy in part-of-speech tagging.
Comput.
Linguist.,21(4):543?565.Mitchell P Marcus, Mary Ann Marcinkiewicz, andBeatrice Santorini.
1993.
Building a large anno-tated corpus of English: the penn treebank.
Comput.Linguist., 19(2):313?330.Phuong Thai Nguyen, Xuan Luong Vu, ThiMinh Huyen Nguyen, Van Hiep Nguyen, andHong Phuong Le.
2009.
Building a LargeSyntactically-Annotated Corpus of Vietnamese.
InProc.
of LAW III workshop, pages 182?185.Dat Quoc Nguyen, Dai Quoc Nguyen, Son Bao Pham,and Dang Duc Pham.
2011.
Ripple Down Rules forPart-of-Speech Tagging.
In Proc.
of 12th CICLing -Volume Part I, pages 190?201.Debbie Richards.
2009.
Two decades of ripple downrules research.
Knowledge Engineering Review,24(2):159?184.Oanh Thi Tran, Cuong Anh Le, Thuy Quang Ha, andQuynh Hoang Le.
2009.
An experimental studyon vietnamese pos tagging.
Proc.
of the 2009 Inter-national Conference on Asian Language Processing,pages 23?27.20
