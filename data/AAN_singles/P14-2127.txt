Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 785?790,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsHierarchical MT Training using Max-Violation PerceptronKai Zhao?Liang Huang?
?Graduate Center & Queens CollegeCity University of New York{kzhao@gc,huang@cs.qc}.cuny.eduHaitao Mi?Abe Ittycheriah??T.
J. Watson Research CenterIBM{hmi,abei}@us.ibm.comAbstractLarge-scale discriminative training has be-come promising for statistical machinetranslation by leveraging the huge train-ing corpus; for example the recent effortin phrase-based MT (Yu et al, 2013) sig-nificantly outperforms mainstream meth-ods that only train on small tuning sets.However, phrase-based MT suffers fromlimited reorderings, and thus its trainingcan only utilize a small portion of the bi-text due to the distortion limit.
To addressthis problem, we extend Yu et al (2013)to syntax-based MT by generalizing theirlatent variable ?violation-fixing?
percep-tron from graphs to hypergraphs.
Exper-iments confirm that our method leads toup to +1.2 BLEU improvement over main-stream methods such as MERT and PRO.1 IntroductionMany natural language processing problems in-cluding part-of-speech tagging (Collins, 2002),parsing (McDonald et al, 2005), and event extrac-tion (Li et al, 2013) have enjoyed great success us-ing large-scale discriminative training algorithms.However, a similar success on machine translationhas been elusive, where the mainstream methodsstill tune on small datasets.What makes large-scale MT training so hardthen?
After numerous attempts by various re-searchers (Liang et al, 2006; Watanabe et al,2007; Arun and Koehn, 2007; Blunsom et al,2008; Chiang et al, 2008; Flanigan et al, 2013;Green et al, 2013), the recent work of Yu et al(2013) finally reveals a major reason: it is the vastamount of (inevitable) search errors in MT decod-ing that astray learning.
To alleviate this prob-lem, their work adopts the theoretically-motivatedframework of violation-fixing perceptron (Huanget al, 2012) tailed for inexact search, yieldinggreat results on phrase-based MT (outperformingCollins (02)inexact?
?searchHuang et al (12)latent?
?variableYu et al (13)?
hypergraph ?Zhang et al (13) ?
?variablethis workFigure 1: Relationship with previous work.small-scale MERT/PRO by a large margin for thefirst time).
However, the underlying phrase-basedmodel suffers from limited distortion and thus canonly employ a small portion (about 1/3 in their Ch-En experiments) of the bitext in training.To better utilize the large training set, wepropose to generalize from phrase-based MT tosyntax-based MT, in particular the hierarchicalphrase-based translation model (HIERO) (Chiang,2005), in order to exploit sentence pairs beyondthe expressive capacity of phrase-based MT.The key challenge here is to extend the latentvariable violation-fixing perceptron of Yu et al(2013) to handle tree-structured derivations andtranslation hypergraphs.
Luckily, Zhang et al(2013) have recently generalized the underlyingviolation-fixing perceptron of Huang et al (2012)from graphs to hypergraphs for bottom-up parsing,which resembles syntax-based decoding.
We justneed to further extend it to handle latent variables.We make the following contributions:1.
We generalize the latent variable violation-fixing perceptron framework to inexactsearch over hypergraphs, which subsumesprevious algorithms for PBMT and bottom-up parsing as special cases (see Fig.
1).2.
We show that syntax-based MT, with its bet-ter handling of long-distance reordering, canexploit a larger portion of the training set,which facilitates sparse lexicalized features.3.
Experiments show that our training algo-rithm outperforms mainstream tuning meth-ods (which optimize on small devsets) by+1.2 BLEU over MERT and PRO on FBIS.785id ruler0S?
?X1,X1?r1S?
?S1X2,S1X2?r2X?
?B`ush??,Bush?r3X?
?Sh?al?ong,Sharon?r4X?
?hu`?t?an, talks?r5X?
?y?u X1j?ux?
?ng X2,held X2with X1?r6X?
?y?u Sh?al?ong, with Sharon?r7X?
?X1j?ux?
?ng X2,X1held X2?S[0:5]X[1:5]X[4:5]hu`?t?an5j?ux??ng4X[2:3]Sh?al?ong3|y?u2S[0:1]X[0:1]0B`ush??1SXXSharon5with4Xtalks3held2SX0Bush1S[0:5]X[1:5]X[4:5]hu`?t?an5j?ux??ng4X[1:3]Sh?al?ong3y?u2S[0:1]X[0:1]0B`ush?
?1SXXtalks5held4XSharon3with2SX0Bush1(a) HIERO rules (b) gold derivation (c) Viterbi derivationFigure 2: An example of HIERO translation.X[0:1] X[2:3] X[4:5]X[1:5]X[1:3]S[0:1]S[0:5]Figure 3: A ?LM hypergraph with two deriva-tions: the gold derivation (Fig.
2b) in solid lines,and the Viterbi derivation (Fig.
2c) in dashed lines.2 Review: Syntax-based MT DecodingFor clarity reasons we will describe HIERO decod-ing as a two-pass process, first without a languagemodel, and then integrating the LM.
This sectionmostly follows Huang and Chiang (2007).In the first, ?LM phase, the decoder parses thesource sentence using the source projection of thesynchronous grammar (see Fig.
2 (a) for an ex-ample), producing a?LM hypergraph where eachnode has a signature N[i:j], where N is the nonter-minal type (either X or S in HIERO) and [i : j] isthe span, and each hyperedge e is an applicationof the translation rule r(e) (see Figure 3).To incorporate the language model, each nodealso needs to remember its target side boundarywords.
Thus a ?LM node N[i:j]is split into mul-tiple +LM nodes of signature Na?b[i:j], where a andb are the boundary words.
For example, with a bi-gram LM, Xheld?Sharon[1:5]is a node whose translationstarts with ?held?
and ends with ?Sharon?.More formally, the whole decoding process canbe cast as a deductive system.
Take the partialtranslation of ?held talks with Sharon?
in Figure 2(b) for example, the deduction isXSharon?Sharon[2:3]: s1Xtalks?talks[4:5]: s2Xheld?Sharon[1:5]: s1+ s2+ s(r5) + ?r5,where s(r5) is the score of rule r5, and the LMcombo score ?
is log Plm(talks | held)Plm(with |talks)Plm(Sharon | with).3 Violation-Fixing Perceptron for HIEROAs mentioned in Section 1, the key to the successof Yu et al (2013) is the adoption of violation-fixing perceptron of Huang et al (2012) whichis tailored for vastly inexact search.
The generalidea is to update somewhere in the middle of thesearch (where search error happens) rather than atthe very end (standard update is often invalid).
Toadapt it to MT where many derivations can outputthe same translation (i.e., spurious ambiguity), Yuet al (2013) extends it to handle latent variableswhich correspond to phrase-based derivations.
Onthe other hand, Zhang et al (2013) has generalizedHuang et al (2012) from graphs to hypergraphsfor bottom-up parsing, which resembles HIEROdecoding.
So we just need to combine the twogeneralizing directions (latent variable and hyper-graph, see Fig.
1).3.1 Latent Variable Hypergraph SearchThe key difference between bottom-up parsingand MT decoding is that in parsing the gold treefor each input sentence is unique, while in MTmany derivations can generate the same referencetranslation.
In other words, the gold derivation toupdate towards is a latent variable.786Here we formally define the latent variable?max-violation?
perceptron over a hypergraph forMT training.
For a given sentence pair ?x, y?, wedenote H(x) as the decoding hypergraph of HI-ERO without any pruning.
We say D ?
H(x) ifD is a full derivation of decoding x, and D can bederived from the hypergraph.
Let good(x, y) bethe set of y-good derivations for ?x, y?
:good(x, y)?= {D ?
H(x) | e(D) = y},where e(D) is the translation from derivation D.We then define the set of y-good partial derivationsthat cover x[i:j]with root N[i:j]asgoodN[i:j](x, y)?= {d ?
D | D ?
good(x, y),root(d) = N[i:j]}We further denote the real decoding hypergraphwith beam-pruning and cube-pruning as H?
(x).The set of y-bad derivations is defined asbadN[i:j](x, y)?= {d ?
D | D ?
H?
(x, y),root(d) = N[i:j], d 6?
goodN[i:j](x, y)}.Note that the y-good derivations are defined overthe unpruned whole decoding hypergraph, whilethe y-bad derivations are defined over the real de-coding hypergraph with pruning.The max-violation method performs the updatewhere the model score difference between theincorrect Viterbi partial derivation and the besty-good partial derivation is maximal, by penaliz-ing the incorrect Viterbi partial derivation and re-warding the y-good partial derivation.More formally, we first find the Viterbi partialderivation d?and the best y-good partial deriva-tion d+for each N[i:j]group in the pruned +LMhypergraph:d+N[i:j](x, y)?= argmaxd?goodN[i:j](x,y)w ??
(x, d),d?N[i:j](x, y)?= argmaxd?badN[i:j](x,y)w ??
(x, d),where ?
(x, d) is the feature vector for derivationd.
Then it finds the group N?[i?:j?
]with the max-imal score difference between the Viterbi deriva-tion and the best y-good derivation:N?[i?:j?
]?= argmaxN[i:j]w ???
(x, d+N[i:j](x, y), d?N[i:j](x, y)),and update as follows:w?
w + ??
(x, d+N?[i?:j?
](x, y), d?N?[i?:j?
](x, y)),where ??
(x, d, d?
)?= ?
(x, d)??
(x, d?
).3.2 Forced Decoding for HIEROWe now describe how to find the gold derivations.1Such derivations can be generated in way similarto Yu et al (2013) by using a language model tai-lored for forced decoding:Pforced(q | p) ={1 if q = p+ 10 otherwise,where p and q are the indices of the boundarywords in the reference translation.
The +LM nodenow has signature Np?q[i:j], where p and q are the in-dexes of the boundary words.
If a boundary worddoes not occur in the reference, its index is set to?
so that its language model score will always be??
; if a boundary word occurs more than once inthe reference, its ?LM node is split into multiple+LM nodes, one for each such index.2We have a similar deductive system for forceddecoding.
For the previous example, rule r5inFigure 2 (a) is rewritten asX?
?y?u X1j?ux?
?ng X2, 1 X24 X1?,where 1 and 4 are the indexes for reference words?held?
and ?with?
respectively.
The deduction forX[1:5]in Figure 2 (b) isX5?5[2:3]: s1X2?3[4:5]: s2X1?5[1:5]: s(r5) + ?+ s1+ s2r5,where ?
= log?i?
{1,3,4}Pforced(i+ 1 | i) = 0.4 ExperimentsFollowing Yu et al (2013), we call our max-violation method MAXFORCE.
Our implemen-tation is mostly in Python on top of the cdecsystem (Dyer et al, 2010) via the pycdec in-terface (Chahuneau et al, 2012).
In addition, weuse minibatch parallelization of (Zhao and Huang,1We only consider single reference in this paper.2Our formulation of index-based language model fixes abug in the word-based LM of Yu et al (2013) when a sub-string appears more than once in the reference (e.g.
?theman...the man...?
); thanks to Dan Gildea for pointing it out.7872013) to speedup perceptron training.
We evalu-ate MAXFORCE for HIERO over two CH-EN cor-pora, IWSLT09 and FBIS, and compare the per-formance with vanilla n-best MERT (Och, 2003)from Moses (Koehn et al, 2007), HypergraphMERT (Kumar et al, 2009), and PRO (Hopkinsand May, 2011) from cdec.4.1 Features DesignWe use all the 18 dense features from cdec, in-cluding language model, direct translation prob-ability p(e|f), lexical translation probabilitiespl(e|f) and pl(f |e), length penalty, counts for thesource and target sides in the training corpus, andflags for the glue rules and pass-through rules.For sparse features we use Word-Edges fea-tures (Charniak and Johnson, 2005; Huang, 2008)which are shown to be extremely effective inboth parsing and phrase-based MT (Yu et al,2013).
We find that even simple Word-Edgesfeatures boost the performance significantly, andadding complex Word-Edges features from Yu etal.
(2013) brings limited improvement and slowsdown the decoding.
So in the following experi-ments we only use Word-Edges features consistingof combinations of English and Chinese words,and Chinese characters, and do not use word clus-ters nor word types.
For simplicity and efficiencyreasons, we also exclude all non-local features.4.2 Datasets and PreprocessingOur first corpus, IWSLT09, contains ?30kshort sentences collected from spoken language.IWSLT04 is used as development set in MAX-FORCE training, and as tuning set for n-bestMERT, Hypergraph MERT, and PRO.
IWSLT05is used as test set.
Both IWSLT04 and IWSLT05contain 16 references.We mainly use this corpusto investigate the properties of MAXFORCE.The second corpus, FBIS, contains ?240k sen-tences.
NIST06 newswire is used as developmentset for MAXFORCE training, and as tuning setfor all other tuning methods.
NIST08 newswireis used as test set.
Both NIST06 newswireand NIST08 newswire contain 4 references.
Wemainly use this corpus to demonstrate the perfor-mance of MAXFORCE in large-scale training.For both corpora, we do standard tokeniza-tion, alignment and rule extraction using the cdectools.
In rule extraction, we remove all 1-countrules but keep the rules mapping from one Chi-nese word to one English word to help balancingsent.
wordsphrase-based MT 32% 12%HIERO 35% 30%HIERO (all rules) 65% 55%Table 1: Reachability comparison (on FBIS) be-tween phrase-based MT reported in Yu et al(2013) (without 1-count rules) and HIERO (withand without 1-count rules).00.20.40.60.8120  40  60  80  100forceddecodableratiosentence lengthloosetightFigure 4: Reachability vs. sent.
length on FBIS.See text below for ?loose?
and ?tight?.between overfitting and coverage.
We use a tri-gram language model trained from the target sidesof the two corpora respectively.4.3 Forced Decoding ReachabilityWe first report the forced decoding reachability forHIERO on FBIS in Table 1.
With the full rule set,65% sentences and 55% words of the whole cor-pus are forced decodable in HIERO.
After pruning1-count rules, our forced decoding covers signif-icantly more words than phrase-based MT in Yuet al (2013).
Furthermore, in phrase-based MT,most decodable sentences are very short, whilein HIERO the lengths of decodable sentences aremore evenly distributed.However, in the following experiments, due toefficiency considerations, we use the ?tight?
ruleextraction in cdec that is more strict than thestandard ?loose?
rule extraction, which generatesa reduced rule set and, thus, a reduced reachabil-ity.
We show the reachability distributions of bothtight and loose rule extraction in Figure 4.4.4 Evaluation on IWSLTFor IWSLT, we first compare the performancefrom various update methods in Figure 5.
Themax-violation method is more than 15 BLEU788303540452  4  6  8  10  12  14  16  18  20BLEUondeviterationMax-Violationlocal updateskipstandard updateFigure 5: Comparison of various update methods.4243444546472  4  6  8  10  12  14  16  18  20BLEUondeviterationsparse featuresdense featuresHypergraph MERTPROn-best MERTFigure 6: Sparse features (Word-Edges) contribute?2 BLEU points, outperforming PRO and MERT.points better than the standard perceptron (alsoknown as ?bold-update?
in Liang et al (2006))which updates at the root of the derivation tree.3,4This can be explained by the fact that in train-ing ?58% of the standard updates are invalid (i.e.,they do not fix any violation).
We also use the?skip?
strategy of Zhang et al (2013) which up-dates at the root of the derivation only when it fixesa search error, avoiding all invalid updates.
Thisachieves ?10 BLEU better than the standard up-date, but is still more than ?5 BLEU worse thanMax-Violation update.
Finally we also try the?local-update?
method from Liang et al (2006)which updates towards the derivation with the bestBleu+1in the root group S[0:|x|].
This method isabout 2 BLEU points worse than max-violation.We further investigate the contribution of sparsefeatures in Figure 6.
On the development set,max-violation update without Word-Edges fea-tures achieves BLEU similar to n-best MERT and3We find that while MAXFORCE generates translations oflength ratio close to 1 during training, the length ratios ondev/test sets are significantly lower, due to OOVs.
So werun a binary search for the length penalty weight after eachtraining iteration to tune the length ratio to ?0.97 on dev set.4We report BLEU with averaged reference lengths.algorithm # feats dev testn-best MERT 18 44.9 47.9Hypergraph MERT 18 46.6 50.7PRO 18 45.0 49.5local update perc.
443K 45.6 49.1MAXFORCE 529K 47.4 51.5Table 2: BLEU scores (with 16 references) of var-ious training algorithms on IWSLT09.algorithm # feats dev testHypergraph MERT 18 27.3 23.0PRO 18 26.4 22.7MAXFORCE 4.5M 27.7 23.9Table 3: BLEU scores (with 4 references) of vari-ous training algorithms on FBIS.PRO, but lower than Hypergraph MERT.
Addingsimple Word-Edges features improves BLEU by?2 points, outperforming the very strong Hyper-graph MERT baseline by?1 point.
See Table 2 fordetails.
The results of n-best MERT, HypergraphMERT, and PRO are averages from 3 runs.4.5 Evaluation on FBISTable 3 shows BLEU scores of Hypergraph MERT,PRO, and MAXFORCE on FBIS.
MAXFORCE ac-tives 4.5M features, and achieves +1.2 BLEU overPRO and +0.9 BLEU over Hypergraph MERT.
Thetraining time (on 32 cores) for Hypergraph MERTand PRO is about 30 min.
on the dev set, and isabout 5 hours for MAXFORCE on the training set.5 ConclusionsWe have presented a latent-variable violation-fixing framework for general structured predic-tion problems with inexact search over hyper-graphs.
Its application on HIERO brings signif-icant improvement in BLEU, compared to algo-rithms that are specially designed for MT tuningsuch as MERT and PRO.AcknowledgmentPart of this work was done during K.
Z.?s intern-ship at IBM.
We thank Martin?Cmejrek and LemaoLiu for discussions, David Chiang for pointingus to pycdec, Dan Gildea for Footnote 2, andthe anonymous reviewers for comments.
Thiswork is supported by DARPA FA8750-13-2-0041(DEFT), DARPA HR0011-12-C-0015 (BOLT),and a Google Faculty Research Award.789ReferencesAbhishek Arun and Philipp Koehn.
2007.
On-line learning methods for discriminative training ofphrase based statistical machine translation.
Proc.of MT Summit XI, 2(5):29.Phil Blunsom, Trevor Cohn, and Miles Osborne.
2008.A discriminative latent variable model for statisticalmachine translation.
In ACL, pages 200?208.Victor Chahuneau, Noah Smith, and Chris Dyer.
2012.pycdec: A python interface to cdec.
Prague Bulletinof Mathematical Linguistics, (98).Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminativereranking.
In Proceedings of ACL, pages 173?180,Ann Arbor, Michigan, June.David Chiang, Yuval Marton, and Philip Resnik.
2008.Online large-margin training of syntactic and struc-tural translation features.
In Proceedings of EMNLP2008.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of ACL.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: Theory and exper-iments with perceptron algorithms.
In Proceedingsof EMNLP.Chris Dyer, Adam Lopez, Juri Ganitkevitch, JohnathanWeese, Ferhan Ture, Phil Blunsom, Hendra Seti-awan, Vladimir Eidelman, and Philip Resnik.
2010.cdec: A decoder, alignment, and learning frameworkfor finite-state and context-free translation models.In Proceedings of the ACL.Jeffrey Flanigan, Chris Dyer, and Jaime Carbonell.2013.
Large-scale discriminative training for statis-tical machine translation using held-out line search.In Proceedings of NAACL 2013.Spence Green, Sida Wang, Daniel Cer, and Christo-pher D Manning.
2013.
Fast and adaptive onlinetraining of feature-rich translation models.
to ap-pear) ACL.Mark Hopkins and Jonathan May.
2011.
Tuning asranking.
In Proceedings of EMNLP.Liang Huang and David Chiang.
2007.
Forest rescor-ing: Fast decoding with integrated language models.In Proceedings of ACL, Prague, Czech Rep., June.Liang Huang, Suphan Fayong, and Yang Guo.
2012.Structured perceptron with inexact search.
In Pro-ceedings of NAACL.Liang Huang.
2008.
Forest reranking: Discriminativeparsing with non-local features.
In Proceedings ofthe ACL: HLT, Columbus, OH, June.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: open source toolkitfor statistical machine translation.
In Proceedingsof ACL.Shankar Kumar, Wolfgang Macherey, Chris Dyer, andFranz Och.
2009.
Efficient minimum error ratetraining and minimum bayes-risk decoding for trans-lation hypergraphs and lattices.
In Proceedings ofthe Joint Conference of ACL and AFNLP.Qi Li, Heng Ji, and Liang Huang.
2013.
Joint eventextraction via structured prediction with global fea-tures.
In Proceedings of ACL.Percy Liang, Alexandre Bouchard-C?ot?e, Dan Klein,and Ben Taskar.
2006.
An end-to-end discrimina-tive approach to machine translation.
In Proceed-ings of COLING-ACL, Sydney, Australia, July.Ryan McDonald, Koby Crammer, and FernandoPereira.
2005.
Online large-margin training of de-pendency parsers.
In Proceedings of the 43rd ACL.Franz Joseph Och.
2003.
Minimum error rate trainingin statistical machine translation.
In Proceedings ofACL, pages 160?167.Taro Watanabe, Jun Suzuki, Hajime Tsukada, andHideki Isozaki.
2007.
Online large-margin trainingfor statistical machine translation.
In Proceedings ofEMNLP-CoNLL.Heng Yu, Liang Huang, Haitao Mi, and Kai Zhao.2013.
Max-violation perceptron and forced decod-ing for scalable MT training.
In Proceedings ofEMNLP.Hao Zhang, Liang Huang, Kai Zhao, and Ryan Mc-Donald.
2013.
Online learning with inexact hyper-graph search.
In Proceedings of EMNLP.Kai Zhao and Liang Huang.
2013.
Minibatch and par-allelization for online large margin structured learn-ing.
In Proceedings of NAACL 2013.790
