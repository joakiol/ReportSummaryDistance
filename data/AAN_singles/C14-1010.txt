Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 89?98, Dublin, Ireland, August 23-29 2014.Group Non-negative Matrix Factorization with Natural Categories forQuestion Retrieval in Community Question Answer ArchivesGuangyou Zhou, Yubo Chen, Daojian Zeng, and Jun ZhaoNational Laboratory of Pattern RecognitionInstitute of Automation, Chinese Academy of Sciences95 Zhongguancun East Road, Beijing 100190, China{gyzhou,yubo.chen,djzeng,jzhao}@nlpr.ia.ac.cnAbstractCommunity question answering (CQA) has become an important service due to the popularity ofCQA archives on the web.
A distinctive feature is that CQA services usually organize questionsinto a hierarchy of natural categories.
In this paper, we focus on the problem of question re-trieval and propose a novel approach, called group non-negative matrix factorization with naturalcategories (GNMFNC).
This is achieved by learning the category-specific topics for each cate-gory as well as shared topics across all categories via a group non-negative matrix factorizationframework.
We derive an efficient algorithm for learning the factorization, analyze its complex-ity, and provide proof of convergence.
Experiments are carried out on a real world CQA data setfrom Yahoo!
Answers.
The results show that our proposed approach significantly outperformsvarious baseline methods and achieves the state-of-the-art performance for question retrieval.1 IntroductionCommunity question answering (CQA) such as Yahoo!
Answers1and Quora2, has become an importantservice due to the popularity of CQA archives on the web.
To make use of the large-scale questions andtheir answers, it is critical to have functionality of helping users to retrieve previous answers (Duan etal., 2008).
Typically, such functionality is achieved by first retrieving the historical questions that bestmatch a user?s queried question, and then using answers of these returned questions to answer the queriedquestion.
This is what we called question retrieval in this paper.The major challenge for question retrieval, as for most information retrieval tasks, is the lexical gapbetween the queried questions and the historical questions in the archives.
For example, if a queried ques-tion contains the word ?company?
but a relevant historical question instead contains the word ?firm?, thenthere is a mismatch and the historical question may not be easily distinguished from an irrelevant one.To solve the lexical gap problem, most researchers focused on translation-based approaches since therelationships between words (or phrases) can be explicitly modeled through word-to-word (or phrases)translation probabilities (Jeon et al., 2005; Riezler et al., 2007; Xue et al., 2008; Lee et al., 2008; Bern-hard and Gurevych, 2009; Zhou et al., 2011; Singh, 2012).
However, these existing methods model therelevance ranking without considering the category-specific and shared topics with natural categories, itis not clear whether this information is useful for question retrieval.A distinctive feature of question-answer pairs in CQA is that CQA services usually organize questionsinto a hierarchy of natural categories.
For example, Yahoo!
Answers contains a hierarchy of 26 categoriesat the first level and more than 1262 subcategories at the leaf level.
When a user asks a question, the useris typically required to choose a category label for the question from a predefined hierarchy.
Questions inthe predefined hierarchy usually share certain generic topics while questions in different categories havetheir specific topics.
For example, questions in categories ?Arts & Humanities?
and ?Beauty & Style?may share the generic topic of ?dance?
but they also have the category-specific topics of ?poem?
and?wearing?, respectively.This work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings footerare added by the organisers.
Licence details: http:// creativecommons.org/licenses/by/4.0/1http://answers.yahoo.com/2http://www.quora.com/89Inspired by the above observation, we propose a novel approach, called group non-negative matrixfactorization with natural categories (GNMFNC).
GNMFNC assumes that there exists a set of category-specific topics for each of the category, and there also exists a set of shared topics for all of the categories.Each question in CQA is specified by its category label, category-specific topics, as well as shared topics.In this way, the large-scale question retrieval problem can be decomposed into small-scale subproblems.In GNMFNC, questions in each category are represented as a term-question matrix.
The term-questionmatrix is then approximated as the product of two matrices: one matrix represents the category-specifictopics as well as the shared topics, and the other matrix denotes the question representation based ontopics.
An objective function is defined to measure the goodness of prediction of the data with themodel.
Optimization of the objective function leads to the automatic discovery of topics as well asthe topic representation of questions.
Finally, we calculate the relevance ranking between the queriedquestions and the historical questions in the latent topic space.Past studies by (Cao et al., 2009; Cao et al., 2010; Ming et al., 2010; Cai et al., 2011; Ji et al., 2012;Zhou et al., 2013) confirmed a significant retrieval improvement by adding the natural categories intovarious existing retrieval models.
However, all these previous work regarded natural categories indi-vidually without considering the relationships among them.
On the contrary, this paper can effectivelycapture the relationships between the shared aspects and the category-specific individual aspects withnatural categories via a group non-negative matrix factorization framework.
Also, our work models therelevance ranking in the latent topic space rather than using the existing retrieval models.
To date, no at-tempts have been made regarding group non-negative matrix factorization in studies of question retrieval,which remains an under-explored area.The remainder of this paper is organized as follows.
Section 2 describes our proposed group non-negative matrix factorization with natural categories for question retrieval.
Section 3 presents the exper-imental results.
In Section 4, we conclude with ideas for future research.2 Group Non-negative Matrix Factorization with Natural Categories2.1 Problem FormulationIn CQA, all questions are usually organized into a hierarchy of categories.
When a user asks a question,the user is typically required to choose a category label for the question from a predefined hierarchy ofcategories.
Hence, each question in CQA has a category label.
Suppose that we are given a question col-lection D in CQA archive with size N , containing terms from a vocabulary V with size M .
A questiond is represented as a vector d ?
RMwhere each entry denotes the weight of the corresponding term,for example tf-idf is used in this paper.
Let C = {c1, c2, ?
?
?
, cP} denote the set of categories (subcat-egories) of question collection D, where P is the number of categories (subcategories).
The questioncollection D is organized into P groups according to their category labels and can be represented asD = {D1,D2, ?
?
?
,DP}.
Dp= {d(p)1, ?
?
?
,d(p)Np} ?
RM?Npis the term-question matrix correspondingto category cp, in which each row stands for a term and each column stands for a question.
Npis thenumber of questions in category cpsuch that?Pp=1Np= N .LetU?p= [Us,Up] ?
RM?
(Ks+Kp)be the term-topic matrix corresponding to category cp, where Ksis the number of shared topics, Kpis the number of category-specific topics corresponding to categorycp, and p ?
[1, P ].
Term-topic matrix Uscan be represented as Us= [u(s)1, ?
?
?
,u(s)Ks] ?
RM?Ks, inwhich each column corresponds to a shared topic.
While the term-topic matrix Upcan be representedas Up= [u(p)1, ?
?
?
,u(p)Kp] ?
RM?Kp.
The total number of topics in the question collection D is K =Ks+ PKp.
Let Vp= [v(p)1, ?
?
?
,v(p)Np] ?
R(Ks+Kp)?Npbe the topic-question matrix corresponding tocategory cp, in which each column denotes the question representation in the topic space.
We also denoteVTp= [HTp,WTp], where Hp?
RKs?Npand Wp?
RKp?Npcorrespond to the coefficients of sharedtopicsUsand category-specific topicsUp, respectively.Thus, given a question collection D = {D1,D2, ?
?
?
,DP} together with the category labels C ={c1, c2, ?
?
?
, cP}, our proposed GNMFNC amounts to modeling the question collection D with P group90simultaneously, arriving at the following objective function:O =P?p=1{?p??Dp?
[Us,Up]Vp?
?2F+ R(Us,Up)}(1)where ?p, ?Dp??2F.
R(Us,Up) is a regularization term used to penalize the ?similarity?
between theshared topics and category-specific topics throughUsandUp.In this paper, we aim to ensure that matrix Uscaptures only shared topics and matrix Upcapturesonly the category-specific topics.
For example, if matricesUsandUpare mutually orthogonal, we haveUTsUp= 0.
To impose this constraint, we attempt to minimize the sum-of-squares of entries of thematrix UTsUp(e.g., ?UTsUp?2Fwhich uniformly optimizes each entry of UTsUp).
With this choice, theregularization term of R(Us,Up) is given byR(Us,Up) =P?p=1?p??UTsUp??2F+P?l=1,l?=p?l??UTpUl?
?2F(2)where ?pand ?lare the regularization parameters, ?p ?
[1, P ], ?l ?
[1, P ].Learning the objective function in equation (1) involves the following optimization problem:minUs,Up,Vp?0L = O + ?1??UTs1M?
1Ks?
?2F+ ?2??UTp1M?
1Kp?
?2F+ ?3??Vp1Np?
1Ks+Kp?
?2F(3)where ?1, ?2and ?3are the shrinkage regularization parameters.
Based on the shrinkage methodology,we can approximately satisfy the normalization constraints for each column of [Us,Up] and VTpbyguaranteeing the optimization converges to a stationary point.2.2 Learning AlgorithmWe present the solution to the GNMFNC optimization problem in equation (3) as the following theorem.The theoretical aspects of the optimization are presented in the next subsection.Theorem 2.1.
UpdatingUs,UpandVpusing equations (4)?
(6) corresponds to category cpwill mono-tonically decrease the objective function in equation (3) until convergence.Us?
Us?
[?Pp=1?pDpHTp][?Pp=1?p[Us,Up]VpHTp+ ?pUpUTpUs](4)Up?
Up?
[?pDpWTp][?p[Us,Up]VpWTp+ ?pUsUTsUp+?Pl=1,l?=p?lUlUTlUp](5)Vp?
Vp?
[?pDTp[Us,Up]][?pVTp[Us,Up]T[Us,Up]](6)where operator ?
is element-wise product and[?][?
]is element-wise division.Based on Theorem 2.1, we note that multiplicative update rules given by equations (4)?
(6) are ob-tained by extending the updates of standard NMF (Lee and Seung, 2001).
A number of techniques canbe used here to optimize the objective function in equation (3), such as alternating least squares (Kimand Park, 2008), the active set method (Kim and Park, 2008), and the projected gradients approach (Lin,2007).
Nonetheless, the multiplicative updates derived in this paper have reasonably fast convergencebehavior as shown empirically in the experiments.2.3 Theoretical AnalysisIn this subsection, we give the theoretical analysis of the optimization, convergence and computationalcomplexity.91Without loss of generality, we only show the optimization ofUsand formulate the Lagrange functionwith constraints as follows:L(Us) = O + ?1??UTs1M?
1Ks?
?2F+ Tr(?sUTs)(7)where Tr(?)
denotes the trace of a matrix, ?s?
RKs?Ksis the Lagrange multiplier for the nonnegativeconstraintUs?
0.The partial derivative of L(Us) w.r.t.
Usis?UsL(Us) = ?2P?p=1?pDpHTp+ 2P?p=1?p[Us,Up]VpHTp+ 2P?p=1?pUpUTpUs+ 2?1Us?
2?1+ ?s(8)Using the Karush-Kuhn-Tucker (KKT) (Boyd and Vandenberghe, 2004) condition ?s?Us= 0, weobtain?UsL(Us) ?Us={?
?Pp=1?pDpHTp+?Pp=1?p[Us,Up]VpHTp+?Pp=1?pUpUTpUs+ ?1Us?
?1}?Us= 0 (9)After normalization ofUs, the terms ?1Usand ?1are in fact equal.
They can be safely ignored fromthe above formula without influencing convergence.
This leads to the updating rule for Usin equation(4).
Following the similar derivations as shown above, we can obtain the updating rules for the restvariablesUpandVpin GNMFNC optimization, as shown in equations (5) and (6).2.3.1 Convergence AnalysisIn this subsection, we prove the convergence of multiplicative updates given by equations (4)?(6).
Wefirst introduce the definition of auxiliary function as follows.Definition 2.1.
F(X,X?)
is an auxiliary function for L(X) if L(X) ?
F(X,X?)
and equality holds ifand only if L(X) = F(X,X).Lemma 2.1.
(Lee and Seung, 2001) If F is an auxiliary function for L, L is non-increasing under theupdateX(t+1)= argminXF(X,X(t))Proof.
By Definition 2.1, L(X(t+1)) ?
F(X(t+1),X(t)) ?
F(X(t),X(t)) = L(X(t))Theorem 2.2.
Let L(U(t+1)s) denote the sum of all terms in L that containU(t+1)s, the following functionis an auxiliary function for L(U(t+1)s)F(U(t+1)s,U(t)s) = L(U(t)s) + (U(t+1)s?U(t)s)?U(t)sL(U(t)s) +12(U(t+1)s?U(t)s)2P(U(t)s)(10)P(U(t)s) =?ij[?Pp=1?p[U(t)s,Up]VpWTp+ ?pUpUTpU(t)s+ ?1U(t)s]ij?ij[U(t)s]ijwhere ?U(t)sL(U(t)s) is the first-order derivative of L(U(t)s) with respect toU(t)s. Theorem 2.2 can beproved similarly to (Lee and Seung, 2001) by validating L(U(t+1)s) ?
F(U(t+1)s,U(t)s), L(U(t+1)s) =F(U(t+1)s,U(t+1)s), and the Hessian matrix ?
?U(t+1)sF(U(t+1)s,U(t)s) ?
0.
Due to limited space, weomit the details of the validation.92addition multiplication division overallGNMFNC:UsP (3MNpKs+MNpKp+MK2s) P (3MNpKs+MNpKp+MK2s) MKsO(PMNpKmax)GNMFNC:Up3MNpKp+MNpKs+ PM2K?3MNpKp+MNpKs+ PM2K?MKpO(PMRK?)GNMFNC:Vp3MNpK?3MNpK?NpK?O(MNpK?
)Table 1: Computational operation counts for each iteration in GNMFNC.Based on Theorem 2.2, we can fixU(t)sand minimize F(U(t+1)s,U(t)s) with respect toU(t+1)s. Whensetting ?U(t+1)sF(U(t+1)s,U(t)s) = 0, we get the following updating ruleU(t+1)s?
U(t)s?
[?Pp=1?pDpHTp+ ?1][?Pp=1?p[U(t)s,Up]VpWTp+ ?pUpUTpU(t)s+ ?1U(t)s](11)which is consistent with the updating rule derived from the KKT conditions aforementioned.By Lemma 2.1 and Theorem 2.2, we have L(U(0)s) = F(U(0)s,U(0)s) ?
F(U(1)s,U(0)s) ?F(U(1)s,U(1)s) = L(U(1)s) ?
?
?
?
?
L(U(Iter)s), where Iter is the number of iterations.
Therefore,Usis monotonically decreasing.
Since the objective function L is lower bounded by 0, the correctnessand convergence of Theorem 2.1 is validated.2.3.2 Computational ComplexityIn this subsection, we discuss the time computational complexity of the proposed algorithm GNMFNC.Besides expressing the complexity of the algorithm using big O notation, we also count the number ofarithmetic operations to provide more details about running time.
We show the results in Table 1, whereKmax= max{Ks,Kp}, K?= Ks+ Kpand R = max{M,Np}.Suppose the multiplicative updates stop after Iter iterations, the time cost of multiplicative updatesthen becomes O(Iter ?
PMRK?).
We set Iter = 100 empirically in rest of the paper.
Therefore, theoverall running time of GNMFNC is linear with respect to the size of word vocabulary, the number ofquestions and categories.2.4 Relevance RankingThe motivation of incorporating matrix factorization into relevance ranking is to learn the word rela-tionships and reduce the ?lexical gap?
(Zhou et al., 2013a).
To do so, given a queried question q withcategory label cpfrom Yahoo!
Answers, we first represent it in the latent topic space as vq,vq= argminv?0?q?
[Us,Up]v?22(12)where vector q is the tf-idf representation of queried question q in the term space.For each historical question d (indexed by r) in question collection D, with representation vd= r-thcolumn ofV, we compute its similarity with queried question vqas followingstopic(q, d) =< vq,vd>?vq?2?
?vd?2(13)The latent topic space score stopic(q, d) is combined with the conventional term matching scoresterm(q, d) for final relevance ranking.
There are several ways to conduct the combination.
Linearcombination is a simple and effective way.
The final relevance ranking score s(q, d) is:s(q, d) = ?stopic(q, d) + (1?
?
)sterm(q, d) (14)where ?
?
[0, 1] is the parameter which controls the relative importance of the latent topic space scoreand term matching score.
sterm(q, d) can be calculated with any of the conventional relevance modelssuch as BM25 (Robertson et al., 1994) and LM (Zhai and Lafferty, 2001).933 Experiments3.1 Data Set and Evaluation MetricsWe collect the data set from Yahoo!
Answers and use the getByCategory function provided in Yahoo!Answers API3to obtain CQA threads from the Yahoo!
site.
More specifically, we utilize the resolvedquestions and the resulting question repository that we use for question retrieval contains 2,288,607 ques-tions.
Each resolved question consists of four parts: ?question title?, ?question description?, ?questionanswers?
and ?question category?.
We only use the ?question title?
and ?question category?
parts, whichhave been widely used in the literature for question retrieval (Cao et al., 2009; Cao et al., 2010).
Thereare 26 first-level categories in the predefined natural hierarchy, i.e., each historical question is categorizedinto one of the 26 categories.
The categories include ?Arts & Humanities?, ?Beauty & Style?, ?Business& Finance?, etc.In order to evaluate our approach, we randomly select 2,000 questions as queried questions from theabove data collection to construct the validation/test sets, and the remaining data collection as trainingset.
Note that we select the queried questions in proportion to the number of questions and categoriesagainst the whole distribution to have a better control over a possible imbalance.
To obtain the ground-truth, we employ the Vector Space Model (VSM) (Salton et al., 1975) to retrieve the top 10 results andobtain manual judgements.
The top 10 results don?t include the queried question itself.
Given a returnedresult by VSM, an annotator is asked to label it with ?relevant?
or ?irrelevant?.
If a returned resultis considered semantically equivalent to the queried question, the annotator will label it as ?relevant?
;otherwise, the annotator will label it as ?irrelevant?.
Two annotators are involved in the annotationprocess.
If a conflict happens, a third person will make judgement for the final result.
In the processof manually judging questions, the annotators are presented only the questions.
As a result, there are intotal 20,000 judged question pairs.
We randomly split the 2,000 queried questions into validation/testsets, each has 1,000/1,000 queried questions.
We use the validation set for parameter tuning and the testset for evaluation.Evaluation Metrics: We evaluate the performance of question retrieval using the following metrics:Mean Average Precision (MAP) and Precision@N (P@N).
MAP rewards methods that return relevantquestions early and also rewards correct ranking of the results.
P@N reports the fraction of the top-Nquestions retrieved that are relevant.
We perform a significant test, i.e., a t-test with a default significantlevel of 0.05.There are several parameters used in the paper, we tune these parameters on the validation set.Specifically, we set the number of category-specific topics per category and the number of sharedtopics in GNMFNC as (Ks,Kp) = {(5, 2), (10, 4), (20, 8), (40, 16), (80, 32)}, resulting in K ={57, 114, 228, 456, 912} total number of topics.
(Note that the total number of topics in GNMFNCis Ks+ 26 ?Kp, where 26 is the number of categories in the first-level predefined natural hierarchy4).Finally, we set (Ks,Kp) = (20, 8) and K = 228 empirically as this setting yields the best performance.For regularization parameters ?pand ?l, it is difficult to directly tune on the validation set, we presentan alternative way by adding a common factor a to look at the objective function of optimization problemin equation (3) on the training data.
In other words, we set ?p=aKs?Kpand ?l=aKp?Kl.
Therefore, wetune the parameters ?pand ?lby alternatively adjusting the common factor a via grid search.
As a result,we set a = 100, resulting in ?p= ?l= 0.625 in the following experiments.
The trade-off parameter ?in the linear combination is set from 0 to 1 in steps of 0.1 for all methods.
We set ?
= 0.6 empirically.For shrinkage regularization parameters, we empirically set ?1= ?2= ?3= 1.3.2 Question Retrieval ResultsIn this experiment, we present the experimental results for question retrieval on the test data set.
Specif-ically, for our proposed GNMFNC, we combine the latent topic matching scores with the term matchingscores given by BM25 and LM, denoted as ?BM25+GNMFNC?
and ?LM+GNMFNC?.
Table 2 shows3http://developer.yahoo.com/answers4Here we do not use the leaf categories because we find that it is not possible to run GNMFNC with such large number oftopics on the current machines, and we will leave it for future work.94Table 2: Comparison with different methodsfor question retrieval.# Methods MAP P@101 BM25 0.243 0.2252 LM 0.286 0.2323 (Jeon et al., 2005) 0.327 0.2354 (Xue et al., 2008) 0.341 0.2385 (Zhou et al., 2011) 0.365 0.2436 (Singh, 2012) 0.354 0.2407 (Cao et al., 2010) 0.358 0.2428 (Cai et al., 2011) 0.331 0.2369 BM25+GNMFNC 0.369 0.24810 LM+GNMFNC 0.374 0.251Table 3: Comparison of matrix factoriza-tions for question retrieval.# Methods MAP P@101 BM25 0.243 0.2252 BM25+NMF 0.325 0.2353 BM25+CNMF 0.344 0.2394 BM25+GNMF 0.361 0.2425 BM25+GNMFNC 0.369 0.2486 LM 0.286 0.2327 LM+NMF 0.337 0.2378 LM+CNMF 0.352 0.2409 LM+GNMF 0.365 0.24310 LM+GNMFNC 0.374 0.251the main retrieval performances under the evaluation metrics MAP, P@1 and P@10.
Row 1 and row2 are the baseline systems, which model the relevance ranking using BM25 (Robertson et al., 1994)and language model (LM) (Zhai and Lafferty, 2001) in the term space.
Row 3 is word-based transla-tion model (Jeon et al., 2005), and row 4 is word-based translation language model (TRLM) (Xue etal., 2008).
Row 5 is phrase-based translation model (Zhou et al., 2011), and row 6 is the entity-basedtranslation model (Singh, 2012).
Row 7 to row 11 explore the natural categories for question retrieval.In row 7, Cao et al.
(2010) employed the natural categories to compute the local and global relevancewith different model combination, here we use the combination VSM + TRLM for comparison becausethis combination obtains the superior performance than others.
In row 8, Cai et al.
(2011) proposed acategory-enhanced TRLM for question retrieval.
There are some clear trends in the results of Table 2:(1) BM25+GNMFNC and LM+GNMFNC perform significantly better than BM25 and LM respec-tively (t-test, p-value < 0.05, row 1 vs. row 9; row 2 vs. row 10), indicating the effective of GNMFNC.
(2) BM25+GNMFNC and LM+GNMFNC perform better than translation methods, some improve-ments are statistical significant (t-test, p-value < 0.05, row 3 and row 4 vs. row 9 and row 10).
Thereason may be that GNMFNC models the relevance ranking in the latent topic space, which can alsoeffectively solve the the lexical gap problem.
(3) Capturing the shared aspects and the category-specific individual aspects with natural categoriesin the group modeling framework can significantly improve the performance of question retrieval (t-test,p-value < 0.05, row 7 and row 8 vs. row 9 and row 10).
(4) Natural categories are useful and effectiveness for question retrieval, no matter in the group mod-eling framework or existing retrieval models (row 3?
row 6 vs. row 7?row 10).3.3 Comparison of Matrix FactorizationsWe note that our proposed GNMFNC is related to non-negative matrix factorization (NMF) (Lee andSeung, 2001) and its variants, we introduce three baselines.
The first baseline is NMF, which is trainedon the whole training data.
The second baseline is CNMF, which is trained on each category withoutconsidering the shared topics.
The third baseline is GNMF (Lee and Choi, 2009; Wang et al., 2012),which is similar to our GNMFNC but there are no constraints on the category-specific topics to preventthem from capturing the information from the shared topics.NMF and GNMF are trained on the training data with the same parameter settings in section 4.1 forfair comparison.
For CNMF, we also train the model on the training data with the same parameter settingsin section 4.1, except parameter Ks, as there exists no shared topics in CNMF.Table 3 shows the question retrieval performance of NMF families on the test set, obtained with thebest parameter settings determined by the validation set.
From the results, we draw the following obser-vations:(1) All of these methods can significantly improve the performance in comparison to the baselineBM25 and LM (t-test, p-value < 0.05).
(2) GNMF and GNMFNC perform significantly better than NMF and CNMF respectively (t-test, p-value < 0.05), indicating the effectiveness of group matrix factorization framework, especially the useof shared topics.950 20 40 60 80 1000.410.420.430.440.450.460.470.480.490.5Iteration numberObjectivefunction valueFigure 1: Convergence curve of GNMFNC.-4 -3 -2 -1 0 1 2 3 40.4140.4160.4180.420.4220.4240.4260.4280.43Log10aConvergedobjectivefunction valueFigure 2: Objective function value vs. factor a.
(3) GNMFNC performs significantly better than GNMF (t-test, p-value < 0.05, row 4 vs. row 5; row9 vs. row 10), indicating the effectiveness of the regularization term on the category-specific topics toprevent them from capturing the information from the shared topics.From the experimental results reported above, we can conclude that our proposed GNMFNC is usefulfor question retrieval with high accuracies.
To the best of our knowledge, it is the first time to investigatethe group matrix factorization for question retrieval.3.4 Convergence BehaviorIn subsection 2.3.1, we have shown that the multiplicative updates given by equations (4)?
(6) are con-vergent.
Here, we empirically show the convergence behavior of GNMFNC.Figure 1 shows the convergence curve of GNMFNC on the training data set.
From the figure, y-axis isthe value of objective function and x-axis denotes the iteration number.
We can see that the multiplicativeupdates for GNMFNC converge very fast, usually within 80 iterations.3.5 Regularization Parameters SelectionOne success of this paper is to use regularized constrains on the category-specific topics to prevent themfrom capturing the information from the shared topics.
It is necessary to give an in-depth analysis ofthe regularization parameters used in the paper.
Consider the regularization term used in equation (2),each element in UTsUpand UTpUlhas a value between 0 and 1 as each column of Us, Upand Ulisnormalized.
Therefore, it is appropriate to normalize the term having ?UTsUp?2Fby KsKpsince thereare Ks?Kpelements inUTsUp.
Similarly, ?UTpUl?2Fis normalized by KlKp.
Note that Kl= Kpandl ?= p. As discussed in subsection 4.1, we present an alternative way by adding a common factor a andset ?p=aKs?Kpand ?l=aKp?Kl.
The common factor a is used to adjust a trade-off between the matrixfactorization errors and the mutual orthogonality, which cannot directly tune on the validation set.
Thus,we look at the objective function of optimization problem in equation (3) on the training data and findthe optimum value for a.Figure 2 shows the objective function value vs. common factor a, where y-axis denotes the convergedobjective function value, and x-axis denotes Log10a .
We can see that the optimum value of a is 100.Therefore, the common factor a can be fixed at 100 for our data set used in the paper, resulting in?p= ?l= 0.625.
Note that the optimum value of (Ks,Kp) are set as (20, 8) in subsection 4.1.
Due tolimited space, we do not give an in-depth analysis for other parameters.4 Conclusion and Future WorkIn this paper, we propose a novel approach, called group non-negative matrix factorization with naturalcategories (GNMFNC).
The proposed method is achieved by learning the category-specific topics foreach category as well as shared topics across all categories via a group non-negative matrix factorizationframework.
We derive an efficient algorithm for learning the factorization, analyze its complexity, and96provide proof of convergence.
Experiments show that our proposed approach significantly outperformsvarious baseline methods and achieves state-of-the-art performance for question retrieval.There are some ways in which this research could be continued.
First, the optimization of GNMFNCcan be decomposed into many sub-optimization problems, a natural avenue for future research is toreduce the running time by executing the optimization in a distributed computing environment (e.g.,MapReduce (Dean et al., 2004)).
Second, another combination approach will be used to incorporate thelatent topic match score as a feature in a learning to rank model, e.g., LambdaRank (Burges et al., 2007).Third, we will try to investigate the use of the proposed approach for other kinds of data sets with largercategories, such as categorized documents from ODP project.5AcknowledgmentsThis work was supported by the National Natural Science Foundation of China (No.
61333018 andNo.
61303180), the Beijing Natural Science Foundation (No.
4144087), CCF Opening Project of Chi-nese Information Processing, and also Sponsored by CCF-Tencent Open Research Fund.
We thank theanonymous reviewers for their insightful comments.ReferencesD.
Bernhard and I. Gurevych.
2009.
Combining lexical semantic resources with question & answer archives fortranslation-based answer finding.
In Proceedings of ACL, pages 728-736.S.
Boyd and L. Vandenberghe.
2004.
Convex Optimization.
Cambridge university press.C.
Boutsidis and E. Gallopoulos.
2008.
SVD based initialization: a head start for nonnegative matrix factorization.Pattern Recognition, 41(4):1350-1362.C.
Burges, R. Ragno, and Q.
Le.
2007.
Learning to rank with nonsmooth cost function.
In Proceedings of NIPS.L.
Cai, G. Zhou, K. Liu, and J. Zhao.
2011.
Learning the latent topics for question retrieval in community QA.
InProceedings of IJCNLP.X.
Cao, G. Cong, B. Cui, C. Jensen, and C. Zhang.
2009.
The use of categorization information in languagemodels for question retrieval.
In Proceedings of CIKM, pages 265-274.X.
Cao, G. Cong, B. Cui, and C. Jensen.
2010.
A generalized framework of exploring category information forquestion retrieval in community question answer archives.
In Proceedings of WWW.J.
Dean, S. Ghemanwat, and G. Inc. 2004.
Mapreduce: simplified data processing on large clusters.
In Proceed-ings of OSDI.H.
Duan, Y. Cao, C. Lin, and Y. Yu.
2008.
Searching questions by identifying questions topics and question focus.In Proceedings of ACL, pages 156-164.J.
Jeon, W. Croft, and J. Lee.
2005.
Finding similar questions in large question and answer archives.
In Proceed-ings of CIKM, pages 84-90.Z.
Ji, F. Xu, and B. Wang.
2012.
A category-integrated language model for question retrieval in communityquestion answering.
In Proceedings of AIRS, pages 14-25.H.
Kim and H. Park.
2008.
Non-negative matrix factorization based on alternating non-negativity constrainedleast squares and active set method.
SIAM J Matrix Anal Appl, 30(2):713-730.A.
Langville, C. Meyer, R. Albright, J. Cox, and D. Duling.
2006.
Initializations for the nonnegative matrixfactorization.
In Proceedings of KDD.J.
Lee, S. Kim, Y.
Song, and H. Rim.
2008.
Bridging lexical gaps between queries and questions on large onlineQ&A collections with compact translation models.
In Proceedings of EMNLP, pages 410-418.D.
Lee and H. Seung.
2001.
Algorithms for non-negative matrix factorization.
In Proceedings of NIPS.5http://www.dmoz.org/97H.
Lee and S. Choi.
2009.
Group nonnegative matrix factorization for eeg classification.
In Proceedings ofAISTATS, pages 320-327.C.
Lin.
2007.
Projected gradient methods for nonnegative matrix factorization.
Neural Comput, 19(10):2756-2779.Z.
Ming, T. Chua, and G. Cong.
2010.
Exploring domain-specific term weight in archived question search.
InProceedings of CIKM, pages 1605-1608.S.
Riezler, A. Vasserman, I. Tsochantaridis, V. Mittal, and Y. Liu.
2007.
Statistical machine translation for queryexpansion in answer retrieval.
In Proceedings of ACL, pages 464-471.S.
Robertson, S. Walker, S. Jones, M. Hancock-Beaulieu, and M. Gatford.
1994.
Okapi at trec-3.
In Proceedingsof TREC, pages 109-126.G.
Salton, A. Wong, and C. Yang.
1975.
A vector space model for automatic indexing.
Communications of theACM, 18(11):613-620.A.
Singh.
2012.
Entity based q&a retrieval.
In Proceedings of EMNLP-CoNLL, pages 1266-1277.Q.
Wang, Z. Cao, J. Xun, and H. Li.
2012.
Group matrix factorizaiton for scalable topic modeling.
In Proceedingsof SIGIR.X.
Xue, J. Jeon, and W. Croft.
2008.
Retrieval models for question and answer archives.
In Proceedings of SIGIR,pages 475-482.C.
Zhai and J. Lafferty.
2001.
A study of smooth methods for language models applied to ad hoc informationretrieval.
In Proceedings of SIGIR, pages 334-342.G.
Zhou, L. Cai, J. Zhao, and K. Liu.
2011.
Phrase-based translation model for question retrieval in communityquestion answer archives.
In Proceedings of ACL, pages 653-662.G.
Zhou, F. Liu, Y. Liu, S. He, and J. Zhao.
2013.
Statistical machine translation improves question retrieval incommunity question answering via matrix factorization.
In Proceedings of ACL, pages 852-861.G.
Zhou, Y. Chen, D. Zeng, and J. Zhao.
2013.
Toward faster and better retrieval models for question search.
InProceedings of CIKM, pages 2139-2148.98
