Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics: Tutorials, page 6,Baltimore, Maryland, USA, 22 June 2014. c?2014 Association for Computational LinguisticsSemantics for Large-Scale Multimedia: New Challenges for NLPFlorian MetzeCarnegie Mellon Universityfmetze@cs.cmu.eduKoichi ShinodaTokyo Institute of Technologyshinoda@cs.titech.ac.jp1 DescriptionThousands of videos are constantly being up-loaded to the web, creating a vast resource, and anever-growing demand for methods to make themeasier to retrieve, search, and index.
As it becomesfeasible to extract both low-level as well as high-level (symbolic) audio, speech, and video featuresfrom this data, these need to be processed further,in order to learn and extract meaningful relationsbetween these.
The language processing commu-nity has made huge process in analyzing the vastamounts of very noisy text data that is availableon the Internet.
While it is very difficult to createsemantic units of low-level image descriptors ornon-speech sounds by themselves, it is compara-tively easy to ground semantics in the word outputof a speech recognizer, or text data that is looselyassociated with a video.
This creates an opportu-nity for NLP researchers to use their unique skills,and make significant contributions to solve taskson data that is even noisier than web text, but (weargue) even more interesting and challenging.This tutorial aims to present to the NLP com-munity the state of the art in audio and videoprocessing, by discussing the most relevant tasksat NIST?s TREC Video Retrieval Evaluation(TRECVID) workshop series.
We liken ?Seman-tic Indexing?
(SIN) task, in which a system mustidentify occurrences of concepts such as ?desk?,or ?dancing?
in a video to the word spotting ap-proach.
We then proceed to explain more recent,and challenging tasks, ?Multimedia Event Detec-tion?
(MED) and ?Multimedia Event Recounting?
(MER), which can be compared to transcriptionand summarization tasks.
Finally, we will presentan easy way to get started in multi-media analysisusing Virtual Machines from the ?Speech Recog-nition Virtual Kitchen?, which will enable tutorialparticipants to perform hands-on experiments dur-ing the tutorial, and at home.2 Outline1.
Introduction?
Content based video retrieval?
What is the ?Semantic Gap???
The TRECVid workshop and its tasks2.
Semantic Indexing?
State-of-the art frameworks?
Extension of Bag-of-Word model?
Multi-modality3.
Multimedia Event Detection & Recounting?
State-of-the art frameworks?
Multimodal fusion?
Semi-supervised and active learning?
Video Summarization4.
Challenges for NLP?
How to design visual concepts??
Intermediate representations??
Are there any grammars in video?5.
Practice session?
Virtual Machines in the SpeechRecognition Virtual Kitchen(http://speechkitchen.org/)3 InstructorsFlorian Metze received his PhD from UniversitatKarlsruhe (TH) in 2005.
He worked as a SeniorResearch Scientist at Deutsche Telekom Labora-tories (T-Labs) and joined Carnegie Mellon Uni-versity?s faculty in 2009.
His interests includesspeech and audio processing, and user interfaces.Koichi Shinoda received his D. Eng.
from TokyoInstitute of Technology in 2001.
In 1989, he joinedNEC Corporation.
From 1997 to 1998, he was avisiting scholar with Bell Labs, Lucent Technolo-gies.
He is currently a Professor at the Tokyo In-stitute of Technology.
His research interests in-clude speech recognition, video information re-trieval, and human interfaces.6
