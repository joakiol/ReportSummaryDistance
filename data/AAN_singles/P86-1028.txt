FORUM ON CONNECTIONISMConnectionist Models for Natura l  Language ProcessingDavid L. WaltzThinking Machines Corporation245 First StreetCambridge, MA 02142andProgram in Linguistics and Cognitive ScienceBrandeis UniversityBrown 125Waltham, MA 02254PANEL IST  STATEMENTAfter an almost twenty year lull, there has been adramatic upsurge of interest in massively parallel models forcomputation, descendants of perceptron and pandemoniummodels, now dubbed 'connectionist models.'
Much of theconnectionist research has focused on models for natural an-guage processing.
There have been three main reasons forthis increase in interest:1.
Scientific adequacy of the models2.
The availability of fine-grained parallel hardwareto run the models3.
The demonstration of powerful connectionistlearning models.The scientific adequacy of models based on a small num-ber of coarse-grained primitives (e.g.
conceptual dependency),popular in AI during the 70's, has been called into questionand substantially replaced by a current emphasis in much ofcomputational linguistics on lexicalist models (i.e., ones whichuse words for representing concepts or meanings).
However,few people can doubt that words are too coarse, that theyhave structure and properties and features.
Connectionistmodels offer very fine granularity; they can capture suchdetail in a manner that still allows for tractable computation.Such models also promise to make the integration of syntac-tic, semantic, pragmatic, and memory models simpler andmore transparent.Fine-grained hardware, such as the Connection Machine,can allow models with millions of active elements, fullvocabularies, and rapid throughput, as well as powerful near-term connectionist applications based on the use of associa-tive memory and hardware support for interprocessor com-munication.
Meanwhile, connectionist learning models, suchas the Boltzmann Machine and its descendant, he backwarderror propagation model, have demonstrated surprisingpower in learning concepts from example; as for instance inSejnowski's NETtalk, which learned the pronunciation rulesfor English from examples.
The future promises yet moresurprising results as the concepts in even more radicalmodels, such as Minsky's Society of Minds model, aredigested and as new, even more powerful hardware becomesavailable.185
