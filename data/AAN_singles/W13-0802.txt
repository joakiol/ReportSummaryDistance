Proceedings of the 7th Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 11?18,Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational LinguisticsTaste of Two Different Flavours: Which Manipuri Script Works Betterfor English-Manipuri Language Pair SMT Systems?Thoudam Doren SinghCentre for Development of Advanced Computing (CDAC), MumbaiGulmohor Cross Road No 9, JuhuMumbai-400049, INDIAthoudam.doren@gmail.comAbstractThe statistical machine translation (SMT) sys-tem heavily depends on the sentence alignedparallel corpus and the target language model.This paper points out some of the core issueson switching a language script and its reper-cussion in the phrase based statistical machinetranslation system development.
The presenttask reports on the outcome of English-Manipuri language pair phrase based SMTtask on two aspects ?
a) Manipuri using Ben-gali script, b) Manipuri using transliteratedMeetei Mayek script.
Two independent viewson Bengali script based SMT and transliter-ated Meitei Mayek based SMT systems of thetraining data and language models are pre-sented and compared.
The impact of variouslanguage models is commendable in such sce-nario.
The BLEU and NIST score shows thatBengali script based phrase based SMT(PBSMT) outperforms over the Meetei Mayekbased English to Manipuri SMT system.However, subjective evaluation shows slightvariation against the automatic scores.1 IntroductionThe present finding is due to some issue of socio-linguistics phenomenon called digraphia - a case ofManipuri language (a resource constrained Indianlanguages spoken mainly in the state of Manipur)using two different scripts namely Bengali script11http://unicode.org/charts/PDF/U0980.pdfand Meetei Mayek2.
Meetei Mayek (MM) is theoriginal script which was used until the 18th cen-tury to represent Manipuri text.
Its earliest use isdated between the 11th and 12th centuries CE3.Manipuri language is recognized by the Indian Un-ion and has been included in the list of 8th sched-uled languages by the 71st amendment of theconstitution in 1992.
In the recent times, the Ben-gali script is getting replaced by Meetei Mayek atschools, government departments and other admin-istrative activities.
It may be noted that Manipuri isthe only Tibeto-Burman language which has itsown script.
Digraphia has implications in languagetechnology as well despite the issues of languageplanning, language policy and language ideology.There are several examples of languages written inone script that was replaced later by another script.Some of the examples are Romanian which origi-nally used Cyrillic then changed to Latin; Turkishand Swahili began with the Arabic then Latin, andmany languages of former Soviet Central Asia,which abandoned the Cyrillic script after the disso-lution of the USSR.
The present study is a typicalcase where the natural language processing of anIndian language is affected in case of switchingscript.Manipuri is a monosyllabic, morphologicallyrich and highly agglutinative in nature.
Tone isvery prominent.
So, a special treatment of thesetonal words is absolutely necessary.
Manipuri lan-guage has 6 vowels and their tone counterparts and6 diphthongs and their tone counterparts.
Thus, a2http://unicode.org/charts/PDF/UABC0.pdf3http://en.wikipedia.org/wiki/Meitei_language11Manipuri learner should know its tone system andthe corresponding word meaning.Natural language processing tasks for Manipurilanguage is at the initial phase.
We use a small par-allel corpus and a sizable monolingual corpus col-lected from Manipuri news to develop English-Manipuri statistical machine translation system.The Manipuri news texts are in Bengali script.
So,we carry out transliteration from Bengali script toMeetei Mayek as discussed in section 3.
Typically,transliteration is carried out between two differentlanguages ?one as a source and the other as a tar-get.
But, in our case, in order to kick start the MTsystem development, Bengali script (in which mostof the digital Manipuri text are available) to MeeteiMayek transliteration is carried out using differentmodels.
The performance of the rule based translit-eration is improved by integrating the conjunct andsyllable handling module in the present rule basedtask along with transliteration unit (TU).
However,due to the tonal characteristic of this language,there is loss of accents for the tonal words whengetting translated from Bengali script.
In otherwords, there is essence of intonation in Manipuritext; the differentiation between Bengali characterssuch as ?
(i) and ? (ee) or ?  (u) and ?  (oo) cannotbe made using Meetei Mayek.
This increases thelexical ambiguity on the transliterated Manipuriwords in Meetei Mayek script.2 Related WorkSeveral SMT systems between English and mor-phologically rich languages are reported.
(Tou-tonova et al 2007) reported the improvement ofan SMT by applying word form prediction modelsfrom a stem using extensive morphological andsyntactic information from source and target lan-guages.
Contributions using factored phrase basedmodel and a probabilistic tree transfer model atdeep syntactic layer are made by (Bojar and Haji?,2008) of English-to-Czech SMT system.
(Yeniterziand Oflazer, 2010) reported syntax-to-morphologymapping in factored phrase-based Statistical Ma-chine Translation (Koehn and Hoang, 2007) fromEnglish to Turkish relying on syntactic analysis onthe source side (English) and then encodes a widevariety of local and non-local syntactic structuresas complex structural tags which appear as addi-tional factors in the training data.
On the target side(Turkish), they only perform morphological analy-sis and disambiguation but treat the complete com-plex morphological tag as a factor, instead ofseparating morphemes.
(Bojar et al 2012) pointedout several pitfalls when designing factored modeltranslation setup.
All the above systems have beendeveloped using one script for each language at thesource as well as target.Manipuri is a relatively free word order wherethe grammatical role of content words is largelydetermined by their case markers and not just bytheir positions in the sentence.
Machine Transla-tion systems of Manipuri and English is reportedby (Singh and Bandyopadhyay, 2010b) on devel-opment of English-Manipuri SMT system usingmorpho-syntactic and semantic information wherethe target case markers are generated based on thesuffixes and semantic relations of the source sen-tence.
The above mentioned system is developedusing Bengali script based Manipuri text.
SMTsystems between English and morphologically richhighly agglutinative language suffer badly if theadequate training and language resource is notavailable.
Not only this, it is important to note thatthe linguistic representation of the text has implica-tions on several NLP aspects not only in machinetranslations systems.
This is our first attempt tobuild and compare English-Manipuri language pairSMT systems using two different scripts of Ma-nipuri.3 Transliterated Parallel CorporaThe English-Manipuri parallel corpora and Ma-nipuri monolingual corpus collected from the newswebsite www.thesangaiexpress.com are based onBengali script.
The Bengali script has 52 conso-nants and 12 vowels.
The modern-day MeeteiMayek script is made up of a core repertoire of 27letters, alongside letters and symbols for final con-sonants, dependent vowel signs, punctuation, anddigits.
Meetei Mayek is a Brahmic script with con-sonants bearing the inherent vowel and vowel ma-tras modifying it.
However, unlike most otherBrahmi-derived scripts, Meetei Mayek employsexplicit final consonants which contain no finalvowels.
The use of the killer (which refers to itsfunction of killing the inherent vowel of a conso-nant letter) is optional in spelling; for example,while ??
may be read dara or dra, ???
must be readdra.
Syllable initial combinations for vowels can12occur in modern usage to represent diphthongs.The Meetei Mayek has 27 letters (Iyek Ipee), 8dependent vowel signs (Cheitap Iyek), 8 final con-sonants (Lonsum Iyek), 10 digits (Cheising Iyek)and 3 punctuation (Cheikhei, Lum Iyek and ApunIyek).BengaliScriptMeetei Mayek, , 	,K (Sam),  e (Na),  f (Til),  F (Thou),  \ (Yang),  r (Dil),  R (Dhou),  B (Un),  T (Ee), ,  j (Rai)?, ? g (Inap)? , ?  b (Unap)Table 1 ?
Many-to-One mapping tableThere is no possibility of direct one-to-one map-ping for the 27 Meetei Mayek letter (Iyek Ipee) toBengali script as given by table 1,  over and abovesome of Bengali scripts which does not have a cor-responding direct mapping to Meetei Mayek suchas ( ,  , ?
, !, ?"
etc.)
which has resulted in the lossof target representation.
The syllable based Bengaliscript to Meetei Mayek transliteration system out-performs the other known transliteration systems innews domain between the two scripts in terms ofprecision and recall (Singh, 2012).
The overallconjunct representation is many-to-many charac-ters in nature for the bilingual transliteration taskof Bengali script and Meetei Mayek.
Some of theexample words using the conjuncts are given as:'$  wDjlKe   (press-na)%&&   rgKfDjgdsg (district-ki)''(')*  KlsDjlfjg\lGf (secretariate-ta)'+',*-   wlfDjOM (petrol)And the Bengali script conjuncts and its constitu-ents along with the Meetei Mayek notation for theabove examples are as given below:'$ (pre)  + + ?.
 + '?
 wDjl% (stri)    ++ ?.
 + ?
 KfDjg'( (cre)  & +  + '?
 sDjl',* (tro) +  + '?
*   fDjOA sample transliterated parallel corpus betweenEnglish and Manipuri is given in the table 2.
Thesetransliterations are based on the syllable basedmodel.English On the part of the election depart-ment, IFCD have been intimidated fortaking up necessary measures.Manipuri inBengali Script'-/ +*0 '12& 1*3&4 567*&* 3-9* 9& +*:;9* :<='> .Manipuri inMeetei Mayek??????
??????????????
????????????????????
?????
????
???????????
????????
?Gloss election departmentki maykeidageeIFCDda darkar leiba thabak payk-hatnaba khanghankhre .English In case of rising the water level ofNambul river, the gate is shut downand the engines are operated to pumpout the water.Manipuri inBengali Script&4@* @-  '-4 	A 1* B*A:CD9 '4E A-4* 	A E F* G* HA'*D4*-*&+ =* .Manipuri inMeetei Mayek??????
??
?????
?????
??
????
???????????????
???
???
??????
???????
?????????
?????
???????????????
?????
?Gloss karigumba nambul turelgi eesingeemay waangkhatlaklabadi gate asithinglaga eesing asi enginena oynachingthoklaga laakpani hayri.English The department has a gate atSamushang meant for draining out theflood water of Lamphelpat.Manipuri inBengali Script*1	<* +*0 '12 E4 '4E1* -'I-+*J&	A HA'*K9* L .Manipuri inMeetei Mayek???????
?
???????????
?????
??????
??????????
????
???????????
??
?Gloss samusangda department asigee gateama lamphelpatki easing ching-thoknaba thammee.Table 2.
Transliterated texts of English ?
Manipuri Par-allel Corpora and the corresponding Gloss134 Building SMT for English-ManipuriThe important resources of building SMT are thetraining and language modeling data.
We use asmall amount of parallel corpora for training and asizable amount of monolingual Manipuri and Eng-lish news corpora.
So, we have two aspects of de-veloping English-Manipuri language pair SMTsystems by using the two different scripts for Ma-nipuri.
The moot question is which script will per-form better.
At the moment, we are developingonly the baseline systems.
So, the downstreamtools are not taken into account which would haveaffected by way of the performance of the scriptspecific tools other than the transliteration systemperformance used in the task.
In the SMT devel-opment process, apart from transliteration accuracyerror, the change in script to represent Manipuritext has made the task of NLP related activities adifference in the way how it was carried out withBengali script towards improving the factoredbased modes in future as well.
Lexical ambiguity isvery common in this language mostly due to tonalcharacteristics.
This has resulted towards the re-quirement of a word sense disambiguation modulemore than before.
This is because of a set of differ-ence in the representation using Meitei Mayek.
Aspart of this ongoing experiment, we augment thetraining data with 4600 manually prepared variantsof verbs and nouns phrases for improving the over-all accuracy and help solving a bit of data sparsityproblem of the SMT system along with an addi-tional lexicon of 10000 entries between Englishand Manipuri to handle bits of data sparsity andsense disambiguation during the training process.The English-Manipuri parallel corpus developedby (Singh and Bandyopadhyay, 2010a) is used inthe experiment.
Moses4 toolkit (Koehn, 2007) isused for training with GIZA++5 and decoding.Minimum error rate training (Och, 2003) for tuningare carried out using the development data for twoscripts.
Table 3 gives the corpus statistics of theEnglish-Manipuri SMT system development.4.1 Lexical AmbiguityManipuri is, by large, a tonal language.
The lexicalambiguity is very prominent even with Bengaliscript based text representation.
The degree of am-4http://www.statmt.org/moses/5http://www.fjoch.com/GIZA++.htmlbiguity worsens due to the convergence as shownby the figure 1 and many to one mapping shown inthe table 1.
So, the Bengali script to Meetei Mayektransliteration has resulted to the lost of severalwords meaning at the transliterated output.
Manyaspects of translation can be best explained at amorphological, syntactic or semantic level.
Thisimplies that the phrase table and target languagemodel are very much affected by using MeeteiMayek based text and hence the output of the SMTsystem.
Thus, lexical ambiguity is one major rea-son on why the transliterated Meetei Mayek scriptbased PBSMT suffers comparatively.
Three exam-ples of lexical ambiguity are given below:(a)1 (mi)   spider  ??
(mi) meaning either spider orman1 (mee)   man  ??
(mi) meaning either spider orman(b)9* (sooba)  to work  ????
(suba) meaning either towork or to hit9* (suba)  to hit  ????
(suba) meaning either towork or to hit(c)9* (sinba) / 	9* (shinba)  substitution  ?????
(sinba)9* (sheenba)   arrangement  ?????
(sinba)9* (sheenba)   sour taste   ?????
(sinba)Figure 1.
An example of convergence of TU (-su, -soo etc.)
from Bengali Script to Meitei Mayek?
?14The lexical ambiguity that arises are twofold,  i)one after transliteration into Meetei Mayek asgiven by examples (a) and (b), ii) one before thetransliteration as given by the example (c) forwhich the ambiguity is doubled after the translit-eration.
Thus, the scripts are functioning as a rep-resentation language for lexical ambiguity like thesemantic phrase sense disambiguation model forSMT (Carpuat and Wu, 2007).4.2 Language ModelingThe impact of the different language models isclearly seen in our experiment mostly by way oflexical variation and convergence characteristics asshown in Figure 1.
Four different language modelsare developed: a) language model (LM1) on Ben-gali script based Manipuri text, b) language model(LM2) on transliterated Manipuri Meetei Mayektext, there is change in the language model pa-rameter such as perplexity which affects the over-all translation decoding process, c) language model(LM3) based on language model (LM1) with trans-literation to Meitei Mayek on Manipuri text fromBengali Script texts, and d) language model (LM4)based on language model (LM2) with translitera-tion to Bengali script on Manipuri text from MeeteiMayek text.
SRILM (Stolcke, 2002) is used tobuild trigram model with modified Kneser-Neysmoothing (Stanley and Joshua, 1998) and interpo-lated with lower order estimates which works bestfor Manipuri language using 2.3 million words of180,000 Manipuri news sentences.
There are varia-tions in the language model parameters whileswitching the scripts.The log probability and perplexity of the sen-tence (considering the first sentence from Table 2)using Bengali script, ?'-/ +*0 '12& 1*3&4567* &* 3-9* 9& +*:;9* :<='> M?
are givenas:logprob= -22.873 ppl= 193.774 ppl1= 347.888while the parameters for the same sentence usingMeetei Mayek, i.e.,???????
??????????????
????????
?????????????????
????
???
????????
????????
??
aregiven as:logprob= -26.7555 ppl= 473.752 ppl1= 939.364It is also observed that some of the n-grams entrieson one language model are not available in theother language model.
For example,-2.708879       1* 'HN9       -0.3211589is a bigram found in Bengali script based languagemodel but not found in the Meetei Mayek basedlanguage model.
Similarly,-6.077539       ??????????????????
-0.06379553is a bigram found in the Meetei Mayek based lan-guage model but not available in Bengali scriptbased language model.
Above all, for the same n-gram in the language models, the log(P(W)) andlog(backoff-weight) are found to be different.
Twobigram examples are given below:-1.972813 1* '*D&+*  -0.09325081-6.077539  ?????
????????
-0.06379553and,-1.759148   1* '*&+*  -0.3929711-6.077539   ?????
??????
-0.063795524.3 EvaluationThe systems are developed using the followingcorpus statistics.# of Sentences # of WordsTraining 10000 231254Development 5000 121201Testing 500 12204Table 3.
Corpus StatisticsThe evaluations of SMT systems are done usingautomatic scoring and subjective evaluation.4.4 Automatic ScoringWe carry out the comparisons of automatic evalua-tion metrics scores for the SMT systems.
The vari-ous models developed are evaluated using BLEU(Papineni et al2002) and NIST (Doddington,2002) automatic scoring techniques.
A high NISTscore means a better translation by measuring theprecision of n-gram.15BLEUScoreNISTScoreMeetei Mayek based Baselineusing LM2 language model11.05 3.57Meetei Mayek based Baselinewith LM3 language model11.81 3.33Bengali Script based Baselineusing LM1 language model15.02 4.01Bengali Script based Baselineusing LM4 language model14.51 3.82Table 4 .
Automatics Scores of English to ManipuriSMT systemBLEU metric gives the precision of n-gram withrespect to the reference translation but with a brev-ity penalty.BLEUScoreNISTScoreBengali Script based Baseline 12.12 4.27Meetei Mayek based Baselineusing13.74 4.31Table 5.
Automatics Scores of Manipuri to EnglishSMT system4.5 Subjective EvaluationThe subjective evaluation is carried out by twobilingual judges.
The inter-annotator agreement is0.3 of scale 1.
The adequacy and fluency used inthe subjective evaluation scales are given by theTable 6 and Table 7.Level Interpretation4 Full meaning is conveyed3 Most of the meaning is conveyed2 Poor meaning is conveyed1 No meaning is conveyedTable 6.
Adequacy ScaleLevel Interpretation4 Flawless with no grammatical error3 Good output with minor errors2 Disfluent ungrammatical with correct phrase1 IncomprehensibleTable 7.
Fluency ScaleThe scores of adequacy and fluency on 100 testsentences based on the length are given at Table 8and Table 9 based on the adequacy and fluencyscales give by Table 6 and Table 7.Sentence length Fluency Adequacy<=15 words 3.13 3.16 Baselineusing Ben-gali  Script>15 words 2.21 2.47<=15 words 3.58 3.47 Baselineusing MeeteiMayek>15 words 2.47 2.63Table 8.
Scores of Adequacy and Fluency of English toManipuri SMT systemSentence length Fluency Adequacy<=15 words 2.39 2.42 Baselineusing Ben-gali  Script>15 words 2.01 2.14<=15 words 2.61 2.65 Baselineusing MeeteiMayek>15 words 2.10 1.94Table 9.
Scores of Adequacy and Fluency of Manipurito English SMT system5 Sample Translation OutputsThe following tables show the various translationoutputs of English-Manipuri as well as Manipuri-English PBSMT systems using Bengali script andMeetei Mayek scripts.English On the part of the election de-partment, IFCD have been intimi-dated for taking up necessarymeasures.Manipuri ReferenceTranslation(Bengali Script)'-/ +*0 '12& 1*3&4 567*&* 3-9* 9& +*:;9* :<='> .Gloss election departmentki maykei-dagee IFCDda darkar leiba tha-bak paykhatnaba khanghankhre .Baseline Transla-tion output(Bengali Script)'-/ +*0 '12& 1*3&4 567*&* 3-9* 9& +*:;9* :<='>.Table 10.
English to Manipuri SMT system output usingBengali Script16English On the part of the election depart-ment, IFCD have been intimidatedfor taking up necessary measures.Manipuri refer-ence Translation(Meetei Mayek)??????
??????????????
????????????????????
?????
????
???????????
????????
?Gloss election departmentki maykeidageeIFCDda darkar leiba thabak payk-hatnaba khanghankhre .Baseline Trans-lation output??????
??????????????
?????????????????
???
???
???????
???????
?Table 11: English to Manipuri SMT system output usingMeetei MayekInput Manipurisentence'-/ +*0 '12& 1*3&4 567*&* 3-9* 9& +*:;9* :<='> .Gloss election departmentki maykeidageeIFCDda darkar leiba thabak paykhat-naba khanghankhre .Reference Eng-lish translationOn the part of the election department,IFCD have been intimidated for takingup necessary measures.BaselineTranslationoutputthe election department notified IFCDto take up necessary stepsTable 12: Manipuri to English translation output usingBengali script:Input Manipurisentence??????
?????
?????????
????????????????????
?????
????
???????????
????????
?Gloss election departmentki maykeidageeIFCDda darkar leiba thabak paykhat-naba khanghankhre .Reference Eng-lish translationOn the part of the election department,IFCD have been intimidated for takingup necessary measures.BaselineTranslationoutputthe election department intimidatedIFCD to take up necessary stepsTable 13: Manipuri to English translation output usingMeetei Mayek:The English to Manipuri SMT system output usingBengali Script suffers fluency and adequacy scoresas given by table 8 compared to English to Ma-nipuri SMT system output using Meetei Mayekscript.
In the case of Manipuri to English SMT sys-tem, the Meetei Mayek based SMT system outper-forms the Bengali script based SMT in terms ofboth fluency and adequacy as given by table 9 aswell as automatic scores as given by table 5.6 Conclusion and DiscussionThe detailed study of grapheme-to-phoneme indi-cates missing tone for several words using presentMeetei Mayek script.
The training process basedon the Bengali script training data is found to havehigher vocabulary coverage all across since therepresentation is done with a finer glyph as com-pared to Meetei Mayek so is the higher automaticscores in case of English-to-Manipuri PBSMT sys-tem.
But, considering the subjective evaluationscores, the Meetei Mayek based SMT systems out-performs the Bengali script based English-to-Manipuri SMT systems as against the automaticscores.
In the case of Manipuri-to-English PBSMTsystems, both the automatic score and subjectiveevaluation scores using Meetei Mayek outperformsthe Bengali script based systems.
Statistical sig-nificant test is performed to judge if a change inscore that comes from a change in the system withscript switching reflects a change in overall trans-lation quality.
The systems show statistically sig-nificant result as measured by bootstrap re-sampling method (Koehn, 2004) on BLEU score.In future, the experiments can be repeated withspecial treatment of individual morphemes in bitsand pieces on a decent size of parallel corpora.More notably, SMT decoders may have the featureof handling two or more scripts of the same lan-guage in the future SMT systems for languageslike Manipuri.AcknowledgmentsI, sincerely, thank Dr. Zia Saquib, Executive Di-rector, CDAC (Mumbai), Prof. Sivaji Bandyop-adhyay, Jadavpur University, Kolkata and theanonymous reviewers for their support and valu-able comments.ReferencesAndreas Stolcke.
2002.
SRILM ?
an extensible languagemodeling toolkit.
In Proceedings of the InternationalConference on Spoken Language Processing.Franz J. Och.
2003.
Minimum error rate training inStatistical Machine Translation, Proceedings ofACL.17George Doddington.
2002.
Automatic evaluation of Ma-chine Translation quality using n-gram co-occurrence statistics.
In Proceedings of HLT 2002,San Diego, CA.Kishore Papineni, Salim Roukos, Todd Ward and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proceedings of40th ACL, Philadelphia, PA.Kristina Toutanova, Hisami Suzuki  and Achim Ruopp.2008.
Applying Morphology Generation Models toMachine Translation, In Proc.
46th Annual Meetingof the Association for Computational Linguistics.Marine Carpuat and Dekai Wu.
2007.
How PhraseSense Disambiguation outperforms Word Sense Dis-ambiguation for Statistical Machine, 11th Interna-tional Conference on Theoretical and MethodologicalIssues in Machine Translation (TMI 2007).
pages 43-52, Sk?vde, Sweden, September 2007.Ond?ej Bojar and Jan Haji?.
2008.
Phrase-Based andDeep Syntactic English-to-Czech Statistical MachineTranslation, Proceedings of the Third Workshop onStatistical Machine Translation, pages 143?146, Co-lumbus, Ohio, USA.Ond?ej Bojar, Bushra Jawaid and Amir Kamran.
2012.Probes in a Taxonomy of Factored Phrase-BasedModels, Proceedings of the 7th Workshop on Statis-tical Machine Translation of Association for Compu-tational Linguistics, pages 253?260, Montr?al,Canada.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In EMNLP-2004:Proceedings of the 2004 Conference on EmpiricalMethods in Natural Language Processing, 25-26 July2004, pages 388-395, Barcelona, Spain.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, Rich-ard Zens, Chris Dyer, Ond?ej Bojar, Alexandra Con-stantin and Evan Herbst.
2007.
Moses: Open SourceToolkit for Statistical Machine Translation, AnnualMeeting of the Association for Computational Lin-guistics (ACL), demonstration session, Prague,Czech Republic.Reyyan Yeniterzi and Kemal Oflazer.
2010.
Syntax-to-Morphology Mapping in Factored Phrase-Based Sta-tistical Machine Translation from English to Turkish,In proceeding of the 48th Annual Meeting of the As-sociation of Computational Linguistics, Pages 454-464, Uppsala, Sweden.Stanley F. Chen and Joshua Goodman.
1998.
An em-pirical study of smoothing techniques for languagemodeling.
Technical Report TR-10-98, Harvard Uni-versity Center for Research in Computing Technol-ogy.Thoudam Doren Singh and Sivaji Bandyopadhyay.2010a.
Semi Automatic Parallel Corpora Extractionfrom Comparable News Corpora, In the InternationalJournal of POLIBITS, Issue 41 (January ?
June2010), ISSN 1870-9044, pages 11-17.Thoudam Doren Singh and Sivaji Bandyopadhyay.2010b.
Manipuri-English Bidirectional StatisticalMachineTranslation Systems using Morphology andDependency Relations, Proceedings of SSST-4,Fourth Workshop on Syntax and Structure in Statisti-cal Translation, pages 83?91, COLING 2010, Bei-jing, August 2010.Thoudam Doren Singh.
2012.
Bidirectional BengaliScript and Meetei Mayek Transliteration of WebBased Manipuri News Corpus, In the Proceedings ofthe 3rd Workshop on South and Southeast AsianNatural Language Processing (SANLP) of COLING2012, IIT Bombay, Mumbai, India, pages 181-189,8th December, 2012.18
