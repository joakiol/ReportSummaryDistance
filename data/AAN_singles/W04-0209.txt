Exploiting semantic information for manual anaphoric annotation inCast3LB corpusBorja Navarro, Rube?n Izquierdo, Maximiliano Saiz-NoedaDepartmento de Lenguajes y Sistemas Informa?ticosUniversidad de AlicanteAp.
Correo 99, E-03080Alicante, Spain{borja,ruben,max}@dlsi.ua.esAbstractThis paper presents the discourse annotation fol-lowed in Cast3LB, a Spanish corpus annotated withseveral information sources (morphological, syntac-tic, semantic and coreferential) at syntactic, seman-tic and discourse level.
3LB annotation scheme hasbeen developed for three languages (Spanish, Cata-lan and Basque).
Human annotators have used aset of tagging techniques and protocols.
Severaltools have provided them with a friendly annotationscheme.
At discourse level, anaphoric and coref-erence expressions are annotated.
One of the mostinteresting contributions to this annotation scenariois the enriched anaphora resolution module that isbased on the previously defined semantic annotationphase to expand the discourse information and useit to suggest the correct antecedent of an anaphorato the annotator.
This paper describes the relevanceof the semantic tags in the discourse annotation inSpanish corpus Cast3LB and shows both levels andtools in the mentioned discourse annotation scheme.1 IntroductionCast3LB corpus is annotated (Navarro et al, 2003)at three linguistic levels: sentence level (syntac-tic), lexical level (semantic) and discourse level.
Atdiscourse level, it is annotated with anaphoric andcoreferential information.
In order to improve thetime-consuming and tedious task of the manuallyannotation, a semiautomatic and interactive processis followed: first, an anaphora resolution system se-lects each anaphora and its antecedent from a listof candidates; then, the human annotator decideswether or not accept the suggestion.With this approach, the correctness of theanaphora resolution system is a key factor in thequest of an efficient annotation process.
For thisreason, we use the linguistic information of theprevious annotation tasks (morphological, syntac-tic and, mainly, semantic information) to improvethe anaphora resolution system.
In this paper wewill focus on the use of semantic information in theanaphora and coreferential manual annotation task.Next section presents the project overview andthe three annotation levels.
Following sectionspresent the semantic annotation and the way itserves to the discourse annotations.
Last sectionpresents annotation tools used to annotate the cor-pus at semantic and coreferential level.2 Cast3LB corpus: annotation projectoverviewCast3Lb project is part of the general project 3LB1.The main objective of this general project is todevelop three corpora annotated with syntactic,semantic and pragmatic/coreferential information:one for Catalan (Cat3LB), one for Basque (Eus3LB)and one for Spanish (Cast3LB).The Spanish corpus Cast3LB is a part of theCLIC-TALP corpus, which is made up of 100.000words from the LexEsp corpus (Sebastia?n et al,2000) plus 25.000 words coming from the EFESpanish Corpus, given by the Agencia EFE (the of-ficial news agency) for research purposes.
The EFEcorpus fragments are comparable among the lan-guages of the general project (Catalan, Basque andSpanish).We have selected this corpus because it containsa large variety of Spanish texts (newspapers, novels,scientific papers.
.
.
), both from Spain and South-America, so it is a good representation of the cur-rent state of the Spanish language.
Moreover, theautomatic morphological annotation of this corpushas been manually checked (Civit, 2003).The spirit of the annotation scheme is to build aflexible system portable to different romance lan-guages and to potential new cases that might appear,but consistent with all annotation levels and annota-tion data.At the syntactic level we follow the constituencyannotation scheme.
Main principles of syntactic an-notation are the following (Civit et al, 2003): a)1Project partially funded by Spanish Government FIT-150-500-2002-244.only the explicit elements are annotated (except forelliptical subjects); b) we do not alter the surfaceword order of the elements; c) we do not follow anyspecific theoretical framework; d) we do not takeinto account the verbal phrase, rather, the main con-stituents of the sentence become the daughters ofthe root node; e) this syntactic information is en-riched by the functional information of the mainphrases, but we have not taken into account the pos-sibility of double functions.At the semantic level, we annotate the sense ofthe nouns, verbs and some adjectives, following anall words approach.
The specific sense (or senses)of each one is assigned by means of the EuroWord-Net offset number (Vossen, 1998).
Also, due tosome words are not available in EuroWordNet ordo not have the suitable sense, we have created twonew tags to mark this circumstance.At the discourse level, we mark the coreference ofnominal phrases and some elliptical elements.
Thecoreference expressions taken into account are per-sonal pronouns, clitics, elliptical subjects and someelliptical adjectives.
The definite descriptions arenot marked.
The possible antecedents consideredare the nominal phrases or other coreferential ex-pressions.3 Semantic annotationAs we said before, main objective of Cast3LBproject at semantic level is to develop an ?all words?corpus with the specific sense (or senses) of nouns,verbs and adjectives.Our proposal is based on the SemCor corpus(Miller, 1990).
This corpus is formed by a por-tion of the Brown corpus and the novel The RedBadge of Courage.
Altogether, it is formed by ap-proximately 250.000 words, where nouns, verbs,adjectives and adverbs have been manually anno-tated with WordNet senses (Miller, 1990).
Anothercorpus with WordNet-based semantic annotation isthe DSO corpus (Ng and Lee, 1996).
In this cor-pus, the most frequent English ambiguous nounsand verbs had been annotated with the correct sense(121 nouns and 70 verbs).
The corpus is formed by192.800 sentences from the Brown Corpus and theWall Street Journal, and it has also been manuallyannotated.
Finally, the SENSEVAL forum has de-veloped a few sense annotated corpora for the eval-uation of Word Sense Disambiguation systems (Kil-garriff and Palmer, 2000), some of which also useWordNet as a lexical resource.We have decided to use Spanish WordNet for sev-eral reasons.
First of all, Spanish WordNet is, up tonow, the more commonly used lexical resource inWord Sense Disambiguation tasks.
Secondly, it isone of the most complete lexical resources currentlyavailable for Spanish.
Finally, as part of EuroWord-Net, the lexical structure of Spanish and the lexicalstructure of Catalan and Basque are related.
There-fore, the annotated senses of the three corpora of3LB project can also be related.The tag used to mark a word sense is its off-set number, that is, its identification number in Eu-roWordNet?s InterLingua Index.
The corpus has42291 lexical words, where 20461 are nouns, 13471are verbs and 8543 are adjectives.On other hand, not all nouns, verbs, adjectivesand adverbs are annotated, due to EuroWordNetdoes not contain them.
Possible lacks in this senseare (i) the synset, (ii) the word, (iii) the synset andthe word, and (iv) the link between the synset andthe word.In order to deal with these cases we have definedtwo more tags in EuroWordNet:?
C1S: the word is found, but not its correctsense (due to a sense lack, or because there isno link between the word and the synset).?
C2S: the word is not found (because it is notthere, or because both the word and the synsetare missing).It is possible to distinguish two methods for se-mantically annotate a corpus.
The first one is linear(or ?textual?)
method (Kilgarriff, 1998), where thehuman annotator marks the sentences token by to-ken up to the end of the corpus.
In this strategy theannotator must read and analyze the sense of eachword every time it appears in the corpus.
The sec-ond annotation method is transversal (or ?lexical?
)(Kilgarriff, 1998), where he/she annotates word-type by word-type, all the occurrences of each wordin the corpus one by one.
With this method, theannotator must read and analyze all the senses of aword only once.We have followed in Cast3LB the transversal pro-cess.
The main advantage of this method is thatwe can focus our attention on the sense structure ofone word and deal with its specific semantic prob-lems: its main sense or senses, its specific senses.
.
.
.Then we check the context of the single word eachtime it appears and select the corresponding sense.Through this approach, semantic features of eachword is taken into consideration only once, and thewhole corpus achieves greater consistency.
Throughthe linear process, however, the annotator must re-member the sense structure of each word and theirspecific problems each time the word appears inthe corpus, making the annotation process muchmore complex, and increasing the possibilities oflow consistency and disagreement between the an-notators.Nevertheless, the transversal method finds its dis-advantage in the annotation of large corpus, be-cause no fragment of the corpus is available untilthe whole corpus is completed.
To avoid this, wehave selected a fragment of the whole corpus andannotated it by means of the linear process.Everybody agrees that semantic annotation is atedious and difficult task.
From a general point ofview, the main problem in the semantic annotationis the subjectivity of the human annotator when itcomes to the selection of the correct sense, becausethere are usually more than one sense for a word,and, due to the WorNet?s granularity, more than onecould be correct for a given word.
Another impor-tant problem in the semantic annotation is the pooragreement between different annotators, due to theambiguity and/or vagueness of many words.In order to overcome these problems, the annota-tion process has been carried out in two steps.
In thefirst step, a subset of ambiguous words have beenannotated twice by two annotators.
With this dou-ble annotation we have developed a disagreementtypology and an annotation handbook, where all thepossible causes of ambiguity have been describedand common solutions have been adopted for therest of cases.
In the second step the remaining cor-pus is annotated following the criteria adopted in theannotation handbook.Our final aim is to obtain useful resources forWord Sense Disambiguation (WSD) systems inSpanish.
This semantically annotated corpus willbe used as a training corpus for the development ofunsupervised systems and as a reference in generalevaluation tasks.
At the end of the project, we willhave a large amount of words with an unambiguoussense tag in a real context.As well as this final application, we exploit thissemantic information in the anaphoric annotationtask.
In (Saiz-Noeda, 2002), how to apply seman-tic information in anaphora resolution systems isshowed and evaluated.
We take this proposal, butapplied to manual anaphora annotation.Due to the corpus has been annotated with syn-tactic information, and the sense of each word ismarked with the offset number of EuroWordNet,it is possible to extract semantic features of eachverb and noun through the ontological concepts ofthe EuroWordNet?s Top Ontology.
Furthermore, thecorpus has been annotated with syntactic roles, soit is possible to extract syntactic patterns formed bythe verb and its main complements: subject-verb,verb-direct objects, verb-indirect objects.As we will show bellow, these patterns are use-ful in order to select the specific antecedent of ananaphora, according to semantic compatibility cri-teria between the antecedent and the verb of the sen-tence where the anaphora appears.4 Discourse annotation: anaphora andcoreferenceAt discourse level, our objective is to annotate theanaphora and the coreference, in order to developuseful resources for anaphora resolution systems.We agreed to annotate the anaphoric elementsand their antecedents.
These anaphoric elements arethe anaphoric ellipsis, the pronominal anaphora andthe coreferential chains.Specifically, in each one, we mark:?
Anaphoric ellipsis:?
The elliptical subject, made explicit in thesyntactic annotation step.
Being a nounphrase, it could also be an antecedent too.Unlike English, where it is possible anexpletive pronoun as subject, in Spanishit is very common an elliptical nominalphrase as subject of the sentence.
This iswhy we have decide to include this kindof anaphora in the annotation process.?
Elliptical head of nominal phrases withan adjective complement.
In English,this construction is the ?one anaphora?.In Spanish, however, the anaphoric con-struction is made up by an elliptical headnoun and an adjective complement.?
Anaphora: Two kinds of pronouns:?
The tonic personal pronouns in the thirdperson.
They can appear in subject func-tion or in object function.?
The atonic pronouns, specifically theclitic pronouns that appear in the subcate-gorization frame of the main verb.?
Finally, there are sets of anaphoric and ellipti-cal units that corefer to the same entity.
Theseunits form coreferential chains.
They must bemarked in order to show the cohesion and co-herence of the text.
They are annotated bymeans of the identification of the same an-tecedent.We do not annotate the definite descriptions.They consist of nominal phrases that can refer (ornot) to an antecedent.
We do not mark them becausethey outline specific problems that make this taskvery difficult: firstly, there are not clear criteria thatallow us to distinguish between coreferential andnot coreferential nominal phrases; secondly, thereare not a clear typology for definite descriptions;and finally, there are not a clear typology of rela-tionships between the definite description and theirantecedents.
These problems could further increasethe time-consuming in the annotation process andwiden the gap of disagreement between the humanannotators.This proposal of annotation scheme is based onthe one used in the MUC (Message UnderstandingConference) (Hirschman, 1997) as well as in theworks of Gaizauskas (Gaizauskas and Humphreys,1996) and Mitkov (Mitkov et al, 2002): this isthe mostly used scheme in coreferential annotation(Mitkov, 2002).In the anaphoric annotation, two linguistic ele-ments must be marked: the anaphoric expressionand its antecedent.
In the antecedent we annotatethe following information:?
A reference tag that shows the presence of anantecedent (?REF?),?
An identification number (?ID?),?
The minimum continuous substring that couldbe considerer correct (?MIN?
).In the coreferential expression, we annotate:?
The presence of a coreferential expression(?COREF?),?
An identification number (?ID?),?
The type of anaphoric expression: ellipticalsubject, elliptical head of noun phrase, tonicpronoun or atonic pronoun (?TYPE?),?
The antecedent, through its identification num-ber (?REF?),?
Finally, a status tag where the annotators showstheir confidence in the annotation (?STA-TUS?
).As previously mentioned in this paper, the mainproblem in the anaphoric annotation is the lowagreement between human annotators.
There is usu-ally less agreement in anaphoric annotation than insyntactic annotation ((Mitkov, 2002), 141).
In orderto reduce this low agreement, we annotate only theclearest type of anaphoric units (pronouns, ellipti-cal subjects and elliptical nominal heads), and weintroduce the lowest necessary information.
More-over, with the tag ?STATUS?, the human annotatorcan show his confidence in the anaphoric unit andthe antecedent marked.
However, at the moment, asoccurs in the semantic annotation, we do not haveenough data on the agreement between annotators.4.1 Manual annotation with an EnrichedAnaphora Resolution SystemAs we said before, we follow a manual anaphora an-notation with the help of a Enriched Anaphora Res-olution System: our idea is to check the automaticannotation of the anaphora resolution system and tocorrect mistakes in the annotation process.In manual anaphora and coreferential annota-tion, the human annotator first locates a possibleanaphora, and then must read back the text untilthe antecedent appears.
With an anaphora resolu-tion system it is possible to automatize this pro-cess: the system selects possible anaphoric ele-ments, their possible antecedents, and decides themain candidate.
The human annotator must onlycheck the suggestion.
The process is more usefulbecause the most tedious task (to select a possibleanaphora, to read back looking for the antecedent,etc.)
is made up by the system.
When the humanannotator checks the solution, he does not read backfor antecedents, he goes directly to the possible an-tecedents.However, the anaphora resolution system must bevery accurate.
In order to automatically specify theantecedent of an anaphora and ensure the correct-ness of the system, we use all the linguistic infor-mation previously annotated in the corpus: morpho-logical, syntactic and semantic.
In this knowledge-based anaphora resolution system, the linguistic in-formation is used through a set of restrictions andpreferences.
Following this strategy, the system re-jects possible antecedents until only one is selected.The key point is the linguistic information used inrestrictions and preferences.We have developed a semantically enrichedanaphora resolution system in order to aid the dis-course annotation level.
EuroWordNet synsets arethe base of the semantic information added to theresolution process.
The fact of counting with a se-mantically annotated corpus such as Cast3Lb facil-itates the use of the anaphora resolution method,based on a natural way of understanding the humanprocess for anaphora resolution.The specific use of semantic information is re-lated to the sematic compatibility between the possi-ble antecedent (a noun) and the verb of the sentencein which the anaphoric pronoun appears.
Due to thepronoun replaces a lexical word (the antecedent),the semantic information of the antecedent mustbe compatible with the semantic restrictions of theverb.
In other words, the anaphoric expression takesthe semantic features of the antecedent, so they mustbe compatible with the semantic restrictions of theverb.In this way, verbs like ?eat?
or ?drink?
will bespecially compatible with animal subjects and eat-able and drinkable objects than others.In our case, the semantic features of the lexi-cal words have been extracted form the ontologi-cal concepts of EuroWorNet, that is, the Top On-tology.
All the synsets in EuroWordnet are seman-tically described through a set of base concepts (themore general concepts).
In the EuroWorNet?s TopOntology, these base concepts are classified in thethree orders of Lyons (Lyons, 1977), according tobasic semantic distinctions.
So through the top on-tology, all the synsets of EuroWordNet are seman-tically described with concepts like ?human?, ?an-imal?, ?artifact?, etc.
With this, we have extractedsubject-verb, verb-direct object and/or verb-indirectobject semantic patterns.From this semantic patters, rules about the se-mantic compatibility between nouns and verbs havebeen extracted.
These rules are applied to theanaphora resolution as preferences.
Based on thepatterns, the system calculates the compatibilitybetween the verb of the sentence in which theanaphora appears and the antecedent.
So the possi-ble antecedents with low compatibility are rejected,and the antecedents with high compatibility are se-lected.
These semantic preferences, plus the syn-tactic and morphological restrictions and prefer-ences, are used to select the correct antecedent ofthe anaphora.Furthermore, semantic information is also used insome rules.
There are two kind of rules:?
?NO?
rules: NO(v#sense,c,r) defines the in-compatibility between the verb v (and it sense)and any name which contains ?c?
in its ontolog-ical concept list, being ?r?
the syntactic func-tion that relates them.?
?MUST?
rules: MUST(v#sense,c,r) definesthe incompatibility between the verb v (and itssense) and all the names that don?t contain ?c?in their ontological concept list, being ?r?
thesyntactic function that relates them.At the final annotation step, the annotator checksif the antecedent selected is the correct one or not,and, in each case, confirms the annotation or cor-rects it.5 Tools5.1 3LB-SAT3LB-SAT (Semantic Annotation Tool) is a tool forthe semantic tagging of multilingual corpora.
Mainfeatures of this tool are:?
it is word-oriented,?
it allows different format for input corpus; ba-sically, the main formats used in corpus anno-tation: treebank format (TBF) and XML for-mat;?
it uses EuroWordNet as a lexical resource.For the XML format a DTD has been defined, thatallows to describe the information structure in eachfile of the corpus.In the annotation process, monosemic words areautomatically annotated.
So, 3LB-SAT is used toannotated only the polysemic words.
When a fileis loaded, all lemmas of the file are shown (Fig-ure 1).
The tool uses different colors to indicate thestate of the annotation process: (i) no occurrence ofthe lemma in the file has been annotated, (ii) someoccurrences of the lemma in the file have been an-notated, or (iii) all the occurrences have been an-notated.
When the annotator selects a lemma, allits occurrences are shown.
The selection of one ofthem shows all possible senses, and the annotatorchooses the correct one for this specific context.Figure 1: 3LB-SAT semantic annotation tool.5.2 3LB-RAT3LB-RAT (Reference Annotation Tool) is a tool de-veloped in 3LB project for the annotation and su-pervision of anaphora and coreferences at discourselevel.The tool provides the annotator with two workingways: manual and semiautomatic.
In the first one,the tool locates and shows all possible anaphoricand coreference elements and their possible an-tecedents.
The annotator chooses one of these pos-sible antecedents and indicates the certainty degreeon this selection (standby, certain or uncertain).There are some exceptional cases that the tool al-ways offers:?
cases of cataphora,?
possible syntactic mistakes (that will be used toreview and to correct the syntactic annotation),?
the possibility of a non-located antecedent,?
the possibility that an antecedent doesn?t ap-pear explicitly in the text,?
the possibility of non-anaphora, that is, the sys-tem has not correctly located an anaphoric ex-pression.In the semiautomatic way, the tool solves eachcoreference by means of the enriched resolutionanaphora method previously explained.
So the sys-tem proposes and shows the most suitable candidateto the annotator.
The annotator can choose the solu-tion that the resolution method offers in all cases, orchoose another solution (manually).3LB-RAT has been developed in Python lan-guage, which guarantees the portability to any Win-dows or Unix platform.
It deals with XML files:it is designed to work and to understand the formatused by the 3LB-SAT tool, but it is able to acceptany other XML specification.As we said before, the tool uses syntactic, mor-phologic and semantic information for the specifi-cation of an anaphora and its antecedent.
The se-mantic information used by the tool is limited toontology concepts and synonymous.
From the se-mantically annotated text, three tables are created,one for each syntactic function: subject, direct ob-ject and indirect object.
In these tables the appear-ance frequency of nouns with verbs (with their cor-rect senses) is stored.
These tables are the base toconstruct the semantic compatibility patterns, whichindicate the compatibility between the ontologicalconcept related with the possible antecedent and theverb of the sentence where the anaphoric expressionappears.
In order to calculate this information, theoccurrence frequency and the conceptual generalitydegree in the ontology are considered.
In this case,a higher punctuation is given to the most concreteconcepts.
For example, ?Human?
concept gives usfurther information than ?Natural?
concept.
Thesepatterns are used in the semantic preferences appli-cation.
For a specific candidate, its semantic com-patibility is calculated from the compatible ontolog-ical concepts on the patterns.
The candidates withgreater compatibility are preferred.When the annotator selects a XML file to open,the possible anaphoric elements of the text and theircandidates are located, and each anaphora is solved.The system shows two lists (Figure 2): the lowerlist shows each anaphora located and its solution.When the annotator selects one of these elements,in the upper box appears the possible candidates listbesides the solution suggested by the system.
At thesame time, in the plain text, the anaphora and theselected candidates are shown with different colors.The annotator can choose any suggested option andthe certainty degree of this election, or accept thesolution given by the system.Figure 2: 3LB-RAT anaphoric annotation tool.6 ConclusionsThe main contribution of this paper is the applica-tion of semantic information to a manual anaphoraannotation process, based on the semantic relationbetween the anaphoric element and its antecedent atdiscourse level.The semantic and anaphoric annotation schemeof the Spanish corpus Cast3LB has been presented,and how anaphoric annotation has been improvedwith the semantic information annotated in previoussteps.
The annotation process is based on the helpof an anaphora resolution system: first, the systemdetects the anaphora and its antecedent, and then thehuman annotator checks the correctness of the auto-matic annotation process and solves possible mis-takes.
The system uses all the linguistic informa-tion previously annotated in the corpus, includingthe semantic information, in order to evaluate thesemantic compatibility between the antecedent andthe verb of the sentence in which the anaphora ap-pears.AcknowledgementsThe authors would like to thank Bele?n and Raquelfor their work in the manual annotation process.ReferencesM.
Civit, Ma.
A.
Mart?
?, B. Navarro, N.
Buf??,B.
Ferna?ndez, and R. Marcos.
2003.
Issues in theSyntactic Annotation of Cast3LB.
In 4th Inter-national Workshop on Linguistically InterpretedCorpora (LINC03), EACL03, Budapest.M.
Civit.
2003.
Criterios de etiquetacio?n y desam-biguacio?n morfosinta?ctica de corpus en Espan?ol.Sociedad Espaola para el Procesamiento delLenguaje Natural, Alicante.R.
Gaizauskas and K. Humphreys.
1996.
Quantita-tive evaluation of coreference algorithms in an in-formation extraction system.
In S. P. Botley andA.
M. McEnery, editors, Corpus-based and Com-putational Approaches to Discourse Anaphora,pages 143?167.
John Benjamins, Amsterdam.L.
Hirschman.
1997.
MUC-7 coreference task def-inition Message Understanding Conference Pro-ceedings.A.
Kilgarriff and M. Palmer.
2000.
Computer andthe Humanities.
Special Issue on SENSEVAL,volume 34.A.
Kilgarriff.
1998.
Gold standard datasets forevaluating word sense disambiguation programs.Computer Speech and Language.
Special Use onEvaluation, 12(4):453?472.J.
Lyons.
1977.
Semantics.
Cambridge UniversityPress, London.G.
A. Miller.
1990.
Wordnet: An on-line lexicaldatabase.
Intenational Journal of Lexicography,3(4):235?312.R.
Mitkov, R. Evans, C. Orasan, C. Barbu,L.
Jones, and V.Sotirova.
2002.
Coreferenceand anaphora: developing annotating tools, an-notated resources and annotation strategies.
InProceedings of the Discourse, Anaphora and Ref-erence Resolution Conference (DAARC 2000),Lancaster, UK.R.
Mitkov.
2002.
Anaphora resolution.
Pearson,London.B.
Navarro, M. Civit, Ma.
A.
Mart?
?, B. Ferna?ndez,and R. Marcos.
2003.
Syntactic, semantic andpragmatic annotation in Cast3LB.
In Proceed-ings of the Shallow Processing of Large Corpora.A Corpus Linguistics WorkShop, Lancaster, UK.H.
T. Ng and H. B. Lee.
1996.
Integrating Mul-tiple Knowledge Sources to Disambiguate WordSense: An Exemplar-Based Approach.
In Pro-ceedings of the 34th Annual Meeting of the As-sociation for Computational Linguistics, SantaCruz, California.M.
Saiz-Noeda.
2002.
Influencia y aplicacio?n depapeles sinta?cticos e informacio?n sema?ntica en laresolucio?n de la ana?fora pronominal en espan?ol.Ph.D.
thesis, Universidad de Alicante, Alicante.N.
Sebastia?n, Ma.
A.
Mart?
?, M. F. Carreiras, andF.
Cuetos.
2000.
2000 LEXESP: Le?xico Informa-tizado del Espan?ol.
Edicions de la Universitat deBarcelona, Barcelona.P.
Vossen.
1998.
A Multilingual Database with Lex-ical Networks.
Kluwer Academic Publisher.
