CUSTOMIZING AND EVALUATING A MULTILINGUAL DISCOURSE MODULEChinatsu AoneSystem Research  and App l i ca t ions  Corporat ion  (SRA)2000 15th Street  Nor thAr l ington ,  VA 22201emaih  aonec  @ sra .comABSTRACTIn this papeh we first describe how we have custom-ized our data-driven multilingu~fl discourse module withinour text understanding system lor dill'erent lm~guages andfor a particular NLP application by utilizing hierm'chic~dlyorganized discourse KB's.
Then, we report qum~titaliveand qmditative findings from ewduating the system bothwith and without discourse processing, ~md discuss howresolving certain kinds of mmphora ffects system perh)r-l nance .1 INTRODUCTIONAlthough previous discourse rese,'uch (cf Hobbs \[7\],Webber 191, Grosz mid Sidner 16/, etc.)
made significantcontributions at a theorelic~d level, the effectiveness ofdiscourse processing in NLP systems h~s not been studiedso Ira' at a practical level (of.
Walker \[8\]).
In systems usedin NLP applications such us the Message Underst,'uldingConferences (of.
14, 5 I), discourse processing is often not asep~u'ate module hut is pmt mid proeel of "template gener-ation."
Thus, the eflbct of different ypes of discourse pro-cessing on a pm'liculm" task has not been shown either.In addition, both at Iheoretical and practical levels, fewseem to have considered esigning discourse processing ina way that is customizable for multiple languages anddomains.
However, since discourse phenomena differmnong Imlguages mid even among domains within thesame language, it ix desirable that discourse processing becustonfizahle and its result ewduable.In this paper, we descril)e how we have customized ourmultilingual discourse module wilhin our tcxl understand-ing system for a pm'ticulm" I~mk (i.e.
data exla'action i  thejoint venture domain) in two different lmlguagcs (i.e.English mid Japanese), mid report he cwduation rcsul|s.2 DISCOURSE MODULEARCHITECTUREIn Aone ~ultl McKee \[2\], we have described our newlanguage- and domain-independent discourse modulewithin our text underslanding system.
In addition to beinglmlguage- mid domain-independent, themodule is ewdu-able m~d mfinable to different applications and domains.The discourse mchitecture is motiwtted by our need to portour text uuderstmlding system to diflcrent languages (e.g.English, Japanese, Spanish) mid to different dom~dns (of.Aone et al \[1\]).
The discourse mtxlule is strictly dam-~hiven so that mmphora resolution h)r different lmlguagesmid domains can be achieved sunply by selecling neces-sary dala.
It consists of one discourse processor (the Reso-lution Engine) and three discourse knowledge bases (theDiscourse Phenomenon KB, the Discourse KnowledgeSource KB, the Discourse Domain KB).
The DiscourseAdminisUator ix a developmenl-time tool for defitfiug thethree discourse KB's.
The m'chitecture is shown in FigureI.peFfortll-At~tllatlliC,gdeft,,, I \[ "q'~':YI)iscc,urs?
M~chlleFigure 1.
Discourse Architecture2.1 I)iscourse Knowledge BasesThe Discourse Knowledge Source KB houses smallwell-delined mmphora resolution strategies.
Each knowl-edge source (KS) is an object in the hierarchically orga-nized KB, and infl)rmation can be inherited from moregeneral to more specific KS's.
This KB consists of threekinds of KS's: generators, \[liters and orderers.
A generatoris uscd to generate possible anlecedent hypotheses fi'om acertain region of text.
Af i l te r  is used to eliminate impossi-ble hypotheses, while an ot~lerer is used to rmlk possiblehyl)othescs in a preference order if there is more than one.Most of the KS's are language-independen!
( .g.
all thegeneralors and the semanlic tilters).
Even when they arelanguage-specilic, a sub-KS can inherit information fromits superclass KS's while defining specific data lee:ally.
Forex,'unple, the Semantic-Gender-Filter KS 1 deliues onlyfunclional definition of this KS, while its sub-KS's forEnglish ~md Japanese ach specify \]~mguage-specific data~md inherit he stone funclioual definilion from their pro'on!KS.1.
Seluanlic-Gender-Filter filters out an antecedenthypothesis whose semantic gende1 is not consistentwith the restriction imposed by the syntaclic gender of~l p I 'O I IOHI | ,1109The Discourse Phenomenon KB contains hierarchi-cally organized discourse phenomenon objects (e.g.Nmne-Anaphora, DeIinite-NP) each of which specifies adefinition of the discourse phenomenon and a set of KS's(i.e.
generators, tilters, and orderers) to apply to resolvethis particular discourse phenomenon.
Because the dis-course KS's are independent of discourse phenomena, thestone discourse KS cm~ be shared by different discoursephenomena in different languages ,and domains.
For exam-pie, KS's such as Sem,-mtic-Type-Filter and Recency-Orderer are used by most discourse phenomena in multiplelanguages.Finally, the Discourse Domain KB contains discoursedomain objects each of which defines a set of discoursephenomena tohmldle in a particular domain.
Since texts indifferent domains exhibit different sets of discourse phe-nomena, and since dilt'erent applications even within thesame domain may not have to handle the same set of dis-course phenomena, the discourse domain KB is a way tocustomize ,and constrain the workload of tile discoursemodule.These three hierarchically organized discourse KB'smake it possible to share some of the discourse KB's whilealso being able to add language- mid domain-specitic dis-course data.2.2 Resolution EngineThe Resolution Engine is the run-time processingmodule which finds tile best ,antecedent hypothesis tot agiven ~maphor by using the discourse KB's describedabove.
First, it determines from the Discourse Dom~fin KBwhich discourse phenomena to handle giveu a particularlanguage ald domain.
Then, it uses the Discourse Phe-nomenon KB to classify ml auaphor as one of the dis-course phenomena and to decide which KS's to apply to it.Next, the Engine applies appropriate generator KS's to get,'m initial set of antecedent hypotheses, mid then applies fil-ter KS's to remove inconsistent hypotheses.
When there ismore than one hypothesis left, orderer KS's specified inthe Discourse Phenomenon KB are invoked to rank thehypotheses.3 CUSTOMIZING DISCOURSE KB'SWe have customized our discourse KB's to perform adata extraction t,'~sk in the joint venture domain.
Our textunderstanding system takes English mid Japanese newspa-per articles about joint ventures as input (cf.
Figure 2), andoutputs database templates (eL Figure 3).
The system hasto extract from the ,articles infonnation regm'ding whichorganizations participate iu a joint venture (including anew joint venture compmly if any), what the purpose oftile joint venture is (e.g.
selling coal), who tim people m'ethat are associated with these organizations, etc.
We madea task-oriented decision that handling organization mm-phora, both definite NPs (e.g.
"the company") and nameanaphora (e.g.
"Toyota" for "Toyota Motors Corp."), is atop priority initially in order to improve performance.Thus, we created in the Discourse Domain KB a discoursedomain object called JV-Data-Extraction which specifiesthat two discourse phenomenon objects from the Dis-course Phenomenon KB, namely mune anaphora (DP-Nmne) mid definite NP anaphora for orgmlizations (DP-DNP-Orgmlization), should be handled ill this applicationdomain.NEW YORK -- A joint veature to export confrom tile United States has been lbnned betweenM&M Ferrous America Ltd. here and CrownCoal & Coke Co., Pittsburgh.Coal obtained by Crown lroln v,'u-ious domes-tic mines will be marketed oflMlore by M&M, alrading colnp~my formed six years ago by formerPhilippiBrothers Inc. employees.
Crown, whichformerly had its own mines, heretofore marketedcoati from v,'uious ources to domestic steehnak-ers only, according to Eric S. Katzenstein, M&Mvice president.
((omitted))Eastern European countries uch as Rommlia arelikely mm'kets, he said.Figure 2.
All Exmnple o1' Input Text<TIE UP REI, ATIONSHII'-2975348 1> :=TIlL U P S TAT\[ IS: EXISTINGENTITY: <ENTITY-2975348-1> <F,NTITY-2975348-2>ACTIVITY: <ACTIVITY-2975348-1><ENTITY-2975348-1 > :=NAME: M&M Ferrous America I,TDAMASES: "M&M"I,OCATION: New York (CITY 4) New York (PROVINCE 1)United States (COUNTI),Y)TYPE: COMPANYPERSON: <PERSON-2975348-1><ENTITY-2975348-2> :=NAME: Crown C~al & Coke COA/JASI~ : "(?rowll"I,OCAT\[ON: Pittsburgh (CITY 4) Pem~sylwtnia (IqU)VINCF, 1)United States (COUNTRY)TYPE: COMPANY<INDUSTRY-2975348-1> :=IN D\[ ISTRY-TYPE: S ALESPRODUCT/SERVICE: (50 "Crown's coal")<ACTIVITY-2975348-1 > :=\[NDUSTRY: <INDUSTRY-2975348 1>ACTIVITY-SIT|';: (Romania (COUNTRY) <ENTITY-2975348-1>)<PERSON-297534g- 1 > :=NAME: Eric S. KatzensteinPERSON'S ENTITY: <I.
;NTITY-2975348- I >POSITION: SREXECFigure 3.
An Exmnple ofau Output Template3.1 Name AnaphoraIn order to resolve name ~maphora, English mid Japa-nese share some of the KS's ill tile Discourse KnowledgeSource KB, nmnely Current-Text-General01; Semmltic-1110Type-Filter, and Recency-Orderer.
Tiffs generator gener-ates all the possible antecedenl hypotheses up to the cur-rent sentence.
The Semantic-Type-Filter hen checks if ricesemantic type of amphor is consistent with that of an ;mte-cedent \[iypothesis.
When there is more than one hypothe-sis left, the Recency-Orderer orders the hypothesesaccording to their proximity to the ataphot.In addition to the three lmcguage-independent KS's,each h'mguage uses a language-specific lilter.
For English,a filter named Englis\[i-N,'une-Filter, which matches ananaphor (e.g.
"Crown") with a subsequence of a~ mtte-cedent nane  string (e.g.
"Crown Coal & Coke CO"), iscurrently employed.
For Japatese, mt additional sittgle fil-ler called Japanese-N,'une-Filter covers seemingly vastwu'iatious of Japanese company crane anaphora 2.
This KSmatches an attuphor with any conthiualion of characters inan ~mtecedenl as long as the character order is preserved(e.g.
"abe" can be an anaphor of "abede").
One exceplionis lhal a~ mtaphor c~m have an extra word "s\[ia" at the endthat is not a part of flte fnll company mune or a compmtyacronym (e.g.
"Westinghouse (WH)" can be refen'cd toauapltoric~dly b "Weslinghouse-sha" or "WH-sha").3.2 Definite NPAttother discourse phenomctton which is handled lorthis lask ix definite NPs relerriug Io organizations such as"the venture," the West Germ+m electronics concern,"etc., where the words "venture" and "cottcern" in thesecotttexts point to subcltksses of I/to semanlic oncept l+or anorg~utization.
Although Japanese does not have a delinitearticle, in writlen Japmlese the word "dou" (literallymeaning "lice sane")  prefixed to certain nout~s performsapproximately the sane function ~Ls English tlelinite a'tiele"the".
Both English and Japatese currently share thesane three KS's (i.e.
Current-Text-Generatoc', Semantic-Type-Filter, Recency-Orderer) lot delinite NP resolution.Additionally, English uses Syntactic-Number-Filter,which checks if the syntaclic nnmber of the anaphor isconsistent with that of ~m anlecedent hypolhesis.
AlthoughJapalese does not exhibit syntactic number distinction, a"don" phr~Lse can only refer semmttic~dly Io a singleentity.
3 Thus, Japanese uses Semanlic-Amount-Eilter,which exchtdes emantically plural entities (e.g.
a con-joined NP, ~m NP with a plural qnmttifier) as possible aate-cedents for a "dou" phrase.4 EVALUATION RESUI : I 'Shi this section, we will report onr evahtalion results.We ran 100 Japanese and 100 English blind test joint vett-2, For example:~\ [~(~H~f~) ,  ~?,~,~ (~.
,~2Z~),  ?
.3.
A definite plural NP can be expressed in Japanese bya numeral or numerical quantilier plus a classifier, as in"ryousha" (file two companies) and "san-sha" (thethree companies).lure ,'uticlcs through our text uuderslmlding system withand without the discourse module turned on, and scoredthe resnlls using an automalic scoring prognam.
The scor-ing program uses a scoring metric from informationretrieval, and reports recall and precision for each slot inthe lemplates as well as a single combined score called F-measure 4 for overall perforlnance (of.
1141).It shouM be noted that this ewduation is a blackboxewduation of the syslem as used in a particular applicationtask.
Consequently, the results do not directly reflect theperfonn~mce of the discourse module itself?
For cxanple,this task does not require all company name anaphora (i.e.aliases) to be reported, but only those which are involvedin joint ventures.
Also, the causes of task l~tilure or successare somelimes due to the lhilure or success of system mod-ules other ttum the discourse module.
For instance, the pro-processing system does not always recognize companynames which me potential autecedenls.
On the other hard,the preprocessing module rather than the discourse modulesometimes recognizes compaty acronyms as aliases.Thus, the resnlts of the hlackbox ev~dnation reflect moreon how the discourse module helps the whole system per-Ibnn a p~uticular task.4.1 Name AnaphoraIt is clem* that the perlbnmmce of name auaphora reso-htlion is directly linked to how well the system tills in theALIASES slot in the output emplates (of.
Figure 3), The100 Japanese texts required idenlifying a total of 127 com-pany name aliases.
With the discourse module tnnted on,the recall of Ihc ALIASES slot increases by 38 poinls andthe precision by 16 points.
Though the set of KS's used fornane amphora was mostly satisihctory, we lound oneproblem paticular to this domain in tx~th l~mguages.
Sincethe texts arc in the joint venture domain, it is often i\[ie c~tsethat the nane of a new joint venture company (e.g.
"'Chrysler Japan") overlaps the nanes of its p~u'ent corn-panics (e.g.
"Chrysler Corp.").
Wlten the text nses a naneanaphor (e.g.
"Chrysler"), it must refer to the pm+ent com-pany even when the joint venture company is mentionedmost recently.
We are plmming to add another ordererwhich preli~rs the pm'ent company when there is such aconllicl.4.2 I)elinite NPWe hyt?
)thesized that resolving delinitc NP's affectsthe extraclion of information about which company is per-forming which "economic activity" in a joint venture (e.g.Compaty A will nlanufaelufe ca's while Company B willmm'ket hem), since snch information appem's later in at4.
F-measure is calculated by:( \[\]7, + 1.0) x 1' x R1~2 x f '+Rwhere 1' is precision, R is recall, and \[\] is the relativeimportmtce given to recall over precision.
In this case,~= 1.0.111Iarticle after compmties involved ill It joint venture are"already introduced into the discourse (e.g.
"Publishingrivals Time Inc. and New York Thnes Co. said they agreedill principle to form ajointiy owned national magazine dis-tribution partnership...
The joint venture will continue tomarket mag~ines currently marketed by Tune Distribu-tion...").Under the same test condition as above, the precisionof the relevant slot (i.e.
ACTIVITY-SITE slot ill Figure 3)increased by 5 points in JapaJmse when discourse process-ing was used.
The recall was not affected much by the dis-course processing; it increased only by 1 point.
In theEnglish test, the changes in both precision and recall werenegligible.
One of the reasons for this less drastic incre~tseof this slot value is that the sentence xpressing economicactivities do not always use delinite NPs for the agents ofsuch activities.
Such agents can be expressed by namemlaphora or pronouns or, often in English, by implicit sub-jects of infinitives, as in "Siemens AG and GTE Corp.agreed to set up a new holding eomp~my in West Germanyto oversee their telecommunications joint venture...".In addition, examination of the test results howed thatwhen there are more than one antecedent hypothesis, topicmarking (using particle "wa") plays a more significantrole in determining the antecedent of a Japmmse "dou"definite NP th,'m recency.
At the time of the testing, how-ever, we were not using topic marking infonnafion to pre-fer topicalized amecedent hypotheses.
Another findingwhich is true of both Japanese and English is that definiteNP ,'maphora resolution often requires pragmatic infercnc-ing ill order to obtain a fact which is not explicitly slated inthe text.
For ex,-unple, in order to resolve the definite NP inthe senteuce "Chevron, an oil company, also said itacquired Rhonc-Poulenc's 30% interest in PetrosyntheseS.A., boosting its holding in the French joint venture to65%," the discourse module has to infer either thatPetrosyuthese S.A. is a French comp~my (perhaps from thecompany designator?)
or that acquiring someone's holdingill a company increases one's holding in that company.
Wcare currently adding KS's which m~dce use of topic infor-mation and pragmatic inferencing, ,and also investigatingwhich combinations of KS's will optimize discourse pcr-fo iTllallce.Furthermore, we think that very little ch,-mge in recallis due to the fact that the system a~ssumed tile parent com-panies to be the value of ACTIVITY-SITE when it isundetermined.
Thus, this detault value kept the recall ofthe system without discourse processing higher, mid them-fore the ACTIVITY-SITE slot was not as good an indica-tor of the discourse module performance as the ALIASESslot.It is interesting to note that ml approach like Dagan ~u~(IItai's \[3\], which uses statistical data on semantic selec-tional restriction that is automatically acquired from largecorpora to resolve anaphora 5, tines not work well in thisdomain.
This is because a typical text in this domain con-tains at least two lX)ssible antecedents (joint venture part-ners m~d possibly a joint venture comp~my) of the s~unesemm~tic type, munely organization, hn" a delinite NP ana-phora referring to organizations.4.3 Overall PerformanceOverall, discourse processing increased the systemperh~rmance measured by tile combination of overallrecall mid precision scores (i.e.
F-measure) by 4 points inJapanese, mostly due to ~m overall increa.se in precision.Interestingly, the discourse processing helped also in theidentification of links between organizations mid people,,'~s indicated by the PERSON slot of the <ENTITY> object,'rod the PERSON'S ENTITY slot of tile <PERSON>object (cf.
Figure 3).
With the discourse processing lungedon, the recall of both PERSON and PERSON'S ENTITYslots incre~Lsed by 7 points, and the precision by 10 pointsand 12 points respectively.We think that this is because when a person associatedwith an organization is mentioncd, the company mune orthe person's naJne is often an anaphoric form as in "CarlosM.
Herrera, president of Preferred," or "Katzenstein, aformer executive with Bomar Resources Inc.".
In order toundersUmd the relation between ,'m organization and a per-son as in "Eric S. Katzenstein, M&M vice president" (cf.Figure 2), tile system has to recognize both the alfilialionlink between the person and the comDmy hnplicit in tileappositive phrase, and the mmphoric link between Iheobjects under different aliases.
Our discourse moduletakes care of both identifying appositive relations (e.g.Eric S. Katzenstein is vice presideu0 and resolving u~uneanaphora (e.g.
"M&M" refers to "M&M Ferrous AmericaLtd.
").5 CURRENT AND FUTURE WORKIn this paper, we have described our multilingual dis-course module mid ils customized iscourse KB's, andreported the blackbox ewduation results when it was usedin a data extraction task in the joint venture domain.
Cur-rently we arc working on the following two research areasin order to improve anaphora resolution.First, we are experimenting with ways to automateIraining of anaphora resolulion by applying machine learn-ing so that the discourse module can be castomized auto-maritally to a p~ticular hmguage, domain or applicationwithout extensive manual knowledge engineering.
Illorder to obtain feedback liar training, we must be able toautomate glassbox evaluation of discourse processingitself.
For this, we have built Iwo tools: a discourse tag-ging tool and a discourse valuation tool.
The former hasbeen used to tag texts with discourse relations, while tilelatter lakes discourseqagged corpora as a key and the sys-tem output as results to be ev~duated.5.
According to theu approach, for a sentence "It wasgoing to collect it," "governnmnt" is a preferred ante?cedent of the first "it," while "money" is of the sec-ond, using such statistics.11"12Second, we are expanding the rm~ge of anaphoric phe-nomena which our discourse module can hmldle.
Theyinclude overt pronouns in English mM Spanish, and zeropronouns in Japanese and Spmfish.REFERENCESI1\] Chinalsu Aone, Hatte Blcjcr, Sharon Flank, DouglasMcKee, and SmMy Shinn.
The Murasaki Project:Multilingual Natural Language UnderslmMing.
InProceedings of the ARPA Human Language Technol-ogy Wvrkshop, 1993.12\] Chinatsu Aone and Dougl,~s McKce.
Language-Inde-pendent Anaphora Resolution System lot Under-standing Multilingu~d "lbxls.
In Proceedings of 31stAnnual Meeting of the ACL, 1993.1131 Ido Dagml ~md Alon llai.
Aulomatic Acquisition ofConstraints for Ihe Resolution of Anaphora Refer-ences and Synlactic Ambiguities.
In Proceedings ofthe 13th International Cot!ference on ComputationalLinguistics, 1990.141 Delense Adwmced Resem'ch Projecks Agency.
Pro-ceedings of t"ourth Message Understanding Confi~r-ettce (MUC-4).
Morgml Kauflmmn Publishers, 1992.\[51 Adwmced Resem'ch Pro}ecls Agency.
Proceedings ofFourth Message Understanding Cot(erence (MUC-5).
Morg,'m Kaufinmm Publishers, 1993.16\] Bm'bara Grosz and Candace L. Sidner.
Attentions,hltenl.iol~s alld file Strtlcture of Discourse.
Cotttpula-tional Linguistics, 12, 1986.171 Jen'y R. Hobbs.
Pronoun Resolution.
TechnicalReport 76-1, Depmlmenl of Computer Science, CityCollege, City University of New York, 1976.\[81 Marilyn A. Walkel; Evaluating Discourse ProcessingAlgorithms.
In Proceedings of 27th Annual Meetingof the ACL, 1989.191 Bonnie Webber.
A Formal Approach to DiscourseAnaphora.
Technical report, Bolt, Beranek, and New-mini, 1978.1113
