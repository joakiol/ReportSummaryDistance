Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries, pages 104?109,Jeju, Republic of Korea, 10 July 2012. c?2012 Association for Computational LinguisticsCombining OCR Outputs for Logical Document Structure MarkupTechnical Background to the ACL 2012 Contributed TaskUlrich Sch?fer Benjamin WeitzDFKI Language Technology LabCampus D 3 1, D-66123 Saarbr?cken, Germany{ulrich.schaefer|benjamin.weitz}@dfki.deAbstractWe describe how paperXML, a logical docu-ment structure markup for scholarly articles,is generated on the basis of OCR tool out-puts.
PaperXML has been initially developedfor the ACL Anthology Searchbench.
Themain purpose was to robustly provide uni-form access to sentences in ACL Anthologypapers from the past 46 years, ranging fromscanned, typewriter-written conference andworkshop proceedings papers, up to recenthigh-quality typeset, born-digital journal arti-cles, with varying layouts.
PaperXML markupincludes information on page and paragraphbreaks, section headings, footnotes, tables,captions, boldface and italics character stylesas well as bibliographic and publication meta-data.
The role of paperXML in the ACL Con-tributed Task Rediscovering 50 Years of Dis-coveries is to serve as fall-back source (1) forolder, scanned papers (mostly published be-fore the year 2000), for which born-digitalPDF sources are not available, (2) for born-digital PDF papers on which the PDFExtractmethod failed, (3) for document parts wherePDFExtract does not output useful markupsuch as currently for tables.
We sketch trans-formation of paperXML into the ACL Con-tributed Task?s TEI P5 XML.1 IntroductionWork on the ACL Anthology Searchbench started in2009.
The goal was to provide combined sentence-semantic, full-text and bibliographic search in thecomplete ACL Anthology (Sch?fer et al, 2011), anda graphical citation browser with citation sentencecontext information (Weitz & Sch?fer, 2012).
Sincethe ACL-HLT 2011 conference, the Searchbench isavailable as a free, public service1.A fixed subset of the Anthology, the ACL An-thology Reference Corpus2 (ACL-ARC), containsvarious representations of the papers such as PDF,bitmap and text files.
The latter were generatedwith PDFBox3 and OCR (Omnipage4), applied tothe PDF files or bitmap versions thereof.
Its staticnature as infrequently released reference corpus andlow character recognition quality especially of older,badly scanned papers, made us to look for alterna-tives.
For quick, automatic updates of the Search-bench index, a robust method for getting the textfrom old and new incoming PDF files was needed.After a thorough comparison of different PDF-to-text extraction tools, a decision was made to processevery PDF paper in the Anthology with ABBYYPDF Transformer5, for various reasons.
It ran stablyand delivered good character recognition rates onboth scanned, typewriter-typeset proceeding papersas well as on born-digital PDF of various sources,even on papers where PDFbox failed to extract (us-able) text.
Reading order recovery, table recognitionand output rendering (HTML) was impressive andde-hyphenation for English text worked reasonablywell.
All in all, ABBYY did not deliver perfect re-sults, but at that time was the best and quickest so-lution to get most of the millions of sentences fromthe papers of 46 years.The role of this OCR-based approach in the ACL1http://aclasb.dfki.de2http://acl-arc.comp.nus.edu.sg3http://pdfbox.apache.org4http://www.nuance.com/omnipage5http://www.abbyy.com104Contributed Task Rediscovering 50 Years of Discov-eries (Sch?fer et al, 2012) is to serve as fall-backsource when the more precise PDFExtract method(Berg et al, 2012) is not applicable.2 Target FormatThe focus of the Searchbench text extraction processwas to retrieve NLP-parsable sentences from scien-tific papers.
Hence distinguishing running text fromsection headings, figure and table captions or foot-notes was an important intermediate task.PaperXML is a simple logical document markupstructure we specifically designed for scientific pa-pers.
It features tags for section headings (with spe-cial treatment of abstract and references), footnotes,figure and table captions.
The full DTD is listedin the Appendix.
A sample document automaticallygenerated by our extraction tool is displayed in Fig-ure 2 on the next page.
In paperXML, figures areignored, but table layouts and character style infor-mation such as boldface or italics are preserved.3 AlgorithmVolk et al (2010) used two different OCR prod-ucts (the above mentioned Omnipage and ABBYY)and tried to improve the overall recognition accuracyon scanned text by merging their outputs.
This ap-proach adds the challenge of having to decide whichversion to trust in case of discrepancy.
Unlike them,we use a single OCR tool, ABBYY, but with two dif-ferent output variants, layout and float, that in partscontain complementary information.
As no directXML output mode exists, we rely on HTML outputthat can also be used to render PDF text extractionresults in a Web browser.3.1 Core rich text and document structureextractionOur algorithm uses the layout variant as primarysource.
Layout tries to render the extracted text asclosely as possible to the original layout.
It pre-serves page breaks and the two-column formattingthat most ACL Anthology papers (except the CLJournal and some older proceedings) share.In the float variant, page and line breaks as wellas multiple column layout are removed in favour of arunning text in reading order which is indispensablefor our purposes.
However, some important layout-specific information such as page breaks is not avail-able in the float format.
Both variants preserve tablelayouts and character style information such as bold-face or italics.
Reading order in both variants maydiffer.
A special code part ensures that nothing islost when aligning the variants.We implemented a Python6 module that readsboth HTML variants and generates a consolidatedXML condensate, paperXML.
It interprets textualcontent, font and position information to identify thelogical structure of a scientific paper.Figure 1: PDF-to-paperXML workflowFigure 1 depicts the overall workflow.
In addi-tion to the two HTML variants, the code also readsBIBTEX metadata in XML format of each paper.A rather large part in the document header of thegenerated paperXML addresses frontpage and bib-liographic metadata.
Section 3.2 explains why andhow this information is extracted and processed.Using XSLT7, paperXML is then transformed intoa tab-separated text file that basically contains onesentence per line plus additional sentence-related6http://www.python.org7http://www.w3.org/TR/xslt105<?xml version="1.0" encoding="UTF-8"?><article><header><firstpageheader><page local="1" global="46"/><title>Task-oriented Evaluation of Syntactic Parsers and Their Representations</title><pubinfo>Proceedings ofACL-08: HLT,pages 46-54, Columbus, Ohio, USA, June 2008.
?2008 Association [...]</pubinfo><author surname="Miyao" givenname="Yusuke"><org name="University of Tokyo" country="Japan" city="Tokyo"/></author>[...]</firstpageheader><frontmatter><p><b>Task-oriented Evaluation of Syntactic Parsers and Their Representations</b></p><p><b>Yusuke Miyao<footnote anchor="1"/>" Rune Saetre<footnote anchor="1"/>" Kenji Sagae<footnote anchor="1"/>" Takuya Matsuzaki<footnote anchor="1"/>" Jun?ichi Tsujii<footnote anchor="1"/>"** </b>^Department of Computer Science, University of Tokyo, Japan * School of Computer Science, University of Manchester,UK *National Center for Text Mining, UK</p><p>{yusuke,rune.saetre,sagae,matuzaki,tsujii}@is.s.u-tokyo.ac.jp</p></frontmatter><abstract>This paper presents a comparative evaluation of several state-of-the-art English parsers [...]</abstract></header><body><section number="1" title="Introduction"><p>Parsing technologies have improved considerably in the past few years, and high-performance syntactic parsers areno longer limited to PCFG-based frameworks (Charniak, 2000; [...]</p></section><section number="2" title="Syntactic Parsers and Their Representations"><p>This paper focuses on eight representative parsers that are classified into three parsing frameworks:<i>dependency parsing, phrase structure parsing, </i>and <i>deep parsing.</i> [...] </p><subsection number="2.1" title="Dependency parsing"><p>Because the shared tasks of CoNLL-2006 and CoNLL-2007 focused [...] </p><p><b>mst </b>McDonald and Pereira (2006)?s dependency parser,<footnote anchor="1"/> based on the Eisneralgorithm for projective dependency parsing (Eisner, 1996) with the second-order factorization.</p><footnote label="1">http://sourceforge.net/projects/mstparser</footnote><figure caption="Figure 1: CoNLL-X dependency tree"/></subsection>[...]<subsection number="4.2" title="Comparison of accuracy improvements"><p>Tables 1 and 2 show the accuracy [...] </p>[...]<p>While the accuracy level of PPI extraction is the similar for the different parsers, parsing speed differs significantly.<page local="7" global="52"/> The dependency parsers are much faster than the other parsers, [...] </p><table caption="Table 1: Accuracy on the PPI task with WSJ-trainedparsers (precision/recall/f-score)" class="main" frame="box" rules="all" border="1" regular="False"><tr class="row"> [...]</table><section title="Acknowledgments"><p>This work was partially supported by Grant-in-Aid for Specially Promoted Research (MEXT, Japan) [...]</p></section><references><p>D.
M. Bikel.
2004.
Intricacies of Collins?
parsing model.
<i>Computational Linguistics, </i>30(4):479-511.</p><p>T.
Briscoe and J. Carroll.
2006.
Evaluating the accuracy of an unlexicalized statistical parser on the PARC [...]</p>[...]</references></body></article>Figure 2: An example of an automatically generated paperXML version of the ACL Anthology document P08-1006.Parts are truncated ([.
.
. ])
and some elements are imbalanced for brevity.106characteristics such as type (paragraph text, head-ing, footnote, caption etc.)
page and offset.
Thisoutput format is used to feed NLP components suchas taggers, parsers or term extraction for the Search-bench?s index generation.
On the right hand side ofthe diagram, we sketch a potentional transformationof paperXML into TEI P5 for the Constributed Task.It will be discussed in Section 4.The extraction algorithm initially computes themain font of a paper based on the number of char-acters with the same style.
Based on this, heuris-tics allow to infer styles for headings, footnotes etc.While headings typically are typeset in boldface inrecent publications, old publications styles e.g.
useuppercase letters with or without boldface.On the basis of this information, special sectionheadings such as abstract, and references areinferred.
Similarly, formatting properties in com-bination with regular expressions and Levenshteindistance (Levenshtein, 1966) are used to identifyfootnotes, figure and table captions etc.
andgenerate corresponding markup.A special doubt element is inserted for text frag-ments that do not look like normal, running text.3.2 Bibliographic metadata and authoraffiliationsConference or publication information can often befound on the first page footer or header or (in case ofthe CL journal) on every page.
Our code recognizesand moves it to dedicated XML elements.
The aimis not to interrupt running text by such ?noise?.Publication authors, title and conference informa-tion as well as page number and PDF URL is com-monly named bibliographic metadata.
Because thisinformation was partly missing in the ACL Anthol-ogy, special care was taken to extract it from thepapers.
In the paperXML generation code, authoraffiliations from the title page are mapped to au-thor names using gazetteers, position information,heuristics etc.
as part of the paperXML generationprocess.
This experimental approach is imperfect,leads to errors and would definitely require man-ual correction.
A solution would be to use man-ually corrected author affiliation information fromthe ACL Anthology Reference Corpus (Bird et al,2008).
This information, however, is not immedi-ately available for recent proceedings or journal ar-ticles.
Therefore, we developed a tool with a graph-ical user interface that assists quick, manual correc-tion of author affiliation information inferred fromprevious publications of the same author in the An-thology by means of the ACL ARC data.Independently from the paperXML extractionprocess, bibliographic metadata for each paper in theACL Anthology has been extracted from BIBTEXfiles and, where BIBTEX was missing, the An-thology index web pages.
We semi-automaticallycorrected encoding errors and generated easy-to-convert BIBTEXML8 files for each paper.
Usingthe page number information extracted during thepaperXML generation process, our code enrichesBIBTEXML files with page number ranges wheremissing in the ACL Anthology?s metadata.
Thisis of course only possible for papers that containpage numbers in the header or footer.
The resultingBIBTEXML metadata are available at DFKI?s pub-lic SubVersioN repository9 along with the affiliationcorrection tool.4 Transformation to TEI P5The ACL Contributed Task Rediscovering 50 Yearsof Discoveries (Sch?fer et al, 2012) proposes to useTEI P510 as an open standard for document struc-ture markup.
The overall structure of paperXMLis largely isomorphic to TEI P5, with minor differ-ences such as in the position of page break markup.In paperXML, page break markup is inserted afterthe sentence that starts before the page break, whilein TEI P5, it appears exactly where it was in the orig-inal text, even within a hyphenated word.The Python code that generates paperXML couldbe modified to make its output conforming to TEI.Alternatively, transformation of paperXML into theTEI format could be performed using XSLT.
Ta-ble 1 summarizes mapping of important markup ele-ments.
Details of the element and attribute structurediffer, which makes a real mapping more compli-cated than it may seem from the table.8http://bibtexml.sourceforge.net9http://aclbib.opendfki.de10http://www.tei-c.org/Guidelines/P5107TEI element paperXML elementTEI articleteiHeader headerauthor (unstructured) author (structured)title titlediv type="abs" abstractfront header/abstractbody bodyback (no correspondance)div type="ack" section title="Acknowledgments"div type="bib" referencesp phead section title="..."hi rend="italic" ihi rend="bold" bhi rend="underline" udel type="lb" - (Unicode soft hyphen)pb n="52" page local="7"global="52"table tablerow trcell tdTable 1: Element and attribute mapping (incomplete) be-tween paperXML and TEI P55 Summary and OutlookWe have described a pragmatic and robust solu-tion for generating logical document markup fromscholarly papers in PDF format.
It is meant asan OCR-based fall-back solution in the ACL Con-tributed Task Rediscovering 50 Years of Discoveries(Sch?fer et al, 2012) when the more precise PDFEx-tract method (Berg et al, 2012) is not applicablebecause it can only handle born-digital PDF docu-ments.
Moreover, the approach can serve as fall-back solution where PDFExtract fails or does notproduce markup (e.g.
currently tables).
Our solutionhas been shown to work even on typewriter-typeset,scanned papers from the 60ies.
Correctness of theproduced markup is limited by heuristics that arenecessary to select at markup and layout borders, re-construct reading order, etc.
Levenshtein distance isused at several places in order to cope with variantssuch as those induced by character recognition er-rors.
The approach is implemented to produce XMLdocuments conforming to the paperXML DTD thatin turn could be transformed to TEI P5 using XSLT.AcknowledgmentsThis work has been funded by the German Fed-eral Ministry of Education and Research, projectsTAKE (FKZ 01IW08003) and Deependance (FKZ01IW11003).ReferencesBerg, ?.
R., Oepen, S., & Read, J.
(2012).
To-wards high-quality text stream extraction fromPDF.
Technical background to the ACL 2012Contributed Task.
In Proceedings of the ACL-2012 main conference workshop on Rediscover-ing 50 Years of Discoveries.
Jeju, Republic ofKorea.Bird, S., Dale, R., Dorr, B., Gibson, B., Joseph, M.,Kan, M.-Y., Lee, D., Powley, B., Radev, D., &Tan, Y. F. (2008).
The ACL Anthology ReferenceCorpus: A reference dataset for bibliographic re-search in computational linguistics.
In Proceed-ings of the sixth international conference on lan-guage resources and evaluation (LREC-08).
Mar-rakech, Morocco.Levenshtein, V. I.
(1966).
Binary codes capableof correcting deletions, insertions, and reversals.Soviet Physics Doklady, 10(8), 707?710.Sch?fer, U., Kiefer, B., Spurk, C., Steffen, J., &Wang, R. (2011).
The ACL Anthology Search-bench.
In Proceedings of the ACL-HLT 2011 sys-tem demonstrations (pp.
7?13).
Portland, OR.Sch?fer, U., Read, J., & Oepen, S. (2012).
Towardsan ACL Anthology corpus with logical documentstructure.
An overview of the ACL 2012 con-tributed task.
In Proceedings of the ACL-2012main conference workshop on Rediscovering 50Years of Discoveries.
Jeju, Republic of Korea.Volk, M., Marek, T., & Sennrich, R. (2010).
Reduc-ing OCR errors by combining two OCR systems.In ECAI-2010 workshop on language technologyfor cultural heritage, social sciences, and human-ities (pp.
61?65).
Lisbon, Portugal.Weitz, B., & Sch?fer, U.
(2012).
A graphical cita-tion browser for the ACL Anthology.
In Proceed-ings of the eighth international conference on lan-guage resources and evaluation LREC-2012 (pp.1718?1722).
Istanbul, Turkey: ELRA.108Appendix: paperXML DTD<!-- paperXML DTD second version as of2009-10-16 Ulrich.Schaefer@dfki.de --><!ELEMENT article (header, body) ><!ELEMENT header (file?, pdfmetadata?,ocrmetadata?, firstpageheader,frontmatter?, abstract) ><!ELEMENT pdfmetadata (meta)* ><!ELEMENT ocrmetadata (meta)* ><!ELEMENT meta EMPTY ><!ATTLIST meta name CDATA #REQUIREDcontent CDATA #REQUIRED ><!ELEMENT firstpageheader (page, title,subtitle?, pubinfo?, author*) ><!ELEMENT frontmatter (p)* ><!ELEMENT title (#PCDATA) ><!ELEMENT subtitle (#PCDATA) ><!ELEMENT pubinfo (#PCDATA) ><!ELEMENT author (#PCDATA | org)* ><!ATTLIST author surname CDATA #IMPLIEDmiddlename CDATA #IMPLIEDgivenname CDATA #IMPLIEDaddress CDATA #IMPLIEDemail CDATA #IMPLIEDhomepage CDATA #IMPLIED ><!ELEMENT org EMPTY ><!ATTLIST org name CDATA #IMPLIEDcountry CDATA #IMPLIEDcity CDATA #IMPLIED ><!ELEMENT abstract (#PCDATA | b | i | u |footnote)* ><!ELEMENT body (section*, references?,appendix*) ><!ELEMENT section (subsection | p | footnote |table | figure | page | doubt)* ><!ATTLIST section number CDATA #IMPLIEDtitle CDATA #REQUIRED ><!ELEMENT subsection (subsubsection | p | table|footnote | table | figure | doubt)* ><!ATTLIST subsection number CDATA #IMPLIEDtitle CDATA #REQUIRED ><!ELEMENT subsubsection (p | footnote | table |figure | page | doubt)* ><!ATTLIST subsubsection number CDATA #IMPLIEDtitle CDATA #REQUIRED ><!ELEMENT references (p | footnote | page |doubt)* ><!ELEMENT appendix (p | footnote | table |figure | page | doubt)* ><!ATTLIST appendix number CDATA #IMPLIEDtitle CDATA #REQUIRED ><!ELEMENT p (#PCDATA | page | b | i | u |footnote)* ><!ELEMENT page EMPTY ><!ATTLIST page local CDATA #REQUIREDglobal CDATA #IMPLIED ><!-- boldface --><!ELEMENT b (#PCDATA | i | u | footnote)* ><!-- italics --><!ELEMENT i (#PCDATA | b | u | footnote)* ><!-- underlined --><!ELEMENT u (#PCDATA | i | b | footnote)* ><!ELEMENT footnote (#PCDATA) ><!ATTLIST footnote label NMTOKEN #IMPLIEDanchor NMTOKEN #IMPLIED ><!-- text that is probably not sentential --><!ELEMENT doubt (#PCDATA) ><!ATTLIST doubt alpha CDATA #REQUIREDlength CDATA #REQUIREDtooSmall CDATA #REQUIREDmonospace CDATA #REQUIRED ><!ELEMENT figure (#PCDATA | p)* ><!ATTLIST figure caption CDATA #IMPLIED ><!-- rest is HTML-like table markup --><!ELEMENT table (tr)* ><!ATTLIST table caption CDATA #IMPLIEDclass CDATA #IMPLIEDframe CDATA #IMPLIEDrules CDATA #IMPLIEDborder CDATA #IMPLIEDregular CDATA #IMPLIED ><!ELEMENT tr (td)* ><!ATTLIST tr class CDATA #IMPLIED ><!ELEMENT td (p)* ><!ATTLIST td class CDATA #IMPLIEDrowspan CDATA #IMPLIEDcolspan CDATA #IMPLIED >109
