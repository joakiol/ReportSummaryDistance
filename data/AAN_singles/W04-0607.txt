Feeding OWL: Extracting and Representingthe Content of Pathology ReportsDavid Schlangen and Manfred StedeDepartment of LinguisticsUniversity of PotsdamP.O.
Box 601553D-14415 Potsdam, Germany{das|stede}@ling.uni-potsdam.deElena Paslaru BontasInstitute for Computer ScienceFreie Universita?t BerlinTakustr.9D-14195 Berlin, Germanypaslaru@inf.fu-berlin.deAbstractThis paper reports on an ongoing project that com-bines NLP with semantic web technologies to sup-port a content-based storage and retrieval of medicalpathology reports.
We describe the NLP componentof the project (a robust parser) and the backgroundknowledge component (a domain ontology repre-sented in OWL), and how they work together duringextraction of domain specific information from nat-ural language reports.
The system provides a goodexample of how NLP techniques can be used to pop-ulate the Semantic Web.1 IntroductionClinical pathologists work with and produce vastamounts of data: images of biological samples andwritten reports of their findings.
Digital Pathologyis the cover term for a number of efforts to intro-duce digital processing into the work-flow of thepathologist.
While previous projects have focussedon storage and distribution of images and reports(e.g.
in Tele-Pathology-projects, (Slodowksa et al,2002; Demichellis et al, 2002)), the work reportedhere explores the use of Natural Language Process-ing (NLP) and Semantic Web technologies to sup-port a content-based storage and retrieval of casereports.
The system that we are building, LUPUS(Lung Pathology System), consists of an NLP com-ponent (a robust parser) and a Semantic Web com-ponent (a domain ontology represented in OWL, anda Description Logic reasoner), which work closelytogether, with the domain ontology guiding the in-formation extraction process.The remainder of the paper is organised as fol-lows.
In the next section we describe the contextand intended application of the system, we discusslinguistic properties of the input material we areworking with, and we give some details of the back-ground ontology we are using.
In Section 3 we gointo the technical details of the process of extractinginformation from natural language reports and rep-resenting it in an OWL representation, after whichwe describe a preliminary evaluation.
We close withdiscussing related work, and planned future work.2 Digital Pathology2.1 The ApplicationLUPUS is intended to support the pathologist in twoways.
First, it is used to semantically annotate alarge archive of case reports, turning them into avaluable resource for diagnosis and teaching.
Thesystem uses the case reports produced by experts(the pathologists) to extract information about theaccompanying images (of the tissue samples), andthus produces semantic annotation both for the re-port and for those images.This corpus of cases can then be searched in afast, content-based manner to retrieve case reports(the textual reports together with the images of tis-sue samples) that might be relevant for a case thepathologist is working on.
The search is content-based in that it can make use of semantic relation-ships between search concepts and those occuringin the text.
We also encode in rules knowledgeabout certain diagnostics tasks, so that for examplequeries asking for ?differential diagnosis?
(?showme cases of diagnoses which are known to be easilyconfusable with the diagnosis I am thinking of forthe present case?)
can be processed?tasks whichnormally require consultation of textbooks.
Thesesearch capabilities are useful both during diagnosisand for teaching, where it makes interesting exam-ples immediately available to students.Another use case is quality control during inputof new reports.
Using our system, such reports canbe entered in a purpose-built editor (which com-bines digital microscopy facilities (Saeger et al,2003) with our semantic annotator / search engine),where they are analysed on-the-fly, and potentialinconsistencies with respect to the background do-main ontology are spotted.1 During the develop-ment phase of the system, we are using this feature1Naturally, to gain acceptance by working pathologists, thisprocess has to be ?minimally invasive?.to detect where the coverage of the system must beextended.The present paper focuses on the process of ex-tracting the relevant information from natural lan-guage reports and representing it in a semanticweb-ready format as a precondition for performingsearches; we leave the description of the search andretrieval functions to another paper.
To give an ideaof the kind of data we are dealing with, and of the in-tended target representation, Figure 1 shows an ex-ample report (at the top of the figure) and the repre-sentation of its content computed by our system (atthe bottom).2 We discuss the input format in the fol-lowing subsection, and the target representation to-gether with the domain knowledge available to us inSubsection 2.3; discussion of the intermediate for-mat that is also shown in the figure is deferred untilSection 3.2.2 Pathology ReportsDuring the development phase of the system, weare using a corpus of 90 randomly selected case re-ports (ca.
13,000 words; i.e.
the average length ofthe reports is ca.
140 words, with a standard devia-tion of 12 words) for testing and grammar develop-ment.
Linguistically, these reports are quite distin-guished: they are written in a ?telegram?-style, withverbs largely being absent (a rough examination ofthe corpus showed that only about every 43rd tokenis a verb, compared to every 11th in a comparablecorpus of German newspaper).
Also, the vocabularyis rather controlled, with very little variation?thisof course is good news for automatically process-ing such input.
On the discourse level we also finda strict structure, with a fixed number of semanti-cally grouped sections.
E.g., information about thediagnosis made will normally be found in the sec-tion ?Kritischer Bericht?
(critical report), and the in-formation in the ?Makroskopie?
and ?Mikroskopie?sections (macroscopy and microscopy, respectively)will be about the same parts of the sample, but ondifferent levels of granularity.The last peculiarity we note is the relatively highfrequency of compound nouns.
These are especiallyimportant for our task, since technical concepts inGerman tend to be expressed by such compoundnouns (rather than by noun groups).
While some2What is shown in the figure is actually already the resultof a preprocessing step; the cases as stored in the database con-tain patient data as well, and are formatted to comply with theHL7 standard for medical data (The HL7 Consortium, 2003).Moreover, the italicisation in the input representation and thenumbers in square brackets are added here for ease of refer-ence and are not part of the actual representations maintainedby the system.of those will denote individual concepts and hencewill be recorded in the domain lexicon, others mustbe analysed and their semantics must be composedout of that of their parts (see below).2.3 Lung Pathology Knowledge in OWLThe result of processing such reports with LUPUSis a representation of (relevant aspects of) their con-tent.
This representation has the form of instancesof concepts and assertions of properties that are de-fined in an ontology, which constitutes the domainknowledge of the system (at the moment focussedon pathologies of the lung).
This ontology is spec-ified in OWL DL (W3C WebOnt WG, 2004), a ver-sion of OWL with a formal semantics and a completeand decidable calculus.
Consequently, the contentof the texts is represented in OWD DL as well, andso the knowledge base of the system consists of theontology and the instances.The ontology we use is compiled out of sev-eral medical sources (such as UMLS (The UMLSConsortium, 2003) and SNOMED (SNOMED Inter-national, 2004)), but since these sources often werenot intended for machine reasoning (i.e., are notnecessarily consistent, and use rather loosely de-fined relations), considerable effort has been spent(and is being spent) on cleaning them up.3 At themoment, about 1,000 domain-level concepts andca.
160 upper-level concepts have been identified,which are connected by about 50 core relation types.To our knowledge, this makes it one of the biggestOWL-ontologies currently in use.Besides representing concepts relevant to our do-main, the ontology also lists properties that in-stances of these concepts can have.
These proper-ties are represented as two-place relations; to givean example, the property ?green?
attributed to anentity x will in our system not be represented as?green(x)?, but rather as something like ?colour(x,green)?.
This allows us to enforce consistencychecks, by demanding that for each second-orderpredicate (colour, malignity, consistency, etc.)
ap-propriate for a given concept only one value ischosen.4 This choice of representation has conse-quences for the way the semantics of adjectives isrepresented in the lexicon, as we will see presently.3There are several current research projects with a similaraim of extracting stricter ontologies from sources like thosementioned above (see e.g.
(Schulz and Hahn, 2001; Burgun andBodenreider, 2001)), and this is by no means a trivial task.
Thepresent paper, however, focuses on a different (but of course in-terdependent) problem, namely that of extracting informationsuch that it can be represented in the way described here.4Technically, these constraints are realised by functionaldata-properties relating entities to enumerated data types.An example report (with translation):<befund><makroskopie>Stanzzylinder von 15 mm La?nge und 1 mm Durchmesser.
[1]</makroskopie><mikroskopie>Stanzbiopsat [2] eingenommen durch Infiltrate einer soliden malignen epithelialen Neoplasie.
[3]Die Tumorzellen mit distinkten Zellgrenzen [4], zum Teil interzellula?r Spaltra?ume [5], zwischendenen stellenweise kleine Bru?cken [6] nachweisbar sind.
Das Zytoplasma leicht basophil,z.T.
auch breit und eosinphil, [7] die Zellkerne hochgradig polymorph mit zum Teilmultiplen basophilen Nukleolen.
[8] Deutliche desmoplastische Stromareaktion.
[9]</mikroskopie><kritischer bericht>Stanzbiopsat aus einer Manifestation eines soliden Karzinoms [10](klinisch rechte Lunge apikal).</kritischer bericht><kommentar>...</kommentar></befund>( Biopsy cylinder of 15 mm length and 1 mm diameter.
| Biobsy infiltrated by a solidmalignant epithelial neoplasia.
The tumor cells with distinct cell borders, partially intercel-lular spatia, between which sporadically small bridges are verifiable.
The cytoplasm lightlybasophil, in part also broad and eosinphile, the nuclei highly polymorphic, partially withmultiple basophile nucleoli.
Distinct desmoplastic stroma reaction.
| Biopsy cylinder froma manifestation of a solid carcinoma (clinical right lung apical).
)?Intermediate Representation (excerpt):[2] unspec det(x2) ?
punch biopsat(x2) [3] unspec plur det(x3) ?
infiltrate(x3, x4) ?indef det(x4) ?
solid(x4) ?malign(x4) ?
epithelial(x4) ?
neoplasia(x4)[4] def plur det(x5)?tumorcell(x5)?with rel(x5, x6)?unspec plur det(x6)?distinctive(x6)?cell borders(x6) [7] spec det(x9) ?
low degree(d1) ?
basophile(x9, d1) ?
partially(d2) ?broad(x9, d2) ?
eosinphile(x9, d2) ?
cytoplasm(x9)[8] def plur det(x10) ?
high degree(d3) ?
polymorpheous(x10, d3) ?
nucleus(x10) ?with rel(x10, x11)?unspec plur det(x11)?partially(d4)?multiple(x11, d4)?basophile(x11)?nucleoli(x11)?Target Representation (excerpt):<Malignant Epithelial Neoplasm C0432650 rdf:ID=?neoplasia x4?><solidity rdf:datatype=?http://www.w3.org/2001/XMLSchema#float?>1.0</solidity></Malignant Epithelial Neoplasm><Cell Border C0032743 rdf:ID=?cell border x61?/><Tumor cells C0431085 rdf:ID=?tumor cell x52?><hasBoundary rdf:resource=?file:...#cell boundary x61?/></Tumor cells C0431085><cytoplasm C0326583 rdf:ID=?cytoplasm1?><broad rdf:datatype=?http://www.w3.org/2001/XMLSchema#float?>1.0</broad><eosinphil rdf:datatype=?http://www.w3.org/2001/XMLSchema#float?>1.0</eosinphil><basophil rdf:datatype=?http://www.w3.org/2001/XMLSchema#float?>0.5</basophil></cytoplasm>Figure 1: Input, Intermediate and Target RepresentationFigure 2: FlowchartUsing OWL DL as a representation format fornatural language content means certain limitationshave to be accepted.
Being a fragment of FOL, itis not expressive enough to represent certain finersemantic details, as will be discussed below.
How-ever, the advantage of using an emerging standardfor delivering and sharing information outweighsthese drawbacks.3 Implementation3.1 OverviewAs mentioned above, most of the sentences in ourcorpus do not contain a finite verb; i.e., according tostandard rules of grammar they are elliptical.
Whilea theoretically motivated approach should strive toresolve this ellipsis contextually (for example as de-scribed in (Schlangen, 2003)), in view of the in-tended application and for reasons of robustness wehave decided to focus only on extracting informa-tion about the entities introduced in the reports?that is, on recognising nominal phrases, leavingaside the question of how verbal meanings are tobe resolved.Our strategy is to combine a ?shallow?
prepro-cessing stage (based on finite-state methods and sta-tistical approaches) with a symbolic phase, in whichthe semantics of the NPs is assembled.5 A require-ment for the processing is that it must be robust, intwo ways: it must be able to deal with unknowntokens (i.e., ?out of vocabulary?
items) and with un-known structure (i.e., ?out of grammar?
construc-tions), degrading gracefully and not just failing.Figure 2 shows a flow chart of the system; theindividual modules are described in the followingsections.5This strategy sits somewhere between Information Extrac-tion, where also only certain phrases are extracted, for which,however, normally no compositional semantics is computed,and ?full?
parsing, where such a semantics is computed only ifthe whole input can be parsed.3.2 PreprocessingThe first step, tokenising and sentence splitting, isfairly standard, and so we skip over it here.
Thesecond step, morpho-syntactic analysis, is more in-teresting.
It is performed by an independently de-veloped module called TAGH, a huge finite-statemachine that makes use of a German word-stemlexicon (containing about 90,000 entries for nouns,17,000 for verbs, 20,000 adjectives and adverbs,and about 1,500 closed class word forms).
Thetransducer is implemented in C++ and has a veryhigh throughput (about 20,000 words per secondon modern machines).
The coverage achieved ona balanced corpus of German is around 96% (Ju-rish, 2003), for our domain the lexicon had to beextended with some domain specific vocabulary.To give an example of the results of the analysis,Figure 3 shows (excerpts of) the output for Sentence2 of the example report.
Note that this is already thePOS-disambiguated output, and we only show oneanalysis for each token.
In most cases, we will getseveral analyses for each token at this stage, differ-ing with respect to their part of speech tag or othermorphological features (e.g., case) that are not fullydetermined by their form.
(The average is 5.7 anal-yses per token.)
Note also that the actual output ofthe module is in an XML format (as indeed are allintermediate representations); only for readability isit presented here as a table.Another useful feature of TAGH is that it pro-vides derivational information about compoundnouns.
To give an example, (1) shows one analysisof the noun ?Untersuchungsergebnis?
(examinationresult).
(1) Untersuchungsergebnisuntersuch(V)?ung(n)/s#ErgebnisAs this shows, the analysis gives us informationabout the stems of the compounds; this can be usedto guide the computation of the meaning of the com-plex noun.
However, this meaning is not fully com-Token Type AnalysisStanzbiopsat Stanzbiopsat [NN Gender=neut Number=sg Case=nom]eingenommen ein|nehm?en [VVPP2]durch durch [APPR]Infiltrate Infiltrat [NN Gender=neut Number=pl Case=acc]einer eine [ARTINDEF Number=sg Case=gen Gender=fem]soliden solid [ADJA Degree=pos Number=sg Case=gen Gender=* ADecl=mixed]malignen maligne [ADJA Degree=pos Number=sg Case=gen Gender=* ADecl=mixed]epithelialen epithelial [ADJA Degree=pos Number=sg Case=gen Gender=* ADecl=mixed]Neoplasie Neoplasie [NN Gender=fem Number=sg Case=*]Figure 3: Result of Morphological Analysis / POS-tag disambiguation for Sentence 2positional, as the nature of the relation between thecompounds is underspecified.
We represent this byuse of an underspecified relation rel that holds be-tween the compounds, and which has to be specifiedlater on in the processing chain.The output of this module is then fed into a statis-tically trained POS-disambiguator, which finds themost likely path through the lattice of morpholog-ical analyses (Jurish, 2003) (with an accuracy of96%).
In cases where morphology failed to providean analysis, the syntagmatically most likely POS tagis chosen.
At the end of this stage all analyses fora given token agree on its part of speech; however,other features (number, person, case, etc.)
mightstill not be disambiguated.At the next stage, certain sequences of tokensare grouped together, namely multi-word expres-sion that denote a single concept in our ontology(e.g., ?anthrakotische Lymphknoten?
denotes a sin-gle concept, and hence is marked as one token oftype NN at this step), and certain other phrases (e.g.specifications of spatial dimensions) which can berecognised easily but would require very specialisedgrammar rules later on.6Then, the domain-specific lexicon is accessed,which maps ?concept names?
(nouns, or phrases asrecognised in the previous step) to the concept IDsused in the ontology.7 Tokens for which there is noentry in that lexicon, and which are hence deemed?irrelevant?
for the domain, are assigned a ?dummy?semantics appropriate for their part of speech, sothat they do not confuse the later parsing stage.
(More details about this kind of robustness will begiven shortly.
)6See for example (Grover et al, 2002) for a discussion ofthe utility of a named entitiy recognition preprocessing stagefor robust symbolic parsing.7Note that this lexicon is one single resource out of whichalso the domain specfic additions to the morphology-lexiconand the list of multi-word expressions are compiled.3.3 Chunk ParsingNext, the analyses of the tokens are transformedinto a feature structure format, and are passed tothe parsing component.8 The output of this stageis an intermediate semantic representation of (as-pects of) the content (of which the notation shownin 1 is a variant).
This format is akin to traditionallogical forms and still has to be mapped into OWL;we decided on this strategy because such a formatis closer to surface structure and hence easier tobuild compositionally (see discussion below in Sec-tion 3.5).
Also note that the semantics is ?flat?, anddoes not represent scope of quantifiers (which onlyvery rarely occur in our data, and cannot be repre-sented OWL in any case).To get an idea of the feature geometry used by thegrammar see Figure 4; this figure also shows the se-mantic representations generated at this stage (in adifferent notation than in Figure fig:reps).
Note the?simulation?
of typing of feature structures, and therepresentation of properties via second order prop-erties as discussed above.
Chunk parsing is per-formed by a chart parser running a grammar that isloosely inspired by HPSG (Pollard and Sag, 1994).9The grammar contains context-free rules for fairlycomplex NPs (allowing arguments of Ns, modifi-cation by PPs, and coordination).
When extractingchunks, the strategy followed by the system is to al-ways extract the largest non-overlapping chunks.10An example might help to illustrate the robust-8Up until here, all steps are performed in one go for thewhole document.
The subsequent steps, on the other hand, areperformed incrementally for each sentence.
This allows thesystem to remove ambiguity when it occurs, rather than havingto maintain and later filter out different analyses.9The parser is implemented in PROLOG, and based on thesimple algorithm given in (Gazdar and Mellish, 1989).
It alsouses code by Michael Covington for dealing with feature struc-tures in PROLOG, which is described in (Covington, 1994).10That strategy will prefer lenght of individual chunks overcoverage of input, for example when there is one big chunk andtwo overlapping smaller chunks at each side of that chunk, thathowever together span more input.??????????????SYN????
?CAT npHEAD?
?CASE nomAGR[NUM sgPER drGEN neu]?
?COMP nil?????SEM???RESTR?
[RELTYPE detTYPE unspecARG x3][RELTYPE entTYPE stanzbiopsatINST x3]?INDEX x3??????????????????????????????????????SYN????
?CAT npHEAD?
?CASE accAGR[NUM plPER drGEN fem]?
?COMP nil?????SEM?????????RESTR?
[RELTYPE detTYPE unspec plurARG x1][RELTYPE entTYPE infiltratARG x2INST x1][RELTYPE detTYPE indefARG x2][RELTYPE propTYPE consistencyARG x2VALUE solid][RELTYPE propTYPE malignityARG x2VALUE malign][RELTYPE propTYPE positionARG x2VALUE epithelial][RELTYPE entTYPE neoplasiaINST x2]?INDEX x1?????????????????????????????
?Figure 4: The chunks extracted from Sentence 2ness of the system.
(2) shows a full syntactic analy-sis of our example sentence.
Our system only recog-nises the chunks indicated by the brackets printedin bold typeface: since it can?t recognise the pred-icative use of the verb here, it is satisfied with justbuilding parses for the NPs it does recognise.
(Theround brackets around the analysis of the first wordindicate that this parse is strictly speaking not cor-rect if the full structure is respected.
)(2) [NP ([NP) [NOM Stanzbiopsat] (]), [ADJP [VVPP2eingenommen] [PP [P durch] [NP Infiltrate einersoliden malignen epithelialen Neoplasie.
]]]]?This is an example of the system?s tolerance to un-known structure; (3) shows a (constructed) exam-ple of an NP where the structure is covered by thegrammar, but there are ?unknown?
(or rather, irrele-vant) lexical items.
As described above, we assigna ?dummy semantics?
(here, a property that is trueof all entities) to words that are irrelevant to the do-main, and so parsing can proceed.
(3) Solid, hardly detectable tumor cells.
?solid(x) ?
true(x) ?
tumor cell(x)A few last remarks about the grammar.
First, asshown in Figure 4, NPs without determiner intro-duce an underspecified relation unspec det, and in-formation about definiteness and number of deter-miners is represented.
This means that all infor-mation to do discourse processing (bridging of def-inites to antecedents) is there; we plan to exploitsuch information in later incarnations of the sys-tem.
Secondly, it can of course occur that there ismore than one analysis spanning the same input;i.e., we can have syntactic ambiguity.
This will bedealt with in the transformation component, wheredomain knowledge is used to only let through ?plau-sible?
analyses.Lastly, prepositions are another source for under-specification.
For instance, given as input the string(4), the parser will compute a semantics where anunderspecified with rel connects the two entitiestumor and alveolar; this relation will be specifiedin the next step, using domain knowledge, to a rela-tion contains.
(4) Ein Tumor mit freien Alveolaren.A tumor with free alveolars.3.4 Resolution of Underspecification usingOntologiesAs described in the previous sections, the output ofthe parser (and of the morphological analysis) mightstill contain underspecified relations.
These are re-solved in the module described in this section.
Thismodule sends a query to a reasoning component thatcan perform inference over the ontology, asking forpossible relations that can hold between (instancesof) entities.
For example (4) above, this will returnthe answer contains, since the ontology specifiesthat ?alveolars?
are parts of tumours (via a chain ofis-a-relations linking tumours with cells, and cellswith alveolars).
In a similar way the underspecifi-cation of compound nouns is resolved.
This processproceeds recursively, ?inside-out?, since compoundnouns can of course be embedded in NPs that areparts of PPs, and so on.3.5 Mapping LF to OWLIn the final step, the logical forms produced by theparser and specified by the previous module aretransformed into OWL-compliant representations.This process is fairly straightforward, as should beclear from comparing the intermediate representa-tion in Figure 1 with the target representation: a)unique identifiers for the instances of concepts aregenerated; b) in cases of plural entities (?three sam-ples?
?
card(x, 3) ?
sample(x)), several separateinstances are created; and c) appropriateness condi-tions for properties are applied: if a property is notdefined for a certain type of entity, the analysis isrejected.This translation step also handles potential syn-tactic ambiguity, since it can filter out analysesif they specify inconsistent information.
Notealso that certain information, e.g.
about secondorder properties, might be lost, due to the re-stricted expressivity of OWL.
E.g., an expres-sion like ?highly polymorpheous?
in Figure 1 ei-ther has to be converted into a representation likepolymorphism : high, or the modification is lost(polymorpheous(x)).This ends our brief description of the system.
Wenow discuss a preliminary evaluation of the mod-ules, related work, and further extensions of the sys-tem we are currently working on or which we areplanning.4 EvaluationAt the moment, we have only evaluated the mod-ules individually, and?since the system is still un-der developement?this evaluation only provides asnapshot of the current state of developement.
Afull-scale evaluation of the whole system in its ap-plication context is planned as soon as the modulesare finalised; plans for this are discussed below.The coverage of the morphology module and thePOS-tagger have already been reported above, so weconcentrate here on the chunk-parser.
To evaluatethis module, we have manually annotated the NPsin a randomly selected test set of 20 reports (ca.2,800 words; we found about 500 NPs).
The re-ports were then morphologically analysed and POS-filtered, and the results were manually checked andcorrected, to ensure that the input was optimal andreally only the performance of the chunker was eval-uated.
We then computed precision and recall basedon two different matching criteria: for exact match-ing, where only exact congruence of chunks counts,a precision of 48% and a recall of 63% was com-puted; the numbers improve when partial matches,i.e.
smaller chunks within the target chunk, receivepartial credit (by a factor of .25), resulting in a (re-laxed) precision of 61% and a (relaxed) recall of80%.
This difference can be explained by the factthat some of the more complex NP-constructions(with quite complex modifications) in our data arenot yet covered by the grammar, and only their con-stituent NPs are recognised.Note that this evaluation just takes into accountthe boundaries of the chunks and not the correct-ness of the computed semantic representations.
Fora full-scale evaluation, we will manually annotatethese NPs with semantic representations, and wewill use this to compute precision and recall alsowith respect to semantics, and ultimately with re-spect to sample search queries.
This annotation,however, is very resource-intensive, and so will onlybe done once the modules have been finalised.5 Related WorkAcquisition of information from texts especiallyfrom the medical domain is a lively research area.Among the many projects in that field, we sharesome of our central concerns with the medSyn-diKAte system (Hahn et al, 2002): robust text anal-ysis of medical reports; a background knowledgebase for guiding the analysis and storing the text?scontent; emphasis on handling co-reference phe-nomena.
What distinguishes LUPUS from medSyn-diKAte, though, is foremost the parsing scheme: thelanguage used in the reports analysed by Hahn et alis much closer to ?natural?
language in that it con-tains sentences with tensed verbs.
Accordingly, theyuse a variant of dependency parsing which is drivenby verb information.
As described in Section 2.2above, this is not an option for us, given the style ofour input texts, and hence our data renders a bottom-up chart parsing approach much more promising.Besides this difference, the work in medSynDiKAtepredates the emergence of XML/web ontology stan-dards and thus uses an earlier description logicknowledge representation language; we are hopingthat by using a standard we will be able to alloweven future semantic web technologies to work withour data.As for the robust analysis side, (Grover et al,2002), also use a similar preprocessing pipelinein combination with parsing.
However, they alsofocus on more ?natural?
input texts (Medline ab-stracts), and they use statistical rather than sym-bolic/ontology based methods for computing themeaning of compound nouns.6 Summary and Further WorkWe have described LUPUS, an NLP system thatmakes use of a domain ontology to guide extractionof information about entities from medical texts,and represents this information as instances of con-cepts from that ontology.
Besides its direct use forcontent-based search on these texts, the fact that thesystem relies entirely on emerging semantic webstandards will make the resulting annotated infor-mation usable for all kinds of agents working withsuch data.As a next step, we plan to add discourse process-ing to the pipeline (see e.g.
(Hahn et al, 1998) fora discussion why such a step is required even forsuch relatively simple texts).
As mentioned above,the prerequisite information (about definite articles,for example) is already there; we plan to use theavailable domain knowledge to guide the search forantecedents for bridging.
As a more technical im-provement we are investigating ways of making thearchitecture less pipeline-y, and to integrate domainreasoning in computing edges in the chart.
Lastly,we are also working on a large-scale evaluation ofthe system, by manually annotating reports to com-pute precision and recall.AcknowledgementsWe thank the anonymous reviewers for their helpfulcomments.
Thanks are also due to Thomas Hanneforthand Bryan Jurish for their help with integrating theirmodules, and to our student assistant Sebastian Maar fordoing much of the actual coding.ReferencesAnita Burgun and Oliver Bodenreider.
2001.
Mappingthe UMLS semantic network into general ontologies.In Proceedings of the AMIA Symposium.Michael A. Covington.
1994.
GULP 3.1: An extensionof prolog for unification-based grammar.
TechnicalReport AI-1994-06, University of Georgia.F.
Demichellis, V. Della Mea, S. Forti, P. Dalla Palma,and C.A.
Beltrami.
2002.
Digital storage of glassslide for quality assurance in histopathology and cy-topathology.
Telemedicine and Telecare, 8(3):138?142.Gerald Gazdar and Chris Mellish.
1989.
Natural Lan-guage Processing in PROLOG.
Addison-Wesley,Wokingham, England.Claire Grover, Ewan Klein, Mirella Lapata, andAlex Lascarides.
2002.
XML-based NLP tools foranalysing and annotating medical language.
In Pro-ceedings of the 2nd Workshop on NLP and XML,Taipei, Taiwan, September.Udo Hahn, Martin Romacker, and Stefan Schulz.
1998.Why discourse structures in medical reports matterfor the validity of automatically generated text knowl-edge bases.
In MedInfo ?98 ?
Proceedings of the 9thWorld Congress on Medical Informatics, pages 633?638, Seoul, Korea, August.Udo Hahn, Martin Romacker, and Stefan Schulz.
2002.Creating knowledge repositories from biomedical re-ports: The medsyndikate text mining system.
In Pa-cific Symposium on Biocomputing, pages 338?349,Hawai, USA, January.Bryan Jurish.
2003.
Part-of-speech tagging with finitestate morphology.
In Proceedings of the Workshop onCollocations and Idioms: Linguistic, Computationaland Psycholinguistic Perspectives, Berlin, Germany,September.Carl Pollard and Ivan Sag.
1994.
Head-Driven PhraseStructure Grammar.
CSLI / The University ofChicago Press, Chicago and London.Kai Saeger, Karsten Schlu?ns, Thomas Schrader, and Pe-ter Hufnagl.
2003.
The virtual microscope for routinepathology based on a pacs system for 6 gb images.In Proceedings of the 17th International Congress onComputer Assisted Radiology and Surgery (CARS),pages 299?304, London, UK, June.David Schlangen.
2003.
A Coherence-Based Approachto the Interpretation of Non-Sentential Utterances inDialogue.
Ph.D. thesis, School of Informatics, Uni-versity of Edinburgh, Edinburgh, UK.Stefan Schulz and Udo Hahn.
2001.
Medical knowledgeengineering?converting major portions of the umlsinto a terminological knowledge base.
InternationalJournal of Medical Informatics.J.
Slodowksa, K. Kayser, and P. Hasleton.
2002.
Tele-consultation in the chest disorders.
European Journalfor Medical Research, 7(Suppl.I):80.SNOMED International.
2004.
SNOMED clinical terms.http://www.snomed.org/index.html.The HL7 Consortium.
2003.
HL7 version 2.5 ANSIstandard, June.
http://www.hl7.org.The UMLS Consortium.
2003.
UMLS release 2003AC.http://www.nlm.nih.gov/research/umls/.W3C WebOnt WG.
2004.
OWL web ontology languageoverview.
W3C recommendation, W3C, Febru-ary.
http://www.w3.org/TR/2004/REC-owl-features-20040210/.
