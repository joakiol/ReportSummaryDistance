Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 884?889,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsComputerized Analysis of a Verbal Fluency TestJames O. Ryan1, Serguei Pakhomov1, Susan Marino1,Charles Bernick2, and Sarah Banks21 College of Pharmacy, University of Minnesota2 Lou Ruvo Center for Brain Health, Cleveland Clinic{ryanx765, pakh0002, marin007}@umn.edu{bernicc, bankss2}@ccf.orgAbstractWe present a system for automated pho-netic clustering analysis of cognitive testsof phonemic verbal fluency, on which onemust name words starting with a specificletter (e.g., ?F?)
for one minute.
Test re-sponses are typically subjected to man-ual phonetic clustering analysis that islabor-intensive and subject to inter-ratervariability.
Our system provides an au-tomated alternative.
In a pilot study,we applied this system to tests of 55novice and experienced professional fight-ers (boxers and mixed martial artists) andfound that experienced fighters producedsignificantly longer chains of phoneticallysimilar words, while no differences werefound in the total number of words pro-duced.
These findings are preliminary, butstrongly suggest that our system can beused to detect subtle signs of brain damagedue to repetitive head trauma in individu-als that are otherwise unimpaired.1 IntroductionThe neuropsychological test of phonemic verbalfluency (PVF) consists of asking the patient togenerate as many words as he or she can in a lim-ited time (usually 60 seconds) that begin with aspecific letter of the alphabet (Benton et al 1989).This test has been used extensively as part of largercognitive test batteries to study cognitive impair-ment resulting from a number of neurological con-ditions, including Parkinson?s and Huntington?sdiseases, various forms of dementia, and traumaticbrain injury (Troyer et al 1998a,b; Raskin et al1992; Ho et al 2002).
Patients with these dis-orders tend to generate significantly fewer wordson this test than do healthy individuals.
Priorstudies have also found that clustering (the degreeto which patients generate groups of phoneticallysimilar words) and switching (transitioning fromone cluster to the next) behaviors are also sensi-tive to the effects of these neurological conditions.Contact sports such as boxing, mixed martialarts, football, and hockey are well known forhigh prevalence of repetitive head trauma.
In re-cent years, the long-term effects of repetitive headtrauma in athletes has become the subject of inten-sive research.
In general, repetitive head traumais a known risk factor for chronic traumatic en-cephalopathy (CTE), a devastating and untreat-able condition that ultimately results in permanentdisability and premature death (Omalu et al 2010;Gavett et al 2011).
However, little is currentlyknown about the relationship between the amountof exposure to head injury and the magnitude ofrisk for developing these conditions.
Furthermore,the development of new behavioral methods aimedat detection of subtle early signs of brain impair-ment is an active area of research.The PVF test is an excellent target for this re-search because it is very easy to administer and hasbeen shown to be sensitive to the effects of acutetraumatic brain injury (Raskin and Rearick, 1996).However, a major obstacle to using this test widelyfor early detection of brain impairment is that clus-tering and switching analyses needed to detectthese subtle changes have to be done manually.These manual approaches are extremely labor-intensive, and are therefore limited in the types ofclustering analyses that can be performed.
Manualmethods are also not scalable to large numbers oftests and are subject to inter-rater variability, mak-ing the results difficult to compare across subjects,as well as across different studies.
Moreover, tra-ditional manual clustering and switching analysesrely primarily on word orthography to determinephonetic similarity (e.g., by comparing the firsttwo letters of two words), rather than phonetic rep-resentations, which would be prohibitively time-884Figure 1: High-level system architecture andworkflow.consuming to obtain by hand.Phonetic similarity has been investigated in ap-plication to a number of research areas, includingspelling correction (Toutanova and Moore, 2002),machine translation (Knight and Graehl, 1998;Kondrak et al 2003), cross-lingual informationretrieval (Melamed, 1999; Fujii and Ishikawa,2001), language acquisition (Somers, 1998), his-torical linguistics (Raman et al 1997), and social-media informatics (Liu et al 2012); we propose anovel clinical application.Our objective was to develop and pilot-test arelatively simple, but robust, system for automaticidentification of word clusters, based on phoneticcontent, that uses the CMU Pronouncing Dictio-nary, a decision tree-based algorithm for gener-ating pronunciations for out-of-dictionary words,and two different approaches to calculating pho-netic similarity between words.We first describe the system architecture andour phonetic-similarity computation methods, andthen present the results of a pilot study, using datafrom professional fighters, demonstrating the util-ity of this system for early detection of subtle signsof brain impairment.2 Automated Clustering AnalysisFigure 1 shows the high-level architecture andworkflow of our system.2.1 Pronunciation DictionaryWe use a dictionary developed for speech recog-nition and synthesis applications at the CarnegieMellon University (CMUdict).
CMUdict containsphonetic transcriptions, using a phone set based onARPABET (Rabiner and Juang, 1993), for NorthAmerican English word pronunciations (Weide,1998).
We used the latest version, cmudict.0.7a,which contains 133,746 entries.From the full set of entries in CMUdict,we removed alternative pronunciations for eachword, leaving a single phonetic representation foreach heteronymous set.
Additionally, all vowelsymbols were stripped of numeric stress mark-ings (e.g., AH1 ?
AH), and all multicharacterphone symbols were converted to arbitrary single-character symbols, in lowercase to distinguishthese symbols from the original single-characterARPABET symbols (e.g., AH ?
c).
Finally,whitespace between the symbols constituting eachphonetic representation was removed, yieldingcompact phonetic-representation strings suitablefor computing our similarity measures.To illustrate, the CMUdict pronunciation entryfor the word phonetic, [F AH0 N EH1 T IH0K], would be represented as FcNiTmK.2.2 Similarity ComputationOur system uses two methods for determiningphonetic similarity: edit distance and a common-biphone check.
Each of these methods gives ameasure of similarity for a pair of phonetic repre-sentations, which we respectively call a phonetic-similarity score (PSS) and a common-biphonescore (CBS).For PSS, we first compute the Levenshteindistance (Levenshtein, 1966) between compactphonetic-representation strings and normalize thatto the length of the longer string; then, that valueis subtracted from 1.
PSS values range from 0 to1, with higher scores indicating greater similarity.The CBS is binary, with a score of 1 given for twophonetic representations that have a common ini-tial and/or final biphone, and 0 for two strings thathave neither in common.885Figure 2: Phonetic chain and common-biphonechain (below) for an example PVF response.2.3 Phonetic ClusteringWe distinguish between two ways of defining pho-netic clusters.
Traditionally, any sequence of nwords in a PVF response is deemed to form a clus-ter if all pairwise word combinations for that se-quence are determined to be phonetically similarby some metric.
In addition to this method, wedeveloped a less stringent approach in which wedefine chains instead of clusters.A chain comprises a sequence for which thephonetic representation of each word is similarto that of the word immediately prior to it in thechain (unless it is chain-initial) and the word sub-sequent to it (unless it is chain-final).
Lone wordsthat do not belong to any cluster constitute sin-gleton clusters.
We call chains based on the edit-distance method phonetic chains, and chains basedon the common-biphone method common-biphonechains; both are illustrated in Figure 2.Unlike the binary CBS method, the PSSmethod produces continuous edit-distance values,and therefore requires a threshold for categorizinga word pair as similar or dissimilar.
We determinethe threshold empirically for each letter by takinga random sample of 1000 words starting with thatletter in CMUdict, computing PSS scores for eachpairwise combination (n = 499, 500), and thensetting the threshold as the value separating theupper quintile of these scores.
With the common-biphone method, two words are considered pho-netically similar simply if their CBS is 1.2.4 System OverviewOur system is written in Python, and is availableonline.1 The system accepts transcriptions of a1http://rxinformatics.umn.edu/downloads.htmlPVF response for a specific letter and, as a pre-processing step, removes any words that do not be-gin with that letter.
After pre-processing, all wordsare phoneticized by dictionary lookup in our mod-ified CMUdict.
For out-of-dictionary words, weautomatically generate a phonetic representationwith a decision tree-based grapheme-to-phonemealgorithm trained on the CMUdict (Pagel et al1998).Next, PSSs and CBSs are computed sequen-tially for each pair of contiguous phonetic rep-resentations, and are used in their respectivemethods to compute the following measures:mean pairwise similarity score (MPSS), meanchain length (MCL), and maximum chain length(MXCL).
Singletons are included in these calcula-tions as chains of length 1.We also calculate equivalent measures for clus-ters, but do not present these results here due tospace limitations, as they are similar to those forchains.
In addition to these measures, our sys-tem produces a count of the total number of wordsthat start with the letter specified for the PVF test(WCNT), and a count of repeated words (RCNT).3 Pilot Study3.1 ParticipantsWe used PVF tests from 55 boxers and mixedmartial artists (4 women, 51 men; mean age 27.7y.o., SD 6.0) that participated in the ProfessionalFighters Brain Health Study (PFBH).
The PFBHis a longitudinal study of unarmed active profes-sional fighters, retired professional fighters, andage/education matched controls (Bernick et al inpress).
It is designed to enroll over 400 partici-pants over the next five years.
The 55 participantsin our pilot represent a sample from the first waveof assessments, conducted in summer of 2012.
All55 participants were fluent speakers of English andwere able to read at at least a 4th-grade level.
Noneof these participants fought in a professional oramateur competition within 45 days prior to test-ing.3.2 MethodsEach participant?s professional fighting historywas used to determine his or her total number ofpro fights and number of fights per year.
Thesefigures were used to construct a composite fight-exposure index as a summary measure of cumula-tive traumatic exposure, as follows.8860.00.10.20.3Common Biphone Edit?DistancemPSSFighter_GroupHigh ExposureLow Exposure(a) Mean pairwise similarity score0123Common Biphone Edit?Distance ManualmCLFighter_GroupHigh ExposureLow Exposure(b) Mean chain/cluster length024Common Biphone Edit?Distance ManualmxCLFighter_GroupHigh ExposureLow Exposure(c) Max chain/cluster lengthFigure 3: Computation-method and exposure-group comparisons showing significant differences be-tween the low- and high-exposure fighter groups on MPSS, MCL, and MXCL measures.
Error barsrepresent 95% confidence intervals around the means.Fighters with zero professional fights were as-signed a score of 0; fighters with between 1 and 15total fights, but only one or fewer fights per year,were assigned a score of 1; fighters with 1-15 to-tal fights, and more than one fight per year, got ascore of 2; fighters with more than 15 total fights,but only one or fewer fights per year, got a scoreof 3; remaining fighters, with more than 15 fightsand more than one fight per year, were assignedthe highest score of 4.Due to the relatively small sample size in ourpilot study, we combined groups with scores of0 and 1 to constitute the low-exposure group(n = 25), and the rest were assigned to the high-exposure group (n = 30).All participants underwent a cognitive test bat-tery that included the PVF test (letter ?F?).
Theirresponses were processed by our system, andmeans for our chaining variables of interest, aswell as counts of total words and repetitions,were compared across the low- and high-exposuregroups.
Additionally, all 55 PVF responses weresubjected to manual phonetic clustering analysis,following the methodology of Troyer et al(1997).With this approach, clusters are used instead ofchains, and two words are considered phoneticallysimilar if they meet any of the following condi-tions: they begin with the same two orthographicletters; they rhyme; they differ by only a vowelsound (e.g., flip and flop); or they are homophones.For each clustering method, the differences inmeans between the groups were tested for sta-tistical significance using one-way ANOVA ad-justed for the effects of age and years of education.Spearman correlation was used to test for associ-ations between continuous variables, due to non-linearity, and to directly compare manually deter-mined clustering measures with corresponding au-tomatically determined chain measures.4 ResultsThe results of comparisons between the clusteringmethods, as well as between the low- and high-exposure groups, are illustrated in Figure 3.2We found a significant difference (p < 0.02)in MPSS between the high- and low-exposuregroups using the common-biphone method (0.15vs.
0.11), while with edit distance the differencewas small (0.29 vs. 0.28) and not significant (Fig-ure 3a).
Due to infeasibility, MPSS was not calcu-lated manually.Mean chain sizes determined by the common-biphone method correlated with manually deter-mined cluster sizes more strongly than did chainsizes determined by edit distance (?
= 0.73, p <0.01 vs. ?
= 0.48, p < 0.01).
Comparisons ofmaximum chain and cluster sizes showed a sim-ilar pattern (?
= 0.71, p < 0.01 vs. ?
= 0.39,p < 0.01).Both automatic methods showed significant dif-ferences (p < 0.01) between the two groups inMCL and MXCL, with each finding longer chainsin the high-exposure group (Figure 3b, 3c); how-ever, slightly larger differences were observed us-ing the common-biphone method (MCL: 2.79 vs.2.21 by common-biphone method, 3.23 vs. 2.80by edit-distance method; MXCL: 3.94 vs. 2.64 by2Clustering measures rely on chains for our automaticmethods, and on clusters for manual analysis.887common biphone, 4.94 vs. 3.76 by edit distance).Group differences for manually determined MCLand MXCL were also significant (p < 0.05 andp < 0.02, respectively), but less so (MCL: 1.71vs.
1.46; MXCL: 4.0 vs. 3.04).5 DiscussionWhile manual phonetic clustering analysis yieldedsignificant differences between the low- and high-exposure fighter groups, our automatic approach,which utilizes phonetic word representations, ap-pears to be more sensitive to these differences; italso appears to produce less variability on cluster-ing measures.
Furthermore, as discussed above,automatic analysis is much less labor-intensive,and thus is more scalable to large numbers of tests.Moreover, our system is not prone to human errorduring analysis, nor to inter-rater variability.Of the two automatic clustering methods, thecommon-biphone method, which uses binary sim-ilarity values, found greater differences betweengroups in MPSS, MCL, and MXCL; thus, it ap-pears to be more sensitive than the edit-distancemethod in detecting group differences.
Common-biphone measures were also found to better cor-relate with manual measures; however, both au-tomated methods disagreed with the manual ap-proach to some extent.
The fact that the auto-mated common-biphone method shows significantdifferences between group means, while havingless variability in measurements, suggests that itmay be a more suitable measure of phonetic clus-tering than the traditional manual method.These results are particularly important in lightof the difference in WCNT means between low-and high-exposure groups being small and not sig-nificant (WCNT: 17.6, SD 5.1 vs. 18.7, SD 4.7;p = 0.24).
Other studies that used manual cluster-ing and switching analyses reported significantlymore switches for healthy controls than for indi-viduals with neurological conditions (Troyer et al1997).
These studies also reported differences inthe total number of words produced, likely due toinvestigating already impaired individuals.Our findings show that the low- and high-exposure groups produced similar numbers ofwords, but the high-exposure group tended toproduce longer sequences of phonetically simi-lar words.
The latter phenomenon may be inter-preted as a mild form of perseverative (stuck-in-set/repetitive) behavior that is characteristic of dis-orders involving damage to frontal and subcorticalbrain structures.To test this interpretation, we correlated MCLand MXCL, the two measures with greatest dif-ferences between low- and high-exposure fighters,with the count of repeated words (RCNT).
Theresulting correlations were 0.41 (p = 0.01) and0.48 (p < 0.001), respectively, which supports theperseverative-behavior interpretation of our find-ings.Clearly, these findings are preliminary and needto be confirmed in larger samples; however, theyplainly demonstrate the utility of our fully auto-mated and quantifiable approach to characteriz-ing and measuring clustering behavior on PVFtests.
Pending further clinical validation, this sys-tem may be used for large-scale screening for sub-tle signs of certain types of brain damage or de-generation not only in contact-sports athletes, butalso in the general population.6 AcknowledgementsWe thank the anonymous reviewers for their in-sightful feedback.ReferencesAtsushi Fujii and Tetsuya Ishikawa.
2001.Japanese/English cross-language informationretrieval: Exploration of query translation andtransliteration.
In Computers and the Humanities35.4.A.L.
Benton, K.D.
Hamsher, and A.B.
Sivan.
1989.Multilingual aphasia examination.C.
Bernick, S.J.
Banks, S. Jones, W. Shin, M. Phillips,M.
Lowe, M. Modic.
In press.
Professional Fight-ers Brain Health Study: Rationale and methods.
InAmerican Journal of Epidemiology.Brandon E. Gavett, Robert A. Stern, and Ann C. Mc-Kee.
2011.
Chronic traumatic encephalopathy: Apotential late effect of sport-related concussive andsubconcussive head trauma.
In Clinics in SportsMedicine 30, no.
1.Aileen K. Ho, Barbara J. Sahakian, Trevor W. Rob-bins, Roger A. Barker, Anne E. Rosser, and John R.Hodges.
2002.
Verbal fluency in Huntington?s dis-ease: A longitudinal analysis of phonemic and se-mantic clustering and switching.
In Neuropsycholo-gia 40, no.
8.Vladimir I. Levenshtein.
1966.
Binary codes capableof correcting deletions, insertions and reversals.
InSoviet Physics Doklady, vol.
10.888Fei Liu, Fuliang Weng, and Xiao Jiang.
2012.
A broad-coverage normalization system for social media lan-guage.
In Proceedings of the 50th Annual Meetingof the Association for Computational Linguistics:Long Papers-Volume 1.
Association for Computa-tional Linguistics.Kevin Knight and Jonathan Graehl.
1998.
Machinetransliteration.
In Computational Linguistics 24.4.Grzegorz Kondrak, Daniel Marcu, and Kevin Knight.2003.
Cognates can improve statistical translationmodels.
In Proceedings of the 2003 Conferenceof the North American Chapter of the Associationfor Computational Linguistics on Human LanguageTechnology: Companion Volume of the Proceed-ings of HLT-NAACL 2003.
Association for Compu-tational Linguistics.I.
Dan Melamed.
1999.
Bitext maps and alignmentvia pattern recognition.
In Computational Linguis-tics 25.1.Bennet I. Omalu, Julian Bailes, Jennifer Lynn Ham-mers, and Robert P. Fitzsimmons.
2010.
Chronictraumatic encephalopathy, suicides and parasuicidesin professional American athletes: The role of theforensic pathologist.
In The American Journal ofForensic Medicine and Pathology 31, no.
2.Vincent Pagel, Kevin Lenzo, and Alan Black.
1998.Letter to sound rules for accented lexicon compres-sion.Lawrence Rabiner and Biing-Hwang Juang.
1993.
Fun-damentals of speech recognition.Anand Raman, John Newman, and Jon Patrick.1997.
A complexity measure for diachronic Chi-nese phonology.
In Proceedings of the SIGPHON97Workshop on Computational Linguistics at theACL97/EACL97.Sarah A. Raskin, Martin Sliwinski, and Joan C. Borod.1992.
Clustering strategies on tasks of verbal fluencyin Parkinson?s disease.
In Neuropsychologia 30, no.1.Sarah A. Raskin and Elizabeth Rearick.
1996.
Verbalfluency in individuals with mild traumatic brain in-jury.
In Neuropsychology 10, no.
3.Harold L. Somers.
1998.
Similarity metrics for align-ing children?s articulation data.
In Proceedings of the36th Annual Meeting of the Association for Compu-tational Linguistics and 17th International Confer-ence on Computational Linguistics-Volume 2.
Asso-ciation for Computational Linguistics.Kristina Toutanova and Robert C. Moore.
2002.
Pro-nunciation modeling for improved spelling correc-tion.
In Proceedings of the 40th Annual Meeting ofthe Association for Computational Linguistics.
As-sociation for Computational Linguistics.Angela K. Troyer, Morris Moscovitch, and Gor-don Winocur.
1997.
Clustering and switching astwo components of verbal fluency: Evidence fromyounger and older healthy adults.
In Neuropsychol-ogy, 11.Angela K. Troyer, Morris Moscovitch, GordonWinocur, Michael P. Alexander, and Don Stuss.1998a.
Clustering and switching on verbal fluency:The effects of focal frontal- and temporal-lobe le-sions.
In Neuropsychologia.Angela K. Troyer, Morris Moscovitch, GordonWinocur, Larry Leach, and Morris Freedman.1998b.
Clustering and switching on verbal fluencytests in Alzheimer?s and Parkinson?s disease.
InJournal of the International Neuropsychological So-ciety 4, no.
2.Robert Weide.
2008.
Carnegie Mel-lon Pronouncing Dictionary, v. 0.7a.http://www.speech.cs.cmu.edu/cgi-bin/cmudict.889
