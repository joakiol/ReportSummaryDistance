Noise as a Tool for Spoken Language Identification.Sunita MaithaniScientific Analysis Group,Defense Research & Development Organization,Metcalfe House, Delhi-110054, India.E-mail: ysmaithani58@yahoo.comAbstractSegmental SNR (Signal to Noise Ratio) isconsidered to be a reasonable   measure ofperceptual quality of speech.
However itonly reflects the distortion in timedependent contour of the signal due tonoise.
Objective Measures such as LogArea Ratio (LAR), Itakura-SaitioDistortion (IS), Log-Likelihood Ratio(LLR) and Weighted Spectral Slope(WSS) are better   measures of perceptualspeech quality as they represent deviationin the spectrum.
Noise affects the speechtime contour and the correspondingfrequency content.
Different languageshave some peculiar characteristics due tovariation in the phonetic content and theirdistribution.
Distortion introduced by noiseand application of enhancement algorithmvaries for different phonemes.
In this papera novel idea of using noise and speechenhancement as means of identifying alanguage is presented, using objectivemeasures of speech quality.
Study is doneon three spoken Indian regional languagesnamely Kashmiri, Bangla and Manipuri,when corrupted by white noise.
It is foundthat the objective measures of noisyspeech, when determined usingcorresponding clear and enhanced speechare different for different languages over arange of SNR, giving clue to the type ofthe language in use.1.
IntroductionSpeech is a  signal  which   easily   gets   corruptedas  it  comes   in  contact   with   the   environment.J.
S. Rawat.Scientific Analysis Group,Metcalfe House, Delhi-110054, India.Defense Research & Development Organization,Except in sound-proof rooms used in studios, it isnot possible to find such ideal noise free conditionsin practice.
Although a large number of noisesexist in environment, broadly they can be classifiedinto Factory, Babble, Engine, White and Channelnoises etc.
However most common kind of noiseencountered is white noise, may it be incommunication systems due to channel orgenerated in the equipment due to thermal or otherelectronic sources or combination of noises due toCentral Limit Theorem (Aleksandr Lyapunov,1901).
Noise thus corrupts the speech, causinglistener?s fatigue and deteriorating performance ofspeech systems.
Application of Speechenhancement or noise cancellation algorithmsalleviates such problems to some extent.
Inliterature several speech enhancement techniquesexist.
Though most traditional algorithms are basedon optimizing mathematical criteria,  they are notwell correlated with speech perception and havenot been as successful in preserving or improvingquality in all regions of speech, especiallytransitional and unvoiced.
Performance is alsoinfluenced by the specific type of noise, specificSNR, noise estimate updates and algorithmparameter settings.
Spectral Subtraction techniqueof speech enhancement is popular and is stillwidely used as front end to speech systems for itssimplistic nature and high quality performanceexcept at very low SNRs (J. Lim, 1983).Variety of languages exists in Indian    region,with Dravidian, Tibeto-Burman, Indo-European,Indo-Aryan and Indo Iranian background.
MostlyIndian languages are phonetic in nature that isthere is one to one correspondence between soundsand the representative alphabet, and combiningthem  creates similar kind of sounds.
Howeverdifferent languages vary in its perceptibility due to811differences  in its phonetic contents and variationsin distribution of different phonemes, stress leveldistribution among phonemes and of courseintonation pattern, nasality usage, allophonicvariants, contextual, phonotactic, or coarticulatoryconstraints etc.Introduction of noise in speech distorts thespeech spectrum and affects its phoneticperceptibility differently, due to the factorsmentioned above.
Enhancement of   noisy speechthough reduces the noise and subsequent irritation,but generally results in distortion of the speechspectrum.
The kind and amount of distortion in thespectrum of enhanced speech will depend on theparticular enhancement technique applied, and theSNR of the noisy speech.
Therefore different typesof speech units will get affected differently by thenoise and subsequent enhancement.In this paper, a novel work on identification ofspoken languages, based on effect of distortionintroduced by white noise in the phonetic contentsof different Indian Regional languages namelyKashmiri, Bangla and Manipuri is reported.
Thiskind of approach is not found in the literature forany other language as well.
Effect of Speechenhancement technique namely spectralsubtraction on noisy speech of these languages isalso studied   at different levels of segmental SNR.White   noise has been considered for noisy spokenlanguage, as it affects all frequency components ofspeech uniformly.
The distortion introduced in theresulting speech is measured by estimatingobjective measures of perceptual speech qualitysuch as LLR, LAR, IS and WSS (Hansen andPellom, 1998).
The variation of these estimatedobjective measures of the spectral distortion, withregard to a particular language, is studied andanalyzed, to see language specific effects of thenoise and enhancement algorithm, in order toprovide clue to the identity   of language in use.The paper has been organized in the followingform:  Section 2 gives details of SpectralSubtraction technique of enhancement used.Section 3 gives a comparative study ofphonotactics of the three languages i.e.
Kashmiri,Bangla and Manipuri in brief.
Section 4 introducesthe objective measures used, namely LAR, IS,LLR and WSS.
Section 5 describes the Results anddiscussion.
Section 6 gives conclusions.2.
Spectral SubtractionThis technique of speech enhancement iscomputationally very efficient, particularly forstationary noise or slowly varying non-stationarynoise.
Spectral subtraction is a noise suppressiontechnique used to reduce the effects of added noisein speech.
It estimates the power of clean speechby explicitly subtracting the estimated noise powerfrom the noisy speech power.
This of courseassumes that the noise and speech are uncorrelatedand additive in the time domain.
Also, as spectralsubtraction based  techniques necessitateestimation of noise during regions of non-speechactivity, it is supposed that noise characteristicschange slowly.
However, because noise isestimated during speech pauses, this makes themethod computationally efficient.
Unfortunately,for these reasons, spectral subtraction is beset by anumber of problems.
First, because noise isestimated during pauses the performance of aspectral subtraction system relies upon a robustnoise/speech classification system.
If amisclassification occurs this may result in amisestimating of the noise model and thus adegradation of the speech estimate.
Spectralsubtraction may also result in negative powerspectrum values, which are then reset to non-negative values.
This results in residual noiseknown as musical noise.
In a speech enhancementapplication it has been shown that, at 5 dB SNR,the quality of the speech signal is improvedwithout decreasing intelligibility.
However, atlower SNR speech this performance reducesrapidly.
When used in Automatic SpeechRecognition (ASR), the trade-off between SNRimprovement and spectral distortion is important.To provide a mathematical description of thespectral subtraction technique, we write thespectrum of the noisy speech y (t) in terms of thatof the clean speech x (t) and additive noise n (t)(the simplest acoustic distortion model):y (t) = x (t) + n (t)                                   - (1)The enhancement is explained in the followingformula (Berouti et al, 1979).812- (2)and      are DFT (discrete fouriertransform) of the enhanced and noisy signal.
N (w)is estimate of noise and ?y  phase of originalsignal.
?
is 2 for working in  power spectrumdomain  and ?
is the over subtraction factor.
( )wX?
( )wY3.
Characteristics of   Manipuri, Bangla andKashmiri spoken languagesDifferent Indian regional languages havecertain linguistic background of their own andlater have added certain foreign loan words.Their phonotactics and grammar is also quitedistinct Following are features of abovespoken languages:Manipuri:  It is a Tibeto-Burman language.
Toneis used to convey phonemic distinction.
Aspiratesare present.
High frequency of the velar nasal isparticularly striking.
Grammatical gender ismissing.
The normal order of words in a sentenceis SOV-subject, object, verb, though this is notalways and everywhere rigorously observed.Tibeto-Burman words are monosyllables.Phonological system of Manipuri can becategorized into two groups ?
segmental phonemesand supra-segmental phonemes.
Segmentalphoneme includes vowels and consonants andsupra-segmental phoneme includes tone andjuncture.
All the six Manipuri vowels can occur ininitial, medial and final position.
There are sixdiphthong like sounds in Manipuri.
They are- ( /?y/,/ay/,   /?w/ ,/oy/, /uy/, /aw/)There are 24 consonant phonemes in Manipurip,t,k, ph,th,kh,m, n,?,c,s,l, h,w,y,b d,g,bh,dh,gh,j, jh,r  .
Among these the last 9 voicedsounds are borrowed from other languages andthey cannot occur in the initial and final position.Only four phonemes can occur in the secondelement of the cluster.
They are w, y, r and l. It canoccur only in the initial and medial position of aword.
There are two types of tone in the languagelevel and falling tone.
Juncture, other than phoneticfeatures, has a phonemic status.Bangla: An Indo-Aryan language.
Standardcolloquial Bengali contains 35 essential phonemes.5 non-essential phonemes which occur only asvariants of other sounds or in    borrowed foreignwords & not used by all speakers.
The tenaspirated stops and affricates are characteristicsand essential sounds of   the language.
They arenot simple but compounds.
( ) )(1)()(?
wj yewNwYwX ????
?Seven vowel phonemes occur with theiropposite nasal phoneme.
All may be long or short.Length   is not considered to be phonemic.
Thereis one 1st person pronoun, three 2nd personpronouns and three pairs of   3rd person pronounswith polite, informal, singular, pluraldiscrimination.
Pronoun and verb have no genderdiscriminatory word.
Most of the sentences don?texplicitly use verbs.
Verbs are inflected in person(1st, 2nd, 3rd), in degrees of politeness (intimate,familiar, respectful), and in tense (past, present,future).
Plural can be inflected by adding suffix ?ra, -der, -era, -diger, -guli, -gulo, -gana.
Thedominant word order in Modern Bengali sentencesis:Subject + Indirect object + Direct object +Oblique object + Verb.Kashmiri:  All the vowels have a nasalcounterpart.
Nasalization is phonemic in Kashmiri.Palatalization is phonemic in Kashmiri.
All thenon-palatal consonants in Kashmiri can bepalatalized.
There are eight pairs of short andlong vowels.
Kashmiri is a syllable-timedlanguage, sometimes; individual words are stressedfor emphasis.
There are four major types ofintonational patterns: (1) High - fall, (2) High -rise, (3) Rise &fall, (4) Mid - level.
Intonationshave syntactic rather than emotional content.Vowels /?/, /o/, /?
:/ do not occur in the word finalposition.
The short vowels /?/, /e/, /u/, and / ?/ donot occur in the word-initial position.
Usually thesemi-vowel /y/ is added in the initial position ofthe words beginning with /i/, /i:/, /e/ and /e:/.Similarly, the semi-vowel /v/ is added to the wordsbeginning with /u/, and /u:/.
Vowel sequencesusually do not occur in Kashmiri.
Word initialconsonant clusters are not as frequent as the wordmedial consonant clusters.
Kashmiri has(C)(C)V(C)(C) syllable structure.????
????
?=?8134.
Objective methods  of speech qualitymeasureIn general speech enhancement or noise reductionis   measured in terms of improvement in SNR, butin reality, this may not be the most appropriateperformance criteria for improvement ofperceptual speech quality.
Humans do have anintuitive understanding of spoken language quality,however this may not be easy to quantify.
In anumber of studies, it has been shown that impact ofnoise on degradation of speech quality is nonuniform.
An objective speech quality measureshows, the level of distortion for each frame,across time.
Since speech frequency content varies,across time, due to sequence of phonemes, neededto produce the sentence, impact of backgrounddistortion will also vary, causing some phoneclasses to get more effected than others, whenproduced in a noisy environment.
Objectivemethods rely on mathematically based measurebetween reference signal and the signal underconsideration.
The objective measures are basedon different parametric representation of thespeech, and differ due to inclusion or non-inclusion of various parameters and the differentweightage given to them, in order to imitateauditory model and perception as closely aspossible.
The details of each one is given below.Itakura-Saitio Distortion Measure (IS):  If foran original clean frame of speech, linearprediction (LP) coefficient vector is, correlation matrix is Rwhere K,        are related to overall sound pressurelevel of the original and enhanced utterances, andK?.
And forprocessed speech LP coefficient vector is    ,correlation matrix is Rd  , then Itakura-Satiodistortion measure is given by,- (3)Where       and       represents the all-pole gains forthe processed and clean speech frame respectively.Log-Likelihood Ratio Measure (LLR): The LLRmeasure is also referred to as the Itakura distance.The LLR measure is found as follows,- (4)Log-Area-Ratio Measure (LAR): The LARmeasure is also based on dissimilarity of LPcoefficients between original and processed speechsignals.
The log-area-ratio parameters are obtainedfrom the pth order LP reflection coefficients for theoriginal              and processed           signals forframe j.
The objective measure is formed asfollows,- (5)Weighted Spectral Slope Measure (WSS): TheWSS measure by Klatt (1982) is based on anauditory model, in which 36 overlapping filters ofprogressively larger bandwidth are used, toestimate the smoothed short-time speech spectrum.The measure finds a weighted difference betweenthe spectral slopes in each band.
The magnitude ofeach weight reflects whether the band is near aspectral peak or valley, and whether the peak is thelargest in the spectrum.
A per-frame measure indecibel is found as- (6)spl   is a parameter which can be varied to increaseoverall performance.5.
Results and DiscussionSentences Spoken by 30 native speakers for eachlanguage namely Manipuri, Bangla and Kashmiriwere recorded at 16 KHz.
Noisy speech with whitenoise   was simulated  with  segmental  SNR  from30 dB to -20 dB.
Objective measures i.e.
IS, LAR,LLR and WSS are computed for each frame, withlength ~ 512 samples.
In first experiment thesemeasures are computed for the noisy speech withreference to the corresponding clean speechsentence, whereas in second experiment theobjective measures   are computed using enhancedspeech and the corresponding noisy speech fordifferent sentences of the languages.
Estimates   ofthese measures are determined for the completesentence  using two methods, namely 5% trim( )( )( )( )211 ?1?1log11log1 ?= ?????????+?
?+=Mi ddLAR jrjrjrjrMd??
( ) ( ) ( ) ( ) ( )( )?=?+?=3612?
?kasplWSS kSkSkwKKKjd( ) 1log,2222?????????+????????????????=???????
???
?dTTddddIS aRaaRaaad rrrrrr( ) ?????
aRd?aR??
?= TTdddLLR aaaa????
rrrrrrlog,d2d?
2??
)( jr ( jr )?K)?arard814mean and median of their values computed foreach frame.
Spectral subtraction method ofenhancement is applied to obtain enhanced speechfrom the noisy speech sentences.
For 10 dBSegSNR noisy speech, the spectrograms of thespeech in three languages corresponding to Clean,Noisy and Enhanced, is shown in figure 1.
It isobserved through the spectrograms, that the noisehas affected the three languages differently.
?Figure 1.
Speech Spectrograms descriptionsRows: 1st-Clear, 2nd-Noisy, 3rd-Enhanced;Columns: 1st-Kashmiri, 2nd -Manipuri, 3rd -Bangla?Estimates of LLR, LAR, IS and WSS arecomputed for SNR range 30 dB to -30 dB fordifferent speech sentences in the three languagesusing noisy and clear and then enhanced and noisyspeech.
It is seen that WSS measure has the widestdynamic range almost 10 times the other measures?Figure 2.
LLR, LAR, IS and WSS estimates vs.SNR plots in Manipuri Speech with experiment-1.
?as shown in figure 2. of experiment -1, usingManipuri Speech.
Thus it can be seen, that WSS ismost suitable for the studies of distortion effects,of noise and enhancement algorithm, on differentspoken languages.WSS estimates of noisy speech, at different SNRare computed, as in experiment-1, and plotted infigure 3.
It is observed that Manipuri is havinglowest WSS estimate followed by Kashmiri andthen highest for Bangla.
This trend is moreprominent particularly for low SNRs.
The otherpoints of plot are for Hindi and mixed languages.S N R in dB         S N R in dBS N R in dB         S N R in dBS N R in dB         S N R in dBS N R in dB       S N R in dBS N R in dB         S N R in dBS N R in dB         S N R in dB?Figure 3.
Plots of WSS estimates (y axis) as inexperiment 1. , for different SNRs in dB i.e.
-25, -20,-15, -15, -10, 0, 5, 10, 15, 20, 25, 30    for Kashmiri,Manipuri,  Bangla,  Hindi   and mixed languages( denoted in x axis by 1, 2, 3, 4, 5 respectively)?In experiment 2, WSS and LAR estimates arecomputed for enhanced speech, with reference to thecorresponding noisy speech, for the three languagesnamely Kashmiri, Manipuri, and Bangla.
Theenhanced speech is obtained after application of815spectral subtraction algorithm on noisy speech of   ofdifferent SNRs,   ranging   from  30 dB  to  -20 dBIn this paper a study is done for possibility of usingLLR, LAR, IS and WSS as objective measures ofspeech   quality,   for discrimination of   Indianregional languages namely Kashmiri, Manipuri andBangla.
This is done by computing estimates ofthese objective measures for noisy speech withwhite noise for the above spoken languages and atSNRs  -30 dB to 30 dB.
First these measures arecomputed for noisy speech with reference tocorresponding clear speech and then for theenhanced speech with reference to thecorresponding noisy speech.
WSS has proved to bethe most useful measure used due to its widerdynamic range.
The two estimates of WSS doprovide clue to the type of language in use due todifferences in its phonetic content.
Thediscrimination provided is highest at lower SNRs.The estimate being lowest for Manipuri, andhighest for Bangla.
The reason could be attributedto the presence of weaker speech units in relativelyhigher concentration, in the language with higherWSS estimates compared to others; as    the speechparameters under consideration for them, wouldundergo higher distortion under the influence ofnoise.in steps of 5 dB.
The mean and median  estimatesof the WSS for  the 2nd  experiment  are shown  intable 1.
Here  also  the  WSS  estimate  is  lowestfor Manipuri, followed by Kashmiri  and  Banglais the highest.
This trend  is  more prominent forlow SNRs.WSS Estimates SNRindBLanguage Median     Mean30 KashmiriManipuriBangla36.2279332.1204138.0658942.5287436.8381342.3087925 KashmiriManipuriBangla40.2549434.7088042.70503345.3482139.6788848.9224520 KashmiriManipuriBangla46.7214738.0318851.4271853.0961642.9519457.5344115 KashmiriManipuriBangla53.7070045.7385760.8580560.9467751.0968567.1744010 KashmiriManipuriBangla65.4308458.6126570.7338871.2464571.9442677.702580 KashmiriManipuriBangla87.7234971.2616992.2374692.3202578.0322497.70964-5 KashmiriManipuriBangla94.5097678.38978101.406497.4375583.14540104.6625-10 KashmiriManipuriBangla98.7040385.42304105.2050100.809791.05538109.2263-20 KashmiriManipuriBangla101.842696.24993109.1610106.9107101.5472112.9643?Table 1.
Median and Mean estimates of WSS forEnhanced speech in Kashmiri, Manipuri andBangla for SNRs -30 dB to 20 dB as in Experiment2.?6.
Conclusion7.
AcknowledgementThe authors are thankful to Director, Dr. P KSaxena and Dr S S Bedi for encouraging us tocarry out this work and allowing presentation ofthe paper.ReferencesA.F Martin F.J. Godman and R.E.Wohlford.1989.
Improved automatic languageidentification in noisy speech.
Proc Int ConfAcoust.
Speech, and Signal Processing .May.
528-531John H.L.
Hansen and Bryan L. Pellom.
Nov1998.
Speech  Enhancement   and   QualityAssessment:   A  Survey,     IEEE    SignalProcessing magazineJ.
Lim.
1983.
Speech   Enhancement.
PrenticeHall Englewood Cliffs, NJ.Klatt, D.1982.
Prediction of perceived phoneticdistance from critical-band spectra.
Proc.
ofIEEE Int.
Conf on ASSP, 1278-1281.M.
Berouti, R. Schwartz and J. Mahoul.1979.Enhancement  of   Speech   corrupted   byacoustic noise.
ICASSP, 208-211816
