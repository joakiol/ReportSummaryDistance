Proceedings of the NAACL HLT 2013 Student Research Workshop, pages 16?23,Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational LinguisticsA Machine Learning Approach to Automatic Term Extractionusing a Rich Feature Set?Merley da Silva Conrado, Thiago A. Salgueiro Pardo, and Solange Oliveira RezendeLaboratory of Computational Intelligence,An Interinstitutional Center for Research and Development in Computational Linguistic,Institute of Mathematical and Computer Sciences,University of Sao Paulo (USP),P.O.
Box 668, 13561-970, Sao Carlos-SP, Brazil{merleyc,taspardo,solange}@icmc.usp.brAbstractIn this paper we propose an automatic termextraction approach that uses machine learn-ing incorporating varied and rich features ofcandidate terms.
In our preliminary experi-ments, we also tested different attribute se-lection methods to verify which features aremore relevant for automatic term extraction.We achieved state of the art results for uni-gram extraction in Brazilian Portuguese.1 IntroductionTerms are terminological units from specialisedtexts (Castellv??
et al 2001).
A term may be: (i) sim-ple1 (a single element), such as ?biodiversity?, or (ii)complex (more than one element), such as ?aquaticecosystem?
and ?natural resource management?.Automatic term extraction (ATE) methods aim toidentify terminological units in specific domain cor-pora (Castellv??
et al 2001).
Such information is ex-tremely useful for several tasks, from the linguisticperspective of building dictionaries, taxonomies andontologies, to computational applications as infor-mation retrieval, extraction, and summarisation.Although ATE has been researched for more than20 years, there is still room for improvement.
Thereare four major ATE problems.
The first one is thatthe ATE approaches may extract terms that are notactual terms (?noise?)
or do not extract actual terms(?silence?).
Considering the ecology domain, an ex-ample of silence is when a term (e.g., pollination),?This research was supported by FAPESP (Proc.
No.2009/16142-3 and 2012/09375-4), Brazil.1When we refer to unigrams, we mean simple terms.with low frequency, is not considered a candidateterm (CT), and, therefore, it will not appear in theextracted term list if we consider its frequency.
Re-garding noise, if we consider that nouns may beterms and that adjectives may not, if an adjective(e.g., ecological) is mistakenly tagged as a noun, itwill be wrongly extracted as a term.
The secondproblem is the difficulty in dealing with extremelyhigh number of candidates (called the high dimen-sionality of candidate representation) that requirestime to process them.
Since the ATE approaches ge-nerate large lists of TCs, we have the third problemthat is the time and human effort spent for validat-ing the TCs, which usually is manually performed.The fourth problem is that the results are still not sa-tisfactory and there is a natural ATE challenge sincethe difficulty in obtaining a consensus among the ex-perts about which words are terms of a specific do-main (Vivaldi and Rodr?
?guez, 2007).Our proposed ATE approach uses machine learn-ing (ML), since it has been achieving high precisionvalues (Zhang et al 2008; Foo and Merkel, 2010;Zhang et al 2010; Loukachevitch, 2012).
AlthoughML may also generate noise and silence, it facili-tates the use of a large number of TCs and their fea-tures, since ML techniques learn by themselves howto recognize a term and then they save time extract-ing them.Our approach differs from others because weadopt a rich feature set using varied knowledge lev-els.
With this, it is possible to decrease the silenceand noise and, consequently, to improve the ATEresults.
Our features range from simple statistical(e.g., term frequency) and linguistic (e.g., part of16speech - POS) knowledge to more sophisticated hy-brid knowledge, such as the analysis of the termcontext.
As far as we know, the combined use ofthis specific knowledge has not been applied before.Another difference is that we apply 3 statistical fea-tures (Term Variance (Liu et al 2005), Term Vari-ance Quality (Dhillon et al 2003), and Term Con-tribution (Liu et al 2003)) that to date have onlybeen used for attribute selection and not for term ex-traction.
As far as we know, the combined use ofthis specific knowledge and feature feedback has notbeen applied before.
We also propose 4 new linguis-tic features for ATE.
All these features are detailed inSection 4.
Finally, for the first time, ML is being ap-plied in the task of ATE in Brazilian Portuguese (BP)corpora.
Our approach may also be easily adapted toother languages.We focus on extracting only unigram terms, sincethis is already a complex task.
We run our experi-ments on 3 different corpora.
Our main contributionis the improvement of precision (in the best case, weimprove the results 11 times) and F-measure (in thebest case, we improve 2 times).Section 2 presents the main related work.
Section3 describes our ATE approach.
Section 4 details theexperiments, and Section 5 reports the results.
Con-clusions and future work are presented in Section 6.2 Related WorkThere are several recent and interesting studies thatare not focused on extracting unigrams (Estopa` etal., 2000; Almeida and Vale, 2008; Zhang et al2008; Zhang et al 2010; Nazar, 2011; Vivaldi et al2012; Lopes, 2012).
Normally, ATE studies use cor-pora of different domain and language and, in somecases, the authors use different evaluation measures.Regardless of variation (e.g., the size of the test cor-pora), we mention studies that have highlighted re-sults for unigrams2.
When possible, we show thebest precision (P) of the related work and its recall(R).
(Ventura and Silva, 2008) extracted terms usingstatistical measures that consider the predecessorsand successors of TCs.
They achieved, for English,P=81.5% and R=55.4% and, for Spanish, P=78.2%2It is not specified if (Zhang et al 2010) extracted simple orcomplex terms.and R=60.8%.
For Spanish, the Greek forms of acandidate and their prefix may help to extract terms(e.g., the Greek formant laring that belongs to theterm laringoespasm in the medical domain) (Vivaldiand Rodr?
?guez, 2007), achieving about P=55.4%and R=58.1%.
For Spanish, (Gelbukh et al 2010)compared TCs of a domain with words of a generalcorpus using Likelihood ratio based distance.
Theyachieved P=92.5%.
For Brazilian Portuguese, theExPorTer methods are the only previous work thatuniquely extract unigrams (Zavaglia et al 2007).Therefore, they are the state of the art for unigramsextraction for BP.
The linguistic ExPorTer consid-ers terms that belong to some POS patterns and usesindicative phrases (such as is defined as) that mayidentify where terms are.
It achieved P=2.74% andR=89.18%.
The hybrid ExPorTer used these lin-guistic features with frequency and Likelihood ratio.The latter one obtained P=12.76% and R=23.25%.3 Term Extraction Approach based onMachine LearningIn order to model the ATE task as a machine learn-ing solution, we consider each word in the inputtexts3 of a specific domain (except the stopwords)as a learning instance (candidate term).
For each in-stance, we identify a set of features over which theclassification is performed.
The classification pre-dicts which words are terms (unigrams) of a specificdomain.
We test different attribute selection meth-ods in order to verify which features are more rele-vant to classify a term.We start by preprocessing the input texts, asshown in Figure 1.
This step consists of POS tag-ging the corpora and normalizing4 the words of thetexts.
The normalization minimizes the second ATEproblem because it allows working with a lower CTrepresentation dimensionality.
When working witha lower dimensionality, the words that do not helpidentify terms are eliminated.
Consequently, fewercandidates should to be validated or refuted as terms(it would minimize the third ATE problem).
Whenworking with fewer candidates it also may improvethe result quality (it handles the fourth ATE prob-3When we refer to texts, we mean documents.4Normalization consists of standardizing the words by re-ducing their variations.17lem), and, definitely, it spends less time and fewerresources to carry out the experiments.
By improv-ing the results, consequently, we minimize silenceand noise, which handles the first ATE problem.Afterwards, we remove stopwords.In order to identify a set of features over whichthe classification is performed, we studied and testedseveral measures.
The feature identification is themost important step of our approach.
We divide thefeatures into two types: (i) the features that obtainstatistical, linguistic, and hybrid knowledge from theinput corpus, such as TFIDF and POS, and (ii) thefeatures that obtain these knowledge from measuresthat use other corpora besides the input corpus.
Thecorpora belong to another domain that is different ofthe input corpus domain (called contrastive corpora)or not belong to any specific domain (called generalcorpora).
Our hypothesis is that, with the joining offeatures of different levels of knowledge, it is possi-ble to improve the ATE.Figure 1: Term extraction approach proposed.4 Experimental SetupAt this point, for obtaining the knowledge in orderto extract terms, we tested 17 features that do notdepend on general or contrastive corpora and 2 fea-tures that depend on these corpora.
We intend toexplore more features (and we will possibly proposenew measures) that use contrastive or general cor-pora or any taxonomic structure.
The experimentsthat expand the number of features are ongoing now.We used 3 corpora of different domains in thePortuguese language.
The EaD corpus (Souza andDi Felippo, 2010) has 347 texts about distance edu-cation and has a gold standard with 118 terms5 (Gi-5(Gianoti and Di Felippo, 2011) stated that the EaD unigramgold standard has 59 terms, but in this paper we used 118 uni-grams that the authors provided us prior to their work.anoti and Di Felippo, 2011).
The second one is theECO6 corpus (Zavaglia et al 2007).
It contains 390texts of ecology domain and its gold standard has322 unigrams.
The latter is the Nanoscience andNanotechnology (N&N) corpus (Coleti et al 2008)that contains 1,057 texts.
Its gold standard has 1,794unigrams (Coleti et al 2008; Coleti et al 2009).In order to preprocess these corpora, we POStagged them using the PALAVRAS parser (Bick,2000) and normalized their words using a stem-ming7 technique.
Stemming was chosen because ofits capacity to group similar word meanings, and itsuse decreases representation dimensionality of can-didate terms, which minimizes the second and thirdATE problems.
Afterwards, we removed the stop-words8, the conjugation of the verb ?to be?, punctu-ation, numbers, accents, and the words composed ofonly one character are removed.We identify and calculate 19 features in which 11features are used for ATE in the literature, 3 featuresare normally applied to the attribute selection tasks(identified by *), 1 normally used for Named EntityRecognition (identified by **), and we created 4 newfeatures (identified by ?).
These features are shownin Table 1, accompanied by the hypotheses that un-derlie their use.
They are also divided into 3 levelsof knowledge: statistical, linguistic, and hybrid.For the S feature, we removed stopwords at thebeginning and at the end of these phrases.
ForPOS, we assumed that terms may also be adjectives(Almeida and Vale, 2008), besides nouns and verbs.For GC and Freq GC, we used the NILC Corpus9 asa general corpus, which contains 40 million words.We created and used 40 indicative phrases (NPs).For example, considering are composed of as an IPin All organisms are composed of one or more cells,we would consider organisms and cells as TCs.
Forfeatures related to CT stem, we analyzed, e.g., thewords educative, educators, education and educatethat came from the stem educ.
Therefore, educ may6ECO corpus - http://www.nilc.icmc.usp.br/nilc/projects/bloc-eco.htm7PTStemmer: A Stemming toolkit for the Portuguese lan-guage - http://code.google.com/p/ptstemmer/8Stoplist and Indicative Phrase list are avaiable inhttp://www2.icmc.usp.br/ merleyc/9NILC Corpus - http://www.nilc.icmc.usp.br/nilc/tools/corpora.htm18Table 1: Features of candidate terms.Feature Description HypothesisThe eight linguistic featuresS noun and prepositional phrases terms are noun phrases and, sometimes, prepositional phrasesN S head of phrases heads of noun and prepositional phrasesPOS noun, proper noun, and adjective terms follow some patternsIP indicative phrases IPs may identify definitions/descriptions that may be termsN noun ?
number of nounsN adj ?
number of adjectives stemmed terms come fromN verb ?
number of verbs higher number of nounsN PO ?
total of words from which stemmed TCs come from than adjectives or verbsThe seven statistical featuresSG** n-gram length each domain has a term patternTF Term Frequency terms have neither low nor very high frequenciesDF Document Frequency terms appear in at least certain number of documentsTFIDF Term Frequency Inverse Document Frequency terms are very common in the corpus(Salton and Buckley, 1987) but they occur in few documents in this corpusTCo* Term Contribution (Liu et al 2003) terms help to distinguish the different documentsTV* Term Variance (Liu et al 2005) terms do not have low frequency in documents and maintain aTVQ* Term Variance Quality (Dhillon et al 2003) non-uniform distribution throughout corpus (higher variance)The four hybrid featuresGC CT occurrence in general corpus terms do not occur with high frequency in a general corpusFreq GC CT frequency in GCC-value the potential of a CT to be a term (Frantzi et al 1998) the C-value helps to extract termsNC-value CT context (Frantzi et al 1998) candidate context helps to extract termshave as features N Noun = 2 (educators and educa-tion), N Adj = 1 educative, N Verb = 1 (educate),and N PO = 4 (total number of words).
Our hy-pothesis is that stemmed candidates that were origi-nated from a higher number of nouns than adjectivesor verbs will be terms.
Finally, we used NC-Valueadapted to unigrams (Barro?n-Ceden?o et al 2009).After calculating the features for each unigram(candidate term), the CT representation has high di-mensionality (it is the second ATE problem) and,hence, the experiments may take a considerableamount of time to be executed.
To decrease this di-mensionality and, consequently, the number of TCs(which corresponds to the second and third ATEproblems, respectively), we tested two different cut-offs, which preserve only TCs that occur in at leasttwo documents in the corpus.
The first cut-off iscalled C1.
In the second one (called C2), the can-didates must be noun and prepositional phrases andalso follow some of these POS: nouns, proper nouns,verbs, and adjectives.
The number of obtained can-didates (stems) was 10,524, 14,385, and 46,203,for the ECO, EaD, and N&N corpora, respectively.When using the C1 cut-off, we decreased to 55,15%,45,82%, and 57,04%, and C2 decreased 63.10%,63.18%, 66.94% in relation to the number of all theobtained candidates (without cutt-offs).5 Experimental Evaluation and ResultsThe first evaluation aimed to identify which fea-tures must be used for ATE (see Section 3).
Forthat, we applied 2 methods that select attributes byevaluating the attribute subsets.
Their evaluation isbased on consistency (CBF) and correlation (CFS).We also tested search methods.
The combinationof these methods, available in WEKA (Hall et al2009), is: CFS SubsetEval using the RankSearchFilter as search method (CFS R), CFS SubsetEvalusing the BestFirst as search method (CFS BF),CBF SubsetEval using the Ranking Filter (C R),and CBF SubsetEval using the Greedy Stepwise(C G).
These methods return feature sets that areconsidered the most representative for the term clas-sification (Table 2).
For the EaD corpus, the CG at-tribute selection method did not select any feature.For our experiments, we also considered all the fea-tures (referred by All).
Additionally, we comparedthe use of two cut-off types for each feature set, C1and C2, detailed in Section 4.For both evaluations8, we chose largely knowninductors in the machine learning area.
They rep-resent different learning paradigms: JRip (Rule In-duction), Na?
?ve Bayes (Probabilistic), J48 (DecisionTree) with confidence factor of 25%, and SMO (Sta-tistical Learning).
All of these algorithms are avail-19Table 2: Features chosen by the attribute selection meth-ods.Methods CorporaEaD ECO N&NCFS RTFIDF, TV, TVQ, TFIDF, TV, TVQ, Freq, TFIDF, TVQ,IP, N Noun, N Adj POS, N Noun IP, Cvalue, N Noun,POS, N Adj, N POCFS BFSame as in the TFIDF, TVQ, Freq, TFIDF, TV,CFS R method.
TCo, POS IP, Cvalue, N Noun,POS, N Adj, N POC RFreq, DF, TFIDF, Freq, DF, TFIDF, Freq, DF, TFIDF,TV, TVQ, TCo, IP, TV, TVQ, TCo, GC, TV, TVQ, TCo, GC,GC, POS, FreqGC, Cvalue, NCvalue, IP, S, Cvalue, POS,NCvalue, Cvalue, IP, S, N S, POS, NCvalue, N S,N Adj, N Noun, N Noun, N Adj, N Noun, N Adj,N Verb, N PO N Verb, N PO N Verb, N POC GMethod did Freq, DF, TFIDF, Freq, DF, TFIDF, S,not select any TV, TVQ, GC, IP, TV, TVQ, TCo, IP,feature.
N S, NCvalue, NCvalue, N S, POS,S, N Noun, POS, GC, N Noun, N PO,N Adj, N PO N Verb, N Adjable in WEKA and described in (Witten and Frank,2005).
We run the experiments on a 10 fold cross-validation and calculated the precision, recall, andF-measure scores of term classification according tothe gold standard of unigrams of each corpus.
Usingdefault parameter values for SMO, the results werelower than the other inductors.
Due to this fact andthe lack of space in the paper, we do not present theSMO results here.The best precision obtained for the EaD corpususing the term classification, 66.66%, was achievedby the C R attribute selection method with the C2cut-off (C R-C2) using the JRIP inductor.
The bestrecall score, 20.96%, was obtained using Na?
?veBayes with the CFS R-C1 method.
The best F-measure was 17.58% using the J48 inductor withC R-C2.
For the ECO corpus, the best precisionwas 60% obtained with the J48 inductor with con-fidence factor of 25% and the C R-C1 method.
Thebest recall was 21.40% with JRIP and the C G-C1method.
Our best F-measure was 24.26% obtainedwith Na?
?ve Bayes using the CFS R-C1 method.For the N&N corpus, the best precision score was61.03% using JRIP.
The best recall was 52.53% andthe best F-measure score was 54.04%, both usingJ48 inductor with confidence factor of 25%.
Thethree results used the All-C2 method.Table 3 shows the comparison of our best resultswith 2 baselines, which are the well-known term fre-quency and TFIDF, using our stoplist.
We also con-sidered all the stemmed words of these corpora asCT, except the stopwords, and we calculated the pre-cision, recall, and F-measure scores for these wordsas well.
Finally, we compared our results with thethird baseline, which is the only previous work thatuniquely extracts unigrams (Zavaglia et al 2007),described in Section 2.
Therefore, this is the stateof the art for unigrams extraction for Portuguese.
Inorder to compare this work with our results of theEaD and N&N corpora, we implemented the ATEmethod of Zavaglia et alWe have to mention thatthis method uses the normalization technique calledlemmatization instead of stemming, which we usedin our method.
The only difference between our im-plementation descriptions and the original method isthat we POS tagged and lemmatizated the texts usingthe same parser (PALAVRAS10 (Bick, 2000)) usedin our experiments instead of the MXPOST tagger(Ratnaparkhi, 1996).For all used corpora, we obtained better results ofprecision and F-measure comparing with the base-lines.
In general, we improve the ATE precisionscores, for the EaD corpus, eleven times (from 6.1%to 66.66%) and, for the N&N corpus, one and a halftimes (from 35.4% to 61.03%), both comparing ourresults with the use of TFIDF.
For the ECO corpus,we improve four and a half times (from 12.9% to60%), by comparing with the use of frequency.
Weimprove the ATE F-measure scores, for the EaD cor-pus, one and a half times (from 10.93% to 17.58%);for the ECO corpus, we slightly improve the results(from 20.64% to 24.26%); and, for the N&N cor-pus, two times (from 28.12% to 54.04%).
The lastthree cases are based on the best F-measure valuesobtained using TFIDF.
Regarding recall, on the onehand, the linguistic ExPorTer method (detailed inSection 2), to which we also compare our results,achieved better recall for all used corpora, about89%.
On the other hand, its precision (about 2%)and F-measure (about 4%) were significantly lowerthan our results.Finally, if we compare our results with the resultsof all stemmed words, with the exception of the stop-words, the recall values of the latter are high (about76%) for all used corpora.
However, the precisionscores are extremely low (about 1.26%), because itused almost all words of the texts.10As all NLP tools for general domains, PALAVRAS is notexcellent for specific domains.
However, as it would be expen-sive (time and manual work) to customize it for each specificdomain that we presented in this paper, we decided use it, eventhough there are error tagging.20Table 3: Comparison with baselines.Method Precision Recall F-Measure(%) (%) (%)The EaD corpusJRIP with C R-C2 66.66 8.06 14.38Na?
?ve Bayes 13.19 20.96 16.19with CFS R-C1J48 with F.C.
of 27.58 12.9 17.580.25 with C R-C2Ling.
ExPorTer 0.33 89.70 0.66Hyb.
ExPorTer 0.07 17.64 0.15Frequency 5.9 50.86 10.57TFIDF 6.1 52.58 10.93All the corpus 0.52 62.9 1.04The ECO corpusJ48 with F.C.
of 60.00 6.02 10.940.25 with C R-C1JRIP with C G-C1 23.44 21.40 22.38Na?
?ve Bayes 33.33 19.06 24.26with CFS R-C1Ling.
ExPorTer 2.74 89.18 5.32Hyb.
ExPorTer 12.76 23.25 16.48Frequency 12.9 43.28 19.87TFIDF 13.4 44.96 20.64All the corpus 1.48 99.07 2.92The N&N corpusJRIP with All-C2 61.03 27.73 38.14J48 with F.C.
of 55.64 52.53 54.040.25 with All-C2Ling.
ExPorTer 3.75 89.40 7.20Hyb.
ExPorTer 1.68 35.35 3.22Frequency 31.6 20.83 25.1TFIDF 35.4 23.33 28.12All the corpus 1.83 66.99 3.576 Conclusions and Future WorkThis paper described ongoing experiments aboutunigrams extraction usingML.
Our first contributionregarding the experiments was to create 4 featuresand to test 4 features that normally are applied toother tasks and not for automatic term extraction.Our second contribution is related to the first andfourth ATE problems, which are the existence of si-lence and noise and low ATE results, respectively.We achieved state of art results for unigrams inBrazilian Portuguese.
We improved, for all used cor-pora, precision (in the best case, we improve the re-sults 11 times using the EaD corpus) and F-measure(in the best case, 2 times using the N&N corpus)and, consequently, we minimized silence and noise.The third contribution is about the features thatare better for extracting domain terms.
All the testedattribute selection methods indicated the TFIDF asan essential feature for ATE.
90.9% of the meth-ods selected N Noun and TVQ, and 81.81% selectedTV, IP, N adj, and POS as relevant features.
How-ever, only one of these methods chose Freq GC, andnone of them chose the SG feature.
Regarding thelevels of knowledge - statistical, linguistic, and hy-brid - in which each feature was classified, at least45.45% of the methods chose 6 statistical, 5 linguis-tic, and 3 hybrid features.
We also observed that thebest F-measures (see Tables 2 and 3) were obtainedwhen using at least linguistic and statistical featurestogether.
This fact proves that our main hypothesis istrue, because we improved the ATE results by join-ing features of different levels of knowledge.
Addi-tionally, we allow the user to choose the features thatare better for term extraction.As the fourth contribution, we minimized theproblem of high dimensionality (as mentioned, thesecond ATE problem) by means of the use of twodifferent cut-offs (C1 and C2).
By reducing thenumber of TCs, fewer candidates were validated orrefuted as terms and, consequently, we minimizedthe third ATE problem, which is the time and humaneffort for validating the TCs.
However, we still per-ceived the need to reduce more the number of can-didates.
Therefore, for future work, we intend to useinstance selection techniques to reduce the term rep-resentation.We believe to have achieved significant results forthe experiments realized to date.
Experiments usingmore features that dependent on general corpus areongoing.
We will also possibly propose new featuresand will use taxonomic structure in order to improvemore the results.
For using the taxonomic structure,we intend to create a conventional taxonomy (Mi-iller and Dorre, 1999) is created using the input cor-pus.
Therefore, we may identify more features forthe instances considering this taxonomy.
For exam-ple, normally in a taxonomy?s leaf specific wordsof a domain happen, consequently, terms should ap-pear there.
Additionally, we are encouraged to adaptthese features for bigram and trigram terms as well.ReferencesG.
M. B. Almeida and O.
A. Vale.
2008.
Do textoao termo: interac?a?o entre terminologia, morfologia e21lingu?
?stica de corpus na extrac?a?o semi-automa?tica determos.
In A. N. Isquerdo and M. J.
B. Finatto, edi-tors, As Cie?ncias do Le?xico: Lexicologia, Lexicografiae Terminologia, volume IV, pages 483?499.
UFMS,MS, Brazil, 1 edition.A.
Barro?n-Ceden?o, G. Sierra, P. Drouin, and S. Anani-adou.
2009.
An improved automatic term recogni-tion method for spanish.
In Proc of the 10th Int.
CNFon Computational Linguistics and Intelligent Text Pro-cessing, pages 125?136, Berlin, Heidelberg.
Springer-Verlag.E.
Bick.
2000.
The Parsing System ?PALAVRAS?.
Auto-matic Grammatical Analysis of Portuguese in a Con-straint Grammar Framework.
University of Arhus,Arhus.M.
T. Cabre?
Castellv?
?, R. Estopa` Bagot, and Jordi VivaldiPalatresi.
2001.
Automatic term detection: a reviewof current systems.
In D. Bourigault, C. Jacquemin,and M-C. L?Homme, editors, Recent Advances inComputational Terminology, pages 53?88, Amster-dam/Philadelphia.
John Benjamins.J.
S. Coleti, D. F. Mattos, L. C. Genoves Junior, A. Can-dido Junior, A.
Di Felippo, G. M. B. Almeida,S.
M.
Alu?
?sio, and O. N. Oliveira Junior.
2008.Compilac?a?o de Corpus em L?
?ngua Portuguesa naa?rea de Nanocie?ncia/Nanotecnologia: Problemas esoluc?o?es, volume 1.
Tagnin and Vale., SP, Brazil, 192edition.J.
S. Coleti, D. F. Mattos, and G. M. B. Almeida.
2009.Primeiro diciona?rio de nanocie?ncia e nanotecnolo-gia em l?
?ngua portuguesa.
In Marcelo Fila Pecenin,Valdemir Miotello, and Talita Aparecida Oliveira, ed-itors, II Encontro Acade?mico de Letras (EALE), pages1?10.
Caderno de Resumos do II EALE.I.
Dhillon, J. Kogan, and C. Nicholas.
2003.
Featureselection and document clustering.
In M. W. Berry,editor, Survey of Text Mining, pages 73?100.
Springer.R.
Estopa`, J. Vivaldi, and M. T. Cabre?.
2000.
Use ofgreek and latin forms for term detection.
In Proc ofthe 2nd on LREC, pages 855?861, Greece.
ELRA.J.
Foo and M. Merkel.
2010.
Using machine learningto perform automatic term recognition.
In N. Bel,B.
Daille, and A. Vasiljevs, editors, Proc of the 7thLREC - Wksp on Methods for automatic acquisitionof Language Resources and their Evaluation Methods,pages 49?54.K.
T. Frantzi, S. Ananiadou, and J. I. Tsujii.
1998.The C-value/NC-value method of automatic recogni-tion for multi-word terms.
In Proc of the 2nd ECDL,pages 585?604, London, UK.
Springer-Verlag.A.
F. Gelbukh, G. Sidorov, E. Lavin-Villa, andL.
Chanona-Herna?ndez.
2010.
Automatic term ex-traction using log-likelihood based comparison withgeneral reference corpus.
In NLDB, pages 248?255.A.
C. Gianoti and A.
Di Felippo.
2011.
Extrac?a?o de con-hecimento terminolo?gico no projeto TermiNet.
Tech-nical Report NILC-TR-11-01, Instituto de Cie?nciasMatema?ticas e de Computac?a?o (ICMC) - USP, SP,Brazil.M.
Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reute-mann, and I. H. Witten.
2009.
The WEKA datamining software: An update.
In SIGKDD-ACM, vol-ume 11, pages 10?18.T.
Liu, S. Liu, and Z. Chen.
2003.
An evaluation onfeature selection for text clustering.
In Proceedings ofthe 10th Int.
CNF on Machine Learning, pages 488?495, San Francisco, CA, USA.
Morgan Kaufmann.L.
Liu, J. Kang, J. Yu, and Z. Wang.
2005.
A compar-ative study on unsupervised feature selection methodsfor text clustering.
In Proc of IEEE NLP-KE, pages597?601.L.
Lopes.
2012.
Extrac?a?o automa?tica de conceitos a par-tir de textos em l?
?ngua portugesa.
Ph.D. thesis, PortoAlegre, RS.
Pontif?
?cia Universidade do Rio Grande doSul (PUCRS).N.
Loukachevitch.
2012.
Automatic term recognitionneeds multiple evidence.
In N. Calzolari, K. Choukri,T.
Declerck, M. Dogan, B. Maegaard, J. Mariani,Odijk, and S. Piperidis, editors, Proc of the 8th onLREC, pages 2401?2407, Istanbul, Turkey.
ELRA.A.
Miiller and J. Dorre.
1999.
The taxgen frame-work: Automating the generation of a taxonomy fora large document collection.
In Proceedings of theThirty-Second Annual Hawaii International Confer-ence on System Sciences (HICSS), volume 2, pages2034?2042, Washington, DC, USA.
IEEE ComputerSociety.R.
Nazar.
2011.
A statistical approach to term extraction.Int.
Journal of English Studies, 11(2).A.
Ratnaparkhi.
1996.
A maximum entropy model forpart-of-speech tagging.
Proc of the CNF on EMNLP,pages 491?497.G.
Salton and C. Buckley.
1987.
Term weighting ap-proaches in automatic text retrieval.
Technical report,Ithaca, NY, USA.J.
W. C. Souza and A.
Di Felippo.
2010.
Um exerc?
?cioem lingu?istica de corpus no a?mbito do projeto Ter-miNet.
Technical Report NILC-TR-10-08, ICMC -USP, SP, Brazil.J.
Ventura and J. F. Silva.
2008.
Ranking and extrac-tion of relevant single words in text.
In Cesare Rossi,editor, Brain, Vision and AI, pages 265?284.
InTech,Education and Publishing.J.
Vivaldi and H.
Rodr??guez.
2007.
Evaluation of termsand term extraction systems: A practical approach.Terminology, 13(2):225?248.22J.
Vivaldi, L. A. Cabrera-Diego, G. Sierra, and M. Pozzi.2012.
Using wikipedia to validate the terminologyfound in a corpus of basic textbooks.
In N. Calzolari,K.
Choukri, T. Declerck, M. U. Dogan, B. Maegaard,J.
Mariani, J. Odijk, and S. Piperidis, editors, Proc ofthe 8th Int.
CNF on LREC, Istanbul, Turkey.
ELRA.I.
H. Witten and E. Frank.
2005.
Data Mining: Practi-cal Machine Learning Tools and Techniques, SecondEdition (Morgan Kaufmann Series in Data Manage-ment Systems).
Morgan Kaufmann Publishers Inc.,San Francisco, CA, USA.C.
Zavaglia, L. H. M. Oliveira, M. G. V. Nunes, andS.
M.
Alu??sio.
2007.
Estrutura ontolo?gica e unidadeslexicais: uma aplicac?a?o computacional no dom?
?nio daecologia.
In Proc.
of the 5th Wksp em Tecnologia daInformac?a?o e da Linguagem Humana, pages 1575?1584, RJ, Brazil.
SBC.Z.
Zhang, J. Iria, C. Brewster, and F. Ciravegna.
2008.A comparative evaluation of term recognition algo-rithms.
In N. Calzolari (CNF Chair), K. Choukri,B.
Maegaard, J. Mariani, J. Odjik, S. Piperidis, andD.
Tapias, editors, Proc of the 6th on LREC, pages2108?2113, Marrakech, Morocco.
ELRA.X.
Zhang, Y.
Song, and A. Fang.
2010.
Term recogni-tion using conditional random fields.
In Proc of IEEENLP-KE, pages 333?336.23
