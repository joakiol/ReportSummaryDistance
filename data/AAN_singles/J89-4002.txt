NATURAL LANGUAGE GENERATION FROM PLANSChris  Mel l ish I and Roger  EvansSchool of Cognitive and Computing SciencesUniversity of SussexFalmerBrighton BN1 9QNUnited KingdomThis paper addresses the problem of designing a system that accepts a plan structure of the sortgenerated by AI planning programs and produces natural language text explaining how to execute theplan.
We describe a system that generates text from plans produced by the NONLIN planner (Tate1976).The results of our system are promising, but the texts still lack much of the smoothness ofhuman-generated text.
This is partly because, although the domain of plans seems a prior i  to providerich structure that a natural language generator can use, in practice a plan that is generated without theproduction of explanations in mind rarely contains the kinds of information that would yield aninteresting natural language account.
For instance, the hierarchical organization assigned to a plan isliable to reflect more a programmer's approach to generating a class of plans efficiently than the waythat a human would naturally "chunk" the relevant actions.
Such problems are, of course, similar tothose that Swartout (1983) encountered with expert systems.
In addition, AI planners have a restrictedview of the world that is hard to match up with the normal semantics of natural language xpressions.Thus constructs that are primitive to the planner may be only clumsily or misleadingly expressed innatural language, and the range of possible natural language constructs may be artificially limited by theshallowness of the planner's representations.1 INTRODUCTIONPlanning is a central concept in Artificial Intelligence,and the state of the art in planning systems allows quitecomplex plans to be produced with very little humanguidance.
If these plans are to be for human consump-tion, they must be explained in a way that is compre-hensible to a human being.
There is thus a practicalreason for considering ways of generating natural lan-guage from plans.
There are also theoretical reasonswhy plans are a good domain for studying naturallanguage generation.
Although there may be a great dealof material in a given plan, there is a kind of consensusamong planning researchers on what sort of informationa plan is likely to contain.
Thus it is possible thatinteresting eneral principles about producing explana-tions of plans can be formulated, independently of thedomains in which the plans are produced.
This prop-erty, of providing a relatively formally defined and yetdomain-independent input, makes plans very attractivefrom a natural anguage generation point of view.This paper discusses a system that accepts a planstructure of the sort generated by AI planning programsand produces natural language text explaining how toexecute the plan.
Our objective in building this systemhas been to develop a clear model of a possible archi-tecture for a language generation system that makes useof simple, well-understood, and restricted computa-tional techniques.
We feel that too much of the work inthis area has been characterized by the use of arbitraryprocedures, which often do not provide a clear basis forfuture work.
We believe that by providing a simple yetnontrivial account of language generation, we can con-tribute at least by providing a "straw man" with knownlimitations, with respect to which other work can becompared.Describing plans represents in many ways an obviousCopyright 1989 by the Association for Computational Linguistics.
Permission tocopy without fee all or part of this material isgranted providedthat the copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page.
Tocopy otherwise, or to republish, requires afee and/or specific permission.0362-613 X/89/010233-249-$03.
O0233 Computational Linguistics Volume 15, Number 4, December 1989Chris Mellish and Roger Evans Natural Language Generation from PlansFigure I Action Graph of a Nonlinear Plan.application of natural language generation, and ourapproach has been to tackle this problem in a fairlystraightforward way, informed by the state of the art aswe perceive it.
The results from our system are prom-ising, but our texts lack much of the smoothness ofhuman-generated explanations.
An analysis of the rea-sons behind some of the system's failures points to anumber of deep problems concerning the connectionbetween AI plans and natural language xplanations.In the next section we briefly introduce the inputsand structure of the language generation system.
Wethen run through the parts of the system by showing aworked example.
The core of this paper concerns themapping from plans to messages, which can be thoughtof as abstract descriptions of natural language dis-courses.
We describe our repertoire of messages, howplan structures are mapped onto messages, and howmessages are simplified.
Finally we look at furtherexamples of the system's output and analyze some of itsfailures and successes.2 SYSTEM OVERVIEW2.1 PLANS AND PLANNERSFor this project, we have adopted a traditional AI viewof planning and plans.
According to this view, the taskof planning to achieve a goal is that of finding a set of(instantaneous) actions which, when performed, willtransform the world as it is (the "initial state") to a newworld (the "final state"), which is similar to the presentworld, but where in addition the goal is true.We assume that the plans produced by our plannerare nonlinear (almost standard with AI planners inceNOAH; Sacerdoti 1975); that is, they only partiallyspecify the order in which the actions are to be per-formed.
Furthermore we assume that the time con-straints involved in a plan can be displayed in an actiongraph, where an action is represented by a point and aline going rightward from one action to another indi-cates that the first action must take place before thesecond (this is true of most, but not all, AI plans--seefor instance Tsang 1986).
Figure 1 shows an actiongraph for a nonlinear plan for building a house.We further assume that plans are in general hierar-chical.
By this we mean that the planner operates in ahierarchical manner (almost standard in AI plannerssince ABSTRIPS; Sacerdoti 1973), first producing aplan :specified at a very abstract level, and then succes-sively refining it until the required level of detail isobtained.
At each stage a process of criticism mayimpose new orderings between actions whose relativeordering seemed to be unconstrained at the previouslevels of abstraction.
For us, the history of this hierar-chical expansion must be present in the final plan, sincewe assume no explicit interaction with the planner itselfwhile it is operating.
(We shall return in Section 5 to thequestion of whether the hierarchical plan structure is infact a sufficient description of the planner's processing.
)For concreteness, we have based our system on theoutput of a single AI planning program, even thoughthere are a number of planning systems that couldproduce a similar style of output.
The input to ournatural language generator, then, is the translation i toProlog of the set of datastructures created by Tate's(1976) NONLIN planner.
:2.2 SYSTEM STRUCTURE AND PARAMETRIZATIONWe have set ourselves the goal of generating from aNONLIN plan a single natural anguage text that ex-plains the actions to be performed and why things haveto be done this way.
To a large extent he explanatorypower of such an account depends on what informationis represented in the plan in the first place.
Although asystem that produces a single monolog from a plan ismore restricted than, say, an interactive system that canbe a,;ked to explain parts of the plan selectively, anumber of possible applications do suggest themselves(for instance, the automatic generation of instructionmanuals), and the monolog task does provide us with anexcellent way of studying the problems of automaticallygenerating large texts.We have attempted tofactor out domain-dependenceas much as possible in the generation system by havingit rely heavily on knowledge xpressed in a declarativefashion.
Given a particular target natural anguage, aspecific lexicon then needs to be provided for thedomain in which the plans are to be generated (we haveconsidered cookery, house building, car maintenance,234 Computational Linguistics Volume 15, Number 4, December 1989Chris Mellish and Roger Evans Natural Language Generation from Planscentral heating installation, and the "blocks world").This provides linguistic representations correspondingto the objects, states, and actions that will arise ingenerated plans.
These lexical representations are sup-plemented by domain-dependent rewrite rules that canbe used to reveal hidden additional structure in theplanner's representation f the domain.
Even with thetarget natural anguage fixed and a particular domaingiven, there are still in general many possible plans fromwhich natural anguage could potentially be generated(indeed, many man-years of AI research were devotedto developing plans simply in the "blocks world").Our natural language generation system can bethought of as consisting of four processing stages,centering on the construction and manipulation of anexpression of our special message language, as follows:Message PlanningMessage SimplificationCompositional Structure BuildingLinearization and OutputMessage Planning is the interface between the genera-tor and the outside world.
At this stage, the generatormust decide "what to say," i.e., which objects andrelationships in the world are to be expressed in lan-guage and in roughly what order.
The output of themessage planner is an expression in the message lan-guage which, following McDonald, we will call themessage.
The idea is that message planning may be arelatively simple process and that the resulting messageis then "cleaned up" and simplified by localized rewriteoperations on the expression ("Message Simplifica-tion").The message is a nonlinguistic object, and the task ofstructure building is to build a first description (afunctional description much as in Functional Grammar;Kay 1979) of a linguistic object that will realize theintended message.
We assume here that a "linguistical-ly motivated" intermediate r presentation f the text isof value (this is argued for, for instance, by McDonald1983).
Our structure builder is purely compositional,and so the amount of information that it can take intoaccount is limited.
We treat structure-building as arecursive descent traversal of the message, using rulesabout how to build linguistic structures that correspondto local patterns in the message.
During this, a simplegrammatical constraint satisfaction system is used, toenforce grammaticality and propagate the consequencesof syntactic decisions.
The recursive descent terminateswhen it reaches elements of the message for which thereare entries in the system's lexicon.Once a structural description of a text has beenproduced, it is necessary to produce a linear sequenceof words.
Our structural descriptions contain only dom-inance information and no ordering information, and soa separate set of rules is used to produce a linearization.This is akin to the ID/LP distinction used in GPSG(Gazdar et al 1985).The resulting system is similar to McDonald's (1983)model, in that it is basically a direct production systemthat utilizes an intermediate syntactic representation.The system is also similar to McDonald's in its empha-sis on local processing, although there is no attempt toproduce a psychological model in our work.
Our con-straint satisfaction system is implemented fficiently byunification, however, so that the effects of local deci-sions can propagate globally without he need for ex-plicit global variables.
This is used, for instance, toenforce a simple model of pronominalization (based onthat of Dale 1986).3 A WORKED EXAMPLEAS an illustration of the various mechanisms containedwithin the system, we present in this section an exampleof the system in operation.
The example is taken from ademonstration application, showing how the languagegenerator might be attached to an expert system.
Thescenario is as follows: we have an expert system whosefunction is to diagnose car-starting faults.
The expertsystem asks questions to which the user can either givean answer or type "how," meaning "how can I find outthe answer?"
In this latter case, the expert systeminvokes a planner to work out what the user has to do,and passes the resultant plan to the language generator,which produces text giving instructions to the user.
Theexpert system then asks its original question again.In our demonstration system, the expert system is infact just a binary decision tree.
At each internal nodethere is a yes-no question and a planner goal, to be usedif the user responds with "how."
At each leaf nodethere is a recommendation a d a planner goal--here"how" is interpreted as "how do I carry out yourrecommendation?"
To make the demonstration morevaried, the system keeps track of what it has alreadytold the user to do, so that, for example, accessing thecarburetor jet will be described ifferently depending onwhether the air filter (which is on top of the carburetor)has already been checked.We pick up the example at a point where it has beenascertained that the battery is OK, but that there is nospark on the spark plugs.
The next step is to test for aspark at the distributor.
The system asks:Is there  a spark  at the  d i s t r ibutor?and we respond with "how."
The NONLIN plan goalassociated with the above question is{tested dist_spark}that is, "make a plan to achieve the state in which wehave tested the distributor spark."
The planner assumesthat we have done nothing already and are standing atthe front of the car, looking at the engine.3.1 THE PLANThe plan produced by NONLIN for this example case isa totally ordered sequence of six actions as follows:Computational Linguistics Volume 15, Number 4, December 1989 235Chris Mellish and Roger Evans Natural Language Generation from Plans{act {detached dirt_cover engine}}{act {detached coil_lead dist_cap}}{act {located mech cab}}{act {started engine}}{act {located mech frontofcar}}{act {observed spark colLlead}}detach the dirt cover from the enginedetach the coil lead from the distributorcapgo to the cabstart the enginego to the front of the carobserve whether there is a spark on thecoil leadHowever, although this is the plan at its lowest level,the plan structure returned by NONLIN also includesthe hierarchical expansion history of the plan.
The planstarted out as just the original goal itself, and wassuccessively expanded to greater levels of detail untilthe primitive actions given above were obtained.
Theexpansion hierarchy for this plan is shown in Figure 2.
2As well as this hierarchical structure (and the order-ing information ot shown in this diagram), NONLINreturns information about preconditions in the plan--where they are needed and where they are established.So, for example, the condition {goal {located mech cab}}is required by node 14 and made true by node 13 (andmade false again by node 15).3.2 THE TEXTAll this information is extracted from NONLIN's datastructures, converted into Prolog clauses, and passed tothe language generator.
The generator looks for ways tobreak up and organize the information in the plan toproduce comprehensible t xt.
This process is describedin more detail in Section 4, but to see what it does in thiscase, we shall concentrate on just one fragment of theabove plan, namely nodes 3, 5, 6, 7, and 8.
These nodesrepresent he expansion of the following NONLINoperator:actsclhema tested_4pattern {act {tested ist_spark}}expansiongoalgoalgoalgoalorderings1 -*2--,{goal {detached coiklead dist_cap}}{goal {started engine}}{goal {located mech frontofcar}}{goal {observed spark coil_lead}}443 -*4conditionsunsupervised {goal {accessible dist}} at selfsupervised {goal {detached coil_leaddist_cap}} at 4 from 1supervised {goal {located mech frontofcar}}at 4 from 3supervised {goal {started engine}} at 4 from2er.Ld;This operator expands the high level action "do some-thing that causes the distributor spark to have beentested" (that is, "test the distributor spark") into foursubgoals (not actions, since if they are already in effect,nothing further needs to be done), the first three ofwhich must preceed the last.
Thus the plan here is toensure that the coil lead is detached from the distributorcap, the engine is started, and the mechanic is at thefront of the car, and then to observe whether there is aspark on the coil lead.Tile subplan gives rise to the following piece of text:TEST ING THE D ISTR IBUTOR SPARKTesting the distributor spark involves detaching the coillead from the distributor cap, starting the engine, going??
?Figure 2 Expansion Hierarchy.1: (goal ( tested ist._spark) }2: {goal {accessible dist} }3: {act {tested istspark) }4: {act {accessible dist} }5: {goal {detached coil_lead dist_cap}6: { goal { started engine } }7: \[goal {located mech frontofcar}8: {goal {observed spark coil_lead} }9: {goal {detached irt_cover engine) }1 O: { goal {located mech cab } }lh  {act {detached irt_cover engine}12: {act \[detached coil_lead dist_eap}13: { act {located mech cab } }14: {act {started engine}15: (act {located mech frontofcar}16: {act {observed spark coil_lead} }236 Computational Linguistics Volume 15, Number 4, December 1989Chris Mellish and Roger Evans Natural Language Generation from Plansto the front of the car and then observing whether thecoil lead sparks.I f  you go to the front of the car now you will not beat the wheel afterwards.
However in order to start theengine you must be at it.
Therefore before going to thefront of the car you must start the engine.I f  you start the engine now you will not be at the frontof the car afterwards.
However in order to detach thecoil lead from the distributor cap you must be at thefront of the car.
Therefore before starting it you mustdetach the coil lead from the distributor cap.Detach the coil lead from the distributor cap.
Afterthis start the engine.
After this go to the front of the car.After this observe whether the coil lead sparks.You have now finished testing the distributor spark.Notice that this text is not just a description of theactions as specified by the plan operator.
Nor is it thefully detailed plan of everything to be done.
It is adescription of the plan operator in the context of thecurrent plan, embellished with additional useful infor-mation from that context.
It includes references toactions at several different levels of abstraction, as wellas information about ordering constraints present in theplan but not present in the basic plan operator.3.3 THE MESSAGEThe first step in the generation of this text is to convertthe plan data into an expression in the generator'sintermediate message language.
The message languageand the strategies for carrying out this conversion arediscussed more fully in Section 4; here we concentrateon those aspects particularly relevant to this text.The overall strategy applied to our subplan is toconstruct an embedding: an introduction-body-conclu-sion structure in which the introduction explains howthe action is expanded, the body explains how toexecute the expansion, and the conclusion makes thepoint that by executing the expansion, the higher levelaction is acheived.
This strategy is appropriate becausethe body of the expansion is relatively simple.
For morecomplex examples, where it is not practical to attemptto describe the expansion merely as an introductorysentence of a paragraph, an alternative strategy wouldbe employed.This strategy decision gives us the general shape ofthe text, and the components of the embedding arestraightforwardly constructed, by reference to the local"shape" of the plan fragment.
Here the actions arelinearly ordered, which suggests presenting them in theorder of execution.
At the same time the message isembellished with the justifications for the action order-ing.
In the above plan operator, the first three actionswere unordered, but lower level considerations (con-cerning where the mechanic is at a given time) imposean ordering on them in the actual plan returned.
Mes-sage elements are added to explain these orderingrequirements, and in this case these necessarily appealto the lower level actions of moving about.The resulting message xpression is too large foreasy display, so we shall concentrate on a small part ofit, the part corresponding to the three sentences:I f  you go to the front of the car now you will not beat the cab afterwards.
However in order to start theengine you must be at it.
Therefore before going to thefront of the ear you must start the engine.The initial message xpression for this text is:implies (contra_seq (hypo_result (user,achieve (goal (located (mech, front ofcar))),not (goal (located (mech, cab)))),prereqs (user,then (wait (\[ \]), achieve (goal (started(engine)))),goal (located (mech, cab)))),neccbefore ( user,then (walt (\[ \]), achieve (goal (started(engine)))),achieve (goal (located (mech, frontofcar)))))where expressions like goal(located(mech,frontofcar))and goal(started(engine)) are straight NONLIN ex-pressions, translated literally into Prolog.
This expres-sion can be read approximately as "the hypotheticalresult of going to the front of the car is that you will notbe in the cab, and this contrasts with the prerequisite ofbeing in the cab to start the engine.
This combinationimplies you should start the engine before you go to thefront of the car."
And of course, that is more or lesswhat the produced text says.3.4 SIMPLIFYING THE MESSAGEThe above message contains a number of redundancies,which will lead to inelegant text if it is used for gener-ation.
First of all, it contains various occurrences ofwait(\[ \]) (the action of waiting for nothing).
These areinserted because in general at certain points of thesubplan being explained, one is forced to wait for theconclusion of actions being performed in other sub-plans; this time, however, there are no such criticalactions in other parts of the plan.
Second, the NONLINexpressions have been inserted verbatim, without anyconsideration f whether they could be expressed moreelegantly in the message language.
Message simplifica-tion concerns rewriting the message xpression gener-ated by message planning into one that is "simpler" insome sense.
This is achieved by applying rewrite rulesto components of the whole message.
Two kinds ofrewrite rules are used: the first kind perform domain-independent s ructural simplifications to message x-pressions, and the second domain- or language-depen-dent alterations.
For example, the following two rulestogether dispose of the redundant wait(\[ \]) terms of theabove message (\[ \] denotes the empty action here):wai t ( \ [  \]) --~ \[ \].then(\[ ]~X) --* X.Computational Linguistics Volume 15, Number 4, December 1989 237Chris Mellish and Roger Evans Natural Language Generation from PlansThese are to be read as rewrite rules, with the expres-sions on the left of the "---~" being rewritten to theexpressions on the right.
Variables are denoted bynames beginning with capital letters.
The operation ofthese rules is entirely domain-independent.
One of thedomain-dependent rules rewrites mech (the mechanic)as user,  to indicate that the mechanic is the same as theperson to whom the instructions are being given.
An-other set of rules rewrites states into a form where theaffected person or object is explicit (this representationallows the system to collapse together multiple statesinvolving the same person):goal (located (X,Y)) --~ state (X, located (Y)).More substantial examples include the following rulesfor talking about moving around:achieve (state (user, located (Y))) --* go_to (user,Y).result (go_to (X,Y),state (user, located (Y))) --~do (go_to (X,Y)).The first causes a phrase such as "get to be at the frontof the car"  to be rewritten as "go to the front of thecar."
The second removes redundancy in a sentencelike "Go  to the front of the car and you will be at thefront of the car ,"  rewriting it as simply "Go to the frontof the car .
"Once all the rewrite rules have been applied, oursimplified example message looks like this:implies (contra_seq (hypo_result (user,go_to (user, function (front, car)),state (user, not (located (cab)))),prereqs (user,start (engine),state (user, located (cab)))),neccbefore (user,start (engine),go_to (user, function (front, car))))3.5 COMPOSITIONAL STRUCTURE BUILDINGThe next stage is to build a linguistic structure from thismessage xpression.
The structure-building componentuses an ordered set of rules for mapping from localmessage patterns to linguistic structures.
It is similar tothe system described in Chester (1976) in the localnature of its operation, but Chester builds sentencesdirectly, rather than via structural representations.Mann et al (1982) would call our system a "directtranslation" system.
A system built in this fashion hasthe advantage of a very simple control structure and hasthe potential of having its principles expressed in mod-ular, independent rules.Our linguistic structural descriptions are similar tothe functional descriptions used in Functional Grammar(Kay 1979; Kay 1984).
For example, the following is aslightly simplified version of the rule used to realize thehypo_result construct above:hp!oo.result (Agent, Act, State) --*\[ ss~nesentence,conjn = \[root = 'if\],first =Is,agent = \[ SAgent\],pred = \[active,morph = pree,SAct,adv = + \[ap, adv_word=\[root=now\]\]\]\],rest =Is,pred =\[vp,aux = \[root = will\],pred =\[vp,$State,morph = inf,adv = + \[ap,adv_word= \[ root = afterwards \] \] \] \] \] \].In this rule, the left hand side of the ---> is a Prologpattern to be matched with part of the message (symbolsbeginning with uppercase letters represent variables,which are to match subexpressions of the message).
Therightlaand side is a functional description, describing theEnglish phrase that is to render that part.
In thesefunctional descriptions, expressions preceded by dollarsigns represent he places where further informationwill be contributed by the expansion of subparts of themessage.
Thus the "agent"  value is obtained by recur-sively matching the value of the variable Agent  (that is,the first argument in the hypo__vesu.lt term) against hestructure rules.This rule is responsible for sentences like:I f  you start the engine now you will not be at the frontof  the car afterwards.The rule provides the basic template for the sentence: itis a combination of two sentences using the conjunction" i f . "
The first sentence is present tense active, withagent specified by the Agent  argument and predicate bythe Act argument, and has an adverbial modifer "now.
"The second sentence is a future tense expression of theState given as argument, with adverbial modifier "af-terwards."
The presence of samesentencer  ensuresthat the whole is a single sentence and that the twosubclauses have the same focus.Tile recursive structure building process "bottomsout" when a message lement is reached for which alinguistic realization appears in the domain-dependentlexicon.
Domain states and properties (Section 4.1) areprovided with lexical entries that describe how torealize them as VPs.
Such entries could be written asstructure building rules in the same format as the above1-~,po_result rule, but in practice it is convenient to usea more compact notation:lx (accessible, be, \[attr: @ accessible\]).lx (answer, answer, \[obj: @ 'the question'\]).lx (start (Z), start, \[obJ: Z\]).238 Comput~ltional Linguistics Volume 15, Number 4, December 1989Chris Mellish and Roger Evans Natural Language Generation from PlansThese entries indicate how each of accessible (a prop-erty), answer, and start(Z) (actions) can be realized inEnglish, by providing a verb and a specification for thecomplements o follow it.
In the first two, the comple-ment phrases are specified irectly as constant strings(indicated by the '@' sign).
In the last one, the filler ofthe obj role (the direct object) will be whatever phraseis used to realize the object Z being started.
Additionalrules provide possible fixed phrases to realize suchdomain objects:re ferent  (eng ine ,  @eng ine) .When a domain object like engine comes to be realized,either the fixed phrase provided (prefixed by 'the') willbe used, or a pronoun with the appropriate gender andnumber will be chosen.
It is clearly a limitation of oursystem that no other possibilities are currently allowed,but in some sense this reflects the fact that plans comewith a great deal of information about he actions to beperformed but very little information about the objectsinvolved in them.Structure building rules are ordered, so rules formore specific patterns can be placed before rules forless specific ones, without he latter having to explicitlyprovide negative conditions.
In addition, rule applica-tion is deterministic, in that, once the left hand side of arule has matched a piece of message and the right handside structure (minus the parts that require recursiverule matching) has been successfully built, no other ulewill ever be tried for that portion of the message.As well as the usual specifications of features andvalues (for example, conjn and first used above),functional descriptions can also contain specificationsof properties, such as s and samesentenee, that therelevant construction must have.
Some of these prop-erties (such as s) are intrinsic--essentially just featureswithout values.
Others are "macros" for bundles ofsimpler feature-value and property specifications.
Forexample, saraesentence is defined as being shorthandfor a bundle of feature-value pairs that limit the possi-bilities for focus movement in and around the structuredescribed.
A collection of such macros enables us toimplement what is essentially Dale's (1986) model ofhow discourse structure constrains pronominalization,which was inspired by the work of Grosz (1977) andSidner (1979).
The use of a macro like ssanesentence(keyed off particular structures in the message) sets upan environment that will allow certain pronominaliza-tions but exclude others.
The choice of whether topronominalize or not is then made on a local basis.
It isinteresting to compare this scheme to that of McKeown(1982), which also makes focus decisions on a localbasis.
McKeown's approach, almost the opposite toours, is to take certain focus priorities as primary andthen to attempt o select material in accordance withthese.
Our approach, which involves considering focusonly after the material has already been organized,regards pronominalization more as a last-minute l xicalComputational Linguistics Volume 15, Number 4, December 1989optimization than as something that is planned in ad-vance.
We have considered incorporating some meansof focus annotation i the message, but it is not alwaysclear at this level what the focus should be.
We havethus preferred to allow message planning simply toplace general constraints on focus movement.As the message is traversed by the structure buildingrules, more and more information accumulates aboutthe output functional description and its components.As is usual in unification grammar, in the written formstructural descriptions are sideways open, that is, anobject satisfying the description is required to have thefeatures listed, but may have any other features inaddition.
Thus our structure building rules only providethe framework of the final functional description.
Therest is filled in by a simple grammatical constraintsatisfaction system.
This enforces grammaticality andhandles the propagation of feature values that areshared between different phrases (for instance, numberagreement).
The constraint satisfaction system is basedon the use of a declarative "grammar specification" ofthe types of legal descriptions and the constraints theymust satisfy.
This specification is compiled into a rep-resentation that essentially treats every property andfeature as a macro for a bundle of conclusions thatfollow from its being involved in a description.3.6 CONSTITUENT ORDERINGThe final task once the linguistic structure has been builtis to determine the order in which the constituents are tobe produced, and to locate the actual words to be used.Substructure ordering is determined by ordering rules.The ordering rules are applied to a structural descriptionin much the same way that structure-building rules areapplied to the message; that is, recursively and compo-sitionally.
The left hand side of an ordering rule is apattern that is matched against he structural descrip-tion.
The right hand side of the first rule whose patternmatches is then taken as a template determining whichparts of the description are to be realized as phrases andin what order.
For example, here is a rule for VPordering:\[vp, ma inverb  = V, adv = A, eompls  = C\] --* \ [V,C~\] .This rule ensures that a verb is realized before itscomplements, which are realized before any adverbialmodifiers, producing VPs like:go to the front of the car nowEach application of an ordering rule returns an orderedlist of functional descriptions.
These are then recur-sively subjected to ordering rules, to determine theirrelevant subphrases and the order these should berealized in.
The recursion "bottoms out" when a func-tional description of type word is reached.
The endresult is a list of word descriptions each containingfeatures detailing aspects of the morphology.
These arepassed to the morphology component (currently ex-239Chris Mellish and Roger Evans Natural Language Generation from Planspressed as raw Prolog code), which will then output heappropriately inflected word.4 PLANS AND MESSAGES4.1 THE MESSAGE LANGUAGEIn some ways, a natural anguage generation system islike an optimizing compiler.
Producing some sort ofnatural anguage from a symbolic input is not a task ofgreat difficulty, but producing text that is smooth andreadable is a challenge (and in general quite beyond thestate of the art).
With both tasks one has the option ofplanning the text and simplifying its form either in asingle pass or in multiple passes.
In language genera-tion, McDonald's MUMBLE (McDonald 1983) pro-duces and simplifies linguistic structures within a singlepass of the input.
Although the modeling of humanlanguage production may require a theory of this kind inthe end, the result is a system where it can be hard toseparate out the different principles of structure build-ing and simplification, because these have all beenconflated for reasons of efficiency.
We have thus optedfor a multi-pass ystem.
Multi-pass optimizing compil-ers need to have specialized internal anguages (virtualmachine codes) more abstract han the output machinecodes and in terms of which optimizations can bestated.
The analog in a natural language generationsystem would be a message language that could ex-press at a level more abstract han linguistic structurethe goals and intended content of a piece of language tobe generated.
We can see elements of such a language inthe "realization specifications" of McDonald and Con-klin (1982) and in the "protosentences" of Mann andMoore (1981).
A crucial part of our own system is theuse of a message language specialized for the explana-tion of plans.Our message language is a language specifically de-vised for expressing the objects that arise in plans andthe kinds of things one might wish to say about them.The main types of statements ("utterances") that canbe made at present as part of our generated text areshown in Figure 3.
These "utterances" mention actionsand states, which could be domain actions and states (asappearing in the plan) or complex actions and states,formed according to the rules in Figure 4.
The messagelanguage provides for the description of actions beingcarried out involving different agents and objects (bothrepresented as "ob jects" - -F igure 5), although NON-L IN provides no indication about who is responsible forany given part of a plan.
Thus the agent of an actiondefaults to usor  for an action that is properly part of thecurrent subplan and someone for an action that hasbeen included in the description but is properly part ofanother subplan.
In this way, each part of the plan isexplained from the point of view of the person executingit, with no assumption that the same person will beexecuting other parts of the plan.
A message consists ofa number of "utterances" linked together by various240UTTERANCE ::=:neccbefore(OB JECT,ACTION,ACTION)--- one action must take place before anotherdo(ACTION)..... instruction to perform an action:result(ACTION,STATE).... as 'do', but also mentioning an effect of the action:hypo_result(OB JECT,ACTION,STATE)--- if the agent carried out the action, the state would holdexpansion(ACTION,ACTION)--- describing the expansion of an action into subactionsprer eqs(OB JECT,ACTION,STATE)--- describing the prerequisites of an action, with the--- assumption that a given agent wil l  perform itneeded(OBJECT,ACTION,STATE)--- describing the reason why a STATE is needed, so that--- OBJECT can perform ACTIONcauses(STATE,STATE)--- once the first state holds, so does the secondnow(STATE)--- indicating that some state now holdsFigure 3 Types of Basic Utterance.organizational devices.
These indicate various kinds ofsequencing and embedding (Figure 6).
Most are simplyways to string together two "utterances,"  with anappropriate conjunction being suggested, according towhat kind of link there is between the two.
The embedconstruction is used to indicate a discourse segmentwhich has an introductory section, a body and a con-cluding section.
Hence it has three parts.
The idea isthat the explicit marking of such structures in themessage language will enable linguistic decisions (forinstance concerning pronominalization) to be mademore intelligently.
In general, the domain-dependentlexicon need only supply a single linguistic representa-tion for the simplest form of a domain action or prop-erty.
The linguistic forms of the more complex formsallowed by the message language are then dealt withautomatically by the system (Figure 7).4.2 FROM PLAN TO MESSAGEA plan with 30 or so actions contains a great deal ofmaterial, spelling out the necessary partial orderingbetween the actions and their preconditions and effects.A crucial task in message planning is cutting thismaterial down into small enough pieces that can berendered as independent pieces of text.
In a domain-independent system for plan explanation, the onlystructure that such a "chunking" can make use of is theabstraction hierarchy and the local "shape"  of theaction graph.
Even this is unfortunately limited by thefact that the abstraction hierarchy may represent a viewof the domain that is convenient to the plan generator,but not the plan executer.The abstraction hierarchy tells us how certain actionsComputational Linguistics Volume 15, Number 4, December 1989Chris Mellish and Roger Evans Natural Language Generation from PlansACTION ::=then(ACTION,ACTION)--- two actions in sequenceachieve(STATE)--- the action to achieve a statewait(STATE)--- waiting until a state holdscomplete(ACTION)--- finishing doing a prolonged actionrepeat(ACTION,STATE)--- doing the action until the state holdsdelegate(OBJECT,ACTION)--- have someone else do an actionparallel(ACTION,ACTION)- -  doing two actions in parallelDOMAIN_ACTIONSTATE ::=and(STATE, STATE)--- both states holdstate(OBJECT,PROPERTY).-- an agent has a propertynot(state(OBJECT, PROPERTY))--- an agent does not have a propertyPROPERTY ::=andp(PROPERTY, PROPERTY)--- conjunction of propertiesenabled(ACTION)--- able to perform an actiondone(ACTION)--- having done an actiondoing(ACTION)--- doing an actionDOMAIN_PROPERTYFigure 4 Actions, States, and Properties.at a particular level of the plan arise from the expansionof a single action at a more abstract level.
Such a groupof actions is an obvious candidate for explaining as asingle chunk.
Thus our basic strategy is to first of all talkabout the plan at the most abstract level, then discussthe expansion of the actions at that level, then discussthe expansion of the actions involved in that, and so on.In general, then, at any time we are concerned with1) selecting out the portion of the plan that correspondsto the expansion of a single abstract action andOBJECT ::=USersomeonefunction(FWORD,OB JECT)DOMAIN_OBJECTFigure 5 Objects.MESSAGE :~---title(ACTION.MESSAGE)--- labels a piece of text with a title (based on an action)embed(MESSAGE,MESSAGE,MESSAGE)--- inn, oduction-body-conclusion typestructureneutral_seq(MES SAGE,MESSAGE)--- two bits produced insequence, but with no implied relationshiptime_then(MES S AGEoMES S AGE)--- two bits produced insequence, this indicating time orderlinked(MESSAGE, MESSAGE)--- two bits prodtw.ed insequence, with some unspecified relafinshiptime_parallel(MES SAGE,MES S AGE)--- two bits produced insequence, indicating parallelism in timecontra_seq(MESSAGE.MESSAGE)--- two bits produced insequence, where the second conCadicts an--- expectation created by the firstimplies(MESSAGE,MESSAGE)--- one dplan statement is u'ue and hence so is anotherUTTERANCEFigure 6 Linking Devices for Utterances.2) describing this, given that whole subsets of theactions in it are to be treated as single actions.The first of these is not trivial because, as the result ofsuccessive criticisms, the set of actions in the expansionof a more abstract action may no longer be a simpleconnected piece of the plan.
As an example of this,Figure 8 is the action graph for a house-building plan,with the actions that are in the expansion of "installingthe services" blocked out.To describe this set of actions and their timing in theplan, it is necessary to describe other actions whosetiming is closely coupled to them.
The actions to beincluded in the explanation of the expansion are ob-tained by a "c losure"  operat ion--a process of tracingthrough all possible paths going forward in time be-tween actions in the expansion.
Any other actionsencountered on these paths are deemed necessary to beincluded in the description.
We call these actions "in-truders."
Thus the actions described form the minimalconvex graph that includes the desired actions (Figure9).Once the lowest-level plan actions corresponding to asingle abstract action have been isolated, the "shape"of this part of the plan at the current level of abstractionneeds to be determined.
The current point in the ab-straction hierarchy specifies the set of actions that canbe mentioned in this part of the text.
I f  one of these is anabstract action, in general there will be a whole class oflowest-level actions that need to be described simply asparts of this action, whose internal structure will bedescribed later.
The lowest-level actions are thusgrouped into subsets, and what is to be explained arerelationships between these subsets, rather than rela-tionships between primitive actions.
Technically, the"chunking" imposed by the current layer of the ab-straction hierarchy defines an equivalence relation, andComputational Linguistics Volume 15, Number 4, December 1989 241Chris Meilish and Roger Evans Natural Language Generation from Plansdo( examineOftter_bolts ) ).do(complete(examine(filter_bolts))).do( de legate (someone , xamineOflter botts) ) ).now( state( user ,enabled( examine(lifter_bolts ) ) ) ).now(state(someone ~lone( examineOilter_ bolts) ) ).now(state( user ~toing ( examine(filter_ bolts) ) ).now(state(plug_leads ~ositioned) ).do(achieve(state(plug_leads,posit ioned) ) ).do(wait(state(plug eads,positioned) ) ).causes(state( user ,done(achieve(state(plug leads,posit oned) ) ) ),state( user, enabled( examine(fdter_ boits) ) ).Examine the filter bolts.Finish examining the Nter  bolts.Have someone examine the Nter bolts.You can now examine the filter bolts.The filter bolts have now been examined.You are now examining the filter bolts.The plug leads are now in position.Get the plug leads to be in position.Wait until the plug leads are in position.Once the plug leads are in position you canexamine the filter bolts.Figure 7 Expressions Generated Using Two Lexical Entries.we are interested in the quotient plan with respect othis relation.
We can define the usual plan relationshipsbetween the relevant subsets of actions in a naturalway.
For instance, we say that one subset comes beforeanother if and only if each element of the first comesbefore each element of the second.
Because such ademanding criterion will apply quite rarely, in generalthere will be a great deal of parallelism in subplanswhose actions are not at the most detailed level.Once a piece of the whole plan has been extractedand its "shape" (relative to some given equivalencerelation) established, rhetorical strategies are applied todecide how particular parts are to be presented.
Themessage created epends directly on the structure of thejustified plan.
Thus, for instance, the expansion of acomplex action gives rise to a section of text repre-sented by a message of the form:title ( Action,embed ( Intro,Body,now (state (user, done (complete(Act ion) ) ) ) ) ) )where Action is the action described, Intro is anintroductory message, which describes the prerequi-sites of the main action and the set of actions in itsexpansion (unless there are too many of them) and Bodydescribes the action graph expanding the main action.The main strategies for describing action graphs are thelump strategy, forwards description, and backwardsdescription (Figure 10).
The lump strategy applies if apiece of the action graph is a self-contained "lump"Figure 8 Distribution of Expression of an Abstract Action.between two actions A and B, with no links betweenany actions inside the "lump" and any actions outside.If the subgraph between the actions is sufficientlycomplex (has more structure than two simple actions inparallel), the strategy suggests that its explanationshould be postponed to a separate "section."
Mean-while the whole subgraph is incorporated into thecurrent explanation as if it were a simple action (this is,of course, the same strategy that is applied for an actionthat is above the primitive level in the abstractionhierarchy).
Forward description is deemed appropriatewhen the action graph is a right-branching structure; inthis case the actions are generally dealt with in timeorder, giving a message of one of the forms:time_then (result (Act, State) .
.
.
.
)neutra\]_seq (result (Act, State),embed (causes (State,state (user, enabled (Acts))),.... \[\])where Act is the first action, State a state that it makestrue, and " .
.
. "
is the message derived from thesubsequent actions.
When the action graph is a leftbranching structure, however, the strategy of back-wards description is suggested.
This gives rise to mes-sages of the form:embed (prereqs(user~ct,Pres) ,now (state(user,enabled (~9?
??
?Figure 9 Closure of Expansion.?
?242 Computational Linguistics Volume 15, Number 4, December 1989Chris MeUish and Roger Evans Natural Language Generation from PlansLump:~ 0  gQO IForwards:Backwards: ~ m  I QQWhen you have done Ayou can do B and C?8 Q?.
Before you can do Ayou must do B and CFigure 10 Rhetorical Strategies.parallel (Act,achieve (State)))))where Act is the first action, with preconditions Presand effects State, and " .
.
. "
is the message derivedfrom the subsequent actions.All of these kinds of messages require the insertion ofpreconditions and effects of actions.
It is necessary forthe system to compute those preconditions and effectsthat are actually relevent for the current plan, ratherthan simply the total sets of preconditions and effects.This amounts to determining the justifications for theaction ordering chosen.
The justification for action Acoming before action B can be of one of two types.Either A is needed to create a state where a precondi-tion of B is true, or A comes before B because otherwiseB would create a state where a precondition of A wasnot true.
The two different possibilities give rise todifferent modes of presentation, but if the justification isredundant or not available from the plan, it is simplymissed out.4.3 IMPROVING THE MESSAGEAs the last section suggests, the initial version of themessage is put together in a very direct way from thestructure of the plan.
As a result, it is often unneces-sarily cumbersome.
Message simplification concernsrewriting the message xpression generated by messageplanning into one that is "simpler" in some sense.
Sincethe amount of material we wish to deal with could belarge, we have avoided considering expensive globalsimplification techniques in favor of emphasizing localsimplification techniques analogous to "peephole" op-timizing techniques in compiling.
Of course, a crucialdifference between language generation and compila-tion is that in the former there is no clear notion of what"optimality" is.
In the absence of a formal and detailedpsychological theory of discourse comprehension, re-searchers in natural anguage generation are reducedmore or less to using their intuitions about whether oneway of phrasing something is "easier to understand"than another.
We have regretfully had to follow thesame course in designing and evaluating our own sys-tem.The domain-independent simplification rules used byour message simplification system are treated equally,but conceptually they seem to be of four main types.Members of the first type tidy up special cases thatcould as easily be detected when the expression isconstructed.
Here is an example of such a rule (\[ \]denotes the empty utterance):(1) neutral_seq (X,\[ \]) --* X.Thus any utterance xpression of type neutral_seq willbe rewritten by this rule if its second component isempty.
Such an expression is rewritten simply to its firstcomponent.
Incorporating such rules into the simplifi-cation stage means that the message-planning compo-nent can be simpler and more perspicuous.The second kind of rule expresses knowledge aboutplanning and plan execution.
Here are two such rules:(2) achieve (state (user, done (Act))) --* Act.
(3) parallel (X, wait (Y)) --* then (X, walt (Y)).Rule (2) expresses the fact that the only way to create astate where you have done an action is to do the action.Rule (3) expresses the fact that waiting is an action thatis always postponed until there is nothing else to do.Both of these principles are useful in finding the bestway to express a given action.A third kind of rule really reflects the linguisticcoverage of the system in an indirect manner.
If there isa special way available for saying a particular kind ofthing, then that should be preferred to using a moregeneral technique.
Here is such a rule:(4) prereqs (user, X, state (user, done (Y))) --*neccbefore (user, Y, X).This rule is about a special case of the prereqs tructurearising in the message.
When one is calling attention tothe prerequisite(s) of an action X, a special case ariseswhen the only prerequisite is the achievement of an-other action Y.
In this case, the prerequisites statementamounts to saying simply that Y must happen before X.In general, one would expect hat expressing the state-ment in this second way would result in a simpler pieceof text than using a general-purpose trategy for ex-pressing prereqs statements.
It is arguable that suchrules should really exist as special-case structure build-ing rules.
Such an approach would, however, precludethe use of simplification rules that made further use ofthe output of such rules.Finally, there are rules that are motivated by notionsof simplicity of structure.
For instance, the rule:(5)  time_parallel (do (X) ,  do (Y ) )  --* do (paral lel  (X,Y)).Computational Linguistics Volume 15, Number 4, December 1989 243Chris Meilish and Roger Evans Natural Language Generation from Plansresults in an expression with one fewer "connectives.
"Such rules should really be backed up by a (perhapspsychological) theory of the complexity of messages.Here is an example of how a message languageexpression can be simplified using these rules.neutr~.\] ~eq (prereqs (user,achieve (state (user, done (al))),state (user,done (parallel (a2, wait (s))))),\[\])is simplified by rule (1) to:prereqs (user,achieve (state (user, done (al))),state (user,done (parallel (a2, wait(s)))))which is simplified by rule (2) to:prereqs (user,el,state (user, done (parallel (a2, wait(s)))))which is simplified by rule (3) to:prereqs (user,el,state (user, done (then (a2, walt(s)))))which is simplified by rule (4) to:neccbefore (user,  then  (a2, wa i t ( s ) ) ,  a l )Here the simplification would result in the differencebetween a text like:In order to get you to have washed the baby you musthave undressed the baby and waited until the bath isfull.and one like the following:You must undress the baby and then wait until the bathis full before you can wash the babyThe rewrite rules we have discussed so far in thissection are independent of the domain in which the planis made.
Our system also allows for domain-dependentrules to be provided for a given planning domain.
Thisprovides a way of automatically rewriting every occur-rence of a given expression coming from the plannerinto another given expression.
One purpose of this kindof rule is to provide a translation for states, which maybe primitive objects to the planner but are required to besomewhat more complex by the generator.
For exam-ple, in the car domain, there is a rule that rewrites theplanner primitive positioned (X) to be the complexterm state (X, positioned).
Domain-dependent rewriterules can also be used to show correspondances be-tween action and state names that seem independent butare in fact strongly connected.
For instance, in thehouse-building plan, there is an action lay_basement_floor and a domain state basement_floor_laid (not alegal message state).
Not surprisingly, the second is aneffect of the first and can only come about by the first244having been done.
Given that we can deal with complexstates and actions, we would do well to replace thesecond by a formula involving the first, in fact state(user', done (lay_basement_floor)).
In this way we cansimplify certain expressions in the message.
For in-stance, the expression:do (achieve (basement_floor_laid))is equivalent to:do (achieve (state (user, done (lay_basement_floor)))which simplifies to:do ( ls~r_basement-floor )by simplification rule (2) above.
Given this domain-dependent rule and the simplifications thus enabled, theexpression do (achieve (basement__floorAaid)) wouldbe realized as something like "lay the basement floor,"rather than "get the basement floor to be laid," whichwould arise from a more straightforward encoding of thestate basement_floor_laid in terms of verbs and cases.Domain-dependent rewrite rules allow us, in princi-ple, infinitely to enrich the semantics of actions andstate,~ represented in the plan.
They thus provide oneway of compensating for the shallowness of the plan-ner's representation.
The basic framework on which theplan actions and states hang is, however, fixed by theplanner and cannot be changed by the generator.
Thusnot all deficiencies of the planner can be rectified by thismethod.
The extensive use of domain-dependent re-write rules is in any case unattractive, asit takes awayfrom the domain-independence of the system.
We willreturn to this topic later.4.4 :KNOWLEDGE SOURCES IN MESSAGE CONSTRUCTIONBefore we leave our discussion of how messages areconstructed, it is useful to summarize the differentknowledge sources that have an effect on the textgenerated from a plan.
The gross organization of themessage is determined by rhetorical strategies that lookfor patterns in the plan structure.
Such strategies arespecific only to the kind of plan that we are taking asinput (i.e., hierarchical, nonlinear plans).
Message sim-plification is usually responsible for the finer-grainstructure of the message, as its rewrite rules operatestrictly locally in the message.
The domain-independentrewrite rules exploit the redundancy in the messagelanguage and express heuristics about how a givenproposition might be expressed most simply.
Such rulesembody simple knowledge about planning and the facil-ities of the message language.
Finally, domain-depen-dent rewrite rules enable some of the hidden structure inthe planner's representation to be revealed.Once a final message has been decided on, its real-ization as text makes use of structure building rules thatdepend on the natural language being used.
At this pointmost of the significant decisions have already beenmade.
The structure-building rules are able to make aComputational Linguistics Volume 15, Number 4, December 1989Chris Mellish and Roger Evans Natural Language Generation from PlansFigure 11 Installing the Services.limited choice among possible syntactic structures andare able to introduce pronominalization where it seemsappropriate, but their scope is heavily constrained bythe message.
During structure building, a domain-de-pendent lexicon makes available a verb entry for eachdomain state and action, as well as a fixed NP that canbe used to denote each domain object.
Although it isuseful to assess the effectiveness of the system byconsidering the text output, many of the more interest-ing problems with the system are really already visibleat the message stage.5.
DISCUSSION5.1 FURTHER EXAMPLESThe system has been tested using a number of differentdomains with rather different characteristics, and theresults have been correspondingly varied.
One domainthat seems to work fairly well is that of cookery recipessuch as the following:MAKING PAPRIKA POTATOES AND SMOKED SAUSAGESMelt the fat, fry the onion in it, add the flour to it andadd the paprika to it.
After this, stir the sauce until itboils.
Meanwhile peel the potatoes and cut them intopieces.
After this, add them to the sauce, cover the panand make the sauce boil, stirring the sauce occasion-ally.
Meanwhile cook the sausages.
After this, add themto the sauce.This text was actually produced from a "mockup" ofplausible planner output, rather than a real plan, and didnot include enough information (about preconditions,effects, etc.)
to warrant he system adding justificationsabout ordering.
This does not seem to matter too much,probably because cookery recipes are traditionally pre-sented as instructions to be followed more or lessblindly.For an example where our techniques produce a lesspleasing result, consider the "installing the services"extract from the house-building plan (discussed above)shown in Figure 11.
In this action graph (which showsno preconditions or effects), we have indicated theactions with abbreviated names.
Those actions in low-ercase are not actually part of installing the services (butare "intruder" actions that are nevertheless crucial tothis part of the plan); they will be described elsewhere inthe text.
Here is the English produced for this planfragment:INSTALLING THE SERVICESInstalling the services involves finishing the electricalwork and laying the storm drains.You must paint the house before finishing the electricalwork.In order to paint the house you must have installed thefinished plumbing and installed the kitchen equipment.You must lay the finished flooring before installing thefinished plumbing and installing the kitchen equipment.You must fasten the plaster and plaster board beforelaying the finished flooring.
In order to fasten theplaster and plaster board you must have installed theair conditioning and installed the rough plumbing andinstalled the rough wiring.Install the drains and then install the air conditioning,installing the rough plumbing.Meanwhile install the rough wiring,You can now fasten the plaster and plaster board.You can now lay the finishedflooring.You can now install the finished plumbing and installthe kitchen equipment.You can now paint the house.You can now finish the electrical work.Meanwhile lay the storm drains.You have now finished installing the services.This account is basically comprehensible, but is repet-itive and quite hard to follow.
One reason for therepetition is that the subject matter is really very boringand uninformative, and it would be quite a challengingtask for a human being to produce interesting andreadable text from the same information.
We discussbelow some other reasons why this text is less thanoptimal.5.2 DEFICIENCIES IN PLANSAlthough generating explanations from the output of anAI planner appears to be a promising application ofnatural language generation research, there are a num-ber of special problems that we have encountered withthis task.
Indeed, we can explain some of the deft-ciences in the text we have been able to generate purelyin terms of deficiencies of the planner and/or its plans.Some problems tem from the use of plan operators notdesigned with text generation in mind, and can besolved within the scope of the planning system.
Moreserious are problems that arise because of deficienciesin the planner methodology itself.
In the development ofour system we have encountered a number of these,ranging from trivial to quite fundamental.
Some of theseare properties of NONLIN in particular; others applymore generally to most AI planning systems.
It is notappropriate to discuss the full details of these problemshere, but we shall mention some of the main points.GRANULARITYOne might ask why, unlike in the cookery recipe, thereis no pronominalization in the text for installing theservices.
The coherence of the text would be improvedComputational Linguistics Volume 15, Number 4, December 1989 245Chris Mellish and Roger Evans Natural Language Generation from Plansconsiderably by the judicious use of pronouns.
Unfor-tunately, whereas in the cookery domain (which weencoded by hand) a particular action of 'frying' istreated as an instance of a general action that canpotentially be applied to different objects; in the house-building domain the objects acted on by an action arefundamentally built into that action.
The difference canbe seen from example lexical entries from the twodomains:ix (fry (Food, In), fry, \[obj: Food, in: In\]).lx (install_rough_wiring, install,\[obj : @ 'the rough wiring'\]).To use pronominalization, one needs to be able todetermine that the same domain object is being men-tioned several times, but only the first type of represen-tation here actually supports the representation f do-main objects.
What has happened here is that, from thepoint of view of making a house-building plan, theplanner cannot make use of properties of a generalaction like 'install,' and so its representation f actionsis at a coarser level of granularity than that required toproduce good text.In common with most plans in traditional AI work,NONLIN plans only encode very weak informationabout causality and temporal relationships.
For in-stance, when there is an action that achieves an effect,there is no way to tell from the plan whether we aredealing with an instantaneous action, an extended ac-tion that terminates as soon as the effect is achieved, oran extended action where the effect is achieved some-time during the execution.
A natural language likeEnglish provides ways of distinguishing between thesecases:Turn on the switch and the light will be on.Pour in the water until the bucket is full.Prepare a chicken curry so that the chicken scraps areused up.Because there is no way to distinguish between these inthe NONLIN representation f effects, our generator isforced to try to find a neutral way to express all of them.As a result, there is a homogeneity in the text that is notnecessarily reflected in the actual plan execution.
Againthe problem can be thought of as a mismatch betweenthe granularity of the representation used for planningand that needed to exploit the facilities of the naturallanguage.The effect of the granularity problem can be lessenedby allowing the plan generator to provide deeper infor-mation about he internal structure of actions and statesthrough domain-dependent rewrite rules.
Our messagelanguage allows us to talk about repeated actions, forinstance, and so we can specify that certain domainactions are really shorthand for more complex expres-sions:filLbucket -~ repeat (pour (water, bucket),state (bucket, full)).246Messages containing these complex actions can then besimplified by domain-independent rules like:result (repeat (Act, State), State) -*do (repeat (Act, State)).Similarly we can use domain-dependent rewrite rules tointroduce tokens tanding for domain objects and hencegive us a basis for pronominalization.
The more onereliies on domain-dependent rewrite rules for good text,however, the less one can claim to have a domain-independent basis for generating text from plans.CONCEPTUAL FRAMEWORKDomain-dependent rewrite rules can be regarded as away of embellishing the planner's output o match upbetter with the requirements for generation.
The basicframework of the plan is, however, something thatcannot be changed unless the generator itself is to startdoing some of the planning.
Assuming that there is somepoint in distinguishing the planner from the generator,the generator is therefore sometimes faced with a mis-match between self-evident concepts in the planner'sconceptual framework and those concepts that can beexpressed simply in natural language.
Consider, forinstance, the notion of (primitive) actions that areunordered in the plan.
If two actions have no orderingrelation between them, then this indicates that theactions can be performed in any order relative to oneanother.
To express correctly the plan's semantics, oneshould therefore make use of expressions like:Install the drains and install the rough wiring, in anyorder.In practice, however, we have chosen to map such apiece of plan into a message like:do (parallel (instalLdrains, inst~.11 rough_wiring)).which then gives rise to a text such as:Install the drains.
Meanwhile install the rough wiring,Treating unordered actions as parallel actions mayindeed both produce good text and even capture thereality of plan execution, as in:Make the sauce boil, stirring the sauce occasionally.but this will only be so if at least one of the actions takesplace over a period of time and the actions can be andare recommended to be executed concurrently.
Thereis, of course, no way to determine from the planner'srepresentation whether this is so.
Indeed, since theplanner egards all primitive actions as essentially in-stantaneous, in all cases it is in some sense incorrect toexpress the planner's recommendations i  this way.
Ifthe correct execution of the plan were critical, forinstance, then it could be very dangerous to hide thelimited way in which the planner views the world as wehave done.
It might thus be suggested that a generatorworking from plans could and should always strive toconvey the plan semantics accurately, even if thisComput~tional Linguistics Volume 15, Number 4, December 1989Chris Mellish and Roger Evans Natural Language Generation from Plansinvolves long-winded and unnatural prose.
But in theend one is faced with an incompatibility between theplanner's conceptual framework and the limits of whatour language can express.
For instance, it unclear howthe action of "installing the rough wiring" can beexpressed in English in such a way that the action canonly be interpreted as an instantaneous action, which isthe way the planner sees it.EXPLANATORY POWERThe texts that we have generated from plans are in-tended to do more than simply tell the reader how toexecute a series of actions.
We always hoped that thejustification structure built by the planner would alsohelp us to explain why the given actions, with theordering described, are the right ones to achieve theplan's goal.
In practice, however, our texts have failedto be explanatory for a number of reasons.
One problemis that, unlike instructions generated by human beings,our texts only tell you what to do, and not what not todo.
It is often just as important for a person to bewarned about he unpleasant consequences of doing thewrong thing as it is to be told what the right thing is.Unfortunately, the notion of "plan" we have adoptedonly makes reference to the successful actions, eventhough the plan generator may have spent a lot of timeexploring other possibilities that did not work out.
Itmight therefore be appropriate, in future work, toconsider natural language generation based on the traceof a planning system, rather than on the final result.Similarly, in many of the texts produced by oursystem the reader is told what to do but is given noillumination as to why things have to be done in thisway.
Unfortunately, although in principle every plan isjustified by earlier actions achieving the preconditionsof later actions, many plans do not contain this infor-mation in a useful form--in the housebuilding plan, forinstance, the only preconditions that are required for anaction in this plan to be performed are the successfulcompletion of previous actions.
That is, the person whohas encoded the operators in terms of which the plan isconstructed has "compiled in" certain ordering con-straints without using the language of preconditions andeffects effectively to explain them.
One is remindedhere of the problems that Swartout (1983) encounteredin producing explanations from expert systems.
Theproblem was that just because a set of rules wassufficient to produce xpert behavior did not mean thatthose rules contained anything illuminating to put intoexplanations.
Similarly in the planning area, there is noreason why a set of operators that are effective forproducing useful plans need contain anything veryinteresting that can be put into a natural languageaccount.
Unfortunately, one cannot necessarily expectmachine-generated plans to come at the right level ofdetail to be really useful to a human being.
For instance,a house-building plan that enabled one to see why therough plumbing must be installed after the drains (pre-Computational Linguistics Volume 15, Number 4, December 1989sumably because otherwise it is hard to make the pipesline up) would be very large, and it would be wellbeyond the state of the art for such a plan to beproduced automatically.
Moreover, such a plan wouldundoubtably contain a lot of information that wasblindingly obvious to a human reader and hence of nointerest whatsoever.ARBITRARY PLANNER RESTRICTIONSAs is typical with application programs, most plannershave particular features that represent non-standard ornovel approaches to certain situations.
This fact meansthat any natural language generator using plans as inputmust customize itself somewhat to the peculiarities ofthe particular planner it is working with.
One problempeculiar to NONLIN's representation language con-cerns the manner in which preconditions are specified.In NONLIN an operator specifies how a goal is ex-panded to a network of subgoals.
As was observed inthe earliest AI planners, the most common case is thata goal has preconditions, goals that must be true beforethe given goal can be achieved.
In NONLIN, one has touse an expansion to represent this, with the conse-quence that one wants the original goal itself to occur inthe expansion (that is Goal expands to Pre ~ .
.
.
.
.
Pre y,Goal).
NONLIN will not allow this, so there have to betwo distinct representations of the goal.
So in the carexample, we have {goal ...} for the high level goal and{act ...} for the low level version (although this schememight not work in every domain).
By this means we canmake NONLIN behave, but give ourselves a linguisticproblem--every action occurs twice.
For example, wemight get:STARTING THE ENGINEGo to the cab and then start the engine and you willhave finished starting it.Roughly speaking, the distinction is between 'startingthe engine' (the whole task) and 'actually starting theengine' (the specific operation).
To some extent we canavoid the problem by using different phrases (e.g., 'turnon the engine'), but it does not make the generation taskeasier.5.3 DEFICIENCIES IN OUR APPROACHThe problems with our natural language accounts are, ofcourse, not entirely due to deficiencies in the plans weare working on.
We have deliberately held closely tosome basic guiding principles to evaluate their applica-bility.
So it is important to pinpoint heir failings in ourcurrent system and mention possible alternative ap-proaches.RELYING ON PLAN STRUCTURETo build a domain-independent system to generate textfrom plans, we have deliberately tried to use onlyinformation that the planner itself understands; i.e.,information about the structure of the plan.
One of the247Chris Meilish and Roger Evans Natural Language Generation from Plansfundamental tenets of our approach was thus that theplan abstraction hierarchy would be a useful source ofinformation about how the text should be organized.But our experience suggests that it may not be as usefulas one might think.
As well as the kind of problemsdescribed above (which might be corrected in a differentplanning system), there seem to be more general dis-crepancies between the kind of abstraction useful to aplanner and the kind useful to a text generator.For example, our car domain and many of theblocksworld plans that have been studied in AI tend tohave a deeper abstraction hierarchy than one mightexpect from the apparent simplicity of the tasks.
Agenerator that tries to exploit them all ends up produc-ing too much structure in its text.
Thus the exampleused in Section 3 also has a 'section':GAINING ACCESS TO THE DISTRIBUTORDetach the dirt cover f rom the engine and you will havef inished gaining access to the distributor.Here there is a level of abstraction that is useful to theplanner, but not to the human reader: it would probablyhave been better to insert this section "in-line" in thehigher level description.
On the other hand, the single"section" devoted to installing the services in thehouse-building plan would have gained from being bro-ken up in some way.
There may be a linguistic solutionto the problem of whether a piece of informationdeserves a ful l" section," perhaps in terms of a domain-dependent model of what is and is not worth saying, orthe problem may point to a fundamental differencebetween the ways the planner and a human perceivesthe planning task.
Either way, what is clear is that theplanner's abstraction hierachy alone is not fully ade-quate for text generation.
Whether we can devise gen-eral principles for producing alternative decompositionsof plans more suitable for text generation remains anopen research area.REPETITIONWe have commented above on reasons why the rawmaterial we can gain from plans is liable to lead torepetitiveness in the text.
Even if we managed to enrichthe plan representations suitably, however, the genera-tor would still be deficient when the input really isuniform.
In particular, the uniformity of the text outputoften leads to unwanted ambiguities, imply because ofthe lack of variation in the stylistic devices used.
Forinstance, in the following excerpt it is unclear whetherthe potato peeling is supposed to be "in parallel with"melting the fat, or just with stirring the sauce:Melt the fat  .
.
.
.After this, stir the sauce until it boils.Meanwhile peel the potatoes and cut them into pieces.We originally hoped to overcome the problem of repe-tition by providing several structure-building rules foreach type of message language construction, whichwould be sensitive to the form of the objects involved in248the construction.
To some extent we succeeded inproducing such rules, but the effect on the text was notgreat.
The problem here is that, even with these extrarules, our structure-building is based solely on localpatterns in the message, whereas the problem of repe-tition can only be solved by a global planning of thetext.
It :might be possible to gain some improvement inour system by having the choice of structure-buildingrules be determined partially by some random factor,but a proper solution requires a more radical redesign.LINGUISTIC SIMPLIFICATIONSThere are a number of stylistic issues that the systemcannot easily accommodate.
For instance, operationssuch as "heavy NP shift," segmentation into sentences,coordination, and ellipsis all require detailed stylisticcontrol and evaluation.
The message language is delib-erately nonlinguistic and so can only approximatelyrepresent the kinds of language-dependent stylistic in-formation such processing needs.
For instance, rewriterules can decide how to group information on the basisof the complexity of the message, but this only indi-rectly reflects the complexity of the text that will begenerated.
The effective use of different stylistic de-vices depends in the end on simplifications that arejustified on linguistic, rather than conceptual, grounds,and this suggests that our architecture should reallyin~zorporate a style module capable of reasoning at thislevel.
Such a style module would necessarily have totake a more global view, looking at the overall inguisticeffect of the localized basic text generation processes.
Itmight be possible to introduce linguistic simplificationsat structure-building time, relaxing the requirement ofcompositionality (indeed, this is how McDonald 1983operates).
We believe, however, that it would be pref-erable to attempt to treat it at least conceptually as asubsequent processing stage.5.4 WAYS FORWARDIn this paper we have described a system for generatingnatural anguage from automatically generated plans.Our main aim in developing the system was to producea model of a complete system using state-of-the-artmethodology and techniques, partly to evaluate thecurrent state of knowledge, and partly to provide a basisfor comparison for future work.
Logically, then, thereare two strands to further work based on this research:building on the evaluation to learn lessons about thedesign of generation systems and the systems theyinteract with, and building on the system itself toproduce better generation-from-plans sy tems.One of the key evaluative l ssons concerns the planstructures a system like this depends on.
We found theplan,; produced by NONLIN unsatisfactory and wehave begun to understand why.
We must now specifywhat we would like a plan to look like and contain,within the general constraint hat a planning systemcouht reasonably produce it.
Our present approach toComlmtational Linguistics Volume 15, Number 4, December 1989Chris Meilish and Roger Evans Natural Language Generation from Plansthis top ic  is to take a very  fo rmal  v iew o f  p lans asa lgebra ic  express ions  over  states ( rather  than act ions  orgoals)  w i th  a we l l -de f ined  fo rmal  semant ics ,  a l lowing usto be c lear  about  the semant ic  e f fect  o f  p lan t ransfor -mat ions .The system itself falls broadly into two parts, build-ing and simplifying the message, and turning the mes-sage into text.
Of these the latter is the more modular,more declarative, and probably more successful atpresent.
To a certain extent it can serve as a piece ofenabling technology for research on the message com-ponent.
Its major deficiency as discussed above isglobal stylistic control.
Its handling of morphology iscurrently rather unprincipled, but the utilization of amorphological representation language such as Datr(Evans and Gazdar 1989 a,b) would rectify this.The biggest outstanding task, however, is the mes-sage planner itself.
The mechanism described aboveemploys some quite powerful techniques in a fairlyeffective way, but it is not very perspicuous or exten-sible.
We have begun work on a new message plannermodule that applies transformation rules to plans of thealgebraic type mentioned above, gradually transformingthe plan into an optimized message structure.
This willprovide us with a rule-based semideclarative frameworkin which to explore further the issues of messageplanning.ACKNOWLEDGMENTSThe work reported here was made possible by SERC grant GR/D/08876.
Both authors are currently supported by SERC AdvancedFellowships.REFERENCESChester, Daniel 1976 The Translation of Formal Proofs into English.Artificial Intelligence, Vol 7, 261.Conklin, E. Jeffrey and McDonald, David D. 1982 Salience: The Keyto the Selection Problem in Natural Language Generation.
In:Proceedings of the 20th Meeting of the Association for Computa-tional Linguistics, Toronto, Canada.Dale, Robert 1986 The Pronominalization Decision in LanguageGeneration.
Dissertation Abstracts International Report 276, Uni-versity of Edinburgh, Edinburgh, U.K.Evans, Roger and Gazdar, Gerald 1989 Inference in Datr.
In: Pro-ceedings of the 1989 European Association for ComputationalLinguistics, UMIST.Evans, Roger and Gazdar, Gerald 1989 The Semantics of Datr.
In:Proceedings of the 1989 Artificial Intelligence Society of GreatBritain, University of Sussex.Gazdar, Gerald; Klein, Ewan; PuUum, Geoffrey; and Sag, Ivan 1985Generalised Phrase Structure Grammar.
Blackwell.Grosz, Barbara J.
1977 The Representation and Use of Focus inDialogue Understanding.
SRI Technical Report 151.Kay, Martin 1979 Functional Grammar.
In: Proceedings of the 5thAnnual Meeting of the Berkeley Linguistics Society.
Berkeley,CA.Kay, Martin 1984 Functional Unification Grammar: A Formalism forMachine Translation.
In: Proceedings of COLING-84.
Stanford,CA.Mann, William C. and Moore, James A.
1981 Computer Generation ofMultiparagraph English Text.
American Journal of ComputationalLinguistics, Vol 7, No 1.Mann, William; Bates, Madeleine; Grosz, Barbara; McDonald, Dav-id; McKeown, Kathleen; and Swartout, William 1982 Text Gen-eration.
American Journal of Computational Linguistics.
Vol 8,No 2.McDonald, David D. 1983 Natural Language Generation as a Com-putational Problem: An Introduction.
In: Brady, Michael andBerwick, Robert (Eds.
), Computational Models of Discourse,MIT Press, Cambridge, MA.McKeown, Kathleen R. 1982 Generating Natural Language Text inResponse to Questions about Database Structure.
Ph.D. thesis,University of Pennsylvania, Philadelphia, PA.Sacerdoti, Earl D. 1973 Planning in a Hierarchy of AbstractionSpaces.
In: Proceedings of the Eighth International Joint Confer-ence on Artificial Intelligence-83.
Palo Alto, CA.Sacerdoti, Earl D. 1975 The Non-Linear Nature of Plans.
In: Pro-ceedings of the Fourth International Joint Conference on ArtificialIntelligence, Tbilisi, USSR.Sidner, Candace L. 1979 Towards a Computational Theory of DefiniteAnaphora Comprehension in English Discourse.
Technical Report537, MIT Artificial Intelligence Laboratory, Cambridge, MA.Swartout, William R. 1983 XPLAIN: A System for Creating andExplaining Expert Consulting Programs.
Artificial Intelligence,Vol 21.Tate, Austin 1976 Project Planning using a Hierarchical Non-linearPlanner.
Dissertation Abstracts International Report 25, Univer-sity of Edinburgh, Edinburgh, U.K.Tsang, Edward 1986 Plan Generation in a Temporal Frame.
In:Proceedings of the 7th European Conference on Artificial Intelli-gence, Brighton, U.K.NOTES1.
Current address: Department of Artificial Intelligence, Universityof Edinburgh, 80 South Bridge, EDINBURGH EH1 IHN, UnitedKingdom.2.
In the node descriptions we distinguish explicitly between goals andactions that achieve goals.
The reason for this is discussed in Section5 below.3.
It is possible, however, to specify that, for a given domain, therewill only ever be one agent.Computational Linguistics Volume 15, Number 4, December 1989 249
