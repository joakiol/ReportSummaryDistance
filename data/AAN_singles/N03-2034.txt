Building lexical semantic representations for Natural Language instructionsElena TerenziComputer SciencePolitecnico di MilanoMilano, Italyelenat@libero.itBarbara Di EugenioComputer ScienceUniversity of IllinoisChicago, IL, USAbdieugen@cs.uic.eduAbstractWe report on our work to automatically build acorpus of instructional text annotated with lex-ical semantics information.
We have coupledthe parser LCFLEX with a lexicon and ontol-ogy derived from two lexical resources, Verb-Net for verbs and CoreLex for nouns.
We dis-cuss how we built our lexicon and ontology,and the parsing results we obtained.1 IntroductionThis paper discusses the lexicon and ontology we builtand coupled with the parser LCFLEX (Rose?
and Lavie,2000), in order to automatically build a corpus of instruc-tional text annotated with lexical semantics information.The lexicon and ontology are derived from two lexicalresources: VerbNet (Kipper et al, 2000a) for verbs andCoreLex (Buitelaar, 1998) for nouns.
We also report theexcellent parsing results we obtained.Our ultimate goal is to develop a (semi)automaticmethod to derive domain knowledge from instructionaltext, in the form of linguistically motivated actionschemes.
To develop this acquisition engine, our ap-proach calls for an instructional corpus where verbs areannotated with their semantic representation, and whererelations such as precondition and effect between the ac-tions denoted by those verbs are marked.
Whereas theaction relation annotation will be manual, the semanticannotation can be done automatically by a parser.We are interested in decompositional theories oflexical semantics such as (Levin and Rappaport Hovav,1992) to account for examples such as the following:(1a) Wipe the fingerprints from the counter.
(1b) Wipe the counter.
(2a) Remove the groceries from the bag.
(2b) Remove the bag.As the effect of the two actions (1a) and (2a), it is inferredthat the specified location (counter in (1a), bag in (2a))has been ?emptied?
of the object (fingerprints in (1a),groceries in (2a)).
Thus, a system could map both verbswipe and remove onto the same action scheme.
How-ever, the apparently equivalent transformations from (1a)to (1b) and from (2a) to (2b) show otherwise.
(1b) de-scribes the same action as (1a), however (2b) cannot havethe same meaning as (2a).
(Levin and Rappaport Hovav,1992) defines classes of verbs according to the ability orinability of a verb to occur in pairs of syntactic framesthat preserve meaning.
The location-as-object variant ispossible only with (some) manner/means verbs such aswipe, and not with result verbs such as remove.We chose to base our lexicon and ontology on VerbNet(Kipper et al, 2000a), that operationalizes Levin?s workand accounts for 960 distinct verbs classified into 72 mainclasses.
Moreover, given VerbNet strong syntactic com-ponents, it can be easily coupled with a parser and used toautomatically generate a semantically annotated corpus.Of course, when building a representation for a sen-tence, we need semantics not only for verbs, but alsofor nouns.
Whereas many NL applications use Word-Net (Fellbaum, 1998), we were in need of a richer lex-icon.
We found CoreLex (Buitelaar, 1998) appropriatefor our needs.
CoreLex is based on a different theorythan Levin?s (that of the generative lexicon (Pustejovsky,1991)), but does provide a compatible decompositionalmeaning representation for nouns.The contribution of our work is to demonstrate that ameaning representation based on decompositional lexicalsemantics can be derived efficiently and effectively.
Webelieve there is no other work that attaches a semanticsof this type to a parser for a large coverage corpus.
Verb-Net has been coupled with the TAG formalism (Kipperet al, 2000b), but no parsing results are available.
More-( :morphology position:syntax (*or*((cat n) (root position) (agr 3s) (semtag (*or* lap1 lap2)))((cat vlex) (root position) (vform bare)(subcat (*or* np np-advp np-pp))(semtag put))):semantics (put (<put-9.1> (subj agent) (obj patient) (modifier destination) (pred destination)))(lap1 (<lap1>))(lap2 (<lap2>)))Figure 1: The entry for position in the LCFLEX lexiconCLASS: put-9.1PARENT: -MEMBERS: arrange immerse lodge mount place position put set situate slingTHEMATIC ROLES: Agt Pat DestSELECTIONAL RESTRICTIONS: Agt[+animate] Pat[+concrete] Dest[+location -region]FRAMES:Transitive with Locative PP Agt V Pat Prep[+loc] Dest cause(Agt, E0) ^ motion(during(E0), Pat) ^:Located-in(start(E0), Pat, Dest) ^ Located-in(end(E0), Pat, Dest)Transitive with Locative Adverb Agt V Pat Dest[+adv-loc] cause(Agt, E0) ^ motion(during(E0), Pat) ^:Located-in(start(E0), Pat, Dest) ^ Located-in(end(E0), Pat, Dest)Figure 2: The class put-9.1 from VerbNetover, we also show that two lexical resources that focuson verbs and nouns can be successfully integrated.2 Lexicon and ontologyWe chose LCFLex (Rose?
and Lavie, 2000), a robust left-corner parser, because it can return portions of analysiswhen faced with ungrammaticalities or unknown wordsor structures (the latter is likely in a large corpus).
Wemodified and augmented LCFLEX?s existing lexicon andbuilt an ontology.To illustrate our work, we will refer to the lexical en-try for position, that can be both a noun (n) or a verb(vlex) ?
the format is provided by LCFLEX, but the:semantics field was originally empty (see Figure 1).For the verb, different subcategorization frames are listedunder subcat: the verb can have as argument just an np,or an np and a pp, or an np and an adverbial phrase.
Eachpart of speech (POS) category is associated to a semtag,an index that links the POS entry to the corresponding se-mantic representation.
<put-9.1>, <lap1> and <lap2>are entries in our ontology.
Before discussing the ontol-ogy, we need to discuss the VerbNet and CoreLex for-malisms.Figure 2 shows a simplified version of the VerbNetclass to which the verb position belongs.
All verbs thatcan undergo the same syntactic alternations belong to thesame class.
Each frame is labeled with its name, and con-sists of the syntactic frame itself (e.g., Agt V Pat PrepDest), and its semantic interpretation.
Agt stands forAgent, V for Verb, Pat for Patient, Dest for Destination.A class includes a list of parent classes, empty in thiscase (verb classes are arranged in a hierarchy), its the-matic roles and selectional restrictions on these.
Then,it specifies all the frames associated with that class, andprovides a meaning representation for each frame.
In thiscase, the two frames are both transitive.
In the first thedestination is a prepositional phrase, whereas in the sec-ond the destination is an adverb.The semantics portion of a lexical entry links the syn-tactic roles built by the parser to the thematic roles in theverb class.
In Figure 1, the following mappings are spec-ified under put: subject to agent, object to patient, mod-ifier to destination for the first frame (the parser alwaysmaps prepositional phrases to modifier roles), and pred todestination for the second frame (the parser usually mapsadverbs to the pred role).As regards nouns, CoreLex defines semantic typessuch as artifact or information.
Nouns are characterizedby bundles of semantic types.
Nouns that share the samebundle are grouped in the same Systematic PolysemousClass (SPC).
The resulting 126 SPCs cover about 40,000nouns.VerbNet classes and CoreLex SPCs are realized as en-tities in our ontology.
Figure 3 shows the entries forput-9.1 and the SPCs lap2 (we omit lap1 for lackof space).
We do not have room for many details, how-ever note that the :spec field is the basis for building thesemantic representation while parsing.
The subfields of:spec are structured as (name type-check arg).arg can be either a variable or a complex argument builtwith one or more functions.
type-check is a the typeconstraint arg must satisfy to be included in the finalrepresentation.
For further details, see (Terenzi, 2002).
(:type <put-9.1>:isa nil:vars (agent patient destination):spec ((agent <animate> agent)(patient <concr-ent> patient)(dest <> (<loc-not-reg> destination))(event <>(<event>(<not-located-in> destination patient)(<in-motion> patient)(<located-in> destination patient)nilevent))))(:type <lap2>:isa (<loc>):instances nil:vars nil:spec ((artifact +)(location +)(psych-feat +)))Figure 3: Two entries in our ontology3 ResultsOur lexicon includes 109 verbs and 289 nouns, groupedunder 9 classes and 47 SPCs respectively (classes andSPCs are the entries in the ontology).We evaluated LCFLEX augmented as we have de-scribed on a test set taken from the home repair portion ofa 9Mb written corpus originally collected at the Univer-sity of Brighton.
We collected the 480 sentences that con-tained at least one of the verbs in our lexicon ?
out of 109verbs, those sentences cover 75.
These 480 sentences in-clude a main clause plus a number of adjunct clauses.
Be-cause we were mostly interested in those specific verbs,we simplified those sentences so that the clause that con-tains the verb of interest becomes the main clause, andthe others are discarded.Correct Partially Wrong Parsercorrect errorOnly Verbs 87% 4.8% 2.2% 6%Verbs, Nouns 96% 4% 0 0Table 1: Parsing ResultsTable 1 reports our results.
A correct parse means thatthe full semantic representation is built with every syntac-tic role mapped to the correct thematic role.
With partialcorrectness we mean that e.g.
not all the syntactic roleswere mapped to their correct thematic roles.
Correctnesswas judged parse by parse by one of the two authors.
Weconducted two evaluations, one earlier after we had notyet included nouns, and one after the full implementa-tion.
In the first evaluation (Only Verbs), we preprocessedthe sentences so that the nouns from the corpus would bemapped to the closest noun in our then small noun lex-icon of about 40 nouns.
The second evaluation (Verbs,Nouns) was conducted on 228 sentences out of the 480tested in the first evaluation.
The 228 sentences containthe original nouns, as we now have the full lexicon forthe nouns too.
The improvement in the second evaluationis due to the full noun lexicon, but the absence of parsererrors to improvements in a new release of the parser.4 Conclusions and future workWe have shown that two rich lexicons such as VerbNetand CoreLex can be successfully integrated.
We havealso shown that a parser which uses such a lexicon andontology performs extremely well on instructional text.We are now poised to systematically run the parser onthe full home repair portion of the corpus (about 6Mb).This is likely to require additions to the lexicon and theontology.AcknowledgementsThis work is supported by award 0133123 from the NationalScience Foundation.
Thanks to all who shared their resourceswith us.ReferencesPaul Buitelaar.
1998.
CoreLex: Systematic Polysemy and Un-derspecification.
Ph.D. thesis, Computer Science, BrandeisUniversity, February.Christiane Fellbaum, editor.
1998.
WordNet: An ElectronicLexical DataBase.
MIT Press, Cambridge, MA.Karin Kipper, Hoa Trang Dang, and Martha Palmer.
2000a.Class-based construction of a verb lexicon.
In AAAI-2000,Proceedings of the Seventeenth National Conference on Ar-tificial Intelligence, Austin, TX.K.
Kipper, H. T. Dang, W. Schuler, and M. Palmer.
2000b.Building a class-based verb lexicon using TAGs.
In TAG+5Fifth International Workshop on Tree Adjoining Grammarsand Related Formalisms.B.
Levin and M. Rappaport Hovav.
1992.
Wiping the slateclean: a lexical semantic exploration.
In B. Levin and S.Pinker, editors, Lexical and Conceptual Semantics.
Black-well Publishers.James Pustejovsky.
1991.
The generative lexicon.
Computa-tional Linguistics, 17(4):409?441.C.
P. Rose?
and A. Lavie.
2000.
Balancing robustness andefficiency in unification-augmented context-free parsers forlarge practical applications.
In J.-C. Junqua and G. van No-ord, editors, Robustness in Language and Speech Technol-ogy.
Kluwer Academic Press.Elena Terenzi.
2002.
Building lexical semantics representa-tions for action verbs.
Master?s thesis, University of Illinois- Chicago, December.
