Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 630?640,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsExpanding Paraphrase Lexicons by Exploiting Lexical VariantsAtsushi Fujita?Pierre Isabelle?
?National Institute of Information and Communications Technology3-5 Hikaridai, Seika-cho, Souraku-gun, Kyoto, 619-0289, Japanatsushi.fujita@nict.go.jp?National Research Council Canada1200 Montreal Road, Ottawa, Ontario, K1A 0R6, CanadaPierre.Isabelle@nrc.caAbstractThis study tackles the problem of paraphraseacquisition: achieving high coverage as wellas accuracy.
Our method first induces para-phrase patterns from given seed paraphrases,exploiting the generality of paraphrases exhib-ited by pairs of lexical variants, e.g., ?amend-ment?
and ?amending,?
in a fully empiri-cal way.
It then searches monolingual cor-pora for new paraphrases that match the pat-terns.
This can extract paraphrases compris-ing words that are completely different fromthose of the given seeds.
In experiments, ourmethod expanded seed sets by factors of 42to 206, gaining 84% to 208% more cover-age than a previous method that generalizesonly identical word forms.
Human evaluationthrough a paraphrase substitution test demon-strated that the newly acquired paraphrases re-tained reasonable quality, given substantiallyhigh-quality seeds.1 IntroductionOne of the characteristics of human languages is thatthe same semantic content can be expressed usingseveral different linguistic expressions, i.e., para-phrases.
Dealing with paraphrases is an importantissue in a broad range of natural language process-ing (NLP) tasks (Madnani and Dorr, 2010; Androut-sopoulos and Malakasiotis, 2010).To adequately and robustly deal with paraphrases,a large-scale knowledge base containing words andphrases having approximately the same meaningis indispensable.
Thus, the task of automaticallycreating such large-scale paraphrase lexicons hasbeen drawing the attention of many researchers (seeSection 2 for details).
The challenge is to en-sure substantial coverage along with high accuracydespite the natural tension between these factors.Among the different types of language resources,monolingual corpora1offer the largest coverage, butthe quality of the extracted candidates is generallyrather low.
The difficulty lies in the manner of dis-tinguishing paraphrases from expressions that standin different semantic relations, e.g., antonyms andsibling words, using only the statistics estimatedfrom such corpora.
In contrast, highly accurate para-phrases can be extracted from parallel or compara-ble corpora, but their coverage is limited owing tothe limited availability of such corpora for most lan-guages.This study aims to improve coverage while main-taining accuracy.
To that end, we propose a methodthat exploits the generality exhibited by pairs of lex-ical variants.
Given a seed set of paraphrase pairs,our method first induces paraphrase patterns by gen-eralizing not only identical word forms (Fujita etal., 2012) but also pairs of lexical variants.
For in-stance, from a seed pair (1a), a pattern (1b) is ac-quired, where the pair of lexical variants (?amend-ment?, ?amending?)
and the shared word form ?reg-ulation?
are generalized.
(1) a. amendment of regulation?
amending regulationb.
X:ment of Y :??
X:ing Y :?With such patterns, new paraphrase pairs that wouldhave been missed using only the surface forms areextracted from a monolingual corpus.
Obtainablepairs can include those comprising words that are1The term ?monolingual corpora?
in this study refers tomonolingual non-parallel corpora, unless otherwise explicitlynoted.
As reviewed in Section 2.1.2, monolingual parallel cor-pora have also been used as a source of paraphrases.630completely different from those of the seed para-phrases, e.g., (2a) and (2b).
(2) a. investment of resources?
investing resourcesb.
recruitment of engineers?
recruiting engineersWhile the generality underlying paraphrases hasbeen exploited either by handcrafted rules (Har-ris, 1957; Mel?
?cuk and Polgu`ere, 1987; Jacquemin,1999; Fujita et al, 2007) or by data-driven tech-niques (Ganitkevitch et al, 2011; Fujita et al, 2012),we still lack a robust and accurate way of identifyingvarious types of lexical variants.
Our method tacklesthis issue using affix patterns that are also acquiredfrom high-quality seed paraphrases in a fully empiri-cal way.
Consequently, our method has the potentialto apply to many languages.2 Previous Work2.1 Creating Paraphrase LexiconsResearchers have been intensively studying methodsfor automatically creating paraphrase lexicons us-ing various types of corpora.
There are two majorstreams: one that uses monolingual corpora and onethat uses parallel or comparable corpora.2.1.1 Monolingual CorporaA monolingual corpus is the most promising re-source when targeting increased coverage, thanksto the availability of Web-scale monolingual data.Techniques that use such corpora mostly extractpairs of expressions by exploiting the contextualsimilarity associated with the Distributional Hy-pothesis (Harris, 1954).
A given expression is repre-sented with its co-occurring expressions such as ad-jacent word n-grams (Pas?ca and Dienes, 2005; Bha-gat and Ravichandran, 2008; Marton, 2013), nomi-nal elements (Lin and Pantel, 2001; Szpektor et al,2004; De Saeger et al, 2011), and modifiers andmodified words (Hagiwara et al, 2006).
The sim-ilarity of a pair of expressions is calculated by com-paring the distributions of their contexts.Despite the quantitative advantage, this approachtends to result in low accuracy.
This is because con-textual information alone often fails to differentiateparaphrases from expressions that have other seman-tic relations, e.g., antonyms and sibling words.2.1.2 Parallel and Comparable CorporaMuch effort has gone into compiling monolingualparallel corpora and extracting paraphrases fromthem by identifying corresponding parts of alignedsentences.
Barzilay and McKeown (2001) and Panget al (2003) collected multiple human translationsof the same source text.
Multiple verbalizations ofmathematical proofs were also used (Barzilay andLee, 2002).
This triangulating method providessolid anchors that guarantee the semantic equiva-lence of sentences (or text fragments).Monolingual comparable corpora are also usefulsources of paraphrases.
For instance, articles fromdifferent newswire services describing the sameevent can be used in that way (Shinyama et al,2002; Barzilay and Elhadad, 2003; Dolan et al,2004; Wubben et al, 2009).
Chen and Dolan (2011)created such corpora by collecting multiple descrip-tions of short movies through crowdsourcing.
Web-harvested definition sentences of the same term of-ten contain paraphrases (Hashimoto et al, 2011; Yanet al, 2013).Bilingual parallel corpora have been recognizedas sources of paraphrases since (Bannard andCallison-Burch, 2005).
First, a translation tableis created using techniques developed for statisti-cal machine translation.
Then, pairs of expressionsin the same language that share the same transla-tions are extracted.
For instance, a pair (?under con-trol?, ?in check?)
will be extracted if they are bothlinked with the German translation ?unter controlle.
?Each paraphrase pair (e1, e2) is assigned probabili-ties, p(e2|e1) and p(e1|e2), estimated by marginal-izing over all the translations F shared by e1and e2,i.e., p(e2|e1) =?f?Fp(e2|f)p(f |e1).This bilingual pivoting approach inspired fur-ther techniques such as the use of syntactic infor-mation as the basis of constraints (Callison-Burch,2008; Zhao et al, 2009), learning patterns using syn-chronous grammar (Ganitkevitch et al, 2011), un-covering missing links by combining multiple trans-lation tables and other lexical resources (Kok andBrockett, 2010), and re-ranking candidate pairs onthe basis of contextual similarity (Chan et al, 2011).Ganitkevitch and Callison-Burch (2014) compiledparaphrase lexicons for various languages on this ap-proach.631Parallel/comparable corpora are useful sources ofhighly accurate paraphrases.
However, for most lan-guages, only small paraphrase lexicons can be cre-ated due to the limited availability of such corpora.2.1.3 Combination of Multiple CorporaUnlike the above methods, which used only a sin-gle type of corpus as sources of paraphrases, Fujitaet al (2012) used both bilingual parallel and mono-lingual corpora as sources.
In that method, para-phrase pairs, e.g., (3a), are first acquired from abilingual parallel corpus using the bilingual pivotingmethod and several heuristic filters for drastic noisereduction.
Second, each paraphrase pair is general-ized into a paraphrase pattern2, e.g., (3b).
Finally,new pairs, e.g., (3c), are extracted from a monolin-gual corpus using the patterns.
(3) a. amendment of regulation?
amending regulationb.
amendment of X ?
amending Xc.
amendment of documents?
amending documentsUsing that method, they were able to expand theseed lexicon by a large multiple (15 to 40 times),and the new paraphrase pairs were of reasonablygood quality.
However, they introduced variablesonly for identical word forms shared by both sidesof each pair and left corresponding pairs of lexicalvariants, e.g., (?amendment?, ?amending?)
in (3a),untouched.2.2 Dealing with Lexical VariantsIn this study, the term lexical variants covers, atleast, the following three types of word groups.Lexical derivations: different words that share thesame stem and a large part of their meaning,e.g., {?develop?, ?developer?, ?development?,.
.
.}.
Words in such a group can have differentparts-of-speech.Morphological variants: different surface formsof the same word, e.g., {?amend?, ?amends?,?amending?, .
.
.}.
These are derived based onprocesses such as inflection and conjugation.Orthographic variants: different spellings of thesame inflectional/conjugation form of the2If a constituency parser is available for the language of in-terest, one can learn syntax-based patterns during the bilingualpivoting process (Ganitkevitch et al, 2011).same word, e.g., {?color?, ?colour?}
and{?authorize?, ?authorise?
}.Several syntactic and semantic theories, suchas transformational grammar (Harris, 1957) andMeaning-Text Theory (Mel?
?cuk and Polgu`ere,1987), propose a representation of paraphrases thatinvolve alternations of lexical variants.
Jacquemin(1999) and Fujita et al (2007) addressed this typeof paraphrase using manually described syntactictransformation patterns in combination with dictio-naries of lexical variants.Catvar (Habash and Dorr, 2003) is a comprehen-sive lexical derivation database for English.
Word-Net (Fellbaum, 1998) also contains information ofthat kind and is currently available for various lan-guages.
Despite its high accuracy, manual creationof rich lexical resources requires a large human ef-fort.
Gaussier (1999) and Fujita et al (2007) ex-tracted groups of lexical derivations from a list ofheadwords of dictionaries through mining affix pat-terns.
This approach significantly reduces human ef-fort, maintaining reasonable accuracy, but the cover-age is still limited because of the reliance on manu-ally compiled dictionaries.3 Proposed MethodThis study is the first attempt to exploit various typesof lexical variants for acquiring paraphrases in acompletely empirical way.Given a seed paraphrase lexicon (SSeed) ourmethod (henceforth LEXVAR) expands it in twosteps (see also Figure 1).Step 1.
Learning paraphrase patterns: FromSSeed, we learn a set of paraphrase patterns,generalizing various types of lexical variants inaddition to identical word forms.Step 2.
Harvesting new paraphrase pairs: Usingthe learned paraphrase patterns, we harvesta set of new paraphrase pairs (SLV) frommonolingual corpora.LEXVAR subsumes Fujita et al (2012)?s methodexplained in Section 2.1.3 (henceforth IDENT), andits output SLValways subsumes IDENT?s output(SID).
As LEXVAR and IDENT have the effectof expanding pre-existing paraphrase lexicons, theycan be used as a complement to the other methodsfor acquiring paraphrases, provided they produce a632Monolingual Corpusairports!in!Europe!!European!airports+amendment!of!regula1on!!amending!regula1on+should!be!noted!that!!is!worth!no1ng!that!SSeed : seed paraphrase pairsX:?!in!Y:?!!Y:an!X:?!X:ment!of!Y:?!!X:ing!Y:?
!should!be!X:ed!that!!is!worth!X:ing!that!SLV : new paraphrase pairsParaphrase patternscohesion!in!Europe!!European!cohesion+democracy!in!Europe!!European!democracy+increase!in!Hai1!!Hai1an!increase+transporta1on!in!suburb!!suburban!transporta1on+economy!in!Uruguay!!Uruguayan!economy+amendment!of!documents+!amending!documents+amendment!of!protocol+!amending!protocol+investment!of!resources+!investing!resources+recruitment!of!engineers+!recruiting!engineers+should!be!highlighted!that!!is!worth!highlighting!that!should!be!reiterated!that!!is!worth!reiterating!that!should!be!stated!that!!is!worth!stating!that!Step 2.
Harvesting New Paraphrase PairsStep 1.
Learning Paraphrase PatternsFigure 1: Overview of our proposed method.sufficient number of high-quality pairs to make lex-ical generalization possible.3.0 Step 0.
Acquiring Seed Paraphrase PairsOur method requires as input a seed paraphrase lex-icon (SSeed) that has high quality and preferablyexhibits various lexical correspondences that ourmethod will exploit.
For this purpose, paraphrasesacquired from bilingual or monolingual parallel cor-pora are preferable (see Section 2.1.2).In this study, we take the bilingual pivotingmethod as an example for the sake of reproducibility.However, the method also outputs a large numberof non-paraphrases.
To obtain further clean seeds,we apply several filters as described in (Fujita etal., 2012) and discard pairs that have low paraphraseprobability, i.e., p(e2|e1) < 0.01, following the con-vention in (Du et al, 2010; Max, 2010; Denkowskiand Lavie, 2010; Fujita et al, 2012).Previous work (Chan et al, 2011; Fujita et al,2012; Ganitkevitch et al, 2013) has proved thatthe information obtained from monolingual data canbe used for assessing bilingually originated para-phrases.
Thus, pairs that have low contextual sim-ilarity are also filtered out.
Among various recipesfor computing contextual similarity, we use a simpleone: cosine measure of two context vectors compris-ing adjacent word 1?4 grams of all of the phrase ap-pearances in given monolingual data.
For a fair com-parison with previous work, we eliminate only pairsthat have no shared context, i.e., Sim(e1, e2) = 0.3.1 Step 1.
Learning Paraphrase PatternsGiven a set of seed paraphrases (SSeed) we first in-duce a set of paraphrase patterns.
From a seed para-phrase (4a), for instance, while IDENT learns (4b),LEXVAR generates (4c) by exploiting the generalityexhibited by corresponding pairs of lexical variants,i.e., (?amendment?, ?amending?).
(4) a. amendment of regulation?
amending regulationb.
amendment of X ?
amending Xc.
X:ment of Y :??
X:ing Y :?The central issue at this stage is to robustly andaccurately identify various types of lexical variants.We examine a data-driven approach, targeting forincreased coverage, but manually created resourcessuch as dictionaries can also be used.3.1.1 Collecting Affix PatternsAs exemplified by (?X:ment?, ?X:ing?)
in (4c),we represent pairs of lexical variants with affix pat-terns.
While Gaussier (1999) considered only suf-fix patterns, we also deal with prefix patterns suchas those exhibited by (?reliable?, ?unreliable?)
and(?exist?, ?coexist?)
observed in the following para-phrase pairs.
(5) a. is not reliable ?
is unreliableb.
exist together with ?
coexist withHowever, we currently do not consider prefix/suffixcombinations, such as (?directly?, ?indirect?)
and(?believed?, ?unbelievable?
), and other types of af-fixes than prefixes and suffixes.Reliable affix patterns are collected from SSeed(cf., headwords of manually compiled dictionaries(Gaussier, 1999; Fujita et al, 2007)).
First, candi-dates of affix patterns are extracted from SSeedonthe following assumption.A pair of words will share a definite se-mantic relation if the words appear on op-posite sides of a paraphrase pair and havethe same stem.We do not rely on any language resources to iden-tify the stems of words.
Instead, we regard wordpairs that share at least one character as candidate633Word1Word2Affix1Affix2Stemaimed aims X:ed X:s aimaimed achieve X:imed X:chieve aachieving aims X:chieving X:ims aachieving achieve X:ing X:e achievTable 1: Candidate pairs of lexical variants and corre-sponding affix patterns extracted from (6).Affix1Affix2# of unique stemsResultlength length?5 <5X:chieve X:imed 0 1 EliminatedX:chieving X:ims 0 1 EliminatedX:ed X:s 69 22 RetainedX:ing X:e 330 70 RetainedTable 2: Filtering affix patterns (# of unique stems takenfrom our experimental result of Europarl setting).pairs of lexical variants and extract the longest com-mon prefix/suffix as their corresponding affix pat-terns.
From a paraphrase pair (6), for instance, weseparately extract four pairs of words and their cor-responding affix patterns, as shown in Table 1.
(6) is aimed at achieving ?
aims to achieveOur candidate affix patterns are then filtered usingthe following criterion (Gaussier, 1999).An affix pattern is retained iff it is associ-ated with at least n unique stems that areat least k characters in length.This criterion relies on two parameters, n and k. Theparameter n assesses whether a pattern is sufficientlyproductive.
The other (k) is more linguistically mo-tivated: a genuine pattern is more likely to be usedfor long stems, as affixation is a general operationfor producing lexical derivations in many languages.In particular, we set k = 5 and n = 2, as proposedin (Gaussier, 1999).
Table 2 presents examples offiltering affix patterns eliminated and retained withthis setting.3.1.2 Generating Paraphrase PatternsUsing the affix patterns acquired in the previousstep, paraphrase patterns are generated from the seedparaphrase pairs in SSeed.
In this step, we exhaus-tively consider all the combinations of word formsand lexical variants that match one of the affix pat-terns.
From the paraphrase pair (6), the followingpattern is generated.
(7) is X:ed at Y :ing ?
X:s to Y :eThanks to the above filtering mechanism, spuriouspatterns, such as (8), are not generated.
(8) is X:imed at Y :chieving?
Y :ims to X:chieve3.2 Step 2.
Harvesting New Paraphrase PairsGiven a set of paraphrase patterns, e.g., (4c) and (7),new paraphrase pairs are harvested from monolin-gual corpora.
In this process, each paraphrase pat-tern is used as a template such that the expressionsthat match both sides of the patterns are collected.Unlike IDENT?s patterns, e.g., (4b), LEXVAR alsocollects corresponding pairs of lexical variants des-ignated by each pattern.
However, affix patternalone cannot guarantee the semantic relation be-tween a corresponding pair of words that each para-phrase pattern implicitly requires.
For instance, thepattern (9b) is learned from (9a), where a definiterelation is assumed between the two elements of(?X:?
?, ?X:an?).
(9) a. countries of Europe?
European nationsb.
countries of X:??
X:an nationsWord pairs inappropriate for this pattern, e.g., (?un-cle?, ?unclean?)
and (?beg?, ?began?
), would be ex-tracted alongside appropriate ones, e.g., (?Haiti?,?Haitian?)
and (?suburb?, ?suburban?).
Nonethe-less, we suppose that the other surface parts of eachparaphrase pair, e.g., ?countries of?
and ?nations?
in(9b), can effectively constrain instances, guarantee-ing the existence of each entire phrase of the pair.Pattern matching alone can generate pairs that arenot suitable as paraphrases in any context.
Thus, weassess the reliability of each pair by calculating con-textual similarity between two phrases in the samemanner as cleaning SSeed: a pair of phrases is elim-inated, if the phrases are used in completely dissim-ilar contexts.3.3 LimitationWhile LEXVAR exploits a kind of generality of para-phrases exhibited by pairs of lexical variants, it doesnot exploit paraphrase pairs comprising completelydifferent surface forms such as those pairs in (10).
(10) a. look like ?
resembleb.
burst into tears ?
cry634To create further large paraphrase lexicons, we needto acquire these idiosyncratic paraphrases by im-proving existing methods and/or exploring yet an-other approach.Another limitation of LEXVAR is that it consid-ers only prefixes and suffixes of words as clues oflexical correspondences.
We will need extensions todeal with a wider range of lexical correspondences.For instance, depending on the targeted language,other types of affixes, such as infixes and circum-fixes, should be taken into account.
Gaussier (1999)pointed out that some lexical derivations involvecharacter-level alternations, e.g., ?c?
and ?c?.?
Fujitaet al (2007) demonstrated that lexical derivations inan ideographic language, i.e., Japanese, can be cap-tured by considering both ideographs and their pho-netic transcriptions.Last but not least, as LEXVAR regards only corpusas source, it does not acquire paraphrases that do notappear in a given corpus.4 Expanding Paraphrase LexiconsTo what extent can our LEXVAR method expand agiven paraphrase lexicon?
We examined this, takingEnglish as a target language and the bilingual pivot-ing method as the means of acquiring SSeed.4.1 Seed Paraphrase PairsWe conducted experiments on the following two cor-pora configurations.Europarl setting: The English?French version ofthe Europarl Parallel Corpus3comprising2.0 M sentence pairs (55.7 M words in Englishand 61.9 M words in French) was used as abilingual corpus.
Its English side and the 2011?2013 editions of News Crawl corpora4com-prising 52.0 M sentences (1.20 B words) wereused as a monolingual corpus.NTCIR setting: The Japanese?English PatentTranslation data5comprising 3.2 M sentencepairs (107 M words in English and 116 Mmorphemes in Japanese) was used as a bilin-gual parallel corpus, while its English side andthe 39.9 M sentences (1.36 B words) from3http://statmt.org/europarl/, release 74http://statmt.org/wmt14/translation-task.html5http://ntcir.nii.ac.jp/PatentMT-2/the 2006?2007 chapters of NTCIR unalignedpatent documents were used as a monolingualcorpus.For learning curve experiments, several sizes ofbilingual sub-corpora were created by sub-samplingsentence pairs for both settings.The other language resources involved in this ex-periment are as follows.Phrase table learner: SyMGIZA++6was used forIBM2 alignment, then grow-diag-final phraseextraction and phrase table pruning were per-formed using toolkits in Moses7.Tokenizer: The tokenizer distributed with Moseswas used for both English and French texts.
ForJapanese data, MeCab8was used.Stoplists: To perform several types of filtering pro-posed by Fujita et al (2012), we used the sto-plists available on the Web9: 571 English and463 French words.
For Japanese, we manuallylisted 160 morphemes.4.2 Paraphrase PatternsParaphrase patterns were learned from the set ofseed paraphrase pairs.
Figure 2 shows the numbersof the acquired paraphrase patterns and the percent-ages of paraphrase pairs in the seed lexicon, SSeed,covered by the patterns.As illustrated by example (4), LEXVAR learnsmore general paraphrase patterns than IDENT .
Ap-plied to another seed paraphrase pair (11a), IDENTwill generate another pattern (11b), but LEXVARwill not: the corresponding (4c) is already learned.
(11) a. development of tourism?
developing tourismb.
development of X ?
developing XOn the other hand, LEXVAR also learns patternsfrom seed paraphrase pairs that IDENT ignores, e.g.,(6) and (9a).
Consequently, a wider range of seedparaphrases were involved in learning patterns andmore patterns were acquired.4.3 New Paraphrase PairsFinally, new paraphrases were acquired from themonolingual data.
At this time, only single words6http://psi.amu.edu.pl/en/index.php?title=SyMGIZA7http://statmt.org/moses/, RELEASE-2.1.18https://code.google.com/p/mecab/, version 0.9969http://members.unine.ch/jacques.savoy/clef/635102103104105106106 107 108# of paraphrasepatterns# of words in the English side of bilingual corpusNTCIR: LEXVARNTCIR: IDENTEuroparl: LEXVAREuroparl: IDENT010203040506070106 107 108Ratioof seedparaphrasescovered by patterns[%]# of words in the English side of bilingual corpusNTCIR: LEXVARNTCIR: IDENTEuroparl: LEXVAREuroparl: IDENTFigure 2: Statistics for the acquired paraphrase patterns: number and coverage against SSeed.103104105106107108106 107 108# of paraphrasepairs# of words in the English side of bilingual corpusEuroparlSLVSIDSSeed63.8M26.8M0.97M104105106107108109106 107 108# of paraphrasepairs# of words in the English side of bilingual corpusNTCIRSLVSIDSSeed137.6M53.0M1.37MFigure 3: Number of acquired paraphrase pairs (left: Europarl, right: NTCIR).were regarded as potential slot-fillers for the pat-terns.
Recall that SLVand SIDare the sets ofparaphrases generated by LEXVAR and IDENT , re-spectively, and SLV?
SID.
Pairs that appeared inSSeedand those used in completely dissimilar con-texts were excluded from both SIDand SLV.Figure 3 demonstrates that, irrespective of the sizeof the bilingual corpus, LEXVAR yielded far more(relative) coverage of paraphrase pairs SLVthannot only SSeedbut also SID.
When the full bilin-gual corpora were used, SLVcontained 63.8 M and137.6 M paraphrase pairs in the two respective set-tings, while SIDcontained only 26.8 M and 53.0 Mpairs.
The seed set SSeedcan be pooled with SLV;thus, LEXVAR expanded SSeedby approximately67 and 101 times in the two respective settings.Figure 4 illustrates the ratio of the expanded partsof the paraphrase lexicons SLVand SIDagainstthe seed set SSeed.
The ratio of SLVagainst SSeedranged over 41?109 and 100?205 in the two respec-tive settings.
This figure also emphasizes the visibleadvantage of SLVover SID: 84%?208% and 139%?159% more coverage.04080120160200240106 107 108Ratioof paraphrasepairsagainst SSeed# of words in the English side of bilingual corpusNTCIR: SLVNTCIR: SIDEuroparl: SLVEuroparl: SID2051004110966Figure 4: Ratio of SLVand SIDto SSeed.We expected that the more the bilingual data thereare, the lower the leverage ratio is, because whena larger bilingual corpus is used, more seed para-phrases can be acquired, and the relative size of themonolingual data compared to the bilingual is lower.While the leverage ratio in the NTCIR setting fol-lows this, the ratio in the Europarl setting does not:it peaks at approximately the middle of the scale.
Wefound that from a very small bilingual corpus, we donot necessarily obtain seed paraphrases that exhibit636the generality exploited by LEXVAR and IDENT .
Inthis case, the leverage ratio cannot be extremely highdespite the large difference in the corpora sizes.LEXVAR also largely contributed to discoveringparaphrases for phrases that were not paraphrasedusing only SSeedand SID.
The ratio of the numbersof unique left-hand side phrases in SLVto those inSSeedranged over 65?147 and 92?415 in the tworespective settings, gaining 76%?210% and 145%?175% more coverage than SID.5 Quality AssessmentThe quality of the created paraphrase lexicons wasmanually evaluated through a paraphrase substitu-tion test: we generated pairs of paraphrase sentencesusing the paraphrase lexicons and asked human eval-uators to assess their quality.5.1 Criteria and ProcedureGenerating paraphrased sentences by substitutingwords and phrases involves two different tasks:generating new sentences and ensuring that themeaning is preserved.
It is therefore straightfor-ward to separately evaluate the grammaticality andmeaning equivalence of each paraphrased sentence(Callison-Burch, 2008).Grammaticality: whether the paraphrased sen-tence is grammaticalMeaning equivalence: whether the meaning of theoriginal sentence is properly preserved by theparaphrased sentenceWe adopted the detailed criteria and procedure de-scribed in (Fujita, 2013), as they resulted in a rea-sonably high inter-evaluator agreement ratio.
Theevaluation protocol is characterized by the followingthree features introduced for reducing human laborand making results consistent.Unit-wise: Several paraphrase examples for thesame source are packaged into an example unitand provided at the same time.Two-phased: Evaluators are first asked to assessonly the grammaticality of each paraphrasedsentence without seeing the original sentence.Then, by comparing each pair of original andparaphrased sentences, they assess to what ex-tent the paraphrased sentence retains the mean-ing of its counterpart.Classification-based: Evaluators are asked to clas-sify each example into one of the predeter-mined categories, guided by the decision treesrespectively designed for evaluating grammati-cality and meaning equivalence.5.2 DataWe used news sentences as in (Callison-Burch,2008; Fujita et al, 2012): the English sentencesfrom WMT 2011?2013 ?newstest?
data (9,000unique sentences).
To reduce the human labor forthe evaluation, they were restricted to those withmoderate length: 10?30 words, which we expectedto provide sufficient but succinct context of the sub-stituted phrases.
5,850 sentences were retained.By substituting phrases in the above sentences us-ing the paraphrase lexicons SSeedand SLVin theEuroparl setting, 88,555 example units comprising1,013,511 paraphrases were generated.
For each ex-ample unit, 3-best paraphrases were then selectedby a 5-gram language model trained on the mono-lingual data in the Europarl setting with modifiedKneser?Ney smoothing using KenLM10.
Finally,from 31,149 units that contained at least three para-phrases, we randomly sampled 200 example unitsfor 200 unique left-hand side phrases.5.3 ResultsWe collected evaluations from three native Englishspeakers.
Table 3 summarizes the inter-evaluatoragreement ratio, Cohen?s ?
(Cohen, 1960).
Thevalues for a coarse-grained binary decision11were?substantial?
for grammaticality and ?moderate?
formeaning equivalence (Landis and Koch, 1977).The quality of the examined paraphrase lexiconsis measured by the precision of the evaluated ex-amples: an example was regarded as correct if andonly if a majority of evaluators (two or three in ourcase) assigned a label corresponding to the posi-tive class in the binary decision.
Table 4 summa-rizes the results.
Despite the low chance of be-ing the 3-best candidates, thanks to various filters,10https://kheafield.com/code/kenlm/11We regarded ?Perfect?
and ?Awkward?
for grammatical-ity, and ?Equivalent?
and either of three categories of slightdifferences ?Missing Info.,?
?Additional Info.,?
and ?IgnorableChange?
for meaning equivalence as positive.
This is consistentwith (Callison-Burch, 2008).637Criterion Fine-grained Coarse-grainedGrammar 0.51 - 0.56 0.64 - 0.79Meaning 0.27 - 0.35 0.48 - 0.53Table 3: Cohen?s ?
of pairwise agreement.Lexicon n Grammar Meaning BothSSeed66 0.85 0.91 0.76SID(?SLV) 339 0.84 0.78 0.66SLV534 0.74 0.78 0.59Total 600 0.75 0.79 0.61Table 4: Precision of paraphrase substitution.paraphrases drawn from SSeedwere of substantiallyhigh quality.
Compared to SSeed, paraphrases sam-pled from SLVhave relatively low precision in bothgrammaticality and meaning equivalence.
However,these scores are reasonably high, considering that nouse is made of rich language-specific resources12.However, more grammatical errors occurred thanwith SSeedand SID.
A manual error analysis re-vealed that the majority of these errors were causedby the differences of syntactic categories betweenphrases, e.g., (12).
(12) The safety issue was considered sufficiently( ?
sufficient consideration) serious for allaffected parties to be informed.Differences of grammatical number and determinerswere the other major error sources.
(13) Federal Security Service now spread a bignetwork of fake sites and there are tons ofpotential buyers ( ?
a potential buyer) ofmilitary weapons.These types of pairs originally existed in SSeedbut were amplified by LEXVAR.
Ganitkevitch andCallison-Burch (2014) stated that morphologicalvariants of the same word might be desirable de-pending on the downstream task.
For instance,they could be useful for paraphrase recognition tasksincluding question answering and multi-documentsummarization.
As they are morphological variants12Although we cannot make a direct comparison owing tothe differences of data and human evaluators, for reference,Callison-Burch (2008) achieved 0.68, 0.61, and 0.55 preci-sion for grammaticality, meaning equivalence, and both, re-spectively, by introducing parser-oriented syntactic constraintsin bilingual pivoting.rather than genuine paraphrases, substituting themin a given context often degrades grammaticality.6 ConclusionWe proposed a method for expanding given para-phrase lexicons by first inducing paraphrase patternsand then searching monolingual corpora with thesepatterns for new paraphrase pairs.
To the best of ourknowledge, this is the first attempt to exploit varioustypes of lexical variants for acquiring paraphrasesin a completely empirical way.
Our method re-quires minimal language-dependent resources, i.e.,stoplists and tokenizers, other than raw corpora.
Wedemonstrated the quantitative impact of our methodand confirmed the potential quality of the expandedparaphrase lexicon.Our future work is four-fold.
(i) Paraphrase lexi-cons created by different methods and sources havedifferent properties.
Designing an overall model toharmonize such heterogeneous lexicons is an impor-tant issue.
(ii) We aim to investigate an extensivecollection of corpora: there are far more corporathan those we used in this experiment.
We are alsointerested in expanding paraphrase lexicons createdby a method other than bilingual pivoting; for in-stance, those extracted from a Web-harvested mono-lingual comparable corpus (Hashimoto et al, 2011;Yan et al, 2013).
(iii) We will apply our methodto various languages for demonstrating its applica-bility, extending it for a wider range of lexical vari-ants depending on the targeted language.
(iv) Para-phrases are the fundamental linguistic phenomenathat affect a wide range of NLP tasks.
We are there-fore interested in determining to what extent ourparaphrase lexicons can improve the performance ofapplication tasks such as machine translation, textsummarization, and text simplification.AcknowledgmentsWe are deeply grateful to Eiichiro Sumita, MasaoUtiyama, Taro Watanabe, Kentaro Torisawa, andanonymous reviewers for their valuable commentson the earlier version of this paper.
This work waspartly supported by JSPS Postdoctoral Fellowshipfor Research Abroad (FYs 2011?2012) and JSPSKAKENHI Grant-in-Aid for Young Scientists (B)25730139.638ReferencesIon Androutsopoulos and Prodromos Malakasiotis.2010.
A survey of paraphrasing and textual entailmentmethods.
Journal of Artificial Intelligence Research,38:135?187.Colin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In Proceed-ings of the 43rd Annual Meeting of the Association forComputational Linguistics (ACL), pages 597?604.Regina Barzilay and Kathleen R. McKeown.
2001.
Ex-tracting paraphrases from a parallel corpus.
In Pro-ceedings of the 39th Annual Meeting of the Associationfor Computational Linguistics (ACL), pages 50?57.Regina Barzilay and Lillian Lee.
2002.
Bootstrap-ping lexical choice via multiple-sequence alignment.In Proceedings of the 2002 Conference on EmpiricalMethods in Natural Language Processing (EMNLP),pages 164?171.Regina Barzilay and Noemie Elhadad.
2003.
Sen-tence alignment for monolingual comparable corpora.In Proceedings of the 2003 Conference on EmpiricalMethods in Natural Language Processing (EMNLP),pages 25?32.Rahul Bhagat and Deepak Ravichandran.
2008.
Largescale acquisition of paraphrases for learning surfacepatterns.
In Proceedings of the 46th Annual Meeting ofthe Association for Computational Linguistics (ACL),pages 161?170.Chris Callison-Burch.
2008.
Syntactic constraints onparaphrases extracted from parallel corpora.
In Pro-ceedings of the 2008 Conference on Empirical Meth-ods in Natural Language Processing (EMNLP), pages196?205.Tsz Ping Chan, Chris Callison-Burch, and Benjamin VanDurme.
2011.
Reranking bilingually extracted para-phrases using monolingual distributional similarity.
InProceedings of the Workshop on Geometrical Modelsof Natual Language Semantics (GEMS), pages 33?42.David L. Chen and William B. Dolan.
2011.
Collectinghighly parallel data for paraphrase evaluation.
In Pro-ceedings of the 49th Annual Meeting of the Associationfor Computational Linguistics (ACL), pages 190?200.Jacob Cohen.
1960.
A coefficient of agreement for nom-inal scales.
Educational and Psychological Measure-ment, 20(1):37?46.Stijn De Saeger, Kentaro Torisawa, Masaaki Tsuchida,Jun?ichi Kazama, Chikara Hashimoto, Ichiro Yamada,Jong Hoon Oh, Istv?an Varga, and Yulan Yan.
2011.Relation acquisition using word classes and partialpatterns.
In Proceedings of the 2011 Conference onEmpirical Methods in Natural Language Processing(EMNLP), pages 825?835.Michael Denkowski and Alon Lavie.
2010.
METEOR-NEXT and the METEOR paraphrase tables: Improvedevaluation support for five target languages.
In Pro-ceedings of the 5th Workshop on Statistical MachineTranslation (WMT) and MetricsMATR, pages 339?342.Bill Dolan, Chris Quirk, and Chris Brockett.
2004.Unsupervised construction of large paraphrase cor-pora: Exploiting massively parallel news sources.In Proceedings of the 20th International Conferenceon Computational Linguistics (COLING), pages 350?356.Jinhua Du, Jie Jiang, and Andy Way.
2010.
Facilitatingtranslation using source language paraphrase lattices.In Proceedings of the 2010 Conference on EmpiricalMethods in Natural Language Processing (EMNLP),pages 420?429.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
The MIT Press.Atsushi Fujita, Shuhei Kato, Naoki Kato, and SatoshiSato.
2007.
A compositional approach toward dy-namic phrasal thesaurus.
In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Para-phrasing (WTEP), pages 151?158.Atsushi Fujita, Pierre Isabelle, and Roland Kuhn.
2012.Enlarging paraphrase collections through generaliza-tion and instantiation.
In Proceedings of the 2012 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning (EMNLP-CoNLL), pages 631?642.Atsushi Fujita.
2013.
A consideration on the methodol-ogy for evaluating large-scale paraphrase lexicons.
InInformation Processing Society of Japan SIG Notes,NL-214-21, pages 1?8.Juri Ganitkevitch, Chris Callison-Burch, CourtneyNapoles, and Benjamin Van Durme.
2011.
Learn-ing sentential paraphrases from bilingual parallel cor-pora for text-to-text generation.
In Proceedings ofthe 2011 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP), pages 1168?1179.Juri Ganitkevitch, Benjamin Van Durme, and ChrisCallison-Burch.
2013.
PPDB: The paraphrasedatabase.
In Proceedings of Human Language Tech-nologies: The 2013 Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics (NAACL-HLT), pages 758?764.Juri Ganitkevitch and Chris Callison-Burch.
2014.
Themultilingual paraphrase database.
In Proceedings ofthe 9th International Conference on Language Re-sources and Evaluation (LREC), pages 4276?4282.
?Eric Gaussier.
1999.
Unsupervised learning of deriva-tional morphology from inflectional lexicons.
In Pro-ceedings of the Workshop on Unsupervised Learningin Natural Language Processing, pages 24?30.639Nizar Habash and Bonnie Jean Dorr.
2003.
A catego-rial variation database for English.
In Proceedingsof the 2003 Human Language Technology Conferenceand the North American Chapter of the Association forComputational Linguistics (HLT-NAACL), pages 96?102.Masato Hagiwara, Yasuhiro Ogawa, and KatsuhikoToyama.
2006.
Selection of effective contextual in-formation for automatic synonym acquisition.
In Pro-ceedings of the 44th Annual Meeting of the Associ-ation for Computational Linguistics and the 21st In-ternational Conference on Computational Linguistics(COLING-ACL), pages 353?360.Zellig Harris.
1954.
Distributional structure.
Word,10(23):146?162.Zellig Harris.
1957.
Co-occurrence and transformationin linguistic structure.
Language, 33(3):283?340.Chikara Hashimoto, Kentaro Torisawa, Stijn De Saeger,Jun?ichi Kazama, and Sadao Kurohashi.
2011.
Ex-tracting paraphrases from definition sentences on theWeb.
In Proceedings of the 49th Annual Meeting ofthe Association for Computational Linguistics (ACL),pages 1087?1097.Christian Jacquemin.
1999.
Syntagmatic and paradig-matic representations of term variation.
In Proceed-ings of the 37th Annual Meeting of the Association forComputational Linguistics (ACL), pages 341?348.Stanley Kok and Chris Brockett.
2010.
Hitting the rightparaphrases in good time.
In Proceedings of HumanLanguage Technologies: The 2010 Annual Conferenceof the North American Chapter of the Association forComputational Linguistics (NAACL-HLT), pages 145?153.J.
Richard Landis and Gary G. Koch.
1977.
The mea-surement of observer agreement for categorical data.Biometrics, 33(1):159?174.Dekang Lin and Patrick Pantel.
2001.
Discovery of infer-ence rules for question answering.
Natural LanguageEngineering, 7(4):343?360.Nitin Madnani and Bonnie J. Dorr.
2010.
Gener-ating phrasal and sentential paraphrases: A surveyof data-driven methods.
Computational Linguistics,36(3):341?387.Yuval Marton.
2013.
Distributional phrasal paraphrasegeneration for statistical machine translation.
ACMTransactions on Intelligent Systems and Technology,4(3).Aur?elien Max.
2010.
Example-based paraphrasing forimproved phrase-based statistical machine translation.In Proceedings of the 2010 Conference on EmpiricalMethods in Natural Language Processing (EMNLP),pages 656?666.Igor Mel?
?cuk and Alain Polgu`ere.
1987.
A formal lexi-con in Meaning-Text Theory (or how to do lexica withwords).
Computational Linguistics, 13(3-4):261?275.Marius Pas?ca and P?eter Dienes.
2005.
Aligning needlesin a haystack: Paraphrase acquisition across the Web.In Proceedings of the 2nd International Joint Con-ference on Natural Language Processing (IJCNLP),pages 119?130.Bo Pang, Kevin Knight, and Daniel Marcu.
2003.Syntax-based alignment of multiple translations: Ex-tracting paraphrases and generating new sentences.
InProceedings of the 2003 Human Language Technol-ogy Conference and the North American Chapter ofthe Association for Computational Linguistics (HLT-NAACL), pages 102?109.Yusuke Shinyama, Satoshi Sekine, Kiyoshi Sudo, andRalph Grishman.
2002.
Automatic paraphrase acqui-sition from news articles.
In Proceedings of the 2002Human Language Technology Conference (HLT).Idan Szpektor, Hristo Tanev, Ido Dagan, and BonaventuraCoppola.
2004.
Scaling Web-based acquisition of en-tailment relations.
In Proceedings of the 2004 Confer-ence on Empirical Methods in Natural Language Pro-cessing (EMNLP), pages 41?48.Sander Wubben, Antal van den Bosch, Emiel Krahmer,and Erwin Marsi.
2009.
Clustering and matchingheadlines for automatic paraphrase acquisition.
InProceedings of the 12th European Workshop on Nat-ural Language Generation (EWNLG), pages 122?125.Yulan Yan, Chikara Hashimoto, Kentaro Torisawa, TakaoKawai, Jun?ichi Kazama, and Stijn De Saeger.
2013.Minimally supervised method for multilingual para-phrase extraction from definition sentences on the web.In Proceedings of Human Language Technologies:The 2013 Annual Conference of the North AmericanChapter of the Association for Computational Linguis-tics (NAACL-HLT), pages 63?73.Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.2009.
Extracting paraphrase patterns from bilin-gual parallel corpora.
Natural Language Engineering,15(4):503?526.640
