Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 777?785,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsThe viability of web-derived polarity lexiconsLeonid Velikovich Sasha Blair-Goldensohn Kerry Hannan Ryan McDonaldGoogle Inc., New York, NY{leonidv|sasha|khannan|ryanmcd}@google.comAbstractWe examine the viability of building largepolarity lexicons semi-automatically from theweb.
We begin by describing a graph propa-gation framework inspired by previous workon constructing polarity lexicons from lexi-cal graphs (Kim and Hovy, 2004; Hu andLiu, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al, 2008; Rao and Ravichan-dran, 2009).
We then apply this techniqueto build an English lexicon that is signifi-cantly larger than those previously studied.Crucially, this web-derived lexicon does notrequire WordNet, part-of-speech taggers, orother language-dependent resources typical ofsentiment analysis systems.
As a result, thelexicon is not limited to specific word classes?
e.g., adjectives that occur in WordNet ?and in fact contains slang, misspellings, multi-word expressions, etc.
We evaluate a lexiconderived from English documents, both qual-itatively and quantitatively, and show that itprovides superior performance to previouslystudied lexicons, including one derived fromWordNet.1 IntroductionPolarity lexicons are large lists of phrases that en-code the polarity of each phrase within it ?
eitherpositive or negative ?
often with some score rep-resenting the magnitude of the polarity (Hatzivas-siloglou and McKeown, 1997; Wiebe, 2000; Turney,2002).
Though classifiers built with machine learn-ing algorithms have become commonplace in thesentiment analysis literature, e.g., Pang et al (2002),the core of many academic and commercial senti-ment analysis systems remains the polarity lexicon,which can be constructed manually (Das and Chen,2007), through heuristics (Kim and Hovy, 2004;Esuli and Sabastiani, 2009) or using machine learn-ing (Turney, 2002; Rao and Ravichandran, 2009).Often lexicons are combined with machine learningfor improved results (Wilson et al, 2005).
The per-vasiveness and sustained use of lexicons can be as-cribed to a number of reasons, including their inter-pretability in large-scale systems as well as the gran-ularity of their analysis.In this work we investigate the viability of polar-ity lexicons that are derived solely from unlabeledweb documents.
We propose a method based ongraph propagation algorithms inspired by previouswork on constructing polarity lexicons from lexicalgraphs (Kim and Hovy, 2004; Hu and Liu, 2004;Esuli and Sabastiani, 2009; Blair-Goldensohn et al,2008; Rao and Ravichandran, 2009).
Whereas pastefforts have used linguistic resources ?
e.g., Word-Net ?
to construct the lexical graph over which prop-agation runs, our lexicons are constructed using agraph built from co-occurrence statistics from theentire web.
Thus, the method we investigate canbe seen as a combination of methods for propagat-ing sentiment across lexical graphs and methods forbuilding sentiment lexicons based on distributionalcharacteristics of phrases in raw data (Turney, 2002).The advantage of breaking the dependence on Word-Net (or related resources like thesauri (Mohammadet al, 2009)) is that it allows the lexicons to includenon-standard entries, most notably spelling mistakesand variations, slang, and multiword expressions.The primary goal of our study is to understand thecharacteristics and practical usefulness of such a lex-icon.
Towards this end, we provide both a qualitativeand quantitative analysis for a web-derived English777lexicon relative to two previously published lexicons?
the lexicon used in Wilson et al (2005) and thelexicon used in Blair-Goldensohn et al (2008).
Ourexperiments show that a web-derived lexicon is notonly significantly larger, but has improved accuracyon a sentence polarity classification task, which isan important problem in many sentiment analysisapplications, including sentiment aggregation andsummarization (Hu and Liu, 2004; Carenini et al,2006; Lerman et al, 2009).
These results hold trueboth when the lexicons are used in conjunction withstring matching to classify sentences, and when theyare included within a contextual classifier frame-work (Wilson et al, 2005).Extracting polarity lexicons from the web hasbeen investigated previously by Kaji and Kitsure-gawa (2007), who study the problem exclusively forJapanese.
In that work a set of positive/negative sen-tences are first extracted from the web using cuesfrom a syntactic parser as well as the documentstructure.
Adjectives phrases are then extracted fromthese sentences based on different statistics of theiroccurrence in the positive or negative set.
Our work,on the other hand, does not rely on syntactic parsersor restrict the set of candidate lexicon entries to spe-cific syntactic classes, i.e., adjective phrases.
As aresult, the lexicon built in our study is on a differentscale than that examined in Kaji and Kitsuregawa(2007).
Though this hypothesis is not tested here, italso makes our techniques more amenable to adap-tation for other languages.2 Constructing the LexiconIn this section we describe a method to construct po-larity lexicons using graph propagation over a phrasesimilarity graph constructed from the web.2.1 Graph Propagation AlgorithmWe construct our lexicon using graph propagationtechniques, which have previously been investigatedin the construction of polarity lexicons (Kim andHovy, 2004; Hu and Liu, 2004; Esuli and Sabas-tiani, 2009; Blair-Goldensohn et al, 2008; Rao andRavichandran, 2009).
We assume as input an undi-rected edge weighted graph G = (V,E), wherewij ?
[0, 1] is the weight of edge (vi, vj) ?
E. Thenode set V is the set of candidate phrases for inclu-sion in a sentiment lexicon.
In practice,G should en-code semantic similarities between two nodes, e.g.,for sentiment analysis one would hope that wij >wik if vi=good, vj=great and vk=bad.
We also as-sume as input two sets of seed phrases, denoted Pfor the positive seed set and N for the negative seedset.
The common property among all graph propaga-tion algorithms is that they attempt to propagate in-formation from the seed sets to the rest of the graphthrough its edges.
This can be done using machinelearning, graph algorithms or more heuristic means.The specific algorithm used in this study is givenin Figure 1, which is distinct from common graphpropagation algorithms, e.g., label propagation (seeSection 2.3).
The output is a polarity vector pol ?R|V | such that poli is the polarity score for the ithcandidate phrase (or the ith node inG).
In particular,we desire pol to have the following semantics:poli =????
?> 0 ith phrase has positive polarity< 0 ith phrase has negative polarity= 0 ith phrase has no sentimentIntuitively, the algorithm works by computing botha positive and a negative polarity magnitude foreach node in the graph, call them pol+i and pol-i.These values are equal to the sum over the maxweighted path from every seed word (either posi-tive or negative) to node vi.
Phrases that are con-nected to multiple positive seed words through shortyet highly weighted paths will receive high positivevalues.
The final polarity of a phrase is then set topoli = pol+i ?
?pol-i, where ?
a constant meant toaccount for the difference in overall mass of positiveand negative flow in the graph.
Thus, after the al-gorithm is run, if a phrase has a higher positive thannegative polarity score, then its final polarity will bepositive, and negative otherwise.There are some implementation details worthpointing out.
First, the algorithm in Figure 1 is writ-ten in an iterative framework, where on each itera-tion, paths of increasing lengths are considered.
Theinput variable T controls the max path length con-sidered by the algorithm.
This can be set to be asmall value in practice, since the multiplicative pathweights result in long paths rarely contributing topolarity scores.
Second, the parameter ?
is a thresh-old that defines the minimum polarity magnitude a778Input: G = (V,E), wij ?
[0, 1],P , N , ?
?
R, T ?
NOutput: pol ?
R|V |Initialize: poli,pol+i ,pol-i = 0, for all ipol+i = 1.0 for all vi ?
P andpol-i = 1.0 for all vi ?
N1.
set ?ij = 0 for all i, j2.
for vi ?
P3.
F = {vi}4. for t : 1 .
.
.
T5.
for (vk, vj) ?
E such that vk ?
F6.
?ij = max{?ij , ?ik ?
wkj}F = F ?
{vj}7. for vj ?
V8.
pol+j =?vi?P?ij9.
Repeat steps 1-8 using N to compute pol-10.
?
=?i pol+i /?i pol-i11.
poli = pol+i ?
?pol-i, for all i12.
if |poli| < ?
then poli = 0.0, for all iFigure 1: Graph Propagation Algorithm.phrase must have to be included in the lexicon.
BothT and ?
were tuned on held-out data.To construct the final lexicon, the remainingnodes ?
those with polarity scores above ?
?
are ex-tracted and assigned their corresponding polarity.2.2 Building a Phrase Graph from the WebGraph propagation algorithms rely on the existenceof graphs that encode meaningful relationships be-tween candidate nodes.
Past studies on building po-larity lexicons have used linguistic resources likeWordNet to define the graph through synonym andantonym relations (Kim and Hovy, 2004; Esuli andSabastiani, 2009; Blair-Goldensohn et al, 2008;Rao and Ravichandran, 2009).
The goal of this studyis to examine the size and quality of polarity lexi-cons when the graph is induced automatically fromdocuments on the web.Constructing a graph from web-computed lexi-cal co-occurrence statistics is a difficult challengein and of itself and the research and implementa-tion hurdles that arise are beyond the scope of thiswork (Alfonseca et al, 2009; Pantel et al, 2009).For this study, we used an English graph where thenode set V was based on all n-grams up to length10 extracted from 4 billion web pages.
This list wasfiltered to 20 million candidate phrases using a num-ber of heuristics including frequency and mutual in-formation of word boundaries.
A context vector foreach candidate phrase was then constructed basedon a window of size six aggregated over all men-tions of the phrase in the 4 billion documents.
Theedge set E was constructed by first, for each po-tential edge (vi, vj), computing the cosine similar-ity value between context vectors.
All edges (vi, vj)were then discarded if they were not one of the 25highest weighted edges adjacent to either node vi orvj .
This serves to both reduce the size of the graphand to eliminate many spurious edges for frequentlyoccurring phrases, while still keeping the graph rela-tively connected.
The weight of the remaining edgeswas set to the corresponding cosine similarity value.Since this graph encodes co-occurrences over alarge, but local context window, it can be noisy forour purposes.
In particular, we might see a numberof edges between positive and negative sentimentwords as well as sentiment words and non-sentimentwords, e.g., sentiment adjectives and all other adjec-tives that are distributionally similar.
Larger win-dows theoretically alleviate this problem as they en-code semantic as opposed to syntactic similarities.We note, however, that the graph propagation al-gorithm described above calculates the sentiment ofeach phrase as the aggregate of all the best paths toseed words.
Thus, even if some local edges are erro-neous in the graph, one hopes that, globally, positivephrases will be influenced more by paths from pos-itive seed words as opposed to negative seed words.Section 3, and indeed this paper, aims to measurewhether this is true or not.2.3 Why Not Label Propagation?Previous studies on constructing polarity lexiconsfrom lexical graphs, e.g., Rao and Ravichandran(2009), have used the label propagation algorithm,which takes the form in Figure 2 (Zhu and Ghahra-mani, 2002).
Label propagation is an iterative algo-rithm where each node takes on the weighted aver-age of its neighbour?s values from the previous iter-ation.
The result is that nodes with many paths toseeds get high polarities due to the influence fromtheir neighbours.
The label propagation algorithmis known to have many desirable properties includ-ing convergence, a well defined objective function779Input: G = (V,E), wij ?
[0, 1], P , NOutput: pol ?
R|V |Initialize: poli = 1.0 for all vi ?
P andpoli = ?1.0 for all vi ?
N andpoli = 0.0 ?vi /?
P ?N1.
for : t .. T2.
poli =P(vi,vj)?Ewij?poljP(vi,vj)wij, ?vi ?
V3.
reset poli = 1.0 ?vi ?
Preset poli = ?1.0 ?vi ?
NFigure 2: The label propagation algorithm (Zhu andGhahramani, 2002).
(minimize squared error between values of adjacentnodes), and an equivalence to computing randomwalks through graphs.The primary difference between standard labelpropagation and the graph propagation algorithmgiven in Section 2.1, is that a node with multiplepaths to a seed will be influenced by all these pathsin the label propagation algorithm, whereas only thesingle path from a seed will influence the polarityof a node in our proposed propagation algorithm ?namely the path with highest weight.
The intuitionbehind label propagation seems justified.
That is, ifa node has multiple paths to a seed, it should be re-flected in a higher score.
This is certainly true whenthe graph is of high quality and all paths trustwor-thy.
However, in a graph constructed from web co-occurrence statistics, this is rarely the case.Our graph consisted of many dense subgraphs,each representing some semantic entity class, suchas actors, authors, tech companies, etc.
Problemsarose when polarity flowed into these dense sub-graphs with the label propagation algorithm.
Ulti-mately, this flow would amplify since the dense sub-graph provided exponentially many paths from eachnode to the source of the flow, which caused a re-inforcement effect.
As a result, the lexicon wouldconsist of large groups of actor names, companies,etc.
This also led to convergence issues since thepolarity is divided proportional to the size of thedense subgraph.
Additionally, negative phrases inthe graph appeared to be in more densely connectedregions, which resulted in the final lexicons beinghighly skewed towards negative entries due to theinfluence of multiple paths to seed words.For best path propagation, these problems wereless acute as each node in the dense subgraph wouldonly get the polarity a single time from each seed,which is decayed by the fact that edge weights aresmaller than 1.
Furthermore, the fact that edgeweights are less than 1 results in most long pathshaving weights near zero, which in turn results infast convergence.3 Lexicon EvaluationWe ran the best path graph propagation algorithmover a graph constructed from the web using manu-ally constructed positive and negative seed sets of187 and 192 words in size, respectively.
Thesewords were generated by a set of five humans andmany are morphological variants of the same root,e.g., excel/excels/excelled.
The algorithm produceda lexicon that contained 178,104 entries.
Dependingon the threshold ?
(see Figure 1), this lexicon couldbe larger or smaller.
As stated earlier, our selectionof ?
and all hyperparameters was based on manualinspection of the resulting lexicons and performanceon held-out data.In the rest of this section we investigate the prop-erties of this lexicon to understand both its generalcharacteristics as well as its possible utility in sen-timent applications.
To this end we compare threedifferent lexicons:1.
Wilson et al: Described in Wilson et al(2005).
Lexicon constructed by combining thelexicon built in Riloff and Wiebe (2003) withother sources1.
Entries are are coarsely rated?
strong/weak positive/negative ?
which weweighted as 1.0, 0.5, -0.5, and -1.0 for our ex-periments.2.
WordNet LP: Described in Blair-Goldensohnet al (2008).
Constructed using label propaga-tion over a graph derived from WordNet syn-onym and antonym links.
Note that label prop-agation is not prone to the kinds of errors dis-cussed in Section 2.3 since the lexical graph isderived from a high quality source.3.
Web GP: The web-derived lexicon describedin Section 2.1 and Section 2.2.1See http://www.cs.pitt.edu/mpqa/7803.1 Qualitative EvaluationTable 1 breaks down the lexicon by the number ofpositive and negative entries of each lexicon, whichclearly shows that the lexicon derived from the webis more than an order of magnitude larger than pre-viously constructed lexicons.2 This in and of it-self is not much of an achievement if the additionalphrases are of poor quality.
However, in Section 3.2we present an empirical evaluation that suggests thatthese terms provide both additional and useful in-formation.
Table 1 also shows the recall of the eachlexicon relative to the other.
Whereas the Wilsonet al (2005) and WordNet lexicon have a recall ofonly 3% relative to the web lexicon, the web lexi-con has a recall of 48% and 70% relative to the twoother lexicons, indicating that it contains a signifi-cant amount of information from the other lexicons.However, this overlap is still small, suggesting thata combination of all the lexicons could provide thebest performance.
In Section 3.2 we investigate thisempirically through a meta classification system.Table 2 shows the distribution of phrases in theweb-derived lexicon relative to the number of to-kens in each phrase.
Here a token is simply definedby whitespace and punctuation, with punctuationcounting as a token, e.g., ?half-baked?
is counted as3 tokens.
For the most part, we see what one mightexpect, as the number of tokens increases, the num-ber of corresponding phrases in the lexicon also de-creases.
Longer phrases are less frequent and thuswill have both fewer and lower weighted edges toadjacent nodes in the graph.
There is a single phraseof length 9, which is ?motion to dismiss for failureto state a claim?.
In fact, the lexicon contains quitea number of legal and medical phrases.
This shouldnot be surprising, since in a graph induced from theweb, a phrase like ?cancer?
(or any disease) shouldbe distributionally similar to phrases like ?illness?,?sick?, and ?death?, which themselves will be simi-lar to standard sentiment phrases like ?bad?
and ?ter-rible?.
These terms are predominantly negative inthe lexicon representing the broad notion that legaland medical events are undesirable.2This also includes the web-derived lexicon of (Kaji and Kit-suregawa, 2007), which has 10K entries.
A recent study byMohammad et al (2009) generated lexicons from thesauri with76K entries.Phrase length 1 2 3# of phrases 37,449 108,631 27,822Phrase length 4 5 6 7 8 9# of phrases 3,489 598 71 29 4 1Table 2: Number of phrases by phrase length in lexiconbuilt from the web.Perhaps the most interesting characteristic of thelexicon is that the most frequent phrase length is 2and not 1.
The primary reason for this is an abun-dance of adjective phrases consisting of an adverband an adjective, such as ?more brittle?
and ?lessbrittle?.
Almost every adjective of length 1 is fre-quently combined in such a way on the web, so itnot surprising that we see many of these phrasesin the lexicon.
Ideally we would see an order onsuch phrases, e.g., ?more brittle?
has a larger neg-ative polarity than ?brittle?, which in turn has alarger negative polarity than ?less brittle?.
However,this is rarely the case and usually the adjective hasthe highest polarity magnitude.
Again, this is eas-ily explained.
These phrases are necessarily morecommon and will thus have more edges with largerweights in the graph and thus a greater chance of ac-cumulating a high sentiment score.
The prominenceof such phrases suggests that a more principled treat-ment of them should be investigated in the future.Finally, Table 3 presents a selection of phrasesfrom both the positive and negative lexicons cate-gorized into revealing verticals.
For both positiveand negative phrases we present typical examples ofphrases ?
usually adjectives ?
that one would expectto be in a sentiment lexicon.
These are phrases notincluded in the seed sets.
We also present multiwordphrases for both positive and negative cases, whichdisplays concretely the advantage of building lexi-cons from the web as opposed to using restricted lin-guistic resources such as WordNet.
Finally, we showtwo special cases.
The first is spelling variations(and mistakes) for positive phrases, which were farmore prominent than for negative phrases.
Many ofthese correspond to social media text where one ex-presses an increased level of sentiment by repeat-ing characters.
The second is vulgarity in negativephrases, which was far more prominent than for pos-itive phrases.
Some of these are clearly appropri-781Recall wrt other lexiconsAll Phrases Pos.
Phrases Neg.
Phrases Wilson et al WordNet LP Web GPWilson et al 7,628 2,718 4,910 100% 37% 2%WordNet LP 12,310 5,705 6,605 21% 100% 3%Web GP 178,104 90,337 87,767 70% 48% 100%Table 1: Lexicon statistics.
Wilson et al is the lexicon used in Wilson et al (2005), WordNet LP is the lexiconconstructed by Blair-Goldensohn et al (2008) that uses label propagation algorithms over a graph constructed throughWordNet, and Web GP is the web-derived lexicon from this study.POSITIVE PHRASES NEGATIVE PHRASESTypical Multiword expressions Spelling variations Typical Multiword expressions Vulgaritycute once in a life time loveable dirty run of the mill fucking stupidfabulous state - of - the - art nicee repulsive out of touch fucked upcuddly fail - safe operation niice crappy over the hill complete bullshitplucky just what the doctor ordered cooool sucky flash in the pan shittyravishing out of this world coooool subpar bumps in the road half assedspunky top of the line koool horrendous foaming at the mouth jackassenchanting melt in your mouth kewl miserable dime a dozen piece of shitprecious snug as a bug cozy lousy pie - in - the - sky son of a bitchcharming out of the box cosy abysmal sick to my stomach sonofabitchstupendous more good than bad sikk wretched pain in my ass sonuvabitchTable 3: Example positive and negative phrases from web lexicon.ate, e.g., ?shitty?, but some are clearly insults andoutbursts that are most likely included due to theirco-occurrence with angry texts.
There were also anumber of derogatory terms and racial slurs in thelexicon, again most of which received negative sen-timent due to their typical disparaging usage.3.2 Quantitative EvaluationTo determine the practical usefulness of a polaritylexicon derived from the web, we measured the per-formance of the lexicon on a sentence classifica-tion/ranking task.
The input is a set of sentences andthe output is a classification of the sentences as be-ing either positive, negative or neutral in sentiment.Additionally, the system outputs two rankings, thefirst a ranking of the sentence by positive polarityand the second a ranking of the sentence by negativepolarity.
Classifying sentences by their sentiment isa subtask of sentiment aggregation systems (Hu andLiu, 2004; Gamon et al, 2005).
Ranking sentencesby their polarity is a critical sub-task in extractivesentiment summarization (Carenini et al, 2006; Ler-man et al, 2009).To classify sentences as being positive, negativeor neutral, we used an augmented vote-flip algo-rithm (Choi and Cardie, 2009), which is given inFigure 3.
This intuition behind this algorithm is sim-ple.
The number of matched positive and negativephrases from the lexicon are counted and whicheverhas the most votes wins.
The algorithm flips the de-cision if the number of negations is odd.
Though thisalgorithm appears crude, it benefits from not relyingon threshold values for neutral classification, whichis difficult due to the fact that the polarity scores inthe three lexicons are not on the same scale.To rank sentences we defined the purity of a sen-tence X as the normalized sum of the sentimentscores for each phrase x in the sentence:purity(X) =?x?X polx?
+?x?X |polx|This is a normalized score in the range [?1, 1].
In-tuitively, sentences with many terms of the same po-larity will have purity scores at the extreme points ofthe range.
Before calculating purity, a simple nega-tion heuristic was implemented that reversed thesentiment scores of terms that were within the scopeof negations.
The term ?
helps to favor sentenceswith multiple phrase matches.
Purity is a commonmetric used for ranking sentences for inclusion insentiment summaries (Lerman et al, 2009).
Purityand negative purity were used to rank sentences asbeing positive and negative sentiment, respectively.The data used in our initial English-only experi-782Lexicon Classifier Contextual ClassifierPositive Negative Positive NegativeP R AP P R AP P R AP P R APWilson et al 56.4 61.8 60.8 58.1 39.0 59.7 74.5 70.3 76.2 80.7 70.1 81.2WordNet LP 50.9 61.7 62.0 54.9 36.4 59.7 72.0 72.5 75.7 78.0 69.8 79.3Web GP 57.7 65.1?
69.6?
60.3 42.9 68.5?
74.1 75.0?
79.9?
80.5 72.6?
82.9?Meta Classifier - - - - - - 76.6?
74.7 81.2?
81.8?
72.2 84.1?Table 4: Positive and negative precision (P), recall (R), and average precision (AP) for three lexicons using eitherlexical matching or contextual classification strategies.
?Web GP is statistically significantly better than Wilson et aland WordNet LP (p < 0.05).
?Meta Classifier is statistically significantly better than all other systems (p < 0.05).Input: Scored lexicon pol, negation list NG,input sentence XOutput: sentiment ?
{POS, NEG, NEU}1. set p, n, ng = 02. for x ?
X3.
if polx > 0 then p++4.
else if polx < 0 then n++5.
else if x ?
NG then ng++6.
flip = (ng % 2 == 1) //ng is odd7.
if (p > n & ?flip) ?
(n > p & flip)return POS8.
else if (p > n & flip) ?
(n > p & ?flip)return NEG19.
return NEUFigure 3: Vote-flip algorithm (Choi and Cardie, 2009).ments were a set of 554 consumer reviews describedin (McDonald et al, 2007).
Each review was sen-tence split and annotated by a human as being pos-itive, negative or neutral in sentiment.
This resultedin 3,916 sentences, with 1,525, 1,542 and 849 posi-tive, negative and neutral sentences, respectively.The first six columns of Table 4 shows: 1) the pos-itive/negative precision-recall of each lexicon-basedsystem where sentence classes were determined us-ing the vote-flip algorithm, and 2) the average preci-sion for each lexicon-based system where purity (ornegative purity) was used to rank sentences.
Boththe Wilson et al and WordNet LP lexicons performat a similar level, with the former slightly better, es-pecially in terms of precision.
The web-derived lex-icon, Web GP, outperforms the other two lexiconsacross the board, in particular when looking at av-erage precision, where the gains are near 10% ab-solute.
If we plot the precision-recall graphs usingpurity to classify sentences ?
as opposed to the vote-flip algorithm, which only provides an unweightedclassification ?
we can see that at almost all recalllevels the web-derived lexicon has superior preci-sion to the other lexicons (Figure 4).
Thus, eventhough the web-derived lexicon is constructed froma lexical graph that contains noise, the graph prop-agation algorithms appear to be fairly robust to thisnoise and are capable of producing large and accu-rate polarity lexicons.The second six columns of Table 4 shows the per-formance of each lexicon as the core of a contextualclassifier (Wilson et al, 2005).
A contextual classi-fier is a machine learned classifier that predicts thepolarity of a sentence using features of that sentenceand its context.
For our experiments, this was a max-imum entropy classifier trained and evaluated us-ing 10-fold cross-validation on the evaluation data.The features included in the classifier were the pu-rity score, the number of positive and negative lex-icon matches, and the number of negations in thesentence, as well as concatenations of these featureswithin the sentence and with the same features de-rived from the sentences in a window of size 1.For each sentence, the contextual classifier pre-dicted either a positive, negative or neutral classifi-cation based on the label with highest probability.Additionally, all sentences were placed in the posi-tive and negative sentence rankings by the probabil-ity the classifier assigned to the positive and negativeclasses, respectively.
Mirroring the results of Wil-son et al (2005), we see that contextual classifiersimprove results substantially over lexical matching.More interestingly, we see that the a contextual clas-sifier over the web-derived lexicons maintains theperformance edge over the other lexicons, thoughthe gap is smaller.
Figure 5 plots the precision-recallcurves for the positive and negative sentence rank-7830 0.2 0.4 0.6 0.8 1Recall0.40.50.60.70.80.91PrecisionWilson et alWordNet LPWeb GP0 0.2 0.4 0.6 0.8 1Recall0.40.50.60.70.80.91PrecisionWilson et alWordNet LPWeb GPFigure 4: Lexicon classifier precision/recall curves for positive (left) and negative (right) classes.0 0.2 0.4 0.6 0.8 1Recall0.40.50.60.70.80.91PrecisionWilson et al CCWordNet LP CCWeb GP CCMeta Classifier0 0.2 0.4 0.6 0.8 1Recall0.40.50.60.70.80.91PrecisionWilson et al CCWordNet LP CCWeb GP CCMeta ClassifierFigure 5: Contextual classifier precision/recall curves for positive (left) and negative (right) classesings, again showing that at almost every level of re-call, the web-derived lexicon has higher precision.For a final English experiment we built a meta-classification system that is identical to the contex-tual classifiers, except it is trained using features de-rived from all lexicons.
Results are shown in thelast row of Table 4 and precision-recall curves areshown in Figure 5.
Not surprisingly, this system hasthe best performance in terms of average precisionas it has access to the largest amount of information,though its performance is only slightly better thanthe contextual classifier for the web-derived lexicon.4 ConclusionsIn this paper we examined the viability of senti-ment lexicons learned semi-automatically from theweb, as opposed to those that rely on manual anno-tation and/or resources such as WordNet.
Our quali-tative experiments indicate that the web derived lex-icon can include a wide range of phrases that havenot been available to previous systems, most no-tably spelling variations, slang, vulgarity, and multi-word expressions.
Quantitatively, we observed thatthe web derived lexicon had superior performanceto previously published lexicons for English clas-sification.
Ultimately, a meta classifier that incor-porates features from all lexicons provides the bestperformance.
In the future we plan to investigate theconstruction of web-derived lexicons for languagesother than English, which is an active area of re-search (Mihalcea et al, 2007; Jijkoun and Hofmann,2009; Rao and Ravichandran, 2009).
The advantageof the web-derived lexicons studied here is that theydo not rely on language specific resources besidesunlabeled data and seed lists.
A primary question iswhether such lexicons improve performance over atranslate-to-English strategy (Banea et al, 2008).Acknowledgements: The authors thank AndrewHogue, Raj Krishnan and Deepak Ravichandran forinsightful discussions about this work.784ReferencesE.
Alfonseca, K. Hall, and S. Hartmann.
2009.
Large-scale computation of distributional similarities forqueries.
In Proceedings of the North American Chap-ter of the Association for Computational Linguistics(NAACL-HLT).C.
Banea, R. Mihalcea, J. Wiebe, and S. Hassan.
2008.Multilingual subjectivity analysis using machine trans-lation.
In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing (EMNLP).S.
Blair-Goldensohn, K. Hannan, R. McDonald, T. Ney-lon, G.A.
Reis, and J. Reynar.
2008.
Building a senti-ment summarizer for local service reviews.
In NLP inthe Information Explosion Era.G.
Carenini, R. Ng, and A. Pauls.
2006.
Multi-documentsummarization of evaluative text.
In Proceedings ofthe European Chapter of the Association for Compu-tational Linguistics (EACL).Y.
Choi and C. Cardie.
2009.
Adapting a polarity lexiconusing integer linear programming for domain-specificsentiment classification.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing (EMNLP).S.R.
Das and M.Y.
Chen.
2007.
Yahoo!
for Amazon:Sentiment extraction from small talk on the web.
Man-agement Science, 53(9):1375?1388.A Esuli and F. Sabastiani.
2009.
SentiWordNet: A pub-licly available lexical resource for opinion mining.
InProceedings of the Language Resource and EvaluationConference (LREC).M.
Gamon, A. Aue, S. Corston-Oliver, and E. Ringger.2005.
Pulse: Mining customer opinions from free text.In Proceedings of the 6th International Symposium onIntelligent Data Analysis (IDA).V.
Hatzivassiloglou and K.R.
McKeown.
1997.
Predict-ing the semantic orientation of adjectives.
In Proceed-ings of the European Chapter of the Association forComputational Linguistics (EACL).M.
Hu and B. Liu.
2004.
Mining and summarizing cus-tomer reviews.
In Proceedings of the InternationalConference on Knowledge Discovery and Data Min-ing (KDD).V.B.
Jijkoun and K. Hofmann.
2009.
Generating a non-english subjectivity lexicon: Relations that matter.
InProceedings of the European Chapter of the Associa-tion for Computational Linguistics (EACL).N.
Kaji and M. Kitsuregawa.
2007.
Building lexicon forsentiment analysis from massive collection of HTMLdocuments.
In Proceedings of the Joint Conferenceon Empirical Methods in Natural Language Process-ing and Computational Natural Language Learning(EMNLP-CoNLL).S.M.
Kim and E. Hovy.
2004.
Determining the senti-ment of opinions.
In Proceedings of the InternationalConference on Computational Linguistics (COLING).Kevin Lerman, Sasha Blair-Goldensohn, and Ryan Mc-Donald.
2009.
Sentiment summarization: Evaluat-ing and learning user preferences.
In Proceedings ofthe European Chapter of the Association for Compu-tational Linguistics (EACL).R.
McDonald, K. Hannan, T. Neylon, M. Wells, andJ.
Reynar.
2007.
Structured models for fine-to-coarsesentiment analysis.
In Proceedings of the Annual Con-ference of the Association for Computational Linguis-tics (ACL).R.
Mihalcea, C. Banea, and J. Wiebe.
2007.
Learningmultilingual subjective language via cross-lingual pro-jections.
In Proceedings of the Annual Conference ofthe Association for Computational Linguistics (ACL).S.
Mohammad, B. Dorr, and C. Dunne.
2009.
Generat-ing high-coverage semantic orientation lexicons fromovertly marked words and a thesaurus.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing (EMNLP).B.
Pang, L. Lee, and S. Vaithyanathan.
2002.
Thumbsup?
Sentiment classification using machine learn-ing techniques.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP).P.
Pantel, E. Crestan, A. Borkovsky, A. Popescu, andV.
Vyas.
2009.
Web-scale distributional similarity andentity set expansion.
In Proceedings of Conference onEmpirical Methods in Natural Language Processing(EMNLP).D.
Rao and D. Ravichandran.
2009.
Semi-SupervisedPolarity Lexicon Induction.
In Proceedings of the Eu-ropean Chapter of the Association for ComputationalLinguistics (EACL).E.
Riloff and J. Wiebe.
2003.
Learning extraction pat-terns for subjective expressions.
In Proceedings ofthe Conference on Empirical Methods in Natural Lan-guage Processing (EMNLP).P.
Turney.
2002.
Thumbs up or thumbs down?
Sentimentorientation applied to unsupervised classification of re-views.
In Proceedings of the Annual Conference of theAssociation for Computational Linguistics (ACL).J.
Wiebe.
2000.
Learning subjective adjectives from cor-pora.
In Proceedings of the National Conference onArtificial Intelligence (AAAI).T.
Wilson, J. Wiebe, and P. Hoffmann.
2005.
Recogniz-ing contextual polarity in phrase-level sentiment anal-ysis.
In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing (EMNLP).X.
Zhu and Z. Ghahramani.
2002.
Learning from labeledand unlabeled data with label propagation.
Technicalreport, CMU CALD tech report CMU-CALD-02.785
