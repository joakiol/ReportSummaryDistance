Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 212?216,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsLanguage-Independent Parsing with Empty ElementsShu Cai and David ChiangUSC Information Sciences Institute4676 Admiralty Way, Suite 1001Marina del Rey, CA 90292{shucai,chiang}@isi.eduYoav GoldbergBen Gurion University of the NegevDepartment of Computer SciencePOB 653 Be?er Sheva, 84105, Israelyoavg@cs.bgu.ac.ilAbstractWe  present  a  simple, language-independentmethod for integrating recovery of empty ele-ments into syntactic parsing.
This method out-performs  the  best  published  method  we  areaware of on English and a recently publishedmethod on Chinese.1 IntroductionEmpty elements in the syntactic analysis of a sen-tence are markers that show where a word or phrasemight otherwise be expected to appear, but does not.They play an important role in understanding thegrammatical relations in the sentence.
For example,in the tree of Figure 2a, the first empty element (*)marks where John would be if believed were in theactive voice (someone believed.
.
.
), and the secondempty element (*T*) marks where the manwould beifwhowere not fronted (John was believed to admirewho?
).Empty elements exist in many languages and servedifferent purposes.
In languages such as Chinese andKorean, where subjects and objects can be droppedto avoid duplication, empty elements are particularlyimportant, as they indicate the position of droppedarguments.
Figure 1 gives an example of a Chineseparse tree with empty elements.
The first empty el-ement (*pro*) marks the subject of the whole sen-tence, a pronoun inferable from context.
The secondempty element (*PRO*) marks the subject of the de-pendent VP (sh?sh?
f?l?
ti?ow?n).The Penn Treebanks (Marcus et  al., 1993; Xueet al, 2005) contain detailed annotations of emptyelements.
Yet  most  parsing  work  based  on  theseresources has ignored empty elements, with some.IP.
.VP.
.VP.
.IP.
.VP.
.NP.
.NN.??ti?ow?nclause.NN.??f?l?law.VV.??sh?sh?implement.NP.-NONE-.*PRO*.VV.??zh?ngzh?suspend.ADVP.AD.?
?z?nsh?for now.NP.-NONE-.
*pro*Figure 1: Chinese parse tree with empty elements marked.The meaning of the sentence is, ?Implementation of thelaw is temporarily suspended.
?notable exceptions.
Johnson (2002) studied empty-element  recovery in English, followed by severalothers (Dienes and Dubey, 2003; Campbell, 2004;Gabbard et al, 2006); the best results we are aware ofare due to Schmid (2006).
Recently, empty-elementrecovery for Chinese has begun to receive attention:Yang and Xue (2010) treat it as classification prob-lem, while Chung and Gildea (2010) pursue severalapproaches for both Korean and Chinese, and ex-plore applications to machine translation.Our intuition motivating this work is that emptyelements are an integral part of syntactic structure,and should be constructed jointly with it, not addedin afterwards.
Moreover, we expect empty-elementrecovery to improve as the parsing quality improves.Our method makes use of a strong syntactic model,the PCFGs with latent annotation of Petrov et al(2006), which  we  extend  to  predict  empty  cate-212gories  by the  use  of lattice  parsing.
The methodis language-independent and performs very well onboth languages we tested it on: for English, it out-performs the best published method we are aware of(Schmid, 2006), and for Chinese, it outperforms themethod of Yang and Xue (2010).12 MethodOur method is fairly simple.
We take a state-of-the-art parsing model, the Berkeley parser (Petrov et al,2006), train it on data with explicit empty elements,and test it on word lattices that can nondeterminis-tically insert empty elements anywhere.
The idea isthat the state-splitting of the parsing model will en-able it to learn where to expect empty elements to beinserted into the test sentences.Tree transformations Prior to training, we alterthe annotation of empty elements so that the termi-nal label is a consistent symbol (?
), the preterminallabel is the type of the empty element, and -NONE-is deleted (see Figure 2b).
This simplifies the lat-tices because there is only one empty symbol, andhelps the parsing model to learn dependencies be-tween nonterminal labels and empty-category typesbecause there is no intervening -NONE-.Then, following Schmid (2006), if a constituentcontains an empty element that is linked to anothernode with label X, then we append /X to its label.If there is more than one empty element, we pro-cess them bottom-up (see Figure 2b).
This helps theparser learn to expect where to find empty elements.In our experiments, we did this only for elements oftype *T*.
Finally, we train the Berkeley parser on thepreprocessed training data.Lattice parsing Unlike the training data, the testdata does not mark any empty elements.
We allowthe parser to produce empty elements by means oflattice-parsing (Chappelier et al, 1999), a general-ization of CKY parsing allowing it to parse a word-lattice instead of a predetermined list of terminals.Lattice parsing adds a layer of flexibility to exist-ing parsing technology, and allows parsing in sit-uations where the yield of  the tree  is  not  knownin advance.
Lattice parsing originated in the speech1Unfortunately, not  enough  information  was  available  tocarry out comparison with the method of Chung and Gildea(2010).processing community  (Hall, 2005; Chappelier  etal., 1999), and  was  recently  applied  to  the  taskof joint clitic-segmentation and syntactic-parsing inHebrew  (Goldberg  and  Tsarfaty, 2008; Goldbergand Elhadad, 2011) and Arabic (Green and Man-ning, 2010).
Here, we use lattice parsing for empty-element recovery.We use a modified version of the Berkeley parserwhich allows handling lattices as input.2The modifi-cation is fairly straightforward: Each lattice arc cor-respond to a lexical item.
Lexical items are now in-dexed by their start and end states rather than bytheir sentence position, and the initialization proce-dure of the CKY chart is changed to allow lexicalitems of spans greater than 1.
We then make the nec-essary adjustments to the parsing algorithm to sup-port this change: trying rules involving preterminalseven when the span is greater than 1, and not relyingon span size for identifying lexical items.At test time, we first construct a lattice for eachtest sentence that allows 0, 1, or 2 empty symbols(?)
between each pair of words or at the start/end ofthe sentence.
Then we feed these lattices through ourlattice parser to produce trees with empty elements.Finally, we reverse the transformations that had beenapplied to the training data.3 Evaluation MeasuresEvaluation metrics for empty-element recovery arenot well established, and previous studies use a vari-ety of metrics.
We review several of these here andadditionally propose a unified evaluation of parsingand empty-element recovery.3If A and B are multisets, let A(x) be the numberof occurrences of x in A, let |A| = ?x A(x), andlet A ?
B be the multiset such that (A ?
B)(x) =min(A(x), B(x)).
If T is the multiset of ?items?
in thetrees being tested andG is the multiset of ?items?
inthe gold-standard trees, thenprecision =|G ?
T ||T | recall =|G ?
T ||G|F1 =21precision+1recall2The modified parser is available at http://www.cs.bgu.ac.il/~yoavg/software/blatt/3We provide a scoring script which supports all of these eval-uation metrics.
The code is available at http://www.isi.edu/~chiang/software/eevalb.py .213.SBARQ.
.SQ.
.VP.
.S.
.VP.
.VP.
.NP.-NONE-.*T*.VB.admire.TO.to.NP.-NONE-.*.VBN.believed..NP.NNP.John.VBZ.is.WHNP.WP.who.SBARQ.
.SQ/WHNP.
.VP/WHNP/NP.
.S/WHNP/NP.
.VP/WHNP.
.VP/WHNP.
.NP/WHNP.*T*.?.VB.admire.TO.to.NP.*.
?.VBN.believed..NP.NNP.John.VBZ.is.WHNP.WP.who(a) (b)Figure 2: English parse tree with empty elements marked.
(a) As annotated in the Penn Treebank.
(b) With emptyelements reconfigured and slash categories added.where ?items?
are defined differently for each met-ric, as  follows.
Define  a nonterminal node, forpresent purposes, to be a node which is neither a ter-minal nor preterminal node.The  standard  PARSEVAL metric  (Black  et  al.,1991) counts labeled nonempty brackets: items are(X, i, j) for each nonempty nonterminal node, whereX is its label and i, j are the start and end positionsof its span.Yang  and  Xue  (2010)  simply  count unlabeledempty elements: items are (i, i) for each empty ele-ment, where i is its position.
If multiple empty ele-ments occur at the same position, they only count thelast one.The metric originally proposed by Johnson (2002)counts labeled empty brackets: items are (X/t, i, i) foreach empty nonterminal node, where X is its labeland t is the type of the empty element it dominates,but also (t, i, i) for each empty element not domi-nated by an empty nonterminal node.4The followingstructure has an empty nonterminal dominating twoempty elements:.SBAR.
.S.-NONE-.
*T*.-NONE-.0Johnson  counts  this  as (SBAR, i, i), (S/*T*, i, i);Schmid  (2006)  counts  it  as  a  single4This happens in the Penn Treebank for types *U* and 0, butnever in the Penn Chinese Treebank except by mistake.
(SBAR-S/*T*, i, i).5 We  tried  to  follow  Schmidin a generic way: we collapse any vertical chain ofempty nonterminals into a single nonterminal.In order to avoid problems associated with caseslike this, we suggest a pair of simpler metrics.
Thefirst is to count labeled empty elements, i.e., itemsare (t, i, i) for each empty element, and the second,similar in spirit to SParseval (Roark et al, 2006), isto count all labeled brackets, i.e., items are (X, i, j)for  each nonterminal  node (whether  nonempty orempty).
These two metrics, together with part-of-speech accuracy, cover all possible nodes in the tree.4 Experiments and ResultsEnglish As is standard, we trained the parser onsections 02?21 of  the Penn Treebank Wall  StreetJournal corpus, used section 00 for development, andsection 23 for testing.
We ran 6 cycles of training;then, because we were unable to complete the 7thsplit-merge cycle with the default setting of merg-ing 50% of splits, we tried increasing merges to 75%and ran 7 cycles of training.
Table 1 presents ourresults.
We chose the parser settings that gave thebest labeled empty elements F1 on the dev set, andused these settings for the test set.
We outperform thestate of the art at recovering empty elements, as wellas achieving state of the art accuracy at recoveringphrase structure.5This difference is not small; scores using Schmid?s metricare lower by roughly 1%.
There are other minor differences inSchmid?s metric which we do not detail here.214Labeled Labeled All LabeledEmpty Brackets Empty Elements BracketsSection System P R F1 P R F1 P R F100 Schmid (2006) 88.3 82.9 85.5 89.4 83.8 86.5 87.1 85.6 86.3split 5?
merge 50% 91.0 79.8 85.0 93.1 81.8 87.1 90.4 88.7 89.5split 6?
merge 50% 91.9 81.1 86.1 93.6 82.4 87.6 90.4 89.1 89.7split 6?
merge 75% 92.7 80.7 86.3 94.6 82.0 87.9 90.3 88.5 89.3split 7?
merge 75% 91.0 80.4 85.4 93.2 82.1 87.3 90.5 88.9 89.723 Schmid (2006) 86.1 81.7 83.8 87.9 83.0 85.4 86.8 85.9 86.4split 6?
merge 75% 90.1 79.5 84.5 92.3 80.9 86.2 90.1 88.5 89.3Table 1: Results on Penn (English) Treebank, Wall Street Journal, sentences with 100 words or fewer.Unlabeled Labeled All LabeledEmpty Elements Empty Elements BracketsTask System P R F1 P R F1 P R F1Dev split 5?
merge 50% 82.5 58.0 68.1 72.6 51.8 60.5 84.6 80.7 82.6split 6?
merge 50% 76.4 60.5 67.5 68.2 55.1 60.9 83.2 81.3 82.2split 7?
merge 50% 74.9 58.7 65.8 65.9 52.5 58.5 82.7 81.1 81.9Test Yang and Xue (2010) 80.3 57.9 63.2split 6?
merge 50% 74.0 61.3 67.0 66.0 54.5 58.6 82.7 80.8 81.7Table 2: Results on Penn (Chinese) Treebank.Chinese We  also  experimented  on  a  subset  ofthe  Penn  Chinese  Treebank  6.0.
For  comparabil-ity  with  previous  work  (Yang  and  Xue, 2010),we trained the parser on sections 0081?0900, usedsections 0041?0080 for development, and sections0001?0040 and 0901?0931 for testing.
The resultsare shown in Table 2.We selected the 6th split-mergecycle based on the labeled empty elements F1 mea-sure.
The unlabeled empty elements column showsthat our system outperforms the baseline system ofYang and Xue (2010).
We also analyzed the empty-element recall by type (Table 3).
Our system outper-formed that of Yang and Xue (2010) especially on*pro*, used for dropped arguments, and *T*, usedfor relative clauses and topicalization.5 Discussion and Future WorkThe  empty-element  recovery  method  we  havepresented  is  simple, highly  effective, and  fullyintegrated with  state  of  the  art  parsing.
We hopeto  exploit  cross-lingual  information  about  emptyelements  in  machine  translation.
Chung  andGildea (2010)  have  shown that  such  informationindeed helps translation, and we plan to extend thiswork  by  handling  more  empty  categories  (ratherTotal Correct RecallType Gold YX Ours YX Ours*pro* 290 125 159 43.1 54.8*PRO* 299 196 199 65.6 66.6*T* 578 338 388 58.5 67.1*RNR* 32 20 15 62.5 46.9*OP* 134 20 65 14.9 48.5* 19 5 3 26.3 15.8Table 3: Recall on different types of empty categories.YX = (Yang and Xue, 2010), Ours = split 6?.than just *pro* and *PRO*), and to incorporate theminto a syntax-based translation model instead of aphrase-based model.We also plan to extend our work here to recovercoindexation information (links between a moved el-ement and the trace which marks the position it wasmoved from).
As a step towards shallow semanticanalysis, this may further benefit other natural lan-guage processing tasks such as machine translationand summary generation.AcknowledgementsWe would like to thank Slav Petrov for his help inrunning the Berkeley parser, and Yaqin Yang, Bert215Xue, Tagyoung Chung, and Dan Gildea for their an-swering our  many questions.
We would also liketo  thank  our  colleagues  in  the  Natural  LanguageGroup  at  ISI for  meaningful  discussions  and  theanonymous reviewers for their thoughtful sugges-tions.
This work was supported in part by DARPAunder contracts HR0011-06-C-0022 (subcontract toBBN Technologies) and DOI-NBC N10AP20031,and by NSF under contract IIS-0908532.ReferencesE.
Black, S. Abney, D. Flickinger, C. Gdaniec, R. Gr-ishman, P. Harrison, D. Hindle, R. Ingria, F. Jelinek,J.
Klavans, M. Liberman, M. Marcus, S. Roukos,B.
Santorini, and T. Strzalkowski.
1991.
A procedurefor quantitatively comparing the syntactic coverage ofEnglish grammars.
In Proc.
DARPA Speech and Natu-ral Language Workshop.Richard Campbell.
2004.
Using linguistic principles torecover empty categories.
In Proc.
ACL.J.-C. Chappelier, M. Rajman, R. Aragu?es, and A. Rozen-knop.
1999.
Lattice parsing for speech recognition.In Proc.
Traitement Automatique du Langage Naturel(TALN).Tagyoung Chung and Daniel  Gildea.
2010.
Effectsof empty categories on machine translation.
In Proc.EMNLP.Pe?ter Dienes and Amit Dubey.
2003.
Antecedent recov-ery: Experiments with a trace tagger.
In Proc.
EMNLP.Ryan Gabbard, Seth Kulick, and Mitchell Marcus.
2006.Fully parsing the Penn Treebank.
In Proc.
NAACLHLT.Yoav Goldberg and Michael Elhadad.
2011.
Joint He-brew segmentation and parsing using a PCFG-LA lat-tice parser.
In Proc.
of ACL.Yoav Goldberg and Reut Tsarfaty.
2008.
A single gener-ative model for joint morphological segmentation andsyntactic parsing.
In Proc.
of ACL.Spence Green and Christopher D. Manning.
2010.
BetterArabic parsing: Baselines, evaluations, and analysis.
InProc of COLING-2010.Keith B.
Hall.
2005.
Best-first word-lattice parsing:techniques for integrated syntactic language modeling.Ph.D.
thesis, Brown University, Providence, RI, USA.Mark Johnson.
2002.
A simple pattern-matching al-gorithm  for  recovering  empty  nodes  and  their  an-tecedents.
In Proc.
ACL.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotated cor-pus of English: the Penn Treebank.
ComputationalLinguistics, 19:313?330.Slav  Petrov, Leon Barrett, Romain  Thibaux, and  DanKlein.
2006.
Learning accurate, compact, and inter-pretable tree annotation.
In Proc.
COLING-ACL.Brian  Roark, Mary  Harper, Eugene  Charniak, BonnieDorr, Mark Johnson, Jeremy G. Kahn, Yang Liu, MariOstendorf, John Hale, Anna Krasnyanskaya, MatthewLease, Izhak Shafran, Matthew Snover, Robin Stewart,and Lisa Yung.
2006.
SParseval: Evaluation metricsfor parsing speech.
In Proc.
LREC.Helmut Schmid.
2006.
Trace prediction and recoverywith unlexicalized PCFGs and slash features.
In Proc.COLING-ACL.Nianwen  Xue, Fei  Xia, Fu-dong  Chiou, and  MarthaPalmer.
2005.
The Penn Chinese TreeBank: Phrasestructure annotation of a large corpus.
Natural Lan-guage Engineering, 11(2):207?238.Yaqin Yang and Nianwen Xue.
2010.
Chasing the ghost:recovering empty categories in the Chinese Treebank.In Proc.
COLING.216
