An Algorithm for One-page Summarization of a Long TextBased on Thematic Hierarchy DetectionYoshio NakaoFujitsu Laboratories Ltd.Kamikodanaka 4-1-1, Nakahara-ku, Kawasaki, Japan, 211-8588nakao@ab.fujitsu.co.jpAbstractThis paper presents an algorithm fortext summarization using the the-matic hierarchy of a text.
The algo-rithm is intended to generate a one-page summary for the user, therebyenabling the user to skim large vol-umes of an electronic book on acomputer display.
The algorithmrst detects the thematic hierarchyof a source text with lexical cohe-sion measured by term repetitions.Then, it identies boundary sen-tences at which a topic of appropri-ate grading probably starts.
Finally,it generates a structured summaryindicating the outline of the the-matic hierarchy.
This paper mainlydescribes and evaluates the part forboundary sentence identication inthe algorithm, and then briey dis-cusses the readability of one-pagesummaries.1 IntroductionThis paper presents an algorithm for textsummarization using the thematic hierarchyof a long text, especially for use by readerswho want to skim an electronic book of sev-eral dozens of pages on a computer display.For those who want an outline to quicklyunderstand important parts of a long text,a one-page summary is more useful than aquarter-size summary, such as that gener-ated by a typical automatic text summa-rizer.
Moreover, a one-page summary helpsusers reading a long text online because thewhole summary can appear at one time onthe screen of a computer display.To make such a highly compressed sum-mary, topics of appropriate grading must beextracted according to the size of the sum-mary to be output, and selected topics mustbe condensed as much as possible.
The pro-posed algorithm decomposes a text into anappropriate number of textual units by theirsubtopics, and then generates short extractsfor each unit.
For example, if a thirty-sentence summary is required to contain asmany topics as possible, the proposed algo-rithm decomposes a source text into approxi-mately ten textual units, and then generates asummary composed of two- or three-sentenceextracts of these units.The proposed algorithm consists of threestages.
In the rst stage, it detects the the-matic hierarchy of a source text to decom-pose a source text into an appropriate num-ber of textual units of approximately the samesize.
In the second stage, it adjusts eachboundary between these textual units to iden-tify a boundary sentence, indicating where atopic corresponding to a textual unit proba-bly starts.
It then selects a lead sentence thatprobably indicates the contents of subsequentparts in the same textual unit.
In the laststage, it generates a structured summary ofthese sentences, thereby providing an outlineof the thematic hierarchy of the source text.The remainder of this paper includes thefollowing: an explanation of problems in one-page summarization that the proposed algo-rithm is intended to solve; brief explanationsof a previously published algorithm for the-matic hierarchy detection (Nakao, 1999) anda problem that must be solved to successfullyrealize one-page summarization; a descriptionand evaluation of the algorithm for boundarysentence identication; a brief explanation ofan algorithm for structured summary con-struction; and some points of discussion onone-page summarization for further research.2 Problems in one-pagesummarization of a long textThis section examines problems in one-pagesummarization.
The proposed algorithm isintended to solve three such problems.The rst problem is related to text decom-position.
Newspaper editorials or technicalpapers can be decomposed based on theirrhetorical structures.
However, a long ag-gregated text, such as a long technical sur-vey report, cannot be decomposed in thesame way, because large textual units, suchas those longer than one section, are usuallyconstructed with only weak and vague rela-tionships.
Likewise, their arrangement mayseem almost at random if analyzed accord-ing to their logical or rhetorical relationships.Thus, a method for detecting such large tex-tual units is required.Since a large textual unit often correspondsto a logical document element, such as a partor section, rendering features of logical ele-ments can have an important role in detectingsuch a unit.
For example, a section headeris distinguishable because it often consistsof a decimal number followed by capitalizedwords.
However, a method for detecting alarge textual unit by rendering features is notexpected to have wide range of applicability.In other words, since the process for render-ing features of logical elements varies accord-ing to document type, heuristic rules for de-tection must be prepared for every documenttype.
That is a problem.
Moreover, the log-ical structure of a text does not always cor-respond to its thematic hierarchy, especiallyif a section consists of an overview clause fol-lowed by other clauses that can be dividedinto several groups by their subtopics.Since then, based on Hearst's work (1994),an algorithm for detecting the thematic hi-erarchy of a text using only lexical cohesion(Haliday and Hasan, 1976) measured by termrepetitions was developed (Nakao, 1999).
Incomparison with some alternatives (Salton etal., 1996; Yaari, 1998), one of the featuresof the algorithm is that it can decompose atext into thematic textual units of approxi-mately the same size, ranging from units justsmaller than the entire text to units of aboutone paragraph.
In this paper, a summariza-tion algorithm based on this feature is pro-posed.The second problem is related to the tex-tual coherence of a one-page summary itself.A three-sentence extract of a large text, whichthe proposed algorithm is designed to gener-ate for an appropriate grading topic, tend toform a collection of unrelated sentences if it isgenerated by simple extraction of importantsentences.
Furthermore, the summary shouldprovides new information to a reader, so anintroduction is necessary to help a reader un-derstand it.
Figure 4 shows a summary exam-ple of a technical survey report consisting ofone hundred thousand characters.
It was gen-erated by extracting sentences with multiplesignicant terms as determined by the like-lihood ratio test of goodness-of-t for termfrequency distribution.
It seems to have sen-tences with some important concepts (key-words), but they do not relate much to oneanother.
Moreover, inferring the contexts inwhich they appear is di?cult.To prevent this problem, the proposed al-gorithm is designed to extract sentences fromonly the lead part of every topic.The third problem is related to the read-ability of a summary.
A one-page summaryis much shorter than a very long text, suchas a one-hundred-page book, but is too longto read easily without some breaks indicatingsegues of topics.
Even for an entire exposi-tory text, for which a method for displayingthe thematic hierarchy with generated head-ers was proposed to assist a reader to explorethe content (Yaari, 1998), a good summary isrequired to help a user understand quickly.To improve readability, the proposed algo-rithm divides every one-page summary intoseveral parts, each of which consists of aheading-like sentence followed by some para-graphs.3 Text Summarization Algorithm3.1 Thematic Hierarchy DetectionIn the rst stage, the proposed algorithm usesthe previously published algorithm (Nakao,1999) to detect the thematic hierarchy of atext based on lexical cohesion measured byterm repetitions.
The output of this stage isa set of lists consisting of thematic boundarycandidate sections (TBCS).
The lists corre-spond individually to every layer of the hier-archy and are composed of TBCSs that sep-arate the source text into thematic textualunits of approximately the same size.3.1.1 Thematic Hierarchy DetectionAlgorithmFirst, the algorithm calculates a cohesionscore at xed-width intervals in a source text.According to Hearst's work (1994), a cohesionscore is calculated based on the lexical sim-ilarity of two adjacent xed-width windows(which are eight times larger than the intervalwidth) set at a specic point by the followingformula:c(bl; br) =twt;blwt;brqtw2t;bltw2t;brwhere bland brare the textual block in theleft and right windows, respectively, and wt;blis the frequency of term1t for bl, and wt;bris the frequency t for br.
Hereafter, the pointbetween the left and right windows is referredto as the reference point of a cohesion score.The algorithm then detects thematicboundaries according to the minimal points offour-item moving average (arithmetic mean offour consecutive scores) of the cohesion scoreseries.
After that, it selects the textual areacontributing the most to every minimal valueand identies it as a TBCS.Figure 1 shows the results of a TBCS de-tection example, where FC is, Forward Co-hesion, a series of average values plotted at1All content words (i.e., verbs, nouns, and adjec-tives) extracted by a tokenizer for Japanese sentences.00.10.20.30.40.50.60.70.810900 11000 11100 11200 11300 11400 11500 11600 11700CohesionScoreLocation in Text [words](4.4)(4.4.1)minimalFCminimalBCmoving average rangeEPFC < BC FC > BCCFCBCTBCSSection BoundaryFigure 1: Example of TBCS Detectionthe reference point of the rst averaged score,and BC is, Backward Cohesion, a series ofaveraged values plotted at the reference pointof the last averaged score.
Since the textualarea just before the point at which FC plottedis always in the left window when one of theaveraged cohesion scores is calculated, FC in-dicates the strength of forward (left-to-right)cohesion at a point.
Conversely, BC indicatesthe strength of backward cohesion at a point.In the gure, EP is, Equilibrium Point, thepoint at which FC and BC have an identi-cal value.
The algorithm checks for FC andBC starting from the beginning till the endof the source text; and it records a TBCS, asdepicted by the rectangle, whenever an equi-librium point is detected (see (Nakao, 1999)for more information).640B(4)1280B(3)2560B(2)5120B(1)entireB(0)0 2000 4000 6000 8000 10000 12000 14000 16000 18000WindowWidth[words]Location in Text [words](4.2)(4.2.1)(4.2.2)(ref)(4.3)(4.3.1) (4.3.2)(4.3.3)(ref)(4.4)(4.4.1)(4.4.2)(4.4.3)(4.4.4)(ref)[0][0] [1] [2][0] [1] [2] [3] [4][0] [1] [2] [3] [4] [5] [6] [7] [8] [9] [10][6]TBCSSection BoundaryFigure 2: Example of Thematic HierarchyFor a sample text, Figure 2 shows the re-sulting thematic hierarchy that was detectedTable 1: Accuracy of Thematic Hierarchy DetectionWindow Boundary # Original TBCS Unied TBCSwidth cor.
res.
Recall Precision Recall Precision5120 1 2 100 (22) 50 (11) 100 (0.3) 50 (0.1)2560 2 4 100 (22) 50 (11) 50 (0.5) 25 (0.3)1280 3 10 100 (27) 30 (8.1) 67 (1.4) 20 (0.4)640 30 42 90 (23) 64 (16) 57 (2.3) 40 (1.7)320 114 163 67 (22) 47 (16) 46 (4.5) 33 (3.2)160 184 365 70 (22) 35 (11) 51 (9.1) 25 (4.6)80 322 813 57 (25) 23 (10) 57 (21) 23 (8.2)40 403 1681 52 (25) 13 (6.2) 71 (42) 17 (10)The gures in parentheses are the baseline rates.by the aforementioned procedure using vary-ing window widths (the ordinates).
Each hor-izontal sequence of rectangles depicts a listof TBCSs detected using a specic windowwidth.To narrow the width of candidate sections,the algorithm then unies a TBCS with an-other TBCS in the layer immediate below.
Itcontinued the process until TBCSs in all lay-ers, from the top to the bottom, are unied.After that, it outputs the thematic hierarchyas a set of lists of TBCS data:i: layer index of the thematichierarchyB(i)[j]: TBCS data containing thefollowing data members:ep: equilibrium pointrange: thematic boundarycandidate section.In Figure 2, for example, B(1)[1] is uniedwith B(2)[1]; B(3)[4]; B(4)[6]; : : :, and the val-ues of its data members (ep and range) arereplaced by those of the unied TBCS in thebottom layer, which has been detected usingthe minimum window width (40 words).3.1.2 Results of Thematic HierarchyDetectionTable 1 summarizes the accuracy of the-matic hierarchy detection in an experimentusing the following three kinds of Japanesetext as test data: a technical survey report2that consists of three main sections and con-tains 17,816 content words; eight series of2\Progress Report of Technical Committee on Net-work Access" in Survey on Natural Language Process-ing Systems by Japan Electronic Industry Develop-ment Association, chapter 4, pp.
117{197, Mar.
1997.newspaper columns3, each of which consists of4 to 24 articles containing about 400 words;and twelve economic research reports4, eachof which consists of about ten articles con-taining 33 to 2,375 words.In the table, cor.
denotes the number of thecorrect data values composed of the startingpoints of sections that contain the same num-ber of words or more than the window widthlisted in the same row5.
In addition, res.
de-notes the number of TBCSs.
The originalTBCS columns list the recall and precisionrates of detected TBCSs before TBCS unica-tion, and the unied TBCS columns list thoserates after TBCS unication.
On each layer,the width of candidate sections for originalTBCS is about half of the window width; andthat of unied TBCS is 25 words (about halfof the minimum window width).
The guresshown in parentheses are the baseline ratescorresponding to random selection.
That is,parts are randomly selected from the sourcetext whose total size is equal to the total areasize of TBCSs.As the boundary gures indicate, the pro-posed algorithm decomposes a text into tex-tual units of about equivalent window widths.In addition, the rates of detected TBCSs areclearly larger than their baselines.
Further-3Obtained from the Daily Yomiuri On-line(http://www.yomiuri.co.jp/).4Monthly reports written for a Japanese companyby a Japanese professor living in the U.S.A.5Only headings and intentional breaks, such assymbol lines inserted to separate a prologue or epi-logue from a main body, are used as correct bound-aries.
As a result, the precision rates of using smallerwindow widths tend to degrade because of insu?cientamounts of correct data.more, for two relatively large series of news-paper columns, the major boundaries weredetected properly.
That is, using larger win-dow widths, those boundaries were selectivelydetected that separate groups of columns bytheir subtopics.
For example, the startingpoint of a set of three consecutive columnsidentically entitled \The Great Cultural Rev-olution" in the \Chinese Revolution" serieswas detected using 1,280 word width window,as well as those of other three sets of consec-utive columns entitled identically.
Thus, theproposed algorithm is expected to be eec-tive for arbitrarily selecting the size of tex-tual units corresponding to dierent gradingtopics.However, there are problems about how todetermine a boundary point in the range de-ned by a TBCS.
Although the previouslypublished algorithm (Nakao, 1999) deter-mines a boundary point with minimal pointsof cohesion scores for the smallest windowwidth, the accuracy degrades substantially(see Table 3).
The boundary sentence identi-cation algorithm given below is a solution tothis problem.3.2 Boundary Sentence IdenticationIn the second stage, from sentences in aTBCS, the algorithm identies a boundarysentence, indicating where a topic corre-sponding to a textual unit probably starts,and selects a lead sentence that probably in-dicates the contents of subsequent parts in thesame textual unit.
Figure 3 shows the algo-rithm in detail.3.2.1 Forward/Backward RelevanceCalculationIn steps 2 and 3, boundaries are identiedand lead sentences are selected based on twokinds of relevance scores for a sentence: for-ward relevance indicating the sentence rele-vance to the textual unit immediately afterthe sentence, and backward relevance indicat-ing the sentence relevance to the textual unitimmediately before the sentence.
The dier-ence between the forward and the backwardrelevance is referred to as relative forward rel-1.
Assign the target layer as the bottom layer ofthe thematic hierarchy: i imax.2.
For each TBCS in the target layer, B(i)[j], dohe following:(a) If i  imax, then select and identifyall sentences in B(i)[j]:range as Bound-ary Sentence Candicates (B.S.C.
); oth-erwise, select and identify the sentencesin B(i)[j]:range located before or identi-cal to the boundary sentence of B(i+ 1)as B.S.C.
(b) From the B.S.C., identify a sentence asa Boundary Sentence (B.S.
), whose rel-ative forward relevance is greater than 0and has the most increment from that ofthe previous sentence.
(c) Among the sentences in the B.S.C.
lo-cated after or identical to the B.S., selectthe sentence that has the greatest for-ward relevance as a Lead Sentence (L.S.).3.
If i > 1, then i i 1, and repeat from step 2.Figure 3: Boundary Sentence IdenticationAlgorithmevance.Forward or backward relevance is calcu-lated using the formula below, where everytextual unit is partitioned at the equilibriumpoints of two adjacent TBCSs in the targetlayer, the equilibrium point of each TBCS isinitially set by the thematic hierarchy detec-tion algorithm, and the point is replaced bythe location of the boundary sentence afterthe boundary sentence is identied (i.e., step2b is completed).rS;u=1jSjXt2Stft;ujuj log(jDjdft))jSj total number of terms in sentence Sjuj total number of terms in textual unit utft;ufrequency of term t in textual unit ujDj total number of xed-width (80 words)blocks in the source textdfttotal number of xed-width blockswhere term t appearsThe use of this formula was proposed asan eective and simple measure for term im-portance estimation (Nakao, 1998)6.
It is a6An experiment reported in (Nakao, 1998) indi-Table 2: Example of Boundary Sentence IdenticationRelevance Sentence [partially presented]Location Backward Forward Relative (translation)O:R:11122 0 0.017 0.017 [??
?, 86] ([Yoshimura et.
al])11124 0.021 0.004 -0.017 ?????
: "??????????
", ?, pp.33-40, 1986(Yoshimura, Kenji ... : Automatic Extraction System of ...)B:S:11146 0 0.016 0.016 4.4.
??????
(Search Engine)L:S:11148 0.005 0.022 0.017 ??????????????????????????
(This section reports on ... of intelligent information access.
)11170 0.010 0.016 0.006 ???????????????????????
(The key issue of the reports in the following clauses is ... )modied version of entropy, where informa-tion bit (log part of the formula) is calcu-lated by reducing the eect of term repeti-tions in a short period.
The modication wasdone to increase the scores for an importantterm higher, based on the reported observa-tion that content bearing words tend to occurin clumps (Bookstein et al, 1998).3.2.2 Example of Boundary SentenceIdenticationTable 2 summarizes an example of bound-ary sentence identication of a TBCS locatedjust before the 12,000th word in Figure 2.
Ev-ery row in the table except the rst row, whichis marked with O:R:, shows a candidate sen-tence.
The row marked B:S: shows a bound-ary sentence, which has positive relative for-ward relevance (0.016 in the fourth column ofthe row) and the greatest increment from theprevious value (-0.017).
The row marked L:S:shows a lead sentence, which has the great-est forward relevance (0.022 in the third col-umn of the row) among all sentences after theboundary sentence.3.2.3 Evaluation of BoundaryIdenticationTable 3 shows recall and precision rates ofthe boundary identication algorithm in thesame format as Table 1.
Compared with theresults obtained using the previous version ofthe algorithm (Nakao, 1999), as shown in theminimal cohesion columns, the proposed al-gorithm identies more accurate boundariescates that heading terms (i.e., terms appeared in head-ings) are eectively detected by scoring terms with thepart of the formula in the summation operator.
(the boundary sentence columns).
In ad-dition, boundary sentence identication wassuccessful for 75% of the correct TBCSs, thatis, TBCSs including correct boundaries7(seeunied TBCS in Table 1).
Thus, the proposedboundary sentence identication algorithm isjudged to be eective.Table 3 also summarizes a feature of theproposed algorithm that it tends to detectand identify headings as boundary sentences(the heading rate columns).
For the part cor-responding to larger textual units, which theproposed algorithm mainly used, the guresin the overall columns indicate that half ofboundary sentences or more are identical toheadings in the original text; and the guresin the identication columns indicate thatthe proposed algorithm identies headings asboundary sentences for more than 80% of thecase where TBCSs including headings.3.3 Summary ConstructionIn the third and last stage, the algorithmoutputs the boundary and lead sentences ofTBCSs on a layer that probably correspondsto topics of appropriate grading.
Based on theratio of source text size to a given summarysize, the algorithm chooses a layer that con-tains an appropriate number of TBCSs, andgenerates a summary with some breaks to in-dicate thematic changes.For example, to generate a 1,000-charactersummary consisting of several parts of ap-proximately 200 characters for each topic, atext decomposition consisting of ve textual7For the correct TBCSs, the average number ofboundary sentence candidates is 4.4.units is appropriate for summarization.
Sincethe sample text used here was decomposedinto ve textual units on the B(2) layer (seeFigure 2), it outputs the boundary sentencesand lead sentences of all TBCSs in B(2).4 DiscussionFigure 5 shows a one-page summary of a tech-nical survey report, where (a) is a part ofthe summary automatically generated, and(b) is its translation.
It corresponds to thepart of the source text between B(1)[1] andB(1)[2] (in Figure 2).
It is composed of threeparts corresponding to B(2)[1], B(2)[2], andB(3)[6].
Each part consists of a boundary sen-tence, presented as a heading, followed by alead sentence.In comparison with the keyword-basedsummary shown in Figure 4, generated in theprocess described in Section 2, the one-pagesummary gives a good impression as beingeasy to understand.
In fact, when we in-formally asked more than ve colleagues tostate their impression of these summaries,they agreed with this point.
As describedin Section 2, one of the reasons for the goodimpression should be the dierence in coher-ence.
The relationship among sentences inthe keyword-based summary is not clear; con-versely, the second sentence of the one-pagesummary introduces the outline of the clause,and it is closely related to the sentences thatfollow it.
The fact that the one-page sum-mary provides at least two sentences, includ-ing a heading, for each topic is also consideredto make coherence strong.As shown in Table 3, the proposed algo-rithm is expected to extract headings eec-tively.
However, there is a problem that de-tected headings do not always correspond totopics of appropriate grading.
For example,the second boundary sentence in the exam-ple is not appropriate because it is a headingof a subclause much smaller than the windowwidth corresponding to B(2)[2], and its pre-vious sentence \4.3.2 Technical Trend of IRTechniques" is more appropriate one.This example is also related to another lim-itation of the proposed algorithm.
Since thereis no outline description in the subsequentpart of the heading of clause 4.3.2, the pro-posed algorithm could not generate a coher-ent extract if it had identied the heading asa boundary sentence.It is a future issue to develop more elab-orated algorithm for summarizing detectedtopics especially for the user who wants richerinformation than that can be provided in aextract consisting of two or three sentences.5 ConclusionThis paper has proposed an algorithm for one-page summarization to help a user skim along text.
It has mainly described and re-ported the eectiveness of the boundary sen-tence identication part of the algorithm.
Ithas also discussed the readability of one-pagesummaries.
The eectiveness of structuredsummaries using the thematic hierarchy is anissue for future evaluation.ReferencesA.
Bookstein, S. T. Klein, and T. Raita.
1998.Clumping properties of content-bearing words.Journal of the American Society for Informa-tion Science, 49(2):102{114.Michael A.K.
Haliday and Ruqaiya Hasan.
1976.Cohesion in English.
Longman, London.Marti A. Hearst.
1994.
Multi-paragraph segmen-tation of expository text.
In Proc.
of the 32ndAnnual Meeting of Association for Computa-tional Linguistics, pages 9{16.Yoshio Nakao.
1998.
Automatic keyword extrac-tion based on the topic structure of a text.
IPSJSIG Notes FI-50-1.
(in Japanese).Yoshio Nakao.
1999.
Thematic hierarchy detec-tion of a text using lexical cohesion.
Journal ofthe Association for Natural Language Process-ing, 6(6):83{112.
(in Japanese).Gerard Salton, Amit Singhal, Chris Buckley, andMandar Mitra.
1996.
Automatic text decom-position using text segments and text themes.In Proc.
of Hypertext '96, pages 53{65. the As-sociation for Computing Machinery.Yaakov Yaari.
1998.
Texplore { exploring expos-itory texts via hierarchical representation.
InProc.
of CVIF '98, pages 25{31.
Association forComputational Linguistics.Table 3: Evaluation of Boundary Sentence IdenticationWindow Boundary # Minimal cohesion Boundary sentence Heading ratewidth cor.
res.
Recall Precision Recall Precision Overall Identication5120 1 2 0 (0.1) 0 (.05) 100 (0.1) 50 (.05) 100 (6.6) 100 (29)2560 2 4 0 (0.2) 0 (0.1) 100 (0.2) 50 (.05) 100 (6.6) 100 (29)1280 3 10 33 (0.5) 10 (0.2) 67 (0.5) 20 (0.2) 80 (6.6) 80 (30)640 30 42 27 (1.0) 19 (0.7) 47 (1.0) 33 (0.7) 67 (6.3) 88 (34)320 114 163 26 (1.8) 18 (1.3) 40 (1.8) 28 (1.3) 54 (5.0) 82 (31)160 184 365 28 (3.5) 14 (1.8) 43 (3.5) 22 (1.8) 37 (4.8) 77 (28)80 322 813 29 (7.8) 12 (3.1) 45 (7.8) 18 (3.1) 23 (4.8) 70 (26)40 403 1681 37 (17) 9 (3.9) 46 (16) 11 (3.9) 12 (4.8) 58 (26)The gures in parentheses are the baseline rates.4.3??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
tf?
idf????????????????????????????????????????
tf???????????????????????????
idf???????????????????????????
[?
?, 92]???
?????????????????????????????????????????????????????????????????????
?ya part of a summary condensed to 1.3% of thesource text(a) Original4.3 Internet Services...
They are also enhanced with some techniques,such as eliminating high frequency words, weighinga term in document titles and headings, etc., toachieve high precision.
......
In addition, since the greatly increasing amount ofpages provided by an Internet service causes a greatincrease of average hit number for a query, moreeective automatic text summarization techniqueis required for helping a user to nd out requiredinformation quickly.
...... Tfidf method weighs a term in a document witha product of the term frequency (tf) in a documentand inverse document frequency (idf), i.e., inverseof the number of document that the term appears.
...... [Kawai, 92] A document classication method cal-culates a score based on2values of not only keywordfrequencies but also semantic frequencies correspond-ing to occurrences of abstracted semantic category intarget divisions.
...(b) TranslationFigure 4: Example of Keyword-based Sum-mary (partially presented)??????????????
[4.3??]?????WWW?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
[(1)??]????????????????????
1????????????????????
[(4)??]???????????????????????????????????????????WWW????????????????????
?ya part of a summary condensed to 1% of thesource text(a) OriginalInternet Services [see 4.3]This clause surveys internet services, electronicpublishing, and digital libraries, reports on theirfeatures, technical points, and problems observedin their typical cases, and suggests the desired ser-vices in the future and the required technology fortheir realization based on the investigation of re-lated research areas.
...Keyword Extraction [see (1)]Keyword-based IR is a popular access method forretrieving document on the networks.
...Distributed IR Systems [see (4)]In near future, it will be impossible for a singleIR system storing all resources in a singledatabase to handle the increasing number oflarge WWW text collections.
...(b) TranslationFigure 5: Example of One-page Summary(partially presented)
