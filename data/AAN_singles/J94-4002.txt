An Algorithm for Pronominal AnaphoraResolutionShalom Lappin"SOAS, University of LondonHerbert J. Leass tSietec SystemtechnikThis paper presents an algorithm for identifying the noun phrase antecedents of third personpronouns and lexical anaphors (reflexives and reciprocals).
The algorithm applies to the syntacticrepresentations generated by McCord's Slot Grammar parser and relies on salience measuresderived from syntactic structure and a simple dynamic model of attentional state.
Like the parser,the algorithm is implemented in Prolog.
The authors have tested it extensively on computermanual texts and conducted a blind test on manual text containing 360 pronoun occurrences.The algorithm successfully identifies the antecedent ofthe pronoun for 86% of these pronounoccurrences.
The relative contributions of the algorithm's components oits overall success ratein this blind test are examined.
Experiments were conducted with an enhancement of the al-gorithm that contributes statistically modelled information concerning semantic and real-worldrelations to the algorithm's decision procedure.
Interestingly, this enhancement only marginallyimproves the algorithm's performance (by 2%).
The algorithm is compared with other approachesto anaphora resolution that have been proposed in the literature.
In particular, the search proce-dure of Hobbs'algorithm was implemented in the Slot Grammar framework and applied to thesentences in the blind test set.
The authors" algorithm achieves a higher rate of success (4%)than Hobbs' algorithm.
The relation of the algorithm to the centering approach is discussed, aswell as to models of anaphora resolution that invoke a variety of informational factors in rankingantecedent candidates.1.
IntroductionWe present an algorithm for identifying both intrasentential nd intersentential n-tecedents of pronouns in text.
We refer to this algorithm as RAP (Resolution of Ana-phora Procedure).
RAP applies to the syntactic structures of McCord's (1990, 1993, inpress) Slot Grammar parser, and like the parser, it is implemented in Prolog.
It relieson measures of salience derived from syntactic structure and a simple dynamic modelof attentional state to select the antecedent noun phrase (NP) of a pronoun from alist of candidates.
It does not employ semantic onditions (beyond those implicit ingrammatical number and gender agreement) or real-world knowledge in evaluatingcandidate antecedents; nor does it model intentional or global discourse structure (asin Grosz and Sidner 1986).
* School of Oriental and African Studies, University of London, London WCIH OXG, UK.
E-mail:slappin@clusl .ulcc.ac.ukMost of the first author's work on this paper was done while he was a Research Staff Member in theComputer Science Department of the IBM T.J. Watson Research Center.t Sietec Systemtechnik (Siemens AG), D-13623 Berlin, Germany.
E-mail: leass@sietec.deThe second author's work on this paper was done while he was a visiting scientist at the IBMGermany Scientific Center.
@ 1994 Association for Computational LinguisticsComputational Linguistics Volume 20, Number 4In Section 2 we present RAP and discuss its main properties.
We provide examplesof its output for different sorts of cases in Section 3.
Most of these examples are takenfrom the computer manual texts on which we trained the algorithm.
We give the resultsof a blind test in Section 4, as well as an analysis of the relative contributions of thealgorithm's components o the overall success rate.
In Section 5 we discuss a proceduredeveloped by Dagan (1992) for using statistically measured lexical preference patternsto reevaluate RAP's salience rankings of antecedent candidates.
We present he resultsof a comparative blind test of RAP and this procedure.
Finally, in Section 6 we compareRAP to several other approaches to anaphora resolution that have been proposed inthe computational literature.2.
The Anaphora Resolution AlgorithmRAP contains the following main components.?
An intrasentential syntactic filter for ruling out anaphoric dependence ofa pronoun on an NP on syntactic grounds (This filter is presented inLappin and McCord 1990a.)?
A morphological filter for ruling out anaphoric dependence of a pronounon an NP due to non-agreement of person, number, or gender features?
A procedure for identifying pleonastic (semantically empty) pronouns?
An anaphor binding algorithm for identifying the possible antecedentbinder of a lexical anaphor (reciprocal or reflexive pronoun) within thesame sentence (This algorithm is presented in Lappin and McCord1990b.)?
A procedure for assigning values to several salience parameters(grammatical role, parallelism of grammatical roles, frequency ofmention, proximity, and sentence recency) for an NP.
(Earlier versions ofthese procedures are presented in Leass and Schwall 1991.)
Thisprocedure mploys a grammatical role hierarchy according to which theevaluation rules assign higher salience weights to (i) subject overnon-subject NPs, (ii) direct objects over other complements,(iii) arguments of a verb over adjuncts and objects of prepositionalphrase (PP) adjuncts of the verb, and (iv) head nouns over complementsof head nouns.
1?
A procedure for identifying anaphorically linked NPs as an equivalenceclass for which a global salience value is computed as the sum of thesalience values of its elements.?
A decision procedure for selecting the preferred element of a list ofantecedent candidates for a pronoun.1 This hierarchy ismore or less identical to the NP accessibility hierarchy proposed by Keenan andComrie (1977).
Johnson (1977) uses a similar grammatical role hierarchy to specify a set of constraintson syntactic relations, including reflexive binding.
Lappin (1985) employs itas a salience hierarchy tostate a non-coreference constraint for pronouns.
Guenthner and Lehmann (1983) use a similar salienceranking of grammatical roles to formulate rules of anaphora resolution.
Centering approaches toanaphora resolution use similar hierarchies a  well (Brennan, Friedman, and Pollard 1987; Walker, Iida,and Cote 1990).536Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution2.1 Some Preliminary DetailsRAP has been implemented for both ESG and GSG (English and German Slot Gram-mars); we will limit ourselves here to a discussion of the English version.
The differ-ences between the two versions are at present minimal, primarily owing to the factthat we have devoted most of our attention to analysis of English.
As with Slot Gram-mar systems in general (McCord 1989b, 1993, in press), an architecture was adoptedthat "factors out" language-specific elements of the algorithm.We have integrated RAP into McCord's (1989a, 1989b) Logic-Based Machine Trans-lation System (LMT).
(We are grateful to Michael McCord and Ullrike Schwall for theirhelp in implementing this integration.)
When the algorithm identifies the antecedentof a pronoun in the source language, the agreement features of the head of the NP cor-responding to the antecedent in the target language are used to generate the pronounin the target language.
Thus, for example, neuter third person pronouns in English aremapped into pronouns with the correct gender feature in German, in which inanimatenouns are marked for gender.RAP operates primarily on a clausal representation f the Slot Grammar analysis ofthe current sentence in a text (McCord et al 1992).
The clausal representation consistsof a set of Prolog unit clauses that provide information on the head-argument andhead-adjunct relations of the phrase structure that the Slot Grammar assigns to asentence (phrase).
Clausal representations of the previous four sentences in the text areretained in the Prolog workspace.
The discourse representation used by our algorithmconsists of these clausal representations, together with additional unit clauses declaringdiscourse referents evoked by NPs in the text and specifying anaphoric links amongdiscourse referents.
2 All information pertaining to a discourse referent or its evokingNP is accessed via an identifier (ID), a Prolog term containing two integers.
The firstinteger identifies the sentence in which the evoking NP occurs, with the sentences ina text being numbered consecutively.
The second integer indicates the position of theNP's head word in the sentence.2.1.1 The Syntactic Filter on Pronoun-NP Coreference.
The filter consists of six con-ditions for NP-pronoun on-coreference within a sentence.
To state these conditions,we use the following terminology.
The agreement features of an NP are its number,person, and gender features.
We will say that a phrase P is in the argument domainof a phrase N iff P and N are both arguments of the same head.
We will say that Pis in the adjunct domain of N iff N is an argument of a head H, P is the object of apreposition PREP, and PREP is an adjunct of H. P is in the NP domain of N iff N isthe determiner of a noun Q and (i) P is an argument of Q, or (ii) P is the object of apreposition PREP and PREP is an adjunct of Q.
A phrase P is contained in a phrase Qiff (i) P is either an argument or an adjunct of Q, i.e., P is immediately contained in Q,or (ii) P is immediately contained in some phrase R, and R is contained in Q.A pronoun P is non-coreferential with a (non-reflexive or non-reciprocal) nounphrase N if any of the following conditions hold:1.
P and N have incompatible agreement features.2.
P is in the argument domain of N.3.
P is in the adjunct domain of N.2 The number  of sentences whose syntactic representations are retained is a parametrically specifiedvalue of the algorithm.
Our  decision to set this value at four is motivated by our experience with thetechnical texts we have been working with.537Computational Linguistics Volume 20, Number 4..6.P is an argument of a head H, N is not a pronoun, and N is containedin H.P is in the NP domain of N.P is a determiner of a noun Q, and N is contained in Q.Examples of coindexings that would be rejected by these conditions are given inFigure 1.Condition 1:The womani said that he/is funny.Condition 2:Shei likes her/.John/seems to want to see himi.Condition 3:She/sat near her/.Condition 4:He/believes that the mani is amusing.This is the man/hei said John/wrote about.Condition 5:John/s portrait of himi is interesting.Condition 6:Hisi portrait of John/is interesting.Hisi description of the portrait by John/is interesting.Figure 1Conditions on NP-pronoun on-coreference (examples).2.1.2 Test for Pleonastic Pronouns.
The tests are partly syntactic and partly lexical.
Aclass of modal adjectives is specified.
It includes the following items (and their corre-sponding morphological negations, as well as comparative and superlative forms).necessary possible certain likely importantgood useful advisable convenient sufficienteconomical easy desirable difficult legalA class of cognitive verbs with the following elements is also specified.recommend think believe know anticipate assume expectIt appearing in the constructions of Figure 2 is considered pleonastic (Cogv-ed = passiveparticiple of cognitive verb); syntactic variants of these constructions (It is not~may beModaladj..., Wouldn't it be Modaladj .
.
.
.
etc.)
are recognized as well.To our knowledge, no other computational treatment of pronominal anaphoraresolution has addressed the problem of pleonastic pronouns.
It could be argued thatrecognizing pleonastic uses of pronouns is a task for levels of syntactic/semantic anal-ysis that precede anaphora resolution.
With the help of semantic lasses defined in thelexicon, it should be possible to include exhaustive tests for these constructions in538Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora ResolutionFigure 2Pleonastic uses of it.It is Modaladj that SIt is Modaladj (for NP) to VPIt is Cogv-ed that SIt seems/appears /means/ fo l lows (that) SNP makes/f inds it Modaladj (for NP) to VPIt is time to VPIt is thanks to NP that Sanalysis grammars.
32.1.3 The Anaphor Binding Algorithm.
The notion higher argument slot used in thefollowing formulation of the binding algorithm is defined by the following hierarchyof argument slots:subj > agent > obj > (iobjlpobj)Here subj is the surface subject slot, agent is the deep subject slot of a verb heading apassive VP, obj is the direct object slot, iobj is the indirect object slot, and pobj is theobject of a PP complement of a verb, as in put NP on NP.
We assume the definitionsof argument domain, adjunct domain, and NP domain given above.A noun phrase N is a possible antecedent binder for a lexical anaphor (i.e., re-ciprocal or reflexive pronoun) A iff N and A do not have incompatible agreementfeatures, and one of the following five conditions holds.1.,3.4..A is in the argument domain of N, and N fills a higher argument slotthan A.A is in the adjunct domain of N.A is in the NP domain of N.N is an argument of a verb V, there is an NP Q in the argument domainor the adjunct domain of N such that Q has no noun determiner, and(i) A is an argument of Q, or (ii) A is an argument of a preposition PREPand PREP is an adjunct of Q.A is a determiner of a noun Q, and (i) Q is in the argument domain of Nand N fills a higher argument slot than Q, or (ii) Q is in the adjunctdomain of N.Examples of bindings licensed by these conditions are given in Figure 3.2.1.4 Salience Weighting.
Salience weighting is accomplished using salience factors.
Agiven salience factor is associated with one or more discourse referents.
These dis-course referents are said to be in the factor's scope.
A weight is associated with each3 ESG does, in fact, recognize some pleonastic uses of it, viz.
in constructions involving extraposedsentential subjects, as in It surprised me that he was there.
A special slot, subj(it), is used.
We expect hatenhancements to ESG and to the Slot Grammar English lexicon will ultimately render our tests forpleonastic pronouns redundant.539Computational Linguistics Volume 20, Number 4Condition 1:They/wanted to see themselves/.Mary knows the people/who John introduced to each other/.Condition 2:Hei worked by himself/.Which friends/plan to travel with each other/?Condition 3:John likes Bill/s portrait of himselfi.Condition 4:They/told stories about themselves/.Condition 5:\[John and Mary\]/like ach otheri's portraits.Figure 3Conditions for antecedent NP-lexical anaphor binding.factor, reflecting its relative contribution to the total  salience of individual discoursereferents.
Initial weights are degraded in the course of processing.The use of salience factors in our algorithm is based on Alshawi's (1987) contextmechanism.
Other than sentence recency, the factors used in RAP differ from Alshawi'sand are more specific to the task of pronominal  anaphora resolution.
Alshawi's frame-work is designed to deal with a broad class of language interpretation problems,including reference resolution, word sense disambiguation, and the interpretation ofimplicit relations.
While Alshawi does propose emphasis factors for memory  entitiesthat are "referents for noun phrases playing syntactic roles regarded as foregroundingthe referent" (Alshawi 1987, p. 17), only topics of sentences in the passive voice andthe agents of certain be clauses receive such emphasis in his system.
Our emphas issalience factors realize a much more detailed measure of structural salience.Degradation of salience factors occurs as the first step in processing a new sentencein the text.
All salience factors that have been assigned prior to the appearance of thissentence have their weights degraded by a factor of two.
When the weight of a givensalience factor reaches zero, the factor is removed.A sentence recency salience factor is created for the current sentence.
Its scope is alldiscourse referents introduced by the current sentence.The discourse referents evoked by the current sentence are tested to see whetherother salience factors should apply.
If at least one discourse referent 4 satisfies theconditions for a given factor type, a new salience factor of that type is created, withthe appropriate discourse referents in its scope.In addition to sentence recency, the algorithm employs the following salience fac-tors:Subject emphasisExistential emphasis: predicate nominal in an existential construction, as inThere are only a few restrictions on LQL query const ruct ion  fo r  WordSmith.4 In this paper we do not distinguish between properties of a discourse referent and properties of the NPthat evokes it.540Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora ResolutionTable 1Salience factor types with initial weightsFactor type Initial weightSentence recency 100Subject emphasis 80Existential emphasis 70Accusative mphasis 50Indirect object and oblique complement emphasis 40Head noun emphasis 80Non-adverbial emphasis 50Accusative emphasis:  direct object (i.e., verbal complement in accusative case)Indirect object and obl ique complement  emphasisHead noun emphasis:  any NP not contained in another NP, using the Slot Grammarnotion of "containment within a phrase" (see Section 2.1.1).
This factor increases thesalience value of an NP that is not embedded within another NP (as its complementor adjunct).
Examples of NPs not receiving head noun emphasis arethe configuration information copied by Backup configurationthe assembly in bay Cthe connector  labe led  P3 on theflatcableNon-adverbia l  emphasis:  any NP not contained in an adverbial PP demarcated by aseparator.
Like head noun emphasis, this factor penalizes NPs in certain embeddedconstructions.
Examples of NPs not receiving non-adverbial emphasis areThroughout thefirstsection of thisguide,used ...In the Panel definition panel,act ion  bar .these symbols are alsoselect the C~Specify'' option from theThe initial weights for each of the above factor types are given in Table 1.
Notethat the relative weighting of some of these factors realizes a hierarchy of grammaticalroles.
52.1.5 Equivalence Classes.
We treat the antecedent-anaphor relation in much the sameway as the "equality" condition of Discourse Representation Theory (DRT) (Kamp1981), as inu---y.This indicates that the discourse referent u, evoked by an anaphoric NP, is anaphori-cally linked to a previously introduced iscourse referent y.
To avoid confusion with5 The specific values of the weights are arbitrary.
The significance of the weighting procedure is in thecomparative r lations among the factors as defined by the weights.
We have determined the efficacy ofthis relational structure of salience factors (and refined it) experimentally (see Section 4.2).541Computational Linguistics Volume 20, Number 4mathematical equality (which, unlike the relation discussed here, is symmetric), werepresent the relation between an anaphor u and its antecedent y byy antecedes u.Two discourse referents u and y are said to be co-referential, 6 written ascoref(u~y)if any of the following holds:?
y antecedes u?
u antecedes y?
z antecedes u for some discourse referent z and coref(z.y)?
z antecedes y for some z and coref(z.u)Also, coref(u,u) is true for any discourse referent u.
The coref relation defines equiva-lence classes of discourse referents, with all discourse referents in an "anaphoric hain"forming one class:equiv(u) = {y I coref(u,y)}Each equivalence class of discourse referents (some of which consist of only onemember) has a salience weight associated with it.
This weight is the sum of the currentweight of all salience factors in whose scope at least one member of the equivalenceclass lies.Equivalence classes, along with the sentence recency factor and the salience degra-dation mechanism, constitute a dynamic system for computing the relative attentionalprominence of denotational NPs in text.2.2 The Resolut ion ProcedureRAP's procedure for identifying antecedents of pronouns is as follows...a.b.C.Create a list of IDs for all NPs in.
the current sentence and classify themas to their type (definite NP, pleonastic pronoun, other pronoun,indefinite NP).Examine all NPs occurring in the current sentence.Distinguish among NPs that evoke new discourse referents,those that evoke discourse referents which are presumablycoreferential with already listed discourse referents, and NPsthat are used non-referentially.Apply salience factors to the discourse referents evoked in theprevious step as appropriate.Apply the syntactic filter and reflexive binding algorithm (firstphase).6 We have not attempted to distinguish among various types of anaphoric relations between discoursereferents.
Our use of "coreference" is in the spirit of Sidner's (1981) "co-specification" and Webber's(1988) "referencem.
"542Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolutiond.
(i)(ii)If the current sentence contains any personal orpossessive pronouns, a list of pairs of IDs from thecurrent sentence is generated.
This list contains thepronoun-NP pairs in the sentence for which coreferencecan be ruled out on syntactic grounds (using theconditions tated above).If the current sentence contains any lexical anaphors(i.e., reciprocal or reflexive pronouns), a list of ID pairsis generated.
Each lexical anaphor is paired with all ofits possible antecedent binders.If any non-pleonastic pronouns are present in the currentsentence, attempt to identify their antecedents.
Resolution isattempted in the order of pronoun occurrence in the sentence.In the case of lexical anaphors (reflexive or reciprocal pronouns), the possible an-tecedent binders were identified by the anaphor binding algorithm.
If more than onecandidate was found, the one with the highest salience weight was chosen (see secondexample of Section 3.1).In the case of third person pronouns, resolution proceeds as follows:1.
A list of possible antecedent candidates i  created.
It contains the mostrecent discourse referent of each equivalence class.
The salience weightof each candidate is calculated and included in the list.
The salienceweight of a candidate can be modified in several ways:a.
If a candidate follows the pronoun, its salience weight isreduced substantially (i.e., cataphora is strongly penalized).b.
If a candidate fills the same slot as the pronoun, its weight isincreased slightly (i.e., parallelism of grammatical roles isrewarded).It is important to note that, unlike the salience factors described inSection 2.1.4, these modifications of the salience weights of candidatesare local to the the resolution of a particular pronoun.2.
A salience threshold is applied; only those candidates whose salienceweight is above the threshold are considered further.3.
The possible agreement features (number and gender) for the pronounare determined.
The possible sg (singular) and pl (plural) genders aredetermined; either of these can be a disjunction or nil.
Pronominal formsin many languages are ambiguous as to number and gender; suchambiguities are taken into account by RAP's morphological fi ter and bythe algorithm as a whole.
The search splits to consider singular andplural antecedents separately (steps 4--6) to allow a general treatment ofnumber ambiguity (as in the Spanish possessive pronoun su or theGerman pronoun sie occurring as an accusative object).4.
The best sg candidate (if any) is selected:a.
If no sg genders were determined for the pronoun, proceed toStep 5.b.
Otherwise, apply the morphological fi ter.543Computational Linguistics Volume 20, Number 4c.
The syntactic filter is applied, using the list of disjointpronoun-NP pairs generated earlier.
The filter excludes anycandidate paired in the list with the pronoun being resolved, aswell as any candidate that is anaphorically inked to an NPpaired with the pronoun.d.
If more than one candidate remains, choose the candidate withthe highest salience weight.
If several candidates have (exactly)the highest weight, choose the candidate closest o the anaphor.Proximity is measured on the surface string and is notdirectional.e.
The remaining candidate is considered the best sg candidate.5.
The best pl candidate (if any) is selected.
The procedure parallels thatoutlined above for the best sg candidate:a.
If no pl gender is specified for the pronoun, proceed to Step 6.b.
Otherwise, apply the morphological fi ter.c.
Apply the syntactic filter.d.
If more than one candidate remains, choose the candidate withthe highest salience weight; if several candidates have thehighest weight, choose the candidate closest o the anaphor.e.
The remaining candidate is considered the best pl candidate.6.
Given the best sg and pl candidates, find the best overall candidate:a.
If a sg candidate was found, but no pl candidate, or vice versa,choose that candidate as the antecedent.b.
If both a sg and a pl candidate were found, choose the candidatewith the greater salience weight (this will never arise in analysisof English text, as all English pronominal forms areunambiguous a  to number).7.
The selected candidate is declared to be the antecedent of the pronoun.The following properties of RAP are worth noting.
First, it applies a powerfulsyntactic and morphological filter to lists of pronoun-NP pairs to reduce the set ofpossible NP antecedents for each pronoun.
Second, NP salience measures are specifiedlargely in terms of syntactic properties and relations (as well as frequency of occur-rence).
These include a hierarchy of grammatical roles, level of phrasal embedding,and parallelism of grammatical role.
Semantic onstraints and real-world knowledgeplay no role in filtering or salience ranking.
Third, proximity of an NP relative to a pro-noun is used to select an antecedent in cases in which several candidates have equalsalience weighting.
Fourth, intrasentential antecedents are preferred to intersententialcandidates.
This preference is achieved by three mechanisms:?
An additional salience value is assigned to NPs in the current sentence.?
The salience values of antecedent candidates in preceding sentences areprogressively degraded relative to the salience values of NPs in thecurrent sentence.?
Proximity is used to resolve ties among antecedent candidates withequal salience values.The fifth property which we note is that anaphora is strongly preferred to cataphora.544Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution3.
Examples of RAP's OutputRAP generates the list of non-coreferential pronoun-NP pairs for the current sentence,the list of pleonastic pronouns, if any, in the current sentence, the list of possibleantecedent NP-lexical anaphor pairs, if any, for the current sentence, and the list ofpronoun-antecedent NP pairs that it has identified, for which antecedents may appearin preceding sentences in the text.
Each NP appearing in any of the first three lists isrepresented by its lexical head followed by the integer that corresponds to its positionin the sequence of tokens in the input string of the current sentence.
The NPs in thepairs of the pronoun-antecedent lis  are represented by their lexical heads followedby their IDs, displayed as a list of two integers.
73.1 Lexical AnaphorsAfter insta l lat ion of the option, the backup copy of the ReferenceDiskette was started for the computer to automat ica l ly  conf igureitself.Antecedent NP- - lex ica l  anaphor pairs.computer .18 - i tsel f .22Anaphor- -Antecedent  links.i tself .
(1.22) to computer.
(1.18)John ta lked to Bil l  about himself.Antecedent NP- - lex ica l  anaphor pairs.John.1 - himself .6,  B i l l .4  - h imsel f .6Anaphor- -Antecedent  links.h imself .
( l .6)  to John.
(1.1)In the second example, \]ohn.
(1.1) was preferred to 8i11.
(1.4) owing to its higher salienceweight.3.2 Pleonastic and Non-Lexical Anaphori?
Pronouns in the Same SentenceMost of the copyr ight not ices are embedded in the EXEC, but thiskeyword makes it poss ib le  for a user -suppl ied  funct ion to have itsown copyright notice.Non-coreferent ia l  pronoun- -NP pairs.it .16 - most.
l ,  i t .16 - notice.5,  it.16 - keyword.14,it .16 - funct ion.23, it.16 - user.20, it.16 - notice.29,it.16 - copyright.28,  i ts.26 - most.
l ,  i ts.26 - notice.5,i ts.26 - notice.29, its.26 - copyr ight .287 Recall that he first integer identifies the sentence in which the NP appears, and the second indicatesthe position of its head word in the sentence.545Computational Linguistics Volume 20, Number 4Pleonastic Pronouns.it.
16Anaphor- -Antecedent  links.its.
( l .26) to function.
(1.23)function.
(l.23) and keyword.
(l.14) share the highest salience weight of all candidatesthat pass the morphological nd syntactic filters; they are both subjects and thereforehigher in salience than the third candidate, ?XEC.(1.10).
function.
(1.23) is then selectedas the antecedent owing to its proximity to the anaphor.3.3 Multiple Cases of Intrasentential AnaphoraBecause of this, MicroEMACS cannot process an incoming ESC until itknows what character follows it.Non-coreferential pronoun--NP pairs.it.12 - character.15, it.l?
- character.15Anaphor--Antecedent links.it.
(l.12) to MicroEMACS.(l.4)it.
(l.iT) to ESC.(I.10)MicroEMACS.
(1.4) is preferred over ESC.
(1.10) as an antecedent of it.(1.12)--MicroEMACS.
(1.4) receives subject emphasis versus the lower object emphasis ofESC.(1.10).
In addition, MicroEMACS.
(1.4) is rewarded because it fills the same gram-matical role as the anaphor being resolved.In the case of it.
(1.17), the parallelism reward works in favor of ESC.
(1.10), causingit to be chosen, despite the general preference for subjects over objects.3.4 Intersentential and Intrasentential Anaphora in the Same SentenceAt this point, emacs is waiting for a command.It is prepared to see  if the variable keys are TRUE, and executessome lines if they are.Non-coreferential pronoun--NP pairs.it.1 - key.
O, it.1 - line.16, it.1 - they.18, they.18 - it.1Anaphor--Antecedent links.it.
(2.1) to emacs.(1.5)they.
(2.18) to key.
(2.0)3.5 Displaying Discourse ReferentsThe discourse referents currently defined can be displayed with their salience weights.The display for the two-sentence t xt of Section 3.4 is as follows: the members ofan equivalence class are displayed on one line.
Since salience factors from previoussentences are degraded by a factor of two when each new sentence is processed,546Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolutiondiscourse referents from earlier sentences that are not members of anaphoric hainsextending into the current sentence rapidly become "uncompetitive.
"Sal ience weight46531028013590Discourse referent(s)emacs.
( i .5) s( i t , l ) .
(2.1)s(key, l) .
(2.9) s(they, l ) .
(2.18)s( l ine, l ) .
(2.16)s(command,2).
( l .
lO)s(point,4) .
( l .3)3.6 Detailed Displays of Salience WeightsYou have not waited for the fi le to close.You may have asked to print on the virtual  printer, but it cannotprint unti l  the output f i le is closed.Non-coreferent ia l  pronoun--NP pairs:you.1 - pr inter.
lO, you.l  - it.13, you.l  - output.19,you.l  - f i le.20, it .13 - you.l, it .13 - output.19,it.13 - f i le .20Sal ience values:pr inter .
(2.10) - 270f i le.
(1.7) - 190Sal ience factor values:pr inter .
(2.10)sentence_rec - i00non_adverbial_emph - 50pobj_emph - 40head_emph - 80f i le.
( l .7)sentence_rec - 50non_adverbial_emph - 25subj_emph - 40head_emph - 40Local sal ience factor values:file.
(I.7)paral le l_roles_reward - 35Anaphor- -Antecedent  links:it .
(2.13) to pr inter .
(2.10)This example illustrates the strong preference for intrasentential ntecedents, print-er.
(2.10) is selected, despite the fact that it is much lower on the hierarchy of grammat-ical roles than the other candidate, file.
(1.7), which also benefits from the parallelismreward.
Degradation of salience weight for the candidate from the previous sentenceis substantial enough to offset these factors.The PARTNUM tag pr ints a part number on the document.&name.
's  init ial  sett ing places it on the back cover.547Computational Linguistics Volume 20, Number 4Non-core ferent ia l  p ronoun- -NP  pa i rs :i t .6  - se t t ing .4 ,  i t .6  - cover .
lOSa l ience  va lues :number .
(1 .7 )  - 175tag .
(1 .3 )  - 155scsym(name) .
(2 .1 )  - 150document .
(1 .10)  - 135PARTNUM.
(1 .2 )  - 75Sa l ience  fac tor  va lues :number .
( l .Z )sentence_rec  - 50non_adverb ia l _emph - 25acc_emph - 25head_emph - 40tag .
( l .3 ) .sentence_rec  - 50non_adverb ia l _emph - 25sub j_emph - 40head_emph - 40scsym(name) .
(2 .1 )sentence_rec  - I00non_adverb ia l _emph - 50PAKTNUM.
( I .2 )sentence_rec  - 50non_adverb ia l _emph - 25Loca l  sa l ience  fac tor  va lues :document .
( l .
lO)sentence_rec  - 50non_adverb ia l _emph - 25pob j_emph - 20head_emph - 40number .
( l ,7 )para l le l _ ro les_ reward  - 35Anaphor - -Antecedent  l inks :s ( i t , l ) .
(2 .6 )  to  s (number , l ) .
( l .7 )Four candidates receive a similar salience weighting in this example.
Two po-tential intrasentential candidates that would have received a high salience ranking,setting.
(2.4) and cover.
(2.10), are ruled out by the syntactic filter.
The remaining in-trasentential candidate, scsym(name).
(2.1) 8 ranks relatively low, as it is a possessivedeterminer- - i t  scores lower than two candidates from the previous sentence.
The par-allelism reward causes number.Off ) to be preferred.4.
Testing of RAP on Manual  TextsWe tuned RAP on a corpus of five computer manuals containing a total of approxi-mately 82,000 words.
From this corpus we extracted sentences with 560 occurrences8 &name.
is a document formatting symbol: it is replaced by a predefined character string when the textis formatted.
ESG treats uch symbols as being unspecified for number and gender; number may beassigned uring parsing, owing to agreement constraints.548Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora ResolutionTable 2Results of training phaseTotal Intersentential cases Intrasentential casesNumber of pronoun occurrences 560 89 471Number of cases that the algorithm 475 (85%) 72 (81%) 403 (86%)resolves correctlyof third person pronouns (including reflexives and reciprocals) and their antece-dents.
9In the training phase, we refined our tests for pleonastic pronouns and exper-imented extensively with salience weighting.
Our goal was, of course, to optimizeRAP's success rate with the training corpus.
We proceeded heuristically, analyzingcases of failure and attempting to eliminate them in as general a manner as possible.The parallelism reward was introduced at this time, as it seemed to make a sub-stantial contribution to the overall success rate.
A salience factor that was originallypresent, viz.
matrix emphasis, was revised to become the non-adverbial emphasis factor.In its original form, this factor contributed to the salience of any NP not contained ina subordinate clause or in an adverbial PP demarcated by a separator.
This was foundto be too general, especially since the relative positions of a given pronoun and itsantecedent candidates are not taken into account.
The revised factor could be thoughtof as an adverbial penalty factor, since it in effect penalizes NPS occurring in adverbialpps.
1?We also experimented with the initial weights for the various factors and with thesize of the parallelism reward and cataphora penalty, again attempting to optimizeRAP's overall success rate.
A value of 35 was chosen for the parallelism reward; thisis just large enough to offset the preference for subjects over accusative objects.
Amuch larger value (175) was found to be necessary for the cataphora penalty.
Thefinal results that we obtained for the training corpus are given in Table 2.Interestingly, the syntactic-morphological filter reduces the set of possible an-tecedents to a single NP, or identifies the pronoun as pleonastic in 163 of the 475cases (34%) that the algorithm resolves correctly.
11It significantly restricts the size ofthe candidate list in most of the other cases, in which the antecedent is selected on thebasis of salience ranking and proximity.
This indicates the importance of a powerfulsyntactic-morphological filtering component in an anaphora resolution system.We then performed a blind test of RAP on a test set of 345 sentences randomlyselected from a corpus of 48 computer manuals containing 1.25 million words.
12 Theresults which we obtained for the test corpus (without any further modifications ofRAP) are given in Table 3.13This blind test provides the basis for a comparative evaluation of RAP and Dagan's?
9 These sentences and those used in the blind test were edited slightly to overcome parse inaccuracies.Rather than revise the lexicon, we made lexical substitutions to improve parses.
In some casesconstructions had to be simplified.
However, such changes did not alter the syntactic relations amongthe pronoun and its possible antecedents.For a discussion of ESG's parsing accuracy, see McCord (1993).10 See comments at the end of Section 4 about refining RAP's measures of structural salience.11 Forty-three of the pronoun occurrences in the training corpus (~ 8%) were pleonastic; a random sampleof 245 pronoun occurrences extracted from our test corpus included 15 pleonastic pronouns (~ 6%).12 The test set was filtered in order to satisfy the conditions of our experiments on the role of statisticallymeasured lexical preference in enhancing RAP's performance.
See Section 5.1 for a discussion of these549Computational Linguistics Volume 20, Number 4Table 3Results of blind testTotal Intersentential cases Intrasentential casesNumber of pronoun occurrences 360 70 290Number of cases that the algorithm 310 (86%) 52 (74%) 258 (89%)resolves correctly(1992) system, RAPSTAT, which employs both RAP's salience weighting mechanismand statistically measured lexical preferences, as well as for a detailed analysis of therelative contributions of the various elements of RAP's salience weighting mechanismto its overall success rate.
We will discuss the blind test in greater detail in the followingsections.4.1 Limitations of the Current AlgorithmSeveral classes of errors that RAP makes are worthy of discussion.
The first occurswith many cases of intersentential naphora, such as the following:This green indicator is lit when the controller is on.It shows that the DC power supply voltages are at the correctlevels.Morphological and syntactic filtering exclude all possible intrasentential candidates.Because the level of sentential embedding does not contribute to RAP's salience weight-ing mechanism, indicator.
(1.3) and controller.
(1.8) are ranked equally, since both aresubjects.
RAP then erroneously chooses controller.
(1.8) as the antecedent, since it iscloser to the pronoun than the other candidate.The next class of errors involves antecedents hat receive a low salience weightingowing to the fact that the evoking NP is embedded in a matrix NP or is in anotherstructurally nonprominent position (such as object of an adverbial PP).The users you enroll may not necessarily be new to the systemand may already have a user profile and a system distributiondirectory entry.&ofc.
checks for the existence of these objects and onlycreates them as necessary.Despite the general preference for intrasentential candidates, user.
(1.2) is selected asthe antecedent, since the only factor contributing to the salience weight of object.
(2.8)is sentence recency.
Selectional restrictions or statistically measured lexical preferences(see Section 5) could clearly help in at least some of these cases.In another class of cases, RAP fails because semantic/pragmatic information isrequired to identify the correct antecedent.conditions.13 Proper esolution was determined by a consensus ofthree opinions, including that of the first author.550Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora ResolutionTable 4Relative contribution of elements of salience weighting mechanismTotal correct Correctly disagrees with RAP Incorrectly disagrees with RAPI 310 (86%)II 308 (86%) 2 4III 308 (86%) 2 4IV 302 (84%) 3 11V 301 (84%) 9VI 297 (83%) 12 25VII 294 (82%) 1 17VIII 231 (64%) 79IX 212 (59%) 21 119X 184 (51%) 17 143Again, the Migration Aid produces an exception reportautomatically at the end of every migration run.As you did with the function, use it to verify that the itemshave been restored to your system successfully.function.
(2.6) is selected as the antecedent, rather than aid.
(1.5).4.2 The Relative Contributions of the Salience Weighting MechanismsUsing the test corpus of our blind test, we conducted experiments with modifiedversions of RAP, in which various elements of the salience weighting mechanismwere switched off.
We present he results in Table 4 and discuss their significance.Ten variants are presented in Table 4; they are as follows:I "standard" RAP (as used in the blind test)II parallelism reward deactivatedIII non-adverbial nd head emphasis deactivatedIV matrix emphasis used instead of non-adverbial emphasisV cataphora penalty deactivatedVI subject, existential, accusative, and indirect object/oblique complementemphasis (i.e., hierarchy of grammatical roles) deactivatedVII equivalence classes deactivatedVIII sentence recency and salience degradation deactivatedIX all "structural" salience weighting deactivated (II +III + V + VI)X all salience weighting and degradation deactivatedThe single most important element of the salience weighting mechanism is therecency preference (sentence recency factor and salience degradation; see VIII).
This isnot surprising, given the relative scarcity of intersentential anaphora in our test corpus(less than 20% of the pronoun occurrences had antecedents in the preceding sentence).Deactivating the equivalence class mechanism also led to a significant deteriorationin RAP's performance; in this variant (VII), only the salience factors applying to a551Computational Linguistics Volume 20, Number 4particular NP contribute to its salience weight, without any contribution from otheranaphorically inked NPs.
The performance of the syntactic filter is degraded some-what in this variant as well, since NPs that are anaphorically linked to an NP fulfillingthe criteria for disjoint reference will no longer be rejected as antecedent candidates.The results for VII and VIII indicate that attentional state plays a significant role inpronominal anaphora resolution and that even a simple model of attentional state canbe quite effective.Deactivating the syntax-based elements of the salience weighting mechanism in-dividually led to relatively small deteriorations in the overall success rate (II, III, IV,V, and VI).
Eliminating the hierarchy of grammatical roles (VI), for example, led toa deterioration of less than 4%.
Despite the comparatively small degradation i per-formance that resulted from turning off these elements individually, their combinedeffect is quite significant, as the results of IX show.
This suggests that the syntacticsalience factors operate in a complex and highly interdependent manner for anaphoraresolution.X relies solely on syntactic/morphological filtering and proximity to choose anantecedent.
Note that the sentence pairs of the blind test set were selected so that,for each pronoun occurrence, at least two antecedent candidates remained after syn-tactic/morphological filtering (see Section 5.1).
In the 17 cases in which X correctlydisagreed with RAP, the proper antecedent happened to be the most proximate can-didate.We suspect hat RAP's overall success rate can be improved (perhaps by 5% ormore) by refining its measures of structural salience.
Other measures of embeddedness,or perhaps of "distance" between anaphor and candidate measured in terms of clausaland NP boundaries, may be more effective than the current mechanisms for non-adverbial and head emphasis.
14Empirical studies of patterns of pronominal anaphorain corpora (ideally in accurately and uniformly parsed corpora) could be helpful indefining the most effective measures of structural salience.
One might use such studiesto obtain statistical data for determining the reliability of each proposed measure as apredictor of the antecedent-anaphor relation and the orthogonality (independence) ofall proposed measures.5.
Salience and Statistically Measured Lexical PreferenceDagan (1992) constructs a procedure, which he refers to as RAPSTAT, for using sta-tistically measured lexical preference patterns to reevaluate RAP's salience rankingsof antecedent candidates.
RAPSTAT assigns a statistical score to each element of acandidate list that RAP generates; this score is intended to provide a measure (relativeto a corpus) of the preference that lexical semantic/pragmatic factors impose upon thecandidate as a possible antecedent for a given pronoun, is14 Such a distance measure is reminiscent of Hobbs' (1978) tree search procedure.
See Section 6.1 for adiscussion of Hobbs' algorithm and its limitations.The results for IV confirm our suspicions from the training phase that matrix emphasis (rewardingNPs not contained in a subordinate clause) does not contribute significantly to successful resolution.15 Assume that P is a non-pleonastic and non-reflexive pronoun in a sentence such that RAP generatesthe non-empty list L of antecedent candidates for P. Let H be the lexical head (generally a verb or anoun) of which P is an argument or an adjunct in the sentence.
RAPSTAT computes a statistical scorefor each element Ci of L, on the basis of the frequency, in a corpus, with which Ci occurs in the samegrammatical relation with H as P occurs with H in the sentence.
The statistical score that RAPSTATassigns to Ci is intended to model the probability of the event where Ci stands in the relevantgrammatical relation to H, given the occurrence of Ci (but taken independently of the other elementsof L).552Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora ResolutionRAPSTAT reevaluates RAP's ranking of the elements of the antecedent candidatelist L in a way that combines both the statistical scores and the salience values of thecandidates.
The elements of L appear in descending order of salience value.
RAPSTATprocesses L as follows.
Initially, it considers the first two elements Cl and C2 of L. If (i)the difference in salience scores between C1 and C2 does not exceed a parametricallyspecified value (the salience difference threshold) and (ii) the statistical score of C2 issignificantly greater than that of C1, then RAPSTAT will substitute the former for thelatter as the currently preferred candidate.
If conditions (i) and (ii) do not hold, RAP-STAT confirms RAP's selection of C1 as the preferred antecedent.
If these conditionsdo hold, then RAPSTAT selects C2 as the currently preferred candidate and proceedsto compare it with the next element of L. It repeats this procedure for each successivepair of candidates in L until either (i) or (ii) fails or the list is completed.
In either case,the last currently preferred candidate is selected as the antecedent.An example of a case in which RAPSTAT overules RAP is the following.The Send Message display is shown, allowing you to enter yourmessage and specify where it will be sent.The two top candidates in the list that RAP generates for it.
(1.17) are display.
(1.4) witha salience value of 345 and message.
(1.13), which has a salience value of 315.
In thecorpus that we used for testing RAPSTAT, the verb-object pair send-display ppearsonly once, whereas send-message occurs 289 times.
As a result, message receives aconsiderably higher statistical score than display.
The salience difference threshold thatwe used for the test is 100, and conditions (i) and (ii) hold for these two candidates.The difference between the salience value of message and the third element of thecandidate list is greater than 100.
Therefore, RAPSTAT correctly selects message as theantecedent of it.5.1 A Blind Test of RAP and RAPSTATDagan et al (in press) report a comparative blind test of RAP and RAPSTAT.
To con-struct a database of grammatical relation counts for RAPSTAT, we applied the SlotGrammar parser to a corpus of 1.25 million words of text from 48 computer manu-als.
We automatically extracted all lexical tuples and recorded their frequencies in theparsed corpus.
We then constructed a test set of pronouns by randomly selecting fromthe corpus sentences containing at least one non-pleonastic third person pronoun oc-currence.
For each such sentence in the set, we included the sentence that immediatelyprecedes it in the text (when the preceding sentence does not contain a pronoun).
16 Wefiltered the test set so that for each pronoun occurrence in the set, (i) RAP generates acandidate list with at least two elements, (ii) the actual antecedent NP appears in thecandidate list, and (iii) there is a total tuple frequency greater than 1 for the candidateSee Dagan 1992 and Dagan et al (in press) for a discussion ofthis lexical statistical pproach toranking antecedent candidates and possible alternatives.16 In the interests of simplicity and uniformity, we discarded sentence pairs in which the first sentencecontains apronoun.
We decided to limit the text preceding the sentence ontaining the pronoun to onesentence because we found that in the manuals which we used to tune the algorithm, almost all casesof intersentential anaphora involved an antecedent i  the immediately preceding sentence.
Moreover,the progressive d cline in the salience values of antecedent candidates in previous entences nsuresthat a candidate appearing ina sentence which is more than one sentence prior to the current one willbe selected only if no candidates xist in either the current or the preceding sentence.
As such cases arerelatively rare in the type of text we studied, we limited our test set to textual units containing thecurrent and the preceding sentence.553Computational Linguistics Volume 20, Number 4list (in most cases, it was considerably larger).
~7 The test set contains 345 sentencepairs with a total of 360 pronoun occurrences.
The results of the blind test for RAPand RAPSTAT are as follows.
TMRAP RAPSTATTotal correct: 310 (86%) 319 (89%)Total decided: 360 (100%) 182 (51%)Correctly decided: 310 (86%) 144 (79%)RAPSTATDisagrees with RAP:Correctly disagrees with RAP:Incorrectly disagrees with RAP:41 (22% of cases decided)25 (61%)16 (39%)RAP/RAPSTATBoth wrong:Either RAP or RAPSTAT is correct:22 (12%)335 (93%)When we further analyzed the results of the blind test, we found that RAPSTAT'ssuccess depends in large part on its use of salience information.
If RAPSTAT's statis-tically based lexical preference scores are used as the only criterion for selecting anantecedent, the statistical selection procedure disagrees with RAP in 151 out of 338instances.
RAP is correct in 120 (79%) of these cases and the statistical decision in 31(21%) of the cases.
When salience is factored into RAPSTAT's decision procedure, therate of disagreement between RAP and RAPSTAT declines harply, and RAPSTAT'sperformance slightly surpasses that of RAP, yielding the results that we obtained inthe blind test.In general, RAPSTAT is a conservative statistical extension of RAP.
It permits ta-tistically measured lexical preference tooverturn salience-based decisions only in casesin which the difference between the salience values of two candidates i small andthe statistical preference for the less salient candidate is comparatively arge.
~9 Thecomparative blind test indicates that incorporating statistical information on lexicalpreference patterns into a salience-based anaphora resolution procedure can yield amodest improvement in performance r lative to a system that relies only on syntacticsalience for antecedent selection.
Our analysis of these results also shows that statis-tically measured lexical preference patterns alone provide a far less efficient basis foranaphora resolution than an algorithm based on syntactic and attentional measures ofsalience.
2?6.
Comparison with Other Approaches to Anaphora ResolutionWe will briefly compare our algorithm with several other approaches to anaphoraresolution that have been suggested.17 In previous tests of RAP we found that it generates a candidate list that includes the correct antecedentof the pronoun in approximately 98% of the cases to which it applies.18 We take RAPSTAT as deciding a case when it considers at least two candidates rather than deferring toRAP after the initial candidate because of a large salience difference between this candidate and thenext one in the list.
In cases in which RAPSTAT does not make an independent decision, it endorsesRAP's selection.
RAPSTAT's total success rate includes both sorts of cases.19 John Justeson did the statistical analysis of the comparative blind test of RAP and RAPSTAT.
Theseresults are described in Dagan et al (in press).20 Dagan (1992) reaches a similar conclusion on the basis of a much smaller experiment.554Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolution6.1 Hobbs' AlgorithmHobbs' (1978) algorithm relies on a simple tree search procedure formulated in termsof depth of embedding and left-right order.
By contrast, RAP uses a multi-dimensionalmeasure of salience that invokes a variety of syntactic properties pecified in termsof the head-argument structures of Slot Grammar, as well as a model of attentionalstate.Hobbs' tree search procedure selects the first candidate ncountered by a left-right depth first search of the tree outside of a minimal path to the pronoun thatsatisfies certain configurational constraints.
The algorithm chooses as the antecedentof a pronoun P the first NPi in the tree obtained by left-to-right breadth-first traversalof the branches to the left of the path T such that (i) T is the path from the NPdominating P to the first NP or S dominating this NP, (ii) T contains an NP or S nodeN that contains the NP dominating P,and (iii) N does not contain NPi.
If an antecedentsatisfying this condition is not found in the sentence containing P,the algorithm selectsthe first NP obtained by a left-to-right breadth first search of the surface structures ofpreceding sentences in the text.We have implemented a version of Hobbs' algorithm for Slot Grammar.
The origi-nal formulation of the algorithm encodes yntactic constraints on pronominal naphorain the definition of the domain to which the search for an antecedent NP applies.
Inour implementation f the algorithm, we have factored out the search procedure andsubstituted RAP's syntactic-morphological filter for Hobbs' procedural filter.
Let theMods (modifiers) of a head H be the sisters of H in the Slot Grammar epresentationof the phrase that H heads.
Our specification of Hobbs' algorithm for Slot Grammaris as follows:..?4...,8..Find a node N1 such that (i) N1 contains the pronoun P; (ii) N1 is an S orNP; and (iii) it is not the case that there is a node N1, such that N1contains N1, and N1, satisfies (i) and (ii).Check the list of Mods of N1 left to right for NPs that are not elements ofthe list of pairs <P-NP> identified by the syntactic-morphological filteras noncoreferential and that occur to the left of RSelect he leftmost NP in the filtered list of NP Mods of N1.If this list is nil, then repeat steps 2 and 3 recursively for each Mod inthe list of Mods of N1, each Mod in this second list of Mods, etc., untilan NP antecedent is found.If no NP antecedent is found by applying step 4, then identify a node N2that is the first NP/S containing N1.If N2 is an NP and is not an element of the list of pairs <P-NP>identified by the filter, propose it as the antecedent.Otherwise, apply steps 2-4 to N2.If no antecedent NP is found, continue to apply steps 5 and 6 and thensteps 2-4 to progressively higher NP/S nodes.If no antecedent NPs are found at the highest S of the sentence, thentake N1 to be the highest S node of the immediately preceding sentenceand apply steps 2-4 to N1.555Computational Linguistics Volume 20, Number 4Table 5Results of blind test (Hobbs' algorithm)Total Intersentential cases Intrasentential casesNumber of pronoun occurrences 360 70Number of cases that the 295 (82%) 61 (87%)algorithm resolves correctlyNumber of cases for which HOBBS 22 9correctly disagrees with RAPNumber of cases for which HOBBS 38 4incorrectly disagrees with RAP290234 (81%)1334We ran this version of Hobbs' algorithm on the test set that we used for the blindtest of RAP and RAPSTAT; the results appear in Table 5.It is important o note that the test set does not include pleonastic pronouns orlexical anaphors (reflexive or reciprocal pronouns), neither of which are dealt with byHobbs' algorithm.
Moreover, our Slot Grammar implementation f the algorithm givesit the full advantage of RAP's syntactic-morphological filter, which is more powerfulthan the configurational filter built into the original specification of the algorithm.Therefore, the test results provide a direct comparison of RAP's salience metric andHobbs' search procedure.Hobbs' algorithm was more successful than RAP in resolving intersentential na-phora (87% versus 74% correct).
21 Because intersentential naphora is relatively rare inour corpus of computer manual texts and because RAP's success rate for intrasententialanaphora is higher than Hobbs' (89% versus 81%), RAP's overall success rate on theblind test set is 4% higher than that of our version of Hobbs' algorithm.
This indicatesthat RAP's salience metric provides a more reliable basis for antecedent selection thanHobbs' search procedure for the text domain on which we tested both algorithms.It is clear from the relatively high rate of agreement between RAP and Hobbs'algorithm on the test set (they agree in 83% of the cases) that there is a significantdegree of convergence between salience as measured by RAP and the configurationalprominence defined by Hobbs' search procedure.
This is to be expected in English,in which grammatical roles are identified by means of phrase order.
However, inlanguages in which grammatical roles are case marked and word order is relativelyfree, we expect that there will be greater divergence in the predictions of the twoalgorithms.
The salience measures used by RAP have application to a wider classof languages than Hobbs' order-based search procedure.
This procedure relies on acorrespondence of grammatical roles and linear precedence relations that holds for acomparatively small class of languages.6.2 Discourse Based MethodsMost of the work in this area seeks to formulate general principles of discourse struc-ture and interpretation and to integrate methods of anaphora resolution into a com-putational model of discourse interpretation (and sometimes of generation as well).Sidner (1981, 1983), Grosz, Joshi, and Weinstein (1983, 1986), Grosz and Sidner (1986),21 The difficulty that RAP encounters with such cases was discussed inSection 4.1.
We are experimentingwith refinements in RAP's scoring mechanism toimprove its performance in these and other cases.556Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora ResolutionBrennan, Friedman, and Pollard (1987), and Webber (1988) present different versionsof this approach.
Dynamic properties of discourse, especially coherence and focusing,are invoked as the primary basis for identifying antecedence andidates; electing acandidate as the antecedent of a pronoun in discourse involves additional constraintsof a syntactic, semantic, and pragmatic nature.In developing our algorithm, we have not attempted to consider elements of dis-course structure beyond the simple model of attentional state realized by equivalenceclasses of discourse referents, alience degradation, and the sentence recency saliencefactor.
The results of our experiments with computer manual texts (see Section 4.2)indicate that, at least for certain text domains, relatively simple models of discoursestructure can be quite useful in pronominal naphora resolution.
We suspect that manyaspects of discourse models discussed in the literature will remain computationallyintractable for quite some time, at least for broad-coverage systems.A more extensive treatment of discourse structure would no doubt improve theperformance of a structurally based algorithm such as RAP.
At the very least, for-matting information concerning paragraph and section boundaries, list elements, etc.,should be taken into account.
A treatment of definite NP resolution would also pre-sumably lead to more accurate resolution of pronominal anaphora, since it wouldimprove the reliability of the salience weighting mechanism.However, some current discourse-based approaches toanaphora resolution assigntoo dominant a role to coherence and focus in antecedent selection.
As a result, theyestablish a strong preference for intersentential over intrasentential anaphora resolu-tion.
This is the case with the anaphora resolution algorithm described by Brennan,Friedman, and Pollard (1987).
This algorithm is based on the centering approach tomodeling attentional structure in discourse (Grosz, Joshi, and Weinstein 1983, 1986).
22Constraints and rules for centering are applied by the algorithm as part of the selectionprocedure for identifying the antecedents of pronouns in a discourse.
The algorithmstrongly prefers intersentential antecedents that preserve the center or maximize con-tinuity in center change, to intrasentential antecedents that cause radical center shifts.This strong preference for intersentential antecedents is inappropriate for at least sometext domains--in our corpus of computer manual texts, for example, we estimatethat less than 20% of referentially used third person pronouns have intersententialantecedents.
23There is a second difficulty with the Brennan et al centering algorithm.
It uses ahierarchy of grammatical roles quite similar to that of RAP, but this role hierarchy doesnot directly influence antecedent selection.
Whereas th e hierarchy in RAP contributesto a multi-dimensional measure of the relative salience of all antecedent candidates,in Brennan et al 1987, it is used only to constrain the choice of the backward-lookingcenter, Cb, of an utterance.
It does not serve as a general preference measure for an-tecedence.
The items in the forward center list, Cf, are ranked according to the hier-archy of grammatical roles.
For an utterance U,, Cb(Un) is required to be the highestranked element of Cf(U~_I) that is realized in U,.
If an element E in the list of possible22 "A discourse segment consists of a sequence of utterances U1 , .
.
.
,  Urn.
With each utterance, Un isassociated with a list of forward-looking centers, Cf(Uti), consisting of those discourse ntities that aredirectly realized or realized by linguistic expressions in that utterance.
Ranking of an entity on this listcorresponds roughly to the likelihood that it will be the pr imary focus of subsequent discourse; thefirst entity on this list is the preferred center, Cp(Un).
Un actually centers, or is 'about,' only one entity ata time, the backward-looking center, Cb(U~).
The backward center is a confirmation of an entity that hasalready been introduced into the discourse; more specifically, it must  be realized in the immediatelypreceding utterance, Un--l" (Brennan, Friedman, and Pollard 1987, p. 155).23 This estimate is based on the small random sample used in our blind test (see Section 5.1).557Computational Linguistics Volume 20, Number 4forward centers, Cf(Un-1), is identified as the antecedent of a pronoun in Un, then E isrealized in Un.
The Brennan et al centering algorithm does not require that the highestranked element of Cf(Un-1) actually be realized in Un, but only that Cb(Un) be the high-est ranked element of Cf(Un-1) which is, in fact, realized in Un.
Antecedent selectionis constrained by rules that sustain cohesion in the relations between the backwardcenters of successive utterances in a discourse, but it is not determined irectly by therole hierarchy used to rank the forward centers of a previous utterance.
Therefore, anNP in Un_~ that is relatively low in the hierarchy of grammatical  roles can serve as anantecedent of a pronoun in Un, provided that no higher ranked NP in Un-1 is taken asthe antecedent of some other pronoun or definite NP in Un.24 An example will serveto illustrate the problem with this approach.The display shows you the status of all the printers.It also provides options that control printers.The (ranked) forward center list for the first sentence is as follows:(\[DISPLAY\] \[STATUS\] \[YOU\] \[PRINTERS3).Applying the filters and ranking mechanism of Brennan, Friedman, and Pollard (1987)yields two possible anchors.
2s Each anchor determines a choice of Cb(Un) and theantecedent of it.
One anchor identifies both with display, whereas the second takesboth to be status.
The hierarchy of grammatical  roles is not used to select display overstatus.
Nothing in the algorithm rules out the choice of status as the backward centerfor the second sentence and as the antecedent of it.
If this selection is made, display isnot realized in the second sentence, and so Cb(Un) is status, which is then the highestranked element of Cf(Un-1) that is realized in Un, as required by constraint 3 of theBrennan et al centering algorithm.In general, we agree with Alshawi (1987, p. 62) that an a lgor i thm/model  relyingon the relative salience of all entities evoked by a text, with a mechanism for removingor filtering entities whose salience falls below a threshold, is preferable to models that"make assumptions about a single (if shifting) focus of attention.
"266.3 Mixed ModelsThis approach seeks to combine a variety of syntactic, semantic, and discourse factorsinto a multi-dimensional metric for ranking antecedent candidates.
On this view, thescore of a candidate is a composite of several distinct scoring procedures, each of whichreflects the prominence of the candidate with respect o a specific type of informationor property.
The systems described by Asher and Wada (1988), Carbonell and Brown(1988), and Rich and LuperFoy (1988) are examples of this mixed evaluation strategy.In general, these systems use composite scoring procedures that assign a globalrank to an antecedent candidate on the basis of the scores that it receives from several24 Other factors, such as level of embedding, may also be considered ingenerating an ordering for the listof forward-looking centers.
Walker, Iida, and Cote (1990) discuss ordering conditions appropriate forJapanese.25 An anchor is an association between abackward-looking center, Cb, and a list of forward-lookingcenters, Cf, for an utterance.
An anchor establishes a link between apronoun and its antecedent byassociating the reference marker of the antecedent with that of the pronoun in the Cf list of theutterance.26 See Walker (1989) for a comparison of the algorithm of Brennan, Friedman, and Pollard (1987) withthat of Hobbs (1978) based on a hand simulation.558Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora Resolutionevaluation metrics.
Each such metric scores the likelihood of the candidate relative toa distinct informational factor.
Thus, for example, Rich and LuperFoy (1988) proposea system that computes the global preference value of a candidate from the scoresprovided by a set of constraint source modules, in which each module invokes dif-ferent sorts of conditions for ranking the antecedent candidate.
The set of modulesincludes (among others) syntactic and morphological filters for checking agreementand syntactic onditions on disjoint reference, a procedure for applying semantic se-lection restrictions to a verb and its arguments, a component that uses contextual ndreal-world knowledge, and modules that represent both the local and global focus ofdiscourse.
The global ranking of an antecedent candidate is a function of the scoresthat it receives from each of the constraint source modules.Our algorithm also uses a mixed evaluation strategy.
We have taken inspirationfrom the discussions of scoring procedures in the works cited above, but we haveavoided constraint sources involving complex inferencing mechanisms and real-worldknowledge, typically required for evaluating the semantic/pragmatic suitability of an-tecedent candidates or for determining details of discourse structure.
In general, itseems to us that reliable large scale modelling of real-world and contextual factors isbeyond the capabilities of current computational systems.
Even constructing a com-prehensive, computationally viable system of semantic selection restrictions and anassociated type hierarchy for a natural anguage is an exceedingly difficult problem,which, to our knowledge, has yet to be solved.
Moreover, our experiments with sta-tistically based lexical preference information casts doubt on the efficacy of relativelyinexpensive (and superficial) methods for capturing semantic and pragmatic factors forpurposes of anaphora resolution.
Our results suggest hat scoring procedures whichrely primarily on tractable syntactic and attentional (recency) properties can yield abroad coverage anaphora resolution system that achieves a good level of performance.7.
Conc lus ionWe have designed and implemented an algorithm for pronominal naphora resolutionthat employs measures of discourse salience derived from syntactic structure and asimple dynamic model of attentional state.
We have performed a blind test of thisalgorithm on a substantial set of cases taken from a corpus of computer manual textand found it to provide good coverage for this set.
It scored higher than a version ofHobbs' algorithm that we implemented for Slot Grammar.Results of experiments with the test corpus show that the syntax-based lementsof our salience weighting mechanism contribute in a complexly interdependent way tothe overall effectiveness of the algorithm.
The results also support he view that atten-tional state plays a significant role in pronominal naphora resolution and demonstratethat even a simple model of attentional state can be quite effective.The addition of statistically measured lexical preferences tothe range of factors thatthe algorithm considers only marginally improved its performance on the blind testset.
Analysis of the results indicates that lexical preference information can be useful incases in which the syntactic salience ranking does not provide a clear decision amongthe top candidates, and there is a strong lexical preference for one of the less salientcandidates.The relatively high success rate of the algorithm suggests the viability of a com-putational model of anaphora resolution in which the relative salience of an NP indiscourse is determined, in large part, by structural factors.
In this model, semanticand real-world knowledge conditions apply to the output of an algorithm that re-solves pronominal anaphora on the basis of syntactic measures of salience, recency,559Computational Linguistics Volume 20, Number 4and frequency of mention.
These conditions are invoked only in cases in which saliencedoes not provide a clear-cut decision and/or  there is substantial semantic-pragmaticsupport for one of the less salient candidates.
27AcknowledgmentsWe would like to thank Martin Chodorow,Ido Dagan, John Justeson, Slava Katz,Michael McCord, Hubert Lehman, AmnonRibak, Ulrike Schwall, and Marilyn Walkerfor helpful discussion of many of the ideasand proposals presented here.
The blind testand evaluation of RAPSTAT reported herewas done jointly with Ido Dagan, JohnJusteson, and Amnon Ribak.
An earlyversion of this paper was presented at theCognitive Science Colloquium of theUniversity of Pennsylvania, in January 1992,and we are grateful to the participants ofthe colloquium for their reactions andsuggestions.
We are also grateful to severalanonymous reviewers of ComputationalLinguistics for helpful comments on earlierdrafts of the paper.ReferencesAlshawi, Hiyan (1987).
Memory and Contextfor Language Interpretation.
Cambridge:Cambridge University Press.Asher, Nicholas, and Wada, Hajime (1988).
"A computational ccount of syntactic,semantic and discourse principles foranaphora resolution."
Journal of Semantics6:309-344.Bosch, Peter (1988).
"Some good reasons forshallow pronoun processing."
InProceedings, IBM Conference on NaturalLanguage Processing.
New York:Thornwood.Brennan, Susan; Friedman, Marilyn; andPollard, Carl (1987).
"A centeringapproach to pronouns."
In Proceedings,25th Annual Meeting of the Association forComputational Linguistics, 155-162.Carbonell, Jaime, and Brown, Ralf (1988).
"Anaphora resolution: A multi-strategyapproach."
In Proceedings, 12thInternational Conference on ComputationalLinguistics, 96-101.Dagan, Ido (1992).
"Multilingual statisticalapproaches for natural anguagedisambiguation" (in Hebrew).
Doctoraldissertation, Israel Institute of Technology,Haifa, Israel.Dagan, Ido; Justeson, John; Lappin, Shalom;Leass, Herbert; and Ribak, Amnon (inpress).
"Syntax and lexical statistics inanaphora resolution."
Applied ArtificialIntelligence.Grosz, Barbara; Joshi, Aravind; andWeinstein, Scott (1983).
"Providing aunified account of definite noun phrasesin discourse."
In Proceedings, 21st AnnualMeeting of the Association of ComputationalLinguistics, 44-50.Grosz, Barbara; Joshi, Aravind; andWeinstein, Scott (1986, unpublished).
"Towards a computational theory ofdiscourse interpretation."
HarvardUniversity and University ofPennsylvania.Grosz, Barbara, and Sidner, Candice (1986).
"Attention, intentions, and the structureof discourse."
Computational Linguistics12:175-204.Guenthner, Franz, and Lehmann, Hubert(1983).
"Rules for pronominalization."
InProceedings, First Annual Meeting of theEuropean Chapter of the ACL, 144-151.Hobbs, Jerry (1978).
"Resolving pronounreferences."
Lingua 44:311-338.Johnson, David (1977).
"On relationalconstraints on grammars."
In Syntax andSemantics 8,edited by P. Cole andJ.
Sadock, 151-178.
New York: AcademicPress.Kamp, Hans (1981).
"A theory of truth andsemantic representation."
In FormalMethods in the Study of Language, dited byJ.
Groenendijk, T. Janssen, andM.
Stokhof.
Amsterdam: MathematischCentrum Tracts.Keenan, Edward, and Comrie, Bernard(1977).
"Noun phrase accessibility anduniversal grammar."
Linguistic Inquiry8:62-100.Lappin, Shalom (1985).
"Pronominalbinding and coreference."
TheoreticalLinguistics 12:241-263.Lappin, Shalom, and McCord, Michael(1990a).
"A syntactic filter on pronominalanaphora in slot grammar."
In Proceedings,28th Annual Meeting of the Association forComputational Linguistics, 135-142.Lappin, Shalom, and McCord, Michael(1990b).
"Anaphora resolution in slotgrammar."
Computational Linguistics16:197-212.27 Bosch (1988) suggests a psychological processing model in which hearers rely on first pass syntacticallybased strategies for initial linking of pronouns to antecedent NPs.560Shalom Lappin and Herbert J. Leass An Algorithm for Pronominal Anaphora ResolutionLeass, Herbert, and Schwall, Ulrike (1991).
"An anaphora resolution procedure formachine translation."
IWBS Report 172,IBM Germany Scientific Center,Heidelberg, Germany.McCord, Michael (1989a).
"Design of LMT:A prolog-based machine translationsystem."
Computational Linguistics15:33-52.McCord, Michael (1989b).
"A new versionof the machine translation system LMT.
"Literary and Linguistic Computing 4:218-229.McCord, Michael (1990).
"Slot grammar: Asystem for simpler construction ofpractical natural anguage grammars."
InNatural Language and Logic: InternationalScientific Symposium, edited by R. Studer,118-145.
Lecture Notes in ComputerScience, Berlin: Springer Verlag.McCord, Michael (1993).
"Heuristics forbroad-coverage natural anguageparsing."
In Proceedings, ARPA HumanLanguage Technology Workshop, Universityof Pennsylvania.McCord, Michael (in press).
"The slotgrammar system."
In Unification inGrammar, edited by Jiirgen Wedekin andChristian Rohrer (also IBM ResearchReport RC 17313).
Cambridge, MA: MITPress.McCord, Michael; Bernth, Arendse; Lappin,Shalom; and Zadrozny, Wlodek (1992).
"Natural anguage processing within aslot grammar framework."
InternationalJournal on Artificial Intelligence Tools1:229-277.Rich, Elaine, and LuperFoy, Susann (1988).
"An architecture for anaphora resolution.
"In Proccedings, ACL Conference on AppliedNatural Language Processing, 18-24.Sidner, Candice (1981).
"Focusing forinterpretation of pronouns."
AmericanJournal of Computational Linguistics7:217-231.Sidner, Candice (1983).
"Focusing in thecomprehension f definite anaphora."
InComputational Models of Discourse, editedby Michael Brady and Robert Berwick,267-330.
Cambridge, MA: MIT Press.Walker, Marilyn (1989).
"Evaluatingdiscourse processing algorithms."
InProceedings, 27th Annual Meeting of theAssociation for Computational Linguistics,251-261.Walker, Marilyn; Iida, Masayo; and Cote,Sharon (1990).
"Centering in Japanesediscourse."
In Proceedings, 13thInternational Conference on ComputationalLinguistics, 1-6.Webber, Bonnie (1988).
"Discourse Deixis:Reference to discourse segments."
InProceedings, 26th Annual Meeting of theAssociation for Computational Linguistics,113-121.Williams, Edwin (1984).
"Grammaticalrelations."
Linguistic Inquiry 15:639~73.561
