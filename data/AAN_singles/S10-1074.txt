Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 333?336,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsEdinburgh-LTG: TempEval-2 System DescriptionClaire Grover, Richard Tobin, Beatrice Alex and Kate ByrneUniversity of EdinburghEdinburgh, United Kingdom{grover, richard, balex, kbyrne3}@inf.ed.ac.ukAbstractWe describe the Edinburgh informationextraction system which we are currentlyadapting for analysis of newspaper textas part of the SYNC3 project.
Our mostrecent focus is geospatial and temporalgrounding of entities and it has been use-ful to participate in TempEval-2 to mea-sure the performance of our system and toguide further development.
We took partin Tasks A and B for English.1 BackgroundThe Language Technology Group (LTG) at Edin-burgh has been active in the field of informationextraction (IE) for a number of years.
Up until re-cently our main focus has been in biomedical IE(Alex et al, 2008) but we have also been pursuingprojects in other domains, e.g.
digitised histori-cal documents (Grover et al, 2010) and we arecurrently participants in the EU-funded SYNC3project where our role is to analyse news arti-cles and establish spatio-temporal and other re-lations between news events.
As a step towardsthis goal, we have been extending and adaptingour IE pipeline to ground spatial and temporal en-tities.
We have developed the Edinburgh Geop-arser for georeferencing documents and have eval-uated our system against the SpatialML corpus,as reported in Tobin et al (2010).
We are cur-rently in the process of developing a rule-baseddate and time grounding component and it is thiscomponent that we used for Task A, which re-quires systems to identify the extents of tempo-ral named entities and provide their interpreta-tion.
The TempEval-2 data also contains event en-tities and we have adapted the output of our in-house chunker (Grover and Tobin, 2006) to iden-tify events for Task B, which requires systems toidentify event denoting words and to compute arange of attributes for them.
In future work we willadapt our machine-learning-based relation extrac-tion component (Haddow, 2008) to recognise re-lations between spatial and temporal entities andevent entities along the lines of the linking tasks.2 The Edinburgh IE SystemOur IE system is a modular pipeline system builtaround the LT-XML21and LT-TTT22toolsets.Documents are converted into our internal doc-ument format and are then passed through a se-quence of linguistic components which each addXML mark-up.
Early stages identify paragraphs,sentences and tokens.
Part-of-speech (POS) tag-ging is done using the C&C tagger (Curran andClark, 2003a) and lemmatisation is done usingmorpha (Minnen et al, 2000).We use both rule-based and machine-learningnamed entity recognition (NER) components, theformer implemented using LT-TTT2 and the lat-ter using the C&C maximum entropy NER tagger(Curran and Clark, 2003b).
We are experiment-ing to find the best combination of the two dif-ferent NER views but this is not an issue in thecase of date and time entities since we have takenthe decision to use the rule-based output for these.The main motivation for this decision arises fromthe need to ground (provide temporal values for)these entities and the rules for the grounding aremost naturally implemented as an elaboration ofthe rules for recognition.Our IE pipeline also uses the LT-TTT2 chun-ker to provide a very shallow syntactic analysis.Figure 1 shows an example of the results of pro-cessing at the point where the rule-based NERand chunker have both applied.
As can be seenfrom Figure 1, a positive feature for TempEval-2 is that the verb group analysis provides in-formation about tense, aspect, voice, modalityand polarity which translate relatively straightfor-wardly into the Task B attributes.
The noun groupanalysis provides verbal stem information (e.g.1www.ltg.ed.ac.uk/software/ltxml22www.ltg.ed.ac.uk/software/lt-ttt2333<s id="s1"><ng><w p="DT" id="w13">The</w><w p="NN" id="w17" l="announcement" vstem="announce" headn="yes">announcement</w></ng><vg tense="pres" voice="pass" asp="simple" modal="yes" neg="yes"><w p="MD" id="w30" pws="yes" l="must" neg="yes">must</w><w p="RB" id="w35" pws="yes" neg="yes">not</w><w p="VB" id="w39" pws="yes" l="be">be</w><w p="VBN" id="w42" pws="yes" l="make" headv="yes">made</w></vg><ng><timex unit="day" trel="same" type="date" id="rb1"><w unit="day" trel="same" p="NN" id="w47" l="today">today</w></timex></ng><w p="."
id="w52" sb="true">.</w></s>Figure 1: Example of NER tagger and chunker output for the sentence ?The announcement must not bemade today.
?vstem="announce") about nominalisations.Various attributes are computed for <timex>elements and these are used by a temporal resolu-tion component to provide a grounding for them.The final output of the IE pipeline contains entitymark-up in ?standoff?
format where the entitiespoint at the word elements using ids.
The dateand event entities for ?made?
and ?today?
are asfollows:<ent tense="pres" voice="pass" neg="yes"modal="yes" asp="simple" id="ev1"subtype="make" type="event"><parts><part ew="w39" sw="w39">made</part></parts></ent><ent wdaynum="5" day="Friday" date="16"month="4" year="2010" unit="day"day-number="733877" trel="same"type="date" id="rb1"><parts><part ew="w47" sw="w47">today</part></parts></ent>The date entity has been grounded with respectto the date of writing (16th April 2010).
To do thegrounding we calculate a day-number value foreach date where the day number count starts from1st January 1 AD.
Using this unique day numberwe are able to calculate the date for any given daynumber as well as the day of the week.
We usethe day number to perform simple arithmetic toground date expressions such as ?last Monday?,?the day after tomorrow?
etc.
Grounding informa-tion is spread across the attributes for day, date,month and year.
A fully grounded date has avalue for all of these while an underspecified date,e.g.
?2009?, ?March 13th?, ?next year?, etc., onlyhas values for some of these attributes.3 Adaptations for TempEval-2Our system has been developed independently ofTimeML or TempEval-2 and there is therefore agap between what our system outputs and what iscontained in the TempEval-2 data.
In order to runour system over the data we needed to convert itinto our XML input format while preserving thetokenisation decisions from the original.
Certaintokenisation mismatches required that we extendvarious rules to allow for alternative token bound-aries, for example, we tokenise ?wasn?t?
as was +n?t whereas the TempEval-2 data contains was+ n + ?t or occasionally wasn + ?t.Other adaptations fall broadly into two classes:extension of our system to cover entities inTempEval-2 that we didn?t previously recognise,and mapping of our output to fit TempEval-2 re-quirements.3.1 ExtensionsThe date and time entities that our system recog-nises are more like the MUC7 TIMEX entities(Chinchor, 1998) than TIMEX3 ones.
In partic-ular, we have focused on dates which can eitherbe fully grounded or which, though underspeci-fied, can be grounded to a precise range, e.g.
?lastmonth?
can be grounded to a particular month andyear given a document creation date and it can beprecisely specified if we take it to express a rangefrom the first to last days of the month.
TIMEX3entities can be vaguer than this, for example, en-tities of type DURATION such as ?twenty years?,?some time?, etc.
can be recognised as denotinga temporal period but cannot easily be grounded.To align our output more closely to TempEval-2, we added NER rules to recognise examples334such as ?a long time?, ?recent years?, ?the past?,?years?, ?some weeks?, ?10 minutes?.
In additionwe needed to compute appropriate information toallow us to create TempEval-2 values such as P1W(period of 1 week).For event recognition, our initial system createdan event entity for every head verb and for ev-ery head noun which was a nominalisation.
Thissimple approach goes a long way towards captur-ing the TempEval-2 events but results in too manyfalse positives and false negatives for nouns.
Inaddition our system did not calculate the informa-tion needed to compute the TempEval-2 class at-tribute.
To help improve performance we addedattributes to potential event entities based on look-up in lexicons compiled from the training data andfrom WordNet (Fellbaum, 1998).
These attributescontribute to the decision as to whether a nounor verb chunk head should be an event entity ornot3.
The lexicons derived from the training datacontain the stems of all the nouns which actedmore than once as events as well as informationabout those predicates which occurred more thanonce as class ASPECTUAL, I STATE, REPORT-ING or STATE in the training data.
Where look-up succeeds for event, if class look-up also suc-ceeds then the class attribute is set accordingly.
Ifclass look-up fails, the default, OCCURRENCE,is used.
The WordNet derived lexicon contains in-formation about whether the first sense of a nounhas event or state as a hypernym.
As a result of thelexical look-up stage, the noun ?work?, for exam-ple, is marked as having occurred in the trainingdata as an event and as having event as a hyper-nym for its first sense.
The conjunction of thesecause it to be considered to be an event entity.
Forverbs, the only substantive change in our systemwas to not consider as events all main verb usesof ?be?
(be happy), ?have?
(have a meal) and ?do?
(do the dishes).3.2 MappingFor both timex and event entities the creationof the extents files was a straightforward map-ping.
For the creation of the attributes files,on the other hand, we used stylesheets to con-struct appropriate values for the TempEval-2 at-tributes based on the attributes in our outputXML.
The construction of event attributes is notoverly complex: for example, where an evententity is specified as tense="nonfin" and3Our system does not recognise adjective events.
How-ever, passive participles, which are sometimes treated as ad-jectives in TempEval-2, are frequently treated as verbs in oursystem and are therefore recognised.voice="pass" the TempEval-2 tense attributeis given the value PASTPART.
For modality ourattribute only records whether a modal verb ispresent or not, so it was necessary to set theTempEval-2 modality attribute to the actual modalverb inside the verb group.For timex entities, a single value for the valueattribute had to be constructed from the valuesof a set of attributes on our entity.
For example,the information in date="16", month="4"year="2010" has to be converted to 2010-04-16.
For durations other attributes provide the rel-evant information, for example for ?two days?
theattributes unit="day", quty="2" are usedto create the value P2D (period of 2 days).4 Evaluation and Error AnalysisThe recognition results for both timex and eventextents are shown in Table 1.
For Task A (timex)we achieved a close balance between precision andrecall, while for Task B (events) we erred towardsrecall at some cost to precision.Task Precision Recall F1Task A 0.85 0.82 0.84Task B 0.75 0.85 0.80Table 1: Extent ResultsFor timex entities our false negatives were allentities of the vaguest kind, for example, ?10-hour?, ?currently?, ?third-quarter?, ?overnight?,?the week?
: these are ones which the original sys-tem did not recognise and for which we added ex-tra rules, though evidently we were not thoroughenough.
The false positives were mostly of thekind that would usually be a date entity but whichwere not considered to be so in the key, for exam-ple, ?1969?, ?Oct 25?, ?now?, ?the past?, ?a fewdays?.
In two cases the system mistakenly identi-fied numbers as times (?1.02?, ?2.41?
).For event entities we had 73 false negatives.Some of these were caused by verbs beingmistagged as nouns (?complies?, ?stretch?, ?suit?
)while others were nouns which didn?t occur inthe WordNet derived lexicon as events.
Therewere 143 event false positives.
Some of theseare clearly wrong, for example, ?destruction?
in?weapons of mass destruction?
while others area consequence of the subtle distinctions that theTempEval-2 guidelines make and which our shal-low approach cannot easily mimic.Table 2 shows the results for attribute detec-tion for both tasks.
In the case of timex attributes335Task Attribute ScoreTask A type 0.84value 0.63Task B polarity 0.99pos 0.97modality 0.99tense 0.92aspect 0.98class 0.76Table 2: Attribute Resultsthere was a set of entities which had systematicallywrong values for both type and value: these weredates such as ?this week?
and ?last week?.
Theseshould have had DATE as their type and a valuesuch as 1998-W19 to indicate exactly which weekin which year they denote.
Our date groundingdoes not currently cover the numbering of weeksin a year and so it would not have been possibleto create appropriate values.
Instead we incor-rectly treated these entities as being of type DU-RATION with value P1W.
Many of the remainingerrors were value errors where the system resolvedrelative dates as past references when they shouldhave been future or vice versa.
For example, thevalue for ?Monday?
in ?He and Palestinian leaderYasser Arafat meet separately Monday with ...?should have been 1998-05-04 but our system in-terpreted it as the past Monday, 1998-04-27.
Therewere a few cases where the value was correct butinsufficient, for example for ?a year ago?
the sys-tem returned 1988 when it should have produced1988-Q3.Our scores for event attributes were high for allattributes except for class.
The high scoring at-tributes were derived from the output of our chun-ker and demonstrate the quality of this component.There does not appear to be a particular patternbehind the small number of errors for these at-tributes except that errors for the pos attribute re-flect POS tagger errors and there were some com-bined tense and modality errors where ?will?
and?would?
should have been interpreted as futuretense but were instead treated as modals.
The classattribute represents information that our systemhad not previously been designed to determine.We computed the class attribute in a relativelyminimal way.
Since the class value is OCCUR-RENCE in nearly 60% of events in the trainingdata, we use this as the default but, as described inSection 3, we override this for events which are inour training data-derived lexicon as REPORTING,ASPECTUAL, I STATE or STATE.
We do not at-tempt to assign the I ACTION class value andnearly half of our class errors result from this.
An-other set of errors comes from missing REPORT-ING events such as ?alleging?, ?telegraphed?
and?acknowledged?.AcknowledgementsThe current phase of development of the Ed-inburgh IE system is supported by the SYNC3project (FP7-231854)4.ReferencesBeatrice Alex, Claire Grover, Barry Haddow, MijailKabadjov, Ewan Klein, Michael Matthews, RichardTobin, and Xinglong Wang.
2008.
Automating cu-ration using a natural language processing pipeline.Genome Biology, 9(Suppl 2).Nancy A. Chinchor.
1998.
Proceedings of the Sev-enth Message Understanding Conference (MUC-7).Fairfax, Virginia.James R. Curran and Stephen Clark.
2003a.
Inves-tigating GIS and smoothing for maximum entropytaggers.
In Proceedings of the 11th Meeting of theEuropean Chapter of the Association for Compu-tational Linguistics (EACL-03), pages 91?98.
Bu-dapest, Hungary.James R. Curran and Stephen Clark.
2003b.
Languageindependent NER using a maximum entropy tagger.In Proceedings of the 7th Conference on NaturalLanguage Learning, Edmonton, Alberta, Canada.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press, Cambridge,MA.Claire Grover and Richard Tobin.
2006.
Rule-basedchunking and reusability.
In Proceedings of the FifthInternational Conference on Language Resourcesand Evaluation (LREC 2006).Claire Grover, Richard Tobin, Kate Byrne, MatthewWoollard, James Reid, Stuart Dunn, and Julian Ball.2010.
Use of the Edinburgh geoparser for georefer-encing digitised historical collections.
Phil.
Trans.R.
Soc.
A.Barry Haddow.
2008.
Using automated feature op-timisation to create an adaptable relation extractionsystem.
In Proc.
of BioNLP 2008, Columbus, Ohio.Guido Minnen, John Carroll, and Darren Pearce.
2000.Robust, applied morphological generation.
In Pro-ceedings of the 1st International Natural LanguageGeneration Conference, Mitzpe Ramon, Israel.Richard Tobin, Claire Grover, Kate Byrne, James Reid,and Jo Walsh.
2010.
Evaluation of georeferencing.In Proceedings of Workshop on Geographic Infor-mation Retrieval (GIR?10).4http://www.sync3.eu/336
