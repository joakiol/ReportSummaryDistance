Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 278?288,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsExploiting Zero Pronouns to Improve Chinese Coreference ResolutionFang KongDepartment of Computer ScienceNational University of Singapore13 Computing DriveSingapore 117417dcskf@nus.edu.sgHwee Tou NgDepartment of Computer ScienceNational University of Singapore13 Computing DriveSingapore 117417nght@comp.nus.edu.sgAbstractCoreference resolution plays a critical rolein discourse analysis.
This paper focuseson exploiting zero pronouns to improve Chi-nese coreference resolution.
In particular, asimplified semantic role labeling frameworkis proposed to identify clauses and to detectzero pronouns effectively, and two effectivemethods (refining syntactic parser and refininglearning example generation) are employed toexploit zero pronouns for Chinese coreferenceresolution.
Evaluation on the CoNLL-2012shared task data set shows that zero pronounscan significantly improve Chinese coreferenceresolution.1 IntroductionAs one of the most important tasks in discourseanalysis, coreference resolution aims to link a givenmention (i.e., entity or event) to its co-referring ex-pression in a text and has been a focus of research innatural language processing (NLP) for decades.Over the last decade, various machine learningtechniques have been applied to coreference reso-lution and have performed reasonably well (Soonet al 2001; Ng and Cardie, 2002; Fernandes et al2012).
Current techniques rely primarily on surfacelevel features such as string match, syntactic featuressuch as apposition, and shallow semantic featuressuch as number, gender, semantic class, etc.Despite similarities between Chinese and English,there are differences that have a significant impacton coreference resolution.
In this paper, we focuson exploiting one of the key characteristics of Chi-nese text, zero pronouns (ZPs), to improve Chinesecoreference resolution.
In particular, a simplified se-mantic role labeling (SRL) framework is proposedto identify Chinese clauses and to detect zero pro-nouns effectively, and two effective methods are em-ployed to exploit zero pronouns for Chinese corefer-ence resolution.
Experimental results show the ef-fectiveness of our approach in improving the perfor-mance of Chinese coreference resolution.
Our workis novel in that it is the first work that incorporatesthe use of zero pronouns to significantly improveChinese coreference resolutionThe rest of this paper is organized as follows.Section 2 describes our baseline Chinese corefer-ence resolution system.
Section 3 motivates howthe detection of zero pronouns can improve Chinesecoreference resolution, using an illustrating exam-ple.
Section 4 presents our approach to detect zeropronouns.
Section 5 proposes two methods to ex-ploit zero pronouns to improve Chinese coreferenceresolution, based on a corpus study and preliminaryexperiments.
Section 6 briefly outlines the relatedwork.
Finally, we conclude our work in Section 7.2 Chinese Coreference ResolutionAccording to Webber (1978), coreference resolu-tion can be decomposed into two complementarysubtasks: (1) anaphoricity determination: decid-ing whether a given noun phrase (NP) is anaphoricor not; and (2) anaphora resolution: linking to-gether multiple mentions of a given entity in theworld.
Our Chinese coreference resolution systemalso contains these two components.
Using the train-ing data set of CoNLL-2012 shared task, we firsttrain an anaphoricity classifier to determine whether278a mention is anaphoric or not, and then employan independently-trained coreference resolution sys-tem to resolve those mentions which are classi-fied as anaphoric.
The lack of gender and numbermakes both anaphoricity determination and corefer-ence resolution in Chinese more difficult.2.1 Anaphoricity DeterminationSince only the mentions that take part in coreferencechains are annotated in the CoNLL-2012 sharedtask data set, we first generate a high-recall, low-precision mention extraction module to extract asmany mentions as possible.
The mention extrac-tion module relies mainly on syntactic parse trees.We extract all NP nodes, QP (quantifier phrase, i.e.,complex amount/measure phrase) nodes, and all ter-minals with part-of-speech tags PN (pronoun) andNR (proper noun) in parse trees to form a mentioncandidate set.
Then, we employ some rules to re-move unlikely mentions, e.g., those which contain(1) measure words such as ??
?/one year?
and??
?/one time?
; (2) named entities whose cat-egories are PERCENT, MONEY, QUANTITY, andCARDINAL; (3) interrogative pronouns such as ???/what?
and??
?/where?.After pruning, we employ a learning-basedmethod to train an independent classifier to deter-mine whether the remaining mentions are anaphoric.Table 1 lists all the features employed in ouranaphoricity determination system.2.2 Coreference ResolutionOur Chinese coreference resolution system adoptsthe same learning-based model and the same set of12 features as Soon et al(2001).
Considering thespecial characteristics of conversation and web texts(i.e., a large proportion of personal pronouns and theorganization of a text into several parts1) and prepar-ing for dealing with zero pronouns, we add somefeatures shown in Table 2.21A text in the CoNLL-2012 data set is broken down intodifferent ?parts?.2AN denotes anaphor, CA denotes antecedent candidate, IPdenotes a simple clause, and CP denotes a clause headed by acomplementizer.
For the feature ANPronounRanking, the rel-ative ranking of a given pronoun is based on its semantic roleand surface position, and we assign the highest rank to zero pro-nouns, similar to Kong et al(2009).R P FGS 76.32 87.14 81.37Auto 64.87 78.42 71.00Table 3: Performance of anaphoricity determination onthe CoNLL-2012 test setR P FAMMention Detection 65.26 67.20 66.22MUC 51.64 61.82 56.27BCUBED 73.40 80.38 76.73CEAF 53.16 45.66 49.13Average 60.71GMBMention Detection 82.01 69.58 75.29MUC 76.21 66.18 70.84BCUBED 76.15 86.59 81.04CEAF 59.75 50.52 54.75Average 68.88GMMention Detection 79.80 100.00 88.77MUC 80.86 85.48 83.11BCUBED 73.66 91.94 81.79CEAF 67.54 64.87 66.18Average 77.02Table 4: Performance of our Chinese coreference resolu-tion system on the CoNLL-2012 test set2.3 Results and AnalysisAll experiments in this section are conducted on theCoNLL-2012 shared task data set.
The SVM-lighttoolkit (Joachims, 1999) with radial basis kerneland default learning parameters is employed in bothanaphoricity determination and coreference resolu-tion.Table 3 reports the performance of anaphoricitydetermination on the CoNLL-2012 test set usinggold-standard parse trees (GS) and automatic parsetrees (Auto).
All performance figures in this paperare given in percentages.
The results show that usingboth gold parse trees and automatic parse trees, ouranaphoricity determination system achieves higherprecision than recall.
In comparison with using goldparse trees, precision decreases by about 9% and re-call 11% on automatic parse trees.Table 4 reports the performance of our Chinesecoreference resolution system on the CoNLL-2012test set under three different experimental settings:with automatic mentions (AM), with gold mention279Feature DescriptionNPType Type of the current mention (pronoun, demonstrative, proper NP).NPNumber Number of the current mention (singular, plural).NPGender Gender of the current mention (male, female).IsHeadWord Whether the current mention is the same as its headword.StrMatch Whether there is a string match between the current mention and another phrase in theprevious context.AliasMatch Whether the current mention is a name alias or abbreviation of another phrase in theprevious context.Appositive Whether the current mention and another phrase in the previous context are in anappositive relation.NestIn Whether another NP is nested in the current mention.NestOut Whether the current mention is nested in another NP.FirstNP Whether the current mention is the first NP of the sentence.FrontDistance The number of words between the current mention and the nearest previous clause.BackDistance The number of words between the current mention and the nearest following clause.WordSense Whether the current mention and another phrase in the previous context have the sameword sense.
Word sense annotation is provided in the CoNLL-2012 data set, based onthe IMS software (Zhong and Ng, 2010).Table 1: Features employed in our anaphoricity determination systemFeature DescriptionAN/CAPronounType Whether the anaphor or the antecedent candidate is a zero pronoun, first per-son, second person, third person, neutral pronoun, or others.
In our corefer-ence resolution system, a zero pronoun is viewed as a kind of special pro-noun.AN/CAGrammaticalRole Whether the anaphor or the antecedent candidate is a subject, object, or oth-ers.AN/CAOwnerClauseType Whether the anaphor or the antecedent candidate is in a matrix clause, anindependent clause, a subordinate clause, or none of the above.AN/CARootPath Whether the path of nodes from the anaphor (or the antecedent candidate) tothe root of the parse tree contains NP, IP, CP, or VP.ANPronounRanking Whether the anaphor is a pronoun and is ranked highest among the pronouns(including zero pronouns) of the sentence.AN/CAClosestNP Whether the antecedent candidate is the closest preceding NP of the anaphor.AN/CAPartDistance This feature captures the distance (in parts) between the antecedent candidateand the anaphor.
If they are in the same part, the value is 0; if they are onepart apart, the value is 1; and so on.AN/CASameSpeaker Whether the antecedent candidate and the anaphor appear in sentences spo-ken by the same person.Table 2: Additional features employed in our Chinese coreference resolution system280boundaries (GMB), and with gold mentions (GM).From the results, we find that:?
Using automatic mentions, our system achieves56.27, 76.73, and 49.13 in F-measure on MUC,BCUBED, and CEAF evaluation metrics, re-spectively.?
Using gold mention boundaries improves theperformance of our system by 14.57, 4.31, and5.62 in F-measure, due to large gains in bothrecall and precision.
We also find that usinggold mention boundaries can boost the recallof mention detection.
As described above, ouranaphoricity determination model relies mainlyon the parser.
Using gold mention boundariescan improve the parser performance.
Thusour coreference resolution system can benefitmuch from using gold mention boundaries (es-pecially the recall).?
Employing gold mentions further boosts oursystem significantly.
In comparison with usinggold mention boundaries, the performance im-provement is attributed more to an increase inprecision.In comparison with the three best systems ofCoNLL-2012 in the Chinese closed track (shown inTable 5), considering average F-measure, we findthat using automatic mentions, our system is onlyinferior to that of Chen and Ng (2012); using goldmention boundaries, our system achieves the bestperformance; and using gold mentions, our system isonly a little worse than that of Chen and Ng (2012).3 MotivationIn order to analyze the impact of zero pronouns onChinese coreference resolution, we first use the re-leased OntoNotes v5.0 data (i.e., the training and de-velopment portions of the CoNLL-2012 shared task)in a corpus study.Statistics show that anaphoric zero pronouns ac-count for 10.7% of the mentions in coreferencechains in the training data, while in the develop-ment data, the proportion is 11.3%.
The experi-mental results of our Chinese coreference resolutionsystem (i.e., the baseline) show that using both goldmention boundaries and gold mentions significantlyimproves system performance, especially for recall,largely due to improved parser performance.
Wethen analyze the impact of zero pronouns on Chi-nese syntactic parsing.
As a preliminary exploration,we integrate Chinese zero pronouns into the Berke-ley parser (Petrov et al 2006), experimenting withgold-standard or automatically determined zero pro-nouns kept or stripped off (using gold-standard wordsegmentation provided in the CoNLL-2012 data).The results indicate that given gold-standard zeropronouns, parsing performance improves by 1.8%in F-measure.
Using automatically determined zeropronouns by our zero pronoun detector to be intro-duced in Section 4, parsing performance also im-proves by 1.4% in F-measure.In order to illustrate the impact of zero pronounson parsing performance, consider the following ex-ample:3Example (1):????????????#?????????#?????????...????????????????????????????#????????
(In future, we have a reconstructionplan.Divide the park into seven regions, andbring some more attractions.. .
.Now we wait for approval of the gov-ernment before implementing this planagain.
It is expected that work can startnext year.
)Without considering zero pronouns, the parse treeof the second sentence output by the Berkeley parseris shown in Figure 1.Prior to parsing, using our zero pronoun detectorto be introduced in Section 4, the presence of zeropronouns (denoted by #) can be detected.
Figure 23In this paper, zero pronouns are denoted by ?#?
and men-tions in the same coreference chain are shown in bold for allexamples.281MD MUC BCUBED CEAF AvgAM(Chen and Ng, 2012) 71.64 62.21 73.55 50.97 62.24(Yuan et al 2012) 68.15 60.33 72.90 48.83 60.69(Bjo?rkelund and Farkas, 2012) 66.37 58.61 73.10 48.19 59.97Our baseline system (without ZPs) 66.22 56.27 76.73 49.13 60.71Our refined system (with auto ZPs) 70.33 59.58 78.15 51.47 63.07GMB(Chen and Ng, 2012) 80.45 71.43 77.04 57.17 68.55(Yuan et al 2012) 74.02 66.44 75.02 51.81 64.42(Bjo?rkelund and Farkas, 2012) 71.02 63.56 74.52 50.20 62.76Our baseline system (without ZPs) 75.29 70.84 81.04 54.75 68.88Our refined system (with auto ZPs) 75.77 72.62 81.45 58.04 70.70GM(Chen and Ng, 2012) 91.73 83.77 81.15 68.38 77.77(Yuan et al 2012) 89.95 82.79 79.79 65.58 76.05(Bjo?rkelund and Farkas, 2012) 83.47 76.85 76.30 56.61 69.92Our baseline system (without ZPs) 88.77 83.11 81.79 66.18 77.02Our refined system (with auto ZPs) 91.49 83.46 82.43 65.88 77.26Table 5: Performance (F-measure) of the three best Chinese coreference resolution systems on the CoNLL-2012 testsetshows the new parse tree, which includes the de-tected zero pronouns, output by the Berkeley parseron the same sentence.
Comparing these two parsetrees, we can see that the detected zero pronounscontribute to better division of clauses and improvedparsing performance, which in turn leads to im-proved Chinese coreference resolution.Detecting the presence of zero pronouns alsohelps to improve local salience modeling, leading toimproved Chinese coreference resolution.
Long sen-tences containing multiple clauses occur more fre-quently in Chinese compared to English.
Further-more, a coreference chain can span many sentences.Zero pronouns can occur not only within one sen-tence (e.g., the first and second zero pronouns of Ex-ample (1)), but can also be scattered across multiplesentences (e.g., the first and third zero pronouns ofExample (1)).
The subjects in the second sentenceof Example (1) are omitted.4 Detection of zero pro-nouns improves local salience modeling, and leadsto the correct identification of all the noun phrasesof the coreference chain in Example (1).4 Zero Pronoun DetectionEmpty elements are those nodes in a parse tree thatdo not have corresponding surface words or phrases.Although empty elements exist in many languages4In Chinese, pro-dropped subjects account for more than36% of subjects in sentences (Kim, 2000).and serve different purposes, they are particularlyimportant for some languages, such as Chinese,where subjects and objects are frequently dropped tokeep a discourse concise.
Among empty elements,type *pro*, namely zero pronoun, is either used fordropped subjects or objects, which can be recoveredfrom the context (anaphoric), or it is of little interestfor the reader or listener to know (non-anaphoric).
Inthe Chinese Treebank, type *pro* constitutes about20% (Yang and Xue, 2010), and more than 85% ofthem are anaphoric (Kong and Zhou, 2010).
Thus,zero pronouns are very important in bridging the in-formation gap in a Chinese text.
In this section, wewill introduce our zero pronoun detector.In Chinese, a zero pronoun always occurs just be-fore a predicate phrase node (e.g., VP).
In particular,if the predicate phrase node occurs in a coordinatestructure or is modified by an adverbial node, weonly need to consider its parent.
A simplified seman-tic role labeling (SRL) framework (only includingpredicate recognition, argument pruning, and argu-ment identification) is adopted to identify the pred-icate phrase subtree (Xue, 2008), i.e., the minimalsubtree governed by a predicate and all its argu-ments.We carry out zero pronoun detection for everypredicate phrase subtree in an iterative manner froma parse tree, i.e., determining whether there is azero pronoun before the given predicate phrase sub-282IPHHHHHHHHHVPHHHHHHHHVPHHHVPHVV?NPNN?
?VP HHVV?NP HHQPHCD?CLPM?NPNN??PU?VPHHHHHVV?
?NPHHHDNPHHHQP HHADVPAD?QPHCD?CLPM?DEG?NPNN?
?PU?Figure 1: The parse tree without considering zero pronounstree.
Viewing the position before the given predi-cate phrase subtree as a zero pronoun candidate, wecan perform zero pronoun detection using a machinelearning approach.During training, if a zero pronoun candidate hasa counterpart in the same position in the annotatedtraining corpus (either anaphoric or non-anaphoric),a positive example is generated.
Otherwise, a nega-tive example is generated.
During testing, each zeropronoun candidate is presented to the zero pronoundetector to determine whether it is a zero pronoun.The features that are employed to detect zero pro-nouns mainly model the context of the clause itself,the left and right siblings, and the path of the clauseto the root node.
Table 6 lists the features in detail.4.1 Results and AnalysisWe evaluate our zero pronoun detector using goldparse trees and automatic parse trees produced bythe Berkeley parser.
The SVM-light toolkit with ra-dial basis kernel and default learning parameters isemployed as our learning algorithm.Table 7 lists the results.
From the results, weR P FGS 89.32 87.29 88.29Auto 74.19 77.79 75.95Table 7: Performance of zero pronoun detection on thetest set using gold and automatic parse treesfind that the performance of our zero pronoun detec-tor drops about 12% in F-measure when using au-tomatic parse trees, compared to using gold parsetrees.
That is, the performance of zero pronoun de-tection also depends on the performance of the syn-tactic parser.5 Exploiting Zero Pronouns to ImproveChinese Coreference ResolutionIn this section, we will propose two methods, refin-ing the syntactic parser and refining learning exam-ple generation, to exploit zero pronouns to improveChinese coreference resolution.283IP      @@@@@@PPPPPPPPPPPPPPPPPPIPHHHNPEE#VPHHHVPHVV?NPNN?
?VPHHVV?NP HHQPHCD?CLPM?NPNN??PU?IPHHHNPEE#VPHHHHHVV?
?NPHHHDNPHHHQP HHADVPAD?QPHCD?CLPM?DEG?NPNN?
?PU?Figure 2: The parse tree with the detected zero pronouns5.1 Refining the Syntactic ParserSimilar to our preliminary experiments, we retrainthe Berkeley parser with explicit, automatically de-tected zero pronouns in the training set and parsethe test set with explicit, automatically detectedzero pronouns using the retrained model.
In bothanaphoricity determination and coreference resolu-tion, the output results of the retrained parser areemployed to generate all features.5.2 Refining Learning Example GenerationIn order to model the salience of all entities, we re-gard all zero pronouns as a special kind of NPs whengenerating the learning examples.
Considering themodest performance of our anaphoricity determina-tion module, we do not determine the anaphoricityof zero pronouns.
Instead, in the coreference res-olution stage, all zero pronouns will be consideredduring learning example generation (including bothtraining and test example generation).For example, consider a coreference chain A1-A2-Z0-A3-A4 containing one zero pronoun foundin an annotated training document.
A1, A2, A3,and A4 are traditional entity mentions, and Z0 is azero pronoun.
During training, pairs of mentions inthe chain that are immediately adjacent (i.e., A1-A2,A2-Z0, Z0-A3, and A3-A4) are used to generate thepositive training examples.
Among them, two ex-amples (i.e., A2-Z0 and Z0-A3) are associated witha zero pronoun, which can act as both an anaphorand an antecedent.
For each positive pair, e.g., Z0-A3, we find any noun phrase and zero pronoun oc-curring between the anaphor A3 and the antecedentZ0, and pair each of them with A3 to form a nega-tive example.
Similarly, test examples can be gen-erated except that only the preceding mentions andzero pronouns in the current and previous two sen-tences will be paired with an anaphor.Incorporating zero pronouns models salience ofall entities more accurately.
The ratio of positive tonegative examples is also less skewed as a result ofconsidering zero pronouns ?
the ratio changes from1:7.9 to 1:6.8 after considering zero pronouns.5.3 ReprocessingAlthough in the OntoNotes corpus, dropped subjectsand objects (i.e., zero pronouns) are considered dur-ing coreference resolution for Chinese, they are not284Feature DescriptionClauseClass Whether the given clause is a terminal clause or non-terminal clause.LeftSibling Whether the given clause has a sibling immediately to its left.LeftSiblingNP Whether the left siblings of the given clause contain an NP.RightSibling Whether the given clause has a sibling immediately to its right.RightSiblingVP Whether the right siblings of the given clause contain a VP.ParentIP/VP Whether the syntactic category of the immediate parent of the given clause is anIP or VP.RootPath Whether the path from the given clause to the root of the parse tree containsan NP or VP or CP.
This feature models how the given clause is syntacticallyconnected to the sentence as a whole, reflecting its function within the sentence.ClauseType The given clause is an independent clause, a subordinate clause, or others.Has-Arg0/Arg1 Whether the given clause has an agent or patient argument.Table 6: Features employed to detect zero pronounsused in the CoNLL-2012 shared task (i.e., in thegold evaluation keys, all the links formed by zeropronouns are removed).As described in Subsection 5.2, during trainingand testing, all links associated with zero pronounswill be considered in our coreference resolution sys-tem.
That is, we do not distinguish zero pronoun res-olution from traditional coreference resolution, andonly view zero pronouns as special pronouns.
Aftergenerating all the links, zero pronouns are includedin coreference chains.
For every coreference chain,all zero pronouns will be removed before evaluation.5.4 Experimental Results and AnalysisFor fair comparison, all our experiments in this sub-section have been conducted using the same experi-mental settings as our baseline system.
When com-pared to our baseline system, all improvements arestatistically significant (p < 0.005).Table 8 lists the coreference resolution perfor-mance incorporating automatically detected zeropronouns.
The results show that:?
Using automatically detected zero pronounsachieves better performance under all experi-mental settings.
In particular, using automaticmentions, performance improves by 3.31%,1.42%, and 2.34% in F-measure on the MUC,BCUBED, and CEAF evaluation metric, re-spectively.
Using gold mention boundaries, au-tomatic zero pronouns contribute 1.82% in av-erage F-measure.
Using gold mentions, theR P FAMMention Detection 71.09 69.58 70.33MUC 55.06 64.91 59.58BCUBED 76.04 80.38 78.15CEAF 53.98 49.19 51.47Average 63.07GMBMention Detection 82.44 70.10 75.77MUC 75.58 69.89 72.62BCUBED 76.35 87.27 81.45CEAF 65.17 52.31 58.04Average 70.70GMMention Detection 84.31 100.00 91.49MUC 80.83 86.27 83.46BCUBED 74.18 92.74 82.43CEAF 69.91 62.29 65.88Average 77.26Table 8: Performance of our Chinese coreference resolu-tion system incorporating zero pronouns285contribution of zero pronouns is only 0.24% inaverage F-measure.
This is because employingeither gold mention boundaries or gold men-tions improves parsing performance.?
Our system incorporating zero pronouns out-performs the three best systems in the CoNLL-2012 shared task when using automatic men-tions or gold mention boundaries.
Using goldmentions, our average F-measure is slightlylower than that of Chen and Ng (2012).5Table 9 presents the contribution of our two meth-ods of exploiting zero pronouns and the impact ofgold-standard zero pronouns.
We conclude that:?
Both the refined parser and refined examplegeneration improve performance.
While therefined parser improves the recall of mentiondetection and coreference resolution, refinedexample generation contributes more to preci-sion.
Combining these two methods further im-proves coreference resolution.?
There is a performance gap of 6.01%, 4.08%,and 3.19% in F-measure on the MUC,BCUBED, and CEAF evaluation metric, re-spectively, between the coreference resolutionsystem with gold-standard zero pronouns andwithout zero pronouns.
This suggests the use-fulness of zero pronoun detection in Chinesecoreference resolution.?
Our proposed methods incorporating automaticzero pronouns reduce the performance gap byabout half.
This shows the effectiveness of ourproposed methods.5.5 DiscussionAlthough the evaluation of the CoNLL-2012 sharedtask does not consider zero pronouns, we also eval-uate the performance of zero pronoun resolution onthe development data set (i.e., extracting all the re-solved coreference links containing zero pronouns,acting as anaphor or antecedent, to conduct the eval-uation independently).
The results show that, forthe correct anaphoric zero pronouns, the precision5Statistical significance testing cannot be conducted sincetheir output files are not released.of our system is 94.76%.
So viewing zero pronounsas a special kind of NP, zero pronouns can bridgesalience and contribute to coreference resolution.
InExample (1), the zero pronouns occurring in the sec-ond sentence help to bridge the coreferential relationbetween the mention ????
?/this plan?
in thelast sentence and the mention ??????
?/a re-construction plan?
in the first sentence.6 Related WorkIn the last decade, both manual rule-based ap-proaches (Lee et al 2011) and statistical ap-proaches (Soon et al 2001; Ng and Cardie, 2002;Fernandes et al 2012) have been proposed forcoreference resolution.
Besides frequently used syn-tactic and semantic features, more linguistic featuresare exploited in recent work (Ponzetto and Strube,2006; Ng, 2007; Versley, 2007).
There is less re-search on Chinese coreference resolution comparedto English.Although zero pronouns are prevalent in Chinese,there is relatively little work on this topic.
For Chi-nese zero pronoun resolution, representative workincludes Converse (2006), Zhao and Ng (2007), andKong and Zhou (2010).For the use of zero pronouns, Chung and Gildea(2010) applied some extracted patterns to recovertwo types of empty elements (*PRO* and *pro*).Although the performance is still not satisfactory(e.g., 63.0 and 44.0 in F-measure for *PRO* and*pro* respectively), it nevertheless improves ma-chine translation performance by 0.96 in BLEUscore.7 ConclusionIn this paper, we focus on exploiting one of the keycharacteristics of Chinese text, zero pronouns, to im-prove Chinese coreference resolution.
In particu-lar, a simplified semantic role labeling frameworkis proposed to detect zero pronouns effectively, andtwo effective methods are employed to incorporatezero pronouns into Chinese coreference resolution.Experiments on the CoNLL-2012 shared task showthe effectiveness of our proposed approach.
To thebest of our knowledge, this is the first attempt at in-corporating zero pronouns into Chinese coreferenceresolution.286MD MUC BCUBED CEAF AvgR P F R P F R P F R P FBaseline 65.26 67.20 66.22 51.64 61.82 56.27 73.40 80.38 76.73 53.16 45.66 49.13 60.71+RP 72.01 66.24 69.00 55.02 61.47 58.07 77.83 78.97 78.40 50.40 49.81 50.10 62.19+REG 65.92 70.02 67.91 49.98 66.27 56.98 73.64 83.45 78.24 51.12 47.44 49.21 61.48+AZPs 71.09 69.58 70.33 55.06 64.91 59.58 76.04 80.38 78.15 53.98 49.19 51.47 63.07+GZPs 72.18 70.59 71.38 58.61 66.45 62.28 78.79 82.94 80.81 54.12 50.63 52.32 65.14Table 9: Contributions of the two methods of incorporating zero pronouns and the impact of gold zero pronouns(RP: refining parser using auto zero pronouns, REG: refining example generation using auto zero pronouns, AZPs:combining both RP and REG using auto zero pronouns, and GZPs: combining both RP and REG using gold zeropronouns)AcknowledgmentsThis research is supported by the Singapore Na-tional Research Foundation under its InternationalResearch Centre @ Singapore Funding Initiativeand administered by the IDM Programme Office.ReferencesAnders Bjo?rkelund and Richa?rd Farkas.
2012.
Data-driven multilingual coreference resolution using re-solver stacking.
In Proceedings of the Joint Confer-ence on EMNLP and CoNLL ?
Shared Task, pages 49?55.Chen Chen and Vincent Ng.
2012.
Combining the best oftwo worlds: A hybrid approach to multilingual coref-erence resolution.
In Proceedings of the Joint Con-ference on EMNLP and CoNLL ?
Shared Task, pages56?63.Tagyoung Chung and Daniel Gildea.
2010.
Effects ofempty categories on machine translation.
In Proceed-ings of the 2010 Conference on Empirical Methods inNatural Language Processing, pages 636?645.Susan Converse.
2006.
Pronominal Anaphora Resolu-tion in Chinese.
Ph.D. thesis, University of Pennsyl-vania.Eraldo Rezende Fernandes, C?
?cero Nogueira dos Santos,and Ruy Luiz Milidiu?.
2012.
Latent structure percep-tron with feature induction for unrestricted coreferenceresolution.
In Proceedings of the Joint Conference onEMNLP and CoNLL ?
Shared Task, pages 41?48.Thorsten Joachims.
1999.
Making large-scale SVMlearning practical.
In Bernhard Scho?lkopf, Christo-pher J. C. Burges, and Alexander J. Smola, editors,Advances in Kernel Methods: Support Vector Learn-ing.
MIT-Press.Young-Joo Kim.
2000.
Subject/object drop in the acqui-sition of Korean: A cross-linguistic comparison.
Jour-nal of East Asian Linguistics, 9:325?351.Fang Kong and Guodong Zhou.
2010.
A tree kernel-based unified framework for Chinese zero anaphoraresolution.
In Proceedings of the 2010 Conference onEmpirical Methods in Natural Language Processing,pages 882?891.Fang Kong, Guodong Zhou, and Qiaoming Zhu.
2009.Employing the centering theory in pronoun resolutionfrom the semantic perspective.
In Proceedings of the2009 Conference on Empirical Methods in NaturalLanguage Processing, pages 987?996.Heeyoung Lee, Yves Peirsman, Angel Chang, NathanaelChambers, Mihai Surdeanu, and Dan Jurafsky.
2011.Stanford?s multi-pass sieve coreference resolution sys-tem at the CoNLL-2011 shared task.
In Proceedingsof the Fifteenth Conference on Computational NaturalLanguage Learning: Shared Task, pages 28?34.Vincent Ng and Claire Cardie.
2002.
Improving machinelearning approaches to coreference resolution.
In Pro-ceedings of the 40th Annual Meeting of the Associationfor Computational Linguistics, pages 104?111.Vincent Ng.
2007.
Semantic class induction and coref-erence resolution.
In Proceedings of the 45th AnnualMeeting of the Association for Computational Linguis-tics, pages 536?543.Slav Petrov, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning accurate, compact, and inter-pretable tree annotation.
In Proceedings of the 21stInternational Conference on Computational Linguis-tics and 44th Annual Meeting of the Association forComputational Linguistics, pages 433?440.Simone Paolo Ponzetto and Michael Strube.
2006.Exploiting semantic role labeling, WordNet andWikipedia for coreference resolution.
In Proceedingsof the Human Language Technology Conference of theNAACL, pages 192?199.Wee Meng Soon, Hwee Tou Ng, and Daniel Chung YongLim.
2001.
A machine learning approach to corefer-ence resolution of noun phrases.
Computational Lin-guistics, 27(4):521?544.287Yannick Versley.
2007.
Antecedent selection techniquesfor high-recall coreference resolution.
In Proceedingsof the 2007 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning, pages 496?505.Bonnie Lynn Webber.
1978.
A Formal Approach to Dis-course Anaphora.
Garland Press.Nianwen Xue.
2008.
Labeling Chinese predicateswith semantic roles.
Computational Linguistics,34(2):225?255.Yaqin Yang and Nianwen Xue.
2010.
Chasing the ghost:Recovering empty categories in the Chinese Treebank.In Coling 2010: Posters, pages 1382?1390.Bo Yuan, Qingcai Chen, Yang Xiang, Xiaolong Wang,Liping Ge, Zengjian Liu, Meng Liao, and Xianbo Si.2012.
A mixed deterministic model for coreferenceresolution.
In Proceedings of the Joint Conference onEMNLP and CoNLL ?
Shared Task, pages 76?82.Shanheng Zhao and Hwee Tou Ng.
2007.
Identifi-cation and resolution of Chinese zero pronouns: Amachine learning approach.
In Proceedings of the2007 Joint Conference on Empirical Methods in Natu-ral Language Processing and Computational NaturalLanguage Learning, pages 541?550.Zhi Zhong and Hwee Tou Ng.
2010.
It Makes Sense:A wide-coverage word sense disambiguation systemfor free text.
In Proceedings of the ACL 2010 SystemDemonstrations, pages 78?83.288
