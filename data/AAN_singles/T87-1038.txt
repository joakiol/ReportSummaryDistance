Mental Models and MetaphorEdwin PlantingsDept.
of Computer ScienceUniversity of TorontoToronto, Ontario CANADA MbS 1A4andRedeemer CollegeAncaster, Ontario CANADA LgG 3N6I.
IntroductionThis paper investigates the significa,lce of the mental models (MM) hypothesis for computa-tional linguistics in general and for metaphor comprehension in particular.
The N~4 hypothesis isthe claim "that people understand the world by forming mental models.
''I The general form ofthis hypothesis is not new: Immanuel Kant and neo-Kantians such as Hans Vaihinger and ErnstCassirer have argued that there is no direct access to the things-in-themselves.
Concepts and con-ceptualizations mediate between the person and the world.Although the general contours of the MM hypothesis have been around for some time, theemphasis on models and domains which one finds in the literature is a more recent phenomenon.Let us consider a definition of an N~:A mental model is a cognitive construct that describes a person's understanding of aparticular content domain in the world.
This contrasts sharply with much other workin cognitive psychology, which attempts to be domain-independent.
?-Donald Norman, for example, investigated calculator usage and found that the models con-structed by individuals varied considerably from user to user.
3 If we take the time to find out, wesee that individuals do differ in the conceptualizations which they form.1 John Sown, Conceptual Structures: Information Proces~,ing in Mind and Machine, (Reading, Ms.: Addison-Wesley, 1984), p. 4.2 John M. Carroll, Review of Mental Model~, Dedre Gentner and Albert Stevens, eds., ContemporaryPsychologII, 30(9), September 1985, p. 694.s Donald Norman, "Some Observations on Mental Models", in Dedre Gentner and Albert L. Stevens, eds.,Mental Models, (Hillsdale, N.J.: Lawrence Erlbaum Associates, 1983), pp.
7-14.1852.
In Search of Homo LoquensAn emphasis on individual differences does not mesh very well with the current linguisticparadigm.
The individual has been banished from contemporary linguistics.
Linguistics studieslanguage but not homo loquena.
There are a number of reasons for this.First, linguistics wants the prestige and status that we bestow on disciplines which are sci-ences.
To achieve this, linguists tend to the abstract and to the universal while ignoring much ofthe idiosyncratic nature of language use.Second, the Saussurean distinction between langue and parole became a cornerstone ofChomskyian linguistics.
Competence, the abstract linguistic system, became the major interest oflinguists; performance, the actual output of language users, was only of passing interest.Third, much of our thinking about language is shaped by a very powerful metaphor whichMichael Reddy has named the 'conduit metaphor.
'4 According to Reddy, our model of humancommunication is based on the following:1.
Ideas (or meanings) are objects.2.
Linguistic expressions are containers.3.
Communication is sending.A speaker puts ideas (objects) into words (containers) and then sends them (along a conduit) to ahearer who takes the ideas/objects out of the word/containers.
What  an expression meansdepends on what meaning the speaker inserted into the container.
Since the meaning is in theexpression, the recipient need only retrieve the meaning.
In this model, the individual hearer con-tributes nothing -- he merely receives.But the hearer does not receive meanings m he receives words.
To the hearer falls the taskof generating meaning in response to these words.
In short, meaning is response.
5 What  is4 Michael Reddy, "The Conduit Metaphor -- A Case of Frame Conflict in our Language About Language"in Andrew Ortony (ed.
), Metaphor and Thought, (Cambridge: Cambridge University Press, 1979).5 I have argued this position in greater length in "Who Decides What Metaphors Mean.
*", Proceedings oftheConference on Computing and the Humanities - -  Today's Research, Tomorrow's Teaching, Toronto, April1986, pp.
194-204.186manufactured epends on the architecture of the meaning generator.
Abandoning the conduitmetaphor forces us to bring the individual into linguistics so that the discipline focuses on bothlanguage and the individual language processor.
Mental models give us a way of bringing thearchitecture of the individual language processor into linguistics.3.
Mode l ing  Menta l  Mode lsA common strategy for software development is to precede the implementation phase with aproblem definition phase.
Normally, the implementation does not commence until the problemdefinition is complete.
But this strategy will not work in constructing models of MMs.
PhilipJohnson-Laird argues that mental models cannot be defined currently:At present, no complete account can be given - -  one may as well ask for an inventoryof the entire products of the human imagination - -  and indeed such an account wouldbe premature, since mental models are supposed to be in people's heads, and theirexact constitution is an empirical question.
6An alternative strategy is to use an iterative software development methodology.
We learn bybuilding so that the problem definition is refined during the development process.
The computer-based modeling of mental models should shed light on their nature.Assume the existence of some domain d. 7 An agent, agent- l ,  constructs a MM of thatdomain which we call MMace~t_l(d).
It is tempting to claim that another agent, agent-2, forms asecond 1VIM of ' that  same domain. '
But that assumes that agent-I  and agent-2 participated in'exactly the same discourse.'
The domain of agent-1 may be similar to the domain of agent,2, butthey are not the same.MMs are not restricted to 'domains in the world.'
First, an agent can construct a MM ofsome imaginary domain.
Second, an agent can construct a MM of some other agent's MM.
LetMMi (MM i (d)) represent agent; 's MM of agent i ' s  MM of some domain.e Philip Johnson-Laird, Mental Models {Cambridge, Ms.: Harvard University Press, 1983), p. 398.7 As Stephen Regoczei and 1 have argued, the domain of discourse is created by the discourse.
This idea isconsistent with the Whorfian hypothesis and much of post-structuralist thinking.
See Stephen Igegoezei andEdwin Plantings, "Ontology and Inventory: A Foundation for a Knowledge Acquisition Methodology", Proceed-fags of the Workshop on Knowledge Acquisition, Banff, Alberta, November 1986, to appear.187In order to model a MM on a computer, we must select some individual, perform knowledgeacquisition operations with the individual, and then build a model of the informant's MM.
Butwhat we are constructing is not a model of the informant's MM (i.e., MMin/o~-~ (d)) but a modelof the analyst's MM of the informant's MM (i.e., MMn-,r,t (MM,.~I o..,n: (d))).
If the developmentinvolves a number of individuals, then the model constructed will not correspond to any particu-lar agent's model.John Sown has defined a notation called conceptual graphs (CGs), which is ideal for model-ing MMs.
CGs are suitable for both knowledge representation a d also for the knowledge acquisi-tion phase which must precede the representation phase, sSown suggests that concepts are the atomic components of mental models:Concepts are inventions of the human mind used to construct a model of the world.They package reality into discrete units for further processing, they support powerfulmechanisms for doing logic, and they are indispensable for precise, extended chains ofreasoning.
9MMs have a structure which can be modeled using CGs.
Each conceptual graph consists of nodeswhich either represent concepts or conceptual relations.
In their linear notation, conceptualgraphs are directly machine representable.
Operations on MMs can be modeled by operations onconceptual graphs.
Since Sowa has defined the algorithms necessary to implement a conceptualprocessor, 10CGs form a basis for modeling both MMs and operations on MMs.4.
Natura l  Language Processing and Menta l  ModelsAlthough our vocabularies overlap considerably, the concepts which each of us hold haveour own personal stamp upon them.
George Steiner has stated this most elegantly:s The merits of Sowa's approach are outlined in more detail in Regoczei and Plantings op cir.0 John Sown, Conceptual Structures .
Information Processing in Mind and Machine, (Reading, Ma.
:Addison-Wesley, 1984), p. 344.l0 At least one conceptual processor has been implemented.
See Jean Fargues, Marie-Claude Landau, AnneDugourd, Laurent Catach "Conceptual Graphs for Semantics and Knowledge Processing", IBM Journal ofResearch and Development, 30(1), January 1986, pp.
70-79.188.
.Each living person draws, deliberately or in immediate habit, on two sources oflinguistic supply: the current vulgate corresponding to his level of literacy, and aprivate thesaurus.
The latter is inextricably a part of his subconscious, of hismemories o far as they may be verbalized, and of his singular, irreducibly specificensemble of his somatic and psychological identity.
Part of the answer to the notori-ous logical conundrum as to whether or not there can be a private language is thataspects of every language-act are unique and individual.
They form what linguists callan idiolect.
Each communicatory gesture has a private residue.
The 'personal lexicon'in every one of us inevitably qualifies the definitions, connotations, emantic movescurrent in public discourse.
11Is this 'personal exicon' a blessing or a curse?
It is this 'personal lexicon' which makeslanguage understanding idiosyncratic.
While there is some overlap in the concepts each of us pos-sess, there is also considerable non-overlap; while there is room for understanding, there is alsoconsiderable room for non-understanding or misunderstanding.If this 'personal lexicon' is a deficiency, why should we build this into computers?
Whyshould computers misunderstand?
So far, attempts have concentrated on making computersunderstand.
Understanding in this case means translating linguistic input into the meaningrepresentation.
For example, if the representational system is CGs, then the translation mapswords into concepts.
But which concepts hould the machine have?The temptation is to say, "Only those which are true."
But this poses two problems.
First,as Lakoff and Johnson have pointed out, our conceptual systems are metaphorical.
To lock thedoor on concepts which do not 'correspond to reality' will exclude machines from modelling alarge part of our mental ife.
Second, who decides what is true?
This is a pragmatic issue whichmust be faced in the knowledge acquisition phase.
Should the analyst argue with the informant?Should the analyst claim that the informant's concepts are wrong?During the knowledge acquisition phase which precedes construction of a natural anguageprocessing (NLP) system, the analyst should attempt o acquire the concepts of the informantwithout judging the concepts to be acceptable or unacceptable.
In practice, this is difficult toachieve.
Once acquired and represented in a machine usable form, the words which act as inputto the system are mapped to concepts.11 George Steiner, After Babel: Aspects of Translation, (New York: Oxford University Press, 1975), p. 46.189wSows has suggested a mechanism for connecting words and concepts: a lexicon which liststhe concepts into which a word can be mapped.
If a word has multiple senses, multiple conceptsare stored in the lexicon.
In Sowa's lexicon, for example, the word 'occupy' is associated withthree different concepts: \[OCCUPY-ACT\], \[OCCUPY-STATE\], and \[OCCUPY-ATTENTION\].The following sentences illustrate the three concepts:The enemy occupied the island with marines.Debbie occupied the office for the afternoon.Baird occupied the baby with computer games.Using this-word-to concept mapping, the conceptual processor constructs a conceptual struc-ture (graph) which represents the meaning of the linguistic input.
The nature of this graphdepends upon the contents of the mental model and upon the word-to-concept mapping.5.
Metaphor  Process ing Wi thout  Menta l  Mode lsMetaphor and analogy have always been very closely associated in AI research.
Consider asentence such as (1).
(1) Peter's argument is full of holes.If this sentence means anything, it does not mean what it says.
The conventional way of produc-ing a 'metaphorical' meaning is to assume that there is an underlying analogy which must becomputed.
What it means to compute an analogy depends on which knowledge representationscheme you are using but generally means something like analogical reasoning, inferencing, ortransfering information from one domain to another.
Since computing analogies is computation-ally expensive, metaphorical interpretations should not be generated for gibberish.
Hence theemphasis in the work of computational linguists such as Jerry Hobbs and Jaime Carbonell hasbeen twofold: t212 See Jerry Hobbs, "Metaphor, Schemata, and Selective Infereneing," Te?hnie~l Report, .
?04, SRI Interna-tional, December 1979 and Jaime Carbone|l, "Metaphor: An Inescapable Phenomenon in Natural LanguageComprehension", Technical Report,, Computer Science Department,, Carnegie-Me|lon University, May 1981.?
-1901.
Find criteria whereby ill-formed input is rejected and metaphors are accepted.
132.
Define the rules which govern what additional inferences may be drawn.Metaphors are expensive to process and hence it is crucial that NLP systems are able tolabel input as metaphoric or non-metaphoric.
Now, some metaphors ignal their presence byviolating semantic onstraints.
A sentence such as(2) John hit the nail with a hammer.fails to violate semantic constraints whereas a sentence such as (1) does since arguments do not'literally' have holes.
But a sentence such as (3) does not violate semantic onstraints.
(3) Zeke's father is an accountant.By most definitions of 'literal', (3) has a literal reading.
But a metaphorical reading can also begenerated, a reading in which attributes uch as meticulous, finicky, boring, dull, and mousey arepredicated of Zeke's father.
14 On the basis of the sentence alone, it is not possible to tell whichreading of (3) is preferred.
While the violation of semantic constraints may be used to detectsome metaphors, it will not reveal them all.
When multiple readings or interpretations are avail-able, we say that a sentence is ambiguous and that disambiguation requires 'context.'8.
Menta l  Mode ls  and  MetaphorMental  models provide some conceptual clarity to some aspects of metaphor  processing.
Iwill examine three such aspects.First, it is incorrect to appeal to 'context' as an aid in disambiguation.
A user has no accessto 'context' although he (potentially) has access to his mental model  of the context.Is George Lakoff and Mark Johnson's Metaphors We Live By has been helpful on this score and its populari-ty among computational linguists is undoubtedly due to Lakoff and Johnson's suggestion that metaphors axesystematic and not ad hoc.14 Such a metaphorical reading should be easy to generate for fans or MontU Python'# Flllin?
Circus who arefamiliar with their caricatures of accountants and bank clerks.191Second, it has become common to distinguish between 'dead'  metaphors and ' l ive' meta-phors.
This distinction is made purely on the basis of the linguistic expression.
A 'dead'  meta-phor, so the explanation goes, has acquired a fixed meaning through repeated use.
Retrieving themeaning is simple: it only requires a table lookup.
But since there seem to be no interestingresearch issues here, 'dead'  metaphors have received little attention from computational  linguists.But a 'dead'  metaphor is not dead for everyone.
Children, for example, are frequently puz-zled by a 'dead'  metaphor such as 'out to lunch.
'(4) Charles is permanently out to lunch.What  is 'dead'  and what is ' l ive' does not depend on the linguistic expression, but upon the men-tal model of the language processor.
Since ~Ms are evolving models, we can use them to modelthis kind of change.Third, it appears that some 'metaphors '  can be processed without relying on analogical rea-soning.
Since each agent participates in multiple discourses, he possesses multiple mental models.An agent might even have a number o f  inconsistent models of the 'same domain. '
Dependingupon which model is running, there may or may not be a mapping from word to concept.
Hencewhat was not a metaphor at time t may be a metaphor at t ime t ?
n simply because anothermodel is running.
15NIMs allow us to make distinctions which cannot be made reliably otherwise.
What  is andis not a metaphor and what is a ' l ive' and what is a 'dead'  metaphor cannot be decided just bylooking at the linguistic expression.
Nor can it be decided by looking at the expression and theagent.
These determinations can only be made with respect to a particular mental  model at aparticular point in time.16 It may be helpful to think of Lako6 and Johnson's conceptual metaphors as inconsistent MMs of thistype.
Each one of their conceptual metaphors would have a difl'erent ontology.
What is permissible in one on-tology may be forbidden in another.
The alternative to multiple ontolo$ies i what we have now: one 'pure' on-tology and lots of computation.1927.
ConcluslonMental models have been used as explanatory models for investigating the conceptualiza-tions which individuals form of fairly structured omains.
Little research as been done in usingin linguistics.
Since CGs provide a basis for modeling ~,  it is now feasible to use MIVls incomputational linguistics.
A linguistics based on mental models is in its infancy and many openquestions remain.
But MMs appear to offer a promising approach.193
