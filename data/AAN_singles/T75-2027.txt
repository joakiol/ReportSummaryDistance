Some Methodological  Issues inNatural Language Understanding ResearchW.
~oodsBolt Beranek ~nd Inc. Newman,Cambridge MA 02138I.
INTRODUCTIONNatural language understanding hassuddenly emerged as a central focus for manydifferent discipl ines.
Appl icat ions areemerging all over the field of computerscience in which language understanding andthe communicat ion of complex intentions tomach ines  is a crucial part.
Moreover,psychologists, l inguists, and phi losophershave found the models emerging fromcomputat ional  l inguist ics research toprovide new stimulus and new methods forincreasing our understanding of the processof human language use and the nature ofcommunication.
In this paper I want todiscuss some of the methodological  problemsI see in the  development of this area ofresearch and some of the things which Ithink are needed in order for the field tobe product ive of real scienti f ic insight anduseful results.In order to discuss methodologies,  wehad best first understand thedifferent tasks for which the methodologiesare to be used.
There are at least twoprimary interests which one can have instudying natural language understanding --construct ing intel l igent machines andunderstanding human language performance.These two different object ives are notmutual ly exclusive, and I wil l  attempt toargue that a large portion of the researchnecessary to either of them is shared by theother.
This common portion consists of apure attempt to understand the process oflanguage understanding, independent of whatdevice (human or machine) does theunderstanding.
However, there are elementsof the dif ferent points of view which arenot shared, and drawing the dist inct ionbetween object ives at the outset is, Ithink, useful.I would claim that both the developmentof useful mechanical  devices forunderstanding language and the understandingof human language performance depend heavi lyon what we might call "device independent"language understanding theory.
That is, aJoint study of human and machine languageunderstanding, attempting to devisea lgor i thms and system organizat ions whichwil l  have the functional performance oflanguage understanding without speci f ica l lytrying to model the performance aspects ofhuman beings.
Theoret ical  and empir icalstudies of this sort provide the foundat ionson which models of human language processingare built which are then subject toempir ical  ver i f icat ion.
They also providethe "bag of tr icks" out of which usefulmechanical  language understanding systemscan be constructed.
Outside the common areaof endeavor, these two different object iveshave different goals.
For both objectives,however, a major component of the researchshould  be to study the device independentlanguage understanding problem.This paper is an attempt to set down mybiases on some issues of methodology forconstruct ing natural language understandingsystems and for performing research incomputat ional  l inguist ics and languageunderstanding.
In it I wil l discuss some ofthe methods that I have found eithereffective and/or needed for performinguseful work in the area of human andmechanical  language understanding.For theoret ical  studies, I wil l arguestrongly for a methodology which stressescommunicable and comprehensible theories,with precise uses of terms and an evaluat ionof formal isms which stresses the cognit iveeff ic iency of the representat ions of theformal ism itself.
I wil l  attempt to citeseveral examples of the di f ferences incognit ive eff ic iency between formalisms.The thrust of many of my comments wil ldeal with the problems of complexity.
Mythesis is that natural language, unlike manyphysical systems is complex in that it takesa large number of facts, rules, or what haveyou to character ize its behavior rather thana small number of equations (of whatevertheoret ical  sophist icat ion or depth).
It isre lat ively easy to construct a grammar orother character izat ion for a fair ly smallsubset of the language (at least it isbecoming more and more so today), but it isnot so easy to cope with the complexity ofthe speci f icat ion when one begins to put inthe magnitude of facts of language which arenecessary to deal with a s igni f icantfract ion of human language performance.Theories for natural language understandingw i l l  have to deal ef fect ively with problemsof scale the number of facts embodied in thetheory.Since this paper is largely designed topromote discussion, the set of issuescovered herein makes no effort to becomplete.
My goal is to raise some issuesfor considerat ion and debate.If.
A PROGRAM FOR THEORETICAL L INGUISTICSAND PSYCHOLOGYThe first point that I would like tomake is that in the pursuit of theoret icalunderstanding in l inguist ics orpsychol inguist ics,  studies will be much moreproduct ive if pursued in the context oftotal language understanding systems and notin isolation.
The subdivis ion of the totalprocess into components such as syntax andsemantics and concentrat ing on one suchcomponent is an effective way of l imit ingscope.
However, it is only just i f iable ifone has at least some reason to bel ieve thathis hypothesized interfaces to those othercomponents are real ist ic (and certain ly onlyif he has precisely specif ied thoseinterfaces).
One cannot expect to pursuesome small niche of the languageunderstanding process without an activeinterest in the entire process and anunderstanding of the role of his specialtyarea in that overal l  process.
Otherwise itis too easy to push problems off on someoneIiIiIIt!IIiIIii13~ mIIII1Ielse, who may not be there to catch them.
(In part icular there is considerable riskthat the problems left for someone else maybe insoluble due to a false assumption aboutthe overall  organization.
Studies pursuedunder such false assumptions are l ikely toturn out worthless.)III.
THEORETICAL AND EMPIRICAL METHODOLOGIESThere is need in the field of naturallanguage understanding for boththeoret ic ians and builders of systems.However, neither can pursue their ends inisolation.
As in many other fields, thetheoretical  and experimental  components gohand in hand in advancing the understandingof the problem.
In the case of languageunderstanding, the theoret icalinvest igat ions consist largely offormulation of frameworks and systems forexpressing language understanding rules orfacts of language and for expressing othertypes of knowledge which impact theunderstanding process.
On the experimentalside, it is necessary to take a theory whichmay appear beaut i fu l ly  consistent andlogical ly adequate in its abstractconsideration, and verify that when facedwith the practical  real ity of implementing asignif icant portion of the facts oflanguage, the formalism is capable ofexpressing all the facts and is not toocumbersome or ineff ic ient for practical ity.The day is past when one could devise a newgrammar formalism, write a few examples init, and tout its advantages without putt ingit to the test of real use.Today's language theoret ic ians musthave a concrete appreciat ion of themechanisms used by computerized languageunderstanding systems and not merelytraining in a classical  school ofl inguist ics or philosophy.
(On the otherhand, they should not be ignorant ofl inguist ics and phi losophy either.)
Somemechanism must be found for increasing the"bag of tr icks" of the people who formulatesuch theories -- including people outsidethe current computat ional  l inguist ics andart i f ic ia l  intel l igence camps.
Hopeful ly,th is  conference will make a beginning inthis direction.IV.
MODELS AND FORMALISMSOne of the depressing methodologicalproblems that currently faces the field ofart i f ic ia l  intel l igence and computat ionall inguist ics is a general tendency to useterms imprecisely and for many people to usethe same term for different things anddifferent terms for the same thing.
Thistendency greatly hampers communicat ion oftheories and results among researchers.One part icular imprecis ion of termsthat I would like to mention here is aconfusion that frequently arises aboutmodels.One frequently hears people refer tothe transformat ional  grammar, model, or theaugmented transit ion network grammar model,and asks what predict ions these models makethat can be empir ical ly verified.
However,when one looks careful ly at what is beingreferred to as a model in these cases, wefind not a model, but rather a formal ism inwhich any of a number of models (ortheories) can be expressed.
Thetransformat ional  grammar formalism and theATN formalism may suggest hypotheses whichcan be tested, but it is only the attachmentof some behavioral  s ignif icance to someaspect of the formal ism which gives rise toa testable model.Argume:nts for or against a model arewhether it is true -- i.e.
whether thepredict ions of the model are borne out byexperiments.
Arguments for or against aformalism or a methodology are itsproductiveness, economy of expression,suggest iveness of good models, ease ofincorporat ing new features necessary to newhypothesized models (i. e. range ofpossible models expressible),  etc.
Oneneeds at the very least that the formal ismused must be capable of representing thecorrect model.
But one doesn't know aheadof time and may never know what the correctmodel is.
Hence it is desirable to have aformalism that can represent all conceivablemodels that could be correct.
If there is aclass of models which the formalism cannotaccount for then there should be an argumentthat no members of that class could possiblybe correct, otherwise a formalism whichincluded that class would be better (in onedimension).
Dimensions of goodness offormalisms include range of possible models,eff ic iency of expression (perspicuity orcognit ive eff ic iency of the formalism),existence of eff ic ient simulators for theformal ism for use in ver i fy ing thecorrectness of a model, or for f indinginadequacies of a model, or for determiningpredict ions of the model, etc.V.
HUMAN LANGUAGE PERFORMANCEIn order to perform good work incomputat ional  l inguist ics and inunderstanding human language performance,one needs to keep always in mind a goodoverview of how people use language and forwhat.
Indeed, a prime focus of thisconference is the development of such aoverview.
My own picture of the role oflanguage in human behavior goes roughly  likethis:There is some internal representat ionof knowledge of the world which isprel inguist ic,  and we probably share most ofit with the other higher animals -- I wouldguess we share a lot of it with cats anddogs, and certainly with apes andchimpanzees.
(What dif ferences of qual i tyor quantity set us apart from these animalsor set the chimps apart from the dogs Iwould not care to speculate.
)Nevertheless, it is clear that cats and dogswithout our l inguist ic machinery and withoutspoken languages do manage to store andremember and use fairly complex pieces ofknowledge of the world, such as how to openI 135doors, how to find their way around, wherethey left things, which dish is theirs, whatfunny sequence of sounds their owners use tocall them (i. e. their names), and thes igni f icance (to them) of all sorts ofthings that go on in the world around them.Humans probably remember large numbers ofsuch things also without specif ic need forlanguage.
We presumably have in our headsomething which is like a language in manyrespects, but which probably does not sharethe peculiar l inear character ist ics  o fspoken and written language (which derivesfrom the temporal order imposed on speechand reading).It no doubt helps us to remember alarger number of things to correlate themwith l inguist ic labels or a pronounceablesequence of sounds, and this no doubt givesa greater abi l i ty for abstract thought.However, it is doubtful  that a language aswe speak it or write it is a prerequis i tefor an organism to have what we might callthought.
Many of the things which we "know"are not expressed in language, and the factthat f inding the appropr iate words todescribe things that we understand issometimes very di f f icult  should give us aclue that the representat ion which we use inour heads is not a simple transcr ipt ion ofthe language that we use to communicate withothers.
Rather, there are a variety ofexposit ion problems which need to be solvedin order to translate even ideas which .areclearly understood into a l inear sequence ofl inguist ic symbols which wil l  be l ikely toarouse or create the same idea in the headof our l istener.
It seems l ikely then thatthe notat ion or whatever  convent ions that weuse to store ideas and information in ourheads is not the same as the language thatwe speak to communicate with others.The language that we speak and write,then, appears to be a device or a disc ip l ineevolved for the purpose of attempt ing toarouse in the head of the l istener somethingsimilar to that which is encoded in the headof the speaker.The process of communicat ionnecessar i ly  involves elements of problemsolving.
What terms does my l istener know?What concepts can I rely on hisunderstanding so that I can express what Iwant to say in terms of them?
How can Ibuild a speci f icat ion out of these pieceswhich wil l  cause him to construct in hismemory the thing which I am trying tocommunicate?
An account of human languageuse must deal with all of these questions.The above picture of the overal l  roleof language in human communicat ion may notbe correct in many respects.
Hopeful ly  aconsensus of this workshop wil l  produce abetter one.
However, I am afraid that acomplete understanding of human language usewil l  have to go hand in hand with anunderstanding of the pre l inguist iccapabi l i t ies for knowledge representat ionand use which the human has.
This level ofhuman abi l i ty is unfortunate ly  verydiff icult  to get one s hands on since it,like Joe Becket's problems of intermediate136cognition, is a process which we are notgeneral ly aware of (since it takes placebelow the level of our conscious awareness)and consequent ly  we have no direct abi l i t iesto see it.
Rather we have to be able toinfer its presence and its nature fromtheoret ical  considerat ions and the effectsthat it has on the overt behavior we cansee.
A methodology for working in this areais extremely diff icult  to work out.A pr incipal  component of such amethodology, I feel, should be a theoret icalattempt to construct models which do thingshumans do and which do them well.
That is,one should try to design intel l igentmachines which can do what humans do, andlet the concepts that emerge from suchdesigns make predict ions about whatperformance one should see at the overtbehavior interface.
It is importanthowever, that such studies go as far as toproduce overt behavior which can beevaluated.
A so called "theoretical" studywhich has no measurable performance isfoundationless.
There is no way to evaluatewhether it is doing anything or not.
Inparticular, many studies of so cal led"semantic representat ions"  need clearstatements of what wil l  be done with theirrepresentat ions and how one can decidewhether a representat ion is correct orincorrect.
Without such an understanding,the entire exercise is one of aesthet ics andwithout sc ient i f ic  contr ibut ion.
In ta lk ingabout semantic representat ions,  one must  bewi l l ing to face the questions of how thedevice knows what those representat ionsmean.
What events in the world wil l  be incontradict ion to the knowledge encoded inthe representat ion and what ones wil l  beconsistent with it?
How wil l  a person (or amachine) know whether an event perceived isconsistent with his semantic representat ionsor not?
How does he decide what to recordwhen he perceives an event -- i. e. whatprocess transforms ("transforms" is hotreal ly the right word for this) an observedevent into a l inguist ic  descr ipt ion of it?What intervening processes take place?
Theseand similar quest ions must be spec i f ica l lyfaced.V I .
EXPLANATORY MODELSThe goal in trying to model humanbehavior should be to find explanatorymodels, not just descr ipt ive models.
If,for example, one discovers that there is areact ion time lag in processing certa intypes of sentences, a model which s imulatedthis behavior by insert ing a delay into acertain s tage  of the processing would be adescr ipt ive model, whereas another modelwhich took longer for processing these typesof sentences because of some extraprocessing which they required due to theorganizat ion of the program would be anexplanatory model.
In my own work, thethings which have excited me and made mefeel that I was d iscover ing something aboutthe way the people understand language, havebeen a lgor i thms that are mot ivated byconsiderat ions of ef f ic iency and "goodengineer ing design" for a specif ic taskI1I!1!IIiiiIIiII!IIwhich then turn out to have  predict ionswhich are borne out in human performance.An example of this is some of the work ofRon Kaplan and Eric Wanner using ATNgrammars to model aspects of humanl inguist ic processing.
(The basic ATNgrammar formal ism was designed foref f ic iency of operation, and notspeci f ica l ly  for human performancemodeling.)
When such an experiment haspositive results, one has not only adescr ipt ion of some aspect of humanbehavior, but also a reason for thebehavior.VII.
COPING WITH COMPLEXITYA crit ical need for all studies inlanguage understanding is effect ivemechanisms for coping with the complexity ofthe phenomenon we are trying to understandand explain.
The models that are requiredfor descr ibing human language performanceare more compl icated than the comparat ive lysimple physical  phenomena in most otherareas of science.
Only the models inart i f ic ia l  inte l l igence and computat ionall inguistics, and perhaps some kinds oftheoret ical  chemistry reach  the level ofhaving theories which comprise thousands ofrules (or equations) that interact incompl icated ways.
If the results ofdetai led studies of l inguist ic phenomena areto be disseminated and the field is to g rowfrom the exchange of information and thecontinued accumulat ion of a body of knownfacts, then the facts must be capable ofbeing communicated.
We have then, at thecore of the methodology of languageunderstanding research, a crit ical need forsome of the byproducts of our own research-- we need to develop effective formal ismsfor representat ion and for communicat ion ofour theories.
The expression of a theory oflanguage in a formal system which isincomprehensib le  or tedious to comprehendwil l  contr ibute l itt le to this endeavor.What is required then, as a fundamental  toolfor research in language understanding is aformal ism for expressing theories o flanguage ( involving large numbers ofe lementary facts) in ways which arecognit ively eff ic ient -- i. e. whichminimize the inte l lectual  effort required tograsp and remember the functions ofindividual  e lements of the theory and theway in which they interact.A good example of cognit ive ef f ic iencyof representat ion occurs in therepresentat ions of transit ion networkgrammars, compared with the intermediatestages of a t ransformat ional  der ivat ion in aconventional  t ransformat ional  grammar.
Itis well  known, that humans find it easier toremember l ists of famil iar elements whichfit together in structured ways than toremember dynamical ly  varying lists ofunfami l iar  things.
In a transit ion networkgrammar, the stages of intermediateprocessing of a sentence proceed through asequence of transit ions through named statesin the grammar.
Each of these states has aname which has mnemonic value andcorresponds to a part icular  mi lestone or137landmark in the course of processing asentence.
A student of the language or agrammar designer or someone studying someoneelse's grammar can become famil iar with eachof these states as a known entity, canremember it by name, and become famil iarwith a variety of information associatedwith that state -- such as what kinds ofl inguist ic construct ions preceeded it, whatconstruct ions to expect to the right,prosodic cues which can be expected toaccompany it, potential  ambiguit ies anddisambiguat ion strategies, etc.
Thecorresponding intermediate stages of at ransformat ional  g rammar  go through asequence of intermediate phrase marke~swhich do not exist ahead of time, are notnamed, have no mnemonic value, areconstructed dynamical ly  during a parsing,and in general provide none of the abovementioned useful cognit ive aids to thestudent of the grammar.Similarly, the information rememberedduring the course of a parsing with an ATNis stored in named registers, again withmnemonic value, while the correspondinginformat ion in a t ransformat ionalintermediate structure is indicated solelyby posit ional  information in theintermediate tree structure with no suchmnemonic aid, with an attendant d i f f icul tyfor memory, and with the added di f f icul tythat it is possible to construct a structureacc identa l ly  which matches the input patternof a rule that one did not intend it toactivate.
The chance of doing thisacc identa l ly  with a mnemonica l ly  namedregister or condit ion is negligible.Many other techniques for expressingcompl icated systems with cognit iveef f ic iency are being developed byprogrammers in sophist icated languages suchas INTERLISP, where some programmers areadopt ing styles of programming which makethe understanding of the program by humanprogrammers and students easier.
A majortechnique of these programming styles fromthe standpoint of cognit ive ef f ic iency isthe use of a h ierarchy of subrout ines withspeci f ied function and mnemonic names toproduce program structures which matchclosely the human conceptual  model of whatthe program is doing.
In such systems, onecan verify the successful  operat ion of ana lgor i thm by a method called recurs ioninduction, which ef fect ively says that ifall of the subrout ines do the right thing,then the main routine wil l  also do the rightthing.
If one is suf f ic ient ly  systematicand careful  in his programming style, thenthe assurance that each level of the programdoes the right thing can be guaranteed byinspect ion and the chances of wr i t ingprograms with hidden bugs or compl icatedprograms whose function cannot be easi lyunderstood is greatly reduced.As an example, consider a techniquewhich I use extensively in my ownprogramming in LISP.
Suppose that I have adata object cal led a conf igurat ion which isrepresented as a list of 5 elements and thesecond element of the list is the state ofthe conf igurat ion.
It is a simple matter ofprogramming discipl ine to extract the statename from such a data object with a functioncalled CONFIG.STATE rather than the LISPfunction CADR, with the result that theprogram is almost self documenting insteadof incomprehensible.
It is easy inINTERLISP to define the two functionsident ical ly and to cause them to compileidentical ly so that no cost in running timeis necessi tated by such programmingtechniques.
(In my case I have a LISPfunction called EQUIVALENCE which takes careof all the details if I s imply call(EQUIVALENCE (CONFIG.STATE CADDR)).
)Recently, new features have been added toINTERLISP which further faci l i tate suchprogramming conventions by providing theuser with a general ized facil ity for recordnaming and field extraction.Another example of the principle ofcognit ive eff ic iency arises in the nowfamous go-to controversy of the programminglanguage theorists.
One school argues thatone should program in a structuraldiscipl ine which makes go-to instruct ionsunnecessary and that such a disc ipl ineshould be forced on a programmer because thecode he will write under such a disc ipl inewill be better.
This extreme point of viewis presumably in contrast to the s i tuat ionin the language FORTRAN where one can handlebranching only by "naming" each of thebranches with (unmnemonic) numeric labelsand speci fy ing go-to instruct ions in termsof such labels.
However, I would argue thatin many other situations, with a languagewhich permits mnemonic labels, a programmercan insert a go-to instruct ion for the samekinds of reasons that he creates manysubrout ines -- i.e., there is a s ignif icantchunk of operat ion which in his mind is aunit (for which he has or can coin a name)and which he would like to represent in hiscode in a way that wil l  enable him to readport ions of the code at a level of detai lwhich is cognit ively eff icient.
When go-toinstruct ions are used in this way, they havethe same value that the abi l i ty to writesubrout ines provides (not only eff ic iency ofwr i t ing a given portion of code once whi lebeing able to enter it for execution fromseveral places, but also the cognit iveef f ic iency of being able to ignore detai lsof how some process operates by referr ing toit by name or label in situations where itis the purpose or goal of a procedure orblock of code which is important and not thedetails).VIII.
THE NEED FOR A COMPREHENSIBLEFRAMEWORKNot only must the individual rules of acomplex system be comprehensible to thesystem designer and the student, but alsothe control f ramework into which these rulesfit must be understood.
Again, there is apr inciple of cognit ive eff ic iency inoperation.
A control  f ramework which issimple to explain and easi ly remembered bythe student of the system as he studies it,is far preferable to one which constant lymisleads the student into thinking thatsomething happens in one way when itactual ly happens di f ferent ly or not at all.One cannot write rules for a system when heis not sure how it will apply the rules orwhen.
Languages which take away from theprogrammer the burden of speci fy ing thedetails of control  structure should not alsotake away his abi l i ty to easi ly understandand forsee what wil l  happen in response tohis rules.IX.
COGNITIVE EFFICIENCY IN GRAMMARSOne of the di lemmas of the field ofcomputat ional  l inguist ics has been thedi f f iculty of evaluat ing the qual ity of agrammar which someone has written.
What isthe scope of grammatical  phenomena which itcovers?
It is one thing to say that agrammar handles questions, imperatives,comparatives, adverbs, etc.
It is anotherthing to discover that what this means isthat certain yes/no and simple wh- quest ionsare handled, that a certain class ofcomparat ives (the easy ones) are handled,and that only single word adverbs before orafter the main verb are handled.
A list ofphenomena supposedly dealt with is obviouslynot suff icient.A common attempt to specify the classof sentences accepted by a grammar is tolist a sample set of the sentences covered.This tends to give a feel ing for what thegrammar can handle, but depending on thescrupulousness of the author in point ing outthe things that his grammar doesn't handle(assuming he real izes what it doesn'thandle) it is very easy for the reader  toovergeneral ize the range actual ly handled.When the author l ists several examples ofdif ferent kinds of comparatives, how doesthe reader decide whether all poss ib i l i t iesare handled or Just those cases that arelisted.
The problem is that what one wantsis a precise, compact, and comprehensib lerepresentat ion of exact ly the class ofsentences which are acceptable and how theyare handled.
But, notice that to the extentthat such a speci f icat ion is real izable,that is exact ly what a grammar should be.Hence, the thing that is needed is aformal ism for grammar speci f icat ion which isprecise, compact, and comprehensib le to ahuman grammar designer.
In short, we need aformal ism for grammar speci f icat ion which iscognit ively eff ic ient -- enough so that agrammarian can tell by inspect ion of thegrammar whether a sentence is acceptable ornot.
While this may not be real izable tothis extent, it seems to focus on thehopelessness of attempting to find someother speci f icat ion of what a grammar doeswhich wil l  somehow be clearer than thegrammar itself.
Instead, it shifts theemphasis to making the grammar formal ismsuf f ic ient ly  perspicuous that one can studyit and understand it directly.The only other method I know of at thepresent to obtain answers to specif icquest ions about what a grammar does is toget your hands on the system and probe itwith your theories of what it handles andwhat it doesn't.
This has its ownIiI!IIiI138 Idisadvantages in the other direction, sinceit is indeed possible for a sentence to failfor a trivial reason that is a simpl e bug ina program and not because the grammar isincorrect or the theory is inadequate.Moreover, it is almost impossible for anyonebut the designer and implementer of thesystem to tell whether it is a simple bug ora real conceptual  di f f iculty and onecertainly can't simply take on faith astatement of "Oh that's just a bug.
"However, I think that it is inevitable thatnatural language grammars wil l  reach a levelof complexity, no matter how perspicuous onemakes the grammar, where computer aid inchecking out theories and finding out whatis or is not handled is an essential  tool.Th isdoes  not obviate the need for cognit iveeff iciency, however.To make the matter more complicated, inmany systems, now, the syntactic componentis not separable from the semantics andpragmatics of the system so that a sentencecan fail to be handled correct ly not onlydue to incorrect syntax (i. e. the grammardoes not match the real i ty of what peoplesay) but also due to concepts which thesystem does not know or things which thesystem finds inappropr iate to the context.For such systems, it is almost impossible tojudge the capabi l i ty  of the individualcomponents of the system in any object iveand non id iosyncrat ic  terms.
Each system isunique in the scope of what it is t ry ing  todo and f inding any equivalent grounds onwhich to compare two of them is di f f icult  ifnot impossible.
The abi l i ty to understandthe formal ism in which the author expresseshis theory and presents it to the world iscrit ical.comprehension as well as mechanicalimplementat ion.
In addition, I havediscussed the need to perform research inthe specia l ized areas of languageunderstanding within the framework of aglobal picture of the entire languageunderstanding process.
I have called formore care in the precise use of terms andthe use where possible of accepted exist ingterms rather than inventing unnecessary newones.
I have also stressed the necessitythat models must produce some overt behaviorwhich can be evaluated, and have noted thedesirabi l i ty of f inding explanatory modelsrather than mere descr ipt ive models if oneis really to produce an understanding of thelanguage understanding process.
I hope thatthe paper wil l  serve as a useful basis fordiscussion.REFERENCESBecker, J.D.
"An Information ProcessingModel of Intermediate-Level  Cognit ion,"Memo AI-119, Stanford Art i f ic ia lInte l l igence Project, StanfordUniversity,  Stanford, Calif., May, 1970.Internat ional  Joint Conference on Art i f ic ia lIntel l igence, London, England,September, 1971.Woods, W.A.
"Transit ion Network Grammarsfor Natural  Language Analysis,"  Comm.ACM, Vol 13, No.
10, (October, 1970).X.
CONCLUSIONIn conclusion, the major thrust of thispaper has been to stress the complexity ofscale which must be dealt with inrepresent ing theories of natural languageunderstanding and especial ly  incommunicat ing them to other people.
Mymajor methodologica l  weapon against thiscomplexity, is to develop speci f icat ionlanguages and notat ions which arecognit ively eff ic ient in the sense that theyminimize the human intel lectual  effortnecessary to understand, remember, design,and use such formalisms.
We should strivefor notat ions that can be used to publ ishgrammars, semantic specif ications, andknowledge bases in a form that one canreal ist ica l ly  expect other people to readand understand.
Simple things such asnaming functions with names that wil l  invokethe correct concept in the head of theperson studying the formal ism (rather than aclever name the author fancies, or the firstthing he happened to name it, or the name itused to have when he used it for somethingelse, etc.)
can make an enormous di f ferencein the cognit ive eff ic iency of a formalism.In short, I am making a plea for making thespeci f icat ion language used for theorydevelopment in natural languageunderstanding be a communicat ion languageintended and engineered for human139
