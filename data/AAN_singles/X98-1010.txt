COREFERENCE RESOLUTION STRATEGIES FROM AN APPLICATIONPERSPECTIVELois C. Childs, David Dadd, Norris HeintzelmanLockheed Martin CorporationP.O.
Box 8048Philadelphia, PA 19101lois.childs @ lmco.com(610) 354-58161.
INTRODUCTIONAs part of our TIPSTER III research program,we have continued our research into strategies toresolve coreferences within a free text document; hisresearch was begun during our TIPSTER II researchprogram.
In the TIPSTER II Proceedings paper, "AnEvaluation of Coreference Resolution Strategies forAcquiring Associated Information," the goal was toevaluate the contributions of various techniques forassociating an entity with three types of information:1) name variations, 2) descriptive phrases, and 3)location information.
This paper discusses theevolution of the coreference r solution techniques ofthe NLToolset ~, as they have been applied to aninformation extraction application, similar to theMUC Scenario Template task.
Development of thisapplication motivated new coreference resolutionalgorithms which were specific to the type of entitybeing handled.
It also has raised the importance ofunderstanding the structure of a document in order toguide the coreference r solution process.In the following paper, Section 2 discusses entityrelated coreference r solution techniques and Section3, the relevance of document zoning.
Section 4concludes with a discussion of future work, whichwill include location merging, event coreferenceresolution, and event merging.The NLToolset is a proprietary text processingproduct, owned by Lockheed Martin Corporation.The NLToolsetThe NLToolset is a framework of tools,techniques, and resources designed for building textprocessing applications.
It is a pattern based systemwhich uses world knowledge resident in a lexicon, alocation gazetteer, and lists of universal terms, suchas first names and Fortune 500 companies.
Thisknowledge base is extensible with generic, as well asdomain-specific, information.
The NLToolset applieslexico-semantic pattern matching in the form of basicstructural patterns (possible-title firstname middle-initial lastname), as well as contextual knowledge(possible-person-name, who is X years old).
TheNLToolset currently contains generic packages ofrules to extract dates/times, percentages, money,phone/fax numbers, passports, identification umbers,social security numbers, person names, organizationnames, locations, vehicles, and drugs.
It can extractfrom upper case and mixed case text.The NLToolset has been applied to routing,indexing, name spotting, information extraction, anddocument management.
It is an object-orientedsystem, implemented in C++ and ODBC to make itportable to both Unix and NT platforms, as well asmultiple databases.An ApplicationOne application, developed with the NLToolset,extracts a complex template which describes cocaineseizures by law enforcement personnel.
Theapplication fills a template which holds informationabout the type of document (document identification,45classification, and source), the entities involved(seizing and trafficking organizations, arrestedpersons), the drug information (amount, type, andmethod of concealment), the platform information(name and type of vehicle involved), the relevantlocations (origin and destination of drugs, and placeof seizure), and the date of the event.An important step in merging all of the relevantinformation together into one template is theresolution of all coreferences among the relevantentities.
In the following example, knowing what thevessel refers to would help in linking that informationto the seizure event, without having to merge thefinding and seizing events.Drugs were found on board a cruise ship in Miami's harbor.Local law enforcement seized 17 kg.
of cocaine on the vessel.The entities involved in this application rangeover several types: persons, organizations, vehicles,drugs, locations, and the events themselves.
In ourwork, we find it helpful to exploit the nature of theentity in finding its coreferences.2.
ENT ITY  COREFERENCESome coreference resolution techniques can beapplied with only slight modifications across entitytypes.
Identifying names and their variations is thefirst step in sorting out the person and organizationentities.
The NLToolset stores each newly recognizednamed entity, along with its computed variations andacronyms.
The variations and acronyms arealgorithmically generated, based on entity type,without reference to the text.
For example, ingeneral, person names can have nicknames, butorganization ames can have acronyms.
(Personssometimes also have acronyms, e.g JFK, but these areexceptions which must be stored as worldknowledge.)
Generated variations are stored in atemporary lexicon so that naturally occurringvariations in the text can be recognized and linked tothe original occurrence.In linking noun phrases with named entities, theNLToolset has rule packages which find noun phrasesof specific types: organization, person, vehicle,drugs.
This allows the NLToolset to limit the searchspace for referents.During context-based name recognition, entitiesare directly linked, via variable bindings within thepatterns, with descriptive phrases that make up theircontext.
These will be found in a set of four syntacticforms which are universal across entity types:appositives, predicate nominatives, prenominals, andname-modified head nouns.APPOSITIVE: Lockheed Martin, the aerospace giant,PREDICATE NOMINATIVE: Lockheed Ma~'n is a leader ininformation technology.PRENOMINAL: the defense contractor, Lockheed MartinCorporation,NAME-MODIFIED HEAD NOUN: the Lockheed MartinconglomerateThese descriptive phrases can make up adocument-specific ontology, or semantic filter, for thenamed entity which can be used to link isolated nounphrase references.
This semantic filter had its originsin our TIPSTER II research on linking organizationnames with descriptive noun phrases.OrganizationsDuring our TIPSTER II research, it was foundthat organization ames ometimes contain embeddedsemantic information which can be useful in resolvingnoun phrase coreferences.
An experiment with theNLToolset's MUC6 performance, as reported in theTIPSTER II Proceedings, showed that using thisinformation contributed five points of recall andseven of precision to the organization descriptorscore.
The technique used was to devise a semanticfilter for an organization oun phrase and compare itto previous organization ames to see if they can belinked.
In the following example, the noun phraseand named organization have jewel references incommon, which would be enough to link them.Semantic Filters:the jewelry chain =>( jewelry jewel chain )Smith Jewelers =>( smith jewelers jeweler jewel )If there is more than one candidate namedentity, file position is considered as a factor, theclosest name being the most likely referent.PersonsAs the NLToolset's coreference resolutiontechniques were expanded to other types of entities, itwas found that previous methods would not always beapplicable.
Person names do not generally containsemantic information.
For example, John Smithwould not automatically be recognized as a toiletmanufacturer.
For this reason, the semantic filtermust rely solely on syntactically linked semanticinformation.
For persons, however, the standard setof four forms (appositive, prenominal, predicatenominative, and name-modified head noun) can be46expanded to include person-specific information, suchas titles, as in the following example.The Judiciary Committee voted today on the impeachment ofPresident Nixon.
The president has announced that he willresign.VehiclesThe vehicle category is problematic becauseentities are often referred to by the type of vehicle,rather than by a specific name.
For example, anairplane name might be Boeing 747 or F-14.
Since itis possible to have several vehicles of the same typediscussed in a document, all with the same "name,"the NLToolset's standard name linking algorithmdoes not apply.
The decision to link names mustcome later, at the event level, when more informationis known.Once the air vehicle names have been identified,airplane noun phrases are found and coreferenceresolution is performed, using the followingalgorithm.
Assume that a noun phrase match belongswith the most recently seen entity, unless there issome contradictory information.
If there is, then thecurrent match is compared to the next most recentlyseen entity.
If a match contradicts all previously seenentities, then it represents a new entity.
The possibletypes of contradictory information currently aremodel information, manufacturer, military branch,airline, and flight number.
The variable bindingfeature of the NLToolset pattern language allows thedeveloper to extract ype information during the namerecognition process.
For example, when the patternfor F-14 is constructed, the developer can inject theknowledge that plane types beginning with the letter Fare considered fighter planes.
This knowledge willallow the NLToolset to link the phrase "the fighter" tothe named plane; moreover, it will prevent he phrase"the helicopter" from being linked.
The algorithm forperson and organization coreference resolutionassumes that a noun phrase is not related unless thereis some evidence to prove it, in direct contrast o thatfor vehicles.Quantified ArtifactsQuantified artifacts, such as drug amounts, arehandled with a straightforward algorithm that isusually successful, having achieved accuracy above90% in the prototype application.All measured amounts of drugs are identified asunique entities.
Generic noun phrases then can referto the last mention of a drug, based on the specificityof the drug type.
For example, the drugs would referto the last drug entity regardless of type, while thecocaine would refer to the last cocaine entity.
Anexception to the rule is the case where the nounphrase is actually referring to a group of drugamounts.
In that case, context clues would need to beconsidered in order to handle that occurrence.
This isan area that has been identified for improvement.Measurement terms alone can indicate a drugamount within an elliPSiS, as in the followingexample.17 kg.
of cocaine was found in the trunk of the car, while 2 kg.were found in the glove compartment.To resolve this coreference to a common drugtype, cocaine, the algorithm picks up the last mentionof the drug from a drug stack, which keeps track ofwhich drug was mentioned last.A problematic ase is that in which a drugseizure is referred to in general terms, giving the totalamount of drugs seized, and then gives a breakdownof the amounts.
The NLToolset will identify allmeasured rug amounts as unique.
Currently, thereare no heuristics to check on redundancy of seizureinformation, based on quantity captured.
This will bean area to explore in future work, as the prototype isbrought o an operational level.3.
DOCUMENT ZONINGDuring the development of the drug seizureapplication, it became apparent that knowledge of thestructure of the document would be of help in limitingthe coreference resolution to semantically relatedzones.
Often, a document is sent to conveyinformation on multiple topics and/or locations.
If thetext processing system does not recognize a topicshift, it may incorrectly relate unrelated information.The challenge is to zone the document beforeinformation extraction begins.
As with most text-processing problems, zoning must be determined viaboth structure and meaning, i.e.
the syntax andsemantics of the document.Authors often use visual cues, such as skippedlines and indentation to alert the reader to shifts intonew topics.
Since text processing techniques havebeen developed for character streams, it is difficult forthem to interpret the visual cues that are twodimensional in nature, rather than linear.
Our currentwork is seeking to apply image understandingtechniques to this problem by constructing anauxiliary grid representation f the text and applyingtwo dimensional pattern matching, in order to extractthe nature of the document's structure.47Knowledge of the structure must then besupplemented with knowledge of the semantics of thestructure.
This will make it possible for the textprocessing system to go beyond the structuralcomponents of paragraph and table to find thesemantic zones of the document which tie structuralcomponents together.
For example, a single word atthe beginning of a paragraph may have significanceonly because of the fact that it is a country name.SPAINLOCAL POLICE HA VE SEIZED ...Depending on the source of the document, theauthor may insert outline characters to help the readerinterpret the structure of the story.A.
PUERTO RICO: ON JULY  5, MARIT IME OFFICERS ...Th~ outline styles are often standard formswhich have been tailored by the author, so anautomatic system must be able to interpret varyingstyles.
In the following, the location will span severalblocks of text, marked alphabetically.1.
CALIFORNIAA.
JULY 5, OFFICERS SUSPECTED.
.
.B.
JULY  7, LOCAL LAW ENFORCEMENT SEIZED ...Pattern matching techniques are being applied atthe tokenizer level to identify structure markers andlook for the outline patterns.Zoning is a topic of ongoing research which isalso being applied to the problem of tabularinformation.BlockFinderImage understanding techniques have beenapplied to the problem of recognizing the structure oftext.
BlockFinder, a prototype of a new NLToolsettool, uses two-dimensional patterns to find the edgesin a grid of text.
It converts an input text file into alist of blocks separated by white space.The BlockFinder is the component of NLToolsetthat looks at a text file from a two dimensionalperspective.
Characters from the file are arranged ina two dimensional grid where the rows of the grid areseparated by newline characters.
By treating thischaracter grid as an image, it is possible to findsections of text which are isolated by white space.Now that the computer has a representation f a filethat reflects how the characters would appear on apage, it is feasible to look "above" and "below"characters in a file to find boundaries where textmeets white space.
In this way the BlockFinder canpick up on zoning cues which are obvious to a humanreader but which have proved elusive for computers.Here is an overview of the BlockFinderalgorithm.1.
Characters from the file stream areinserted into a 2-D array.
Anewline character starts a newline of the array.
Tab charactersinsert white space up to the nexteight character tab stop.2.
Each character is classified as text,punctuation, or white space.3.
White space consistent with normalword spacing within a block oftext is filtered out.
These spacecharacters are reclassified astext.4.
Punctuation consistent with standardEnglish is filtered out.
Thesepunctuation characters arereclassified as text.5.
The boundaries between text andnon-text characters are markedas edges.6.
Adjacent edges are linked together toform longer straight edges.7.
The long straight edges are groupedto trace the boundaries of textblocks.8.
These text blocks are flagged asdocument zones.Most of the blocks detected by the BlockFinderare sections and paragraphs within a document.These blocks are continuous; they can be representedby a start and end position in the file stream.
TheBlockFinder finds other (non-continuous) blocks aswell.
A primary example of a non-continuous blockis a column of a table.
Work is underway to have theBlockFinder isolate and organize these column blocksinto a table structure that would allow the NLToolsetto interpret tabular data.Whether the identified blocks represent tabularcolumns, paragraphs, or sections of a document, theycontain important clues to the document'sorganization.
These clues help the human reader tounderstand the document.
The BlockFinder allowsthe NLToolset to use these same clues to break thedocument into logical zones which should, in turn,improve the quality of the coreferences generated.48Outline MatchingThe author of a document has an almost infinitevariety of conventions from which to choose toindicate text grouping.
Sections, sub-sections, orparagraphs can be separated by blank lines, or byoutline symbols, or by some arbitrary indentation withno blank lines.
A system that can also use outlinecharacters and indentation as well as blocks will bemore successful than one that works with blocksalone.The outline hierarchy of a document is indicatedby the order in which the outline symbols appear.In our prototype, during tokenization, an outlinelabel (a letter or number) is recognized as one or twodigits or letters followed by a "."
at the beginning of aline.
The tokenizer then inserts the title "outline-letter," "outline-number," or "outline-roman.
''2Pattern matching is used to determine hierarchyby position in the file.
If the first occurrence of anoutline title is a Roman numeral, then we know thatRoman numerals are being used as the top outlinelevel.
Similarly, if the second type of outline title toappear (that is not Roman) is an outline letter andlastly an outline number, then we have identified thestyle.
This pattern matching is used to create newlabels that indicate hierarchy: outlinel, outline2,outline3, etc.
Next, we simply find and group eachoutline label and the text associated with it intocomponent objects.Internal structures are used to group the Outlinecomponents into parent-child relationships thatrepresent zone structure.IndentationNext, we intend to look at indentation to indicatethe breaking of a block of text into smaller units (i.e.paragraph).
In our prototype, if the indentation isgreater at the break point than the indentation at thestart of the containing block, the new units will begrouped as children of the containing block.Otherwise, the new units are sibling s to the containingblock.Semantic ZonesThe idea behind using the blocks, outlines, andindentation, is to create the basic document structure2 Exceptions are made for single digit Romannumerals, I V, X, etc., which can either epresentRoman numerals or letters, depending on the context.first, refining at each step, using the new information.Once the structure has been built, we will usesemantic pattern matching to determine the meaningof the structure based on prior information concerningthe document style.
For example, in the case of theapplication under discussion, document sections aresometimes marked with location names that haveeither no outline labels or an outlinel label.
So, thecollection of components that start with a locationname is a document section, and it and all its childrencan be treated as a single zone.When the document sections and subsectionshave been identified, the code can verify that thereference token retrieved is in the same documentsection as the current oken.
If it is not, than it is notan accurate reference.
Also, since the location in thesection header has been identified, it is clearly thedefault location for any event found in that section.4.
CONCLUSIONS AND FUTUREWORKResearch is ongoing to expand the capability ofthe NLToolset's coreference r solution module.Location MergingThe location template for the drug seizureapplication contains slots to hold information aboutthe locale (a descriptive, such as Highway 40), thecity, state, country, latitude/longitude, r gion or bodyof water.
To extract a complete representation f thelocation for an event, the NLToolset must collect alllocation references and merge them into a completedescription of the location.
In the following example,a pattern to extract seizure information may pick upboth the city, San Felipe, and the locale, Highway 32.These must then be merged into one template, basedon the knowledge that they are related via the seizureextraction pattern.
Additionally, the countryinformation must then be added.
While it is possibleto use the gazetteer to look up city names in order tofind the associated country, sometimes a city namehas been used in more than one country, and otherinformation, such as zoning information, must be usedto disambiguate.
Another problem is that not allevents occur in large cities; small towns are notusually listed in the gazetteer.1.
BOLIVIAA.
LA PAZ: ON JULY 8 COAST GUARD PATROLSSIGHTED...B. SAN FELIPE: JULY 7, LOCAL LAW ENFORCEMENTOFFICERS SEIZED 2 TONS OF COCAINE ON HIGHWAY 32.49Location merging capability, based on event andzoning information, will be added to the NLToolset inthe near future.Event Coreference ResolutionDuring development of the applicationprototype, event coreference r solution was identifiedas a necessary technique to better the accuracy of thesystem.
The following example illustrates theproblem.17 KG.
OF COCAINE WERE SEIZED IN MIAMI.
THEOPERATION WAS CONDUCTED BY A TEAM CONSISTINGOF THE FBI, THE COAST GUARD, AND LOCALAUTHORITIES.In order to tie in the seizing organizations to theseizure event, the system must be able to identify thereferent of operation as the entire seizure event.
Thisis coreference r solution at a later stage of processingthan that for entities; it must occur after the mainevents have been identified.
The plan is to applypatterns which match nominalized event forms, and tolink them to the known events, based on zoninginformation.Event MergingEvent merging is a challenging part of extractingcomplex scenario templates.
Authors usually spreadinformation across several sentences, depending onthe understanding of the reader to link the relatedinformation.
The following example illustrates thispoint.17 KG OF COCAINE WAS SEIZED ON THE HMS PINAFORE.THE VESSEL HAD EMBARKED FROM CALl AND WASHEADED FOR MIAMI.Thoroughly understanding the text is notsomething that automatic text processing systemscurrently do successfully.
In fact, the most successfulinformation extraction systems long ago gave up thegoal of completely understanding free text.
Targetedextraction of relevant information has been the mostfruitful strategy, thus far.To continue in this tradition, our TIPSTERresearch as identified two techniques to investigateas solutions to the event merging problem.
The firstis entity-based event merging.
This technique isbased on the observation that the entity coreferenceresolution can act as a vehicle for linking secondaryinformation.
In the previous example, having linkedthe vessel with the platform HMS Pinafore wouldallow the origin and destination of the vessel tomigrate back to the extracted seizure event via thecoreference chain.The second technique to be developed is basedon the idea that a particular event is usually composedof a finite set of predictable activities.
For example, asuccessful Coast Guard seizure operation may becomposed of patrolling, boarding, arresting, andseizing activities.
This is not a new idea in the fieldof Artificial Intelligence.Since extracting isolated event information issomething that the NLToolset does very well, it isthought that a profile of an event can be modeled.The profile would consist of a main event and itsassociated events.
The NLToolset could then mergethe extracted information based on the compatibilityof its participating entities and zoning information.Something like this was developed on a limited basisfor the joint venture scenario template of the originalTIPSTER program.
In that case, the LISP version ofthe NLToolset alowed ownership information to bemerged into the main event of joint venture based onentity compatibility.The differences between the two techniques,entity-based and profile-based event merging, aresubtle.
Both require the construction of patterns forextracting associated event information.
The maindifference is that, in the former, the associatedinformation, e.g.
vessel destination, is tied to theentities involved.
This method does not preclude thepossibility that an entity may be involved in morethan one event; however, event merging, as a stepafter event extraction, is not required.With profile-based event merging, the entityinformation is kept associated with the extractedevent and merging takes place after all events havebeen extracted.
As the application is expanded tohandle more than one type of main event, there maybe overlaps among the profiled subevents.Both techniques will be investigated under theremainder of the current TIPSTER research effort.SummaryThis paper has discussed the evolution of thecoreference resolution techniques of the NLToolset,as they have been applied to an information extractionapplication, similar to the MUC Scenario Templatetasks.
It has also discussed current work onunderstanding document structure, as well as futurework on improving information merging techniques.50
